3116ea2053d9de960ec3753eb07f3d243c370662aa1f0175ad357057c9ce5a52
main
public static void main(String[] args)
{    System.out.println("- Downloader started");    File baseDirectory = new File(args[0]);    System.out.println("- Using base directory: " + baseDirectory.getAbsolutePath());            File mavenWrapperPropertyFile = new File(baseDirectory, MAVEN_WRAPPER_PROPERTIES_PATH);    String url = DEFAULT_DOWNLOAD_URL;    if (mavenWrapperPropertyFile.exists()) {        FileInputStream mavenWrapperPropertyFileInputStream = null;        try {            mavenWrapperPropertyFileInputStream = new FileInputStream(mavenWrapperPropertyFile);            Properties mavenWrapperProperties = new Properties();            mavenWrapperProperties.load(mavenWrapperPropertyFileInputStream);            url = mavenWrapperProperties.getProperty(PROPERTY_NAME_WRAPPER_URL, url);        } catch (IOException e) {            System.out.println("- ERROR loading '" + MAVEN_WRAPPER_PROPERTIES_PATH + "'");        } finally {            try {                if (mavenWrapperPropertyFileInputStream != null) {                    mavenWrapperPropertyFileInputStream.close();                }            } catch (IOException e) {                        }        }    }    System.out.println("- Downloading from: : " + url);    File outputFile = new File(baseDirectory.getAbsolutePath(), MAVEN_WRAPPER_JAR_PATH);    if (!outputFile.getParentFile().exists()) {        if (!outputFile.getParentFile().mkdirs()) {            System.out.println("- ERROR creating output direcrory '" + outputFile.getParentFile().getAbsolutePath() + "'");        }    }    System.out.println("- Downloading to: " + outputFile.getAbsolutePath());    try {        downloadFileFromURL(url, outputFile);        System.out.println("Done");        System.exit(0);    } catch (Throwable e) {        System.out.println("- Error downloading");        e.printStackTrace();        System.exit(1);    }}
2c94ce339013a89f688fb49c4fcc9e035e31e12f304d887ab8f8c4fb3c497535
downloadFileFromURL
private static void downloadFileFromURL(String urlString, File destination) throws Exception
{    URL website = new URL(urlString);    ReadableByteChannel rbc;    rbc = Channels.newChannel(website.openStream());    FileOutputStream fos = new FileOutputStream(destination);    fos.getChannel().transferFrom(rbc, 0, Long.MAX_VALUE);    fos.close();    rbc.close();}
c81fbd5877072a1c84999b77c619e8b604ae6df64688738f44d1cc916ea34a40
getThriftInstance
public static RpcClient getThriftInstance(Properties props)
{    ThriftRpcClient client = new SecureThriftRpcClient();    client.configure(props);    return client;}
fa4f42f502232e3df3e3fcca36975ce5c8d1abbffe40e7f6c43927c7172af8aa
configure
protected void configure(Properties properties) throws FlumeException
{    super.configure(properties);    serverPrincipal = properties.getProperty(SERVER_PRINCIPAL);    if (serverPrincipal == null || serverPrincipal.isEmpty()) {        throw new IllegalArgumentException("Flume in secure mode, but Flume config doesn't " + "specify a server principal to use for Kerberos auth.");    }    String clientPrincipal = properties.getProperty(CLIENT_PRINCIPAL);    String keytab = properties.getProperty(CLIENT_KEYTAB);    this.privilegedExecutor = FlumeAuthenticationUtil.getAuthenticator(clientPrincipal, keytab);    if (!privilegedExecutor.isAuthenticated()) {        throw new FlumeException("Authentication failed in Kerberos mode for " + "principal " + clientPrincipal + " keytab " + keytab);    }}
30561a0117c71b5fb3657e6125e0ae03f7f53220317e3ac7ea0745435f1e0f52
getTransport
protected TTransport getTransport(TSocket tsocket) throws Exception
{    Map<String, String> saslProperties = new HashMap<String, String>();    saslProperties.put(Sasl.QOP, "auth");    String[] names;    try {        names = FlumeAuthenticationUtil.splitKerberosName(serverPrincipal);    } catch (IOException e) {        throw new FlumeException("Error while trying to resolve Principal name - " + serverPrincipal, e);    }    return new UgiSaslClientTransport("GSSAPI", null, names[0], names[1], saslProperties, null, tsocket, privilegedExecutor);}
fd1b6ddac4f075638dad22b8ece4fc60f699953bf2fd7ba6aafc75dce7729044
open
public void open() throws FlumeException
{    try {        this.privilegedExecutor.execute(new PrivilegedExceptionAction<Void>() {            public Void run() throws FlumeException {                                                callSuperClassOpen();                return null;            }        });    } catch (InterruptedException e) {        throw new FlumeException("Interrupted while opening underlying transport", e);    } catch (Exception e) {        throw new FlumeException("Failed to open SASL transport", e);    }}
c89a9bfd6d74637a562ecb943be281a98f3ee5be22bef60c37b4d51b9d5bcf93
run
public Void run() throws FlumeException
{            callSuperClassOpen();    return null;}
4e67463cfbf7ba8d278b89777068b0cfc96f5a7f2471c319bf40bfe1ecf4d081
callSuperClassOpen
private void callSuperClassOpen() throws FlumeException
{    try {        super.open();    } catch (TTransportException e) {        throw new FlumeException("Failed to open SASL transport", e);    }}
6c9ff369edf7279763dddec5391569393156070f43327f25829a1e91cb2acc70
getAuthenticator
public static synchronized FlumeAuthenticator getAuthenticator(String principal, String keytab) throws SecurityException
{    if (principal == null && keytab == null) {        return SimpleAuthenticator.getSimpleAuthenticator();    }    Preconditions.checkArgument(principal != null, "Principal can not be null when keytab is provided");    Preconditions.checkArgument(keytab != null, "Keytab can not be null when Principal is provided");    if (kerbAuthenticator == null) {        kerbAuthenticator = new KerberosAuthenticator();    }    kerbAuthenticator.authenticate(principal, keytab);    return kerbAuthenticator;}
fcf2eaa69548ccfb2470fdc424c0615367c43d541e2219ab590ece34d2643543
getSaslGssCallbackHandler
public static CallbackHandler getSaslGssCallbackHandler()
{    return new SaslRpcServer.SaslGssCallbackHandler();}
8b7b22d1a3f88990644a5ad03656382f3e6e8e87987f742a0f65c50fa9c66410
splitKerberosName
public static String[] splitKerberosName(String principal) throws IOException
{    String resolvedPrinc = SecurityUtil.getServerPrincipal(principal, "");    return SaslRpcServer.splitKerberosName(resolvedPrinc);}
fdc3107f80848d4b46dfad80bb372064dc0bdc3215374226a8d432403d418098
clearCredentials
 static void clearCredentials()
{    kerbAuthenticator = null;}
aa813644385e5ba744e61299ec5d565be49239365cf13c5cc326100b22a1d107
execute
public T execute(PrivilegedAction<T> action)
{    return privilegedExecutor.execute(action);}
de7d76eb38acb5046a5f656bfc11877daa63d9f94df85c9d9d89859052cf5f11
execute
public T execute(PrivilegedExceptionAction<T> action) throws Exception
{    return privilegedExecutor.execute(action);}
6df24b5c768f387d97a984f10e433c08f2bee1758d41bc87fa806896e4d35aa8
proxyAs
public synchronized PrivilegedExecutor proxyAs(String proxyUserName)
{    if (proxyUserName == null || proxyUserName.isEmpty()) {        return this;    }    if (proxyCache.get(proxyUserName) == null) {        UserGroupInformation proxyUgi;        proxyUgi = UserGroupInformation.createProxyUser(proxyUserName, ugi);        printUGI(proxyUgi);        proxyCache.put(proxyUserName, new UGIExecutor(proxyUgi));    }    return proxyCache.get(proxyUserName);}
dc65f02fa1d333f908424da1b3350b52f4bc6fefe9646d1266e579e3c5be7951
isAuthenticated
public boolean isAuthenticated()
{    return true;}
54a3c260124754f3c9c54d896ccc2e068569c986b51efa46640aa57aee38e985
authenticate
public synchronized void authenticate(String principal, String keytab)
{        Preconditions.checkArgument(principal != null && !principal.isEmpty(), "Invalid Kerberos principal: " + String.valueOf(principal));    Preconditions.checkArgument(keytab != null && !keytab.isEmpty(), "Invalid Kerberos keytab: " + String.valueOf(keytab));    File keytabFile = new File(keytab);    Preconditions.checkArgument(keytabFile.isFile() && keytabFile.canRead(), "Keytab is not a readable file: " + String.valueOf(keytab));        String resolvedPrincipal;    try {                        resolvedPrincipal = SecurityUtil.getServerPrincipal(principal, "");    } catch (IOException e) {        throw new IllegalArgumentException("Host lookup error resolving kerberos principal (" + principal + "). Exception follows.", e);    }    Preconditions.checkNotNull(resolvedPrincipal, "Resolved Principal must not be null");                            KerberosUser newUser = new KerberosUser(resolvedPrincipal, keytab);    Preconditions.checkState(prevUser == null || prevUser.equals(newUser), "Cannot use multiple kerberos principals in the same agent. " + " Must restart agent to use new principal or keytab. " + "Previous = %s, New = %s", prevUser, newUser);        if (!UserGroupInformation.isSecurityEnabled()) {        Configuration conf = new Configuration(false);        conf.set(HADOOP_SECURITY_AUTHENTICATION, "kerberos");        UserGroupInformation.setConfiguration(conf);    }        UserGroupInformation curUser = null;    try {        curUser = UserGroupInformation.getLoginUser();        if (curUser != null && !curUser.hasKerberosCredentials()) {            curUser = null;        }    } catch (IOException e) {        LOG.warn("User unexpectedly had no active login. Continuing with " + "authentication", e);    }    /*     *  if ugi is not null,     *     if ugi matches currently logged in kerberos user, we are good     *     else we are logged out, so relogin our ugi     *  else if ugi is null, login and populate state     */    try {        if (ugi != null) {            if (curUser != null && curUser.getUserName().equals(ugi.getUserName())) {                LOG.debug("Using existing principal login: {}", ugi);            } else {                LOG.info("Attempting kerberos Re-login as principal ({}) ", new Object[] { ugi.getUserName() });                ugi.reloginFromKeytab();            }        } else {            LOG.info("Attempting kerberos login as principal ({}) from keytab " + "file ({})", new Object[] { resolvedPrincipal, keytab });            UserGroupInformation.loginUserFromKeytab(resolvedPrincipal, keytab);            this.ugi = UserGroupInformation.getLoginUser();            this.prevUser = new KerberosUser(resolvedPrincipal, keytab);            this.privilegedExecutor = new UGIExecutor(this.ugi);        }    } catch (IOException e) {        throw new SecurityException("Authentication error while attempting to " + "login as kerberos principal (" + resolvedPrincipal + ") using " + "keytab (" + keytab + "). Exception follows.", e);    }    printUGI(this.ugi);}
64eb57ac9fb2dfb55440bc66aa15710f7aac49ab4e56e3b672daaf4ce1e99a64
printUGI
private void printUGI(UserGroupInformation ugi)
{    if (ugi != null) {                AuthenticationMethod authMethod = ugi.getAuthenticationMethod();        LOG.info("\n{} \nUser: {} \nAuth method: {} \nKeytab: {} \n", new Object[] { authMethod.equals(AuthenticationMethod.PROXY) ? "Proxy as: " : "Logged as: ", ugi.getUserName(), authMethod, ugi.isFromKeytab() });    }}
67dd6beca10a7a8e757eb21a8c74fafd696e2a1188ec5c9be8f73bd99048576f
startCredentialRefresher
public void startCredentialRefresher()
{        int CHECK_TGT_INTERVAL = 120;    ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1);    scheduler.scheduleWithFixedDelay(new Runnable() {        @Override        public void run() {            try {                ugi.checkTGTAndReloginFromKeytab();            } catch (IOException e) {                LOG.warn("Error occured during checkTGTAndReloginFromKeytab() for user " + ugi.getUserName(), e);            }        }    }, CHECK_TGT_INTERVAL, CHECK_TGT_INTERVAL, TimeUnit.SECONDS);}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    try {        ugi.checkTGTAndReloginFromKeytab();    } catch (IOException e) {        LOG.warn("Error occured during checkTGTAndReloginFromKeytab() for user " + ugi.getUserName(), e);    }}
cd5218eb32fac43635af225cee6a361bdf95f3a2233a5a942ce695f8011a5612
getUserName
 String getUserName()
{    if (ugi != null) {        return ugi.getUserName();    } else {        return null;    }}
40e1cf9248326abb178dce50e316b4055970fcd93d8f6e734201f68ebbc066e3
getPrincipal
public String getPrincipal()
{    return principal;}
a05c4a1e8a08d59c9b8ca03c745f80a27acbb567aa7720bd5a5304c3e4d11cb1
getKeyTab
public String getKeyTab()
{    return keyTab;}
4afeb0868b55bdd8e18a00a3cb43d83e0714378d1c4bb36f0936daefc060e2e8
equals
public boolean equals(Object obj)
{    if (obj == null) {        return false;    }    if (getClass() != obj.getClass()) {        return false;    }    final KerberosUser other = (KerberosUser) obj;    if ((this.principal == null) ? (other.principal != null) : !this.principal.equals(other.principal)) {        return false;    }    if ((this.keyTab == null) ? (other.keyTab != null) : !this.keyTab.equals(other.keyTab)) {        return false;    }    return true;}
0ac42bf5188762fc1283b5cbd2b3bb1031e80963813b3b310b15c3fb47050003
hashCode
public int hashCode()
{    int hash = 7;    hash = 41 * hash + (this.principal != null ? this.principal.hashCode() : 0);    hash = 41 * hash + (this.keyTab != null ? this.keyTab.hashCode() : 0);    return hash;}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return "{ principal: " + principal + ", keytab: " + keyTab + " }";}
0445399c7b72d4e47ef4011e64e051b5bbf9e334c3d00abd291b9c5a3e305b04
getSimpleAuthenticator
public static SimpleAuthenticator getSimpleAuthenticator()
{    return SimpleAuthenticatorHolder.authenticator;}
de7d76eb38acb5046a5f656bfc11877daa63d9f94df85c9d9d89859052cf5f11
execute
public T execute(PrivilegedExceptionAction<T> action) throws Exception
{    return action.run();}
aa813644385e5ba744e61299ec5d565be49239365cf13c5cc326100b22a1d107
execute
public T execute(PrivilegedAction<T> action)
{    return action.run();}
6df24b5c768f387d97a984f10e433c08f2bee1758d41bc87fa806896e4d35aa8
proxyAs
public synchronized PrivilegedExecutor proxyAs(String proxyUserName)
{    if (proxyUserName == null || proxyUserName.isEmpty()) {        return this;    }    if (proxyCache.get(proxyUserName) == null) {        UserGroupInformation proxyUgi;        try {            proxyUgi = UserGroupInformation.createProxyUser(proxyUserName, UserGroupInformation.getCurrentUser());        } catch (IOException e) {            throw new SecurityException("Unable to create proxy User", e);        }        proxyCache.put(proxyUserName, new UGIExecutor(proxyUgi));    }    return proxyCache.get(proxyUserName);}
dc65f02fa1d333f908424da1b3350b52f4bc6fefe9646d1266e579e3c5be7951
isAuthenticated
public boolean isAuthenticated()
{    return false;}
67dd6beca10a7a8e757eb21a8c74fafd696e2a1188ec5c9be8f73bd99048576f
startCredentialRefresher
public void startCredentialRefresher()
{}
aa813644385e5ba744e61299ec5d565be49239365cf13c5cc326100b22a1d107
execute
public T execute(PrivilegedAction<T> action)
{    ensureValidAuth();    return ugi.doAs(action);}
de7d76eb38acb5046a5f656bfc11877daa63d9f94df85c9d9d89859052cf5f11
execute
public T execute(PrivilegedExceptionAction<T> action) throws Exception
{    ensureValidAuth();    return ugi.doAs(action);}
8ce03c64e58d08a48c0e1a4fb5af90b31da701bbb1b6efc349f357da43448e20
ensureValidAuth
private void ensureValidAuth()
{    reloginUGI(ugi);    if (ugi.getAuthenticationMethod().equals(AuthenticationMethod.PROXY)) {        reloginUGI(ugi.getRealUser());    }}
e7091faf208f995bfbf7db6925ad1953cdf5f4d65ed246d639c5eea8bc3f3f57
reloginUGI
private void reloginUGI(UserGroupInformation ugi)
{    try {        if (ugi.hasKerberosCredentials()) {            long now = System.currentTimeMillis();            if (now - lastReloginAttempt < MIN_TIME_BEFORE_RELOGIN) {                return;            }            lastReloginAttempt = now;            ugi.checkTGTAndReloginFromKeytab();        }    } catch (IOException e) {        throw new SecurityException("Error trying to relogin from keytab for user " + ugi.getUserName(), e);    }}
cd5218eb32fac43635af225cee6a361bdf95f3a2233a5a942ce695f8011a5612
getUserName
 String getUserName()
{    if (ugi != null) {        return ugi.getUserName();    } else {        return null;    }}
d89d570373cc3f1e47e89bd8e5ba6e68c9a05d25f832a6567174a4dcf6476c14
startMiniKdc
public static void startMiniKdc() throws Exception
{    workDir = new File(System.getProperty("test.dir", "target"), TestFlumeAuthenticator.class.getSimpleName());    flumeKeytab = new File(workDir, "flume.keytab");    aliceKeytab = new File(workDir, "alice.keytab");    conf = MiniKdc.createConf();    kdc = new MiniKdc(conf, workDir);    kdc.start();    kdc.createPrincipal(flumeKeytab, flumePrincipal);    flumePrincipal = flumePrincipal + "@" + kdc.getRealm();    kdc.createPrincipal(aliceKeytab, alicePrincipal);    alicePrincipal = alicePrincipal + "@" + kdc.getRealm();}
9fc1da8ac56d93321965bcabaa15fcdaff1fb66dece61770035efba65bae6c40
stopMiniKdc
public static void stopMiniKdc()
{    if (kdc != null) {        kdc.stop();    }}
39e5ba029cc67f6f1d45c6d20f0df595ec16bc61da20d7680fcbbdae4fe7f95b
tearDown
public void tearDown()
{        FlumeAuthenticationUtil.clearCredentials();}
df006f93846f0a76da81bb1b30e51d748c4dc2dec927db1670cd4e1094c3f61e
testNullLogin
public void testNullLogin() throws IOException
{    String principal = null;    String keytab = null;    FlumeAuthenticator authenticator = FlumeAuthenticationUtil.getAuthenticator(principal, keytab);    assertFalse(authenticator.isAuthenticated());}
d6f188250086af0e20f91c2b82d4010d35bfdda8788bea2d61cb1bc4f29f1955
testFlumeLogin
public void testFlumeLogin() throws IOException
{    String principal = flumePrincipal;    String keytab = flumeKeytab.getAbsolutePath();    String expResult = principal;    FlumeAuthenticator authenticator = FlumeAuthenticationUtil.getAuthenticator(principal, keytab);    assertTrue(authenticator.isAuthenticated());    String result = ((KerberosAuthenticator) authenticator).getUserName();    assertEquals("Initial login failed", expResult, result);    authenticator = FlumeAuthenticationUtil.getAuthenticator(principal, keytab);    result = ((KerberosAuthenticator) authenticator).getUserName();    assertEquals("Re-login failed", expResult, result);    principal = alicePrincipal;    keytab = aliceKeytab.getAbsolutePath();    try {        authenticator = FlumeAuthenticationUtil.getAuthenticator(principal, keytab);        result = ((KerberosAuthenticator) authenticator).getUserName();        fail("Login should have failed with a new principal: " + result);    } catch (Exception ex) {        assertTrue("Login with a new principal failed, but for an unexpected " + "reason: " + ex.getMessage(), ex.getMessage().contains("Cannot use multiple kerberos principals"));    }}
fcde8eef5a4f6fe9234549d6be633513daa7b236d3d1e93f4fc18358c9cb845e
testKerberosAuthenticatorExceptionInExecute
public void testKerberosAuthenticatorExceptionInExecute() throws Exception
{    String principal = flumePrincipal;    String keytab = flumeKeytab.getAbsolutePath();    FlumeAuthenticator authenticator = FlumeAuthenticationUtil.getAuthenticator(principal, keytab);    assertTrue(authenticator instanceof KerberosAuthenticator);    authenticator.execute(new PrivilegedExceptionAction<Object>() {        @Override        public Object run() throws Exception {            throw new IOException();        }    });}
708d7ba28c5e644e54301c3016fb4782ea395f002f5494bf26bbb64a66532a9a
run
public Object run() throws Exception
{    throw new IOException();}
832d8ba573cfd71509dc5d2218b6b4b0dcb332a589342c7ceeaee4a96686c3bc
testSimpleAuthenticatorExceptionInExecute
public void testSimpleAuthenticatorExceptionInExecute() throws Exception
{    FlumeAuthenticator authenticator = FlumeAuthenticationUtil.getAuthenticator(null, null);    assertTrue(authenticator instanceof SimpleAuthenticator);    authenticator.execute(new PrivilegedExceptionAction<Object>() {        @Override        public Object run() throws Exception {            throw new IOException();        }    });}
708d7ba28c5e644e54301c3016fb4782ea395f002f5494bf26bbb64a66532a9a
run
public Object run() throws Exception
{    throw new IOException();}
1e393123049f0601a07cd63de531bc748b7964879c07d1d6e96fc456e3f4446e
testProxyAs
public void testProxyAs() throws IOException
{    String username = "alice";    String expResult = username;    FlumeAuthenticator authenticator = FlumeAuthenticationUtil.getAuthenticator(null, null);    String result = ((UGIExecutor) (authenticator.proxyAs(username))).getUserName();    assertEquals("Proxy as didn't generate the expected username", expResult, result);    authenticator = FlumeAuthenticationUtil.getAuthenticator(flumePrincipal, flumeKeytab.getAbsolutePath());    String login = ((KerberosAuthenticator) authenticator).getUserName();    assertEquals("Login succeeded, but the principal doesn't match", flumePrincipal, login);    result = ((UGIExecutor) (authenticator.proxyAs(username))).getUserName();    assertEquals("Proxy as didn't generate the expected username", expResult, result);}
63fd5995668f7c2d7f9d6436d501c9a38e7046d634565746a2c2737ba66c62f4
testFlumeLoginPrincipalWithoutRealm
public void testFlumeLoginPrincipalWithoutRealm() throws Exception
{    String principal = "flume";    File keytab = new File(workDir, "flume2.keytab");    kdc.createPrincipal(keytab, principal);    String expResult = principal + "@" + kdc.getRealm();    FlumeAuthenticator authenticator = FlumeAuthenticationUtil.getAuthenticator(principal, keytab.getAbsolutePath());    assertTrue(authenticator.isAuthenticated());    String result = ((KerberosAuthenticator) authenticator).getUserName();    assertEquals("Initial login failed", expResult, result);    authenticator = FlumeAuthenticationUtil.getAuthenticator(principal, keytab.getAbsolutePath());    result = ((KerberosAuthenticator) authenticator).getUserName();    assertEquals("Re-login failed", expResult, result);    principal = "alice";    keytab = aliceKeytab;    try {        authenticator = FlumeAuthenticationUtil.getAuthenticator(principal, keytab.getAbsolutePath());        result = ((KerberosAuthenticator) authenticator).getUserName();        fail("Login should have failed with a new principal: " + result);    } catch (Exception ex) {        assertTrue("Login with a new principal failed, but for an unexpected " + "reason: " + ex.getMessage(), ex.getMessage().contains("Cannot use multiple kerberos principals"));    }}
6bf7573bb5d07e10c5afe362cfb201e8e048eff387dc844dea55e00cd6fc23bb
rebuild
public boolean rebuild() throws IOException, Exception
{    LOG.info("Attempting to fast replay the log files.");    List<LogFile.SequentialReader> logReaders = Lists.newArrayList();    for (File logFile : logFiles) {        try {            logReaders.add(LogFileFactory.getSequentialReader(logFile, null, fsyncPerTransaction));        } catch (EOFException e) {            LOG.warn("Ignoring " + logFile + " due to EOF", e);        }    }    long transactionIDSeed = 0;    long writeOrderIDSeed = 0;    try {        for (LogFile.SequentialReader log : logReaders) {            LogRecord entry;            int fileID = log.getLogFileID();            while ((entry = log.next()) != null) {                int offset = entry.getOffset();                TransactionEventRecord record = entry.getEvent();                long trans = record.getTransactionID();                long writeOrderID = record.getLogWriteOrderID();                transactionIDSeed = Math.max(trans, transactionIDSeed);                writeOrderIDSeed = Math.max(writeOrderID, writeOrderIDSeed);                if (record.getRecordType() == TransactionEventRecord.Type.PUT.get()) {                    uncommittedPuts.put(record.getTransactionID(), new ComparableFlumeEventPointer(new FlumeEventPointer(fileID, offset), record.getLogWriteOrderID()));                } else if (record.getRecordType() == TransactionEventRecord.Type.TAKE.get()) {                    Take take = (Take) record;                    uncommittedTakes.put(record.getTransactionID(), new ComparableFlumeEventPointer(new FlumeEventPointer(take.getFileID(), take.getOffset()), record.getLogWriteOrderID()));                } else if (record.getRecordType() == TransactionEventRecord.Type.COMMIT.get()) {                    Commit commit = (Commit) record;                    if (commit.getType() == TransactionEventRecord.Type.PUT.get()) {                        Set<ComparableFlumeEventPointer> puts = uncommittedPuts.get(record.getTransactionID());                        if (puts != null) {                            for (ComparableFlumeEventPointer put : puts) {                                if (!pendingTakes.remove(put)) {                                    committedPuts.add(put);                                }                            }                        }                    } else {                        Set<ComparableFlumeEventPointer> takes = uncommittedTakes.get(record.getTransactionID());                        if (takes != null) {                            for (ComparableFlumeEventPointer take : takes) {                                if (!committedPuts.remove(take)) {                                    pendingTakes.add(take);                                }                            }                        }                    }                } else if (record.getRecordType() == TransactionEventRecord.Type.ROLLBACK.get()) {                    if (uncommittedPuts.containsKey(record.getTransactionID())) {                        uncommittedPuts.removeAll(record.getTransactionID());                    } else {                        uncommittedTakes.removeAll(record.getTransactionID());                    }                }            }        }    } catch (Exception e) {        LOG.warn("Error while generating checkpoint using fast generation logic", e);        return false;    } finally {        TransactionIDOracle.setSeed(transactionIDSeed);        WriteOrderOracle.setSeed(writeOrderIDSeed);        for (LogFile.SequentialReader reader : logReaders) {            reader.close();        }    }    Set<ComparableFlumeEventPointer> sortedPuts = Sets.newTreeSet(committedPuts);    int count = 0;    for (ComparableFlumeEventPointer put : sortedPuts) {        queue.addTail(put.pointer);        count++;    }    LOG.info("Replayed {} events using fast replay logic.", count);    return true;}
89fbec33d0eea6622d2ed4eac5a3a7f6a450a6d031df42509c8faa7346354185
writeCheckpoint
private void writeCheckpoint() throws IOException
{    long checkpointLogOrderID = 0;    List<LogFile.MetaDataWriter> metaDataWriters = Lists.newArrayList();    for (File logFile : logFiles) {        String name = logFile.getName();        metaDataWriters.add(LogFileFactory.getMetaDataWriter(logFile, Integer.parseInt(name.substring(name.lastIndexOf('-') + 1))));    }    try {        if (queue.checkpoint(true)) {            checkpointLogOrderID = queue.getLogWriteOrderID();            for (LogFile.MetaDataWriter metaDataWriter : metaDataWriters) {                metaDataWriter.markCheckpoint(checkpointLogOrderID);            }        }    } catch (Exception e) {        LOG.warn("Error while generating checkpoint using fast generation logic", e);    } finally {        for (LogFile.MetaDataWriter metaDataWriter : metaDataWriters) {            metaDataWriter.close();        }    }}
d42e5c85bfdaf7e323a3e395b8786876ca9be2b14c53fd5fd7a865fa80e00716
compareTo
public int compareTo(ComparableFlumeEventPointer o)
{    if (orderID < o.orderID) {        return -1;    } else {                return 1;    }}
0ac42bf5188762fc1283b5cbd2b3bb1031e80963813b3b310b15c3fb47050003
hashCode
public int hashCode()
{    return pointer.hashCode();}
8d37d11c7ecfc0d0589696a89cb385888c83bd3e43ea0c95a3b4ae4ef78180ce
equals
public boolean equals(Object o)
{    if (this == o) {        return true;    }    if (o == null) {        return false;    }    if (o.getClass() != this.getClass()) {        return false;    }    return pointer.equals(((ComparableFlumeEventPointer) o).pointer);}
b6047c2d62e0dd012f9e8fbf9c3b04878ae171af7f5ab52171412c0b606ca520
main
public static void main(String[] args) throws Exception
{    Options options = new Options();    Option opt = new Option("c", true, "checkpoint directory");    opt.setRequired(true);    options.addOption(opt);    opt = new Option("l", true, "comma-separated list of log directories");    opt.setRequired(true);    options.addOption(opt);    options.addOption(opt);    opt = new Option("t", true, "capacity of the channel");    opt.setRequired(true);    options.addOption(opt);    CommandLineParser parser = new GnuParser();    CommandLine cli = parser.parse(options, args);    File checkpointDir = new File(cli.getOptionValue("c"));    String[] logDirs = cli.getOptionValue("l").split(",");    List<File> logFiles = Lists.newArrayList();    for (String logDir : logDirs) {        logFiles.addAll(LogUtils.getLogs(new File(logDir)));    }    int capacity = Integer.parseInt(cli.getOptionValue("t"));    File checkpointFile = new File(checkpointDir, "checkpoint");    if (checkpointFile.exists()) {        LOG.error("Cannot execute fast replay", new IllegalStateException("Checkpoint exists" + checkpointFile));    } else {        EventQueueBackingStore backingStore = EventQueueBackingStoreFactory.get(checkpointFile, capacity, "channel", new FileChannelCounter("Main"));        FlumeEventQueue queue = new FlumeEventQueue(backingStore, new File(checkpointDir, "inflighttakes"), new File(checkpointDir, "inflightputs"), new File(checkpointDir, Log.QUEUE_SET));        CheckpointRebuilder rebuilder = new CheckpointRebuilder(logFiles, queue, true);        if (rebuilder.rebuild()) {            rebuilder.writeCheckpoint();        } else {            LOG.error("Could not rebuild the checkpoint due to errors.");        }    }}
5478cc5683f6dfd4515c383752d7c803555efc63d03fd84a03ba8dcd17eb4324
readFields
public void readFields(DataInput in) throws IOException
{    super.readFields(in);    type = in.readShort();}
ff459529bcc4ea422faba6b6520c4e8654b516e08262ab0f00c35a0a8eab1287
writeProtos
 void writeProtos(OutputStream out) throws IOException
{    ProtosFactory.Commit.Builder commitBuilder = ProtosFactory.Commit.newBuilder();    commitBuilder.setType(type);    commitBuilder.build().writeDelimitedTo(out);}
ed3036c0872aa703f9545ed610d496273c0e0d83e257a6ac951369babec5826f
readProtos
 void readProtos(InputStream in) throws IOException
{    ProtosFactory.Commit commit = Preconditions.checkNotNull(ProtosFactory.Commit.parseDelimitedFrom(in), "Commit cannot be null");    type = (short) commit.getType();}
c41ecddfc0a9a3df29f8967c1a2d1a38c205333fec846621ab871a4e6269c145
getType
 short getType()
{    return type;}
a894510dd4db439ff8e17ae1059489dc3abc97178e5932ceed0c70c3af165401
write
public void write(DataOutput out) throws IOException
{    super.write(out);    out.writeShort(type);}
147f0f476f4c0d7cf6562426d486e8b3ee28674432ee6bf7aba345b8ab78c816
getRecordType
 short getRecordType()
{    return Type.COMMIT.get();}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    StringBuilder builder = new StringBuilder();    builder.append("Commit [type=");    builder.append(type);    builder.append(", getLogWriteOrderID()=");    builder.append(getLogWriteOrderID());    builder.append(", getTransactionID()=");    builder.append(getTransactionID());    builder.append("]");    return builder.toString();}
55adeb3d7e7a17cae578e2145865818ee0ea0e25d90e2ce45e6f16192c2521a1
newEncryptorBuilder
public Encryptor.Builder<AESCTRNoPaddingEncryptor> newEncryptorBuilder()
{    return new EncryptorBuilder();}
4c2195d3eeba98485775b3fbafa43c1d596fe1c8a698983cc0a522d67f30cdf2
newDecryptorBuilder
public Decryptor.Builder<AESCTRNoPaddingDecryptor> newDecryptorBuilder()
{    return new DecryptorBuilder();}
09df56b45e2a186a4621b6320d9aa8abc0347ed8b9dc83aa1e5b19450fc08c4b
build
public AESCTRNoPaddingEncryptor build()
{    ByteBuffer buffer = ByteBuffer.allocate(16);    byte[] seed = new byte[12];    SecureRandom random = new SecureRandom();    random.nextBytes(seed);    buffer.put(seed).putInt(1);    return new AESCTRNoPaddingEncryptor(key, buffer.array());}
8d8f2db587113385ce73bb790c74cb7ff5df9a8512b4fed36efc09722d654d65
build
public AESCTRNoPaddingDecryptor build()
{    return new AESCTRNoPaddingDecryptor(key, parameters);}
ee1b81ab984e2fcf7c5f27311d9fcd7a43a2a79cb16793fc4fc65c9c7043749e
getParameters
public byte[] getParameters()
{    return parameters;}
a346cd6cfa43801346dbdcc6563501719bdc00d620b4a7174d54303bd27e504d
getCodec
public String getCodec()
{    return TYPE;}
ff65a15637907c4faf1aa877012236d81c1dfe6800275132fb05a6f7fdbe0559
encrypt
public byte[] encrypt(byte[] clearText)
{    return doFinal(cipher, clearText);}
01b4496f42425ff3a4eb950075cb915c54f205b32e98261c798464bf17de1063
decrypt
public byte[] decrypt(byte[] cipherText)
{    return doFinal(cipher, cipherText);}
a346cd6cfa43801346dbdcc6563501719bdc00d620b4a7174d54303bd27e504d
getCodec
public String getCodec()
{    return TYPE;}
cf2fd6af7f622081aab476a1ba6c45fc340b6c07c0ba74bf5ff54c0cac088c20
doFinal
private static byte[] doFinal(Cipher cipher, byte[] input) throws DecryptionFailureException
{    try {        return cipher.doFinal(input);    } catch (Exception e) {        String msg = "Unable to encrypt or decrypt data " + TYPE + " input.length " + input.length;        LOG.error(msg, e);        throw new DecryptionFailureException(msg, e);    }}
e9713832c4e7ae9c32cba8c6a9065ef70641b05aed6b1ba2be5c6bc9b7c80eeb
getCipher
private static Cipher getCipher(Key key, int mode, byte[] parameters)
{    try {        Cipher cipher = Cipher.getInstance(TYPE);        cipher.init(mode, key, new IvParameterSpec(parameters));        return cipher;    } catch (Exception e) {        String msg = "Unable to load key using transformation: " + TYPE;        if (e instanceof InvalidKeyException) {            try {                int maxAllowedLen = Cipher.getMaxAllowedKeyLength(TYPE);                if (maxAllowedLen < 256) {                    msg += "; Warning: Maximum allowed key length = " + maxAllowedLen + " with the available JCE security policy files. Have you" + " installed the JCE unlimited strength jurisdiction policy" + " files?";                }            } catch (NoSuchAlgorithmException ex) {                msg += "; Unable to find specified algorithm?";            }        }        LOG.error(msg, e);        throw Throwables.propagate(e);    }}
7513b576a46a5b70e3f731eaf9e19e052d9989292ad2ce56974351c2de1ed3ce
setKey
public Builder<T> setKey(Key key)
{    this.key = Preconditions.checkNotNull(key, "key cannot be null");    return this;}
7513b576a46a5b70e3f731eaf9e19e052d9989292ad2ce56974351c2de1ed3ce
setKey
public Builder<T> setKey(Key key)
{    this.key = Preconditions.checkNotNull(key, "key cannot be null");    return this;}
6739a3e5cda9dcc76963ef55a78b875516801b30a23c56f1182866d15770ceeb
setParameters
public Builder<T> setParameters(byte[] parameters)
{    this.parameters = parameters;    return this;}
ca2b02a7caa6be919f5d33b01354212f2a5549960dbae740a4a2949257c719a6
getEncrypter
public static CipherProvider.Encryptor getEncrypter(String cipherProviderType, Key key)
{    if (cipherProviderType == null) {        return null;    }    CipherProvider provider = getProvider(cipherProviderType);    return provider.newEncryptorBuilder().setKey(key).build();}
169c1fe347d2acb03a20ab7fc4bd75acc6b7ca79810edd4f106acddc4e67dfe2
getDecrypter
public static CipherProvider.Decryptor getDecrypter(String cipherProviderType, Key key, byte[] parameters)
{    if (cipherProviderType == null) {        return null;    }    CipherProvider provider = getProvider(cipherProviderType);    return provider.newDecryptorBuilder().setKey(key).setParameters(parameters).build();}
bc4fe9f26e3a051e0c6bae18c12fe380a3fcfb403f16cd3aeab649f1627dcdc8
getProvider
private static CipherProvider getProvider(String cipherProviderType)
{    Preconditions.checkNotNull(cipherProviderType, "cipher provider type must not be null");        CipherProviderType type;    try {        type = CipherProviderType.valueOf(cipherProviderType.toUpperCase(Locale.ENGLISH));    } catch (IllegalArgumentException e) {        logger.debug("Not in enum, loading provider class: {}", cipherProviderType);        type = CipherProviderType.OTHER;    }    Class<? extends CipherProvider> providerClass = type.getProviderClass();        if (providerClass == null) {        try {            Class c = Class.forName(cipherProviderType);            if (c != null && CipherProvider.class.isAssignableFrom(c)) {                providerClass = (Class<? extends CipherProvider>) c;            } else {                String errMessage = "Unable to instantiate provider from " + cipherProviderType;                logger.error(errMessage);                throw new FlumeException(errMessage);            }        } catch (ClassNotFoundException ex) {            logger.error("Class not found: " + cipherProviderType, ex);            throw new FlumeException(ex);        }    }    try {        return providerClass.newInstance();    } catch (Exception ex) {        String errMessage = "Cannot instantiate provider: " + cipherProviderType;        logger.error(errMessage, ex);        throw new FlumeException(errMessage, ex);    }}
4ea3eaaa6f9276033feb46677459314b8bb4305ed44df4d1883380a4a2c4253d
getProviderClass
public Class<? extends CipherProvider> getProviderClass()
{    return providerClass;}
1f95922d6671065e53da9defefcbe47ca11822fd889b79f429a5bd4d017ebd1d
getKey
public Key getKey(String alias)
{    String passwordFile = keyStorePasswordFile.getAbsolutePath();    try {        char[] keyPassword = keyStorePassword;        if (aliasPasswordFileMap.containsKey(alias)) {            File keyPasswordFile = aliasPasswordFileMap.get(alias);            keyPassword = Files.toString(keyPasswordFile, Charsets.UTF_8).trim().toCharArray();            passwordFile = keyPasswordFile.getAbsolutePath();        }        Key key = ks.getKey(alias, keyPassword);        if (key == null) {            throw new IllegalStateException("KeyStore returned null for " + alias);        }        return key;    } catch (Exception e) {        String msg = e.getClass().getName() + ": " + e.getMessage() + ". " + "Key = " + alias + ", passwordFile = " + passwordFile;        throw new RuntimeException(msg, e);    }}
0508193530fbe14acf6142f491f292423b4f20cf3cb7cef1736c3b1712d495bb
build
public KeyProvider build(Context context)
{    String keyStoreFileName = context.getString(EncryptionConfiguration.JCE_FILE_KEY_STORE_FILE);    String keyStorePasswordFileName = context.getString(EncryptionConfiguration.JCE_FILE_KEY_STORE_PASSWORD_FILE);    Preconditions.checkState(!Strings.isNullOrEmpty(keyStoreFileName), "KeyStore file not specified");    Preconditions.checkState(!Strings.isNullOrEmpty(keyStorePasswordFileName), "KeyStore password  file not specified");    Map<String, File> aliasPasswordFileMap = Maps.newHashMap();    String passwordProtectedKeys = context.getString(EncryptionConfiguration.JCE_FILE_KEYS);    Preconditions.checkState(!Strings.isNullOrEmpty(passwordProtectedKeys), "Keys available to KeyStore was not specified or empty");    for (String passwordName : passwordProtectedKeys.trim().split("\\s+")) {        String propertyName = Joiner.on(".").join(EncryptionConfiguration.JCE_FILE_KEYS, passwordName, EncryptionConfiguration.JCE_FILE_KEY_PASSWORD_FILE);        String passwordFileName = context.getString(propertyName, keyStorePasswordFileName);        File passwordFile = new File(passwordFileName.trim());        if (passwordFile.isFile()) {            aliasPasswordFileMap.put(passwordName, passwordFile);        } else {            logger.warn("Password file for alias " + passwordName + " does not exist");        }    }    File keyStoreFile = new File(keyStoreFileName.trim());    File keyStorePasswordFile = new File(keyStorePasswordFileName.trim());    return new JCEFileKeyProvider(keyStoreFile, keyStorePasswordFile, aliasPasswordFileMap);}
fda03cc7fc1b1dc4f6adaf01d8bb0411f0ac819bab3f505f86800df91393fd4d
getInstance
public static KeyProvider getInstance(String keyProviderType, Context context)
{    Preconditions.checkNotNull(keyProviderType, "key provider type must not be null");        KeyProviderType type;    try {        type = KeyProviderType.valueOf(keyProviderType.toUpperCase(Locale.ENGLISH));    } catch (IllegalArgumentException e) {        logger.debug("Not in enum, loading provider class: {}", keyProviderType);        type = KeyProviderType.OTHER;    }    Class<? extends KeyProvider.Builder> providerClass = type.getBuilderClass();        if (providerClass == null) {        try {            Class c = Class.forName(keyProviderType);            if (c != null && KeyProvider.Builder.class.isAssignableFrom(c)) {                providerClass = (Class<? extends KeyProvider.Builder>) c;            } else {                String errMessage = "Unable to instantiate Builder from " + keyProviderType;                logger.error(errMessage);                throw new FlumeException(errMessage);            }        } catch (ClassNotFoundException ex) {            logger.error("Class not found: " + keyProviderType, ex);            throw new FlumeException(ex);        }    }        KeyProvider.Builder provider;    try {        provider = providerClass.newInstance();    } catch (InstantiationException ex) {        String errMessage = "Cannot instantiate builder: " + keyProviderType;        logger.error(errMessage, ex);        throw new FlumeException(errMessage, ex);    } catch (IllegalAccessException ex) {        String errMessage = "Cannot instantiate builder: " + keyProviderType;        logger.error(errMessage, ex);        throw new FlumeException(errMessage, ex);    }    return provider.build(context);}
7ffab58de462c9ac1e5bc3672820e199e38a3f9968ad712086a66b1b7801d1e1
getBuilderClass
public Class<? extends KeyProvider.Builder> getBuilderClass()
{    return keyProviderClass;}
4a537c59d3ef4a55534dfb6f3ad02d519da4084f1286cca0722e0d8fba8839d1
getSize
 int getSize()
{    return queueSize;}
8e9a7ef55da51482ff27d7797040c1afaac2e6df975506603e3cd59c6768ffc2
setSize
 void setSize(int size)
{    queueSize = size;}
ac155ed646f488ac7cc0fa7d1b1acecd43ae6cb13670949da15b555c735312d9
getHead
 int getHead()
{    return queueHead;}
39aad0d24a8eb8c8cb7e98cda7d734593723986d4c57c5b8b0c2a12ea8f72941
setHead
 void setHead(int head)
{    queueHead = head;}
cd9b1419c96ec0bef311045782c3584a80c38b33e188891e1255d00a6c0de344
getCapacity
 int getCapacity()
{    return capacity;}
0c786cac7bb579622c9ab7c4d2d58ca1e63a59687a9e7538f6ae86092d8891ec
getName
 String getName()
{    return name;}
c999d5d21162c97fdf3d52b81d405388d52f7237dc41a5916600206494a9e26c
setLogWriteOrderID
protected void setLogWriteOrderID(long logWriteOrderID)
{    this.logWriteOrderID = logWriteOrderID;}
6f899e2330de3aa68f5a005ba9aabc09d680e404a4d3d21223717d239ab0ee4d
getLogWriteOrderID
 long getLogWriteOrderID()
{    return logWriteOrderID;}
bec86fa88d00f4695ab39bef2ea7b829e419e36673a2c8eaeac75b3a8724fbc3
get
 static EventQueueBackingStore get(File checkpointFile, int capacity, String name, FileChannelCounter counter) throws Exception
{    return get(checkpointFile, capacity, name, counter, true);}
720f5782ba39a108eb7c0aade6439888678d441584d22a307aa9dfc517646798
get
 static EventQueueBackingStore get(File checkpointFile, int capacity, String name, FileChannelCounter counter, boolean upgrade) throws Exception
{    return get(checkpointFile, null, capacity, name, counter, upgrade, false, false);}
5f15315f9abac889392a79d16e52ac82c4bdd9a634523c0259303d68fb4f7efe
get
 static EventQueueBackingStore get(File checkpointFile, File backupCheckpointDir, int capacity, String name, FileChannelCounter counter, boolean upgrade, boolean shouldBackup, boolean compressBackup) throws Exception
{    File metaDataFile = Serialization.getMetaDataFile(checkpointFile);    RandomAccessFile checkpointFileHandle = null;    try {        boolean checkpointExists = checkpointFile.exists();        boolean metaDataExists = metaDataFile.exists();        if (metaDataExists) {                        if (!checkpointExists || checkpointFile.length() == 0) {                LOG.warn("MetaData file for checkpoint " + " exists but checkpoint does not. Checkpoint = " + checkpointFile + ", metaDataFile = " + metaDataFile);                throw new BadCheckpointException("The last checkpoint was not completed correctly, " + "since Checkpoint file does not exist while metadata " + "file does.");            }        }                if (!checkpointExists) {            if (!checkpointFile.createNewFile()) {                throw new IOException("Cannot create " + checkpointFile);            }            return new EventQueueBackingStoreFileV3(checkpointFile, capacity, name, counter, backupCheckpointDir, shouldBackup, compressBackup);        }                if (metaDataExists) {            return new EventQueueBackingStoreFileV3(checkpointFile, capacity, name, counter, backupCheckpointDir, shouldBackup, compressBackup);        }        checkpointFileHandle = new RandomAccessFile(checkpointFile, "r");        int version = (int) checkpointFileHandle.readLong();        if (Serialization.VERSION_2 == version) {            if (upgrade) {                return upgrade(checkpointFile, capacity, name, backupCheckpointDir, shouldBackup, compressBackup, counter);            }            return new EventQueueBackingStoreFileV2(checkpointFile, capacity, name, counter);        }        LOG.error("Found version " + Integer.toHexString(version) + " in " + checkpointFile);        throw new BadCheckpointException("Checkpoint file exists with " + Serialization.VERSION_3 + " but no metadata file found.");    } finally {        if (checkpointFileHandle != null) {            try {                checkpointFileHandle.close();            } catch (IOException e) {                LOG.warn("Unable to close " + checkpointFile, e);            }        }    }}
253e8eed5b775fc78556902ebf954d28f7ff571fa3bfeff43ef2198d1780fdbb
upgrade
private static EventQueueBackingStore upgrade(File checkpointFile, int capacity, String name, File backupCheckpointDir, boolean shouldBackup, boolean compressBackup, FileChannelCounter counter) throws Exception
{    LOG.info("Attempting upgrade of " + checkpointFile + " for " + name);    EventQueueBackingStoreFileV2 backingStoreV2 = new EventQueueBackingStoreFileV2(checkpointFile, capacity, name, counter);    String backupName = checkpointFile.getName() + "-backup-" + System.currentTimeMillis();    Files.copy(checkpointFile, new File(checkpointFile.getParentFile(), backupName));    File metaDataFile = Serialization.getMetaDataFile(checkpointFile);    EventQueueBackingStoreFileV3.upgrade(backingStoreV2, checkpointFile, metaDataFile);    return new EventQueueBackingStoreFileV3(checkpointFile, capacity, name, counter, backupCheckpointDir, shouldBackup, compressBackup);}
aa666756ef2d1b335bd9b87dad171ee10a77adc53a45d57ac4644a071590b37b
getCheckpointLogWriteOrderID
protected long getCheckpointLogWriteOrderID()
{    return elementsBuffer.get(INDEX_WRITE_ORDER_ID);}
909e4fb2c8f0a1641e3b54871ec6c2714fd1c7b77c89b7578b2a0061103776ee
backupCheckpoint
protected void backupCheckpoint(File backupDirectory) throws IOException
{    int availablePermits = backupCompletedSema.drainPermits();    Preconditions.checkState(availablePermits == 0, "Expected no permits to be available in the backup semaphore, " + "but " + availablePermits + " permits were available.");    if (slowdownBackup) {        try {            TimeUnit.SECONDS.sleep(10);        } catch (Exception ex) {            Throwables.propagate(ex);        }    }    File backupFile = new File(backupDirectory, BACKUP_COMPLETE_FILENAME);    if (backupExists(backupDirectory)) {        if (!backupFile.delete()) {            throw new IOException("Error while doing backup of checkpoint. Could " + "not remove" + backupFile.toString() + ".");        }    }    Serialization.deleteAllFiles(backupDirectory, Log.EXCLUDES);    File checkpointDir = checkpointFile.getParentFile();    File[] checkpointFiles = checkpointDir.listFiles();    Preconditions.checkNotNull(checkpointFiles, "Could not retrieve files " + "from the checkpoint directory. Cannot complete backup of the " + "checkpoint.");    for (File origFile : checkpointFiles) {        if (Log.EXCLUDES.contains(origFile.getName())) {            continue;        }        if (compressBackup && origFile.equals(checkpointFile)) {            Serialization.compressFile(origFile, new File(backupDirectory, origFile.getName() + COMPRESSED_FILE_EXTENSION));        } else {            Serialization.copyFile(origFile, new File(backupDirectory, origFile.getName()));        }    }    Preconditions.checkState(!backupFile.exists(), "The backup file exists " + "while it is not supposed to. Are multiple channels configured to use " + "this directory: " + backupDirectory.toString() + " as backup?");    if (!backupFile.createNewFile()) {        LOG.error("Could not create backup file. Backup of checkpoint will " + "not be used during replay even if checkpoint is bad.");    }}
afe217256719d49b96450f63d125f81df25f83f16a441935aeebb3ecc99a75a6
restoreBackup
public static boolean restoreBackup(File checkpointDir, File backupDir) throws IOException
{    if (!backupExists(backupDir)) {        return false;    }    Serialization.deleteAllFiles(checkpointDir, Log.EXCLUDES);    File[] backupFiles = backupDir.listFiles();    if (backupFiles == null) {        return false;    } else {        for (File backupFile : backupFiles) {            String fileName = backupFile.getName();            if (!fileName.equals(BACKUP_COMPLETE_FILENAME) && !fileName.equals(Log.FILE_LOCK)) {                if (fileName.endsWith(COMPRESSED_FILE_EXTENSION)) {                    Serialization.decompressFile(backupFile, new File(checkpointDir, fileName.substring(0, fileName.lastIndexOf("."))));                } else {                    Serialization.copyFile(backupFile, new File(checkpointDir, fileName));                }            }        }        return true;    }}
1ba115c54c7da1dd4f7c5f1e7f387df624cdaf1c8b9a2637018cb371a8d9eab4
beginCheckpoint
 void beginCheckpoint() throws IOException
{    LOG.info("Start checkpoint for " + checkpointFile + ", elements to sync = " + overwriteMap.size());    if (shouldBackup) {        int permits = backupCompletedSema.drainPermits();        Preconditions.checkState(permits <= 1, "Expected only one or less " + "permits to checkpoint, but got " + String.valueOf(permits) + " permits");        if (permits < 1) {                        throw new IOException("Previous backup of checkpoint files is still " + "in progress. Will attempt to checkpoint only at the end of the " + "next checkpoint interval. Try increasing the checkpoint interval " + "if this error happens often.");        }    }        elementsBuffer.put(INDEX_CHECKPOINT_MARKER, CHECKPOINT_INCOMPLETE);    mappedBuffer.force();}
70c99b144173cb55c0d774049ad16dc4918f99d3c287b34c3cb740bad73a92bf
checkpoint
 void checkpoint() throws IOException
{    setLogWriteOrderID(WriteOrderOracle.next());    LOG.info("Updating checkpoint metadata: logWriteOrderID: " + getLogWriteOrderID() + ", queueSize: " + getSize() + ", queueHead: " + getHead());    elementsBuffer.put(INDEX_WRITE_ORDER_ID, getLogWriteOrderID());    try {        writeCheckpointMetaData();    } catch (IOException e) {        throw new IOException("Error writing metadata", e);    }    Iterator<Integer> it = overwriteMap.keySet().iterator();    while (it.hasNext()) {        int index = it.next();        long value = overwriteMap.get(index);        elementsBuffer.put(index, value);        it.remove();    }    Preconditions.checkState(overwriteMap.isEmpty(), "concurrent update detected ");        elementsBuffer.put(INDEX_CHECKPOINT_MARKER, CHECKPOINT_COMPLETE);    mappedBuffer.force();    if (shouldBackup) {        startBackupThread();    }}
3063c590f072d8fabb6ef552010516f7429f11f8392eb5a081dddb372afc2688
startBackupThread
private void startBackupThread()
{    Preconditions.checkNotNull(checkpointBackUpExecutor, "Expected the checkpoint backup exector to be non-null, " + "but it is null. Checkpoint will not be backed up.");    LOG.info("Attempting to back up checkpoint.");    checkpointBackUpExecutor.submit(new Runnable() {        @Override        public void run() {            boolean error = false;            try {                backupCheckpoint(backupDir);            } catch (Throwable throwable) {                fileChannelCounter.incrementCheckpointBackupWriteErrorCount();                error = true;                LOG.error("Backing up of checkpoint directory failed.", throwable);            } finally {                backupCompletedSema.release();            }            if (!error) {                LOG.info("Checkpoint backup completed.");            }        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    boolean error = false;    try {        backupCheckpoint(backupDir);    } catch (Throwable throwable) {        fileChannelCounter.incrementCheckpointBackupWriteErrorCount();        error = true;        LOG.error("Backing up of checkpoint directory failed.", throwable);    } finally {        backupCompletedSema.release();    }    if (!error) {        LOG.info("Checkpoint backup completed.");    }}
c2864e5a4894768906844a2ddb5f229fc8d93aa73ebb06368e7b1ddbe43efd96
close
 void close()
{    mappedBuffer.force();    try {        checkpointFileHandle.close();    } catch (IOException e) {        LOG.info("Error closing " + checkpointFile, e);    }    if (checkpointBackUpExecutor != null && !checkpointBackUpExecutor.isShutdown()) {        checkpointBackUpExecutor.shutdown();        try {                        while (!checkpointBackUpExecutor.awaitTermination(1, TimeUnit.SECONDS)) {            }        } catch (InterruptedException ex) {            LOG.warn("Interrupted while waiting for checkpoint backup to " + "complete");        }    }}
294f8825d663d062512b7f7144b3d64b1099038ba0d799c2c60ce4b66db393e6
get
 long get(int index)
{    int realIndex = getPhysicalIndex(index);    long result = EMPTY;    if (overwriteMap.containsKey(realIndex)) {        result = overwriteMap.get(realIndex);    } else {        result = elementsBuffer.get(realIndex);    }    return result;}
8d0e2bbb5cdad4e227a7b212ac55b1a0429f3d4170dd492c0d2e75ccee5c6a32
getReferenceCounts
 ImmutableSortedSet<Integer> getReferenceCounts()
{    return ImmutableSortedSet.copyOf(logFileIDReferenceCounts.keySet());}
57bdad7d941a0e79a917ea6b6e47a3561b25e0135088d9d65e37d7a8af0113fb
put
 void put(int index, long value)
{    int realIndex = getPhysicalIndex(index);    overwriteMap.put(realIndex, value);}
8e46faee47498bb4016d37896c8ef5d75327ef814cc99f9d99f32004f999eab4
syncRequired
 boolean syncRequired()
{    return overwriteMap.size() > 0;}
e42d277be3654cc982e72c307736792c2056af67faca415b9c18ac3bea398f0d
incrementFileID
protected void incrementFileID(int fileID)
{    AtomicInteger counter = logFileIDReferenceCounts.get(fileID);    if (counter == null) {        counter = new AtomicInteger(0);        logFileIDReferenceCounts.put(fileID, counter);    }    counter.incrementAndGet();}
8d64de82161a59a670505594c8438c389d22162ed378a90e1430627e03cc9057
decrementFileID
protected void decrementFileID(int fileID)
{    AtomicInteger counter = logFileIDReferenceCounts.get(fileID);    Preconditions.checkState(counter != null, "null counter ");    int count = counter.decrementAndGet();    if (count == 0) {        logFileIDReferenceCounts.remove(fileID);    }}
f8f895740fe7b3f1e0365df7b8b3f6f5717a79dd66aede279130ed3367460d95
getPhysicalIndex
protected int getPhysicalIndex(int index)
{    return HEADER_SIZE + (getHead() + index) % getCapacity();}
b37f7ce319dd1baba7cc8cee5b09a6790bbbb74d1ee7397113a647197c69d5ee
allocate
protected static void allocate(File file, long totalBytes) throws IOException
{    RandomAccessFile checkpointFile = new RandomAccessFile(file, "rw");    boolean success = false;    try {        if (totalBytes <= MAX_ALLOC_BUFFER_SIZE) {            /*         * totalBytes <= MAX_ALLOC_BUFFER_SIZE, so this can be cast to int         * without a problem.         */            checkpointFile.write(new byte[(int) totalBytes]);        } else {            byte[] initBuffer = new byte[MAX_ALLOC_BUFFER_SIZE];            long remainingBytes = totalBytes;            while (remainingBytes >= MAX_ALLOC_BUFFER_SIZE) {                checkpointFile.write(initBuffer);                remainingBytes -= MAX_ALLOC_BUFFER_SIZE;            }            /*         * At this point, remainingBytes is < MAX_ALLOC_BUFFER_SIZE,         * so casting to int is fine.         */            if (remainingBytes > 0) {                checkpointFile.write(initBuffer, 0, (int) remainingBytes);            }        }        success = true;    } finally {        try {            checkpointFile.close();        } catch (IOException e) {            if (success) {                throw e;            }        }    }}
afc42eb1369137a792a1aa2f157b35f4ae52533efe81274540b77b0ad01151f6
backupExists
public static boolean backupExists(File backupDir)
{    return new File(backupDir, BACKUP_COMPLETE_FILENAME).exists();}
b6047c2d62e0dd012f9e8fbf9c3b04878ae171af7f5ab52171412c0b606ca520
main
public static void main(String[] args) throws Exception
{    File file = new File(args[0]);    File inflightTakesFile = new File(args[1]);    File inflightPutsFile = new File(args[2]);    File queueSetDir = new File(args[3]);    if (!file.exists()) {        throw new IOException("File " + file + " does not exist");    }    if (file.length() == 0) {        throw new IOException("File " + file + " is empty");    }    int capacity = (int) ((file.length() - (HEADER_SIZE * 8L)) / 8L);    EventQueueBackingStoreFile backingStore = (EventQueueBackingStoreFile) EventQueueBackingStoreFactory.get(file, capacity, "debug", new FileChannelCounter("Main"), false);    System.out.println("File Reference Counts" + backingStore.logFileIDReferenceCounts);    System.out.println("Queue Capacity " + backingStore.getCapacity());    System.out.println("Queue Size " + backingStore.getSize());    System.out.println("Queue Head " + backingStore.getHead());    for (int index = 0; index < backingStore.getCapacity(); index++) {        long value = backingStore.get(backingStore.getPhysicalIndex(index));        int fileID = (int) (value >>> 32);        int offset = (int) value;        System.out.println(index + ":" + Long.toHexString(value) + " fileID = " + fileID + ", offset = " + offset);    }    FlumeEventQueue queue = new FlumeEventQueue(backingStore, inflightTakesFile, inflightPutsFile, queueSetDir);    SetMultimap<Long, Long> putMap = queue.deserializeInflightPuts();    System.out.println("Inflight Puts:");    for (Long txnID : putMap.keySet()) {        Set<Long> puts = putMap.get(txnID);        System.out.println("Transaction ID: " + String.valueOf(txnID));        for (long value : puts) {            int fileID = (int) (value >>> 32);            int offset = (int) value;            System.out.println(Long.toHexString(value) + " fileID = " + fileID + ", offset = " + offset);        }    }    SetMultimap<Long, Long> takeMap = queue.deserializeInflightTakes();    System.out.println("Inflight takes:");    for (Long txnID : takeMap.keySet()) {        Set<Long> takes = takeMap.get(txnID);        System.out.println("Transaction ID: " + String.valueOf(txnID));        for (long value : takes) {            int fileID = (int) (value >>> 32);            int offset = (int) value;            System.out.println(Long.toHexString(value) + " fileID = " + fileID + ", offset = " + offset);        }    }}
9f67712f3b9f214ca7b392af6e5db3a77d403ecd0385e507664bc69c71708934
getVersion
protected int getVersion()
{    return Serialization.VERSION_2;}
e42d277be3654cc982e72c307736792c2056af67faca415b9c18ac3bea398f0d
incrementFileID
protected void incrementFileID(int fileID)
{    super.incrementFileID(fileID);    Preconditions.checkState(logFileIDReferenceCounts.size() < MAX_ACTIVE_LOGS, "Too many active logs ");}
1a6835c40977b00c9293c3652aaa6121640dd89b316041887a198545c6382c1b
deocodeActiveLogCounter
private Pair<Integer, Integer> deocodeActiveLogCounter(long value)
{    int fileId = (int) (value >>> 32);    int count = (int) value;    return Pair.of(fileId, count);}
55c7f649dc15456bb8c7bd6d8b06d40ca30bc87f6be2b8a126de37f97f04405d
encodeActiveLogCounter
private long encodeActiveLogCounter(int fileId, int count)
{    long result = fileId;    result = (long) fileId << 32;    result += (long) count;    return result;}
38b7e240f0e202cc8d31f265b80d345600afce673c3757e9060479bb0b9b523e
writeCheckpointMetaData
protected void writeCheckpointMetaData()
{    elementsBuffer.put(INDEX_SIZE, getSize());    elementsBuffer.put(INDEX_HEAD, getHead());    List<Long> fileIdAndCountEncoded = new ArrayList<Long>();    for (Integer fileId : logFileIDReferenceCounts.keySet()) {        Integer count = logFileIDReferenceCounts.get(fileId).get();        long value = encodeActiveLogCounter(fileId, count);        fileIdAndCountEncoded.add(value);    }    int emptySlots = MAX_ACTIVE_LOGS - fileIdAndCountEncoded.size();    for (int i = 0; i < emptySlots; i++) {        fileIdAndCountEncoded.add(0L);    }    for (int i = 0; i < MAX_ACTIVE_LOGS; i++) {        elementsBuffer.put(i + INDEX_ACTIVE_LOG, fileIdAndCountEncoded.get(i));    }}
47b04517931403b67671a2e224c56859ece21b4601d810653298ab754abca857
getMetaDataFile
 File getMetaDataFile()
{    return metaDataFile;}
9f67712f3b9f214ca7b392af6e5db3a77d403ecd0385e507664bc69c71708934
getVersion
protected int getVersion()
{    return Serialization.VERSION_3;}
89c976ea8bc2281bfa963187129987ac4aec002114a35a6e59c90867ca379c0a
writeCheckpointMetaData
protected void writeCheckpointMetaData() throws IOException
{    ProtosFactory.Checkpoint.Builder checkpointBuilder = ProtosFactory.Checkpoint.newBuilder();    checkpointBuilder.setVersion(getVersion());    checkpointBuilder.setQueueHead(getHead());    checkpointBuilder.setQueueSize(getSize());    checkpointBuilder.setWriteOrderID(getLogWriteOrderID());    for (Integer logFileID : logFileIDReferenceCounts.keySet()) {        int count = logFileIDReferenceCounts.get(logFileID).get();        if (count != 0) {            ProtosFactory.ActiveLog.Builder activeLogBuilder = ProtosFactory.ActiveLog.newBuilder();            activeLogBuilder.setLogFileID(logFileID);            activeLogBuilder.setCount(count);            checkpointBuilder.addActiveLogs(activeLogBuilder.build());        }    }    FileOutputStream outputStream = new FileOutputStream(metaDataFile);    try {        checkpointBuilder.build().writeDelimitedTo(outputStream);        outputStream.getChannel().force(true);    } finally {        try {            outputStream.close();        } catch (IOException e) {            LOG.warn("Unable to close " + metaDataFile, e);        }    }}
c7959d5c82ecfcca2e78a2829686a0daf9646993e80150cc3c2e367e8b212e6e
upgrade
 static void upgrade(EventQueueBackingStoreFileV2 backingStoreV2, File checkpointFile, File metaDataFile) throws IOException
{    int head = backingStoreV2.getHead();    int size = backingStoreV2.getSize();    long writeOrderID = backingStoreV2.getLogWriteOrderID();    Map<Integer, AtomicInteger> referenceCounts = backingStoreV2.logFileIDReferenceCounts;    ProtosFactory.Checkpoint.Builder checkpointBuilder = ProtosFactory.Checkpoint.newBuilder();    checkpointBuilder.setVersion(Serialization.VERSION_3);    checkpointBuilder.setQueueHead(head);    checkpointBuilder.setQueueSize(size);    checkpointBuilder.setWriteOrderID(writeOrderID);    for (Integer logFileID : referenceCounts.keySet()) {        int count = referenceCounts.get(logFileID).get();        if (count > 0) {            ProtosFactory.ActiveLog.Builder activeLogBuilder = ProtosFactory.ActiveLog.newBuilder();            activeLogBuilder.setLogFileID(logFileID);            activeLogBuilder.setCount(count);            checkpointBuilder.addActiveLogs(activeLogBuilder.build());        }    }    FileOutputStream outputStream = new FileOutputStream(metaDataFile);    try {        checkpointBuilder.build().writeDelimitedTo(outputStream);        outputStream.getChannel().force(true);    } finally {        try {            outputStream.close();        } catch (IOException e) {            LOG.warn("Unable to close " + metaDataFile, e);        }    }    RandomAccessFile checkpointFileHandle = new RandomAccessFile(checkpointFile, "rw");    try {        checkpointFileHandle.seek(INDEX_VERSION * Serialization.SIZE_OF_LONG);        checkpointFileHandle.writeLong(Serialization.VERSION_3);        checkpointFileHandle.getChannel().force(true);    } finally {        try {            checkpointFileHandle.close();        } catch (IOException e) {            LOG.warn("Unable to close " + checkpointFile, e);        }    }}
732fc6b12e55ca9242ae79a21cff96fdf0dba340ebb5ed8aff101503a624fdd6
getEventFromTransactionEvent
public static Event getEventFromTransactionEvent(TransactionEventRecord transactionEventRecord)
{    if (transactionEventRecord instanceof Put) {        return ((Put) transactionEventRecord).getEvent();    }    return null;}
831a1aefa333c15f969e26873201d65e004e9eae64fe390a121d56ac6619f888
setName
public synchronized void setName(String name)
{    channelNameDescriptor = "[channel=" + name + "]";    super.setName(name);}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    useDualCheckpoints = context.getBoolean(FileChannelConfiguration.USE_DUAL_CHECKPOINTS, FileChannelConfiguration.DEFAULT_USE_DUAL_CHECKPOINTS);    compressBackupCheckpoint = context.getBoolean(FileChannelConfiguration.COMPRESS_BACKUP_CHECKPOINT, FileChannelConfiguration.DEFAULT_COMPRESS_BACKUP_CHECKPOINT);    String homePath = System.getProperty("user.home").replace('\\', '/');    String strCheckpointDir = context.getString(FileChannelConfiguration.CHECKPOINT_DIR, homePath + "/.flume/file-channel/checkpoint").trim();    String strBackupCheckpointDir = context.getString(FileChannelConfiguration.BACKUP_CHECKPOINT_DIR, "").trim();    String[] strDataDirs = Iterables.toArray(Splitter.on(",").trimResults().omitEmptyStrings().split(context.getString(FileChannelConfiguration.DATA_DIRS, homePath + "/.flume/file-channel/data")), String.class);    checkpointDir = new File(strCheckpointDir);    if (useDualCheckpoints) {        Preconditions.checkState(!strBackupCheckpointDir.isEmpty(), "Dual checkpointing is enabled, but the backup directory is not set. " + "Please set " + FileChannelConfiguration.BACKUP_CHECKPOINT_DIR + " " + "to enable dual checkpointing");        backupCheckpointDir = new File(strBackupCheckpointDir);        /*       * If the backup directory is the same as the checkpoint directory,       * then throw an exception and force the config system to ignore this       * channel.       */        Preconditions.checkState(!backupCheckpointDir.equals(checkpointDir), "Could not configure " + getName() + ". The checkpoint backup " + "directory and the checkpoint directory are " + "configured to be the same.");    }    dataDirs = new File[strDataDirs.length];    for (int i = 0; i < strDataDirs.length; i++) {        dataDirs[i] = new File(strDataDirs[i]);    }    capacity = context.getInteger(FileChannelConfiguration.CAPACITY, FileChannelConfiguration.DEFAULT_CAPACITY);    if (capacity <= 0) {        capacity = FileChannelConfiguration.DEFAULT_CAPACITY;        LOG.warn("Invalid capacity specified, initializing channel to " + "default capacity of {}", capacity);    }    keepAlive = context.getInteger(FileChannelConfiguration.KEEP_ALIVE, FileChannelConfiguration.DEFAULT_KEEP_ALIVE);    transactionCapacity = context.getInteger(FileChannelConfiguration.TRANSACTION_CAPACITY, FileChannelConfiguration.DEFAULT_TRANSACTION_CAPACITY);    if (transactionCapacity <= 0) {        transactionCapacity = FileChannelConfiguration.DEFAULT_TRANSACTION_CAPACITY;        LOG.warn("Invalid transaction capacity specified, " + "initializing channel to default " + "capacity of {}", transactionCapacity);    }    Preconditions.checkState(transactionCapacity <= capacity, "File Channel transaction capacity cannot be greater than the " + "capacity of the channel.");    checkpointInterval = context.getLong(FileChannelConfiguration.CHECKPOINT_INTERVAL, FileChannelConfiguration.DEFAULT_CHECKPOINT_INTERVAL);    if (checkpointInterval <= 0) {        LOG.warn("Checkpoint interval is invalid: " + checkpointInterval + ", using default: " + FileChannelConfiguration.DEFAULT_CHECKPOINT_INTERVAL);        checkpointInterval = FileChannelConfiguration.DEFAULT_CHECKPOINT_INTERVAL;    }        maxFileSize = Math.min(context.getLong(FileChannelConfiguration.MAX_FILE_SIZE, FileChannelConfiguration.DEFAULT_MAX_FILE_SIZE), FileChannelConfiguration.DEFAULT_MAX_FILE_SIZE);    minimumRequiredSpace = Math.max(context.getLong(FileChannelConfiguration.MINIMUM_REQUIRED_SPACE, FileChannelConfiguration.DEFAULT_MINIMUM_REQUIRED_SPACE), FileChannelConfiguration.FLOOR_MINIMUM_REQUIRED_SPACE);    useLogReplayV1 = context.getBoolean(FileChannelConfiguration.USE_LOG_REPLAY_V1, FileChannelConfiguration.DEFAULT_USE_LOG_REPLAY_V1);    useFastReplay = context.getBoolean(FileChannelConfiguration.USE_FAST_REPLAY, FileChannelConfiguration.DEFAULT_USE_FAST_REPLAY);    Context encryptionContext = new Context(context.getSubProperties(EncryptionConfiguration.ENCRYPTION_PREFIX + "."));    String encryptionKeyProviderName = encryptionContext.getString(EncryptionConfiguration.KEY_PROVIDER);    encryptionActiveKey = encryptionContext.getString(EncryptionConfiguration.ACTIVE_KEY);    encryptionCipherProvider = encryptionContext.getString(EncryptionConfiguration.CIPHER_PROVIDER);    if (encryptionKeyProviderName != null) {        Preconditions.checkState(!Strings.isNullOrEmpty(encryptionActiveKey), "Encryption configuration problem: " + EncryptionConfiguration.ACTIVE_KEY + " is missing");        Preconditions.checkState(!Strings.isNullOrEmpty(encryptionCipherProvider), "Encryption configuration problem: " + EncryptionConfiguration.CIPHER_PROVIDER + " is missing");        Context keyProviderContext = new Context(encryptionContext.getSubProperties(EncryptionConfiguration.KEY_PROVIDER + "."));        encryptionKeyProvider = KeyProviderFactory.getInstance(encryptionKeyProviderName, keyProviderContext);    } else {        Preconditions.checkState(encryptionActiveKey == null, "Encryption configuration problem: " + EncryptionConfiguration.ACTIVE_KEY + " is present while key " + "provider name is not.");        Preconditions.checkState(encryptionCipherProvider == null, "Encryption configuration problem: " + EncryptionConfiguration.CIPHER_PROVIDER + " is present while " + "key provider name is not.");    }    fsyncPerTransaction = context.getBoolean(FileChannelConfiguration.FSYNC_PER_TXN, FileChannelConfiguration.DEFAULT_FSYNC_PRE_TXN);    fsyncInterval = context.getInteger(FileChannelConfiguration.FSYNC_INTERVAL, FileChannelConfiguration.DEFAULT_FSYNC_INTERVAL);    checkpointOnClose = context.getBoolean(FileChannelConfiguration.CHKPT_ONCLOSE, FileChannelConfiguration.DEFAULT_CHKPT_ONCLOSE);    if (queueRemaining == null) {        queueRemaining = new Semaphore(capacity, true);    }    if (log != null) {        log.setCheckpointInterval(checkpointInterval);        log.setMaxFileSize(maxFileSize);    }    if (channelCounter == null) {        channelCounter = new FileChannelCounter(getName());    }    channelCounter.setUnhealthy(0);}
5b05914888e421f26bff6f39231facdd35759f746a9af780ebac2cf5b2c81932
start
public synchronized void start()
{    LOG.info("Starting {}...", this);    channelCounter.start();    try {        Builder builder = createLogBuilder();        log = builder.build();        log.replay();        setOpen(true);        int depth = getDepth();        Preconditions.checkState(queueRemaining.tryAcquire(depth), "Unable to acquire " + depth + " permits " + channelNameDescriptor);        LOG.info("Queue Size after replay: " + depth + " " + channelNameDescriptor);    } catch (Throwable t) {        setOpen(false);        channelCounter.setUnhealthy(1);        startupError = t;        LOG.error("Failed to start the file channel " + channelNameDescriptor, t);        if (t instanceof Error) {            throw (Error) t;        }    }    if (open) {        channelCounter.setChannelSize(getDepth());        channelCounter.setChannelCapacity(capacity);    }    super.start();}
d0a473e546766e75873ac3f8e0bfcf1c9d89707ec04560f2dc4fb48684f40ab0
createLogBuilder
 Builder createLogBuilder()
{    Builder builder = new Log.Builder();    builder.setCheckpointInterval(checkpointInterval);    builder.setMaxFileSize(maxFileSize);    builder.setMinimumRequiredSpace(minimumRequiredSpace);    builder.setQueueSize(capacity);    builder.setCheckpointDir(checkpointDir);    builder.setLogDirs(dataDirs);    builder.setChannelName(getName());    builder.setUseLogReplayV1(useLogReplayV1);    builder.setUseFastReplay(useFastReplay);    builder.setEncryptionKeyProvider(encryptionKeyProvider);    builder.setEncryptionKeyAlias(encryptionActiveKey);    builder.setEncryptionCipherProvider(encryptionCipherProvider);    builder.setUseDualCheckpoints(useDualCheckpoints);    builder.setCompressBackupCheckpoint(compressBackupCheckpoint);    builder.setBackupCheckpointDir(backupCheckpointDir);    builder.setFsyncPerTransaction(fsyncPerTransaction);    builder.setFsyncInterval(fsyncInterval);    builder.setCheckpointOnClose(checkpointOnClose);    builder.setChannelCounter(channelCounter);    return builder;}
06e1ddba8663c90da407ac517f29ed70555cfe57b0332c9a96e7c696e0255364
stop
public synchronized void stop()
{    LOG.info("Stopping {}...", this);    startupError = null;    int size = getDepth();    close();    if (!open) {        channelCounter.setChannelSize(size);        channelCounter.stop();    }    super.stop();}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return "FileChannel " + getName() + " { dataDirs: " + Arrays.toString(dataDirs) + " }";}
39f7d6d1213100383ba6ea7c79d8ed4ca1c7407a0f2469c0973c0709371a6cb9
createTransaction
protected BasicTransactionSemantics createTransaction()
{    if (!open) {        String msg = "Channel closed " + channelNameDescriptor;        if (startupError != null) {            msg += ". Due to " + startupError.getClass().getName() + ": " + startupError.getMessage();            throw new IllegalStateException(msg, startupError);        }        throw new IllegalStateException(msg);    }    FileBackedTransaction trans = transactions.get();    if (trans != null && !trans.isClosed()) {        Preconditions.checkState(false, "Thread has transaction which is still open: " + trans.getStateAsString() + channelNameDescriptor);    }    trans = new FileBackedTransaction(log, TransactionIDOracle.next(), transactionCapacity, keepAlive, queueRemaining, getName(), fsyncPerTransaction, channelCounter);    transactions.set(trans);    return trans;}
170ac0ba2743a5ae89070349fad30a25c0bad3a58d397ed2a912c5b4a07965a6
getDepth
protected int getDepth()
{    Preconditions.checkState(open, "Channel closed" + channelNameDescriptor);    Preconditions.checkNotNull(log, "log");    FlumeEventQueue queue = log.getFlumeEventQueue();    Preconditions.checkNotNull(queue, "queue");    return queue.getSize();}
c2864e5a4894768906844a2ddb5f229fc8d93aa73ebb06368e7b1ddbe43efd96
close
 void close()
{    if (open) {        setOpen(false);        try {            log.close();        } catch (Exception e) {            LOG.error("Error while trying to close the log.", e);            Throwables.propagate(e);        }        log = null;        queueRemaining = null;    }}
6a45395008c8d72ef8040e5dd292c1a749460e802d04a6311ece973e6dae9364
didFastReplay
 boolean didFastReplay()
{    return log.didFastReplay();}
c8ad46c6ecb9227e082e211665f36f819f8d94b4ad177f7c5017998d3eeb689d
didFullReplayDueToBadCheckpointException
 boolean didFullReplayDueToBadCheckpointException()
{    return log.didFullReplayDueToBadCheckpointException();}
19a24880b630c5416795a9247f56f3014ca8e567f85c7b8e4d6760590c45fccd
isOpen
public boolean isOpen()
{    return open;}
10ac6d406fed75342c67c0f104e8d16cf23f629b2ad6dd67427c95a8a544aa5c
setOpen
private void setOpen(boolean open)
{    this.open = open;    channelCounter.setOpen(this.open);}
dd4285d1d56658bae07f7f0b1d2bb1dabdbbe0aa9d28c3bb4f97d26d67980f5c
checkpointBackupRestored
 boolean checkpointBackupRestored()
{    if (log != null) {        return log.backupRestored();    }    return false;}
9fc87ff49e637f8381799ef5805303c7c85bbff6d0029f79a674469a67320595
getLog
 Log getLog()
{    return log;}
3f19f4af25ea94fcfd16e5ccbe95b711a9a40c24e3b78e951339e843b5258ac1
getChannelCounter
 FileChannelCounter getChannelCounter()
{    return channelCounter;}
c571ab4ff4ca7bf7123cf5ecd24cb716b666646f029f59e3775081551a025e6b
getTransactionCapacity
public long getTransactionCapacity()
{    return transactionCapacity;}
a02079f86eb5c334e2d9ecb1b8dfe4e8e3cef5fe42a93b938aa3404b730f74ce
isClosed
private boolean isClosed()
{    return State.CLOSED.equals(getState());}
cde4cf9a899f8263e54b94ac96353850b395b238208a5ff0f51d7f77c1d28958
getStateAsString
private String getStateAsString()
{    return String.valueOf(getState());}
12f20da1039baa55cd8cd24a8512df38790e6cb0af896f04ec9f5012ddf00b9a
doPut
protected void doPut(Event event) throws InterruptedException
{    channelCounter.incrementEventPutAttemptCount();    if (putList.remainingCapacity() == 0) {        throw new ChannelException("Put queue for FileBackedTransaction " + "of capacity " + putList.size() + " full, consider " + "committing more frequently, increasing capacity or " + "increasing thread count. " + channelNameDescriptor);    }        if (!queueRemaining.tryAcquire(keepAlive, TimeUnit.SECONDS)) {        throw new ChannelFullException("The channel has reached it's capacity. " + "This might be the result of a sink on the channel having too " + "low of batch size, a downstream system running slower than " + "normal, or that the channel capacity is just too low. " + channelNameDescriptor);    }    boolean success = false;    log.lockShared();    try {        FlumeEventPointer ptr = log.put(transactionID, event);        Preconditions.checkState(putList.offer(ptr), "putList offer failed " + channelNameDescriptor);        queue.addWithoutCommit(ptr, transactionID);        success = true;    } catch (IOException e) {        channelCounter.incrementEventPutErrorCount();        throw new ChannelException("Put failed due to IO error " + channelNameDescriptor, e);    } finally {        log.unlockShared();        if (!success) {                                    queueRemaining.release();        }    }}
f8425491b25802703eb5080383b86f3b99d38a0998a1c49a9f85e4971cf4e57c
doTake
protected Event doTake() throws InterruptedException
{    channelCounter.incrementEventTakeAttemptCount();    if (takeList.remainingCapacity() == 0) {        throw new ChannelException("Take list for FileBackedTransaction, capacity " + takeList.size() + " full, consider committing more frequently, " + "increasing capacity, or increasing thread count. " + channelNameDescriptor);    }    log.lockShared();    try {        while (true) {            FlumeEventPointer ptr = queue.removeHead(transactionID);            if (ptr == null) {                return null;            } else {                try {                                                            Preconditions.checkState(takeList.offer(ptr), "takeList offer failed " + channelNameDescriptor);                                        log.take(transactionID, ptr);                    Event event = log.get(ptr);                    return event;                } catch (IOException e) {                    channelCounter.incrementEventTakeErrorCount();                    throw new ChannelException("Take failed due to IO error " + channelNameDescriptor, e);                } catch (NoopRecordException e) {                    LOG.warn("Corrupt record replaced by File Channel Integrity " + "tool found. Will retrieve next event", e);                    takeList.remove(ptr);                } catch (CorruptEventException ex) {                    channelCounter.incrementEventTakeErrorCount();                    if (fsyncPerTransaction) {                        throw new ChannelException(ex);                    }                    LOG.warn("Corrupt record found. Event will be " + "skipped, and next event will be read.", ex);                    takeList.remove(ptr);                }            }        }    } finally {        log.unlockShared();    }}
1665f7d1b67a1fa794c9fb67a1be01e4bf6a8b0e782a8f9a49914917f9ecf058
doCommit
protected void doCommit() throws InterruptedException
{    int puts = putList.size();    int takes = takeList.size();    if (puts > 0) {        Preconditions.checkState(takes == 0, "nonzero puts and takes " + channelNameDescriptor);        log.lockShared();        try {            log.commitPut(transactionID);            channelCounter.addToEventPutSuccessCount(puts);            synchronized (queue) {                while (!putList.isEmpty()) {                    if (!queue.addTail(putList.removeFirst())) {                        StringBuilder msg = new StringBuilder();                        msg.append("Queue add failed, this shouldn't be able to ");                        msg.append("happen. A portion of the transaction has been ");                        msg.append("added to the queue but the remaining portion ");                        msg.append("cannot be added. Those messages will be consumed ");                        msg.append("despite this transaction failing. Please report.");                        msg.append(channelNameDescriptor);                        LOG.error(msg.toString());                        Preconditions.checkState(false, msg.toString());                    }                }                queue.completeTransaction(transactionID);            }        } catch (IOException e) {            throw new ChannelException("Commit failed due to IO error " + channelNameDescriptor, e);        } finally {            log.unlockShared();        }    } else if (takes > 0) {        log.lockShared();        try {            log.commitTake(transactionID);            queue.completeTransaction(transactionID);            channelCounter.addToEventTakeSuccessCount(takes);        } catch (IOException e) {            throw new ChannelException("Commit failed due to IO error " + channelNameDescriptor, e);        } finally {            log.unlockShared();        }        queueRemaining.release(takes);    }    putList.clear();    takeList.clear();    channelCounter.setChannelSize(queue.getSize());}
2cbb76d448fbcbe4b802d87cf143885cfe914d2929bc4f7d5164451c23333cb5
doRollback
protected void doRollback() throws InterruptedException
{    int puts = putList.size();    int takes = takeList.size();    log.lockShared();    try {        if (takes > 0) {            Preconditions.checkState(puts == 0, "nonzero puts and takes " + channelNameDescriptor);            synchronized (queue) {                while (!takeList.isEmpty()) {                    Preconditions.checkState(queue.addHead(takeList.removeLast()), "Queue add failed, this shouldn't be able to happen " + channelNameDescriptor);                }            }        }        putList.clear();        takeList.clear();        queue.completeTransaction(transactionID);        channelCounter.setChannelSize(queue.getSize());        log.rollback(transactionID);    } catch (IOException e) {        throw new ChannelException("Commit failed due to IO error " + channelNameDescriptor, e);    } finally {        log.unlockShared();                        queueRemaining.release(puts);    }}
e070824179dec2f9614419fc4c8df8e445802c6196ed702dc83bc6777977382c
initialValue
protected CharsetEncoder initialValue()
{    return Charset.forName("UTF-8").newEncoder().onMalformedInput(CodingErrorAction.REPLACE).onUnmappableCharacter(CodingErrorAction.REPLACE);}
014aa9be05b03659e6a7151affb7545eb1864ac5b507ea9aa2a2b1f2b956ee24
initialValue
protected CharsetDecoder initialValue()
{    return Charset.forName("UTF-8").newDecoder().onMalformedInput(CodingErrorAction.REPLACE).onUnmappableCharacter(CodingErrorAction.REPLACE);}
9a691e59a635186c5f7258710b8e44f5caf3510a02999c2c0ea95c8238b813ad
getHeaders
public Map<String, String> getHeaders()
{    return headers;}
6d1c35600a6f29feedab1769a2763829b83814294b318a32e8c71bf3529059a1
setHeaders
public void setHeaders(Map<String, String> headers)
{    this.headers = headers;}
a624aa1b85808a74c9f320025ea600169bd6e4692611a44ef53a1970442ef820
getBody
public byte[] getBody()
{    return body;}
b8505eb3e09ba9bb11ab8433148a62af59b6b1a27ffe7e69cf12f0e20e7c76a1
setBody
public void setBody(byte[] body)
{    this.body = body;}
a894510dd4db439ff8e17ae1059489dc3abc97178e5932ceed0c70c3af165401
write
public void write(DataOutput out) throws IOException
{    out.writeByte(0);    Map<String, String> writeHeaders = getHeaders();    if (null != writeHeaders) {        out.writeInt(headers.size());        CharsetEncoder encoder = ENCODER_FACTORY.get();        for (String key : headers.keySet()) {            out.writeByte(EVENT_MAP_TEXT_WRITABLE_ID);            ByteBuffer keyBytes = encoder.encode(CharBuffer.wrap(key.toCharArray()));            int keyLength = keyBytes.limit();            WritableUtils.writeVInt(out, keyLength);            out.write(keyBytes.array(), 0, keyLength);            String value = headers.get(key);            out.write(EVENT_MAP_TEXT_WRITABLE_ID);            ByteBuffer valueBytes = encoder.encode(CharBuffer.wrap(value.toCharArray()));            int valueLength = valueBytes.limit();            WritableUtils.writeVInt(out, valueLength);            out.write(valueBytes.array(), 0, valueLength);        }    } else {        out.writeInt(0);    }    byte[] body = getBody();    if (body == null) {        out.writeInt(-1);    } else {        out.writeInt(body.length);        out.write(body);    }}
5478cc5683f6dfd4515c383752d7c803555efc63d03fd84a03ba8dcd17eb4324
readFields
public void readFields(DataInput in) throws IOException
{        byte newClasses = in.readByte();        for (byte i = 0; i < newClasses; i++) {        in.readByte();        in.readUTF();    }    Map<String, String> newHeaders = new HashMap<String, String>();    int numEntries = in.readInt();    CharsetDecoder decoder = DECODER_FACTORY.get();    for (int i = 0; i < numEntries; i++) {        byte keyClassId = in.readByte();        assert (keyClassId == EVENT_MAP_TEXT_WRITABLE_ID);        int keyLength = WritableUtils.readVInt(in);        byte[] keyBytes = new byte[keyLength];        in.readFully(keyBytes, 0, keyLength);        String key = decoder.decode(ByteBuffer.wrap(keyBytes)).toString();        byte valueClassId = in.readByte();        assert (valueClassId == EVENT_MAP_TEXT_WRITABLE_ID);        int valueLength = WritableUtils.readVInt(in);        byte[] valueBytes = new byte[valueLength];        in.readFully(valueBytes, 0, valueLength);        String value = decoder.decode(ByteBuffer.wrap(valueBytes)).toString();        newHeaders.put(key, value);    }    setHeaders(newHeaders);    byte[] body = null;    int bodyLength = in.readInt();    if (bodyLength != -1) {        body = new byte[bodyLength];        in.readFully(body);    }    setBody(body);}
5640f4da07ce5fc7f1b1bc00abf3990d7debc8686bf68096c572b8729ba5000c
from
 static FlumeEvent from(DataInput in) throws IOException
{    FlumeEvent event = new FlumeEvent();    event.readFields(in);    return event;}
5e7fde6fc47b6006059dd577db1ae0c9ccc55096d3ad388b5279bb5c428839bb
getFileID
 int getFileID()
{    return fileID;}
bac23a8fc6fffed654c50d3177925aad71721d720df30d650b70b9983be5436a
getOffset
 int getOffset()
{    return offset;}
c517a84e36dd6eca9678e2224b1f4d7a7e02e21d16dc30b22289baea67cd33d5
toLong
public long toLong()
{    long result = fileID;    result = (long) fileID << 32;    result += (long) offset;    return result;}
0ac42bf5188762fc1283b5cbd2b3bb1031e80963813b3b310b15c3fb47050003
hashCode
public int hashCode()
{    final int prime = 31;    int result = 1;    result = prime * result + fileID;    result = prime * result + offset;    return result;}
4afeb0868b55bdd8e18a00a3cb43d83e0714378d1c4bb36f0936daefc060e2e8
equals
public boolean equals(Object obj)
{    if (this == obj) {        return true;    }    if (obj == null) {        return false;    }    if (getClass() != obj.getClass()) {        return false;    }    FlumeEventPointer other = (FlumeEventPointer) obj;    if (fileID != other.fileID) {        return false;    }    if (offset != other.offset) {        return false;    }    return true;}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return "FlumeEventPointer [fileID=" + fileID + ", offset=" + offset + "]";}
4a6c7579f01adb293b027d72201b7c27f50297c13b20b046c664d998fa2c84c2
fromLong
public static FlumeEventPointer fromLong(long value)
{    int fileID = (int) (value >>> 32);    int offset = (int) value;    return new FlumeEventPointer(fileID, offset);}
1bd0d28b81890ba4769a42fc2ae315ab80236eca21202ab289720818d9c62884
deserializeInflightPuts
 SetMultimap<Long, Long> deserializeInflightPuts() throws IOException, BadCheckpointException
{    return inflightPuts.deserialize();}
82125b4ea208b232f976ba425879962e2a4e976f72af0e336b28e77be0364352
deserializeInflightTakes
 SetMultimap<Long, Long> deserializeInflightTakes() throws IOException, BadCheckpointException
{    return inflightTakes.deserialize();}
0c1fe87b96a3f48facc23f23a55a3b3329f4b1a8c0d16c09023f412462d9c24e
getLogWriteOrderID
 synchronized long getLogWriteOrderID()
{    return backingStore.getLogWriteOrderID();}
7b508aebd572038f342efd2c32ef8086e26e99710a2b5e4c1fea251ded4519bb
checkpoint
 synchronized boolean checkpoint(boolean force) throws Exception
{    if (!backingStore.syncRequired() && !inflightTakes.syncRequired() && !force) {                        LOG.debug("Checkpoint not required");        return false;    }    backingStore.beginCheckpoint();    inflightPuts.serializeAndWrite();    inflightTakes.serializeAndWrite();    backingStore.checkpoint();    return true;}
01b527502d1a2b58a3f66379b74c012a7cbdafdadb3decdb11f9e5cb285dcd88
removeHead
 synchronized FlumeEventPointer removeHead(long transactionID)
{    if (backingStore.getSize() == 0) {        return null;    }    long value = remove(0, transactionID);    Preconditions.checkState(value != EMPTY, "Empty value " + channelNameDescriptor);    FlumeEventPointer ptr = FlumeEventPointer.fromLong(value);    backingStore.decrementFileID(ptr.getFileID());    return ptr;}
e7039b7fcfdc508a818ac0c855a4074c847f64cb44523bf178d27267f1f6a3e2
addHead
 synchronized boolean addHead(FlumeEventPointer e)
{        if (backingStore.getSize() == backingStore.getCapacity()) {        LOG.error("Could not reinsert to queue, events which were taken but " + "not committed. Please report this issue.");        return false;    }    long value = e.toLong();    Preconditions.checkArgument(value != EMPTY);    backingStore.incrementFileID(e.getFileID());    add(0, value);    return true;}
d087514c15220e6d88042c836dc0aaae2b7770badab606d196f7b88039fb0ba4
addTail
 synchronized boolean addTail(FlumeEventPointer e)
{    if (getSize() == backingStore.getCapacity()) {        return false;    }    long value = e.toLong();    Preconditions.checkArgument(value != EMPTY);    backingStore.incrementFileID(e.getFileID());    add(backingStore.getSize(), value);    return true;}
1cc80f53fed885bf131aa2af54252a989f632c559352f720beb2ba6e97c6f3b6
addWithoutCommit
 synchronized void addWithoutCommit(FlumeEventPointer e, long transactionID)
{    inflightPuts.addEvent(transactionID, e.toLong());}
570943752be95b12706cd17c548375078a77b3247bfbd6f40c77aea1d8b7d72d
remove
 synchronized boolean remove(FlumeEventPointer e)
{    long value = e.toLong();    Preconditions.checkArgument(value != EMPTY);    if (queueSet == null) {        throw new IllegalStateException("QueueSet is null, thus replayComplete" + " has been called which is illegal");    }    if (!queueSet.contains(value)) {        return false;    }    searchCount++;    long start = System.currentTimeMillis();    for (int i = 0; i < backingStore.getSize(); i++) {        if (get(i) == value) {            remove(i, 0);            FlumeEventPointer ptr = FlumeEventPointer.fromLong(value);            backingStore.decrementFileID(ptr.getFileID());            searchTime += System.currentTimeMillis() - start;            return true;        }    }    searchTime += System.currentTimeMillis() - start;    return false;}
e9ec0c08b8f95cb95b9e3638c3c334d99b9890720a29a387d3b9ab7a0dee98a4
getFileIDs
 synchronized SortedSet<Integer> getFileIDs()
{                SortedSet<Integer> fileIDs = new TreeSet<Integer>(backingStore.getReferenceCounts());    fileIDs.addAll(inflightPuts.getFileIDs());    fileIDs.addAll(inflightTakes.getFileIDs());    return fileIDs;}
c9e736310e70a7c0db8b39f54cc9e8774278f9ab4ba0da40f3dbe66a4e5c9eb6
get
protected long get(int index)
{    if (index < 0 || index > backingStore.getSize() - 1) {        throw new IndexOutOfBoundsException(String.valueOf(index) + channelNameDescriptor);    }    return backingStore.get(index);}
c5444aa439feb007af8fa9db36eb09c4d1bdecb78f97603f7ffe5eaf5ecc5ff3
set
private void set(int index, long value)
{    if (index < 0 || index > backingStore.getSize() - 1) {        throw new IndexOutOfBoundsException(String.valueOf(index) + channelNameDescriptor);    }    backingStore.put(index, value);}
a65751b53fa8e6bd327a81f9183f55eb917d9922f669a4d7eac74cf9402c4bbf
add
protected boolean add(int index, long value)
{    if (index < 0 || index > backingStore.getSize()) {        throw new IndexOutOfBoundsException(String.valueOf(index) + channelNameDescriptor);    }    if (backingStore.getSize() == backingStore.getCapacity()) {        return false;    }    backingStore.setSize(backingStore.getSize() + 1);    if (index <= backingStore.getSize() / 2) {                backingStore.setHead(backingStore.getHead() - 1);        if (backingStore.getHead() < 0) {            backingStore.setHead(backingStore.getCapacity() - 1);        }        for (int i = 0; i < index; i++) {            set(i, get(i + 1));        }    } else {                for (int i = backingStore.getSize() - 1; i > index; i--) {            set(i, get(i - 1));        }    }    set(index, value);    if (queueSet != null) {        queueSet.add(value);    }    return true;}
6ea739e0e07d92ba7cece3b6cef09026d9351859a2aebcbc0b6d20dd48dc973b
completeTransaction
 synchronized void completeTransaction(long transactionID)
{    if (!inflightPuts.completeTransaction(transactionID)) {        inflightTakes.completeTransaction(transactionID);    }}
43fabe68ea5398a10c1c36e30b1a57c03d74076d01a81efe51a2f60c271b643d
remove
protected synchronized long remove(int index, long transactionID)
{    if (index < 0 || index > backingStore.getSize() - 1) {        throw new IndexOutOfBoundsException("index = " + index + ", queueSize " + backingStore.getSize() + " " + channelNameDescriptor);    }    copyCount++;    long start = System.currentTimeMillis();    long value = get(index);    if (queueSet != null) {        queueSet.remove(value);    }        if (transactionID != 0) {        inflightTakes.addEvent(transactionID, value);    }    if (index > backingStore.getSize() / 2) {                for (int i = index; i < backingStore.getSize() - 1; i++) {            long rightValue = get(i + 1);            set(i, rightValue);        }        set(backingStore.getSize() - 1, EMPTY);    } else {                for (int i = index - 1; i >= 0; i--) {            long leftValue = get(i);            set(i + 1, leftValue);        }        set(0, EMPTY);        backingStore.setHead(backingStore.getHead() + 1);        if (backingStore.getHead() == backingStore.getCapacity()) {            backingStore.setHead(0);        }    }    backingStore.setSize(backingStore.getSize() - 1);    copyTime += System.currentTimeMillis() - start;    return value;}
1da36d395979887871986f1eadab757a1cbe336586e6ca29b8d6242ecf2b55d5
getSize
protected synchronized int getSize()
{    return backingStore.getSize() + inflightTakes.getSize();}
b5a88633b1030fb86fd7f643804f6ea7ac9e8b092ca1aac528aa0781750bc032
getCapacity
public int getCapacity()
{    return backingStore.getCapacity();}
815bfe0a563c69c617425d0b5d05bf8b5871fce6b21a7c939b7949a62f1fc24e
close
 synchronized void close() throws IOException
{    try {        if (db != null) {            db.close();        }    } catch (Exception ex) {        LOG.warn("Error closing db", ex);    }    try {        backingStore.close();        inflightPuts.close();        inflightTakes.close();    } catch (IOException e) {        LOG.warn("Error closing backing store", e);    }}
fa7ca62184f5680e6e297175fac7d8674effcf672568d868110fcad56ebadb26
replayComplete
 synchronized void replayComplete()
{    String msg = "Search Count = " + searchCount + ", Search Time = " + searchTime + ", Copy Count = " + copyCount + ", Copy Time = " + copyTime;    LOG.info(msg);    if (db != null) {        db.close();    }    queueSet = null;    db = null;}
39257ce27e77b7aec0b40b146a6e9b940af71f392c0957b877b62780f9830bbc
getSearchCount
 long getSearchCount()
{    return searchCount;}
c8b3059a015d6b2d678e4faec96bee3a50f7745c33a163398949ed1a40e8a724
getCopyCount
 long getCopyCount()
{    return copyCount;}
977a0fda4f5bb3eb634d7930cdef793f652b9bc5b80e3deb56ad8980e872fb5c
completeTransaction
public boolean completeTransaction(Long transactionID)
{    if (!inflightEvents.containsKey(transactionID)) {        return false;    }    inflightEvents.removeAll(transactionID);    inflightFileIDs.removeAll(transactionID);    syncRequired = true;    return true;}
e035855d26135eae488c92a4eee6bedc63537cec8a1897cf05916cd304176692
addEvent
public void addEvent(Long transactionID, Long pointer)
{    inflightEvents.put(transactionID, pointer);    inflightFileIDs.put(transactionID, FlumeEventPointer.fromLong(pointer).getFileID());    syncRequired = true;}
ac8e2230a9880973bbc4bb175e6ac870e7781eab1426985ae547e45ff35fe88b
serializeAndWrite
public void serializeAndWrite() throws Exception
{    Collection<Long> values = inflightEvents.values();    if (!fileChannel.isOpen()) {        file = new RandomAccessFile(inflightEventsFile, "rw");        fileChannel = file.getChannel();    }    if (values.isEmpty()) {        file.setLength(0L);    }    try {        int expectedFileSize = ((        (inflightEvents.keySet().size() * 2) +         values.size()) *         8) +         16;                        file.setLength(expectedFileSize);        Preconditions.checkState(file.length() == expectedFileSize, "Expected File size of inflight events file does not match the " + "current file size. Checkpoint is incomplete.");        file.seek(0);        final ByteBuffer buffer = ByteBuffer.allocate(expectedFileSize);        LongBuffer longBuffer = buffer.asLongBuffer();        for (Long txnID : inflightEvents.keySet()) {            Set<Long> pointers = inflightEvents.get(txnID);            longBuffer.put(txnID);            longBuffer.put((long) pointers.size());            LOG.debug("Number of events inserted into " + "inflights file: " + String.valueOf(pointers.size()) + " file: " + inflightEventsFile.getCanonicalPath());            long[] written = ArrayUtils.toPrimitive(pointers.toArray(new Long[0]));            longBuffer.put(written);        }        byte[] checksum = digest.digest(buffer.array());        file.write(checksum);        buffer.position(0);        fileChannel.write(buffer);        fileChannel.force(true);        syncRequired = false;    } catch (IOException ex) {        LOG.error("Error while writing checkpoint to disk.", ex);        throw ex;    }}
20539be131ad1f2b64dee6c10d955c548bc4eb3b7bf9287c5dd73e9162efa404
deserialize
public SetMultimap<Long, Long> deserialize() throws IOException, BadCheckpointException
{    SetMultimap<Long, Long> inflights = HashMultimap.create();    if (!fileChannel.isOpen()) {        file = new RandomAccessFile(inflightEventsFile, "rw");        fileChannel = file.getChannel();    }    if (file.length() == 0) {        return inflights;    }    file.seek(0);    byte[] checksum = new byte[16];    file.read(checksum);    ByteBuffer buffer = ByteBuffer.allocate((int) (file.length() - file.getFilePointer()));    fileChannel.read(buffer);    byte[] fileChecksum = digest.digest(buffer.array());    if (!Arrays.equals(checksum, fileChecksum)) {        throw new BadCheckpointException("Checksum of inflights file differs" + " from the checksum expected.");    }    buffer.position(0);    LongBuffer longBuffer = buffer.asLongBuffer();    try {        while (true) {            long txnID = longBuffer.get();            int numEvents = (int) (longBuffer.get());            for (int i = 0; i < numEvents; i++) {                long val = longBuffer.get();                inflights.put(txnID, val);            }        }    } catch (BufferUnderflowException ex) {        LOG.debug("Reached end of inflights buffer. Long buffer position =" + String.valueOf(longBuffer.position()));    }    return inflights;}
941db94d6268e6af95af0456d14a8e0ddcf7f7ed2bb867b918ae21dbe3f2de3d
getSize
public int getSize()
{    return inflightEvents.size();}
5ed177c1fbe4a12ca329af4102515ec770c26853f3c3713e0f82938a8857955a
syncRequired
public boolean syncRequired()
{    return syncRequired;}
e05edb7a04bddc7025b39444d08ef0c2586476b2fb420290a18d6d3b5b0796fd
getFileIDs
public Collection<Integer> getFileIDs()
{    return inflightFileIDs.values();}
a8d2debb48e0de5297d2598b1fa54f5dd6ed844ae624b095c17082e2c688a186
getInFlightPointers
public Collection<Long> getInFlightPointers()
{    return inflightEvents.values();}
e0823f55b3a09d41a3e1e792f7e6687db9199c2db9b29e9922d93cbdc6f1284b
close
public void close() throws IOException
{    file.close();}
19a24880b630c5416795a9247f56f3014ca8e567f85c7b8e4d6760590c45fccd
isOpen
public boolean isOpen()
{    return open;}
ec405af79bc7fdff05442272a33d126fb8c68784105328bccf8e9f890a7786ff
setOpen
public void setOpen(boolean open)
{    this.open = open;}
6bf93c52cf32997b01f1a0cd0476ff4f49b78c6e63a84f95fce5fc541e92dd08
getClosed
public int getClosed()
{    return open ? 0 : 1;}
90bed88f20d3b9ead98fb2fafcf5899a37386b3363faf8eff9290dd8626572fb
getUnhealthy
public int getUnhealthy()
{    return unhealthy;}
0bede06c7897dc00b22b03e6014bfdc6bd0e226675a6c9e2c40c08ae1e8778e6
setUnhealthy
public void setUnhealthy(int unhealthy)
{    this.unhealthy = unhealthy;}
30ab0d2e76660866b1ded6a1ea6afceb12a5634453946e56d678a18df781d29d
getEventPutErrorCount
public long getEventPutErrorCount()
{    return get(EVENT_PUT_ERROR_COUNT);}
44ab277565f12378bf195e30bfce53e1625815e283cd40f9a8515bedd396b222
incrementEventPutErrorCount
public void incrementEventPutErrorCount()
{    increment(EVENT_PUT_ERROR_COUNT);}
2f95fba411f0343ae61172b84dfda63c8fe0bb64d9b64baaa048a6f00af03c77
getEventTakeErrorCount
public long getEventTakeErrorCount()
{    return get(EVENT_TAKE_ERROR_COUNT);}
25f43f9e630e9b016d89734beca5318fe54d2e73956b3dd1838c50e7e5c52fe1
incrementEventTakeErrorCount
public void incrementEventTakeErrorCount()
{    increment(EVENT_TAKE_ERROR_COUNT);}
217576b3c77e9b92d33eb6fa393cf8e4e3e1c1991fbb31a1dd1bc855a1f5e83a
getCheckpointWriteErrorCount
public long getCheckpointWriteErrorCount()
{    return get(CHECKPOINT_WRITE_ERROR_COUNT);}
ee2134f47885ab871995aff25550e615b91b599d5e22401ca889183f45c7ffce
incrementCheckpointWriteErrorCount
public void incrementCheckpointWriteErrorCount()
{    increment(CHECKPOINT_WRITE_ERROR_COUNT);}
494ebdbc33cc1ba0c4280b1b785d91dcbad3cbfb3596698f6b791c052f15b4ae
getCheckpointBackupWriteErrorCount
public long getCheckpointBackupWriteErrorCount()
{    return get(CHECKPOINT_BACKUP_WRITE_ERROR_COUNT);}
bf242ae0d495eee17a8a5c0743e329633087fd215adc54653b5d17fce597d4c9
incrementCheckpointBackupWriteErrorCount
public void incrementCheckpointBackupWriteErrorCount()
{    increment(CHECKPOINT_BACKUP_WRITE_ERROR_COUNT);}
23458df6e7b260ad4cd5efa46eb8e6dd3153eb0f8d9685296768d0c8df20ee1b
isFsyncPerTransaction
 boolean isFsyncPerTransaction()
{    return fsyncPerTransaction;}
da3809b6f90a9a0376aaec30050ce7f662d0f3e0225a996a7f35d224133a32bf
setFsyncPerTransaction
 void setFsyncPerTransaction(boolean fsyncPerTransaction)
{    this.fsyncPerTransaction = fsyncPerTransaction;}
74f31342fb25a3124e2949bbf4e51509a5c9e03dad54d1a0c69f3ac951e2a7b5
getFsyncInterval
 int getFsyncInterval()
{    return fsyncInterval;}
45108958cd8f1a8b1984af1f4a3ec15bbaa90efedd711f5307e322edec155a19
setFsyncInterval
 void setFsyncInterval(int fsyncInterval)
{    this.fsyncInterval = fsyncInterval;}
0641864f018928230ad8c47c7aa1a6edac2d10af169f83b03778b7bacb25edb3
setUsableSpaceRefreshInterval
 Builder setUsableSpaceRefreshInterval(long usableSpaceRefreshInterval)
{    bUsableSpaceRefreshInterval = usableSpaceRefreshInterval;    return this;}
fd45c8188e1bea1560dbcf155f844fffb4b47d8313447d8d11418309442c69e1
setCheckpointInterval
 Builder setCheckpointInterval(long interval)
{    bCheckpointInterval = interval;    return this;}
f536d3664da49bc494695c694acb3806acc759eb8bee2b7dc544e1e676a0bc9d
setMaxFileSize
 Builder setMaxFileSize(long maxSize)
{    bMaxFileSize = maxSize;    return this;}
cedec03469f161dc8ba347cac8f23924f7812edcc4cc02a19dca1bb2d085e759
setQueueSize
 Builder setQueueSize(int capacity)
{    bQueueCapacity = capacity;    return this;}
d40a93442a98ee27c64a5d9c00efd478fd57e5fe8fd020d664bd4cbd8d1626b7
setCheckpointDir
 Builder setCheckpointDir(File cpDir)
{    bCheckpointDir = cpDir;    return this;}
c6e9541508efb092d4097f8f9b61f0f1a31b36f5b168429f268b0089a149dc43
setLogDirs
 Builder setLogDirs(File[] dirs)
{    bLogDirs = dirs;    return this;}
9fec4300964c284c29bade222545492f0318e1efc45a41b05868f45c280ed78a
setChannelName
 Builder setChannelName(String name)
{    bName = name;    return this;}
6f32698d971dac0fa661a0fb332cce3b131fec1724bee4593636dc2e4aa8389b
setMinimumRequiredSpace
 Builder setMinimumRequiredSpace(long minimumRequiredSpace)
{    bMinimumRequiredSpace = minimumRequiredSpace;    return this;}
3cf1dca9be3725af0e9a116554ce1731ece72e3ba5cd4c8dd1e5e71dfe4e5abb
setUseLogReplayV1
 Builder setUseLogReplayV1(boolean useLogReplayV1)
{    this.useLogReplayV1 = useLogReplayV1;    return this;}
e0d7a59eb4d831c7813c965b3fa767ec3b3a093dbdfa54ef25cbe2d10673333e
setUseFastReplay
 Builder setUseFastReplay(boolean useFastReplay)
{    this.useFastReplay = useFastReplay;    return this;}
1f7cfc683a2e23f9d5c328b54e0c8802e940f483ecab7957d29c598cc68a7008
setEncryptionKeyProvider
 Builder setEncryptionKeyProvider(KeyProvider encryptionKeyProvider)
{    bEncryptionKeyProvider = encryptionKeyProvider;    return this;}
4ec25358a0ad55fbb188c39740dfd8335bd8859c1d058b91b21a7b11640d2a4d
setEncryptionKeyAlias
 Builder setEncryptionKeyAlias(String encryptionKeyAlias)
{    bEncryptionKeyAlias = encryptionKeyAlias;    return this;}
9220dbe12ee2015bc5f69ac0e40928036cfc6d2e0a226ef75bbe029d2a94d0fd
setEncryptionCipherProvider
 Builder setEncryptionCipherProvider(String encryptionCipherProvider)
{    bEncryptionCipherProvider = encryptionCipherProvider;    return this;}
d32f06242267d52366f2d3c8888a2ebb384718ad7700cb5ee4c14ba1a6aba091
setUseDualCheckpoints
 Builder setUseDualCheckpoints(boolean UseDualCheckpoints)
{    this.bUseDualCheckpoints = UseDualCheckpoints;    return this;}
1fd268b2ea705a33b11262b124e2e15d48a2918f6bf9ec0c0a5f6e6b26b8549f
setCompressBackupCheckpoint
 Builder setCompressBackupCheckpoint(boolean compressBackupCheckpoint)
{    this.bCompressBackupCheckpoint = compressBackupCheckpoint;    return this;}
68fe290f5fbd849f7d198d2932fcd80788abbc37da49c3073e54b894d0abbbe4
setBackupCheckpointDir
 Builder setBackupCheckpointDir(File backupCheckpointDir)
{    this.bBackupCheckpointDir = backupCheckpointDir;    return this;}
e6799492ee190deb37f84f70bfd7f750a8abfc2b0f6dd70fcdcc2a25b41e5dce
setCheckpointOnClose
 Builder setCheckpointOnClose(boolean enableCheckpointOnClose)
{    this.checkpointOnClose = enableCheckpointOnClose;    return this;}
bf39f8121fb57b65055dc41aef10ae7b2d1036caf6abfade1833d5cba6ff3916
setChannelCounter
 Builder setChannelCounter(FileChannelCounter channelCounter)
{    this.channelCounter = channelCounter;    return this;}
28b5b87c68b58288d1c4322726ca02bbd8fb37e105a574d3a198ddd3df776b2a
build
 Log build() throws IOException
{    return new Log(bCheckpointInterval, bMaxFileSize, bQueueCapacity, bUseDualCheckpoints, bCompressBackupCheckpoint, bCheckpointDir, bBackupCheckpointDir, bName, useLogReplayV1, useFastReplay, bMinimumRequiredSpace, bEncryptionKeyProvider, bEncryptionKeyAlias, bEncryptionCipherProvider, bUsableSpaceRefreshInterval, fsyncPerTransaction, fsyncInterval, checkpointOnClose, channelCounter, bLogDirs);}
676ffb19866e5392bd6e733714956689675d5f070655fbd32ac634123e4cb91a
replay
 void replay() throws IOException
{    Preconditions.checkState(!open, "Cannot replay after Log has been opened");    lockExclusive();    try {        /*       * First we are going to look through the data directories       * and find all log files. We will store the highest file id       * (at the end of the filename) we find and use that when we       * create additional log files.       *       * Also store up the list of files so we can replay them later.       */        LOGGER.info("Replay started");        nextFileID.set(0);        List<File> dataFiles = Lists.newArrayList();        for (File logDir : logDirs) {            for (File file : LogUtils.getLogs(logDir)) {                int id = LogUtils.getIDForFile(file);                dataFiles.add(file);                nextFileID.set(Math.max(nextFileID.get(), id));                idLogFileMap.put(id, LogFileFactory.getRandomReader(new File(logDir, PREFIX + id), encryptionKeyProvider, fsyncPerTransaction));            }        }        LOGGER.info("Found NextFileID " + nextFileID + ", from " + dataFiles);        /*       * sort the data files by file id so we can replay them by file id       * which should approximately give us sequential events       */        LogUtils.sort(dataFiles);        boolean shouldFastReplay = this.useFastReplay;        /*       * Read the checkpoint (in memory queue) from one of two alternating       * locations. We will read the last one written to disk.       */        File checkpointFile = new File(checkpointDir, "checkpoint");        if (shouldFastReplay) {            if (checkpointFile.exists()) {                LOGGER.debug("Disabling fast full replay because checkpoint " + "exists: " + checkpointFile);                shouldFastReplay = false;            } else {                LOGGER.debug("Not disabling fast full replay because checkpoint " + " does not exist: " + checkpointFile);            }        }        File inflightTakesFile = new File(checkpointDir, "inflighttakes");        File inflightPutsFile = new File(checkpointDir, "inflightputs");        File queueSetDir = new File(checkpointDir, QUEUE_SET);        EventQueueBackingStore backingStore = null;        try {            backingStore = EventQueueBackingStoreFactory.get(checkpointFile, backupCheckpointDir, queueCapacity, channelNameDescriptor, channelCounter, true, this.useDualCheckpoints, this.compressBackupCheckpoint);            queue = new FlumeEventQueue(backingStore, inflightTakesFile, inflightPutsFile, queueSetDir);            LOGGER.info("Last Checkpoint " + new Date(checkpointFile.lastModified()) + ", queue depth = " + queue.getSize());            /*         * We now have everything we need to actually replay the log files         * the queue, the timestamp the queue was written to disk, and         * the list of data files.         *         * This will throw if and only if checkpoint file was fine,         * but the inflights were not. If the checkpoint was bad, the backing         * store factory would have thrown.         */            doReplay(queue, dataFiles, encryptionKeyProvider, shouldFastReplay);        } catch (BadCheckpointException ex) {            backupRestored = false;            if (useDualCheckpoints) {                LOGGER.warn("Checkpoint may not have completed successfully. " + "Restoring checkpoint and starting up.", ex);                if (EventQueueBackingStoreFile.backupExists(backupCheckpointDir)) {                    backupRestored = EventQueueBackingStoreFile.restoreBackup(checkpointDir, backupCheckpointDir);                }            }            if (!backupRestored) {                LOGGER.warn("Checkpoint may not have completed successfully. " + "Forcing full replay, this may take a while.", ex);                if (!Serialization.deleteAllFiles(checkpointDir, EXCLUDES)) {                    throw new IOException("Could not delete files in checkpoint " + "directory to recover from a corrupt or incomplete checkpoint");                }            }            backingStore = EventQueueBackingStoreFactory.get(checkpointFile, backupCheckpointDir, queueCapacity, channelNameDescriptor, channelCounter, true, useDualCheckpoints, compressBackupCheckpoint);            queue = new FlumeEventQueue(backingStore, inflightTakesFile, inflightPutsFile, queueSetDir);                                    shouldFastReplay = this.useFastReplay;            doReplay(queue, dataFiles, encryptionKeyProvider, shouldFastReplay);            if (!shouldFastReplay) {                didFullReplayDueToBadCheckpointException = true;            }        }        for (int index = 0; index < logDirs.length; index++) {            LOGGER.info("Rolling " + logDirs[index]);            roll(index);        }        /*       * Now that we have replayed, write the current queue to disk       */        writeCheckpoint(true);        open = true;    } catch (Exception ex) {        LOGGER.error("Failed to initialize Log on " + channelNameDescriptor, ex);        if (ex instanceof IOException) {            throw (IOException) ex;        }        Throwables.propagate(ex);    } finally {        unlockExclusive();    }}
120184dd08c381abe66d76a005bdc3b3aebcae831da8d434ff1e20f6a543e9f8
doReplay
private void doReplay(FlumeEventQueue queue, List<File> dataFiles, KeyProvider encryptionKeyProvider, boolean useFastReplay) throws Exception
{    CheckpointRebuilder rebuilder = new CheckpointRebuilder(dataFiles, queue, fsyncPerTransaction);    if (useFastReplay && rebuilder.rebuild()) {        didFastReplay = true;        LOGGER.info("Fast replay successful.");    } else {        ReplayHandler replayHandler = new ReplayHandler(queue, encryptionKeyProvider, fsyncPerTransaction);        if (useLogReplayV1) {            LOGGER.info("Replaying logs with v1 replay logic");            replayHandler.replayLogv1(dataFiles);        } else {            LOGGER.info("Replaying logs with v2 replay logic");            replayHandler.replayLog(dataFiles);        }        readCount = replayHandler.getReadCount();        putCount = replayHandler.getPutCount();        takeCount = replayHandler.getTakeCount();        rollbackCount = replayHandler.getRollbackCount();        committedCount = replayHandler.getCommitCount();    }}
6a45395008c8d72ef8040e5dd292c1a749460e802d04a6311ece973e6dae9364
didFastReplay
 boolean didFastReplay()
{    return didFastReplay;}
8df54b08ee09b4f121b16fa1d7eca39ba87e5d5a201e717044dc3e42611324c6
getReadCount
public int getReadCount()
{    return readCount;}
748c273b80f6fbb19de858e3bbac0785a6ea61b27a241f9b5a48075e98780cfb
getPutCount
public int getPutCount()
{    return putCount;}
b6b4b6b55518732a7847ce8d1f92d040503d8cdb0f340b2de1dad891b4a6a0b0
getTakeCount
public int getTakeCount()
{    return takeCount;}
015922852728fd062f778eb55881b4ab2f549adf391ac31457c0127a62412704
getCommittedCount
public int getCommittedCount()
{    return committedCount;}
d38c4508d682e0ee5457a8cf8102b3b6369de1e877b1f0e5174b35c01fca332a
getRollbackCount
public int getRollbackCount()
{    return rollbackCount;}
1757c11165cfffa4f8ea750da2ee7233039c4f5946a366e8985f31b15786b29e
backupRestored
 boolean backupRestored()
{    return backupRestored;}
c8ad46c6ecb9227e082e211665f36f819f8d94b4ad177f7c5017998d3eeb689d
didFullReplayDueToBadCheckpointException
 boolean didFullReplayDueToBadCheckpointException()
{    return didFullReplayDueToBadCheckpointException;}
50cf37c2a8dec55c1af1f313cd2dfb77fd3bf1ac9c52edd777c818b2bfa39bb9
getNextFileID
 int getNextFileID()
{    Preconditions.checkState(open, "Log is closed");    return nextFileID.get();}
67757b1c40bd628ea68e6f29e49350fb654c77a5c849b5804819fa2cd0c341ee
getFlumeEventQueue
 FlumeEventQueue getFlumeEventQueue()
{    Preconditions.checkState(open, "Log is closed");    return queue;}
a681503e812355f31c330307a34c5cb9e15c734302cb9d343c7826700d031527
get
 FlumeEvent get(FlumeEventPointer pointer) throws IOException, InterruptedException, NoopRecordException, CorruptEventException
{    Preconditions.checkState(open, "Log is closed");    int id = pointer.getFileID();    LogFile.RandomReader logFile = idLogFileMap.get(id);    Preconditions.checkNotNull(logFile, "LogFile is null for id " + id);    try {        return logFile.get(pointer.getOffset());    } catch (CorruptEventException ex) {        if (fsyncPerTransaction) {            open = false;            throw new IOException("Corrupt event found. Please run File Channel " + "Integrity tool.", ex);        }        throw ex;    }}
c7e7990a231e6df7fbd5d32f974558a31b57084119bbf02238d8417bb60d0a16
put
 FlumeEventPointer put(long transactionID, Event event) throws IOException
{    Preconditions.checkState(open, "Log is closed");    FlumeEvent flumeEvent = new FlumeEvent(event.getHeaders(), event.getBody());    Put put = new Put(transactionID, WriteOrderOracle.next(), flumeEvent);    ByteBuffer buffer = TransactionEventRecord.toByteBuffer(put);    int logFileIndex = nextLogWriter(transactionID);    long usableSpace = logFiles.get(logFileIndex).getUsableSpace();    long requiredSpace = minimumRequiredSpace + buffer.limit();    if (usableSpace <= requiredSpace) {        throw new IOException("Usable space exhausted, only " + usableSpace + " bytes remaining, required " + requiredSpace + " bytes");    }    boolean error = true;    try {        try {            FlumeEventPointer ptr = logFiles.get(logFileIndex).put(buffer);            error = false;            return ptr;        } catch (LogFileRetryableIOException e) {            if (!open) {                throw e;            }            roll(logFileIndex, buffer);            FlumeEventPointer ptr = logFiles.get(logFileIndex).put(buffer);            error = false;            return ptr;        }    } finally {        if (error && open) {            roll(logFileIndex);        }    }}
ee91a1a600dd01234f5738056f74ae37a36c738d756dfc70d390d2e0efa975a8
take
 void take(long transactionID, FlumeEventPointer pointer) throws IOException
{    Preconditions.checkState(open, "Log is closed");    Take take = new Take(transactionID, WriteOrderOracle.next(), pointer.getOffset(), pointer.getFileID());    ByteBuffer buffer = TransactionEventRecord.toByteBuffer(take);    int logFileIndex = nextLogWriter(transactionID);    long usableSpace = logFiles.get(logFileIndex).getUsableSpace();    long requiredSpace = minimumRequiredSpace + buffer.limit();    if (usableSpace <= requiredSpace) {        throw new IOException("Usable space exhausted, only " + usableSpace + " bytes remaining, required " + requiredSpace + " bytes");    }    boolean error = true;    try {        try {            logFiles.get(logFileIndex).take(buffer);            error = false;        } catch (LogFileRetryableIOException e) {            if (!open) {                throw e;            }            roll(logFileIndex, buffer);            logFiles.get(logFileIndex).take(buffer);            error = false;        }    } finally {        if (error && open) {            roll(logFileIndex);        }    }}
6ecbfdbd8f9c493395f2bfb38662f6efc7ec1018c0a44b2c255c4202f5b24b55
rollback
 void rollback(long transactionID) throws IOException
{    Preconditions.checkState(open, "Log is closed");    if (LOGGER.isDebugEnabled()) {        LOGGER.debug("Rolling back " + transactionID);    }    Rollback rollback = new Rollback(transactionID, WriteOrderOracle.next());    ByteBuffer buffer = TransactionEventRecord.toByteBuffer(rollback);    int logFileIndex = nextLogWriter(transactionID);    long usableSpace = logFiles.get(logFileIndex).getUsableSpace();    long requiredSpace = minimumRequiredSpace + buffer.limit();    if (usableSpace <= requiredSpace) {        throw new IOException("Usable space exhausted, only " + usableSpace + " bytes remaining, required " + requiredSpace + " bytes");    }    boolean error = true;    try {        try {            logFiles.get(logFileIndex).rollback(buffer);            error = false;        } catch (LogFileRetryableIOException e) {            if (!open) {                throw e;            }            roll(logFileIndex, buffer);            logFiles.get(logFileIndex).rollback(buffer);            error = false;        }    } finally {        if (error && open) {            roll(logFileIndex);        }    }}
dd95bbe9831bea6f023f80976f6d4c97ef852f4fd2dab17b3fbedab5490fee61
commitPut
 void commitPut(long transactionID) throws IOException, InterruptedException
{    Preconditions.checkState(open, "Log is closed");    commit(transactionID, TransactionEventRecord.Type.PUT.get());}
3e4aa19c9e4f54622d21577b020a7278cab39bec42ae5d79f14ce4395c8d9a6c
commitTake
 void commitTake(long transactionID) throws IOException, InterruptedException
{    Preconditions.checkState(open, "Log is closed");    commit(transactionID, TransactionEventRecord.Type.TAKE.get());}
58101f3a5fa321512081bcb7e2ec0cc51da1f90499998e48aa1cb0a1543c3fa0
unlockExclusive
private void unlockExclusive()
{    checkpointWriterLock.unlock();}
357d8fb2e9f21a95451ce921e0ccbdd7092e3f04bb97d779d8b430612afce3bc
lockShared
 void lockShared()
{    checkpointReadLock.lock();}
6e6d7f5d57e63ff6694a18c96b4849dc86ab3a79807bfbdef5a05c8505c758a1
unlockShared
 void unlockShared()
{    checkpointReadLock.unlock();}
5aec1b698020d656ebc07f86c50025538094fc0557a4cbcf669515481bd935ce
lockExclusive
private void lockExclusive()
{    checkpointWriterLock.lock();}
bc494cfecbb57650350e7394808bc5914946f1333cf7acf13e2e7c4abadf281c
close
 void close() throws IOException
{    lockExclusive();    try {        open = false;        try {            if (checkpointOnClose) {                                writeCheckpoint(true);            }        } catch (Exception err) {            LOGGER.warn("Failed creating checkpoint on close of channel " + channelNameDescriptor + "Replay will take longer next time channel is started.", err);        }        shutdownWorker();        if (logFiles != null) {            for (int index = 0; index < logFiles.length(); index++) {                LogFile.Writer writer = logFiles.get(index);                if (writer != null) {                    writer.close();                }            }        }        synchronized (idLogFileMap) {            for (Integer logId : idLogFileMap.keySet()) {                LogFile.RandomReader reader = idLogFileMap.get(logId);                if (reader != null) {                    reader.close();                }            }        }        queue.close();        try {            unlock(checkpointDir);        } catch (IOException ex) {            LOGGER.warn("Error unlocking " + checkpointDir, ex);        }        if (useDualCheckpoints) {            try {                unlock(backupCheckpointDir);            } catch (IOException ex) {                LOGGER.warn("Error unlocking " + checkpointDir, ex);            }        }        for (File logDir : logDirs) {            try {                unlock(logDir);            } catch (IOException ex) {                LOGGER.warn("Error unlocking " + logDir, ex);            }        }    } finally {        unlockExclusive();    }}
060dd93e28599167a4d0a3a57e39e1a2992c60f82c9b82b855776fb0ff6220f7
shutdownWorker
 void shutdownWorker()
{    String msg = "Attempting to shutdown background worker.";    System.out.println(msg);    LOGGER.info(msg);    workerExecutor.shutdown();    try {        workerExecutor.awaitTermination(10, TimeUnit.SECONDS);    } catch (InterruptedException e) {        LOGGER.error("Interrupted while waiting for worker to die.");    }}
51dd98cf6ec8ce606179a9afda708cb44737c1d36aebb89f3cfb184969b7eb93
setCheckpointInterval
 void setCheckpointInterval(long checkpointInterval)
{    this.checkpointInterval = checkpointInterval;}
7a310e17b83b52de33fcacbd21ea3d26e9e18458c16e04a4c3f9d489b80e1e8c
setMaxFileSize
 void setMaxFileSize(long maxFileSize)
{    this.maxFileSize = maxFileSize;}
f9f6b823b3f2ff171095773837145ace3a979f5541829d592007bc633319bad2
commit
private void commit(long transactionID, short type) throws IOException
{    Preconditions.checkState(open, "Log is closed");    Commit commit = new Commit(transactionID, WriteOrderOracle.next(), type);    ByteBuffer buffer = TransactionEventRecord.toByteBuffer(commit);    int logFileIndex = nextLogWriter(transactionID);    long usableSpace = logFiles.get(logFileIndex).getUsableSpace();    long requiredSpace = minimumRequiredSpace + buffer.limit();    if (usableSpace <= requiredSpace) {        throw new IOException("Usable space exhausted, only " + usableSpace + " bytes remaining, required " + requiredSpace + " bytes");    }    boolean error = true;    try {        try {            LogFile.Writer logFileWriter = logFiles.get(logFileIndex);                                                logFileWriter.commit(buffer);            logFileWriter.sync();            error = false;        } catch (LogFileRetryableIOException e) {            if (!open) {                throw e;            }            roll(logFileIndex, buffer);            LogFile.Writer logFileWriter = logFiles.get(logFileIndex);            logFileWriter.commit(buffer);            logFileWriter.sync();            error = false;        }    } finally {        if (error && open) {            roll(logFileIndex);        }    }}
a84fc49590d1e234e20d6093ef142c3e141a63c460ac2630c589ba99d93aa7dd
nextLogWriter
private int nextLogWriter(long transactionID)
{    return (int) Math.abs(transactionID % (long) logFiles.length());}
fed3231e567476a63fd8d8933c4dfd0b0bd169b3e54ca6e46a77c6805fdf1b77
roll
private void roll(int index) throws IOException
{    roll(index, null);}
322c35bd73f0d8dab9be2cb9a4d7410b98530699e517f214e48c09d3b6ab4457
roll
private synchronized void roll(int index, ByteBuffer buffer) throws IOException
{    lockShared();    try {        LogFile.Writer oldLogFile = logFiles.get(index);                if (oldLogFile == null || buffer == null || oldLogFile.isRollRequired(buffer)) {            try {                LOGGER.info("Roll start " + logDirs[index]);                int fileID = nextFileID.incrementAndGet();                File file = new File(logDirs[index], PREFIX + fileID);                LogFile.Writer writer = LogFileFactory.getWriter(file, fileID, maxFileSize, encryptionKey, encryptionKeyAlias, encryptionCipherProvider, usableSpaceRefreshInterval, fsyncPerTransaction, fsyncInterval);                idLogFileMap.put(fileID, LogFileFactory.getRandomReader(file, encryptionKeyProvider, fsyncPerTransaction));                                logFiles.set(index, writer);                                if (oldLogFile != null) {                    oldLogFile.close();                }            } finally {                LOGGER.info("Roll end");            }        }    } finally {        unlockShared();    }}
7d37b69fdbcc5022790f7bad3bcce6db9008826eb9224278538f9f84d29affcd
writeCheckpoint
private boolean writeCheckpoint() throws Exception
{    return writeCheckpoint(false);}
f72da5d79369ed5d171e79054a4a505fb0fe546c5c0da93c39fb5d58ad7e754a
writeCheckpoint
private Boolean writeCheckpoint(Boolean force) throws Exception
{    boolean checkpointCompleted = false;    long usableSpace = checkpointDir.getUsableSpace();    if (usableSpace <= minimumRequiredSpace) {        throw new IOException("Usable space exhausted, only " + usableSpace + " bytes remaining, required " + minimumRequiredSpace + " bytes");    }    lockExclusive();    SortedSet<Integer> logFileRefCountsAll = null;    SortedSet<Integer> logFileRefCountsActive = null;    try {        if (queue.checkpoint(force)) {            long logWriteOrderID = queue.getLogWriteOrderID();                                                                                    logFileRefCountsAll = queue.getFileIDs();            logFileRefCountsActive = new TreeSet<Integer>(logFileRefCountsAll);            int numFiles = logFiles.length();            for (int i = 0; i < numFiles; i++) {                LogFile.Writer logWriter = logFiles.get(i);                int logFileID = logWriter.getLogFileID();                File logFile = logWriter.getFile();                LogFile.MetaDataWriter writer = LogFileFactory.getMetaDataWriter(logFile, logFileID);                try {                    writer.markCheckpoint(logWriter.position(), logWriteOrderID);                } finally {                    writer.close();                }                logFileRefCountsAll.remove(logFileID);                LOGGER.info("Updated checkpoint for file: " + logFile + " position: " + logWriter.position() + " logWriteOrderID: " + logWriteOrderID);            }                        Iterator<Integer> idIterator = logFileRefCountsAll.iterator();            while (idIterator.hasNext()) {                int id = idIterator.next();                LogFile.RandomReader reader = idLogFileMap.remove(id);                File file = reader.getFile();                reader.close();                LogFile.MetaDataWriter writer = LogFileFactory.getMetaDataWriter(file, id);                try {                    writer.markCheckpoint(logWriteOrderID);                } finally {                    reader = LogFileFactory.getRandomReader(file, encryptionKeyProvider, fsyncPerTransaction);                    idLogFileMap.put(id, reader);                    writer.close();                }                LOGGER.debug("Updated checkpoint for file: " + file + "logWriteOrderID " + logWriteOrderID);                idIterator.remove();            }            Preconditions.checkState(logFileRefCountsAll.size() == 0, "Could not update all data file timestamps: " + logFileRefCountsAll);                        for (int index = 0; index < logDirs.length; index++) {                logFileRefCountsActive.add(logFiles.get(index).getLogFileID());            }            checkpointCompleted = true;        }    } finally {        unlockExclusive();    }        if (open && checkpointCompleted) {        removeOldLogs(logFileRefCountsActive);    }        return true;}
6e299c2112a8f9a0c9434ce8c2a8e40720ee9c7c93aed232a0868001487792fc
removeOldLogs
private void removeOldLogs(SortedSet<Integer> fileIDs)
{    Preconditions.checkState(open, "Log is closed");        for (File fileToDelete : pendingDeletes) {        LOGGER.info("Removing old file: " + fileToDelete);        FileUtils.deleteQuietly(fileToDelete);    }    pendingDeletes.clear();            int minFileID = fileIDs.first();    LOGGER.debug("Files currently in use: " + fileIDs);    for (File logDir : logDirs) {        List<File> logs = LogUtils.getLogs(logDir);                LogUtils.sort(logs);                int size = logs.size() - MIN_NUM_LOGS;        for (int index = 0; index < size; index++) {            File logFile = logs.get(index);            int logFileID = LogUtils.getIDForFile(logFile);            if (logFileID < minFileID) {                LogFile.RandomReader reader = idLogFileMap.remove(logFileID);                if (reader != null) {                    reader.close();                }                File metaDataFile = Serialization.getMetaDataFile(logFile);                pendingDeletes.add(logFile);                pendingDeletes.add(metaDataFile);            }        }    }}
377c4733b6410147b3377555b46571e72f7a7b2084933bad52bad268d74ffccf
lock
private void lock(File dir) throws IOException
{    FileLock lock = tryLock(dir);    if (lock == null) {        String msg = "Cannot lock " + dir + ". The directory is already locked. " + channelNameDescriptor;        LOGGER.info(msg);        throw new IOException(msg);    }    FileLock secondLock = tryLock(dir);    if (secondLock != null) {        LOGGER.warn("Directory " + dir + " does not support locking");        secondLock.release();        secondLock.channel().close();    }    locks.put(dir.getAbsolutePath(), lock);}
4fbe40f39cafc4b650840c736edfb952fb79c3313e576bab43680e2645da643f
tryLock
private FileLock tryLock(File dir) throws IOException
{    File lockF = new File(dir, FILE_LOCK);    lockF.deleteOnExit();    RandomAccessFile file = new RandomAccessFile(lockF, "rws");    FileLock res = null;    try {        res = file.getChannel().tryLock();    } catch (OverlappingFileLockException oe) {        file.close();        return null;    } catch (IOException e) {        LOGGER.error("Cannot create lock on " + lockF, e);        file.close();        throw e;    }    return res;}
58ea25c562c53b47dc7aa60b00535a5666968aed1f6f82c8a95a5214151f896e
unlock
private void unlock(File dir) throws IOException
{    FileLock lock = locks.remove(dir.getAbsolutePath());    if (lock == null) {        return;    }    lock.release();    lock.channel().close();    lock = null;}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    try {        if (log.open) {            log.writeCheckpoint();        }    } catch (IOException e) {        log.channelCounter.incrementCheckpointWriteErrorCount();        LOG.error("Error doing checkpoint", e);    } catch (Throwable e) {        log.channelCounter.incrementCheckpointWriteErrorCount();        LOG.error("General error in checkpoint worker", e);    }}
74a922c24123a57f388ccbb6719eacf0caaae466c0c63bed487f1a7053596ba8
skipRecord
protected static void skipRecord(RandomAccessFile fileHandle, int offset) throws IOException
{    fileHandle.seek(offset);    int length = fileHandle.readInt();    fileHandle.skipBytes(length);}
610c91d5cc293b8d98b99f6e6fd902257b6a74c6ae327bfe77c30c40e291c2f3
getFileHandle
protected RandomAccessFile getFileHandle()
{    return writeFileHandle;}
ae8317be6d0153776667e3e7800798991a0a2ab58283e8fa349e9c232a1ed6b1
setLastCheckpointOffset
protected void setLastCheckpointOffset(long lastCheckpointOffset)
{    this.lastCheckpointOffset = lastCheckpointOffset;}
f94271c4cf864ea4664ee46088df8dd08b99bde01acd827b1fce4335f9ba2b0e
setLastCheckpointWriteOrderID
protected void setLastCheckpointWriteOrderID(long lastCheckpointWriteOrderID)
{    this.lastCheckpointWriteOrderID = lastCheckpointWriteOrderID;}
672b0499c3f41c53ab714985743543295dcc7436741bae46c8fa8d4a61ccc257
getLastCheckpointOffset
protected long getLastCheckpointOffset()
{    return lastCheckpointOffset;}
259670b161299c860a66c791b00c424360435de5e81fb1b8fc0dda36b4e39950
getLastCheckpointWriteOrderID
protected long getLastCheckpointWriteOrderID()
{    return lastCheckpointWriteOrderID;}
c5870bee4d8aae0dbb4fc998e5df2359b099b102035ab9cff8a3f563cd53e8af
getFile
protected File getFile()
{    return file;}
37577daae3e6885d20b01a7613dac1b97746b975a1adbb8739af1ac79849f44d
getLogFileID
protected int getLogFileID()
{    return logFileID;}
0b230e00eb0490666bbed0e2c58b21b7fb98d58c1fdaf2b695718ea1279b0b95
markCheckpoint
 void markCheckpoint(long logWriteOrderID) throws IOException
{    markCheckpoint(lastCheckpointOffset, logWriteOrderID);}
c2864e5a4894768906844a2ddb5f229fc8d93aa73ebb06368e7b1ddbe43efd96
close
 void close()
{    try {        writeFileHandle.close();    } catch (IOException e) {        LOG.warn("Unable to close " + file, e);    }}
39f7dc1ee3d831e27ad656f3a16a032aecc3e51888fd303f499b35c2c3eda75b
decrement
 void decrement(long numBytes)
{    Preconditions.checkArgument(numBytes >= 0, "numBytes less than zero");    value.addAndGet(-numBytes);}
3cb3a06782104b3fbf81e675a867cda7b1c3ae6592dce829c85af32fd248e725
getUsableSpace
 long getUsableSpace()
{    long now = System.currentTimeMillis();    if (now - interval > lastRefresh.get()) {        value.set(fs.getUsableSpace());        lastRefresh.set(now);    }    return Math.max(value.get(), 0L);}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    try {        sync();    } catch (Throwable ex) {        LOG.error("Data file, " + getFile().toString() + " could not " + "be synced to disk due to an error.", ex);    }}
90dafa3ab6a64bb059ea7288ac544d28d1f042564c7a47e1f95e710905ac9e34
getEncryptor
protected CipherProvider.Encryptor getEncryptor()
{    return encryptor;}
c173cb7fcc48521404389c0bcac73b77a1333d6f2d59d6d13235a283f977c1ff
getLogFileID
 int getLogFileID()
{    return logFileID;}
355b93a07ac6e04dbb961ee2d515721e0c9cb060fc8d3cf1eb4efb5fabd06a5e
getFile
 File getFile()
{    return file;}
251074404565ec7ba7f161ce223346b839d4cdc86b6336aff188eec654a65b2d
getParent
 String getParent()
{    return file.getParent();}
3cb3a06782104b3fbf81e675a867cda7b1c3ae6592dce829c85af32fd248e725
getUsableSpace
 long getUsableSpace()
{    return usableSpace.getUsableSpace();}
b8eaf4d24382b917b6b47f212d54f544822dc8b704d528461ac21b8cb38a087b
getMaxSize
 long getMaxSize()
{    return maxFileSize;}
f5a066681eee8d50ebca73837d6b873c91610fd3195193a5d6c008aa498560aa
getLastCommitPosition
 long getLastCommitPosition()
{    return lastCommitPosition;}
2cc026742cb2e93239100f04e44fa6800e6cbd3241328b5827c2f751fd9daaee
getLastSyncPosition
 long getLastSyncPosition()
{    return lastSyncPosition;}
f0bc5158cd862ceb52ed5cb4aa1985daa463e703359fa42ba442c1fb2b479589
getSyncCount
 long getSyncCount()
{    return syncCount;}
865d1364634730a099c727c08a7e4a050c534a0150f05413549f4971dd8a341c
position
 synchronized long position() throws IOException
{    return getFileChannel().position();}
8018b16323125017cfcc8b4667ba2016ce1961ec592609fe73645c22d6f275a9
put
 synchronized FlumeEventPointer put(ByteBuffer buffer) throws IOException
{    if (encryptor != null) {        buffer = ByteBuffer.wrap(encryptor.encrypt(buffer.array()));    }    Pair<Integer, Integer> pair = write(buffer);    return new FlumeEventPointer(pair.getLeft(), pair.getRight());}
48d163c862b576149b9b10db07ad1a767ea2055ddff37d35493c7d9ebeeff8ec
take
 synchronized void take(ByteBuffer buffer) throws IOException
{    if (encryptor != null) {        buffer = ByteBuffer.wrap(encryptor.encrypt(buffer.array()));    }    write(buffer);}
1a22fac3a871133efd085d0deb98d5420453985146ebb58b4a6e374223b1c2c9
rollback
 synchronized void rollback(ByteBuffer buffer) throws IOException
{    if (encryptor != null) {        buffer = ByteBuffer.wrap(encryptor.encrypt(buffer.array()));    }    write(buffer);}
ec85e9ab7e6fdf8ddfb1001318f6424b33c6e316637188be7e919cca6dbd7e14
commit
 synchronized void commit(ByteBuffer buffer) throws IOException
{    if (encryptor != null) {        buffer = ByteBuffer.wrap(encryptor.encrypt(buffer.array()));    }    write(buffer);    dirty = true;    lastCommitPosition = position();}
b187d61c3943c4af357306546282ad153480de3705ad578dd6ddad98afd70bf0
write
private Pair<Integer, Integer> write(ByteBuffer buffer) throws IOException
{    if (!isOpen()) {        throw new LogFileRetryableIOException("File closed " + file);    }    long length = position();    long expectedLength = length + (long) buffer.limit();    if (expectedLength > maxFileSize) {        throw new LogFileRetryableIOException(expectedLength + " > " + maxFileSize);    }    int offset = (int) length;    Preconditions.checkState(offset >= 0, String.valueOf(offset));        int recordLength = 1 + (int) Serialization.SIZE_OF_INT + buffer.limit();    usableSpace.decrement(recordLength);    preallocate(recordLength);    ByteBuffer toWrite = ByteBuffer.allocate(recordLength);    toWrite.put(OP_RECORD);    writeDelimitedBuffer(toWrite, buffer);    toWrite.position(0);    int wrote = getFileChannel().write(toWrite);    Preconditions.checkState(wrote == toWrite.limit());    return Pair.of(getLogFileID(), offset);}
27b5d791436b91ea77e05f92d1cd3dcc07bba495863cd0bc7374636329a65a1f
isRollRequired
 synchronized boolean isRollRequired(ByteBuffer buffer) throws IOException
{    return isOpen() && position() + (long) buffer.limit() > getMaxSize();}
48e6b0ec63ecb484de5a78c07772224012b64104e46064c61df0277afd28a7bd
sync
 synchronized void sync() throws IOException
{    if (!fsyncPerTransaction && !dirty) {        if (LOG.isDebugEnabled()) {            LOG.debug("No events written to file, " + getFile().toString() + " in last " + fsyncInterval + " or since last commit.");        }        return;    }    if (!isOpen()) {        throw new LogFileRetryableIOException("File closed " + file);    }    if (lastSyncPosition < lastCommitPosition) {        getFileChannel().force(false);        lastSyncPosition = position();        syncCount++;        dirty = false;    }}
c401d6c020094555819b5cc0e5ea1bf46ae861b2b822b856b3acde530f71d576
isOpen
protected boolean isOpen()
{    return open;}
610c91d5cc293b8d98b99f6e6fd902257b6a74c6ae327bfe77c30c40e291c2f3
getFileHandle
protected RandomAccessFile getFileHandle()
{    return writeFileHandle;}
a7f3c05f57ae219de7dd7d836a77f27d5c16e1318d838ab799c15848ecb85603
getFileChannel
protected FileChannel getFileChannel()
{    return writeFileChannel;}
cf62b3ead696615fc40c1105b82a567582ae57fd2b4a5167144d628577e19dd0
close
 synchronized void close()
{    if (open) {        open = false;        if (!fsyncPerTransaction) {                        if (syncExecutor != null) {                                syncExecutor.shutdown();            }        }        if (writeFileChannel.isOpen()) {            LOG.info("Closing " + file);            try {                writeFileChannel.force(true);            } catch (IOException e) {                LOG.warn("Unable to flush to disk " + file, e);            }            try {                writeFileHandle.close();            } catch (IOException e) {                LOG.warn("Unable to close " + file, e);            }        }    }}
9ebd25be38b64e9068d72d7f721263a0ae6eb512565d644637687b0a9c05b1b2
preallocate
protected void preallocate(int size) throws IOException
{    long position = position();    if (position + size > getFileChannel().size()) {        LOG.debug("Preallocating at position " + position);        synchronized (FILL) {            FILL.position(0);            getFileChannel().write(FILL, position);        }    }}
021d0189e241d1abad5e7126877ec86a51d4208e8edaf6132269abef2632a43e
markRecordAsNoop
public void markRecordAsNoop(long offset) throws IOException
{                    fileHandle.seek(offset);    byte byteRead = fileHandle.readByte();    Preconditions.checkState(byteRead == OP_RECORD || byteRead == OP_NOOP, "Expected to read a record but the byte read indicates EOF");    fileHandle.seek(offset);    LOG.info("Marking event as " + OP_NOOP + " at " + offset + " for file " + file.toString());    fileHandle.writeByte(OP_NOOP);}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{    try {        fileHandle.getFD().sync();        fileHandle.close();    } catch (IOException e) {        LOG.error("Could not close file handle to file " + fileHandle.toString(), e);    }}
355b93a07ac6e04dbb961ee2d515721e0c9cb060fc8d3cf1eb4efb5fabd06a5e
getFile
 File getFile()
{    return file;}
dc42be4e52ac3548812626edfc2a95014985f249b4386a019e91c1d64022a53b
getKeyProvider
protected KeyProvider getKeyProvider()
{    return encryptionKeyProvider;}
b6b78e38576c83a42e74db712a4e2a55a020606cd58a08e325b85f750891bbc1
get
 FlumeEvent get(int offset) throws IOException, InterruptedException, CorruptEventException, NoopRecordException
{    Preconditions.checkState(open, "File closed");    RandomAccessFile fileHandle = checkOut();    boolean error = true;    try {        fileHandle.seek(offset);        byte operation = fileHandle.readByte();        if (operation == OP_NOOP) {            throw new NoopRecordException("No op record found. Corrupt record " + "may have been repaired by File Channel Integrity tool");        }        if (operation != OP_RECORD) {            throw new CorruptEventException("Operation code is invalid. File " + "is corrupt. Please run File Channel Integrity tool.");        }        TransactionEventRecord record = doGet(fileHandle);        if (!(record instanceof Put)) {            Preconditions.checkState(false, "Record is " + record.getClass().getSimpleName());        }        error = false;        return ((Put) record).getEvent();    } finally {        if (error) {            close(fileHandle, file);        } else {            checkIn(fileHandle);        }    }}
cf62b3ead696615fc40c1105b82a567582ae57fd2b4a5167144d628577e19dd0
close
 synchronized void close()
{    if (open) {        open = false;        LOG.info("Closing RandomReader " + file);        List<RandomAccessFile> fileHandles = Lists.newArrayList();        while (readFileHandles.drainTo(fileHandles) > 0) {            for (RandomAccessFile fileHandle : fileHandles) {                synchronized (fileHandle) {                    try {                        fileHandle.close();                    } catch (IOException e) {                        LOG.warn("Unable to close fileHandle for " + file, e);                    }                }            }            fileHandles.clear();            try {                Thread.sleep(5L);            } catch (InterruptedException e) {                        }        }    }}
f860190df9d386d37c142da9984fdb7600c71c471bd35ca3d63ed210a11c2cca
open
private RandomAccessFile open() throws IOException
{    return new RandomAccessFile(file, "r");}
72138630a1088fe86d77820a57abf435ee1b5ff71809e3a4158be64dab861587
checkIn
private void checkIn(RandomAccessFile fileHandle)
{    if (!readFileHandles.offer(fileHandle)) {        close(fileHandle, file);    }}
2824e6ea0067a8c32f282a501d3e57c6aa022d767102303efdce0aa607854877
checkOut
private RandomAccessFile checkOut() throws IOException, InterruptedException
{    RandomAccessFile fileHandle = readFileHandles.poll();    if (fileHandle != null) {        return fileHandle;    }    int remaining = readFileHandles.remainingCapacity();    if (remaining > 0) {        LOG.info("Opening " + file + " for read, remaining number of file " + "handles available for reads of this file is " + remaining);        return open();    }    return readFileHandles.take();}
3802797d2c7554db31035c04c22237087ab25331f9d13e462af81f5dbbf82686
close
private static void close(RandomAccessFile fileHandle, File file)
{    if (fileHandle != null) {        try {            fileHandle.close();        } catch (IOException e) {            LOG.warn("Unable to close " + file, e);        }    }}
093d9872a06a57616961fd91a608bbd9b673aa342f1db2bdb4a4cd4e23e3520b
setLastCheckpointPosition
protected void setLastCheckpointPosition(long lastCheckpointPosition)
{    this.lastCheckpointPosition = lastCheckpointPosition;}
f94271c4cf864ea4664ee46088df8dd08b99bde01acd827b1fce4335f9ba2b0e
setLastCheckpointWriteOrderID
protected void setLastCheckpointWriteOrderID(long lastCheckpointWriteOrderID)
{    this.lastCheckpointWriteOrderID = lastCheckpointWriteOrderID;}
2980a2303c755fd00344d0bedab23262832bdd73763279664fd518b5a6b44902
setPreviousCheckpointPosition
protected void setPreviousCheckpointPosition(long backupCheckpointPosition)
{    this.backupCheckpointPosition = backupCheckpointPosition;}
0860937b9026c51ab55b92fd783ad5a03f06d072c334b1493ea78b4bc6e29dce
setPreviousCheckpointWriteOrderID
protected void setPreviousCheckpointWriteOrderID(long backupCheckpointWriteOrderID)
{    this.backupCheckpointWriteOrderID = backupCheckpointWriteOrderID;}
ad32e1089ec5c5016aff7f9080c35ae3dc341d0f04a63160d34d1fac635eae6c
setLogFileID
protected void setLogFileID(int logFileID)
{    this.logFileID = logFileID;    Preconditions.checkArgument(logFileID >= 0, "LogFileID is not positive: " + Integer.toHexString(logFileID));}
dc42be4e52ac3548812626edfc2a95014985f249b4386a019e91c1d64022a53b
getKeyProvider
protected KeyProvider getKeyProvider()
{    return encryptionKeyProvider;}
610c91d5cc293b8d98b99f6e6fd902257b6a74c6ae327bfe77c30c40e291c2f3
getFileHandle
protected RandomAccessFile getFileHandle()
{    return fileHandle;}
c173cb7fcc48521404389c0bcac73b77a1333d6f2d59d6d13235a283f977c1ff
getLogFileID
 int getLogFileID()
{    return logFileID;}
a6476f13350b412d760577718dbdacca0adfa40ef6a8e8c7e83e50fcb79a5b77
skipToLastCheckpointPosition
 void skipToLastCheckpointPosition(long checkpointWriteOrderID) throws IOException
{    if (lastCheckpointPosition > 0L) {        long position = 0;        if (lastCheckpointWriteOrderID <= checkpointWriteOrderID) {            position = lastCheckpointPosition;        } else if (backupCheckpointWriteOrderID <= checkpointWriteOrderID && backupCheckpointPosition > 0) {            position = backupCheckpointPosition;        }        fileChannel.position(position);        LOG.info("fast-forward to checkpoint position: " + position);    } else {        LOG.info("Checkpoint for file(" + file.getAbsolutePath() + ") " + "is: " + lastCheckpointWriteOrderID + ", which is beyond the " + "requested checkpoint time: " + checkpointWriteOrderID + " and position " + lastCheckpointPosition);    }}
9e2f50f0d709bf7332707c869c5b664cf1c870c758c043b4cda0e7ab135906f6
next
public LogRecord next() throws IOException, CorruptEventException
{    int offset = -1;    try {        long position = fileChannel.position();        if (position > FileChannelConfiguration.DEFAULT_MAX_FILE_SIZE) {            LOG.info("File position exceeds the threshold: " + FileChannelConfiguration.DEFAULT_MAX_FILE_SIZE + ", position: " + position);        }        offset = (int) position;        Preconditions.checkState(offset >= 0);        while (offset < fileHandle.length()) {            byte operation = fileHandle.readByte();            if (operation == OP_RECORD) {                break;            } else if (operation == OP_EOF) {                LOG.info("Encountered EOF at " + offset + " in " + file);                return null;            } else if (operation == OP_NOOP) {                LOG.info("No op event found in file: " + file.toString() + " at " + offset + ". Skipping event.");                skipRecord(fileHandle, offset + 1);                offset = (int) fileHandle.getFilePointer();                continue;            } else {                LOG.error("Encountered non op-record at " + offset + " " + Integer.toHexString(operation) + " in " + file);                return null;            }        }        if (offset >= fileHandle.length()) {            return null;        }        return doNext(offset);    } catch (EOFException e) {        return null;    } catch (IOException e) {        throw new IOException("Unable to read next Transaction from log file " + file.getCanonicalPath() + " at offset " + offset, e);    }}
e33a639e263ff9d83209a851b8c533a766cc4009a53280d4a36c022dc99ce441
getPosition
public long getPosition() throws IOException
{    return fileChannel.position();}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{    if (fileHandle != null) {        try {            fileHandle.close();        } catch (IOException e) {        }    }}
73ee65d6883d2963e26d7adcd2c2c679653ceabdf628b2a8fb4c7385ed0e3271
writeDelimitedBuffer
protected static void writeDelimitedBuffer(ByteBuffer output, ByteBuffer buffer) throws IOException
{    output.putInt(buffer.limit());    output.put(buffer);}
92aeb587f130ff86d0bd4d8444075540d0d0919a595deea9b8d66cf82d4c0893
readDelimitedBuffer
protected static byte[] readDelimitedBuffer(RandomAccessFile fileHandle) throws IOException, CorruptEventException
{    int length = fileHandle.readInt();    if (length < 0) {        throw new CorruptEventException("Length of event is: " + String.valueOf(length) + ". Event must have length >= 0. Possible corruption of data or partial fsync.");    }    byte[] buffer = new byte[length];    try {        fileHandle.readFully(buffer);    } catch (EOFException ex) {        throw new CorruptEventException("Remaining data in file less than " + "expected size of event.", ex);    }    return buffer;}
5af3098f4abf518ba6a3c5148dc1ce2452d8f53f1ea8200da6ee4c15e3af39b2
main
public static void main(String[] args) throws EOFException, IOException, CorruptEventException
{    File file = new File(args[0]);    LogFile.SequentialReader reader = null;    try {        reader = LogFileFactory.getSequentialReader(file, null, false);        LogRecord entry;        FlumeEventPointer ptr;                        int fileId = reader.getLogFileID();        int count = 0;        int readCount = 0;        int putCount = 0;        int takeCount = 0;        int rollbackCount = 0;        int commitCount = 0;        while ((entry = reader.next()) != null) {            int offset = entry.getOffset();            TransactionEventRecord record = entry.getEvent();            short type = record.getRecordType();            long trans = record.getTransactionID();            long ts = record.getLogWriteOrderID();            readCount++;            ptr = null;            if (type == TransactionEventRecord.Type.PUT.get()) {                putCount++;                ptr = new FlumeEventPointer(fileId, offset);            } else if (type == TransactionEventRecord.Type.TAKE.get()) {                takeCount++;                Take take = (Take) record;                ptr = new FlumeEventPointer(take.getFileID(), take.getOffset());            } else if (type == TransactionEventRecord.Type.ROLLBACK.get()) {                rollbackCount++;            } else if (type == TransactionEventRecord.Type.COMMIT.get()) {                commitCount++;            } else {                Preconditions.checkArgument(false, "Unknown record type: " + Integer.toHexString(type));            }            System.out.println(Joiner.on(", ").skipNulls().join(trans, ts, fileId, offset, TransactionEventRecord.getName(type), ptr));        }        System.out.println("Replayed " + count + " from " + file + " read: " + readCount + ", put: " + putCount + ", take: " + takeCount + ", rollback: " + rollbackCount + ", commit: " + commitCount);    } catch (EOFException e) {        System.out.println("Hit EOF on " + file);    } finally {        if (reader != null) {            reader.close();        }    }}
269b5ca0ffe35c9e2147b8f1ac45d62c857b0d63ca3f2a0d3ea5ce89663e5216
getMetaDataWriter
 static LogFile.MetaDataWriter getMetaDataWriter(File file, int logFileID) throws IOException
{    RandomAccessFile logFile = null;    try {        File metaDataFile = Serialization.getMetaDataFile(file);        if (metaDataFile.exists()) {            return new LogFileV3.MetaDataWriter(file, logFileID);        }        logFile = new RandomAccessFile(file, "r");        int version = logFile.readInt();        if (Serialization.VERSION_2 == version) {            return new LogFileV2.MetaDataWriter(file, logFileID);        }        throw new IOException("File " + file + " has bad version " + Integer.toHexString(version));    } finally {        if (logFile != null) {            try {                logFile.close();            } catch (IOException e) {                LOGGER.warn("Unable to close " + file, e);            }        }    }}
9d6da3fb883ff239002e1c1155c92c3782c072e824ef9a803ed48fc5dbf0abbe
getWriter
 static LogFile.Writer getWriter(File file, int logFileID, long maxFileSize, @Nullable Key encryptionKey, @Nullable String encryptionKeyAlias, @Nullable String encryptionCipherProvider, long usableSpaceRefreshInterval, boolean fsyncPerTransaction, int fsyncInterval) throws IOException
{    Preconditions.checkState(!file.exists(), "File already exists " + file.getAbsolutePath());    Preconditions.checkState(file.createNewFile(), "File could not be created " + file.getAbsolutePath());    return new LogFileV3.Writer(file, logFileID, maxFileSize, encryptionKey, encryptionKeyAlias, encryptionCipherProvider, usableSpaceRefreshInterval, fsyncPerTransaction, fsyncInterval);}
3302b8d1d861912c1d8ff2eb80a042b9fd371a171ac81d2c510230867ada1432
getRandomReader
 static LogFile.RandomReader getRandomReader(File file, @Nullable KeyProvider encryptionKeyProvider, boolean fsyncPerTransaction) throws IOException
{    RandomAccessFile logFile = new RandomAccessFile(file, "r");    try {        File metaDataFile = Serialization.getMetaDataFile(file);                if (logFile.length() == 0L || metaDataFile.exists()) {            return new LogFileV3.RandomReader(file, encryptionKeyProvider, fsyncPerTransaction);        }        int version = logFile.readInt();        if (Serialization.VERSION_2 == version) {            return new LogFileV2.RandomReader(file);        }        throw new IOException("File " + file + " has bad version " + Integer.toHexString(version));    } finally {        if (logFile != null) {            try {                logFile.close();            } catch (IOException e) {                LOGGER.warn("Unable to close " + file, e);            }        }    }}
d02827a4339e97fd37193498142a091f1bb1ae3c7b66d7bc12a625016fb6c609
getSequentialReader
 static LogFile.SequentialReader getSequentialReader(File file, @Nullable KeyProvider encryptionKeyProvider, boolean fsyncPerTransaction) throws IOException
{    RandomAccessFile logFile = null;    try {        File metaDataFile = Serialization.getMetaDataFile(file);        File oldMetadataFile = Serialization.getOldMetaDataFile(file);        File tempMetadataFile = Serialization.getMetaDataTempFile(file);        boolean hasMeta = false;                if (metaDataFile.exists()) {            hasMeta = true;        } else if (tempMetadataFile.exists()) {            if (tempMetadataFile.renameTo(metaDataFile)) {                hasMeta = true;            } else {                throw new IOException("Renaming of " + tempMetadataFile.getName() + " to " + metaDataFile.getName() + " failed");            }        } else if (oldMetadataFile.exists()) {            if (oldMetadataFile.renameTo(metaDataFile)) {                hasMeta = true;            } else {                throw new IOException("Renaming of " + oldMetadataFile.getName() + " to " + metaDataFile.getName() + " failed");            }        }        if (hasMeta) {                        if (oldMetadataFile.exists()) {                oldMetadataFile.delete();            }            if (tempMetadataFile.exists()) {                tempMetadataFile.delete();            }            if (metaDataFile.length() == 0L) {                if (file.length() != 0L) {                    String msg = String.format("MetaData file %s is empty, but log %s" + " is of size %d", metaDataFile, file, file.length());                    throw new IllegalStateException(msg);                }                throw new EOFException(String.format("MetaData file %s is empty", metaDataFile));            }            return new LogFileV3.SequentialReader(file, encryptionKeyProvider, fsyncPerTransaction);        }        logFile = new RandomAccessFile(file, "r");        int version = logFile.readInt();        if (Serialization.VERSION_2 == version) {            return new LogFileV2.SequentialReader(file);        }        throw new IOException("File " + file + " has bad version " + Integer.toHexString(version));    } finally {        if (logFile != null) {            try {                logFile.close();            } catch (IOException e) {                LOGGER.warn("Unable to close " + file, e);            }        }    }}
79a966a07ccbcb0b4d9ecf92f24220884c3e0f26014374b2d7a63a7f8c67d9a8
getVersion
 int getVersion()
{    return Serialization.VERSION_2;}
b13df78922410d7527cebc0ac66dc14e5abbdc2d0ad2b45b8457b0e22fe40d9a
markCheckpoint
 void markCheckpoint(long currentPosition, long logWriteOrderID) throws IOException
{    RandomAccessFile writeFileHandle = getFileHandle();    writeFileHandle.seek(OFFSET_CHECKPOINT);    writeFileHandle.writeLong(currentPosition);    writeFileHandle.writeLong(logWriteOrderID);    writeFileHandle.getChannel().force(true);    LOGGER.info("Noted checkpoint for file: " + getFile() + ", id: " + getLogFileID() + ", checkpoint position: " + currentPosition + ", logWriteOrderID: " + logWriteOrderID);}
79a966a07ccbcb0b4d9ecf92f24220884c3e0f26014374b2d7a63a7f8c67d9a8
getVersion
 int getVersion()
{    return Serialization.VERSION_2;}
79a966a07ccbcb0b4d9ecf92f24220884c3e0f26014374b2d7a63a7f8c67d9a8
getVersion
 int getVersion()
{    return Serialization.VERSION_2;}
82a2c10e971a75a3f793bc39b500bf2e036f41494695093f3670f79d7c5746cf
doGet
protected TransactionEventRecord doGet(RandomAccessFile fileHandle) throws IOException
{    return TransactionEventRecord.fromDataInputV2(fileHandle);}
54bc0b349a40e5994cc6b2b7c63b7bdb8eaebafd56321e290c868307cb2a4574
getVersion
public int getVersion()
{    return Serialization.VERSION_2;}
214a87b1fa6946e04ae083c7cd04d2a1f3b04d8dc063549aee65ec2d30853f19
doNext
 LogRecord doNext(int offset) throws IOException
{    TransactionEventRecord event = TransactionEventRecord.fromDataInputV2(getFileHandle());    return new LogRecord(getLogFileID(), offset, event);}
79a966a07ccbcb0b4d9ecf92f24220884c3e0f26014374b2d7a63a7f8c67d9a8
getVersion
 int getVersion()
{    return Serialization.VERSION_3;}
b13df78922410d7527cebc0ac66dc14e5abbdc2d0ad2b45b8457b0e22fe40d9a
markCheckpoint
 void markCheckpoint(long currentPosition, long logWriteOrderID) throws IOException
{    ProtosFactory.LogFileMetaData.Builder metaDataBuilder = ProtosFactory.LogFileMetaData.newBuilder(logFileMetaData);    metaDataBuilder.setCheckpointPosition(currentPosition);    metaDataBuilder.setCheckpointWriteOrderID(logWriteOrderID);    /*       * Set the previous checkpoint position and write order id so that it       * would be possible to recover from a backup.       */    metaDataBuilder.setBackupCheckpointPosition(logFileMetaData.getCheckpointPosition());    metaDataBuilder.setBackupCheckpointWriteOrderID(logFileMetaData.getCheckpointWriteOrderID());    logFileMetaData = metaDataBuilder.build();    writeDelimitedTo(logFileMetaData, metaDataFile);}
14c702d5ed8bd89cd0840d2849be41e67a73b00c346f996839f90c8c3f4d3aaa
read
 ProtosFactory.LogFileMetaData read() throws IOException
{    FileInputStream inputStream = new FileInputStream(metaDataFile);    try {        ProtosFactory.LogFileMetaData metaData = Preconditions.checkNotNull(ProtosFactory.LogFileMetaData.parseDelimitedFrom(inputStream), "Metadata cannot be null");        if (metaData.getLogFileID() != logFileID) {            throw new IOException("The file id of log file: " + logFile + " is different from expected " + " id: expected = " + logFileID + ", found = " + metaData.getLogFileID());        }        return metaData;    } finally {        try {            inputStream.close();        } catch (IOException e) {            LOGGER.warn("Unable to close " + metaDataFile, e);        }    }}
b748736aaa335b20940c131798b9967af5e4e262e76c352344e880fd9a29afe2
writeDelimitedTo
public static void writeDelimitedTo(GeneratedMessage msg, File file) throws IOException
{    File tmp = Serialization.getMetaDataTempFile(file);    FileOutputStream outputStream = new FileOutputStream(tmp);    boolean closed = false;    try {        msg.writeDelimitedTo(outputStream);        outputStream.getChannel().force(true);        outputStream.close();        closed = true;        if (!tmp.renameTo(file)) {                                                                        File oldFile = Serialization.getOldMetaDataFile(file);            if (!file.renameTo(oldFile)) {                throw new IOException("Unable to rename " + file + " to " + oldFile);            }            if (!tmp.renameTo(file)) {                throw new IOException("Unable to rename " + tmp + " over " + file);            }            oldFile.delete();        }    } finally {        if (!closed) {            try {                outputStream.close();            } catch (IOException e) {                LOGGER.warn("Unable to close " + tmp, e);            }        }    }}
79a966a07ccbcb0b4d9ecf92f24220884c3e0f26014374b2d7a63a7f8c67d9a8
getVersion
 int getVersion()
{    return Serialization.VERSION_3;}
878ec3bf8d4ea4d1be225314287d1ae975a213eac901d6224d92a82addef1da9
initialize
private void initialize() throws IOException
{    File metaDataFile = Serialization.getMetaDataFile(getFile());    FileInputStream inputStream = new FileInputStream(metaDataFile);    try {        ProtosFactory.LogFileMetaData metaData = Preconditions.checkNotNull(ProtosFactory.LogFileMetaData.parseDelimitedFrom(inputStream), "MetaData cannot be null");        int version = metaData.getVersion();        if (version != getVersion()) {            throw new IOException("Version is " + Integer.toHexString(version) + " expected " + Integer.toHexString(getVersion()) + " file: " + getFile().getCanonicalPath());        }        encryptionEnabled = false;        if (metaData.hasEncryption()) {            if (getKeyProvider() == null) {                throw new IllegalStateException("Data file is encrypted but no " + " provider was specified");            }            ProtosFactory.LogFileEncryption encryption = metaData.getEncryption();            key = getKeyProvider().getKey(encryption.getKeyAlias());            cipherProvider = encryption.getCipherProvider();            parameters = encryption.getParameters().toByteArray();            encryptionEnabled = true;        }    } finally {        try {            inputStream.close();        } catch (IOException e) {            LOGGER.warn("Unable to close " + metaDataFile, e);        }    }}
eebb343e6bc323fb691c31de08e92e69b0b97c19e117861b5117eaeb40b561dd
getDecryptor
private CipherProvider.Decryptor getDecryptor()
{    CipherProvider.Decryptor decryptor = decryptors.poll();    if (decryptor == null) {        decryptor = CipherProviderFactory.getDecrypter(cipherProvider, key, parameters);    }    return decryptor;}
79a966a07ccbcb0b4d9ecf92f24220884c3e0f26014374b2d7a63a7f8c67d9a8
getVersion
 int getVersion()
{    return Serialization.VERSION_3;}
a2cc2c27792efa48fd7fbf732d19c3bfb3bdf55ca9186a429e93beec909b408e
doGet
protected TransactionEventRecord doGet(RandomAccessFile fileHandle) throws IOException, CorruptEventException
{        synchronized (this) {        if (!initialized) {            initialized = true;            initialize();        }    }    boolean success = false;    CipherProvider.Decryptor decryptor = null;    try {        byte[] buffer = readDelimitedBuffer(fileHandle);        if (encryptionEnabled) {            decryptor = getDecryptor();            buffer = decryptor.decrypt(buffer);        }        TransactionEventRecord event = TransactionEventRecord.fromByteArray(buffer);        success = true;        return event;    } catch (DecryptionFailureException ex) {        throw new CorruptEventException("Error decrypting event", ex);    } finally {        if (success && encryptionEnabled && decryptor != null) {            decryptors.offer(decryptor);        }    }}
54bc0b349a40e5994cc6b2b7c63b7bdb8eaebafd56321e290c868307cb2a4574
getVersion
public int getVersion()
{    return Serialization.VERSION_3;}
1dbd7e78c25174aaf132b3b55f337e85b1b18ba5a31f8de6d7cf88694e282274
doNext
 LogRecord doNext(int offset) throws IOException, CorruptEventException, DecryptionFailureException
{    byte[] buffer = null;    TransactionEventRecord event = null;    try {        buffer = readDelimitedBuffer(getFileHandle());        if (decryptor != null) {            buffer = decryptor.decrypt(buffer);        }        event = TransactionEventRecord.fromByteArray(buffer);    } catch (CorruptEventException ex) {        LOGGER.warn("Corrupt file found. File id: log-" + this.getLogFileID(), ex);                if (!fsyncPerTransaction) {            return null;        }        throw ex;    } catch (DecryptionFailureException ex) {        if (!fsyncPerTransaction) {            LOGGER.warn("Could not decrypt even read from channel. Skipping " + "event.", ex);            return null;        }        throw ex;    }    return new LogRecord(getLogFileID(), offset, event);}
360b2bfc246ce54778e6115e7d10cad4b1d433142ab79c8d8fab437091e0ec14
getFileID
public int getFileID()
{    return fileID;}
d50e038b298d330cb813a0c139773f71a1aa72016b2df3558e55bbec788582ff
getOffset
public int getOffset()
{    return offset;}
de27c4fc648019abc1ae0374cea8dc84792b64030d53fe8888558f88396617a2
getEvent
public TransactionEventRecord getEvent()
{    return event;}
af2efcbfa819784ca7e853511c86772c67bacbfdb2b8bab0e9a4064f7632f34b
compareTo
public int compareTo(LogRecord o)
{    int result = new Long(event.getLogWriteOrderID()).compareTo(o.getEvent().getLogWriteOrderID());    if (result == 0) {                        result = new Long(event.getTransactionID()).compareTo(o.getEvent().getTransactionID());        if (result == 0) {                                    Integer thisIndex = Arrays.binarySearch(replaySortOrder, event.getRecordType());            Integer thatIndex = Arrays.binarySearch(replaySortOrder, o.getEvent().getRecordType());            return thisIndex.compareTo(thatIndex);        }    }    return result;}
b2331433219d4cf279350c25e0375f986b29b36b2c471cf4554992fd3a1a66f6
sort
 static void sort(List<File> logs)
{    Collections.sort(logs, new Comparator<File>() {        @Override        public int compare(File file1, File file2) {            int id1 = getIDForFile(file1);            int id2 = getIDForFile(file2);            if (id1 > id2) {                return 1;            } else if (id1 == id2) {                return 0;            }            return -1;        }    });}
591386bbb9fbc4cdb93cb0ab11177f474dc728b0795db2809af8ad1094030a7b
compare
public int compare(File file1, File file2)
{    int id1 = getIDForFile(file1);    int id2 = getIDForFile(file2);    if (id1 > id2) {        return 1;    } else if (id1 == id2) {        return 0;    }    return -1;}
ae1ba638d8c263d00869c7be576786a9388db6daf172a755529f508d69658031
getIDForFile
 static int getIDForFile(File file)
{    return Integer.parseInt(file.getName().substring(Log.PREFIX.length()));}
5222f3644098ccbcef8a263bc4fd5d0e3bdf58b2e52126dd96368bd79d4ca58e
getLogs
 static List<File> getLogs(File logDir)
{    List<File> result = Lists.newArrayList();    File[] files = logDir.listFiles();    if (files == null) {        String msg = logDir + ".listFiles() returned null: ";        msg += "File = " + logDir.isFile() + ", ";        msg += "Exists = " + logDir.exists() + ", ";        msg += "Writable = " + logDir.canWrite();        throw new IllegalStateException(msg);    }    for (File file : files) {        String name = file.getName();        if (pattern.matcher(name).matches()) {            result.add(file);        }    }    return result;}
d0661002e192af7f93f35e8b74bf51d06a2346b1224bff77a983858eaaad4d5a
getLeft
 L getLeft()
{    return left;}
355173efc534bbab05524df3dd680cb1639840a1c805bd125f2fbc0b051d8e8a
getRight
 R getRight()
{    return right;}
a4aa1f98d40fbb26c558cf9f541b11a3cf5452cd58e5c0f1243777e89886ec59
of
 static Pair<L, R> of(L left, R right)
{    return new Pair<L, R>(left, right);}
199638b55b1fbb07d5c574aad10c10032254dd9ba4d60c3c1be16c0cf27b69a8
registerAllExtensions
public static void registerAllExtensions(com.google.protobuf.ExtensionRegistry registry)
{}
616b7f115532cd18f7777c088f7c87644f932b181a6968944619af3cec72310b
getDefaultInstance
public static Checkpoint getDefaultInstance()
{    return defaultInstance;}
823d600e5f99219f48a5e9630c1d13c6d36545d74b528c76e897ae587c86cb1e
getDefaultInstanceForType
public Checkpoint getDefaultInstanceForType()
{    return defaultInstance;}
afeb2882aee0a13dc444e9d430b86a6dc175c48ee917722e2d5ab50801b7ab38
getUnknownFields
public final com.google.protobuf.UnknownFieldSet getUnknownFields()
{    return this.unknownFields;}
e061a4269a7822f30b36dfe5c448257acd508bbe5bfe85e23841ca998b986e73
getDescriptor
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Checkpoint_descriptor;}
14146f9740b0a47326835ccc62490511ca2c1acd8a7ad735c50f15b98d8aa156
internalGetFieldAccessorTable
protected com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Checkpoint_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint.class, org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint.Builder.class);}
196d84e713e659a83a492fe498d2768a5421617da0ae81a026c8b97fd67e2c75
parsePartialFrom
public Checkpoint parsePartialFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return new Checkpoint(input, extensionRegistry);}
d4bcf4fc515c7f2d23d0cc66807b3357b550670c056632a2229d9974d5cfb340
getParserForType
public com.google.protobuf.Parser<Checkpoint> getParserForType()
{    return PARSER;}
7d59dce09306b81b0dfd081c0e225800c0c7af165a630435fc7af24e4cf390ff
hasVersion
public boolean hasVersion()
{    return ((bitField0_ & 0x00000001) == 0x00000001);}
54bc0b349a40e5994cc6b2b7c63b7bdb8eaebafd56321e290c868307cb2a4574
getVersion
public int getVersion()
{    return version_;}
666ebf72ef9522ec373bacef4fec39f5ed7488bd91fe541a94edbb3e4a724dfa
hasWriteOrderID
public boolean hasWriteOrderID()
{    return ((bitField0_ & 0x00000002) == 0x00000002);}
65bbe4b4f5e1caf2299d87699fa774a6e959dcca7e06f38d7c26ff5c8e868db5
getWriteOrderID
public long getWriteOrderID()
{    return writeOrderID_;}
1b181f62a7b67aa52195f7180ce299e06f755e2c896317cdcfbd2bf697bf0053
hasQueueSize
public boolean hasQueueSize()
{    return ((bitField0_ & 0x00000004) == 0x00000004);}
7ec185e280bd1f09f678c9a882962cce8017cf7334e4dd7e0f75abaecb12ef9c
getQueueSize
public int getQueueSize()
{    return queueSize_;}
57d2cffb86bde8139238184d09793efb9d8d8f0d917a7d8d5412f1212187b0da
hasQueueHead
public boolean hasQueueHead()
{    return ((bitField0_ & 0x00000008) == 0x00000008);}
d6b1ed5f021fa898cc7833652cc9d1e79123873d459bfacf8e4b2192d1fee062
getQueueHead
public int getQueueHead()
{    return queueHead_;}
32ccde0dad61ad6337340297878d85dc39622d6bae5ac4f4377934e9d4f443b1
getActiveLogsList
public java.util.List<org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog> getActiveLogsList()
{    return activeLogs_;}
2b8bde994481fafd237cc4829f70fc689a75a2b32284ba22dc12b6683f00e96a
getActiveLogsOrBuilderList
public java.util.List<? extends org.apache.flume.channel.file.proto.ProtosFactory.ActiveLogOrBuilder> getActiveLogsOrBuilderList()
{    return activeLogs_;}
d6261971982365bfcd22ddde20c80b95cc76698d3ffb27ab4790aff9e2429b33
getActiveLogsCount
public int getActiveLogsCount()
{    return activeLogs_.size();}
60f23c7c5337efc64973a904b7b66bbb9a2d1b460dfc816ffd807053e8dc7638
getActiveLogs
public org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog getActiveLogs(int index)
{    return activeLogs_.get(index);}
68915530de69a99a840b39c6f1e91e950f98cd44905733583c8e27081a7a4c7f
getActiveLogsOrBuilder
public org.apache.flume.channel.file.proto.ProtosFactory.ActiveLogOrBuilder getActiveLogsOrBuilder(int index)
{    return activeLogs_.get(index);}
3eb5746a869e932254ccd9230e2597001e979870dcff9439accc4b8a5e5b6007
initFields
private void initFields()
{    version_ = 0;    writeOrderID_ = 0L;    queueSize_ = 0;    queueHead_ = 0;    activeLogs_ = java.util.Collections.emptyList();}
dde7cd718eaa61cad29906454acf122daba6680a2db55e4787a359a08951b5e7
isInitialized
public final boolean isInitialized()
{    byte isInitialized = memoizedIsInitialized;    if (isInitialized != -1)        return isInitialized == 1;    if (!hasVersion()) {        memoizedIsInitialized = 0;        return false;    }    if (!hasWriteOrderID()) {        memoizedIsInitialized = 0;        return false;    }    if (!hasQueueSize()) {        memoizedIsInitialized = 0;        return false;    }    if (!hasQueueHead()) {        memoizedIsInitialized = 0;        return false;    }    for (int i = 0; i < getActiveLogsCount(); i++) {        if (!getActiveLogs(i).isInitialized()) {            memoizedIsInitialized = 0;            return false;        }    }    memoizedIsInitialized = 1;    return true;}
b78da5ac0d0f56440a60e0c8711e74775e8d0aafe7882e5346a5dcc6fa783f73
writeTo
public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException
{    getSerializedSize();    if (((bitField0_ & 0x00000001) == 0x00000001)) {        output.writeSFixed32(1, version_);    }    if (((bitField0_ & 0x00000002) == 0x00000002)) {        output.writeSFixed64(2, writeOrderID_);    }    if (((bitField0_ & 0x00000004) == 0x00000004)) {        output.writeSFixed32(3, queueSize_);    }    if (((bitField0_ & 0x00000008) == 0x00000008)) {        output.writeSFixed32(4, queueHead_);    }    for (int i = 0; i < activeLogs_.size(); i++) {        output.writeMessage(5, activeLogs_.get(i));    }    getUnknownFields().writeTo(output);}
2bd67191ad73644076f3a74f7b306983cf9bd449d2e535f9b7f802bd0492f9f1
getSerializedSize
public int getSerializedSize()
{    int size = memoizedSerializedSize;    if (size != -1)        return size;    size = 0;    if (((bitField0_ & 0x00000001) == 0x00000001)) {        size += com.google.protobuf.CodedOutputStream.computeSFixed32Size(1, version_);    }    if (((bitField0_ & 0x00000002) == 0x00000002)) {        size += com.google.protobuf.CodedOutputStream.computeSFixed64Size(2, writeOrderID_);    }    if (((bitField0_ & 0x00000004) == 0x00000004)) {        size += com.google.protobuf.CodedOutputStream.computeSFixed32Size(3, queueSize_);    }    if (((bitField0_ & 0x00000008) == 0x00000008)) {        size += com.google.protobuf.CodedOutputStream.computeSFixed32Size(4, queueHead_);    }    for (int i = 0; i < activeLogs_.size(); i++) {        size += com.google.protobuf.CodedOutputStream.computeMessageSize(5, activeLogs_.get(i));    }    size += getUnknownFields().getSerializedSize();    memoizedSerializedSize = size;    return size;}
969c11f748ec8e7ea2d7ab9b282e6a50da757a9197e9f5c9c8a8c921b705557f
writeReplace
protected java.lang.Object writeReplace() throws java.io.ObjectStreamException
{    return super.writeReplace();}
84fb49f39f2f204399e94405e38e4425b584dd5312525ddf45ae301221893be0
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint parseFrom(com.google.protobuf.ByteString data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
42615a1fc17458cad7902885549f302c2e28cd75d13793adb77bf3c0ea6c80ef
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint parseFrom(com.google.protobuf.ByteString data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
cc0ded40c8c740a3eafc72c537d6dd97ebdab25b3710955e49fee1aa352e6799
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint parseFrom(byte[] data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
3b0e11e7aef7329c80b28d6a751726cb0d92a518d7befa2c5b9f3bef346f2c7e
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint parseFrom(byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
80ddd58a38fb72c6f319c30e768a3f416f3331096e2d8ac293f95f9d1af517f9
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint parseFrom(java.io.InputStream input) throws java.io.IOException
{    return PARSER.parseFrom(input);}
60ff62a2c49f8ff142aeddbdd06c01c077d0b46181dd59a67e272d61094bf1d0
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint parseFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseFrom(input, extensionRegistry);}
fa4bbe15ee228c4900a98d4a10d4c5ab840ccb2148818927006586a2ee6d6a88
parseDelimitedFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint parseDelimitedFrom(java.io.InputStream input) throws java.io.IOException
{    return PARSER.parseDelimitedFrom(input);}
cd5e73429b7696d526d494197d145f4efa7100fc021b3b446697c392bc0030aa
parseDelimitedFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint parseDelimitedFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseDelimitedFrom(input, extensionRegistry);}
a861d81e319292707096a79a3837442e01b93bef10940e143eb6e94f9bd5e9cd
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint parseFrom(com.google.protobuf.CodedInputStream input) throws java.io.IOException
{    return PARSER.parseFrom(input);}
e37dc1aa005d76159cefc73e3c201da3a3682dd7e41f52fb6d1e22e3aba2f69e
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint parseFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseFrom(input, extensionRegistry);}
e32f866eb7533a232fadc4ef42bb022716435f415dc4a0f7ed4fff845f45ead0
newBuilder
public static Builder newBuilder()
{    return Builder.create();}
a2589243249ba32b92e98298a2511019cd74b21c911d510f075da5ff7e8b6399
newBuilderForType
public Builder newBuilderForType()
{    return newBuilder();}
20d06b4248b6967b3ed5813067be47d396116e0892782aac58caffaf6c565269
newBuilder
public static Builder newBuilder(org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint prototype)
{    return newBuilder().mergeFrom(prototype);}
8f9c3ced03d87377003831ec6560ea40c4b718fc762fc1ca14b030b0ed8256d4
toBuilder
public Builder toBuilder()
{    return newBuilder(this);}
2a4c0cac516d5bc4a1109ad4c836ca7b20e2bab822eb3f5bbb7c506c60fb0415
newBuilderForType
protected Builder newBuilderForType(com.google.protobuf.GeneratedMessage.BuilderParent parent)
{    Builder builder = new Builder(parent);    return builder;}
e061a4269a7822f30b36dfe5c448257acd508bbe5bfe85e23841ca998b986e73
getDescriptor
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Checkpoint_descriptor;}
14146f9740b0a47326835ccc62490511ca2c1acd8a7ad735c50f15b98d8aa156
internalGetFieldAccessorTable
protected com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Checkpoint_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint.class, org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint.Builder.class);}
7c751d7a2accff7e718ee1e6ea5d2457fe6e182e8c39098e52a8848f56cf2cfe
maybeForceBuilderInitialization
private void maybeForceBuilderInitialization()
{    if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {        getActiveLogsFieldBuilder();    }}
db452528a8bc9d155fa120bbe8533aa1eebe58fe8bf85ab33cdc1987e2489b8f
create
private static Builder create()
{    return new Builder();}
7930c451f279d9927ff235e4ac064561e1505f9b7ae117d9f681b345534ff9e3
clear
public Builder clear()
{    super.clear();    version_ = 0;    bitField0_ = (bitField0_ & ~0x00000001);    writeOrderID_ = 0L;    bitField0_ = (bitField0_ & ~0x00000002);    queueSize_ = 0;    bitField0_ = (bitField0_ & ~0x00000004);    queueHead_ = 0;    bitField0_ = (bitField0_ & ~0x00000008);    if (activeLogsBuilder_ == null) {        activeLogs_ = java.util.Collections.emptyList();        bitField0_ = (bitField0_ & ~0x00000010);    } else {        activeLogsBuilder_.clear();    }    return this;}
845fff95a97cf125489126ddee47248563aa80a59ed327d7d1c7cb9d90dcec30
clone
public Builder clone()
{    return create().mergeFrom(buildPartial());}
5a2efdcbff6cd8f893a197208cee010e41df6afb0e928da5d7126d953902ee30
getDescriptorForType
public com.google.protobuf.Descriptors.Descriptor getDescriptorForType()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Checkpoint_descriptor;}
5970d4ebe701e764dd4429bb3cda3aab5fabe1a2f47d8c3eaa65e6d38f00acfa
getDefaultInstanceForType
public org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint getDefaultInstanceForType()
{    return org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint.getDefaultInstance();}
af7973d10fcf943edf07248a3ba3dec6df509f0d510e7b0a7d92ad9971ab7e2d
build
public org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint build()
{    org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint result = buildPartial();    if (!result.isInitialized()) {        throw newUninitializedMessageException(result);    }    return result;}
4b15d6dbb1f7cbab37e5f4931cdd797849ba75eb137f15bf787115ec20b66eb8
buildPartial
public org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint buildPartial()
{    org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint result = new org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint(this);    int from_bitField0_ = bitField0_;    int to_bitField0_ = 0;    if (((from_bitField0_ & 0x00000001) == 0x00000001)) {        to_bitField0_ |= 0x00000001;    }    result.version_ = version_;    if (((from_bitField0_ & 0x00000002) == 0x00000002)) {        to_bitField0_ |= 0x00000002;    }    result.writeOrderID_ = writeOrderID_;    if (((from_bitField0_ & 0x00000004) == 0x00000004)) {        to_bitField0_ |= 0x00000004;    }    result.queueSize_ = queueSize_;    if (((from_bitField0_ & 0x00000008) == 0x00000008)) {        to_bitField0_ |= 0x00000008;    }    result.queueHead_ = queueHead_;    if (activeLogsBuilder_ == null) {        if (((bitField0_ & 0x00000010) == 0x00000010)) {            activeLogs_ = java.util.Collections.unmodifiableList(activeLogs_);            bitField0_ = (bitField0_ & ~0x00000010);        }        result.activeLogs_ = activeLogs_;    } else {        result.activeLogs_ = activeLogsBuilder_.build();    }    result.bitField0_ = to_bitField0_;    onBuilt();    return result;}
9c02b14012758934fbc876f583b7201b524cfd4dce350a6fd2cdeea1bb86b6f9
mergeFrom
public Builder mergeFrom(com.google.protobuf.Message other)
{    if (other instanceof org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint) {        return mergeFrom((org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint) other);    } else {        super.mergeFrom(other);        return this;    }}
cf5b11c73c8b945e6fe22c0361a4e3a3349ef89532d68e4db95fd77c88c87f2b
mergeFrom
public Builder mergeFrom(org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint other)
{    if (other == org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint.getDefaultInstance())        return this;    if (other.hasVersion()) {        setVersion(other.getVersion());    }    if (other.hasWriteOrderID()) {        setWriteOrderID(other.getWriteOrderID());    }    if (other.hasQueueSize()) {        setQueueSize(other.getQueueSize());    }    if (other.hasQueueHead()) {        setQueueHead(other.getQueueHead());    }    if (activeLogsBuilder_ == null) {        if (!other.activeLogs_.isEmpty()) {            if (activeLogs_.isEmpty()) {                activeLogs_ = other.activeLogs_;                bitField0_ = (bitField0_ & ~0x00000010);            } else {                ensureActiveLogsIsMutable();                activeLogs_.addAll(other.activeLogs_);            }            onChanged();        }    } else {        if (!other.activeLogs_.isEmpty()) {            if (activeLogsBuilder_.isEmpty()) {                activeLogsBuilder_.dispose();                activeLogsBuilder_ = null;                activeLogs_ = other.activeLogs_;                bitField0_ = (bitField0_ & ~0x00000010);                activeLogsBuilder_ = com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ? getActiveLogsFieldBuilder() : null;            } else {                activeLogsBuilder_.addAllMessages(other.activeLogs_);            }        }    }    this.mergeUnknownFields(other.getUnknownFields());    return this;}
dde7cd718eaa61cad29906454acf122daba6680a2db55e4787a359a08951b5e7
isInitialized
public final boolean isInitialized()
{    if (!hasVersion()) {        return false;    }    if (!hasWriteOrderID()) {        return false;    }    if (!hasQueueSize()) {        return false;    }    if (!hasQueueHead()) {        return false;    }    for (int i = 0; i < getActiveLogsCount(); i++) {        if (!getActiveLogs(i).isInitialized()) {            return false;        }    }    return true;}
576f0ac95d3431feb1ba705ec8f537aa5e5a58300021599ce7c111ed9b61d887
mergeFrom
public Builder mergeFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint parsedMessage = null;    try {        parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);    } catch (com.google.protobuf.InvalidProtocolBufferException e) {        parsedMessage = (org.apache.flume.channel.file.proto.ProtosFactory.Checkpoint) e.getUnfinishedMessage();        throw e;    } finally {        if (parsedMessage != null) {            mergeFrom(parsedMessage);        }    }    return this;}
7d59dce09306b81b0dfd081c0e225800c0c7af165a630435fc7af24e4cf390ff
hasVersion
public boolean hasVersion()
{    return ((bitField0_ & 0x00000001) == 0x00000001);}
54bc0b349a40e5994cc6b2b7c63b7bdb8eaebafd56321e290c868307cb2a4574
getVersion
public int getVersion()
{    return version_;}
9dd33050be56688653b9f4ab470d891970d7ac93da62ce7bb4e1cfcdbd354961
setVersion
public Builder setVersion(int value)
{    bitField0_ |= 0x00000001;    version_ = value;    onChanged();    return this;}
783a8c6c2d64f24a8f1e45eff356873b618a2782a7ff4802b6ee3ae49121243f
clearVersion
public Builder clearVersion()
{    bitField0_ = (bitField0_ & ~0x00000001);    version_ = 0;    onChanged();    return this;}
666ebf72ef9522ec373bacef4fec39f5ed7488bd91fe541a94edbb3e4a724dfa
hasWriteOrderID
public boolean hasWriteOrderID()
{    return ((bitField0_ & 0x00000002) == 0x00000002);}
65bbe4b4f5e1caf2299d87699fa774a6e959dcca7e06f38d7c26ff5c8e868db5
getWriteOrderID
public long getWriteOrderID()
{    return writeOrderID_;}
6129623f36f3348ae2a0d4fbb222328d51c7621d30dd86914fbaaed042afb1ec
setWriteOrderID
public Builder setWriteOrderID(long value)
{    bitField0_ |= 0x00000002;    writeOrderID_ = value;    onChanged();    return this;}
88a3be5748ebf09087d1b25cf8681be82200e0ca88acbb46c576ec509f14c684
clearWriteOrderID
public Builder clearWriteOrderID()
{    bitField0_ = (bitField0_ & ~0x00000002);    writeOrderID_ = 0L;    onChanged();    return this;}
1b181f62a7b67aa52195f7180ce299e06f755e2c896317cdcfbd2bf697bf0053
hasQueueSize
public boolean hasQueueSize()
{    return ((bitField0_ & 0x00000004) == 0x00000004);}
7ec185e280bd1f09f678c9a882962cce8017cf7334e4dd7e0f75abaecb12ef9c
getQueueSize
public int getQueueSize()
{    return queueSize_;}
80a63d2bb7d744c0d2f983f06416ee44b9ac505114a67187dbd48e9a58edff52
setQueueSize
public Builder setQueueSize(int value)
{    bitField0_ |= 0x00000004;    queueSize_ = value;    onChanged();    return this;}
cc82372a33940b861e83ec12b2973de31308f651363ab401297cfba538159138
clearQueueSize
public Builder clearQueueSize()
{    bitField0_ = (bitField0_ & ~0x00000004);    queueSize_ = 0;    onChanged();    return this;}
57d2cffb86bde8139238184d09793efb9d8d8f0d917a7d8d5412f1212187b0da
hasQueueHead
public boolean hasQueueHead()
{    return ((bitField0_ & 0x00000008) == 0x00000008);}
d6b1ed5f021fa898cc7833652cc9d1e79123873d459bfacf8e4b2192d1fee062
getQueueHead
public int getQueueHead()
{    return queueHead_;}
75bd539ee722f65862cecd187fe8745cfcc46c2ecd0c9b4c65c73bbaf46bb63b
setQueueHead
public Builder setQueueHead(int value)
{    bitField0_ |= 0x00000008;    queueHead_ = value;    onChanged();    return this;}
ddec6388cc07fb3678f67c92edd18686a8867f7fe1f3ec7536c902e3c47cb9e1
clearQueueHead
public Builder clearQueueHead()
{    bitField0_ = (bitField0_ & ~0x00000008);    queueHead_ = 0;    onChanged();    return this;}
e7dbe9091eb01eefd9fb19e95cad12a6afba3fd093890c36cf2a0c1c5806a819
ensureActiveLogsIsMutable
private void ensureActiveLogsIsMutable()
{    if (!((bitField0_ & 0x00000010) == 0x00000010)) {        activeLogs_ = new java.util.ArrayList<org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog>(activeLogs_);        bitField0_ |= 0x00000010;    }}
32ccde0dad61ad6337340297878d85dc39622d6bae5ac4f4377934e9d4f443b1
getActiveLogsList
public java.util.List<org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog> getActiveLogsList()
{    if (activeLogsBuilder_ == null) {        return java.util.Collections.unmodifiableList(activeLogs_);    } else {        return activeLogsBuilder_.getMessageList();    }}
d6261971982365bfcd22ddde20c80b95cc76698d3ffb27ab4790aff9e2429b33
getActiveLogsCount
public int getActiveLogsCount()
{    if (activeLogsBuilder_ == null) {        return activeLogs_.size();    } else {        return activeLogsBuilder_.getCount();    }}
60f23c7c5337efc64973a904b7b66bbb9a2d1b460dfc816ffd807053e8dc7638
getActiveLogs
public org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog getActiveLogs(int index)
{    if (activeLogsBuilder_ == null) {        return activeLogs_.get(index);    } else {        return activeLogsBuilder_.getMessage(index);    }}
e3e593dfdd1943868bece78d38472938d78a6175c66ff2dcab4f74544d3d82b7
setActiveLogs
public Builder setActiveLogs(int index, org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog value)
{    if (activeLogsBuilder_ == null) {        if (value == null) {            throw new NullPointerException();        }        ensureActiveLogsIsMutable();        activeLogs_.set(index, value);        onChanged();    } else {        activeLogsBuilder_.setMessage(index, value);    }    return this;}
e62f0f667f0bd9323cdb98810925d2f99fb150fa4cfc3b91883d977ec2df1f85
setActiveLogs
public Builder setActiveLogs(int index, org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog.Builder builderForValue)
{    if (activeLogsBuilder_ == null) {        ensureActiveLogsIsMutable();        activeLogs_.set(index, builderForValue.build());        onChanged();    } else {        activeLogsBuilder_.setMessage(index, builderForValue.build());    }    return this;}
76fc7557a8b3ccccfb2b004fec2b367ac888eb572b0cdbf799322effc2b1fbb8
addActiveLogs
public Builder addActiveLogs(org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog value)
{    if (activeLogsBuilder_ == null) {        if (value == null) {            throw new NullPointerException();        }        ensureActiveLogsIsMutable();        activeLogs_.add(value);        onChanged();    } else {        activeLogsBuilder_.addMessage(value);    }    return this;}
4c60fd53a31ef355123aa8762a099afe9bcf1dbf8313cd527f9f85369a47ff64
addActiveLogs
public Builder addActiveLogs(int index, org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog value)
{    if (activeLogsBuilder_ == null) {        if (value == null) {            throw new NullPointerException();        }        ensureActiveLogsIsMutable();        activeLogs_.add(index, value);        onChanged();    } else {        activeLogsBuilder_.addMessage(index, value);    }    return this;}
a97dd4ccc6dbdce5f9847518a1881decf794d64bd9e0bbc38802f5cbbcc27817
addActiveLogs
public Builder addActiveLogs(org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog.Builder builderForValue)
{    if (activeLogsBuilder_ == null) {        ensureActiveLogsIsMutable();        activeLogs_.add(builderForValue.build());        onChanged();    } else {        activeLogsBuilder_.addMessage(builderForValue.build());    }    return this;}
bbde866be3b80b05d6bf0768464f54d67d969c9ec9e328e70324d171a08dc9b9
addActiveLogs
public Builder addActiveLogs(int index, org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog.Builder builderForValue)
{    if (activeLogsBuilder_ == null) {        ensureActiveLogsIsMutable();        activeLogs_.add(index, builderForValue.build());        onChanged();    } else {        activeLogsBuilder_.addMessage(index, builderForValue.build());    }    return this;}
5a7090b72d282e0e0a2b6b06671fb31b8dbaeb81b4ad9aeb536710cc633643a5
addAllActiveLogs
public Builder addAllActiveLogs(java.lang.Iterable<? extends org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog> values)
{    if (activeLogsBuilder_ == null) {        ensureActiveLogsIsMutable();        super.addAll(values, activeLogs_);        onChanged();    } else {        activeLogsBuilder_.addAllMessages(values);    }    return this;}
0bbc09df3c09bacc2ad18a2cda7eb7f02b5c5859f9c658287f957ecce82311c0
clearActiveLogs
public Builder clearActiveLogs()
{    if (activeLogsBuilder_ == null) {        activeLogs_ = java.util.Collections.emptyList();        bitField0_ = (bitField0_ & ~0x00000010);        onChanged();    } else {        activeLogsBuilder_.clear();    }    return this;}
19e210c9cb7734bbb5a67cf00bfb49e1419f83d94b92266f2b9615f28a583134
removeActiveLogs
public Builder removeActiveLogs(int index)
{    if (activeLogsBuilder_ == null) {        ensureActiveLogsIsMutable();        activeLogs_.remove(index);        onChanged();    } else {        activeLogsBuilder_.remove(index);    }    return this;}
2a5932bf180a1c45f0b6b35e6e18faac2a574c6abd6b4fe8a47da4c8afb72735
getActiveLogsBuilder
public org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog.Builder getActiveLogsBuilder(int index)
{    return getActiveLogsFieldBuilder().getBuilder(index);}
68915530de69a99a840b39c6f1e91e950f98cd44905733583c8e27081a7a4c7f
getActiveLogsOrBuilder
public org.apache.flume.channel.file.proto.ProtosFactory.ActiveLogOrBuilder getActiveLogsOrBuilder(int index)
{    if (activeLogsBuilder_ == null) {        return activeLogs_.get(index);    } else {        return activeLogsBuilder_.getMessageOrBuilder(index);    }}
2b8bde994481fafd237cc4829f70fc689a75a2b32284ba22dc12b6683f00e96a
getActiveLogsOrBuilderList
public java.util.List<? extends org.apache.flume.channel.file.proto.ProtosFactory.ActiveLogOrBuilder> getActiveLogsOrBuilderList()
{    if (activeLogsBuilder_ != null) {        return activeLogsBuilder_.getMessageOrBuilderList();    } else {        return java.util.Collections.unmodifiableList(activeLogs_);    }}
4dcc541cb5d2ed84ad64735b6775badac92d137bc1fcb3c990a28b9ebc6ea7d8
addActiveLogsBuilder
public org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog.Builder addActiveLogsBuilder()
{    return getActiveLogsFieldBuilder().addBuilder(org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog.getDefaultInstance());}
306e44c76e61ba1b92cb0da50096f14601793aed9f1595e7c7b02699de322e5b
addActiveLogsBuilder
public org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog.Builder addActiveLogsBuilder(int index)
{    return getActiveLogsFieldBuilder().addBuilder(index, org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog.getDefaultInstance());}
af894ea842ac289c201282114d5b3c56f677fce3c3726938137a8e42064aa722
getActiveLogsBuilderList
public java.util.List<org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog.Builder> getActiveLogsBuilderList()
{    return getActiveLogsFieldBuilder().getBuilderList();}
6563d46ce6ba5df96e9d07cc29d24e2450184d7648e8745285012477db3bd6a8
getActiveLogsFieldBuilder
private com.google.protobuf.RepeatedFieldBuilder<org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog, org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog.Builder, org.apache.flume.channel.file.proto.ProtosFactory.ActiveLogOrBuilder> getActiveLogsFieldBuilder()
{    if (activeLogsBuilder_ == null) {        activeLogsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog, org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog.Builder, org.apache.flume.channel.file.proto.ProtosFactory.ActiveLogOrBuilder>(activeLogs_, ((bitField0_ & 0x00000010) == 0x00000010), getParentForChildren(), isClean());        activeLogs_ = null;    }    return activeLogsBuilder_;}
6f0581677967bbf37eae889add1dffb8516a46a6a54e6c63d60bb2c30bb388a1
getDefaultInstance
public static ActiveLog getDefaultInstance()
{    return defaultInstance;}
d46b85556394728c83ac9b5db469d5762572881cd52ec1f8cda44c4854d9ecd4
getDefaultInstanceForType
public ActiveLog getDefaultInstanceForType()
{    return defaultInstance;}
afeb2882aee0a13dc444e9d430b86a6dc175c48ee917722e2d5ab50801b7ab38
getUnknownFields
public final com.google.protobuf.UnknownFieldSet getUnknownFields()
{    return this.unknownFields;}
e061a4269a7822f30b36dfe5c448257acd508bbe5bfe85e23841ca998b986e73
getDescriptor
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_ActiveLog_descriptor;}
14146f9740b0a47326835ccc62490511ca2c1acd8a7ad735c50f15b98d8aa156
internalGetFieldAccessorTable
protected com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_ActiveLog_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog.class, org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog.Builder.class);}
2b8b30edd2af807ec859bdb0030bcd8f3202576a4a0e2c2cf3ff2757b13dc0bf
parsePartialFrom
public ActiveLog parsePartialFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return new ActiveLog(input, extensionRegistry);}
9dcfc176ed68229bf82f691e5fcbadc99189d5017cb7a24e5399097f156f3a64
getParserForType
public com.google.protobuf.Parser<ActiveLog> getParserForType()
{    return PARSER;}
428f9ecd7ad45d129c52ddb8a178708f69ee7c9bb3c00c150381c62114feace2
hasLogFileID
public boolean hasLogFileID()
{    return ((bitField0_ & 0x00000001) == 0x00000001);}
25d38ece28270e73fd525d53116fdc0f338860b47257c28518fa9a0c6ec86d5d
getLogFileID
public int getLogFileID()
{    return logFileID_;}
e188fffa8ecda586102ce45e56e29cb360186b8ba209becfa7a04dc9db4e6a12
hasCount
public boolean hasCount()
{    return ((bitField0_ & 0x00000002) == 0x00000002);}
29fa59e92e8a9fa433fd7b38ebb21e8ece484149bc8e4a2726bba6f5dab39acf
getCount
public int getCount()
{    return count_;}
3eb5746a869e932254ccd9230e2597001e979870dcff9439accc4b8a5e5b6007
initFields
private void initFields()
{    logFileID_ = 0;    count_ = 0;}
dde7cd718eaa61cad29906454acf122daba6680a2db55e4787a359a08951b5e7
isInitialized
public final boolean isInitialized()
{    byte isInitialized = memoizedIsInitialized;    if (isInitialized != -1)        return isInitialized == 1;    if (!hasLogFileID()) {        memoizedIsInitialized = 0;        return false;    }    if (!hasCount()) {        memoizedIsInitialized = 0;        return false;    }    memoizedIsInitialized = 1;    return true;}
b78da5ac0d0f56440a60e0c8711e74775e8d0aafe7882e5346a5dcc6fa783f73
writeTo
public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException
{    getSerializedSize();    if (((bitField0_ & 0x00000001) == 0x00000001)) {        output.writeSFixed32(1, logFileID_);    }    if (((bitField0_ & 0x00000002) == 0x00000002)) {        output.writeSFixed32(2, count_);    }    getUnknownFields().writeTo(output);}
2bd67191ad73644076f3a74f7b306983cf9bd449d2e535f9b7f802bd0492f9f1
getSerializedSize
public int getSerializedSize()
{    int size = memoizedSerializedSize;    if (size != -1)        return size;    size = 0;    if (((bitField0_ & 0x00000001) == 0x00000001)) {        size += com.google.protobuf.CodedOutputStream.computeSFixed32Size(1, logFileID_);    }    if (((bitField0_ & 0x00000002) == 0x00000002)) {        size += com.google.protobuf.CodedOutputStream.computeSFixed32Size(2, count_);    }    size += getUnknownFields().getSerializedSize();    memoizedSerializedSize = size;    return size;}
969c11f748ec8e7ea2d7ab9b282e6a50da757a9197e9f5c9c8a8c921b705557f
writeReplace
protected java.lang.Object writeReplace() throws java.io.ObjectStreamException
{    return super.writeReplace();}
a93c50a8127ae62bd7b4e6f162e8d8604a6e3d0d5f234d6dd36f3ca046a4897f
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog parseFrom(com.google.protobuf.ByteString data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
496ee72f28abed3bde5f8ba45a6a19c469ebb39d5e32799cf2a4dd2499ad3719
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog parseFrom(com.google.protobuf.ByteString data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
bd43875d76604883d9c505728ccb59cd08ab76ea16303987d4c32c8e7a01338a
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog parseFrom(byte[] data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
4eb8ab1bedf21c7f8b3acf7a4813f1e046b5cb0768d0ada1ccb0d024a09738f7
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog parseFrom(byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
b4b96816c5e9e16c497f3ec484cfea4af4d4e69f03fc8d9bc51daa1994f7e2dd
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog parseFrom(java.io.InputStream input) throws java.io.IOException
{    return PARSER.parseFrom(input);}
0d9473d9c55305e48bc94f4c2ffd24ba5c5a5480787d22df924c64261c0d523f
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog parseFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseFrom(input, extensionRegistry);}
5976d6d5aba381ab237fe4bd232a9df3e88affe2d80ebe45d2df0da8ae24d1fa
parseDelimitedFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog parseDelimitedFrom(java.io.InputStream input) throws java.io.IOException
{    return PARSER.parseDelimitedFrom(input);}
c2320c4ae7610ec4e41f311d4b7e29069d4d4f1f5fb7dcb9028c0cc8270db8a8
parseDelimitedFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog parseDelimitedFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseDelimitedFrom(input, extensionRegistry);}
d4a35313fd04961099fbf718d3a21d4f3f1b6296365be7c09a364eebfabccc7f
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog parseFrom(com.google.protobuf.CodedInputStream input) throws java.io.IOException
{    return PARSER.parseFrom(input);}
0e3570f8b29745bdca2e48dbf3a7d4cf86db89bd39c4dbf16ed9a3334b0625c3
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog parseFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseFrom(input, extensionRegistry);}
e32f866eb7533a232fadc4ef42bb022716435f415dc4a0f7ed4fff845f45ead0
newBuilder
public static Builder newBuilder()
{    return Builder.create();}
a2589243249ba32b92e98298a2511019cd74b21c911d510f075da5ff7e8b6399
newBuilderForType
public Builder newBuilderForType()
{    return newBuilder();}
90fe406e97731799a9bbf87a27857af337b1558a23d6822eec7b8c00eeda3a3d
newBuilder
public static Builder newBuilder(org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog prototype)
{    return newBuilder().mergeFrom(prototype);}
8f9c3ced03d87377003831ec6560ea40c4b718fc762fc1ca14b030b0ed8256d4
toBuilder
public Builder toBuilder()
{    return newBuilder(this);}
2a4c0cac516d5bc4a1109ad4c836ca7b20e2bab822eb3f5bbb7c506c60fb0415
newBuilderForType
protected Builder newBuilderForType(com.google.protobuf.GeneratedMessage.BuilderParent parent)
{    Builder builder = new Builder(parent);    return builder;}
e061a4269a7822f30b36dfe5c448257acd508bbe5bfe85e23841ca998b986e73
getDescriptor
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_ActiveLog_descriptor;}
14146f9740b0a47326835ccc62490511ca2c1acd8a7ad735c50f15b98d8aa156
internalGetFieldAccessorTable
protected com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_ActiveLog_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog.class, org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog.Builder.class);}
7c751d7a2accff7e718ee1e6ea5d2457fe6e182e8c39098e52a8848f56cf2cfe
maybeForceBuilderInitialization
private void maybeForceBuilderInitialization()
{    if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {    }}
db452528a8bc9d155fa120bbe8533aa1eebe58fe8bf85ab33cdc1987e2489b8f
create
private static Builder create()
{    return new Builder();}
7930c451f279d9927ff235e4ac064561e1505f9b7ae117d9f681b345534ff9e3
clear
public Builder clear()
{    super.clear();    logFileID_ = 0;    bitField0_ = (bitField0_ & ~0x00000001);    count_ = 0;    bitField0_ = (bitField0_ & ~0x00000002);    return this;}
845fff95a97cf125489126ddee47248563aa80a59ed327d7d1c7cb9d90dcec30
clone
public Builder clone()
{    return create().mergeFrom(buildPartial());}
5a2efdcbff6cd8f893a197208cee010e41df6afb0e928da5d7126d953902ee30
getDescriptorForType
public com.google.protobuf.Descriptors.Descriptor getDescriptorForType()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_ActiveLog_descriptor;}
7d83a7762c31495b188cc0e5d573643d39e8673ca4b746ae5eedde621b491c99
getDefaultInstanceForType
public org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog getDefaultInstanceForType()
{    return org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog.getDefaultInstance();}
863a92a685d84967810546a4f789aac7d9730322cf9ef8c2236341328a24c6c7
build
public org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog build()
{    org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog result = buildPartial();    if (!result.isInitialized()) {        throw newUninitializedMessageException(result);    }    return result;}
c2804ef0514e14b4e361ea943307b85fad40c33a56f09dfc41a9057eb76cdac7
buildPartial
public org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog buildPartial()
{    org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog result = new org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog(this);    int from_bitField0_ = bitField0_;    int to_bitField0_ = 0;    if (((from_bitField0_ & 0x00000001) == 0x00000001)) {        to_bitField0_ |= 0x00000001;    }    result.logFileID_ = logFileID_;    if (((from_bitField0_ & 0x00000002) == 0x00000002)) {        to_bitField0_ |= 0x00000002;    }    result.count_ = count_;    result.bitField0_ = to_bitField0_;    onBuilt();    return result;}
9c02b14012758934fbc876f583b7201b524cfd4dce350a6fd2cdeea1bb86b6f9
mergeFrom
public Builder mergeFrom(com.google.protobuf.Message other)
{    if (other instanceof org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog) {        return mergeFrom((org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog) other);    } else {        super.mergeFrom(other);        return this;    }}
711a412539a5cf7b21ee5d0c5ae7f379030a7e53375c04cdc09a97962c13f974
mergeFrom
public Builder mergeFrom(org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog other)
{    if (other == org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog.getDefaultInstance())        return this;    if (other.hasLogFileID()) {        setLogFileID(other.getLogFileID());    }    if (other.hasCount()) {        setCount(other.getCount());    }    this.mergeUnknownFields(other.getUnknownFields());    return this;}
dde7cd718eaa61cad29906454acf122daba6680a2db55e4787a359a08951b5e7
isInitialized
public final boolean isInitialized()
{    if (!hasLogFileID()) {        return false;    }    if (!hasCount()) {        return false;    }    return true;}
576f0ac95d3431feb1ba705ec8f537aa5e5a58300021599ce7c111ed9b61d887
mergeFrom
public Builder mergeFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog parsedMessage = null;    try {        parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);    } catch (com.google.protobuf.InvalidProtocolBufferException e) {        parsedMessage = (org.apache.flume.channel.file.proto.ProtosFactory.ActiveLog) e.getUnfinishedMessage();        throw e;    } finally {        if (parsedMessage != null) {            mergeFrom(parsedMessage);        }    }    return this;}
428f9ecd7ad45d129c52ddb8a178708f69ee7c9bb3c00c150381c62114feace2
hasLogFileID
public boolean hasLogFileID()
{    return ((bitField0_ & 0x00000001) == 0x00000001);}
25d38ece28270e73fd525d53116fdc0f338860b47257c28518fa9a0c6ec86d5d
getLogFileID
public int getLogFileID()
{    return logFileID_;}
7037ac6fdab63466f2642ed88196f433d0e7d39afb4b08082aaa9ee4d1f26daf
setLogFileID
public Builder setLogFileID(int value)
{    bitField0_ |= 0x00000001;    logFileID_ = value;    onChanged();    return this;}
ab092576bd2b926c6746b38d8a1794e63f77e6bd37ababf890b3cd2b4420d7b2
clearLogFileID
public Builder clearLogFileID()
{    bitField0_ = (bitField0_ & ~0x00000001);    logFileID_ = 0;    onChanged();    return this;}
e188fffa8ecda586102ce45e56e29cb360186b8ba209becfa7a04dc9db4e6a12
hasCount
public boolean hasCount()
{    return ((bitField0_ & 0x00000002) == 0x00000002);}
29fa59e92e8a9fa433fd7b38ebb21e8ece484149bc8e4a2726bba6f5dab39acf
getCount
public int getCount()
{    return count_;}
eb1554ffc5745c16556436506df27f18284b57f41f2b1bb9071a07791b9ff93b
setCount
public Builder setCount(int value)
{    bitField0_ |= 0x00000002;    count_ = value;    onChanged();    return this;}
19ee49c6e32007147f6cdba42e330e96d8fe5aac61e6ccbed65e25b05a1c0afc
clearCount
public Builder clearCount()
{    bitField0_ = (bitField0_ & ~0x00000002);    count_ = 0;    onChanged();    return this;}
1191047a3dc08bcb83d2be0625a5175924f0fb3c4a51c7536415de28aad08a2f
getDefaultInstance
public static LogFileMetaData getDefaultInstance()
{    return defaultInstance;}
c4731cd0f1570bf161c9ffec8cb2dd445b06a791919ff3cfc06ec17e2f3eb795
getDefaultInstanceForType
public LogFileMetaData getDefaultInstanceForType()
{    return defaultInstance;}
afeb2882aee0a13dc444e9d430b86a6dc175c48ee917722e2d5ab50801b7ab38
getUnknownFields
public final com.google.protobuf.UnknownFieldSet getUnknownFields()
{    return this.unknownFields;}
e061a4269a7822f30b36dfe5c448257acd508bbe5bfe85e23841ca998b986e73
getDescriptor
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_LogFileMetaData_descriptor;}
14146f9740b0a47326835ccc62490511ca2c1acd8a7ad735c50f15b98d8aa156
internalGetFieldAccessorTable
protected com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_LogFileMetaData_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData.class, org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData.Builder.class);}
f2ad69fa93e86747d98eb1b10a20668f95bc070c91ecf5ac4a2f0a9f390832ac
parsePartialFrom
public LogFileMetaData parsePartialFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return new LogFileMetaData(input, extensionRegistry);}
716d182e4a4bfe169106a46096596b03a2882d88beb901dc34bebb16eac03a0e
getParserForType
public com.google.protobuf.Parser<LogFileMetaData> getParserForType()
{    return PARSER;}
7d59dce09306b81b0dfd081c0e225800c0c7af165a630435fc7af24e4cf390ff
hasVersion
public boolean hasVersion()
{    return ((bitField0_ & 0x00000001) == 0x00000001);}
54bc0b349a40e5994cc6b2b7c63b7bdb8eaebafd56321e290c868307cb2a4574
getVersion
public int getVersion()
{    return version_;}
428f9ecd7ad45d129c52ddb8a178708f69ee7c9bb3c00c150381c62114feace2
hasLogFileID
public boolean hasLogFileID()
{    return ((bitField0_ & 0x00000002) == 0x00000002);}
25d38ece28270e73fd525d53116fdc0f338860b47257c28518fa9a0c6ec86d5d
getLogFileID
public int getLogFileID()
{    return logFileID_;}
66a58c7213955625fe02aa80055378e132b8a9181bc0830b946f9e8e00a0365a
hasCheckpointPosition
public boolean hasCheckpointPosition()
{    return ((bitField0_ & 0x00000004) == 0x00000004);}
ce761584e48349f92c221e8b66a03e56c2df1027fadb4576bd946e4bfc8c6fcd
getCheckpointPosition
public long getCheckpointPosition()
{    return checkpointPosition_;}
bc3abc5a5c6abf0ed1d82b5bb76f9de937ca184e05fd6bd9d37795cd89c130a1
hasCheckpointWriteOrderID
public boolean hasCheckpointWriteOrderID()
{    return ((bitField0_ & 0x00000008) == 0x00000008);}
f6a8983d95bb53270f1521e9e699a0a652364493534919b370ee00865e4ce575
getCheckpointWriteOrderID
public long getCheckpointWriteOrderID()
{    return checkpointWriteOrderID_;}
5277e4d8ff41f1680e3247fa75c0baf6903e27295ce6c1060c97abe33bea5af6
hasEncryption
public boolean hasEncryption()
{    return ((bitField0_ & 0x00000010) == 0x00000010);}
6274368f78544659e3cc2e135b9b983cd70c4f34c21076a0258afe454b00087d
getEncryption
public org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption getEncryption()
{    return encryption_;}
25574e6b4e909a06a56d2e1660c0d27b456e48f18b9231949ec8e660b82eff87
getEncryptionOrBuilder
public org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryptionOrBuilder getEncryptionOrBuilder()
{    return encryption_;}
b8a52a8ea3a09f80326228f959e42e3166de8407b1fa215fcc1e88fa693be051
hasBackupCheckpointPosition
public boolean hasBackupCheckpointPosition()
{    return ((bitField0_ & 0x00000020) == 0x00000020);}
fd495479da8f829dd1e2a192411bfb424201f5e61892c8b386fcef136a9bbe00
getBackupCheckpointPosition
public long getBackupCheckpointPosition()
{    return backupCheckpointPosition_;}
0697e3b84ec2b598161f127c827305241b819d637a4fe8b70fd4932bfb47141f
hasBackupCheckpointWriteOrderID
public boolean hasBackupCheckpointWriteOrderID()
{    return ((bitField0_ & 0x00000040) == 0x00000040);}
f2b5d9842d2f3a66aa83b929c5206c68d43902a019891375422f60687ff3df94
getBackupCheckpointWriteOrderID
public long getBackupCheckpointWriteOrderID()
{    return backupCheckpointWriteOrderID_;}
3eb5746a869e932254ccd9230e2597001e979870dcff9439accc4b8a5e5b6007
initFields
private void initFields()
{    version_ = 0;    logFileID_ = 0;    checkpointPosition_ = 0L;    checkpointWriteOrderID_ = 0L;    encryption_ = org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption.getDefaultInstance();    backupCheckpointPosition_ = 0L;    backupCheckpointWriteOrderID_ = 0L;}
dde7cd718eaa61cad29906454acf122daba6680a2db55e4787a359a08951b5e7
isInitialized
public final boolean isInitialized()
{    byte isInitialized = memoizedIsInitialized;    if (isInitialized != -1)        return isInitialized == 1;    if (!hasVersion()) {        memoizedIsInitialized = 0;        return false;    }    if (!hasLogFileID()) {        memoizedIsInitialized = 0;        return false;    }    if (!hasCheckpointPosition()) {        memoizedIsInitialized = 0;        return false;    }    if (!hasCheckpointWriteOrderID()) {        memoizedIsInitialized = 0;        return false;    }    if (hasEncryption()) {        if (!getEncryption().isInitialized()) {            memoizedIsInitialized = 0;            return false;        }    }    memoizedIsInitialized = 1;    return true;}
b78da5ac0d0f56440a60e0c8711e74775e8d0aafe7882e5346a5dcc6fa783f73
writeTo
public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException
{    getSerializedSize();    if (((bitField0_ & 0x00000001) == 0x00000001)) {        output.writeSFixed32(1, version_);    }    if (((bitField0_ & 0x00000002) == 0x00000002)) {        output.writeSFixed32(2, logFileID_);    }    if (((bitField0_ & 0x00000004) == 0x00000004)) {        output.writeSFixed64(3, checkpointPosition_);    }    if (((bitField0_ & 0x00000008) == 0x00000008)) {        output.writeSFixed64(4, checkpointWriteOrderID_);    }    if (((bitField0_ & 0x00000010) == 0x00000010)) {        output.writeMessage(5, encryption_);    }    if (((bitField0_ & 0x00000020) == 0x00000020)) {        output.writeSFixed64(6, backupCheckpointPosition_);    }    if (((bitField0_ & 0x00000040) == 0x00000040)) {        output.writeSFixed64(7, backupCheckpointWriteOrderID_);    }    getUnknownFields().writeTo(output);}
2bd67191ad73644076f3a74f7b306983cf9bd449d2e535f9b7f802bd0492f9f1
getSerializedSize
public int getSerializedSize()
{    int size = memoizedSerializedSize;    if (size != -1)        return size;    size = 0;    if (((bitField0_ & 0x00000001) == 0x00000001)) {        size += com.google.protobuf.CodedOutputStream.computeSFixed32Size(1, version_);    }    if (((bitField0_ & 0x00000002) == 0x00000002)) {        size += com.google.protobuf.CodedOutputStream.computeSFixed32Size(2, logFileID_);    }    if (((bitField0_ & 0x00000004) == 0x00000004)) {        size += com.google.protobuf.CodedOutputStream.computeSFixed64Size(3, checkpointPosition_);    }    if (((bitField0_ & 0x00000008) == 0x00000008)) {        size += com.google.protobuf.CodedOutputStream.computeSFixed64Size(4, checkpointWriteOrderID_);    }    if (((bitField0_ & 0x00000010) == 0x00000010)) {        size += com.google.protobuf.CodedOutputStream.computeMessageSize(5, encryption_);    }    if (((bitField0_ & 0x00000020) == 0x00000020)) {        size += com.google.protobuf.CodedOutputStream.computeSFixed64Size(6, backupCheckpointPosition_);    }    if (((bitField0_ & 0x00000040) == 0x00000040)) {        size += com.google.protobuf.CodedOutputStream.computeSFixed64Size(7, backupCheckpointWriteOrderID_);    }    size += getUnknownFields().getSerializedSize();    memoizedSerializedSize = size;    return size;}
969c11f748ec8e7ea2d7ab9b282e6a50da757a9197e9f5c9c8a8c921b705557f
writeReplace
protected java.lang.Object writeReplace() throws java.io.ObjectStreamException
{    return super.writeReplace();}
ce47b1cdfc4e8b633ddb511e887ceca925ea57cb31cdccf2c686a0f119102e82
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData parseFrom(com.google.protobuf.ByteString data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
5b7da974426a2b4bd0c7d0c1bebaa0396195ee9d066fda4360426e2203a13413
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData parseFrom(com.google.protobuf.ByteString data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
ce07507737e6a7261e3bc84debe1e338253d0d6eb6a1b48b283c73c0915bbe47
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData parseFrom(byte[] data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
1b63b9497a55f9e9c85d9f956140b8d9fb3be55da3f44d7c7039fc721f4833fa
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData parseFrom(byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
e0f29e59e59587c77d1afec219b3ab49ff7aa5ed56457e7e2bf4114d71c111f1
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData parseFrom(java.io.InputStream input) throws java.io.IOException
{    return PARSER.parseFrom(input);}
c3f7582e5fa31a9a7a5709223699e6c7f6cbd1f338124eee02fa2780a2bfceaf
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData parseFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseFrom(input, extensionRegistry);}
233d455c88f1f5871d698e0a0dc3e434fe9909925c80c90a923cbe2cc25c9390
parseDelimitedFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData parseDelimitedFrom(java.io.InputStream input) throws java.io.IOException
{    return PARSER.parseDelimitedFrom(input);}
22b07a703820bf0578fa97ae1592651407d24d83af61275153e33d54daccffaf
parseDelimitedFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData parseDelimitedFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseDelimitedFrom(input, extensionRegistry);}
98f88a1528fc9de9552161fa79cf28b169b91aab44c504d56d85bbfea35dfab2
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData parseFrom(com.google.protobuf.CodedInputStream input) throws java.io.IOException
{    return PARSER.parseFrom(input);}
66f71a63f18585ca4c22fe6a916fb5eb68a875ab9a470db8ef4b5e43ae54e1d0
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData parseFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseFrom(input, extensionRegistry);}
e32f866eb7533a232fadc4ef42bb022716435f415dc4a0f7ed4fff845f45ead0
newBuilder
public static Builder newBuilder()
{    return Builder.create();}
a2589243249ba32b92e98298a2511019cd74b21c911d510f075da5ff7e8b6399
newBuilderForType
public Builder newBuilderForType()
{    return newBuilder();}
262b2b2fe38f26936eca06d0277b54ca15f8d93dc02874c2729f3b54d63906a9
newBuilder
public static Builder newBuilder(org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData prototype)
{    return newBuilder().mergeFrom(prototype);}
8f9c3ced03d87377003831ec6560ea40c4b718fc762fc1ca14b030b0ed8256d4
toBuilder
public Builder toBuilder()
{    return newBuilder(this);}
2a4c0cac516d5bc4a1109ad4c836ca7b20e2bab822eb3f5bbb7c506c60fb0415
newBuilderForType
protected Builder newBuilderForType(com.google.protobuf.GeneratedMessage.BuilderParent parent)
{    Builder builder = new Builder(parent);    return builder;}
e061a4269a7822f30b36dfe5c448257acd508bbe5bfe85e23841ca998b986e73
getDescriptor
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_LogFileMetaData_descriptor;}
14146f9740b0a47326835ccc62490511ca2c1acd8a7ad735c50f15b98d8aa156
internalGetFieldAccessorTable
protected com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_LogFileMetaData_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData.class, org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData.Builder.class);}
7c751d7a2accff7e718ee1e6ea5d2457fe6e182e8c39098e52a8848f56cf2cfe
maybeForceBuilderInitialization
private void maybeForceBuilderInitialization()
{    if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {        getEncryptionFieldBuilder();    }}
db452528a8bc9d155fa120bbe8533aa1eebe58fe8bf85ab33cdc1987e2489b8f
create
private static Builder create()
{    return new Builder();}
7930c451f279d9927ff235e4ac064561e1505f9b7ae117d9f681b345534ff9e3
clear
public Builder clear()
{    super.clear();    version_ = 0;    bitField0_ = (bitField0_ & ~0x00000001);    logFileID_ = 0;    bitField0_ = (bitField0_ & ~0x00000002);    checkpointPosition_ = 0L;    bitField0_ = (bitField0_ & ~0x00000004);    checkpointWriteOrderID_ = 0L;    bitField0_ = (bitField0_ & ~0x00000008);    if (encryptionBuilder_ == null) {        encryption_ = org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption.getDefaultInstance();    } else {        encryptionBuilder_.clear();    }    bitField0_ = (bitField0_ & ~0x00000010);    backupCheckpointPosition_ = 0L;    bitField0_ = (bitField0_ & ~0x00000020);    backupCheckpointWriteOrderID_ = 0L;    bitField0_ = (bitField0_ & ~0x00000040);    return this;}
845fff95a97cf125489126ddee47248563aa80a59ed327d7d1c7cb9d90dcec30
clone
public Builder clone()
{    return create().mergeFrom(buildPartial());}
5a2efdcbff6cd8f893a197208cee010e41df6afb0e928da5d7126d953902ee30
getDescriptorForType
public com.google.protobuf.Descriptors.Descriptor getDescriptorForType()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_LogFileMetaData_descriptor;}
5e2dbaafc04f689533e5d5cbe24fa8f4d325a5a5744586863dd45358e6c92c23
getDefaultInstanceForType
public org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData getDefaultInstanceForType()
{    return org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData.getDefaultInstance();}
f6dc6b16f34b8cf861192e022b04110b7da60aef6c8e8f8e0578a5154e23482e
build
public org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData build()
{    org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData result = buildPartial();    if (!result.isInitialized()) {        throw newUninitializedMessageException(result);    }    return result;}
7bad92c91686da95445129da46b15edc74e8ad1f8524073ad61e8081ca36116e
buildPartial
public org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData buildPartial()
{    org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData result = new org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData(this);    int from_bitField0_ = bitField0_;    int to_bitField0_ = 0;    if (((from_bitField0_ & 0x00000001) == 0x00000001)) {        to_bitField0_ |= 0x00000001;    }    result.version_ = version_;    if (((from_bitField0_ & 0x00000002) == 0x00000002)) {        to_bitField0_ |= 0x00000002;    }    result.logFileID_ = logFileID_;    if (((from_bitField0_ & 0x00000004) == 0x00000004)) {        to_bitField0_ |= 0x00000004;    }    result.checkpointPosition_ = checkpointPosition_;    if (((from_bitField0_ & 0x00000008) == 0x00000008)) {        to_bitField0_ |= 0x00000008;    }    result.checkpointWriteOrderID_ = checkpointWriteOrderID_;    if (((from_bitField0_ & 0x00000010) == 0x00000010)) {        to_bitField0_ |= 0x00000010;    }    if (encryptionBuilder_ == null) {        result.encryption_ = encryption_;    } else {        result.encryption_ = encryptionBuilder_.build();    }    if (((from_bitField0_ & 0x00000020) == 0x00000020)) {        to_bitField0_ |= 0x00000020;    }    result.backupCheckpointPosition_ = backupCheckpointPosition_;    if (((from_bitField0_ & 0x00000040) == 0x00000040)) {        to_bitField0_ |= 0x00000040;    }    result.backupCheckpointWriteOrderID_ = backupCheckpointWriteOrderID_;    result.bitField0_ = to_bitField0_;    onBuilt();    return result;}
9c02b14012758934fbc876f583b7201b524cfd4dce350a6fd2cdeea1bb86b6f9
mergeFrom
public Builder mergeFrom(com.google.protobuf.Message other)
{    if (other instanceof org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData) {        return mergeFrom((org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData) other);    } else {        super.mergeFrom(other);        return this;    }}
09a051cba959f9e1d25d0993b86fb1067f4dab7eb03a8a842e9e4a5620c52814
mergeFrom
public Builder mergeFrom(org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData other)
{    if (other == org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData.getDefaultInstance())        return this;    if (other.hasVersion()) {        setVersion(other.getVersion());    }    if (other.hasLogFileID()) {        setLogFileID(other.getLogFileID());    }    if (other.hasCheckpointPosition()) {        setCheckpointPosition(other.getCheckpointPosition());    }    if (other.hasCheckpointWriteOrderID()) {        setCheckpointWriteOrderID(other.getCheckpointWriteOrderID());    }    if (other.hasEncryption()) {        mergeEncryption(other.getEncryption());    }    if (other.hasBackupCheckpointPosition()) {        setBackupCheckpointPosition(other.getBackupCheckpointPosition());    }    if (other.hasBackupCheckpointWriteOrderID()) {        setBackupCheckpointWriteOrderID(other.getBackupCheckpointWriteOrderID());    }    this.mergeUnknownFields(other.getUnknownFields());    return this;}
dde7cd718eaa61cad29906454acf122daba6680a2db55e4787a359a08951b5e7
isInitialized
public final boolean isInitialized()
{    if (!hasVersion()) {        return false;    }    if (!hasLogFileID()) {        return false;    }    if (!hasCheckpointPosition()) {        return false;    }    if (!hasCheckpointWriteOrderID()) {        return false;    }    if (hasEncryption()) {        if (!getEncryption().isInitialized()) {            return false;        }    }    return true;}
576f0ac95d3431feb1ba705ec8f537aa5e5a58300021599ce7c111ed9b61d887
mergeFrom
public Builder mergeFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData parsedMessage = null;    try {        parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);    } catch (com.google.protobuf.InvalidProtocolBufferException e) {        parsedMessage = (org.apache.flume.channel.file.proto.ProtosFactory.LogFileMetaData) e.getUnfinishedMessage();        throw e;    } finally {        if (parsedMessage != null) {            mergeFrom(parsedMessage);        }    }    return this;}
7d59dce09306b81b0dfd081c0e225800c0c7af165a630435fc7af24e4cf390ff
hasVersion
public boolean hasVersion()
{    return ((bitField0_ & 0x00000001) == 0x00000001);}
54bc0b349a40e5994cc6b2b7c63b7bdb8eaebafd56321e290c868307cb2a4574
getVersion
public int getVersion()
{    return version_;}
9dd33050be56688653b9f4ab470d891970d7ac93da62ce7bb4e1cfcdbd354961
setVersion
public Builder setVersion(int value)
{    bitField0_ |= 0x00000001;    version_ = value;    onChanged();    return this;}
783a8c6c2d64f24a8f1e45eff356873b618a2782a7ff4802b6ee3ae49121243f
clearVersion
public Builder clearVersion()
{    bitField0_ = (bitField0_ & ~0x00000001);    version_ = 0;    onChanged();    return this;}
428f9ecd7ad45d129c52ddb8a178708f69ee7c9bb3c00c150381c62114feace2
hasLogFileID
public boolean hasLogFileID()
{    return ((bitField0_ & 0x00000002) == 0x00000002);}
25d38ece28270e73fd525d53116fdc0f338860b47257c28518fa9a0c6ec86d5d
getLogFileID
public int getLogFileID()
{    return logFileID_;}
7037ac6fdab63466f2642ed88196f433d0e7d39afb4b08082aaa9ee4d1f26daf
setLogFileID
public Builder setLogFileID(int value)
{    bitField0_ |= 0x00000002;    logFileID_ = value;    onChanged();    return this;}
ab092576bd2b926c6746b38d8a1794e63f77e6bd37ababf890b3cd2b4420d7b2
clearLogFileID
public Builder clearLogFileID()
{    bitField0_ = (bitField0_ & ~0x00000002);    logFileID_ = 0;    onChanged();    return this;}
66a58c7213955625fe02aa80055378e132b8a9181bc0830b946f9e8e00a0365a
hasCheckpointPosition
public boolean hasCheckpointPosition()
{    return ((bitField0_ & 0x00000004) == 0x00000004);}
ce761584e48349f92c221e8b66a03e56c2df1027fadb4576bd946e4bfc8c6fcd
getCheckpointPosition
public long getCheckpointPosition()
{    return checkpointPosition_;}
9a9278d2c3829c52bd71a43af361cbe25cae941ae2068edbb7712355905ff3fe
setCheckpointPosition
public Builder setCheckpointPosition(long value)
{    bitField0_ |= 0x00000004;    checkpointPosition_ = value;    onChanged();    return this;}
c8413ce2ef84b082763ab7365c1e1f843ec716d5a9531e944ffcf7f664fbec11
clearCheckpointPosition
public Builder clearCheckpointPosition()
{    bitField0_ = (bitField0_ & ~0x00000004);    checkpointPosition_ = 0L;    onChanged();    return this;}
bc3abc5a5c6abf0ed1d82b5bb76f9de937ca184e05fd6bd9d37795cd89c130a1
hasCheckpointWriteOrderID
public boolean hasCheckpointWriteOrderID()
{    return ((bitField0_ & 0x00000008) == 0x00000008);}
f6a8983d95bb53270f1521e9e699a0a652364493534919b370ee00865e4ce575
getCheckpointWriteOrderID
public long getCheckpointWriteOrderID()
{    return checkpointWriteOrderID_;}
1bf13defce747e04157080fb81b8d30d451ea221050c0165e6dc5372850338ed
setCheckpointWriteOrderID
public Builder setCheckpointWriteOrderID(long value)
{    bitField0_ |= 0x00000008;    checkpointWriteOrderID_ = value;    onChanged();    return this;}
a49c3eb3badece6cbaff3552326a90ced277e6f23339cdfef6834cd7d25073b0
clearCheckpointWriteOrderID
public Builder clearCheckpointWriteOrderID()
{    bitField0_ = (bitField0_ & ~0x00000008);    checkpointWriteOrderID_ = 0L;    onChanged();    return this;}
5277e4d8ff41f1680e3247fa75c0baf6903e27295ce6c1060c97abe33bea5af6
hasEncryption
public boolean hasEncryption()
{    return ((bitField0_ & 0x00000010) == 0x00000010);}
6274368f78544659e3cc2e135b9b983cd70c4f34c21076a0258afe454b00087d
getEncryption
public org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption getEncryption()
{    if (encryptionBuilder_ == null) {        return encryption_;    } else {        return encryptionBuilder_.getMessage();    }}
12dff7ca678da39df5e6a3bfb53aa39107f35f73b127f4c7841063968722107e
setEncryption
public Builder setEncryption(org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption value)
{    if (encryptionBuilder_ == null) {        if (value == null) {            throw new NullPointerException();        }        encryption_ = value;        onChanged();    } else {        encryptionBuilder_.setMessage(value);    }    bitField0_ |= 0x00000010;    return this;}
4bbdd5899d11a3ccdc9714914931862791a2e8ee2b9980d9f9ce5206456409e6
setEncryption
public Builder setEncryption(org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption.Builder builderForValue)
{    if (encryptionBuilder_ == null) {        encryption_ = builderForValue.build();        onChanged();    } else {        encryptionBuilder_.setMessage(builderForValue.build());    }    bitField0_ |= 0x00000010;    return this;}
10ca5924386d035e775fa7f3a81a1ec42f3c6a881d78600f5b97f5d34bc1b423
mergeEncryption
public Builder mergeEncryption(org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption value)
{    if (encryptionBuilder_ == null) {        if (((bitField0_ & 0x00000010) == 0x00000010) && encryption_ != org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption.getDefaultInstance()) {            encryption_ = org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption.newBuilder(encryption_).mergeFrom(value).buildPartial();        } else {            encryption_ = value;        }        onChanged();    } else {        encryptionBuilder_.mergeFrom(value);    }    bitField0_ |= 0x00000010;    return this;}
f522561c37fc10036d39f05f2191520aa5dbe845b91e5816c04924d7e4b39210
clearEncryption
public Builder clearEncryption()
{    if (encryptionBuilder_ == null) {        encryption_ = org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption.getDefaultInstance();        onChanged();    } else {        encryptionBuilder_.clear();    }    bitField0_ = (bitField0_ & ~0x00000010);    return this;}
9d9cb6161d01b80e02aa7e63b2c8949ecc4bcefc9d33c5b5d77f1a761734500d
getEncryptionBuilder
public org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption.Builder getEncryptionBuilder()
{    bitField0_ |= 0x00000010;    onChanged();    return getEncryptionFieldBuilder().getBuilder();}
25574e6b4e909a06a56d2e1660c0d27b456e48f18b9231949ec8e660b82eff87
getEncryptionOrBuilder
public org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryptionOrBuilder getEncryptionOrBuilder()
{    if (encryptionBuilder_ != null) {        return encryptionBuilder_.getMessageOrBuilder();    } else {        return encryption_;    }}
4723cae94e8fb5a6675d8e0996ed56082657ed4bb46593e6fb35bb31b1e83040
getEncryptionFieldBuilder
private com.google.protobuf.SingleFieldBuilder<org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption, org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption.Builder, org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryptionOrBuilder> getEncryptionFieldBuilder()
{    if (encryptionBuilder_ == null) {        encryptionBuilder_ = new com.google.protobuf.SingleFieldBuilder<org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption, org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption.Builder, org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryptionOrBuilder>(encryption_, getParentForChildren(), isClean());        encryption_ = null;    }    return encryptionBuilder_;}
b8a52a8ea3a09f80326228f959e42e3166de8407b1fa215fcc1e88fa693be051
hasBackupCheckpointPosition
public boolean hasBackupCheckpointPosition()
{    return ((bitField0_ & 0x00000020) == 0x00000020);}
fd495479da8f829dd1e2a192411bfb424201f5e61892c8b386fcef136a9bbe00
getBackupCheckpointPosition
public long getBackupCheckpointPosition()
{    return backupCheckpointPosition_;}
e3fd0c90d1235310aee8ae89bbb052f9756a2d6d3d54643b08e21babb2b6b716
setBackupCheckpointPosition
public Builder setBackupCheckpointPosition(long value)
{    bitField0_ |= 0x00000020;    backupCheckpointPosition_ = value;    onChanged();    return this;}
bcbe4cf0c0483ffaa45ef365e0bddad37035b9cdc6d2e7ee10e30e027d38dac8
clearBackupCheckpointPosition
public Builder clearBackupCheckpointPosition()
{    bitField0_ = (bitField0_ & ~0x00000020);    backupCheckpointPosition_ = 0L;    onChanged();    return this;}
0697e3b84ec2b598161f127c827305241b819d637a4fe8b70fd4932bfb47141f
hasBackupCheckpointWriteOrderID
public boolean hasBackupCheckpointWriteOrderID()
{    return ((bitField0_ & 0x00000040) == 0x00000040);}
f2b5d9842d2f3a66aa83b929c5206c68d43902a019891375422f60687ff3df94
getBackupCheckpointWriteOrderID
public long getBackupCheckpointWriteOrderID()
{    return backupCheckpointWriteOrderID_;}
f3a7729dedb0267e1c718cff073dce6c9f3b932ad393e14ec4b36f80c5064bc8
setBackupCheckpointWriteOrderID
public Builder setBackupCheckpointWriteOrderID(long value)
{    bitField0_ |= 0x00000040;    backupCheckpointWriteOrderID_ = value;    onChanged();    return this;}
9eb45ab2241a196635f2e10377d6ca8d1ceeac7e29697cf6bde53f856cc832aa
clearBackupCheckpointWriteOrderID
public Builder clearBackupCheckpointWriteOrderID()
{    bitField0_ = (bitField0_ & ~0x00000040);    backupCheckpointWriteOrderID_ = 0L;    onChanged();    return this;}
9f80a045b3468518f18446e59e4080f4da98584ea6c1717e6feb94aa63b2c92d
getDefaultInstance
public static LogFileEncryption getDefaultInstance()
{    return defaultInstance;}
a15daacef8bda0778919101871d83d7867e092cf73917ddf10515edf627e6934
getDefaultInstanceForType
public LogFileEncryption getDefaultInstanceForType()
{    return defaultInstance;}
afeb2882aee0a13dc444e9d430b86a6dc175c48ee917722e2d5ab50801b7ab38
getUnknownFields
public final com.google.protobuf.UnknownFieldSet getUnknownFields()
{    return this.unknownFields;}
e061a4269a7822f30b36dfe5c448257acd508bbe5bfe85e23841ca998b986e73
getDescriptor
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_LogFileEncryption_descriptor;}
14146f9740b0a47326835ccc62490511ca2c1acd8a7ad735c50f15b98d8aa156
internalGetFieldAccessorTable
protected com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_LogFileEncryption_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption.class, org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption.Builder.class);}
bd8d30625cdbe00b55d3c4e12723f400fd65842ed65419759fd0197d34b9634d
parsePartialFrom
public LogFileEncryption parsePartialFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return new LogFileEncryption(input, extensionRegistry);}
5fa344bdadb33cb8cdb816dfc8f34834aa2fa9bbfa7b3e6e41afa83103e5b5a5
getParserForType
public com.google.protobuf.Parser<LogFileEncryption> getParserForType()
{    return PARSER;}
30facdd23ef3b9b68574b8d86f5e91314fd801e518d906995ff445aa21d44924
hasCipherProvider
public boolean hasCipherProvider()
{    return ((bitField0_ & 0x00000001) == 0x00000001);}
827d104322f79595d7ba2be2d4e55168389adf62ce3bd39540a6e8290723231f
getCipherProvider
public java.lang.String getCipherProvider()
{    java.lang.Object ref = cipherProvider_;    if (ref instanceof java.lang.String) {        return (java.lang.String) ref;    } else {        com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;        java.lang.String s = bs.toStringUtf8();        if (bs.isValidUtf8()) {            cipherProvider_ = s;        }        return s;    }}
c979ba1e8f0f60c964d31635a70f0dc39929afa40a87d8f995f3e4bd822c1afe
getCipherProviderBytes
public com.google.protobuf.ByteString getCipherProviderBytes()
{    java.lang.Object ref = cipherProvider_;    if (ref instanceof java.lang.String) {        com.google.protobuf.ByteString b = com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);        cipherProvider_ = b;        return b;    } else {        return (com.google.protobuf.ByteString) ref;    }}
f7fac6911ba777daceb24850da777b3a0880ac0f4589da7f7fab9f526cf2d776
hasKeyAlias
public boolean hasKeyAlias()
{    return ((bitField0_ & 0x00000002) == 0x00000002);}
e5279762cdda8ee3a53c91e672e1426a7ee74dc9c38792079a008c9ad8b3563f
getKeyAlias
public java.lang.String getKeyAlias()
{    java.lang.Object ref = keyAlias_;    if (ref instanceof java.lang.String) {        return (java.lang.String) ref;    } else {        com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;        java.lang.String s = bs.toStringUtf8();        if (bs.isValidUtf8()) {            keyAlias_ = s;        }        return s;    }}
2565ed0702b2cb7cf596c97172d78448ee7a55beafd1c99e09ade4dab34399f7
getKeyAliasBytes
public com.google.protobuf.ByteString getKeyAliasBytes()
{    java.lang.Object ref = keyAlias_;    if (ref instanceof java.lang.String) {        com.google.protobuf.ByteString b = com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);        keyAlias_ = b;        return b;    } else {        return (com.google.protobuf.ByteString) ref;    }}
3873b34a7e026fb583c295e16276c0d84bd2bf586beccc2b1384ed72807589e8
hasParameters
public boolean hasParameters()
{    return ((bitField0_ & 0x00000004) == 0x00000004);}
ac23878f46864ceaf60dd9f398b6aa0b6a97681547c6c2a26d91a833699933fd
getParameters
public com.google.protobuf.ByteString getParameters()
{    return parameters_;}
3eb5746a869e932254ccd9230e2597001e979870dcff9439accc4b8a5e5b6007
initFields
private void initFields()
{    cipherProvider_ = "";    keyAlias_ = "";    parameters_ = com.google.protobuf.ByteString.EMPTY;}
dde7cd718eaa61cad29906454acf122daba6680a2db55e4787a359a08951b5e7
isInitialized
public final boolean isInitialized()
{    byte isInitialized = memoizedIsInitialized;    if (isInitialized != -1)        return isInitialized == 1;    if (!hasCipherProvider()) {        memoizedIsInitialized = 0;        return false;    }    if (!hasKeyAlias()) {        memoizedIsInitialized = 0;        return false;    }    memoizedIsInitialized = 1;    return true;}
b78da5ac0d0f56440a60e0c8711e74775e8d0aafe7882e5346a5dcc6fa783f73
writeTo
public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException
{    getSerializedSize();    if (((bitField0_ & 0x00000001) == 0x00000001)) {        output.writeBytes(1, getCipherProviderBytes());    }    if (((bitField0_ & 0x00000002) == 0x00000002)) {        output.writeBytes(2, getKeyAliasBytes());    }    if (((bitField0_ & 0x00000004) == 0x00000004)) {        output.writeBytes(3, parameters_);    }    getUnknownFields().writeTo(output);}
2bd67191ad73644076f3a74f7b306983cf9bd449d2e535f9b7f802bd0492f9f1
getSerializedSize
public int getSerializedSize()
{    int size = memoizedSerializedSize;    if (size != -1)        return size;    size = 0;    if (((bitField0_ & 0x00000001) == 0x00000001)) {        size += com.google.protobuf.CodedOutputStream.computeBytesSize(1, getCipherProviderBytes());    }    if (((bitField0_ & 0x00000002) == 0x00000002)) {        size += com.google.protobuf.CodedOutputStream.computeBytesSize(2, getKeyAliasBytes());    }    if (((bitField0_ & 0x00000004) == 0x00000004)) {        size += com.google.protobuf.CodedOutputStream.computeBytesSize(3, parameters_);    }    size += getUnknownFields().getSerializedSize();    memoizedSerializedSize = size;    return size;}
969c11f748ec8e7ea2d7ab9b282e6a50da757a9197e9f5c9c8a8c921b705557f
writeReplace
protected java.lang.Object writeReplace() throws java.io.ObjectStreamException
{    return super.writeReplace();}
d2e8bfb193ed16eea001c63baba621f88b8a1973a8277253b2df34f2f2d90c74
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption parseFrom(com.google.protobuf.ByteString data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
b83af25634386e837f8b830c05c8e29dc375d098668913c17e213d2261a3e017
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption parseFrom(com.google.protobuf.ByteString data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
9b145e791303c6be259210f7a143ccd2ec0333e34606698ff64a8961a63b5263
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption parseFrom(byte[] data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
9a5a00ac59ab8ce19a83485a1490c1081882997978863aa612b8edd0c292ae87
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption parseFrom(byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
c76b4f862755dd4c7a9130b6f2defe588beaa7276397eec6df6dce109428e7a4
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption parseFrom(java.io.InputStream input) throws java.io.IOException
{    return PARSER.parseFrom(input);}
7cbe30cda049ca1a3b6fab2d21d01d214d2414ecf28128f27d1eafb8a605e1c0
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption parseFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseFrom(input, extensionRegistry);}
5e193d3d1c94d051ac82b5fefb9b8e90d0fa8ca0ac96a7f2caa9b6c6b8938e16
parseDelimitedFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption parseDelimitedFrom(java.io.InputStream input) throws java.io.IOException
{    return PARSER.parseDelimitedFrom(input);}
a1c5c8ebb56c188b47d53cac0349cc94e71871e18381afa0e434ad4d0f298d19
parseDelimitedFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption parseDelimitedFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseDelimitedFrom(input, extensionRegistry);}
f66c32da9bd2afa076f123232429c83717ac297a204b0c95319e8b9f522339d5
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption parseFrom(com.google.protobuf.CodedInputStream input) throws java.io.IOException
{    return PARSER.parseFrom(input);}
b81f338d8621f32d6532e4ebc1ef2b00f8c41aebece1cd75a1dfe501e05bc44b
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption parseFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseFrom(input, extensionRegistry);}
e32f866eb7533a232fadc4ef42bb022716435f415dc4a0f7ed4fff845f45ead0
newBuilder
public static Builder newBuilder()
{    return Builder.create();}
a2589243249ba32b92e98298a2511019cd74b21c911d510f075da5ff7e8b6399
newBuilderForType
public Builder newBuilderForType()
{    return newBuilder();}
46d131e94327bd6e364b26730b51771cdeead51e9ce00f9e3a314e51276c3bd4
newBuilder
public static Builder newBuilder(org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption prototype)
{    return newBuilder().mergeFrom(prototype);}
8f9c3ced03d87377003831ec6560ea40c4b718fc762fc1ca14b030b0ed8256d4
toBuilder
public Builder toBuilder()
{    return newBuilder(this);}
2a4c0cac516d5bc4a1109ad4c836ca7b20e2bab822eb3f5bbb7c506c60fb0415
newBuilderForType
protected Builder newBuilderForType(com.google.protobuf.GeneratedMessage.BuilderParent parent)
{    Builder builder = new Builder(parent);    return builder;}
e061a4269a7822f30b36dfe5c448257acd508bbe5bfe85e23841ca998b986e73
getDescriptor
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_LogFileEncryption_descriptor;}
14146f9740b0a47326835ccc62490511ca2c1acd8a7ad735c50f15b98d8aa156
internalGetFieldAccessorTable
protected com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_LogFileEncryption_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption.class, org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption.Builder.class);}
7c751d7a2accff7e718ee1e6ea5d2457fe6e182e8c39098e52a8848f56cf2cfe
maybeForceBuilderInitialization
private void maybeForceBuilderInitialization()
{    if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {    }}
db452528a8bc9d155fa120bbe8533aa1eebe58fe8bf85ab33cdc1987e2489b8f
create
private static Builder create()
{    return new Builder();}
7930c451f279d9927ff235e4ac064561e1505f9b7ae117d9f681b345534ff9e3
clear
public Builder clear()
{    super.clear();    cipherProvider_ = "";    bitField0_ = (bitField0_ & ~0x00000001);    keyAlias_ = "";    bitField0_ = (bitField0_ & ~0x00000002);    parameters_ = com.google.protobuf.ByteString.EMPTY;    bitField0_ = (bitField0_ & ~0x00000004);    return this;}
845fff95a97cf125489126ddee47248563aa80a59ed327d7d1c7cb9d90dcec30
clone
public Builder clone()
{    return create().mergeFrom(buildPartial());}
5a2efdcbff6cd8f893a197208cee010e41df6afb0e928da5d7126d953902ee30
getDescriptorForType
public com.google.protobuf.Descriptors.Descriptor getDescriptorForType()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_LogFileEncryption_descriptor;}
4703d1b3f17012133b3ef81161eb4f4b37b88e8c7bcb3ed2e6265a552e00590c
getDefaultInstanceForType
public org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption getDefaultInstanceForType()
{    return org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption.getDefaultInstance();}
1f8e6a19376d4ce61f5c237f340fecbc22e863050e9888e847a88856a3f168e0
build
public org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption build()
{    org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption result = buildPartial();    if (!result.isInitialized()) {        throw newUninitializedMessageException(result);    }    return result;}
0c053153b9a0a0ba54ad6412aec102ceb9a408ba8a76d3f23dbe4b5030dfc49b
buildPartial
public org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption buildPartial()
{    org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption result = new org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption(this);    int from_bitField0_ = bitField0_;    int to_bitField0_ = 0;    if (((from_bitField0_ & 0x00000001) == 0x00000001)) {        to_bitField0_ |= 0x00000001;    }    result.cipherProvider_ = cipherProvider_;    if (((from_bitField0_ & 0x00000002) == 0x00000002)) {        to_bitField0_ |= 0x00000002;    }    result.keyAlias_ = keyAlias_;    if (((from_bitField0_ & 0x00000004) == 0x00000004)) {        to_bitField0_ |= 0x00000004;    }    result.parameters_ = parameters_;    result.bitField0_ = to_bitField0_;    onBuilt();    return result;}
9c02b14012758934fbc876f583b7201b524cfd4dce350a6fd2cdeea1bb86b6f9
mergeFrom
public Builder mergeFrom(com.google.protobuf.Message other)
{    if (other instanceof org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption) {        return mergeFrom((org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption) other);    } else {        super.mergeFrom(other);        return this;    }}
1045cb0f861697cfa26f1f888c62d0c939a5f1fc2c2ca12e5aafc197b4d12144
mergeFrom
public Builder mergeFrom(org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption other)
{    if (other == org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption.getDefaultInstance())        return this;    if (other.hasCipherProvider()) {        bitField0_ |= 0x00000001;        cipherProvider_ = other.cipherProvider_;        onChanged();    }    if (other.hasKeyAlias()) {        bitField0_ |= 0x00000002;        keyAlias_ = other.keyAlias_;        onChanged();    }    if (other.hasParameters()) {        setParameters(other.getParameters());    }    this.mergeUnknownFields(other.getUnknownFields());    return this;}
dde7cd718eaa61cad29906454acf122daba6680a2db55e4787a359a08951b5e7
isInitialized
public final boolean isInitialized()
{    if (!hasCipherProvider()) {        return false;    }    if (!hasKeyAlias()) {        return false;    }    return true;}
576f0ac95d3431feb1ba705ec8f537aa5e5a58300021599ce7c111ed9b61d887
mergeFrom
public Builder mergeFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption parsedMessage = null;    try {        parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);    } catch (com.google.protobuf.InvalidProtocolBufferException e) {        parsedMessage = (org.apache.flume.channel.file.proto.ProtosFactory.LogFileEncryption) e.getUnfinishedMessage();        throw e;    } finally {        if (parsedMessage != null) {            mergeFrom(parsedMessage);        }    }    return this;}
30facdd23ef3b9b68574b8d86f5e91314fd801e518d906995ff445aa21d44924
hasCipherProvider
public boolean hasCipherProvider()
{    return ((bitField0_ & 0x00000001) == 0x00000001);}
827d104322f79595d7ba2be2d4e55168389adf62ce3bd39540a6e8290723231f
getCipherProvider
public java.lang.String getCipherProvider()
{    java.lang.Object ref = cipherProvider_;    if (!(ref instanceof java.lang.String)) {        java.lang.String s = ((com.google.protobuf.ByteString) ref).toStringUtf8();        cipherProvider_ = s;        return s;    } else {        return (java.lang.String) ref;    }}
c979ba1e8f0f60c964d31635a70f0dc39929afa40a87d8f995f3e4bd822c1afe
getCipherProviderBytes
public com.google.protobuf.ByteString getCipherProviderBytes()
{    java.lang.Object ref = cipherProvider_;    if (ref instanceof String) {        com.google.protobuf.ByteString b = com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);        cipherProvider_ = b;        return b;    } else {        return (com.google.protobuf.ByteString) ref;    }}
f139cab8a127cdf037130393b9d3e8fd65d68e5bd8303c8ee31d967205d8a16f
setCipherProvider
public Builder setCipherProvider(java.lang.String value)
{    if (value == null) {        throw new NullPointerException();    }    bitField0_ |= 0x00000001;    cipherProvider_ = value;    onChanged();    return this;}
a29e22322598f7e847b354aa0164708e570f14f17adf4fbee501592733c93142
clearCipherProvider
public Builder clearCipherProvider()
{    bitField0_ = (bitField0_ & ~0x00000001);    cipherProvider_ = getDefaultInstance().getCipherProvider();    onChanged();    return this;}
34f1a1549b7f727a8ac9f6dd8eed2c88bc9d8788bfc159486a9a0aad0ba1b3ee
setCipherProviderBytes
public Builder setCipherProviderBytes(com.google.protobuf.ByteString value)
{    if (value == null) {        throw new NullPointerException();    }    bitField0_ |= 0x00000001;    cipherProvider_ = value;    onChanged();    return this;}
f7fac6911ba777daceb24850da777b3a0880ac0f4589da7f7fab9f526cf2d776
hasKeyAlias
public boolean hasKeyAlias()
{    return ((bitField0_ & 0x00000002) == 0x00000002);}
e5279762cdda8ee3a53c91e672e1426a7ee74dc9c38792079a008c9ad8b3563f
getKeyAlias
public java.lang.String getKeyAlias()
{    java.lang.Object ref = keyAlias_;    if (!(ref instanceof java.lang.String)) {        java.lang.String s = ((com.google.protobuf.ByteString) ref).toStringUtf8();        keyAlias_ = s;        return s;    } else {        return (java.lang.String) ref;    }}
2565ed0702b2cb7cf596c97172d78448ee7a55beafd1c99e09ade4dab34399f7
getKeyAliasBytes
public com.google.protobuf.ByteString getKeyAliasBytes()
{    java.lang.Object ref = keyAlias_;    if (ref instanceof String) {        com.google.protobuf.ByteString b = com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);        keyAlias_ = b;        return b;    } else {        return (com.google.protobuf.ByteString) ref;    }}
5cb41a6095a2da8421d1301ad2a5510ddcc3ada05ba4f8aed894ba98ba3e2507
setKeyAlias
public Builder setKeyAlias(java.lang.String value)
{    if (value == null) {        throw new NullPointerException();    }    bitField0_ |= 0x00000002;    keyAlias_ = value;    onChanged();    return this;}
3ccd4fe1590e705365077c86165c6e37da3c9979d42966a34c254054fee3444c
clearKeyAlias
public Builder clearKeyAlias()
{    bitField0_ = (bitField0_ & ~0x00000002);    keyAlias_ = getDefaultInstance().getKeyAlias();    onChanged();    return this;}
1c0c29ddfdcc1045248c0db14ca98b6375b2cc60820ab870573f81dea80334bb
setKeyAliasBytes
public Builder setKeyAliasBytes(com.google.protobuf.ByteString value)
{    if (value == null) {        throw new NullPointerException();    }    bitField0_ |= 0x00000002;    keyAlias_ = value;    onChanged();    return this;}
3873b34a7e026fb583c295e16276c0d84bd2bf586beccc2b1384ed72807589e8
hasParameters
public boolean hasParameters()
{    return ((bitField0_ & 0x00000004) == 0x00000004);}
ac23878f46864ceaf60dd9f398b6aa0b6a97681547c6c2a26d91a833699933fd
getParameters
public com.google.protobuf.ByteString getParameters()
{    return parameters_;}
3f88273468aa85e16b10c9306662bb04955d52359cbfbb0ba1bea74e604b97e0
setParameters
public Builder setParameters(com.google.protobuf.ByteString value)
{    if (value == null) {        throw new NullPointerException();    }    bitField0_ |= 0x00000004;    parameters_ = value;    onChanged();    return this;}
051576aef894c2b1756dfe8ed39e0dc83ce7d4ccc898958880ad606e87937415
clearParameters
public Builder clearParameters()
{    bitField0_ = (bitField0_ & ~0x00000004);    parameters_ = getDefaultInstance().getParameters();    onChanged();    return this;}
13c91d13e6cbafcc95454b04ca18942cc133f392582b0b915a95b38172dabdad
getDefaultInstance
public static TransactionEventHeader getDefaultInstance()
{    return defaultInstance;}
5c9bcc6bcb2b83cff41e671068561fb3b9df41917fdaf158b29d55f8fe1179ec
getDefaultInstanceForType
public TransactionEventHeader getDefaultInstanceForType()
{    return defaultInstance;}
afeb2882aee0a13dc444e9d430b86a6dc175c48ee917722e2d5ab50801b7ab38
getUnknownFields
public final com.google.protobuf.UnknownFieldSet getUnknownFields()
{    return this.unknownFields;}
e061a4269a7822f30b36dfe5c448257acd508bbe5bfe85e23841ca998b986e73
getDescriptor
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_TransactionEventHeader_descriptor;}
14146f9740b0a47326835ccc62490511ca2c1acd8a7ad735c50f15b98d8aa156
internalGetFieldAccessorTable
protected com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_TransactionEventHeader_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader.class, org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader.Builder.class);}
5327b469bd56b71a9d74640074f0363ea59943bcc3ed148592cd211ddd7eff83
parsePartialFrom
public TransactionEventHeader parsePartialFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return new TransactionEventHeader(input, extensionRegistry);}
af8de14d47ce7ece17e70dee48a745c5cc19eb79a46c152ffc33733514bc1f3c
getParserForType
public com.google.protobuf.Parser<TransactionEventHeader> getParserForType()
{    return PARSER;}
4ac9c8bdb45364b8bdef0861dc92b4de77e1341d7edd5064d476c713d0cf58da
hasType
public boolean hasType()
{    return ((bitField0_ & 0x00000001) == 0x00000001);}
e13ca6770d128854311e967cbfe111c5323a9155e542cbb6a563c89bfcce6811
getType
public int getType()
{    return type_;}
442725da080e76c9a0028510c49c171116d05d5fbfb1bb6636c045624beb2ed8
hasTransactionID
public boolean hasTransactionID()
{    return ((bitField0_ & 0x00000002) == 0x00000002);}
25de822ce0aedb3bc656eef85eacbed67412b6218160e7b158f97ebef1b969fc
getTransactionID
public long getTransactionID()
{    return transactionID_;}
666ebf72ef9522ec373bacef4fec39f5ed7488bd91fe541a94edbb3e4a724dfa
hasWriteOrderID
public boolean hasWriteOrderID()
{    return ((bitField0_ & 0x00000004) == 0x00000004);}
65bbe4b4f5e1caf2299d87699fa774a6e959dcca7e06f38d7c26ff5c8e868db5
getWriteOrderID
public long getWriteOrderID()
{    return writeOrderID_;}
3eb5746a869e932254ccd9230e2597001e979870dcff9439accc4b8a5e5b6007
initFields
private void initFields()
{    type_ = 0;    transactionID_ = 0L;    writeOrderID_ = 0L;}
dde7cd718eaa61cad29906454acf122daba6680a2db55e4787a359a08951b5e7
isInitialized
public final boolean isInitialized()
{    byte isInitialized = memoizedIsInitialized;    if (isInitialized != -1)        return isInitialized == 1;    if (!hasType()) {        memoizedIsInitialized = 0;        return false;    }    if (!hasTransactionID()) {        memoizedIsInitialized = 0;        return false;    }    if (!hasWriteOrderID()) {        memoizedIsInitialized = 0;        return false;    }    memoizedIsInitialized = 1;    return true;}
b78da5ac0d0f56440a60e0c8711e74775e8d0aafe7882e5346a5dcc6fa783f73
writeTo
public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException
{    getSerializedSize();    if (((bitField0_ & 0x00000001) == 0x00000001)) {        output.writeSFixed32(1, type_);    }    if (((bitField0_ & 0x00000002) == 0x00000002)) {        output.writeSFixed64(2, transactionID_);    }    if (((bitField0_ & 0x00000004) == 0x00000004)) {        output.writeSFixed64(3, writeOrderID_);    }    getUnknownFields().writeTo(output);}
2bd67191ad73644076f3a74f7b306983cf9bd449d2e535f9b7f802bd0492f9f1
getSerializedSize
public int getSerializedSize()
{    int size = memoizedSerializedSize;    if (size != -1)        return size;    size = 0;    if (((bitField0_ & 0x00000001) == 0x00000001)) {        size += com.google.protobuf.CodedOutputStream.computeSFixed32Size(1, type_);    }    if (((bitField0_ & 0x00000002) == 0x00000002)) {        size += com.google.protobuf.CodedOutputStream.computeSFixed64Size(2, transactionID_);    }    if (((bitField0_ & 0x00000004) == 0x00000004)) {        size += com.google.protobuf.CodedOutputStream.computeSFixed64Size(3, writeOrderID_);    }    size += getUnknownFields().getSerializedSize();    memoizedSerializedSize = size;    return size;}
969c11f748ec8e7ea2d7ab9b282e6a50da757a9197e9f5c9c8a8c921b705557f
writeReplace
protected java.lang.Object writeReplace() throws java.io.ObjectStreamException
{    return super.writeReplace();}
b76db30b2253f3d8c72f89fe65ab43b7f8b475d539082c5ad522752f26bbb7b8
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader parseFrom(com.google.protobuf.ByteString data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
673cc52dee1d2c4937f7fc256a95f651da286bb3c6f16ec430043663dd16dcf0
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader parseFrom(com.google.protobuf.ByteString data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
ff23498dc7be1214b05ac0cf91f0fb361f15ce652a122e60e6c6cb1dabca4ffe
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader parseFrom(byte[] data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
9aace6481e2644be4a7a99bab3488f5cbcb4cc45fc303688fad9dd67a2cfad20
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader parseFrom(byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
7f9da8ec71a2d2180e46e49b50f5350c272d05ce1ca34764349c81ea60b73576
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader parseFrom(java.io.InputStream input) throws java.io.IOException
{    return PARSER.parseFrom(input);}
c27b47c279158f15d4e4414a0f202a1534370cf8480c711f7ad7e85832012fa4
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader parseFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseFrom(input, extensionRegistry);}
3de60382b865be7019c07ea753424e6daeecd25092b46d738a5342a212b53cae
parseDelimitedFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader parseDelimitedFrom(java.io.InputStream input) throws java.io.IOException
{    return PARSER.parseDelimitedFrom(input);}
28b91b2a42e78f71bbf39042c5e6bc912e7560793568861e2ddfead9e20ed788
parseDelimitedFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader parseDelimitedFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseDelimitedFrom(input, extensionRegistry);}
e28a163a15d1700adbe6480dfc5da7980bc846ea39fcb115e42c4d52a45a6c2a
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader parseFrom(com.google.protobuf.CodedInputStream input) throws java.io.IOException
{    return PARSER.parseFrom(input);}
1b07f09b2dc93a75972d05f8a05c804e8a7b344ee95c0f76b4ec5c518bb3c1b2
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader parseFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseFrom(input, extensionRegistry);}
e32f866eb7533a232fadc4ef42bb022716435f415dc4a0f7ed4fff845f45ead0
newBuilder
public static Builder newBuilder()
{    return Builder.create();}
a2589243249ba32b92e98298a2511019cd74b21c911d510f075da5ff7e8b6399
newBuilderForType
public Builder newBuilderForType()
{    return newBuilder();}
0fb0985649a6dfff6d3e72449d3ad3487de327563db9dd8851f32f81ddf739f9
newBuilder
public static Builder newBuilder(org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader prototype)
{    return newBuilder().mergeFrom(prototype);}
8f9c3ced03d87377003831ec6560ea40c4b718fc762fc1ca14b030b0ed8256d4
toBuilder
public Builder toBuilder()
{    return newBuilder(this);}
2a4c0cac516d5bc4a1109ad4c836ca7b20e2bab822eb3f5bbb7c506c60fb0415
newBuilderForType
protected Builder newBuilderForType(com.google.protobuf.GeneratedMessage.BuilderParent parent)
{    Builder builder = new Builder(parent);    return builder;}
e061a4269a7822f30b36dfe5c448257acd508bbe5bfe85e23841ca998b986e73
getDescriptor
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_TransactionEventHeader_descriptor;}
14146f9740b0a47326835ccc62490511ca2c1acd8a7ad735c50f15b98d8aa156
internalGetFieldAccessorTable
protected com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_TransactionEventHeader_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader.class, org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader.Builder.class);}
7c751d7a2accff7e718ee1e6ea5d2457fe6e182e8c39098e52a8848f56cf2cfe
maybeForceBuilderInitialization
private void maybeForceBuilderInitialization()
{    if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {    }}
db452528a8bc9d155fa120bbe8533aa1eebe58fe8bf85ab33cdc1987e2489b8f
create
private static Builder create()
{    return new Builder();}
7930c451f279d9927ff235e4ac064561e1505f9b7ae117d9f681b345534ff9e3
clear
public Builder clear()
{    super.clear();    type_ = 0;    bitField0_ = (bitField0_ & ~0x00000001);    transactionID_ = 0L;    bitField0_ = (bitField0_ & ~0x00000002);    writeOrderID_ = 0L;    bitField0_ = (bitField0_ & ~0x00000004);    return this;}
845fff95a97cf125489126ddee47248563aa80a59ed327d7d1c7cb9d90dcec30
clone
public Builder clone()
{    return create().mergeFrom(buildPartial());}
5a2efdcbff6cd8f893a197208cee010e41df6afb0e928da5d7126d953902ee30
getDescriptorForType
public com.google.protobuf.Descriptors.Descriptor getDescriptorForType()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_TransactionEventHeader_descriptor;}
30b24ee2ccc53a20c3340a58875e9f4b27aa84cbf1501fffd67b3b455720bdaf
getDefaultInstanceForType
public org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader getDefaultInstanceForType()
{    return org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader.getDefaultInstance();}
191ae57ca8a82dc3ad01199599f2b2795ba97ed064330e4a2de025c245dc5535
build
public org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader build()
{    org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader result = buildPartial();    if (!result.isInitialized()) {        throw newUninitializedMessageException(result);    }    return result;}
ad6ca49af4165053d5742db3762e2fadd72624e1bf94e5c3f8b9b35d9b89a32c
buildPartial
public org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader buildPartial()
{    org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader result = new org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader(this);    int from_bitField0_ = bitField0_;    int to_bitField0_ = 0;    if (((from_bitField0_ & 0x00000001) == 0x00000001)) {        to_bitField0_ |= 0x00000001;    }    result.type_ = type_;    if (((from_bitField0_ & 0x00000002) == 0x00000002)) {        to_bitField0_ |= 0x00000002;    }    result.transactionID_ = transactionID_;    if (((from_bitField0_ & 0x00000004) == 0x00000004)) {        to_bitField0_ |= 0x00000004;    }    result.writeOrderID_ = writeOrderID_;    result.bitField0_ = to_bitField0_;    onBuilt();    return result;}
9c02b14012758934fbc876f583b7201b524cfd4dce350a6fd2cdeea1bb86b6f9
mergeFrom
public Builder mergeFrom(com.google.protobuf.Message other)
{    if (other instanceof org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader) {        return mergeFrom((org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader) other);    } else {        super.mergeFrom(other);        return this;    }}
d1916f32f1a7602108f378bd31075927c95699ff0a1521a463813f5631e4314f
mergeFrom
public Builder mergeFrom(org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader other)
{    if (other == org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader.getDefaultInstance())        return this;    if (other.hasType()) {        setType(other.getType());    }    if (other.hasTransactionID()) {        setTransactionID(other.getTransactionID());    }    if (other.hasWriteOrderID()) {        setWriteOrderID(other.getWriteOrderID());    }    this.mergeUnknownFields(other.getUnknownFields());    return this;}
dde7cd718eaa61cad29906454acf122daba6680a2db55e4787a359a08951b5e7
isInitialized
public final boolean isInitialized()
{    if (!hasType()) {        return false;    }    if (!hasTransactionID()) {        return false;    }    if (!hasWriteOrderID()) {        return false;    }    return true;}
576f0ac95d3431feb1ba705ec8f537aa5e5a58300021599ce7c111ed9b61d887
mergeFrom
public Builder mergeFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader parsedMessage = null;    try {        parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);    } catch (com.google.protobuf.InvalidProtocolBufferException e) {        parsedMessage = (org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventHeader) e.getUnfinishedMessage();        throw e;    } finally {        if (parsedMessage != null) {            mergeFrom(parsedMessage);        }    }    return this;}
4ac9c8bdb45364b8bdef0861dc92b4de77e1341d7edd5064d476c713d0cf58da
hasType
public boolean hasType()
{    return ((bitField0_ & 0x00000001) == 0x00000001);}
e13ca6770d128854311e967cbfe111c5323a9155e542cbb6a563c89bfcce6811
getType
public int getType()
{    return type_;}
271e5b7cc262226c64b87a5b4575c3a23786db4662acea052c8e63718dec6140
setType
public Builder setType(int value)
{    bitField0_ |= 0x00000001;    type_ = value;    onChanged();    return this;}
20943f6fd4102c4b33b82c7b1390d3b35b1ccc148abd3b605ca0411637f7a028
clearType
public Builder clearType()
{    bitField0_ = (bitField0_ & ~0x00000001);    type_ = 0;    onChanged();    return this;}
442725da080e76c9a0028510c49c171116d05d5fbfb1bb6636c045624beb2ed8
hasTransactionID
public boolean hasTransactionID()
{    return ((bitField0_ & 0x00000002) == 0x00000002);}
25de822ce0aedb3bc656eef85eacbed67412b6218160e7b158f97ebef1b969fc
getTransactionID
public long getTransactionID()
{    return transactionID_;}
9519a46b4b7d1bc3b12db61ff014d03d58ee9ee9e0f9d3df12dd78dfd27d3ae4
setTransactionID
public Builder setTransactionID(long value)
{    bitField0_ |= 0x00000002;    transactionID_ = value;    onChanged();    return this;}
236e0b01bc398dc84a829502ed280000e3d63e0a0a8437c281c7e7a0db5252ee
clearTransactionID
public Builder clearTransactionID()
{    bitField0_ = (bitField0_ & ~0x00000002);    transactionID_ = 0L;    onChanged();    return this;}
666ebf72ef9522ec373bacef4fec39f5ed7488bd91fe541a94edbb3e4a724dfa
hasWriteOrderID
public boolean hasWriteOrderID()
{    return ((bitField0_ & 0x00000004) == 0x00000004);}
65bbe4b4f5e1caf2299d87699fa774a6e959dcca7e06f38d7c26ff5c8e868db5
getWriteOrderID
public long getWriteOrderID()
{    return writeOrderID_;}
6129623f36f3348ae2a0d4fbb222328d51c7621d30dd86914fbaaed042afb1ec
setWriteOrderID
public Builder setWriteOrderID(long value)
{    bitField0_ |= 0x00000004;    writeOrderID_ = value;    onChanged();    return this;}
88a3be5748ebf09087d1b25cf8681be82200e0ca88acbb46c576ec509f14c684
clearWriteOrderID
public Builder clearWriteOrderID()
{    bitField0_ = (bitField0_ & ~0x00000004);    writeOrderID_ = 0L;    onChanged();    return this;}
efbb197d7c5f05d5f8f0ebfe9e4e599f998eacc2945ff0594bd45fe5ad0018b7
getDefaultInstance
public static Put getDefaultInstance()
{    return defaultInstance;}
ee63d9d60c6ff77f8813b004fdc113ec82556618664ed67256ef4b267f0eb6e4
getDefaultInstanceForType
public Put getDefaultInstanceForType()
{    return defaultInstance;}
afeb2882aee0a13dc444e9d430b86a6dc175c48ee917722e2d5ab50801b7ab38
getUnknownFields
public final com.google.protobuf.UnknownFieldSet getUnknownFields()
{    return this.unknownFields;}
e061a4269a7822f30b36dfe5c448257acd508bbe5bfe85e23841ca998b986e73
getDescriptor
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Put_descriptor;}
14146f9740b0a47326835ccc62490511ca2c1acd8a7ad735c50f15b98d8aa156
internalGetFieldAccessorTable
protected com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Put_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.flume.channel.file.proto.ProtosFactory.Put.class, org.apache.flume.channel.file.proto.ProtosFactory.Put.Builder.class);}
aac072d707eae89d30d38e1a9962dfca5babece5bfe98c8313dea60854bb8a2f
parsePartialFrom
public Put parsePartialFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return new Put(input, extensionRegistry);}
e7906a47edcee940c30abb98b7798c803c9ab7daf8d41d787a98c24fa3db9f7c
getParserForType
public com.google.protobuf.Parser<Put> getParserForType()
{    return PARSER;}
d7361c99dc1e1d730fc6746e49a7be7d91260f0ee66dfa2669deadd13f4adfe1
hasEvent
public boolean hasEvent()
{    return ((bitField0_ & 0x00000001) == 0x00000001);}
49b967c05c02f4483b4b572327ac12caa9cad4f13a73e98b6dd8035272651a97
getEvent
public org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent getEvent()
{    return event_;}
4495cfaf819d27b24b14bae3a098255c5081b0c494fcfbb6d517c0a7a17e30a9
getEventOrBuilder
public org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventOrBuilder getEventOrBuilder()
{    return event_;}
01dafc26472f684224d5624f027f02ffd9463d4c85aa87711af43e77cd91a803
hasChecksum
public boolean hasChecksum()
{    return ((bitField0_ & 0x00000002) == 0x00000002);}
c7006660efb96692079d648b472fc889d4d3a39d327551d3625c34e89b92c6d7
getChecksum
public long getChecksum()
{    return checksum_;}
3eb5746a869e932254ccd9230e2597001e979870dcff9439accc4b8a5e5b6007
initFields
private void initFields()
{    event_ = org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent.getDefaultInstance();    checksum_ = 0L;}
dde7cd718eaa61cad29906454acf122daba6680a2db55e4787a359a08951b5e7
isInitialized
public final boolean isInitialized()
{    byte isInitialized = memoizedIsInitialized;    if (isInitialized != -1)        return isInitialized == 1;    if (!hasEvent()) {        memoizedIsInitialized = 0;        return false;    }    if (!getEvent().isInitialized()) {        memoizedIsInitialized = 0;        return false;    }    memoizedIsInitialized = 1;    return true;}
b78da5ac0d0f56440a60e0c8711e74775e8d0aafe7882e5346a5dcc6fa783f73
writeTo
public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException
{    getSerializedSize();    if (((bitField0_ & 0x00000001) == 0x00000001)) {        output.writeMessage(1, event_);    }    if (((bitField0_ & 0x00000002) == 0x00000002)) {        output.writeSFixed64(2, checksum_);    }    getUnknownFields().writeTo(output);}
2bd67191ad73644076f3a74f7b306983cf9bd449d2e535f9b7f802bd0492f9f1
getSerializedSize
public int getSerializedSize()
{    int size = memoizedSerializedSize;    if (size != -1)        return size;    size = 0;    if (((bitField0_ & 0x00000001) == 0x00000001)) {        size += com.google.protobuf.CodedOutputStream.computeMessageSize(1, event_);    }    if (((bitField0_ & 0x00000002) == 0x00000002)) {        size += com.google.protobuf.CodedOutputStream.computeSFixed64Size(2, checksum_);    }    size += getUnknownFields().getSerializedSize();    memoizedSerializedSize = size;    return size;}
969c11f748ec8e7ea2d7ab9b282e6a50da757a9197e9f5c9c8a8c921b705557f
writeReplace
protected java.lang.Object writeReplace() throws java.io.ObjectStreamException
{    return super.writeReplace();}
585391a77be6f16f9d87d236b3067317d32157fd8f2dc4a74dcd0b0be88c7819
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Put parseFrom(com.google.protobuf.ByteString data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
2920fa3312543fe81f1ad4023759c505792df80811c6ab59267d5f8cda22e32d
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Put parseFrom(com.google.protobuf.ByteString data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
d53f8257dbcb89b0f38ab14eb3639131279ca330922115cc39b8d9bb581ab684
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Put parseFrom(byte[] data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
5cdcca9eae1d33ffaa6e90a53dcd25d88ce5fdd297f63a34f08256ba4e0c67e8
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Put parseFrom(byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
1e694b04cc8fba19625bd9de8a81a3e770194ea06abaca1d3054ffe7816601a7
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Put parseFrom(java.io.InputStream input) throws java.io.IOException
{    return PARSER.parseFrom(input);}
e794254047805bcfddd8c9b53c9443fb8d101d0c249617b1b3ef966f87b346ab
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Put parseFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseFrom(input, extensionRegistry);}
a7ea58d6fe750e3caa95e9b871e698777ec9a6dbcebb8d02a72a6b5b74c6b642
parseDelimitedFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Put parseDelimitedFrom(java.io.InputStream input) throws java.io.IOException
{    return PARSER.parseDelimitedFrom(input);}
f868b6f5954a8a77f3d7566a1f46ebb871d651aaddd8c077c52140b61ca64f19
parseDelimitedFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Put parseDelimitedFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseDelimitedFrom(input, extensionRegistry);}
9b897aa1b6c796b59cfcfce5f7b3881dc1fa9cc7ab3411d90812fa61006ad47b
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Put parseFrom(com.google.protobuf.CodedInputStream input) throws java.io.IOException
{    return PARSER.parseFrom(input);}
2152c1890bf9950a471d87d34e407552a0b41d694f00026a2396d3c318d95733
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Put parseFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseFrom(input, extensionRegistry);}
e32f866eb7533a232fadc4ef42bb022716435f415dc4a0f7ed4fff845f45ead0
newBuilder
public static Builder newBuilder()
{    return Builder.create();}
a2589243249ba32b92e98298a2511019cd74b21c911d510f075da5ff7e8b6399
newBuilderForType
public Builder newBuilderForType()
{    return newBuilder();}
c5d05932ac590ee034aec4a80cd3f521b9d9c70e6a2349fb30d9c4bd48bb8c13
newBuilder
public static Builder newBuilder(org.apache.flume.channel.file.proto.ProtosFactory.Put prototype)
{    return newBuilder().mergeFrom(prototype);}
8f9c3ced03d87377003831ec6560ea40c4b718fc762fc1ca14b030b0ed8256d4
toBuilder
public Builder toBuilder()
{    return newBuilder(this);}
2a4c0cac516d5bc4a1109ad4c836ca7b20e2bab822eb3f5bbb7c506c60fb0415
newBuilderForType
protected Builder newBuilderForType(com.google.protobuf.GeneratedMessage.BuilderParent parent)
{    Builder builder = new Builder(parent);    return builder;}
e061a4269a7822f30b36dfe5c448257acd508bbe5bfe85e23841ca998b986e73
getDescriptor
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Put_descriptor;}
14146f9740b0a47326835ccc62490511ca2c1acd8a7ad735c50f15b98d8aa156
internalGetFieldAccessorTable
protected com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Put_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.flume.channel.file.proto.ProtosFactory.Put.class, org.apache.flume.channel.file.proto.ProtosFactory.Put.Builder.class);}
7c751d7a2accff7e718ee1e6ea5d2457fe6e182e8c39098e52a8848f56cf2cfe
maybeForceBuilderInitialization
private void maybeForceBuilderInitialization()
{    if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {        getEventFieldBuilder();    }}
db452528a8bc9d155fa120bbe8533aa1eebe58fe8bf85ab33cdc1987e2489b8f
create
private static Builder create()
{    return new Builder();}
7930c451f279d9927ff235e4ac064561e1505f9b7ae117d9f681b345534ff9e3
clear
public Builder clear()
{    super.clear();    if (eventBuilder_ == null) {        event_ = org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent.getDefaultInstance();    } else {        eventBuilder_.clear();    }    bitField0_ = (bitField0_ & ~0x00000001);    checksum_ = 0L;    bitField0_ = (bitField0_ & ~0x00000002);    return this;}
845fff95a97cf125489126ddee47248563aa80a59ed327d7d1c7cb9d90dcec30
clone
public Builder clone()
{    return create().mergeFrom(buildPartial());}
5a2efdcbff6cd8f893a197208cee010e41df6afb0e928da5d7126d953902ee30
getDescriptorForType
public com.google.protobuf.Descriptors.Descriptor getDescriptorForType()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Put_descriptor;}
79c0961d5aeaee2a0fb36e5a47372dc48c7ba37df86a817e1394f073c1973e18
getDefaultInstanceForType
public org.apache.flume.channel.file.proto.ProtosFactory.Put getDefaultInstanceForType()
{    return org.apache.flume.channel.file.proto.ProtosFactory.Put.getDefaultInstance();}
475807495114ba402956486fd02dc3f823b219638ae8bb145af1a381599119d0
build
public org.apache.flume.channel.file.proto.ProtosFactory.Put build()
{    org.apache.flume.channel.file.proto.ProtosFactory.Put result = buildPartial();    if (!result.isInitialized()) {        throw newUninitializedMessageException(result);    }    return result;}
0f781406b43cad7df5aa01ddc6f637c467e66845014489b9a203749f9e738db1
buildPartial
public org.apache.flume.channel.file.proto.ProtosFactory.Put buildPartial()
{    org.apache.flume.channel.file.proto.ProtosFactory.Put result = new org.apache.flume.channel.file.proto.ProtosFactory.Put(this);    int from_bitField0_ = bitField0_;    int to_bitField0_ = 0;    if (((from_bitField0_ & 0x00000001) == 0x00000001)) {        to_bitField0_ |= 0x00000001;    }    if (eventBuilder_ == null) {        result.event_ = event_;    } else {        result.event_ = eventBuilder_.build();    }    if (((from_bitField0_ & 0x00000002) == 0x00000002)) {        to_bitField0_ |= 0x00000002;    }    result.checksum_ = checksum_;    result.bitField0_ = to_bitField0_;    onBuilt();    return result;}
9c02b14012758934fbc876f583b7201b524cfd4dce350a6fd2cdeea1bb86b6f9
mergeFrom
public Builder mergeFrom(com.google.protobuf.Message other)
{    if (other instanceof org.apache.flume.channel.file.proto.ProtosFactory.Put) {        return mergeFrom((org.apache.flume.channel.file.proto.ProtosFactory.Put) other);    } else {        super.mergeFrom(other);        return this;    }}
3bf15b82f54bcff51352c35693d00ad6ec043f48dc71b2fc3b1263ca2b13b4b1
mergeFrom
public Builder mergeFrom(org.apache.flume.channel.file.proto.ProtosFactory.Put other)
{    if (other == org.apache.flume.channel.file.proto.ProtosFactory.Put.getDefaultInstance())        return this;    if (other.hasEvent()) {        mergeEvent(other.getEvent());    }    if (other.hasChecksum()) {        setChecksum(other.getChecksum());    }    this.mergeUnknownFields(other.getUnknownFields());    return this;}
dde7cd718eaa61cad29906454acf122daba6680a2db55e4787a359a08951b5e7
isInitialized
public final boolean isInitialized()
{    if (!hasEvent()) {        return false;    }    if (!getEvent().isInitialized()) {        return false;    }    return true;}
576f0ac95d3431feb1ba705ec8f537aa5e5a58300021599ce7c111ed9b61d887
mergeFrom
public Builder mergeFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    org.apache.flume.channel.file.proto.ProtosFactory.Put parsedMessage = null;    try {        parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);    } catch (com.google.protobuf.InvalidProtocolBufferException e) {        parsedMessage = (org.apache.flume.channel.file.proto.ProtosFactory.Put) e.getUnfinishedMessage();        throw e;    } finally {        if (parsedMessage != null) {            mergeFrom(parsedMessage);        }    }    return this;}
d7361c99dc1e1d730fc6746e49a7be7d91260f0ee66dfa2669deadd13f4adfe1
hasEvent
public boolean hasEvent()
{    return ((bitField0_ & 0x00000001) == 0x00000001);}
49b967c05c02f4483b4b572327ac12caa9cad4f13a73e98b6dd8035272651a97
getEvent
public org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent getEvent()
{    if (eventBuilder_ == null) {        return event_;    } else {        return eventBuilder_.getMessage();    }}
ffdfb633441d9f8f31d903560f6686acaa08763712bafd9e427f2e9c7a08b7ff
setEvent
public Builder setEvent(org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent value)
{    if (eventBuilder_ == null) {        if (value == null) {            throw new NullPointerException();        }        event_ = value;        onChanged();    } else {        eventBuilder_.setMessage(value);    }    bitField0_ |= 0x00000001;    return this;}
1de5dd3df1ba0ce017a31b3bd61df298f5f35d94ecb299ecb19e6d37fcb8d626
setEvent
public Builder setEvent(org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent.Builder builderForValue)
{    if (eventBuilder_ == null) {        event_ = builderForValue.build();        onChanged();    } else {        eventBuilder_.setMessage(builderForValue.build());    }    bitField0_ |= 0x00000001;    return this;}
5f91d0b70981410c6e516a8b49f91b321ab634a9e334a84c3cfe14dc7c554bcf
mergeEvent
public Builder mergeEvent(org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent value)
{    if (eventBuilder_ == null) {        if (((bitField0_ & 0x00000001) == 0x00000001) && event_ != org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent.getDefaultInstance()) {            event_ = org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent.newBuilder(event_).mergeFrom(value).buildPartial();        } else {            event_ = value;        }        onChanged();    } else {        eventBuilder_.mergeFrom(value);    }    bitField0_ |= 0x00000001;    return this;}
ca0a7f25cdd1bb45d89e46f655ebf96ecc2dff8756463ddcd58a346c5a6aa2c5
clearEvent
public Builder clearEvent()
{    if (eventBuilder_ == null) {        event_ = org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent.getDefaultInstance();        onChanged();    } else {        eventBuilder_.clear();    }    bitField0_ = (bitField0_ & ~0x00000001);    return this;}
09237a988bdd9b4dc1a57fc48df897e50ccd5b8daf36b97fc04e4af342077b04
getEventBuilder
public org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent.Builder getEventBuilder()
{    bitField0_ |= 0x00000001;    onChanged();    return getEventFieldBuilder().getBuilder();}
4495cfaf819d27b24b14bae3a098255c5081b0c494fcfbb6d517c0a7a17e30a9
getEventOrBuilder
public org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventOrBuilder getEventOrBuilder()
{    if (eventBuilder_ != null) {        return eventBuilder_.getMessageOrBuilder();    } else {        return event_;    }}
10e627146c76322a142e2acc7e8d4c7a5243f14aaa7af25fd0350a6686ffe90d
getEventFieldBuilder
private com.google.protobuf.SingleFieldBuilder<org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent, org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent.Builder, org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventOrBuilder> getEventFieldBuilder()
{    if (eventBuilder_ == null) {        eventBuilder_ = new com.google.protobuf.SingleFieldBuilder<org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent, org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent.Builder, org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventOrBuilder>(event_, getParentForChildren(), isClean());        event_ = null;    }    return eventBuilder_;}
01dafc26472f684224d5624f027f02ffd9463d4c85aa87711af43e77cd91a803
hasChecksum
public boolean hasChecksum()
{    return ((bitField0_ & 0x00000002) == 0x00000002);}
c7006660efb96692079d648b472fc889d4d3a39d327551d3625c34e89b92c6d7
getChecksum
public long getChecksum()
{    return checksum_;}
e08481754b33daad01890dba4f0116195fba61d19876a418279f8325e78df0e4
setChecksum
public Builder setChecksum(long value)
{    bitField0_ |= 0x00000002;    checksum_ = value;    onChanged();    return this;}
aee485f7a8aeaa80d2525c4707eb836ea6ddbfb41556edd1a5402c0d0f01eef3
clearChecksum
public Builder clearChecksum()
{    bitField0_ = (bitField0_ & ~0x00000002);    checksum_ = 0L;    onChanged();    return this;}
254a71655e33dbcef7728655c4edaa500d39ef010663201d7479189c743f0fb7
getDefaultInstance
public static Take getDefaultInstance()
{    return defaultInstance;}
aa0f4f4ff726c1d72de14a9a5bea07b31c48b54f60590fa4d46d0553fccf2231
getDefaultInstanceForType
public Take getDefaultInstanceForType()
{    return defaultInstance;}
afeb2882aee0a13dc444e9d430b86a6dc175c48ee917722e2d5ab50801b7ab38
getUnknownFields
public final com.google.protobuf.UnknownFieldSet getUnknownFields()
{    return this.unknownFields;}
e061a4269a7822f30b36dfe5c448257acd508bbe5bfe85e23841ca998b986e73
getDescriptor
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Take_descriptor;}
14146f9740b0a47326835ccc62490511ca2c1acd8a7ad735c50f15b98d8aa156
internalGetFieldAccessorTable
protected com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Take_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.flume.channel.file.proto.ProtosFactory.Take.class, org.apache.flume.channel.file.proto.ProtosFactory.Take.Builder.class);}
893053264307ece5e35b3455ebacb4d437c897c34c89bf4c7ae40f353fa3dcc8
parsePartialFrom
public Take parsePartialFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return new Take(input, extensionRegistry);}
a94d6ddce5fd1058ef9629bcc646117a0d10886cb148171f0ffbb3d0de35ab00
getParserForType
public com.google.protobuf.Parser<Take> getParserForType()
{    return PARSER;}
769d9aa30ed0e13754be51706815059e3aa58727a0a99177766d0b6e2e217b3a
hasFileID
public boolean hasFileID()
{    return ((bitField0_ & 0x00000001) == 0x00000001);}
360b2bfc246ce54778e6115e7d10cad4b1d433142ab79c8d8fab437091e0ec14
getFileID
public int getFileID()
{    return fileID_;}
b37284313d3e317efc0d7c66204796d5ab87d8c1f0c5e1cd464ce919dd0854ec
hasOffset
public boolean hasOffset()
{    return ((bitField0_ & 0x00000002) == 0x00000002);}
d50e038b298d330cb813a0c139773f71a1aa72016b2df3558e55bbec788582ff
getOffset
public int getOffset()
{    return offset_;}
3eb5746a869e932254ccd9230e2597001e979870dcff9439accc4b8a5e5b6007
initFields
private void initFields()
{    fileID_ = 0;    offset_ = 0;}
dde7cd718eaa61cad29906454acf122daba6680a2db55e4787a359a08951b5e7
isInitialized
public final boolean isInitialized()
{    byte isInitialized = memoizedIsInitialized;    if (isInitialized != -1)        return isInitialized == 1;    if (!hasFileID()) {        memoizedIsInitialized = 0;        return false;    }    if (!hasOffset()) {        memoizedIsInitialized = 0;        return false;    }    memoizedIsInitialized = 1;    return true;}
b78da5ac0d0f56440a60e0c8711e74775e8d0aafe7882e5346a5dcc6fa783f73
writeTo
public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException
{    getSerializedSize();    if (((bitField0_ & 0x00000001) == 0x00000001)) {        output.writeSFixed32(1, fileID_);    }    if (((bitField0_ & 0x00000002) == 0x00000002)) {        output.writeSFixed32(2, offset_);    }    getUnknownFields().writeTo(output);}
2bd67191ad73644076f3a74f7b306983cf9bd449d2e535f9b7f802bd0492f9f1
getSerializedSize
public int getSerializedSize()
{    int size = memoizedSerializedSize;    if (size != -1)        return size;    size = 0;    if (((bitField0_ & 0x00000001) == 0x00000001)) {        size += com.google.protobuf.CodedOutputStream.computeSFixed32Size(1, fileID_);    }    if (((bitField0_ & 0x00000002) == 0x00000002)) {        size += com.google.protobuf.CodedOutputStream.computeSFixed32Size(2, offset_);    }    size += getUnknownFields().getSerializedSize();    memoizedSerializedSize = size;    return size;}
969c11f748ec8e7ea2d7ab9b282e6a50da757a9197e9f5c9c8a8c921b705557f
writeReplace
protected java.lang.Object writeReplace() throws java.io.ObjectStreamException
{    return super.writeReplace();}
d9568a35d713cbef68791caf53d70227c4f7fc3388d6fa5deed5ca3531d02573
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Take parseFrom(com.google.protobuf.ByteString data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
9aee845d9e58d28e56768e21643fad31b44f7a47032714271b67edcd114cd804
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Take parseFrom(com.google.protobuf.ByteString data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
0236b703b13abf94fb772a66ff405a94c23b86d4d4934f838fdc836753bd6bd4
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Take parseFrom(byte[] data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
3eafd3039dcc5b948f2a93ce0ba6a17bd447bda4dbc9df254c609e795758d7f5
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Take parseFrom(byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
60675e4cb2f1684d7e1591f0c6a0f765a2b424ea7e5a575e43dd45810dcab197
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Take parseFrom(java.io.InputStream input) throws java.io.IOException
{    return PARSER.parseFrom(input);}
bd61ead11d6e0700692917f60108bbbccc703d0ae6ce2e83ce4cda57556028c0
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Take parseFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseFrom(input, extensionRegistry);}
51002bc739dbbeae9ca8b6724793ea90c647d3fdab924fc7b800de18999341ff
parseDelimitedFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Take parseDelimitedFrom(java.io.InputStream input) throws java.io.IOException
{    return PARSER.parseDelimitedFrom(input);}
0fb3386e36d40e974870a914028766f6761f3bc472ce464e9a5fa30f4881c8ba
parseDelimitedFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Take parseDelimitedFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseDelimitedFrom(input, extensionRegistry);}
c8b6315acdf0e187c28a6228ff2536bf960802f1739a936d1b945f51b8d80948
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Take parseFrom(com.google.protobuf.CodedInputStream input) throws java.io.IOException
{    return PARSER.parseFrom(input);}
8e2a9af2ef7386885058906d46949aa830c1776fa0d64f49e90c4d1db017e24f
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Take parseFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseFrom(input, extensionRegistry);}
e32f866eb7533a232fadc4ef42bb022716435f415dc4a0f7ed4fff845f45ead0
newBuilder
public static Builder newBuilder()
{    return Builder.create();}
a2589243249ba32b92e98298a2511019cd74b21c911d510f075da5ff7e8b6399
newBuilderForType
public Builder newBuilderForType()
{    return newBuilder();}
eda4434751566589f2359572cf47f890b1db2cb4418c003bd0983079dd2ad684
newBuilder
public static Builder newBuilder(org.apache.flume.channel.file.proto.ProtosFactory.Take prototype)
{    return newBuilder().mergeFrom(prototype);}
8f9c3ced03d87377003831ec6560ea40c4b718fc762fc1ca14b030b0ed8256d4
toBuilder
public Builder toBuilder()
{    return newBuilder(this);}
2a4c0cac516d5bc4a1109ad4c836ca7b20e2bab822eb3f5bbb7c506c60fb0415
newBuilderForType
protected Builder newBuilderForType(com.google.protobuf.GeneratedMessage.BuilderParent parent)
{    Builder builder = new Builder(parent);    return builder;}
e061a4269a7822f30b36dfe5c448257acd508bbe5bfe85e23841ca998b986e73
getDescriptor
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Take_descriptor;}
14146f9740b0a47326835ccc62490511ca2c1acd8a7ad735c50f15b98d8aa156
internalGetFieldAccessorTable
protected com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Take_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.flume.channel.file.proto.ProtosFactory.Take.class, org.apache.flume.channel.file.proto.ProtosFactory.Take.Builder.class);}
7c751d7a2accff7e718ee1e6ea5d2457fe6e182e8c39098e52a8848f56cf2cfe
maybeForceBuilderInitialization
private void maybeForceBuilderInitialization()
{    if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {    }}
db452528a8bc9d155fa120bbe8533aa1eebe58fe8bf85ab33cdc1987e2489b8f
create
private static Builder create()
{    return new Builder();}
7930c451f279d9927ff235e4ac064561e1505f9b7ae117d9f681b345534ff9e3
clear
public Builder clear()
{    super.clear();    fileID_ = 0;    bitField0_ = (bitField0_ & ~0x00000001);    offset_ = 0;    bitField0_ = (bitField0_ & ~0x00000002);    return this;}
845fff95a97cf125489126ddee47248563aa80a59ed327d7d1c7cb9d90dcec30
clone
public Builder clone()
{    return create().mergeFrom(buildPartial());}
5a2efdcbff6cd8f893a197208cee010e41df6afb0e928da5d7126d953902ee30
getDescriptorForType
public com.google.protobuf.Descriptors.Descriptor getDescriptorForType()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Take_descriptor;}
6cf95617783ab58c1ba2db0f9ee97812f92f7a988ab7935a999ec371f1397288
getDefaultInstanceForType
public org.apache.flume.channel.file.proto.ProtosFactory.Take getDefaultInstanceForType()
{    return org.apache.flume.channel.file.proto.ProtosFactory.Take.getDefaultInstance();}
fde401e4c85a6978c17b87e69c275e304550d4e7b0b4ad9e4ec0ac184ab02d39
build
public org.apache.flume.channel.file.proto.ProtosFactory.Take build()
{    org.apache.flume.channel.file.proto.ProtosFactory.Take result = buildPartial();    if (!result.isInitialized()) {        throw newUninitializedMessageException(result);    }    return result;}
e566ad7eca6022312760cd9cfaacb66934faa7d87aba190cded2a039f3932d34
buildPartial
public org.apache.flume.channel.file.proto.ProtosFactory.Take buildPartial()
{    org.apache.flume.channel.file.proto.ProtosFactory.Take result = new org.apache.flume.channel.file.proto.ProtosFactory.Take(this);    int from_bitField0_ = bitField0_;    int to_bitField0_ = 0;    if (((from_bitField0_ & 0x00000001) == 0x00000001)) {        to_bitField0_ |= 0x00000001;    }    result.fileID_ = fileID_;    if (((from_bitField0_ & 0x00000002) == 0x00000002)) {        to_bitField0_ |= 0x00000002;    }    result.offset_ = offset_;    result.bitField0_ = to_bitField0_;    onBuilt();    return result;}
9c02b14012758934fbc876f583b7201b524cfd4dce350a6fd2cdeea1bb86b6f9
mergeFrom
public Builder mergeFrom(com.google.protobuf.Message other)
{    if (other instanceof org.apache.flume.channel.file.proto.ProtosFactory.Take) {        return mergeFrom((org.apache.flume.channel.file.proto.ProtosFactory.Take) other);    } else {        super.mergeFrom(other);        return this;    }}
62644950341b2c5b49b4a542b1809eb05acfd69e888dcbdce9cd53eb51037d13
mergeFrom
public Builder mergeFrom(org.apache.flume.channel.file.proto.ProtosFactory.Take other)
{    if (other == org.apache.flume.channel.file.proto.ProtosFactory.Take.getDefaultInstance())        return this;    if (other.hasFileID()) {        setFileID(other.getFileID());    }    if (other.hasOffset()) {        setOffset(other.getOffset());    }    this.mergeUnknownFields(other.getUnknownFields());    return this;}
dde7cd718eaa61cad29906454acf122daba6680a2db55e4787a359a08951b5e7
isInitialized
public final boolean isInitialized()
{    if (!hasFileID()) {        return false;    }    if (!hasOffset()) {        return false;    }    return true;}
576f0ac95d3431feb1ba705ec8f537aa5e5a58300021599ce7c111ed9b61d887
mergeFrom
public Builder mergeFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    org.apache.flume.channel.file.proto.ProtosFactory.Take parsedMessage = null;    try {        parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);    } catch (com.google.protobuf.InvalidProtocolBufferException e) {        parsedMessage = (org.apache.flume.channel.file.proto.ProtosFactory.Take) e.getUnfinishedMessage();        throw e;    } finally {        if (parsedMessage != null) {            mergeFrom(parsedMessage);        }    }    return this;}
769d9aa30ed0e13754be51706815059e3aa58727a0a99177766d0b6e2e217b3a
hasFileID
public boolean hasFileID()
{    return ((bitField0_ & 0x00000001) == 0x00000001);}
360b2bfc246ce54778e6115e7d10cad4b1d433142ab79c8d8fab437091e0ec14
getFileID
public int getFileID()
{    return fileID_;}
0c43c33fffd44a8c87508c0ad5d0d06b57aba06006b7a879484943a1510ae6fd
setFileID
public Builder setFileID(int value)
{    bitField0_ |= 0x00000001;    fileID_ = value;    onChanged();    return this;}
8351dff70179fef4ca03a4f41ea21161e8dc7878b998549f00676bd6e85b85cf
clearFileID
public Builder clearFileID()
{    bitField0_ = (bitField0_ & ~0x00000001);    fileID_ = 0;    onChanged();    return this;}
b37284313d3e317efc0d7c66204796d5ab87d8c1f0c5e1cd464ce919dd0854ec
hasOffset
public boolean hasOffset()
{    return ((bitField0_ & 0x00000002) == 0x00000002);}
d50e038b298d330cb813a0c139773f71a1aa72016b2df3558e55bbec788582ff
getOffset
public int getOffset()
{    return offset_;}
b8742ff6efd274435ba47dabd4c0380a296c8f7e8324e6478389ae502897c383
setOffset
public Builder setOffset(int value)
{    bitField0_ |= 0x00000002;    offset_ = value;    onChanged();    return this;}
a49634948f3e05f737734d5f00491f3d8405e8bbd10a3343bf5b651e356960b0
clearOffset
public Builder clearOffset()
{    bitField0_ = (bitField0_ & ~0x00000002);    offset_ = 0;    onChanged();    return this;}
3be1977f210bb6a0e9a765ac7014a1da827ec843c3f7014b5dbedf309aeb86b7
getDefaultInstance
public static Rollback getDefaultInstance()
{    return defaultInstance;}
8edb32885240a85b25dc0c890a8f249d5a0587bd6ff361b56af576dfc8395300
getDefaultInstanceForType
public Rollback getDefaultInstanceForType()
{    return defaultInstance;}
afeb2882aee0a13dc444e9d430b86a6dc175c48ee917722e2d5ab50801b7ab38
getUnknownFields
public final com.google.protobuf.UnknownFieldSet getUnknownFields()
{    return this.unknownFields;}
e061a4269a7822f30b36dfe5c448257acd508bbe5bfe85e23841ca998b986e73
getDescriptor
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Rollback_descriptor;}
14146f9740b0a47326835ccc62490511ca2c1acd8a7ad735c50f15b98d8aa156
internalGetFieldAccessorTable
protected com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Rollback_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.flume.channel.file.proto.ProtosFactory.Rollback.class, org.apache.flume.channel.file.proto.ProtosFactory.Rollback.Builder.class);}
5c900dff48c5bb66db83e732de1a046aa58e292bfff6e5d484bdd78ace304809
parsePartialFrom
public Rollback parsePartialFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return new Rollback(input, extensionRegistry);}
68422462d83f606991700ecaff6da6e2632155e2c4569a61537454c1087b9ddd
getParserForType
public com.google.protobuf.Parser<Rollback> getParserForType()
{    return PARSER;}
3eb5746a869e932254ccd9230e2597001e979870dcff9439accc4b8a5e5b6007
initFields
private void initFields()
{}
dde7cd718eaa61cad29906454acf122daba6680a2db55e4787a359a08951b5e7
isInitialized
public final boolean isInitialized()
{    byte isInitialized = memoizedIsInitialized;    if (isInitialized != -1)        return isInitialized == 1;    memoizedIsInitialized = 1;    return true;}
b78da5ac0d0f56440a60e0c8711e74775e8d0aafe7882e5346a5dcc6fa783f73
writeTo
public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException
{    getSerializedSize();    getUnknownFields().writeTo(output);}
2bd67191ad73644076f3a74f7b306983cf9bd449d2e535f9b7f802bd0492f9f1
getSerializedSize
public int getSerializedSize()
{    int size = memoizedSerializedSize;    if (size != -1)        return size;    size = 0;    size += getUnknownFields().getSerializedSize();    memoizedSerializedSize = size;    return size;}
969c11f748ec8e7ea2d7ab9b282e6a50da757a9197e9f5c9c8a8c921b705557f
writeReplace
protected java.lang.Object writeReplace() throws java.io.ObjectStreamException
{    return super.writeReplace();}
7c4b4f851968c21aa09d89e17cf9062a63e132d646560712d14bdaa6e841967f
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Rollback parseFrom(com.google.protobuf.ByteString data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
6745906f7ad323a61d2813508c9ab65ad23805e2bf21d84d85d15dc3d4db98cb
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Rollback parseFrom(com.google.protobuf.ByteString data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
036e39d49176e2bb5a68580bf1740e6ba672f34c882fc72e8e78b247ea369dbf
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Rollback parseFrom(byte[] data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
407d9fdd5ae7bab72c64f1412d4e87ed48fe6f50e40748b48fbaf7e42798badb
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Rollback parseFrom(byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
3264d918847272d2479fb6005b3f8345b3d641d6e961faff1c9079b67e594aab
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Rollback parseFrom(java.io.InputStream input) throws java.io.IOException
{    return PARSER.parseFrom(input);}
73725b48dc51cd1feaddd3902b7b062769fc4d04ed5628ff27d7c14d2fd514bc
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Rollback parseFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseFrom(input, extensionRegistry);}
35dfb2d737002bdb79dd52ff5a93f55ac40c7c43310a424bc9e719a377c344bd
parseDelimitedFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Rollback parseDelimitedFrom(java.io.InputStream input) throws java.io.IOException
{    return PARSER.parseDelimitedFrom(input);}
a58f03fd61c5484ff5826ea9180628b687c1e2a17c880333e0f3447f3769d30c
parseDelimitedFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Rollback parseDelimitedFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseDelimitedFrom(input, extensionRegistry);}
6a78eef25c87f62ce366d6816635dd2e8d0e20f1dbe2437173449cf58653c67f
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Rollback parseFrom(com.google.protobuf.CodedInputStream input) throws java.io.IOException
{    return PARSER.parseFrom(input);}
8ea17590e87ad142f1eff7db25f094084ce034fdcaa9c008bda43e8eaadf9845
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Rollback parseFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseFrom(input, extensionRegistry);}
e32f866eb7533a232fadc4ef42bb022716435f415dc4a0f7ed4fff845f45ead0
newBuilder
public static Builder newBuilder()
{    return Builder.create();}
a2589243249ba32b92e98298a2511019cd74b21c911d510f075da5ff7e8b6399
newBuilderForType
public Builder newBuilderForType()
{    return newBuilder();}
cc5cb4bdaba4fdd965ca268262f009907824fa350a13c61965218bbd7fffa736
newBuilder
public static Builder newBuilder(org.apache.flume.channel.file.proto.ProtosFactory.Rollback prototype)
{    return newBuilder().mergeFrom(prototype);}
8f9c3ced03d87377003831ec6560ea40c4b718fc762fc1ca14b030b0ed8256d4
toBuilder
public Builder toBuilder()
{    return newBuilder(this);}
2a4c0cac516d5bc4a1109ad4c836ca7b20e2bab822eb3f5bbb7c506c60fb0415
newBuilderForType
protected Builder newBuilderForType(com.google.protobuf.GeneratedMessage.BuilderParent parent)
{    Builder builder = new Builder(parent);    return builder;}
e061a4269a7822f30b36dfe5c448257acd508bbe5bfe85e23841ca998b986e73
getDescriptor
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Rollback_descriptor;}
14146f9740b0a47326835ccc62490511ca2c1acd8a7ad735c50f15b98d8aa156
internalGetFieldAccessorTable
protected com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Rollback_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.flume.channel.file.proto.ProtosFactory.Rollback.class, org.apache.flume.channel.file.proto.ProtosFactory.Rollback.Builder.class);}
7c751d7a2accff7e718ee1e6ea5d2457fe6e182e8c39098e52a8848f56cf2cfe
maybeForceBuilderInitialization
private void maybeForceBuilderInitialization()
{    if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {    }}
db452528a8bc9d155fa120bbe8533aa1eebe58fe8bf85ab33cdc1987e2489b8f
create
private static Builder create()
{    return new Builder();}
7930c451f279d9927ff235e4ac064561e1505f9b7ae117d9f681b345534ff9e3
clear
public Builder clear()
{    super.clear();    return this;}
845fff95a97cf125489126ddee47248563aa80a59ed327d7d1c7cb9d90dcec30
clone
public Builder clone()
{    return create().mergeFrom(buildPartial());}
5a2efdcbff6cd8f893a197208cee010e41df6afb0e928da5d7126d953902ee30
getDescriptorForType
public com.google.protobuf.Descriptors.Descriptor getDescriptorForType()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Rollback_descriptor;}
376c84ef91375a9467aeb41a1dca936456c363f371d6a3fa6b893e7a7e008789
getDefaultInstanceForType
public org.apache.flume.channel.file.proto.ProtosFactory.Rollback getDefaultInstanceForType()
{    return org.apache.flume.channel.file.proto.ProtosFactory.Rollback.getDefaultInstance();}
ff8898dda0548fa15b05727b805f5d26607c729bea2799f41234fe408e3381fd
build
public org.apache.flume.channel.file.proto.ProtosFactory.Rollback build()
{    org.apache.flume.channel.file.proto.ProtosFactory.Rollback result = buildPartial();    if (!result.isInitialized()) {        throw newUninitializedMessageException(result);    }    return result;}
914a19f5125d70cbfd9816efe9b148753a2c669351b42732c500272c83237fff
buildPartial
public org.apache.flume.channel.file.proto.ProtosFactory.Rollback buildPartial()
{    org.apache.flume.channel.file.proto.ProtosFactory.Rollback result = new org.apache.flume.channel.file.proto.ProtosFactory.Rollback(this);    onBuilt();    return result;}
9c02b14012758934fbc876f583b7201b524cfd4dce350a6fd2cdeea1bb86b6f9
mergeFrom
public Builder mergeFrom(com.google.protobuf.Message other)
{    if (other instanceof org.apache.flume.channel.file.proto.ProtosFactory.Rollback) {        return mergeFrom((org.apache.flume.channel.file.proto.ProtosFactory.Rollback) other);    } else {        super.mergeFrom(other);        return this;    }}
7129ab6040ee266ff38074d4cb27829e5fddb8835ba2eccfdc2af81b1f1f0d24
mergeFrom
public Builder mergeFrom(org.apache.flume.channel.file.proto.ProtosFactory.Rollback other)
{    if (other == org.apache.flume.channel.file.proto.ProtosFactory.Rollback.getDefaultInstance())        return this;    this.mergeUnknownFields(other.getUnknownFields());    return this;}
dde7cd718eaa61cad29906454acf122daba6680a2db55e4787a359a08951b5e7
isInitialized
public final boolean isInitialized()
{    return true;}
576f0ac95d3431feb1ba705ec8f537aa5e5a58300021599ce7c111ed9b61d887
mergeFrom
public Builder mergeFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    org.apache.flume.channel.file.proto.ProtosFactory.Rollback parsedMessage = null;    try {        parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);    } catch (com.google.protobuf.InvalidProtocolBufferException e) {        parsedMessage = (org.apache.flume.channel.file.proto.ProtosFactory.Rollback) e.getUnfinishedMessage();        throw e;    } finally {        if (parsedMessage != null) {            mergeFrom(parsedMessage);        }    }    return this;}
97e74918aaa099b8dc4af2a07cf135690fe20c3c48c838a911ed1cbb5e5e87ef
getDefaultInstance
public static Commit getDefaultInstance()
{    return defaultInstance;}
01e64b9252782830bed4b73fffc15a78d0c832da6c7619a17a2538cf7cbbebdd
getDefaultInstanceForType
public Commit getDefaultInstanceForType()
{    return defaultInstance;}
afeb2882aee0a13dc444e9d430b86a6dc175c48ee917722e2d5ab50801b7ab38
getUnknownFields
public final com.google.protobuf.UnknownFieldSet getUnknownFields()
{    return this.unknownFields;}
e061a4269a7822f30b36dfe5c448257acd508bbe5bfe85e23841ca998b986e73
getDescriptor
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Commit_descriptor;}
14146f9740b0a47326835ccc62490511ca2c1acd8a7ad735c50f15b98d8aa156
internalGetFieldAccessorTable
protected com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Commit_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.flume.channel.file.proto.ProtosFactory.Commit.class, org.apache.flume.channel.file.proto.ProtosFactory.Commit.Builder.class);}
ccfff3662c95902a41a7e6025e02bc2e85dbde106874e355397a3062b9d99075
parsePartialFrom
public Commit parsePartialFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return new Commit(input, extensionRegistry);}
55bdb0e660670e02ed86b34ee9498a13c6beeb47b067488a9c171af829ff518a
getParserForType
public com.google.protobuf.Parser<Commit> getParserForType()
{    return PARSER;}
4ac9c8bdb45364b8bdef0861dc92b4de77e1341d7edd5064d476c713d0cf58da
hasType
public boolean hasType()
{    return ((bitField0_ & 0x00000001) == 0x00000001);}
e13ca6770d128854311e967cbfe111c5323a9155e542cbb6a563c89bfcce6811
getType
public int getType()
{    return type_;}
3eb5746a869e932254ccd9230e2597001e979870dcff9439accc4b8a5e5b6007
initFields
private void initFields()
{    type_ = 0;}
dde7cd718eaa61cad29906454acf122daba6680a2db55e4787a359a08951b5e7
isInitialized
public final boolean isInitialized()
{    byte isInitialized = memoizedIsInitialized;    if (isInitialized != -1)        return isInitialized == 1;    if (!hasType()) {        memoizedIsInitialized = 0;        return false;    }    memoizedIsInitialized = 1;    return true;}
b78da5ac0d0f56440a60e0c8711e74775e8d0aafe7882e5346a5dcc6fa783f73
writeTo
public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException
{    getSerializedSize();    if (((bitField0_ & 0x00000001) == 0x00000001)) {        output.writeSFixed32(1, type_);    }    getUnknownFields().writeTo(output);}
2bd67191ad73644076f3a74f7b306983cf9bd449d2e535f9b7f802bd0492f9f1
getSerializedSize
public int getSerializedSize()
{    int size = memoizedSerializedSize;    if (size != -1)        return size;    size = 0;    if (((bitField0_ & 0x00000001) == 0x00000001)) {        size += com.google.protobuf.CodedOutputStream.computeSFixed32Size(1, type_);    }    size += getUnknownFields().getSerializedSize();    memoizedSerializedSize = size;    return size;}
969c11f748ec8e7ea2d7ab9b282e6a50da757a9197e9f5c9c8a8c921b705557f
writeReplace
protected java.lang.Object writeReplace() throws java.io.ObjectStreamException
{    return super.writeReplace();}
01a812604848ffaf0771a3f931edd3e1f422ebc67686318dd8e5aa3f931a50e8
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Commit parseFrom(com.google.protobuf.ByteString data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
7c8905badac62f3c8d15627f47aab1ab0deb9e78be5cdccb5c0cad97cd174194
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Commit parseFrom(com.google.protobuf.ByteString data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
f64ed83421008b81cfc2392647c9d144af3b05d67f70a27ef930fd4c5f6a6186
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Commit parseFrom(byte[] data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
8c26135eb5e4479d862928e21a84c9915af57b21f8ca027fe499751e2445899e
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Commit parseFrom(byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
803466c1e46a9910d1548808b4470471e16aa1bb3860d38565980acee9ca05d9
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Commit parseFrom(java.io.InputStream input) throws java.io.IOException
{    return PARSER.parseFrom(input);}
b2c0c602b3b0e763cd1da506355a3ca44f253a8b1df7c804b0ca21b4572ba326
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Commit parseFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseFrom(input, extensionRegistry);}
6f2a549e787623acd0fff8de4bdac6aed4a0240f2e3b06f1810929c1d7cfa4f5
parseDelimitedFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Commit parseDelimitedFrom(java.io.InputStream input) throws java.io.IOException
{    return PARSER.parseDelimitedFrom(input);}
ce725907380531402807200d07393bfc0536dbd642a67d9ac0b5869c8491703c
parseDelimitedFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Commit parseDelimitedFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseDelimitedFrom(input, extensionRegistry);}
9043b35c2360c7a023b5fda957f8c90c19033c14b091eefcefefcbfbc766165e
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Commit parseFrom(com.google.protobuf.CodedInputStream input) throws java.io.IOException
{    return PARSER.parseFrom(input);}
715345b3605fca3c788486f02739c7145e6ba934b6a702e976dcfa08ee4dc2b2
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.Commit parseFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseFrom(input, extensionRegistry);}
e32f866eb7533a232fadc4ef42bb022716435f415dc4a0f7ed4fff845f45ead0
newBuilder
public static Builder newBuilder()
{    return Builder.create();}
a2589243249ba32b92e98298a2511019cd74b21c911d510f075da5ff7e8b6399
newBuilderForType
public Builder newBuilderForType()
{    return newBuilder();}
54df31d484b47affaff7320d60668c12db864ea865221a0594ddbe0ca97ae06c
newBuilder
public static Builder newBuilder(org.apache.flume.channel.file.proto.ProtosFactory.Commit prototype)
{    return newBuilder().mergeFrom(prototype);}
8f9c3ced03d87377003831ec6560ea40c4b718fc762fc1ca14b030b0ed8256d4
toBuilder
public Builder toBuilder()
{    return newBuilder(this);}
2a4c0cac516d5bc4a1109ad4c836ca7b20e2bab822eb3f5bbb7c506c60fb0415
newBuilderForType
protected Builder newBuilderForType(com.google.protobuf.GeneratedMessage.BuilderParent parent)
{    Builder builder = new Builder(parent);    return builder;}
e061a4269a7822f30b36dfe5c448257acd508bbe5bfe85e23841ca998b986e73
getDescriptor
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Commit_descriptor;}
14146f9740b0a47326835ccc62490511ca2c1acd8a7ad735c50f15b98d8aa156
internalGetFieldAccessorTable
protected com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Commit_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.flume.channel.file.proto.ProtosFactory.Commit.class, org.apache.flume.channel.file.proto.ProtosFactory.Commit.Builder.class);}
7c751d7a2accff7e718ee1e6ea5d2457fe6e182e8c39098e52a8848f56cf2cfe
maybeForceBuilderInitialization
private void maybeForceBuilderInitialization()
{    if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {    }}
db452528a8bc9d155fa120bbe8533aa1eebe58fe8bf85ab33cdc1987e2489b8f
create
private static Builder create()
{    return new Builder();}
7930c451f279d9927ff235e4ac064561e1505f9b7ae117d9f681b345534ff9e3
clear
public Builder clear()
{    super.clear();    type_ = 0;    bitField0_ = (bitField0_ & ~0x00000001);    return this;}
845fff95a97cf125489126ddee47248563aa80a59ed327d7d1c7cb9d90dcec30
clone
public Builder clone()
{    return create().mergeFrom(buildPartial());}
5a2efdcbff6cd8f893a197208cee010e41df6afb0e928da5d7126d953902ee30
getDescriptorForType
public com.google.protobuf.Descriptors.Descriptor getDescriptorForType()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_Commit_descriptor;}
54c30e60827d5240052d85d2be855847f5b04d113e07fefd273dea59eaf28bbb
getDefaultInstanceForType
public org.apache.flume.channel.file.proto.ProtosFactory.Commit getDefaultInstanceForType()
{    return org.apache.flume.channel.file.proto.ProtosFactory.Commit.getDefaultInstance();}
b801280ec29f1f4a5214fcd432224cd7781f451544fce5780c01964fb8aa5ed1
build
public org.apache.flume.channel.file.proto.ProtosFactory.Commit build()
{    org.apache.flume.channel.file.proto.ProtosFactory.Commit result = buildPartial();    if (!result.isInitialized()) {        throw newUninitializedMessageException(result);    }    return result;}
8b9537e82cb3b02a88ee35086e70a85894de7b6a0822a8293b8dc43878104fb6
buildPartial
public org.apache.flume.channel.file.proto.ProtosFactory.Commit buildPartial()
{    org.apache.flume.channel.file.proto.ProtosFactory.Commit result = new org.apache.flume.channel.file.proto.ProtosFactory.Commit(this);    int from_bitField0_ = bitField0_;    int to_bitField0_ = 0;    if (((from_bitField0_ & 0x00000001) == 0x00000001)) {        to_bitField0_ |= 0x00000001;    }    result.type_ = type_;    result.bitField0_ = to_bitField0_;    onBuilt();    return result;}
9c02b14012758934fbc876f583b7201b524cfd4dce350a6fd2cdeea1bb86b6f9
mergeFrom
public Builder mergeFrom(com.google.protobuf.Message other)
{    if (other instanceof org.apache.flume.channel.file.proto.ProtosFactory.Commit) {        return mergeFrom((org.apache.flume.channel.file.proto.ProtosFactory.Commit) other);    } else {        super.mergeFrom(other);        return this;    }}
22bf7c520843fb15037e007342ace02820d8df6d1b3eae8f07ceed0a5103b836
mergeFrom
public Builder mergeFrom(org.apache.flume.channel.file.proto.ProtosFactory.Commit other)
{    if (other == org.apache.flume.channel.file.proto.ProtosFactory.Commit.getDefaultInstance())        return this;    if (other.hasType()) {        setType(other.getType());    }    this.mergeUnknownFields(other.getUnknownFields());    return this;}
dde7cd718eaa61cad29906454acf122daba6680a2db55e4787a359a08951b5e7
isInitialized
public final boolean isInitialized()
{    if (!hasType()) {        return false;    }    return true;}
576f0ac95d3431feb1ba705ec8f537aa5e5a58300021599ce7c111ed9b61d887
mergeFrom
public Builder mergeFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    org.apache.flume.channel.file.proto.ProtosFactory.Commit parsedMessage = null;    try {        parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);    } catch (com.google.protobuf.InvalidProtocolBufferException e) {        parsedMessage = (org.apache.flume.channel.file.proto.ProtosFactory.Commit) e.getUnfinishedMessage();        throw e;    } finally {        if (parsedMessage != null) {            mergeFrom(parsedMessage);        }    }    return this;}
4ac9c8bdb45364b8bdef0861dc92b4de77e1341d7edd5064d476c713d0cf58da
hasType
public boolean hasType()
{    return ((bitField0_ & 0x00000001) == 0x00000001);}
e13ca6770d128854311e967cbfe111c5323a9155e542cbb6a563c89bfcce6811
getType
public int getType()
{    return type_;}
271e5b7cc262226c64b87a5b4575c3a23786db4662acea052c8e63718dec6140
setType
public Builder setType(int value)
{    bitField0_ |= 0x00000001;    type_ = value;    onChanged();    return this;}
20943f6fd4102c4b33b82c7b1390d3b35b1ccc148abd3b605ca0411637f7a028
clearType
public Builder clearType()
{    bitField0_ = (bitField0_ & ~0x00000001);    type_ = 0;    onChanged();    return this;}
08c7392ff9fe7a085c32f8b2f68554922b62a3efd728630577d348584c916278
getDefaultInstance
public static TransactionEventFooter getDefaultInstance()
{    return defaultInstance;}
2824181b11f9d1187793e76dea776c1e170e8beec0134b25e7fb90428ccb15da
getDefaultInstanceForType
public TransactionEventFooter getDefaultInstanceForType()
{    return defaultInstance;}
afeb2882aee0a13dc444e9d430b86a6dc175c48ee917722e2d5ab50801b7ab38
getUnknownFields
public final com.google.protobuf.UnknownFieldSet getUnknownFields()
{    return this.unknownFields;}
e061a4269a7822f30b36dfe5c448257acd508bbe5bfe85e23841ca998b986e73
getDescriptor
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_TransactionEventFooter_descriptor;}
14146f9740b0a47326835ccc62490511ca2c1acd8a7ad735c50f15b98d8aa156
internalGetFieldAccessorTable
protected com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_TransactionEventFooter_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter.class, org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter.Builder.class);}
a0d7cc9e84e07ee35a9842410d2b11c7b6a305c07143ed5548ea766e59c76c9b
parsePartialFrom
public TransactionEventFooter parsePartialFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return new TransactionEventFooter(input, extensionRegistry);}
df6a228b792900882a92bc93d04d44c4560bce94cc01973953ffca8056c5dab0
getParserForType
public com.google.protobuf.Parser<TransactionEventFooter> getParserForType()
{    return PARSER;}
3eb5746a869e932254ccd9230e2597001e979870dcff9439accc4b8a5e5b6007
initFields
private void initFields()
{}
dde7cd718eaa61cad29906454acf122daba6680a2db55e4787a359a08951b5e7
isInitialized
public final boolean isInitialized()
{    byte isInitialized = memoizedIsInitialized;    if (isInitialized != -1)        return isInitialized == 1;    memoizedIsInitialized = 1;    return true;}
b78da5ac0d0f56440a60e0c8711e74775e8d0aafe7882e5346a5dcc6fa783f73
writeTo
public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException
{    getSerializedSize();    getUnknownFields().writeTo(output);}
2bd67191ad73644076f3a74f7b306983cf9bd449d2e535f9b7f802bd0492f9f1
getSerializedSize
public int getSerializedSize()
{    int size = memoizedSerializedSize;    if (size != -1)        return size;    size = 0;    size += getUnknownFields().getSerializedSize();    memoizedSerializedSize = size;    return size;}
969c11f748ec8e7ea2d7ab9b282e6a50da757a9197e9f5c9c8a8c921b705557f
writeReplace
protected java.lang.Object writeReplace() throws java.io.ObjectStreamException
{    return super.writeReplace();}
62c9aad228d8a956c802a449f83e29867f5687733304dc2b5d05b7d672786141
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter parseFrom(com.google.protobuf.ByteString data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
7ea6eedc1d95cb8eb6d17d6dbc519abf84d0c5ca2e059d520f5479f6c8e0457b
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter parseFrom(com.google.protobuf.ByteString data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
5fd3960d330ed92e398d4a0a0bd9128b7aabacbaa3226c5774b354ed42691aa0
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter parseFrom(byte[] data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
7a6def0063e45959cca3bab8f722f2b8ae91cb64c39256292f0cd8297800201e
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter parseFrom(byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
6b02bdeac8e2cc514a2ef6a8aeefe11f19938378d39aa76edad7ccb5111c6d59
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter parseFrom(java.io.InputStream input) throws java.io.IOException
{    return PARSER.parseFrom(input);}
566f0d21550f52e343d4c026b9e258d9417799a9310df6584ead6b05fd94810c
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter parseFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseFrom(input, extensionRegistry);}
ca88797289447bc55438125e875385a6d141ac95592b0d253d12a8242b87bc98
parseDelimitedFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter parseDelimitedFrom(java.io.InputStream input) throws java.io.IOException
{    return PARSER.parseDelimitedFrom(input);}
bcda5aca95427aa968019fb37e4c6336bd07184d4a86525b549b032bd1ae2501
parseDelimitedFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter parseDelimitedFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseDelimitedFrom(input, extensionRegistry);}
426a0a042c96185dcece09fc4d045c7d8b34b2f9fef303fa7ea99ec30ca9269f
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter parseFrom(com.google.protobuf.CodedInputStream input) throws java.io.IOException
{    return PARSER.parseFrom(input);}
fb8c764376203e0864cca347b9fa27061fae2abb0213f564c23f8675091a878b
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter parseFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseFrom(input, extensionRegistry);}
e32f866eb7533a232fadc4ef42bb022716435f415dc4a0f7ed4fff845f45ead0
newBuilder
public static Builder newBuilder()
{    return Builder.create();}
a2589243249ba32b92e98298a2511019cd74b21c911d510f075da5ff7e8b6399
newBuilderForType
public Builder newBuilderForType()
{    return newBuilder();}
6f2224b504e78ee03dd7c6e895456bbe499aa61dcecdf51a812c333f89c072bd
newBuilder
public static Builder newBuilder(org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter prototype)
{    return newBuilder().mergeFrom(prototype);}
8f9c3ced03d87377003831ec6560ea40c4b718fc762fc1ca14b030b0ed8256d4
toBuilder
public Builder toBuilder()
{    return newBuilder(this);}
2a4c0cac516d5bc4a1109ad4c836ca7b20e2bab822eb3f5bbb7c506c60fb0415
newBuilderForType
protected Builder newBuilderForType(com.google.protobuf.GeneratedMessage.BuilderParent parent)
{    Builder builder = new Builder(parent);    return builder;}
e061a4269a7822f30b36dfe5c448257acd508bbe5bfe85e23841ca998b986e73
getDescriptor
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_TransactionEventFooter_descriptor;}
14146f9740b0a47326835ccc62490511ca2c1acd8a7ad735c50f15b98d8aa156
internalGetFieldAccessorTable
protected com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_TransactionEventFooter_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter.class, org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter.Builder.class);}
7c751d7a2accff7e718ee1e6ea5d2457fe6e182e8c39098e52a8848f56cf2cfe
maybeForceBuilderInitialization
private void maybeForceBuilderInitialization()
{    if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {    }}
db452528a8bc9d155fa120bbe8533aa1eebe58fe8bf85ab33cdc1987e2489b8f
create
private static Builder create()
{    return new Builder();}
7930c451f279d9927ff235e4ac064561e1505f9b7ae117d9f681b345534ff9e3
clear
public Builder clear()
{    super.clear();    return this;}
845fff95a97cf125489126ddee47248563aa80a59ed327d7d1c7cb9d90dcec30
clone
public Builder clone()
{    return create().mergeFrom(buildPartial());}
5a2efdcbff6cd8f893a197208cee010e41df6afb0e928da5d7126d953902ee30
getDescriptorForType
public com.google.protobuf.Descriptors.Descriptor getDescriptorForType()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_TransactionEventFooter_descriptor;}
003f710c0fed4355916f9f49ac4a02c5a66e9b6c0024f97edc52c73e04ac625f
getDefaultInstanceForType
public org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter getDefaultInstanceForType()
{    return org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter.getDefaultInstance();}
9d3dc5045cd4e3e02ffab85f66a1f234e8b6f2e00c8d3df31644dac1663fdd8d
build
public org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter build()
{    org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter result = buildPartial();    if (!result.isInitialized()) {        throw newUninitializedMessageException(result);    }    return result;}
1932fddab979edaff12e8e07c6602cced8c3394449737689a6dc309a948ac367
buildPartial
public org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter buildPartial()
{    org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter result = new org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter(this);    onBuilt();    return result;}
9c02b14012758934fbc876f583b7201b524cfd4dce350a6fd2cdeea1bb86b6f9
mergeFrom
public Builder mergeFrom(com.google.protobuf.Message other)
{    if (other instanceof org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter) {        return mergeFrom((org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter) other);    } else {        super.mergeFrom(other);        return this;    }}
a56416687695134cccd65b8b714fa0c18b099332d64fcd2123ee2268bcda3f3d
mergeFrom
public Builder mergeFrom(org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter other)
{    if (other == org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter.getDefaultInstance())        return this;    this.mergeUnknownFields(other.getUnknownFields());    return this;}
dde7cd718eaa61cad29906454acf122daba6680a2db55e4787a359a08951b5e7
isInitialized
public final boolean isInitialized()
{    return true;}
576f0ac95d3431feb1ba705ec8f537aa5e5a58300021599ce7c111ed9b61d887
mergeFrom
public Builder mergeFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter parsedMessage = null;    try {        parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);    } catch (com.google.protobuf.InvalidProtocolBufferException e) {        parsedMessage = (org.apache.flume.channel.file.proto.ProtosFactory.TransactionEventFooter) e.getUnfinishedMessage();        throw e;    } finally {        if (parsedMessage != null) {            mergeFrom(parsedMessage);        }    }    return this;}
904ccc7981c2c38f0e28f5f758da51fdab0b4d5b2a337a6ab62730e2a455d0f1
getDefaultInstance
public static FlumeEvent getDefaultInstance()
{    return defaultInstance;}
9bd929f9655b5f9c38659bda9e1c4beca749dd5766f739f818b0f378c9e4f5a5
getDefaultInstanceForType
public FlumeEvent getDefaultInstanceForType()
{    return defaultInstance;}
afeb2882aee0a13dc444e9d430b86a6dc175c48ee917722e2d5ab50801b7ab38
getUnknownFields
public final com.google.protobuf.UnknownFieldSet getUnknownFields()
{    return this.unknownFields;}
e061a4269a7822f30b36dfe5c448257acd508bbe5bfe85e23841ca998b986e73
getDescriptor
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_FlumeEvent_descriptor;}
14146f9740b0a47326835ccc62490511ca2c1acd8a7ad735c50f15b98d8aa156
internalGetFieldAccessorTable
protected com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_FlumeEvent_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent.class, org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent.Builder.class);}
cce155d79a225eb20760b146d7a5b590905a1d788466120a886486aff25485a2
parsePartialFrom
public FlumeEvent parsePartialFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return new FlumeEvent(input, extensionRegistry);}
9187aafb96f6faa43375f7f6497f2f602fdc84b6971d822455a290a457fe2826
getParserForType
public com.google.protobuf.Parser<FlumeEvent> getParserForType()
{    return PARSER;}
b60a724db7c2cc4226e49333f10eb8ea3492a0937c16b2fc706aa15356850400
getHeadersList
public java.util.List<org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader> getHeadersList()
{    return headers_;}
5c3f4206d8a582d8f62e4f3904364af07b4d5e7863d2402a15718d01a510e8ab
getHeadersOrBuilderList
public java.util.List<? extends org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeaderOrBuilder> getHeadersOrBuilderList()
{    return headers_;}
41d022a96d594ee9e8b11eecb9dc1e0fa6d043f260cc8a1e59ebcf5aeaab7a83
getHeadersCount
public int getHeadersCount()
{    return headers_.size();}
aa33193abb03c1d0cf64a09909f0cf5e323984844229627d1bbdd7ca7e66f76a
getHeaders
public org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader getHeaders(int index)
{    return headers_.get(index);}
f77edf1825340ed737f0ab6f767f5817e45a9ca4cdd2865802ff010db2822866
getHeadersOrBuilder
public org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeaderOrBuilder getHeadersOrBuilder(int index)
{    return headers_.get(index);}
83a36f3cbd64feebff76ee3ae9ed597267f5457b0de0f990a39a7a3755600b41
hasBody
public boolean hasBody()
{    return ((bitField0_ & 0x00000001) == 0x00000001);}
78a6eba25286268d041979390832e1030ecac5762b5930e82b24367e4f01a873
getBody
public com.google.protobuf.ByteString getBody()
{    return body_;}
3eb5746a869e932254ccd9230e2597001e979870dcff9439accc4b8a5e5b6007
initFields
private void initFields()
{    headers_ = java.util.Collections.emptyList();    body_ = com.google.protobuf.ByteString.EMPTY;}
dde7cd718eaa61cad29906454acf122daba6680a2db55e4787a359a08951b5e7
isInitialized
public final boolean isInitialized()
{    byte isInitialized = memoizedIsInitialized;    if (isInitialized != -1)        return isInitialized == 1;    if (!hasBody()) {        memoizedIsInitialized = 0;        return false;    }    for (int i = 0; i < getHeadersCount(); i++) {        if (!getHeaders(i).isInitialized()) {            memoizedIsInitialized = 0;            return false;        }    }    memoizedIsInitialized = 1;    return true;}
b78da5ac0d0f56440a60e0c8711e74775e8d0aafe7882e5346a5dcc6fa783f73
writeTo
public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException
{    getSerializedSize();    for (int i = 0; i < headers_.size(); i++) {        output.writeMessage(1, headers_.get(i));    }    if (((bitField0_ & 0x00000001) == 0x00000001)) {        output.writeBytes(2, body_);    }    getUnknownFields().writeTo(output);}
2bd67191ad73644076f3a74f7b306983cf9bd449d2e535f9b7f802bd0492f9f1
getSerializedSize
public int getSerializedSize()
{    int size = memoizedSerializedSize;    if (size != -1)        return size;    size = 0;    for (int i = 0; i < headers_.size(); i++) {        size += com.google.protobuf.CodedOutputStream.computeMessageSize(1, headers_.get(i));    }    if (((bitField0_ & 0x00000001) == 0x00000001)) {        size += com.google.protobuf.CodedOutputStream.computeBytesSize(2, body_);    }    size += getUnknownFields().getSerializedSize();    memoizedSerializedSize = size;    return size;}
969c11f748ec8e7ea2d7ab9b282e6a50da757a9197e9f5c9c8a8c921b705557f
writeReplace
protected java.lang.Object writeReplace() throws java.io.ObjectStreamException
{    return super.writeReplace();}
c87e45b6d6d251c9a3b16ca3641f935dffe1090aeb8dc5bfb0dffc3f35ffa6ad
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent parseFrom(com.google.protobuf.ByteString data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
f6606f7875382c7e9b24fde2920d34ea873d219a1cacb757c043d22756ebb2cd
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent parseFrom(com.google.protobuf.ByteString data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
3ccd59ff8f3638859c8813af2cba4469c36930eebcfabb1604d72830cafc3ffc
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent parseFrom(byte[] data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
1e5dc6ef6e1f09ac10fe928d9dd52dc244555f0689013073a2ff2eee2c001b0e
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent parseFrom(byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
0919fade1473a4d948b6405e2ff3e2e5e047ba82ae27a5f0e07b941eee3cca7b
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent parseFrom(java.io.InputStream input) throws java.io.IOException
{    return PARSER.parseFrom(input);}
b13147f557131d861bcc3bac8cacf6779d0bb9468719a4b741d14b91a7be299a
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent parseFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseFrom(input, extensionRegistry);}
4b37fe0d12ccd7fcfe40a77924d5f17fc9e2bb47af7c2d185d187ab4584e707f
parseDelimitedFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent parseDelimitedFrom(java.io.InputStream input) throws java.io.IOException
{    return PARSER.parseDelimitedFrom(input);}
ca9326f78d069be4ae6772247b03c39bdfe27f942c1937bc9ca178d045032cf5
parseDelimitedFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent parseDelimitedFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseDelimitedFrom(input, extensionRegistry);}
7d9a78538e31904175127c37b2f47e3f64b01cd57014bf28c6ac954b545c5ac4
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent parseFrom(com.google.protobuf.CodedInputStream input) throws java.io.IOException
{    return PARSER.parseFrom(input);}
09548e03966143379f4b06d555b7e0d5cdf3493d71e0a9be9766f522ba2ccca4
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent parseFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseFrom(input, extensionRegistry);}
e32f866eb7533a232fadc4ef42bb022716435f415dc4a0f7ed4fff845f45ead0
newBuilder
public static Builder newBuilder()
{    return Builder.create();}
a2589243249ba32b92e98298a2511019cd74b21c911d510f075da5ff7e8b6399
newBuilderForType
public Builder newBuilderForType()
{    return newBuilder();}
c60bde4d7417bb268d6818bb9fd21fdc07755ce8c6a03aae26c6a02161cacbae
newBuilder
public static Builder newBuilder(org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent prototype)
{    return newBuilder().mergeFrom(prototype);}
8f9c3ced03d87377003831ec6560ea40c4b718fc762fc1ca14b030b0ed8256d4
toBuilder
public Builder toBuilder()
{    return newBuilder(this);}
2a4c0cac516d5bc4a1109ad4c836ca7b20e2bab822eb3f5bbb7c506c60fb0415
newBuilderForType
protected Builder newBuilderForType(com.google.protobuf.GeneratedMessage.BuilderParent parent)
{    Builder builder = new Builder(parent);    return builder;}
e061a4269a7822f30b36dfe5c448257acd508bbe5bfe85e23841ca998b986e73
getDescriptor
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_FlumeEvent_descriptor;}
14146f9740b0a47326835ccc62490511ca2c1acd8a7ad735c50f15b98d8aa156
internalGetFieldAccessorTable
protected com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_FlumeEvent_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent.class, org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent.Builder.class);}
7c751d7a2accff7e718ee1e6ea5d2457fe6e182e8c39098e52a8848f56cf2cfe
maybeForceBuilderInitialization
private void maybeForceBuilderInitialization()
{    if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {        getHeadersFieldBuilder();    }}
db452528a8bc9d155fa120bbe8533aa1eebe58fe8bf85ab33cdc1987e2489b8f
create
private static Builder create()
{    return new Builder();}
7930c451f279d9927ff235e4ac064561e1505f9b7ae117d9f681b345534ff9e3
clear
public Builder clear()
{    super.clear();    if (headersBuilder_ == null) {        headers_ = java.util.Collections.emptyList();        bitField0_ = (bitField0_ & ~0x00000001);    } else {        headersBuilder_.clear();    }    body_ = com.google.protobuf.ByteString.EMPTY;    bitField0_ = (bitField0_ & ~0x00000002);    return this;}
845fff95a97cf125489126ddee47248563aa80a59ed327d7d1c7cb9d90dcec30
clone
public Builder clone()
{    return create().mergeFrom(buildPartial());}
5a2efdcbff6cd8f893a197208cee010e41df6afb0e928da5d7126d953902ee30
getDescriptorForType
public com.google.protobuf.Descriptors.Descriptor getDescriptorForType()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_FlumeEvent_descriptor;}
021b8024c681d95c01ef90f2b3a593186e7dea00770e935ca993f1ad2f6067da
getDefaultInstanceForType
public org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent getDefaultInstanceForType()
{    return org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent.getDefaultInstance();}
25ee5299af8210d0b85d0e0fa995c37e2ea306664847241736a050547768b17a
build
public org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent build()
{    org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent result = buildPartial();    if (!result.isInitialized()) {        throw newUninitializedMessageException(result);    }    return result;}
4243f366bf5d2ca3e07e8f47a349615635a81dc6497543f33334fcc340d9904f
buildPartial
public org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent buildPartial()
{    org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent result = new org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent(this);    int from_bitField0_ = bitField0_;    int to_bitField0_ = 0;    if (headersBuilder_ == null) {        if (((bitField0_ & 0x00000001) == 0x00000001)) {            headers_ = java.util.Collections.unmodifiableList(headers_);            bitField0_ = (bitField0_ & ~0x00000001);        }        result.headers_ = headers_;    } else {        result.headers_ = headersBuilder_.build();    }    if (((from_bitField0_ & 0x00000002) == 0x00000002)) {        to_bitField0_ |= 0x00000001;    }    result.body_ = body_;    result.bitField0_ = to_bitField0_;    onBuilt();    return result;}
9c02b14012758934fbc876f583b7201b524cfd4dce350a6fd2cdeea1bb86b6f9
mergeFrom
public Builder mergeFrom(com.google.protobuf.Message other)
{    if (other instanceof org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent) {        return mergeFrom((org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent) other);    } else {        super.mergeFrom(other);        return this;    }}
1067452b65df4657bd519cd181d18d38a900bae8bc1486135db5999a1f5a7025
mergeFrom
public Builder mergeFrom(org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent other)
{    if (other == org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent.getDefaultInstance())        return this;    if (headersBuilder_ == null) {        if (!other.headers_.isEmpty()) {            if (headers_.isEmpty()) {                headers_ = other.headers_;                bitField0_ = (bitField0_ & ~0x00000001);            } else {                ensureHeadersIsMutable();                headers_.addAll(other.headers_);            }            onChanged();        }    } else {        if (!other.headers_.isEmpty()) {            if (headersBuilder_.isEmpty()) {                headersBuilder_.dispose();                headersBuilder_ = null;                headers_ = other.headers_;                bitField0_ = (bitField0_ & ~0x00000001);                headersBuilder_ = com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ? getHeadersFieldBuilder() : null;            } else {                headersBuilder_.addAllMessages(other.headers_);            }        }    }    if (other.hasBody()) {        setBody(other.getBody());    }    this.mergeUnknownFields(other.getUnknownFields());    return this;}
dde7cd718eaa61cad29906454acf122daba6680a2db55e4787a359a08951b5e7
isInitialized
public final boolean isInitialized()
{    if (!hasBody()) {        return false;    }    for (int i = 0; i < getHeadersCount(); i++) {        if (!getHeaders(i).isInitialized()) {            return false;        }    }    return true;}
576f0ac95d3431feb1ba705ec8f537aa5e5a58300021599ce7c111ed9b61d887
mergeFrom
public Builder mergeFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent parsedMessage = null;    try {        parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);    } catch (com.google.protobuf.InvalidProtocolBufferException e) {        parsedMessage = (org.apache.flume.channel.file.proto.ProtosFactory.FlumeEvent) e.getUnfinishedMessage();        throw e;    } finally {        if (parsedMessage != null) {            mergeFrom(parsedMessage);        }    }    return this;}
c6b11dff49fe607496298156a973f002f09b90599c5512adbd065d3bfc1fd9d4
ensureHeadersIsMutable
private void ensureHeadersIsMutable()
{    if (!((bitField0_ & 0x00000001) == 0x00000001)) {        headers_ = new java.util.ArrayList<org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader>(headers_);        bitField0_ |= 0x00000001;    }}
b60a724db7c2cc4226e49333f10eb8ea3492a0937c16b2fc706aa15356850400
getHeadersList
public java.util.List<org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader> getHeadersList()
{    if (headersBuilder_ == null) {        return java.util.Collections.unmodifiableList(headers_);    } else {        return headersBuilder_.getMessageList();    }}
41d022a96d594ee9e8b11eecb9dc1e0fa6d043f260cc8a1e59ebcf5aeaab7a83
getHeadersCount
public int getHeadersCount()
{    if (headersBuilder_ == null) {        return headers_.size();    } else {        return headersBuilder_.getCount();    }}
aa33193abb03c1d0cf64a09909f0cf5e323984844229627d1bbdd7ca7e66f76a
getHeaders
public org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader getHeaders(int index)
{    if (headersBuilder_ == null) {        return headers_.get(index);    } else {        return headersBuilder_.getMessage(index);    }}
d0493b038cb707a26496c25e8c29fcef325e6608e9b4352b9f32b98609c772f5
setHeaders
public Builder setHeaders(int index, org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader value)
{    if (headersBuilder_ == null) {        if (value == null) {            throw new NullPointerException();        }        ensureHeadersIsMutable();        headers_.set(index, value);        onChanged();    } else {        headersBuilder_.setMessage(index, value);    }    return this;}
02147dff61e3bb1420d451d5c698baa8349cc307f81c9d2bd79b933d1cec53e5
setHeaders
public Builder setHeaders(int index, org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader.Builder builderForValue)
{    if (headersBuilder_ == null) {        ensureHeadersIsMutable();        headers_.set(index, builderForValue.build());        onChanged();    } else {        headersBuilder_.setMessage(index, builderForValue.build());    }    return this;}
8e2df731ac502e194bf67cdba557b1ac22875e07bb9670b7f090c98c7740f4bd
addHeaders
public Builder addHeaders(org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader value)
{    if (headersBuilder_ == null) {        if (value == null) {            throw new NullPointerException();        }        ensureHeadersIsMutable();        headers_.add(value);        onChanged();    } else {        headersBuilder_.addMessage(value);    }    return this;}
d8962870b347c5c5485939262607d9e2d3d288fb549bb1d8bdfdbbb92852058d
addHeaders
public Builder addHeaders(int index, org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader value)
{    if (headersBuilder_ == null) {        if (value == null) {            throw new NullPointerException();        }        ensureHeadersIsMutable();        headers_.add(index, value);        onChanged();    } else {        headersBuilder_.addMessage(index, value);    }    return this;}
0773a7e14ad890f203defb0e0c749bca1ccb2d30bd5d0cc9cd14fcd244590afb
addHeaders
public Builder addHeaders(org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader.Builder builderForValue)
{    if (headersBuilder_ == null) {        ensureHeadersIsMutable();        headers_.add(builderForValue.build());        onChanged();    } else {        headersBuilder_.addMessage(builderForValue.build());    }    return this;}
4669a19f59065e919c2b694c163948bc0dcec548b6d2adbdbd8d0773e987f1b2
addHeaders
public Builder addHeaders(int index, org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader.Builder builderForValue)
{    if (headersBuilder_ == null) {        ensureHeadersIsMutable();        headers_.add(index, builderForValue.build());        onChanged();    } else {        headersBuilder_.addMessage(index, builderForValue.build());    }    return this;}
e58379e134baae3da514f18b4b258a7f7c530112f0761f0c57357130ceeb114a
addAllHeaders
public Builder addAllHeaders(java.lang.Iterable<? extends org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader> values)
{    if (headersBuilder_ == null) {        ensureHeadersIsMutable();        super.addAll(values, headers_);        onChanged();    } else {        headersBuilder_.addAllMessages(values);    }    return this;}
96201ba66a54a7105f01dcb2f40aab2dfd27c7c3246f5f443644f9f99ec3162b
clearHeaders
public Builder clearHeaders()
{    if (headersBuilder_ == null) {        headers_ = java.util.Collections.emptyList();        bitField0_ = (bitField0_ & ~0x00000001);        onChanged();    } else {        headersBuilder_.clear();    }    return this;}
804a7df1dc7363efe3a41dc911d9a09992eaf40f70caafa7dc240f460cf002a6
removeHeaders
public Builder removeHeaders(int index)
{    if (headersBuilder_ == null) {        ensureHeadersIsMutable();        headers_.remove(index);        onChanged();    } else {        headersBuilder_.remove(index);    }    return this;}
078e517c5cf671dae1f66db1b90d2a6eeb97a1d3a00bcc067799bd17b41a61f8
getHeadersBuilder
public org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader.Builder getHeadersBuilder(int index)
{    return getHeadersFieldBuilder().getBuilder(index);}
f77edf1825340ed737f0ab6f767f5817e45a9ca4cdd2865802ff010db2822866
getHeadersOrBuilder
public org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeaderOrBuilder getHeadersOrBuilder(int index)
{    if (headersBuilder_ == null) {        return headers_.get(index);    } else {        return headersBuilder_.getMessageOrBuilder(index);    }}
5c3f4206d8a582d8f62e4f3904364af07b4d5e7863d2402a15718d01a510e8ab
getHeadersOrBuilderList
public java.util.List<? extends org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeaderOrBuilder> getHeadersOrBuilderList()
{    if (headersBuilder_ != null) {        return headersBuilder_.getMessageOrBuilderList();    } else {        return java.util.Collections.unmodifiableList(headers_);    }}
6a6c23a09ea56c5e1b54797e2886436b523ab967c1ff97aaeebad888599ec284
addHeadersBuilder
public org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader.Builder addHeadersBuilder()
{    return getHeadersFieldBuilder().addBuilder(org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader.getDefaultInstance());}
9a15378c9c5f3deb03af978fde424dbee54d347883408b533d0eb47a4f46eb22
addHeadersBuilder
public org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader.Builder addHeadersBuilder(int index)
{    return getHeadersFieldBuilder().addBuilder(index, org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader.getDefaultInstance());}
9f08369fa35555b7dcb5990c447eb4613e4758921f9d8aacdfdf069973e75439
getHeadersBuilderList
public java.util.List<org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader.Builder> getHeadersBuilderList()
{    return getHeadersFieldBuilder().getBuilderList();}
ec4863d90e7d8840bc6fbbc84a3b030f5e5c4155e5057eed303064da30730b26
getHeadersFieldBuilder
private com.google.protobuf.RepeatedFieldBuilder<org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader, org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader.Builder, org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeaderOrBuilder> getHeadersFieldBuilder()
{    if (headersBuilder_ == null) {        headersBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader, org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader.Builder, org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeaderOrBuilder>(headers_, ((bitField0_ & 0x00000001) == 0x00000001), getParentForChildren(), isClean());        headers_ = null;    }    return headersBuilder_;}
83a36f3cbd64feebff76ee3ae9ed597267f5457b0de0f990a39a7a3755600b41
hasBody
public boolean hasBody()
{    return ((bitField0_ & 0x00000002) == 0x00000002);}
78a6eba25286268d041979390832e1030ecac5762b5930e82b24367e4f01a873
getBody
public com.google.protobuf.ByteString getBody()
{    return body_;}
8e25d686d884c4c110eb446791d6925633101e7b011089085c3e7d71e77b5839
setBody
public Builder setBody(com.google.protobuf.ByteString value)
{    if (value == null) {        throw new NullPointerException();    }    bitField0_ |= 0x00000002;    body_ = value;    onChanged();    return this;}
e80b1d4ff8c011a38858227523f97de62ddfb17a3136b26ee2b765dd39d83322
clearBody
public Builder clearBody()
{    bitField0_ = (bitField0_ & ~0x00000002);    body_ = getDefaultInstance().getBody();    onChanged();    return this;}
d4424004700b6d159862a6d4e19ced915461e14c98b72ed6763f6ebb80e76644
getDefaultInstance
public static FlumeEventHeader getDefaultInstance()
{    return defaultInstance;}
ca0475b839bd3c2f3e76af4ce6452cc4e806080e331798f843331630f2335a3b
getDefaultInstanceForType
public FlumeEventHeader getDefaultInstanceForType()
{    return defaultInstance;}
afeb2882aee0a13dc444e9d430b86a6dc175c48ee917722e2d5ab50801b7ab38
getUnknownFields
public final com.google.protobuf.UnknownFieldSet getUnknownFields()
{    return this.unknownFields;}
e061a4269a7822f30b36dfe5c448257acd508bbe5bfe85e23841ca998b986e73
getDescriptor
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_FlumeEventHeader_descriptor;}
14146f9740b0a47326835ccc62490511ca2c1acd8a7ad735c50f15b98d8aa156
internalGetFieldAccessorTable
protected com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_FlumeEventHeader_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader.class, org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader.Builder.class);}
290fe1be93469cf99e61f7637c5788fa3256327232928cf0ba5ecb64abf7ec4e
parsePartialFrom
public FlumeEventHeader parsePartialFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return new FlumeEventHeader(input, extensionRegistry);}
8baa48774a4c23b137643e95ce2ccec83c57586a5f2db8707aa3001b2bea8c98
getParserForType
public com.google.protobuf.Parser<FlumeEventHeader> getParserForType()
{    return PARSER;}
3d43f50bb45a9a7cdc6e13d035f0b5f07da624c7d610f8566643664d8f77e820
hasKey
public boolean hasKey()
{    return ((bitField0_ & 0x00000001) == 0x00000001);}
047c54d0c4ae0097629c78313543b21fe7c9606bce1b212deeadb1a9952aeb3d
getKey
public java.lang.String getKey()
{    java.lang.Object ref = key_;    if (ref instanceof java.lang.String) {        return (java.lang.String) ref;    } else {        com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;        java.lang.String s = bs.toStringUtf8();        if (bs.isValidUtf8()) {            key_ = s;        }        return s;    }}
c8dcc45177cfe933c49df3d8f441fbd5849f0f6d52c8a3d5fa340554b6148110
getKeyBytes
public com.google.protobuf.ByteString getKeyBytes()
{    java.lang.Object ref = key_;    if (ref instanceof java.lang.String) {        com.google.protobuf.ByteString b = com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);        key_ = b;        return b;    } else {        return (com.google.protobuf.ByteString) ref;    }}
258d74581b7c36a36f14ac351a56248c96622e4794d629fa1d8f556bd5b32cfc
hasValue
public boolean hasValue()
{    return ((bitField0_ & 0x00000002) == 0x00000002);}
5fe750442f74fec8e2337d6a8f85d11f7ac11c410ea9afb9807e7c5e05520cae
getValue
public java.lang.String getValue()
{    java.lang.Object ref = value_;    if (ref instanceof java.lang.String) {        return (java.lang.String) ref;    } else {        com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;        java.lang.String s = bs.toStringUtf8();        if (bs.isValidUtf8()) {            value_ = s;        }        return s;    }}
6c5e6d1ec43c0fe42bdf45c44e6e70be94206e44ce0ab238c28132b3a057b9b5
getValueBytes
public com.google.protobuf.ByteString getValueBytes()
{    java.lang.Object ref = value_;    if (ref instanceof java.lang.String) {        com.google.protobuf.ByteString b = com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);        value_ = b;        return b;    } else {        return (com.google.protobuf.ByteString) ref;    }}
3eb5746a869e932254ccd9230e2597001e979870dcff9439accc4b8a5e5b6007
initFields
private void initFields()
{    key_ = "";    value_ = "";}
dde7cd718eaa61cad29906454acf122daba6680a2db55e4787a359a08951b5e7
isInitialized
public final boolean isInitialized()
{    byte isInitialized = memoizedIsInitialized;    if (isInitialized != -1)        return isInitialized == 1;    if (!hasKey()) {        memoizedIsInitialized = 0;        return false;    }    memoizedIsInitialized = 1;    return true;}
b78da5ac0d0f56440a60e0c8711e74775e8d0aafe7882e5346a5dcc6fa783f73
writeTo
public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException
{    getSerializedSize();    if (((bitField0_ & 0x00000001) == 0x00000001)) {        output.writeBytes(1, getKeyBytes());    }    if (((bitField0_ & 0x00000002) == 0x00000002)) {        output.writeBytes(2, getValueBytes());    }    getUnknownFields().writeTo(output);}
2bd67191ad73644076f3a74f7b306983cf9bd449d2e535f9b7f802bd0492f9f1
getSerializedSize
public int getSerializedSize()
{    int size = memoizedSerializedSize;    if (size != -1)        return size;    size = 0;    if (((bitField0_ & 0x00000001) == 0x00000001)) {        size += com.google.protobuf.CodedOutputStream.computeBytesSize(1, getKeyBytes());    }    if (((bitField0_ & 0x00000002) == 0x00000002)) {        size += com.google.protobuf.CodedOutputStream.computeBytesSize(2, getValueBytes());    }    size += getUnknownFields().getSerializedSize();    memoizedSerializedSize = size;    return size;}
969c11f748ec8e7ea2d7ab9b282e6a50da757a9197e9f5c9c8a8c921b705557f
writeReplace
protected java.lang.Object writeReplace() throws java.io.ObjectStreamException
{    return super.writeReplace();}
7732e3b21b6382816d1c0646394e86800f0363b5433de2e77d06fa990905ada0
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader parseFrom(com.google.protobuf.ByteString data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
bfdb5bd7bc9f870ec6e4274ed1bc54f70f9e87265fcff1f9f549f522a6521ae0
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader parseFrom(com.google.protobuf.ByteString data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
8b4f01f8ee98954991ac6cb349336470524d5b81cc59ea85ff97cc44df22462c
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader parseFrom(byte[] data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
2cd913e1b33e7577cdad0c4f1f34b7165e2ddfeaf6333c170281b58d41cbde18
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader parseFrom(byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
8e54c50214c141f88ff0b09ce507fc3945188f5f97f10359f25baa51add84eab
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader parseFrom(java.io.InputStream input) throws java.io.IOException
{    return PARSER.parseFrom(input);}
371a9d986385a5152437a0bd5830bd301d68910bcbb739afbc48af39f73174ce
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader parseFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseFrom(input, extensionRegistry);}
67768b8d46cfedf832f2e0abcef428b8e546dcba2ca9b3275474ebc73b165306
parseDelimitedFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader parseDelimitedFrom(java.io.InputStream input) throws java.io.IOException
{    return PARSER.parseDelimitedFrom(input);}
828888a4ea92c24cdd3b4056fc98cee30e299bf69b22df675e2b62a488a2750e
parseDelimitedFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader parseDelimitedFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseDelimitedFrom(input, extensionRegistry);}
b3023869659401324bb8e3de5b545a7bca2a8344a396d0db5f83627fc55f13a6
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader parseFrom(com.google.protobuf.CodedInputStream input) throws java.io.IOException
{    return PARSER.parseFrom(input);}
57c88c982475363bd967b7afa266b4df262ea3280ce8129d7dcd932694802e09
parseFrom
public static org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader parseFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return PARSER.parseFrom(input, extensionRegistry);}
e32f866eb7533a232fadc4ef42bb022716435f415dc4a0f7ed4fff845f45ead0
newBuilder
public static Builder newBuilder()
{    return Builder.create();}
a2589243249ba32b92e98298a2511019cd74b21c911d510f075da5ff7e8b6399
newBuilderForType
public Builder newBuilderForType()
{    return newBuilder();}
8de0aa3017c0bb642511abfe92f3f60097bee2b8647d0dda57dacbdeddd0d64b
newBuilder
public static Builder newBuilder(org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader prototype)
{    return newBuilder().mergeFrom(prototype);}
8f9c3ced03d87377003831ec6560ea40c4b718fc762fc1ca14b030b0ed8256d4
toBuilder
public Builder toBuilder()
{    return newBuilder(this);}
2a4c0cac516d5bc4a1109ad4c836ca7b20e2bab822eb3f5bbb7c506c60fb0415
newBuilderForType
protected Builder newBuilderForType(com.google.protobuf.GeneratedMessage.BuilderParent parent)
{    Builder builder = new Builder(parent);    return builder;}
e061a4269a7822f30b36dfe5c448257acd508bbe5bfe85e23841ca998b986e73
getDescriptor
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_FlumeEventHeader_descriptor;}
14146f9740b0a47326835ccc62490511ca2c1acd8a7ad735c50f15b98d8aa156
internalGetFieldAccessorTable
protected com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_FlumeEventHeader_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader.class, org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader.Builder.class);}
7c751d7a2accff7e718ee1e6ea5d2457fe6e182e8c39098e52a8848f56cf2cfe
maybeForceBuilderInitialization
private void maybeForceBuilderInitialization()
{    if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {    }}
db452528a8bc9d155fa120bbe8533aa1eebe58fe8bf85ab33cdc1987e2489b8f
create
private static Builder create()
{    return new Builder();}
7930c451f279d9927ff235e4ac064561e1505f9b7ae117d9f681b345534ff9e3
clear
public Builder clear()
{    super.clear();    key_ = "";    bitField0_ = (bitField0_ & ~0x00000001);    value_ = "";    bitField0_ = (bitField0_ & ~0x00000002);    return this;}
845fff95a97cf125489126ddee47248563aa80a59ed327d7d1c7cb9d90dcec30
clone
public Builder clone()
{    return create().mergeFrom(buildPartial());}
5a2efdcbff6cd8f893a197208cee010e41df6afb0e928da5d7126d953902ee30
getDescriptorForType
public com.google.protobuf.Descriptors.Descriptor getDescriptorForType()
{    return org.apache.flume.channel.file.proto.ProtosFactory.internal_static_FlumeEventHeader_descriptor;}
ce96f7083224fe589f6b517fbb6962d5d016cc86db3fa32173dc1ddca1c5a392
getDefaultInstanceForType
public org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader getDefaultInstanceForType()
{    return org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader.getDefaultInstance();}
ee849f576e32fc306c6dfc6b3a1dcb78b032a23e9ba291bafbbecc4802ef833d
build
public org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader build()
{    org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader result = buildPartial();    if (!result.isInitialized()) {        throw newUninitializedMessageException(result);    }    return result;}
71f849041bb8a261898b6001a344c521fd81bdf7c2fe892b77e733d54dc1c098
buildPartial
public org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader buildPartial()
{    org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader result = new org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader(this);    int from_bitField0_ = bitField0_;    int to_bitField0_ = 0;    if (((from_bitField0_ & 0x00000001) == 0x00000001)) {        to_bitField0_ |= 0x00000001;    }    result.key_ = key_;    if (((from_bitField0_ & 0x00000002) == 0x00000002)) {        to_bitField0_ |= 0x00000002;    }    result.value_ = value_;    result.bitField0_ = to_bitField0_;    onBuilt();    return result;}
9c02b14012758934fbc876f583b7201b524cfd4dce350a6fd2cdeea1bb86b6f9
mergeFrom
public Builder mergeFrom(com.google.protobuf.Message other)
{    if (other instanceof org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader) {        return mergeFrom((org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader) other);    } else {        super.mergeFrom(other);        return this;    }}
ed65985e6d9c6864ef3daf47b0da0ae983ddf69224b75c48f426d50d241627d3
mergeFrom
public Builder mergeFrom(org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader other)
{    if (other == org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader.getDefaultInstance())        return this;    if (other.hasKey()) {        bitField0_ |= 0x00000001;        key_ = other.key_;        onChanged();    }    if (other.hasValue()) {        bitField0_ |= 0x00000002;        value_ = other.value_;        onChanged();    }    this.mergeUnknownFields(other.getUnknownFields());    return this;}
dde7cd718eaa61cad29906454acf122daba6680a2db55e4787a359a08951b5e7
isInitialized
public final boolean isInitialized()
{    if (!hasKey()) {        return false;    }    return true;}
576f0ac95d3431feb1ba705ec8f537aa5e5a58300021599ce7c111ed9b61d887
mergeFrom
public Builder mergeFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader parsedMessage = null;    try {        parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);    } catch (com.google.protobuf.InvalidProtocolBufferException e) {        parsedMessage = (org.apache.flume.channel.file.proto.ProtosFactory.FlumeEventHeader) e.getUnfinishedMessage();        throw e;    } finally {        if (parsedMessage != null) {            mergeFrom(parsedMessage);        }    }    return this;}
3d43f50bb45a9a7cdc6e13d035f0b5f07da624c7d610f8566643664d8f77e820
hasKey
public boolean hasKey()
{    return ((bitField0_ & 0x00000001) == 0x00000001);}
047c54d0c4ae0097629c78313543b21fe7c9606bce1b212deeadb1a9952aeb3d
getKey
public java.lang.String getKey()
{    java.lang.Object ref = key_;    if (!(ref instanceof java.lang.String)) {        java.lang.String s = ((com.google.protobuf.ByteString) ref).toStringUtf8();        key_ = s;        return s;    } else {        return (java.lang.String) ref;    }}
c8dcc45177cfe933c49df3d8f441fbd5849f0f6d52c8a3d5fa340554b6148110
getKeyBytes
public com.google.protobuf.ByteString getKeyBytes()
{    java.lang.Object ref = key_;    if (ref instanceof String) {        com.google.protobuf.ByteString b = com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);        key_ = b;        return b;    } else {        return (com.google.protobuf.ByteString) ref;    }}
65471569ebd53ddc1f87dbf3c9121b75837385f638061efc2f442b1bc6ade514
setKey
public Builder setKey(java.lang.String value)
{    if (value == null) {        throw new NullPointerException();    }    bitField0_ |= 0x00000001;    key_ = value;    onChanged();    return this;}
fd3b609f40656dfd56e30df7f92266f87a8a0f0f432c240eccfa696f884cfe86
clearKey
public Builder clearKey()
{    bitField0_ = (bitField0_ & ~0x00000001);    key_ = getDefaultInstance().getKey();    onChanged();    return this;}
7e170215373763644640fd5896d68e7c2d488c102fbf6986f0aa769d0b94ea18
setKeyBytes
public Builder setKeyBytes(com.google.protobuf.ByteString value)
{    if (value == null) {        throw new NullPointerException();    }    bitField0_ |= 0x00000001;    key_ = value;    onChanged();    return this;}
258d74581b7c36a36f14ac351a56248c96622e4794d629fa1d8f556bd5b32cfc
hasValue
public boolean hasValue()
{    return ((bitField0_ & 0x00000002) == 0x00000002);}
5fe750442f74fec8e2337d6a8f85d11f7ac11c410ea9afb9807e7c5e05520cae
getValue
public java.lang.String getValue()
{    java.lang.Object ref = value_;    if (!(ref instanceof java.lang.String)) {        java.lang.String s = ((com.google.protobuf.ByteString) ref).toStringUtf8();        value_ = s;        return s;    } else {        return (java.lang.String) ref;    }}
6c5e6d1ec43c0fe42bdf45c44e6e70be94206e44ce0ab238c28132b3a057b9b5
getValueBytes
public com.google.protobuf.ByteString getValueBytes()
{    java.lang.Object ref = value_;    if (ref instanceof String) {        com.google.protobuf.ByteString b = com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);        value_ = b;        return b;    } else {        return (com.google.protobuf.ByteString) ref;    }}
97aee92666fbbe7174a8ecb7afc7f48b55f1a7448995e6000a3c58f0f0e20244
setValue
public Builder setValue(java.lang.String value)
{    if (value == null) {        throw new NullPointerException();    }    bitField0_ |= 0x00000002;    value_ = value;    onChanged();    return this;}
7aa401423c5f6872ac77cd1e785966dfdaeb52a25ea98f216cee702f120a038c
clearValue
public Builder clearValue()
{    bitField0_ = (bitField0_ & ~0x00000002);    value_ = getDefaultInstance().getValue();    onChanged();    return this;}
bcdcfa6eb65ed115bfa428f4555f5c81aee3fb42a686421a03abd35a1ac32243
setValueBytes
public Builder setValueBytes(com.google.protobuf.ByteString value)
{    if (value == null) {        throw new NullPointerException();    }    bitField0_ |= 0x00000002;    value_ = value;    onChanged();    return this;}
d89a873db80c2368d8f6325a1db7f8e1359f195eeddfadda2a0e8079d1cd56ae
getDescriptor
public static com.google.protobuf.Descriptors.FileDescriptor getDescriptor()
{    return descriptor;}
224c23efa88f76f75befbf7108a56fdc531065116f2bd0df86a70845fc339c65
assignDescriptors
public com.google.protobuf.ExtensionRegistry assignDescriptors(com.google.protobuf.Descriptors.FileDescriptor root)
{    descriptor = root;    internal_static_Checkpoint_descriptor = getDescriptor().getMessageTypes().get(0);    internal_static_Checkpoint_fieldAccessorTable = new com.google.protobuf.GeneratedMessage.FieldAccessorTable(internal_static_Checkpoint_descriptor, new java.lang.String[] { "Version", "WriteOrderID", "QueueSize", "QueueHead", "ActiveLogs" });    internal_static_ActiveLog_descriptor = getDescriptor().getMessageTypes().get(1);    internal_static_ActiveLog_fieldAccessorTable = new com.google.protobuf.GeneratedMessage.FieldAccessorTable(internal_static_ActiveLog_descriptor, new java.lang.String[] { "LogFileID", "Count" });    internal_static_LogFileMetaData_descriptor = getDescriptor().getMessageTypes().get(2);    internal_static_LogFileMetaData_fieldAccessorTable = new com.google.protobuf.GeneratedMessage.FieldAccessorTable(internal_static_LogFileMetaData_descriptor, new java.lang.String[] { "Version", "LogFileID", "CheckpointPosition", "CheckpointWriteOrderID", "Encryption", "BackupCheckpointPosition", "BackupCheckpointWriteOrderID" });    internal_static_LogFileEncryption_descriptor = getDescriptor().getMessageTypes().get(3);    internal_static_LogFileEncryption_fieldAccessorTable = new com.google.protobuf.GeneratedMessage.FieldAccessorTable(internal_static_LogFileEncryption_descriptor, new java.lang.String[] { "CipherProvider", "KeyAlias", "Parameters" });    internal_static_TransactionEventHeader_descriptor = getDescriptor().getMessageTypes().get(4);    internal_static_TransactionEventHeader_fieldAccessorTable = new com.google.protobuf.GeneratedMessage.FieldAccessorTable(internal_static_TransactionEventHeader_descriptor, new java.lang.String[] { "Type", "TransactionID", "WriteOrderID" });    internal_static_Put_descriptor = getDescriptor().getMessageTypes().get(5);    internal_static_Put_fieldAccessorTable = new com.google.protobuf.GeneratedMessage.FieldAccessorTable(internal_static_Put_descriptor, new java.lang.String[] { "Event", "Checksum" });    internal_static_Take_descriptor = getDescriptor().getMessageTypes().get(6);    internal_static_Take_fieldAccessorTable = new com.google.protobuf.GeneratedMessage.FieldAccessorTable(internal_static_Take_descriptor, new java.lang.String[] { "FileID", "Offset" });    internal_static_Rollback_descriptor = getDescriptor().getMessageTypes().get(7);    internal_static_Rollback_fieldAccessorTable = new com.google.protobuf.GeneratedMessage.FieldAccessorTable(internal_static_Rollback_descriptor, new java.lang.String[] {});    internal_static_Commit_descriptor = getDescriptor().getMessageTypes().get(8);    internal_static_Commit_fieldAccessorTable = new com.google.protobuf.GeneratedMessage.FieldAccessorTable(internal_static_Commit_descriptor, new java.lang.String[] { "Type" });    internal_static_TransactionEventFooter_descriptor = getDescriptor().getMessageTypes().get(9);    internal_static_TransactionEventFooter_fieldAccessorTable = new com.google.protobuf.GeneratedMessage.FieldAccessorTable(internal_static_TransactionEventFooter_descriptor, new java.lang.String[] {});    internal_static_FlumeEvent_descriptor = getDescriptor().getMessageTypes().get(10);    internal_static_FlumeEvent_fieldAccessorTable = new com.google.protobuf.GeneratedMessage.FieldAccessorTable(internal_static_FlumeEvent_descriptor, new java.lang.String[] { "Headers", "Body" });    internal_static_FlumeEventHeader_descriptor = getDescriptor().getMessageTypes().get(11);    internal_static_FlumeEventHeader_fieldAccessorTable = new com.google.protobuf.GeneratedMessage.FieldAccessorTable(internal_static_FlumeEventHeader_descriptor, new java.lang.String[] { "Key", "Value" });    return null;}
69826425089e5a02115e66193942cf7d3632d27b331042ea763d5d27a9f2ed7a
getEvent
 FlumeEvent getEvent()
{    return event;}
5478cc5683f6dfd4515c383752d7c803555efc63d03fd84a03ba8dcd17eb4324
readFields
public void readFields(DataInput in) throws IOException
{    super.readFields(in);    event = FlumeEvent.from(in);}
a894510dd4db439ff8e17ae1059489dc3abc97178e5932ceed0c70c3af165401
write
public void write(DataOutput out) throws IOException
{    super.write(out);    event.write(out);}
ff459529bcc4ea422faba6b6520c4e8654b516e08262ab0f00c35a0a8eab1287
writeProtos
 void writeProtos(OutputStream out) throws IOException
{    ProtosFactory.Put.Builder putBuilder = ProtosFactory.Put.newBuilder();    ProtosFactory.FlumeEvent.Builder eventBuilder = ProtosFactory.FlumeEvent.newBuilder();    Map<String, String> headers = event.getHeaders();    ProtosFactory.FlumeEventHeader.Builder headerBuilder = ProtosFactory.FlumeEventHeader.newBuilder();    if (headers != null) {        for (String key : headers.keySet()) {            String value = headers.get(key);            headerBuilder.clear();            headerBuilder.setKey(key);            if (value != null) {                headerBuilder.setValue(value);            }            eventBuilder.addHeaders(headerBuilder.build());        }    }    eventBuilder.setBody(ByteString.copyFrom(event.getBody()));    ProtosFactory.FlumeEvent protoEvent = eventBuilder.build();    putBuilder.setEvent(protoEvent);    putBuilder.setChecksum(calculateChecksum(event.getBody()));    putBuilder.build().writeDelimitedTo(out);}
9fce46216a0ec11a452e592d1915c11fa2bd8433190fa7cff3a39fa461b51a99
readProtos
 void readProtos(InputStream in) throws IOException, CorruptEventException
{    ProtosFactory.Put put = Preconditions.checkNotNull(ProtosFactory.Put.parseDelimitedFrom(in), "Put cannot be null");    Map<String, String> headers = Maps.newHashMap();    ProtosFactory.FlumeEvent protosEvent = put.getEvent();    for (ProtosFactory.FlumeEventHeader header : protosEvent.getHeadersList()) {        headers.put(header.getKey(), header.getValue());    }    byte[] eventBody = protosEvent.getBody().toByteArray();    if (put.hasChecksum()) {        long eventBodyChecksum = calculateChecksum(eventBody);        if (eventBodyChecksum != put.getChecksum()) {            throw new CorruptEventException("Expected checksum for event was " + eventBodyChecksum + " but the checksum of the event is " + put.getChecksum());        }    }        event = new FlumeEvent(headers, eventBody);}
b1f1d76c4f123b199ac676efa189c76bf4ff0ae1d44ce83e4a370d276c5f56fc
calculateChecksum
protected long calculateChecksum(byte[] body)
{    checksum.reset();    checksum.update(body, 0, body.length);    return checksum.getValue();}
12991c1ba6d11bc0d9e819983daa54b7152b27e3c2559adf3376888457c16c11
getRecordType
public short getRecordType()
{    return Type.PUT.get();}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    StringBuilder builder = new StringBuilder();    builder.append("Put [event=");    builder.append(event);    builder.append(", getLogWriteOrderID()=");    builder.append(getLogWriteOrderID());    builder.append(", getTransactionID()=");    builder.append(getTransactionID());    builder.append("]");    return builder.toString();}
8df54b08ee09b4f121b16fa1d7eca39ba87e5d5a201e717044dc3e42611324c6
getReadCount
public int getReadCount()
{    return readCount;}
748c273b80f6fbb19de858e3bbac0785a6ea61b27a241f9b5a48075e98780cfb
getPutCount
public int getPutCount()
{    return putCount;}
b6b4b6b55518732a7847ce8d1f92d040503d8cdb0f340b2de1dad891b4a6a0b0
getTakeCount
public int getTakeCount()
{    return takeCount;}
25d4e6fa8594699dd66afa00aa26deebacd7db19797d60aa2662340536ef4c2b
getCommitCount
public int getCommitCount()
{    return commitCount;}
d38c4508d682e0ee5457a8cf8102b3b6369de1e877b1f0e5174b35c01fca332a
getRollbackCount
public int getRollbackCount()
{    return rollbackCount;}
1921041065845eb9d3df1bb7e372c1750e8ede75a255557d62e2d63a2f994ed1
replayLogv1
 void replayLogv1(List<File> logs) throws Exception
{    int total = 0;    int count = 0;    MultiMap transactionMap = new MultiValueMap();        SetMultimap<Long, Long> inflightPuts = queue.deserializeInflightPuts();    for (Long txnID : inflightPuts.keySet()) {        Set<Long> eventPointers = inflightPuts.get(txnID);        for (Long eventPointer : eventPointers) {            transactionMap.put(txnID, FlumeEventPointer.fromLong(eventPointer));        }    }    SetMultimap<Long, Long> inflightTakes = queue.deserializeInflightTakes();    LOG.info("Starting replay of " + logs);    for (File log : logs) {        LOG.info("Replaying " + log);        LogFile.SequentialReader reader = null;        try {            reader = LogFileFactory.getSequentialReader(log, encryptionKeyProvider, fsyncPerTransaction);            reader.skipToLastCheckpointPosition(queue.getLogWriteOrderID());            LogRecord entry;            FlumeEventPointer ptr;                                    int fileId = reader.getLogFileID();            while ((entry = reader.next()) != null) {                int offset = entry.getOffset();                TransactionEventRecord record = entry.getEvent();                short type = record.getRecordType();                long trans = record.getTransactionID();                readCount++;                if (record.getLogWriteOrderID() > lastCheckpoint) {                    if (type == TransactionEventRecord.Type.PUT.get()) {                        putCount++;                        ptr = new FlumeEventPointer(fileId, offset);                        transactionMap.put(trans, ptr);                    } else if (type == TransactionEventRecord.Type.TAKE.get()) {                        takeCount++;                        Take take = (Take) record;                        ptr = new FlumeEventPointer(take.getFileID(), take.getOffset());                        transactionMap.put(trans, ptr);                    } else if (type == TransactionEventRecord.Type.ROLLBACK.get()) {                        rollbackCount++;                        transactionMap.remove(trans);                    } else if (type == TransactionEventRecord.Type.COMMIT.get()) {                        commitCount++;                        @SuppressWarnings("unchecked")                        Collection<FlumeEventPointer> pointers = (Collection<FlumeEventPointer>) transactionMap.remove(trans);                        if (((Commit) record).getType() == TransactionEventRecord.Type.TAKE.get()) {                            if (inflightTakes.containsKey(trans)) {                                if (pointers == null) {                                    pointers = Sets.newHashSet();                                }                                Set<Long> takes = inflightTakes.removeAll(trans);                                Iterator<Long> it = takes.iterator();                                while (it.hasNext()) {                                    Long take = it.next();                                    pointers.add(FlumeEventPointer.fromLong(take));                                }                            }                        }                        if (pointers != null && pointers.size() > 0) {                            processCommit(((Commit) record).getType(), pointers);                            count += pointers.size();                        }                    } else {                        Preconditions.checkArgument(false, "Unknown record type: " + Integer.toHexString(type));                    }                } else {                    skipCount++;                }            }            LOG.info("Replayed " + count + " from " + log);            if (LOG.isDebugEnabled()) {                LOG.debug("read: " + readCount + ", put: " + putCount + ", take: " + takeCount + ", rollback: " + rollbackCount + ", commit: " + commitCount + ", skipp: " + skipCount);            }        } catch (EOFException e) {            LOG.warn("Hit EOF on " + log);        } finally {            total += count;            count = 0;            if (reader != null) {                reader.close();            }        }    }            int uncommittedTakes = 0;    for (Long inflightTxnId : inflightTakes.keySet()) {        Set<Long> inflightUncommittedTakes = inflightTakes.get(inflightTxnId);        for (Long inflightUncommittedTake : inflightUncommittedTakes) {            queue.addHead(FlumeEventPointer.fromLong(inflightUncommittedTake));            uncommittedTakes++;        }    }    inflightTakes.clear();    count += uncommittedTakes;    int pendingTakesSize = pendingTakes.size();    if (pendingTakesSize > 0) {        String msg = "Pending takes " + pendingTakesSize + " exist after the end of replay";        if (LOG.isDebugEnabled()) {            for (Long pointer : pendingTakes) {                LOG.debug("Pending take " + FlumeEventPointer.fromLong(pointer));            }        } else {            LOG.error(msg + ". Duplicate messages will exist in destination.");        }    }    LOG.info("Replayed " + total);}
a19189b3662a4399efa86e1ce17a3539fdb1d33ad0a93d7cc5edf681b71fde6d
replayLog
 void replayLog(List<File> logs) throws Exception
{    int count = 0;    MultiMap transactionMap = new MultiValueMap();        long transactionIDSeed = lastCheckpoint, writeOrderIDSeed = lastCheckpoint;    LOG.info("Starting replay of " + logs);            SetMultimap<Long, Long> inflightPuts = queue.deserializeInflightPuts();    for (Long txnID : inflightPuts.keySet()) {        Set<Long> eventPointers = inflightPuts.get(txnID);        for (Long eventPointer : eventPointers) {            transactionMap.put(txnID, FlumeEventPointer.fromLong(eventPointer));        }    }    SetMultimap<Long, Long> inflightTakes = queue.deserializeInflightTakes();    try {        for (File log : logs) {            LOG.info("Replaying " + log);            try {                LogFile.SequentialReader reader = LogFileFactory.getSequentialReader(log, encryptionKeyProvider, fsyncPerTransaction);                reader.skipToLastCheckpointPosition(queue.getLogWriteOrderID());                Preconditions.checkState(!readers.containsKey(reader.getLogFileID()), "Readers " + readers + " already contains " + reader.getLogFileID());                readers.put(reader.getLogFileID(), reader);                LogRecord logRecord = reader.next();                if (logRecord == null) {                    readers.remove(reader.getLogFileID());                    reader.close();                } else {                    logRecordBuffer.add(logRecord);                }            } catch (EOFException e) {                LOG.warn("Ignoring " + log + " due to EOF", e);            }        }        LogRecord entry = null;        FlumeEventPointer ptr = null;        while ((entry = next()) != null) {                                    int fileId = entry.getFileID();            int offset = entry.getOffset();            TransactionEventRecord record = entry.getEvent();            short type = record.getRecordType();            long trans = record.getTransactionID();            transactionIDSeed = Math.max(transactionIDSeed, trans);            writeOrderIDSeed = Math.max(writeOrderIDSeed, record.getLogWriteOrderID());            readCount++;            if (readCount % 10000 == 0 && readCount > 0) {                LOG.info("read: " + readCount + ", put: " + putCount + ", take: " + takeCount + ", rollback: " + rollbackCount + ", commit: " + commitCount + ", skip: " + skipCount + ", eventCount:" + count);            }            if (record.getLogWriteOrderID() > lastCheckpoint) {                if (type == TransactionEventRecord.Type.PUT.get()) {                    putCount++;                    ptr = new FlumeEventPointer(fileId, offset);                    transactionMap.put(trans, ptr);                } else if (type == TransactionEventRecord.Type.TAKE.get()) {                    takeCount++;                    Take take = (Take) record;                    ptr = new FlumeEventPointer(take.getFileID(), take.getOffset());                    transactionMap.put(trans, ptr);                } else if (type == TransactionEventRecord.Type.ROLLBACK.get()) {                    rollbackCount++;                    transactionMap.remove(trans);                } else if (type == TransactionEventRecord.Type.COMMIT.get()) {                    commitCount++;                    @SuppressWarnings("unchecked")                    Collection<FlumeEventPointer> pointers = (Collection<FlumeEventPointer>) transactionMap.remove(trans);                    if (((Commit) record).getType() == TransactionEventRecord.Type.TAKE.get()) {                        if (inflightTakes.containsKey(trans)) {                            if (pointers == null) {                                pointers = Sets.newHashSet();                            }                            Set<Long> takes = inflightTakes.removeAll(trans);                            Iterator<Long> it = takes.iterator();                            while (it.hasNext()) {                                Long take = it.next();                                pointers.add(FlumeEventPointer.fromLong(take));                            }                        }                    }                    if (pointers != null && pointers.size() > 0) {                        processCommit(((Commit) record).getType(), pointers);                        count += pointers.size();                    }                } else {                    Preconditions.checkArgument(false, "Unknown record type: " + Integer.toHexString(type));                }            } else {                skipCount++;            }        }        LOG.info("read: " + readCount + ", put: " + putCount + ", take: " + takeCount + ", rollback: " + rollbackCount + ", commit: " + commitCount + ", skip: " + skipCount + ", eventCount:" + count);        queue.replayComplete();    } finally {        TransactionIDOracle.setSeed(transactionIDSeed);        WriteOrderOracle.setSeed(writeOrderIDSeed);        for (LogFile.SequentialReader reader : readers.values()) {            if (reader != null) {                reader.close();            }        }    }            int uncommittedTakes = 0;    for (Long inflightTxnId : inflightTakes.keySet()) {        Set<Long> inflightUncommittedTakes = inflightTakes.get(inflightTxnId);        for (Long inflightUncommittedTake : inflightUncommittedTakes) {            queue.addHead(FlumeEventPointer.fromLong(inflightUncommittedTake));            uncommittedTakes++;        }    }    inflightTakes.clear();    count += uncommittedTakes;    int pendingTakesSize = pendingTakes.size();    if (pendingTakesSize > 0) {        LOG.info("Pending takes " + pendingTakesSize + " exist after the" + " end of replay. Duplicate messages will exist in" + " destination.");    }}
6855befb52301b64144c34cfd266de2c603e9d2bffaf5b7f990c10439de0ee10
next
private LogRecord next() throws IOException, CorruptEventException
{    LogRecord resultLogRecord = logRecordBuffer.poll();    if (resultLogRecord != null) {                LogFile.SequentialReader reader = readers.get(resultLogRecord.getFileID());        LogRecord nextLogRecord;        if ((nextLogRecord = reader.next()) != null) {            logRecordBuffer.add(nextLogRecord);        }    }    return resultLogRecord;}
2b66d376da84953b2cddb88b13feef26e3f8355910b5856152cefe9ce2b91087
processCommit
private void processCommit(short type, Collection<FlumeEventPointer> pointers)
{    if (type == TransactionEventRecord.Type.PUT.get()) {        for (FlumeEventPointer pointer : pointers) {            if (!queue.addTail(pointer)) {                throw new IllegalStateException("Unable to add " + pointer + ". Queue depth = " + queue.getSize() + ", Capacity = " + queue.getCapacity());            }            if (pendingTakes.remove(pointer.toLong())) {                Preconditions.checkState(queue.remove(pointer), "Take was pending and pointer was successfully added to the" + " queue but could not be removed: " + pointer);            }        }    } else if (type == TransactionEventRecord.Type.TAKE.get()) {        for (FlumeEventPointer pointer : pointers) {            boolean removed = queue.remove(pointer);            if (!removed) {                pendingTakes.add(pointer.toLong());            }        }    } else {        Preconditions.checkArgument(false, "Unknown record type: " + Integer.toHexString(type));    }}
5478cc5683f6dfd4515c383752d7c803555efc63d03fd84a03ba8dcd17eb4324
readFields
public void readFields(DataInput in) throws IOException
{    super.readFields(in);}
a894510dd4db439ff8e17ae1059489dc3abc97178e5932ceed0c70c3af165401
write
public void write(DataOutput out) throws IOException
{    super.write(out);}
ff459529bcc4ea422faba6b6520c4e8654b516e08262ab0f00c35a0a8eab1287
writeProtos
 void writeProtos(OutputStream out) throws IOException
{    ProtosFactory.Rollback.Builder rollbackBuilder = ProtosFactory.Rollback.newBuilder();    rollbackBuilder.build().writeDelimitedTo(out);}
ed3036c0872aa703f9545ed610d496273c0e0d83e257a6ac951369babec5826f
readProtos
 void readProtos(InputStream in) throws IOException
{    @SuppressWarnings("unused")    ProtosFactory.Rollback rollback = Preconditions.checkNotNull(ProtosFactory.Rollback.parseDelimitedFrom(in), "Rollback cannot be null");}
147f0f476f4c0d7cf6562426d486e8b3ee28674432ee6bf7aba345b8ab78c816
getRecordType
 short getRecordType()
{    return Type.ROLLBACK.get();}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    StringBuilder builder = new StringBuilder();    builder.append("Rollback [getLogWriteOrderID()=");    builder.append(getLogWriteOrderID());    builder.append(", getTransactionID()=");    builder.append(getTransactionID());    builder.append("]");    return builder.toString();}
f7ac213c7204ddc2fa960f524491ef5596e8c92c0163f470672d1039e4c8c78f
getMetaDataTempFile
 static File getMetaDataTempFile(File metaDataFile)
{    String metaDataFileName = metaDataFile.getName() + METADATA_TMP_FILENAME;    return new File(metaDataFile.getParentFile(), metaDataFileName);}
f21c0afc5d9111f8b6b64eb04eba94c8e42b604d1df35ed8fa29cb5e16cbe7be
getMetaDataFile
 static File getMetaDataFile(File file)
{    String metaDataFileName = file.getName() + METADATA_FILENAME;    return new File(file.getParentFile(), metaDataFileName);}
e65c5fb4b79dc45c7ccda5452a3e8f9934958c568603d8a7e416c6a49821638e
getOldMetaDataFile
 static File getOldMetaDataFile(File file)
{    String oldMetaDataFileName = file.getName() + OLD_METADATA_FILENAME;    return new File(file.getParentFile(), oldMetaDataFileName);}
4cded206836b9f59201a46ab78f4e283f90dac44d5486502cfe69dc311fd0347
deleteAllFiles
 static boolean deleteAllFiles(File checkpointDir, @Nullable Set<String> excludes)
{    if (!checkpointDir.isDirectory()) {        return false;    }    File[] files = checkpointDir.listFiles();    if (files == null) {        return false;    }    StringBuilder builder;    if (files.length == 0) {        return true;    } else {        builder = new StringBuilder("Deleted the following files: ");    }    if (excludes == null) {        excludes = Collections.emptySet();    }    for (File file : files) {        if (excludes.contains(file.getName())) {            LOG.info("Skipping " + file.getName() + " because it is in excludes " + "set");            continue;        }        if (!FileUtils.deleteQuietly(file)) {            LOG.info(builder.toString());            LOG.error("Error while attempting to delete: " + file.getAbsolutePath());            return false;        }        builder.append(", ").append(file.getName());    }    builder.append(".");    LOG.info(builder.toString());    return true;}
8ddf3cd79c552c3a00eb3c17e9c14ae7618add8eea7aab034357fc77c09f205f
copyFile
public static boolean copyFile(File from, File to) throws IOException
{    Preconditions.checkNotNull(from, "Source file is null, file copy failed.");    Preconditions.checkNotNull(to, "Destination file is null, " + "file copy failed.");    Preconditions.checkState(from.exists(), "Source file: " + from.toString() + " does not exist.");    Preconditions.checkState(!to.exists(), "Destination file: " + to.toString() + " unexpectedly exists.");    BufferedInputStream in = null;        RandomAccessFile out = null;    try {        in = new BufferedInputStream(new FileInputStream(from));        out = new RandomAccessFile(to, "rw");        byte[] buf = new byte[FILE_BUFFER_SIZE];        int total = 0;        while (true) {            int read = in.read(buf);            if (read == -1) {                break;            }            out.write(buf, 0, read);            total += read;        }        out.getFD().sync();        Preconditions.checkState(total == from.length(), "The size of the origin file and destination file are not equal.");        return true;    } catch (Exception ex) {        LOG.error("Error while attempting to copy " + from.toString() + " to " + to.toString() + ".", ex);        Throwables.propagate(ex);    } finally {        Throwable th = null;        try {            if (in != null) {                in.close();            }        } catch (Throwable ex) {            LOG.error("Error while closing input file.", ex);            th = ex;        }        try {            if (out != null) {                out.close();            }        } catch (IOException ex) {            LOG.error("Error while closing output file.", ex);            Throwables.propagate(ex);        }        if (th != null) {            Throwables.propagate(th);        }    }        throw new IOException("Copying file: " + from.toString() + " to: " + to.toString() + " may have failed.");}
c6cdeea034600c5fb5177ab8201417bf4cabbb7308219f4e905a55bb7cb1eb87
compressFile
public static boolean compressFile(File uncompressed, File compressed) throws IOException
{    Preconditions.checkNotNull(uncompressed, "Source file is null, compression failed.");    Preconditions.checkNotNull(compressed, "Destination file is null, compression failed.");    Preconditions.checkState(uncompressed.exists(), "Source file: " + uncompressed.toString() + " does not exist.");    Preconditions.checkState(!compressed.exists(), "Compressed file: " + compressed.toString() + " unexpectedly " + "exists.");    BufferedInputStream in = null;    FileOutputStream out = null;    SnappyOutputStream snappyOut = null;    try {        in = new BufferedInputStream(new FileInputStream(uncompressed));        out = new FileOutputStream(compressed);        snappyOut = new SnappyOutputStream(out);        byte[] buf = new byte[FILE_BUFFER_SIZE];        while (true) {            int read = in.read(buf);            if (read == -1) {                break;            }            snappyOut.write(buf, 0, read);        }        out.getFD().sync();        return true;    } catch (Exception ex) {        LOG.error("Error while attempting to compress " + uncompressed.toString() + " to " + compressed.toString() + ".", ex);        Throwables.propagate(ex);    } finally {        Throwable th = null;        try {            if (in != null) {                in.close();            }        } catch (Throwable ex) {            LOG.error("Error while closing input file.", ex);            th = ex;        }        try {            if (snappyOut != null) {                snappyOut.close();            }        } catch (IOException ex) {            LOG.error("Error while closing output file.", ex);            Throwables.propagate(ex);        }        if (th != null) {            Throwables.propagate(th);        }    }        throw new IOException("Copying file: " + uncompressed.toString() + " to: " + compressed.toString() + " may have failed.");}
92e7852ef1f5f0d8f5a08e437e05df67698bf956482daf2bc5f8c8a87c634b96
decompressFile
public static boolean decompressFile(File compressed, File decompressed) throws IOException
{    Preconditions.checkNotNull(compressed, "Source file is null, decompression failed.");    Preconditions.checkNotNull(decompressed, "Destination file is " + "null, decompression failed.");    Preconditions.checkState(compressed.exists(), "Source file: " + compressed.toString() + " does not exist.");    Preconditions.checkState(!decompressed.exists(), "Decompressed file: " + decompressed.toString() + " unexpectedly exists.");    BufferedInputStream in = null;    SnappyInputStream snappyIn = null;    FileOutputStream out = null;    try {        in = new BufferedInputStream(new FileInputStream(compressed));        snappyIn = new SnappyInputStream(in);        out = new FileOutputStream(decompressed);        byte[] buf = new byte[FILE_BUFFER_SIZE];        while (true) {            int read = snappyIn.read(buf);            if (read == -1) {                break;            }            out.write(buf, 0, read);        }        out.getFD().sync();        return true;    } catch (Exception ex) {        LOG.error("Error while attempting to compress " + compressed.toString() + " to " + decompressed.toString() + ".", ex);        Throwables.propagate(ex);    } finally {        Throwable th = null;        try {            if (in != null) {                in.close();            }        } catch (Throwable ex) {            LOG.error("Error while closing input file.", ex);            th = ex;        }        try {            if (snappyIn != null) {                snappyIn.close();            }        } catch (IOException ex) {            LOG.error("Error while closing output file.", ex);            Throwables.propagate(ex);        }        if (th != null) {            Throwables.propagate(th);        }    }        throw new IOException("Decompressing file: " + compressed.toString() + " to: " + decompressed.toString() + " may have failed.");}
bac23a8fc6fffed654c50d3177925aad71721d720df30d650b70b9983be5436a
getOffset
 int getOffset()
{    return offset;}
5e7fde6fc47b6006059dd577db1ae0c9ccc55096d3ad388b5279bb5c428839bb
getFileID
 int getFileID()
{    return fileID;}
5478cc5683f6dfd4515c383752d7c803555efc63d03fd84a03ba8dcd17eb4324
readFields
public void readFields(DataInput in) throws IOException
{    super.readFields(in);    offset = in.readInt();    fileID = in.readInt();}
a894510dd4db439ff8e17ae1059489dc3abc97178e5932ceed0c70c3af165401
write
public void write(DataOutput out) throws IOException
{    super.write(out);    out.writeInt(offset);    out.writeInt(fileID);}
ff459529bcc4ea422faba6b6520c4e8654b516e08262ab0f00c35a0a8eab1287
writeProtos
 void writeProtos(OutputStream out) throws IOException
{    ProtosFactory.Take.Builder takeBuilder = ProtosFactory.Take.newBuilder();    takeBuilder.setFileID(fileID);    takeBuilder.setOffset(offset);    takeBuilder.build().writeDelimitedTo(out);}
ed3036c0872aa703f9545ed610d496273c0e0d83e257a6ac951369babec5826f
readProtos
 void readProtos(InputStream in) throws IOException
{    ProtosFactory.Take take = Preconditions.checkNotNull(ProtosFactory.Take.parseDelimitedFrom(in), "Take cannot be null");    fileID = take.getFileID();    offset = take.getOffset();}
147f0f476f4c0d7cf6562426d486e8b3ee28674432ee6bf7aba345b8ab78c816
getRecordType
 short getRecordType()
{    return Type.TAKE.get();}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    StringBuilder builder = new StringBuilder();    builder.append("Take [offset=");    builder.append(offset);    builder.append(", fileID=");    builder.append(fileID);    builder.append(", getLogWriteOrderID()=");    builder.append(getLogWriteOrderID());    builder.append(", getTransactionID()=");    builder.append(getTransactionID());    builder.append("]");    return builder.toString();}
5478cc5683f6dfd4515c383752d7c803555efc63d03fd84a03ba8dcd17eb4324
readFields
public void readFields(DataInput in) throws IOException
{}
a894510dd4db439ff8e17ae1059489dc3abc97178e5932ceed0c70c3af165401
write
public void write(DataOutput out) throws IOException
{}
6f899e2330de3aa68f5a005ba9aabc09d680e404a4d3d21223717d239ab0ee4d
getLogWriteOrderID
 long getLogWriteOrderID()
{    return logWriteOrderID;}
57f91049b8c3983afd59ced3320bda2b928206ed4d66c8aad7888015595c7919
getTransactionID
 long getTransactionID()
{    return transactionID;}
99b7baf68ad64807ad3ba4ff647ffd5c9cf6b86a52e2b9112c03b2c044eb089b
get
public short get()
{    return id;}
d1bb4c624798550ba89c08dd14a015384d7b05b9ce122eeb21eb1bc7935facde
toByteBufferV2
 static ByteBuffer toByteBufferV2(TransactionEventRecord record)
{    ByteArrayOutputStream byteOutput = new ByteArrayOutputStream(512);    DataOutputStream dataOutput = new DataOutputStream(byteOutput);    try {        dataOutput.writeInt(MAGIC_HEADER);        dataOutput.writeShort(record.getRecordType());        dataOutput.writeLong(record.getTransactionID());        dataOutput.writeLong(record.getLogWriteOrderID());        record.write(dataOutput);        dataOutput.flush();                return ByteBuffer.wrap(byteOutput.toByteArray());    } catch (IOException e) {                throw Throwables.propagate(e);    } finally {        if (dataOutput != null) {            try {                dataOutput.close();            } catch (IOException e) {                LOG.warn("Error closing byte array output stream", e);            }        }    }}
8006052de42cd87a592faf0e98547df412d182d20e491396fb9c6fd3900f3813
fromDataInputV2
 static TransactionEventRecord fromDataInputV2(DataInput in) throws IOException
{    int header = in.readInt();    if (header != MAGIC_HEADER) {        throw new IOException("Header " + Integer.toHexString(header) + " is not the required value: " + Integer.toHexString(MAGIC_HEADER));    }    short type = in.readShort();    long transactionID = in.readLong();    long writeOrderID = in.readLong();    TransactionEventRecord entry = newRecordForType(type, transactionID, writeOrderID);    entry.readFields(in);    return entry;}
56382f8a8415ce623a251ae02445000f31ecbdabfdf274cb840676f201ec8229
toByteBuffer
 static ByteBuffer toByteBuffer(TransactionEventRecord record)
{    ByteArrayOutputStream byteOutput = new ByteArrayOutputStream(512);    try {        ProtosFactory.TransactionEventHeader.Builder headerBuilder = ProtosFactory.TransactionEventHeader.newBuilder();        headerBuilder.setType(record.getRecordType());        headerBuilder.setTransactionID(record.getTransactionID());        headerBuilder.setWriteOrderID(record.getLogWriteOrderID());        headerBuilder.build().writeDelimitedTo(byteOutput);        record.writeProtos(byteOutput);        ProtosFactory.TransactionEventFooter footer = ProtosFactory.TransactionEventFooter.newBuilder().build();        footer.writeDelimitedTo(byteOutput);        return ByteBuffer.wrap(byteOutput.toByteArray());    } catch (IOException e) {        throw Throwables.propagate(e);    } finally {        if (byteOutput != null) {            try {                byteOutput.close();            } catch (IOException e) {                LOG.warn("Error closing byte array output stream", e);            }        }    }}
861c9e4005a6df1e494075dc19b04801fa891d91bbe34c7ab530982aa8f42557
fromByteArray
 static TransactionEventRecord fromByteArray(byte[] buffer) throws IOException, CorruptEventException
{    ByteArrayInputStream in = new ByteArrayInputStream(buffer);    try {        ProtosFactory.TransactionEventHeader header = Preconditions.checkNotNull(ProtosFactory.TransactionEventHeader.parseDelimitedFrom(in), "Header cannot be null");        short type = (short) header.getType();        long transactionID = header.getTransactionID();        long writeOrderID = header.getWriteOrderID();        TransactionEventRecord transactionEvent = newRecordForType(type, transactionID, writeOrderID);        transactionEvent.readProtos(in);        @SuppressWarnings("unused")        ProtosFactory.TransactionEventFooter footer = Preconditions.checkNotNull(ProtosFactory.TransactionEventFooter.parseDelimitedFrom(in), "Footer cannot be null");        return transactionEvent;    } catch (InvalidProtocolBufferException ex) {        throw new CorruptEventException("Could not parse event from data file.", ex);    } finally {        try {            in.close();        } catch (IOException e) {            LOG.warn("Error closing byte array input stream", e);        }    }}
ea57316a405b45d9162b7f521048e02eccd7b66908177a1ac1cb0543ce01dee2
getName
 static String getName(short type)
{    Constructor<? extends TransactionEventRecord> constructor = TYPES.get(type);    Preconditions.checkNotNull(constructor, "Unknown action " + Integer.toHexString(type));    return constructor.getDeclaringClass().getSimpleName();}
26b574c279205f228da1172fb01c2835ea4f58d6481eeae1172fa7e1a39efdd1
newRecordForType
private static TransactionEventRecord newRecordForType(short type, long transactionID, long writeOrderID)
{    Constructor<? extends TransactionEventRecord> constructor = TYPES.get(type);    Preconditions.checkNotNull(constructor, "Unknown action " + Integer.toHexString(type));    try {        return constructor.newInstance(transactionID, writeOrderID);    } catch (Exception e) {        throw Throwables.propagate(e);    }}
eb9dd7d0fcd80bd04997cdf231b17836afbbebc2f5a51cec623d9f1e39cdc91a
setSeed
public static void setSeed(long highest)
{    long previous;    while (highest > (previous = TRANSACTION_ID.get())) {        TRANSACTION_ID.compareAndSet(previous, highest);    }}
5935ba3d04875cfe9832271d049826605ad918ef8a10df379ca3a4d2e3c7c0be
next
public static long next()
{    return TRANSACTION_ID.incrementAndGet();}
8303f9f3e3b2e144f7049b79e76cebe24d9103d0acd24e201f26f50bfd4430f8
writeVInt
public static void writeVInt(DataOutput stream, int i) throws IOException
{    writeVLong(stream, i);}
e9562e466f35a453b656ae8d69bbe91b95a4f4403d218c7e220ebd86f2788d7f
writeVLong
public static void writeVLong(DataOutput stream, long i) throws IOException
{    if (i >= -112 && i <= 127) {        stream.writeByte((byte) i);        return;    }    int len = -112;    if (i < 0) {                i ^= -1L;        len = -120;    }    long tmp = i;    while (tmp != 0) {        tmp = tmp >> 8;        len--;    }    stream.writeByte((byte) len);    len = (len < -120) ? -(len + 120) : -(len + 112);    for (int idx = len; idx != 0; idx--) {        int shiftbits = (idx - 1) * 8;        long mask = 0xFFL << shiftbits;        stream.writeByte((byte) ((i & mask) >> shiftbits));    }}
60440c6dc93a79da2e1414b9096ae37873ad7f1cc024c7d3d68e9572e3752b58
readVLong
public static long readVLong(DataInput stream) throws IOException
{    byte firstByte = stream.readByte();    int len = decodeVIntSize(firstByte);    if (len == 1) {        return firstByte;    }    long i = 0;    for (int idx = 0; idx < len - 1; idx++) {        byte b = stream.readByte();        i = i << 8;        i = i | (b & 0xFF);    }    return (isNegativeVInt(firstByte) ? (i ^ -1L) : i);}
30d48f64de6128aa01c1aff642f01b57102885a575bca7a9c2176e3d7b9bbadd
readVInt
public static int readVInt(DataInput stream) throws IOException
{    long n = readVLong(stream);    if ((n > Integer.MAX_VALUE) || (n < Integer.MIN_VALUE)) {        throw new IOException("value too long to fit in integer");    }    return (int) n;}
af140b7a032261cecca683243a5b3420358cf53609e91414dfecd8524538be0e
isNegativeVInt
public static boolean isNegativeVInt(byte value)
{    return value < -120 || (value >= -112 && value < 0);}
daac91c6716bed534b4a71fe5eae42c1c216c795d7aac042287eb06642bbcd43
decodeVIntSize
public static int decodeVIntSize(byte value)
{    if (value >= -112) {        return 1;    } else if (value < -120) {        return -119 - value;    }    return -111 - value;}
eb9dd7d0fcd80bd04997cdf231b17836afbbebc2f5a51cec623d9f1e39cdc91a
setSeed
public static void setSeed(long highest)
{    long previous;    while (highest > (previous = WRITER_ORDERER.get())) {        WRITER_ORDERER.compareAndSet(previous, highest);    }}
5935ba3d04875cfe9832271d049826605ad918ef8a10df379ca3a4d2e3c7c0be
next
public static long next()
{    return WRITER_ORDERER.incrementAndGet();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    run = true;    while (run && count < until) {        boolean error = true;        try {            if (Sink.Status.READY.equals(sink.process())) {                count++;                error = false;            }        } catch (Exception ex) {            errors.add(ex);        }        if (error) {            try {                Thread.sleep(1000L);            } catch (InterruptedException e) {            }        }    }}
df491dc8b9ff7b029a14c1088c98b538ae923511d668b67ae742be7c636ab813
shutdown
public void shutdown()
{    run = false;}
29fa59e92e8a9fa433fd7b38ebb21e8ece484149bc8e4a2726bba6f5dab39acf
getCount
public int getCount()
{    return count;}
a407d91a774f57efe813e5e26e48006c3516df5330c47f452c999cdf8d8c1df8
getErrors
public List<Exception> getErrors()
{    return errors;}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    run = true;    while (run && count < until) {        boolean error = true;        try {            if (PollableSource.Status.READY.equals(source.process())) {                count++;                error = false;            }        } catch (Exception ex) {            errors.add(ex);        }        if (error) {            try {                Thread.sleep(1000L);            } catch (InterruptedException e) {            }        }    }}
df491dc8b9ff7b029a14c1088c98b538ae923511d668b67ae742be7c636ab813
shutdown
public void shutdown()
{    run = false;}
29fa59e92e8a9fa433fd7b38ebb21e8ece484149bc8e4a2726bba6f5dab39acf
getCount
public int getCount()
{    return count;}
a407d91a774f57efe813e5e26e48006c3516df5330c47f452c999cdf8d8c1df8
getErrors
public List<Exception> getErrors()
{    return errors;}
ced3637227837bc8935023b279f6d11e541ba2dd6bbaff26ba3afa81b2fd1240
test
public void test() throws Exception
{    testBasic();    testEmpty();    testNullPlainText();    testNullCipherText();}
374f30b9565fa26944e766e4b0405ecb054a03175df55727b3e28dc9fd8468ac
testBasic
public void testBasic() throws Exception
{    String expected = "mn state fair is the place to be";    byte[] cipherText = encryptor.encrypt(expected.getBytes(Charsets.UTF_8));    byte[] clearText = decryptor.decrypt(cipherText);    Assert.assertEquals(expected, new String(clearText, Charsets.UTF_8));}
78a274d3e62b678bde84ffa04fce2257229222b9cdb81f0cda384c23968ba864
testEmpty
public void testEmpty() throws Exception
{    String expected = "";    byte[] cipherText = encryptor.encrypt(new byte[] {});    byte[] clearText = decryptor.decrypt(cipherText);    Assert.assertEquals(expected, new String(clearText));}
f4b07f380da5fe821c5eab0c543d0d69e519142020c8ed193239dcf530c68644
testNullPlainText
public void testNullPlainText() throws Exception
{    try {        encryptor.encrypt(null);        Assert.fail();    } catch (NullPointerException e) {        }}
800b8ffb618fc68ad0d5081ce0bc7a948569a9aaa3c9c5190128ba6a965ec4cc
testNullCipherText
public void testNullCipherText() throws Exception
{    try {        decryptor.decrypt(null);        Assert.fail();    } catch (NullPointerException e) {        }}
ee8e5674f64f36b5bca5742fd6e06fa2e1423539a06ca090eb8d0faaf9958e99
newKey
private static Key newKey()
{    KeyGenerator keyGen;    try {        keyGen = KeyGenerator.getInstance("AES");        Key key = keyGen.generateKey();        return key;    } catch (Exception e) {        throw Throwables.propagate(e);    }}
98319e3c9cd43e28e9c50b750a045e96e8e58d0bb0a0ffe37feeb1f78c7a077e
createKeyStore
public static void createKeyStore(File keyStoreFile, File keyStorePasswordFile, Map<String, File> keyAliasPassword) throws Exception
{    KeyStore ks = KeyStore.getInstance("jceks");    ks.load(null);    List<String> keysWithSeperatePasswords = Lists.newArrayList();    for (String alias : keyAliasPassword.keySet()) {        Key key = newKey();        char[] password = null;        File passwordFile = keyAliasPassword.get(alias);        if (passwordFile == null) {            password = Files.toString(keyStorePasswordFile, Charsets.UTF_8).toCharArray();        } else {            keysWithSeperatePasswords.add(alias);            password = Files.toString(passwordFile, Charsets.UTF_8).toCharArray();        }        ks.setKeyEntry(alias, key, password, null);    }    char[] keyStorePassword = Files.toString(keyStorePasswordFile, Charsets.UTF_8).toCharArray();    FileOutputStream outputStream = new FileOutputStream(keyStoreFile);    ks.store(outputStream, keyStorePassword);    outputStream.close();}
8083d2609d6a745c54b105d448d225e11cb81f1df1220f9203e181860458643d
configureTestKeyStore
public static Map<String, File> configureTestKeyStore(File baseDir, File keyStoreFile) throws IOException
{    Map<String, File> result = Maps.newHashMap();    if (System.getProperty("java.vendor").contains("IBM")) {        Resources.copy(Resources.getResource("ibm-test.keystore"), new FileOutputStream(keyStoreFile));    } else {        Resources.copy(Resources.getResource("sun-test.keystore"), new FileOutputStream(keyStoreFile));    }    /* Commands below:     * keytool -genseckey -alias key-0 -keypass keyPassword -keyalg AES \     *   -keysize 128 -validity 9000 -keystore src/test/resources/test.keystore \     *   -storetype jceks -storepass keyStorePassword     * keytool -genseckey -alias key-1 -keyalg AES -keysize 128 -validity 9000 \     *   -keystore src/test/resources/test.keystore -storetype jceks \     *   -storepass keyStorePassword     */        result.put("key-0", TestUtils.writeStringToFile(baseDir, "key-0", "keyPassword"));    result.put("key-1", null);    return result;}
de0d32b59724782f05d949314cf2980133b614f8b68531f8d5c2644b5e27ffc5
configureForKeyStore
public static Map<String, String> configureForKeyStore(File keyStoreFile, File keyStorePasswordFile, Map<String, File> keyAliasPassword) throws Exception
{    Map<String, String> context = Maps.newHashMap();    List<String> keys = Lists.newArrayList();    Joiner joiner = Joiner.on(".");    for (String alias : keyAliasPassword.keySet()) {        File passwordFile = keyAliasPassword.get(alias);        if (passwordFile == null) {            keys.add(alias);        } else {            String propertyName = joiner.join(EncryptionConfiguration.KEY_PROVIDER, EncryptionConfiguration.JCE_FILE_KEYS, alias, EncryptionConfiguration.JCE_FILE_KEY_PASSWORD_FILE);            keys.add(alias);            context.put(propertyName, passwordFile.getAbsolutePath());        }    }    context.put(joiner.join(EncryptionConfiguration.KEY_PROVIDER, EncryptionConfiguration.JCE_FILE_KEY_STORE_FILE), keyStoreFile.getAbsolutePath());    if (keyStorePasswordFile != null) {        context.put(joiner.join(EncryptionConfiguration.KEY_PROVIDER, EncryptionConfiguration.JCE_FILE_KEY_STORE_PASSWORD_FILE), keyStorePasswordFile.getAbsolutePath());    }    context.put(joiner.join(EncryptionConfiguration.KEY_PROVIDER, EncryptionConfiguration.JCE_FILE_KEYS), Joiner.on(" ").join(keys));    return context;}
27681e68ec2a1eb903f955680ebe003ceb3707295c8aad884b692d378c6e37cf
setup
public void setup() throws Exception
{    KeyGenerator keyGen = KeyGenerator.getInstance("AES");    key = keyGen.generateKey();    encryptor = CipherProviderFactory.getEncrypter(CipherProviderType.AESCTRNOPADDING.name(), key);    decryptor = CipherProviderFactory.getDecrypter(CipherProviderType.AESCTRNOPADDING.name(), key, encryptor.getParameters());    cipherProviderTestSuite = new CipherProviderTestSuite(encryptor, decryptor);}
ced3637227837bc8935023b279f6d11e541ba2dd6bbaff26ba3afa81b2fd1240
test
public void test() throws Exception
{    cipherProviderTestSuite.test();}
27681e68ec2a1eb903f955680ebe003ceb3707295c8aad884b692d378c6e37cf
setup
public void setup() throws Exception
{    super.setup();    keyStorePasswordFile = new File(baseDir, "keyStorePasswordFile");    Files.write("keyStorePassword", keyStorePasswordFile, Charsets.UTF_8);    keyStoreFile = new File(baseDir, "keyStoreFile");    Assert.assertTrue(keyStoreFile.createNewFile());    keyAliasPassword = Maps.newHashMap();    keyAliasPassword.putAll(EncryptionTestUtils.configureTestKeyStore(baseDir, keyStoreFile));}
ec8b6259c87a96a7e78ab8ec13a826f2caf0d2a1c593d4aec011e181f3e17bbf
teardown
public void teardown()
{    super.teardown();}
85635c999a7bcba4dbbcf8974dbf4cb48dec43e958941fb791d04824b273027a
getOverrides
private Map<String, String> getOverrides() throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.CAPACITY, String.valueOf(100));    overrides.put(FileChannelConfiguration.TRANSACTION_CAPACITY, String.valueOf(100));    return overrides;}
178f491e7ee11296588387928877a71fcce9037549691d048a0c79fbe4ddb6e2
getOverridesForEncryption
private Map<String, String> getOverridesForEncryption() throws Exception
{    Map<String, String> overrides = getOverrides();    Map<String, String> encryptionProps = EncryptionTestUtils.configureForKeyStore(keyStoreFile, keyStorePasswordFile, keyAliasPassword);    encryptionProps.put(EncryptionConfiguration.KEY_PROVIDER, KeyProviderType.JCEKSFILE.name());    encryptionProps.put(EncryptionConfiguration.CIPHER_PROVIDER, CipherProviderType.AESCTRNOPADDING.name());    encryptionProps.put(EncryptionConfiguration.ACTIVE_KEY, "key-1");    for (String key : encryptionProps.keySet()) {        overrides.put(EncryptionConfiguration.ENCRYPTION_PREFIX + "." + key, encryptionProps.get(key));    }    return overrides;}
a73caca4a144137e21cb8fceaf6952d2f75af1aee51bcda50c67d1bd845c0d9b
testThreadedConsume
public void testThreadedConsume() throws Exception
{    int numThreads = 20;    Map<String, String> overrides = getOverridesForEncryption();    overrides.put(FileChannelConfiguration.CAPACITY, String.valueOf(10000));    overrides.put(FileChannelConfiguration.TRANSACTION_CAPACITY, String.valueOf(100));    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Executor executor = Executors.newFixedThreadPool(numThreads);    Set<String> in = fillChannel(channel, "threaded-consume");    final AtomicBoolean error = new AtomicBoolean(false);    final CountDownLatch startLatch = new CountDownLatch(numThreads);    final CountDownLatch stopLatch = new CountDownLatch(numThreads);    final Set<String> out = Collections.synchronizedSet(new HashSet<String>());    for (int i = 0; i < numThreads; i++) {        executor.execute(new Runnable() {            @Override            public void run() {                try {                    startLatch.countDown();                    startLatch.await();                    out.addAll(takeEvents(channel, 10));                } catch (Throwable t) {                    error.set(true);                    LOGGER.error("Error in take thread", t);                } finally {                    stopLatch.countDown();                }            }        });    }    stopLatch.await();    Assert.assertFalse(error.get());    compareInputAndOut(in, out);}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    try {        startLatch.countDown();        startLatch.await();        out.addAll(takeEvents(channel, 10));    } catch (Throwable t) {        error.set(true);        LOGGER.error("Error in take thread", t);    } finally {        stopLatch.countDown();    }}
41da033717df54ce5953631d8d94f23376794918d7091d09d97df6040fe67162
testThreadedProduce
public void testThreadedProduce() throws Exception
{    int numThreads = 20;    Map<String, String> overrides = getOverridesForEncryption();    overrides.put(FileChannelConfiguration.CAPACITY, String.valueOf(10000));    overrides.put(FileChannelConfiguration.TRANSACTION_CAPACITY, String.valueOf(100));    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Executor executor = Executors.newFixedThreadPool(numThreads);    final AtomicBoolean error = new AtomicBoolean(false);    final CountDownLatch startLatch = new CountDownLatch(numThreads);    final CountDownLatch stopLatch = new CountDownLatch(numThreads);    final Set<String> in = Collections.synchronizedSet(new HashSet<String>());    for (int i = 0; i < numThreads; i++) {        executor.execute(new Runnable() {            @Override            public void run() {                try {                    startLatch.countDown();                    startLatch.await();                    in.addAll(putEvents(channel, "thread-produce", 10, 10000, true));                } catch (Throwable t) {                    error.set(true);                    LOGGER.error("Error in put thread", t);                } finally {                    stopLatch.countDown();                }            }        });    }    stopLatch.await();    Set<String> out = consumeChannel(channel);    Assert.assertFalse(error.get());    compareInputAndOut(in, out);}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    try {        startLatch.countDown();        startLatch.await();        in.addAll(putEvents(channel, "thread-produce", 10, 10000, true));    } catch (Throwable t) {        error.set(true);        LOGGER.error("Error in put thread", t);    } finally {        stopLatch.countDown();    }}
7f481deaa5ecccbe1f620a0e7a52ef4d2e45612c66a4952928898db6558a72e1
testConfiguration
public void testConfiguration() throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put("encryption.activeKey", "key-1");    overrides.put("encryption.cipherProvider", "AESCTRNOPADDING");    overrides.put("encryption.keyProvider", "JCEKSFILE");    overrides.put("encryption.keyProvider.keyStoreFile", keyStoreFile.getAbsolutePath());    overrides.put("encryption.keyProvider.keyStorePasswordFile", keyStorePasswordFile.getAbsolutePath());    overrides.put("encryption.keyProvider.keys", "key-0 key-1");    overrides.put("encryption.keyProvider.keys.key-0.passwordFile", keyAliasPassword.get("key-0").getAbsolutePath());    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> in = fillChannel(channel, "restart");    channel.stop();    channel = TestUtils.createFileChannel(checkpointDir.getAbsolutePath(), dataDir, overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> out = consumeChannel(channel);    compareInputAndOut(in, out);}
078acc2fbfb3ddd267257d2c0155de10e5e494d1d6a88e159b234df2cf0865f7
testBasicEncyrptionDecryption
public void testBasicEncyrptionDecryption() throws Exception
{    Map<String, String> overrides = getOverridesForEncryption();    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> in = fillChannel(channel, "restart");    channel.stop();    channel = TestUtils.createFileChannel(checkpointDir.getAbsolutePath(), dataDir, overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> out = consumeChannel(channel);    compareInputAndOut(in, out);}
725b4d5b3a9f0389f74d1795da68e5eca900a356ca2bdef729adf21534bdeac2
testEncryptedChannelWithoutEncryptionConfigFails
public void testEncryptedChannelWithoutEncryptionConfigFails() throws Exception
{    Map<String, String> overrides = getOverridesForEncryption();    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    fillChannel(channel, "will-not-restart");    channel.stop();    Map<String, String> noEncryptionOverrides = getOverrides();    channel = createFileChannel(noEncryptionOverrides);    channel.start();    if (channel.isOpen()) {        try {            takeEvents(channel, 1, 1);            Assert.fail("Channel was opened and take did not throw exception");        } catch (ChannelException ex) {                }    }}
fd9d1d8f484b22230e61ea6c1a4aee2fcc2b38de83ee2bba4462debdbc1a4a4d
testUnencyrptedAndEncryptedLogs
public void testUnencyrptedAndEncryptedLogs() throws Exception
{    Map<String, String> noEncryptionOverrides = getOverrides();    channel = createFileChannel(noEncryptionOverrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> in = fillChannel(channel, "unencrypted-and-encrypted");    int numEventsToRemove = in.size() / 2;    for (int i = 0; i < numEventsToRemove; i++) {        Assert.assertTrue(in.removeAll(takeEvents(channel, 1, 1)));    }        channel.stop();    Map<String, String> overrides = getOverridesForEncryption();    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    in.addAll(fillChannel(channel, "unencrypted-and-encrypted"));    Set<String> out = consumeChannel(channel);    compareInputAndOut(in, out);}
b731af3cb7788f1994a1a1c290fb02a9275b5dafd78ff0f17fc77dad3c568f22
testBadKeyProviderInvalidValue
public void testBadKeyProviderInvalidValue() throws Exception
{    Map<String, String> overrides = getOverridesForEncryption();    overrides.put(Joiner.on(".").join(EncryptionConfiguration.ENCRYPTION_PREFIX, EncryptionConfiguration.KEY_PROVIDER), "invalid");    try {        channel = createFileChannel(overrides);        Assert.fail();    } catch (FlumeException ex) {        Assert.assertEquals("java.lang.ClassNotFoundException: invalid", ex.getMessage());    }}
217816c17d623c406588fe64607415465200b226c70245bc6481cfd4d17ad254
testBadKeyProviderInvalidClass
public void testBadKeyProviderInvalidClass() throws Exception
{    Map<String, String> overrides = getOverridesForEncryption();    overrides.put(Joiner.on(".").join(EncryptionConfiguration.ENCRYPTION_PREFIX, EncryptionConfiguration.KEY_PROVIDER), String.class.getName());    try {        channel = createFileChannel(overrides);        Assert.fail();    } catch (FlumeException ex) {        Assert.assertEquals("Unable to instantiate Builder from java.lang.String", ex.getMessage());    }}
6d12642c94352a53ae52022c4e653d529ae3e530844ce01037027c7ff32a5c73
testBadCipherProviderInvalidValue
public void testBadCipherProviderInvalidValue() throws Exception
{    Map<String, String> overrides = getOverridesForEncryption();    overrides.put(Joiner.on(".").join(EncryptionConfiguration.ENCRYPTION_PREFIX, EncryptionConfiguration.CIPHER_PROVIDER), "invalid");    channel = createFileChannel(overrides);    channel.start();    Assert.assertFalse(channel.isOpen());}
dbc6577a1905259c65f45d1fa01ed022c5662dda65041ef138a318df8abe377e
testBadCipherProviderInvalidClass
public void testBadCipherProviderInvalidClass() throws Exception
{    Map<String, String> overrides = getOverridesForEncryption();    overrides.put(Joiner.on(".").join(EncryptionConfiguration.ENCRYPTION_PREFIX, EncryptionConfiguration.CIPHER_PROVIDER), String.class.getName());    channel = createFileChannel(overrides);    channel.start();    Assert.assertFalse(channel.isOpen());}
b2699cd2bdd3845914f5ae8252d965131615d90b8ab408c39fd5975af2d67a3d
testMissingKeyStoreFile
public void testMissingKeyStoreFile() throws Exception
{    Map<String, String> overrides = getOverridesForEncryption();    overrides.put(Joiner.on(".").join(EncryptionConfiguration.ENCRYPTION_PREFIX, EncryptionConfiguration.KEY_PROVIDER, EncryptionConfiguration.JCE_FILE_KEY_STORE_FILE), "/path/does/not/exist");    try {        channel = createFileChannel(overrides);        Assert.fail();    } catch (RuntimeException ex) {        Assert.assertTrue("Exception message is incorrect: " + ex.getMessage(), ex.getMessage().startsWith("java.io.FileNotFoundException: /path/does/not/exist "));    }}
73a497f196c26a75daf9c1ec9033b0a9436dc101d2e8acb1a890a8cc6958dbec
testMissingKeyStorePasswordFile
public void testMissingKeyStorePasswordFile() throws Exception
{    Map<String, String> overrides = getOverridesForEncryption();    overrides.put(Joiner.on(".").join(EncryptionConfiguration.ENCRYPTION_PREFIX, EncryptionConfiguration.KEY_PROVIDER, EncryptionConfiguration.JCE_FILE_KEY_STORE_PASSWORD_FILE), "/path/does/not/exist");    try {        channel = createFileChannel(overrides);        Assert.fail();    } catch (RuntimeException ex) {        Assert.assertTrue("Exception message is incorrect: " + ex.getMessage(), ex.getMessage().startsWith("java.io.FileNotFoundException: /path/does/not/exist "));    }}
a15997457bc59c2a35a8209216d9122001c31a595183ce1f77915c549b0e724e
testBadKeyStorePassword
public void testBadKeyStorePassword() throws Exception
{    Files.write("invalid", keyStorePasswordFile, Charsets.UTF_8);    Map<String, String> overrides = getOverridesForEncryption();    try {        channel = TestUtils.createFileChannel(checkpointDir.getAbsolutePath(), dataDir, overrides);        Assert.fail();    } catch (RuntimeException ex) {        Assert.assertEquals("java.io.IOException: Keystore was tampered with, or " + "password was incorrect", ex.getMessage());    }}
100a9637d7850131e21f46df0fe10fb48a6ae8ed6f1428c3f3546a68f323a10c
testBadKeyAlias
public void testBadKeyAlias() throws Exception
{    Map<String, String> overrides = getOverridesForEncryption();    overrides.put(EncryptionConfiguration.ENCRYPTION_PREFIX + "." + EncryptionConfiguration.ACTIVE_KEY, "invalid");    channel = TestUtils.createFileChannel(checkpointDir.getAbsolutePath(), dataDir, overrides);    channel.start();    Assert.assertFalse(channel.isOpen());}
27681e68ec2a1eb903f955680ebe003ceb3707295c8aad884b692d378c6e37cf
setup
public void setup() throws Exception
{    baseDir = Files.createTempDir();    keyStorePasswordFile = new File(baseDir, "keyStorePasswordFile");    Files.write("keyStorePassword", keyStorePasswordFile, Charsets.UTF_8);    keyAliasPassword = Maps.newHashMap();    keyStoreFile = new File(baseDir, "keyStoreFile");    Assert.assertTrue(keyStoreFile.createNewFile());}
a317f472727975f13a20ef21472e1d5e0a0fd93702ee696b9c962178a725931f
cleanup
public void cleanup()
{    FileUtils.deleteQuietly(baseDir);}
c097dbfc1352d0421177914656cddcf188a755fee63ae7ee51b6ff557c603ad2
initializeForKey
private void initializeForKey(Key key)
{    encryptor = new AESCTRNoPaddingProvider.EncryptorBuilder().setKey(key).build();    decryptor = new AESCTRNoPaddingProvider.DecryptorBuilder().setKey(key).setParameters(encryptor.getParameters()).build();}
d74a841d67dd43b6704e272c7ab6790b75f36026df196b97492d8a729fe9d1c8
testWithNewKeyStore
public void testWithNewKeyStore() throws Exception
{    createNewKeyStore();    EncryptionTestUtils.createKeyStore(keyStoreFile, keyStorePasswordFile, keyAliasPassword);    Context context = new Context(EncryptionTestUtils.configureForKeyStore(keyStoreFile, keyStorePasswordFile, keyAliasPassword));    Context keyProviderContext = new Context(context.getSubProperties(EncryptionConfiguration.KEY_PROVIDER + "."));    KeyProvider keyProvider = KeyProviderFactory.getInstance(KeyProviderType.JCEKSFILE.name(), keyProviderContext);    testKeyProvider(keyProvider);}
8803c3e59c1157de8296c9ed17381d6be0c640093a4d608fec792f81d55fdd6c
testWithExistingKeyStore
public void testWithExistingKeyStore() throws Exception
{    keyAliasPassword.putAll(EncryptionTestUtils.configureTestKeyStore(baseDir, keyStoreFile));    Context context = new Context(EncryptionTestUtils.configureForKeyStore(keyStoreFile, keyStorePasswordFile, keyAliasPassword));    Context keyProviderContext = new Context(context.getSubProperties(EncryptionConfiguration.KEY_PROVIDER + "."));    KeyProvider keyProvider = KeyProviderFactory.getInstance(KeyProviderType.JCEKSFILE.name(), keyProviderContext);    testKeyProvider(keyProvider);}
7ae77e3ea80f74069a8132efe8c4d786e04104c34072d08375ecf7771e14d187
createNewKeyStore
private void createNewKeyStore() throws Exception
{    for (int i = 0; i < 10; i++) {                if (i % 2 == 0) {            String alias = "test-" + i;            String password = String.valueOf(i);            keyAliasPassword.put(alias, TestUtils.writeStringToFile(baseDir, alias, password));        }    }}
7af470928afa12bcc9257c1eba58a2cadc020b186f71bf01492642d2644ffd29
testKeyProvider
private void testKeyProvider(KeyProvider keyProvider)
{    for (String alias : keyAliasPassword.keySet()) {        Key key = keyProvider.getKey(alias);        initializeForKey(key);        String expected = "some text here " + alias;        byte[] cipherText = encryptor.encrypt(expected.getBytes(Charsets.UTF_8));        byte[] clearText = decryptor.decrypt(cipherText);        Assert.assertEquals(expected, new String(clearText, Charsets.UTF_8));    }}
935d9dc08fe11323dcaaf5c6f96db76bb87fd0fc4b9fcc33e9eca9f620f5620c
setup
public void setup() throws IOException
{    file = File.createTempFile("Checkpoint", "");    inflightPuts = File.createTempFile("inflightPuts", "");    inflightTakes = File.createTempFile("inflightTakes", "");    queueSet = File.createTempFile("queueset", "");    Assert.assertTrue(file.isFile());    Assert.assertTrue(file.canWrite());}
a317f472727975f13a20ef21472e1d5e0a0fd93702ee696b9c962178a725931f
cleanup
public void cleanup()
{    file.delete();}
201ceaeec1d6c505857a11e3f4b3b5be8dba93fda85e1105434de73759a3825a
testSerialization
public void testSerialization() throws Exception
{    EventQueueBackingStore backingStore = new EventQueueBackingStoreFileV2(file, 1, "test", new FileChannelCounter("test"));    FlumeEventPointer ptrIn = new FlumeEventPointer(10, 20);    FlumeEventQueue queueIn = new FlumeEventQueue(backingStore, inflightTakes, inflightPuts, queueSet);    queueIn.addHead(ptrIn);    FlumeEventQueue queueOut = new FlumeEventQueue(backingStore, inflightTakes, inflightPuts, queueSet);    Assert.assertEquals(0, queueOut.getLogWriteOrderID());    queueIn.checkpoint(false);    FlumeEventQueue queueOut2 = new FlumeEventQueue(backingStore, inflightTakes, inflightPuts, queueSet);    FlumeEventPointer ptrOut = queueOut2.removeHead(0L);    Assert.assertEquals(ptrIn, ptrOut);    Assert.assertTrue(queueOut2.getLogWriteOrderID() > 0);}
27681e68ec2a1eb903f955680ebe003ceb3707295c8aad884b692d378c6e37cf
setup
public void setup() throws Exception
{    super.setup();}
ec8b6259c87a96a7e78ab8ec13a826f2caf0d2a1c593d4aec011e181f3e17bbf
teardown
public void teardown()
{    super.teardown();}
9762d7c20e218a67b14b23ec3fde5b1f46e4735d70c4df3f6bd471a975f1727b
testFastReplay
public void testFastReplay() throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.CAPACITY, String.valueOf(50));    overrides.put(FileChannelConfiguration.TRANSACTION_CAPACITY, String.valueOf(50));    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> in = fillChannel(channel, "checkpointBulder");    channel.stop();    File checkpointFile = new File(checkpointDir, "checkpoint");    File metaDataFile = Serialization.getMetaDataFile(checkpointFile);    File inflightTakesFile = new File(checkpointDir, "inflighttakes");    File inflightPutsFile = new File(checkpointDir, "inflightputs");    File queueSetDir = new File(checkpointDir, "queueset");    Assert.assertTrue(checkpointFile.delete());    Assert.assertTrue(metaDataFile.delete());    Assert.assertTrue(inflightTakesFile.delete());    Assert.assertTrue(inflightPutsFile.delete());    EventQueueBackingStore backingStore = EventQueueBackingStoreFactory.get(checkpointFile, 50, "test", new FileChannelCounter("test"));    FlumeEventQueue queue = new FlumeEventQueue(backingStore, inflightTakesFile, inflightPutsFile, queueSetDir);    CheckpointRebuilder checkpointRebuilder = new CheckpointRebuilder(getAllLogs(dataDirs), queue, true);    Assert.assertTrue(checkpointRebuilder.rebuild());    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> out = consumeChannel(channel);    compareInputAndOut(in, out);}
935d9dc08fe11323dcaaf5c6f96db76bb87fd0fc4b9fcc33e9eca9f620f5620c
setup
public void setup() throws IOException
{    baseDir = Files.createTempDir();    checkpoint = new File(baseDir, "checkpoint");    inflightTakes = new File(baseDir, "takes");    inflightPuts = new File(baseDir, "puts");    queueSetDir = new File(baseDir, "queueset");    TestUtils.copyDecompressed("fileformat-v2-checkpoint.gz", checkpoint);}
ec8b6259c87a96a7e78ab8ec13a826f2caf0d2a1c593d4aec011e181f3e17bbf
teardown
public void teardown()
{    FileUtils.deleteQuietly(baseDir);}
f97656f966b0f8b623bb78e641600fb88df6a2abaf8945c52ea981b94b30c7af
testWithNoFlag
public void testWithNoFlag() throws Exception
{    verify(EventQueueBackingStoreFactory.get(checkpoint, 10, "test", new FileChannelCounter("test")), Serialization.VERSION_3, pointersInTestCheckpoint);}
096c77a50364ae35fec869c3dcd7b74180703d0953599e85b62278b3216d6d2b
testWithFlag
public void testWithFlag() throws Exception
{    verify(EventQueueBackingStoreFactory.get(checkpoint, 10, "test", new FileChannelCounter("test"), true), Serialization.VERSION_3, pointersInTestCheckpoint);}
9512d37ce3241218874b5ec7e73c5249afc9050227266653b57d87252c879d51
testNoUprade
public void testNoUprade() throws Exception
{    verify(EventQueueBackingStoreFactory.get(checkpoint, 10, "test", new FileChannelCounter("test"), false), Serialization.VERSION_2, pointersInTestCheckpoint);}
f7b0519a69ea1c99d0ed1233f901e4df85edd8d2159b12a19ff0db98e1c92824
testDecreaseCapacity
public void testDecreaseCapacity() throws Exception
{    Assert.assertTrue(checkpoint.delete());    EventQueueBackingStore backingStore = EventQueueBackingStoreFactory.get(checkpoint, 10, "test", new FileChannelCounter("test"));    backingStore.close();    EventQueueBackingStoreFactory.get(checkpoint, 9, "test", new FileChannelCounter("test"));    Assert.fail();}
7962b1472014e80d302d5026ed62edad2ee2f8819524d54ae95d99c4a6ff0503
testIncreaseCapacity
public void testIncreaseCapacity() throws Exception
{    Assert.assertTrue(checkpoint.delete());    EventQueueBackingStore backingStore = EventQueueBackingStoreFactory.get(checkpoint, 10, "test", new FileChannelCounter("test"));    backingStore.close();    EventQueueBackingStoreFactory.get(checkpoint, 11, "test", new FileChannelCounter("test"));    Assert.fail();}
1d6b25be6049697840ab05f5ee506f12f19a54fbd10c836baf9583b24a4e82c0
testNewCheckpoint
public void testNewCheckpoint() throws Exception
{    Assert.assertTrue(checkpoint.delete());    verify(EventQueueBackingStoreFactory.get(checkpoint, 10, "test", new FileChannelCounter("test"), false), Serialization.VERSION_3, Collections.<Long>emptyList());}
717785448ce1b090874e850c719223a96f7dc362d5919f6105617c175aacf4ec
testCheckpointBadVersion
public void testCheckpointBadVersion() throws Exception
{    RandomAccessFile writer = new RandomAccessFile(checkpoint, "rw");    try {        EventQueueBackingStore backingStore = EventQueueBackingStoreFactory.get(checkpoint, 10, "test", new FileChannelCounter("test"));        backingStore.close();        writer.seek(EventQueueBackingStoreFile.INDEX_VERSION * Serialization.SIZE_OF_LONG);        writer.writeLong(94L);        writer.getFD().sync();        backingStore = EventQueueBackingStoreFactory.get(checkpoint, 10, "test", new FileChannelCounter("test"));    } finally {        writer.close();    }}
280a367b799ea42c57804b5422128c588d633d42b13f62f607588eafd28aa8d6
testIncompleteCheckpoint
public void testIncompleteCheckpoint() throws Exception
{    RandomAccessFile writer = new RandomAccessFile(checkpoint, "rw");    try {        EventQueueBackingStore backingStore = EventQueueBackingStoreFactory.get(checkpoint, 10, "test", new FileChannelCounter("test"));        backingStore.close();        writer.seek(EventQueueBackingStoreFile.INDEX_CHECKPOINT_MARKER * Serialization.SIZE_OF_LONG);        writer.writeLong(EventQueueBackingStoreFile.CHECKPOINT_INCOMPLETE);        writer.getFD().sync();        backingStore = EventQueueBackingStoreFactory.get(checkpoint, 10, "test", new FileChannelCounter("test"));    } finally {        writer.close();    }}
4e70d11fa5a3eb28dafde48806c2c3704f8cb2bc885da70672678c744b360a5d
testCheckpointVersionNotEqualToMeta
public void testCheckpointVersionNotEqualToMeta() throws Exception
{    RandomAccessFile writer = new RandomAccessFile(checkpoint, "rw");    try {        EventQueueBackingStore backingStore = EventQueueBackingStoreFactory.get(checkpoint, 10, "test", new FileChannelCounter("test"));        backingStore.close();        writer.seek(EventQueueBackingStoreFile.INDEX_VERSION * Serialization.SIZE_OF_LONG);        writer.writeLong(2L);        writer.getFD().sync();        backingStore = EventQueueBackingStoreFactory.get(checkpoint, 10, "test", new FileChannelCounter("test"));    } finally {        writer.close();    }}
5e3626efde22e9d9becebdc5ab1c553a9356cc8f0f98fcecbf0650dcacc462dc
testCheckpointVersionNotEqualToMeta2
public void testCheckpointVersionNotEqualToMeta2() throws Exception
{    FileOutputStream os = null;    try {        EventQueueBackingStore backingStore = EventQueueBackingStoreFactory.get(checkpoint, 10, "test", new FileChannelCounter("test"));        backingStore.close();        Assert.assertTrue(checkpoint.exists());        Assert.assertTrue(Serialization.getMetaDataFile(checkpoint).length() != 0);        FileInputStream is = new FileInputStream(Serialization.getMetaDataFile(checkpoint));        ProtosFactory.Checkpoint meta = ProtosFactory.Checkpoint.parseDelimitedFrom(is);        Assert.assertNotNull(meta);        is.close();        os = new FileOutputStream(Serialization.getMetaDataFile(checkpoint));        meta.toBuilder().setVersion(2).build().writeDelimitedTo(os);        os.flush();        backingStore = EventQueueBackingStoreFactory.get(checkpoint, 10, "test", new FileChannelCounter("test"));    } finally {        os.close();    }}
0137985013ded0d91fefbb5afc12b4924cfedcbb94c6a1327c1192b638201927
testCheckpointOrderIdNotEqualToMeta
public void testCheckpointOrderIdNotEqualToMeta() throws Exception
{    RandomAccessFile writer = new RandomAccessFile(checkpoint, "rw");    try {        EventQueueBackingStore backingStore = EventQueueBackingStoreFactory.get(checkpoint, 10, "test", new FileChannelCounter("test"));        backingStore.close();        writer.seek(EventQueueBackingStoreFile.INDEX_WRITE_ORDER_ID * Serialization.SIZE_OF_LONG);        writer.writeLong(2L);        writer.getFD().sync();        backingStore = EventQueueBackingStoreFactory.get(checkpoint, 10, "test", new FileChannelCounter("test"));    } finally {        writer.close();    }}
48e91f1c0b3d9cd9348167fd9026c51411968ed089ce860695b1e431b4ea44d8
testCheckpointOrderIdNotEqualToMeta2
public void testCheckpointOrderIdNotEqualToMeta2() throws Exception
{    FileOutputStream os = null;    try {        EventQueueBackingStore backingStore = EventQueueBackingStoreFactory.get(checkpoint, 10, "test", new FileChannelCounter("test"));        backingStore.close();        Assert.assertTrue(checkpoint.exists());        Assert.assertTrue(Serialization.getMetaDataFile(checkpoint).length() != 0);        FileInputStream is = new FileInputStream(Serialization.getMetaDataFile(checkpoint));        ProtosFactory.Checkpoint meta = ProtosFactory.Checkpoint.parseDelimitedFrom(is);        Assert.assertNotNull(meta);        is.close();        os = new FileOutputStream(Serialization.getMetaDataFile(checkpoint));        meta.toBuilder().setWriteOrderID(1).build().writeDelimitedTo(os);        os.flush();        backingStore = EventQueueBackingStoreFactory.get(checkpoint, 10, "test", new FileChannelCounter("test"));    } finally {        os.close();    }}
d440a55bcebe74418c50e84ab3d3e8a4e2830c8863e217527774441e640380b2
testTruncateMeta
public void testTruncateMeta() throws Exception
{    EventQueueBackingStore backingStore = EventQueueBackingStoreFactory.get(checkpoint, 10, "test", new FileChannelCounter("test"));    backingStore.close();    Assert.assertTrue(checkpoint.exists());    File metaFile = Serialization.getMetaDataFile(checkpoint);    Assert.assertTrue(metaFile.length() != 0);    RandomAccessFile writer = new RandomAccessFile(metaFile, "rw");    writer.setLength(0);    writer.getFD().sync();    writer.close();    backingStore = EventQueueBackingStoreFactory.get(checkpoint, 10, "test", new FileChannelCounter("test"));}
7d6dab7564b3fb82da77507155dd091e7f3bb22fc0c1a5d78d3f2eda60d872fc
testCorruptMeta
public void testCorruptMeta() throws Throwable
{    EventQueueBackingStore backingStore = EventQueueBackingStoreFactory.get(checkpoint, 10, "test", new FileChannelCounter("test"));    backingStore.close();    Assert.assertTrue(checkpoint.exists());    File metaFile = Serialization.getMetaDataFile(checkpoint);    Assert.assertTrue(metaFile.length() != 0);    RandomAccessFile writer = new RandomAccessFile(metaFile, "rw");    writer.seek(10);    writer.writeLong(new Random().nextLong());    writer.getFD().sync();    writer.close();    try {        backingStore = EventQueueBackingStoreFactory.get(checkpoint, 10, "test", new FileChannelCounter("test"));    } catch (BadCheckpointException ex) {        throw ex.getCause();    }}
5a8c8b70a6696a746a9dec8ed030e50639a3daee9cc367167bc60a45ba9bed56
verify
private void verify(EventQueueBackingStore backingStore, long expectedVersion, List<Long> expectedPointers) throws Exception
{    FlumeEventQueue queue = new FlumeEventQueue(backingStore, inflightTakes, inflightPuts, queueSetDir);    List<Long> actualPointers = Lists.newArrayList();    FlumeEventPointer ptr;    while ((ptr = queue.removeHead(0L)) != null) {        actualPointers.add(ptr.toLong());    }    Assert.assertEquals(expectedPointers, actualPointers);    Assert.assertEquals(10, backingStore.getCapacity());    DataInputStream in = new DataInputStream(new FileInputStream(checkpoint));    long actualVersion = in.readLong();    Assert.assertEquals(expectedVersion, actualVersion);    in.close();}
38a59d061b21d9987e0eae1217d107ddd7b086928af86233add7bcf0850a4b44
testPutEvent
public void testPutEvent()
{    FlumeEvent event = new FlumeEvent(null, new byte[5]);    Put put = new Put(1L, 1L, event);    Event returnEvent = EventUtils.getEventFromTransactionEvent(put);    Assert.assertNotNull(returnEvent);    Assert.assertEquals(5, returnEvent.getBody().length);}
b92d809b95c649ad1f97a76f3b76cdb24ce646f2a3dbc9f41b9a20b93d9a8841
testInvalidEvent
public void testInvalidEvent()
{    Take take = new Take(1L, 1L);    Event returnEvent = EventUtils.getEventFromTransactionEvent(take);    Assert.assertNull(returnEvent);}
27681e68ec2a1eb903f955680ebe003ceb3707295c8aad884b692d378c6e37cf
setup
public void setup() throws Exception
{    super.setup();}
ec8b6259c87a96a7e78ab8ec13a826f2caf0d2a1c593d4aec011e181f3e17bbf
teardown
public void teardown()
{    super.teardown();}
a230bbeaf3ff1106ba2f22e014e75369ee8b73941345217e8437fed823d5463d
testNegativeCapacities
public void testNegativeCapacities()
{    Map<String, String> parms = Maps.newHashMap();    parms.put(FileChannelConfiguration.CAPACITY, "-3");    parms.put(FileChannelConfiguration.TRANSACTION_CAPACITY, "-1");    parms.put(FileChannelConfiguration.CHECKPOINT_INTERVAL, "-2");    FileChannel channel = createFileChannel(parms);    Assert.assertTrue(field("capacity").ofType(Integer.class).in(channel).get() > 0);    Assert.assertTrue(field("transactionCapacity").ofType(Integer.class).in(channel).get() > 0);    Assert.assertTrue(field("checkpointInterval").ofType(Long.class).in(channel).get() > 0);}
377490e15631407baf2a68d364518bf17bfe9f4defde52b3e4ba2688eabc9fc2
testFailAfterTakeBeforeCommit
public void testFailAfterTakeBeforeCommit() throws Throwable
{    final FileChannel channel = createFileChannel();    channel.start();    final Set<String> eventSet = putEvents(channel, "testTakeFailBeforeCommit", 5, 5);    Transaction tx = channel.getTransaction();    takeWithoutCommit(channel, tx, 2);            Executors.newSingleThreadExecutor().submit(new Runnable() {        @Override        public void run() {            Transaction tx = channel.getTransaction();            takeWithoutCommit(channel, tx, 3);        }    }).get();    forceCheckpoint(channel);    channel.stop();        try {        Executors.newSingleThreadExecutor().submit(new Runnable() {            @Override            public void run() {                FileChannel channel = createFileChannel();                channel.start();                Set<String> output = null;                try {                    output = takeEvents(channel, 5);                } catch (Exception e) {                    Throwables.propagate(e);                }                compareInputAndOut(eventSet, output);                channel.stop();            }        }).get();    } catch (ExecutionException e) {        throw e.getCause();    }}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    Transaction tx = channel.getTransaction();    takeWithoutCommit(channel, tx, 3);}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    FileChannel channel = createFileChannel();    channel.start();    Set<String> output = null;    try {        output = takeEvents(channel, 5);    } catch (Exception e) {        Throwables.propagate(e);    }    compareInputAndOut(eventSet, output);    channel.stop();}
3a9a8ebc14d28119e8ce8e8062be59833b53578b4a3f50081a6573fe723fd310
testFailAfterPutCheckpointCommit
public void testFailAfterPutCheckpointCommit() throws Throwable
{    final Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.CHECKPOINT_INTERVAL, "10000");    final FileChannel channel = createFileChannel(overrides);    channel.start();    Transaction tx = channel.getTransaction();    final Set<String> input = putWithoutCommit(channel, tx, "failAfterPut", 3);            final CountDownLatch latch = new CountDownLatch(1);    Executors.newSingleThreadExecutor().submit(new Runnable() {        @Override        public void run() {            Transaction tx = channel.getTransaction();            input.addAll(putWithoutCommit(channel, tx, "failAfterPut", 3));            try {                latch.await();                tx.commit();            } catch (InterruptedException e) {                tx.rollback();                Throwables.propagate(e);            } finally {                tx.close();            }        }    });    forceCheckpoint(channel);    tx.commit();    tx.close();    latch.countDown();    Thread.sleep(2000);    channel.stop();    final Set<String> out = Sets.newHashSet();        try {        Executors.newSingleThreadExecutor().submit(new Runnable() {            @Override            public void run() {                try {                    FileChannel channel = createFileChannel();                    channel.start();                    out.addAll(takeEvents(channel, 6));                    channel.stop();                } catch (Exception ex) {                    Throwables.propagate(ex);                }            }        }).get();    } catch (ExecutionException e) {        throw e.getCause();    }}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    Transaction tx = channel.getTransaction();    input.addAll(putWithoutCommit(channel, tx, "failAfterPut", 3));    try {        latch.await();        tx.commit();    } catch (InterruptedException e) {        tx.rollback();        Throwables.propagate(e);    } finally {        tx.close();    }}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    try {        FileChannel channel = createFileChannel();        channel.start();        out.addAll(takeEvents(channel, 6));        channel.stop();    } catch (Exception ex) {        Throwables.propagate(ex);    }}
39d8ffe88a8de403c18fca7a8afd73e3dbaf9935d25ea355700570988e72cbdf
testReconfigure
public void testReconfigure() throws Exception
{    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> in = Sets.newHashSet();    try {        while (true) {            in.addAll(putEvents(channel, "reconfig", 1, 1));        }    } catch (ChannelException e) {        Assert.assertEquals("The channel has reached it's capacity. " + "This might be the result of a sink on the channel having too " + "low of batch size, a downstream system running slower than " + "normal, or that the channel capacity is just too low. [channel=" + channel.getName() + "]", e.getMessage());    }    Configurables.configure(channel, createContext());    Set<String> out = takeEvents(channel, 1, Integer.MAX_VALUE);    compareInputAndOut(in, out);}
c75354e1d2e0d02b03907d071638189e6542ce58f45d2d051fa2b3b6c2f9f294
testPut
public void testPut() throws Exception
{    channel.start();    Assert.assertTrue(channel.isOpen());        int found = takeEvents(channel, 1, 5).size();    Assert.assertEquals(0, found);    Set<String> expected = Sets.newHashSet();    expected.addAll(putEvents(channel, "unbatched", 1, 5));    expected.addAll(putEvents(channel, "batched", 5, 5));    Set<String> actual = takeEvents(channel, 1);    compareInputAndOut(expected, actual);}
eceefd4abf267324aa568030a4aa86d248862520a25e7f5ae0a53201870b3f1a
testPutConvertsNullValueToEmptyStrInHeader
public void testPutConvertsNullValueToEmptyStrInHeader() throws Exception
{    channel.start();    Event event = EventBuilder.withBody("test body".getBytes(Charsets.UTF_8), Collections.<String, String>singletonMap(TEST_KEY, null));    Transaction txPut = channel.getTransaction();    txPut.begin();    channel.put(event);    txPut.commit();    txPut.close();    Transaction txTake = channel.getTransaction();    txTake.begin();    Event eventTaken = channel.take();    Assert.assertArrayEquals(event.getBody(), eventTaken.getBody());    Assert.assertEquals("", eventTaken.getHeaders().get(TEST_KEY));    txTake.commit();    txTake.close();}
0ad2bd48d6b337c6a9cc3dcf0bab26daf3c044d6b3959585b10dd97cb5959acc
testCommitAfterNoPutTake
public void testCommitAfterNoPutTake() throws Exception
{    channel.start();    Assert.assertTrue(channel.isOpen());    Transaction transaction;    transaction = channel.getTransaction();    transaction.begin();    transaction.commit();    transaction.close();        channel.stop();    channel = createFileChannel();    channel.start();    Assert.assertTrue(channel.isOpen());    transaction = channel.getTransaction();    transaction.begin();    Assert.assertNull(channel.take());    transaction.commit();    transaction.close();}
de7031ae9f15d2c1d1febcf2fbb9ce3082d4a40395c68e3b2f5b055c1b136d37
testCapacity
public void testCapacity() throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.CAPACITY, String.valueOf(5));    overrides.put(FileChannelConfiguration.TRANSACTION_CAPACITY, String.valueOf(5));    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    fillChannel(channel, "fillup");            Transaction transaction;    transaction = channel.getTransaction();    transaction.begin();    Event event = channel.take();    Assert.assertNotNull(event);    transaction.rollback();    transaction.close();        Assert.assertEquals(0, fillChannel(channel, "capacity").size());        Assert.assertEquals(5, takeEvents(channel, 1, 5).size());}
2ebb80a86c3b2ea57ecba539bdcafdcf81f54001fb0b82cf334e66c42e559d00
testRaceFoundInFLUME1432
public void testRaceFoundInFLUME1432() throws Exception
{        Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.KEEP_ALIVE, String.valueOf(10L));    overrides.put(FileChannelConfiguration.CAPACITY, String.valueOf(10L));    overrides.put(FileChannelConfiguration.TRANSACTION_CAPACITY, String.valueOf(10L));    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    fillChannel(channel, "fillup");        Future<String> put = Executors.newSingleThreadExecutor().submit(new Callable<String>() {        @Override        public String call() throws Exception {            Set<String> result = putEvents(channel, "blocked-put", 1, 1);            Assert.assertTrue(result.toString(), result.size() == 1);            Iterator<String> iter = result.iterator();            return iter.next();        }    });        Thread.sleep(1000L);        Set<String> result = takeEvents(channel, 1, 1);    Assert.assertTrue(result.toString(), result.size() == 1);    String putmsg = put.get();    Assert.assertNotNull(putmsg);    String takemsg = result.iterator().next();    Assert.assertNotNull(takemsg);    LOG.info("Got: put " + putmsg + ", take " + takemsg);    channel.stop();    channel = createFileChannel(overrides);            channel.start();    Assert.assertTrue(channel.isOpen());}
0de366753fb2c2ae2fa0e376bb10ccfbbff19256a8a508826be7c2384f30ac4b
call
public String call() throws Exception
{    Set<String> result = putEvents(channel, "blocked-put", 1, 1);    Assert.assertTrue(result.toString(), result.size() == 1);    Iterator<String> iter = result.iterator();    return iter.next();}
80fcda5cf3f798b60b61e899d4de74294786e3ab0f4f7eaf07da58a4a39dcb90
testThreaded
public void testThreaded() throws IOException, InterruptedException
{    channel.start();    Assert.assertTrue(channel.isOpen());    int numThreads = 10;    final CountDownLatch producerStopLatch = new CountDownLatch(numThreads);    final CountDownLatch consumerStopLatch = new CountDownLatch(numThreads);    final List<Exception> errors = Collections.synchronizedList(new ArrayList<Exception>());    final Set<String> expected = Collections.synchronizedSet(new HashSet<String>());    final Set<String> actual = Collections.synchronizedSet(new HashSet<String>());    for (int i = 0; i < numThreads; i++) {        final int id = i;        Thread t = new Thread() {            @Override            public void run() {                try {                    if (id % 2 == 0) {                        expected.addAll(putEvents(channel, Integer.toString(id), 1, 5));                    } else {                        expected.addAll(putEvents(channel, Integer.toString(id), 5, 5));                    }                    LOG.info("Completed some puts " + expected.size());                } catch (Exception e) {                    LOG.error("Error doing puts", e);                    errors.add(e);                } finally {                    producerStopLatch.countDown();                }            }        };        t.setDaemon(true);        t.start();    }    for (int i = 0; i < numThreads; i++) {        final int id = i;        Thread t = new Thread() {            @Override            public void run() {                try {                    while (!producerStopLatch.await(1, TimeUnit.SECONDS) || expected.size() > actual.size()) {                        if (id % 2 == 0) {                            actual.addAll(takeEvents(channel, 1, Integer.MAX_VALUE));                        } else {                            actual.addAll(takeEvents(channel, 5, Integer.MAX_VALUE));                        }                    }                    if (actual.isEmpty()) {                        LOG.error("Found nothing!");                    } else {                        LOG.info("Completed some takes " + actual.size());                    }                } catch (Exception e) {                    LOG.error("Error doing takes", e);                    errors.add(e);                } finally {                    consumerStopLatch.countDown();                }            }        };        t.setDaemon(true);        t.start();    }    Assert.assertTrue("Timed out waiting for producers", producerStopLatch.await(30, TimeUnit.SECONDS));    Assert.assertTrue("Timed out waiting for consumer", consumerStopLatch.await(30, TimeUnit.SECONDS));    Assert.assertEquals(Collections.EMPTY_LIST, errors);    compareInputAndOut(expected, actual);}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    try {        if (id % 2 == 0) {            expected.addAll(putEvents(channel, Integer.toString(id), 1, 5));        } else {            expected.addAll(putEvents(channel, Integer.toString(id), 5, 5));        }        LOG.info("Completed some puts " + expected.size());    } catch (Exception e) {        LOG.error("Error doing puts", e);        errors.add(e);    } finally {        producerStopLatch.countDown();    }}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    try {        while (!producerStopLatch.await(1, TimeUnit.SECONDS) || expected.size() > actual.size()) {            if (id % 2 == 0) {                actual.addAll(takeEvents(channel, 1, Integer.MAX_VALUE));            } else {                actual.addAll(takeEvents(channel, 5, Integer.MAX_VALUE));            }        }        if (actual.isEmpty()) {            LOG.error("Found nothing!");        } else {            LOG.info("Completed some takes " + actual.size());        }    } catch (Exception e) {        LOG.error("Error doing takes", e);        errors.add(e);    } finally {        consumerStopLatch.countDown();    }}
0c9f9f166715223f95deb82bf61d3153ddde64bffbdf4c79691d2af9f7563f67
testLocking
public void testLocking() throws IOException
{    channel.start();    Assert.assertTrue(channel.isOpen());    FileChannel fileChannel = createFileChannel();    fileChannel.start();    Assert.assertTrue(!fileChannel.isOpen());}
57845302301eb88d82416cf55a23a741f27258ddadad9656820e21546aac4aa5
testTakeTransactionCrossingCheckpoint
public void testTakeTransactionCrossingCheckpoint() throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.CHECKPOINT_INTERVAL, "10000");    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> in = fillChannel(channel, "restart");    Set<String> out = Sets.newHashSet();        Transaction tx = channel.getTransaction();    out.addAll(takeWithoutCommit(channel, tx, 1));            forceCheckpoint(channel);    tx.commit();    tx.close();    channel.stop();    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());        Set<String> out2 = takeEvents(channel, 1, Integer.MAX_VALUE);    channel.stop();    in.removeAll(out);    compareInputAndOut(in, out2);}
c2e3117aeb239c955c235a077ce005e3e89d378d51cedb89c7bfe2e239920509
testPutForceCheckpointCommitReplay
public void testPutForceCheckpointCommitReplay() throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.CAPACITY, String.valueOf(2));    overrides.put(FileChannelConfiguration.TRANSACTION_CAPACITY, String.valueOf(2));    overrides.put(FileChannelConfiguration.CHECKPOINT_INTERVAL, "10000");    FileChannel channel = createFileChannel(overrides);    channel.start();        Transaction tx = channel.getTransaction();    Set<String> in = putWithoutCommit(channel, tx, "putWithoutCommit", 1);    forceCheckpoint(channel);    tx.commit();    tx.close();    channel.stop();    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> out = takeEvents(channel, 1);    compareInputAndOut(in, out);    channel.stop();}
88e05d47e933f72aefda14bcaff5f89b68ab0d88f7fedf232ff1d0a9a5a9e36d
testPutCheckpointCommitCheckpointReplay
public void testPutCheckpointCommitCheckpointReplay() throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.CAPACITY, String.valueOf(2));    overrides.put(FileChannelConfiguration.TRANSACTION_CAPACITY, String.valueOf(2));    overrides.put(FileChannelConfiguration.CHECKPOINT_INTERVAL, "10000");    FileChannel channel = createFileChannel(overrides);    channel.start();        Transaction tx = channel.getTransaction();    Set<String> in = putWithoutCommit(channel, tx, "doubleCheckpoint", 1);    forceCheckpoint(channel);    tx.commit();    tx.close();    forceCheckpoint(channel);    channel.stop();    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> out = takeEvents(channel, 5);    compareInputAndOut(in, out);    channel.stop();}
35a0a3b64fffeab0d4d939f4db6ffe22c4a8a13754f57418f37f86e24c646354
testReferenceCounts
public void testReferenceCounts() throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.CHECKPOINT_INTERVAL, "10000");    overrides.put(FileChannelConfiguration.MAX_FILE_SIZE, "150");    final FileChannel channel = createFileChannel(overrides);    channel.start();    putEvents(channel, "testing-reference-counting", 1, 15);    Transaction tx = channel.getTransaction();    takeWithoutCommit(channel, tx, 10);    forceCheckpoint(channel);    tx.rollback();            final Set<String> takenEvents = Sets.newHashSet();    Executors.newSingleThreadExecutor().submit(new Runnable() {        @Override        public void run() {            try {                takenEvents.addAll(takeEvents(channel, 15));            } catch (Exception ex) {                Throwables.propagate(ex);            }        }    }).get();    Assert.assertEquals(15, takenEvents.size());}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    try {        takenEvents.addAll(takeEvents(channel, 15));    } catch (Exception ex) {        Throwables.propagate(ex);    }}
e23352e0174289642b9759ece9542afaf49e36fd4ffa3da700d716de6cb94359
testRollbackIncompleteTransaction
public void testRollbackIncompleteTransaction() throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.CHECKPOINT_INTERVAL, String.valueOf(Integer.MAX_VALUE));    final FileChannel channel = createFileChannel(overrides);    channel.start();    FileBackedTransaction tx = (FileBackedTransaction) channel.getTransaction();    InflightEventWrapper inflightPuts = field("inflightPuts").ofType(InflightEventWrapper.class).in(field("queue").ofType(FlumeEventQueue.class).in(tx).get()).get();    tx.begin();    for (int i = 0; i < 100; i++) {        channel.put(EventBuilder.withBody("TestEvent".getBytes()));    }    Assert.assertFalse(inflightPuts.getFileIDs().isEmpty());    Assert.assertFalse(inflightPuts.getInFlightPointers().isEmpty());    tx.rollback();    tx.close();    Assert.assertTrue(inflightPuts.getFileIDs().isEmpty());    Assert.assertTrue(inflightPuts.getInFlightPointers().isEmpty());    Assert.assertTrue(channel.getDepth() == 0);    Set<String> in = putEvents(channel, "testing-rollbacks", 100, 100);    tx = (FileBackedTransaction) channel.getTransaction();    InflightEventWrapper inflightTakes = field("inflightTakes").ofType(InflightEventWrapper.class).in(field("queue").ofType(FlumeEventQueue.class).in(tx).get()).get();    tx.begin();    for (int i = 0; i < 100; i++) {        channel.take();    }    Assert.assertFalse(inflightTakes.getFileIDs().isEmpty());    Assert.assertFalse(inflightTakes.getInFlightPointers().isEmpty());    tx.rollback();    tx.close();    Assert.assertTrue(inflightTakes.getFileIDs().isEmpty());    Assert.assertTrue(inflightTakes.getInFlightPointers().isEmpty());    Assert.assertTrue(channel.getDepth() == in.size());}
14cabe3179bcca22b32cdc4aae0b2eb1492ec51be7ef39ff81e8a038141ddd54
testChannelDiesOnCorruptEventFsync
public void testChannelDiesOnCorruptEventFsync() throws Exception
{    testChannelDiesOnCorruptEvent(true);}
adaec6547ec31718ae69df5cdad663657c2f85f5771f4f626a7e77044b999d71
testChannelDiesOnCorruptEventNoFsync
public void testChannelDiesOnCorruptEventNoFsync() throws Exception
{    testChannelDiesOnCorruptEvent(false);}
5e0eefd254ce30b1a786f522bcd9feba4148f0b3e033fede3b3e22d805696cdf
testChannelDiesOnCorruptEvent
private void testChannelDiesOnCorruptEvent(boolean fsyncPerTxn) throws Exception
{    Map<String, String> overrides = new HashMap<String, String>();    overrides.put(FileChannelConfiguration.FSYNC_PER_TXN, String.valueOf(fsyncPerTxn));    final FileChannel channel = createFileChannel(overrides);    channel.start();    putEvents(channel, "test-corrupt-event", 100, 100);    for (File dataDir : dataDirs) {        File[] files = dataDir.listFiles(new FilenameFilter() {            @Override            public boolean accept(File dir, String name) {                if (!name.endsWith("meta") && !name.contains("lock")) {                    return true;                }                return false;            }        });        if (files != null && files.length > 0) {            for (int j = 0; j < files.length; j++) {                RandomAccessFile fileToCorrupt = new RandomAccessFile(files[0], "rw");                fileToCorrupt.seek(50);                fileToCorrupt.writeByte(234);                fileToCorrupt.close();            }        }    }    Set<String> events;    try {        events = consumeChannel(channel, true);    } catch (IllegalStateException ex) {                                Assert.assertTrue(ex.getMessage().contains("Log is closed"));        throw ex;    }    if (fsyncPerTxn) {        Assert.fail();    } else {                        Assert.assertEquals(99, events.size());    }}
ca62bfdc0472b2de6468644412d9ad6b432937742edcb5ca65b1f23b694b5853
accept
public boolean accept(File dir, String name)
{    if (!name.endsWith("meta") && !name.contains("lock")) {        return true;    }    return false;}
f8e9d8f67577187fcb8aced07a68be0e25e74edeffa22fb6667c82817f5a1c23
testFileChannelCounterIsOpen
public void testFileChannelCounterIsOpen()
{    FileChannel channel = createFileChannel();    FileChannelCounter counter = channel.getChannelCounter();    Assert.assertEquals(counter.isOpen(), false);    channel.start();    Assert.assertEquals(counter.isOpen(), true);    channel.stop();    Assert.assertEquals(counter.isOpen(), false);}
27681e68ec2a1eb903f955680ebe003ceb3707295c8aad884b692d378c6e37cf
setup
public void setup() throws Exception
{    baseDir = Files.createTempDir();    checkpointDir = new File(baseDir, "chkpt");    backupDir = new File(baseDir, "backup");    uncompressedBackupCheckpoint = new File(backupDir, "checkpoint");    compressedBackupCheckpoint = new File(backupDir, "checkpoint.snappy");    Assert.assertTrue(checkpointDir.mkdirs() || checkpointDir.isDirectory());    Assert.assertTrue(backupDir.mkdirs() || backupDir.isDirectory());    dataDirs = new File[dataDirCount];    dataDir = "";    for (int i = 0; i < dataDirs.length; i++) {        dataDirs[i] = new File(baseDir, "data" + (i + 1));        Assert.assertTrue(dataDirs[i].mkdirs() || dataDirs[i].isDirectory());        dataDir += dataDirs[i].getAbsolutePath() + ",";    }    dataDir = dataDir.substring(0, dataDir.length() - 1);    channel = createFileChannel();}
ec8b6259c87a96a7e78ab8ec13a826f2caf0d2a1c593d4aec011e181f3e17bbf
teardown
public void teardown()
{    if (channel != null && channel.isOpen()) {        channel.stop();    }    FileUtils.deleteQuietly(baseDir);}
340fc5827b5f262b5f147c44207ea5f7010198d9d33b6f7cb842f49860a829b5
createContext
protected Context createContext()
{    return createContext(new HashMap<String, String>());}
c5e90e137fb43e386c458928dae93919e33bd03e36949c3506aea157b59fede1
createContext
protected Context createContext(Map<String, String> overrides)
{    return TestUtils.createFileChannelContext(checkpointDir.getAbsolutePath(), dataDir, backupDir.getAbsolutePath(), overrides);}
9ae2b166654ed261fa0e12110ae508fc5e5863e2a4f01f7ad40238936cbc4041
createFileChannel
protected FileChannel createFileChannel()
{    return createFileChannel(new HashMap<String, String>());}
014ad32c13980f24eb406e766e1f0abcde4f396a69f1d0b81ece116ffac995f5
createFileChannel
protected FileChannel createFileChannel(Map<String, String> overrides)
{    return TestUtils.createFileChannel(checkpointDir.getAbsolutePath(), dataDir, backupDir.getAbsolutePath(), overrides);}
19386d177e1cf01134cb11f7ebde313531197c2846937e70a977b97172eb44a4
testEventTakePutErrorCount
public void testEventTakePutErrorCount() throws Exception
{    final long usableSpaceRefreshInterval = 1;    FileChannel channel = Mockito.spy(createFileChannel());    Mockito.when(channel.createLogBuilder()).then(new Answer<Log.Builder>() {        @Override        public Log.Builder answer(InvocationOnMock invocation) throws Throwable {            Log.Builder ret = (Log.Builder) invocation.callRealMethod();            ret.setUsableSpaceRefreshInterval(usableSpaceRefreshInterval);            return ret;        }    });    channel.start();    FileChannelCounter channelCounter = channel.getChannelCounter();    Transaction tx = channel.getTransaction();    tx.begin();    channel.put(EventBuilder.withBody("test1".getBytes()));    channel.put(EventBuilder.withBody("test2".getBytes()));    tx.commit();    tx.close();    assertEquals(2, channelCounter.getEventPutAttemptCount());    assertEquals(2, channelCounter.getEventPutSuccessCount());    assertEquals(0, channelCounter.getEventPutErrorCount());    tx = channel.getTransaction();    tx.begin();    channel.take();    tx.commit();    tx.close();    assertEquals(1, channelCounter.getEventTakeAttemptCount());    assertEquals(1, channelCounter.getEventTakeSuccessCount());    assertEquals(0, channelCounter.getEventTakeErrorCount());    FileUtils.deleteDirectory(baseDir);    Thread.sleep(2 * usableSpaceRefreshInterval);    tx = channel.getTransaction();    tx.begin();    ChannelException putException = null;    try {        channel.put(EventBuilder.withBody("test".getBytes()));    } catch (ChannelException ex) {        putException = ex;    }    assertNotNull(putException);    assertTrue(putException.getCause() instanceof IOException);    assertEquals(3, channelCounter.getEventPutAttemptCount());    assertEquals(2, channelCounter.getEventPutSuccessCount());    assertEquals(1, channelCounter.getEventPutErrorCount());    ChannelException takeException = null;    try {                channel.take();    } catch (ChannelException ex) {        takeException = ex;    }    assertNotNull(takeException);    assertTrue(takeException.getCause() instanceof IOException);    assertEquals(2, channelCounter.getEventTakeAttemptCount());    assertEquals(1, channelCounter.getEventTakeSuccessCount());    assertEquals(1, channelCounter.getEventTakeErrorCount());}
dd88d71fe13f1893cdb9cff55cf5936777211ec61f39dd04600099aecedd832c
answer
public Log.Builder answer(InvocationOnMock invocation) throws Throwable
{    Log.Builder ret = (Log.Builder) invocation.callRealMethod();    ret.setUsableSpaceRefreshInterval(usableSpaceRefreshInterval);    return ret;}
3144e8de5eb557bfac26c2eb60c806fc0a858c0e175c1d34e2ac6c1bc987d72e
testCorruptEventTaken
public void testCorruptEventTaken() throws Exception
{    FileChannel channel = createFileChannel(Collections.singletonMap(FileChannelConfiguration.FSYNC_PER_TXN, "false"));    channel.start();    FileChannelCounter channelCounter = channel.getChannelCounter();    Transaction tx = channel.getTransaction();    tx.begin();    channel.put(EventBuilder.withBody("test".getBytes()));    tx.commit();    tx.close();    byte[] data = FileUtils.readFileToByteArray(new File(dataDirs[0], "log-1"));        data[0] = LogFile.OP_EOF;    FileUtils.writeByteArrayToFile(new File(dataDirs[0], "log-1"), data);    tx = channel.getTransaction();    tx.begin();    try {        channel.take();    } catch (Throwable t) {                                        Assert.fail("No exception should be thrown as fsyncPerTransaction is false");    }    assertEquals(1, channelCounter.getEventTakeAttemptCount());    assertEquals(0, channelCounter.getEventTakeSuccessCount());    assertEquals(1, channelCounter.getEventTakeErrorCount());}
92679c27ac5296ab301e5eedeeef3fc68aede6112d2c871ee7eea1c15bfb20e5
testCheckpointWriteErrorCount
public void testCheckpointWriteErrorCount() throws Exception
{    int checkpointInterval = 1500;    final FileChannel channel = createFileChannel(Collections.singletonMap(FileChannelConfiguration.CHECKPOINT_INTERVAL, String.valueOf(checkpointInterval)));    channel.start();    Transaction tx = channel.getTransaction();    tx.begin();    channel.put(EventBuilder.withBody("test".getBytes()));    tx.commit();    tx.close();    final long beforeCheckpointWrite = System.currentTimeMillis();        assertEventuallyTrue("checkpoint should have been written", new BooleanPredicate() {        @Override        public boolean get() {            return new File(checkpointDir, "checkpoint").lastModified() > beforeCheckpointWrite;        }    }, checkpointInterval * 3);    assertEquals(0, channel.getChannelCounter().getCheckpointWriteErrorCount());    FileUtils.deleteDirectory(baseDir);        assertEventuallyTrue("checkpointWriterErrorCount should be 1", new BooleanPredicate() {        @Override        public boolean get() {            return channel.getChannelCounter().getCheckpointWriteErrorCount() == 1;        }    }, checkpointInterval * 3);}
6cf11a46102b951081d83a9a1bfda78f4218d87e00069730c9e29e408d9029be
get
public boolean get()
{    return new File(checkpointDir, "checkpoint").lastModified() > beforeCheckpointWrite;}
6cf11a46102b951081d83a9a1bfda78f4218d87e00069730c9e29e408d9029be
get
public boolean get()
{    return channel.getChannelCounter().getCheckpointWriteErrorCount() == 1;}
50f9d5d82f5cf8772d86817c00cadf4c920f56a504cebbaf73c0cdd2f801c8b9
testHealthy
public void testHealthy() throws Exception
{    FileChannel channel = createFileChannel();    assertEquals(0, channel.getChannelCounter().getUnhealthy());    assertEquals(1, channel.getChannelCounter().getClosed());    assertFalse(channel.getChannelCounter().isOpen());    channel.start();    assertEquals(0, channel.getChannelCounter().getUnhealthy());    assertEquals(0, channel.getChannelCounter().getClosed());    assertTrue(channel.getChannelCounter().isOpen());}
775be7a7b278d221be401bb67f0442fc678581145b140176c74f2ad76b9c9a7f
testUnhealthy
public void testUnhealthy() throws Exception
{    FileChannel channel = createFileChannel();    assertEquals(0, channel.getChannelCounter().getUnhealthy());    assertEquals(1, channel.getChannelCounter().getClosed());    assertFalse(channel.getChannelCounter().isOpen());    FileUtils.write(new File(dataDirs[0], "log-1"), "invalid data file content");    channel.start();    assertEquals(1, channel.getChannelCounter().getUnhealthy());    assertEquals(1, channel.getChannelCounter().getClosed());    assertFalse(channel.getChannelCounter().isOpen());}
95d093e1e6672f403fcd93d4c3b4eff77cf81e7e7ba4a1baddd0f2c82b44749d
testCheckpointBackupWriteErrorShouldIncreaseCounter
public void testCheckpointBackupWriteErrorShouldIncreaseCounter() throws IOException, InterruptedException
{    FileChannelCounter fileChannelCounter = new FileChannelCounter("test");    File checkpointFile = File.createTempFile("checkpoint", ".tmp");    File backupDir = Files.createTempDirectory("checkpoint").toFile();    backupDir.deleteOnExit();    checkpointFile.deleteOnExit();    EventQueueBackingStoreFileV3 backingStoreFileV3 = new EventQueueBackingStoreFileV3(checkpointFile, 1, "test", fileChannelCounter, backupDir, true, false);        backingStoreFileV3.checkpoint();        assertEventuallyTrue("checkpoint backup write failure should increase counter to 1", new BooleanPredicate() {        @Override        public boolean get() {            return fileChannelCounter.getCheckpointBackupWriteErrorCount() == 1;        }    }, 100);}
6cf11a46102b951081d83a9a1bfda78f4218d87e00069730c9e29e408d9029be
get
public boolean get()
{    return fileChannelCounter.getCheckpointBackupWriteErrorCount() == 1;}
4e0b0e22a09e27f93418e7a0491184b5e8d82d81a55af317b9a66eb10311a37e
testCheckpointBackupWriteErrorShouldIncreaseCounter2
public void testCheckpointBackupWriteErrorShouldIncreaseCounter2() throws Exception
{    int checkpointInterval = 1500;    Map config = new HashMap();    config.put(FileChannelConfiguration.CHECKPOINT_INTERVAL, String.valueOf(checkpointInterval));    config.put(FileChannelConfiguration.USE_DUAL_CHECKPOINTS, "true");    final FileChannel channel = createFileChannel(Collections.unmodifiableMap(config));    channel.start();    Transaction tx = channel.getTransaction();    tx.begin();    channel.put(EventBuilder.withBody("test".getBytes()));    tx.commit();    tx.close();    final long beforeCheckpointWrite = System.currentTimeMillis();        assertEventuallyTrue("checkpoint backup should have been written", new BooleanPredicate() {        @Override        public boolean get() {            return new File(backupDir, "checkpoint").lastModified() > beforeCheckpointWrite;        }    }, checkpointInterval * 3);    assertEquals(0, channel.getChannelCounter().getCheckpointBackupWriteErrorCount());    FileUtils.deleteDirectory(backupDir);    tx = channel.getTransaction();    tx.begin();    channel.put(EventBuilder.withBody("test2".getBytes()));    tx.commit();    tx.close();        assertEventuallyTrue("checkpointBackupWriteErrorCount should be 1", new BooleanPredicate() {        @Override        public boolean get() {            return channel.getChannelCounter().getCheckpointBackupWriteErrorCount() >= 1;        }    }, checkpointInterval * 3);}
6cf11a46102b951081d83a9a1bfda78f4218d87e00069730c9e29e408d9029be
get
public boolean get()
{    return new File(backupDir, "checkpoint").lastModified() > beforeCheckpointWrite;}
6cf11a46102b951081d83a9a1bfda78f4218d87e00069730c9e29e408d9029be
get
public boolean get()
{    return channel.getChannelCounter().getCheckpointBackupWriteErrorCount() >= 1;}
5e5f6d26262d2faaa852fa570e38e3fcd8a17dcff6025c90751df9989edcd49f
assertEventuallyTrue
private static void assertEventuallyTrue(String description, BooleanPredicate expression, long timeoutMillis) throws InterruptedException
{    long start = System.currentTimeMillis();    while (System.currentTimeMillis() < start + timeoutMillis) {        if (expression.get())            break;        Thread.sleep(timeoutMillis / 10);    }    assertTrue(description, expression.get());}
27681e68ec2a1eb903f955680ebe003ceb3707295c8aad884b692d378c6e37cf
setup
public void setup() throws Exception
{    super.setup();}
ec8b6259c87a96a7e78ab8ec13a826f2caf0d2a1c593d4aec011e181f3e17bbf
teardown
public void teardown()
{    super.teardown();}
0e52eb9f03a238e8f14e3fc987e1c25606eb8375140a505411ab1bb15a42c8ca
testFileFormatV2postFLUME1432
public void testFileFormatV2postFLUME1432() throws Exception
{    TestUtils.copyDecompressed("fileformat-v2-checkpoint.gz", new File(checkpointDir, "checkpoint"));    for (int i = 0; i < dataDirs.length; i++) {        int fileIndex = i + 1;        TestUtils.copyDecompressed("fileformat-v2-log-" + fileIndex + ".gz", new File(dataDirs[i], "log-" + fileIndex));    }    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.CAPACITY, String.valueOf(10));    overrides.put(FileChannelConfiguration.TRANSACTION_CAPACITY, String.valueOf(10));    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> events = takeEvents(channel, 1);    Set<String> expected = new HashSet<String>();    expected.addAll(Arrays.asList((new String[] { "2684", "2685", "2686", "2687", "2688", "2689", "2690", "2691" })));    compareInputAndOut(expected, events);}
aed965ac30c4737a6d5a12bb95db34f7f2f97f909e8c2965e499f4aa6ac6f191
testFileFormatV2PreFLUME1432LogReplayV1
public void testFileFormatV2PreFLUME1432LogReplayV1() throws Exception
{    doTestFileFormatV2PreFLUME1432(true);}
e0accf22f746846f10fb667e19d7242637a31e2e473df4e15a1ffabbedd5e0da
testFileFormatV2PreFLUME1432LogReplayV2
public void testFileFormatV2PreFLUME1432LogReplayV2() throws Exception
{    doTestFileFormatV2PreFLUME1432(false);}
f6c66a0d1d98a2bc2fc689d16df211028ffe8930f40e6d1561229159794f07c3
doTestFileFormatV2PreFLUME1432
public void doTestFileFormatV2PreFLUME1432(boolean useLogReplayV1) throws Exception
{    TestUtils.copyDecompressed("fileformat-v2-pre-FLUME-1432-checkpoint.gz", new File(checkpointDir, "checkpoint"));    for (int i = 0; i < dataDirs.length; i++) {        int fileIndex = i + 1;        TestUtils.copyDecompressed("fileformat-v2-pre-FLUME-1432-log-" + fileIndex + ".gz", new File(dataDirs[i], "log-" + fileIndex));    }    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.CAPACITY, String.valueOf(10000));    overrides.put(FileChannelConfiguration.USE_LOG_REPLAY_V1, String.valueOf(useLogReplayV1));    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> events = takeEvents(channel, 1);    Assert.assertEquals(50, events.size());}
27681e68ec2a1eb903f955680ebe003ceb3707295c8aad884b692d378c6e37cf
setup
public void setup() throws Exception
{    super.setup();}
ec8b6259c87a96a7e78ab8ec13a826f2caf0d2a1c593d4aec011e181f3e17bbf
teardown
public void teardown()
{    super.teardown();}
014ad32c13980f24eb406e766e1f0abcde4f396a69f1d0b81ece116ffac995f5
createFileChannel
protected FileChannel createFileChannel(Map<String, String> overrides)
{        overrides.put(FileChannelConfiguration.CHECKPOINT_INTERVAL, "6000000");    return TestUtils.createFileChannel(checkpointDir.getAbsolutePath(), dataDir, backupDir.getAbsolutePath(), overrides);}
2b000974fb7e27450b498ac353a20906a42ce1cbab988ecc4096207e7ceaf40d
testRestartLogReplayV1
public void testRestartLogReplayV1() throws Exception
{    doTestRestart(true, false, false, false);}
2a3c66b88fec1f1268162c9df568fb163cb59651c36258fc55845ec4acaf6d9b
testRestartLogReplayV2
public void testRestartLogReplayV2() throws Exception
{    doTestRestart(false, false, false, false);}
9bd3c32ef09ef8c0f57859a2ccb1b33b601e210dcebcb3186d7c4f58e6d04d72
testFastReplayV1
public void testFastReplayV1() throws Exception
{    doTestRestart(true, true, true, true);}
f0b741db4adfb53908843161db5e1f64001e0d6f3451067bd3dd0ad5b6232404
testFastReplayV2
public void testFastReplayV2() throws Exception
{    doTestRestart(false, true, true, true);}
62f7c0a248efee480b68abc4c5ae37e7ae94e05d784dc63c6129c8732895b6be
testFastReplayNegativeTestV1
public void testFastReplayNegativeTestV1() throws Exception
{    doTestRestart(true, true, false, true);}
682633c62d9dfad1f66899cb63ebf38b2ab0348fb2cc9dbd71c9b3809154797a
testFastReplayNegativeTestV2
public void testFastReplayNegativeTestV2() throws Exception
{    doTestRestart(false, true, false, true);}
8f4c630aa844e33d50cad170f705da1de08161265dfb2de22e4b9a4349393906
testNormalReplayV1
public void testNormalReplayV1() throws Exception
{    doTestRestart(true, true, true, false);}
1dd8fe069211f8dbebb9285a937feeac141690a83c439e499ab5d45cc0e55f1b
testNormalReplayV2
public void testNormalReplayV2() throws Exception
{    doTestRestart(false, true, true, false);}
26d9a42acd2f2506565f5da77e2f1140b3277bcb7a933ef7c0da7a50518c8575
doTestRestart
public void doTestRestart(boolean useLogReplayV1, boolean forceCheckpoint, boolean deleteCheckpoint, boolean useFastReplay) throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.USE_LOG_REPLAY_V1, String.valueOf(useLogReplayV1));    overrides.put(FileChannelConfiguration.USE_FAST_REPLAY, String.valueOf(useFastReplay));    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> in = fillChannel(channel, "restart");    if (forceCheckpoint) {        forceCheckpoint(channel);    }    channel.stop();    if (deleteCheckpoint) {        File checkpoint = new File(checkpointDir, "checkpoint");        Assert.assertTrue(checkpoint.delete());        File checkpointMetaData = Serialization.getMetaDataFile(checkpoint);        Assert.assertTrue(checkpointMetaData.delete());    }    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> out = consumeChannel(channel);    compareInputAndOut(in, out);}
a73fc105655f76353003e5543fab987c0febb211e6f8fab06a174de6940df25e
testRestartWhenMetaDataExistsButCheckpointDoesNot
public void testRestartWhenMetaDataExistsButCheckpointDoesNot() throws Exception
{    doTestRestartWhenMetaDataExistsButCheckpointDoesNot(false);}
9554cfafb93a1a4432e76ccc89e44a9f5092189487c67bf166fc9decba1dbd41
testRestartWhenMetaDataExistsButCheckpointDoesNotWithBackup
public void testRestartWhenMetaDataExistsButCheckpointDoesNotWithBackup() throws Exception
{    doTestRestartWhenMetaDataExistsButCheckpointDoesNot(true);}
b3c29029a92e0ba8b8c0485dd23f6bcc91bfb87d9dd43e7f4d0ad2129c664941
doTestRestartWhenMetaDataExistsButCheckpointDoesNot
private void doTestRestartWhenMetaDataExistsButCheckpointDoesNot(boolean backup) throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.USE_DUAL_CHECKPOINTS, String.valueOf(backup));    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> in = putEvents(channel, "restart", 10, 100);    Assert.assertEquals(100, in.size());    forceCheckpoint(channel);    if (backup) {        Thread.sleep(2000);    }    channel.stop();    File checkpoint = new File(checkpointDir, "checkpoint");    Assert.assertTrue(checkpoint.delete());    File checkpointMetaData = Serialization.getMetaDataFile(checkpoint);    Assert.assertTrue(checkpointMetaData.exists());    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Assert.assertTrue(checkpoint.exists());    Assert.assertTrue(checkpointMetaData.exists());    Assert.assertTrue(!backup || channel.checkpointBackupRestored());    Set<String> out = consumeChannel(channel);    compareInputAndOut(in, out);}
f35afb7a0ff4c0740a8d930327c48ebf0da84ff9571d9dad8360a278405f24b5
testRestartWhenCheckpointExistsButMetaDoesNot
public void testRestartWhenCheckpointExistsButMetaDoesNot() throws Exception
{    doTestRestartWhenCheckpointExistsButMetaDoesNot(false);}
44c84bf4b7cc2ac722d4d1ce48d6b88fe4543c46caed0203123bd1edb0799c1c
testRestartWhenCheckpointExistsButMetaDoesNotWithBackup
public void testRestartWhenCheckpointExistsButMetaDoesNotWithBackup() throws Exception
{    doTestRestartWhenCheckpointExistsButMetaDoesNot(true);}
b7ae596e8ef7a848c97eb4c107003f66130550402327ff50db1f4a8a5160f652
doTestRestartWhenCheckpointExistsButMetaDoesNot
private void doTestRestartWhenCheckpointExistsButMetaDoesNot(boolean backup) throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.USE_DUAL_CHECKPOINTS, String.valueOf(backup));    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> in = putEvents(channel, "restart", 10, 100);    Assert.assertEquals(100, in.size());    forceCheckpoint(channel);    if (backup) {        Thread.sleep(2000);    }    channel.stop();    File checkpoint = new File(checkpointDir, "checkpoint");    File checkpointMetaData = Serialization.getMetaDataFile(checkpoint);    Assert.assertTrue(checkpointMetaData.delete());    Assert.assertTrue(checkpoint.exists());    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Assert.assertTrue(checkpoint.exists());    Assert.assertTrue(checkpointMetaData.exists());    Assert.assertTrue(!backup || channel.checkpointBackupRestored());    Set<String> out = consumeChannel(channel);    compareInputAndOut(in, out);}
a5b1ef29d9e525ad888cebf7a868fa748fd3319e21ee2d2c401c097086e96412
testRestartWhenNoCheckpointExists
public void testRestartWhenNoCheckpointExists() throws Exception
{    doTestRestartWhenNoCheckpointExists(false);}
bffc61a760b596f40669d805ff4924b786fd2ba4440432600429315b92e54b26
testRestartWhenNoCheckpointExistsWithBackup
public void testRestartWhenNoCheckpointExistsWithBackup() throws Exception
{    doTestRestartWhenNoCheckpointExists(true);}
8c9cff72e03d0bc2ee84b0534194bb73f1479811464a3ed7c61b443103582026
doTestRestartWhenNoCheckpointExists
private void doTestRestartWhenNoCheckpointExists(boolean backup) throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.USE_DUAL_CHECKPOINTS, String.valueOf(backup));    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> in = putEvents(channel, "restart", 10, 100);    Assert.assertEquals(100, in.size());    forceCheckpoint(channel);    if (backup) {        Thread.sleep(2000);    }    channel.stop();    File checkpoint = new File(checkpointDir, "checkpoint");    File checkpointMetaData = Serialization.getMetaDataFile(checkpoint);    Assert.assertTrue(checkpointMetaData.delete());    Assert.assertTrue(checkpoint.delete());    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Assert.assertTrue(checkpoint.exists());    Assert.assertTrue(checkpointMetaData.exists());    Assert.assertTrue(!backup || channel.checkpointBackupRestored());    Set<String> out = consumeChannel(channel);    compareInputAndOut(in, out);}
dc5b29241d2065a9eb18be017df7b911f6877ee86030f9492896306565aba9d3
testBadCheckpointVersion
public void testBadCheckpointVersion() throws Exception
{    doTestBadCheckpointVersion(false);}
cd8f5eda6c96260f4e54bb57b2674215429ffa0d92739af86b2eaee39867e31a
testBadCheckpointVersionWithBackup
public void testBadCheckpointVersionWithBackup() throws Exception
{    doTestBadCheckpointVersion(true);}
09a1efb85ed5028f7e293a0e973b121edd817c82374266562661fe2e6156a6ff
doTestBadCheckpointVersion
private void doTestBadCheckpointVersion(boolean backup) throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.USE_DUAL_CHECKPOINTS, String.valueOf(backup));    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> in = putEvents(channel, "restart", 10, 100);    Assert.assertEquals(100, in.size());    forceCheckpoint(channel);    if (backup) {        Thread.sleep(2000);    }    channel.stop();    File checkpoint = new File(checkpointDir, "checkpoint");    RandomAccessFile writer = new RandomAccessFile(checkpoint, "rw");    writer.seek(EventQueueBackingStoreFile.INDEX_VERSION * Serialization.SIZE_OF_LONG);    writer.writeLong(2L);    writer.getFD().sync();    writer.close();    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Assert.assertTrue(!backup || channel.checkpointBackupRestored());    Set<String> out = consumeChannel(channel);    compareInputAndOut(in, out);}
8180bafc7454bae9060e39f805119a1f412bcb46c83d4f3e4c3063d8891c36c9
testBadCheckpointMetaVersion
public void testBadCheckpointMetaVersion() throws Exception
{    doTestBadCheckpointMetaVersion(false);}
0c7e94b0739b2469f81791c499de59be795db76e79a6439ab8aecf212205564a
testBadCheckpointMetaVersionWithBackup
public void testBadCheckpointMetaVersionWithBackup() throws Exception
{    doTestBadCheckpointMetaVersion(true);}
d49783a3a6aa5a0d8e475f0339c70f78e71ca3f9a2ca45d77f7b19b3c6a3e51d
doTestBadCheckpointMetaVersion
private void doTestBadCheckpointMetaVersion(boolean backup) throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.USE_DUAL_CHECKPOINTS, String.valueOf(backup));    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> in = putEvents(channel, "restart", 10, 100);    Assert.assertEquals(100, in.size());    forceCheckpoint(channel);    if (backup) {        Thread.sleep(2000);    }    channel.stop();    File checkpoint = new File(checkpointDir, "checkpoint");    FileInputStream is = new FileInputStream(Serialization.getMetaDataFile(checkpoint));    ProtosFactory.Checkpoint meta = ProtosFactory.Checkpoint.parseDelimitedFrom(is);    Assert.assertNotNull(meta);    is.close();    FileOutputStream os = new FileOutputStream(Serialization.getMetaDataFile(checkpoint));    meta.toBuilder().setVersion(2).build().writeDelimitedTo(os);    os.flush();    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Assert.assertTrue(!backup || channel.checkpointBackupRestored());    Set<String> out = consumeChannel(channel);    compareInputAndOut(in, out);}
a40d2ff5d6b576adc8f3fddd0463ed556895b2ef3d53c617134dcba146e2e3f2
testDifferingOrderIDCheckpointAndMetaVersion
public void testDifferingOrderIDCheckpointAndMetaVersion() throws Exception
{    doTestDifferingOrderIDCheckpointAndMetaVersion(false);}
52bdc398ff6aaceb454aeb82def0b37c1af6b1d7e4536c0263d9a65788a2f5f1
testDifferingOrderIDCheckpointAndMetaVersionWithBackup
public void testDifferingOrderIDCheckpointAndMetaVersionWithBackup() throws Exception
{    doTestDifferingOrderIDCheckpointAndMetaVersion(true);}
7e5523a93cd7b1c77fbefa36329dee0ad7ac5ceb4f5f325772ba0645f2e60339
doTestDifferingOrderIDCheckpointAndMetaVersion
private void doTestDifferingOrderIDCheckpointAndMetaVersion(boolean backup) throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.USE_DUAL_CHECKPOINTS, String.valueOf(backup));    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> in = putEvents(channel, "restart", 10, 100);    Assert.assertEquals(100, in.size());    forceCheckpoint(channel);    if (backup) {        Thread.sleep(2000);    }    channel.stop();    File checkpoint = new File(checkpointDir, "checkpoint");    FileInputStream is = new FileInputStream(Serialization.getMetaDataFile(checkpoint));    ProtosFactory.Checkpoint meta = ProtosFactory.Checkpoint.parseDelimitedFrom(is);    Assert.assertNotNull(meta);    is.close();    FileOutputStream os = new FileOutputStream(Serialization.getMetaDataFile(checkpoint));    meta.toBuilder().setWriteOrderID(12).build().writeDelimitedTo(os);    os.flush();    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Assert.assertTrue(!backup || channel.checkpointBackupRestored());    Set<String> out = consumeChannel(channel);    compareInputAndOut(in, out);}
280a367b799ea42c57804b5422128c588d633d42b13f62f607588eafd28aa8d6
testIncompleteCheckpoint
public void testIncompleteCheckpoint() throws Exception
{    doTestIncompleteCheckpoint(false);}
b7fe706e88b222d8a597aafca078e3a338c588cfe528785fc3d8c7dc1eb8c56e
testIncompleteCheckpointWithCheckpoint
public void testIncompleteCheckpointWithCheckpoint() throws Exception
{    doTestIncompleteCheckpoint(true);}
33d5d4bd0a0baf22d59a24ae5f1f4503970365f45453d588b84e8e4cdd534f9f
doTestIncompleteCheckpoint
private void doTestIncompleteCheckpoint(boolean backup) throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.USE_DUAL_CHECKPOINTS, String.valueOf(backup));    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> in = putEvents(channel, "restart", 10, 100);    Assert.assertEquals(100, in.size());    forceCheckpoint(channel);    if (backup) {        Thread.sleep(2000);    }    channel.stop();    File checkpoint = new File(checkpointDir, "checkpoint");    RandomAccessFile writer = new RandomAccessFile(checkpoint, "rw");    writer.seek(EventQueueBackingStoreFile.INDEX_CHECKPOINT_MARKER * Serialization.SIZE_OF_LONG);    writer.writeLong(EventQueueBackingStoreFile.CHECKPOINT_INCOMPLETE);    writer.getFD().sync();    writer.close();    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Assert.assertTrue(!backup || channel.checkpointBackupRestored());    Set<String> out = consumeChannel(channel);    compareInputAndOut(in, out);}
4c4988866cee97879b37c4c1b2ef906989764f8b7694c605da81e5e22112bd33
testCorruptInflightPuts
public void testCorruptInflightPuts() throws Exception
{    doTestCorruptInflights("inflightputs", false);}
7ee980db11dea9ca50dee775ba9487dc5b07ea95cbb2495a2bbb0fd31dfc74c3
testCorruptInflightPutsWithBackup
public void testCorruptInflightPutsWithBackup() throws Exception
{    doTestCorruptInflights("inflightputs", true);}
849d44a333ec2001ddf66fbf0a6e8febb4062d083bef365db04f91c9f7037e98
testCorruptInflightTakes
public void testCorruptInflightTakes() throws Exception
{    doTestCorruptInflights("inflighttakes", false);}
c2610f08a265b81e15858e139afce2fc7899546796d04550df59e5e543ee16a7
testCorruptInflightTakesWithBackup
public void testCorruptInflightTakesWithBackup() throws Exception
{    doTestCorruptInflights("inflighttakes", true);}
fee7205f5e22555c6e2d23612fff23775d2c51e2ea957a0db442d392cf10fd92
testFastReplayWithCheckpoint
public void testFastReplayWithCheckpoint() throws Exception
{    testFastReplay(false, true);}
2ea342a4682d20bd713ccefe03f965e9067f7549fecdfa54fd30934db7d496a2
testFastReplayWithBadCheckpoint
public void testFastReplayWithBadCheckpoint() throws Exception
{    testFastReplay(true, true);}
349455025bdb7b3319b0eac66ea6654f5bfac1eb9ddcbfcbcd1929d5ed7bd166
testNoFastReplayWithCheckpoint
public void testNoFastReplayWithCheckpoint() throws Exception
{    testFastReplay(false, false);}
25996468a0187529979d30379e83b453b49f7bdf67b16b26239301d08653d919
testNoFastReplayWithBadCheckpoint
public void testNoFastReplayWithBadCheckpoint() throws Exception
{    testFastReplay(true, false);}
364348404b80bb728c4cc62ef16cecd2127f0ead7d8f989715124f5e2b1ee84d
testFastReplay
private void testFastReplay(boolean shouldCorruptCheckpoint, boolean useFastReplay) throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.USE_FAST_REPLAY, String.valueOf(useFastReplay));    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> in = putEvents(channel, "restart", 10, 100);    Assert.assertEquals(100, in.size());    forceCheckpoint(channel);    channel.stop();    if (shouldCorruptCheckpoint) {        File checkpoint = new File(checkpointDir, "checkpoint");        RandomAccessFile writer = new RandomAccessFile(Serialization.getMetaDataFile(checkpoint), "rw");        writer.seek(10);        writer.writeLong(new Random().nextLong());        writer.getFD().sync();        writer.close();    }    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> out = consumeChannel(channel);    if (useFastReplay && shouldCorruptCheckpoint) {        Assert.assertTrue(channel.didFastReplay());    } else {        Assert.assertFalse(channel.didFastReplay());    }    compareInputAndOut(in, out);}
26db8900e9dee68170a31135798f0a0f7cc551efd4d62ef38adf2b35b23b5731
doTestCorruptInflights
private void doTestCorruptInflights(String name, boolean backup) throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.USE_DUAL_CHECKPOINTS, String.valueOf(backup));    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    final Set<String> in1 = putEvents(channel, "restart-", 10, 100);    Assert.assertEquals(100, in1.size());    Executors.newSingleThreadScheduledExecutor().submit(new Runnable() {        @Override        public void run() {            Transaction tx = channel.getTransaction();            Set<String> out1 = takeWithoutCommit(channel, tx, 100);            Assert.assertEquals(100, out1.size());        }    });    Transaction tx = channel.getTransaction();    Set<String> in2 = putWithoutCommit(channel, tx, "restart", 100);    Assert.assertEquals(100, in2.size());    forceCheckpoint(channel);    if (backup) {        Thread.sleep(2000);    }    tx.commit();    tx.close();    channel.stop();    File inflight = new File(checkpointDir, name);    RandomAccessFile writer = new RandomAccessFile(inflight, "rw");    writer.write(new Random().nextInt());    writer.close();    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Assert.assertTrue(!backup || channel.checkpointBackupRestored());    Set<String> out = consumeChannel(channel);    in1.addAll(in2);    compareInputAndOut(in1, out);}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    Transaction tx = channel.getTransaction();    Set<String> out1 = takeWithoutCommit(channel, tx, 100);    Assert.assertEquals(100, out1.size());}
9df9a96ffb082ae1a4f914e5c02e20fb554a2afcffbb08efa3abc4720712fb3d
testTruncatedCheckpointMeta
public void testTruncatedCheckpointMeta() throws Exception
{    doTestTruncatedCheckpointMeta(false);}
11047e7e5be29851fa2ca974621b47c7ae5b57be2847f613aa2e8cf28dd0f3f2
testTruncatedCheckpointMetaWithBackup
public void testTruncatedCheckpointMetaWithBackup() throws Exception
{    doTestTruncatedCheckpointMeta(true);}
08311b53789a08d279538eb5bcad75c76a772c02e008ecc370614e3d18b1b235
doTestTruncatedCheckpointMeta
private void doTestTruncatedCheckpointMeta(boolean backup) throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.USE_DUAL_CHECKPOINTS, String.valueOf(backup));    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> in = putEvents(channel, "restart", 10, 100);    Assert.assertEquals(100, in.size());    forceCheckpoint(channel);    if (backup) {        Thread.sleep(2000);    }    channel.stop();    File checkpoint = new File(checkpointDir, "checkpoint");    RandomAccessFile writer = new RandomAccessFile(Serialization.getMetaDataFile(checkpoint), "rw");    writer.setLength(0);    writer.getFD().sync();    writer.close();    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Assert.assertTrue(!backup || channel.checkpointBackupRestored());    Set<String> out = consumeChannel(channel);    compareInputAndOut(in, out);}
81f8d5b2b79569f59607d5bc29739e59fa131e7620cc05a2fbc6aaae1c6dcf47
testCorruptCheckpointMeta
public void testCorruptCheckpointMeta() throws Exception
{    doTestCorruptCheckpointMeta(false);}
ffb08436e52898d82d14062a8bac79032c9bfa5a8e97d060140051dc419a4a5b
testCorruptCheckpointMetaWithBackup
public void testCorruptCheckpointMetaWithBackup() throws Exception
{    doTestCorruptCheckpointMeta(true);}
aa6f6a1fc70af4f21d221cdad8b9b559a2b6e862ffbc3a37ef8c5130e3becd19
doTestCorruptCheckpointMeta
private void doTestCorruptCheckpointMeta(boolean backup) throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.USE_DUAL_CHECKPOINTS, String.valueOf(backup));    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> in = putEvents(channel, "restart", 10, 100);    Assert.assertEquals(100, in.size());    forceCheckpoint(channel);    if (backup) {        Thread.sleep(2000);    }    channel.stop();    File checkpoint = new File(checkpointDir, "checkpoint");    RandomAccessFile writer = new RandomAccessFile(Serialization.getMetaDataFile(checkpoint), "rw");    writer.seek(10);    writer.writeLong(new Random().nextLong());    writer.getFD().sync();    writer.close();    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Assert.assertTrue(!backup || channel.checkpointBackupRestored());    Set<String> out = consumeChannel(channel);    compareInputAndOut(in, out);}
5d676ec1a54bbdad7cd844889cf9b0baf81229b22adc93001338cda62df06694
checkIfBackupUsed
private void checkIfBackupUsed(boolean backup)
{    boolean backupRestored = channel.checkpointBackupRestored();    if (backup) {        Assert.assertTrue(backupRestored);    } else {        Assert.assertFalse(backupRestored);    }}
72443a78598a9451b96030a25763f898e113056b5949b986577b638f6a65bd42
testCorruptCheckpointVersionMostSignificant4Bytes
public void testCorruptCheckpointVersionMostSignificant4Bytes() throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> in = putEvents(channel, "restart", 10, 100);    Assert.assertEquals(100, in.size());    forceCheckpoint(channel);    channel.stop();    File checkpoint = new File(checkpointDir, "checkpoint");    RandomAccessFile writer = new RandomAccessFile(checkpoint, "rw");    writer.seek(EventQueueBackingStoreFile.INDEX_VERSION * Serialization.SIZE_OF_LONG);    writer.write(new byte[] { (byte) 1, (byte) 5 });    writer.getFD().sync();    writer.close();    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> out = consumeChannel(channel);    Assert.assertTrue(channel.didFullReplayDueToBadCheckpointException());    compareInputAndOut(in, out);}
7eb595635917158c2e550fb20ed15147e7417c7cc24e5bb1e344e8523812e618
testCorruptCheckpointCompleteMarkerMostSignificant4Bytes
public void testCorruptCheckpointCompleteMarkerMostSignificant4Bytes() throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> in = putEvents(channel, "restart", 10, 100);    Assert.assertEquals(100, in.size());    forceCheckpoint(channel);    channel.stop();    File checkpoint = new File(checkpointDir, "checkpoint");    RandomAccessFile writer = new RandomAccessFile(checkpoint, "rw");    writer.seek(EventQueueBackingStoreFile.INDEX_CHECKPOINT_MARKER * Serialization.SIZE_OF_LONG);    writer.write(new byte[] { (byte) 1, (byte) 5 });    writer.getFD().sync();    writer.close();    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> out = consumeChannel(channel);    Assert.assertTrue(channel.didFullReplayDueToBadCheckpointException());    compareInputAndOut(in, out);}
952cfbf656a09b96fc5e9d746102c7a197614297a1dc313bacf961ae8606f968
testWithExtraLogs
public void testWithExtraLogs() throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.CAPACITY, "10");    overrides.put(FileChannelConfiguration.TRANSACTION_CAPACITY, "10");    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> in = fillChannel(channel, "extralogs");    for (int i = 0; i < dataDirs.length; i++) {        File file = new File(dataDirs[i], Log.PREFIX + (1000 + i));        Assert.assertTrue(file.createNewFile());        Assert.assertTrue(file.length() == 0);        File metaDataFile = Serialization.getMetaDataFile(file);        File metaDataTempFile = Serialization.getMetaDataTempFile(metaDataFile);        Assert.assertTrue(metaDataTempFile.createNewFile());    }    channel.stop();    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> out = consumeChannel(channel);    compareInputAndOut(in, out);}
27371083f07a77ca5f8040f2190d270eb9efa44d8ab69e1571efa45f7dd3391b
testBackupUsedEnsureNoFullReplayWithoutCompression
public void testBackupUsedEnsureNoFullReplayWithoutCompression() throws Exception
{    testBackupUsedEnsureNoFullReplay(false);}
0215aa1ef1acce05d842d670f8696c93fdef6880af62605202df6a88218f5568
testBackupUsedEnsureNoFullReplayWithCompression
public void testBackupUsedEnsureNoFullReplayWithCompression() throws Exception
{    testBackupUsedEnsureNoFullReplay(true);}
703c7cfe100a196a1e2486b8190894d227e49d9ae7c1956020ab8c9b0ffa9b46
testBackupUsedEnsureNoFullReplay
private void testBackupUsedEnsureNoFullReplay(boolean compressedBackup) throws Exception
{    File dataDir = Files.createTempDir();    File tempBackup = Files.createTempDir();    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.DATA_DIRS, dataDir.getAbsolutePath());    overrides.put(FileChannelConfiguration.USE_DUAL_CHECKPOINTS, "true");    overrides.put(FileChannelConfiguration.COMPRESS_BACKUP_CHECKPOINT, String.valueOf(compressedBackup));    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> in = putEvents(channel, "restart", 10, 100);    Assert.assertEquals(100, in.size());    Thread.sleep(5000);    forceCheckpoint(channel);    Thread.sleep(5000);    in = putEvents(channel, "restart", 10, 100);    takeEvents(channel, 10, 100);    Assert.assertEquals(100, in.size());    for (File file : backupDir.listFiles()) {        if (file.getName().equals(Log.FILE_LOCK)) {            continue;        }        Files.copy(file, new File(tempBackup, file.getName()));    }    forceCheckpoint(channel);    channel.stop();    Serialization.deleteAllFiles(checkpointDir, Log.EXCLUDES);                    Serialization.deleteAllFiles(backupDir, Log.EXCLUDES);    for (File file : tempBackup.listFiles()) {        if (file.getName().equals(Log.FILE_LOCK)) {            continue;        }        Files.copy(file, new File(backupDir, file.getName()));    }    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    checkIfBackupUsed(true);    Assert.assertEquals(100, channel.getLog().getPutCount());    Assert.assertEquals(20, channel.getLog().getCommittedCount());    Assert.assertEquals(100, channel.getLog().getTakeCount());    Assert.assertEquals(0, channel.getLog().getRollbackCount());        Assert.assertEquals(220, channel.getLog().getReadCount());    consumeChannel(channel);    FileUtils.deleteQuietly(dataDir);    FileUtils.deleteQuietly(tempBackup);}
58cbef374c1562418a77f41158d4b34dddcc0160695952288350cbe80a64b789
testDataFilesRequiredByBackupNotDeleted
public void testDataFilesRequiredByBackupNotDeleted() throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.USE_DUAL_CHECKPOINTS, "true");    overrides.put(FileChannelConfiguration.MAX_FILE_SIZE, "1000");    channel = createFileChannel(overrides);    channel.start();    String prefix = "abcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyz";    Assert.assertTrue(channel.isOpen());    putEvents(channel, prefix, 10, 100);    Set<String> origFiles = Sets.newHashSet();    for (File dir : dataDirs) {        origFiles.addAll(Lists.newArrayList(dir.list()));    }    forceCheckpoint(channel);    takeEvents(channel, 10, 50);    long beforeSecondCheckpoint = System.currentTimeMillis();    forceCheckpoint(channel);    Set<String> newFiles = Sets.newHashSet();    int olderThanCheckpoint = 0;    int totalMetaFiles = 0;    for (File dir : dataDirs) {        File[] metadataFiles = dir.listFiles(new FilenameFilter() {            @Override            public boolean accept(File dir, String name) {                if (name.endsWith(".meta")) {                    return true;                }                return false;            }        });        totalMetaFiles = metadataFiles.length;        for (File metadataFile : metadataFiles) {            if (metadataFile.lastModified() < beforeSecondCheckpoint) {                olderThanCheckpoint++;            }        }        newFiles.addAll(Lists.newArrayList(dir.list()));    }    /*     * Files which are not required by the new checkpoint should not have been     * modified by the checkpoint.     */    Assert.assertTrue(olderThanCheckpoint > 0);    Assert.assertTrue(totalMetaFiles != olderThanCheckpoint);    /*     * All files needed by original checkpoint should still be there.     */    Assert.assertTrue(newFiles.containsAll(origFiles));    takeEvents(channel, 10, 50);    forceCheckpoint(channel);    newFiles = Sets.newHashSet();    for (File dir : dataDirs) {        newFiles.addAll(Lists.newArrayList(dir.list()));    }    Assert.assertTrue(!newFiles.containsAll(origFiles));}
ca62bfdc0472b2de6468644412d9ad6b432937742edcb5ca65b1f23b694b5853
accept
public boolean accept(File dir, String name)
{    if (name.endsWith(".meta")) {        return true;    }    return false;}
47b853d698b0aae6a2131ca504056b73c6307a3b775ae32f9596391caddab05d
testSlowBackup
public void testSlowBackup() throws Throwable
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.USE_DUAL_CHECKPOINTS, "true");    overrides.put(FileChannelConfiguration.MAX_FILE_SIZE, "1000");    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> in = putEvents(channel, "restart", 10, 100);    Assert.assertEquals(100, in.size());    slowdownBackup(channel);    forceCheckpoint(channel);    in = putEvents(channel, "restart", 10, 100);    takeEvents(channel, 10, 100);    Assert.assertEquals(100, in.size());    try {        forceCheckpoint(channel);    } catch (ReflectionError ex) {        throw ex.getCause();    } finally {        channel.stop();    }}
2b503ab652195aa64a1691cc8be1d6f9b6651133282f18ceccaa6ad1425e9b9b
testCompressBackup
public void testCompressBackup() throws Throwable
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.USE_DUAL_CHECKPOINTS, "true");    overrides.put(FileChannelConfiguration.MAX_FILE_SIZE, "1000");    overrides.put(FileChannelConfiguration.COMPRESS_BACKUP_CHECKPOINT, "true");    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    putEvents(channel, "restart", 10, 100);    forceCheckpoint(channel);        Thread.sleep(2000);    Assert.assertTrue(compressedBackupCheckpoint.exists());    Serialization.decompressFile(compressedBackupCheckpoint, uncompressedBackupCheckpoint);    File checkpoint = new File(checkpointDir, "checkpoint");    Assert.assertTrue(FileUtils.contentEquals(checkpoint, uncompressedBackupCheckpoint));    channel.stop();}
051b53f302109157d6c47de9d10332c6112033d293daea6320924160306bd25e
testToggleCheckpointCompressionFromTrueToFalse
public void testToggleCheckpointCompressionFromTrueToFalse() throws Exception
{    restartToggleCompression(true);}
efe4b29fbcedb6dc495f3dd34031c4b635631b75fb37c088b408187cb3f39a29
testToggleCheckpointCompressionFromFalseToTrue
public void testToggleCheckpointCompressionFromFalseToTrue() throws Exception
{    restartToggleCompression(false);}
64dc1a62ba8d3f580d88e24c8a2d50a8e3def183fe4d90da1b5079774926c4be
restartToggleCompression
public void restartToggleCompression(boolean originalCheckpointCompressed) throws Exception
{    Map<String, String> overrides = Maps.newHashMap();    overrides.put(FileChannelConfiguration.USE_DUAL_CHECKPOINTS, "true");    overrides.put(FileChannelConfiguration.MAX_FILE_SIZE, "1000");    overrides.put(FileChannelConfiguration.TRANSACTION_CAPACITY, "1000");    overrides.put(FileChannelConfiguration.CAPACITY, "1000");    overrides.put(FileChannelConfiguration.COMPRESS_BACKUP_CHECKPOINT, String.valueOf(originalCheckpointCompressed));    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> in = fillChannel(channel, "restart");    forceCheckpoint(channel);    Thread.sleep(2000);    Assert.assertEquals(compressedBackupCheckpoint.exists(), originalCheckpointCompressed);    Assert.assertEquals(uncompressedBackupCheckpoint.exists(), !originalCheckpointCompressed);    channel.stop();    File checkpoint = new File(checkpointDir, "checkpoint");    Assert.assertTrue(checkpoint.delete());    File checkpointMetaData = Serialization.getMetaDataFile(checkpoint);    Assert.assertTrue(checkpointMetaData.delete());    overrides.put(FileChannelConfiguration.COMPRESS_BACKUP_CHECKPOINT, String.valueOf(!originalCheckpointCompressed));    channel = createFileChannel(overrides);    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> out = consumeChannel(channel);    compareInputAndOut(in, out);    forceCheckpoint(channel);    Thread.sleep(2000);    Assert.assertEquals(compressedBackupCheckpoint.exists(), !originalCheckpointCompressed);    Assert.assertEquals(uncompressedBackupCheckpoint.exists(), originalCheckpointCompressed);}
79aaa71856e3da80ab39ba67c973af1fed23e8bef325ca9c03ea5fe6077e1850
slowdownBackup
private static void slowdownBackup(FileChannel channel)
{    Log log = field("log").ofType(Log.class).in(channel).get();    FlumeEventQueue queue = field("queue").ofType(FlumeEventQueue.class).in(log).get();    EventQueueBackingStore backingStore = field("backingStore").ofType(EventQueueBackingStore.class).in(queue).get();    field("slowdownBackup").ofType(Boolean.class).in(backingStore).set(true);}
27681e68ec2a1eb903f955680ebe003ceb3707295c8aad884b692d378c6e37cf
setup
public void setup() throws Exception
{    super.setup();}
ec8b6259c87a96a7e78ab8ec13a826f2caf0d2a1c593d4aec011e181f3e17bbf
teardown
public void teardown()
{    super.teardown();}
97b8d7ef4d46236da3ecc6eab65d1e4d4b87ab82ae65b916e66d8b79c412493a
testRollbackAfterNoPutTake
public void testRollbackAfterNoPutTake() throws Exception
{    channel.start();    Assert.assertTrue(channel.isOpen());    Transaction transaction;    transaction = channel.getTransaction();    transaction.begin();    transaction.rollback();    transaction.close();        channel.stop();    channel = createFileChannel();    channel.start();    Assert.assertTrue(channel.isOpen());    transaction = channel.getTransaction();    transaction.begin();    Assert.assertNull(channel.take());    transaction.commit();    transaction.close();}
da10a308438fd3d40c7bf00f2c92fdb0767f568aeb6d025156a6f5bbb91773c0
testRollbackSimulatedCrash
public void testRollbackSimulatedCrash() throws Exception
{    channel.start();    Assert.assertTrue(channel.isOpen());    int numEvents = 50;    Set<String> in = putEvents(channel, "rollback", 1, numEvents);    Transaction transaction;        transaction = channel.getTransaction();    transaction.begin();    channel.put(EventBuilder.withBody("rolled back".getBytes(Charsets.UTF_8)));    transaction.rollback();    transaction.close();        channel.stop();    channel = createFileChannel();    channel.start();    Assert.assertTrue(channel.isOpen());        Set<String> out = takeEvents(channel, 1, numEvents);    compareInputAndOut(in, out);}
08675190aed54a759945f29b3fdcdb18d1e9db61e0a82cabce6586c3079c900b
testRollbackSimulatedCrashWithSink
public void testRollbackSimulatedCrashWithSink() throws Exception
{    channel.start();    Assert.assertTrue(channel.isOpen());    int numEvents = 100;    LoggerSink sink = new LoggerSink();    sink.setChannel(channel);        CountingSinkRunner runner = new CountingSinkRunner(sink, numEvents - 1);    runner.start();    putEvents(channel, "rollback", 10, numEvents);    Transaction transaction;        transaction = channel.getTransaction();    transaction.begin();    byte[] bytes = "rolled back".getBytes(Charsets.UTF_8);    channel.put(EventBuilder.withBody(bytes));    transaction.rollback();    transaction.close();    while (runner.isAlive()) {        Thread.sleep(10L);    }    Assert.assertEquals(numEvents - 1, runner.getCount());    for (Exception ex : runner.getErrors()) {        LOG.warn("Sink had error", ex);    }    Assert.assertEquals(Collections.EMPTY_LIST, runner.getErrors());        channel.stop();    channel = createFileChannel();    channel.start();    Assert.assertTrue(channel.isOpen());    Set<String> out = takeEvents(channel, 1, 1);    Assert.assertEquals(1, out.size());    String s = out.iterator().next();    Assert.assertTrue(s, s.startsWith("rollback-90-9"));}
0b309a742a08b61f932d92aa0ff7edc89c85d011d923a9d9fc6e79b18b165775
testBasics
public void testBasics()
{    Map<String, String> headers = Maps.newHashMap();    headers.put("key", "value");    byte[] body = "flume".getBytes(Charsets.UTF_8);    FlumeEvent event = new FlumeEvent(headers, body);    Assert.assertEquals(headers, event.getHeaders());    Assert.assertTrue(Arrays.equals(body, event.getBody()));}
1192794e64aea8c7b542cde309f1c91028423a3d7da09e14ee39125a501edbbd
testSerialization
public void testSerialization() throws IOException
{    Map<String, String> headers = Maps.newHashMap();    headers.put("key", "value");    byte[] body = "flume".getBytes(Charsets.UTF_8);    FlumeEvent in = new FlumeEvent(headers, body);    FlumeEvent out = FlumeEvent.from(TestUtils.toDataInput(in));    Assert.assertEquals(headers, out.getHeaders());    Assert.assertTrue(Arrays.equals(body, out.getBody()));    in.setHeaders(null);    in.setBody(null);    out = FlumeEvent.from(TestUtils.toDataInput(in));    Assert.assertEquals(Maps.newHashMap(), out.getHeaders());    Assert.assertNull(out.getBody());}
e624146b2355a9d983d791e04515d910e99c229ec3db8beef146d6d13cb28a07
testGetter
public void testGetter()
{    FlumeEventPointer pointer = new FlumeEventPointer(1, 1);    Assert.assertEquals(1, pointer.getFileID());    Assert.assertEquals(1, pointer.getOffset());}
d743635326590d02d09b08382668302390b29ae4396743be077aaaa0d7b5353f
testEquals
public void testEquals()
{    FlumeEventPointer pointerA = new FlumeEventPointer(1, 1);    FlumeEventPointer pointerB = new FlumeEventPointer(1, 1);    Assert.assertEquals(pointerA, pointerB);    Assert.assertEquals(pointerB, pointerA);    pointerA = new FlumeEventPointer(1, 1);    pointerB = new FlumeEventPointer(2, 2);    Assert.assertFalse(pointerA.equals(pointerB));    Assert.assertFalse(pointerB.equals(pointerA));}
ad6f12d30164517b5d8852c2595ff6dcc9e828122d198b1d26eaebfe2762e22e
testHashCode
public void testHashCode()
{    FlumeEventPointer pointerA = new FlumeEventPointer(1, 1);    FlumeEventPointer pointerB = new FlumeEventPointer(1, 1);    Assert.assertEquals(pointerA.hashCode(), pointerB.hashCode());    pointerA = new FlumeEventPointer(1, 1);    pointerB = new FlumeEventPointer(2, 2);    Assert.assertFalse(pointerA.hashCode() == pointerB.hashCode());}
e90efb2131391eeb41c5c09897a7e7eaa4d8b5f5a3c184ea97a0153fb60c62e6
testPack
public void testPack()
{    FlumeEventPointer pointerA = new FlumeEventPointer(1, 1);    FlumeEventPointer pointerB = new FlumeEventPointer(1, 2);    Assert.assertEquals(4294967297L, pointerA.toLong());    Assert.assertEquals(4294967298L, pointerB.toLong());    Assert.assertEquals(pointerA, FlumeEventPointer.fromLong(pointerA.toLong()));    Assert.assertEquals(pointerB, FlumeEventPointer.fromLong(pointerB.toLong()));}
6db084419c63cb1d86eb1d8377937728dff12a26896d86fb08dc2fd538cca4df
getCheckpoint
 File getCheckpoint()
{    return checkpoint;}
5b0b08fa899e2c620e2d48075cab8bf1a1ea075d2f09036138933cbc02aefb25
getInflightPuts
 File getInflightPuts()
{    return inflightPuts;}
4a2af842a56750dc8a6c19b3bdb5a1e1b7ec7c6d4580aa94f42329fec88cd71f
getInflightTakes
 File getInflightTakes()
{    return inflightTakes;}
e0ff60bba62a4b46f727ffc97b94d26b89e3c2be97f1359272477ded80e3cbcd
getQueueSetDir
 File getQueueSetDir()
{    return queueSetDir;}
05b1ecfbc60ae35c05dc6970331eda8c5bd0ac67a22f73ad21de808ec375f7cd
delete
 void delete()
{    FileUtils.deleteQuietly(baseDir);}
99368237115bcd481a1248dee30803c780b17e2ee128f406ebf46bc0a5c175b3
data
public static Collection<Object[]> data() throws Exception
{    Object[][] data = new Object[][] { { new EventQueueBackingStoreSupplier() {        @Override        public EventQueueBackingStore get() throws Exception {            Assert.assertTrue(baseDir.isDirectory() || baseDir.mkdirs());            return new EventQueueBackingStoreFileV2(getCheckpoint(), 1000, "test", new FileChannelCounter("test"));        }    } }, { new EventQueueBackingStoreSupplier() {        @Override        public EventQueueBackingStore get() throws Exception {            Assert.assertTrue(baseDir.isDirectory() || baseDir.mkdirs());            return new EventQueueBackingStoreFileV3(getCheckpoint(), 1000, "test", new FileChannelCounter("test"));        }    } } };    return Arrays.asList(data);}
b6905bedb958ca84f1351978f812e998953a5367927994b7a5b1797ad2be0cfa
get
public EventQueueBackingStore get() throws Exception
{    Assert.assertTrue(baseDir.isDirectory() || baseDir.mkdirs());    return new EventQueueBackingStoreFileV2(getCheckpoint(), 1000, "test", new FileChannelCounter("test"));}
b6905bedb958ca84f1351978f812e998953a5367927994b7a5b1797ad2be0cfa
get
public EventQueueBackingStore get() throws Exception
{    Assert.assertTrue(baseDir.isDirectory() || baseDir.mkdirs());    return new EventQueueBackingStoreFileV3(getCheckpoint(), 1000, "test", new FileChannelCounter("test"));}
27681e68ec2a1eb903f955680ebe003ceb3707295c8aad884b692d378c6e37cf
setup
public void setup() throws Exception
{    backingStore = backingStoreSupplier.get();}
9779bf7fab76efc73510dce8feeee2e5d4343f6c015cf6fe29938f6ac009ad3f
cleanup
public void cleanup() throws IOException
{    if (backingStore != null) {        backingStore.close();    }    backingStoreSupplier.delete();}
de7031ae9f15d2c1d1febcf2fbb9ce3082d4a40395c68e3b2f5b055c1b136d37
testCapacity
public void testCapacity() throws Exception
{    backingStore.close();    File checkpoint = backingStoreSupplier.getCheckpoint();    Assert.assertTrue(checkpoint.delete());    backingStore = new EventQueueBackingStoreFileV2(checkpoint, 1, "test", new FileChannelCounter("test"));    queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());    Assert.assertTrue(queue.addTail(pointer1));    Assert.assertFalse(queue.addTail(pointer2));}
977adf27a7f27f0e59566ed051f8c5a570fcde5959d0704ff2ff8aa605615bdd
testInvalidCapacityZero
public void testInvalidCapacityZero() throws Exception
{    backingStore.close();    File checkpoint = backingStoreSupplier.getCheckpoint();    Assert.assertTrue(checkpoint.delete());    backingStore = new EventQueueBackingStoreFileV2(checkpoint, 0, "test", new FileChannelCounter("test"));    queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());}
8d5eee67cb2202d55e41ce0b0d78606cf2ae186d029cd3a72014a4b8756a20c1
testInvalidCapacityNegative
public void testInvalidCapacityNegative() throws Exception
{    backingStore.close();    File checkpoint = backingStoreSupplier.getCheckpoint();    Assert.assertTrue(checkpoint.delete());    backingStore = new EventQueueBackingStoreFileV2(checkpoint, -1, "test", new FileChannelCounter("test"));    queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());}
2cd867cf48300c510943f304afd5ab64210f567999cf94b31fee5f0c3e62595b
testQueueIsEmptyAfterCreation
public void testQueueIsEmptyAfterCreation() throws Exception
{    queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());    Assert.assertNull(queue.removeHead(0L));}
d148761902d362d7760d0254af7eedef2b80f4c2410cd8aca9b2b6ef4cf852f3
addTail1
public void addTail1() throws Exception
{    queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());    Assert.assertTrue(queue.addTail(pointer1));    Assert.assertEquals(pointer1, queue.removeHead(0));    Assert.assertEquals(Sets.newHashSet(), queue.getFileIDs());}
68680987977837d3e5f6728dd25ffcbc239aa1996bfe3dcfd9f70094b61a9996
addTail2
public void addTail2() throws Exception
{    queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());    Assert.assertTrue(queue.addTail(pointer1));    Assert.assertTrue(queue.addTail(pointer2));    Assert.assertEquals(Sets.newHashSet(1, 2), queue.getFileIDs());    Assert.assertEquals(pointer1, queue.removeHead(0));    Assert.assertEquals(Sets.newHashSet(2), queue.getFileIDs());}
c43b167041cd73bf1626d63f093f0d54555082403b9b2e0e67bb1aebc20be192
addTailLarge
public void addTailLarge() throws Exception
{    queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());    int size = 500;    Set<Integer> fileIDs = Sets.newHashSet();    for (int i = 1; i <= size; i++) {        Assert.assertTrue(queue.addTail(new FlumeEventPointer(i, i)));        fileIDs.add(i);        Assert.assertEquals(fileIDs, queue.getFileIDs());    }    for (int i = 1; i <= size; i++) {        Assert.assertEquals(new FlumeEventPointer(i, i), queue.removeHead(0));        fileIDs.remove(i);        Assert.assertEquals(fileIDs, queue.getFileIDs());    }    Assert.assertEquals(Sets.newHashSet(), queue.getFileIDs());}
c5af27d5e127299fa904e7dbaa57e66c7d9be1d7293942f2a470f7b096ff7f12
addHead1
public void addHead1() throws Exception
{    queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());    Assert.assertTrue(queue.addHead(pointer1));    Assert.assertEquals(Sets.newHashSet(1), queue.getFileIDs());    Assert.assertEquals(pointer1, queue.removeHead(0));    Assert.assertEquals(Sets.newHashSet(), queue.getFileIDs());}
a1741bd19b8575b897904557c7dfda6bc299b633346f284beb4998b9ce57a813
addHead2
public void addHead2() throws Exception
{    queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());    queue.replayComplete();    Assert.assertTrue(queue.addHead(pointer1));    Assert.assertTrue(queue.addHead(pointer2));    Assert.assertEquals(Sets.newHashSet(1, 2), queue.getFileIDs());    Assert.assertEquals(pointer2, queue.removeHead(0));    Assert.assertEquals(Sets.newHashSet(1), queue.getFileIDs());}
4e09dd7f9702ba28845730178fae88b3e233f4eb60cd2fa8c4675fe98fb44039
addHeadLarge
public void addHeadLarge() throws Exception
{    queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());    queue.replayComplete();    int size = 500;    Set<Integer> fileIDs = Sets.newHashSet();    for (int i = 1; i <= size; i++) {        Assert.assertTrue(queue.addHead(new FlumeEventPointer(i, i)));        fileIDs.add(i);        Assert.assertEquals(fileIDs, queue.getFileIDs());    }    for (int i = size; i > 0; i--) {        Assert.assertEquals(new FlumeEventPointer(i, i), queue.removeHead(0));        fileIDs.remove(i);        Assert.assertEquals(fileIDs, queue.getFileIDs());    }    Assert.assertEquals(Sets.newHashSet(), queue.getFileIDs());}
73d0d4a5198ad19d3aa209192aa58c4637c758cb9807266da15de404aa1bb7f1
addTailRemove1
public void addTailRemove1() throws Exception
{    queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());    Assert.assertTrue(queue.addTail(pointer1));    Assert.assertEquals(Sets.newHashSet(1), queue.getFileIDs());    Assert.assertTrue(queue.remove(pointer1));    queue.replayComplete();    Assert.assertEquals(Sets.newHashSet(), queue.getFileIDs());    Assert.assertNull(queue.removeHead(0));    Assert.assertEquals(Sets.newHashSet(), queue.getFileIDs());}
d429a97806e98d4db40a448b4d55374a2f880bdb9bd5ca0fbbc339a637706ff9
addTailRemove2
public void addTailRemove2() throws Exception
{    queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());    Assert.assertTrue(queue.addTail(pointer1));    Assert.assertTrue(queue.addTail(pointer2));    Assert.assertTrue(queue.remove(pointer1));    queue.replayComplete();    Assert.assertEquals(pointer2, queue.removeHead(0));}
10e810d909ccf0bcb1bdae42b533e4ba34383fd793c450d5fe387f4fa8f9386d
addHeadRemove1
public void addHeadRemove1() throws Exception
{    queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());    queue.addHead(pointer1);    Assert.assertTrue(queue.remove(pointer1));    Assert.assertNull(queue.removeHead(0));}
7f07e6bcaeab05cb69c39b1462d5929f1b232bef0f0b9194805a1c0d76e18ed1
addHeadRemove2
public void addHeadRemove2() throws Exception
{    queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());    Assert.assertTrue(queue.addHead(pointer1));    Assert.assertTrue(queue.addHead(pointer2));    Assert.assertTrue(queue.remove(pointer1));    queue.replayComplete();    Assert.assertEquals(pointer2, queue.removeHead(0));}
f0c35bfad7ed9e041d17e0f7e351a0d14c4dcf99599f35275667600c4eabe54f
testUnknownPointerDoesNotCauseSearch
public void testUnknownPointerDoesNotCauseSearch() throws Exception
{    queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());    Assert.assertTrue(queue.addHead(pointer1));    Assert.assertTrue(queue.addHead(pointer2));        Assert.assertFalse(queue.remove(pointer3));    Assert.assertTrue(queue.remove(pointer1));    Assert.assertTrue(queue.remove(pointer2));    queue.replayComplete();    Assert.assertEquals(2, queue.getSearchCount());}
ee1e4c1bc616c7ecdc2c295e96576f637f0e46b750a06bd7bae2853ab689f60f
testRemoveAfterReplayComplete
public void testRemoveAfterReplayComplete() throws Exception
{    queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());    queue.replayComplete();    queue.remove(pointer1);}
e41e145273775df393d11d8bb35701ec787922eac619dc78e1d0b087d3b2ea1f
testWrappingCorrectly
public void testWrappingCorrectly() throws Exception
{    queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());    int size = Integer.MAX_VALUE;    for (int i = 1; i <= size; i++) {        if (!queue.addHead(new FlumeEventPointer(i, i))) {            break;        }    }    for (int i = queue.getSize() / 2; i > 0; i--) {        Assert.assertNotNull(queue.removeHead(0));    }        for (int i = 1; i <= size; i++) {        if (!queue.addHead(new FlumeEventPointer(i, i))) {            break;        }    }}
055d9ee98cd4626a1eab79158d6be2a6780bde673d4ba5f52751f94701976bb7
testInflightPuts
public void testInflightPuts() throws Exception
{    queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());    long txnID1 = new Random().nextInt(Integer.MAX_VALUE - 1);    long txnID2 = txnID1 + 1;    queue.addWithoutCommit(new FlumeEventPointer(1, 1), txnID1);    queue.addWithoutCommit(new FlumeEventPointer(2, 1), txnID1);    queue.addWithoutCommit(new FlumeEventPointer(2, 2), txnID2);    queue.checkpoint(true);    TimeUnit.SECONDS.sleep(3L);    queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());    SetMultimap<Long, Long> deserializedMap = queue.deserializeInflightPuts();    Assert.assertTrue(deserializedMap.get(txnID1).contains(new FlumeEventPointer(1, 1).toLong()));    Assert.assertTrue(deserializedMap.get(txnID1).contains(new FlumeEventPointer(2, 1).toLong()));    Assert.assertTrue(deserializedMap.get(txnID2).contains(new FlumeEventPointer(2, 2).toLong()));}
e1c9f3298b2efb949d7bb1a20887e36cd04acdfcf108fa951bdc56746acd4d2e
testInflightTakes
public void testInflightTakes() throws Exception
{    queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());    long txnID1 = new Random().nextInt(Integer.MAX_VALUE - 1);    long txnID2 = txnID1 + 1;    queue.addTail(new FlumeEventPointer(1, 1));    queue.addTail(new FlumeEventPointer(2, 1));    queue.addTail(new FlumeEventPointer(2, 2));    queue.removeHead(txnID1);    queue.removeHead(txnID2);    queue.removeHead(txnID2);    queue.checkpoint(true);    TimeUnit.SECONDS.sleep(3L);    queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());    SetMultimap<Long, Long> deserializedMap = queue.deserializeInflightTakes();    Assert.assertTrue(deserializedMap.get(txnID1).contains(new FlumeEventPointer(1, 1).toLong()));    Assert.assertTrue(deserializedMap.get(txnID2).contains(new FlumeEventPointer(2, 1).toLong()));    Assert.assertTrue(deserializedMap.get(txnID2).contains(new FlumeEventPointer(2, 2).toLong()));}
4c4988866cee97879b37c4c1b2ef906989764f8b7694c605da81e5e22112bd33
testCorruptInflightPuts
public void testCorruptInflightPuts() throws Exception
{    RandomAccessFile inflight = null;    try {        queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());        long txnID1 = new Random().nextInt(Integer.MAX_VALUE - 1);        long txnID2 = txnID1 + 1;        queue.addWithoutCommit(new FlumeEventPointer(1, 1), txnID1);        queue.addWithoutCommit(new FlumeEventPointer(2, 1), txnID1);        queue.addWithoutCommit(new FlumeEventPointer(2, 2), txnID2);        queue.checkpoint(true);        TimeUnit.SECONDS.sleep(3L);        inflight = new RandomAccessFile(backingStoreSupplier.getInflightPuts(), "rw");        inflight.seek(0);        inflight.writeInt(new Random().nextInt());        queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());        SetMultimap<Long, Long> deserializedMap = queue.deserializeInflightPuts();        Assert.assertTrue(deserializedMap.get(txnID1).contains(new FlumeEventPointer(1, 1).toLong()));        Assert.assertTrue(deserializedMap.get(txnID1).contains(new FlumeEventPointer(2, 1).toLong()));        Assert.assertTrue(deserializedMap.get(txnID2).contains(new FlumeEventPointer(2, 2).toLong()));    } finally {        inflight.close();    }}
849d44a333ec2001ddf66fbf0a6e8febb4062d083bef365db04f91c9f7037e98
testCorruptInflightTakes
public void testCorruptInflightTakes() throws Exception
{    RandomAccessFile inflight = null;    try {        queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());        long txnID1 = new Random().nextInt(Integer.MAX_VALUE - 1);        long txnID2 = txnID1 + 1;        queue.addWithoutCommit(new FlumeEventPointer(1, 1), txnID1);        queue.addWithoutCommit(new FlumeEventPointer(2, 1), txnID1);        queue.addWithoutCommit(new FlumeEventPointer(2, 2), txnID2);        queue.checkpoint(true);        TimeUnit.SECONDS.sleep(3L);        inflight = new RandomAccessFile(backingStoreSupplier.getInflightTakes(), "rw");        inflight.seek(0);        inflight.writeInt(new Random().nextInt());        queue = new FlumeEventQueue(backingStore, backingStoreSupplier.getInflightTakes(), backingStoreSupplier.getInflightPuts(), backingStoreSupplier.getQueueSetDir());        SetMultimap<Long, Long> deserializedMap = queue.deserializeInflightTakes();        Assert.assertTrue(deserializedMap.get(txnID1).contains(new FlumeEventPointer(1, 1).toLong()));        Assert.assertTrue(deserializedMap.get(txnID1).contains(new FlumeEventPointer(2, 1).toLong()));        Assert.assertTrue(deserializedMap.get(txnID2).contains(new FlumeEventPointer(2, 2).toLong()));    } finally {        inflight.close();    }}
5ff0b8f7d2b080bcc6214fa5f91be74727145ea81cacb63a99c8d0f3106c089f
setup
public void setup()
{    baseDir = Files.createTempDir();    checkpointDir = new File(baseDir, "chkpt");    Assert.assertTrue(checkpointDir.mkdirs() || checkpointDir.isDirectory());    dataDirs = new File[3];    dataDir = "";    for (int i = 0; i < dataDirs.length; i++) {        dataDirs[i] = new File(baseDir, "data" + (i + 1));        Assert.assertTrue(dataDirs[i].mkdirs() || dataDirs[i].isDirectory());        dataDir += dataDirs[i].getAbsolutePath() + ",";    }    dataDir = dataDir.substring(0, dataDir.length() - 1);}
ec8b6259c87a96a7e78ab8ec13a826f2caf0d2a1c593d4aec011e181f3e17bbf
teardown
public void teardown()
{    if (channel != null && channel.isOpen()) {        channel.stop();    }    FileUtils.deleteQuietly(baseDir);}
531229985b064f38225e95e8ad5df62ee0b9493443dcbd95ef29a7022dbfd6b8
testIntegration
public void testIntegration() throws IOException, InterruptedException
{            Context context = new Context();    context.put(FileChannelConfiguration.CHECKPOINT_DIR, checkpointDir.getAbsolutePath());    context.put(FileChannelConfiguration.DATA_DIRS, dataDir);    context.put(FileChannelConfiguration.CAPACITY, String.valueOf(10000));        context.put(FileChannelConfiguration.CHECKPOINT_INTERVAL, "5000");    context.put(FileChannelConfiguration.MAX_FILE_SIZE, String.valueOf(1024 * 1024 * 5));        channel = new FileChannel();    channel.setName("FileChannel-" + UUID.randomUUID());    Configurables.configure(channel, context);    channel.start();    Assert.assertTrue(channel.isOpen());    SequenceGeneratorSource source = new SequenceGeneratorSource();    CountingSourceRunner sourceRunner = new CountingSourceRunner(source, channel);    source.configure(context);    source.start();    NullSink sink = new NullSink();    sink.setChannel(channel);    CountingSinkRunner sinkRunner = new CountingSinkRunner(sink);    sinkRunner.start();    sourceRunner.start();    TimeUnit.SECONDS.sleep(30);        sourceRunner.shutdown();    while (sourceRunner.isAlive()) {        Thread.sleep(10L);    }        while (channel.getDepth() > 0) {        Thread.sleep(10L);    }        sinkRunner.shutdown();        TimeUnit.SECONDS.sleep(5);    List<File> logs = Lists.newArrayList();    for (int i = 0; i < dataDirs.length; i++) {        logs.addAll(LogUtils.getLogs(dataDirs[i]));    }    LOG.info("Total Number of Logs = " + logs.size());    for (File logFile : logs) {        LOG.info("LogFile = " + logFile);    }    LOG.info("Source processed " + sinkRunner.getCount());    LOG.info("Sink processed " + sourceRunner.getCount());    for (Exception ex : sourceRunner.getErrors()) {        LOG.warn("Source had error", ex);    }    for (Exception ex : sinkRunner.getErrors()) {        LOG.warn("Sink had error", ex);    }    Assert.assertEquals(sinkRunner.getCount(), sinkRunner.getCount());    Assert.assertEquals(Collections.EMPTY_LIST, sinkRunner.getErrors());    Assert.assertEquals(Collections.EMPTY_LIST, sourceRunner.getErrors());}
935d9dc08fe11323dcaaf5c6f96db76bb87fd0fc4b9fcc33e9eca9f620f5620c
setup
public void setup() throws IOException
{    transactionID = 0;    checkpointDir = Files.createTempDir();    FileUtils.forceDeleteOnExit(checkpointDir);    Assert.assertTrue(checkpointDir.isDirectory());    dataDirs = new File[3];    for (int i = 0; i < dataDirs.length; i++) {        dataDirs[i] = Files.createTempDir();        Assert.assertTrue(dataDirs[i].isDirectory());    }    log = new Log.Builder().setCheckpointInterval(1L).setMaxFileSize(MAX_FILE_SIZE).setQueueSize(CAPACITY).setCheckpointDir(checkpointDir).setLogDirs(dataDirs).setCheckpointOnClose(false).setChannelName("testlog").setChannelCounter(new FileChannelCounter("testlog")).build();    log.replay();}
93ddb9271c07486589b690e583e7371785fa8059cfd29c9df68b9fd811855cc1
cleanup
public void cleanup() throws Exception
{    if (log != null) {        log.close();    }    FileUtils.deleteQuietly(checkpointDir);    for (int i = 0; i < dataDirs.length; i++) {        FileUtils.deleteQuietly(dataDirs[i]);    }}
ba90da66113730de66b15509ea337232078f5124c0040f7e79c2e9d1754860f7
testPutGet
public void testPutGet() throws IOException, InterruptedException, NoopRecordException, CorruptEventException
{    FlumeEvent eventIn = TestUtils.newPersistableEvent();    long transactionID = ++this.transactionID;    FlumeEventPointer eventPointer = log.put(transactionID, eventIn);        log.commitPut(transactionID);        FlumeEvent eventOut = log.get(eventPointer);    Assert.assertNotNull(eventOut);    Assert.assertEquals(eventIn.getHeaders(), eventOut.getHeaders());    Assert.assertArrayEquals(eventIn.getBody(), eventOut.getBody());}
dbf6b411d20fe19945c516383e4570426683635815c8f7b1c52b9b6eb79de112
testRoll
public void testRoll() throws IOException, InterruptedException, NoopRecordException, CorruptEventException
{    log.shutdownWorker();    Thread.sleep(1000);    for (int i = 0; i < 1000; i++) {        FlumeEvent eventIn = TestUtils.newPersistableEvent();        long transactionID = ++this.transactionID;        FlumeEventPointer eventPointer = log.put(transactionID, eventIn);                FlumeEvent eventOut = log.get(eventPointer);        Assert.assertNotNull(eventOut);        Assert.assertEquals(eventIn.getHeaders(), eventOut.getHeaders());        Assert.assertArrayEquals(eventIn.getBody(), eventOut.getBody());    }    int logCount = 0;    for (File dataDir : dataDirs) {        for (File logFile : dataDir.listFiles()) {            if (logFile.getName().startsWith("log-")) {                logCount++;            }        }    }        Assert.assertEquals(186, logCount);}
fd9bb0fdde356e3e8ee40ddda6d67b02cd97a5063d2aa7667244b53f6b13d150
testPutCommit
public void testPutCommit() throws IOException, InterruptedException, NoopRecordException, CorruptEventException
{    FlumeEvent eventIn = TestUtils.newPersistableEvent();    long transactionID = ++this.transactionID;    FlumeEventPointer eventPointerIn = log.put(transactionID, eventIn);    log.commitPut(transactionID);    log.close();    log = new Log.Builder().setCheckpointInterval(Long.MAX_VALUE).setMaxFileSize(FileChannelConfiguration.DEFAULT_MAX_FILE_SIZE).setQueueSize(CAPACITY).setCheckpointDir(checkpointDir).setLogDirs(dataDirs).setChannelName("testlog").setChannelCounter(new FileChannelCounter("testlog")).build();    log.replay();    takeAndVerify(eventPointerIn, eventIn);}
90db2def02cdaf35327fcfe45489a37e2ee5254d3337212af74b78ac60e829bc
testPutRollback
public void testPutRollback() throws IOException, InterruptedException
{    FlumeEvent eventIn = TestUtils.newPersistableEvent();    long transactionID = ++this.transactionID;    log.put(transactionID, eventIn);        log.rollback(transactionID);    log.close();    log = new Log.Builder().setCheckpointInterval(Long.MAX_VALUE).setMaxFileSize(FileChannelConfiguration.DEFAULT_MAX_FILE_SIZE).setQueueSize(CAPACITY).setCheckpointDir(checkpointDir).setLogDirs(dataDirs).setChannelName("testlog").setChannelCounter(new FileChannelCounter("testlog")).build();    log.replay();    FlumeEventQueue queue = log.getFlumeEventQueue();    Assert.assertNull(queue.removeHead(transactionID));}
614b0e7b18ecbabb525bb4ef1403593d80903e568d3b6f6deefda6b210355383
testMinimumRequiredSpaceTooSmallOnStartup
public void testMinimumRequiredSpaceTooSmallOnStartup() throws IOException, InterruptedException
{    log.close();    log = new Log.Builder().setCheckpointInterval(Long.MAX_VALUE).setMaxFileSize(FileChannelConfiguration.DEFAULT_MAX_FILE_SIZE).setQueueSize(CAPACITY).setCheckpointDir(checkpointDir).setLogDirs(dataDirs).setChannelName("testlog").setMinimumRequiredSpace(Long.MAX_VALUE).setChannelCounter(new FileChannelCounter("testlog")).build();    try {        log.replay();        Assert.fail();    } catch (IOException e) {        Assert.assertTrue(e.getMessage(), e.getMessage().startsWith("Usable space exhausted"));    }}
78043f5bb543888f05962f3570f1c8ef63330e32a6e763aee136a438807e3264
testMinimumRequiredSpaceTooSmallForPut
public void testMinimumRequiredSpaceTooSmallForPut() throws IOException, InterruptedException
{    try {        doTestMinimumRequiredSpaceTooSmallForPut();    } catch (IOException e) {        LOGGER.info("Error during test, retrying", e);        doTestMinimumRequiredSpaceTooSmallForPut();    } catch (AssertionError e) {        LOGGER.info("Test failed, let's be sure it failed for good reason", e);        doTestMinimumRequiredSpaceTooSmallForPut();    }}
ba78f179ffc4cd5618eba3211dd8b728043340a69d5e853629ab03fe9db40409
doTestMinimumRequiredSpaceTooSmallForPut
public void doTestMinimumRequiredSpaceTooSmallForPut() throws IOException, InterruptedException
{    long minimumRequiredSpace = checkpointDir.getUsableSpace() - (10L * 1024L * 1024L);    log.close();    log = new Log.Builder().setCheckpointInterval(Long.MAX_VALUE).setMaxFileSize(FileChannelConfiguration.DEFAULT_MAX_FILE_SIZE).setQueueSize(CAPACITY).setCheckpointDir(checkpointDir).setLogDirs(dataDirs).setChannelName("testlog").setMinimumRequiredSpace(minimumRequiredSpace).setUsableSpaceRefreshInterval(1L).setChannelCounter(new FileChannelCounter("testlog")).build();    log.replay();    File filler = new File(checkpointDir, "filler");    byte[] buffer = new byte[64 * 1024];    FileOutputStream out = new FileOutputStream(filler);    while (checkpointDir.getUsableSpace() > minimumRequiredSpace) {        out.write(buffer);    }    out.close();    try {        FlumeEvent eventIn = TestUtils.newPersistableEvent();        long transactionID = ++this.transactionID;        log.put(transactionID, eventIn);        Assert.fail();    } catch (IOException e) {        Assert.assertTrue(e.getMessage(), e.getMessage().startsWith("Usable space exhausted"));    }}
0fa8bc888061723343f813983db4abdd06f2437cedae3ab39797333df568099d
testPutTakeCommit
public void testPutTakeCommit() throws IOException, InterruptedException
{    FlumeEvent eventIn = TestUtils.newPersistableEvent();    long putTransactionID = ++transactionID;    FlumeEventPointer eventPointer = log.put(putTransactionID, eventIn);    log.commitPut(putTransactionID);    long takeTransactionID = ++transactionID;    log.take(takeTransactionID, eventPointer);    log.commitTake(takeTransactionID);    log.close();    new Log.Builder().setCheckpointInterval(Long.MAX_VALUE).setMaxFileSize(FileChannelConfiguration.DEFAULT_MAX_FILE_SIZE).setQueueSize(1).setCheckpointDir(checkpointDir).setLogDirs(dataDirs).setChannelName("testlog").setChannelCounter(new FileChannelCounter("testlog")).build();    log.replay();    FlumeEventQueue queue = log.getFlumeEventQueue();    Assert.assertNull(queue.removeHead(0));}
0e3c930e30ea88174fb5e49d00921de88b7b9741d0fc9fc753722a30f1834fda
testPutTakeRollbackLogReplayV1
public void testPutTakeRollbackLogReplayV1() throws IOException, InterruptedException, NoopRecordException, CorruptEventException
{    doPutTakeRollback(true);}
29a0110511d0ba656339acdae97affbaeea942f92e74800969d9b97c5db6d700
testPutTakeRollbackLogReplayV2
public void testPutTakeRollbackLogReplayV2() throws IOException, InterruptedException, NoopRecordException, CorruptEventException
{    doPutTakeRollback(false);}
722e7da97bb9dcec8d1c5aba2c1541ea12f8d6fd66929a9a087b8fd739360634
doPutTakeRollback
public void doPutTakeRollback(boolean useLogReplayV1) throws IOException, InterruptedException, NoopRecordException, CorruptEventException
{    FlumeEvent eventIn = TestUtils.newPersistableEvent();    long putTransactionID = ++transactionID;    FlumeEventPointer eventPointerIn = log.put(putTransactionID, eventIn);    log.commitPut(putTransactionID);    long takeTransactionID = ++transactionID;    log.take(takeTransactionID, eventPointerIn);    log.rollback(takeTransactionID);    log.close();    new Log.Builder().setCheckpointInterval(Long.MAX_VALUE).setMaxFileSize(FileChannelConfiguration.DEFAULT_MAX_FILE_SIZE).setQueueSize(1).setCheckpointDir(checkpointDir).setLogDirs(dataDirs).setChannelName("testlog").setUseLogReplayV1(useLogReplayV1).setChannelCounter(new FileChannelCounter("testlog")).build();    log.replay();    takeAndVerify(eventPointerIn, eventIn);}
9f0dafd64d5e9a10fc6d343dda42b820053dab31621623d98fd0636c9e949ada
testCommitNoPut
public void testCommitNoPut() throws IOException, InterruptedException
{    long putTransactionID = ++transactionID;    log.commitPut(putTransactionID);    log.close();    new Log.Builder().setCheckpointInterval(Long.MAX_VALUE).setMaxFileSize(FileChannelConfiguration.DEFAULT_MAX_FILE_SIZE).setQueueSize(1).setCheckpointDir(checkpointDir).setLogDirs(dataDirs).setChannelName("testlog").setChannelCounter(new FileChannelCounter("testlog")).build();    log.replay();    FlumeEventQueue queue = log.getFlumeEventQueue();    FlumeEventPointer eventPointerOut = queue.removeHead(0);    Assert.assertNull(eventPointerOut);}
1daa6ab2ad7be371583cc2fb9c413ea661bbc20718afd5b9e92baca40c9e6abc
testCommitNoTake
public void testCommitNoTake() throws IOException, InterruptedException
{    long putTransactionID = ++transactionID;    log.commitTake(putTransactionID);    log.close();    new Log.Builder().setCheckpointInterval(Long.MAX_VALUE).setMaxFileSize(FileChannelConfiguration.DEFAULT_MAX_FILE_SIZE).setQueueSize(1).setCheckpointDir(checkpointDir).setLogDirs(dataDirs).setChannelName("testlog").setChannelCounter(new FileChannelCounter("testlog")).build();    log.replay();    FlumeEventQueue queue = log.getFlumeEventQueue();    FlumeEventPointer eventPointerOut = queue.removeHead(0);    Assert.assertNull(eventPointerOut);}
c2912c7c9c87185128f3f14441b3c7d758150b96098ada369bfb8b07f01cff77
testRollbackNoPutTake
public void testRollbackNoPutTake() throws IOException, InterruptedException
{    long putTransactionID = ++transactionID;    log.rollback(putTransactionID);    log.close();    new Log.Builder().setCheckpointInterval(Long.MAX_VALUE).setMaxFileSize(FileChannelConfiguration.DEFAULT_MAX_FILE_SIZE).setQueueSize(1).setCheckpointDir(checkpointDir).setLogDirs(dataDirs).setChannelName("testlog").setChannelCounter(new FileChannelCounter("testlog")).build();    log.replay();    FlumeEventQueue queue = log.getFlumeEventQueue();    FlumeEventPointer eventPointerOut = queue.removeHead(0);    Assert.assertNull(eventPointerOut);}
3fa19a8027cf0817089a2db4cdaef2d5ea869524eef77dcb0ec6c0ca33750b48
testGetLogs
public void testGetLogs() throws IOException
{    File logDir = dataDirs[0];    List<File> expected = Lists.newArrayList();    for (int i = 0; i < 10; i++) {        File log = new File(logDir, Log.PREFIX + i);        expected.add(log);        Assert.assertTrue(log.isFile() || log.createNewFile());        File metaDataFile = Serialization.getMetaDataFile(log);        File metaDataTempFile = Serialization.getMetaDataTempFile(metaDataFile);        File logGzip = new File(logDir, Log.PREFIX + i + ".gz");        Assert.assertTrue(metaDataFile.isFile() || metaDataFile.createNewFile());        Assert.assertTrue(metaDataTempFile.isFile() || metaDataTempFile.createNewFile());        Assert.assertTrue(log.isFile() || logGzip.createNewFile());    }    List<File> actual = LogUtils.getLogs(logDir);    LogUtils.sort(actual);    LogUtils.sort(expected);    Assert.assertEquals(expected, actual);}
5babf06d663a5c9c4ee756e28c6f7732c07d79e7c07333f514f011b4a3b7bebb
testReplayFailsWithAllEmptyLogMetaDataNormalReplay
public void testReplayFailsWithAllEmptyLogMetaDataNormalReplay() throws IOException, InterruptedException
{    doTestReplayFailsWithAllEmptyLogMetaData(false);}
0ad2fc4eab51fe6c43120fec325632ef89c34c22e0346c2ab7bc98c47794f439
testReplayFailsWithAllEmptyLogMetaDataFastReplay
public void testReplayFailsWithAllEmptyLogMetaDataFastReplay() throws IOException, InterruptedException
{    doTestReplayFailsWithAllEmptyLogMetaData(true);}
2c79cbeb561c417abb4ec58de444f198ffdc61230b6552828c37e409739f4725
doTestReplayFailsWithAllEmptyLogMetaData
public void doTestReplayFailsWithAllEmptyLogMetaData(boolean useFastReplay) throws IOException, InterruptedException
{        log.close();    log = new Log.Builder().setCheckpointInterval(1L).setMaxFileSize(MAX_FILE_SIZE).setQueueSize(CAPACITY).setCheckpointDir(checkpointDir).setLogDirs(dataDirs).setChannelName("testlog").setUseFastReplay(useFastReplay).setChannelCounter(new FileChannelCounter("testlog")).build();    log.replay();    FlumeEvent eventIn = TestUtils.newPersistableEvent();    long transactionID = ++this.transactionID;    log.put(transactionID, eventIn);    log.commitPut(transactionID);    log.close();    if (useFastReplay) {        FileUtils.deleteQuietly(checkpointDir);        Assert.assertTrue(checkpointDir.mkdir());    }    List<File> logFiles = Lists.newArrayList();    for (int i = 0; i < dataDirs.length; i++) {        logFiles.addAll(LogUtils.getLogs(dataDirs[i]));    }    Assert.assertTrue(logFiles.size() > 0);    for (File logFile : logFiles) {        File logFileMeta = Serialization.getMetaDataFile(logFile);        Assert.assertTrue(logFileMeta.delete());        Assert.assertTrue(logFileMeta.createNewFile());    }    log = new Log.Builder().setCheckpointInterval(1L).setMaxFileSize(MAX_FILE_SIZE).setQueueSize(CAPACITY).setCheckpointDir(checkpointDir).setLogDirs(dataDirs).setChannelName("testlog").setUseFastReplay(useFastReplay).setChannelCounter(new FileChannelCounter("testlog")).build();    try {        log.replay();        Assert.fail();    } catch (IllegalStateException expected) {        String msg = expected.getMessage();        Assert.assertNotNull(msg);        Assert.assertTrue(msg, msg.contains(".meta is empty, but log"));    }}
3b093b55bd2f454022164ba3d47f93312bff2c77537ae6264387e1757501dc75
testReplaySucceedsWithUnusedEmptyLogMetaDataNormalReplay
public void testReplaySucceedsWithUnusedEmptyLogMetaDataNormalReplay() throws IOException, InterruptedException, NoopRecordException, CorruptEventException
{    FlumeEvent eventIn = TestUtils.newPersistableEvent();    long transactionID = ++this.transactionID;    FlumeEventPointer eventPointer = log.put(transactionID, eventIn);        log.commitPut(transactionID);    log.close();    log = new Log.Builder().setCheckpointInterval(1L).setMaxFileSize(MAX_FILE_SIZE).setQueueSize(CAPACITY).setCheckpointDir(checkpointDir).setLogDirs(dataDirs).setChannelName("testlog").setChannelCounter(new FileChannelCounter("testlog")).build();    doTestReplaySucceedsWithUnusedEmptyLogMetaData(eventIn, eventPointer);}
6177d2a4c4eb5384bc8ab2ecec251d317006d5ee9f8dc65496c13d0cf77a6c46
testReplaySucceedsWithUnusedEmptyLogMetaDataFastReplay
public void testReplaySucceedsWithUnusedEmptyLogMetaDataFastReplay() throws IOException, InterruptedException, NoopRecordException, CorruptEventException
{    FlumeEvent eventIn = TestUtils.newPersistableEvent();    long transactionID = ++this.transactionID;    FlumeEventPointer eventPointer = log.put(transactionID, eventIn);        log.commitPut(transactionID);    log.close();    checkpointDir = Files.createTempDir();    FileUtils.forceDeleteOnExit(checkpointDir);    Assert.assertTrue(checkpointDir.isDirectory());    log = new Log.Builder().setCheckpointInterval(1L).setMaxFileSize(MAX_FILE_SIZE).setQueueSize(CAPACITY).setCheckpointDir(checkpointDir).setLogDirs(dataDirs).setChannelName("testlog").setUseFastReplay(true).setChannelCounter(new FileChannelCounter("testlog")).build();    doTestReplaySucceedsWithUnusedEmptyLogMetaData(eventIn, eventPointer);}
eaf9079b7cc73c8cc2546cef4ed93eaac083a8f597c184eafb7700d32d86cca5
doTestReplaySucceedsWithUnusedEmptyLogMetaData
public void doTestReplaySucceedsWithUnusedEmptyLogMetaData(FlumeEvent eventIn, FlumeEventPointer eventPointer) throws IOException, InterruptedException, NoopRecordException, CorruptEventException
{    for (int i = 0; i < dataDirs.length; i++) {        for (File logFile : LogUtils.getLogs(dataDirs[i])) {            if (logFile.length() == 0L) {                File logFileMeta = Serialization.getMetaDataFile(logFile);                Assert.assertTrue(logFileMeta.delete());                Assert.assertTrue(logFileMeta.createNewFile());            }        }    }    log.replay();    FlumeEvent eventOut = log.get(eventPointer);    Assert.assertNotNull(eventOut);    Assert.assertEquals(eventIn.getHeaders(), eventOut.getHeaders());    Assert.assertArrayEquals(eventIn.getBody(), eventOut.getBody());}
a2952fc7a5c6e5a851c3bf8ba0fa577c33fe3bd189edb0c093fe024a87723c99
testCachedFSUsableSpace
public void testCachedFSUsableSpace() throws Exception
{    File fs = mock(File.class);    when(fs.getUsableSpace()).thenReturn(Long.MAX_VALUE);    LogFile.CachedFSUsableSpace cachedFS = new LogFile.CachedFSUsableSpace(fs, 1000L);    Assert.assertEquals(cachedFS.getUsableSpace(), Long.MAX_VALUE);    cachedFS.decrement(Integer.MAX_VALUE);    Assert.assertEquals(cachedFS.getUsableSpace(), Long.MAX_VALUE - Integer.MAX_VALUE);    try {        cachedFS.decrement(-1);        Assert.fail();    } catch (IllegalArgumentException expected) {    }    when(fs.getUsableSpace()).thenReturn(Long.MAX_VALUE - 1L);    Thread.sleep(1100);    Assert.assertEquals(cachedFS.getUsableSpace(), Long.MAX_VALUE - 1L);}
5ae6a5c950406cdd3e2ab59bfafc463c5af746dd024a9f83c4a6a56d6fdfb09f
testCheckpointOnClose
public void testCheckpointOnClose() throws Exception
{    log.close();    log = new Log.Builder().setCheckpointInterval(1L).setMaxFileSize(MAX_FILE_SIZE).setQueueSize(CAPACITY).setCheckpointDir(checkpointDir).setLogDirs(dataDirs).setCheckpointOnClose(true).setChannelName("testLog").setChannelCounter(new FileChannelCounter("testlog")).build();    log.replay();        FlumeEvent eventIn = TestUtils.newPersistableEvent();    log.put(transactionID, eventIn);    log.commitPut(transactionID);        File checkPointMetaFile = FileUtils.listFiles(checkpointDir, new String[] { "meta" }, false).iterator().next();    long before = FileUtils.checksumCRC32(checkPointMetaFile);        log.close();        long after = FileUtils.checksumCRC32(checkPointMetaFile);    Assert.assertFalse(before == after);}
0866717dc65347860e6e8a2b0b18126a8ba8bd5f6844ed1ffe8301111721cba5
takeAndVerify
private void takeAndVerify(FlumeEventPointer eventPointerIn, FlumeEvent eventIn) throws IOException, InterruptedException, NoopRecordException, CorruptEventException
{    FlumeEventQueue queue = log.getFlumeEventQueue();    FlumeEventPointer eventPointerOut = queue.removeHead(0);    Assert.assertNotNull(eventPointerOut);    Assert.assertNull(queue.removeHead(0));    Assert.assertEquals(eventPointerIn, eventPointerOut);    Assert.assertEquals(eventPointerIn.hashCode(), eventPointerOut.hashCode());    FlumeEvent eventOut = log.get(eventPointerOut);    Assert.assertNotNull(eventOut);    Assert.assertEquals(eventIn.getHeaders(), eventOut.getHeaders());    Assert.assertArrayEquals(eventIn.getBody(), eventOut.getBody());}
935d9dc08fe11323dcaaf5c6f96db76bb87fd0fc4b9fcc33e9eca9f620f5620c
setup
public void setup() throws IOException
{    fileID = 1;    transactionID = 1L;    dataDir = Files.createTempDir();    dataFile = new File(dataDir, String.valueOf(fileID));    Assert.assertTrue(dataDir.isDirectory());    logFileWriter = LogFileFactory.getWriter(dataFile, fileID, Integer.MAX_VALUE, null, null, null, Long.MAX_VALUE, true, 0);}
9779bf7fab76efc73510dce8feeee2e5d4343f6c015cf6fe29938f6ac009ad3f
cleanup
public void cleanup() throws IOException
{    try {        if (logFileWriter != null) {            logFileWriter.close();        }    } finally {        FileUtils.deleteQuietly(dataDir);    }}
c181c0619f58a6ed033c7cfdd3056a9081abe4b7d11b2703f9390e3af839bbf2
testWriterRefusesToOverwriteFile
public void testWriterRefusesToOverwriteFile() throws IOException
{    Assert.assertTrue(dataFile.isFile() || dataFile.createNewFile());    try {        LogFileFactory.getWriter(dataFile, fileID, Integer.MAX_VALUE, null, null, null, Long.MAX_VALUE, true, 0);        Assert.fail();    } catch (IllegalStateException e) {        Assert.assertEquals("File already exists " + dataFile.getAbsolutePath(), e.getMessage());    }}
6f41b18382022604721f170b0be9cec8bb42153b4b7cc757b87a501ca6700f7b
testWriterFailsWithDirectory
public void testWriterFailsWithDirectory() throws IOException
{    FileUtils.deleteQuietly(dataFile);    Assert.assertFalse(dataFile.exists());    Assert.assertTrue(dataFile.mkdirs());    try {        LogFileFactory.getWriter(dataFile, fileID, Integer.MAX_VALUE, null, null, null, Long.MAX_VALUE, true, 0);        Assert.fail();    } catch (IllegalStateException e) {        Assert.assertEquals("File already exists " + dataFile.getAbsolutePath(), e.getMessage());    }}
fa36337fe7b6d04944453582b26e28d3275e4a25ad783e3b2891bb8a5061d73a
testPutGet
public void testPutGet() throws InterruptedException, IOException
{    final List<Throwable> errors = Collections.synchronizedList(new ArrayList<Throwable>());    ExecutorService executorService = Executors.newFixedThreadPool(10);    CompletionService<Void> completionService = new ExecutorCompletionService<Void>(executorService);    final LogFile.RandomReader logFileReader = LogFileFactory.getRandomReader(dataFile, null, true);    for (int i = 0; i < 1000; i++) {                synchronized (errors) {            for (Throwable throwable : errors) {                Throwables.propagateIfInstanceOf(throwable, AssertionError.class);            }                        for (Throwable throwable : errors) {                Throwables.propagate(throwable);            }        }        final FlumeEvent eventIn = TestUtils.newPersistableEvent();        final Put put = new Put(++transactionID, WriteOrderOracle.next(), eventIn);        ByteBuffer bytes = TransactionEventRecord.toByteBuffer(put);        FlumeEventPointer ptr = logFileWriter.put(bytes);        final int offset = ptr.getOffset();        completionService.submit(new Runnable() {            @Override            public void run() {                try {                    FlumeEvent eventOut = logFileReader.get(offset);                    Assert.assertEquals(eventIn.getHeaders(), eventOut.getHeaders());                    Assert.assertTrue(Arrays.equals(eventIn.getBody(), eventOut.getBody()));                } catch (Throwable throwable) {                    synchronized (errors) {                        errors.add(throwable);                    }                }            }        }, null);    }    for (int i = 0; i < 1000; i++) {        completionService.take();    }        for (Throwable throwable : errors) {        Throwables.propagateIfInstanceOf(throwable, AssertionError.class);    }        for (Throwable throwable : errors) {        Throwables.propagate(throwable);    }}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    try {        FlumeEvent eventOut = logFileReader.get(offset);        Assert.assertEquals(eventIn.getHeaders(), eventOut.getHeaders());        Assert.assertTrue(Arrays.equals(eventIn.getBody(), eventOut.getBody()));    } catch (Throwable throwable) {        synchronized (errors) {            errors.add(throwable);        }    }}
f556bafe6e4b5f1a183d9605340465a5f9f5ed577b528c0e9a8f118d74639f81
testReader
public void testReader() throws InterruptedException, IOException, CorruptEventException
{    Map<Integer, Put> puts = Maps.newHashMap();    for (int i = 0; i < 1000; i++) {        FlumeEvent eventIn = TestUtils.newPersistableEvent();        Put put = new Put(++transactionID, WriteOrderOracle.next(), eventIn);        ByteBuffer bytes = TransactionEventRecord.toByteBuffer(put);        FlumeEventPointer ptr = logFileWriter.put(bytes);        puts.put(ptr.getOffset(), put);    }    LogFile.SequentialReader reader = LogFileFactory.getSequentialReader(dataFile, null, true);    LogRecord entry;    while ((entry = reader.next()) != null) {        Integer offset = entry.getOffset();        TransactionEventRecord record = entry.getEvent();        Put put = puts.get(offset);        FlumeEvent eventIn = put.getEvent();        Assert.assertEquals(put.getTransactionID(), record.getTransactionID());        Assert.assertTrue(record instanceof Put);        FlumeEvent eventOut = ((Put) record).getEvent();        Assert.assertEquals(eventIn.getHeaders(), eventOut.getHeaders());        Assert.assertTrue(Arrays.equals(eventIn.getBody(), eventOut.getBody()));    }}
719f0992c99c121a864f2e985ac1bf66c62dbdd232405d621a2358ef3575c031
testReaderOldMetaFile
public void testReaderOldMetaFile() throws InterruptedException, IOException, CorruptEventException
{    Map<Integer, Put> puts = Maps.newHashMap();    for (int i = 0; i < 1000; i++) {        FlumeEvent eventIn = TestUtils.newPersistableEvent();        Put put = new Put(++transactionID, WriteOrderOracle.next(), eventIn);        ByteBuffer bytes = TransactionEventRecord.toByteBuffer(put);        FlumeEventPointer ptr = logFileWriter.put(bytes);        puts.put(ptr.getOffset(), put);    }        File metadataFile = Serialization.getMetaDataFile(dataFile);    File oldMetadataFile = Serialization.getOldMetaDataFile(dataFile);    if (!metadataFile.renameTo(oldMetadataFile)) {        Assert.fail("Renaming to meta.old failed");    }    LogFile.SequentialReader reader = LogFileFactory.getSequentialReader(dataFile, null, true);    Assert.assertTrue(metadataFile.exists());    Assert.assertFalse(oldMetadataFile.exists());    LogRecord entry;    while ((entry = reader.next()) != null) {        Integer offset = entry.getOffset();        TransactionEventRecord record = entry.getEvent();        Put put = puts.get(offset);        FlumeEvent eventIn = put.getEvent();        Assert.assertEquals(put.getTransactionID(), record.getTransactionID());        Assert.assertTrue(record instanceof Put);        FlumeEvent eventOut = ((Put) record).getEvent();        Assert.assertEquals(eventIn.getHeaders(), eventOut.getHeaders());        Assert.assertTrue(Arrays.equals(eventIn.getBody(), eventOut.getBody()));    }}
ac8610cce79461c272241585dc1668c7b2ff061ad36f07910df14d70b565c9f0
testReaderTempMetaFile
public void testReaderTempMetaFile() throws InterruptedException, IOException, CorruptEventException
{    Map<Integer, Put> puts = Maps.newHashMap();    for (int i = 0; i < 1000; i++) {        FlumeEvent eventIn = TestUtils.newPersistableEvent();        Put put = new Put(++transactionID, WriteOrderOracle.next(), eventIn);        ByteBuffer bytes = TransactionEventRecord.toByteBuffer(put);        FlumeEventPointer ptr = logFileWriter.put(bytes);        puts.put(ptr.getOffset(), put);    }        File metadataFile = Serialization.getMetaDataFile(dataFile);    File tempMetadataFile = Serialization.getMetaDataTempFile(dataFile);    File oldMetadataFile = Serialization.getOldMetaDataFile(dataFile);        oldMetadataFile.createNewFile();    if (!metadataFile.renameTo(tempMetadataFile)) {        Assert.fail("Renaming to meta.temp failed");    }    LogFile.SequentialReader reader = LogFileFactory.getSequentialReader(dataFile, null, true);    Assert.assertTrue(metadataFile.exists());    Assert.assertFalse(tempMetadataFile.exists());    Assert.assertFalse(oldMetadataFile.exists());    LogRecord entry;    while ((entry = reader.next()) != null) {        Integer offset = entry.getOffset();        TransactionEventRecord record = entry.getEvent();        Put put = puts.get(offset);        FlumeEvent eventIn = put.getEvent();        Assert.assertEquals(put.getTransactionID(), record.getTransactionID());        Assert.assertTrue(record instanceof Put);        FlumeEvent eventOut = ((Put) record).getEvent();        Assert.assertEquals(eventIn.getHeaders(), eventOut.getHeaders());        Assert.assertTrue(Arrays.equals(eventIn.getBody(), eventOut.getBody()));    }}
251846005c500ca4cb99c75ada7bbabe07dba512b83f84a0a6aa35b1c4aa42e8
testWriteDelimitedTo
public void testWriteDelimitedTo() throws IOException
{    if (dataFile.isFile()) {        Assert.assertTrue(dataFile.delete());    }    Assert.assertTrue(dataFile.createNewFile());    ProtosFactory.LogFileMetaData.Builder metaDataBuilder = ProtosFactory.LogFileMetaData.newBuilder();    metaDataBuilder.setVersion(1);    metaDataBuilder.setLogFileID(2);    metaDataBuilder.setCheckpointPosition(3);    metaDataBuilder.setCheckpointWriteOrderID(4);    LogFileV3.writeDelimitedTo(metaDataBuilder.build(), dataFile);    ProtosFactory.LogFileMetaData metaData = ProtosFactory.LogFileMetaData.parseDelimitedFrom(new FileInputStream(dataFile));    Assert.assertEquals(1, metaData.getVersion());    Assert.assertEquals(2, metaData.getLogFileID());    Assert.assertEquals(3, metaData.getCheckpointPosition());    Assert.assertEquals(4, metaData.getCheckpointWriteOrderID());}
fe1652640a9e769ffe94e59a72ae0f3dd1d7e37653f697bbf73d1a64628aaa51
testPutGetCorruptEvent
public void testPutGetCorruptEvent() throws Exception
{    final LogFile.RandomReader logFileReader = LogFileFactory.getRandomReader(dataFile, null, true);    final FlumeEvent eventIn = TestUtils.newPersistableEvent(2500);    final Put put = new Put(++transactionID, WriteOrderOracle.next(), eventIn);    ByteBuffer bytes = TransactionEventRecord.toByteBuffer(put);    FlumeEventPointer ptr = logFileWriter.put(bytes);    logFileWriter.commit(TransactionEventRecord.toByteBuffer(new Commit(transactionID, WriteOrderOracle.next())));    logFileWriter.sync();    final int offset = ptr.getOffset();    RandomAccessFile writer = new RandomAccessFile(dataFile, "rw");    writer.seek(offset + 1500);    writer.write((byte) 45);    writer.write((byte) 12);    writer.getFD().sync();    logFileReader.get(offset);        Assert.fail();}
c4eb1fe0b2984acb3bac05e0bcfa339984d5fab991999fc9ca8f6f6ae491502f
testPutGetNoopEvent
public void testPutGetNoopEvent() throws Exception
{    final LogFile.RandomReader logFileReader = LogFileFactory.getRandomReader(dataFile, null, true);    final FlumeEvent eventIn = TestUtils.newPersistableEvent(2500);    final Put put = new Put(++transactionID, WriteOrderOracle.next(), eventIn);    ByteBuffer bytes = TransactionEventRecord.toByteBuffer(put);    FlumeEventPointer ptr = logFileWriter.put(bytes);    logFileWriter.commit(TransactionEventRecord.toByteBuffer(new Commit(transactionID, WriteOrderOracle.next())));    logFileWriter.sync();    final int offset = ptr.getOffset();    LogFile.OperationRecordUpdater updater = new LogFile.OperationRecordUpdater(dataFile);    updater.markRecordAsNoop(offset);    logFileReader.get(offset);        Assert.fail();}
b075d43c14fa077a2fe123fb73c7483d8463647bc72f7920e9ca89a989dae930
testOperationRecordUpdater
public void testOperationRecordUpdater() throws Exception
{    File tempDir = Files.createTempDir();    File temp = new File(tempDir, "temp");    final RandomAccessFile tempFile = new RandomAccessFile(temp, "rw");    for (int i = 0; i < 5000; i++) {        tempFile.write(LogFile.OP_RECORD);    }    tempFile.seek(0);    LogFile.OperationRecordUpdater recordUpdater = new LogFile.OperationRecordUpdater(temp);        for (int i = 0; i < 5000; i += 10) {        recordUpdater.markRecordAsNoop(i);    }    recordUpdater.close();    tempFile.seek(0);        for (int i = 0; i < 5000; i += 10) {        tempFile.seek(i);        Assert.assertEquals(LogFile.OP_NOOP, tempFile.readByte());    }}
4cc038875a9224ce92df722498884aa467dcbc3b55107ab460b9051d0437d75b
testOpRecordUpdaterWithFlumeEvents
public void testOpRecordUpdaterWithFlumeEvents() throws Exception
{    final FlumeEvent eventIn = TestUtils.newPersistableEvent(2500);    final Put put = new Put(++transactionID, WriteOrderOracle.next(), eventIn);    ByteBuffer bytes = TransactionEventRecord.toByteBuffer(put);    FlumeEventPointer ptr = logFileWriter.put(bytes);    logFileWriter.commit(TransactionEventRecord.toByteBuffer(new Commit(transactionID, WriteOrderOracle.next())));    logFileWriter.sync();    final int offset = ptr.getOffset();    LogFile.OperationRecordUpdater updater = new LogFile.OperationRecordUpdater(dataFile);    updater.markRecordAsNoop(offset);    RandomAccessFile fileReader = new RandomAccessFile(dataFile, "rw");    Assert.assertEquals(LogFile.OP_NOOP, fileReader.readByte());}
e7831ad0ba076d2b23241d6776f59cf17ff72108ec17048a9214e99bf15d4166
testGroupCommit
public void testGroupCommit() throws Exception
{    final FlumeEvent eventIn = TestUtils.newPersistableEvent(250);    final CyclicBarrier barrier = new CyclicBarrier(20);    ExecutorService executorService = Executors.newFixedThreadPool(20);    ExecutorCompletionService<Void> completionService = new ExecutorCompletionService<Void>(executorService);    final LogFile.Writer writer = logFileWriter;    final AtomicLong txnId = new AtomicLong(++transactionID);    for (int i = 0; i < 20; i++) {        completionService.submit(new Callable<Void>() {            @Override            public Void call() {                try {                    Put put = new Put(txnId.incrementAndGet(), WriteOrderOracle.next(), eventIn);                    ByteBuffer bytes = TransactionEventRecord.toByteBuffer(put);                    writer.put(bytes);                    writer.commit(TransactionEventRecord.toByteBuffer(new Commit(txnId.get(), WriteOrderOracle.next())));                    barrier.await();                    writer.sync();                } catch (Exception ex) {                    Throwables.propagate(ex);                }                return null;            }        });    }    for (int i = 0; i < 20; i++) {        completionService.take().get();    }        Assert.assertTrue(logFileWriter.position() >= 5000);    Assert.assertEquals(1, writer.getSyncCount());    Assert.assertTrue(logFileWriter.getLastCommitPosition() == logFileWriter.getLastSyncPosition());    executorService.shutdown();}
129e071a5acdf44209957699325f269c391c2463b78b7efe09056606615ae94b
call
public Void call()
{    try {        Put put = new Put(txnId.incrementAndGet(), WriteOrderOracle.next(), eventIn);        ByteBuffer bytes = TransactionEventRecord.toByteBuffer(put);        writer.put(bytes);        writer.commit(TransactionEventRecord.toByteBuffer(new Commit(txnId.get(), WriteOrderOracle.next())));        barrier.await();        writer.sync();    } catch (Exception ex) {        Throwables.propagate(ex);    }    return null;}
b7b21d24e32e4f868979d3cde8815b02ce5665794ec7983f0b9cfd9954331bff
testConstructor
public void testConstructor()
{    long now = System.currentTimeMillis();    Commit commit = new Commit(now, now + 1);    LogRecord logRecord = new LogRecord(1, 2, commit);    Assert.assertTrue(now == commit.getTransactionID());    Assert.assertTrue(now + 1 == commit.getLogWriteOrderID());    Assert.assertTrue(1 == logRecord.getFileID());    Assert.assertTrue(2 == logRecord.getOffset());    Assert.assertTrue(commit == logRecord.getEvent());}
29a816b53400888b9eecac83596fd6938b61c9dcf61d2f7d295c14fcb21bd55d
testSortOrder
public void testSortOrder()
{        long now = System.currentTimeMillis();    List<LogRecord> records = Lists.newArrayList();    for (int i = 0; i < 3; i++) {        Commit commit = new Commit((long) i, now - i);        LogRecord logRecord = new LogRecord(1, i, commit);        records.add(logRecord);    }    LogRecord logRecord;    logRecord = Collections.min(records);    Assert.assertTrue(String.valueOf(logRecord.getOffset()), 2 == logRecord.getOffset());    records.remove(logRecord);    logRecord = Collections.min(records);    Assert.assertTrue(String.valueOf(logRecord.getOffset()), 1 == logRecord.getOffset());    records.remove(logRecord);    logRecord = Collections.min(records);    Assert.assertTrue(String.valueOf(logRecord.getOffset()), 0 == logRecord.getOffset());    records.remove(logRecord);}
9803b99f7aea5c0e0f7c7c5fb4a764d4a1157b01170c1e3adb26881b26098e03
testTypes
public void testTypes() throws IOException
{    Put put = new Put(System.currentTimeMillis(), WriteOrderOracle.next());    Assert.assertEquals(TransactionEventRecord.Type.PUT.get(), put.getRecordType());    Take take = new Take(System.currentTimeMillis(), WriteOrderOracle.next());    Assert.assertEquals(TransactionEventRecord.Type.TAKE.get(), take.getRecordType());    Rollback rollback = new Rollback(System.currentTimeMillis(), WriteOrderOracle.next());    Assert.assertEquals(TransactionEventRecord.Type.ROLLBACK.get(), rollback.getRecordType());    Commit commit = new Commit(System.currentTimeMillis(), WriteOrderOracle.next());    Assert.assertEquals(TransactionEventRecord.Type.COMMIT.get(), commit.getRecordType());}
bc24a3c678c52df6cea6af34eed311718706c6a6710d400f5c488be4a6ccce83
testPutSerialization
public void testPutSerialization() throws IOException
{    Put in = new Put(System.currentTimeMillis(), WriteOrderOracle.next(), new FlumeEvent(new HashMap<String, String>(), new byte[0]));    Put out = (Put) TransactionEventRecord.fromDataInputV2(toDataInput(in));    Assert.assertEquals(in.getClass(), out.getClass());    Assert.assertEquals(in.getRecordType(), out.getRecordType());    Assert.assertEquals(in.getTransactionID(), out.getTransactionID());    Assert.assertEquals(in.getLogWriteOrderID(), out.getLogWriteOrderID());    Assert.assertEquals(in.getEvent().getHeaders(), out.getEvent().getHeaders());    Assert.assertTrue(Arrays.equals(in.getEvent().getBody(), out.getEvent().getBody()));}
07faf03e287f2fceeb15b3d503a0b40433184544ad7021e8a00b18ffa737df86
testTakeSerialization
public void testTakeSerialization() throws IOException
{    Take in = new Take(System.currentTimeMillis(), WriteOrderOracle.next(), 10, 20);    Take out = (Take) TransactionEventRecord.fromDataInputV2(toDataInput(in));    Assert.assertEquals(in.getClass(), out.getClass());    Assert.assertEquals(in.getRecordType(), out.getRecordType());    Assert.assertEquals(in.getTransactionID(), out.getTransactionID());    Assert.assertEquals(in.getLogWriteOrderID(), out.getLogWriteOrderID());    Assert.assertEquals(in.getFileID(), out.getFileID());    Assert.assertEquals(in.getOffset(), out.getOffset());}
90f2b3319632358e8a46153e890ef58937cfe2e8946522d2cb8e7b43fc1a35fb
testRollbackSerialization
public void testRollbackSerialization() throws IOException
{    Rollback in = new Rollback(System.currentTimeMillis(), WriteOrderOracle.next());    Rollback out = (Rollback) TransactionEventRecord.fromDataInputV2(toDataInput(in));    Assert.assertEquals(in.getClass(), out.getClass());    Assert.assertEquals(in.getRecordType(), out.getRecordType());    Assert.assertEquals(in.getTransactionID(), out.getTransactionID());    Assert.assertEquals(in.getLogWriteOrderID(), out.getLogWriteOrderID());}
671715c8bad1f99ab9e61c55d111a9fea64c66ba559892deda9ad193eb55632b
testCommitSerialization
public void testCommitSerialization() throws IOException
{    Commit in = new Commit(System.currentTimeMillis(), WriteOrderOracle.next());    Commit out = (Commit) TransactionEventRecord.fromDataInputV2(toDataInput(in));    Assert.assertEquals(in.getClass(), out.getClass());    Assert.assertEquals(in.getRecordType(), out.getRecordType());    Assert.assertEquals(in.getTransactionID(), out.getTransactionID());    Assert.assertEquals(in.getLogWriteOrderID(), out.getLogWriteOrderID());}
e5521df45bbe4e672f826d78cebceb0a89a3a2d9fdbdb97fa447b041e6a0aefa
testBadHeader
public void testBadHeader() throws IOException
{    Put in = new Put(System.currentTimeMillis(), WriteOrderOracle.next(), new FlumeEvent(new HashMap<String, String>(), new byte[0]));    try {        TransactionEventRecord.fromDataInputV2(toDataInput(0, in));        Assert.fail();    } catch (IOException e) {        Assert.assertEquals("Header 0 is not the required value: deadbeef", e.getMessage());    }}
464c7f6b7f70ed9b73f4a2e2ae6dc499ac48c9966c57d62abb80925c97e5fd86
testBadType
public void testBadType() throws IOException
{    TransactionEventRecord in = mock(TransactionEventRecord.class);    when(in.getRecordType()).thenReturn(Short.MIN_VALUE);    try {        TransactionEventRecord.fromDataInputV2(toDataInput(in));        Assert.fail();    } catch (NullPointerException e) {        Assert.assertEquals("Unknown action ffff8000", e.getMessage());    }}
5b765e6924fef8e3899585d0cfd9c9ca2a8e8b4febb5d3ef691bb2fa71a7e396
toDataInput
private DataInput toDataInput(TransactionEventRecord record) throws IOException
{    ByteBuffer buffer = TransactionEventRecord.toByteBufferV2(record);    ByteArrayInputStream byteInput = new ByteArrayInputStream(buffer.array());    DataInputStream dataInput = new DataInputStream(byteInput);    return dataInput;}
a9063f23b6f0a07a458e5438c6bf37f84d18ad31a1bfe1926254e1ddc16e36a9
toDataInput
private DataInput toDataInput(int header, TransactionEventRecord record) throws IOException
{    ByteArrayOutputStream byteOutput = new ByteArrayOutputStream();    DataOutputStream dataOutput = new DataOutputStream(byteOutput);    dataOutput.writeInt(header);    dataOutput.writeShort(record.getRecordType());    dataOutput.writeLong(record.getTransactionID());    dataOutput.writeLong(record.getLogWriteOrderID());    record.write(dataOutput);    ByteArrayInputStream byteInput = new ByteArrayInputStream(byteOutput.toByteArray());    DataInputStream dataInput = new DataInputStream(byteInput);    return dataInput;}
9803b99f7aea5c0e0f7c7c5fb4a764d4a1157b01170c1e3adb26881b26098e03
testTypes
public void testTypes() throws IOException
{    Put put = new Put(System.currentTimeMillis(), WriteOrderOracle.next());    Assert.assertEquals(TransactionEventRecord.Type.PUT.get(), put.getRecordType());    Take take = new Take(System.currentTimeMillis(), WriteOrderOracle.next());    Assert.assertEquals(TransactionEventRecord.Type.TAKE.get(), take.getRecordType());    Rollback rollback = new Rollback(System.currentTimeMillis(), WriteOrderOracle.next());    Assert.assertEquals(TransactionEventRecord.Type.ROLLBACK.get(), rollback.getRecordType());    Commit commit = new Commit(System.currentTimeMillis(), WriteOrderOracle.next());    Assert.assertEquals(TransactionEventRecord.Type.COMMIT.get(), commit.getRecordType());}
689803f68dcd96117e8e257f0a3b0586a5ae66c0c355882ef457ebfc13a30137
testPutSerialization
public void testPutSerialization() throws IOException, CorruptEventException
{    Map<String, String> headers = new HashMap<String, String>();    headers.put("key", "value");    Put in = new Put(System.currentTimeMillis(), WriteOrderOracle.next(), new FlumeEvent(headers, new byte[0]));    Put out = (Put) TransactionEventRecord.fromByteArray(toByteArray(in));    Assert.assertEquals(in.getClass(), out.getClass());    Assert.assertEquals(in.getRecordType(), out.getRecordType());    Assert.assertEquals(in.getTransactionID(), out.getTransactionID());    Assert.assertEquals(in.getLogWriteOrderID(), out.getLogWriteOrderID());    Assert.assertEquals(in.getEvent().getHeaders(), out.getEvent().getHeaders());    Assert.assertEquals(headers, in.getEvent().getHeaders());    Assert.assertEquals(headers, out.getEvent().getHeaders());    Assert.assertTrue(Arrays.equals(in.getEvent().getBody(), out.getEvent().getBody()));}
e8cd1dd2439f38f7e08b06e000915696eacadaa177a2d1be9bb83b1ba08645f2
testPutSerializationNullHeader
public void testPutSerializationNullHeader() throws IOException, CorruptEventException
{    Put in = new Put(System.currentTimeMillis(), WriteOrderOracle.next(), new FlumeEvent(null, new byte[0]));    Put out = (Put) TransactionEventRecord.fromByteArray(toByteArray(in));    Assert.assertEquals(in.getClass(), out.getClass());    Assert.assertEquals(in.getRecordType(), out.getRecordType());    Assert.assertEquals(in.getTransactionID(), out.getTransactionID());    Assert.assertEquals(in.getLogWriteOrderID(), out.getLogWriteOrderID());    Assert.assertNull(in.getEvent().getHeaders());    Assert.assertNotNull(out.getEvent().getHeaders());    Assert.assertTrue(Arrays.equals(in.getEvent().getBody(), out.getEvent().getBody()));}
1f347c6d9a1909d4582d047e61c17cb9c0f75a58fa2fe4092e799f3bade2d169
testTakeSerialization
public void testTakeSerialization() throws IOException, CorruptEventException
{    Take in = new Take(System.currentTimeMillis(), WriteOrderOracle.next(), 10, 20);    Take out = (Take) TransactionEventRecord.fromByteArray(toByteArray(in));    Assert.assertEquals(in.getClass(), out.getClass());    Assert.assertEquals(in.getRecordType(), out.getRecordType());    Assert.assertEquals(in.getTransactionID(), out.getTransactionID());    Assert.assertEquals(in.getLogWriteOrderID(), out.getLogWriteOrderID());    Assert.assertEquals(in.getFileID(), out.getFileID());    Assert.assertEquals(in.getOffset(), out.getOffset());}
7c979aceee9443b7d28a0b7029a9afb2c0d08a5546dc89f183e91c0a8cb94a6f
testRollbackSerialization
public void testRollbackSerialization() throws IOException, CorruptEventException
{    Rollback in = new Rollback(System.currentTimeMillis(), WriteOrderOracle.next());    Rollback out = (Rollback) TransactionEventRecord.fromByteArray(toByteArray(in));    Assert.assertEquals(in.getClass(), out.getClass());    Assert.assertEquals(in.getRecordType(), out.getRecordType());    Assert.assertEquals(in.getTransactionID(), out.getTransactionID());    Assert.assertEquals(in.getLogWriteOrderID(), out.getLogWriteOrderID());}
21f3706932954b76612de3b164ede4654d34b2ed4cc745f09e1e6c14f1b9b730
testCommitSerialization
public void testCommitSerialization() throws IOException, CorruptEventException
{    Commit in = new Commit(System.currentTimeMillis(), WriteOrderOracle.next());    Commit out = (Commit) TransactionEventRecord.fromByteArray(toByteArray(in));    Assert.assertEquals(in.getClass(), out.getClass());    Assert.assertEquals(in.getRecordType(), out.getRecordType());    Assert.assertEquals(in.getTransactionID(), out.getTransactionID());    Assert.assertEquals(in.getLogWriteOrderID(), out.getLogWriteOrderID());}
a463d883e602d0aa80987681e8f952147d3a15e8eefb77d704d65900b88899a9
testBadType
public void testBadType() throws IOException, CorruptEventException
{    TransactionEventRecord in = mock(TransactionEventRecord.class);    when(in.getRecordType()).thenReturn(Short.MIN_VALUE);    try {        TransactionEventRecord.fromByteArray(toByteArray(in));        Assert.fail();    } catch (NullPointerException e) {        Assert.assertEquals("Unknown action ffff8000", e.getMessage());    }}
d0ac28553cb2ab54b05a863a2a5874fdc847ff2a3585a64fcbdf33d287887f0d
toByteArray
private byte[] toByteArray(TransactionEventRecord record) throws IOException
{    ByteBuffer buffer = TransactionEventRecord.toByteBuffer(record);    return buffer.array();}
b7ac0667b74faa9a4a0416c81473aab7a7f62e804ceff8385e2ef7f8f4b37b3d
testSetSeed
public void testSetSeed()
{    long current = TransactionIDOracle.next();    current += Integer.MAX_VALUE;    TransactionIDOracle.setSeed(current);    Assert.assertTrue(TransactionIDOracle.next() > System.currentTimeMillis());}
e6b4e0162efc97e8b669ca7ab47358dc6fb80db4fd1ed42101ffeaabc39f68ab
newPersistableEvent
public static FlumeEvent newPersistableEvent()
{    Map<String, String> headers = Maps.newHashMap();    String timestamp = String.valueOf(System.currentTimeMillis());    headers.put("timestamp", timestamp);    FlumeEvent event = new FlumeEvent(headers, timestamp.getBytes());    return event;}
b47e36b128061f403c2cdde91921a7911f7c24dffc1526f3efa11b1527f015c7
newPersistableEvent
public static FlumeEvent newPersistableEvent(int size)
{    Map<String, String> headers = Maps.newHashMap();    String timestamp = String.valueOf(System.currentTimeMillis());    headers.put("timestamp", timestamp);    byte[] data = new byte[size];    Arrays.fill(data, (byte) 54);    FlumeEvent event = new FlumeEvent(headers, data);    return event;}
23cbdff95bc808208c724389609709009f38947495bd2b12ac32875ea472906a
toDataInput
public static DataInput toDataInput(Writable writable) throws IOException
{    ByteArrayOutputStream byteOutput = new ByteArrayOutputStream();    DataOutputStream dataOutput = new DataOutputStream(byteOutput);    writable.write(dataOutput);    ByteArrayInputStream byteInput = new ByteArrayInputStream(byteOutput.toByteArray());    DataInputStream dataInput = new DataInputStream(byteInput);    return dataInput;}
c005b0bc7455891d3181a6a89ea28500d42e97815a784db7db8407482033a2af
compareInputAndOut
public static void compareInputAndOut(Set<String> in, Set<String> out)
{    Assert.assertNotNull(in);    Assert.assertNotNull(out);    Assert.assertEquals(in.size(), out.size());    Assert.assertTrue(in.equals(out));}
3f73392f69a03dea424c6f60e035ab615aa070496c21e1bd4fa95ed37815fa1d
putWithoutCommit
public static Set<String> putWithoutCommit(Channel channel, Transaction tx, String prefix, int number)
{    Set<String> events = Sets.newHashSet();    tx.begin();    for (int i = 0; i < number; i++) {        String eventData = (prefix + UUID.randomUUID()).toString();        Event event = EventBuilder.withBody(eventData.getBytes());        channel.put(event);        events.add(eventData);    }    return events;}
0faf829baf587bfe48cbfc799c6367f33e36057ae827e61d2356c79537f0a0ee
takeWithoutCommit
public static Set<String> takeWithoutCommit(Channel channel, Transaction tx, int number)
{    Set<String> events = Sets.newHashSet();    tx.begin();    for (int i = 0; i < number; i++) {        Event e = channel.take();        if (e == null) {            break;        }        events.add(new String(e.getBody()));    }    return events;}
b80f9b4b06632bb6e0f56590a5166ac1dc79c727c3868357443f99cbf56b034c
getAllLogs
public static List<File> getAllLogs(File[] dataDirs)
{    List<File> result = Lists.newArrayList();    for (File dataDir : dataDirs) {        result.addAll(LogUtils.getLogs(dataDir));    }    return result;}
06f13c3d05ba8718b9a9f629e492ef8ae8c046efe0931204143ec8127d9f1469
forceCheckpoint
public static void forceCheckpoint(FileChannel channel)
{    Log log = field("log").ofType(Log.class).in(channel).get();    Assert.assertTrue("writeCheckpoint returned false", method("writeCheckpoint").withReturnType(Boolean.class).withParameterTypes(Boolean.class).in(log).invoke(true));}
684fe18a5dd446253baa1a9dc19f012e5e724ad9376d3fe22e21767fe1a72729
takeEvents
public static Set<String> takeEvents(Channel channel, int batchSize) throws Exception
{    return takeEvents(channel, batchSize, false);}
e211b6a2ab54e9581bd7d8032d6e8b39cfac6bd6b571e29d9f0708226bd530f9
takeEvents
public static Set<String> takeEvents(Channel channel, int batchSize, boolean checkForCorruption) throws Exception
{    return takeEvents(channel, batchSize, Integer.MAX_VALUE, checkForCorruption);}
69478d79861e1bc0c05184f75aaf7a1ad46e168ac3acdc1fd622fce37a965e75
takeEvents
public static Set<String> takeEvents(Channel channel, int batchSize, int numEvents) throws Exception
{    return takeEvents(channel, batchSize, numEvents, false);}
184ada3b2d848ea4ac6cd18794160601cf9517e341e457ef2a7dffa37cc29cf2
takeEvents
public static Set<String> takeEvents(Channel channel, int batchSize, int numEvents, boolean checkForCorruption) throws Exception
{    Set<String> result = Sets.newHashSet();    for (int i = 0; i < numEvents; i += batchSize) {        Transaction transaction = channel.getTransaction();        try {            transaction.begin();            for (int j = 0; j < batchSize; j++) {                Event event;                try {                    event = channel.take();                } catch (ChannelException ex) {                    Throwable th = ex;                    String msg;                    if (checkForCorruption) {                        msg = "Corrupt event found. Please run File Channel";                        th = ex.getCause();                    } else {                        msg = "Take list for FileBackedTransaction, capacity";                    }                    Assert.assertTrue(th.getMessage().startsWith(msg));                    if (checkForCorruption) {                        throw (Exception) th;                    }                    transaction.commit();                    return result;                }                if (event == null) {                    transaction.commit();                    return result;                }                result.add(new String(event.getBody(), Charsets.UTF_8));            }            transaction.commit();        } catch (Throwable ex) {            transaction.rollback();            throw new RuntimeException(ex);        } finally {            transaction.close();        }    }    return result;}
bcd3739fd0699a4b9d0532694f7363ce576abf42e3ef678fa681062e72977d4d
consumeChannel
public static Set<String> consumeChannel(Channel channel) throws Exception
{    return consumeChannel(channel, false);}
03d760178a30f752fdb35e8f25f29b444c9efacf8b72bc0f276910585cb039c3
consumeChannel
public static Set<String> consumeChannel(Channel channel, boolean checkForCorruption) throws Exception
{    Set<String> result = Sets.newHashSet();    int[] batchSizes = new int[] { 1000, 100, 10, 1 };    for (int i = 0; i < batchSizes.length; i++) {        while (true) {            Set<String> batch = takeEvents(channel, batchSizes[i], checkForCorruption);            if (batch.isEmpty()) {                break;            }            result.addAll(batch);        }    }    return result;}
60fab8f658a926d8116a6617b7eb10dca531da92fa9c43146f79dc0516d9e89a
fillChannel
public static Set<String> fillChannel(Channel channel, String prefix) throws Exception
{    Set<String> result = Sets.newHashSet();    int[] batchSizes = new int[] { 1000, 100, 10, 1 };    for (int i = 0; i < batchSizes.length; i++) {        try {            while (true) {                Set<String> batch = putEvents(channel, prefix, batchSizes[i], Integer.MAX_VALUE, true);                if (batch.isEmpty()) {                    break;                }                result.addAll(batch);            }        } catch (ChannelException e) {            Assert.assertTrue(("The channel has reached it's capacity. This might " + "be the result of a sink on the channel having too low of batch " + "size, a downstream system running slower than normal, or that " + "the channel capacity is just too low. [channel=" + channel.getName() + "]").equals(e.getMessage()) || e.getMessage().startsWith("Put queue for FileBackedTransaction of capacity "));        }    }    return result;}
95db1a55618fb744fb3ccf72e87cd79678b33e4b5ba262c857d428db8dcd37c7
putEvents
public static Set<String> putEvents(Channel channel, String prefix, int batchSize, int numEvents) throws Exception
{    return putEvents(channel, prefix, batchSize, numEvents, false);}
247926e36e384aa9e5defc586d005f1e3c143ea8bbfd1ad3d1e6af4f8ff706b7
putEvents
public static Set<String> putEvents(Channel channel, String prefix, int batchSize, int numEvents, boolean untilCapacityIsReached) throws Exception
{    Set<String> result = Sets.newHashSet();    for (int i = 0; i < numEvents; i += batchSize) {        Transaction transaction = channel.getTransaction();        transaction.begin();        try {            Set<String> batch = Sets.newHashSet();            for (int j = 0; j < batchSize; j++) {                String s = prefix + "-" + i + "-" + j + "-" + UUID.randomUUID();                Event event = EventBuilder.withBody(s.getBytes(Charsets.UTF_8));                channel.put(event);                batch.add(s);            }            transaction.commit();            result.addAll(batch);        } catch (Exception ex) {            transaction.rollback();            if (untilCapacityIsReached && ex instanceof ChannelException && ("The channel has reached it's capacity. " + "This might be the result of a sink on the channel having too " + "low of batch size, a downstream system running slower than " + "normal, or that the channel capacity is just too low. " + "[channel=" + channel.getName() + "]").equals(ex.getMessage())) {                break;            }            throw ex;        } finally {            transaction.close();        }    }    return result;}
8b9858c86ca527b03371a948940cddf6ad417139933560763c149243d465548e
copyDecompressed
public static void copyDecompressed(String resource, File output) throws IOException
{    URL input = Resources.getResource(resource);    FileOutputStream fos = new FileOutputStream(output);    GZIPInputStream gzis = new GZIPInputStream(input.openStream());    ByteStreams.copy(gzis, fos);    fos.close();    gzis.close();}
bb55ac345eaba267fb992b01c69a6a67622147bff79ecfe4bb60133851575c10
createFileChannelContext
public static Context createFileChannelContext(String checkpointDir, String dataDir, String backupDir, Map<String, String> overrides)
{    Context context = new Context();    context.put(FileChannelConfiguration.CHECKPOINT_DIR, checkpointDir);    if (backupDir != null) {        context.put(FileChannelConfiguration.BACKUP_CHECKPOINT_DIR, backupDir);    }    context.put(FileChannelConfiguration.DATA_DIRS, dataDir);    context.put(FileChannelConfiguration.KEEP_ALIVE, String.valueOf(1));    context.put(FileChannelConfiguration.CAPACITY, String.valueOf(10000));    context.putAll(overrides);    return context;}
6d110278d627e53bc461536d9f3537fc04769c9fb046cd97f610e61f66981d13
createFileChannel
public static FileChannel createFileChannel(String checkpointDir, String dataDir, Map<String, String> overrides)
{    return createFileChannel(checkpointDir, dataDir, null, overrides);}
bb180e8036d5b96c15d47a37a9c81cd9063da35d9ba128ea7f471e03cb8cb6b6
createFileChannel
public static FileChannel createFileChannel(String checkpointDir, String dataDir, String backupDir, Map<String, String> overrides)
{    FileChannel channel = new FileChannel();    channel.setName("FileChannel-" + UUID.randomUUID());    Context context = createFileChannelContext(checkpointDir, dataDir, backupDir, overrides);    Configurables.configure(channel, context);    return channel;}
e104c556a1faf841a3344f0af4b9acfde7a16e8285ee3c5059ed4fe978d77d12
writeStringToFile
public static File writeStringToFile(File baseDir, String name, String text) throws IOException
{    File passwordFile = new File(baseDir, name);    Files.write(text, passwordFile, Charsets.UTF_8);    return passwordFile;}
b7ac0667b74faa9a4a0416c81473aab7a7f62e804ceff8385e2ef7f8f4b37b3d
testSetSeed
public void testSetSeed()
{    long current = WriteOrderOracle.next();    current += Integer.MAX_VALUE;    WriteOrderOracle.setSeed(current);    Assert.assertTrue(WriteOrderOracle.next() > System.currentTimeMillis());}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return getName();}
239fbe3eb64d679cbac1161825b07d6a8436ead3c6c3d140d9caec2275827023
getName
public String getName()
{    return name;}
c33f77a3eda94397499aa55de90aaff8823a7f1506b6d1bc5ae6e4b8cdf125e9
getValidationQuery
public String getValidationQuery()
{    return validationQuery;}
3007a8f2f4344f37e0ea865f5c68caff3a1eeb7faeecb8e9284846efd748cf0c
getByName
public static DatabaseType getByName(String dbName)
{    DatabaseType type = null;    try {        type = DatabaseType.valueOf(dbName.trim().toUpperCase(Locale.ENGLISH));    } catch (IllegalArgumentException ex) {        type = DatabaseType.OTHER;    }    return type;}
058844389afa5b72c3fd7c8bd66386590c82d7b305410188bbe7bc7722271882
schemaExists
public boolean schemaExists()
{    Connection connection = null;    Statement stmt = null;    try {        connection = dataSource.getConnection();        stmt = connection.createStatement();        ResultSet rset = stmt.executeQuery(QUREY_SYSCHEMA_FLUME);        if (!rset.next()) {            LOGGER.warn("Schema for FLUME does not exist");            return false;        }        String flumeSchemaId = rset.getString(1);        LOGGER.debug("Flume schema ID: " + flumeSchemaId);        connection.commit();    } catch (SQLException ex) {        try {            connection.rollback();        } catch (SQLException ex2) {            LOGGER.error("Unable to rollback transaction", ex2);        }        throw new JdbcChannelException("Unable to query schema", ex);    } finally {        if (stmt != null) {            try {                stmt.close();            } catch (SQLException ex) {                LOGGER.error("Unable to close schema lookup stmt", ex);            }        }        if (connection != null) {            try {                connection.close();            } catch (SQLException ex) {                LOGGER.error("Unable to close connection", ex);            }        }    }    return true;}
aa9c667222ad93cbc38ef7187461b1b89ab142158f6ebd3af2f92fd13db9dd42
createSchemaObjects
public void createSchemaObjects(boolean createForeignKeys, boolean createIndex)
{    runQuery(QUERY_CREATE_SCHEMA_FLUME);    runQuery(QUERY_CREATE_TABLE_FL_EVENT);    if (createForeignKeys) {        runQuery(QUERY_CREATE_TABLE_FL_PLSPILL_FK);        runQuery(QUERY_CREATE_TABLE_FL_HEADER_FK);        runQuery(QUERY_CREATE_TABLE_FL_NMSPILL_FK);        runQuery(QUERY_CREATE_TABLE_FL_VLSPILL_FK);    } else {        runQuery(QUERY_CREATE_TABLE_FL_PLSPILL_NOFK);        runQuery(QUERY_CREATE_TABLE_FL_HEADER_NOFK);        runQuery(QUERY_CREATE_TABLE_FL_NMSPILL_NOFK);        runQuery(QUERY_CREATE_TABLE_FL_VLSPILL_NOFK);    }    if (createIndex) {        runQuery(QUERY_CREATE_INDEX_FLE_CHANNEL);        runQuery(QUERY_CREATE_INDEX_FLH_EVENT);        runQuery(QUERY_CREATE_INDEX_FLP_EVENT);        runQuery(QUERY_CREATE_INDEX_FLN_HEADER);        runQuery(QUERY_CREATE_INDEX_FLV_HEADER);    }}
8dfe0f88e223756a229820e8f35327ada18643b1ef54e44a8b33a0f8722c74af
validateSchema
public void validateSchema()
{    verifyTableStructure(SCHEMA_FLUME, TABLE_FL_EVENT_NAME, COLUMN_FLE_ID, COLUMN_FLE_PAYLOAD, COLUMN_FLE_CHANNEL, COLUMN_FLE_SPILL);    verifyTableStructure(SCHEMA_FLUME, TABLE_FL_PLSPILL_NAME, COLUMN_FLP_EVENT, COLUMN_FLP_SPILL);    verifyTableStructure(SCHEMA_FLUME, TABLE_FL_HEADER_NAME, COLUMN_FLH_ID, COLUMN_FLH_EVENT, COLUMN_FLH_NAME, COLUMN_FLH_VALUE, COLUMN_FLH_NMSPILL, COLUMN_FLH_VLSPILL);    verifyTableStructure(SCHEMA_FLUME, TABLE_FL_NMSPILL_NAME, COLUMN_FLN_HEADER, COLUMN_FLN_SPILL);    verifyTableStructure(SCHEMA_FLUME, TABLE_FL_VLSPILL_NAME, COLUMN_FLV_HEADER, COLUMN_FLV_SPILL);}
2b9fc5ac67a6a53349b843774fb89084a057a12aabed0ae3c2775648680edf73
verifyTableStructure
private void verifyTableStructure(String schemaName, String tableName, String... columns)
{    Set<String> columnNames = new HashSet<String>();    Connection connection = null;    PreparedStatement pStmt = null;    try {        connection = dataSource.getConnection();        pStmt = connection.prepareStatement(COLUMN_LOOKUP_QUERY);        pStmt.setString(1, tableName);        pStmt.setString(2, schemaName);        ResultSet rset = pStmt.executeQuery();        while (rset.next()) {            columnNames.add(rset.getString(1));        }        connection.commit();    } catch (SQLException ex) {        try {            connection.rollback();        } catch (SQLException ex2) {            LOGGER.error("Unable to rollback transaction", ex2);        }        throw new JdbcChannelException("Unable to run query: " + COLUMN_LOOKUP_QUERY + ": 1=" + tableName + ", 2=" + schemaName, ex);    } finally {        if (pStmt != null) {            try {                pStmt.close();            } catch (SQLException ex) {                LOGGER.error("Unable to close statement", ex);            }            if (connection != null) {                try {                    connection.close();                } catch (SQLException ex) {                    LOGGER.error("Unable to close connection", ex);                }            }        }    }    Set<String> columnDiff = new HashSet<String>();    columnDiff.addAll(columnNames);        StringBuilder sb = new StringBuilder("{");    boolean first = true;    for (String column : columns) {        columnDiff.remove(column);        if (first) {            first = false;        } else {            sb.append(", ");        }        sb.append(column);    }    sb.append("}");    String expectedColumns = sb.toString();    if (LOGGER.isDebugEnabled()) {        LOGGER.debug("Table " + schemaName + "." + tableName + " expected columns: " + expectedColumns + ", actual columns: " + columnNames);    }    if (columnNames.size() != columns.length || columnDiff.size() != 0) {        throw new JdbcChannelException("Expected table " + schemaName + "." + tableName + " to have columns: " + expectedColumns + ". Instead " + "found columns: " + columnNames);    }}
8391881ef7559e1f7733e672bfcc176c3cee6c540d00e36b94782fd7ef6cab88
runQuery
private void runQuery(String query)
{    Connection connection = null;    Statement stmt = null;    try {        connection = dataSource.getConnection();        stmt = connection.createStatement();        if (stmt.execute(query)) {            ResultSet rset = stmt.getResultSet();            int count = 0;            while (rset.next()) {                count++;            }            LOGGER.info("QUERY(" + query + ") produced unused resultset with " + count + " rows");        } else {            int updateCount = stmt.getUpdateCount();            LOGGER.info("QUERY(" + query + ") Update count: " + updateCount);        }        connection.commit();    } catch (SQLException ex) {        try {            connection.rollback();        } catch (SQLException ex2) {            LOGGER.error("Unable to rollback transaction", ex2);        }        throw new JdbcChannelException("Unable to run query: " + query, ex);    } finally {        if (stmt != null) {            try {                stmt.close();            } catch (SQLException ex) {                LOGGER.error("Unable to close statement", ex);            }            if (connection != null) {                try {                    connection.close();                } catch (SQLException ex) {                    LOGGER.error("Unable to close connection", ex);                }            }        }    }}
f429304ed375b13e68f12aa5b8e637cd421697c3a622e823822504aba7df7c0c
storeEvent
public void storeEvent(PersistableEvent pe, Connection connection)
{        byte[] basePayload = pe.getBasePayload();    byte[] spillPayload = pe.getSpillPayload();    boolean hasSpillPayload = (spillPayload != null);    String channelName = pe.getChannelName();    LOGGER.debug("Preparing insert event: " + pe);    PreparedStatement baseEventStmt = null;    PreparedStatement spillEventStmt = null;    PreparedStatement baseHeaderStmt = null;    PreparedStatement headerNameSpillStmt = null;    PreparedStatement headerValueSpillStmt = null;    try {        baseEventStmt = connection.prepareStatement(STMT_INSERT_EVENT_BASE, Statement.RETURN_GENERATED_KEYS);        baseEventStmt.setBytes(1, basePayload);        baseEventStmt.setString(2, channelName);        baseEventStmt.setBoolean(3, hasSpillPayload);        int baseEventCount = baseEventStmt.executeUpdate();        if (baseEventCount != 1) {            throw new JdbcChannelException("Invalid update count on base " + "event insert: " + baseEventCount);        }                ResultSet eventIdResult = baseEventStmt.getGeneratedKeys();        if (!eventIdResult.next()) {            throw new JdbcChannelException("Unable to retrieive inserted event-id");        }        long eventId = eventIdResult.getLong(1);        pe.setEventId(eventId);                if (hasSpillPayload) {            spillEventStmt = connection.prepareStatement(STMT_INSERT_EVENT_SPILL);            spillEventStmt.setLong(1, eventId);            spillEventStmt.setBinaryStream(2, new ByteArrayInputStream(spillPayload), spillPayload.length);            int spillEventCount = spillEventStmt.executeUpdate();            if (spillEventCount != 1) {                throw new JdbcChannelException("Invalid update count on spill " + "event insert: " + spillEventCount);            }        }                List<HeaderEntry> headers = pe.getHeaderEntries();        if (headers != null && headers.size() > 0) {            List<HeaderEntry> headerWithNameSpill = new ArrayList<HeaderEntry>();            List<HeaderEntry> headerWithValueSpill = new ArrayList<HeaderEntry>();            baseHeaderStmt = connection.prepareStatement(STMT_INSERT_HEADER_BASE, Statement.RETURN_GENERATED_KEYS);            Iterator<HeaderEntry> it = headers.iterator();            while (it.hasNext()) {                HeaderEntry entry = it.next();                SpillableString name = entry.getName();                SpillableString value = entry.getValue();                baseHeaderStmt.setLong(1, eventId);                baseHeaderStmt.setString(2, name.getBase());                baseHeaderStmt.setString(3, value.getBase());                baseHeaderStmt.setBoolean(4, name.hasSpill());                baseHeaderStmt.setBoolean(5, value.hasSpill());                int updateCount = baseHeaderStmt.executeUpdate();                if (updateCount != 1) {                    throw new JdbcChannelException("Unexpected update header count: " + updateCount);                }                ResultSet headerIdResultSet = baseHeaderStmt.getGeneratedKeys();                if (!headerIdResultSet.next()) {                    throw new JdbcChannelException("Unable to retrieve inserted header id");                }                long headerId = headerIdResultSet.getLong(1);                entry.setId(headerId);                if (name.hasSpill()) {                    headerWithNameSpill.add(entry);                }                if (value.hasSpill()) {                    headerWithValueSpill.add(entry);                }            }                        if (headerWithNameSpill.size() > 0) {                LOGGER.debug("Number of headers with name spill: " + headerWithNameSpill.size());                headerNameSpillStmt = connection.prepareStatement(STMT_INSERT_HEADER_NAME_SPILL);                for (HeaderEntry entry : headerWithNameSpill) {                    String nameSpill = entry.getName().getSpill();                    headerNameSpillStmt.setLong(1, entry.getId());                    headerNameSpillStmt.setString(2, nameSpill);                    headerNameSpillStmt.addBatch();                }                int[] nameSpillUpdateCount = headerNameSpillStmt.executeBatch();                if (nameSpillUpdateCount.length != headerWithNameSpill.size()) {                    throw new JdbcChannelException("Unexpected update count for header " + "name spills: expected " + headerWithNameSpill.size() + ", " + "found " + nameSpillUpdateCount.length);                }                for (int i = 0; i < nameSpillUpdateCount.length; i++) {                    if (nameSpillUpdateCount[i] != 1) {                        throw new JdbcChannelException("Unexpected update count for " + "header name spill at position " + i + ", value: " + nameSpillUpdateCount[i]);                    }                }            }                        if (headerWithValueSpill.size() > 0) {                LOGGER.debug("Number of headers with value spill: " + headerWithValueSpill.size());                headerValueSpillStmt = connection.prepareStatement(STMT_INSERT_HEADER_VALUE_SPILL);                for (HeaderEntry entry : headerWithValueSpill) {                    String valueSpill = entry.getValue().getSpill();                    headerValueSpillStmt.setLong(1, entry.getId());                    headerValueSpillStmt.setString(2, valueSpill);                    headerValueSpillStmt.addBatch();                }                int[] valueSpillUpdateCount = headerValueSpillStmt.executeBatch();                if (valueSpillUpdateCount.length != headerWithValueSpill.size()) {                    throw new JdbcChannelException("Unexpected update count for header " + "value spills: expected " + headerWithValueSpill.size() + ", " + "found " + valueSpillUpdateCount.length);                }                for (int i = 0; i < valueSpillUpdateCount.length; i++) {                    if (valueSpillUpdateCount[i] != 1) {                        throw new JdbcChannelException("Unexpected update count for " + "header value spill at position " + i + ", value: " + valueSpillUpdateCount[i]);                    }                }            }        }    } catch (SQLException ex) {        throw new JdbcChannelException("Unable to persist event: " + pe, ex);    } finally {        if (baseEventStmt != null) {            try {                baseEventStmt.close();            } catch (SQLException ex) {                LOGGER.error("Unable to close base event statement", ex);            }        }        if (spillEventStmt != null) {            try {                spillEventStmt.close();            } catch (SQLException ex) {                LOGGER.error("Unable to close spill event statement", ex);            }        }        if (baseHeaderStmt != null) {            try {                baseHeaderStmt.close();            } catch (SQLException ex) {                LOGGER.error("Unable to close base header statement", ex);            }        }        if (headerNameSpillStmt != null) {            try {                headerNameSpillStmt.close();            } catch (SQLException ex) {                LOGGER.error("Unable to close header name spill statement", ex);            }        }        if (headerValueSpillStmt != null) {            try {                headerValueSpillStmt.close();            } catch (SQLException ex) {                LOGGER.error("Unable to close header value spill statement", ex);            }        }    }    LOGGER.debug("Event persisted: " + pe);}
c22c36cead03f4a7bcf5a9d8c329c9258a04676f5f6dbd8dd316db4fad1b82ca
fetchAndDeleteEvent
public PersistableEvent fetchAndDeleteEvent(String channel, Connection connection)
{    PersistableEvent.Builder peBuilder = null;    PreparedStatement baseEventFetchStmt = null;    PreparedStatement spillEventFetchStmt = null;    InputStream payloadInputStream = null;    PreparedStatement baseHeaderFetchStmt = null;    PreparedStatement nameSpillHeaderStmt = null;    PreparedStatement valueSpillHeaderStmt = null;    PreparedStatement deleteSpillEventStmt = null;    PreparedStatement deleteNameSpillHeaderStmt = null;    PreparedStatement deleteValueSpillHeaderStmt = null;    PreparedStatement deleteBaseHeaderStmt = null;    PreparedStatement deleteBaseEventStmt = null;    try {        baseEventFetchStmt = connection.prepareStatement(STMT_FETCH_PAYLOAD_BASE);        baseEventFetchStmt.setString(1, channel);        ResultSet rsetBaseEvent = baseEventFetchStmt.executeQuery();        if (!rsetBaseEvent.next()) {                        LOGGER.debug("No events found for channel: " + channel);            return null;        }                long eventId = rsetBaseEvent.getLong(1);        peBuilder = new PersistableEvent.Builder(channel, eventId);        peBuilder.setBasePayload(rsetBaseEvent.getBytes(2));        boolean hasSpill = rsetBaseEvent.getBoolean(3);        if (hasSpill) {            spillEventFetchStmt = connection.prepareStatement(STMT_FETCH_PAYLOAD_SPILL);            spillEventFetchStmt.setLong(1, eventId);            ResultSet rsetSpillEvent = spillEventFetchStmt.executeQuery();            if (!rsetSpillEvent.next()) {                throw new JdbcChannelException("Payload spill expected but not " + "found for event: " + eventId);            }            Blob payloadSpillBlob = rsetSpillEvent.getBlob(1);            payloadInputStream = payloadSpillBlob.getBinaryStream();            ByteArrayOutputStream spillStream = new ByteArrayOutputStream();            byte[] buffer = new byte[1024];            int length = 0;            while ((length = payloadInputStream.read(buffer)) != -1) {                spillStream.write(buffer, 0, length);            }            peBuilder.setSpillPayload(spillStream.toByteArray());                        deleteSpillEventStmt = connection.prepareStatement(STMT_DELETE_EVENT_SPILL);            deleteSpillEventStmt.setLong(1, eventId);            int updateCount = deleteSpillEventStmt.executeUpdate();            if (updateCount != 1) {                throw new JdbcChannelException("Unexpected row count for spill " + "delete: " + updateCount);            }        }        if (rsetBaseEvent.next()) {            throw new JdbcChannelException("More than expected events retrieved");        }                List<Long> nameSpillHeaders = null;        List<Long> valueSpillHeaders = null;        baseHeaderFetchStmt = connection.prepareStatement(STMT_FETCH_HEADER_BASE);        baseHeaderFetchStmt.setLong(1, eventId);                int headerCount = 0;        ResultSet rsetBaseHeader = baseHeaderFetchStmt.executeQuery();        while (rsetBaseHeader.next()) {            headerCount++;            long headerId = rsetBaseHeader.getLong(1);            String baseName = rsetBaseHeader.getString(2);            String baseValue = rsetBaseHeader.getString(3);            boolean hasNameSpill = rsetBaseHeader.getBoolean(4);            boolean hasValueSpill = rsetBaseHeader.getBoolean(5);            peBuilder.setHeader(headerId, baseName, baseValue);            if (hasNameSpill) {                if (nameSpillHeaders == null) {                    nameSpillHeaders = new ArrayList<Long>();                }                nameSpillHeaders.add(headerId);            }            if (hasValueSpill) {                if (valueSpillHeaders == null) {                    valueSpillHeaders = new ArrayList<Long>();                }                valueSpillHeaders.add(headerId);            }        }        if (nameSpillHeaders != null) {            nameSpillHeaderStmt = connection.prepareStatement(STMT_FETCH_HEADER_NAME_SPILL);            deleteNameSpillHeaderStmt = connection.prepareStatement(STMT_DELETE_HEADER_NAME_SPILL);            for (long headerId : nameSpillHeaders) {                nameSpillHeaderStmt.setLong(1, headerId);                ResultSet rsetHeaderNameSpill = nameSpillHeaderStmt.executeQuery();                if (!rsetHeaderNameSpill.next()) {                    throw new JdbcChannelException("Name spill was set for header " + headerId + " but was not found");                }                String nameSpill = rsetHeaderNameSpill.getString(1);                peBuilder.setHeaderNameSpill(headerId, nameSpill);                deleteNameSpillHeaderStmt.setLong(1, headerId);                deleteNameSpillHeaderStmt.addBatch();            }                        int[] headerNameSpillDelete = deleteNameSpillHeaderStmt.executeBatch();            if (headerNameSpillDelete.length != nameSpillHeaders.size()) {                throw new JdbcChannelException("Unexpected number of header name " + "spill deletes: expected " + nameSpillHeaders.size() + ", found: " + headerNameSpillDelete.length);            }            for (int numRowsAffected : headerNameSpillDelete) {                if (numRowsAffected != 1) {                    throw new JdbcChannelException("Unexpected number of deleted rows " + "for header name spill deletes: " + numRowsAffected);                }            }        }        if (valueSpillHeaders != null) {            valueSpillHeaderStmt = connection.prepareStatement(STMT_FETCH_HEADER_VALUE_SPILL);            deleteValueSpillHeaderStmt = connection.prepareStatement(STMT_DELETE_HEADER_VALUE_SPILL);            for (long headerId : valueSpillHeaders) {                valueSpillHeaderStmt.setLong(1, headerId);                ResultSet rsetHeaderValueSpill = valueSpillHeaderStmt.executeQuery();                if (!rsetHeaderValueSpill.next()) {                    throw new JdbcChannelException("Value spill was set for header " + headerId + " but was not found");                }                String valueSpill = rsetHeaderValueSpill.getString(1);                peBuilder.setHeaderValueSpill(headerId, valueSpill);                deleteValueSpillHeaderStmt.setLong(1, headerId);                deleteValueSpillHeaderStmt.addBatch();            }                        int[] headerValueSpillDelete = deleteValueSpillHeaderStmt.executeBatch();            if (headerValueSpillDelete.length != valueSpillHeaders.size()) {                throw new JdbcChannelException("Unexpected number of header value " + "spill deletes: expected " + valueSpillHeaders.size() + ", found: " + headerValueSpillDelete.length);            }            for (int numRowsAffected : headerValueSpillDelete) {                if (numRowsAffected != 1) {                    throw new JdbcChannelException("Unexpected number of deleted rows " + "for header value spill deletes: " + numRowsAffected);                }            }        }                if (headerCount > 0) {            deleteBaseHeaderStmt = connection.prepareStatement(STMT_DELETE_HEADER_BASE);            deleteBaseHeaderStmt.setLong(1, eventId);            int rowCount = deleteBaseHeaderStmt.executeUpdate();            if (rowCount != headerCount) {                throw new JdbcChannelException("Unexpected base header delete count: " + "expected: " + headerCount + ", found: " + rowCount);            }        }                deleteBaseEventStmt = connection.prepareStatement(STMT_DELETE_EVENT_BASE);        deleteBaseEventStmt.setLong(1, eventId);        int rowCount = deleteBaseEventStmt.executeUpdate();        if (rowCount != 1) {            throw new JdbcChannelException("Unexpected row count for delete of " + "event-id: " + eventId + ", count: " + rowCount);        }    } catch (SQLException ex) {        throw new JdbcChannelException("Unable to retrieve event", ex);    } catch (IOException ex) {        throw new JdbcChannelException("Unable to read data", ex);    } finally {        if (payloadInputStream != null) {            try {                payloadInputStream.close();            } catch (IOException ex) {                LOGGER.error("Unable to close payload spill stream", ex);            }        }        if (baseEventFetchStmt != null) {            try {                baseEventFetchStmt.close();            } catch (SQLException ex) {                LOGGER.error("Unable to close base event fetch statement", ex);            }        }        if (spillEventFetchStmt != null) {            try {                spillEventFetchStmt.close();            } catch (SQLException ex) {                LOGGER.error("Unable to close spill event fetch statment", ex);            }        }        if (deleteSpillEventStmt != null) {            try {                deleteSpillEventStmt.close();            } catch (SQLException ex) {                LOGGER.error("Unable to close event spill delete statement", ex);            }        }        if (baseHeaderFetchStmt != null) {            try {                baseHeaderFetchStmt.close();            } catch (SQLException ex) {                LOGGER.error("Unable to close base header fetch statement", ex);            }        }        if (nameSpillHeaderStmt != null) {            try {                nameSpillHeaderStmt.close();            } catch (SQLException ex) {                LOGGER.error("Unable to close name spill fetch statement", ex);            }        }        if (valueSpillHeaderStmt != null) {            try {                valueSpillHeaderStmt.close();            } catch (SQLException ex) {                LOGGER.error("Unable to close value spill fetch statement", ex);            }        }        if (deleteNameSpillHeaderStmt != null) {            try {                deleteNameSpillHeaderStmt.close();            } catch (SQLException ex) {                LOGGER.error("Unable to close value spill delete statement", ex);            }        }        if (deleteValueSpillHeaderStmt != null) {            try {                deleteValueSpillHeaderStmt.close();            } catch (SQLException ex) {                LOGGER.error("Unable to close value spill delete statement", ex);            }        }        if (deleteBaseHeaderStmt != null) {            try {                deleteBaseHeaderStmt.close();            } catch (SQLException ex) {                LOGGER.error("Unable to close base header delete statement", ex);            }        }        if (deleteBaseEventStmt != null) {            try {                deleteBaseEventStmt.close();            } catch (SQLException ex) {                LOGGER.error("Unable to close base event delete statement", ex);            }        }    }    return peBuilder.build();}
d6b29990b793a55eb722c9babe2a429420cc0c1bc6c70a4f68bb207a5a813dd3
getChannelSize
public long getChannelSize(Connection connection)
{    long size = 0L;    Statement stmt = null;    try {        stmt = connection.createStatement();        stmt.execute(QUERY_CHANNEL_SIZE);        ResultSet rset = stmt.getResultSet();        if (!rset.next()) {            throw new JdbcChannelException("Failed to determine channel size: " + "Query (" + QUERY_CHANNEL_SIZE + ") did not produce any results");        }        size = rset.getLong(1);        connection.commit();    } catch (SQLException ex) {        try {            connection.rollback();        } catch (SQLException ex2) {            LOGGER.error("Unable to rollback transaction", ex2);        }        throw new JdbcChannelException("Unable to run query: " + QUERY_CHANNEL_SIZE, ex);    } finally {        if (stmt != null) {            try {                stmt.close();            } catch (SQLException ex) {                LOGGER.error("Unable to close statement", ex);            }        }    }    return size;}
e4bf2219790f20c2d4001a7f5c63acfdb7c8b37f31fb070d3ff0611da90bd7ab
initialize
public void initialize(Context context)
{    LOGGER.debug("Initializing JDBC Channel provider");    initializeSystemProperties(context);    initializeDataSource(context);    initializeSchema(context);    initializeChannelState(context);}
a4537da084f7dce4dd13d896327e414a20d947a1bbc1ba57186d17dcea381c67
initializeSystemProperties
private void initializeSystemProperties(Context context)
{    Map<String, String> sysProps = new HashMap<String, String>();    Map<String, String> sysPropsOld = context.getSubProperties(ConfigurationConstants.OLD_CONFIG_JDBC_SYSPROP_PREFIX);    if (sysPropsOld.size() > 0) {        LOGGER.warn("Long form configuration prefix \"" + ConfigurationConstants.OLD_CONFIG_JDBC_SYSPROP_PREFIX + "\" is deprecated. Please use the short form prefix \"" + ConfigurationConstants.CONFIG_JDBC_SYSPROP_PREFIX + "\" instead.");        sysProps.putAll(sysPropsOld);    }    Map<String, String> sysPropsNew = context.getSubProperties(ConfigurationConstants.CONFIG_JDBC_SYSPROP_PREFIX);        if (sysPropsNew.size() > 0) {        sysProps.putAll(sysPropsNew);    }    for (String key : sysProps.keySet()) {        String value = sysProps.get(key);        if (key != null && value != null) {            System.setProperty(key, value);        }    }}
dae19b289dab630689965c2b8b59043947e30e2efd79cab52f6db9d65ba03a72
initializeChannelState
private void initializeChannelState(Context context)
{    String maxCapacityStr = getConfigurationString(context, ConfigurationConstants.CONFIG_MAX_CAPACITY, ConfigurationConstants.OLD_CONFIG_MAX_CAPACITY, "0");    long maxCapacitySpecified = 0;    try {        maxCapacitySpecified = Long.parseLong(maxCapacityStr);    } catch (NumberFormatException nfe) {        LOGGER.warn("Invalid value specified for maximum channel capacity: " + maxCapacityStr, nfe);    }    if (maxCapacitySpecified > 0) {        this.maxCapacity = maxCapacitySpecified;        LOGGER.info("Maximum channel capacity: {}", maxCapacity);    } else {        LOGGER.warn("JDBC channel will operate without a capacity limit.");    }    if (maxCapacity > 0) {                JdbcTransactionImpl tx = null;        try {            tx = getTransaction();            tx.begin();            Connection conn = tx.getConnection();            currentSize.set(schemaHandler.getChannelSize(conn));            tx.commit();        } catch (Exception ex) {            tx.rollback();            throw new JdbcChannelException("Failed to initialize current size", ex);        } finally {            if (tx != null) {                tx.close();            }        }        long currentSizeLong = currentSize.get();        if (currentSizeLong > maxCapacity) {            LOGGER.warn("The current size of channel (" + currentSizeLong + ") is more than the specified maximum capacity (" + maxCapacity + "). If this situation persists, it may require resizing and " + "replanning of your deployment.");        }        LOGGER.info("Current channel size: {}", currentSizeLong);    }}
9f9007ff5e6f228400dcc84e9c519eb6a131e84ff1885e48f0b21b06ca4d6a5f
initializeSchema
private void initializeSchema(Context context)
{    String createSchemaFlag = getConfigurationString(context, ConfigurationConstants.CONFIG_CREATE_SCHEMA, ConfigurationConstants.OLD_CONFIG_CREATE_SCHEMA, "true");    boolean createSchema = Boolean.valueOf(createSchemaFlag);    LOGGER.debug("Create schema flag set to: " + createSchema);        schemaHandler = SchemaHandlerFactory.getHandler(databaseType, dataSource);    if (!schemaHandler.schemaExists()) {        if (!createSchema) {            throw new JdbcChannelException("Schema does not exist and " + "auto-generation is disabled. Please enable auto-generation of " + "schema and try again.");        }        String createIndexFlag = getConfigurationString(context, ConfigurationConstants.CONFIG_CREATE_INDEX, ConfigurationConstants.OLD_CONFIG_CREATE_INDEX, "true");        String createForeignKeysFlag = getConfigurationString(context, ConfigurationConstants.CONFIG_CREATE_FK, ConfigurationConstants.OLD_CONFIG_CREATE_FK, "true");        boolean createIndex = Boolean.valueOf(createIndexFlag);        if (!createIndex) {            LOGGER.warn("Index creation is disabled, indexes will not be created.");        }        boolean createForeignKeys = Boolean.valueOf(createForeignKeysFlag);        if (createForeignKeys) {            LOGGER.info("Foreign Key Constraints will be enabled.");        } else {            LOGGER.info("Foreign Key Constratins will be disabled.");        }                schemaHandler.createSchemaObjects(createForeignKeys, createIndex);    }        schemaHandler.validateSchema();}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{    try {        connectionPool.close();    } catch (Exception ex) {        throw new JdbcChannelException("Unable to close connection pool", ex);    }    if (databaseType.equals(DatabaseType.DERBY) && driverClassName.equals(EMBEDDED_DERBY_DRIVER_CLASSNAME)) {                if (connectUrl.startsWith("jdbc:derby:")) {            int index = connectUrl.indexOf(";");            String baseUrl = null;            if (index != -1) {                baseUrl = connectUrl.substring(0, index + 1);            } else {                baseUrl = connectUrl + ";";            }            String shutDownUrl = baseUrl + "shutdown=true";            LOGGER.debug("Attempting to shutdown embedded Derby using URL: " + shutDownUrl);            try {                DriverManager.getConnection(shutDownUrl);            } catch (SQLException ex) {                                if (ex.getErrorCode() != 45000) {                    throw new JdbcChannelException("Unable to shutdown embedded Derby: " + shutDownUrl + " Error Code: " + ex.getErrorCode(), ex);                }                LOGGER.info("Embedded Derby shutdown raised SQL STATE " + "45000 as expected.");            }        } else {            LOGGER.warn("Even though embedded Derby drvier was loaded, the connect " + "URL is of an unexpected form: " + connectUrl + ". Therfore no " + "attempt will be made to shutdown embedded Derby instance.");        }    }    dataSource = null;    txFactory = null;    schemaHandler = null;}
e7b251d92e4ee0314b139e1ee9c231d325c1506bda6354b0acda7c5e9bb08efe
persistEvent
public void persistEvent(String channel, Event event)
{    PersistableEvent persistableEvent = new PersistableEvent(channel, event);    JdbcTransactionImpl tx = null;    try {        tx = getTransaction();        tx.begin();        if (maxCapacity > 0) {            long currentSizeLong = currentSize.get();            if (currentSizeLong >= maxCapacity) {                throw new JdbcChannelException("Channel capacity reached: " + "maxCapacity: " + maxCapacity + ", currentSize: " + currentSizeLong);            }        }                schemaHandler.storeEvent(persistableEvent, tx.getConnection());        tx.incrementPersistedEventCount();        tx.commit();    } catch (Exception ex) {        tx.rollback();        throw new JdbcChannelException("Failed to persist event", ex);    } finally {        if (tx != null) {            tx.close();        }    }    LOGGER.debug("Persisted event: {}", persistableEvent.getEventId());}
18d3b53ac016bfd1f2e8320ce7337d0e227843086718a3157e329b2861d975e4
removeEvent
public Event removeEvent(String channelName)
{    PersistableEvent result = null;    JdbcTransactionImpl tx = null;    try {        tx = getTransaction();        tx.begin();                result = schemaHandler.fetchAndDeleteEvent(channelName, tx.getConnection());        if (result != null) {            tx.incrementRemovedEventCount();        }        tx.commit();    } catch (Exception ex) {        tx.rollback();        throw new JdbcChannelException("Failed to persist event", ex);    } finally {        if (tx != null) {            tx.close();        }    }    if (result != null) {        LOGGER.debug("Removed event: {}", ((PersistableEvent) result).getEventId());    } else {        LOGGER.debug("No event found for removal");    }    return result;}
c9b6d69a238c2a4147b9c265a99464dc6ef2e08e6d907efbe865d18efc60e944
getTransaction
public JdbcTransactionImpl getTransaction()
{    return txFactory.get();}
096442fd6e114247dd330fa20116965b3f3e2a51f5dd480d897861f1ac8c486f
initializeDataSource
private void initializeDataSource(Context context)
{    driverClassName = getConfigurationString(context, ConfigurationConstants.CONFIG_JDBC_DRIVER_CLASS, ConfigurationConstants.OLD_CONFIG_JDBC_DRIVER_CLASS, null);    connectUrl = getConfigurationString(context, ConfigurationConstants.CONFIG_URL, ConfigurationConstants.OLD_CONFIG_URL, null);    String userName = getConfigurationString(context, ConfigurationConstants.CONFIG_USERNAME, ConfigurationConstants.OLD_CONFIG_USERNAME, null);    String password = getConfigurationString(context, ConfigurationConstants.CONFIG_PASSWORD, ConfigurationConstants.OLD_CONFIG_PASSWORD, null);    String jdbcPropertiesFile = getConfigurationString(context, ConfigurationConstants.CONFIG_JDBC_PROPS_FILE, ConfigurationConstants.OLD_CONFIG_JDBC_PROPS_FILE, null);    String dbTypeName = getConfigurationString(context, ConfigurationConstants.CONFIG_DATABASE_TYPE, ConfigurationConstants.OLD_CONFIG_DATABASE_TYPE, null);        if (connectUrl == null || connectUrl.trim().length() == 0) {        LOGGER.warn("No connection URL specified. " + "Using embedded derby database instance.");        driverClassName = DEFAULT_DRIVER_CLASSNAME;        userName = DEFAULT_USERNAME;        password = DEFAULT_PASSWORD;        dbTypeName = DEFAULT_DBTYPE;        String homePath = System.getProperty("user.home").replace('\\', '/');        String defaultDbDir = homePath + "/.flume/jdbc-channel";        File dbDir = new File(defaultDbDir);        String canonicalDbDirPath = null;        try {            canonicalDbDirPath = dbDir.getCanonicalPath();        } catch (IOException ex) {            throw new JdbcChannelException("Unable to find canonical path of dir: " + defaultDbDir, ex);        }        if (!dbDir.exists()) {            if (!dbDir.mkdirs()) {                throw new JdbcChannelException("unable to create directory: " + canonicalDbDirPath);            }        }        connectUrl = "jdbc:derby:" + canonicalDbDirPath + "/db;create=true";                jdbcPropertiesFile = null;        LOGGER.warn("Overriding values for - driver: " + driverClassName + ", user: " + userName + "connectUrl: " + connectUrl + ", jdbc properties file: " + jdbcPropertiesFile + ", dbtype: " + dbTypeName);    }        databaseType = DatabaseType.getByName(dbTypeName);    switch(databaseType) {        case DERBY:        case MYSQL:            break;        default:            throw new JdbcChannelException("Database " + databaseType + " not supported at this time");    }        if (driverClassName == null || driverClassName.trim().length() == 0) {        throw new JdbcChannelException("No jdbc driver specified");    }    try {        Class.forName(driverClassName);    } catch (ClassNotFoundException ex) {        throw new JdbcChannelException("Unable to load driver: " + driverClassName, ex);    }        Properties jdbcProps = new Properties();    if (jdbcPropertiesFile != null && jdbcPropertiesFile.trim().length() > 0) {        File jdbcPropsFile = new File(jdbcPropertiesFile.trim());        if (!jdbcPropsFile.exists()) {            throw new JdbcChannelException("Jdbc properties file does not exist: " + jdbcPropertiesFile);        }        InputStream inStream = null;        try {            inStream = new FileInputStream(jdbcPropsFile);            jdbcProps.load(inStream);        } catch (IOException ex) {            throw new JdbcChannelException("Unable to load jdbc properties " + "from file: " + jdbcPropertiesFile, ex);        } finally {            if (inStream != null) {                try {                    inStream.close();                } catch (IOException ex) {                    LOGGER.error("Unable to close file: " + jdbcPropertiesFile, ex);                }            }        }    }    if (userName != null) {        Object oldUser = jdbcProps.put("user", userName);        if (oldUser != null) {            LOGGER.warn("Overriding user from: " + oldUser + " to: " + userName);        }    }    if (password != null) {        Object oldPass = jdbcProps.put("password", password);        if (oldPass != null) {            LOGGER.warn("Overriding password from the jdbc properties with " + " the one specified explicitly.");        }    }    if (LOGGER.isDebugEnabled()) {        StringBuilder sb = new StringBuilder("JDBC Properties {");        boolean first = true;        Enumeration<?> propertyKeys = jdbcProps.propertyNames();        while (propertyKeys.hasMoreElements()) {            if (first) {                first = false;            } else {                sb.append(", ");            }            String key = (String) propertyKeys.nextElement();            sb.append(key).append("=");            if (key.equalsIgnoreCase("password")) {                sb.append("*******");            } else {                sb.append(jdbcProps.get(key));            }        }        sb.append("}");        LOGGER.debug(sb.toString());    }        String txIsolation = getConfigurationString(context, ConfigurationConstants.CONFIG_TX_ISOLATION_LEVEL, ConfigurationConstants.OLD_CONFIG_TX_ISOLATION_LEVEL, TransactionIsolation.READ_COMMITTED.getName());    TransactionIsolation txIsolationLevel = TransactionIsolation.getByName(txIsolation);    LOGGER.debug("Transaction isolation will be set to: " + txIsolationLevel);        ConnectionFactory connFactory = new DriverManagerConnectionFactory(connectUrl, jdbcProps);    connectionPool = new GenericObjectPool();    String maxActiveConnections = getConfigurationString(context, ConfigurationConstants.CONFIG_MAX_CONNECTIONS, ConfigurationConstants.OLD_CONFIG_MAX_CONNECTIONS, "10");    int maxActive = 10;    if (maxActiveConnections != null && maxActiveConnections.length() > 0) {        try {            maxActive = Integer.parseInt(maxActiveConnections);        } catch (NumberFormatException nfe) {            LOGGER.warn("Max active connections has invalid value: " + maxActiveConnections + ", Using default: " + maxActive);        }    }    LOGGER.debug("Max active connections for the pool: " + maxActive);    connectionPool.setMaxActive(maxActive);    statementPool = new GenericKeyedObjectPoolFactory(null);        new PoolableConnectionFactory(connFactory, connectionPool, statementPool, databaseType.getValidationQuery(), false, false, txIsolationLevel.getCode());    dataSource = new PoolingDataSource(connectionPool);    txFactory = new JdbcTransactionFactory(dataSource, this);}
5bd27b592cd10866c510889805ea91c69d277c1d381e60bd8f2d134daa85b638
updateCurrentChannelSize
protected void updateCurrentChannelSize(long delta)
{    long currentSizeLong = currentSize.addAndGet(delta);    LOGGER.debug("channel size updated to: " + currentSizeLong);}
b83abba8cd10a5b1debb0152a138208cd2c6d290aeacd9c55a6f081620cbd402
getConfigurationString
private String getConfigurationString(Context context, String key, String oldKey, String defaultValue)
{    String oldValue = context.getString(oldKey);    if (oldValue != null && oldValue.length() > 0) {        LOGGER.warn("Long form configuration key \"" + oldKey + "\" is deprecated. Please use the short form key \"" + key + "\" instead.");    }    String value = context.getString(key);    if (value == null) {        if (oldValue != null) {            value = oldValue;        } else {            value = defaultValue;        }    }    return value;}
604c644371506ede00c9a6d1fba30ee121d13ecd7a58c71ac13316e2b908526f
initialValue
protected JdbcTransactionImpl initialValue()
{    return new JdbcTransactionImpl(dataSource, this, providerImpl);}
1e146b07faa919b1916e630a172c03c6ebfc96663a23166e205cd71924113b12
begin
public void begin()
{    if (!active) {        throw new JdbcChannelException("Inactive transaction");    }    if (count == 0) {                try {            connection = dataSource.getConnection();        } catch (SQLException ex) {            throw new JdbcChannelException("Unable to lease connection", ex);        }                try {            connection.clearWarnings();        } catch (SQLException ex) {            LOGGER.error("Error while clearing warnings: " + ex.getErrorCode(), ex);        }    }    count++;    LOGGER.trace("Tx count-begin: " + count + ", rollback: " + rollback);}
609962ed3c13286966d937afa9c301e49ddab59023e4f4c7704fb7ba9630b243
commit
public void commit()
{    if (!active) {        throw new JdbcChannelException("Inactive transaction");    }    if (rollback) {        throw new JdbcChannelException("Cannot commit transaction marked for rollback");    }    LOGGER.trace("Tx count-commit: " + count + ", rollback: " + rollback);}
f1b7a3da67263bf9cf38feebb790935f22fffbce70c05f42446b0a1c1fd2c534
rollback
public void rollback()
{    if (!active) {        throw new JdbcChannelException("Inactive transaction");    }    LOGGER.warn("Marking transaction for rollback");    rollback = true;    LOGGER.trace("Tx count-rollback: " + count + ", rollback: " + rollback);}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{    if (!active) {        throw new JdbcChannelException("Inactive transaction");    }    count--;    LOGGER.debug("Tx count-close: " + count + ", rollback: " + rollback);    if (count == 0) {        active = false;        try {            if (rollback) {                LOGGER.info("Attempting transaction roll-back");                connection.rollback();            } else {                LOGGER.debug("Attempting transaction commit");                connection.commit();                                providerImpl.updateCurrentChannelSize(this.persistedEventCount - this.removedEventCount);                this.persistedEventCount = 0;                this.removedEventCount = 0;            }        } catch (SQLException ex) {            throw new JdbcChannelException("Unable to finalize transaction", ex);        } finally {            if (connection != null) {                                try {                    SQLWarning warning = connection.getWarnings();                    if (warning != null) {                        StringBuilder sb = new StringBuilder("Connection warnigns: ");                        boolean first = true;                        while (warning != null) {                            if (first) {                                first = false;                            } else {                                sb.append("; ");                            }                            sb.append("[").append(warning.getErrorCode()).append("] ");                            sb.append(warning.getMessage());                        }                        LOGGER.warn(sb.toString());                    }                } catch (SQLException ex) {                    LOGGER.error("Error while retrieving warnigns: " + ex.getErrorCode(), ex);                }                                try {                    connection.close();                } catch (SQLException ex) {                    LOGGER.error("Unable to close connection: " + ex.getErrorCode(), ex);                }            }                        txFactory.remove();                        connection = null;            txFactory = null;        }    }}
f6fba2aab02900d9ecf41587a4c7ef0c8a7d42aac5c22d11a6efcedd7e5ae0eb
getConnection
protected Connection getConnection()
{    if (!active) {        throw new JdbcChannelException("Inactive transaction");    }    return connection;}
9c3924a46ac812219a627bdf8772399c7a0ba230ba99acd219bf8da24546d9ab
incrementRemovedEventCount
protected void incrementRemovedEventCount()
{    removedEventCount++;}
7e6a76f3b4d6942cb01cbd7ecf3e80379c104b19bf13c72485c9dafb2bf64e17
incrementPersistedEventCount
protected void incrementPersistedEventCount()
{    persistedEventCount++;}
058844389afa5b72c3fd7c8bd66386590c82d7b305410188bbe7bc7722271882
schemaExists
public boolean schemaExists()
{        return false;}
8dfe0f88e223756a229820e8f35327ada18643b1ef54e44a8b33a0f8722c74af
validateSchema
public void validateSchema()
{}
f429304ed375b13e68f12aa5b8e637cd421697c3a622e823822504aba7df7c0c
storeEvent
public void storeEvent(PersistableEvent pe, Connection connection)
{}
c22c36cead03f4a7bcf5a9d8c329c9258a04676f5f6dbd8dd316db4fad1b82ca
fetchAndDeleteEvent
public PersistableEvent fetchAndDeleteEvent(String channel, Connection connection)
{        return null;}
d6b29990b793a55eb722c9babe2a429420cc0c1bc6c70a4f68bb207a5a813dd3
getChannelSize
public long getChannelSize(Connection connection)
{        return 0;}
aa9c667222ad93cbc38ef7187461b1b89ab142158f6ebd3af2f92fd13db9dd42
createSchemaObjects
public void createSchemaObjects(boolean createForeignKeys, boolean createIndex)
{}
af1b8cf306fde4045ee54ba384634bf5442623cb143a20761f118879f5c5d184
getChannelName
public String getChannelName()
{    return channel;}
f1ef0637b591e17559012d876208e4eb6ee5f5c95b4d45e41aae5b333ec81acf
getBasePayload
public byte[] getBasePayload()
{    return this.basePayload;}
966b34cee106b22740003bd8b130d35a9b3583ce4908d0cb8b2780ee1168c5b5
getSpillPayload
public byte[] getSpillPayload()
{    return this.spillPayload;}
91c6515ca93f12e2e8f471a6be8906aafdcddeb978f971fd500fcb1661729d73
setEventId
protected void setEventId(long eventId)
{    this.eventId = eventId;}
b97d70323e6d2de8952ae45cdb07be4f3acc7d3268b5539bdccd72de5ac23185
getEventId
protected long getEventId()
{    return this.eventId;}
571862733421b239b764028be893cf32936f65d661ab08dd95e0ef2fa0caa89e
getHeaderEntries
public List<HeaderEntry> getHeaderEntries()
{    return headers;}
0f6b56f6c6cb2c16771633d3de46616fbb989f333bc9adb2259b2cd3ebf0ee17
getNameString
public String getNameString()
{    return name.getString();}
f0c26dee33c5c7025eaa5efc87035c7bbcd9f7d304135ff58873152449cb1c3d
getName
public SpillableString getName()
{    return name;}
0cbd7214192142d4f9f5080714100bfba7e9c51bd21bb53410890009b2d82d28
getValueString
public String getValueString()
{    return value.getString();}
a14310aedbbe6b51bcb0c52baf535cf85577c4a9c7eb2f179d31afe484be1d5f
getValue
public SpillableString getValue()
{    return value;}
d7abe103f5df5c3aa1eb4003c8945b73a67b47c633269dc7a92347a534b5ea6c
setId
protected void setId(long headerId)
{    this.headerId = headerId;}
12988e32fb9e7822231bf05b7d2b2013fd70cf350e185d48e6fdacbe7847e62e
getId
public long getId()
{    return headerId;}
f42d3a9ab6fb63af07d71ecf45ac73310a60386e25d3e3e7432f976ffe7e728f
getBase
public String getBase()
{    return base;}
c8c0fb7a0e2b4572f75bbf3917fe1f009027e3cd0d5bf231367763fb02ef03ed
getSpill
public String getSpill()
{    return spill;}
6f98cfba8fd1113c0670baa214bd66d71beaef8f7140e311bc823c3ff4e19591
getString
public String getString()
{    if (spill == null) {        return base;    }    return base + spill;}
7b1fedb2e801d815e375fd9bca581f189570a15e436ed4dfe5b694984bf47d7d
hasSpill
public boolean hasSpill()
{    return spill != null;}
6d1c35600a6f29feedab1769a2763829b83814294b318a32e8c71bf3529059a1
setHeaders
public void setHeaders(Map<String, String> headers)
{    throw new UnsupportedOperationException("Cannot update headers of " + "persistable event");}
a624aa1b85808a74c9f320025ea600169bd6e4692611a44ef53a1970442ef820
getBody
public byte[] getBody()
{    byte[] result = null;    if (spillPayload == null) {        result = Arrays.copyOf(basePayload, basePayload.length);    } else {        result = new byte[basePayload.length + spillPayload.length];        System.arraycopy(basePayload, 0, result, 0, basePayload.length);        System.arraycopy(spillPayload, 0, result, basePayload.length, spillPayload.length);    }    return result;}
b8505eb3e09ba9bb11ab8433148a62af59b6b1a27ffe7e69cf12f0e20e7c76a1
setBody
public void setBody(byte[] body)
{    throw new UnsupportedOperationException("Cannot update payload of " + "persistable event");}
9a691e59a635186c5f7258710b8e44f5caf3510a02999c2c0ea95c8238b813ad
getHeaders
public Map<String, String> getHeaders()
{    Map<String, String> headerMap = null;    if (headers != null) {        headerMap = new HashMap<String, String>();        for (HeaderEntry entry : headers) {            headerMap.put(entry.getNameString(), entry.getValueString());        }    }    return headerMap;}
728177375656d7b08aa55fc55c1930bcc7af766e668c0e39df3f1667f62bd1df
setEventId
public Builder setEventId(long eventId)
{    bEventId = eventId;    return this;}
82d72f4ce1a2690f019bd4e6bf3e00ea54cfb7614c0fe5612155c5c9a1f4dd69
setChannel
public Builder setChannel(String channel)
{    bChannelName = channel;    return this;}
824e34f368eb46d31ad32c143170aa63a929450e9fc2708c91bdcca32dbbdb1f
setBasePayload
public Builder setBasePayload(byte[] basePayload)
{    bBasePayload = basePayload;    return this;}
d5a1d47ae5411be84f5c14279c47f999ab87abd84f680956eeef85f88411e559
setSpillPayload
public Builder setSpillPayload(byte[] spillPayload)
{    bSpillPayload = spillPayload;    return this;}
c723ffb496cbaa521bd50f5dd62acf74f61ce2b1c322e178372f7176adc1459f
setHeader
public Builder setHeader(long headerId, String baseName, String baseValue)
{    if (bHeaderParts == null) {        bHeaderParts = new HashMap<Long, HeaderPart>();    }    HeaderPart hp = new HeaderPart(baseName, baseValue);    if (bHeaderParts.put(headerId, hp) != null) {        throw new JdbcChannelException("Duplicate header found: " + "headerId: " + headerId + ", baseName: " + baseName + ", " + "baseValue: " + baseValue);    }    return this;}
5f964f19b79dda4f472afabc1d5b5d76825b0fe278fec5393497c397a92bb070
setHeaderNameSpill
public Builder setHeaderNameSpill(long headerId, String nameSpill)
{    HeaderPart hp = bHeaderParts.get(headerId);    if (hp == null) {        throw new JdbcChannelException("Header not found for spill: " + headerId);    }    hp.setSpillName(nameSpill);    return this;}
1748c234b9ed606dc91892d00d0ac8c726a9e87f6138d0175b8c82cd5f94a3be
setHeaderValueSpill
public Builder setHeaderValueSpill(long headerId, String valueSpill)
{    HeaderPart hp = bHeaderParts.get(headerId);    if (hp == null) {        throw new JdbcChannelException("Header not found for spill: " + headerId);    }    hp.setSpillValue(valueSpill);    return this;}
ab64dbda919495862894b05c50a5520c8bc6f34a3c7852ba23e26ddf0328b8a0
build
public PersistableEvent build()
{    List<HeaderEntry> bHeaders = new ArrayList<HeaderEntry>();    if (bHeaderParts != null) {        for (long headerId : bHeaderParts.keySet()) {            HeaderPart part = bHeaderParts.get(headerId);            bHeaders.add(part.getEntry(headerId));        }    }    PersistableEvent pe = new PersistableEvent(bEventId, bChannelName, bBasePayload, bSpillPayload, bHeaders);    bEventId = 0L;    bChannelName = null;    bBasePayload = null;    bSpillPayload = null;    bHeaderParts = null;    return pe;}
a100fe31721f4eeb2cb03167188a81b0d1731da47427f916a57524fd71dc80cf
getBaseName
 String getBaseName()
{    return hBaseName;}
fcfb4276f82568bd4911db1ecbff042644a105fee91c7f28db35ffa999371ca1
getBaseValue
 String getBaseValue()
{    return hBaseValue;}
cbfa494c45f896506c3f4f3ecfd720fa29b3472d5f27a42674536737d22ecfa3
getSpillName
 String getSpillName()
{    return hSpillName;}
070ad809700798864b8b06baa87523c3907b3abd4588dd7464cdb3cb3d8cf789
getSpillValue
 String getSpillValue()
{    return hSpillValue;}
469be038442f193263e389d9d436726349333b32f7d3390d0e861b4205bc2f6f
setSpillName
 void setSpillName(String spillName)
{    hSpillName = spillName;}
906067c1511ad1264ebb5a40af682d5ac8b36b700df9955dd3aaf74ac213d4b0
setSpillValue
 void setSpillValue(String spillValue)
{    hSpillValue = spillValue;}
ab9de3125e372cedd76743dd1458044826596f143f1f3359981ecd1993e451d0
getEntry
 HeaderEntry getEntry(long headerId)
{    return new HeaderEntry(headerId, hBaseName, hSpillName, hBaseValue, hSpillValue);}
9d0fa4969ed62e4926646334c6054ffc5d0f3f404143a233922e3df81305228f
getHandler
public static SchemaHandler getHandler(DatabaseType dbType, DataSource dataSource)
{    SchemaHandler handler = null;    switch(dbType) {        case DERBY:            handler = new DerbySchemaHandler(dataSource);            break;        case MYSQL:            handler = new MySQLSchemaHandler(dataSource);            break;        default:            throw new JdbcChannelException("Database " + dbType + " not supported yet");    }    return handler;}
7c433c140e986ede99b2704e4370ce4dc62a481b499e15037b573f27288bffc9
put
public void put(Event event) throws ChannelException
{    getProvider().persistEvent(getName(), event);}
bd28ef43945352a9d826db660bc6e7b38e1777eec9decd45c0467679fc18a6dd
take
public Event take() throws ChannelException
{    return getProvider().removeEvent(getName());}
2940dfdc387e1882ca0545a619d502102ae0c821f25b9ee739eafaade9ca3ee9
getTransaction
public Transaction getTransaction()
{    return getProvider().getTransaction();}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    JdbcChannelProviderFactory.releaseProvider(getName());    provider = null;    super.stop();}
0794d4d28af8e1ea7f81b68a7b4f6d30f28a808992420723f5547975c99027ab
getProvider
private JdbcChannelProvider getProvider()
{    return provider;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    provider = JdbcChannelProviderFactory.getProvider(context, getName());    LOG.info("JDBC Channel initialized: " + getName());}
1aaa88cdff2c01375a9b2d3a3087c8a5e60f9e5ec1eaee1d6d82f56f1c9fa97c
getProvider
public static synchronized JdbcChannelProvider getProvider(Context context, String name)
{    if (PROVIDER == null) {        PROVIDER = new JdbcChannelProviderImpl();        PROVIDER.initialize(context);    }    if (!INSTANCES.add(name)) {        throw new JdbcChannelException("Attempt to initialize multiple " + "channels with same name: " + name);    }    return PROVIDER;}
cdeaa952b65acb99a476950dc6f228ef5538ae7abd99ead6f171f59b05f37026
releaseProvider
public static synchronized void releaseProvider(String name)
{    if (!INSTANCES.remove(name)) {        throw new JdbcChannelException("Attempt to release non-existant channel: " + name);    }    if (INSTANCES.size() == 0) {                PROVIDER.close();        PROVIDER = null;    }}
871172d34cf47bd1ccc8d8f81877fbf834289fcf345350e529b8b4e7a6708c5d
getCode
public int getCode()
{    return code;}
239fbe3eb64d679cbac1161825b07d6a8436ead3c6c3d140d9caec2275827023
getName
public String getName()
{    return name;}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return getName();}
19cd17741eff0454624d08a67b873cd5561b51c5945441f8364354335dace768
getByName
public static TransactionIsolation getByName(String name)
{    return valueOf(name.trim().toUpperCase(Locale.ENGLISH));}
c536957a0359efaba4fa041a9429ed02027b66c9e6f5cc21d07eb308cc675a0d
setUp
public void setUp() throws IOException
{    derbyCtx.clear();    derbyCtx.put(ConfigurationConstants.CONFIG_CREATE_SCHEMA, "true");    derbyCtx.put(ConfigurationConstants.CONFIG_DATABASE_TYPE, "DERBY");    derbyCtx.put(ConfigurationConstants.CONFIG_JDBC_DRIVER_CLASS, "org.apache.derby.jdbc.EmbeddedDriver");    derbyCtx.put(ConfigurationConstants.CONFIG_PASSWORD, "");    derbyCtx.put(ConfigurationConstants.CONFIG_USERNAME, "sa");    File tmpDir = new File("target/test");    tmpDir.mkdirs();    File derbyLogFile = new File(tmpDir, "derbytest.log");    String derbyLogFilePath = derbyLogFile.getCanonicalPath();    derbyCtx.put(ConfigurationConstants.CONFIG_JDBC_SYSPROP_PREFIX + "derby.stream.error.file", derbyLogFilePath);        File tempFile = File.createTempFile("temp", "_db", tmpDir);    String absFileName = tempFile.getCanonicalPath();    tempFile.delete();    derbyDbDir = new File(absFileName + "_dir");    if (!derbyDbDir.exists()) {        derbyDbDir.mkdirs();    }    derbyCtx.put(ConfigurationConstants.CONFIG_URL, "jdbc:derby:memory:" + derbyDbDir.getCanonicalPath() + "/db;create=true");    configureChannel(derbyCtx);    LOGGER.info("Derby Properties: " + derbyCtx);}
8674c74184ae78d9c78496daa54d5d270a60645f29799a69c54a03a9165fb870
testDerbyChannelCapacity
public void testDerbyChannelCapacity()
{    provider = new JdbcChannelProviderImpl();    derbyCtx.put(ConfigurationConstants.CONFIG_MAX_CAPACITY, "10");    provider.initialize(derbyCtx);    Set<MockEvent> events = new HashSet<MockEvent>();    for (int i = 1; i < 12; i++) {        events.add(MockEventUtils.generateMockEvent(i, i, i, 61 % i, 1));    }    Iterator<MockEvent> meIt = events.iterator();    int count = 0;    while (meIt.hasNext()) {        count++;        MockEvent me = meIt.next();        String chName = me.getChannel();        try {            provider.persistEvent(chName, me);            if (count == 11) {                Assert.fail();            }        } catch (JdbcChannelException ex) {                        Assert.assertEquals(11, count);        }                Event e = provider.removeEvent(chName);        Assert.assertNotNull(e);                provider.persistEvent(chName, me);    }}
bb0033ba2bb6ea7aebeb0618cd30a4d8567e8f7440b1c011a2637d85ec200b73
testDerbySetup
public void testDerbySetup()
{    provider = new JdbcChannelProviderImpl();    provider.initialize(derbyCtx);    Transaction tx1 = provider.getTransaction();    tx1.begin();    Transaction tx2 = provider.getTransaction();    Assert.assertSame(tx1, tx2);    tx2.begin();    tx2.close();    tx1.close();    Transaction tx3 = provider.getTransaction();    Assert.assertNotSame(tx1, tx3);    tx3.begin();    tx3.close();    provider.close();    provider = null;}
942f6986d05aa31f95fb0c8398c74dcee14fee8a07643e0d40be0e76285e7173
testEventWithSimulatedSourceAndSinks
public void testEventWithSimulatedSourceAndSinks() throws Exception
{    provider = new JdbcChannelProviderImpl();    provider.initialize(derbyCtx);    Map<String, List<MockEvent>> eventMap = new HashMap<String, List<MockEvent>>();    for (int i = 1; i < 121; i++) {        MockEvent me = MockEventUtils.generateMockEvent(i, i, i, 61 % i, 10);        List<MockEvent> meList = eventMap.get(me.getChannel());        if (meList == null) {            meList = new ArrayList<MockEvent>();            eventMap.put(me.getChannel(), meList);        }        meList.add(me);    }    List<MockSource> sourceList = new ArrayList<MockSource>();    List<MockSink> sinkList = new ArrayList<MockSink>();    for (String channel : eventMap.keySet()) {        List<MockEvent> meList = eventMap.get(channel);        sourceList.add(new MockSource(channel, meList, provider));        sinkList.add(new MockSink(channel, meList, provider));    }    ExecutorService sourceExecutor = Executors.newFixedThreadPool(10);    ExecutorService sinkExecutor = Executors.newFixedThreadPool(10);    List<Future<Integer>> srcResults = sourceExecutor.invokeAll(sourceList, 300, TimeUnit.SECONDS);    Thread.sleep(MockEventUtils.generateSleepInterval(3000));    List<Future<Integer>> sinkResults = sinkExecutor.invokeAll(sinkList, 300, TimeUnit.SECONDS);    int srcCount = 0;    for (Future<Integer> srcOutput : srcResults) {        srcCount += srcOutput.get();    }    Assert.assertEquals(120, srcCount);    int sinkCount = 0;    for (Future<Integer> sinkOutput : sinkResults) {        sinkCount += sinkOutput.get();    }    Assert.assertEquals(120, sinkCount);}
090bb0ac3029d70ecaafa6998f98cf17b53006647bb41a7da88e6e3782beeea8
testPeristingEvents
public void testPeristingEvents()
{    provider = new JdbcChannelProviderImpl();    provider.initialize(derbyCtx);    Map<String, List<MockEvent>> eventMap = new HashMap<String, List<MockEvent>>();    Set<MockEvent> events = new HashSet<MockEvent>();    for (int i = 1; i < 81; i++) {        events.add(MockEventUtils.generateMockEvent(i, i, i, 61 % i, 5));    }    Iterator<MockEvent> meIt = events.iterator();    while (meIt.hasNext()) {        MockEvent me = meIt.next();        String chName = me.getChannel();        List<MockEvent> eventList = eventMap.get(chName);        if (eventList == null) {            eventList = new ArrayList<MockEvent>();            eventMap.put(chName, eventList);        }        eventList.add(me);        provider.persistEvent(me.getChannel(), me);    }    for (String chName : eventMap.keySet()) {        List<MockEvent> meList = eventMap.get(chName);        Iterator<MockEvent> it = meList.iterator();        while (it.hasNext()) {            MockEvent me = it.next();            Event event = provider.removeEvent(chName);            assertEquals(me, event);        }                Event nullEvent = provider.removeEvent(chName);        Assert.assertNull(nullEvent);    }    provider.close();    provider = null;}
4c13cfd246f35a1161312356fa1f76b51c9cdf2b26331f153ac9cce2136e069a
assertEquals
private static void assertEquals(Event e1, Event e2)
{    byte[] pl1 = e1.getBody();    byte[] pl2 = e2.getBody();    Assert.assertArrayEquals(pl1, pl2);    Map<String, String> h1 = e1.getHeaders();    Map<String, String> h2 = e2.getHeaders();    if (h1 == null || h1.size() == 0) {        Assert.assertTrue(h2 == null || h2.size() == 0);    } else {        Assert.assertTrue(h1.size() == h2.size());        for (String key : h1.keySet()) {            Assert.assertTrue(h2.containsKey(key));            String v1 = h1.get(key);            String v2 = h2.remove(key);            Assert.assertEquals(v1, v2);        }        Assert.assertTrue(h2.size() == 0);    }}
b15ec24534831cd8187de4c70ba4518879af91358fd307c4f306a42afcccad2c
tearDown
public void tearDown() throws IOException
{    if (provider != null) {        try {            provider.close();        } catch (Exception ex) {            LOGGER.error("Unable to close provider", ex);        }    }    provider = null;}
fb0b06273dcc43d32a573d8b12b8bca2f30a068c91b790a1ca062b8cbeff9e27
call
public Integer call() throws Exception
{    LOGGER.debug("Sink for channel[" + channel + "]: starting");    if (events == null) {        return 0;    }    Iterator<MockEvent> it = events.iterator();    while (it.hasNext()) {        MockEvent me = it.next();        Event event = null;        while (event == null) {            event = provider.removeEvent(channel);            if (event == null) {                LOGGER.debug("Sink for channel[" + channel + "]: empty queue");                try {                    Thread.sleep(MockEventUtils.generateSleepInterval(1000));                } catch (InterruptedException ex) {                    Thread.currentThread().interrupt();                }            } else {                LOGGER.debug("Sink for channel[" + channel + "]: removed event: " + event);            }        }        BaseJdbcChannelProviderTest.assertEquals(me, event);    }    LOGGER.debug("Sink for channel[" + channel + "]: retrieved all events");    return events.size();}
fb0b06273dcc43d32a573d8b12b8bca2f30a068c91b790a1ca062b8cbeff9e27
call
public Integer call() throws Exception
{    LOGGER.debug("Source for channel[" + channel + "]: starting");    if (events == null) {        return 0;    }    Iterator<MockEvent> it = events.iterator();    while (it.hasNext()) {        MockEvent me = it.next();        Assert.assertEquals(channel, me.getChannel());        provider.persistEvent(channel, me);        try {            Thread.sleep(MockEventUtils.generateSleepInterval(1000));        } catch (InterruptedException ex) {            Thread.currentThread().interrupt();        }    }    LOGGER.debug("Source for channel[" + channel + "]: submitted all events");    return events.size();}
9a691e59a635186c5f7258710b8e44f5caf3510a02999c2c0ea95c8238b813ad
getHeaders
public Map<String, String> getHeaders()
{    return headers;}
6d1c35600a6f29feedab1769a2763829b83814294b318a32e8c71bf3529059a1
setHeaders
public void setHeaders(Map<String, String> headers)
{}
a624aa1b85808a74c9f320025ea600169bd6e4692611a44ef53a1970442ef820
getBody
public byte[] getBody()
{    return payload;}
b8505eb3e09ba9bb11ab8433148a62af59b6b1a27ffe7e69cf12f0e20e7c76a1
setBody
public void setBody(byte[] body)
{}
190e6762112b434704596a6c1097fd091aa8aab4a3d6b99b5987df2bbaf2443f
getChannel
public String getChannel()
{    return channel;}
5131f792c052f17f5db401365f16dc80a256d48384ee227a5fd78b5fb7f9e0e5
generatePayload
public static byte[] generatePayload(int size)
{    byte[] result = new byte[size];    RANDOM.nextBytes(result);    return result;}
c583e2a1f489a9a4e928f1a792574651c1489a33bd2ea8225340727dea853d0d
generateHeaderString
public static String generateHeaderString(int size)
{    StringBuilder sb = new StringBuilder();    for (int i = 0; i < size; i++) {        int x = Math.abs(RANDOM.nextInt());        int y = x % CHARS.length;        sb.append(CHARS[y]);    }    return sb.toString();}
df84e6db3c16bebb137550723ea71d7f02a4c698fa0bcc987e3920f36f3e83ef
generateMockEvent
public static MockEvent generateMockEvent(int payloadMargin, int headerNameMargin, int headerValueMargin, int numHeaders, int numChannels)
{    int chIndex = 0;    if (numChannels > 1) {        chIndex = Math.abs(RANDOM.nextInt()) % numChannels;    }    String channel = "test-" + chIndex;    StringBuilder sb = new StringBuilder("New Event[payload size:");    int plTh = ConfigurationConstants.PAYLOAD_LENGTH_THRESHOLD;    int plSize = Math.abs(RANDOM.nextInt()) % plTh + payloadMargin;    sb.append(plSize).append(", numHeaders:").append(numHeaders);    sb.append(", channel:").append(channel);    byte[] payload = generatePayload(plSize);    int nmTh = ConfigurationConstants.HEADER_NAME_LENGTH_THRESHOLD;    int vlTh = ConfigurationConstants.HEADER_VALUE_LENGTH_THRESHOLD;    Map<String, String> headers = new HashMap<String, String>();    for (int i = 0; i < numHeaders; i++) {        int nmSize = Math.abs(RANDOM.nextInt()) % nmTh + headerNameMargin;        int vlSize = Math.abs(RANDOM.nextInt()) % vlTh + headerValueMargin;        String name = generateHeaderString(nmSize);        String value = generateHeaderString(vlSize);        headers.put(name, value);        sb.append("{nm:").append(nmSize).append(",vl:").append(vlSize);        sb.append("} ");    }    LOGGER.debug(sb.toString());    return new MockEvent(payload, headers, channel);}
8899c318d8893fc0ec7b7d1eec72b6114a05c720bf476d404cfddae35e63d663
generateSleepInterval
public static int generateSleepInterval(int upperBound)
{    return Math.abs(RANDOM.nextInt(upperBound));}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    enumMap.clear();    enumMap.put(DBTYPE_OTHER, DatabaseType.OTHER);    enumMap.put(DBTYPE_DERBY, DatabaseType.DERBY);    enumMap.put(DBTYPE_MYSQL, DatabaseType.MYSQL);    enumMap.put(DBTYPE_PGSQL, DatabaseType.POSTGRESQL);    enumMap.put(DBTYPE_ORACLE, DatabaseType.ORACLE);}
aa77dfd2722d94ebbbd79083de3d8ffbf284c94d02474f3c148c72fa7b52b3a5
testDatabaseTypeLookup
public void testDatabaseTypeLookup()
{    for (String key : enumMap.keySet()) {        DatabaseType type = enumMap.get(key);        DatabaseType lookupType = DatabaseType.valueOf(key);        String lookupTypeName = lookupType.getName();        Assert.assertEquals(lookupTypeName, lookupType.toString());        Assert.assertSame(type, lookupType);        Assert.assertEquals(key, lookupTypeName);        DatabaseType lookupType2 = DatabaseType.getByName(key.toLowerCase(Locale.ENGLISH));        Assert.assertSame(type, lookupType2);    }}
9e83ac6353eafc9068483fa0bb1693580e69970f696609e2940317290b7bb860
testUnknonwnDatabaseTypeLookup
public void testUnknonwnDatabaseTypeLookup()
{    String[] invalidTypes = new String[] { "foo", "bar", "abcd" };    for (String key : invalidTypes) {        DatabaseType type = DatabaseType.getByName(key);        Assert.assertSame(type, DatabaseType.OTHER);    }}
50a481f1826069ba8c11ac4239a2792e122f5d845a094bb23f700908b2d98e16
testCreateQueries
public void testCreateQueries()
{    Assert.assertEquals(DerbySchemaHandler.QUERY_CREATE_SCHEMA_FLUME, EXPECTED_QUERY_CREATE_SCHEMA_FLUME);    Assert.assertEquals(DerbySchemaHandler.QUERY_CREATE_TABLE_FL_EVENT, EXPECTED_QUERY_CREATE_TABLE_FL_EVENT);    Assert.assertEquals(DerbySchemaHandler.QUERY_CREATE_INDEX_FLE_CHANNEL, EXPECTED_QUERY_CREATE_INDEX_FLE_CHANNEL);    Assert.assertEquals(DerbySchemaHandler.QUERY_CREATE_TABLE_FL_PLSPILL_FK, EXPECTED_QUERY_CREATE_TABLE_FL_PLSPILL_FK);    Assert.assertEquals(DerbySchemaHandler.QUERY_CREATE_TABLE_FL_PLSPILL_NOFK, EXPECTED_QUERY_CREATE_TABLE_FL_PLSPILL_NOFK);    Assert.assertEquals(DerbySchemaHandler.QUERY_CREATE_INDEX_FLP_EVENT, EXPECTED_QUERY_CREATE_INDEX_FLP_EVENT);    Assert.assertEquals(DerbySchemaHandler.QUERY_CREATE_TABLE_FL_HEADER_FK, EXPECTED_QUERY_CREATE_TABLE_FL_HEADER_FK);    Assert.assertEquals(DerbySchemaHandler.QUERY_CREATE_TABLE_FL_HEADER_NOFK, EXPECTED_QUERY_CREATE_TABLE_FL_HEADER_NOFK);    Assert.assertEquals(DerbySchemaHandler.QUERY_CREATE_INDEX_FLH_EVENT, EXPECTED_QUERY_CREATE_INDEX_FLH_EVENT);    Assert.assertEquals(DerbySchemaHandler.QUERY_CREATE_TABLE_FL_NMSPILL_FK, EXPECTED_QUERY_CREATE_TABLE_FL_NMSPILL_FK);    Assert.assertEquals(DerbySchemaHandler.QUERY_CREATE_TABLE_FL_NMSPILL_NOFK, EXPECTED_QUERY_CREATE_TABLE_FL_NMSPILL_NOFK);    Assert.assertEquals(DerbySchemaHandler.QUERY_CREATE_INDEX_FLN_HEADER, EXPECTED_QUERY_CREATE_INDEX_FLN_HEADER);    Assert.assertEquals(DerbySchemaHandler.QUERY_CREATE_TABLE_FL_VLSPILL_FK, EXPECTED_QUERY_CREATE_TABLE_FL_VLSPILL_FK);    Assert.assertEquals(DerbySchemaHandler.QUERY_CREATE_TABLE_FL_VLSPILL_NOFK, EXPECTED_QUERY_CREATE_TABLE_FL_VLSPILL_NOFK);    Assert.assertEquals(DerbySchemaHandler.QUERY_CREATE_INDEX_FLV_HEADER, EXPECTED_QUERY_CREATE_INDEX_FLV_HEADER);    Assert.assertEquals(DerbySchemaHandler.COLUMN_LOOKUP_QUERY, EXPECTED_COLUMN_LOOKUP_QUERY);    Assert.assertEquals(DerbySchemaHandler.QUERY_CHANNEL_SIZE, EXPECTED_QUERY_CHANNEL_SIZE);    Assert.assertEquals(DerbySchemaHandler.STMT_INSERT_EVENT_BASE, EXPECTED_STMT_INSERT_EVENT_BASE);    Assert.assertEquals(DerbySchemaHandler.STMT_INSERT_EVENT_SPILL, EXPECTED_STMT_INSERT_EVENT_SPILL);    Assert.assertEquals(DerbySchemaHandler.STMT_INSERT_HEADER_BASE, EXPECTED_STMT_INSERT_HEADER_BASE);    Assert.assertEquals(DerbySchemaHandler.STMT_INSERT_HEADER_NAME_SPILL, EXPECTED_STMT_INSERT_HEADER_NAME_SPILL);    Assert.assertEquals(DerbySchemaHandler.STMT_INSERT_HEADER_VALUE_SPILL, EXPECTED_STMT_INSERT_HEADER_VALUE_SPILL);    Assert.assertEquals(DerbySchemaHandler.STMT_FETCH_PAYLOAD_BASE, EXPECTED_STMT_FETCH_PAYLOAD_BASE);    Assert.assertEquals(DerbySchemaHandler.STMT_FETCH_PAYLOAD_SPILL, EXPECTED_STMT_FETCH_PAYLOAD_SPILL);    Assert.assertEquals(DerbySchemaHandler.STMT_FETCH_HEADER_BASE, EXPECTED_STMT_FETCH_HEADER_BASE);    Assert.assertEquals(DerbySchemaHandler.STMT_FETCH_HEADER_NAME_SPILL, EXPECTED_STMT_FETCH_HEADER_NAME_SPILL);    Assert.assertEquals(DerbySchemaHandler.STMT_FETCH_HEADER_VALUE_SPILL, EXPECTED_STMT_FETCH_HEADER_VALUE_SPILL);    Assert.assertEquals(DerbySchemaHandler.STMT_DELETE_HEADER_VALUE_SPILL, EXPECTED_STMT_DELETE_HEADER_VALUE_SPILL);    Assert.assertEquals(DerbySchemaHandler.STMT_DELETE_HEADER_NAME_SPILL, EXPECTED_STMT_DELETE_HEADER_NAME_SPILL);    Assert.assertEquals(DerbySchemaHandler.STMT_DELETE_EVENT_SPILL, EXPECTED_STMT_DELETE_EVENT_SPILL);    Assert.assertEquals(DerbySchemaHandler.STMT_DELETE_HEADER_BASE, EXPECTED_STMT_DELETE_HEADER_BASE);    Assert.assertEquals(DerbySchemaHandler.STMT_DELETE_EVENT_BASE, EXPECTED_STMT_DELETE_EVENT_BASE);}
1d752171bde4acb9fe16ef9ee93edbd1a8c1d00f1c41b5be32764f9c0f579c0d
configureChannel
protected void configureChannel(Context context)
{}
1d752171bde4acb9fe16ef9ee93edbd1a8c1d00f1c41b5be32764f9c0f579c0d
configureChannel
protected void configureChannel(Context context)
{    context.put(ConfigurationConstants.CONFIG_CREATE_FK, "false");}
c558bab9706ad803ae5ee7adecb5d79413905c21805466f4dbaf46e288b17d8a
testMarshalling
public void testMarshalling()
{    int nameLimit = ConfigurationConstants.HEADER_NAME_LENGTH_THRESHOLD;    int valLimit = ConfigurationConstants.HEADER_VALUE_LENGTH_THRESHOLD;    byte[] s1 = MockEventUtils.generatePayload(1);    runTest(s1, null);    byte[] s2 = MockEventUtils.generatePayload(2);    runTest(s2, new HashMap<String, String>());    int th = ConfigurationConstants.PAYLOAD_LENGTH_THRESHOLD;    byte[] s3 = MockEventUtils.generatePayload(th - 2);    Map<String, String> m3 = new HashMap<String, String>();    m3.put(MockEventUtils.generateHeaderString(1), MockEventUtils.generateHeaderString(1));    runTest(s3, m3);    byte[] s4 = MockEventUtils.generatePayload(th - 1);    Map<String, String> m4 = new HashMap<String, String>();    m4.put(MockEventUtils.generateHeaderString(nameLimit - 21), "w");    m4.put(MockEventUtils.generateHeaderString(nameLimit - 2), "x");    m4.put(MockEventUtils.generateHeaderString(nameLimit - 1), "y");    m4.put(MockEventUtils.generateHeaderString(nameLimit), "z");    m4.put(MockEventUtils.generateHeaderString(nameLimit + 1), "a");    m4.put(MockEventUtils.generateHeaderString(nameLimit + 2), "b");    m4.put(MockEventUtils.generateHeaderString(nameLimit + 21), "c");    runTest(s4, m4);    byte[] s5 = MockEventUtils.generatePayload(th);    Map<String, String> m5 = new HashMap<String, String>();    m5.put("w", MockEventUtils.generateHeaderString(valLimit - 21));    m5.put("x", MockEventUtils.generateHeaderString(valLimit - 2));    m5.put("y", MockEventUtils.generateHeaderString(valLimit - 1));    m5.put("z", MockEventUtils.generateHeaderString(valLimit));    m5.put("a", MockEventUtils.generateHeaderString(valLimit + 1));    m5.put("b", MockEventUtils.generateHeaderString(valLimit + 2));    m5.put("c", MockEventUtils.generateHeaderString(valLimit + 21));    runTest(s5, m5);    byte[] s6 = MockEventUtils.generatePayload(th + 1);    Map<String, String> m6 = new HashMap<String, String>();    m6.put(MockEventUtils.generateHeaderString(nameLimit - 21), MockEventUtils.generateHeaderString(valLimit - 21));    m6.put(MockEventUtils.generateHeaderString(nameLimit - 2), MockEventUtils.generateHeaderString(valLimit - 2));    m6.put(MockEventUtils.generateHeaderString(nameLimit - 1), MockEventUtils.generateHeaderString(valLimit - 1));    m6.put(MockEventUtils.generateHeaderString(nameLimit), MockEventUtils.generateHeaderString(valLimit));    m6.put(MockEventUtils.generateHeaderString(nameLimit + 1), MockEventUtils.generateHeaderString(valLimit + 1));    m6.put(MockEventUtils.generateHeaderString(nameLimit + 2), MockEventUtils.generateHeaderString(valLimit + 2));    m6.put(MockEventUtils.generateHeaderString(nameLimit + 21), MockEventUtils.generateHeaderString(valLimit + 21));    runTest(s6, m6);    byte[] s7 = MockEventUtils.generatePayload(th + 2);    runTest(s7, null);    byte[] s8 = MockEventUtils.generatePayload(th + 27);    runTest(s8, null);}
89d753d5b1fc0b9b0045afde67e8cd68946a964b3563d0763199009d5d26b54a
runTest
private void runTest(byte[] payload, Map<String, String> headers)
{    PersistableEvent pe = new PersistableEvent("test", new MockEvent(payload, headers, null));    Assert.assertArrayEquals(payload, pe.getBody());    Map<String, String> h = pe.getHeaders();    if (h == null) {        Assert.assertTrue(headers == null || headers.size() == 0);    } else {        Assert.assertTrue(headers.size() == h.size());        for (String key : h.keySet()) {            Assert.assertTrue(headers.containsKey(key));            String value = h.get(key);            String expectedValue = headers.remove(key);            Assert.assertEquals(expectedValue, value);        }        Assert.assertTrue(headers.size() == 0);    }}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    enumMap.clear();    enumMap.put(TX_READ_UNCOMMITTED, TransactionIsolation.READ_UNCOMMITTED);    enumMap.put(TX_READ_COMMITTED, TransactionIsolation.READ_COMMITTED);    enumMap.put(TX_REPEATABLE_READ, TransactionIsolation.REPEATABLE_READ);    enumMap.put(TX_SERIALIZABLE, TransactionIsolation.SERIALIZABLE);}
6c440f999e938b9c401aad0f763e545e63b6f6295beecd6daffef60035bb7f08
testReverseLookup
public void testReverseLookup()
{    for (String key : enumMap.keySet()) {        TransactionIsolation txIsolation = enumMap.get(key);        TransactionIsolation lookupTxIsolation = TransactionIsolation.valueOf(key);        String lookupTxIsolationName = lookupTxIsolation.getName();        Assert.assertEquals(lookupTxIsolationName, lookupTxIsolation.toString());        Assert.assertSame(txIsolation, lookupTxIsolation);        Assert.assertEquals(key, lookupTxIsolationName);        TransactionIsolation lookupTxIsolation2 = TransactionIsolation.getByName(key.toLowerCase(Locale.ENGLISH));        Assert.assertSame(txIsolation, lookupTxIsolation2);    }}
5dee74994b401705c52e8bfe74299dce3e47a9f73d41888c43b6486c13555699
initialValue
public ConsumerAndRecords initialValue()
{    return createConsumerAndRecords();}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    logger.info("Starting Kafka Channel: {}", getName());        if (migrateZookeeperOffsets && zookeeperConnect != null && !zookeeperConnect.isEmpty()) {        migrateOffsets();    }    producer = new KafkaProducer<String, byte[]>(producerProps);        logger.info("Topic = {}", topic.get());    counter.start();    super.start();}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    for (ConsumerAndRecords c : consumers) {        try {            decommissionConsumerAndRecords(c);        } catch (Exception ex) {            logger.warn("Error while shutting down consumer.", ex);        }    }    producer.close();    counter.stop();    super.stop();    logger.info("Kafka channel {} stopped.", getName());}
39f7d6d1213100383ba6ea7c79d8ed4ca1c7407a0f2469c0973c0709371a6cb9
createTransaction
protected BasicTransactionSemantics createTransaction()
{    return new KafkaTransaction();}
46d29f7ad11cbcef8540e00a81a800b1024d2dd215004afe43cc5f5e986aa6c6
configure
public void configure(Context ctx)
{        translateOldProps(ctx);    topicStr = ctx.getString(TOPIC_CONFIG);    if (topicStr == null || topicStr.isEmpty()) {        topicStr = DEFAULT_TOPIC;        logger.info("Topic was not specified. Using {} as the topic.", topicStr);    }    topic.set(topicStr);    groupId = ctx.getString(KAFKA_CONSUMER_PREFIX + ConsumerConfig.GROUP_ID_CONFIG);    if (groupId == null || groupId.isEmpty()) {        groupId = DEFAULT_GROUP_ID;        logger.info("Group ID was not specified. Using {} as the group id.", groupId);    }    String bootStrapServers = ctx.getString(BOOTSTRAP_SERVERS_CONFIG);    if (bootStrapServers == null || bootStrapServers.isEmpty()) {        throw new ConfigurationException("Bootstrap Servers must be specified");    }    setProducerProps(ctx, bootStrapServers);    setConsumerProps(ctx, bootStrapServers);    parseAsFlumeEvent = ctx.getBoolean(PARSE_AS_FLUME_EVENT, DEFAULT_PARSE_AS_FLUME_EVENT);    pollTimeout = ctx.getLong(POLL_TIMEOUT, DEFAULT_POLL_TIMEOUT);    staticPartitionId = ctx.getInteger(STATIC_PARTITION_CONF);    partitionHeader = ctx.getString(PARTITION_HEADER_NAME);    migrateZookeeperOffsets = ctx.getBoolean(MIGRATE_ZOOKEEPER_OFFSETS, DEFAULT_MIGRATE_ZOOKEEPER_OFFSETS);    zookeeperConnect = ctx.getString(ZOOKEEPER_CONNECT_FLUME_KEY);    if (logger.isDebugEnabled() && LogPrivacyUtil.allowLogPrintConfig()) {        logger.debug("Kafka properties: {}", ctx);    }    if (counter == null) {        counter = new KafkaChannelCounter(getName());    }}
9565e04e40844b638e2d6f16cea61410d649b230a2ee9cd04ac50dcfc8690cb8
translateOldProps
private void translateOldProps(Context ctx)
{    if (!(ctx.containsKey(TOPIC_CONFIG))) {        ctx.put(TOPIC_CONFIG, ctx.getString("topic"));        logger.warn("{} is deprecated. Please use the parameter {}", "topic", TOPIC_CONFIG);    }        if (!(ctx.containsKey(BOOTSTRAP_SERVERS_CONFIG))) {        String brokerList = ctx.getString(BROKER_LIST_FLUME_KEY);        if (brokerList == null || brokerList.isEmpty()) {            throw new ConfigurationException("Bootstrap Servers must be specified");        } else {            ctx.put(BOOTSTRAP_SERVERS_CONFIG, brokerList);            logger.warn("{} is deprecated. Please use the parameter {}", BROKER_LIST_FLUME_KEY, BOOTSTRAP_SERVERS_CONFIG);        }    }        if (!(ctx.containsKey(KAFKA_CONSUMER_PREFIX + ConsumerConfig.GROUP_ID_CONFIG))) {        String oldGroupId = ctx.getString(GROUP_ID_FLUME);        if (oldGroupId != null && !oldGroupId.isEmpty()) {            ctx.put(KAFKA_CONSUMER_PREFIX + ConsumerConfig.GROUP_ID_CONFIG, oldGroupId);            logger.warn("{} is deprecated. Please use the parameter {}", GROUP_ID_FLUME, KAFKA_CONSUMER_PREFIX + ConsumerConfig.GROUP_ID_CONFIG);        }    }    if (!(ctx.containsKey((KAFKA_CONSUMER_PREFIX + ConsumerConfig.AUTO_OFFSET_RESET_CONFIG)))) {        Boolean oldReadSmallest = ctx.getBoolean(READ_SMALLEST_OFFSET);        String auto;        if (oldReadSmallest != null) {            if (oldReadSmallest) {                auto = "earliest";            } else {                auto = "latest";            }            ctx.put(KAFKA_CONSUMER_PREFIX + ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, auto);            logger.warn("{} is deprecated. Please use the parameter {}", READ_SMALLEST_OFFSET, KAFKA_CONSUMER_PREFIX + ConsumerConfig.AUTO_OFFSET_RESET_CONFIG);        }    }}
f39cf5b98d08d91f4de6cd4408a508b256556c13ab42e60fe7029eed95c118f5
setProducerProps
private void setProducerProps(Context ctx, String bootStrapServers)
{    producerProps.clear();    producerProps.put(ProducerConfig.ACKS_CONFIG, DEFAULT_ACKS);    producerProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, DEFAULT_KEY_SERIALIZER);    producerProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, DEFAULT_VALUE_SERIAIZER);        producerProps.putAll(ctx.getSubProperties(KAFKA_PRODUCER_PREFIX));    producerProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootStrapServers);    KafkaSSLUtil.addGlobalSSLParameters(producerProps);}
dc2830550f31ad013fdccb8f1c8c13c8da9e7bafc1df57001c01e16852d5ce62
getProducerProps
protected Properties getProducerProps()
{    return producerProps;}
303d3d594f11ee4c63b803e53fa186697e29aa56d036506fba2741c8e8b05678
setConsumerProps
private void setConsumerProps(Context ctx, String bootStrapServers)
{    consumerProps.clear();    consumerProps.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, DEFAULT_KEY_DESERIALIZER);    consumerProps.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, DEFAULT_VALUE_DESERIAIZER);    consumerProps.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, DEFAULT_AUTO_OFFSET_RESET);        consumerProps.putAll(ctx.getSubProperties(KAFKA_CONSUMER_PREFIX));        consumerProps.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootStrapServers);    consumerProps.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);    consumerProps.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);    KafkaSSLUtil.addGlobalSSLParameters(consumerProps);}
ad38d9184579e989e53631d4ad19a4b25dd5bb9f0502185875fb2ba8b14a90fa
getConsumerProps
protected Properties getConsumerProps()
{    return consumerProps;}
7ba65e7dcc80c935c46704ee89cac54f67c71723395e5ebb57d2c12e1f1f041d
createConsumerAndRecords
private synchronized ConsumerAndRecords createConsumerAndRecords()
{    try {        KafkaConsumer<String, byte[]> consumer = new KafkaConsumer<String, byte[]>(consumerProps);        ConsumerAndRecords car = new ConsumerAndRecords(consumer, channelUUID);        logger.info("Created new consumer to connect to Kafka");        car.consumer.subscribe(Arrays.asList(topic.get()), new ChannelRebalanceListener(rebalanceFlag));        car.offsets = new HashMap<TopicPartition, OffsetAndMetadata>();        consumers.add(car);        return car;    } catch (Exception e) {        throw new FlumeException("Unable to connect to Kafka", e);    }}
613048a4181d9de40cc1ad524b49bb4d493590e81fe2e80fe60a9023928920a9
migrateOffsets
private void migrateOffsets()
{    try (KafkaZkClient zkClient = KafkaZkClient.apply(zookeeperConnect, JaasUtils.isZkSecurityEnabled(), ZK_SESSION_TIMEOUT, ZK_CONNECTION_TIMEOUT, 10, Time.SYSTEM, "kafka.server", "SessionExpireListener");        KafkaConsumer<String, byte[]> consumer = new KafkaConsumer<>(consumerProps)) {        Map<TopicPartition, OffsetAndMetadata> kafkaOffsets = getKafkaOffsets(consumer);        if (kafkaOffsets == null) {            logger.warn("Topic " + topicStr + " not found in Kafka. Offset migration will be skipped.");            return;        }        if (!kafkaOffsets.isEmpty()) {            logger.info("Found Kafka offsets for topic {}. Will not migrate from zookeeper", topicStr);            logger.debug("Offsets found: {}", kafkaOffsets);            return;        }        logger.info("No Kafka offsets found. Migrating zookeeper offsets");        Map<TopicPartition, OffsetAndMetadata> zookeeperOffsets = getZookeeperOffsets(zkClient, consumer);        if (zookeeperOffsets.isEmpty()) {            logger.warn("No offsets to migrate found in Zookeeper");            return;        }        logger.info("Committing Zookeeper offsets to Kafka");        logger.debug("Offsets to commit: {}", zookeeperOffsets);        consumer.commitSync(zookeeperOffsets);                Map<TopicPartition, OffsetAndMetadata> newKafkaOffsets = getKafkaOffsets(consumer);        logger.debug("Offsets committed: {}", newKafkaOffsets);        if (newKafkaOffsets == null || !newKafkaOffsets.keySet().containsAll(zookeeperOffsets.keySet())) {            throw new FlumeException("Offsets could not be committed");        }    }}
d8d14a846b52392aa86839c6d0aebeb459f3567196198762ae28152d0eb7514e
getKafkaOffsets
private Map<TopicPartition, OffsetAndMetadata> getKafkaOffsets(KafkaConsumer<String, byte[]> client)
{    Map<TopicPartition, OffsetAndMetadata> offsets = null;    List<PartitionInfo> partitions = client.partitionsFor(topicStr);    if (partitions != null) {        offsets = new HashMap<>();        for (PartitionInfo partition : partitions) {            TopicPartition key = new TopicPartition(topicStr, partition.partition());            OffsetAndMetadata offsetAndMetadata = client.committed(key);            if (offsetAndMetadata != null) {                offsets.put(key, offsetAndMetadata);            }        }    }    return offsets;}
2e3418781c2fdc6063f3c5512ddf1798d77ada450abcf306ea52e660782c4b87
getZookeeperOffsets
private Map<TopicPartition, OffsetAndMetadata> getZookeeperOffsets(KafkaZkClient zkClient, KafkaConsumer<String, byte[]> consumer)
{    Map<TopicPartition, OffsetAndMetadata> offsets = new HashMap<>();    List<PartitionInfo> partitions = consumer.partitionsFor(topicStr);    for (PartitionInfo partition : partitions) {        TopicPartition topicPartition = new TopicPartition(topicStr, partition.partition());        Option<Object> optionOffset = zkClient.getConsumerOffset(groupId, topicPartition);        if (optionOffset.nonEmpty()) {            Long offset = (Long) optionOffset.get();            OffsetAndMetadata offsetAndMetadata = new OffsetAndMetadata(offset);            offsets.put(topicPartition, offsetAndMetadata);        }    }    return offsets;}
9c075cfacabf6b1927205e74adff1c1b60e216e26d616f9285e2af8c6ca60ef1
decommissionConsumerAndRecords
private void decommissionConsumerAndRecords(ConsumerAndRecords c)
{    c.consumer.wakeup();    c.consumer.close();}
3b4ef17d91a2683dbefe10b7b291fd2578c15a7f3e307f89bcceddfaf2465dd3
registerThread
 void registerThread()
{    try {        consumerAndRecords.get();    } catch (Exception e) {        logger.error(e.getMessage());        e.printStackTrace();    }}
089dd8ebc0ff4cc8f274f4df7a6cd25c63963a7dd757c692d51b389fe1b5a9c3
doBegin
protected void doBegin() throws InterruptedException
{    rebalanceFlag.set(false);}
12f20da1039baa55cd8cd24a8512df38790e6cb0af896f04ec9f5012ddf00b9a
doPut
protected void doPut(Event event) throws InterruptedException
{    type = TransactionType.PUT;    if (!producerRecords.isPresent()) {        producerRecords = Optional.of(new LinkedList<ProducerRecord<String, byte[]>>());    }    String key = event.getHeaders().get(KEY_HEADER);    Integer partitionId = null;    try {        if (staticPartitionId != null) {            partitionId = staticPartitionId;        }                if (partitionHeader != null) {            String headerVal = event.getHeaders().get(partitionHeader);            if (headerVal != null) {                partitionId = Integer.parseInt(headerVal);            }        }        if (partitionId != null) {            producerRecords.get().add(new ProducerRecord<String, byte[]>(topic.get(), partitionId, key, serializeValue(event, parseAsFlumeEvent)));        } else {            producerRecords.get().add(new ProducerRecord<String, byte[]>(topic.get(), key, serializeValue(event, parseAsFlumeEvent)));        }        counter.incrementEventPutAttemptCount();    } catch (NumberFormatException e) {        throw new ChannelException("Non integer partition id specified", e);    } catch (Exception e) {        throw new ChannelException("Error while serializing event", e);    }}
f8425491b25802703eb5080383b86f3b99d38a0998a1c49a9f85e4971cf4e57c
doTake
protected Event doTake() throws InterruptedException
{    logger.trace("Starting event take");    type = TransactionType.TAKE;    try {        if (!(consumerAndRecords.get().uuid.equals(channelUUID))) {            logger.info("UUID mismatch, creating new consumer");            decommissionConsumerAndRecords(consumerAndRecords.get());            consumerAndRecords.remove();        }    } catch (Exception ex) {        logger.warn("Error while shutting down consumer", ex);    }    if (!events.isPresent()) {        events = Optional.of(new LinkedList<Event>());    }    Event e;        if (rebalanceFlag.get()) {        logger.debug("Returning null event after Consumer rebalance.");        return null;    }    if (!consumerAndRecords.get().failedEvents.isEmpty()) {        e = consumerAndRecords.get().failedEvents.removeFirst();    } else {        if (logger.isTraceEnabled()) {            logger.trace("Assignment during take: {}", consumerAndRecords.get().consumer.assignment().toString());        }        try {            long startTime = System.nanoTime();            if (!consumerAndRecords.get().recordIterator.hasNext()) {                consumerAndRecords.get().poll();            }            if (consumerAndRecords.get().recordIterator.hasNext()) {                ConsumerRecord<String, byte[]> record = consumerAndRecords.get().recordIterator.next();                e = deserializeValue(record.value(), parseAsFlumeEvent);                TopicPartition tp = new TopicPartition(record.topic(), record.partition());                OffsetAndMetadata oam = new OffsetAndMetadata(record.offset() + 1, batchUUID);                consumerAndRecords.get().saveOffsets(tp, oam);                                if (record.key() != null) {                    e.getHeaders().put(KEY_HEADER, record.key());                }                long endTime = System.nanoTime();                counter.addToKafkaEventGetTimer((endTime - startTime) / (1000 * 1000));                if (logger.isDebugEnabled()) {                    logger.debug("{} processed output from partition {} offset {}", new Object[] { getName(), record.partition(), record.offset() });                }            } else {                return null;            }            counter.incrementEventTakeAttemptCount();        } catch (Exception ex) {            logger.warn("Error while getting events from Kafka. This is usually caused by " + "trying to read a non-flume event. Ensure the setting for " + "parseAsFlumeEvent is correct", ex);            throw new ChannelException("Error while getting events from Kafka", ex);        }    }    eventTaken = true;    events.get().add(e);    return e;}
1665f7d1b67a1fa794c9fb67a1be01e4bf6a8b0e782a8f9a49914917f9ecf058
doCommit
protected void doCommit() throws InterruptedException
{    logger.trace("Starting commit");    if (type.equals(TransactionType.NONE)) {        return;    }    if (type.equals(TransactionType.PUT)) {        if (!kafkaFutures.isPresent()) {            kafkaFutures = Optional.of(new LinkedList<Future<RecordMetadata>>());        }        try {            long batchSize = producerRecords.get().size();            long startTime = System.nanoTime();            int index = 0;            for (ProducerRecord<String, byte[]> record : producerRecords.get()) {                index++;                kafkaFutures.get().add(producer.send(record, new ChannelCallback(index, startTime)));            }                        producer.flush();            for (Future<RecordMetadata> future : kafkaFutures.get()) {                future.get();            }            long endTime = System.nanoTime();            counter.addToKafkaEventSendTimer((endTime - startTime) / (1000 * 1000));            counter.addToEventPutSuccessCount(batchSize);            producerRecords.get().clear();            kafkaFutures.get().clear();        } catch (Exception ex) {            logger.warn("Sending events to Kafka failed", ex);            throw new ChannelException("Commit failed as send to Kafka failed", ex);        }    } else {                if (consumerAndRecords.get().failedEvents.isEmpty() && eventTaken) {            logger.trace("About to commit batch");            long startTime = System.nanoTime();            consumerAndRecords.get().commitOffsets();            long endTime = System.nanoTime();            counter.addToKafkaCommitTimer((endTime - startTime) / (1000 * 1000));            if (logger.isDebugEnabled()) {                logger.debug(consumerAndRecords.get().getCommittedOffsetsString());            }        }        int takes = events.get().size();        if (takes > 0) {            counter.addToEventTakeSuccessCount(takes);            events.get().clear();        }    }}
2cbb76d448fbcbe4b802d87cf143885cfe914d2929bc4f7d5164451c23333cb5
doRollback
protected void doRollback() throws InterruptedException
{    if (type.equals(TransactionType.NONE)) {        return;    }    if (type.equals(TransactionType.PUT)) {        producerRecords.get().clear();        kafkaFutures.get().clear();    } else {        counter.addToRollbackCounter(events.get().size());        consumerAndRecords.get().failedEvents.addAll(events.get());        events.get().clear();    }}
9f68536866c1f94ae409f881c6192e26b4aeb52b9eccd7875fd13f59598f1f05
serializeValue
private byte[] serializeValue(Event event, boolean parseAsFlumeEvent) throws IOException
{    byte[] bytes;    if (parseAsFlumeEvent) {        if (!tempOutStream.isPresent()) {            tempOutStream = Optional.of(new ByteArrayOutputStream());        }        if (!writer.isPresent()) {            writer = Optional.of(new SpecificDatumWriter<AvroFlumeEvent>(AvroFlumeEvent.class));        }        tempOutStream.get().reset();        AvroFlumeEvent e = new AvroFlumeEvent(toCharSeqMap(event.getHeaders()), ByteBuffer.wrap(event.getBody()));        encoder = EncoderFactory.get().directBinaryEncoder(tempOutStream.get(), encoder);        writer.get().write(e, encoder);        encoder.flush();        bytes = tempOutStream.get().toByteArray();    } else {        bytes = event.getBody();    }    return bytes;}
2ed33845f8860417c2749ce3165d372bdfbcf558666670beecf3c4e960ab6ebe
deserializeValue
private Event deserializeValue(byte[] value, boolean parseAsFlumeEvent) throws IOException
{    Event e;    if (parseAsFlumeEvent) {        ByteArrayInputStream in = new ByteArrayInputStream(value);        decoder = DecoderFactory.get().directBinaryDecoder(in, decoder);        if (!reader.isPresent()) {            reader = Optional.of(new SpecificDatumReader<AvroFlumeEvent>(AvroFlumeEvent.class));        }        AvroFlumeEvent event = reader.get().read(null, decoder);        e = EventBuilder.withBody(event.getBody().array(), toStringMap(event.getHeaders()));    } else {        e = EventBuilder.withBody(value, Collections.EMPTY_MAP);    }    return e;}
ca70404cb05aa6f426a79eb036db13b49ea4f886fb6ea56db781f7474943c006
toCharSeqMap
private static Map<CharSequence, CharSequence> toCharSeqMap(Map<String, String> stringMap)
{    Map<CharSequence, CharSequence> charSeqMap = new HashMap<CharSequence, CharSequence>();    for (Map.Entry<String, String> entry : stringMap.entrySet()) {        charSeqMap.put(entry.getKey(), entry.getValue());    }    return charSeqMap;}
2e58b3ac498ab3927896f17dd5b1322f2b5601df3bbefc5d05d04de291b821f1
toStringMap
private static Map<String, String> toStringMap(Map<CharSequence, CharSequence> charSeqMap)
{    Map<String, String> stringMap = new HashMap<String, String>();    for (Map.Entry<CharSequence, CharSequence> entry : charSeqMap.entrySet()) {        stringMap.put(entry.getKey().toString(), entry.getValue().toString());    }    return stringMap;}
1aa393ceabfa69a4af16958f184ec373a2ec974753d807cbca170b877c3c554c
poll
private void poll()
{    logger.trace("Polling with timeout: {}ms channel-{}", pollTimeout, getName());    try {        records = consumer.poll(Duration.ofMillis(pollTimeout));        recordIterator = records.iterator();        logger.debug("{} returned {} records from last poll", getName(), records.count());    } catch (WakeupException e) {        logger.trace("Consumer woken up for channel {}.", getName());    }}
2fd2b4c60443a0e416a57da97ba7c02be15611a88ac07b6bed062b724f4ab88e
commitOffsets
private void commitOffsets()
{    try {        consumer.commitSync(offsets);    } catch (Exception e) {        logger.info("Error committing offsets.", e);    } finally {        logger.trace("About to clear offsets map.");        offsets.clear();    }}
8ce5d7e34e007bcf72d21727c36d9771f2a2969ccf9613f091877c9a734317ee
getOffsetMapString
private String getOffsetMapString()
{    StringBuilder sb = new StringBuilder();    sb.append(getName()).append(" current offsets map: ");    for (TopicPartition tp : offsets.keySet()) {        sb.append("p").append(tp.partition()).append("-").append(offsets.get(tp).offset()).append(" ");    }    return sb.toString();}
17c8e79a9f784f297b3f65043c4ce9fdf49f04bca10c6c4e8d02a4261459831d
getCommittedOffsetsString
private String getCommittedOffsetsString()
{    StringBuilder sb = new StringBuilder();    sb.append(getName()).append(" committed: ");    for (TopicPartition tp : consumer.assignment()) {        try {            sb.append("[").append(tp).append(",").append(consumer.committed(tp).offset()).append("] ");        } catch (NullPointerException npe) {            logger.debug("Committed {}", tp);        }    }    return sb.toString();}
f1108b2a168af6bdb74f3366578bf4ab0e652f2c3cdd912712346088647bf184
saveOffsets
private void saveOffsets(TopicPartition tp, OffsetAndMetadata oam)
{    offsets.put(tp, oam);    if (logger.isTraceEnabled()) {        logger.trace(getOffsetMapString());    }}
b915c65ba01f7e32012a43ee05a76416b6d754633b4081b5f849aa6a507799b3
onCompletion
public void onCompletion(RecordMetadata metadata, Exception exception)
{    if (exception != null) {        log.trace("Error sending message to Kafka due to " + exception.getMessage());    }    if (log.isDebugEnabled()) {        long batchElapsedTime = System.currentTimeMillis() - startTime;        if (metadata != null) {            log.debug("Acked message_no " + index + ": " + metadata.topic() + "-" + metadata.partition() + "-" + metadata.offset() + "-" + batchElapsedTime);        }    }}
cac5d34fe0051519b8bdcb32fd429171075d1bd2c0191749047730ecbb52d987
onPartitionsRevoked
public void onPartitionsRevoked(Collection<TopicPartition> partitions)
{    for (TopicPartition partition : partitions) {        log.info("topic {} - partition {} revoked.", partition.topic(), partition.partition());        rebalanceFlag.set(true);    }}
0592fcd4dbb7085351acc388587ef8b2537c35944360fa0b76c763a3c7ab1a6e
onPartitionsAssigned
public void onPartitionsAssigned(Collection<TopicPartition> partitions)
{    for (TopicPartition partition : partitions) {        log.info("topic {} - partition {} assigned.", partition.topic(), partition.partition());    }}
7fc3faef7fc1a25f43d7b4d25bc32bfda61d430506a43299c108698dd750dd8d
testProps
public void testProps() throws Exception
{    Context context = new Context();    context.put("kafka.producer.some-parameter", "1");    context.put("kafka.consumer.another-parameter", "1");    context.put(BOOTSTRAP_SERVERS_CONFIG, testUtil.getKafkaServerUrl());    context.put(TOPIC_CONFIG, topic);    final KafkaChannel channel = new KafkaChannel();    Configurables.configure(channel, context);    Properties consumerProps = channel.getConsumerProps();    Properties producerProps = channel.getProducerProps();    Assert.assertEquals(producerProps.getProperty("some-parameter"), "1");    Assert.assertEquals(consumerProps.getProperty("another-parameter"), "1");}
cd053fe59e0a9bfc95796e9481c2c91fbf528f1c004929cb6ffee950e2584024
testOldConfig
public void testOldConfig() throws Exception
{    Context context = new Context();    context.put(BROKER_LIST_FLUME_KEY, testUtil.getKafkaServerUrl());    context.put(GROUP_ID_FLUME, "flume-something");    context.put(READ_SMALLEST_OFFSET, "true");    context.put("topic", topic);    final KafkaChannel channel = new KafkaChannel();    Configurables.configure(channel, context);    Properties consumerProps = channel.getConsumerProps();    Properties producerProps = channel.getProducerProps();    Assert.assertEquals(producerProps.getProperty(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG), testUtil.getKafkaServerUrl());    Assert.assertEquals(consumerProps.getProperty(ConsumerConfig.GROUP_ID_CONFIG), "flume-something");    Assert.assertEquals(consumerProps.getProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG), "earliest");}
c4a6122c6ea7aa887dcddf11482a0f192e0154a4c6ea0dfba1103edb30c91877
testStopAndStart
public void testStopAndStart() throws Exception
{    doTestStopAndStart(false, false);}
ad8ca853b26506483f10df6b29a59f632e1c9d89ad4c89369f1857f1f32015be
testStopAndStartWithRollback
public void testStopAndStartWithRollback() throws Exception
{    doTestStopAndStart(true, true);}
21f862b72734098d443b72f89b69b84f538750163bd683acb440b85049ff7a1b
testStopAndStartWithRollbackAndNoRetry
public void testStopAndStartWithRollbackAndNoRetry() throws Exception
{    doTestStopAndStart(true, false);}
3105413b9b4be72c0b3545840e0198a470ca2b95b64dd45b3b212d91305fffb1
testNullKeyNoHeader
public void testNullKeyNoHeader() throws Exception
{    doTestNullKeyNoHeader();}
0e4714e6d888c30281b241800fa458d5a1273a29dcd7a1691fb2a6944b23faf9
testDefaultSettingsOnReConfigure
public void testDefaultSettingsOnReConfigure() throws Exception
{    String sampleProducerProp = "compression.type";    String sampleProducerVal = "snappy";    String sampleConsumerProp = "fetch.min.bytes";    String sampleConsumerVal = "99";    Context context = prepareDefaultContext(false);    context.put(KafkaChannelConfiguration.KAFKA_PRODUCER_PREFIX + sampleProducerProp, sampleProducerVal);    context.put(KafkaChannelConfiguration.KAFKA_CONSUMER_PREFIX + sampleConsumerProp, sampleConsumerVal);    final KafkaChannel channel = createChannel(context);    Assert.assertEquals(sampleProducerVal, channel.getProducerProps().getProperty(sampleProducerProp));    Assert.assertEquals(sampleConsumerVal, channel.getConsumerProps().getProperty(sampleConsumerProp));    context = prepareDefaultContext(false);    channel.configure(context);    Assert.assertNull(channel.getProducerProps().getProperty(sampleProducerProp));    Assert.assertNull(channel.getConsumerProps().getProperty(sampleConsumerProp));}
3e3f42bbf28181bdda957e2b2575504cf51b56fc817cd01385f40464e95bfae8
doTestNullKeyNoHeader
private void doTestNullKeyNoHeader() throws Exception
{    final KafkaChannel channel = startChannel(false);    Properties props = channel.getProducerProps();    KafkaProducer<String, byte[]> producer = new KafkaProducer<>(props);    for (int i = 0; i < 50; i++) {        ProducerRecord<String, byte[]> data = new ProducerRecord<>(topic, null, String.valueOf(i).getBytes());        producer.send(data).get();    }    ExecutorCompletionService<Void> submitterSvc = new ExecutorCompletionService<>(Executors.newCachedThreadPool());    List<Event> events = pullEvents(channel, submitterSvc, 50, false, false);    wait(submitterSvc, 5);    List<String> finals = new ArrayList<>(50);    for (int i = 0; i < 50; i++) {        finals.add(i, events.get(i).getHeaders().get(KEY_HEADER));    }    for (int i = 0; i < 50; i++) {        Assert.assertTrue(finals.get(i) == null);    }    channel.stop();}
530137ee806f35e52836ef82c1edb9fcbc9ece095a45f347fbedd0185e1a56ca
doTestStopAndStart
private void doTestStopAndStart(boolean rollback, boolean retryAfterRollback) throws Exception
{    final KafkaChannel channel = startChannel(true);    ExecutorService underlying = Executors.newCachedThreadPool();    ExecutorCompletionService<Void> submitterSvc = new ExecutorCompletionService<>(underlying);    final List<List<Event>> events = createBaseList();    putEvents(channel, events, submitterSvc);    wait(submitterSvc, 5);    channel.stop();    final KafkaChannel channel2 = startChannel(true);    int total = 50;    if (rollback && !retryAfterRollback) {        total = 40;    }    final List<Event> eventsPulled = pullEvents(channel2, submitterSvc, total, rollback, retryAfterRollback);    wait(submitterSvc, 5);    channel2.stop();    if (!retryAfterRollback && rollback) {        final KafkaChannel channel3 = startChannel(true);        int expectedRemaining = 50 - eventsPulled.size();        final List<Event> eventsPulled2 = pullEvents(channel3, submitterSvc, expectedRemaining, false, false);        wait(submitterSvc, 5);        Assert.assertEquals(expectedRemaining, eventsPulled2.size());        eventsPulled.addAll(eventsPulled2);        channel3.stop();    }    underlying.shutdownNow();    verify(eventsPulled);}
48b9886e530661b2b323cef0ee7b37e209245c80d73075643a5d3baa2daa1b60
testMetricsCount
public void testMetricsCount() throws Exception
{    final KafkaChannel channel = startChannel(true);    ExecutorService underlying = Executors.newCachedThreadPool();    ExecutorCompletionService<Void> submitterSvc = new ExecutorCompletionService<Void>(underlying);    final List<List<Event>> events = createBaseList();    putEvents(channel, events, submitterSvc);    takeEventsWithCommittingTxn(channel, 50);    KafkaChannelCounter counter = (KafkaChannelCounter) Whitebox.getInternalState(channel, "counter");    Assert.assertEquals(50, counter.getEventPutAttemptCount());    Assert.assertEquals(50, counter.getEventPutSuccessCount());    Assert.assertEquals(50, counter.getEventTakeAttemptCount());    Assert.assertEquals(50, counter.getEventTakeSuccessCount());    channel.stop();}
163885029fbfb4b31cc84daa8eda2b4a1241937243918de94c782b67d8a2931e
takeEventsWithCommittingTxn
private void takeEventsWithCommittingTxn(KafkaChannel channel, long eventsCount)
{    List<Event> takeEventsList = new ArrayList<>();    Transaction txn = channel.getTransaction();    txn.begin();    while (takeEventsList.size() < eventsCount) {        Event event = channel.take();        if (event != null) {            takeEventsList.add(event);        }    }    txn.commit();    txn.close();}
a8f8a5073e97a792e06b6477d614cfe2353999ff0388b62aa18f6c33c8633bf4
setupClass
public static void setupClass() throws Exception
{    testUtil.prepare();    Thread.sleep(2500);}
27681e68ec2a1eb903f955680ebe003ceb3707295c8aad884b692d378c6e37cf
setup
public void setup() throws Exception
{    topic = findUnusedTopic();    createTopic(topic, DEFAULT_TOPIC_PARTITIONS);    Thread.sleep(2500);}
7bc01499962f9db4f29ce028fa1e575b4b5f7e9b37f763467d82ccb96ea15886
tearDown
public static void tearDown()
{    testUtil.tearDown();}
ae4d81ba1a180d0e714ff6bdd6e8a71e5365a18f74684cebba460621d24cbba9
findUnusedTopic
 String findUnusedTopic()
{    String newTopic = null;    boolean topicFound = false;    while (!topicFound) {        newTopic = RandomStringUtils.randomAlphabetic(8);        if (!usedTopics.contains(newTopic)) {            usedTopics.add(newTopic);            topicFound = true;        }    }    return newTopic;}
79086eb33c99f0da3f5f0f71865599ec7612ca98ca5963eea7a2d344feb2d166
createTopic
 static void createTopic(String topicName, int numPartitions)
{    testUtil.createTopics(Collections.singletonList(topicName), numPartitions);}
fd5c1844647806d7605876b10a1f4469c300e9ccb21ffb65b7af240732357195
deleteTopic
 static void deleteTopic(String topicName)
{    testUtil.deleteTopic(topicName);}
f686e52c181ec80215302c95672da22470a0be07d08375c17d001eb170581d02
startChannel
 KafkaChannel startChannel(boolean parseAsFlume) throws Exception
{    Context context = prepareDefaultContext(parseAsFlume);    KafkaChannel channel = createChannel(context);    channel.start();    return channel;}
5ed4bcb71544beece8134535e7fad22f689711f75a31fa662d41eac939636095
prepareDefaultContext
 Context prepareDefaultContext(boolean parseAsFlume)
{        Context context = new Context();    context.put(BOOTSTRAP_SERVERS_CONFIG, testUtil.getKafkaServerUrl());    context.put(PARSE_AS_FLUME_EVENT, String.valueOf(parseAsFlume));    context.put(TOPIC_CONFIG, topic);    context.put(KAFKA_CONSUMER_PREFIX + "max.poll.interval.ms", "10000");    return context;}
60660ea65c6ffd88b6bb626c15d41fea6289ffcf642c8287cb69468dca1cf3a0
createChannel
 KafkaChannel createChannel(Context context) throws Exception
{    final KafkaChannel channel = new KafkaChannel();    Configurables.configure(channel, context);    return channel;}
eb79232bc1e749481b07b057ffbde060da7c8a6a50f1654c6325448b9ad8b740
pullEvents
 List<Event> pullEvents(final KafkaChannel channel, ExecutorCompletionService<Void> submitterSvc, final int total, final boolean testRollbacks, final boolean retryAfterRollback)
{    final List<Event> eventsPulled = Collections.synchronizedList(new ArrayList<Event>(50));    final CyclicBarrier barrier = new CyclicBarrier(5);    final AtomicInteger counter = new AtomicInteger(0);    final AtomicInteger rolledBackCount = new AtomicInteger(0);    final AtomicBoolean startedGettingEvents = new AtomicBoolean(false);    final AtomicBoolean rolledBack = new AtomicBoolean(false);    for (int k = 0; k < 5; k++) {        final int index = k;        submitterSvc.submit(new Callable<Void>() {            @Override            public Void call() throws Exception {                Transaction tx = null;                final List<Event> eventsLocal = Lists.newLinkedList();                channel.registerThread();                Thread.sleep(1000);                barrier.await();                while (counter.get() < (total - rolledBackCount.get())) {                    if (tx == null) {                        tx = channel.getTransaction();                        tx.begin();                    }                    try {                        Event e = channel.take();                        if (e != null) {                            startedGettingEvents.set(true);                            eventsLocal.add(e);                        } else {                            if (testRollbacks && index == 4 && (!rolledBack.get()) && startedGettingEvents.get()) {                                tx.rollback();                                tx.close();                                tx = null;                                rolledBack.set(true);                                final int eventsLocalSize = eventsLocal.size();                                eventsLocal.clear();                                if (!retryAfterRollback) {                                    rolledBackCount.set(eventsLocalSize);                                    return null;                                }                            } else {                                tx.commit();                                tx.close();                                tx = null;                                eventsPulled.addAll(eventsLocal);                                counter.getAndAdd(eventsLocal.size());                                eventsLocal.clear();                            }                        }                    } catch (Exception ex) {                        eventsLocal.clear();                        if (tx != null) {                            tx.rollback();                            tx.close();                        }                        tx = null;                        ex.printStackTrace();                    }                }                                return null;            }        });    }    return eventsPulled;}
d12537fee0d4fb03a2b54ca4cc2cb7aeeb6659af2e7d4f187baf67a1d3ca17d2
call
public Void call() throws Exception
{    Transaction tx = null;    final List<Event> eventsLocal = Lists.newLinkedList();    channel.registerThread();    Thread.sleep(1000);    barrier.await();    while (counter.get() < (total - rolledBackCount.get())) {        if (tx == null) {            tx = channel.getTransaction();            tx.begin();        }        try {            Event e = channel.take();            if (e != null) {                startedGettingEvents.set(true);                eventsLocal.add(e);            } else {                if (testRollbacks && index == 4 && (!rolledBack.get()) && startedGettingEvents.get()) {                    tx.rollback();                    tx.close();                    tx = null;                    rolledBack.set(true);                    final int eventsLocalSize = eventsLocal.size();                    eventsLocal.clear();                    if (!retryAfterRollback) {                        rolledBackCount.set(eventsLocalSize);                        return null;                    }                } else {                    tx.commit();                    tx.close();                    tx = null;                    eventsPulled.addAll(eventsLocal);                    counter.getAndAdd(eventsLocal.size());                    eventsLocal.clear();                }            }        } catch (Exception ex) {            eventsLocal.clear();            if (tx != null) {                tx.rollback();                tx.close();            }            tx = null;            ex.printStackTrace();        }    }        return null;}
cb4f3b764f5374db7d808c75c08dd86d6f322840f3fb41922706ca8e616d0af7
wait
 void wait(ExecutorCompletionService<Void> submitterSvc, int max) throws Exception
{    int completed = 0;    while (completed < max) {        submitterSvc.take();        completed++;    }}
392ac57af9c747a99327613860028ad0eca9d9a3126d6c9e750c50db7d7d0637
createBaseList
 List<List<Event>> createBaseList()
{    final List<List<Event>> events = new ArrayList<>();    for (int i = 0; i < 5; i++) {        List<Event> eventList = new ArrayList<>(10);        events.add(eventList);        for (int j = 0; j < 10; j++) {            Map<String, String> hdrs = new HashMap<>();            String v = (String.valueOf(i) + " - " + String.valueOf(j));            hdrs.put("header", v);            eventList.add(EventBuilder.withBody(v.getBytes(), hdrs));        }    }    return events;}
6f5f617421bd7a50cae145b41ec0b06854c1292b803241afc7a662cbd1e2c94c
putEvents
 void putEvents(final KafkaChannel channel, final List<List<Event>> events, ExecutorCompletionService<Void> submitterSvc)
{    for (int i = 0; i < 5; i++) {        final int index = i;        submitterSvc.submit(new Callable<Void>() {            @Override            public Void call() {                Transaction tx = channel.getTransaction();                tx.begin();                List<Event> eventsToPut = events.get(index);                for (int j = 0; j < 10; j++) {                    channel.put(eventsToPut.get(j));                }                try {                    tx.commit();                } finally {                    tx.close();                }                return null;            }        });    }}
129e071a5acdf44209957699325f269c391c2463b78b7efe09056606615ae94b
call
public Void call()
{    Transaction tx = channel.getTransaction();    tx.begin();    List<Event> eventsToPut = events.get(index);    for (int j = 0; j < 10; j++) {        channel.put(eventsToPut.get(j));    }    try {        tx.commit();    } finally {        tx.close();    }    return null;}
41503ff1f2e51bed0e9a5703d21d106511ce78425ab73afd2ac665be32752eaa
verify
 void verify(List<Event> eventsPulled)
{    Assert.assertFalse(eventsPulled.isEmpty());    Assert.assertEquals(50, eventsPulled.size());    Set<String> eventStrings = new HashSet<>();    for (Event e : eventsPulled) {        Assert.assertEquals(e.getHeaders().get("header"), new String(e.getBody()));        eventStrings.add(e.getHeaders().get("header"));    }    for (int i = 0; i < 5; i++) {        for (int j = 0; j < 10; j++) {            String v = String.valueOf(i) + " - " + String.valueOf(j);            Assert.assertTrue(eventStrings.contains(v));            eventStrings.remove(v);        }    }    Assert.assertTrue(eventStrings.isEmpty());}
34094e83ce9d1d18ed0a550d28caa22887200afb6e36205ec9b03439b313be73
testOffsetsNotCommittedOnStop
public void testOffsetsNotCommittedOnStop() throws Exception
{    String message = "testOffsetsNotCommittedOnStop-" + System.nanoTime();    KafkaChannel channel = startChannel(false);    KafkaProducer<String, byte[]> producer = new KafkaProducer<>(channel.getProducerProps());    ProducerRecord<String, byte[]> data = new ProducerRecord<>(topic, "header-" + message, message.getBytes());    producer.send(data).get();    producer.flush();    producer.close();    Event event = takeEventWithoutCommittingTxn(channel);    Assert.assertNotNull(event);    Assert.assertTrue(Arrays.equals(message.getBytes(), event.getBody()));        channel.stop();    channel = startChannel(false);        event = takeEventWithoutCommittingTxn(channel);    Assert.assertNotNull(event);    Assert.assertTrue(Arrays.equals(message.getBytes(), event.getBody()));}
9013435a7d2832768d92dce6d230707c75d638ff04a3ac9af59726d076fcc3fe
testMigrateOffsetsNone
public void testMigrateOffsetsNone() throws Exception
{    doTestMigrateZookeeperOffsets(false, false, "testMigrateOffsets-none");}
46e3a714348321e56822d77382d1ab3684d504556fc564d42334d3ce3950a209
testMigrateOffsetsZookeeper
public void testMigrateOffsetsZookeeper() throws Exception
{    doTestMigrateZookeeperOffsets(true, false, "testMigrateOffsets-zookeeper");}
8a8d3c57baf073c92f55a995afb1fea6ae5a93a5b5f6905a6b8ec7ac46a87985
testMigrateOffsetsKafka
public void testMigrateOffsetsKafka() throws Exception
{    doTestMigrateZookeeperOffsets(false, true, "testMigrateOffsets-kafka");}
1ec8e570babff831d12e16c7e88fd169155e884dc0355f52292055fe9543b209
testMigrateOffsetsBoth
public void testMigrateOffsetsBoth() throws Exception
{    doTestMigrateZookeeperOffsets(true, true, "testMigrateOffsets-both");}
5d9b4efd3ca10ae5eaa6d896e9e42c36bb1c996ec86ede1f84009385651849f6
takeEventWithoutCommittingTxn
private Event takeEventWithoutCommittingTxn(KafkaChannel channel)
{    for (int i = 0; i < 10; i++) {        Transaction txn = channel.getTransaction();        txn.begin();        Event event = channel.take();        if (event != null) {            return event;        } else {            txn.commit();            txn.close();        }    }    return null;}
991597c704b93a56b51bceb0265ec8fb52e75cbd137270191bd756d3b6a75837
doTestMigrateZookeeperOffsets
private void doTestMigrateZookeeperOffsets(boolean hasZookeeperOffsets, boolean hasKafkaOffsets, String group) throws Exception
{        topic = findUnusedTopic();    createTopic(topic, 1);    Context context = prepareDefaultContext(false);    context.put(ZOOKEEPER_CONNECT_FLUME_KEY, testUtil.getZkUrl());    context.put(GROUP_ID_FLUME, group);    final KafkaChannel channel = createChannel(context);        Long fifthOffset = 0L;    Long tenthOffset = 0L;    Properties props = channel.getProducerProps();    KafkaProducer<String, byte[]> producer = new KafkaProducer<>(props);    for (int i = 1; i <= 50; i++) {        ProducerRecord<String, byte[]> data = new ProducerRecord<>(topic, null, String.valueOf(i).getBytes());        RecordMetadata recordMetadata = producer.send(data).get();        if (i == 5) {            fifthOffset = recordMetadata.offset();        }        if (i == 10) {            tenthOffset = recordMetadata.offset();        }    }        if (hasZookeeperOffsets) {        KafkaZkClient zkClient = KafkaZkClient.apply(testUtil.getZkUrl(), JaasUtils.isZkSecurityEnabled(), 30000, 30000, 10, Time.SYSTEM, "kafka.server", "SessionExpireListener");        zkClient.getConsumerOffset(group, new TopicPartition(topic, 0));        Long offset = tenthOffset + 1;        zkClient.setOrCreateConsumerOffset(group, new TopicPartition(topic, 0), offset);        zkClient.close();    }        if (hasKafkaOffsets) {        Map<TopicPartition, OffsetAndMetadata> offsets = new HashMap<>();        offsets.put(new TopicPartition(topic, 0), new OffsetAndMetadata(fifthOffset + 1));        KafkaConsumer<String, byte[]> consumer = new KafkaConsumer<>(channel.getConsumerProps());        consumer.commitSync(offsets);        consumer.close();    }        channel.start();    ExecutorCompletionService<Void> submitterSvc = new ExecutorCompletionService<>(Executors.newCachedThreadPool());    List<Event> events = pullEvents(channel, submitterSvc, 20, false, false);    wait(submitterSvc, 5);    List<Integer> finals = new ArrayList<>(40);    for (Event event : events) {        finals.add(Integer.parseInt(new String(event.getBody())));    }    channel.stop();    if (!hasKafkaOffsets && !hasZookeeperOffsets) {                Assert.assertTrue("Channel should read the the first message", finals.contains(1));    } else if (hasKafkaOffsets && hasZookeeperOffsets) {                Assert.assertFalse("Channel should not read the 5th message", finals.contains(5));        Assert.assertTrue("Channel should read the 6th message", finals.contains(6));    } else if (hasKafkaOffsets) {                Assert.assertFalse("Channel should not read the 5th message", finals.contains(5));        Assert.assertTrue("Channel should read the 6th message", finals.contains(6));    } else {                Assert.assertFalse("Channel should not read the 10th message", finals.contains(10));        Assert.assertTrue("Channel should read the 11th message", finals.contains(11));    }}
ef8dbf440fb66cb86787b44e402977ce22afa22b01d45709a90775db2e8043fa
testMigrateZookeeperOffsetsWhenTopicNotExists
public void testMigrateZookeeperOffsetsWhenTopicNotExists() throws Exception
{    topic = findUnusedTopic();    Context context = prepareDefaultContext(false);    context.put(ZOOKEEPER_CONNECT_FLUME_KEY, testUtil.getZkUrl());    context.put(GROUP_ID_FLUME, "testMigrateOffsets-nonExistingTopic");    KafkaChannel channel = createChannel(context);    channel.start();    Assert.assertEquals(LifecycleState.START, channel.getLifecycleState());    channel.stop();}
e48d1677285889268cb07f67b10d61011eb172d28de610dbc16dc9863b79f793
testParseAsFlumeEventFalse
public void testParseAsFlumeEventFalse() throws Exception
{    doParseAsFlumeEventFalse(false);}
2d65d7ad60c487944fea5dee22cdd368cc28741fa382ee31f37f75c431f71831
testParseAsFlumeEventFalseCheckHeader
public void testParseAsFlumeEventFalseCheckHeader() throws Exception
{    doParseAsFlumeEventFalse(true);}
4c6aac3126f31c25f6b4c65f13f25be707336d21e3ac0f9075fc88c33e04e19a
testParseAsFlumeEventFalseAsSource
public void testParseAsFlumeEventFalseAsSource() throws Exception
{    doParseAsFlumeEventFalseAsSource(false);}
f9fb923c4d53560222b09b83cef6dfd7296167bf45c5c5cd1379f3bcf20c16dd
testParseAsFlumeEventFalseAsSourceCheckHeader
public void testParseAsFlumeEventFalseAsSourceCheckHeader() throws Exception
{    doParseAsFlumeEventFalseAsSource(true);}
0199a292a959d441af3d86c7a2ac82e95a27040e5176c6e4734aaab7f04f1d4b
doParseAsFlumeEventFalse
private void doParseAsFlumeEventFalse(Boolean checkHeaders) throws Exception
{    final KafkaChannel channel = startChannel(false);    Properties props = channel.getProducerProps();    KafkaProducer<String, byte[]> producer = new KafkaProducer<>(props);    for (int i = 0; i < 50; i++) {        ProducerRecord<String, byte[]> data = new ProducerRecord<>(topic, String.valueOf(i) + "-header", String.valueOf(i).getBytes());        producer.send(data).get();    }    ExecutorCompletionService<Void> submitterSvc = new ExecutorCompletionService<>(Executors.newCachedThreadPool());    List<Event> events = pullEvents(channel, submitterSvc, 50, false, false);    wait(submitterSvc, 5);    Map<Integer, String> finals = new HashMap<>();    for (int i = 0; i < 50; i++) {        finals.put(Integer.parseInt(new String(events.get(i).getBody())), events.get(i).getHeaders().get(KEY_HEADER));    }    for (int i = 0; i < 50; i++) {        Assert.assertTrue(finals.keySet().contains(i));        if (checkHeaders) {            Assert.assertTrue(finals.containsValue(String.valueOf(i) + "-header"));        }        finals.remove(i);    }    Assert.assertTrue(finals.isEmpty());    channel.stop();}
b6e5407617811af293e65153c1d35d866a512460c6dba808bac22d12ddc3bdb9
doParseAsFlumeEventFalseAsSource
private void doParseAsFlumeEventFalseAsSource(Boolean checkHeaders) throws Exception
{    final KafkaChannel channel = startChannel(false);    List<String> msgs = new ArrayList<>();    Map<String, String> headers = new HashMap<>();    for (int i = 0; i < 50; i++) {        msgs.add(String.valueOf(i));    }    Transaction tx = channel.getTransaction();    tx.begin();    for (int i = 0; i < msgs.size(); i++) {        headers.put(KEY_HEADER, String.valueOf(i) + "-header");        channel.put(EventBuilder.withBody(msgs.get(i).getBytes(), headers));    }    tx.commit();    ExecutorCompletionService<Void> submitterSvc = new ExecutorCompletionService<>(Executors.newCachedThreadPool());    List<Event> events = pullEvents(channel, submitterSvc, 50, false, false);    wait(submitterSvc, 5);    Map<Integer, String> finals = new HashMap<>();    for (int i = 0; i < 50; i++) {        finals.put(Integer.parseInt(new String(events.get(i).getBody())), events.get(i).getHeaders().get(KEY_HEADER));    }    for (int i = 0; i < 50; i++) {        Assert.assertTrue(finals.keySet().contains(i));        if (checkHeaders) {            Assert.assertTrue(finals.containsValue(String.valueOf(i) + "-header"));        }        finals.remove(i);    }    Assert.assertTrue(finals.isEmpty());    channel.stop();}
439d573a8fe6b9f67a27cb60e2850e6a12d6480c39c2bbdf25dd441abd3588d4
testPartitionHeaderSet
public void testPartitionHeaderSet() throws Exception
{    doPartitionHeader(PartitionTestScenario.PARTITION_ID_HEADER_ONLY);}
aa3bd505695f5347aecf0584c09825cc85b68fedd4e1a15a589bb064aea95eea
testPartitionHeaderNotSet
public void testPartitionHeaderNotSet() throws Exception
{    doPartitionHeader(PartitionTestScenario.NO_PARTITION_HEADERS);}
2694c4434a057bdd807b5b20e95415c2ed1d9b91a19744eafb63da3ea4601d47
testStaticPartitionAndHeaderSet
public void testStaticPartitionAndHeaderSet() throws Exception
{    doPartitionHeader(PartitionTestScenario.STATIC_HEADER_AND_PARTITION_ID);}
5eaa1a43820208b4c4e044780230d07518ef48fcad085c3a7ce2d9472037a50e
testStaticPartitionHeaderNotSet
public void testStaticPartitionHeaderNotSet() throws Exception
{    doPartitionHeader(PartitionTestScenario.STATIC_HEADER_ONLY);}
22202a1c65bf8e178130f9ea56f5104fd95be5bbcdce9664f0c4709798313016
testPartitionHeaderMissing
public void testPartitionHeaderMissing() throws Exception
{    doPartitionErrors(PartitionOption.NOTSET);}
428921eedf5c0fe05642b500b5eff30c5f5a633b42f3e5d6e097c0a2fc8a4d53
testPartitionHeaderOutOfRange
public void testPartitionHeaderOutOfRange() throws Exception
{    doPartitionErrors(PartitionOption.VALIDBUTOUTOFRANGE);}
079276eeaa368790038bc1fb2fa30a09c7ad5d93e60756a45a19a82242cb84a6
testPartitionHeaderInvalid
public void testPartitionHeaderInvalid() throws Exception
{    doPartitionErrors(PartitionOption.NOTANUMBER);}
019b2ec0724485a6c391f6dc7e4ecc873c4ff11d039c6295eee9328aff3b82bf
doPartitionHeader
private void doPartitionHeader(PartitionTestScenario scenario) throws Exception
{    final int numPtns = DEFAULT_TOPIC_PARTITIONS;    final int numMsgs = numPtns * 10;    final Integer staticPtn = DEFAULT_TOPIC_PARTITIONS - 2;    Context context = prepareDefaultContext(false);    if (scenario == PartitionTestScenario.PARTITION_ID_HEADER_ONLY || scenario == PartitionTestScenario.STATIC_HEADER_AND_PARTITION_ID) {        context.put(PARTITION_HEADER_NAME, "partition-header");    }    if (scenario == PartitionTestScenario.STATIC_HEADER_AND_PARTITION_ID || scenario == PartitionTestScenario.STATIC_HEADER_ONLY) {        context.put(STATIC_PARTITION_CONF, staticPtn.toString());    }    final KafkaChannel channel = createChannel(context);    channel.start();            Map<Integer, List<Event>> partitionMap = new HashMap<>(numPtns);    for (int i = 0; i < numPtns; i++) {        partitionMap.put(i, new ArrayList<Event>());    }    Transaction tx = channel.getTransaction();    tx.begin();    List<Event> orderedEvents = KafkaPartitionTestUtil.generateSkewedMessageList(scenario, numMsgs, partitionMap, numPtns, staticPtn);    for (Event event : orderedEvents) {        channel.put(event);    }    tx.commit();    Map<Integer, List<byte[]>> resultsMap = KafkaPartitionTestUtil.retrieveRecordsFromPartitions(topic, numPtns, channel.getConsumerProps());    KafkaPartitionTestUtil.checkResultsAgainstSkew(scenario, partitionMap, resultsMap, staticPtn, numMsgs);    channel.stop();}
f26d2592b519db23f19acfb585a34e0fb1a58018e1c22759fef53da8065bb883
doPartitionErrors
private void doPartitionErrors(PartitionOption option) throws Exception
{    Context context = prepareDefaultContext(false);    context.put(PARTITION_HEADER_NAME, KafkaPartitionTestUtil.PARTITION_HEADER);    String tempTopic = findUnusedTopic();    createTopic(tempTopic, 5);    final KafkaChannel channel = createChannel(context);    channel.start();    Transaction tx = channel.getTransaction();    tx.begin();    Map<String, String> headers = new HashMap<>();    switch(option) {        case VALIDBUTOUTOFRANGE:            headers.put(KafkaPartitionTestUtil.PARTITION_HEADER, String.valueOf(DEFAULT_TOPIC_PARTITIONS + 2));            break;        case NOTSET:            headers.put("wrong-header", "2");            break;        case NOTANUMBER:            headers.put(KafkaPartitionTestUtil.PARTITION_HEADER, "not-a-number");            break;        default:            break;    }    Event event = EventBuilder.withBody(String.valueOf(9).getBytes(), headers);    channel.put(event);    tx.commit();    deleteTopic(tempTopic);}
abfa9f4847814bf14dfc941f721a69c7cee0bc0eab31f788639f03dc4f1affb1
testSuccess
public void testSuccess() throws Exception
{    doTestSuccessRollback(false, false);}
47c408c57186c9da814e70d1f58a3a86151bac8456007a8e668d3be525d27b7d
testSuccessInterleave
public void testSuccessInterleave() throws Exception
{    doTestSuccessRollback(false, true);}
ba7f134eb8e67018766470d33ad084c510743b59bc28c46bb142075afe4acc9c
testRollbacks
public void testRollbacks() throws Exception
{    doTestSuccessRollback(true, false);}
6b7356d3f0f44ac90ad26a6ed0c865ff2854d921f3b01a6fc79402728e4d554b
testRollbacksInterleave
public void testRollbacksInterleave() throws Exception
{    doTestSuccessRollback(true, true);}
c7cff4bcaa5a1f1ee9135c0215961a1ae88e57e66911be97c97ed0607a630c6e
doTestSuccessRollback
private void doTestSuccessRollback(final boolean rollback, final boolean interleave) throws Exception
{    final KafkaChannel channel = startChannel(true);    writeAndVerify(rollback, channel, interleave);    channel.stop();}
75e53403ad7c34b6dd768615d752e4fc6d77fb7e76338920de1064c8ee2ef6c4
writeAndVerify
private void writeAndVerify(final boolean testRollbacks, final KafkaChannel channel, final boolean interleave) throws Exception
{    final List<List<Event>> events = createBaseList();    ExecutorCompletionService<Void> submitterSvc = new ExecutorCompletionService<Void>(Executors.newCachedThreadPool());    putEvents(channel, events, submitterSvc);    if (interleave) {        wait(submitterSvc, 5);    }    ExecutorCompletionService<Void> submitterSvc2 = new ExecutorCompletionService<Void>(Executors.newCachedThreadPool());    final List<Event> eventsPulled = pullEvents(channel, submitterSvc2, 50, testRollbacks, true);    if (!interleave) {        wait(submitterSvc, 5);    }    wait(submitterSvc2, 5);    verify(eventsPulled);}
06afc905ccc8c7ac21595c61130cd017693c566a830c98e9d49a20a3db34407d
getTotalStored
protected int getTotalStored()
{    return totalStored.availablePermits();}
3a41a411877758f36590e1fe9fd7479c89c261536f84ab0985c56e8d4c5cb4f8
getMemoryCapacity
public int getMemoryCapacity()
{    return memoryCapacity;}
de23e962b3a7b392edb551c20d5f2e0c78e823b2c2b242cb18ac5a79139d4837
getOverflowTimeout
public int getOverflowTimeout()
{    return overflowTimeout;}
ccacf6f30a132de0698334a39d8062313b60f58b9a2c065fb67cdfa35c7e7da4
getMaxMemQueueSize
public int getMaxMemQueueSize()
{    return maxMemQueueSize;}
666ec1acdc37918494e062f4cb92248ba2085d6a181d4dd23d54d9cdba27b3f6
getOverflowCapacity
protected Integer getOverflowCapacity()
{    return overflowCapacity;}
a8978108b23c0ebb3d22b4d324fdba8e41e7623dfb4c1428fc1c1fd44d4abde7
isOverflowDisabled
protected boolean isOverflowDisabled()
{    return overflowDisabled;}
fc2e4990be81a2672e44d90020869c02e4f082ea2eaab5734c3eaa463caffa4e
queueSize
public int queueSize()
{    synchronized (queueLock) {        return memQueue.size();    }}
5b8f9d63f4341530dbf936cdcb0773f4c8d12ffc5218c3f3f162717d29b4d414
add
public void add(int amount)
{    value += amount;}
2e357842a94cbe0053b9335d638b77fbb7cf048124996f871e25c3069c81a0b7
intValue
public int intValue()
{    return value;}
e7daf8b2ce3177c095695e7644426fe09e80b39aa02592fd6c1ccf4cf24ce3ee
dump
public String dump()
{    StringBuilder sb = new StringBuilder();    sb.append("  [ ");    for (MutableInteger i : queue) {        sb.append(i.intValue());        sb.append(" ");    }    sb.append("]");    return sb.toString();}
1529c4b1c32e6b66c9598d47d716d14aef9351093015b7f9cc57a9362f408be5
putPrimary
public void putPrimary(Integer eventCount)
{    totalPuts += eventCount;    if ((queue.peekLast() == null) || queue.getLast().intValue() < 0) {        queue.addLast(new MutableInteger(eventCount));    } else {        queue.getLast().add(eventCount);    }}
14664fba9b0281d903c5050addb413beba9d473e3451631e927d9e078b361103
putFirstPrimary
public void putFirstPrimary(Integer eventCount)
{    if ((queue.peekFirst() == null) || queue.getFirst().intValue() < 0) {        queue.addFirst(new MutableInteger(eventCount));    } else {        queue.getFirst().add(eventCount);    }}
bf3f04cafd5c3096603bd3308834c72e8308df485c971127d88f389a27341709
putOverflow
public void putOverflow(Integer eventCount)
{    totalPuts += eventCount;    if ((queue.peekLast() == null) || queue.getLast().intValue() > 0) {        queue.addLast(new MutableInteger(-eventCount));    } else {        queue.getLast().add(-eventCount);    }    overflowCounter += eventCount;}
a71188209c91f0743d2c64122f2f90d132b08b57f986c2a1ce1f02ebab27c1c2
putFirstOverflow
public void putFirstOverflow(Integer eventCount)
{    if ((queue.peekFirst() == null) || queue.getFirst().intValue() > 0) {        queue.addFirst(new MutableInteger(-eventCount));    } else {        queue.getFirst().add(-eventCount);    }    overflowCounter += eventCount;}
29b00f2a07e2e06484d539f05030bdfa4e630d53c65b090d41acd221905c06d1
front
public int front()
{    return queue.getFirst().intValue();}
803915e853382ad445a6e2333fabb8beb8e4acd70e908a0d818400f7baac42af
isEmpty
public boolean isEmpty()
{    return queue.isEmpty();}
f7c4e5d20f78c1306c3dee0f414d057da47f42d51878eb738acb4e04a2dec3b1
takePrimary
public void takePrimary(int takeCount)
{    MutableInteger headValue = queue.getFirst();        if (headValue.intValue() < takeCount) {        throw new IllegalStateException("Cannot take " + takeCount + " from " + headValue.intValue() + " in DrainOrder Queue");    }    headValue.add(-takeCount);    if (headValue.intValue() == 0) {        queue.removeFirst();    }}
5790bae00a3a31304911318a96eb183c7f7e5ee34f1857df7933d5b81945bd50
takeOverflow
public void takeOverflow(int takeCount)
{    MutableInteger headValue = queue.getFirst();    if (headValue.intValue() > -takeCount) {        throw new IllegalStateException("Cannot take " + takeCount + " from " + headValue.intValue() + " in DrainOrder Queue head ");    }    headValue.add(takeCount);    if (headValue.intValue() == 0) {        queue.removeFirst();    }    overflowCounter -= takeCount;}
1e146b07faa919b1916e630a172c03c6ebfc96663a23166e205cd71924113b12
begin
public void begin()
{    super.begin();}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{    if (overflowTakeTx != null) {        overflowTakeTx.close();    }    if (overflowPutTx != null) {        overflowPutTx.close();    }    super.close();}
12f20da1039baa55cd8cd24a8512df38790e6cb0af896f04ec9f5012ddf00b9a
doPut
protected void doPut(Event event) throws InterruptedException
{    channelCounter.incrementEventPutAttemptCount();    putCalled = true;    int eventByteSize = (int) Math.ceil(estimateEventSize(event) / avgEventSize);    if (!putList.offer(event)) {        throw new ChannelFullException("Put queue in " + getName() + " channel's Transaction having capacity " + putList.size() + " full, consider reducing batch size of sources");    }    putListByteCount += eventByteSize;}
f8425491b25802703eb5080383b86f3b99d38a0998a1c49a9f85e4971cf4e57c
doTake
protected Event doTake() throws InterruptedException
{    channelCounter.incrementEventTakeAttemptCount();    if (!totalStored.tryAcquire(overflowTimeout, TimeUnit.SECONDS)) {        LOGGER.debug("Take is backing off as channel is empty.");        return null;    }    boolean takeSuceeded = false;    try {        Event event;        synchronized (queueLock) {            int drainOrderTop = drainOrder.front();            if (!takeCalled) {                takeCalled = true;                if (drainOrderTop < 0) {                    useOverflow = true;                    overflowTakeTx = getOverflowTx();                    overflowTakeTx.begin();                }            }            if (useOverflow) {                if (drainOrderTop > 0) {                    LOGGER.debug("Take is switching to primary");                                        return null;                }                event = overflowTakeTx.take();                ++takeCount;                drainOrder.takeOverflow(1);            } else {                if (drainOrderTop < 0) {                    LOGGER.debug("Take is switching to overflow");                                        return null;                }                event = memQueue.poll();                ++takeCount;                drainOrder.takePrimary(1);                Preconditions.checkNotNull(event, "Queue.poll returned NULL despite" + " semaphore signalling existence of entry");            }        }        int eventByteSize = (int) Math.ceil(estimateEventSize(event) / avgEventSize);        if (!useOverflow) {                        takeList.offer(event);        }        takeListByteCount += eventByteSize;        takeSuceeded = true;        return event;    } finally {        if (!takeSuceeded) {            totalStored.release();        }    }}
1665f7d1b67a1fa794c9fb67a1be01e4bf6a8b0e782a8f9a49914917f9ecf058
doCommit
protected void doCommit() throws InterruptedException
{    if (putCalled) {        putCommit();        if (LOGGER.isDebugEnabled()) {            LOGGER.debug("Put Committed. Drain Order Queue state : " + drainOrder.dump());        }    } else if (takeCalled) {        takeCommit();        if (LOGGER.isDebugEnabled()) {            LOGGER.debug("Take Committed. Drain Order Queue state : " + drainOrder.dump());        }    }}
870975b32fd7fed8bb62226fbda741bfb6e12de8814a52094396fb2415a7184f
takeCommit
private void takeCommit()
{    if (takeCount > largestTakeTxSize) {        largestTakeTxSize = takeCount;    }    synchronized (queueLock) {        if (overflowTakeTx != null) {            overflowTakeTx.commit();        }        double memoryPercentFree = (memoryCapacity == 0) ? 0 : (memoryCapacity - memQueue.size() + takeCount) / (double) memoryCapacity;        if (overflowActivated && memoryPercentFree >= overflowDeactivationThreshold) {            overflowActivated = false;            LOGGER.info("Overflow Deactivated");        }        channelCounter.setChannelSize(getTotalStored());    }    if (!useOverflow) {        memQueRemaining.release(takeCount);        bytesRemaining.release(takeListByteCount);    }    channelCounter.addToEventTakeSuccessCount(takeCount);}
f4c502159c65b1af2daa4f6c9d3a3898daed6a2a3845ab1113ca72c2000ba19f
putCommit
private void putCommit() throws InterruptedException
{        int timeout = overflowActivated ? 0 : overflowTimeout;    if (memoryCapacity != 0) {                if (!memQueRemaining.tryAcquire(putList.size(), timeout, TimeUnit.SECONDS)) {            if (overflowDisabled) {                throw new ChannelFullException("Spillable Memory Channel's " + "memory capacity has been reached and overflow is " + "disabled. Consider increasing memoryCapacity.");            }            overflowActivated = true;            useOverflow = true;                } else if (!bytesRemaining.tryAcquire(putListByteCount, overflowTimeout, TimeUnit.SECONDS)) {            memQueRemaining.release(putList.size());            if (overflowDisabled) {                throw new ChannelFullException("Spillable Memory Channel's " + "memory capacity has been reached.  " + (bytesRemaining.availablePermits() * (int) avgEventSize) + " bytes are free and overflow is disabled. Consider " + "increasing byteCapacity or capacity.");            }            overflowActivated = true;            useOverflow = true;        }    } else {        useOverflow = true;    }    if (putList.size() > largestPutTxSize) {        largestPutTxSize = putList.size();    }    if (useOverflow) {        commitPutsToOverflow();    } else {        commitPutsToPrimary();    }}
a9b50cc978162dbd923a87d05f64852735114fcc0a229d14f33f4e2c618275a6
commitPutsToOverflow
private void commitPutsToOverflow() throws InterruptedException
{    overflowPutTx = getOverflowTx();    overflowPutTx.begin();    for (Event event : putList) {        overflowPutTx.put(event);    }    commitPutsToOverflow_core(overflowPutTx);    totalStored.release(putList.size());    overflowPutCount += putList.size();    channelCounter.addToEventPutSuccessCount(putList.size());}
96d1086607a4ca9e6df716cdf4ab23d8067921b79d2645cf3e206efe786f097e
commitPutsToOverflow_core
private void commitPutsToOverflow_core(Transaction overflowPutTx) throws InterruptedException
{        for (int i = 0; i < 2; ++i) {        try {            synchronized (queueLock) {                overflowPutTx.commit();                drainOrder.putOverflow(putList.size());                channelCounter.setChannelSize(memQueue.size() + drainOrder.overflowCounter);                break;            }        } catch (ChannelFullException e) {                        if (i == 0) {                Thread.sleep(overflowTimeout * 1000);            } else {                throw e;            }        }    }}
e96ca641a39b32261afe998b05085ed9b98c1f098f5ba4d161414db7c44b9a76
commitPutsToPrimary
private void commitPutsToPrimary()
{    synchronized (queueLock) {        for (Event e : putList) {            if (!memQueue.offer(e)) {                throw new ChannelException("Unable to insert event into memory " + "queue in spite of spare capacity, this is very unexpected");            }        }        drainOrder.putPrimary(putList.size());        maxMemQueueSize = (memQueue.size() > maxMemQueueSize) ? memQueue.size() : maxMemQueueSize;        channelCounter.setChannelSize(memQueue.size() + drainOrder.overflowCounter);    }        totalStored.release(putList.size());    channelCounter.addToEventPutSuccessCount(putList.size());}
29c03e5706a43ef13c083eeb7ced8ad018dfba403134c5972f8063e77ddd24a1
doRollback
protected void doRollback()
{    LOGGER.debug("Rollback() of " + (takeCalled ? " Take Tx" : (putCalled ? " Put Tx" : "Empty Tx")));    if (putCalled) {        if (overflowPutTx != null) {            overflowPutTx.rollback();        }        if (!useOverflow) {            bytesRemaining.release(putListByteCount);            putList.clear();        }        putListByteCount = 0;    } else if (takeCalled) {        synchronized (queueLock) {            if (overflowTakeTx != null) {                overflowTakeTx.rollback();            }            if (useOverflow) {                drainOrder.putFirstOverflow(takeCount);            } else {                int remainingCapacity = memoryCapacity - memQueue.size();                Preconditions.checkState(remainingCapacity >= takeCount, "Not enough space in memory queue to rollback takes. This" + " should never happen, please report");                while (!takeList.isEmpty()) {                    memQueue.addFirst(takeList.removeLast());                }                drainOrder.putFirstPrimary(takeCount);            }        }        totalStored.release(takeCount);    } else {        overflowTakeTx.rollback();    }    channelCounter.setChannelSize(memQueue.size() + drainOrder.overflowCounter);}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    if (    getLifecycleState() == LifecycleState.START || getLifecycleState() == LifecycleState.ERROR) {        stop();    }    if (totalStored == null) {        totalStored = new Semaphore(0);    }    if (channelCounter == null) {        channelCounter = new ChannelCounter(getName());    }        Integer newMemoryCapacity;    try {        newMemoryCapacity = context.getInteger(MEMORY_CAPACITY, defaultMemoryCapacity);        if (newMemoryCapacity == null) {            newMemoryCapacity = defaultMemoryCapacity;        }        if (newMemoryCapacity < 0) {            throw new NumberFormatException(MEMORY_CAPACITY + " must be >= 0");        }    } catch (NumberFormatException e) {        newMemoryCapacity = defaultMemoryCapacity;        LOGGER.warn("Invalid " + MEMORY_CAPACITY + " specified, initializing " + getName() + " channel to default value of {}", defaultMemoryCapacity);    }    try {        resizePrimaryQueue(newMemoryCapacity);    } catch (InterruptedException e) {        Thread.currentThread().interrupt();    }        try {        Integer newOverflowTimeout = context.getInteger(OVERFLOW_TIMEOUT, defaultOverflowTimeout);        overflowTimeout = (newOverflowTimeout != null) ? newOverflowTimeout : defaultOverflowTimeout;    } catch (NumberFormatException e) {        LOGGER.warn("Incorrect value for " + getName() + "'s " + OVERFLOW_TIMEOUT + " setting. Using default value {}", defaultOverflowTimeout);        overflowTimeout = defaultOverflowTimeout;    }    try {        Integer newThreshold = context.getInteger(OVERFLOW_DEACTIVATION_THRESHOLD);        overflowDeactivationThreshold = (newThreshold != null) ? newThreshold / 100.0 : defaultOverflowDeactivationThreshold / 100.0;    } catch (NumberFormatException e) {        LOGGER.warn("Incorrect value for " + getName() + "'s " + OVERFLOW_DEACTIVATION_THRESHOLD + ". Using default value {} %", defaultOverflowDeactivationThreshold);        overflowDeactivationThreshold = defaultOverflowDeactivationThreshold / 100.0;    }        try {        byteCapacityBufferPercentage = context.getInteger(BYTE_CAPACITY_BUFFER_PERCENTAGE, defaultByteCapacityBufferPercentage);    } catch (NumberFormatException e) {        LOGGER.warn("Error parsing " + BYTE_CAPACITY_BUFFER_PERCENTAGE + " for " + getName() + ". Using default=" + defaultByteCapacityBufferPercentage + ". " + e.getMessage());        byteCapacityBufferPercentage = defaultByteCapacityBufferPercentage;    }    try {        avgEventSize = context.getInteger(AVG_EVENT_SIZE, defaultAvgEventSize);    } catch (NumberFormatException e) {        LOGGER.warn("Error parsing " + AVG_EVENT_SIZE + " for " + getName() + ". Using default = " + defaultAvgEventSize + ". " + e.getMessage());        avgEventSize = defaultAvgEventSize;    }    try {        byteCapacity = (int) ((context.getLong(BYTE_CAPACITY, defaultByteCapacity) * (1 - byteCapacityBufferPercentage * .01)) / avgEventSize);        if (byteCapacity < 1) {            byteCapacity = Integer.MAX_VALUE;        }    } catch (NumberFormatException e) {        LOGGER.warn("Error parsing " + BYTE_CAPACITY + " setting for " + getName() + ". Using default = " + defaultByteCapacity + ". " + e.getMessage());        byteCapacity = (int) ((defaultByteCapacity * (1 - byteCapacityBufferPercentage * .01)) / avgEventSize);    }    if (bytesRemaining == null) {        bytesRemaining = new Semaphore(byteCapacity);        lastByteCapacity = byteCapacity;    } else {        if (byteCapacity > lastByteCapacity) {            bytesRemaining.release(byteCapacity - lastByteCapacity);            lastByteCapacity = byteCapacity;        } else {            try {                if (!bytesRemaining.tryAcquire(lastByteCapacity - byteCapacity, overflowTimeout, TimeUnit.SECONDS)) {                    LOGGER.warn("Couldn't acquire permits to downsize the byte capacity, " + "resizing has been aborted");                } else {                    lastByteCapacity = byteCapacity;                }            } catch (InterruptedException e) {                Thread.currentThread().interrupt();            }        }    }    try {                overflowCapacity = context.getInteger(OVERFLOW_CAPACITY, defaultOverflowCapacity);                if (memoryCapacity < 1 && overflowCapacity < 1) {            LOGGER.warn("For channel " + getName() + OVERFLOW_CAPACITY + " cannot be set to 0 if " + MEMORY_CAPACITY + " is also 0. " + "Using default value " + OVERFLOW_CAPACITY + " = " + defaultOverflowCapacity);            overflowCapacity = defaultOverflowCapacity;        }        overflowDisabled = (overflowCapacity < 1);        if (overflowDisabled) {            overflowActivated = false;        }    } catch (NumberFormatException e) {        overflowCapacity = defaultOverflowCapacity;    }            context.put(KEEP_ALIVE, "0");        context.put(CAPACITY, Integer.toString(overflowCapacity));    super.configure(context);}
3b5ee854ba1e9f7371221a61e0d1236908317fd234db97126e4a8da841194ace
resizePrimaryQueue
private void resizePrimaryQueue(int newMemoryCapacity) throws InterruptedException
{    if (memQueue != null && memoryCapacity == newMemoryCapacity) {        return;    }    if (memoryCapacity > newMemoryCapacity) {        int diff = memoryCapacity - newMemoryCapacity;        if (!memQueRemaining.tryAcquire(diff, overflowTimeout, TimeUnit.SECONDS)) {            LOGGER.warn("Memory buffer currently contains more events than the new size. " + "Downsizing has been aborted.");            return;        }        synchronized (queueLock) {            ArrayDeque<Event> newQueue = new ArrayDeque<Event>(newMemoryCapacity);            newQueue.addAll(memQueue);            memQueue = newQueue;            memoryCapacity = newMemoryCapacity;        }    } else {                synchronized (queueLock) {            ArrayDeque<Event> newQueue = new ArrayDeque<Event>(newMemoryCapacity);            if (memQueue != null) {                newQueue.addAll(memQueue);            }            memQueue = newQueue;            if (memQueRemaining == null) {                memQueRemaining = new Semaphore(newMemoryCapacity);            } else {                int diff = newMemoryCapacity - memoryCapacity;                memQueRemaining.release(diff);            }            memoryCapacity = newMemoryCapacity;        }    }}
5b05914888e421f26bff6f39231facdd35759f746a9af780ebac2cf5b2c81932
start
public synchronized void start()
{    super.start();    int overFlowCount = super.getDepth();    if (drainOrder.isEmpty()) {        drainOrder.putOverflow(overFlowCount);        totalStored.release(overFlowCount);    }    channelCounter.start();    int totalCount = overFlowCount + memQueue.size();    channelCounter.setChannelCapacity(memoryCapacity + getOverflowCapacity());    channelCounter.setChannelSize(totalCount);}
06e1ddba8663c90da407ac517f29ed70555cfe57b0332c9a96e7c696e0255364
stop
public synchronized void stop()
{    if (getLifecycleState() == LifecycleState.STOP) {        return;    }    channelCounter.setChannelSize(memQueue.size() + drainOrder.overflowCounter);    channelCounter.stop();    super.stop();}
39f7d6d1213100383ba6ea7c79d8ed4ca1c7407a0f2469c0973c0709371a6cb9
createTransaction
protected BasicTransactionSemantics createTransaction()
{    return new SpillableMemoryTransaction(channelCounter);}
514a570ff3ce300581987c3597b1137cdc59a8353e3b465736bf6ed873fbda35
getOverflowTx
private BasicTransactionSemantics getOverflowTx()
{    return super.createTransaction();}
4e51a290ddf8d180e1f63b61bfb9a1379099162f4e9d2692f6e7c053ac01b9e4
estimateEventSize
private long estimateEventSize(Event event)
{    byte[] body = event.getBody();    if (body != null && body.length != 0) {        return body.length;    }        return 1;}
5303ab6d641599b7a7bffd72dd4c720bd2f592a5a6a6e213e92a4b0ba2fb04a0
configureChannel
private void configureChannel(Map<String, String> overrides)
{    Context context = new Context();    File checkPointDir = fileChannelDir.newFolder("checkpoint");    File dataDir = fileChannelDir.newFolder("data");    context.put(FileChannelConfiguration.CHECKPOINT_DIR, checkPointDir.getAbsolutePath());    context.put(FileChannelConfiguration.DATA_DIRS, dataDir.getAbsolutePath());        context.put(FileChannelConfiguration.CHECKPOINT_INTERVAL, "5000");    if (overrides != null) {        context.putAll(overrides);    }    Configurables.configure(channel, context);}
c7479f52a06264aaf637e08eab58fdb497faec33c169a5e2f0dbebae01af04d7
reconfigureChannel
private void reconfigureChannel(Map<String, String> overrides)
{    configureChannel(overrides);    channel.stop();    channel.start();}
ce78d4e8dae1222bbe0eef03d0a5e79082669d33818fe7a64109a177aacf6a9d
startChannel
private void startChannel(Map<String, String> params)
{    configureChannel(params);    channel.start();}
c002fd13e5f51a36e5accf29bf52e47abb30063693f2cf87adb535026c1b3e53
restartChannel
private void restartChannel(Map<String, String> params)
{    channel.stop();    setUp();    startChannel(params);}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    channel = new SpillableMemoryChannel();    channel.setName("spillChannel-" + UUID.randomUUID());}
39e5ba029cc67f6f1d45c6d20f0df595ec16bc61da20d7680fcbbdae4fe7f95b
tearDown
public void tearDown()
{    channel.stop();}
c88be7a9ce60541e81ab1f6f81a850478e4e6f1d33e502bd83623f4ed979361d
putN
private static void putN(int first, int count, AbstractChannel channel)
{    for (int i = 0; i < count; ++i) {        channel.put(EventBuilder.withBody(String.valueOf(first++).getBytes()));    }}
10763010117eba463470a61a756a57bb1c34d606e766d622bf344f8bc01aae87
takeNull
private static void takeNull(AbstractChannel channel)
{    channel.take();}
6ac15f352196991fb265901f81ecbc27b9628a068bb98bf3c82e98f5f6faaa02
takeN
private static void takeN(int first, int count, AbstractChannel channel)
{    int last = first + count;    for (int i = first; i < last; ++i) {        Event e = channel.take();        if (e == null) {            throw new NullFound(i);        }        Event expected = EventBuilder.withBody(String.valueOf(i).getBytes());        Assert.assertArrayEquals(e.getBody(), expected.getBody());    }}
4498648bf86878a0c3713eea9c4895a3179631a47df7b3a01217504ab03607e7
takeN_NoCheck
private static int takeN_NoCheck(int batchSize, AbstractChannel channel)
{    int i = 0;    for (; i < batchSize; ++i) {        Event e = channel.take();        if (e == null) {            try {                Thread.sleep(0);            } catch (InterruptedException ex) {            /* ignore */            }            return i;        }    }    return i;}
e2b4864062ec7e40a3cf6c1ffd546c9e1bdc142dc34f7e1a34d27c565dc7504d
transactionalPutN
private static void transactionalPutN(int first, int count, AbstractChannel channel)
{    Transaction tx = channel.getTransaction();    tx.begin();    try {        putN(first, count, channel);        tx.commit();    } catch (RuntimeException e) {        tx.rollback();        throw e;    } finally {        tx.close();    }}
b9acc3e87742c49de03363fb7d988143bf36d460f12b879dad4b0ac452556959
transactionalTakeN
private static void transactionalTakeN(int first, int count, AbstractChannel channel)
{    Transaction tx = channel.getTransaction();    tx.begin();    try {        takeN(first, count, channel);        tx.commit();    } catch (NullFound e) {        tx.commit();        throw e;    } catch (AssertionError e) {        tx.rollback();        throw e;    } catch (RuntimeException e) {        tx.rollback();        throw e;    } finally {        tx.close();    }}
69ff2bdb62907c98682f669bf379b903bc29032b21ecd1f26137f4bb9c5b5f70
transactionalTakeN_NoCheck
private static int transactionalTakeN_NoCheck(int count, AbstractChannel channel)
{    Transaction tx = channel.getTransaction();    tx.begin();    try {        int eventCount = takeN_NoCheck(count, channel);        tx.commit();        return eventCount;    } catch (RuntimeException e) {        tx.rollback();        throw e;    } finally {        tx.close();    }}
acc8cd1e00eb4d96b5b2acfd65e8f3a91223cf6ba186200c70272b4b5c2d461e
transactionalTakeNull
private static void transactionalTakeNull(int count, AbstractChannel channel)
{    Transaction tx = channel.getTransaction();    tx.begin();    try {        for (int i = 0; i < count; ++i) {            takeNull(channel);        }        tx.commit();    } catch (AssertionError e) {        tx.rollback();        throw e;    } catch (RuntimeException e) {        tx.rollback();        throw e;    } finally {        tx.close();    }}
a24e9785407aba8e6d54b9733af552604e8a636ba59320bd0e85dd0225888e9c
makePutThread
private Thread makePutThread(String threadName, final int first, final int count, final int batchSize, final AbstractChannel channel)
{    return new Thread(threadName) {        public void run() {            int maxdepth = 0;            StopWatch watch = new StopWatch();            for (int i = first; i < first + count; i = i + batchSize) {                transactionalPutN(i, batchSize, channel);            }            watch.elapsed();        }    };}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    int maxdepth = 0;    StopWatch watch = new StopWatch();    for (int i = first; i < first + count; i = i + batchSize) {        transactionalPutN(i, batchSize, channel);    }    watch.elapsed();}
7aec8dac63954cfe702bc7b45342cca5672154a450c189bb7a2bc573b09ef554
makeTakeThread
private static Thread makeTakeThread(String threadName, final int first, final int count, final int batchSize, final AbstractChannel channel)
{    return new Thread(threadName) {        public void run() {            StopWatch watch = new StopWatch();            for (int i = first; i < first + count; ) {                try {                    transactionalTakeN(i, batchSize, channel);                    i = i + batchSize;                } catch (NullFound e) {                    i = e.expectedValue;                }            }            watch.elapsed();        }    };}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    StopWatch watch = new StopWatch();    for (int i = first; i < first + count; ) {        try {            transactionalTakeN(i, batchSize, channel);            i = i + batchSize;        } catch (NullFound e) {            i = e.expectedValue;        }    }    watch.elapsed();}
0248f19fe5e8fe4acdf83192b9f1e8462bd5ffd2e2fd47e15d4f2db4e6f7ce70
makeTakeThread_noCheck
private static Thread makeTakeThread_noCheck(String threadName, final int totalEvents, final int batchSize, final AbstractChannel channel)
{    return new Thread(threadName) {        public void run() {            int batchSz = batchSize;            StopWatch watch = new StopWatch();            int i = 0, attempts = 0;            while (i < totalEvents) {                int remaining = totalEvents - i;                batchSz = (remaining > batchSz) ? batchSz : remaining;                int takenCount = transactionalTakeN_NoCheck(batchSz, channel);                if (takenCount < batchSz) {                    try {                        Thread.sleep(20);                    } catch (InterruptedException ex) {                    /* ignore */                    }                }                i += takenCount;                ++attempts;                if (attempts > totalEvents * 3) {                    throw new TooManyNulls(attempts);                }            }            watch.elapsed(" items = " + i + ", attempts = " + attempts);        }    };}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    int batchSz = batchSize;    StopWatch watch = new StopWatch();    int i = 0, attempts = 0;    while (i < totalEvents) {        int remaining = totalEvents - i;        batchSz = (remaining > batchSz) ? batchSz : remaining;        int takenCount = transactionalTakeN_NoCheck(batchSz, channel);        if (takenCount < batchSz) {            try {                Thread.sleep(20);            } catch (InterruptedException ex) {            /* ignore */            }        }        i += takenCount;        ++attempts;        if (attempts > totalEvents * 3) {            throw new TooManyNulls(attempts);        }    }    watch.elapsed(" items = " + i + ", attempts = " + attempts);}
e77f57e671708d02d3582f3199e3d54beec5752b0d1e21498173eda487a68b4b
testPutTake
public void testPutTake()
{    Map<String, String> params = new HashMap<String, String>();    params.put("memoryCapacity", "5");    params.put("overflowCapacity", "5");    params.put(FileChannelConfiguration.TRANSACTION_CAPACITY, "5");    startChannel(params);    Transaction tx = channel.getTransaction();    tx.begin();    putN(0, 2, channel);    tx.commit();    tx.close();    tx = channel.getTransaction();    tx.begin();    takeN(0, 2, channel);    tx.commit();    tx.close();}
c31ee5a26ee9447e1025630ae49e14d55618bb5b3a6dce505e9c851440bce631
testCapacityDisableOverflow
public void testCapacityDisableOverflow()
{    Map<String, String> params = new HashMap<String, String>();    params.put("memoryCapacity", "2");        params.put("overflowCapacity", "0");    params.put("overflowTimeout", "0");    startChannel(params);    transactionalPutN(0, 2, channel);    boolean threw = false;    try {        transactionalPutN(2, 1, channel);    } catch (ChannelException e) {        threw = true;    }    Assert.assertTrue("Expecting ChannelFullException to be thrown", threw);    transactionalTakeN(0, 2, channel);    Transaction tx = channel.getTransaction();    tx.begin();    Assert.assertNull(channel.take());    tx.commit();    tx.close();}
9f9f57959f4ce44a12cfbee085e2b24d2c2224fc7972c2e33b62a9964d7b3080
testCapacityWithOverflow
public void testCapacityWithOverflow()
{    Map<String, String> params = new HashMap<String, String>();    params.put("memoryCapacity", "2");    params.put("overflowCapacity", "4");    params.put(FileChannelConfiguration.TRANSACTION_CAPACITY, "3");    params.put("overflowTimeout", "0");    startChannel(params);    transactionalPutN(1, 2, channel);    transactionalPutN(3, 2, channel);    transactionalPutN(5, 2, channel);    boolean threw = false;    try {                transactionalPutN(7, 2, channel);    } catch (ChannelFullException e) {        threw = true;    }    Assert.assertTrue("Expecting ChannelFullException to be thrown", threw);    transactionalTakeN(1, 2, channel);    transactionalTakeN(3, 2, channel);    transactionalTakeN(5, 2, channel);}
bdd8102049131beffe1c506f8a2505f9d5260753c1d1a668a2d4f53541ac6835
testRestart
public void testRestart()
{    Map<String, String> params = new HashMap<String, String>();    params.put("memoryCapacity", "2");    params.put("overflowCapacity", "10");    params.put(FileChannelConfiguration.TRANSACTION_CAPACITY, "4");    params.put("overflowTimeout", "0");    startChannel(params);    transactionalPutN(1, 2, channel);        transactionalPutN(3, 2, channel);    restartChannel(params);        transactionalTakeN(3, 2, channel);}
f075db21a163c22f13a282e09526a6253105d6ffb4cc750f82e28fe27ec8a254
testBasicStart
public void testBasicStart()
{    Map<String, String> params = new HashMap<String, String>();    params.put("memoryCapacity", "10000000");    params.put("overflowCapacity", "20000000");    params.put(FileChannelConfiguration.TRANSACTION_CAPACITY, "10");    params.put("overflowTimeout", "1");    startChannel(params);    transactionalPutN(1, 5, channel);    transactionalPutN(6, 5, channel);        transactionalPutN(11, 5, channel);    transactionalTakeN(1, 10, channel);    transactionalTakeN(11, 5, channel);}
001f3f7fff9674ca590d64d910908507994f95b3f62fca1f45c041c2b6c60e12
testOverflow
public void testOverflow()
{    Map<String, String> params = new HashMap<String, String>();    params.put("memoryCapacity", "10");    params.put("overflowCapacity", "20");    params.put(FileChannelConfiguration.TRANSACTION_CAPACITY, "10");    params.put("overflowTimeout", "1");    startChannel(params);    transactionalPutN(1, 5, channel);    transactionalPutN(6, 5, channel);        transactionalPutN(11, 5, channel);    transactionalTakeN(1, 10, channel);    transactionalTakeN(11, 5, channel);}
16d1bdedbf338412c736351b60a9c26d168560440aca7425e467663f2bd1a955
testDrainOrder
public void testDrainOrder()
{    Map<String, String> params = new HashMap<String, String>();    params.put("memoryCapacity", "10");    params.put("overflowCapacity", "10");    params.put(FileChannelConfiguration.TRANSACTION_CAPACITY, "5");    params.put("overflowTimeout", "1");    startChannel(params);    transactionalPutN(1, 5, channel);    transactionalPutN(6, 5, channel);        transactionalPutN(11, 5, channel);        transactionalPutN(16, 5, channel);    transactionalTakeN(1, 1, channel);    transactionalTakeN(2, 5, channel);    transactionalTakeN(7, 4, channel);    transactionalPutN(20, 2, channel);    transactionalPutN(22, 3, channel);        transactionalTakeN(11, 3, channel);        transactionalTakeN(14, 5, channel);        transactionalTakeN(19, 2, channel);}
14332555ce2994daab52ca4df11e59a0aff1ec73b84120de350d0a0be189b55b
testByteCapacity
public void testByteCapacity()
{    Map<String, String> params = new HashMap<String, String>();    params.put("memoryCapacity", "1000");        params.put("byteCapacity", "100");    params.put("avgEventSize", "10");    params.put("overflowCapacity", "20");    params.put(FileChannelConfiguration.TRANSACTION_CAPACITY, "10");    params.put("overflowTimeout", "1");    startChannel(params);        transactionalPutN(1, 8, channel);    transactionalPutN(9, 10, channel);        transactionalPutN(19, 10, channel);    boolean threw = false;    try {                transactionalPutN(11, 1, channel);    } catch (ChannelFullException e) {        threw = true;    }    Assert.assertTrue("byteCapacity did not throw as expected", threw);}
724fdfde4c2a859ef602699ef9f114e0234188def374de8623cb476f82de0390
testDrainingOnChannelBoundary
public void testDrainingOnChannelBoundary()
{    Map<String, String> params = new HashMap<String, String>();    params.put("memoryCapacity", "5");    params.put("overflowCapacity", "15");    params.put(FileChannelConfiguration.TRANSACTION_CAPACITY, "10");    params.put("overflowTimeout", "1");    startChannel(params);    transactionalPutN(1, 5, channel);        transactionalPutN(6, 5, channel);        transactionalPutN(11, 5, channel);        transactionalPutN(16, 5, channel);    transactionalTakeN(1, 3, channel);    Transaction tx = channel.getTransaction();    tx.begin();    takeN(4, 2, channel);        takeNull(channel);    tx.commit();    tx.close();        transactionalTakeN(6, 5, channel);        transactionalTakeN(11, 5, channel);        transactionalTakeN(16, 2, channel);    transactionalPutN(21, 5, channel);    tx = channel.getTransaction();    tx.begin();        takeN(18, 3, channel);        takeNull(channel);    tx.commit();    tx.close();    transactionalTakeN(21, 5, channel);}
cfcb66f85810871b63a3df14fd3fafd5de01b2ab3ca52d0e6ce5bcb5e9ff43e5
testRollBack
public void testRollBack()
{    Map<String, String> params = new HashMap<String, String>();    params.put("memoryCapacity", "100");    params.put("overflowCapacity", "900");    params.put(FileChannelConfiguration.TRANSACTION_CAPACITY, "900");    params.put("overflowTimeout", "0");    startChannel(params);        transactionalPutN(1, 5, channel);    Transaction tx = channel.getTransaction();    tx.begin();    putN(6, 5, channel);    tx.rollback();    tx.close();    transactionalTakeN(1, 5, channel);    transactionalTakeNull(2, channel);        transactionalPutN(11, 5, channel);    transactionalTakeN(11, 5, channel);        transactionalPutN(16, 5, channel);    tx = channel.getTransaction();    tx.begin();    takeN(16, 5, channel);    takeNull(channel);    tx.rollback();    tx.close();    transactionalTakeN_NoCheck(5, channel);        transactionalPutN(21, 5, channel);    transactionalTakeN(21, 5, channel);}
2dd52a13696de39220c7bc222eed33cf53442512f8cb9daf5c99749a50b6ce39
testReconfigure
public void testReconfigure()
{        Map<String, String> params = new HashMap<String, String>();    params.put("memoryCapacity", "10");    params.put("overflowCapacity", "0");    params.put("overflowTimeout", "0");    startChannel(params);    Assert.assertTrue("overflowTimeout setting did not reconfigure correctly", channel.getOverflowTimeout() == 0);    Assert.assertTrue("memoryCapacity did not reconfigure correctly", channel.getMemoryCapacity() == 10);    Assert.assertTrue("overflowCapacity did not reconfigure correctly", channel.isOverflowDisabled());    transactionalPutN(1, 10, channel);    boolean threw = false;    try {                transactionalPutN(11, 10, channel);    } catch (ChannelException e) {        threw = true;    }    Assert.assertTrue("Expected the channel to fill up and throw an exception, " + "but it did not throw", threw);        params = new HashMap<String, String>();    params.put("memoryCapacity", "20");    params.put("overflowCapacity", "0");    reconfigureChannel(params);    Assert.assertTrue("overflowTimeout setting did not reconfigure correctly", channel.getOverflowTimeout() == SpillableMemoryChannel.defaultOverflowTimeout);    Assert.assertTrue("memoryCapacity did not reconfigure correctly", channel.getMemoryCapacity() == 20);    Assert.assertTrue("overflowCapacity did not reconfigure correctly", channel.isOverflowDisabled());        transactionalTakeN(1, 10, channel);    transactionalPutN(11, 10, channel);    transactionalPutN(21, 10, channel);    threw = false;    try {                transactionalPutN(31, 10, channel);    } catch (ChannelException e) {        threw = true;    }    Assert.assertTrue("Expected the channel to fill up and throw an exception, " + "but it did not throw", threw);    transactionalTakeN(11, 10, channel);    transactionalTakeN(21, 10, channel);        params = new HashMap<String, String>();    reconfigureChannel(params);    Assert.assertTrue("overflowTimeout setting did not reconfigure correctly", channel.getOverflowTimeout() == SpillableMemoryChannel.defaultOverflowTimeout);    Assert.assertTrue("memoryCapacity did not reconfigure correctly", channel.getMemoryCapacity() == SpillableMemoryChannel.defaultMemoryCapacity);    Assert.assertTrue("overflowCapacity did not reconfigure correctly", channel.getOverflowCapacity() == SpillableMemoryChannel.defaultOverflowCapacity);    Assert.assertFalse("overflowCapacity did not reconfigure correctly", channel.isOverflowDisabled());        params = new HashMap<String, String>();    params.put("memoryCapacity", "10");    params.put("overflowCapacity", "10");    params.put("transactionCapacity", "5");    params.put("overflowTimeout", "1");    reconfigureChannel(params);    transactionalPutN(1, 5, channel);    transactionalPutN(6, 5, channel);    transactionalPutN(11, 5, channel);    transactionalPutN(16, 5, channel);    threw = false;    try {                transactionalPutN(21, 5, channel);    } catch (ChannelException e) {        threw = true;    }    Assert.assertTrue("Expected the last insertion to fail, but it didn't.", threw);        params = new HashMap<String, String>();    params.put("memoryCapacity", "10");    params.put("overflowCapacity", "20");    params.put("transactionCapacity", "10");    params.put("overflowTimeout", "1");    reconfigureChannel(params);        transactionalPutN(21, 5, channel);    transactionalTakeN(1, 10, channel);    transactionalTakeN(11, 5, channel);    transactionalTakeN(16, 5, channel);    transactionalTakeN(21, 5, channel);}
25458130d19ee34e3a260bc9511c6f79bc36364aa34116a521da273babf9f294
testParallelSingleSourceAndSink
public void testParallelSingleSourceAndSink() throws InterruptedException
{    Map<String, String> params = new HashMap<String, String>();    params.put("memoryCapacity", "1000020");    params.put("overflowCapacity", "0");    params.put("overflowTimeout", "3");    startChannel(params);        Thread sourceThd = makePutThread("src", 1, 500000, 100, channel);    Thread sinkThd = makeTakeThread("sink", 1, 500000, 100, channel);    StopWatch watch = new StopWatch();    sinkThd.start();    sourceThd.start();    sourceThd.join();    sinkThd.join();    watch.elapsed();    System.out.println("Max Queue size " + channel.getMaxMemQueueSize());}
6cf6cc74d6ebc29eb0e63a29b59295e673dbfc3c96460a1a06e3779fd183795f
testCounters
public void testCounters() throws InterruptedException
{    Map<String, String> params = new HashMap<String, String>();    params.put("memoryCapacity", "5000");    params.put("overflowCapacity", "5000");    params.put("transactionCapacity", "5000");    params.put("overflowTimeout", "0");    startChannel(params);    Assert.assertTrue("channel.channelCounter should have started", channel.channelCounter.getStartTime() > 0);        Thread sourceThd = makePutThread("src", 1, 5000, 2500, channel);    sourceThd.start();    sourceThd.join();    Assert.assertEquals(5000, channel.getTotalStored());    Assert.assertEquals(5000, channel.channelCounter.getChannelSize());    Assert.assertEquals(5000, channel.channelCounter.getEventPutAttemptCount());    Assert.assertEquals(5000, channel.channelCounter.getEventPutSuccessCount());        Thread sinkThd = makeTakeThread("sink", 1, 5000, 1000, channel);    sinkThd.start();    sinkThd.join();    Assert.assertEquals(0, channel.getTotalStored());    Assert.assertEquals(0, channel.channelCounter.getChannelSize());    Assert.assertEquals(5000, channel.channelCounter.getEventTakeAttemptCount());    Assert.assertEquals(5000, channel.channelCounter.getEventTakeSuccessCount());        sourceThd = makePutThread("src", 1, 10000, 1000, channel);    sourceThd.start();    sourceThd.join();    Assert.assertEquals(10000, channel.getTotalStored());    Assert.assertEquals(10000, channel.channelCounter.getChannelSize());    Assert.assertEquals(15000, channel.channelCounter.getEventPutAttemptCount());    Assert.assertEquals(15000, channel.channelCounter.getEventPutSuccessCount());        sinkThd = makeTakeThread("sink", 1, 5000, 1000, channel);    sinkThd.start();    sinkThd.join();    Assert.assertEquals(5000, channel.getTotalStored());    Assert.assertEquals(5000, channel.channelCounter.getChannelSize());    Assert.assertEquals(10000, channel.channelCounter.getEventTakeAttemptCount());    Assert.assertEquals(10000, channel.channelCounter.getEventTakeSuccessCount());        transactionalTakeN(5001, 1000, channel);    transactionalTakeN(6001, 1000, channel);    transactionalTakeN(7001, 1000, channel);    transactionalTakeN(8001, 1000, channel);    transactionalTakeN(9001, 1000, channel);    Assert.assertEquals(0, channel.getTotalStored());    Assert.assertEquals(0, channel.channelCounter.getChannelSize());    Assert.assertEquals(15000, channel.channelCounter.getEventTakeAttemptCount());    Assert.assertEquals(15000, channel.channelCounter.getEventTakeSuccessCount());        sourceThd = makePutThread("src1", 1, 5000, 1000, channel);    Thread sourceThd2 = makePutThread("src2", 1, 5000, 500, channel);    sinkThd = makeTakeThread_noCheck("sink1", 5000, 1000, channel);    sourceThd.start();    sourceThd2.start();    sinkThd.start();    sourceThd.join();    sourceThd2.join();    sinkThd.join();    Assert.assertEquals(5000, channel.getTotalStored());    Assert.assertEquals(5000, channel.channelCounter.getChannelSize());    Thread sinkThd2 = makeTakeThread_noCheck("sink2", 2500, 500, channel);    Thread sinkThd3 = makeTakeThread_noCheck("sink3", 2500, 1000, channel);    sinkThd2.start();    sinkThd3.start();    sinkThd2.join();    sinkThd3.join();    Assert.assertEquals(0, channel.getTotalStored());    Assert.assertEquals(0, channel.channelCounter.getChannelSize());    Assert.assertEquals(25000, channel.channelCounter.getEventTakeSuccessCount());    Assert.assertEquals(25000, channel.channelCounter.getEventPutSuccessCount());    Assert.assertTrue("TakeAttempt channel counter value larger than expected", 25000 <= channel.channelCounter.getEventTakeAttemptCount());    Assert.assertTrue("PutAttempt channel counter value larger than expected", 25000 <= channel.channelCounter.getEventPutAttemptCount());}
ec1a075946f54210679e3ab47de2e0f672a8a39c82ea72a734bb8e1c5c2bce58
createSourceThreads
public ArrayList<Thread> createSourceThreads(int count, int totalEvents, int batchSize)
{    ArrayList<Thread> sourceThds = new ArrayList<Thread>();    for (int i = 0; i < count; ++i) {        sourceThds.add(makePutThread("src" + i, 1, totalEvents / count, batchSize, channel));    }    return sourceThds;}
9643b6ddfd0092a30c127497e26dddd7173847423088174836b1cc3c90c822bf
createSinkThreads
public ArrayList<Thread> createSinkThreads(int count, int totalEvents, int batchSize)
{    ArrayList<Thread> sinkThreads = new ArrayList<Thread>(count);    for (int i = 0; i < count; ++i) {        sinkThreads.add(makeTakeThread_noCheck("sink" + i, totalEvents / count, batchSize, channel));    }    return sinkThreads;}
88cc1621effd5b558a7842667a9a15a8286691f272b6b0c69f415c33d6f82dfd
startThreads
public void startThreads(ArrayList<Thread> threads)
{    for (Thread thread : threads) {        thread.start();    }}
46103a5cf3dabf1e214d9116623b1a23207ffa7d2705379b9d5c4330761187e5
joinThreads
public void joinThreads(ArrayList<Thread> threads) throws InterruptedException
{    for (Thread thread : threads) {        try {            thread.join();        } catch (InterruptedException e) {            System.out.println("Interrupted while waiting on " + thread.getName());            throw e;        }    }}
fd3039622c82590747d64797b9a503c56a17a16166c03757aa863e9373c4fa18
testParallelMultipleSourcesAndSinks
public void testParallelMultipleSourcesAndSinks() throws InterruptedException
{    int sourceCount = 8;    int sinkCount = 8;    int eventCount = 1000000;    int batchSize = 100;    Map<String, String> params = new HashMap<String, String>();    params.put("memoryCapacity", "0");    params.put("overflowCapacity", String.valueOf(eventCount));    params.put("overflowTimeout", "3");    startChannel(params);    ArrayList<Thread> sinks = createSinkThreads(sinkCount, eventCount, batchSize);    ArrayList<Thread> sources = createSourceThreads(sourceCount, eventCount, batchSize);    StopWatch watch = new StopWatch();    startThreads(sinks);    startThreads(sources);    joinThreads(sources);    joinThreads(sinks);    watch.elapsed();    System.out.println("Max Queue size " + channel.getMaxMemQueueSize());    Assert.assertEquals(eventCount, channel.drainOrder.totalPuts);    Assert.assertEquals("Channel not fully drained", 0, channel.getTotalStored());    System.out.println("testParallelMultipleSourcesAndSinks done");}
e0306f4892df65d62bafd1ccc0c4c058414a6a5920cabbf09fefef17ffa47049
elapsed
public void elapsed()
{    elapsed(null);}
f59b0b98df7bd0b211b64f81d4de9a19cbf9acf96387789374c679a52d516d76
elapsed
public void elapsed(String suffix)
{    long elapsed = System.currentTimeMillis() - startTime;    if (suffix == null) {        suffix = "";    } else {        suffix = "{ " + suffix + " }";    }    if (elapsed < 10000) {        System.out.println(Thread.currentThread().getName() + " : [ " + elapsed + " ms ].        " + suffix);    } else {        System.out.println(Thread.currentThread().getName() + " : [ " + elapsed / 1000 + " sec ].       " + suffix);    }}
600aa40e25b4a8ab336eda6bff8cf3a92296ee8c096c078f1f9ee2353bc23dbf
setHosts
public void setHosts(String hostNames)
{    this.hosts = hostNames;}
45098b74ec14c6692b95054facbc5232e326adeb816c05bd7e1c862ba00b4bd1
setSelector
public void setSelector(String selector)
{    this.selector = selector;}
2c17b02c8eab09471d90de153577df05814a2a6415df333d2781baf98794ae6f
setMaxBackoff
public void setMaxBackoff(String maxBackoff)
{    this.maxBackoff = maxBackoff;}
9a2576a2aadbdf9fb5e6b216b5a659138b4a553db51a126500ad37906c2da6f9
append
public synchronized void append(LoggingEvent event)
{    if (!configured) {        String errorMsg = "Flume Log4jAppender not configured correctly! Cannot" + " send events to Flume.";        LogLog.error(errorMsg);        if (getUnsafeMode()) {            return;        }        throw new FlumeException(errorMsg);    }    super.append(event);}
6f51d7f254038df5f21e16c1c5b37079ce2630d0dba4df99f9766e1952f4ad88
activateOptions
public void activateOptions() throws FlumeException
{    try {        final Properties properties = getProperties(hosts, selector, maxBackoff, getTimeout());        rpcClient = RpcClientFactory.getInstance(properties);        if (layout != null) {            layout.activateOptions();        }        configured = true;    } catch (Exception e) {        String errormsg = "RPC client creation failed! " + e.getMessage();        LogLog.error(errormsg);        if (getUnsafeMode()) {            return;        }        throw new FlumeException(e);    }    initializeClientAddress();}
b93d1e86b4b943a98456abf703e9aba4cbabd14b8a199a9024f70256960e4339
getProperties
private Properties getProperties(String hosts, String selector, String maxBackoff, long timeout) throws FlumeException
{    if (StringUtils.isEmpty(hosts)) {        throw new FlumeException("hosts must not be null");    }    Properties props = new Properties();    String[] hostsAndPorts = hosts.split("\\s+");    StringBuilder names = new StringBuilder();    for (int i = 0; i < hostsAndPorts.length; i++) {        String hostAndPort = hostsAndPorts[i];        String name = "h" + i;        props.setProperty(RpcClientConfigurationConstants.CONFIG_HOSTS_PREFIX + name, hostAndPort);        names.append(name).append(" ");    }    props.put(RpcClientConfigurationConstants.CONFIG_HOSTS, names.toString());    props.put(RpcClientConfigurationConstants.CONFIG_CLIENT_TYPE, ClientType.DEFAULT_LOADBALANCE.toString());    if (!StringUtils.isEmpty(selector)) {        props.put(RpcClientConfigurationConstants.CONFIG_HOST_SELECTOR, selector);    }    if (!StringUtils.isEmpty(maxBackoff)) {        long millis = Long.parseLong(maxBackoff.trim());        if (millis <= 0) {            throw new FlumeException("Misconfigured max backoff, value must be greater than 0");        }        props.put(RpcClientConfigurationConstants.CONFIG_BACKOFF, String.valueOf(true));        props.put(RpcClientConfigurationConstants.CONFIG_MAX_BACKOFF, maxBackoff);    }    props.setProperty(RpcClientConfigurationConstants.CONFIG_CONNECT_TIMEOUT, String.valueOf(timeout));    props.setProperty(RpcClientConfigurationConstants.CONFIG_REQUEST_TIMEOUT, String.valueOf(timeout));    return props;}
e0fa78820317ae47696a582baa012b1fcab2b09f440c8d2ad022fd2b3cf84126
append
public synchronized void append(LoggingEvent event) throws FlumeException
{        if (rpcClient == null) {        String errorMsg = "Cannot Append to Appender! Appender either closed or" + " not setup correctly!";        LogLog.error(errorMsg);        if (unsafeMode) {            return;        }        throw new FlumeException(errorMsg);    }    if (!rpcClient.isActive()) {        reconnect();    }    List<Event> flumeEvents = parseEvents(event);    try {        switch(flumeEvents.size()) {            case 0:                break;            case 1:                rpcClient.append(flumeEvents.get(0));                break;            default:                rpcClient.appendBatch(flumeEvents);        }    } catch (EventDeliveryException e) {        String msg = "Flume append() failed.";        LogLog.error(msg);        if (unsafeMode) {            return;        }        throw new FlumeException(msg + " Exception follows.", e);    }}
0f591b29b93abdd838be8e1cd1663a10b8f7ac39ef0b988e6210df22aa15ae4e
parseEvents
private List<Event> parseEvents(LoggingEvent loggingEvent)
{    Map<String, String> headers = new HashMap<>();    headers.put(Log4jAvroHeaders.LOGGER_NAME.toString(), loggingEvent.getLoggerName());    headers.put(Log4jAvroHeaders.TIMESTAMP.toString(), String.valueOf(loggingEvent.timeStamp));    headers.put(Log4jAvroHeaders.ADDRESS.toString(), clientAddress);                headers.put(Log4jAvroHeaders.LOG_LEVEL.toString(), String.valueOf(loggingEvent.getLevel().toInt()));    Map<String, String> headersWithEncoding = null;    Collection<?> messages;    if (loggingEvent.getMessage() instanceof Collection) {        messages = (Collection) loggingEvent.getMessage();    } else {        messages = Collections.singleton(loggingEvent.getMessage());    }    List<Event> events = new LinkedList<>();    for (Object message : messages) {        if (message instanceof GenericRecord) {            GenericRecord record = (GenericRecord) message;            populateAvroHeaders(headers, record.getSchema());            events.add(EventBuilder.withBody(serialize(record, record.getSchema()), headers));        } else if (message instanceof SpecificRecord || avroReflectionEnabled) {            Schema schema = ReflectData.get().getSchema(message.getClass());            populateAvroHeaders(headers, schema);            events.add(EventBuilder.withBody(serialize(message, schema), headers));        } else {            String msg;            if (layout != null) {                LoggingEvent singleLoggingEvent = new LoggingEvent(loggingEvent.getFQNOfLoggerClass(), loggingEvent.getLogger(), loggingEvent.getTimeStamp(), loggingEvent.getLevel(), message, loggingEvent.getThreadName(), loggingEvent.getThrowableInformation(), loggingEvent.getNDC(), loggingEvent.getLocationInformation(), loggingEvent.getProperties());                msg = layout.format(singleLoggingEvent);            } else {                msg = message.toString();            }            if (headersWithEncoding == null) {                headersWithEncoding = new HashMap<>(headers);                headersWithEncoding.put(Log4jAvroHeaders.MESSAGE_ENCODING.toString(), "UTF8");            }            events.add(EventBuilder.withBody(msg, Charset.forName("UTF8"), headersWithEncoding));        }    }    return events;}
49061fd25142682dba25600222e0e9d01c9ee6a8c93cde28dc090d7a1a1f8ece
populateAvroHeaders
protected void populateAvroHeaders(Map<String, String> hdrs, Schema schema)
{    if (avroSchemaUrl != null) {        hdrs.put(Log4jAvroHeaders.AVRO_SCHEMA_URL.toString(), avroSchemaUrl);        return;    }    LogLog.warn("Cannot find ID for schema. Adding header for schema, " + "which may be inefficient. Consider setting up an Avro Schema Cache.");    hdrs.put(Log4jAvroHeaders.AVRO_SCHEMA_LITERAL.toString(), schema.toString());}
0fce9d9b9671a1dd7b3705b2d8e46eda653d815e7a32cca917d9b5eb70f28707
serialize
private byte[] serialize(Object datum, Schema datumSchema) throws FlumeException
{    if (schema == null || !datumSchema.equals(schema)) {        schema = datumSchema;        out = new ByteArrayOutputStream();        writer = new ReflectDatumWriter<>(schema);        encoder = EncoderFactory.get().binaryEncoder(out, null);    }    out.reset();    try {        writer.write(datum, encoder);        encoder.flush();        return out.toByteArray();    } catch (IOException e) {        throw new FlumeException(e);    }}
09b6754a9ed0a90a22fc91d2e8392c167b7cd88f21ddd7ba703270e2ac5efa01
close
public synchronized void close() throws FlumeException
{        if (rpcClient != null) {        try {            rpcClient.close();        } catch (FlumeException ex) {            LogLog.error("Error while trying to close RpcClient.", ex);            if (unsafeMode) {                return;            }            throw ex;        } finally {            rpcClient = null;        }    } else {        String errorMsg = "Flume log4jappender already closed!";        LogLog.error(errorMsg);        if (unsafeMode) {            return;        }        throw new FlumeException(errorMsg);    }}
5488a172a0faebd556671180c4ddcb9a3349258e7a59413e29fe1f0b86a01b75
requiresLayout
public boolean requiresLayout()
{        return true;}
4aa7bc4ec8e1bf4bce39ba1b5453e415396ed88a65ecf7d8dd71f4e416936103
setHostname
public void setHostname(String hostname)
{    this.hostname = hostname;}
978b4a4182d7d5f4402fdef1f86d8511d09d2d1f97abd85ee89933c68ea32c5f
setPort
public void setPort(int port)
{    this.port = port;}
cf8d30272facba874833bbc3d1dbc3a26c28c5f7a61c53cdbec1138e7c294cb4
setUnsafeMode
public void setUnsafeMode(boolean unsafeMode)
{    this.unsafeMode = unsafeMode;}
54dad8109e1d5f9ff6c3173940dd3ba4f75cacd04f85e0ef19d6d8ba5f48b9c0
getUnsafeMode
public boolean getUnsafeMode()
{    return unsafeMode;}
93ae46c9aad9a95261ae049939dff5e41cac41171a2b0b7f4037427d98e5455c
setTimeout
public void setTimeout(long timeout)
{    this.timeout = timeout;}
cc169cd7e343039ac53b992dd789247f8d6d9abf791e1dd1552ebadba8e74245
getTimeout
public long getTimeout()
{    return this.timeout;}
f129159bee83e8b5a9bbc4e23ca2a2d240c100a65a26b295a9dce4af6a211352
setAvroReflectionEnabled
public void setAvroReflectionEnabled(boolean avroReflectionEnabled)
{    this.avroReflectionEnabled = avroReflectionEnabled;}
4091cfceece6f6e7167ea44222ca6c90422b65e96b81280bcc9dbb469b8941cf
setAvroSchemaUrl
public void setAvroSchemaUrl(String avroSchemaUrl)
{    this.avroSchemaUrl = avroSchemaUrl;}
6f51d7f254038df5f21e16c1c5b37079ce2630d0dba4df99f9766e1952f4ad88
activateOptions
public void activateOptions() throws FlumeException
{    Properties props = new Properties();    props.setProperty(RpcClientConfigurationConstants.CONFIG_HOSTS, "h1");    props.setProperty(RpcClientConfigurationConstants.CONFIG_HOSTS_PREFIX + "h1", hostname + ":" + port);    props.setProperty(RpcClientConfigurationConstants.CONFIG_CONNECT_TIMEOUT, String.valueOf(timeout));    props.setProperty(RpcClientConfigurationConstants.CONFIG_REQUEST_TIMEOUT, String.valueOf(timeout));    try {        rpcClient = RpcClientFactory.getInstance(props);        if (layout != null) {            layout.activateOptions();        }    } catch (FlumeException e) {        String errormsg = "RPC client creation failed! " + e.getMessage();        LogLog.error(errormsg);        if (unsafeMode) {            return;        }        throw e;    }    initializeClientAddress();}
46eabd91c816d98d9534b98e380f9af699643b1547752e59f1e3b4d4244bcdcd
initializeClientAddress
protected void initializeClientAddress() throws FlumeException
{    try {        clientAddress = InetAddress.getLocalHost().getHostAddress();    } catch (UnknownHostException e) {        String errormsg = "Failed to resolve local host address! " + e.getMessage();        LogLog.error(errormsg);        if (unsafeMode) {            return;        }        throw new FlumeException(e);    }}
70dfb71836e1098b261438062d9d6c88ab19c8dcd795073ed480be2848250110
reconnect
private void reconnect() throws FlumeException
{    close();    activateOptions();}
239fbe3eb64d679cbac1161825b07d6a8436ead3c6c3d140d9caec2275827023
getName
public String getName()
{    return headerName;}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return getName();}
0df5e438dabd3d2955e0fe9becea5b024847cd24d5b81b34695c37c9be5dcb68
getByName
public static Log4jAvroHeaders getByName(String headerName)
{    Log4jAvroHeaders hdrs = null;    try {        hdrs = Log4jAvroHeaders.valueOf(headerName.toLowerCase(Locale.ENGLISH).trim());    } catch (IllegalArgumentException e) {        hdrs = Log4jAvroHeaders.OTHER;    }    return hdrs;}
b7cd477e3847ca54493a3d95c367fd041d0c83cf85567d779143ba9ef810966f
getFreePorts
private static List<Integer> getFreePorts(int numberOfPorts) throws IOException
{    List<Integer> ports = new ArrayList<>(numberOfPorts);    for (int index = 0; index < numberOfPorts; ++index) {        try (ServerSocket socket = new ServerSocket(0)) {            ports.add(socket.getLocalPort());        }    }    return ports;}
e57b986ef2c63e5558fceacc31ff2e1a4c3f43f1776ddc2d6e92b829fb2f5e01
toHostList
private static String toHostList(List<Integer> ports)
{    List<String> addresses = new ArrayList<String>(ports.size());    for (Integer port : ports) {        addresses.add("localhost:" + port);    }    String hostList = StringUtils.join(addresses, " ");    return hostList;}
d3630180434f92599b2571c3591d93bc1554df95db5edede21a792f660b43723
initiate
public void initiate() throws InterruptedException
{    ch = new MemoryChannel();    configureChannel();}
1c2dca67d9c9e84e67eba78eafec23244d63e8df80f2924ced720728ebbc2134
configureChannel
private void configureChannel()
{    Configurables.configure(ch, new Context());    List<Channel> channels = new ArrayList<Channel>();    channels.add(ch);    rcs = new ReplicatingChannelSelector();    rcs.setChannels(channels);}
8d9ec964cb2b1702f35510b65dc80717f83aa9b6d06f2d7caf8545c5d3f9a1d1
cleanUp
public void cleanUp()
{    for (Source source : sources) {        source.stop();    }}
a494e0204c2620b6970bc6377f82efadbdbf385e15a48778d6e8b29a5810154a
testLog4jAppenderRoundRobin
public void testLog4jAppenderRoundRobin() throws IOException
{    int numberOfMsgs = 1000;    int expectedPerSource = 500;    String propertiesFile = "flume-loadbalancinglog4jtest.properties";    startSources(propertiesFile, false, getFreePorts(2));    sendAndAssertMessages(numberOfMsgs);    for (CountingAvroSource source : sources) {        Assert.assertEquals(expectedPerSource, source.appendCount.get());    }}
264542ad8c2e520b762f5693860541f9f86bf3a08d41d7343f90c10280445dc0
testLog4jAppenderRandom
public void testLog4jAppenderRandom() throws IOException
{    int numberOfMsgs = 1000;    String propertiesFile = "flume-loadbalancing-rnd-log4jtest.properties";    startSources(propertiesFile, false, getFreePorts(10));    sendAndAssertMessages(numberOfMsgs);    int total = 0;    Set<Integer> counts = new HashSet<Integer>();    for (CountingAvroSource source : sources) {        total += source.appendCount.intValue();        counts.add(source.appendCount.intValue());    }        Assert.assertTrue("Very unusual distribution " + counts.size(), counts.size() > 2);    Assert.assertTrue("Missing events", total == numberOfMsgs);}
926a03d4e58301cfc9a91dffd6f4186d064ae309f68577c8f9af630784fc069b
testRandomBackoff
public void testRandomBackoff() throws Exception
{    String propertiesFile = "flume-loadbalancing-backoff-log4jtest.properties";    startSources(propertiesFile, false, getFreePorts(3));    sources.get(0).setFail();    sources.get(2).setFail();    sendAndAssertMessages(50);    Assert.assertEquals(50, sources.get(1).appendCount.intValue());    Assert.assertEquals(0, sources.get(0).appendCount.intValue());    Assert.assertEquals(0, sources.get(2).appendCount.intValue());    sources.get(0).setOk();        sources.get(1).setFail();    try {        send(1);                Assert.fail("Expected EventDeliveryException");    } catch (FlumeException e) {        Assert.assertTrue(e.getCause() instanceof EventDeliveryException);    }        Thread.sleep(2500);    sendAndAssertMessages(50);    Assert.assertEquals(50, sources.get(0).appendCount.intValue());    Assert.assertEquals(50, sources.get(1).appendCount.intValue());    Assert.assertEquals(0, sources.get(2).appendCount.intValue());}
b91e75b12dcdbffb7f5eb071d1faa6017fb9925ceaac70d9770781c65ddd20fc
testRandomBackoffUnsafeMode
public void testRandomBackoffUnsafeMode() throws Exception
{    String propertiesFile = "flume-loadbalancing-backoff-log4jtest.properties";    startSources(propertiesFile, true, getFreePorts(3));    sources.get(0).setFail();    sources.get(1).setFail();    sources.get(2).setFail();    sendAndAssertFail();}
11b8a0794b5679b30570f1d2473b359dcff1a4fe5b8d715d01ef99e44905caa3
testTimeout
public void testTimeout() throws Throwable
{    String propertiesFile = "flume-loadbalancinglog4jtest.properties";    ch = new TestLog4jAppender.SlowMemoryChannel(2000);    configureChannel();    slowDown = true;    startSources(propertiesFile, false, getFreePorts(3));    int level = 20000;    String msg = "This is log message number" + String.valueOf(level);    try {        fixture.log(Level.toLevel(level), msg);    } catch (FlumeException ex) {        throw ex.getCause();    }}
93715cabbff33e9b681d92d98473a56b93a5805f7dff34f2aefe950046065fc6
testRandomBackoffNotUnsafeMode
public void testRandomBackoffNotUnsafeMode() throws Throwable
{    String propertiesFile = "flume-loadbalancing-backoff-log4jtest.properties";    startSources(propertiesFile, false, getFreePorts(3));    sources.get(0).setFail();    sources.get(1).setFail();    sources.get(2).setFail();    try {        sendAndAssertFail();    } catch (FlumeException ex) {        throw ex.getCause();    }}
00892328945b8aaff6b3ba9aeef83b401e353aaab2df78f87a1408a1637a31b5
send
private void send(int numberOfMsgs) throws EventDeliveryException
{    for (int count = 0; count < numberOfMsgs; count++) {        int level = count % 5;        String msg = "This is log message number" + String.valueOf(count);        fixture.log(Level.toLevel(level), msg);    }}
472fc8134996d2426d5f1be4bb32ace780ea9c82a9cb9a02a281f7bfbca4f2d0
sendAndAssertFail
private void sendAndAssertFail() throws IOException
{    int level = 20000;    String msg = "This is log message number" + String.valueOf(level);    fixture.log(Level.toLevel(level), msg);    Transaction transaction = ch.getTransaction();    transaction.begin();    Event event = ch.take();    Assert.assertNull(event);    transaction.commit();    transaction.close();}
5562f8ba559600cb9eefa9e2bc4545ab99f4cab7869c196cfca4e9554e02684d
sendAndAssertMessages
private void sendAndAssertMessages(int numberOfMsgs) throws IOException
{    for (int count = 0; count < numberOfMsgs; count++) {        int level = count % 5;        String msg = "This is log message number" + String.valueOf(count);        fixture.log(Level.toLevel(level), msg);        Transaction transaction = ch.getTransaction();        transaction.begin();        Event event = ch.take();        Assert.assertNotNull(event);        Assert.assertEquals(new String(event.getBody(), "UTF8"), msg);        Map<String, String> hdrs = event.getHeaders();        Assert.assertNotNull(hdrs.get(Log4jAvroHeaders.TIMESTAMP.toString()));        Assert.assertNotNull(hdrs.get(Log4jAvroHeaders.ADDRESS.toString()));        Assert.assertEquals(Level.toLevel(level), Level.toLevel(hdrs.get(Log4jAvroHeaders.LOG_LEVEL.toString())));        Assert.assertEquals(fixture.getName(), hdrs.get(Log4jAvroHeaders.LOGGER_NAME.toString()));        Assert.assertEquals("UTF8", hdrs.get(Log4jAvroHeaders.MESSAGE_ENCODING.toString()));                System.out.println("Got body: " + new String(event.getBody(), "UTF8"));        transaction.commit();        transaction.close();    }}
eaa7c6902e727b7dca8470d0cf1d4edde0b967b6c0322ee4f829a07bbe865310
startSources
private void startSources(String log4jProps, boolean unsafeMode, List<Integer> ports) throws IOException
{    for (int port : ports) {        CountingAvroSource source = new CountingAvroSource(port);        Context context = new Context();        context.put("port", String.valueOf(port));        context.put("bind", "0.0.0.0");        Configurables.configure(source, context);        sources.add(source);        source.setChannelProcessor(new ChannelProcessor(rcs));    }    for (Source source : sources) {        source.start();    }                        Reader reader = new InputStreamReader(getClass().getResourceAsStream("/" + log4jProps));    Properties props = new Properties();    props.load(reader);    props.setProperty("log4j.appender.out2.Hosts", toHostList(ports));    props.setProperty("log4j.appender.out2.UnsafeMode", String.valueOf(unsafeMode));    if (slowDown) {        props.setProperty("log4j.appender.out2.Timeout", String.valueOf(1000));    }    PropertyConfigurator.configure(props);    fixture = LogManager.getLogger(TestLoadBalancingLog4jAppender.class);}
902d8c03dbeabbb86b273f6d30d5e971e602e235d1b27aaaf62e64ea478776e4
setOk
public void setOk()
{    this.isFail = false;}
562bc04b7a028279f294a76da67fa6709d066ffc85bf5dad74bbb3025818df93
setFail
public void setFail()
{    this.isFail = true;}
239fbe3eb64d679cbac1161825b07d6a8436ead3c6c3d140d9caec2275827023
getName
public String getName()
{    return "testing..." + port2;}
5cfefa9eb8d596c2038b87543a218d1191b1a401bf72bf728817d641a2a7982a
append
public Status append(AvroFlumeEvent avroEvent)
{    if (isFail) {        return Status.FAILED;    }    appendCount.incrementAndGet();    return super.append(avroEvent);}
01fc7ee085fd6b74cd16aa539fa2b8f6930f97e3c0ec1b25a3234b4948e165b6
appendBatch
public Status appendBatch(List<AvroFlumeEvent> events)
{    if (isFail) {        return Status.FAILED;    }    appendCount.addAndGet(events.size());    return super.appendBatch(events);}
d2736cb1a1c64615d3e4c0619544e21348d5e5b69c9b67bca5628de60256c11e
getFreePort
private static int getFreePort() throws Exception
{    try (ServerSocket socket = new ServerSocket(0)) {        return socket.getLocalPort();    }}
1208e04a49a59dc7e64167efc0536d004072ac20bf030192ae6eefa0f68c3b8a
initiate
public void initiate() throws Exception
{    int port = getFreePort();    source = Mockito.spy(new AvroSource());    ch = new MemoryChannel();    Configurables.configure(ch, new Context());    Context context = new Context();    context.put("port", String.valueOf(port));    context.put("bind", "localhost");    Configurables.configure(source, context);    File TESTFILE = new File(TestLog4jAppender.class.getClassLoader().getResource("flume-log4jtest.properties").getFile());    FileReader reader = new FileReader(TESTFILE);    props = new Properties();    props.load(reader);    props.put("log4j.appender.out2.Port", String.valueOf(port));    reader.close();}
f8da1974006e3fc9b0f1d89ba39da6e2d271c0c203e111198231232d6e29e721
configureSource
private void configureSource()
{    ChannelSelector rcs = new ReplicatingChannelSelector();    rcs.setChannels(Collections.singletonList(ch));    source.setChannelProcessor(new ChannelProcessor(rcs));    source.start();}
24fcabcd9272ae9ce02993724eca63a61d97449eff3e294bea7e9c1a70d900ca
testLog4jAppender
public void testLog4jAppender() throws IOException
{    configureSource();    PropertyConfigurator.configure(props);    Logger logger = LogManager.getLogger(TestLog4jAppender.class);    for (int count = 0; count <= 1000; count++) {        /*       * Log4j internally defines levels as multiples of 10000. So if we       * create levels directly using count, the level will be set as the       * default.       */        int level = ((count % 5) + 1) * 10000;        String msg = "This is log message number" + String.valueOf(count);        logger.log(Level.toLevel(level), msg);        Transaction transaction = ch.getTransaction();        transaction.begin();        Event event = ch.take();        Assert.assertNotNull(event);        Assert.assertEquals(new String(event.getBody(), "UTF8"), msg);        Map<String, String> hdrs = event.getHeaders();        Assert.assertNotNull(hdrs.get(Log4jAvroHeaders.TIMESTAMP.toString()));        Assert.assertEquals(Level.toLevel(level), Level.toLevel(Integer.valueOf(hdrs.get(Log4jAvroHeaders.LOG_LEVEL.toString()))));        Assert.assertNotNull(hdrs.get(Log4jAvroHeaders.ADDRESS.toString()));        Assert.assertEquals(logger.getName(), hdrs.get(Log4jAvroHeaders.LOGGER_NAME.toString()));        Assert.assertEquals("UTF8", hdrs.get(Log4jAvroHeaders.MESSAGE_ENCODING.toString()));        transaction.commit();        transaction.close();    }}
fb14c4ac1417898312a0f734fb6fd43999bdb5d10e356a6c6b039d8fa5bced2c
testBatchedSending
private void testBatchedSending(int numEvents)
{    configureSource();    PropertyConfigurator.configure(props);    Logger logger = LogManager.getLogger(getClass());    List<String> events = IntStream.range(0, numEvents).mapToObj(String::valueOf).collect(Collectors.toList());    logger.info(events);    Transaction tx = ch.getTransaction();    tx.begin();    for (String s : events) {        Event e = ch.take();        Assert.assertNotNull(e);        Assert.assertEquals(s, new String(e.getBody()));    }    Assert.assertNull("There should be no more events in the channel", ch.take());}
1657182949618c3f8811c732e6cd5011ee9095c8cbac160e38cd3395a0ad0c57
testLogBatch
public void testLogBatch()
{    testBatchedSending(5);    Mockito.verify(source, Mockito.times(1)).appendBatch(Mockito.anyList());    Mockito.verify(source, Mockito.times(0)).append(Mockito.any(AvroFlumeEvent.class));}
f88932ec1a5858013b62fcb84f3e60e5cc5bbb8f804234bf0c6f0eee8cf7a6be
testLogSingleMessage
public void testLogSingleMessage()
{    configureSource();    PropertyConfigurator.configure(props);    Logger logger = LogManager.getLogger(getClass());    logger.info("test");    Transaction tx = ch.getTransaction();    tx.begin();    Event e = ch.take();    Assert.assertNotNull(e);    Assert.assertEquals("test", new String(e.getBody()));    Mockito.verify(source, Mockito.times(0)).appendBatch(Mockito.anyList());    Mockito.verify(source, Mockito.times(1)).append(Mockito.any(AvroFlumeEvent.class));}
0f8bd8f4b6010059dab695cbbf95316fe45475e216be088b3b67177dd16fc6a6
testLogSingleMessageInCollection
public void testLogSingleMessageInCollection()
{    testBatchedSending(1);    Mockito.verify(source, Mockito.times(0)).appendBatch(Mockito.anyList());    Mockito.verify(source, Mockito.times(1)).append(Mockito.any(AvroFlumeEvent.class));}
06a3297cc4e1e7984095a8ca0caa20fd5e7f9bd9d4d00c70aaa546369bc04182
testLogEmptyBatch
public void testLogEmptyBatch()
{    testBatchedSending(0);    Mockito.verify(source, Mockito.times(0)).appendBatch(Mockito.anyList());    Mockito.verify(source, Mockito.times(0)).append(Mockito.any(AvroFlumeEvent.class));}
6d00ee4c0dbd39b707b68120e0d5cf26305e619cc5a8832a60eae8d9c217b9c7
testLog4jAppenderFailureUnsafeMode
public void testLog4jAppenderFailureUnsafeMode() throws Throwable
{    configureSource();    props.setProperty("log4j.appender.out2.UnsafeMode", String.valueOf(true));    PropertyConfigurator.configure(props);    Logger logger = LogManager.getLogger(TestLog4jAppender.class);    source.stop();    sendAndAssertFail(logger);}
f40a534a01ad15dd355d0bba5e999c456a94b3a482627fff75f667c8885c3a91
testLog4jAppenderFailureNotUnsafeMode
public void testLog4jAppenderFailureNotUnsafeMode() throws Throwable
{    configureSource();    PropertyConfigurator.configure(props);    Logger logger = LogManager.getLogger(TestLog4jAppender.class);    source.stop();    sendAndAssertFail(logger);}
14a35725d3378d554438d3854a798120bd5583209f0b6f82d75013ac1675cafe
sendAndAssertFail
private void sendAndAssertFail(Logger logger) throws Throwable
{    /*     * Log4j internally defines levels as multiples of 10000. So if we     * create levels directly using count, the level will be set as the     * default.     */    int level = 20000;    try {        logger.log(Level.toLevel(level), "Test Msg");    } catch (FlumeException ex) {        ex.printStackTrace();        throw ex.getCause();    }    Transaction transaction = ch.getTransaction();    transaction.begin();    Event event = ch.take();    Assert.assertNull(event);    transaction.commit();    transaction.close();}
846c346f2e3b937d32a104babfc4347cde069fe17421ab5a8c552ac4baf1ff55
testLayout
public void testLayout() throws IOException
{    configureSource();    props.put("log4j.appender.out2.layout", "org.apache.log4j.PatternLayout");    props.put("log4j.appender.out2.layout.ConversionPattern", "%-5p [%t]: %m%n");    PropertyConfigurator.configure(props);    Logger logger = LogManager.getLogger(TestLog4jAppender.class);    Thread.currentThread().setName("Log4jAppenderTest");    for (int count = 0; count <= 100; count++) {        /*       * Log4j internally defines levels as multiples of 10000. So if we       * create levels directly using count, the level will be set as the       * default.       */        int level = ((count % 5) + 1) * 10000;        String msg = "This is log message number" + String.valueOf(count);        logger.log(Level.toLevel(level), msg);        Transaction transaction = ch.getTransaction();        transaction.begin();        Event event = ch.take();        Assert.assertNotNull(event);        StringBuilder builder = new StringBuilder();        builder.append("[").append("Log4jAppenderTest").append("]: ").append(msg);                String eventBody = new String(event.getBody(), "UTF-8");        String eventLevel = eventBody.split("\\s+")[0];        Assert.assertEquals(Level.toLevel(level).toString(), eventLevel);        Assert.assertEquals(new String(event.getBody(), "UTF8").trim().substring(eventLevel.length()).trim(), builder.toString());        Map<String, String> hdrs = event.getHeaders();        Assert.assertNotNull(hdrs.get(Log4jAvroHeaders.TIMESTAMP.toString()));        Assert.assertEquals(Level.toLevel(level), Level.toLevel(Integer.parseInt(hdrs.get(Log4jAvroHeaders.LOG_LEVEL.toString()))));        Assert.assertEquals(logger.getName(), hdrs.get(Log4jAvroHeaders.LOGGER_NAME.toString()));        Assert.assertEquals("UTF8", hdrs.get(Log4jAvroHeaders.MESSAGE_ENCODING.toString()));        transaction.commit();        transaction.close();    }}
bd3da1311c554c6867842ecd82fbf0687229511c0f172cda4270e62f65d82091
testSlowness
public void testSlowness() throws Throwable
{    ch = new SlowMemoryChannel(2000);    Configurables.configure(ch, new Context());    configureSource();    props.put("log4j.appender.out2.Timeout", "1000");    props.put("log4j.appender.out2.layout", "org.apache.log4j.PatternLayout");    props.put("log4j.appender.out2.layout.ConversionPattern", "%-5p [%t]: %m%n");    PropertyConfigurator.configure(props);    Logger logger = LogManager.getLogger(TestLog4jAppender.class);    Thread.currentThread().setName("Log4jAppenderTest");    int level = 10000;    String msg = "This is log message number" + String.valueOf(1);    try {        logger.log(Level.toLevel(level), msg);    } catch (FlumeException ex) {        throw ex.getCause();    }}
86aef34769877562e472ecf7d242bfd48ea0112a4f8e9f2d62a85840a0c685c2
testSlownessUnsafeMode
public void testSlownessUnsafeMode() throws Throwable
{    props.setProperty("log4j.appender.out2.UnsafeMode", String.valueOf(true));    testSlowness();}
8d9ec964cb2b1702f35510b65dc80717f83aa9b6d06f2d7caf8545c5d3f9a1d1
cleanUp
public void cleanUp()
{    source.stop();    ch.stop();    props.clear();}
703ad3ee0af19d2906fd7e0e4632200d181dc8c3fe1ffd8767d8933497ba5d07
put
public void put(Event e)
{    try {        TimeUnit.MILLISECONDS.sleep(slowTime);    } catch (Exception ex) {        throw new RuntimeException(ex);    }    super.put(e);}
d2736cb1a1c64615d3e4c0619544e21348d5e5b69c9b67bca5628de60256c11e
getFreePort
private static int getFreePort() throws Exception
{    try (ServerSocket socket = new ServerSocket(0)) {        return socket.getLocalPort();    }}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    URL schemaUrl = getClass().getClassLoader().getResource("myrecord.avsc");    Files.copy(Resources.newInputStreamSupplier(schemaUrl), new File("/tmp/myrecord.avsc"));    port = getFreePort();    source = new AvroSource();    ch = new MemoryChannel();    Configurables.configure(ch, new Context());    Context context = new Context();    context.put("port", String.valueOf(port));    context.put("bind", "localhost");    Configurables.configure(source, context);    List<Channel> channels = new ArrayList<>();    channels.add(ch);    ChannelSelector rcs = new ReplicatingChannelSelector();    rcs.setChannels(channels);    source.setChannelProcessor(new ChannelProcessor(rcs));    source.start();}
5bbb78a7903fd83b506a4db1f97097a97f879c32252358c6969a48bd5c519ee7
loadProperties
private void loadProperties(String file) throws IOException
{    File TESTFILE = new File(TestLog4jAppenderWithAvro.class.getClassLoader().getResource(file).getFile());    FileReader reader = new FileReader(TESTFILE);    props = new Properties();    props.load(reader);    reader.close();}
6293b42766320d16d1867b6f02e41a7c90014bd2224e8566b141358013eded47
testAvroGeneric
public void testAvroGeneric() throws IOException
{    loadProperties("flume-log4jtest-avro-generic.properties");    props.put("log4j.appender.out2.Port", String.valueOf(port));    PropertyConfigurator.configure(props);    Logger logger = LogManager.getLogger(TestLog4jAppenderWithAvro.class);    String msg = "This is log message number " + String.valueOf(0);    Schema schema = new Schema.Parser().parse(getClass().getClassLoader().getResource("myrecord.avsc").openStream());    GenericRecordBuilder builder = new GenericRecordBuilder(schema);    GenericRecord record = builder.set("message", msg).build();    logger.info(record);    Transaction transaction = ch.getTransaction();    transaction.begin();    Event event = ch.take();    Assert.assertNotNull(event);    GenericDatumReader<GenericRecord> reader = new GenericDatumReader<>(schema);    BinaryDecoder decoder = DecoderFactory.get().binaryDecoder(event.getBody(), null);    GenericRecord recordFromEvent = reader.read(null, decoder);    Assert.assertEquals(msg, recordFromEvent.get("message").toString());    Map<String, String> hdrs = event.getHeaders();    Assert.assertNull(hdrs.get(Log4jAvroHeaders.MESSAGE_ENCODING.toString()));    Assert.assertEquals("Schema URL should be set", "file:///tmp/myrecord.avsc", hdrs.get(Log4jAvroHeaders.AVRO_SCHEMA_URL.toString()));    Assert.assertNull("Schema string should not be set", hdrs.get(Log4jAvroHeaders.AVRO_SCHEMA_LITERAL.toString()));    transaction.commit();    transaction.close();}
da2cac9ca22550aa0fc261ef1c37d04c907ea5fff9a0d97a1148b17ce9c16921
testAvroReflect
public void testAvroReflect() throws IOException
{    loadProperties("flume-log4jtest-avro-reflect.properties");    props.put("log4j.appender.out2.Port", String.valueOf(port));    PropertyConfigurator.configure(props);    Logger logger = LogManager.getLogger(TestLog4jAppenderWithAvro.class);    String msg = "This is log message number " + String.valueOf(0);    AppEvent appEvent = new AppEvent();    appEvent.setMessage(msg);    logger.info(appEvent);    Transaction transaction = ch.getTransaction();    transaction.begin();    Event event = ch.take();    Assert.assertNotNull(event);    Schema schema = ReflectData.get().getSchema(appEvent.getClass());    ReflectDatumReader<AppEvent> reader = new ReflectDatumReader<>(AppEvent.class);    BinaryDecoder decoder = DecoderFactory.get().binaryDecoder(event.getBody(), null);    AppEvent recordFromEvent = reader.read(null, decoder);    Assert.assertEquals(msg, recordFromEvent.getMessage());    Map<String, String> hdrs = event.getHeaders();    Assert.assertNull(hdrs.get(Log4jAvroHeaders.MESSAGE_ENCODING.toString()));    Assert.assertNull("Schema URL should not be set", hdrs.get(Log4jAvroHeaders.AVRO_SCHEMA_URL.toString()));    Assert.assertEquals("Schema string should be set", schema.toString(), hdrs.get(Log4jAvroHeaders.AVRO_SCHEMA_LITERAL.toString()));    transaction.commit();    transaction.close();}
2425330c39b426bdfa42e58dea63023374a115919c34972083c85b1074a9b8ab
testDifferentEventTypesInBatchWithAvroReflect
public void testDifferentEventTypesInBatchWithAvroReflect() throws IOException
{    loadProperties("flume-log4jtest-avro-reflect.properties");    props.put("log4j.appender.out2.Port", String.valueOf(port));    PropertyConfigurator.configure(props);    Logger logger = LogManager.getLogger(getClass());    List<Object> events = Arrays.asList("string", new AppEvent("appEvent"));    logger.info(events);    Transaction transaction = ch.getTransaction();    transaction.begin();    for (Object o : events) {        Event e = ch.take();        Assert.assertNotNull(e);        ReflectDatumReader<?> reader = new ReflectDatumReader<>(o.getClass());        BinaryDecoder decoder = DecoderFactory.get().binaryDecoder(e.getBody(), null);        Object readObject = reader.read(null, decoder);        Assert.assertEquals(o, readObject);        Map<String, String> hdrs = e.getHeaders();        Assert.assertNull(hdrs.get(Log4jAvroHeaders.MESSAGE_ENCODING.toString()));        Assert.assertNull("Schema URL should not be set", hdrs.get(Log4jAvroHeaders.AVRO_SCHEMA_URL.toString()));        Assert.assertEquals("Schema string should be set", ReflectData.get().getSchema(readObject.getClass()).toString(), hdrs.get(Log4jAvroHeaders.AVRO_SCHEMA_LITERAL.toString()));    }    Assert.assertNull("There should be no more events in the channel", ch.take());}
a0afac55d214698e256e47ca5e8c96d0f7178862497d546dd0fe9ec1fc4f3948
testDifferentEventTypesInBatchWithAvroGeneric
public void testDifferentEventTypesInBatchWithAvroGeneric() throws IOException
{    loadProperties("flume-log4jtest-avro-generic.properties");    props.put("log4j.appender.out2.Port", String.valueOf(port));    PropertyConfigurator.configure(props);    Logger logger = LogManager.getLogger(getClass());    String msg = "Avro log message";    Schema schema = new Schema.Parser().parse(getClass().getClassLoader().getResource("myrecord.avsc").openStream());    GenericRecordBuilder builder = new GenericRecordBuilder(schema);    GenericRecord record = builder.set("message", msg).build();    List<Object> events = Arrays.asList("string", record);    logger.info(events);    Transaction transaction = ch.getTransaction();    transaction.begin();    Event event = ch.take();    Assert.assertNotNull(event);    Assert.assertEquals("string", new String(event.getBody()));    event = ch.take();    Assert.assertNotNull(event);    GenericDatumReader<GenericRecord> reader = new GenericDatumReader<>(schema);    BinaryDecoder decoder = DecoderFactory.get().binaryDecoder(event.getBody(), null);    GenericRecord recordFromEvent = reader.read(null, decoder);    Assert.assertEquals(msg, recordFromEvent.get("message").toString());    Map<String, String> hdrs = event.getHeaders();    Assert.assertNull(hdrs.get(Log4jAvroHeaders.MESSAGE_ENCODING.toString()));    Assert.assertEquals("Schema URL should be set", "file:///tmp/myrecord.avsc", hdrs.get(Log4jAvroHeaders.AVRO_SCHEMA_URL.toString()));    Assert.assertNull("Schema string should not be set", hdrs.get(Log4jAvroHeaders.AVRO_SCHEMA_LITERAL.toString()));    transaction.commit();    transaction.close();}
8d9ec964cb2b1702f35510b65dc80717f83aa9b6d06f2d7caf8545c5d3f9a1d1
cleanUp
public void cleanUp()
{    source.stop();    ch.stop();    props.clear();}
b46153cc21231cb60e014b6b3c49b437699575e4012681cb08026e5238c66751
getMessage
public String getMessage()
{    return message;}
2bcf6673d72f24a37567f86c2d21222c057668cc9dcc031caf2d074de4775d13
setMessage
public void setMessage(String message)
{    this.message = message;}
8d37d11c7ecfc0d0589696a89cb385888c83bd3e43ea0c95a3b4ae4ef78180ce
equals
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    AppEvent appEvent = (AppEvent) o;    return message != null ? message.equals(appEvent.message) : appEvent.message == null;}
0ac42bf5188762fc1283b5cbd2b3bb1031e80963813b3b310b15c3fb47050003
hashCode
public int hashCode()
{    return message != null ? message.hashCode() : 0;}
f498f22eaf0816bf385a43365651d1b6d0455905fdd2d6be01ceefeb84e8f432
setName
public void setName(String name)
{    this.name = name;}
239fbe3eb64d679cbac1161825b07d6a8436ead3c6c3d140d9caec2275827023
getName
public String getName()
{    return name;}
e46fbd31cf9c6caffaa8eb691a3bbd936651af72e2a52fbf8d1c7ad20e0e1e65
filter
public String filter(String key)
{    return System.getenv(key);}
a8f99150e663aa3c2dda83df4cd26bf8e9352d150bcca7ca0ce579d6eacbce0a
initializeWithConfiguration
public void initializeWithConfiguration(Map<String, String> configuration)
{}
aaa8728280b643d6f2ce2059e07d52693163c65d9c72dd701a647b372c58b227
filter
public void filter()
{    environmentVariables.set(MY_PASSWORD_KEY, FILTERED);    environmentVariables.set(MY_PASSWORD_KEY_2, FILTERED_2);    ConfigFilter configFilter = new EnvironmentVariableConfigFilter();    assertEquals(FILTERED, configFilter.filter(MY_PASSWORD_KEY));    assertEquals(FILTERED_2, configFilter.filter(MY_PASSWORD_KEY_2));}
6ee622aa07c9e1060d265030b44501fd7c95cd2903efa46886168d4c5e97eb16
filterUnknownKey
public void filterUnknownKey()
{    ConfigFilter configFilter = new EnvironmentVariableConfigFilter();    assertNull(configFilter.filter("unknown"));}
e46fbd31cf9c6caffaa8eb691a3bbd936651af72e2a52fbf8d1c7ad20e0e1e65
filter
public String filter(String key)
{    try {        return execCommand(key);    } catch (InterruptedException | IllegalStateException | IOException ex) {        LOGGER.error("Error while reading value for key {}: ", key, ex);    }    return null;}
a8f99150e663aa3c2dda83df4cd26bf8e9352d150bcca7ca0ce579d6eacbce0a
initializeWithConfiguration
public void initializeWithConfiguration(Map<String, String> configuration)
{    String charsetName = configuration.getOrDefault(CHARSET_KEY, CHARSET_DEFAULT);    try {        charset = Charset.forName(charsetName);    } catch (UnsupportedCharsetException ex) {        throw new RuntimeException("Unsupported charset: " + charsetName, ex);    }    command = configuration.get(COMMAND_KEY);    if (command == null) {        throw new IllegalArgumentException(COMMAND_KEY + " must be set for " + "ExternalProcessConfigFilter");    }}
8860b5c1bb3dfad26e67b53c5787e6e47dc45f18d7fec0fd80186b232733c16c
execCommand
private String execCommand(String key) throws IOException, InterruptedException
{    String[] split = command.split("\\s+");    int newLength = split.length + 1;    String[] commandParts = Arrays.copyOf(split, newLength);    commandParts[newLength - 1] = key;    Process p = Runtime.getRuntime().exec(commandParts);    p.waitFor();    if (p.exitValue() != 0) {        String stderr;        try {            stderr = getResultFromStream(p.getErrorStream());        } catch (Throwable t) {            stderr = null;        }        throw new IllegalStateException(String.format("Process (%s) exited with non-zero (%s) status code. Sterr: %s", this.command, p.exitValue(), stderr));    }    return getResultFromStream(p.getInputStream());}
64df341944d3297c1b02860ef479bdc2c4cb087d47b9c11fd81db2c634a5e104
getResultFromStream
private String getResultFromStream(InputStream inputStream)
{    try (Scanner scanner = new Scanner(inputStream, charset.name())) {        String result = null;        if (scanner.hasNextLine()) {            result = scanner.nextLine();            if (scanner.hasNextLine()) {                LOGGER.warn("External process has more than one line of output. " + "Only the first line is used.");            }        } else {            LOGGER.warn("External process has not produced any output.");        }        return result;    }}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    configFilter = new ExternalProcessConfigFilter();}
1728a9bf59f1a0439a4fe9c7d707ab6da1cfc935e00700a13a676a758427eeea
filterOk
public void filterOk()
{    String file = Thread.currentThread().getContextClassLoader().getResource("test.sh").getFile();    File testExecutable = new File(file);    testExecutable.setExecutable(true);    HashMap<String, String> configuration = new HashMap<>();    configuration.put("command", file);    configFilter.initializeWithConfiguration(configuration);    assertEquals(FILTERED, configFilter.filter(MY_PASSWORD_KEY));    assertEquals(FILTERED_2, configFilter.filter(MY_PASSWORD_KEY_2));}
1dc29a506bdbd2d4edabfef975ddeb79e7eaf4b6e51fca23298836cc4356ec7b
filterError
public void filterError()
{    String file = Thread.currentThread().getContextClassLoader().getResource("test_error.sh").getFile();    File testExecutable = new File(file);    testExecutable.setExecutable(true);    HashMap<String, String> configuration = new HashMap<>();    configuration.put("command", file);    configFilter.initializeWithConfiguration(configuration);    assertNull(configFilter.filter(MY_PASSWORD_KEY));}
a8f99150e663aa3c2dda83df4cd26bf8e9352d150bcca7ca0ce579d6eacbce0a
initializeWithConfiguration
public void initializeWithConfiguration(Map<String, String> configuration)
{    LOGGER.debug("Initializing hadoop credential store.");    hadoopConfiguration = new Configuration();    hadoopConfiguration.set(HADOOP_SECURITY + CREDENTIAL_PROVIDER_PATH, configuration.get(CREDENTIAL_PROVIDER_PATH));    String passwordFile = configuration.get(PASSWORD_FILE_CONFIG_KEY);    if (passwordFile != null && !passwordFile.isEmpty()) {        checkPasswordFile(passwordFile);        hadoopConfiguration.set(HADOOP_SECURITY + PASSWORD_FILE_CONFIG_KEY, passwordFile);    }}
53394ff16bc9c4a753e0420ff9a6d8079f6ec6e05d8d500db49a0dc12317fe5a
checkPasswordFile
private void checkPasswordFile(String passwordFile)
{    if (Thread.currentThread().getContextClassLoader().getResource(passwordFile) == null) {        LOGGER.error("The java keystore provider password file has to be on the classpath." + " The password file provided in the configuration cannot be found and will not be used");    }}
e46fbd31cf9c6caffaa8eb691a3bbd936651af72e2a52fbf8d1c7ad20e0e1e65
filter
public String filter(String key)
{    char[] result = null;    try {        result = hadoopConfiguration.getPassword(key);    } catch (IOException e) {        LOGGER.error("Error while reading value for key {}: ", key, e);    }    return result == null ? null : new String(result);}
7f0f73b325bcd37632c396c02bb87ddfe4bb9da1a35fac272192ae84740eb688
setUpClass
public static void setUpClass() throws Exception
{    generateTempFileNames();    fillCredStoreWithDefaultPassword();    fillCredStoreWithPasswordFile();    fillCredStoreWithEnvironmentVariablePassword();}
7bc01499962f9db4f29ce028fa1e575b4b5f7e9b37f763467d82ccb96ea15886
tearDown
public static void tearDown()
{    fileDefault.deleteOnExit();    fileEnvPassword.deleteOnExit();    fileFilePassword.deleteOnExit();}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    String[] objects = System.getenv().keySet().toArray(new String[0]);    environmentVariables.clear(objects);    configFilter = new HadoopCredentialStoreConfigFilter();}
b66fa37153b29c004938aecb1550d16c820b6d859f4eb28fdda9870bcacbf947
filterDefaultPasswordFile
public void filterDefaultPasswordFile()
{    HashMap<String, String> configuration = new HashMap<>();    configuration.put(CREDENTIAL_PROVIDER_PATH, providerPathDefault);    configFilter.initializeWithConfiguration(configuration);    assertEquals("filtered_default", configFilter.filter("password"));}
1c3361359a8bbe427593d65e199d189478a6347107115017b252dfcd7e5214a8
filterWithEnvPassword
public void filterWithEnvPassword()
{    environmentVariables.set("HADOOP_CREDSTORE_PASSWORD", "envSecret");    HashMap<String, String> configuration = new HashMap<>();    configuration.put(CREDENTIAL_PROVIDER_PATH, providerPathEnv);    configFilter.initializeWithConfiguration(configuration);    assertEquals("filtered_env", configFilter.filter("password"));}
4f7d4db290a900357f0147976e4f6dd78c75119646b2a61ba4559049feedff44
filterWithPasswordFile
public void filterWithPasswordFile()
{    HashMap<String, String> configuration = new HashMap<>();    configuration.put(CREDENTIAL_PROVIDER_PATH, providerPathPwdFile);    configuration.put(PASSWORD_FILE_CONFIG_KEY, "test-password.txt");    configFilter.initializeWithConfiguration(configuration);    assertEquals("filtered_file", configFilter.filter("password"));}
8935e76aebb2e44c25a55abea20b24227c7d2f0f179b82f7eb28a46459fabdc3
filterWithEnvNoPassword
public void filterWithEnvNoPassword()
{    HashMap<String, String> configuration = new HashMap<>();    configuration.put(CREDENTIAL_PROVIDER_PATH, providerPathEnv);    configFilter.initializeWithConfiguration(configuration);    assertNull(configFilter.filter("password"));}
1ad2977bd4d89530070f4d2e05fa381c71392f209354f79f7a2ff7cad77bd132
filterErrorWithPasswordFileWrongPassword
public void filterErrorWithPasswordFileWrongPassword()
{    HashMap<String, String> configuration = new HashMap<>();    configuration.put(CREDENTIAL_PROVIDER_PATH, providerPathPwdFile);    configuration.put(PASSWORD_FILE_CONFIG_KEY, "test-password2.txt");    configFilter.initializeWithConfiguration(configuration);    assertNull(configFilter.filter("password"));}
ef9c59474b616fc9452cbebec64ce60bd0b3bc7cc004a8f713dcec35cd2db05b
filterErrorWithPasswordFileNoPasswordFile
public void filterErrorWithPasswordFileNoPasswordFile()
{    HashMap<String, String> configuration = new HashMap<>();    configuration.put(CREDENTIAL_PROVIDER_PATH, providerPathPwdFile);    configFilter.initializeWithConfiguration(configuration);    assertNull(configFilter.filter("password"));}
fefbd397cfc097dca5287b8ec9a49d65d342feb727c3bdd68ce3c7fbc2220568
filterErrorWithNoProvider
public void filterErrorWithNoProvider()
{    HashMap<String, String> configuration = new HashMap<>();    configFilter.initializeWithConfiguration(configuration);}
7562aacba3ed81f155c1278e6ad46a78f1ae9b82f542c67835ac73df2e25e409
fillCredStoreWithEnvironmentVariablePassword
private static void fillCredStoreWithEnvironmentVariablePassword() throws Exception
{    environmentVariables.set("HADOOP_CREDSTORE_PASSWORD", "envSecret");    runCommand("create password -value filtered_env -provider " + providerPathEnv, new Configuration());}
362a6f572bc758e63696199bd5fede1595a7ca65d1574ad34464670d82de2950
fillCredStoreWithPasswordFile
private static void fillCredStoreWithPasswordFile() throws Exception
{    Configuration conf = new Configuration();    conf.set(HADOOP_SECURITY + PASSWORD_FILE_CONFIG_KEY, "test-password.txt");    runCommand("create password -value filtered_file -provider " + providerPathPwdFile, conf);}
921843df7b72a3cb6aaaacfa5afaa88dfd95f7c90a28324edcff15ff90167db4
fillCredStoreWithDefaultPassword
private static void fillCredStoreWithDefaultPassword() throws Exception
{    runCommand("create password -value filtered_default -provider " + providerPathDefault, new Configuration());}
b9e2d45b13bfaa1e6ec856867fccd19ff5dc67050d0e1083901c442ebb3f2294
generateTempFileNames
private static void generateTempFileNames() throws IOException
{    fileDefault = Files.createTempFile("test-default-pwd-", ".jceks").toFile();    boolean deleted = fileDefault.delete();    fileEnvPassword = Files.createTempFile("test-env-pwd-", ".jceks").toFile();    deleted &= fileEnvPassword.delete();    fileFilePassword = Files.createTempFile("test-file-pwd-", ".jceks").toFile();    deleted &= fileFilePassword.delete();    if (!deleted) {        fail("Could not delete temporary files");    }    providerPathDefault = "jceks://file/" + fileDefault.getAbsolutePath();    providerPathEnv = "jceks://file/" + fileEnvPassword.getAbsolutePath();    providerPathPwdFile = "jceks://file/" + fileFilePassword.getAbsolutePath();}
c36447389b5ef02f90cd94bef16f13b6d0d70f864e20140266eae87a27bc28be
runCommand
private static void runCommand(String c, Configuration conf) throws Exception
{    ToolRunner.run(conf, new CredentialShell(), c.split(" "));}
d959aee6a1a6d10c9ab41bc4708573e57f1c016515cbfac660d5066035af4ccc
getChannelConfigurationType
public String getChannelConfigurationType()
{    return channelConfigurationType;}
ddcf4002d874041c24a1b2b68e8b9374370f5a532c219f0f5422ebb0ecbba2d4
getConfiguration
public ChannelConfiguration getConfiguration(String name) throws ConfigurationException
{    if (this == OTHER) {        return new ChannelConfiguration(name);    }    Class<? extends ChannelConfiguration> clazz;    ChannelConfiguration instance = null;    try {        if (channelConfigurationType != null) {            clazz = (Class<? extends ChannelConfiguration>) Class.forName(channelConfigurationType);            instance = clazz.getConstructor(String.class).newInstance(name);        } else {            return new ChannelConfiguration(name);        }    } catch (ClassNotFoundException e) {                instance = new ChannelConfiguration(name);                instance.setNotFoundConfigClass();    } catch (Exception e) {        throw new ConfigurationException(e);    }    return instance;}
873cad62be98ed7e56366b0f37464e66c4b071364af066d8957f3a800004ecb4
getChannels
public Set<String> getChannels()
{    return channelNames;}
8ab37774f9613d002414107db5c9c57e1c36e68b7d6cc319466004d4f8c2fd75
setChannels
public void setChannels(Set<String> channelNames)
{    this.channelNames = channelNames;}
f50dcaff3cb7c7b6059577289b4dce5beccfd33a49a26ad7ccd29897d7bcbbea
getChannelSelectorConfigurationType
public String getChannelSelectorConfigurationType()
{    return this.selectorType;}
733fbb933b218f8c8bd2af23ebd6283c33dea7de3e34eddcd9b40b2016c2e43c
getConfiguration
public ChannelSelectorConfiguration getConfiguration(String name) throws ConfigurationException
{    if (this == OTHER) {        return new ChannelSelectorConfiguration(name);    }    Class<? extends ChannelSelectorConfiguration> clazz;    ChannelSelectorConfiguration instance = null;    try {                if (this.selectorType != null) {            clazz = (Class<? extends ChannelSelectorConfiguration>) Class.forName(this.selectorType);            instance = clazz.getConstructor(String.class).newInstance(name);        } else {            return new ChannelSelectorConfiguration(name);        }    } catch (ClassNotFoundException e) {                instance = new ChannelSelectorConfiguration(name);                instance.setNotFoundConfigClass();    } catch (Exception e) {        throw new ConfigurationException("Configuration error!", e);    }    return instance;}
127608cce9944e6016907b78da668158fe9a132cdb42c61991a7e502d240426b
getChannelSelectorClassName
public String getChannelSelectorClassName()
{    return channelSelectorClassName;}
cfac927e2f01f3beaf1fd6e054846dfbf79b00c5682148da97865c5140e7327f
getClassName
public String getClassName()
{    return channelSelectorClassName;}
551c0000cbfea74a7f1227d0eeefd6957eb1593ad686cdcc40bd83e1a94a7e1b
getChannelClassName
public String getChannelClassName()
{    return channelClassName;}
cfac927e2f01f3beaf1fd6e054846dfbf79b00c5682148da97865c5140e7327f
getClassName
public String getClassName()
{    return channelClassName;}
8c2b850f15b0567ac65b994f597b665e30bf60a61366d85ed5f8f940b22f0903
isNotFoundConfigClass
public boolean isNotFoundConfigClass()
{    return notFoundConfigClass;}
9a0e3dea78f4c138ebb5922f3a086ae9341036fa7580fb994d1bac88aa87380f
setNotFoundConfigClass
public void setNotFoundConfigClass()
{    this.notFoundConfigClass = true;}
3588a81910ca3a9e96c7f3c0373562bf84d86ea9540239daf34421432c6dd9c5
getErrors
public List<FlumeConfigurationError> getErrors()
{    return errors;}
fa47897acd081345080fc68c9f58ae17a63581f7e2187e4637955118b04f027a
configure
public void configure(Context context) throws ConfigurationException
{    failIfConfigured();    String confType = context.getString(BasicConfigurationConstants.CONFIG_TYPE);    if (confType != null && !confType.isEmpty()) {        this.type = confType;    }        if (this.type == null || this.type.isEmpty()) {        errors.add(new FlumeConfigurationError(componentName, BasicConfigurationConstants.CONFIG_TYPE, FlumeConfigurationErrorType.ATTRS_MISSING, ErrorOrWarning.ERROR));        throw new ConfigurationException("Component has no type. Cannot configure. " + componentName);    }}
653f6837d324adc840cb45fc615f75321f0fa1efd4ee5a81e483ff4bc4e26850
failIfConfigured
protected void failIfConfigured() throws ConfigurationException
{    if (configured) {        throw new ConfigurationException("Already configured component." + componentName);    }}
624f725337dde847c4a699397a02f1b5558c709c88374adb10e603d835f48c88
getType
public String getType()
{    return type;}
8ab53042064bb8f4e31355121ce5a5ccc6f3b8e9227cceb605ae26d51b21bddd
setType
public void setType(String type)
{    this.type = type;}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return toString(0);}
167f366474d3fcb23d30207cfbde726d2c37216fc3b740b30da36e6d0530ff92
toString
public String toString(int indentCount)
{    StringBuilder indentSb = new StringBuilder();    for (int i = 0; i < indentCount; i++) {        indentSb.append(FlumeConfiguration.INDENTSTEP);    }    String indent = indentSb.toString();    StringBuilder sb = new StringBuilder(indent);    sb.append("ComponentConfiguration[").append(componentName).append("]");    sb.append(FlumeConfiguration.NEWLINE).append(indent).append(FlumeConfiguration.INDENTSTEP).append("CONFIG: ");    sb.append(FlumeConfiguration.NEWLINE).append(indent).append(FlumeConfiguration.INDENTSTEP);    return sb.toString();}
f3582dedc5a60972387514c1a69a3aeba1621c63b1cd72b1e7cd4b550a63667e
getComponentName
public String getComponentName()
{    return componentName;}
93eb9ac15362b3251d0a0e1aaa02b730331748b51a2a3087415e30ddedb89b09
setConfigured
protected void setConfigured()
{    configured = true;}
618d5399cb8fdfe87ba0e41f4dc09577f1a960037a2d58dabf8514613b5ba5d9
getComponentType
public String getComponentType()
{    return componentType;}
cd1215968d69be8b27340a7634bc8916518489c803283b947ef244b7efb70ea4
create
public static ComponentConfiguration create(String name, String type, ComponentType component) throws ConfigurationException
{    Class<? extends ComponentConfiguration> confType = null;    if (type == null) {        throw new ConfigurationException("Cannot create component without knowing its type!");    }    try {        confType = (Class<? extends ComponentConfiguration>) Class.forName(type);        return confType.getConstructor(String.class).newInstance(type);    } catch (Exception ignored) {        try {            type = type.toUpperCase(Locale.ENGLISH);            switch(component) {                case SOURCE:                    return SourceConfigurationType.valueOf(type.toUpperCase(Locale.ENGLISH)).getConfiguration(name);                case CONFIG_FILTER:                    return ConfigFilterConfigurationType.valueOf(type.toUpperCase(Locale.ENGLISH)).getConfiguration(name);                case SINK:                    return SinkConfigurationType.valueOf(type.toUpperCase(Locale.ENGLISH)).getConfiguration(name);                case CHANNEL:                    return ChannelConfigurationType.valueOf(type.toUpperCase(Locale.ENGLISH)).getConfiguration(name);                case SINK_PROCESSOR:                    return SinkProcessorConfigurationType.valueOf(type.toUpperCase(Locale.ENGLISH)).getConfiguration(name);                case CHANNELSELECTOR:                    return ChannelSelectorConfigurationType.valueOf(type.toUpperCase(Locale.ENGLISH)).getConfiguration(name);                case SINKGROUP:                    return new SinkGroupConfiguration(name);                default:                    throw new ConfigurationException("Cannot create configuration. Unknown Type specified: " + type);            }        } catch (ConfigurationException e) {            throw e;        } catch (Exception e) {            throw new ConfigurationException("Could not create configuration! " + " Due to " + e.getClass().getSimpleName() + ": " + e.getMessage(), e);        }    }}
60ac5f2e5cfc802d2fe35dec45b6b45dafbe56469c26f315060cdcc384c0101c
getConfigFilterConfigurationType
public String getConfigFilterConfigurationType()
{    return configurationName;}
6e75a8bfeb758c1410c4d710a09260f915db7c5acce45d947ce29110d7d4fd92
getConfiguration
public ConfigFilterConfiguration getConfiguration(String name) throws ConfigurationException
{    if (this == OTHER) {        return new ConfigFilterConfiguration(name);    }    Class<? extends ConfigFilterConfiguration> clazz;    ConfigFilterConfiguration instance = null;    try {        if (configurationName != null) {            clazz = (Class<? extends ConfigFilterConfiguration>) Class.forName(configurationName);            instance = clazz.getConstructor(String.class).newInstance(name);        } else {            return new ConfigFilterConfiguration(name);        }    } catch (ClassNotFoundException e) {                instance = new ConfigFilterConfiguration(name);                instance.setNotFoundConfigClass();    } catch (Exception e) {        throw new ConfigurationException("Couldn't create configuration", e);    }    return instance;}
cfac927e2f01f3beaf1fd6e054846dfbf79b00c5682148da97865c5140e7327f
getClassName
public String getClassName()
{    return className;}
a5262a0a89842f15ecd68629542db5bc76a238ea01c7cd521c1d28c04af81369
create
public static ConfigFilter create(String name, String type) throws FlumeException
{    Preconditions.checkNotNull(name, "name");    Preconditions.checkNotNull(type, "type");    LOGGER.info("Creating instance of configfilter {}, type {}", name, type);    Class<? extends ConfigFilter> aClass = getClass(type);    try {        ConfigFilter configFilter = aClass.newInstance();        configFilter.setName(name);        return configFilter;    } catch (Exception ex) {        throw new FlumeException("Unable to create configfilter: " + name + ", type: " + type + ", class: " + aClass.getName(), ex);    }}
499a4d4cf6bf68626f5e4bd888b5ef777daa99f5f9661a958ecf3d78ad740604
getClass
public static Class<? extends ConfigFilter> getClass(String type) throws FlumeException
{    String classname = type;    ConfigFilterType srcType = ConfigFilterType.OTHER;    try {        srcType = ConfigFilterType.valueOf(type.toUpperCase(Locale.ENGLISH));    } catch (IllegalArgumentException ex) {        LOGGER.debug("Configfilter type {} is a custom type", type);    }    if (srcType != ConfigFilterType.OTHER) {        classname = srcType.getClassName();    }    try {        return (Class<? extends ConfigFilter>) Class.forName(classname);    } catch (Exception ex) {        throw new FlumeException("Unable to load configfilter type: " + type + ", class: " + classname, ex);    }}
a035295825480046fdf3d3c32baba0da5b1146a506cd88ac3e8c55d364e6c0aa
getConfigurationErrors
public List<FlumeConfigurationError> getConfigurationErrors()
{    return errors;}
f06ebbf5a577e49e263591c0817fa04888a0e4f4268f7448352f3c1f5772a5a0
getConfigurationFor
public AgentConfiguration getConfigurationFor(String hostname)
{    return agentConfigMap.get(hostname);}
ce37c18bcfcc800fd407d9a33a7e2fb33800846062baa4a25bbd6cca06e48348
validateConfiguration
private void validateConfiguration()
{    Set<Entry<String, AgentConfiguration>> entries = agentConfigMap.entrySet();    Iterator<Entry<String, AgentConfiguration>> it = entries.iterator();    while (it.hasNext()) {        Entry<String, AgentConfiguration> next = it.next();        String agentName = next.getKey();        AgentConfiguration aconf = next.getValue();        if (!aconf.isValid()) {            LOGGER.warn("Agent configuration invalid for agent '{}'. It will be removed.", agentName);            addError(agentName, AGENT_CONFIGURATION_INVALID, ERROR);            it.remove();        }        LOGGER.debug("Channels:{}\n", aconf.channels);        LOGGER.debug("Sinks {}\n", aconf.sinks);        LOGGER.debug("Sources {}\n", aconf.sources);    }    LOGGER.info("Post-validation flume configuration contains configuration for agents: {}", agentConfigMap.keySet());}
d37093c49f45fb7a556e2a0fbb612b16a54b4356f6fc3d471135349bf87df92a
addRawProperty
private boolean addRawProperty(String rawName, String rawValue)
{        if (rawName == null || rawValue == null) {        addError("", AGENT_NAME_MISSING, ERROR);        return false;    }        String name = rawName.trim();    String value = rawValue.trim();        if (value.isEmpty()) {        addError(name, PROPERTY_VALUE_NULL, ERROR);        return false;    }    int index = name.indexOf('.');        if (index == -1) {        addError(name, AGENT_NAME_MISSING, ERROR);        return false;    }    String agentName = name.substring(0, index);        if (agentName.isEmpty()) {        addError(name, AGENT_NAME_MISSING, ERROR);        return false;    }    String configKey = name.substring(index + 1);        if (configKey.isEmpty()) {        addError(name, PROPERTY_NAME_NULL, ERROR);        return false;    }    AgentConfiguration aconf = agentConfigMap.get(agentName);    if (aconf == null) {        aconf = new AgentConfiguration(agentName, errors);        agentConfigMap.put(agentName, aconf);    }        return aconf.addProperty(configKey, value);}
a23cc065f8b2c746267f6b01067927f75b1d2f60e784d81309bbeadf6e9ff6ae
addError
private void addError(String component, FlumeConfigurationErrorType errorType, ErrorOrWarning level)
{    errors.add(new FlumeConfigurationError(component, "", errorType, level));}
d9c277bb30cd09e5b96dfe7359e96795db40de147cda28213316b13f82140eab
getChannelConfigMap
public Map<String, ComponentConfiguration> getChannelConfigMap()
{    return channelConfigMap;}
2bcfdc26e061051f5f05642dd6e88703dd6a44f8a0c2cf1cd405cd152ea50a46
getSourceConfigMap
public Map<String, ComponentConfiguration> getSourceConfigMap()
{    return sourceConfigMap;}
785c9ea763739152326af75c9c23118a8cea239958cb5231b1aa304da895c50f
getConfigFilterConfigMap
public Map<String, ComponentConfiguration> getConfigFilterConfigMap()
{    return configFilterConfigMap;}
caac20e098a21a222a8fb7fb098689dadf606a7308a12d9772323c8981f448d2
getSinkConfigMap
public Map<String, ComponentConfiguration> getSinkConfigMap()
{    return sinkConfigMap;}
c14487113aab4281afae2a51395ceda764720955c1b3190ba6403d3bf6cbf36c
getSinkGroupConfigMap
public Map<String, ComponentConfiguration> getSinkGroupConfigMap()
{    return sinkgroupConfigMap;}
9b30851cba85f1a4de8fabcf72eaa18aec71f3c57aa6cd7a81f9dbe71aa6d338
getConfigFilterContext
public Map<String, Context> getConfigFilterContext()
{    return configFilterContextMap;}
025db0a522107e9f96f1a34f58aeb0cae2f7cb2e93e1fa5236ca1661887addf7
getSourceContext
public Map<String, Context> getSourceContext()
{    return sourceContextMap;}
7f723632c1e38e7da51558de3664bc2e3b631e99164eb1a889a14ebcd11e9ac9
getSinkContext
public Map<String, Context> getSinkContext()
{    return sinkContextMap;}
496b5c8266dde95d806e6eba2f704235c81b4c2c880198dd73425a7a9714fda6
getChannelContext
public Map<String, Context> getChannelContext()
{    return channelContextMap;}
8c37a9ccc5926e633fcf73a8c2d919aca5b0b7dc2382dd9693ca80202cc2bd96
getSinkSet
public Set<String> getSinkSet()
{    return sinkSet;}
7680e7287cfc20164b2e9d5ca1d04e6c69f5ea7035d4e5998a44f9ea090bd00d
getConfigFilterSet
public Set<String> getConfigFilterSet()
{    return configFilterSet;}
c86480b2bbfdc4473fa1ee5f9fd799199f4331c9f198f2da34e43f90e5dd1f50
getSourceSet
public Set<String> getSourceSet()
{    return sourceSet;}
b7d64bc3de11f0a5bbd4e391c5a6cbc56d48cc417afa0bba48fb59980575cabf
getChannelSet
public Set<String> getChannelSet()
{    return channelSet;}
b0d59fa94314755263e8b9b49db51e65c572ee83ed05206664ba8e3a0c630ca7
getSinkgroupSet
public Set<String> getSinkgroupSet()
{    return sinkgroupSet;}
712e82c8f36f7cef7dbb9dd0bc7b096319029c6a3d723c8416dd3846bfe40cef
isValid
private boolean isValid()
{    LOGGER.debug("Starting validation of configuration for agent: {}", agentName);    if (LOGGER.isDebugEnabled() && LogPrivacyUtil.allowLogPrintConfig()) {        LOGGER.debug("Initial configuration: {}", getPrevalidationConfig());    }    configFilterSet = validateConfigFilterSet();    createConfigFilters();    runFiltersThroughConfigs();        if (channels == null || channels.trim().isEmpty()) {        LOGGER.warn("Agent configuration for '{}' does not contain any channels. Marking it as invalid.", agentName);        addError(CONFIG_CHANNELS, PROPERTY_VALUE_NULL, ERROR);        return false;    }    channelSet = new HashSet<>(Arrays.asList(channels.split("\\s+")));    channelSet = validateChannels(channelSet);    if (channelSet.isEmpty()) {        LOGGER.warn("Agent configuration for '{}' does not contain any valid channels. " + "Marking it as invalid.", agentName);        addError(CONFIG_CHANNELS, PROPERTY_VALUE_NULL, ERROR);        return false;    }    sourceSet = validateSources(channelSet);    sinkSet = validateSinks(channelSet);    sinkgroupSet = validateGroups(sinkSet);        if (sourceSet.isEmpty() && sinkSet.isEmpty()) {        LOGGER.warn("Agent configuration for '{}' has no sources or sinks. Will be marked invalid.", agentName);        addError(CONFIG_SOURCES, PROPERTY_VALUE_NULL, ERROR);        addError(CONFIG_SINKS, PROPERTY_VALUE_NULL, ERROR);        return false;    }        this.configFilters = getSpaceDelimitedList(configFilterSet);    sources = getSpaceDelimitedList(sourceSet);    channels = getSpaceDelimitedList(channelSet);    sinks = getSpaceDelimitedList(sinkSet);    sinkgroups = getSpaceDelimitedList(sinkgroupSet);    if (LOGGER.isDebugEnabled() && LogPrivacyUtil.allowLogPrintConfig()) {        LOGGER.debug("Post validation configuration for {}", agentName);        LOGGER.debug(getPostvalidationConfig());    }    return true;}
16619ae3f41aa462d2bde0ebae9517a99a5e90c795709ff3144b3982680fef82
runFiltersThroughConfigs
private void runFiltersThroughConfigs()
{    runFiltersOnContextMaps(sourceContextMap, channelContextMap, sinkContextMap, sinkGroupContextMap);}
40b662dd69c719e58d4cc16c9cd5ef7094f5d99f3beabeea84423e7da338c927
runFiltersOnContextMaps
private void runFiltersOnContextMaps(Map<String, Context>... maps)
{    for (Map<String, Context> map : maps) {        for (Context context : map.values()) {            for (String key : context.getParameters().keySet()) {                filterValue(context, key);            }        }    }}
83bf4179dc76368aeb018b1432dffaccbc98954c4e67acd88c7525e567255858
createConfigFilters
private void createConfigFilters()
{    for (String name : configFilterSet) {        Context context = configFilterContextMap.get(name);        ComponentConfiguration componentConfiguration = configFilterConfigMap.get(name);        try {            if (context != null) {                ConfigFilter configFilter = ConfigFilterFactory.create(name, context.getString(BasicConfigurationConstants.CONFIG_TYPE));                configFilter.initializeWithConfiguration(context.getParameters());                configFiltersInstances.add(configFilter);                configFilterPatternCache.put(configFilter.getName(), createConfigFilterPattern(configFilter));            } else if (componentConfiguration != null) {                ConfigFilter configFilter = ConfigFilterFactory.create(componentConfiguration.getComponentName(), componentConfiguration.getType());                configFiltersInstances.add(configFilter);                configFilterPatternCache.put(configFilter.getName(), createConfigFilterPattern(configFilter));            }        } catch (Exception e) {            LOGGER.error("Error while creating config filter {}", name, e);        }    }}
d8d9108dfe82682b51fbbd2f3f86223cd28ff95060e9a12c8c33afa35793f0a9
createConfigFilterPattern
private Pattern createConfigFilterPattern(ConfigFilter configFilter)
{        return Pattern.compile(    "\\$\\{" +     Pattern.quote(configFilter.getName()) +     "\\[(|'|\")" +     "(?<key>[-_a-zA-Z0-9]+)" +     "\\1\\]" +     "\\}");}
113a7074419f0e806fc05d3e54ade148844bb944ef2039e52598bf50488f96e0
filterValue
private void filterValue(Context c, String contextKey)
{    for (ConfigFilter configFilter : configFiltersInstances) {        try {            Pattern pattern = configFilterPatternCache.get(configFilter.getName());            String currentValue = c.getString(contextKey);            Matcher matcher = pattern.matcher(currentValue);            String filteredValue = currentValue;            while (matcher.find()) {                String key = matcher.group("key");                LOGGER.debug("Replacing {} from config filter {}", key, configFilter.getName());                String filtered = configFilter.filter(key);                if (filtered == null) {                    continue;                }                String fullMatch = matcher.group();                filteredValue = filteredValue.replace(fullMatch, filtered);            }            c.put(contextKey, filteredValue);        } catch (Exception e) {            e.printStackTrace();            LOGGER.error("Error while matching and filtering configFilter: {} and key: {}", new Object[] { configFilter.getName(), contextKey, e });        }    }}
faaa6696bdc6483c06e9147fe795441ae0547de1b1369840d4e18ac9152b0db7
addError
private void addError(String key, FlumeConfigurationErrorType errorType, ErrorOrWarning level)
{    errorList.add(new FlumeConfigurationError(agentName, key, errorType, level));}
9305e2c1a4aea4e557126cff87a4ce5166ab83498a5a1b1d2197d7cabaf035dd
getKnownChannel
private ChannelType getKnownChannel(String type)
{    return getKnownComponent(type, ChannelType.values());}
9bc293aae2e7b37120544e6c4ba7a8e48ccacfd3af22c65c42a051e7f1edc619
getKnownSink
private SinkType getKnownSink(String type)
{    return getKnownComponent(type, SinkType.values());}
dd8d7dca1fdc9b5aaa3956533f3e4ef148752c7a245f17d637b21bc99c550162
getKnownSource
private SourceType getKnownSource(String type)
{    return getKnownComponent(type, SourceType.values());}
7b503c7b461522ff117dde08002061e1c495c1ff796d51c41ffd956995c77e06
getKnownConfigFilter
private ConfigFilterType getKnownConfigFilter(String type)
{    return getKnownComponent(type, ConfigFilterType.values());}
e5410d27eee13f2506632c67ad4617bc67ed266fc9316351c7afdfd3a3d426f6
getKnownComponent
private T getKnownComponent(String type, T[] values)
{    for (T value : values) {        if (value.toString().equalsIgnoreCase(type))            return value;        String src = value.getClassName();        if (src != null && src.equalsIgnoreCase(type))            return value;    }    return null;}
bddbdc77e63da958c85440fc0cb7585f66734da88d88a67d0147738fb6d4f9fc
validateChannels
private Set<String> validateChannels(Set<String> channelSet)
{    Iterator<String> iter = channelSet.iterator();    Map<String, Context> newContextMap = new HashMap<>();    ChannelConfiguration conf = null;    /*       * The logic for the following code:       *       * Is it a known component?       *  -Yes: Get the ChannelType and set the string name of that to       *        config and set configSpecified to true.       *  -No.Look for config type for the given component:       *      -Config Found:       *        Set config to the type mentioned, set configSpecified to true       *      -No Config found:       *        Set config to OTHER, configSpecified to false,       *        do basic validation. Leave the context in the       *        contextMap to process later. Setting it to other returns       *        a vanilla configuration(Source/Sink/Channel Configuration),       *        which does basic syntactic validation. This object is not       *        put into the map, so the context is retained which can be       *        picked up - this is meant for older classes which don't       *        implement ConfigurableComponent.       */    while (iter.hasNext()) {        String channelName = iter.next();        Context channelContext = channelContextMap.get(channelName);                if (channelContext != null) {                        ChannelType chType = getKnownChannel(channelContext.getString(BasicConfigurationConstants.CONFIG_TYPE));            boolean configSpecified = false;            String config = null;                        if (chType == null) {                config = channelContext.getString(CONFIG_CONFIG);                if (config == null || config.isEmpty()) {                    config = "OTHER";                } else {                    configSpecified = true;                }            } else {                config = chType.toString().toUpperCase(Locale.ENGLISH);                configSpecified = true;            }            try {                conf = (ChannelConfiguration) ComponentConfigurationFactory.create(channelName, config, ComponentType.CHANNEL);                LOGGER.debug("Created channel {}", channelName);                if (conf != null) {                    conf.configure(channelContext);                }                if ((configSpecified && conf.isNotFoundConfigClass()) || !configSpecified) {                    newContextMap.put(channelName, channelContext);                } else if (configSpecified) {                    channelConfigMap.put(channelName, conf);                }                if (conf != null) {                    errorList.addAll(conf.getErrors());                }            } catch (ConfigurationException e) {                                if (conf != null)                    errorList.addAll(conf.getErrors());                iter.remove();                LOGGER.warn("Could not configure channel {} due to: {}", new Object[] { channelName, e.getMessage(), e });            }        } else {            iter.remove();            addError(channelName, CONFIG_ERROR, ERROR);        }    }    channelContextMap = newContextMap;    Set<String> tempchannelSet = new HashSet<String>();    tempchannelSet.addAll(channelConfigMap.keySet());    tempchannelSet.addAll(channelContextMap.keySet());    channelSet.retainAll(tempchannelSet);    return channelSet;}
88cc076d4d620544da94b8dcd632a9e00ac8adf20e86d1615327d8881f18497b
validateConfigFilterSet
private Set<String> validateConfigFilterSet()
{    if (configFilters == null || configFilters.isEmpty()) {        LOGGER.warn("Agent configuration for '{}' has no configfilters.", agentName);        return new HashSet<>();    }    Set<String> configFilterSet = new HashSet<>(Arrays.asList(configFilters.split("\\s+")));    Map<String, Context> newContextMap = new HashMap<>();    Iterator<String> iter = configFilterSet.iterator();    ConfigFilterConfiguration conf = null;    while (iter.hasNext()) {        String configFilterName = iter.next();        Context configFilterContext = configFilterContextMap.get(configFilterName);        if (configFilterContext != null) {                        ConfigFilterType chType = getKnownConfigFilter(configFilterContext.getString(BasicConfigurationConstants.CONFIG_TYPE));            boolean configSpecified = false;            String config = null;                        if (chType == null) {                config = configFilterContext.getString(CONFIG_CONFIG);                if (config == null || config.isEmpty()) {                    config = "OTHER";                } else {                    configSpecified = true;                }            } else {                config = chType.toString().toUpperCase(Locale.ENGLISH);                configSpecified = true;            }            try {                conf = (ConfigFilterConfiguration) ComponentConfigurationFactory.create(configFilterName, config, ComponentType.CONFIG_FILTER);                LOGGER.debug("Created configfilter {}", configFilterName);                if (conf != null) {                    conf.configure(configFilterContext);                }                if ((configSpecified && conf.isNotFoundConfigClass()) || !configSpecified) {                    newContextMap.put(configFilterName, configFilterContext);                } else if (configSpecified) {                    configFilterConfigMap.put(configFilterName, conf);                }                if (conf != null) {                    errorList.addAll(conf.getErrors());                }            } catch (ConfigurationException e) {                if (conf != null)                    errorList.addAll(conf.getErrors());                iter.remove();                LOGGER.warn("Could not configure configfilter {} due to: {}", new Object[] { configFilterName, e.getMessage(), e });            }        } else {            iter.remove();            addError(configFilterName, CONFIG_ERROR, ERROR);            LOGGER.warn("Configuration empty for: {}. Removed.", configFilterName);        }    }    configFilterContextMap = newContextMap;    Set<String> tempchannelSet = new HashSet<String>();    tempchannelSet.addAll(configFilterConfigMap.keySet());    tempchannelSet.addAll(configFilterContextMap.keySet());    configFilterSet.retainAll(tempchannelSet);    return configFilterSet;}
5ffdab9e0d109bf221f66fd6c5500f721a6ff2bb7d10e04385850057a064dd3e
validateSources
private Set<String> validateSources(Set<String> channelSet)
{        if (sources == null || sources.isEmpty()) {        LOGGER.warn("Agent configuration for '{}' has no sources.", agentName);        addError(CONFIG_SOURCES, PROPERTY_VALUE_NULL, WARNING);        return new HashSet<String>();    }    Set<String> sourceSet = new HashSet<String>(Arrays.asList(sources.split("\\s+")));    Map<String, Context> newContextMap = new HashMap<String, Context>();    Iterator<String> iter = sourceSet.iterator();    SourceConfiguration srcConf = null;    /*       * The logic for the following code:       *       * Is it a known component?       *  -Yes: Get the SourceType and set the string name of that to       *        config and set configSpecified to true.       *  -No.Look for config type for the given component:       *      -Config Found:       *        Set config to the type mentioned, set configSpecified to true       *      -No Config found:       *        Set config to OTHER, configSpecified to false,       *        do basic validation. Leave the context in the       *        contextMap to process later. Setting it to other returns       *        a vanilla configuration(Source/Sink/Channel Configuration),       *        which does basic syntactic validation. This object is not       *        put into the map, so the context is retained which can be       *        picked up - this is meant for older classes which don't       *        implement ConfigurableComponent.       */    while (iter.hasNext()) {        String sourceName = iter.next();        Context srcContext = sourceContextMap.get(sourceName);        String config = null;        boolean configSpecified = false;        if (srcContext != null) {            SourceType srcType = getKnownSource(srcContext.getString(BasicConfigurationConstants.CONFIG_TYPE));            if (srcType == null) {                config = srcContext.getString(CONFIG_CONFIG);                if (config == null || config.isEmpty()) {                    config = "OTHER";                } else {                    configSpecified = true;                }            } else {                config = srcType.toString().toUpperCase(Locale.ENGLISH);                configSpecified = true;            }            try {                                                srcConf = (SourceConfiguration) ComponentConfigurationFactory.create(sourceName, config, ComponentType.SOURCE);                if (srcConf != null) {                    srcConf.configure(srcContext);                    Set<String> channels = new HashSet<String>();                    if (srcConf.getChannels() != null) {                        channels.addAll(srcConf.getChannels());                    }                    channels.retainAll(channelSet);                    if (channels.isEmpty()) {                        throw new ConfigurationException("No Channels configured for " + sourceName);                    }                    srcContext.put(CONFIG_CHANNELS, this.getSpaceDelimitedList(channels));                }                if ((configSpecified && srcConf.isNotFoundConfigClass()) || !configSpecified) {                    newContextMap.put(sourceName, srcContext);                } else if (configSpecified) {                    sourceConfigMap.put(sourceName, srcConf);                }                if (srcConf != null)                    errorList.addAll(srcConf.getErrors());            } catch (ConfigurationException e) {                if (srcConf != null)                    errorList.addAll(srcConf.getErrors());                iter.remove();                LOGGER.warn("Could not configure source  {} due to: {}", new Object[] { sourceName, e.getMessage(), e });            }        } else {            iter.remove();            addError(sourceName, CONFIG_ERROR, ERROR);            LOGGER.warn("Configuration empty for: {}.Removed.", sourceName);        }    }            sourceContextMap = newContextMap;    Set<String> tempsourceSet = new HashSet<String>();    tempsourceSet.addAll(sourceContextMap.keySet());    tempsourceSet.addAll(sourceConfigMap.keySet());    sourceSet.retainAll(tempsourceSet);    return sourceSet;}
85c2c4cd4c50a3e7b73fb6ff911543e22b2b5199694a2830defc0cd51467a8c2
validateSinks
private Set<String> validateSinks(Set<String> channelSet)
{            Map<String, Context> newContextMap = new HashMap<String, Context>();    Set<String> sinkSet;    SinkConfiguration sinkConf = null;    if (sinks == null || sinks.isEmpty()) {        LOGGER.warn("Agent configuration for '{}' has no sinks.", agentName);        addError(CONFIG_SINKS, PROPERTY_VALUE_NULL, WARNING);        return new HashSet<String>();    } else {        sinkSet = new HashSet<String>(Arrays.asList(sinks.split("\\s+")));    }    Iterator<String> iter = sinkSet.iterator();    /*       * The logic for the following code:       *       * Is it a known component?       *  -Yes: Get the SinkType and set the string name of that to       *        config and set configSpecified to true.       *  -No.Look for config type for the given component:       *      -Config Found:       *        Set config to the type mentioned, set configSpecified to true       *      -No Config found:       *        Set config to OTHER, configSpecified to false,       *        do basic validation. Leave the context in the       *        contextMap to process later. Setting it to other returns       *        a vanilla configuration(Source/Sink/Channel Configuration),       *        which does basic syntactic validation. This object is not       *        put into the map, so the context is retained which can be       *        picked up - this is meant for older classes which don't       *        implement ConfigurableComponent.       */    while (iter.hasNext()) {        String sinkName = iter.next();        Context sinkContext = sinkContextMap.get(sinkName.trim());        if (sinkContext == null) {            iter.remove();            LOGGER.warn("no context for sink{}", sinkName);            addError(sinkName, CONFIG_ERROR, ERROR);        } else {            String config = null;            boolean configSpecified = false;            SinkType sinkType = getKnownSink(sinkContext.getString(BasicConfigurationConstants.CONFIG_TYPE));            if (sinkType == null) {                config = sinkContext.getString(CONFIG_CONFIG);                if (config == null || config.isEmpty()) {                    config = "OTHER";                } else {                    configSpecified = true;                }            } else {                config = sinkType.toString().toUpperCase(Locale.ENGLISH);                configSpecified = true;            }            try {                LOGGER.debug("Creating sink: {} using {}", sinkName, config);                sinkConf = (SinkConfiguration) ComponentConfigurationFactory.create(sinkName, config, ComponentType.SINK);                if (sinkConf != null) {                    sinkConf.configure(sinkContext);                }                if (!channelSet.contains(sinkConf.getChannel())) {                    throw new ConfigurationException("Channel " + sinkConf.getChannel() + " not in active set.");                }                if ((configSpecified && sinkConf.isNotFoundConfigClass()) || !configSpecified) {                    newContextMap.put(sinkName, sinkContext);                } else if (configSpecified) {                    sinkConfigMap.put(sinkName, sinkConf);                }                if (sinkConf != null)                    errorList.addAll(sinkConf.getErrors());            } catch (ConfigurationException e) {                iter.remove();                if (sinkConf != null)                    errorList.addAll(sinkConf.getErrors());                LOGGER.warn("Could not configure sink  {} due to: {}", new Object[] { sinkName, e.getMessage(), e });            }        }        }    sinkContextMap = newContextMap;    Set<String> tempSinkset = new HashSet<String>();    tempSinkset.addAll(sinkConfigMap.keySet());    tempSinkset.addAll(sinkContextMap.keySet());    sinkSet.retainAll(tempSinkset);    return sinkSet;}
1cd36e733990f8af813d6dd8f842a7876b5055526dea5460437597d38e7e39a0
validateGroups
private Set<String> validateGroups(Set<String> sinkSet)
{    Set<String> sinkgroupSet = stringToSet(sinkgroups, " ");    Map<String, String> usedSinks = new HashMap<String, String>();    Iterator<String> iter = sinkgroupSet.iterator();    SinkGroupConfiguration conf;    while (iter.hasNext()) {        String sinkgroupName = iter.next();        Context context = this.sinkGroupContextMap.get(sinkgroupName);        if (context != null) {            try {                conf = (SinkGroupConfiguration) ComponentConfigurationFactory.create(sinkgroupName, "sinkgroup", ComponentType.SINKGROUP);                conf.configure(context);                Set<String> groupSinks = validGroupSinks(sinkSet, usedSinks, conf);                if (conf != null)                    errorList.addAll(conf.getErrors());                if (groupSinks != null && !groupSinks.isEmpty()) {                    List<String> sinkArray = new ArrayList<String>();                    sinkArray.addAll(groupSinks);                    conf.setSinks(sinkArray);                    sinkgroupConfigMap.put(sinkgroupName, conf);                } else {                    addError(sinkgroupName, CONFIG_ERROR, ERROR);                    if (conf != null)                        errorList.addAll(conf.getErrors());                    throw new ConfigurationException("No available sinks for sinkgroup: " + sinkgroupName + ". Sinkgroup will be removed");                }            } catch (ConfigurationException e) {                iter.remove();                addError(sinkgroupName, CONFIG_ERROR, ERROR);                LOGGER.warn("Could not configure sink group {} due to: {}", new Object[] { sinkgroupName, e.getMessage(), e });            }        } else {            iter.remove();            addError(sinkgroupName, CONFIG_ERROR, ERROR);            LOGGER.warn("Configuration error for: {}.Removed.", sinkgroupName);        }    }    sinkgroupSet.retainAll(sinkgroupConfigMap.keySet());    return sinkgroupSet;}
60a2259dfdaf26d81f57fd3a17d1a46d40de1549e1c23afba65e5f05ad071a2c
validGroupSinks
private Set<String> validGroupSinks(Set<String> sinkSet, Map<String, String> usedSinks, SinkGroupConfiguration groupConf)
{    Set<String> groupSinks = Collections.synchronizedSet(new HashSet<String>(groupConf.getSinks()));    if (groupSinks.isEmpty())        return null;    Iterator<String> sinkIt = groupSinks.iterator();    while (sinkIt.hasNext()) {        String curSink = sinkIt.next();        if (usedSinks.containsKey(curSink)) {            LOGGER.warn("Agent configuration for '{}' sinkgroup '{}' sink '{}' in use by another group: " + "'{}', sink not added", new Object[] { agentName, groupConf.getComponentName(), curSink, usedSinks.get(curSink) });            addError(groupConf.getComponentName(), PROPERTY_PART_OF_ANOTHER_GROUP, ERROR);            sinkIt.remove();            continue;        } else if (!sinkSet.contains(curSink)) {            LOGGER.warn("Agent configuration for '{}' sinkgroup '{}' sink not found: '{}', " + " sink not added", new Object[] { agentName, groupConf.getComponentName(), curSink });            addError(curSink, INVALID_PROPERTY, ERROR);            sinkIt.remove();            continue;        } else {            usedSinks.put(curSink, groupConf.getComponentName());        }    }    return groupSinks;}
0d10a2e8e32e9224113d6508c12cb31c730cbd18108369b14feee5546e4d54c9
getSpaceDelimitedList
private String getSpaceDelimitedList(Set<String> entries)
{    if (entries.isEmpty()) {        return null;    }    StringBuilder sb = new StringBuilder();    for (String entry : entries) {        sb.append(" ").append(entry);    }    return sb.toString().trim();}
15f82a1e21dcf44adb7af38cb7e32b44c7738abd3d09e0cec929fcabdf8a01af
stringToSet
private static Set<String> stringToSet(String target, String delim)
{    Set<String> out = new HashSet<String>();    if (target == null || target.trim().length() == 0) {        return out;    }    StringTokenizer t = new StringTokenizer(target, delim);    while (t.hasMoreTokens()) {        out.add(t.nextToken());    }    return out;}
98597dbadaaf5a7de245452527b1101546d74efb91fbeee886d58d41bc5ff9c3
getPrevalidationConfig
public String getPrevalidationConfig()
{    StringBuilder sb = new StringBuilder("AgentConfiguration[");    sb.append(agentName).append("]").append(NEWLINE);    sb.append("CONFIG_FILTERS: ").append(configFilterContextMap).append(NEWLINE);    sb.append("SOURCES: ").append(sourceContextMap).append(NEWLINE);    sb.append("CHANNELS: ").append(channelContextMap).append(NEWLINE);    sb.append("SINKS: ").append(sinkContextMap).append(NEWLINE);    return sb.toString();}
a047ba7d0f0335566eaad12a812d199f92e814073558bc970e50922afe0b6177
getPostvalidationConfig
public String getPostvalidationConfig()
{    StringBuilder sb = new StringBuilder("AgentConfiguration created without Configuration stubs " + "for which only basic syntactical validation was performed[");    sb.append(agentName).append("]").append(NEWLINE);    if (!sourceContextMap.isEmpty() || !sinkContextMap.isEmpty() || !channelContextMap.isEmpty()) {        if (!sourceContextMap.isEmpty()) {            sb.append("SOURCES: ").append(sourceContextMap).append(NEWLINE);        }        if (!channelContextMap.isEmpty()) {            sb.append("CHANNELS: ").append(channelContextMap).append(NEWLINE);        }        if (!sinkContextMap.isEmpty()) {            sb.append("SINKS: ").append(sinkContextMap).append(NEWLINE);        }    }    if (!sourceConfigMap.isEmpty() || !sinkConfigMap.isEmpty() || !channelConfigMap.isEmpty()) {        sb.append("AgentConfiguration created with Configuration stubs " + "for which full validation was performed[");        sb.append(agentName).append("]").append(NEWLINE);        if (!sourceConfigMap.isEmpty()) {            sb.append("SOURCES: ").append(sourceConfigMap).append(NEWLINE);        }        if (!channelConfigMap.isEmpty()) {            sb.append("CHANNELS: ").append(channelConfigMap).append(NEWLINE);        }        if (!sinkConfigMap.isEmpty()) {            sb.append("SINKS: ").append(sinkConfigMap).append(NEWLINE);        }    }    return sb.toString();}
b1fd9a26d90b2fcf6ddf8eda7858190b70393e6b0df650ce82cf954f006bbe4c
addProperty
private boolean addProperty(String key, String value)
{        if (CONFIG_CONFIGFILTERS.equals(key)) {        if (configFilters == null) {            configFilters = value;            return true;        } else {            LOGGER.warn("Duplicate configfilter list specified for agent: {}", agentName);            addError(CONFIG_CONFIGFILTERS, DUPLICATE_PROPERTY, ERROR);            return false;        }    }        if (CONFIG_SOURCES.equals(key)) {        if (sources == null) {            sources = value;            return true;        } else {            LOGGER.warn("Duplicate source list specified for agent: {}", agentName);            addError(CONFIG_SOURCES, DUPLICATE_PROPERTY, ERROR);            return false;        }    }        if (CONFIG_SINKS.equals(key)) {        if (sinks == null) {            sinks = value;            LOGGER.info("Added sinks: {} Agent: {}", sinks, agentName);            return true;        } else {            LOGGER.warn("Duplicate sink list specfied for agent: {}", agentName);            addError(CONFIG_SINKS, DUPLICATE_PROPERTY, ERROR);            return false;        }    }        if (CONFIG_CHANNELS.equals(key)) {        if (channels == null) {            channels = value;            return true;        } else {            LOGGER.warn("Duplicate channel list specified for agent: {}", agentName);            addError(CONFIG_CHANNELS, DUPLICATE_PROPERTY, ERROR);            return false;        }    }        if (CONFIG_SINKGROUPS.equals(key)) {        if (sinkgroups == null) {            sinkgroups = value;            return true;        } else {            LOGGER.warn("Duplicate sinkgroup list specfied for agent: {}", agentName);            addError(CONFIG_SINKGROUPS, DUPLICATE_PROPERTY, ERROR);            return false;        }    }    if (addAsSourceConfig(key, value) || addAsChannelValue(key, value) || addAsSinkConfig(key, value) || addAsSinkGroupConfig(key, value) || addAsConfigFilterConfig(key, value)) {        return true;    }    LOGGER.warn("Invalid property specified: {}", key);    addError(key, INVALID_PROPERTY, ERROR);    return false;}
ebd48e3b13792146c52e7cc0fed882b849bd75256c519c5baf145585010cc6c9
addAsConfigFilterConfig
private boolean addAsConfigFilterConfig(String key, String value)
{    return addComponentConfig(key, value, CONFIG_CONFIGFILTERS_PREFIX, configFilterContextMap);}
70c6d4ed76672208e51ce13b4247977f656f1bddb3b4de6595ccdbe13668cc41
addAsSinkGroupConfig
private boolean addAsSinkGroupConfig(String key, String value)
{    return addComponentConfig(key, value, CONFIG_SINKGROUPS_PREFIX, sinkGroupContextMap);}
c17e332f67ac6e6e958cae0111bbf81bb843f5fd7c4f9e54e00219ff2f81120d
addAsSinkConfig
private boolean addAsSinkConfig(String key, String value)
{    return addComponentConfig(key, value, CONFIG_SINKS_PREFIX, sinkContextMap);}
1657d2323f3a34581ec42e9d77fe6e1ced69d9490841e4bb39dce6e81ef11161
addAsChannelValue
private boolean addAsChannelValue(String key, String value)
{    return addComponentConfig(key, value, CONFIG_CHANNELS_PREFIX, channelContextMap);}
ce315e66baa70f0352dacb0442e3035f0758ca98dcf7db5b4c7d31f59e0cd69a
addAsSourceConfig
private boolean addAsSourceConfig(String key, String value)
{    return addComponentConfig(key, value, CONFIG_SOURCES_PREFIX, sourceContextMap);}
056ef18ca6b9a850bbc619e514dbac018f7d13c993296e43f64796c175cc9cf2
addComponentConfig
private boolean addComponentConfig(String key, String value, String configPrefix, Map<String, Context> contextMap)
{    ComponentNameAndConfigKey parsed = parseConfigKey(key, configPrefix);    if (parsed != null) {        String name = parsed.getComponentName().trim();        LOGGER.info("Processing:{}", name);        Context context = contextMap.get(name);        if (context == null) {            LOGGER.debug("Created context for {}: {}", name, parsed.getConfigKey());            context = new Context();            contextMap.put(name, context);        }        context.put(parsed.getConfigKey(), value);        return true;    }    return false;}
e093b7f533b7b4f4c04ca9cbcfa413d0965d8a92ee7cbaa272d60a6cb95c3a96
parseConfigKey
private ComponentNameAndConfigKey parseConfigKey(String key, String prefix)
{        if (!key.startsWith(prefix)) {        return null;    }            int index = key.indexOf('.', prefix.length() + 1);    if (index == -1) {        return null;    }    String name = key.substring(prefix.length(), index);    String configKey = key.substring(prefix.length() + name.length() + 1);        if (name.isEmpty() || configKey.isEmpty()) {        return null;    }    return new ComponentNameAndConfigKey(name, configKey);}
f3582dedc5a60972387514c1a69a3aeba1621c63b1cd72b1e7cd4b550a63667e
getComponentName
public String getComponentName()
{    return componentName;}
57e9dfc77ce30bbec8603b30b2fdaffe5bbdcd4662e950a76532cf441a968fb3
getConfigKey
public String getConfigKey()
{    return configKey;}
f3582dedc5a60972387514c1a69a3aeba1621c63b1cd72b1e7cd4b550a63667e
getComponentName
public String getComponentName()
{    return componentName;}
71dcee8caa732fdfbbc9042fbd951dc9dfd911ed9a4cabf0966856ac5de53dfc
getKey
public String getKey()
{    return key;}
c992ba8336d449288b16eaa014e491d6d3397fa5851d64861674891424eeb148
getErrorType
public FlumeConfigurationErrorType getErrorType()
{    return errorType;}
764cb8c69dae71cd98a85ff7ec4577cdc2a7b4c8ceddaac0d3440d767b4e5b6e
getErrorOrWarning
public ErrorOrWarning getErrorOrWarning()
{    return error;}
735d2bd2d31b5695cc6801e48a1e2b92cd0a4cc38870ad4f31df08f8a70419a7
getError
public String getError()
{    return error;}
824c85504f31c143c756a1713518f60d7c0bf0c7531c34e59b4e4ca952e93df0
allowLogRawData
public static boolean allowLogRawData()
{    return Boolean.getBoolean(LOG_RAWDATA_PROP);}
7dcaa2b6728d85947ae5e9e7ec7599b9e04021e4b421683fd8229740342be6b6
allowLogPrintConfig
public static boolean allowLogPrintConfig()
{    return Boolean.getBoolean(LOG_PRINTCONFIG_PROP);}
190e6762112b434704596a6c1097fd091aa8aab4a3d6b99b5987df2bbaf2443f
getChannel
public String getChannel()
{    return channel;}
b512e1db952c963511259db2a2f852b682acbab938af4709cd53dc52673be86a
getChannel
public void getChannel(String channel)
{    this.channel = channel;}
fa47897acd081345080fc68c9f58ae17a63581f7e2187e4637955118b04f027a
configure
public void configure(Context context) throws ConfigurationException
{    super.configure(context);    this.channel = context.getString("channel");    if (this.channel == null || this.channel.isEmpty()) {        errors.add(new FlumeConfigurationError(componentName, "channel", FlumeConfigurationErrorType.PROPERTY_VALUE_NULL, ErrorOrWarning.ERROR));        throw new ConfigurationException("No channel configured for sink: " + this.getComponentName());    }}
167f366474d3fcb23d30207cfbde726d2c37216fc3b740b30da36e6d0530ff92
toString
public String toString(int indentCount)
{    String basicStr = super.toString(indentCount);    StringBuilder sb = new StringBuilder();    sb.append(basicStr).append(FlumeConfiguration.INDENTSTEP).append("CHANNEL:").append(this.channel).append(FlumeConfiguration.NEWLINE);    return sb.toString();}
f67344b55a7fe32754daa9f740e08a21cd931200369062511866fe8a782242e3
getSinkConfigurationType
public String getSinkConfigurationType()
{    return this.sinkConfigurationName;}
a67fca4252ea25cd2081b8523f8733a0e79612053c23211516b4cd4d49d2d642
getConfiguration
public SinkConfiguration getConfiguration(String name) throws ConfigurationException
{    if (this == OTHER) {        return new SinkConfiguration(name);    }    Class<? extends SinkConfiguration> clazz;    SinkConfiguration instance = null;    try {        if (sinkConfigurationName != null) {            clazz = (Class<? extends SinkConfiguration>) Class.forName(sinkConfigurationName);            instance = clazz.getConstructor(String.class).newInstance(name);        } else {            return new SinkConfiguration(name);        }    } catch (ClassNotFoundException e) {                instance = new SinkConfiguration(name);                instance.setNotFoundConfigClass();    } catch (Exception e) {        throw new ConfigurationException("Couldn't create configuration", e);    }    return instance;}
8dac8f7690a058a24ba9a04df42400f6df39b1e1021fffa7b272c26223763b7b
setSinks
public void setSinks(List<String> sinks)
{    this.sinks = sinks;}
58d8cbd53650c41e936a90ad904914810b6416166b414bdd7a84a721705df47e
getSinks
public List<String> getSinks()
{    return sinks;}
fa47897acd081345080fc68c9f58ae17a63581f7e2187e4637955118b04f027a
configure
public void configure(Context context) throws ConfigurationException
{    super.configure(context);    sinks = Arrays.asList(context.getString(BasicConfigurationConstants.CONFIG_SINKS).split("\\s+"));    Map<String, String> params = context.getSubProperties(BasicConfigurationConstants.CONFIG_SINK_PROCESSOR_PREFIX);    processorContext = new Context();    processorContext.putAll(params);    SinkProcessorType spType = getKnownSinkProcessor(processorContext.getString(BasicConfigurationConstants.CONFIG_TYPE));    if (spType != null) {        processorConf = (SinkProcessorConfiguration) ComponentConfigurationFactory.create(this.getComponentName() + "-processor", spType.toString(), ComponentType.SINK_PROCESSOR);        if (processorConf != null) {            processorConf.setSinks(new HashSet<String>(sinks));            processorConf.configure(processorContext);        }    }    setConfigured();}
3df3ea64af481bf37e5a287996857c74cdfafecc0e245c2144b5213a5c4eed42
getProcessorContext
public Context getProcessorContext()
{    return processorContext;}
11f74d236ab9e9e19c165bf2858989e9ce655076b298d1e6ae9928a4fedeab25
setProcessorContext
public void setProcessorContext(Context processorContext)
{    this.processorContext = processorContext;}
6f5f791b87a6aebac32e2064507ec832656bd9499460c39ffb6266f21bd6c102
getSinkProcessorConfiguration
public SinkProcessorConfiguration getSinkProcessorConfiguration()
{    return processorConf;}
22728653d77090f48962544cbaee58bf1fc56d7c1d3042aac700dcc53438d0b7
setSinkProcessorConfiguration
public void setSinkProcessorConfiguration(SinkProcessorConfiguration conf)
{    this.processorConf = conf;}
6a6ee216faf17a1e13d78fc7a187f7b9d29ca7351ba595a51e40a3e646a9732b
getKnownSinkProcessor
private SinkProcessorType getKnownSinkProcessor(String type)
{    SinkProcessorType[] values = SinkProcessorType.values();    for (SinkProcessorType value : values) {        if (value.toString().equalsIgnoreCase(type))            return value;        String sinkProcessClassName = value.getClassName();        if (sinkProcessClassName != null && sinkProcessClassName.equalsIgnoreCase(type)) {            return value;        }    }    return null;}
fa47897acd081345080fc68c9f58ae17a63581f7e2187e4637955118b04f027a
configure
public void configure(Context context) throws ConfigurationException
{}
61e277a3b4a0efc6dbe0a97d8efe050cb1c34a8c8202ca33b063d893b0532f7c
getSinks
public Set<String> getSinks()
{    return sinks;}
a41b990779624b01f8f97765d2f09064a8cea1bc6ce819667f8df287d6480e5f
setSinks
public void setSinks(Set<String> sinks)
{    this.sinks = sinks;}
4090cab6c7113bc213aae1b540151e660d01b030871b240c9ebae4dbc8d62a91
getSinkProcessorConfigurationType
public String getSinkProcessorConfigurationType()
{    return processorClassName;}
e560505f8de56210709b3bcb93c010e556e72b057c497850d278e8a00f73352d
getConfiguration
public SinkProcessorConfiguration getConfiguration(String name) throws ConfigurationException
{    Class<? extends SinkProcessorConfiguration> clazz;    SinkProcessorConfiguration instance = null;    try {        if (processorClassName != null) {            clazz = (Class<? extends SinkProcessorConfiguration>) Class.forName(processorClassName);            instance = clazz.getConstructor(String.class).newInstance(name);        } else {            return new SinkProcessorConfiguration(name);        }    } catch (ClassNotFoundException e) {                instance = new SinkProcessorConfiguration(name);                instance.setNotFoundConfigClass();    } catch (Exception e) {        throw new ConfigurationException("Could not instantiate configuration!", e);    }    return instance;}
caf00a8bcf46496c1872c79f2708fcc0b0d6e3bbbcd2c13c9b78d4ddc138fcd4
getSinkProcessorClassName
public String getSinkProcessorClassName()
{    return processorClassName;}
cfac927e2f01f3beaf1fd6e054846dfbf79b00c5682148da97865c5140e7327f
getClassName
public String getClassName()
{    return processorClassName;}
d68fda8b3da6ec94370e286a856431a6adcc267406936b6cc37a540e20c79bdb
getSinkClassName
public String getSinkClassName()
{    return sinkClassName;}
cfac927e2f01f3beaf1fd6e054846dfbf79b00c5682148da97865c5140e7327f
getClassName
public String getClassName()
{    return sinkClassName;}
873cad62be98ed7e56366b0f37464e66c4b071364af066d8957f3a800004ecb4
getChannels
public Set<String> getChannels()
{    return channels;}
ba91a91deb8d7fc99ece26bec0377d7ca3b3db70cd5d09e91fcef53ba9cd07ce
getSelectorConfiguration
public ChannelSelectorConfiguration getSelectorConfiguration()
{    return selectorConf;}
fa47897acd081345080fc68c9f58ae17a63581f7e2187e4637955118b04f027a
configure
public void configure(Context context) throws ConfigurationException
{    super.configure(context);    try {        String channelList = context.getString(BasicConfigurationConstants.CONFIG_CHANNELS);        if (channelList != null) {            this.channels = new HashSet<String>(Arrays.asList(channelList.split("\\s+")));        }        if (channels.isEmpty()) {            errors.add(new FlumeConfigurationError(componentName, ComponentType.CHANNEL.getComponentType(), FlumeConfigurationErrorType.PROPERTY_VALUE_NULL, ErrorOrWarning.ERROR));            throw new ConfigurationException("No channels set for " + this.getComponentName());        }        Map<String, String> selectorParams = context.getSubProperties(BasicConfigurationConstants.CONFIG_SOURCE_CHANNELSELECTOR_PREFIX);        String selType;        if (selectorParams != null && !selectorParams.isEmpty()) {            selType = selectorParams.get(BasicConfigurationConstants.CONFIG_TYPE);        } else {            selType = ChannelSelectorConfigurationType.REPLICATING.toString();        }        if (selType == null || selType.isEmpty()) {            selType = ChannelSelectorConfigurationType.REPLICATING.toString();        }        ChannelSelectorType selectorType = this.getKnownChannelSelector(selType);        Context selectorContext = new Context();        selectorContext.putAll(selectorParams);        String config = null;        if (selectorType == null) {            config = selectorContext.getString(BasicConfigurationConstants.CONFIG_CONFIG);            if (config == null || config.isEmpty()) {                config = "OTHER";            }        } else {            config = selectorType.toString().toUpperCase(Locale.ENGLISH);        }        this.selectorConf = (ChannelSelectorConfiguration) ComponentConfigurationFactory.create(ComponentType.CHANNELSELECTOR.getComponentType(), config, ComponentType.CHANNELSELECTOR);        selectorConf.setChannels(channels);        selectorConf.configure(selectorContext);    } catch (Exception e) {        errors.add(new FlumeConfigurationError(componentName, ComponentType.CHANNELSELECTOR.getComponentType(), FlumeConfigurationErrorType.CONFIG_ERROR, ErrorOrWarning.ERROR));        throw new ConfigurationException("Failed to configure component!", e);    }}
167f366474d3fcb23d30207cfbde726d2c37216fc3b740b30da36e6d0530ff92
toString
public String toString(int indentCount)
{    String basicStr = super.toString(indentCount);    StringBuilder sb = new StringBuilder();    sb.append(basicStr).append("CHANNELS:");    for (String channel : this.channels) {        sb.append(FlumeConfiguration.INDENTSTEP).append(channel).append(FlumeConfiguration.NEWLINE);    }    return sb.toString();}
902316e69891d8e06c6f5559342617acb48d6338f494538c7883c0f1516c03cc
getKnownChannelSelector
private ChannelSelectorType getKnownChannelSelector(String type)
{    ChannelSelectorType[] values = ChannelSelectorType.values();    for (ChannelSelectorType value : values) {        if (value.toString().equalsIgnoreCase(type))            return value;        String clName = value.getClassName();        if (clName != null && clName.equalsIgnoreCase(type))            return value;    }    return null;}
fc35adad951a283b80653b2d01af7df06ea1aba929603fd9f7f5be2b95503433
getSourceConfigurationType
public String getSourceConfigurationType()
{    return this.srcConfigurationName;}
08770d307980c417c86938be9021909b013ff0e8ac5a4c9372b5014fa38197a6
getConfiguration
public SourceConfiguration getConfiguration(String name) throws ConfigurationException
{    if (this == OTHER) {        return new SourceConfiguration(name);    }    Class<? extends SourceConfiguration> clazz = null;    SourceConfiguration instance = null;    try {        if (srcConfigurationName != null) {            clazz = (Class<? extends SourceConfiguration>) Class.forName(srcConfigurationName);            instance = clazz.getConstructor(String.class).newInstance(name);        } else {                        instance = new SourceConfiguration(name);                        instance.setNotFoundConfigClass();        }    } catch (ClassNotFoundException e) {                instance = new SourceConfiguration(name);                instance.setNotFoundConfigClass();    } catch (Exception e) {        throw new ConfigurationException("Error creating configuration", e);    }    return instance;}
5f0ccf55894810602cb67c30c8b7ec4b79bd87ef60364dbe5598b8d06ab4d20b
getSourceClassName
public String getSourceClassName()
{    return sourceClassName;}
cfac927e2f01f3beaf1fd6e054846dfbf79b00c5682148da97865c5140e7327f
getClassName
public String getClassName()
{    return sourceClassName;}
9a914969663ac068ea3ae4aab261451e2d015d39f830a40321a10efa18ba5a4f
getParameters
public Map<String, String> getParameters()
{    synchronized (parameters) {        return ImmutableMap.copyOf(parameters);    }}
21ac40bb9a99614b6ac18fa4043acb6173fccff96066fdfab963dba597923aa8
clear
public void clear()
{    parameters.clear();}
1fcf1f3fcabdf5de1324b4fb55e345c5235036fc145b624411ab5981db35d2ab
getSubProperties
public Map<String, String> getSubProperties(String prefix)
{    Preconditions.checkArgument(prefix.endsWith("."), "The given prefix does not end with a period (" + prefix + ")");    Map<String, String> result = Maps.newHashMap();    synchronized (parameters) {        for (Entry<String, String> entry : parameters.entrySet()) {            String key = entry.getKey();            if (key.startsWith(prefix)) {                String name = key.substring(prefix.length());                result.put(name, entry.getValue());            }        }    }    return ImmutableMap.copyOf(result);}
fc0f482863453346ff4362c3195f540dd977f646e03a3c93964b8fb207d58ad2
putAll
public void putAll(Map<String, String> map)
{    parameters.putAll(map);}
239c940befd3c340f14defaaf354c56ad9c4a6d3d3f3ae3bb898f4a25c63f9e1
put
public void put(String key, String value)
{    parameters.put(key, value);}
305e0f9c6661052b2e7eebf9a3b58c41a4cc25c2575d2859f4de53780ddc43eb
containsKey
public boolean containsKey(String key)
{    return parameters.containsKey(key);}
1fedf1931cd1e16654098af1ff070faf312aaf8e3a5c35993708b25550101483
getBoolean
public Boolean getBoolean(String key, Boolean defaultValue)
{    String value = get(key);    if (value != null) {        return Boolean.valueOf(Boolean.parseBoolean(value.trim()));    }    return defaultValue;}
b5412394a136d392a0c9460b3c88c6e22b4e6df029494b65e9025d8fb83f26c3
getBoolean
public Boolean getBoolean(String key)
{    return getBoolean(key, null);}
4a2592d7afc27c8d9144a8b25affe2facdc4196c7c99a7f106bbd64ee2273ee5
getInteger
public Integer getInteger(String key, Integer defaultValue)
{    String value = get(key);    if (value != null) {        return Integer.valueOf(Integer.parseInt(value.trim()));    }    return defaultValue;}
4244f915d0409fca08bc4217c72442deb0cc320a4f48eebe4ff8140852d422c4
getInteger
public Integer getInteger(String key)
{    return getInteger(key, null);}
22257a111987dff64d7063fd2cf77ae69bba44b5e616830e87935561e67025e6
getLong
public Long getLong(String key, Long defaultValue)
{    String value = get(key);    if (value != null) {        return Long.valueOf(Long.parseLong(value.trim()));    }    return defaultValue;}
91058ccf12294bca811f20658be85c2664888d83b443a479d864a6ed171811c1
getLong
public Long getLong(String key)
{    return getLong(key, null);}
9075cb0df91977dbd4bd297549a09f010258daa557d12267607a7c9ce4af3eb0
getString
public String getString(String key, String defaultValue)
{    return get(key, defaultValue);}
95011ca7e877e72f1ee94653f93a4d1e5400136e489fa807cc2773a2b3b24f0b
getString
public String getString(String key)
{    return get(key);}
42d4d0e3e4463db95e5f97ea519d23ddf6f3aed0e34c80edb2769bb8c2b39e7e
getFloat
public Float getFloat(String key, Float defaultValue)
{    String value = get(key);    if (value != null) {        return Float.parseFloat(value.trim());    }    return defaultValue;}
fcd9e5509bd8929291a073701bf04ec43374a8c48f6b5bcbae569d4033017fd2
getFloat
public Float getFloat(String key)
{    return getFloat(key, null);}
9c142284e70d8b85e7b3a24f749c424e6eae234ec87e51b3cfa5c6432941f0bc
getDouble
public Double getDouble(String key, Double defaultValue)
{    String value = get(key);    if (value != null) {        return Double.parseDouble(value.trim());    }    return defaultValue;}
41b73abb172c9d0695b9cff21c467ddbc27dc84666e834c489b791268a526cdf
getDouble
public Double getDouble(String key)
{    return getDouble(key, null);}
a1fde84a24c8fbb72f997fabcdf5c21cfdbc6db4b318a9497a8364479b2a93c4
get
private String get(String key, String defaultValue)
{    String result = parameters.get(key);    if (result != null) {        return result;    }    return defaultValue;}
adc830f03c3299e684c5dcea23751242a59e6fa93a1a3eea399a5c6ea9d3af80
get
private String get(String key)
{    return get(key, null);}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return "{ parameters:" + parameters + " }";}
e46fbd31cf9c6caffaa8eb691a3bbd936651af72e2a52fbf8d1c7ad20e0e1e65
filter
public String filter(String key)
{    if (key.equals("null")) {        return null;    }    if (key.equals("throw")) {        throw new IllegalStateException("Test exception");    }    return "filtered_" + key;}
a8f99150e663aa3c2dda83df4cd26bf8e9352d150bcca7ca0ce579d6eacbce0a
initializeWithConfiguration
public void initializeWithConfiguration(Map<String, String> configuration)
{}
20e2a644947d3e87e64634fdc1c4995ccf691de7fa609927084dd6b446665623
testFLUME1847
public void testFLUME1847() throws Exception
{    Context context = new Context();    context.put("type", "something");    SourceConfiguration sourceConfig = new SourceConfiguration("src");    sourceConfig.configure(context);}
864a127308c07219b912b05b989721f80ee42fbb783d349aac2bba2c8fb1d763
setupClass
public static void setupClass()
{    PROPERTIES.put(SOURCES, "s1 s2");    PROPERTIES.put(SOURCES + ".s1.type", "s1_type");    PROPERTIES.put(SOURCES + ".s1.channels", "c1");    PROPERTIES.put(SOURCES + ".s2.type", "jms");    PROPERTIES.put(SOURCES + ".s2.channels", "c2");    PROPERTIES.put(CHANNELS, "c1 c2");    PROPERTIES.put(CHANNELS + ".c1.type", "c1_type");    PROPERTIES.put(CHANNELS + ".c2.type", "memory");    PROPERTIES.put(SINKS, "k1 k2");    PROPERTIES.put(SINKS + ".k1.type", "k1_type");    PROPERTIES.put(SINKS + ".k2.type", "null");    PROPERTIES.put(SINKS + ".k1.channel", "c1");    PROPERTIES.put(SINKS + ".k2.channel", "c2");    PROPERTIES.put(AGENT + ".sinkgroups", "g1");    PROPERTIES.put(AGENT + ".sinkgroups.g1.sinks", "k1 k2");    PROPERTIES.put(AGENT + ".configfilters", "f1 f2");    PROPERTIES.put(AGENT + ".configfilters.f1.type", "f1_type");    PROPERTIES.put(AGENT + ".configfilters.f2.type", "env");}
2fe9feab8a76c81cd2774223a7493c28cc75c6bf6ef3a6bb54cca658654bee75
testConfigHasNoErrors
public void testConfigHasNoErrors()
{    FlumeConfiguration configuration = new FlumeConfiguration(PROPERTIES);    assertTrue(configuration.getConfigurationErrors().isEmpty());}
321ce77d46e8b88261159ffe4d46061d9aada1197f2012e9c4a242d90f78a232
testSourcesAdded
public void testSourcesAdded()
{    FlumeConfiguration configuration = new FlumeConfiguration(PROPERTIES);    Set<String> sourceSet = configuration.getConfigurationFor(AGENT).getSourceSet();    assertEquals(new HashSet<>(Arrays.asList("s1", "s2")), sourceSet);}
fa1ca42d204530b733a9c6d0bd40eaf49ec265a8516f5e1d9586f5fe36a59dea
testFiltersAdded
public void testFiltersAdded()
{    FlumeConfiguration configuration = new FlumeConfiguration(PROPERTIES);    Set<String> configFilterSet = configuration.getConfigurationFor(AGENT).getConfigFilterSet();    assertEquals(new HashSet<>(Arrays.asList("f1", "f2")), configFilterSet);}
781163159d94bdbbf4b181c16553674f93dd67816fafe3a40b55813cc111de75
testSinksAdded
public void testSinksAdded()
{    FlumeConfiguration configuration = new FlumeConfiguration(PROPERTIES);    Set<String> sinkSet = configuration.getConfigurationFor(AGENT).getSinkSet();    assertEquals(new HashSet<>(Arrays.asList("k1", "k2")), sinkSet);}
b2b051274e124e5af0bda4aac9a130aac7fd74f252160f5145f866f962a24716
testChannelsAdded
public void testChannelsAdded()
{    FlumeConfiguration configuration = new FlumeConfiguration(PROPERTIES);    Set<String> channelSet = configuration.getConfigurationFor(AGENT).getChannelSet();    assertEquals(new HashSet<>(Arrays.asList("c1", "c2")), channelSet);}
ecbaf71b356e1307415a7e49008963ede071d905c1e9cf91e6813b4afcb390f5
testSinkGroupsAdded
public void testSinkGroupsAdded()
{    FlumeConfiguration configuration = new FlumeConfiguration(PROPERTIES);    Set<String> sinkSet = configuration.getConfigurationFor(AGENT).getSinkgroupSet();    assertEquals(new HashSet<>(Arrays.asList("g1")), sinkSet);}
4f49b7be5bee4b96e3d6ff20d6817c21f70d594234ac091bf23234920b3e4115
testConfigFiltersMappedCorrectly
public void testConfigFiltersMappedCorrectly()
{    FlumeConfiguration configuration = new FlumeConfiguration(PROPERTIES);    Map<String, Context> contextMap = configuration.getConfigurationFor(AGENT).getConfigFilterContext();    assertEquals("f1_type", contextMap.get("f1").getString("type"));}
3a29c365961889c3a79cb4ec484b7fae51aa4a66afedd737a8e324f99f1554db
testSourcesMappedCorrectly
public void testSourcesMappedCorrectly()
{    FlumeConfiguration configuration = new FlumeConfiguration(PROPERTIES);    Map<String, Context> contextMap = configuration.getConfigurationFor(AGENT).getSourceContext();    assertEquals("s1_type", contextMap.get("s1").getString("type"));}
a8d2f6ffe8429b3d86061a9e961165f9270543c1640f1cba012b0c0324bfb822
testSinksMappedCorrectly
public void testSinksMappedCorrectly()
{    FlumeConfiguration configuration = new FlumeConfiguration(PROPERTIES);    Map<String, Context> contextMap = configuration.getConfigurationFor(AGENT).getSinkContext();    assertEquals("k1_type", contextMap.get("k1").getString("type"));}
aa73397f713f1d7e46426669990ad519db8ddfc0b04c1d8c56ca13e8c125ca1c
testChannelsMappedCorrectly
public void testChannelsMappedCorrectly()
{    FlumeConfiguration configuration = new FlumeConfiguration(PROPERTIES);    Map<String, Context> contextMap = configuration.getConfigurationFor(AGENT).getChannelContext();    assertEquals("c1_type", contextMap.get("c1").getString("type"));}
7882403341e87f8a4eee89f143b374a9eb66a5958fdb07c281ba04685df97bd8
testChannelsConfigMappedCorrectly
public void testChannelsConfigMappedCorrectly()
{    FlumeConfiguration configuration = new FlumeConfiguration(PROPERTIES);    Map<String, ComponentConfiguration> configMap = configuration.getConfigurationFor(AGENT).getChannelConfigMap();    assertEquals("memory", configMap.get("c2").getType());}
330a758d84613535599bc5e2602e7bfe96c300f967314126e8fc9430522df3e4
testConfigFilterConfigMappedCorrectly
public void testConfigFilterConfigMappedCorrectly()
{    FlumeConfiguration configuration = new FlumeConfiguration(PROPERTIES);    Map<String, ComponentConfiguration> configMap = configuration.getConfigurationFor(AGENT).getConfigFilterConfigMap();    assertEquals("env", configMap.get("f2").getType());}
fd059d8439563617d324fafd7b368fe14c81f6ab85684282d29f18a403e65620
testSourceConfigMappedCorrectly
public void testSourceConfigMappedCorrectly()
{    FlumeConfiguration configuration = new FlumeConfiguration(PROPERTIES);    Map<String, ComponentConfiguration> configMap = configuration.getConfigurationFor(AGENT).getSourceConfigMap();    assertEquals("jms", configMap.get("s2").getType());}
a5fc937503ae11bf19f6f38a444f96c17bd083c895455a96ace90a7ede90bae3
testSinkConfigMappedCorrectly
public void testSinkConfigMappedCorrectly()
{    FlumeConfiguration configuration = new FlumeConfiguration(PROPERTIES);    Map<String, ComponentConfiguration> configMap = configuration.getConfigurationFor(AGENT).getSinkConfigMap();    assertEquals("null", configMap.get("k2").getType());}
7f12c97189b240b265ff8f4f9368acdc7f427cc87cef376d7b613b5a7a2754aa
testSinkgroupConfigMappedCorrectly
public void testSinkgroupConfigMappedCorrectly()
{    FlumeConfiguration configuration = new FlumeConfiguration(PROPERTIES);    Map<String, ComponentConfiguration> configMap = configuration.getConfigurationFor(AGENT).getSinkGroupConfigMap();    assertEquals("Sinkgroup", configMap.get("g1").getType());}
f525e058d4f40b7a031913e6c7eb7027780b2de811ec9d7eb2bb409ee90775db
testNoChannelIsInvalid
public void testNoChannelIsInvalid()
{    Map<String, String> properties = new HashMap<>(PROPERTIES);    properties.put(CHANNELS, "");    FlumeConfiguration flumeConfiguration = new FlumeConfiguration(properties);    assertFalse(flumeConfiguration.getConfigurationErrors().isEmpty());    assertNull(flumeConfiguration.getConfigurationFor(AGENT));}
fe22ce2d72fd28b86837c27df9087920fd481189e291e5f55e990b51e8a0876d
testNoSourcesIsValid
public void testNoSourcesIsValid()
{    Map<String, String> properties = new HashMap<>(PROPERTIES);    properties.remove(SOURCES);    properties.remove(SOURCES + ".s1.type");    properties.remove(SOURCES + ".s1.channels");    properties.remove(SOURCES + ".s2.type");    properties.remove(SOURCES + ".s2.channels");    FlumeConfiguration flumeConfiguration = new FlumeConfiguration(properties);    assertConfigHasNoError(flumeConfiguration);    assertNotNull(flumeConfiguration.getConfigurationFor(AGENT));}
fe03de0b06c5fb1f6e744c31b461bda85a06d6732a08d5fb32f622d73d948b29
testNoSinksIsValid
public void testNoSinksIsValid()
{    Map<String, String> properties = new HashMap<>(PROPERTIES);    properties.remove(SINKS);    properties.remove(SINKS + ".k1.type", "k1_type");    properties.remove(SINKS + ".k2.type", "null");    properties.remove(SINKS + ".k1.channel", "c1");    properties.remove(SINKS + ".k2.channel", "c2");    properties.remove(AGENT + ".sinkgroups", "g1");    properties.remove(AGENT + ".sinkgroups.g1.sinks", "k1 k2");    FlumeConfiguration flumeConfiguration = new FlumeConfiguration(properties);    assertConfigHasNoError(flumeConfiguration);    assertNotNull(flumeConfiguration.getConfigurationFor(AGENT));}
c97e60e48cf141f9523682fbab1c2c7c047198bb94bcd729cfc8686da3c27fa1
assertConfigHasNoError
private void assertConfigHasNoError(FlumeConfiguration configuration)
{    List<FlumeConfigurationError> configurationErrors = configuration.getConfigurationErrors();    long count = 0L;    for (FlumeConfigurationError e : configurationErrors) {        if (e.getErrorOrWarning() == ERROR) {            count++;        }    }    assertTrue(count == 0);}
fb5673f278cac4f8da850da866a04ee33af14246c5d3fd5cca482798a29792d2
testNoSourcesAndNoSinksIsInvalid
public void testNoSourcesAndNoSinksIsInvalid()
{    Map<String, String> properties = new HashMap<>(PROPERTIES);    properties.put(SOURCES, "");    properties.put(SINKS, "");    FlumeConfiguration flumeConfiguration = new FlumeConfiguration(properties);    assertFalse(flumeConfiguration.getConfigurationErrors().isEmpty());    assertNull(flumeConfiguration.getConfigurationFor(AGENT));}
6d8433567b50a341eea8e68e73e3334925cd1b1e910d774f7f1e61106e5cdf43
testFLUME1743
public void testFLUME1743()
{    Properties properties = new Properties();    properties.put("agent1.channels", "ch0");    properties.put("agent1.channels.ch0.type", "memory");    properties.put("agent1.sources", "src0");    properties.put("agent1.sources.src0.type", "multiport_syslogtcp");    properties.put("agent1.sources.src0.channels", "ch0");    properties.put("agent1.sources.src0.host", "localhost");    properties.put("agent1.sources.src0.ports", "10001 10002 10003");    properties.put("agent1.sources.src0.portHeader", "port");    properties.put("agent1.sinks", "sink0");    properties.put("agent1.sinks.sink0.type", "null");    properties.put("agent1.sinks.sink0.channel", "ch0");    properties.put("agent1.configfilters", "f1");    properties.put("agent1.configfilters.f1.type", "env");    FlumeConfiguration conf = new FlumeConfiguration(properties);    AgentConfiguration agentConfiguration = conf.getConfigurationFor("agent1");    Assert.assertEquals(String.valueOf(agentConfiguration.getSourceSet()), 1, agentConfiguration.getSourceSet().size());    Assert.assertEquals(String.valueOf(agentConfiguration.getChannelSet()), 1, agentConfiguration.getChannelSet().size());    Assert.assertEquals(String.valueOf(agentConfiguration.getSinkSet()), 1, agentConfiguration.getSinkSet().size());    Assert.assertTrue(agentConfiguration.getSourceSet().contains("src0"));    Assert.assertTrue(agentConfiguration.getChannelSet().contains("ch0"));    Assert.assertTrue(agentConfiguration.getSinkSet().contains("sink0"));    Assert.assertTrue(agentConfiguration.getConfigFilterSet().contains("f1"));}
ec91a698486ba04d8587e370a8d9e2de464d2aa0b6eb180eadbb9239d58441e3
testFlumeConfigAdsErrorOnNullName
public void testFlumeConfigAdsErrorOnNullName()
{    HashMap<String, String> properties = new HashMap<>();    properties.put(null, "something");    FlumeConfiguration config = new FlumeConfiguration(properties);    List<FlumeConfigurationError> configurationErrors = config.getConfigurationErrors();    assertEquals(1, configurationErrors.size());    assertError(configurationErrors.get(0), AGENT_NAME_MISSING, "", "", ERROR);}
4bce51b9241a88ef2d134b1754932ddc0690f28a075ec2cfb9c54da7eea7e2d9
testFlumeConfigAddsErrorOnNullValue
public void testFlumeConfigAddsErrorOnNullValue()
{    HashMap<String, String> properties = new HashMap<>();    properties.put("something", null);    FlumeConfiguration config = new FlumeConfiguration(properties);    List<FlumeConfigurationError> configurationErrors = config.getConfigurationErrors();    assertEquals(1, configurationErrors.size());    assertError(configurationErrors.get(0), AGENT_NAME_MISSING, "", "", ERROR);}
df2b165fe2f47f2d111149b41aecf7981f0af3e6daae4d1ab6ee15bdadaaf280
testFlumeConfigAddsErrorOnEmptyValue
public void testFlumeConfigAddsErrorOnEmptyValue()
{    HashMap<String, String> properties = new HashMap<>();    properties.put("something", "");    FlumeConfiguration config = new FlumeConfiguration(properties);    List<FlumeConfigurationError> configurationErrors = config.getConfigurationErrors();    assertEquals(1, configurationErrors.size());    assertError(configurationErrors.get(0), PROPERTY_VALUE_NULL, "something", "", ERROR);}
fa1070ad348b5b4fefd6bf97e992ba391aa7319dde4e7ba7c10b15f6b31330f4
testFlumeConfigAddsErrorOnNoAgentNameValue
public void testFlumeConfigAddsErrorOnNoAgentNameValue()
{    HashMap<String, String> properties = new HashMap<>();    properties.put("something", "value");    FlumeConfiguration config = new FlumeConfiguration(properties);    List<FlumeConfigurationError> configurationErrors = config.getConfigurationErrors();    assertEquals(1, configurationErrors.size());    assertError(configurationErrors.get(0), AGENT_NAME_MISSING, "something", "", ERROR);}
f26b10fe795a10a3b77e4298d0721404dd08a6d367eeb64ec039ba8e844d1c71
testFlumeConfigAddsErrorOnEmptyAgentNameValue
public void testFlumeConfigAddsErrorOnEmptyAgentNameValue()
{    Properties properties = new Properties();    properties.put(".something", "value");    FlumeConfiguration config = new FlumeConfiguration(properties);    List<FlumeConfigurationError> configurationErrors = config.getConfigurationErrors();    assertEquals(1, configurationErrors.size());    assertError(configurationErrors.get(0), AGENT_NAME_MISSING, ".something", "", ERROR);}
f7d543616f28e087f44f31337d22ba78b33f46a7bc22a73a16589752475c1a51
testFlumeConfigAddsErrorOnEmptyPropertyName
public void testFlumeConfigAddsErrorOnEmptyPropertyName()
{    HashMap<String, String> properties = new HashMap<>();    properties.put("agent.", "something");    FlumeConfiguration config = new FlumeConfiguration(properties);    List<FlumeConfigurationError> configurationErrors = config.getConfigurationErrors();    assertEquals(1, configurationErrors.size());    assertError(configurationErrors.get(0), PROPERTY_NAME_NULL, "agent.", "", ERROR);}
1dad4eaa154ca7ee686100e1b219ab8c28639424b1ff2da507cd1f1c85ac0a37
testFlumeConfigAddsErrorOnInvalidConfig
public void testFlumeConfigAddsErrorOnInvalidConfig()
{    HashMap<String, String> properties = new HashMap<>();    properties.put("agent.channels", "c1");    properties.put("agent.channel.c1", "cc1");    FlumeConfiguration config = new FlumeConfiguration(properties);    List<FlumeConfigurationError> configurationErrors = config.getConfigurationErrors();    assertEquals(4, configurationErrors.size());    assertError(configurationErrors.get(0), INVALID_PROPERTY, "agent", "channel.c1", ERROR);    assertError(configurationErrors.get(1), CONFIG_ERROR, "agent", "c1", ERROR);    assertError(configurationErrors.get(2), PROPERTY_VALUE_NULL, "agent", "channels", ERROR);    assertError(configurationErrors.get(3), AGENT_CONFIGURATION_INVALID, "agent", "", ERROR);}
2068d30ae2a7f02e761c867b73860913a171cb4b5740d4ec47b96b6943bb2b3a
assertError
private void assertError(FlumeConfigurationError error, FlumeConfigurationErrorType agentNameMissing, String componentName, String key, ErrorOrWarning eow)
{    assertEquals(agentNameMissing, error.getErrorType());    assertEquals("ComponentName mismatch.", componentName, error.getComponentName());    assertEquals("Key mismatch.", key, error.getKey());    assertEquals(eow, error.getErrorOrWarning());}
244eb14b713b092d66f4d885dcbb1b62bbbe26fd64cbd58acf8191bd02f57756
testFlumeConfigFilterWorks
public void testFlumeConfigFilterWorks()
{    Properties properties = new Properties();    properties.put("agent1.channels", "ch0");    properties.put("agent1.channels.ch0.type", "file");    properties.put("agent1.channels.ch0.param1", "${f1['param']}");    properties.put("agent1.channels.ch0.param2", "${f1['param\"]}");    properties.put("agent1.channels.ch0.param3", "${f1['null']}");    properties.put("agent1.channels.ch0.param4", "${f1['throw']}");    properties.put("agent1.sources", "src0");    properties.put("agent1.sources.src0.type", "multiport_syslogtcp");    properties.put("agent1.sources.src0.channels", "ch0");    properties.put("agent1.sources.src0.host", "${f1[host]}");    properties.put("agent1.sources.src0.ports", "10001 10002 10003");    properties.put("agent1.sources.src0.portHeader", "${f2[\"port\"]}-${f1['header']}");    properties.put("agent1.sinks", "sink0");    properties.put("agent1.sinks.sink0.type", "thrift");    properties.put("agent1.sinks.sink0.param", "${f2['param']}");    properties.put("agent1.sinks.sink0.channel", "ch0");    properties.put("agent1.configfilters", "f1 f2");    properties.put("agent1.configfilters.f1.type", "org.apache.flume.conf.configfilter.MockConfigFilter");    properties.put("agent1.configfilters.f2.type", "org.apache.flume.conf.configfilter.MockConfigFilter");    FlumeConfiguration conf = new FlumeConfiguration(properties);    AgentConfiguration agentConfiguration = conf.getConfigurationFor("agent1");    Context src0 = agentConfiguration.getSourceContext().get("src0");    assertEquals("filtered_host", src0.getString("host"));    assertEquals("filtered_port-filtered_header", src0.getString("portHeader"));    Context sink0 = agentConfiguration.getSinkContext().get("sink0");    assertEquals("filtered_param", sink0.getString("param"));    Context ch0 = agentConfiguration.getChannelContext().get("ch0");    assertEquals("filtered_param", ch0.getString("param1"));    assertEquals("${f1['param\"]}", ch0.getString("param2"));    assertEquals("${f1['null']}", ch0.getString("param3"));    assertEquals("${f1['throw']}", ch0.getString("param4"));}
831a1aefa333c15f969e26873201d65e004e9eae64fe390a121d56ac6619f888
setName
public synchronized void setName(String name)
{    this.name = name;}
5b05914888e421f26bff6f39231facdd35759f746a9af780ebac2cf5b2c81932
start
public synchronized void start()
{    lifecycleState = LifecycleState.START;}
06e1ddba8663c90da407ac517f29ed70555cfe57b0332c9a96e7c696e0255364
stop
public synchronized void stop()
{    lifecycleState = LifecycleState.STOP;}
82e342b29ff4fad8c64d554dc21ad55a5f2c8063fce3b580e896b7968d90473a
getLifecycleState
public synchronized LifecycleState getLifecycleState()
{    return lifecycleState;}
5a8aa5c66e12ab4bee0bd8ab8101da1e45260314118196130f684c97aec2075b
getName
public synchronized String getName()
{    return name;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return this.getClass().getName() + "{name: " + name + "}";}
ded821e17be2b03d6966295956416048ab3ded89fe4ee222d253f53c96a4d49e
getAllChannels
public List<Channel> getAllChannels()
{    return channels;}
03814e663bf24d10936483aadd9a758fc73393f287b1625690b9aaab7e4f2c5b
setChannels
public void setChannels(List<Channel> channels)
{    this.channels = channels;}
831a1aefa333c15f969e26873201d65e004e9eae64fe390a121d56ac6619f888
setName
public synchronized void setName(String name)
{    this.name = name;}
5a8aa5c66e12ab4bee0bd8ab8101da1e45260314118196130f684c97aec2075b
getName
public synchronized String getName()
{    return name;}
dd07312f91dd3a5bf087186b83f002ae6913bc67ba1ead39a892e9d43aab8ccc
getChannelNameMap
protected Map<String, Channel> getChannelNameMap()
{    Map<String, Channel> channelNameMap = new HashMap<String, Channel>();    for (Channel ch : getAllChannels()) {        channelNameMap.put(ch.getName(), ch);    }    return channelNameMap;}
b6c3d61e55ff6471d39dd88bbb4614e6c1e6293ef281997aa18c18fc0e741945
getChannelListFromNames
protected List<Channel> getChannelListFromNames(String channels, Map<String, Channel> channelNameMap)
{    List<Channel> configuredChannels = new ArrayList<Channel>();    if (channels == null || channels.isEmpty()) {        return configuredChannels;    }    String[] chNames = channels.split(" ");    for (String name : chNames) {        Channel ch = channelNameMap.get(name);        if (ch != null) {            configuredChannels.add(ch);        } else {            throw new FlumeException("Selector channel not found: " + name);        }    }    return configuredChannels;}
db1e53c4b67562939358d7b98664e7421898f856fe95ffa1be615eef690fa185
initialize
protected void initialize()
{}
7c433c140e986ede99b2704e4370ce4dc62a481b499e15037b573f27288bffc9
put
public void put(Event event) throws ChannelException
{    BasicTransactionSemantics transaction = currentTransaction.get();    Preconditions.checkState(transaction != null, "No transaction exists for this thread");    transaction.put(event);}
bd28ef43945352a9d826db660bc6e7b38e1777eec9decd45c0467679fc18a6dd
take
public Event take() throws ChannelException
{    BasicTransactionSemantics transaction = currentTransaction.get();    Preconditions.checkState(transaction != null, "No transaction exists for this thread");    return transaction.take();}
2940dfdc387e1882ca0545a619d502102ae0c821f25b9ee739eafaade9ca3ee9
getTransaction
public Transaction getTransaction()
{    if (!initialized) {        synchronized (this) {            if (!initialized) {                initialize();                initialized = true;            }        }    }    BasicTransactionSemantics transaction = currentTransaction.get();    if (transaction == null || transaction.getState().equals(BasicTransactionSemantics.State.CLOSED)) {        transaction = createTransaction();        currentTransaction.set(transaction);    }    return transaction;}
089dd8ebc0ff4cc8f274f4df7a6cd25c63963a7dd757c692d51b389fe1b5a9c3
doBegin
protected void doBegin() throws InterruptedException
{}
b59bbf45e4d212692a02e8bffbd55012fa8166d3da26e9dbfa4ceaa420037e32
doClose
protected void doClose()
{}
497a0b73c16f4d3cd05130da534e42e3243ea27b8080c19b340ff44989ce1ce6
put
protected void put(Event event)
{    Preconditions.checkState(Thread.currentThread().getId() == initialThreadId, "put() called from different thread than getTransaction()!");    Preconditions.checkState(state.equals(State.OPEN), "put() called when transaction is %s!", state);    Preconditions.checkArgument(event != null, "put() called with null event!");    try {        doPut(event);    } catch (InterruptedException e) {        Thread.currentThread().interrupt();        throw new ChannelException(e.toString(), e);    }}
628c45b759d0cb078cd620b4024dcf961781cd26228da93018419912983219e1
take
protected Event take()
{    Preconditions.checkState(Thread.currentThread().getId() == initialThreadId, "take() called from different thread than getTransaction()!");    Preconditions.checkState(state.equals(State.OPEN), "take() called when transaction is %s!", state);    try {        return doTake();    } catch (InterruptedException e) {        Thread.currentThread().interrupt();        return null;    }}
54b663d79ea5a3eb1a2a4fdf975f8e3dd8fec756216ff2ce25feb2f218b26fd3
getState
protected State getState()
{    return state;}
1e146b07faa919b1916e630a172c03c6ebfc96663a23166e205cd71924113b12
begin
public void begin()
{    Preconditions.checkState(Thread.currentThread().getId() == initialThreadId, "begin() called from different thread than getTransaction()!");    Preconditions.checkState(state.equals(State.NEW), "begin() called when transaction is " + state + "!");    try {        doBegin();    } catch (InterruptedException e) {        Thread.currentThread().interrupt();        throw new ChannelException(e.toString(), e);    }    state = State.OPEN;}
609962ed3c13286966d937afa9c301e49ddab59023e4f4c7704fb7ba9630b243
commit
public void commit()
{    Preconditions.checkState(Thread.currentThread().getId() == initialThreadId, "commit() called from different thread than getTransaction()!");    Preconditions.checkState(state.equals(State.OPEN), "commit() called when transaction is %s!", state);    try {        doCommit();    } catch (InterruptedException e) {        Thread.currentThread().interrupt();        throw new ChannelException(e.toString(), e);    }    state = State.COMPLETED;}
f1b7a3da67263bf9cf38feebb790935f22fffbce70c05f42446b0a1c1fd2c534
rollback
public void rollback()
{    Preconditions.checkState(Thread.currentThread().getId() == initialThreadId, "rollback() called from different thread than getTransaction()!");    Preconditions.checkState(state.equals(State.OPEN), "rollback() called when transaction is %s!", state);    state = State.COMPLETED;    try {        doRollback();    } catch (InterruptedException e) {        Thread.currentThread().interrupt();        throw new ChannelException(e.toString(), e);    }}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{    Preconditions.checkState(Thread.currentThread().getId() == initialThreadId, "close() called from different thread than getTransaction()!");    Preconditions.checkState(state.equals(State.NEW) || state.equals(State.COMPLETED), "close() called when transaction is %s" + " - you must either commit or rollback first", state);    state = State.CLOSED;    doClose();}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    StringBuilder builder = new StringBuilder();    builder.append("BasicTransactionSemantics: {");    builder.append(" state:").append(state);    builder.append(" initialThreadId:").append(initialThreadId);    builder.append(" }");    return builder.toString();}
46ffa8d56c2364376c7a2fb00ff1e97ead501825886406f582f8797ba07e934c
initialize
public void initialize()
{    interceptorChain.initialize();}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{    interceptorChain.close();}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    configureInterceptors(context);}
23b5ff802a42fbe01270b5a0de2b2171e751a21412b0143fea528a9c95419713
configureInterceptors
private void configureInterceptors(Context context)
{    List<Interceptor> interceptors = Lists.newLinkedList();    String interceptorListStr = context.getString("interceptors", "");    if (interceptorListStr.isEmpty()) {        return;    }    String[] interceptorNames = interceptorListStr.split("\\s+");    Context interceptorContexts = new Context(context.getSubProperties("interceptors."));        InterceptorBuilderFactory factory = new InterceptorBuilderFactory();    for (String interceptorName : interceptorNames) {        Context interceptorContext = new Context(interceptorContexts.getSubProperties(interceptorName + "."));        String type = interceptorContext.getString("type");        if (type == null) {            LOG.error("Type not specified for interceptor " + interceptorName);            throw new FlumeException("Interceptor.Type not specified for " + interceptorName);        }        try {            Interceptor.Builder builder = factory.newInstance(type);            builder.configure(interceptorContext);            interceptors.add(builder.build());        } catch (ClassNotFoundException e) {            LOG.error("Builder class not found. Exception follows.", e);            throw new FlumeException("Interceptor.Builder not found.", e);        } catch (InstantiationException e) {            LOG.error("Could not instantiate Builder. Exception follows.", e);            throw new FlumeException("Interceptor.Builder not constructable.", e);        } catch (IllegalAccessException e) {            LOG.error("Unable to access Builder. Exception follows.", e);            throw new FlumeException("Unable to access Interceptor.Builder.", e);        }    }    interceptorChain.setInterceptors(interceptors);}
f66a4e70acc0324a6755c912090c9eb26817a1fd90873558edad5bf30a386e85
getSelector
public ChannelSelector getSelector()
{    return selector;}
6a281bd341733c50bb47f772bdbb1f810d45d986614aa6a6c4721bf628667cee
processEventBatch
public void processEventBatch(List<Event> events)
{    Preconditions.checkNotNull(events, "Event list must not be null");    events = interceptorChain.intercept(events);    Map<Channel, List<Event>> reqChannelQueue = new LinkedHashMap<Channel, List<Event>>();    Map<Channel, List<Event>> optChannelQueue = new LinkedHashMap<Channel, List<Event>>();    for (Event event : events) {        List<Channel> reqChannels = selector.getRequiredChannels(event);        for (Channel ch : reqChannels) {            List<Event> eventQueue = reqChannelQueue.get(ch);            if (eventQueue == null) {                eventQueue = new ArrayList<Event>();                reqChannelQueue.put(ch, eventQueue);            }            eventQueue.add(event);        }        List<Channel> optChannels = selector.getOptionalChannels(event);        for (Channel ch : optChannels) {            List<Event> eventQueue = optChannelQueue.get(ch);            if (eventQueue == null) {                eventQueue = new ArrayList<Event>();                optChannelQueue.put(ch, eventQueue);            }            eventQueue.add(event);        }    }        for (Channel reqChannel : reqChannelQueue.keySet()) {        Transaction tx = reqChannel.getTransaction();        Preconditions.checkNotNull(tx, "Transaction object must not be null");        try {            tx.begin();            List<Event> batch = reqChannelQueue.get(reqChannel);            for (Event event : batch) {                reqChannel.put(event);            }            tx.commit();        } catch (Throwable t) {            tx.rollback();            if (t instanceof Error) {                LOG.error("Error while writing to required channel: " + reqChannel, t);                throw (Error) t;            } else if (t instanceof ChannelException) {                throw (ChannelException) t;            } else {                throw new ChannelException("Unable to put batch on required " + "channel: " + reqChannel, t);            }        } finally {            if (tx != null) {                tx.close();            }        }    }        for (Channel optChannel : optChannelQueue.keySet()) {        Transaction tx = optChannel.getTransaction();        Preconditions.checkNotNull(tx, "Transaction object must not be null");        try {            tx.begin();            List<Event> batch = optChannelQueue.get(optChannel);            for (Event event : batch) {                optChannel.put(event);            }            tx.commit();        } catch (Throwable t) {            tx.rollback();            LOG.error("Unable to put batch on optional channel: " + optChannel, t);            if (t instanceof Error) {                throw (Error) t;            }        } finally {            if (tx != null) {                tx.close();            }        }    }}
f3326056dea515fc7d004baa8ecfac759f3a87959903bca208fc1d01d51a76cb
processEvent
public void processEvent(Event event)
{    event = interceptorChain.intercept(event);    if (event == null) {        return;    }        List<Channel> requiredChannels = selector.getRequiredChannels(event);    for (Channel reqChannel : requiredChannels) {        Transaction tx = reqChannel.getTransaction();        Preconditions.checkNotNull(tx, "Transaction object must not be null");        try {            tx.begin();            reqChannel.put(event);            tx.commit();        } catch (Throwable t) {            tx.rollback();            if (t instanceof Error) {                LOG.error("Error while writing to required channel: " + reqChannel, t);                throw (Error) t;            } else if (t instanceof ChannelException) {                throw (ChannelException) t;            } else {                throw new ChannelException("Unable to put event on required " + "channel: " + reqChannel, t);            }        } finally {            if (tx != null) {                tx.close();            }        }    }        List<Channel> optionalChannels = selector.getOptionalChannels(event);    for (Channel optChannel : optionalChannels) {        Transaction tx = null;        try {            tx = optChannel.getTransaction();            tx.begin();            optChannel.put(event);            tx.commit();        } catch (Throwable t) {            tx.rollback();            LOG.error("Unable to put event on optional channel: " + optChannel, t);            if (t instanceof Error) {                throw (Error) t;            }        } finally {            if (tx != null) {                tx.close();            }        }    }}
9ecd3671fc2567f09741fefb7f0fba1ae37b8b92ffefacb0eff6e0ebbcb9d031
create
public static ChannelSelector create(List<Channel> channels, Map<String, String> config)
{    ChannelSelector selector = getSelectorForType(config.get(BasicConfigurationConstants.CONFIG_TYPE));    selector.setChannels(channels);    Context context = new Context();    context.putAll(config);    Configurables.configure(selector, context);    return selector;}
95fd75b03e685dc7301cb527df48fd5eb4cfcfdc1936b2097dfc7884b6e94837
create
public static ChannelSelector create(List<Channel> channels, ChannelSelectorConfiguration conf)
{    String type = ChannelSelectorType.REPLICATING.toString();    if (conf != null) {        type = conf.getType();    }    ChannelSelector selector = getSelectorForType(type);    selector.setChannels(channels);    Configurables.configure(selector, conf);    return selector;}
f3577084b199c785e91eb9520d58bb8666ce6d193e57979eb1077b292e5776f0
getSelectorForType
private static ChannelSelector getSelectorForType(String type)
{    if (type == null || type.trim().length() == 0) {        return new ReplicatingChannelSelector();    }    String selectorClassName = type;    ChannelSelectorType selectorType = ChannelSelectorType.OTHER;    try {        selectorType = ChannelSelectorType.valueOf(type.toUpperCase(Locale.ENGLISH));    } catch (IllegalArgumentException ex) {        LOGGER.debug("Selector type {} is a custom type", type);    }    if (!selectorType.equals(ChannelSelectorType.OTHER)) {        selectorClassName = selectorType.getChannelSelectorClassName();    }    ChannelSelector selector = null;    try {        @SuppressWarnings("unchecked")        Class<? extends ChannelSelector> selectorClass = (Class<? extends ChannelSelector>) Class.forName(selectorClassName);        selector = selectorClass.newInstance();    } catch (Exception ex) {        throw new FlumeException("Unable to load selector type: " + type + ", class: " + selectorClassName, ex);    }    return selector;}
5ae50acf54ce000dbee5c937f7e90a6a14552ac0a7786d39d5b6ffe12910bd97
put
public static void put(final Channel channel, final Event event) throws ChannelException
{    transact(channel, new Runnable() {        @Override        public void run() {            channel.put(event);        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    channel.put(event);}
d96bff7b36d412e7d653212b10faf0164ecf6438fa30229438c2de28f3f6292c
put
public static void put(final Channel channel, final Collection<Event> events) throws ChannelException
{    transact(channel, new Runnable() {        @Override        public void run() {            for (Event event : events) {                channel.put(event);            }        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    for (Event event : events) {        channel.put(event);    }}
e4e377c80e146a5c2402b2a13b4957f2a9e6a04c7852a3465c4b466512b614f3
take
public static Event take(final Channel channel) throws ChannelException
{    return transact(channel, new Callable<Event>() {        @Override        public Event call() {            return channel.take();        }    });}
75f0dff330d82925f46c5bd9b3e4026260aa5532e6c6db4d4cd47863e0308b9a
call
public Event call()
{    return channel.take();}
d4accd9a864ae053cfa20b7e496b3b0015498bb0c3d52572796489c021c046f7
take
public static List<Event> take(final Channel channel, final int max) throws ChannelException
{    return transact(channel, new Callable<List<Event>>() {        @Override        public List<Event> call() {            List<Event> events = new ArrayList<Event>(max);            while (events.size() < max) {                Event event = channel.take();                if (event == null) {                    break;                }                events.add(event);            }            return events;        }    });}
717cb9cb46a5d18cb85b8667751f3f606607c99a1c9880f283646bc4b9254191
call
public List<Event> call()
{    List<Event> events = new ArrayList<Event>(max);    while (events.size() < max) {        Event event = channel.take();        if (event == null) {            break;        }        events.add(event);    }    return events;}
3990aaad10673e346f612fd8e02f1c8fe61d44ce23de27ca0640911255dad345
transact
public static void transact(Channel channel, Runnable transactor) throws ChannelException
{    transact(channel, Executors.callable(transactor));}
85e0904b90b9954a289767373aa58fb110ac9c05e942c22c15444fc0073c450c
transact
public static T transact(Channel channel, Callable<T> transactor) throws ChannelException
{    Transaction transaction = channel.getTransaction();    boolean committed = false;    boolean interrupted = false;    try {        transaction.begin();        T value = transactor.call();        transaction.commit();        committed = true;        return value;    } catch (Throwable e) {        interrupted = Thread.currentThread().isInterrupted();        try {            transaction.rollback();        } catch (Throwable e2) {            logger.error("Failed to roll back transaction, exception follows:", e2);        }        if (e instanceof InterruptedException) {            interrupted = true;        } else if (e instanceof Error) {            throw (Error) e;        } else if (e instanceof RuntimeException) {            throw (RuntimeException) e;        }        throw new ChannelException(e);    } finally {        interrupted = interrupted || Thread.currentThread().isInterrupted();        try {            transaction.close();        } catch (Throwable e) {            if (committed) {                if (e instanceof Error) {                    throw (Error) e;                } else if (e instanceof RuntimeException) {                    throw (RuntimeException) e;                } else {                    throw new ChannelException(e);                }            } else {                logger.error("Failed to close transaction after error, exception follows:", e);            }        } finally {            if (interrupted) {                Thread.currentThread().interrupt();            }        }    }}
9655b8feec78579a471e4e3bbf13aefd6fa9b4331d3d48f231beb32b4abfcbfd
create
public Channel create(String name, String type) throws FlumeException
{    Preconditions.checkNotNull(name, "name");    Preconditions.checkNotNull(type, "type");    logger.info("Creating instance of channel {} type {}", name, type);    Class<? extends Channel> channelClass = getClass(type);    try {        return channelClass.newInstance();    } catch (Exception ex) {        throw new FlumeException("Unable to create channel: " + name + ", type: " + type + ", class: " + channelClass.getName(), ex);    }}
c1e82f94e4fb0d95d421bf579c57d0dc6e2cced0debf096fbf32e234895659b4
getClass
public Class<? extends Channel> getClass(String type) throws FlumeException
{    String channelClassName = type;    ChannelType channelType = ChannelType.OTHER;    try {        channelType = ChannelType.valueOf(type.toUpperCase(Locale.ENGLISH));    } catch (IllegalArgumentException ex) {        logger.debug("Channel type {} is a custom type", type);    }    if (!channelType.equals(ChannelType.OTHER)) {        channelClassName = channelType.getChannelClassName();    }    try {        return (Class<? extends Channel>) Class.forName(channelClassName);    } catch (Exception ex) {        throw new FlumeException("Unable to load channel type: " + type + ", class: " + channelClassName, ex);    }}
12f20da1039baa55cd8cd24a8512df38790e6cb0af896f04ec9f5012ddf00b9a
doPut
protected void doPut(Event event) throws InterruptedException
{    channelCounter.incrementEventPutAttemptCount();    int eventByteSize = (int) Math.ceil(estimateEventSize(event) / byteCapacitySlotSize);    if (!putList.offer(event)) {        throw new ChannelException("Put queue for MemoryTransaction of capacity " + putList.size() + " full, consider committing more frequently, " + "increasing capacity or increasing thread count");    }    putByteCounter += eventByteSize;}
f8425491b25802703eb5080383b86f3b99d38a0998a1c49a9f85e4971cf4e57c
doTake
protected Event doTake() throws InterruptedException
{    channelCounter.incrementEventTakeAttemptCount();    if (takeList.remainingCapacity() == 0) {        throw new ChannelException("Take list for MemoryTransaction, capacity " + takeList.size() + " full, consider committing more frequently, " + "increasing capacity, or increasing thread count");    }    if (!queueStored.tryAcquire(keepAlive, TimeUnit.SECONDS)) {        return null;    }    Event event;    synchronized (queueLock) {        event = queue.poll();    }    Preconditions.checkNotNull(event, "Queue.poll returned NULL despite semaphore " + "signalling existence of entry");    takeList.put(event);    int eventByteSize = (int) Math.ceil(estimateEventSize(event) / byteCapacitySlotSize);    takeByteCounter += eventByteSize;    return event;}
1665f7d1b67a1fa794c9fb67a1be01e4bf6a8b0e782a8f9a49914917f9ecf058
doCommit
protected void doCommit() throws InterruptedException
{    int remainingChange = takeList.size() - putList.size();    if (remainingChange < 0) {        if (!bytesRemaining.tryAcquire(putByteCounter, keepAlive, TimeUnit.SECONDS)) {            throw new ChannelException("Cannot commit transaction. Byte capacity " + "allocated to store event body " + byteCapacity * byteCapacitySlotSize + "reached. Please increase heap space/byte capacity allocated to " + "the channel as the sinks may not be keeping up with the sources");        }        if (!queueRemaining.tryAcquire(-remainingChange, keepAlive, TimeUnit.SECONDS)) {            bytesRemaining.release(putByteCounter);            throw new ChannelFullException("Space for commit to queue couldn't be acquired." + " Sinks are likely not keeping up with sources, or the buffer size is too tight");        }    }    int puts = putList.size();    int takes = takeList.size();    synchronized (queueLock) {        if (puts > 0) {            while (!putList.isEmpty()) {                if (!queue.offer(putList.removeFirst())) {                    throw new RuntimeException("Queue add failed, this shouldn't be able to happen");                }            }        }        putList.clear();        takeList.clear();    }    bytesRemaining.release(takeByteCounter);    takeByteCounter = 0;    putByteCounter = 0;    queueStored.release(puts);    if (remainingChange > 0) {        queueRemaining.release(remainingChange);    }    if (puts > 0) {        channelCounter.addToEventPutSuccessCount(puts);    }    if (takes > 0) {        channelCounter.addToEventTakeSuccessCount(takes);    }    channelCounter.setChannelSize(queue.size());}
29c03e5706a43ef13c083eeb7ced8ad018dfba403134c5972f8063e77ddd24a1
doRollback
protected void doRollback()
{    int takes = takeList.size();    synchronized (queueLock) {        Preconditions.checkState(queue.remainingCapacity() >= takeList.size(), "Not enough space in memory channel " + "queue to rollback takes. This should never happen, please report");        while (!takeList.isEmpty()) {            queue.addFirst(takeList.removeLast());        }        putList.clear();    }    putByteCounter = 0;    takeByteCounter = 0;    queueStored.release(takes);    channelCounter.setChannelSize(queue.size());}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    Integer capacity = null;    try {        capacity = context.getInteger("capacity", defaultCapacity);    } catch (NumberFormatException e) {        capacity = defaultCapacity;        LOGGER.warn("Invalid capacity specified, initializing channel to " + "default capacity of {}", defaultCapacity);    }    if (capacity <= 0) {        capacity = defaultCapacity;        LOGGER.warn("Invalid capacity specified, initializing channel to " + "default capacity of {}", defaultCapacity);    }    try {        transCapacity = context.getInteger("transactionCapacity", defaultTransCapacity);    } catch (NumberFormatException e) {        transCapacity = defaultTransCapacity;        LOGGER.warn("Invalid transation capacity specified, initializing channel" + " to default capacity of {}", defaultTransCapacity);    }    if (transCapacity <= 0) {        transCapacity = defaultTransCapacity;        LOGGER.warn("Invalid transation capacity specified, initializing channel" + " to default capacity of {}", defaultTransCapacity);    }    Preconditions.checkState(transCapacity <= capacity, "Transaction Capacity of Memory Channel cannot be higher than " + "the capacity.");    try {        byteCapacityBufferPercentage = context.getInteger("byteCapacityBufferPercentage", defaultByteCapacityBufferPercentage);    } catch (NumberFormatException e) {        byteCapacityBufferPercentage = defaultByteCapacityBufferPercentage;    }    try {        byteCapacity = (int) ((context.getLong("byteCapacity", defaultByteCapacity).longValue() * (1 - byteCapacityBufferPercentage * .01)) / byteCapacitySlotSize);        if (byteCapacity < 1) {            byteCapacity = Integer.MAX_VALUE;        }    } catch (NumberFormatException e) {        byteCapacity = (int) ((defaultByteCapacity * (1 - byteCapacityBufferPercentage * .01)) / byteCapacitySlotSize);    }    try {        keepAlive = context.getInteger("keep-alive", defaultKeepAlive);    } catch (NumberFormatException e) {        keepAlive = defaultKeepAlive;    }    if (queue != null) {        try {            resizeQueue(capacity);        } catch (InterruptedException e) {            Thread.currentThread().interrupt();        }    } else {        synchronized (queueLock) {            queue = new LinkedBlockingDeque<Event>(capacity);            queueRemaining = new Semaphore(capacity);            queueStored = new Semaphore(0);        }    }    if (bytesRemaining == null) {        bytesRemaining = new Semaphore(byteCapacity);        lastByteCapacity = byteCapacity;    } else {        if (byteCapacity > lastByteCapacity) {            bytesRemaining.release(byteCapacity - lastByteCapacity);            lastByteCapacity = byteCapacity;        } else {            try {                if (!bytesRemaining.tryAcquire(lastByteCapacity - byteCapacity, keepAlive, TimeUnit.SECONDS)) {                    LOGGER.warn("Couldn't acquire permits to downsize the byte capacity, resizing has been aborted");                } else {                    lastByteCapacity = byteCapacity;                }            } catch (InterruptedException e) {                Thread.currentThread().interrupt();            }        }    }    if (channelCounter == null) {        channelCounter = new ChannelCounter(getName());    }}
be3c22dad63dbc6af8a8bf66ee331099a876e7bbd946aec8beffa1cbb1e67145
resizeQueue
private void resizeQueue(int capacity) throws InterruptedException
{    int oldCapacity;    synchronized (queueLock) {        oldCapacity = queue.size() + queue.remainingCapacity();    }    if (oldCapacity == capacity) {        return;    } else if (oldCapacity > capacity) {        if (!queueRemaining.tryAcquire(oldCapacity - capacity, keepAlive, TimeUnit.SECONDS)) {            LOGGER.warn("Couldn't acquire permits to downsize the queue, resizing has been aborted");        } else {            synchronized (queueLock) {                LinkedBlockingDeque<Event> newQueue = new LinkedBlockingDeque<Event>(capacity);                newQueue.addAll(queue);                queue = newQueue;            }        }    } else {        synchronized (queueLock) {            LinkedBlockingDeque<Event> newQueue = new LinkedBlockingDeque<Event>(capacity);            newQueue.addAll(queue);            queue = newQueue;        }        queueRemaining.release(capacity - oldCapacity);    }}
5b05914888e421f26bff6f39231facdd35759f746a9af780ebac2cf5b2c81932
start
public synchronized void start()
{    channelCounter.start();    channelCounter.setChannelSize(queue.size());    channelCounter.setChannelCapacity(Long.valueOf(queue.size() + queue.remainingCapacity()));    super.start();}
06e1ddba8663c90da407ac517f29ed70555cfe57b0332c9a96e7c696e0255364
stop
public synchronized void stop()
{    channelCounter.setChannelSize(queue.size());    channelCounter.stop();    super.stop();}
39f7d6d1213100383ba6ea7c79d8ed4ca1c7407a0f2469c0973c0709371a6cb9
createTransaction
protected BasicTransactionSemantics createTransaction()
{    return new MemoryTransaction(transCapacity, channelCounter);}
4e51a290ddf8d180e1f63b61bfb9a1379099162f4e9d2692f6e7c053ac01b9e4
estimateEventSize
private long estimateEventSize(Event event)
{    byte[] body = event.getBody();    if (body != null && body.length != 0) {        return body.length;    }        return 1;}
4095348d01225a6d93971d622d3fed26e15b7bec9b8dab32b4a08f851c5f805c
getBytesRemainingValue
 int getBytesRemainingValue()
{    return bytesRemaining.availablePermits();}
c571ab4ff4ca7bf7123cf5ecd24cb716b666646f029f59e3775081551a025e6b
getTransactionCapacity
public long getTransactionCapacity()
{    return transCapacity;}
2867a95f4043bd914fc5fd871807225fbbdca7ee0281448a22c7c1c4c2704ad8
getRequiredChannels
public List<Channel> getRequiredChannels(Event event)
{    String headerValue = event.getHeaders().get(headerName);    if (headerValue == null || headerValue.trim().length() == 0) {        return defaultChannels;    }    List<Channel> channels = channelMapping.get(headerValue);        if (channels == null) {        channels = defaultChannels;    }    return channels;}
133a6e8d0ed5a3be5e9d2acc00f35a293003326d21bfd0361adfb6cb5bc065af
getOptionalChannels
public List<Channel> getOptionalChannels(Event event)
{    String hdr = event.getHeaders().get(headerName);    List<Channel> channels = optionalChannels.get(hdr);    if (channels == null) {        channels = EMPTY_LIST;    }    return channels;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    this.headerName = context.getString(CONFIG_MULTIPLEX_HEADER_NAME, DEFAULT_MULTIPLEX_HEADER);    Map<String, Channel> channelNameMap = getChannelNameMap();    defaultChannels = getChannelListFromNames(context.getString(CONFIG_DEFAULT_CHANNEL), channelNameMap);    Map<String, String> mapConfig = context.getSubProperties(CONFIG_PREFIX_MAPPING);    channelMapping = new HashMap<String, List<Channel>>();    for (String headerValue : mapConfig.keySet()) {        List<Channel> configuredChannels = getChannelListFromNames(mapConfig.get(headerValue), channelNameMap);                if (configuredChannels.size() == 0) {            throw new FlumeException("No channel configured for when " + "header value is: " + headerValue);        }        if (channelMapping.put(headerValue, configuredChannels) != null) {            throw new FlumeException("Selector channel configured twice");        }    }            Map<String, String> optionalChannelsMapping = context.getSubProperties(CONFIG_PREFIX_OPTIONAL + ".");    optionalChannels = new HashMap<String, List<Channel>>();    for (String hdr : optionalChannelsMapping.keySet()) {        List<Channel> confChannels = getChannelListFromNames(optionalChannelsMapping.get(hdr), channelNameMap);        if (confChannels.isEmpty()) {            confChannels = EMPTY_LIST;        }                        List<Channel> reqdChannels = channelMapping.get(hdr);                if (reqdChannels == null || reqdChannels.isEmpty()) {            reqdChannels = defaultChannels;        }        for (Channel c : reqdChannels) {            if (confChannels.contains(c)) {                confChannels.remove(c);            }        }        if (optionalChannels.put(hdr, confChannels) != null) {            throw new FlumeException("Selector channel configured twice");        }    }}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    Integer capacity = context.getInteger("capacity");    keepAlive = context.getInteger("keep-alive");    if (capacity == null) {        capacity = defaultCapacity;    }    if (keepAlive == null) {        keepAlive = defaultKeepAlive;    }    queue = new ArrayBlockingQueue<Event>(capacity);    if (channelCounter == null) {        channelCounter = new ChannelCounter(getName());    }}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    channelCounter.start();    channelCounter.setChannelSize(queue.size());    channelCounter.setChannelSize(Long.valueOf(queue.size() + queue.remainingCapacity()));    super.start();}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    channelCounter.setChannelSize(queue.size());    channelCounter.stop();    super.stop();}
13c3ef8adeeda9f28fd9b14c61bf7980ca13c6d145dddf21387c5f36c3cdfc7f
put
public void put(Event event)
{    Preconditions.checkState(queue != null, "No queue defined (Did you forget to configure me?");    channelCounter.incrementEventPutAttemptCount();    try {        queue.put(event);    } catch (InterruptedException ex) {        throw new ChannelException("Failed to put(" + event + ")", ex);    }    channelCounter.addToEventPutSuccessCount(1);    channelCounter.setChannelSize(queue.size());}
da962cc4b95e17f8cd5b1ca3219103002f3c7029eba6370c203b854edfc9eb38
take
public Event take()
{    Preconditions.checkState(queue != null, "No queue defined (Did you forget to configure me?");    channelCounter.incrementEventTakeAttemptCount();    try {        Event e = queue.poll(keepAlive, TimeUnit.SECONDS);        channelCounter.addToEventTakeSuccessCount(1);        channelCounter.setChannelSize(queue.size());        return e;    } catch (InterruptedException ex) {        throw new ChannelException("Failed to take()", ex);    }}
2940dfdc387e1882ca0545a619d502102ae0c821f25b9ee739eafaade9ca3ee9
getTransaction
public Transaction getTransaction()
{    return NoOpTransaction.sharedInstance();}
8f823864e501c7f2f0260b693870ef079b93a41cc1ee375b594470b3672907e4
sharedInstance
public static Transaction sharedInstance()
{    if (sharedInstance == null) {        sharedInstance = new NoOpTransaction();    }    return sharedInstance;}
1e146b07faa919b1916e630a172c03c6ebfc96663a23166e205cd71924113b12
begin
public void begin()
{}
609962ed3c13286966d937afa9c301e49ddab59023e4f4c7704fb7ba9630b243
commit
public void commit()
{}
f1b7a3da67263bf9cf38feebb790935f22fffbce70c05f42446b0a1c1fd2c534
rollback
public void rollback()
{}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{}
2867a95f4043bd914fc5fd871807225fbbdca7ee0281448a22c7c1c4c2704ad8
getRequiredChannels
public List<Channel> getRequiredChannels(Event event)
{    /*     * Seems like there are lot of components within flume that do not call     * configure method. It is conceiveable that custom component tests too     * do that. So in that case, revert to old behavior.     */    if (requiredChannels == null) {        return getAllChannels();    }    return requiredChannels;}
133a6e8d0ed5a3be5e9d2acc00f35a293003326d21bfd0361adfb6cb5bc065af
getOptionalChannels
public List<Channel> getOptionalChannels(Event event)
{    return optionalChannels;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    String optionalList = context.getString(CONFIG_OPTIONAL);    requiredChannels = new ArrayList<Channel>(getAllChannels());    Map<String, Channel> channelNameMap = getChannelNameMap();    if (optionalList != null && !optionalList.isEmpty()) {        for (String optional : optionalList.split("\\s+")) {            Channel optionalChannel = channelNameMap.get(optional);            requiredChannels.remove(optionalChannel);            if (!optionalChannels.contains(optionalChannel)) {                optionalChannels.add(optionalChannel);            }        }    }}
3116ea2053d9de960ec3753eb07f3d243c370662aa1f0175ad357057c9ce5a52
main
public static void main(String[] args)
{    SSLUtil.initGlobalSSLParameters();    AvroCLIClient client = new AvroCLIClient();    try {        if (client.parseCommandLine(args)) {            client.run();        }    } catch (ParseException e) {        logger.error("Unable to parse command line options - {}", e.getMessage());    } catch (IOException e) {        logger.error("Unable to send data to Flume. Exception follows.", e);    } catch (FlumeException e) {        logger.error("Unable to open connection to Flume. Exception follows.", e);    } catch (EventDeliveryException e) {        logger.error("Unable to deliver events to Flume. Exception follows.", e);    }    logger.debug("Exiting");}
8a0f8b91a0d241413b6dabcd291c75ad53892145cc09804aaecf394cf8b0dd67
parseHeaders
private void parseHeaders(CommandLine commandLine)
{    String headerFile = commandLine.getOptionValue("headerFile");    FileInputStream fs = null;    try {        if (headerFile != null) {            fs = new FileInputStream(headerFile);            Properties properties = new Properties();            properties.load(fs);            for (Map.Entry<Object, Object> propertiesEntry : properties.entrySet()) {                String key = (String) propertiesEntry.getKey();                String value = (String) propertiesEntry.getValue();                logger.debug("Inserting Header Key [" + key + "] header value [" + value + "]");                headers.put(key, value);            }        }    } catch (Exception e) {        logger.error("Unable to load headerFile", headerFile, e);        return;    } finally {        if (fs != null) {            try {                fs.close();            } catch (Exception e) {                logger.error("Unable to close headerFile", e);                return;            }        }    }}
c554ac44f53c04f590e8fbbc09761146585238dbc0d1422fec0f2dced4468162
parseCommandLine
private boolean parseCommandLine(String[] args) throws ParseException
{    Options options = new Options();    options.addOption("P", "rpcProps", true, "RPC client properties file with " + "server connection params").addOption("p", "port", true, "port of the avro source").addOption("H", "host", true, "hostname of the avro source").addOption("F", "filename", true, "file to stream to avro source").addOption(null, "dirname", true, "directory to stream to avro source").addOption("R", "headerFile", true, ("file containing headers as " + "key/value pairs on each new line")).addOption("h", "help", false, "display help text");    CommandLineParser parser = new GnuParser();    CommandLine commandLine = parser.parse(options, args);    if (commandLine.hasOption('h')) {        new HelpFormatter().printHelp("flume-ng avro-client", "", options, "The --dirname option assumes that a spooling directory exists " + "where immutable log files are dropped.", true);        return false;    }    if (commandLine.hasOption("filename") && commandLine.hasOption("dirname")) {        throw new ParseException("--filename and --dirname options cannot be used simultaneously");    }    if (!commandLine.hasOption("port") && !commandLine.hasOption("host") && !commandLine.hasOption("rpcProps")) {        throw new ParseException("Either --rpcProps or both --host and --port " + "must be specified.");    }    if (commandLine.hasOption("rpcProps")) {        rpcClientPropsFile = commandLine.getOptionValue("rpcProps");        Preconditions.checkNotNull(rpcClientPropsFile, "RPC client properties " + "file must be specified after --rpcProps argument.");        Preconditions.checkArgument(new File(rpcClientPropsFile).exists(), "RPC client properties file %s does not exist!", rpcClientPropsFile);    }    if (rpcClientPropsFile == null) {        if (!commandLine.hasOption("port")) {            throw new ParseException("You must specify a port to connect to with --port");        }        port = Integer.parseInt(commandLine.getOptionValue("port"));        if (!commandLine.hasOption("host")) {            throw new ParseException("You must specify a hostname to connect to with --host");        }        hostname = commandLine.getOptionValue("host");    }    fileName = commandLine.getOptionValue("filename");    dirName = commandLine.getOptionValue("dirname");    if (commandLine.hasOption("headerFile")) {        parseHeaders(commandLine);    }    return true;}
c11ed181a9cb0617f62868a61ae840e405e0eea19813358637b681c313c59719
run
private void run() throws IOException, FlumeException, EventDeliveryException
{    EventReader reader = null;    RpcClient rpcClient;    if (rpcClientPropsFile != null) {        rpcClient = RpcClientFactory.getInstance(new File(rpcClientPropsFile));    } else {        rpcClient = RpcClientFactory.getDefaultInstance(hostname, port, BATCH_SIZE);    }    try {        if (fileName != null) {            reader = new SimpleTextLineEventReader(new FileReader(new File(fileName)));        } else if (dirName != null) {            reader = new ReliableSpoolingFileEventReader.Builder().spoolDirectory(new File(dirName)).sourceCounter(new SourceCounter("avrocli")).build();        } else {            reader = new SimpleTextLineEventReader(new InputStreamReader(System.in));        }        long lastCheck = System.currentTimeMillis();        long sentBytes = 0;        int batchSize = rpcClient.getBatchSize();        List<Event> events;        while (!(events = reader.readEvents(batchSize)).isEmpty()) {            for (Event event : events) {                event.setHeaders(headers);                sentBytes += event.getBody().length;                sent++;                long now = System.currentTimeMillis();                if (now >= lastCheck + 5000) {                    logger.debug("Packed {} bytes, {} events", sentBytes, sent);                    lastCheck = now;                }            }            rpcClient.appendBatch(events);            if (reader instanceof ReliableEventReader) {                ((ReliableEventReader) reader).commit();            }        }        logger.debug("Finished");    } finally {        if (reader != null) {            logger.debug("Closing reader");            reader.close();        }        logger.debug("Closing RPC client");        rpcClient.close();    }}
f2e5c6694fd1af47fcb59007bdb5fa6e9b86abb1e9d6d917ef21e1d810274c74
getCandidateFiles
private List<File> getCandidateFiles(final Path directory)
{    Preconditions.checkNotNull(directory);    final List<File> candidateFiles = new ArrayList<>();    try {        final Set<Path> trackerDirCompletedFiles = getTrackerDirCompletedFiles();        Files.walkFileTree(directory, new SimpleFileVisitor<Path>() {            @Override            public FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) throws IOException {                if (directory.equals(dir)) {                                        return FileVisitResult.CONTINUE;                }                String directoryName = dir.getFileName().toString();                if (!recursiveDirectorySearch || directoryName.startsWith(".") || ignorePattern.matcher(directoryName).matches()) {                    return FileVisitResult.SKIP_SUBTREE;                }                return FileVisitResult.CONTINUE;            }            @Override            public FileVisitResult visitFile(Path candidate, BasicFileAttributes attrs) throws IOException {                String fileName = candidate.getFileName().toString();                if (!fileName.endsWith(completedSuffix) && !isFileInTrackerDir(trackerDirCompletedFiles, candidate) && !fileName.startsWith(".") && includePattern.matcher(fileName).matches() && !ignorePattern.matcher(fileName).matches()) {                    candidateFiles.add(candidate.toFile());                }                return FileVisitResult.CONTINUE;            }        });    } catch (IOException e) {        logger.error("I/O exception occurred while listing directories. " + "Files already matched will be returned. " + directory, e);        sourceCounter.incrementGenericProcessingFail();    }    return candidateFiles;}
69a6be06b24a615260f3fd3c8200c8b2b084204987790b826896c35bb72841d2
preVisitDirectory
public FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) throws IOException
{    if (directory.equals(dir)) {                return FileVisitResult.CONTINUE;    }    String directoryName = dir.getFileName().toString();    if (!recursiveDirectorySearch || directoryName.startsWith(".") || ignorePattern.matcher(directoryName).matches()) {        return FileVisitResult.SKIP_SUBTREE;    }    return FileVisitResult.CONTINUE;}
9ad7049089dfe9b65270bf434ee8e30307bb8afd27f19dd45416de2f01bba1ba
visitFile
public FileVisitResult visitFile(Path candidate, BasicFileAttributes attrs) throws IOException
{    String fileName = candidate.getFileName().toString();    if (!fileName.endsWith(completedSuffix) && !isFileInTrackerDir(trackerDirCompletedFiles, candidate) && !fileName.startsWith(".") && includePattern.matcher(fileName).matches() && !ignorePattern.matcher(fileName).matches()) {        candidateFiles.add(candidate.toFile());    }    return FileVisitResult.CONTINUE;}
0a03b81c68dbbf3dfe69a7587a2fecf6a56e94c8bf14adc8e7b3a9bb964b02c3
getTrackerDirCompletedFiles
private Set<Path> getTrackerDirCompletedFiles() throws IOException
{    final Set<Path> completedFiles = new HashSet<>();    if (TrackingPolicy.TRACKER_DIR != trackingPolicy) {        return completedFiles;    }    Path trackerDirPath = trackerDirectory.toPath();    Files.walkFileTree(trackerDirPath, new SimpleFileVisitor<Path>() {        @Override        public FileVisitResult visitFile(Path candidate, BasicFileAttributes attrs) throws IOException {            String fileName = candidate.getFileName().toString();            if (fileName.endsWith(completedSuffix)) {                completedFiles.add(candidate.toAbsolutePath());            }            return FileVisitResult.CONTINUE;        }    });    return completedFiles;}
9ad7049089dfe9b65270bf434ee8e30307bb8afd27f19dd45416de2f01bba1ba
visitFile
public FileVisitResult visitFile(Path candidate, BasicFileAttributes attrs) throws IOException
{    String fileName = candidate.getFileName().toString();    if (fileName.endsWith(completedSuffix)) {        completedFiles.add(candidate.toAbsolutePath());    }    return FileVisitResult.CONTINUE;}
734b53dffb348b14a31edfe85b283049fd0084cd342af39f1860d3aed27df1d6
isFileInTrackerDir
private boolean isFileInTrackerDir(Set<Path> completedFiles, Path path)
{    Path relPath = getRelPathToSpoolDir(path);    Path trackerPath = Paths.get(trackerDirectoryAbsolutePath, relPath.toString() + completedSuffix);    return completedFiles.contains(trackerPath);}
ccebe6c02246a418ab0dd11ed52f821daa0ebb39b1819a0d350c5ecde812f0c2
getRelPathToSpoolDir
private Path getRelPathToSpoolDir(Path path)
{    return spoolDirPath.relativize(path.toAbsolutePath());}
731fc9c478fe37065587cbe0c91246be285a4261265f44be26ca8282742531e9
getListFilesCount
 int getListFilesCount()
{    return listFilesCount;}
babd44a619ec30cadf628dd50e725d19849759784079942495e8fb2909d473bc
getLastFileRead
public String getLastFileRead()
{    if (!lastFileRead.isPresent()) {        return null;    }    return lastFileRead.get().getFile().getAbsolutePath();}
faacd45ce21d1cbb584374a868166f2921664ee3631184fbc58c2a737d41fefb
readEvent
public Event readEvent() throws IOException
{    List<Event> events = readEvents(1);    if (!events.isEmpty()) {        return events.get(0);    } else {        return null;    }}
54fb38a1d197eddb2b60ecdecace63039e95c1beccdbf2a178d1f6dbdaf9e966
readEvents
public List<Event> readEvents(int numEvents) throws IOException
{    if (!committed) {        if (!currentFile.isPresent()) {            throw new IllegalStateException("File should not roll when " + "commit is outstanding.");        }        logger.info("Last read was never committed - resetting mark position.");        currentFile.get().getDeserializer().reset();    } else {                if (!currentFile.isPresent()) {            currentFile = getNextFile();        }                if (!currentFile.isPresent()) {            return Collections.emptyList();        }    }    List<Event> events = readDeserializerEvents(numEvents);    /* It's possible that the last read took us just up to a file boundary.     * If so, try to roll to the next file, if there is one.     * Loop until events is not empty or there is no next file in case of 0 byte files */    while (events.isEmpty()) {        logger.info("Last read took us just up to a file boundary. " + "Rolling to the next file, if there is one.");        retireCurrentFile();        currentFile = getNextFile();        if (!currentFile.isPresent()) {            return Collections.emptyList();        }        events = readDeserializerEvents(numEvents);    }    fillHeader(events);    committed = false;    lastFileRead = currentFile;    return events;}
cd21502b92f5cf06c7b8b6a85a09e1df4c486a48c37708b64da76a475c37f113
readDeserializerEvents
private List<Event> readDeserializerEvents(int numEvents) throws IOException
{    EventDeserializer des = currentFile.get().getDeserializer();    List<Event> events = des.readEvents(numEvents);    if (events.isEmpty() && firstTimeRead) {        events.add(EventBuilder.withBody(new byte[0]));    }    firstTimeRead = false;    return events;}
58d7ccd724ddfb00e03a5d56e7cb09c5811c87d1eafb1e98bb3b172162274766
fillHeader
private void fillHeader(List<Event> events)
{    if (annotateFileName) {        String filename = currentFile.get().getFile().getAbsolutePath();        for (Event event : events) {            event.getHeaders().put(fileNameHeader, filename);        }    }    if (annotateBaseName) {        String basename = currentFile.get().getFile().getName();        for (Event event : events) {            event.getHeaders().put(baseNameHeader, basename);        }    }}
e0823f55b3a09d41a3e1e792f7e6687db9199c2db9b29e9922d93cbdc6f1284b
close
public void close() throws IOException
{    if (currentFile.isPresent()) {        currentFile.get().getDeserializer().close();        currentFile = Optional.absent();    }}
9686b51f14ae68fc049f472c7635d5385053dc8384dae21aaed20cdf86644fa0
commit
public void commit() throws IOException
{    if (!committed && currentFile.isPresent()) {        currentFile.get().getDeserializer().mark();        committed = true;    }}
d1d90ef5f8b0e15896ad458ed1bcb8ae020f371e0272c1e8de59f912c8dcfb1f
retireCurrentFile
private void retireCurrentFile() throws IOException
{    Preconditions.checkState(currentFile.isPresent());    File fileToRoll = new File(currentFile.get().getFile().getAbsolutePath());    currentFile.get().getDeserializer().close();        if (fileToRoll.lastModified() != currentFile.get().getLastModified()) {        String message = "File has been modified since being read: " + fileToRoll;        throw new IllegalStateException(message);    }    if (fileToRoll.length() != currentFile.get().getLength()) {        String message = "File has changed size since being read: " + fileToRoll;        throw new IllegalStateException(message);    }    if (deletePolicy.equalsIgnoreCase(DeletePolicy.NEVER.name())) {        if (trackingPolicy == TrackingPolicy.RENAME) {            rollCurrentFile(fileToRoll);        } else {            rollCurrentFileInTrackerDir(fileToRoll);        }    } else if (deletePolicy.equalsIgnoreCase(DeletePolicy.IMMEDIATE.name())) {        deleteCurrentFile(fileToRoll);    } else {                throw new IllegalArgumentException("Unsupported delete policy: " + deletePolicy);    }}
bafd3d844a1ee0bc8efd82dcae47cb7b8ee2e7528669779f72330ec14b35186f
rollCurrentFile
private void rollCurrentFile(File fileToRoll) throws IOException
{    File dest = new File(fileToRoll.getPath() + completedSuffix);    logger.info("Preparing to move file {} to {}", fileToRoll, dest);        if (dest.exists() && PlatformDetect.isWindows()) {        /*       * If we are here, it means the completed file already exists. In almost       * every case this means the user is violating an assumption of Flume       * (that log files are placed in the spooling directory with unique       * names). However, there is a corner case on Windows systems where the       * file was already rolled but the rename was not atomic. If that seems       * likely, we let it pass with only a warning.       */        if (com.google.common.io.Files.equal(currentFile.get().getFile(), dest)) {            logger.warn("Completed file " + dest + " already exists, but files match, so continuing.");            boolean deleted = fileToRoll.delete();            if (!deleted) {                logger.error("Unable to delete file " + fileToRoll.getAbsolutePath() + ". It will likely be ingested another time.");                sourceCounter.incrementGenericProcessingFail();            }        } else {            String message = "File name has been re-used with different" + " files. Spooling assumptions violated for " + dest;            throw new IllegalStateException(message);        }        } else if (dest.exists()) {        String message = "File name has been re-used with different" + " files. Spooling assumptions violated for " + dest;        throw new IllegalStateException(message);        } else {        boolean renamed = fileToRoll.renameTo(dest);        if (renamed) {            logger.debug("Successfully rolled file {} to {}", fileToRoll, dest);                        deleteMetaFile();        } else {            /* If we are here then the file cannot be renamed for a reason other         * than that the destination file exists (actually, that remains         * possible w/ small probability due to TOC-TOU conditions).*/            String message = "Unable to move " + fileToRoll + " to " + dest + ". This will likely cause duplicate events. Please verify that " + "flume has sufficient permissions to perform these operations.";            throw new FlumeException(message);        }    }}
d07711cf42a79b2d83dab639bddcc2971510bf0176872ed5601ceee5eac0e93f
rollCurrentFileInTrackerDir
private void rollCurrentFileInTrackerDir(File fileToRoll) throws IOException
{    Path path = fileToRoll.toPath();    Path relToRoll = getRelPathToSpoolDir(path);    File dest = new File(trackerDirectory.getPath(), relToRoll + completedSuffix);    logger.info("Preparing to create tracker file for {} at {}", fileToRoll, dest);    if (dest.exists()) {        String message = "File name has been re-used with different" + " files. Spooling assumptions violated for " + dest;        throw new IllegalStateException(message);    }            dest.getParentFile().mkdirs();    if (!dest.createNewFile()) {        throw new IOException("Could not create tracker file: " + dest);    }}
758288cf7e5f760db6811162fe8ebc467e3fd8a1a7e52b19b48d8420a3c56f1c
deleteCurrentFile
private void deleteCurrentFile(File fileToDelete) throws IOException
{    logger.info("Preparing to delete file {}", fileToDelete);    if (!fileToDelete.exists()) {        logger.warn("Unable to delete nonexistent file: {}", fileToDelete);        return;    }    if (!fileToDelete.delete()) {        throw new IOException("Unable to delete spool file: " + fileToDelete);    }        deleteMetaFile();}
710b227e19206f86bdfa7f8d8851c93cba27cfb1c85412f4227f82c6bef9c8ac
getNextFile
private Optional<FileInfo> getNextFile()
{    List<File> candidateFiles = Collections.emptyList();    if (consumeOrder != ConsumeOrder.RANDOM || candidateFileIter == null || !candidateFileIter.hasNext()) {        candidateFiles = getCandidateFiles(spoolDirectory.toPath());        listFilesCount++;        candidateFileIter = candidateFiles.iterator();    }    if (!candidateFileIter.hasNext()) {                return Optional.absent();    }    File selectedFile = candidateFileIter.next();    if (consumeOrder == ConsumeOrder.RANDOM) {                return openFile(selectedFile);    } else if (consumeOrder == ConsumeOrder.YOUNGEST) {        for (File candidateFile : candidateFiles) {            long compare = selectedFile.lastModified() - candidateFile.lastModified();            if (compare == 0) {                                selectedFile = smallerLexicographical(selectedFile, candidateFile);            } else if (compare < 0) {                                selectedFile = candidateFile;            }        }    } else {                for (File candidateFile : candidateFiles) {            long compare = selectedFile.lastModified() - candidateFile.lastModified();            if (compare == 0) {                                selectedFile = smallerLexicographical(selectedFile, candidateFile);            } else if (compare > 0) {                                selectedFile = candidateFile;            }        }    }    firstTimeRead = true;    return openFile(selectedFile);}
e1cbe42374516ade5787788846e1a44544dc70f3bb99629eabc9a6956df971cb
smallerLexicographical
private File smallerLexicographical(File f1, File f2)
{    if (f1.getName().compareTo(f2.getName()) < 0) {        return f1;    }    return f2;}
b0be0b0cb18670988808158eb600d395122ede4aeb2dca88b744f06db960ba9b
openFile
private Optional<FileInfo> openFile(File file)
{    try {                String nextPath = file.getPath();        PositionTracker tracker = DurablePositionTracker.getInstance(metaFile, nextPath);        if (!tracker.getTarget().equals(nextPath)) {            tracker.close();            deleteMetaFile();            tracker = DurablePositionTracker.getInstance(metaFile, nextPath);        }                Preconditions.checkState(tracker.getTarget().equals(nextPath), "Tracker target %s does not equal expected filename %s", tracker.getTarget(), nextPath);        ResettableInputStream in = new ResettableFileInputStream(file, tracker, ResettableFileInputStream.DEFAULT_BUF_SIZE, inputCharset, decodeErrorPolicy);        EventDeserializer deserializer = EventDeserializerFactory.getInstance(deserializerType, deserializerContext, in);        return Optional.of(new FileInfo(file, deserializer));    } catch (FileNotFoundException e) {                logger.warn("Could not find file: " + file, e);        return Optional.absent();    } catch (IOException e) {        logger.error("Exception opening file: " + file, e);        sourceCounter.incrementGenericProcessingFail();        return Optional.absent();    }}
4515158d664d17dd12c6e629fd53e0b4446de3d0f8f5063a8797311f1ffcc9dc
deleteMetaFile
private void deleteMetaFile() throws IOException
{    if (metaFile.exists() && !metaFile.delete()) {        throw new IOException("Unable to delete old meta file " + metaFile);    }}
06efe89013376b2c8901b8c2f25c9d64c09dc3ad3ebdfda3159e0662716680cc
getLength
public long getLength()
{    return length;}
2ec784375f5f3608678998e41354a271f8bfe208c827c31b5e5d990a02005727
getLastModified
public long getLastModified()
{    return lastModified;}
5b86cf63624fbc9eb2d0cbde5d6539abbb48fd854348f33953f8a2fc9ebed403
getDeserializer
public EventDeserializer getDeserializer()
{    return deserializer;}
ce0460f83bd172eacce98e8169f6d9b1d4ec316943fcf77ee2d8f12bbe7327a0
getFile
public File getFile()
{    return file;}
83aade48da0d3c048ea75417bbdffc1a922ed6f64b949e9e2dfb5e2de1f78418
spoolDirectory
public Builder spoolDirectory(File directory)
{    this.spoolDirectory = directory;    return this;}
88182175980eb15932e89ae91c24c856cac61466e9ab632552a301f93ba0ee43
completedSuffix
public Builder completedSuffix(String completedSuffix)
{    this.completedSuffix = completedSuffix;    return this;}
b2f8e1ad20728d28babd1b0a5c73108b6614b89c343e18e41d3e409c6e6e12c7
includePattern
public Builder includePattern(String includePattern)
{    this.includePattern = includePattern;    return this;}
23dc8ae1ef381646fe158f6ffc967c4c212f0128a4b38cb9381e9bb5fbd31477
ignorePattern
public Builder ignorePattern(String ignorePattern)
{    this.ignorePattern = ignorePattern;    return this;}
0a6909c0c765d57b1c92e40a48d5d595eddda288c6ca3d8845df40f834f59539
trackerDirPath
public Builder trackerDirPath(String trackerDirPath)
{    this.trackerDirPath = trackerDirPath;    return this;}
5b8d31006cea65fd26624f9e92d17bb6e047192eec78433a61e92aca9b9faf6f
annotateFileName
public Builder annotateFileName(Boolean annotateFileName)
{    this.annotateFileName = annotateFileName;    return this;}
53247e4bffb761586708fd2345c8c0bc70564feb02006216a5af0c09d165a476
fileNameHeader
public Builder fileNameHeader(String fileNameHeader)
{    this.fileNameHeader = fileNameHeader;    return this;}
5b56ff6e810aeb9d1040df42b13199df6b4607ca1946eee3fe05f9b88274b8c2
annotateBaseName
public Builder annotateBaseName(Boolean annotateBaseName)
{    this.annotateBaseName = annotateBaseName;    return this;}
0579763a48a2cb48fd8c5587ce970b48e92e189a56adaabafcea029ea22faee4
baseNameHeader
public Builder baseNameHeader(String baseNameHeader)
{    this.baseNameHeader = baseNameHeader;    return this;}
66c6f766b6c92027b5e368bd29f6257bac42692f517c5535bec0c2f4441b4f7a
deserializerType
public Builder deserializerType(String deserializerType)
{    this.deserializerType = deserializerType;    return this;}
88ce3f3b7eab060b5ab757b5c9ef4f2b803e4bdb3a245ab36e8e3757e7538698
deserializerContext
public Builder deserializerContext(Context deserializerContext)
{    this.deserializerContext = deserializerContext;    return this;}
8da4f09354cf83c0af5b6c14e743183440125459e5aae6a70b346426cd9c0c32
deletePolicy
public Builder deletePolicy(String deletePolicy)
{    this.deletePolicy = deletePolicy;    return this;}
e250670ee16a3460284364d4f14f2dc028468939fc8626a0abb70ee4c680df9b
trackingPolicy
public Builder trackingPolicy(String trackingPolicy)
{    this.trackingPolicy = trackingPolicy;    return this;}
2f6429b651505585b4c669d42db9bf39433bc0c7b5783cd25379321a61c3c911
inputCharset
public Builder inputCharset(String inputCharset)
{    this.inputCharset = inputCharset;    return this;}
eb40b2492a50a69ad5e028e64498e2e564f0d49d1d7b1b2a7b5905caf6947ef9
recursiveDirectorySearch
public Builder recursiveDirectorySearch(boolean recursiveDirectorySearch)
{    this.recursiveDirectorySearch = recursiveDirectorySearch;    return this;}
15cd17ac29bb1b0d193fd4745a7bd69e97751ab54a59ba047ecd06fbd2c9c45e
decodeErrorPolicy
public Builder decodeErrorPolicy(DecodeErrorPolicy decodeErrorPolicy)
{    this.decodeErrorPolicy = decodeErrorPolicy;    return this;}
1670636e6a11fba7ec72a20f67b8ce023423d6dc2b67c46a0a6b00d858e31072
consumeOrder
public Builder consumeOrder(ConsumeOrder consumeOrder)
{    this.consumeOrder = consumeOrder;    return this;}
169e0de3c6a6a0bd2727fb43b5485756d0e0c83fde0e1cb5cdbfca449ef6065a
sourceCounter
public Builder sourceCounter(SourceCounter sourceCounter)
{    this.sourceCounter = sourceCounter;    return this;}
a51d76a371b8edb89e0c172c092588c48d0f61ffd8632f10ded503f6d34ef745
build
public ReliableSpoolingFileEventReader build() throws IOException
{    return new ReliableSpoolingFileEventReader(spoolDirectory, completedSuffix, includePattern, ignorePattern, trackerDirPath, annotateFileName, fileNameHeader, annotateBaseName, baseNameHeader, deserializerType, deserializerContext, deletePolicy, trackingPolicy, inputCharset, decodeErrorPolicy, consumeOrder, recursiveDirectorySearch, sourceCounter);}
faacd45ce21d1cbb584374a868166f2921664ee3631184fbc58c2a737d41fefb
readEvent
public Event readEvent() throws IOException
{    String line = reader.readLine();    if (line != null) {        return EventBuilder.withBody(line, Charsets.UTF_8);    } else {        return null;    }}
6b354b7e97da36f5175fcf18e7e097ce33c1dd93a1e511aa16359a5ecde5e7ab
readEvents
public List<Event> readEvents(int n) throws IOException
{    List<Event> events = Lists.newLinkedList();    while (events.size() < n) {        Event event = readEvent();        if (event != null) {            events.add(event);        } else {            break;        }    }    return events;}
e0823f55b3a09d41a3e1e792f7e6687db9199c2db9b29e9922d93cbdc6f1284b
close
public void close() throws IOException
{    reader.close();}
6db50b48fedff04156d28c3afc75a9fa77b78fc148a88704bc501d7e66a740b6
configure
public static boolean configure(Object target, Context context)
{    if (target instanceof Configurable) {        ((Configurable) target).configure(context);        return true;    }    return false;}
711d5104afeac2fb5edfb59e743bd7532bd42781609cd6f4a4621904dc4eef61
configure
public static boolean configure(Object target, ComponentConfiguration conf)
{    if (target instanceof ConfigurableComponent) {        ((ConfigurableComponent) target).configure(conf);        return true;    }    return false;}
d7bf838e869ad13e6d722a4e561dea8d4a00ef6be0dd2270e6b7c638d8fd0830
ensureRequiredNonNull
public static void ensureRequiredNonNull(Context context, String... keys)
{    for (String key : keys) {        if (!context.getParameters().containsKey(key) || context.getParameters().get(key) == null) {            throw new IllegalArgumentException("Required parameter " + key + " must exist and may not be null");        }    }}
ccd5ebd37d0d4a597561b442aed8bfcafcfff55e5cfb97592affc3d5d7d70387
ensureOptionalNonNull
public static void ensureOptionalNonNull(Context context, String... keys)
{    for (String key : keys) {        if (context.getParameters().containsKey(key) && context.getParameters().get(key) == null) {            throw new IllegalArgumentException("Optional parameter " + key + " may not be null");        }    }}
07fba08828022872e7a053fe158ceccf89afe18e4fdbf64016ee88925ebeba00
get
public synchronized Long get(String name)
{    return getCounter(name).get();}
b6d29b7ef0ec220ca9dca250d47a2f82d2fa877f8a12349c14fdfdba90252200
incrementAndGet
public synchronized Long incrementAndGet(String name)
{    return getCounter(name).incrementAndGet();}
eef68a7d6b910190d21cee3d628407426801675938b0fa6d86a59fdaeda4995f
addAndGet
public synchronized Long addAndGet(String name, Long delta)
{    return getCounter(name).addAndGet(delta);}
b0f65b412436a712ffced49953ec24bd05fa34083c068b17f44596dba20a9011
add
public synchronized void add(CounterGroup counterGroup)
{    synchronized (counterGroup) {        for (Entry<String, AtomicLong> entry : counterGroup.getCounters().entrySet()) {            addAndGet(entry.getKey(), entry.getValue().get());        }    }}
d10390532ada97bf4c37e4bbb648cc87df95cd19969832247ff0edf8d3c2cf3f
set
public synchronized void set(String name, Long value)
{    getCounter(name).set(value);}
7e0e14e0e3576f5955bc9ea6c6cd67a0075b8ee4f219977c520552afbb31520e
getCounter
public synchronized AtomicLong getCounter(String name)
{    if (!counters.containsKey(name)) {        counters.put(name, new AtomicLong());    }    return counters.get(name);}
ced683865ec943e6fb0f59cfe94f9b041011464836da39fedb553752fdfb3495
toString
public synchronized String toString()
{    return "{ name:" + name + " counters:" + counters + " }";}
5a8aa5c66e12ab4bee0bd8ab8101da1e45260314118196130f684c97aec2075b
getName
public synchronized String getName()
{    return name;}
831a1aefa333c15f969e26873201d65e004e9eae64fe390a121d56ac6619f888
setName
public synchronized void setName(String name)
{    this.name = name;}
054117660707c6da86a90b191946520b8285c0aecbaa1bda6be7f5cfa98f4206
getCounters
public synchronized HashMap<String, AtomicLong> getCounters()
{    return counters;}
1945f8699844c8dfe25fc5392006ce975a18aaf8ed2ad3774c2112a73d1287a4
setCounters
public synchronized void setCounters(HashMap<String, AtomicLong> counters)
{    this.counters = counters;}
fd3e26e8732c3153223cf3a2012e9ef58a99859d8aa647fd73890f6d01798163
dumpEvent
public static String dumpEvent(Event event)
{    return dumpEvent(event, DEFAULT_MAX_BYTES);}
384df930818ab635b8269d89dded93f3d62833d75b2a6dfea69fb2468c940cc8
dumpEvent
public static String dumpEvent(Event event, int maxBytes)
{    StringBuilder buffer = new StringBuilder();    if (event == null || event.getBody() == null) {        buffer.append("null");    } else if (event.getBody().length == 0) {        } else {        byte[] body = event.getBody();        byte[] data = Arrays.copyOf(body, Math.min(body.length, maxBytes));        ByteArrayOutputStream out = new ByteArrayOutputStream();        try {            HexDump.dump(data, 0, out, 0);            String hexDump = new String(out.toByteArray());                        if (hexDump.startsWith(HEXDUMP_OFFSET)) {                hexDump = hexDump.substring(HEXDUMP_OFFSET.length());            }            buffer.append(hexDump);        } catch (Exception e) {            if (LOGGER.isInfoEnabled()) {                LOGGER.info("Exception while dumping event", e);            }            buffer.append("...Exception while dumping: ").append(e.getMessage());        }        String result = buffer.toString();        if (result.endsWith(EOL) && buffer.length() > EOL.length()) {            buffer.delete(buffer.length() - EOL.length(), buffer.length()).toString();        }    }    return "{ headers:" + event.getHeaders() + " body:" + buffer + " }";}
cc25f2e1132b63178604b643e38e093461b774b9dbdac953b48415b446f5eae2
containsTag
public static boolean containsTag(String in)
{    return tagPattern.matcher(in).find();}
ec50ce8fb4551d3e9ca562512b77d8f0985578d59430c8f5ab3c402b2849d8b7
expandShorthand
public static String expandShorthand(char c)
{        switch(c) {        case 'a':            return "weekday_short";        case 'A':            return "weekday_full";        case 'b':            return "monthname_short";        case 'B':            return "monthname_full";        case 'c':            return "datetime";        case 'd':                        return "day_of_month_xx";        case 'e':                        return "day_of_month_x";        case 'D':                        return "date_short";        case 'H':            return "hour_24_xx";        case 'I':            return "hour_12_xx";        case 'j':                        return "day_of_year_xxx";        case 'k':                        return "hour_24";        case 'l':                        return "hour_12";        case 'm':            return "month_xx";        case 'n':                        return "month_x";        case 'M':            return "minute_xx";        case 'p':            return "am_pm";        case 's':            return "unix_seconds";        case 'S':            return "seconds_xx";        case 't':                        return "unix_millis";        case 'y':            return "year_xx";        case 'Y':            return "year_xxxx";        case 'z':            return "timezone_delta";        default:                        return "" + c;    }}
94f0e581081fb7de26936dc77ba4bb3acc4c9d584eff825e3c8e7869e7eb7a34
replaceShorthand
public static String replaceShorthand(char c, Map<String, String> headers)
{    return replaceShorthand(c, headers, false, 0, 0);}
8ce009143fb83b1099a41664b6acbcdd213ac58fa94d926f83febfc0bcee199d
replaceShorthand
public static String replaceShorthand(char c, Map<String, String> headers, boolean needRounding, int unit, int roundDown)
{    return replaceShorthand(c, headers, null, needRounding, unit, roundDown, false);}
4a07b036cab6e49845928a560789ae1009ec153e638bdd28b2c7c7f98231d8f4
replaceShorthand
public static String replaceShorthand(char c, Map<String, String> headers, TimeZone timeZone, boolean needRounding, int unit, int roundDown, boolean useLocalTimestamp)
{    long ts = 0;    if (useLocalTimestamp) {        ts = clock.currentTimeMillis();    }    return replaceShorthand(c, headers, timeZone, needRounding, unit, roundDown, false, ts);}
39777ac3cd06bcf7436ff5134bffddf97b090e76d01a8c7a212e2f6265658d01
initialValue
protected HashMap<String, SimpleDateFormat> initialValue()
{    return new HashMap<String, SimpleDateFormat>();}
6f491d734a371b60f29388bc8da402337077ee6e2bb9087449eb3b8bd7fc3030
getSimpleDateFormat
protected static SimpleDateFormat getSimpleDateFormat(String string)
{    HashMap<String, SimpleDateFormat> localCache = simpleDateFormatCache.get();    SimpleDateFormat simpleDateFormat = localCache.get(string);    if (simpleDateFormat == null) {        simpleDateFormat = new SimpleDateFormat(string);        localCache.put(string, simpleDateFormat);        simpleDateFormatCache.set(localCache);    }    return simpleDateFormat;}
27006b7fb8466ea2aec0bfd4d8a8c86bf8bb66c0b99eef9adfd68f3323d32463
replaceStaticString
protected static String replaceStaticString(String key)
{    String replacementString = "";    switch(key.toLowerCase()) {        case "localhost":            replacementString = InetAddressCache.hostName;            break;        case "ip":            replacementString = InetAddressCache.hostAddress;            break;        case "fqdn":            replacementString = InetAddressCache.canonicalHostName;            break;        default:            throw new RuntimeException("The static escape string '" + key + "'" + " was provided but does not match any of (localhost,IP,FQDN)");    }    return replacementString;}
1e63514a77d034161924c018b2be4cfc5370045d6b604b08401f1206e24d937c
replaceShorthand
protected static String replaceShorthand(char c, Map<String, String> headers, TimeZone timeZone, boolean needRounding, int unit, int roundDown, boolean useLocalTimestamp, long ts)
{    String timestampHeader = null;    try {        if (!useLocalTimestamp) {            timestampHeader = headers.get("timestamp");            Preconditions.checkNotNull(timestampHeader, "Expected timestamp in " + "the Flume event headers, but it was null");            ts = Long.valueOf(timestampHeader);        } else {            timestampHeader = String.valueOf(ts);        }    } catch (NumberFormatException e) {        throw new RuntimeException("Flume wasn't able to parse timestamp header" + " in the event to resolve time based bucketing. Please check that" + " you're correctly populating timestamp header (for example using" + " TimestampInterceptor source interceptor).", e);    }    if (needRounding) {        ts = roundDown(roundDown, unit, ts, timeZone);    }        String formatString = "";    switch(c) {        case '%':            return "%";        case 'a':            formatString = "EEE";            break;        case 'A':            formatString = "EEEE";            break;        case 'b':            formatString = "MMM";            break;        case 'B':            formatString = "MMMM";            break;        case 'c':            formatString = "EEE MMM d HH:mm:ss yyyy";            break;        case 'd':            formatString = "dd";            break;        case 'e':            formatString = "d";            break;        case 'D':            formatString = "MM/dd/yy";            break;        case 'H':            formatString = "HH";            break;        case 'I':            formatString = "hh";            break;        case 'j':            formatString = "DDD";            break;        case 'k':            formatString = "H";            break;        case 'l':            formatString = "h";            break;        case 'm':            formatString = "MM";            break;        case 'M':            formatString = "mm";            break;        case 'n':            formatString = "M";            break;        case 'p':            formatString = "a";            break;        case 's':            return "" + (ts / 1000);        case 'S':            formatString = "ss";            break;        case 't':                        return timestampHeader;        case 'y':            formatString = "yy";            break;        case 'Y':            formatString = "yyyy";            break;        case 'z':            formatString = "ZZZ";            break;        default:                        return "";    }    SimpleDateFormat format = getSimpleDateFormat(formatString);    if (timeZone != null) {        format.setTimeZone(timeZone);    } else {        format.setTimeZone(TimeZone.getDefault());    }    Date date = new Date(ts);    return format.format(date);}
d7479c95ec99453e2c7d2708b517cd64015f115cc8a4c07bb55a02e981be37bd
roundDown
private static long roundDown(int roundDown, int unit, long ts, TimeZone timeZone)
{    long timestamp = ts;    if (roundDown <= 0) {        roundDown = 1;    }    switch(unit) {        case Calendar.SECOND:            timestamp = TimestampRoundDownUtil.roundDownTimeStampSeconds(ts, roundDown, timeZone);            break;        case Calendar.MINUTE:            timestamp = TimestampRoundDownUtil.roundDownTimeStampMinutes(ts, roundDown, timeZone);            break;        case Calendar.HOUR_OF_DAY:            timestamp = TimestampRoundDownUtil.roundDownTimeStampHours(ts, roundDown, timeZone);            break;        default:            timestamp = ts;            break;    }    return timestamp;}
0b53e3092d3d70268f4c71d2ddaab12e7c8246b1657824db87159a30f7ce84fc
escapeString
public static String escapeString(String in, Map<String, String> headers)
{    return escapeString(in, headers, false, 0, 0);}
1fdf65aee8529bb613dea69ba13b7fc06ac841a185043d4acc7436fc00176618
escapeString
public static String escapeString(String in, Map<String, String> headers, boolean needRounding, int unit, int roundDown)
{    return escapeString(in, headers, null, needRounding, unit, roundDown, false);}
84f160c16a3db5249f5227bc04733d09dbf6e43b5edabf63bab6b9b96f9ca38e
escapeString
public static String escapeString(String in, Map<String, String> headers, TimeZone timeZone, boolean needRounding, int unit, int roundDown, boolean useLocalTimeStamp)
{    long ts = clock.currentTimeMillis();    Matcher matcher = tagPattern.matcher(in);    StringBuffer sb = new StringBuffer();    while (matcher.find()) {        String replacement = "";                if (matcher.group(2) != null) {            replacement = headers.get(matcher.group(2));            if (replacement == null) {                replacement = "";                        }                } else if (matcher.group(3) != null) {            replacement = replaceStaticString(matcher.group(3));        } else {                                                Preconditions.checkState(matcher.group(1) != null && matcher.group(1).length() == 1, "Expected to match single character tag in string " + in);            char c = matcher.group(1).charAt(0);            replacement = replaceShorthand(c, headers, timeZone, needRounding, unit, roundDown, useLocalTimeStamp, ts);        }                                                                                replacement = replacement.replaceAll("\\\\", "\\\\\\\\");        replacement = replacement.replaceAll("\\$", "\\\\\\$");        matcher.appendReplacement(sb, replacement);    }    matcher.appendTail(sb);    return sb.toString();}
3af244eb4659c91423681055d3ca2f71617e55920a57217437c2f1220f0ec5fe
getEscapeMapping
public static Map<String, String> getEscapeMapping(String in, Map<String, String> headers)
{    return getEscapeMapping(in, headers, false, 0, 0);}
8633f0cc9bfcb365b3ee63feb2b5c0678b94ac3796212a3e4b7fa6b9ad7abb83
getEscapeMapping
public static Map<String, String> getEscapeMapping(String in, Map<String, String> headers, boolean needRounding, int unit, int roundDown)
{    Map<String, String> mapping = new HashMap<String, String>();    Matcher matcher = tagPattern.matcher(in);    while (matcher.find()) {        String replacement = "";                if (matcher.group(2) != null) {            replacement = headers.get(matcher.group(2));            if (replacement == null) {                replacement = "";                        }            mapping.put(matcher.group(2), replacement);        } else {                                                Preconditions.checkState(matcher.group(1) != null && matcher.group(1).length() == 1, "Expected to match single character tag in string " + in);            char c = matcher.group(1).charAt(0);            replacement = replaceShorthand(c, headers, needRounding, unit, roundDown);            mapping.put(expandShorthand(c), replacement);        }    }    return mapping;}
344e3f3165a448b0b0fc80952f14e35f312289c5570f6e943dcbfe4919da684a
setClock
public static void setClock(Clock clk)
{    clock = clk;}
6030ca76fb783a15b70521d3d1cb997127b0160e00ecf83bd2bce9d558311500
getClock
public static Clock getClock()
{    return clock;}
ac70fa043de99e03b6b293e164e53b4b54e3a5d2de8e131bd36ff9b52624620a
nextFile
public File nextFile()
{    StringBuilder sb = new StringBuilder();    sb.append(filePrefix).append(seriesTimestamp).append("-");    sb.append(fileIndex.incrementAndGet());    if (extension.length() > 0) {        sb.append(".").append(extension);    }    currentFile = new File(baseDirectory, sb.toString());    return currentFile;}
5ddddbfd18b8f5f9a8d7cb81ba90971d0f4e48448c27a413bfb31148ec64cd59
getCurrentFile
public File getCurrentFile()
{    if (currentFile == null) {        return nextFile();    }    return currentFile;}
522f2ae429fb2c5be76ef28faa36d493ed00b9003568d833f2ff65c3a0ede1d4
rotate
public void rotate()
{    currentFile = null;}
2acea3cc4b7819aa01125c0925485260feb738f0a88afdd8495d74b8d5f12864
getBaseDirectory
public File getBaseDirectory()
{    return baseDirectory;}
09ce29bd77efdaf62d4b0e1fa33457f700f0ee9ef2af0ecb8696e18e3ff5f1e5
setBaseDirectory
public void setBaseDirectory(File baseDirectory)
{    this.baseDirectory = baseDirectory;}
c88e1d08d647730284421c393f18e3866f9a05139b9dd7d72c42b706fef6c7f0
getSeriesTimestamp
public long getSeriesTimestamp()
{    return seriesTimestamp;}
a45881c16ab9e38f31484f692ce1411b032f19370daab3e4040c1c04d984146f
getPrefix
public String getPrefix()
{    return filePrefix;}
dd386f4d75b694f73345347a9b2e46289fee679d7748d4d3eee41cd501d6e88c
getExtension
public String getExtension()
{    return extension;}
d1bd9b44d1ffe4252859df8edf4ec3b4eef354e8bc672541b9b1435e17908ffb
getFileIndex
public AtomicInteger getFileIndex()
{    return fileIndex;}
c422e08675d771dc859d026b05ec2bed433b52dba1b72a2d1669a069bda6abc0
build
public PathManager build(Context context)
{    return new DefaultPathManager(context);}
53bd97ac8dcb0096c3d7f3e4600d466b2e6393a809a5f2e955599a87889ba541
getInstance
public static PathManager getInstance(String managerType, Context context)
{    Preconditions.checkNotNull(managerType, "path manager type must not be null");        PathManagerType type;    try {        type = PathManagerType.valueOf(managerType.toUpperCase(Locale.ENGLISH));    } catch (IllegalArgumentException e) {        logger.debug("Not in enum, loading builder class: {}", managerType);        type = PathManagerType.OTHER;    }    Class<? extends PathManager.Builder> builderClass = type.getBuilderClass();        if (builderClass == null) {        try {            Class c = Class.forName(managerType);            if (c != null && PathManager.Builder.class.isAssignableFrom(c)) {                builderClass = (Class<? extends PathManager.Builder>) c;            } else {                String errMessage = "Unable to instantiate Builder from " + managerType + ": does not appear to implement " + PathManager.Builder.class.getName();                throw new FlumeException(errMessage);            }        } catch (ClassNotFoundException ex) {            logger.error("Class not found: " + managerType, ex);            throw new FlumeException(ex);        }    }        PathManager.Builder builder;    try {        builder = builderClass.newInstance();    } catch (InstantiationException ex) {        String errMessage = "Cannot instantiate builder: " + managerType;        logger.error(errMessage, ex);        throw new FlumeException(errMessage, ex);    } catch (IllegalAccessException ex) {        String errMessage = "Cannot instantiate builder: " + managerType;        logger.error(errMessage, ex);        throw new FlumeException(errMessage, ex);    }    return builder.build(context);}
e35989fdd9d1a36d726aef55f6803fe84e9ebc4936248a9f6a3ba73e4efb9011
getBuilderClass
public Class<? extends PathManager.Builder> getBuilderClass()
{    return builderClass;}
ac70fa043de99e03b6b293e164e53b4b54e3a5d2de8e131bd36ff9b52624620a
nextFile
public File nextFile()
{    StringBuilder sb = new StringBuilder();    String date = formatter.print(LocalDateTime.now());    if (!date.equals(lastRoll)) {        getFileIndex().set(0);        lastRoll = date;    }    sb.append(getPrefix()).append(date).append("-");    sb.append(getFileIndex().incrementAndGet());    if (getExtension().length() > 0) {        sb.append(".").append(getExtension());    }    currentFile = new File(getBaseDirectory(), sb.toString());    return currentFile;}
c422e08675d771dc859d026b05ec2bed433b52dba1b72a2d1669a069bda6abc0
build
public PathManager build(Context context)
{    return new RollTimePathManager(context);}
3d4d6a1e88683106e619144443879009a94e457736c7a0c62eac0aa5b6427b92
format
public byte[] format(Event event)
{    String body = event.getBody().length > 0 ? new String(event.getBody()) : "";    return (body + "\n").getBytes();}
08d638df459482995811ce34aaeb2b42519cbcb39e9d8b822ad0916bcdb70990
getChannelSize
public long getChannelSize()
{    return get(COUNTER_CHANNEL_SIZE);}
4c19de79a019b8b3b12af4f58d47617c276344093788113451caa49e74fa86b6
setChannelSize
public void setChannelSize(long newSize)
{    set(COUNTER_CHANNEL_SIZE, newSize);}
ef53886c398fb2fccfa32cf158a439042407e6fd7a7937aa9a472a03e26b4f41
getEventPutAttemptCount
public long getEventPutAttemptCount()
{    return get(COUNTER_EVENT_PUT_ATTEMPT);}
228878e4cbf39885a5eda68b7e17fbab21a50cb9a6c53e55c1f2ce06231e9cc4
incrementEventPutAttemptCount
public long incrementEventPutAttemptCount()
{    return increment(COUNTER_EVENT_PUT_ATTEMPT);}
b81cb3ba4932236c30559726aebf465809f34af76ac37739a75a11676919308d
getEventTakeAttemptCount
public long getEventTakeAttemptCount()
{    return get(COUNTER_EVENT_TAKE_ATTEMPT);}
27835228802c6603eb7dbcb8b01d8e3947be90d99f67782c72405e43d2b70987
incrementEventTakeAttemptCount
public long incrementEventTakeAttemptCount()
{    return increment(COUNTER_EVENT_TAKE_ATTEMPT);}
99511ea98fcc3713ef420096981e74b93f83a53abbf1a47f532ab78470502c05
getEventPutSuccessCount
public long getEventPutSuccessCount()
{    return get(COUNTER_EVENT_PUT_SUCCESS);}
de0a705dfbfd9320f2ddecd51213461a7594ecbf7a78e97af6a34b06b6f8700e
addToEventPutSuccessCount
public long addToEventPutSuccessCount(long delta)
{    return addAndGet(COUNTER_EVENT_PUT_SUCCESS, delta);}
2b3789c8065a43c271db5f675e809eac542f0d7512e62d0a6c48fd52869b666b
getEventTakeSuccessCount
public long getEventTakeSuccessCount()
{    return get(COUNTER_EVENT_TAKE_SUCCESS);}
9334896fe0bb76c3b903fe472150d5eddb34b31a87c73a828b158c4c31529277
addToEventTakeSuccessCount
public long addToEventTakeSuccessCount(long delta)
{    return addAndGet(COUNTER_EVENT_TAKE_SUCCESS, delta);}
65cb73ebfe40d5c33d2e4e72755eeb55a103a250cb8283a0be0c2a212f197e7b
setChannelCapacity
public void setChannelCapacity(long capacity)
{    set(COUNTER_CHANNEL_CAPACITY, capacity);}
1e7714cd322f186d0349990c12d8972f7ed7c1b5543f0c662e690d09e4e88f4c
getChannelCapacity
public long getChannelCapacity()
{    return get(COUNTER_CHANNEL_CAPACITY);}
21d15a44a8d87d53e7d8b878d687e295d865882ec6a57e4c90647b3f5004bdf6
getChannelFillPercentage
public double getChannelFillPercentage()
{    long capacity = getChannelCapacity();    if (capacity != 0L) {        return (getChannelSize() / (double) capacity) * 100;    }    return Double.MAX_VALUE;}
7d63f633a4a9e6d8776ad2e2c158e816cc009184a98f4929e26a0924b9862731
xdr_string
protected void xdr_string(String s)
{    byte[] bytes = s.getBytes();    int len = bytes.length;    xdr_int(len);    System.arraycopy(bytes, 0, buffer, offset, len);    offset += len;    pad();}
c18a82dc1593cb5dedea43b6bd64c24a0b2b350173ca07e247558ef679f4d5b4
pad
private void pad()
{    int newOffset = ((offset + 3) / 4) * 4;    while (offset < newOffset) {        buffer[offset++] = 0;    }}
cdce792ab979f031b46c3685f72dd530564832eeb0ab4661b865f103f1253e12
xdr_int
protected void xdr_int(int i)
{    buffer[offset++] = (byte) ((i >> 24) & 0xff);    buffer[offset++] = (byte) ((i >> 16) & 0xff);    buffer[offset++] = (byte) ((i >> 8) & 0xff);    buffer[offset++] = (byte) (i & 0xff);}
1ecf8868b73ad03af9bec460f0fc397513bf09ff87318ccae55541dad973eb48
sendToGangliaNodes
public synchronized void sendToGangliaNodes()
{    DatagramPacket packet;    for (SocketAddress addr : addresses) {        try {            packet = new DatagramPacket(buffer, offset, addr);            socket.send(packet);        } catch (Exception ex) {            logger.warn("Could not send metrics to metrics server: " + addr.toString(), ex);        }    }    offset = 0;}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    try {        socket = new DatagramSocket();        hostname = InetAddress.getLocalHost().getHostName();    } catch (SocketException ex) {        logger.error("Could not create socket for metrics collection.");        throw new FlumeException("Could not create socket for metrics collection.", ex);    } catch (Exception ex2) {        logger.warn("Unknown error occured", ex2);    }    for (HostInfo host : hosts) {        addresses.add(new InetSocketAddress(host.getHostName(), host.getPortNumber()));    }    collectorRunnable.server = this;    if (service.isShutdown() || service.isTerminated()) {        service = Executors.newSingleThreadScheduledExecutor();    }    service.scheduleWithFixedDelay(collectorRunnable, 0, pollFrequency, TimeUnit.SECONDS);}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    service.shutdown();    while (!service.isTerminated()) {        try {            logger.warn("Waiting for ganglia service to stop");            service.awaitTermination(500, TimeUnit.MILLISECONDS);        } catch (InterruptedException ex) {            logger.warn("Interrupted while waiting" + " for ganglia monitor to shutdown", ex);            service.shutdownNow();        }    }    addresses.clear();}
85e630751527826e08edf113d222189b92a2223d697a89a55fcc2ddc93c5656b
setPollFrequency
public void setPollFrequency(int pollFrequency)
{    this.pollFrequency = pollFrequency;}
2e8f8e9aacd9380d82051f48e1c1e063a7148513a8c3e97b673038d68865f6a3
getPollFrequency
public int getPollFrequency()
{    return pollFrequency;}
d40ed5663609b3b3e28951391d2bb2a3febf748cc1fab9f56bedcda3621b0531
setIsGanglia3
public void setIsGanglia3(boolean isGanglia3)
{    this.isGanglia3 = isGanglia3;}
9ffd6ae64986901141f4d6583160997610597716c2878d0b0f927f04a7527583
isGanglia3
public boolean isGanglia3()
{    return this.isGanglia3;}
4d949c3bb1ee332e9259759594999fba3e55eb74eba1e1afc1275dbd11bb2d07
createGangliaMessage
protected void createGangliaMessage(String name, String value)
{    logger.debug("Sending ganglia3 formatted message." + name + ": " + value);    name = hostname + "." + name;    xdr_int(0);    String type = "string";    try {        Float.parseFloat(value);        type = "float";    } catch (NumberFormatException ex) {        }        xdr_string(type);    xdr_string(name);    xdr_string(value);    xdr_string(DEFAULT_UNITS);    xdr_int(DEFAULT_SLOPE);    xdr_int(DEFAULT_TMAX);    xdr_int(DEFAULT_DMAX);}
1f7f6002386d14b3c47d615253f01fcac3d4fd31c0cd5c49dadfaaa570e02f16
createGangliaMessage31
protected void createGangliaMessage31(String name, String value)
{    logger.debug("Sending ganglia 3.1 formatted message: " + name + ": " + value);        xdr_int(128);        xdr_string(hostname);        xdr_string(name);        xdr_int(0);    String type = "string";    try {        Float.parseFloat(value);        type = "float";    } catch (NumberFormatException ex) {        }        xdr_string(type);        xdr_string(name);        xdr_string(DEFAULT_UNITS);        xdr_int(DEFAULT_SLOPE);        xdr_int(DEFAULT_TMAX);        xdr_int(DEFAULT_DMAX);    xdr_int(1);    /*Num of the entries in extra_value field for Ganglia 3.1.x*/    xdr_string("GROUP");    /*Group attribute*/    xdr_string("flume");    /*Group value*/    this.sendToGangliaNodes();                        xdr_int(133);        xdr_string(hostname);        xdr_string(name);        xdr_int(0);        xdr_string("%s");        xdr_string(value);}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    this.pollFrequency = context.getInteger(this.CONF_POLL_FREQUENCY, 60);    String localHosts = context.getString(this.CONF_HOSTS);    if (localHosts == null || localHosts.isEmpty()) {        throw new ConfigurationException("Hosts list cannot be empty.");    }    this.hosts = this.getHostsFromString(localHosts);    this.isGanglia3 = context.getBoolean(this.CONF_ISGANGLIA3, false);}
0656d98526934f030288c98b189e79007edb344749405adba1e17481c824a123
getHostsFromString
private List<HostInfo> getHostsFromString(String hosts) throws FlumeException
{    List<HostInfo> hostInfoList = new ArrayList<HostInfo>();    String[] hostsAndPorts = hosts.split(",");    int i = 0;    for (String host : hostsAndPorts) {        String[] hostAndPort = host.split(":");        if (hostAndPort.length < 2) {            logger.warn("Invalid ganglia host: ", host);            continue;        }        try {            hostInfoList.add(new HostInfo("ganglia_host-" + String.valueOf(i), hostAndPort[0], Integer.parseInt(hostAndPort[1])));        } catch (Exception e) {            logger.warn("Invalid ganglia host: " + host, e);            continue;        }    }    if (hostInfoList.isEmpty()) {        throw new FlumeException("No valid ganglia hosts defined!");    }    return hostInfoList;}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    try {        Map<String, Map<String, String>> metricsMap = JMXPollUtil.getAllMBeans();        for (String component : metricsMap.keySet()) {            Map<String, String> attributeMap = metricsMap.get(component);            for (String attribute : attributeMap.keySet()) {                if (isGanglia3) {                    server.createGangliaMessage(GANGLIA_CONTEXT + component + "." + attribute, attributeMap.get(attribute));                } else {                    server.createGangliaMessage31(GANGLIA_CONTEXT + component + "." + attribute, attributeMap.get(attribute));                }                server.sendToGangliaNodes();            }        }    } catch (Throwable t) {        logger.error("Unexpected error", t);    }}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    jettyServer = new Server();            HttpConfiguration httpConfiguration = new HttpConfiguration();    ServerConnector connector = new ServerConnector(jettyServer, new HttpConnectionFactory(httpConfiguration));    connector.setReuseAddress(true);    connector.setPort(port);    jettyServer.addConnector(connector);    jettyServer.setHandler(new HTTPMetricsHandler());    try {        jettyServer.start();        while (!jettyServer.isStarted()) {            Thread.sleep(500);        }    } catch (Exception ex) {        LOG.error("Error starting Jetty. JSON Metrics may not be available.", ex);    }}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    try {        jettyServer.stop();        jettyServer.join();    } catch (Exception ex) {        LOG.error("Error stopping Jetty. JSON Metrics may not be available.", ex);    }}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    port = context.getInteger(CONFIG_PORT, DEFAULT_PORT);}
2b6df1a88deaddd304de6120f83d90916c691ac969bb779985689853a7fd33bf
handle
public void handle(String target, Request r1, HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException
{        if (request.getMethod().equalsIgnoreCase("TRACE") || request.getMethod().equalsIgnoreCase("OPTIONS")) {        response.sendError(HttpServletResponse.SC_FORBIDDEN);        response.flushBuffer();        ((Request) request).setHandled(true);        return;    }    if (target.equals("/")) {        response.setContentType("text/html;charset=utf-8");        response.setStatus(HttpServletResponse.SC_OK);        response.getWriter().write("For Flume metrics please click" + " <a href = \"./metrics\"> here</a>.");        response.flushBuffer();        ((Request) request).setHandled(true);        return;    } else if (target.equalsIgnoreCase("/metrics")) {        response.setContentType("application/json;charset=utf-8");        response.setStatus(HttpServletResponse.SC_OK);        Map<String, Map<String, String>> metricsMap = JMXPollUtil.getAllMBeans();        String json = gson.toJson(metricsMap, mapType);        response.getWriter().write(json);        response.flushBuffer();        ((Request) request).setHandled(true);        return;    }    response.sendError(HttpServletResponse.SC_NOT_FOUND);    response.flushBuffer();}
b912485f0510f04da894b5786f90a60c16d90bf76801025f297185a8a5ec7ed5
addToKafkaEventGetTimer
public long addToKafkaEventGetTimer(long delta)
{    return addAndGet(TIMER_KAFKA_EVENT_GET, delta);}
562d3fba6e700499a5e5605df0bbcf1003eda596799b76a6a02ed43e07916631
addToKafkaEventSendTimer
public long addToKafkaEventSendTimer(long delta)
{    return addAndGet(TIMER_KAFKA_EVENT_SEND, delta);}
b0927fc0c327be079765629e62b6a772884cf847ae9848c910cd7e80e7fe55d9
addToKafkaCommitTimer
public long addToKafkaCommitTimer(long delta)
{    return addAndGet(TIMER_KAFKA_COMMIT, delta);}
b99ffa8d8915d55465a205ea0dcae0ade1e1324f0616c9c2a443aaa0b5f57e97
addToRollbackCounter
public long addToRollbackCounter(long delta)
{    return addAndGet(COUNT_ROLLBACK, delta);}
b61aa9a42ab7b40833b7dc93e6f8253fc2e6c21dfbf4120e9d782f9e82a05f9c
getKafkaEventGetTimer
public long getKafkaEventGetTimer()
{    return get(TIMER_KAFKA_EVENT_GET);}
25dd922b55fc45539fe5a2c1015e63cc43592828da9c9b0bbb402ce96211871f
getKafkaEventSendTimer
public long getKafkaEventSendTimer()
{    return get(TIMER_KAFKA_EVENT_SEND);}
e3a2e82a80c0ee52bc6ffd855e0de6fd0845ff318aa92c1ce951cb8a39e57836
getKafkaCommitTimer
public long getKafkaCommitTimer()
{    return get(TIMER_KAFKA_COMMIT);}
12adb7362c6c0ffdb6bf76485b46e2712c713b5a5b191019362e9523f5b4f5d6
getRollbackCount
public long getRollbackCount()
{    return get(COUNT_ROLLBACK);}
562d3fba6e700499a5e5605df0bbcf1003eda596799b76a6a02ed43e07916631
addToKafkaEventSendTimer
public long addToKafkaEventSendTimer(long delta)
{    return addAndGet(TIMER_KAFKA_EVENT_SEND, delta);}
3bd7ef984124f8a8dc4ff64b7e2930d204b4a96249719a0b32525f7b4f64da7e
incrementRollbackCount
public long incrementRollbackCount()
{    return increment(COUNT_ROLLBACK);}
25dd922b55fc45539fe5a2c1015e63cc43592828da9c9b0bbb402ce96211871f
getKafkaEventSendTimer
public long getKafkaEventSendTimer()
{    return get(TIMER_KAFKA_EVENT_SEND);}
12adb7362c6c0ffdb6bf76485b46e2712c713b5a5b191019362e9523f5b4f5d6
getRollbackCount
public long getRollbackCount()
{    return get(COUNT_ROLLBACK);}
b912485f0510f04da894b5786f90a60c16d90bf76801025f297185a8a5ec7ed5
addToKafkaEventGetTimer
public long addToKafkaEventGetTimer(long delta)
{    return addAndGet(TIMER_KAFKA_EVENT_GET, delta);}
b0927fc0c327be079765629e62b6a772884cf847ae9848c910cd7e80e7fe55d9
addToKafkaCommitTimer
public long addToKafkaCommitTimer(long delta)
{    return addAndGet(TIMER_KAFKA_COMMIT, delta);}
8bbd0b8f63250327c6c679c13f46da63cd1607e74f4139de407e4052555a7a47
incrementKafkaEmptyCount
public long incrementKafkaEmptyCount()
{    return increment(COUNTER_KAFKA_EMPTY);}
e3a2e82a80c0ee52bc6ffd855e0de6fd0845ff318aa92c1ce951cb8a39e57836
getKafkaCommitTimer
public long getKafkaCommitTimer()
{    return get(TIMER_KAFKA_COMMIT);}
b61aa9a42ab7b40833b7dc93e6f8253fc2e6c21dfbf4120e9d782f9e82a05f9c
getKafkaEventGetTimer
public long getKafkaEventGetTimer()
{    return get(TIMER_KAFKA_EVENT_GET);}
0a5610136519d9748c2990603d5234394a05f9bd1adc622c6561bc307baf8ad0
getKafkaEmptyCount
public long getKafkaEmptyCount()
{    return get(COUNTER_KAFKA_EMPTY);}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    register();    stopTime.set(0L);    for (String counter : counterMap.keySet()) {        counterMap.get(counter).set(0L);    }    startTime.set(System.currentTimeMillis());    logger.info("Component type: " + type + ", name: " + name + " started");}
2d9a050f2e52f179501f1638a0d47268239a8845a6b1e52e75362205f201fd7f
register
 void register()
{    if (!registered) {        try {            ObjectName objName = new ObjectName("org.apache.flume." + type.name().toLowerCase(Locale.ENGLISH) + ":type=" + this.name);            if (ManagementFactory.getPlatformMBeanServer().isRegistered(objName)) {                logger.debug("Monitored counter group for type: " + type + ", name: " + name + ": Another MBean is already registered with this name. " + "Unregistering that pre-existing MBean now...");                ManagementFactory.getPlatformMBeanServer().unregisterMBean(objName);                logger.debug("Monitored counter group for type: " + type + ", name: " + name + ": Successfully unregistered pre-existing MBean.");            }            ManagementFactory.getPlatformMBeanServer().registerMBean(this, objName);            logger.info("Monitored counter group for type: " + type + ", name: " + name + ": Successfully registered new MBean.");            registered = true;        } catch (Exception ex) {            logger.error("Failed to register monitored counter group for type: " + type + ", name: " + name, ex);        }    }}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{        stopTime.set(System.currentTimeMillis());        logger.info("Component type: " + type + ", name: " + name + " stopped");        final String typePrefix = type.name().toLowerCase(Locale.ENGLISH);        logger.info("Shutdown Metric for type: " + type + ", " + "name: " + name + ". " + typePrefix + "." + COUNTER_GROUP_START_TIME + " == " + startTime);        logger.info("Shutdown Metric for type: " + type + ", " + "name: " + name + ". " + typePrefix + "." + COUNTER_GROUP_STOP_TIME + " == " + stopTime);        final List<String> mapKeys = new ArrayList<String>(counterMap.keySet());    Collections.sort(mapKeys);        for (final String counterMapKey : mapKeys) {                final long counterMapValue = get(counterMapKey);        logger.info("Shutdown Metric for type: " + type + ", " + "name: " + name + ". " + counterMapKey + " == " + counterMapValue);    }}
afc2d9d29525357dc0a8793ba8a0adf0e8de8c4687915bde8bfb32988722ba0c
getStartTime
public long getStartTime()
{    return startTime.get();}
4eec965eb39d1fd55e0f1a79be7ab5273141eba36a52d61fca3fde27578447a2
getStopTime
public long getStopTime()
{    return stopTime.get();}
30c5449c6b5eb9c7f0a380bfd47f034e2fb127c28cd09faea4b05291405320a0
toString
public final String toString()
{    StringBuilder sb = new StringBuilder(type.name()).append(":");    sb.append(name).append("{");    boolean first = true;    Iterator<String> counterIterator = counterMap.keySet().iterator();    while (counterIterator.hasNext()) {        if (first) {            first = false;        } else {            sb.append(", ");        }        String counterName = counterIterator.next();        sb.append(counterName).append("=").append(get(counterName));    }    sb.append("}");    return sb.toString();}
6ac7d0c2a2145a5fd94f80c4ad47ea52e29745eb443e36aed1cefaa7b03aa34c
get
protected long get(String counter)
{    return counterMap.get(counter).get();}
704e95e6881dc4e5113acfa0d3634abb5c0efbcc93bc3dd1bd28b3c064248ca5
set
protected void set(String counter, long value)
{    counterMap.get(counter).set(value);}
bf9ba914f533ba8f1845788201e0227c9fd212458af8371ea63457b98c6a12aa
addAndGet
protected long addAndGet(String counter, long delta)
{    return counterMap.get(counter).addAndGet(delta);}
8d7aa74adcbe88c4407898354e0dca4b2495dffa36e8be06ffd56578323f1695
increment
protected long increment(String counter)
{    return counterMap.get(counter).incrementAndGet();}
624f725337dde847c4a699397a02f1b5558c709c88374adb10e603d835f48c88
getType
public String getType()
{    return type.name();}
f3bc60545af1774b93babd1990f19f1516b71cbd06907df93c77f59be1951f8b
getMonitorClass
public Class<? extends MonitorService> getMonitorClass()
{    return this.monitoringClass;}
5b2adc36f0388a10ab6ac8b80857d0854c0dcfe53b4b99d0931416226e449499
getConnectionCreatedCount
public long getConnectionCreatedCount()
{    return get(COUNTER_CONNECTION_CREATED);}
7bac7e3a9fc2c51ad1edc28d3d8ab7ed7c92e5bd957a90ed00b7acd2cf82dc72
incrementConnectionCreatedCount
public long incrementConnectionCreatedCount()
{    return increment(COUNTER_CONNECTION_CREATED);}
fdb28d05f077bcf854eff219a3acfe628229841f510a904246f66c56a4cf83ba
getConnectionClosedCount
public long getConnectionClosedCount()
{    return get(COUNTER_CONNECTION_CLOSED);}
08190741029a5cd55042af8d0aae79e7673ab26a9409b66253b624a8bd5a0d2f
incrementConnectionClosedCount
public long incrementConnectionClosedCount()
{    return increment(COUNTER_CONNECTION_CLOSED);}
d966dd9d46a4353570583330587b5c995932cae4826b54bdc10dfc4255d98268
getConnectionFailedCount
public long getConnectionFailedCount()
{    return get(COUNTER_CONNECTION_FAILED);}
5ad1e024215a9e5c18b6bb61b2bd0d5d65f4711c7eb536561e1dcb6253cb6aa8
incrementConnectionFailedCount
public long incrementConnectionFailedCount()
{    return increment(COUNTER_CONNECTION_FAILED);}
ed1f8fe69f1d8114d24899cdc469ce4de8744dcee66812a6c32ee4db179e68d5
getBatchEmptyCount
public long getBatchEmptyCount()
{    return get(COUNTER_BATCH_EMPTY);}
0f209e9970d9d6f3d394c72cb502b6ab2f5385feb2c4af8df42401a182b519d6
incrementBatchEmptyCount
public long incrementBatchEmptyCount()
{    return increment(COUNTER_BATCH_EMPTY);}
c7a1080810e3b30a403bf90f6554bf032ff4921e55897476efea8368e5bb6716
getBatchUnderflowCount
public long getBatchUnderflowCount()
{    return get(COUNTER_BATCH_UNDERFLOW);}
07af351fe3bd5139ce656031f8b0c00804b4a2a527c876b62f4e3fba06c243bb
incrementBatchUnderflowCount
public long incrementBatchUnderflowCount()
{    return increment(COUNTER_BATCH_UNDERFLOW);}
a56511007b9384530e302bc7417214d475d7dd01ec0c05801d5bdb2b288ada19
getBatchCompleteCount
public long getBatchCompleteCount()
{    return get(COUNTER_BATCH_COMPLETE);}
b9844ffaae8c10e935c5738417f887ec565eaa5cb536b93a272e459dc9b320f5
incrementBatchCompleteCount
public long incrementBatchCompleteCount()
{    return increment(COUNTER_BATCH_COMPLETE);}
ecb5af70827e153d60f2356307e2a3c6b124e3100647f3ca0f39adcec5c8880e
getEventDrainAttemptCount
public long getEventDrainAttemptCount()
{    return get(COUNTER_EVENT_DRAIN_ATTEMPT);}
c274e2c1f9a429fe5dda2b55dc0c05057c3ed9d6b1393e7ef6704262288f6ea5
incrementEventDrainAttemptCount
public long incrementEventDrainAttemptCount()
{    return increment(COUNTER_EVENT_DRAIN_ATTEMPT);}
d553dbdcace50858e481d272a515dbb84a7815924235874e9c2f31a60ae79b34
addToEventDrainAttemptCount
public long addToEventDrainAttemptCount(long delta)
{    return addAndGet(COUNTER_EVENT_DRAIN_ATTEMPT, delta);}
81e8fa4e237a1f7f9cd7e9f538b03effd558cdd67da039377060379e7c3fcd42
getEventDrainSuccessCount
public long getEventDrainSuccessCount()
{    return get(COUNTER_EVENT_DRAIN_SUCCESS);}
7f23166d26b7175bc08e7694856d1db4c7939a1c798f6925fd40749533c0fdfe
incrementEventDrainSuccessCount
public long incrementEventDrainSuccessCount()
{    return increment(COUNTER_EVENT_DRAIN_SUCCESS);}
7ed374a9ab89ec33b0b0d504293c680279d51d6e5272b14df4fa6f59b653d74d
addToEventDrainSuccessCount
public long addToEventDrainSuccessCount(long delta)
{    return addAndGet(COUNTER_EVENT_DRAIN_SUCCESS, delta);}
edd958669069410c55b5d8e6eb806082b501154852db2ac427cd0c97fd41be21
incrementEventWriteFail
public long incrementEventWriteFail()
{    return increment(COUNTER_EVENT_WRITE_FAIL);}
8f568089b4a4d89b7e519865cc698ca209ece8b6f2370f09cee81ce430c54b62
getEventWriteFail
public long getEventWriteFail()
{    return get(COUNTER_EVENT_WRITE_FAIL);}
4770d237c46b0524d34438a8ad57572b0ab8f339d4954c66aca8249fae9620ba
incrementChannelReadFail
public long incrementChannelReadFail()
{    return increment(COUNTER_CHANNEL_READ_FAIL);}
a3fe53100479baa570b78efd2e458ac208dff63e893237d7eb835d76e03b87c8
getChannelReadFail
public long getChannelReadFail()
{    return get(COUNTER_CHANNEL_READ_FAIL);}
7c9e24fa9c3508f1c060620ce3c38dfdfc5880a07ccdd1a025f6e5a9a542e8dd
incrementEventWriteOrChannelFail
public long incrementEventWriteOrChannelFail(Throwable t)
{    if (t instanceof ChannelException) {        return incrementChannelReadFail();    }    return incrementEventWriteFail();}
96e3541e15cd90868b83f9e274cb24b42b0d5436e384f0ce7287f55ecbf328d8
getEventReceivedCount
public long getEventReceivedCount()
{    return get(COUNTER_EVENTS_RECEIVED);}
c5065bd987a05ac50a6e1055d552240816b4dd5be2e349cf3a5386d3ef6d2241
incrementEventReceivedCount
public long incrementEventReceivedCount()
{    return increment(COUNTER_EVENTS_RECEIVED);}
a7e3c1d8391bd0e2b16beb8b9ddda0fac6916ab8ddce4029364213911b41d3ab
addToEventReceivedCount
public long addToEventReceivedCount(long delta)
{    return addAndGet(COUNTER_EVENTS_RECEIVED, delta);}
06f39338443737e3e13b9852f877d4b0850f4e656ba0f7f4ce82bb59ac861659
getEventAcceptedCount
public long getEventAcceptedCount()
{    return get(COUNTER_EVENTS_ACCEPTED);}
d838cca53e3d791c8f6399b136e804a0a16d13317f620628122a0f9ed1a81ef8
incrementEventAcceptedCount
public long incrementEventAcceptedCount()
{    return increment(COUNTER_EVENTS_ACCEPTED);}
679ab4b1c35c4e3f41926c52b6d8780041b4efedf723945e62b34c6d66bb188e
addToEventAcceptedCount
public long addToEventAcceptedCount(long delta)
{    return addAndGet(COUNTER_EVENTS_ACCEPTED, delta);}
82d429c8ce52e21e46406370669e28d8b40e52729c17e711578ed02ef704fbe5
getAppendReceivedCount
public long getAppendReceivedCount()
{    return get(COUNTER_APPEND_RECEIVED);}
3993cc5da2d5f4576abfd29c46d9898f1de4b2929ada09d5f18be6c7619530d0
incrementAppendReceivedCount
public long incrementAppendReceivedCount()
{    return increment(COUNTER_APPEND_RECEIVED);}
90e1cf0f61eb5667bbc993513f29d705c940d20f68c2952bf5f824adac60cfde
getAppendAcceptedCount
public long getAppendAcceptedCount()
{    return get(COUNTER_APPEND_ACCEPTED);}
de4a5b98774381185ba2b25787cfe731bb130381f6f5aa9b001bc3fa3f1cbe64
incrementAppendAcceptedCount
public long incrementAppendAcceptedCount()
{    return increment(COUNTER_APPEND_ACCEPTED);}
2601b952a77ba2d2e2edad19afd5a16e6d4c8564e97070049fd69d3fdda78a52
getAppendBatchReceivedCount
public long getAppendBatchReceivedCount()
{    return get(COUNTER_APPEND_BATCH_RECEIVED);}
e92fd75486c8f98ee2281919ae56a1eca95df2b47ef4ab9d41761ed6abfbba15
incrementAppendBatchReceivedCount
public long incrementAppendBatchReceivedCount()
{    return increment(COUNTER_APPEND_BATCH_RECEIVED);}
f92b1c670de628d8afc2af65a54d230534156d568abdfec29d53aeac6151c231
getAppendBatchAcceptedCount
public long getAppendBatchAcceptedCount()
{    return get(COUNTER_APPEND_BATCH_ACCEPTED);}
d54cad551fbd5971e9e426d030d2ed15885920592dec40d4050bb84bf26f039b
incrementAppendBatchAcceptedCount
public long incrementAppendBatchAcceptedCount()
{    return increment(COUNTER_APPEND_BATCH_ACCEPTED);}
cf65f7579d43456640cd1b4d4926a4a2367e8443c7f2f0c5b119adbfdd480f62
getOpenConnectionCount
public long getOpenConnectionCount()
{    return get(COUNTER_OPEN_CONNECTION_COUNT);}
7dfe55517798643dd2641f78be45daf1447cd119e52c66d3773c35ef18a0be39
setOpenConnectionCount
public void setOpenConnectionCount(long openConnectionCount)
{    set(COUNTER_OPEN_CONNECTION_COUNT, openConnectionCount);}
c8544f66e91820f5d013d3d7872a1b4d78339291237ce02f78f84e2a0c85bfd7
incrementEventReadFail
public long incrementEventReadFail()
{    return increment(COUNTER_EVENT_READ_FAIL);}
00aea069cd49ae0a9665f8266c04ecca9a95a52c0e3d5035048aa4f545cacad6
getEventReadFail
public long getEventReadFail()
{    return get(COUNTER_EVENT_READ_FAIL);}
1e721479b95fa5a8a9dea522d083e747dd8e29f4239a4af95df01511ae3554ed
incrementChannelWriteFail
public long incrementChannelWriteFail()
{    return increment(COUNTER_CHANNEL_WRITE_FAIL);}
e5312e6291c4940b345cfaf10f48224e478ab4e45a64294955390b1bc59283b8
getChannelWriteFail
public long getChannelWriteFail()
{    return get(COUNTER_CHANNEL_WRITE_FAIL);}
0ce86306f7f2f7192547336d1cc6a0ce193b3ac60358eb6a6952ec6faa07fc6d
incrementGenericProcessingFail
public long incrementGenericProcessingFail()
{    return increment(COUNTER_GENERIC_PROCESSING_FAIL);}
87f8771c84aafb57d756c0d408a1ad0d18a3c7d2a9da8349484d546405f5c893
getGenericProcessingFail
public long getGenericProcessingFail()
{    return get(COUNTER_GENERIC_PROCESSING_FAIL);}
9abe3c5cf5fb614a21cb49d2fc3504790709a9ca82d962154bba2640333e4e1e
incrementEventReadOrChannelFail
public long incrementEventReadOrChannelFail(Throwable t)
{    if (t instanceof ChannelException) {        return incrementChannelWriteFail();    }    return incrementEventReadFail();}
ce964438953c1b990a421d7ddfbdf6da7b1ef4e7cd0d3852aa4d07d1d68ff639
getAllMBeans
public static Map<String, Map<String, String>> getAllMBeans()
{    Map<String, Map<String, String>> mbeanMap = Maps.newHashMap();    Set<ObjectInstance> queryMBeans = null;    try {        queryMBeans = mbeanServer.queryMBeans(null, null);    } catch (Exception ex) {        LOG.error("Could not get Mbeans for monitoring", ex);        Throwables.propagate(ex);    }    for (ObjectInstance obj : queryMBeans) {        try {            if (!obj.getObjectName().toString().startsWith("org.apache.flume")) {                continue;            }            MBeanAttributeInfo[] attrs = mbeanServer.getMBeanInfo(obj.getObjectName()).getAttributes();            String[] strAtts = new String[attrs.length];            for (int i = 0; i < strAtts.length; i++) {                strAtts[i] = attrs[i].getName();            }            AttributeList attrList = mbeanServer.getAttributes(obj.getObjectName(), strAtts);            String component = obj.getObjectName().toString().substring(obj.getObjectName().toString().indexOf('=') + 1);            Map<String, String> attrMap = Maps.newHashMap();            for (Object attr : attrList) {                Attribute localAttr = (Attribute) attr;                if (localAttr.getName().equalsIgnoreCase("type")) {                    component = localAttr.getValue() + "." + component;                }                attrMap.put(localAttr.getName(), localAttr.getValue().toString());            }            mbeanMap.put(component, attrMap);        } catch (Exception e) {            LOG.error("Unable to poll JMX for metrics.", e);        }    }    return mbeanMap;}
46ffa8d56c2364376c7a2fb00ff1e97ead501825886406f582f8797ba07e934c
initialize
public void initialize()
{}
fa63d27bd1bea8d2c8a54d25059a5646f17912afe7a54c75ebd7cfd8635b0016
intercept
public Event intercept(Event event)
{    Map<String, String> headers = event.getHeaders();    if (preserveExisting && headers.containsKey(header)) {        return event;    }    if (host != null) {        headers.put(header, host);    }    return event;}
b7fd8a02f88da0ddad8327ade8d4986c180b70eb77329c7227efb6274c9c0a2b
intercept
public List<Event> intercept(List<Event> events)
{    for (Event event : events) {        intercept(event);    }    return events;}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{}
17b740b5f67eb00407e17fdf73a9126423f207c9cfe5b24f2166c823c2b8ee22
build
public Interceptor build()
{    return new HostInterceptor(preserveExisting, useIP, header);}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    preserveExisting = context.getBoolean(PRESERVE, PRESERVE_DFLT);    useIP = context.getBoolean(USE_IP, USE_IP_DFLT);    header = context.getString(HOST_HEADER, HOST);}
6e2e1db94962c712a9d2305b1b0bce7d86d580c7b5d8f28010bc00f663aa1773
lookup
private static Class<? extends Builder> lookup(String name)
{    try {        return InterceptorType.valueOf(name.toUpperCase(Locale.ENGLISH)).getBuilderClass();    } catch (IllegalArgumentException e) {        return null;    }}
2ae0f013f2e11054bbae5c635385f1a3cd9e4ac7c2b684cfaed9c712a71885a0
newInstance
public static Builder newInstance(String name) throws ClassNotFoundException, InstantiationException, IllegalAccessException
{    Class<? extends Builder> clazz = lookup(name);    if (clazz == null) {        clazz = (Class<? extends Builder>) Class.forName(name);    }    return clazz.newInstance();}
d5f84e747c515d7032506dde8acb09662f38cf722f7134cde669b20e85b8c2f5
setInterceptors
public void setInterceptors(List<Interceptor> interceptors)
{    this.interceptors = interceptors;}
fa63d27bd1bea8d2c8a54d25059a5646f17912afe7a54c75ebd7cfd8635b0016
intercept
public Event intercept(Event event)
{    for (Interceptor interceptor : interceptors) {        if (event == null) {            return null;        }        event = interceptor.intercept(event);    }    return event;}
b7fd8a02f88da0ddad8327ade8d4986c180b70eb77329c7227efb6274c9c0a2b
intercept
public List<Event> intercept(List<Event> events)
{    for (Interceptor interceptor : interceptors) {        if (events.isEmpty()) {            return events;        }        events = interceptor.intercept(events);        Preconditions.checkNotNull(events, "Event list returned null from interceptor %s", interceptor);    }    return events;}
46ffa8d56c2364376c7a2fb00ff1e97ead501825886406f582f8797ba07e934c
initialize
public void initialize()
{    Iterator<Interceptor> iter = interceptors.iterator();    while (iter.hasNext()) {        Interceptor interceptor = iter.next();        interceptor.initialize();    }}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{    Iterator<Interceptor> iter = interceptors.iterator();    while (iter.hasNext()) {        Interceptor interceptor = iter.next();        interceptor.close();    }}
22aa5b476ccd6c7e9b0ff9f7cae04a9c87130d890a69ba7c89167c88350f3561
getBuilderClass
public Class<? extends Interceptor.Builder> getBuilderClass()
{    return builderClass;}
46ffa8d56c2364376c7a2fb00ff1e97ead501825886406f582f8797ba07e934c
initialize
public void initialize()
{}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{}
fa63d27bd1bea8d2c8a54d25059a5646f17912afe7a54c75ebd7cfd8635b0016
intercept
public Event intercept(Event event)
{    Matcher matcher = regex.matcher(new String(event.getBody(), Charsets.UTF_8));    Map<String, String> headers = event.getHeaders();    if (matcher.find()) {        for (int group = 0, count = matcher.groupCount(); group < count; group++) {            int groupIndex = group + 1;            if (groupIndex > serializers.size()) {                if (logger.isDebugEnabled()) {                    logger.debug("Skipping group {} to {} due to missing serializer", group, count);                }                break;            }            NameAndSerializer serializer = serializers.get(group);            if (logger.isDebugEnabled()) {                logger.debug("Serializing {} using {}", serializer.headerName, serializer.serializer);            }            headers.put(serializer.headerName, serializer.serializer.serialize(matcher.group(groupIndex)));        }    }    return event;}
b7fd8a02f88da0ddad8327ade8d4986c180b70eb77329c7227efb6274c9c0a2b
intercept
public List<Event> intercept(List<Event> events)
{    List<Event> intercepted = Lists.newArrayListWithCapacity(events.size());    for (Event event : events) {        Event interceptedEvent = intercept(event);        if (interceptedEvent != null) {            intercepted.add(interceptedEvent);        }    }    return intercepted;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    String regexString = context.getString(REGEX);    Preconditions.checkArgument(!StringUtils.isEmpty(regexString), "Must supply a valid regex string");    regex = Pattern.compile(regexString);    regex.pattern();    regex.matcher("").groupCount();    configureSerializers(context);}
c207bbc4b5ae14e343abf7a6844a4b5e2c0a20888f2846595877ad85b669a925
configureSerializers
private void configureSerializers(Context context)
{    String serializerListStr = context.getString(SERIALIZERS);    Preconditions.checkArgument(!StringUtils.isEmpty(serializerListStr), "Must supply at least one name and serializer");    String[] serializerNames = serializerListStr.split("\\s+");    Context serializerContexts = new Context(context.getSubProperties(SERIALIZERS + "."));    serializerList = Lists.newArrayListWithCapacity(serializerNames.length);    for (String serializerName : serializerNames) {        Context serializerContext = new Context(serializerContexts.getSubProperties(serializerName + "."));        String type = serializerContext.getString("type", "DEFAULT");        String name = serializerContext.getString("name");        Preconditions.checkArgument(!StringUtils.isEmpty(name), "Supplied name cannot be empty.");        if ("DEFAULT".equals(type)) {            serializerList.add(new NameAndSerializer(name, defaultSerializer));        } else {            serializerList.add(new NameAndSerializer(name, getCustomSerializer(type, serializerContext)));        }    }}
c9611dba5b79a8e58b03f9ee62e35cadeff64208a471d5189010c2013c26eea2
getCustomSerializer
private RegexExtractorInterceptorSerializer getCustomSerializer(String clazzName, Context context)
{    try {        RegexExtractorInterceptorSerializer serializer = (RegexExtractorInterceptorSerializer) Class.forName(clazzName).newInstance();        serializer.configure(context);        return serializer;    } catch (Exception e) {        logger.error("Could not instantiate event serializer.", e);        Throwables.propagate(e);    }    return defaultSerializer;}
17b740b5f67eb00407e17fdf73a9126423f207c9cfe5b24f2166c823c2b8ee22
build
public Interceptor build()
{    Preconditions.checkArgument(regex != null, "Regex pattern was misconfigured");    Preconditions.checkArgument(serializerList.size() > 0, "Must supply a valid group match id list");    return new RegexExtractorInterceptor(regex, serializerList);}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    String pattern = context.getString("pattern");    Preconditions.checkArgument(!StringUtils.isEmpty(pattern), "Must configure with a valid pattern");    formatter = DateTimeFormat.forPattern(pattern);}
8e0eb8d458e01ec5e9f009a43709aa6ebeb598b21118d38b2a40fd22ddb3b4fd
serialize
public String serialize(String value)
{    DateTime dateTime = formatter.parseDateTime(value);    return Long.toString(dateTime.getMillis());}
57746d8a7acafcf5647f649109937334de6090302f29c32ed7da0df311700e35
configure
public void configure(ComponentConfiguration conf)
{}
8e0eb8d458e01ec5e9f009a43709aa6ebeb598b21118d38b2a40fd22ddb3b4fd
serialize
public String serialize(String value)
{    return value;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{}
57746d8a7acafcf5647f649109937334de6090302f29c32ed7da0df311700e35
configure
public void configure(ComponentConfiguration conf)
{}
46ffa8d56c2364376c7a2fb00ff1e97ead501825886406f582f8797ba07e934c
initialize
public void initialize()
{}
fa63d27bd1bea8d2c8a54d25059a5646f17912afe7a54c75ebd7cfd8635b0016
intercept
public Event intercept(Event event)
{    if (!excludeEvents) {        if (regex.matcher(new String(event.getBody())).find()) {            return event;        } else {            return null;        }    } else {        if (regex.matcher(new String(event.getBody())).find()) {            return null;        } else {            return event;        }    }}
b7fd8a02f88da0ddad8327ade8d4986c180b70eb77329c7227efb6274c9c0a2b
intercept
public List<Event> intercept(List<Event> events)
{    List<Event> out = Lists.newArrayList();    for (Event event : events) {        Event outEvent = intercept(event);        if (outEvent != null) {            out.add(outEvent);        }    }    return out;}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    String regexString = context.getString(REGEX, DEFAULT_REGEX);    regex = Pattern.compile(regexString);    excludeEvents = context.getBoolean(EXCLUDE_EVENTS, DEFAULT_EXCLUDE_EVENTS);}
17b740b5f67eb00407e17fdf73a9126423f207c9cfe5b24f2166c823c2b8ee22
build
public Interceptor build()
{    logger.info(String.format("Creating RegexFilteringInterceptor: regex=%s,excludeEvents=%s", regex, excludeEvents));    return new RegexFilteringInterceptor(regex, excludeEvents);}
46ffa8d56c2364376c7a2fb00ff1e97ead501825886406f582f8797ba07e934c
initialize
public void initialize()
{}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{}
797f83e6086441dd9993958289c4edc2108e0a3f660cb15d1f8ed00ff1c015cb
intercept
public List<Event> intercept(final List<Event> events)
{    for (final Event event : events) {        intercept(event);    }    return events;}
114e6029a4648f5055c87b05527a2c1b87e35bf9b997d4c365dce5c711b7a203
intercept
public Event intercept(final Event event)
{    assert event != null : "Missing Flume event while intercepting";    try {        final Map<String, String> headers = event.getHeaders();                if (withName != null && headers.remove(withName) != null) {            LOG.trace("Removed header \"{}\" for event: {}", withName, event);        }                if (fromList != null || matchRegex != null) {            final Iterator<String> headerIterator = headers.keySet().iterator();            List<String> removedHeaders = new LinkedList<>();            while (headerIterator.hasNext()) {                final String currentHeader = headerIterator.next();                if (fromList != null && fromList.contains(currentHeader)) {                    headerIterator.remove();                    removedHeaders.add(currentHeader);                } else if (matchRegex != null) {                    final Matcher matcher = matchRegex.matcher(currentHeader);                    if (matcher.matches()) {                        headerIterator.remove();                        removedHeaders.add(currentHeader);                    }                }            }            if (!removedHeaders.isEmpty() && LogPrivacyUtil.allowLogRawData()) {                LOG.trace("Removed headers \"{}\" for event: {}", removedHeaders, event);            }        }    } catch (final Exception e) {        LOG.error("Failed to process event " + event, e);    }    return event;}
17b740b5f67eb00407e17fdf73a9126423f207c9cfe5b24f2166c823c2b8ee22
build
public Interceptor build()
{    if (LOG.isDebugEnabled()) {        LOG.debug("Creating RemoveHeaderInterceptor with: withName={}, fromList={}, " + "listSeparator={}, matchRegex={}", new String[] { withName, fromList, listSeparator, String.valueOf(matchRegex) });    }    return new RemoveHeaderInterceptor(withName, fromList, listSeparator, matchRegex);}
162d31283a4f4512a23d7f69bb074a565081c656fbe8c16c21cee4aa582249b8
configure
public void configure(final Context context)
{    withName = context.getString(WITH_NAME);    fromList = context.getString(FROM_LIST);    listSeparator = context.getString(LIST_SEPARATOR, LIST_SEPARATOR_DEFAULT);    final String matchRegexStr = context.getString(MATCH_REGEX);    if (matchRegexStr != null) {        matchRegex = Pattern.compile(matchRegexStr);    }}
46ffa8d56c2364376c7a2fb00ff1e97ead501825886406f582f8797ba07e934c
initialize
public void initialize()
{}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{}
fa63d27bd1bea8d2c8a54d25059a5646f17912afe7a54c75ebd7cfd8635b0016
intercept
public Event intercept(Event event)
{    String origBody = new String(event.getBody(), charset);    Matcher matcher = searchPattern.matcher(origBody);    String newBody = matcher.replaceAll(replaceString);    event.setBody(newBody.getBytes(charset));    return event;}
b7fd8a02f88da0ddad8327ade8d4986c180b70eb77329c7227efb6274c9c0a2b
intercept
public List<Event> intercept(List<Event> events)
{    for (Event event : events) {        intercept(event);    }    return events;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    String searchPattern = context.getString(SEARCH_PAT_KEY);    Preconditions.checkArgument(!StringUtils.isEmpty(searchPattern), "Must supply a valid search pattern " + SEARCH_PAT_KEY + " (may not be empty)");    replaceString = context.getString(REPLACE_STRING_KEY);        if (replaceString == null) {        replaceString = "";    }    searchRegex = Pattern.compile(searchPattern);    if (context.containsKey(CHARSET_KEY)) {                charset = Charset.forName(context.getString(CHARSET_KEY));    }}
17b740b5f67eb00407e17fdf73a9126423f207c9cfe5b24f2166c823c2b8ee22
build
public Interceptor build()
{    Preconditions.checkNotNull(searchRegex, "Regular expression search pattern required");    Preconditions.checkNotNull(replaceString, "Replacement string required");    return new SearchAndReplaceInterceptor(searchRegex, replaceString, charset);}
46ffa8d56c2364376c7a2fb00ff1e97ead501825886406f582f8797ba07e934c
initialize
public void initialize()
{}
fa63d27bd1bea8d2c8a54d25059a5646f17912afe7a54c75ebd7cfd8635b0016
intercept
public Event intercept(Event event)
{    Map<String, String> headers = event.getHeaders();    if (preserveExisting && headers.containsKey(key)) {        return event;    }    headers.put(key, value);    return event;}
b7fd8a02f88da0ddad8327ade8d4986c180b70eb77329c7227efb6274c9c0a2b
intercept
public List<Event> intercept(List<Event> events)
{    for (Event event : events) {        intercept(event);    }    return events;}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    preserveExisting = context.getBoolean(Constants.PRESERVE, Constants.PRESERVE_DEFAULT);    key = context.getString(Constants.KEY, Constants.KEY_DEFAULT);    value = context.getString(Constants.VALUE, Constants.VALUE_DEFAULT);}
17b740b5f67eb00407e17fdf73a9126423f207c9cfe5b24f2166c823c2b8ee22
build
public Interceptor build()
{    logger.info(String.format("Creating StaticInterceptor: preserveExisting=%s,key=%s,value=%s", preserveExisting, key, value));    return new StaticInterceptor(preserveExisting, key, value);}
46ffa8d56c2364376c7a2fb00ff1e97ead501825886406f582f8797ba07e934c
initialize
public void initialize()
{}
fa63d27bd1bea8d2c8a54d25059a5646f17912afe7a54c75ebd7cfd8635b0016
intercept
public Event intercept(Event event)
{    Map<String, String> headers = event.getHeaders();    if (preserveExisting && headers.containsKey(header)) {        } else {        long now = System.currentTimeMillis();        headers.put(header, Long.toString(now));    }    return event;}
b7fd8a02f88da0ddad8327ade8d4986c180b70eb77329c7227efb6274c9c0a2b
intercept
public List<Event> intercept(List<Event> events)
{    for (Event event : events) {        intercept(event);    }    return events;}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{}
17b740b5f67eb00407e17fdf73a9126423f207c9cfe5b24f2166c823c2b8ee22
build
public Interceptor build()
{    return new TimestampInterceptor(preserveExisting, header);}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    preserveExisting = context.getBoolean(CONFIG_PRESERVE, DEFAULT_PRESERVE);    header = context.getString(CONFIG_HEADER_NAME, DEFAULT_HEADER_NAME);}
3c9d709457a05932e9433ebf22e7cb7b028dce3bf5099e62dc55f97de03dddf3
waitForState
public static boolean waitForState(LifecycleAware delegate, LifecycleState state) throws InterruptedException
{    return waitForState(delegate, state, 0);}
ce519743668fdb32ebfae5e333fa40781f54e39535894210a71cb96aedcbe92f
waitForState
public static boolean waitForState(LifecycleAware delegate, LifecycleState state, long timeout) throws InterruptedException
{    return waitForOneOf(delegate, new LifecycleState[] { state }, timeout);}
2d185e18ecdd5485c419edc78acd3bb43a6e5ea9b453fb0750c9bd362796e8e5
waitForOneOf
public static boolean waitForOneOf(LifecycleAware delegate, LifecycleState[] states) throws InterruptedException
{    return waitForOneOf(delegate, states, 0);}
3490dd02b8d52f8b6a003b2e5672afa9ca2f63f81b5bdcea3208dbd42173b301
waitForOneOf
public static boolean waitForOneOf(LifecycleAware delegate, LifecycleState[] states, long timeout) throws InterruptedException
{    if (logger.isDebugEnabled()) {        logger.debug("Waiting for state {} for delegate:{} up to {}ms", new Object[] { states, delegate, timeout });    }    long sleepInterval = Math.max(shortestSleepDuration, timeout / maxNumberOfChecks);    long deadLine = System.currentTimeMillis() + timeout;    do {        for (LifecycleState state : states) {            if (delegate.getLifecycleState().equals(state)) {                return true;            }        }        Thread.sleep(sleepInterval);    } while (timeout == 0 || System.currentTimeMillis() < deadLine);    logger.debug("Didn't see {} state(s) within timeout of {}ms", states, timeout);    return false;}
276fe3621a54017aa31ed8634a1f2e779379d7a81aaa78f3161b1cd8d0ed670e
stopAll
public static void stopAll(List<LifecycleAware> services) throws InterruptedException
{    for (LifecycleAware service : services) {        waitForOneOf(service, LifecycleState.STOP_OR_ERROR);    }}
5b05914888e421f26bff6f39231facdd35759f746a9af780ebac2cf5b2c81932
start
public synchronized void start()
{    logger.info("Starting lifecycle supervisor {}", Thread.currentThread().getId());    monitorService.scheduleWithFixedDelay(purger, 2, 2, TimeUnit.HOURS);    lifecycleState = LifecycleState.START;    logger.debug("Lifecycle supervisor started");}
06e1ddba8663c90da407ac517f29ed70555cfe57b0332c9a96e7c696e0255364
stop
public synchronized void stop()
{    logger.info("Stopping lifecycle supervisor {}", Thread.currentThread().getId());    if (monitorService != null) {        monitorService.shutdown();        try {            monitorService.awaitTermination(10, TimeUnit.SECONDS);        } catch (InterruptedException e) {            logger.error("Interrupted while waiting for monitor service to stop");        }        if (!monitorService.isTerminated()) {            monitorService.shutdownNow();            try {                while (!monitorService.isTerminated()) {                    monitorService.awaitTermination(10, TimeUnit.SECONDS);                }            } catch (InterruptedException e) {                logger.error("Interrupted while waiting for monitor service to stop");            }        }    }    for (final Entry<LifecycleAware, Supervisoree> entry : supervisedProcesses.entrySet()) {        if (entry.getKey().getLifecycleState().equals(LifecycleState.START)) {            entry.getValue().status.desiredState = LifecycleState.STOP;            entry.getKey().stop();        }    }    /* If we've failed, preserve the error state. */    if (lifecycleState.equals(LifecycleState.START)) {        lifecycleState = LifecycleState.STOP;    }    supervisedProcesses.clear();    monitorFutures.clear();    logger.debug("Lifecycle supervisor stopped");}
64709d0ae8c92c4e64e90b6673d90564860243b12a089ed54ef9147cc9cd9134
fail
public synchronized void fail()
{    lifecycleState = LifecycleState.ERROR;}
c2831b31f4ac1208226413f9a3c5449e0f64a126e5cc2bb9db7ebf5d22b0a31b
supervise
public synchronized void supervise(LifecycleAware lifecycleAware, SupervisorPolicy policy, LifecycleState desiredState)
{    if (this.monitorService.isShutdown() || this.monitorService.isTerminated() || this.monitorService.isTerminating()) {        throw new FlumeException("Supervise called on " + lifecycleAware + " " + "after shutdown has been initiated. " + lifecycleAware + " will not" + " be started");    }    Preconditions.checkState(!supervisedProcesses.containsKey(lifecycleAware), "Refusing to supervise " + lifecycleAware + " more than once");    if (logger.isDebugEnabled()) {        logger.debug("Supervising service:{} policy:{} desiredState:{}", new Object[] { lifecycleAware, policy, desiredState });    }    Supervisoree process = new Supervisoree();    process.status = new Status();    process.policy = policy;    process.status.desiredState = desiredState;    process.status.error = false;    MonitorRunnable monitorRunnable = new MonitorRunnable();    monitorRunnable.lifecycleAware = lifecycleAware;    monitorRunnable.supervisoree = process;    monitorRunnable.monitorService = monitorService;    supervisedProcesses.put(lifecycleAware, process);    ScheduledFuture<?> future = monitorService.scheduleWithFixedDelay(monitorRunnable, 0, 3, TimeUnit.SECONDS);    monitorFutures.put(lifecycleAware, future);}
bcb3a31732df85ae446921f2d7aef80c7a30453b2364a35ea74ab51c1285b9df
unsupervise
public synchronized void unsupervise(LifecycleAware lifecycleAware)
{    Preconditions.checkState(supervisedProcesses.containsKey(lifecycleAware), "Unaware of " + lifecycleAware + " - can not unsupervise");    logger.debug("Unsupervising service:{}", lifecycleAware);    synchronized (lifecycleAware) {        Supervisoree supervisoree = supervisedProcesses.get(lifecycleAware);        supervisoree.status.discard = true;        this.setDesiredState(lifecycleAware, LifecycleState.STOP);        logger.info("Stopping component: {}", lifecycleAware);        lifecycleAware.stop();    }    supervisedProcesses.remove(lifecycleAware);            monitorFutures.get(lifecycleAware).cancel(false);        needToPurge = true;    monitorFutures.remove(lifecycleAware);}
4aef88dfa4e85f9f95a57a7f83a2ef9c7f0bacb5e56e6793810c99bace863645
setDesiredState
public synchronized void setDesiredState(LifecycleAware lifecycleAware, LifecycleState desiredState)
{    Preconditions.checkState(supervisedProcesses.containsKey(lifecycleAware), "Unaware of " + lifecycleAware + " - can not set desired state to " + desiredState);    logger.debug("Setting desiredState:{} on service:{}", desiredState, lifecycleAware);    Supervisoree supervisoree = supervisedProcesses.get(lifecycleAware);    supervisoree.status.desiredState = desiredState;}
82e342b29ff4fad8c64d554dc21ad55a5f2c8063fce3b580e896b7968d90473a
getLifecycleState
public synchronized LifecycleState getLifecycleState()
{    return lifecycleState;}
0816e8807eefbe0dd4ee29481dce48468d52695fd6d9e97fccaa2571ed9c42c8
isComponentInErrorState
public synchronized boolean isComponentInErrorState(LifecycleAware component)
{    return supervisedProcesses.get(component).status.error;}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    logger.debug("checking process:{} supervisoree:{}", lifecycleAware, supervisoree);    long now = System.currentTimeMillis();    try {        if (supervisoree.status.firstSeen == null) {            logger.debug("first time seeing {}", lifecycleAware);            supervisoree.status.firstSeen = now;        }        supervisoree.status.lastSeen = now;        synchronized (lifecycleAware) {            if (supervisoree.status.discard) {                                logger.info("Component has already been stopped {}", lifecycleAware);                return;            } else if (supervisoree.status.error) {                logger.info("Component {} is in error state, and Flume will not" + "attempt to change its state", lifecycleAware);                return;            }            supervisoree.status.lastSeenState = lifecycleAware.getLifecycleState();            if (!lifecycleAware.getLifecycleState().equals(supervisoree.status.desiredState)) {                logger.debug("Want to transition {} from {} to {} (failures:{})", new Object[] { lifecycleAware, supervisoree.status.lastSeenState, supervisoree.status.desiredState, supervisoree.status.failures });                switch(supervisoree.status.desiredState) {                    case START:                        try {                            lifecycleAware.start();                        } catch (Throwable e) {                            logger.error("Unable to start " + lifecycleAware + " - Exception follows.", e);                            if (e instanceof Error) {                                                                supervisoree.status.desiredState = LifecycleState.STOP;                                try {                                    lifecycleAware.stop();                                    logger.warn("Component {} stopped, since it could not be" + "successfully started due to missing dependencies", lifecycleAware);                                } catch (Throwable e1) {                                    logger.error("Unsuccessful attempt to " + "shutdown component: {} due to missing dependencies." + " Please shutdown the agent" + "or disable this component, or the agent will be" + "in an undefined state.", e1);                                    supervisoree.status.error = true;                                    if (e1 instanceof Error) {                                        throw (Error) e1;                                    }                                                                                                }                            }                            supervisoree.status.failures++;                        }                        break;                    case STOP:                        try {                            lifecycleAware.stop();                        } catch (Throwable e) {                            logger.error("Unable to stop " + lifecycleAware + " - Exception follows.", e);                            if (e instanceof Error) {                                throw (Error) e;                            }                            supervisoree.status.failures++;                        }                        break;                    default:                        logger.warn("I refuse to acknowledge {} as a desired state", supervisoree.status.desiredState);                }                if (!supervisoree.policy.isValid(lifecycleAware, supervisoree.status)) {                    logger.error("Policy {} of {} has been violated - supervisor should exit!", supervisoree.policy, lifecycleAware);                }            }        }    } catch (Throwable t) {        logger.error("Unexpected error", t);    }    logger.debug("Status check complete");}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    if (needToPurge) {        monitorService.purge();        needToPurge = false;    }}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return "{ lastSeen:" + lastSeen + " lastSeenState:" + lastSeenState + " desiredState:" + desiredState + " firstSeen:" + firstSeen + " failures:" + failures + " discard:" + discard + " error:" + error + " }";}
78956502fb1aedfe41bcb7d296273cd07f803a6fc511620045f98af2bf5720ee
isValid
 boolean isValid(LifecycleAware object, Status status)
{    return true;}
78956502fb1aedfe41bcb7d296273cd07f803a6fc511620045f98af2bf5720ee
isValid
 boolean isValid(LifecycleAware object, Status status)
{    return status.failures == 0;}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return "{ status:" + status + " policy:" + policy + " }";}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    int syncIntervalBytes = context.getInteger(SYNC_INTERVAL_BYTES, DEFAULT_SYNC_INTERVAL_BYTES);    String compressionCodec = context.getString(COMPRESSION_CODEC, DEFAULT_COMPRESSION_CODEC);    writer = new ReflectDatumWriter<T>(getSchema());    dataFileWriter = new DataFileWriter<T>(writer);    dataFileWriter.setSyncInterval(syncIntervalBytes);    try {        CodecFactory codecFactory = CodecFactory.fromString(compressionCodec);        dataFileWriter.setCodec(codecFactory);    } catch (AvroRuntimeException e) {        logger.warn("Unable to instantiate avro codec with name (" + compressionCodec + "). Compression disabled. Exception follows.", e);    }}
8e16e9a819af3299e39546ad020872007eb755dcb366430d3993b74dee1bacbf
afterCreate
public void afterCreate() throws IOException
{        dataFileWriter.create(getSchema(), getOutputStream());}
6b0e0eb6f48e834d2a656991dd837b62aa5933c8521ea4e91248dfcd2497a8b4
afterReopen
public void afterReopen() throws IOException
{        throw new UnsupportedOperationException("Avro API doesn't support append");}
4006d97185c9ea4783f6cf751ad0782e94ac872b01261a143985ae49fd402fec
write
public void write(Event event) throws IOException
{    T destType = convert(event);    dataFileWriter.append(destType);}
c3e67ec76f1b008887f1caba645a2614900cde6e477acca1bc3ecc36bf357fcf
flush
public void flush() throws IOException
{    dataFileWriter.flush();}
7a1f7a8f2fe39aaa0ecd2a186248a03a6459440636130fa195826e0616eafff7
beforeClose
public void beforeClose() throws IOException
{}
77bb5e791ef374371f37b37dfa587fb1895f9b41427ff7b2adba8629c2a9e150
supportsReopen
public boolean supportsReopen()
{    return false;}
d5733c44c840ac46efb6598535ea2075945778acf86288e95348ecae0d94fc1b
initialize
private void initialize() throws IOException, NoSuchAlgorithmException
{    SeekableResettableInputBridge in = new SeekableResettableInputBridge(ris);    long pos = in.tell();    in.seek(0L);    fileReader = new DataFileReader<GenericRecord>(in, new GenericDatumReader<GenericRecord>());    fileReader.sync(pos);    schema = fileReader.getSchema();    datumWriter = new GenericDatumWriter(schema);    out = new ByteArrayOutputStream();    encoder = EncoderFactory.get().binaryEncoder(out, encoder);    schemaHash = SchemaNormalization.parsingFingerprint("CRC-64-AVRO", schema);    schemaHashString = Hex.encodeHexString(schemaHash);}
faacd45ce21d1cbb584374a868166f2921664ee3631184fbc58c2a737d41fefb
readEvent
public Event readEvent() throws IOException
{    if (fileReader.hasNext()) {        record = fileReader.next(record);        out.reset();        datumWriter.write(record, encoder);        encoder.flush();                Event event = EventBuilder.withBody(out.toByteArray());        if (schemaType == AvroSchemaType.HASH) {            event.getHeaders().put(AVRO_SCHEMA_HEADER_HASH, schemaHashString);        } else {            event.getHeaders().put(AVRO_SCHEMA_HEADER_LITERAL, schema.toString());        }        return event;    }    return null;}
54fb38a1d197eddb2b60ecdecace63039e95c1beccdbf2a178d1f6dbdaf9e966
readEvents
public List<Event> readEvents(int numEvents) throws IOException
{    List<Event> events = Lists.newArrayList();    for (int i = 0; i < numEvents && fileReader.hasNext(); i++) {        Event event = readEvent();        if (event != null) {            events.add(event);        }    }    return events;}
740b2d69a871de3f06de1d6974b0a76e5d58ff23733964f6f17d60eedfcb816d
mark
public void mark() throws IOException
{    long pos = fileReader.previousSync() - DataFileConstants.SYNC_SIZE;    if (pos < 0)        pos = 0;    ((RemoteMarkable) ris).markPosition(pos);}
39fd2a669bd97a959085d10145da4dcd11d83878afcd67b2123354de7e8771d9
reset
public void reset() throws IOException
{    long pos = ((RemoteMarkable) ris).getMarkPosition();    fileReader.sync(pos);}
e0823f55b3a09d41a3e1e792f7e6687db9199c2db9b29e9922d93cbdc6f1284b
close
public void close() throws IOException
{    ris.close();}
6f66078c2401f77d7459cea082a47e98f945e1a50c5ae6fe6f03aefc3aed9558
build
public EventDeserializer build(Context context, ResettableInputStream in)
{    if (!(in instanceof RemoteMarkable)) {        throw new IllegalArgumentException("Cannot use this deserializer " + "without a RemoteMarkable input stream");    }    AvroEventDeserializer deserializer = new AvroEventDeserializer(context, in);    try {        deserializer.initialize();    } catch (Exception e) {        throw new FlumeException("Cannot instantiate deserializer", e);    }    return deserializer;}
d82b4dff89e8597e847f70bbec619b3fbe6165fdff6be403c9711e93ebce3d4d
seek
public void seek(long p) throws IOException
{    ris.seek(p);}
0efa2bd8fc7bc3d72996c492a3eaca80646290caeceea873a5afabb84aa9504c
tell
public long tell() throws IOException
{    return ris.tell();}
6be07d6c52de04a91907264c1c435ebdd48a3b2cf48f2e117699a543fff56681
length
public long length() throws IOException
{    if (ris instanceof LengthMeasurable) {        return ((LengthMeasurable) ris).length();    } else {                return Long.MAX_VALUE;    }}
56e08d87e6bd0be2a60f9b2de3195d58bc9d56a2637f6fed6210d21e832632ea
read
public int read(byte[] b, int off, int len) throws IOException
{    return ris.read(b, off, len);}
e0823f55b3a09d41a3e1e792f7e6687db9199c2db9b29e9922d93cbdc6f1284b
close
public void close() throws IOException
{    ris.close();}
77bb5e791ef374371f37b37dfa587fb1895f9b41427ff7b2adba8629c2a9e150
supportsReopen
public boolean supportsReopen()
{    return true;}
13e6dce1d3c574fc5e362aa0f78a4c13c8ac8c5fe33c1216f59240ca9bae91ea
afterCreate
public void afterCreate()
{}
f90b53038a60ac705d39f6f72fc87403a9ea4351dcfc99667d503e1e2b8a1f47
afterReopen
public void afterReopen()
{}
b407c3929b7bc9ea82a0f95b657f4bf3fbdc05b81d71309abdf5b7f8ed225605
beforeClose
public void beforeClose()
{}
61051314be11cbf715bd0d33e121da75fbf313fb46410a15b2ea61b90ff451dc
write
public void write(Event e) throws IOException
{    out.write(e.getBody());    if (appendNewline) {        out.write('\n');    }}
c3e67ec76f1b008887f1caba645a2614900cde6e477acca1bc3ecc36bf357fcf
flush
public void flush() throws IOException
{}
74e8fa60d6fc51ca3723cb17e94c593fb7b56c215ce37ab9c280f06c5b880433
build
public EventSerializer build(Context context, OutputStream out)
{    BodyTextEventSerializer s = new BodyTextEventSerializer(out, context);    return s;}
9effb0dde099d3eed1a559b68b5cc14d2a3cb59af0c26748d9cef2e2470b87a5
getInstance
public static DurablePositionTracker getInstance(File trackerFile, String target) throws IOException
{    if (!trackerFile.exists()) {        return new DurablePositionTracker(trackerFile, target);    }        DurablePositionTracker oldTracker = new DurablePositionTracker(trackerFile, target);    String existingTarget = oldTracker.getTarget();    long targetPosition = oldTracker.getPosition();    oldTracker.close();    File tmpMeta = File.createTempFile(trackerFile.getName(), ".tmp", trackerFile.getParentFile());    tmpMeta.delete();    DurablePositionTracker tmpTracker = new DurablePositionTracker(tmpMeta, existingTarget);    tmpTracker.storePosition(targetPosition);    tmpTracker.close();        if (PlatformDetect.isWindows()) {        if (!trackerFile.delete()) {            throw new IOException("Unable to delete existing meta file " + trackerFile);        }    }        if (!tmpMeta.renameTo(trackerFile)) {        throw new IOException("Unable to rename " + tmpMeta + " to " + trackerFile);    }        DurablePositionTracker newTracker = new DurablePositionTracker(trackerFile, existingTarget);    return newTracker;}
81ba9df88b2fae8d350af70cf825bcb3c97f5dda9de28ccd33808f5da2efe22b
initReader
private void initReader() throws IOException
{    long syncPos = trackerFile.length() - 256L;    if (syncPos < 0)        syncPos = 0L;    reader.sync(syncPos);    while (reader.hasNext()) {        reader.next(metaCache);    }}
fc7286b746c0e4228647850868e1855699a361f072597e83ac07d4495b79801e
storePosition
public synchronized void storePosition(long position) throws IOException
{    metaCache.setOffset(position);    writer.append(metaCache);    writer.sync();    writer.flush();}
67cd0d7bd111ce1ee11d2f1d1d6f39bacde44a4b9379d49c0977be0dd30a44c3
getPosition
public synchronized long getPosition()
{    return metaCache.getOffset();}
bbc94651494aa1806a69f755aa4fb0e77230e45e6bab1ee17a348de34ee7d11f
getTarget
public String getTarget()
{    return target;}
e0823f55b3a09d41a3e1e792f7e6687db9199c2db9b29e9922d93cbdc6f1284b
close
public void close() throws IOException
{    if (isOpen) {        writer.close();        reader.close();        isOpen = false;    }}
47f4358f9b9255bfbb9eeb15dcf47b5ff02c38942878e93dd84972a6f6c48ae3
getInstance
public static EventDeserializer getInstance(String deserializerType, Context context, ResettableInputStream in)
{    Preconditions.checkNotNull(deserializerType, "serializer type must not be null");        EventDeserializerType type;    try {        type = EventDeserializerType.valueOf(deserializerType.toUpperCase(Locale.ENGLISH));    } catch (IllegalArgumentException e) {        logger.debug("Not in enum, loading builder class: {}", deserializerType);        type = EventDeserializerType.OTHER;    }    Class<? extends EventDeserializer.Builder> builderClass = type.getBuilderClass();        if (builderClass == null) {        try {            Class c = Class.forName(deserializerType);            if (c != null && EventDeserializer.Builder.class.isAssignableFrom(c)) {                builderClass = (Class<? extends EventDeserializer.Builder>) c;            } else {                String errMessage = "Unable to instantiate Builder from " + deserializerType + ": does not appear to implement " + EventDeserializer.Builder.class.getName();                throw new FlumeException(errMessage);            }        } catch (ClassNotFoundException ex) {            logger.error("Class not found: " + deserializerType, ex);            throw new FlumeException(ex);        }    }        EventDeserializer.Builder builder;    try {        builder = builderClass.newInstance();    } catch (InstantiationException ex) {        String errMessage = "Cannot instantiate builder: " + deserializerType;        logger.error(errMessage, ex);        throw new FlumeException(errMessage, ex);    } catch (IllegalAccessException ex) {        String errMessage = "Cannot instantiate builder: " + deserializerType;        logger.error(errMessage, ex);        throw new FlumeException(errMessage, ex);    }    return builder.build(context, in);}
e492cd9b6359d1088f2095b7747604f5b7e26ad1928ee559b1690c1aad12bb68
getBuilderClass
public Class<? extends EventDeserializer.Builder> getBuilderClass()
{    return builderClass;}
0c6ab28bf2b23bf42a01ff4a3b2c20f8454db38048bbba6dd5152860c5fec9ee
getInstance
public static EventSerializer getInstance(String serializerType, Context context, OutputStream out)
{    Preconditions.checkNotNull(serializerType, "serializer type must not be null");        EventSerializerType type;    try {        type = EventSerializerType.valueOf(serializerType.toUpperCase(Locale.ENGLISH));    } catch (IllegalArgumentException e) {        logger.debug("Not in enum, loading builder class: {}", serializerType);        type = EventSerializerType.OTHER;    }    Class<? extends EventSerializer.Builder> builderClass = type.getBuilderClass();        if (builderClass == null) {        try {            Class c = Class.forName(serializerType);            if (c != null && EventSerializer.Builder.class.isAssignableFrom(c)) {                builderClass = (Class<? extends EventSerializer.Builder>) c;            } else {                String errMessage = "Unable to instantiate Builder from " + serializerType + ": does not appear to implement " + EventSerializer.Builder.class.getName();                throw new FlumeException(errMessage);            }        } catch (ClassNotFoundException ex) {            logger.error("Class not found: " + serializerType, ex);            throw new FlumeException(ex);        }    }        EventSerializer.Builder builder;    try {        builder = builderClass.newInstance();    } catch (InstantiationException ex) {        String errMessage = "Cannot instantiate builder: " + serializerType;        logger.error(errMessage, ex);        throw new FlumeException(errMessage, ex);    } catch (IllegalAccessException ex) {        String errMessage = "Cannot instantiate builder: " + serializerType;        logger.error(errMessage, ex);        throw new FlumeException(errMessage, ex);    }    return builder.build(context, out);}
d513e63b83c006aa561648ead2e3c55be6677aab206e55bc3bffde7c9b1fe411
getBuilderClass
public Class<? extends EventSerializer.Builder> getBuilderClass()
{    return builderClass;}
83126e46f74779f8ca7db78442694c63703e46d31d53234da4174f2af8bfc162
getSchema
protected Schema getSchema()
{    return SCHEMA;}
d714b22089f1841fc084c332fb23274bae6df3e73b3dd079d5243c5d4e61d251
getOutputStream
protected OutputStream getOutputStream()
{    return out;}
649b3e5d7c5708e60d2c54b455e84dc93cf0a40eec9eb25129e2c876678acba4
convert
protected Event convert(Event event)
{    return event;}
74e8fa60d6fc51ca3723cb17e94c593fb7b56c215ce37ab9c280f06c5b880433
build
public EventSerializer build(Context context, OutputStream out)
{    FlumeEventAvroEventSerializer writer = new FlumeEventAvroEventSerializer(out);    writer.configure(context);    return writer;}
77bb5e791ef374371f37b37dfa587fb1895f9b41427ff7b2adba8629c2a9e150
supportsReopen
public boolean supportsReopen()
{    return true;}
13e6dce1d3c574fc5e362aa0f78a4c13c8ac8c5fe33c1216f59240ca9bae91ea
afterCreate
public void afterCreate()
{}
f90b53038a60ac705d39f6f72fc87403a9ea4351dcfc99667d503e1e2b8a1f47
afterReopen
public void afterReopen()
{}
b407c3929b7bc9ea82a0f95b657f4bf3fbdc05b81d71309abdf5b7f8ed225605
beforeClose
public void beforeClose()
{}
61051314be11cbf715bd0d33e121da75fbf313fb46410a15b2ea61b90ff451dc
write
public void write(Event e) throws IOException
{    out.write((e.getHeaders() + " ").getBytes());    out.write(e.getBody());    if (appendNewline) {        out.write('\n');    }}
c3e67ec76f1b008887f1caba645a2614900cde6e477acca1bc3ecc36bf357fcf
flush
public void flush() throws IOException
{}
74e8fa60d6fc51ca3723cb17e94c593fb7b56c215ce37ab9c280f06c5b880433
build
public EventSerializer build(Context context, OutputStream out)
{    HeaderAndBodyTextEventSerializer s = new HeaderAndBodyTextEventSerializer(out, context);    return s;}
faacd45ce21d1cbb584374a868166f2921664ee3631184fbc58c2a737d41fefb
readEvent
public Event readEvent() throws IOException
{    ensureOpen();    String line = readLine();    if (line == null) {        return null;    } else {        return EventBuilder.withBody(line, outputCharset);    }}
54fb38a1d197eddb2b60ecdecace63039e95c1beccdbf2a178d1f6dbdaf9e966
readEvents
public List<Event> readEvents(int numEvents) throws IOException
{    ensureOpen();    List<Event> events = Lists.newLinkedList();    for (int i = 0; i < numEvents; i++) {        Event event = readEvent();        if (event != null) {            events.add(event);        } else {            break;        }    }    return events;}
740b2d69a871de3f06de1d6974b0a76e5d58ff23733964f6f17d60eedfcb816d
mark
public void mark() throws IOException
{    ensureOpen();    in.mark();}
39fd2a669bd97a959085d10145da4dcd11d83878afcd67b2123354de7e8771d9
reset
public void reset() throws IOException
{    ensureOpen();    in.reset();}
e0823f55b3a09d41a3e1e792f7e6687db9199c2db9b29e9922d93cbdc6f1284b
close
public void close() throws IOException
{    if (isOpen) {        reset();        in.close();        isOpen = false;    }}
558d14d22f2b89dd49d031eee7a0a0504b3594b3e64004bdfc806522c4e44f4f
ensureOpen
private void ensureOpen()
{    if (!isOpen) {        throw new IllegalStateException("Serializer has been closed");    }}
a17681413f45b8b8a39a535540c391709ab9d0334f5fc9033b4d909c57acbea4
readLine
private String readLine() throws IOException
{    StringBuilder sb = new StringBuilder();    int c;    int readChars = 0;    while ((c = in.readChar()) != -1) {        readChars++;                if (c == '\n') {            break;        }        sb.append((char) c);        if (readChars >= maxLineLength) {            logger.warn("Line length exceeds max ({}), truncating line!", maxLineLength);            break;        }    }    if (readChars > 0) {        return sb.toString();    } else {        return null;    }}
6f66078c2401f77d7459cea082a47e98f945e1a50c5ae6fe6f03aefc3aed9558
build
public EventDeserializer build(Context context, ResettableInputStream in)
{    return new LineDeserializer(context, in);}
a37e9b68a73d4980d3166cc7603c09d2d17c57346d25be1dab0d80ba4b4c9cd8
read
public synchronized int read() throws IOException
{    int len = read(byteBuf, 0, 1);    if (len == -1) {        return -1;        } else if (len == 0) {        return -1;    } else {        return byteBuf[0] & 0xFF;    }}
8e59c6150e256449c8da582f6f12741b77299ddd71a7e101f0e3e39ad6662e56
read
public synchronized int read(byte[] b, int off, int len) throws IOException
{    logger.trace("read(buf, {}, {})", off, len);    if (position >= fileSize) {        return -1;    }    if (!buf.hasRemaining()) {        refillBuf();    }    int rem = buf.remaining();    if (len > rem) {        len = rem;    }    buf.get(b, off, len);    incrPosition(len, true);    return len;}
a05d3c0fd23dc48188a4b59e70126d128c2d3b2aa2b9110f1dd02202488a01fd
readChar
public synchronized int readChar() throws IOException
{        if (hasLowSurrogate) {        hasLowSurrogate = false;        return lowSurrogate;    }        if (buf.remaining() < maxCharWidth) {        buf.clear();        buf.flip();        refillBuf();    }    int start = buf.position();    charBuf.clear();    charBuf.limit(1);    boolean isEndOfInput = false;    if (position >= fileSize) {        isEndOfInput = true;    }    CoderResult res = decoder.decode(buf, charBuf, isEndOfInput);    if (res.isMalformed() || res.isUnmappable()) {        res.throwException();    }    int delta = buf.position() - start;    charBuf.flip();        if (charBuf.hasRemaining()) {        char c = charBuf.get();        incrPosition(delta, true);        return c;    }        if (buf.hasRemaining()) {        charBuf.clear();                charBuf.limit(2);                res = decoder.decode(buf, charBuf, isEndOfInput);        if (res.isMalformed() || res.isUnmappable()) {            res.throwException();        }        charBuf.flip();                if (charBuf.remaining() == 2) {            char highSurrogate = charBuf.get();                        lowSurrogate = charBuf.get();                        if (!Character.isHighSurrogate(highSurrogate) || !Character.isLowSurrogate(lowSurrogate)) {                                logger.warn("Decoded a pair of chars, but it does not seem to be a surrogate pair: {} {}", (int) highSurrogate, (int) lowSurrogate);            }            hasLowSurrogate = true;                        delta = buf.position() - start;            incrPosition(delta, true);                        return highSurrogate;        }    }        incrPosition(delta, false);    return -1;}
11b2af6bd08121cae1b5dda2c2824ad7a48fd92c8edc7df1740b162ff942ec54
refillBuf
private void refillBuf() throws IOException
{    buf.compact();        chan.position(position);    chan.read(buf);    buf.flip();}
740b2d69a871de3f06de1d6974b0a76e5d58ff23733964f6f17d60eedfcb816d
mark
public void mark() throws IOException
{    tracker.storePosition(tell());}
a6fabb9e21d6b463db8da3ab05154a73a3dab7480ac216a8f00ac1ce437c16aa
markPosition
public void markPosition(long position) throws IOException
{    tracker.storePosition(position);}
71beb4753628e119b20d0cd4ce3a841b567b82dda9e769c6651c523672645ce2
getMarkPosition
public long getMarkPosition() throws IOException
{    return tracker.getPosition();}
39fd2a669bd97a959085d10145da4dcd11d83878afcd67b2123354de7e8771d9
reset
public void reset() throws IOException
{    seek(tracker.getPosition());}
6be07d6c52de04a91907264c1c435ebdd48a3b2cf48f2e117699a543fff56681
length
public long length() throws IOException
{    return file.length();}
0efa2bd8fc7bc3d72996c492a3eaca80646290caeceea873a5afabb84aa9504c
tell
public long tell() throws IOException
{    logger.trace("Tell position: {}", syncPosition);    return syncPosition;}
f4460e78147559e82c8e3ceb26424f7150d712ba06d0293383d75be65b94be19
seek
public synchronized void seek(long newPos) throws IOException
{    logger.trace("Seek to position: {}", newPos);        long relativeChange = newPos - position;        if (relativeChange == 0)        return;    long newBufPos = buf.position() + relativeChange;    if (newBufPos >= 0 && newBufPos < buf.limit()) {                buf.position((int) newBufPos);    } else {                buf.clear();        buf.flip();    }        decoder.reset();        chan.position(newPos);        position = syncPosition = newPos;}
c98bbc54c9531b44077d8c389c8b9060fdf2eac4df1cef53658fa44c552e14b4
incrPosition
private void incrPosition(int incr, boolean updateSyncPosition)
{    position += incr;    if (updateSyncPosition) {        syncPosition = position;    }}
e0823f55b3a09d41a3e1e792f7e6687db9199c2db9b29e9922d93cbdc6f1284b
close
public void close() throws IOException
{    tracker.close();    in.close();}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    clientProps = new Properties();    hostname = context.getString("hostname");    port = context.getInteger("port");    Preconditions.checkState(hostname != null, "No hostname specified");    Preconditions.checkState(port != null, "No port specified");    clientProps.setProperty(RpcClientConfigurationConstants.CONFIG_HOSTS, "h1");    clientProps.setProperty(RpcClientConfigurationConstants.CONFIG_HOSTS_PREFIX + "h1", hostname + ":" + port);    for (Entry<String, String> entry : context.getParameters().entrySet()) {        clientProps.setProperty(entry.getKey(), entry.getValue());    }    batchSize = AbstractRpcClient.parseBatchSize(clientProps);    if (sinkCounter == null) {        sinkCounter = new SinkCounter(getName());    }    cxnResetInterval = context.getInteger("reset-connection-interval", DEFAULT_CXN_RESET_INTERVAL);    if (cxnResetInterval == DEFAULT_CXN_RESET_INTERVAL) {        logger.info("Connection reset is set to " + String.valueOf(DEFAULT_CXN_RESET_INTERVAL) + ". Will not reset connection to next hop");    }}
5f74bfc78e9acad2daa95c9a0a46642b5c5a7df747fe483f1ecae25d2d32c473
createConnection
private void createConnection() throws FlumeException
{    if (client == null) {        logger.info("Rpc sink {}: Building RpcClient with hostname: {}, " + "port: {}", new Object[] { getName(), hostname, port });        try {            resetConnectionFlag = new AtomicBoolean(false);            client = initializeRpcClient(clientProps);            Preconditions.checkNotNull(client, "Rpc Client could not be " + "initialized. " + getName() + " could not be started");            sinkCounter.incrementConnectionCreatedCount();            if (cxnResetInterval > 0) {                cxnResetExecutor.schedule(new Runnable() {                    @Override                    public void run() {                        resetConnectionFlag.set(true);                    }                }, cxnResetInterval, TimeUnit.SECONDS);            }        } catch (Exception ex) {            sinkCounter.incrementConnectionFailedCount();            if (ex instanceof FlumeException) {                throw (FlumeException) ex;            } else {                throw new FlumeException(ex);            }        }        logger.debug("Rpc sink {}: Created RpcClient: {}", getName(), client);    }}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    resetConnectionFlag.set(true);}
d5d97276214bd177f3f64da8208c16e3103b486feafd85feea822d2ad3923f83
resetConnection
private void resetConnection()
{    try {        destroyConnection();        createConnection();    } catch (Throwable throwable) {                logger.error("Error while trying to expire connection", throwable);    }}
eb60ae841c2d2082e59317db5dad2d34255a87ba153c6718320fafe5da2c84c7
destroyConnection
private void destroyConnection()
{    if (client != null) {        logger.debug("Rpc sink {} closing Rpc client: {}", getName(), client);        try {            client.close();            sinkCounter.incrementConnectionClosedCount();        } catch (FlumeException e) {            sinkCounter.incrementConnectionFailedCount();            logger.error("Rpc sink " + getName() + ": Attempt to close Rpc " + "client failed. Exception follows.", e);        }    }    client = null;}
95c095e458cc951c92af1f3e27385fe0445cfa672551cef8c9f09ee948f772d3
verifyConnection
private void verifyConnection() throws FlumeException
{    if (client == null) {        createConnection();    } else if (!client.isActive()) {        destroyConnection();        createConnection();    }}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    logger.info("Starting {}...", this);    sinkCounter.start();    try {        createConnection();    } catch (FlumeException e) {        logger.warn("Unable to create Rpc client using hostname: " + hostname + ", port: " + port, e);        /* Try to prevent leaking resources. */        destroyConnection();    }    super.start();    logger.info("Rpc sink {} started.", getName());}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    logger.info("Rpc sink {} stopping...", getName());    destroyConnection();    cxnResetExecutor.shutdown();    try {        if (cxnResetExecutor.awaitTermination(5, TimeUnit.SECONDS)) {            cxnResetExecutor.shutdownNow();        }    } catch (Exception ex) {        logger.error("Interrupted while waiting for connection reset executor to shut down");    }    sinkCounter.stop();    super.stop();    logger.info("Rpc sink {} stopped. Metrics: {}", getName(), sinkCounter);}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return "RpcSink " + getName() + " { host: " + hostname + ", port: " + port + " }";}
e52e5e378330fd7f87ee30351bbfcec47b751fee12ece2ef0cfdd77a08c906e1
process
public Status process() throws EventDeliveryException
{    Status status = Status.READY;    Channel channel = getChannel();    Transaction transaction = channel.getTransaction();    if (resetConnectionFlag.get()) {        resetConnection();                                resetConnectionFlag.set(false);    }    try {        transaction.begin();        verifyConnection();        List<Event> batch = Lists.newLinkedList();        for (int i = 0; i < client.getBatchSize(); i++) {            Event event = channel.take();            if (event == null) {                break;            }            batch.add(event);        }        int size = batch.size();        int batchSize = client.getBatchSize();        if (size == 0) {            sinkCounter.incrementBatchEmptyCount();            status = Status.BACKOFF;        } else {            if (size < batchSize) {                sinkCounter.incrementBatchUnderflowCount();            } else {                sinkCounter.incrementBatchCompleteCount();            }            sinkCounter.addToEventDrainAttemptCount(size);            client.appendBatch(batch);        }        transaction.commit();        sinkCounter.addToEventDrainSuccessCount(size);    } catch (Throwable t) {        transaction.rollback();        if (t instanceof Error) {            throw (Error) t;        } else if (t instanceof ChannelException) {            logger.error("Rpc Sink " + getName() + ": Unable to get event from" + " channel " + channel.getName() + ". Exception follows.", t);            sinkCounter.incrementChannelReadFail();            status = Status.BACKOFF;        } else {            sinkCounter.incrementEventWriteFail();            destroyConnection();            throw new EventDeliveryException("Failed to send events", t);        }    } finally {        transaction.close();    }    return status;}
da681ba142039d381d5b1c53abc7845fb3eb773f98c224b9a759bef7a85b8e24
getUnderlyingClient
 RpcClient getUnderlyingClient()
{    return client;}
dcc511f35190533c2d6fcc6073d66b12e111f5004c64ff08ccc3609a06ab844d
getBatchSize
public long getBatchSize()
{    return batchSize;}
5b05914888e421f26bff6f39231facdd35759f746a9af780ebac2cf5b2c81932
start
public synchronized void start()
{    Preconditions.checkState(channel != null, "No channel configured");    lifecycleState = LifecycleState.START;}
06e1ddba8663c90da407ac517f29ed70555cfe57b0332c9a96e7c696e0255364
stop
public synchronized void stop()
{    lifecycleState = LifecycleState.STOP;}
a61510da3112b9522b0c86d8a03cd3a8b8168239e91a6ef6240d2692147969ac
getChannel
public synchronized Channel getChannel()
{    return channel;}
2bb3503a646f3daf32e9f9b6b779db5bc1e30d6d1d041d0a2c00ed8eda95b76f
setChannel
public synchronized void setChannel(Channel channel)
{    this.channel = channel;}
82e342b29ff4fad8c64d554dc21ad55a5f2c8063fce3b580e896b7968d90473a
getLifecycleState
public synchronized LifecycleState getLifecycleState()
{    return lifecycleState;}
831a1aefa333c15f969e26873201d65e004e9eae64fe390a121d56ac6619f888
setName
public synchronized void setName(String name)
{    this.name = name;}
5a8aa5c66e12ab4bee0bd8ab8101da1e45260314118196130f684c97aec2075b
getName
public synchronized String getName()
{    return name;}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return this.getClass().getName() + "{name:" + name + ", channel:" + channel.getName() + "}";}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    for (Sink s : sinkList) {        s.start();    }    state = LifecycleState.START;}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    for (Sink s : sinkList) {        s.stop();    }    state = LifecycleState.STOP;}
54497ccb2ff9760f1ec7fc0d0055d4bc60d5981953c5f3d7550c4b31a01e7642
getLifecycleState
public LifecycleState getLifecycleState()
{    return state;}
f695d7ad6b14573ebac5862366b06ace6d813150f5ef5408700977ad05b2fedb
setSinks
public void setSinks(List<Sink> sinks)
{    List<Sink> list = new ArrayList<Sink>();    list.addAll(sinks);    sinkList = Collections.unmodifiableList(list);}
e4f8d4b14bdda07ada9cc746db1c29a1be4389797605069278b4ed8d101231af
getSinks
protected List<Sink> getSinks()
{    return sinkList;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    Long timeOut = context.getLong("maxTimeOut");    if (timeOut != null) {        maxTimeOut = timeOut;    }}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    state = LifecycleState.START;}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    state = LifecycleState.STOP;}
54497ccb2ff9760f1ec7fc0d0055d4bc60d5981953c5f3d7550c4b31a01e7642
getLifecycleState
public LifecycleState getLifecycleState()
{    return state;}
f695d7ad6b14573ebac5862366b06ace6d813150f5ef5408700977ad05b2fedb
setSinks
public void setSinks(List<Sink> sinks)
{    sinkList = new ArrayList<Sink>();    sinkList.addAll(sinks);}
e4f8d4b14bdda07ada9cc746db1c29a1be4389797605069278b4ed8d101231af
getSinks
protected List<Sink> getSinks()
{    return sinkList;}
497dece7d60715f461b0442340f1acd3c1030611700f9ca57462b4f292dbc014
informSinkFailed
public void informSinkFailed(Sink failedSink)
{}
7cf77a31240dd1bfbea90dee2aefa991063c1ecde51e0ad04a2e42de2a19a99c
initializeRpcClient
protected RpcClient initializeRpcClient(Properties props)
{    logger.info("Attempting to create Avro Rpc client.");    return RpcClientFactory.getInstance(props);}
8bc18de440e794d62909c616e30b34c00bae152fc350ca8241c385cff9ffe260
create
public Sink create(String name, String type) throws FlumeException
{    Preconditions.checkNotNull(name, "name");    Preconditions.checkNotNull(type, "type");    logger.info("Creating instance of sink: {}, type: {}", name, type);    Class<? extends Sink> sinkClass = getClass(type);    try {        Sink sink = sinkClass.newInstance();        sink.setName(name);        return sink;    } catch (Exception ex) {        throw new FlumeException("Unable to create sink: " + name + ", type: " + type + ", class: " + sinkClass.getName(), ex);    }}
634505b6021a89a5cb061eebbff1f29aa3b9c38864352785c42d80c4ba3e92aa
getClass
public Class<? extends Sink> getClass(String type) throws FlumeException
{    String sinkClassName = type;    SinkType sinkType = SinkType.OTHER;    try {        sinkType = SinkType.valueOf(type.toUpperCase(Locale.ENGLISH));    } catch (IllegalArgumentException ex) {        logger.debug("Sink type {} is a custom type", type);    }    if (!sinkType.equals(SinkType.OTHER)) {        sinkClassName = sinkType.getSinkClassName();    }    try {        return (Class<? extends Sink>) Class.forName(sinkClassName);    } catch (Exception ex) {        throw new FlumeException("Unable to load sink type: " + type + ", class: " + sinkClassName, ex);    }}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    Preconditions.checkNotNull(sink, "DefaultSinkProcessor sink not set");    sink.start();    lifecycleState = LifecycleState.START;}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    Preconditions.checkNotNull(sink, "DefaultSinkProcessor sink not set");    sink.stop();    lifecycleState = LifecycleState.STOP;}
54497ccb2ff9760f1ec7fc0d0055d4bc60d5981953c5f3d7550c4b31a01e7642
getLifecycleState
public LifecycleState getLifecycleState()
{    return lifecycleState;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{}
e52e5e378330fd7f87ee30351bbfcec47b751fee12ece2ef0cfdd77a08c906e1
process
public Status process() throws EventDeliveryException
{    return sink.process();}
f695d7ad6b14573ebac5862366b06ace6d813150f5ef5408700977ad05b2fedb
setSinks
public void setSinks(List<Sink> sinks)
{    Preconditions.checkNotNull(sinks);    Preconditions.checkArgument(sinks.size() == 1, "DefaultSinkPolicy can " + "only handle one sink, " + "try using a policy that supports multiple sinks");    sink = sinks.get(0);}
57746d8a7acafcf5647f649109937334de6090302f29c32ed7da0df311700e35
configure
public void configure(ComponentConfiguration conf)
{}
431a9a6a509893125a5f79ca50c7be6f0a9df0cf6929d220c86e2636879a30e8
compareTo
public int compareTo(FailedSink arg0)
{    return refresh.compareTo(arg0.refresh);}
7b3336b7cf84b0c6ce2db9c7eb76a83e597e7737629a898e17ee59dfe8650ff7
getRefresh
public Long getRefresh()
{    return refresh;}
a1d61526efb1cd79070475dd88d9b6cc13804b426a526f20a3800ce88a05b286
getSink
public Sink getSink()
{    return sink;}
662807e717be061b7681bfc98fc289c15e50f09e1fa1e4f653abf892fe96dced
getPriority
public Integer getPriority()
{    return priority;}
54aad337e62e250cbec4383274a234aaa58ac22232a94d808e99a9845f4851c8
incFails
public void incFails()
{    sequentialFailures++;    adjustRefresh();    logger.debug("Sink {} failed again, new refresh is at {}, current time {}", new Object[] { sink.getName(), refresh, System.currentTimeMillis() });}
c0109b9e0f560875c39a308844d6c7aec71c74a010383ced30e298f40fdfc905
adjustRefresh
private void adjustRefresh()
{    refresh = System.currentTimeMillis() + Math.min(maxPenalty, (1 << sequentialFailures) * FAILURE_PENALTY);}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    liveSinks = new TreeMap<Integer, Sink>();    failedSinks = new PriorityQueue<FailedSink>();    Integer nextPrio = 0;    String maxPenaltyStr = context.getString(MAX_PENALTY_PREFIX);    if (maxPenaltyStr == null) {        maxPenalty = DEFAULT_MAX_PENALTY;    } else {        try {            maxPenalty = Integer.parseInt(maxPenaltyStr);        } catch (NumberFormatException e) {            logger.warn("{} is not a valid value for {}", new Object[] { maxPenaltyStr, MAX_PENALTY_PREFIX });            maxPenalty = DEFAULT_MAX_PENALTY;        }    }    for (Entry<String, Sink> entry : sinks.entrySet()) {        String priStr = PRIORITY_PREFIX + entry.getKey();        Integer priority;        try {            priority = Integer.parseInt(context.getString(priStr));        } catch (Exception e) {            priority = --nextPrio;        }        if (!liveSinks.containsKey(priority)) {            liveSinks.put(priority, sinks.get(entry.getKey()));        } else {            logger.warn("Sink {} not added to FailverSinkProcessor as priority" + "duplicates that of sink {}", entry.getKey(), liveSinks.get(priority));        }    }    activeSink = liveSinks.get(liveSinks.lastKey());}
e52e5e378330fd7f87ee30351bbfcec47b751fee12ece2ef0cfdd77a08c906e1
process
public Status process() throws EventDeliveryException
{        Long now = System.currentTimeMillis();    while (!failedSinks.isEmpty() && failedSinks.peek().getRefresh() < now) {        FailedSink cur = failedSinks.poll();        Status s;        try {            s = cur.getSink().process();            if (s == Status.READY) {                liveSinks.put(cur.getPriority(), cur.getSink());                activeSink = liveSinks.get(liveSinks.lastKey());                logger.debug("Sink {} was recovered from the fail list", cur.getSink().getName());            } else {                                failedSinks.add(cur);            }            return s;        } catch (Exception e) {            cur.incFails();            failedSinks.add(cur);        }    }    Status ret = null;    while (activeSink != null) {        try {            ret = activeSink.process();            return ret;        } catch (Exception e) {            logger.warn("Sink {} failed and has been sent to failover list", activeSink.getName(), e);            activeSink = moveActiveToDeadAndGetNext();        }    }    throw new EventDeliveryException("All sinks failed to process, " + "nothing left to failover to");}
0ba31535cd303061a0dc36872ac621a06b8dc853c1066d925c318f5e80bb499f
moveActiveToDeadAndGetNext
private Sink moveActiveToDeadAndGetNext()
{    Integer key = liveSinks.lastKey();    failedSinks.add(new FailedSink(key, activeSink, 1));    liveSinks.remove(key);    if (liveSinks.isEmpty())        return null;    if (liveSinks.lastKey() != null) {        return liveSinks.get(liveSinks.lastKey());    } else {        return null;    }}
f695d7ad6b14573ebac5862366b06ace6d813150f5ef5408700977ad05b2fedb
setSinks
public void setSinks(List<Sink> sinks)
{        super.setSinks(sinks);    this.sinks = new HashMap<String, Sink>();    for (Sink sink : sinks) {        this.sinks.put(sink.getName(), sink);    }}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    Preconditions.checkState(getSinks().size() > 1, "The LoadBalancingSinkProcessor cannot be used for a single sink. " + "Please configure more than one sinks and try again.");    String selectorTypeName = context.getString(CONFIG_SELECTOR, SELECTOR_NAME_ROUND_ROBIN);    Boolean shouldBackOff = context.getBoolean(CONFIG_BACKOFF, false);    selector = null;    if (selectorTypeName.equalsIgnoreCase(SELECTOR_NAME_ROUND_ROBIN)) {        selector = new RoundRobinSinkSelector(shouldBackOff);    } else if (selectorTypeName.equalsIgnoreCase(SELECTOR_NAME_RANDOM)) {        selector = new RandomOrderSinkSelector(shouldBackOff);    } else {        try {            @SuppressWarnings("unchecked")            Class<? extends SinkSelector> klass = (Class<? extends SinkSelector>) Class.forName(selectorTypeName);            selector = klass.newInstance();        } catch (Exception ex) {            throw new FlumeException("Unable to instantiate sink selector: " + selectorTypeName, ex);        }    }    selector.setSinks(getSinks());    selector.configure(new Context(context.getSubProperties(CONFIG_SELECTOR_PREFIX)));    LOGGER.debug("Sink selector: " + selector + " initialized");}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    super.start();    selector.start();}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    super.stop();    selector.stop();}
e52e5e378330fd7f87ee30351bbfcec47b751fee12ece2ef0cfdd77a08c906e1
process
public Status process() throws EventDeliveryException
{    Status status = null;    Iterator<Sink> sinkIterator = selector.createSinkIterator();    while (sinkIterator.hasNext()) {        Sink sink = sinkIterator.next();        try {            status = sink.process();            break;        } catch (Exception ex) {            selector.informSinkFailed(sink);            LOGGER.warn("Sink failed to consume event. " + "Attempting next sink if available.", ex);        }    }    if (status == null) {        throw new EventDeliveryException("All configured sinks have failed");    }    return status;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    super.configure(context);    if (maxTimeOut != 0) {        selector.setMaxTimeOut(maxTimeOut);    }}
dea5ea7b472761f6d87672c86d98f9e92684516fee22a20090f9681327cd5b74
createSinkIterator
public Iterator<Sink> createSinkIterator()
{    return selector.createIterator();}
f695d7ad6b14573ebac5862366b06ace6d813150f5ef5408700977ad05b2fedb
setSinks
public void setSinks(List<Sink> sinks)
{    selector.setObjects(sinks);}
497dece7d60715f461b0442340f1acd3c1030611700f9ca57462b4f292dbc014
informSinkFailed
public void informSinkFailed(Sink failedSink)
{    selector.informFailure(failedSink);}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    super.configure(context);    if (maxTimeOut != 0) {        selector.setMaxTimeOut(maxTimeOut);    }}
f695d7ad6b14573ebac5862366b06ace6d813150f5ef5408700977ad05b2fedb
setSinks
public void setSinks(List<Sink> sinks)
{    selector.setObjects(sinks);}
dea5ea7b472761f6d87672c86d98f9e92684516fee22a20090f9681327cd5b74
createSinkIterator
public Iterator<Sink> createSinkIterator()
{    return selector.createIterator();}
497dece7d60715f461b0442340f1acd3c1030611700f9ca57462b4f292dbc014
informSinkFailed
public void informSinkFailed(Sink failedSink)
{    selector.informFailure(failedSink);}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    String strMaxBytes = context.getString(MAX_BYTES_DUMP_KEY);    if (!Strings.isNullOrEmpty(strMaxBytes)) {        try {            maxBytesToLog = Integer.parseInt(strMaxBytes);        } catch (NumberFormatException e) {            logger.warn(String.format("Unable to convert %s to integer, using default value(%d) for maxByteToDump", strMaxBytes, DEFAULT_MAX_BYTE_DUMP));            maxBytesToLog = DEFAULT_MAX_BYTE_DUMP;        }    }}
e52e5e378330fd7f87ee30351bbfcec47b751fee12ece2ef0cfdd77a08c906e1
process
public Status process() throws EventDeliveryException
{    Status result = Status.READY;    Channel channel = getChannel();    Transaction transaction = channel.getTransaction();    Event event = null;    try {        transaction.begin();        event = channel.take();        if (event != null) {            if (logger.isInfoEnabled()) {                logger.info("Event: " + EventHelper.dumpEvent(event, maxBytesToLog));            }        } else {                        result = Status.BACKOFF;        }        transaction.commit();    } catch (Exception ex) {        transaction.rollback();        throw new EventDeliveryException("Failed to log event: " + event, ex);    } finally {        transaction.close();    }    return result;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    batchSize = context.getInteger("batchSize", DFLT_BATCH_SIZE);    logger.debug(this.getName() + " " + "batch size set to " + String.valueOf(batchSize));    Preconditions.checkArgument(batchSize > 0, "Batch size must be > 0");    logEveryNEvents = context.getInteger("logEveryNEvents", DFLT_LOG_EVERY_N_EVENTS);    logger.debug(this.getName() + " " + "log event N events set to " + logEveryNEvents);    Preconditions.checkArgument(logEveryNEvents > 0, "logEveryNEvents must be > 0");}
e52e5e378330fd7f87ee30351bbfcec47b751fee12ece2ef0cfdd77a08c906e1
process
public Status process() throws EventDeliveryException
{    Status status = Status.READY;    Channel channel = getChannel();    Transaction transaction = channel.getTransaction();    Event event = null;    long eventCounter = counterGroup.get("events.success");    try {        transaction.begin();        int i = 0;        for (i = 0; i < batchSize; i++) {            event = channel.take();            if (++eventCounter % logEveryNEvents == 0) {                logger.info("Null sink {} successful processed {} events.", getName(), eventCounter);            }            if (event == null) {                status = Status.BACKOFF;                break;            }        }        transaction.commit();        counterGroup.addAndGet("events.success", (long) Math.min(batchSize, i));        counterGroup.incrementAndGet("transaction.success");    } catch (Exception ex) {        transaction.rollback();        counterGroup.incrementAndGet("transaction.failed");        logger.error("Failed to deliver event. Exception follows.", ex);        throw new EventDeliveryException("Failed to deliver event: " + event, ex);    } finally {        transaction.close();    }    return status;}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    logger.info("Starting {}...", this);    counterGroup.setName(this.getName());    super.start();    logger.info("Null sink {} started.", getName());}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    logger.info("Null sink {} stopping...", getName());    super.stop();    logger.info("Null sink {} stopped. Event metrics: {}", getName(), counterGroup);}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return "NullSink " + getName() + " { batchSize: " + batchSize + " }";}
dcc511f35190533c2d6fcc6073d66b12e111f5004c64ff08ccc3609a06ab844d
getBatchSize
public long getBatchSize()
{    return batchSize;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    String pathManagerType = context.getString("sink.pathManager", "DEFAULT");    String directory = context.getString("sink.directory");    String rollInterval = context.getString("sink.rollInterval");    serializerType = context.getString("sink.serializer", "TEXT");    serializerContext = new Context(context.getSubProperties("sink." + EventSerializer.CTX_PREFIX));    Context pathManagerContext = new Context(context.getSubProperties("sink." + PathManager.CTX_PREFIX));    pathController = PathManagerFactory.getInstance(pathManagerType, pathManagerContext);    Preconditions.checkArgument(directory != null, "Directory may not be null");    Preconditions.checkNotNull(serializerType, "Serializer type is undefined");    if (rollInterval == null) {        this.rollInterval = defaultRollInterval;    } else {        this.rollInterval = Long.parseLong(rollInterval);    }    batchSize = context.getInteger("sink.batchSize", defaultBatchSize);    this.directory = new File(directory);    if (sinkCounter == null) {        sinkCounter = new SinkCounter(getName());    }}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    logger.info("Starting {}...", this);    sinkCounter.start();    super.start();    pathController.setBaseDirectory(directory);    if (rollInterval > 0) {        rollService = Executors.newScheduledThreadPool(1, new ThreadFactoryBuilder().setNameFormat("rollingFileSink-roller-" + Thread.currentThread().getId() + "-%d").build());        /*       * Every N seconds, mark that it's time to rotate. We purposefully do NOT       * touch anything other than the indicator flag to avoid error handling       * issues (e.g. IO exceptions occuring in two different threads.       * Resist the urge to actually perform rotation in a separate thread!       */        rollService.scheduleAtFixedRate(new Runnable() {            @Override            public void run() {                logger.debug("Marking time to rotate file {}", pathController.getCurrentFile());                shouldRotate = true;            }        }, rollInterval, rollInterval, TimeUnit.SECONDS);    } else {        logger.info("RollInterval is not valid, file rolling will not happen.");    }    logger.info("RollingFileSink {} started.", getName());}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    logger.debug("Marking time to rotate file {}", pathController.getCurrentFile());    shouldRotate = true;}
e52e5e378330fd7f87ee30351bbfcec47b751fee12ece2ef0cfdd77a08c906e1
process
public Status process() throws EventDeliveryException
{    if (shouldRotate) {        logger.debug("Time to rotate {}", pathController.getCurrentFile());        if (outputStream != null) {            logger.debug("Closing file {}", pathController.getCurrentFile());            try {                serializer.flush();                serializer.beforeClose();                outputStream.close();                sinkCounter.incrementConnectionClosedCount();                shouldRotate = false;            } catch (IOException e) {                sinkCounter.incrementConnectionFailedCount();                throw new EventDeliveryException("Unable to rotate file " + pathController.getCurrentFile() + " while delivering event", e);            } finally {                serializer = null;                outputStream = null;            }            pathController.rotate();        }    }    if (outputStream == null) {        File currentFile = pathController.getCurrentFile();        logger.debug("Opening output stream for file {}", currentFile);        try {            outputStream = new BufferedOutputStream(new FileOutputStream(currentFile));            serializer = EventSerializerFactory.getInstance(serializerType, serializerContext, outputStream);            serializer.afterCreate();            sinkCounter.incrementConnectionCreatedCount();        } catch (IOException e) {            sinkCounter.incrementConnectionFailedCount();            throw new EventDeliveryException("Failed to open file " + pathController.getCurrentFile() + " while delivering event", e);        }    }    Channel channel = getChannel();    Transaction transaction = channel.getTransaction();    Event event = null;    Status result = Status.READY;    try {        transaction.begin();        int eventAttemptCounter = 0;        for (int i = 0; i < batchSize; i++) {            event = channel.take();            if (event != null) {                sinkCounter.incrementEventDrainAttemptCount();                eventAttemptCounter++;                serializer.write(event);            /*           * FIXME: Feature: Rotate on size and time by checking bytes written and           * setting shouldRotate = true if we're past a threshold.           */            /*           * FIXME: Feature: Control flush interval based on time or number of           * events. For now, we're super-conservative and flush on each write.           */            } else {                                result = Status.BACKOFF;                break;            }        }        serializer.flush();        outputStream.flush();        transaction.commit();        sinkCounter.addToEventDrainSuccessCount(eventAttemptCounter);    } catch (Exception ex) {        sinkCounter.incrementEventWriteOrChannelFail(ex);        transaction.rollback();        throw new EventDeliveryException("Failed to process transaction", ex);    } finally {        transaction.close();    }    return result;}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    logger.info("RollingFile sink {} stopping...", getName());    sinkCounter.stop();    super.stop();    if (outputStream != null) {        logger.debug("Closing file {}", pathController.getCurrentFile());        try {            serializer.flush();            serializer.beforeClose();            outputStream.close();            sinkCounter.incrementConnectionClosedCount();        } catch (IOException e) {            sinkCounter.incrementConnectionFailedCount();            logger.error("Unable to close output stream. Exception follows.", e);        } finally {            outputStream = null;            serializer = null;        }    }    if (rollInterval > 0) {        rollService.shutdown();        while (!rollService.isTerminated()) {            try {                rollService.awaitTermination(1, TimeUnit.SECONDS);            } catch (InterruptedException e) {                logger.debug("Interrupted while waiting for roll service to stop. " + "Please report this.", e);            }        }    }    logger.info("RollingFile sink {} stopped. Event metrics: {}", getName(), sinkCounter);}
bbde6d53f0c8b431c941f033b75e526c9da022d1f4d3ce08b1a14383991ad106
getDirectory
public File getDirectory()
{    return directory;}
4e94516d009f8c3f3f2e9ae0daaae33fb7c108aa9af779b37077227dcbaff806
setDirectory
public void setDirectory(File directory)
{    this.directory = directory;}
0e7fdfabcc2eb7d6cd21eb7799ae878d314e34ba20e3e1c0455db687858d828c
getRollInterval
public long getRollInterval()
{    return rollInterval;}
c6c1cd86cbd7e1930ffee480e2dccbcd922f4aacbf26ab5a883382bea62c0e81
setRollInterval
public void setRollInterval(long rollInterval)
{    this.rollInterval = rollInterval;}
dcc511f35190533c2d6fcc6073d66b12e111f5004c64ff08ccc3609a06ab844d
getBatchSize
public long getBatchSize()
{    return batchSize;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    conf = new SinkGroupConfiguration("sinkgrp");    try {        conf.configure(context);    } catch (ConfigurationException e) {        throw new FlumeException("Invalid Configuration!", e);    }    configure(conf);}
5824a44f0378e18d9ee390869319cad8cb11c2ffc7c83febf9571dedcf2d3143
getProcessor
public SinkProcessor getProcessor()
{    return processor;}
57746d8a7acafcf5647f649109937334de6090302f29c32ed7da0df311700e35
configure
public void configure(ComponentConfiguration conf)
{    this.conf = (SinkGroupConfiguration) conf;    processor = SinkProcessorFactory.getProcessor(this.conf.getProcessorContext(), sinks);}
ea3c687bde14231a0a7443680c738b7467cec52d93ac6b594cf13472b33c0a01
getProcessor
public static SinkProcessor getProcessor(Context context, List<Sink> sinks)
{    Preconditions.checkNotNull(context);    Preconditions.checkNotNull(sinks);    Preconditions.checkArgument(!sinks.isEmpty());    Map<String, String> params = context.getParameters();    SinkProcessor processor;    String typeStr = params.get(TYPE);    SinkProcessorType type = SinkProcessorType.OTHER;    String processorClassName = typeStr;    try {        type = SinkProcessorType.valueOf(typeStr.toUpperCase(Locale.ENGLISH));    } catch (Exception ex) {        logger.warn("Sink Processor type {} is a custom type", typeStr);    }    if (!type.equals(SinkProcessorType.OTHER)) {        processorClassName = type.getSinkProcessorClassName();    }    logger.debug("Creating instance of sink processor type {}, class {}", typeStr, processorClassName);    Class<? extends SinkProcessor> processorClass = null;    try {        processorClass = (Class<? extends SinkProcessor>) Class.forName(processorClassName);    } catch (Exception ex) {        throw new FlumeException("Unable to load sink processor type: " + typeStr + ", class: " + type.getSinkProcessorClassName(), ex);    }    try {        processor = processorClass.newInstance();    } catch (Exception e) {        throw new FlumeException("Unable to create sink processor, type: " + typeStr + ", class: " + processorClassName, e);    }    processor.setSinks(sinks);    Configurables.configure(processor, context);    return processor;}
e631aaa47bef10cad6b0a3a88d263e0f1c314fa3ceae158a5e34a85f04cf984c
getProcessor
public static SinkProcessor getProcessor(ComponentConfiguration conf, List<Sink> sinks)
{    String typeStr = conf.getType();    SinkProcessor processor;    SinkProcessorType type = SinkProcessorType.DEFAULT;    try {        type = SinkProcessorType.valueOf(typeStr.toUpperCase(Locale.ENGLISH));    } catch (Exception ex) {        logger.warn("Sink type {} does not exist, using default", typeStr);    }    Class<? extends SinkProcessor> processorClass = null;    try {        processorClass = (Class<? extends SinkProcessor>) Class.forName(type.getSinkProcessorClassName());    } catch (Exception ex) {        throw new FlumeException("Unable to load sink processor type: " + typeStr + ", class: " + type.getSinkProcessorClassName(), ex);    }    try {        processor = processorClass.newInstance();    } catch (Exception e) {        throw new FlumeException("Unable to create processor, type: " + typeStr + ", class: " + type.getSinkProcessorClassName(), e);    }    processor.setSinks(sinks);    Configurables.configure(processor, conf);    return processor;}
7cf77a31240dd1bfbea90dee2aefa991063c1ecde51e0ad04a2e42de2a19a99c
initializeRpcClient
protected RpcClient initializeRpcClient(Properties props)
{            props.setProperty(RpcClientConfigurationConstants.CONFIG_CONNECTION_POOL_SIZE, String.valueOf(1));    boolean enableKerberos = Boolean.parseBoolean(props.getProperty(RpcClientConfigurationConstants.KERBEROS_KEY, "false"));    if (enableKerberos) {        return SecureRpcClientFactory.getThriftInstance(props);    } else {        props.setProperty(RpcClientConfigurationConstants.CONFIG_CLIENT_TYPE, RpcClientFactory.ClientType.THRIFT.name());        return RpcClientFactory.getInstance(props);    }}
7fd7cfd47183ef4803ed58d25c698d8408ad2e725b3f1186ed49623777f11d91
getPolicy
public SinkProcessor getPolicy()
{    return policy;}
61b30fb011e83ba60d7d50d3b2b9eeb95a150d17fdfa7f373618b3c50204f3e6
setSink
public void setSink(SinkProcessor policy)
{    this.policy = policy;}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    SinkProcessor policy = getPolicy();    policy.start();    runner = new PollingRunner();    runner.policy = policy;    runner.counterGroup = counterGroup;    runner.shouldStop = new AtomicBoolean();    runnerThread = new Thread(runner);    runnerThread.setName("SinkRunner-PollingRunner-" + policy.getClass().getSimpleName());    runnerThread.start();    lifecycleState = LifecycleState.START;}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    if (runnerThread != null) {        runner.shouldStop.set(true);        runnerThread.interrupt();        while (runnerThread.isAlive()) {            try {                logger.debug("Waiting for runner thread to exit");                runnerThread.join(500);            } catch (InterruptedException e) {                logger.debug("Interrupted while waiting for runner thread to exit. Exception follows.", e);            }        }    }    getPolicy().stop();    lifecycleState = LifecycleState.STOP;}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return "SinkRunner: { policy:" + getPolicy() + " counterGroup:" + counterGroup + " }";}
54497ccb2ff9760f1ec7fc0d0055d4bc60d5981953c5f3d7550c4b31a01e7642
getLifecycleState
public LifecycleState getLifecycleState()
{    return lifecycleState;}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    logger.debug("Polling sink runner starting");    while (!shouldStop.get()) {        try {            if (policy.process().equals(Sink.Status.BACKOFF)) {                counterGroup.incrementAndGet("runner.backoffs");                Thread.sleep(Math.min(counterGroup.incrementAndGet("runner.backoffs.consecutive") * backoffSleepIncrement, maxBackoffSleep));            } else {                counterGroup.set("runner.backoffs.consecutive", 0L);            }        } catch (InterruptedException e) {            logger.debug("Interrupted while processing an event. Exiting.");            counterGroup.incrementAndGet("runner.interruptions");        } catch (Exception e) {            logger.error("Unable to deliver event. Exception follows.", e);            if (e instanceof EventDeliveryException) {                counterGroup.incrementAndGet("runner.deliveryErrors");            } else {                counterGroup.incrementAndGet("runner.errors");            }            try {                Thread.sleep(maxBackoffSleep);            } catch (InterruptedException ex) {                Thread.currentThread().interrupt();            }        }    }    logger.debug("Polling runner exiting. Metrics:{}", counterGroup);}
e52e5e378330fd7f87ee30351bbfcec47b751fee12ece2ef0cfdd77a08c906e1
process
public Status process() throws EventDeliveryException
{    Exception exception = getStartException();    if (exception != null) {        throw new FlumeException("Source had error configuring or starting", exception);    }    if (!isStarted()) {        throw new EventDeliveryException("Source is not started.  It is in '" + getLifecycleState() + "' state");    }    return doProcess();}
a2af24a400c0da4ba99526694f737263b89979f4f1b86b18d58f395203b06daa
configure
public synchronized void configure(Context context)
{    super.configure(context);    backoffSleepIncrement = context.getLong(PollableSourceConstants.BACKOFF_SLEEP_INCREMENT, PollableSourceConstants.DEFAULT_BACKOFF_SLEEP_INCREMENT);    maxBackoffSleep = context.getLong(PollableSourceConstants.MAX_BACKOFF_SLEEP, PollableSourceConstants.DEFAULT_MAX_BACKOFF_SLEEP);}
0c2bf215960a91e6d67dc2ecb6d4080c5643555055eb51cae826ed4203acda99
getBackOffSleepIncrement
public long getBackOffSleepIncrement()
{    return backoffSleepIncrement;}
09defa6fbcbcba505a3608243e14bdec0cc8c0e18b7feec629a8be8d48285381
getMaxBackOffSleepInterval
public long getMaxBackOffSleepInterval()
{    return maxBackoffSleep;}
5b05914888e421f26bff6f39231facdd35759f746a9af780ebac2cf5b2c81932
start
public synchronized void start()
{    Preconditions.checkState(channelProcessor != null, "No channel processor configured");    lifecycleState = LifecycleState.START;}
06e1ddba8663c90da407ac517f29ed70555cfe57b0332c9a96e7c696e0255364
stop
public synchronized void stop()
{    lifecycleState = LifecycleState.STOP;}
74a7441b8111aa9a42fdab2b10930b1d015bfd032254c824144b4dc531728cbf
setChannelProcessor
public synchronized void setChannelProcessor(ChannelProcessor cp)
{    channelProcessor = cp;}
5e3cb287180061d5add74340d60e758feaa2bfc57f8ae6de0d9f53771f1033d1
getChannelProcessor
public synchronized ChannelProcessor getChannelProcessor()
{    return channelProcessor;}
82e342b29ff4fad8c64d554dc21ad55a5f2c8063fce3b580e896b7968d90473a
getLifecycleState
public synchronized LifecycleState getLifecycleState()
{    return lifecycleState;}
831a1aefa333c15f969e26873201d65e004e9eae64fe390a121d56ac6619f888
setName
public synchronized void setName(String name)
{    this.name = name;}
5a8aa5c66e12ab4bee0bd8ab8101da1e45260314118196130f684c97aec2075b
getName
public synchronized String getName()
{    return name;}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return this.getClass().getName() + "{name:" + name + ",state:" + lifecycleState + "}";}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    configureSsl(context);    Configurables.ensureRequiredNonNull(context, PORT_KEY, BIND_KEY);    port = context.getInteger(PORT_KEY);    bindAddress = context.getString(BIND_KEY);    compressionType = context.getString(COMPRESSION_TYPE, "none");    try {        maxThreads = context.getInteger(THREADS, 0);    } catch (NumberFormatException e) {        logger.warn("AVRO source\'s \"threads\" property must specify an integer value.", context.getString(THREADS));    }    enableIpFilter = context.getBoolean(IP_FILTER_KEY, false);    if (enableIpFilter) {        patternRuleConfigDefinition = context.getString(IP_FILTER_RULES_KEY);        if (patternRuleConfigDefinition == null || patternRuleConfigDefinition.trim().isEmpty()) {            throw new FlumeException("ipFilter is configured with true but ipFilterRules is not defined:" + " ");        }        String[] patternRuleDefinitions = patternRuleConfigDefinition.split(",");        rules = new ArrayList<IpFilterRule>(patternRuleDefinitions.length);        for (String patternRuleDefinition : patternRuleDefinitions) {            rules.add(generateRule(patternRuleDefinition));        }    }    if (sourceCounter == null) {        sourceCounter = new SourceCounter(getName());    }}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    logger.info("Starting {}...", this);    try {        Responder responder = new SpecificResponder(AvroSourceProtocol.class, this);        socketChannelFactory = initSocketChannelFactory();        ChannelPipelineFactory pipelineFactory = initChannelPipelineFactory();        server = new NettyServer(responder, new InetSocketAddress(bindAddress, port), socketChannelFactory, pipelineFactory, null);    } catch (org.jboss.netty.channel.ChannelException nce) {        logger.error("Avro source {} startup failed. Cannot initialize Netty server", getName(), nce);        stop();        throw new FlumeException("Failed to set up server socket", nce);    }    connectionCountUpdater = Executors.newSingleThreadScheduledExecutor();    server.start();    sourceCounter.start();    super.start();    final NettyServer srv = (NettyServer) server;    connectionCountUpdater.scheduleWithFixedDelay(() -> sourceCounter.setOpenConnectionCount(Long.valueOf(srv.getNumActiveConnections())), 0, 60, TimeUnit.SECONDS);    logger.info("Avro source {} started.", getName());}
8fba5e5f89dcc77bdf532cc8f08c4e3794f8fb3e97a0674f16d67ebf943603d9
initSocketChannelFactory
private NioServerSocketChannelFactory initSocketChannelFactory()
{    NioServerSocketChannelFactory socketChannelFactory;    if (maxThreads <= 0) {        socketChannelFactory = new NioServerSocketChannelFactory(Executors.newCachedThreadPool(new ThreadFactoryBuilder().setNameFormat("Avro " + NettyTransceiver.class.getSimpleName() + " Boss-%d").build()), Executors.newCachedThreadPool(new ThreadFactoryBuilder().setNameFormat("Avro " + NettyTransceiver.class.getSimpleName() + "  I/O Worker-%d").build()));    } else {        socketChannelFactory = new NioServerSocketChannelFactory(Executors.newCachedThreadPool(new ThreadFactoryBuilder().setNameFormat("Avro " + NettyTransceiver.class.getSimpleName() + " Boss-%d").build()), Executors.newFixedThreadPool(maxThreads, new ThreadFactoryBuilder().setNameFormat("Avro " + NettyTransceiver.class.getSimpleName() + "  I/O Worker-%d").build()));    }    return socketChannelFactory;}
0140d2d0bce87c3a28821be78de24b655b600add2a8799a1fb26cb334883725f
initChannelPipelineFactory
private ChannelPipelineFactory initChannelPipelineFactory()
{    ChannelPipelineFactory pipelineFactory;    boolean enableCompression = compressionType.equalsIgnoreCase("deflate");    if (enableCompression || isSslEnabled() || enableIpFilter) {        pipelineFactory = new AdvancedChannelPipelineFactory(enableCompression, enableIpFilter, patternRuleConfigDefinition, getSslEngineSupplier(false));    } else {        pipelineFactory = Channels::pipeline;    }    return pipelineFactory;}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    logger.info("Avro source {} stopping: {}", getName(), this);    if (server != null) {        server.close();        try {            server.join();            server = null;        } catch (InterruptedException e) {            logger.info("Avro source " + getName() + ": Interrupted while waiting " + "for Avro server to stop. Exiting. Exception follows.", e);            Thread.currentThread().interrupt();        }    }    if (socketChannelFactory != null) {        socketChannelFactory.releaseExternalResources();        socketChannelFactory = null;    }    sourceCounter.stop();    if (connectionCountUpdater != null) {        connectionCountUpdater.shutdownNow();        connectionCountUpdater = null;    }    super.stop();    logger.info("Avro source {} stopped. Metrics: {}", getName(), sourceCounter);}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return "Avro source " + getName() + ": { bindAddress: " + bindAddress + ", port: " + port + " }";}
2e58b3ac498ab3927896f17dd5b1322f2b5601df3bbefc5d05d04de291b821f1
toStringMap
private static Map<String, String> toStringMap(Map<CharSequence, CharSequence> charSeqMap)
{    Map<String, String> stringMap = new HashMap<String, String>();    for (Map.Entry<CharSequence, CharSequence> entry : charSeqMap.entrySet()) {        stringMap.put(entry.getKey().toString(), entry.getValue().toString());    }    return stringMap;}
5cfefa9eb8d596c2038b87543a218d1191b1a401bf72bf728817d641a2a7982a
append
public Status append(AvroFlumeEvent avroEvent)
{    if (logger.isDebugEnabled()) {        if (LogPrivacyUtil.allowLogRawData()) {            logger.debug("Avro source {}: Received avro event: {}", getName(), avroEvent);        } else {            logger.debug("Avro source {}: Received avro event", getName());        }    }    sourceCounter.incrementAppendReceivedCount();    sourceCounter.incrementEventReceivedCount();    Event event = EventBuilder.withBody(avroEvent.getBody().array(), toStringMap(avroEvent.getHeaders()));    try {        getChannelProcessor().processEvent(event);    } catch (ChannelException ex) {        logger.warn("Avro source " + getName() + ": Unable to process event. " + "Exception follows.", ex);        sourceCounter.incrementChannelWriteFail();        return Status.FAILED;    }    sourceCounter.incrementAppendAcceptedCount();    sourceCounter.incrementEventAcceptedCount();    return Status.OK;}
01fc7ee085fd6b74cd16aa539fa2b8f6930f97e3c0ec1b25a3234b4948e165b6
appendBatch
public Status appendBatch(List<AvroFlumeEvent> events)
{    logger.debug("Avro source {}: Received avro event batch of {} events.", getName(), events.size());    sourceCounter.incrementAppendBatchReceivedCount();    sourceCounter.addToEventReceivedCount(events.size());    List<Event> batch = new ArrayList<Event>();    for (AvroFlumeEvent avroEvent : events) {        Event event = EventBuilder.withBody(avroEvent.getBody().array(), toStringMap(avroEvent.getHeaders()));        batch.add(event);    }    try {        getChannelProcessor().processEventBatch(batch);    } catch (Throwable t) {        logger.error("Avro source " + getName() + ": Unable to process event " + "batch. Exception follows.", t);        sourceCounter.incrementChannelWriteFail();        if (t instanceof Error) {            throw (Error) t;        }        return Status.FAILED;    }    sourceCounter.incrementAppendBatchAcceptedCount();    sourceCounter.addToEventAcceptedCount(events.size());    return Status.OK;}
6c38935073146e9b6b1d66c0e800cb8b322881ea20ad3d8398358f2fe6b78605
generateRule
private PatternRule generateRule(String patternRuleDefinition) throws FlumeException
{    patternRuleDefinition = patternRuleDefinition.trim();        int firstColonIndex = patternRuleDefinition.indexOf(":");    if (firstColonIndex == -1) {        throw new FlumeException("Invalid ipFilter patternRule '" + patternRuleDefinition + "' should look like <'allow'  or 'deny'>:<'ip' or " + "'name'>:<pattern>");    } else {        String ruleAccessFlag = patternRuleDefinition.substring(0, firstColonIndex);        int secondColonIndex = patternRuleDefinition.indexOf(":", firstColonIndex + 1);        if ((!ruleAccessFlag.equals("allow") && !ruleAccessFlag.equals("deny")) || secondColonIndex == -1) {            throw new FlumeException("Invalid ipFilter patternRule '" + patternRuleDefinition + "' should look like <'allow'  or 'deny'>:<'ip' or " + "'name'>:<pattern>");        }        String patternTypeFlag = patternRuleDefinition.substring(firstColonIndex + 1, secondColonIndex);        if ((!patternTypeFlag.equals("ip") && !patternTypeFlag.equals("name"))) {            throw new FlumeException("Invalid ipFilter patternRule '" + patternRuleDefinition + "' should look like <'allow'  or 'deny'>:<'ip' or " + "'name'>:<pattern>");        }        boolean isAllow = ruleAccessFlag.equals("allow");        String patternRuleString = (patternTypeFlag.equals("ip") ? "i" : "n") + ":" + patternRuleDefinition.substring(secondColonIndex + 1);        logger.info("Adding ipFilter PatternRule: " + (isAllow ? "Allow" : "deny") + " " + patternRuleString);        return new PatternRule(isAllow, patternRuleString);    }}
cad0ca6670898490d4708d44f6fd87df22865c8cca5776775b5fc8cd9e37c866
getPipeline
public ChannelPipeline getPipeline() throws Exception
{    ChannelPipeline pipeline = Channels.pipeline();    if (enableCompression) {        ZlibEncoder encoder = new ZlibEncoder(6);        pipeline.addFirst("deflater", encoder);        pipeline.addFirst("inflater", new ZlibDecoder());    }    sslEngineSupplier.get().ifPresent(sslEngine -> {        logger.info("SSLEngine protocols enabled: " + Arrays.asList(sslEngine.getEnabledProtocols()));                                pipeline.addFirst("ssl", new SslHandler(sslEngine));    });    if (enableIpFilter) {        logger.info("Setting up ipFilter with the following rule definition: " + patternRuleConfigDefinition);        IpFilterRuleHandler ipFilterHandler = new IpFilterRuleHandler();        ipFilterHandler.addAll(rules);        logger.info("Adding ipFilter with " + ipFilterHandler.size() + " rules");        pipeline.addFirst("ipFilter", ipFilterHandler);    }    return pipeline;}
a2af24a400c0da4ba99526694f737263b89979f4f1b86b18d58f395203b06daa
configure
public synchronized void configure(Context context)
{    if (isStarted()) {        throw new IllegalStateException("Configure called when started");    } else {        try {            exception = null;            setLifecycleState(LifecycleState.IDLE);            doConfigure(context);        } catch (Exception e) {            exception = e;            setLifecycleState(LifecycleState.ERROR);                        Throwables.propagate(e);        }    }}
5b05914888e421f26bff6f39231facdd35759f746a9af780ebac2cf5b2c81932
start
public synchronized void start()
{    if (exception != null) {        logger.error(String.format("Cannot start due to error: name = %s", getName()), exception);    } else {        try {            Preconditions.checkState(channelProcessor != null, "No channel processor configured");            doStart();            setLifecycleState(LifecycleState.START);        } catch (Exception e) {            logger.error(String.format("Unexpected error performing start: name = %s", getName()), e);            exception = e;            setLifecycleState(LifecycleState.ERROR);        }    }}
06e1ddba8663c90da407ac517f29ed70555cfe57b0332c9a96e7c696e0255364
stop
public synchronized void stop()
{    try {        doStop();        setLifecycleState(LifecycleState.STOP);    } catch (Exception e) {        logger.error(String.format("Unexpected error performing stop: name = %s", getName()), e);        setLifecycleState(LifecycleState.ERROR);    }}
74a7441b8111aa9a42fdab2b10930b1d015bfd032254c824144b4dc531728cbf
setChannelProcessor
public synchronized void setChannelProcessor(ChannelProcessor cp)
{    channelProcessor = cp;}
5e3cb287180061d5add74340d60e758feaa2bfc57f8ae6de0d9f53771f1033d1
getChannelProcessor
public synchronized ChannelProcessor getChannelProcessor()
{    return channelProcessor;}
831a1aefa333c15f969e26873201d65e004e9eae64fe390a121d56ac6619f888
setName
public synchronized void setName(String name)
{    this.name = name;}
5a8aa5c66e12ab4bee0bd8ab8101da1e45260314118196130f684c97aec2075b
getName
public synchronized String getName()
{    return name;}
82e342b29ff4fad8c64d554dc21ad55a5f2c8063fce3b580e896b7968d90473a
getLifecycleState
public synchronized LifecycleState getLifecycleState()
{    return lifecycleState;}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return this.getClass().getName() + "{name:" + name + ",state:" + lifecycleState + "}";}
fe471bf7532118fea6b6924e67c5d1a500476ea28f4354a8803ea85fd7e1e9cd
isStarted
protected boolean isStarted()
{    return getLifecycleState() == LifecycleState.START;}
e2a4df158977affe5b31bff25b5f5827f4e1d83464c1e7bb154543006c6277d8
getStartException
protected Exception getStartException()
{    return exception;}
32b0dce770c4d0a843bd7f7f042de985e6cd2ef98bbddd89b4ff8762c0403c3b
setLifecycleState
protected synchronized void setLifecycleState(LifecycleState lifecycleState)
{    this.lifecycleState = lifecycleState;}
17d29393758668a1293f61beedc047c1ec37361eae63c8729e56ce2b0a2a6081
create
public Source create(String name, String type) throws FlumeException
{    Preconditions.checkNotNull(name, "name");    Preconditions.checkNotNull(type, "type");    logger.info("Creating instance of source {}, type {}", name, type);    Class<? extends Source> sourceClass = getClass(type);    try {        Source source = sourceClass.newInstance();        source.setName(name);        return source;    } catch (Exception ex) {        throw new FlumeException("Unable to create source: " + name + ", type: " + type + ", class: " + sourceClass.getName(), ex);    }}
1248a116f5ddc9343c3efc43aac00279559a4a1e0f119b6466d583d430638aa3
getClass
public Class<? extends Source> getClass(String type) throws FlumeException
{    String sourceClassName = type;    SourceType srcType = SourceType.OTHER;    try {        srcType = SourceType.valueOf(type.toUpperCase(Locale.ENGLISH));    } catch (IllegalArgumentException ex) {        logger.debug("Source type {} is a custom type", type);    }    if (!srcType.equals(SourceType.OTHER)) {        sourceClassName = srcType.getSourceClassName();    }    try {        return (Class<? extends Source>) Class.forName(sourceClassName);    } catch (Exception ex) {        throw new FlumeException("Unable to load source type: " + type + ", class: " + sourceClassName, ex);    }}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    Source source = getSource();    ChannelProcessor cp = source.getChannelProcessor();    cp.initialize();    source.start();    lifecycleState = LifecycleState.START;}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    Source source = getSource();    source.stop();    ChannelProcessor cp = source.getChannelProcessor();    cp.close();    lifecycleState = LifecycleState.STOP;}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return "EventDrivenSourceRunner: { source:" + getSource() + " }";}
54497ccb2ff9760f1ec7fc0d0055d4bc60d5981953c5f3d7550c4b31a01e7642
getLifecycleState
public LifecycleState getLifecycleState()
{    return lifecycleState;}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    logger.info("Exec source starting with command: {}", command);        sourceCounter.start();    executor = Executors.newSingleThreadExecutor();    runner = new ExecRunnable(shell, command, getChannelProcessor(), sourceCounter, restart, restartThrottle, logStderr, bufferCount, batchTimeout, charset);        runnerFuture = executor.submit(runner);        super.start();    logger.debug("Exec source started");}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    logger.info("Stopping exec source with command: {}", command);    if (runner != null) {        runner.setRestart(false);        runner.kill();    }    if (runnerFuture != null) {        logger.debug("Stopping exec runner");        runnerFuture.cancel(true);        logger.debug("Exec runner stopped");    }    executor.shutdown();    while (!executor.isTerminated()) {        logger.debug("Waiting for exec executor service to stop");        try {            executor.awaitTermination(500, TimeUnit.MILLISECONDS);        } catch (InterruptedException e) {            logger.debug("Interrupted while waiting for exec executor service " + "to stop. Just exiting.");            Thread.currentThread().interrupt();        }    }    sourceCounter.stop();    super.stop();    logger.debug("Exec source with command:{} stopped. Metrics:{}", command, sourceCounter);}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    command = context.getString("command");    Preconditions.checkState(command != null, "The parameter command must be specified");    restartThrottle = context.getLong(ExecSourceConfigurationConstants.CONFIG_RESTART_THROTTLE, ExecSourceConfigurationConstants.DEFAULT_RESTART_THROTTLE);    restart = context.getBoolean(ExecSourceConfigurationConstants.CONFIG_RESTART, ExecSourceConfigurationConstants.DEFAULT_RESTART);    logStderr = context.getBoolean(ExecSourceConfigurationConstants.CONFIG_LOG_STDERR, ExecSourceConfigurationConstants.DEFAULT_LOG_STDERR);    bufferCount = context.getInteger(ExecSourceConfigurationConstants.CONFIG_BATCH_SIZE, ExecSourceConfigurationConstants.DEFAULT_BATCH_SIZE);    batchTimeout = context.getLong(ExecSourceConfigurationConstants.CONFIG_BATCH_TIME_OUT, ExecSourceConfigurationConstants.DEFAULT_BATCH_TIME_OUT);    charset = Charset.forName(context.getString(ExecSourceConfigurationConstants.CHARSET, ExecSourceConfigurationConstants.DEFAULT_CHARSET));    shell = context.getString(ExecSourceConfigurationConstants.CONFIG_SHELL, null);    if (sourceCounter == null) {        sourceCounter = new SourceCounter(getName());    }}
dcc511f35190533c2d6fcc6073d66b12e111f5004c64ff08ccc3609a06ab844d
getBatchSize
public long getBatchSize()
{    return bufferCount;}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    do {        String exitCode = "unknown";        BufferedReader reader = null;        String line = null;        final List<Event> eventList = new ArrayList<Event>();        timedFlushService = Executors.newSingleThreadScheduledExecutor(new ThreadFactoryBuilder().setNameFormat("timedFlushExecService" + Thread.currentThread().getId() + "-%d").build());        try {            if (shell != null) {                String[] commandArgs = formulateShellCommand(shell, command);                process = Runtime.getRuntime().exec(commandArgs);            } else {                String[] commandArgs = command.split("\\s+");                process = new ProcessBuilder(commandArgs).start();            }            reader = new BufferedReader(new InputStreamReader(process.getInputStream(), charset));                        StderrReader stderrReader = new StderrReader(new BufferedReader(new InputStreamReader(process.getErrorStream(), charset)), logStderr);            stderrReader.setName("StderrReader-[" + command + "]");            stderrReader.setDaemon(true);            stderrReader.start();            future = timedFlushService.scheduleWithFixedDelay(new Runnable() {                @Override                public void run() {                    try {                        synchronized (eventList) {                            if (!eventList.isEmpty() && timeout()) {                                flushEventBatch(eventList);                            }                        }                    } catch (Exception e) {                        logger.error("Exception occurred when processing event batch", e);                        if (e instanceof InterruptedException) {                            Thread.currentThread().interrupt();                        }                    }                }            }, batchTimeout, batchTimeout, TimeUnit.MILLISECONDS);            while ((line = reader.readLine()) != null) {                sourceCounter.incrementEventReceivedCount();                synchronized (eventList) {                    eventList.add(EventBuilder.withBody(line.getBytes(charset)));                    if (eventList.size() >= bufferCount || timeout()) {                        flushEventBatch(eventList);                    }                }            }            synchronized (eventList) {                if (!eventList.isEmpty()) {                    flushEventBatch(eventList);                }            }        } catch (Exception e) {            logger.error("Failed while running command: " + command, e);            if (e instanceof InterruptedException) {                Thread.currentThread().interrupt();            }        } finally {            if (reader != null) {                try {                    reader.close();                } catch (IOException ex) {                    logger.error("Failed to close reader for exec source", ex);                }            }            exitCode = String.valueOf(kill());        }        if (restart) {            logger.info("Restarting in {}ms, exit code {}", restartThrottle, exitCode);            try {                Thread.sleep(restartThrottle);            } catch (InterruptedException e) {                Thread.currentThread().interrupt();            }        } else {            logger.info("Command [" + command + "] exited with " + exitCode);        }    } while (restart);}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    try {        synchronized (eventList) {            if (!eventList.isEmpty() && timeout()) {                flushEventBatch(eventList);            }        }    } catch (Exception e) {        logger.error("Exception occurred when processing event batch", e);        if (e instanceof InterruptedException) {            Thread.currentThread().interrupt();        }    }}
4269563f2ffce4f4e66f71a9ab13aa6d478e9565a735dc59ccd78001c967e5c4
flushEventBatch
private void flushEventBatch(List<Event> eventList)
{    channelProcessor.processEventBatch(eventList);    sourceCounter.addToEventAcceptedCount(eventList.size());    eventList.clear();    lastPushToChannel = systemClock.currentTimeMillis();}
99cc5f6be46f7fb675ddcd432b4449160d787eea995654d3a250affa57de56cf
timeout
private boolean timeout()
{    return (systemClock.currentTimeMillis() - lastPushToChannel) >= batchTimeout;}
4f1949bf264c0ddc39a0e7b2852b51ca5e41e3ca19406240b28b0727a3619062
formulateShellCommand
private static String[] formulateShellCommand(String shell, String command)
{    String[] shellArgs = shell.split("\\s+");    String[] result = new String[shellArgs.length + 1];    System.arraycopy(shellArgs, 0, result, 0, shellArgs.length);    result[shellArgs.length] = command;    return result;}
54c1653e181188cb50fa9a10a3ff5e8ee3eb6b2c1a46e531a3ad52c8ecb7800c
kill
public int kill()
{    if (process != null) {        synchronized (process) {            process.destroy();            try {                int exitValue = process.waitFor();                                if (future != null) {                    future.cancel(true);                }                if (timedFlushService != null) {                    timedFlushService.shutdown();                    while (!timedFlushService.isTerminated()) {                        try {                            timedFlushService.awaitTermination(500, TimeUnit.MILLISECONDS);                        } catch (InterruptedException e) {                            logger.debug("Interrupted while waiting for exec executor service " + "to stop. Just exiting.");                            Thread.currentThread().interrupt();                        }                    }                }                return exitValue;            } catch (InterruptedException ex) {                Thread.currentThread().interrupt();            }        }        return Integer.MIN_VALUE;    }    return Integer.MIN_VALUE / 2;}
cb6d80f04edceeade4e85920b2503a7b1ba6ff7273307cc67723f2314700eb01
setRestart
public void setRestart(boolean restart)
{    this.restart = restart;}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    try {        int i = 0;        String line = null;        while ((line = input.readLine()) != null) {            if (logStderr) {                                                                logger.info("StderrLogger[{}] = '{}'", ++i, line);            }        }    } catch (IOException e) {        logger.info("StderrLogger exiting", e);    } finally {        try {            if (input != null) {                input.close();            }        } catch (IOException ex) {            logger.error("Failed to close stderr reader for exec source", ex);        }    }}
6149235d1cca31f74c8a1b0176ec8d5eeed9c336bcd1197b00e3d5d634691bd6
getEvents
public List<Event> getEvents(HttpServletRequest request) throws Exception
{    Map<String, String> headers = new HashMap<String, String>();    InputStream inputStream = request.getInputStream();    Map<String, String[]> parameters = request.getParameterMap();    for (String parameter : parameters.keySet()) {        String value = parameters.get(parameter)[0];        if (LOG.isDebugEnabled() && LogPrivacyUtil.allowLogRawData()) {            LOG.debug("Setting Header [Key, Value] as [{},{}] ", parameter, value);        }        headers.put(parameter, value);    }    for (String header : mandatoryHeaders) {        Preconditions.checkArgument(headers.containsKey(header), "Please specify " + header + " parameter in the request.");    }    ByteArrayOutputStream outputStream = new ByteArrayOutputStream();    try {        IOUtils.copy(inputStream, outputStream);        LOG.debug("Building an Event with stream of size -- {}", outputStream.size());        Event event = EventBuilder.withBody(outputStream.toByteArray(), headers);        event.setHeaders(headers);        List<Event> eventList = new ArrayList<Event>();        eventList.add(event);        return eventList;    } finally {        outputStream.close();        inputStream.close();    }}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    this.commaSeparatedHeaders = context.getString(MANDATORY_PARAMETERS, DEFAULT_MANDATORY_PARAMETERS);    this.mandatoryHeaders = commaSeparatedHeaders.split(PARAMETER_SEPARATOR);}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    configureSsl(context);    sourceContext = context;    try {        port = context.getInteger(HTTPSourceConfigurationConstants.CONFIG_PORT);        host = context.getString(HTTPSourceConfigurationConstants.CONFIG_BIND, HTTPSourceConfigurationConstants.DEFAULT_BIND);        Preconditions.checkState(host != null && !host.isEmpty(), "HTTPSource hostname specified is empty");        Preconditions.checkNotNull(port, "HTTPSource requires a port number to be" + " specified");        String handlerClassName = context.getString(HTTPSourceConfigurationConstants.CONFIG_HANDLER, HTTPSourceConfigurationConstants.DEFAULT_HANDLER).trim();        @SuppressWarnings("unchecked")        Class<? extends HTTPSourceHandler> clazz = (Class<? extends HTTPSourceHandler>) Class.forName(handlerClassName);        handler = clazz.getDeclaredConstructor().newInstance();        Map<String, String> subProps = context.getSubProperties(HTTPSourceConfigurationConstants.CONFIG_HANDLER_PREFIX);        handler.configure(new Context(subProps));    } catch (ClassNotFoundException ex) {        LOG.error("Error while configuring HTTPSource. Exception follows.", ex);        Throwables.propagate(ex);    } catch (ClassCastException ex) {        LOG.error("Deserializer is not an instance of HTTPSourceHandler." + "Deserializer must implement HTTPSourceHandler.");        Throwables.propagate(ex);    } catch (Exception ex) {        LOG.error("Error configuring HTTPSource!", ex);        Throwables.propagate(ex);    }    if (sourceCounter == null) {        sourceCounter = new SourceCounter(getName());    }}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    Preconditions.checkState(srv == null, "Running HTTP Server found in source: " + getName() + " before I started one." + "Will not attempt to start.");    QueuedThreadPool threadPool = new QueuedThreadPool();    if (sourceContext.getSubProperties("QueuedThreadPool.").size() > 0) {        FlumeBeanConfigurator.setConfigurationFields(threadPool, sourceContext);    }    srv = new Server(threadPool);        MBeanContainer mbContainer = new MBeanContainer(ManagementFactory.getPlatformMBeanServer());    srv.addEventListener(mbContainer);    srv.addBean(mbContainer);    HttpConfiguration httpConfiguration = new HttpConfiguration();    httpConfiguration.addCustomizer(new SecureRequestCustomizer());    FlumeBeanConfigurator.setConfigurationFields(httpConfiguration, sourceContext);    ServerConnector connector = getSslContextSupplier().get().map(sslContext -> {        SslContextFactory sslCtxFactory = new SslContextFactory();        sslCtxFactory.setSslContext(sslContext);        sslCtxFactory.setExcludeProtocols(getExcludeProtocols().toArray(new String[] {}));        sslCtxFactory.setIncludeProtocols(getIncludeProtocols().toArray(new String[] {}));        sslCtxFactory.setExcludeCipherSuites(getExcludeCipherSuites().toArray(new String[] {}));        sslCtxFactory.setIncludeCipherSuites(getIncludeCipherSuites().toArray(new String[] {}));        FlumeBeanConfigurator.setConfigurationFields(sslCtxFactory, sourceContext);        httpConfiguration.setSecurePort(port);        httpConfiguration.setSecureScheme("https");        return new ServerConnector(srv, new SslConnectionFactory(sslCtxFactory, HttpVersion.HTTP_1_1.asString()), new HttpConnectionFactory(httpConfiguration));    }).orElse(new ServerConnector(srv, new HttpConnectionFactory(httpConfiguration)));    connector.setPort(port);    connector.setHost(host);    connector.setReuseAddress(true);    FlumeBeanConfigurator.setConfigurationFields(connector, sourceContext);    srv.addConnector(connector);    try {        ServletContextHandler context = new ServletContextHandler(ServletContextHandler.SESSIONS);        context.setContextPath("/");        srv.setHandler(context);        context.addServlet(new ServletHolder(new FlumeHTTPServlet()), "/");        context.setSecurityHandler(HTTPServerConstraintUtil.enforceConstraints());        srv.start();    } catch (Exception ex) {        LOG.error("Error while starting HTTPSource. Exception follows.", ex);        Throwables.propagate(ex);    }    Preconditions.checkArgument(srv.isRunning());    sourceCounter.start();    super.start();}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    try {        srv.stop();        srv.join();        srv = null;    } catch (Exception ex) {        LOG.error("Error while stopping HTTPSource. Exception follows.", ex);    }    sourceCounter.stop();    LOG.info("Http source {} stopped. Metrics: {}", getName(), sourceCounter);}
245e54574fc1a25a103d22d3204bf35be42e36c465aab507af031550ece8f3c1
doPost
public void doPost(HttpServletRequest request, HttpServletResponse response) throws IOException
{        List<Event> events = Collections.emptyList();    try {        events = handler.getEvents(request);    } catch (HTTPBadRequestException ex) {        LOG.warn("Received bad request from client. ", ex);        sourceCounter.incrementEventReadFail();        response.sendError(HttpServletResponse.SC_BAD_REQUEST, "Bad request from client. " + ex.getMessage());        return;    } catch (Exception ex) {        LOG.warn("Deserializer threw unexpected exception. ", ex);        sourceCounter.incrementEventReadFail();        response.sendError(HttpServletResponse.SC_INTERNAL_SERVER_ERROR, "Deserializer threw unexpected exception. " + ex.getMessage());        return;    }    sourceCounter.incrementAppendBatchReceivedCount();    sourceCounter.addToEventReceivedCount(events.size());    try {        getChannelProcessor().processEventBatch(events);    } catch (ChannelException ex) {        LOG.warn("Error appending event to channel. " + "Channel might be full. Consider increasing the channel " + "capacity or make sure the sinks perform faster.", ex);        sourceCounter.incrementChannelWriteFail();        response.sendError(HttpServletResponse.SC_SERVICE_UNAVAILABLE, "Error appending event to channel. Channel might be full." + ex.getMessage());        return;    } catch (Exception ex) {        LOG.warn("Unexpected error appending event to channel. ", ex);        sourceCounter.incrementGenericProcessingFail();        response.sendError(HttpServletResponse.SC_INTERNAL_SERVER_ERROR, "Unexpected error while appending event to channel. " + ex.getMessage());        return;    }    response.setCharacterEncoding(request.getCharacterEncoding());    response.setStatus(HttpServletResponse.SC_OK);    response.flushBuffer();    sourceCounter.incrementAppendBatchAcceptedCount();    sourceCounter.addToEventAcceptedCount(events.size());}
d7e91af38a609bac07b9c0e3d10d41d22242533a648505018c9f288184b79855
doGet
public void doGet(HttpServletRequest request, HttpServletResponse response) throws IOException
{    doPost(request, response);}
82593912efae810f61bf230023ee3ce5908a99a1ab79d6dca85db4f96d270b44
configureSsl
protected void configureSsl(Context context)
{    handleDeprecatedParameter(context, "ssl", "enableSSL");    handleDeprecatedParameter(context, "exclude-protocols", "excludeProtocols");    handleDeprecatedParameter(context, "keystore-password", "keystorePassword");    super.configureSsl(context);}
f96c4dc76ad313fd89612a2bafaa263067e8e6fe7c6c24a2d7b15b5bb4fbad33
handleDeprecatedParameter
private void handleDeprecatedParameter(Context context, String newParam, String oldParam)
{    if (!context.containsKey(newParam) && context.containsKey(oldParam)) {        context.put(newParam, context.getString(oldParam));    }}
6149235d1cca31f74c8a1b0176ec8d5eeed9c336bcd1197b00e3d5d634691bd6
getEvents
public List<Event> getEvents(HttpServletRequest request) throws Exception
{    BufferedReader reader = request.getReader();    String charset = request.getCharacterEncoding();        if (charset == null) {        LOG.debug("Charset is null, default charset of UTF-8 will be used.");        charset = "UTF-8";    } else if (!(charset.equalsIgnoreCase("utf-8") || charset.equalsIgnoreCase("utf-16") || charset.equalsIgnoreCase("utf-32"))) {        LOG.error("Unsupported character set in request {}. " + "JSON handler supports UTF-8, " + "UTF-16 and UTF-32 only.", charset);        throw new UnsupportedCharsetException("JSON handler supports UTF-8, " + "UTF-16 and UTF-32 only.");    }    /*     * Gson throws Exception if the data is not parseable to JSON.     * Need not catch it since the source will catch it and return error.     */    List<Event> eventList = new ArrayList<Event>(0);    try {        eventList = gson.fromJson(reader, listType);    } catch (JsonSyntaxException ex) {        throw new HTTPBadRequestException("Request has invalid JSON Syntax.", ex);    }    for (Event e : eventList) {        ((JSONEvent) e).setCharset(charset);    }    return getSimpleEvents(eventList);}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{}
765cb4858616defbf6722d18283bf69efefad318e871be75d5d084219d1ad3a1
getSimpleEvents
private List<Event> getSimpleEvents(List<Event> events)
{    List<Event> newEvents = new ArrayList<Event>(events.size());    for (Event e : events) {        newEvents.add(EventBuilder.withBody(e.getBody(), e.getHeaders()));    }    return newEvents;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    configureSsl(context);    String portsStr = context.getString(SyslogSourceConfigurationConstants.CONFIG_PORTS);    Preconditions.checkNotNull(portsStr, "Must define config " + "parameter for MultiportSyslogTCPSource: ports");    for (String portStr : portsStr.split("\\s+")) {        Integer port = Integer.parseInt(portStr);        ports.add(port);    }    host = context.getString(SyslogSourceConfigurationConstants.CONFIG_HOST);    numProcessors = context.getInteger(SyslogSourceConfigurationConstants.CONFIG_NUMPROCESSORS);    maxEventSize = context.getInteger(SyslogSourceConfigurationConstants.CONFIG_EVENTSIZE, SyslogUtils.DEFAULT_SIZE);    String defaultCharsetStr = context.getString(SyslogSourceConfigurationConstants.CONFIG_CHARSET, SyslogSourceConfigurationConstants.DEFAULT_CHARSET);    try {        defaultCharset = Charset.forName(defaultCharsetStr);    } catch (Exception ex) {        throw new IllegalArgumentException("Unable to parse charset " + "string (" + defaultCharsetStr + ") from port configuration.", ex);    }    defaultDecoder = new ThreadSafeDecoder(defaultCharset);        portCharsets.clear();    {        Map<String, String> portCharsetCfg = context.getSubProperties(SyslogSourceConfigurationConstants.CONFIG_PORT_CHARSET_PREFIX);        for (Map.Entry<String, String> entry : portCharsetCfg.entrySet()) {            String portStr = entry.getKey();            String charsetStr = entry.getValue();            Integer port = Integer.parseInt(portStr);            Preconditions.checkNotNull(port, "Invalid port number in config");            try {                Charset charset = Charset.forName(charsetStr);                portCharsets.put(port, new ThreadSafeDecoder(charset));            } catch (Exception ex) {                throw new IllegalArgumentException("Unable to parse charset " + "string (" + charsetStr + ") from port configuration.", ex);            }        }    }    batchSize = context.getInteger(SyslogSourceConfigurationConstants.CONFIG_BATCHSIZE, SyslogSourceConfigurationConstants.DEFAULT_BATCHSIZE);    portHeader = context.getString(SyslogSourceConfigurationConstants.CONFIG_PORT_HEADER);    clientIPHeader = context.getString(SyslogSourceConfigurationConstants.CONFIG_CLIENT_IP_HEADER);    clientHostnameHeader = context.getString(SyslogSourceConfigurationConstants.CONFIG_CLIENT_HOSTNAME_HEADER);    readBufferSize = context.getInteger(SyslogSourceConfigurationConstants.CONFIG_READBUF_SIZE, SyslogSourceConfigurationConstants.DEFAULT_READBUF_SIZE);    keepFields = SyslogUtils.chooseFieldsToKeep(context.getString(SyslogSourceConfigurationConstants.CONFIG_KEEP_FIELDS, SyslogSourceConfigurationConstants.DEFAULT_KEEP_FIELDS));    if (sourceCounter == null) {        sourceCounter = new SourceCounter(getName());    }}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    logger.info("Starting {}...", this);        if (numProcessors != null) {        acceptor = new NioSocketAcceptor(numProcessors);    } else {        acceptor = new NioSocketAcceptor();    }    getSslContextSupplier().get().ifPresent(sslContext -> {        SslFilter filter = new SslFilter(sslContext);        SSLParameters sslParameters = sslContext.getDefaultSSLParameters();        filter.setEnabledProtocols(getFilteredProtocols(sslParameters));        filter.setEnabledCipherSuites(getFilteredCipherSuites(sslParameters));        acceptor.getFilterChain().addFirst("ssl", filter);    });    acceptor.setReuseAddress(true);    acceptor.getSessionConfig().setReadBufferSize(readBufferSize);    acceptor.getSessionConfig().setIdleTime(IdleStatus.BOTH_IDLE, 10);    acceptor.setHandler(new MultiportSyslogHandler(maxEventSize, batchSize, getChannelProcessor(), sourceCounter, portHeader, clientIPHeader, clientHostnameHeader, defaultDecoder, portCharsets, keepFields));    for (int port : ports) {        InetSocketAddress addr;        if (host != null) {            addr = new InetSocketAddress(host, port);        } else {            addr = new InetSocketAddress(port);        }        try {                                    acceptor.bind(addr);        } catch (IOException ex) {            logger.error("Could not bind to address: " + String.valueOf(addr), ex);        }    }    sourceCounter.start();    super.start();    logger.info("{} started.", this);}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    logger.info("Stopping {}...", this);    acceptor.unbind();    acceptor.dispose();    sourceCounter.stop();    super.stop();    logger.info("{} stopped. Metrics: {}", this, sourceCounter);}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return "Multiport Syslog TCP source " + getName();}
dcc511f35190533c2d6fcc6073d66b12e111f5004c64ff08ccc3609a06ab844d
getBatchSize
public long getBatchSize()
{    return batchSize;}
8008b08daa41d0aaf89d398494d716a7c241f24ac04efb303cb040446aa7c053
exceptionCaught
public void exceptionCaught(IoSession session, Throwable cause) throws Exception
{    logger.error("Error in syslog message handler", cause);    sourceCounter.incrementGenericProcessingFail();    if (cause instanceof Error) {        Throwables.propagate(cause);    }}
752e4b3d1e0b89528573517578e116652a3a15e40fa02d13d2ac8aff3d5b602f
sessionCreated
public void sessionCreated(IoSession session)
{    logger.info("Session created: {}", session);                session.setAttribute(SAVED_BUF, IoBuffer.allocate(maxEventSize, false));}
6a88059ed94b59098c9d1ca0efce213a95ad05a3862a9bc5bbb45e288377147b
sessionOpened
public void sessionOpened(IoSession session)
{        logger.debug("Session opened: {}", session);}
98df847013a1783b032337a8186b9bcf36c6d328dc8c35682ed1284e2aa55b5b
sessionClosed
public void sessionClosed(IoSession session)
{    logger.info("Session closed: {}", session);}
7e1bfeceb8a4524076e6b4207f4dbde5d76222329cf6e1e6a0757a92d3f01198
messageReceived
public void messageReceived(IoSession session, Object message)
{    IoBuffer buf = (IoBuffer) message;    IoBuffer savedBuf = (IoBuffer) session.getAttribute(SAVED_BUF);    ParsedBuffer parsedLine = new ParsedBuffer();    List<Event> events = Lists.newArrayList();        CharsetDecoder decoder = defaultDecoder.get();    int port = ((InetSocketAddress) session.getLocalAddress()).getPort();    if (portCharsets.containsKey(port)) {        decoder = portCharsets.get(port).get();    }        while (buf.hasRemaining()) {        events.clear();                for (int num = 0; num < batchSize && buf.hasRemaining(); num++) {            if (lineSplitter.parseLine(buf, savedBuf, parsedLine)) {                Event event = parseEvent(parsedLine, decoder);                if (portHeader != null) {                    event.getHeaders().put(portHeader, String.valueOf(port));                }                if (clientIPHeader != null) {                    event.getHeaders().put(clientIPHeader, SyslogUtils.getIP(session.getRemoteAddress()));                }                if (clientHostnameHeader != null) {                    event.getHeaders().put(clientHostnameHeader, SyslogUtils.getHostname(session.getRemoteAddress()));                }                events.add(event);            } else {                logger.trace("Parsed null event");            }        }                if (events.isEmpty()) {            logger.trace("Empty set!");            return;        }        int numEvents = events.size();        sourceCounter.addToEventReceivedCount(numEvents);                try {            channelProcessor.processEventBatch(events);            sourceCounter.addToEventAcceptedCount(numEvents);        } catch (Throwable t) {            logger.error("Error writing to channel, event dropped", t);            sourceCounter.incrementEventReadOrChannelFail(t);            if (t instanceof Error) {                Throwables.propagate(t);            }        }    }}
9d6a1a72f0d4fc9b1debf8833c2b4feea43f3645dd72bdbe701c943f9779963a
parseEvent
 Event parseEvent(ParsedBuffer parsedBuf, CharsetDecoder decoder)
{    String msg = null;    try {        msg = parsedBuf.buffer.getString(decoder);    } catch (Throwable t) {        logger.info("Error decoding line with charset (" + decoder.charset() + "). Exception follows.", t);        sourceCounter.incrementEventReadFail();        if (t instanceof Error) {            Throwables.propagate(t);        }                byte[] bytes = new byte[parsedBuf.buffer.remaining()];        parsedBuf.buffer.get(bytes);        Event event = EventBuilder.withBody(bytes);        event.getHeaders().put(SyslogUtils.EVENT_STATUS, SyslogUtils.SyslogStatus.INVALID.getSyslogStatus());        return event;    }    if (logger.isTraceEnabled()) {        if (LogPrivacyUtil.allowLogRawData()) {            logger.trace("Seen raw event: {}", msg);        } else {            logger.trace("Seen raw event.");        }    }    Event event;    try {        event = syslogParser.parseMessage(msg, decoder.charset(), keepFields);        if (parsedBuf.incomplete) {            event.getHeaders().put(SyslogUtils.EVENT_STATUS, SyslogUtils.SyslogStatus.INCOMPLETE.getSyslogStatus());        }    } catch (IllegalArgumentException ex) {        event = EventBuilder.withBody(msg, decoder.charset());        event.getHeaders().put(SyslogUtils.EVENT_STATUS, SyslogUtils.SyslogStatus.INVALID.getSyslogStatus());        logger.debug("Error parsing syslog event", ex);        sourceCounter.incrementEventReadFail();    }    return event;}
2671c9ba3f87f1bc11b66e7de505712f9b18d6ed2de211dfd8dac8b6bd3544b6
parseLine
public boolean parseLine(IoBuffer buf, IoBuffer savedBuf, ParsedBuffer parsedBuf)
{        parsedBuf.buffer = null;    parsedBuf.incomplete = false;    byte curByte;    buf.mark();        int msgPos = savedBuf.position();    boolean seenNewline = false;    while (!seenNewline && buf.hasRemaining() && msgPos < maxLineLength) {        curByte = buf.get();                if (curByte == NEWLINE) {            seenNewline = true;        }        msgPos++;    }        if (seenNewline) {        int end = buf.position();        buf.reset();        int start = buf.position();        if (savedBuf.position() > 0) {                        byte[] tmp = new byte[end - start];            buf.get(tmp);            savedBuf.put(tmp);            int len = savedBuf.position() - 1;            savedBuf.flip();            parsedBuf.buffer = savedBuf.getSlice(len);            savedBuf.clear();        } else {            parsedBuf.buffer = buf.getSlice(end - start - 1);                        buf.get();        }        return true;        } else {                if (msgPos == maxLineLength) {            int end = buf.position();            buf.reset();            int start = buf.position();            if (savedBuf.position() > 0) {                                byte[] tmp = new byte[end - start];                buf.get(tmp);                savedBuf.put(tmp);                savedBuf.flip();                parsedBuf.buffer = savedBuf.getSlice(msgPos);                savedBuf.clear();            } else {                                parsedBuf.buffer = buf.getSlice(msgPos);            }            logger.warn("Event size larger than specified event size: {}. " + "Consider increasing the max event size.", maxLineLength);            parsedBuf.incomplete = true;            return true;                } else if (!buf.hasRemaining()) {            int end = buf.position();            buf.reset();            int start = buf.position();            byte[] tmp = new byte[end - start];            buf.get(tmp);            savedBuf.put(tmp);            return false;                } else {            throw new IllegalStateException("unexpected buffer state: " + "msgPos=" + msgPos + ", buf.hasRemaining=" + buf.hasRemaining() + ", savedBuf.hasRemaining=" + savedBuf.hasRemaining() + ", seenNewline=" + seenNewline + ", maxLen=" + maxLineLength);        }    }}
014aa9be05b03659e6a7151affb7545eb1864ac5b507ea9aa2a2b1f2b956ee24
initialValue
protected CharsetDecoder initialValue()
{    return charset.newDecoder();}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    String hostKey = NetcatSourceConfigurationConstants.CONFIG_HOSTNAME;    String portKey = NetcatSourceConfigurationConstants.CONFIG_PORT;    String ackEventKey = NetcatSourceConfigurationConstants.CONFIG_ACKEVENT;    Configurables.ensureRequiredNonNull(context, hostKey, portKey);    hostName = context.getString(hostKey);    port = context.getInteger(portKey);    ackEveryEvent = context.getBoolean(ackEventKey, true);    maxLineLength = context.getInteger(NetcatSourceConfigurationConstants.CONFIG_MAX_LINE_LENGTH, NetcatSourceConfigurationConstants.DEFAULT_MAX_LINE_LENGTH);    sourceEncoding = context.getString(NetcatSourceConfigurationConstants.CONFIG_SOURCE_ENCODING, NetcatSourceConfigurationConstants.DEFAULT_ENCODING);}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    logger.info("Source starting");    counterGroup.incrementAndGet("open.attempts");    try {        SocketAddress bindPoint = new InetSocketAddress(hostName, port);        serverSocket = ServerSocketChannel.open();        serverSocket.socket().setReuseAddress(true);        serverSocket.socket().bind(bindPoint);        logger.info("Created serverSocket:{}", serverSocket);    } catch (IOException e) {        counterGroup.incrementAndGet("open.errors");        logger.error("Unable to bind to socket. Exception follows.", e);        stop();        throw new FlumeException(e);    }    handlerService = Executors.newCachedThreadPool(new ThreadFactoryBuilder().setNameFormat("netcat-handler-%d").build());    AcceptHandler acceptRunnable = new AcceptHandler(maxLineLength);    acceptThreadShouldStop.set(false);    acceptRunnable.counterGroup = counterGroup;    acceptRunnable.handlerService = handlerService;    acceptRunnable.shouldStop = acceptThreadShouldStop;    acceptRunnable.ackEveryEvent = ackEveryEvent;    acceptRunnable.source = this;    acceptRunnable.serverSocket = serverSocket;    acceptRunnable.sourceEncoding = sourceEncoding;    acceptThread = new Thread(acceptRunnable);    acceptThread.start();    logger.debug("Source started");    super.start();}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    logger.info("Source stopping");    acceptThreadShouldStop.set(true);    if (acceptThread != null) {        logger.debug("Stopping accept handler thread");        while (acceptThread.isAlive()) {            try {                logger.debug("Waiting for accept handler to finish");                acceptThread.interrupt();                acceptThread.join(500);            } catch (InterruptedException e) {                logger.debug("Interrupted while waiting for accept handler to finish");                Thread.currentThread().interrupt();            }        }        logger.debug("Stopped accept handler thread");    }    if (serverSocket != null) {        try {            serverSocket.close();        } catch (IOException e) {            logger.error("Unable to close socket. Exception follows.", e);            return;        }    }    if (handlerService != null) {        handlerService.shutdown();        logger.debug("Waiting for handler service to stop");                try {            handlerService.awaitTermination(500, TimeUnit.MILLISECONDS);        } catch (InterruptedException e) {            logger.debug("Interrupted while waiting for netcat handler service to stop");            Thread.currentThread().interrupt();        }        if (!handlerService.isShutdown()) {            handlerService.shutdownNow();        }        logger.debug("Handler service stopped");    }    logger.debug("Source stopped. Event metrics:{}", counterGroup);    super.stop();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    logger.debug("Starting accept handler");    while (!shouldStop.get()) {        try {            SocketChannel socketChannel = serverSocket.accept();            NetcatSocketHandler request = new NetcatSocketHandler(maxLineLength);            request.socketChannel = socketChannel;            request.counterGroup = counterGroup;            request.source = source;            request.ackEveryEvent = ackEveryEvent;            request.sourceEncoding = sourceEncoding;            handlerService.submit(request);            counterGroup.incrementAndGet("accept.succeeded");        } catch (ClosedByInterruptException e) {                } catch (IOException e) {            logger.error("Unable to accept connection. Exception follows.", e);            counterGroup.incrementAndGet("accept.failed");        }    }    logger.debug("Accept handler exiting");}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    logger.debug("Starting connection handler");    Event event = null;    try {        Reader reader = Channels.newReader(socketChannel, sourceEncoding);        Writer writer = Channels.newWriter(socketChannel, sourceEncoding);        CharBuffer buffer = CharBuffer.allocate(maxLineLength);                buffer.flip();        while (true) {                        int charsRead = fill(buffer, reader);            logger.debug("Chars read = {}", charsRead);                        int eventsProcessed = processEvents(buffer, writer);            logger.debug("Events processed = {}", eventsProcessed);            if (charsRead == -1) {                                break;            } else if (charsRead == 0 && eventsProcessed == 0) {                if (buffer.remaining() == buffer.capacity()) {                                                                                                                                            logger.warn("Client sent event exceeding the maximum length");                    counterGroup.incrementAndGet("events.failed");                    writer.write("FAILED: Event exceeds the maximum length (" + buffer.capacity() + " chars, including newline)\n");                    writer.flush();                    break;                }            }        }        socketChannel.close();        counterGroup.incrementAndGet("sessions.completed");    } catch (IOException e) {        counterGroup.incrementAndGet("sessions.broken");        try {            socketChannel.close();        } catch (IOException ex) {            logger.error("Unable to close socket channel. Exception follows.", ex);        }    }    logger.debug("Connection handler exiting");}
7addf1f5e5bb9154e4364585bf0dc5a107b44931f22660aabbb0130240b759fb
processEvents
private int processEvents(CharBuffer buffer, Writer writer) throws IOException
{    int numProcessed = 0;    boolean foundNewLine = true;    while (foundNewLine) {        foundNewLine = false;        int limit = buffer.limit();        for (int pos = buffer.position(); pos < limit; pos++) {            if (buffer.get(pos) == '\n') {                                                buffer.limit(pos);                ByteBuffer bytes = Charsets.UTF_8.encode(buffer);                                buffer.limit(limit);                                byte[] body = new byte[bytes.remaining()];                bytes.get(body);                Event event = EventBuilder.withBody(body);                                ChannelException ex = null;                try {                    source.getChannelProcessor().processEvent(event);                } catch (ChannelException chEx) {                    ex = chEx;                }                if (ex == null) {                    counterGroup.incrementAndGet("events.processed");                    numProcessed++;                    if (true == ackEveryEvent) {                        writer.write("OK\n");                    }                } else {                    counterGroup.incrementAndGet("events.failed");                    logger.warn("Error processing event. Exception follows.", ex);                    writer.write("FAILED: " + ex.getMessage() + "\n");                }                writer.flush();                                                buffer.position(pos + 1);                foundNewLine = true;                break;            }        }    }    return numProcessed;}
7f26ec51b0796065b91646594d12f4c7e8803e23c69d8b55d7fcc01f33d5d47f
fill
private int fill(CharBuffer buffer, Reader reader) throws IOException
{        buffer.compact();        int charsRead = reader.read(buffer);    counterGroup.addAndGet("characters.received", Long.valueOf(charsRead));        buffer.flip();    return charsRead;}
8010ae9f11395e54738ada7edeae034430b266daadec631ad41e281af14cc55e
extractEvent
private Event extractEvent(ChannelBuffer in, SocketAddress remoteAddress)
{    Map<String, String> headers = new HashMap<String, String>();    headers.put(remoteHostHeader, remoteAddress.toString());    byte b = 0;    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Event e = null;    boolean doneReading = false;    try {        while (!doneReading && in.readable()) {            b = in.readByte();                        if (b == '\n') {                doneReading = true;            } else {                baos.write(b);            }        }        e = EventBuilder.withBody(baos.toByteArray(), headers);    } finally {        }    return e;}
4f76b67c26f20c1fedc5b82f44e950c0e47781ff2b7cef10a24b2d1df30f5bf3
messageReceived
public void messageReceived(ChannelHandlerContext ctx, MessageEvent mEvent)
{    try {        Event e = extractEvent((ChannelBuffer) mEvent.getMessage(), mEvent.getRemoteAddress());        if (e == null) {            return;        }        getChannelProcessor().processEvent(e);        counterGroup.incrementAndGet("events.success");    } catch (ChannelException ex) {        counterGroup.incrementAndGet("events.dropped");        logger.error("Error writing to channel", ex);    } catch (RuntimeException ex) {        counterGroup.incrementAndGet("events.dropped");        logger.error("Error retrieving event from udp stream, event dropped", ex);    }}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{        ConnectionlessBootstrap serverBootstrap = new ConnectionlessBootstrap(new OioDatagramChannelFactory(Executors.newCachedThreadPool()));    final NetcatHandler handler = new NetcatHandler();    serverBootstrap.setOption("receiveBufferSizePredictorFactory", new AdaptiveReceiveBufferSizePredictorFactory(DEFAULT_MIN_SIZE, DEFAULT_INITIAL_SIZE, maxsize));    serverBootstrap.setPipelineFactory(new ChannelPipelineFactory() {        @Override        public ChannelPipeline getPipeline() {            return Channels.pipeline(handler);        }    });    if (host == null) {        nettyChannel = serverBootstrap.bind(new InetSocketAddress(port));    } else {        nettyChannel = serverBootstrap.bind(new InetSocketAddress(host, port));    }    super.start();}
3654cc9e940fc67e40ac6f0979dae0f3d13c444a2b2571febff4690252784e68
getPipeline
public ChannelPipeline getPipeline()
{    return Channels.pipeline(handler);}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    logger.info("Netcat UDP Source stopping...");    logger.info("Metrics:{}", counterGroup);    if (nettyChannel != null) {        nettyChannel.close();        try {            nettyChannel.getCloseFuture().await(60, TimeUnit.SECONDS);        } catch (InterruptedException e) {            logger.warn("netty server stop interrupted", e);        } finally {            nettyChannel = null;        }    }    super.stop();}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    Configurables.ensureRequiredNonNull(context, CONFIG_PORT);    port = context.getInteger(CONFIG_PORT);    host = context.getString(CONFIG_HOST);    remoteHostHeader = context.getString(REMOTE_ADDRESS_HEADER);}
00d6bcbeeb78b50d59aae19bfcb4380bdf1a1c10681d7668effe7c1eec50faa9
getSourcePort
public int getSourcePort()
{    SocketAddress localAddress = nettyChannel.getLocalAddress();    if (localAddress instanceof InetSocketAddress) {        InetSocketAddress addr = (InetSocketAddress) localAddress;        return addr.getPort();    }    return 0;}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    PollableSource source = (PollableSource) getSource();    ChannelProcessor cp = source.getChannelProcessor();    cp.initialize();    source.start();    runner = new PollingRunner();    runner.source = source;    runner.counterGroup = counterGroup;    runner.shouldStop = shouldStop;    runnerThread = new Thread(runner);    runnerThread.setName(getClass().getSimpleName() + "-" + source.getClass().getSimpleName() + "-" + source.getName());    runnerThread.start();    lifecycleState = LifecycleState.START;}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    runner.shouldStop.set(true);    try {        runnerThread.interrupt();        runnerThread.join();    } catch (InterruptedException e) {        logger.warn("Interrupted while waiting for polling runner to stop. Please report this.", e);        Thread.currentThread().interrupt();    }    Source source = getSource();    source.stop();    ChannelProcessor cp = source.getChannelProcessor();    cp.close();    lifecycleState = LifecycleState.STOP;}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return "PollableSourceRunner: { source:" + getSource() + " counterGroup:" + counterGroup + " }";}
54497ccb2ff9760f1ec7fc0d0055d4bc60d5981953c5f3d7550c4b31a01e7642
getLifecycleState
public LifecycleState getLifecycleState()
{    return lifecycleState;}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    logger.debug("Polling runner starting. Source:{}", source);    while (!shouldStop.get()) {        counterGroup.incrementAndGet("runner.polls");        try {            if (source.process().equals(PollableSource.Status.BACKOFF)) {                counterGroup.incrementAndGet("runner.backoffs");                Thread.sleep(Math.min(counterGroup.incrementAndGet("runner.backoffs.consecutive") * source.getBackOffSleepIncrement(), source.getMaxBackOffSleepInterval()));            } else {                counterGroup.set("runner.backoffs.consecutive", 0L);            }        } catch (InterruptedException e) {            logger.info("Source runner interrupted. Exiting");            counterGroup.incrementAndGet("runner.interruptions");        } catch (EventDeliveryException e) {            logger.error("Unable to deliver event. Exception follows.", e);            counterGroup.incrementAndGet("runner.deliveryErrors");        } catch (Exception e) {            counterGroup.incrementAndGet("runner.errors");            logger.error("Unhandled exception, logging and sleeping for " + source.getMaxBackOffSleepInterval() + "ms", e);            try {                Thread.sleep(source.getMaxBackOffSleepInterval());            } catch (InterruptedException ex) {                Thread.currentThread().interrupt();            }        }    }    logger.debug("Polling runner exiting. Metrics:{}", counterGroup);}
142257108f477bf2e124e1838bfbce41c0a617c37f4ee7c5e0f8eb9232c79477
doConfigure
protected void doConfigure(Context context) throws FlumeException
{    batchSize = context.getInteger("batchSize", 1);    totalEvents = context.getLong("totalEvents", Long.MAX_VALUE);    Preconditions.checkArgument(batchSize > 0, "batchSize was %s but expected positive", batchSize);    if (sourceCounter == null) {        sourceCounter = new SourceCounter(getName());    }}
a30bb502129b437d7473071d9300950cf74e2295abc5081e9e1dca626bc22835
doProcess
protected Status doProcess() throws EventDeliveryException
{    Status status = Status.READY;    long eventsSentTX = eventsSent;    try {        if (batchSize == 1) {            if (eventsSentTX < totalEvents) {                getChannelProcessor().processEvent(EventBuilder.withBody(String.valueOf(eventsSentTX++).getBytes()));                sourceCounter.incrementEventAcceptedCount();            } else {                status = Status.BACKOFF;            }        } else {            List<Event> batchArrayList = new ArrayList<>(batchSize);            for (int i = 0; i < batchSize; i++) {                if (eventsSentTX < totalEvents) {                    batchArrayList.add(i, EventBuilder.withBody(String.valueOf(eventsSentTX++).getBytes()));                } else {                    status = Status.BACKOFF;                    break;                }            }            if (!batchArrayList.isEmpty()) {                getChannelProcessor().processEventBatch(batchArrayList);                sourceCounter.incrementAppendBatchAcceptedCount();                sourceCounter.addToEventAcceptedCount(batchArrayList.size());            }        }        eventsSent = eventsSentTX;    } catch (ChannelException ex) {        logger.error(getName() + " source could not write to channel.", ex);        sourceCounter.incrementChannelWriteFail();    }    return status;}
9dc3ff24bcdde4c0d9a8a91bf810de54f264a0f1ca17b695fea6381be65d7456
doStart
protected void doStart() throws FlumeException
{    logger.info("Sequence generator source do starting");    sourceCounter.start();    logger.debug("Sequence generator source do started");}
984404ddc9435f386a11b7a4633a4b527dc0cdb6ff0eb2dfeb17ad1c4907be8b
doStop
protected void doStop() throws FlumeException
{    logger.info("Sequence generator source do stopping");    sourceCounter.stop();    logger.info("Sequence generator source do stopped. Metrics:{}", getName(), sourceCounter);}
dcc511f35190533c2d6fcc6073d66b12e111f5004c64ff08ccc3609a06ab844d
getBatchSize
public long getBatchSize()
{    return batchSize;}
1940c120e0c3e8fbe4d605b3271078f7f299479d4d0d72b866037ab6c0386637
create
public static RateLimiter create(double permitsPerSecond)
{    /*     * The default RateLimiter configuration can save the unused permits of up to one second.     * This is to avoid unnecessary stalls in situations like this: A RateLimiter of 1qps,     * and 4 threads, all calling acquire() at these moments:     *     * T0 at 0 seconds     * T1 at 1.05 seconds     * T2 at 2 seconds     * T3 at 3 seconds     *     * Due to the slight delay of T1, T2 would have to sleep till 2.05 seconds,     * and T3 would also have to sleep till 3.05 seconds.     */    return create(SleepingStopwatch.createFromSystemTimer(), permitsPerSecond);}
9b370504c93076a340c15a61ab2272927b52384ac437bb98e61ba105eed2825b
create
 static RateLimiter create(SleepingStopwatch stopwatch, double permitsPerSecond)
{    RateLimiter rateLimiter = new SmoothBursty(stopwatch, 1.0);    rateLimiter.setRate(permitsPerSecond);    return rateLimiter;}
b0b67f081f904410d183d91bdb228d111acbeaba3b99d2f7c78ff1a0fd1cbb52
create
public static RateLimiter create(double permitsPerSecond, long warmupPeriod, TimeUnit unit)
{    checkArgument(warmupPeriod >= 0, "warmupPeriod must not be negative: %s", warmupPeriod);    return create(SleepingStopwatch.createFromSystemTimer(), permitsPerSecond, warmupPeriod, unit);}
54f46e02b101b315b59dbb0465ed1896e757842214c2c3028a056d1c4784be3e
create
 static RateLimiter create(SleepingStopwatch stopwatch, double permitsPerSecond, long warmupPeriod, TimeUnit unit)
{    RateLimiter rateLimiter = new SmoothWarmingUp(stopwatch, warmupPeriod, unit);    rateLimiter.setRate(permitsPerSecond);    return rateLimiter;}
88abd1d223db988fd37a140021d9307cfaff0e00c4a0280e2815ccadfd26abb2
mutex
private Object mutex()
{    Object mutex = mutexDoNotUseDirectly;    if (mutex == null) {        synchronized (this) {            mutex = mutexDoNotUseDirectly;            if (mutex == null) {                mutexDoNotUseDirectly = mutex = new Object();            }        }    }    return mutex;}
dce555f0415708c969e6a4a1fdba0a9aa0ee4ab7778da0a048318f8e5806555a
setRate
public final void setRate(double permitsPerSecond)
{    checkArgument(permitsPerSecond > 0.0 && !Double.isNaN(permitsPerSecond), "rate must be positive");    synchronized (mutex()) {        doSetRate(permitsPerSecond, stopwatch.readMicros());    }}
f667ea67384d8350844d8381d057ce18eac852082c387439c2b9d804654520db
getRate
public final double getRate()
{    synchronized (mutex()) {        return doGetRate();    }}
dbce2456f854d72c45119dbd1bc9ecbd29bddf257ae04102532740ca9ce37660
acquire
public double acquire()
{    return acquire(1);}
f2e55dd9b28bad9022fd3a46b68ebd7900c14f004c91d19210f818c9685e5b5b
acquire
public double acquire(int permits)
{    long microsToWait = reserve(permits);    stopwatch.sleepMicrosUninterruptibly(microsToWait);    return 1.0 * microsToWait / SECONDS.toMicros(1L);}
fa356fb8908e2b76377702b3a154fccff2dee1872f3245d075478114aa111595
reserve
 final long reserve(int permits)
{    checkPermits(permits);    synchronized (mutex()) {        return reserveAndGetWaitLength(permits, stopwatch.readMicros());    }}
10dee9235ef64055db3dae3fb7352feb689beca47d6142a91e408e2b64aea972
tryAcquire
public boolean tryAcquire(long timeout, TimeUnit unit)
{    return tryAcquire(1, timeout, unit);}
f172c38bb3d62daf081fa7c242839a85ae11b1e1c09f83a7274d40c6fcc4f00d
tryAcquire
public boolean tryAcquire(int permits)
{    return tryAcquire(permits, 0, MICROSECONDS);}
c1dcf26512fb3f2f17c3d850741ea7d728254a5c9b9467b5d5829c9157ce22cd
tryAcquire
public boolean tryAcquire()
{    return tryAcquire(1, 0, MICROSECONDS);}
e17268114a4b50294dd0a069267a94406e60d3ba72c161b14472a983717f65f3
tryAcquire
public boolean tryAcquire(int permits, long timeout, TimeUnit unit)
{    long timeoutMicros = max(unit.toMicros(timeout), 0);    checkPermits(permits);    long microsToWait;    synchronized (mutex()) {        long nowMicros = stopwatch.readMicros();        if (!canAcquire(nowMicros, timeoutMicros)) {            return false;        } else {            microsToWait = reserveAndGetWaitLength(permits, nowMicros);        }    }    stopwatch.sleepMicrosUninterruptibly(microsToWait);    return true;}
d0e698f58122e46868f844b94b3f72e74ad70a9fcd719ab9cfd5951b23ffe3e5
canAcquire
private boolean canAcquire(long nowMicros, long timeoutMicros)
{    return queryEarliestAvailable(nowMicros) - timeoutMicros <= nowMicros;}
ac7ce07824f3f240d7044b49b2a497d581f9431ed0799996e789834866997d82
reserveAndGetWaitLength
 final long reserveAndGetWaitLength(int permits, long nowMicros)
{    long momentAvailable = reserveEarliestAvailable(permits, nowMicros);    return max(momentAvailable - nowMicros, 0);}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return String.format("RateLimiter[stableRate=%3.1fqps]", getRate());}
0de3bb3e88161cd23166077f27e859ffbb7fc3bcecd1b6c82a056dc4474c8b99
createFromSystemTimer
 static final SleepingStopwatch createFromSystemTimer()
{    return new SleepingStopwatch() {        final Stopwatch stopwatch = Stopwatch.createStarted();        @Override        long readMicros() {            return stopwatch.elapsed(MICROSECONDS);        }        @Override        void sleepMicrosUninterruptibly(long micros) {            if (micros > 0) {                Uninterruptibles.sleepUninterruptibly(micros, MICROSECONDS);            }        }    };}
c78d4b2452713fabb9ddfd87e1cb4c3c3e4d5d310bb8166b0eaf73a5548abffa
readMicros
 long readMicros()
{    return stopwatch.elapsed(MICROSECONDS);}
a0d49470cd449e73bcbe764b6c505fc3ece38a9e57107d0efb2ecff928150a53
sleepMicrosUninterruptibly
 void sleepMicrosUninterruptibly(long micros)
{    if (micros > 0) {        Uninterruptibles.sleepUninterruptibly(micros, MICROSECONDS);    }}
5a121c04ce3631349e4eede5a3cbc1f585ef4bcf5ffb5b8db103430af5fc8dbf
checkPermits
private static int checkPermits(int permits)
{    checkArgument(permits > 0, "Requested permits (%s) must be positive", permits);    return permits;}
b91341943e4a9fee7a944e8a10fdb2b93825dd066c8319fd7f9393e04cc5c7b9
doSetRate
 void doSetRate(double permitsPerSecond, double stableIntervalMicros)
{    double oldMaxPermits = maxPermits;    maxPermits = warmupPeriodMicros / stableIntervalMicros;    halfPermits = maxPermits / 2.0;        double coldIntervalMicros = stableIntervalMicros * 3.0;    slope = (coldIntervalMicros - stableIntervalMicros) / halfPermits;    if (oldMaxPermits == Double.POSITIVE_INFINITY) {                storedPermits = 0.0;    } else {        storedPermits = (oldMaxPermits == 0.0) ?         maxPermits : storedPermits * maxPermits / oldMaxPermits;    }}
018b9aa1dc9fa41d5434ae34d9b4f56139c5a799b9abe633200397fc3da491d3
storedPermitsToWaitTime
 long storedPermitsToWaitTime(double storedPermits, double permitsToTake)
{    double availablePermitsAboveHalf = storedPermits - halfPermits;    long micros = 0;        if (availablePermitsAboveHalf > 0.0) {        double permitsAboveHalfToTake = min(availablePermitsAboveHalf, permitsToTake);        micros = (long) (permitsAboveHalfToTake * (permitsToTime(availablePermitsAboveHalf) + permitsToTime(availablePermitsAboveHalf - permitsAboveHalfToTake)) / 2.0);        permitsToTake -= permitsAboveHalfToTake;    }        micros += (stableIntervalMicros * permitsToTake);    return micros;}
51fba0c0a4b48c8c8da644201b2f1137d5d3e509bb68eaf85419b4cfdcd26af4
permitsToTime
private double permitsToTime(double permits)
{    return stableIntervalMicros + permits * slope;}
b91341943e4a9fee7a944e8a10fdb2b93825dd066c8319fd7f9393e04cc5c7b9
doSetRate
 void doSetRate(double permitsPerSecond, double stableIntervalMicros)
{    double oldMaxPermits = this.maxPermits;    maxPermits = maxBurstSeconds * permitsPerSecond;    if (oldMaxPermits == Double.POSITIVE_INFINITY) {                storedPermits = maxPermits;    } else {        storedPermits = (oldMaxPermits == 0.0) ?         0.0 : storedPermits * maxPermits / oldMaxPermits;    }}
018b9aa1dc9fa41d5434ae34d9b4f56139c5a799b9abe633200397fc3da491d3
storedPermitsToWaitTime
 long storedPermitsToWaitTime(double storedPermits, double permitsToTake)
{    return 0L;}
1e7756058b0246f945a6b422ebf1077a4792d53f7fa28d5a70060c6f682c872c
doSetRate
 final void doSetRate(double permitsPerSecond, long nowMicros)
{    resync(nowMicros);    double stableIntervalMicros = SECONDS.toMicros(1L) / permitsPerSecond;    this.stableIntervalMicros = stableIntervalMicros;    doSetRate(permitsPerSecond, stableIntervalMicros);}
563b0625278c11a7f40db56347b7916cfaa19910ff07f92e351b812abd30d4ef
doGetRate
 final double doGetRate()
{    return SECONDS.toMicros(1L) / stableIntervalMicros;}
29ba4cf76a7d95e101d6a1d7bc94d3b675a0016e1cf7283ae4bccee1a362d468
queryEarliestAvailable
 final long queryEarliestAvailable(long nowMicros)
{    return nextFreeTicketMicros;}
7120bd38bd570786da5dd163df797ddf4f454ca21808f96ba3d5fe1a2961c54c
reserveEarliestAvailable
 final long reserveEarliestAvailable(int requiredPermits, long nowMicros)
{    resync(nowMicros);    long returnValue = nextFreeTicketMicros;    double storedPermitsToSpend = min(requiredPermits, this.storedPermits);    double freshPermits = requiredPermits - storedPermitsToSpend;    long waitMicros = storedPermitsToWaitTime(this.storedPermits, storedPermitsToSpend) + (long) (freshPermits * stableIntervalMicros);    this.nextFreeTicketMicros = nextFreeTicketMicros + waitMicros;    this.storedPermits -= storedPermitsToSpend;    return returnValue;}
36990b247f76856f6681c174c90ee4da72867560a8852b07c49cfd183cba5ba5
resync
private void resync(long nowMicros)
{        if (nowMicros > nextFreeTicketMicros) {        storedPermits = min(maxPermits, storedPermits + (nowMicros - nextFreeTicketMicros) / stableIntervalMicros);        nextFreeTicketMicros = nowMicros;    }}
3af20d783d0ffa9f61b423d223550466e1903c8bc25af59c86cd0da827153ad9
createUnstarted
public static Stopwatch createUnstarted()
{    return new Stopwatch();}
5a55ee9bc4d8aab92750e4df8fe15c573579283cdf5482a3227bed73c8f834cd
createUnstarted
public static Stopwatch createUnstarted(Ticker ticker)
{    return new Stopwatch(ticker);}
8eb8829e5c8b11a1f623e846b30a56388a751372ae8e45e2c2c966c3d9817449
createStarted
public static Stopwatch createStarted()
{    return new Stopwatch().start();}
6b9af4ab6f1c980e1a5743350f995ec1ce3cc7b9558bc4447640e0f592ac153b
createStarted
public static Stopwatch createStarted(Ticker ticker)
{    return new Stopwatch(ticker).start();}
1cd1b470351cc164620985e84951745a66160c6782dec39e46562afc0eaa2246
isRunning
public boolean isRunning()
{    return isRunning;}
48185a4e8bc8ede1b1c5ea965cafcde23d836a816eb1ead3dcc5a9d9b0742ec2
start
public Stopwatch start()
{    checkState(!isRunning, "This stopwatch is already running.");    isRunning = true;    startTick = ticker.read();    return this;}
eff60db5ef6b308339951d4b38dcb18288d0c0046689d26e2fd7aaebf3903b61
stop
public Stopwatch stop()
{    long tick = ticker.read();    checkState(isRunning, "This stopwatch is already stopped.");    isRunning = false;    elapsedNanos += tick - startTick;    return this;}
51ef54f0b8f0f397ff3104aec10791a70d5d4c0edd0cf93e2abf8db66ec40ccd
reset
public Stopwatch reset()
{    elapsedNanos = 0;    isRunning = false;    return this;}
731406b27347ee5c11739cfd0343676e2954986265e36e66fe33909f527ba248
elapsedNanos
private long elapsedNanos()
{    return isRunning ? ticker.read() - startTick + elapsedNanos : elapsedNanos;}
50b52858ad1d5b5b985b4d97c0ae78e2cba0c3eb10ff78a962c1b5f8f3371d50
elapsed
public long elapsed(TimeUnit desiredUnit)
{    return desiredUnit.convert(elapsedNanos(), NANOSECONDS);}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    long nanos = elapsedNanos();    TimeUnit unit = chooseUnit(nanos);    double value = (double) nanos / NANOSECONDS.convert(1, unit);        return String.format("%.4g %s", value, abbreviate(unit));}
d1c4652727ec360a71a7b074c992fa78e595927dc781829773120ebeef20d824
chooseUnit
private static TimeUnit chooseUnit(long nanos)
{    if (DAYS.convert(nanos, NANOSECONDS) > 0) {        return DAYS;    }    if (HOURS.convert(nanos, NANOSECONDS) > 0) {        return HOURS;    }    if (MINUTES.convert(nanos, NANOSECONDS) > 0) {        return MINUTES;    }    if (SECONDS.convert(nanos, NANOSECONDS) > 0) {        return SECONDS;    }    if (MILLISECONDS.convert(nanos, NANOSECONDS) > 0) {        return MILLISECONDS;    }    if (MICROSECONDS.convert(nanos, NANOSECONDS) > 0) {        return MICROSECONDS;    }    return NANOSECONDS;}
28c8e257a330987bdcf5d214f5285749ab8a2960eefbb2304c0f0a9a4a104e7b
abbreviate
private static String abbreviate(TimeUnit unit)
{    switch(unit) {        case NANOSECONDS:            return "ns";        case MICROSECONDS:                        return "\u03bcs";        case MILLISECONDS:            return "ms";        case SECONDS:            return "s";        case MINUTES:            return "min";        case HOURS:            return "h";        case DAYS:            return "d";        default:            throw new AssertionError();    }}
095c460e3b289100cf7da90322e782f282af38a5dd70aa7602c11d8541769129
awaitUninterruptibly
public static void awaitUninterruptibly(CountDownLatch latch)
{    boolean interrupted = false;    try {        while (true) {            try {                latch.await();                return;            } catch (InterruptedException e) {                interrupted = true;            }        }    } finally {        if (interrupted) {            Thread.currentThread().interrupt();        }    }}
6dee1b2d2e4f429a2c09e38a684097343709065b151428d413a63dc07d42c385
awaitUninterruptibly
public static boolean awaitUninterruptibly(CountDownLatch latch, long timeout, TimeUnit unit)
{    boolean interrupted = false;    try {        long remainingNanos = unit.toNanos(timeout);        long end = System.nanoTime() + remainingNanos;        while (true) {            try {                                return latch.await(remainingNanos, NANOSECONDS);            } catch (InterruptedException e) {                interrupted = true;                remainingNanos = end - System.nanoTime();            }        }    } finally {        if (interrupted) {            Thread.currentThread().interrupt();        }    }}
159e1988202c0aeb4be2f53b3c6755e79527d0d030ee94a41a520d6cdcc61fe0
joinUninterruptibly
public static void joinUninterruptibly(Thread toJoin)
{    boolean interrupted = false;    try {        while (true) {            try {                toJoin.join();                return;            } catch (InterruptedException e) {                interrupted = true;            }        }    } finally {        if (interrupted) {            Thread.currentThread().interrupt();        }    }}
e8c86f483777ede4c46135c178bab77e2cf4448c60f3fd4b4c2bed0568a04afd
joinUninterruptibly
public static void joinUninterruptibly(Thread toJoin, long timeout, TimeUnit unit)
{    Preconditions.checkNotNull(toJoin);    boolean interrupted = false;    try {        long remainingNanos = unit.toNanos(timeout);        long end = System.nanoTime() + remainingNanos;        while (true) {            try {                                NANOSECONDS.timedJoin(toJoin, remainingNanos);                return;            } catch (InterruptedException e) {                interrupted = true;                remainingNanos = end - System.nanoTime();            }        }    } finally {        if (interrupted) {            Thread.currentThread().interrupt();        }    }}
14136efe1661ac4c5fda33b95ea7424fda17f3277a307b023c6e47358789c24d
getUninterruptibly
public static V getUninterruptibly(Future<V> future) throws ExecutionException
{    boolean interrupted = false;    try {        while (true) {            try {                return future.get();            } catch (InterruptedException e) {                interrupted = true;            }        }    } finally {        if (interrupted) {            Thread.currentThread().interrupt();        }    }}
f66af7aa0afe89c0970e6073ba24a4eede72c5e668f6b5391c3e1640276fd475
getUninterruptibly
public static V getUninterruptibly(Future<V> future, long timeout, TimeUnit unit) throws ExecutionException, TimeoutException
{    boolean interrupted = false;    try {        long remainingNanos = unit.toNanos(timeout);        long end = System.nanoTime() + remainingNanos;        while (true) {            try {                                return future.get(remainingNanos, NANOSECONDS);            } catch (InterruptedException e) {                interrupted = true;                remainingNanos = end - System.nanoTime();            }        }    } finally {        if (interrupted) {            Thread.currentThread().interrupt();        }    }}
7f2252603986531f1b5fefcb7af3b1c3d8bf92e7606661b88f7a265db0aa9912
takeUninterruptibly
public static E takeUninterruptibly(BlockingQueue<E> queue)
{    boolean interrupted = false;    try {        while (true) {            try {                return queue.take();            } catch (InterruptedException e) {                interrupted = true;            }        }    } finally {        if (interrupted) {            Thread.currentThread().interrupt();        }    }}
cb7d0efd69573da21576878a2c3f8e23ab1a7bf9ed3603b3fd46d40169320042
putUninterruptibly
public static void putUninterruptibly(BlockingQueue<E> queue, E element)
{    boolean interrupted = false;    try {        while (true) {            try {                queue.put(element);                return;            } catch (InterruptedException e) {                interrupted = true;            }        }    } finally {        if (interrupted) {            Thread.currentThread().interrupt();        }    }}
b5260277dbce98b430b7a2f92cd0198ccf3cc61eb106e1015716d557f67839ac
sleepUninterruptibly
public static void sleepUninterruptibly(long sleepFor, TimeUnit unit)
{    boolean interrupted = false;    try {        long remainingNanos = unit.toNanos(sleepFor);        long end = System.nanoTime() + remainingNanos;        while (true) {            try {                                NANOSECONDS.sleep(remainingNanos);                return;            } catch (InterruptedException e) {                interrupted = true;                remainingNanos = end - System.nanoTime();            }        }    } finally {        if (interrupted) {            Thread.currentThread().interrupt();        }    }}
cbad60a6676017e786249e444aaa0a2d370dc3b39a03226dc83e6820296c022b
tryAcquireUninterruptibly
public static boolean tryAcquireUninterruptibly(Semaphore semaphore, long timeout, TimeUnit unit)
{    return tryAcquireUninterruptibly(semaphore, 1, timeout, unit);}
3c2df213a337c9ef7fe4936ce174f5f0d6e3df81e72834ab5b537a24972a2fc7
tryAcquireUninterruptibly
public static boolean tryAcquireUninterruptibly(Semaphore semaphore, int permits, long timeout, TimeUnit unit)
{    boolean interrupted = false;    try {        long remainingNanos = unit.toNanos(timeout);        long end = System.nanoTime() + remainingNanos;        while (true) {            try {                                return semaphore.tryAcquire(permits, remainingNanos, NANOSECONDS);            } catch (InterruptedException e) {                interrupted = true;                remainingNanos = end - System.nanoTime();            }        }    } finally {        if (interrupted) {            Thread.currentThread().interrupt();        }    }}
5b05914888e421f26bff6f39231facdd35759f746a9af780ebac2cf5b2c81932
start
public synchronized void start()
{    logger.info("SpoolDirectorySource source starting with directory: {}", spoolDirectory);    executor = Executors.newSingleThreadScheduledExecutor();    File directory = new File(spoolDirectory);    try {        reader = new ReliableSpoolingFileEventReader.Builder().spoolDirectory(directory).completedSuffix(completedSuffix).includePattern(includePattern).ignorePattern(ignorePattern).trackerDirPath(trackerDirPath).annotateFileName(fileHeader).fileNameHeader(fileHeaderKey).annotateBaseName(basenameHeader).baseNameHeader(basenameHeaderKey).deserializerType(deserializerType).deserializerContext(deserializerContext).deletePolicy(deletePolicy).inputCharset(inputCharset).decodeErrorPolicy(decodeErrorPolicy).consumeOrder(consumeOrder).recursiveDirectorySearch(recursiveDirectorySearch).trackingPolicy(trackingPolicy).sourceCounter(sourceCounter).build();    } catch (IOException ioe) {        throw new FlumeException("Error instantiating spooling event parser", ioe);    }    Runnable runner = new SpoolDirectoryRunnable(reader, sourceCounter);    executor.scheduleWithFixedDelay(runner, 0, pollDelay, TimeUnit.MILLISECONDS);    super.start();    logger.debug("SpoolDirectorySource source started");    sourceCounter.start();}
06e1ddba8663c90da407ac517f29ed70555cfe57b0332c9a96e7c696e0255364
stop
public synchronized void stop()
{    executor.shutdown();    try {        executor.awaitTermination(10L, TimeUnit.SECONDS);    } catch (InterruptedException ex) {        logger.info("Interrupted while awaiting termination", ex);    }    executor.shutdownNow();    super.stop();    sourceCounter.stop();    logger.info("SpoolDir source {} stopped. Metrics: {}", getName(), sourceCounter);}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return "Spool Directory source " + getName() + ": { spoolDir: " + spoolDirectory + " }";}
a2af24a400c0da4ba99526694f737263b89979f4f1b86b18d58f395203b06daa
configure
public synchronized void configure(Context context)
{    spoolDirectory = context.getString(SPOOL_DIRECTORY);    Preconditions.checkState(spoolDirectory != null, "Configuration must specify a spooling directory");    completedSuffix = context.getString(SPOOLED_FILE_SUFFIX, DEFAULT_SPOOLED_FILE_SUFFIX);    deletePolicy = context.getString(DELETE_POLICY, DEFAULT_DELETE_POLICY);    fileHeader = context.getBoolean(FILENAME_HEADER, DEFAULT_FILE_HEADER);    fileHeaderKey = context.getString(FILENAME_HEADER_KEY, DEFAULT_FILENAME_HEADER_KEY);    basenameHeader = context.getBoolean(BASENAME_HEADER, DEFAULT_BASENAME_HEADER);    basenameHeaderKey = context.getString(BASENAME_HEADER_KEY, DEFAULT_BASENAME_HEADER_KEY);    batchSize = context.getInteger(BATCH_SIZE, DEFAULT_BATCH_SIZE);    inputCharset = context.getString(INPUT_CHARSET, DEFAULT_INPUT_CHARSET);    decodeErrorPolicy = DecodeErrorPolicy.valueOf(context.getString(DECODE_ERROR_POLICY, DEFAULT_DECODE_ERROR_POLICY).toUpperCase(Locale.ENGLISH));    includePattern = context.getString(INCLUDE_PAT, DEFAULT_INCLUDE_PAT);    ignorePattern = context.getString(IGNORE_PAT, DEFAULT_IGNORE_PAT);    trackerDirPath = context.getString(TRACKER_DIR, DEFAULT_TRACKER_DIR);    deserializerType = context.getString(DESERIALIZER, DEFAULT_DESERIALIZER);    deserializerContext = new Context(context.getSubProperties(DESERIALIZER + "."));    consumeOrder = ConsumeOrder.valueOf(context.getString(CONSUME_ORDER, DEFAULT_CONSUME_ORDER.toString()).toUpperCase(Locale.ENGLISH));    pollDelay = context.getInteger(POLL_DELAY, DEFAULT_POLL_DELAY);    recursiveDirectorySearch = context.getBoolean(RECURSIVE_DIRECTORY_SEARCH, DEFAULT_RECURSIVE_DIRECTORY_SEARCH);            Integer bufferMaxLineLength = context.getInteger(BUFFER_MAX_LINE_LENGTH);    if (bufferMaxLineLength != null && deserializerType != null && deserializerType.equalsIgnoreCase(DEFAULT_DESERIALIZER)) {        deserializerContext.put(LineDeserializer.MAXLINE_KEY, bufferMaxLineLength.toString());    }    maxBackoff = context.getInteger(MAX_BACKOFF, DEFAULT_MAX_BACKOFF);    if (sourceCounter == null) {        sourceCounter = new SourceCounter(getName());    }    trackingPolicy = context.getString(TRACKING_POLICY, DEFAULT_TRACKING_POLICY);}
76977a5995f7ddd59c78433d25288ad49ec6d0db465536d6c3204468f0aaceac
hasFatalError
protected boolean hasFatalError()
{    return hasFatalError;}
316dd6c3af23297ca94e10bbf149349b864193bb3aa25a279a925df0ff9efb08
setBackOff
protected void setBackOff(boolean backoff)
{    this.backoff = backoff;}
f35166e793020cfa47b618fd998aabe88d55e312504157b91ef07cc99cf1d447
didHitChannelException
protected boolean didHitChannelException()
{    return hitChannelException;}
7282cb7f16267e0bee710b6fe0be6cc42a0cd864bf2b9e82addecb3d448fcdd9
didHitChannelFullException
protected boolean didHitChannelFullException()
{    return hitChannelFullException;}
b05ca35750b98c4eff8ae76009aba8e2bbea887f602a6883787de337ec3f4cef
getSourceCounter
protected SourceCounter getSourceCounter()
{    return sourceCounter;}
80006874ae5360e433412875c029e6df46c10dbff23c50366a5a2c87a8706e57
getRecursiveDirectorySearch
protected boolean getRecursiveDirectorySearch()
{    return recursiveDirectorySearch;}
dcc511f35190533c2d6fcc6073d66b12e111f5004c64ff08ccc3609a06ab844d
getBatchSize
public long getBatchSize()
{    return batchSize;}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    int backoffInterval = 250;    boolean readingEvents = false;    try {        while (!Thread.interrupted()) {            readingEvents = true;            List<Event> events = reader.readEvents(batchSize);            readingEvents = false;            if (events.isEmpty()) {                break;            }            sourceCounter.addToEventReceivedCount(events.size());            sourceCounter.incrementAppendBatchReceivedCount();            try {                getChannelProcessor().processEventBatch(events);                reader.commit();            } catch (ChannelFullException ex) {                logger.warn("The channel is full, and cannot write data now. The " + "source will try again after " + backoffInterval + " milliseconds");                sourceCounter.incrementChannelWriteFail();                hitChannelFullException = true;                backoffInterval = waitAndGetNewBackoffInterval(backoffInterval);                continue;            } catch (ChannelException ex) {                logger.warn("The channel threw an exception, and cannot write data now. The " + "source will try again after " + backoffInterval + " milliseconds");                sourceCounter.incrementChannelWriteFail();                hitChannelException = true;                backoffInterval = waitAndGetNewBackoffInterval(backoffInterval);                continue;            }            backoffInterval = 250;            sourceCounter.addToEventAcceptedCount(events.size());            sourceCounter.incrementAppendBatchAcceptedCount();        }    } catch (Throwable t) {        logger.error("FATAL: " + SpoolDirectorySource.this.toString() + ": " + "Uncaught exception in SpoolDirectorySource thread. " + "Restart or reconfigure Flume to continue processing.", t);        if (readingEvents) {            sourceCounter.incrementEventReadFail();        } else {            sourceCounter.incrementGenericProcessingFail();        }        hasFatalError = true;        Throwables.propagate(t);    }}
e356dac11862394a86fdd75cde6d0519a5845116c2617e3b58bda571fb3904b2
waitAndGetNewBackoffInterval
private int waitAndGetNewBackoffInterval(int backoffInterval) throws InterruptedException
{    if (backoff) {        TimeUnit.MILLISECONDS.sleep(backoffInterval);        backoffInterval = backoffInterval << 1;        backoffInterval = backoffInterval >= maxBackoff ? maxBackoff : backoffInterval;    }    return backoffInterval;}
2d9d51996e62722400e0f2b3fadfe08977ebbc7959939fd30e32592120d08fd8
getKeystore
public String getKeystore()
{    return keystore;}
2f9978b9cfa0c10123ad0df9a83a7cf9de2445d7f8ceb7c405762326a7e044a9
getKeystorePassword
public String getKeystorePassword()
{    return keystorePassword;}
4e964cf89a66912a83b288619809d64c2aa684e320891b89099e6d560eb2db61
getKeystoreType
public String getKeystoreType()
{    return keystoreType;}
82884cc8584b00d8e6a2a8b1b98e06266fd796d03f9cf8bd50136a809e2b42b7
getExcludeProtocols
public Set<String> getExcludeProtocols()
{    return excludeProtocols;}
c4a72f0324428285b295529f42239f9a047b2e260db411c567df293520ceb172
getIncludeProtocols
public Set<String> getIncludeProtocols()
{    return includeProtocols;}
a099ff76ce01f93918cbc70fd88c8ea5cd3284714512a907471dcf305818bab8
getExcludeCipherSuites
public Set<String> getExcludeCipherSuites()
{    return excludeCipherSuites;}
b9d8b5bde9bb9340c8d6ee39b1447a75160bc3222db5fe10f2dfe40c899254b5
getIncludeCipherSuites
public Set<String> getIncludeCipherSuites()
{    return includeCipherSuites;}
c50a196cf078a696ffde0bf0ba0b359244cbc9936ba924295ddd5d971df6ffcc
isSslEnabled
public boolean isSslEnabled()
{    return sslEnabled;}
82593912efae810f61bf230023ee3ce5908a99a1ab79d6dca85db4f96d270b44
configureSsl
protected void configureSsl(Context context)
{    sslEnabled = context.getBoolean(SSL_ENABLED_KEY, SSL_ENABLED_DEFAULT_VALUE);    keystore = context.getString(KEYSTORE_KEY, SSLUtil.getGlobalKeystorePath());    keystorePassword = context.getString(KEYSTORE_PASSWORD_KEY, SSLUtil.getGlobalKeystorePassword());    keystoreType = context.getString(KEYSTORE_TYPE_KEY, SSLUtil.getGlobalKeystoreType(KEYSTORE_TYPE_DEFAULT_VALUE));    parseList(context.getString(EXCLUDE_PROTOCOLS, SSLUtil.getGlobalExcludeProtocols()), excludeProtocols);    parseList(context.getString(INCLUDE_PROTOCOLS, SSLUtil.getGlobalIncludeProtocols()), includeProtocols);    parseList(context.getString(EXCLUDE_CIPHER_SUITES, SSLUtil.getGlobalExcludeCipherSuites()), excludeCipherSuites);    parseList(context.getString(INCLUDE_CIPHER_SUITES, SSLUtil.getGlobalIncludeCipherSuites()), includeCipherSuites);    if (sslEnabled) {        Objects.requireNonNull(keystore, KEYSTORE_KEY + " must be specified when SSL is enabled");        Objects.requireNonNull(keystorePassword, KEYSTORE_PASSWORD_KEY + " must be specified when SSL is enabled");        try {            KeyStore ks = KeyStore.getInstance(keystoreType);            ks.load(new FileInputStream(keystore), keystorePassword.toCharArray());        } catch (Exception ex) {            throw new FlumeException("Source " + getName() + " configured with invalid keystore: " + keystore, ex);        }    }}
acf251b9f3e4e131f34d6dc90ccad7973ccc97f9d01fdec0a88b71bba6c2911a
getSslContext
private Optional<SSLContext> getSslContext()
{    if (sslEnabled) {        try {            KeyStore ks = KeyStore.getInstance(keystoreType);            ks.load(new FileInputStream(keystore), keystorePassword.toCharArray());                        String algorithm = KeyManagerFactory.getDefaultAlgorithm();                        KeyManagerFactory kmf = KeyManagerFactory.getInstance(algorithm);            kmf.init(ks, keystorePassword.toCharArray());            SSLContext serverContext = SSLContext.getInstance("TLS");            serverContext.init(kmf.getKeyManagers(), null, null);            return Optional.of(serverContext);        } catch (Exception e) {            throw new Error("Failed to initialize the server-side SSLContext", e);        }    } else {        return Optional.empty();    }}
ee878bbdc86fa07de9bcdd5262ed099b73e4fe4e5d26cb90028de32901f71475
getSslEngine
private Optional<SSLEngine> getSslEngine(boolean useClientMode)
{    return getSslContext().map(sslContext -> {        SSLEngine sslEngine = sslContext.createSSLEngine();        sslEngine.setUseClientMode(useClientMode);        sslEngine.setEnabledProtocols(getFilteredProtocols(sslEngine.getEnabledProtocols()));        sslEngine.setEnabledCipherSuites(getFilteredCipherSuites(sslEngine.getEnabledCipherSuites()));        return sslEngine;    });}
b216d20e8930a6ea1ee53dcc4cf6b7c91bc5ea73980794988635b550ec0e9eb8
getSslContextSupplier
protected Supplier<Optional<SSLContext>> getSslContextSupplier()
{    return this::getSslContext;}
10d942d3f3786265b231be8980e5f9fe29831c6f9d89606549d51e94a71b4ee2
getSslEngineSupplier
protected Supplier<Optional<SSLEngine>> getSslEngineSupplier(boolean useClientMode)
{    return () -> getSslEngine(useClientMode);}
f181278a4c2ebf07ff442f10c90594127fe70a47792ea474a6edb91a9720e635
getFilteredProtocols
protected String[] getFilteredProtocols(SSLParameters sslParameters)
{    return getFilteredProtocols(sslParameters.getProtocols());}
04ae4b421381c217162ef81a8a3e2785bc2454a23b16544363d4af32706a1f9d
getFilteredProtocols
private String[] getFilteredProtocols(String[] enabledProtocols)
{    return Stream.of(enabledProtocols).filter(o -> includeProtocols.isEmpty() || includeProtocols.contains(o)).filter(o -> !excludeProtocols.contains(o)).toArray(String[]::new);}
c6c8b95b625d95da51995272207330cfc8c18211bc336bc31539d926c33b5cc2
getFilteredCipherSuites
protected String[] getFilteredCipherSuites(SSLParameters sslParameters)
{    return getFilteredCipherSuites(sslParameters.getCipherSuites());}
64bbff2cba7ab802e9a4d86e02e782d011741f12580621b4a9603c247c9ea178
getFilteredCipherSuites
private String[] getFilteredCipherSuites(String[] enabledCipherSuites)
{    return Stream.of(enabledCipherSuites).filter(o -> includeCipherSuites.isEmpty() || includeCipherSuites.contains(o)).filter(o -> !excludeCipherSuites.contains(o)).toArray(String[]::new);}
35833cfe1654e0e2b88d479868200bf24f8538d225db4f61ba2f7c135502235b
parseList
private void parseList(String value, Set<String> set)
{    if (Objects.nonNull(value)) {        set.addAll(Arrays.asList(value.split(" ")));    }}
142257108f477bf2e124e1838bfbce41c0a617c37f4ee7c5e0f8eb9232c79477
doConfigure
protected void doConfigure(Context context) throws FlumeException
{    /* Limit on the total number of events. */    maxTotalEvents = context.getLong("maxTotalEvents", -1L);    /* Limit on the total number of successful events. */    maxSuccessfulEvents = context.getLong("maxSuccessfulEvents", -1L);    /* Set max events in a batch submission */    batchSize = context.getInteger("batchSize", 1);    /* Size of events to be generated. */    int size = context.getInteger("size", 500);    int rateLimit = context.getInteger("maxEventsPerSecond", 0);    if (rateLimit > 0) {        limiter = RateLimiter.create(rateLimit);    } else {        limiter = null;    }    prepEventData(size);}
c65129bc3ad9a58fca395ad591f99e724b5f1887e383ca453a6b5332b1292167
prepEventData
private void prepEventData(int bufferSize)
{    buffer = new byte[bufferSize];    Arrays.fill(buffer, Byte.MAX_VALUE);    if (batchSize > 1) {                eventBatchList = new ArrayList<Event>();        for (int i = 0; i < batchSize; i++) {            eventBatchList.add(EventBuilder.withBody(buffer));        }    } else {                event = EventBuilder.withBody(buffer);    }}
a30bb502129b437d7473071d9300950cf74e2295abc5081e9e1dca626bc22835
doProcess
protected Status doProcess() throws EventDeliveryException
{    long totalEventSent = counterGroup.addAndGet("events.total", lastSent);    if ((maxTotalEvents >= 0 && totalEventSent >= maxTotalEvents) || (maxSuccessfulEvents >= 0 && counterGroup.get("events.successful") >= maxSuccessfulEvents)) {        return Status.BACKOFF;    }    try {        lastSent = batchSize;        if (batchSize == 1) {            if (limiter != null) {                limiter.acquire();            }            getChannelProcessor().processEvent(event);        } else {            long eventsLeft = maxTotalEvents - totalEventSent;            if (maxTotalEvents >= 0 && eventsLeft < batchSize) {                eventBatchListToProcess = eventBatchList.subList(0, (int) eventsLeft);            } else {                eventBatchListToProcess = eventBatchList;            }            lastSent = eventBatchListToProcess.size();            if (limiter != null) {                                limiter.acquire((int) lastSent);            }            getChannelProcessor().processEventBatch(eventBatchListToProcess);        }        counterGroup.addAndGet("events.successful", lastSent);    } catch (ChannelException ex) {        counterGroup.addAndGet("events.failed", lastSent);        return Status.BACKOFF;    }    return Status.READY;}
9dc3ff24bcdde4c0d9a8a91bf810de54f264a0f1ca17b695fea6381be65d7456
doStart
protected void doStart() throws FlumeException
{    logger.info("Stress source doStart finished");}
984404ddc9435f386a11b7a4633a4b527dc0cdb6ff0eb2dfeb17ad1c4907be8b
doStop
protected void doStop() throws FlumeException
{    logger.info("Stress source do stop. Metrics:{}", counterGroup);}
dcc511f35190533c2d6fcc6073d66b12e111f5004c64ff08ccc3609a06ab844d
getBatchSize
public long getBatchSize()
{    return batchSize;}
824b8a1aad35c64b761f2bae97ba2f1adae7e1bd41a79abe5a64aaad82d99844
load
public Long load(String key) throws Exception
{    return timeParser.parseMillis(key);}
a0e62e12488bc1e8d4abacbd4635851ca95d58220f6af6375fa0f82eda79aac7
parseMessage
public Event parseMessage(String msg, Charset charset, Set<String> keepFields)
{    Map<String, String> headers = Maps.newHashMap();    int msgLen = msg.length();    int curPos = 0;    Preconditions.checkArgument(msg.charAt(curPos) == '<', "Bad format: invalid priority: cannot find open bracket '<' (%s)", msg);    int endBracketPos = msg.indexOf('>');    Preconditions.checkArgument(endBracketPos > 0 && endBracketPos <= 6, "Bad format: invalid priority: cannot find end bracket '>' (%s)", msg);    String priority = msg.substring(1, endBracketPos);    int pri = Integer.parseInt(priority);    int facility = pri / 8;    int severity = pri % 8;        headers.put(SyslogUtils.SYSLOG_PRIORITY, priority);        headers.put(SyslogUtils.SYSLOG_FACILITY, String.valueOf(facility));    headers.put(SyslogUtils.SYSLOG_SEVERITY, String.valueOf(severity));    Preconditions.checkArgument(msgLen > endBracketPos + 1, "Bad format: no data except priority (%s)", msg);        curPos = endBracketPos + 1;        String version = null;    if (msgLen > curPos + 2 && "1 ".equals(msg.substring(curPos, curPos + 2))) {        version = msg.substring(curPos, curPos + 1);        headers.put(SyslogUtils.SYSLOG_VERSION, version);        curPos += 2;    }        long ts;    String tsString;    char dateStartChar = msg.charAt(curPos);    try {                if (dateStartChar == '-') {            tsString = Character.toString(dateStartChar);            ts = System.currentTimeMillis();            if (msgLen <= curPos + 2) {                throw new IllegalArgumentException("bad syslog format (missing hostname)");            }                        curPos += 2;                } else if (dateStartChar >= 'A' && dateStartChar <= 'Z') {            if (msgLen <= curPos + RFC3164_LEN) {                throw new IllegalArgumentException("bad timestamp format");            }            tsString = msg.substring(curPos, curPos + RFC3164_LEN);            ts = parseRfc3164Time(tsString);            curPos += RFC3164_LEN + 1;                } else {            int nextSpace = msg.indexOf(' ', curPos);            if (nextSpace == -1) {                throw new IllegalArgumentException("bad timestamp format");            }            tsString = msg.substring(curPos, nextSpace);            ts = parseRfc5424Date(tsString);            curPos = nextSpace + 1;        }    } catch (IllegalArgumentException ex) {        throw new IllegalArgumentException("Unable to parse message: " + msg, ex);    }    headers.put("timestamp", String.valueOf(ts));        int nextSpace = msg.indexOf(' ', curPos);    if (nextSpace == -1) {        throw new IllegalArgumentException("bad syslog format (missing hostname)");    }            String hostname = new String(msg.substring(curPos, nextSpace));    headers.put("host", hostname);        String data = "";    if (msgLen > nextSpace + 1 && !SyslogUtils.keepAllFields(keepFields)) {        curPos = nextSpace + 1;        data = msg.substring(curPos);        data = SyslogUtils.addFieldsToBody(keepFields, data, priority, version, tsString, hostname);    } else {        data = msg;    }    Event event = EventBuilder.withBody(data, charset, headers);    return event;}
d483a2d5feedec2718e6d587789835d3b9b21606007d2439b0ae079e6811b723
parseRfc5424Date
protected long parseRfc5424Date(String msg)
{    Long ts = null;    int curPos = 0;    int msgLen = msg.length();    Preconditions.checkArgument(msgLen > RFC5424_PREFIX_LEN, "Bad format: Not a valid RFC5424 timestamp: %s", msg);    String timestampPrefix = msg.substring(curPos, RFC5424_PREFIX_LEN);    try {        ts = timestampCache.get(timestampPrefix);    } catch (ExecutionException ex) {        throw new IllegalArgumentException("bad timestamp format", ex);    }    curPos += RFC5424_PREFIX_LEN;    Preconditions.checkArgument(ts != null, "Parsing error: timestamp is null");        if (msg.charAt(curPos) == '.') {                boolean foundEnd = false;        int endMillisPos = curPos + 1;        if (msgLen <= endMillisPos) {            throw new IllegalArgumentException("bad timestamp format (no TZ)");        }                while (!foundEnd) {            char curDigit = msg.charAt(endMillisPos);            if (curDigit >= '0' && curDigit <= '9') {                endMillisPos++;            } else {                foundEnd = true;            }        }                final int fractionalPositions = endMillisPos - (curPos + 1);        if (fractionalPositions > 0) {            long milliseconds = Long.parseLong(msg.substring(curPos + 1, endMillisPos));            if (fractionalPositions > 3) {                milliseconds /= Math.pow(10, (fractionalPositions - 3));            } else if (fractionalPositions < 3) {                milliseconds *= Math.pow(10, (3 - fractionalPositions));            }            ts += milliseconds;        } else {            throw new IllegalArgumentException("Bad format: Invalid timestamp (fractional portion): " + msg);        }        curPos = endMillisPos;    }        char tzFirst = msg.charAt(curPos);        if (tzFirst == 'Z') {        } else if (tzFirst == '+' || tzFirst == '-') {        Preconditions.checkArgument(msgLen > curPos + 5, "Bad format: Invalid timezone (%s)", msg);        int polarity;        if (tzFirst == '+') {            polarity = +1;        } else {            polarity = -1;        }        char[] h = new char[5];        for (int i = 0; i < 5; i++) {            h[i] = msg.charAt(curPos + 1 + i);        }        if (h[0] >= '0' && h[0] <= '9' && h[1] >= '0' && h[1] <= '9' && h[2] == ':' && h[3] >= '0' && h[3] <= '9' && h[4] >= '0' && h[4] <= '9') {            int hourOffset = Integer.parseInt(msg.substring(curPos + 1, curPos + 3));            int minOffset = Integer.parseInt(msg.substring(curPos + 4, curPos + 6));            ts -= polarity * ((hourOffset * 60) + minOffset) * 60000;        } else {            throw new IllegalArgumentException("Bad format: Invalid timezone: " + msg);        }    }    return ts;}
b31eb26f94977fdaed4dc88f106e0246a4e55fb5af177621d058706a32753838
parseRfc3164Time
protected long parseRfc3164Time(String ts)
{    DateTime now = DateTime.now();    int year = now.getYear();    ts = TWO_SPACES.matcher(ts).replaceFirst(" ");    DateTime date;    try {        date = rfc3164Format.parseDateTime(ts);    } catch (IllegalArgumentException e) {        logger.debug("rfc3164 date parse failed on (" + ts + "): invalid format", e);        return 0;    }    if (date != null) {        DateTime fixed = date.withYear(year);                if (fixed.isAfter(now) && fixed.minusMonths(1).isAfter(now)) {            fixed = date.minusYears(1);                } else if (fixed.isBefore(now) && fixed.plusMonths(1).isBefore(now)) {            fixed = date.plusYears(1);        }        date = fixed;    }    if (date == null) {        return 0;    }    return date.getMillis();}
86fc9180bfd240fe97244653d07326368ad12bf8e7703b39ba00dcfe1fb94b8c
setEventSize
public void setEventSize(int eventSize)
{    syslogUtils.setEventSize(eventSize);}
a638fe4d29b8a91536d40bcc35d86b0c853477772ffd659cc81ae8cf8232f039
setKeepFields
public void setKeepFields(Set<String> keepFields)
{    syslogUtils.setKeepFields(keepFields);}
5076fc50c0c93cab4d6d0d9549180610124e7fad796b1ba0940d6430295545b8
setFormater
public void setFormater(Map<String, String> prop)
{    syslogUtils.addFormats(prop);}
6ff693a1dffad393b823ac29389a69d10a55489db29ae58772b5946044b41230
setClientIPHeader
public void setClientIPHeader(String clientIPHeader)
{    this.clientIPHeader = clientIPHeader;}
a1ea6b8e31e3caad7d38a2eb074794e35ea90a66c5239d6582a78d384bb4459e
setClientHostnameHeader
public void setClientHostnameHeader(String clientHostnameHeader)
{    this.clientHostnameHeader = clientHostnameHeader;}
4f76b67c26f20c1fedc5b82f44e950c0e47781ff2b7cef10a24b2d1df30f5bf3
messageReceived
public void messageReceived(ChannelHandlerContext ctx, MessageEvent mEvent)
{    ChannelBuffer buff = (ChannelBuffer) mEvent.getMessage();    while (buff.readable()) {        Event e = syslogUtils.extractEvent(buff);        if (e == null) {            logger.debug("Parsed partial event, event will be generated when " + "rest of the event is received.");            continue;        }        if (clientIPHeader != null) {            e.getHeaders().put(clientIPHeader, SyslogUtils.getIP(ctx.getChannel().getRemoteAddress()));        }        if (clientHostnameHeader != null) {            e.getHeaders().put(clientHostnameHeader, SyslogUtils.getHostname(ctx.getChannel().getRemoteAddress()));        }        sourceCounter.incrementEventReceivedCount();        try {            getChannelProcessor().processEvent(e);            sourceCounter.incrementEventAcceptedCount();        } catch (ChannelException ex) {            logger.error("Error writting to channel, event dropped", ex);            sourceCounter.incrementChannelWriteFail();        } catch (RuntimeException ex) {            logger.error("Error parsing event from syslog stream, event dropped", ex);            sourceCounter.incrementEventReadFail();            return;        }    }}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    ChannelFactory factory = new NioServerSocketChannelFactory(Executors.newCachedThreadPool(), Executors.newCachedThreadPool());    ServerBootstrap serverBootstrap = new ServerBootstrap(factory);    serverBootstrap.setPipelineFactory(new PipelineFactory(eventSize, formaterProp, keepFields, clientIPHeader, clientHostnameHeader, getSslEngineSupplier(false)));    logger.info("Syslog TCP Source starting...");    if (host == null) {        nettyChannel = serverBootstrap.bind(new InetSocketAddress(port));    } else {        nettyChannel = serverBootstrap.bind(new InetSocketAddress(host, port));    }    sourceCounter.start();    super.start();}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    logger.info("Syslog TCP Source stopping...");    logger.info("Metrics: {}", sourceCounter);    if (nettyChannel != null) {        nettyChannel.close();        try {            nettyChannel.getCloseFuture().await(60, TimeUnit.SECONDS);        } catch (InterruptedException e) {            logger.warn("netty server stop interrupted", e);        } finally {            nettyChannel = null;        }    }    sourceCounter.stop();    super.stop();}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    configureSsl(context);    Configurables.ensureRequiredNonNull(context, SyslogSourceConfigurationConstants.CONFIG_PORT);    port = context.getInteger(SyslogSourceConfigurationConstants.CONFIG_PORT);    host = context.getString(SyslogSourceConfigurationConstants.CONFIG_HOST);    eventSize = context.getInteger("eventSize", SyslogUtils.DEFAULT_SIZE);    formaterProp = context.getSubProperties(SyslogSourceConfigurationConstants.CONFIG_FORMAT_PREFIX);    keepFields = SyslogUtils.chooseFieldsToKeep(context.getString(SyslogSourceConfigurationConstants.CONFIG_KEEP_FIELDS, SyslogSourceConfigurationConstants.DEFAULT_KEEP_FIELDS));    clientIPHeader = context.getString(SyslogSourceConfigurationConstants.CONFIG_CLIENT_IP_HEADER);    clientHostnameHeader = context.getString(SyslogSourceConfigurationConstants.CONFIG_CLIENT_HOSTNAME_HEADER);    if (sourceCounter == null) {        sourceCounter = new SourceCounter(getName());    }}
c230123124e2180d0c45676bfc6d055566067bc7eb9de592c1a3f1a77e6c2653
getBoundAddress
 InetSocketAddress getBoundAddress()
{    SocketAddress localAddress = nettyChannel.getLocalAddress();    if (!(localAddress instanceof InetSocketAddress)) {        throw new IllegalArgumentException("Not bound to an internet address");    }    return (InetSocketAddress) localAddress;}
b467f890c82e0e6dd60197701062cf947bebf9aa2f5b26307145a60711f5aec7
getSourceCounter
 SourceCounter getSourceCounter()
{    return sourceCounter;}
3654cc9e940fc67e40ac6f0979dae0f3d13c444a2b2571febff4690252784e68
getPipeline
public ChannelPipeline getPipeline()
{    syslogTcpHandler handler = new syslogTcpHandler();    handler.setEventSize(eventSize);    handler.setFormater(formaterProp);    handler.setKeepFields(keepFields);    handler.setClientIPHeader(clientIPHeader);    handler.setClientHostnameHeader(clientHostnameHeader);    ChannelPipeline pipeline = Channels.pipeline(handler);    sslEngineSupplier.get().ifPresent(sslEngine -> {        pipeline.addFirst("ssl", new SslHandler(sslEngine));    });    return pipeline;}
5076fc50c0c93cab4d6d0d9549180610124e7fad796b1ba0940d6430295545b8
setFormater
public void setFormater(Map<String, String> prop)
{    syslogUtils.addFormats(prop);}
a638fe4d29b8a91536d40bcc35d86b0c853477772ffd659cc81ae8cf8232f039
setKeepFields
public void setKeepFields(Set<String> keepFields)
{    syslogUtils.setKeepFields(keepFields);}
6ff693a1dffad393b823ac29389a69d10a55489db29ae58772b5946044b41230
setClientIPHeader
public void setClientIPHeader(String clientIPHeader)
{    this.clientIPHeader = clientIPHeader;}
a1ea6b8e31e3caad7d38a2eb074794e35ea90a66c5239d6582a78d384bb4459e
setClientHostnameHeader
public void setClientHostnameHeader(String clientHostnameHeader)
{    this.clientHostnameHeader = clientHostnameHeader;}
4f76b67c26f20c1fedc5b82f44e950c0e47781ff2b7cef10a24b2d1df30f5bf3
messageReceived
public void messageReceived(ChannelHandlerContext ctx, MessageEvent mEvent)
{    try {        syslogUtils.setEventSize(maxsize);        Event e = syslogUtils.extractEvent((ChannelBuffer) mEvent.getMessage());        if (e == null) {            return;        }        if (clientIPHeader != null) {            e.getHeaders().put(clientIPHeader, SyslogUtils.getIP(mEvent.getRemoteAddress()));        }        if (clientHostnameHeader != null) {            e.getHeaders().put(clientHostnameHeader, SyslogUtils.getHostname(mEvent.getRemoteAddress()));        }        sourceCounter.incrementEventReceivedCount();        getChannelProcessor().processEvent(e);        sourceCounter.incrementEventAcceptedCount();    } catch (ChannelException ex) {        logger.error("Error writting to channel", ex);        sourceCounter.incrementChannelWriteFail();        return;    } catch (RuntimeException ex) {        logger.error("Error parsing event from syslog stream, event dropped", ex);        sourceCounter.incrementEventReadFail();        return;    }}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{        ConnectionlessBootstrap serverBootstrap = new ConnectionlessBootstrap(new OioDatagramChannelFactory(Executors.newCachedThreadPool()));    final syslogHandler handler = new syslogHandler();    handler.setFormater(formaterProp);    handler.setKeepFields(keepFields);    handler.setClientIPHeader(clientIPHeader);    handler.setClientHostnameHeader(clientHostnameHeader);    serverBootstrap.setOption("receiveBufferSizePredictorFactory", new AdaptiveReceiveBufferSizePredictorFactory(DEFAULT_MIN_SIZE, DEFAULT_INITIAL_SIZE, maxsize));    serverBootstrap.setPipelineFactory(new ChannelPipelineFactory() {        @Override        public ChannelPipeline getPipeline() {            return Channels.pipeline(handler);        }    });    if (host == null) {        nettyChannel = serverBootstrap.bind(new InetSocketAddress(port));    } else {        nettyChannel = serverBootstrap.bind(new InetSocketAddress(host, port));    }    sourceCounter.start();    super.start();}
3654cc9e940fc67e40ac6f0979dae0f3d13c444a2b2571febff4690252784e68
getPipeline
public ChannelPipeline getPipeline()
{    return Channels.pipeline(handler);}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    logger.info("Syslog UDP Source stopping...");    logger.info("Metrics: {}", sourceCounter);    if (nettyChannel != null) {        nettyChannel.close();        try {            nettyChannel.getCloseFuture().await(60, TimeUnit.SECONDS);        } catch (InterruptedException e) {            logger.warn("netty server stop interrupted", e);        } finally {            nettyChannel = null;        }    }    sourceCounter.stop();    super.stop();}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    Configurables.ensureRequiredNonNull(context, SyslogSourceConfigurationConstants.CONFIG_PORT);    port = context.getInteger(SyslogSourceConfigurationConstants.CONFIG_PORT);    host = context.getString(SyslogSourceConfigurationConstants.CONFIG_HOST);    formaterProp = context.getSubProperties(SyslogSourceConfigurationConstants.CONFIG_FORMAT_PREFIX);    keepFields = SyslogUtils.chooseFieldsToKeep(context.getString(SyslogSourceConfigurationConstants.CONFIG_KEEP_FIELDS, SyslogSourceConfigurationConstants.DEFAULT_KEEP_FIELDS));    clientIPHeader = context.getString(SyslogSourceConfigurationConstants.CONFIG_CLIENT_IP_HEADER);    clientHostnameHeader = context.getString(SyslogSourceConfigurationConstants.CONFIG_CLIENT_HOSTNAME_HEADER);    if (sourceCounter == null) {        sourceCounter = new SourceCounter(getName());    }}
c230123124e2180d0c45676bfc6d055566067bc7eb9de592c1a3f1a77e6c2653
getBoundAddress
 InetSocketAddress getBoundAddress()
{    SocketAddress localAddress = nettyChannel.getLocalAddress();    if (!(localAddress instanceof InetSocketAddress)) {        throw new IllegalArgumentException("Not bound to an internet address");    }    return (InetSocketAddress) localAddress;}
b467f890c82e0e6dd60197701062cf947bebf9aa2f5b26307145a60711f5aec7
getSourceCounter
 SourceCounter getSourceCounter()
{    return sourceCounter;}
4f18e4ee1015a83f1a8a5ee5f77610b0807f433ba7a0ed5166ef003c33f29ad4
keepAllFields
public static boolean keepAllFields(Set<String> keepFields)
{    if (keepFields == null) {        return false;    }    return keepFields.contains(KEEP_FIELDS_ALL);}
71a6e0f6e071e7cd2feea96697311a34f4c077c87d057030eecc26d4082cd069
chooseFieldsToKeep
public static Set<String> chooseFieldsToKeep(String keepFields)
{    if (keepFields == null) {        return null;    }    keepFields = keepFields.trim().toLowerCase(Locale.ENGLISH);    if (keepFields.equals("false") || keepFields.equals("none")) {        return null;    }    if (keepFields.equals("true") || keepFields.equals("all")) {        Set<String> fieldsToKeep = new HashSet<String>(1);        fieldsToKeep.add(KEEP_FIELDS_ALL);        return fieldsToKeep;    }    Set<String> fieldsToKeep = new HashSet<String>(DEFAULT_FIELDS_TO_KEEP.length);    for (String field : DEFAULT_FIELDS_TO_KEEP) {        if (keepFields.indexOf(field) != -1) {            fieldsToKeep.add(field);        }    }    return fieldsToKeep;}
6621f1417c1385e03687aa8df6e57b105c2c91c0f3f47b318731f42e92fd9f1b
addFieldsToBody
public static String addFieldsToBody(Set<String> keepFields, String body, String priority, String version, String timestamp, String hostname)
{        if (keepFields != null) {        if (keepFields.contains(SyslogSourceConfigurationConstants.CONFIG_KEEP_FIELDS_HOSTNAME)) {            body = hostname + " " + body;        }        if (keepFields.contains(SyslogSourceConfigurationConstants.CONFIG_KEEP_FIELDS_TIMESTAMP)) {            body = timestamp + " " + body;        }        if (keepFields.contains(SyslogSourceConfigurationConstants.CONFIG_KEEP_FIELDS_VERSION)) {            if (version != null && !version.isEmpty()) {                body = version + " " + body;            }        }        if (keepFields.contains(SyslogSourceConfigurationConstants.CONFIG_KEEP_FIELDS_PRIORITY)) {            body = "<" + priority + ">" + body;        }    }    return body;}
17ed6c8e496aa5be58d886295f07f56623422959354614a94a120996e0cd056a
getIP
public static String getIP(SocketAddress socketAddress)
{    try {        InetSocketAddress inetSocketAddress = (InetSocketAddress) socketAddress;        String ip = inetSocketAddress.getAddress().getHostAddress();        if (ip != null) {            return ip;        } else {            throw new NullPointerException("The returned IP is null");        }    } catch (Exception e) {        logger.warn("Unable to retrieve client IP address", e);    }        return "";}
2c58fff35e6f09476f812a2829e6d9171ad1adfab90506dadf19e914401da0ae
getHostname
public static String getHostname(SocketAddress socketAddress)
{    try {        InetSocketAddress inetSocketAddress = (InetSocketAddress) socketAddress;        String hostname = inetSocketAddress.getHostName();        if (hostname != null) {            return hostname;        } else {            throw new NullPointerException("The returned hostname is null");        }    } catch (Exception e) {        logger.warn("Unable to retrieve client hostname", e);    }        return "";}
ef1e12fefd2497c7abd81a034b202941f0094debb6b52ccc84beb875e6f3a04a
addFormats
public void addFormats(Map<String, String> formatProp)
{    if (formatProp.isEmpty() || !formatProp.containsKey(SyslogSourceConfigurationConstants.CONFIG_REGEX)) {        return;    }    SyslogFormatter fmt1 = new SyslogFormatter();    fmt1.regexPattern = Pattern.compile(formatProp.get(SyslogSourceConfigurationConstants.CONFIG_REGEX));    if (formatProp.containsKey(SyslogSourceConfigurationConstants.CONFIG_SEARCH)) {        fmt1.searchPattern.add(formatProp.get(SyslogSourceConfigurationConstants.CONFIG_SEARCH));    }    if (formatProp.containsKey(SyslogSourceConfigurationConstants.CONFIG_REPLACE)) {        fmt1.replacePattern.add(formatProp.get(SyslogSourceConfigurationConstants.CONFIG_REPLACE));    }    if (formatProp.containsKey(SyslogSourceConfigurationConstants.CONFIG_DATEFORMAT)) {        fmt1.dateFormat.add(new SimpleDateFormat(formatProp.get(SyslogSourceConfigurationConstants.CONFIG_DATEFORMAT)));    }    formats.add(0, fmt1);}
9732cfd16147c893790a30199ba99103e3b9aadf995f94ad163187fb722bc5de
initHeaderFormats
private void initHeaderFormats()
{        SyslogFormatter fmt1 = new SyslogFormatter();    fmt1.regexPattern = Pattern.compile(SYSLOG_MSG_RFC5424_0);        fmt1.searchPattern.add("Z");    fmt1.replacePattern.add("+0000");        fmt1.searchPattern.add("([+-])(\\d{2})[:](\\d{2})");    fmt1.replacePattern.add("$1$2$3");        fmt1.searchPattern.add("(T\\d{2}:\\d{2}:\\d{2}\\.\\d{3})(\\d*)");    fmt1.replacePattern.add("$1");    fmt1.dateFormat.add(new SimpleDateFormat(SYSLOG_TIMESTAMP_FORMAT_RFC5424_1, Locale.ENGLISH));    fmt1.dateFormat.add(new SimpleDateFormat(SYSLOG_TIMESTAMP_FORMAT_RFC5424_2, Locale.ENGLISH));    fmt1.dateFormat.add(new SimpleDateFormat(SYSLOG_TIMESTAMP_FORMAT_RFC5424_3, Locale.ENGLISH));    fmt1.dateFormat.add(new SimpleDateFormat(SYSLOG_TIMESTAMP_FORMAT_RFC5424_4, Locale.ENGLISH));    fmt1.addYear = false;        SyslogFormatter fmt2 = new SyslogFormatter();    fmt2.regexPattern = Pattern.compile(SYSLOG_MSG_RFC3164_0);        fmt2.searchPattern.add("  ");    fmt2.replacePattern.add(" ");    fmt2.dateFormat.add(new SimpleDateFormat(SYSLOG_TIMESTAMP_FORMAT_RFC3164_1, Locale.ENGLISH));    fmt2.addYear = true;    formats.add(fmt1);    formats.add(fmt2);}
58ba64a627d3ddd9d09fe548d3afa65964097ee3e13bccb05fea30edfc9fdda8
getSyslogStatus
public String getSyslogStatus()
{    return this.syslogStatus;}
5167cba467eae994b074c216de1c1e305c5f862015fac7d1ee6132ef91bbc31d
buildEvent
 Event buildEvent()
{    try {        byte[] body;        int pri = 0;        int sev = 0;        int facility = 0;        if (!isBadEvent) {            pri = Integer.parseInt(prio.toString());            sev = pri % 8;            facility = pri / 8;            formatHeaders();        }        Map<String, String> headers = new HashMap<String, String>();        headers.put(SYSLOG_FACILITY, String.valueOf(facility));        headers.put(SYSLOG_SEVERITY, String.valueOf(sev));        if ((priority != null) && (priority.length() > 0)) {            headers.put("priority", priority);        }        if ((version != null) && (version.length() > 0)) {            headers.put("version", version);        }        if ((timeStamp != null) && timeStamp.length() > 0) {            headers.put("timestamp", timeStamp);        }        if ((hostName != null) && (hostName.length() > 0)) {            headers.put("host", hostName);        }        if (isBadEvent) {            logger.warn("Event created from Invalid Syslog data.");            headers.put(EVENT_STATUS, SyslogStatus.INVALID.getSyslogStatus());        } else if (isIncompleteEvent) {            logger.warn("Event size larger than specified event size: {}. You should " + "consider increasing your event size.", maxSize);            headers.put(EVENT_STATUS, SyslogStatus.INCOMPLETE.getSyslogStatus());        }        if (!keepAllFields(keepFields)) {            if ((msgBody != null) && (msgBody.length() > 0)) {                body = msgBody.getBytes();            } else {                                body = baos.toByteArray();            }        } else {            body = baos.toByteArray();        }                return EventBuilder.withBody(body, headers);    } finally {        reset();    }}
e982eec9e1c5eb5a8cf7764ff15d4f6265ee4f62bda0893105fab6d581312bff
formatHeaders
private void formatHeaders()
{    String eventStr = baos.toString();    String timeStampString = null;    for (int p = 0; p < formats.size(); p++) {        SyslogFormatter fmt = formats.get(p);        Pattern pattern = fmt.regexPattern;        Matcher matcher = pattern.matcher(eventStr);        if (!matcher.matches()) {            continue;        }        MatchResult res = matcher.toMatchResult();        for (int grp = 1; grp <= res.groupCount(); grp++) {            String value = res.group(grp);            if (grp == SYSLOG_TIMESTAMP_POS) {                timeStampString = value;                                if (value != null) {                    for (int sp = 0; sp < fmt.searchPattern.size(); sp++) {                        value = value.replaceAll(fmt.searchPattern.get(sp), fmt.replacePattern.get(sp));                    }                                        if (fmt.addYear) {                        value = clock.instant().atOffset(ZoneOffset.UTC).get(ChronoField.YEAR) + value;                    }                                        for (int dt = 0; dt < fmt.dateFormat.size(); dt++) {                        try {                            Date parsedDate = fmt.dateFormat.get(dt).parse(value);                            /*                 * Some code to try and add some smarts to the year insertion.                 * Original code just added the current year which was okay-ish, but around                 * January 1st becomes pretty naïve.                 * The current year is added above. This code, if the year has been added does                 * the following:                 * 1. Compute what the computed time, but one month in the past would be.                 * 2. Compute what the computed time, but eleven months in the future would be.                 * If the computed time is more than one month in the future then roll it back a                 * year. If the computed time is more than eleven months in the past then roll it                 * forward a year. This gives us a 12 month rolling window (11 months in the past,                 * 1 month in the future) of timestamps.                 */                            if (fmt.addYear) {                                Calendar calParsed = Calendar.getInstance();                                calParsed.setTime(parsedDate);                                Calendar calMinusOneMonth = Calendar.getInstance();                                calMinusOneMonth.setTime(parsedDate);                                calMinusOneMonth.add(Calendar.MONTH, -1);                                Calendar calPlusElevenMonths = Calendar.getInstance();                                calPlusElevenMonths.setTime(parsedDate);                                calPlusElevenMonths.add(Calendar.MONTH, +11);                                long currentTimeMillis = clock.millis();                                if (calParsed.getTimeInMillis() > currentTimeMillis && calMinusOneMonth.getTimeInMillis() > currentTimeMillis) {                                                                        Calendar c1 = Calendar.getInstance();                                    c1.setTime(parsedDate);                                    c1.add(Calendar.YEAR, -1);                                    parsedDate = c1.getTime();                                } else if (calParsed.getTimeInMillis() < currentTimeMillis && calPlusElevenMonths.getTimeInMillis() < currentTimeMillis) {                                                                        Calendar c1 = Calendar.getInstance();                                    c1.setTime(parsedDate);                                    c1.add(Calendar.YEAR, +1);                                    parsedDate = c1.getTime();                                }                            }                            timeStamp = String.valueOf(parsedDate.getTime());                                                        break;                        } catch (ParseException e) {                                                        continue;                        }                    }                }            } else if (grp == SYSLOG_HOSTNAME_POS) {                hostName = value;            } else if (grp == SYSLOG_PRIORITY_POS) {                priority = value;            } else if (grp == SYSLOG_VERSION_POS) {                version = value;            } else if (grp == SYSLOG_BODY_POS) {                msgBody = addFieldsToBody(keepFields, value, priority, version, timeStampString, hostName);            }        }                break;    }}
797abe964dfff3ea52683e6ab27a5cb7ccb950ef54ae8d67166411c260052e08
reset
private void reset()
{    baos.reset();    m = Mode.START;    prio.delete(0, prio.length());    isBadEvent = false;    isIncompleteEvent = false;    hostName = null;    timeStamp = null;    msgBody = null;}
e54e20cfe05e688f0519b89219f0b32d04d014372eb865b54ab1aed658357883
extractEvent
public Event extractEvent(ChannelBuffer in)
{    /* for protocol debugging    ByteBuffer bb = in.toByteBuffer();    int remaining = bb.remaining();    byte[] buf = new byte[remaining];    bb.get(buf);    HexDump.dump(buf, 0, System.out, 0);    */    byte b = 0;    Event e = null;    boolean doneReading = false;    try {        while (!doneReading && in.readable()) {            b = in.readByte();            switch(m) {                case START:                    if (b == '<') {                        baos.write(b);                        m = Mode.PRIO;                    } else if (b == '\n') {                                                                                                                                                                        logger.debug("Delimiter found while in START mode, ignoring..");                    } else {                        isBadEvent = true;                        baos.write(b);                                                m = Mode.DATA;                    }                    break;                case PRIO:                    baos.write(b);                    if (b == '>') {                        if (prio.length() == 0) {                            isBadEvent = true;                        }                        m = Mode.DATA;                    } else {                        char ch = (char) b;                        prio.append(ch);                                                if (!Character.isDigit(ch) || prio.length() > 3) {                            isBadEvent = true;                                                        m = Mode.DATA;                        }                    }                    break;                case DATA:                                        if (b == '\n') {                        e = buildEvent();                        doneReading = true;                    } else {                        baos.write(b);                    }                    if (baos.size() == this.maxSize && !doneReading) {                        isIncompleteEvent = true;                        e = buildEvent();                        doneReading = true;                    }                    break;            }        }                if (e == null && isUdp) {            doneReading = true;            e = buildEvent();        }    } finally {        }    return e;}
efa66bff571d7ee37e7f98431c17652cb7882ef8f8591ede3e2abcdfdc2f84eb
getEventSize
public Integer getEventSize()
{    return maxSize;}
af25f7aa53d989b203c7764a0d4ba9d6b6a71789fb5b7f0849d0b21495444088
setEventSize
public void setEventSize(Integer eventSize)
{    this.maxSize = eventSize;}
a638fe4d29b8a91536d40bcc35d86b0c853477772ffd659cc81ae8cf8232f039
setKeepFields
public void setKeepFields(Set<String> keepFields)
{    this.keepFields = keepFields;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    configureSsl(context);    logger.info("Configuring thrift source.");    port = context.getInteger(CONFIG_PORT);    Preconditions.checkNotNull(port, "Port must be specified for Thrift " + "Source.");    bindAddress = context.getString(CONFIG_BIND);    Preconditions.checkNotNull(bindAddress, "Bind address must be specified " + "for Thrift Source.");    try {        maxThreads = context.getInteger(CONFIG_THREADS, 0);        maxThreads = (maxThreads <= 0) ? Integer.MAX_VALUE : maxThreads;    } catch (NumberFormatException e) {        logger.warn("Thrift source\'s \"threads\" property must specify an " + "integer value: " + context.getString(CONFIG_THREADS));    }    if (sourceCounter == null) {        sourceCounter = new SourceCounter(getName());    }    protocol = context.getString(CONFIG_PROTOCOL);    if (protocol == null) {                protocol = COMPACT_PROTOCOL;    }    Preconditions.checkArgument((protocol.equalsIgnoreCase(BINARY_PROTOCOL) || protocol.equalsIgnoreCase(COMPACT_PROTOCOL)), "binary or compact are the only valid Thrift protocol types to " + "choose from.");    principal = context.getString(AGENT_PRINCIPAL);    String keytab = context.getString(AGENT_KEYTAB);    enableKerberos = context.getBoolean(KERBEROS_KEY, false);    this.flumeAuth = FlumeAuthenticationUtil.getAuthenticator(principal, keytab);    if (enableKerberos) {        if (!flumeAuth.isAuthenticated()) {            throw new FlumeException("Authentication failed in Kerberos mode for " + "principal " + principal + " keytab " + keytab);        }        flumeAuth.startCredentialRefresher();    }}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    logger.info("Starting thrift source");        server = getTThreadedSelectorServer();        if (server == null) {        server = getTThreadPoolServer();    }    servingExecutor = Executors.newSingleThreadExecutor(new ThreadFactoryBuilder().setNameFormat("Flume Thrift Source I/O Boss").build());    /**     * Start serving.     */    servingExecutor.submit(new Runnable() {        @Override        public void run() {            flumeAuth.execute(new PrivilegedAction<Object>() {                @Override                public Object run() {                    server.serve();                    return null;                }            });        }    });    long timeAfterStart = System.currentTimeMillis();    while (!server.isServing()) {        try {            if (System.currentTimeMillis() - timeAfterStart >= 10000) {                throw new FlumeException("Thrift server failed to start!");            }            TimeUnit.MILLISECONDS.sleep(1000);        } catch (InterruptedException e) {            Thread.currentThread().interrupt();            throw new FlumeException("Interrupted while waiting for Thrift server" + " to start.", e);        }    }    sourceCounter.start();    logger.info("Started Thrift source.");    super.start();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    flumeAuth.execute(new PrivilegedAction<Object>() {        @Override        public Object run() {            server.serve();            return null;        }    });}
c776c1d9926d3c451c94535f06a7834f6cdda8e431a2f491bdd1600744ded326
run
public Object run()
{    server.serve();    return null;}
94adee46804cabc666cbe8b7a2579fdad108426f370a461104048388748d15ee
getSSLServerTransport
private TServerTransport getSSLServerTransport()
{    try {        TServerTransport transport;        TSSLTransportFactory.TSSLTransportParameters params = new TSSLTransportFactory.TSSLTransportParameters();        params.setKeyStore(getKeystore(), getKeystorePassword(), KeyManagerFactory.getDefaultAlgorithm(), getKeystoreType());        transport = TSSLTransportFactory.getServerSocket(port, 120000, InetAddress.getByName(bindAddress), params);        ServerSocket serverSock = ((TServerSocket) transport).getServerSocket();        if (serverSock instanceof SSLServerSocket) {            SSLServerSocket sslServerSock = (SSLServerSocket) serverSock;            SSLParameters sslParameters = sslServerSock.getSSLParameters();            sslServerSock.setEnabledCipherSuites(getFilteredCipherSuites(sslParameters));            sslServerSock.setEnabledProtocols(getFilteredProtocols(sslParameters));        }        return transport;    } catch (Throwable throwable) {        throw new FlumeException("Cannot start Thrift source.", throwable);    }}
a54ee6c494f24af94c163b6f39d015aa10dd468ad4c862f8dde2b1421a8d154d
getTServerTransport
private TServerTransport getTServerTransport()
{    try {        return new TServerSocket(new InetSocketAddress(bindAddress, port));    } catch (Throwable throwable) {        throw new FlumeException("Cannot start Thrift source.", throwable);    }}
efd4ae0c46e938851f598ce972694ea2afd2fddc81ea1d17b9d4ed42880c72c3
getProtocolFactory
private TProtocolFactory getProtocolFactory()
{    if (protocol.equals(BINARY_PROTOCOL)) {        logger.info("Using TBinaryProtocol");        return new TBinaryProtocol.Factory();    } else {        logger.info("Using TCompactProtocol");        return new TCompactProtocol.Factory();    }}
6b5cec01fc8c563a447b4197225dcbfc0dd974bb6a0b5c82be1a8f048611363c
getTThreadedSelectorServer
private TServer getTThreadedSelectorServer()
{    if (isSslEnabled() || enableKerberos) {        return null;    }    Class<?> serverClass;    Class<?> argsClass;    TServer.AbstractServerArgs args;    try {        serverClass = Class.forName("org.apache.thrift" + ".server.TThreadedSelectorServer");        argsClass = Class.forName("org.apache.thrift" + ".server.TThreadedSelectorServer$Args");        TServerTransport serverTransport = new TNonblockingServerSocket(new InetSocketAddress(bindAddress, port));        ExecutorService sourceService;        ThreadFactory threadFactory = new ThreadFactoryBuilder().setNameFormat("Flume Thrift IPC Thread %d").build();        if (maxThreads == 0) {            sourceService = Executors.newCachedThreadPool(threadFactory);        } else {            sourceService = Executors.newFixedThreadPool(maxThreads, threadFactory);        }        args = (TNonblockingServer.AbstractNonblockingServerArgs) argsClass.getConstructor(TNonblockingServerTransport.class).newInstance(serverTransport);        Method m = argsClass.getDeclaredMethod("executorService", ExecutorService.class);        m.invoke(args, sourceService);        populateServerParams(args);        /*       * Both THsHaServer and TThreadedSelectorServer allows us to pass in       * the executor service to use - unfortunately the "executorService"       * method does not exist in the parent abstract Args class,       * so use reflection to pass the executor in.       *       */        server = (TServer) serverClass.getConstructor(argsClass).newInstance(args);    } catch (ClassNotFoundException e) {        return null;    } catch (Throwable ex) {        throw new FlumeException("Cannot start Thrift Source.", ex);    }    return server;}
640c61fdce9f2d115222edeac7d0e5ef7a65ffb59e3a5ed235676d916e55be92
getTThreadPoolServer
private TServer getTThreadPoolServer()
{    TServerTransport serverTransport;    if (isSslEnabled()) {        serverTransport = getSSLServerTransport();    } else {        serverTransport = getTServerTransport();    }    TThreadPoolServer.Args serverArgs = new TThreadPoolServer.Args(serverTransport);    serverArgs.maxWorkerThreads(maxThreads);    populateServerParams(serverArgs);    return new TThreadPoolServer(serverArgs);}
d1277acfeb71f1a59c633997cd88fe78282ed9933465ab1611f69c7ef5052340
populateServerParams
private void populateServerParams(TServer.AbstractServerArgs args)
{        args.protocolFactory(getProtocolFactory());        if (enableKerberos) {        args.transportFactory(getSASLTransportFactory());    } else {        args.transportFactory(new TFastFramedTransport.Factory());    }        args.processor(new ThriftSourceProtocol.Processor<ThriftSourceHandler>(new ThriftSourceHandler()));}
984da8e1a97e6070715253c58ed18a8ea790fde48232ccc009cb650a6f4dac45
getSASLTransportFactory
private TTransportFactory getSASLTransportFactory()
{    String[] names;    try {        names = FlumeAuthenticationUtil.splitKerberosName(principal);    } catch (IOException e) {        throw new FlumeException("Error while trying to resolve Principal name - " + principal, e);    }    Map<String, String> saslProperties = new HashMap<String, String>();    saslProperties.put(Sasl.QOP, "auth");    TSaslServerTransport.Factory saslTransportFactory = new TSaslServerTransport.Factory();    saslTransportFactory.addServerDefinition("GSSAPI", names[0], names[1], saslProperties, FlumeAuthenticationUtil.getSaslGssCallbackHandler());    return saslTransportFactory;}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    if (server != null && server.isServing()) {        server.stop();    }    if (servingExecutor != null) {        servingExecutor.shutdown();        try {            if (!servingExecutor.awaitTermination(5, TimeUnit.SECONDS)) {                servingExecutor.shutdownNow();            }        } catch (InterruptedException e) {            throw new FlumeException("Interrupted while waiting for server to be " + "shutdown.");        }    }    sourceCounter.stop();    super.stop();}
a54b69432f679ba4c49b1d013a0043e6205966d8a826637757a24931a9413f53
append
public Status append(ThriftFlumeEvent event) throws TException
{    Event flumeEvent = EventBuilder.withBody(event.getBody(), event.getHeaders());    sourceCounter.incrementAppendReceivedCount();    sourceCounter.incrementEventReceivedCount();    try {        getChannelProcessor().processEvent(flumeEvent);    } catch (ChannelException ex) {        logger.warn("Thrift source " + getName() + " could not append events " + "to the channel.", ex);        sourceCounter.incrementChannelWriteFail();        return Status.FAILED;    }    sourceCounter.incrementAppendAcceptedCount();    sourceCounter.incrementEventAcceptedCount();    return Status.OK;}
5d2dac105501257fa7413f36011388c07328bc76fa6f4a71c4e016aacfd6a925
appendBatch
public Status appendBatch(List<ThriftFlumeEvent> events) throws TException
{    sourceCounter.incrementAppendBatchReceivedCount();    sourceCounter.addToEventReceivedCount(events.size());    List<Event> flumeEvents = Lists.newArrayList();    for (ThriftFlumeEvent event : events) {        flumeEvents.add(EventBuilder.withBody(event.getBody(), event.getHeaders()));    }    try {        getChannelProcessor().processEventBatch(flumeEvents);    } catch (ChannelException ex) {        logger.warn("Thrift source %s could not append events to the channel.", getName());        sourceCounter.incrementChannelWriteFail();        return Status.FAILED;    }    sourceCounter.incrementAppendBatchAcceptedCount();    sourceCounter.addToEventAcceptedCount(events.size());    return Status.OK;}
27b05d73bfd2261c7514de238c7234f6ba77ccedb7a3894c9cef92878805920f
forSource
public static SourceRunner forSource(Source source)
{    SourceRunner runner = null;    if (source instanceof PollableSource) {        runner = new PollableSourceRunner();        ((PollableSourceRunner) runner).setSource((PollableSource) source);    } else if (source instanceof EventDrivenSource) {        runner = new EventDrivenSourceRunner();        ((EventDrivenSourceRunner) runner).setSource((EventDrivenSource) source);    } else {        throw new IllegalArgumentException("No known runner type for source " + source);    }    return runner;}
c447bf187e71df2ed36b6f089a159c9449db4e7a41a578c0f9ac8588bf7dc706
getSource
public Source getSource()
{    return source;}
4ddc7b60fb83394f08c40e65a9a69e2697d847708179df8b1d60860db19d6cbf
setSource
public void setSource(Source source)
{    this.source = source;}
40832d7575f348110d4b53bc172a3cd3feb40023d7b53063d98f3ba0ab440aa6
currentTimeMillis
public long currentTimeMillis()
{    return System.currentTimeMillis();}
4db626060c4286b800843c6136d38d336df12866854f71658be0aeb4c4cc181e
allocate
public static ByteBuffer allocate(int size)
{    Preconditions.checkArgument(size > 0, "Size must be greater than zero");    long maxDirectMemory = getDirectMemorySize();    long allocatedCurrently = allocated.get();    LOG.info("Direct Memory Allocation: " + " Allocation = " + size + ", Allocated = " + allocatedCurrently + ", MaxDirectMemorySize = " + maxDirectMemory + ", Remaining = " + Math.max(0, (maxDirectMemory - allocatedCurrently)));    try {        ByteBuffer result = ByteBuffer.allocateDirect(size);        allocated.addAndGet(size);        return result;    } catch (OutOfMemoryError error) {        LOG.error("Error allocating " + size + ", you likely want" + " to increase " + MAX_DIRECT_MEMORY_PARAM, error);        throw error;    }}
858931bd42e6bf2cfd80b35ae87908c9487f307c6ae603f80130cf918434f086
clean
public static void clean(ByteBuffer buffer) throws Exception
{    Preconditions.checkArgument(buffer.isDirect(), "buffer isn't direct!");    Method cleanerMethod = buffer.getClass().getMethod("cleaner");    cleanerMethod.setAccessible(true);    Object cleaner = cleanerMethod.invoke(buffer);    Method cleanMethod = cleaner.getClass().getMethod("clean");    cleanMethod.setAccessible(true);    cleanMethod.invoke(cleaner);    allocated.getAndAdd(-buffer.capacity());    long maxDirectMemory = getDirectMemorySize();    LOG.info("Direct Memory Deallocation: " + ", Allocated = " + allocated.get() + ", MaxDirectMemorySize = " + maxDirectMemory + ", Remaining = " + Math.max(0, (maxDirectMemory - allocated.get())));}
5fc9e0ab356e0e9736b1d0abdda5e7335836abaa9edf6b12eba340952d3c3004
getDirectMemorySize
public static long getDirectMemorySize()
{    RuntimeMXBean RuntimemxBean = ManagementFactory.getRuntimeMXBean();    List<String> arguments = Lists.reverse(RuntimemxBean.getInputArguments());        long multiplier = 1;    for (String s : arguments) {        if (s.contains(MAX_DIRECT_MEMORY_PARAM)) {            String memSize = s.toLowerCase(Locale.ENGLISH).replace(MAX_DIRECT_MEMORY_PARAM.toLowerCase(Locale.ENGLISH), "").trim();            if (memSize.contains("k")) {                multiplier = 1024;            } else if (memSize.contains("m")) {                multiplier = 1048576;            } else if (memSize.contains("g")) {                multiplier = 1073741824;            }            memSize = memSize.replaceAll("[^\\d]", "");            long retValue = Long.parseLong(memSize);            return retValue * multiplier;        }    }    return DEFAULT_SIZE;}
4b9b775c434435a63103682ad5cfe1238de650c884679691e78431d6d00d0f9f
getDefaultDirectMemorySize
private static long getDefaultDirectMemorySize()
{    try {        Class<?> VM = Class.forName("sun.misc.VM");        Method maxDirectMemory = VM.getDeclaredMethod("maxDirectMemory", (Class<?>) null);        Object result = maxDirectMemory.invoke(null, (Object[]) null);        if (result != null && result instanceof Long) {            return (Long) result;        }    } catch (Exception e) {        LOG.info("Unable to get maxDirectMemory from VM: " + e.getClass().getSimpleName() + ": " + e.getMessage());    }        return Runtime.getRuntime().maxMemory();}
9ca9e6d75327e06dd95ccb060da82668fa6b4f766189a3e23e1da73148d7f2e6
setConfigurationFields
public static void setConfigurationFields(Object configurable, Map<String, String> properties) throws ConfigurationException
{    Class<?> clazz = configurable.getClass();    for (Method method : clazz.getMethods()) {        String methodName = method.getName();        if (methodName.startsWith("set") && method.getParameterTypes().length == 1) {            String fieldName = methodName.substring(3);            String value = properties.get(StringUtils.uncapitalize(fieldName));            if (value != null) {                Class<?> fieldType = method.getParameterTypes()[0];                ;                try {                    if (fieldType.equals(String.class)) {                        method.invoke(configurable, value);                    } else if (fieldType.equals(boolean.class)) {                        method.invoke(configurable, Boolean.parseBoolean(value));                    } else if (fieldType.equals(short.class)) {                        method.invoke(configurable, Short.parseShort(value));                    } else if (fieldType.equals(long.class)) {                        method.invoke(configurable, Long.parseLong(value));                    } else if (fieldType.equals(float.class)) {                        method.invoke(configurable, Float.parseFloat(value));                    } else if (fieldType.equals(int.class)) {                        method.invoke(configurable, Integer.parseInt(value));                    } else if (fieldType.equals(double.class)) {                        method.invoke(configurable, Double.parseDouble(value));                    } else if (fieldType.equals(char.class)) {                        method.invoke(configurable, value.charAt(0));                    } else if (fieldType.equals(byte.class)) {                        method.invoke(configurable, Byte.parseByte(value));                    } else if (fieldType.equals(String[].class)) {                        method.invoke(configurable, (Object) value.split("\\s+"));                    } else {                        throw new ConfigurationException("Unable to configure component due to an unsupported type on field: " + fieldName);                    }                } catch (Exception ex) {                    if (ex instanceof ConfigurationException) {                        throw (ConfigurationException) ex;                    } else {                        throw new ConfigurationException("Unable to configure component: ", ex);                    }                }            }        }    }}
cdea9b960d059b0f201f0ab252a3fe31132fac15f5196699dfb28e73d1576d51
setConfigurationFields
public static void setConfigurationFields(Object configurable, Context context) throws ConfigurationException
{    Class<?> clazz = configurable.getClass();    Map<String, String> properties = context.getSubProperties(clazz.getSimpleName() + ".");    setConfigurationFields(configurable, properties);}
75cb9317f3faad102fb56a5e440ca68daf89c239879a0ed675c9763553ccfcea
setConfigurationFields
public static void setConfigurationFields(Object configurable, Context context, String subPropertiesPrefix) throws ConfigurationException
{    Map<String, String> properties = context.getSubProperties(subPropertiesPrefix);    setConfigurationFields(configurable, properties);}
3116ea2053d9de960ec3753eb07f3d243c370662aa1f0175ad357057c9ce5a52
main
public static void main(String[] args)
{    if (args.length == 0) {        for (Object prop : System.getProperties().keySet()) {            System.out.println(prop + "=" + System.getProperty((String) prop, ""));        }    } else {        for (String prop : args) {            System.out.println(prop + "=" + System.getProperty(prop, ""));        }    }}
2693ef32307ed8ae06c4ea6d7f81ff2012f41980e114dde7891c3d0703f81e10
enforceConstraints
public static ConstraintSecurityHandler enforceConstraints()
{    Constraint c = new Constraint();    c.setAuthenticate(true);    ConstraintMapping cmt = new ConstraintMapping();    cmt.setConstraint(c);    cmt.setMethod("TRACE");    cmt.setPathSpec("/*");    ConstraintMapping cmo = new ConstraintMapping();    cmo.setConstraint(c);    cmo.setMethod("OPTIONS");    cmo.setPathSpec("/*");    ConstraintSecurityHandler sh = new ConstraintSecurityHandler();    sh.setConstraintMappings(new ConstraintMapping[] { cmt, cmo });    return sh;}
ced6c2520db0ab962d2351adf8dd037f5679ea025a95c3d97f835b0c84c25132
isWindows
public static boolean isWindows()
{    String os = System.getProperty("os.name");    boolean isWin = (os.toLowerCase(Locale.ENGLISH).indexOf("win") >= 0);    return isWin;}
71cc4e957e66722202351c2eaf36d53608bec93e12f682c61e620d71f1135c6c
roundDownTimeStampSeconds
public static long roundDownTimeStampSeconds(long timestamp, int roundDownSec) throws IllegalStateException
{    return roundDownTimeStampSeconds(timestamp, roundDownSec, null);}
01689883f84640779db773d73d2ebc9110fc04463720fcdc1909622127b943cd
roundDownTimeStampSeconds
public static long roundDownTimeStampSeconds(long timestamp, int roundDownSec, TimeZone timeZone) throws IllegalStateException
{    Preconditions.checkArgument(roundDownSec > 0 && roundDownSec <= 60, "RoundDownSec must be > 0 and <=60");    Calendar cal = roundDownField(timestamp, Calendar.SECOND, roundDownSec, timeZone);    cal.set(Calendar.MILLISECOND, 0);    return cal.getTimeInMillis();}
1b8337c083d00697b080eb2df457cce96579c176c4f3501345f305c16e450ad1
roundDownTimeStampMinutes
public static long roundDownTimeStampMinutes(long timestamp, int roundDownMins) throws IllegalStateException
{    return roundDownTimeStampMinutes(timestamp, roundDownMins, null);}
078b988768f9871e195bc5b73365b013f254974f2e93d3ea9f371be5fe7979f9
roundDownTimeStampMinutes
public static long roundDownTimeStampMinutes(long timestamp, int roundDownMins, TimeZone timeZone) throws IllegalStateException
{    Preconditions.checkArgument(roundDownMins > 0 && roundDownMins <= 60, "RoundDown must be > 0 and <=60");    Calendar cal = roundDownField(timestamp, Calendar.MINUTE, roundDownMins, timeZone);    cal.set(Calendar.SECOND, 0);    cal.set(Calendar.MILLISECOND, 0);    return cal.getTimeInMillis();}
7d2f2f5ddde6b0097fff410e5ca471131b9f35aad01e12823a32b57f377bba66
roundDownTimeStampHours
public static long roundDownTimeStampHours(long timestamp, int roundDownHours) throws IllegalStateException
{    return roundDownTimeStampHours(timestamp, roundDownHours, null);}
0e9df94474a33dcd487dd48ed7252b5a86ead1523a6bf1d4592453351e53c848
roundDownTimeStampHours
public static long roundDownTimeStampHours(long timestamp, int roundDownHours, TimeZone timeZone) throws IllegalStateException
{    Preconditions.checkArgument(roundDownHours > 0 && roundDownHours <= 24, "RoundDown must be > 0 and <=24");    Calendar cal = roundDownField(timestamp, Calendar.HOUR_OF_DAY, roundDownHours, timeZone);    cal.set(Calendar.MINUTE, 0);    cal.set(Calendar.SECOND, 0);    cal.set(Calendar.MILLISECOND, 0);    return cal.getTimeInMillis();}
0075d16523ef5b3566e046fe6ab5032d2f46104e1e48ce9ace1021720d7d14b5
roundDownField
private static Calendar roundDownField(long timestamp, int field, int roundDown, TimeZone timeZone)
{    Preconditions.checkArgument(timestamp > 0, "Timestamp must be positive");    Calendar cal = (timeZone == null) ? Calendar.getInstance() : Calendar.getInstance(timeZone);    cal.setTimeInMillis(timestamp);    int fieldVal = cal.get(field);    int remainder = (fieldVal % roundDown);    cal.set(field, fieldVal - remainder);    return cal;}
4bbc095c05fe2a54c7e6885f2d616e78c45e69373afeb1343a8fbd297a770752
getPackage
 static Package getPackage()
{    return myPackage;}
09e2faf8b93816114e25a166e8a9df366645ed17d7b1f777d4604469c347b564
getVersion
public static String getVersion()
{    return version != null ? version.version() : "Unknown";}
7bd8281e0e8c7f0947ceadb9341e602a368c8c95c69d28d68d42f0fc5c186c7e
getRevision
public static String getRevision()
{    if (version != null && version.revision() != null && !version.revision().isEmpty()) {        return version.revision();    }    return "Unknown";}
adae2b0f0dba16e5890ac42d141cfff9939c28198d82d4b334f2213969bc1d2c
getBranch
public static String getBranch()
{    return version != null ? version.branch() : "Unknown";}
8c0698c50b086a251ebc68bbe03cbbc8e2217b41b2fbd15126954d348d22e878
getDate
public static String getDate()
{    return version != null ? version.date() : "Unknown";}
949e47d3c72f0e2f2fc1c19768bb96a7a987363c6ec3e29b9d156f84101b932c
getUser
public static String getUser()
{    return version != null ? version.user() : "Unknown";}
9504f2f8895269430956f0fc7dcfda87efa3b964ab2894cf3fae87e061bdf781
getUrl
public static String getUrl()
{    return version != null ? version.url() : "Unknown";}
7cc0703447c4ff0d185c6eda465ba9ca7081a07554fc5faf1fae4df904e027b1
getSrcChecksum
public static String getSrcChecksum()
{    return version != null ? version.srcChecksum() : "Unknown";}
9def613df73f85ca8d7c7a09de54e66c138295012409c0d47237c441d957e699
getBuildVersion
public static String getBuildVersion()
{    return VersionInfo.getVersion() + " from " + VersionInfo.getRevision() + " by " + VersionInfo.getUser() + " on " + VersionInfo.getDate() + " source checksum " + VersionInfo.getSrcChecksum();}
3116ea2053d9de960ec3753eb07f3d243c370662aa1f0175ad357057c9ce5a52
main
public static void main(String[] args)
{    System.out.println("Flume " + getVersion());    System.out.println("Source code repository: " + "https://git-wip-us.apache.org/repos/asf/flume.git");    System.out.println("Revision: " + getRevision());    System.out.println("Compiled by " + getUser() + " on " + getDate());    System.out.println("From source with checksum " + getSrcChecksum());}
9f140bc188b985c904d915d0f9caa9e6bf6d6f8102e28fa3b4fe9ee164f58adc
getMode
public Mode getMode()
{    return mode;}
87c7debf16c81615d71d0b3936979cd226b8ac5f59f847bc2e429b388651926d
setMode
public void setMode(Mode mode)
{    this.mode = mode;}
313e2b6bfbd5186f65832a2560d6b291d8c933b99ed76a370db7ebc88cdd3324
wasLastTransactionCommitted
public boolean wasLastTransactionCommitted()
{    return lastTransactionCommitted;}
1eb3d682dc3b6a5c2114ba58fc0aaa20eea3f6d08523603bdd91458040e5f926
wasLastTransactionRolledBack
public boolean wasLastTransactionRolledBack()
{    return lastTransactionRolledBack;}
f33b1dac7373e19e9f41224bc279b97d3560c06bbafef601065a025495d6335d
wasLastTransactionClosed
public boolean wasLastTransactionClosed()
{    return lastTransactionClosed;}
39f7d6d1213100383ba6ea7c79d8ed4ca1c7407a0f2469c0973c0709371a6cb9
createTransaction
protected BasicTransactionSemantics createTransaction()
{    return new TestTransaction();}
d0f4c357d2169cf240c2c3f89fd8dbc51920c60b5fd178b99212bec33f26e303
doMode
protected void doMode() throws InterruptedException
{    switch(mode) {        case THROW_ERROR:            throw new TestError();        case THROW_RUNTIME:            throw new TestRuntimeException();        case THROW_CHANNEL:            throw new ChannelException("test");        case SLEEP:            Thread.sleep(300000);            break;    }}
089dd8ebc0ff4cc8f274f4df7a6cd25c63963a7dd757c692d51b389fe1b5a9c3
doBegin
protected void doBegin() throws InterruptedException
{    doMode();}
12f20da1039baa55cd8cd24a8512df38790e6cb0af896f04ec9f5012ddf00b9a
doPut
protected void doPut(Event event) throws InterruptedException
{    doMode();    synchronized (queue) {        queue.add(event);    }}
f8425491b25802703eb5080383b86f3b99d38a0998a1c49a9f85e4971cf4e57c
doTake
protected Event doTake() throws InterruptedException
{    doMode();    synchronized (queue) {        return queue.poll();    }}
1665f7d1b67a1fa794c9fb67a1be01e4bf6a8b0e782a8f9a49914917f9ecf058
doCommit
protected void doCommit() throws InterruptedException
{    doMode();    lastTransactionCommitted = true;}
2cbb76d448fbcbe4b802d87cf143885cfe914d2929bc4f7d5164451c23333cb5
doRollback
protected void doRollback() throws InterruptedException
{    lastTransactionRolledBack = true;    doMode();}
b59bbf45e4d212692a02e8bffbd55012fa8166d3da26e9dbfa4ceaa420037e32
doClose
protected void doClose()
{    lastTransactionClosed = true;    Preconditions.checkState(mode != TestChannel.Mode.SLEEP, "doClose() can't throw InterruptedException, so why SLEEP?");    try {        doMode();    } catch (InterruptedException e) {        Assert.fail();    }}
74251532c2866329c820e1210d4802b4a0ceadd8a82bc25c1943a770510d8a03
testException
protected void testException(Class<? extends Throwable> exceptionClass, Runnable test)
{    try {        test.run();        Assert.fail();    } catch (Throwable e) {        if (exceptionClass == InterruptedException.class && e instanceof ChannelException && e.getCause() instanceof InterruptedException) {            Assert.assertTrue(Thread.interrupted());        } else if (!exceptionClass.isInstance(e)) {            throw new AssertionError(e);        }    }}
a33f710883f04532348334aa4c9dca187e6820cd7b06a440437c9ec088f306bf
testIllegalArgument
protected void testIllegalArgument(Runnable test)
{    testException(IllegalArgumentException.class, test);}
97ae08498708cf1259b0b24bb60eed96f195dde5aa0f74e5a6f40dd3a97f7fff
testIllegalState
protected void testIllegalState(Runnable test)
{    testException(IllegalStateException.class, test);}
d68350066775fd69699db4ae2a46affaf56a06333c58914719fe7799254006e3
testWrongThread
protected void testWrongThread(final Runnable test) throws Exception
{    executor.submit(new Runnable() {        @Override        public void run() {            testIllegalState(test);        }    }).get();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    testIllegalState(test);}
716403653d0dcd9744f8b1249dbd1ce886ffe3f1a2ff7a72fa91a260b35eb132
testMode
protected void testMode(TestChannel.Mode mode, Runnable test)
{    TestChannel.Mode oldMode = channel.getMode();    try {        channel.setMode(mode);        test.run();    } finally {        channel.setMode(oldMode);    }}
e02556e17278c7678f483f7295289a27634df70da75b5b262f68a10cf241da58
testException
protected void testException(TestChannel.Mode mode, final Class<? extends Throwable> exceptionClass, final Runnable test)
{    testMode(mode, new Runnable() {        @Override        public void run() {            testException(exceptionClass, test);        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    testException(exceptionClass, test);}
90095609d464a712e4f9e4f16134bbe0ec5a09d6c965995fb78e5d91840f9649
testError
protected void testError(Runnable test)
{    testException(TestChannel.Mode.THROW_ERROR, TestError.class, test);}
b9d6d87f8fae20bc842178cdf7c950650bf9052e6b9825f2aedc56a0eb845007
testRuntimeException
protected void testRuntimeException(Runnable test)
{    testException(TestChannel.Mode.THROW_RUNTIME, TestRuntimeException.class, test);}
f88ba9dc439132db378e61d202b909d4d5a3102cf2ce6739301763774df43e54
testChannelException
protected void testChannelException(Runnable test)
{    testException(TestChannel.Mode.THROW_CHANNEL, ChannelException.class, test);}
c34776731f8bfeb66dbe04ea0a6fc6df82e8a5998f2f5ffef2aea9086061e05b
testInterrupt
protected void testInterrupt(final Runnable test)
{    testMode(TestChannel.Mode.SLEEP, new Runnable() {        @Override        public void run() {            testException(InterruptedException.class, new Runnable() {                @Override                public void run() {                    interruptTest(test);                }            });        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    testException(InterruptedException.class, new Runnable() {        @Override        public void run() {            interruptTest(test);        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    interruptTest(test);}
137894053540dde4b682160225c2f8d39b8fe70ea4a5197e407d336b9ba1e4e3
interruptTest
protected void interruptTest(final Runnable test)
{    final Thread mainThread = Thread.currentThread();    Future<?> future = executor.submit(new Runnable() {        @Override        public void run() {            try {                Thread.sleep(500);            } catch (InterruptedException e) {            }            mainThread.interrupt();        }    });    test.run();    try {        future.get();    } catch (Exception e) {        throw new AssertionError(e);    }}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    try {        Thread.sleep(500);    } catch (InterruptedException e) {    }    mainThread.interrupt();}
0e0dc3b380b3d21a52bcc1ce8848bec9265c45b880634d50814f0ad318578e14
testExceptions
protected void testExceptions(Runnable test) throws Exception
{    testWrongThread(test);    testBasicExceptions(test);    testInterrupt(test);}
95f9bb7ed85f72454e83f398d757818827282dc3ba66f72aa6d357479cc1ce6d
testBasicExceptions
protected void testBasicExceptions(Runnable test) throws Exception
{    testError(test);    testRuntimeException(test);    testChannelException(test);}
a137d67cbf4a7af20aa93177e840bb9f03d5c275b44a5cc3e10dbc09459dad4d
before
public void before()
{    Preconditions.checkState(channel == null, "test cleanup failed!");    Preconditions.checkState(executor == null, "test cleanup failed!");    channel = new TestChannel();    executor = Executors.newCachedThreadPool();}
e9923bdda539e76e2a1b0f9413f75194af84363b024fcb88195a34593794c316
after
public void after()
{    channel = null;    executor.shutdown();    executor = null;}
b72368b220d21a6c0da5e035d09c53b456dec98deda2c41aed3216679bf58c23
createMockChannel
public static Channel createMockChannel(String name)
{    Channel ch = new MockChannel();    ch.setName(name);    return ch;}
7c433c140e986ede99b2704e4370ce4dc62a481b499e15037b573f27288bffc9
put
public void put(Event event) throws ChannelException
{    events.add(event);}
bd28ef43945352a9d826db660bc6e7b38e1777eec9decd45c0467679fc18a6dd
take
public Event take() throws ChannelException
{    return (events.size() > 0) ? events.get(0) : null;}
2940dfdc387e1882ca0545a619d502102ae0c821f25b9ee739eafaade9ca3ee9
getTransaction
public Transaction getTransaction()
{    return new MockTransaction();}
1e146b07faa919b1916e630a172c03c6ebfc96663a23166e205cd71924113b12
begin
public void begin()
{}
609962ed3c13286966d937afa9c301e49ddab59023e4f4c7704fb7ba9630b243
commit
public void commit()
{}
f1b7a3da67263bf9cf38feebb790935f22fffbce70c05f42446b0a1c1fd2c534
rollback
public void rollback()
{}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{}
9a691e59a635186c5f7258710b8e44f5caf3510a02999c2c0ea95c8238b813ad
getHeaders
public Map<String, String> getHeaders()
{    return headers;}
6d1c35600a6f29feedab1769a2763829b83814294b318a32e8c71bf3529059a1
setHeaders
public void setHeaders(Map<String, String> headers)
{    this.headers = new HashMap<String, String>();    this.headers.putAll(headers);}
a624aa1b85808a74c9f320025ea600169bd6e4692611a44ef53a1970442ef820
getBody
public byte[] getBody()
{    return body;}
b8505eb3e09ba9bb11ab8433148a62af59b6b1a27ffe7e69cf12f0e20e7c76a1
setBody
public void setBody(byte[] body)
{    this.body = new byte[body.length];    System.arraycopy(body, 0, this.body, 0, body.length);}
c6708de972d6e84e45a42b7f78cd8874397c3cf1b49b2058875047597c598618
testHappyPath
public void testHappyPath()
{    for (int i = 0; i < events.size(); ++i) {        Transaction transaction = channel.getTransaction();        transaction.begin();        channel.put(events.get(i));        transaction.commit();        transaction.close();    }    for (int i = 0; i < events.size(); ++i) {        Transaction transaction = channel.getTransaction();        transaction.begin();        Assert.assertSame(events.get(i), channel.take());        transaction.commit();        transaction.close();    }}
bf4e6072d5c315146f0dad27d007db3db5e52e7fc10559966393c23bae2a6bb4
testMultiThreadedHappyPath
public void testMultiThreadedHappyPath() throws Exception
{    final int testLength = 1000;    Future<?> producer = executor.submit(new Runnable() {        @Override        public void run() {            try {                Thread.sleep(500);                for (int i = 0; i < testLength; ++i) {                    Transaction transaction = channel.getTransaction();                    transaction.begin();                    channel.put(events.get(i % events.size()));                    transaction.commit();                    transaction.close();                    Thread.sleep(1);                }                Thread.sleep(500);            } catch (InterruptedException e) {                Assert.fail();            }        }    });    int i = 0;    while (!producer.isDone()) {        Transaction transaction = channel.getTransaction();        transaction.begin();        Event event = channel.take();        if (event != null) {            Assert.assertSame(events.get(i % events.size()), event);            ++i;        }        transaction.commit();        transaction.close();    }    Assert.assertEquals(testLength, i);    producer.get();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    try {        Thread.sleep(500);        for (int i = 0; i < testLength; ++i) {            Transaction transaction = channel.getTransaction();            transaction.begin();            channel.put(events.get(i % events.size()));            transaction.commit();            transaction.close();            Thread.sleep(1);        }        Thread.sleep(500);    } catch (InterruptedException e) {        Assert.fail();    }}
e9ce8fa2bab2dfbe897ef4c7c846a2338ae03204b58b49f158ec316eabe105ce
testGetTransaction
public void testGetTransaction() throws Exception
{    final Transaction transaction = channel.getTransaction();    executor.submit(new Runnable() {        @Override        public void run() {            Assert.assertNotSame(transaction, channel.getTransaction());        }    }).get();    Assert.assertSame(transaction, channel.getTransaction());    transaction.begin();    executor.submit(new Runnable() {        @Override        public void run() {            Assert.assertNotSame(transaction, channel.getTransaction());        }    }).get();    Assert.assertSame(transaction, channel.getTransaction());    transaction.commit();    executor.submit(new Runnable() {        @Override        public void run() {            Assert.assertNotSame(transaction, channel.getTransaction());        }    }).get();    Assert.assertSame(transaction, channel.getTransaction());    transaction.close();    executor.submit(new Runnable() {        @Override        public void run() {            Assert.assertNotSame(transaction, channel.getTransaction());        }    }).get();    Assert.assertNotSame(transaction, channel.getTransaction());}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    Assert.assertNotSame(transaction, channel.getTransaction());}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    Assert.assertNotSame(transaction, channel.getTransaction());}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    Assert.assertNotSame(transaction, channel.getTransaction());}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    Assert.assertNotSame(transaction, channel.getTransaction());}
b29c5f0bf18e679748919260bf14346ce756ff4f1c6ba6ddbb7d2a7cecd5b25b
testBegin
public void testBegin() throws Exception
{    final Transaction transaction = channel.getTransaction();    testExceptions(new Runnable() {        @Override        public void run() {            transaction.begin();        }    });    transaction.begin();    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.begin();        }    });    transaction.commit();    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.begin();        }    });    transaction.close();    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.begin();        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.begin();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.begin();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.begin();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.begin();}
5c5ca7798ae7b5ae7cc4d19e302eba9c6f332fec4f86825457eb6f71145da0ff
testPut1
public void testPut1() throws Exception
{    testIllegalState(new Runnable() {        @Override        public void run() {            channel.put(events.get(0));        }    });    Transaction transaction = channel.getTransaction();    testIllegalState(new Runnable() {        @Override        public void run() {            channel.put(events.get(0));        }    });    transaction.begin();    channel.put(events.get(0));    testIllegalArgument(new Runnable() {        @Override        public void run() {            channel.put(null);        }    });    testExceptions(new Runnable() {        @Override        public void run() {            channel.put(events.get(0));        }    });    transaction.commit();    testIllegalState(new Runnable() {        @Override        public void run() {            channel.put(events.get(0));        }    });    transaction.close();    testIllegalState(new Runnable() {        @Override        public void run() {            channel.put(events.get(0));        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    channel.put(events.get(0));}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    channel.put(events.get(0));}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    channel.put(null);}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    channel.put(events.get(0));}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    channel.put(events.get(0));}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    channel.put(events.get(0));}
3391ed7eda1899a431c504689b37104730ddfc5301899979b1182ebabc3f9aed
testPut2
public void testPut2() throws Exception
{    Transaction transaction = channel.getTransaction();    transaction.begin();    channel.put(events.get(0));    transaction.rollback();    testIllegalState(new Runnable() {        @Override        public void run() {            channel.put(events.get(0));        }    });    transaction.close();    testIllegalState(new Runnable() {        @Override        public void run() {            channel.put(events.get(0));        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    channel.put(events.get(0));}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    channel.put(events.get(0));}
1ac93d4ca710d6ee29af049407f65509eedb91dbb1dcf5d0b14555554528e549
testPut3
public void testPut3() throws Exception
{    Transaction transaction = channel.getTransaction();    transaction.begin();    channel.put(events.get(0));    final Transaction finalTransaction = transaction;    testChannelException(new Runnable() {        @Override        public void run() {            finalTransaction.commit();        }    });    transaction.rollback();    testIllegalState(new Runnable() {        @Override        public void run() {            channel.put(events.get(0));        }    });    transaction.close();    testIllegalState(new Runnable() {        @Override        public void run() {            channel.put(events.get(0));        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    finalTransaction.commit();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    channel.put(events.get(0));}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    channel.put(events.get(0));}
75139bde671c668e118079835fe428ed266aa5def22fcb8eeae18b7ec1d4cc47
testTake1
public void testTake1() throws Exception
{    testIllegalState(new Runnable() {        @Override        public void run() {            channel.take();        }    });    Transaction transaction = channel.getTransaction();    testIllegalState(new Runnable() {        @Override        public void run() {            channel.take();        }    });    transaction.begin();    Assert.assertNull(channel.take());    for (int i = 0; i < 1000; ++i) {        channel.put(events.get(i % events.size()));    }    Assert.assertNotNull(channel.take());    testWrongThread(new Runnable() {        @Override        public void run() {            channel.take();        }    });    testBasicExceptions(new Runnable() {        @Override        public void run() {            channel.take();        }    });    testMode(TestChannel.Mode.SLEEP, new Runnable() {        @Override        public void run() {            interruptTest(new Runnable() {                @Override                public void run() {                    Assert.assertNull(channel.take());                    Assert.assertTrue(Thread.interrupted());                }            });        }    });    Assert.assertNotNull(channel.take());    transaction.commit();    testIllegalState(new Runnable() {        @Override        public void run() {            channel.take();        }    });    transaction.close();    testIllegalState(new Runnable() {        @Override        public void run() {            channel.take();        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    channel.take();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    channel.take();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    channel.take();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    channel.take();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    interruptTest(new Runnable() {        @Override        public void run() {            Assert.assertNull(channel.take());            Assert.assertTrue(Thread.interrupted());        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    Assert.assertNull(channel.take());    Assert.assertTrue(Thread.interrupted());}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    channel.take();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    channel.take();}
d34bd417e6f8387f6fe8854cedf2d7188fb3360be4a996383644f1987e22731e
testTake2
public void testTake2() throws Exception
{    Transaction transaction = channel.getTransaction();    transaction.begin();    channel.take();    transaction.rollback();    testIllegalState(new Runnable() {        @Override        public void run() {            channel.take();        }    });    transaction.close();    testIllegalState(new Runnable() {        @Override        public void run() {            channel.take();        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    channel.take();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    channel.take();}
163bdeb237f340a7a4f967672ad0ed0a7b4d86a00b9f01450fce8ca673df59b9
testTake3
public void testTake3() throws Exception
{    Transaction transaction = channel.getTransaction();    transaction.begin();    channel.take();    final Transaction finalTransaction = transaction;    testChannelException(new Runnable() {        @Override        public void run() {            finalTransaction.commit();        }    });    transaction.rollback();    testIllegalState(new Runnable() {        @Override        public void run() {            channel.take();        }    });    transaction.close();    testIllegalState(new Runnable() {        @Override        public void run() {            channel.take();        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    finalTransaction.commit();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    channel.take();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    channel.take();}
755ce874d114f02e8e2670edeadda10666543f70fda2bb33655393a517a50f5e
testCommit1
public void testCommit1() throws Exception
{    final Transaction transaction = channel.getTransaction();    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.commit();        }    });    transaction.begin();    testExceptions(new Runnable() {        @Override        public void run() {            transaction.commit();        }    });    transaction.commit();    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.commit();        }    });    transaction.close();    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.commit();        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.commit();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.commit();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.commit();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.commit();}
98e3831ec85d8c8204ed61307e95f0d50205eab62dabcae73c9b8be1d38a3956
testCommit2
public void testCommit2() throws Exception
{    final Transaction transaction = channel.getTransaction();    transaction.begin();    transaction.rollback();    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.commit();        }    });    transaction.close();    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.commit();        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.commit();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.commit();}
f3232dbaa7874377f5fa18b0c510e7b4096ed34c9752d1514ce10d5da7fd0e26
testRollback1
public void testRollback1() throws Exception
{    final Transaction transaction = channel.getTransaction();    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.rollback();        }    });    transaction.begin();    testWrongThread(new Runnable() {        @Override        public void run() {            transaction.rollback();        }    });    transaction.rollback();    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.rollback();        }    });    transaction.close();    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.rollback();        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.rollback();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.rollback();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.rollback();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.rollback();}
351c461edb3cee80c89ef1745bf2df964bec4aa55436d57e7e54ecb8fb689384
testRollback2
public void testRollback2() throws Exception
{    final Transaction transaction = channel.getTransaction();    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.rollback();        }    });    transaction.begin();    testError(new Runnable() {        @Override        public void run() {            transaction.rollback();        }    });    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.rollback();        }    });    transaction.close();    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.rollback();        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.rollback();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.rollback();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.rollback();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.rollback();}
1edf36d89d6e9d0559e125eb975b0d73129c2818088cd7d31518829546905eb1
testRollback3
public void testRollback3() throws Exception
{    final Transaction transaction = channel.getTransaction();    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.rollback();        }    });    transaction.begin();    testRuntimeException(new Runnable() {        @Override        public void run() {            transaction.rollback();        }    });    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.rollback();        }    });    transaction.close();    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.rollback();        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.rollback();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.rollback();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.rollback();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.rollback();}
d3dee61c669f778eb35086136941d416575057ba925e8a2adda779931b4409f8
testRollback4
public void testRollback4() throws Exception
{    final Transaction transaction = channel.getTransaction();    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.rollback();        }    });    transaction.begin();    testChannelException(new Runnable() {        @Override        public void run() {            transaction.rollback();        }    });    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.rollback();        }    });    transaction.close();    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.rollback();        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.rollback();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.rollback();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.rollback();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.rollback();}
730e495405aadcd678ca4dd09340aac6fe246c1f51f18e224ecbc0b2d5bbdf33
testRollback5
public void testRollback5() throws Exception
{    final Transaction transaction = channel.getTransaction();    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.rollback();        }    });    transaction.begin();    testInterrupt(new Runnable() {        @Override        public void run() {            transaction.rollback();        }    });    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.rollback();        }    });    transaction.close();    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.rollback();        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.rollback();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.rollback();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.rollback();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.rollback();}
568611ce5ecd1309add4aff6d51c45d383caec4aef3a1815d4d86ab0c475b842
testRollback6
public void testRollback6() throws Exception
{    final Transaction transaction = channel.getTransaction();    transaction.begin();    transaction.commit();    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.rollback();        }    });    transaction.close();    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.rollback();        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.rollback();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.rollback();}
20a59a1f8e301477729a09911f215652c080ff7dbe414546dc96c3ec37931cd9
testRollback7
public void testRollback7() throws Exception
{    final Transaction transaction = channel.getTransaction();    transaction.begin();    testExceptions(new Runnable() {        @Override        public void run() {            transaction.commit();        }    });    transaction.rollback();    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.rollback();        }    });    transaction.close();    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.rollback();        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.commit();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.rollback();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.rollback();}
ecf181fae6dd657f505113e9cad9a4a590fa074b9ed2524566169ff331b111f0
testClose1
public void testClose1() throws Exception
{    final Transaction transaction = channel.getTransaction();    testError(new Runnable() {        @Override        public void run() {            transaction.close();        }    });    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.close();        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.close();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.close();}
9183592946cf22e27bf16f5392d74d439dc2365d86990378eb9fb3f3fd70d27e
testClose2
public void testClose2() throws Exception
{    final Transaction transaction = channel.getTransaction();    testRuntimeException(new Runnable() {        @Override        public void run() {            transaction.close();        }    });    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.close();        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.close();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.close();}
02cbcb90f92dd6b0fed035cf28890c5a936df669b6d51a3c7980fedd64a45902
testClose3
public void testClose3() throws Exception
{    final Transaction transaction = channel.getTransaction();    testChannelException(new Runnable() {        @Override        public void run() {            transaction.close();        }    });    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.close();        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.close();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.close();}
46daac043bb19de8310c24e5d95ff8d090e33f57022c9b9d4ccd2d9bb2f7d6be
testClose4
public void testClose4() throws Exception
{    final Transaction transaction = channel.getTransaction();    transaction.begin();    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.close();        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.close();}
d8523aef25c356d2e47b1768d11d20737da7b0de70ce08a92cb48b600b200d58
testClose5
public void testClose5() throws Exception
{    final Transaction transaction = channel.getTransaction();    transaction.begin();    testChannelException(new Runnable() {        @Override        public void run() {            transaction.commit();        }    });    testIllegalState(new Runnable() {        @Override        public void run() {            transaction.close();        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.commit();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    transaction.close();}
aee493b311413e99fb171c504dd2f99eb55afcd07a42a8a56e675ffd25171eb5
testExceptionFromGetTransaction
public void testExceptionFromGetTransaction()
{        Channel ch = mock(Channel.class);    when(ch.getTransaction()).thenThrow(new ChannelException("doh!"));    ChannelSelector sel = new ReplicatingChannelSelector();    sel.setChannels(Lists.newArrayList(ch));    ChannelProcessor proc = new ChannelProcessor(sel);    List<Event> events = Lists.newArrayList();    events.add(EventBuilder.withBody("event 1", Charsets.UTF_8));    proc.processEventBatch(events);}
236b8f9f67e2cdcf80aac91896af930852fe9a31f97c09ffd04ee1cead65f2c1
testNullFromGetTransaction
public void testNullFromGetTransaction()
{        Channel ch = mock(Channel.class);    when(ch.getTransaction()).thenReturn(null);    ChannelSelector sel = new ReplicatingChannelSelector();    sel.setChannels(Lists.newArrayList(ch));    ChannelProcessor proc = new ChannelProcessor(sel);    List<Event> events = Lists.newArrayList();    events.add(EventBuilder.withBody("event 1", Charsets.UTF_8));    boolean threw = false;    try {        proc.processEventBatch(events);    } catch (NullPointerException ex) {        threw = true;        Assert.assertNotNull("NPE must be manually thrown", ex.getMessage());    }    Assert.assertTrue("Must throw NPE", threw);}
e165e38b8423680da0f3e7a494ac41d3873d5554953f823522e6d79f88a68735
testRequiredAndOptionalChannels
public void testRequiredAndOptionalChannels()
{    Context context = new Context();    ArrayList<Channel> channels = new ArrayList<Channel>();    for (int i = 0; i < 4; i++) {        Channel ch = new MemoryChannel();        ch.setName("ch" + i);        Configurables.configure(ch, context);        channels.add(ch);    }    ChannelSelector selector = new ReplicatingChannelSelector();    selector.setChannels(channels);    context = new Context();    context.put(ReplicatingChannelSelector.CONFIG_OPTIONAL, "ch2 ch3");    Configurables.configure(selector, context);    ChannelProcessor processor = new ChannelProcessor(selector);    context = new Context();    Configurables.configure(processor, context);    Event event1 = EventBuilder.withBody("event 1", Charsets.UTF_8);    processor.processEvent(event1);    try {        Thread.sleep(3000);    } catch (InterruptedException e) {    }    for (Channel channel : channels) {        Transaction transaction = channel.getTransaction();        transaction.begin();        Event event_ch = channel.take();        Assert.assertEquals(event1, event_ch);        transaction.commit();        transaction.close();    }    List<Event> events = Lists.newArrayList();    for (int i = 0; i < 100; i++) {        events.add(EventBuilder.withBody("event " + i, Charsets.UTF_8));    }    processor.processEventBatch(events);    try {        Thread.sleep(3000);    } catch (InterruptedException e) {    }    for (Channel channel : channels) {        Transaction transaction = channel.getTransaction();        transaction.begin();        for (int i = 0; i < 100; i++) {            Event event_ch = channel.take();            Assert.assertNotNull(event_ch);        }        transaction.commit();        transaction.close();    }}
4011e6bccc76170385e154efafb01ae3a129f7113d3a60a4b353a04e635880e2
testHappyPath1
public void testHappyPath1()
{    ChannelUtils.put(channel, events.get(0));    Assert.assertTrue(channel.wasLastTransactionCommitted());    Assert.assertFalse(channel.wasLastTransactionRolledBack());    Assert.assertTrue(channel.wasLastTransactionClosed());}
a9be03e82dc6f48da2cc6b02d3b0a6b20876e1faa427eb395f3c091d6a5def63
testHappyPath2
public void testHappyPath2()
{    ChannelUtils.take(channel);    Assert.assertTrue(channel.wasLastTransactionCommitted());    Assert.assertFalse(channel.wasLastTransactionRolledBack());    Assert.assertTrue(channel.wasLastTransactionClosed());}
87d02db7594a33cf75511f80515d3508a7fe8d371f863f9962f4c09a8632adf3
testHappyPath3
public void testHappyPath3()
{    ChannelUtils.put(channel, events.get(0));    Assert.assertSame(events.get(0), ChannelUtils.take(channel));}
0c1784099946f12750331e65f64bd033b8dce71a86de8e34d6f3184d9bc0e7d8
testHappyPath4
public void testHappyPath4()
{    for (int i = 0; i < events.size(); ++i) {        ChannelUtils.put(channel, events.get(i));    }    for (int i = 0; i < events.size(); ++i) {        Assert.assertSame(events.get(i), ChannelUtils.take(channel));    }}
821ba2c4814ca1ca49e545b655a45287164e3cca33ba2017d8a2db8d4aa9c7b8
testHappyPath5
public void testHappyPath5()
{    int rounds = 10;    for (int i = 0; i < rounds; ++i) {        ChannelUtils.put(channel, events);    }    for (int i = 0; i < rounds; ++i) {        List<Event> takenEvents = ChannelUtils.take(channel, events.size());        Assert.assertTrue(takenEvents.size() == events.size());        for (int j = 0; j < events.size(); ++j) {            Assert.assertSame(events.get(j), takenEvents.get(j));        }    }}
e181972f9134aabe1f392ca224163f7947327346443e31f35066b880a6b2d571
testTransact
private void testTransact(final TestChannel.Mode mode, Class<? extends Throwable> exceptionClass, final Runnable test)
{    testException(exceptionClass, new Runnable() {        @Override        public void run() {            ChannelUtils.transact(channel, new Runnable() {                @Override                public void run() {                    testMode(mode, test);                }            });        }    });    Assert.assertFalse(channel.wasLastTransactionCommitted());    Assert.assertTrue(channel.wasLastTransactionRolledBack());    Assert.assertTrue(channel.wasLastTransactionClosed());}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    ChannelUtils.transact(channel, new Runnable() {        @Override        public void run() {            testMode(mode, test);        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    testMode(mode, test);}
a87d725ccc7b2f6b7b4c64d4381477deb310d0ff75f2bc2058d71b97293d15d5
testTransact
private void testTransact(TestChannel.Mode mode, Class<? extends Throwable> exceptionClass)
{    testTransact(mode, exceptionClass, new Runnable() {        @Override        public void run() {            channel.put(events.get(0));        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    channel.put(events.get(0));}
bc039688ab37350c20af249fa24b67b9236549e5af2f35994da7c99358f02688
testError
public void testError()
{    testTransact(TestChannel.Mode.THROW_ERROR, TestError.class);}
fc922ba377c6adc7e7bc4bf8c999023f41515fc0861b31b892031a8d0eb1f0ad
testRuntimeException
public void testRuntimeException()
{    testTransact(TestChannel.Mode.THROW_RUNTIME, TestRuntimeException.class);}
d3964a0a7bb0c6fee9f4243399ab05805ddd0eaa22706ae783f2f70c2cbb0a6d
testChannelException
public void testChannelException()
{    testTransact(TestChannel.Mode.THROW_CHANNEL, ChannelException.class);}
8927a27fef2cfff1bdf4aac8fa4a96b6b008bc7f361558d9b8736fa7f4cef7ce
testInterrupt
public void testInterrupt() throws Exception
{    testTransact(TestChannel.Mode.SLEEP, InterruptedException.class, new Runnable() {        @Override        public void run() {            interruptTest(new Runnable() {                @Override                public void run() {                    channel.put(events.get(0));                }            });        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    interruptTest(new Runnable() {        @Override        public void run() {            channel.put(events.get(0));        }    });}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    channel.put(events.get(0));}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    channel = new MemoryChannel();}
da8739c2052ea478f41e8494a65fc57ca3e6ad2ed7c7740528cdddb66f1358d6
testPutTake
public void testPutTake() throws InterruptedException, EventDeliveryException
{    Event event = EventBuilder.withBody("test event".getBytes());    Context context = new Context();    Configurables.configure(channel, context);    Transaction transaction = channel.getTransaction();    Assert.assertNotNull(transaction);    transaction.begin();    channel.put(event);    transaction.commit();    transaction.close();    transaction = channel.getTransaction();    Assert.assertNotNull(transaction);    transaction.begin();    Event event2 = channel.take();    Assert.assertEquals(event, event2);    transaction.commit();}
3cd0e46b25c383b9e4ab7957bb9e1a9a5c0191428186b8161f7c2fd9a1c88be3
testPutAcceptsNullValueInHeader
public void testPutAcceptsNullValueInHeader()
{    Configurables.configure(channel, new Context());    Event event = EventBuilder.withBody("test body".getBytes(Charsets.UTF_8), Collections.<String, String>singletonMap("test_key", null));    Transaction txPut = channel.getTransaction();    txPut.begin();    channel.put(event);    txPut.commit();    txPut.close();    Transaction txTake = channel.getTransaction();    txTake.begin();    Event eventTaken = channel.take();    Assert.assertEquals(event, eventTaken);    txTake.commit();}
95b0b8ca155717ec91cc43e6ceb910c6da1471b63765145051639c82eefd0aad
testChannelResize
public void testChannelResize()
{    Context context = new Context();    Map<String, String> parms = new HashMap<String, String>();    parms.put("capacity", "5");    parms.put("transactionCapacity", "5");    context.putAll(parms);    Configurables.configure(channel, context);    Transaction transaction = channel.getTransaction();    transaction.begin();    for (int i = 0; i < 5; i++) {        channel.put(EventBuilder.withBody(String.format("test event %d", i).getBytes()));    }    transaction.commit();    transaction.close();    /*     * Verify overflow semantics     */    transaction = channel.getTransaction();    boolean overflowed = false;    try {        transaction.begin();        channel.put(EventBuilder.withBody("overflow event".getBytes()));        transaction.commit();    } catch (ChannelException e) {        overflowed = true;        transaction.rollback();    } finally {        transaction.close();    }    Assert.assertTrue(overflowed);    /*     * Reconfigure capacity down and add another event, shouldn't result in exception     */    parms.put("capacity", "6");    context.putAll(parms);    Configurables.configure(channel, context);    transaction = channel.getTransaction();    transaction.begin();    channel.put(EventBuilder.withBody("extended capacity event".getBytes()));    transaction.commit();    transaction.close();    /*     * Attempt to reconfigure capacity to below current entry count and verify     * it wasn't carried out     */    parms.put("capacity", "2");    parms.put("transactionCapacity", "2");    context.putAll(parms);    Configurables.configure(channel, context);    for (int i = 0; i < 6; i++) {        transaction = channel.getTransaction();        transaction.begin();        Assert.assertNotNull(channel.take());        transaction.commit();        transaction.close();    }}
4984413ea3f7708d842347a30254a7fa39117a1d17206a35dc6646a10e08bb8a
testTransactionPutCapacityOverload
public void testTransactionPutCapacityOverload()
{    Context context = new Context();    Map<String, String> parms = new HashMap<String, String>();    parms.put("capacity", "5");    parms.put("transactionCapacity", "2");    context.putAll(parms);    Configurables.configure(channel, context);    Transaction transaction = channel.getTransaction();    transaction.begin();    channel.put(EventBuilder.withBody("test".getBytes()));    channel.put(EventBuilder.withBody("test".getBytes()));        channel.put(EventBuilder.withBody("test".getBytes()));    Assert.fail();}
82b11185b560386837cc66deb3c275ea81445ac0017c1344c8e8d51f78f4daaf
testCapacityOverload
public void testCapacityOverload()
{    Context context = new Context();    Map<String, String> parms = new HashMap<String, String>();    parms.put("capacity", "5");    parms.put("transactionCapacity", "3");    context.putAll(parms);    Configurables.configure(channel, context);    Transaction transaction = channel.getTransaction();    transaction.begin();    channel.put(EventBuilder.withBody("test".getBytes()));    channel.put(EventBuilder.withBody("test".getBytes()));    channel.put(EventBuilder.withBody("test".getBytes()));    transaction.commit();    transaction.close();    transaction = channel.getTransaction();    transaction.begin();    channel.put(EventBuilder.withBody("test".getBytes()));    channel.put(EventBuilder.withBody("test".getBytes()));    channel.put(EventBuilder.withBody("test".getBytes()));        transaction.commit();    Assert.fail();}
43f65f8e739955878a5f0eaaa4402a0cc4f324bc84d55e6a84fd6d18067ae322
testCapacityBufferEmptyingAfterTakeCommit
public void testCapacityBufferEmptyingAfterTakeCommit()
{    Context context = new Context();    Map<String, String> parms = new HashMap<String, String>();    parms.put("capacity", "3");    parms.put("transactionCapacity", "3");    context.putAll(parms);    Configurables.configure(channel, context);    Transaction tx = channel.getTransaction();    tx.begin();    channel.put(EventBuilder.withBody("test".getBytes()));    channel.put(EventBuilder.withBody("test".getBytes()));    channel.put(EventBuilder.withBody("test".getBytes()));    tx.commit();    tx.close();    tx = channel.getTransaction();    tx.begin();    channel.take();    channel.take();    tx.commit();    tx.close();    tx = channel.getTransaction();    tx.begin();    channel.put(EventBuilder.withBody("test".getBytes()));    channel.put(EventBuilder.withBody("test".getBytes()));    tx.commit();    tx.close();}
8dbd7c25cc10948d1ab590f9810ddec09da282b49acf4cfb869d61227ed68b83
testCapacityBufferEmptyingAfterRollback
public void testCapacityBufferEmptyingAfterRollback()
{    Context context = new Context();    Map<String, String> parms = new HashMap<String, String>();    parms.put("capacity", "3");    parms.put("transactionCapacity", "3");    context.putAll(parms);    Configurables.configure(channel, context);    Transaction tx = channel.getTransaction();    tx.begin();    channel.put(EventBuilder.withBody("test".getBytes()));    channel.put(EventBuilder.withBody("test".getBytes()));    channel.put(EventBuilder.withBody("test".getBytes()));    tx.rollback();    tx.close();    tx = channel.getTransaction();    tx.begin();    channel.put(EventBuilder.withBody("test".getBytes()));    channel.put(EventBuilder.withBody("test".getBytes()));    channel.put(EventBuilder.withBody("test".getBytes()));    tx.commit();    tx.close();}
bc01b622c435743dbd7a4b1e554143babcb16b962b5447258978a1ef3d81f5c5
testByteCapacityOverload
public void testByteCapacityOverload()
{    Context context = new Context();    Map<String, String> parms = new HashMap<String, String>();    parms.put("byteCapacity", "2000");    parms.put("byteCapacityBufferPercentage", "20");    context.putAll(parms);    Configurables.configure(channel, context);    byte[] eventBody = new byte[405];    Transaction transaction = channel.getTransaction();    transaction.begin();    channel.put(EventBuilder.withBody(eventBody));    channel.put(EventBuilder.withBody(eventBody));    channel.put(EventBuilder.withBody(eventBody));    transaction.commit();    transaction.close();    transaction = channel.getTransaction();    transaction.begin();    channel.put(EventBuilder.withBody(eventBody));    channel.put(EventBuilder.withBody(eventBody));        transaction.commit();    Assert.fail();}
c8cd27ab1fe6bf653b7cd60d24c950710a24e009bb5e7fd8867a389678436b89
testByteCapacityAfterRollback
public void testByteCapacityAfterRollback()
{    Context ctx = new Context(ImmutableMap.of("byteCapacity", "1000"));    Configurables.configure(channel, ctx);    Assert.assertEquals(8, channel.getBytesRemainingValue());    Event e = new SimpleEvent();    Transaction t = channel.getTransaction();    t.begin();    channel.put(e);    t.rollback();    Assert.assertEquals(8, channel.getBytesRemainingValue());}
039d397f55da6728bf44fc0cf81d2d7b241be375b17e8adc819c4594dd1cbcd5
testByteCapacityBufferEmptyingAfterTakeCommit
public void testByteCapacityBufferEmptyingAfterTakeCommit()
{    Context context = new Context();    Map<String, String> parms = new HashMap<String, String>();    parms.put("byteCapacity", "2000");    parms.put("byteCapacityBufferPercentage", "20");    context.putAll(parms);    Configurables.configure(channel, context);    byte[] eventBody = new byte[405];    Transaction tx = channel.getTransaction();    tx.begin();    channel.put(EventBuilder.withBody(eventBody));    channel.put(EventBuilder.withBody(eventBody));    channel.put(EventBuilder.withBody(eventBody));    channel.put(EventBuilder.withBody(eventBody));    try {        channel.put(EventBuilder.withBody(eventBody));        throw new RuntimeException("Put was able to overflow byte capacity.");    } catch (ChannelException ce) {        }    tx.commit();    tx.close();    tx = channel.getTransaction();    tx.begin();    channel.take();    channel.take();    tx.commit();    tx.close();    tx = channel.getTransaction();    tx.begin();    channel.put(EventBuilder.withBody(eventBody));    channel.put(EventBuilder.withBody(eventBody));    try {        channel.put(EventBuilder.withBody(eventBody));        throw new RuntimeException("Put was able to overflow byte capacity.");    } catch (ChannelException ce) {        }    tx.commit();    tx.close();}
2f8329c4d654156d66b897a4a6d46dce531103805ec6deb10b96814789202b98
testByteCapacityBufferEmptyingAfterRollback
public void testByteCapacityBufferEmptyingAfterRollback()
{    Context context = new Context();    Map<String, String> parms = new HashMap<String, String>();    parms.put("byteCapacity", "2000");    parms.put("byteCapacityBufferPercentage", "20");    context.putAll(parms);    Configurables.configure(channel, context);    byte[] eventBody = new byte[405];    Transaction tx = channel.getTransaction();    tx.begin();    channel.put(EventBuilder.withBody(eventBody));    channel.put(EventBuilder.withBody(eventBody));    channel.put(EventBuilder.withBody(eventBody));    tx.rollback();    tx.close();    tx = channel.getTransaction();    tx.begin();    channel.put(EventBuilder.withBody(eventBody));    channel.put(EventBuilder.withBody(eventBody));    channel.put(EventBuilder.withBody(eventBody));    tx.commit();    tx.close();}
86103944a51b5e5ffc85ca1173f6eca416aad55ad6c4840f4c2095fdd5b7a711
testByteCapacityBufferChangeConfig
public void testByteCapacityBufferChangeConfig()
{    Context context = new Context();    Map<String, String> parms = new HashMap<String, String>();    parms.put("byteCapacity", "2000");    parms.put("byteCapacityBufferPercentage", "20");    context.putAll(parms);    Configurables.configure(channel, context);    byte[] eventBody = new byte[405];    Transaction tx = channel.getTransaction();    tx.begin();    channel.put(EventBuilder.withBody(eventBody));    tx.commit();    tx.close();    channel.stop();    parms.put("byteCapacity", "1500");    context.putAll(parms);    Configurables.configure(channel, context);    channel.start();    tx = channel.getTransaction();    tx.begin();    channel.put(EventBuilder.withBody(eventBody));    try {        channel.put(EventBuilder.withBody(eventBody));        tx.commit();        Assert.fail();    } catch (ChannelException e) {                tx.rollback();    } finally {        tx.close();    }    channel.stop();    parms.put("byteCapacity", "250");    parms.put("byteCapacityBufferPercentage", "20");    context.putAll(parms);    Configurables.configure(channel, context);    channel.start();    tx = channel.getTransaction();    tx.begin();    channel.put(EventBuilder.withBody(eventBody));    tx.commit();    tx.close();    channel.stop();    parms.put("byteCapacity", "300");    context.putAll(parms);    Configurables.configure(channel, context);    channel.start();    tx = channel.getTransaction();    tx.begin();    try {        for (int i = 0; i < 2; i++) {            channel.put(EventBuilder.withBody(eventBody));        }        tx.commit();        Assert.fail();    } catch (ChannelException e) {                tx.rollback();    } finally {        tx.close();    }    channel.stop();    parms.put("byteCapacity", "3300");    context.putAll(parms);    Configurables.configure(channel, context);    channel.start();    tx = channel.getTransaction();    tx.begin();    try {        for (int i = 0; i < 15; i++) {            channel.put(EventBuilder.withBody(eventBody));        }        tx.commit();        Assert.fail();    } catch (ChannelException e) {                tx.rollback();    } finally {        tx.close();    }    channel.stop();    parms.put("byteCapacity", "4000");    context.putAll(parms);    Configurables.configure(channel, context);    channel.start();    tx = channel.getTransaction();    tx.begin();    try {        for (int i = 0; i < 25; i++) {            channel.put(EventBuilder.withBody(eventBody));        }        tx.commit();        Assert.fail();    } catch (ChannelException e) {                tx.rollback();    } finally {        tx.close();    }    channel.stop();}
439f0946099d1306188f1e8618d32a3c13d00b0518491e687ffce936b57c4826
testNullEmptyEvent
public void testNullEmptyEvent()
{    Context context = new Context();    Map<String, String> parms = new HashMap<String, String>();    parms.put("byteCapacity", "2000");    parms.put("byteCapacityBufferPercentage", "20");    context.putAll(parms);    Configurables.configure(channel, context);    Transaction tx = channel.getTransaction();    tx.begin();        channel.put(EventBuilder.withBody(null));    tx.commit();    tx.close();    tx = channel.getTransaction();    tx.begin();    channel.put(EventBuilder.withBody(new byte[0]));    tx.commit();    tx.close();}
a230bbeaf3ff1106ba2f22e014e75369ee8b73941345217e8437fed823d5463d
testNegativeCapacities
public void testNegativeCapacities()
{    Context context = new Context();    Map<String, String> parms = new HashMap<String, String>();    parms.put("capacity", "-3");    parms.put("transactionCapacity", "-1");    context.putAll(parms);    Configurables.configure(channel, context);    Assert.assertTrue(field("queue").ofType(LinkedBlockingDeque.class).in(channel).get().remainingCapacity() > 0);    Assert.assertTrue(field("transCapacity").ofType(Integer.class).in(channel).get() > 0);}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{}
e19374af57a4950c57c617f68e8cc5cacfeeb8fe9f6335d1014e0f06a02d87a5
testTransactionConcurrency
public void testTransactionConcurrency() throws InterruptedException
{    final Channel channel = new MemoryChannel();    barrier = new CyclicBarrier(2);    Configurables.configure(channel, new Context());    Thread t1 = new Thread(new Runnable() {        @Override        public void run() {            Transaction tx = channel.getTransaction();            tx.begin();            channel.put(EventBuilder.withBody("first event".getBytes()));            try {                barrier.await();                barrier.await();                tx.rollback();                barrier.await();                tx.close();                                barrier.await();            } catch (InterruptedException e) {                Assert.fail();            } catch (BrokenBarrierException e) {                Assert.fail();            }        }    });    Thread t2 = new Thread(new Runnable() {        @Override        public void run() {            Transaction tx = channel.getTransaction();            try {                barrier.await();                tx.begin();                channel.put(EventBuilder.withBody("second event".getBytes()));                barrier.await();                barrier.await();                tx.commit();                tx.close();                                barrier.await();            } catch (InterruptedException e) {                Assert.fail();            } catch (BrokenBarrierException e) {                Assert.fail();            }        }    });    t1.start();    t2.start();    t1.join(1000);    if (t1.isAlive()) {        Assert.fail("Thread1 failed to finish");        t1.interrupt();    }    t2.join(1000);    if (t2.isAlive()) {        Assert.fail("Thread2 failed to finish");        t2.interrupt();    }    Transaction tx = channel.getTransaction();    tx.begin();    Event e = channel.take();    Assert.assertEquals("second event", new String(e.getBody()));    Assert.assertNull(channel.take());    tx.commit();    tx.close();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    Transaction tx = channel.getTransaction();    tx.begin();    channel.put(EventBuilder.withBody("first event".getBytes()));    try {        barrier.await();        barrier.await();        tx.rollback();        barrier.await();        tx.close();                barrier.await();    } catch (InterruptedException e) {        Assert.fail();    } catch (BrokenBarrierException e) {        Assert.fail();    }}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    Transaction tx = channel.getTransaction();    try {        barrier.await();        tx.begin();        channel.put(EventBuilder.withBody("second event".getBytes()));        barrier.await();        barrier.await();        tx.commit();        tx.close();                barrier.await();    } catch (InterruptedException e) {        Assert.fail();    } catch (BrokenBarrierException e) {        Assert.fail();    }}
35bb17773f5d165da4ad2a8d35502e2162821247ac329cceca69349887c438db
testManyThreads
public void testManyThreads() throws InterruptedException
{    final Channel channel = new MemoryChannel();    Context context = new Context();    context.put("keep-alive", "1");        context.put("capacity", "5000");                context.put("transactionCapacity", "5000");    Configurables.configure(channel, context);    final ConcurrentHashMap<String, AtomicInteger> committedPuts = new ConcurrentHashMap<String, AtomicInteger>();    final int threadCount = 100;    final CountDownLatch startGate = new CountDownLatch(1);    final CountDownLatch endGate = new CountDownLatch(threadCount);    for (int i = 0; i < threadCount; i++) {        Thread t = new Thread() {            @Override            public void run() {                Long tid = Thread.currentThread().getId();                String strtid = tid.toString();                Random rng = new Random(tid);                try {                    startGate.await();                } catch (InterruptedException e1) {                    Thread.currentThread().interrupt();                }                for (int j = 0; j < 10; j++) {                    int events = rng.nextInt(5) + 1;                    Transaction tx = channel.getTransaction();                    tx.begin();                    for (int k = 0; k < events; k++) {                        channel.put(EventBuilder.withBody(strtid.getBytes()));                    }                    if (rng.nextBoolean()) {                        tx.commit();                        AtomicInteger tcount = committedPuts.get(strtid);                        if (tcount == null) {                            committedPuts.put(strtid, new AtomicInteger(events));                        } else {                            tcount.addAndGet(events);                        }                    } else {                        tx.rollback();                    }                    tx.close();                }                endGate.countDown();            }        };        t.start();    }    startGate.countDown();    endGate.await();    if (committedPuts.isEmpty()) {        Assert.fail();    }        Transaction tx = channel.getTransaction();    tx.begin();    Event e;    while ((e = channel.take()) != null) {        String index = new String(e.getBody());        AtomicInteger remain = committedPuts.get(index);        int post = remain.decrementAndGet();        if (post == 0) {            committedPuts.remove(index);        }    }    tx.commit();    tx.close();    if (!committedPuts.isEmpty()) {        Assert.fail();    }}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    Long tid = Thread.currentThread().getId();    String strtid = tid.toString();    Random rng = new Random(tid);    try {        startGate.await();    } catch (InterruptedException e1) {        Thread.currentThread().interrupt();    }    for (int j = 0; j < 10; j++) {        int events = rng.nextInt(5) + 1;        Transaction tx = channel.getTransaction();        tx.begin();        for (int k = 0; k < events; k++) {            channel.put(EventBuilder.withBody(strtid.getBytes()));        }        if (rng.nextBoolean()) {            tx.commit();            AtomicInteger tcount = committedPuts.get(strtid);            if (tcount == null) {                committedPuts.put(strtid, new AtomicInteger(events));            } else {                tcount.addAndGet(events);            }        } else {            tx.rollback();        }        tx.close();    }    endGate.countDown();}
190bb14b77ba1dae745875f0bde1ecd96399344d77a558322cb277bbd7284b57
testConcurrentSinksAndSources
public void testConcurrentSinksAndSources() throws InterruptedException
{    final Channel channel = new MemoryChannel();    Context context = new Context();    context.put("keep-alive", "1");        context.put("capacity", "100");                context.put("transactionCapacity", "100");    Configurables.configure(channel, context);    final ConcurrentHashMap<String, AtomicInteger> committedPuts = new ConcurrentHashMap<String, AtomicInteger>();    final ConcurrentHashMap<String, AtomicInteger> committedTakes = new ConcurrentHashMap<String, AtomicInteger>();    final int threadCount = 100;    final CountDownLatch startGate = new CountDownLatch(1);    final CountDownLatch endGate = new CountDownLatch(threadCount);        for (int i = 0; i < threadCount / 2; i++) {        Thread t = new Thread() {            @Override            public void run() {                Long tid = Thread.currentThread().getId();                String strtid = tid.toString();                Random rng = new Random(tid);                try {                    startGate.await();                } catch (InterruptedException e1) {                    Thread.currentThread().interrupt();                }                for (int j = 0; j < 10; j++) {                    int events = rng.nextInt(5) + 1;                    Transaction tx = channel.getTransaction();                    tx.begin();                    for (int k = 0; k < events; k++) {                        channel.put(EventBuilder.withBody(strtid.getBytes()));                    }                    if (rng.nextBoolean()) {                        try {                            tx.commit();                            AtomicInteger tcount = committedPuts.get(strtid);                            if (tcount == null) {                                committedPuts.put(strtid, new AtomicInteger(events));                            } else {                                tcount.addAndGet(events);                            }                        } catch (ChannelException e) {                            System.out.print("puts commit failed");                            tx.rollback();                        }                    } else {                        tx.rollback();                    }                    tx.close();                }                endGate.countDown();            }        };                t.start();        final Integer takeMapLock = 0;        t = new Thread() {            @Override            public void run() {                Random rng = new Random(Thread.currentThread().getId());                try {                    startGate.await();                } catch (InterruptedException e1) {                    Thread.currentThread().interrupt();                }                for (int j = 0; j < 10; j++) {                    int events = rng.nextInt(5) + 1;                    Transaction tx = channel.getTransaction();                    tx.begin();                    Event[] taken = new Event[events];                    int k;                    for (k = 0; k < events; k++) {                        taken[k] = channel.take();                        if (taken[k] == null)                            break;                    }                    if (rng.nextBoolean()) {                        try {                            tx.commit();                            for (Event e : taken) {                                if (e == null)                                    break;                                String index = new String(e.getBody());                                synchronized (takeMapLock) {                                    AtomicInteger remain = committedTakes.get(index);                                    if (remain == null) {                                        committedTakes.put(index, new AtomicInteger(1));                                    } else {                                        remain.incrementAndGet();                                    }                                }                            }                        } catch (ChannelException e) {                            System.out.print("takes commit failed");                            tx.rollback();                        }                    } else {                        tx.rollback();                    }                    tx.close();                }                endGate.countDown();            }        };                t.start();    }    startGate.countDown();    if (!endGate.await(20, TimeUnit.SECONDS)) {        Assert.fail("Not all threads ended succesfully");    }        Transaction tx = channel.getTransaction();    tx.begin();    Event e;        while ((e = channel.take()) != null) {        String index = new String(e.getBody());        AtomicInteger remain = committedPuts.get(index);        int post = remain.decrementAndGet();        if (post == 0) {            committedPuts.remove(index);        }    }    tx.commit();    tx.close();        for (Entry<String, AtomicInteger> takes : committedTakes.entrySet()) {        AtomicInteger count = committedPuts.get(takes.getKey());        if (count == null) {            Assert.fail("Putted data doesn't exist");        }        if (count.get() != takes.getValue().get()) {            Assert.fail(String.format("Mismatched put and take counts expected %d had %d", count.get(), takes.getValue().get()));        }        committedPuts.remove(takes.getKey());    }    if (!committedPuts.isEmpty()) {        Assert.fail("Puts still has entries remaining");    }}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    Long tid = Thread.currentThread().getId();    String strtid = tid.toString();    Random rng = new Random(tid);    try {        startGate.await();    } catch (InterruptedException e1) {        Thread.currentThread().interrupt();    }    for (int j = 0; j < 10; j++) {        int events = rng.nextInt(5) + 1;        Transaction tx = channel.getTransaction();        tx.begin();        for (int k = 0; k < events; k++) {            channel.put(EventBuilder.withBody(strtid.getBytes()));        }        if (rng.nextBoolean()) {            try {                tx.commit();                AtomicInteger tcount = committedPuts.get(strtid);                if (tcount == null) {                    committedPuts.put(strtid, new AtomicInteger(events));                } else {                    tcount.addAndGet(events);                }            } catch (ChannelException e) {                System.out.print("puts commit failed");                tx.rollback();            }        } else {            tx.rollback();        }        tx.close();    }    endGate.countDown();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    Random rng = new Random(Thread.currentThread().getId());    try {        startGate.await();    } catch (InterruptedException e1) {        Thread.currentThread().interrupt();    }    for (int j = 0; j < 10; j++) {        int events = rng.nextInt(5) + 1;        Transaction tx = channel.getTransaction();        tx.begin();        Event[] taken = new Event[events];        int k;        for (k = 0; k < events; k++) {            taken[k] = channel.take();            if (taken[k] == null)                break;        }        if (rng.nextBoolean()) {            try {                tx.commit();                for (Event e : taken) {                    if (e == null)                        break;                    String index = new String(e.getBody());                    synchronized (takeMapLock) {                        AtomicInteger remain = committedTakes.get(index);                        if (remain == null) {                            committedTakes.put(index, new AtomicInteger(1));                        } else {                            remain.incrementAndGet();                        }                    }                }            } catch (ChannelException e) {                System.out.print("takes commit failed");                tx.rollback();            }        } else {            tx.rollback();        }        tx.close();    }    endGate.countDown();}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    channel = new MemoryChannel();}
254b92225d966bfe51c69cd02f2dd1121dae8714ce58bde97ebb640909269d0d
testCommit
public void testCommit() throws InterruptedException, EventDeliveryException
{    Event event;    Event event2;    Context context = new Context();    int putCounter = 0;    context.put("keep-alive", "1");    context.put("capacity", "100");    context.put("transactionCapacity", "50");    Configurables.configure(channel, context);    Transaction transaction = channel.getTransaction();    Assert.assertNotNull(transaction);    transaction.begin();    for (putCounter = 0; putCounter < 10; putCounter++) {        event = EventBuilder.withBody(("test event" + putCounter).getBytes());        channel.put(event);    }    transaction.commit();    transaction.close();    transaction = channel.getTransaction();    Assert.assertNotNull(transaction);    transaction = channel.getTransaction();    transaction.begin();    for (int i = 0; i < 10; i++) {        event2 = channel.take();        Assert.assertNotNull("lost an event", event2);        Assert.assertArrayEquals(event2.getBody(), ("test event" + i).getBytes());        }    event2 = channel.take();    Assert.assertNull("extra event found", event2);    transaction.commit();    transaction.close();}
a6c83db2f6bdd0f25c095e50b48ea67f7ad7cfbc8a69f36af32fa8517a71e7cf
testRollBack
public void testRollBack() throws InterruptedException, EventDeliveryException
{    Event event;    Event event2;    Context context = new Context();    int putCounter = 0;    context.put("keep-alive", "1");    Configurables.configure(channel, context);    Transaction transaction = channel.getTransaction();    Assert.assertNotNull(transaction);        transaction.begin();    for (putCounter = 0; putCounter < 10; putCounter++) {        event = EventBuilder.withBody(("test event" + putCounter).getBytes());        channel.put(event);    }    transaction.rollback();    transaction.close();        transaction = channel.getTransaction();    transaction.begin();    event2 = channel.take();    Assert.assertNull("extra event found", event2);    transaction.commit();    transaction.close();        transaction = channel.getTransaction();    transaction.begin();    for (putCounter = 0; putCounter < 10; putCounter++) {        event = EventBuilder.withBody(("test event" + putCounter).getBytes());        channel.put(event);    }    transaction.commit();    transaction.close();    transaction = channel.getTransaction();    Assert.assertNotNull(transaction);        transaction.begin();    for (int i = 0; i < 10; i++) {        event2 = channel.take();        Assert.assertNotNull("lost an event", event2);        Assert.assertArrayEquals(event2.getBody(), ("test event" + i).getBytes());    }    event2 = channel.take();    Assert.assertNull("extra event found", event2);    transaction.rollback();    transaction.close();        transaction = channel.getTransaction();    transaction.begin();    for (int i = 0; i < 10; i++) {        event2 = channel.take();        Assert.assertNotNull("lost an event", event2);        Assert.assertArrayEquals(event2.getBody(), ("test event" + i).getBytes());    }    event2 = channel.take();    Assert.assertNull("extra event found", event2);    transaction.rollback();    transaction.close();}
3b0ced28003027efc71d73807d30b3a18bd75c59c8d88349beb6f6aa3b842786
testReEntTxn
public void testReEntTxn() throws InterruptedException, EventDeliveryException
{    Event event;    Event event2;    Context context = new Context();    int putCounter = 0;    context.put("keep-alive", "1");    Configurables.configure(channel, context);    Transaction transaction = channel.getTransaction();    Assert.assertNotNull(transaction);        transaction.begin();    for (putCounter = 0; putCounter < 10; putCounter++) {                transaction.begin();        event = EventBuilder.withBody(("test event" + putCounter).getBytes());        channel.put(event);                transaction.commit();    }    transaction.commit();    transaction.close();    transaction = channel.getTransaction();    Assert.assertNotNull(transaction);    transaction.begin();    for (int i = 0; i < 10; i++) {        event2 = channel.take();        Assert.assertNotNull("lost an event", event2);        Assert.assertArrayEquals(event2.getBody(), ("test event" + i).getBytes());        }    event2 = channel.take();    Assert.assertNull("extra event found", event2);    transaction.commit();    transaction.close();}
6b54398317d42effecd89be011f1c838fbb1c6cfc0a59ee16b779c8f31f273ba
testReEntTxnRollBack
public void testReEntTxnRollBack() throws InterruptedException, EventDeliveryException
{    Event event;    Event event2;    Context context = new Context();    int putCounter = 0;    context.put("keep-alive", "1");    Configurables.configure(channel, context);    Transaction transaction = channel.getTransaction();    Assert.assertNotNull(transaction);        transaction.begin();    for (putCounter = 0; putCounter < 10; putCounter++) {        event = EventBuilder.withBody(("test event" + putCounter).getBytes());        channel.put(event);    }    transaction.rollback();    transaction.close();        transaction = channel.getTransaction();    transaction.begin();    event2 = channel.take();    Assert.assertNull("extra event found", event2);    transaction.commit();    transaction.close();        transaction = channel.getTransaction();    transaction.begin();    for (putCounter = 0; putCounter < 10; putCounter++) {        event = EventBuilder.withBody(("test event" + putCounter).getBytes());        channel.put(event);    }    transaction.commit();    transaction.close();    transaction = channel.getTransaction();    Assert.assertNotNull(transaction);        transaction.begin();    for (int i = 0; i < 10; i++) {                transaction.begin();        event2 = channel.take();        Assert.assertNotNull("lost an event", event2);        Assert.assertArrayEquals(event2.getBody(), ("test event" + i).getBytes());                transaction.commit();    }    event2 = channel.take();    Assert.assertNull("extra event found", event2);    transaction.rollback();    transaction.close();        transaction = channel.getTransaction();    transaction.begin();    for (int i = 0; i < 10; i++) {        event2 = channel.take();        Assert.assertNotNull("lost an event", event2);        Assert.assertArrayEquals(event2.getBody(), ("test event" + i).getBytes());    }    event2 = channel.take();    Assert.assertNull("extra event found", event2);    transaction.rollback();    transaction.close();}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    channels.clear();    channels.add(MockChannel.createMockChannel("ch1"));    channels.add(MockChannel.createMockChannel("ch2"));    channels.add(MockChannel.createMockChannel("ch3"));    config.put("type", "multiplexing");    config.put("header", "myheader");    config.put("optional.foo", "ch2 ch3");    config.put("optional.xyz", "ch1 ch3");    config.put("optional.zebra", "ch1 ch2");}
c8a96497da8ff87ba7f02db0d6e4da5706b6d0d3e7b22592c6e15574bd7c480c
testSelection
public void testSelection() throws Exception
{    config.put("mapping.foo", "ch1 ch2");    config.put("mapping.bar", "ch2 ch3");    config.put("mapping.xyz", "ch1 ch2 ch3");    config.put("default", "ch1 ch3");    selector = ChannelSelectorFactory.create(channels, config);    Assert.assertTrue(selector instanceof MultiplexingChannelSelector);    Event event1 = new MockEvent();    Map<String, String> header1 = new HashMap<String, String>();        header1.put("myheader", "foo");    event1.setHeaders(header1);    List<Channel> reqCh1 = selector.getRequiredChannels(event1);    Assert.assertEquals(2, reqCh1.size());    Assert.assertTrue(reqCh1.get(0).getName().equals("ch1"));    Assert.assertTrue(reqCh1.get(1).getName().equals("ch2"));    List<Channel> optCh1 = selector.getOptionalChannels(event1);    Assert.assertTrue(optCh1.size() == 1);        Assert.assertTrue(optCh1.get(0).getName().equals("ch3"));    Event event2 = new MockEvent();    Map<String, String> header2 = new HashMap<String, String>();        header2.put("myheader", "bar");    event2.setHeaders(header2);    List<Channel> reqCh2 = selector.getRequiredChannels(event2);    Assert.assertEquals(2, reqCh2.size());    Assert.assertTrue(reqCh2.get(0).getName().equals("ch2"));    Assert.assertTrue(reqCh2.get(1).getName().equals("ch3"));    List<Channel> optCh2 = selector.getOptionalChannels(event2);    Assert.assertTrue(optCh2.isEmpty());    Event event3 = new MockEvent();    Map<String, String> header3 = new HashMap<String, String>();        header3.put("myheader", "xyz");    event3.setHeaders(header3);    List<Channel> reqCh3 = selector.getRequiredChannels(event3);    Assert.assertEquals(3, reqCh3.size());    Assert.assertTrue(reqCh3.get(0).getName().equals("ch1"));    Assert.assertTrue(reqCh3.get(1).getName().equals("ch2"));    Assert.assertTrue(reqCh3.get(2).getName().equals("ch3"));    List<Channel> optCh3 = selector.getOptionalChannels(event3);        Assert.assertTrue(optCh3.size() == 0);}
0cae8c298c82af0272ff6cb49995d6848bb3d0ab932d95cab55ac261900e06de
testNoSelection
public void testNoSelection() throws Exception
{    config.put("mapping.foo", "ch1 ch2");    config.put("mapping.bar", "ch2 ch3");    config.put("mapping.xyz", "ch1 ch2 ch3");    config.put("default", "ch1 ch3");    selector = ChannelSelectorFactory.create(channels, config);    Assert.assertTrue(selector instanceof MultiplexingChannelSelector);    Event noHeaderEvent = new MockEvent();    List<Channel> reqCh1 = selector.getRequiredChannels(noHeaderEvent);    List<Channel> optCh1 = selector.getOptionalChannels(noHeaderEvent);    Assert.assertEquals(2, reqCh1.size());    Assert.assertTrue(reqCh1.get(0).getName().equals("ch1"));    Assert.assertTrue(reqCh1.get(1).getName().equals("ch3"));    Assert.assertTrue(optCh1.isEmpty());    Map<String, String> header2 = new HashMap<String, String>();    header2.put("someheader", "foo");    Event invalidHeaderEvent = new MockEvent();    invalidHeaderEvent.setHeaders(header2);    List<Channel> reqCh2 = selector.getRequiredChannels(invalidHeaderEvent);    List<Channel> optCh2 = selector.getOptionalChannels(invalidHeaderEvent);    Assert.assertEquals(2, reqCh2.size());    Assert.assertTrue(reqCh2.get(0).getName().equals("ch1"));    Assert.assertTrue(reqCh2.get(1).getName().equals("ch3"));    Assert.assertTrue(optCh2.isEmpty());    Map<String, String> header3 = new HashMap<String, String>();    header3.put("myheader", "bar1");    Event unmatchedHeaderEvent = new MockEvent();    unmatchedHeaderEvent.setHeaders(header3);    List<Channel> reqCh3 = selector.getRequiredChannels(unmatchedHeaderEvent);    List<Channel> optCh3 = selector.getOptionalChannels(unmatchedHeaderEvent);    Assert.assertEquals(2, reqCh3.size());    Assert.assertTrue(reqCh3.get(0).getName().equals("ch1"));    Assert.assertTrue(reqCh3.get(1).getName().equals("ch3"));    Assert.assertTrue(optCh3.isEmpty());    Map<String, String> header4 = new HashMap<String, String>();    header4.put("myheader", "zebra");    Event zebraEvent = new MockEvent();    zebraEvent.setHeaders(header4);    List<Channel> reqCh4 = selector.getRequiredChannels(zebraEvent);    List<Channel> optCh4 = selector.getOptionalChannels(zebraEvent);    Assert.assertEquals(2, reqCh4.size());    Assert.assertTrue(reqCh4.get(0).getName().equals("ch1"));    Assert.assertTrue(reqCh4.get(1).getName().equals("ch3"));        Assert.assertTrue(optCh4.size() == 1);    Assert.assertTrue(optCh4.get(0).getName().equals("ch2"));    List<Channel> allChannels = selector.getAllChannels();    Assert.assertTrue(allChannels.size() == 3);    Assert.assertTrue(allChannels.get(0).getName().equals("ch1"));    Assert.assertTrue(allChannels.get(1).getName().equals("ch2"));    Assert.assertTrue(allChannels.get(2).getName().equals("ch3"));}
688b8baad1d603115829922c0a0bc878749bcc9c42ff59bdbe0cde6816774fee
testNoDefault
public void testNoDefault()
{    config.put("mapping.foo", "ch1 ch2");    config.put("mapping.bar", "ch2 ch3");    config.put("mapping.xyz", "ch1 ch2 ch3");    config.put("mapping.zebra", "ch2");    config.put("optional.zebra", "ch1 ch3");    selector = ChannelSelectorFactory.create(channels, config);    Assert.assertTrue(selector instanceof MultiplexingChannelSelector);    Event event1 = new MockEvent();    Map<String, String> header1 = new HashMap<String, String>();        header1.put("myheader", "foo");    event1.setHeaders(header1);    List<Channel> reqCh1 = selector.getRequiredChannels(event1);    Assert.assertEquals(2, reqCh1.size());    Assert.assertEquals("ch1", reqCh1.get(0).getName());    Assert.assertEquals("ch2", reqCh1.get(1).getName());    List<Channel> optCh1 = selector.getOptionalChannels(event1);    Assert.assertTrue(optCh1.size() == 1);        Assert.assertEquals("ch3", optCh1.get(0).getName());    Event event2 = new MockEvent();    Map<String, String> header2 = new HashMap<String, String>();        header2.put("myheader", "bar");    event2.setHeaders(header2);    List<Channel> reqCh2 = selector.getRequiredChannels(event2);    Assert.assertEquals(2, reqCh2.size());    Assert.assertEquals("ch2", reqCh2.get(0).getName());    Assert.assertEquals("ch3", reqCh2.get(1).getName());    List<Channel> optCh2 = selector.getOptionalChannels(event2);    Assert.assertTrue(optCh2.isEmpty());    Event event3 = new MockEvent();    Map<String, String> header3 = new HashMap<String, String>();        header3.put("myheader", "xyz");    event3.setHeaders(header3);    List<Channel> reqCh3 = selector.getRequiredChannels(event3);    Assert.assertEquals(3, reqCh3.size());    Assert.assertEquals("ch1", reqCh3.get(0).getName());    Assert.assertEquals("ch2", reqCh3.get(1).getName());    Assert.assertEquals("ch3", reqCh3.get(2).getName());    List<Channel> optCh3 = selector.getOptionalChannels(event3);        Assert.assertTrue(optCh3.isEmpty());    Event event4 = new MockEvent();    Map<String, String> header4 = new HashMap<String, String>();    header4.put("myheader", "zebra");    event4.setHeaders(header4);    List<Channel> reqCh4 = selector.getRequiredChannels(event4);    Assert.assertEquals(1, reqCh4.size());    Assert.assertEquals("ch2", reqCh4.get(0).getName());    List<Channel> optCh4 = selector.getOptionalChannels(event4);    Assert.assertEquals(2, optCh4.size());    Assert.assertEquals("ch1", optCh4.get(0).getName());    Assert.assertEquals("ch3", optCh4.get(1).getName());}
05e4156a237e499ebf495fd1cc629c7ff10ba9ae715c062385104d9443b06359
testNoMandatory
public void testNoMandatory()
{    config.put("default", "ch3");    config.put("optional.foo", "ch1 ch2");    config.put("optional.zebra", "ch2 ch3");    selector = ChannelSelectorFactory.create(channels, config);    Assert.assertTrue(selector instanceof MultiplexingChannelSelector);    Event event1 = new MockEvent();    Map<String, String> header1 = new HashMap<String, String>();        header1.put("myheader", "foo");    event1.setHeaders(header1);    List<Channel> reqCh1 = selector.getRequiredChannels(event1);    Assert.assertEquals(1, reqCh1.size());    Assert.assertEquals("ch3", reqCh1.get(0).getName());    List<Channel> optCh1 = selector.getOptionalChannels(event1);    Assert.assertEquals(2, optCh1.size());        Assert.assertEquals("ch1", optCh1.get(0).getName());    Assert.assertEquals("ch2", optCh1.get(1).getName());    Event event4 = new MockEvent();    Map<String, String> header4 = new HashMap<String, String>();    header4.put("myheader", "zebra");    event4.setHeaders(header4);    List<Channel> reqCh4 = selector.getRequiredChannels(event4);    Assert.assertEquals(1, reqCh4.size());    Assert.assertTrue(reqCh4.get(0).getName().equals("ch3"));    List<Channel> optCh4 = selector.getOptionalChannels(event4);            Assert.assertEquals(1, optCh4.size());    Assert.assertEquals("ch2", optCh4.get(0).getName());}
72839c82fc7a62497acf4f504b894fd6bce71dbe85653da776147af795db09c1
testOnlyOptional
public void testOnlyOptional()
{    config.put("optional.foo", "ch1 ch2");    config.put("optional.zebra", "ch2 ch3");    selector = ChannelSelectorFactory.create(channels, config);    Assert.assertTrue(selector instanceof MultiplexingChannelSelector);    Event event1 = new MockEvent();    Map<String, String> header1 = new HashMap<String, String>();        header1.put("myheader", "foo");    event1.setHeaders(header1);    List<Channel> reqCh1 = selector.getRequiredChannels(event1);    Assert.assertTrue(reqCh1.isEmpty());    List<Channel> optCh1 = selector.getOptionalChannels(event1);    Assert.assertEquals(2, optCh1.size());        Event event4 = new MockEvent();    Map<String, String> header4 = new HashMap<String, String>();    header4.put("myheader", "zebra");    event4.setHeaders(header4);    List<Channel> reqCh4 = selector.getRequiredChannels(event4);    Assert.assertTrue(reqCh4.isEmpty());    List<Channel> optCh4 = selector.getOptionalChannels(event4);    Assert.assertEquals(2, optCh4.size());    Assert.assertEquals("ch2", optCh4.get(0).getName());    Assert.assertEquals("ch3", optCh4.get(1).getName());}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    channels.clear();    channels.add(MockChannel.createMockChannel("ch1"));    channels.add(MockChannel.createMockChannel("ch2"));    channels.add(MockChannel.createMockChannel("ch3"));    channels.add(MockChannel.createMockChannel("ch4"));    selector = ChannelSelectorFactory.create(channels, new HashMap<String, String>());}
aad638dceaf03ff419d71ff98d5f0235c1d4ac37059409902e05e6ef25f6fb76
testReplicatingSelector
public void testReplicatingSelector() throws Exception
{    selector.configure(new Context());    List<Channel> channels = selector.getRequiredChannels(new MockEvent());    Assert.assertNotNull(channels);    Assert.assertEquals(4, channels.size());    Assert.assertEquals("ch1", channels.get(0).getName());    Assert.assertEquals("ch2", channels.get(1).getName());    Assert.assertEquals("ch3", channels.get(2).getName());    Assert.assertEquals("ch4", channels.get(3).getName());    List<Channel> optCh = selector.getOptionalChannels(new MockEvent());    Assert.assertEquals(0, optCh.size());}
70dccaabac257fd56d2926ba22612b718bb1e46609fa9eb037d5550746d270f9
testOptionalChannels
public void testOptionalChannels() throws Exception
{    Context context = new Context();    context.put(ReplicatingChannelSelector.CONFIG_OPTIONAL, "ch1");    Configurables.configure(selector, context);    List<Channel> channels = selector.getRequiredChannels(new MockEvent());    Assert.assertNotNull(channels);    Assert.assertEquals(3, channels.size());    Assert.assertEquals("ch2", channels.get(0).getName());    Assert.assertEquals("ch3", channels.get(1).getName());    Assert.assertEquals("ch4", channels.get(2).getName());    List<Channel> optCh = selector.getOptionalChannels(new MockEvent());    Assert.assertEquals(1, optCh.size());    Assert.assertEquals("ch1", optCh.get(0).getName());}
583d5fca95fc33118f96c8c292c74c13093b566d7d50a34d16e65adf0450e8de
testMultipleOptionalChannels
public void testMultipleOptionalChannels() throws Exception
{    Context context = new Context();    context.put(ReplicatingChannelSelector.CONFIG_OPTIONAL, "ch1 ch4");    Configurables.configure(selector, context);    List<Channel> channels = selector.getRequiredChannels(new MockEvent());    Assert.assertNotNull(channels);    Assert.assertEquals(2, channels.size());    Assert.assertEquals("ch2", channels.get(0).getName());    Assert.assertEquals("ch3", channels.get(1).getName());    List<Channel> optCh = selector.getOptionalChannels(new MockEvent());    Assert.assertEquals(2, optCh.size());    Assert.assertEquals("ch1", optCh.get(0).getName());    Assert.assertEquals("ch4", optCh.get(1).getName());}
ceadf348f43231711c80821a04f65680f640276f1ec51fe1fa9616db7c8d7116
testMultipleOptionalChannelsSameChannelTwice
public void testMultipleOptionalChannelsSameChannelTwice() throws Exception
{    Context context = new Context();    context.put(ReplicatingChannelSelector.CONFIG_OPTIONAL, "ch1 ch4 ch1");    Configurables.configure(selector, context);    List<Channel> channels = selector.getRequiredChannels(new MockEvent());    Assert.assertNotNull(channels);    Assert.assertEquals(2, channels.size());    Assert.assertEquals("ch2", channels.get(0).getName());    Assert.assertEquals("ch3", channels.get(1).getName());    List<Channel> optCh = selector.getOptionalChannels(new MockEvent());    Assert.assertEquals(2, optCh.size());    Assert.assertEquals("ch1", optCh.get(0).getName());    Assert.assertEquals("ch4", optCh.get(1).getName());}
a137d67cbf4a7af20aa93177e840bb9f03d5c275b44a5cc3e10dbc09459dad4d
before
public void before()
{    tmpDir = Files.createTempDir();}
e9923bdda539e76e2a1b0f9413f75194af84363b024fcb88195a34593794c316
after
public void after()
{    for (File f : tmpDir.listFiles()) {        f.delete();    }    tmpDir.delete();}
f816027e12229939db2fa148168a191b3d6c11a7e8ee37c17ca6dde99c0d9318
testSimpleRead
public void testSimpleRead() throws IOException
{    File f1 = new File(tmpDir.getAbsolutePath() + "/file1");    Files.write("file1line1\nfile1line2\nfile1line3\nfile1line4\n" + "file1line5\nfile1line6\nfile1line7\nfile1line8\n", f1, Charsets.UTF_8);    SimpleTextLineEventReader reader = new SimpleTextLineEventReader(new FileReader(f1));    assertEquals("file1line1", bodyAsString(reader.readEvent()));    assertEquals("file1line2", bodyAsString(reader.readEvent()));    assertEquals("file1line3", bodyAsString(reader.readEvent()));    assertEquals("file1line4", bodyAsString(reader.readEvent()));    assertEquals("file1line5", bodyAsString(reader.readEvent()));    assertEquals("file1line6", bodyAsString(reader.readEvent()));    assertEquals("file1line7", bodyAsString(reader.readEvent()));    assertEquals("file1line8", bodyAsString(reader.readEvent()));    assertEquals(null, reader.readEvent());}
baf4d0b9d800d2d054400489df37be1ba4497fa5adf87dce3fd4407db7de36f0
testBatchedReadsWithinAFile
public void testBatchedReadsWithinAFile() throws IOException
{    File f1 = new File(tmpDir.getAbsolutePath() + "/file1");    Files.write("file1line1\nfile1line2\nfile1line3\nfile1line4\n" + "file1line5\nfile1line6\nfile1line7\nfile1line8\n", f1, Charsets.UTF_8);    SimpleTextLineEventReader reader = new SimpleTextLineEventReader(new FileReader(f1));    List<String> out = bodiesAsStrings(reader.readEvents(5));        assertEquals(5, out.size());    assertTrue(out.contains("file1line1"));    assertTrue(out.contains("file1line2"));    assertTrue(out.contains("file1line3"));    assertTrue(out.contains("file1line4"));    assertTrue(out.contains("file1line5"));}
4025eea9f3b21b0461b238c9007c9d249848601aa521b2a46afffa2010284bf3
testBatchedReadsAtFileBoundary
public void testBatchedReadsAtFileBoundary() throws IOException
{    File f1 = new File(tmpDir.getAbsolutePath() + "/file1");    Files.write("file1line1\nfile1line2\nfile1line3\nfile1line4\n" + "file1line5\nfile1line6\nfile1line7\nfile1line8\n", f1, Charsets.UTF_8);    SimpleTextLineEventReader reader = new SimpleTextLineEventReader(new FileReader(f1));    List<String> out = bodiesAsStrings(reader.readEvents(10));        assertEquals(8, out.size());    assertTrue(out.contains("file1line1"));    assertTrue(out.contains("file1line2"));    assertTrue(out.contains("file1line3"));    assertTrue(out.contains("file1line4"));    assertTrue(out.contains("file1line5"));    assertTrue(out.contains("file1line6"));    assertTrue(out.contains("file1line7"));    assertTrue(out.contains("file1line8"));}
e72c325150599c6a481eeb6500204f514bddcdc8490213cd6e982ca37e004f86
setup
public void setup() throws IOException, InterruptedException
{    if (!WORK_DIR.isDirectory()) {        Files.createParentDirs(new File(WORK_DIR, "dummy"));    }        for (int i = 0; i < 4; i++) {        File fileName = new File(WORK_DIR, "file" + i);        StringBuilder sb = new StringBuilder();                for (int j = 0; j < i; j++) {            sb.append("file" + i + "line" + j + "\n");        }        Files.write(sb.toString(), fileName, Charsets.UTF_8);    }        Thread.sleep(1500L);    Files.write("\n", new File(WORK_DIR, "emptylineFile"), Charsets.UTF_8);}
39e5ba029cc67f6f1d45c6d20f0df595ec16bc61da20d7680fcbbdae4fe7f95b
tearDown
public void tearDown()
{    deleteDir(WORK_DIR);}
34fec78bbfe5e4d7ca66d2da444513ef4f720f2e339ef9e195e9395c3a234c7a
deleteDir
private void deleteDir(File dir)
{        try {        FileUtils.deleteDirectory(dir);    } catch (IOException e) {        logger.warn("Cannot delete work directory {}", dir.getAbsolutePath(), e);    }}
4f71e860053de8c54c86e794d5c44f7678c168caa45537609072c10990aa310a
processEventsWithReader
private void processEventsWithReader(ReliableEventReader reader, int nEvents) throws IOException
{    List<Event> events;    do {        events = reader.readEvents(nEvents);        reader.commit();    } while (!events.isEmpty());}
6cbff297520603fd1c2900cf1b2d73e44babfd47ea45b43edc422e3ab5b8fda9
checkLeftFilesInDir
private boolean checkLeftFilesInDir(File dir, String[] files)
{    List<File> actualFiles = listFiles(dir);    Set<String> expectedFiles = new HashSet<String>(Arrays.asList(files));        if (actualFiles.size() != expectedFiles.size()) {        return false;    }        for (File f : actualFiles) {        expectedFiles.remove(f.getName());    }    return expectedFiles.isEmpty();}
e5e9e141663d0dccd5433917feb0529297e7a44c331a304f12596af25c162bd7
testIncludePattern
public void testIncludePattern() throws IOException
{    ReliableEventReader reader = new ReliableSpoolingFileEventReader.Builder().spoolDirectory(WORK_DIR).includePattern("^file2$").deletePolicy(DeletePolicy.IMMEDIATE.toString()).sourceCounter(new SourceCounter("test")).build();    String[] beforeFiles = { "file0", "file1", "file2", "file3", "emptylineFile" };    Assert.assertTrue("Expected " + beforeFiles.length + " files in working dir", checkLeftFilesInDir(WORK_DIR, beforeFiles));    processEventsWithReader(reader, 10);    String[] afterFiles = { "file0", "file1", "file3", "emptylineFile" };    Assert.assertTrue("Expected " + afterFiles.length + " files left in working dir", checkLeftFilesInDir(WORK_DIR, afterFiles));    Assert.assertTrue("Expected no files left in tracker dir", checkLeftFilesInDir(TRACKER_DIR, new String[0]));}
4c30720591bf95f2511811fab84f0ebb4ab981647ee6b61704540e589309b475
testIgnorePattern
public void testIgnorePattern() throws IOException
{    ReliableEventReader reader = new ReliableSpoolingFileEventReader.Builder().spoolDirectory(WORK_DIR).ignorePattern("^file2$").deletePolicy(DeletePolicy.IMMEDIATE.toString()).sourceCounter(new SourceCounter("test")).build();    String[] beforeFiles = { "file0", "file1", "file2", "file3", "emptylineFile" };    Assert.assertTrue("Expected " + beforeFiles.length + " files in working dir", checkLeftFilesInDir(WORK_DIR, beforeFiles));    processEventsWithReader(reader, 10);    String[] files = { "file2" };    Assert.assertTrue("Expected " + files.length + " files left in working dir", checkLeftFilesInDir(WORK_DIR, files));    Assert.assertTrue("Expected no files left in tracker dir", checkLeftFilesInDir(TRACKER_DIR, new String[0]));}
1113237f9eaf84f6774c69b57ccfd6dcb8fcb905f5e09c0a0437bc080e5fdf86
testIncludeExcludePatternNoConflict
public void testIncludeExcludePatternNoConflict() throws IOException
{                                ReliableEventReader reader = new ReliableSpoolingFileEventReader.Builder().spoolDirectory(WORK_DIR).ignorePattern("^file[013]$").includePattern("^file2$").deletePolicy(DeletePolicy.IMMEDIATE.toString()).sourceCounter(new SourceCounter("test")).build();    String[] beforeFiles = { "file0", "file1", "file2", "file3", "emptylineFile" };    Assert.assertTrue("Expected " + beforeFiles.length + " files in working dir", checkLeftFilesInDir(WORK_DIR, beforeFiles));    processEventsWithReader(reader, 10);    String[] files = { "file0", "file1", "file3", "emptylineFile" };    Assert.assertTrue("Expected " + files.length + " files left in working dir", checkLeftFilesInDir(WORK_DIR, files));    Assert.assertTrue("Expected no files left in tracker dir", checkLeftFilesInDir(TRACKER_DIR, new String[0]));}
7b2611d21d23558074ce77ea53ec9ac5c4f2e43eeefd003cac441f899c125462
testIncludeExcludePatternConflict
public void testIncludeExcludePatternConflict() throws IOException
{                        ReliableEventReader reader = new ReliableSpoolingFileEventReader.Builder().spoolDirectory(WORK_DIR).ignorePattern("^file2$").includePattern("^file2$").deletePolicy(DeletePolicy.IMMEDIATE.toString()).sourceCounter(new SourceCounter("test")).build();    String[] beforeFiles = { "file0", "file1", "file2", "file3", "emptylineFile" };    Assert.assertTrue("Expected " + beforeFiles.length + " files in working dir", checkLeftFilesInDir(WORK_DIR, beforeFiles));    processEventsWithReader(reader, 10);    String[] files = { "file0", "file1", "file2", "file3", "emptylineFile" };    Assert.assertTrue("Expected " + files.length + " files left in working dir", checkLeftFilesInDir(WORK_DIR, files));    Assert.assertTrue("Expected no files left in tracker dir", checkLeftFilesInDir(TRACKER_DIR, new String[0]));}
382fa75240424dfe790532e609ff707a7b832d0e2de1d95596340d2955d48571
testRepeatedCallsWithCommitAlways
public void testRepeatedCallsWithCommitAlways() throws IOException
{    ReliableEventReader reader = new ReliableSpoolingFileEventReader.Builder().spoolDirectory(WORK_DIR).sourceCounter(new SourceCounter("test")).build();    final int expectedLines = 1 + 1 + 2 + 3 + 1;    int seenLines = 0;    for (int i = 0; i < 10; i++) {        List<Event> events = reader.readEvents(10);        seenLines += events.size();        reader.commit();    }    Assert.assertEquals(expectedLines, seenLines);}
f0f4c8f1f974c6d39a0374c4cfc453a2a0c1d826e81a93e0a37999044f62b577
testRepeatedCallsWithCommitOnSuccess
public void testRepeatedCallsWithCommitOnSuccess() throws IOException
{    String trackerDirPath = SpoolDirectorySourceConfigurationConstants.DEFAULT_TRACKER_DIR;    File trackerDir = new File(WORK_DIR, trackerDirPath);    ReliableEventReader reader = new ReliableSpoolingFileEventReader.Builder().spoolDirectory(WORK_DIR).trackerDirPath(trackerDirPath).sourceCounter(new SourceCounter("test")).build();    final int expectedLines = 1 + 1 + 2 + 3 + 1;    int seenLines = 0;    for (int i = 0; i < 10; i++) {        List<Event> events = reader.readEvents(10);        int numEvents = events.size();        if (numEvents > 0) {            seenLines += numEvents;            reader.commit();                        File[] files = trackerDir.listFiles();            Assert.assertNotNull(files);            Assert.assertTrue("Expected tracker files in tracker dir " + trackerDir.getAbsolutePath(), files.length > 0);        }    }    Assert.assertEquals(expectedLines, seenLines);}
a2b5ae5b12a52192823d2e8882d18625cfcf9c99307de0428471d598abb87c40
testFileDeletion
public void testFileDeletion() throws IOException
{    ReliableEventReader reader = new ReliableSpoolingFileEventReader.Builder().spoolDirectory(WORK_DIR).deletePolicy(DeletePolicy.IMMEDIATE.name()).sourceCounter(new SourceCounter("test")).build();    List<File> before = listFiles(WORK_DIR);    Assert.assertEquals("Expected 5, not: " + before, 5, before.size());    List<Event> events;    do {        events = reader.readEvents(10);        reader.commit();    } while (!events.isEmpty());    List<File> after = listFiles(WORK_DIR);    Assert.assertEquals("Expected 0, not: " + after, 0, after.size());    List<File> trackerFiles = listFiles(new File(WORK_DIR, SpoolDirectorySourceConfigurationConstants.DEFAULT_TRACKER_DIR));    Assert.assertEquals("Expected 0, not: " + trackerFiles, 0, trackerFiles.size());}
5ca15f432ac246873aa2a30cfbb31515ae29c12dc1ade1908c6ddb07f2d69002
testNullConsumeOrder
public void testNullConsumeOrder() throws IOException
{    new ReliableSpoolingFileEventReader.Builder().spoolDirectory(WORK_DIR).consumeOrder(null).sourceCounter(new SourceCounter("test")).build();}
dd5c832c6f555951286289cc884ef24ea3b7e9df68db784b24fb431f29f6f97b
testConsumeFileRandomly
public void testConsumeFileRandomly() throws IOException
{    ReliableEventReader reader = new ReliableSpoolingFileEventReader.Builder().spoolDirectory(WORK_DIR).consumeOrder(ConsumeOrder.RANDOM).sourceCounter(new SourceCounter("test")).build();    File fileName = new File(WORK_DIR, "new-file");    FileUtils.write(fileName, "New file created in the end. Shoud be read randomly.\n");    Set<String> actual = Sets.newHashSet();    readEventsForFilesInDir(WORK_DIR, reader, actual);    Set<String> expected = Sets.newHashSet();    createExpectedFromFilesInSetup(expected);    expected.add("");    expected.add("New file created in the end. Shoud be read randomly.");    Assert.assertEquals(expected, actual);}
02b054ba043db3226bebedd5958889d5637d9f04314d3ebcf3a25f81ad91a1b7
testConsumeFileRandomlyNewFile
public void testConsumeFileRandomlyNewFile() throws Exception
{        if (SystemUtils.IS_OS_WINDOWS) {        return;    }    final ReliableEventReader reader = new ReliableSpoolingFileEventReader.Builder().spoolDirectory(WORK_DIR).consumeOrder(ConsumeOrder.RANDOM).sourceCounter(new SourceCounter("test")).build();    File fileName = new File(WORK_DIR, "new-file");    FileUtils.write(fileName, "New file created in the end. Shoud be read randomly.\n");    Set<String> expected = Sets.newHashSet();    int totalFiles = WORK_DIR.listFiles().length;    final Set<String> actual = Sets.newHashSet();    ExecutorService executor = Executors.newSingleThreadExecutor();    final Semaphore semaphore1 = new Semaphore(0);    final Semaphore semaphore2 = new Semaphore(0);    Future<Void> wait = executor.submit(new Callable<Void>() {        @Override        public Void call() throws Exception {            readEventsForFilesInDir(WORK_DIR, reader, actual, semaphore1, semaphore2);            return null;        }    });    semaphore1.acquire();    File finalFile = new File(WORK_DIR, "t-file");    FileUtils.write(finalFile, "Last file");    semaphore2.release();    wait.get();    int listFilesCount = ((ReliableSpoolingFileEventReader) reader).getListFilesCount();    finalFile.delete();    createExpectedFromFilesInSetup(expected);    expected.add("");    expected.add("New file created in the end. Shoud be read randomly.");    expected.add("Last file");    Assert.assertTrue(listFilesCount < (totalFiles + 2));    Assert.assertEquals(expected, actual);}
d12537fee0d4fb03a2b54ca4cc2cb7aeeb6659af2e7d4f187baf67a1d3ca17d2
call
public Void call() throws Exception
{    readEventsForFilesInDir(WORK_DIR, reader, actual, semaphore1, semaphore2);    return null;}
d3ea8a94bbf2bd09eda004cb428c965270d21bab0419dc29aa302c2f87dbc7d7
testConsumeFileOldest
public void testConsumeFileOldest() throws IOException, InterruptedException
{    ReliableEventReader reader = new ReliableSpoolingFileEventReader.Builder().spoolDirectory(WORK_DIR).consumeOrder(ConsumeOrder.OLDEST).sourceCounter(new SourceCounter("test")).build();    File file1 = new File(WORK_DIR, "new-file1");    File file2 = new File(WORK_DIR, "new-file2");    File file3 = new File(WORK_DIR, "new-file3");    Thread.sleep(1000L);    FileUtils.write(file2, "New file2 created.\n");    Thread.sleep(1000L);    FileUtils.write(file1, "New file1 created.\n");    Thread.sleep(1000L);    FileUtils.write(file3, "New file3 created.\n");        List<String> actual = Lists.newLinkedList();    readEventsForFilesInDir(WORK_DIR, reader, actual);    List<String> expected = Lists.newLinkedList();    createExpectedFromFilesInSetup(expected);        expected.add("");    expected.add("New file2 created.");    expected.add("New file1 created.");    expected.add("New file3 created.");    Assert.assertEquals(expected, actual);}
0f6f86027ecab5a2194149bb5d944a9ac094bcddc8fc3c019f5d1d3531a533ae
testConsumeFileYoungest
public void testConsumeFileYoungest() throws IOException, InterruptedException
{    ReliableEventReader reader = new ReliableSpoolingFileEventReader.Builder().spoolDirectory(WORK_DIR).consumeOrder(ConsumeOrder.YOUNGEST).sourceCounter(new SourceCounter("test")).build();    File file1 = new File(WORK_DIR, "new-file1");    File file2 = new File(WORK_DIR, "new-file2");    File file3 = new File(WORK_DIR, "new-file3");    Thread.sleep(1000L);    FileUtils.write(file2, "New file2 created.\n");    Thread.sleep(1000L);    FileUtils.write(file3, "New file3 created.\n");    Thread.sleep(1000L);    FileUtils.write(file1, "New file1 created.\n");        List<String> actual = Lists.newLinkedList();    readEventsForFilesInDir(WORK_DIR, reader, actual);    List<String> expected = Lists.newLinkedList();    createExpectedFromFilesInSetup(expected);    Collections.sort(expected);        expected.add(0, "");    expected.add(0, "New file2 created.");    expected.add(0, "New file3 created.");    expected.add(0, "New file1 created.");    Assert.assertEquals(expected, actual);}
be5ea74150d5c3fe6f7174d3ab06afe609ec5cbd263506cfcae08ca10bba581a
testConsumeFileOldestWithLexicographicalComparision
public void testConsumeFileOldestWithLexicographicalComparision() throws IOException, InterruptedException
{    ReliableEventReader reader = new ReliableSpoolingFileEventReader.Builder().spoolDirectory(WORK_DIR).consumeOrder(ConsumeOrder.OLDEST).sourceCounter(new SourceCounter("test")).build();    File file1 = new File(WORK_DIR, "new-file1");    File file2 = new File(WORK_DIR, "new-file2");    File file3 = new File(WORK_DIR, "new-file3");    Thread.sleep(1000L);    FileUtils.write(file3, "New file3 created.\n");    FileUtils.write(file2, "New file2 created.\n");    FileUtils.write(file1, "New file1 created.\n");    file1.setLastModified(file3.lastModified());    file1.setLastModified(file2.lastModified());            List<String> actual = Lists.newLinkedList();    readEventsForFilesInDir(WORK_DIR, reader, actual);    List<String> expected = Lists.newLinkedList();    createExpectedFromFilesInSetup(expected);        expected.add("");    expected.add("New file1 created.");    expected.add("New file2 created.");    expected.add("New file3 created.");    Assert.assertEquals(expected, actual);}
d71c81c18ab2012b28cd193a697b5176674b448cf08fc43e8572db14cffbeba2
testConsumeFileYoungestWithLexicographicalComparision
public void testConsumeFileYoungestWithLexicographicalComparision() throws IOException, InterruptedException
{    ReliableEventReader reader = new ReliableSpoolingFileEventReader.Builder().spoolDirectory(WORK_DIR).consumeOrder(ConsumeOrder.YOUNGEST).sourceCounter(new SourceCounter("test")).build();    File file1 = new File(WORK_DIR, "new-file1");    File file2 = new File(WORK_DIR, "new-file2");    File file3 = new File(WORK_DIR, "new-file3");    Thread.sleep(1000L);    FileUtils.write(file1, "New file1 created.\n");    FileUtils.write(file2, "New file2 created.\n");    FileUtils.write(file3, "New file3 created.\n");    file1.setLastModified(file3.lastModified());    file1.setLastModified(file2.lastModified());            List<String> actual = Lists.newLinkedList();    readEventsForFilesInDir(WORK_DIR, reader, actual);    List<String> expected = Lists.newLinkedList();    createExpectedFromFilesInSetup(expected);        expected.add(0, "");    expected.add(0, "New file3 created.");    expected.add(0, "New file2 created.");    expected.add(0, "New file1 created.");    Assert.assertEquals(expected, actual);}
798e09d99e810dc06812963548c1274169fe995792f6e315174833a073c1b6e6
testLargeNumberOfFilesOLDEST
public void testLargeNumberOfFilesOLDEST() throws IOException
{    templateTestForRecursiveDirs(ConsumeOrder.OLDEST, null, 3, 3, 37, TrackingPolicy.RENAME);}
bc90fd09521fda036a435161e8e6de827bae432f6a2f515cd6457fda8d7da585
testLargeNumberOfFilesYOUNGEST
public void testLargeNumberOfFilesYOUNGEST() throws IOException
{    templateTestForRecursiveDirs(ConsumeOrder.YOUNGEST, Comparator.reverseOrder(), 3, 3, 37, TrackingPolicy.RENAME);}
a560cc96885ec9f4da1356b8b75ac6cbee783a30a0b9823c474f37c41542c1e5
testLargeNumberOfFilesRANDOM
public void testLargeNumberOfFilesRANDOM() throws IOException
{    templateTestForRecursiveDirs(ConsumeOrder.RANDOM, null, 3, 3, 37, TrackingPolicy.RENAME);}
59adc86d7517df914426ba0e76f9c778211a113561974dbebfaa829e1ba5afc4
testLargeNumberOfFilesOLDESTTrackerDir
public void testLargeNumberOfFilesOLDESTTrackerDir() throws IOException
{    templateTestForRecursiveDirs(ConsumeOrder.OLDEST, null, 3, 3, 10, TrackingPolicy.TRACKER_DIR);}
7fc7b6f0d5485045404c1c3094b07644fcd582532d094a284826d7f99509f4ce
testLargeNumberOfFilesYOUNGESTTrackerDir
public void testLargeNumberOfFilesYOUNGESTTrackerDir() throws IOException
{    templateTestForRecursiveDirs(ConsumeOrder.YOUNGEST, Comparator.reverseOrder(), 3, 3, 10, TrackingPolicy.TRACKER_DIR);}
125ecd84f9e19dc0e1b5a03cbf0c9815f0eee6e79e55a7affe41f2cc62714f46
testLargeNumberOfFilesRANDOMTrackerDir
public void testLargeNumberOfFilesRANDOMTrackerDir() throws IOException
{    templateTestForRecursiveDirs(ConsumeOrder.RANDOM, null, 3, 3, 10, TrackingPolicy.TRACKER_DIR);}
84bf22b03dc1b7e37b4185225c9d54a25e310c590d1cd89b624b9cd8c68e572a
testZeroByteTrackerFile
public void testZeroByteTrackerFile() throws IOException
{    String trackerDirPath = SpoolDirectorySourceConfigurationConstants.DEFAULT_TRACKER_DIR;    File trackerDir = new File(WORK_DIR, trackerDirPath);    if (!trackerDir.exists()) {        trackerDir.mkdir();    }    File trackerFile = new File(trackerDir, ReliableSpoolingFileEventReader.metaFileName);    if (trackerFile.exists()) {        trackerFile.delete();    }    trackerFile.createNewFile();    ReliableEventReader reader = new ReliableSpoolingFileEventReader.Builder().spoolDirectory(WORK_DIR).trackerDirPath(trackerDirPath).sourceCounter(new SourceCounter("test")).build();    final int expectedLines = 1;    int seenLines = 0;    List<Event> events = reader.readEvents(10);    int numEvents = events.size();    if (numEvents > 0) {        seenLines += numEvents;        reader.commit();    }        Assert.assertEquals(expectedLines, seenLines);}
394ec0e6b59c95c85878143a32e65575bbb3d96d3139d0583087718a6934a2bc
templateTestForRecursiveDirs
private void templateTestForRecursiveDirs(ConsumeOrder order, Comparator<Long> comparator, int depth, int dirNum, int fileNum, TrackingPolicy trackingPolicy) throws IOException
{    File dir = null;    try {        dir = new File("target/test/work/" + this.getClass().getSimpleName() + "_large");        Files.createParentDirs(new File(dir, "dummy"));        ReliableEventReader reader = new ReliableSpoolingFileEventReader.Builder().spoolDirectory(dir).consumeOrder(order).trackingPolicy(trackingPolicy.toString()).recursiveDirectorySearch(true).sourceCounter(new SourceCounter("test")).build();        Map<Long, List<String>> expected;        if (comparator == null) {            expected = new TreeMap<Long, List<String>>();        } else {            expected = new TreeMap<Long, List<String>>(comparator);        }        createMultilevelFiles(dir, 0, depth, dirNum, fileNum, expected, new MutableLong(0L));        Collection<String> expectedColl;        int index = 0;        if (order == ConsumeOrder.RANDOM) {            expectedColl = Sets.newHashSet();        } else {            expectedColl = new ArrayList<>();        }        for (Entry<Long, List<String>> entry : expected.entrySet()) {            Collections.sort(entry.getValue());            expectedColl.addAll(entry.getValue());        }        int expNum = expectedColl.size();        int actualNum = 0;        for (int i = 0; i < expNum; i++) {            List<Event> events;            events = reader.readEvents(10);            for (Event e : events) {                actualNum++;                if (order == ConsumeOrder.RANDOM) {                    Assert.assertTrue(expectedColl.remove(new String(e.getBody())));                } else {                    String exp = ((ArrayList<String>) expectedColl).get(index);                    String actual = new String(e.getBody());                    Assert.assertEquals(exp, actual);                    index++;                }            }            reader.commit();        }        Assert.assertEquals(expNum, actualNum);    } finally {        deleteDir(dir);    }}
cfe9d3a84a80707aedfae189dd942a104623f4aa2837bfbc5ff2192e94ad0f2d
createMultilevelFiles
private void createMultilevelFiles(File dir, int currDepth, int maxDepth, int dirNum, int fileNum, Map<Long, List<String>> expected, MutableLong id) throws IOException
{    if (currDepth == maxDepth) {        createFiles(dir, fileNum, expected, id);    } else {        for (int i = 0; i < dirNum; i++) {            File nextDir = new File(dir, "dir-" + i);            nextDir.mkdirs();            createMultilevelFiles(nextDir, currDepth + 1, maxDepth, dirNum, fileNum, expected, id);        }    }}
8d76e449cfeceb32af40046ee383fa3696a133e3e220b5c5f0c8e5d6904aa957
createFiles
private void createFiles(File dir, int fileNum, Map<Long, List<String>> expected, MutableLong id) throws IOException
{    for (int i = 0; i < fileNum; i++) {        File f = new File(dir, "file-" + id);        String data = f.getPath();        Files.write(data, f, Charsets.UTF_8);        long lastMod = id.longValue() * 10000L;        f.setLastModified(lastMod);        if (expected.containsKey(f.lastModified())) {            expected.get(f.lastModified()).add(data);        } else {            expected.put(f.lastModified(), Lists.newArrayList(data));        }        id.increment();    }}
6d6892433352bb458f657d4a9712a42e6c53855ab1f8ee32c7099aaf0375509e
readEventsForFilesInDir
private void readEventsForFilesInDir(File dir, ReliableEventReader reader, Collection<String> actual) throws IOException
{    readEventsForFilesInDir(dir, reader, actual, null, null);}
e35feba3961f9e70eedb440f54cb7415c6f4b21a06c7524c4f7556421a1c1a3e
readEventsForFilesInDir
private void readEventsForFilesInDir(File dir, ReliableEventReader reader, Collection<String> actual, Semaphore semaphore1, Semaphore semaphore2) throws IOException
{    List<Event> events;    boolean executed = false;    for (int i = 0; i < listFiles(dir).size(); i++) {        events = reader.readEvents(10);        for (Event e : events) {            actual.add(new String(e.getBody()));        }        reader.commit();        try {            if (!executed) {                executed = true;                if (semaphore1 != null) {                    semaphore1.release();                }                if (semaphore2 != null) {                    semaphore2.acquire();                }            }        } catch (Exception ex) {            throw new IOException(ex);        }    }}
16a11deec9b8e6606b7934bdd962fb600d825690a609be40dd360dd2f57de589
createExpectedFromFilesInSetup
private void createExpectedFromFilesInSetup(Collection<String> expected)
{    expected.add("");    for (int i = 0; i < 4; i++) {        for (int j = 0; j < i; j++) {            expected.add("file" + i + "line" + j);        }    }}
03de42d6dc21518e05f56aaaff37725823cf6e358b460fd3e0a248a8b46f52c8
listFiles
private static List<File> listFiles(File dir)
{    List<File> files = Lists.newArrayList(dir.listFiles(new FileFilter() {        @Override        public boolean accept(File pathname) {            return !pathname.isDirectory();        }    }));    return files;}
155bb26e6e044e511a6b4e1abe493e1d98e838ec86fc602edcf25c1a5b9f7f03
accept
public boolean accept(File pathname)
{    return !pathname.isDirectory();}
ff97395b99774c1f3bab4a96b591e093af46b9c4e39ed5a4ef0b4b2ee00bd80e
bodyAsString
 static String bodyAsString(Event event)
{    return new String(event.getBody());}
28e08ca5ceb7a59e19e4f28f271fed6443ff355e9e1aaaa56a13fc2ef24d57b0
bodiesAsStrings
 static List<String> bodiesAsStrings(List<Event> events)
{    List<String> bodies = Lists.newArrayListWithCapacity(events.size());    for (Event event : events) {        bodies.add(bodyAsString(event));    }    return bodies;}
7e82c20496509c1e9ed70d3fba64335857e21663497ae950c8129b445a70b2e5
getParser
private ReliableSpoolingFileEventReader getParser(int maxLineLength)
{    Context ctx = new Context();    ctx.put(LineDeserializer.MAXLINE_KEY, Integer.toString(maxLineLength));    ReliableSpoolingFileEventReader parser;    try {        parser = new ReliableSpoolingFileEventReader.Builder().spoolDirectory(tmpDir).completedSuffix(completedSuffix).deserializerContext(ctx).sourceCounter(new SourceCounter("dummy")).build();    } catch (IOException ioe) {        throw Throwables.propagate(ioe);    }    return parser;}
8d55b7b4c2c4c3fa4ef1fc518c5a9f6d136d4a3e68acd255b35026aaba28e8af
getParser
private ReliableSpoolingFileEventReader getParser()
{    return getParser(bufferMaxLineLength);}
ea0cfa3873c01140402490f04d3338a8477856046db4f538cac50fd0973b39b4
directoryFilter
private FileFilter directoryFilter()
{    return new FileFilter() {        public boolean accept(File candidate) {            if (candidate.isDirectory()) {                return false;            }            return true;        }    };}
bfa386a6dd1fa1a66673c293abe4ab6d460032cc17f2ecfa5f6bcffe8ad4a0a9
accept
public boolean accept(File candidate)
{    if (candidate.isDirectory()) {        return false;    }    return true;}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    tmpDir = Files.createTempDir();}
39e5ba029cc67f6f1d45c6d20f0df595ec16bc61da20d7680fcbbdae4fe7f95b
tearDown
public void tearDown()
{    for (File f : tmpDir.listFiles()) {        if (f.isDirectory()) {            for (File sdf : f.listFiles()) {                sdf.delete();            }        }        f.delete();    }    tmpDir.delete();}
4327be53d80afd4d67a895f1c56c7ad74f1e5c84fdea2bf99407acc032c9619d
testBasicSpooling
public void testBasicSpooling() throws IOException
{    File f1 = new File(tmpDir.getAbsolutePath() + "/file1");    File f2 = new File(tmpDir.getAbsolutePath() + "/file2");    File f3 = new File(tmpDir.getAbsolutePath() + "/file3");    Files.write("file1line1\nfile1line2\n", f1, Charsets.UTF_8);    Files.write("file2line1\nfile2line2\n", f2, Charsets.UTF_8);    Files.write("file3line1\nfile3line2\n", f3, Charsets.UTF_8);    ReliableSpoolingFileEventReader parser = getParser();    List<String> out = Lists.newArrayList();    for (int i = 0; i < 6; i++) {        logger.info("At line {}", i);        String body = bodyAsString(parser.readEvent());        logger.debug("Seen event with body: {}", body);        out.add(body);        parser.commit();    }        assertTrue(out.contains("file1line1"));    assertTrue(out.contains("file1line2"));    assertTrue(out.contains("file2line1"));    assertTrue(out.contains("file2line2"));    assertTrue(out.contains("file3line1"));    assertTrue(out.contains("file3line2"));    List<File> outFiles = Lists.newArrayList(tmpDir.listFiles(directoryFilter()));    assertEquals(3, outFiles.size());        assertTrue(outFiles.contains(new File(tmpDir + "/file1" + completedSuffix)));    assertTrue(outFiles.contains(new File(tmpDir + "/file2" + completedSuffix)));    assertTrue(outFiles.contains(new File(tmpDir + "/file3")));}
854c9e25300975dfafea0a10bd89cd39834d43dd7988fea00fb5d0c163eb59ad
testInitiallyEmptyDirectory
public void testInitiallyEmptyDirectory() throws IOException
{    ReliableSpoolingFileEventReader parser = getParser();    assertNull(parser.readEvent());    assertEquals(0, parser.readEvents(10).size());    File f1 = new File(tmpDir.getAbsolutePath() + "/file1");    Files.write("file1line1\nfile1line2\n", f1, Charsets.UTF_8);    List<String> out = bodiesAsStrings(parser.readEvents(2));    parser.commit();        assertTrue(out.contains("file1line1"));    assertTrue(out.contains("file1line2"));    File f2 = new File(tmpDir.getAbsolutePath() + "/file2");    Files.write("file2line1\nfile2line2\n", f2, Charsets.UTF_8);        parser.readEvent();    parser.commit();    List<File> outFiles = Lists.newArrayList(tmpDir.listFiles(directoryFilter()));    assertEquals(2, outFiles.size());    assertTrue(outFiles.contains(new File(tmpDir + "/file1" + completedSuffix)));    assertTrue(outFiles.contains(new File(tmpDir + "/file2")));}
82d2d34a545db2b233a176e93bfb290cb53966b33bb9a54f59e35d6e5f85c9fe
testFileChangesDuringRead
public void testFileChangesDuringRead() throws IOException
{    File f1 = new File(tmpDir.getAbsolutePath() + "/file1");    Files.write("file1line1\nfile1line2\n", f1, Charsets.UTF_8);    ReliableSpoolingFileEventReader parser1 = getParser();    List<String> out = Lists.newArrayList();    out.addAll(bodiesAsStrings(parser1.readEvents(2)));    parser1.commit();    assertEquals(2, out.size());    assertTrue(out.contains("file1line1"));    assertTrue(out.contains("file1line2"));    Files.append("file1line3\n", f1, Charsets.UTF_8);    out.add(bodyAsString(parser1.readEvent()));    parser1.commit();    out.add(bodyAsString(parser1.readEvent()));    parser1.commit();}
8f9e5de85f9d53a55f187b24c77a5d819bc8a0e05e68dd3fd256ab34f61c4965
testDestinationExistsAndSameFileWindows
public void testDestinationExistsAndSameFileWindows() throws IOException
{    System.setProperty("os.name", "Some version of Windows");    File f1 = new File(tmpDir.getAbsolutePath() + "/file1");    File f1Completed = new File(tmpDir.getAbsolutePath() + "/file1" + completedSuffix);    Files.write("file1line1\nfile1line2\n", f1, Charsets.UTF_8);    Files.write("file1line1\nfile1line2\n", f1Completed, Charsets.UTF_8);    ReliableSpoolingFileEventReader parser = getParser();    List<String> out = Lists.newArrayList();    for (int i = 0; i < 2; i++) {        out.add(bodyAsString(parser.readEvent()));        parser.commit();    }    File f2 = new File(tmpDir.getAbsolutePath() + "/file2");    Files.write("file2line1\nfile2line2\n", f2, Charsets.UTF_8);    for (int i = 0; i < 2; i++) {        out.add(bodyAsString(parser.readEvent()));        parser.commit();    }        assertEquals(4, out.size());    assertTrue(out.contains("file1line1"));    assertTrue(out.contains("file1line2"));    assertTrue(out.contains("file2line1"));    assertTrue(out.contains("file2line2"));        List<File> outFiles = Lists.newArrayList(tmpDir.listFiles(directoryFilter()));    assertEquals(2, outFiles.size());    assertTrue(outFiles.contains(new File(tmpDir + "/file2")));    assertTrue(outFiles.contains(new File(tmpDir + "/file1" + completedSuffix)));}
ec5c8ed027d60530a6406086ce94130e8b2658dab2e90544c46f28da79bc72bb
testDestinationExistsAndSameFileNotOnWindows
public void testDestinationExistsAndSameFileNotOnWindows() throws IOException
{    System.setProperty("os.name", "Some version of Linux");    File f1 = new File(tmpDir.getAbsolutePath() + "/file1");    File f1Completed = new File(tmpDir.getAbsolutePath() + "/file1" + completedSuffix);    Files.write("file1line1\nfile1line2\n", f1, Charsets.UTF_8);    Files.write("file1line1\nfile1line2\n", f1Completed, Charsets.UTF_8);    ReliableSpoolingFileEventReader parser = getParser();    List<String> out = Lists.newArrayList();    for (int i = 0; i < 2; i++) {        out.add(bodyAsString(parser.readEvent()));        parser.commit();    }    File f2 = new File(tmpDir.getAbsolutePath() + "/file2");    Files.write("file2line1\nfile2line2\n", f2, Charsets.UTF_8);    for (int i = 0; i < 2; i++) {        out.add(bodyAsString(parser.readEvent()));        parser.commit();    }}
912f79fa391cbb5d5b58ac2c1b5f42f329ed0f0feef0d13e45284b6815cfd9f8
testBasicCommitFailure
public void testBasicCommitFailure() throws IOException
{    File f1 = new File(tmpDir.getAbsolutePath() + "/file1");    Files.write("file1line1\nfile1line2\nfile1line3\nfile1line4\n" + "file1line5\nfile1line6\nfile1line7\nfile1line8\n" + "file1line9\nfile1line10\nfile1line11\nfile1line12\n", f1, Charsets.UTF_8);    ReliableSpoolingFileEventReader parser = getParser();    List<String> out1 = bodiesAsStrings(parser.readEvents(4));    assertTrue(out1.contains("file1line1"));    assertTrue(out1.contains("file1line2"));    assertTrue(out1.contains("file1line3"));    assertTrue(out1.contains("file1line4"));    List<String> out2 = bodiesAsStrings(parser.readEvents(4));    assertTrue(out2.contains("file1line1"));    assertTrue(out2.contains("file1line2"));    assertTrue(out2.contains("file1line3"));    assertTrue(out2.contains("file1line4"));    parser.commit();    List<String> out3 = bodiesAsStrings(parser.readEvents(4));    assertTrue(out3.contains("file1line5"));    assertTrue(out3.contains("file1line6"));    assertTrue(out3.contains("file1line7"));    assertTrue(out3.contains("file1line8"));    parser.commit();    List<String> out4 = bodiesAsStrings(parser.readEvents(4));    assertEquals(4, out4.size());    assertTrue(out4.contains("file1line9"));    assertTrue(out4.contains("file1line10"));    assertTrue(out4.contains("file1line11"));    assertTrue(out4.contains("file1line12"));}
b6624704e98dfa54ebb32492a82c74c4737e8f6ba7ebf1023f75f9d8be9a0ed9
testBasicCommitFailureAndBufferSizeChanges
public void testBasicCommitFailureAndBufferSizeChanges() throws IOException
{    File f1 = new File(tmpDir.getAbsolutePath() + "/file1");    Files.write("file1line1\nfile1line2\nfile1line3\nfile1line4\n" + "file1line5\nfile1line6\nfile1line7\nfile1line8\n" + "file1line9\nfile1line10\nfile1line11\nfile1line12\n", f1, Charsets.UTF_8);    ReliableSpoolingFileEventReader parser = getParser();    List<String> out1 = bodiesAsStrings(parser.readEvents(5));    assertTrue(out1.contains("file1line1"));    assertTrue(out1.contains("file1line2"));    assertTrue(out1.contains("file1line3"));    assertTrue(out1.contains("file1line4"));    assertTrue(out1.contains("file1line5"));    List<String> out2 = bodiesAsStrings(parser.readEvents(2));    assertTrue(out2.contains("file1line1"));    assertTrue(out2.contains("file1line2"));    parser.commit();    List<String> out3 = bodiesAsStrings(parser.readEvents(2));    assertTrue(out3.contains("file1line3"));    assertTrue(out3.contains("file1line4"));    parser.commit();    List<String> out4 = bodiesAsStrings(parser.readEvents(2));    assertTrue(out4.contains("file1line5"));    assertTrue(out4.contains("file1line6"));    parser.commit();    List<String> out5 = bodiesAsStrings(parser.readEvents(2));    assertTrue(out5.contains("file1line7"));    assertTrue(out5.contains("file1line8"));    parser.commit();    List<String> out6 = bodiesAsStrings(parser.readEvents(15));    assertTrue(out6.contains("file1line9"));    assertTrue(out6.contains("file1line10"));    assertTrue(out6.contains("file1line11"));    assertTrue(out6.contains("file1line12"));}
0d98369a8821a94bdd94b12a6712a67be3f2f34958a1ee13887c26d1b51ecaf1
testDestinationExistsAndDifferentFile
public void testDestinationExistsAndDifferentFile() throws IOException
{    File f1 = new File(tmpDir.getAbsolutePath() + "/file1");    File f1Completed = new File(tmpDir.getAbsolutePath() + "/file1" + completedSuffix);    Files.write("file1line1\nfile1line2\n", f1, Charsets.UTF_8);    Files.write("file1line1\nfile1XXXe2\n", f1Completed, Charsets.UTF_8);    ReliableSpoolingFileEventReader parser = getParser();    List<String> out = Lists.newArrayList();    for (int i = 0; i < 2; i++) {        out.add(bodyAsString(parser.readEvent()));        parser.commit();    }    File f2 = new File(tmpDir.getAbsolutePath() + "/file2");    Files.write("file2line1\nfile2line2\n", f2, Charsets.UTF_8);    for (int i = 0; i < 2; i++) {        out.add(bodyAsString(parser.readEvent()));        parser.commit();    }}
d5fcf4487f820e22a7a8ed0672dbd885083dcbcbc4cfb9e5726bd6b01d202f56
testBehaviorWithEmptyFile
public void testBehaviorWithEmptyFile() throws IOException
{    File f1 = new File(tmpDir.getAbsolutePath() + "/file0");    Files.touch(f1);    ReliableSpoolingFileEventReader parser = getParser();    File f2 = new File(tmpDir.getAbsolutePath() + "/file1");    Files.write("file1line1\nfile1line2\nfile1line3\nfile1line4\n" + "file1line5\nfile1line6\nfile1line7\nfile1line8\n", f2, Charsets.UTF_8);        Event event = parser.readEvent();    assertEquals(0, event.getBody().length);    List<String> out = bodiesAsStrings(parser.readEvents(8));    parser.commit();    assertEquals(8, out.size());    assertTrue(out.contains("file1line1"));    assertTrue(out.contains("file1line2"));    assertTrue(out.contains("file1line3"));    assertTrue(out.contains("file1line4"));    assertTrue(out.contains("file1line5"));    assertTrue(out.contains("file1line6"));    assertTrue(out.contains("file1line7"));    assertTrue(out.contains("file1line8"));    assertNull(parser.readEvent());        List<File> outFiles = Lists.newArrayList(tmpDir.listFiles(directoryFilter()));    assertEquals(2, outFiles.size());    assertTrue("Outfiles should have file0 & file1: " + outFiles, outFiles.contains(new File(tmpDir + "/file0" + completedSuffix)));    assertTrue("Outfiles should have file0 & file1: " + outFiles, outFiles.contains(new File(tmpDir + "/file1" + completedSuffix)));}
baf4d0b9d800d2d054400489df37be1ba4497fa5adf87dce3fd4407db7de36f0
testBatchedReadsWithinAFile
public void testBatchedReadsWithinAFile() throws IOException
{    File f1 = new File(tmpDir.getAbsolutePath() + "/file1");    Files.write("file1line1\nfile1line2\nfile1line3\nfile1line4\n" + "file1line5\nfile1line6\nfile1line7\nfile1line8\n", f1, Charsets.UTF_8);    ReliableSpoolingFileEventReader parser = getParser();    List<String> out = bodiesAsStrings(parser.readEvents(5));    parser.commit();        assertEquals(5, out.size());    assertTrue(out.contains("file1line1"));    assertTrue(out.contains("file1line2"));    assertTrue(out.contains("file1line3"));    assertTrue(out.contains("file1line4"));    assertTrue(out.contains("file1line5"));}
b2a1ed011c80eaa0b4be5688648b1a226d6a387667cee7f975aa79abf29ffd56
testBatchedReadsAcrossFileBoundary
public void testBatchedReadsAcrossFileBoundary() throws IOException
{    File f1 = new File(tmpDir.getAbsolutePath() + "/file1");    Files.write("file1line1\nfile1line2\nfile1line3\nfile1line4\n" + "file1line5\nfile1line6\nfile1line7\nfile1line8\n", f1, Charsets.UTF_8);    ReliableSpoolingFileEventReader parser = getParser();    List<String> out1 = bodiesAsStrings(parser.readEvents(5));    parser.commit();    File f2 = new File(tmpDir.getAbsolutePath() + "/file2");    Files.write("file2line1\nfile2line2\nfile2line3\nfile2line4\n" + "file2line5\nfile2line6\nfile2line7\nfile2line8\n", f2, Charsets.UTF_8);    List<String> out2 = bodiesAsStrings(parser.readEvents(5));    parser.commit();    List<String> out3 = bodiesAsStrings(parser.readEvents(5));    parser.commit();        assertEquals(5, out1.size());    assertTrue(out1.contains("file1line1"));    assertTrue(out1.contains("file1line2"));    assertTrue(out1.contains("file1line3"));    assertTrue(out1.contains("file1line4"));    assertTrue(out1.contains("file1line5"));        assertEquals(3, out2.size());    assertTrue(out2.contains("file1line6"));    assertTrue(out2.contains("file1line7"));    assertTrue(out2.contains("file1line8"));        assertEquals(5, out3.size());    assertTrue(out3.contains("file2line1"));    assertTrue(out3.contains("file2line2"));    assertTrue(out3.contains("file2line3"));    assertTrue(out3.contains("file2line4"));    assertTrue(out3.contains("file2line5"));        List<File> outFiles = Lists.newArrayList(tmpDir.listFiles(directoryFilter()));    assertEquals(2, outFiles.size());    assertTrue(outFiles.contains(new File(tmpDir + "/file1" + completedSuffix)));    assertTrue(outFiles.contains(new File(tmpDir + "/file2")));}
705979611469ddd748c7e249036fc97936457e77446217c899654da023c53f04
testEmptyDirectoryAfterCommittingFile
public void testEmptyDirectoryAfterCommittingFile() throws IOException
{    File f1 = new File(tmpDir.getAbsolutePath() + "/file1");    Files.write("file1line1\nfile1line2\n", f1, Charsets.UTF_8);    ReliableSpoolingFileEventReader parser = getParser();    List<String> allLines = bodiesAsStrings(parser.readEvents(2));    assertEquals(2, allLines.size());    parser.commit();    List<String> empty = bodiesAsStrings(parser.readEvents(10));    assertEquals(0, empty.size());}
3b28a51fa8d37949ad995eba4e5555212de1cd72021898cc3358bf5e51f46c22
testLineExceedsMaxLineLength
public void testLineExceedsMaxLineLength() throws IOException
{    final int maxLineLength = 12;    File f1 = new File(tmpDir.getAbsolutePath() + "/file1");    Files.write("file1line1\nfile1line2\nfile1line3\nfile1line4\n" + "file1line5\nfile1line6\nfile1line7\nfile1line8\n" + "reallyreallyreallyreallyLongLineHerefile1line9\n" + "file1line10\nfile1line11\nfile1line12\nfile1line13\n", f1, Charsets.UTF_8);    ReliableSpoolingFileEventReader parser = getParser(maxLineLength);    List<String> out1 = bodiesAsStrings(parser.readEvents(5));    assertTrue(out1.contains("file1line1"));    assertTrue(out1.contains("file1line2"));    assertTrue(out1.contains("file1line3"));    assertTrue(out1.contains("file1line4"));    assertTrue(out1.contains("file1line5"));    parser.commit();    List<String> out2 = bodiesAsStrings(parser.readEvents(4));    assertTrue(out2.contains("file1line6"));    assertTrue(out2.contains("file1line7"));    assertTrue(out2.contains("file1line8"));    assertTrue(out2.contains("reallyreally"));    parser.commit();    List<String> out3 = bodiesAsStrings(parser.readEvents(5));    assertTrue(out3.contains("reallyreally"));    assertTrue(out3.contains("LongLineHere"));    assertTrue(out3.contains("file1line9"));    assertTrue(out3.contains("file1line10"));    assertTrue(out3.contains("file1line11"));    parser.commit();    List<String> out4 = bodiesAsStrings(parser.readEvents(5));    assertTrue(out4.contains("file1line12"));    assertTrue(out4.contains("file1line13"));    assertEquals(2, out4.size());    parser.commit();    assertEquals(0, parser.readEvents(5).size());}
81dad2b530f78bd73d051a5661c01674d51a3cf63bd23e324b9d1146435bb6a0
testNameCorrespondsToLatestRead
public void testNameCorrespondsToLatestRead() throws IOException
{    File f1 = new File(tmpDir.getAbsolutePath() + "/file1");    Files.write("file1line1\nfile1line2\nfile1line3\nfile1line4\n" + "file1line5\nfile1line6\nfile1line7\nfile1line8\n", f1, Charsets.UTF_8);    ReliableSpoolingFileEventReader parser = getParser();    parser.readEvents(5);    parser.commit();    assertNotNull(parser.getLastFileRead());    assertTrue(parser.getLastFileRead().endsWith("file1"));    File f2 = new File(tmpDir.getAbsolutePath() + "/file2");    Files.write("file2line1\nfile2line2\nfile2line3\nfile2line4\n" + "file2line5\nfile2line6\nfile2line7\nfile2line8\n", f2, Charsets.UTF_8);    parser.readEvents(5);    parser.commit();    assertNotNull(parser.getLastFileRead());    assertTrue(parser.getLastFileRead().endsWith("file1"));    parser.readEvents(5);    parser.commit();    assertNotNull(parser.getLastFileRead());    assertTrue(parser.getLastFileRead().endsWith("file2"));    parser.readEvents(5);    assertTrue(parser.getLastFileRead().endsWith("file2"));    parser.readEvents(5);    assertTrue(parser.getLastFileRead().endsWith("file2"));}
ab42f4e61694d3aec7298c7e9281ec1a590fef048f01c2fc8a4acb0c113fa265
testPrintable
public void testPrintable()
{    SimpleEvent event = new SimpleEvent();    event.setBody("Some text".getBytes());    String eventDump = EventHelper.dumpEvent(event);    System.out.println(eventDump);    Assert.assertTrue(eventDump, eventDump.contains("Some text"));}
dc7ca72c4cdb65e0e4e875e6a51fec830706157ecdd97aad65bc1f05e988894a
testNonPrintable
public void testNonPrintable()
{    SimpleEvent event = new SimpleEvent();    byte[] body = new byte[5];    event.setBody(body);    String eventDump = EventHelper.dumpEvent(event);    Assert.assertTrue(eventDump, eventDump.contains("....."));}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    cal = createCalendar(2012, 5, 23, 13, 46, 33, 234, null);    headers = new HashMap<>();    headers.put("timestamp", String.valueOf(cal.getTimeInMillis()));    Calendar calWithTimeZone = createCalendar(2012, 5, 23, 13, 46, 33, 234, CUSTOM_TIMEZONE);    headersWithTimeZone = new HashMap<>();    headersWithTimeZone.put("timestamp", String.valueOf(calWithTimeZone.getTimeInMillis()));}
0c5766eeaaef9ae9a684584d11122a953464f66e95c06b7a438ffba4df080169
testDateFormatCache
public void testDateFormatCache()
{    TimeZone utcTimeZone = TimeZone.getTimeZone("UTC");    String test = "%c";    BucketPath.escapeString(test, headers, utcTimeZone, false, Calendar.HOUR_OF_DAY, 12, false);    String escapedString = BucketPath.escapeString(test, headers, false, Calendar.HOUR_OF_DAY, 12);    System.out.println("Escaped String: " + escapedString);    SimpleDateFormat format = new SimpleDateFormat("EEE MMM d HH:mm:ss yyyy");    Date d = new Date(cal.getTimeInMillis());    String expectedString = format.format(d);    System.out.println("Expected String: " + expectedString);    Assert.assertEquals(expectedString, escapedString);}
51723bc2a6fb0ac4669ff3afa32dddb4f4605e7f7248a1449579c6d67f6c4d7b
testDateFormatHours
public void testDateFormatHours()
{    String test = "%c";    String escapedString = BucketPath.escapeString(test, headers, true, Calendar.HOUR_OF_DAY, 12);    System.out.println("Escaped String: " + escapedString);    Calendar cal2 = createCalendar(2012, 5, 23, 12, 0, 0, 0, null);    SimpleDateFormat format = new SimpleDateFormat("EEE MMM d HH:mm:ss yyyy");    Date d = new Date(cal2.getTimeInMillis());    String expectedString = format.format(d);    System.out.println("Expected String: " + expectedString);    Assert.assertEquals(expectedString, escapedString);}
857047866f801f9dc57a7f03783fb033a2f46b51ed8b6e0690a365d4a59d27e8
testDateFormatHoursTimeZone
public void testDateFormatHoursTimeZone()
{    String test = "%c";    String escapedString = BucketPath.escapeString(test, headersWithTimeZone, CUSTOM_TIMEZONE, true, Calendar.HOUR_OF_DAY, 12, false);    System.out.println("Escaped String: " + escapedString);    Calendar cal2 = createCalendar(2012, 5, 23, 12, 0, 0, 0, CUSTOM_TIMEZONE);    SimpleDateFormat format = new SimpleDateFormat("EEE MMM d HH:mm:ss yyyy");    format.setTimeZone(CUSTOM_TIMEZONE);    Date d = new Date(cal2.getTimeInMillis());    String expectedString = format.format(d);    System.out.println("Expected String: " + expectedString);    Assert.assertEquals(expectedString, escapedString);}
d4090731e959626a1b7ffb5fa6d934b97315ff2086b9ece81558fc3f9a48a2b6
testDateFormatMinutes
public void testDateFormatMinutes()
{    String test = "%s";    String escapedString = BucketPath.escapeString(test, headers, true, Calendar.MINUTE, 5);    System.out.println("Escaped String: " + escapedString);    Calendar cal2 = createCalendar(2012, 5, 23, 13, 45, 0, 0, null);    String expectedString = String.valueOf(cal2.getTimeInMillis() / 1000);    System.out.println("Expected String: " + expectedString);    Assert.assertEquals(expectedString, escapedString);}
78e0cdd32029586caa4ac4254e57b07a6c2c7033355905d6ae5cff19b403ce1d
testDateFormatMinutesTimeZone
public void testDateFormatMinutesTimeZone()
{    String test = "%s";    String escapedString = BucketPath.escapeString(test, headersWithTimeZone, CUSTOM_TIMEZONE, true, Calendar.MINUTE, 5, false);    System.out.println("Escaped String: " + escapedString);    Calendar cal2 = createCalendar(2012, 5, 23, 13, 45, 0, 0, CUSTOM_TIMEZONE);    String expectedString = String.valueOf(cal2.getTimeInMillis() / 1000);    System.out.println("Expected String: " + expectedString);    Assert.assertEquals(expectedString, escapedString);}
e989a450eab3915fafb60a35c8e19d5c988ec3239d84bbcb564f414cbed46903
testDateFormatSeconds
public void testDateFormatSeconds()
{    String test = "%s";    String escapedString = BucketPath.escapeString(test, headers, true, Calendar.SECOND, 5);    System.out.println("Escaped String: " + escapedString);    Calendar cal2 = createCalendar(2012, 5, 23, 13, 46, 30, 0, null);    String expectedString = String.valueOf(cal2.getTimeInMillis() / 1000);    System.out.println("Expected String: " + expectedString);    Assert.assertEquals(expectedString, escapedString);}
a6045004279c350a31a66c9c858210c5dfd3fb1e5b85f40a72b23d23d5918dd6
testDateFormatSecondsTimeZone
public void testDateFormatSecondsTimeZone()
{    String test = "%s";    String escapedString = BucketPath.escapeString(test, headersWithTimeZone, CUSTOM_TIMEZONE, true, Calendar.SECOND, 5, false);    System.out.println("Escaped String: " + escapedString);    Calendar cal2 = createCalendar(2012, 5, 23, 13, 46, 30, 0, CUSTOM_TIMEZONE);    String expectedString = String.valueOf(cal2.getTimeInMillis() / 1000);    System.out.println("Expected String: " + expectedString);    Assert.assertEquals(expectedString, escapedString);}
cba36c425aa048f98ae78217ec4fddf13a697671271de8f6e1a2a3876a338ccf
testNoRounding
public void testNoRounding()
{    String test = "%c";    String escapedString = BucketPath.escapeString(test, headers, false, Calendar.HOUR_OF_DAY, 12);    System.out.println("Escaped String: " + escapedString);    SimpleDateFormat format = new SimpleDateFormat("EEE MMM d HH:mm:ss yyyy");    Date d = new Date(cal.getTimeInMillis());    String expectedString = format.format(d);    System.out.println("Expected String: " + expectedString);    Assert.assertEquals(expectedString, escapedString);}
519861bb4864e9603c36bdf9701810c9c99ed9d5a4eedfdd668e9d7a6b80fb2e
testNoPadding
public void testNoPadding()
{    Calendar calender;    Map<String, String> calender_timestamp;    calender = Calendar.getInstance();        calender.set(2014, (5 - 1), 3, 13, 46, 33);    calender_timestamp = new HashMap<String, String>();    calender_timestamp.put("timestamp", String.valueOf(calender.getTimeInMillis()));    SimpleDateFormat format = new SimpleDateFormat("M-d");        String test = "%n-%e";    String escapedString = BucketPath.escapeString(test, calender_timestamp, false, Calendar.HOUR_OF_DAY, 12);    Date d = new Date(calender.getTimeInMillis());    String expectedString = format.format(d);        calender.set(2014, (11 - 1), 13, 13, 46, 33);    calender_timestamp.put("timestamp", String.valueOf(calender.getTimeInMillis()));    escapedString += " " + BucketPath.escapeString(test, calender_timestamp, false, Calendar.HOUR_OF_DAY, 12);    System.out.println("Escaped String: " + escapedString);    d = new Date(calender.getTimeInMillis());    expectedString += " " + format.format(d);    System.out.println("Expected String: " + expectedString);    Assert.assertEquals(expectedString, escapedString);}
e2c824ea3ffe9bf28a07eda2adbe2c922f7eb5ce2256360d3a65d38b480eef53
testDateFormatTimeZone
public void testDateFormatTimeZone()
{    TimeZone utcTimeZone = TimeZone.getTimeZone("UTC");    String test = "%c";    String escapedString = BucketPath.escapeString(test, headers, utcTimeZone, false, Calendar.HOUR_OF_DAY, 12, false);    System.out.println("Escaped String: " + escapedString);    SimpleDateFormat format = new SimpleDateFormat("EEE MMM d HH:mm:ss yyyy");    format.setTimeZone(utcTimeZone);    Date d = new Date(cal.getTimeInMillis());    String expectedString = format.format(d);    System.out.println("Expected String: " + expectedString);    Assert.assertEquals(expectedString, escapedString);}
984e7508330b5e52e733122516aaf707d3be8cbf1a01e6ff301f3b43e1138421
testDateRace
public void testDateRace()
{    Clock mockClock = mock(Clock.class);    DateTimeFormatter parser = ISODateTimeFormat.dateTimeParser();    long two = parser.parseMillis("2013-04-21T02:59:59-00:00");    long three = parser.parseMillis("2013-04-21T03:00:00-00:00");    when(mockClock.currentTimeMillis()).thenReturn(two, three);        Clock origClock = BucketPath.getClock();    BucketPath.setClock(mockClock);    String pat = "%H:%M";    String escaped = BucketPath.escapeString(pat, new HashMap<String, String>(), TimeZone.getTimeZone("UTC"), true, Calendar.MINUTE, 10, true);        BucketPath.setClock(origClock);    Assert.assertEquals("Race condition detected", "02:50", escaped);}
03f15ba3e3610d9289cf522c061a6cc7f2b9422fb508f2473e30f632ccbdcb4a
createCalendar
private static Calendar createCalendar(int year, int month, int day, int hour, int minute, int second, int ms, @Nullable TimeZone timeZone)
{    Calendar cal = (timeZone == null) ? Calendar.getInstance() : Calendar.getInstance(timeZone);    cal.set(year, month, day, hour, minute, second);    cal.set(Calendar.MILLISECOND, ms);    return cal;}
70600f9ef48acbdc3d77d3a4ba0b43a1d2c68077aa4be135ba4d252500c40e4d
testStaticEscapeStrings
public void testStaticEscapeStrings()
{    Map<String, String> staticStrings;    staticStrings = new HashMap<>();    try {        InetAddress addr = InetAddress.getLocalHost();        staticStrings.put("localhost", addr.getHostName());        staticStrings.put("IP", addr.getHostAddress());        staticStrings.put("FQDN", addr.getCanonicalHostName());    } catch (UnknownHostException e) {        Assert.fail("Test failed due to UnkownHostException");    }    TimeZone utcTimeZone = TimeZone.getTimeZone("UTC");    String filePath = "%[localhost]/%[IP]/%[FQDN]";    String realPath = BucketPath.escapeString(filePath, headers, utcTimeZone, false, Calendar.HOUR_OF_DAY, 12, false);    String[] args = realPath.split("\\/");    Assert.assertEquals(args[0], staticStrings.get("localhost"));    Assert.assertEquals(args[1], staticStrings.get("IP"));    Assert.assertEquals(args[2], staticStrings.get("FQDN"));    StringBuilder s = new StringBuilder();    s.append("Expected String: ").append(staticStrings.get("localhost"));    s.append("/").append(staticStrings.get("IP")).append("/");    s.append(staticStrings.get("FQDN"));    System.out.println(s);    System.out.println("Escaped String: " + realPath);}
a4a773d0ac04678db5375773135e2f62496d1a3e87159eab54ea43e264ba8e2c
testStaticEscapeStringsNoKey
public void testStaticEscapeStringsNoKey()
{    Map<String, String> staticStrings;    staticStrings = new HashMap<>();    TimeZone utcTimeZone = TimeZone.getTimeZone("UTC");    String filePath = "%[abcdefg]/%[IP]/%[FQDN]";    String realPath = BucketPath.escapeString(filePath, headers, utcTimeZone, false, Calendar.HOUR_OF_DAY, 12, false);}
d2736cb1a1c64615d3e4c0619544e21348d5e5b69c9b67bca5628de60256c11e
getFreePort
private static int getFreePort() throws Exception
{    try (ServerSocket socket = new ServerSocket(0)) {        return socket.getLocalPort();    }}
ce8e84581da859e30f1c3b38747aedb1966873ca63d5023bea721860ac20970d
testJSON
public void testJSON() throws Exception
{    memChannel.setName("memChannel");    pmemChannel.setName("pmemChannel");    Context c = new Context();    Configurables.configure(memChannel, c);    Configurables.configure(pmemChannel, c);    memChannel.start();    pmemChannel.start();    Transaction txn = memChannel.getTransaction();    txn.begin();    memChannel.put(EventBuilder.withBody("blah".getBytes()));    memChannel.put(EventBuilder.withBody("blah".getBytes()));    txn.commit();    txn.close();    txn = memChannel.getTransaction();    txn.begin();    memChannel.take();    txn.commit();    txn.close();    Transaction txn2 = pmemChannel.getTransaction();    txn2.begin();    pmemChannel.put(EventBuilder.withBody("blah".getBytes()));    pmemChannel.put(EventBuilder.withBody("blah".getBytes()));    txn2.commit();    txn2.close();    txn2 = pmemChannel.getTransaction();    txn2.begin();    pmemChannel.take();    txn2.commit();    txn2.close();    testWithPort(getFreePort());    memChannel.stop();    pmemChannel.stop();}
eac70f6fc332b3b76b350f117b0f1470fccfd555ccf72e5372cd1ec666d291d4
testWithPort
private void testWithPort(int port) throws Exception
{    MonitorService srv = new HTTPMetricsServer();    Context context = new Context();    context.put(HTTPMetricsServer.CONFIG_PORT, String.valueOf(port));    srv.configure(context);    srv.start();    Thread.sleep(1000);    URL url = new URL("http://0.0.0.0:" + String.valueOf(port) + "/metrics");    HttpURLConnection conn = (HttpURLConnection) url.openConnection();    conn.setRequestMethod("GET");    BufferedReader reader = new BufferedReader(new InputStreamReader(conn.getInputStream()));    String line;    String result = "";    while ((line = reader.readLine()) != null) {        result += line;    }    reader.close();    Map<String, Map<String, String>> mbeans = gson.fromJson(result, mapType);    Assert.assertNotNull(mbeans);    Map<String, String> memBean = mbeans.get("CHANNEL.memChannel");    Assert.assertNotNull(memBean);    JMXTestUtils.checkChannelCounterParams(memBean);    Map<String, String> pmemBean = mbeans.get("CHANNEL.pmemChannel");    Assert.assertNotNull(pmemBean);    JMXTestUtils.checkChannelCounterParams(pmemBean);    srv.stop();}
9fed529ed01a24e35ecf5b44992de2269e79aa485c2d1989ffb5abac0df57bfd
testTrace
public void testTrace() throws Exception
{    doTestForbiddenMethods(getFreePort(), "TRACE");}
8d5a1c70a5a42dfccd954328a6fb267785f09d415e93df22f7b7e578bd4bf938
testOptions
public void testOptions() throws Exception
{    doTestForbiddenMethods(getFreePort(), "OPTIONS");}
5963dd20d8b6d331fdac87ee1c1c55cf97d350a87b6aebce494ad35f8aea8685
doTestForbiddenMethods
public void doTestForbiddenMethods(int port, String method) throws Exception
{    MonitorService srv = new HTTPMetricsServer();    Context context = new Context();    context.put(HTTPMetricsServer.CONFIG_PORT, String.valueOf(port));    srv.configure(context);    srv.start();    Thread.sleep(1000);    URL url = new URL("http://0.0.0.0:" + String.valueOf(port) + "/metrics");    HttpURLConnection conn = (HttpURLConnection) url.openConnection();    conn.setRequestMethod(method);    Assert.assertEquals(HttpServletResponse.SC_FORBIDDEN, conn.getResponseCode());    srv.stop();}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    counter = new KafkaSourceCounter("test");}
334f4e20dacde2c6a9a3d1fe64bd06ce0411a03b0f96279e17080abb8f0007c2
testAddToKafkaEventGetTimer
public void testAddToKafkaEventGetTimer() throws Exception
{    Assert.assertEquals(1L, counter.addToKafkaEventGetTimer(1L));}
e498876e22801a0a2e52b3a18cd235d24427c4c159c8a47ce44de88e6b7ee753
testAddToKafkaCommitTimer
public void testAddToKafkaCommitTimer() throws Exception
{    Assert.assertEquals(1L, counter.addToKafkaCommitTimer(1L));}
29641fe9cd75c94140ead846f56f7f9d3c666b4a7a808c319e5b7776b67ada01
testIncrementKafkaEmptyCount
public void testIncrementKafkaEmptyCount() throws Exception
{    Assert.assertEquals(1L, counter.incrementKafkaEmptyCount());}
76c1491372e4c5347f67b03784ce16e103938c2f23578e81cb7b940d92cda084
testGetKafkaCommitTimer
public void testGetKafkaCommitTimer() throws Exception
{    Assert.assertEquals(0, counter.getKafkaCommitTimer());}
830df667825b07a9e478be5b04ac5f929ca684865e81c81abebc48407541f1a1
testGetKafkaEventGetTimer
public void testGetKafkaEventGetTimer() throws Exception
{    Assert.assertEquals(0, counter.getKafkaEventGetTimer());}
f5245f2f5292e0029d83b6fdf2956d6fe4381831ec99e98e91427d4c2fa97ecb
testGetKafkaEmptyCount
public void testGetKafkaEmptyCount() throws Exception
{    Assert.assertEquals(0, counter.getKafkaEmptyCount());}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    mbServer = ManagementFactory.getPlatformMBeanServer();    random = new Random(System.nanoTime());}
fe712d02ff622ac27c6bc05f9888b7a0826e0ebba0aed5c88f27ed004aecaa00
testSinkCounter
public void testSinkCounter() throws Exception
{    String name = getRandomName();    SinkCounter skc = new SinkCounter(name);    skc.register();    ObjectName on = new ObjectName(SINK_OBJ_NAME_PREFIX + name);    assertSkCounterState(on, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L);    skc.start();    long start1 = getStartTime(on);    Assert.assertTrue("StartTime", start1 != 0L);    Assert.assertTrue("StopTime", getStopTime(on) == 0L);    int connCreated = random.nextInt(MAX_BOUNDS);    int connClosed = random.nextInt(MAX_BOUNDS);    int connFailed = random.nextInt(MAX_BOUNDS);    int batchEmpty = random.nextInt(MAX_BOUNDS);    int batchUnderflow = random.nextInt(MAX_BOUNDS);    int batchComplete = random.nextInt(MAX_BOUNDS);    int eventDrainAttempt = random.nextInt(MAX_BOUNDS);    int eventDrainSuccess = random.nextInt(MAX_BOUNDS);    for (int i = 0; i < connCreated; i++) {        skc.incrementConnectionCreatedCount();    }    for (int i = 0; i < connClosed; i++) {        skc.incrementConnectionClosedCount();    }    for (int i = 0; i < connFailed; i++) {        skc.incrementConnectionFailedCount();    }    for (int i = 0; i < batchEmpty; i++) {        skc.incrementBatchEmptyCount();    }    for (int i = 0; i < batchUnderflow; i++) {        skc.incrementBatchUnderflowCount();    }    for (int i = 0; i < batchComplete; i++) {        skc.incrementBatchCompleteCount();    }    for (int i = 0; i < eventDrainAttempt; i++) {        skc.incrementEventDrainAttemptCount();    }    for (int i = 0; i < eventDrainSuccess; i++) {        skc.incrementEventDrainSuccessCount();    }    assertSkCounterState(on, connCreated, connClosed, connFailed, batchEmpty, batchUnderflow, batchComplete, eventDrainAttempt, eventDrainSuccess);    skc.stop();    Assert.assertTrue("StartTime", getStartTime(on) != 0L);    Assert.assertTrue("StopTime", getStopTime(on) != 0L);    assertSkCounterState(on, connCreated, connClosed, connFailed, batchEmpty, batchUnderflow, batchComplete, eventDrainAttempt, eventDrainSuccess);        Thread.sleep(5L);    skc.start();    Assert.assertTrue("StartTime", getStartTime(on) != 0L);    Assert.assertTrue("StartTime", getStartTime(on) > start1);    Assert.assertTrue("StopTime", getStopTime(on) == 0L);    assertSkCounterState(on, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L);    int eventDrainAttempt2 = random.nextInt(MAX_BOUNDS);    int eventDrainSuccess2 = random.nextInt(MAX_BOUNDS);    skc.addToEventDrainAttemptCount(eventDrainAttempt2);    skc.addToEventDrainSuccessCount(eventDrainSuccess2);    assertSkCounterState(on, 0L, 0L, 0L, 0L, 0L, 0L, eventDrainAttempt2, eventDrainSuccess2);}
2dce4ae7aea5ea8ef90c327f8a3deae5d35b66dd89d2780cd871a38e8ec5f677
testChannelCounter
public void testChannelCounter() throws Exception
{    String name = getRandomName();    ChannelCounter chc = new ChannelCounter(name);    chc.register();    ObjectName on = new ObjectName(CHANNEL_OBJ_NAME_PREFIX + name);    assertChCounterState(on, 0L, 0L, 0L, 0L, 0L);    Assert.assertTrue("StartTime", getStartTime(on) == 0L);    Assert.assertTrue("StopTime", getStopTime(on) == 0L);    chc.start();    long start1 = getStartTime(on);    Assert.assertTrue("StartTime", start1 != 0L);    Assert.assertTrue("StopTime", getStopTime(on) == 0L);    int numChannelSize = random.nextInt(MAX_BOUNDS);    int numEventPutAttempt = random.nextInt(MAX_BOUNDS);    int numEventTakeAttempt = random.nextInt(MAX_BOUNDS);    int numEventPutSuccess = random.nextInt(MAX_BOUNDS);    int numEventTakeSuccess = random.nextInt(MAX_BOUNDS);    chc.setChannelSize(numChannelSize);    for (int i = 0; i < numEventPutAttempt; i++) {        chc.incrementEventPutAttemptCount();    }    for (int i = 0; i < numEventTakeAttempt; i++) {        chc.incrementEventTakeAttemptCount();    }    chc.addToEventPutSuccessCount(numEventPutSuccess);    chc.addToEventTakeSuccessCount(numEventTakeSuccess);    assertChCounterState(on, numChannelSize, numEventPutAttempt, numEventTakeAttempt, numEventPutSuccess, numEventTakeSuccess);    chc.stop();    Assert.assertTrue("StartTime", getStartTime(on) != 0L);    Assert.assertTrue("StopTime", getStopTime(on) != 0L);    assertChCounterState(on, numChannelSize, numEventPutAttempt, numEventTakeAttempt, numEventPutSuccess, numEventTakeSuccess);        Thread.sleep(5L);    chc.start();    Assert.assertTrue("StartTime", getStartTime(on) != 0L);    Assert.assertTrue("StartTime", getStartTime(on) > start1);    Assert.assertTrue("StopTime", getStopTime(on) == 0L);    assertChCounterState(on, 0L, 0L, 0L, 0L, 0L);}
bb4bd0cd6601ca643d38b7b6af1486643afa178a932dcd39ed591c9f29591e60
testSourceCounter
public void testSourceCounter() throws Exception
{    String name = getRandomName();    SourceCounter srcc = new SourceCounter(name);    srcc.register();    ObjectName on = new ObjectName(SOURCE_OBJ_NAME_PREFIX + name);    assertSrcCounterState(on, 0L, 0L, 0L, 0L, 0L, 0L);    Assert.assertTrue("StartTime", getStartTime(on) == 0L);    Assert.assertTrue("StopTime", getStopTime(on) == 0L);    srcc.start();    long start1 = getStartTime(on);    Assert.assertTrue("StartTime", start1 != 0L);    Assert.assertTrue("StopTime", getStopTime(on) == 0L);    int numEventReceived = random.nextInt(MAX_BOUNDS);    int numEventAccepted = random.nextInt(MAX_BOUNDS);    int numAppendReceived = random.nextInt(MAX_BOUNDS);    int numAppendAccepted = random.nextInt(MAX_BOUNDS);    int numAppendBatchReceived = random.nextInt(MAX_BOUNDS);    int numAppendBatchAccepted = random.nextInt(MAX_BOUNDS);    srcc.addToEventReceivedCount(numEventReceived);    srcc.addToEventAcceptedCount(numEventAccepted);    for (int i = 0; i < numAppendReceived; i++) {        srcc.incrementAppendReceivedCount();    }    for (int i = 0; i < numAppendAccepted; i++) {        srcc.incrementAppendAcceptedCount();    }    for (int i = 0; i < numAppendBatchReceived; i++) {        srcc.incrementAppendBatchReceivedCount();    }    for (int i = 0; i < numAppendBatchAccepted; i++) {        srcc.incrementAppendBatchAcceptedCount();    }    assertSrcCounterState(on, numEventReceived, numEventAccepted, numAppendReceived, numAppendAccepted, numAppendBatchReceived, numAppendBatchAccepted);    srcc.stop();    Assert.assertTrue("StartTime", getStartTime(on) != 0L);    Assert.assertTrue("StopTime", getStopTime(on) != 0L);    assertSrcCounterState(on, numEventReceived, numEventAccepted, numAppendReceived, numAppendAccepted, numAppendBatchReceived, numAppendBatchAccepted);        Thread.sleep(5L);    srcc.start();    Assert.assertTrue("StartTime", getStartTime(on) != 0L);    Assert.assertTrue("StartTime", getStartTime(on) > start1);    Assert.assertTrue("StopTime", getStopTime(on) == 0L);    assertSrcCounterState(on, 0L, 0L, 0L, 0L, 0L, 0L);    int numEventReceived2 = random.nextInt(MAX_BOUNDS);    int numEventAccepted2 = random.nextInt(MAX_BOUNDS);    for (int i = 0; i < numEventReceived2; i++) {        srcc.incrementEventReceivedCount();    }    for (int i = 0; i < numEventAccepted2; i++) {        srcc.incrementEventAcceptedCount();    }    assertSrcCounterState(on, numEventReceived2, numEventAccepted2, 0L, 0L, 0L, 0L);}
2ca038c4e37be0459dd69171025b56ad9f8d65b906af0995a34fc51a7b7b1bd4
testRegisterTwice
public void testRegisterTwice() throws Exception
{    String name = "re-register-" + getRandomName();    SourceCounter c1 = new SourceCounter(name);    c1.register();    ObjectName on = new ObjectName(SOURCE_OBJ_NAME_PREFIX + name);    Assert.assertEquals("StartTime", 0L, getStartTime(on));    Assert.assertEquals("StopTime", 0L, getStopTime(on));    c1.start();    c1.stop();    Assert.assertTrue("StartTime", getStartTime(on) > 0L);    Assert.assertTrue("StopTime", getStopTime(on) > 0L);    SourceCounter c2 = new SourceCounter(name);    c2.register();    Assert.assertEquals("StartTime", 0L, getStartTime(on));    Assert.assertEquals("StopTime", 0L, getStopTime(on));}
f6162e98abad53c27e838a08e87aaab9f369adb4b6b31601adc03b5a5b8d91d2
assertSrcCounterState
private void assertSrcCounterState(ObjectName on, long eventReceivedCount, long eventAcceptedCount, long appendReceivedCount, long appendAcceptedCount, long appendBatchReceivedCount, long appendBatchAcceptedCount) throws Exception
{    Assert.assertEquals("SrcEventReceived", getSrcEventReceivedCount(on), eventReceivedCount);    Assert.assertEquals("SrcEventAccepted", getSrcEventAcceptedCount(on), eventAcceptedCount);    Assert.assertEquals("SrcAppendReceived", getSrcAppendReceivedCount(on), appendReceivedCount);    Assert.assertEquals("SrcAppendAccepted", getSrcAppendAcceptedCount(on), appendAcceptedCount);    Assert.assertEquals("SrcAppendBatchReceived", getSrcAppendBatchReceivedCount(on), appendBatchReceivedCount);    Assert.assertEquals("SrcAppendBatchAccepted", getSrcAppendBatchAcceptedCount(on), appendBatchAcceptedCount);}
33be48cd86441c713baceded9f89258f6b93148d20a4ede908e5ae18afe44f7e
assertChCounterState
private void assertChCounterState(ObjectName on, long channelSize, long eventPutAttempt, long eventTakeAttempt, long eventPutSuccess, long eventTakeSuccess) throws Exception
{    Assert.assertEquals("ChChannelSize", getChChannelSize(on), channelSize);    Assert.assertEquals("ChEventPutAttempt", getChEventPutAttempt(on), eventPutAttempt);    Assert.assertEquals("ChEventTakeAttempt", getChEventTakeAttempt(on), eventTakeAttempt);    Assert.assertEquals("ChEventPutSuccess", getChEventPutSuccess(on), eventPutSuccess);    Assert.assertEquals("ChEventTakeSuccess", getChEventTakeSuccess(on), eventTakeSuccess);}
7dad12d63ce64a52359e05d513c13b76063ceacb966773b84390f3d1434cf45c
assertSkCounterState
private void assertSkCounterState(ObjectName on, long connCreated, long connClosed, long connFailed, long batchEmpty, long batchUnderflow, long batchComplete, long eventDrainAttempt, long eventDrainSuccess) throws Exception
{    Assert.assertEquals("SkConnCreated", getSkConnectionCreated(on), connCreated);    Assert.assertEquals("SkConnClosed", getSkConnectionClosed(on), connClosed);    Assert.assertEquals("SkConnFailed", getSkConnectionFailed(on), connFailed);    Assert.assertEquals("SkBatchEmpty", getSkBatchEmpty(on), batchEmpty);    Assert.assertEquals("SkBatchUnderflow", getSkBatchUnderflow(on), batchUnderflow);    Assert.assertEquals("SkBatchComplete", getSkBatchComplete(on), batchComplete);    Assert.assertEquals("SkEventDrainAttempt", getSkEventDrainAttempt(on), eventDrainAttempt);    Assert.assertEquals("SkEventDrainSuccess", getSkEventDrainSuccess(on), eventDrainSuccess);}
18cd215761385469f90e404ce3b9a77893b130350a233e82f2eed1a9d3617a28
getStartTime
private long getStartTime(ObjectName on) throws Exception
{    return getLongAttribute(on, ATTR_START_TIME);}
3df52b6910a4e67dd3c7a1a48325d4b203a3f7ec33ba2d8f139738907d6fea96
getStopTime
private long getStopTime(ObjectName on) throws Exception
{    return getLongAttribute(on, ATTR_STOP_TIME);}
76015e9668fc6d96f1a18749495d7f303ddde77597c67a225dba09528fbb1385
getSkConnectionCreated
private long getSkConnectionCreated(ObjectName on) throws Exception
{    return getLongAttribute(on, SK_ATTR_CONN_CREATED);}
1f6ccb0748ca91e157d6af8d5d9c592b70922647a5c10cda32eac69577601be1
getSkConnectionClosed
private long getSkConnectionClosed(ObjectName on) throws Exception
{    return getLongAttribute(on, SK_ATTR_CONN_CLOSED);}
7bdc38d07513d84c95d082a77613f4992ec35c5bff9247d515421a64dc8175bb
getSkConnectionFailed
private long getSkConnectionFailed(ObjectName on) throws Exception
{    return getLongAttribute(on, SK_ATTR_CONN_FAILED);}
7a5819b1c3ddfe094364efa9fca49d38d1d16495f9deb6a1160230d19fdbbe9c
getSkBatchEmpty
private long getSkBatchEmpty(ObjectName on) throws Exception
{    return getLongAttribute(on, SK_ATTR_BATCH_EMPTY);}
3372854de341ceeb09d007502d94932f74c2e9f30b40b8a34e0e62048f2df801
getSkBatchUnderflow
private long getSkBatchUnderflow(ObjectName on) throws Exception
{    return getLongAttribute(on, SK_ATTR_BATCH_UNDERFLOW);}
9d636e38f21a994c07e1741a5e2092f8c598de57287e8e26bef687ad4b093a0c
getSkBatchComplete
private long getSkBatchComplete(ObjectName on) throws Exception
{    return getLongAttribute(on, SK_ATTR_BATCH_COMPLETE);}
3a73be83f58fc75bd55184c4cbd9a22042428f26ce96b8a523072470e3191af6
getSkEventDrainAttempt
private long getSkEventDrainAttempt(ObjectName on) throws Exception
{    return getLongAttribute(on, SK_ATTR_EVENT_DRAIN_ATTEMPT);}
58b2a28c8ba920b9993c38984f92f483e6b06454a32cba5eaf209dd3bb2e0d77
getSkEventDrainSuccess
private long getSkEventDrainSuccess(ObjectName on) throws Exception
{    return getLongAttribute(on, SK_ATTR_EVENT_DRAIN_SUCCESS);}
866ea1ed3e78a7c4cb2c8c39b98d1387a9913a26f61d8fb4ce65627d4e4868fc
getChChannelSize
private long getChChannelSize(ObjectName on) throws Exception
{    return getLongAttribute(on, CH_ATTR_CHANNEL_SIZE);}
b97672be504f42dc7db482bd78296b4dad78fbf9a0f4bfad9e840a709a551c7a
getChEventPutAttempt
private long getChEventPutAttempt(ObjectName on) throws Exception
{    return getLongAttribute(on, CH_ATTR_EVENT_PUT_ATTEMPT);}
f3e54cae2592419afc5b6e32076fc3660ea0569340eccb126076d7df1b8cbaa8
getChEventTakeAttempt
private long getChEventTakeAttempt(ObjectName on) throws Exception
{    return getLongAttribute(on, CH_ATTR_EVENT_TAKE_ATTEMPT);}
fac6e82e55260bfe6e9a1a37440988c60213e160f76c240742cc49679adc0bcb
getChEventPutSuccess
private long getChEventPutSuccess(ObjectName on) throws Exception
{    return getLongAttribute(on, CH_ATTR_EVENT_PUT_SUCCESS);}
139d26561187f1651ca91025bd3e12757d358dd35c705d0871f6fc0bd3b6f9f6
getChEventTakeSuccess
private long getChEventTakeSuccess(ObjectName on) throws Exception
{    return getLongAttribute(on, CH_ATTR_EVENT_TAKE_SUCCESS);}
b94691363a043247db55f99a329b1c502270f5ec1a59fd2e7c98696b4f890110
getSrcAppendBatchAcceptedCount
private long getSrcAppendBatchAcceptedCount(ObjectName on) throws Exception
{    return getLongAttribute(on, SRC_ATTR_APPEND_BATCH_ACCEPTED_COUNT);}
c9902b11e4278a735830f45c429cf2afebdc99f5ec2349c64d14a1e69c8ff5a7
getSrcAppendBatchReceivedCount
private long getSrcAppendBatchReceivedCount(ObjectName on) throws Exception
{    return getLongAttribute(on, SRC_ATTR_APPEND_BATCH_RECEVIED_COUNT);}
878b6b53d08cb6ca5fd993c343948a1a6f61aafd6ef4b568faa20e1d9145a503
getSrcAppendAcceptedCount
private long getSrcAppendAcceptedCount(ObjectName on) throws Exception
{    return getLongAttribute(on, SRC_ATTR_APPEND_ACCEPTED_COUNT);}
01bdf395f20483fb28af2486a0398ce16fd8cf13cc99469ba3a4a75a0f0901fe
getSrcAppendReceivedCount
private long getSrcAppendReceivedCount(ObjectName on) throws Exception
{    return getLongAttribute(on, SRC_ATTR_APPEND_RECEVIED_COUNT);}
7416e412e7ad1089afc2c9a1f1b0a5ca2da81a78e8a08ab5b773f6b9337c1c2a
getSrcEventAcceptedCount
private long getSrcEventAcceptedCount(ObjectName on) throws Exception
{    return getLongAttribute(on, SRC_ATTR_EVENT_ACCEPTED_COUNT);}
2f3357264c35606170cdf8fa4d90c5fa81c5b6decdc3c8771ef1ab04b6bf5fa5
getSrcEventReceivedCount
private long getSrcEventReceivedCount(ObjectName on) throws Exception
{    return getLongAttribute(on, SRC_ATTR_EVENT_RECEVIED_COUNT);}
beaaf0a870f9d45c96175ef744d053726e088aad752ee4c41b99c40188f09b8f
getLongAttribute
private long getLongAttribute(ObjectName on, String attr) throws Exception
{    Object result = getAttribute(on, attr);    return ((Long) result).longValue();}
feb102c6c48f05b509cdad92101e1f2fcb411b808a1a865505cd131588c0a3d1
getAttribute
private Object getAttribute(ObjectName objName, String attrName) throws Exception
{    return mbServer.getAttribute(objName, attrName);}
a17bc71f48bdda511a729ab27f5958bb8fecba5f501fd0a99589738254db9683
getRandomName
private String getRandomName()
{    return "random-" + System.nanoTime();}
7d5f1259f244a1d3309b30d181432ee48d53e183d9f266e40b040808564a6db2
checkChannelCounterParams
public static void checkChannelCounterParams(Map<String, String> attrs)
{    Assert.assertNotNull(attrs.get("StartTime"));    Assert.assertNotNull(attrs.get("StopTime"));    Assert.assertTrue(Long.parseLong(attrs.get("ChannelSize")) != 0);    Assert.assertTrue(Long.parseLong(attrs.get("EventPutAttemptCount")) == 2);    Assert.assertTrue(Long.parseLong(attrs.get("EventTakeAttemptCount")) == 1);    Assert.assertTrue(Long.parseLong(attrs.get("EventPutSuccessCount")) == 2);    Assert.assertTrue(Long.parseLong(attrs.get("EventTakeSuccessCount")) == 1);}
71ef2edc2d0dc30dd8ae55058d505233a88f6dadbe0ccd81c8ee923c1bd0e196
testJMXPoll
public void testJMXPoll()
{    memChannel.setName("memChannel");    pmemChannel.setName("pmemChannel");    Context c = new Context();    Configurables.configure(memChannel, c);    Configurables.configure(pmemChannel, c);    memChannel.start();    pmemChannel.start();    Transaction txn = memChannel.getTransaction();    txn.begin();    memChannel.put(EventBuilder.withBody("blah".getBytes()));    memChannel.put(EventBuilder.withBody("blah".getBytes()));    txn.commit();    txn.close();    txn = memChannel.getTransaction();    txn.begin();    memChannel.take();    txn.commit();    txn.close();    Transaction txn2 = pmemChannel.getTransaction();    txn2.begin();    pmemChannel.put(EventBuilder.withBody("blah".getBytes()));    pmemChannel.put(EventBuilder.withBody("blah".getBytes()));    txn2.commit();    txn2.close();    txn2 = pmemChannel.getTransaction();    txn2.begin();    pmemChannel.take();    txn2.commit();    txn2.close();    Map<String, Map<String, String>> mbeans = JMXPollUtil.getAllMBeans();    Assert.assertNotNull(mbeans);    Map<String, String> memBean = mbeans.get("CHANNEL.memChannel");    Assert.assertNotNull(memBean);    JMXTestUtils.checkChannelCounterParams(memBean);    Map<String, String> pmemBean = mbeans.get("CHANNEL.pmemChannel");    Assert.assertNotNull(pmemBean);    JMXTestUtils.checkChannelCounterParams(pmemBean);    memChannel.stop();    pmemChannel.stop();}
46ffa8d56c2364376c7a2fb00ff1e97ead501825886406f582f8797ba07e934c
initialize
public void initialize()
{}
fa63d27bd1bea8d2c8a54d25059a5646f17912afe7a54c75ebd7cfd8635b0016
intercept
public Event intercept(Event event)
{    Map<String, String> headers = event.getHeaders();    if (headers.containsKey("Bad-Words")) {        headers.remove("Bad-Words");    }    return event;}
b7fd8a02f88da0ddad8327ade8d4986c180b70eb77329c7227efb6274c9c0a2b
intercept
public List<Event> intercept(List<Event> events)
{    for (Event e : events) {        intercept(e);    }    return events;}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{}
17b740b5f67eb00407e17fdf73a9126423f207c9cfe5b24f2166c823c2b8ee22
build
public Interceptor build()
{    return new CensoringInterceptor();}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{}
c4836a4637f89ec6d26616b68b633ef6239fe905afea41d706acbf848dce5eec
buildEventWithHeader
private Event buildEventWithHeader()
{    return EventBuilder.withBody("My test event".getBytes(), ImmutableMap.of(HEADER1, HEADER1, HEADER2, HEADER2, HEADER3, HEADER3, HEADER4, HEADER4, HEADER5, HEADER5));}
125e6af9db34c9dba24b7e1782480ea4f1cac1b8a8744ce7c307497cb3685200
buildEventWithoutHeader
private Event buildEventWithoutHeader()
{    return EventBuilder.withBody("My test event".getBytes());}
b2a1f6bc9b7616b1370fe3fc1c2058ecebb3e372234596a417d84a5df80b02bc
testBadConfig
public void testBadConfig() throws Exception
{    new RemoveHeaderIntBuilder().fromList(HEADER1, "(").build();}
071cce1d655e5dbf943da9421946a67743db208e7bf8e98277acb3fa078d1a73
testWithName
public void testWithName() throws IllegalAccessException, ClassNotFoundException, InstantiationException
{    final Interceptor removeHeaderInterceptor = new RemoveHeaderIntBuilder().withName(HEADER4).build();    final Event event1 = buildEventWithHeader();    Assert.assertEquals(HEADER1, event1.getHeaders().get(HEADER1));    Assert.assertEquals(HEADER2, event1.getHeaders().get(HEADER2));    Assert.assertEquals(HEADER3, event1.getHeaders().get(HEADER3));    Assert.assertEquals(HEADER4, event1.getHeaders().get(HEADER4));    Assert.assertEquals(HEADER5, event1.getHeaders().get(HEADER5));    removeHeaderInterceptor.intercept(event1);    Assert.assertEquals(HEADER1, event1.getHeaders().get(HEADER1));    Assert.assertEquals(HEADER2, event1.getHeaders().get(HEADER2));    Assert.assertEquals(HEADER3, event1.getHeaders().get(HEADER3));    Assert.assertNull(event1.getHeaders().get(HEADER4));    Assert.assertEquals(HEADER5, event1.getHeaders().get(HEADER5));    final Event event2 = buildEventWithoutHeader();    Assert.assertTrue(event2.getHeaders().isEmpty());    removeHeaderInterceptor.intercept(event2);    Assert.assertTrue(event2.getHeaders().isEmpty());}
19e4198e3d4e3a7960772f765264ab7df12df4e5a5e101a92ee28d400ac64008
testFromListWithDefaultSeparator1
public void testFromListWithDefaultSeparator1() throws Exception
{    final Interceptor removeHeaderInterceptor = new RemoveHeaderIntBuilder().fromList(HEADER4 + MY_SEPARATOR + HEADER2).build();    final Event event1 = buildEventWithHeader();    Assert.assertEquals(HEADER1, event1.getHeaders().get(HEADER1));    Assert.assertEquals(HEADER2, event1.getHeaders().get(HEADER2));    Assert.assertEquals(HEADER3, event1.getHeaders().get(HEADER3));    Assert.assertEquals(HEADER4, event1.getHeaders().get(HEADER4));    Assert.assertEquals(HEADER5, event1.getHeaders().get(HEADER5));    removeHeaderInterceptor.intercept(event1);    Assert.assertEquals(HEADER1, event1.getHeaders().get(HEADER1));    Assert.assertEquals(HEADER2, event1.getHeaders().get(HEADER2));    Assert.assertEquals(HEADER3, event1.getHeaders().get(HEADER3));    Assert.assertEquals(HEADER4, event1.getHeaders().get(HEADER4));    Assert.assertEquals(HEADER5, event1.getHeaders().get(HEADER5));    final Event event2 = buildEventWithoutHeader();    Assert.assertTrue(event2.getHeaders().isEmpty());    removeHeaderInterceptor.intercept(event2);    Assert.assertTrue(event2.getHeaders().isEmpty());}
27a830b5e4ffa0b61b21a6a6a2346f7edefc1cfced78b3da75394e2747cbe224
testFromListWithDefaultSeparator2
public void testFromListWithDefaultSeparator2() throws Exception
{    final Interceptor removeHeaderInterceptor = new RemoveHeaderIntBuilder().fromList(HEADER4 + DEFAULT_SEPARATOR + HEADER2).build();    final Event event1 = buildEventWithHeader();    Assert.assertEquals(HEADER1, event1.getHeaders().get(HEADER1));    Assert.assertEquals(HEADER2, event1.getHeaders().get(HEADER2));    Assert.assertEquals(HEADER3, event1.getHeaders().get(HEADER3));    Assert.assertEquals(HEADER4, event1.getHeaders().get(HEADER4));    Assert.assertEquals(HEADER5, event1.getHeaders().get(HEADER5));    removeHeaderInterceptor.intercept(event1);    Assert.assertEquals(HEADER1, event1.getHeaders().get(HEADER1));    Assert.assertNull(event1.getHeaders().get(HEADER2));    Assert.assertEquals(HEADER3, event1.getHeaders().get(HEADER3));    Assert.assertNull(event1.getHeaders().get(HEADER4));    Assert.assertEquals(HEADER5, event1.getHeaders().get(HEADER5));    final Event event2 = buildEventWithoutHeader();    Assert.assertTrue(event2.getHeaders().isEmpty());    removeHeaderInterceptor.intercept(event2);    Assert.assertTrue(event2.getHeaders().isEmpty());}
2b160d2865492a0ecae148639301d51572892be16830dc2ec39ab9b585915428
testFromListWithCustomSeparator1
public void testFromListWithCustomSeparator1() throws Exception
{    final Interceptor removeHeaderInterceptor = new RemoveHeaderIntBuilder().fromList(HEADER4 + MY_SEPARATOR + HEADER2, MY_SEPARATOR).build();    final Event event1 = buildEventWithHeader();    Assert.assertEquals(HEADER1, event1.getHeaders().get(HEADER1));    Assert.assertEquals(HEADER2, event1.getHeaders().get(HEADER2));    Assert.assertEquals(HEADER3, event1.getHeaders().get(HEADER3));    Assert.assertEquals(HEADER4, event1.getHeaders().get(HEADER4));    Assert.assertEquals(HEADER5, event1.getHeaders().get(HEADER5));    removeHeaderInterceptor.intercept(event1);    Assert.assertEquals(HEADER1, event1.getHeaders().get(HEADER1));    Assert.assertNull(event1.getHeaders().get(HEADER2));    Assert.assertEquals(HEADER3, event1.getHeaders().get(HEADER3));    Assert.assertNull(event1.getHeaders().get(HEADER4));    Assert.assertEquals(HEADER5, event1.getHeaders().get(HEADER5));    final Event event2 = buildEventWithoutHeader();    Assert.assertTrue(event2.getHeaders().isEmpty());    removeHeaderInterceptor.intercept(event2);    Assert.assertTrue(event2.getHeaders().isEmpty());}
43c2da7f0ad617ccb84277fa5bbed015711e79023db3e6580b539a353635a52b
testFromListWithCustomSeparator2
public void testFromListWithCustomSeparator2() throws Exception
{    final Interceptor removeHeaderInterceptor = new RemoveHeaderIntBuilder().fromList(HEADER4 + DEFAULT_SEPARATOR + HEADER2, MY_SEPARATOR).build();    final Event event1 = buildEventWithHeader();    Assert.assertEquals(HEADER1, event1.getHeaders().get(HEADER1));    Assert.assertEquals(HEADER2, event1.getHeaders().get(HEADER2));    Assert.assertEquals(HEADER3, event1.getHeaders().get(HEADER3));    Assert.assertEquals(HEADER4, event1.getHeaders().get(HEADER4));    Assert.assertEquals(HEADER5, event1.getHeaders().get(HEADER5));    removeHeaderInterceptor.intercept(event1);    Assert.assertEquals(HEADER1, event1.getHeaders().get(HEADER1));    Assert.assertEquals(HEADER2, event1.getHeaders().get(HEADER2));    Assert.assertEquals(HEADER3, event1.getHeaders().get(HEADER3));    Assert.assertEquals(HEADER4, event1.getHeaders().get(HEADER4));    Assert.assertEquals(HEADER5, event1.getHeaders().get(HEADER5));    final Event event2 = buildEventWithoutHeader();    Assert.assertTrue(event2.getHeaders().isEmpty());    removeHeaderInterceptor.intercept(event2);    Assert.assertTrue(event2.getHeaders().isEmpty());}
76bc921f96e14f1c36a5fbeabb776b3031d2137e4503c2518823ec11ea451c38
testMatchRegex
public void testMatchRegex() throws Exception
{    final Interceptor removeHeaderInterceptor = new RemoveHeaderIntBuilder().matchRegex("my-header1.*").build();    final Event event1 = buildEventWithHeader();    Assert.assertEquals(HEADER1, event1.getHeaders().get(HEADER1));    Assert.assertEquals(HEADER2, event1.getHeaders().get(HEADER2));    Assert.assertEquals(HEADER3, event1.getHeaders().get(HEADER3));    Assert.assertEquals(HEADER4, event1.getHeaders().get(HEADER4));    Assert.assertEquals(HEADER5, event1.getHeaders().get(HEADER5));    removeHeaderInterceptor.intercept(event1);    Assert.assertNull(event1.getHeaders().get(HEADER1));    Assert.assertNull(event1.getHeaders().get(HEADER2));    Assert.assertNull(event1.getHeaders().get(HEADER3));    Assert.assertEquals(HEADER4, event1.getHeaders().get(HEADER4));    Assert.assertEquals(HEADER5, event1.getHeaders().get(HEADER5));    final Event event2 = buildEventWithoutHeader();    Assert.assertTrue(event2.getHeaders().isEmpty());    removeHeaderInterceptor.intercept(event2);    Assert.assertTrue(event2.getHeaders().isEmpty());}
049782c18fbdd6792746a664b16dbfa70b182a95d81c55926e8a18c2ab90c21b
testAll
public void testAll() throws Exception
{    final Interceptor removeHeaderInterceptor = new RemoveHeaderIntBuilder().matchRegex("my-header2.*").fromList(HEADER1 + MY_SEPARATOR + HEADER3, MY_SEPARATOR).withName(HEADER2).build();    final Event event1 = buildEventWithHeader();    Assert.assertEquals(HEADER1, event1.getHeaders().get(HEADER1));    Assert.assertEquals(HEADER2, event1.getHeaders().get(HEADER2));    Assert.assertEquals(HEADER3, event1.getHeaders().get(HEADER3));    Assert.assertEquals(HEADER4, event1.getHeaders().get(HEADER4));    Assert.assertEquals(HEADER5, event1.getHeaders().get(HEADER5));    removeHeaderInterceptor.intercept(event1);    Assert.assertTrue(event1.getHeaders().isEmpty());    final Event event2 = buildEventWithoutHeader();    Assert.assertTrue(event2.getHeaders().isEmpty());    removeHeaderInterceptor.intercept(event2);    Assert.assertTrue(event2.getHeaders().isEmpty());}
c6e505dc98c03a4e81e0582cc3f136940c23b7dc9a9893b7108d0d58b8e7a7dd
withName
 RemoveHeaderIntBuilder withName(final String str)
{    contextMap.put(RemoveHeaderInterceptor.WITH_NAME, str);    return this;}
80a356ac9b5114d1ba68694a7fd2dc659e00bed3d3a1b7d5eaf0e1e523a30760
fromList
 RemoveHeaderIntBuilder fromList(final String str)
{    contextMap.put(RemoveHeaderInterceptor.FROM_LIST, str);    return this;}
66ccab9a67300c65abfd8d298e56296c35629b274dd72d5b8ede40bc6348da5f
fromList
 RemoveHeaderIntBuilder fromList(final String str, final String separator)
{    fromList(str);    contextMap.put(RemoveHeaderInterceptor.LIST_SEPARATOR, separator);    return this;}
c959b9e4b2ae22487bfd7e4e53b1dbd845d992bd915f598dc60db9ab4c7c9a4e
matchRegex
 RemoveHeaderIntBuilder matchRegex(final String str)
{    contextMap.put(RemoveHeaderInterceptor.MATCH_REGEX, str);    return this;}
36a259375a36a29200657f75da2353d258ed031aa338368b4edd957c4c0f2f53
build
public Interceptor build() throws InstantiationException, IllegalAccessException, ClassNotFoundException
{    Interceptor.Builder builder = InterceptorBuilderFactory.newInstance(InterceptorType.REMOVE_HEADER.toString());    builder.configure(new Context(contextMap));    return builder.build();}
865e40555cf6a1a2ba13e36fba6b798c0620e36468291038ce916a8d73385c42
testCensor
public void testCensor()
{    MemoryChannel memCh = new MemoryChannel();    memCh.configure(new Context());    memCh.start();    ChannelSelector cs = new ReplicatingChannelSelector();    cs.setChannels(Lists.<Channel>newArrayList(memCh));    ChannelProcessor cp = new ChannelProcessor(cs);        Map<String, String> cfgMap = Maps.newHashMap();    cfgMap.put("interceptors", "a");    String builderClass = CensoringInterceptor.Builder.class.getName();    cfgMap.put("interceptors.a.type", builderClass);    Context ctx = new Context(cfgMap);        cp.configure(ctx);    cp.initialize();    Map<String, String> headers = Maps.newHashMap();    String badWord = "scribe";    headers.put("Bad-Words", badWord);    Event event1 = EventBuilder.withBody("test", Charsets.UTF_8, headers);    Assert.assertEquals(badWord, event1.getHeaders().get("Bad-Words"));    cp.processEvent(event1);    Transaction tx = memCh.getTransaction();    tx.begin();    Event event1a = memCh.take();    Assert.assertNull(event1a.getHeaders().get("Bad-Words"));    tx.commit();    tx.close();        cp.close();    memCh.stop();}
374f30b9565fa26944e766e4b0405ecb054a03175df55727b3e28dc9fd8468ac
testBasic
public void testBasic() throws Exception
{    Interceptor.Builder builder = InterceptorBuilderFactory.newInstance(InterceptorType.HOST.toString());    Interceptor interceptor = builder.build();    Event eventBeforeIntercept = EventBuilder.withBody("test event", Charsets.UTF_8);    Assert.assertNull(eventBeforeIntercept.getHeaders().get(Constants.HOST));    Event eventAfterIntercept = interceptor.intercept(eventBeforeIntercept);    String actualHost = eventAfterIntercept.getHeaders().get(Constants.HOST);    Assert.assertNotNull(actualHost);}
3be81f913a89a35c7e5f1495336fcf9f432efd966f902c066b1d76354ae60366
testCustomHeader
public void testCustomHeader() throws Exception
{    Interceptor.Builder builder = InterceptorBuilderFactory.newInstance(InterceptorType.HOST.toString());    Context ctx = new Context();    ctx.put("preserveExisting", "false");    ctx.put("hostHeader", "hostname");    builder.configure(ctx);    Interceptor interceptor = builder.build();    Event eventBeforeIntercept = EventBuilder.withBody("test event", Charsets.UTF_8);    Assert.assertNull(eventBeforeIntercept.getHeaders().get("hostname"));    Event eventAfterIntercept = interceptor.intercept(eventBeforeIntercept);    String actualHost = eventAfterIntercept.getHeaders().get("hostname");    Assert.assertNotNull(actualHost);    Assert.assertEquals(InetAddress.getLocalHost().getHostAddress(), actualHost);}
cd5b7a7c1e3671d1d33df4c3f64427e131335e0ca76022cc999c1cceea851d0d
testPreserve
public void testPreserve() throws Exception
{    Context ctx = new Context();    ctx.put("preserveExisting", "true");    Interceptor.Builder builder = InterceptorBuilderFactory.newInstance(InterceptorType.HOST.toString());    builder.configure(ctx);    Interceptor interceptor = builder.build();    final String ORIGINAL_HOST = "originalhost";    Event eventBeforeIntercept = EventBuilder.withBody("test event", Charsets.UTF_8);    eventBeforeIntercept.getHeaders().put(Constants.HOST, ORIGINAL_HOST);    Assert.assertEquals(ORIGINAL_HOST, eventBeforeIntercept.getHeaders().get(Constants.HOST));    String expectedHost = ORIGINAL_HOST;    Event eventAfterIntercept = interceptor.intercept(eventBeforeIntercept);    String actualHost = eventAfterIntercept.getHeaders().get(Constants.HOST);    Assert.assertNotNull(actualHost);    Assert.assertEquals(expectedHost, actualHost);}
fb62cdcebcda8a8eaa6a8a70f7038bad0060c76014c0bdc8760f41c696ba617b
testClobber
public void testClobber() throws Exception
{    Context ctx = new Context();        ctx.put("preserveExisting", "false");    Interceptor.Builder builder = InterceptorBuilderFactory.newInstance(InterceptorType.HOST.toString());    builder.configure(ctx);    Interceptor interceptor = builder.build();    final String ORIGINAL_HOST = "originalhost";    Event eventBeforeIntercept = EventBuilder.withBody("test event", Charsets.UTF_8);    eventBeforeIntercept.getHeaders().put(Constants.HOST, ORIGINAL_HOST);    Assert.assertEquals(ORIGINAL_HOST, eventBeforeIntercept.getHeaders().get(Constants.HOST));    String expectedHost = InetAddress.getLocalHost().getHostAddress();    Event eventAfterIntercept = interceptor.intercept(eventBeforeIntercept);    String actualHost = eventAfterIntercept.getHeaders().get(Constants.HOST);    Assert.assertNotNull(actualHost);    Assert.assertEquals(expectedHost, actualHost);}
84149f3d33a02710f683fbba966d4a6c7b0ff6d19cea9780a7b0b0f32d50f752
testUseIP
public void testUseIP() throws Exception
{    Context ctx = new Context();        ctx.put("useIP", "true");    Interceptor.Builder builder = InterceptorBuilderFactory.newInstance(InterceptorType.HOST.toString());    builder.configure(ctx);    Interceptor interceptor = builder.build();    final String ORIGINAL_HOST = "originalhost";    Event eventBeforeIntercept = EventBuilder.withBody("test event", Charsets.UTF_8);    eventBeforeIntercept.getHeaders().put(Constants.HOST, ORIGINAL_HOST);    Assert.assertEquals(ORIGINAL_HOST, eventBeforeIntercept.getHeaders().get(Constants.HOST));    String expectedHost = InetAddress.getLocalHost().getHostAddress();    Event eventAfterIntercept = interceptor.intercept(eventBeforeIntercept);    String actualHost = eventAfterIntercept.getHeaders().get(Constants.HOST);    Assert.assertNotNull(actualHost);    Assert.assertEquals(expectedHost, actualHost);}
3a23efe7cdfcca236e76d3b45ed8c584f73d7bfda92b3b2bf996c696acf07a8e
testUseHostname
public void testUseHostname() throws Exception
{    Context ctx = new Context();    ctx.put("useIP", "false");    Interceptor.Builder builder = InterceptorBuilderFactory.newInstance(InterceptorType.HOST.toString());    builder.configure(ctx);    Interceptor interceptor = builder.build();    final String ORIGINAL_HOST = "originalhost";    Event eventBeforeIntercept = EventBuilder.withBody("test event", Charsets.UTF_8);    eventBeforeIntercept.getHeaders().put(Constants.HOST, ORIGINAL_HOST);    Assert.assertEquals(ORIGINAL_HOST, eventBeforeIntercept.getHeaders().get(Constants.HOST));    String expectedHost = InetAddress.getLocalHost().getCanonicalHostName();    Event eventAfterIntercept = interceptor.intercept(eventBeforeIntercept);    String actualHost = eventAfterIntercept.getHeaders().get(Constants.HOST);    Assert.assertNotNull(actualHost);    Assert.assertEquals(expectedHost, actualHost);}
1359225215853f3f89f4af5641e298ce821f026f91f6d3bc4f753adf82ab1c74
init
public void init() throws Exception
{    fixtureBuilder = InterceptorBuilderFactory.newInstance(InterceptorType.REGEX_EXTRACTOR.toString());}
0f1ee7e606da130cfcad7e0fe4ac310aff27d85a8e414b26dd6c147ede9ab7c1
shouldNotAllowConfigurationWithoutRegex
public void shouldNotAllowConfigurationWithoutRegex() throws Exception
{    try {        fixtureBuilder.build();        Assert.fail();    } catch (IllegalArgumentException ex) {        }}
043ec81249daa147235a2f39f7758a866ba7a9bd2327c17ee94653fba13c8f9f
shouldNotAllowConfigurationWithIllegalRegex
public void shouldNotAllowConfigurationWithIllegalRegex() throws Exception
{    try {        Context context = new Context();        context.put(RegexExtractorInterceptor.REGEX, "?&?&&&?&?&?&&&??");        fixtureBuilder.configure(context);        fixtureBuilder.build();        Assert.fail();    } catch (IllegalArgumentException ex) {        }}
0d137a28651f41c55bce8d1a4db697edb1384dd702dafbe9ed27cca27fc9c6fb
shouldNotAllowConfigurationWithoutMatchIds
public void shouldNotAllowConfigurationWithoutMatchIds() throws Exception
{    try {        Context context = new Context();        context.put(RegexExtractorInterceptor.REGEX, ".*");        context.put(RegexExtractorInterceptor.SERIALIZERS, "");        fixtureBuilder.configure(context);        fixtureBuilder.build();        Assert.fail();    } catch (IllegalArgumentException ex) {        }}
4ade8d4fe1a63967998d924e671397b895ef59f28e4e4fcc1815490b255b7b38
shouldNotAllowMisconfiguredSerializers
public void shouldNotAllowMisconfiguredSerializers() throws Exception
{    try {        Context context = new Context();        context.put(RegexExtractorInterceptor.REGEX, "(\\d):(\\d):(\\d)");        context.put(RegexExtractorInterceptor.SERIALIZERS, ",,,");        fixtureBuilder.configure(context);        fixtureBuilder.build();        Assert.fail();    } catch (IllegalArgumentException ex) {        }}
2b88815ff6bdc9017232eeadd217cd3ac8e257f09cb5fbff07a81cbd62da5e18
shouldNotAllowEmptyNames
public void shouldNotAllowEmptyNames() throws Exception
{    try {        String space = " ";        Context context = new Context();        context.put(RegexExtractorInterceptor.REGEX, "(\\d):(\\d):(\\d)");        context.put(RegexExtractorInterceptor.SERIALIZERS, Joiner.on(',').join(space, space, space));        fixtureBuilder.configure(context);        fixtureBuilder.build();        Assert.fail();    } catch (IllegalArgumentException ex) {        }}
d9c367905989956011067c2708c0ba21a202950fc4c04ec8a40afae7974d2c63
shouldExtractAddHeadersForAllMatchGroups
public void shouldExtractAddHeadersForAllMatchGroups() throws Exception
{    Context context = new Context();    context.put(RegexExtractorInterceptor.REGEX, "(\\d):(\\d):(\\d)");    context.put(RegexExtractorInterceptor.SERIALIZERS, "s1 s2 s3");    context.put(RegexExtractorInterceptor.SERIALIZERS + ".s1.name", "Num1");    context.put(RegexExtractorInterceptor.SERIALIZERS + ".s2.name", "Num2");    context.put(RegexExtractorInterceptor.SERIALIZERS + ".s3.name", "Num3");    fixtureBuilder.configure(context);    Interceptor fixture = fixtureBuilder.build();    Event event = EventBuilder.withBody("1:2:3.4foobar5", Charsets.UTF_8);    Event expected = EventBuilder.withBody("1:2:3.4foobar5", Charsets.UTF_8);    expected.getHeaders().put("Num1", "1");    expected.getHeaders().put("Num2", "2");    expected.getHeaders().put("Num3", "3");    Event actual = fixture.intercept(event);    Assert.assertArrayEquals(expected.getBody(), actual.getBody());    Assert.assertEquals(expected.getHeaders(), actual.getHeaders());}
9c61732acbee4963e69bc7687c6a294572c83821374742461ad3d409be4cb967
shouldExtractAddHeadersForAllMatchGroupsIgnoringMissingIds
public void shouldExtractAddHeadersForAllMatchGroupsIgnoringMissingIds() throws Exception
{    String body = "2012-10-17 14:34:44,338";    Context context = new Context();        context.put(RegexExtractorInterceptor.REGEX, "^(\\d\\d\\d\\d-\\d\\d-\\d\\d\\s\\d\\d:\\d\\d)(:\\d\\d,\\d\\d\\d)");    context.put(RegexExtractorInterceptor.SERIALIZERS, "s1");    context.put(RegexExtractorInterceptor.SERIALIZERS + ".s1.name", "timestamp");    fixtureBuilder.configure(context);    Interceptor fixture = fixtureBuilder.build();    Event event = EventBuilder.withBody(body, Charsets.UTF_8);    Event expected = EventBuilder.withBody(body, Charsets.UTF_8);    expected.getHeaders().put("timestamp", "2012-10-17 14:34");    Event actual = fixture.intercept(event);    Assert.assertArrayEquals(expected.getBody(), actual.getBody());    Assert.assertEquals(expected.getHeaders(), actual.getHeaders());}
b3be662217d413839187d0562f3a483e2062e0869cb73a510d11e420bf59144f
shouldExtractAddHeadersUsingSpecifiedSerializer
public void shouldExtractAddHeadersUsingSpecifiedSerializer() throws Exception
{    long now = (System.currentTimeMillis() / 60000L) * 60000L;    String pattern = "yyyy-MM-dd HH:mm:ss,SSS";    DateTimeFormatter formatter = DateTimeFormat.forPattern(pattern);    String body = formatter.print(now);    System.out.println(body);    Context context = new Context();        context.put(RegexExtractorInterceptor.REGEX, "^(\\d\\d\\d\\d-\\d\\d-\\d\\d\\s\\d\\d:\\d\\d)(:\\d\\d,\\d\\d\\d)");    context.put(RegexExtractorInterceptor.SERIALIZERS, "s1 s2");    String millisSerializers = RegexExtractorInterceptorMillisSerializer.class.getName();    context.put(RegexExtractorInterceptor.SERIALIZERS + ".s1.type", millisSerializers);    context.put(RegexExtractorInterceptor.SERIALIZERS + ".s1.name", "timestamp");    context.put(RegexExtractorInterceptor.SERIALIZERS + ".s1.pattern", "yyyy-MM-dd HH:mm");        context.put(RegexExtractorInterceptor.SERIALIZERS + ".s2.name", "data");    fixtureBuilder.configure(context);    Interceptor fixture = fixtureBuilder.build();    Event event = EventBuilder.withBody(body, Charsets.UTF_8);    Event expected = EventBuilder.withBody(body, Charsets.UTF_8);    expected.getHeaders().put("timestamp", String.valueOf(now));    expected.getHeaders().put("data", ":00,000");    Event actual = fixture.intercept(event);    Assert.assertArrayEquals(expected.getBody(), actual.getBody());    Assert.assertEquals(expected.getHeaders(), actual.getHeaders());}
7296e655f3c1db3574c032e390586d6d18b61b08359e35225da79c82ee899266
shouldRequirePatternInConfiguration
public void shouldRequirePatternInConfiguration()
{    try {        RegexExtractorInterceptorMillisSerializer fixture = new RegexExtractorInterceptorMillisSerializer();        fixture.configure(new Context());        Assert.fail();    } catch (IllegalArgumentException ex) {        }}
94b30cd0136c3d009235b414f9d70472499987aef37219e1863e66e6e1c1d6e2
shouldRequireValidPatternInConfiguration
public void shouldRequireValidPatternInConfiguration()
{    try {        RegexExtractorInterceptorMillisSerializer fixture = new RegexExtractorInterceptorMillisSerializer();        Context context = new Context();        context.put("pattern", "ABCDEFG");        fixture.configure(context);        Assert.fail();    } catch (IllegalArgumentException ex) {        }}
82228ebe7d03915672d476f010b7a949dff869444a3c43df7d53ca032e467eb3
shouldReturnMillisFromPattern
public void shouldReturnMillisFromPattern()
{    RegexExtractorInterceptorMillisSerializer fixture = new RegexExtractorInterceptorMillisSerializer();    Context context = new Context();    String pattern = "yyyy-MM-dd HH:mm:ss";    context.put("pattern", pattern);    fixture.configure(context);    DateTimeFormatter formatter = DateTimeFormat.forPattern(pattern);    long time = (System.currentTimeMillis() / 1000L) * 1000L;    Assert.assertEquals(String.valueOf(time), fixture.serialize(formatter.print(time)));}
36a6443104b412f37c94fa43cfe45bd6a7caed1f6af1a830d691d1b18552443d
shouldReturnSameValue
public void shouldReturnSameValue()
{    RegexExtractorInterceptorPassThroughSerializer fixture = new RegexExtractorInterceptorPassThroughSerializer();    fixture.configure(new Context());    String input = "testing (1,2,3,4)";    Assert.assertEquals(input, fixture.serialize(input));}
ce3fd943433394b62f7cc055bd819240e8c9f43a5dfcbc9a2c322ba43b137933
testDefaultBehavior
public void testDefaultBehavior() throws ClassNotFoundException, InstantiationException, IllegalAccessException
{    Interceptor.Builder builder = InterceptorBuilderFactory.newInstance(InterceptorType.REGEX_FILTER.toString());    builder.configure(new Context());    Interceptor interceptor = builder.build();    Event event = EventBuilder.withBody("test", Charsets.UTF_8);    Event filteredEvent = interceptor.intercept(event);    Assert.assertNotNull(filteredEvent);    Assert.assertEquals(event, filteredEvent);}
dc48cbbb37caa6e9ec53676623ffb6a03c8c6237898cb2440e17894a3f836f39
testInclusion
public void testInclusion() throws ClassNotFoundException, InstantiationException, IllegalAccessException
{    Interceptor.Builder builder = InterceptorBuilderFactory.newInstance(InterceptorType.REGEX_FILTER.toString());    Context ctx = new Context();    ctx.put(Constants.REGEX, "(INFO.*)|(WARNING.*)");    ctx.put(Constants.EXCLUDE_EVENTS, "false");    builder.configure(ctx);    Interceptor interceptor = builder.build();    Event shouldPass1 = EventBuilder.withBody("INFO: some message", Charsets.UTF_8);    Assert.assertNotNull(interceptor.intercept(shouldPass1));    Event shouldPass2 = EventBuilder.withBody("WARNING: some message", Charsets.UTF_8);    Assert.assertNotNull(interceptor.intercept(shouldPass2));    Event shouldNotPass = EventBuilder.withBody("DEBUG: some message", Charsets.UTF_8);    Assert.assertNull(interceptor.intercept(shouldNotPass));    builder.configure(ctx);}
04ce07a4844563f83ddb1106551e7ff08273100b05154a9869ddc800a811467f
testExclusion
public void testExclusion() throws ClassNotFoundException, InstantiationException, IllegalAccessException
{    Interceptor.Builder builder = InterceptorBuilderFactory.newInstance(InterceptorType.REGEX_FILTER.toString());    Context ctx = new Context();    ctx.put(Constants.REGEX, ".*DEBUG.*");    ctx.put(Constants.EXCLUDE_EVENTS, "true");    builder.configure(ctx);    Interceptor interceptor = builder.build();    Event shouldPass1 = EventBuilder.withBody("INFO: some message", Charsets.UTF_8);    Assert.assertNotNull(interceptor.intercept(shouldPass1));    Event shouldPass2 = EventBuilder.withBody("WARNING: some message", Charsets.UTF_8);    Assert.assertNotNull(interceptor.intercept(shouldPass2));    Event shouldNotPass = EventBuilder.withBody("this message has DEBUG in it", Charsets.UTF_8);    Assert.assertNull(interceptor.intercept(shouldNotPass));    builder.configure(ctx);}
3068b682135723177d28081ec1a9e0e647fc58a62f567454f6241fa967d86f2d
testSearchReplace
private void testSearchReplace(Context context, String input, String output) throws Exception
{    Interceptor.Builder builder = InterceptorBuilderFactory.newInstance(InterceptorType.SEARCH_REPLACE.toString());    builder.configure(context);    Interceptor interceptor = builder.build();    Event event = EventBuilder.withBody(input, Charsets.UTF_8);    event = interceptor.intercept(event);    String val = new String(event.getBody(), Charsets.UTF_8);    assertEquals(output, val);    logger.info(val);}
bb97d4bc0b294d99635939f162dbd575b36d78e2994793c8a39e63c43bc696b8
testRemovePrefix
public void testRemovePrefix() throws Exception
{    Context context = new Context();    context.put("searchPattern", "^prefix");    context.put("replaceString", "");    testSearchReplace(context, "prefix non-prefix suffix", " non-prefix suffix");}
66da799f931585dac4d584ec69d0f5b126c53c459185390b4c7ad879eff5bed2
testSyslogStripPriority
public void testSyslogStripPriority() throws Exception
{    final String input = "<13>Feb  5 17:32:18 10.0.0.99 Use the BFG!";    final String output = "Feb  5 17:32:18 10.0.0.99 Use the BFG!";    Context context = new Context();    context.put("searchPattern", "^<[0-9]+>");    context.put("replaceString", "");    testSearchReplace(context, input, output);}
d41bf53af33b9f01415214ad9ee59bcbcbdda64756bfaf949e31fdcf5513fe8b
testCapturedGroups
public void testCapturedGroups() throws Exception
{    final String input = "The quick brown fox jumped over the lazy dog.";    final String output = "The hungry dog ate the careless fox.";    Context context = new Context();    context.put("searchPattern", "The quick brown ([a-z]+) jumped over the lazy ([a-z]+).");    context.put("replaceString", "The hungry $2 ate the careless $1.");    testSearchReplace(context, input, output);}
412c6adab31d6f3c63be911b1d0068f5f6b03a05e4e880ccbfaf4630f618548a
testRepeatedRemoval
public void testRepeatedRemoval() throws Exception
{    final String input = "Email addresses: test@test.com and foo@test.com";    final String output = "Email addresses: REDACTED and REDACTED";    Context context = new Context();    context.put("searchPattern", "[A-Za-z0-9_.]+@[A-Za-z0-9_-]+\\.com");    context.put("replaceString", "REDACTED");    testSearchReplace(context, input, output);}
43b13e53f186b01e537877c0e1747149f6ed712836070863e26fe201091a6eb3
testReplaceEmpty
public void testReplaceEmpty() throws Exception
{    final String input = "Abc123@test.com";    final String output = "@test.com";    Context context = new Context();    context.put("searchPattern", "^[A-Za-z0-9_]+");    testSearchReplace(context, input, output);    context.put("replaceString", "");    testSearchReplace(context, input, output);}
419a69bc1ed0a467f915488112b17451313f40774b8ed14241470e9a0cb4c429
testDefaultKeyValue
public void testDefaultKeyValue() throws ClassNotFoundException, InstantiationException, IllegalAccessException
{    Interceptor.Builder builder = InterceptorBuilderFactory.newInstance(InterceptorType.STATIC.toString());    builder.configure(new Context());    Interceptor interceptor = builder.build();    Event event = EventBuilder.withBody("test", Charsets.UTF_8);    Assert.assertNull(event.getHeaders().get(Constants.KEY));    event = interceptor.intercept(event);    String val = event.getHeaders().get(Constants.KEY);    Assert.assertNotNull(val);    Assert.assertEquals(Constants.VALUE, val);}
9dc614fa5a5e15cf8816e1f0c5621c6009e3e9ad3fbead8eeeb24dbc5f748ae4
testCustomKeyValue
public void testCustomKeyValue() throws ClassNotFoundException, InstantiationException, IllegalAccessException
{    Interceptor.Builder builder = InterceptorBuilderFactory.newInstance(InterceptorType.STATIC.toString());    Context ctx = new Context();    ctx.put(Constants.KEY, "myKey");    ctx.put(Constants.VALUE, "myVal");    builder.configure(ctx);    Interceptor interceptor = builder.build();    Event event = EventBuilder.withBody("test", Charsets.UTF_8);    Assert.assertNull(event.getHeaders().get("myKey"));    event = interceptor.intercept(event);    String val = event.getHeaders().get("myKey");    Assert.assertNotNull(val);    Assert.assertEquals("myVal", val);}
30258fa3aefebfd199499386c2efb40b85228b9718c288a6311a582e8954e39a
testReplace
public void testReplace() throws ClassNotFoundException, InstantiationException, IllegalAccessException
{    Interceptor.Builder builder = InterceptorBuilderFactory.newInstance(InterceptorType.STATIC.toString());    Context ctx = new Context();    ctx.put(Constants.PRESERVE, "false");    ctx.put(Constants.VALUE, "replacement value");    builder.configure(ctx);    Interceptor interceptor = builder.build();    Event event = EventBuilder.withBody("test", Charsets.UTF_8);    event.getHeaders().put(Constants.KEY, "incumbent value");    Assert.assertNotNull(event.getHeaders().get(Constants.KEY));    event = interceptor.intercept(event);    String val = event.getHeaders().get(Constants.KEY);    Assert.assertNotNull(val);    Assert.assertEquals("replacement value", val);}
1cc3b1bed52fca46ac60902cf4f42f5508fadd313923e1556daf67f757299d2d
testPreserve
public void testPreserve() throws ClassNotFoundException, InstantiationException, IllegalAccessException
{    Interceptor.Builder builder = InterceptorBuilderFactory.newInstance(InterceptorType.STATIC.toString());    Context ctx = new Context();    ctx.put(Constants.PRESERVE, "true");    ctx.put(Constants.VALUE, "replacement value");    builder.configure(ctx);    Interceptor interceptor = builder.build();    Event event = EventBuilder.withBody("test", Charsets.UTF_8);    event.getHeaders().put(Constants.KEY, "incumbent value");    Assert.assertNotNull(event.getHeaders().get(Constants.KEY));    event = interceptor.intercept(event);    String val = event.getHeaders().get(Constants.KEY);    Assert.assertNotNull(val);    Assert.assertEquals("incumbent value", val);}
6f8fc2d7f4859aab7b15fb8f075162614a323497ad9bad5f60b8a72e66c9ec9f
testBasic
public void testBasic() throws ClassNotFoundException, InstantiationException, IllegalAccessException
{    Interceptor.Builder builder = InterceptorBuilderFactory.newInstance(InterceptorType.TIMESTAMP.toString());    Interceptor interceptor = builder.build();    Event event = EventBuilder.withBody("test event", Charsets.UTF_8);    Assert.assertNull(event.getHeaders().get(Constants.DEFAULT_HEADER_NAME));    Long now = System.currentTimeMillis();    event = interceptor.intercept(event);    String timestampStr = event.getHeaders().get(Constants.DEFAULT_HEADER_NAME);    Assert.assertNotNull(timestampStr);    Assert.assertTrue(Long.parseLong(timestampStr) >= now);}
1cc3b1bed52fca46ac60902cf4f42f5508fadd313923e1556daf67f757299d2d
testPreserve
public void testPreserve() throws ClassNotFoundException, InstantiationException, IllegalAccessException
{    Context ctx = new Context();    ctx.put("preserveExisting", "true");    Interceptor.Builder builder = InterceptorBuilderFactory.newInstance(InterceptorType.TIMESTAMP.toString());    builder.configure(ctx);    Interceptor interceptor = builder.build();    long originalTs = 1L;    Event event = EventBuilder.withBody("test event", Charsets.UTF_8);    event.getHeaders().put(Constants.DEFAULT_HEADER_NAME, Long.toString(originalTs));    Assert.assertEquals(Long.toString(originalTs), event.getHeaders().get(Constants.DEFAULT_HEADER_NAME));    event = interceptor.intercept(event);    String timestampStr = event.getHeaders().get(Constants.DEFAULT_HEADER_NAME);    Assert.assertNotNull(timestampStr);    Assert.assertTrue(Long.parseLong(timestampStr) == originalTs);}
0df59945444bdaa36bfc441c9d29b304a56ab573d13ceec0e12373a8e3c38ce5
testClobber
public void testClobber() throws ClassNotFoundException, InstantiationException, IllegalAccessException
{    Context ctx = new Context();        ctx.put("preserveExisting", "false");    Interceptor.Builder builder = InterceptorBuilderFactory.newInstance(InterceptorType.TIMESTAMP.toString());    builder.configure(ctx);    Interceptor interceptor = builder.build();    long originalTs = 1L;    Event event = EventBuilder.withBody("test event", Charsets.UTF_8);    event.getHeaders().put(Constants.DEFAULT_HEADER_NAME, Long.toString(originalTs));    Assert.assertEquals(Long.toString(originalTs), event.getHeaders().get(Constants.DEFAULT_HEADER_NAME));    Long now = System.currentTimeMillis();    event = interceptor.intercept(event);    String timestampStr = event.getHeaders().get(Constants.DEFAULT_HEADER_NAME);    Assert.assertNotNull(timestampStr);    Assert.assertTrue(Long.parseLong(timestampStr) >= now);}
3be81f913a89a35c7e5f1495336fcf9f432efd966f902c066b1d76354ae60366
testCustomHeader
public void testCustomHeader() throws Exception
{    Context ctx = new Context();    ctx.put(TimestampInterceptor.Constants.CONFIG_HEADER_NAME, "timestampHeader");    Interceptor.Builder builder = InterceptorBuilderFactory.newInstance(InterceptorType.TIMESTAMP.toString());    builder.configure(ctx);    Interceptor interceptor = builder.build();    long originalTs = 1L;    Event event = EventBuilder.withBody("test event", Charsets.UTF_8);    event.getHeaders().put(Constants.DEFAULT_HEADER_NAME, Long.toString(originalTs));    Long now = System.currentTimeMillis();    event = interceptor.intercept(event);    Assert.assertEquals(Long.toString(originalTs), event.getHeaders().get(Constants.DEFAULT_HEADER_NAME));    String timestampStr = event.getHeaders().get("timestampHeader");    Assert.assertNotNull(timestampStr);    Assert.assertTrue(Long.parseLong(timestampStr) >= now);}
fa682c44b2e4f0d71444cfb7f6fe829248875a8b5d59f03a89d8ec56054f3613
testWaitForState
public void testWaitForState() throws LifecycleException, InterruptedException
{    LifecycleAware delegate = new SleeperLifecycleDelegate();    Assert.assertTrue(delegate.getLifecycleState().equals(LifecycleState.IDLE));    delegate.start();    boolean reached = LifecycleController.waitForState(delegate, LifecycleState.START, 2000);    Assert.assertEquals(true, reached);    Assert.assertEquals(LifecycleState.START, delegate.getLifecycleState());    delegate.stop();    reached = LifecycleController.waitForState(delegate, LifecycleState.STOP, 2000);    Assert.assertEquals(true, reached);    Assert.assertEquals(LifecycleState.STOP, delegate.getLifecycleState());    delegate.start();    reached = LifecycleController.waitForState(delegate, LifecycleState.IDLE, 500);    Assert.assertEquals(false, reached);    Assert.assertEquals(LifecycleState.START, delegate.getLifecycleState());}
b9033a4b6c0d56f4d253571b1608b427d2b41b76476d6900ce6c7284bb46ac77
testWaitForOneOf
public void testWaitForOneOf() throws LifecycleException, InterruptedException
{    LifecycleAware delegate = new SleeperLifecycleDelegate();    Assert.assertEquals(LifecycleState.IDLE, delegate.getLifecycleState());    delegate.start();    boolean reached = LifecycleController.waitForOneOf(delegate, new LifecycleState[] { LifecycleState.STOP, LifecycleState.START }, 2000);    Assert.assertTrue("Matched a state change", reached);    Assert.assertEquals(LifecycleState.START, delegate.getLifecycleState());}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    try {        Thread.sleep(sleepTime);    } catch (InterruptedException e) {        }    state = LifecycleState.START;}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    try {        Thread.sleep(sleepTime);    } catch (InterruptedException e) {        }    state = LifecycleState.STOP;}
54497ccb2ff9760f1ec7fc0d0055d4bc60d5981953c5f3d7550c4b31a01e7642
getLifecycleState
public LifecycleState getLifecycleState()
{    return state;}
3622149c6784b29b84933a274da70e6dd3bcd4e0516c91ca69a43538c013b9ee
getSleepTime
public long getSleepTime()
{    return sleepTime;}
7b62fd0a5a13798f179827594a7c8f7ae8f685d6c4dca2d01870d26e3283eab7
setSleepTime
public void setSleepTime(long sleepTime)
{    this.sleepTime = sleepTime;}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    supervisor = new LifecycleSupervisor();}
c4f45f7d53073d46f60c681223bbc97cbae6510a50e4e1ea05620815a939ff96
testLifecycle
public void testLifecycle() throws LifecycleException, InterruptedException
{    supervisor.start();    supervisor.stop();}
cd82ba107d0f6fcf879dd28f2ef0b1f52b1e259254c505a914c82f01070d5ae7
testSupervise
public void testSupervise() throws LifecycleException, InterruptedException
{    supervisor.start();    /* Attempt to supervise a known-to-fail config. */    /*     * LogicalNode node = new LogicalNode(); SupervisorPolicy policy = new     * SupervisorPolicy.OnceOnlyPolicy(); supervisor.supervise(node, policy,     * LifecycleState.START);     */    CountingLifecycleAware node = new CountingLifecycleAware();    SupervisorPolicy policy = new SupervisorPolicy.OnceOnlyPolicy();    supervisor.supervise(node, policy, LifecycleState.START);    Thread.sleep(10000);    node = new CountingLifecycleAware();    policy = new SupervisorPolicy.OnceOnlyPolicy();    supervisor.supervise(node, policy, LifecycleState.START);    Thread.sleep(5000);    supervisor.stop();}
f2ba229795456158e969d85ac2137d17bd9dfe6503210f8a0801b4994a863f21
testSuperviseBroken
public void testSuperviseBroken() throws LifecycleException, InterruptedException
{    supervisor.start();    /* Attempt to supervise a known-to-fail config. */    LifecycleAware node = new LifecycleAware() {        @Override        public void stop() {        }        @Override        public void start() {            throw new NullPointerException("Boom!");        }        @Override        public LifecycleState getLifecycleState() {            return LifecycleState.IDLE;        }    };    SupervisorPolicy policy = new SupervisorPolicy.OnceOnlyPolicy();    supervisor.supervise(node, policy, LifecycleState.START);    Thread.sleep(5000);    supervisor.stop();}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    throw new NullPointerException("Boom!");}
54497ccb2ff9760f1ec7fc0d0055d4bc60d5981953c5f3d7550c4b31a01e7642
getLifecycleState
public LifecycleState getLifecycleState()
{    return LifecycleState.IDLE;}
703bf40fb033d4ea1ba1d5e0e21a2f8112b238da6d6e2da7727fec6e3bb3d07c
testSuperviseSupervisor
public void testSuperviseSupervisor() throws LifecycleException, InterruptedException
{    supervisor.start();    LifecycleSupervisor supervisor2 = new LifecycleSupervisor();    CountingLifecycleAware node = new CountingLifecycleAware();    SupervisorPolicy policy = new SupervisorPolicy.OnceOnlyPolicy();    supervisor2.supervise(node, policy, LifecycleState.START);    supervisor.supervise(supervisor2, new SupervisorPolicy.AlwaysRestartPolicy(), LifecycleState.START);    Thread.sleep(10000);    supervisor.stop();}
37838eca1738020a92874ad9b62e1044a1ec58f693a2705d8070f7de5a55913d
testUnsuperviseServce
public void testUnsuperviseServce() throws LifecycleException, InterruptedException
{    supervisor.start();    LifecycleAware service = new CountingLifecycleAware();    SupervisorPolicy policy = new SupervisorPolicy.OnceOnlyPolicy();    supervisor.supervise(service, policy, LifecycleState.START);    supervisor.unsupervise(service);    service.stop();    supervisor.stop();}
0ed39e467e19b3033897a4fc69482dbf4cb0df01b4d2ebf55fcefff07b13d277
testStopServce
public void testStopServce() throws LifecycleException, InterruptedException
{    supervisor.start();    CountingLifecycleAware service = new CountingLifecycleAware();    SupervisorPolicy policy = new SupervisorPolicy.OnceOnlyPolicy();    Assert.assertEquals(Long.valueOf(0), service.counterGroup.get("start"));    Assert.assertEquals(Long.valueOf(0), service.counterGroup.get("stop"));    supervisor.supervise(service, policy, LifecycleState.START);    Thread.sleep(3200);    Assert.assertEquals(Long.valueOf(1), service.counterGroup.get("start"));    Assert.assertEquals(Long.valueOf(0), service.counterGroup.get("stop"));    supervisor.setDesiredState(service, LifecycleState.STOP);    Thread.sleep(3200);    Assert.assertEquals(Long.valueOf(1), service.counterGroup.get("start"));    Assert.assertEquals(Long.valueOf(1), service.counterGroup.get("stop"));    supervisor.stop();}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    counterGroup.incrementAndGet("start");    lifecycleState = LifecycleState.START;}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    counterGroup.incrementAndGet("stop");    lifecycleState = LifecycleState.STOP;}
54497ccb2ff9760f1ec7fc0d0055d4bc60d5981953c5f3d7550c4b31a01e7642
getLifecycleState
public LifecycleState getLifecycleState()
{    return lifecycleState;}
f79d05b42c11ee1f4b1e4e4ab6d21344c052d3a318f2568b7f96a49637f98b76
readChar
public int readChar() throws IOException
{    if (curPos >= str.length()) {        return -1;    }    return str.charAt(curPos++);}
740b2d69a871de3f06de1d6974b0a76e5d58ff23733964f6f17d60eedfcb816d
mark
public void mark() throws IOException
{    markPos = curPos;}
39fd2a669bd97a959085d10145da4dcd11d83878afcd67b2123354de7e8771d9
reset
public void reset() throws IOException
{    curPos = markPos;}
62032bfd4a1c0bb1c932a4c527e1d71aebf93308af8494a3c9f3705168a09088
seek
public void seek(long position) throws IOException
{    throw new UnsupportedOperationException("Unimplemented in test class");}
0efa2bd8fc7bc3d72996c492a3eaca80646290caeceea873a5afabb84aa9504c
tell
public long tell() throws IOException
{    throw new UnsupportedOperationException("Unimplemented in test class");}
00c6cb892813c6b89e072a7f09dccdece629f30849daab28245b06f3e679bf54
read
public int read() throws IOException
{    throw new UnsupportedOperationException("This test class doesn't return " + "bytes!");}
56e08d87e6bd0be2a60f9b2de3195d58bc9d56a2637f6fed6210d21e832632ea
read
public int read(byte[] b, int off, int len) throws IOException
{    throw new UnsupportedOperationException("This test class doesn't return " + "bytes!");}
e0823f55b3a09d41a3e1e792f7e6687db9199c2db9b29e9922d93cbdc6f1284b
close
public void close() throws IOException
{}
d714b22089f1841fc084c332fb23274bae6df3e73b3dd079d5243c5d4e61d251
getOutputStream
protected OutputStream getOutputStream()
{    return out;}
83126e46f74779f8ca7db78442694c63703e46d31d53234da4174f2af8bfc162
getSchema
protected Schema getSchema()
{    return schema;}
ca11faf4b1d442732c93e7765f65853fbe6499b0ebff4d108cf23cc176bb2759
convert
protected SyslogEvent convert(Event event)
{    SyslogEvent sle = new SyslogEvent();            String msg = new String(event.getBody(), Charsets.UTF_8);        int seek = 0;                Map<String, String> headers = event.getHeaders();    boolean fromSyslogSource = false;    if (headers.containsKey(SyslogUtils.SYSLOG_FACILITY)) {        fromSyslogSource = true;        int facility = Integer.parseInt(headers.get(SyslogUtils.SYSLOG_FACILITY));        sle.setFacility(facility);    }    if (headers.containsKey(SyslogUtils.SYSLOG_SEVERITY)) {        fromSyslogSource = true;        int severity = Integer.parseInt(headers.get(SyslogUtils.SYSLOG_SEVERITY));        sle.setSeverity(severity);    }        if (!fromSyslogSource) {        if (msg.charAt(0) == '<') {            int end = msg.indexOf(">");            if (end > -1) {                seek = end + 1;                String priStr = msg.substring(1, end);                int priority = Integer.parseInt(priStr);                int severity = priority % 8;                int facility = (priority - severity) / 8;                sle.setFacility(facility);                sle.setSeverity(severity);            }        }    }        String timestampStr = msg.substring(seek, seek + 15);    long ts = parseRfc3164Date(timestampStr);    if (ts != 0) {        sle.setTimestamp(ts);                seek += 15 + 1;    }        int nextSpace = msg.indexOf(' ', seek);    if (nextSpace > -1) {        String hostname = msg.substring(seek, nextSpace);        sle.setHostname(hostname);        seek = nextSpace + 1;    }        String actualMessage = msg.substring(seek);    sle.setMessage(actualMessage);    if (logger.isDebugEnabled() && LogPrivacyUtil.allowLogRawData()) {        logger.debug("Serialized event as: {}", sle);    }    return sle;}
9727b37e8ef3f7aee045dbb8661a651c642405cf3db557f65af95adda6eaa73a
parseRfc3164Date
private static long parseRfc3164Date(String in)
{    DateTime date = null;    try {        date = dateFmt1.parseDateTime(in);    } catch (IllegalArgumentException e) {                logger.debug("Date parse failed on ({}), trying single-digit date", in);    }    if (date == null) {        try {            date = dateFmt2.parseDateTime(in);        } catch (IllegalArgumentException e) {                        logger.debug("2nd date parse failed on ({}), unknown date format", in);        }    }        if (date != null) {        DateTime now = new DateTime();        int year = now.getYear();        DateTime corrected = date.withYear(year);                if (corrected.isAfter(now) && corrected.minusMonths(1).isAfter(now)) {            corrected = date.minusYears(1);                } else if (corrected.isBefore(now) && corrected.plusMonths(1).isBefore(now)) {            corrected = date.plusYears(1);        }        date = corrected;    }    if (date == null) {        return 0;    }    return date.getMillis();}
74e8fa60d6fc51ca3723cb17e94c593fb7b56c215ce37ab9c280f06c5b880433
build
public EventSerializer build(Context context, OutputStream out)
{    SyslogAvroEventSerializer writer = null;    try {        writer = new SyslogAvroEventSerializer(out);        writer.configure(context);    } catch (IOException e) {        logger.error("Unable to parse schema file. Exception follows.", e);    }    return writer;}
36269d6b2ba82efed0884615d151be09bdce673f9e5f80239d3e9af174f5991f
setFacility
public void setFacility(int f)
{    facility = f;}
8b4d604084de64b1f0f01692640400ad1971567c8fc1e2047ec808792755a9d5
getFacility
public int getFacility()
{    return facility;}
07b109476ebcb9c7e34242f10d4754577832a6d7f9220d409c2ca68dc1ea7ed0
setSeverity
public void setSeverity(int s)
{    severity = s;}
10ad5fffb4a981bc6909604d0385c8545afe1f616ef0173df4b28d50cf272673
getSeverity
public int getSeverity()
{    return severity;}
4ac4906179aa8346d5761ca069b77a82c8f41f74479b405a1d5a759b092cf78d
setTimestamp
public void setTimestamp(long t)
{    timestamp = t;}
efd4f04d2f7438e26699863148fedf2a1756ec4f9ea70d9d64b80b1bdb63169b
getTimestamp
public long getTimestamp()
{    return timestamp;}
8654e25cdfc06659297928a27b2e537e183d8dba96a2df9cd9c7b4cc0d088ea7
setHostname
public void setHostname(String h)
{    hostname = h;}
27236935fc56b50befbdcf980df4df93fc1cb38744897e3c4ee05c744e513e94
getHostname
public String getHostname()
{    return hostname;}
40127a17f270d990aacbb571bc0bb861266247658291960d23d43b775326a54f
setMessage
public void setMessage(String m)
{    message = m;}
b46153cc21231cb60e014b6b3c49b437699575e4012681cb08026e5238c66751
getMessage
public String getMessage()
{    return message;}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    StringBuilder builder = new StringBuilder();    builder.append("{ Facility: ").append(facility).append(", ");    builder.append(" Severity: ").append(severity).append(", ");    builder.append(" Timestamp: ").append(timestamp).append(", ");    builder.append(" Hostname: ").append(hostname).append(", ");    builder.append(" Message: \"").append(message).append("\" }");    return builder.toString();}
018abccac5e8247333227d10d17818fed21808dff88f62679e51295a37c4a6cc
resetTest
public void resetTest() throws IOException
{    File tempFile = newTestFile(true);    String target = tempFile.getAbsolutePath();    logger.info("Target: {}", target);    TransientPositionTracker tracker = new TransientPositionTracker(target);    AvroEventDeserializer.Builder desBuilder = new AvroEventDeserializer.Builder();    EventDeserializer deserializer = desBuilder.build(new Context(), new ResettableFileInputStream(tempFile, tracker));    BinaryDecoder decoder = null;    DatumReader<GenericRecord> reader = new GenericDatumReader<GenericRecord>(schema);    decoder = DecoderFactory.get().binaryDecoder(deserializer.readEvent().getBody(), decoder);    assertEquals("bar", reader.read(null, decoder).get("foo").toString());    deserializer.reset();    decoder = DecoderFactory.get().binaryDecoder(deserializer.readEvent().getBody(), decoder);    assertEquals("bar", reader.read(null, decoder).get("foo").toString());    deserializer.mark();    decoder = DecoderFactory.get().binaryDecoder(deserializer.readEvent().getBody(), decoder);    assertEquals("baz", reader.read(null, decoder).get("foo").toString());    deserializer.reset();    decoder = DecoderFactory.get().binaryDecoder(deserializer.readEvent().getBody(), decoder);    assertEquals("baz", reader.read(null, decoder).get("foo").toString());    assertNull(deserializer.readEvent());}
d066758b8246c3fc3680a79f687846aa6dadfa7b3ee92f3adeb9b10df33fe5d3
testSchemaHash
public void testSchemaHash() throws IOException, NoSuchAlgorithmException
{    File tempFile = newTestFile(true);    String target = tempFile.getAbsolutePath();    logger.info("Target: {}", target);    TransientPositionTracker tracker = new TransientPositionTracker(target);    Context context = new Context();    context.put(AvroEventDeserializer.CONFIG_SCHEMA_TYPE_KEY, AvroEventDeserializer.AvroSchemaType.HASH.toString());    ResettableInputStream in = new ResettableFileInputStream(tempFile, tracker);    EventDeserializer des = new AvroEventDeserializer.Builder().build(context, in);    Event event = des.readEvent();    String eventSchemaHash = event.getHeaders().get(AvroEventDeserializer.AVRO_SCHEMA_HEADER_HASH);    String expectedSchemaHash = Hex.encodeHexString(SchemaNormalization.parsingFingerprint("CRC-64-AVRO", schema));    Assert.assertEquals(expectedSchemaHash, eventSchemaHash);}
e2cfefa2c52c9e9fd7984ae6465800f53c03bf3b94857fc4d3b7fffe4126b233
testSchemaLiteral
public void testSchemaLiteral() throws IOException
{    File tempFile = newTestFile(true);    String target = tempFile.getAbsolutePath();    logger.info("Target: {}", target);    TransientPositionTracker tracker = new TransientPositionTracker(target);    Context context = new Context();    context.put(AvroEventDeserializer.CONFIG_SCHEMA_TYPE_KEY, AvroEventDeserializer.AvroSchemaType.LITERAL.toString());    ResettableInputStream in = new ResettableFileInputStream(tempFile, tracker);    EventDeserializer des = new AvroEventDeserializer.Builder().build(context, in);    Event event = des.readEvent();    String eventSchema = event.getHeaders().get(AvroEventDeserializer.AVRO_SCHEMA_HEADER_LITERAL);    Assert.assertEquals(schema.toString(), eventSchema);}
2b2d6e89bb731e916868933697a87ba02b0debf68069169975fe1e8eb2852efd
newTestFile
private File newTestFile(boolean deleteOnExit) throws IOException
{    File tempFile = File.createTempFile("testDirectFile", "tmp");    if (deleteOnExit) {        tempFile.deleteOnExit();    }    DataFileWriter<GenericRecord> writer = new DataFileWriter<GenericRecord>(new GenericDatumWriter<GenericRecord>(schema));    writer.create(schema, tempFile);    GenericRecordBuilder recordBuilder;    recordBuilder = new GenericRecordBuilder(schema);    recordBuilder.set("foo", "bar");    GenericRecord record = recordBuilder.build();    writer.append(record);    writer.sync();    recordBuilder = new GenericRecordBuilder(schema);    recordBuilder.set("foo", "baz");    record = recordBuilder.build();    writer.append(record);    writer.sync();    writer.flush();    writer.close();    return tempFile;}
52cbdf53c523567b2364eedf54458166a2e4dfa2c90b600c5a67ac5d76158ce9
testWithNewline
public void testWithNewline() throws FileNotFoundException, IOException
{    OutputStream out = new FileOutputStream(testFile);    EventSerializer serializer = EventSerializerFactory.getInstance("text", new Context(), out);    serializer.afterCreate();    serializer.write(EventBuilder.withBody("event 1", Charsets.UTF_8));    serializer.write(EventBuilder.withBody("event 2", Charsets.UTF_8));    serializer.write(EventBuilder.withBody("event 3", Charsets.UTF_8));    serializer.flush();    serializer.beforeClose();    out.flush();    out.close();    BufferedReader reader = new BufferedReader(new FileReader(testFile));    Assert.assertEquals("event 1", reader.readLine());    Assert.assertEquals("event 2", reader.readLine());    Assert.assertEquals("event 3", reader.readLine());    Assert.assertNull(reader.readLine());    reader.close();    FileUtils.forceDelete(testFile);}
7ca325fd63218622725ddd4cf6605bc008c84fa9d77b2e20dafc65165dffd2fc
testNoNewline
public void testNoNewline() throws FileNotFoundException, IOException
{    OutputStream out = new FileOutputStream(testFile);    Context context = new Context();    context.put("appendNewline", "false");    EventSerializer serializer = EventSerializerFactory.getInstance("text", context, out);    serializer.afterCreate();    serializer.write(EventBuilder.withBody("event 1\n", Charsets.UTF_8));    serializer.write(EventBuilder.withBody("event 2\n", Charsets.UTF_8));    serializer.write(EventBuilder.withBody("event 3\n", Charsets.UTF_8));    serializer.flush();    serializer.beforeClose();    out.flush();    out.close();    BufferedReader reader = new BufferedReader(new FileReader(testFile));    Assert.assertEquals("event 1", reader.readLine());    Assert.assertEquals("event 2", reader.readLine());    Assert.assertEquals("event 3", reader.readLine());    Assert.assertNull(reader.readLine());    reader.close();    FileUtils.forceDelete(testFile);}
3f9d0ccb42dab3de03aa7df78b3a2a2f6470c09a916f5eefc9bc1427b6d1397a
testBasicTracker
public void testBasicTracker() throws IOException
{    File metaFile = File.createTempFile(getClass().getName(), ".meta");    metaFile.delete();    File dataFile = File.createTempFile(getClass().getName(), ".data");    Files.write("line 1\nline2\n", dataFile, Charsets.UTF_8);    final long NEW_POS = 7;    PositionTracker tracker;    tracker = new DurablePositionTracker(metaFile, dataFile.toString());    Assert.assertEquals(0, tracker.getPosition());    tracker.storePosition(NEW_POS);    Assert.assertEquals(NEW_POS, tracker.getPosition());    tracker.close();        tracker = new DurablePositionTracker(metaFile, "foobar");    Assert.assertEquals(NEW_POS, tracker.getPosition());    Assert.assertEquals(dataFile.getAbsolutePath(), tracker.getTarget());}
8f2fab071317f6c6b7b7d5935b0329aa7a00d63b77ae4153204036dd0071ec5f
testGoodTrackerFile
public void testGoodTrackerFile() throws IOException, URISyntaxException
{    String fileName = "/TestResettableFileInputStream_1.avro";    File trackerFile = new File(getClass().getResource(fileName).toURI());    Assert.assertTrue(trackerFile.exists());    PositionTracker tracker;    tracker = new DurablePositionTracker(trackerFile, "foo");        Assert.assertEquals(62, tracker.getPosition());}
9f3ca537c78e419afc7172c19c7d8df78fe6c7a35fbd06f550c34e3beb76c47a
testPartialTrackerFile
public void testPartialTrackerFile() throws IOException, URISyntaxException
{    String fileName = "/TestResettableFileInputStream_1.truncated.avro";    File trackerFile = new File(getClass().getResource(fileName).toURI());    Assert.assertTrue(trackerFile.exists());    PositionTracker tracker;    tracker = new DurablePositionTracker(trackerFile, "foo");        Assert.assertEquals(25, tracker.getPosition());}
d6c2f618159c70276545510a6dd1b4416b18a4730e822557d0d9a8379f2e1bbb
testAvroSerializer
public void testAvroSerializer() throws FileNotFoundException, IOException
{    createAvroFile(TESTFILE, null);    validateAvroFile(TESTFILE);    FileUtils.forceDelete(TESTFILE);}
f1b7703d7bc7af1cc4b3f2b388477732a23199323bddb962f34f7b2bec6a0380
testAvroSerializerNullCompression
public void testAvroSerializerNullCompression() throws FileNotFoundException, IOException
{    createAvroFile(TESTFILE, "null");    validateAvroFile(TESTFILE);    FileUtils.forceDelete(TESTFILE);}
8a4196c34aca288f6be7000cc8aa4884808b0b86e4bbd1bd1e4498caeb81955c
testAvroSerializerDeflateCompression
public void testAvroSerializerDeflateCompression() throws FileNotFoundException, IOException
{    createAvroFile(TESTFILE, "deflate");    validateAvroFile(TESTFILE);    FileUtils.forceDelete(TESTFILE);}
c4a5f7f19f4f9201ff29bff0ddbbc21c8146f0bfcd734e125b44eac32275c2eb
testAvroSerializerSnappyCompression
public void testAvroSerializerSnappyCompression() throws FileNotFoundException, IOException
{        Assume.assumeTrue(!"Mac OS X".equals(System.getProperty("os.name")) || !System.getProperty("java.version").startsWith("1.7."));    createAvroFile(TESTFILE, "snappy");    validateAvroFile(TESTFILE);    FileUtils.forceDelete(TESTFILE);}
3beedb71c27f024048cc769d742ee25d33cd8b6cb0fd7dc8af55c3519eb2aef8
createAvroFile
public void createAvroFile(File file, String codec) throws FileNotFoundException, IOException
{    if (file.exists()) {        FileUtils.forceDelete(file);    }        OutputStream out = new FileOutputStream(file);    Context ctx = new Context();    if (codec != null) {        ctx.put("compressionCodec", codec);    }    EventSerializer.Builder builder = new FlumeEventAvroEventSerializer.Builder();    EventSerializer serializer = builder.build(ctx, out);    serializer.afterCreate();    serializer.write(EventBuilder.withBody("yo man!", Charsets.UTF_8));    serializer.write(EventBuilder.withBody("2nd event!", Charsets.UTF_8));    serializer.write(EventBuilder.withBody("last one!", Charsets.UTF_8));    serializer.flush();    serializer.beforeClose();    out.flush();    out.close();}
053fdcaebd7b0cdcc4016d341256e033a7241b92108e9701373336ea51565b32
validateAvroFile
public void validateAvroFile(File file) throws IOException
{        DatumReader<GenericRecord> reader = new GenericDatumReader<GenericRecord>();    DataFileReader<GenericRecord> fileReader = new DataFileReader<GenericRecord>(file, reader);    GenericRecord record = new GenericData.Record(fileReader.getSchema());    int numEvents = 0;    while (fileReader.hasNext()) {        fileReader.next(record);        ByteBuffer body = (ByteBuffer) record.get("body");        CharsetDecoder decoder = Charsets.UTF_8.newDecoder();        String bodyStr = decoder.decode(body).toString();        System.out.println(bodyStr);        numEvents++;    }    fileReader.close();    Assert.assertEquals("Should have found a total of 3 events", 3, numEvents);}
52cbdf53c523567b2364eedf54458166a2e4dfa2c90b600c5a67ac5d76158ce9
testWithNewline
public void testWithNewline() throws FileNotFoundException, IOException
{    Map<String, String> headers = new HashMap<String, String>();    headers.put("header1", "value1");    headers.put("header2", "value2");    OutputStream out = new FileOutputStream(testFile);    EventSerializer serializer = EventSerializerFactory.getInstance("header_and_text", new Context(), out);    serializer.afterCreate();    serializer.write(EventBuilder.withBody("event 1", Charsets.UTF_8, headers));    serializer.write(EventBuilder.withBody("event 2", Charsets.UTF_8, headers));    serializer.write(EventBuilder.withBody("event 3", Charsets.UTF_8, headers));    serializer.flush();    serializer.beforeClose();    out.flush();    out.close();    BufferedReader reader = new BufferedReader(new FileReader(testFile));    Assert.assertEquals("{header2=value2, header1=value1} event 1", reader.readLine());    Assert.assertEquals("{header2=value2, header1=value1} event 2", reader.readLine());    Assert.assertEquals("{header2=value2, header1=value1} event 3", reader.readLine());    Assert.assertNull(reader.readLine());    reader.close();    FileUtils.forceDelete(testFile);}
7ca325fd63218622725ddd4cf6605bc008c84fa9d77b2e20dafc65165dffd2fc
testNoNewline
public void testNoNewline() throws FileNotFoundException, IOException
{    Map<String, String> headers = new HashMap<String, String>();    headers.put("header1", "value1");    headers.put("header2", "value2");    OutputStream out = new FileOutputStream(testFile);    Context context = new Context();    context.put("appendNewline", "false");    EventSerializer serializer = EventSerializerFactory.getInstance("header_and_text", context, out);    serializer.afterCreate();    serializer.write(EventBuilder.withBody("event 1\n", Charsets.UTF_8, headers));    serializer.write(EventBuilder.withBody("event 2\n", Charsets.UTF_8, headers));    serializer.write(EventBuilder.withBody("event 3\n", Charsets.UTF_8, headers));    serializer.flush();    serializer.beforeClose();    out.flush();    out.close();    BufferedReader reader = new BufferedReader(new FileReader(testFile));    Assert.assertEquals("{header2=value2, header1=value1} event 1", reader.readLine());    Assert.assertEquals("{header2=value2, header1=value1} event 2", reader.readLine());    Assert.assertEquals("{header2=value2, header1=value1} event 3", reader.readLine());    Assert.assertNull(reader.readLine());    reader.close();    FileUtils.forceDelete(testFile);}
5ff0b8f7d2b080bcc6214fa5f91be74727145ea81cacb63a99c8d0f3106c089f
setup
public void setup()
{    StringBuilder sb = new StringBuilder();    sb.append("line 1\n");    sb.append("line 2\n");    mini = sb.toString();}
32a84367eb013cb94c7ed1f29a1624497de1920a58948a2e1df03fccabd66c62
testSimple
public void testSimple() throws IOException
{    ResettableInputStream in = new ResettableTestStringInputStream(mini);    EventDeserializer des = new LineDeserializer(new Context(), in);    validateMiniParse(des);}
f497c90b97ac6150ded473fcbc9852cd06a58f33d996face04ec89cb2ee12187
testSimpleViaBuilder
public void testSimpleViaBuilder() throws IOException
{    ResettableInputStream in = new ResettableTestStringInputStream(mini);    EventDeserializer.Builder builder = new LineDeserializer.Builder();    EventDeserializer des = builder.build(new Context(), in);    validateMiniParse(des);}
6ec2c359dd933b344ad5dfe4c5fce80cdbacb465064151cea418f82a9dc5a5be
testSimpleViaFactory
public void testSimpleViaFactory() throws IOException
{    ResettableInputStream in = new ResettableTestStringInputStream(mini);    EventDeserializer des;    des = EventDeserializerFactory.getInstance("LINE", new Context(), in);    validateMiniParse(des);}
acb7c05d6d1c6eae20d98d66bef35127a15fff8c529d9b477c929594b70eaf93
testBatch
public void testBatch() throws IOException
{    ResettableInputStream in = new ResettableTestStringInputStream(mini);    EventDeserializer des = new LineDeserializer(new Context(), in);    List<Event> events;        events = des.readEvents(1);    Assert.assertEquals(1, events.size());    assertEventBodyEquals("line 1", events.get(0));        events = des.readEvents(10);    Assert.assertEquals(1, events.size());    assertEventBodyEquals("line 2", events.get(0));    des.mark();    des.close();}
6ef8c18bb46f92dbe2f36b9f66520a306c35dff6a795a9cb9ffab7d05de8dc07
testMaxLineLength
public void testMaxLineLength() throws IOException
{    String longLine = "abcdefghijklmnopqrstuvwxyz\n";    Context ctx = new Context();    ctx.put(LineDeserializer.MAXLINE_KEY, "10");    ResettableInputStream in = new ResettableTestStringInputStream(longLine);    EventDeserializer des = new LineDeserializer(ctx, in);    assertEventBodyEquals("abcdefghij", des.readEvent());    assertEventBodyEquals("klmnopqrst", des.readEvent());    assertEventBodyEquals("uvwxyz", des.readEvent());    Assert.assertNull(des.readEvent());}
05e3edadce85d5800c7a30094e91f4722af2211c20b5089f20718edb9e6f953d
assertEventBodyEquals
private void assertEventBodyEquals(String expected, Event event)
{    String bodyStr = new String(event.getBody(), Charsets.UTF_8);    Assert.assertEquals(expected, bodyStr);}
67ad278bfd37e5c8ef4f08d61f76c86b25a937db01dc8fa22335bd85aa8729a2
validateMiniParse
private void validateMiniParse(EventDeserializer des) throws IOException
{    Event evt;    evt = des.readEvent();    Assert.assertEquals(new String(evt.getBody()), "line 1");    des.mark();    evt = des.readEvent();    Assert.assertEquals(new String(evt.getBody()), "line 2");        des.reset();    evt = des.readEvent();    Assert.assertEquals("Line 2 should be repeated, " + "because we reset() the stream", new String(evt.getBody()), "line 2");    evt = des.readEvent();    Assert.assertNull("Event should be null because there are no lines " + "left to read", evt);    des.mark();    des.close();}
27681e68ec2a1eb903f955680ebe003ceb3707295c8aad884b692d378c6e37cf
setup
public void setup() throws Exception
{    Files.createParentDirs(new File(WORK_DIR, "dummy"));    file = File.createTempFile(getClass().getSimpleName(), ".txt", WORK_DIR);    logger.info("Data file: {}", file);    meta = File.createTempFile(getClass().getSimpleName(), ".avro", WORK_DIR);    logger.info("PositionTracker meta file: {}", meta);        meta.delete();}
c6aaebb5a52567751db8dc8e1cb9dd4a4e582ef964a374b376c6a04f741802dc
tearDown
public void tearDown() throws Exception
{    if (CLEANUP) {        meta.delete();        file.delete();    }}
077a7b325c79adde84ee9d44bbda4c20cd851b4457d0f67bdc7171d35426292d
testBasicRead
public void testBasicRead() throws IOException
{    String output = singleLineFileInit(file, Charsets.UTF_8);    PositionTracker tracker = new DurablePositionTracker(meta, file.getPath());    ResettableInputStream in = new ResettableFileInputStream(file, tracker);    String result = readLine(in, output.length());    assertEquals(output, result);    String afterEOF = readLine(in, output.length());    assertNull(afterEOF);    in.close();}
16d9a583d350647ca3d6e844a18438c8c1712c6b8d7a0ef0a273c19c77ab0d86
testReadByte
public void testReadByte() throws IOException
{    byte[] bytes = new byte[255];    for (int i = 0; i < 255; i++) {        bytes[i] = (byte) i;    }    Files.write(bytes, file);    PositionTracker tracker = new DurablePositionTracker(meta, file.getPath());    ResettableInputStream in = new ResettableFileInputStream(file, tracker);    for (int i = 0; i < 255; i++) {        assertEquals(i, in.read());    }    assertEquals(-1, in.read());    in.close();}
480795a50f2a97f46fc02d6e793acbef6a840e3d32a288de21fec62ec92980b8
testMultiByteCharRead
public void testMultiByteCharRead() throws IOException
{    ByteArrayOutputStream out = new ByteArrayOutputStream();    out.write("1234567".getBytes(Charsets.UTF_8));        generateUtf83ByteSequence(out);        Files.write(out.toByteArray(), file);    ResettableInputStream in = initInputStream(8, Charsets.UTF_8, DecodeErrorPolicy.FAIL);    String result = readLine(in, 8);    assertEquals("1234567\u0A93\n", result);}
9d29503747dfc75bdbad532b7e22414b08ea71fe96bd93f27e32d5dc3c730cd7
testUtf8SurrogatePairRead
public void testUtf8SurrogatePairRead() throws IOException
{    ByteArrayOutputStream out = new ByteArrayOutputStream();    out.write("1234567".getBytes(Charsets.UTF_8));    generateUtf8SurrogatePairSequence(out);            Files.write(out.toByteArray(), file);    ResettableInputStream in = initInputStream(8, Charsets.UTF_8, DecodeErrorPolicy.FAIL);    String result = readLine(in, 9);    assertEquals("1234567\uD83D\uDE18\n", result);}
bd44a5fd4c38cfc76060980db57cb89802d1785413cc9109e32a9eae210e3d44
testUtf16BOMAndSurrogatePairRead
public void testUtf16BOMAndSurrogatePairRead() throws IOException
{    ByteArrayOutputStream out = new ByteArrayOutputStream();    generateUtf16SurrogatePairSequence(out);            Files.write(out.toByteArray(), file);    ResettableInputStream in = initInputStream(8, Charsets.UTF_16, DecodeErrorPolicy.FAIL);    String result = readLine(in, 2);    assertEquals("\uD83D\uDE18\n", result);}
026bc872806e11281d4e302d616e0f6a15ddae1e82a2663bae042116b9fcd33a
testShiftJisSurrogateCharRead
public void testShiftJisSurrogateCharRead() throws IOException
{    ByteArrayOutputStream out = new ByteArrayOutputStream();    out.write("1234567".getBytes(Charset.forName("Shift_JIS")));        generateShiftJis2ByteSequence(out);        Files.write(out.toByteArray(), file);    ResettableInputStream in = initInputStream(8, Charset.forName("Shift_JIS"), DecodeErrorPolicy.FAIL);    String result = readLine(in, 8);    assertEquals("1234567\u4E9C\n", result);}
bc14ecae79126f90c3fd8ac8e6d028848fdcfb5d97adc0da02d7bde929e8a052
testUtf8DecodeErrorHandlingFailMalformed
public void testUtf8DecodeErrorHandlingFailMalformed() throws IOException
{    ResettableInputStream in = initUtf8DecodeTest(DecodeErrorPolicy.FAIL);    while (in.readChar() != -1) {        }    fail("Expected MalformedInputException!");}
38c859c8abcb67c632c1b6469cc00bf031cdd0ca64d0e6e0da7a3cf56bbde99c
testUtf8DecodeErrorHandlingIgnore
public void testUtf8DecodeErrorHandlingIgnore() throws IOException
{    ResettableInputStream in = initUtf8DecodeTest(DecodeErrorPolicy.IGNORE);    int c;    StringBuilder sb = new StringBuilder();    while ((c = in.readChar()) != -1) {        sb.append((char) c);    }    assertEquals("Latin1: ()\nLong: ()\nNonUnicode: ()\n", sb.toString());}
60d7923683ac0d8d54118105d7ded81531ae14f8eb569aa47db442a01ec4c978
testUtf8DecodeErrorHandlingReplace
public void testUtf8DecodeErrorHandlingReplace() throws IOException
{    ResettableInputStream in = initUtf8DecodeTest(DecodeErrorPolicy.REPLACE);    int c;    StringBuilder sb = new StringBuilder();    while ((c = in.readChar()) != -1) {        sb.append((char) c);    }    String preJdk8ExpectedStr = "Latin1: (X)\nLong: (XXX)\nNonUnicode: (X)\n";    String expectedStr = "Latin1: (X)\nLong: (XXX)\nNonUnicode: (XXXXX)\n";    String javaVersionStr = System.getProperty("java.version");    double javaVersion = Double.parseDouble(javaVersionStr.substring(0, 3));    if (javaVersion < 1.8) {        assertTrue(preJdk8ExpectedStr.replaceAll("X", "\ufffd").equals(sb.toString()));    } else {        assertTrue(expectedStr.replaceAll("X", "\ufffd").equals(sb.toString()));    }}
d761fdbbdda7743cc7b9978d6bc112f0a699d9c2830ce9cf585392d47ddfb0aa
testLatin1DecodeErrorHandlingFailMalformed
public void testLatin1DecodeErrorHandlingFailMalformed() throws IOException
{    ByteArrayOutputStream out = new ByteArrayOutputStream();    generateLatin1InvalidSequence(out);    Files.write(out.toByteArray(), file);    ResettableInputStream in = initInputStream(DecodeErrorPolicy.FAIL);    while (in.readChar() != -1) {        }    fail("Expected MalformedInputException!");}
ac8181daf396d37f4037e82bbf833a6934209d8316f067989ea1a2a40971585c
testLatin1DecodeErrorHandlingReplace
public void testLatin1DecodeErrorHandlingReplace() throws IOException
{    ByteArrayOutputStream out = new ByteArrayOutputStream();    generateLatin1InvalidSequence(out);    Files.write(out.toByteArray(), file);    ResettableInputStream in = initInputStream(DecodeErrorPolicy.REPLACE);    int c;    StringBuilder sb = new StringBuilder();    while ((c = in.readChar()) != -1) {        sb.append((char) c);    }    assertEquals("Invalid: (X)\n".replaceAll("X", "\ufffd"), sb.toString());}
26689ef90df9999cd92d2c0d527e69125d799e61ab463766f4e98e100bcbb090
testReset
public void testReset() throws IOException
{    String output = singleLineFileInit(file, Charsets.UTF_8);    PositionTracker tracker = new DurablePositionTracker(meta, file.getPath());    ResettableInputStream in = new ResettableFileInputStream(file, tracker);    String result1 = readLine(in, output.length());    assertEquals(output, result1);    in.reset();    String result2 = readLine(in, output.length());    assertEquals(output, result2);    String result3 = readLine(in, output.length());    assertNull("Should be null: " + result3, result3);    in.close();}
3ff208747fdb65d670ea63b2304356b23ccf0b0547363873929b2eaa58824df5
testMarkReset
public void testMarkReset() throws IOException
{    List<String> expected = multiLineFileInit(file, Charsets.UTF_8);    int MAX_LEN = 100;    PositionTracker tracker = new DurablePositionTracker(meta, file.getPath());    ResettableInputStream in = new ResettableFileInputStream(file, tracker);    String result0 = readLine(in, MAX_LEN);    assertEquals(expected.get(0), result0);    in.reset();    String result0a = readLine(in, MAX_LEN);    assertEquals(expected.get(0), result0a);    in.mark();    String result1 = readLine(in, MAX_LEN);    assertEquals(expected.get(1), result1);    in.reset();    String result1a = readLine(in, MAX_LEN);    assertEquals(expected.get(1), result1a);    in.mark();    in.close();}
793a0b5226212128f24c26367fa0cf77d224e25c13fe705db225f0bd3ee323bc
testMarkResetWithSurrogatePairs
public void testMarkResetWithSurrogatePairs() throws IOException
{    ByteArrayOutputStream out = new ByteArrayOutputStream();    out.write("foo".getBytes(Charsets.UTF_8));    generateUtf8SurrogatePairSequence(out);    out.write("bar".getBytes(Charsets.UTF_8));    Files.write(out.toByteArray(), file);    PositionTracker tracker = new DurablePositionTracker(meta, file.getPath());    ResettableInputStream in = new ResettableFileInputStream(file, tracker);    Assert.assertEquals('f', in.readChar());    Assert.assertEquals('o', in.readChar());    in.mark();    Assert.assertEquals('o', in.readChar());        Assert.assertEquals('\ud83d', in.readChar());        in.reset();            Assert.assertEquals('\ude18', in.readChar());        Assert.assertEquals('o', in.readChar());        Assert.assertEquals('\ud83d', in.readChar());            in.mark();        in.reset();            Assert.assertEquals('\ude18', in.readChar());    Assert.assertEquals('b', in.readChar());    Assert.assertEquals('a', in.readChar());        in.reset();    Assert.assertEquals('b', in.readChar());    Assert.assertEquals('a', in.readChar());    Assert.assertEquals('r', in.readChar());    Assert.assertEquals(-1, in.readChar());    in.close();        tracker.close();}
d753ae16e73168863ea46d1fd1a386265dfdce6924e2d2914c028e83adb17157
testResume
public void testResume() throws IOException
{    List<String> expected = multiLineFileInit(file, Charsets.UTF_8);    int MAX_LEN = 100;    PositionTracker tracker = new DurablePositionTracker(meta, file.getPath());    ResettableInputStream in = new ResettableFileInputStream(file, tracker);    String result0 = readLine(in, MAX_LEN);    String result1 = readLine(in, MAX_LEN);    in.mark();    String result2 = readLine(in, MAX_LEN);    Assert.assertEquals(expected.get(2), result2);    String result3 = readLine(in, MAX_LEN);    Assert.assertEquals(expected.get(3), result3);    in.close();        tracker.close();        tracker = new DurablePositionTracker(meta, file.getPath());    in = new ResettableFileInputStream(file, tracker);    String result2a = readLine(in, MAX_LEN);    String result3a = readLine(in, MAX_LEN);    Assert.assertEquals(result2, result2a);    Assert.assertEquals(result3, result3a);}
33fbf6f0186cf7a7febf7cd0e0a607b625e7770eda67be149f9a93897091c945
testResumeWithSurrogatePairs
public void testResumeWithSurrogatePairs() throws IOException
{    ByteArrayOutputStream out = new ByteArrayOutputStream();    out.write("foo".getBytes(Charsets.UTF_8));    generateUtf8SurrogatePairSequence(out);    out.write("bar".getBytes(Charsets.UTF_8));    Files.write(out.toByteArray(), file);    PositionTracker tracker = new DurablePositionTracker(meta, file.getPath());    ResettableInputStream in = new ResettableFileInputStream(file, tracker);    Assert.assertEquals('f', in.readChar());    Assert.assertEquals('o', in.readChar());    in.mark();    Assert.assertEquals('o', in.readChar());        Assert.assertEquals('\ud83d', in.readChar());        in.reset();            in.close();        tracker.close();        tracker = new DurablePositionTracker(meta, file.getPath());    in = new ResettableFileInputStream(file, tracker);        Assert.assertEquals('o', in.readChar());        Assert.assertEquals('\ud83d', in.readChar());            in.mark();            in.close();        tracker.close();        tracker = new DurablePositionTracker(meta, file.getPath());    in = new ResettableFileInputStream(file, tracker);        Assert.assertEquals('b', in.readChar());    Assert.assertEquals('a', in.readChar());    Assert.assertEquals('r', in.readChar());    Assert.assertEquals(-1, in.readChar());    in.close();        tracker.close();}
8efad1ad7ceaf9676979aed14ccddbf65f0e21a33103745bb53e755215471228
testSeek
public void testSeek() throws IOException
{    int NUM_LINES = 1000;    int LINE_LEN = 1000;    generateData(file, Charsets.UTF_8, NUM_LINES, LINE_LEN);    PositionTracker tracker = new DurablePositionTracker(meta, file.getPath());    ResettableInputStream in = new ResettableFileInputStream(file, tracker, 10 * LINE_LEN, Charsets.UTF_8, DecodeErrorPolicy.FAIL);    String line = "";    for (int i = 0; i < 9; i++) {        line = readLine(in, LINE_LEN);    }    int lineNum = Integer.parseInt(line.substring(0, 10));    assertEquals(8, lineNum);        long pos = in.tell();        in.seek(pos - 2 * LINE_LEN);    line = readLine(in, LINE_LEN);    lineNum = Integer.parseInt(line.substring(0, 10));    assertEquals(7, lineNum);        in.seek(in.tell() + LINE_LEN);    line = readLine(in, LINE_LEN);    lineNum = Integer.parseInt(line.substring(0, 10));    assertEquals(9, lineNum);        in.seek(in.tell() + 20 * LINE_LEN);    line = readLine(in, LINE_LEN);    lineNum = Integer.parseInt(line.substring(0, 10));    assertEquals(30, lineNum);        in.seek(in.tell() - 25 * LINE_LEN);    line = readLine(in, LINE_LEN);    lineNum = Integer.parseInt(line.substring(0, 10));    assertEquals(6, lineNum);        in.seek(100 * LINE_LEN);        in.seek(0);    in.seek(9 * LINE_LEN);    assertEquals(9, Integer.parseInt(readLine(in, LINE_LEN).substring(0, 10)));    assertEquals(10, Integer.parseInt(readLine(in, LINE_LEN).substring(0, 10)));    assertEquals(11, Integer.parseInt(readLine(in, LINE_LEN).substring(0, 10)));}
488c09d89acced6aa1af518072a6cc90105d695d653b8a689d3b92da67ac59b6
initUtf8DecodeTest
private ResettableInputStream initUtf8DecodeTest(DecodeErrorPolicy policy) throws IOException
{    writeBigBadUtf8Sequence(file);    return initInputStream(policy);}
b199c7dfd6a85e108c3e3bf7e6640ef53d8fa1f8225320aeb23405b0e1be8884
initInputStream
private ResettableInputStream initInputStream(DecodeErrorPolicy policy) throws IOException
{    return initInputStream(2048, Charsets.UTF_8, policy);}
7217280e4bceed61e1375b77de9c15b2c1569fff199a7015c69deb3f2ea02fc8
initInputStream
private ResettableInputStream initInputStream(int bufferSize, Charset charset, DecodeErrorPolicy policy) throws IOException
{    PositionTracker tracker = new DurablePositionTracker(meta, file.getPath());    ResettableInputStream in = new ResettableFileInputStream(file, tracker, bufferSize, charset, policy);    return in;}
1300ff0579548d7d252cc26947227b09c2795cc113272d206854ada2fdb722a4
writeBigBadUtf8Sequence
private void writeBigBadUtf8Sequence(File file) throws IOException
{    ByteArrayOutputStream out = new ByteArrayOutputStream();    generateUtf8Latin1Sequence(out);    generateUtf8OverlyLongSequence(out);    generateUtf8NonUnicodeSequence(out);    Files.write(out.toByteArray(), file);}
7ffc7b25c03a0aceedf4a63a862d0d674ba9ea05f014479547a6b73789a815e9
generateUtf8OverlyLongSequence
private void generateUtf8OverlyLongSequence(OutputStream out) throws IOException
{    out.write("Long: (".getBytes(Charsets.UTF_8));        out.write(new byte[] { (byte) 0xe0, (byte) 0x80, (byte) 0xaf });    out.write(")\n".getBytes(Charsets.UTF_8));}
a6204851523f2e2ae681209af212ed1b9a8ee2fb655153810909121167e78581
generateUtf8NonUnicodeSequence
private void generateUtf8NonUnicodeSequence(OutputStream out) throws IOException
{    out.write("NonUnicode: (".getBytes(Charsets.UTF_8));        out.write(new byte[] { (byte) 0xf8, (byte) 0xa1, (byte) 0xa1, (byte) 0xa1, (byte) 0xa1 });    out.write(")\n".getBytes(Charsets.UTF_8));}
75f6c28c63c006a46565ab2555fc79f7a2789c2a630280abbb438382d9bb4e63
generateUtf8Latin1Sequence
private void generateUtf8Latin1Sequence(OutputStream out) throws IOException
{    out.write("Latin1: (".getBytes(Charsets.UTF_8));        out.write(new byte[] { (byte) 0xe9 });    out.write(")\n".getBytes(Charsets.UTF_8));}
32995fe7a780e43ba6174949a169fe13128902f89e5499a165e339ac2aa49f6c
generateLatin1InvalidSequence
private void generateLatin1InvalidSequence(OutputStream out) throws IOException
{    out.write("Invalid: (".getBytes(Charsets.UTF_8));        out.write(new byte[] { (byte) 0x81 });    out.write(")\n".getBytes(Charsets.UTF_8));}
1c097fde5d6ac649a747d8d589fcb148076ee62c02b2a3b88a06822cb7d5e6fe
generateUtf8SurrogatePairSequence
private void generateUtf8SurrogatePairSequence(OutputStream out) throws IOException
{        out.write(new byte[] { (byte) 0xF0, (byte) 0x9F, (byte) 0x98, (byte) 0x98 });}
4f98bf87ebc3526c11c9a30a607c0470daee19aaa7727d635131421d59e42d45
generateUtf16SurrogatePairSequence
private void generateUtf16SurrogatePairSequence(OutputStream out) throws IOException
{        out.write(new byte[] { (byte) 0xFE, (byte) 0xFF });        out.write(new byte[] { (byte) 0xD8, (byte) 0x3D, (byte) 0xDE, (byte) 0x18 });}
28d6c5b7348be122d7b7f1edd81b90769681b44881bc7a4b90cebafdaa25cddd
generateUtf83ByteSequence
private void generateUtf83ByteSequence(OutputStream out) throws IOException
{        out.write(new byte[] { (byte) 0xe0, (byte) 0xaa, (byte) 0x93 });}
d218c12e9b04ccfed23df3427bc76f71611a520ac59c9cd820d7b01a6b2b41f6
generateShiftJis2ByteSequence
private void generateShiftJis2ByteSequence(OutputStream out) throws IOException
{        out.write(new byte[] { (byte) 0x88, (byte) 0x9f });}
7046f2ed6379e4a3156aace85acb47442710f9210be580a9c4162558debff54b
readLine
private static String readLine(ResettableInputStream in, int maxLength) throws IOException
{    StringBuilder s = new StringBuilder();    int c;    int i = 1;    while ((c = in.readChar()) != -1) {                if (c == '\n') {            break;        }                s.append((char) c);        if (i++ > maxLength) {            System.out.println("Output: >" + s + "<");            throw new RuntimeException("Too far!");        }    }    if (s.length() > 0) {        s.append('\n');        return s.toString();    } else {        return null;    }}
9dc04baff60ccee022ac62e74ce00eb1367896545cd000b5685d9366131f7a6d
singleLineFileInit
private static String singleLineFileInit(File file, Charset charset) throws IOException
{    String output = "This is gonna be great!\n";    Files.write(output.getBytes(charset), file);    return output;}
2c278d06ec34688bbd308927743afa1e68625f9112cf5f068185e731f0c04c88
multiLineFileInit
private static List<String> multiLineFileInit(File file, Charset charset) throws IOException
{    List<String> lines = Lists.newArrayList();    lines.add("1. On the planet of Mars\n");    lines.add("2. They have clothes just like ours,\n");    lines.add("3. And they have the same shoes and same laces,\n");    lines.add("4. And they have the same charms and same graces...\n");    StringBuilder sb = new StringBuilder();    for (String line : lines) {        sb.append(line);    }    Files.write(sb.toString().getBytes(charset), file);    return lines;}
8d024eabefac491145728e4ce51cb71cdeadf959daae9429a9074c96673be822
generateData
private static void generateData(File file, Charset charset, int numLines, int lineLen) throws IOException
{    OutputStream out = new BufferedOutputStream(new FileOutputStream(file));    StringBuilder junk = new StringBuilder();    for (int x = 0; x < lineLen - 13; x++) {        junk.append('x');    }    String payload = junk.toString();    StringBuilder builder = new StringBuilder();    for (int i = 0; i < numLines; i++) {        builder.append(String.format("%010d: %s\n", i, payload));        if (i % 1000 == 0 && i != 0) {            out.write(builder.toString().getBytes(charset));            builder.setLength(0);        }    }    out.write(builder.toString().getBytes(charset));    out.close();    Assert.assertEquals(lineLen * numLines, file.length());}
685075474ffd4270a1e9180f19b49225faa603992c11dc1236416f724ee2c639
generateSyslogEvents
private static List<Event> generateSyslogEvents()
{    List<Event> list = Lists.newArrayList();    Event e;        e = EventBuilder.withBody("Apr  7 01:00:00 host Msg 01", Charsets.UTF_8);    e.getHeaders().put(SyslogUtils.SYSLOG_FACILITY, "1");    e.getHeaders().put(SyslogUtils.SYSLOG_SEVERITY, "2");    list.add(e);        e = EventBuilder.withBody("Apr 22 01:00:00 host Msg 02", Charsets.UTF_8);    e.getHeaders().put(SyslogUtils.SYSLOG_FACILITY, "1");    e.getHeaders().put(SyslogUtils.SYSLOG_SEVERITY, "3");    list.add(e);        e = EventBuilder.withBody("<8>Apr 22 01:00:00 host Msg 03", Charsets.UTF_8);    list.add(e);    return list;}
339b50e5383cadcb678910a88fa26ac78c6e7f688677b264e6370e0a2effeeef
test
public void test() throws FileNotFoundException, IOException
{        Assume.assumeTrue(!"Mac OS X".equals(System.getProperty("os.name")) || !System.getProperty("java.version").startsWith("1.7."));            OutputStream out = new FileOutputStream(testFile);    String builderName = SyslogAvroEventSerializer.Builder.class.getName();    Context ctx = new Context();    ctx.put("syncInterval", "4096");    ctx.put("compressionCodec", "snappy");    EventSerializer serializer = EventSerializerFactory.getInstance(builderName, ctx, out);        serializer.afterCreate();    List<Event> events = generateSyslogEvents();    for (Event e : events) {        serializer.write(e);    }    serializer.flush();    serializer.beforeClose();    out.flush();    out.close();        DatumReader<GenericRecord> reader = new GenericDatumReader<GenericRecord>();    DataFileReader<GenericRecord> fileReader = new DataFileReader<GenericRecord>(testFile, reader);    GenericRecord record = new GenericData.Record(fileReader.getSchema());    int numEvents = 0;    while (fileReader.hasNext()) {        fileReader.next(record);        int facility = (Integer) record.get("facility");        int severity = (Integer) record.get("severity");        long timestamp = (Long) record.get("timestamp");        String hostname = record.get("hostname").toString();        String message = record.get("message").toString();        Assert.assertEquals("Facility should be 1", 1, facility);        System.out.println(timestamp + ": " + message);        numEvents++;    }    fileReader.close();    Assert.assertEquals("Should have found a total of 3 events", 3, numEvents);    FileUtils.forceDelete(testFile);}
fe9fbec2aa2b036379a9c23a980ccf4be8edeb363d8f9f9c2bbd322574292201
storePosition
public void storePosition(long position) throws IOException
{    this.position = position;}
440295a41d4e3cef67a12523813a1969b46946ef4ce8d8b8b75a27bceedd007b
getPosition
public long getPosition()
{    return position;}
bbc94651494aa1806a69f755aa4fb0e77230e45e6bab1ee17a348de34ee7d11f
getTarget
public String getTarget()
{    return target;}
e0823f55b3a09d41a3e1e792f7e6687db9199c2db9b29e9922d93cbdc6f1284b
close
public void close() throws IOException
{}
dea5ea7b472761f6d87672c86d98f9e92684516fee22a20090f9681327cd5b74
createSinkIterator
public Iterator<Sink> createSinkIterator()
{    return getSinks().iterator();}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    super.configure(context);    if (context.getString(SET_ME) == null) {        throw new RuntimeException("config key " + SET_ME + " not specified");    }}
a505a221a080c584c1896dbef1a0d5c74c6ef08b41d9b90521f8bad26d05354c
test
public void test()
{    Context context = new Context();    context.put("type", FailoverSinkProcessor.class.getName());    context.put("priority.sink1", "1");    context.put("priority.sink2", "2");    SinkFactory sf = new DefaultSinkFactory();    List<Sink> sinks = new ArrayList<Sink>();    sinks.add(sf.create("sink1", "avro"));    sinks.add(sf.create("sink2", "avro"));    SinkProcessor sp = SinkProcessorFactory.getProcessor(context, sinks);    context.put("type", "failover");    SinkProcessor sp2 = SinkProcessorFactory.getProcessor(context, sinks);    Assert.assertEquals(sp.getClass(), sp2.getClass());}
d8bec4b40e2f051599283f5dfa7bc5792a1416a367140747230c06494fe5845d
testInstantiatingLoadBalancingSinkProcessor
public void testInstantiatingLoadBalancingSinkProcessor()
{    Context context = new Context();    context.put("type", LoadBalancingSinkProcessor.class.getName());    context.put("selector", "random");    SinkFactory sf = new DefaultSinkFactory();    List<Sink> sinks = new ArrayList<Sink>();    sinks.add(sf.create("sink1", "avro"));    sinks.add(sf.create("sink2", "avro"));    SinkProcessor sp = SinkProcessorFactory.getProcessor(context, sinks);    context.put("type", "load_balance");    SinkProcessor sp2 = SinkProcessorFactory.getProcessor(context, sinks);    Assert.assertEquals(sp.getClass(), sp2.getClass());}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    setUp("none", 0);}
77699adcf354004a7e427a77903b9d26d8753e8a3711c65533707ee47481e0b9
setUp
public void setUp(String compressionType, int compressionLevel)
{    if (sink != null) {        throw new RuntimeException("double setup");    }    sink = new AvroSink();    channel = new MemoryChannel();    Context context = createBaseContext();    if (compressionType.equals("deflate")) {        context.put("compression-type", compressionType);        context.put("compression-level", Integer.toString(compressionLevel));    }    sink.setChannel(channel);    Configurables.configure(sink, context);    Configurables.configure(channel, context);}
da20136ddae1a4d237464815f4be04143afb0882d1440ad4da0d8b8607a29cb4
createBaseContext
private Context createBaseContext()
{    Context context = new Context();    context.put("hostname", hostname);    context.put("port", String.valueOf(port));    context.put("batch-size", String.valueOf(2));    context.put("connect-timeout", String.valueOf(2000L));    context.put("request-timeout", String.valueOf(3000L));    return context;}
f886ef2b967939d166d3c3e803ece5e059413b59be6e671afcffd235b985d8df
createServer
private Server createServer(AvroSourceProtocol protocol) throws IllegalAccessException, InstantiationException
{    Server server = new NettyServer(new SpecificResponder(AvroSourceProtocol.class, protocol), new InetSocketAddress(hostname, port));    return server;}
6d88781de2af935eebc21db7db9d4de72f21435cd8847dd53246a4ea598f807a
testLifecycle
public void testLifecycle() throws InterruptedException, InstantiationException, IllegalAccessException
{    setUp();    Server server = createServer(new MockAvroServer());    server.start();    sink.start();    Assert.assertTrue(LifecycleController.waitForOneOf(sink, LifecycleState.START_OR_ERROR, 5000));    sink.stop();    Assert.assertTrue(LifecycleController.waitForOneOf(sink, LifecycleState.STOP_OR_ERROR, 5000));    server.close();}
4afe32a4e025390c48e31ded629950f7d5923342a27ea0a580754296f8e957e0
testProcess
public void testProcess() throws InterruptedException, EventDeliveryException, InstantiationException, IllegalAccessException
{    setUp();    Event event = EventBuilder.withBody("test event 1", Charsets.UTF_8);    Server server = createServer(new MockAvroServer());    server.start();    sink.start();    Assert.assertTrue(LifecycleController.waitForOneOf(sink, LifecycleState.START_OR_ERROR, 5000));    Transaction transaction = channel.getTransaction();    transaction.begin();    for (int i = 0; i < 10; i++) {        channel.put(event);    }    transaction.commit();    transaction.close();    for (int i = 0; i < 5; i++) {        Sink.Status status = sink.process();        Assert.assertEquals(Sink.Status.READY, status);    }    Assert.assertEquals(Sink.Status.BACKOFF, sink.process());    sink.stop();    Assert.assertTrue(LifecycleController.waitForOneOf(sink, LifecycleState.STOP_OR_ERROR, 5000));    server.close();}
133889073b798e91e5f943a5f53441727de8b1469e9c7b0f0d9e93d06fd3b07f
testChannelException
public void testChannelException() throws InterruptedException, EventDeliveryException, InstantiationException, IllegalAccessException
{    setUp();    Server server = createServer(new MockAvroServer());    server.start();    sink.start();    Channel channel = Mockito.mock(Channel.class);    Mockito.when(channel.take()).thenThrow(new ChannelException("dummy"));    Transaction transaction = Mockito.mock(BasicTransactionSemantics.class);    Mockito.when(channel.getTransaction()).thenReturn(transaction);    sink.setChannel(channel);    Sink.Status status = sink.process();    sink.stop();    server.close();    SinkCounter sinkCounter = (SinkCounter) Whitebox.getInternalState(sink, "sinkCounter");    Assert.assertEquals(1, sinkCounter.getChannelReadFail());}
e95df02a7e540efd7d7920f1921dd3f5c279ca7a3cc56279d08f64baf4360d64
testTimeout
public void testTimeout() throws InterruptedException, EventDeliveryException, InstantiationException, IllegalAccessException
{    setUp();    Event event = EventBuilder.withBody("foo", Charsets.UTF_8);    AtomicLong delay = new AtomicLong();    Server server = createServer(new DelayMockAvroServer(delay));    server.start();    sink.start();    Assert.assertTrue(LifecycleController.waitForOneOf(sink, LifecycleState.START_OR_ERROR, 5000));    Transaction txn = channel.getTransaction();    txn.begin();    for (int i = 0; i < 4; i++) {        channel.put(event);    }    txn.commit();    txn.close();            delay.set(3000L);    boolean threw = false;    try {        sink.process();    } catch (EventDeliveryException ex) {        logger.info("Correctly threw due to connect timeout. Exception follows.", ex);        threw = true;    }    Assert.assertTrue("Must throw due to connect timeout", threw);        delay.set(0);    sink.process();            delay.set(4000L);    threw = false;    try {        sink.process();    } catch (EventDeliveryException ex) {        logger.info("Correctly threw due to request timeout. Exception follows.", ex);        threw = true;    }    Assert.assertTrue("Must throw due to request timeout", threw);    sink.stop();    Assert.assertTrue(LifecycleController.waitForOneOf(sink, LifecycleState.STOP_OR_ERROR, 5000));    server.close();    SinkCounter sinkCounter = (SinkCounter) Whitebox.getInternalState(sink, "sinkCounter");    Assert.assertEquals(2, sinkCounter.getEventWriteFail());}
739b586bd17b6b0660fade9a24451fa6ebba7587a1810337859b161b7ef9f0c4
testFailedConnect
public void testFailedConnect() throws InterruptedException, EventDeliveryException, InstantiationException, IllegalAccessException
{    setUp();    Event event = EventBuilder.withBody("test event 1", Charset.forName("UTF8"));    Server server = createServer(new MockAvroServer());    server.start();    sink.start();    Assert.assertTrue(LifecycleController.waitForOneOf(sink, LifecycleState.START_OR_ERROR, 5000));        Thread.sleep(500L);    server.close();        Thread.sleep(500L);    Transaction transaction = channel.getTransaction();    transaction.begin();    for (int i = 0; i < 10; i++) {        channel.put(event);    }    transaction.commit();    transaction.close();    for (int i = 0; i < 5; i++) {        boolean threwException = false;        try {            sink.process();        } catch (EventDeliveryException e) {            threwException = true;        }        Assert.assertTrue("Must throw EventDeliveryException if disconnected", threwException);    }    server = createServer(new MockAvroServer());    server.start();    for (int i = 0; i < 5; i++) {        Sink.Status status = sink.process();        Assert.assertEquals(Sink.Status.READY, status);    }    Assert.assertEquals(Sink.Status.BACKOFF, sink.process());    sink.stop();    Assert.assertTrue(LifecycleController.waitForOneOf(sink, LifecycleState.STOP_OR_ERROR, 5000));    server.close();    SinkCounter sinkCounter = (SinkCounter) Whitebox.getInternalState(sink, "sinkCounter");    Assert.assertEquals(5, sinkCounter.getEventWriteFail());    Assert.assertEquals(4, sinkCounter.getConnectionFailedCount());}
66f4db13c030f4511cdcd810b074238c670ea594cbe5d25968e9a4c03aa6d1a0
testReset
public void testReset() throws Exception
{    setUp();    Server server = createServer(new MockAvroServer());    server.start();    Context context = new Context();    context.put("hostname", hostname);    context.put("port", String.valueOf(port));    context.put("batch-size", String.valueOf(2));    context.put("connect-timeout", String.valueOf(2000L));    context.put("request-timeout", String.valueOf(3000L));    context.put("reset-connection-interval", String.valueOf("5"));    sink.setChannel(channel);    Configurables.configure(sink, context);    sink.start();    RpcClient firstClient = sink.getUnderlyingClient();    Thread.sleep(6000);    Transaction t = channel.getTransaction();    t.begin();    channel.put(EventBuilder.withBody("This is a test", Charset.defaultCharset()));    t.commit();    t.close();    sink.process();        Assert.assertFalse(firstClient == sink.getUnderlyingClient());    sink.stop();    context.put("hostname", hostname);    context.put("port", String.valueOf(port));    context.put("batch-size", String.valueOf(2));    context.put("connect-timeout", String.valueOf(2000L));    context.put("request-timeout", String.valueOf(3000L));    context.put("reset-connection-interval", String.valueOf("0"));    sink.setChannel(channel);    Configurables.configure(sink, context);    sink.start();    firstClient = sink.getUnderlyingClient();    Thread.sleep(6000);        Assert.assertTrue(firstClient == sink.getUnderlyingClient());    sink.stop();    context.clear();    context.put("hostname", hostname);    context.put("port", String.valueOf(port));    context.put("batch-size", String.valueOf(2));    context.put("connect-timeout", String.valueOf(2000L));    context.put("request-timeout", String.valueOf(3000L));    sink.setChannel(channel);    Configurables.configure(sink, context);    sink.start();    firstClient = sink.getUnderlyingClient();    Thread.sleep(6000);        Assert.assertTrue(firstClient == sink.getUnderlyingClient());    sink.stop();    server.close();}
5633262f200cdd75b67617e0f51f8c38269058aafbd48a4b6b9c77fc67c0f715
testSslProcessTrustAllCerts
public void testSslProcessTrustAllCerts() throws InterruptedException, EventDeliveryException, InstantiationException, IllegalAccessException
{    setUp();    Context context = createBaseContext();    context.put("ssl", String.valueOf(true));    context.put("trust-all-certs", String.valueOf(true));    Configurables.configure(sink, context);    doTestSslProcess();}
1ba89474a308824bfc2b0822e7fbdfd5dc8eace7bb2f0d8004c20b97ce3f297a
testSslProcessWithComponentTruststore
public void testSslProcessWithComponentTruststore() throws InterruptedException, EventDeliveryException, InstantiationException, IllegalAccessException
{    setUp();    Context context = createBaseContext();    context.put("ssl", String.valueOf(true));    context.put("truststore", "src/test/resources/truststore.jks");    context.put("truststore-password", "password");    Configurables.configure(sink, context);    doTestSslProcess();}
504d5347e3c8807f9525828ed9982ec041ddb47a816d3656a93738eee002c783
testSslProcessWithComponentTruststoreNoPassword
public void testSslProcessWithComponentTruststoreNoPassword() throws InterruptedException, EventDeliveryException, InstantiationException, IllegalAccessException
{    setUp();    Context context = createBaseContext();    context.put("ssl", String.valueOf(true));    context.put("truststore", "src/test/resources/truststore.jks");    Configurables.configure(sink, context);    doTestSslProcess();}
31654be0112d2bcf1451c093aec36b05c469e01eba0cf44bb2faa0ad47c48098
testSslProcessWithGlobalTruststore
public void testSslProcessWithGlobalTruststore() throws InterruptedException, EventDeliveryException, InstantiationException, IllegalAccessException
{    setUp();    System.setProperty("javax.net.ssl.trustStore", "src/test/resources/truststore.jks");    System.setProperty("javax.net.ssl.trustStorePassword", "password");    Context context = createBaseContext();    context.put("ssl", String.valueOf(true));    Configurables.configure(sink, context);    doTestSslProcess();    System.clearProperty("javax.net.ssl.trustStore");    System.clearProperty("javax.net.ssl.trustStorePassword");}
56201e4e87ed56957b69f2a10e1d0653d2c2da84477d56d5190ca230c6c113d9
testSslProcessWithGlobalTruststoreNoPassword
public void testSslProcessWithGlobalTruststoreNoPassword() throws InterruptedException, EventDeliveryException, InstantiationException, IllegalAccessException
{    setUp();    System.setProperty("javax.net.ssl.trustStore", "src/test/resources/truststore.jks");    Context context = createBaseContext();    context.put("ssl", String.valueOf(true));    Configurables.configure(sink, context);    doTestSslProcess();    System.clearProperty("javax.net.ssl.trustStore");}
da5593aed532710faba14fac3710c7529ebaec6458a77fa93f32d57b58458d1a
doTestSslProcess
private void doTestSslProcess() throws InterruptedException, EventDeliveryException, InstantiationException, IllegalAccessException
{    Server server = createSslServer(new MockAvroServer());    server.start();    sink.start();    Assert.assertTrue(LifecycleController.waitForOneOf(sink, LifecycleState.START_OR_ERROR, 5000));    Transaction transaction = channel.getTransaction();    transaction.begin();    Event event = EventBuilder.withBody("test event 1", Charsets.UTF_8);    for (int i = 0; i < 10; i++) {        channel.put(event);    }    transaction.commit();    transaction.close();    for (int i = 0; i < 5; i++) {        Sink.Status status = sink.process();        Assert.assertEquals(Sink.Status.READY, status);    }    Assert.assertEquals(Sink.Status.BACKOFF, sink.process());    sink.stop();    Assert.assertTrue(LifecycleController.waitForOneOf(sink, LifecycleState.STOP_OR_ERROR, 5000));    server.close();}
be4d0b5747e3e2017350246057e18178bce350766838d36ad0864e661fe224e4
testSslWithCompression
public void testSslWithCompression() throws InterruptedException, EventDeliveryException, InstantiationException, IllegalAccessException
{    setUp("deflate", 6);    boolean bound = false;    AvroSource source;    Channel sourceChannel;    int selectedPort;    source = new AvroSource();    sourceChannel = new MemoryChannel();    Configurables.configure(sourceChannel, new Context());    List<Channel> channels = new ArrayList<Channel>();    channels.add(sourceChannel);    ChannelSelector rcs = new ReplicatingChannelSelector();    rcs.setChannels(channels);    source.setChannelProcessor(new ChannelProcessor(rcs));    Context context = new Context();    context.put("port", port.toString());    context.put("bind", hostname);    context.put("threads", "50");    context.put("compression-type", "deflate");    context.put("ssl", String.valueOf(true));    context.put("keystore", "src/test/resources/server.p12");    context.put("keystore-password", "password");    context.put("keystore-type", "PKCS12");    Configurables.configure(source, context);    source.start();    Assert.assertTrue("Reached start or error", LifecycleController.waitForOneOf(source, LifecycleState.START_OR_ERROR));    Assert.assertEquals("Server is started", LifecycleState.START, source.getLifecycleState());    Event event = EventBuilder.withBody("Hello avro", Charset.forName("UTF8"));    context = createBaseContext();    context.put("ssl", String.valueOf(true));    context.put("trust-all-certs", String.valueOf(true));    context.put("compression-type", "deflate");    context.put("compression-level", Integer.toString(6));    Configurables.configure(sink, context);    sink.start();    Transaction sickTransaction = channel.getTransaction();    sickTransaction.begin();    for (int i = 0; i < 10; i++) {        channel.put(event);    }    sickTransaction.commit();    sickTransaction.close();    for (int i = 0; i < 5; i++) {        Sink.Status status = sink.process();        logger.debug("Calling Process " + i + " times:" + status);        Assert.assertEquals(Sink.Status.READY, status);    }    sink.stop();    Transaction sourceTransaction = sourceChannel.getTransaction();    sourceTransaction.begin();    Event sourceEvent = sourceChannel.take();    Assert.assertNotNull(sourceEvent);    Assert.assertEquals("Channel contained our event", "Hello avro", new String(sourceEvent.getBody()));    sourceTransaction.commit();    sourceTransaction.close();    logger.debug("Round trip event:{}", sourceEvent);    source.stop();    Assert.assertTrue("Reached stop or error", LifecycleController.waitForOneOf(source, LifecycleState.STOP_OR_ERROR));    Assert.assertEquals("Server is stopped", LifecycleState.STOP, source.getLifecycleState());}
1c04b01bcb5cd022e74867764dc244ac7921688efaa1fc5ece50178ce82004bb
testSslSinkWithNonSslServer
public void testSslSinkWithNonSslServer() throws InterruptedException, InstantiationException, IllegalAccessException
{    setUp();    Server server = createServer(new MockAvroServer());    server.start();    Context context = createBaseContext();    context.put("ssl", String.valueOf(true));    context.put("trust-all-certs", String.valueOf(true));    Configurables.configure(sink, context);    boolean failed = doRequestWhenFailureExpected();    server.close();    if (!failed) {        Assert.fail("SSL-enabled sink successfully connected to a non-SSL-enabled server, " + "that's wrong.");    }    SinkCounter sinkCounter = (SinkCounter) Whitebox.getInternalState(sink, "sinkCounter");    Assert.assertEquals(1, sinkCounter.getEventWriteFail());}
101a32498acfdc2a020472a5ab5c8ef4df945021706557287fff3094bbc4c93d
testSslSinkWithNonTrustedCert
public void testSslSinkWithNonTrustedCert() throws InterruptedException, InstantiationException, IllegalAccessException
{    setUp();    Server server = createSslServer(new MockAvroServer());    server.start();    Context context = createBaseContext();    context.put("ssl", String.valueOf(true));    Configurables.configure(sink, context);    boolean failed = doRequestWhenFailureExpected();    server.close();    if (!failed) {        Assert.fail("SSL-enabled sink successfully connected to a server with an " + "untrusted certificate when it should have failed");    }    SinkCounter sinkCounter = (SinkCounter) Whitebox.getInternalState(sink, "sinkCounter");    Assert.assertEquals(1, sinkCounter.getEventWriteFail());}
5c09239692ad92267d91e4d5abe90cfd4bf183fa2304bc43756d283b92032412
doRequestWhenFailureExpected
private boolean doRequestWhenFailureExpected() throws InterruptedException
{    sink.start();    Assert.assertTrue(LifecycleController.waitForOneOf(sink, LifecycleState.START_OR_ERROR, 5000));    Transaction transaction = channel.getTransaction();    transaction.begin();    Event event = EventBuilder.withBody("test event 1", Charsets.UTF_8);    channel.put(event);    transaction.commit();    transaction.close();    boolean failed;    try {        sink.process();        failed = false;    } catch (EventDeliveryException ex) {        logger.info("Correctly failed to send event", ex);        failed = true;    }    sink.stop();    Assert.assertTrue(LifecycleController.waitForOneOf(sink, LifecycleState.STOP_OR_ERROR, 5000));    return failed;}
33b62e1c7be812f512556661355158fd9a23077b6df105ffe3a1a07692e73a6f
testRequestWithNoCompression
public void testRequestWithNoCompression() throws InterruptedException, IOException, EventDeliveryException
{    doRequest(false, false, 6);}
84d2d3b14879b614db72791918a94d264d3eda170957deee90626d3a357e6876
testRequestWithCompressionOnClientAndServerOnLevel0
public void testRequestWithCompressionOnClientAndServerOnLevel0() throws InterruptedException, IOException, EventDeliveryException
{    doRequest(true, true, 0);}
0ea0c491c16fea549d7f44d03bc388bdb440cb9eabd5c2b479e9d4a8526a76c6
testRequestWithCompressionOnClientAndServerOnLevel1
public void testRequestWithCompressionOnClientAndServerOnLevel1() throws InterruptedException, IOException, EventDeliveryException
{    doRequest(true, true, 1);}
056b2dd70b0ba47f3c8b55261b66e3b23a07286811fba6ff8e822daea87bbb18
testRequestWithCompressionOnClientAndServerOnLevel6
public void testRequestWithCompressionOnClientAndServerOnLevel6() throws InterruptedException, IOException, EventDeliveryException
{    doRequest(true, true, 6);}
de31bbc9ea2e9015b76d82369157697a93a9e4ba3e5fe29cf92ae1cc6a0e8363
testRequestWithCompressionOnClientAndServerOnLevel9
public void testRequestWithCompressionOnClientAndServerOnLevel9() throws InterruptedException, IOException, EventDeliveryException
{    doRequest(true, true, 9);}
3010af4480dbbdf2b1c655cfcb83ce77c17f87e952d38e2ffd0ce6d16eacc199
doRequest
private void doRequest(boolean serverEnableCompression, boolean clientEnableCompression, int compressionLevel) throws InterruptedException, IOException, EventDeliveryException
{    if (clientEnableCompression) {        setUp("deflate", compressionLevel);    } else {        setUp("none", compressionLevel);    }    boolean bound = false;    AvroSource source;    Channel sourceChannel;    int selectedPort;    source = new AvroSource();    sourceChannel = new MemoryChannel();    Configurables.configure(sourceChannel, new Context());    List<Channel> channels = new ArrayList<Channel>();    channels.add(sourceChannel);    ChannelSelector rcs = new ReplicatingChannelSelector();    rcs.setChannels(channels);    source.setChannelProcessor(new ChannelProcessor(rcs));    Context context = new Context();    context.put("port", port.toString());    context.put("bind", hostname);    context.put("threads", "50");    if (serverEnableCompression) {        context.put("compression-type", "deflate");    } else {        context.put("compression-type", "none");    }    Configurables.configure(source, context);    source.start();    Assert.assertTrue("Reached start or error", LifecycleController.waitForOneOf(source, LifecycleState.START_OR_ERROR));    Assert.assertEquals("Server is started", LifecycleState.START, source.getLifecycleState());    Event event = EventBuilder.withBody("Hello avro", Charset.forName("UTF8"));    sink.start();    Transaction sickTransaction = channel.getTransaction();    sickTransaction.begin();    for (int i = 0; i < 10; i++) {        channel.put(event);    }    sickTransaction.commit();    sickTransaction.close();    for (int i = 0; i < 5; i++) {        Sink.Status status = sink.process();        logger.debug("Calling Process " + i + " times:" + status);        Assert.assertEquals(Sink.Status.READY, status);    }    sink.stop();    Transaction sourceTransaction = sourceChannel.getTransaction();    sourceTransaction.begin();    Event sourceEvent = sourceChannel.take();    Assert.assertNotNull(sourceEvent);    Assert.assertEquals("Channel contained our event", "Hello avro", new String(sourceEvent.getBody()));    sourceTransaction.commit();    sourceTransaction.close();    logger.debug("Round trip event:{}", sourceEvent);    source.stop();    Assert.assertTrue("Reached stop or error", LifecycleController.waitForOneOf(source, LifecycleState.STOP_OR_ERROR));    Assert.assertEquals("Server is stopped", LifecycleState.STOP, source.getLifecycleState());}
16896c3c4fd07c175b3a70f7caa364f655a38a6b63a54a3895b30e8dcacf0f52
append
public Status append(AvroFlumeEvent event) throws AvroRemoteException
{    logger.debug("Received event:{}", event);    return Status.OK;}
a8baf3969fe87a0c94bf276b347c3cf4fd1f38175e8dddac6a5e509a3b6db442
appendBatch
public Status appendBatch(List<AvroFlumeEvent> events) throws AvroRemoteException
{    logger.debug("Received event batch:{}", events);    return Status.OK;}
85e5197a60a2132ffb1b538c850ce49bb128f0368dae33fed1ae33c0d0dc2378
sleep
private void sleep() throws AvroRemoteException
{    try {        Thread.sleep(delay.get());    } catch (InterruptedException e) {        throw new AvroRemoteException("Interrupted while sleeping", e);    }}
16896c3c4fd07c175b3a70f7caa364f655a38a6b63a54a3895b30e8dcacf0f52
append
public Status append(AvroFlumeEvent event) throws AvroRemoteException
{    logger.debug("Received event:{}; delaying for {}ms", event, delay);    sleep();    return Status.OK;}
a8baf3969fe87a0c94bf276b347c3cf4fd1f38175e8dddac6a5e509a3b6db442
appendBatch
public Status appendBatch(List<AvroFlumeEvent> events) throws AvroRemoteException
{    logger.debug("Received event batch:{}; delaying for {}ms", events, delay);    sleep();    return Status.OK;}
4c465b9cf881cb6212146b65664672f3841741755544b6aca9ce6c02d3ff9ca0
createSslServer
private Server createSslServer(AvroSourceProtocol protocol) throws IllegalAccessException, InstantiationException
{    Server server = new NettyServer(new SpecificResponder(AvroSourceProtocol.class, protocol), new InetSocketAddress(hostname, port), new NioServerSocketChannelFactory(Executors.newCachedThreadPool(), Executors.newCachedThreadPool()), new SSLChannelPipelineFactory(), null);    return server;}
1ba4580af5abb23ba6240c843d2da0abc4be225dfb5b9dee1e58f621a8eac35e
createServerSSLContext
private SSLContext createServerSSLContext()
{    try {        KeyStore ks = KeyStore.getInstance(keystoreType);        ks.load(new FileInputStream(keystore), keystorePassword.toCharArray());                KeyManagerFactory kmf = KeyManagerFactory.getInstance(getAlgorithm());        kmf.init(ks, keystorePassword.toCharArray());        SSLContext serverContext = SSLContext.getInstance("TLS");        serverContext.init(kmf.getKeyManagers(), null, null);        return serverContext;    } catch (Exception e) {        throw new Error("Failed to initialize the server-side SSLContext", e);    }}
ab89e51d439a571b4cdf36b539e8e831eac3a07807def7af75c7032c6d752079
getAlgorithm
private String getAlgorithm()
{    String algorithm = Security.getProperty("ssl.KeyManagerFactory.algorithm");    if (algorithm == null) {        algorithm = "SunX509";    }    return algorithm;}
cad0ca6670898490d4708d44f6fd87df22865c8cca5776775b5fc8cd9e37c866
getPipeline
public ChannelPipeline getPipeline() throws Exception
{    ChannelPipeline pipeline = Channels.pipeline();    SSLEngine sslEngine = createServerSSLContext().createSSLEngine();    sslEngine.setUseClientMode(false);    pipeline.addLast("ssl", new SslHandler(sslEngine));    return pipeline;}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    sinkFactory = new DefaultSinkFactory();}
996e2858736461ad9d50dd3cec655ae7536aa8af28bf1878aa7a9e5d930fff25
testDuplicateCreate
public void testDuplicateCreate()
{    Sink avroSink1 = sinkFactory.create("avroSink1", "avro");    Sink avroSink2 = sinkFactory.create("avroSink2", "avro");    Assert.assertNotNull(avroSink1);    Assert.assertNotNull(avroSink2);    Assert.assertNotSame(avroSink1, avroSink2);    Assert.assertTrue(avroSink1 instanceof AvroSink);    Assert.assertTrue(avroSink2 instanceof AvroSink);    Sink s1 = sinkFactory.create("avroSink1", "avro");    Sink s2 = sinkFactory.create("avroSink2", "avro");    Assert.assertNotSame(avroSink1, s1);    Assert.assertNotSame(avroSink2, s2);}
e903e77d297adbb273393d3828ed7b5fe06d00cb2fddd6fd09b865f48b631048
verifySinkCreation
private void verifySinkCreation(String name, String type, Class<?> typeClass) throws Exception
{    Sink sink = sinkFactory.create(name, type);    Assert.assertNotNull(sink);    Assert.assertTrue(typeClass.isInstance(sink));}
15cdb99d70a28ec9de08cfb7662c893a5159432e883227a75afa8b1b8e3a3668
testSinkCreation
public void testSinkCreation() throws Exception
{    verifySinkCreation("null-sink", "null", NullSink.class);    verifySinkCreation("logger-sink", "logger", LoggerSink.class);    verifySinkCreation("file-roll-sink", "file_roll", RollingFileSink.class);    verifySinkCreation("avro-sink", "avro", AvroSink.class);}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    state = LifecycleState.START;}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    state = LifecycleState.STOP;}
54497ccb2ff9760f1ec7fc0d0055d4bc60d5981953c5f3d7550c4b31a01e7642
getLifecycleState
public LifecycleState getLifecycleState()
{    return state;}
f498f22eaf0816bf385a43365651d1b6d0455905fdd2d6be01ceefeb84e8f432
setName
public void setName(String name)
{    this.name = name;}
239fbe3eb64d679cbac1161825b07d6a8436ead3c6c3d140d9caec2275827023
getName
public String getName()
{    return name;}
00671b39eabfa83348c21301d4eff1a2c5b5fe357955fa1a644f10ece980061a
setChannel
public void setChannel(Channel channel)
{    this.channel = channel;}
6ed7f0520aae719b8d45ade975f859348e62dec13fa614b6f4db9564a7112095
getChannel
public Channel getChannel()
{    return channel;}
9e0a9ab4b1f6b4cc5fc9ae4e529e664ba9056cc41996b11324d6352f0986c1a2
setRemaining
public synchronized void setRemaining(int remaining)
{    this.remaining = remaining;}
e52e5e378330fd7f87ee30351bbfcec47b751fee12ece2ef0cfdd77a08c906e1
process
public Status process() throws EventDeliveryException
{    synchronized (this) {        if (remaining <= 0) {            throw new EventDeliveryException("can't consume more");        }    }    Transaction tx = channel.getTransaction();    tx.begin();    Event e = channel.take();    tx.commit();    tx.close();    if (e != null) {        synchronized (this) {            remaining--;        }        written++;    }    return Status.READY;}
cfbe733129d44f98708368f6fa731fa615de109b8168bbc66150edf836705c76
getWritten
public Integer getWritten()
{    return written;}
2b58a9bd726f44a115ff9005cf865de6e1736b4d63f1a4d686489cdcd784565f
testFailover
public void testFailover() throws InterruptedException
{    Channel ch = new MemoryChannel();    ConsumeXSink s1 = new ConsumeXSink(10);    s1.setChannel(ch);    s1.setName("s1");    ConsumeXSink s2 = new ConsumeXSink(50);    s2.setChannel(ch);    s2.setName("s2");    ConsumeXSink s3 = new ConsumeXSink(100);    s3.setChannel(ch);    s3.setName("s3");    Context context = new Context();    Configurables.configure(s1, context);    Configurables.configure(s2, context);    Configurables.configure(s3, context);    Configurables.configure(ch, context);    ch.start();    List<Sink> sinks = new LinkedList<Sink>();    sinks.add(s1);    sinks.add(s2);    sinks.add(s3);    SinkGroup group = new SinkGroup(sinks);    Map<String, String> params = new HashMap<String, String>();    params.put("sinks", "s1 s2 s3");    params.put("processor.type", "failover");    params.put("processor.priority.s1", "3");    params.put("processor.priority.s2", "2");    params.put("processor.priority.s3", "1");    params.put("processor.maxpenalty", "10000");    context.putAll(params);    Configurables.configure(group, context);    SinkRunner runner = new SinkRunner(group.getProcessor());    runner.start();    Assert.assertEquals(LifecycleState.START, s1.getLifecycleState());    Assert.assertEquals(LifecycleState.START, s2.getLifecycleState());    Assert.assertEquals(LifecycleState.START, s3.getLifecycleState());    for (int i = 0; i < 15; i++) {        Transaction tx = ch.getTransaction();        tx.begin();        ch.put(EventBuilder.withBody("test".getBytes()));        tx.commit();        tx.close();    }    Thread.sleep(100);    Assert.assertEquals(new Integer(10), s1.getWritten());    Assert.assertEquals(new Integer(5), s2.getWritten());    for (int i = 0; i < 50; i++) {        Transaction tx = ch.getTransaction();        tx.begin();        ch.put(EventBuilder.withBody("test".getBytes()));        tx.commit();        tx.close();    }    Thread.sleep(100);    Assert.assertEquals(new Integer(50), s2.getWritten());    Assert.assertEquals(new Integer(5), s3.getWritten());        s2.setRemaining(20);        Thread.sleep(5000);    for (int i = 0; i < 100; i++) {        Transaction tx = ch.getTransaction();        tx.begin();        ch.put(EventBuilder.withBody("test".getBytes()));        tx.commit();        tx.close();    }    Thread.sleep(1000);    Assert.assertEquals(new Integer(10), s1.getWritten());    Assert.assertEquals(new Integer(70), s2.getWritten());    Assert.assertEquals(new Integer(85), s3.getWritten());    runner.stop();    ch.stop();}
6aa4c6dd2eaaede5cd924c2c84a4ddbb9f9dfdf4539352b8b6dab1377f39add9
getContext
private Context getContext(String selectorType, boolean backoff)
{    Map<String, String> p = new HashMap<String, String>();    p.put("selector", selectorType);    p.put("backoff", String.valueOf(backoff));    Context ctx = new Context(p);    return ctx;}
3f22ce1fb0fd22f866643687184b55510e2cc7a36683a73b370ad0390c52b927
getContext
private Context getContext(String selectorType)
{    Map<String, String> p = new HashMap<String, String>();    p.put("selector", selectorType);    Context ctx = new Context(p);    return ctx;}
a58d914b61a007eb3c3b59d1598b78129dbf1efd329a1bfefc16f9369023f2bb
getProcessor
private LoadBalancingSinkProcessor getProcessor(String selectorType, List<Sink> sinks, boolean backoff)
{    return getProcessor(sinks, getContext(selectorType, backoff));}
974803b3be8ec4d70c8656656d3765d735bcfc9284d30c9cc3ab3e60aa597bef
getProcessor
private LoadBalancingSinkProcessor getProcessor(List<Sink> sinks, Context ctx)
{    LoadBalancingSinkProcessor lbsp = new LoadBalancingSinkProcessor();    lbsp.setSinks(sinks);    lbsp.configure(ctx);    lbsp.start();    return lbsp;}
a862fe747259d17da19a409e8c40ef63feffe4b49c9a330c6713cc930c4c5ad0
testDefaultConfiguration
public void testDefaultConfiguration() throws Exception
{        Channel ch = new MockChannel();    int n = 100;    int numEvents = 3 * n;    for (int i = 0; i < numEvents; i++) {        ch.put(new MockEvent("test" + i));    }    MockSink s1 = new MockSink(1);    s1.setChannel(ch);    MockSink s2 = new MockSink(2);    s2.setChannel(ch);    MockSink s3 = new MockSink(3);    s3.setChannel(ch);    List<Sink> sinks = new ArrayList<Sink>();    sinks.add(s1);    sinks.add(s2);    sinks.add(s3);    LoadBalancingSinkProcessor lbsp = getProcessor(sinks, new Context());    Status s = Status.READY;    while (s != Status.BACKOFF) {        s = lbsp.process();    }    Assert.assertTrue(s1.getEvents().size() == n);    Assert.assertTrue(s2.getEvents().size() == n);    Assert.assertTrue(s3.getEvents().size() == n);}
c20a067bcf5e21e7e6a6cdddc5d3f3af7fae81dac54e51bf73d34a8c78c9d79f
testRandomOneActiveSink
public void testRandomOneActiveSink() throws Exception
{    Channel ch = new MockChannel();    int n = 10;    int numEvents = n;    for (int i = 0; i < numEvents; i++) {        ch.put(new MockEvent("test" + i));    }    MockSink s1 = new MockSink(1);    s1.setChannel(ch);        s1.setFail(true);    MockSink s2 = new MockSink(2);    s2.setChannel(ch);    MockSink s3 = new MockSink(3);    s3.setChannel(ch);        s3.setFail(true);    List<Sink> sinks = new ArrayList<Sink>();    sinks.add(s1);    sinks.add(s2);    sinks.add(s3);    LoadBalancingSinkProcessor lbsp = getProcessor("random", sinks, false);    Sink.Status s = Sink.Status.READY;    while (s != Sink.Status.BACKOFF) {        s = lbsp.process();    }    Assert.assertTrue(s1.getEvents().size() == 0);    Assert.assertTrue(s2.getEvents().size() == n);    Assert.assertTrue(s3.getEvents().size() == 0);}
926a03d4e58301cfc9a91dffd6f4186d064ae309f68577c8f9af630784fc069b
testRandomBackoff
public void testRandomBackoff() throws Exception
{    Channel ch = new MockChannel();    int n = 100;    int numEvents = n;    for (int i = 0; i < numEvents; i++) {        ch.put(new MockEvent("test" + i));    }    MockSink s1 = new MockSink(1);    s1.setChannel(ch);        s1.setFail(true);    MockSink s2 = new MockSink(2);    s2.setChannel(ch);    MockSink s3 = new MockSink(3);    s3.setChannel(ch);        s3.setFail(true);    List<Sink> sinks = new ArrayList<Sink>();    sinks.add(s1);    sinks.add(s2);    sinks.add(s3);    LoadBalancingSinkProcessor lbsp = getProcessor("random", sinks, true);        for (int i = 0; i < 50; i++) {                lbsp.process();    }    Assert.assertEquals(50, s2.getEvents().size());    s2.setFail(true);        s1.setFail(false);    try {        lbsp.process();                Assert.fail("Expected EventDeliveryException");    } catch (EventDeliveryException e) {        }        Thread.sleep(2100);    Sink.Status s = Sink.Status.READY;    while (s != Sink.Status.BACKOFF) {        s = lbsp.process();    }    Assert.assertEquals(50, s1.getEvents().size());    Assert.assertEquals(50, s2.getEvents().size());    Assert.assertEquals(0, s3.getEvents().size());}
beaa5cdfdead0a1245d2a6c7f2eda1e3bcffc5851d144b45de0b293bebd591ab
testRandomPersistentFailure
public void testRandomPersistentFailure() throws Exception
{    Channel ch = new MockChannel();    int n = 100;    int numEvents = 3 * n;    for (int i = 0; i < numEvents; i++) {        ch.put(new MockEvent("test" + i));    }    MockSink s1 = new MockSink(1);    s1.setChannel(ch);    MockSink s2 = new MockSink(2);    s2.setChannel(ch);        s2.setFail(true);    MockSink s3 = new MockSink(3);    s3.setChannel(ch);    List<Sink> sinks = new ArrayList<Sink>();    sinks.add(s1);    sinks.add(s2);    sinks.add(s3);    LoadBalancingSinkProcessor lbsp = getProcessor("random", sinks, false);    Status s = Status.READY;    while (s != Status.BACKOFF) {        s = lbsp.process();    }    Assert.assertTrue(s2.getEvents().size() == 0);    Assert.assertTrue(s1.getEvents().size() + s3.getEvents().size() == 3 * n);}
76d21f1fd961f41f2658ecfbef8511a26bedefceeb0833e3332ed7767e9aaede
testRandomNoFailure
public void testRandomNoFailure() throws Exception
{    Channel ch = new MockChannel();    int n = 10000;    int numEvents = n;    for (int i = 0; i < numEvents; i++) {        ch.put(new MockEvent("test" + i));    }    MockSink s1 = new MockSink(1);    s1.setChannel(ch);    MockSink s2 = new MockSink(2);    s2.setChannel(ch);    MockSink s3 = new MockSink(3);    s3.setChannel(ch);    MockSink s4 = new MockSink(4);    s4.setChannel(ch);    MockSink s5 = new MockSink(5);    s5.setChannel(ch);    MockSink s6 = new MockSink(6);    s6.setChannel(ch);    MockSink s7 = new MockSink(7);    s7.setChannel(ch);    MockSink s8 = new MockSink(8);    s8.setChannel(ch);    MockSink s9 = new MockSink(9);    s9.setChannel(ch);    MockSink s0 = new MockSink(0);    s0.setChannel(ch);    List<Sink> sinks = new ArrayList<Sink>();    sinks.add(s1);    sinks.add(s2);    sinks.add(s3);    sinks.add(s4);    sinks.add(s5);    sinks.add(s6);    sinks.add(s7);    sinks.add(s8);    sinks.add(s9);    sinks.add(s0);    LoadBalancingSinkProcessor lbsp = getProcessor("random", sinks, false);    Status s = Status.READY;    while (s != Status.BACKOFF) {        s = lbsp.process();    }    Set<Integer> sizeSet = new HashSet<Integer>();    int sum = 0;    for (Sink ms : sinks) {        int count = ((MockSink) ms).getEvents().size();        sum += count;        sizeSet.add(count);    }        Assert.assertEquals(n, sum);                        Assert.assertTrue("Miraculous distribution", sizeSet.size() > 1);}
6996d22b9a1f2dd82d83f00e83d2f09455ffa5bb551053c6e5eb692e203d5ecf
testRoundRobinOneActiveSink
public void testRoundRobinOneActiveSink() throws Exception
{    Channel ch = new MockChannel();    int n = 10;    int numEvents = n;    for (int i = 0; i < numEvents; i++) {        ch.put(new MockEvent("test" + i));    }    MockSink s1 = new MockSink(1);    s1.setChannel(ch);        s1.setFail(true);    MockSink s2 = new MockSink(2);    s2.setChannel(ch);    MockSink s3 = new MockSink(3);    s3.setChannel(ch);        s3.setFail(true);    List<Sink> sinks = new ArrayList<Sink>();    sinks.add(s1);    sinks.add(s2);    sinks.add(s3);    LoadBalancingSinkProcessor lbsp = getProcessor("round_robin", sinks, false);    Sink.Status s = Sink.Status.READY;    while (s != Sink.Status.BACKOFF) {        s = lbsp.process();    }    Assert.assertTrue(s1.getEvents().size() == 0);    Assert.assertTrue(s2.getEvents().size() == n);    Assert.assertTrue(s3.getEvents().size() == 0);}
04c60b5e5cf25b872de4071455257681ac7a48d0bd0623569751ea675ec4a2c9
testRoundRobinPersistentFailure
public void testRoundRobinPersistentFailure() throws Exception
{    Channel ch = new MockChannel();    int n = 100;    int numEvents = 3 * n;    for (int i = 0; i < numEvents; i++) {        ch.put(new MockEvent("test" + i));    }    MockSink s1 = new MockSink(1);    s1.setChannel(ch);    MockSink s2 = new MockSink(2);    s2.setChannel(ch);        s2.setFail(true);    MockSink s3 = new MockSink(3);    s3.setChannel(ch);    List<Sink> sinks = new ArrayList<Sink>();    sinks.add(s1);    sinks.add(s2);    sinks.add(s3);    LoadBalancingSinkProcessor lbsp = getProcessor("round_robin", sinks, false);    Status s = Status.READY;    while (s != Status.BACKOFF) {        s = lbsp.process();    }    Assert.assertTrue(s1.getEvents().size() == n);    Assert.assertTrue(s2.getEvents().size() == 0);    Assert.assertTrue(s3.getEvents().size() == 2 * n);}
4b8d79192f8a365d37fd0a998d3b8333bb3317432ba8cf36f8dc0c9f00246048
testRoundRobinBackoffInitialFailure
public void testRoundRobinBackoffInitialFailure() throws EventDeliveryException
{    Channel ch = new MockChannel();    int n = 100;    int numEvents = 3 * n;    for (int i = 0; i < numEvents; i++) {        ch.put(new MockEvent("test" + i));    }    MockSink s1 = new MockSink(1);    s1.setChannel(ch);    MockSink s2 = new MockSink(2);    s2.setChannel(ch);    MockSink s3 = new MockSink(3);    s3.setChannel(ch);    List<Sink> sinks = new ArrayList<Sink>();    sinks.add(s1);    sinks.add(s2);    sinks.add(s3);    LoadBalancingSinkProcessor lbsp = getProcessor("round_robin", sinks, true);    Status s = Status.READY;    for (int i = 0; i < 3 && s != Status.BACKOFF; i++) {        s = lbsp.process();    }    s2.setFail(true);    for (int i = 0; i < 3 && s != Status.BACKOFF; i++) {        s = lbsp.process();    }    s2.setFail(false);    while (s != Status.BACKOFF) {        s = lbsp.process();    }    Assert.assertEquals((3 * n) / 2, s1.getEvents().size());    Assert.assertEquals(1, s2.getEvents().size());    Assert.assertEquals((3 * n) / 2 - 1, s3.getEvents().size());}
668937636c4b72bd4e64225ee44a180fe988a735ce104e4220621766505e71d3
testRoundRobinBackoffIncreasingBackoffs
public void testRoundRobinBackoffIncreasingBackoffs() throws EventDeliveryException, InterruptedException
{    Channel ch = new MockChannel();    int n = 100;    int numEvents = 3 * n;    for (int i = 0; i < numEvents; i++) {        ch.put(new MockEvent("test" + i));    }    MockSink s1 = new MockSink(1);    s1.setChannel(ch);    MockSink s2 = new MockSink(2);    s2.setChannel(ch);    s2.setFail(true);    MockSink s3 = new MockSink(3);    s3.setChannel(ch);    List<Sink> sinks = new ArrayList<Sink>();    sinks.add(s1);    sinks.add(s2);    sinks.add(s3);    LoadBalancingSinkProcessor lbsp = getProcessor("round_robin", sinks, true);    Status s = Status.READY;    for (int i = 0; i < 3 && s != Status.BACKOFF; i++) {        s = lbsp.process();    }    Assert.assertEquals(0, s2.getEvents().size());    Thread.sleep(2100);        for (int i = 0; i < 3 && s != Status.BACKOFF; i++) {        s = lbsp.process();    }    Assert.assertEquals(0, s2.getEvents().size());    s2.setFail(false);    Thread.sleep(2100);        for (int i = 0; i < 3 && s != Status.BACKOFF; i++) {        s = lbsp.process();    }    Assert.assertEquals(0, s2.getEvents().size());        Thread.sleep(2100);    while (s != Status.BACKOFF) {        s = lbsp.process();    }    Assert.assertEquals(n + 2, s1.getEvents().size());    Assert.assertEquals(n - 3, s2.getEvents().size());    Assert.assertEquals(n + 1, s3.getEvents().size());}
7cf55e2acb50d402ce39b904445708dd0d1838a208486e23ef562904a7d280af
testRoundRobinBackoffFailureRecovery
public void testRoundRobinBackoffFailureRecovery() throws EventDeliveryException, InterruptedException
{    Channel ch = new MockChannel();    int n = 100;    int numEvents = 3 * n;    for (int i = 0; i < numEvents; i++) {        ch.put(new MockEvent("test" + i));    }    MockSink s1 = new MockSink(1);    s1.setChannel(ch);    MockSink s2 = new MockSink(2);    s2.setChannel(ch);    s2.setFail(true);    MockSink s3 = new MockSink(3);    s3.setChannel(ch);    List<Sink> sinks = new ArrayList<Sink>();    sinks.add(s1);    sinks.add(s2);    sinks.add(s3);    LoadBalancingSinkProcessor lbsp = getProcessor("round_robin", sinks, true);    Status s = Status.READY;    for (int i = 0; i < 3 && s != Status.BACKOFF; i++) {        s = lbsp.process();    }    s2.setFail(false);    Thread.sleep(2001);    while (s != Status.BACKOFF) {        s = lbsp.process();    }    Assert.assertEquals(n + 1, s1.getEvents().size());    Assert.assertEquals(n - 1, s2.getEvents().size());    Assert.assertEquals(n, s3.getEvents().size());}
6bfa33b4376bdbf4aaed713219ffee3f73493c63f4bce2bd7adb43cae7ce9f0c
testRoundRobinNoFailure
public void testRoundRobinNoFailure() throws Exception
{    Channel ch = new MockChannel();    int n = 100;    int numEvents = 3 * n;    for (int i = 0; i < numEvents; i++) {        ch.put(new MockEvent("test" + i));    }    MockSink s1 = new MockSink(1);    s1.setChannel(ch);    MockSink s2 = new MockSink(2);    s2.setChannel(ch);    MockSink s3 = new MockSink(3);    s3.setChannel(ch);    List<Sink> sinks = new ArrayList<Sink>();    sinks.add(s1);    sinks.add(s2);    sinks.add(s3);    LoadBalancingSinkProcessor lbsp = getProcessor("round_robin", sinks, false);    Status s = Status.READY;    while (s != Status.BACKOFF) {        s = lbsp.process();    }    Assert.assertTrue(s1.getEvents().size() == n);    Assert.assertTrue(s2.getEvents().size() == n);    Assert.assertTrue(s3.getEvents().size() == n);}
9031b7c9c2fc86dae3beb4f7d5851c2de85cf7ac550b1955f98cb07846170485
testCustomSelector
public void testCustomSelector() throws Exception
{    Channel ch = new MockChannel();    int n = 10;    int numEvents = n;    for (int i = 0; i < numEvents; i++) {        ch.put(new MockEvent("test" + i));    }    MockSink s1 = new MockSink(1);    s1.setChannel(ch);        s1.setFail(true);    MockSink s2 = new MockSink(2);    s2.setChannel(ch);    MockSink s3 = new MockSink(3);    s3.setChannel(ch);    List<Sink> sinks = new ArrayList<Sink>();    sinks.add(s1);    sinks.add(s2);    sinks.add(s3);        Context ctx = getContext(FixedOrderSelector.class.getCanonicalName());    ctx.put("selector." + FixedOrderSelector.SET_ME, "foo");    LoadBalancingSinkProcessor lbsp = getProcessor(sinks, ctx);    Sink.Status s = Sink.Status.READY;    while (s != Sink.Status.BACKOFF) {        s = lbsp.process();    }    Assert.assertTrue(s1.getEvents().size() == 0);    Assert.assertTrue(s2.getEvents().size() == n);    Assert.assertTrue(s3.getEvents().size() == 0);}
e0c1bc1193aea23b57d6791c756541a17390e4b00d18439b05723cc2828c4ee9
getEvents
 List<Event> getEvents()
{    return events;}
88187863014f9569e6378eef1914c47682c2f68e03f1603006cb774d90310666
getId
 int getId()
{    return id;}
961415cf8dd758e0b5212ff913a90322b407213a178c9f2b93260a0024ecf734
setFail
 void setFail(boolean bFail)
{    fail = bFail;}
e52e5e378330fd7f87ee30351bbfcec47b751fee12ece2ef0cfdd77a08c906e1
process
public Status process() throws EventDeliveryException
{    if (fail) {        throw new EventDeliveryException("failed");    }    Event e = this.getChannel().take();    if (e == null) {        return Status.BACKOFF;    }    events.add(e);    return Status.READY;}
7c433c140e986ede99b2704e4370ce4dc62a481b499e15037b573f27288bffc9
put
public void put(Event event) throws ChannelException
{    events.add(event);}
bd28ef43945352a9d826db660bc6e7b38e1777eec9decd45c0467679fc18a6dd
take
public Event take() throws ChannelException
{    if (events.size() > 0) {        return events.remove(0);    }    return null;}
2940dfdc387e1882ca0545a619d502102ae0c821f25b9ee739eafaade9ca3ee9
getTransaction
public Transaction getTransaction()
{    return null;}
9a691e59a635186c5f7258710b8e44f5caf3510a02999c2c0ea95c8238b813ad
getHeaders
public Map<String, String> getHeaders()
{    return EMPTY_HEADERS;}
6d1c35600a6f29feedab1769a2763829b83814294b318a32e8c71bf3529059a1
setHeaders
public void setHeaders(Map<String, String> headers)
{    throw new UnsupportedOperationException();}
a624aa1b85808a74c9f320025ea600169bd6e4692611a44ef53a1970442ef820
getBody
public byte[] getBody()
{    return body;}
b8505eb3e09ba9bb11ab8433148a62af59b6b1a27ffe7e69cf12f0e20e7c76a1
setBody
public void setBody(byte[] body)
{    this.body = body;}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    sink = new LoggerSink();}
48b1171dc1eae7ac875e7863b1468e29cd2c69fbb5d70747639baa30e0f4c402
testAppend
public void testAppend() throws InterruptedException, LifecycleException, EventDeliveryException
{    Channel channel = new PseudoTxnMemoryChannel();    Context context = new Context();    Configurables.configure(channel, context);    Configurables.configure(sink, context);    sink.setChannel(channel);    sink.start();    for (int i = 0; i < 10; i++) {        Event event = EventBuilder.withBody(("Test " + i).getBytes());        channel.put(event);        sink.process();    }    sink.stop();}
f4f3cb22f3c73b1af19f779b5f0b9a13445517b4cfd170fd4e4278d0a8a13908
testAppendWithCustomSize
public void testAppendWithCustomSize() throws InterruptedException, LifecycleException, EventDeliveryException
{    Channel channel = new PseudoTxnMemoryChannel();    Context context = new Context();    context.put(LoggerSink.MAX_BYTES_DUMP_KEY, String.valueOf(30));    Configurables.configure(channel, context);    Configurables.configure(sink, context);    sink.setChannel(channel);    sink.start();    for (int i = 0; i < 10; i++) {        Event event = EventBuilder.withBody((Strings.padStart("Test " + i, 30, 'P')).getBytes());        channel.put(event);        sink.process();    }    sink.stop();}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    tmpDir = new File("/tmp/flume-rfs-" + System.currentTimeMillis() + "-" + Thread.currentThread().getId());    sink = new RollingFileSink();    sink.setChannel(new MemoryChannel());    tmpDir.mkdirs();}
39e5ba029cc67f6f1d45c6d20f0df595ec16bc61da20d7680fcbbdae4fe7f95b
tearDown
public void tearDown()
{    tmpDir.delete();}
d775fc74478454f488ee0852240b05fdf840c462ce93b753615de6df6bfc28a3
testLifecycle
public void testLifecycle()
{    Context context = new Context();    context.put("sink.directory", tmpDir.getPath());    Configurables.configure(sink, context);    sink.start();    sink.stop();}
33ed54ac586cfd71579be6b9da1313a42aad73a938bdbae7aeabfed4df9a6cc1
testAppend
public void testAppend() throws InterruptedException, EventDeliveryException, IOException
{    Context context = new Context();    context.put("sink.directory", tmpDir.getPath());    context.put("sink.rollInterval", "1");    context.put("sink.batchSize", "1");    doTest(context);}
944f0f2449abf69070e000e6f979e620799638fb25345e5f31e19a60341cff3b
testAppend2
public void testAppend2() throws InterruptedException, EventDeliveryException, IOException
{    Context context = new Context();    context.put("sink.directory", tmpDir.getPath());    context.put("sink.rollInterval", "0");    context.put("sink.batchSize", "1");    doTest(context);}
7568e6b26157813e5c42b3ce03d3014e5b7f7b14a0b52039dbf270db8b32e266
testAppend3
public void testAppend3() throws InterruptedException, EventDeliveryException, IOException
{    File tmpDir = new File("target/tmpLog");    tmpDir.mkdirs();    cleanDirectory(tmpDir);    Context context = new Context();    context.put("sink.directory", "target/tmpLog");    context.put("sink.rollInterval", "0");    context.put("sink.batchSize", "1");    context.put("sink.pathManager.prefix", "test3-");    context.put("sink.pathManager.extension", "txt");    doTest(context);}
4892d32025617fb1f8ee3053849d82cbf9e5546aaa74771ba002c2d8d01917ca
testRollTime
public void testRollTime() throws InterruptedException, EventDeliveryException, IOException
{    File tmpDir = new File("target/tempLog");    tmpDir.mkdirs();    cleanDirectory(tmpDir);    Context context = new Context();    context.put("sink.directory", "target/tempLog/");    context.put("sink.rollInterval", "1");    context.put("sink.batchSize", "1");    context.put("sink.pathManager", "rolltime");    context.put("sink.pathManager.prefix", "test4-");    context.put("sink.pathManager.extension", "txt");    doTest(context);}
5a5b61ae675ce4c8f043b76f5c5faab53dc798077e3aee74172b670c29e29ac1
testChannelException
public void testChannelException() throws InterruptedException, IOException
{    Context context = new Context();    context.put("sink.directory", tmpDir.getPath());    context.put("sink.rollInterval", "0");    context.put("sink.batchSize", "1");    Channel channel = Mockito.mock(Channel.class);    Mockito.when(channel.take()).thenThrow(new ChannelException("dummy"));    Transaction transaction = Mockito.mock(BasicTransactionSemantics.class);    Mockito.when(channel.getTransaction()).thenReturn(transaction);    try {        doTest(context, channel);    } catch (EventDeliveryException e) {        }    SinkCounter sinkCounter = (SinkCounter) Whitebox.getInternalState(sink, "sinkCounter");    Assert.assertEquals(1, sinkCounter.getChannelReadFail());}
0786655dcef85160df9b9c1c83977010b2ae1267349dda9206a65c6416ad476a
doTest
private void doTest(Context context) throws EventDeliveryException, InterruptedException, IOException
{    doTest(context, null);}
80c87fc5f8a66bffc0799ca72453dc97d423354cdd371c2865bc50e79597c032
doTest
private void doTest(Context context, Channel channel) throws EventDeliveryException, InterruptedException, IOException
{    Configurables.configure(sink, context);    if (channel == null) {        channel = new PseudoTxnMemoryChannel();        Configurables.configure(channel, context);    }    sink.setChannel(channel);    sink.start();    for (int i = 0; i < 10; i++) {        Event event = new SimpleEvent();        event.setBody(("Test event " + i).getBytes());        channel.put(event);        sink.process();        Thread.sleep(500);    }    sink.stop();    for (String file : sink.getDirectory().list()) {        BufferedReader reader = new BufferedReader(new FileReader(new File(sink.getDirectory(), file)));        String lastLine = null;        String currentLine = null;        while ((currentLine = reader.readLine()) != null) {            lastLine = currentLine;            logger.debug("Produced file:{} lastLine:{}", file, lastLine);        }        reader.close();    }}
75502f648a61e65a5477fb6877527b5cd08d4628a3ce25c019267626fa95610a
cleanDirectory
private void cleanDirectory(File dir)
{    File[] files = dir.listFiles();    for (File file : files) {        file.delete();    }}
152860a3695c50b51492bffade2d5c00747089b9d57474f0073c5168d4b8e33c
testTransCapBatchSizeCompatibility
public void testTransCapBatchSizeCompatibility() throws EventDeliveryException
{    Context context = new Context();    context.put("sink.directory", tmpDir.getPath());    context.put("sink.rollInterval", "0");    context.put("sink.batchSize", "1000");    Configurables.configure(sink, context);    context.put("capacity", "50");    context.put("transactionCapacity", "5");    Channel channel = new MemoryChannel();    Configurables.configure(channel, context);    sink.setChannel(channel);    sink.start();    try {        for (int j = 0; j < 10; j++) {            Transaction tx = channel.getTransaction();            tx.begin();            for (int i = 0; i < 5; i++) {                Event event = new SimpleEvent();                event.setBody(("Test event " + i).getBytes());                channel.put(event);            }            tx.commit();            tx.close();        }        sink.process();    } finally {        sink.stop();    }}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    sink = new ThriftSink();    channel = new MemoryChannel();    hostname = "0.0.0.0";    try (ServerSocket socket = new ServerSocket(0)) {        port = socket.getLocalPort();    }    Context context = createBaseContext();    context.put(ThriftRpcClient.CONFIG_PROTOCOL, ThriftRpcClient.COMPACT_PROTOCOL);    sink.setChannel(channel);    Configurables.configure(sink, context);    Configurables.configure(channel, context);}
da20136ddae1a4d237464815f4be04143afb0882d1440ad4da0d8b8607a29cb4
createBaseContext
private Context createBaseContext()
{    Context context = new Context();    context.put("hostname", hostname);    context.put("port", String.valueOf(port));    context.put("batch-size", String.valueOf(2));    context.put("connect-timeout", String.valueOf(2000L));    context.put("request-timeout", String.valueOf(2000L));    return context;}
c6aaebb5a52567751db8dc8e1cb9dd4a4e582ef964a374b376c6a04f741802dc
tearDown
public void tearDown() throws Exception
{    channel.stop();    sink.stop();    src.stop();}
248a2f396b9a9a010ac74170a4665ba409afec88d8acd326f61b9c03b29df424
testProcess
public void testProcess() throws Exception
{    Event event = EventBuilder.withBody("test event 1", Charsets.UTF_8);    src = new ThriftTestingSource(ThriftTestingSource.HandlerType.OK.name(), port, ThriftRpcClient.COMPACT_PROTOCOL);    channel.start();    sink.start();    Transaction transaction = channel.getTransaction();    transaction.begin();    for (int i = 0; i < 11; i++) {        channel.put(event);    }    transaction.commit();    transaction.close();    for (int i = 0; i < 6; i++) {        Sink.Status status = sink.process();        Assert.assertEquals(Sink.Status.READY, status);    }    Assert.assertEquals(Sink.Status.BACKOFF, sink.process());    sink.stop();    Assert.assertEquals(11, src.flumeEvents.size());    Assert.assertEquals(6, src.batchCount);    Assert.assertEquals(0, src.individualCount);}
fa995b03ca9e1f4836314f4d5200645d3b8864e16081ff096ec164d83b863fc7
testTimeout
public void testTimeout() throws Exception
{    AtomicLong delay = new AtomicLong();    src = new ThriftTestingSource(ThriftTestingSource.HandlerType.ALTERNATE.name(), port, ThriftRpcClient.COMPACT_PROTOCOL);    src.setDelay(delay);    delay.set(2500);    Event event = EventBuilder.withBody("foo", Charsets.UTF_8);    sink.start();    Transaction txn = channel.getTransaction();    txn.begin();    for (int i = 0; i < 4; i++) {        channel.put(event);    }    txn.commit();    txn.close();        boolean threw = false;    try {        sink.process();    } catch (EventDeliveryException ex) {        threw = true;    }    Assert.assertTrue("Must throw due to connect timeout", threw);        delay.set(0);    sink.process();            delay.set(2500L);    threw = false;    try {        sink.process();    } catch (EventDeliveryException ex) {        threw = true;    }    Assert.assertTrue("Must throw due to request timeout", threw);    sink.stop();}
c9dfd4df59a1db6866d83304f108145a0ced5f5388b6bc56c727ff27261c26ec
testFailedConnect
public void testFailedConnect() throws Exception
{    Event event = EventBuilder.withBody("test event 1", Charset.forName("UTF8"));    sink.start();        Thread.sleep(500L);        Thread.sleep(500L);    Transaction transaction = channel.getTransaction();    transaction.begin();    for (int i = 0; i < 10; i++) {        channel.put(event);    }    transaction.commit();    transaction.close();    for (int i = 0; i < 5; i++) {        boolean threwException = false;        try {            sink.process();        } catch (EventDeliveryException e) {            threwException = true;        }        Assert.assertTrue("Must throw EventDeliveryException if disconnected", threwException);    }    src = new ThriftTestingSource(ThriftTestingSource.HandlerType.OK.name(), port, ThriftRpcClient.COMPACT_PROTOCOL);    for (int i = 0; i < 5; i++) {        Sink.Status status = sink.process();        Assert.assertEquals(Sink.Status.READY, status);    }    Assert.assertEquals(Sink.Status.BACKOFF, sink.process());    sink.stop();}
f5139d6d7d050f7752f1bfd0670a41aefdf531fd5950fdb68926fcbe69ec966f
testSslProcessWithComponentTruststore
public void testSslProcessWithComponentTruststore() throws Exception
{    Context context = createBaseContext();    context.put("ssl", String.valueOf(true));    context.put("truststore", "src/test/resources/truststorefile.jks");    context.put("truststore-password", "password");    Configurables.configure(sink, context);    doTestSslProcess();}
d8b81304b4963409dfd39dfecd0994ecaf0bc0f93271e042ae096a027aa09cda
testSslProcessWithComponentTruststoreNoPassword
public void testSslProcessWithComponentTruststoreNoPassword() throws Exception
{    Context context = createBaseContext();    context.put("ssl", String.valueOf(true));    context.put("truststore", "src/test/resources/truststorefile.jks");    Configurables.configure(sink, context);    doTestSslProcess();}
33c4174d1115cabe2b70971bafd4aa59717b7e744b578d3c81c610d56a3c67ce
testSslProcessWithGlobalTruststore
public void testSslProcessWithGlobalTruststore() throws Exception
{    System.setProperty("javax.net.ssl.trustStore", "src/test/resources/truststorefile.jks");    System.setProperty("javax.net.ssl.trustStorePassword", "password");    Context context = createBaseContext();    context.put("ssl", String.valueOf(true));    Configurables.configure(sink, context);    doTestSslProcess();    System.clearProperty("javax.net.ssl.trustStore");    System.clearProperty("javax.net.ssl.trustStorePassword");}
d0b5fc2b382fb0b76de57ee770d61693df5520081173619a2e1ad885dffd5f1a
testSslProcessWithGlobalTruststoreNoPassword
public void testSslProcessWithGlobalTruststoreNoPassword() throws Exception
{    System.setProperty("javax.net.ssl.trustStore", "src/test/resources/truststorefile.jks");    Context context = createBaseContext();    context.put("ssl", String.valueOf(true));    Configurables.configure(sink, context);    doTestSslProcess();    System.clearProperty("javax.net.ssl.trustStore");}
de6dcfc751c9f9b4ce3fda36b219c929f4d4c1212645d96a207181f982f9e41e
doTestSslProcess
private void doTestSslProcess() throws Exception
{    src = new ThriftTestingSource(ThriftTestingSource.HandlerType.OK.name(), port, ThriftRpcClient.COMPACT_PROTOCOL, "src/test/resources/keystorefile.jks", "password", KeyManagerFactory.getDefaultAlgorithm(), "JKS");    channel.start();    sink.start();    Transaction transaction = channel.getTransaction();    transaction.begin();    Event event = EventBuilder.withBody("test event 1", Charsets.UTF_8);    for (int i = 0; i < 11; i++) {        channel.put(event);    }    transaction.commit();    transaction.close();    for (int i = 0; i < 6; i++) {        Sink.Status status = sink.process();        Assert.assertEquals(Sink.Status.READY, status);    }    Assert.assertEquals(Sink.Status.BACKOFF, sink.process());    sink.stop();    Assert.assertEquals(11, src.flumeEvents.size());    Assert.assertEquals(6, src.batchCount);    Assert.assertEquals(0, src.individualCount);}
7e784461aa01193e4ab131ea5739109606a37a2c710a54b43ad29e874ebb2e66
testSslSinkWithNonSslServer
public void testSslSinkWithNonSslServer() throws Exception
{    src = new ThriftTestingSource(ThriftTestingSource.HandlerType.OK.name(), port, ThriftRpcClient.COMPACT_PROTOCOL);    Context context = createBaseContext();    context.put("ssl", String.valueOf(true));    context.put("truststore", "src/test/resources/truststorefile.jks");    context.put("truststore-password", "password");    Configurables.configure(sink, context);    boolean failed = doRequestWhenFailureExpected();    if (!failed) {        Assert.fail("SSL-enabled sink successfully connected to a non-SSL-enabled server, " + "that's wrong.");    }}
5c395442adadc4abf00a68f8c89746235a9fdfa0b54ae6b70acc1f3bbf182e60
testSslSinkWithNonTrustedCert
public void testSslSinkWithNonTrustedCert() throws Exception
{    src = new ThriftTestingSource(ThriftTestingSource.HandlerType.OK.name(), port, ThriftRpcClient.COMPACT_PROTOCOL, "src/test/resources/keystorefile.jks", "password", KeyManagerFactory.getDefaultAlgorithm(), "JKS");    Context context = createBaseContext();    context.put("ssl", String.valueOf(true));    Configurables.configure(sink, context);    boolean failed = doRequestWhenFailureExpected();    if (!failed) {        Assert.fail("SSL-enabled sink successfully connected to a server with an " + "untrusted certificate when it should have failed");    }}
1934ff947e313fbabb39c25ec268415f4eef5347ab39050bc4220c924cff4f90
doRequestWhenFailureExpected
private boolean doRequestWhenFailureExpected() throws Exception
{    channel.start();    sink.start();    Assert.assertTrue(LifecycleController.waitForOneOf(sink, LifecycleState.START_OR_ERROR, 5000));    Transaction transaction = channel.getTransaction();    transaction.begin();    Event event = EventBuilder.withBody("test event 1", Charsets.UTF_8);    channel.put(event);    transaction.commit();    transaction.close();    boolean failed;    try {        Sink.Status status = sink.process();        failed = false;    } catch (EventDeliveryException ex) {                failed = true;    }    sink.stop();    Assert.assertTrue(LifecycleController.waitForOneOf(sink, LifecycleState.STOP_OR_ERROR, 5000));    return failed;}
a5e1ecdf74f7bf6b03b8893d7dc4cfd597218d7dd1f689ae4130c6098d6c953d
getAuthType
public String getAuthType()
{    throw new UnsupportedOperationException("Not supported yet.");}
ac1ec2bb87fdfa82ab2b8fa5fd84af00d909d23eccf6c28a5caa65a0069afc9f
getCookies
public Cookie[] getCookies()
{    throw new UnsupportedOperationException("Not supported yet.");}
9e92fd3d658a0df3524c102cacb49bef3aa8ae46e55fd93435c4be453a05287e
getDateHeader
public long getDateHeader(String name)
{    throw new UnsupportedOperationException("Not supported yet.");}
ce222e9e26ff92f109221120401e746a4137a63055fa3f4c459b71bc3b9a3f7b
getHeader
public String getHeader(String name)
{    throw new UnsupportedOperationException("Not supported yet.");}
28b0c997c131404786bbbdd3ec37f60921de5b2bcb5130762067766d85ab4fd0
getHeaders
public Enumeration<String> getHeaders(String name)
{    throw new UnsupportedOperationException("Not supported yet.");}
3fd51ab7145093004f3f7aae59cbbcb5dae230d3c4e39cf14fabbcce235b4f82
getHeaderNames
public Enumeration<String> getHeaderNames()
{    throw new UnsupportedOperationException("Not supported yet.");}
74306b64876c9b5783bd20f2a526e5915d1622b58f033098ad1c25aec724bcbe
getIntHeader
public int getIntHeader(String name)
{    throw new UnsupportedOperationException("Not supported yet.");}
1b04a48e342452eec0b4d88df8c129ec91df7eef97b2ef3d27b577702117da62
getMethod
public String getMethod()
{    throw new UnsupportedOperationException("Not supported yet.");}
b0572b00526a00d95ab79c671b4a8944b16ce663f94319e13a5d4a2ac449cbea
getPathInfo
public String getPathInfo()
{    throw new UnsupportedOperationException("Not supported yet.");}
ba4e6b322fc6b4428b75274638015c9390b2b19d785d00c10f55752af475f678
getPathTranslated
public String getPathTranslated()
{    throw new UnsupportedOperationException("Not supported yet.");}
42d7437c151b9dbb6f43ec28cbadef8c4353e27e2d8f78e6b214d4a521205a61
getContextPath
public String getContextPath()
{    throw new UnsupportedOperationException("Not supported yet.");}
c7e000b510b9e11ec345d0fca397786eb5eabc475ef4adfe46dbc1cdbfb67ac4
getQueryString
public String getQueryString()
{    throw new UnsupportedOperationException("Not supported yet.");}
7a704082341a235e83c8e8512683bfd4e606683c2a7331adb94e42fe0c4f6ad7
getRemoteUser
public String getRemoteUser()
{    throw new UnsupportedOperationException("Not supported yet.");}
79438252e97fceeb1d82609d90f6afad95f8f768ff65fb71c428a92b0146e2ed
isUserInRole
public boolean isUserInRole(String role)
{    throw new UnsupportedOperationException("Not supported yet.");}
5d9bb0cdc7b2aa820d5d654cc4e191bb6fca3070733bad6303dfb3f7744ead0a
getUserPrincipal
public Principal getUserPrincipal()
{    throw new UnsupportedOperationException("Not supported yet.");}
e56b1108091fe9672e1528ce5995ac3fa13b44b9f1217b7ea3a1e9e5b52833e5
getRequestedSessionId
public String getRequestedSessionId()
{    throw new UnsupportedOperationException("Not supported yet.");}
36b26a68930fb147c2256251e6144032adb25b7313e9bfd66b646c5b3311234a
getRequestURI
public String getRequestURI()
{    throw new UnsupportedOperationException("Not supported yet.");}
66f1c944211008a90ffacd9aed8af6e5b661104535214981ba2202efd8fb54ec
getRequestURL
public StringBuffer getRequestURL()
{    throw new UnsupportedOperationException("Not supported yet.");}
b05723a1cff0d36c5ac027abcbfe10f6b028aaf2fb08552c33e326a54e901818
getServletPath
public String getServletPath()
{    throw new UnsupportedOperationException("Not supported yet.");}
602a1ce6dc0819d1dcba30a60fc4377d9a00548c7e823ee6cef63a939cb2c79f
getSession
public HttpSession getSession(boolean create)
{    throw new UnsupportedOperationException("Not supported yet.");}
8671a3c391a4c1d16d46e234fe9b96b92ea0cef19bac007dc5f02541a7b0c75b
getSession
public HttpSession getSession()
{    throw new UnsupportedOperationException("Not supported yet.");}
d9652c8fd847ec1d437759518061822e590079dafd23aa8ac8f148d365ca0301
isRequestedSessionIdValid
public boolean isRequestedSessionIdValid()
{    throw new UnsupportedOperationException("Not supported yet.");}
58571e473a7f2b59034411ca74271c20a7e9688d55f221aaced3111991a37006
isRequestedSessionIdFromCookie
public boolean isRequestedSessionIdFromCookie()
{    throw new UnsupportedOperationException("Not supported yet.");}
ae3f8403b41004eed4053f56fbcb00d1bcffbde205053e065abaad4caeedd167
isRequestedSessionIdFromURL
public boolean isRequestedSessionIdFromURL()
{    throw new UnsupportedOperationException("Not supported yet.");}
91fe83cc24a51476b247823443d2e339ad738ac0b2c5dcc936fc91135461a066
isRequestedSessionIdFromUrl
public boolean isRequestedSessionIdFromUrl()
{    throw new UnsupportedOperationException("Not supported yet.");}
96440be7e79088e99a89c61b00b69b2672e3676f355e6cd72bbcc7b6ce9f52e7
getAttribute
public Object getAttribute(String name)
{    throw new UnsupportedOperationException("Not supported yet.");}
fe04c2f676a8d24a57ed5bfda43fbcfda44366dca8b7629b3c6ec9df33a7155e
getAttributeNames
public Enumeration<String> getAttributeNames()
{    throw new UnsupportedOperationException("Not supported yet.");}
2186a2d07d275933cee1ccdc23594c721a23eef874c7db3eaac48dc460261076
getCharacterEncoding
public String getCharacterEncoding()
{    return charset;}
1146ccfd8fbd52ac06edfd387636418325962c8bd3986593ba8477c262a05709
setCharacterEncoding
public void setCharacterEncoding(String env) throws UnsupportedEncodingException
{    this.charset = env;}
e46fa6eda177f5a73935edebc9250d53a0f24aff114a05533c5485d430532a0c
getContentLength
public int getContentLength()
{    throw new UnsupportedOperationException("Not supported yet.");}
baea39c86756a5efaaec8e2f01175d687e0a60e86379d9b91d98a3d4089abf86
getContentType
public String getContentType()
{    throw new UnsupportedOperationException("Not supported yet.");}
bf6e925563f9c2ae72d990408dc442b0450abe4f49c7342f20f60383d755aefa
getInputStream
public ServletInputStream getInputStream() throws IOException
{    throw new UnsupportedOperationException("Not supported yet.");}
c74d5696b207ef199f062aa5cb98dab40366de6923677c46f82a5be4d0be9c6a
getParameter
public String getParameter(String name)
{    throw new UnsupportedOperationException("Not supported yet.");}
6aad5633fe95df7ad0a37a12b19ee3f4e676b82438d57c81ac340cb903d4b039
getParameterNames
public Enumeration<String> getParameterNames()
{    throw new UnsupportedOperationException("Not supported yet.");}
d504a649d3f21a51cd09758546ba9d7dd553d645200658cda85ea3fb5bced486
getParameterValues
public String[] getParameterValues(String name)
{    throw new UnsupportedOperationException("Not supported yet.");}
80cc3bc2e1a4c42c630819ed5347e1e0e32c5606abceba4fafcb8cd0642b1487
getParameterMap
public Map<String, String[]> getParameterMap()
{    throw new UnsupportedOperationException("Not supported yet.");}
6a5c52ec96402a32005f10b5e3e237a089c21a231622163ebe5dea143f2fdbbe
getProtocol
public String getProtocol()
{    throw new UnsupportedOperationException("Not supported yet.");}
e061928b565977a057ff8a6d86fe57cbf8a9d77f4650b89ecccf6a3fad75b041
getScheme
public String getScheme()
{    throw new UnsupportedOperationException("Not supported yet.");}
295e56d955a85a3ecf1251e130a26abbf506ec6fe560fa3e0abe83095fba1f9a
getServerName
public String getServerName()
{    throw new UnsupportedOperationException("Not supported yet.");}
fb00e90a8ec104f857c0c29dc4ec4c66b82069eacd0acdce01e781796bfb2af5
getServerPort
public int getServerPort()
{    throw new UnsupportedOperationException("Not supported yet.");}
86b2b71b7b98edff9f5113d051d8f5d57c4ffe08d33c255c11978eda6ae8852e
getReader
public BufferedReader getReader() throws IOException
{    return reader;}
b129b8faa1ae3da62e0297e32d848abc7421f1c3ebcf5e63c0471b443bdf881b
getRemoteAddr
public String getRemoteAddr()
{    throw new UnsupportedOperationException("Not supported yet.");}
fa9749b81b10c14461936619cc780fa60a31019edb5168107252ae924f220fce
getRemoteHost
public String getRemoteHost()
{    throw new UnsupportedOperationException("Not supported yet.");}
945a35d3fb518a0c55804c2d155dc288910a9bdad8c692b09944714f67a4b5d0
setAttribute
public void setAttribute(String name, Object o)
{    throw new UnsupportedOperationException("Not supported yet.");}
ebd826e2f5ea1795265bbd6a04f646d353eadedf491f3582776219967aa556df
removeAttribute
public void removeAttribute(String name)
{    throw new UnsupportedOperationException("Not supported yet.");}
62c15d02f6b13e14cb41947626ab4f45983b517eef0d7b1c1622bc399cd93159
getLocale
public Locale getLocale()
{    throw new UnsupportedOperationException("Not supported yet.");}
fd32db1eab8cac484748888f74cf98e1fc3ce0e7fac178a6d95afaef6a975a17
getLocales
public Enumeration<Locale> getLocales()
{    throw new UnsupportedOperationException("Not supported yet.");}
c6a8b35027b486f9efda96936274975b221803473bdc28c586ea3371f63c78bd
isSecure
public boolean isSecure()
{    throw new UnsupportedOperationException("Not supported yet.");}
261bef39e3b74518d9c03fb40ced3026ed4a9a50ba03b84a7d71cf95e6caaf64
getRequestDispatcher
public RequestDispatcher getRequestDispatcher(String path)
{    throw new UnsupportedOperationException("Not supported yet.");}
ddc87359e020d4228fdab5b6243687c240939f8507efa0581636dcf1e6cdbdf1
getRealPath
public String getRealPath(String path)
{    throw new UnsupportedOperationException("Not supported yet.");}
9c5c1eedb87aa6332e5956f6ee46498fe5e4bb3e3a11f5ee878d0dd6b5ba22ad
getRemotePort
public int getRemotePort()
{    throw new UnsupportedOperationException("Not supported yet.");}
d1e8aa28b8adf9b8d244c889974bf7ae0383bb51d67dd63248f2c0c9b4e4c8db
getLocalName
public String getLocalName()
{    throw new UnsupportedOperationException("Not supported yet.");}
0bc6bc164c2b7fbabb37c3d670ec3211f1ce84575579d2adcc3a34a0b0bd9056
getLocalAddr
public String getLocalAddr()
{    throw new UnsupportedOperationException("Not supported yet.");}
0f9342907a55818619d2e2cfa5fa813892dc2783be692f8ecc0da9029bc998d0
getLocalPort
public int getLocalPort()
{    throw new UnsupportedOperationException("Not supported yet.");}
5e489504343d251f353e96081a17ff43164a17f5ac571bcf117c9249ccfe8a54
getAsyncContext
public AsyncContext getAsyncContext()
{    throw new UnsupportedOperationException("Not supported yet.");}
ad88cb8c83027755533559c9cdaf0551ae9742b3e37c33f4e8688212d795ab55
getContentLengthLong
public long getContentLengthLong()
{    throw new UnsupportedOperationException("Not supported yet.");}
3823289235931b640c6d381d0692a0b4d3d4c6a63a4b6249b9d1f44cec867b93
getDispatcherType
public DispatcherType getDispatcherType()
{    throw new UnsupportedOperationException("Not supported yet.");}
080e6dfeffad4589787f1a6fda9a213672aea9ede479cb0719278c34fafc3319
getServletContext
public ServletContext getServletContext()
{    throw new UnsupportedOperationException("Not supported yet.");}
f317c516ab0d1c2358099c3604dd9fcf3e25af304bb62be5a6ac6e47e937c9d1
isAsyncStarted
public boolean isAsyncStarted()
{    throw new UnsupportedOperationException("Not supported yet.");}
b33ca950ff93e2cf1f82311fa73d014537b855c5167fb191c39d6826cbb52b13
isAsyncSupported
public boolean isAsyncSupported()
{    throw new UnsupportedOperationException("Not supported yet.");}
154a6bd872ba0d39f3ed62089a137afd64d911175701322fc9c622d6a8f1b523
startAsync
public AsyncContext startAsync() throws IllegalStateException
{    throw new UnsupportedOperationException("Not supported yet.");}
da53a6551b577700b4e7243759e777ecaadbace4e1b6d842b89806a88a3d6cc2
startAsync
public AsyncContext startAsync(ServletRequest arg0, ServletResponse arg1) throws IllegalStateException
{    throw new UnsupportedOperationException("Not supported yet.");}
c29ec83246299f75193d088f0e736a842234576eb925a4b22d187ca7c2ae2c40
authenticate
public boolean authenticate(HttpServletResponse arg0) throws IOException, ServletException
{    throw new UnsupportedOperationException("Not supported yet.");}
ba084856e7597fba3995d87a09f865466046b950a345c327961652b9c6da8111
changeSessionId
public String changeSessionId()
{    throw new UnsupportedOperationException("Not supported yet.");}
ada90df6828034a454d593948c284333d4793c3a6a7bf340ff9a5cb0dee0868c
getPart
public Part getPart(String arg0) throws IOException, ServletException
{    throw new UnsupportedOperationException("Not supported yet.");}
3788804bb4373016732d3f3ba97c666c2f54ec75b69747dfd2650725b51eb5fd
getParts
public Collection<Part> getParts() throws IOException, ServletException
{    throw new UnsupportedOperationException("Not supported yet.");}
78a7cdc106a77719be73c76cd45cd0d8f9c126dbc7ad11e04ef41597b553598d
login
public void login(String arg0, String arg1) throws ServletException
{    throw new UnsupportedOperationException("Not supported yet.");}
a67df56b0b1e4d64ff144a3b770219afcba09841521b77ab852ba8816bb83f2f
logout
public void logout() throws ServletException
{    throw new UnsupportedOperationException("Not supported yet.");}
ce31c14d1ddbc66c91b53308d877f771687a79676f350df9008dc11181da6c92
upgrade
public T upgrade(Class<T> arg0) throws IOException, ServletException
{    throw new UnsupportedOperationException("Not supported yet.");}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    handler = new BLOBHandler();}
bb0b585beef48d49c9cf5d2b3ac2d27db9d1eecdae3fa2517d76f5b4a7e4fca2
testCSVData
public void testCSVData() throws Exception
{    Map requestParameterMap = new HashMap();    requestParameterMap.put("param1", new String[] { "value1" });    requestParameterMap.put("param2", new String[] { "value2" });    HttpServletRequest req = mock(HttpServletRequest.class);    final String csvData = "a,b,c";    ServletInputStream servletInputStream = new DelegatingServletInputStream(new ByteArrayInputStream(csvData.getBytes()));    when(req.getInputStream()).thenReturn(servletInputStream);    when(req.getParameterMap()).thenReturn(requestParameterMap);    Context context = mock(Context.class);    when(context.getString(BLOBHandler.MANDATORY_PARAMETERS, BLOBHandler.DEFAULT_MANDATORY_PARAMETERS)).thenReturn("param1,param2");    handler.configure(context);    List<Event> deserialized = handler.getEvents(req);    assertEquals(1, deserialized.size());    Event e = deserialized.get(0);    assertEquals(new String(e.getBody()), csvData);    assertEquals(e.getHeaders().get("param1"), "value1");    assertEquals(e.getHeaders().get("param2"), "value2");}
543b34ee5327d78857570bffef1df4cfd07cf82e9d610fa42caa3a46cb216248
testTabData
public void testTabData() throws Exception
{    Map requestParameterMap = new HashMap();    requestParameterMap.put("param1", new String[] { "value1" });    HttpServletRequest req = mock(HttpServletRequest.class);    final String tabData = "a\tb\tc";    ServletInputStream servletInputStream = new DelegatingServletInputStream(new ByteArrayInputStream(tabData.getBytes()));    when(req.getInputStream()).thenReturn(servletInputStream);    when(req.getParameterMap()).thenReturn(requestParameterMap);    Context context = mock(Context.class);    when(context.getString(BLOBHandler.MANDATORY_PARAMETERS, BLOBHandler.DEFAULT_MANDATORY_PARAMETERS)).thenReturn("param1");    handler.configure(context);    List<Event> deserialized = handler.getEvents(req);    assertEquals(1, deserialized.size());    Event e = deserialized.get(0);    assertEquals(new String(e.getBody()), tabData);    assertEquals(e.getHeaders().get("param1"), "value1");}
18e0e91743f68240a98cc3b3494a01e8a12c62703177c6bb45e35d0110a2dcdc
testMissingParameters
public void testMissingParameters() throws Exception
{    Map requestParameterMap = new HashMap();    HttpServletRequest req = mock(HttpServletRequest.class);    final String tabData = "a\tb\tc";    ServletInputStream servletInputStream = new DelegatingServletInputStream(new ByteArrayInputStream(tabData.getBytes()));    when(req.getInputStream()).thenReturn(servletInputStream);    when(req.getParameterMap()).thenReturn(requestParameterMap);    Context context = mock(Context.class);    when(context.getString(BLOBHandler.MANDATORY_PARAMETERS, BLOBHandler.DEFAULT_MANDATORY_PARAMETERS)).thenReturn("param1");    handler.configure(context);    handler.getEvents(req);}
1e201b756a83a2b6e97c3a711132c7bebfd3094727ff71572b53d36bb3d7899d
getSourceStream
public final InputStream getSourceStream()
{    return this.sourceStream;}
00c6cb892813c6b89e072a7f09dccdece629f30849daab28245b06f3e679bf54
read
public int read() throws IOException
{    return this.sourceStream.read();}
e0823f55b3a09d41a3e1e792f7e6687db9199c2db9b29e9922d93cbdc6f1284b
close
public void close() throws IOException
{    super.close();    this.sourceStream.close();}
58b8f2fb86ad0f0d38d8270683e2ddf9f267d37ccbf8fb77ec76fba4b799959c
isFinished
public boolean isFinished()
{    throw new UnsupportedOperationException("Not supported yet.");}
586d69414c54ba6467cd376c67aba0fe5e6acbea25d49028f8dffabf13fff625
isReady
public boolean isReady()
{    throw new UnsupportedOperationException("Not supported yet.");}
d4f309aab5b833a5982b3ebca9cc17c73241d82ab65cce143e37dd88c93dd7e4
setReadListener
public void setReadListener(ReadListener arg0)
{    throw new UnsupportedOperationException("Not supported yet.");}
4d072973845457c68e0bdcaf8605a63c4e82cee51aa51c4f7db0b2f7a2d3a532
findFreePort
private static int findFreePort() throws IOException
{    ServerSocket socket = new ServerSocket(0);    int port = socket.getLocalPort();    socket.close();    return port;}
cfcc86b23e607219ebc84d1690abf588fe3f29ba7bceb776e951c561811cf919
getDefaultNonSecureContext
private static Context getDefaultNonSecureContext(int port) throws IOException
{    Context ctx = new Context();    ctx.put(HTTPSourceConfigurationConstants.CONFIG_BIND, "0.0.0.0");    ctx.put(HTTPSourceConfigurationConstants.CONFIG_PORT, String.valueOf(port));    ctx.put("QueuedThreadPool.MaxThreads", "100");    return ctx;}
268c7384707921f076efefc47d7bf46a946c248edd0e3da72c62903e5ca42411
getDefaultSecureContext
private static Context getDefaultSecureContext(int port) throws IOException
{    Context sslContext = new Context();    sslContext.put(HTTPSourceConfigurationConstants.CONFIG_PORT, String.valueOf(port));    sslContext.put(HTTPSourceConfigurationConstants.SSL_ENABLED, "true");    sslContext.put(HTTPSourceConfigurationConstants.SSL_KEYSTORE_PASSWORD, "password");    sslContext.put(HTTPSourceConfigurationConstants.SSL_KEYSTORE, "src/test/resources/jettykeystore");    return sslContext;}
069fc327f8fcabfa4cb8ff5f3772c30dfd639cdb966a8e99bf18ca3c8bc85f0d
getDefaultSecureContextGlobalKeystore
private static Context getDefaultSecureContextGlobalKeystore(int port) throws IOException
{    System.setProperty("javax.net.ssl.keyStore", "src/test/resources/jettykeystore");    System.setProperty("javax.net.ssl.keyStorePassword", "password");    Context sslContext = new Context();    sslContext.put(HTTPSourceConfigurationConstants.CONFIG_PORT, String.valueOf(port));    sslContext.put(HTTPSourceConfigurationConstants.SSL_ENABLED, "true");    return sslContext;}
7f0f73b325bcd37632c396c02bb87ddfe4bb9da1a35fac272192ae84740eb688
setUpClass
public static void setUpClass() throws Exception
{    httpSource = new HTTPSource();    httpChannel = new MemoryChannel();    httpPort = findFreePort();    configureSourceAndChannel(httpSource, httpChannel, getDefaultNonSecureContext(httpPort));    httpChannel.start();    httpSource.start();    httpsSource = new HTTPSource();    httpsChannel = new MemoryChannel();    httpsPort = findFreePort();    configureSourceAndChannel(httpsSource, httpsChannel, getDefaultSecureContext(httpsPort));    httpsChannel.start();    httpsSource.start();    httpsGlobalKeystoreSource = new HTTPSource();    httpsGlobalKeystoreChannel = new MemoryChannel();    httpsGlobalKeystorePort = findFreePort();    configureSourceAndChannel(httpsGlobalKeystoreSource, httpsGlobalKeystoreChannel, getDefaultSecureContextGlobalKeystore(httpsGlobalKeystorePort));    httpsGlobalKeystoreChannel.start();    httpsGlobalKeystoreSource.start();    System.clearProperty("javax.net.ssl.keyStore");    System.clearProperty("javax.net.ssl.keyStorePassword");}
1b63cb98cdd665cd8877265965b1a7cc87182b8208c529d1dccbd24e2c4f4eeb
configureSourceAndChannel
private static void configureSourceAndChannel(HTTPSource source, Channel channel, Context context)
{    Context channelContext = new Context();    channelContext.put("capacity", "100");    Configurables.configure(channel, channelContext);    Configurables.configure(source, context);    ChannelSelector rcs1 = new ReplicatingChannelSelector();    rcs1.setChannels(Collections.singletonList(channel));    source.setChannelProcessor(new ChannelProcessor(rcs1));}
57356f1c78bbffcbadab516b764dcc9a36fc07f0e28b2d56b001ac2d49131cb2
tearDownClass
public static void tearDownClass() throws Exception
{    httpSource.stop();    httpChannel.stop();    httpsSource.stop();    httpsChannel.stop();    httpsGlobalKeystoreSource.stop();    httpsGlobalKeystoreChannel.stop();}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    HttpClientBuilder builder = HttpClientBuilder.create();    httpClient = builder.build();    postRequest = new HttpPost("http://0.0.0.0:" + httpPort);}
6585f52b73df900795cafe996c0b532954be2cff3d5929b3f60005f02235c401
testSimple
public void testSimple() throws IOException, InterruptedException
{    StringEntity input = new StringEntity("[{\"headers\":{\"a\": \"b\"},\"body\": \"random_body\"}," + "{\"headers\":{\"e\": \"f\"},\"body\": \"random_body2\"}]");            input.setContentType("application/json");    postRequest.setEntity(input);    HttpResponse response = httpClient.execute(postRequest);    Assert.assertEquals(HttpServletResponse.SC_OK, response.getStatusLine().getStatusCode());    Transaction tx = httpChannel.getTransaction();    tx.begin();    Event e = httpChannel.take();    Assert.assertNotNull(e);    Assert.assertEquals("b", e.getHeaders().get("a"));    Assert.assertEquals("random_body", new String(e.getBody(), "UTF-8"));    e = httpChannel.take();    Assert.assertNotNull(e);    Assert.assertEquals("f", e.getHeaders().get("e"));    Assert.assertEquals("random_body2", new String(e.getBody(), "UTF-8"));    tx.commit();    tx.close();}
9fed529ed01a24e35ecf5b44992de2269e79aa485c2d1989ffb5abac0df57bfd
testTrace
public void testTrace() throws Exception
{    doTestForbidden(new HttpTrace("http://0.0.0.0:" + httpPort));}
8d5a1c70a5a42dfccd954328a6fb267785f09d415e93df22f7b7e578bd4bf938
testOptions
public void testOptions() throws Exception
{    doTestForbidden(new HttpOptions("http://0.0.0.0:" + httpPort));}
112f9c796beba7dc5a9cf0df795af386f69ceb68510d0ee2bf7e9448658b0bd6
doTestForbidden
private void doTestForbidden(HttpRequestBase request) throws Exception
{    HttpResponse response = httpClient.execute(request);    Assert.assertEquals(HttpServletResponse.SC_FORBIDDEN, response.getStatusLine().getStatusCode());}
7b315218c76455ae0de69a11e76897caf044a071b2caf210148490f72efb9a99
testSimpleUTF16
public void testSimpleUTF16() throws IOException, InterruptedException
{    StringEntity input = new StringEntity("[{\"headers\":{\"a\": \"b\"},\"body\": \"random_body\"}," + "{\"headers\":{\"e\": \"f\"},\"body\": \"random_body2\"}]", "UTF-16");    input.setContentType("application/json; charset=utf-16");    postRequest.setEntity(input);    HttpResponse response = httpClient.execute(postRequest);    Assert.assertEquals(HttpServletResponse.SC_OK, response.getStatusLine().getStatusCode());    Transaction tx = httpChannel.getTransaction();    tx.begin();    Event e = httpChannel.take();    Assert.assertNotNull(e);    Assert.assertEquals("b", e.getHeaders().get("a"));    Assert.assertEquals("random_body", new String(e.getBody(), "UTF-16"));    e = httpChannel.take();    Assert.assertNotNull(e);    Assert.assertEquals("f", e.getHeaders().get("e"));    Assert.assertEquals("random_body2", new String(e.getBody(), "UTF-16"));    tx.commit();    tx.close();}
01c98bf02b9f68a1daec251c9281f9f8fd7adf8deeca49efd57dec3723bb6263
testInvalid
public void testInvalid() throws Exception
{    StringEntity input = new StringEntity("[{\"a\": \"b\",[\"d\":\"e\"],\"body\": \"random_body\"}," + "{\"e\": \"f\",\"body\": \"random_body2\"}]");    input.setContentType("application/json");    postRequest.setEntity(input);    HttpResponse response = httpClient.execute(postRequest);    Assert.assertEquals(HttpServletResponse.SC_BAD_REQUEST, response.getStatusLine().getStatusCode());    SourceCounter sc = (SourceCounter) Whitebox.getInternalState(httpSource, "sourceCounter");    Assert.assertEquals(1, sc.getEventReadFail());}
3e17c401ad7ab93883b5355aba000f583ee2ca59be73239a0c8885f4ff2539b9
testBigBatchDeserializarionUTF8
public void testBigBatchDeserializarionUTF8() throws Exception
{    testBatchWithVariousEncoding("UTF-8");}
b327ccf917b4d4187044155c02c909bb215006324b8df222c1c42e4cd34c4a9d
testBigBatchDeserializarionUTF16
public void testBigBatchDeserializarionUTF16() throws Exception
{    testBatchWithVariousEncoding("UTF-16");}
84417d3de3f759c93a1c5eb33a7f24c3b3fdeccf7be3eae4a1bd1e9ec82ca554
testBigBatchDeserializarionUTF32
public void testBigBatchDeserializarionUTF32() throws Exception
{    testBatchWithVariousEncoding("UTF-32");}
7f9aca75746b489bcf662defd69d00df2fd6c6e982f7ad640b6d44f05d15550d
testCounterGenericFail
public void testCounterGenericFail() throws Exception
{    ChannelProcessor cp = Mockito.mock(ChannelProcessor.class);    doThrow(new RuntimeException("dummy")).when(cp).processEventBatch(anyListOf(Event.class));    ChannelProcessor oldCp = httpSource.getChannelProcessor();    httpSource.setChannelProcessor(cp);    testBatchWithVariousEncoding("UTF-8");    SourceCounter sc = (SourceCounter) Whitebox.getInternalState(httpSource, "sourceCounter");    Assert.assertEquals(1, sc.getGenericProcessingFail());    httpSource.setChannelProcessor(oldCp);}
cff45a0d39426061b080e44b420ee4494425129e7aeafde8ca1a634bec77f50a
testSingleEvent
public void testSingleEvent() throws Exception
{    StringEntity input = new StringEntity("[{\"headers\" : {\"a\": \"b\"},\"body\":" + " \"random_body\"}]");    input.setContentType("application/json");    postRequest.setEntity(input);    httpClient.execute(postRequest);    Transaction tx = httpChannel.getTransaction();    tx.begin();    Event e = httpChannel.take();    Assert.assertNotNull(e);    Assert.assertEquals("b", e.getHeaders().get("a"));    Assert.assertEquals("random_body", new String(e.getBody(), "UTF-8"));    tx.commit();    tx.close();}
28056c738adaf867ea80ba3e61a952b0e8d8e99a1ce41e1556f0ef699a5684a4
testConfigurables
public void testConfigurables() throws Exception
{    StringEntity input = new StringEntity("[{\"headers\" : {\"a\": \"b\"},\"body\":" + " \"random_body\"}]");    input.setContentType("application/json");    postRequest.setEntity(input);    HttpResponse resp = httpClient.execute(postRequest);        Assert.assertTrue(resp.getHeaders("X-Powered-By").length == 0);    Assert.assertTrue(resp.getHeaders("Server").length == 1);    Transaction tx = httpChannel.getTransaction();    tx.begin();    Event e = httpChannel.take();    Assert.assertNotNull(e);    tx.commit();    tx.close();    Assert.assertTrue(findMBeans("org.eclipse.jetty.util.thread:type=queuedthreadpool,*", "maxThreads", 123).size() == 0);    Assert.assertTrue(findMBeans("org.eclipse.jetty.server:type=serverconnector,*", "acceptQueueSize", 22).size() == 0);    int newPort = findFreePort();    Context configuredSourceContext = getDefaultNonSecureContext(newPort);    configuredSourceContext.put("HttpConfiguration.sendServerVersion", "false");    configuredSourceContext.put("HttpConfiguration.sendXPoweredBy", "true");    configuredSourceContext.put("ServerConnector.acceptQueueSize", "22");    configuredSourceContext.put("QueuedThreadPool.maxThreads", "123");    HTTPSource newSource = new HTTPSource();    Channel newChannel = new MemoryChannel();    configureSourceAndChannel(newSource, newChannel, configuredSourceContext);    newChannel.start();    newSource.start();    HttpPost newPostRequest = new HttpPost("http://0.0.0.0:" + newPort);    resp = httpClient.execute(newPostRequest);    Assert.assertTrue(resp.getHeaders("X-Powered-By").length > 0);    Assert.assertTrue(resp.getHeaders("Server").length == 0);    Assert.assertTrue(findMBeans("org.eclipse.jetty.util.thread:type=queuedthreadpool,*", "maxThreads", 123).size() == 1);    Assert.assertTrue(findMBeans("org.eclipse.jetty.server:type=serverconnector,*", "acceptQueueSize", 22).size() == 1);    newSource.stop();    newChannel.stop();        newPort = findFreePort();    configuredSourceContext = getDefaultSecureContext(newPort);    configuredSourceContext.put("SslContextFactory.IncludeProtocols", "abc def");    newSource = new HTTPSource();    newChannel = new MemoryChannel();    configureSourceAndChannel(newSource, newChannel, configuredSourceContext);    newChannel.start();    newSource.start();    newPostRequest = new HttpPost("http://0.0.0.0:" + newPort);    try {        doTestHttps(null, newPort, httpsChannel);                Assert.assertTrue(false);    } catch (AssertionError ex) {        }    newSource.stop();    newChannel.stop();}
e09f7bb5d5a69e79e72fb3b86a6776b178463d9b6929d6177da05b1a7cf85e0c
testFullChannel
public void testFullChannel() throws Exception
{    HttpResponse response = putWithEncoding("UTF-8", 150).response;    Assert.assertEquals(HttpServletResponse.SC_SERVICE_UNAVAILABLE, response.getStatusLine().getStatusCode());    SourceCounter sc = (SourceCounter) Whitebox.getInternalState(httpSource, "sourceCounter");    Assert.assertEquals(1, sc.getChannelWriteFail());}
9d8b3cd859683a89d41b04646dc9b0ca11cf8184a309f6b27c5868c2dfda3b73
testFail
public void testFail() throws Exception
{    HTTPSourceHandler handler = field("handler").ofType(HTTPSourceHandler.class).in(httpSource).get();            field("handler").ofType(HTTPSourceHandler.class).in(httpSource).set(null);    HttpResponse response = putWithEncoding("UTF-8", 1).response;    Assert.assertEquals(HttpServletResponse.SC_INTERNAL_SERVER_ERROR, response.getStatusLine().getStatusCode());        field("handler").ofType(HTTPSourceHandler.class).in(httpSource).set(handler);}
b534a43d7a9312f9d5010815e7f25f62ae63d9a34fb74eaef275d5011997021a
testMBeans
public void testMBeans() throws Exception
{    MBeanServer mbeanServer = ManagementFactory.getPlatformMBeanServer();    ObjectName objectName = new ObjectName("org.eclipse.jetty.*:*");    Set<ObjectInstance> queryMBeans = mbeanServer.queryMBeans(objectName, null);    Assert.assertTrue(queryMBeans.size() > 0);}
b878bb9c9d3208b43e3855fd94f26e3b698e34531ae0aa9f148dae63f1245a4a
testHandlerThrowingException
public void testHandlerThrowingException() throws Exception
{            HttpResponse response = putWithEncoding("ISO-8859-1", 150).response;    Assert.assertEquals(HttpServletResponse.SC_INTERNAL_SERVER_ERROR, response.getStatusLine().getStatusCode());}
be4f5d6144957275faa18ae09c86a1f50b2b8f807d6f148fafc9668f98fe674d
findMBeans
private Set<ObjectInstance> findMBeans(String name, String attribute, int value) throws MalformedObjectNameException
{    MBeanServer mbeanServer = ManagementFactory.getPlatformMBeanServer();    ObjectName objectName = new ObjectName(name);    QueryExp q = Query.eq(Query.attr(attribute), Query.value(value));    return mbeanServer.queryMBeans(objectName, q);}
5ae0f5f39bcfffb41edb6c3d7b3bca67bf0399e2e7bfe90e2f2abaf9333fee65
putWithEncoding
private ResultWrapper putWithEncoding(String encoding, int n) throws Exception
{    Type listType = new TypeToken<List<JSONEvent>>() {    }.getType();    List<JSONEvent> events = new ArrayList<JSONEvent>();    Random rand = new Random();    for (int i = 0; i < n; i++) {        Map<String, String> input = Maps.newHashMap();        for (int j = 0; j < 10; j++) {            input.put(String.valueOf(i) + String.valueOf(j), String.valueOf(i));        }        JSONEvent e = new JSONEvent();        e.setHeaders(input);        e.setBody(String.valueOf(rand.nextGaussian()).getBytes(encoding));        events.add(e);    }    Gson gson = new Gson();    String json = gson.toJson(events, listType);    StringEntity input = new StringEntity(json);    input.setContentType("application/json; charset=" + encoding);    postRequest.setEntity(input);    HttpResponse resp = httpClient.execute(postRequest);    return new ResultWrapper(resp, events);}
4c7773e721682e3af5506942b26204c7bed9eff09ae44829e4b7c6f941160873
testHttps
public void testHttps() throws Exception
{    doTestHttps(null, httpsPort, httpsChannel);}
97db63beb75a74f1bc95724de6490bd247afce41faa734349d8f069703ff3cdc
testHttpsSSLv3
public void testHttpsSSLv3() throws Exception
{    doTestHttps("SSLv3", httpsPort, httpsChannel);}
5047e2759634fc89e123829b90908f675c5516024fc945d82ee02d90ae1f7cc5
testHttpsGlobalKeystore
public void testHttpsGlobalKeystore() throws Exception
{    doTestHttps(null, httpsGlobalKeystorePort, httpsGlobalKeystoreChannel);}
3543148928e88c62f5063c06b134cf360cabb0382cde888d8d9ca5bb2083722a
doTestHttps
private void doTestHttps(String protocol, int port, Channel channel) throws Exception
{    Type listType = new TypeToken<List<JSONEvent>>() {    }.getType();    List<JSONEvent> events = new ArrayList<JSONEvent>();    Random rand = new Random();    for (int i = 0; i < 10; i++) {        Map<String, String> input = Maps.newHashMap();        for (int j = 0; j < 10; j++) {            input.put(String.valueOf(i) + String.valueOf(j), String.valueOf(i));        }        input.put("MsgNum", String.valueOf(i));        JSONEvent e = new JSONEvent();        e.setHeaders(input);        e.setBody(String.valueOf(rand.nextGaussian()).getBytes("UTF-8"));        events.add(e);    }    Gson gson = new Gson();    String json = gson.toJson(events, listType);    HttpsURLConnection httpsURLConnection = null;    Transaction transaction = null;    try {        TrustManager[] trustAllCerts = { new X509TrustManager() {            @Override            public void checkClientTrusted(java.security.cert.X509Certificate[] x509Certificates, String s) throws CertificateException {                        }            @Override            public void checkServerTrusted(java.security.cert.X509Certificate[] x509Certificates, String s) throws CertificateException {                        }            public java.security.cert.X509Certificate[] getAcceptedIssuers() {                return null;            }        } };        SSLContext sc = null;        javax.net.ssl.SSLSocketFactory factory = null;        if (System.getProperty("java.vendor").contains("IBM")) {            sc = SSLContext.getInstance("SSL_TLS");        } else {            sc = SSLContext.getInstance("SSL");        }        HostnameVerifier hv = new HostnameVerifier() {            public boolean verify(String arg0, SSLSession arg1) {                return true;            }        };        sc.init(null, trustAllCerts, new SecureRandom());        if (protocol != null) {            factory = new DisabledProtocolsSocketFactory(sc.getSocketFactory(), protocol);        } else {            factory = sc.getSocketFactory();        }        HttpsURLConnection.setDefaultSSLSocketFactory(factory);        HttpsURLConnection.setDefaultHostnameVerifier(NoopHostnameVerifier.INSTANCE);        URL sslUrl = new URL("https://0.0.0.0:" + port);        httpsURLConnection = (HttpsURLConnection) sslUrl.openConnection();        httpsURLConnection.setDoInput(true);        httpsURLConnection.setDoOutput(true);        httpsURLConnection.setRequestMethod("POST");        httpsURLConnection.getOutputStream().write(json.getBytes());        int statusCode = httpsURLConnection.getResponseCode();        Assert.assertEquals(200, statusCode);        transaction = channel.getTransaction();        transaction.begin();        for (int i = 0; i < 10; i++) {            Event e = channel.take();            Assert.assertNotNull(e);            Assert.assertEquals(String.valueOf(i), e.getHeaders().get("MsgNum"));        }    } finally {        if (transaction != null) {            transaction.commit();            transaction.close();        }        httpsURLConnection.disconnect();    }}
4d6b8a3853bd7455b75bda05be670dd8ea6f20223b5c5f70e2913592a47a93c7
checkClientTrusted
public void checkClientTrusted(java.security.cert.X509Certificate[] x509Certificates, String s) throws CertificateException
{}
7ba71cf8492a7e4d31baa0d9fa8f599142e0333694f65f19a2d03d62662dea15
checkServerTrusted
public void checkServerTrusted(java.security.cert.X509Certificate[] x509Certificates, String s) throws CertificateException
{}
a35f7a0798c73280978ccb8b2dbe5ee78ce3a0ff346555b49e87a5da2164e76c
getAcceptedIssuers
public java.security.cert.X509Certificate[] getAcceptedIssuers()
{    return null;}
d33a78b520f0db248fc6f9641469cdc3efb71c3ab9dd773a6ace58dc086b8902
verify
public boolean verify(String arg0, SSLSession arg1)
{    return true;}
c52f9cb33079a71aa634f44a9e2968020ef8e0f40e6466bdc13c2113d1260863
testHttpsSourceNonHttpsClient
public void testHttpsSourceNonHttpsClient() throws Exception
{    Type listType = new TypeToken<List<JSONEvent>>() {    }.getType();    List<JSONEvent> events = new ArrayList<JSONEvent>();    Random rand = new Random();    for (int i = 0; i < 10; i++) {        Map<String, String> input = Maps.newHashMap();        for (int j = 0; j < 10; j++) {            input.put(String.valueOf(i) + String.valueOf(j), String.valueOf(i));        }        input.put("MsgNum", String.valueOf(i));        JSONEvent e = new JSONEvent();        e.setHeaders(input);        e.setBody(String.valueOf(rand.nextGaussian()).getBytes("UTF-8"));        events.add(e);    }    Gson gson = new Gson();    String json = gson.toJson(events, listType);    HttpURLConnection httpURLConnection = null;    try {        URL url = new URL("http://0.0.0.0:" + httpsPort);        httpURLConnection = (HttpURLConnection) url.openConnection();        httpURLConnection.setDoInput(true);        httpURLConnection.setDoOutput(true);        httpURLConnection.setRequestMethod("POST");        httpURLConnection.getOutputStream().write(json.getBytes());        httpURLConnection.getResponseCode();        Assert.fail("HTTP Client cannot connect to HTTPS source");    } catch (Exception exception) {        Assert.assertTrue("Exception expected", true);    } finally {        httpURLConnection.disconnect();    }}
c32026dcb7ce137aba1af90afab00da0c6f07f195efcb3779e821b83ad39d869
takeWithEncoding
private void takeWithEncoding(String encoding, int n, List<JSONEvent> events) throws Exception
{    Transaction tx = httpChannel.getTransaction();    tx.begin();    Event e = null;    int i = 0;    while (true) {        e = httpChannel.take();        if (e == null) {            break;        }        Event current = events.get(i++);        Assert.assertEquals(new String(current.getBody(), encoding), new String(e.getBody(), encoding));        Assert.assertEquals(current.getHeaders(), e.getHeaders());    }    Assert.assertEquals(n, events.size());    tx.commit();    tx.close();}
d9f3567c4406d4c37f5df8b553350c87d3ab5701a28426355ae2df7b09e9dbbe
testBatchWithVariousEncoding
private void testBatchWithVariousEncoding(String encoding) throws Exception
{    testBatchWithVariousEncoding(encoding, 50);}
f5ba8d9416512e8535315be14ee53bb3cc661cd6f5cd0b531cc5af5cc8e3a9e6
testBatchWithVariousEncoding
private void testBatchWithVariousEncoding(String encoding, int n) throws Exception
{    List<JSONEvent> events = putWithEncoding(encoding, n).events;    takeWithEncoding(encoding, n, events);}
0ff49fb160d4fc07619583a4017d12910c5d5299326eb72fa73c8916b32ad462
getDefaultCipherSuites
public String[] getDefaultCipherSuites()
{    return socketFactory.getDefaultCipherSuites();}
e6bd8d7c2ab9d07a58f015eb51ef1f39513045f1a602fc30b46d25a8a9608312
getSupportedCipherSuites
public String[] getSupportedCipherSuites()
{    return socketFactory.getSupportedCipherSuites();}
79a882b9b9781d9271a417c705f8812a74505441f8dbd5db5abf35d5d1548b49
createSocket
public Socket createSocket(Socket socket, String s, int i, boolean b) throws IOException
{    SSLSocket sc = (SSLSocket) socketFactory.createSocket(socket, s, i, b);    sc.setEnabledProtocols(protocols);    return sc;}
4966b2e5e6ef7d1361179508cc88d6edfccba11b8b0fe9b75233bdad2b752efa
createSocket
public Socket createSocket(String s, int i) throws IOException, UnknownHostException
{    SSLSocket sc = (SSLSocket) socketFactory.createSocket(s, i);    sc.setEnabledProtocols(protocols);    return sc;}
0c7b845671f7231644f65f45c0815518b234e22f8b967385ff297801374a9c85
createSocket
public Socket createSocket(String s, int i, InetAddress inetAddress, int i2) throws IOException, UnknownHostException
{    SSLSocket sc = (SSLSocket) socketFactory.createSocket(s, i, inetAddress, i2);    sc.setEnabledProtocols(protocols);    return sc;}
0d7597f18aa83dadf431d62893dc991a833f4579a4ff6ea0be0cd330488cab17
createSocket
public Socket createSocket(InetAddress inetAddress, int i) throws IOException
{    SSLSocket sc = (SSLSocket) socketFactory.createSocket(inetAddress, i);    sc.setEnabledProtocols(protocols);    return sc;}
26e8bfd7d51d3be01de4c81dbd49e05f19bb290ba6a286c14671eed47c7a029f
createSocket
public Socket createSocket(InetAddress inetAddress, int i, InetAddress inetAddress2, int i2) throws IOException
{    SSLSocket sc = (SSLSocket) socketFactory.createSocket(inetAddress, i, inetAddress2, i2);    sc.setEnabledProtocols(protocols);    return sc;}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    handler = new JSONHandler();}
f774a7f33944dd5625a7d5a93bfb6968911cd47d5443afd8a03d3a8855decb92
testMultipleEvents
public void testMultipleEvents() throws Exception
{    String json = "[{\"headers\":{\"a\": \"b\"},\"body\": \"random_body\"}," + "{\"headers\":{\"e\": \"f\"},\"body\": \"random_body2\"}]";    HttpServletRequest req = new FlumeHttpServletRequestWrapper(json);    List<Event> deserialized = handler.getEvents(req);    Event e = deserialized.get(0);    Assert.assertEquals("b", e.getHeaders().get("a"));    Assert.assertEquals("random_body", new String(e.getBody(), "UTF-8"));    e = deserialized.get(1);    Assert.assertEquals("f", e.getHeaders().get("e"));    Assert.assertEquals("random_body2", new String(e.getBody(), "UTF-8"));}
03147ab5e3d41a1cf38666458e961b01465905c693f2c1a2b262b7a68146bd9f
testMultipleEventsUTF16
public void testMultipleEventsUTF16() throws Exception
{    String json = "[{\"headers\":{\"a\": \"b\"},\"body\": \"random_body\"}," + "{\"headers\":{\"e\": \"f\"},\"body\": \"random_body2\"}]";    HttpServletRequest req = new FlumeHttpServletRequestWrapper(json, "UTF-16");    List<Event> deserialized = handler.getEvents(req);    Event e = deserialized.get(0);    Assert.assertEquals("b", e.getHeaders().get("a"));    Assert.assertEquals("random_body", new String(e.getBody(), "UTF-16"));    e = deserialized.get(1);    Assert.assertEquals("f", e.getHeaders().get("e"));    Assert.assertEquals("random_body2", new String(e.getBody(), "UTF-16"));}
bef5f62346d1f77a507ea746fe14e7ee876dd28642480934399e278f9b8971fa
testMultipleEventsUTF32
public void testMultipleEventsUTF32() throws Exception
{    String json = "[{\"headers\":{\"a\": \"b\"},\"body\": \"random_body\"}," + "{\"headers\":{\"e\": \"f\"},\"body\": \"random_body2\"}]";    HttpServletRequest req = new FlumeHttpServletRequestWrapper(json, "UTF-32");    List<Event> deserialized = handler.getEvents(req);    Event e = deserialized.get(0);    Assert.assertEquals("b", e.getHeaders().get("a"));    Assert.assertEquals("random_body", new String(e.getBody(), "UTF-32"));    e = deserialized.get(1);    Assert.assertEquals("f", e.getHeaders().get("e"));    Assert.assertEquals("random_body2", new String(e.getBody(), "UTF-32"));}
48ca6eebb3d207551d690abe9386baeaf2be039b2015a5a666e69d608205204c
testMultipleEventsUTF8
public void testMultipleEventsUTF8() throws Exception
{    String json = "[{\"headers\":{\"a\": \"b\"},\"body\": \"random_body\"}," + "{\"headers\":{\"e\": \"f\"},\"body\": \"random_body2\"}]";    HttpServletRequest req = new FlumeHttpServletRequestWrapper(json, "UTF-8");    List<Event> deserialized = handler.getEvents(req);    Event e = deserialized.get(0);    Assert.assertEquals("b", e.getHeaders().get("a"));    Assert.assertEquals("random_body", new String(e.getBody(), "UTF-8"));    e = deserialized.get(1);    Assert.assertEquals("f", e.getHeaders().get("e"));    Assert.assertEquals("random_body2", new String(e.getBody(), "UTF-8"));}
2691969b7daf05a695269d40599437fda2a31a958f9973027ed4207b1a52f10e
testEscapedJSON
public void testEscapedJSON() throws Exception
{        String json = "[{\"headers\":{\"a\": \"b\"}}," + "{\"headers\":{\"e\": \"f\"},\"body\": \"rand\\\"om_body2\"}]";    HttpServletRequest req = new FlumeHttpServletRequestWrapper(json);    List<Event> deserialized = handler.getEvents(req);    Event e = deserialized.get(0);    Assert.assertEquals("b", e.getHeaders().get("a"));    Assert.assertTrue(e.getBody().length == 0);    e = deserialized.get(1);    Assert.assertEquals("f", e.getHeaders().get("e"));    Assert.assertEquals("rand\"om_body2", new String(e.getBody(), "UTF-8"));}
f791a610e86fbb4761a926aedf62606424ff69d6782a97fd30f39b6058dbc028
testNoBody
public void testNoBody() throws Exception
{    String json = "[{\"headers\" : {\"a\": \"b\"}}," + "{\"headers\" : {\"e\": \"f\"},\"body\": \"random_body2\"}]";    HttpServletRequest req = new FlumeHttpServletRequestWrapper(json);    List<Event> deserialized = handler.getEvents(req);    Event e = deserialized.get(0);    Assert.assertEquals("b", e.getHeaders().get("a"));    Assert.assertTrue(e.getBody().length == 0);    e = deserialized.get(1);    Assert.assertEquals("f", e.getHeaders().get("e"));    Assert.assertEquals("random_body2", new String(e.getBody(), "UTF-8"));}
4c48f6de3b85508470c2ac9f92f8679f3089f4fbd857ddbf530feb34d2b00e01
testSingleHTMLEvent
public void testSingleHTMLEvent() throws Exception
{    String json = "[{\"headers\": {\"a\": \"b\"}," + "\"body\": \"<html><body>test</body></html>\"}]";    HttpServletRequest req = new FlumeHttpServletRequestWrapper(json);    List<Event> deserialized = handler.getEvents(req);    Event e = deserialized.get(0);    Assert.assertEquals("b", e.getHeaders().get("a"));    Assert.assertEquals("<html><body>test</body></html>", new String(e.getBody(), "UTF-8"));}
cff45a0d39426061b080e44b420ee4494425129e7aeafde8ca1a634bec77f50a
testSingleEvent
public void testSingleEvent() throws Exception
{    String json = "[{\"headers\" : {\"a\": \"b\"},\"body\": \"random_body\"}]";    HttpServletRequest req = new FlumeHttpServletRequestWrapper(json);    List<Event> deserialized = handler.getEvents(req);    Event e = deserialized.get(0);    Assert.assertEquals("b", e.getHeaders().get("a"));    Assert.assertEquals("random_body", new String(e.getBody(), "UTF-8"));}
4a9531d6b2d7094b7aaf5c00eed9e6da3b9a47a3de1d8396934ef048d5403d0e
testBadEvent
public void testBadEvent() throws Exception
{    String json = "{[\"a\": \"b\"],\"body\": \"random_body\"}";    HttpServletRequest req = new FlumeHttpServletRequestWrapper(json);    handler.getEvents(req);    Assert.fail();}
efff5c7c8ff559172f6b752e68370b28bcc16ba0162834827c3752bbecd71505
testError
public void testError() throws Exception
{    String json = "[{\"headers\" : {\"a\": \"b\"},\"body\": \"random_body\"}]";    HttpServletRequest req = new FlumeHttpServletRequestWrapper(json, "ISO-8859-1");    handler.getEvents(req);    Assert.fail();}
55ea503278450b35dcc79407be972c3cd58c10d50419520b842642dfae6c811b
testSingleEventInArray
public void testSingleEventInArray() throws Exception
{    String json = "[{\"headers\": {\"a\": \"b\"},\"body\": \"random_body\"}]";    HttpServletRequest req = new FlumeHttpServletRequestWrapper(json);    List<Event> deserialized = handler.getEvents(req);    Event e = deserialized.get(0);    Assert.assertEquals("b", e.getHeaders().get("a"));    Assert.assertEquals("random_body", new String(e.getBody(), "UTF-8"));}
645c3707600ebbe7ca8534e9d86d785abea34cde7be78c1f753bdff2de3dda31
testMultipleLargeEvents
public void testMultipleLargeEvents() throws Exception
{    String json = "[{\"headers\" : {\"a\": \"b\", \"a2\": \"b2\"," + "\"a3\": \"b3\",\"a4\": \"b4\"},\"body\": \"random_body\"}," + "{\"headers\" :{\"e\": \"f\",\"e2\": \"f2\"," + "\"e3\": \"f3\",\"e4\": \"f4\",\"e5\": \"f5\"}," + "\"body\": \"random_body2\"}," + "{\"headers\" :{\"q1\": \"b\",\"q2\": \"b2\",\"q3\": \"b3\",\"q4\": \"b4\"}," + "\"body\": \"random_bodyq\"}]";    HttpServletRequest req = new FlumeHttpServletRequestWrapper(json);    List<Event> deserialized = handler.getEvents(req);    Event e = deserialized.get(0);    Assert.assertNotNull(e);    Assert.assertEquals("b", e.getHeaders().get("a"));    Assert.assertEquals("b2", e.getHeaders().get("a2"));    Assert.assertEquals("b3", e.getHeaders().get("a3"));    Assert.assertEquals("b4", e.getHeaders().get("a4"));    Assert.assertEquals("random_body", new String(e.getBody(), "UTF-8"));    e = deserialized.get(1);    Assert.assertNotNull(e);    Assert.assertEquals("f", e.getHeaders().get("e"));    Assert.assertEquals("f2", e.getHeaders().get("e2"));    Assert.assertEquals("f3", e.getHeaders().get("e3"));    Assert.assertEquals("f4", e.getHeaders().get("e4"));    Assert.assertEquals("f5", e.getHeaders().get("e5"));    Assert.assertEquals("random_body2", new String(e.getBody(), "UTF-8"));    e = deserialized.get(2);    Assert.assertNotNull(e);    Assert.assertEquals("b", e.getHeaders().get("q1"));    Assert.assertEquals("b2", e.getHeaders().get("q2"));    Assert.assertEquals("b3", e.getHeaders().get("q3"));    Assert.assertEquals("b4", e.getHeaders().get("q4"));    Assert.assertEquals("random_bodyq", new String(e.getBody(), "UTF-8"));}
96ea468b5e5fad25754664b675bf605a651bf7022d2d508d02314fd0116f176a
testDeserializarion
public void testDeserializarion() throws Exception
{    Type listType = new TypeToken<List<JSONEvent>>() {    }.getType();    List<JSONEvent> events = Lists.newArrayList();    Random rand = new Random();    for (int i = 1; i < 10; i++) {        Map<String, String> input = Maps.newHashMap();        for (int j = 1; j < 10; j++) {            input.put(String.valueOf(i) + String.valueOf(j), String.valueOf(i));        }        JSONEvent e = new JSONEvent();        e.setBody(String.valueOf(rand.nextGaussian()).getBytes("UTF-8"));        e.setHeaders(input);        events.add(e);    }    Gson gson = new Gson();    List<Event> deserialized = handler.getEvents(new FlumeHttpServletRequestWrapper(gson.toJson(events, listType)));    int i = 0;    for (Event e : deserialized) {        Event current = events.get(i++);        Assert.assertEquals(new String(current.getBody(), "UTF-8"), new String(e.getBody(), "UTF-8"));        Assert.assertEquals(current.getHeaders(), e.getHeaders());    }}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{}
54497ccb2ff9760f1ec7fc0d0055d4bc60d5981953c5f3d7550c4b31a01e7642
getLifecycleState
public LifecycleState getLifecycleState()
{    return null;}
d34ae400fa404ae8de18399724ab38aa30dec04afdb69bd8c6bd899e741fe133
setChannelProcessor
public void setChannelProcessor(ChannelProcessor cp)
{}
f498f22eaf0816bf385a43365651d1b6d0455905fdd2d6be01ceefeb84e8f432
setName
public void setName(String name)
{    this.name = name;}
239fbe3eb64d679cbac1161825b07d6a8436ead3c6c3d140d9caec2275827023
getName
public String getName()
{    return name;}
2d47839be71cf363737c5c26abff8ca7e978b9a2567179574c983ee89f00b2da
getChannelProcessor
public ChannelProcessor getChannelProcessor()
{    return null;}
55a7f99ea12a874ee6b4e42c2e184f3b174a1b226664a015fd13d18771b5f34d
testSimple
public void testSimple()
{    RateLimiter limiter = RateLimiter.create(stopwatch, 5.0);        limiter.acquire();        limiter.acquire();        limiter.acquire();    assertEvents("R0.00", "R0.20", "R0.20");}
ec7fcf7607f692f1535bc4ac1117b3241859d15d4019d98e28db9d0ea70770fd
testImmediateTryAcquire
public void testImmediateTryAcquire()
{    RateLimiter r = RateLimiter.create(1);    assertTrue("Unable to acquire initial permit", r.tryAcquire());    assertFalse("Capable of acquiring secondary permit", r.tryAcquire());}
8940fd1e859755e105ff11444d6203c0ec7a11b1759a7c6cbfa17d9073ce6550
testSimpleRateUpdate
public void testSimpleRateUpdate()
{    RateLimiter limiter = RateLimiter.create(5.0, 5, SECONDS);    assertEquals(5.0, limiter.getRate());    limiter.setRate(10.0);    assertEquals(10.0, limiter.getRate());    try {        limiter.setRate(0.0);        fail();    } catch (IllegalArgumentException expected) {    }    try {        limiter.setRate(-10.0);        fail();    } catch (IllegalArgumentException expected) {    }}
1738519450694326d8cf85efbaaeb57002ac88b1e09e2f9f9b299e91830c58a2
testAcquireParameterValidation
public void testAcquireParameterValidation()
{    RateLimiter limiter = RateLimiter.create(999);    try {        limiter.acquire(0);        fail();    } catch (IllegalArgumentException expected) {    }    try {        limiter.acquire(-1);        fail();    } catch (IllegalArgumentException expected) {    }    try {        limiter.tryAcquire(0);        fail();    } catch (IllegalArgumentException expected) {    }    try {        limiter.tryAcquire(-1);        fail();    } catch (IllegalArgumentException expected) {    }    try {        limiter.tryAcquire(0, 1, SECONDS);        fail();    } catch (IllegalArgumentException expected) {    }    try {        limiter.tryAcquire(-1, 1, SECONDS);        fail();    } catch (IllegalArgumentException expected) {    }}
8700be4ffe0f5625aa8b24020729b4e3cc7744a0e29c7ead6f9814ce208bafe2
testSimpleWithWait
public void testSimpleWithWait()
{    RateLimiter limiter = RateLimiter.create(stopwatch, 5.0);        limiter.acquire();        stopwatch.sleepMillis(200);        limiter.acquire();        limiter.acquire();    assertEvents("R0.00", "U0.20", "R0.00", "R0.20");}
054e9e9ff89b4c51e7b2cd233cc03bd088c1dc51855697da8d1172897e6aa989
testSimpleAcquireReturnValues
public void testSimpleAcquireReturnValues()
{    RateLimiter limiter = RateLimiter.create(stopwatch, 5.0);        assertEquals(0.0, limiter.acquire(), EPSILON);        stopwatch.sleepMillis(200);        assertEquals(0.0, limiter.acquire(), EPSILON);        assertEquals(0.2, limiter.acquire(), EPSILON);    assertEvents("R0.00", "U0.20", "R0.00", "R0.20");}
c59dabcfd948221b98b9e31769b7d200e57775695c26969d2c635ecb71582a13
testSimpleAcquireEarliestAvailableIsInPast
public void testSimpleAcquireEarliestAvailableIsInPast()
{    RateLimiter limiter = RateLimiter.create(stopwatch, 5.0);    assertEquals(0.0, limiter.acquire(), EPSILON);    stopwatch.sleepMillis(400);    assertEquals(0.0, limiter.acquire(), EPSILON);    assertEquals(0.0, limiter.acquire(), EPSILON);    assertEquals(0.2, limiter.acquire(), EPSILON);}
e056a226954762c79be5c9737841eafd57ee19f9d1ceb2cadfdb7bbdfdd211fa
testOneSecondBurst
public void testOneSecondBurst()
{    RateLimiter limiter = RateLimiter.create(stopwatch, 5.0);        stopwatch.sleepMillis(1000);        stopwatch.sleepMillis(1000);        limiter.acquire(1);        limiter.acquire(1);        limiter.acquire(3);        limiter.acquire(1);        limiter.acquire();    assertEvents("U1.00", "U1.00",     "R0.00",     "R0.00",     "R0.00",     "R0.00", "R0.20");}
4eb80ba026d52ef7e3b3c8930fd562e089ded33a3d9fd937fd892149f866f505
testCreateWarmupParameterValidation
public void testCreateWarmupParameterValidation()
{    RateLimiter.create(1.0, 1, NANOSECONDS);    RateLimiter.create(1.0, 0, NANOSECONDS);    try {        RateLimiter.create(0.0, 1, NANOSECONDS);        fail();    } catch (IllegalArgumentException expected) {    }    try {        RateLimiter.create(1.0, -1, NANOSECONDS);        fail();    } catch (IllegalArgumentException expected) {    }}
c688e6ffd4a78a90ea757798b6ab73604182af9a13b1a1119d3fa789983f678c
testWarmUp
public void testWarmUp()
{    RateLimiter limiter = RateLimiter.create(stopwatch, 2.0, 4000, MILLISECONDS);    for (int i = 0; i < 8; i++) {                limiter.acquire();    }        stopwatch.sleepMillis(500);        stopwatch.sleepMillis(4000);    for (int i = 0; i < 8; i++) {                limiter.acquire();    }        stopwatch.sleepMillis(500);        stopwatch.sleepMillis(2000);    for (int i = 0; i < 8; i++) {                limiter.acquire();    }    assertEvents(    "R0.00, R1.38, R1.13, R0.88, R0.63, R0.50, R0.50, R0.50",     "U0.50",     "U4.00",     "R0.00, R1.38, R1.13, R0.88, R0.63, R0.50, R0.50, R0.50",     "U0.50",     "U2.00",     "R0.00, R0.50, R0.50, R0.50, R0.50, R0.50, R0.50, R0.50");}
f913704f1522c8e9d9beef7fcbf02d6af7572e2e1bc03f7290ca9afb04b42213
testWarmUpAndUpdate
public void testWarmUpAndUpdate()
{    RateLimiter limiter = RateLimiter.create(stopwatch, 2.0, 4000, MILLISECONDS);    for (int i = 0; i < 8; i++) {                limiter.acquire();    }        stopwatch.sleepMillis(4500);    for (int i = 0; i < 3; i++) {                        limiter.acquire();    }        limiter.setRate(4.0);        limiter.acquire();    for (int i = 0; i < 4; i++) {                limiter.acquire();    }        stopwatch.sleepMillis(4250);    for (int i = 0; i < 11; i++) {                limiter.acquire();    }        assertEvents(    "R0.00, R1.38, R1.13, R0.88, R0.63, R0.50, R0.50, R0.50",     "U4.50",     "R0.00, R1.38, R1.13",     "R0.88",     "R0.34, R0.28, R0.25, R0.25",     "U4.25",     "R0.00, R0.72, R0.66, R0.59, R0.53, R0.47, R0.41",     "R0.34, R0.28, R0.25, R0.25");}
eda6b8b844665cd86e811ee68b05bcf17c738e38355bd39908e93bdb1c3f60aa
testBurstyAndUpdate
public void testBurstyAndUpdate()
{    RateLimiter rateLimiter = RateLimiter.create(stopwatch, 1.0);        rateLimiter.acquire(1);        rateLimiter.acquire(1);        rateLimiter.setRate(2.0);        rateLimiter.acquire(1);        rateLimiter.acquire(2);        rateLimiter.acquire(4);        rateLimiter.acquire(1);    assertEvents("R0.00", "R1.00", "R1.00", "R0.50", "R1.00", "R2.00");}
d05cff9f49959bfdc21bec421c3ff07f64c4cb53e4a32779b898a487081e34f5
testTryAcquire_noWaitAllowed
public void testTryAcquire_noWaitAllowed()
{    RateLimiter limiter = RateLimiter.create(stopwatch, 5.0);    assertTrue(limiter.tryAcquire(0, SECONDS));    assertFalse(limiter.tryAcquire(0, SECONDS));    assertFalse(limiter.tryAcquire(0, SECONDS));    stopwatch.sleepMillis(100);    assertFalse(limiter.tryAcquire(0, SECONDS));}
2eeea04b7d5a36f6de298735d240a26214f16e99b1c782ffb4f57b67e6044724
testTryAcquire_someWaitAllowed
public void testTryAcquire_someWaitAllowed()
{    RateLimiter limiter = RateLimiter.create(stopwatch, 5.0);    assertTrue(limiter.tryAcquire(0, SECONDS));    assertTrue(limiter.tryAcquire(200, MILLISECONDS));    assertFalse(limiter.tryAcquire(100, MILLISECONDS));    stopwatch.sleepMillis(100);    assertTrue(limiter.tryAcquire(100, MILLISECONDS));}
2c62e725de253f04a17a3bf149e0faef05b226366901ba708b5f837311bcb7b3
testTryAcquire_overflow
public void testTryAcquire_overflow()
{    RateLimiter limiter = RateLimiter.create(stopwatch, 5.0);    assertTrue(limiter.tryAcquire(0, MICROSECONDS));    stopwatch.sleepMillis(100);    assertTrue(limiter.tryAcquire(Long.MAX_VALUE, MICROSECONDS));}
155dff6ed571ad97467eb59e522ac0760b396f8e22b20bd1c884682e6302cd2c
testTryAcquire_negative
public void testTryAcquire_negative()
{    RateLimiter limiter = RateLimiter.create(stopwatch, 5.0);    assertTrue(limiter.tryAcquire(5, 0, SECONDS));    stopwatch.sleepMillis(900);    assertFalse(limiter.tryAcquire(1, Long.MIN_VALUE, SECONDS));    stopwatch.sleepMillis(100);    assertTrue(limiter.tryAcquire(1, -1, SECONDS));}
7469736c072819d238dd482556d89b415393993b8cd9efb3a84ab23b81c5acb8
testSimpleWeights
public void testSimpleWeights()
{    RateLimiter rateLimiter = RateLimiter.create(stopwatch, 1.0);        rateLimiter.acquire(1);        rateLimiter.acquire(1);        rateLimiter.acquire(2);        rateLimiter.acquire(4);        rateLimiter.acquire(8);        rateLimiter.acquire(1);    assertEvents("R0.00", "R1.00", "R1.00", "R2.00", "R4.00", "R8.00");}
d80fbffeb175a95c62972fca9dea9abb83417d7832b42e755d5c1964db95f487
testInfinity_Bursty
public void testInfinity_Bursty()
{    RateLimiter limiter = RateLimiter.create(stopwatch, Double.POSITIVE_INFINITY);    limiter.acquire(Integer.MAX_VALUE / 4);    limiter.acquire(Integer.MAX_VALUE / 2);    limiter.acquire(Integer.MAX_VALUE);        assertEvents("R0.00", "R0.00", "R0.00");    limiter.setRate(2.0);    limiter.acquire();    limiter.acquire();    limiter.acquire();    limiter.acquire();    limiter.acquire();    assertEvents(    "R0.00", "R0.00",     "R0.00",     "R0.50", "R0.50");    limiter.setRate(Double.POSITIVE_INFINITY);    limiter.acquire();    limiter.acquire();    limiter.acquire();        assertEvents("R0.50", "R0.00", "R0.00");}
8762b5e9294055f40e5a578f0791f00282ea0643c950f8d8c116960909569cf3
testInfinity_BustyTimeElapsed
public void testInfinity_BustyTimeElapsed()
{    RateLimiter limiter = RateLimiter.create(stopwatch, Double.POSITIVE_INFINITY);    stopwatch.instant += 1000000;    limiter.setRate(2.0);    for (int i = 0; i < 5; i++) {        limiter.acquire();    }    assertEvents(    "R0.00", "R0.00",     "R0.00",     "R0.50", "R0.50");}
981141a39727ed5e2d19b4ecafc08091ce2aa751b2c4522eb00822aa3c055c91
testInfinity_WarmUp
public void testInfinity_WarmUp()
{    RateLimiter limiter = RateLimiter.create(stopwatch, Double.POSITIVE_INFINITY, 10, SECONDS);    limiter.acquire(Integer.MAX_VALUE / 4);    limiter.acquire(Integer.MAX_VALUE / 2);    limiter.acquire(Integer.MAX_VALUE);    assertEvents("R0.00", "R0.00", "R0.00");    limiter.setRate(1.0);    limiter.acquire();    limiter.acquire();    limiter.acquire();    assertEvents("R0.00", "R1.00", "R1.00");    limiter.setRate(Double.POSITIVE_INFINITY);    limiter.acquire();    limiter.acquire();    limiter.acquire();    assertEvents("R1.00", "R0.00", "R0.00");}
9b267f4015f913163ff6e83b1ee231ab32fea3cb401daea3fa31f8575de5e222
testInfinity_WarmUpTimeElapsed
public void testInfinity_WarmUpTimeElapsed()
{    RateLimiter limiter = RateLimiter.create(stopwatch, Double.POSITIVE_INFINITY, 10, SECONDS);    stopwatch.instant += 1000000;    limiter.setRate(1.0);    for (int i = 0; i < 5; i++) {        limiter.acquire();    }    assertEvents("R0.00", "R1.00", "R1.00", "R1.00", "R1.00");}
72dda8bf22963b78836cccee1df03f4f72d52d891f567dc8871d76a601d87a42
testWeNeverGetABurstMoreThanOneSec
public void testWeNeverGetABurstMoreThanOneSec()
{    RateLimiter limiter = RateLimiter.create(stopwatch, 1.0);    int[] rates = { 1000, 1, 10, 1000000, 10, 1 };    for (int rate : rates) {        int oneSecWorthOfWork = rate;        stopwatch.sleepMillis(rate * 1000);        limiter.setRate(rate);        long burst = measureTotalTimeMillis(limiter, oneSecWorthOfWork, new Random());                assertTrue(burst <= 1000);        long afterBurst = measureTotalTimeMillis(limiter, oneSecWorthOfWork, new Random());                assertTrue(afterBurst >= 1000);    }}
da937406528dec1cd1695b27daa16f5a8353d4bedbec31a134ff78cf19fc6498
testTimeToWarmUpIsHonouredEvenWithWeights
public void testTimeToWarmUpIsHonouredEvenWithWeights()
{    Random random = new Random();    int maxPermits = 10;    double[] qpsToTest = { 4.0, 2.0, 1.0, 0.5, 0.1 };    for (int trial = 0; trial < 100; trial++) {        for (double qps : qpsToTest) {                                                long warmupMillis = (long) ((2 * maxPermits / qps) * 1000.0);            RateLimiter rateLimiter = RateLimiter.create(stopwatch, qps, warmupMillis, MILLISECONDS);            assertEquals(warmupMillis, measureTotalTimeMillis(rateLimiter, maxPermits, random));        }    }}
f4265f3ee5d76cbc591c6d50f924557a6c5ba65d4e8fb1d56de5cf53cec3b6fb
measureTotalTimeMillis
private long measureTotalTimeMillis(RateLimiter rateLimiter, int permits, Random random)
{    long startTime = stopwatch.instant;    while (permits > 0) {        int nextPermitsToAcquire = Math.max(1, random.nextInt(permits));        permits -= nextPermitsToAcquire;        rateLimiter.acquire(nextPermitsToAcquire);    }        rateLimiter.acquire(1);    return NANOSECONDS.toMillis(stopwatch.instant - startTime);}
09ee81331712874248793b4551fce40e8640470fa845fac2f34170247adaf498
assertEvents
private void assertEvents(String... events)
{    assertEquals(Arrays.toString(events), stopwatch.readEventsAndClear());}
dae7e07ed936046fd3bf0b1c44a20a928a9355a6eeb76f9e1ca95528004898e5
readMicros
public long readMicros()
{    return NANOSECONDS.toMicros(instant);}
501441055718619ea838ec1fa68ef442fa1755234bc34af12a84aa71e5c7303d
sleepMillis
 void sleepMillis(int millis)
{    sleepMicros("U", MILLISECONDS.toMicros(millis));}
fad88dcc3c67d5f277f988ec138f29bb6fe9ad2feaf5b6055173eada368ceb22
sleepMicros
 void sleepMicros(String caption, long micros)
{    instant += MICROSECONDS.toNanos(micros);    events.add(caption + String.format("%3.2f", (micros / 1000000.0)));}
a0d49470cd449e73bcbe764b6c505fc3ece38a9e57107d0efb2ecff928150a53
sleepMicrosUninterruptibly
 void sleepMicrosUninterruptibly(long micros)
{    sleepMicros("R", micros);}
a6ee19d5ae6647efdae0f0315e48a1fe29f7ec8492b5f95e450dfab525d2bdc2
readEventsAndClear
 String readEventsAndClear()
{    try {        return events.toString();    } finally {        events.clear();    }}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return events.toString();}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    source = spy(new AbstractPollableSource() {        @Override        protected Status doProcess() throws EventDeliveryException {            return Status.BACKOFF;        }        @Override        protected void doConfigure(Context context) throws FlumeException {            throw new FlumeException("dummy");        }        @Override        protected void doStart() throws FlumeException {        }        @Override        protected void doStop() throws FlumeException {        }    });}
a30bb502129b437d7473071d9300950cf74e2295abc5081e9e1dca626bc22835
doProcess
protected Status doProcess() throws EventDeliveryException
{    return Status.BACKOFF;}
142257108f477bf2e124e1838bfbce41c0a617c37f4ee7c5e0f8eb9232c79477
doConfigure
protected void doConfigure(Context context) throws FlumeException
{    throw new FlumeException("dummy");}
9dc3ff24bcdde4c0d9a8a91bf810de54f264a0f1ca17b695fea6381be65d7456
doStart
protected void doStart() throws FlumeException
{}
984404ddc9435f386a11b7a4633a4b527dc0cdb6ff0eb2dfeb17ad1c4907be8b
doStop
protected void doStop() throws FlumeException
{}
3987587836e2d227ce8211fece83fcc96076f5bd903000da4ca4311cb82f7014
testExceptionStartup
public void testExceptionStartup() throws Exception
{    source.configure(new Context());}
47c3eee6d219f1f235e35d96063d956bf56305a240f66f725316c415063cf788
testNotStarted
public void testNotStarted() throws Exception
{    source.process();}
ac37ea15a5eeb115305ff48697cd24e438ab6cd2bbc6bfb9eb878258d4ec7852
voidBackOffConfig
public void voidBackOffConfig()
{    source = spy(new AbstractPollableSource() {        @Override        protected Status doProcess() throws EventDeliveryException {            return Status.BACKOFF;        }        @Override        protected void doConfigure(Context context) throws FlumeException {        }        @Override        protected void doStart() throws FlumeException {        }        @Override        protected void doStop() throws FlumeException {        }    });    HashMap<String, String> inputConfigs = new HashMap<String, String>();    inputConfigs.put(PollableSourceConstants.BACKOFF_SLEEP_INCREMENT, "42");    inputConfigs.put(PollableSourceConstants.MAX_BACKOFF_SLEEP, "4242");    Context context = new Context(inputConfigs);    source.configure(context);    Assert.assertEquals("BackOffSleepIncrement should equal 42 but it equals " + source.getBackOffSleepIncrement(), 42L, source.getBackOffSleepIncrement());    Assert.assertEquals("BackOffSleepIncrement should equal 42 but it equals " + source.getMaxBackOffSleepInterval(), 4242L, source.getMaxBackOffSleepInterval());}
a30bb502129b437d7473071d9300950cf74e2295abc5081e9e1dca626bc22835
doProcess
protected Status doProcess() throws EventDeliveryException
{    return Status.BACKOFF;}
142257108f477bf2e124e1838bfbce41c0a617c37f4ee7c5e0f8eb9232c79477
doConfigure
protected void doConfigure(Context context) throws FlumeException
{}
9dc3ff24bcdde4c0d9a8a91bf810de54f264a0f1ca17b695fea6381be65d7456
doStart
protected void doStart() throws FlumeException
{}
984404ddc9435f386a11b7a4633a4b527dc0cdb6ff0eb2dfeb17ad1c4907be8b
doStop
protected void doStop() throws FlumeException
{}
44fe7fba670c232c0ec497e56c0be37408e822c1f504ba8f9d52ad22f9792e74
voidBackOffConfigDefaults
public void voidBackOffConfigDefaults()
{    source = spy(new AbstractPollableSource() {        @Override        protected Status doProcess() throws EventDeliveryException {            return Status.BACKOFF;        }        @Override        protected void doConfigure(Context context) throws FlumeException {        }        @Override        protected void doStart() throws FlumeException {        }        @Override        protected void doStop() throws FlumeException {        }    });    HashMap<String, String> inputConfigs = new HashMap<String, String>();    Assert.assertEquals("BackOffSleepIncrement should equal " + PollableSourceConstants.DEFAULT_BACKOFF_SLEEP_INCREMENT + " but it equals " + source.getBackOffSleepIncrement(), PollableSourceConstants.DEFAULT_BACKOFF_SLEEP_INCREMENT, source.getBackOffSleepIncrement());    Assert.assertEquals("BackOffSleepIncrement should equal " + PollableSourceConstants.DEFAULT_MAX_BACKOFF_SLEEP + " but it equals " + source.getMaxBackOffSleepInterval(), PollableSourceConstants.DEFAULT_MAX_BACKOFF_SLEEP, source.getMaxBackOffSleepInterval());}
a30bb502129b437d7473071d9300950cf74e2295abc5081e9e1dca626bc22835
doProcess
protected Status doProcess() throws EventDeliveryException
{    return Status.BACKOFF;}
142257108f477bf2e124e1838bfbce41c0a617c37f4ee7c5e0f8eb9232c79477
doConfigure
protected void doConfigure(Context context) throws FlumeException
{}
9dc3ff24bcdde4c0d9a8a91bf810de54f264a0f1ca17b695fea6381be65d7456
doStart
protected void doStart() throws FlumeException
{}
984404ddc9435f386a11b7a4633a4b527dc0cdb6ff0eb2dfeb17ad1c4907be8b
doStop
protected void doStop() throws FlumeException
{}
74d341ac3879e68bf7d657a8391efe94bd29383b59d592d2c30ac58506567148
setUp
public void setUp() throws UnknownHostException
{    localhost = InetAddress.getByName("127.0.0.1");    source = new AvroSource();    channel = new MemoryChannel();    Configurables.configure(channel, new Context());    List<Channel> channels = new ArrayList<Channel>();    channels.add(channel);    ChannelSelector rcs = new ReplicatingChannelSelector();    rcs.setChannels(channels);    source.setChannelProcessor(new ChannelProcessor(rcs));}
1535fcdd6ca3dd330dcc636affe543b72151f453b79e6a20d8e21e11c1d8b45b
testLifecycle
public void testLifecycle() throws InterruptedException, IOException
{    Context context = new Context();    context.put("port", String.valueOf(selectedPort = getFreePort()));    context.put("bind", "0.0.0.0");    Configurables.configure(source, context);    source.start();    Assert.assertTrue("Reached start or error", LifecycleController.waitForOneOf(source, LifecycleState.START_OR_ERROR));    Assert.assertEquals("Server is started", LifecycleState.START, source.getLifecycleState());    source.stop();    Assert.assertTrue("Reached stop or error", LifecycleController.waitForOneOf(source, LifecycleState.STOP_OR_ERROR));    Assert.assertEquals("Server is stopped", LifecycleState.STOP, source.getLifecycleState());}
292d2de5ed3342412c1e0a052d16159611dca4d62177d2464223bb86d356bfc9
testSourceStoppedOnFlumeExceptionIfPortUsed
public void testSourceStoppedOnFlumeExceptionIfPortUsed() throws InterruptedException, IOException
{    final String loopbackIPv4 = "127.0.0.1";    final int port = 10500;        try (ServerSocketChannel dummyServerSocket = ServerSocketChannel.open()) {        dummyServerSocket.socket().setReuseAddress(true);        dummyServerSocket.socket().bind(new InetSocketAddress(loopbackIPv4, port));        Context context = new Context();        context.put("port", String.valueOf(port));        context.put("bind", loopbackIPv4);        Configurables.configure(source, context);        try {            source.start();            Assert.fail("Expected an exception during startup caused by binding on a used port");        } catch (FlumeException e) {            logger.info("Received an expected exception.", e);            Assert.assertTrue("Expected a server socket setup related root cause", e.getMessage().contains("server socket"));        }    }            Assert.assertEquals("Server is stopped", LifecycleState.STOP, source.getLifecycleState());}
cb11fa92edc040b365f91763a6c7113acbec3e6de4c8734d66d51a39a3afa9b9
testInvalidAddress
public void testInvalidAddress() throws InterruptedException, IOException
{    final String invalidHost = "invalid.host";    final int port = 10501;    Context context = new Context();    context.put("port", String.valueOf(port));    context.put("bind", invalidHost);    Configurables.configure(source, context);    try {        source.start();        Assert.fail("Expected an exception during startup caused by binding on a invalid host");    } catch (FlumeException e) {        logger.info("Received an expected exception.", e);        Assert.assertTrue("Expected a server socket setup related root cause", e.getMessage().contains("server socket"));    }            Assert.assertEquals("Server is stopped", LifecycleState.STOP, source.getLifecycleState());}
0069667c4477750e8dc5750acf5c9951ea4c00738bdb2704cc063c71b9e6e63f
testRequestWithNoCompression
public void testRequestWithNoCompression() throws InterruptedException, IOException
{    doRequest(false, false, 6);}
df0b3fbf0b69dcfcf4dd16d7a6cf131f61cd28369e4145b37c3409c7f48e635c
testRequestWithCompressionOnClientAndServerOnLevel0
public void testRequestWithCompressionOnClientAndServerOnLevel0() throws InterruptedException, IOException
{    doRequest(true, true, 0);}
9ae3f1da4a9545c28cb2dd0c911e4d7c7ac1ff527b20ca1d528ded3f909655c8
testRequestWithCompressionOnClientAndServerOnLevel1
public void testRequestWithCompressionOnClientAndServerOnLevel1() throws InterruptedException, IOException
{    doRequest(true, true, 1);}
1579a7ede4379218a49862acc92982c1b31f3168d5fcf378fd3185ee0284b81a
testRequestWithCompressionOnClientAndServerOnLevel6
public void testRequestWithCompressionOnClientAndServerOnLevel6() throws InterruptedException, IOException
{    doRequest(true, true, 6);}
6f23164d87a341b2e8ddb5e76281019d4ed06441a4a8bc0255affef5086c6b3a
testRequestWithCompressionOnClientAndServerOnLevel9
public void testRequestWithCompressionOnClientAndServerOnLevel9() throws InterruptedException, IOException
{    doRequest(true, true, 9);}
b2cf9a3577c5582bfd88e8115e8912ecdc7d388eb224cc7b6bceee69a137a06b
testRequestWithCompressionOnServerOnly
public void testRequestWithCompressionOnServerOnly() throws InterruptedException, IOException
{        doRequest(true, false, 6);}
8144715e32cb73129f94c34e62f9446af358ecc27e8c5cc2ae1b8120f3d1b606
testRequestWithCompressionOnClientOnly
public void testRequestWithCompressionOnClientOnly() throws InterruptedException, IOException
{        doRequest(false, true, 6);}
065fed0def1db70b06229afadfa7e8e42101148ae1928501d38dd9c9e38b15ab
doRequest
private void doRequest(boolean serverEnableCompression, boolean clientEnableCompression, int compressionLevel) throws InterruptedException, IOException
{    Context context = new Context();    context.put("port", String.valueOf(selectedPort = getFreePort()));    context.put("bind", "0.0.0.0");    context.put("threads", "50");    if (serverEnableCompression) {        context.put("compression-type", "deflate");    } else {        context.put("compression-type", "none");    }    Configurables.configure(source, context);    source.start();    Assert.assertTrue("Reached start or error", LifecycleController.waitForOneOf(source, LifecycleState.START_OR_ERROR));    Assert.assertEquals("Server is started", LifecycleState.START, source.getLifecycleState());    AvroSourceProtocol client;    NettyTransceiver nettyTransceiver;    if (clientEnableCompression) {        nettyTransceiver = new NettyTransceiver(new InetSocketAddress(selectedPort), new CompressionChannelFactory(compressionLevel));        client = SpecificRequestor.getClient(AvroSourceProtocol.class, nettyTransceiver);    } else {        nettyTransceiver = new NettyTransceiver(new InetSocketAddress(selectedPort));        client = SpecificRequestor.getClient(AvroSourceProtocol.class, nettyTransceiver);    }    AvroFlumeEvent avroEvent = new AvroFlumeEvent();    avroEvent.setHeaders(new HashMap<CharSequence, CharSequence>());    avroEvent.setBody(ByteBuffer.wrap("Hello avro".getBytes()));    Status status = client.append(avroEvent);    Assert.assertEquals(Status.OK, status);    Transaction transaction = channel.getTransaction();    transaction.begin();    Event event = channel.take();    Assert.assertNotNull(event);    Assert.assertEquals("Channel contained our event", "Hello avro", new String(event.getBody()));    transaction.commit();    transaction.close();    logger.debug("Round trip event:{}", event);    nettyTransceiver.close();    source.stop();    Assert.assertTrue("Reached stop or error", LifecycleController.waitForOneOf(source, LifecycleState.STOP_OR_ERROR));    Assert.assertEquals("Server is stopped", LifecycleState.STOP, source.getLifecycleState());}
e588fdcac0f93907e6fd30ac1e1ee422df799f8f5afe399e4e667bd8e1725f56
getFreePort
private static int getFreePort() throws IOException
{    try (ServerSocket socket = new ServerSocket(0)) {        return socket.getLocalPort();    }}
f1d152743f68a17edf485ca7b0b821c356590cf73312288f7adcb6c93907e077
newChannel
public SocketChannel newChannel(ChannelPipeline pipeline)
{    try {        ZlibEncoder encoder = new ZlibEncoder(compressionLevel);        pipeline.addFirst("deflater", encoder);        pipeline.addFirst("inflater", new ZlibDecoder());        return super.newChannel(pipeline);    } catch (Exception ex) {        throw new RuntimeException("Cannot create Compression channel", ex);    }}
06be2f5815de448f4b15c606e0527d38454ffaff1d7d5961ab59ca6f1cd37346
testSslRequestWithComponentKeystore
public void testSslRequestWithComponentKeystore() throws InterruptedException, IOException
{    Context context = new Context();    context.put("port", String.valueOf(selectedPort = getFreePort()));    context.put("bind", "0.0.0.0");    context.put("ssl", "true");    context.put("keystore", "src/test/resources/server.p12");    context.put("keystore-password", "password");    context.put("keystore-type", "PKCS12");    Configurables.configure(source, context);    doSslRequest();}
f406ac922185de79da2480a530d3022343bc81859e052cfa8e1dd240431a109d
testSslRequestWithGlobalKeystore
public void testSslRequestWithGlobalKeystore() throws InterruptedException, IOException
{    System.setProperty("javax.net.ssl.keyStore", "src/test/resources/server.p12");    System.setProperty("javax.net.ssl.keyStorePassword", "password");    System.setProperty("javax.net.ssl.keyStoreType", "PKCS12");    Context context = new Context();    context.put("port", String.valueOf(selectedPort = getFreePort()));    context.put("bind", "0.0.0.0");    context.put("ssl", "true");    Configurables.configure(source, context);    doSslRequest();    System.clearProperty("javax.net.ssl.keyStore");    System.clearProperty("javax.net.ssl.keyStorePassword");}
9fe2e1c3f2e3e22a4526b08fefe66c51f1a60af3af331b46c89d9e8dae3c0016
doSslRequest
private void doSslRequest() throws InterruptedException, IOException
{    source.start();    Assert.assertTrue("Reached start or error", LifecycleController.waitForOneOf(source, LifecycleState.START_OR_ERROR));    Assert.assertEquals("Server is started", LifecycleState.START, source.getLifecycleState());    AvroSourceProtocol client = SpecificRequestor.getClient(AvroSourceProtocol.class, new NettyTransceiver(new InetSocketAddress(selectedPort), new SSLChannelFactory()));    AvroFlumeEvent avroEvent = new AvroFlumeEvent();    avroEvent.setHeaders(new HashMap<CharSequence, CharSequence>());    avroEvent.setBody(ByteBuffer.wrap("Hello avro ssl".getBytes()));    Status status = client.append(avroEvent);    Assert.assertEquals(Status.OK, status);    Transaction transaction = channel.getTransaction();    transaction.begin();    Event event = channel.take();    Assert.assertNotNull(event);    Assert.assertEquals("Channel contained our event", "Hello avro ssl", new String(event.getBody()));    transaction.commit();    transaction.close();    logger.debug("Round trip event:{}", event);    source.stop();    Assert.assertTrue("Reached stop or error", LifecycleController.waitForOneOf(source, LifecycleState.STOP_OR_ERROR));    Assert.assertEquals("Server is stopped", LifecycleState.STOP, source.getLifecycleState());}
f1d152743f68a17edf485ca7b0b821c356590cf73312288f7adcb6c93907e077
newChannel
public SocketChannel newChannel(ChannelPipeline pipeline)
{    try {        SSLContext sslContext = SSLContext.getInstance("TLS");        sslContext.init(null, new TrustManager[] { new PermissiveTrustManager() }, null);        SSLEngine sslEngine = sslContext.createSSLEngine();        sslEngine.setUseClientMode(true);                        pipeline.addFirst("ssl", new SslHandler(sslEngine));        return super.newChannel(pipeline);    } catch (Exception ex) {        throw new RuntimeException("Cannot create SSL channel", ex);    }}
ff4e4a28c0a152e6e1627ea02e0bba88ca318bc15e775b9321ba555aa17a72e5
checkClientTrusted
public void checkClientTrusted(X509Certificate[] certs, String s)
{}
9c224c0159aa7449b31fb34da6b66aa554f1404356900809ff3fb435bc2ca415
checkServerTrusted
public void checkServerTrusted(X509Certificate[] certs, String s)
{}
b516c58bc22bde695ccdef782f17985d051ddc0b89329e35483cf2a3a576c7fe
getAcceptedIssuers
public X509Certificate[] getAcceptedIssuers()
{    return new X509Certificate[0];}
8dc3fceeb2e62dacef8ce71d0dfd12757e09abbac7703103d6ac860e44c1d6a4
testValidIpFilterAllows
public void testValidIpFilterAllows() throws InterruptedException, IOException
{    doIpFilterTest(localhost, "allow:name:localhost,deny:ip:*", true, false);    doIpFilterTest(localhost, "allow:ip:" + localhost.getHostAddress() + ",deny:ip:*", true, false);    doIpFilterTest(localhost, "allow:ip:*", true, false);    doIpFilterTest(localhost, "allow:ip:" + localhost.getHostAddress().substring(0, 3) + "*,deny:ip:*", true, false);    doIpFilterTest(localhost, "allow:ip:127.0.0.2,allow:ip:" + localhost.getHostAddress().substring(0, 3) + "*,deny:ip:*", true, false);    doIpFilterTest(localhost, "allow:name:localhost,deny:ip:*", true, true);    doIpFilterTest(localhost, "allow:ip:*", true, true);}
1c765b839cc28de6068fe4a26de196ce9f3dc301255111e5d30ab8ec30fdaef4
testValidIpFilterDenys
public void testValidIpFilterDenys() throws InterruptedException, IOException
{    doIpFilterTest(localhost, "deny:ip:*", false, false);    doIpFilterTest(localhost, "deny:name:localhost", false, false);    doIpFilterTest(localhost, "deny:ip:" + localhost.getHostAddress() + ",allow:ip:*", false, false);    doIpFilterTest(localhost, "deny:ip:*", false, false);    doIpFilterTest(localhost, "allow:ip:45.2.2.2,deny:ip:*", false, false);    doIpFilterTest(localhost, "deny:ip:" + localhost.getHostAddress().substring(0, 3) + "*,allow:ip:*", false, false);    doIpFilterTest(localhost, "deny:ip:*", false, true);}
2c6f5ad646ee8b7c2a0b5f0d15472ad850c74109e6e003a194bb3ba979bdb60b
testInvalidIpFilter
public void testInvalidIpFilter() throws InterruptedException, IOException
{    doIpFilterTest(localhost, "deny:ip:*", false, false);    doIpFilterTest(localhost, "allow:name:localhost", true, false);    doIpFilterTest(localhost, "deny:ip:127.0.0.2,allow:ip:*,deny:ip:" + localhost.getHostAddress(), true, false);    doIpFilterTest(localhost, "deny:ip:" + localhost.getHostAddress().substring(0, 3) + "*,allow:ip:*", false, false);        Consumer<Exception> exceptionChecker = (Exception ex) -> {        logger.info("Received an expected exception", ex);                Assert.assertTrue("Expected an ipFilterRules related exception", ex.getMessage().contains("ipFilter"));    };    try {        doIpFilterTest(localhost, null, false, false);        Assert.fail("The null ipFilterRules config should have thrown an exception.");    } catch (FlumeException e) {        exceptionChecker.accept(e);    }    try {        doIpFilterTest(localhost, "", true, false);        Assert.fail("The empty string ipFilterRules config should have thrown " + "an exception");    } catch (FlumeException e) {        exceptionChecker.accept(e);    }    try {        doIpFilterTest(localhost, "homer:ip:45.4.23.1", true, false);        Assert.fail("Bad ipFilterRules config should have thrown an exception.");    } catch (FlumeException e) {        exceptionChecker.accept(e);    }    try {        doIpFilterTest(localhost, "allow:sleeps:45.4.23.1", true, false);        Assert.fail("Bad ipFilterRules config should have thrown an exception.");    } catch (FlumeException e) {        exceptionChecker.accept(e);    }}
5b684276d9f7c417fcac77b7cb6a04c9b20a5e75db8546865b6448fc21e20d8b
doIpFilterTest
public void doIpFilterTest(InetAddress dest, String ruleDefinition, boolean eventShouldBeAllowed, boolean testWithSSL) throws InterruptedException, IOException
{    Context context = new Context();    context.put("port", String.valueOf(selectedPort = getFreePort()));    context.put("bind", "0.0.0.0");    context.put("ipFilter", "true");    if (ruleDefinition != null) {        context.put("ipFilterRules", ruleDefinition);    }    if (testWithSSL) {        logger.info("Client testWithSSL" + testWithSSL);        context.put("ssl", "true");        context.put("keystore", "src/test/resources/server.p12");        context.put("keystore-password", "password");        context.put("keystore-type", "PKCS12");    }        Configurables.configure(source, context);    source.start();    Assert.assertTrue("Reached start or error", LifecycleController.waitForOneOf(source, LifecycleState.START_OR_ERROR));    Assert.assertEquals("Server is started", LifecycleState.START, source.getLifecycleState());    AvroSourceProtocol client;    NettyTransceiver nettyTransceiver = null;    try {        if (testWithSSL) {            nettyTransceiver = new NettyTransceiver(new InetSocketAddress(dest, selectedPort), new SSLChannelFactory());            client = SpecificRequestor.getClient(AvroSourceProtocol.class, nettyTransceiver);        } else {            nettyTransceiver = new NettyTransceiver(new InetSocketAddress(dest, selectedPort));            client = SpecificRequestor.getClient(AvroSourceProtocol.class, nettyTransceiver);        }        AvroFlumeEvent avroEvent = new AvroFlumeEvent();        avroEvent.setHeaders(new HashMap<CharSequence, CharSequence>());        avroEvent.setBody(ByteBuffer.wrap("Hello avro ipFilter".getBytes()));        logger.info("Client about to append");        Status status = client.append(avroEvent);        logger.info("Client appended");        Assert.assertEquals(Status.OK, status);    } catch (IOException e) {        Assert.assertTrue("Should have been allowed: " + ruleDefinition, !eventShouldBeAllowed);        return;    } finally {        if (nettyTransceiver != null) {            nettyTransceiver.close();        }        source.stop();    }    Assert.assertTrue("Should have been denied: " + ruleDefinition, eventShouldBeAllowed);    Transaction transaction = channel.getTransaction();    transaction.begin();    Event event = channel.take();    Assert.assertNotNull(event);    Assert.assertEquals("Channel contained our event", "Hello avro ipFilter", new String(event.getBody()));    transaction.commit();    transaction.close();    logger.debug("Round trip event:{}", event);    Assert.assertTrue("Reached stop or error", LifecycleController.waitForOneOf(source, LifecycleState.STOP_OR_ERROR));    Assert.assertEquals("Server is stopped", LifecycleState.STOP, source.getLifecycleState());}
842ce523cd5b575230a4e53c3d57d7b83c10bc784cdf87d5c299626f97ef80e0
testErrorCounterChannelWriteFail
public void testErrorCounterChannelWriteFail() throws Exception
{    Context context = new Context();    context.put("port", String.valueOf(selectedPort = getFreePort()));    context.put("bind", "0.0.0.0");    source.configure(context);    ChannelProcessor cp = Mockito.mock(ChannelProcessor.class);    doThrow(new ChannelException("dummy")).when(cp).processEvent(any(Event.class));    doThrow(new ChannelException("dummy")).when(cp).processEventBatch(anyListOf(Event.class));    source.setChannelProcessor(cp);    source.start();    AvroFlumeEvent avroEvent = new AvroFlumeEvent();    avroEvent.setHeaders(new HashMap<CharSequence, CharSequence>());    avroEvent.setBody(ByteBuffer.wrap("Hello avro ssl".getBytes()));    source.append(avroEvent);    source.appendBatch(Arrays.asList(avroEvent));    SourceCounter sc = (SourceCounter) Whitebox.getInternalState(source, "sourceCounter");    Assert.assertEquals(2, sc.getChannelWriteFail());    source.stop();}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    context = new Context();    channelProcessor = mock(ChannelProcessor.class);}
cfe184dc99e231bcba8648e82f5943d48a5b88d7be86ec3f5dcd65a1ebc3ad78
spyAndConfigure
public DoNothingSource spyAndConfigure(DoNothingSource source)
{    source = spy(source);    source.setChannelProcessor(channelProcessor);    source.configure(context);    return source;}
205220e0636f4eb8f9e52af329308884e36f327533bedbd7dfb19f5c630fd4ba
testDoConfigureThrowsException
public void testDoConfigureThrowsException() throws Exception
{    source = spy(new DoNothingSource() {        @Override        protected void doConfigure(Context context) throws FlumeException {            throw new FlumeException("dummy");        }    });    source.setChannelProcessor(channelProcessor);    try {        source.configure(context);        Assert.fail();    } catch (FlumeException expected) {    }    Assert.assertFalse(source.isStarted());    Assert.assertEquals(LifecycleState.ERROR, source.getLifecycleState());    Assert.assertNotNull(source.getStartException());}
142257108f477bf2e124e1838bfbce41c0a617c37f4ee7c5e0f8eb9232c79477
doConfigure
protected void doConfigure(Context context) throws FlumeException
{    throw new FlumeException("dummy");}
65131af34befe60902d42155d826c459faf4b4e55b3ab72d994391d9d01c0f36
testDoStartThrowsException
public void testDoStartThrowsException() throws Exception
{    source = spyAndConfigure(new DoNothingSource() {        @Override        protected void doStart() throws FlumeException {            throw new FlumeException("dummy");        }    });    source.start();    Assert.assertFalse(source.isStarted());    Assert.assertEquals(LifecycleState.ERROR, source.getLifecycleState());    Assert.assertNotNull(source.getStartException());}
9dc3ff24bcdde4c0d9a8a91bf810de54f264a0f1ca17b695fea6381be65d7456
doStart
protected void doStart() throws FlumeException
{    throw new FlumeException("dummy");}
d3756a5592f61de33c882e5dbda56a15adbc3e08af530fe0cfb33eb221487f01
testDoStopThrowsException
public void testDoStopThrowsException() throws Exception
{    source = spyAndConfigure(new DoNothingSource() {        @Override        protected void doStop() throws FlumeException {            throw new FlumeException("dummy");        }    });    source.start();    source.stop();    Assert.assertFalse(source.isStarted());    Assert.assertEquals(LifecycleState.ERROR, source.getLifecycleState());    Assert.assertNull(source.getStartException());}
984404ddc9435f386a11b7a4633a4b527dc0cdb6ff0eb2dfeb17ad1c4907be8b
doStop
protected void doStop() throws FlumeException
{    throw new FlumeException("dummy");}
614298399b1fa2d869c9f68e9563c1f56b570da6c15d7ccf7c7fff3f0ba05faa
testConfigureCalledWhenStarted
public void testConfigureCalledWhenStarted() throws Exception
{    source = spyAndConfigure(new DoNothingSource());    source.start();    try {        source.configure(context);        Assert.fail();    } catch (IllegalStateException expected) {    }    Assert.assertTrue(source.isStarted());    Assert.assertNull(source.getStartException());}
142257108f477bf2e124e1838bfbce41c0a617c37f4ee7c5e0f8eb9232c79477
doConfigure
protected void doConfigure(Context context) throws FlumeException
{}
9dc3ff24bcdde4c0d9a8a91bf810de54f264a0f1ca17b695fea6381be65d7456
doStart
protected void doStart() throws FlumeException
{}
984404ddc9435f386a11b7a4633a4b527dc0cdb6ff0eb2dfeb17ad1c4907be8b
doStop
protected void doStop() throws FlumeException
{}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    sourceFactory = new DefaultSourceFactory();}
996e2858736461ad9d50dd3cec655ae7536aa8af28bf1878aa7a9e5d930fff25
testDuplicateCreate
public void testDuplicateCreate()
{    Source avroSource1 = sourceFactory.create("avroSource1", "avro");    Source avroSource2 = sourceFactory.create("avroSource2", "avro");    Assert.assertNotNull(avroSource1);    Assert.assertNotNull(avroSource2);    Assert.assertNotSame(avroSource1, avroSource2);    Assert.assertTrue(avroSource1 instanceof AvroSource);    Assert.assertTrue(avroSource2 instanceof AvroSource);    Source s1 = sourceFactory.create("avroSource1", "avro");    Source s2 = sourceFactory.create("avroSource2", "avro");    Assert.assertNotSame(avroSource1, s1);    Assert.assertNotSame(avroSource2, s2);}
19585d495419ef575ffb017a4ec49442e1ee0dc9e6ffabc07962b505c7b2cdcf
verifySourceCreation
private void verifySourceCreation(String name, String type, Class<?> typeClass) throws Exception
{    Source src = sourceFactory.create(name, type);    Assert.assertNotNull(src);    Assert.assertTrue(typeClass.isInstance(src));}
0c16acec32fcf80cd5a552f9ee650a164cc387b771ac9b4a070d7d60237efac3
testSourceCreation
public void testSourceCreation() throws Exception
{    verifySourceCreation("seq-src", "seq", SequenceGeneratorSource.class);    verifySourceCreation("netcat-src", "netcat", NetcatSource.class);    verifySourceCreation("netcat-udp-src", "netcatudp", NetcatUdpSource.class);    verifySourceCreation("exec-src", "exec", ExecSource.class);    verifySourceCreation("avro-src", "avro", AvroSource.class);    verifySourceCreation("syslogtcp-src", "syslogtcp", SyslogTcpSource.class);    verifySourceCreation("multiport_syslogtcp-src", "multiport_syslogtcp", MultiportSyslogTCPSource.class);    verifySourceCreation("syslogudp-src", "syslogudp", SyslogUDPSource.class);    verifySourceCreation("spooldir-src", "spooldir", SpoolDirectorySource.class);    verifySourceCreation("http-src", "http", HTTPSource.class);    verifySourceCreation("thrift-src", "thrift", ThriftSource.class);    verifySourceCreation("custom-src", MockSource.class.getCanonicalName(), MockSource.class);}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    context.put("keep-alive", "1");    context.put("capacity", "1000");    context.put("transactionCapacity", "1000");    Configurables.configure(channel, context);    rcs.setChannels(Lists.newArrayList(channel));    source = new ExecSource();    source.setChannelProcessor(new ChannelProcessor(rcs));}
39e5ba029cc67f6f1d45c6d20f0df595ec16bc61da20d7680fcbbdae4fe7f95b
tearDown
public void tearDown()
{    source.stop();        ObjectName objName = null;    try {        objName = new ObjectName("org.apache.flume.source" + ":type=" + source.getName());        ManagementFactory.getPlatformMBeanServer().unregisterMBean(objName);    } catch (Exception ex) {        System.out.println("Failed to unregister the monitored counter: " + objName + ex.getMessage());    }}
f17538cf17524fddaaf7d764d1faa55f1820043264b4da162ea8dbdd898a53be
testProcess
public void testProcess() throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{        File inputFile = File.createTempFile("input", null);    File ouputFile = File.createTempFile("ouput", null);    FileUtils.forceDeleteOnExit(inputFile);    FileUtils.forceDeleteOnExit(ouputFile);        FileOutputStream outputStream1 = new FileOutputStream(inputFile);    for (int i = 0; i < 10; i++) {        outputStream1.write(RandomStringUtils.randomAlphanumeric(200).getBytes());        outputStream1.write('\n');    }    outputStream1.close();    String command = SystemUtils.IS_OS_WINDOWS ? String.format("cmd /c type %s", inputFile.getAbsolutePath()) : String.format("cat %s", inputFile.getAbsolutePath());    context.put("command", command);    context.put("keep-alive", "1");    context.put("capacity", "1000");    context.put("transactionCapacity", "1000");    Configurables.configure(source, context);    source.start();    Thread.sleep(2000);    Transaction transaction = channel.getTransaction();    transaction.begin();    Event event;    FileOutputStream outputStream = new FileOutputStream(ouputFile);    while ((event = channel.take()) != null) {        outputStream.write(event.getBody());        outputStream.write('\n');    }    outputStream.close();    transaction.commit();    transaction.close();    Assert.assertEquals(FileUtils.checksumCRC32(inputFile), FileUtils.checksumCRC32(ouputFile));}
3bc0e42f02b819a1bc3e5af5be669e0468a27015232ee5d6affb5c704973480b
testShellCommandSimple
public void testShellCommandSimple() throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{    if (SystemUtils.IS_OS_WINDOWS) {        runTestShellCmdHelper("powershell -ExecutionPolicy Unrestricted -command", "1..5", new String[] { "1", "2", "3", "4", "5" });    } else {        runTestShellCmdHelper("/bin/bash -c", "seq 5", new String[] { "1", "2", "3", "4", "5" });    }}
be87495722a5021d6dd4d34a56a90790b542593052c69f9008a0e5b024b1062d
testShellCommandBackTicks
public void testShellCommandBackTicks() throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{        if (SystemUtils.IS_OS_WINDOWS) {        runTestShellCmdHelper("powershell -ExecutionPolicy Unrestricted -command", "$(1..5)", new String[] { "1", "2", "3", "4", "5" });    } else {        runTestShellCmdHelper("/bin/bash -c", "echo `seq 5`", new String[] { "1 2 3 4 5" });        runTestShellCmdHelper("/bin/bash -c", "echo $(seq 5)", new String[] { "1 2 3 4 5" });    }}
364557ad129f828f7c81209a097de9f6e45b1bf6bd1387af9b2dd7df25c58e0b
testShellCommandComplex
public void testShellCommandComplex() throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{        String[] expected = { "1234", "abcd", "ijk", "xyz", "zzz" };        if (SystemUtils.IS_OS_WINDOWS) {        runTestShellCmdHelper("powershell -ExecutionPolicy Unrestricted -command", "'zzz','1234','xyz','abcd','ijk' | sort", expected);    } else {        runTestShellCmdHelper("/bin/bash -c", "echo zzz 1234 xyz abcd ijk | xargs -n1 echo | sort -f", expected);    }}
2411952c0d90b58dd0cd1db273d0a6668634f6254845841dd7b34c04c9bfcf1d
testShellCommandScript
public void testShellCommandScript() throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{        if (SystemUtils.IS_OS_WINDOWS) {        runTestShellCmdHelper("powershell -ExecutionPolicy Unrestricted -command", "foreach ($i in 1..5) { $i }", new String[] { "1", "2", "3", "4", "5" });                runTestShellCmdHelper("powershell -ExecutionPolicy Unrestricted -command", "if(2+2 -gt 3) { 'good' } else { 'not good' } ", new String[] { "good" });    } else {        runTestShellCmdHelper("/bin/bash -c", "for i in {1..5}; do echo $i;done", new String[] { "1", "2", "3", "4", "5" });                runTestShellCmdHelper("/bin/bash -c", "if ((2+2>3)); " + "then  echo good; else echo not good; fi", new String[] { "good" });    }}
206531cbefb4ad533eefe0527a4bc4dd54036c302702b98da761d884ae6fd521
testShellCommandEmbeddingAndEscaping
public void testShellCommandEmbeddingAndEscaping() throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{        String fileName = SystemUtils.IS_OS_WINDOWS ? "src\\test\\resources\\test_command.ps1" : "src/test/resources/test_command.txt";    BufferedReader reader = new BufferedReader(new FileReader(fileName));    try {        String shell = SystemUtils.IS_OS_WINDOWS ? "powershell -ExecutionPolicy Unrestricted -command" : "/bin/bash -c";        String command1 = reader.readLine();        Assert.assertNotNull(command1);        String[] output1 = new String[] { "'1'", "\"2\"", "\\3", "\\4" };        runTestShellCmdHelper(shell, command1, output1);        String command2 = reader.readLine();        Assert.assertNotNull(command2);        String[] output2 = new String[] { "1", "2", "3", "4", "5" };        runTestShellCmdHelper(shell, command2, output2);        String command3 = reader.readLine();        Assert.assertNotNull(command3);        String[] output3 = new String[] { "2", "3", "4", "5", "6" };        runTestShellCmdHelper(shell, command3, output3);    } finally {        reader.close();    }}
64048dcfab2bda163f99b8df1d28bc497cb9565c02bdc794a24d05f5731ce361
testMonitoredCounterGroup
public void testMonitoredCounterGroup() throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{        if (SystemUtils.IS_OS_WINDOWS) {        runTestShellCmdHelper("powershell -ExecutionPolicy Unrestricted -command", "foreach ($i in 1..5) { $i }", new String[] { "1", "2", "3", "4", "5" });    } else {        runTestShellCmdHelper("/bin/bash -c", "for i in {1..5}; do echo $i;done", new String[] { "1", "2", "3", "4", "5" });    }    ObjectName objName = null;    try {        objName = new ObjectName("org.apache.flume.source" + ":type=" + source.getName());        MBeanServer mbeanServer = ManagementFactory.getPlatformMBeanServer();        String[] strAtts = { "Type", "EventReceivedCount", "EventAcceptedCount" };        AttributeList attrList = mbeanServer.getAttributes(objName, strAtts);        Assert.assertNotNull(attrList.get(0));        Assert.assertEquals("Expected Value: Type", "Type", ((Attribute) attrList.get(0)).getName());        Assert.assertEquals("Expected Value: SOURCE", "SOURCE", ((Attribute) attrList.get(0)).getValue());        Assert.assertNotNull(attrList.get(1));        Assert.assertEquals("Expected Value: EventReceivedCount", "EventReceivedCount", ((Attribute) attrList.get(1)).getName());        Assert.assertEquals("Expected Value: 5", "5", ((Attribute) attrList.get(1)).getValue().toString());        Assert.assertNotNull(attrList.get(2));        Assert.assertEquals("Expected Value: EventAcceptedCount", "EventAcceptedCount", ((Attribute) attrList.get(2)).getName());        Assert.assertEquals("Expected Value: 5", "5", ((Attribute) attrList.get(2)).getValue().toString());    } catch (Exception ex) {        System.out.println("Unable to retreive the monitored counter: " + objName + ex.getMessage());    }}
a1a991fcb30b63575c23ed39420b8664382d87d7cbbfd0e8b535656763044062
testBatchTimeout
public void testBatchTimeout() throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{    String filePath = "/tmp/flume-execsource." + Thread.currentThread().getId();    String eventBody = "TestMessage";    FileOutputStream outputStream = new FileOutputStream(filePath);    context.put(ExecSourceConfigurationConstants.CONFIG_BATCH_SIZE, "50000");    context.put(ExecSourceConfigurationConstants.CONFIG_BATCH_TIME_OUT, "750");    context.put("shell", SystemUtils.IS_OS_WINDOWS ? "powershell -ExecutionPolicy Unrestricted -command" : "/bin/bash -c");    context.put("command", SystemUtils.IS_OS_WINDOWS ? "Get-Content " + filePath + " | Select-Object -Last 10" : ("tail -f " + filePath));    Configurables.configure(source, context);    source.start();    Transaction transaction = channel.getTransaction();    transaction.begin();    for (int lineNumber = 0; lineNumber < 3; lineNumber++) {        outputStream.write((eventBody).getBytes());        outputStream.write(String.valueOf(lineNumber).getBytes());        outputStream.write('\n');        outputStream.flush();    }    outputStream.close();    Thread.sleep(1500);    for (int i = 0; i < 3; i++) {        Event event = channel.take();        assertNotNull(event);        assertNotNull(event.getBody());        assertEquals(eventBody + String.valueOf(i), new String(event.getBody()));    }    transaction.commit();    transaction.close();    source.stop();    File file = new File(filePath);    FileUtils.forceDelete(file);}
190bb2ba50d8ea6af721d3639b1964ae423b0f1806a9d4753d4f8cc78d5195f5
runTestShellCmdHelper
private void runTestShellCmdHelper(String shell, String command, String[] expectedOutput) throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{    context.put("shell", shell);    context.put("command", command);    Configurables.configure(source, context);    source.start();            Thread.sleep(2500);    Transaction transaction = channel.getTransaction();    transaction.begin();    try {        List<String> output = Lists.newArrayList();        Event event;        while ((event = channel.take()) != null) {            output.add(new String(event.getBody(), Charset.defaultCharset()));        }        transaction.commit();        Assert.assertArrayEquals(expectedOutput, output.toArray(new String[] {}));    } finally {        transaction.close();        source.stop();    }}
5cfd8acd54c5e73106f2c383b6c2ea96b144e829ab00b20f1d162d18df12f002
testRestart
public void testRestart() throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{    context.put(ExecSourceConfigurationConstants.CONFIG_RESTART_THROTTLE, "10");    context.put(ExecSourceConfigurationConstants.CONFIG_RESTART, "true");    context.put("command", SystemUtils.IS_OS_WINDOWS ? "cmd /c echo flume" : "echo flume");    Configurables.configure(source, context);    source.start();    Transaction transaction = channel.getTransaction();    transaction.begin();    long start = System.currentTimeMillis();    for (int i = 0; i < 5; i++) {        Event event = channel.take();        assertNotNull(event);        assertNotNull(event.getBody());        assertEquals("flume", new String(event.getBody(), Charsets.UTF_8));    }        assertTrue(System.currentTimeMillis() - start < 10000L);    transaction.commit();    transaction.close();    source.stop();}
659b4ca410a3c5e577ee7b133a343a7ff41a06e4bca46289075d3f4c02f9e208
testShutdown
public void testShutdown() throws Exception
{        int seconds = 272;        boolean searchForCommand = true;    while (searchForCommand) {        searchForCommand = false;        String command = SystemUtils.IS_OS_WINDOWS ? "cmd /c sleep " + seconds : "sleep " + seconds;        String searchTxt = SystemUtils.IS_OS_WINDOWS ? "sleep.exe" : "\b" + command + "\b";        Pattern pattern = Pattern.compile(searchTxt);        for (String line : exec(SystemUtils.IS_OS_WINDOWS ? "cmd /c tasklist /FI \"SESSIONNAME eq Console\"" : "ps -ef")) {            if (pattern.matcher(line).find()) {                seconds++;                searchForCommand = true;                break;            }        }    }            String command = "sleep " + seconds;    Pattern pattern = Pattern.compile("\b" + command + "\b");    context.put(ExecSourceConfigurationConstants.CONFIG_RESTART, "false");    context.put("command", command);    Configurables.configure(source, context);    source.start();    Thread.sleep(1000L);    source.stop();    Thread.sleep(1000L);    for (String line : exec(SystemUtils.IS_OS_WINDOWS ? "cmd /c tasklist /FI \"SESSIONNAME eq Console\"" : "ps -ef")) {        if (pattern.matcher(line).find()) {            Assert.fail("Found [" + line + "]");        }    }}
3b8f87ba5ebc9e11629ada639f2fe0a3b7a6235a22758e9a7fb9fe84c4edb1d8
exec
private static List<String> exec(String command) throws Exception
{    String[] commandArgs = command.split("\\s+");    Process process = new ProcessBuilder(commandArgs).start();    BufferedReader reader = null;    try {        reader = new BufferedReader(new InputStreamReader(process.getInputStream()));        List<String> result = Lists.newArrayList();        String line;        while ((line = reader.readLine()) != null) {            result.add(line);        }        return result;    } finally {        process.destroy();        if (reader != null) {            reader.close();        }        int exit = process.waitFor();        if (exit != 0) {            throw new IllegalStateException("Command [" + command + "] exited with " + exit);        }    }}
aff5bf0e76532d5598332a2e57bd7177aabc5c4191bdcbb00f97a816aa025c08
getFreePort
private static final int getFreePort() throws IOException
{    try (ServerSocket socket = new ServerSocket(0)) {        return socket.getLocalPort();    }}
cec60905e6695066cea87079028df977c91a6bd12995741f570ef8a4d11189f4
getEvent
private byte[] getEvent(int counter)
{        String msg1 = "<10>" + stamp1 + " " + host1 + " " + data1 + " " + String.valueOf(counter) + "\n";    return msg1.getBytes();}
b4a00c06bb3ef36aa9ffa6edef160491b009e0dc14572acc35ca81dbd9d065b6
testNPorts
private List<Integer> testNPorts(MultiportSyslogTCPSource source, Channel channel, List<Event> channelEvents, int numPorts, ChannelProcessor channelProcessor, BiConsumer<Integer, byte[]> eventSenderFuncton, Context additionalContext) throws IOException
{    Context channelContext = new Context();    channelContext.put("capacity", String.valueOf(2000));    channelContext.put("transactionCapacity", String.valueOf(2000));    Configurables.configure(channel, channelContext);    if (channelProcessor == null) {        List<Channel> channels = Lists.newArrayList();        channels.add(channel);        ChannelSelector rcs = new ReplicatingChannelSelector();        rcs.setChannels(channels);        source.setChannelProcessor(new ChannelProcessor(rcs));    } else {        source.setChannelProcessor(channelProcessor);    }    List<Integer> portList = new ArrayList<>(numPorts);    while (portList.size() < numPorts) {        int port = getFreePort();        if (!portList.contains(port)) {            portList.add(port);        }    }    StringBuilder ports = new StringBuilder();    for (int i = 0; i < numPorts; i++) {        ports.append(String.valueOf(portList.get(i))).append(" ");    }    Context context = new Context();    context.put(SyslogSourceConfigurationConstants.CONFIG_PORTS, ports.toString().trim());    context.put("portHeader", "port");    context.putAll(additionalContext.getParameters());    source.configure(context);    source.start();    for (int i = 0; i < numPorts; i++) {        eventSenderFuncton.accept(portList.get(i), getEvent(i));    }    Transaction txn = channel.getTransaction();    txn.begin();    for (int i = 0; i < numPorts; i++) {        Event e = channel.take();        if (e == null) {            throw new NullPointerException("Event is null");        }        channelEvents.add(e);    }    try {        txn.commit();    } catch (Throwable t) {        txn.rollback();    } finally {        txn.close();    }    return portList;}
d4896a3a3d90880756e898d2693a138d03863f07709bcf3405c7c69c8bbf928f
testMultiplePorts
public void testMultiplePorts() throws IOException, ParseException
{    MultiportSyslogTCPSource source = new MultiportSyslogTCPSource();    Channel channel = new MemoryChannel();    List<Event> channelEvents = new ArrayList<>();    int numPorts = 1000;    List<Integer> portList = testNPorts(source, channel, channelEvents, numPorts, null, getSimpleEventSender(), new Context());        processEvents(channelEvents, numPorts, portList);    source.stop();}
9262d703df8ef58c82eb9388d19a0426849106074df8bf64710ff75702cf71bd
testMultiplePortsSSL
public void testMultiplePortsSSL() throws Exception
{    SSLContext sslContext = SSLContext.getInstance("TLS");    sslContext.init(null, new TrustManager[] { new X509TrustManager() {        @Override        public void checkClientTrusted(X509Certificate[] certs, String s) {                }        @Override        public void checkServerTrusted(X509Certificate[] certs, String s) {                }        @Override        public X509Certificate[] getAcceptedIssuers() {            return new X509Certificate[0];        }    } }, null);    SocketFactory socketFactory = sslContext.getSocketFactory();    Context context = new Context();    context.put("ssl", "true");    context.put("keystore", "src/test/resources/server.p12");    context.put("keystore-password", "password");    context.put("keystore-type", "PKCS12");    MultiportSyslogTCPSource source = new MultiportSyslogTCPSource();    Channel channel = new MemoryChannel();    List<Event> channelEvents = new ArrayList<>();    int numPorts = 10;    List<Integer> portList = testNPorts(source, channel, channelEvents, numPorts, null, getSSLEventSender(socketFactory), context);        processEvents(channelEvents, numPorts, portList);    source.stop();}
ff4e4a28c0a152e6e1627ea02e0bba88ca318bc15e775b9321ba555aa17a72e5
checkClientTrusted
public void checkClientTrusted(X509Certificate[] certs, String s)
{}
9c224c0159aa7449b31fb34da6b66aa554f1404356900809ff3fb435bc2ca415
checkServerTrusted
public void checkServerTrusted(X509Certificate[] certs, String s)
{}
b516c58bc22bde695ccdef782f17985d051ddc0b89329e35483cf2a3a576c7fe
getAcceptedIssuers
public X509Certificate[] getAcceptedIssuers()
{    return new X509Certificate[0];}
e69d82c77597585a18d1f4b3677803b3311379551691f7f3ce7d773a8cfbeab7
getSSLEventSender
private BiConsumer<Integer, byte[]> getSSLEventSender(SocketFactory socketFactory)
{    return (port, event) -> {        try {            Socket syslogSocket = socketFactory.createSocket(InetAddress.getLocalHost(), port);            syslogSocket.getOutputStream().write(event);            syslogSocket.close();        } catch (Exception e) {            e.printStackTrace();        }    };}
d18b310396839414b39b80428f7f70e9e38f5fe7dd929d098d86e3fb66906120
getSimpleEventSender
private BiConsumer<Integer, byte[]> getSimpleEventSender()
{    return (Integer port, byte[] event) -> {        try {            Socket syslogSocket = new Socket(InetAddress.getLocalHost(), port);            syslogSocket.getOutputStream().write(event);            syslogSocket.close();        } catch (IOException e) {            e.printStackTrace();        }    };}
c8645ec5912a31f49b30524b21e220404a2fb0b2e7aa02a879dc152590c8723b
processEvents
private void processEvents(List<Event> channelEvents, int numPorts, List<Integer> portList)
{    for (int i = 0; i < numPorts; i++) {        Iterator<Event> iter = channelEvents.iterator();        while (iter.hasNext()) {            Event e = iter.next();            Map<String, String> headers = e.getHeaders();                        Integer port = null;            if (headers.containsKey("port")) {                port = Integer.parseInt(headers.get("port"));            }            iter.remove();            Assert.assertEquals("Timestamps must match", String.valueOf(time.getMillis()), headers.get("timestamp"));            String host2 = headers.get("host");            Assert.assertEquals(host1, host2);            if (port != null) {                int num = portList.indexOf(port);                Assert.assertEquals(data1 + " " + String.valueOf(num), new String(e.getBody()));            }        }    }}
91c661285103556a3173a7cb7ad1b1180035407f88b0a10b9f35823e3960dba3
testFragmented
public void testFragmented() throws CharacterCodingException
{    final int maxLen = 100;    IoBuffer savedBuf = IoBuffer.allocate(maxLen);    String origMsg = "<1>- - blah blam foo\n";    IoBuffer buf1 = IoBuffer.wrap(origMsg.substring(0, 11).getBytes(Charsets.UTF_8));    IoBuffer buf2 = IoBuffer.wrap(origMsg.substring(11, 16).getBytes(Charsets.UTF_8));    IoBuffer buf3 = IoBuffer.wrap(origMsg.substring(16, 21).getBytes(Charsets.UTF_8));    LineSplitter lineSplitter = new LineSplitter(maxLen);    ParsedBuffer parsedLine = new ParsedBuffer();    Assert.assertFalse("Incomplete line should not be parsed", lineSplitter.parseLine(buf1, savedBuf, parsedLine));    Assert.assertFalse("Incomplete line should not be parsed", lineSplitter.parseLine(buf2, savedBuf, parsedLine));    Assert.assertTrue("Completed line should be parsed", lineSplitter.parseLine(buf3, savedBuf, parsedLine));        Assert.assertEquals(origMsg.trim(), parsedLine.buffer.getString(Charsets.UTF_8.newDecoder()));    parsedLine.buffer.rewind();    MultiportSyslogHandler handler = new MultiportSyslogHandler(maxLen, 100, null, null, null, null, null, new ThreadSafeDecoder(Charsets.UTF_8), new ConcurrentHashMap<Integer, ThreadSafeDecoder>(), null);    Event event = handler.parseEvent(parsedLine, Charsets.UTF_8.newDecoder());    String body = new String(event.getBody(), Charsets.UTF_8);    Assert.assertEquals("Event body incorrect", origMsg.trim().substring(7), body);}
5166ef0bde1a0610a2dd7e72cacaa8231d7bc42e46e1684650516e9cf24c0ffa
testCharsetParsing
public void testCharsetParsing() throws FileNotFoundException, IOException
{    String header = "<10>2012-08-11T01:01:01Z localhost ";    String enBody = "Yarf yarf yarf";    String enMsg = header + enBody;    String frBody = "Comment " + "\u00EA" + "tes-vous?";    String frMsg = header + frBody;    String esBody = "¿Cómo estás?";    String esMsg = header + esBody;        MultiportSyslogHandler handler = new MultiportSyslogHandler(1000, 10, new ChannelProcessor(new ReplicatingChannelSelector()), new SourceCounter("test"), null, null, null, new ThreadSafeDecoder(Charsets.UTF_8), new ConcurrentHashMap<Integer, ThreadSafeDecoder>(), null);    ParsedBuffer parsedBuf = new ParsedBuffer();    parsedBuf.incomplete = false;        String[] bodies = { enBody, esBody, frBody };    String[] msgs = { enMsg, esMsg, frMsg };    Charset[] charsets = { Charsets.UTF_8, Charsets.ISO_8859_1 };    for (Charset charset : charsets) {        for (int i = 0; i < msgs.length; i++) {            String msg = msgs[i];            String body = bodies[i];            parsedBuf.buffer = IoBuffer.wrap(msg.getBytes(charset));            Event evt = handler.parseEvent(parsedBuf, charset.newDecoder());            String result = new String(evt.getBody(), charset);                        Assert.assertEquals(charset + " parse error: " + msg, body, result);            Assert.assertNull(evt.getHeaders().get(SyslogUtils.EVENT_STATUS));        }    }            byte[] badUtf8Seq = enMsg.getBytes(Charsets.ISO_8859_1);    int badMsgLen = badUtf8Seq.length;        badUtf8Seq[badMsgLen - 2] = (byte) 0xFE;        badUtf8Seq[badMsgLen - 1] = (byte) 0xFF;    parsedBuf.buffer = IoBuffer.wrap(badUtf8Seq);    Event evt = handler.parseEvent(parsedBuf, Charsets.UTF_8.newDecoder());    Assert.assertEquals("event body: " + new String(evt.getBody(), Charsets.ISO_8859_1) + " and my default charset = " + Charset.defaultCharset() + " with event = " + evt, SyslogUtils.SyslogStatus.INVALID.getSyslogStatus(), evt.getHeaders().get(SyslogUtils.EVENT_STATUS));    Assert.assertArrayEquals("Raw message data should be kept in body of event", badUtf8Seq, evt.getBody());    SourceCounter sc = (SourceCounter) Whitebox.getInternalState(handler, "sourceCounter");    Assert.assertEquals(1, sc.getEventReadFail());}
38b1cf4309ee72c44e2f333d46660b6a62cd6491267827e3205fc155ea3c81f8
testHandlerGenericFail
public void testHandlerGenericFail() throws Exception
{        MultiportSyslogHandler handler = new MultiportSyslogHandler(1000, 10, new ChannelProcessor(new ReplicatingChannelSelector()), new SourceCounter("test"), null, null, null, new ThreadSafeDecoder(Charsets.UTF_8), new ConcurrentHashMap<Integer, ThreadSafeDecoder>(), null);    handler.exceptionCaught(null, new RuntimeException("dummy"));    SourceCounter sc = (SourceCounter) Whitebox.getInternalState(handler, "sourceCounter");    Assert.assertEquals(1, sc.getGenericProcessingFail());}
b991f33701feeba848476644a63557bc7f5fa218836b6c730c754360568f6577
takeEvent
private static Event takeEvent(Channel channel)
{    Transaction txn = channel.getTransaction();    txn.begin();    Event evt = channel.take();    txn.commit();    txn.close();    return evt;}
47c3436d94badb1d51000226b6a0b51428032f5b57e763121941b4dca59f607f
testPortCharsetHandling
public void testPortCharsetHandling() throws UnknownHostException, Exception
{            InetAddress localAddr = InetAddress.getLocalHost();    DefaultIoSessionDataStructureFactory dsFactory = new DefaultIoSessionDataStructureFactory();        int port1 = 10001;    NioSession session1 = mock(NioSession.class);    session1.setAttributeMap(dsFactory.getAttributeMap(session1));    SocketAddress sockAddr1 = new InetSocketAddress(localAddr, port1);    when(session1.getLocalAddress()).thenReturn(sockAddr1);        int port2 = 10002;    NioSession session2 = mock(NioSession.class);    session2.setAttributeMap(dsFactory.getAttributeMap(session2));    SocketAddress sockAddr2 = new InetSocketAddress(localAddr, port2);    when(session2.getLocalAddress()).thenReturn(sockAddr2);        ConcurrentMap<Integer, ThreadSafeDecoder> portCharsets = new ConcurrentHashMap<Integer, ThreadSafeDecoder>();    portCharsets.put(port1, new ThreadSafeDecoder(Charsets.ISO_8859_1));    portCharsets.put(port2, new ThreadSafeDecoder(Charsets.UTF_8));                MemoryChannel chan = new MemoryChannel();    chan.configure(new Context());    chan.start();    ReplicatingChannelSelector sel = new ReplicatingChannelSelector();    sel.setChannels(Lists.<Channel>newArrayList(chan));    ChannelProcessor chanProc = new ChannelProcessor(sel);        MultiportSyslogHandler handler = new MultiportSyslogHandler(1000, 10, chanProc, new SourceCounter("test"), null, null, null, new ThreadSafeDecoder(Charsets.UTF_8), portCharsets, null);        handler.sessionCreated(session1);    handler.sessionCreated(session2);                String header = "<10>2012-08-17T02:14:00-07:00 192.168.1.110 ";        String dangerousChars = "þÿÀÁ";            String msg;    IoBuffer buf;    Event evt;        msg = header + dangerousChars + "\n";    buf = IoBuffer.wrap(msg.getBytes(Charsets.ISO_8859_1));    handler.messageReceived(session1, buf);    evt = takeEvent(chan);    Assert.assertNotNull("Event vanished!", evt);    Assert.assertNull(evt.getHeaders().get(SyslogUtils.EVENT_STATUS));        msg = header + dangerousChars + "\n";    buf = IoBuffer.wrap(msg.getBytes(Charsets.ISO_8859_1));    handler.messageReceived(session2, buf);    evt = takeEvent(chan);    Assert.assertNotNull("Event vanished!", evt);    Assert.assertEquals("Expected invalid event due to character encoding", SyslogUtils.SyslogStatus.INVALID.getSyslogStatus(), evt.getHeaders().get(SyslogUtils.EVENT_STATUS));        msg = header + dangerousChars + "\n";    buf = IoBuffer.wrap(msg.getBytes(Charsets.UTF_8));    handler.messageReceived(session2, buf);    evt = takeEvent(chan);    Assert.assertNotNull("Event vanished!", evt);    Assert.assertNull(evt.getHeaders().get(SyslogUtils.EVENT_STATUS));    SourceCounter sc = (SourceCounter) Whitebox.getInternalState(handler, "sourceCounter");    Assert.assertEquals(1, sc.getEventReadFail());}
842ce523cd5b575230a4e53c3d57d7b83c10bc784cdf87d5c299626f97ef80e0
testErrorCounterChannelWriteFail
public void testErrorCounterChannelWriteFail() throws Exception
{    MultiportSyslogTCPSource source = new MultiportSyslogTCPSource();    Channel channel = new MemoryChannel();    List<Event> channelEvents = new ArrayList<>();    ChannelProcessor cp = Mockito.mock(ChannelProcessor.class);    doThrow(new ChannelException("dummy")).doNothing().when(cp).processEventBatch(anyListOf(Event.class));    try {        testNPorts(source, channel, channelEvents, 1, cp, getSimpleEventSender(), new Context());    } catch (Exception e) {        }    SourceCounter sc = (SourceCounter) Whitebox.getInternalState(source, "sourceCounter");    Assert.assertEquals(1, sc.getChannelWriteFail());    source.stop();}
912c4f3aed86518d1c1e02d8712fe9360a78728cb5dee11a737ebaa1e16aeb2d
testClientHeaders
public void testClientHeaders() throws IOException
{    String testClientIPHeader = "testClientIPHeader";    String testClientHostnameHeader = "testClientHostnameHeader";    MultiportSyslogTCPSource source = new MultiportSyslogTCPSource();    Channel channel = new MemoryChannel();    Configurables.configure(channel, new Context());    List<Channel> channels = Lists.newArrayList();    channels.add(channel);    ChannelSelector rcs = new ReplicatingChannelSelector();    rcs.setChannels(channels);    source.setChannelProcessor(new ChannelProcessor(rcs));    int port = getFreePort();    Context context = new Context();    context.put("host", InetAddress.getLoopbackAddress().getHostAddress());    context.put("ports", String.valueOf(port));    context.put("clientIPHeader", testClientIPHeader);    context.put("clientHostnameHeader", testClientHostnameHeader);    source.configure(context);    source.start();        Socket syslogSocket = new Socket(InetAddress.getLoopbackAddress().getHostAddress(), port);    syslogSocket.getOutputStream().write(getEvent(0));    Event e = takeEvent(channel);    source.stop();    Map<String, String> headers = e.getHeaders();    checkHeader(headers, testClientIPHeader, InetAddress.getLoopbackAddress().getHostAddress());    checkHeader(headers, testClientHostnameHeader, InetAddress.getLoopbackAddress().getHostName());}
a44f581323789d5e69d5381e5cad2b6a38afa08520b5904004e2fd1567cba8f2
checkHeader
private static void checkHeader(Map<String, String> headers, String headerName, String expectedValue)
{    assertTrue("Missing event header: " + headerName, headers.containsKey(headerName));    assertEquals("Event header value does not match: " + headerName, expectedValue, headers.get(headerName));}
20a0d20db92e539dc6a5a11f49c6117d2a5157536305ee4a7e3d51c0b1ded528
getFreePort
private static int getFreePort()
{    try (ServerSocket socket = new ServerSocket(0)) {        return socket.getLocalPort();    } catch (IOException e) {        throw new AssertionError("Can not find free port.", e);    }}
74d341ac3879e68bf7d657a8391efe94bd29383b59d592d2c30ac58506567148
setUp
public void setUp() throws UnknownHostException
{    localhost = InetAddress.getByName("127.0.0.1");    source = new NetcatSource();    channel = new MemoryChannel();    Configurables.configure(channel, new Context());    List<Channel> channels = new ArrayList<Channel>();    channels.add(channel);    ChannelSelector rcs = new ReplicatingChannelSelector();    rcs.setChannels(channels);    source.setChannelProcessor(new ChannelProcessor(rcs));}
5e85f5d173b8a153a127f935e4d28ccc79e22b52fe822aef03b31102571f6c6c
testUTF16BEencoding
public void testUTF16BEencoding() throws InterruptedException, IOException
{    String encoding = "UTF-16BE";    startSource(encoding, "false", "1", "512");    Socket netcatSocket = new Socket(localhost, selectedPort);    try {                for (int i = 0; i < 20; i++) {            sendEvent(netcatSocket, english, encoding);            Assert.assertArrayEquals("Channel contained our event", english.getBytes(defaultCharset), getFlumeEvent());        }                for (int i = 0; i < 20; i++) {            sendEvent(netcatSocket, french, encoding);            Assert.assertArrayEquals("Channel contained our event", french.getBytes(defaultCharset), getFlumeEvent());        }    } finally {        netcatSocket.close();        stopSource();    }}
dc247e6543a9b5fc20ca4f72129f0fa14143db9a70b83fe777fbb89cbfedcf6f
testUTF16LEencoding
public void testUTF16LEencoding() throws InterruptedException, IOException
{    String encoding = "UTF-16LE";    startSource(encoding, "false", "1", "512");    Socket netcatSocket = new Socket(localhost, selectedPort);    try {                for (int i = 0; i < 20; i++) {            sendEvent(netcatSocket, english, encoding);            Assert.assertArrayEquals("Channel contained our event", english.getBytes(defaultCharset), getFlumeEvent());        }                for (int i = 0; i < 20; i++) {            sendEvent(netcatSocket, french, encoding);            Assert.assertArrayEquals("Channel contained our event", french.getBytes(defaultCharset), getFlumeEvent());        }    } finally {        netcatSocket.close();        stopSource();    }}
84a54c1b62ce8145768d40cd91d3875508b7fbc60f7c30bc3a15c4f75d734c2d
testUTF8encoding
public void testUTF8encoding() throws InterruptedException, IOException
{    String encoding = "UTF-8";    startSource(encoding, "false", "1", "512");    Socket netcatSocket = new Socket(localhost, selectedPort);    try {                for (int i = 0; i < 20; i++) {            sendEvent(netcatSocket, english, encoding);            Assert.assertArrayEquals("Channel contained our event", english.getBytes(defaultCharset), getFlumeEvent());        }                for (int i = 0; i < 20; i++) {            sendEvent(netcatSocket, french, encoding);            Assert.assertArrayEquals("Channel contained our event", french.getBytes(defaultCharset), getFlumeEvent());        }    } finally {        netcatSocket.close();        stopSource();    }}
0dc9be2653a322a50d3b372f46cacea59c89b2ecefce0d9dad00534ad57b3321
testIS88591encoding
public void testIS88591encoding() throws InterruptedException, IOException
{    String encoding = "ISO-8859-1";    startSource(encoding, "false", "1", "512");    Socket netcatSocket = new Socket(localhost, selectedPort);    try {                for (int i = 0; i < 20; i++) {            sendEvent(netcatSocket, english, encoding);            Assert.assertArrayEquals("Channel contained our event", english.getBytes(defaultCharset), getFlumeEvent());        }                for (int i = 0; i < 20; i++) {            sendEvent(netcatSocket, french, encoding);            Assert.assertArrayEquals("Channel contained our event", french.getBytes(defaultCharset), getFlumeEvent());        }    } finally {        netcatSocket.close();        stopSource();    }}
bef2ce1daec3e036afd558a67a21331f18d46629315e977a4378af5bb8dd16e5
testAck
public void testAck() throws InterruptedException, IOException
{    String encoding = "UTF-8";    String ackEvent = "OK";    startSource(encoding, "true", "1", "512");    Socket netcatSocket = new Socket(localhost, selectedPort);    LineIterator inputLineIterator = IOUtils.lineIterator(netcatSocket.getInputStream(), encoding);    try {                for (int i = 0; i < 20; i++) {            sendEvent(netcatSocket, english, encoding);            Assert.assertArrayEquals("Channel contained our event", english.getBytes(defaultCharset), getFlumeEvent());            Assert.assertEquals("Socket contained the Ack", ackEvent, inputLineIterator.nextLine());        }                for (int i = 0; i < 20; i++) {            sendEvent(netcatSocket, french, encoding);            Assert.assertArrayEquals("Channel contained our event", french.getBytes(defaultCharset), getFlumeEvent());            Assert.assertEquals("Socket contained the Ack", ackEvent, inputLineIterator.nextLine());        }    } finally {        netcatSocket.close();        stopSource();    }}
4d3da8d0bc593bcc1dc7636730d027e598d2419e8d3d54de3260e3371096342f
testMaxLineLength
public void testMaxLineLength() throws InterruptedException, IOException
{    String encoding = "UTF-8";    startSource(encoding, "false", "1", "10");    Socket netcatSocket = new Socket(localhost, selectedPort);    try {        sendEvent(netcatSocket, "123456789", encoding);        Assert.assertArrayEquals("Channel contained our event", "123456789".getBytes(defaultCharset), getFlumeEvent());        sendEvent(netcatSocket, english, encoding);        Assert.assertEquals("Channel does not contain an event", null, getRawFlumeEvent());    } finally {        netcatSocket.close();        stopSource();    }}
3154b2ac2f73511b9d4b49c6f057f879f23fd3ff013fe30d1e42cd9f1ac5ac2a
testMaxLineLengthwithAck
public void testMaxLineLengthwithAck() throws InterruptedException, IOException
{    String encoding = "UTF-8";    String ackEvent = "OK";    String ackErrorEvent = "FAILED: Event exceeds the maximum length (10 chars, including newline)";    startSource(encoding, "true", "1", "10");    Socket netcatSocket = new Socket(localhost, selectedPort);    LineIterator inputLineIterator = IOUtils.lineIterator(netcatSocket.getInputStream(), encoding);    try {        sendEvent(netcatSocket, "123456789", encoding);        Assert.assertArrayEquals("Channel contained our event", "123456789".getBytes(defaultCharset), getFlumeEvent());        Assert.assertEquals("Socket contained the Ack", ackEvent, inputLineIterator.nextLine());        sendEvent(netcatSocket, english, encoding);        Assert.assertEquals("Channel does not contain an event", null, getRawFlumeEvent());        Assert.assertEquals("Socket contained the Error Ack", ackErrorEvent, inputLineIterator.nextLine());    } finally {        netcatSocket.close();        stopSource();    }}
9f487d58c5dd3d12358bdb08117bfec2452250c050c5d4551d5c0be445d9fa44
testSourceStoppedOnFlumeException
public void testSourceStoppedOnFlumeException() throws InterruptedException, IOException
{    boolean isFlumeExceptionThrown = false;        try (ServerSocketChannel dummyServerSocket = ServerSocketChannel.open()) {        dummyServerSocket.socket().setReuseAddress(true);        dummyServerSocket.socket().bind(new InetSocketAddress("0.0.0.0", 10500));        Context context = new Context();        context.put("port", String.valueOf(10500));        context.put("bind", "0.0.0.0");        context.put("ack-every-event", "false");        Configurables.configure(source, context);        source.start();    } catch (FlumeException fe) {        isFlumeExceptionThrown = true;    }            Assert.assertTrue("Flume exception is thrown as port already in use", isFlumeExceptionThrown);    Assert.assertEquals("Server is stopped", LifecycleState.STOP, source.getLifecycleState());}
82ff754e8d7e19de05bb72d8756f74623e8faebb01b67ab8a7f90784af0138e1
startSource
private void startSource(String encoding, String ack, String batchSize, String maxLineLength) throws InterruptedException
{    Context context = new Context();    context.put("port", String.valueOf(selectedPort = getFreePort()));    context.put("bind", "0.0.0.0");    context.put("ack-every-event", ack);    context.put("encoding", encoding);    context.put("batch-size", batchSize);    context.put("max-line-length", maxLineLength);    Configurables.configure(source, context);    source.start();    Assert.assertTrue("Reached start or error", LifecycleController.waitForOneOf(source, LifecycleState.START_OR_ERROR));    Assert.assertEquals("Server is started", LifecycleState.START, source.getLifecycleState());}
51dc7a59c8926b18d57e1f075be860aca4fe08c20b4aa6eb60d5cef93a57400c
sendEvent
private void sendEvent(Socket socket, String content, String encoding) throws IOException
{    OutputStream output = socket.getOutputStream();    IOUtils.write(content + IOUtils.LINE_SEPARATOR_UNIX, output, encoding);    output.flush();}
61b0e72d6ef01591f6935fa83c60a8cf40b44feb7fec1f4d15a4d9dafb45b041
getFlumeEvent
private byte[] getFlumeEvent()
{    Transaction transaction = channel.getTransaction();    transaction.begin();    Event event = channel.take();    Assert.assertNotNull(event);    try {        transaction.commit();    } catch (Throwable t) {        transaction.rollback();    } finally {        transaction.close();    }    logger.debug("Round trip event:{}", event);    return event.getBody();}
f63169bc1c914657ede37cd840b7404a67cd603ccb02e4a1ee44a70e388e3c86
getRawFlumeEvent
private Event getRawFlumeEvent()
{    Transaction transaction = channel.getTransaction();    transaction.begin();    Event event = channel.take();    try {        transaction.commit();    } catch (Throwable t) {        transaction.rollback();    } finally {        transaction.close();    }    logger.debug("Round trip event:{}", event);    return event;}
72ae902765a611e581401b6dcd0037153826ec1d0a404f60c74ba6df6eb403c4
stopSource
private void stopSource() throws InterruptedException
{    source.stop();    Assert.assertTrue("Reached stop or error", LifecycleController.waitForOneOf(source, LifecycleState.STOP_OR_ERROR));    Assert.assertEquals("Server is stopped", LifecycleState.STOP, source.getLifecycleState());    logger.info("Source stopped");}
d4ed25ac8ad321cf30617caf76c4576654e12017af8058c0917f5c720521f0ec
init
private void init()
{    source = new NetcatUdpSource();    channel = new MemoryChannel();    Configurables.configure(channel, new Context());    List<Channel> channels = new ArrayList<Channel>();    channels.add(channel);    ChannelSelector rcs = new ReplicatingChannelSelector();    rcs.setChannels(channels);    source.setChannelProcessor(new ChannelProcessor(rcs));    Context context = new Context();    context.put("port", String.valueOf(TEST_NETCAT_PORT));    source.configure(context);}
bf1d9ced4d3fcc6dd8d4b5be47bb0654085e7e45e758d6b37239b8e86b5eade7
runUdpTest
private void runUdpTest(String data1) throws IOException
{    init();    source.start();        DatagramSocket socket;    DatagramPacket datagramPacket;    datagramPacket = new DatagramPacket(data1.getBytes(), data1.getBytes().length, InetAddress.getLocalHost(), source.getSourcePort());    for (int i = 0; i < 10; i++) {        socket = new DatagramSocket();        socket.send(datagramPacket);        socket.close();    }    List<Event> channelEvents = new ArrayList<Event>();    Transaction txn = channel.getTransaction();    txn.begin();    for (int i = 0; i < 10; i++) {        Event e = channel.take();        Assert.assertNotNull(e);        channelEvents.add(e);    }    try {        txn.commit();    } catch (Throwable t) {        txn.rollback();    } finally {        txn.close();    }    source.stop();    for (Event e : channelEvents) {        Assert.assertNotNull(e);        String str = new String(e.getBody(), Charsets.UTF_8);        logger.info(str);        Assert.assertArrayEquals(data1.getBytes(), e.getBody());    }}
3cbc78eaff31d056a1e0d25e4e53f637188521118e072e9366611ccf9f7452cd
testLargePayload
public void testLargePayload() throws Exception
{    init();    source.start();        byte[] largePayload = getPayload(1000).getBytes();    DatagramSocket socket;    DatagramPacket datagramPacket;    datagramPacket = new DatagramPacket(largePayload, 1000, InetAddress.getLocalHost(), source.getSourcePort());    for (int i = 0; i < 10; i++) {        socket = new DatagramSocket();        socket.send(datagramPacket);        socket.close();    }    List<Event> channelEvents = new ArrayList<Event>();    Transaction txn = channel.getTransaction();    txn.begin();    for (int i = 0; i < 10; i++) {        Event e = channel.take();        Assert.assertNotNull(e);        channelEvents.add(e);    }    try {        txn.commit();    } catch (Throwable t) {        txn.rollback();    } finally {        txn.close();    }    source.stop();    for (Event e : channelEvents) {        Assert.assertNotNull(e);        Assert.assertArrayEquals(largePayload, e.getBody());    }}
1674d14cd5af08003d3af836d9f168584441f5d12432d3c64a6b736ad9e548d7
testShortString
public void testShortString() throws IOException
{    runUdpTest(shortString);}
ca5eced9a29540ee37131ce2534b8df45a7e399d21ace60534f4c267c3d0e31e
testMediumString
public void testMediumString() throws IOException
{    runUdpTest(mediumString);}
370a8b17a844882ed82af28ad6d3de2caffabe42ef05e88612d6ca09767db5a3
getPayload
private String getPayload(int length)
{    StringBuilder payload = new StringBuilder(length);    for (int n = 0; n < length; ++n) {        payload.append("x");    }    return payload.toString();}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    sourceRunner = new PollableSourceRunner();}
f4f5bd17f7ef219499ed059849d7c2a0a6915756e4cd28bf2c10b3c9db532190
testLifecycle
public void testLifecycle() throws InterruptedException
{    final Channel channel = new MemoryChannel();    final CountDownLatch latch = new CountDownLatch(50);    Configurables.configure(channel, new Context());    final ChannelSelector cs = new ReplicatingChannelSelector();    cs.setChannels(Lists.newArrayList(channel));    PollableSource source = new PollableSource() {        private String name;        private ChannelProcessor cp = new ChannelProcessor(cs);        @Override        public Status process() throws EventDeliveryException {            Transaction transaction = channel.getTransaction();            try {                transaction.begin();                Event event = EventBuilder.withBody(String.valueOf("Event " + latch.getCount()).getBytes());                latch.countDown();                if (latch.getCount() % 20 == 0) {                    throw new EventDeliveryException("I don't like event:" + event);                }                channel.put(event);                transaction.commit();                return Status.READY;            } catch (EventDeliveryException e) {                logger.error("Unable to deliver event. Exception follows.", e);                transaction.rollback();                return Status.BACKOFF;            } finally {                transaction.close();            }        }        @Override        public long getBackOffSleepIncrement() {            return PollableSourceConstants.DEFAULT_BACKOFF_SLEEP_INCREMENT;        }        @Override        public long getMaxBackOffSleepInterval() {            return PollableSourceConstants.DEFAULT_MAX_BACKOFF_SLEEP;        }        @Override        public void start() {                }        @Override        public void stop() {                }        @Override        public LifecycleState getLifecycleState() {                        return null;        }        @Override        public void setName(String name) {            this.name = name;        }        @Override        public String getName() {            return name;        }        @Override        public void setChannelProcessor(ChannelProcessor channelProcessor) {            cp = channelProcessor;        }        @Override        public ChannelProcessor getChannelProcessor() {            return cp;        }    };    sourceRunner.setSource(source);    sourceRunner.start();    latch.await();    sourceRunner.stop();}
e52e5e378330fd7f87ee30351bbfcec47b751fee12ece2ef0cfdd77a08c906e1
process
public Status process() throws EventDeliveryException
{    Transaction transaction = channel.getTransaction();    try {        transaction.begin();        Event event = EventBuilder.withBody(String.valueOf("Event " + latch.getCount()).getBytes());        latch.countDown();        if (latch.getCount() % 20 == 0) {            throw new EventDeliveryException("I don't like event:" + event);        }        channel.put(event);        transaction.commit();        return Status.READY;    } catch (EventDeliveryException e) {        logger.error("Unable to deliver event. Exception follows.", e);        transaction.rollback();        return Status.BACKOFF;    } finally {        transaction.close();    }}
0c2bf215960a91e6d67dc2ecb6d4080c5643555055eb51cae826ed4203acda99
getBackOffSleepIncrement
public long getBackOffSleepIncrement()
{    return PollableSourceConstants.DEFAULT_BACKOFF_SLEEP_INCREMENT;}
09defa6fbcbcba505a3608243e14bdec0cc8c0e18b7feec629a8be8d48285381
getMaxBackOffSleepInterval
public long getMaxBackOffSleepInterval()
{    return PollableSourceConstants.DEFAULT_MAX_BACKOFF_SLEEP;}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{}
54497ccb2ff9760f1ec7fc0d0055d4bc60d5981953c5f3d7550c4b31a01e7642
getLifecycleState
public LifecycleState getLifecycleState()
{        return null;}
f498f22eaf0816bf385a43365651d1b6d0455905fdd2d6be01ceefeb84e8f432
setName
public void setName(String name)
{    this.name = name;}
239fbe3eb64d679cbac1161825b07d6a8436ead3c6c3d140d9caec2275827023
getName
public String getName()
{    return name;}
798a786aec56b24024eca0cd5b9a2eea1f206479ac0815d20c6206f765786979
setChannelProcessor
public void setChannelProcessor(ChannelProcessor channelProcessor)
{    cp = channelProcessor;}
2d47839be71cf363737c5c26abff8ca7e978b9a2567179574c983ee89f00b2da
getChannelProcessor
public ChannelProcessor getChannelProcessor()
{    return cp;}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    source = new SequenceGeneratorSource();    source.setName(TestSequenceGeneratorSource.class.getCanonicalName());}
2eefde437491d7d7dae8bb5f851d3d9c97e7f5fb29703a386541921cc57f3242
testLifecycle
public void testLifecycle() throws org.apache.flume.EventDeliveryException
{    final int DOPROCESS_LOOPS = 5;    Context context = new Context();    Configurables.configure(source, context);    ChannelProcessor cp = Mockito.mock(ChannelProcessor.class);    source.setChannelProcessor(cp);    source.start();    for (int i = 0; i < DOPROCESS_LOOPS; i++) {        source.process();    }    source.stop();}
b15f208a68b5d327681da5a6bf40b3fb38ad6af9161756b28ac70b5b3da2bd8a
testSingleEvents
public void testSingleEvents() throws EventDeliveryException
{    final int BATCH_SIZE = 1;    final int TOTAL_EVENTS = 5;    final int DOPROCESS_LOOPS = 10;    Context context = new Context();    context.put("batchSize", Integer.toString(BATCH_SIZE));    context.put("totalEvents", Integer.toString(TOTAL_EVENTS));    Configurables.configure(source, context);    ChannelProcessor cp = Mockito.mock(ChannelProcessor.class);    Mockito.doNothing().doThrow(    ChannelException.class).doNothing().when(cp).processEvent(Mockito.any(Event.class));    source.setChannelProcessor(cp);    source.start();    for (int i = 0; i < DOPROCESS_LOOPS; i++) {        source.process();    }    ArgumentCaptor<Event> argumentCaptor = ArgumentCaptor.forClass(Event.class);    Mockito.verify(cp, Mockito.times(6)).processEvent(argumentCaptor.capture());    Mockito.verify(cp, Mockito.never()).processEventBatch(Mockito.anyListOf(Event.class));    verifyEventSequence(TOTAL_EVENTS, argumentCaptor.getAllValues());}
d59dae653df09368eeb9e41898080af3b6cce06651c185e68c85a0dd7ee10403
testBatch
public void testBatch() throws EventDeliveryException
{    final int BATCH_SIZE = 3;    final int TOTAL_EVENTS = 5;    final int DOPROCESS_LOOPS = 10;    Context context = new Context();    context.put("batchSize", Integer.toString(BATCH_SIZE));    context.put("totalEvents", Integer.toString(TOTAL_EVENTS));    Configurables.configure(source, context);    ChannelProcessor cp = Mockito.mock(ChannelProcessor.class);    Mockito.doNothing().doThrow(    ChannelException.class).doNothing().when(cp).processEventBatch(Mockito.anyListOf(Event.class));    source.setChannelProcessor(cp);    source.start();    for (int i = 0; i < DOPROCESS_LOOPS; i++) {        source.process();    }    ArgumentCaptor<List<Event>> argumentCaptor = ArgumentCaptor.forClass((Class) List.class);    Mockito.verify(cp, Mockito.never()).processEvent(Mockito.any(Event.class));    Mockito.verify(cp, Mockito.times(3)).processEventBatch(argumentCaptor.capture());    List<List<Event>> eventBatches = argumentCaptor.getAllValues();    verifyEventSequence(TOTAL_EVENTS, flatOutBatches(eventBatches));}
ccee32fda2cad95e6bb670e7d87d844a16b3e5e3e8aedd9bee176cf7c461f47a
verifyEventSequence
private static void verifyEventSequence(int expectedTotalEvents, List<Event> actualEvents)
{    Set<Integer> uniqueEvents = new LinkedHashSet<>();    for (Event e : actualEvents) {        uniqueEvents.add(Integer.parseInt(new String(e.getBody())));    }    List<Integer> sortedFilteredEvents = new ArrayList<>(uniqueEvents);    Collections.sort(sortedFilteredEvents);    Assert.assertEquals("mismatching number of events", expectedTotalEvents, sortedFilteredEvents.size());    for (int i = 0; i < sortedFilteredEvents.size(); ++i) {        Assert.assertEquals("missing or unexpected event body", i, (int) sortedFilteredEvents.get(i));    }}
8cb2324ae329a8e73f8b97660840a405de98efd9ddf512654d9c9c900a8a0f66
flatOutBatches
private static List<Event> flatOutBatches(List<List<Event>> eventBatches)
{    List<Event> events = new ArrayList<>();    for (List<Event> le : eventBatches) {        for (Event e : le) {            events.add(e);        }    }    return events;}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    source = new SpoolDirectorySource();    channel = new MemoryChannel();    Configurables.configure(channel, new Context());    List<Channel> channels = new ArrayList<Channel>();    channels.add(channel);    ChannelSelector rcs = new ReplicatingChannelSelector();    rcs.setChannels(channels);    source.setChannelProcessor(new ChannelProcessor(rcs));    tmpDir = Files.createTempDir();}
39e5ba029cc67f6f1d45c6d20f0df595ec16bc61da20d7680fcbbdae4fe7f95b
tearDown
public void tearDown()
{    deleteFiles(tmpDir);    tmpDir.delete();}
e8e6e6d80fb44f8b8de61da093a90ce0f57bf2ebc54d81fa6112faa531b19f3b
deleteFiles
private void deleteFiles(File directory)
{    for (File f : directory.listFiles()) {        if (f.isDirectory()) {            deleteFiles(f);            f.delete();        } else {            f.delete();        }    }}
80aa8d6764f6883161330157a64d72018857a2a00392492da3f18ecee9ed3340
testInvalidSortOrder
public void testInvalidSortOrder()
{    Context context = new Context();    context.put(SpoolDirectorySourceConfigurationConstants.SPOOL_DIRECTORY, tmpDir.getAbsolutePath());    context.put(SpoolDirectorySourceConfigurationConstants.CONSUME_ORDER, "undefined");    Configurables.configure(source, context);}
4936ddf03cc61bfed22cb422e94c9c45b719f3aebb8705034c72f3b08fbf2e61
testValidSortOrder
public void testValidSortOrder()
{    Context context = new Context();    context.put(SpoolDirectorySourceConfigurationConstants.SPOOL_DIRECTORY, tmpDir.getAbsolutePath());    context.put(SpoolDirectorySourceConfigurationConstants.CONSUME_ORDER, "oLdESt");    Configurables.configure(source, context);    context.put(SpoolDirectorySourceConfigurationConstants.CONSUME_ORDER, "yoUnGest");    Configurables.configure(source, context);    context.put(SpoolDirectorySourceConfigurationConstants.CONSUME_ORDER, "rAnDom");    Configurables.configure(source, context);}
539b494be8d8e7839c6000e7a44e7ad88ec0689402790fd4fc04e7eeebdfdddb
testPutFilenameHeader
public void testPutFilenameHeader() throws IOException, InterruptedException
{    Context context = new Context();    File f1 = new File(tmpDir.getAbsolutePath() + "/file1");    Files.write("file1line1\nfile1line2\nfile1line3\nfile1line4\n" + "file1line5\nfile1line6\nfile1line7\nfile1line8\n", f1, Charsets.UTF_8);    context.put(SpoolDirectorySourceConfigurationConstants.SPOOL_DIRECTORY, tmpDir.getAbsolutePath());    context.put(SpoolDirectorySourceConfigurationConstants.FILENAME_HEADER, "true");    context.put(SpoolDirectorySourceConfigurationConstants.FILENAME_HEADER_KEY, "fileHeaderKeyTest");    Configurables.configure(source, context);    source.start();    while (source.getSourceCounter().getEventAcceptedCount() < 8) {        Thread.sleep(10);    }    Transaction txn = channel.getTransaction();    txn.begin();    Event e = channel.take();    Assert.assertNotNull("Event must not be null", e);    Assert.assertNotNull("Event headers must not be null", e.getHeaders());    Assert.assertNotNull(e.getHeaders().get("fileHeaderKeyTest"));    Assert.assertEquals(f1.getAbsolutePath(), e.getHeaders().get("fileHeaderKeyTest"));    txn.commit();    txn.close();}
6eeddff2b7f94b44aa569672b78397c09f119b6c578bb60d01c35dadbeed2ef7
testPutBasenameHeader
public void testPutBasenameHeader() throws IOException, InterruptedException
{    Context context = new Context();    File f1 = new File(tmpDir.getAbsolutePath() + "/file1");    Files.write("file1line1\nfile1line2\nfile1line3\nfile1line4\n" + "file1line5\nfile1line6\nfile1line7\nfile1line8\n", f1, Charsets.UTF_8);    context.put(SpoolDirectorySourceConfigurationConstants.SPOOL_DIRECTORY, tmpDir.getAbsolutePath());    context.put(SpoolDirectorySourceConfigurationConstants.BASENAME_HEADER, "true");    context.put(SpoolDirectorySourceConfigurationConstants.BASENAME_HEADER_KEY, "basenameHeaderKeyTest");    Configurables.configure(source, context);    source.start();    while (source.getSourceCounter().getEventAcceptedCount() < 8) {        Thread.sleep(10);    }    Transaction txn = channel.getTransaction();    txn.begin();    Event e = channel.take();    Assert.assertNotNull("Event must not be null", e);    Assert.assertNotNull("Event headers must not be null", e.getHeaders());    Assert.assertNotNull(e.getHeaders().get("basenameHeaderKeyTest"));    Assert.assertEquals(f1.getName(), e.getHeaders().get("basenameHeaderKeyTest"));    txn.commit();    txn.close();}
128e513257edccb4deea2fb127bb910030914ec8989a1f762e8780699a87b2a9
testRecursion_SetToTrue
public void testRecursion_SetToTrue() throws IOException, InterruptedException
{    File subDir = new File(tmpDir, "directorya/directoryb/directoryc");    boolean directoriesCreated = subDir.mkdirs();    Assert.assertTrue("source directories must be created", directoriesCreated);    final String FILE_NAME = "recursion_file.txt";    File f1 = new File(subDir, FILE_NAME);    String origBody = "file1line1\nfile1line2\nfile1line3\nfile1line4\n" + "file1line5\nfile1line6\nfile1line7\nfile1line8\n";    Files.write(origBody, f1, Charsets.UTF_8);    Context context = new Context();    context.put(SpoolDirectorySourceConfigurationConstants.RECURSIVE_DIRECTORY_SEARCH,     "true");    context.put(SpoolDirectorySourceConfigurationConstants.SPOOL_DIRECTORY,     tmpDir.getAbsolutePath());    context.put(SpoolDirectorySourceConfigurationConstants.FILENAME_HEADER,     "true");    Configurables.configure(source, context);    source.start();    Assert.assertTrue("Recursion setting in source is correct", source.getRecursiveDirectorySearch());    Transaction txn = channel.getTransaction();    txn.begin();    long startTime = System.currentTimeMillis();    Event e = null;    while (System.currentTimeMillis() - startTime < 300 && e == null) {        e = channel.take();        Thread.sleep(10);    }    Assert.assertNotNull("Event must not be null", e);    Assert.assertNotNull("Event headers must not be null", e.getHeaders());    Assert.assertTrue("File header value did not end with expected filename", e.getHeaders().get("file").endsWith(FILE_NAME));    ByteArrayOutputStream baos = new ByteArrayOutputStream();    do {                baos.write(e.getBody());                baos.write('\n');        e = channel.take();    } while (e != null);    Assert.assertEquals("Event body is correct", Arrays.toString(origBody.getBytes()), Arrays.toString(baos.toByteArray()));    txn.commit();    txn.close();}
f4bd3b61c0a7d65e6bab760ab3697baa8dd6562f771f1f8174c1f0a1d142b5c0
testRecursion_SetToFalse
public void testRecursion_SetToFalse() throws IOException, InterruptedException
{    Context context = new Context();    File subDir = new File(tmpDir, "directory");    boolean directoriesCreated = subDir.mkdirs();    Assert.assertTrue("source directories must be created", directoriesCreated);    File f1 = new File(subDir.getAbsolutePath() + "/file1.txt");    Files.write("file1line1\nfile1line2\nfile1line3\nfile1line4\n" + "file1line5\nfile1line6\nfile1line7\nfile1line8\n", f1, Charsets.UTF_8);    context.put(SpoolDirectorySourceConfigurationConstants.RECURSIVE_DIRECTORY_SEARCH, "false");    context.put(SpoolDirectorySourceConfigurationConstants.SPOOL_DIRECTORY, tmpDir.getAbsolutePath());    context.put(SpoolDirectorySourceConfigurationConstants.FILENAME_HEADER, "true");    context.put(SpoolDirectorySourceConfigurationConstants.FILENAME_HEADER_KEY, "fileHeaderKeyTest");    Configurables.configure(source, context);    source.start();        Assert.assertFalse("Recursion setting in source is not set to false (this" + "test does not want recursion enabled)", source.getRecursiveDirectorySearch());    Transaction txn = channel.getTransaction();    txn.begin();    long startTime = System.currentTimeMillis();    Event e = null;    while (System.currentTimeMillis() - startTime < 300 && e == null) {        e = channel.take();        Thread.sleep(10);    }    Assert.assertNull("Event must be null", e);    txn.commit();    txn.close();}
3b5d94ab890b4e2664ec6567db687a95e9b3b2e71331c545033c973fe005e8ae
testLifecycle
public void testLifecycle() throws IOException, InterruptedException
{    Context context = new Context();    File f1 = new File(tmpDir.getAbsolutePath() + "/file1");    Files.write("file1line1\nfile1line2\nfile1line3\nfile1line4\n" + "file1line5\nfile1line6\nfile1line7\nfile1line8\n", f1, Charsets.UTF_8);    context.put(SpoolDirectorySourceConfigurationConstants.SPOOL_DIRECTORY, tmpDir.getAbsolutePath());    Configurables.configure(source, context);    for (int i = 0; i < 10; i++) {        source.start();        Assert.assertTrue("Reached start or error", LifecycleController.waitForOneOf(source, LifecycleState.START_OR_ERROR));        Assert.assertEquals("Server is started", LifecycleState.START, source.getLifecycleState());        source.stop();        Assert.assertTrue("Reached stop or error", LifecycleController.waitForOneOf(source, LifecycleState.STOP_OR_ERROR));        Assert.assertEquals("Server is stopped", LifecycleState.STOP, source.getLifecycleState());    }}
40c3f0f9f92676221c170cad36e3ef9346c2ffc9196fa5c5ab599cb0ebb882f2
testReconfigure
public void testReconfigure() throws InterruptedException, IOException
{    final int NUM_RECONFIGS = 20;    for (int i = 0; i < NUM_RECONFIGS; i++) {        Context context = new Context();        File file = new File(tmpDir.getAbsolutePath() + "/file-" + i);        Files.write("File " + i, file, Charsets.UTF_8);        context.put(SpoolDirectorySourceConfigurationConstants.SPOOL_DIRECTORY, tmpDir.getAbsolutePath());        Configurables.configure(source, context);        source.start();        Thread.sleep(TimeUnit.SECONDS.toMillis(1));        Transaction txn = channel.getTransaction();        txn.begin();        try {            Event event = channel.take();            String content = new String(event.getBody(), Charsets.UTF_8);            Assert.assertEquals("File " + i, content);            txn.commit();        } catch (Throwable t) {            txn.rollback();        } finally {            txn.close();        }        source.stop();        Assert.assertFalse("Fatal error on iteration " + i, source.hasFatalError());    }}
a8de7b43154da60640f030181334328bbc922dcbc5c5192cd712865c86728187
testSourceDoesNotDieOnFullChannel
public void testSourceDoesNotDieOnFullChannel() throws Exception
{    Context chContext = new Context();    chContext.put("capacity", "2");    chContext.put("transactionCapacity", "2");    chContext.put("keep-alive", "0");    channel.stop();    Configurables.configure(channel, chContext);    channel.start();    Context context = new Context();    File f1 = new File(tmpDir.getAbsolutePath() + "/file1");    Files.write("file1line1\nfile1line2\nfile1line3\nfile1line4\n" + "file1line5\nfile1line6\nfile1line7\nfile1line8\n", f1, Charsets.UTF_8);    context.put(SpoolDirectorySourceConfigurationConstants.SPOOL_DIRECTORY, tmpDir.getAbsolutePath());    context.put(SpoolDirectorySourceConfigurationConstants.BATCH_SIZE, "2");    Configurables.configure(source, context);    source.setBackOff(false);    source.start();        long startTime = System.currentTimeMillis();    while (System.currentTimeMillis() - startTime < 5000 && !source.didHitChannelFullException()) {        Thread.sleep(10);    }    Assert.assertTrue("Expected to hit ChannelFullException, but did not!", source.didHitChannelFullException());    List<String> dataOut = Lists.newArrayList();    for (int i = 0; i < 8; ) {        Transaction tx = channel.getTransaction();        tx.begin();        Event e = channel.take();        if (e != null) {            dataOut.add(new String(e.getBody(), "UTF-8"));            i++;        }        e = channel.take();        if (e != null) {            dataOut.add(new String(e.getBody(), "UTF-8"));            i++;        }        tx.commit();        tx.close();    }    Assert.assertEquals(8, dataOut.size());    source.stop();}
b6b3a86bed22cdf4491d9c9c573093a8f73463cf359693043a1d68d58f5f0925
testEndWithZeroByteFiles
public void testEndWithZeroByteFiles() throws IOException, InterruptedException
{    Context context = new Context();    File f1 = new File(tmpDir.getAbsolutePath() + "/file1");    Files.write("file1line1\n", f1, Charsets.UTF_8);    File f2 = new File(tmpDir.getAbsolutePath() + "/file2");    File f3 = new File(tmpDir.getAbsolutePath() + "/file3");    File f4 = new File(tmpDir.getAbsolutePath() + "/file4");    Files.touch(f2);    Files.touch(f3);    Files.touch(f4);    context.put(SpoolDirectorySourceConfigurationConstants.SPOOL_DIRECTORY, tmpDir.getAbsolutePath());    Configurables.configure(source, context);    source.start();        Thread.sleep(5000);    Assert.assertFalse("Server did not error", source.hasFatalError());    Assert.assertEquals("Four messages were read", 4, source.getSourceCounter().getEventAcceptedCount());    source.stop();}
fce54a0a15eec390bd0b7b18482c482495a8cca17f5f5db59b0fb09467b3e96e
testWithAllEmptyFiles
public void testWithAllEmptyFiles() throws InterruptedException, IOException
{    Context context = new Context();    File[] f = new File[10];    for (int i = 0; i < 10; i++) {        f[i] = new File(tmpDir.getAbsolutePath() + "/file" + i);        Files.write(new byte[0], f[i]);    }    context.put(SpoolDirectorySourceConfigurationConstants.SPOOL_DIRECTORY, tmpDir.getAbsolutePath());    context.put(SpoolDirectorySourceConfigurationConstants.FILENAME_HEADER, "true");    context.put(SpoolDirectorySourceConfigurationConstants.FILENAME_HEADER_KEY, "fileHeaderKeyTest");    Configurables.configure(source, context);    source.start();    Thread.sleep(10);    for (int i = 0; i < 10; i++) {        Transaction txn = channel.getTransaction();        txn.begin();        Event e = channel.take();        Assert.assertNotNull("Event must not be null", e);        Assert.assertNotNull("Event headers must not be null", e.getHeaders());        Assert.assertNotNull(e.getHeaders().get("fileHeaderKeyTest"));        Assert.assertEquals(f[i].getAbsolutePath(), e.getHeaders().get("fileHeaderKeyTest"));        Assert.assertArrayEquals(new byte[0], e.getBody());        txn.commit();        txn.close();    }    source.stop();}
2878468972c559d8117fe0224ef17699be1f72415cf7982657bb65edd70d0eb4
testWithEmptyAndDataFiles
public void testWithEmptyAndDataFiles() throws InterruptedException, IOException
{    Context context = new Context();    File f1 = new File(tmpDir.getAbsolutePath() + "/file1");    Files.write("some data".getBytes(), f1);    File f2 = new File(tmpDir.getAbsolutePath() + "/file2");    Files.write(new byte[0], f2);    context.put(SpoolDirectorySourceConfigurationConstants.SPOOL_DIRECTORY, tmpDir.getAbsolutePath());    Configurables.configure(source, context);    source.start();    Thread.sleep(10);    for (int i = 0; i < 2; i++) {        Transaction txn = channel.getTransaction();        txn.begin();        Event e = channel.take();        txn.commit();        txn.close();    }    Transaction txn = channel.getTransaction();    txn.begin();    Assert.assertNull(channel.take());    txn.commit();    txn.close();    source.stop();}
5f3737d0fa56071ceaa7bd905ae70caf84022a3b6cd95dadc66af0248cf28e02
errorCounterCommonInit
private SourceCounter errorCounterCommonInit()
{    SourceCounter sc = new SourceCounter("dummy");    sc.start();    Context context = new Context();    context.put(SpoolDirectorySourceConfigurationConstants.SPOOL_DIRECTORY, tmpDir.getAbsolutePath());    Configurables.configure(source, context);    return sc;}
372d76569b82137cc5011f1824442b986efe1a923733b253995be02256a9b325
testErrorCounters
public void testErrorCounters() throws Exception
{    SourceCounter sc = errorCounterCommonInit();    ChannelProcessor cp = Mockito.mock(ChannelProcessor.class);    Mockito.doThrow(new ChannelException("dummy")).doThrow(new ChannelFullException("dummy")).doThrow(new RuntimeException("runtime")).when(cp).processEventBatch(Matchers.anyListOf(Event.class));    source.setChannelProcessor(cp);    ReliableSpoolingFileEventReader reader = Mockito.mock(ReliableSpoolingFileEventReader.class);    List<Event> events = new ArrayList<>();    events.add(Mockito.mock(Event.class));    Mockito.doReturn(events).doReturn(events).doReturn(events).doThrow(new IOException("dummy")).when(reader).readEvents(Mockito.anyInt());    Runnable runner = source.new SpoolDirectoryRunnable(reader, sc);    try {        runner.run();    } catch (Exception ex) {        }    Assert.assertEquals(2, sc.getChannelWriteFail());    Assert.assertEquals(1, sc.getGenericProcessingFail());}
fadbbf1e2a2f05fb22a914b78a0f9a0c8d7951630987c1cecefddbf7a5ee31a8
testErrorCounterEventReadFail
public void testErrorCounterEventReadFail() throws Exception
{    SourceCounter sc = errorCounterCommonInit();    ChannelProcessor cp = Mockito.mock(ChannelProcessor.class);    source.setChannelProcessor(cp);    ReliableSpoolingFileEventReader reader = Mockito.mock(ReliableSpoolingFileEventReader.class);    List<Event> events = new ArrayList<>();    events.add(Mockito.mock(Event.class));    Mockito.doReturn(events).doThrow(new IOException("dummy")).when(reader).readEvents(Mockito.anyInt());    Runnable runner = source.new SpoolDirectoryRunnable(reader, sc);    try {        runner.run();    } catch (Exception ex) {        }    Assert.assertEquals(1, sc.getEventReadFail());}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    mockProcessor = mock(ChannelProcessor.class);}
94c2fb68d4f083fe84f58d1ca9dfd35b809c100843bbd726164d2ed2924566ee
getEvent
private Event getEvent(StressSource source)
{    return field("event").ofType(Event.class).in(source).get();}
0f46f284bfe0bb87ebb5a160805b071847f77b8b49689bb140f1c9ab6de3971f
getLastProcessedEventList
private List<Event> getLastProcessedEventList(StressSource source)
{    return field("eventBatchListToProcess").ofType(List.class).in(source).get();}
20a2e150af420005b2d3426682e16835e710933e3fc0097f2ba3161a4b851ba7
getCounterGroup
private CounterGroup getCounterGroup(StressSource source)
{    return field("counterGroup").ofType(CounterGroup.class).in(source).get();}
73cbcd2db797b50133f65c2b8bc8444d6afc75caca9d32a1fd8cbea0a4a654b8
testMaxTotalEvents
public void testMaxTotalEvents() throws InterruptedException, EventDeliveryException
{    StressSource source = new StressSource();    source.setChannelProcessor(mockProcessor);    Context context = new Context();    context.put("maxTotalEvents", "35");    source.configure(context);    source.start();    for (int i = 0; i < 50; i++) {        source.process();    }    verify(mockProcessor, times(35)).processEvent(getEvent(source));}
c215848ae20f65f5b5a91bdbdeb3a9617ce99e38de7d6b528346d7f0428602a9
testRateLimitedEventsNoBatch
public void testRateLimitedEventsNoBatch() throws InterruptedException, EventDeliveryException
{    StressSource source = new StressSource();    source.setChannelProcessor(mockProcessor);    Context context = new Context();    context.put("maxTotalEvents", "20");    context.put("maxEventsPerSecond", "20");    source.configure(context);    long startTime = System.currentTimeMillis();    source.start();    for (int i = 0; i < 20; i++) {        source.process();    }    long finishTime = System.currentTimeMillis();        Assert.assertTrue(finishTime - startTime < 1300);    Assert.assertTrue(finishTime - startTime > 700);    source.stop();}
71d7dce9dcce99808feb76935898a774480bedfd8dc55ac62029dda40d5c1a16
testNonRateLimitedEventsNoBatch
public void testNonRateLimitedEventsNoBatch() throws InterruptedException, EventDeliveryException
{    StressSource source = new StressSource();    source.setChannelProcessor(mockProcessor);    Context context = new Context();        context = new Context();    context.put("maxTotalEvents", "20");    context.put("maxEventsPerSecond", "0");    source.configure(context);    long startTime = System.currentTimeMillis();    source.start();    for (int i = 0; i <= 20; i++) {        source.process();    }    long finishTime = System.currentTimeMillis();    Assert.assertTrue(finishTime - startTime < 70);}
63f154ec937bbe78bdc604c73be904ba9f67e2b84ba8913b082cb891eeea0520
testRateLimitedEventsBatch
public void testRateLimitedEventsBatch() throws InterruptedException, EventDeliveryException
{    StressSource source = new StressSource();    source.setChannelProcessor(mockProcessor);    Context context = new Context();    context.put("maxTotalEvents", "20");    context.put("maxEventsPerSecond", "20");    context.put("batchSize", "3");    source.configure(context);    long startTime = System.currentTimeMillis();    source.start();    for (int i = 0; i < 20; i++) {        source.process();    }    long finishTime = System.currentTimeMillis();        Assert.assertTrue(finishTime - startTime < 1300);    Assert.assertTrue(finishTime - startTime > 700);    source.stop();}
e655ac7cb2a09d54709bade36ffb8bf433d6a5b053133f3d8c0b3d9fa837da28
testNonRateLimitedEventsBatch
public void testNonRateLimitedEventsBatch() throws InterruptedException, EventDeliveryException
{    StressSource source = new StressSource();    source.setChannelProcessor(mockProcessor);    Context context = new Context();        context.put("maxTotalEvents", "20");    context.put("maxEventsPerSecond", "0");    source.configure(context);    long startTime = System.currentTimeMillis();    source.start();    for (int i = 0; i <= 20; i++) {        source.process();    }    long finishTime = System.currentTimeMillis();    Assert.assertTrue(finishTime - startTime < 70);}
e785a5a1c8be2881f15967ffee7532a518eeaa389b87b72656da2a9bc781f5f6
testBatchEvents
public void testBatchEvents() throws InterruptedException, EventDeliveryException
{    StressSource source = new StressSource();    source.setChannelProcessor(mockProcessor);    Context context = new Context();    context.put("maxTotalEvents", "35");    context.put("batchSize", "10");    source.configure(context);    source.start();    for (int i = 0; i < 50; i++) {        if (source.process() == Status.BACKOFF) {            TestCase.assertTrue("Source should have sent all events in 4 batches", i == 4);            break;        }        if (i < 3) {            verify(mockProcessor, times(i + 1)).processEventBatch(getLastProcessedEventList(source));        } else {            verify(mockProcessor, times(1)).processEventBatch(getLastProcessedEventList(source));        }    }    long successfulEvents = getCounterGroup(source).get("events.successful");    TestCase.assertTrue("Number of successful events should be 35 but was " + successfulEvents, successfulEvents == 35);    long failedEvents = getCounterGroup(source).get("events.failed");    TestCase.assertTrue("Number of failure events should be 0 but was " + failedEvents, failedEvents == 0);}
8ae2efdcfbccb2e21b2eba76d0e30e0b6a30f41054193dc4ce8ca8dabe2ba981
testBatchEventsWithoutMatTotalEvents
public void testBatchEventsWithoutMatTotalEvents() throws InterruptedException, EventDeliveryException
{    StressSource source = new StressSource();    source.setChannelProcessor(mockProcessor);    Context context = new Context();    context.put("batchSize", "10");    source.configure(context);    source.start();    for (int i = 0; i < 10; i++) {        Assert.assertFalse("StressSource with no maxTotalEvents should not return " + Status.BACKOFF, source.process() == Status.BACKOFF);    }    verify(mockProcessor, times(10)).processEventBatch(getLastProcessedEventList(source));    long successfulEvents = getCounterGroup(source).get("events.successful");    TestCase.assertTrue("Number of successful events should be 100 but was " + successfulEvents, successfulEvents == 100);    long failedEvents = getCounterGroup(source).get("events.failed");    TestCase.assertTrue("Number of failure events should be 0 but was " + failedEvents, failedEvents == 0);}
de445d737d451d65b8819d798fdd8a85e13a8a97f9f4b12802f97d021021dd10
testMaxSuccessfulEvents
public void testMaxSuccessfulEvents() throws InterruptedException, EventDeliveryException
{    StressSource source = new StressSource();    source.setChannelProcessor(mockProcessor);    Context context = new Context();    context.put("maxSuccessfulEvents", "35");    source.configure(context);    source.start();    for (int i = 0; i < 10; i++) {        source.process();    }        doThrow(new ChannelException("stub")).when(mockProcessor).processEvent(getEvent(source));    source.process();    doNothing().when(mockProcessor).processEvent(getEvent(source));    for (int i = 0; i < 10; i++) {        source.process();    }        doThrow(new ChannelException("stub")).when(mockProcessor).processEvent(getEvent(source));    source.process();    doNothing().when(mockProcessor).processEvent(getEvent(source));    for (int i = 0; i < 50; i++) {        source.process();    }            verify(mockProcessor, times(37)).processEvent(getEvent(source));}
4ec4988bea31ee164a82deaf36820d2db0d5ec9614010b032792b4b980f1aaea
testRfc5424DateParsing
public void testRfc5424DateParsing()
{    final String[] examples = { "1985-04-12T23:20:50.52Z", "1985-04-12T19:20:50.52-04:00", "2003-10-11T22:14:15.003Z", "2003-08-24T05:14:15.000003-07:00", "2012-04-13T11:11:11-08:00", "2012-04-13T08:08:08.0001+00:00", "2012-04-13T08:08:08.251+00:00" };    SyslogParser parser = new SyslogParser();    DateTimeFormatter jodaParser = ISODateTimeFormat.dateTimeParser();    for (String ex : examples) {        Assert.assertEquals("Problem parsing date string: " + ex, jodaParser.parseMillis(ex), parser.parseRfc5424Date(ex));    }}
ee796e4d5a5bad12906797fb8a050e4ffa03c8a8018246ee1872835d4578fd30
testMessageParsing
public void testMessageParsing()
{    SyslogParser parser = new SyslogParser();    Charset charset = Charsets.UTF_8;    List<String> messages = Lists.newArrayList();        messages.add("<34>Oct 11 22:14:15 mymachine su: 'su root' failed for " + "lonvick on /dev/pts/8");    messages.add("<13>Feb  5 17:32:18 10.0.0.99 Use the BFG!");    messages.add("<165>Aug 24 05:34:00 CST 1987 mymachine myproc[10]: %% " + "It's time to make the do-nuts.  %%  Ingredients: Mix=OK, Jelly=OK # " + "Devices: Mixer=OK, Jelly_Injector=OK, Frier=OK # Transport: " + "Conveyer1=OK, Conveyer2=OK # %%");    messages.add("<0>Oct 22 10:52:12 scapegoat 1990 Oct 22 10:52:01 TZ-6 " + "scapegoat.dmz.example.org 10.1.2.3 sched[0]: That's All Folks!");        messages.add("<34>1 2003-10-11T22:14:15.003Z mymachine.example.com su - " + "ID47 - BOM'su root' failed for lonvick on /dev/pts/8");    messages.add("<165>1 2003-08-24T05:14:15.000003-07:00 192.0.2.1 myproc " + "8710 - - %% It's time to make the do-nuts.");        messages.add("<13>2003-08-24T05:14:15Z localhost snarf?");    messages.add("<13>2012-08-16T14:34:03-08:00 127.0.0.1 test shnap!");        for (String msg : messages) {        Set<String> keepFields = new HashSet<String>();        Event event = parser.parseMessage(msg, charset, keepFields);        Assert.assertNull("Failure to parse known-good syslog message", event.getHeaders().get(SyslogUtils.EVENT_STATUS));    }        for (String msg : messages) {        Set<String> keepFields = new HashSet<String>();        keepFields.add(SyslogUtils.KEEP_FIELDS_ALL);        Event event = parser.parseMessage(msg, charset, keepFields);        Assert.assertArrayEquals(event.getBody(), msg.getBytes());        Assert.assertNull("Failure to parse known-good syslog message", event.getHeaders().get(SyslogUtils.EVENT_STATUS));    }        for (String msg : messages) {        Set<String> keepFields = new HashSet<String>();        keepFields.add(SyslogSourceConfigurationConstants.CONFIG_KEEP_FIELDS_HOSTNAME);        Event event = parser.parseMessage(msg, charset, keepFields);        Assert.assertTrue("Failure to persist hostname", new String(event.getBody()).contains(event.getHeaders().get("host")));        Assert.assertNull("Failure to parse known-good syslog message", event.getHeaders().get(SyslogUtils.EVENT_STATUS));    }}
0c7c2faf870bffbd8a89f2c4fc53472415077c0e35bfbf65d6f0f2328d14d3a5
init
private void init(String keepFields)
{    init(keepFields, new Context());}
037ece0f30486e0a9dbc2731be2dfd75865287e6ba8c7ac3b97e193aeb941e59
init
private void init(String keepFields, Context context)
{    source = new SyslogTcpSource();    channel = new MemoryChannel();    Configurables.configure(channel, new Context());    List<Channel> channels = new ArrayList<>();    channels.add(channel);    ChannelSelector rcs = new ReplicatingChannelSelector();    rcs.setChannels(channels);    source.setChannelProcessor(new ChannelProcessor(rcs));    context.put("host", InetAddress.getLoopbackAddress().getHostAddress());    context.put("port", String.valueOf(TEST_SYSLOG_PORT));    context.put("keepFields", keepFields);    source.configure(context);}
f6de5e1a0fddd5a72841e9c36d265e83d8d088ed99ee3083779113093300d290
initSsl
private void initSsl()
{    Context context = new Context();    context.put("ssl", "true");    context.put("keystore", "src/test/resources/server.p12");    context.put("keystore-password", "password");    context.put("keystore-type", "PKCS12");    init("none", context);}
fe0f215d7328c07ce78b6755a4f666b47290af292ffcee9c2b24103d5755ff79
runKeepFieldsTest
private void runKeepFieldsTest(String keepFields) throws IOException
{    init(keepFields);    source.start();        InetSocketAddress addr = source.getBoundAddress();    for (int i = 0; i < 10; i++) {        try (Socket syslogSocket = new Socket(addr.getAddress(), addr.getPort())) {            syslogSocket.getOutputStream().write(bodyWithTandH.getBytes());        }    }    List<Event> channelEvents = new ArrayList<>();    Transaction txn = channel.getTransaction();    txn.begin();    for (int i = 0; i < 10; i++) {        Event e = channel.take();        if (e == null) {            throw new NullPointerException("Event is null");        }        channelEvents.add(e);    }    try {        txn.commit();    } catch (Throwable t) {        txn.rollback();    } finally {        txn.close();    }    source.stop();    for (Event e : channelEvents) {        Assert.assertNotNull(e);        String str = new String(e.getBody(), Charsets.UTF_8);        logger.info(str);        if (keepFields.equals("true") || keepFields.equals("all")) {            Assert.assertArrayEquals(bodyWithTandH.trim().getBytes(), e.getBody());        } else if (keepFields.equals("false") || keepFields.equals("none")) {            Assert.assertArrayEquals(data1.getBytes(), e.getBody());        } else if (keepFields.equals("hostname")) {            Assert.assertArrayEquals(bodyWithHostname.getBytes(), e.getBody());        } else if (keepFields.equals("timestamp")) {            Assert.assertArrayEquals(bodyWithTimestamp.getBytes(), e.getBody());        }    }}
708d23e9c8cc2212b8063745610334cb366f5c62c578c1eba580a22db840696e
testKeepFields
public void testKeepFields() throws IOException
{    runKeepFieldsTest("all");        runKeepFieldsTest("true");}
519ca59b7801124d6f2641f49b8b52f666d6c83d0eabf0c350371646af37961f
testRemoveFields
public void testRemoveFields() throws IOException
{    runKeepFieldsTest("none");        runKeepFieldsTest("false");}
377fb823f9f6a5d8239637a518a9e2a24b1784566a6cb82e2d228e5843bc15e6
testKeepHostname
public void testKeepHostname() throws IOException
{    runKeepFieldsTest("hostname");}
e8ab2dd23db39e87cd5b24b5c58987f66109c22d6adbeece7a50956bd55c3978
testKeepTimestamp
public void testKeepTimestamp() throws IOException
{    runKeepFieldsTest("timestamp");}
3e69a2e10490f19046a33091cc5b5c31847cfeb8a14a759f53053ea610acc2eb
testSourceCounter
public void testSourceCounter() throws IOException
{    runKeepFieldsTest("all");    assertEquals(10, source.getSourceCounter().getEventAcceptedCount());    assertEquals(10, source.getSourceCounter().getEventReceivedCount());}
acafc4af09bdb908a7194949f3024ccffa4498f4de7d43747bb3bd22c2c3b4f2
testSourceCounterChannelFail
public void testSourceCounterChannelFail() throws Exception
{    init("true");    errorCounterCommon(new ChannelException("dummy"));    for (int i = 0; i < 10 && source.getSourceCounter().getChannelWriteFail() == 0; i++) {        Thread.sleep(100);    }    assertEquals(1, source.getSourceCounter().getChannelWriteFail());}
c2fb038d160d4afc3911f6704827cfba20ce37624701715fd960f56859572c86
testSourceCounterEventFail
public void testSourceCounterEventFail() throws Exception
{    init("true");    errorCounterCommon(new RuntimeException("dummy"));    for (int i = 0; i < 10 && source.getSourceCounter().getEventReadFail() == 0; i++) {        Thread.sleep(100);    }    assertEquals(1, source.getSourceCounter().getEventReadFail());}
85d60a7e269b4c4476ff8170126536306fd32f6421f7dd7de2745e0a8fb0848d
errorCounterCommon
private void errorCounterCommon(Exception e) throws IOException
{    ChannelProcessor cp = Mockito.mock(ChannelProcessor.class);    doThrow(e).when(cp).processEvent(any(Event.class));    source.setChannelProcessor(cp);    source.start();        InetSocketAddress addr = source.getBoundAddress();    try (Socket syslogSocket = new Socket(addr.getAddress(), addr.getPort())) {        syslogSocket.getOutputStream().write(bodyWithTandH.getBytes());    }}
44d3747aa949fba480e3d03742550bc8ec29445c2ecc27c46a5f8d1566f6c4b6
testSSLMessages
public void testSSLMessages() throws Exception
{    initSsl();    source.start();    InetSocketAddress address = source.getBoundAddress();    SSLContext sslContext = SSLContext.getInstance("TLS");    sslContext.init(null, new TrustManager[] { new X509TrustManager() {        @Override        public void checkClientTrusted(X509Certificate[] certs, String s) {                }        @Override        public void checkServerTrusted(X509Certificate[] certs, String s) {                }        @Override        public X509Certificate[] getAcceptedIssuers() {            return new X509Certificate[0];        }    } }, null);    SocketFactory socketFactory = sslContext.getSocketFactory();    Socket socket = socketFactory.createSocket();    socket.connect(address);    OutputStream outputStream = socket.getOutputStream();    outputStream.write(bodyWithTandH.getBytes());    socket.close();        Transaction transaction = channel.getTransaction();    transaction.begin();    Event event = channel.take();    assertEquals(new String(event.getBody()), data1);    transaction.commit();    transaction.close();}
ff4e4a28c0a152e6e1627ea02e0bba88ca318bc15e775b9321ba555aa17a72e5
checkClientTrusted
public void checkClientTrusted(X509Certificate[] certs, String s)
{}
9c224c0159aa7449b31fb34da6b66aa554f1404356900809ff3fb435bc2ca415
checkServerTrusted
public void checkServerTrusted(X509Certificate[] certs, String s)
{}
b516c58bc22bde695ccdef782f17985d051ddc0b89329e35483cf2a3a576c7fe
getAcceptedIssuers
public X509Certificate[] getAcceptedIssuers()
{    return new X509Certificate[0];}
912c4f3aed86518d1c1e02d8712fe9360a78728cb5dee11a737ebaa1e16aeb2d
testClientHeaders
public void testClientHeaders() throws IOException
{    String testClientIPHeader = "testClientIPHeader";    String testClientHostnameHeader = "testClientHostnameHeader";    Context context = new Context();    context.put("clientIPHeader", testClientIPHeader);    context.put("clientHostnameHeader", testClientHostnameHeader);    init("none", context);    source.start();        InetSocketAddress addr = source.getBoundAddress();    Socket syslogSocket = new Socket(addr.getAddress(), addr.getPort());    syslogSocket.getOutputStream().write(bodyWithTandH.getBytes());    Transaction txn = channel.getTransaction();    txn.begin();    Event e = channel.take();    try {        txn.commit();    } catch (Throwable t) {        txn.rollback();    } finally {        txn.close();    }    source.stop();    Map<String, String> headers = e.getHeaders();    checkHeader(headers, testClientIPHeader, InetAddress.getLoopbackAddress().getHostAddress());    checkHeader(headers, testClientHostnameHeader, InetAddress.getLoopbackAddress().getHostName());}
a44f581323789d5e69d5381e5cad2b6a38afa08520b5904004e2fd1567cba8f2
checkHeader
private static void checkHeader(Map<String, String> headers, String headerName, String expectedValue)
{    assertTrue("Missing event header: " + headerName, headers.containsKey(headerName));    assertEquals("Event header value does not match: " + headerName, expectedValue, headers.get(headerName));}
0c7c2faf870bffbd8a89f2c4fc53472415077c0e35bfbf65d6f0f2328d14d3a5
init
private void init(String keepFields)
{    init(keepFields, new Context());}
037ece0f30486e0a9dbc2731be2dfd75865287e6ba8c7ac3b97e193aeb941e59
init
private void init(String keepFields, Context context)
{    source = new SyslogUDPSource();    channel = new MemoryChannel();    Configurables.configure(channel, new Context());    List<Channel> channels = new ArrayList<Channel>();    channels.add(channel);    ChannelSelector rcs = new ReplicatingChannelSelector();    rcs.setChannels(channels);    source.setChannelProcessor(new ChannelProcessor(rcs));    context.put("host", InetAddress.getLoopbackAddress().getHostAddress());    context.put("port", String.valueOf(TEST_SYSLOG_PORT));    context.put("keepFields", keepFields);    source.configure(context);}
fe0f215d7328c07ce78b6755a4f666b47290af292ffcee9c2b24103d5755ff79
runKeepFieldsTest
private void runKeepFieldsTest(String keepFields) throws IOException
{    init(keepFields);    source.start();        DatagramPacket datagramPacket = createDatagramPacket(bodyWithTandH.getBytes());    for (int i = 0; i < 10; i++) {        sendDatagramPacket(datagramPacket);    }    List<Event> channelEvents = new ArrayList<>();    Transaction txn = channel.getTransaction();    txn.begin();    for (int i = 0; i < 10; i++) {        Event e = channel.take();        Assert.assertNotNull(e);        channelEvents.add(e);    }    commitAndCloseTransaction(txn);    source.stop();    for (Event e : channelEvents) {        Assert.assertNotNull(e);        String str = new String(e.getBody(), Charsets.UTF_8);        logger.info(str);        if (keepFields.equals("true") || keepFields.equals("all")) {            Assert.assertArrayEquals(bodyWithTandH.trim().getBytes(), e.getBody());        } else if (keepFields.equals("false") || keepFields.equals("none")) {            Assert.assertArrayEquals(data1.getBytes(), e.getBody());        } else if (keepFields.equals("hostname")) {            Assert.assertArrayEquals(bodyWithHostname.getBytes(), e.getBody());        } else if (keepFields.equals("timestamp")) {            Assert.assertArrayEquals(bodyWithTimestamp.getBytes(), e.getBody());        }    }}
3cbc78eaff31d056a1e0d25e4e53f637188521118e072e9366611ccf9f7452cd
testLargePayload
public void testLargePayload() throws Exception
{    init("true");    source.start();        byte[] largePayload = getPayload(1000).getBytes();    DatagramPacket datagramPacket = createDatagramPacket(largePayload);    for (int i = 0; i < 10; i++) {        sendDatagramPacket(datagramPacket);    }    List<Event> channelEvents = new ArrayList<>();    Transaction txn = channel.getTransaction();    txn.begin();    for (int i = 0; i < 10; i++) {        Event e = channel.take();        Assert.assertNotNull(e);        channelEvents.add(e);    }    commitAndCloseTransaction(txn);    source.stop();    for (Event e : channelEvents) {        Assert.assertNotNull(e);        Assert.assertArrayEquals(largePayload, e.getBody());    }}
708d23e9c8cc2212b8063745610334cb366f5c62c578c1eba580a22db840696e
testKeepFields
public void testKeepFields() throws IOException
{    runKeepFieldsTest("all");        runKeepFieldsTest("true");}
519ca59b7801124d6f2641f49b8b52f666d6c83d0eabf0c350371646af37961f
testRemoveFields
public void testRemoveFields() throws IOException
{    runKeepFieldsTest("none");        runKeepFieldsTest("false");}
377fb823f9f6a5d8239637a518a9e2a24b1784566a6cb82e2d228e5843bc15e6
testKeepHostname
public void testKeepHostname() throws IOException
{    runKeepFieldsTest("hostname");}
e8ab2dd23db39e87cd5b24b5c58987f66109c22d6adbeece7a50956bd55c3978
testKeepTimestamp
public void testKeepTimestamp() throws IOException
{    runKeepFieldsTest("timestamp");}
bb4bd0cd6601ca643d38b7b6af1486643afa178a932dcd39ed591c9f29591e60
testSourceCounter
public void testSourceCounter() throws Exception
{    init("true");    doCounterCommon();        for (int i = 0; i < 10 && source.getSourceCounter().getEventAcceptedCount() == 0; i++) {        Thread.sleep(100);    }    Assert.assertEquals(1, source.getSourceCounter().getEventAcceptedCount());    Assert.assertEquals(1, source.getSourceCounter().getEventReceivedCount());}
c9e6fe818448a94adc60ddbb1d826f78737d8f4a157444a9f54581bf0b793647
doCounterCommon
private void doCounterCommon() throws IOException, InterruptedException
{    source.start();    DatagramPacket datagramPacket = createDatagramPacket("test".getBytes());    sendDatagramPacket(datagramPacket);}
acafc4af09bdb908a7194949f3024ccffa4498f4de7d43747bb3bd22c2c3b4f2
testSourceCounterChannelFail
public void testSourceCounterChannelFail() throws Exception
{    init("true");    ChannelProcessor cp = Mockito.mock(ChannelProcessor.class);    doThrow(new ChannelException("dummy")).when(cp).processEvent(any(Event.class));    source.setChannelProcessor(cp);    doCounterCommon();    for (int i = 0; i < 10 && source.getSourceCounter().getChannelWriteFail() == 0; i++) {        Thread.sleep(100);    }    Assert.assertEquals(1, source.getSourceCounter().getChannelWriteFail());}
7334596853b0550c8950a42716e7d03cfd7a243d2e6d5bee5d78702f5c25e5b0
testSourceCounterReadFail
public void testSourceCounterReadFail() throws Exception
{    init("true");    ChannelProcessor cp = Mockito.mock(ChannelProcessor.class);    doThrow(new RuntimeException("dummy")).when(cp).processEvent(any(Event.class));    source.setChannelProcessor(cp);    doCounterCommon();    for (int i = 0; i < 10 && source.getSourceCounter().getEventReadFail() == 0; i++) {        Thread.sleep(100);    }    Assert.assertEquals(1, source.getSourceCounter().getEventReadFail());}
f4e129eb10a23d88f30bb463805633703c943907d319e2f7fb0eed781492fc2b
createDatagramPacket
private DatagramPacket createDatagramPacket(byte[] payload)
{    InetSocketAddress addr = source.getBoundAddress();    return new DatagramPacket(payload, payload.length, addr.getAddress(), addr.getPort());}
1ec6cfc08931048a1704baa735bccb4f88c7b39360c13006834efef8659bead1
sendDatagramPacket
private void sendDatagramPacket(DatagramPacket datagramPacket) throws IOException
{    try (DatagramSocket syslogSocket = new DatagramSocket()) {        syslogSocket.send(datagramPacket);    }}
69cabdcdcc35f037de2c382b5cf8261ac3776e7bdcbf65fce71e46c872d7f4a6
commitAndCloseTransaction
private void commitAndCloseTransaction(Transaction txn)
{    try {        txn.commit();    } catch (Throwable t) {        logger.error("Transaction commit failed, rolling back", t);        txn.rollback();    } finally {        txn.close();    }}
370a8b17a844882ed82af28ad6d3de2caffabe42ef05e88612d6ca09767db5a3
getPayload
private String getPayload(int length)
{    StringBuilder payload = new StringBuilder(length);    for (int n = 0; n < length; ++n) {        payload.append("x");    }    return payload.toString();}
912c4f3aed86518d1c1e02d8712fe9360a78728cb5dee11a737ebaa1e16aeb2d
testClientHeaders
public void testClientHeaders() throws IOException
{    String testClientIPHeader = "testClientIPHeader";    String testClientHostnameHeader = "testClientHostnameHeader";    Context context = new Context();    context.put("clientIPHeader", testClientIPHeader);    context.put("clientHostnameHeader", testClientHostnameHeader);    init("none", context);    source.start();    DatagramPacket datagramPacket = createDatagramPacket(bodyWithTandH.getBytes());    sendDatagramPacket(datagramPacket);    Transaction txn = channel.getTransaction();    txn.begin();    Event e = channel.take();    commitAndCloseTransaction(txn);    source.stop();    Map<String, String> headers = e.getHeaders();    checkHeader(headers, testClientIPHeader, InetAddress.getLoopbackAddress().getHostAddress());    checkHeader(headers, testClientHostnameHeader, InetAddress.getLoopbackAddress().getHostName());}
a44f581323789d5e69d5381e5cad2b6a38afa08520b5904004e2fd1567cba8f2
checkHeader
private static void checkHeader(Map<String, String> headers, String headerName, String expectedValue)
{    assertTrue("Missing event header: " + headerName, headers.containsKey(headerName));    assertEquals("Event header value does not match: " + headerName, expectedValue, headers.get(headerName));}
2c3ffc5d2769e28d2d3c0be260732a529525624e489bf51939c38a5879e72464
TestHeader0
public void TestHeader0() throws ParseException
{    String stamp1 = "2012-04-13T11:11:11";    String format1 = "yyyy-MM-dd'T'HH:mm:ssZ";    String host1 = "ubuntu-11.cloudera.com";    String data1 = "some msg";        String msg1 = "<10>" + stamp1 + "+08:00" + " " + host1 + " " + data1 + "\n";    checkHeader(msg1, stamp1 + "+0800", format1, host1, data1);}
5224ba6e2ed07f8a5884a17968efd64ffa008b6ea09fa7d183c85d0103a5846c
TestHeader1
public void TestHeader1() throws ParseException
{    String stamp1 = "2012-04-13T11:11:11";    String format1 = "yyyy-MM-dd'T'HH:mm:ss";    String host1 = "ubuntu-11.cloudera.com";    String data1 = "some msg";    String msg1 = "<10>1 " + stamp1 + " " + host1 + " " + data1 + "\n";    checkHeader(msg1, stamp1, format1, host1, data1);}
f4d6a0ebcd9b2e92c30a76a9943a638220ce20c343b76189c1aa4982e0ac845b
TestHeader2
public void TestHeader2() throws ParseException
{    String stamp1 = "2012-04-13T11:11:11";    String format1 = "yyyy-MM-dd'T'HH:mm:ssZ";    String host1 = "ubuntu-11.cloudera.com";    String data1 = "some msg";        String msg1 = "<10>1 " + stamp1 + "Z" + " " + host1 + " " + data1 + "\n";    checkHeader(msg1, stamp1 + "+0000", format1, host1, data1);}
1f8f1dba57902e312ac861e9d3123013a89bac38af4164775fcf5e80a8e5fc6b
TestHeader3
public void TestHeader3() throws ParseException
{    String stamp1 = "2012-04-13T11:11:11";    String format1 = "yyyy-MM-dd'T'HH:mm:ssZ";    String host1 = "ubuntu-11.cloudera.com";    String data1 = "some msg";        String msg1 = "<10>1 " + stamp1 + "+08:00" + " " + host1 + " " + data1 + "\n";    checkHeader(msg1, stamp1 + "+0800", format1, host1, data1);}
84ba3de92126d26dfa5c0ff4e5d433ad346ee4f5c518c3eb6bc9909b13cbc7a7
TestHeader4
public void TestHeader4() throws ParseException
{    String host1 = "ubuntu-11.cloudera.com";    String data1 = "some msg";        String msg1 = "<10>1 " + "-" + " " + host1 + " " + data1 + "\n";    checkHeader(msg1, null, null, host1, data1);}
89bbc2a976cc681818220be0a37c68df649d8445bd42000547090a1d91f1193b
TestHeader5
public void TestHeader5() throws ParseException
{    String stamp1 = "2012-04-13T11:11:11";    String format1 = "yyyy-MM-dd'T'HH:mm:ss";    String host1 = "-";    String data1 = "some msg";        String msg1 = "<10>1 " + stamp1 + " " + host1 + " " + data1 + "\n";    checkHeader(msg1, stamp1, format1, null, data1);}
3dfd023864125de643ddd4613a5f2cb056ba3ace5c94799ad7dfd7e9b816cbbc
TestHeader6
public void TestHeader6() throws ParseException
{    String stamp1 = "2012-04-13T11:11:11";    String format1 = "yyyy-MM-dd'T'HH:mm:ssZ";    String host1 = "-";    String data1 = "some msg";        String msg1 = "<10>1 " + stamp1 + "Z" + " " + host1 + " " + data1 + "\n";    checkHeader(msg1, stamp1 + "+0000", format1, null, data1);}
ab29fadf064d48fc643d4bb0adf15da78be1af0efbb8dff97167b59cc9339119
TestHeader7
public void TestHeader7() throws ParseException
{    String stamp1 = "2012-04-13T11:11:11";    String format1 = "yyyy-MM-dd'T'HH:mm:ssZ";    String host1 = "-";    String data1 = "some msg";        String msg1 = "<10>1 " + stamp1 + "+08:00" + " " + host1 + " " + data1 + "\n";    checkHeader(msg1, stamp1 + "+0800", format1, null, data1);}
929ffab06e1a5fbf4a500b6c0604d9afb750fae8b74ac35691503201368d0f1e
TestHeader8
public void TestHeader8() throws ParseException
{    String stamp1 = "2012-04-13T11:11:11.999";    String format1 = "yyyy-MM-dd'T'HH:mm:ss.S";    String host1 = "ubuntu-11.cloudera.com";    String data1 = "some msg";    String msg1 = "<10>1 " + stamp1 + " " + host1 + " " + data1 + "\n";    checkHeader(msg1, stamp1, format1, host1, data1);}
f100117a44793d3c8d5728c09fb25ec1aad156a8068c3c8d00a8cde32af0d2c0
TestHeader9
public void TestHeader9() throws ParseException
{    SimpleDateFormat sdf = new SimpleDateFormat("MMM  d hh:MM:ss", Locale.ENGLISH);    Calendar cal = Calendar.getInstance();    String year = String.valueOf(cal.get(Calendar.YEAR));    String stamp1 = sdf.format(cal.getTime());    String format1 = "yyyyMMM d HH:mm:ss";    String host1 = "ubuntu-11.cloudera.com";    String data1 = "some msg";        String msg1 = "<10>" + stamp1 + " " + host1 + " " + data1 + "\n";    checkHeader(msg1, year + stamp1, format1, host1, data1);}
7d4bab082a064f1dd9e7b2e4ccb7c1e5b4e09e6431fda0f100b0dd4ea763a344
TestHeader10
public void TestHeader10() throws ParseException
{    SimpleDateFormat sdf = new SimpleDateFormat("MMM  d hh:MM:ss", Locale.ENGLISH);    Calendar cal = Calendar.getInstance();    String year = String.valueOf(cal.get(Calendar.YEAR));    String stamp1 = sdf.format(cal.getTime());    String format1 = "yyyyMMM d HH:mm:ss";    String host1 = "ubuntu-11.cloudera.com";    String data1 = "some msg";        String msg1 = "<10>" + stamp1 + " " + host1 + " " + data1 + "\n";    checkHeader(msg1, year + stamp1, format1, host1, data1);}
8244a714e328c9da309123f0b9ccc491128e48070f1d78a06ae8fc182a7ac04f
TestHeader11
public void TestHeader11() throws ParseException
{            String inputStamp = "2014-10-03T17:20:01.123456-07:00";    String outputStamp = "2014-10-03T17:20:01.123-07:00";    String format1 = "yyyy-MM-dd'T'HH:mm:ss.S";    String host1 = "ubuntu-11.cloudera.com";    String data1 = "some msg";    String msg1 = "<10>" + inputStamp + " " + host1 + " " + data1 + "\n";    checkHeader(msg1, outputStamp, format1, host1, data1);}
aee9dcf284f67c1f4b6f1235bbf15bdfe5e8c1a3d49092d73c7d6e92c58e1969
TestRfc3164HeaderApacheLogWithNulls
public void TestRfc3164HeaderApacheLogWithNulls() throws ParseException
{    SimpleDateFormat sdf = new SimpleDateFormat("MMM  d hh:MM:ss", Locale.ENGLISH);    Calendar cal = Calendar.getInstance();    String year = String.valueOf(cal.get(Calendar.YEAR));    String stamp1 = sdf.format(cal.getTime());    String format1 = "yyyyMMM d HH:mm:ss";    String host1 = "ubuntu-11.cloudera.com";    String data1 = "- hyphen_null_breaks_5424_pattern [07/Jun/2012:14:46:44 -0600]";    String msg1 = "<10>" + stamp1 + " " + host1 + " " + data1 + "\n";    checkHeader(msg1, year + stamp1, format1, host1, data1);}
d1770f0f5de5c5239bdd99f982454a909ab1f433d3878247f8f2999b31b34321
TestRfc3164Dates
public void TestRfc3164Dates() throws ParseException
{        for (int monthOffset = 0; monthOffset <= 13; monthOffset++) {        Clock mockClock = Clock.fixed(LocalDateTime.now().plusMonths(monthOffset).toInstant(ZoneOffset.UTC), Clock.systemDefaultZone().getZone());                for (int i = -10; i <= 1; i++) {            SimpleDateFormat sdf = new SimpleDateFormat("MMM  d hh:MM:ss", Locale.ENGLISH);            Date date = new Date(mockClock.millis());            Calendar cal = Calendar.getInstance();            cal.setTime(date);            cal.add(Calendar.MONTH, i);                        if (i == 1) {                cal.add(Calendar.DAY_OF_MONTH, -1);            }            String stamp1 = sdf.format(cal.getTime());            String year = String.valueOf(cal.get(Calendar.YEAR));            String format1 = "yyyyMMM d HH:mm:ss";            String host1 = "ubuntu-11.cloudera.com";            String data1 = "some msg";                        String msg1 = "<10>" + stamp1 + " " + host1 + " " + data1 + "\n";            checkHeader(msg1, year + stamp1, format1, host1, data1, mockClock);        }    }}
19ebc7a258d728a1a4b3a954c9062cdc5fb4761f907aacbaafdb654c3cef0e41
checkHeader
public static void checkHeader(String keepFields, String msg1, String stamp1, String format1, String host1, String data1, Clock clock) throws ParseException
{    SyslogUtils util;    if (keepFields == null || keepFields.isEmpty()) {        util = new SyslogUtils(SyslogUtils.DEFAULT_SIZE, new HashSet<String>(), false, clock);    } else {        util = new SyslogUtils(SyslogUtils.DEFAULT_SIZE, SyslogUtils.chooseFieldsToKeep(keepFields), false, clock);    }    ChannelBuffer buff = ChannelBuffers.buffer(200);    buff.writeBytes(msg1.getBytes());    Event e = util.extractEvent(buff);    if (e == null) {        throw new NullPointerException("Event is null");    }    Map<String, String> headers2 = e.getHeaders();    if (stamp1 == null) {        Assert.assertFalse(headers2.containsKey("timestamp"));    } else {        SimpleDateFormat formater = new SimpleDateFormat(format1, Locale.ENGLISH);        Assert.assertEquals(String.valueOf(formater.parse(stamp1).getTime()), headers2.get("timestamp"));    }    if (host1 == null) {        Assert.assertFalse(headers2.containsKey("host"));    } else {        String host2 = headers2.get("host");        Assert.assertEquals(host2, host1);    }    Assert.assertEquals(data1, new String(e.getBody()));}
793bca0324a108e4344806d92c0fa76c04ed75ac72d135a702c06176f34a99bf
checkHeader
public static void checkHeader(String keepFields, String msg1, String stamp1, String format1, String host1, String data1) throws ParseException
{    checkHeader(keepFields, msg1, stamp1, format1, host1, data1, Clock.system(Clock.systemDefaultZone().getZone()));}
dbce7a7e9766de29a67eac65c7ab15c65496fbd561678662a40f78dab30076a5
checkHeader
public static void checkHeader(String msg1, String stamp1, String format1, String host1, String data1, Clock clock) throws ParseException
{    checkHeader("none", msg1, stamp1, format1, host1, data1, clock);}
f53e71a014e827faf8d8283ba879e51efaf329ff89cf352c27036762143e3bde
checkHeader
public static void checkHeader(String msg1, String stamp1, String format1, String host1, String data1) throws ParseException
{    checkHeader("none", msg1, stamp1, format1, host1, data1, Clock.system(Clock.systemDefaultZone().getZone()));}
26f7b823e57cf092dee95cbd72a320987290172dba367067620f43d21a55f05b
testExtractBadEvent1
public void testExtractBadEvent1()
{    String badData1 = "<10F> bad bad data\n";    SyslogUtils util = new SyslogUtils(false);    ChannelBuffer buff = ChannelBuffers.buffer(100);    buff.writeBytes(badData1.getBytes());    Event e = util.extractEvent(buff);    if (e == null) {        throw new NullPointerException("Event is null");    }    Map<String, String> headers = e.getHeaders();    Assert.assertEquals("0", headers.get(SyslogUtils.SYSLOG_FACILITY));    Assert.assertEquals("0", headers.get(SyslogUtils.SYSLOG_SEVERITY));    Assert.assertEquals(SyslogUtils.SyslogStatus.INVALID.getSyslogStatus(), headers.get(SyslogUtils.EVENT_STATUS));    Assert.assertEquals(badData1.trim(), new String(e.getBody()).trim());}
06dea33ed0d6b3e960dae01a486f01d9c9416ffa55e7f69d6e82e14764642851
testExtractBadEvent2
public void testExtractBadEvent2()
{    String badData1 = "hi guys! <10> bad bad data\n";    SyslogUtils util = new SyslogUtils(false);    ChannelBuffer buff = ChannelBuffers.buffer(100);    buff.writeBytes(badData1.getBytes());    Event e = util.extractEvent(buff);    if (e == null) {        throw new NullPointerException("Event is null");    }    Map<String, String> headers = e.getHeaders();    Assert.assertEquals("0", headers.get(SyslogUtils.SYSLOG_FACILITY));    Assert.assertEquals("0", headers.get(SyslogUtils.SYSLOG_SEVERITY));    Assert.assertEquals(SyslogUtils.SyslogStatus.INVALID.getSyslogStatus(), headers.get(SyslogUtils.EVENT_STATUS));    Assert.assertEquals(badData1.trim(), new String(e.getBody()).trim());}
53193b17f4f0b10c4bd33aa426a27870927d5d25157e975f1e746ca7354d2313
testExtractBadEvent3
public void testExtractBadEvent3()
{    String badData1 = "<> bad bad data\n";    SyslogUtils util = new SyslogUtils(false);    ChannelBuffer buff = ChannelBuffers.buffer(100);    buff.writeBytes(badData1.getBytes());    Event e = util.extractEvent(buff);    if (e == null) {        throw new NullPointerException("Event is null");    }    Map<String, String> headers = e.getHeaders();    Assert.assertEquals("0", headers.get(SyslogUtils.SYSLOG_FACILITY));    Assert.assertEquals("0", headers.get(SyslogUtils.SYSLOG_SEVERITY));    Assert.assertEquals(SyslogUtils.SyslogStatus.INVALID.getSyslogStatus(), headers.get(SyslogUtils.EVENT_STATUS));    Assert.assertEquals(badData1.trim(), new String(e.getBody()).trim());}
529107d7fb8dbe572ed3fa599691986904ce43ae834f4edca8686c3eba9858f0
testExtractBadEvent4
public void testExtractBadEvent4()
{    String badData1 = "<123123123123123123123123123123> bad bad data\n";    SyslogUtils util = new SyslogUtils(false);    ChannelBuffer buff = ChannelBuffers.buffer(100);    buff.writeBytes(badData1.getBytes());    Event e = util.extractEvent(buff);    if (e == null) {        throw new NullPointerException("Event is null");    }    Map<String, String> headers = e.getHeaders();    Assert.assertEquals("0", headers.get(SyslogUtils.SYSLOG_FACILITY));    Assert.assertEquals("0", headers.get(SyslogUtils.SYSLOG_SEVERITY));    Assert.assertEquals(SyslogUtils.SyslogStatus.INVALID.getSyslogStatus(), headers.get(SyslogUtils.EVENT_STATUS));    Assert.assertEquals(badData1.trim(), new String(e.getBody()).trim());}
f3569b805b2288f4a08a5487bedfceef0dba39e5d8fb71a41724711d4d39ad9d
testExtractGoodEvent
public void testExtractGoodEvent()
{    String priority = "<10>";    String goodData1 = "Good good good data\n";    SyslogUtils util = new SyslogUtils(false);    ChannelBuffer buff = ChannelBuffers.buffer(100);    buff.writeBytes((priority + goodData1).getBytes());    Event e = util.extractEvent(buff);    if (e == null) {        throw new NullPointerException("Event is null");    }    Map<String, String> headers = e.getHeaders();    Assert.assertEquals("1", headers.get(SyslogUtils.SYSLOG_FACILITY));    Assert.assertEquals("2", headers.get(SyslogUtils.SYSLOG_SEVERITY));    Assert.assertEquals(null, headers.get(SyslogUtils.EVENT_STATUS));    Assert.assertEquals(priority + goodData1.trim(), new String(e.getBody()).trim());}
5688a2938c0aad45da785fd27da5f3e56d6ee4cda6a89a9a19a1880ffc215cac
testBadEventGoodEvent
public void testBadEventGoodEvent()
{    String badData1 = "hi guys! <10F> bad bad data\n";    SyslogUtils util = new SyslogUtils(false);    ChannelBuffer buff = ChannelBuffers.buffer(100);    buff.writeBytes(badData1.getBytes());    String priority = "<10>";    String goodData1 = "Good good good data\n";    buff.writeBytes((priority + goodData1).getBytes());    Event e = util.extractEvent(buff);    if (e == null) {        throw new NullPointerException("Event is null");    }    Map<String, String> headers = e.getHeaders();    Assert.assertEquals("0", headers.get(SyslogUtils.SYSLOG_FACILITY));    Assert.assertEquals("0", headers.get(SyslogUtils.SYSLOG_SEVERITY));    Assert.assertEquals(SyslogUtils.SyslogStatus.INVALID.getSyslogStatus(), headers.get(SyslogUtils.EVENT_STATUS));    Assert.assertEquals(badData1.trim(), new String(e.getBody()).trim());    Event e2 = util.extractEvent(buff);    if (e2 == null) {        throw new NullPointerException("Event is null");    }    Map<String, String> headers2 = e2.getHeaders();    Assert.assertEquals("1", headers2.get(SyslogUtils.SYSLOG_FACILITY));    Assert.assertEquals("2", headers2.get(SyslogUtils.SYSLOG_SEVERITY));    Assert.assertEquals(null, headers2.get(SyslogUtils.EVENT_STATUS));    Assert.assertEquals(priority + goodData1.trim(), new String(e2.getBody()).trim());}
87964e9ffb550f276d14a64ffd1e4c7e6430d21a7b845ea1ef01cc8f8fac6c16
testGoodEventBadEvent
public void testGoodEventBadEvent()
{    String badData1 = "hi guys! <10F> bad bad data\n";    String priority = "<10>";    String goodData1 = "Good good good data\n";    SyslogUtils util = new SyslogUtils(false);    ChannelBuffer buff = ChannelBuffers.buffer(100);    buff.writeBytes((priority + goodData1).getBytes());    buff.writeBytes(badData1.getBytes());    Event e2 = util.extractEvent(buff);    if (e2 == null) {        throw new NullPointerException("Event is null");    }    Map<String, String> headers2 = e2.getHeaders();    Assert.assertEquals("1", headers2.get(SyslogUtils.SYSLOG_FACILITY));    Assert.assertEquals("2", headers2.get(SyslogUtils.SYSLOG_SEVERITY));    Assert.assertEquals(null, headers2.get(SyslogUtils.EVENT_STATUS));    Assert.assertEquals(priority + goodData1.trim(), new String(e2.getBody()).trim());    Event e = util.extractEvent(buff);    if (e == null) {        throw new NullPointerException("Event is null");    }    Map<String, String> headers = e.getHeaders();    Assert.assertEquals("0", headers.get(SyslogUtils.SYSLOG_FACILITY));    Assert.assertEquals("0", headers.get(SyslogUtils.SYSLOG_SEVERITY));    Assert.assertEquals(SyslogUtils.SyslogStatus.INVALID.getSyslogStatus(), headers.get(SyslogUtils.EVENT_STATUS));    Assert.assertEquals(badData1.trim(), new String(e.getBody()).trim());}
d93723215bf39535ce4014eaa2ec123db20c1a160c3f84f44d5a056ef9bcd4b4
testBadEventBadEvent
public void testBadEventBadEvent()
{    String badData1 = "hi guys! <10F> bad bad data\n";    SyslogUtils util = new SyslogUtils(false);    ChannelBuffer buff = ChannelBuffers.buffer(100);    buff.writeBytes(badData1.getBytes());    String badData2 = "hi guys! <20> bad bad data\n";    buff.writeBytes((badData2).getBytes());    Event e = util.extractEvent(buff);    if (e == null) {        throw new NullPointerException("Event is null");    }    Map<String, String> headers = e.getHeaders();    Assert.assertEquals("0", headers.get(SyslogUtils.SYSLOG_FACILITY));    Assert.assertEquals("0", headers.get(SyslogUtils.SYSLOG_SEVERITY));    Assert.assertEquals(SyslogUtils.SyslogStatus.INVALID.getSyslogStatus(), headers.get(SyslogUtils.EVENT_STATUS));    Assert.assertEquals(badData1.trim(), new String(e.getBody()).trim());    Event e2 = util.extractEvent(buff);    if (e2 == null) {        throw new NullPointerException("Event is null");    }    Map<String, String> headers2 = e2.getHeaders();    Assert.assertEquals("0", headers2.get(SyslogUtils.SYSLOG_FACILITY));    Assert.assertEquals("0", headers2.get(SyslogUtils.SYSLOG_SEVERITY));    Assert.assertEquals(SyslogUtils.SyslogStatus.INVALID.getSyslogStatus(), headers2.get(SyslogUtils.EVENT_STATUS));    Assert.assertEquals(badData2.trim(), new String(e2.getBody()).trim());}
880f01a7464f5b5b40950023268304222fd51f5fc007945a8052b36d83a428fa
testGoodEventGoodEvent
public void testGoodEventGoodEvent()
{    String priority = "<10>";    String goodData1 = "Good good good data\n";    SyslogUtils util = new SyslogUtils(false);    ChannelBuffer buff = ChannelBuffers.buffer(100);    buff.writeBytes((priority + goodData1).getBytes());    String priority2 = "<20>";    String goodData2 = "Good really good data\n";    buff.writeBytes((priority2 + goodData2).getBytes());    Event e = util.extractEvent(buff);    if (e == null) {        throw new NullPointerException("Event is null");    }    Map<String, String> headers = e.getHeaders();    Assert.assertEquals("1", headers.get(SyslogUtils.SYSLOG_FACILITY));    Assert.assertEquals("2", headers.get(SyslogUtils.SYSLOG_SEVERITY));    Assert.assertEquals(null, headers.get(SyslogUtils.EVENT_STATUS));    Assert.assertEquals(priority + goodData1.trim(), new String(e.getBody()).trim());    Event e2 = util.extractEvent(buff);    if (e2 == null) {        throw new NullPointerException("Event is null");    }    Map<String, String> headers2 = e2.getHeaders();    Assert.assertEquals("2", headers2.get(SyslogUtils.SYSLOG_FACILITY));    Assert.assertEquals("4", headers2.get(SyslogUtils.SYSLOG_SEVERITY));    Assert.assertEquals(null, headers.get(SyslogUtils.EVENT_STATUS));    Assert.assertEquals(priority2 + goodData2.trim(), new String(e2.getBody()).trim());}
529abca0b51f6179c2200959600e9b035713d6824494500dc182eb4416421d08
testExtractBadEventLarge
public void testExtractBadEventLarge()
{    String badData1 = "<10> bad bad data bad bad\n";        SyslogUtils util = new SyslogUtils(5, null, false);    ChannelBuffer buff = ChannelBuffers.buffer(100);    buff.writeBytes(badData1.getBytes());    Event e = util.extractEvent(buff);    if (e == null) {        throw new NullPointerException("Event is null");    }    Map<String, String> headers = e.getHeaders();    Assert.assertEquals("1", headers.get(SyslogUtils.SYSLOG_FACILITY));    Assert.assertEquals("2", headers.get(SyslogUtils.SYSLOG_SEVERITY));    Assert.assertEquals(SyslogUtils.SyslogStatus.INCOMPLETE.getSyslogStatus(), headers.get(SyslogUtils.EVENT_STATUS));    Assert.assertEquals("<10> bad b".trim(), new String(e.getBody()).trim());    Event e2 = util.extractEvent(buff);    if (e2 == null) {        throw new NullPointerException("Event is null");    }    Map<String, String> headers2 = e2.getHeaders();    Assert.assertEquals("0", headers2.get(SyslogUtils.SYSLOG_FACILITY));    Assert.assertEquals("0", headers2.get(SyslogUtils.SYSLOG_SEVERITY));    Assert.assertEquals(SyslogUtils.SyslogStatus.INVALID.getSyslogStatus(), headers2.get(SyslogUtils.EVENT_STATUS));    Assert.assertEquals("ad data ba".trim(), new String(e2.getBody()).trim());}
08e9736a31f90f6022ae77301ad0dc3756d01e9ebf00b8fd465df2157ecfd366
testKeepFields
public void testKeepFields() throws Exception
{    String stamp1 = "2012-04-13T11:11:11";    String format1 = "yyyy-MM-dd'T'HH:mm:ssZ";    String host1 = "ubuntu-11.cloudera.com";    String data1 = "some msg";        String msg1 = "<10>1 " + stamp1 + "+08:00" + " " + host1 + " " + data1 + "\n";    checkHeader("none", msg1, stamp1 + "+0800", format1, host1, data1);    checkHeader("false", msg1, stamp1 + "+0800", format1, host1, data1);    String data2 = "ubuntu-11.cloudera.com some msg";    checkHeader("hostname", msg1, stamp1 + "+0800", format1, host1, data2);    String data3 = "2012-04-13T11:11:11+08:00 ubuntu-11.cloudera.com some msg";    checkHeader("timestamp hostname", msg1, stamp1 + "+0800", format1, host1, data3);    String data4 = "<10>2012-04-13T11:11:11+08:00 ubuntu-11.cloudera.com some msg";    checkHeader("priority timestamp hostname", msg1, stamp1 + "+0800", format1, host1, data4);    String data5 = "<10>1 2012-04-13T11:11:11+08:00 ubuntu-11.cloudera.com some msg";    checkHeader("priority version timestamp hostname", msg1, stamp1 + "+0800", format1, host1, data5);    checkHeader("all", msg1, stamp1 + "+0800", format1, host1, data5);    checkHeader("true", msg1, stamp1 + "+0800", format1, host1, data5);}
f24dcb4eae5431f762c36ad3772221a49ac976cc54980a1ad3cea6663cbfa967
testGetIPWhenSuccessful
public void testGetIPWhenSuccessful()
{    SocketAddress socketAddress = new InetSocketAddress("localhost", 2000);    String ip = SyslogUtils.getIP(socketAddress);    assertEquals("127.0.0.1", ip);}
cdfd9aab66cf9fee3fb713208e017bdb54429e14726625a7fdfdb6cd972f2ec9
testGetIPWhenInputIsNull
public void testGetIPWhenInputIsNull()
{    SocketAddress socketAddress = null;    String ip = SyslogUtils.getIP(socketAddress);    assertEquals("", ip);}
92340ecddc639db95646c31715215a177aae05f18dd64e24cc68e4617dcffe84
testGetIPWhenInputIsNotInetSocketAddress
public void testGetIPWhenInputIsNotInetSocketAddress()
{    SocketAddress socketAddress = new SocketAddress() {    };    String ip = SyslogUtils.getIP(socketAddress);    assertEquals("", ip);}
0976472ee9dbef8266e7be3dfd94d5b6fb34426d597d82238c35bf7e1bc60f6c
testGetHostnameWhenSuccessful
public void testGetHostnameWhenSuccessful()
{    SocketAddress socketAddress = new InetSocketAddress("127.0.0.1", 2000);    String hostname = SyslogUtils.getHostname(socketAddress);    assertEquals("localhost", hostname);}
2b869cd4125a7773f33463a78fef7c1a21cd81dfe6254db664874700c3bb90ee
testGetHostnameWhenInputIsNull
public void testGetHostnameWhenInputIsNull()
{    SocketAddress socketAddress = null;    String hostname = SyslogUtils.getHostname(socketAddress);    assertEquals("", hostname);}
dd7c05d277e3eeca179469cfb6738079598e78845bbababb3a0b2fff6590aa4d
testGetHostnameWhenInputIsNotInetSocketAddress
public void testGetHostnameWhenInputIsNotInetSocketAddress()
{    SocketAddress socketAddress = new SocketAddress() {    };    String hostname = SyslogUtils.getHostname(socketAddress);    assertEquals("", hostname);}
c536957a0359efaba4fa041a9429ed02027b66c9e6f5cc21d07eb308cc675a0d
setUp
public void setUp() throws IOException
{    try (ServerSocket socket = new ServerSocket(0)) {        port = socket.getLocalPort();    }    props.clear();    props.setProperty("hosts", "h1");    props.setProperty("hosts.h1", "0.0.0.0:" + String.valueOf(port));    props.setProperty(RpcClientConfigurationConstants.CONFIG_BATCH_SIZE, "10");    props.setProperty(RpcClientConfigurationConstants.CONFIG_REQUEST_TIMEOUT, "2000");    channel = new MemoryChannel();    source = new ThriftSource();}
58a3bb0fa8ecc3e0a1306beb26f516223d2bf3d47efcbf1262a44af030c64a22
stop
public void stop() throws Exception
{    source.stop();}
f8da1974006e3fc9b0f1d89ba39da6e2d271c0c203e111198231232d6e29e721
configureSource
private void configureSource()
{    List<Channel> channels = new ArrayList<Channel>();    channels.add(channel);    ChannelSelector rcs = new ReplicatingChannelSelector();    rcs.setChannels(channels);    source.setChannelProcessor(new ChannelProcessor(rcs));}
1ed41e108e741f7132266f3f097639a3bf3e68286a9f2e6eac2ceffd48140bd5
testAppendSSLWithComponentKeystore
public void testAppendSSLWithComponentKeystore() throws Exception
{    Context context = new Context();    channel.configure(context);    configureSource();    context.put(ThriftSource.CONFIG_BIND, "0.0.0.0");    context.put(ThriftSource.CONFIG_PORT, String.valueOf(port));    context.put("ssl", "true");    context.put("keystore", "src/test/resources/keystorefile.jks");    context.put("keystore-password", "password");    context.put("keystore-type", "JKS");    Configurables.configure(source, context);    doAppendSSL();}
bf838b3712a1fad118f4a1f3dd36261bdcff7513e39076a20862893e5eb43f73
testAppendSSLWithGlobalKeystore
public void testAppendSSLWithGlobalKeystore() throws Exception
{    System.setProperty("javax.net.ssl.keyStore", "src/test/resources/keystorefile.jks");    System.setProperty("javax.net.ssl.keyStorePassword", "password");    System.setProperty("javax.net.ssl.keyStoreType", "JKS");    Context context = new Context();    channel.configure(context);    configureSource();    context.put(ThriftSource.CONFIG_BIND, "0.0.0.0");    context.put(ThriftSource.CONFIG_PORT, String.valueOf(port));    context.put("ssl", "true");    Configurables.configure(source, context);    doAppendSSL();    System.clearProperty("javax.net.ssl.keyStore");    System.clearProperty("javax.net.ssl.keyStorePassword");    System.clearProperty("javax.net.ssl.keyStoreType");}
3dec85c784a4eb7766a715fdd7856bb097d6ac029edbe608d917f5d8df45eda0
doAppendSSL
private void doAppendSSL() throws EventDeliveryException
{    Properties sslprops = (Properties) props.clone();    sslprops.put("ssl", "true");    sslprops.put("truststore", "src/test/resources/truststorefile.jks");    sslprops.put("truststore-password", "password");    client = RpcClientFactory.getThriftInstance(sslprops);    source.start();    for (int i = 0; i < 30; i++) {        client.append(EventBuilder.withBody(String.valueOf(i).getBytes()));    }    Transaction transaction = channel.getTransaction();    transaction.begin();    for (int i = 0; i < 30; i++) {        Event event = channel.take();        Assert.assertNotNull(event);        Assert.assertEquals(String.valueOf(i), new String(event.getBody()));    }    transaction.commit();    transaction.close();}
a6c188d62e287a81a3d76adfe357c1145dd1fa7a2ac4296a0f849b4bc89108e1
testAppend
public void testAppend() throws Exception
{    client = RpcClientFactory.getThriftInstance(props);    Context context = new Context();    channel.configure(context);    configureSource();    context.put(ThriftSource.CONFIG_BIND, "0.0.0.0");    context.put(ThriftSource.CONFIG_PORT, String.valueOf(port));    Configurables.configure(source, context);    source.start();    for (int i = 0; i < 30; i++) {        client.append(EventBuilder.withBody(String.valueOf(i).getBytes()));    }    Transaction transaction = channel.getTransaction();    transaction.begin();    for (int i = 0; i < 30; i++) {        Event event = channel.take();        Assert.assertNotNull(event);        Assert.assertEquals(String.valueOf(i), new String(event.getBody()));    }    transaction.commit();    transaction.close();}
f8d601636a051250ad517a6e5cdccf8ac880337199d5623c85860ffa5a1731d8
testAppendBatch
public void testAppendBatch() throws Exception
{    client = RpcClientFactory.getThriftInstance(props);    Context context = new Context();    context.put("capacity", "1000");    context.put("transactionCapacity", "1000");    channel.configure(context);    configureSource();    context.put(ThriftSource.CONFIG_BIND, "0.0.0.0");    context.put(ThriftSource.CONFIG_PORT, String.valueOf(port));    Configurables.configure(source, context);    source.start();    for (int i = 0; i < 30; i++) {        List<Event> events = Lists.newArrayList();        for (int j = 0; j < 10; j++) {            Map<String, String> hdrs = Maps.newHashMap();            hdrs.put("time", String.valueOf(System.currentTimeMillis()));            events.add(EventBuilder.withBody(String.valueOf(i).getBytes(), hdrs));        }        client.appendBatch(events);    }    Transaction transaction = channel.getTransaction();    transaction.begin();    long after = System.currentTimeMillis();    List<Integer> events = Lists.newArrayList();    for (int i = 0; i < 300; i++) {        Event event = channel.take();        Assert.assertNotNull(event);        Assert.assertTrue(Long.valueOf(event.getHeaders().get("time")) <= after);        events.add(Integer.parseInt(new String(event.getBody())));    }    transaction.commit();    transaction.close();    Collections.sort(events);    int index = 0;        for (int i = 0; i < 30; i++) {        for (int j = 0; j < 10; j++) {            Assert.assertEquals(i, events.get(index++).intValue());        }    }}
3659152e954d1a832382854168c26415485d6dd8397e59b6976fa18ec2d5a19b
testAppendBigBatch
public void testAppendBigBatch() throws Exception
{    client = RpcClientFactory.getThriftInstance(props);    Context context = new Context();    context.put("capacity", "3000");    context.put("transactionCapacity", "3000");    channel.configure(context);    configureSource();    context.put(ThriftSource.CONFIG_BIND, "0.0.0.0");    context.put(ThriftSource.CONFIG_PORT, String.valueOf(port));    Configurables.configure(source, context);    source.start();    for (int i = 0; i < 5; i++) {        List<Event> events = Lists.newArrayList();        for (int j = 0; j < 500; j++) {            Map<String, String> hdrs = Maps.newHashMap();            hdrs.put("time", String.valueOf(System.currentTimeMillis()));            events.add(EventBuilder.withBody(String.valueOf(i).getBytes(), hdrs));        }        client.appendBatch(events);    }    Transaction transaction = channel.getTransaction();    transaction.begin();    long after = System.currentTimeMillis();    List<Integer> events = Lists.newArrayList();    for (int i = 0; i < 2500; i++) {        Event event = channel.take();        Assert.assertNotNull(event);        Assert.assertTrue(Long.valueOf(event.getHeaders().get("time")) < after);        events.add(Integer.parseInt(new String(event.getBody())));    }    transaction.commit();    transaction.close();    Collections.sort(events);    int index = 0;        for (int i = 0; i < 5; i++) {        for (int j = 0; j < 500; j++) {            Assert.assertEquals(i, events.get(index++).intValue());        }    }}
18c6614a92015c646a9fc33e949b72456e75d40ec42178060264cb4b8c43177e
testMultipleClients
public void testMultipleClients() throws Exception
{    ExecutorService submitter = Executors.newCachedThreadPool();    client = RpcClientFactory.getThriftInstance(props);    Context context = new Context();    context.put("capacity", "1000");    context.put("transactionCapacity", "1000");    channel.configure(context);    configureSource();    context.put(ThriftSource.CONFIG_BIND, "0.0.0.0");    context.put(ThriftSource.CONFIG_PORT, String.valueOf(port));    Configurables.configure(source, context);    source.start();    ExecutorCompletionService<Void> completionService = new ExecutorCompletionService<>(submitter);    for (int i = 0; i < 30; i++) {        completionService.submit(new SubmitHelper(i), null);    }    for (int i = 0; i < 30; i++) {        completionService.take();    }    Transaction transaction = channel.getTransaction();    transaction.begin();    long after = System.currentTimeMillis();    List<Integer> events = Lists.newArrayList();    for (int i = 0; i < 300; i++) {        Event event = channel.take();        Assert.assertNotNull(event);        Assert.assertTrue(Long.valueOf(event.getHeaders().get("time")) < after);        events.add(Integer.parseInt(new String(event.getBody())));    }    transaction.commit();    transaction.close();    Collections.sort(events);    int index = 0;        for (int i = 0; i < 30; i++) {        for (int j = 0; j < 10; j++) {            Assert.assertEquals(i, events.get(index++).intValue());        }    }}
842ce523cd5b575230a4e53c3d57d7b83c10bc784cdf87d5c299626f97ef80e0
testErrorCounterChannelWriteFail
public void testErrorCounterChannelWriteFail() throws Exception
{    client = RpcClientFactory.getThriftInstance(props);    Context context = new Context();    context.put(ThriftSource.CONFIG_BIND, "0.0.0.0");    context.put(ThriftSource.CONFIG_PORT, String.valueOf(port));    source.configure(context);    ChannelProcessor cp = Mockito.mock(ChannelProcessor.class);    doThrow(new ChannelException("dummy")).when(cp).processEvent(any(Event.class));    doThrow(new ChannelException("dummy")).when(cp).processEventBatch(anyListOf(Event.class));    source.setChannelProcessor(cp);    source.start();    Event event = EventBuilder.withBody("hello".getBytes());    try {        client.append(event);    } catch (EventDeliveryException e) {        }    try {        client.appendBatch(Arrays.asList(event));    } catch (EventDeliveryException e) {        }    SourceCounter sc = (SourceCounter) Whitebox.getInternalState(source, "sourceCounter");    Assert.assertEquals(2, sc.getChannelWriteFail());    source.stop();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    List<Event> events = Lists.newArrayList();    for (int j = 0; j < 10; j++) {        Map<String, String> hdrs = Maps.newHashMap();        hdrs.put("time", String.valueOf(System.currentTimeMillis()));        events.add(EventBuilder.withBody(String.valueOf(i).getBytes(), hdrs));    }    try {        client.appendBatch(events);    } catch (EventDeliveryException e) {        throw new FlumeException(e);    }}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    context = new Context();}
187565b5d08ecbb7fe6a4fb4b8b23c3b997dbe3836e68259bcd57dfd2f8bd6f6
testPutGet
public void testPutGet()
{    assertEquals("Context is empty", 0, context.getParameters().size());    context.put("test", "value");    assertEquals("value", context.getString("test"));    context.clear();    assertNull(context.getString("test"));    assertEquals("value", context.getString("test", "value"));    context.put("test", "true");    assertEquals(new Boolean(true), context.getBoolean("test"));    context.clear();    assertNull(context.getBoolean("test"));    assertEquals(new Boolean(true), context.getBoolean("test", true));    context.put("test", "1");    assertEquals(new Integer(1), context.getInteger("test"));    context.clear();    assertNull(context.getInteger("test"));    assertEquals(new Integer(1), context.getInteger("test", 1));    context.put("test", String.valueOf(Long.MAX_VALUE));    assertEquals(new Long(Long.MAX_VALUE), context.getLong("test"));    context.clear();    assertNull(context.getLong("test"));    assertEquals(new Long(Long.MAX_VALUE), context.getLong("test", Long.MAX_VALUE));    context.put("test", "0.1");    assertEquals(new Float(0.1), context.getFloat("test"));    context.clear();    assertNull(context.getFloat("test"));    assertEquals(new Float(1.1), context.getFloat("test", 1.1F));    context.put("test", "0.1");    assertEquals(new Double(0.1), context.getDouble("test"));    context.clear();    assertNull(context.getDouble("test"));    assertEquals(new Double(1.1), context.getDouble("test", 1.1));}
9d8e052f67dd360fcbb68f951a683831caaba1e23baf641a666735396712c2ae
testSubProperties
public void testSubProperties()
{    context.put("my.key", "1");    context.put("otherKey", "otherValue");    assertEquals(ImmutableMap.of("key", "1"), context.getSubProperties("my."));}
3deceb959d5bccbc206b56a7d66d87a97414b3f736f3985705b56a10bf6f42a7
testClear
public void testClear()
{    context.put("test", "1");    context.clear();    assertNull(context.getInteger("test"));}
75acef493789912d1c90c48a2a23b22397f0ee1df42d5b70d8521c1d5ab1bd24
testPutAll
public void testPutAll()
{    context.putAll(ImmutableMap.of("test", "1"));    assertEquals("1", context.getString("test"));}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    counterGroup = new CounterGroup();}
49d905ea382069d074a0cabed01434777ae93e244a583ce8ac324615a1bd4d55
testGetCounter
public void testGetCounter()
{    AtomicLong counter = counterGroup.getCounter("test");    Assert.assertNotNull(counter);    Assert.assertEquals(0, counter.get());}
eaa5dd587a1051f25f65fe1808fe232d587180e61c71e00071a4b765af52ae7a
testGet
public void testGet()
{    long value = counterGroup.get("test");    Assert.assertEquals(0, value);}
c9f4c74d2d7ac5090bbb2dad79b7b32b12c9e95f2f71739807cf1386fb064aff
testIncrementAndGet
public void testIncrementAndGet()
{    long value = counterGroup.incrementAndGet("test");    Assert.assertEquals(1, value);}
be98f2ac04bdbdcb1f827bfda03ea25976037f2690c88c761c1d8c232a4849c1
testAddAndGet
public void testAddAndGet()
{    long value = counterGroup.addAndGet("test", 13L);    Assert.assertEquals(13, value);}
4ee844ce45d8f7884278ff66b7a2a478c44462fed5d8cd65bac5beab237a0bc5
testIntConfiguration
public void testIntConfiguration()
{    Map<String, String> props = new HashMap<String, String>();    Random random = new Random();    int intValue = random.nextInt(Integer.MAX_VALUE - 1) + 1;    props.put(testPrefix + "testInt", Integer.toString(intValue));    Context context = new Context(props);    TestBean bean = new TestBean();    Assert.assertEquals(0, bean.getTestInt());    FlumeBeanConfigurator.setConfigurationFields(bean, context);    Assert.assertEquals(intValue, bean.getTestInt());}
7f0cb96a871eb84525a3c88ca61656cb4809507736756c3078f413e238374a42
testShortConfiguration
public void testShortConfiguration()
{    Map<String, String> props = new HashMap<String, String>();    Random random = new Random();    short shortValue = (short) (random.nextInt(Short.MAX_VALUE - 1) + 1);    props.put(testPrefix + "testShort", Short.toString(shortValue));    Context context = new Context(props);    TestBean bean = new TestBean();    Assert.assertEquals(0, bean.getTestShort());    FlumeBeanConfigurator.setConfigurationFields(bean, context);    Assert.assertEquals(shortValue, bean.getTestShort());}
8f3b6acdb9ae440f04f0b2f0cfc64643d81f570963bff74604d1cc62327badca
testLongConfiguration
public void testLongConfiguration()
{    Map<String, String> props = new HashMap<String, String>();    long longValue = ThreadLocalRandom.current().nextLong(Integer.MAX_VALUE, Long.MAX_VALUE);    props.put(testPrefix + "testLong", Long.toString(longValue));    Context context = new Context(props);    TestBean bean = new TestBean();    Assert.assertEquals(0, bean.getTestLong());    FlumeBeanConfigurator.setConfigurationFields(bean, context);    Assert.assertEquals(longValue, bean.getTestLong());}
e06996181f1548b07cd0fee4ea9d074348c392f75fd388d6211655cddfe3c561
testByteConfiguration
public void testByteConfiguration()
{    Map<String, String> props = new HashMap<String, String>();    Random random = new Random();    byte byteValue = (byte) (random.nextInt(Byte.MAX_VALUE - 1) + 1);    props.put(testPrefix + "testByte", Byte.toString(byteValue));    Context context = new Context(props);    TestBean bean = new TestBean();    Assert.assertEquals(0, bean.getTestByte());    FlumeBeanConfigurator.setConfigurationFields(bean, context);    Assert.assertEquals(byteValue, bean.getTestByte());}
4c4e902c4577a46faf809af726bd87013b0eb009a731fca2003c5b213843c059
testBooleanConfiguration
public void testBooleanConfiguration()
{    Map<String, String> props = new HashMap<String, String>();    props.put(testPrefix + "testBoolean", "true");    Context context = new Context(props);    TestBean bean = new TestBean();    Assert.assertEquals(false, bean.getTestBoolean());    FlumeBeanConfigurator.setConfigurationFields(bean, context);    Assert.assertEquals(true, bean.getTestBoolean());}
a794b377cfcebbb2485b9ee246a1ac6f6366f41e3acd7de7aa7d2900976dc841
testDoubleConfiguration
public void testDoubleConfiguration()
{    Map<String, String> props = new HashMap<String, String>();    Random random = new Random();    double doubleValue = random.nextDouble();    props.put(testPrefix + "testDouble", Double.toString(doubleValue));    Context context = new Context(props);    TestBean bean = new TestBean();    Assert.assertEquals(0.0d, bean.getTestDouble());    FlumeBeanConfigurator.setConfigurationFields(bean, context);    Assert.assertEquals(doubleValue, bean.getTestDouble());}
2b1d1baeade46e7fe5748b1700c8f812ac0e8b074b57041a2c2ba0122b3c4ce6
testFloatConfiguration
public void testFloatConfiguration()
{    Map<String, String> props = new HashMap<String, String>();    Random random = new Random();    float floatValue = random.nextFloat();    props.put(testPrefix + "testFloat", Float.toString(floatValue));    Context context = new Context(props);    TestBean bean = new TestBean();    Assert.assertEquals(0.0f, bean.getTestFloat());    FlumeBeanConfigurator.setConfigurationFields(bean, context);    Assert.assertEquals(floatValue, bean.getTestFloat());}
8c4eeb077d40f73bee768df3c696f87d75bdd9ab843b4d5641d4a7c2c79a86f9
testStringConfiguration
public void testStringConfiguration()
{    Map<String, String> props = new HashMap<String, String>();    String stringValue = UUID.randomUUID().toString();    props.put(testPrefix + "testString", stringValue);    Context context = new Context(props);    TestBean bean = new TestBean();    Assert.assertEquals("", bean.getTestString());    FlumeBeanConfigurator.setConfigurationFields(bean, context);    Assert.assertEquals(stringValue, bean.getTestString());}
5344e7e1dbc4f2c5000b35c3a0d299f639cc32a9a550dc21f89676b08d2796aa
testPrivateConfiguration
public void testPrivateConfiguration()
{    Map<String, String> props = new HashMap<String, String>();    Random random = new Random();    int intValue = random.nextInt(Integer.MAX_VALUE - 1) + 1;    props.put(testPrefix + "privateInt", Integer.toString(intValue));    Context context = new Context(props);    TestBean bean = new TestBean();    Assert.assertEquals(0, bean.getPrivateInt());    FlumeBeanConfigurator.setConfigurationFields(bean, context);    Assert.assertTrue(bean.getPrivateInt() != intValue);}
dffd363fa628315474343cdaaddc076a87ec38641f4e6416575caf47f55ab883
getTestInt
public int getTestInt()
{    return testInt;}
ec89f62d498e77221586a80007becece8d3bed4ce9e58df6820812190b3a673d
setTestInt
public void setTestInt(int testInt)
{    this.testInt = testInt;}
429eb767b7d6447862af1d44a002c6be94eb2166636ef90399c714f250792050
getTestShort
public short getTestShort()
{    return testShort;}
f75ff9a8aa12608bcbe333cc217d1a406a2334e7108de1b305763a28e69d7954
setTestShort
public void setTestShort(short testShort)
{    this.testShort = testShort;}
e575d576c5a00f53817f8010fa86057df1e37b0194db5bfba1c8584856a9e460
getTestLong
public long getTestLong()
{    return testLong;}
a54af46ddc9a2d49bd8ee7a84b0f27700fee2f51e79d19d51daae89181fd82d0
setTestLong
public void setTestLong(long testLong)
{    this.testLong = testLong;}
cbfbb4f92cbaa51a0cf2a854c522f5e33a9c1c81faa778e2c3fdafe93d975e6e
getTestByte
public byte getTestByte()
{    return testByte;}
7abb04a3675fb86ca537fc1c3c93d512843c47b6092ee1897a809a6eecae9ec5
setTestByte
public void setTestByte(byte testByte)
{    this.testByte = testByte;}
4529ad6bc3f4b6ae1a4e52ca9ec5481148469735e4b70161c47f3f975b7a9f57
getTestBoolean
public boolean getTestBoolean()
{    return testBoolean;}
38df76116e75d7f808c30ee248c0e4179a08e1900cf8b75b27c192163a0a2f2f
setTestBoolean
public void setTestBoolean(boolean testBoolean)
{    this.testBoolean = testBoolean;}
1d6a4f4a91534cbdf4ce72903bdfb90ef140a53ae952b607426f326de51b8131
getTestFloat
public float getTestFloat()
{    return testFloat;}
7d0ce7e884da83ec455bcd6c7f67293abb52b5a17dc4703cff9be82bdb3428dd
setTestFloat
public void setTestFloat(float testFloat)
{    this.testFloat = testFloat;}
beff639294e38c3abd84a03efb2da19ac305e4fd7ffe5587c574abd7638668d6
getTestDouble
public double getTestDouble()
{    return testDouble;}
ccb7913a171f6f0c9886df06493fa571fb0523aaf57c91099423e19ab48654c4
setTestDouble
public void setTestDouble(double testDouble)
{    this.testDouble = testDouble;}
928366e4db21d9aea7cd15c4f083ba40f0a243720ae435337829f78203b7671e
getTestString
public String getTestString()
{    return testString;}
fdcc364bedb09dd5f0a4ff04c4f7faae13f2beff74d22b77613a61cfd4048b3f
setTestString
public void setTestString(String testString)
{    this.testString = testString;}
8ce6c2957a1aa2386ff7e3bb4b91afce57bcd00513736546095a3abcca19a420
getPrivateInt
private int getPrivateInt()
{    return privateInt;}
51f2747525a17618d0dd85939b719ccd4b30bb7798aec4d3aa9d2614e8dfd3f1
setPrivateInt
private void setPrivateInt(int privateInt)
{    this.privateInt = privateInt;}
6dfd12cfe635cb71799e5de60a804c19d0c03d82da4ce44e604ad47121fed304
testRoundDownTimeStampSeconds
public void testRoundDownTimeStampSeconds()
{    Calendar cal = BASE_CALENDAR_WITH_DEFAULT_TIMEZONE;    Calendar cal2 = createCalendar(2012, 5, 15, 15, 12, 0, 0, null);    long timeToVerify = cal2.getTimeInMillis();    long ret = TimestampRoundDownUtil.roundDownTimeStampSeconds(cal.getTimeInMillis(), 60);    System.out.println("Cal 1: " + cal.toString());    System.out.println("Cal 2: " + cal2.toString());    Assert.assertEquals(timeToVerify, ret);}
3910461ff58f9e0bdea937ac5a829935845265164b9fc0fea2b71b884122b777
testRoundDownTimeStampSecondsWithTimeZone
public void testRoundDownTimeStampSecondsWithTimeZone()
{    Calendar cal = BASE_CALENDAR_WITH_CUSTOM_TIMEZONE;    Calendar cal2 = createCalendar(2012, 5, 15, 15, 12, 0, 0, CUSTOM_TIMEZONE);    long timeToVerify = cal2.getTimeInMillis();    long withoutTimeZone = TimestampRoundDownUtil.roundDownTimeStampSeconds(cal.getTimeInMillis(), 60);    long withTimeZone = TimestampRoundDownUtil.roundDownTimeStampSeconds(cal.getTimeInMillis(), 60, CUSTOM_TIMEZONE);    assertThat(withoutTimeZone, not(equalTo(timeToVerify)));    Assert.assertEquals(withTimeZone, timeToVerify);}
12d396c6f3aa59ff296e1ec45e6022e5c431a48d6cc76fda103deb1fd9efb3a2
testRoundDownTimeStampMinutes
public void testRoundDownTimeStampMinutes()
{    Calendar cal = BASE_CALENDAR_WITH_DEFAULT_TIMEZONE;    Calendar cal2 = createCalendar(2012, 5, 15, 15, 10, 0, 0, null);    long timeToVerify = cal2.getTimeInMillis();    long ret = TimestampRoundDownUtil.roundDownTimeStampMinutes(cal.getTimeInMillis(), 5);    System.out.println("Cal 1: " + cal.toString());    System.out.println("Cal 2: " + cal2.toString());    Assert.assertEquals(timeToVerify, ret);}
8fa7c509e6f1b96714db5b4e987e035848777322be2537a52467e5e56c8c7294
testRoundDownTimeStampMinutesWithTimeZone
public void testRoundDownTimeStampMinutesWithTimeZone()
{    Calendar cal = BASE_CALENDAR_WITH_CUSTOM_TIMEZONE;    Calendar cal2 = createCalendar(2012, 5, 15, 15, 10, 0, 0, CUSTOM_TIMEZONE);    long timeToVerify = cal2.getTimeInMillis();    long withoutTimeZone = TimestampRoundDownUtil.roundDownTimeStampMinutes(cal.getTimeInMillis(), 5);    long withTimeZone = TimestampRoundDownUtil.roundDownTimeStampMinutes(cal.getTimeInMillis(), 5, CUSTOM_TIMEZONE);    assertThat(withoutTimeZone, not(equalTo(timeToVerify)));    Assert.assertEquals(withTimeZone, timeToVerify);}
60490d0579dd11e472e3fe472cea6d4a502d2ae074a397ef9e52aa9a77782d61
testRoundDownTimeStampHours
public void testRoundDownTimeStampHours()
{    Calendar cal = BASE_CALENDAR_WITH_DEFAULT_TIMEZONE;    Calendar cal2 = createCalendar(2012, 5, 15, 14, 0, 0, 0, null);    long timeToVerify = cal2.getTimeInMillis();    long ret = TimestampRoundDownUtil.roundDownTimeStampHours(cal.getTimeInMillis(), 2);    System.out.println("Cal 1: " + ret);    System.out.println("Cal 2: " + cal2.toString());    Assert.assertEquals(timeToVerify, ret);}
16da16103cc4162c496b24535dfd97805bbcb1f796da8f59ea0c27bf76c6c51e
testRoundDownTimeStampHoursWithTimeZone
public void testRoundDownTimeStampHoursWithTimeZone()
{    Calendar cal = BASE_CALENDAR_WITH_CUSTOM_TIMEZONE;    Calendar cal2 = createCalendar(2012, 5, 15, 14, 0, 0, 0, CUSTOM_TIMEZONE);    long timeToVerify = cal2.getTimeInMillis();    long withoutTimeZone = TimestampRoundDownUtil.roundDownTimeStampHours(cal.getTimeInMillis(), 2);    long withTimeZone = TimestampRoundDownUtil.roundDownTimeStampHours(cal.getTimeInMillis(), 2, CUSTOM_TIMEZONE);    assertThat(withoutTimeZone, not(equalTo(timeToVerify)));    Assert.assertEquals(withTimeZone, timeToVerify);}
03f15ba3e3610d9289cf522c061a6cc7f2b9422fb508f2473e30f632ccbdcb4a
createCalendar
private static Calendar createCalendar(int year, int month, int day, int hour, int minute, int second, int ms, @Nullable TimeZone timeZone)
{    Calendar cal = (timeZone == null) ? Calendar.getInstance() : Calendar.getInstance(timeZone);    cal.set(year, month, day, hour, minute, second);    cal.set(Calendar.MILLISECOND, ms);    return cal;}
9fcf9a3c332a05bec06d8e12fea555df71843e5b436865a28b647b1294f5699a
testVersionInfoUnknown
public void testVersionInfoUnknown()
{    logger.debug("Flume " + VersionInfo.getVersion());    logger.debug("Subversion " + VersionInfo.getUrl() + " -r " + VersionInfo.getRevision());    logger.debug("Compiled by " + VersionInfo.getUser() + " on " + VersionInfo.getDate());    logger.debug("From source with checksum " + VersionInfo.getSrcChecksum());    logger.debug("Flume " + VersionInfo.getBuildVersion());    assertTrue("getVersion returned Unknown", !VersionInfo.getVersion().equals("Unknown"));    assertTrue("getUser returned Unknown", !VersionInfo.getUser().equals("Unknown"));    assertTrue("getUrl returned Unknown", !VersionInfo.getUrl().equals("Unknown"));    assertTrue("getSrcChecksum returned Unknown", !VersionInfo.getSrcChecksum().equals("Unknown"));        assertTrue("getBuildVersion returned unexpected format", VersionInfo.getBuildVersion().matches(".+from.+by.+on.+source checksum.+"));        assertNotNull("getRevision returned null", VersionInfo.getRevision());    assertNotNull("getBranch returned null", VersionInfo.getBranch());}
35c6ef04386043cfb7d14c4c96d242b3fc22cfc4dd6e21e69d4e28bb10b8591f
configure
public void configure(Map<String, String> properties) throws FlumeException
{    if (state == State.STARTED) {        throw new IllegalStateException("Cannot be configured while started");    }    doConfigure(properties);    state = State.STOPPED;}
fc7610fefb6a424c0406856a8ef050aae5c5a872cd7a19f6e91628281f67b7b3
start
public void start() throws FlumeException
{    if (state == State.STARTED) {        throw new IllegalStateException("Cannot be started while started");    } else if (state == State.NEW) {        throw new IllegalStateException("Cannot be started before being " + "configured");    }            Source source = Preconditions.checkNotNull(sourceRunner.getSource(), "Source runner returned null source");    if (source instanceof EmbeddedSource) {        embeddedSource = (EmbeddedSource) source;    } else {        throw new IllegalStateException("Unknown source type: " + source.getClass().getName());    }    doStart();    state = State.STARTED;}
945569f80889f9b1619409eed7a6fedef1cbd6b591e99a1aa9b981f84045680c
stop
public void stop() throws FlumeException
{    if (state != State.STARTED) {        throw new IllegalStateException("Cannot be stopped unless started");    }    supervisor.stop();    embeddedSource = null;    state = State.STOPPED;}
b3e872fdc2a159d4800577bb14f194904f49614b5f3fd8cff6a52cf00e7aa4a6
doConfigure
private void doConfigure(Map<String, String> properties)
{    properties = EmbeddedAgentConfiguration.configure(name, properties);    if (LOGGER.isDebugEnabled() && LogPrivacyUtil.allowLogPrintConfig()) {        LOGGER.debug("Agent configuration values");        for (String key : new TreeSet<String>(properties.keySet())) {            LOGGER.debug(key + " = " + properties.get(key));        }    }    MaterializedConfiguration conf = configurationProvider.get(name, properties);    Map<String, SourceRunner> sources = conf.getSourceRunners();    if (sources.size() != 1) {        throw new FlumeException("Expected one source and got " + sources.size());    }    Map<String, Channel> channels = conf.getChannels();    if (channels.size() != 1) {        throw new FlumeException("Expected one channel and got " + channels.size());    }    Map<String, SinkRunner> sinks = conf.getSinkRunners();    if (sinks.size() != 1) {        throw new FlumeException("Expected one sink group and got " + sinks.size());    }    this.sourceRunner = sources.values().iterator().next();    this.channel = channels.values().iterator().next();    this.sinkRunner = sinks.values().iterator().next();}
bfe0dadb3015fbb01e61dcdfe38487cc83944056a00803884401f10619adba8e
put
public void put(Event event) throws EventDeliveryException
{    if (state != State.STARTED) {        throw new IllegalStateException("Cannot put events unless started");    }    try {        embeddedSource.put(event);    } catch (ChannelException ex) {        throw new EventDeliveryException("Embedded agent " + name + ": Unable to process event: " + ex.getMessage(), ex);    }}
f3e1c7e6a2285a33cacb984b96f18c24b141234007694ea240cfe98191a492ec
putAll
public void putAll(List<Event> events) throws EventDeliveryException
{    if (state != State.STARTED) {        throw new IllegalStateException("Cannot put events unless started");    }    try {        embeddedSource.putAll(events);    } catch (ChannelException ex) {        throw new EventDeliveryException("Embedded agent " + name + ": Unable to process event: " + ex.getMessage(), ex);    }}
2e01d659071d38bdc7688a100e7f54d40806e241c4286a6fe5055b02fa09ff18
doStart
private void doStart()
{    boolean error = true;    try {        channel.start();        sinkRunner.start();        sourceRunner.start();        supervisor.supervise(channel, new SupervisorPolicy.AlwaysRestartPolicy(), LifecycleState.START);        supervisor.supervise(sinkRunner, new SupervisorPolicy.AlwaysRestartPolicy(), LifecycleState.START);        supervisor.supervise(sourceRunner, new SupervisorPolicy.AlwaysRestartPolicy(), LifecycleState.START);        error = false;    } finally {        if (error) {            stopLogError(sourceRunner);            stopLogError(channel);            stopLogError(sinkRunner);            supervisor.stop();        }    }}
a797a64f0ead7ecd143de91db57f689380b3b2a4b75e46181a86a6e067f726b9
stopLogError
private void stopLogError(LifecycleAware lifeCycleAware)
{    try {        if (LifecycleState.START.equals(lifeCycleAware.getLifecycleState())) {            lifeCycleAware.stop();        }    } catch (Exception e) {        LOGGER.warn("Exception while stopping " + lifeCycleAware, e);    }}
e503714e8de7445d5ce2ea3dd8a75fafa65281f9f6bd36a09aac0680b6928df2
validate
private static void validate(String name, Map<String, String> properties) throws FlumeException
{    if (properties.containsKey(SOURCE_TYPE)) {        checkAllowed(ALLOWED_SOURCES, properties.get(SOURCE_TYPE));    }    checkRequired(properties, CHANNEL_TYPE);    checkAllowed(ALLOWED_CHANNELS, properties.get(CHANNEL_TYPE));    checkRequired(properties, SINKS);    String sinkNames = properties.get(SINKS);    for (String sink : sinkNames.split("\\s+")) {        if (DISALLOWED_SINK_NAMES.contains(sink.toLowerCase(Locale.ENGLISH))) {            throw new FlumeException("Sink name " + sink + " is one of the" + " disallowed sink names: " + DISALLOWED_SINK_NAMES);        }        String key = join(sink, TYPE);        checkRequired(properties, key);        checkAllowed(ALLOWED_SINKS, properties.get(key));    }    checkRequired(properties, SINK_PROCESSOR_TYPE);    checkAllowed(ALLOWED_SINK_PROCESSORS, properties.get(SINK_PROCESSOR_TYPE));}
5893a4f9bf202001c1e0d4b7f3244941b5d0a23be6d2f093ca5ed8cd8b1b8816
configure
 static Map<String, String> configure(String name, Map<String, String> properties) throws FlumeException
{    validate(name, properties);        properties = new HashMap<String, String>(properties);    if (!properties.containsKey(SOURCE_TYPE) || SOURCE_TYPE_EMBEDDED_ALIAS.equalsIgnoreCase(properties.get(SOURCE_TYPE))) {        properties.put(SOURCE_TYPE, SOURCE_TYPE_EMBEDDED);    }    String sinkNames = properties.remove(SINKS);    String strippedName = name.replaceAll("\\s+", "");    String sourceName = "source-" + strippedName;    String channelName = "channel-" + strippedName;    String sinkGroupName = "sink-group-" + strippedName;    /*     * Now we are going to process the user supplied configuration     * and generate an agent configuration. This is only to supply     * a simpler client api than passing in an entire agent configuration.     */        Map<String, String> result = Maps.newHashMap();    /*     * First we are going to setup all the root level pointers. I.E     * point the agent at the components, sink group at sinks, and     * source at the channel.     */        result.put(join(name, BasicConfigurationConstants.CONFIG_SOURCES), sourceName);        result.put(join(name, BasicConfigurationConstants.CONFIG_CHANNELS), channelName);        result.put(join(name, BasicConfigurationConstants.CONFIG_SINKS), sinkNames);        result.put(join(name, BasicConfigurationConstants.CONFIG_SINKGROUPS), sinkGroupName);        result.put(join(name, BasicConfigurationConstants.CONFIG_SINKGROUPS, sinkGroupName, SINKS), sinkNames);        result.put(join(name, BasicConfigurationConstants.CONFIG_SOURCES, sourceName, BasicConfigurationConstants.CONFIG_CHANNELS), channelName);            Set<String> userProvidedKeys = new HashSet<String>(properties.keySet());    /*     * Second process the sink configuration and point the sinks     * at the channel.     */    for (String sink : sinkNames.split("\\s+")) {        for (String key : userProvidedKeys) {            String value = properties.get(key);            if (key.startsWith(sink + SEPERATOR)) {                properties.remove(key);                result.put(join(name, BasicConfigurationConstants.CONFIG_SINKS, key), value);            }        }                result.put(join(name, BasicConfigurationConstants.CONFIG_SINKS, sink, BasicConfigurationConstants.CONFIG_CHANNEL), channelName);    }    /*     * Third, process all remaining configuration items, prefixing them     * correctly and then passing them on to the agent.     */    userProvidedKeys = new HashSet<String>(properties.keySet());    for (String key : userProvidedKeys) {        String value = properties.get(key);        if (key.startsWith(SOURCE_PREFIX)) {                        key = key.replaceFirst(SOURCE, sourceName);            result.put(join(name, BasicConfigurationConstants.CONFIG_SOURCES, key), value);        } else if (key.startsWith(CHANNEL_PREFIX)) {                        key = key.replaceFirst(CHANNEL, channelName);            result.put(join(name, BasicConfigurationConstants.CONFIG_CHANNELS, key), value);        } else if (key.startsWith(SINK_PROCESSOR_PREFIX)) {                        result.put(join(name, BasicConfigurationConstants.CONFIG_SINKGROUPS, sinkGroupName, key), value);        } else {                        throw new FlumeException("Unknown configuration " + key);        }    }    return result;}
a910eaf338ad9a5c0651c70ef3af250551de74f21820bfaa6578a8418237e133
checkAllowed
private static void checkAllowed(String[] allowedTypes, String type)
{    boolean isAllowed = false;    type = type.trim();    for (String allowedType : allowedTypes) {        if (allowedType.equalsIgnoreCase(type)) {            isAllowed = true;            break;        }    }    if (!isAllowed) {        throw new FlumeException("Component type of " + type + " is not in " + "allowed types of " + Arrays.toString(allowedTypes));    }}
4a3ae9ff007aca566291fa7166ef3668799351b34688bcb97b22ebfb8819cf13
checkRequired
private static void checkRequired(Map<String, String> properties, String name)
{    if (!properties.containsKey(name)) {        throw new FlumeException("Required parameter not found " + name);    }}
72c40d49ad17f38184f6c794cb8e646611444a489349bb147bb9f23a93602f66
join
private static String join(String... parts)
{    return JOINER.join(parts);}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{}
7c433c140e986ede99b2704e4370ce4dc62a481b499e15037b573f27288bffc9
put
public void put(Event event) throws ChannelException
{    getChannelProcessor().processEvent(event);}
2d9be54666bd3dc656a4a993a3950a8b4bb06af85423f51df28904e15fb8c2bc
putAll
public void putAll(List<Event> events) throws ChannelException
{    getChannelProcessor().processEventBatch(events);}
a73b339635e9fd1fb04a0cd2ed57bb558ad2e70d9f9acfe54625aad8b4d65ff9
get
 MaterializedConfiguration get(String name, Map<String, String> properties)
{    MemoryConfigurationProvider confProvider = new MemoryConfigurationProvider(name, properties);    return confProvider.getConfiguration();}
017528fe1ef89aa4d378c2cb88ab31e1cb5c27aac07c4d607cf4e80bfc231077
getFlumeConfiguration
protected FlumeConfiguration getFlumeConfiguration()
{    return new FlumeConfiguration(properties);}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    headers = Maps.newHashMap();    headers.put("key1", "value1");    body = "body".getBytes(Charsets.UTF_8);    int port = findFreePort();    eventCollector = new EventCollector();    Responder responder = new SpecificResponder(AvroSourceProtocol.class, eventCollector);    nettyServer = new NettyServer(responder, new InetSocketAddress(HOSTNAME, port));    nettyServer.start();        Thread.sleep(1000L);    properties = Maps.newHashMap();    properties.put("channel.type", "memory");    properties.put("channel.capacity", "200");    properties.put("sinks", "sink1 sink2");    properties.put("sink1.type", "avro");    properties.put("sink2.type", "avro");    properties.put("sink1.hostname", HOSTNAME);    properties.put("sink1.port", String.valueOf(port));    properties.put("sink2.hostname", HOSTNAME);    properties.put("sink2.port", String.valueOf(port));    properties.put("processor.type", "load_balance");    agent = new EmbeddedAgent("test-" + serialNumber.incrementAndGet());}
c6aaebb5a52567751db8dc8e1cb9dd4a4e582ef964a374b376c6a04f741802dc
tearDown
public void tearDown() throws Exception
{    if (agent != null) {        try {            agent.stop();        } catch (Exception e) {            LOGGER.debug("Error shutting down agent", e);        }    }    if (nettyServer != null) {        try {            nettyServer.close();        } catch (Exception e) {            LOGGER.debug("Error shutting down server", e);        }    }}
c75354e1d2e0d02b03907d071638189e6542ce58f45d2d051fa2b3b6c2f9f294
testPut
public void testPut() throws Exception
{    agent.configure(properties);    agent.start();    agent.put(EventBuilder.withBody(body, headers));    Event event;    while ((event = eventCollector.poll()) == null) {        Thread.sleep(500L);    }    Assert.assertNotNull(event);    Assert.assertArrayEquals(body, event.getBody());    Assert.assertEquals(headers, event.getHeaders());}
3af27c044bb285984cc787d1135589816427d8f51412e8ae6d1189fadc1158b4
testPutAll
public void testPutAll() throws Exception
{    List<Event> events = Lists.newArrayList();    events.add(EventBuilder.withBody(body, headers));    agent.configure(properties);    agent.start();    agent.putAll(events);    Event event;    while ((event = eventCollector.poll()) == null) {        Thread.sleep(500L);    }    Assert.assertNotNull(event);    Assert.assertArrayEquals(body, event.getBody());    Assert.assertEquals(headers, event.getHeaders());}
1dafeff38c19c4d88b214dd685a7cc9faa8bcb872f7559329c7c9f0d8bf582d4
testPutWithInterceptors
public void testPutWithInterceptors() throws Exception
{    properties.put("source.interceptors", "i1");    properties.put("source.interceptors.i1.type", "static");    properties.put("source.interceptors.i1.key", "key2");    properties.put("source.interceptors.i1.value", "value2");    agent.configure(properties);    agent.start();    agent.put(EventBuilder.withBody(body, headers));    Event event;    while ((event = eventCollector.poll()) == null) {        Thread.sleep(500L);    }    Assert.assertNotNull(event);    Assert.assertArrayEquals(body, event.getBody());    Map<String, String> newHeaders = new HashMap<String, String>(headers);    newHeaders.put("key2", "value2");    Assert.assertEquals(newHeaders, event.getHeaders());}
f03773b83dc96ee39d2e5820a04ab7b1feba23770b12974835616e184f54014d
testEmbeddedAgentName
public void testEmbeddedAgentName() throws Exception
{    EmbeddedAgent embedAgent = new EmbeddedAgent("test 1 2" + serialNumber.incrementAndGet());    List<Event> events = Lists.newArrayList();    events.add(EventBuilder.withBody(body, headers));    embedAgent.configure(properties);    embedAgent.start();    embedAgent.putAll(events);    Event event;    while ((event = eventCollector.poll()) == null) {        Thread.sleep(500L);    }    Assert.assertNotNull(event);    Assert.assertArrayEquals(body, event.getBody());    Assert.assertEquals(headers, event.getHeaders());    if (embedAgent != null) {        try {            embedAgent.stop();        } catch (Exception e) {            LOGGER.debug("Error shutting down agent", e);        }    }}
a218ea053824e928ba21dfd4facc386d100f2d4e273ee76bd404112d43b52d7d
poll
public Event poll()
{    AvroFlumeEvent avroEvent = eventQueue.poll();    if (avroEvent != null) {        return EventBuilder.withBody(avroEvent.getBody().array(), toStringMap(avroEvent.getHeaders()));    }    return null;}
16896c3c4fd07c175b3a70f7caa364f655a38a6b63a54a3895b30e8dcacf0f52
append
public Status append(AvroFlumeEvent event) throws AvroRemoteException
{    eventQueue.add(event);    return Status.OK;}
a8baf3969fe87a0c94bf276b347c3cf4fd1f38175e8dddac6a5e509a3b6db442
appendBatch
public Status appendBatch(List<AvroFlumeEvent> events) throws AvroRemoteException
{    Preconditions.checkState(eventQueue.addAll(events));    return Status.OK;}
2e58b3ac498ab3927896f17dd5b1322f2b5601df3bbefc5d05d04de291b821f1
toStringMap
private static Map<String, String> toStringMap(Map<CharSequence, CharSequence> charSeqMap)
{    Map<String, String> stringMap = new HashMap<String, String>();    for (Map.Entry<CharSequence, CharSequence> entry : charSeqMap.entrySet()) {        stringMap.put(entry.getKey().toString(), entry.getValue().toString());    }    return stringMap;}
4d072973845457c68e0bdcaf8605a63c4e82cee51aa51c4f7db0b2f7a2d3a532
findFreePort
private static int findFreePort() throws IOException
{    try (ServerSocket socket = new ServerSocket(0)) {        return socket.getLocalPort();    }}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    properties = Maps.newHashMap();    properties.put("source.type", EmbeddedAgentConfiguration.SOURCE_TYPE_EMBEDDED);    properties.put("channel.type", "memory");    properties.put("channel.capacity", "200");    properties.put("sinks", "sink1 sink2");    properties.put("sink1.type", "avro");    properties.put("sink2.type", "avro");    properties.put("sink1.hostname", "sink1.host");    properties.put("sink1.port", "2");    properties.put("sink2.hostname", "sink2.host");    properties.put("sink2.port", "2");    properties.put("processor.type", "load_balance");    properties.put("source.interceptors", "i1");    properties.put("source.interceptors.i1.type", "timestamp");}
dbf92195addf48b7f9f789921a2b979b6b01b6e3584a227081090c0a6015d7e9
testFullSourceType
public void testFullSourceType() throws Exception
{    doTestExcepted(EmbeddedAgentConfiguration.configure("test1", properties));}
d5e03f65496d06a67f86146932a3de7ba14ffedf609a01c9251dbb88409fd440
testMissingSourceType
public void testMissingSourceType() throws Exception
{    Assert.assertNotNull(properties.remove("source.type"));    doTestExcepted(EmbeddedAgentConfiguration.configure("test1", properties));}
95df72270cad57a264d602c0a5213b9a0a085b7b6f468e1f0a9f28618ab0b519
testShortSourceType
public void testShortSourceType() throws Exception
{    properties.put("source.type", "EMBEDDED");    doTestExcepted(EmbeddedAgentConfiguration.configure("test1", properties));}
e5ae5e56ab438ee8efa40b0f4d2a1ab87b77dc3dd6d3c0619a2213ecc2687f5c
doTestExcepted
public void doTestExcepted(Map<String, String> actual) throws Exception
{    Map<String, String> expected = Maps.newHashMap();    expected.put("test1.channels", "channel-test1");    expected.put("test1.channels.channel-test1.capacity", "200");    expected.put("test1.channels.channel-test1.type", "memory");    expected.put("test1.sinkgroups", "sink-group-test1");    expected.put("test1.sinkgroups.sink-group-test1.processor.type", "load_balance");    expected.put("test1.sinkgroups.sink-group-test1.sinks", "sink1 sink2");    expected.put("test1.sinks", "sink1 sink2");    expected.put("test1.sinks.sink1.channel", "channel-test1");    expected.put("test1.sinks.sink1.hostname", "sink1.host");    expected.put("test1.sinks.sink1.port", "2");    expected.put("test1.sinks.sink1.type", "avro");    expected.put("test1.sinks.sink2.channel", "channel-test1");    expected.put("test1.sinks.sink2.hostname", "sink2.host");    expected.put("test1.sinks.sink2.port", "2");    expected.put("test1.sinks.sink2.type", "avro");    expected.put("test1.sources", "source-test1");    expected.put("test1.sources.source-test1.channels", "channel-test1");    expected.put("test1.sources.source-test1.type", EmbeddedAgentConfiguration.SOURCE_TYPE_EMBEDDED);    expected.put("test1.sources.source-test1.interceptors", "i1");    expected.put("test1.sources.source-test1.interceptors.i1.type", "timestamp");    Assert.assertEquals(expected, actual);}
00adba076fcff283b4a5713783af518e417f2b908a33a98882012f131b833f30
testBadSource
public void testBadSource() throws Exception
{    properties.put("source.type", "exec");    EmbeddedAgentConfiguration.configure("test1", properties);}
44e5a58496ccd0ec6dfdfebc0372cc2896ee228e88d399a6828456cb6f7bbf12
testBadChannel
public void testBadChannel() throws Exception
{    properties.put("channel.type", "jdbc");    EmbeddedAgentConfiguration.configure("test1", properties);}
10e8d5941fd9bc57897d6b0faf1e4c1f9daf1e1ccf264bb238a44fb251594b55
testBadSink
public void testBadSink() throws Exception
{    properties.put("sink1.type", "hbase");    EmbeddedAgentConfiguration.configure("test1", properties);}
3b08ba0fe678674927f69ca06a84cfb8e54a6eacebd5f6de467462ffd9a5a705
testBadSinkProcessor
public void testBadSinkProcessor() throws Exception
{    properties.put("processor.type", "bad");    EmbeddedAgentConfiguration.configure("test1", properties);}
1c18448c05bdc48a255490b4baa396be033853831023bb9b7815badbbbf03c28
testNoChannel
public void testNoChannel() throws Exception
{    properties.remove("channel.type");    EmbeddedAgentConfiguration.configure("test1", properties);}
cfff0e92aadf82c03cc74baaa9c136d063d743beec5aa268c96821a5c8fcf31b
testNoSink
public void testNoSink() throws Exception
{    properties.remove("sink2.type");    EmbeddedAgentConfiguration.configure("test1", properties);}
0fe33b396e3d188df8b79d653d5795723cb41f2fc16ac148225106dea5a30249
testNoSinkProcessor
public void testNoSinkProcessor() throws Exception
{    properties.remove("processor.type");    EmbeddedAgentConfiguration.configure("test1", properties);}
7c379770c6796142d62c5b1f951dd67d2b964a4d04eaadc81c8c00ff7f287cae
testBadKey
public void testBadKey() throws Exception
{    properties.put("bad.key.name", "bad");    EmbeddedAgentConfiguration.configure("test1", properties);}
e29a28850aa1f7711ff8e3e5643fc847195480ea86deb2853304daf47bb24d2f
testSinkNamedLikeSource
public void testSinkNamedLikeSource() throws Exception
{    properties.put("sinks", "source");    EmbeddedAgentConfiguration.configure("test1", properties);}
cc702584d594ac20613223ecb16ae17fd031ee46b7217b74d6abb86808c1d5c4
testSinkNamedLikeChannel
public void testSinkNamedLikeChannel() throws Exception
{    properties.put("sinks", "channel");    EmbeddedAgentConfiguration.configure("test1", properties);}
80400678d1fb808057d0b0762e3f998d17ee6032ffc404adfd5afdc710376a35
testSinkNamedLikeProcessor
public void testSinkNamedLikeProcessor() throws Exception
{    properties.put("sinks", "processor");    EmbeddedAgentConfiguration.configure("test1", properties);}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    properties = Maps.newHashMap();    properties.put("source.type", EmbeddedAgentConfiguration.SOURCE_TYPE_EMBEDDED);    properties.put("channel.type", "memory");    properties.put("sinks", "sink1 sink2");    properties.put("sink1.type", "avro");    properties.put("sink2.type", "avro");    properties.put("processor.type", "load_balance");    sourceRunner = mock(SourceRunner.class);    channel = mock(Channel.class);    sinkRunner = mock(SinkRunner.class);    source = mock(EmbeddedSource.class);    when(sourceRunner.getSource()).thenReturn(source);    when(sourceRunner.getLifecycleState()).thenReturn(LifecycleState.START);    when(channel.getLifecycleState()).thenReturn(LifecycleState.START);    when(sinkRunner.getLifecycleState()).thenReturn(LifecycleState.START);    config = new MaterializedConfiguration() {        @Override        public Map<String, SourceRunner> getSourceRunners() {            Map<String, SourceRunner> result = Maps.newHashMap();            result.put("source", sourceRunner);            return ImmutableMap.copyOf(result);        }        @Override        public Map<String, SinkRunner> getSinkRunners() {            Map<String, SinkRunner> result = Maps.newHashMap();            result.put("sink", sinkRunner);            return ImmutableMap.copyOf(result);        }        @Override        public Map<String, Channel> getChannels() {            Map<String, Channel> result = Maps.newHashMap();            result.put("channel", channel);            return ImmutableMap.copyOf(result);        }        @Override        public void addSourceRunner(String name, SourceRunner sourceRunner) {            throw new UnsupportedOperationException();        }        @Override        public void addSinkRunner(String name, SinkRunner sinkRunner) {            throw new UnsupportedOperationException();        }        @Override        public void addChannel(String name, Channel channel) {            throw new UnsupportedOperationException();        }    };    agent = new EmbeddedAgent(new MaterializedConfigurationProvider() {        public MaterializedConfiguration get(String name, Map<String, String> properties) {            return config;        }    }, "dummy");}
eab92b0193defc26e6b087b2b9cc0b00c4835a7204f3b382c7754a37026d2d7b
getSourceRunners
public Map<String, SourceRunner> getSourceRunners()
{    Map<String, SourceRunner> result = Maps.newHashMap();    result.put("source", sourceRunner);    return ImmutableMap.copyOf(result);}
e682ab5a7aeef354fa754a0bf6814a927c29821895d0581ff95145c9c577a3c6
getSinkRunners
public Map<String, SinkRunner> getSinkRunners()
{    Map<String, SinkRunner> result = Maps.newHashMap();    result.put("sink", sinkRunner);    return ImmutableMap.copyOf(result);}
1962a53d0a4f9845d56ff5f49e696f818846bace2fa42f41ec51d2956dce1fcb
getChannels
public Map<String, Channel> getChannels()
{    Map<String, Channel> result = Maps.newHashMap();    result.put("channel", channel);    return ImmutableMap.copyOf(result);}
0c3c870bd91a71c588fe015c10b525118652bd184b759e70a763ce9b6a32ac2e
addSourceRunner
public void addSourceRunner(String name, SourceRunner sourceRunner)
{    throw new UnsupportedOperationException();}
8f265261b16075f78b3e04e7395ba38fafbbbf0a17ebc76b26356f4c2faa4e11
addSinkRunner
public void addSinkRunner(String name, SinkRunner sinkRunner)
{    throw new UnsupportedOperationException();}
7b1cceed1937b5297f129befde597f42b16e557c043a1c9b3a2f0a0ef685bf8b
addChannel
public void addChannel(String name, Channel channel)
{    throw new UnsupportedOperationException();}
e383666fc1021a95b2a88b4b362750c4239ebae15fe5db09331b1f8fed1b296e
get
public MaterializedConfiguration get(String name, Map<String, String> properties)
{    return config;}
7b1b5c34b22429dcf25a45b4733de77d9764f3b5356d4e3dca0044e7c8955c71
testStart
public void testStart()
{    agent.configure(properties);    agent.start();    verify(sourceRunner, times(1)).start();    verify(channel, times(1)).start();    verify(sinkRunner, times(1)).start();}
a8d9e8a45b91f9aad253ca3e2c70f33d23c59ce9f9443d8a9337283da479a215
testStop
public void testStop()
{    agent.configure(properties);    agent.start();    agent.stop();    verify(sourceRunner, times(1)).stop();    verify(channel, times(1)).stop();    verify(sinkRunner, times(1)).stop();}
816b558240642370ae52702193dcf7151b83ddf9a1c0881f695beb4b1f3faf18
testStartSourceThrowsException
public void testStartSourceThrowsException()
{    doThrow(new LocalRuntimeException()).when(sourceRunner).start();    startExpectingLocalRuntimeException();}
c164291e9dde3ef6162455b28d43ecf7b729222975a8172283343a7a7b2bfaac
testStartChannelThrowsException
public void testStartChannelThrowsException()
{    doThrow(new LocalRuntimeException()).when(channel).start();    startExpectingLocalRuntimeException();}
b6e9fdf821be6013773053b7c63b52ee372d45c259a4c40c95f02726aba486af
testStartSinkThrowsException
public void testStartSinkThrowsException()
{    doThrow(new LocalRuntimeException()).when(sinkRunner).start();    startExpectingLocalRuntimeException();}
24a16273aadd136e0928da7a0fea4e2e87128f202d83c1d72efc975a1e65ff4b
startExpectingLocalRuntimeException
private void startExpectingLocalRuntimeException()
{    agent.configure(properties);    try {        agent.start();        Assert.fail();    } catch (LocalRuntimeException e) {        }    verify(sourceRunner, times(1)).stop();    verify(channel, times(1)).stop();    verify(sinkRunner, times(1)).stop();}
f70f5c10acbd5fb4f1503cb67452f69da7ae8eeee08b59c003d5632eb7ec8f66
testPut
public void testPut() throws EventDeliveryException
{    Event event = new SimpleEvent();    agent.configure(properties);    agent.start();    agent.put(event);    verify(source, times(1)).put(event);}
a0dc631be192de65d5f4ccee7032929460d5f9e513fc40bf67fae6ceb55f8803
testPutAll
public void testPutAll() throws EventDeliveryException
{    Event event = new SimpleEvent();    List<Event> events = Lists.newArrayList();    events.add(event);    agent.configure(properties);    agent.start();    agent.putAll(events);    verify(source, times(1)).putAll(events);}
b3fb6eb6237697d0af57a3a54891005ec109dbbb933bbfdad06c28e064fe65bb
testPutNotStarted
public void testPutNotStarted() throws EventDeliveryException
{    Event event = new SimpleEvent();    agent.configure(properties);    agent.put(event);}
ddc29060c5723fec62fa00ee8256f9e4eae8b36f1c17cb1ed71e749675457dd6
testPutAllNotStarted
public void testPutAllNotStarted() throws EventDeliveryException
{    Event event = new SimpleEvent();    List<Event> events = Lists.newArrayList();    events.add(event);    agent.configure(properties);    agent.putAll(events);}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    agent = new EmbeddedAgent("dummy");    properties = Maps.newHashMap();    properties.put("source.type", EmbeddedAgentConfiguration.SOURCE_TYPE_EMBEDDED);    properties.put("channel.type", "memory");    properties.put("sinks", "sink1 sink2");    properties.put("sink1.type", "avro");    properties.put("sink2.type", "avro");    properties.put("sink1.hostname", HOSTNAME);    properties.put("sink1.port", "0");    properties.put("sink2.hostname", HOSTNAME);    properties.put("sink2.port", "0");    properties.put("processor.type", "load_balance");}
9ee46c51e0c0f584a4ee782d4fcbd9d762101b36a49d3d26e3667ccb07e65765
testConfigureWithBadSourceType
public void testConfigureWithBadSourceType()
{    properties.put(EmbeddedAgentConfiguration.SOURCE_TYPE, "bad");    agent.configure(properties);}
dad99bedd126c832db9c378536cfe05cc17451bc5f359480005ae6c4e1962225
testConfigureWhileStarted
public void testConfigureWhileStarted()
{    try {        agent.configure(properties);        agent.start();    } catch (Exception e) {        Throwables.propagate(e);    }    agent.configure(properties);}
ce8750366e00c3885b8300021156e37081997844f63642907031cd3ba5a92e54
testConfigureMultipleTimes
public void testConfigureMultipleTimes()
{    agent.configure(properties);    agent.configure(properties);}
c83486fad3fe87cfaac4e4d410929c5358ae01fd8668ce9049ccc3b60ffbd319
testStartWhileStarted
public void testStartWhileStarted()
{    try {        agent.configure(properties);        agent.start();    } catch (Exception e) {        Throwables.propagate(e);    }    agent.start();}
9527e0ea0b0039667a6a42b1d6e38bd50fe78e4bb3888d4e6d07aae9cb1238eb
testStartUnconfigured
public void testStartUnconfigured()
{    agent.start();}
ff445f131fdff3ec0bc68b6f1eabb6dfc56335d8e4f5392c0f38dd22869bc90a
testStopBeforeConfigure
public void testStopBeforeConfigure()
{    agent.stop();}
056c9497496922ac768f5bd57af1d883bec84633c53144f7d9dce34e7b9db055
testStoppedWhileStopped
public void testStoppedWhileStopped()
{    try {        agent.configure(properties);    } catch (Exception e) {        Throwables.propagate(e);    }    agent.stop();}
68a7c3b72cfe2e1a138a3e1b603dfe0dcb9f5dee5b515c9c6389f952f858e092
testStopAfterStop
public void testStopAfterStop()
{    try {        agent.configure(properties);        agent.start();        agent.stop();    } catch (Exception e) {        Throwables.propagate(e);    }    agent.stop();}
b37a9cf3dfeaaea37b496833d8f401660f138e3e73b9ea4abcc47f2b2edb06af
testStopAfterConfigure
public void testStopAfterConfigure()
{    try {        agent.configure(properties);    } catch (Exception e) {        Throwables.propagate(e);    }    agent.stop();}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{        res = new SpecificResponder(FlumeOGEventAvroServer.class, this);    try {        http = new HttpServer(res, host, port);    } catch (IOException eI) {        LOG.warn("Failed to start server", eI);        return;    }    http.start();    super.start();}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    http.close();    super.stop();}
8606c6bdc3bf80e4bbb780074bf51d114ef2c7d8d8f4292adc5f5a849fdb46a2
append
public Void append(AvroFlumeOGEvent evt) throws AvroRemoteException
{    counterGroup.incrementAndGet("rpc.received");    Map<String, String> headers = new HashMap<String, String>();        headers.put(HOST, evt.getHost().toString());    headers.put(TIMESTAMP, evt.getTimestamp().toString());    headers.put(PRIORITY, evt.getPriority().toString());    headers.put(NANOS, evt.getNanos().toString());    for (Entry<CharSequence, ByteBuffer> entry : evt.getFields().entrySet()) {        headers.put(entry.getKey().toString(), entry.getValue().toString());    }    headers.put(OG_EVENT, "yes");    Event event = EventBuilder.withBody(evt.getBody().array(), headers);    try {        getChannelProcessor().processEvent(event);        counterGroup.incrementAndGet("rpc.events");    } catch (ChannelException ex) {        return null;    }    counterGroup.incrementAndGet("rpc.successful");    return null;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    port = Integer.parseInt(context.getString("port"));    host = context.getString("host");}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    source = new AvroLegacySource();    channel = new MemoryChannel();    Configurables.configure(channel, new Context());    List<Channel> channels = new ArrayList<Channel>();    channels.add(channel);    ChannelSelector rcs = new ReplicatingChannelSelector();    rcs.setChannels(channels);    source.setChannelProcessor(new ChannelProcessor(rcs));    try (ServerSocket socket = new ServerSocket(0)) {        selectedPort = socket.getLocalPort();    }}
f4f5bd17f7ef219499ed059849d7c2a0a6915756e4cd28bf2c10b3c9db532190
testLifecycle
public void testLifecycle() throws InterruptedException
{    Context context = new Context();    context.put("port", String.valueOf(selectedPort));    context.put("host", "0.0.0.0");    Configurables.configure(source, context);    source.start();    Assert.assertTrue("Reached start or error", LifecycleController.waitForOneOf(source, LifecycleState.START_OR_ERROR));    Assert.assertEquals("Server is started", LifecycleState.START, source.getLifecycleState());    source.stop();    Assert.assertTrue("Reached stop or error", LifecycleController.waitForOneOf(source, LifecycleState.STOP_OR_ERROR));    Assert.assertEquals("Server is stopped", LifecycleState.STOP, source.getLifecycleState());}
57d90793d7dcba7a87564056c6a9b1861757a6720e13e5223291aa5dfefacc9f
testRequest
public void testRequest() throws InterruptedException, IOException
{    Context context = new Context();    context.put("port", String.valueOf(selectedPort));    context.put("host", "0.0.0.0");    Configurables.configure(source, context);    source.start();    Assert.assertTrue("Reached start or error", LifecycleController.waitForOneOf(source, LifecycleState.START_OR_ERROR));    Assert.assertEquals("Server is started", LifecycleState.START, source.getLifecycleState());        URL url = new URL("http", "0.0.0.0", selectedPort, "/");    Transceiver http = new HttpTransceiver(url);    FlumeOGEventAvroServer client = SpecificRequestor.getClient(FlumeOGEventAvroServer.class, http);    AvroFlumeOGEvent avroEvent = AvroFlumeOGEvent.newBuilder().setHost("foo").setPriority(Priority.INFO).setNanos(0).setTimestamp(1).setFields(new HashMap<CharSequence, ByteBuffer>()).setBody(ByteBuffer.wrap("foo".getBytes())).build();    client.append(avroEvent);        Transaction transaction = channel.getTransaction();    transaction.begin();    Event event = channel.take();    Assert.assertNotNull(event);    Assert.assertEquals("Channel contained our event", "foo", new String(event.getBody()));    transaction.commit();    transaction.close();    source.stop();    Assert.assertTrue("Reached stop or error", LifecycleController.waitForOneOf(source, LifecycleState.STOP_OR_ERROR));    Assert.assertEquals("Server is stopped", LifecycleState.STOP, source.getLifecycleState());}
7f820eeb69ca0b6ba212f7fa738d25f53ebc1bc5cfb29c2200e154ad62791a65
getValue
public int getValue()
{    return value;}
4105b80f79caf901f9ba7a296e0a07b7e0669e5fb0e0cdc3d41153f3a0922248
findByValue
public static EventStatus findByValue(int value)
{    switch(value) {        case 0:            return ACK;        case 1:            return COMMITED;        case 2:            return ERR;        default:            return null;    }}
7f820eeb69ca0b6ba212f7fa738d25f53ebc1bc5cfb29c2200e154ad62791a65
getValue
public int getValue()
{    return value;}
44831607ae790539b408e6e5e3acf43de39469b9e8c090c285f7388797dfdab9
findByValue
public static Priority findByValue(int value)
{    switch(value) {        case 0:            return FATAL;        case 1:            return ERROR;        case 2:            return WARN;        case 3:            return INFO;        case 4:            return DEBUG;        case 5:            return TRACE;        default:            return null;    }}
92e9e6589c16b4fde1efd2a77a414bb3a621362cc64c5ef5a21381d0e5b55b5f
findByThriftId
public static _Fields findByThriftId(int fieldId)
{    switch(fieldId) {        case         1:            return TIMESTAMP;        case         2:            return PRIORITY;        case         3:            return BODY;        case         4:            return NANOS;        case         5:            return HOST;        case         6:            return FIELDS;        default:            return null;    }}
950148827ecab1253536a12003b5b2c41c2778a566a9ed4cb2487de641d6bde4
findByThriftIdOrThrow
public static _Fields findByThriftIdOrThrow(int fieldId)
{    _Fields fields = findByThriftId(fieldId);    if (fields == null)        throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");    return fields;}
eb44b9fdf7e05046f232aa9f1f3bb9a0cf815a486270439682862994e0d2c224
findByName
public static _Fields findByName(String name)
{    return byName.get(name);}
7f8fa4ecb4119b59b8047c285ac8f8729a909f121d1d3386d19ebfc6c04ab5df
getThriftFieldId
public short getThriftFieldId()
{    return _thriftId;}
68f4afd0e3cff42097dd5b6508fea1f7952d6d93f52ded3c1deea7186fff780c
getFieldName
public String getFieldName()
{    return _fieldName;}
2316de0ea36ca15f5239e50b43bbabc620f1d6c4d3de6239fad05ba6b8ce47e3
deepCopy
public ThriftFlumeEvent deepCopy()
{    return new ThriftFlumeEvent(this);}
21ac40bb9a99614b6ac18fa4043acb6173fccff96066fdfab963dba597923aa8
clear
public void clear()
{    setTimestampIsSet(false);    this.timestamp = 0;    this.priority = null;    this.body = null;    setNanosIsSet(false);    this.nanos = 0;    this.host = null;    this.fields = null;}
efd4f04d2f7438e26699863148fedf2a1756ec4f9ea70d9d64b80b1bdb63169b
getTimestamp
public long getTimestamp()
{    return this.timestamp;}
5377ba64a5ebefdc0131ddb54b396fb4688bd5a83fadb3c07d79ef517f93c7f0
setTimestamp
public ThriftFlumeEvent setTimestamp(long timestamp)
{    this.timestamp = timestamp;    setTimestampIsSet(true);    return this;}
b6910fde8a10d8868c9bf9292e67a197338fbfd87bc837444ea7b3f9d281b407
unsetTimestamp
public void unsetTimestamp()
{    __isset_bitfield = EncodingUtils.clearBit(__isset_bitfield, __TIMESTAMP_ISSET_ID);}
81599edf0708588632e261b85894513cbf84e5d70cbad1bb2c289569e3230c6c
isSetTimestamp
public boolean isSetTimestamp()
{    return EncodingUtils.testBit(__isset_bitfield, __TIMESTAMP_ISSET_ID);}
9dc34b755a9e6c66b23901565dfdaaf01f6d52020da7663ea348a55e19fa1976
setTimestampIsSet
public void setTimestampIsSet(boolean value)
{    __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __TIMESTAMP_ISSET_ID, value);}
3677ee2d716057412e04a1f7bc0b3b41fce238eb9020826e80f32b2ecac1422a
getPriority
public Priority getPriority()
{    return this.priority;}
47702b01b06405204c8cfb2fd2f1e630d97a38c408b79ecf4f4b5c7210218572
setPriority
public ThriftFlumeEvent setPriority(Priority priority)
{    this.priority = priority;    return this;}
9ccb1bc67a0d81b0cf55950f0ea3ebe3dc79d0c3aa985af173a4cd6213ab2948
unsetPriority
public void unsetPriority()
{    this.priority = null;}
e8772fd017acb03008616b44c828754aeffa65f79916b75f1bc8f185666bc5b8
isSetPriority
public boolean isSetPriority()
{    return this.priority != null;}
261173c2575a969a5fcce0c56605f3b1dbb980869bec7d913b72e4abe5b16584
setPriorityIsSet
public void setPriorityIsSet(boolean value)
{    if (!value) {        this.priority = null;    }}
a624aa1b85808a74c9f320025ea600169bd6e4692611a44ef53a1970442ef820
getBody
public byte[] getBody()
{    setBody(org.apache.thrift.TBaseHelper.rightSize(body));    return body == null ? null : body.array();}
6825dd2155acce7578b5606a92bed8085ff901f9ae2b15ad46eb18db83fdc09b
bufferForBody
public ByteBuffer bufferForBody()
{    return org.apache.thrift.TBaseHelper.copyBinary(body);}
f3119fb9c7b01d96eef2cceda08b56535d9733cf381abe1ed5719c168eeafac0
setBody
public ThriftFlumeEvent setBody(byte[] body)
{    this.body = body == null ? (ByteBuffer) null : ByteBuffer.wrap(Arrays.copyOf(body, body.length));    return this;}
6d8efae403ba0b86d295ad5e9bef4b1271f23c1a550dd01755bae760d4b0206a
setBody
public ThriftFlumeEvent setBody(ByteBuffer body)
{    this.body = org.apache.thrift.TBaseHelper.copyBinary(body);    return this;}
bbd2e7250ca731f2583f817bf60c907b11b4b3d376a9c63f64dd4d1ebd41e273
unsetBody
public void unsetBody()
{    this.body = null;}
e78c3c9980dd4f34198d7b9ffe6e92e064fbd41f217bb4eee7ede4ab182a8e79
isSetBody
public boolean isSetBody()
{    return this.body != null;}
73c5b5c0ca4a4b1dd3cf1158ccd1e92892fc068c9732b46a15c02aa91e4612fb
setBodyIsSet
public void setBodyIsSet(boolean value)
{    if (!value) {        this.body = null;    }}
51166947659c74823a6ef26e3480f8ab4c6396997552aa6e67d664e0567096c9
getNanos
public long getNanos()
{    return this.nanos;}
5c867f0f1b5940e1f72b9f7869c84a0115bf97cfdd7964dad33e8893f2a3e573
setNanos
public ThriftFlumeEvent setNanos(long nanos)
{    this.nanos = nanos;    setNanosIsSet(true);    return this;}
e0baf7b605b86f4dd91c1ad0bf6038f2a6a4cd8234c1f5e6d7072210aafa2670
unsetNanos
public void unsetNanos()
{    __isset_bitfield = EncodingUtils.clearBit(__isset_bitfield, __NANOS_ISSET_ID);}
90af457853ded280170afd51d4b19ef9854bc0db9f7e5553dd0ecceb262c7c0b
isSetNanos
public boolean isSetNanos()
{    return EncodingUtils.testBit(__isset_bitfield, __NANOS_ISSET_ID);}
ddf8df8b4bf72e19d495697f0d9a358852cc7bcd7fa69490c3da36c3eb7c7ec1
setNanosIsSet
public void setNanosIsSet(boolean value)
{    __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __NANOS_ISSET_ID, value);}
165b1c9352ad3d309866d5286d1a7fd8eae4d022cb5ad661b1269ac75c218ebb
getHost
public String getHost()
{    return this.host;}
1f3c33d350db41bdc8e34a7a1484fe8f2c2a2d8f993035b2953d852ae4a2562f
setHost
public ThriftFlumeEvent setHost(String host)
{    this.host = host;    return this;}
8b7fce167451b1b5c7ddadd1a12239cfc4365cf1510ff385171690aa40278a79
unsetHost
public void unsetHost()
{    this.host = null;}
409af77183785969b9d4fff35db9a0828b7e89afcca88ac52e358eab101e1f9b
isSetHost
public boolean isSetHost()
{    return this.host != null;}
961eb8eeb0458540fbc22e76a3a66823f175ed44feb84d2f7b76104c10e74013
setHostIsSet
public void setHostIsSet(boolean value)
{    if (!value) {        this.host = null;    }}
9e16401f415f504dab50a8ea4ce34c3ff5d49dbed7f8d0687c2b631ff9457c4e
getFieldsSize
public int getFieldsSize()
{    return (this.fields == null) ? 0 : this.fields.size();}
3afa1781a9f1dce3079cba696c7a1cf3dbcc420166f7f041c60d59c481311288
putToFields
public void putToFields(String key, ByteBuffer val)
{    if (this.fields == null) {        this.fields = new HashMap<String, ByteBuffer>();    }    this.fields.put(key, val);}
3bcb099b19c495c5f76be337e31c91430c3728d1c7017131c896be9d6eb51947
getFields
public Map<String, ByteBuffer> getFields()
{    return this.fields;}
17889710556e9a4ab68cac11717c18316f63d40d827e3ba0ba12d896add17550
setFields
public ThriftFlumeEvent setFields(Map<String, ByteBuffer> fields)
{    this.fields = fields;    return this;}
e4b748745644a06846bd955b8359e80c7c0fc38dd81864cf502fa55aec93817b
unsetFields
public void unsetFields()
{    this.fields = null;}
ad894ddd4f9a7848139d0b733d50c630e7befa449d2e1b3a8db9f143dcc9c3a6
isSetFields
public boolean isSetFields()
{    return this.fields != null;}
6e3048398b9337ac591ef1527bb43fb20dc943063aa46fd4f54c0eb4f413ea7f
setFieldsIsSet
public void setFieldsIsSet(boolean value)
{    if (!value) {        this.fields = null;    }}
56898e9e8fffee777f79916bb0318d8a0a1794f171b373787ede8ccabb314f39
setFieldValue
public void setFieldValue(_Fields field, Object value)
{    switch(field) {        case TIMESTAMP:            if (value == null) {                unsetTimestamp();            } else {                setTimestamp((Long) value);            }            break;        case PRIORITY:            if (value == null) {                unsetPriority();            } else {                setPriority((Priority) value);            }            break;        case BODY:            if (value == null) {                unsetBody();            } else {                setBody((ByteBuffer) value);            }            break;        case NANOS:            if (value == null) {                unsetNanos();            } else {                setNanos((Long) value);            }            break;        case HOST:            if (value == null) {                unsetHost();            } else {                setHost((String) value);            }            break;        case FIELDS:            if (value == null) {                unsetFields();            } else {                setFields((Map<String, ByteBuffer>) value);            }            break;    }}
464d81fc54c8c50a21a786b4dc4dd56822e73892271735c454cff15126bc2dfd
getFieldValue
public Object getFieldValue(_Fields field)
{    switch(field) {        case TIMESTAMP:            return getTimestamp();        case PRIORITY:            return getPriority();        case BODY:            return getBody();        case NANOS:            return getNanos();        case HOST:            return getHost();        case FIELDS:            return getFields();    }    throw new IllegalStateException();}
71ed64fc282e6b120c36448a4f95d0d8102f98c0455e5f84713743b2826d64c9
isSet
public boolean isSet(_Fields field)
{    if (field == null) {        throw new IllegalArgumentException();    }    switch(field) {        case TIMESTAMP:            return isSetTimestamp();        case PRIORITY:            return isSetPriority();        case BODY:            return isSetBody();        case NANOS:            return isSetNanos();        case HOST:            return isSetHost();        case FIELDS:            return isSetFields();    }    throw new IllegalStateException();}
6b3ab298cb5d88dbb2c510c786f53e377489a40e2716e63c26a3e1691765f6c5
equals
public boolean equals(Object that)
{    if (that == null)        return false;    if (that instanceof ThriftFlumeEvent)        return this.equals((ThriftFlumeEvent) that);    return false;}
9158faf8319125a7abb82b54fbc77d61a302a6adeb01b3af2229439e67cbdee3
equals
public boolean equals(ThriftFlumeEvent that)
{    if (that == null)        return false;    boolean this_present_timestamp = true;    boolean that_present_timestamp = true;    if (this_present_timestamp || that_present_timestamp) {        if (!(this_present_timestamp && that_present_timestamp))            return false;        if (this.timestamp != that.timestamp)            return false;    }    boolean this_present_priority = true && this.isSetPriority();    boolean that_present_priority = true && that.isSetPriority();    if (this_present_priority || that_present_priority) {        if (!(this_present_priority && that_present_priority))            return false;        if (!this.priority.equals(that.priority))            return false;    }    boolean this_present_body = true && this.isSetBody();    boolean that_present_body = true && that.isSetBody();    if (this_present_body || that_present_body) {        if (!(this_present_body && that_present_body))            return false;        if (!this.body.equals(that.body))            return false;    }    boolean this_present_nanos = true;    boolean that_present_nanos = true;    if (this_present_nanos || that_present_nanos) {        if (!(this_present_nanos && that_present_nanos))            return false;        if (this.nanos != that.nanos)            return false;    }    boolean this_present_host = true && this.isSetHost();    boolean that_present_host = true && that.isSetHost();    if (this_present_host || that_present_host) {        if (!(this_present_host && that_present_host))            return false;        if (!this.host.equals(that.host))            return false;    }    boolean this_present_fields = true && this.isSetFields();    boolean that_present_fields = true && that.isSetFields();    if (this_present_fields || that_present_fields) {        if (!(this_present_fields && that_present_fields))            return false;        if (!this.fields.equals(that.fields))            return false;    }    return true;}
0ac42bf5188762fc1283b5cbd2b3bb1031e80963813b3b310b15c3fb47050003
hashCode
public int hashCode()
{    List<Object> list = new ArrayList<Object>();    boolean present_timestamp = true;    list.add(present_timestamp);    if (present_timestamp)        list.add(timestamp);    boolean present_priority = true && (isSetPriority());    list.add(present_priority);    if (present_priority)        list.add(priority.getValue());    boolean present_body = true && (isSetBody());    list.add(present_body);    if (present_body)        list.add(body);    boolean present_nanos = true;    list.add(present_nanos);    if (present_nanos)        list.add(nanos);    boolean present_host = true && (isSetHost());    list.add(present_host);    if (present_host)        list.add(host);    boolean present_fields = true && (isSetFields());    list.add(present_fields);    if (present_fields)        list.add(fields);    return list.hashCode();}
2776a7656966ac330be02b6e48740a44b6aff157c729fd79247c8e892cd0d433
compareTo
public int compareTo(ThriftFlumeEvent other)
{    if (!getClass().equals(other.getClass())) {        return getClass().getName().compareTo(other.getClass().getName());    }    int lastComparison = 0;    lastComparison = Boolean.valueOf(isSetTimestamp()).compareTo(other.isSetTimestamp());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetTimestamp()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.timestamp, other.timestamp);        if (lastComparison != 0) {            return lastComparison;        }    }    lastComparison = Boolean.valueOf(isSetPriority()).compareTo(other.isSetPriority());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetPriority()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.priority, other.priority);        if (lastComparison != 0) {            return lastComparison;        }    }    lastComparison = Boolean.valueOf(isSetBody()).compareTo(other.isSetBody());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetBody()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.body, other.body);        if (lastComparison != 0) {            return lastComparison;        }    }    lastComparison = Boolean.valueOf(isSetNanos()).compareTo(other.isSetNanos());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetNanos()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.nanos, other.nanos);        if (lastComparison != 0) {            return lastComparison;        }    }    lastComparison = Boolean.valueOf(isSetHost()).compareTo(other.isSetHost());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetHost()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.host, other.host);        if (lastComparison != 0) {            return lastComparison;        }    }    lastComparison = Boolean.valueOf(isSetFields()).compareTo(other.isSetFields());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetFields()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.fields, other.fields);        if (lastComparison != 0) {            return lastComparison;        }    }    return 0;}
8ce4cec748163fe422fba58a0ef1f5936a95d5ce0ec9e530aab7c5a59149b857
fieldForId
public _Fields fieldForId(int fieldId)
{    return _Fields.findByThriftId(fieldId);}
9c387dbc68e2929966a2f4d7377de396c1c24932dd7e709eba5cf9e1c90787af
read
public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException
{    schemes.get(iprot.getScheme()).getScheme().read(iprot, this);}
72f9005ef45238c38f6c8b9506f41c8599609ccde331e03c7044ee080e1472da
write
public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException
{    schemes.get(oprot.getScheme()).getScheme().write(oprot, this);}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    StringBuilder sb = new StringBuilder("ThriftFlumeEvent(");    boolean first = true;    sb.append("timestamp:");    sb.append(this.timestamp);    first = false;    if (!first)        sb.append(", ");    sb.append("priority:");    if (this.priority == null) {        sb.append("null");    } else {        sb.append(this.priority);    }    first = false;    if (!first)        sb.append(", ");    sb.append("body:");    if (this.body == null) {        sb.append("null");    } else {        org.apache.thrift.TBaseHelper.toString(this.body, sb);    }    first = false;    if (!first)        sb.append(", ");    sb.append("nanos:");    sb.append(this.nanos);    first = false;    if (!first)        sb.append(", ");    sb.append("host:");    if (this.host == null) {        sb.append("null");    } else {        sb.append(this.host);    }    first = false;    if (!first)        sb.append(", ");    sb.append("fields:");    if (this.fields == null) {        sb.append("null");    } else {        sb.append(this.fields);    }    first = false;    sb.append(")");    return sb.toString();}
e9a9838299550df368382cb18b6693a9d80b274b5c7bc089afc33713eceefbe1
validate
public void validate() throws org.apache.thrift.TException
{}
784e52bd99c637d4fd80e90272ace2edbc622a5a5ac2a515ab45f6d177fc378a
writeObject
private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException
{    try {        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
a2d949a3bc49af9f8b746197cee0585da9e196149570b4a376f3635b857a1744
readObject
private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException
{    try {                __isset_bitfield = 0;        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
dfdf1a28c2416ef7d317d21385dd5a48567a4fe15eb3c1cbe4394bdf69b83e75
getScheme
public ThriftFlumeEventStandardScheme getScheme()
{    return new ThriftFlumeEventStandardScheme();}
88bb01b5cb02b97411a3f4c6a8571d130cf36e97e765fdb003ebaedab3ec1ffb
read
public void read(org.apache.thrift.protocol.TProtocol iprot, ThriftFlumeEvent struct) throws org.apache.thrift.TException
{    org.apache.thrift.protocol.TField schemeField;    iprot.readStructBegin();    while (true) {        schemeField = iprot.readFieldBegin();        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) {            break;        }        switch(schemeField.id) {            case             1:                if (schemeField.type == org.apache.thrift.protocol.TType.I64) {                    struct.timestamp = iprot.readI64();                    struct.setTimestampIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            case             2:                if (schemeField.type == org.apache.thrift.protocol.TType.I32) {                    struct.priority = com.cloudera.flume.handlers.thrift.Priority.findByValue(iprot.readI32());                    struct.setPriorityIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            case             3:                if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {                    struct.body = iprot.readBinary();                    struct.setBodyIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            case             4:                if (schemeField.type == org.apache.thrift.protocol.TType.I64) {                    struct.nanos = iprot.readI64();                    struct.setNanosIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            case             5:                if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {                    struct.host = iprot.readString();                    struct.setHostIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            case             6:                if (schemeField.type == org.apache.thrift.protocol.TType.MAP) {                    {                        org.apache.thrift.protocol.TMap _map0 = iprot.readMapBegin();                        struct.fields = new HashMap<String, ByteBuffer>(2 * _map0.size);                        String _key1;                        ByteBuffer _val2;                        for (int _i3 = 0; _i3 < _map0.size; ++_i3) {                            _key1 = iprot.readString();                            _val2 = iprot.readBinary();                            struct.fields.put(_key1, _val2);                        }                        iprot.readMapEnd();                    }                    struct.setFieldsIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            default:                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);        }        iprot.readFieldEnd();    }    iprot.readStructEnd();        struct.validate();}
39463fe1fc1c2a3d91c3f823d9addd7c99382ddb3bca23d72e9c9a87503aebd1
write
public void write(org.apache.thrift.protocol.TProtocol oprot, ThriftFlumeEvent struct) throws org.apache.thrift.TException
{    struct.validate();    oprot.writeStructBegin(STRUCT_DESC);    oprot.writeFieldBegin(TIMESTAMP_FIELD_DESC);    oprot.writeI64(struct.timestamp);    oprot.writeFieldEnd();    if (struct.priority != null) {        oprot.writeFieldBegin(PRIORITY_FIELD_DESC);        oprot.writeI32(struct.priority.getValue());        oprot.writeFieldEnd();    }    if (struct.body != null) {        oprot.writeFieldBegin(BODY_FIELD_DESC);        oprot.writeBinary(struct.body);        oprot.writeFieldEnd();    }    oprot.writeFieldBegin(NANOS_FIELD_DESC);    oprot.writeI64(struct.nanos);    oprot.writeFieldEnd();    if (struct.host != null) {        oprot.writeFieldBegin(HOST_FIELD_DESC);        oprot.writeString(struct.host);        oprot.writeFieldEnd();    }    if (struct.fields != null) {        oprot.writeFieldBegin(FIELDS_FIELD_DESC);        {            oprot.writeMapBegin(new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, struct.fields.size()));            for (Map.Entry<String, ByteBuffer> _iter4 : struct.fields.entrySet()) {                oprot.writeString(_iter4.getKey());                oprot.writeBinary(_iter4.getValue());            }            oprot.writeMapEnd();        }        oprot.writeFieldEnd();    }    oprot.writeFieldStop();    oprot.writeStructEnd();}
b7a8b6dabda80fe8ca03969c956638825445621ac37b10813fb4003f61ead2e3
getScheme
public ThriftFlumeEventTupleScheme getScheme()
{    return new ThriftFlumeEventTupleScheme();}
b4eb96149fcdb1ffb99a6e16024c46faa76c1b4c7c2e72265c9f5ea50e804593
write
public void write(org.apache.thrift.protocol.TProtocol prot, ThriftFlumeEvent struct) throws org.apache.thrift.TException
{    TTupleProtocol oprot = (TTupleProtocol) prot;    BitSet optionals = new BitSet();    if (struct.isSetTimestamp()) {        optionals.set(0);    }    if (struct.isSetPriority()) {        optionals.set(1);    }    if (struct.isSetBody()) {        optionals.set(2);    }    if (struct.isSetNanos()) {        optionals.set(3);    }    if (struct.isSetHost()) {        optionals.set(4);    }    if (struct.isSetFields()) {        optionals.set(5);    }    oprot.writeBitSet(optionals, 6);    if (struct.isSetTimestamp()) {        oprot.writeI64(struct.timestamp);    }    if (struct.isSetPriority()) {        oprot.writeI32(struct.priority.getValue());    }    if (struct.isSetBody()) {        oprot.writeBinary(struct.body);    }    if (struct.isSetNanos()) {        oprot.writeI64(struct.nanos);    }    if (struct.isSetHost()) {        oprot.writeString(struct.host);    }    if (struct.isSetFields()) {        {            oprot.writeI32(struct.fields.size());            for (Map.Entry<String, ByteBuffer> _iter5 : struct.fields.entrySet()) {                oprot.writeString(_iter5.getKey());                oprot.writeBinary(_iter5.getValue());            }        }    }}
05d7c1b8349c8aa4f7928380b00b26dfcbc1fb7a3d18bc8387e943602eeeecf7
read
public void read(org.apache.thrift.protocol.TProtocol prot, ThriftFlumeEvent struct) throws org.apache.thrift.TException
{    TTupleProtocol iprot = (TTupleProtocol) prot;    BitSet incoming = iprot.readBitSet(6);    if (incoming.get(0)) {        struct.timestamp = iprot.readI64();        struct.setTimestampIsSet(true);    }    if (incoming.get(1)) {        struct.priority = com.cloudera.flume.handlers.thrift.Priority.findByValue(iprot.readI32());        struct.setPriorityIsSet(true);    }    if (incoming.get(2)) {        struct.body = iprot.readBinary();        struct.setBodyIsSet(true);    }    if (incoming.get(3)) {        struct.nanos = iprot.readI64();        struct.setNanosIsSet(true);    }    if (incoming.get(4)) {        struct.host = iprot.readString();        struct.setHostIsSet(true);    }    if (incoming.get(5)) {        {            org.apache.thrift.protocol.TMap _map6 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());            struct.fields = new HashMap<String, ByteBuffer>(2 * _map6.size);            String _key7;            ByteBuffer _val8;            for (int _i9 = 0; _i9 < _map6.size; ++_i9) {                _key7 = iprot.readString();                _val8 = iprot.readBinary();                struct.fields.put(_key7, _val8);            }        }        struct.setFieldsIsSet(true);    }}
c51e5cb6ab84996a366ca4c36408fdbb38461fdcc74ad26ed70818820572aaea
getClient
public Client getClient(org.apache.thrift.protocol.TProtocol prot)
{    return new Client(prot);}
f9e94ad26495767f197f0f23bc1a6ce01f90f5c97eede94dcba020bf0dbb3a1f
getClient
public Client getClient(org.apache.thrift.protocol.TProtocol iprot, org.apache.thrift.protocol.TProtocol oprot)
{    return new Client(iprot, oprot);}
2ee99747aa9f1817b046211a8415a43f92912a6de7d304fdbace6bb1f79bfcec
append
public void append(ThriftFlumeEvent evt) throws org.apache.thrift.TException
{    send_append(evt);}
2c4b9436e0511039dd789bd99b69d1ee1722187eb6d61fea827b9f761156138e
send_append
public void send_append(ThriftFlumeEvent evt) throws org.apache.thrift.TException
{    append_args args = new append_args();    args.setEvt(evt);    sendBaseOneway("append", args);}
74c04afedff7e7f1db198af05495ab99d94093999f23a6edf9a07c8ee8190112
close
public void close() throws org.apache.thrift.TException
{    send_close();    recv_close();}
e76fa24e9d96029d60ffcefe865d3eca2690a3c9d2a231a8e205ed303e1bf151
send_close
public void send_close() throws org.apache.thrift.TException
{    close_args args = new close_args();    sendBase("close", args);}
eef0d2ecd6509276f921c3f4e6451bc04dbb7f95a6d93dfab0e4ef2b10e604cd
recv_close
public void recv_close() throws org.apache.thrift.TException
{    close_result result = new close_result();    receiveBase(result, "close");    return;}
f3ce7d595d2009029c2fe49ca987d74d1a0cbb743047cd46460382cbee61e7ac
getAsyncClient
public AsyncClient getAsyncClient(org.apache.thrift.transport.TNonblockingTransport transport)
{    return new AsyncClient(protocolFactory, clientManager, transport);}
303dc3fd98133996d1971fa0bcd1a43fb6c8ffa751efc1965dc362f435a391ec
append
public void append(ThriftFlumeEvent evt, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException
{    checkReady();    append_call method_call = new append_call(evt, resultHandler, this, ___protocolFactory, ___transport);    this.___currentMethod = method_call;    ___manager.call(method_call);}
345dc223bb11c0c727744b96de56d5f0f1f3c374a491b829541ac5c66b1c1fe4
write_args
public void write_args(org.apache.thrift.protocol.TProtocol prot) throws org.apache.thrift.TException
{    prot.writeMessageBegin(new org.apache.thrift.protocol.TMessage("append", org.apache.thrift.protocol.TMessageType.ONEWAY, 0));    append_args args = new append_args();    args.setEvt(evt);    args.write(prot);    prot.writeMessageEnd();}
8269412134ae420ee447a4bed83e0158c036c979f371fd69ab849ca2087fc27f
getResult
public void getResult() throws org.apache.thrift.TException
{    if (getState() != org.apache.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {        throw new IllegalStateException("Method call not finished!");    }    org.apache.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());    org.apache.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);}
8361a8400e22b1542d7ccffdd2a0b6fdd2ac3ad1558c804e14d0e3c3939c43e3
close
public void close(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException
{    checkReady();    close_call method_call = new close_call(resultHandler, this, ___protocolFactory, ___transport);    this.___currentMethod = method_call;    ___manager.call(method_call);}
345dc223bb11c0c727744b96de56d5f0f1f3c374a491b829541ac5c66b1c1fe4
write_args
public void write_args(org.apache.thrift.protocol.TProtocol prot) throws org.apache.thrift.TException
{    prot.writeMessageBegin(new org.apache.thrift.protocol.TMessage("close", org.apache.thrift.protocol.TMessageType.CALL, 0));    close_args args = new close_args();    args.write(prot);    prot.writeMessageEnd();}
8269412134ae420ee447a4bed83e0158c036c979f371fd69ab849ca2087fc27f
getResult
public void getResult() throws org.apache.thrift.TException
{    if (getState() != org.apache.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {        throw new IllegalStateException("Method call not finished!");    }    org.apache.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());    org.apache.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);    (new Client(prot)).recv_close();}
738d78d4660b6e44339a7f3c7826f5d36a27f149eba243598f194475b7236304
getProcessMap
private static Map<String, org.apache.thrift.ProcessFunction<I, ? extends org.apache.thrift.TBase>> getProcessMap(Map<String, org.apache.thrift.ProcessFunction<I, ? extends org.apache.thrift.TBase>> processMap)
{    processMap.put("append", new append());    processMap.put("close", new close());    return processMap;}
fab9ebfb6770036ca6071b38a442fa954ec29efcf210daee760abb23bcb51493
getEmptyArgsInstance
public append_args getEmptyArgsInstance()
{    return new append_args();}
bebf296c86daa8f23132c9bae180b870c6dd9b8ba06fba8cc6695c835567cc77
isOneway
protected boolean isOneway()
{    return true;}
0ff32682c26201844b37294f065e5b1c935e140bab73a7ae38a54940ffea343b
getResult
public org.apache.thrift.TBase getResult(I iface, append_args args) throws org.apache.thrift.TException
{    iface.append(args.evt);    return null;}
9fd025a09523717c4678e357cef9626a5650283eb7349efeb595888375beb950
getEmptyArgsInstance
public close_args getEmptyArgsInstance()
{    return new close_args();}
bebf296c86daa8f23132c9bae180b870c6dd9b8ba06fba8cc6695c835567cc77
isOneway
protected boolean isOneway()
{    return false;}
cea255ef7bef3b2275ad884eb0c57f08e920418e38b1d7ed9964165bd9634ef5
getResult
public close_result getResult(I iface, close_args args) throws org.apache.thrift.TException
{    close_result result = new close_result();    iface.close();    return result;}
0409c31db10aa18694f957fa32b798fbeb64358a429f845b92d5de9db93dd0c4
getProcessMap
private static Map<String, org.apache.thrift.AsyncProcessFunction<I, ? extends org.apache.thrift.TBase, ?>> getProcessMap(Map<String, org.apache.thrift.AsyncProcessFunction<I, ? extends org.apache.thrift.TBase, ?>> processMap)
{    processMap.put("append", new append());    processMap.put("close", new close());    return processMap;}
fab9ebfb6770036ca6071b38a442fa954ec29efcf210daee760abb23bcb51493
getEmptyArgsInstance
public append_args getEmptyArgsInstance()
{    return new append_args();}
88076e4fdbf9f6c1a1e24bcd58d13357e2cca43eda177e8d755dd362ce3cb1bc
getResultHandler
public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid)
{    final org.apache.thrift.AsyncProcessFunction fcall = this;    return new AsyncMethodCallback<Void>() {        public void onComplete(Void o) {        }        public void onError(Exception e) {        }    };}
cd5b8a19197cb3ccf1cd836a996592642fc7ac634c77d8dae64fa6b6d826d77c
onComplete
public void onComplete(Void o)
{}
50d81b3017874db254d9688aef6f4422ecef15f2cd874858a2f0d6437f81587e
onError
public void onError(Exception e)
{}
bebf296c86daa8f23132c9bae180b870c6dd9b8ba06fba8cc6695c835567cc77
isOneway
protected boolean isOneway()
{    return true;}
4e9e05d3c93b79bd37a3331b3cbf3bbb1187faf7ff9c2989570cfce0d0daf222
start
public void start(I iface, append_args args, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws TException
{    iface.append(args.evt, resultHandler);}
9fd025a09523717c4678e357cef9626a5650283eb7349efeb595888375beb950
getEmptyArgsInstance
public close_args getEmptyArgsInstance()
{    return new close_args();}
88076e4fdbf9f6c1a1e24bcd58d13357e2cca43eda177e8d755dd362ce3cb1bc
getResultHandler
public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid)
{    final org.apache.thrift.AsyncProcessFunction fcall = this;    return new AsyncMethodCallback<Void>() {        public void onComplete(Void o) {            close_result result = new close_result();            try {                fcall.sendResponse(fb, result, org.apache.thrift.protocol.TMessageType.REPLY, seqid);                return;            } catch (Exception e) {                LOGGER.error("Exception writing to internal frame buffer", e);            }            fb.close();        }        public void onError(Exception e) {            byte msgType = org.apache.thrift.protocol.TMessageType.REPLY;            org.apache.thrift.TBase msg;            close_result result = new close_result();            {                msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;                msg = (org.apache.thrift.TBase) new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());            }            try {                fcall.sendResponse(fb, msg, msgType, seqid);                return;            } catch (Exception ex) {                LOGGER.error("Exception writing to internal frame buffer", ex);            }            fb.close();        }    };}
cd5b8a19197cb3ccf1cd836a996592642fc7ac634c77d8dae64fa6b6d826d77c
onComplete
public void onComplete(Void o)
{    close_result result = new close_result();    try {        fcall.sendResponse(fb, result, org.apache.thrift.protocol.TMessageType.REPLY, seqid);        return;    } catch (Exception e) {        LOGGER.error("Exception writing to internal frame buffer", e);    }    fb.close();}
50d81b3017874db254d9688aef6f4422ecef15f2cd874858a2f0d6437f81587e
onError
public void onError(Exception e)
{    byte msgType = org.apache.thrift.protocol.TMessageType.REPLY;    org.apache.thrift.TBase msg;    close_result result = new close_result();    {        msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;        msg = (org.apache.thrift.TBase) new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());    }    try {        fcall.sendResponse(fb, msg, msgType, seqid);        return;    } catch (Exception ex) {        LOGGER.error("Exception writing to internal frame buffer", ex);    }    fb.close();}
bebf296c86daa8f23132c9bae180b870c6dd9b8ba06fba8cc6695c835567cc77
isOneway
protected boolean isOneway()
{    return false;}
a8a56c80a6c56a0e19888aa206a31d031cd74b2709318e342e48de48fc4bde72
start
public void start(I iface, close_args args, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws TException
{    iface.close(resultHandler);}
92e9e6589c16b4fde1efd2a77a414bb3a621362cc64c5ef5a21381d0e5b55b5f
findByThriftId
public static _Fields findByThriftId(int fieldId)
{    switch(fieldId) {        case         1:            return EVT;        default:            return null;    }}
950148827ecab1253536a12003b5b2c41c2778a566a9ed4cb2487de641d6bde4
findByThriftIdOrThrow
public static _Fields findByThriftIdOrThrow(int fieldId)
{    _Fields fields = findByThriftId(fieldId);    if (fields == null)        throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");    return fields;}
eb44b9fdf7e05046f232aa9f1f3bb9a0cf815a486270439682862994e0d2c224
findByName
public static _Fields findByName(String name)
{    return byName.get(name);}
7f8fa4ecb4119b59b8047c285ac8f8729a909f121d1d3386d19ebfc6c04ab5df
getThriftFieldId
public short getThriftFieldId()
{    return _thriftId;}
68f4afd0e3cff42097dd5b6508fea1f7952d6d93f52ded3c1deea7186fff780c
getFieldName
public String getFieldName()
{    return _fieldName;}
6d0a02c9ac0e8bc12e6898bbb36fc312cdbb310d6f261b69ab890a1574872e1f
deepCopy
public append_args deepCopy()
{    return new append_args(this);}
21ac40bb9a99614b6ac18fa4043acb6173fccff96066fdfab963dba597923aa8
clear
public void clear()
{    this.evt = null;}
7106781281c822a2e66adf3e63542b0da19d8295a96f8ed002382a37c4e70386
getEvt
public ThriftFlumeEvent getEvt()
{    return this.evt;}
101542242049f23f339d17dddf0805554bd06ae88edfaa23c0b0e1646db34291
setEvt
public append_args setEvt(ThriftFlumeEvent evt)
{    this.evt = evt;    return this;}
d5d64596b5fb3ef64d42261e73b75c704905e267860a8667f6324ed4167f2266
unsetEvt
public void unsetEvt()
{    this.evt = null;}
41b3cddfc8827d573e3a3f9536efcc2bd9363dd8b2d9942c4c901199551cb0f5
isSetEvt
public boolean isSetEvt()
{    return this.evt != null;}
bb73633b6b351db859b025f545fee511ba0eb6767523017dd57973dacd5b261b
setEvtIsSet
public void setEvtIsSet(boolean value)
{    if (!value) {        this.evt = null;    }}
56898e9e8fffee777f79916bb0318d8a0a1794f171b373787ede8ccabb314f39
setFieldValue
public void setFieldValue(_Fields field, Object value)
{    switch(field) {        case EVT:            if (value == null) {                unsetEvt();            } else {                setEvt((ThriftFlumeEvent) value);            }            break;    }}
464d81fc54c8c50a21a786b4dc4dd56822e73892271735c454cff15126bc2dfd
getFieldValue
public Object getFieldValue(_Fields field)
{    switch(field) {        case EVT:            return getEvt();    }    throw new IllegalStateException();}
71ed64fc282e6b120c36448a4f95d0d8102f98c0455e5f84713743b2826d64c9
isSet
public boolean isSet(_Fields field)
{    if (field == null) {        throw new IllegalArgumentException();    }    switch(field) {        case EVT:            return isSetEvt();    }    throw new IllegalStateException();}
6b3ab298cb5d88dbb2c510c786f53e377489a40e2716e63c26a3e1691765f6c5
equals
public boolean equals(Object that)
{    if (that == null)        return false;    if (that instanceof append_args)        return this.equals((append_args) that);    return false;}
97266308601aace3cf2b09520931eac4b2095685bd0fcf8b488cfa656b03ee43
equals
public boolean equals(append_args that)
{    if (that == null)        return false;    boolean this_present_evt = true && this.isSetEvt();    boolean that_present_evt = true && that.isSetEvt();    if (this_present_evt || that_present_evt) {        if (!(this_present_evt && that_present_evt))            return false;        if (!this.evt.equals(that.evt))            return false;    }    return true;}
0ac42bf5188762fc1283b5cbd2b3bb1031e80963813b3b310b15c3fb47050003
hashCode
public int hashCode()
{    List<Object> list = new ArrayList<Object>();    boolean present_evt = true && (isSetEvt());    list.add(present_evt);    if (present_evt)        list.add(evt);    return list.hashCode();}
ec875de4680f4aa36cd6613be149d55c231417712e308042d5f5de1d3948f9ab
compareTo
public int compareTo(append_args other)
{    if (!getClass().equals(other.getClass())) {        return getClass().getName().compareTo(other.getClass().getName());    }    int lastComparison = 0;    lastComparison = Boolean.valueOf(isSetEvt()).compareTo(other.isSetEvt());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetEvt()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.evt, other.evt);        if (lastComparison != 0) {            return lastComparison;        }    }    return 0;}
8ce4cec748163fe422fba58a0ef1f5936a95d5ce0ec9e530aab7c5a59149b857
fieldForId
public _Fields fieldForId(int fieldId)
{    return _Fields.findByThriftId(fieldId);}
9c387dbc68e2929966a2f4d7377de396c1c24932dd7e709eba5cf9e1c90787af
read
public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException
{    schemes.get(iprot.getScheme()).getScheme().read(iprot, this);}
72f9005ef45238c38f6c8b9506f41c8599609ccde331e03c7044ee080e1472da
write
public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException
{    schemes.get(oprot.getScheme()).getScheme().write(oprot, this);}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    StringBuilder sb = new StringBuilder("append_args(");    boolean first = true;    sb.append("evt:");    if (this.evt == null) {        sb.append("null");    } else {        sb.append(this.evt);    }    first = false;    sb.append(")");    return sb.toString();}
e9a9838299550df368382cb18b6693a9d80b274b5c7bc089afc33713eceefbe1
validate
public void validate() throws org.apache.thrift.TException
{        if (evt != null) {        evt.validate();    }}
784e52bd99c637d4fd80e90272ace2edbc622a5a5ac2a515ab45f6d177fc378a
writeObject
private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException
{    try {        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
a2d949a3bc49af9f8b746197cee0585da9e196149570b4a376f3635b857a1744
readObject
private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException
{    try {        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
cf55bcfadc08d0298e097cf56dde2d351352c4520cf5229b97d3b872a143d18e
getScheme
public append_argsStandardScheme getScheme()
{    return new append_argsStandardScheme();}
ec50a00bb34dd4840c0420213fcd759eeb9f8014b58127ce5a962e727042102e
read
public void read(org.apache.thrift.protocol.TProtocol iprot, append_args struct) throws org.apache.thrift.TException
{    org.apache.thrift.protocol.TField schemeField;    iprot.readStructBegin();    while (true) {        schemeField = iprot.readFieldBegin();        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) {            break;        }        switch(schemeField.id) {            case             1:                if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {                    struct.evt = new ThriftFlumeEvent();                    struct.evt.read(iprot);                    struct.setEvtIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            default:                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);        }        iprot.readFieldEnd();    }    iprot.readStructEnd();        struct.validate();}
97a099fc0cd3bf3d170ef7fe529cb1111abba0a7f133025cf4c19ac57fd3cef3
write
public void write(org.apache.thrift.protocol.TProtocol oprot, append_args struct) throws org.apache.thrift.TException
{    struct.validate();    oprot.writeStructBegin(STRUCT_DESC);    if (struct.evt != null) {        oprot.writeFieldBegin(EVT_FIELD_DESC);        struct.evt.write(oprot);        oprot.writeFieldEnd();    }    oprot.writeFieldStop();    oprot.writeStructEnd();}
1dba376b5814fd505e392c45331af8c147a696f83c2371ba7a532566f093d80a
getScheme
public append_argsTupleScheme getScheme()
{    return new append_argsTupleScheme();}
f0adfbd44086ddc7bacfc531ecb21e95d8aa270e862f1314ed49d82f6011dd54
write
public void write(org.apache.thrift.protocol.TProtocol prot, append_args struct) throws org.apache.thrift.TException
{    TTupleProtocol oprot = (TTupleProtocol) prot;    BitSet optionals = new BitSet();    if (struct.isSetEvt()) {        optionals.set(0);    }    oprot.writeBitSet(optionals, 1);    if (struct.isSetEvt()) {        struct.evt.write(oprot);    }}
039b331f172ef46048ca41f5a01d69ed9339739a434d3571233be825ee7820ab
read
public void read(org.apache.thrift.protocol.TProtocol prot, append_args struct) throws org.apache.thrift.TException
{    TTupleProtocol iprot = (TTupleProtocol) prot;    BitSet incoming = iprot.readBitSet(1);    if (incoming.get(0)) {        struct.evt = new ThriftFlumeEvent();        struct.evt.read(iprot);        struct.setEvtIsSet(true);    }}
92e9e6589c16b4fde1efd2a77a414bb3a621362cc64c5ef5a21381d0e5b55b5f
findByThriftId
public static _Fields findByThriftId(int fieldId)
{    switch(fieldId) {        default:            return null;    }}
950148827ecab1253536a12003b5b2c41c2778a566a9ed4cb2487de641d6bde4
findByThriftIdOrThrow
public static _Fields findByThriftIdOrThrow(int fieldId)
{    _Fields fields = findByThriftId(fieldId);    if (fields == null)        throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");    return fields;}
eb44b9fdf7e05046f232aa9f1f3bb9a0cf815a486270439682862994e0d2c224
findByName
public static _Fields findByName(String name)
{    return byName.get(name);}
7f8fa4ecb4119b59b8047c285ac8f8729a909f121d1d3386d19ebfc6c04ab5df
getThriftFieldId
public short getThriftFieldId()
{    return _thriftId;}
68f4afd0e3cff42097dd5b6508fea1f7952d6d93f52ded3c1deea7186fff780c
getFieldName
public String getFieldName()
{    return _fieldName;}
a46093fb12df36def199cd5ccfa9d7143d4370910fd72af3e3c90256197c5cb3
deepCopy
public close_args deepCopy()
{    return new close_args(this);}
21ac40bb9a99614b6ac18fa4043acb6173fccff96066fdfab963dba597923aa8
clear
public void clear()
{}
56898e9e8fffee777f79916bb0318d8a0a1794f171b373787ede8ccabb314f39
setFieldValue
public void setFieldValue(_Fields field, Object value)
{    switch(field) {    }}
464d81fc54c8c50a21a786b4dc4dd56822e73892271735c454cff15126bc2dfd
getFieldValue
public Object getFieldValue(_Fields field)
{    switch(field) {    }    throw new IllegalStateException();}
71ed64fc282e6b120c36448a4f95d0d8102f98c0455e5f84713743b2826d64c9
isSet
public boolean isSet(_Fields field)
{    if (field == null) {        throw new IllegalArgumentException();    }    switch(field) {    }    throw new IllegalStateException();}
6b3ab298cb5d88dbb2c510c786f53e377489a40e2716e63c26a3e1691765f6c5
equals
public boolean equals(Object that)
{    if (that == null)        return false;    if (that instanceof close_args)        return this.equals((close_args) that);    return false;}
1f501773f274e0ddec916b8ebcbbf06116277a71841b2b51338f9782d5126ced
equals
public boolean equals(close_args that)
{    if (that == null)        return false;    return true;}
0ac42bf5188762fc1283b5cbd2b3bb1031e80963813b3b310b15c3fb47050003
hashCode
public int hashCode()
{    List<Object> list = new ArrayList<Object>();    return list.hashCode();}
1e4d93755b406527188eadfda340facfb05b323876ed239256072248d5732e41
compareTo
public int compareTo(close_args other)
{    if (!getClass().equals(other.getClass())) {        return getClass().getName().compareTo(other.getClass().getName());    }    int lastComparison = 0;    return 0;}
8ce4cec748163fe422fba58a0ef1f5936a95d5ce0ec9e530aab7c5a59149b857
fieldForId
public _Fields fieldForId(int fieldId)
{    return _Fields.findByThriftId(fieldId);}
9c387dbc68e2929966a2f4d7377de396c1c24932dd7e709eba5cf9e1c90787af
read
public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException
{    schemes.get(iprot.getScheme()).getScheme().read(iprot, this);}
72f9005ef45238c38f6c8b9506f41c8599609ccde331e03c7044ee080e1472da
write
public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException
{    schemes.get(oprot.getScheme()).getScheme().write(oprot, this);}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    StringBuilder sb = new StringBuilder("close_args(");    boolean first = true;    sb.append(")");    return sb.toString();}
e9a9838299550df368382cb18b6693a9d80b274b5c7bc089afc33713eceefbe1
validate
public void validate() throws org.apache.thrift.TException
{}
784e52bd99c637d4fd80e90272ace2edbc622a5a5ac2a515ab45f6d177fc378a
writeObject
private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException
{    try {        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
a2d949a3bc49af9f8b746197cee0585da9e196149570b4a376f3635b857a1744
readObject
private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException
{    try {        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
2742da8d85e461a73cc1929bae1f5636a78250f46fb8af1ec6dc192b465ecad5
getScheme
public close_argsStandardScheme getScheme()
{    return new close_argsStandardScheme();}
2666da786fefac241c4bbd157363bb675aaa151245cba2d5c9c686ebfaf3d3cb
read
public void read(org.apache.thrift.protocol.TProtocol iprot, close_args struct) throws org.apache.thrift.TException
{    org.apache.thrift.protocol.TField schemeField;    iprot.readStructBegin();    while (true) {        schemeField = iprot.readFieldBegin();        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) {            break;        }        switch(schemeField.id) {            default:                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);        }        iprot.readFieldEnd();    }    iprot.readStructEnd();        struct.validate();}
5807cdb5fcbed7925feba220cda1f10537cb33ad81e6a5add5291ad97abb06ea
write
public void write(org.apache.thrift.protocol.TProtocol oprot, close_args struct) throws org.apache.thrift.TException
{    struct.validate();    oprot.writeStructBegin(STRUCT_DESC);    oprot.writeFieldStop();    oprot.writeStructEnd();}
a715e6319e827962cc079cbc14491dd0c1b50b5c671ee9b728ee833d4a5acb98
getScheme
public close_argsTupleScheme getScheme()
{    return new close_argsTupleScheme();}
30c778dc8b5af252a2654731de205104b0cd8b750a6e101bbbb682e3ca0b0785
write
public void write(org.apache.thrift.protocol.TProtocol prot, close_args struct) throws org.apache.thrift.TException
{    TTupleProtocol oprot = (TTupleProtocol) prot;}
adcea70635c88bbb4fe8115054fd5c624a0a362ad75afa1866815c00baf1ad28
read
public void read(org.apache.thrift.protocol.TProtocol prot, close_args struct) throws org.apache.thrift.TException
{    TTupleProtocol iprot = (TTupleProtocol) prot;}
92e9e6589c16b4fde1efd2a77a414bb3a621362cc64c5ef5a21381d0e5b55b5f
findByThriftId
public static _Fields findByThriftId(int fieldId)
{    switch(fieldId) {        default:            return null;    }}
950148827ecab1253536a12003b5b2c41c2778a566a9ed4cb2487de641d6bde4
findByThriftIdOrThrow
public static _Fields findByThriftIdOrThrow(int fieldId)
{    _Fields fields = findByThriftId(fieldId);    if (fields == null)        throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");    return fields;}
eb44b9fdf7e05046f232aa9f1f3bb9a0cf815a486270439682862994e0d2c224
findByName
public static _Fields findByName(String name)
{    return byName.get(name);}
7f8fa4ecb4119b59b8047c285ac8f8729a909f121d1d3386d19ebfc6c04ab5df
getThriftFieldId
public short getThriftFieldId()
{    return _thriftId;}
68f4afd0e3cff42097dd5b6508fea1f7952d6d93f52ded3c1deea7186fff780c
getFieldName
public String getFieldName()
{    return _fieldName;}
8865b6cb24fee25092514ad0afa03b907de159f6452b23837e6870b6fb47069b
deepCopy
public close_result deepCopy()
{    return new close_result(this);}
21ac40bb9a99614b6ac18fa4043acb6173fccff96066fdfab963dba597923aa8
clear
public void clear()
{}
56898e9e8fffee777f79916bb0318d8a0a1794f171b373787ede8ccabb314f39
setFieldValue
public void setFieldValue(_Fields field, Object value)
{    switch(field) {    }}
464d81fc54c8c50a21a786b4dc4dd56822e73892271735c454cff15126bc2dfd
getFieldValue
public Object getFieldValue(_Fields field)
{    switch(field) {    }    throw new IllegalStateException();}
71ed64fc282e6b120c36448a4f95d0d8102f98c0455e5f84713743b2826d64c9
isSet
public boolean isSet(_Fields field)
{    if (field == null) {        throw new IllegalArgumentException();    }    switch(field) {    }    throw new IllegalStateException();}
6b3ab298cb5d88dbb2c510c786f53e377489a40e2716e63c26a3e1691765f6c5
equals
public boolean equals(Object that)
{    if (that == null)        return false;    if (that instanceof close_result)        return this.equals((close_result) that);    return false;}
c2abb1dc4314b4960c609e769c5eafb79d2741d4f5e3cb2c0a66ca539e468cce
equals
public boolean equals(close_result that)
{    if (that == null)        return false;    return true;}
0ac42bf5188762fc1283b5cbd2b3bb1031e80963813b3b310b15c3fb47050003
hashCode
public int hashCode()
{    List<Object> list = new ArrayList<Object>();    return list.hashCode();}
7167469f84727c2bb864f2de550865f8edb9f21c898d1596e8e89a7f558f62a0
compareTo
public int compareTo(close_result other)
{    if (!getClass().equals(other.getClass())) {        return getClass().getName().compareTo(other.getClass().getName());    }    int lastComparison = 0;    return 0;}
8ce4cec748163fe422fba58a0ef1f5936a95d5ce0ec9e530aab7c5a59149b857
fieldForId
public _Fields fieldForId(int fieldId)
{    return _Fields.findByThriftId(fieldId);}
9c387dbc68e2929966a2f4d7377de396c1c24932dd7e709eba5cf9e1c90787af
read
public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException
{    schemes.get(iprot.getScheme()).getScheme().read(iprot, this);}
72f9005ef45238c38f6c8b9506f41c8599609ccde331e03c7044ee080e1472da
write
public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException
{    schemes.get(oprot.getScheme()).getScheme().write(oprot, this);}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    StringBuilder sb = new StringBuilder("close_result(");    boolean first = true;    sb.append(")");    return sb.toString();}
e9a9838299550df368382cb18b6693a9d80b274b5c7bc089afc33713eceefbe1
validate
public void validate() throws org.apache.thrift.TException
{}
784e52bd99c637d4fd80e90272ace2edbc622a5a5ac2a515ab45f6d177fc378a
writeObject
private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException
{    try {        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
a2d949a3bc49af9f8b746197cee0585da9e196149570b4a376f3635b857a1744
readObject
private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException
{    try {        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
5c13c87a866a58b4536ace0b288d4ec7ff7c2cc862f24f860ef936b3a00e6d63
getScheme
public close_resultStandardScheme getScheme()
{    return new close_resultStandardScheme();}
f25d6a4b8cfee19f830961ea5f078df68f48b209de5ae62fc7ff87fba63401c2
read
public void read(org.apache.thrift.protocol.TProtocol iprot, close_result struct) throws org.apache.thrift.TException
{    org.apache.thrift.protocol.TField schemeField;    iprot.readStructBegin();    while (true) {        schemeField = iprot.readFieldBegin();        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) {            break;        }        switch(schemeField.id) {            default:                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);        }        iprot.readFieldEnd();    }    iprot.readStructEnd();        struct.validate();}
157f2cfedb9d81e464f4e61de9a68ea6e70bb9bf66fa81849cfbc2ec15742dc4
write
public void write(org.apache.thrift.protocol.TProtocol oprot, close_result struct) throws org.apache.thrift.TException
{    struct.validate();    oprot.writeStructBegin(STRUCT_DESC);    oprot.writeFieldStop();    oprot.writeStructEnd();}
38db1a41b049738d97b40b8468076b8970bfdb59553eddc45f133d234c108353
getScheme
public close_resultTupleScheme getScheme()
{    return new close_resultTupleScheme();}
00c4d3011ebc0530c0efc7da37b50b56abc615d72beea9a512eb6097c8c49cb8
write
public void write(org.apache.thrift.protocol.TProtocol prot, close_result struct) throws org.apache.thrift.TException
{    TTupleProtocol oprot = (TTupleProtocol) prot;}
cc9dd789647103b6764b1913c1f64ea24d63b647c5c0b6d28dcc59cf60ba683b
read
public void read(org.apache.thrift.protocol.TProtocol prot, close_result struct) throws org.apache.thrift.TException
{    TTupleProtocol iprot = (TTupleProtocol) prot;}
2ff66a48ae8c6ce041aae98e91d464b7e20dcdfefed4148456a12ff6ca0215e5
append
public void append(ThriftFlumeEvent evt)
{    if (evt == null) {        return;    }    Map<String, String> headers = new HashMap<String, String>();        headers.put(HOST, evt.getHost());    headers.put(TIMESTAMP, Long.toString(evt.getTimestamp()));    headers.put(PRIORITY, evt.getPriority().toString());    headers.put(NANOS, Long.toString(evt.getNanos()));    for (Entry<String, ByteBuffer> entry : evt.getFields().entrySet()) {        headers.put(entry.getKey().toString(), UTF_8.decode(entry.getValue()).toString());    }    headers.put(OG_EVENT, "yes");    Event event = EventBuilder.withBody(evt.getBody(), headers);    counterGroup.incrementAndGet("rpc.events");    try {        getChannelProcessor().processEvent(event);    } catch (ChannelException ex) {        LOG.warn("Failed to process event", ex);        return;    }    counterGroup.incrementAndGet("rpc.successful");    return;}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    server.serve();}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    port = Integer.parseInt(context.getString("port"));    host = context.getString("host");}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    try {        InetSocketAddress bindAddr = new InetSocketAddress(host, port);        serverTransport = new TServerSocket(bindAddr);        ThriftFlumeEventServer.Processor processor = new ThriftFlumeEventServer.Processor(new ThriftFlumeEventServerImpl());        server = new TThreadPoolServer(new TThreadPoolServer.Args(serverTransport).processor(processor));    } catch (TTransportException e) {        throw new FlumeException("Failed starting source", e);    }    ThriftHandler thriftHandler = new ThriftHandler(server);    thriftHandlerThread = new Thread(thriftHandler);    thriftHandlerThread.start();    super.start();}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    server.stop();    serverTransport.close();    try {        thriftHandlerThread.join();    } catch (InterruptedException eI) {        LOG.warn("stop interrupted", eI);        return;    }    super.stop();}
2ff66a48ae8c6ce041aae98e91d464b7e20dcdfefed4148456a12ff6ca0215e5
append
public void append(ThriftFlumeEvent evt)
{    TTransport transport;    try {        transport = new TSocket(host, port);        TProtocol protocol = new TBinaryProtocol(transport);        Client client = new Client(protocol);        transport.open();        client.append(evt);        transport.close();    } catch (TTransportException e) {        e.printStackTrace();    } catch (TException e) {        e.printStackTrace();    }}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    source = new ThriftLegacySource();    channel = new MemoryChannel();    Configurables.configure(channel, new Context());    List<Channel> channels = new ArrayList<Channel>();    channels.add(channel);    ChannelSelector rcs = new ReplicatingChannelSelector();    rcs.setChannels(channels);    source.setChannelProcessor(new ChannelProcessor(rcs));    try (ServerSocket socket = new ServerSocket(0)) {        selectedPort = socket.getLocalPort();    }}
f38c82adeb6124bee2be4dd15684e7b2b21aea85eb27305d49fc28f61b4abc66
bind
private void bind() throws InterruptedException
{    Context context = new Context();    context.put("port", String.valueOf(selectedPort));    context.put("host", "0.0.0.0");    Configurables.configure(source, context);    source.start();    Assert.assertTrue("Reached start or error", LifecycleController.waitForOneOf(source, LifecycleState.START_OR_ERROR));    Assert.assertEquals("Server is started", LifecycleState.START, source.getLifecycleState());}
c3128d0393b45b7e76560eff40e592288f219c147aa031045cf0e4488b80e0aa
stop
private void stop() throws InterruptedException
{    source.stop();    Assert.assertTrue("Reached stop or error", LifecycleController.waitForOneOf(source, LifecycleState.STOP_OR_ERROR));    Assert.assertEquals("Server is stopped", LifecycleState.STOP, source.getLifecycleState());}
f4f5bd17f7ef219499ed059849d7c2a0a6915756e4cd28bf2c10b3c9db532190
testLifecycle
public void testLifecycle() throws InterruptedException
{    bind();    stop();}
57d90793d7dcba7a87564056c6a9b1861757a6720e13e5223291aa5dfefacc9f
testRequest
public void testRequest() throws InterruptedException, IOException
{    bind();    Map<String, ByteBuffer> flumeMap = new HashMap<>();    ThriftFlumeEvent thriftEvent = new ThriftFlumeEvent(1, Priority.INFO, ByteBuffer.wrap("foo".getBytes()), 0, "fooHost", flumeMap);    FlumeClient fClient = new FlumeClient("0.0.0.0", selectedPort);    fClient.append(thriftEvent);        Transaction transaction = channel.getTransaction();    transaction.begin();    Event event = channel.take();    Assert.assertNotNull(event);    Assert.assertEquals("Channel contained our event", "foo", new String(event.getBody()));    transaction.commit();    transaction.close();    stop();}
c89cbfd7eda852a4e5a8a22001bf30b88835d6cca9be941a446814721c948ee9
testHeaders
public void testHeaders() throws InterruptedException, IOException
{    bind();    Map<String, ByteBuffer> flumeHeaders = new HashMap<>();    flumeHeaders.put("hello", ByteBuffer.wrap("world".getBytes("UTF-8")));    ThriftFlumeEvent thriftEvent = new ThriftFlumeEvent(1, Priority.INFO, ByteBuffer.wrap("foo".getBytes()), 0, "fooHost", flumeHeaders);    FlumeClient fClient = new FlumeClient("0.0.0.0", selectedPort);    fClient.append(thriftEvent);        Transaction transaction = channel.getTransaction();    transaction.begin();    Event event = channel.take();    Assert.assertNotNull(event);    Assert.assertEquals("Event in channel has our header", "world", event.getHeaders().get("hello"));    transaction.commit();    transaction.close();    stop();}
a2bf4d051617062d632680a78981c30aaf1851d8f3a8bdbaeb8a36c71b0f1715
getConfiguration
public MaterializedConfiguration getConfiguration()
{    MaterializedConfiguration conf = new SimpleMaterializedConfiguration();    FlumeConfiguration fconfig = getFlumeConfiguration();    AgentConfiguration agentConf = fconfig.getConfigurationFor(getAgentName());    if (agentConf != null) {        Map<String, ChannelComponent> channelComponentMap = Maps.newHashMap();        Map<String, SourceRunner> sourceRunnerMap = Maps.newHashMap();        Map<String, SinkRunner> sinkRunnerMap = Maps.newHashMap();        try {            loadChannels(agentConf, channelComponentMap);            loadSources(agentConf, channelComponentMap, sourceRunnerMap);            loadSinks(agentConf, channelComponentMap, sinkRunnerMap);            Set<String> channelNames = new HashSet<String>(channelComponentMap.keySet());            for (String channelName : channelNames) {                ChannelComponent channelComponent = channelComponentMap.get(channelName);                if (channelComponent.components.isEmpty()) {                    LOGGER.warn(String.format("Channel %s has no components connected" + " and has been removed.", channelName));                    channelComponentMap.remove(channelName);                    Map<String, Channel> nameChannelMap = channelCache.get(channelComponent.channel.getClass());                    if (nameChannelMap != null) {                        nameChannelMap.remove(channelName);                    }                } else {                    LOGGER.info(String.format("Channel %s connected to %s", channelName, channelComponent.components.toString()));                    conf.addChannel(channelName, channelComponent.channel);                }            }            for (Map.Entry<String, SourceRunner> entry : sourceRunnerMap.entrySet()) {                conf.addSourceRunner(entry.getKey(), entry.getValue());            }            for (Map.Entry<String, SinkRunner> entry : sinkRunnerMap.entrySet()) {                conf.addSinkRunner(entry.getKey(), entry.getValue());            }        } catch (InstantiationException ex) {            LOGGER.error("Failed to instantiate component", ex);        } finally {            channelComponentMap.clear();            sourceRunnerMap.clear();            sinkRunnerMap.clear();        }    } else {        LOGGER.warn("No configuration found for this host:{}", getAgentName());    }    return conf;}
d32b6f6173b212f43a4d239ed76282744e22d6fc747cef3b672f2afce4af8e99
getAgentName
public String getAgentName()
{    return agentName;}
c2a75cac5d0a0e6684c5ffeb760c649b05d12eabbf570519654dd7d7aafed086
loadChannels
private void loadChannels(AgentConfiguration agentConf, Map<String, ChannelComponent> channelComponentMap) throws InstantiationException
{    LOGGER.info("Creating channels");    /*     * Some channels will be reused across re-configurations. To handle this,     * we store all the names of current channels, perform the reconfiguration,     * and then if a channel was not used, we delete our reference to it.     * This supports the scenario where you enable channel "ch0" then remove it     * and add it back. Without this, channels like memory channel would cause     * the first instances data to show up in the seconds.     */    ListMultimap<Class<? extends Channel>, String> channelsNotReused = ArrayListMultimap.create();        for (Map.Entry<Class<? extends Channel>, Map<String, Channel>> entry : channelCache.entrySet()) {        Class<? extends Channel> channelKlass = entry.getKey();        Set<String> channelNames = entry.getValue().keySet();        channelsNotReused.get(channelKlass).addAll(channelNames);    }    Set<String> channelNames = agentConf.getChannelSet();    Map<String, ComponentConfiguration> compMap = agentConf.getChannelConfigMap();    /*     * Components which have a ComponentConfiguration object     */    for (String chName : channelNames) {        ComponentConfiguration comp = compMap.get(chName);        if (comp != null) {            Channel channel = getOrCreateChannel(channelsNotReused, comp.getComponentName(), comp.getType());            try {                Configurables.configure(channel, comp);                channelComponentMap.put(comp.getComponentName(), new ChannelComponent(channel));                LOGGER.info("Created channel " + chName);            } catch (Exception e) {                String msg = String.format("Channel %s has been removed due to an " + "error during configuration", chName);                LOGGER.error(msg, e);            }        }    }    /*     * Components which DO NOT have a ComponentConfiguration object     * and use only Context     */    for (String chName : channelNames) {        Context context = agentConf.getChannelContext().get(chName);        if (context != null) {            Channel channel = getOrCreateChannel(channelsNotReused, chName, context.getString(BasicConfigurationConstants.CONFIG_TYPE));            try {                Configurables.configure(channel, context);                channelComponentMap.put(chName, new ChannelComponent(channel));                LOGGER.info("Created channel " + chName);            } catch (Exception e) {                String msg = String.format("Channel %s has been removed due to an " + "error during configuration", chName);                LOGGER.error(msg, e);            }        }    }    /*     * Any channel which was not re-used, will have it's reference removed     */    for (Class<? extends Channel> channelKlass : channelsNotReused.keySet()) {        Map<String, Channel> channelMap = channelCache.get(channelKlass);        if (channelMap != null) {            for (String channelName : channelsNotReused.get(channelKlass)) {                if (channelMap.remove(channelName) != null) {                    LOGGER.info("Removed {} of type {}", channelName, channelKlass);                }            }            if (channelMap.isEmpty()) {                channelCache.remove(channelKlass);            }        }    }}
b05980175ffbc1e03a07b181ae39bc52febdc707cf2f6519e123fc9f4b2f3c71
getOrCreateChannel
private Channel getOrCreateChannel(ListMultimap<Class<? extends Channel>, String> channelsNotReused, String name, String type) throws FlumeException
{    Class<? extends Channel> channelClass = channelFactory.getClass(type);    /*     * Channel has requested a new instance on each re-configuration     */    if (channelClass.isAnnotationPresent(Disposable.class)) {        Channel channel = channelFactory.create(name, type);        channel.setName(name);        return channel;    }    Map<String, Channel> channelMap = channelCache.get(channelClass);    if (channelMap == null) {        channelMap = new HashMap<String, Channel>();        channelCache.put(channelClass, channelMap);    }    Channel channel = channelMap.get(name);    if (channel == null) {        channel = channelFactory.create(name, type);        channel.setName(name);        channelMap.put(name, channel);    }    channelsNotReused.get(channelClass).remove(name);    return channel;}
ae9c8dd476785f891d779d8cab6470abd00019f58a5fad3d932a6f9619f4cc2a
loadSources
private void loadSources(AgentConfiguration agentConf, Map<String, ChannelComponent> channelComponentMap, Map<String, SourceRunner> sourceRunnerMap) throws InstantiationException
{    Set<String> sourceNames = agentConf.getSourceSet();    Map<String, ComponentConfiguration> compMap = agentConf.getSourceConfigMap();    /*     * Components which have a ComponentConfiguration object     */    for (String sourceName : sourceNames) {        ComponentConfiguration comp = compMap.get(sourceName);        if (comp != null) {            SourceConfiguration config = (SourceConfiguration) comp;            Source source = sourceFactory.create(comp.getComponentName(), comp.getType());            try {                Configurables.configure(source, config);                Set<String> channelNames = config.getChannels();                List<Channel> sourceChannels = getSourceChannels(channelComponentMap, source, channelNames);                if (sourceChannels.isEmpty()) {                    String msg = String.format("Source %s is not connected to a " + "channel", sourceName);                    throw new IllegalStateException(msg);                }                ChannelSelectorConfiguration selectorConfig = config.getSelectorConfiguration();                ChannelSelector selector = ChannelSelectorFactory.create(sourceChannels, selectorConfig);                ChannelProcessor channelProcessor = new ChannelProcessor(selector);                Configurables.configure(channelProcessor, config);                source.setChannelProcessor(channelProcessor);                sourceRunnerMap.put(comp.getComponentName(), SourceRunner.forSource(source));                for (Channel channel : sourceChannels) {                    ChannelComponent channelComponent = Preconditions.checkNotNull(channelComponentMap.get(channel.getName()), String.format("Channel %s", channel.getName()));                    channelComponent.components.add(sourceName);                }            } catch (Exception e) {                String msg = String.format("Source %s has been removed due to an " + "error during configuration", sourceName);                LOGGER.error(msg, e);            }        }    }    /*     * Components which DO NOT have a ComponentConfiguration object     * and use only Context     */    Map<String, Context> sourceContexts = agentConf.getSourceContext();    for (String sourceName : sourceNames) {        Context context = sourceContexts.get(sourceName);        if (context != null) {            Source source = sourceFactory.create(sourceName, context.getString(BasicConfigurationConstants.CONFIG_TYPE));            try {                Configurables.configure(source, context);                String[] channelNames = context.getString(BasicConfigurationConstants.CONFIG_CHANNELS).split("\\s+");                List<Channel> sourceChannels = getSourceChannels(channelComponentMap, source, Arrays.asList(channelNames));                if (sourceChannels.isEmpty()) {                    String msg = String.format("Source %s is not connected to a " + "channel", sourceName);                    throw new IllegalStateException(msg);                }                Map<String, String> selectorConfig = context.getSubProperties(BasicConfigurationConstants.CONFIG_SOURCE_CHANNELSELECTOR_PREFIX);                ChannelSelector selector = ChannelSelectorFactory.create(sourceChannels, selectorConfig);                ChannelProcessor channelProcessor = new ChannelProcessor(selector);                Configurables.configure(channelProcessor, context);                source.setChannelProcessor(channelProcessor);                sourceRunnerMap.put(sourceName, SourceRunner.forSource(source));                for (Channel channel : sourceChannels) {                    ChannelComponent channelComponent = Preconditions.checkNotNull(channelComponentMap.get(channel.getName()), String.format("Channel %s", channel.getName()));                    channelComponent.components.add(sourceName);                }            } catch (Exception e) {                String msg = String.format("Source %s has been removed due to an " + "error during configuration", sourceName);                LOGGER.error(msg, e);            }        }    }}
beb034095449b8d8238d4a3e35f7dc6e2ed64c69561d0451c39b7ffd37ddcd5f
getSourceChannels
private List<Channel> getSourceChannels(Map<String, ChannelComponent> channelComponentMap, Source source, Collection<String> channelNames) throws InstantiationException
{    List<Channel> sourceChannels = new ArrayList<Channel>();    for (String chName : channelNames) {        ChannelComponent channelComponent = channelComponentMap.get(chName);        if (channelComponent != null) {            checkSourceChannelCompatibility(source, channelComponent.channel);            sourceChannels.add(channelComponent.channel);        }    }    return sourceChannels;}
750aca9de14f4c37d8ba486ffa9ef6c193beecac3e81b3db225c203ca9ee930b
checkSourceChannelCompatibility
private void checkSourceChannelCompatibility(Source source, Channel channel) throws InstantiationException
{    if (source instanceof BatchSizeSupported && channel instanceof TransactionCapacitySupported) {        long transCap = ((TransactionCapacitySupported) channel).getTransactionCapacity();        long batchSize = ((BatchSizeSupported) source).getBatchSize();        if (transCap < batchSize) {            String msg = String.format("Incompatible source and channel settings defined. " + "source's batch size is greater than the channels transaction capacity. " + "Source: %s, batch size = %d, channel %s, transaction capacity = %d", source.getName(), batchSize, channel.getName(), transCap);            throw new InstantiationException(msg);        }    }}
77c4f7491287178fe1c42cfc608b253832fbc83867e45afd1211d81fbba95a14
checkSinkChannelCompatibility
private void checkSinkChannelCompatibility(Sink sink, Channel channel) throws InstantiationException
{    if (sink instanceof BatchSizeSupported && channel instanceof TransactionCapacitySupported) {        long transCap = ((TransactionCapacitySupported) channel).getTransactionCapacity();        long batchSize = ((BatchSizeSupported) sink).getBatchSize();        if (transCap < batchSize) {            String msg = String.format("Incompatible sink and channel settings defined. " + "sink's batch size is greater than the channels transaction capacity. " + "Sink: %s, batch size = %d, channel %s, transaction capacity = %d", sink.getName(), batchSize, channel.getName(), transCap);            throw new InstantiationException(msg);        }    }}
df910293e1a2a4d6491ec5b1d80bc2a28b6d1b63e73d6244c704fad28e9040da
loadSinks
private void loadSinks(AgentConfiguration agentConf, Map<String, ChannelComponent> channelComponentMap, Map<String, SinkRunner> sinkRunnerMap) throws InstantiationException
{    Set<String> sinkNames = agentConf.getSinkSet();    Map<String, ComponentConfiguration> compMap = agentConf.getSinkConfigMap();    Map<String, Sink> sinks = new HashMap<String, Sink>();    /*     * Components which have a ComponentConfiguration object     */    for (String sinkName : sinkNames) {        ComponentConfiguration comp = compMap.get(sinkName);        if (comp != null) {            SinkConfiguration config = (SinkConfiguration) comp;            Sink sink = sinkFactory.create(comp.getComponentName(), comp.getType());            try {                Configurables.configure(sink, config);                ChannelComponent channelComponent = channelComponentMap.get(config.getChannel());                if (channelComponent == null) {                    String msg = String.format("Sink %s is not connected to a " + "channel", sinkName);                    throw new IllegalStateException(msg);                }                checkSinkChannelCompatibility(sink, channelComponent.channel);                sink.setChannel(channelComponent.channel);                sinks.put(comp.getComponentName(), sink);                channelComponent.components.add(sinkName);            } catch (Exception e) {                String msg = String.format("Sink %s has been removed due to an " + "error during configuration", sinkName);                LOGGER.error(msg, e);            }        }    }    /*     * Components which DO NOT have a ComponentConfiguration object     * and use only Context     */    Map<String, Context> sinkContexts = agentConf.getSinkContext();    for (String sinkName : sinkNames) {        Context context = sinkContexts.get(sinkName);        if (context != null) {            Sink sink = sinkFactory.create(sinkName, context.getString(BasicConfigurationConstants.CONFIG_TYPE));            try {                Configurables.configure(sink, context);                ChannelComponent channelComponent = channelComponentMap.get(context.getString(BasicConfigurationConstants.CONFIG_CHANNEL));                if (channelComponent == null) {                    String msg = String.format("Sink %s is not connected to a " + "channel", sinkName);                    throw new IllegalStateException(msg);                }                checkSinkChannelCompatibility(sink, channelComponent.channel);                sink.setChannel(channelComponent.channel);                sinks.put(sinkName, sink);                channelComponent.components.add(sinkName);            } catch (Exception e) {                String msg = String.format("Sink %s has been removed due to an " + "error during configuration", sinkName);                LOGGER.error(msg, e);            }        }    }    loadSinkGroups(agentConf, sinks, sinkRunnerMap);}
24f149b086f3cf9c69330a2b967d044bdc388a1c49f8b980d94706653917fed8
loadSinkGroups
private void loadSinkGroups(AgentConfiguration agentConf, Map<String, Sink> sinks, Map<String, SinkRunner> sinkRunnerMap) throws InstantiationException
{    Set<String> sinkGroupNames = agentConf.getSinkgroupSet();    Map<String, ComponentConfiguration> compMap = agentConf.getSinkGroupConfigMap();    Map<String, String> usedSinks = new HashMap<String, String>();    for (String groupName : sinkGroupNames) {        ComponentConfiguration comp = compMap.get(groupName);        if (comp != null) {            SinkGroupConfiguration groupConf = (SinkGroupConfiguration) comp;            List<Sink> groupSinks = new ArrayList<Sink>();            for (String sink : groupConf.getSinks()) {                Sink s = sinks.remove(sink);                if (s == null) {                    String sinkUser = usedSinks.get(sink);                    if (sinkUser != null) {                        throw new InstantiationException(String.format("Sink %s of group %s already " + "in use by group %s", sink, groupName, sinkUser));                    } else {                        throw new InstantiationException(String.format("Sink %s of group %s does " + "not exist or is not properly configured", sink, groupName));                    }                }                groupSinks.add(s);                usedSinks.put(sink, groupName);            }            try {                SinkGroup group = new SinkGroup(groupSinks);                Configurables.configure(group, groupConf);                sinkRunnerMap.put(comp.getComponentName(), new SinkRunner(group.getProcessor()));            } catch (Exception e) {                String msg = String.format("SinkGroup %s has been removed due to " + "an error during configuration", groupName);                LOGGER.error(msg, e);            }        }    }        for (Entry<String, Sink> entry : sinks.entrySet()) {        if (!usedSinks.containsValue(entry.getKey())) {            try {                SinkProcessor pr = new DefaultSinkProcessor();                List<Sink> sinkMap = new ArrayList<Sink>();                sinkMap.add(entry.getValue());                pr.setSinks(sinkMap);                Configurables.configure(pr, new Context());                sinkRunnerMap.put(entry.getKey(), new SinkRunner(pr));            } catch (Exception e) {                String msg = String.format("SinkGroup %s has been removed due to " + "an error during configuration", entry.getKey());                LOGGER.error(msg, e);            }        }    }}
c82b37383a096afe73c62bec512184222887c3bd715422e059e7ae56362eee7d
toMap
protected Map<String, String> toMap(Properties properties)
{    Map<String, String> result = Maps.newHashMap();    Enumeration<?> propertyNames = properties.propertyNames();    while (propertyNames.hasMoreElements()) {        String name = (String) propertyNames.nextElement();        String value = properties.getProperty(name);        result.put(name, value);    }    return result;}
3e7fa7897eb1ce58d1f5d02800bcda26a6517d05d5644bd603c1c86073d075c6
createClient
protected CuratorFramework createClient()
{    return CuratorFrameworkFactory.newClient(zkConnString, new ExponentialBackoffRetry(1000, 1));}
9748cb603791573bb981fe6f4827ff505dcd5580fc4ed15e4794686afedfd92c
configFromBytes
protected FlumeConfiguration configFromBytes(byte[] configData) throws IOException
{    Map<String, String> configMap;    if (configData == null || configData.length == 0) {        configMap = Collections.emptyMap();    } else {        String fileContent = new String(configData, Charsets.UTF_8);        Properties properties = new Properties();        properties.load(new StringReader(fileContent));        configMap = toMap(properties);    }    return new FlumeConfiguration(configMap);}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    lifecycleLock.lock();    try {        for (LifecycleAware component : components) {            supervisor.supervise(component, new SupervisorPolicy.AlwaysRestartPolicy(), LifecycleState.START);        }    } finally {        lifecycleLock.unlock();    }}
f1c8f087173733480e2a8d5973ca85d63604f5f0234d009cf53555821df8b0a9
handleConfigurationEvent
public void handleConfigurationEvent(MaterializedConfiguration conf)
{    try {        lifecycleLock.lockInterruptibly();        stopAllComponents();        startAllComponents(conf);    } catch (InterruptedException e) {        logger.info("Interrupted while trying to handle configuration event");        return;    } finally {                if (lifecycleLock.isHeldByCurrentThread()) {            lifecycleLock.unlock();        }    }}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    lifecycleLock.lock();    stopAllComponents();    try {        supervisor.stop();        if (monitorServer != null) {            monitorServer.stop();        }    } finally {        lifecycleLock.unlock();    }}
1670849281ef92bfc2f0675b34d272d193cc4643dca040497ec7aa101108bb9d
stopAllComponents
private void stopAllComponents()
{    if (this.materializedConfiguration != null) {        logger.info("Shutting down configuration: {}", this.materializedConfiguration);        for (Entry<String, SourceRunner> entry : this.materializedConfiguration.getSourceRunners().entrySet()) {            try {                logger.info("Stopping Source " + entry.getKey());                supervisor.unsupervise(entry.getValue());            } catch (Exception e) {                logger.error("Error while stopping {}", entry.getValue(), e);            }        }        for (Entry<String, SinkRunner> entry : this.materializedConfiguration.getSinkRunners().entrySet()) {            try {                logger.info("Stopping Sink " + entry.getKey());                supervisor.unsupervise(entry.getValue());            } catch (Exception e) {                logger.error("Error while stopping {}", entry.getValue(), e);            }        }        for (Entry<String, Channel> entry : this.materializedConfiguration.getChannels().entrySet()) {            try {                logger.info("Stopping Channel " + entry.getKey());                supervisor.unsupervise(entry.getValue());            } catch (Exception e) {                logger.error("Error while stopping {}", entry.getValue(), e);            }        }    }    if (monitorServer != null) {        monitorServer.stop();    }}
0881d6fc0c2ed6dccff9872c5bb80c31dd034db9eb2f26bb29a37bedcb6161bd
startAllComponents
private void startAllComponents(MaterializedConfiguration materializedConfiguration)
{    logger.info("Starting new configuration:{}", materializedConfiguration);    this.materializedConfiguration = materializedConfiguration;    for (Entry<String, Channel> entry : materializedConfiguration.getChannels().entrySet()) {        try {            logger.info("Starting Channel " + entry.getKey());            supervisor.supervise(entry.getValue(), new SupervisorPolicy.AlwaysRestartPolicy(), LifecycleState.START);        } catch (Exception e) {            logger.error("Error while starting {}", entry.getValue(), e);        }    }    /*     * Wait for all channels to start.     */    for (Channel ch : materializedConfiguration.getChannels().values()) {        while (ch.getLifecycleState() != LifecycleState.START && !supervisor.isComponentInErrorState(ch)) {            try {                logger.info("Waiting for channel: " + ch.getName() + " to start. Sleeping for 500 ms");                Thread.sleep(500);            } catch (InterruptedException e) {                logger.error("Interrupted while waiting for channel to start.", e);                Throwables.propagate(e);            }        }    }    for (Entry<String, SinkRunner> entry : materializedConfiguration.getSinkRunners().entrySet()) {        try {            logger.info("Starting Sink " + entry.getKey());            supervisor.supervise(entry.getValue(), new SupervisorPolicy.AlwaysRestartPolicy(), LifecycleState.START);        } catch (Exception e) {            logger.error("Error while starting {}", entry.getValue(), e);        }    }    for (Entry<String, SourceRunner> entry : materializedConfiguration.getSourceRunners().entrySet()) {        try {            logger.info("Starting Source " + entry.getKey());            supervisor.supervise(entry.getValue(), new SupervisorPolicy.AlwaysRestartPolicy(), LifecycleState.START);        } catch (Exception e) {            logger.error("Error while starting {}", entry.getValue(), e);        }    }    this.loadMonitoring();}
5ed30220b99716d7f78fd6d86579bc4ad48af184847462a5e4c7c6962bd6fbd0
loadMonitoring
private void loadMonitoring()
{    Properties systemProps = System.getProperties();    Set<String> keys = systemProps.stringPropertyNames();    try {        if (keys.contains(CONF_MONITOR_CLASS)) {            String monitorType = systemProps.getProperty(CONF_MONITOR_CLASS);            Class<? extends MonitorService> klass;            try {                                klass = MonitoringType.valueOf(monitorType.toUpperCase(Locale.ENGLISH)).getMonitorClass();            } catch (Exception e) {                                klass = (Class<? extends MonitorService>) Class.forName(monitorType);            }            this.monitorServer = klass.newInstance();            Context context = new Context();            for (String key : keys) {                if (key.startsWith(CONF_MONITOR_PREFIX)) {                    context.put(key.substring(CONF_MONITOR_PREFIX.length()), systemProps.getProperty(key));                }            }            monitorServer.configure(context);            monitorServer.start();        }    } catch (Exception e) {        logger.warn("Error starting monitoring. " + "Monitoring might not be available.", e);    }}
3116ea2053d9de960ec3753eb07f3d243c370662aa1f0175ad357057c9ce5a52
main
public static void main(String[] args)
{    try {        SSLUtil.initGlobalSSLParameters();        Options options = new Options();        Option option = new Option("n", "name", true, "the name of this agent");        option.setRequired(true);        options.addOption(option);        option = new Option("f", "conf-file", true, "specify a config file (required if -z missing)");        option.setRequired(false);        options.addOption(option);        option = new Option(null, "no-reload-conf", false, "do not reload config file if changed");        options.addOption(option);                option = new Option("z", "zkConnString", true, "specify the ZooKeeper connection to use (required if -f missing)");        option.setRequired(false);        options.addOption(option);        option = new Option("p", "zkBasePath", true, "specify the base path in ZooKeeper for agent configs");        option.setRequired(false);        options.addOption(option);        option = new Option("h", "help", false, "display help text");        options.addOption(option);        CommandLineParser parser = new GnuParser();        CommandLine commandLine = parser.parse(options, args);        if (commandLine.hasOption('h')) {            new HelpFormatter().printHelp("flume-ng agent", options, true);            return;        }        String agentName = commandLine.getOptionValue('n');        boolean reload = !commandLine.hasOption("no-reload-conf");        boolean isZkConfigured = false;        if (commandLine.hasOption('z') || commandLine.hasOption("zkConnString")) {            isZkConfigured = true;        }        Application application;        if (isZkConfigured) {                        String zkConnectionStr = commandLine.getOptionValue('z');            String baseZkPath = commandLine.getOptionValue('p');            if (reload) {                EventBus eventBus = new EventBus(agentName + "-event-bus");                List<LifecycleAware> components = Lists.newArrayList();                PollingZooKeeperConfigurationProvider zookeeperConfigurationProvider = new PollingZooKeeperConfigurationProvider(agentName, zkConnectionStr, baseZkPath, eventBus);                components.add(zookeeperConfigurationProvider);                application = new Application(components);                eventBus.register(application);            } else {                StaticZooKeeperConfigurationProvider zookeeperConfigurationProvider = new StaticZooKeeperConfigurationProvider(agentName, zkConnectionStr, baseZkPath);                application = new Application();                application.handleConfigurationEvent(zookeeperConfigurationProvider.getConfiguration());            }        } else {            File configurationFile = new File(commandLine.getOptionValue('f'));            /*         * The following is to ensure that by default the agent will fail on         * startup if the file does not exist.         */            if (!configurationFile.exists()) {                                if (System.getProperty(Constants.SYSPROP_CALLED_FROM_SERVICE) == null) {                    String path = configurationFile.getPath();                    try {                        path = configurationFile.getCanonicalPath();                    } catch (IOException ex) {                        logger.error("Failed to read canonical path for file: " + path, ex);                    }                    throw new ParseException("The specified configuration file does not exist: " + path);                }            }            List<LifecycleAware> components = Lists.newArrayList();            if (reload) {                EventBus eventBus = new EventBus(agentName + "-event-bus");                PollingPropertiesFileConfigurationProvider configurationProvider = new PollingPropertiesFileConfigurationProvider(agentName, configurationFile, eventBus, 30);                components.add(configurationProvider);                application = new Application(components);                eventBus.register(application);            } else {                PropertiesFileConfigurationProvider configurationProvider = new PropertiesFileConfigurationProvider(agentName, configurationFile);                application = new Application();                application.handleConfigurationEvent(configurationProvider.getConfiguration());            }        }        application.start();        final Application appReference = application;        Runtime.getRuntime().addShutdownHook(new Thread("agent-shutdown-hook") {            @Override            public void run() {                appReference.stop();            }        });    } catch (Exception e) {        logger.error("A fatal error occurred while running. Exception follows.", e);    }}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    appReference.stop();}
3bdbcae03866e4f0b67216c60c957d3e8faa17255902f300d81319aa14f9a7e6
resolveEnvVars
protected static String resolveEnvVars(String input)
{    Preconditions.checkNotNull(input);        Pattern p = Pattern.compile("\\$\\{(\\w+)\\}");    Matcher m = p.matcher(input);    StringBuffer sb = new StringBuffer();    while (m.find()) {        String envVarName = m.group(1);        String envVarValue = System.getenv(envVarName);        m.appendReplacement(sb, null == envVarValue ? "" : envVarValue);    }    m.appendTail(sb);    return sb.toString();}
24b97b4a87e6aecb892eb1fbffabcbccc67ab8799b48339ba108a4e72cefdea9
getProperty
public String getProperty(String key)
{    return resolveEnvVars(super.getProperty(key));}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    LOGGER.info("Configuration provider starting");    Preconditions.checkState(file != null, "The parameter file must not be null");    executorService = Executors.newSingleThreadScheduledExecutor(new ThreadFactoryBuilder().setNameFormat("conf-file-poller-%d").build());    FileWatcherRunnable fileWatcherRunnable = new FileWatcherRunnable(file, counterGroup);    executorService.scheduleWithFixedDelay(fileWatcherRunnable, 0, interval, TimeUnit.SECONDS);    lifecycleState = LifecycleState.START;    LOGGER.debug("Configuration provider started");}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    LOGGER.info("Configuration provider stopping");    executorService.shutdown();    try {        if (!executorService.awaitTermination(500, TimeUnit.MILLISECONDS)) {            LOGGER.debug("File watcher has not terminated. Forcing shutdown of executor.");            executorService.shutdownNow();            while (!executorService.awaitTermination(500, TimeUnit.MILLISECONDS)) {                LOGGER.debug("Waiting for file watcher to terminate");            }        }    } catch (InterruptedException e) {        LOGGER.debug("Interrupted while waiting for file watcher to terminate");        Thread.currentThread().interrupt();    }    lifecycleState = LifecycleState.STOP;    LOGGER.debug("Configuration provider stopped");}
82e342b29ff4fad8c64d554dc21ad55a5f2c8063fce3b580e896b7968d90473a
getLifecycleState
public synchronized LifecycleState getLifecycleState()
{    return lifecycleState;}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return "{ file:" + file + " counterGroup:" + counterGroup + "  provider:" + getClass().getCanonicalName() + " agentName:" + getAgentName() + " }";}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    LOGGER.debug("Checking file:{} for changes", file);    counterGroup.incrementAndGet("file.checks");    long lastModified = file.lastModified();    if (lastModified > lastChange) {        LOGGER.info("Reloading configuration file:{}", file);        counterGroup.incrementAndGet("file.loads");        lastChange = lastModified;        try {            eventBus.post(getConfiguration());        } catch (Exception e) {            LOGGER.error("Failed to load configuration data. Exception follows.", e);        } catch (NoClassDefFoundError e) {            LOGGER.error("Failed to start agent because dependencies were not " + "found in classpath. Error follows.", e);        } catch (Throwable t) {                        LOGGER.error("Unhandled error", t);        }    }}
017528fe1ef89aa4d378c2cb88ab31e1cb5c27aac07c4d607cf4e80bfc231077
getFlumeConfiguration
protected FlumeConfiguration getFlumeConfiguration()
{    return flumeConfiguration;}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    LOGGER.debug("Starting...");    try {        client.start();        try {            agentNodeCache = new NodeCache(client, basePath + "/" + getAgentName());            agentNodeCache.start();            agentNodeCache.getListenable().addListener(new NodeCacheListener() {                @Override                public void nodeChanged() throws Exception {                    refreshConfiguration();                }            });        } catch (Exception e) {            client.close();            throw e;        }    } catch (Exception e) {        lifecycleState = LifecycleState.ERROR;        if (e instanceof RuntimeException) {            throw (RuntimeException) e;        } else {            throw new FlumeException(e);        }    }    lifecycleState = LifecycleState.START;}
95a1d12a17566499008636423784493306962712fbc4daf5f8810e4e38689b3c
nodeChanged
public void nodeChanged() throws Exception
{    refreshConfiguration();}
738db2e58d873f4a9f7dc4a75fc1bbd96071a3dd53addcee9fc28ccfbcb95323
refreshConfiguration
private void refreshConfiguration() throws IOException
{    LOGGER.info("Refreshing configuration from ZooKeeper");    byte[] data = null;    ChildData childData = agentNodeCache.getCurrentData();    if (childData != null) {        data = childData.getData();    }    flumeConfiguration = configFromBytes(data);    eventBus.post(getConfiguration());}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    LOGGER.debug("Stopping...");    if (agentNodeCache != null) {        try {            agentNodeCache.close();        } catch (IOException e) {            LOGGER.warn("Encountered exception while stopping", e);            lifecycleState = LifecycleState.ERROR;        }    }    try {        client.close();    } catch (Exception e) {        LOGGER.warn("Error stopping Curator client", e);        lifecycleState = LifecycleState.ERROR;    }    if (lifecycleState != LifecycleState.ERROR) {        lifecycleState = LifecycleState.STOP;    }}
54497ccb2ff9760f1ec7fc0d0055d4bc60d5981953c5f3d7550c4b31a01e7642
getLifecycleState
public LifecycleState getLifecycleState()
{    return lifecycleState;}
05ae98012079c3abe4e0540f97ea4516bbdb8b2b9682d5a7419bd54900999a55
getFlumeConfiguration
public FlumeConfiguration getFlumeConfiguration()
{    BufferedReader reader = null;    try {        reader = new BufferedReader(new FileReader(file));        String resolverClassName = System.getProperty("propertiesImplementation", DEFAULT_PROPERTIES_IMPLEMENTATION);        Class<? extends Properties> propsclass = Class.forName(resolverClassName).asSubclass(Properties.class);        Properties properties = propsclass.newInstance();        properties.load(reader);        return new FlumeConfiguration(toMap(properties));    } catch (IOException ex) {        LOGGER.error("Unable to load file:" + file + " (I/O failure) - Exception follows.", ex);    } catch (ClassNotFoundException e) {        LOGGER.error("Configuration resolver class not found", e);    } catch (InstantiationException e) {        LOGGER.error("Instantiation exception", e);    } catch (IllegalAccessException e) {        LOGGER.error("Illegal access exception", e);    } finally {        if (reader != null) {            try {                reader.close();            } catch (IOException ex) {                LOGGER.warn("Unable to close file reader for file: " + file, ex);            }        }    }    return new FlumeConfiguration(new HashMap<String, String>());}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return "{ sourceRunners:" + sourceRunners + " sinkRunners:" + sinkRunners + " channels:" + channels + " }";}
0c3c870bd91a71c588fe015c10b525118652bd184b759e70a763ce9b6a32ac2e
addSourceRunner
public void addSourceRunner(String name, SourceRunner sourceRunner)
{    sourceRunners.put(name, sourceRunner);}
8f265261b16075f78b3e04e7395ba38fafbbbf0a17ebc76b26356f4c2faa4e11
addSinkRunner
public void addSinkRunner(String name, SinkRunner sinkRunner)
{    sinkRunners.put(name, sinkRunner);}
7b1cceed1937b5297f129befde597f42b16e557c043a1c9b3a2f0a0ef685bf8b
addChannel
public void addChannel(String name, Channel channel)
{    channels.put(name, channel);}
1962a53d0a4f9845d56ff5f49e696f818846bace2fa42f41ec51d2956dce1fcb
getChannels
public Map<String, Channel> getChannels()
{    return ImmutableMap.copyOf(channels);}
eab92b0193defc26e6b087b2b9cc0b00c4835a7204f3b382c7754a37026d2d7b
getSourceRunners
public Map<String, SourceRunner> getSourceRunners()
{    return ImmutableMap.copyOf(sourceRunners);}
e682ab5a7aeef354fa754a0bf6814a927c29821895d0581ff95145c9c577a3c6
getSinkRunners
public Map<String, SinkRunner> getSinkRunners()
{    return ImmutableMap.copyOf(sinkRunners);}
017528fe1ef89aa4d378c2cb88ab31e1cb5c27aac07c4d607cf4e80bfc231077
getFlumeConfiguration
protected FlumeConfiguration getFlumeConfiguration()
{    try {        CuratorFramework cf = createClient();        cf.start();        try {            byte[] data = cf.getData().forPath(basePath + "/" + getAgentName());            return configFromBytes(data);        } finally {            cf.close();        }    } catch (Exception e) {        LOGGER.error("Error getting configuration info from Zookeeper", e);        throw new FlumeException(e);    }}
1f2b0564fa7b57bff9ef3a59b9ee6979f773791abd2f875d797f03cc43743dfb
testDispoableChannel
public void testDispoableChannel() throws Exception
{    String agentName = "agent1";    Map<String, String> properties = getPropertiesForChannel(agentName, DisposableChannel.class.getName());    MemoryConfigurationProvider provider = new MemoryConfigurationProvider(agentName, properties);    MaterializedConfiguration config1 = provider.getConfiguration();    Channel channel1 = config1.getChannels().values().iterator().next();    Assert.assertTrue(channel1 instanceof DisposableChannel);    MaterializedConfiguration config2 = provider.getConfiguration();    Channel channel2 = config2.getChannels().values().iterator().next();    Assert.assertTrue(channel2 instanceof DisposableChannel);    Assert.assertNotSame(channel1, channel2);}
6063078f122dc5243c24c8e21bd81e61d2520d6a53821dc06fa51d968d1e80d2
testReusableChannel
public void testReusableChannel() throws Exception
{    String agentName = "agent1";    Map<String, String> properties = getPropertiesForChannel(agentName, RecyclableChannel.class.getName());    MemoryConfigurationProvider provider = new MemoryConfigurationProvider(agentName, properties);    MaterializedConfiguration config1 = provider.getConfiguration();    Channel channel1 = config1.getChannels().values().iterator().next();    Assert.assertTrue(channel1 instanceof RecyclableChannel);    MaterializedConfiguration config2 = provider.getConfiguration();    Channel channel2 = config2.getChannels().values().iterator().next();    Assert.assertTrue(channel2 instanceof RecyclableChannel);    Assert.assertSame(channel1, channel2);}
4bbcaca0f2b152e362eb8abcdc99343a1a4cccbf0fd2dacef9ff3dcc124687d4
testUnspecifiedChannel
public void testUnspecifiedChannel() throws Exception
{    String agentName = "agent1";    Map<String, String> properties = getPropertiesForChannel(agentName, UnspecifiedChannel.class.getName());    MemoryConfigurationProvider provider = new MemoryConfigurationProvider(agentName, properties);    MaterializedConfiguration config1 = provider.getConfiguration();    Channel channel1 = config1.getChannels().values().iterator().next();    Assert.assertTrue(channel1 instanceof UnspecifiedChannel);    MaterializedConfiguration config2 = provider.getConfiguration();    Channel channel2 = config2.getChannels().values().iterator().next();    Assert.assertTrue(channel2 instanceof UnspecifiedChannel);    Assert.assertSame(channel1, channel2);}
33837a8c2ce01f97e766792922a89bd7f492cb8fbd985bc2998ff97562d98c46
testReusableChannelNotReusedLater
public void testReusableChannelNotReusedLater() throws Exception
{    String agentName = "agent1";    Map<String, String> propertiesReusable = getPropertiesForChannel(agentName, RecyclableChannel.class.getName());    Map<String, String> propertiesDispoable = getPropertiesForChannel(agentName, DisposableChannel.class.getName());    MemoryConfigurationProvider provider = new MemoryConfigurationProvider(agentName, propertiesReusable);    MaterializedConfiguration config1 = provider.getConfiguration();    Channel channel1 = config1.getChannels().values().iterator().next();    Assert.assertTrue(channel1 instanceof RecyclableChannel);    provider.setProperties(propertiesDispoable);    MaterializedConfiguration config2 = provider.getConfiguration();    Channel channel2 = config2.getChannels().values().iterator().next();    Assert.assertTrue(channel2 instanceof DisposableChannel);    provider.setProperties(propertiesReusable);    MaterializedConfiguration config3 = provider.getConfiguration();    Channel channel3 = config3.getChannels().values().iterator().next();    Assert.assertTrue(channel3 instanceof RecyclableChannel);    Assert.assertNotSame(channel1, channel3);}
146f81a1fee702a9683a29e6d588a467add90f7019041a51f840106bdd992ee6
testSourceThrowsExceptionDuringConfiguration
public void testSourceThrowsExceptionDuringConfiguration() throws Exception
{    String agentName = "agent1";    String sourceType = UnconfigurableSource.class.getName();    String channelType = "memory";    String sinkType = "null";    Map<String, String> properties = getProperties(agentName, sourceType, channelType, sinkType);    MemoryConfigurationProvider provider = new MemoryConfigurationProvider(agentName, properties);    MaterializedConfiguration config = provider.getConfiguration();    Assert.assertTrue(config.getSourceRunners().size() == 0);    Assert.assertTrue(config.getChannels().size() == 1);    Assert.assertTrue(config.getSinkRunners().size() == 1);}
874db11b68f89f0e3a228865682b53ed58797e2bd45cf1b3d14040fa52cfe4e8
testChannelThrowsExceptionDuringConfiguration
public void testChannelThrowsExceptionDuringConfiguration() throws Exception
{    String agentName = "agent1";    String sourceType = "seq";    String channelType = UnconfigurableChannel.class.getName();    String sinkType = "null";    Map<String, String> properties = getProperties(agentName, sourceType, channelType, sinkType);    MemoryConfigurationProvider provider = new MemoryConfigurationProvider(agentName, properties);    MaterializedConfiguration config = provider.getConfiguration();    Assert.assertTrue(config.getSourceRunners().size() == 0);    Assert.assertTrue(config.getChannels().size() == 0);    Assert.assertTrue(config.getSinkRunners().size() == 0);}
bcec3ee929bc224a3f6951adc29fc6cb4ea78f413b3e978c9375c11f64d9d008
testSinkThrowsExceptionDuringConfiguration
public void testSinkThrowsExceptionDuringConfiguration() throws Exception
{    String agentName = "agent1";    String sourceType = "seq";    String channelType = "memory";    String sinkType = UnconfigurableSink.class.getName();    Map<String, String> properties = getProperties(agentName, sourceType, channelType, sinkType);    MemoryConfigurationProvider provider = new MemoryConfigurationProvider(agentName, properties);    MaterializedConfiguration config = provider.getConfiguration();    Assert.assertTrue(config.getSourceRunners().size() == 1);    Assert.assertTrue(config.getChannels().size() == 1);    Assert.assertTrue(config.getSinkRunners().size() == 0);}
bf4bcfc3396fdb18ce5cf8ef6491d7f165e1ae1d04f6455dd804316f3d5126e2
testSourceAndSinkThrowExceptionDuringConfiguration
public void testSourceAndSinkThrowExceptionDuringConfiguration() throws Exception
{    String agentName = "agent1";    String sourceType = UnconfigurableSource.class.getName();    String channelType = "memory";    String sinkType = UnconfigurableSink.class.getName();    Map<String, String> properties = getProperties(agentName, sourceType, channelType, sinkType);    MemoryConfigurationProvider provider = new MemoryConfigurationProvider(agentName, properties);    MaterializedConfiguration config = provider.getConfiguration();    Assert.assertTrue(config.getSourceRunners().size() == 0);    Assert.assertTrue(config.getChannels().size() == 0);    Assert.assertTrue(config.getSinkRunners().size() == 0);}
12ba0e0e82d7451e40311a6edc1951442e78aff5a3ecf170a61d314bcf2441d1
testSinkSourceMismatchDuringConfiguration
public void testSinkSourceMismatchDuringConfiguration() throws Exception
{    String agentName = "agent1";    String sourceType = "seq";    String channelType = "memory";    String sinkType = "avro";    Map<String, String> properties = getProperties(agentName, sourceType, channelType, sinkType);    properties.put(agentName + ".channels.channel1.capacity", "1000");    properties.put(agentName + ".channels.channel1.transactionCapacity", "1000");    properties.put(agentName + ".sources.source1.batchSize", "1000");    properties.put(agentName + ".sinks.sink1.batch-size", "1000");    properties.put(agentName + ".sinks.sink1.hostname", "10.10.10.10");    properties.put(agentName + ".sinks.sink1.port", "1010");    MemoryConfigurationProvider provider = new MemoryConfigurationProvider(agentName, properties);    MaterializedConfiguration config = provider.getConfiguration();    Assert.assertTrue(config.getSourceRunners().size() == 1);    Assert.assertTrue(config.getChannels().size() == 1);    Assert.assertTrue(config.getSinkRunners().size() == 1);    properties.put(agentName + ".sources.source1.batchSize", "1001");    properties.put(agentName + ".sinks.sink1.batch-size", "1000");    provider = new MemoryConfigurationProvider(agentName, properties);    config = provider.getConfiguration();    Assert.assertTrue(config.getSourceRunners().size() == 0);    Assert.assertTrue(config.getChannels().size() == 1);    Assert.assertTrue(config.getSinkRunners().size() == 1);    properties.put(agentName + ".sources.source1.batchSize", "1000");    properties.put(agentName + ".sinks.sink1.batch-size", "1001");    provider = new MemoryConfigurationProvider(agentName, properties);    config = provider.getConfiguration();    Assert.assertTrue(config.getSourceRunners().size() == 1);    Assert.assertTrue(config.getChannels().size() == 1);    Assert.assertTrue(config.getSinkRunners().size() == 0);    properties.put(agentName + ".sources.source1.batchSize", "1001");    properties.put(agentName + ".sinks.sink1.batch-size", "1001");    provider = new MemoryConfigurationProvider(agentName, properties);    config = provider.getConfiguration();    Assert.assertTrue(config.getSourceRunners().size() == 0);    Assert.assertTrue(config.getChannels().size() == 0);    Assert.assertTrue(config.getSinkRunners().size() == 0);}
4609c1bc3e9edc740ad82dae60b80bb53edd21b09db9257684f6fa96d286bbf2
getProperties
private Map<String, String> getProperties(String agentName, String sourceType, String channelType, String sinkType)
{    Map<String, String> properties = Maps.newHashMap();    properties.put(agentName + ".sources", "source1");    properties.put(agentName + ".channels", "channel1");    properties.put(agentName + ".sinks", "sink1");    properties.put(agentName + ".sources.source1.type", sourceType);    properties.put(agentName + ".sources.source1.channels", "channel1");    properties.put(agentName + ".channels.channel1.type", channelType);    properties.put(agentName + ".channels.channel1.capacity", "100");    properties.put(agentName + ".sinks.sink1.type", sinkType);    properties.put(agentName + ".sinks.sink1.channel", "channel1");    return properties;}
849db2f77459c2995036db19b045cf80ef7817f9092d298368cc6c56a7c41595
getPropertiesForChannel
private Map<String, String> getPropertiesForChannel(String agentName, String channelType)
{    return getProperties(agentName, "seq", channelType, "null");}
49453becca597b1f247c67c1d4be7d9b4e4c5f70e44af3c422a4affa55dbc1a3
setProperties
public void setProperties(Map<String, String> properties)
{    this.properties = properties;}
017528fe1ef89aa4d378c2cb88ab31e1cb5c27aac07c4d607cf4e80bfc231077
getFlumeConfiguration
protected FlumeConfiguration getFlumeConfiguration()
{    return new FlumeConfiguration(properties);}
7c433c140e986ede99b2704e4370ce4dc62a481b499e15037b573f27288bffc9
put
public void put(Event event) throws ChannelException
{    throw new UnsupportedOperationException();}
bd28ef43945352a9d826db660bc6e7b38e1777eec9decd45c0467679fc18a6dd
take
public Event take() throws ChannelException
{    throw new UnsupportedOperationException();}
2940dfdc387e1882ca0545a619d502102ae0c821f25b9ee739eafaade9ca3ee9
getTransaction
public Transaction getTransaction()
{    throw new UnsupportedOperationException();}
7c433c140e986ede99b2704e4370ce4dc62a481b499e15037b573f27288bffc9
put
public void put(Event event) throws ChannelException
{    throw new UnsupportedOperationException();}
bd28ef43945352a9d826db660bc6e7b38e1777eec9decd45c0467679fc18a6dd
take
public Event take() throws ChannelException
{    throw new UnsupportedOperationException();}
2940dfdc387e1882ca0545a619d502102ae0c821f25b9ee739eafaade9ca3ee9
getTransaction
public Transaction getTransaction()
{    throw new UnsupportedOperationException();}
7c433c140e986ede99b2704e4370ce4dc62a481b499e15037b573f27288bffc9
put
public void put(Event event) throws ChannelException
{    throw new UnsupportedOperationException();}
bd28ef43945352a9d826db660bc6e7b38e1777eec9decd45c0467679fc18a6dd
take
public Event take() throws ChannelException
{    throw new UnsupportedOperationException();}
2940dfdc387e1882ca0545a619d502102ae0c821f25b9ee739eafaade9ca3ee9
getTransaction
public Transaction getTransaction()
{    throw new UnsupportedOperationException();}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    throw new RuntimeException("expected");}
7c433c140e986ede99b2704e4370ce4dc62a481b499e15037b573f27288bffc9
put
public void put(Event event) throws ChannelException
{    throw new UnsupportedOperationException();}
bd28ef43945352a9d826db660bc6e7b38e1777eec9decd45c0467679fc18a6dd
take
public Event take() throws ChannelException
{    throw new UnsupportedOperationException();}
2940dfdc387e1882ca0545a619d502102ae0c821f25b9ee739eafaade9ca3ee9
getTransaction
public Transaction getTransaction()
{    throw new UnsupportedOperationException();}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    throw new RuntimeException("expected");}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    throw new RuntimeException("expected");}
e52e5e378330fd7f87ee30351bbfcec47b751fee12ece2ef0cfdd77a08c906e1
process
public Status process() throws EventDeliveryException
{    throw new UnsupportedOperationException();}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    zkServer = new TestingServer();    client = CuratorFrameworkFactory.newClient("localhost:" + zkServer.getPort(), new ExponentialBackoffRetry(1000, 3));    client.start();    EnsurePath ensurePath = new EnsurePath(AGENT_PATH);    ensurePath.ensure(client.getZookeeperClient());    doSetUp();}
c6aaebb5a52567751db8dc8e1cb9dd4a4e582ef964a374b376c6a04f741802dc
tearDown
public void tearDown() throws Exception
{    doTearDown();    zkServer.close();    client.close();}
43220d3f41a63d965c61232bbf05f0035b74dc2889ae45ff5869eece5395e960
addData
protected void addData() throws Exception
{    Reader in = new InputStreamReader(getClass().getClassLoader().getResourceAsStream(FLUME_CONF_FILE), Charsets.UTF_8);    try {        String config = IOUtils.toString(in);        client.setData().forPath(AGENT_PATH, config.getBytes());    } finally {        in.close();    }}
8b60d39aec9ee2087936cfb4928d15e7b93d6de0b63ad3b321ed1754b4bf7b35
verifyProperties
protected void verifyProperties(AbstractConfigurationProvider cp)
{    FlumeConfiguration configuration = cp.getFlumeConfiguration();    Assert.assertNotNull(configuration);    /*     * Test the known errors in the file     */    List<String> expected = Lists.newArrayList();    expected.add("host5 CONFIG_ERROR");    expected.add("host5 INVALID_PROPERTY");    expected.add("host4 CONFIG_ERROR");    expected.add("host4 CONFIG_ERROR");    expected.add("host4 PROPERTY_VALUE_NULL");    expected.add("host4 PROPERTY_VALUE_NULL");    expected.add("host4 PROPERTY_VALUE_NULL");    expected.add("host4 AGENT_CONFIGURATION_INVALID");    expected.add("ch2 ATTRS_MISSING");    expected.add("host3 CONFIG_ERROR");    expected.add("host3 PROPERTY_VALUE_NULL");    expected.add("host3 AGENT_CONFIGURATION_INVALID");    expected.add("host2 PROPERTY_VALUE_NULL");    expected.add("host2 AGENT_CONFIGURATION_INVALID");    List<String> actual = Lists.newArrayList();    for (FlumeConfigurationError error : configuration.getConfigurationErrors()) {        actual.add(error.getComponentName() + " " + error.getErrorType().toString());    }    Collections.sort(expected);    Collections.sort(actual);    Assert.assertEquals(expected, actual);    FlumeConfiguration.AgentConfiguration agentConfiguration = configuration.getConfigurationFor("host1");    Assert.assertNotNull(agentConfiguration);    Set<String> sources = Sets.newHashSet("source1");    Set<String> sinks = Sets.newHashSet("sink1");    Set<String> channels = Sets.newHashSet("channel1");    Assert.assertEquals(sources, agentConfiguration.getSourceSet());    Assert.assertEquals(sinks, agentConfiguration.getSinkSet());    Assert.assertEquals(channels, agentConfiguration.getChannelSet());}
27681e68ec2a1eb903f955680ebe003ceb3707295c8aad884b692d378c6e37cf
setup
public void setup() throws Exception
{    baseDir = Files.createTempDir();}
c6aaebb5a52567751db8dc8e1cb9dd4a4e582ef964a374b376c6a04f741802dc
tearDown
public void tearDown() throws Exception
{    FileUtils.deleteDirectory(baseDir);}
e11b450ca89332ef3a01a46f392df46804a1b66bc2655c821c5a62057944240f
mockLifeCycle
private T mockLifeCycle(Class<T> klass)
{    T lifeCycleAware = mock(klass);    final AtomicReference<LifecycleState> state = new AtomicReference<LifecycleState>();    state.set(LifecycleState.IDLE);    when(lifeCycleAware.getLifecycleState()).then(new Answer<LifecycleState>() {        @Override        public LifecycleState answer(InvocationOnMock invocation) throws Throwable {            return state.get();        }    });    doAnswer(new Answer<Void>() {        @Override        public Void answer(InvocationOnMock invocation) throws Throwable {            state.set(LifecycleState.START);            return null;        }    }).when(lifeCycleAware).start();    doAnswer(new Answer<Void>() {        @Override        public Void answer(InvocationOnMock invocation) throws Throwable {            state.set(LifecycleState.STOP);            return null;        }    }).when(lifeCycleAware).stop();    return lifeCycleAware;}
21a0615669ee268431b71e9037ecf798d18f592e5febe6d30e58e745f0a18bb7
answer
public LifecycleState answer(InvocationOnMock invocation) throws Throwable
{    return state.get();}
95bf71523ce2b266f318cc556abf31d0edd833353a1498e854e22b8b3a97d573
answer
public Void answer(InvocationOnMock invocation) throws Throwable
{    state.set(LifecycleState.START);    return null;}
95bf71523ce2b266f318cc556abf31d0edd833353a1498e854e22b8b3a97d573
answer
public Void answer(InvocationOnMock invocation) throws Throwable
{    state.set(LifecycleState.STOP);    return null;}
a39ea4bfb0f908651dc021f6947f00f6de7d6bf2b06e514d389a44d25ca681bd
testBasicConfiguration
public void testBasicConfiguration() throws Exception
{    EventBus eventBus = new EventBus("test-event-bus");    MaterializedConfiguration materializedConfiguration = new SimpleMaterializedConfiguration();    SourceRunner sourceRunner = mockLifeCycle(SourceRunner.class);    materializedConfiguration.addSourceRunner("test", sourceRunner);    SinkRunner sinkRunner = mockLifeCycle(SinkRunner.class);    materializedConfiguration.addSinkRunner("test", sinkRunner);    Channel channel = mockLifeCycle(Channel.class);    materializedConfiguration.addChannel("test", channel);    ConfigurationProvider configurationProvider = mock(ConfigurationProvider.class);    when(configurationProvider.getConfiguration()).thenReturn(materializedConfiguration);    Application application = new Application();    eventBus.register(application);    eventBus.post(materializedConfiguration);    application.start();    Thread.sleep(1000L);    verify(sourceRunner).start();    verify(sinkRunner).start();    verify(channel).start();    application.stop();    Thread.sleep(1000L);    verify(sourceRunner).stop();    verify(sinkRunner).stop();    verify(channel).stop();}
f8512748db9753dd81ab776d37e2799c6c2876d29a38a29edf7262c3863e67b8
testFLUME1854
public void testFLUME1854() throws Exception
{    File configFile = new File(baseDir, "flume-conf.properties");    Files.copy(new File(getClass().getClassLoader().getResource("flume-conf.properties").getFile()), configFile);    Random random = new Random();    for (int i = 0; i < 3; i++) {        EventBus eventBus = new EventBus("test-event-bus");        PollingPropertiesFileConfigurationProvider configurationProvider = new PollingPropertiesFileConfigurationProvider("host1", configFile, eventBus, 1);        List<LifecycleAware> components = Lists.newArrayList();        components.add(configurationProvider);        Application application = new Application(components);        eventBus.register(application);        application.start();        Thread.sleep(random.nextInt(10000));        application.stop();    }}
672931d86e13cacb202345c9e7bf581eae7632527b2acaed47dad75a6e0448ed
testFLUME2786
public void testFLUME2786() throws Exception
{    final String agentName = "test";    final int interval = 1;    final long intervalMs = 1000L;    File configFile = new File(baseDir, "flume-conf.properties");    Files.copy(new File(getClass().getClassLoader().getResource("flume-conf.properties.2786").getFile()), configFile);    File mockConfigFile = spy(configFile);    when(mockConfigFile.lastModified()).then(new Answer<Long>() {        @Override        public Long answer(InvocationOnMock invocation) throws Throwable {            Thread.sleep(intervalMs);            return System.currentTimeMillis();        }    });    EventBus eventBus = new EventBus(agentName + "-event-bus");    PollingPropertiesFileConfigurationProvider configurationProvider = new PollingPropertiesFileConfigurationProvider(agentName, mockConfigFile, eventBus, interval);    PollingPropertiesFileConfigurationProvider mockConfigurationProvider = spy(configurationProvider);    doAnswer(new Answer<Void>() {        @Override        public Void answer(InvocationOnMock invocation) throws Throwable {            Thread.sleep(intervalMs);            invocation.callRealMethod();            return null;        }    }).when(mockConfigurationProvider).stop();    List<LifecycleAware> components = Lists.newArrayList();    components.add(mockConfigurationProvider);    Application application = new Application(components);    eventBus.register(application);    application.start();    Thread.sleep(1500L);    application.stop();}
6b058fcbe8b5fddb7fec7fdedc1ae4bc752170a34ef5278fb8a1359a4b685e35
answer
public Long answer(InvocationOnMock invocation) throws Throwable
{    Thread.sleep(intervalMs);    return System.currentTimeMillis();}
95bf71523ce2b266f318cc556abf31d0edd833353a1498e854e22b8b3a97d573
answer
public Void answer(InvocationOnMock invocation) throws Throwable
{    Thread.sleep(intervalMs);    invocation.callRealMethod();    return null;}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    provider = new PropertiesFileConfigurationProvider("a1", TESTFILE);}
bd1b43d286afc0b94c2924244dbd98a0928f9ac18a141fe87f94b0d56cd4faa3
resolveEnvVar
public void resolveEnvVar() throws Exception
{    environmentVariables.set("VARNAME", "varvalue");    String resolved = EnvVarResolverProperties.resolveEnvVars("padding ${VARNAME} padding");    Assert.assertEquals("padding varvalue padding", resolved);}
275e0a22f5540ebef43c2997d16c14f7cb7b1889708d4f1e0df19f3d92462391
resolveEnvVars
public void resolveEnvVars() throws Exception
{    environmentVariables.set("VARNAME1", "varvalue1");    environmentVariables.set("VARNAME2", "varvalue2");    String resolved = EnvVarResolverProperties.resolveEnvVars("padding ${VARNAME1} ${VARNAME2} padding");    Assert.assertEquals("padding varvalue1 varvalue2 padding", resolved);}
55ec0cfe67926942b603f822d7ab3dff5cd493d534a7a428a7ab7567d1906dd4
getProperty
public void getProperty() throws Exception
{    String NC_PORT = "6667";    environmentVariables.set("NC_PORT", NC_PORT);    System.setProperty("propertiesImplementation", "org.apache.flume.node.EnvVarResolverProperties");    Assert.assertEquals(NC_PORT, provider.getFlumeConfiguration().getConfigurationFor("a1").getSourceContext().get("r1").getParameters().get("port"));}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    baseDir = Files.createTempDir();    configFile = new File(baseDir, TESTFILE.getName());    Files.copy(TESTFILE, configFile);    eventBus = new EventBus("test");    provider = new PollingPropertiesFileConfigurationProvider("host1", configFile, eventBus, 1);    provider.start();    LifecycleController.waitForOneOf(provider, LifecycleState.START_OR_ERROR);}
c6aaebb5a52567751db8dc8e1cb9dd4a4e582ef964a374b376c6a04f741802dc
tearDown
public void tearDown() throws Exception
{    FileUtils.deleteDirectory(baseDir);    provider.stop();}
d10db0e3653ed73511f03e48febaa41eb8f11b3a5736815b8a26982f058b8f35
testPolling
public void testPolling() throws Exception
{        Thread.sleep(2000L);    final List<MaterializedConfiguration> events = Lists.newArrayList();    Object eventHandler = new Object() {        @Subscribe        public synchronized void handleConfigurationEvent(MaterializedConfiguration event) {            events.add(event);        }    };    eventBus.register(eventHandler);    configFile.setLastModified(System.currentTimeMillis());        Thread.sleep(2000L);    Assert.assertEquals(String.valueOf(events), 1, events.size());    MaterializedConfiguration materializedConfiguration = events.remove(0);    Assert.assertEquals(1, materializedConfiguration.getSourceRunners().size());    Assert.assertEquals(1, materializedConfiguration.getSinkRunners().size());    Assert.assertEquals(1, materializedConfiguration.getChannels().size());}
cb4f1d3b88a683b005eed125c640cbf6db4bcafaeb73ddb1574a8fee20846309
handleConfigurationEvent
public synchronized void handleConfigurationEvent(MaterializedConfiguration event)
{    events.add(event);}
2b267f0b3ab41e66e4d3ed245bf2053953bc02aa246c118259e68dc9b41c6c3e
notifyEvent
public synchronized void notifyEvent(MaterializedConfiguration mConfig)
{    notified = true;    notifyAll();}
9a1fd26019ee5732cec2ca74ab9c858573874090f26372a8c31303a325cc88b4
awaitEvent
public synchronized void awaitEvent() throws InterruptedException
{    while (!notified) {        wait();    }}
82d93c01a4aa8b564ec62dfb621083598a6a6b25ac4a6655d6e3db9476e48cd1
reset
public synchronized void reset()
{    notified = false;}
fa0376aa4fb507886a841829a802ac094af293381bf8bb1a03b96eb7e26f5f02
doSetUp
protected void doSetUp() throws Exception
{    eb = new EventBus("test");    es = new EventSync();    es.reset();    eb.register(es);    cp = new PollingZooKeeperConfigurationProvider(AGENT_NAME, "localhost:" + zkServer.getPort(), null, eb);    cp.start();    LifecycleController.waitForOneOf(cp, LifecycleState.START_OR_ERROR);}
676d5ca61267a0dfcd97782efeaeea6b8606ee22500b986f8f6e3ead2d6fe527
doTearDown
protected void doTearDown() throws Exception
{}
d10db0e3653ed73511f03e48febaa41eb8f11b3a5736815b8a26982f058b8f35
testPolling
public void testPolling() throws Exception
{    es.awaitEvent();    es.reset();    FlumeConfiguration fc = cp.getFlumeConfiguration();    Assert.assertTrue(fc.getConfigurationErrors().isEmpty());    AgentConfiguration ac = fc.getConfigurationFor(AGENT_NAME);    Assert.assertNull(ac);    addData();    es.awaitEvent();    es.reset();    verifyProperties(cp);}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    provider = new PropertiesFileConfigurationProvider("test", TESTFILE);}
c6aaebb5a52567751db8dc8e1cb9dd4a4e582ef964a374b376c6a04f741802dc
tearDown
public void tearDown() throws Exception
{}
aaf680172edb37c7b2cb49d472965687b0322347e17b92aa619914a408af23bc
testPropertyRead
public void testPropertyRead() throws Exception
{    FlumeConfiguration configuration = provider.getFlumeConfiguration();    Assert.assertNotNull(configuration);    /*     * Test the known errors in the file     */    List<String> expected = Lists.newArrayList();    expected.add("host5 CONFIG_ERROR");    expected.add("host5 INVALID_PROPERTY");    expected.add("host4 CONFIG_ERROR");    expected.add("host4 CONFIG_ERROR");    expected.add("host4 PROPERTY_VALUE_NULL");    expected.add("host4 PROPERTY_VALUE_NULL");    expected.add("host4 PROPERTY_VALUE_NULL");    expected.add("host4 AGENT_CONFIGURATION_INVALID");    expected.add("ch2 ATTRS_MISSING");    expected.add("host3 CONFIG_ERROR");    expected.add("host3 PROPERTY_VALUE_NULL");    expected.add("host3 AGENT_CONFIGURATION_INVALID");    expected.add("host2 PROPERTY_VALUE_NULL");    expected.add("host2 AGENT_CONFIGURATION_INVALID");    List<String> actual = Lists.newArrayList();    for (FlumeConfigurationError error : configuration.getConfigurationErrors()) {        actual.add(error.getComponentName() + " " + error.getErrorType().toString());    }    Collections.sort(expected);    Collections.sort(actual);    Assert.assertEquals(expected, actual);    AgentConfiguration agentConfiguration = configuration.getConfigurationFor("host1");    Assert.assertNotNull(agentConfiguration);    LOGGER.info(agentConfiguration.getPrevalidationConfig());    LOGGER.info(agentConfiguration.getPostvalidationConfig());    Set<String> sources = Sets.newHashSet("source1");    Set<String> sinks = Sets.newHashSet("sink1");    Set<String> channels = Sets.newHashSet("channel1");    Assert.assertEquals(sources, agentConfiguration.getSourceSet());    Assert.assertEquals(sinks, agentConfiguration.getSinkSet());    Assert.assertEquals(channels, agentConfiguration.getChannelSet());}
fa0376aa4fb507886a841829a802ac094af293381bf8bb1a03b96eb7e26f5f02
doSetUp
protected void doSetUp() throws Exception
{    addData();    configurationProvider = new StaticZooKeeperConfigurationProvider(AGENT_NAME, "localhost:" + zkServer.getPort(), null);}
676d5ca61267a0dfcd97782efeaeea6b8606ee22500b986f8f6e3ead2d6fe527
doTearDown
protected void doTearDown() throws Exception
{}
aaf680172edb37c7b2cb49d472965687b0322347e17b92aa619914a408af23bc
testPropertyRead
public void testPropertyRead() throws Exception
{    verifyProperties(configurationProvider);}
6a1bb22738bbd08ebbb6cc494923dc47f4ed3342640172cf132b2f852b510695
data
public static Collection<?> data()
{    Object[][] data = new Object[][] { { true }, { false } };    return Arrays.asList(data);}
20a0d20db92e539dc6a5a11f49c6117d2a5157536305ee4a7e3d51c0b1ded528
getFreePort
private static int getFreePort()
{    try (ServerSocket socket = new ServerSocket(0)) {        return socket.getLocalPort();    } catch (IOException e) {        throw new AssertionError("Can not open socket", e);    }}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    logger.info("Running setup");    channel = new MemoryChannel();    source = new NetcatSource();    Context context = new Context();    Configurables.configure(channel, context);    List<Channel> channels = Lists.newArrayList(channel);    ChannelSelector rcs = new ReplicatingChannelSelector();    rcs.setChannels(channels);    source.setChannelProcessor(new ChannelProcessor(rcs));}
0a08e57b8fd62549ead86d6c09050e7c70669961513c344148689c9fe1a35aa5
testLifecycle
public void testLifecycle() throws InterruptedException, LifecycleException, EventDeliveryException
{    final int port = getFreePort();    ExecutorService executor = Executors.newFixedThreadPool(3);    Context context = new Context();    context.put("bind", "0.0.0.0");    context.put("port", String.valueOf(port));    context.put("ack-every-event", String.valueOf(ackEveryEvent));    Configurables.configure(source, context);    source.start();    Runnable clientRequestRunnable = new Runnable() {        @Override        public void run() {            try {                SocketChannel clientChannel = SocketChannel.open(new InetSocketAddress(port));                Writer writer = Channels.newWriter(clientChannel, "utf-8");                BufferedReader reader = new BufferedReader(Channels.newReader(clientChannel, "utf-8"));                writer.write("Test message\n");                writer.flush();                if (ackEveryEvent) {                    String response = reader.readLine();                    Assert.assertEquals("Server should return OK", "OK", response);                } else {                    Assert.assertFalse("Server should not return anything", reader.ready());                }                clientChannel.close();            } catch (IOException e) {                logger.error("Caught exception: ", e);            }        }    };    ChannelSelector selector = source.getChannelProcessor().getSelector();    Transaction tx = selector.getAllChannels().get(0).getTransaction();    tx.begin();    for (int i = 0; i < 100; i++) {        logger.info("Sending request");        executor.submit(clientRequestRunnable);        Event event = channel.take();        Assert.assertNotNull(event);        Assert.assertArrayEquals("Test message".getBytes(), event.getBody());    }    tx.commit();    tx.close();    executor.shutdown();    while (!executor.isTerminated()) {        executor.awaitTermination(500, TimeUnit.MILLISECONDS);    }    source.stop();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    try {        SocketChannel clientChannel = SocketChannel.open(new InetSocketAddress(port));        Writer writer = Channels.newWriter(clientChannel, "utf-8");        BufferedReader reader = new BufferedReader(Channels.newReader(clientChannel, "utf-8"));        writer.write("Test message\n");        writer.flush();        if (ackEveryEvent) {            String response = reader.readLine();            Assert.assertEquals("Server should return OK", "OK", response);        } else {            Assert.assertFalse("Server should not return anything", reader.ready());        }        clientChannel.close();    } catch (IOException e) {        logger.error("Caught exception: ", e);    }}
8a0e3f9d0059a53ed500415e4af0ff5787e07d5db23f3a6333f33e66492a9e1b
getBatchSize
public int getBatchSize()
{    return batchSize;}
80c1432d35f38a3d5605a9725b59afda41a2f9696891727c919493ddcce168cb
parseBatchSize
public static int parseBatchSize(Properties properties)
{    String strBatchSize = properties.getProperty(RpcClientConfigurationConstants.CONFIG_BATCH_SIZE);    logger.debug("Batch size string = " + strBatchSize);    int batchSize = RpcClientConfigurationConstants.DEFAULT_BATCH_SIZE;    if (strBatchSize != null && !strBatchSize.isEmpty()) {        try {            int parsedBatch = Integer.parseInt(strBatchSize);            if (parsedBatch < 1) {                logger.warn("Invalid value for batchSize: {}; Using default value.", parsedBatch);            } else {                batchSize = parsedBatch;            }        } catch (NumberFormatException e) {            logger.warn("Batchsize is not valid for RpcClient: " + strBatchSize + ". Default value assigned.", e);        }    }    return batchSize;}
8aa512570468192cc551df19081fb3e5ae4a44ebd5ada6171d8192c44144f57d
configureHosts
private synchronized void configureHosts(Properties properties) throws FlumeException
{    if (isActive) {        logger.error("This client was already configured, " + "cannot reconfigure.");        throw new FlumeException("This client was already configured, " + "cannot reconfigure.");    }    hosts = HostInfo.getHostInfoList(properties);    String tries = properties.getProperty(RpcClientConfigurationConstants.CONFIG_MAX_ATTEMPTS);    if (tries == null || tries.isEmpty()) {        maxTries = hosts.size();    } else {        try {            maxTries = Integer.parseInt(tries);        } catch (NumberFormatException e) {            maxTries = hosts.size();        }    }    batchSize = parseBatchSize(properties);    isActive = true;}
84b266784270d6f4d77303a46d62827e0a485bda378164bf7b0c4ba595b93857
getMaxTries
protected Integer getMaxTries()
{    return maxTries;}
154024fbc6496c3c7a3730c32e897991db4e8bf65d5b47ffbe98b66bd271a0b6
getClient
private synchronized RpcClient getClient()
{    if (client == null || !this.client.isActive()) {        client = getNextClient();        return client;    } else {        return client;    }}
1a5fbca1f83b7b141583cb0c2c4250c7d29bdfe934d193c1e998aebb56cace48
append
public void append(Event event) throws EventDeliveryException
{                    RpcClient localClient = null;    synchronized (this) {        if (!isActive) {            logger.error("Attempting to append to an already closed client.");            throw new EventDeliveryException("Attempting to append to an already closed client.");        }    }        int tries = 0;    while (tries < maxTries) {        try {            tries++;            localClient = getClient();            localClient.append(event);            return;        } catch (EventDeliveryException e) {                        logger.warn("Client failed. Exception follows: ", e);            localClient.close();            localClient = null;        } catch (Exception e2) {            logger.error("Failed to send event: ", e2);            throw new EventDeliveryException("Failed to send event. Exception follows: ", e2);        }    }    logger.error("Tried many times, could not send event.");    throw new EventDeliveryException("Failed to send the event!");}
198dd9299985e913fe35a351789cf03b0804221fcedde2f9cb31f869d084c1fd
appendBatch
public void appendBatch(List<Event> events) throws EventDeliveryException
{    RpcClient localClient = null;    synchronized (this) {        if (!isActive) {            logger.error("Attempting to append to an already closed client.");            throw new EventDeliveryException("Attempting to append to an already closed client!");        }    }    int tries = 0;    while (tries < maxTries) {        try {            tries++;            localClient = getClient();            localClient.appendBatch(events);            return;        } catch (EventDeliveryException e) {                        logger.warn("Client failed. Exception follows: ", e);            localClient.close();            localClient = null;        } catch (Exception e1) {            logger.error("No clients active: ", e1);            throw new EventDeliveryException("No clients currently active. " + "Exception follows: ", e1);        }    }    logger.error("Tried many times, could not send event.");    throw new EventDeliveryException("Failed to send the event!");}
b5f98c2fd00ffb1b39edb8dc69b89afc99d1772c1b09665c0e53463a095451b2
isActive
public synchronized boolean isActive()
{    return isActive;}
09b6754a9ed0a90a22fc91d2e8392c167b7cd88f21ddd7ba703270e2ac5efa01
close
public synchronized void close() throws FlumeException
{    if (client != null) {        client.close();        isActive = false;    }}
d9d19b58ab0a9677797e8d562087f1e654d3ce0df051a325fff0f360ab04fc68
getLastConnectedServerAddress
protected InetSocketAddress getLastConnectedServerAddress()
{    HostInfo hostInfo = hosts.get(lastCheckedhost);    return new InetSocketAddress(hostInfo.getHostName(), hostInfo.getPortNumber());}
100f38d45a6680fffae0262182afccd6a3c8347edaa7a81dee465b246916c18d
getNextClient
private RpcClient getNextClient() throws FlumeException
{    lastCheckedhost = (lastCheckedhost == (hosts.size() - 1)) ? -1 : lastCheckedhost;    RpcClient localClient = null;    int limit = hosts.size();    Properties props = new Properties();    props.putAll(configurationProperties);    props.put(RpcClientConfigurationConstants.CONFIG_CLIENT_TYPE, RpcClientConfigurationConstants.DEFAULT_CLIENT_TYPE);        for (int count = lastCheckedhost + 1; count < limit; count++) {        HostInfo hostInfo = hosts.get(count);        try {            setDefaultProperties(hostInfo, props);            localClient = RpcClientFactory.getInstance(props);            lastCheckedhost = count;            return localClient;        } catch (FlumeException e) {            logger.info("Could not connect to " + hostInfo, e);            continue;        }    }    for (int count = 0; count <= lastCheckedhost; count++) {        HostInfo hostInfo = hosts.get(count);        try {            setDefaultProperties(hostInfo, props);            localClient = RpcClientFactory.getInstance(props);            lastCheckedhost = count;            return localClient;        } catch (FlumeException e) {            logger.info("Could not connect to " + hostInfo, e);            continue;        }    }    if (localClient == null) {        lastCheckedhost = -1;        logger.error("No active client found.");        throw new FlumeException("No active client.");    }        return localClient;}
4f3c8918695d1a3f18ed8c4d15fa69e3fe508f78710a2339966489556c13af0a
setDefaultProperties
private void setDefaultProperties(HostInfo hostInfo, Properties props)
{    props.put(RpcClientConfigurationConstants.CONFIG_CLIENT_TYPE, RpcClientFactory.ClientType.DEFAULT.name());    props.put(RpcClientConfigurationConstants.CONFIG_HOSTS, hostInfo.getReferenceName());}
5df6ba1bd54623dd2cae117c172c633fb90f6596118ecc5ddca1143d026bb7dd
configure
public void configure(Properties properties) throws FlumeException
{    configurationProperties = new Properties();    configurationProperties.putAll(properties);    configureHosts(configurationProperties);}
8bce1b9cf244db26636ff1c9fea08efa07ffe0e4b51fd774b6de209364d70245
getReferenceName
public String getReferenceName()
{    return referenceName;}
39d9cd6f38baa59fab797f91a6856e0162449a9f7cddd492a3b663cf6cbec3fe
getHostName
public String getHostName()
{    return hostName;}
99b0ac8fb450c61c9841d5a2d6355df61db128505c00039773c8b92b799f49d9
getPortNumber
public int getPortNumber()
{    return portNumber;}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return referenceName + "{" + hostName + ":" + portNumber + "}";}
9af771e5f7cf6e3fdd4664de9daf46819f7c3a6dff89b88e1664765156e66d8c
getHostInfoList
public static List<HostInfo> getHostInfoList(Properties properties)
{    List<HostInfo> hosts = new ArrayList<HostInfo>();    String hostNames = properties.getProperty(RpcClientConfigurationConstants.CONFIG_HOSTS);    String[] hostList;    if (hostNames != null && !hostNames.isEmpty()) {        hostList = hostNames.split("\\s+");        for (int i = 0; i < hostList.length; i++) {            String hostAndPortStr = properties.getProperty(RpcClientConfigurationConstants.CONFIG_HOSTS_PREFIX + hostList[i]);                        if (hostAndPortStr != null) {                String[] hostAndPort = hostAndPortStr.split(":");                if (hostAndPort.length != 2) {                    LOGGER.error("Invalid host address" + hostAndPortStr);                    throw new FlumeException("Invalid host address" + hostAndPortStr);                }                Integer port = null;                try {                    port = Integer.parseInt(hostAndPort[1]);                } catch (NumberFormatException e) {                    LOGGER.error("Invalid port number" + hostAndPortStr, e);                    throw new FlumeException("Invalid port number" + hostAndPortStr);                }                HostInfo info = new HostInfo(hostList[i], hostAndPort[0].trim(), port);                hosts.add(info);            }        }    }    return hosts;}
1a5fbca1f83b7b141583cb0c2c4250c7d29bdfe934d193c1e998aebb56cace48
append
public void append(Event event) throws EventDeliveryException
{    throwIfClosed();    boolean eventSent = false;    Iterator<HostInfo> it = selector.createHostIterator();    while (it.hasNext()) {        HostInfo host = it.next();        try {            RpcClient client = getClient(host);            client.append(event);            eventSent = true;            break;        } catch (Exception ex) {            selector.informFailure(host);            LOGGER.warn("Failed to send event to host " + host, ex);        }    }    if (!eventSent) {        throw new EventDeliveryException("Unable to send event to any host");    }}
198dd9299985e913fe35a351789cf03b0804221fcedde2f9cb31f869d084c1fd
appendBatch
public void appendBatch(List<Event> events) throws EventDeliveryException
{    throwIfClosed();    boolean batchSent = false;    Iterator<HostInfo> it = selector.createHostIterator();    while (it.hasNext()) {        HostInfo host = it.next();        try {            RpcClient client = getClient(host);            client.appendBatch(events);            batchSent = true;            break;        } catch (Exception ex) {            selector.informFailure(host);            LOGGER.warn("Failed to send batch to host " + host, ex);        }    }    if (!batchSent) {        throw new EventDeliveryException("Unable to send batch to any host");    }}
967d21828dd4b7396b26e55f80c4b30972f51b68d2fa61b73d106a476da86ea0
isActive
public boolean isActive()
{    return isOpen;}
55d4a013b41c703b07c5f94ef919750aa6c878568a3c38eee06b69deea03d4b3
throwIfClosed
private void throwIfClosed() throws EventDeliveryException
{    if (!isOpen) {        throw new EventDeliveryException("Rpc Client is closed");    }}
0cba8c786806bb353f75fd185b36c373dd29ee524383c17946be357df745cfe2
close
public void close() throws FlumeException
{    isOpen = false;    synchronized (this) {        Iterator<String> it = clientMap.keySet().iterator();        while (it.hasNext()) {            String name = it.next();            RpcClient client = clientMap.get(name);            if (client != null) {                try {                    client.close();                } catch (Exception ex) {                    LOGGER.warn("Failed to close client: " + name, ex);                }            }            it.remove();        }    }}
fa4f42f502232e3df3e3fcca36975ce5c8d1abbffe40e7f6c43927c7172af8aa
configure
protected void configure(Properties properties) throws FlumeException
{    clientMap = new HashMap<String, RpcClient>();    configurationProperties = new Properties();    configurationProperties.putAll(properties);    hosts = HostInfo.getHostInfoList(properties);    if (hosts.size() < 2) {        throw new FlumeException("At least two hosts are required to use the " + "load balancing RPC client.");    }    String lbTypeName = properties.getProperty(RpcClientConfigurationConstants.CONFIG_HOST_SELECTOR, RpcClientConfigurationConstants.HOST_SELECTOR_ROUND_ROBIN);    boolean backoff = Boolean.valueOf(properties.getProperty(RpcClientConfigurationConstants.CONFIG_BACKOFF, String.valueOf(false)));    String maxBackoffStr = properties.getProperty(RpcClientConfigurationConstants.CONFIG_MAX_BACKOFF);    long maxBackoff = 0;    if (maxBackoffStr != null) {        maxBackoff = Long.parseLong(maxBackoffStr);    }    if (lbTypeName.equalsIgnoreCase(RpcClientConfigurationConstants.HOST_SELECTOR_ROUND_ROBIN)) {        selector = new RoundRobinHostSelector(backoff, maxBackoff);    } else if (lbTypeName.equalsIgnoreCase(RpcClientConfigurationConstants.HOST_SELECTOR_RANDOM)) {        selector = new RandomOrderHostSelector(backoff, maxBackoff);    } else {        try {            @SuppressWarnings("unchecked")            Class<? extends HostSelector> klass = (Class<? extends HostSelector>) Class.forName(lbTypeName);            selector = klass.newInstance();        } catch (Exception ex) {            throw new FlumeException("Unable to instantiate host selector: " + lbTypeName, ex);        }    }    selector.setHosts(hosts);    batchSize = parseBatchSize(properties);    isOpen = true;}
5d1b69d20eb28ed358bce39b6678771353f67ca4453d4a77647bc3db8813d3b9
getClient
private synchronized RpcClient getClient(HostInfo info) throws FlumeException, EventDeliveryException
{    throwIfClosed();    String name = info.getReferenceName();    RpcClient client = clientMap.get(name);    if (client == null) {        client = createClient(name);        clientMap.put(name, client);    } else if (!client.isActive()) {        try {            client.close();        } catch (Exception ex) {            LOGGER.warn("Failed to close client for " + info, ex);        }        client = createClient(name);        clientMap.put(name, client);    }    return client;}
e49188c941456aca2c5b466aceb267993646e6c8f46c6c9eb18cd97a11248ab9
createClient
private RpcClient createClient(String referenceName) throws FlumeException
{    Properties props = getClientConfigurationProperties(referenceName);    return RpcClientFactory.getInstance(props);}
d8776e8af60a8f8a973b0493d9e77d20153e17e55931e31c434d79df6c7c2e9f
getClientConfigurationProperties
private Properties getClientConfigurationProperties(String referenceName)
{    Properties props = new Properties();    props.putAll(configurationProperties);    props.put(RpcClientConfigurationConstants.CONFIG_CLIENT_TYPE, RpcClientFactory.ClientType.DEFAULT);    props.put(RpcClientConfigurationConstants.CONFIG_HOSTS, referenceName);    return props;}
3141a7a6edb1fab403b8980ca8d74dc45b223bb9724c25153e4b8a0e1cc26392
createHostIterator
public synchronized Iterator<HostInfo> createHostIterator()
{    return selector.createIterator();}
6c09fb3bfc2e74211dbf67f4aa0676c75336a191139625f3220fdcb407171905
setHosts
public synchronized void setHosts(List<HostInfo> hosts)
{    selector.setObjects(hosts);}
3a9d0919bde6f08943142091667c39937e4f456f33d18dfe1469f729b9da76d9
informFailure
public synchronized void informFailure(HostInfo failedHost)
{    selector.informFailure(failedHost);}
3141a7a6edb1fab403b8980ca8d74dc45b223bb9724c25153e4b8a0e1cc26392
createHostIterator
public synchronized Iterator<HostInfo> createHostIterator()
{    return selector.createIterator();}
6c09fb3bfc2e74211dbf67f4aa0676c75336a191139625f3220fdcb407171905
setHosts
public synchronized void setHosts(List<HostInfo> hosts)
{    selector.setObjects(hosts);}
859036eebf83eaffea63dc17d5de951eafe2e6a271d6283e593bc7172066ef6f
informFailure
public void informFailure(HostInfo failedHost)
{    selector.informFailure(failedHost);}
741a91a76dd92aeb327a7de04be7065780aa04a4e8ed6f05f194f5734e317713
connect
private void connect() throws FlumeException
{    connect(connectTimeout, TimeUnit.MILLISECONDS);}
fb636a21a3f333e52a59dac0cd802bf48965edb274d564ae718e5ba1c39fc15e
connect
private void connect(long timeout, TimeUnit tu) throws FlumeException
{    callTimeoutPool = Executors.newCachedThreadPool(new TransceiverThreadFactory("Flume Avro RPC Client Call Invoker"));    NioClientSocketChannelFactory socketChannelFactory = null;    try {        ExecutorService bossExecutor = Executors.newCachedThreadPool(new TransceiverThreadFactory("Avro " + NettyTransceiver.class.getSimpleName() + " Boss"));        ExecutorService workerExecutor = Executors.newCachedThreadPool(new TransceiverThreadFactory("Avro " + NettyTransceiver.class.getSimpleName() + " I/O Worker"));        if (enableDeflateCompression || enableSsl) {            if (maxIoWorkers >= 1) {                socketChannelFactory = new SSLCompressionChannelFactory(bossExecutor, workerExecutor, enableDeflateCompression, enableSsl, trustAllCerts, compressionLevel, truststore, truststorePassword, truststoreType, excludeProtocols, includeProtocols, excludeCipherSuites, includeCipherSuites, maxIoWorkers);            } else {                socketChannelFactory = new SSLCompressionChannelFactory(bossExecutor, workerExecutor, enableDeflateCompression, enableSsl, trustAllCerts, compressionLevel, truststore, truststorePassword, truststoreType, excludeProtocols, includeProtocols, excludeCipherSuites, includeCipherSuites);            }        } else {            if (maxIoWorkers >= 1) {                socketChannelFactory = new NioClientSocketChannelFactory(bossExecutor, workerExecutor, maxIoWorkers);            } else {                socketChannelFactory = new NioClientSocketChannelFactory(bossExecutor, workerExecutor);            }        }        transceiver = new NettyTransceiver(this.address, socketChannelFactory, tu.toMillis(timeout));        avroClient = SpecificRequestor.getClient(AvroSourceProtocol.Callback.class, transceiver);    } catch (Throwable t) {        if (callTimeoutPool != null) {            callTimeoutPool.shutdownNow();        }        if (socketChannelFactory != null) {            socketChannelFactory.releaseExternalResources();        }        if (t instanceof IOException) {            throw new FlumeException(this + ": RPC connection error", t);        } else if (t instanceof FlumeException) {            throw (FlumeException) t;        } else if (t instanceof Error) {            throw (Error) t;        } else {            throw new FlumeException(this + ": Unexpected exception", t);        }    }    setState(ConnState.READY);}
0cba8c786806bb353f75fd185b36c373dd29ee524383c17946be357df745cfe2
close
public void close() throws FlumeException
{    if (callTimeoutPool != null) {        callTimeoutPool.shutdown();        try {            if (!callTimeoutPool.awaitTermination(requestTimeout, TimeUnit.MILLISECONDS)) {                callTimeoutPool.shutdownNow();                if (!callTimeoutPool.awaitTermination(requestTimeout, TimeUnit.MILLISECONDS)) {                    logger.warn(this + ": Unable to cleanly shut down call timeout " + "pool");                }            }        } catch (InterruptedException ex) {            logger.warn(this + ": Interrupted during close", ex);                        callTimeoutPool.shutdownNow();                        Thread.currentThread().interrupt();        }        callTimeoutPool = null;    }    try {        transceiver.close();    } catch (IOException ex) {        throw new FlumeException(this + ": Error closing transceiver.", ex);    } finally {        setState(ConnState.DEAD);    }}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return "NettyAvroRpcClient { host: " + address.getHostName() + ", port: " + address.getPort() + " }";}
1a5fbca1f83b7b141583cb0c2c4250c7d29bdfe934d193c1e998aebb56cace48
append
public void append(Event event) throws EventDeliveryException
{    try {        append(event, requestTimeout, TimeUnit.MILLISECONDS);    } catch (Throwable t) {                        setState(ConnState.DEAD);        if (t instanceof Error) {            throw (Error) t;        }        if (t instanceof TimeoutException) {            throw new EventDeliveryException(this + ": Failed to send event. " + "RPC request timed out after " + requestTimeout + "ms", t);        }        throw new EventDeliveryException(this + ": Failed to send event", t);    }}
228039381b0abc44f3ccd77ccf30954a2db2fbab8120ba643464b85368dca294
append
private void append(Event event, long timeout, TimeUnit tu) throws EventDeliveryException
{    assertReady();    final CallFuture<Status> callFuture = new CallFuture<Status>();    final AvroFlumeEvent avroEvent = new AvroFlumeEvent();    avroEvent.setBody(ByteBuffer.wrap(event.getBody()));    avroEvent.setHeaders(toCharSeqMap(event.getHeaders()));    Future<Void> handshake;    try {                handshake = callTimeoutPool.submit(new Callable<Void>() {            @Override            public Void call() throws Exception {                avroClient.append(avroEvent, callFuture);                return null;            }        });    } catch (RejectedExecutionException ex) {        throw new EventDeliveryException(this + ": Executor error", ex);    }    try {        handshake.get(connectTimeout, TimeUnit.MILLISECONDS);    } catch (TimeoutException ex) {        throw new EventDeliveryException(this + ": Handshake timed out after " + connectTimeout + " ms", ex);    } catch (InterruptedException ex) {        throw new EventDeliveryException(this + ": Interrupted in handshake", ex);    } catch (ExecutionException ex) {        throw new EventDeliveryException(this + ": RPC request exception", ex);    } catch (CancellationException ex) {        throw new EventDeliveryException(this + ": RPC request cancelled", ex);    } finally {        if (!handshake.isDone()) {            handshake.cancel(true);        }    }    waitForStatusOK(callFuture, timeout, tu);}
d12537fee0d4fb03a2b54ca4cc2cb7aeeb6659af2e7d4f187baf67a1d3ca17d2
call
public Void call() throws Exception
{    avroClient.append(avroEvent, callFuture);    return null;}
198dd9299985e913fe35a351789cf03b0804221fcedde2f9cb31f869d084c1fd
appendBatch
public void appendBatch(List<Event> events) throws EventDeliveryException
{    try {        appendBatch(events, requestTimeout, TimeUnit.MILLISECONDS);    } catch (Throwable t) {                        setState(ConnState.DEAD);        if (t instanceof Error) {            throw (Error) t;        }        if (t instanceof TimeoutException) {            throw new EventDeliveryException(this + ": Failed to send event. " + "RPC request timed out after " + requestTimeout + " ms", t);        }        throw new EventDeliveryException(this + ": Failed to send batch", t);    }}
11afd6ef55a3a9e4fe8c4d3529b6a0fbacaf2f3a1a4b602e2308a7a0c0b6f57f
appendBatch
private void appendBatch(List<Event> events, long timeout, TimeUnit tu) throws EventDeliveryException
{    assertReady();    Iterator<Event> iter = events.iterator();    final List<AvroFlumeEvent> avroEvents = new LinkedList<AvroFlumeEvent>();        while (iter.hasNext()) {        avroEvents.clear();        for (int i = 0; i < batchSize && iter.hasNext(); i++) {            Event event = iter.next();            AvroFlumeEvent avroEvent = new AvroFlumeEvent();            avroEvent.setBody(ByteBuffer.wrap(event.getBody()));            avroEvent.setHeaders(toCharSeqMap(event.getHeaders()));            avroEvents.add(avroEvent);        }        final CallFuture<Status> callFuture = new CallFuture<Status>();        Future<Void> handshake;        try {                        handshake = callTimeoutPool.submit(new Callable<Void>() {                @Override                public Void call() throws Exception {                    avroClient.appendBatch(avroEvents, callFuture);                    return null;                }            });        } catch (RejectedExecutionException ex) {            throw new EventDeliveryException(this + ": Executor error", ex);        }        try {            handshake.get(connectTimeout, TimeUnit.MILLISECONDS);        } catch (TimeoutException ex) {            throw new EventDeliveryException(this + ": Handshake timed out after " + connectTimeout + "ms", ex);        } catch (InterruptedException ex) {            throw new EventDeliveryException(this + ": Interrupted in handshake", ex);        } catch (ExecutionException ex) {            throw new EventDeliveryException(this + ": RPC request exception", ex);        } catch (CancellationException ex) {            throw new EventDeliveryException(this + ": RPC request cancelled", ex);        } finally {            if (!handshake.isDone()) {                handshake.cancel(true);            }        }        waitForStatusOK(callFuture, timeout, tu);    }}
d12537fee0d4fb03a2b54ca4cc2cb7aeeb6659af2e7d4f187baf67a1d3ca17d2
call
public Void call() throws Exception
{    avroClient.appendBatch(avroEvents, callFuture);    return null;}
ae5038701851fddf39e3abee36eefb62c79299c94ceef6dbac109edb57cdd480
waitForStatusOK
private void waitForStatusOK(CallFuture<Status> callFuture, long timeout, TimeUnit tu) throws EventDeliveryException
{    try {        Status status = callFuture.get(timeout, tu);        if (status != Status.OK) {            throw new EventDeliveryException(this + ": Avro RPC call returned " + "Status: " + status);        }    } catch (CancellationException ex) {        throw new EventDeliveryException(this + ": RPC future was cancelled", ex);    } catch (ExecutionException ex) {        throw new EventDeliveryException(this + ": Exception thrown from " + "remote handler", ex);    } catch (TimeoutException ex) {        throw new EventDeliveryException(this + ": RPC request timed out", ex);    } catch (InterruptedException ex) {        Thread.currentThread().interrupt();        throw new EventDeliveryException(this + ": RPC request interrupted", ex);    }}
147cbc17fa73ba948c2a5cdf2d5a2baa853ca48c32a7d081e7356b74d9386da2
setState
private void setState(ConnState newState)
{    stateLock.lock();    try {        if (connState == ConnState.DEAD && connState != newState) {            throw new IllegalStateException("Cannot transition from CLOSED state.");        }        connState = newState;    } finally {        stateLock.unlock();    }}
adef8c889d0485dd9fbdf8ad10539c84dcd7fec3a0830db3e4a78b6e3dc6ea50
assertReady
private void assertReady() throws EventDeliveryException
{    stateLock.lock();    try {        ConnState curState = connState;        if (curState != ConnState.READY) {            throw new EventDeliveryException("RPC failed, client in an invalid " + "state: " + curState);        }    } finally {        stateLock.unlock();    }}
ca70404cb05aa6f426a79eb036db13b49ea4f886fb6ea56db781f7474943c006
toCharSeqMap
private static Map<CharSequence, CharSequence> toCharSeqMap(Map<String, String> stringMap)
{    Map<CharSequence, CharSequence> charSeqMap = new HashMap<CharSequence, CharSequence>();    for (Map.Entry<String, String> entry : stringMap.entrySet()) {        charSeqMap.put(entry.getKey(), entry.getValue());    }    return charSeqMap;}
967d21828dd4b7396b26e55f80c4b30972f51b68d2fa61b73d106a476da86ea0
isActive
public boolean isActive()
{    stateLock.lock();    try {        return (connState == ConnState.READY);    } finally {        stateLock.unlock();    }}
c9ff77504a3bc41c7d2b6c48d0ebb14c3a19ff184370e311e44e675f3146194a
configure
public synchronized void configure(Properties properties) throws FlumeException
{    stateLock.lock();    try {        if (connState == ConnState.READY || connState == ConnState.DEAD) {            throw new FlumeException("This client was already configured, " + "cannot reconfigure.");        }    } finally {        stateLock.unlock();    }    batchSize = parseBatchSize(properties);        String hostNames = properties.getProperty(RpcClientConfigurationConstants.CONFIG_HOSTS);    String[] hosts = null;    if (hostNames != null && !hostNames.isEmpty()) {        hosts = hostNames.split("\\s+");    } else {        throw new FlumeException("Hosts list is invalid: " + hostNames);    }    if (hosts.length > 1) {        logger.warn("More than one hosts are specified for the default client. " + "Only the first host will be used and others ignored. Specified: " + hostNames + "; to be used: " + hosts[0]);    }    String host = properties.getProperty(RpcClientConfigurationConstants.CONFIG_HOSTS_PREFIX + hosts[0]);    if (host == null || host.isEmpty()) {        throw new FlumeException("Host not found: " + hosts[0]);    }    String[] hostAndPort = host.split(":");    if (hostAndPort.length != 2) {        throw new FlumeException("Invalid hostname: " + hosts[0]);    }    Integer port = null;    try {        port = Integer.parseInt(hostAndPort[1]);    } catch (NumberFormatException e) {        throw new FlumeException("Invalid Port: " + hostAndPort[1], e);    }    this.address = new InetSocketAddress(hostAndPort[0], port);        connectTimeout = RpcClientConfigurationConstants.DEFAULT_CONNECT_TIMEOUT_MILLIS;    String strConnTimeout = properties.getProperty(RpcClientConfigurationConstants.CONFIG_CONNECT_TIMEOUT);    if (strConnTimeout != null && strConnTimeout.trim().length() > 0) {        try {            connectTimeout = Long.parseLong(strConnTimeout);            if (connectTimeout < 1000) {                logger.warn("Connection timeout specified less than 1s. " + "Using default value instead.");                connectTimeout = RpcClientConfigurationConstants.DEFAULT_CONNECT_TIMEOUT_MILLIS;            }        } catch (NumberFormatException ex) {            logger.error("Invalid connect timeout specified: " + strConnTimeout);        }    }        requestTimeout = RpcClientConfigurationConstants.DEFAULT_REQUEST_TIMEOUT_MILLIS;    String strReqTimeout = properties.getProperty(RpcClientConfigurationConstants.CONFIG_REQUEST_TIMEOUT);    if (strReqTimeout != null && strReqTimeout.trim().length() > 0) {        try {            requestTimeout = Long.parseLong(strReqTimeout);            if (requestTimeout < 1000) {                logger.warn("Request timeout specified less than 1s. " + "Using default value instead.");                requestTimeout = RpcClientConfigurationConstants.DEFAULT_REQUEST_TIMEOUT_MILLIS;            }        } catch (NumberFormatException ex) {            logger.error("Invalid request timeout specified: " + strReqTimeout);        }    }    String enableCompressionStr = properties.getProperty(RpcClientConfigurationConstants.CONFIG_COMPRESSION_TYPE);    if (enableCompressionStr != null && enableCompressionStr.equalsIgnoreCase("deflate")) {        this.enableDeflateCompression = true;        String compressionLvlStr = properties.getProperty(RpcClientConfigurationConstants.CONFIG_COMPRESSION_LEVEL);        compressionLevel = RpcClientConfigurationConstants.DEFAULT_COMPRESSION_LEVEL;        if (compressionLvlStr != null) {            try {                compressionLevel = Integer.parseInt(compressionLvlStr);            } catch (NumberFormatException ex) {                logger.error("Invalid compression level: " + compressionLvlStr);            }        }    }    configureSSL(properties);    String maxIoWorkersStr = properties.getProperty(RpcClientConfigurationConstants.MAX_IO_WORKERS);    if (!StringUtils.isEmpty(maxIoWorkersStr)) {        try {            maxIoWorkers = Integer.parseInt(maxIoWorkersStr);        } catch (NumberFormatException ex) {            logger.warn("Invalid maxIOWorkers:" + maxIoWorkersStr + " Using " + "default maxIOWorkers.");            maxIoWorkers = -1;        }    }    if (maxIoWorkers < 1) {        logger.info("Using default maxIOWorkers");        maxIoWorkers = -1;    }    this.connect();}
02166686c9ffef8abcca97b0bc3e38cb95c97860d78686958b46127a2ecadb18
newThread
public Thread newThread(Runnable r)
{    Thread thread = new Thread(r);    thread.setDaemon(true);    thread.setName(prefix + " " + threadId.incrementAndGet());    return thread;}
f1d152743f68a17edf485ca7b0b821c356590cf73312288f7adcb6c93907e077
newChannel
public SocketChannel newChannel(ChannelPipeline pipeline)
{    TrustManager[] managers;    try {        if (enableCompression) {            ZlibEncoder encoder = new ZlibEncoder(compressionLevel);            pipeline.addFirst("deflater", encoder);            pipeline.addFirst("inflater", new ZlibDecoder());        }        if (enableSsl) {            if (trustAllCerts) {                logger.warn("No truststore configured, setting TrustManager to accept" + " all server certificates");                managers = new TrustManager[] { new PermissiveTrustManager() };            } else {                KeyStore keystore = null;                if (truststore != null) {                    InputStream truststoreStream = new FileInputStream(truststore);                    keystore = KeyStore.getInstance(truststoreType);                    keystore.load(truststoreStream, truststorePassword != null ? truststorePassword.toCharArray() : null);                }                TrustManagerFactory tmf = TrustManagerFactory.getInstance("SunX509");                                                tmf.init(keystore);                managers = tmf.getTrustManagers();            }            SSLContext sslContext = SSLContext.getInstance("TLS");            sslContext.init(null, managers, null);            SSLEngine sslEngine = sslContext.createSSLEngine();            sslEngine.setUseClientMode(true);            List<String> enabledProtocols = new ArrayList<String>();            for (String protocol : sslEngine.getEnabledProtocols()) {                if ((includeProtocols.isEmpty() || includeProtocols.contains(protocol)) && !excludeProtocols.contains(protocol)) {                    enabledProtocols.add(protocol);                }            }            sslEngine.setEnabledProtocols(enabledProtocols.toArray(new String[0]));            List<String> enabledCipherSuites = new ArrayList<String>();            for (String suite : sslEngine.getEnabledCipherSuites()) {                if ((includeCipherSuites.isEmpty() || includeCipherSuites.contains(suite)) && !excludeCipherSuites.contains(suite)) {                    enabledCipherSuites.add(suite);                }            }            sslEngine.setEnabledCipherSuites(enabledCipherSuites.toArray(new String[0]));            logger.info("SSLEngine protocols enabled: " + Arrays.asList(sslEngine.getEnabledProtocols()));            logger.info("SSLEngine cipher suites enabled: " + Arrays.asList(sslEngine.getEnabledProtocols()));                                                pipeline.addFirst("ssl", new SslHandler(sslEngine));        }        return super.newChannel(pipeline);    } catch (Exception ex) {        logger.error("Cannot create SSL channel", ex);        throw new RuntimeException("Cannot create SSL channel", ex);    }}
ff4e4a28c0a152e6e1627ea02e0bba88ca318bc15e775b9321ba555aa17a72e5
checkClientTrusted
public void checkClientTrusted(X509Certificate[] certs, String s)
{}
9c224c0159aa7449b31fb34da6b66aa554f1404356900809ff3fb435bc2ca415
checkServerTrusted
public void checkServerTrusted(X509Certificate[] certs, String s)
{}
b516c58bc22bde695ccdef782f17985d051ddc0b89329e35483cf2a3a576c7fe
getAcceptedIssuers
public X509Certificate[] getAcceptedIssuers()
{    return new X509Certificate[0];}
1861e85fe1b6eca21103c6fd1e0e301c7d8b3044f2b062c9732505419418f832
getInstance
public static RpcClient getInstance(Properties properties) throws FlumeException
{    String type = null;    type = properties.getProperty(RpcClientConfigurationConstants.CONFIG_CLIENT_TYPE);    if (type == null || type.isEmpty()) {        type = ClientType.DEFAULT.getClientClassName();    }    Class<? extends AbstractRpcClient> clazz;    AbstractRpcClient client;    try {        String clientClassType = type;        ClientType clientType = null;        try {            clientType = ClientType.valueOf(type.toUpperCase(Locale.ENGLISH));        } catch (IllegalArgumentException e) {            clientType = ClientType.OTHER;        }        if (!clientType.equals(ClientType.OTHER)) {            clientClassType = clientType.getClientClassName();        }        clazz = (Class<? extends AbstractRpcClient>) Class.forName(clientClassType);    } catch (ClassNotFoundException e) {        throw new FlumeException("No such client!", e);    }    try {        client = clazz.newInstance();    } catch (InstantiationException e) {        throw new FlumeException("Cannot instantiate client. " + "Exception follows:", e);    } catch (IllegalAccessException e) {        throw new FlumeException("Cannot instantiate client. " + "Exception follows:", e);    }    client.configure(properties);    return client;}
ee542661d3c41f24dbaafefdb829b799823307d92729ebaaf523570c6cc40de9
getInstance
public static RpcClient getInstance(File propertiesFile) throws FileNotFoundException, IOException
{    Reader reader = new FileReader(propertiesFile);    Properties props = new Properties();    props.load(reader);    return getInstance(props);}
3839775497ed4e65b10ccb6d5e24a8a05fc94f0cb108949908577eb2ba7e1608
getInstance
public static RpcClient getInstance(String hostname, Integer port) throws FlumeException
{    return getDefaultInstance(hostname, port);}
38a3846af30840df75dfcb337809302902837f08dc99b0cf633899d44c326d5e
getDefaultInstance
public static RpcClient getDefaultInstance(String hostname, Integer port) throws FlumeException
{    return getDefaultInstance(hostname, port, 0);}
ec5e74f312d0cdea320f8a729f5aff70dc21e0c4867550770a3c6d60186ceae3
getInstance
public static RpcClient getInstance(String hostname, Integer port, Integer batchSize) throws FlumeException
{    return getDefaultInstance(hostname, port, batchSize);}
023a34f28ccb2879ab864e36591f8e6d0640a375384b38960126f3ae6e69b312
getDefaultInstance
public static RpcClient getDefaultInstance(String hostname, Integer port, Integer batchSize) throws FlumeException
{    if (hostname == null) {        throw new NullPointerException("hostname must not be null");    }    if (port == null) {        throw new NullPointerException("port must not be null");    }    if (batchSize == null) {        throw new NullPointerException("batchSize must not be null");    }    Properties props = new Properties();    props.setProperty(RpcClientConfigurationConstants.CONFIG_HOSTS, "h1");    props.setProperty(RpcClientConfigurationConstants.CONFIG_HOSTS_PREFIX + "h1", hostname + ":" + port.intValue());    props.setProperty(RpcClientConfigurationConstants.CONFIG_BATCH_SIZE, batchSize.toString());    NettyAvroRpcClient client = new NettyAvroRpcClient();    client.configure(props);    return client;}
27a39425ec57b940ef8c348602f87b55fc8e2ca8a14cff80d147df82542cfcbf
getThriftInstance
public static RpcClient getThriftInstance(String hostname, Integer port, Integer batchSize)
{    if (hostname == null) {        throw new NullPointerException("hostname must not be null");    }    if (port == null) {        throw new NullPointerException("port must not be null");    }    if (batchSize == null) {        throw new NullPointerException("batchSize must not be null");    }    Properties props = new Properties();    props.setProperty(RpcClientConfigurationConstants.CONFIG_HOSTS, "h1");    props.setProperty(RpcClientConfigurationConstants.CONFIG_HOSTS_PREFIX + "h1", hostname + ":" + port.intValue());    props.setProperty(RpcClientConfigurationConstants.CONFIG_BATCH_SIZE, batchSize.toString());    ThriftRpcClient client = new ThriftRpcClient();    client.configure(props);    return client;}
d9aaab1e1218cba7da89c3f69a7a0b0dea3066c2cedf4a3435c130c709208ff6
getThriftInstance
public static RpcClient getThriftInstance(String hostname, Integer port)
{    return getThriftInstance(hostname, port, RpcClientConfigurationConstants.DEFAULT_BATCH_SIZE);}
c81fbd5877072a1c84999b77c619e8b604ae6df64688738f44d1cc916ea34a40
getThriftInstance
public static RpcClient getThriftInstance(Properties props)
{    props.setProperty(RpcClientConfigurationConstants.CONFIG_CLIENT_TYPE, ClientType.THRIFT.clientClassName);    return getInstance(props);}
09f8ce1c8c4e488e0b93b87c62130059ba0d12a5b794022dffec1f09169a9117
getClientClassName
protected String getClientClassName()
{    return this.clientClassName;}
facd1585bcb0e9d5cbbb61ff71eebdf2e29ff077f6adafd94d34f2d9b23f004d
configureSSL
protected void configureSSL(Properties properties) throws FlumeException
{    enableSsl = Boolean.parseBoolean(properties.getProperty(RpcClientConfigurationConstants.CONFIG_SSL));    trustAllCerts = Boolean.parseBoolean(properties.getProperty(RpcClientConfigurationConstants.CONFIG_TRUST_ALL_CERTS));    truststore = properties.getProperty(RpcClientConfigurationConstants.CONFIG_TRUSTSTORE, SSLUtil.getGlobalTruststorePath());    truststorePassword = properties.getProperty(RpcClientConfigurationConstants.CONFIG_TRUSTSTORE_PASSWORD, SSLUtil.getGlobalTruststorePassword());    truststoreType = properties.getProperty(RpcClientConfigurationConstants.CONFIG_TRUSTSTORE_TYPE, SSLUtil.getGlobalTruststoreType("JKS"));    parseList(properties.getProperty(RpcClientConfigurationConstants.CONFIG_EXCLUDE_PROTOCOLS, SSLUtil.getGlobalExcludeProtocols()), excludeProtocols);    parseList(properties.getProperty(RpcClientConfigurationConstants.CONFIG_INCLUDE_PROTOCOLS, SSLUtil.getGlobalIncludeProtocols()), includeProtocols);    parseList(properties.getProperty(RpcClientConfigurationConstants.CONFIG_EXCLUDE_CIPHER_SUITES, SSLUtil.getGlobalExcludeCipherSuites()), excludeCipherSuites);    parseList(properties.getProperty(RpcClientConfigurationConstants.CONFIG_INCLUDE_CIPHER_SUITES, SSLUtil.getGlobalIncludeCipherSuites()), includeCipherSuites);}
35833cfe1654e0e2b88d479868200bf24f8538d225db4f61ba2f7c135502235b
parseList
private void parseList(String value, Set<String> set)
{    if (Objects.nonNull(value)) {        set.addAll(Arrays.asList(value.split(" ")));    }}
02166686c9ffef8abcca97b0bc3e38cb95c97860d78686958b46127a2ecadb18
newThread
public Thread newThread(Runnable r)
{    Thread t = new Thread(r);    t.setName("Flume Thrift RPC thread - " + String.valueOf(threadCounter.incrementAndGet()));    return t;}
1a5fbca1f83b7b141583cb0c2c4250c7d29bdfe934d193c1e998aebb56cace48
append
public void append(Event event) throws EventDeliveryException
{            ClientWrapper client = null;    boolean destroyedClient = false;    try {        if (!isActive()) {            throw new EventDeliveryException("Client was closed due to error. " + "Please create a new client");        }        client = connectionManager.checkout();        final ThriftFlumeEvent thriftEvent = new ThriftFlumeEvent(event.getHeaders(), ByteBuffer.wrap(event.getBody()));        doAppend(client, thriftEvent).get(requestTimeout, TimeUnit.MILLISECONDS);    } catch (Throwable e) {        if (e instanceof ExecutionException) {            Throwable cause = e.getCause();            if (cause instanceof EventDeliveryException) {                throw (EventDeliveryException) cause;            } else if (cause instanceof TimeoutException) {                throw new EventDeliveryException("Append call timeout", cause);            }        }        destroyedClient = true;                if (client != null) {            connectionManager.destroy(client);        }        if (e instanceof Error) {            throw (Error) e;        } else if (e instanceof RuntimeException) {            throw (RuntimeException) e;        }        throw new EventDeliveryException("Failed to send event. ", e);    } finally {        if (client != null && !destroyedClient) {            connectionManager.checkIn(client);        }    }}
198dd9299985e913fe35a351789cf03b0804221fcedde2f9cb31f869d084c1fd
appendBatch
public void appendBatch(List<Event> events) throws EventDeliveryException
{            ClientWrapper client = null;    boolean destroyedClient = false;    try {        if (!isActive()) {            throw new EventDeliveryException("Client was closed " + "due to error or is not yet configured.");        }        client = connectionManager.checkout();        final List<ThriftFlumeEvent> thriftFlumeEvents = new ArrayList<ThriftFlumeEvent>();        Iterator<Event> eventsIter = events.iterator();        while (eventsIter.hasNext()) {            thriftFlumeEvents.clear();            for (int i = 0; i < batchSize && eventsIter.hasNext(); i++) {                Event event = eventsIter.next();                thriftFlumeEvents.add(new ThriftFlumeEvent(event.getHeaders(), ByteBuffer.wrap(event.getBody())));            }            if (!thriftFlumeEvents.isEmpty()) {                doAppendBatch(client, thriftFlumeEvents).get(requestTimeout, TimeUnit.MILLISECONDS);            }        }    } catch (Throwable e) {        if (e instanceof ExecutionException) {            Throwable cause = e.getCause();            if (cause instanceof EventDeliveryException) {                throw (EventDeliveryException) cause;            } else if (cause instanceof TimeoutException) {                throw new EventDeliveryException("Append call timeout", cause);            }        }        destroyedClient = true;                if (client != null) {            connectionManager.destroy(client);        }        if (e instanceof Error) {            throw (Error) e;        } else if (e instanceof RuntimeException) {            throw (RuntimeException) e;        }        throw new EventDeliveryException("Failed to send event. ", e);    } finally {        if (client != null && !destroyedClient) {            connectionManager.checkIn(client);        }    }}
6d205705af39f1e6fd99e5d8779a41a65d3a8f19aa3b71ab46b53e293b90dab2
doAppend
private Future<Void> doAppend(final ClientWrapper client, final ThriftFlumeEvent e) throws Exception
{    return callTimeoutPool.submit(new Callable<Void>() {        @Override        public Void call() throws Exception {            Status status = client.client.append(e);            if (status != Status.OK) {                throw new EventDeliveryException("Failed to deliver events. Server " + "returned status : " + status.name());            }            return null;        }    });}
d12537fee0d4fb03a2b54ca4cc2cb7aeeb6659af2e7d4f187baf67a1d3ca17d2
call
public Void call() throws Exception
{    Status status = client.client.append(e);    if (status != Status.OK) {        throw new EventDeliveryException("Failed to deliver events. Server " + "returned status : " + status.name());    }    return null;}
72118a9526e3278a0cbea13850a238145f9dd6638f3fd56e766ad35d783051d8
doAppendBatch
private Future<Void> doAppendBatch(final ClientWrapper client, final List<ThriftFlumeEvent> e) throws Exception
{    return callTimeoutPool.submit(new Callable<Void>() {        @Override        public Void call() throws Exception {            Status status = client.client.appendBatch(e);            if (status != Status.OK) {                throw new EventDeliveryException("Failed to deliver events. Server " + "returned status : " + status.name());            }            return null;        }    });}
d12537fee0d4fb03a2b54ca4cc2cb7aeeb6659af2e7d4f187baf67a1d3ca17d2
call
public Void call() throws Exception
{    Status status = client.client.appendBatch(e);    if (status != Status.OK) {        throw new EventDeliveryException("Failed to deliver events. Server " + "returned status : " + status.name());    }    return null;}
967d21828dd4b7396b26e55f80c4b30972f51b68d2fa61b73d106a476da86ea0
isActive
public boolean isActive()
{    stateLock.lock();    try {        return (connState == State.READY);    } finally {        stateLock.unlock();    }}
0cba8c786806bb353f75fd185b36c373dd29ee524383c17946be357df745cfe2
close
public void close() throws FlumeException
{    try {                stateLock.lock();        connState = State.DEAD;        connectionManager.closeAll();        callTimeoutPool.shutdown();        if (!callTimeoutPool.awaitTermination(5, TimeUnit.SECONDS)) {            callTimeoutPool.shutdownNow();        }    } catch (Throwable ex) {        if (ex instanceof Error) {            throw (Error) ex;        } else if (ex instanceof RuntimeException) {            throw (RuntimeException) ex;        }        throw new FlumeException("Failed to close RPC client. ", ex);    } finally {        stateLock.unlock();    }}
fa4f42f502232e3df3e3fcca36975ce5c8d1abbffe40e7f6c43927c7172af8aa
configure
protected void configure(Properties properties) throws FlumeException
{    if (isActive()) {        throw new FlumeException("Attempting to re-configured an already " + "configured client!");    }    stateLock.lock();    try {        HostInfo host = HostInfo.getHostInfoList(properties).get(0);        hostname = host.getHostName();        port = host.getPortNumber();        protocol = properties.getProperty(CONFIG_PROTOCOL);        if (protocol == null) {                        protocol = COMPACT_PROTOCOL;        }                if (!(protocol.equalsIgnoreCase(BINARY_PROTOCOL) || protocol.equalsIgnoreCase(COMPACT_PROTOCOL))) {            LOGGER.warn("'binary' or 'compact' are the only valid Thrift protocol types to " + "choose from. Defaulting to 'compact'.");            protocol = COMPACT_PROTOCOL;        }        batchSize = parseBatchSize(properties);        requestTimeout = Long.parseLong(properties.getProperty(RpcClientConfigurationConstants.CONFIG_REQUEST_TIMEOUT, String.valueOf(RpcClientConfigurationConstants.DEFAULT_REQUEST_TIMEOUT_MILLIS)));        if (requestTimeout < 1000) {            LOGGER.warn("Request timeout specified less than 1s. " + "Using default value instead.");            requestTimeout = RpcClientConfigurationConstants.DEFAULT_REQUEST_TIMEOUT_MILLIS;        }        int connectionPoolSize = Integer.parseInt(properties.getProperty(RpcClientConfigurationConstants.CONFIG_CONNECTION_POOL_SIZE, String.valueOf(RpcClientConfigurationConstants.DEFAULT_CONNECTION_POOL_SIZE)));        if (connectionPoolSize < 1) {            LOGGER.warn("Connection Pool Size specified is less than 1. " + "Using default value instead.");            connectionPoolSize = RpcClientConfigurationConstants.DEFAULT_CONNECTION_POOL_SIZE;        }        configureSSL(properties);        connectionManager = new ConnectionPoolManager(connectionPoolSize);        connState = State.READY;    } catch (Throwable ex) {                connState = State.DEAD;        if (ex instanceof Error) {            throw (Error) ex;        } else if (ex instanceof RuntimeException) {            throw (RuntimeException) ex;        }        throw new FlumeException("Error while configuring RpcClient. ", ex);    } finally {        stateLock.unlock();    }}
30561a0117c71b5fb3657e6125e0ae03f7f53220317e3ac7ea0745435f1e0f52
getTransport
protected TTransport getTransport(TSocket tsocket) throws Exception
{    return new TFastFramedTransport(tsocket);}
8d37d11c7ecfc0d0589696a89cb385888c83bd3e43ea0c95a3b4ae4ef78180ce
equals
public boolean equals(Object o)
{    if (o == null) {        return false;    }        if (this == o) {        return true;    }    return false;}
0ac42bf5188762fc1283b5cbd2b3bb1031e80963813b3b310b15c3fb47050003
hashCode
public int hashCode()
{    return hashCode;}
33b80a0a83752a9d474507b11531de0f2945c45d1c4e6c82000a933c10f51b31
checkout
public ClientWrapper checkout() throws Exception
{    ClientWrapper ret = null;    poolLock.lock();    try {        if (availableClients.isEmpty() && currentPoolSize < maxPoolSize) {            ret = new ClientWrapper();            currentPoolSize++;            checkedOutClients.add(ret);            return ret;        }        while (availableClients.isEmpty()) {            availableClientsCondition.await();        }        ret = availableClients.poll();        checkedOutClients.add(ret);    } finally {        poolLock.unlock();    }    return ret;}
e6046f5e9ac7834ff6381f3ac05c098efa2f758a179a282ae92c9506bae59246
checkIn
public void checkIn(ClientWrapper client)
{    poolLock.lock();    try {        availableClients.add(client);        checkedOutClients.remove(client);        availableClientsCondition.signal();    } finally {        poolLock.unlock();    }}
d704499116619296b233c512852cbedfa9b34cb6fb65d69000c581b18801c2d0
destroy
public void destroy(ClientWrapper client)
{    poolLock.lock();    try {        checkedOutClients.remove(client);        currentPoolSize--;    } finally {        poolLock.unlock();    }    client.transport.close();}
72fda972f0ef9cf90dd72e4e59f12e49760ecaa5946cc7f2f236638c6e6ec919
closeAll
public void closeAll()
{    poolLock.lock();    try {        for (ClientWrapper c : availableClients) {            c.transport.close();            currentPoolSize--;        }                for (ClientWrapper c : checkedOutClients) {            c.transport.close();            currentPoolSize--;        }    } finally {        poolLock.unlock();    }}
4186c726336277994918d6647fe4b13123cd0508ebf8990ffb4b2f99785438b0
createSSLContext
private static SSLContext createSSLContext(String truststore, String truststorePassword, String truststoreType) throws FlumeException
{    SSLContext ctx;    try {        ctx = SSLContext.getInstance("TLS");        TrustManagerFactory tmf;        tmf = TrustManagerFactory.getInstance(TrustManagerFactory.getDefaultAlgorithm());        KeyStore ts = null;        if (truststore != null && truststoreType != null) {            ts = KeyStore.getInstance(truststoreType);            ts.load(new FileInputStream(truststore), truststorePassword != null ? truststorePassword.toCharArray() : null);            tmf.init(ts);        }        tmf.init(ts);        ctx.init(null, tmf.getTrustManagers(), null);    } catch (Exception e) {        throw new FlumeException("Error creating the transport", e);    }    return ctx;}
74f20d28cf536cd6c2066083f9c9755803a92c0133e635a6a39505bd3110a3d9
createSSLSocket
private static TSocket createSSLSocket(SSLSocketFactory factory, String host, int port, int timeout, Set<String> excludeProtocols, Set<String> includeProtocols, Set<String> excludeCipherSuites, Set<String> includeCipherSuites) throws FlumeException
{    try {        SSLSocket socket = (SSLSocket) factory.createSocket(host, port);        socket.setSoTimeout(timeout);        List<String> enabledProtocols = new ArrayList<String>();        for (String protocol : socket.getEnabledProtocols()) {            if ((includeProtocols.isEmpty() || includeProtocols.contains(protocol)) && !excludeProtocols.contains(protocol)) {                enabledProtocols.add(protocol);            }        }        socket.setEnabledProtocols(enabledProtocols.toArray(new String[0]));        List<String> enabledCipherSuites = new ArrayList<String>();        for (String suite : socket.getEnabledCipherSuites()) {            if ((includeCipherSuites.isEmpty() || includeCipherSuites.contains(suite)) && !excludeCipherSuites.contains(suite)) {                enabledCipherSuites.add(suite);            }        }        socket.setEnabledCipherSuites(enabledCipherSuites.toArray(new String[0]));        return new TSocket(socket);    } catch (Exception e) {        throw new FlumeException("Could not connect to " + host + " on port " + port, e);    }}
778a7a0ca4c6dcc9392a8fe197ba6274a8c406c294850e0767da81dd3680014a
withBody
public static Event withBody(byte[] body, Map<String, String> headers)
{    Event event = new SimpleEvent();    if (body == null) {        body = new byte[0];    }    event.setBody(body);    if (headers != null) {        event.setHeaders(new HashMap<String, String>(headers));    }    return event;}
ec7d4664ab985788c2c8d4f6c4c4c3b751e14c7a44f3f2af09f55feec357c877
withBody
public static Event withBody(byte[] body)
{    return withBody(body, null);}
b843e091c96e220e0d6cf6c420acc7de1423444ff6c2ea800b06869866150ce1
withBody
public static Event withBody(String body, Charset charset, Map<String, String> headers)
{    return withBody(body.getBytes(charset), headers);}
7dc7108061222e129bbf8bed152c7137cc3e1a909a73f43684a403141959f85c
withBody
public static Event withBody(String body, Charset charset)
{    return withBody(body, charset, null);}
9a691e59a635186c5f7258710b8e44f5caf3510a02999c2c0ea95c8238b813ad
getHeaders
public Map<String, String> getHeaders()
{    return headers;}
6d1c35600a6f29feedab1769a2763829b83814294b318a32e8c71bf3529059a1
setHeaders
public void setHeaders(Map<String, String> headers)
{    this.headers = headers;}
a624aa1b85808a74c9f320025ea600169bd6e4692611a44ef53a1970442ef820
getBody
public byte[] getBody()
{    if (body != null) {        try {            return body.getBytes(charset);        } catch (UnsupportedEncodingException ex) {            throw new FlumeException(String.format("%s encoding not supported", charset), ex);        }    } else {        return new byte[0];    }}
b8505eb3e09ba9bb11ab8433148a62af59b6b1a27ffe7e69cf12f0e20e7c76a1
setBody
public void setBody(byte[] body)
{    if (body != null) {        this.body = new String(body);    } else {        this.body = "";    }}
fc3f3b8f5cdca2576ba508dd7b5e6d25e4b215eea28778e21a51f7fd51031e34
setCharset
public void setCharset(String charset)
{    this.charset = charset;}
9a691e59a635186c5f7258710b8e44f5caf3510a02999c2c0ea95c8238b813ad
getHeaders
public Map<String, String> getHeaders()
{    return headers;}
6d1c35600a6f29feedab1769a2763829b83814294b318a32e8c71bf3529059a1
setHeaders
public void setHeaders(Map<String, String> headers)
{    this.headers = headers;}
a624aa1b85808a74c9f320025ea600169bd6e4692611a44ef53a1970442ef820
getBody
public byte[] getBody()
{    return body;}
b8505eb3e09ba9bb11ab8433148a62af59b6b1a27ffe7e69cf12f0e20e7c76a1
setBody
public void setBody(byte[] body)
{    if (body == null) {        body = new byte[0];    }    this.body = body;}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    Integer bodyLen = null;    if (body != null)        bodyLen = body.length;    return "[Event headers = " + headers + ", body.length = " + bodyLen + " ]";}
7f820eeb69ca0b6ba212f7fa738d25f53ebc1bc5cfb29c2200e154ad62791a65
getValue
public int getValue()
{    return value;}
1ab87aaf6d45bdc73efb182577bb93237b4fe4d8969db0ea40620fff163376a7
findByValue
public static Status findByValue(int value)
{    switch(value) {        case 0:            return OK;        case 1:            return FAILED;        case 2:            return ERROR;        case 3:            return UNKNOWN;        default:            return null;    }}
92e9e6589c16b4fde1efd2a77a414bb3a621362cc64c5ef5a21381d0e5b55b5f
findByThriftId
public static _Fields findByThriftId(int fieldId)
{    switch(fieldId) {        case         1:            return HEADERS;        case         2:            return BODY;        default:            return null;    }}
950148827ecab1253536a12003b5b2c41c2778a566a9ed4cb2487de641d6bde4
findByThriftIdOrThrow
public static _Fields findByThriftIdOrThrow(int fieldId)
{    _Fields fields = findByThriftId(fieldId);    if (fields == null)        throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");    return fields;}
eb44b9fdf7e05046f232aa9f1f3bb9a0cf815a486270439682862994e0d2c224
findByName
public static _Fields findByName(String name)
{    return byName.get(name);}
7f8fa4ecb4119b59b8047c285ac8f8729a909f121d1d3386d19ebfc6c04ab5df
getThriftFieldId
public short getThriftFieldId()
{    return _thriftId;}
68f4afd0e3cff42097dd5b6508fea1f7952d6d93f52ded3c1deea7186fff780c
getFieldName
public String getFieldName()
{    return _fieldName;}
2316de0ea36ca15f5239e50b43bbabc620f1d6c4d3de6239fad05ba6b8ce47e3
deepCopy
public ThriftFlumeEvent deepCopy()
{    return new ThriftFlumeEvent(this);}
21ac40bb9a99614b6ac18fa4043acb6173fccff96066fdfab963dba597923aa8
clear
public void clear()
{    this.headers = null;    this.body = null;}
ae84259ac531ffb68a9f8162878a39351340b6e1e851f7185020c4eba85ec785
getHeadersSize
public int getHeadersSize()
{    return (this.headers == null) ? 0 : this.headers.size();}
548cd05b1d8f49a4e3a6f532fba672098ab11d684981bb78028301389ed3164d
putToHeaders
public void putToHeaders(String key, String val)
{    if (this.headers == null) {        this.headers = new HashMap<String, String>();    }    this.headers.put(key, val);}
9a691e59a635186c5f7258710b8e44f5caf3510a02999c2c0ea95c8238b813ad
getHeaders
public Map<String, String> getHeaders()
{    return this.headers;}
e440ad2f9db40604ca6b8b102611aed6f9eae82e3ba86b6762361d3212b70d2d
setHeaders
public ThriftFlumeEvent setHeaders(Map<String, String> headers)
{    this.headers = headers;    return this;}
178c5412f52059f9172489b15c3467b43d51e4b41b1e1287a6980c8e62981d97
unsetHeaders
public void unsetHeaders()
{    this.headers = null;}
0d420a568b93a0c9c6e9bfcf5c3b372b08d123aa49b11425477c34b20c1aecf1
isSetHeaders
public boolean isSetHeaders()
{    return this.headers != null;}
84dc87bac1ee774c1d599bac97eaa24324c5f5113c46733e20a6135f05e1ccd6
setHeadersIsSet
public void setHeadersIsSet(boolean value)
{    if (!value) {        this.headers = null;    }}
a624aa1b85808a74c9f320025ea600169bd6e4692611a44ef53a1970442ef820
getBody
public byte[] getBody()
{    setBody(org.apache.thrift.TBaseHelper.rightSize(body));    return body == null ? null : body.array();}
6825dd2155acce7578b5606a92bed8085ff901f9ae2b15ad46eb18db83fdc09b
bufferForBody
public ByteBuffer bufferForBody()
{    return org.apache.thrift.TBaseHelper.copyBinary(body);}
f3119fb9c7b01d96eef2cceda08b56535d9733cf381abe1ed5719c168eeafac0
setBody
public ThriftFlumeEvent setBody(byte[] body)
{    this.body = body == null ? (ByteBuffer) null : ByteBuffer.wrap(Arrays.copyOf(body, body.length));    return this;}
6d8efae403ba0b86d295ad5e9bef4b1271f23c1a550dd01755bae760d4b0206a
setBody
public ThriftFlumeEvent setBody(ByteBuffer body)
{    this.body = org.apache.thrift.TBaseHelper.copyBinary(body);    return this;}
bbd2e7250ca731f2583f817bf60c907b11b4b3d376a9c63f64dd4d1ebd41e273
unsetBody
public void unsetBody()
{    this.body = null;}
e78c3c9980dd4f34198d7b9ffe6e92e064fbd41f217bb4eee7ede4ab182a8e79
isSetBody
public boolean isSetBody()
{    return this.body != null;}
73c5b5c0ca4a4b1dd3cf1158ccd1e92892fc068c9732b46a15c02aa91e4612fb
setBodyIsSet
public void setBodyIsSet(boolean value)
{    if (!value) {        this.body = null;    }}
56898e9e8fffee777f79916bb0318d8a0a1794f171b373787ede8ccabb314f39
setFieldValue
public void setFieldValue(_Fields field, Object value)
{    switch(field) {        case HEADERS:            if (value == null) {                unsetHeaders();            } else {                setHeaders((Map<String, String>) value);            }            break;        case BODY:            if (value == null) {                unsetBody();            } else {                setBody((ByteBuffer) value);            }            break;    }}
464d81fc54c8c50a21a786b4dc4dd56822e73892271735c454cff15126bc2dfd
getFieldValue
public Object getFieldValue(_Fields field)
{    switch(field) {        case HEADERS:            return getHeaders();        case BODY:            return getBody();    }    throw new IllegalStateException();}
71ed64fc282e6b120c36448a4f95d0d8102f98c0455e5f84713743b2826d64c9
isSet
public boolean isSet(_Fields field)
{    if (field == null) {        throw new IllegalArgumentException();    }    switch(field) {        case HEADERS:            return isSetHeaders();        case BODY:            return isSetBody();    }    throw new IllegalStateException();}
6b3ab298cb5d88dbb2c510c786f53e377489a40e2716e63c26a3e1691765f6c5
equals
public boolean equals(Object that)
{    if (that == null)        return false;    if (that instanceof ThriftFlumeEvent)        return this.equals((ThriftFlumeEvent) that);    return false;}
9158faf8319125a7abb82b54fbc77d61a302a6adeb01b3af2229439e67cbdee3
equals
public boolean equals(ThriftFlumeEvent that)
{    if (that == null)        return false;    boolean this_present_headers = true && this.isSetHeaders();    boolean that_present_headers = true && that.isSetHeaders();    if (this_present_headers || that_present_headers) {        if (!(this_present_headers && that_present_headers))            return false;        if (!this.headers.equals(that.headers))            return false;    }    boolean this_present_body = true && this.isSetBody();    boolean that_present_body = true && that.isSetBody();    if (this_present_body || that_present_body) {        if (!(this_present_body && that_present_body))            return false;        if (!this.body.equals(that.body))            return false;    }    return true;}
0ac42bf5188762fc1283b5cbd2b3bb1031e80963813b3b310b15c3fb47050003
hashCode
public int hashCode()
{    List<Object> list = new ArrayList<Object>();    boolean present_headers = true && (isSetHeaders());    list.add(present_headers);    if (present_headers)        list.add(headers);    boolean present_body = true && (isSetBody());    list.add(present_body);    if (present_body)        list.add(body);    return list.hashCode();}
2776a7656966ac330be02b6e48740a44b6aff157c729fd79247c8e892cd0d433
compareTo
public int compareTo(ThriftFlumeEvent other)
{    if (!getClass().equals(other.getClass())) {        return getClass().getName().compareTo(other.getClass().getName());    }    int lastComparison = 0;    lastComparison = Boolean.valueOf(isSetHeaders()).compareTo(other.isSetHeaders());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetHeaders()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.headers, other.headers);        if (lastComparison != 0) {            return lastComparison;        }    }    lastComparison = Boolean.valueOf(isSetBody()).compareTo(other.isSetBody());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetBody()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.body, other.body);        if (lastComparison != 0) {            return lastComparison;        }    }    return 0;}
8ce4cec748163fe422fba58a0ef1f5936a95d5ce0ec9e530aab7c5a59149b857
fieldForId
public _Fields fieldForId(int fieldId)
{    return _Fields.findByThriftId(fieldId);}
9c387dbc68e2929966a2f4d7377de396c1c24932dd7e709eba5cf9e1c90787af
read
public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException
{    schemes.get(iprot.getScheme()).getScheme().read(iprot, this);}
72f9005ef45238c38f6c8b9506f41c8599609ccde331e03c7044ee080e1472da
write
public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException
{    schemes.get(oprot.getScheme()).getScheme().write(oprot, this);}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    StringBuilder sb = new StringBuilder("ThriftFlumeEvent(");    boolean first = true;    sb.append("headers:");    if (this.headers == null) {        sb.append("null");    } else {        sb.append(this.headers);    }    first = false;    if (!first)        sb.append(", ");    sb.append("body:");    if (this.body == null) {        sb.append("null");    } else {        org.apache.thrift.TBaseHelper.toString(this.body, sb);    }    first = false;    sb.append(")");    return sb.toString();}
e9a9838299550df368382cb18b6693a9d80b274b5c7bc089afc33713eceefbe1
validate
public void validate() throws org.apache.thrift.TException
{        if (headers == null) {        throw new org.apache.thrift.protocol.TProtocolException("Required field 'headers' was not present! Struct: " + toString());    }    if (body == null) {        throw new org.apache.thrift.protocol.TProtocolException("Required field 'body' was not present! Struct: " + toString());    }}
784e52bd99c637d4fd80e90272ace2edbc622a5a5ac2a515ab45f6d177fc378a
writeObject
private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException
{    try {        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
a2d949a3bc49af9f8b746197cee0585da9e196149570b4a376f3635b857a1744
readObject
private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException
{    try {        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
dfdf1a28c2416ef7d317d21385dd5a48567a4fe15eb3c1cbe4394bdf69b83e75
getScheme
public ThriftFlumeEventStandardScheme getScheme()
{    return new ThriftFlumeEventStandardScheme();}
88bb01b5cb02b97411a3f4c6a8571d130cf36e97e765fdb003ebaedab3ec1ffb
read
public void read(org.apache.thrift.protocol.TProtocol iprot, ThriftFlumeEvent struct) throws org.apache.thrift.TException
{    org.apache.thrift.protocol.TField schemeField;    iprot.readStructBegin();    while (true) {        schemeField = iprot.readFieldBegin();        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) {            break;        }        switch(schemeField.id) {            case             1:                if (schemeField.type == org.apache.thrift.protocol.TType.MAP) {                    {                        org.apache.thrift.protocol.TMap _map0 = iprot.readMapBegin();                        struct.headers = new HashMap<String, String>(2 * _map0.size);                        String _key1;                        String _val2;                        for (int _i3 = 0; _i3 < _map0.size; ++_i3) {                            _key1 = iprot.readString();                            _val2 = iprot.readString();                            struct.headers.put(_key1, _val2);                        }                        iprot.readMapEnd();                    }                    struct.setHeadersIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            case             2:                if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {                    struct.body = iprot.readBinary();                    struct.setBodyIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            default:                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);        }        iprot.readFieldEnd();    }    iprot.readStructEnd();        struct.validate();}
39463fe1fc1c2a3d91c3f823d9addd7c99382ddb3bca23d72e9c9a87503aebd1
write
public void write(org.apache.thrift.protocol.TProtocol oprot, ThriftFlumeEvent struct) throws org.apache.thrift.TException
{    struct.validate();    oprot.writeStructBegin(STRUCT_DESC);    if (struct.headers != null) {        oprot.writeFieldBegin(HEADERS_FIELD_DESC);        {            oprot.writeMapBegin(new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, struct.headers.size()));            for (Map.Entry<String, String> _iter4 : struct.headers.entrySet()) {                oprot.writeString(_iter4.getKey());                oprot.writeString(_iter4.getValue());            }            oprot.writeMapEnd();        }        oprot.writeFieldEnd();    }    if (struct.body != null) {        oprot.writeFieldBegin(BODY_FIELD_DESC);        oprot.writeBinary(struct.body);        oprot.writeFieldEnd();    }    oprot.writeFieldStop();    oprot.writeStructEnd();}
b7a8b6dabda80fe8ca03969c956638825445621ac37b10813fb4003f61ead2e3
getScheme
public ThriftFlumeEventTupleScheme getScheme()
{    return new ThriftFlumeEventTupleScheme();}
b4eb96149fcdb1ffb99a6e16024c46faa76c1b4c7c2e72265c9f5ea50e804593
write
public void write(org.apache.thrift.protocol.TProtocol prot, ThriftFlumeEvent struct) throws org.apache.thrift.TException
{    TTupleProtocol oprot = (TTupleProtocol) prot;    {        oprot.writeI32(struct.headers.size());        for (Map.Entry<String, String> _iter5 : struct.headers.entrySet()) {            oprot.writeString(_iter5.getKey());            oprot.writeString(_iter5.getValue());        }    }    oprot.writeBinary(struct.body);}
05d7c1b8349c8aa4f7928380b00b26dfcbc1fb7a3d18bc8387e943602eeeecf7
read
public void read(org.apache.thrift.protocol.TProtocol prot, ThriftFlumeEvent struct) throws org.apache.thrift.TException
{    TTupleProtocol iprot = (TTupleProtocol) prot;    {        org.apache.thrift.protocol.TMap _map6 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());        struct.headers = new HashMap<String, String>(2 * _map6.size);        String _key7;        String _val8;        for (int _i9 = 0; _i9 < _map6.size; ++_i9) {            _key7 = iprot.readString();            _val8 = iprot.readString();            struct.headers.put(_key7, _val8);        }    }    struct.setHeadersIsSet(true);    struct.body = iprot.readBinary();    struct.setBodyIsSet(true);}
c51e5cb6ab84996a366ca4c36408fdbb38461fdcc74ad26ed70818820572aaea
getClient
public Client getClient(org.apache.thrift.protocol.TProtocol prot)
{    return new Client(prot);}
f9e94ad26495767f197f0f23bc1a6ce01f90f5c97eede94dcba020bf0dbb3a1f
getClient
public Client getClient(org.apache.thrift.protocol.TProtocol iprot, org.apache.thrift.protocol.TProtocol oprot)
{    return new Client(iprot, oprot);}
af6650b67fbf9ba9ec209712e72764bae88319e00958d3251a744576fb3488e6
append
public Status append(ThriftFlumeEvent event) throws org.apache.thrift.TException
{    send_append(event);    return recv_append();}
7afa578deece5eb4809fbfa0b7af3f8940b38985bb88a27958e7ef87ca27a719
send_append
public void send_append(ThriftFlumeEvent event) throws org.apache.thrift.TException
{    append_args args = new append_args();    args.setEvent(event);    sendBase("append", args);}
8dff90cd2b6b8ab30e267ef008c923edadee9f9993228075547ad026c84fbcd9
recv_append
public Status recv_append() throws org.apache.thrift.TException
{    append_result result = new append_result();    receiveBase(result, "append");    if (result.isSetSuccess()) {        return result.success;    }    throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, "append failed: unknown result");}
e74931a2c01a9935877aca1dd5583b6cb562736a55c40783569805f96b6c547e
appendBatch
public Status appendBatch(List<ThriftFlumeEvent> events) throws org.apache.thrift.TException
{    send_appendBatch(events);    return recv_appendBatch();}
5f7d101b9e2b7587784c02fcef7a71bac6aa87c0e5e4b79aa6629be85d9207bb
send_appendBatch
public void send_appendBatch(List<ThriftFlumeEvent> events) throws org.apache.thrift.TException
{    appendBatch_args args = new appendBatch_args();    args.setEvents(events);    sendBase("appendBatch", args);}
f83a893240efe0558263f1a97cdbc873224b9b148e309c58c8cff623098c236b
recv_appendBatch
public Status recv_appendBatch() throws org.apache.thrift.TException
{    appendBatch_result result = new appendBatch_result();    receiveBase(result, "appendBatch");    if (result.isSetSuccess()) {        return result.success;    }    throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, "appendBatch failed: unknown result");}
f3ce7d595d2009029c2fe49ca987d74d1a0cbb743047cd46460382cbee61e7ac
getAsyncClient
public AsyncClient getAsyncClient(org.apache.thrift.transport.TNonblockingTransport transport)
{    return new AsyncClient(protocolFactory, clientManager, transport);}
cb97869e960e2f6ab63822d90e9ab266a89bf2eeeb28fdfc5b58e0fe05fb1a23
append
public void append(ThriftFlumeEvent event, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException
{    checkReady();    append_call method_call = new append_call(event, resultHandler, this, ___protocolFactory, ___transport);    this.___currentMethod = method_call;    ___manager.call(method_call);}
345dc223bb11c0c727744b96de56d5f0f1f3c374a491b829541ac5c66b1c1fe4
write_args
public void write_args(org.apache.thrift.protocol.TProtocol prot) throws org.apache.thrift.TException
{    prot.writeMessageBegin(new org.apache.thrift.protocol.TMessage("append", org.apache.thrift.protocol.TMessageType.CALL, 0));    append_args args = new append_args();    args.setEvent(event);    args.write(prot);    prot.writeMessageEnd();}
38e9151c019470681d9688da9025328f6300ebe1abdd1d6f60201e8c29d7813a
getResult
public Status getResult() throws org.apache.thrift.TException
{    if (getState() != org.apache.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {        throw new IllegalStateException("Method call not finished!");    }    org.apache.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());    org.apache.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);    return (new Client(prot)).recv_append();}
6f9d4216219088c49a5101ce816a8e7580eaf815515eb7d3ed7262b9d46f852a
appendBatch
public void appendBatch(List<ThriftFlumeEvent> events, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException
{    checkReady();    appendBatch_call method_call = new appendBatch_call(events, resultHandler, this, ___protocolFactory, ___transport);    this.___currentMethod = method_call;    ___manager.call(method_call);}
345dc223bb11c0c727744b96de56d5f0f1f3c374a491b829541ac5c66b1c1fe4
write_args
public void write_args(org.apache.thrift.protocol.TProtocol prot) throws org.apache.thrift.TException
{    prot.writeMessageBegin(new org.apache.thrift.protocol.TMessage("appendBatch", org.apache.thrift.protocol.TMessageType.CALL, 0));    appendBatch_args args = new appendBatch_args();    args.setEvents(events);    args.write(prot);    prot.writeMessageEnd();}
38e9151c019470681d9688da9025328f6300ebe1abdd1d6f60201e8c29d7813a
getResult
public Status getResult() throws org.apache.thrift.TException
{    if (getState() != org.apache.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {        throw new IllegalStateException("Method call not finished!");    }    org.apache.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());    org.apache.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);    return (new Client(prot)).recv_appendBatch();}
738d78d4660b6e44339a7f3c7826f5d36a27f149eba243598f194475b7236304
getProcessMap
private static Map<String, org.apache.thrift.ProcessFunction<I, ? extends org.apache.thrift.TBase>> getProcessMap(Map<String, org.apache.thrift.ProcessFunction<I, ? extends org.apache.thrift.TBase>> processMap)
{    processMap.put("append", new append());    processMap.put("appendBatch", new appendBatch());    return processMap;}
fab9ebfb6770036ca6071b38a442fa954ec29efcf210daee760abb23bcb51493
getEmptyArgsInstance
public append_args getEmptyArgsInstance()
{    return new append_args();}
bebf296c86daa8f23132c9bae180b870c6dd9b8ba06fba8cc6695c835567cc77
isOneway
protected boolean isOneway()
{    return false;}
bbc375564a6611a1d8a8e53b1839e9361d32fd7cee6f064062e1290039e7c16e
getResult
public append_result getResult(I iface, append_args args) throws org.apache.thrift.TException
{    append_result result = new append_result();    result.success = iface.append(args.event);    return result;}
00e6a0e3dde612d77dfbdffc03b77ad780c9f3307b8a66d3cfe8ad3786d83134
getEmptyArgsInstance
public appendBatch_args getEmptyArgsInstance()
{    return new appendBatch_args();}
bebf296c86daa8f23132c9bae180b870c6dd9b8ba06fba8cc6695c835567cc77
isOneway
protected boolean isOneway()
{    return false;}
574f54950ffa1ba562b722ee239029596b4e5d9e90d68965158adfcd2d0b606c
getResult
public appendBatch_result getResult(I iface, appendBatch_args args) throws org.apache.thrift.TException
{    appendBatch_result result = new appendBatch_result();    result.success = iface.appendBatch(args.events);    return result;}
0409c31db10aa18694f957fa32b798fbeb64358a429f845b92d5de9db93dd0c4
getProcessMap
private static Map<String, org.apache.thrift.AsyncProcessFunction<I, ? extends org.apache.thrift.TBase, ?>> getProcessMap(Map<String, org.apache.thrift.AsyncProcessFunction<I, ? extends org.apache.thrift.TBase, ?>> processMap)
{    processMap.put("append", new append());    processMap.put("appendBatch", new appendBatch());    return processMap;}
fab9ebfb6770036ca6071b38a442fa954ec29efcf210daee760abb23bcb51493
getEmptyArgsInstance
public append_args getEmptyArgsInstance()
{    return new append_args();}
08ff4ca611fc7bcfed52b87f87b9563641cd8777a75885d7278b755f1f1a766e
getResultHandler
public AsyncMethodCallback<Status> getResultHandler(final AsyncFrameBuffer fb, final int seqid)
{    final org.apache.thrift.AsyncProcessFunction fcall = this;    return new AsyncMethodCallback<Status>() {        public void onComplete(Status o) {            append_result result = new append_result();            result.success = o;            try {                fcall.sendResponse(fb, result, org.apache.thrift.protocol.TMessageType.REPLY, seqid);                return;            } catch (Exception e) {                LOGGER.error("Exception writing to internal frame buffer", e);            }            fb.close();        }        public void onError(Exception e) {            byte msgType = org.apache.thrift.protocol.TMessageType.REPLY;            org.apache.thrift.TBase msg;            append_result result = new append_result();            {                msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;                msg = (org.apache.thrift.TBase) new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());            }            try {                fcall.sendResponse(fb, msg, msgType, seqid);                return;            } catch (Exception ex) {                LOGGER.error("Exception writing to internal frame buffer", ex);            }            fb.close();        }    };}
fddbdaf601c2ea35cfda6c8c59d892b29ff427db2fc9e01e5e23913ef9065502
onComplete
public void onComplete(Status o)
{    append_result result = new append_result();    result.success = o;    try {        fcall.sendResponse(fb, result, org.apache.thrift.protocol.TMessageType.REPLY, seqid);        return;    } catch (Exception e) {        LOGGER.error("Exception writing to internal frame buffer", e);    }    fb.close();}
50d81b3017874db254d9688aef6f4422ecef15f2cd874858a2f0d6437f81587e
onError
public void onError(Exception e)
{    byte msgType = org.apache.thrift.protocol.TMessageType.REPLY;    org.apache.thrift.TBase msg;    append_result result = new append_result();    {        msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;        msg = (org.apache.thrift.TBase) new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());    }    try {        fcall.sendResponse(fb, msg, msgType, seqid);        return;    } catch (Exception ex) {        LOGGER.error("Exception writing to internal frame buffer", ex);    }    fb.close();}
bebf296c86daa8f23132c9bae180b870c6dd9b8ba06fba8cc6695c835567cc77
isOneway
protected boolean isOneway()
{    return false;}
f283878fde76142684721934b95b4ae9d549de12b1dc858db13f2b4331f2d7e7
start
public void start(I iface, append_args args, org.apache.thrift.async.AsyncMethodCallback<Status> resultHandler) throws TException
{    iface.append(args.event, resultHandler);}
00e6a0e3dde612d77dfbdffc03b77ad780c9f3307b8a66d3cfe8ad3786d83134
getEmptyArgsInstance
public appendBatch_args getEmptyArgsInstance()
{    return new appendBatch_args();}
08ff4ca611fc7bcfed52b87f87b9563641cd8777a75885d7278b755f1f1a766e
getResultHandler
public AsyncMethodCallback<Status> getResultHandler(final AsyncFrameBuffer fb, final int seqid)
{    final org.apache.thrift.AsyncProcessFunction fcall = this;    return new AsyncMethodCallback<Status>() {        public void onComplete(Status o) {            appendBatch_result result = new appendBatch_result();            result.success = o;            try {                fcall.sendResponse(fb, result, org.apache.thrift.protocol.TMessageType.REPLY, seqid);                return;            } catch (Exception e) {                LOGGER.error("Exception writing to internal frame buffer", e);            }            fb.close();        }        public void onError(Exception e) {            byte msgType = org.apache.thrift.protocol.TMessageType.REPLY;            org.apache.thrift.TBase msg;            appendBatch_result result = new appendBatch_result();            {                msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;                msg = (org.apache.thrift.TBase) new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());            }            try {                fcall.sendResponse(fb, msg, msgType, seqid);                return;            } catch (Exception ex) {                LOGGER.error("Exception writing to internal frame buffer", ex);            }            fb.close();        }    };}
fddbdaf601c2ea35cfda6c8c59d892b29ff427db2fc9e01e5e23913ef9065502
onComplete
public void onComplete(Status o)
{    appendBatch_result result = new appendBatch_result();    result.success = o;    try {        fcall.sendResponse(fb, result, org.apache.thrift.protocol.TMessageType.REPLY, seqid);        return;    } catch (Exception e) {        LOGGER.error("Exception writing to internal frame buffer", e);    }    fb.close();}
50d81b3017874db254d9688aef6f4422ecef15f2cd874858a2f0d6437f81587e
onError
public void onError(Exception e)
{    byte msgType = org.apache.thrift.protocol.TMessageType.REPLY;    org.apache.thrift.TBase msg;    appendBatch_result result = new appendBatch_result();    {        msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;        msg = (org.apache.thrift.TBase) new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());    }    try {        fcall.sendResponse(fb, msg, msgType, seqid);        return;    } catch (Exception ex) {        LOGGER.error("Exception writing to internal frame buffer", ex);    }    fb.close();}
bebf296c86daa8f23132c9bae180b870c6dd9b8ba06fba8cc6695c835567cc77
isOneway
protected boolean isOneway()
{    return false;}
899c1fa5322a4f89eeada4937a2558c6f83f4a27a4303efe8c52919714374d89
start
public void start(I iface, appendBatch_args args, org.apache.thrift.async.AsyncMethodCallback<Status> resultHandler) throws TException
{    iface.appendBatch(args.events, resultHandler);}
92e9e6589c16b4fde1efd2a77a414bb3a621362cc64c5ef5a21381d0e5b55b5f
findByThriftId
public static _Fields findByThriftId(int fieldId)
{    switch(fieldId) {        case         1:            return EVENT;        default:            return null;    }}
950148827ecab1253536a12003b5b2c41c2778a566a9ed4cb2487de641d6bde4
findByThriftIdOrThrow
public static _Fields findByThriftIdOrThrow(int fieldId)
{    _Fields fields = findByThriftId(fieldId);    if (fields == null)        throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");    return fields;}
eb44b9fdf7e05046f232aa9f1f3bb9a0cf815a486270439682862994e0d2c224
findByName
public static _Fields findByName(String name)
{    return byName.get(name);}
7f8fa4ecb4119b59b8047c285ac8f8729a909f121d1d3386d19ebfc6c04ab5df
getThriftFieldId
public short getThriftFieldId()
{    return _thriftId;}
68f4afd0e3cff42097dd5b6508fea1f7952d6d93f52ded3c1deea7186fff780c
getFieldName
public String getFieldName()
{    return _fieldName;}
6d0a02c9ac0e8bc12e6898bbb36fc312cdbb310d6f261b69ab890a1574872e1f
deepCopy
public append_args deepCopy()
{    return new append_args(this);}
21ac40bb9a99614b6ac18fa4043acb6173fccff96066fdfab963dba597923aa8
clear
public void clear()
{    this.event = null;}
8e42125443ac798507d972a7cf6f9d2b64e62e200f883e4ae6984c2e715594cf
getEvent
public ThriftFlumeEvent getEvent()
{    return this.event;}
b7c5a07bf9354fa34f8c817ec0fa927947205bdf3abb9ca1146b0ec329cb1476
setEvent
public append_args setEvent(ThriftFlumeEvent event)
{    this.event = event;    return this;}
8bd98c0d4dbb3ef64674d9f857b8f671c19f59a7e8d9f5a2e256561d5c898a2c
unsetEvent
public void unsetEvent()
{    this.event = null;}
61236857ea1ec9483a7a21bf2aa2f3cf84d6397c20c8d98e4c471354c2047589
isSetEvent
public boolean isSetEvent()
{    return this.event != null;}
f6c2273686880a263f54942c75607a58414d4125ea66c0d5fddda3f41110f965
setEventIsSet
public void setEventIsSet(boolean value)
{    if (!value) {        this.event = null;    }}
56898e9e8fffee777f79916bb0318d8a0a1794f171b373787ede8ccabb314f39
setFieldValue
public void setFieldValue(_Fields field, Object value)
{    switch(field) {        case EVENT:            if (value == null) {                unsetEvent();            } else {                setEvent((ThriftFlumeEvent) value);            }            break;    }}
464d81fc54c8c50a21a786b4dc4dd56822e73892271735c454cff15126bc2dfd
getFieldValue
public Object getFieldValue(_Fields field)
{    switch(field) {        case EVENT:            return getEvent();    }    throw new IllegalStateException();}
71ed64fc282e6b120c36448a4f95d0d8102f98c0455e5f84713743b2826d64c9
isSet
public boolean isSet(_Fields field)
{    if (field == null) {        throw new IllegalArgumentException();    }    switch(field) {        case EVENT:            return isSetEvent();    }    throw new IllegalStateException();}
6b3ab298cb5d88dbb2c510c786f53e377489a40e2716e63c26a3e1691765f6c5
equals
public boolean equals(Object that)
{    if (that == null)        return false;    if (that instanceof append_args)        return this.equals((append_args) that);    return false;}
97266308601aace3cf2b09520931eac4b2095685bd0fcf8b488cfa656b03ee43
equals
public boolean equals(append_args that)
{    if (that == null)        return false;    boolean this_present_event = true && this.isSetEvent();    boolean that_present_event = true && that.isSetEvent();    if (this_present_event || that_present_event) {        if (!(this_present_event && that_present_event))            return false;        if (!this.event.equals(that.event))            return false;    }    return true;}
0ac42bf5188762fc1283b5cbd2b3bb1031e80963813b3b310b15c3fb47050003
hashCode
public int hashCode()
{    List<Object> list = new ArrayList<Object>();    boolean present_event = true && (isSetEvent());    list.add(present_event);    if (present_event)        list.add(event);    return list.hashCode();}
ec875de4680f4aa36cd6613be149d55c231417712e308042d5f5de1d3948f9ab
compareTo
public int compareTo(append_args other)
{    if (!getClass().equals(other.getClass())) {        return getClass().getName().compareTo(other.getClass().getName());    }    int lastComparison = 0;    lastComparison = Boolean.valueOf(isSetEvent()).compareTo(other.isSetEvent());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetEvent()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.event, other.event);        if (lastComparison != 0) {            return lastComparison;        }    }    return 0;}
8ce4cec748163fe422fba58a0ef1f5936a95d5ce0ec9e530aab7c5a59149b857
fieldForId
public _Fields fieldForId(int fieldId)
{    return _Fields.findByThriftId(fieldId);}
9c387dbc68e2929966a2f4d7377de396c1c24932dd7e709eba5cf9e1c90787af
read
public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException
{    schemes.get(iprot.getScheme()).getScheme().read(iprot, this);}
72f9005ef45238c38f6c8b9506f41c8599609ccde331e03c7044ee080e1472da
write
public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException
{    schemes.get(oprot.getScheme()).getScheme().write(oprot, this);}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    StringBuilder sb = new StringBuilder("append_args(");    boolean first = true;    sb.append("event:");    if (this.event == null) {        sb.append("null");    } else {        sb.append(this.event);    }    first = false;    sb.append(")");    return sb.toString();}
e9a9838299550df368382cb18b6693a9d80b274b5c7bc089afc33713eceefbe1
validate
public void validate() throws org.apache.thrift.TException
{        if (event != null) {        event.validate();    }}
784e52bd99c637d4fd80e90272ace2edbc622a5a5ac2a515ab45f6d177fc378a
writeObject
private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException
{    try {        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
a2d949a3bc49af9f8b746197cee0585da9e196149570b4a376f3635b857a1744
readObject
private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException
{    try {        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
cf55bcfadc08d0298e097cf56dde2d351352c4520cf5229b97d3b872a143d18e
getScheme
public append_argsStandardScheme getScheme()
{    return new append_argsStandardScheme();}
ec50a00bb34dd4840c0420213fcd759eeb9f8014b58127ce5a962e727042102e
read
public void read(org.apache.thrift.protocol.TProtocol iprot, append_args struct) throws org.apache.thrift.TException
{    org.apache.thrift.protocol.TField schemeField;    iprot.readStructBegin();    while (true) {        schemeField = iprot.readFieldBegin();        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) {            break;        }        switch(schemeField.id) {            case             1:                if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {                    struct.event = new ThriftFlumeEvent();                    struct.event.read(iprot);                    struct.setEventIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            default:                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);        }        iprot.readFieldEnd();    }    iprot.readStructEnd();        struct.validate();}
97a099fc0cd3bf3d170ef7fe529cb1111abba0a7f133025cf4c19ac57fd3cef3
write
public void write(org.apache.thrift.protocol.TProtocol oprot, append_args struct) throws org.apache.thrift.TException
{    struct.validate();    oprot.writeStructBegin(STRUCT_DESC);    if (struct.event != null) {        oprot.writeFieldBegin(EVENT_FIELD_DESC);        struct.event.write(oprot);        oprot.writeFieldEnd();    }    oprot.writeFieldStop();    oprot.writeStructEnd();}
1dba376b5814fd505e392c45331af8c147a696f83c2371ba7a532566f093d80a
getScheme
public append_argsTupleScheme getScheme()
{    return new append_argsTupleScheme();}
f0adfbd44086ddc7bacfc531ecb21e95d8aa270e862f1314ed49d82f6011dd54
write
public void write(org.apache.thrift.protocol.TProtocol prot, append_args struct) throws org.apache.thrift.TException
{    TTupleProtocol oprot = (TTupleProtocol) prot;    BitSet optionals = new BitSet();    if (struct.isSetEvent()) {        optionals.set(0);    }    oprot.writeBitSet(optionals, 1);    if (struct.isSetEvent()) {        struct.event.write(oprot);    }}
039b331f172ef46048ca41f5a01d69ed9339739a434d3571233be825ee7820ab
read
public void read(org.apache.thrift.protocol.TProtocol prot, append_args struct) throws org.apache.thrift.TException
{    TTupleProtocol iprot = (TTupleProtocol) prot;    BitSet incoming = iprot.readBitSet(1);    if (incoming.get(0)) {        struct.event = new ThriftFlumeEvent();        struct.event.read(iprot);        struct.setEventIsSet(true);    }}
92e9e6589c16b4fde1efd2a77a414bb3a621362cc64c5ef5a21381d0e5b55b5f
findByThriftId
public static _Fields findByThriftId(int fieldId)
{    switch(fieldId) {        case         0:            return SUCCESS;        default:            return null;    }}
950148827ecab1253536a12003b5b2c41c2778a566a9ed4cb2487de641d6bde4
findByThriftIdOrThrow
public static _Fields findByThriftIdOrThrow(int fieldId)
{    _Fields fields = findByThriftId(fieldId);    if (fields == null)        throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");    return fields;}
eb44b9fdf7e05046f232aa9f1f3bb9a0cf815a486270439682862994e0d2c224
findByName
public static _Fields findByName(String name)
{    return byName.get(name);}
7f8fa4ecb4119b59b8047c285ac8f8729a909f121d1d3386d19ebfc6c04ab5df
getThriftFieldId
public short getThriftFieldId()
{    return _thriftId;}
68f4afd0e3cff42097dd5b6508fea1f7952d6d93f52ded3c1deea7186fff780c
getFieldName
public String getFieldName()
{    return _fieldName;}
6defb2e5fdf76f0612ca91d93d88fa1b3fae137abc608c7f97693953ea216e80
deepCopy
public append_result deepCopy()
{    return new append_result(this);}
21ac40bb9a99614b6ac18fa4043acb6173fccff96066fdfab963dba597923aa8
clear
public void clear()
{    this.success = null;}
d50c9b06b2377a1256c116ce2b90c030c954d248ac07d70567ec15f69cff8215
getSuccess
public Status getSuccess()
{    return this.success;}
cbc8cc7355c9c3c7af837f165718a49a998b8d14807f13bd4e15c893c5b4003c
setSuccess
public append_result setSuccess(Status success)
{    this.success = success;    return this;}
b11d50af86567118806a3c839311a4bbc691cc019f2b233dae1d90d66ba25d35
unsetSuccess
public void unsetSuccess()
{    this.success = null;}
94737a429af3ca2ae08f628bc393ecee61310b6ae56ecb9e65d11a0d4edf2fb9
isSetSuccess
public boolean isSetSuccess()
{    return this.success != null;}
ade9d0378b151827122f3a20ecdf75cbb0fad960c542ca429237092ddfa5078b
setSuccessIsSet
public void setSuccessIsSet(boolean value)
{    if (!value) {        this.success = null;    }}
56898e9e8fffee777f79916bb0318d8a0a1794f171b373787ede8ccabb314f39
setFieldValue
public void setFieldValue(_Fields field, Object value)
{    switch(field) {        case SUCCESS:            if (value == null) {                unsetSuccess();            } else {                setSuccess((Status) value);            }            break;    }}
464d81fc54c8c50a21a786b4dc4dd56822e73892271735c454cff15126bc2dfd
getFieldValue
public Object getFieldValue(_Fields field)
{    switch(field) {        case SUCCESS:            return getSuccess();    }    throw new IllegalStateException();}
71ed64fc282e6b120c36448a4f95d0d8102f98c0455e5f84713743b2826d64c9
isSet
public boolean isSet(_Fields field)
{    if (field == null) {        throw new IllegalArgumentException();    }    switch(field) {        case SUCCESS:            return isSetSuccess();    }    throw new IllegalStateException();}
6b3ab298cb5d88dbb2c510c786f53e377489a40e2716e63c26a3e1691765f6c5
equals
public boolean equals(Object that)
{    if (that == null)        return false;    if (that instanceof append_result)        return this.equals((append_result) that);    return false;}
3904c4541dfcd25da1dad8d4a20773b10e095db809f40ca893cef5a186f3fbe2
equals
public boolean equals(append_result that)
{    if (that == null)        return false;    boolean this_present_success = true && this.isSetSuccess();    boolean that_present_success = true && that.isSetSuccess();    if (this_present_success || that_present_success) {        if (!(this_present_success && that_present_success))            return false;        if (!this.success.equals(that.success))            return false;    }    return true;}
0ac42bf5188762fc1283b5cbd2b3bb1031e80963813b3b310b15c3fb47050003
hashCode
public int hashCode()
{    List<Object> list = new ArrayList<Object>();    boolean present_success = true && (isSetSuccess());    list.add(present_success);    if (present_success)        list.add(success.getValue());    return list.hashCode();}
1dd3d601e5b7293718df4eb619edf2db9e8786e9d9e3143752ea914deb5ddd6a
compareTo
public int compareTo(append_result other)
{    if (!getClass().equals(other.getClass())) {        return getClass().getName().compareTo(other.getClass().getName());    }    int lastComparison = 0;    lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(other.isSetSuccess());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetSuccess()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.success, other.success);        if (lastComparison != 0) {            return lastComparison;        }    }    return 0;}
8ce4cec748163fe422fba58a0ef1f5936a95d5ce0ec9e530aab7c5a59149b857
fieldForId
public _Fields fieldForId(int fieldId)
{    return _Fields.findByThriftId(fieldId);}
9c387dbc68e2929966a2f4d7377de396c1c24932dd7e709eba5cf9e1c90787af
read
public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException
{    schemes.get(iprot.getScheme()).getScheme().read(iprot, this);}
72f9005ef45238c38f6c8b9506f41c8599609ccde331e03c7044ee080e1472da
write
public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException
{    schemes.get(oprot.getScheme()).getScheme().write(oprot, this);}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    StringBuilder sb = new StringBuilder("append_result(");    boolean first = true;    sb.append("success:");    if (this.success == null) {        sb.append("null");    } else {        sb.append(this.success);    }    first = false;    sb.append(")");    return sb.toString();}
e9a9838299550df368382cb18b6693a9d80b274b5c7bc089afc33713eceefbe1
validate
public void validate() throws org.apache.thrift.TException
{}
784e52bd99c637d4fd80e90272ace2edbc622a5a5ac2a515ab45f6d177fc378a
writeObject
private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException
{    try {        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
a2d949a3bc49af9f8b746197cee0585da9e196149570b4a376f3635b857a1744
readObject
private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException
{    try {        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
9eeda82b345d11c6bf1ffe61f3642ad0fc97b31f05bce86452dc150991174946
getScheme
public append_resultStandardScheme getScheme()
{    return new append_resultStandardScheme();}
8d25ffa944891a2e2307fb7a789821dc5c92e472b07af9d9cc84402286b4579f
read
public void read(org.apache.thrift.protocol.TProtocol iprot, append_result struct) throws org.apache.thrift.TException
{    org.apache.thrift.protocol.TField schemeField;    iprot.readStructBegin();    while (true) {        schemeField = iprot.readFieldBegin();        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) {            break;        }        switch(schemeField.id) {            case             0:                if (schemeField.type == org.apache.thrift.protocol.TType.I32) {                    struct.success = org.apache.flume.thrift.Status.findByValue(iprot.readI32());                    struct.setSuccessIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            default:                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);        }        iprot.readFieldEnd();    }    iprot.readStructEnd();        struct.validate();}
4615c00bb52db3560dcee7d315c5044e509048b775015f1c1fcf1a45300ec6a0
write
public void write(org.apache.thrift.protocol.TProtocol oprot, append_result struct) throws org.apache.thrift.TException
{    struct.validate();    oprot.writeStructBegin(STRUCT_DESC);    if (struct.success != null) {        oprot.writeFieldBegin(SUCCESS_FIELD_DESC);        oprot.writeI32(struct.success.getValue());        oprot.writeFieldEnd();    }    oprot.writeFieldStop();    oprot.writeStructEnd();}
4b945d0491310bfd866bd03df5f7467b1ce32d16b150250d7c076a97547fd9ba
getScheme
public append_resultTupleScheme getScheme()
{    return new append_resultTupleScheme();}
135426de192aa329dd85eb50ca4ed37b15f16d47da9f8dfc94bb842f414eca89
write
public void write(org.apache.thrift.protocol.TProtocol prot, append_result struct) throws org.apache.thrift.TException
{    TTupleProtocol oprot = (TTupleProtocol) prot;    BitSet optionals = new BitSet();    if (struct.isSetSuccess()) {        optionals.set(0);    }    oprot.writeBitSet(optionals, 1);    if (struct.isSetSuccess()) {        oprot.writeI32(struct.success.getValue());    }}
0647070215f0472445bc0f3aed25831a5eca5c9e039dafbec7e89cd877956592
read
public void read(org.apache.thrift.protocol.TProtocol prot, append_result struct) throws org.apache.thrift.TException
{    TTupleProtocol iprot = (TTupleProtocol) prot;    BitSet incoming = iprot.readBitSet(1);    if (incoming.get(0)) {        struct.success = org.apache.flume.thrift.Status.findByValue(iprot.readI32());        struct.setSuccessIsSet(true);    }}
92e9e6589c16b4fde1efd2a77a414bb3a621362cc64c5ef5a21381d0e5b55b5f
findByThriftId
public static _Fields findByThriftId(int fieldId)
{    switch(fieldId) {        case         1:            return EVENTS;        default:            return null;    }}
950148827ecab1253536a12003b5b2c41c2778a566a9ed4cb2487de641d6bde4
findByThriftIdOrThrow
public static _Fields findByThriftIdOrThrow(int fieldId)
{    _Fields fields = findByThriftId(fieldId);    if (fields == null)        throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");    return fields;}
eb44b9fdf7e05046f232aa9f1f3bb9a0cf815a486270439682862994e0d2c224
findByName
public static _Fields findByName(String name)
{    return byName.get(name);}
7f8fa4ecb4119b59b8047c285ac8f8729a909f121d1d3386d19ebfc6c04ab5df
getThriftFieldId
public short getThriftFieldId()
{    return _thriftId;}
68f4afd0e3cff42097dd5b6508fea1f7952d6d93f52ded3c1deea7186fff780c
getFieldName
public String getFieldName()
{    return _fieldName;}
5a9a8562ff5bb95cab5051f3ff988fd18a0d4d8eb19c20ef5516068253765151
deepCopy
public appendBatch_args deepCopy()
{    return new appendBatch_args(this);}
21ac40bb9a99614b6ac18fa4043acb6173fccff96066fdfab963dba597923aa8
clear
public void clear()
{    this.events = null;}
65b4e435ff9de98179e0132dcffc4755c00704fc22d76e07152450a792f065e1
getEventsSize
public int getEventsSize()
{    return (this.events == null) ? 0 : this.events.size();}
ffb76f248f6e04e3ff39849e17ec5d9a718c29c9c607f95d43cf46a82350692a
getEventsIterator
public java.util.Iterator<ThriftFlumeEvent> getEventsIterator()
{    return (this.events == null) ? null : this.events.iterator();}
a4136db87271d61e287433dc8824e0e900b5e9e3bdb5e57ae422d3bf2ff9d2c2
addToEvents
public void addToEvents(ThriftFlumeEvent elem)
{    if (this.events == null) {        this.events = new ArrayList<ThriftFlumeEvent>();    }    this.events.add(elem);}
e9912b2082a71946bafc444ebb748db0f3c77fcb2117bbe2c5a1e0c436286b66
getEvents
public List<ThriftFlumeEvent> getEvents()
{    return this.events;}
0bf9b39fb47925f404f37eba207bba00c75fd964575784908377c4c603cfb5f1
setEvents
public appendBatch_args setEvents(List<ThriftFlumeEvent> events)
{    this.events = events;    return this;}
414519c71862018c1ddc417b3b5ceeee7ff0fae20b0b5b35a7b166a3b3ded8d8
unsetEvents
public void unsetEvents()
{    this.events = null;}
a4e4fd5e9f92a713c83338204e3f1f9c1109b5564b120903334df24edf253176
isSetEvents
public boolean isSetEvents()
{    return this.events != null;}
47d526bc721b02cb36d3fcaf35d52684de924eaf305a0090e446d978bbedb0f6
setEventsIsSet
public void setEventsIsSet(boolean value)
{    if (!value) {        this.events = null;    }}
56898e9e8fffee777f79916bb0318d8a0a1794f171b373787ede8ccabb314f39
setFieldValue
public void setFieldValue(_Fields field, Object value)
{    switch(field) {        case EVENTS:            if (value == null) {                unsetEvents();            } else {                setEvents((List<ThriftFlumeEvent>) value);            }            break;    }}
464d81fc54c8c50a21a786b4dc4dd56822e73892271735c454cff15126bc2dfd
getFieldValue
public Object getFieldValue(_Fields field)
{    switch(field) {        case EVENTS:            return getEvents();    }    throw new IllegalStateException();}
71ed64fc282e6b120c36448a4f95d0d8102f98c0455e5f84713743b2826d64c9
isSet
public boolean isSet(_Fields field)
{    if (field == null) {        throw new IllegalArgumentException();    }    switch(field) {        case EVENTS:            return isSetEvents();    }    throw new IllegalStateException();}
6b3ab298cb5d88dbb2c510c786f53e377489a40e2716e63c26a3e1691765f6c5
equals
public boolean equals(Object that)
{    if (that == null)        return false;    if (that instanceof appendBatch_args)        return this.equals((appendBatch_args) that);    return false;}
e0075c6a01425665eeb6c1b4231e07dad26ac119f4967e35bc69bfd864847caa
equals
public boolean equals(appendBatch_args that)
{    if (that == null)        return false;    boolean this_present_events = true && this.isSetEvents();    boolean that_present_events = true && that.isSetEvents();    if (this_present_events || that_present_events) {        if (!(this_present_events && that_present_events))            return false;        if (!this.events.equals(that.events))            return false;    }    return true;}
0ac42bf5188762fc1283b5cbd2b3bb1031e80963813b3b310b15c3fb47050003
hashCode
public int hashCode()
{    List<Object> list = new ArrayList<Object>();    boolean present_events = true && (isSetEvents());    list.add(present_events);    if (present_events)        list.add(events);    return list.hashCode();}
9fdf54f70a17a871f4dc2bb93fac2a732eb8db3edb4e789673e048d3c07f124a
compareTo
public int compareTo(appendBatch_args other)
{    if (!getClass().equals(other.getClass())) {        return getClass().getName().compareTo(other.getClass().getName());    }    int lastComparison = 0;    lastComparison = Boolean.valueOf(isSetEvents()).compareTo(other.isSetEvents());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetEvents()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.events, other.events);        if (lastComparison != 0) {            return lastComparison;        }    }    return 0;}
8ce4cec748163fe422fba58a0ef1f5936a95d5ce0ec9e530aab7c5a59149b857
fieldForId
public _Fields fieldForId(int fieldId)
{    return _Fields.findByThriftId(fieldId);}
9c387dbc68e2929966a2f4d7377de396c1c24932dd7e709eba5cf9e1c90787af
read
public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException
{    schemes.get(iprot.getScheme()).getScheme().read(iprot, this);}
72f9005ef45238c38f6c8b9506f41c8599609ccde331e03c7044ee080e1472da
write
public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException
{    schemes.get(oprot.getScheme()).getScheme().write(oprot, this);}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    StringBuilder sb = new StringBuilder("appendBatch_args(");    boolean first = true;    sb.append("events:");    if (this.events == null) {        sb.append("null");    } else {        sb.append(this.events);    }    first = false;    sb.append(")");    return sb.toString();}
e9a9838299550df368382cb18b6693a9d80b274b5c7bc089afc33713eceefbe1
validate
public void validate() throws org.apache.thrift.TException
{}
784e52bd99c637d4fd80e90272ace2edbc622a5a5ac2a515ab45f6d177fc378a
writeObject
private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException
{    try {        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
a2d949a3bc49af9f8b746197cee0585da9e196149570b4a376f3635b857a1744
readObject
private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException
{    try {        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
60d207924ddabdb35aa92a1cb73ee79722fd163e1066f068c1143f3005c31b61
getScheme
public appendBatch_argsStandardScheme getScheme()
{    return new appendBatch_argsStandardScheme();}
f69e24bd6a16aa64f3adf01fc117ba4d6d450d0e359d48d58876b6b98d90a721
read
public void read(org.apache.thrift.protocol.TProtocol iprot, appendBatch_args struct) throws org.apache.thrift.TException
{    org.apache.thrift.protocol.TField schemeField;    iprot.readStructBegin();    while (true) {        schemeField = iprot.readFieldBegin();        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) {            break;        }        switch(schemeField.id) {            case             1:                if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {                    {                        org.apache.thrift.protocol.TList _list10 = iprot.readListBegin();                        struct.events = new ArrayList<ThriftFlumeEvent>(_list10.size);                        ThriftFlumeEvent _elem11;                        for (int _i12 = 0; _i12 < _list10.size; ++_i12) {                            _elem11 = new ThriftFlumeEvent();                            _elem11.read(iprot);                            struct.events.add(_elem11);                        }                        iprot.readListEnd();                    }                    struct.setEventsIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            default:                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);        }        iprot.readFieldEnd();    }    iprot.readStructEnd();        struct.validate();}
1387550635c7c170c465a652280ab2ae7341addd2d735709a071b69ce4f7ba37
write
public void write(org.apache.thrift.protocol.TProtocol oprot, appendBatch_args struct) throws org.apache.thrift.TException
{    struct.validate();    oprot.writeStructBegin(STRUCT_DESC);    if (struct.events != null) {        oprot.writeFieldBegin(EVENTS_FIELD_DESC);        {            oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, struct.events.size()));            for (ThriftFlumeEvent _iter13 : struct.events) {                _iter13.write(oprot);            }            oprot.writeListEnd();        }        oprot.writeFieldEnd();    }    oprot.writeFieldStop();    oprot.writeStructEnd();}
f173884af68d18159d06ca27e20c7867a604cced0667da72525ee4b0b8d5a75a
getScheme
public appendBatch_argsTupleScheme getScheme()
{    return new appendBatch_argsTupleScheme();}
042a1f06039cf63f966a403b0e4b339900b3c48fe5bbf9496869276bcede12fb
write
public void write(org.apache.thrift.protocol.TProtocol prot, appendBatch_args struct) throws org.apache.thrift.TException
{    TTupleProtocol oprot = (TTupleProtocol) prot;    BitSet optionals = new BitSet();    if (struct.isSetEvents()) {        optionals.set(0);    }    oprot.writeBitSet(optionals, 1);    if (struct.isSetEvents()) {        {            oprot.writeI32(struct.events.size());            for (ThriftFlumeEvent _iter14 : struct.events) {                _iter14.write(oprot);            }        }    }}
13a09da5b9e0c07fbc088735b01dcb44e2fb8311d5d7d1cd86a0eb04612d8fa5
read
public void read(org.apache.thrift.protocol.TProtocol prot, appendBatch_args struct) throws org.apache.thrift.TException
{    TTupleProtocol iprot = (TTupleProtocol) prot;    BitSet incoming = iprot.readBitSet(1);    if (incoming.get(0)) {        {            org.apache.thrift.protocol.TList _list15 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());            struct.events = new ArrayList<ThriftFlumeEvent>(_list15.size);            ThriftFlumeEvent _elem16;            for (int _i17 = 0; _i17 < _list15.size; ++_i17) {                _elem16 = new ThriftFlumeEvent();                _elem16.read(iprot);                struct.events.add(_elem16);            }        }        struct.setEventsIsSet(true);    }}
92e9e6589c16b4fde1efd2a77a414bb3a621362cc64c5ef5a21381d0e5b55b5f
findByThriftId
public static _Fields findByThriftId(int fieldId)
{    switch(fieldId) {        case         0:            return SUCCESS;        default:            return null;    }}
950148827ecab1253536a12003b5b2c41c2778a566a9ed4cb2487de641d6bde4
findByThriftIdOrThrow
public static _Fields findByThriftIdOrThrow(int fieldId)
{    _Fields fields = findByThriftId(fieldId);    if (fields == null)        throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");    return fields;}
eb44b9fdf7e05046f232aa9f1f3bb9a0cf815a486270439682862994e0d2c224
findByName
public static _Fields findByName(String name)
{    return byName.get(name);}
7f8fa4ecb4119b59b8047c285ac8f8729a909f121d1d3386d19ebfc6c04ab5df
getThriftFieldId
public short getThriftFieldId()
{    return _thriftId;}
68f4afd0e3cff42097dd5b6508fea1f7952d6d93f52ded3c1deea7186fff780c
getFieldName
public String getFieldName()
{    return _fieldName;}
580a941e80195c267e7ae2fe6b639c5d8c01a6d044cd117764eb344b75fed3d7
deepCopy
public appendBatch_result deepCopy()
{    return new appendBatch_result(this);}
21ac40bb9a99614b6ac18fa4043acb6173fccff96066fdfab963dba597923aa8
clear
public void clear()
{    this.success = null;}
d50c9b06b2377a1256c116ce2b90c030c954d248ac07d70567ec15f69cff8215
getSuccess
public Status getSuccess()
{    return this.success;}
73c5129f2f5a34a5091d4ea36a7964fd6ff7bd58e866d1620e3a3e11dfe46f74
setSuccess
public appendBatch_result setSuccess(Status success)
{    this.success = success;    return this;}
b11d50af86567118806a3c839311a4bbc691cc019f2b233dae1d90d66ba25d35
unsetSuccess
public void unsetSuccess()
{    this.success = null;}
94737a429af3ca2ae08f628bc393ecee61310b6ae56ecb9e65d11a0d4edf2fb9
isSetSuccess
public boolean isSetSuccess()
{    return this.success != null;}
ade9d0378b151827122f3a20ecdf75cbb0fad960c542ca429237092ddfa5078b
setSuccessIsSet
public void setSuccessIsSet(boolean value)
{    if (!value) {        this.success = null;    }}
56898e9e8fffee777f79916bb0318d8a0a1794f171b373787ede8ccabb314f39
setFieldValue
public void setFieldValue(_Fields field, Object value)
{    switch(field) {        case SUCCESS:            if (value == null) {                unsetSuccess();            } else {                setSuccess((Status) value);            }            break;    }}
464d81fc54c8c50a21a786b4dc4dd56822e73892271735c454cff15126bc2dfd
getFieldValue
public Object getFieldValue(_Fields field)
{    switch(field) {        case SUCCESS:            return getSuccess();    }    throw new IllegalStateException();}
71ed64fc282e6b120c36448a4f95d0d8102f98c0455e5f84713743b2826d64c9
isSet
public boolean isSet(_Fields field)
{    if (field == null) {        throw new IllegalArgumentException();    }    switch(field) {        case SUCCESS:            return isSetSuccess();    }    throw new IllegalStateException();}
6b3ab298cb5d88dbb2c510c786f53e377489a40e2716e63c26a3e1691765f6c5
equals
public boolean equals(Object that)
{    if (that == null)        return false;    if (that instanceof appendBatch_result)        return this.equals((appendBatch_result) that);    return false;}
cfb42e3313b2782bf9e45b128a8d62633145a1d4dfe5c3be15919f6dcdb24fd1
equals
public boolean equals(appendBatch_result that)
{    if (that == null)        return false;    boolean this_present_success = true && this.isSetSuccess();    boolean that_present_success = true && that.isSetSuccess();    if (this_present_success || that_present_success) {        if (!(this_present_success && that_present_success))            return false;        if (!this.success.equals(that.success))            return false;    }    return true;}
0ac42bf5188762fc1283b5cbd2b3bb1031e80963813b3b310b15c3fb47050003
hashCode
public int hashCode()
{    List<Object> list = new ArrayList<Object>();    boolean present_success = true && (isSetSuccess());    list.add(present_success);    if (present_success)        list.add(success.getValue());    return list.hashCode();}
11c238a76f0bc51376e2b0739a84cc4a134a72cd0525ba24ee223e58dc927082
compareTo
public int compareTo(appendBatch_result other)
{    if (!getClass().equals(other.getClass())) {        return getClass().getName().compareTo(other.getClass().getName());    }    int lastComparison = 0;    lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(other.isSetSuccess());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetSuccess()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.success, other.success);        if (lastComparison != 0) {            return lastComparison;        }    }    return 0;}
8ce4cec748163fe422fba58a0ef1f5936a95d5ce0ec9e530aab7c5a59149b857
fieldForId
public _Fields fieldForId(int fieldId)
{    return _Fields.findByThriftId(fieldId);}
9c387dbc68e2929966a2f4d7377de396c1c24932dd7e709eba5cf9e1c90787af
read
public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException
{    schemes.get(iprot.getScheme()).getScheme().read(iprot, this);}
72f9005ef45238c38f6c8b9506f41c8599609ccde331e03c7044ee080e1472da
write
public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException
{    schemes.get(oprot.getScheme()).getScheme().write(oprot, this);}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    StringBuilder sb = new StringBuilder("appendBatch_result(");    boolean first = true;    sb.append("success:");    if (this.success == null) {        sb.append("null");    } else {        sb.append(this.success);    }    first = false;    sb.append(")");    return sb.toString();}
e9a9838299550df368382cb18b6693a9d80b274b5c7bc089afc33713eceefbe1
validate
public void validate() throws org.apache.thrift.TException
{}
784e52bd99c637d4fd80e90272ace2edbc622a5a5ac2a515ab45f6d177fc378a
writeObject
private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException
{    try {        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
a2d949a3bc49af9f8b746197cee0585da9e196149570b4a376f3635b857a1744
readObject
private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException
{    try {        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
8549f3c94fbc342a1af708ef907e0323bebf115cc35fab582fe713ead27e5478
getScheme
public appendBatch_resultStandardScheme getScheme()
{    return new appendBatch_resultStandardScheme();}
ffc60ad8c7e59fa84fe7fc0fa8bf15ba5b605123b1c54e36a7c0ff1da41bbae6
read
public void read(org.apache.thrift.protocol.TProtocol iprot, appendBatch_result struct) throws org.apache.thrift.TException
{    org.apache.thrift.protocol.TField schemeField;    iprot.readStructBegin();    while (true) {        schemeField = iprot.readFieldBegin();        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) {            break;        }        switch(schemeField.id) {            case             0:                if (schemeField.type == org.apache.thrift.protocol.TType.I32) {                    struct.success = org.apache.flume.thrift.Status.findByValue(iprot.readI32());                    struct.setSuccessIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            default:                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);        }        iprot.readFieldEnd();    }    iprot.readStructEnd();        struct.validate();}
82f4a91345928a241e1d370f0823181233dff9f4f7e859dbbf7747d455816307
write
public void write(org.apache.thrift.protocol.TProtocol oprot, appendBatch_result struct) throws org.apache.thrift.TException
{    struct.validate();    oprot.writeStructBegin(STRUCT_DESC);    if (struct.success != null) {        oprot.writeFieldBegin(SUCCESS_FIELD_DESC);        oprot.writeI32(struct.success.getValue());        oprot.writeFieldEnd();    }    oprot.writeFieldStop();    oprot.writeStructEnd();}
e1abcb2ef7aa4893c2eb17e4500077a0ea9f256dd8978c68bf946d6090da3c47
getScheme
public appendBatch_resultTupleScheme getScheme()
{    return new appendBatch_resultTupleScheme();}
ee4d22391ed401b6ef63163f10b94da08975191daf16eb35e11f0a0018eec4a4
write
public void write(org.apache.thrift.protocol.TProtocol prot, appendBatch_result struct) throws org.apache.thrift.TException
{    TTupleProtocol oprot = (TTupleProtocol) prot;    BitSet optionals = new BitSet();    if (struct.isSetSuccess()) {        optionals.set(0);    }    oprot.writeBitSet(optionals, 1);    if (struct.isSetSuccess()) {        oprot.writeI32(struct.success.getValue());    }}
ac3d84d86fb7b4457d986445845d861c8fe09ede9ff2fdc8c39788105bdb7a1f
read
public void read(org.apache.thrift.protocol.TProtocol prot, appendBatch_result struct) throws org.apache.thrift.TException
{    TTupleProtocol iprot = (TTupleProtocol) prot;    BitSet incoming = iprot.readBitSet(1);    if (incoming.get(0)) {        struct.success = org.apache.flume.thrift.Status.findByValue(iprot.readI32());        struct.setSuccessIsSet(true);    }}
a983052c86023ea278d328948e7e28909621cfe73a86b56c94d0d53dfa111821
setObjects
public void setObjects(List<T> objects)
{    for (T sink : objects) {        FailureState state = new FailureState();        stateMap.put(sink, state);    }}
c6aa69d42f92e9bce10fa308156df7cf939ae33ac1473f7ede5b30133155ac68
getObjects
public List<T> getObjects()
{    return new ArrayList<T>(stateMap.keySet());}
0b6c1a198a2f26a2cccd4831c13d50e3d9884e104f78445d319431907c302bd6
informFailure
public void informFailure(T failedObject)
{        if (!shouldBackOff) {        return;    }    FailureState state = stateMap.get(failedObject);    long now = System.currentTimeMillis();    long delta = now - state.lastFail;    /*     * When do we increase the backoff period?     * We basically calculate the time difference between the last failure     * and the current one. If this failure happened within one hour of the     * last backoff period getting over, then we increase the timeout,     * since the object did not recover yet. Else we assume this is a fresh     * failure and reset the count.     */    long lastBackoffLength = Math.min(maxTimeout, 1000 * (1 << state.sequentialFails));    long allowableDiff = lastBackoffLength + CONSIDER_SEQUENTIAL_RANGE;    if (allowableDiff > delta) {        if (state.sequentialFails < EXP_BACKOFF_COUNTER_LIMIT) {            state.sequentialFails++;        }    } else {        state.sequentialFails = 1;    }    state.lastFail = now;                state.restoreTime = now + Math.min(maxTimeout, 1000 * (1 << state.sequentialFails));}
bfe424746d4c60f70d68149fd181c5a945c5c97936e3770b9c36869bd68941d0
getIndexList
protected List<Integer> getIndexList()
{    long now = System.currentTimeMillis();    List<Integer> indexList = new ArrayList<Integer>();    int i = 0;    for (T obj : stateMap.keySet()) {        if (!isShouldBackOff() || stateMap.get(obj).restoreTime < now) {            indexList.add(i);        }        i++;    }    return indexList;}
10cb53569990ea6ce271552742b62fc0a29037c6d665978b2572705b32ef320b
isShouldBackOff
public boolean isShouldBackOff()
{    return shouldBackOff;}
3e6d87f3caa6512a9b465cbc047de0202b9bf02ac86371ce687b825e4976f598
setMaxTimeOut
public void setMaxTimeOut(long timeout)
{    this.maxTimeout = timeout;}
7a97cce13511a515d74563823a709dcea0886985b0754506958b844818a963e9
getMaxTimeOut
public long getMaxTimeOut()
{    return this.maxTimeout;}
b9d98a838f9e4de91c7265a854726006dcc619cc08d3eb3724fd396d44a87dba
createIterator
public synchronized Iterator<T> createIterator()
{    List<Integer> indexList = getIndexList();    int size = indexList.size();    int[] indexOrder = new int[size];    while (indexList.size() != 1) {        int pick = random.nextInt(indexList.size());        indexOrder[indexList.size() - 1] = indexList.remove(pick);    }    indexOrder[0] = indexList.get(0);    return new SpecificOrderIterator<T>(indexOrder, getObjects());}
2698686884a34becad0663adcbf9f6da24482745ded2e7e371deea86d52d1371
createIterator
public Iterator<T> createIterator()
{    List<Integer> activeIndices = getIndexList();    int size = activeIndices.size();        if (nextHead >= size) {        nextHead = 0;    }    int begin = nextHead++;    if (nextHead == activeIndices.size()) {        nextHead = 0;    }    int[] indexOrder = new int[size];    for (int i = 0; i < size; i++) {        indexOrder[i] = activeIndices.get((begin + i) % size);    }    return new SpecificOrderIterator<T>(indexOrder, getObjects());}
d51e5f7450eca0a0f63da1a466189e262d053b84aa767ba3be5cea740af7251b
hasNext
public boolean hasNext()
{    return index < order.length;}
0065325c0b6db8e2da52a39fd2e7ee6b3c2e4399e222206472be21a840aad14f
next
public T next()
{    return items.get(order[index++]);}
eb35e4acc0ab2c89fd30970f01fba35488b3a4581b2af1986091209043508a3e
remove
public void remove()
{    throw new UnsupportedOperationException();}
41701043a46f4698dae1e85a334e36dc5a261d55328321589893de888513b3e1
initGlobalSSLParameters
public static void initGlobalSSLParameters()
{    initSysPropFromEnvVar(SYS_PROP_KEYSTORE_PATH, ENV_VAR_KEYSTORE_PATH, DESCR_KEYSTORE_PATH);    initSysPropFromEnvVar(SYS_PROP_KEYSTORE_PASSWORD, ENV_VAR_KEYSTORE_PASSWORD, DESCR_KEYSTORE_PASSWORD);    initSysPropFromEnvVar(SYS_PROP_KEYSTORE_TYPE, ENV_VAR_KEYSTORE_TYPE, DESCR_KEYSTORE_TYPE);    initSysPropFromEnvVar(SYS_PROP_TRUSTSTORE_PATH, ENV_VAR_TRUSTSTORE_PATH, DESCR_TRUSTSTORE_PATH);    initSysPropFromEnvVar(SYS_PROP_TRUSTSTORE_PASSWORD, ENV_VAR_TRUSTSTORE_PASSWORD, DESCR_TRUSTSTORE_PASSWORD);    initSysPropFromEnvVar(SYS_PROP_TRUSTSTORE_TYPE, ENV_VAR_TRUSTSTORE_TYPE, DESCR_TRUSTSTORE_TYPE);    initSysPropFromEnvVar(SYS_PROP_INCLUDE_PROTOCOLS, ENV_VAR_INCLUDE_PROTOCOLS, DESCR_INCLUDE_PROTOCOLS);    initSysPropFromEnvVar(SYS_PROP_EXCLUDE_PROTOCOLS, ENV_VAR_EXCLUDE_PROTOCOLS, DESCR_EXCLUDE_PROTOCOLS);    initSysPropFromEnvVar(SYS_PROP_INCLUDE_CIPHERSUITES, ENV_VAR_INCLUDE_CIPHERSUITES, DESCR_INCLUDE_CIPHERSUITES);    initSysPropFromEnvVar(SYS_PROP_EXCLUDE_CIPHERSUITES, ENV_VAR_EXCLUDE_CIPHERSUITES, DESCR_EXCLUDE_CIPHERSUITES);}
8aa9dae271bd296ff562e8ecdd512fe0aa6af18e1322e016852d8e430761ef8a
initSysPropFromEnvVar
private static void initSysPropFromEnvVar(String sysPropName, String envVarName, String description)
{    if (System.getProperty(sysPropName) != null) {        LOGGER.debug("Global SSL " + description + " has been initialized from system property.");    } else {        String envVarValue = System.getenv(envVarName);        if (envVarValue != null) {            System.setProperty(sysPropName, envVarValue);            LOGGER.debug("Global SSL " + description + " has been initialized from environment variable.");        } else {            LOGGER.debug("No global SSL " + description + " specified.");        }    }}
17b69facbfef59dc5fec3853f73d381fd249273cc719232c1adf782d51c2a77e
getGlobalKeystorePath
public static String getGlobalKeystorePath()
{    return System.getProperty(SYS_PROP_KEYSTORE_PATH);}
835d861c6ce620ee9e99c6866161ec61a636c25a33b93085d7f1f0019b3b3449
getGlobalKeystorePassword
public static String getGlobalKeystorePassword()
{    return System.getProperty(SYS_PROP_KEYSTORE_PASSWORD);}
c7da7025b329a52ed60cd6394fc3df7c9f98a035833d11722a1b5b08c2171aae
getGlobalKeystoreType
public static String getGlobalKeystoreType(String defaultValue)
{    String sysPropValue = System.getProperty(SYS_PROP_KEYSTORE_TYPE);    return sysPropValue != null ? sysPropValue : defaultValue;}
d3278096a5ab6624e278ecba96029811865703c012d7748d374c519348739e98
getGlobalTruststorePath
public static String getGlobalTruststorePath()
{    return System.getProperty(SYS_PROP_TRUSTSTORE_PATH);}
5df1cfdceba32d6f4b27d92def4945ac736b83f02eb0958f8638082032a24b0e
getGlobalTruststorePassword
public static String getGlobalTruststorePassword()
{    return System.getProperty(SYS_PROP_TRUSTSTORE_PASSWORD);}
a844491dd06680199f7233b5233a5ebfc785d5686d4a10f1d6b8e053e5adf3d5
getGlobalTruststoreType
public static String getGlobalTruststoreType(String defaultValue)
{    String sysPropValue = System.getProperty(SYS_PROP_TRUSTSTORE_TYPE);    return sysPropValue != null ? sysPropValue : defaultValue;}
96c3e0a3204498ce5eddf4a4c16f207b9e59c9cdd06cb106d7fbd52c69f5b081
getGlobalExcludeProtocols
public static String getGlobalExcludeProtocols()
{    return normalizeProperty(SYS_PROP_EXCLUDE_PROTOCOLS);}
1e54e452913c74afe0a888b0e9fa4e2c344508df67cb283670ea4815b1390574
getGlobalIncludeProtocols
public static String getGlobalIncludeProtocols()
{    return normalizeProperty(SYS_PROP_INCLUDE_PROTOCOLS);}
0f1739fb1b3c1bf16dac30b7975f918cffe35816e35979d3d38d81764ac4c344
getGlobalExcludeCipherSuites
public static String getGlobalExcludeCipherSuites()
{    return normalizeProperty(SYS_PROP_EXCLUDE_CIPHERSUITES);}
f4578dfac7811fc4fb07e78478afcd91549cd356a6b2b813e4c8a9200bf32429
getGlobalIncludeCipherSuites
public static String getGlobalIncludeCipherSuites()
{    return normalizeProperty(SYS_PROP_INCLUDE_CIPHERSUITES);}
a0b089f4a25354fb4754f7d26ad5450c45d2306c210db9b1f6ada3b206aeb127
normalizeProperty
private static String normalizeProperty(String name)
{    String property = System.getProperty(name);    return property == null ? null : property.replaceAll(",", " ");}
4f4a1b343b73a648d0e68d8879be09e3ba454588e34c3e515eb650e6284f00a7
handlerSimpleAppendTest
public static void handlerSimpleAppendTest(AvroSourceProtocol handler) throws FlumeException, EventDeliveryException
{    handlerSimpleAppendTest(handler, false, false, 0);}
d432d40e0b2024d137f8b4b67bdf63e8bc4ec905dbe05cbf95dad3b09063d8d1
handlerSimpleAppendTest
public static void handlerSimpleAppendTest(AvroSourceProtocol handler, boolean enableServerCompression, boolean enableClientCompression, int compressionLevel) throws FlumeException, EventDeliveryException
{    NettyAvroRpcClient client = null;    Server server = startServer(handler, 0, enableServerCompression);    try {        Properties starterProp = new Properties();        if (enableClientCompression) {            starterProp.setProperty(RpcClientConfigurationConstants.CONFIG_COMPRESSION_TYPE, "deflate");            starterProp.setProperty(RpcClientConfigurationConstants.CONFIG_COMPRESSION_LEVEL, "" + compressionLevel);        } else {            starterProp.setProperty(RpcClientConfigurationConstants.CONFIG_COMPRESSION_TYPE, "none");        }        client = getStockLocalClient(server.getPort(), starterProp);        boolean isActive = client.isActive();        Assert.assertTrue("Client should be active", isActive);        client.append(EventBuilder.withBody("wheee!!!", Charset.forName("UTF8")));    } finally {        stopServer(server);        if (client != null)            client.close();    }}
e556629f02508e9a3c47653a0b0c48c8314166fd66baf5ab560b6dd8dc262344
handlerBatchAppendTest
public static void handlerBatchAppendTest(AvroSourceProtocol handler) throws FlumeException, EventDeliveryException
{    handlerBatchAppendTest(handler, false, false, 0);}
d43aa84d7923fe4b99e2d5aa8bcac03367445bb9bc1119c75963cc68de6d24de
handlerBatchAppendTest
public static void handlerBatchAppendTest(AvroSourceProtocol handler, boolean enableServerCompression, boolean enableClientCompression, int compressionLevel) throws FlumeException, EventDeliveryException
{    NettyAvroRpcClient client = null;    Server server = startServer(handler, 0, enableServerCompression);    try {        Properties starterProp = new Properties();        if (enableClientCompression) {            starterProp.setProperty(RpcClientConfigurationConstants.CONFIG_COMPRESSION_TYPE, "deflate");            starterProp.setProperty(RpcClientConfigurationConstants.CONFIG_COMPRESSION_LEVEL, "" + compressionLevel);        } else {            starterProp.setProperty(RpcClientConfigurationConstants.CONFIG_COMPRESSION_TYPE, "none");        }        client = getStockLocalClient(server.getPort(), starterProp);        boolean isActive = client.isActive();        Assert.assertTrue("Client should be active", isActive);        int batchSize = client.getBatchSize();        List<Event> events = new ArrayList<Event>();        for (int i = 0; i < batchSize; i++) {            events.add(EventBuilder.withBody("evt: " + i, Charset.forName("UTF8")));        }        client.appendBatch(events);    } finally {        stopServer(server);        if (client != null)            client.close();    }}
15b078652da856306274f14fcad61eb1cc52ceff850659839a6e16d838b4a783
getStockLocalClient
public static NettyAvroRpcClient getStockLocalClient(int port)
{    Properties props = new Properties();    return getStockLocalClient(port, props);}
0bdf60b04eaa6293a43dc001ea86b9e3ab3b3b609da0e5afbbef20936a0cfa69
getStockLocalClient
public static NettyAvroRpcClient getStockLocalClient(int port, Properties starterProp)
{    starterProp.setProperty(RpcClientConfigurationConstants.CONFIG_HOSTS, "h1");    starterProp.setProperty(RpcClientConfigurationConstants.CONFIG_HOSTS_PREFIX + "h1", "127.0.0.1" + ":" + port);    NettyAvroRpcClient client = new NettyAvroRpcClient();    client.configure(starterProp);    return client;}
680ed48d25d45900e2f778a249510d16a359ce8f0bc8efdd0344c27e32077012
startServer
public static Server startServer(AvroSourceProtocol handler, int port, boolean enableCompression)
{    Responder responder = new SpecificResponder(AvroSourceProtocol.class, handler);    Server server;    if (enableCompression) {        server = new NettyServer(responder, new InetSocketAddress(localhost, port), new NioServerSocketChannelFactory(Executors.newCachedThreadPool(), Executors.newCachedThreadPool()), new CompressionChannelPipelineFactory(), null);    } else {        server = new NettyServer(responder, new InetSocketAddress(localhost, port));    }    server.start();    logger.info("Server started on hostname: {}, port: {}", new Object[] { localhost, Integer.toString(server.getPort()) });    try {        Thread.sleep(300L);    } catch (InterruptedException ex) {        logger.error("Thread interrupted. Exception follows.", ex);        Thread.currentThread().interrupt();    }    return server;}
0ed819c938aae03e58363a7f094042633a54e0a1228262852e4a9892eca1d61d
startServer
public static Server startServer(AvroSourceProtocol handler)
{    return startServer(handler, 0, false);}
8ccd225e59782158e3f56e84762e8cd2087788f50f795b2f512bf997610f6ae9
startServer
public static Server startServer(AvroSourceProtocol handler, int port)
{    return startServer(handler, port, false);}
faaac4a2fd0a8c4d50f3d10a9ec7caa6c03244aa14cb1f08f00f72bcdf9a66cc
stopServer
public static void stopServer(Server server)
{    try {        server.close();        server.join();    } catch (InterruptedException ex) {        logger.error("Thread interrupted. Exception follows.", ex);        Thread.currentThread().interrupt();    }}
75aa31ee485c8db580f13f7f28691ec46c5d1c6d74a8c23efaff32f4efd91f82
getAppendCount
public int getAppendCount()
{    return appendCount;}
7d17e6e932654328df807fdb3c16c5210d5c9516ca0cf2da9d5541fe49ca500a
getAppendBatchCount
public int getAppendBatchCount()
{    return appendBatchCount;}
d96e2668dc227362a6de3cac8f1c7ffd0544111b3897b318561bbeb7c4da2682
isFailed
public boolean isFailed()
{    return failed;}
9aef2003f1d60eb1f17015fcde54f78365c93b63fc957101c946bf4edb1b580d
setFailed
public void setFailed()
{    this.failed = true;}
1510e873c0c2272e628815919234fb64059c8eeb7e3b9ed075bb6ba6d535115e
setOK
public void setOK()
{    this.failed = false;}
16896c3c4fd07c175b3a70f7caa364f655a38a6b63a54a3895b30e8dcacf0f52
append
public Status append(AvroFlumeEvent event) throws AvroRemoteException
{    if (failed) {        logger.debug("Event rejected");        return Status.FAILED;    }    logger.debug("LB: Received event from append(): {}", new String(event.getBody().array(), Charset.forName("UTF8")));    appendCount++;    return Status.OK;}
a8baf3969fe87a0c94bf276b347c3cf4fd1f38175e8dddac6a5e509a3b6db442
appendBatch
public Status appendBatch(List<AvroFlumeEvent> events) throws AvroRemoteException
{    if (failed) {        logger.debug("Event batch rejected");        return Status.FAILED;    }    logger.debug("LB: Received {} events from appendBatch()", events.size());    appendBatchCount++;    return Status.OK;}
16896c3c4fd07c175b3a70f7caa364f655a38a6b63a54a3895b30e8dcacf0f52
append
public Status append(AvroFlumeEvent event) throws AvroRemoteException
{    logger.info("OK: Received event from append(): {}", new String(event.getBody().array(), Charset.forName("UTF8")));    return Status.OK;}
a8baf3969fe87a0c94bf276b347c3cf4fd1f38175e8dddac6a5e509a3b6db442
appendBatch
public Status appendBatch(List<AvroFlumeEvent> events) throws AvroRemoteException
{    logger.info("OK: Received {} events from appendBatch()", events.size());    return Status.OK;}
16896c3c4fd07c175b3a70f7caa364f655a38a6b63a54a3895b30e8dcacf0f52
append
public Status append(AvroFlumeEvent event) throws AvroRemoteException
{    logger.info("Failed: Received event from append(): {}", new String(event.getBody().array(), Charset.forName("UTF8")));    return Status.FAILED;}
a8baf3969fe87a0c94bf276b347c3cf4fd1f38175e8dddac6a5e509a3b6db442
appendBatch
public Status appendBatch(List<AvroFlumeEvent> events) throws AvroRemoteException
{    logger.info("Failed: Received {} events from appendBatch()", events.size());    return Status.FAILED;}
16896c3c4fd07c175b3a70f7caa364f655a38a6b63a54a3895b30e8dcacf0f52
append
public Status append(AvroFlumeEvent event) throws AvroRemoteException
{    logger.info("Unknown: Received event from append(): {}", new String(event.getBody().array(), Charset.forName("UTF8")));    return Status.UNKNOWN;}
a8baf3969fe87a0c94bf276b347c3cf4fd1f38175e8dddac6a5e509a3b6db442
appendBatch
public Status appendBatch(List<AvroFlumeEvent> events) throws AvroRemoteException
{    logger.info("Unknown: Received {} events from appendBatch()", events.size());    return Status.UNKNOWN;}
16896c3c4fd07c175b3a70f7caa364f655a38a6b63a54a3895b30e8dcacf0f52
append
public Status append(AvroFlumeEvent event) throws AvroRemoteException
{    logger.info("Throwing: Received event from append(): {}", new String(event.getBody().array(), Charset.forName("UTF8")));    throw new AvroRemoteException("Handler smash!");}
a8baf3969fe87a0c94bf276b347c3cf4fd1f38175e8dddac6a5e509a3b6db442
appendBatch
public Status appendBatch(List<AvroFlumeEvent> events) throws AvroRemoteException
{    logger.info("Throwing: Received {} events from appendBatch()", events.size());    throw new AvroRemoteException("Handler smash!");}
cad0ca6670898490d4708d44f6fd87df22865c8cca5776775b5fc8cd9e37c866
getPipeline
public ChannelPipeline getPipeline() throws Exception
{    ChannelPipeline pipeline = Channels.pipeline();    ZlibEncoder encoder = new ZlibEncoder(6);    pipeline.addFirst("deflater", encoder);    pipeline.addFirst("inflater", new ZlibDecoder());    return pipeline;}
8c7ac92e4e5226adffe8aa7e3a11a40e2dd2981bad244f1f7f2110ecc447eaab
testFailover
public void testFailover() throws FlumeException, EventDeliveryException, InterruptedException
{    FailoverRpcClient client = null;    Server server1 = RpcTestUtils.startServer(new OKAvroHandler());    Server server2 = RpcTestUtils.startServer(new OKAvroHandler());    Server server3 = RpcTestUtils.startServer(new OKAvroHandler());    Properties props = new Properties();    int s1Port = server1.getPort();    int s2Port = server2.getPort();    int s3Port = server3.getPort();    props.put("client.type", "default_failover");    props.put("hosts", "host1 host2 host3");    props.put("hosts.host1", "127.0.0.1:" + String.valueOf(s1Port));    props.put("hosts.host2", "127.0.0.1:" + String.valueOf(s2Port));    props.put("hosts.host3", "127.0.0.1:" + String.valueOf(s3Port));    client = (FailoverRpcClient) RpcClientFactory.getInstance(props);    List<Event> events = new ArrayList<Event>();    for (int i = 0; i < 50; i++) {        events.add(EventBuilder.withBody("evt: " + i, Charset.forName("UTF8")));    }    client.appendBatch(events);    Assert.assertEquals(client.getLastConnectedServerAddress(), new InetSocketAddress("127.0.0.1", server1.getPort()));    server1.close();        Thread.sleep(1000L);    events = new ArrayList<Event>();    for (int i = 0; i < 50; i++) {        events.add(EventBuilder.withBody("evt: " + i, Charset.forName("UTF8")));    }    client.appendBatch(events);    Assert.assertEquals(new InetSocketAddress("localhost", server2.getPort()), client.getLastConnectedServerAddress());    server2.close();        Thread.sleep(1000L);    client.append(EventBuilder.withBody("Had a sandwich?", Charset.forName("UTF8")));    Assert.assertEquals(new InetSocketAddress("localhost", server3.getPort()), client.getLastConnectedServerAddress());        Server server4 = RpcTestUtils.startServer(new OKAvroHandler(), s2Port);    server3.close();        Thread.sleep(1000L);    events = new ArrayList<Event>();    for (int i = 0; i < 50; i++) {        events.add(EventBuilder.withBody("evt: " + i, Charset.forName("UTF8")));    }    client.appendBatch(events);    Assert.assertEquals(new InetSocketAddress("localhost", s2Port), client.getLastConnectedServerAddress());    Server server5 = RpcTestUtils.startServer(new OKAvroHandler(), s1Port);        client.append(EventBuilder.withBody("Had a mango?", Charset.forName("UTF8")));    Assert.assertEquals(new InetSocketAddress("localhost", s2Port), client.getLastConnectedServerAddress());    server4.close();        Thread.sleep(1000L);    events = new ArrayList<Event>();    for (int i = 0; i < 50; i++) {        events.add(EventBuilder.withBody("evt: " + i, Charset.forName("UTF8")));    }    client.appendBatch(events);    Assert.assertEquals(new InetSocketAddress("localhost", s1Port), client.getLastConnectedServerAddress());    server5.close();        Thread.sleep(1000L);    Server server6 = RpcTestUtils.startServer(new OKAvroHandler(), s1Port);    client.append(EventBuilder.withBody("Had a whole watermelon?", Charset.forName("UTF8")));    Assert.assertEquals(new InetSocketAddress("localhost", s1Port), client.getLastConnectedServerAddress());    server6.close();        Thread.sleep(1000L);    Server server7 = RpcTestUtils.startServer(new OKAvroHandler(), s3Port);    events = new ArrayList<Event>();    for (int i = 0; i < 50; i++) {        events.add(EventBuilder.withBody("evt: " + i, Charset.forName("UTF8")));    }    client.appendBatch(events);    Assert.assertEquals(new InetSocketAddress("localhost", s3Port), client.getLastConnectedServerAddress());    server7.close();}
69aa9209ef30e5d331c0b5926298c5c998beeaa26802eb15231e2ae8057096a8
testFailedServers
public void testFailedServers() throws FlumeException, EventDeliveryException
{    FailoverRpcClient client = null;    Server server1 = RpcTestUtils.startServer(new OKAvroHandler());    Server server2 = RpcTestUtils.startServer(new OKAvroHandler());    Server server3 = RpcTestUtils.startServer(new OKAvroHandler());    Properties props = new Properties();    props.put("client.type", "default_failover");    props.put("hosts", "host1 host2 host3");    props.put("hosts.host1", "localhost:" + String.valueOf(server1.getPort()));    props.put("hosts.host2", "localhost:" + String.valueOf(server2.getPort()));    props.put("hosts.host3", " localhost:" + String.valueOf(server3.getPort()));    client = (FailoverRpcClient) RpcClientFactory.getInstance(props);    List<Event> events = new ArrayList<Event>();    for (int i = 0; i < 50; i++) {        events.add(EventBuilder.withBody("evt: " + i, Charset.forName("UTF8")));    }    client.appendBatch(events);    server1.close();    server2.close();    server3.close();    events = new ArrayList<Event>();    for (int i = 0; i < 50; i++) {        events.add(EventBuilder.withBody("evt: " + i, Charset.forName("UTF8")));    }    client.appendBatch(events);}
a8242e54d02abc5d8b4ecb2d23afb41af1ee99c9a359f86216c4ff2e48440e7e
testCreatingLbClientSingleHost
public void testCreatingLbClientSingleHost()
{    Server server1 = null;    RpcClient c = null;    try {        server1 = RpcTestUtils.startServer(new OKAvroHandler());        Properties p = new Properties();        p.put("host1", "127.0.0.1:" + server1.getPort());        p.put("hosts", "host1");        p.put("client.type", "default_loadbalance");        RpcClientFactory.getInstance(p);    } finally {        if (server1 != null)            server1.close();        if (c != null)            c.close();    }}
70362b5d4b6c294bcf13c721a4483c4934f10b3549e83d46483cd4712a2d477c
testTwoHostFailover
public void testTwoHostFailover() throws Exception
{    Server s1 = null;    Server s2 = null;    RpcClient c = null;    try {        LoadBalancedAvroHandler h1 = new LoadBalancedAvroHandler();        LoadBalancedAvroHandler h2 = new LoadBalancedAvroHandler();        s1 = RpcTestUtils.startServer(h1);        s2 = RpcTestUtils.startServer(h2);        Properties p = new Properties();        p.put("hosts", "h1 h2");        p.put("client.type", "default_loadbalance");        p.put("hosts.h1", "127.0.0.1:" + s1.getPort());        p.put("hosts.h2", "127.0.0.1:" + s2.getPort());        c = RpcClientFactory.getInstance(p);        Assert.assertTrue(c instanceof LoadBalancingRpcClient);        for (int i = 0; i < 100; i++) {            if (i == 20) {                h2.setFailed();            } else if (i == 40) {                h2.setOK();            }            c.append(getEvent(i));        }        Assert.assertEquals(60, h1.getAppendCount());        Assert.assertEquals(40, h2.getAppendCount());    } finally {        if (s1 != null)            s1.close();        if (s2 != null)            s2.close();        if (c != null)            c.close();    }}
4caedb3e49d521996288b7ea3e3367e026e3c11bdbc29a8c01cab3e24d797766
testTwoHostFailoverThrowAfterClose
public void testTwoHostFailoverThrowAfterClose() throws Exception
{    Server s1 = null;    Server s2 = null;    RpcClient c = null;    try {        LoadBalancedAvroHandler h1 = new LoadBalancedAvroHandler();        LoadBalancedAvroHandler h2 = new LoadBalancedAvroHandler();        s1 = RpcTestUtils.startServer(h1);        s2 = RpcTestUtils.startServer(h2);        Properties p = new Properties();        p.put("hosts", "h1 h2");        p.put("client.type", "default_loadbalance");        p.put("hosts.h1", "127.0.0.1:" + s1.getPort());        p.put("hosts.h2", "127.0.0.1:" + s2.getPort());        c = RpcClientFactory.getInstance(p);        Assert.assertTrue(c instanceof LoadBalancingRpcClient);        for (int i = 0; i < 100; i++) {            if (i == 20) {                h2.setFailed();            } else if (i == 40) {                h2.setOK();            }            c.append(getEvent(i));        }        Assert.assertEquals(60, h1.getAppendCount());        Assert.assertEquals(40, h2.getAppendCount());        if (c != null)            c.close();        c.append(getEvent(3));        Assert.fail();    } finally {        if (s1 != null)            s1.close();        if (s2 != null)            s2.close();    }}
1f096b04a9ef3c979d6ed030d621218f5b42bfc8dc59d6ca247f91d59cf94bdd
testTwoHostsOneDead
public void testTwoHostsOneDead() throws Exception
{    LOGGER.info("Running testTwoHostsOneDead...");    Server s1 = null;    RpcClient c1 = null;    RpcClient c2 = null;    try {        LoadBalancedAvroHandler h1 = new LoadBalancedAvroHandler();        s1 = RpcTestUtils.startServer(h1);                Properties p = new Properties();        p.put("hosts", "h1 h2");        p.put("client.type", "default_loadbalance");                p.put("hosts.h1", "127.0.0.1:" + 0);        p.put("hosts.h2", "127.0.0.1:" + s1.getPort());                c1 = RpcClientFactory.getInstance(p);        Assert.assertTrue(c1 instanceof LoadBalancingRpcClient);        for (int i = 0; i < 10; i++) {            c1.appendBatch(getBatchedEvent(i));        }        Assert.assertEquals(10, h1.getAppendBatchCount());                c2 = RpcClientFactory.getInstance(p);        Assert.assertTrue(c2 instanceof LoadBalancingRpcClient);        for (int i = 0; i < 10; i++) {            c2.append(getEvent(i));        }        Assert.assertEquals(10, h1.getAppendCount());    } finally {        if (s1 != null)            s1.close();        if (c1 != null)            c1.close();        if (c2 != null)            c2.close();    }}
b7e7d9bee0d0fd97d7930947bf1260965e8ffbadeccea7716e8712c13829d195
testTwoHostFailoverBatch
public void testTwoHostFailoverBatch() throws Exception
{    Server s1 = null;    Server s2 = null;    RpcClient c = null;    try {        LoadBalancedAvroHandler h1 = new LoadBalancedAvroHandler();        LoadBalancedAvroHandler h2 = new LoadBalancedAvroHandler();        s1 = RpcTestUtils.startServer(h1);        s2 = RpcTestUtils.startServer(h2);        Properties p = new Properties();        p.put("hosts", "h1 h2");        p.put("client.type", "default_loadbalance");        p.put("hosts.h1", "127.0.0.1:" + s1.getPort());        p.put("hosts.h2", "127.0.0.1:" + s2.getPort());        c = RpcClientFactory.getInstance(p);        Assert.assertTrue(c instanceof LoadBalancingRpcClient);        for (int i = 0; i < 100; i++) {            if (i == 20) {                h2.setFailed();            } else if (i == 40) {                h2.setOK();            }            c.appendBatch(getBatchedEvent(i));        }        Assert.assertEquals(60, h1.getAppendBatchCount());        Assert.assertEquals(40, h2.getAppendBatchCount());    } finally {        if (s1 != null)            s1.close();        if (s2 != null)            s2.close();        if (c != null)            c.close();    }}
41dc7d8f4efa5dfaf1b5e1abfefec84462cec60b95557fdd0b52b4850e1ef08e
testLbDefaultClientTwoHosts
public void testLbDefaultClientTwoHosts() throws Exception
{    Server s1 = null;    Server s2 = null;    RpcClient c = null;    try {        LoadBalancedAvroHandler h1 = new LoadBalancedAvroHandler();        LoadBalancedAvroHandler h2 = new LoadBalancedAvroHandler();        s1 = RpcTestUtils.startServer(h1);        s2 = RpcTestUtils.startServer(h2);        Properties p = new Properties();        p.put("hosts", "h1 h2");        p.put("client.type", "default_loadbalance");        p.put("hosts.h1", "127.0.0.1:" + s1.getPort());        p.put("hosts.h2", "127.0.0.1:" + s2.getPort());        c = RpcClientFactory.getInstance(p);        Assert.assertTrue(c instanceof LoadBalancingRpcClient);        for (int i = 0; i < 100; i++) {            c.append(getEvent(i));        }        Assert.assertEquals(50, h1.getAppendCount());        Assert.assertEquals(50, h2.getAppendCount());    } finally {        if (s1 != null)            s1.close();        if (s2 != null)            s2.close();        if (c != null)            c.close();    }}
6beb2df47976072ace359a86631a7428dfb9cff2831bfacf05c41a9fdeff2987
testLbDefaultClientTwoHostsBatch
public void testLbDefaultClientTwoHostsBatch() throws Exception
{    Server s1 = null;    Server s2 = null;    RpcClient c = null;    try {        LoadBalancedAvroHandler h1 = new LoadBalancedAvroHandler();        LoadBalancedAvroHandler h2 = new LoadBalancedAvroHandler();        s1 = RpcTestUtils.startServer(h1);        s2 = RpcTestUtils.startServer(h2);        Properties p = new Properties();        p.put("hosts", "h1 h2");        p.put("client.type", "default_loadbalance");        p.put("hosts.h1", "127.0.0.1:" + s1.getPort());        p.put("hosts.h2", "127.0.0.1:" + s2.getPort());        c = RpcClientFactory.getInstance(p);        Assert.assertTrue(c instanceof LoadBalancingRpcClient);        for (int i = 0; i < 100; i++) {            c.appendBatch(getBatchedEvent(i));        }        Assert.assertEquals(50, h1.getAppendBatchCount());        Assert.assertEquals(50, h2.getAppendBatchCount());    } finally {        if (s1 != null)            s1.close();        if (s2 != null)            s2.close();        if (c != null)            c.close();    }}
4024854523aaa53b8e70bfb09a98f82006e9ee069c42454157cf9c8f5869a49f
testLbClientTenHostRandomDistribution
public void testLbClientTenHostRandomDistribution() throws Exception
{    final int NUM_HOSTS = 10;    final int NUM_EVENTS = 1000;    Server[] s = new Server[NUM_HOSTS];    LoadBalancedAvroHandler[] h = new LoadBalancedAvroHandler[NUM_HOSTS];    RpcClient c = null;    try {        Properties p = new Properties();        StringBuilder hostList = new StringBuilder("");        for (int i = 0; i < NUM_HOSTS; i++) {            h[i] = new LoadBalancedAvroHandler();            s[i] = RpcTestUtils.startServer(h[i]);            String name = "h" + i;            p.put("hosts." + name, "127.0.0.1:" + s[i].getPort());            hostList.append(name).append(" ");        }        p.put("hosts", hostList.toString().trim());        p.put("client.type", "default_loadbalance");        p.put("host-selector", "random");        c = RpcClientFactory.getInstance(p);        Assert.assertTrue(c instanceof LoadBalancingRpcClient);        for (int i = 0; i < NUM_EVENTS; i++) {            c.append(getEvent(i));        }        Set<Integer> counts = new HashSet<Integer>();        int total = 0;        for (LoadBalancedAvroHandler handler : h) {            total += handler.getAppendCount();            counts.add(handler.getAppendCount());        }        Assert.assertTrue("Very unusual distribution", counts.size() > 2);        Assert.assertTrue("Missing events", total == NUM_EVENTS);    } finally {        for (int i = 0; i < NUM_HOSTS; i++) {            if (s[i] != null)                s[i].close();        }    }}
5e4ab5ae474b947fc39e280ca61f3fd1b7d774584653719d478f80def378e551
testLbClientTenHostRandomDistributionBatch
public void testLbClientTenHostRandomDistributionBatch() throws Exception
{    final int NUM_HOSTS = 10;    final int NUM_EVENTS = 1000;    Server[] s = new Server[NUM_HOSTS];    LoadBalancedAvroHandler[] h = new LoadBalancedAvroHandler[NUM_HOSTS];    RpcClient c = null;    try {        Properties p = new Properties();        StringBuilder hostList = new StringBuilder("");        for (int i = 0; i < NUM_HOSTS; i++) {            h[i] = new LoadBalancedAvroHandler();            s[i] = RpcTestUtils.startServer(h[i]);            String name = "h" + i;            p.put("hosts." + name, "127.0.0.1:" + s[i].getPort());            hostList.append(name).append(" ");        }        p.put("hosts", hostList.toString().trim());        p.put("client.type", "default_loadbalance");        p.put("host-selector", "random");        c = RpcClientFactory.getInstance(p);        Assert.assertTrue(c instanceof LoadBalancingRpcClient);        for (int i = 0; i < NUM_EVENTS; i++) {            c.appendBatch(getBatchedEvent(i));        }        Set<Integer> counts = new HashSet<Integer>();        int total = 0;        for (LoadBalancedAvroHandler handler : h) {            total += handler.getAppendBatchCount();            counts.add(handler.getAppendBatchCount());        }        Assert.assertTrue("Very unusual distribution", counts.size() > 2);        Assert.assertTrue("Missing events", total == NUM_EVENTS);    } finally {        for (int i = 0; i < NUM_HOSTS; i++) {            if (s[i] != null)                s[i].close();        }    }}
5e57ff6ae32ecad8ed24feeed76fec811e399c06697cf9f215c458a8b0e78258
testLbClientTenHostRoundRobinDistribution
public void testLbClientTenHostRoundRobinDistribution() throws Exception
{    final int NUM_HOSTS = 10;    final int NUM_EVENTS = 1000;    Server[] s = new Server[NUM_HOSTS];    LoadBalancedAvroHandler[] h = new LoadBalancedAvroHandler[NUM_HOSTS];    RpcClient c = null;    try {        Properties p = new Properties();        StringBuilder hostList = new StringBuilder("");        for (int i = 0; i < NUM_HOSTS; i++) {            h[i] = new LoadBalancedAvroHandler();            s[i] = RpcTestUtils.startServer(h[i]);            String name = "h" + i;            p.put("hosts." + name, "127.0.0.1:" + s[i].getPort());            hostList.append(name).append(" ");        }        p.put("hosts", hostList.toString().trim());        p.put("client.type", "default_loadbalance");        p.put("host-selector", "round_robin");        c = RpcClientFactory.getInstance(p);        Assert.assertTrue(c instanceof LoadBalancingRpcClient);        for (int i = 0; i < NUM_EVENTS; i++) {            c.append(getEvent(i));        }        Set<Integer> counts = new HashSet<Integer>();        int total = 0;        for (LoadBalancedAvroHandler handler : h) {            total += handler.getAppendCount();            counts.add(handler.getAppendCount());        }        Assert.assertTrue("Very unusual distribution", counts.size() == 1);        Assert.assertTrue("Missing events", total == NUM_EVENTS);    } finally {        for (int i = 0; i < NUM_HOSTS; i++) {            if (s[i] != null)                s[i].close();        }    }}
bf8b9a69429377a1ed115c26bd949f31908c04768e7fe68335d807ff6ad87b88
testLbClientTenHostRoundRobinDistributionBatch
public void testLbClientTenHostRoundRobinDistributionBatch() throws Exception
{    final int NUM_HOSTS = 10;    final int NUM_EVENTS = 1000;    Server[] s = new Server[NUM_HOSTS];    LoadBalancedAvroHandler[] h = new LoadBalancedAvroHandler[NUM_HOSTS];    RpcClient c = null;    try {        Properties p = new Properties();        StringBuilder hostList = new StringBuilder("");        for (int i = 0; i < NUM_HOSTS; i++) {            h[i] = new LoadBalancedAvroHandler();            s[i] = RpcTestUtils.startServer(h[i]);            String name = "h" + i;            p.put("hosts." + name, "127.0.0.1:" + s[i].getPort());            hostList.append(name).append(" ");        }        p.put("hosts", hostList.toString().trim());        p.put("client.type", "default_loadbalance");        p.put("host-selector", "round_robin");        c = RpcClientFactory.getInstance(p);        Assert.assertTrue(c instanceof LoadBalancingRpcClient);        for (int i = 0; i < NUM_EVENTS; i++) {            c.appendBatch(getBatchedEvent(i));        }        Set<Integer> counts = new HashSet<Integer>();        int total = 0;        for (LoadBalancedAvroHandler handler : h) {            total += handler.getAppendBatchCount();            counts.add(handler.getAppendBatchCount());        }        Assert.assertTrue("Very unusual distribution", counts.size() == 1);        Assert.assertTrue("Missing events", total == NUM_EVENTS);    } finally {        for (int i = 0; i < NUM_HOSTS; i++) {            if (s[i] != null)                s[i].close();        }    }}
926a03d4e58301cfc9a91dffd6f4186d064ae309f68577c8f9af630784fc069b
testRandomBackoff
public void testRandomBackoff() throws Exception
{    Properties p = new Properties();    List<LoadBalancedAvroHandler> hosts = new ArrayList<LoadBalancedAvroHandler>();    List<Server> servers = new ArrayList<Server>();    StringBuilder hostList = new StringBuilder("");    for (int i = 0; i < 3; i++) {        LoadBalancedAvroHandler s = new LoadBalancedAvroHandler();        hosts.add(s);        Server srv = RpcTestUtils.startServer(s);        servers.add(srv);        String name = "h" + i;        p.put("hosts." + name, "127.0.0.1:" + srv.getPort());        hostList.append(name).append(" ");    }    p.put("hosts", hostList.toString().trim());    p.put("client.type", "default_loadbalance");    p.put("host-selector", "random");    p.put("backoff", "true");    hosts.get(0).setFailed();    hosts.get(2).setFailed();    RpcClient c = RpcClientFactory.getInstance(p);    Assert.assertTrue(c instanceof LoadBalancingRpcClient);        for (int i = 0; i < 50; i++) {                c.append(EventBuilder.withBody(("test" + String.valueOf(i)).getBytes()));    }    Assert.assertEquals(50, hosts.get(1).getAppendCount());    Assert.assertEquals(0, hosts.get(0).getAppendCount());    Assert.assertEquals(0, hosts.get(2).getAppendCount());    hosts.get(0).setOK();        hosts.get(1).setFailed();    try {        c.append(EventBuilder.withBody("shouldfail".getBytes()));                Assert.fail("Expected EventDeliveryException");    } catch (EventDeliveryException e) {        }        Thread.sleep(2500);    for (int i = 0; i < 50; i++) {                c.append(EventBuilder.withBody(("test" + String.valueOf(i)).getBytes()));    }    Assert.assertEquals(50, hosts.get(0).getAppendCount());    Assert.assertEquals(50, hosts.get(1).getAppendCount());    Assert.assertEquals(0, hosts.get(2).getAppendCount());}
4b8d79192f8a365d37fd0a998d3b8333bb3317432ba8cf36f8dc0c9f00246048
testRoundRobinBackoffInitialFailure
public void testRoundRobinBackoffInitialFailure() throws EventDeliveryException
{    Properties p = new Properties();    List<LoadBalancedAvroHandler> hosts = new ArrayList<LoadBalancedAvroHandler>();    List<Server> servers = new ArrayList<Server>();    StringBuilder hostList = new StringBuilder("");    for (int i = 0; i < 3; i++) {        LoadBalancedAvroHandler s = new LoadBalancedAvroHandler();        hosts.add(s);        Server srv = RpcTestUtils.startServer(s);        servers.add(srv);        String name = "h" + i;        p.put("hosts." + name, "127.0.0.1:" + srv.getPort());        hostList.append(name).append(" ");    }    p.put("hosts", hostList.toString().trim());    p.put("client.type", "default_loadbalance");    p.put("host-selector", "round_robin");    p.put("backoff", "true");    RpcClient c = RpcClientFactory.getInstance(p);    Assert.assertTrue(c instanceof LoadBalancingRpcClient);    for (int i = 0; i < 3; i++) {        c.append(EventBuilder.withBody("testing".getBytes()));    }    hosts.get(1).setFailed();    for (int i = 0; i < 3; i++) {        c.append(EventBuilder.withBody("testing".getBytes()));    }    hosts.get(1).setOK();        for (int i = 0; i < 3; i++) {        c.append(EventBuilder.withBody("testing".getBytes()));    }    Assert.assertEquals(1 + 2 + 1, hosts.get(0).getAppendCount());    Assert.assertEquals(1, hosts.get(1).getAppendCount());    Assert.assertEquals(1 + 1 + 2, hosts.get(2).getAppendCount());}
9ddd6bdecb0c29d89739de50994aa45377ca0af67bfd04d606d1e468e0d0cf1a
testRoundRobinBackoffIncreasingBackoffs
public void testRoundRobinBackoffIncreasingBackoffs() throws Exception
{    Properties p = new Properties();    List<LoadBalancedAvroHandler> hosts = new ArrayList<LoadBalancedAvroHandler>();    List<Server> servers = new ArrayList<Server>();    StringBuilder hostList = new StringBuilder("");    for (int i = 0; i < 3; i++) {        LoadBalancedAvroHandler s = new LoadBalancedAvroHandler();        hosts.add(s);        if (i == 1) {            s.setFailed();        }        Server srv = RpcTestUtils.startServer(s);        servers.add(srv);        String name = "h" + i;        p.put("hosts." + name, "127.0.0.1:" + srv.getPort());        hostList.append(name).append(" ");    }    p.put("hosts", hostList.toString().trim());    p.put("client.type", "default_loadbalance");    p.put("host-selector", "round_robin");    p.put("backoff", "true");    RpcClient c = RpcClientFactory.getInstance(p);    Assert.assertTrue(c instanceof LoadBalancingRpcClient);    for (int i = 0; i < 3; i++) {        c.append(EventBuilder.withBody("testing".getBytes()));    }    Assert.assertEquals(0, hosts.get(1).getAppendCount());    Thread.sleep(2100);        for (int i = 0; i < 3; i++) {        c.append(EventBuilder.withBody("testing".getBytes()));    }    Assert.assertEquals(0, hosts.get(1).getAppendCount());    hosts.get(1).setOK();    Thread.sleep(2100);        for (int i = 0; i < 3; i++) {        c.append(EventBuilder.withBody("testing".getBytes()));    }    Assert.assertEquals(0, hosts.get(1).getAppendCount());        Thread.sleep(2500);    int numEvents = 60;    for (int i = 0; i < numEvents; i++) {        c.append(EventBuilder.withBody("testing".getBytes()));    }    Assert.assertEquals(2 + 2 + 1 + (numEvents / 3), hosts.get(0).getAppendCount());    Assert.assertEquals((numEvents / 3), hosts.get(1).getAppendCount());    Assert.assertEquals(1 + 1 + 2 + (numEvents / 3), hosts.get(2).getAppendCount());}
7cf55e2acb50d402ce39b904445708dd0d1838a208486e23ef562904a7d280af
testRoundRobinBackoffFailureRecovery
public void testRoundRobinBackoffFailureRecovery() throws EventDeliveryException, InterruptedException
{    Properties p = new Properties();    List<LoadBalancedAvroHandler> hosts = new ArrayList<LoadBalancedAvroHandler>();    List<Server> servers = new ArrayList<Server>();    StringBuilder hostList = new StringBuilder("");    for (int i = 0; i < 3; i++) {        LoadBalancedAvroHandler s = new LoadBalancedAvroHandler();        hosts.add(s);        if (i == 1) {            s.setFailed();        }        Server srv = RpcTestUtils.startServer(s);        servers.add(srv);        String name = "h" + i;        p.put("hosts." + name, "127.0.0.1:" + srv.getPort());        hostList.append(name).append(" ");    }    p.put("hosts", hostList.toString().trim());    p.put("client.type", "default_loadbalance");    p.put("host-selector", "round_robin");    p.put("backoff", "true");    RpcClient c = RpcClientFactory.getInstance(p);    Assert.assertTrue(c instanceof LoadBalancingRpcClient);    for (int i = 0; i < 3; i++) {        c.append(EventBuilder.withBody("recovery test".getBytes()));    }    hosts.get(1).setOK();    Thread.sleep(3000);    int numEvents = 60;    for (int i = 0; i < numEvents; i++) {        c.append(EventBuilder.withBody("testing".getBytes()));    }    Assert.assertEquals(2 + (numEvents / 3), hosts.get(0).getAppendCount());    Assert.assertEquals(0 + (numEvents / 3), hosts.get(1).getAppendCount());    Assert.assertEquals(1 + (numEvents / 3), hosts.get(2).getAppendCount());}
6b49fc92708b7c140298b6e819206d1979959a283faddc3dd061d8f36da59050
getBatchedEvent
private List<Event> getBatchedEvent(int index)
{    List<Event> result = new ArrayList<Event>();    result.add(getEvent(index));    return result;}
6407472a714024d12c2c41946842c08d503851dee3d5706731ec55bae053f3e1
getEvent
private Event getEvent(int index)
{    return EventBuilder.withBody(("event: " + index).getBytes());}
714b91ab4a065890a4f73869df61fff72f4f315bcdc84b01a0db2ac29d0d7c8a
testOKServerSimple
public void testOKServerSimple() throws FlumeException, EventDeliveryException
{    RpcTestUtils.handlerSimpleAppendTest(new OKAvroHandler());}
55eb93f61edd985006d2d6b977a3f67fd8172f812dbb7d74c15cce3eb5af03bf
testOKServerSimpleCompressionLevel6
public void testOKServerSimpleCompressionLevel6() throws FlumeException, EventDeliveryException
{    RpcTestUtils.handlerSimpleAppendTest(new OKAvroHandler(), true, true, 6);}
15252430ff1e801cf65454a6c24d32067c898c422cc6371cbb1235537cc186df
testOKServerSimpleCompressionLevel0
public void testOKServerSimpleCompressionLevel0() throws FlumeException, EventDeliveryException
{    RpcTestUtils.handlerSimpleAppendTest(new OKAvroHandler(), true, true, 0);}
8c11532063bd9ea7e17a7662ce2bf65c7dcdbeaf01738adffaeb2fb3a177eb8a
testOKServerSimpleCompressionClientOnly
public void testOKServerSimpleCompressionClientOnly() throws FlumeException, EventDeliveryException
{    RpcTestUtils.handlerSimpleAppendTest(new OKAvroHandler(), false, true, 6);}
2b39f6dd544b4602fe79b475423f01db80bd30d2f7c11bcdea5546c6697faa2c
testOKServerSimpleCompressionServerOnly
public void testOKServerSimpleCompressionServerOnly() throws FlumeException, EventDeliveryException
{    RpcTestUtils.handlerSimpleAppendTest(new OKAvroHandler(), true, false, 6);}
ad9778ba036fe9a874f2d2e0d3cc8dc929137c603fc852f47cfc49d79281c781
testOKServerBatch
public void testOKServerBatch() throws FlumeException, EventDeliveryException
{    RpcTestUtils.handlerBatchAppendTest(new OKAvroHandler());}
9fd853af8b393988c895ee256f3f5ec12b900452e6f1e2a133e71cd427bbfcf7
testOKServerBatchCompressionLevel0
public void testOKServerBatchCompressionLevel0() throws FlumeException, EventDeliveryException
{    RpcTestUtils.handlerBatchAppendTest(new OKAvroHandler(), true, true, 0);}
c558f2984fdb0cd441d6c8fb00f97dcdbb598a06df14ab1266de647af42efcd6
testOKServerBatchCompressionLevel6
public void testOKServerBatchCompressionLevel6() throws FlumeException, EventDeliveryException
{    RpcTestUtils.handlerBatchAppendTest(new OKAvroHandler(), true, true, 6);}
60b6ab84480242288fd2db249c669d384dfebc67aaab19029c8692ace339c6e7
testOKServerBatchCompressionServerOnly
public void testOKServerBatchCompressionServerOnly() throws FlumeException, EventDeliveryException
{    RpcTestUtils.handlerBatchAppendTest(new OKAvroHandler(), true, false, 6);}
fd6f4d9a8ad548113278cf8d0d392178cca0bd227aa133f8249f21ac2c6e7b95
testOKServerBatchCompressionClientOnly
public void testOKServerBatchCompressionClientOnly() throws FlumeException, EventDeliveryException
{    RpcTestUtils.handlerBatchAppendTest(new OKAvroHandler(), false, true, 6);}
4e532b21765412f0892318dcdfb12d0bef540256c714acc33347f134d6e720e8
testUnableToConnect
public void testUnableToConnect() throws FlumeException
{    @SuppressWarnings("unused")    NettyAvroRpcClient client = new NettyAvroRpcClient();    Properties props = new Properties();    props.setProperty(RpcClientConfigurationConstants.CONFIG_HOSTS, "localhost");    props.setProperty(RpcClientConfigurationConstants.CONFIG_HOSTS_PREFIX + "localhost", localhost + ":" + 1);    client.configure(props);}
b88679be248da47e0b3b4b0aefc0528a89dd458f1d0d0b161272209718f72ed2
testBatchOverrun
public void testBatchOverrun() throws FlumeException, EventDeliveryException
{    int batchSize = 10;    int moreThanBatchSize = batchSize + 1;    NettyAvroRpcClient client = null;    Server server = RpcTestUtils.startServer(new OKAvroHandler());    Properties props = new Properties();    props.setProperty(RpcClientConfigurationConstants.CONFIG_HOSTS, "localhost");    props.setProperty(RpcClientConfigurationConstants.CONFIG_HOSTS_PREFIX + "localhost", localhost + ":" + server.getPort());    props.setProperty(RpcClientConfigurationConstants.CONFIG_BATCH_SIZE, "" + batchSize);    try {        client = new NettyAvroRpcClient();        client.configure(props);                List<Event> events = new ArrayList<Event>();        for (int i = 0; i < moreThanBatchSize; i++) {            events.add(EventBuilder.withBody("evt: " + i, Charset.forName("UTF8")));        }        client.appendBatch(events);    } finally {        RpcTestUtils.stopServer(server);        if (client != null)            client.close();    }}
8fb278f5c5c40f44c4fc293a7c61caccf2c26b5178bf7b795730f36492b9de37
testServerDisconnect
public void testServerDisconnect() throws FlumeException, EventDeliveryException, InterruptedException
{    NettyAvroRpcClient client = null;    Server server = RpcTestUtils.startServer(new OKAvroHandler());    try {        client = RpcTestUtils.getStockLocalClient(server.getPort());        server.close();                Thread.sleep(1000L);        try {            server.join();        } catch (InterruptedException ex) {            logger.warn("Thread interrupted during join()", ex);            Thread.currentThread().interrupt();        }        try {            client.append(EventBuilder.withBody("hello", Charset.forName("UTF8")));        } finally {            Assert.assertFalse("Client should not be active", client.isActive());        }    } finally {        RpcTestUtils.stopServer(server);        if (client != null)            client.close();    }}
7b9d2ffcad6de4da5e166d7bf505b53007b57c4fafcd8a7195b312a6b26e7814
testClientClosedRequest
public void testClientClosedRequest() throws FlumeException, EventDeliveryException
{    NettyAvroRpcClient client = null;    Server server = RpcTestUtils.startServer(new OKAvroHandler());    try {        client = RpcTestUtils.getStockLocalClient(server.getPort());        client.close();        Assert.assertFalse("Client should not be active", client.isActive());        System.out.println("Yaya! I am not active after client close!");        client.append(EventBuilder.withBody("hello", Charset.forName("UTF8")));    } finally {        RpcTestUtils.stopServer(server);        if (client != null)            client.close();    }}
d5c197855f9c6e5156f896bc7010c3f17f6512c9d8913053ee3d05f447223c72
testFailedServerSimple
public void testFailedServerSimple() throws FlumeException, EventDeliveryException
{    RpcTestUtils.handlerSimpleAppendTest(new FailedAvroHandler());    logger.error("Failed: I should never have gotten here!");}
aca8d5100ab2332b26127d3fac65a47d48ce5c44987f2bf4d32d55d6935ef735
testUnknownServerSimple
public void testUnknownServerSimple() throws FlumeException, EventDeliveryException
{    RpcTestUtils.handlerSimpleAppendTest(new UnknownAvroHandler());    logger.error("Unknown: I should never have gotten here!");}
9711b16de1fdad50a3082acfad84bdd7a31f7bf1d8c5dc945e2dd137d38728d3
testThrowingServerSimple
public void testThrowingServerSimple() throws FlumeException, EventDeliveryException
{    RpcTestUtils.handlerSimpleAppendTest(new ThrowingAvroHandler());    logger.error("Throwing: I should never have gotten here!");}
4e0a24bbe8f5fa6b434fdf6ccd6427915ba1f27b319af9e9520cf314e982e6c7
testFailedServerBatch
public void testFailedServerBatch() throws FlumeException, EventDeliveryException
{    RpcTestUtils.handlerBatchAppendTest(new FailedAvroHandler());    logger.error("Failed: I should never have gotten here!");}
a6fd7b4fa3774db9ebc77f871659872e248eff5103ed56f1b753e61ba24aaf50
testUnknownServerBatch
public void testUnknownServerBatch() throws FlumeException, EventDeliveryException
{    RpcTestUtils.handlerBatchAppendTest(new UnknownAvroHandler());    logger.error("Unknown: I should never have gotten here!");}
ac35afac3348e8226b08f2186c58873ef7393f1f7ceda17187dff56a2ebcf06e
testThrowingServerBatch
public void testThrowingServerBatch() throws FlumeException, EventDeliveryException
{    RpcTestUtils.handlerBatchAppendTest(new ThrowingAvroHandler());    logger.error("Throwing: I should never have gotten here!");}
b28a1c00792153bb2f9bcc52abe3d31b9362adca5736fb03f6fa66b31851f27f
testAppendWithMaxIOWorkers
public void testAppendWithMaxIOWorkers() throws FlumeException, EventDeliveryException
{    NettyAvroRpcClient client = null;    Server server = RpcTestUtils.startServer(new OKAvroHandler());    Properties props = new Properties();    props.setProperty(RpcClientConfigurationConstants.CONFIG_HOSTS, "localhost");    props.setProperty(RpcClientConfigurationConstants.CONFIG_HOSTS_PREFIX + "localhost", localhost + ":" + server.getPort());    props.setProperty(RpcClientConfigurationConstants.MAX_IO_WORKERS, Integer.toString(2));    try {        client = new NettyAvroRpcClient();        client.configure(props);        for (int i = 0; i < 5; i++) {            client.append(EventBuilder.withBody("evt:" + i, Charset.forName("UTF8")));        }    } finally {        RpcTestUtils.stopServer(server);        if (client != null) {            client.close();        }    }}
ea29493de397eb6355b8fa297b95aa77dd343b7427c6f85e655dbd6ea40a1ff9
testAppendWithMaxIOWorkersSimpleCompressionLevel0
public void testAppendWithMaxIOWorkersSimpleCompressionLevel0() throws FlumeException, EventDeliveryException
{    NettyAvroRpcClient client = null;    Server server = RpcTestUtils.startServer(new OKAvroHandler(), 0, true);    Properties props = new Properties();    props.setProperty(RpcClientConfigurationConstants.CONFIG_HOSTS, "localhost");    props.setProperty(RpcClientConfigurationConstants.CONFIG_HOSTS_PREFIX + "localhost", localhost + ":" + server.getPort());    props.setProperty(RpcClientConfigurationConstants.MAX_IO_WORKERS, Integer.toString(2));    props.setProperty(RpcClientConfigurationConstants.CONFIG_COMPRESSION_TYPE, "deflate");    props.setProperty(RpcClientConfigurationConstants.CONFIG_COMPRESSION_LEVEL, "" + 0);    try {        client = new NettyAvroRpcClient();        client.configure(props);        for (int i = 0; i < 5; i++) {            client.append(EventBuilder.withBody("evt:" + i, Charset.forName("UTF8")));        }    } finally {        RpcTestUtils.stopServer(server);        if (client != null) {            client.close();        }    }}
985a869417756695c45edde8c830083b3aee6ca0fba02edcc7626fa276162ba0
testTwoParamSimpleAppend
public void testTwoParamSimpleAppend() throws FlumeException, EventDeliveryException
{    RpcClient client = null;    Server server = RpcTestUtils.startServer(new OKAvroHandler());    try {        client = RpcClientFactory.getDefaultInstance(localhost, server.getPort());        client.append(EventBuilder.withBody("wheee!!!", Charset.forName("UTF8")));    } finally {        RpcTestUtils.stopServer(server);        if (client != null)            client.close();    }}
cd1a51cffc62d0c83b5b1a20d17428e89ad778466c669db1b61c0d4081bfebb4
testTwoParamDeprecatedAppend
public void testTwoParamDeprecatedAppend() throws FlumeException, EventDeliveryException
{    RpcClient client = null;    Server server = RpcTestUtils.startServer(new OKAvroHandler());    try {        client = RpcClientFactory.getInstance(localhost, server.getPort());        client.append(EventBuilder.withBody("wheee!!!", Charset.forName("UTF8")));    } finally {        RpcTestUtils.stopServer(server);        if (client != null)            client.close();    }}
1c3b2a4d732671757afb5795b5aabf386746ef255d24b23c287abe9f2040e7cf
testThreeParamDeprecatedAppend
public void testThreeParamDeprecatedAppend() throws FlumeException, EventDeliveryException
{    RpcClient client = null;    Server server = RpcTestUtils.startServer(new OKAvroHandler());    try {        client = RpcClientFactory.getInstance(localhost, server.getPort(), 3);        Assert.assertEquals("Batch size was specified", 3, client.getBatchSize());        client.append(EventBuilder.withBody("wheee!!!", Charset.forName("UTF8")));    } finally {        RpcTestUtils.stopServer(server);        if (client != null)            client.close();    }}
740d2082ac0014d586d1acf3e702bced806c13552474d4957f299e753381da04
testThreeParamBatchAppend
public void testThreeParamBatchAppend() throws FlumeException, EventDeliveryException
{    int batchSize = 7;    RpcClient client = null;    Server server = RpcTestUtils.startServer(new OKAvroHandler());    try {        client = RpcClientFactory.getDefaultInstance(localhost, server.getPort(), batchSize);        List<Event> events = new ArrayList<Event>();        for (int i = 0; i < batchSize; i++) {            events.add(EventBuilder.withBody("evt: " + i, Charset.forName("UTF8")));        }        client.appendBatch(events);    } finally {        RpcTestUtils.stopServer(server);        if (client != null)            client.close();    }}
cfd890da510d85c4798b66e3b768be34f9b6af885bc21c49d1d0d54d2fb834ce
testPropertiesBatchAppend
public void testPropertiesBatchAppend() throws FlumeException, EventDeliveryException
{    int batchSize = 7;    RpcClient client = null;    Server server = RpcTestUtils.startServer(new OKAvroHandler());    try {        Properties p = new Properties();        p.put("hosts", "host1");        p.put("hosts.host1", localhost + ":" + String.valueOf(server.getPort()));        p.put("batch-size", String.valueOf(batchSize));        client = RpcClientFactory.getInstance(p);        List<Event> events = new ArrayList<Event>();        for (int i = 0; i < batchSize; i++) {            events.add(EventBuilder.withBody("evt: " + i, Charset.forName("UTF8")));        }        client.appendBatch(events);    } finally {        RpcTestUtils.stopServer(server);        if (client != null)            client.close();    }}
440e4d93d650427ffbbb3b1475298cedcd7634c4d6f076860633997dc3319fb7
testTwoParamBatchAppendOverflow
public void testTwoParamBatchAppendOverflow() throws FlumeException, EventDeliveryException
{    RpcClient client = null;    Server server = RpcTestUtils.startServer(new OKAvroHandler());    try {        client = RpcClientFactory.getDefaultInstance(localhost, server.getPort());        int batchSize = client.getBatchSize();        int moreThanBatch = batchSize + 1;        List<Event> events = new ArrayList<Event>();        for (int i = 0; i < moreThanBatch; i++) {            events.add(EventBuilder.withBody("evt: " + i, Charset.forName("UTF8")));        }        client.appendBatch(events);    } finally {        RpcTestUtils.stopServer(server);        if (client != null)            client.close();    }}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    props.setProperty("hosts", "h1");    try (ServerSocket socket = new ServerSocket(0)) {        port = socket.getLocalPort();    }    props.setProperty(RpcClientConfigurationConstants.CONFIG_CLIENT_TYPE, "thrift");    props.setProperty("hosts.h1", "0.0.0.0:" + String.valueOf(port));    props.setProperty(RpcClientConfigurationConstants.CONFIG_BATCH_SIZE, "10");    props.setProperty(RpcClientConfigurationConstants.CONFIG_REQUEST_TIMEOUT, "2000");    props.setProperty(ThriftRpcClient.CONFIG_PROTOCOL, ThriftRpcClient.COMPACT_PROTOCOL);}
c6aaebb5a52567751db8dc8e1cb9dd4a4e582ef964a374b376c6a04f741802dc
tearDown
public void tearDown() throws Exception
{    src.stop();}
aa8060ecc1110ae3759d2c76a33883023eaae33e2f701ed54cb03ff47c5dc44e
insertEvents
private static void insertEvents(RpcClient client, int count) throws Exception
{    for (int i = 0; i < count; i++) {        Map<String, String> header = new HashMap<String, String>();        header.put(SEQ, String.valueOf(i));        client.append(EventBuilder.withBody(String.valueOf(i).getBytes(), header));    }}
20bc14cb1adbea95bbe047e371f28edc0133a95b037157dc182c4cb5ef15c52d
insertAsBatch
private static void insertAsBatch(RpcClient client, int start, int limit) throws Exception
{    List<Event> events = new ArrayList<Event>();    for (int i = start; i <= limit; i++) {        Map<String, String> header = new HashMap<String, String>();        header.put(SEQ, String.valueOf(i));        events.add(EventBuilder.withBody(String.valueOf(i).getBytes(), header));    }    client.appendBatch(events);}
c31f5cbb82d26f4853828068bb1ce58f673bf28f9eb883cef911242976b2aa81
testOK
public void testOK() throws Exception
{    src = new ThriftTestingSource(ThriftTestingSource.HandlerType.OK.name(), port, ThriftRpcClient.COMPACT_PROTOCOL);    client = (ThriftRpcClient) RpcClientFactory.getInstance(props);        insertEvents(client, 10);        insertAsBatch(client, 10, 25);        insertAsBatch(client, 26, 37);    int count = 0;    Assert.assertEquals(38, src.flumeEvents.size());    for (Event e : src.flumeEvents) {        Assert.assertEquals(new String(e.getBody()), String.valueOf(count++));    }    Assert.assertEquals(10, src.individualCount);    Assert.assertEquals(4, src.batchCount);    Assert.assertEquals(2, src.incompleteBatches);}
5155ed9ad8d6d29ffac2045540959b357fe6801e4b843ebd497f96cf9d46f5a9
testSlow
public void testSlow() throws Exception
{    src = new ThriftTestingSource(ThriftTestingSource.HandlerType.SLOW.name(), port, ThriftRpcClient.COMPACT_PROTOCOL);    client = (ThriftRpcClient) RpcClientFactory.getInstance(props);        insertEvents(client, 2);        insertAsBatch(client, 2, 25);        insertAsBatch(client, 26, 37);    int count = 0;    Assert.assertEquals(38, src.flumeEvents.size());    for (Event e : src.flumeEvents) {        Assert.assertEquals(new String(e.getBody()), String.valueOf(count++));    }    Assert.assertEquals(2, src.individualCount);    Assert.assertEquals(5, src.batchCount);    Assert.assertEquals(2, src.incompleteBatches);}
9d8b3cd859683a89d41b04646dc9b0ca11cf8184a309f6b27c5868c2dfda3b73
testFail
public void testFail() throws Exception
{    src = new ThriftTestingSource(ThriftTestingSource.HandlerType.FAIL.name(), port, ThriftRpcClient.COMPACT_PROTOCOL);    client = (ThriftRpcClient) RpcClientFactory.getInstance(props);        insertEvents(client, 2);    Assert.fail("Expected EventDeliveryException to be thrown.");}
c7b8a98cbbcb2c8866784e101e383912d4624cee52fc3536d0c24788c2c895dc
testError
public void testError() throws Throwable
{    try {        src = new ThriftTestingSource(ThriftTestingSource.HandlerType.ERROR.name(), port, ThriftRpcClient.COMPACT_PROTOCOL);        client = (ThriftRpcClient) RpcClientFactory.getThriftInstance("0.0.0.0", port);                insertEvents(client, 2);    } catch (EventDeliveryException ex) {        Assert.assertEquals("Failed to send event. ", ex.getMessage());    }}
11b8a0794b5679b30570f1d2473b359dcff1a4fe5b8d715d01ef99e44905caa3
testTimeout
public void testTimeout() throws Throwable
{    try {        src = new ThriftTestingSource(ThriftTestingSource.HandlerType.TIMEOUT.name(), port, ThriftRpcClient.COMPACT_PROTOCOL);        client = (ThriftRpcClient) RpcClientFactory.getThriftInstance(props);                insertEvents(client, 2);    } catch (EventDeliveryException ex) {        throw ex.getCause();    }}
117ef0df0736b95f56dc046276095a5aac60c69a5bd6303f2314ea1e70b04b99
testMultipleThreads
public void testMultipleThreads() throws Throwable
{    src = new ThriftTestingSource(ThriftTestingSource.HandlerType.OK.name(), port, ThriftRpcClient.COMPACT_PROTOCOL);    client = (ThriftRpcClient) RpcClientFactory.getThriftInstance("0.0.0.0", port, 10);    int threadCount = 100;    ExecutorService submissionSvc = Executors.newFixedThreadPool(threadCount);    ArrayList<Future<?>> futures = new ArrayList<Future<?>>(threadCount);    for (int i = 0; i < threadCount; i++) {        futures.add(submissionSvc.submit(new Runnable() {            @Override            public void run() {                try {                    insertAsBatch(client, 0, 9);                } catch (Exception e) {                                        e.printStackTrace();                                }            }        }));    }    for (int i = 0; i < threadCount; i++) {        futures.get(i).get();    }    ArrayList<String> events = new ArrayList<String>();    for (Event e : src.flumeEvents) {        events.add(new String(e.getBody()));    }    int count = 0;    Collections.sort(events);    for (int i = 0; i < events.size(); ) {        for (int j = 0; j < threadCount; j++) {            Assert.assertEquals(String.valueOf(count), events.get(i++));        }        count++;    }}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    try {        insertAsBatch(client, 0, 9);    } catch (Exception e) {                e.printStackTrace();        }}
208f6d2dcc8a79bca144afa09c5514cb60c523789cbbd9bbe76957b9450798bd
setDelay
public void setDelay(AtomicLong delay)
{    this.delay = delay;}
a54b69432f679ba4c49b1d013a0043e6205966d8a826637757a24931a9413f53
append
public Status append(ThriftFlumeEvent event) throws TException
{    flumeEvents.add(EventBuilder.withBody(event.getBody(), event.getHeaders()));    individualCount++;    return Status.OK;}
5d2dac105501257fa7413f36011388c07328bc76fa6f4a71c4e016aacfd6a925
appendBatch
public Status appendBatch(List<ThriftFlumeEvent> events) throws TException
{    batchCount++;    if (events.size() < 10) {        incompleteBatches++;    }    for (ThriftFlumeEvent event : events) {        flumeEvents.add(EventBuilder.withBody(event.getBody(), event.getHeaders()));    }    return Status.OK;}
a54b69432f679ba4c49b1d013a0043e6205966d8a826637757a24931a9413f53
append
public Status append(ThriftFlumeEvent event) throws TException
{    return Status.FAILED;}
5d2dac105501257fa7413f36011388c07328bc76fa6f4a71c4e016aacfd6a925
appendBatch
public Status appendBatch(List<ThriftFlumeEvent> events) throws TException
{    return Status.FAILED;}
a54b69432f679ba4c49b1d013a0043e6205966d8a826637757a24931a9413f53
append
public Status append(ThriftFlumeEvent event) throws TException
{    throw new FlumeException("Forced Error");}
5d2dac105501257fa7413f36011388c07328bc76fa6f4a71c4e016aacfd6a925
appendBatch
public Status appendBatch(List<ThriftFlumeEvent> events) throws TException
{    throw new FlumeException("Forced Error");}
a54b69432f679ba4c49b1d013a0043e6205966d8a826637757a24931a9413f53
append
public Status append(ThriftFlumeEvent event) throws TException
{    try {        TimeUnit.MILLISECONDS.sleep(1550);    } catch (InterruptedException e) {        throw new FlumeException("Error", e);    }    return super.append(event);}
5d2dac105501257fa7413f36011388c07328bc76fa6f4a71c4e016aacfd6a925
appendBatch
public Status appendBatch(List<ThriftFlumeEvent> events) throws TException
{    try {        TimeUnit.MILLISECONDS.sleep(1550);    } catch (InterruptedException e) {        throw new FlumeException("Error", e);    }    return super.appendBatch(events);}
a54b69432f679ba4c49b1d013a0043e6205966d8a826637757a24931a9413f53
append
public Status append(ThriftFlumeEvent event) throws TException
{    try {        TimeUnit.MILLISECONDS.sleep(5000);    } catch (InterruptedException e) {        throw new FlumeException("Error", e);    }    return super.append(event);}
5d2dac105501257fa7413f36011388c07328bc76fa6f4a71c4e016aacfd6a925
appendBatch
public Status appendBatch(List<ThriftFlumeEvent> events) throws TException
{    try {        TimeUnit.MILLISECONDS.sleep(5000);    } catch (InterruptedException e) {        throw new FlumeException("Error", e);    }    return super.appendBatch(events);}
a54b69432f679ba4c49b1d013a0043e6205966d8a826637757a24931a9413f53
append
public Status append(ThriftFlumeEvent event) throws TException
{    try {        if (delay != null) {            TimeUnit.MILLISECONDS.sleep(delay.get());        }    } catch (InterruptedException e) {        throw new FlumeException("Error", e);    }    return super.append(event);}
5d2dac105501257fa7413f36011388c07328bc76fa6f4a71c4e016aacfd6a925
appendBatch
public Status appendBatch(List<ThriftFlumeEvent> events) throws TException
{    try {        if (delay != null) {            TimeUnit.MILLISECONDS.sleep(delay.get());        }    } catch (InterruptedException e) {        throw new FlumeException("Error", e);    }    return super.appendBatch(events);}
61b4c9f242895ca7e02299e38bbbd36da3ce4a82cd288238fb2c8617db3d9011
getHandler
private ThriftSourceProtocol.Iface getHandler(String handlerName)
{    ThriftSourceProtocol.Iface handler = null;    if (handlerName.equals(HandlerType.OK.name())) {        handler = new ThriftOKHandler();    } else if (handlerName.equals(HandlerType.FAIL.name())) {        handler = new ThriftFailHandler();    } else if (handlerName.equals(HandlerType.ERROR.name())) {        handler = new ThriftErrorHandler();    } else if (handlerName.equals(HandlerType.SLOW.name())) {        handler = new ThriftSlowHandler();    } else if (handlerName.equals(HandlerType.TIMEOUT.name())) {        handler = new ThriftTimeoutHandler();    } else if (handlerName.equals(HandlerType.ALTERNATE.name())) {        handler = new ThriftAlternateHandler();    }    return handler;}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    server.serve();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    server.serve();}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    server.stop();}
a0e6d87b49030e017835c28e4e0dbb3e6dc153b508244dee722844b3b844761f
testBody
public void testBody()
{    Event e1 = EventBuilder.withBody("e1".getBytes());    Assert.assertNotNull(e1);    Assert.assertArrayEquals("body is correct", "e1".getBytes(), e1.getBody());    Event e2 = EventBuilder.withBody(Long.valueOf(2).toString().getBytes());    Assert.assertNotNull(e2);    Assert.assertArrayEquals("body is correct", Long.valueOf(2L).toString().getBytes(), e2.getBody());}
438057137aaef901fe81371452abcb8afed0750edc6332e045cf31a53c33baa3
testHeaders
public void testHeaders()
{    Map<String, String> headers = new HashMap<String, String>();    headers.put("one", "1");    headers.put("two", "2");    Event e1 = EventBuilder.withBody("e1".getBytes(), headers);    Assert.assertNotNull(e1);    Assert.assertArrayEquals("e1 has the proper body", "e1".getBytes(), e1.getBody());    Assert.assertEquals("e1 has the proper headers", 2, e1.getHeaders().size());    Assert.assertEquals("e1 has a one key", "1", e1.getHeaders().get("one"));}
47b5ed448cfda1597917c44ecdba273cab97fa7b14bf81d1acd79afc383d42c8
testJsonEventUnsupportedEncoding
public void testJsonEventUnsupportedEncoding()
{    JSONEvent jsonEvent = new JSONEvent();    jsonEvent.setCharset("dummy");    jsonEvent.setBody("This is json event".getBytes());    jsonEvent.getBody();}
6a1bb22738bbd08ebbb6cc494923dc47f4ed3342640172cf132b2f852b510695
data
public static Collection<?> data()
{    return Arrays.asList(new Object[][] {     { null, null, null }, { "sysprop", null, "sysprop" }, { "sysprop,sysprop", null, "sysprop sysprop" }, { null, "envvar", "envvar" }, { null, "envvar,envvar", "envvar envvar" }, { "sysprop", "envvar", "sysprop" }, { "sysprop,sysprop", "envvar,envvar", "sysprop sysprop" } });}
6a1bb22738bbd08ebbb6cc494923dc47f4ed3342640172cf132b2f852b510695
data
public static Collection<?> data()
{    return Arrays.asList(new Object[][] {     { null, null, null }, { "sysprop", null, "sysprop" }, { null, "envvar", "envvar" }, { "sysprop", "envvar", "sysprop" } });}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    setSysProp(getSysPropName(), sysPropValue);    setEnvVar(getEnvVarName(), envVarValue);}
39e5ba029cc67f6f1d45c6d20f0df595ec16bc61da20d7680fcbbdae4fe7f95b
tearDown
public void tearDown()
{    setSysProp(getSysPropName(), null);    setEnvVar(getEnvVarName(), null);}
e53d45ad19854f8d55986bf63c053490bbe9dc9e58102088fee1b8c28a8fb631
setSysProp
private static void setSysProp(String name, String value)
{    if (value != null) {        System.setProperty(name, value);    } else {        System.clearProperty(name);    }}
2195baa18f35fe82394d1b63d468b078ebc7af9a1d5cb3e6db96a345b50c5c48
setEnvVar
private static void setEnvVar(String name, String value)
{    try {        injectEnvironmentVariable(name, value);    } catch (ReflectiveOperationException e) {        throw new AssertionError("Test setup  failed.", e);    }}
7ef99b06b2059c86799822efceaa6fbaeb94a17e5544bd02ab93052fd59a6ad3
injectEnvironmentVariable
private static void injectEnvironmentVariable(String key, String value) throws ReflectiveOperationException
{    Class<?> processEnvironment = Class.forName("java.lang.ProcessEnvironment");    Field unmodifiableMapField = getAccessibleField(processEnvironment, "theUnmodifiableEnvironment");    Object unmodifiableMap = unmodifiableMapField.get(null);    injectIntoUnmodifiableMap(key, value, unmodifiableMap);    Field mapField = getAccessibleField(processEnvironment, "theEnvironment");    Map<String, String> map = (Map<String, String>) mapField.get(null);    if (value != null) {        map.put(key, value);    } else {        map.remove(key);    }}
2061df7c9717ec1d2aafbd74b070f8b8d1aff12782c6838daeaf1f67e2273a4e
getAccessibleField
private static Field getAccessibleField(Class<?> clazz, String fieldName) throws NoSuchFieldException
{    Field field = clazz.getDeclaredField(fieldName);    field.setAccessible(true);    return field;}
246124542cea0a3663fab762ed283da0358acd60ee105895d84c273cd74688d6
injectIntoUnmodifiableMap
private static void injectIntoUnmodifiableMap(String key, String value, Object map) throws ReflectiveOperationException
{    Class unmodifiableMap = Class.forName("java.util.Collections$UnmodifiableMap");    Field field = getAccessibleField(unmodifiableMap, "m");    Object obj = field.get(map);    if (value != null) {        ((Map<String, String>) obj).put(key, value);    } else {        ((Map<String, String>) obj).remove(key);    }}
c62cdf683d51b128dd7108e03281f189030ed4203fd322e9c2bda10b3def759c
getSysPropName
protected String getSysPropName()
{    return "flume.ssl.exclude.cipherSuites";}
1a87adce45f7169b52224f3c5cd16a5b2927a7d31ec57a21ceb5103af9367c66
getEnvVarName
protected String getEnvVarName()
{    return "FLUME_SSL_EXCLUDE_CIPHERSUITES";}
8d9706f218d9c6502f6faa08c23dac50b3547122c5c6bc8e6a3a598d0209c3cd
testIncludeProtocols
public void testIncludeProtocols()
{    SSLUtil.initGlobalSSLParameters();    String actualValue = SSLUtil.getGlobalExcludeCipherSuites();    Assert.assertEquals(expectedValue, actualValue);}
c62cdf683d51b128dd7108e03281f189030ed4203fd322e9c2bda10b3def759c
getSysPropName
protected String getSysPropName()
{    return "flume.ssl.exclude.protocols";}
1a87adce45f7169b52224f3c5cd16a5b2927a7d31ec57a21ceb5103af9367c66
getEnvVarName
protected String getEnvVarName()
{    return "FLUME_SSL_EXCLUDE_PROTOCOLS";}
a654826e64a7063c3652d45b9610012faa4a92127df82bd7537907f61fcff913
testExcludeProtocols
public void testExcludeProtocols()
{    SSLUtil.initGlobalSSLParameters();    String actualValue = SSLUtil.getGlobalExcludeProtocols();    Assert.assertEquals(expectedValue, actualValue);}
c62cdf683d51b128dd7108e03281f189030ed4203fd322e9c2bda10b3def759c
getSysPropName
protected String getSysPropName()
{    return "flume.ssl.include.cipherSuites";}
1a87adce45f7169b52224f3c5cd16a5b2927a7d31ec57a21ceb5103af9367c66
getEnvVarName
protected String getEnvVarName()
{    return "FLUME_SSL_INCLUDE_CIPHERSUITES";}
8d9706f218d9c6502f6faa08c23dac50b3547122c5c6bc8e6a3a598d0209c3cd
testIncludeProtocols
public void testIncludeProtocols()
{    SSLUtil.initGlobalSSLParameters();    String actualValue = SSLUtil.getGlobalIncludeCipherSuites();    Assert.assertEquals(expectedValue, actualValue);}
c62cdf683d51b128dd7108e03281f189030ed4203fd322e9c2bda10b3def759c
getSysPropName
protected String getSysPropName()
{    return "flume.ssl.include.protocols";}
1a87adce45f7169b52224f3c5cd16a5b2927a7d31ec57a21ceb5103af9367c66
getEnvVarName
protected String getEnvVarName()
{    return "FLUME_SSL_INCLUDE_PROTOCOLS";}
8d9706f218d9c6502f6faa08c23dac50b3547122c5c6bc8e6a3a598d0209c3cd
testIncludeProtocols
public void testIncludeProtocols()
{    SSLUtil.initGlobalSSLParameters();    String actualValue = SSLUtil.getGlobalIncludeProtocols();    Assert.assertEquals(expectedValue, actualValue);}
c62cdf683d51b128dd7108e03281f189030ed4203fd322e9c2bda10b3def759c
getSysPropName
protected String getSysPropName()
{    return "javax.net.ssl.keyStorePassword";}
1a87adce45f7169b52224f3c5cd16a5b2927a7d31ec57a21ceb5103af9367c66
getEnvVarName
protected String getEnvVarName()
{    return "FLUME_SSL_KEYSTORE_PASSWORD";}
bd5f5252d7cfb036d2eb5660a2b2f5f42c4831698cbeefa6ac9f268493e7129c
testKeystorePassword
public void testKeystorePassword()
{    SSLUtil.initGlobalSSLParameters();    String keystorePassword = SSLUtil.getGlobalKeystorePassword();    Assert.assertEquals(expectedValue, keystorePassword);}
c62cdf683d51b128dd7108e03281f189030ed4203fd322e9c2bda10b3def759c
getSysPropName
protected String getSysPropName()
{    return "javax.net.ssl.keyStore";}
1a87adce45f7169b52224f3c5cd16a5b2927a7d31ec57a21ceb5103af9367c66
getEnvVarName
protected String getEnvVarName()
{    return "FLUME_SSL_KEYSTORE_PATH";}
06b15e447dbe141fef8137b31bcf77a404ff3f3095fda456b42bef6a446462e6
testKeystorePath
public void testKeystorePath()
{    SSLUtil.initGlobalSSLParameters();    String keystorePath = SSLUtil.getGlobalKeystorePath();    Assert.assertEquals(expectedValue, keystorePath);}
c62cdf683d51b128dd7108e03281f189030ed4203fd322e9c2bda10b3def759c
getSysPropName
protected String getSysPropName()
{    return "javax.net.ssl.keyStoreType";}
1a87adce45f7169b52224f3c5cd16a5b2927a7d31ec57a21ceb5103af9367c66
getEnvVarName
protected String getEnvVarName()
{    return "FLUME_SSL_KEYSTORE_TYPE";}
5950e372d1ad7eeca1e32d759f00a81ee01ef5ba96fe4e17694b5f338d0463d9
testKeystoreType
public void testKeystoreType()
{    SSLUtil.initGlobalSSLParameters();    String keystoreType = SSLUtil.getGlobalKeystoreType(null);    Assert.assertEquals(expectedValue, keystoreType);}
6a1bb22738bbd08ebbb6cc494923dc47f4ed3342640172cf132b2f852b510695
data
public static Collection<?> data()
{    return Arrays.asList(new Object[][] {     { null, null, "default" }, { "sysprop", null, "sysprop" }, { null, "envvar", "envvar" }, { "sysprop", "envvar", "sysprop" } });}
c62cdf683d51b128dd7108e03281f189030ed4203fd322e9c2bda10b3def759c
getSysPropName
protected String getSysPropName()
{    return "javax.net.ssl.keyStoreType";}
1a87adce45f7169b52224f3c5cd16a5b2927a7d31ec57a21ceb5103af9367c66
getEnvVarName
protected String getEnvVarName()
{    return "FLUME_SSL_KEYSTORE_TYPE";}
5950e372d1ad7eeca1e32d759f00a81ee01ef5ba96fe4e17694b5f338d0463d9
testKeystoreType
public void testKeystoreType()
{    SSLUtil.initGlobalSSLParameters();    String keystoreType = SSLUtil.getGlobalKeystoreType("default");    Assert.assertEquals(expectedValue, keystoreType);}
c62cdf683d51b128dd7108e03281f189030ed4203fd322e9c2bda10b3def759c
getSysPropName
protected String getSysPropName()
{    return "javax.net.ssl.trustStorePassword";}
1a87adce45f7169b52224f3c5cd16a5b2927a7d31ec57a21ceb5103af9367c66
getEnvVarName
protected String getEnvVarName()
{    return "FLUME_SSL_TRUSTSTORE_PASSWORD";}
01ec227aedc13119f138aeaafa78e29e2073dcf969582b95b7b49a8d205c9c98
testTruststorePassword
public void testTruststorePassword()
{    SSLUtil.initGlobalSSLParameters();    String truststorePassword = SSLUtil.getGlobalTruststorePassword();    Assert.assertEquals(expectedValue, truststorePassword);}
c62cdf683d51b128dd7108e03281f189030ed4203fd322e9c2bda10b3def759c
getSysPropName
protected String getSysPropName()
{    return "javax.net.ssl.trustStore";}
1a87adce45f7169b52224f3c5cd16a5b2927a7d31ec57a21ceb5103af9367c66
getEnvVarName
protected String getEnvVarName()
{    return "FLUME_SSL_TRUSTSTORE_PATH";}
82d4c22a9bb786a99ad17d656deb5f4aedc7d78a641ebf8027894bd7f99b5449
testTruststorePath
public void testTruststorePath()
{    SSLUtil.initGlobalSSLParameters();    String truststorePath = SSLUtil.getGlobalTruststorePath();    Assert.assertEquals(expectedValue, truststorePath);}
c62cdf683d51b128dd7108e03281f189030ed4203fd322e9c2bda10b3def759c
getSysPropName
protected String getSysPropName()
{    return "javax.net.ssl.trustStoreType";}
1a87adce45f7169b52224f3c5cd16a5b2927a7d31ec57a21ceb5103af9367c66
getEnvVarName
protected String getEnvVarName()
{    return "FLUME_SSL_TRUSTSTORE_TYPE";}
59030c53f43b5fd6fb54dfc14fabbbef05e9a5a001637cf924a2e669b64d3bd3
testTruststoreType
public void testTruststoreType()
{    SSLUtil.initGlobalSSLParameters();    String truststoreType = SSLUtil.getGlobalTruststoreType(null);    Assert.assertEquals(expectedValue, truststoreType);}
6a1bb22738bbd08ebbb6cc494923dc47f4ed3342640172cf132b2f852b510695
data
public static Collection<?> data()
{    return Arrays.asList(new Object[][] {     { null, null, "default" }, { "sysprop", null, "sysprop" }, { null, "envvar", "envvar" }, { "sysprop", "envvar", "sysprop" } });}
c62cdf683d51b128dd7108e03281f189030ed4203fd322e9c2bda10b3def759c
getSysPropName
protected String getSysPropName()
{    return "javax.net.ssl.trustStoreType";}
1a87adce45f7169b52224f3c5cd16a5b2927a7d31ec57a21ceb5103af9367c66
getEnvVarName
protected String getEnvVarName()
{    return "FLUME_SSL_TRUSTSTORE_TYPE";}
59030c53f43b5fd6fb54dfc14fabbbef05e9a5a001637cf924a2e669b64d3bd3
testTruststoreType
public void testTruststoreType()
{    SSLUtil.initGlobalSSLParameters();    String truststoreType = SSLUtil.getGlobalTruststoreType("default");    Assert.assertEquals(expectedValue, truststoreType);}
2dde8ae3631e374ba0bcd5d0fb1c9dee0c05cf428308593fdac45c20704dac30
allowedFormats
protected List<String> allowedFormats()
{    return Lists.newArrayList("avro", "parquet");}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    this.context = context;    String principal = context.getString(AUTH_PRINCIPAL);    String keytab = context.getString(AUTH_KEYTAB);    String effectiveUser = context.getString(AUTH_PROXY_USER);    this.privilegedExecutor = FlumeAuthenticationUtil.getAuthenticator(principal, keytab).proxyAs(effectiveUser);        String datasetURI = context.getString(CONFIG_KITE_DATASET_URI);    if (datasetURI != null) {        this.datasetUri = URI.create(datasetURI);        this.datasetName = uriToName(datasetUri);    } else {        String repositoryURI = context.getString(CONFIG_KITE_REPO_URI);        Preconditions.checkNotNull(repositoryURI, "No dataset configured. Setting " + CONFIG_KITE_DATASET_URI + " is required.");        this.datasetName = context.getString(CONFIG_KITE_DATASET_NAME);        Preconditions.checkNotNull(datasetName, "No dataset configured. Setting " + CONFIG_KITE_DATASET_URI + " is required.");        String namespace = context.getString(CONFIG_KITE_DATASET_NAMESPACE, DEFAULT_NAMESPACE);        this.datasetUri = new URIBuilder(repositoryURI, namespace, datasetName).build();    }    this.setName(datasetUri.toString());    if (context.getBoolean(CONFIG_SYNCABLE_SYNC_ON_BATCH, DEFAULT_SYNCABLE_SYNC_ON_BATCH)) {        Preconditions.checkArgument(context.getBoolean(CONFIG_FLUSHABLE_COMMIT_ON_BATCH, DEFAULT_FLUSHABLE_COMMIT_ON_BATCH), "Configuration error: " + CONFIG_FLUSHABLE_COMMIT_ON_BATCH + " must be set to true when " + CONFIG_SYNCABLE_SYNC_ON_BATCH + " is set to true.");    }        this.failurePolicy = FAILURE_POLICY_FACTORY.newPolicy(context);        this.batchSize = context.getLong(CONFIG_KITE_BATCH_SIZE, DEFAULT_BATCH_SIZE);    this.rollIntervalSeconds = context.getInteger(CONFIG_KITE_ROLL_INTERVAL, DEFAULT_ROLL_INTERVAL);    this.counter = new SinkCounter(datasetName);}
5b05914888e421f26bff6f39231facdd35759f746a9af780ebac2cf5b2c81932
start
public synchronized void start()
{    this.lastRolledMillis = System.currentTimeMillis();    counter.start();        LOG.info("Started DatasetSink " + getName());    super.start();}
494f4304ac9d44234be19d2f9cee5ee51de512b178623ecae009cd8a7d50c322
roll
 void roll()
{    this.lastRolledMillis = 0L;}
aa244a622f9294c61b247915aad2afda7db8f31710699a1edaa9a2459f7303ea
getWriter
 DatasetWriter<GenericRecord> getWriter()
{    return writer;}
879269d0dede0417998bb715fe6cad9aedaf337c056db935fa1c8ffebba7a434
setWriter
 void setWriter(DatasetWriter<GenericRecord> writer)
{    this.writer = writer;}
0c501fe4af99c24d97d5e2ba107036f440bc3c6dcd514b066ce13dedb3fcf7c2
setParser
 void setParser(EntityParser<GenericRecord> parser)
{    this.parser = parser;}
ad5dd3f5fb917bf9c71149a2f787a2108d452e148c51c4b5e6fef383b0288ccf
setFailurePolicy
 void setFailurePolicy(FailurePolicy failurePolicy)
{    this.failurePolicy = failurePolicy;}
06e1ddba8663c90da407ac517f29ed70555cfe57b0332c9a96e7c696e0255364
stop
public synchronized void stop()
{    counter.stop();    try {                        closeWriter();        commitTransaction();    } catch (EventDeliveryException ex) {        rollbackTransaction();        LOG.warn("Closing the writer failed: " + ex.getLocalizedMessage());        LOG.debug("Exception follows.", ex);            }        LOG.info("Stopped dataset sink: " + getName());    super.stop();}
e52e5e378330fd7f87ee30351bbfcec47b751fee12ece2ef0cfdd77a08c906e1
process
public Status process() throws EventDeliveryException
{    long processedEvents = 0;    try {        if (shouldRoll()) {            closeWriter();            commitTransaction();            createWriter();        }                Preconditions.checkNotNull(writer, "Can't process events with a null writer. This is likely a bug.");        Channel channel = getChannel();                enterTransaction(channel);        for (; processedEvents < batchSize; processedEvents += 1) {            Event event = channel.take();            if (event == null) {                                break;            }            write(event);        }                if (commitOnBatch) {                        if (syncOnBatch && writer instanceof Syncable) {                ((Syncable) writer).sync();            } else if (writer instanceof Flushable) {                ((Flushable) writer).flush();            }            boolean committed = commitTransaction();            Preconditions.checkState(committed, "Tried to commit a batch when there was no transaction");            committedBatch |= committed;        }    } catch (Throwable th) {                        rollbackTransaction();        if (commitOnBatch && committedBatch) {            try {                closeWriter();            } catch (EventDeliveryException ex) {                LOG.warn("Error closing writer there may be temp files that need to" + " be manually recovered: " + ex.getLocalizedMessage());                LOG.debug("Exception follows.", ex);            }        } else {            this.writer = null;        }                Throwables.propagateIfInstanceOf(th, Error.class);        Throwables.propagateIfInstanceOf(th, EventDeliveryException.class);        throw new EventDeliveryException(th);    }    if (processedEvents == 0) {        counter.incrementBatchEmptyCount();        return Status.BACKOFF;    } else if (processedEvents < batchSize) {        counter.incrementBatchUnderflowCount();    } else {        counter.incrementBatchCompleteCount();    }    counter.addToEventDrainSuccessCount(processedEvents);    return Status.READY;}
3266bc309f5b6d8b6a818be3fb0642a77460a49c4b3055525395c6b3ca86e117
write
 void write(Event event) throws EventDeliveryException
{    try {        this.entity = parser.parse(event, reuseEntity ? entity : null);        this.bytesParsed += event.getBody().length;                                        writer.write(entity);    } catch (NonRecoverableEventException ex) {        failurePolicy.handle(event, ex);    } catch (DataFileWriter.AppendWriteException ex) {        failurePolicy.handle(event, ex);    } catch (RuntimeException ex) {        Throwables.propagateIfInstanceOf(ex, EventDeliveryException.class);        throw new EventDeliveryException(ex);    }}
793658403a4ceeb10e8fff292252be102da79a6c1006f222e5b7ba5e647ab041
createWriter
 void createWriter() throws EventDeliveryException
{        committedBatch = false;    try {        View<GenericRecord> view;        view = privilegedExecutor.execute(new PrivilegedAction<Dataset<GenericRecord>>() {            @Override            public Dataset<GenericRecord> run() {                return Datasets.load(datasetUri);            }        });        DatasetDescriptor descriptor = view.getDataset().getDescriptor();        Format format = descriptor.getFormat();        Preconditions.checkArgument(allowedFormats().contains(format.getName()), "Unsupported format: " + format.getName());        Schema newSchema = descriptor.getSchema();        if (datasetSchema == null || !newSchema.equals(datasetSchema)) {            this.datasetSchema = descriptor.getSchema();                        parser = ENTITY_PARSER_FACTORY.newParser(datasetSchema, context);        }        this.reuseEntity = !(Formats.PARQUET.equals(format));                        this.commitOnBatch = context.getBoolean(CONFIG_FLUSHABLE_COMMIT_ON_BATCH, DEFAULT_FLUSHABLE_COMMIT_ON_BATCH) && (Formats.AVRO.equals(format));                        this.syncOnBatch = context.getBoolean(CONFIG_SYNCABLE_SYNC_ON_BATCH, DEFAULT_SYNCABLE_SYNC_ON_BATCH) && (Formats.AVRO.equals(format));        this.datasetName = view.getDataset().getName();        this.writer = view.newWriter();                this.lastRolledMillis = System.currentTimeMillis();        this.bytesParsed = 0L;    } catch (DatasetNotFoundException ex) {        throw new EventDeliveryException("Dataset " + datasetUri + " not found." + " The dataset must be created before Flume can write to it.", ex);    } catch (RuntimeException ex) {        throw new EventDeliveryException("Error trying to open a new" + " writer for dataset " + datasetUri, ex);    }}
f68941c1f126bb2f7d0a380a3a1370f541bcf222b61a2e425ac4d16cf4cfa8f3
run
public Dataset<GenericRecord> run()
{    return Datasets.load(datasetUri);}
b909d28f12af18f7e1f3c65646a53eccf93937ac9bb42a97286b701c3c593ec9
shouldRoll
private boolean shouldRoll()
{    long currentTimeMillis = System.currentTimeMillis();    long elapsedTimeSeconds = TimeUnit.MILLISECONDS.toSeconds(currentTimeMillis - lastRolledMillis);    LOG.debug("Current time: {}, lastRolled: {}, diff: {} sec", new Object[] { currentTimeMillis, lastRolledMillis, elapsedTimeSeconds });    return elapsedTimeSeconds >= rollIntervalSeconds || writer == null;}
b83f031a3eae2ebaebffe76a2c087115369ec7a9285ce44fdd7d5c42d9332f8c
closeWriter
 void closeWriter() throws EventDeliveryException
{    if (writer != null) {        try {            writer.close();            long elapsedTimeSeconds = TimeUnit.MILLISECONDS.toSeconds(System.currentTimeMillis() - lastRolledMillis);            LOG.info("Closed writer for {} after {} seconds and {} bytes parsed", new Object[] { datasetUri, elapsedTimeSeconds, bytesParsed });        } catch (DatasetIOException ex) {            throw new EventDeliveryException("Check HDFS permissions/health. IO" + " error trying to close the  writer for dataset " + datasetUri, ex);        } catch (RuntimeException ex) {            throw new EventDeliveryException("Error trying to close the  writer for" + " dataset " + datasetUri, ex);        } finally {                                                                        this.writer = null;            failurePolicy.close();        }    }}
5a8ac7b6c9cccd9fcc3bcc963e3e67d2a2aee8b258c4f05c3ea617f086f9e06c
enterTransaction
private void enterTransaction(Channel channel) throws EventDeliveryException
{        if (transaction == null) {        this.transaction = channel.getTransaction();        transaction.begin();        failurePolicy = FAILURE_POLICY_FACTORY.newPolicy(context);    }}
29abc97f558f7c23859a1fb810aef037eca2fc94ea65a30181949390bf48b028
commitTransaction
 boolean commitTransaction() throws EventDeliveryException
{    if (transaction != null) {        failurePolicy.sync();        transaction.commit();        transaction.close();        this.transaction = null;        return true;    } else {        return false;    }}
39df09f240f37fe2ffe8ccc5d25cf583c26da720da1f61a3da43df03fb8044ee
rollbackTransaction
private void rollbackTransaction()
{    if (transaction != null) {        try {                                    transaction.rollback();        } catch (RuntimeException ex) {            LOG.error("Transaction rollback failed: " + ex.getLocalizedMessage());            LOG.debug("Exception follows.", ex);        } finally {            transaction.close();            this.transaction = null;        }    }}
ca6109e65de8384100006e77f61064ebbe9658f513f06b44ec46f3cfec34925d
uriToName
private static String uriToName(URI uri)
{    return Registration.lookupDatasetUri(URI.create(uri.getRawSchemeSpecificPart())).second().get("dataset");}
dcc511f35190533c2d6fcc6073d66b12e111f5004c64ff08ccc3609a06ab844d
getBatchSize
public long getBatchSize()
{    return batchSize;}
3fd557b7c6ff3dd050bed7e946556d39a84779b403f8f1b2a705855fd1c8efa3
load
public Schema load(String literal)
{    Preconditions.checkNotNull(literal, "Schema literal cannot be null without a Schema URL");    return new Schema.Parser().parse(literal);}
39da28fac383929a0aae943c4876b7143c54b431880d115f9ac8fe280a21fed6
load
public Schema load(String url) throws IOException
{    Schema.Parser parser = new Schema.Parser();    InputStream is = null;    try {        FileSystem fs = FileSystem.get(URI.create(url), conf);        if (url.toLowerCase(Locale.ENGLISH).startsWith("hdfs:/")) {            is = fs.open(new Path(url));        } else {            is = new URL(url).openStream();        }        return parser.parse(is);    } finally {        if (is != null) {            is.close();        }    }}
69136e49bc124910ed4f616f6e6584fb2f633db176b29d5bdc3e02d6f2d64628
load
public DatumReader<GenericRecord> load(Schema schema)
{        return new GenericDatumReader<GenericRecord>(schema, datasetSchema);}
4de98c74a2abe2a5114d7aad8c8dcdc0fbc90111b058b70d12df387c3076ba50
parse
public GenericRecord parse(Event event, GenericRecord reuse) throws EventDeliveryException, NonRecoverableEventException
{    decoder = DecoderFactory.get().binaryDecoder(event.getBody(), decoder);    try {        DatumReader<GenericRecord> reader = readers.getUnchecked(schema(event));        return reader.read(reuse, decoder);    } catch (IOException ex) {        throw new NonRecoverableEventException("Cannot deserialize event", ex);    } catch (RuntimeException ex) {        throw new NonRecoverableEventException("Cannot deserialize event", ex);    }}
7fb26f356b61ace191b4d701bcbefc817083983ed3ef23a2787f6bf6c8c64355
schema
private static Schema schema(Event event) throws EventDeliveryException, NonRecoverableEventException
{    Map<String, String> headers = event.getHeaders();    String schemaURL = headers.get(AVRO_SCHEMA_URL_HEADER);    try {        if (schemaURL != null) {            return schemasFromURL.get(schemaURL);        } else {            String schemaLiteral = headers.get(AVRO_SCHEMA_LITERAL_HEADER);            if (schemaLiteral == null) {                throw new NonRecoverableEventException("No schema in event headers." + " Headers must include either " + AVRO_SCHEMA_URL_HEADER + " or " + AVRO_SCHEMA_LITERAL_HEADER);            }            return schemasFromLiteral.get(schemaLiteral);        }    } catch (ExecutionException ex) {        throw new EventDeliveryException("Cannot get schema", ex.getCause());    } catch (UncheckedExecutionException ex) {        throw new NonRecoverableEventException("Cannot parse schema", ex.getCause());    }}
f2c31be8e9661583805e55c2a4aca89f605757f4ee66543d04341d4638ab1bd0
build
public EntityParser<GenericRecord> build(Schema datasetSchema, Context config)
{    return new AvroParser(datasetSchema);}
177b04bea1456f2b7e29cb6e131a0494deff679293e1f70d234de40804923266
newParser
public EntityParser<GenericRecord> newParser(Schema datasetSchema, Context config)
{    EntityParser<GenericRecord> parser;    String parserType = config.getString(CONFIG_ENTITY_PARSER, DEFAULT_ENTITY_PARSER);    if (parserType.equals(AVRO_ENTITY_PARSER)) {        parser = new AvroParser.Builder().build(datasetSchema, config);    } else {        Class<? extends EntityParser.Builder> builderClass;        Class c;        try {            c = Class.forName(parserType);        } catch (ClassNotFoundException ex) {            throw new IllegalArgumentException("EntityParser.Builder class " + parserType + " not found. Must set " + CONFIG_ENTITY_PARSER + " to a class that implements EntityParser.Builder or to a builtin" + " parser: " + Arrays.toString(AVAILABLE_PARSERS), ex);        }        if (c != null && EntityParser.Builder.class.isAssignableFrom(c)) {            builderClass = c;        } else {            throw new IllegalArgumentException("Class " + parserType + " does not" + " implement EntityParser.Builder. Must set " + CONFIG_ENTITY_PARSER + " to a class that extends" + " EntityParser.Builder or to a builtin parser: " + Arrays.toString(AVAILABLE_PARSERS));        }        EntityParser.Builder<GenericRecord> builder;        try {            builder = builderClass.newInstance();        } catch (InstantiationException ex) {            throw new IllegalArgumentException("Can't instantiate class " + parserType + ". Must set " + CONFIG_ENTITY_PARSER + " to a class" + " that extends EntityParser.Builder or to a builtin parser: " + Arrays.toString(AVAILABLE_PARSERS), ex);        } catch (IllegalAccessException ex) {            throw new IllegalArgumentException("Can't instantiate class " + parserType + ". Must set " + CONFIG_ENTITY_PARSER + " to a class" + " that extends EntityParser.Builder or to a builtin parser: " + Arrays.toString(AVAILABLE_PARSERS), ex);        }        parser = builder.build(datasetSchema, config);    }    return parser;}
b5b7488d5c2761db3705c993da05e219213f8cbb0c365496cdb7d4fe2c0bd7b4
newPolicy
public FailurePolicy newPolicy(Context config)
{    FailurePolicy policy;    String policyType = config.getString(CONFIG_FAILURE_POLICY, DEFAULT_FAILURE_POLICY);    if (policyType.equals(RETRY_FAILURE_POLICY)) {        policy = new RetryPolicy.Builder().build(config);    } else if (policyType.equals(SAVE_FAILURE_POLICY)) {        policy = new SavePolicy.Builder().build(config);    } else {        Class<? extends FailurePolicy.Builder> builderClass;        Class c;        try {            c = Class.forName(policyType);        } catch (ClassNotFoundException ex) {            throw new IllegalArgumentException("FailurePolicy.Builder class " + policyType + " not found. Must set " + CONFIG_FAILURE_POLICY + " to a class that implements FailurePolicy.Builder or to a builtin" + " policy: " + Arrays.toString(AVAILABLE_POLICIES), ex);        }        if (c != null && FailurePolicy.Builder.class.isAssignableFrom(c)) {            builderClass = c;        } else {            throw new IllegalArgumentException("Class " + policyType + " does not" + " implement FailurePolicy.Builder. Must set " + CONFIG_FAILURE_POLICY + " to a class that extends" + " FailurePolicy.Builder or to a builtin policy: " + Arrays.toString(AVAILABLE_POLICIES));        }        FailurePolicy.Builder builder;        try {            builder = builderClass.newInstance();        } catch (InstantiationException ex) {            throw new IllegalArgumentException("Can't instantiate class " + policyType + ". Must set " + CONFIG_FAILURE_POLICY + " to a class" + " that extends FailurePolicy.Builder or to a builtin policy: " + Arrays.toString(AVAILABLE_POLICIES), ex);        } catch (IllegalAccessException ex) {            throw new IllegalArgumentException("Can't instantiate class " + policyType + ". Must set " + CONFIG_FAILURE_POLICY + " to a class" + " that extends FailurePolicy.Builder or to a builtin policy: " + Arrays.toString(AVAILABLE_POLICIES), ex);        }        policy = builder.build(config);    }    return policy;}
727dfbf1fb7e5e787e436b970211c78efe5033f1894d0c9ba77c4c276a6e9fd8
handle
public void handle(Event event, Throwable cause) throws EventDeliveryException
{    LOG.error("Event delivery failed: " + cause.getLocalizedMessage());    LOG.debug("Exception follows.", cause);    throw new EventDeliveryException(cause);}
4223629f3a2ce615a5ffd569b849293fc089314d21e923d027433068e2393f29
sync
public void sync() throws EventDeliveryException
{}
bbf60bf143f343ea4248dafb0d14a8d1673ff69cc0d175f74cf81756a6ac2087
close
public void close() throws EventDeliveryException
{}
afa7d2a63bc89ece9f90ddbb6e0d01f1aee2d5b22b9d72efa91c3410991f1ad8
build
public FailurePolicy build(Context config)
{    return new RetryPolicy();}
727dfbf1fb7e5e787e436b970211c78efe5033f1894d0c9ba77c4c276a6e9fd8
handle
public void handle(Event event, Throwable cause) throws EventDeliveryException
{    try {        if (writer == null) {            writer = dataset.newWriter();        }        final AvroFlumeEvent avroEvent = new AvroFlumeEvent();        avroEvent.setBody(ByteBuffer.wrap(event.getBody()));        avroEvent.setHeaders(toCharSeqMap(event.getHeaders()));        writer.write(avroEvent);        nEventsHandled++;    } catch (RuntimeException ex) {        throw new EventDeliveryException(ex);    }}
4223629f3a2ce615a5ffd569b849293fc089314d21e923d027433068e2393f29
sync
public void sync() throws EventDeliveryException
{    if (nEventsHandled > 0) {        if (Formats.PARQUET.equals(dataset.getDataset().getDescriptor().getFormat())) {                                    close();        } else {            if (writer instanceof Syncable) {                ((Syncable) writer).sync();            }        }    }}
bbf60bf143f343ea4248dafb0d14a8d1673ff69cc0d175f74cf81756a6ac2087
close
public void close() throws EventDeliveryException
{    if (nEventsHandled > 0) {        try {            writer.close();        } catch (RuntimeException ex) {            throw new EventDeliveryException(ex);        } finally {            writer = null;            nEventsHandled = 0;        }    }}
1fe08fdec01aff5e5b8db67ec169d92654373e11e1e3a73014b164758ec613cc
toCharSeqMap
private static Map<CharSequence, CharSequence> toCharSeqMap(Map<String, String> map)
{    return Maps.<CharSequence, CharSequence>newHashMap(map);}
afa7d2a63bc89ece9f90ddbb6e0d01f1aee2d5b22b9d72efa91c3410991f1ad8
build
public FailurePolicy build(Context config)
{    return new SavePolicy(config);}
7b34ffe7cbe4c2dd9018689e7b47f173ab94b4461d95377720f3d8d71eda701d
saveSchema
public static void saveSchema() throws IOException
{    oldTestBuildDataProp = System.getProperty(TEST_BUILD_DATA_KEY);    System.setProperty(TEST_BUILD_DATA_KEY, DFS_DIR);    FileWriter schema = new FileWriter(SCHEMA_FILE);    schema.append(RECORD_SCHEMA.toString());    schema.close();}
ece20925fce346cce8156286e6fb6c3527c97916e4c6ffa79543eac2f6cc7e6d
tearDownClass
public static void tearDownClass()
{    FileUtils.deleteQuietly(new File(DFS_DIR));    if (oldTestBuildDataProp != null) {        System.setProperty(TEST_BUILD_DATA_KEY, oldTestBuildDataProp);    }}
f505fa1aae91d29b4928b5d692955b3ab79ae1f312b432fc3b61309431da6039
setup
public void setup() throws EventDeliveryException
{    Datasets.delete(FILE_DATASET_URI);    Datasets.create(FILE_DATASET_URI, DESCRIPTOR);    this.config = new Context();    config.put("keep-alive", "0");    this.in = new MemoryChannel();    Configurables.configure(in, config);    config.put(DatasetSinkConstants.CONFIG_KITE_DATASET_URI, FILE_DATASET_URI);    GenericRecordBuilder builder = new GenericRecordBuilder(RECORD_SCHEMA);    expected = Lists.<GenericRecord>newArrayList(builder.set("id", "1").set("msg", "msg1").build(), builder.set("id", "2").set("msg", "msg2").build(), builder.set("id", "3").set("msg", "msg3").build());    putToChannel(in, Iterables.transform(expected, new Function<GenericRecord, Event>() {        private int i = 0;        @Override        public Event apply(@Nullable GenericRecord rec) {            this.i += 1;            boolean useURI = (i % 2) == 0;            return event(rec, RECORD_SCHEMA, SCHEMA_FILE, useURI);        }    }));}
01da8d4dc43f8d9ea7b0d7e62bcd2605fd58f68330c363ff899131ef376aaa5f
apply
public Event apply(@Nullable GenericRecord rec)
{    this.i += 1;    boolean useURI = (i % 2) == 0;    return event(rec, RECORD_SCHEMA, SCHEMA_FILE, useURI);}
ec8b6259c87a96a7e78ab8ec13a826f2caf0d2a1c593d4aec011e181f3e17bbf
teardown
public void teardown()
{    Datasets.delete(FILE_DATASET_URI);}
f93467e5402c900b5c55f13baec85f17b99380d614cc595a73e710593e2b4ce2
testOldConfig
public void testOldConfig() throws EventDeliveryException
{    config.put(DatasetSinkConstants.CONFIG_KITE_DATASET_URI, null);    config.put(DatasetSinkConstants.CONFIG_KITE_REPO_URI, FILE_REPO_URI);    config.put(DatasetSinkConstants.CONFIG_KITE_DATASET_NAME, DATASET_NAME);    DatasetSink sink = sink(in, config);        sink.start();    sink.process();    sink.stop();    Assert.assertEquals(Sets.newHashSet(expected), read(Datasets.load(FILE_DATASET_URI)));    Assert.assertEquals("Should have committed", 0, remaining(in));}
86a9a4c6eb6144ba8df49eac278f943281e1b98280c4aef537f3ca58a10e8ab1
testDatasetUriOverridesOldConfig
public void testDatasetUriOverridesOldConfig() throws EventDeliveryException
{        config.put(DatasetSinkConstants.CONFIG_KITE_REPO_URI, "bad uri");    config.put(DatasetSinkConstants.CONFIG_KITE_DATASET_NAME, "");    DatasetSink sink = sink(in, config);        sink.start();    sink.process();    sink.stop();    Assert.assertEquals(Sets.newHashSet(expected), read(Datasets.load(FILE_DATASET_URI)));    Assert.assertEquals("Should have committed", 0, remaining(in));}
4b5faa2c794ccecf466ef08be9fbb3dfb3068fca82bf330cf8138de621c27429
testFileStore
public void testFileStore() throws EventDeliveryException, NonRecoverableEventException, NonRecoverableEventException
{    DatasetSink sink = sink(in, config);        sink.start();    sink.process();    sink.stop();    Assert.assertEquals(Sets.newHashSet(expected), read(Datasets.load(FILE_DATASET_URI)));    Assert.assertEquals("Should have committed", 0, remaining(in));}
a8acb73e2036ed00a544fdc2c2c5c965a5640f1914ee1a5a4d80846becb5804c
testParquetDataset
public void testParquetDataset() throws EventDeliveryException
{    Datasets.delete(FILE_DATASET_URI);    Dataset<GenericRecord> created = Datasets.create(FILE_DATASET_URI, new DatasetDescriptor.Builder(DESCRIPTOR).format("parquet").build());    DatasetSink sink = sink(in, config);        sink.start();    sink.process();        assertThrows("Transaction should still be open", IllegalStateException.class, new Callable() {        @Override        public Object call() throws EventDeliveryException {            in.getTransaction().begin();            return null;        }    });        Assert.assertEquals("Should not have committed", 0, read(created).size());    sink.stop();    Assert.assertEquals(Sets.newHashSet(expected), read(created));    Assert.assertEquals("Should have committed", 0, remaining(in));}
cf0cc9d91f4d61ab3cd00dcf497818d42c3b3708d257acb0d9ac7ce7334058b2
call
public Object call() throws EventDeliveryException
{    in.getTransaction().begin();    return null;}
3ce9ae5cb84fc62d8a5a94e40da13a3933032ecfde4edd107a3f8a63449a65b8
testPartitionedData
public void testPartitionedData() throws EventDeliveryException
{    URI partitionedUri = URI.create("dataset:file:target/test_repo/partitioned");    try {        Datasets.create(partitionedUri, new DatasetDescriptor.Builder(DESCRIPTOR).partitionStrategy(new PartitionStrategy.Builder().identity("id",         10).build()).build());        config.put(DatasetSinkConstants.CONFIG_KITE_DATASET_URI, partitionedUri.toString());        DatasetSink sink = sink(in, config);                sink.start();        sink.process();        sink.stop();        Assert.assertEquals(Sets.newHashSet(expected), read(Datasets.load(partitionedUri)));        Assert.assertEquals("Should have committed", 0, remaining(in));    } finally {        if (Datasets.exists(partitionedUri)) {            Datasets.delete(partitionedUri);        }    }}
f9d73bb6cfc10f3c28b2ee5b1e7d487bee402075a14d34665e5ddca3e28d7721
testStartBeforeDatasetCreated
public void testStartBeforeDatasetCreated() throws EventDeliveryException
{        Datasets.delete(FILE_DATASET_URI);    DatasetSink sink = sink(in, config);        sink.start();        try {        sink.process();        Assert.fail("Should have thrown an exception: no such dataset");    } catch (EventDeliveryException e) {        }        Datasets.create(FILE_DATASET_URI, DESCRIPTOR);        sink.process();    sink.stop();    Assert.assertEquals(Sets.newHashSet(expected), read(Datasets.load(FILE_DATASET_URI)));    Assert.assertEquals("Should have committed", 0, remaining(in));}
14c78495b0e58c95406efb5d1d4c8ba474090aeca307c099f72795196c8aad86
testDatasetUpdate
public void testDatasetUpdate() throws EventDeliveryException
{        GenericRecordBuilder updatedBuilder = new GenericRecordBuilder(UPDATED_SCHEMA);    GenericData.Record updatedRecord = updatedBuilder.set("id", "0").set("priority", 1).set("msg", "Priority 1 message!").build();        Set<GenericRecord> expectedAsUpdated = Sets.newHashSet();    for (GenericRecord record : expected) {        expectedAsUpdated.add(updatedBuilder.clear("priority").set("id", record.get("id")).set("msg", record.get("msg")).build());    }    expectedAsUpdated.add(updatedRecord);    DatasetSink sink = sink(in, config);        sink.start();    sink.process();        DatasetDescriptor updated = new DatasetDescriptor.Builder(Datasets.load(FILE_DATASET_URI).getDataset().getDescriptor()).schema(UPDATED_SCHEMA).build();    Datasets.update(FILE_DATASET_URI, updated);        sink.roll();        putToChannel(in, event(updatedRecord, UPDATED_SCHEMA, null, false));        sink.process();    sink.stop();    Assert.assertEquals(expectedAsUpdated, read(Datasets.load(FILE_DATASET_URI)));    Assert.assertEquals("Should have committed", 0, remaining(in));}
c7281453411c307fcc023ddb83a2e439f92ff6b87daac02280ae0cb8d5410b0d
testMiniClusterStore
public void testMiniClusterStore() throws EventDeliveryException, IOException
{        MiniDFSCluster cluster = new MiniDFSCluster.Builder(new Configuration()).build();    FileSystem dfs = cluster.getFileSystem();    Configuration conf = dfs.getConf();    URI hdfsUri = URI.create("dataset:" + conf.get("fs.defaultFS") + "/tmp/repo" + DATASET_NAME);    try {                Datasets.create(hdfsUri, DESCRIPTOR);                config.put(DatasetSinkConstants.CONFIG_KITE_DATASET_URI, hdfsUri.toString());        DatasetSink sink = sink(in, config);                sink.start();        sink.process();        sink.stop();        Assert.assertEquals(Sets.newHashSet(expected), read(Datasets.load(hdfsUri)));        Assert.assertEquals("Should have committed", 0, remaining(in));    } finally {        if (Datasets.exists(hdfsUri)) {            Datasets.delete(hdfsUri);        }        cluster.shutdown();    }}
d0a12239fd1bbf2603288db4d8a2e699218b3800f51013399d37b107f4e3fbbb
testBatchSize
public void testBatchSize() throws EventDeliveryException
{    DatasetSink sink = sink(in, config);        config.put("kite.batchSize", "2");    Configurables.configure(sink, config);    sink.start();        sink.process();        sink.roll();        sink.process();    Assert.assertEquals(Sets.newHashSet(expected.subList(0, 2)), read(Datasets.load(FILE_DATASET_URI)));    Assert.assertEquals("Should have committed", 0, remaining(in));        sink.roll();        sink.process();    Assert.assertEquals(Sets.newHashSet(expected), read(Datasets.load(FILE_DATASET_URI)));    sink.stop();}
03fa35ab118cddee84342255ba64d91f9a2639c4823b7140ad125615701d9bf7
testTimedFileRolling
public void testTimedFileRolling() throws EventDeliveryException, InterruptedException
{            config.put("kite.rollInterval", "1");    DatasetSink sink = sink(in, config);    Dataset<GenericRecord> records = Datasets.load(FILE_DATASET_URI);        sink.start();    sink.process();    Assert.assertEquals("Should have committed", 0, remaining(in));        Thread.sleep(1100);        sink.process();    Assert.assertEquals(Sets.newHashSet(expected), read(records));        sink.stop();}
d8e0dd85cf0dd66682cc91ccd4bc476469fa7c24635a3481c8104bdb088b0518
testCompatibleSchemas
public void testCompatibleSchemas() throws EventDeliveryException
{    DatasetSink sink = sink(in, config);        GenericRecordBuilder compatBuilder = new GenericRecordBuilder(COMPATIBLE_SCHEMA);    GenericData.Record compatibleRecord = compatBuilder.set("id", "0").build();        putToChannel(in, event(compatibleRecord, COMPATIBLE_SCHEMA, null, false));            GenericRecordBuilder builder = new GenericRecordBuilder(RECORD_SCHEMA);    GenericData.Record expectedRecord = builder.set("id", "0").build();    expected.add(expectedRecord);        sink.start();    sink.process();    sink.stop();    Assert.assertEquals(Sets.newHashSet(expected), read(Datasets.load(FILE_DATASET_URI)));    Assert.assertEquals("Should have committed", 0, remaining(in));}
60adb402a38294b8e52c85dfaa98e97258f6a61d7020b478ed9b8b4f712d6e4d
testIncompatibleSchemas
public void testIncompatibleSchemas() throws EventDeliveryException
{    final DatasetSink sink = sink(in, config);    GenericRecordBuilder builder = new GenericRecordBuilder(INCOMPATIBLE_SCHEMA);    GenericData.Record rec = builder.set("username", "koala").build();    putToChannel(in, event(rec, INCOMPATIBLE_SCHEMA, null, false));        sink.start();    assertThrows("Should fail", EventDeliveryException.class, new Callable() {        @Override        public Object call() throws EventDeliveryException {            sink.process();            return null;        }    });    sink.stop();    Assert.assertEquals("Should have rolled back", expected.size() + 1, remaining(in));}
cf0cc9d91f4d61ab3cd00dcf497818d42c3b3708d257acb0d9ac7ce7334058b2
call
public Object call() throws EventDeliveryException
{    sink.process();    return null;}
24549e9fd510d4186c3e0f58ca6080905b733c64272d4ab2753851ae1c2bcc7c
testMissingSchema
public void testMissingSchema() throws EventDeliveryException
{    final DatasetSink sink = sink(in, config);    Event badEvent = new SimpleEvent();    badEvent.setHeaders(Maps.<String, String>newHashMap());    badEvent.setBody(serialize(expected.get(0), RECORD_SCHEMA));    putToChannel(in, badEvent);        sink.start();    assertThrows("Should fail", EventDeliveryException.class, new Callable() {        @Override        public Object call() throws EventDeliveryException {            sink.process();            return null;        }    });    sink.stop();    Assert.assertEquals("Should have rolled back", expected.size() + 1, remaining(in));}
cf0cc9d91f4d61ab3cd00dcf497818d42c3b3708d257acb0d9ac7ce7334058b2
call
public Object call() throws EventDeliveryException
{    sink.process();    return null;}
96ff3eeba57c4c72d764396ef61ac72d887a6300fd411a3cfd8259cc4ab7050a
testFileStoreWithSavePolicy
public void testFileStoreWithSavePolicy() throws EventDeliveryException
{    if (Datasets.exists(ERROR_DATASET_URI)) {        Datasets.delete(ERROR_DATASET_URI);    }    config.put(DatasetSinkConstants.CONFIG_FAILURE_POLICY, DatasetSinkConstants.SAVE_FAILURE_POLICY);    config.put(DatasetSinkConstants.CONFIG_KITE_ERROR_DATASET_URI, ERROR_DATASET_URI);    DatasetSink sink = sink(in, config);        sink.start();    sink.process();    sink.stop();    Assert.assertEquals(Sets.newHashSet(expected), read(Datasets.load(FILE_DATASET_URI)));    Assert.assertEquals("Should have committed", 0, remaining(in));}
996d3d8a0b86fd413a4993a4b8501d9561aa1f7ad0a0e4780e8e9e3fdfda0861
testMissingSchemaWithSavePolicy
public void testMissingSchemaWithSavePolicy() throws EventDeliveryException
{    if (Datasets.exists(ERROR_DATASET_URI)) {        Datasets.delete(ERROR_DATASET_URI);    }    config.put(DatasetSinkConstants.CONFIG_FAILURE_POLICY, DatasetSinkConstants.SAVE_FAILURE_POLICY);    config.put(DatasetSinkConstants.CONFIG_KITE_ERROR_DATASET_URI, ERROR_DATASET_URI);    final DatasetSink sink = sink(in, config);    Event badEvent = new SimpleEvent();    badEvent.setHeaders(Maps.<String, String>newHashMap());    badEvent.setBody(serialize(expected.get(0), RECORD_SCHEMA));    putToChannel(in, badEvent);        sink.start();    sink.process();    sink.stop();    Assert.assertEquals("Good records should have been written", Sets.newHashSet(expected), read(Datasets.load(FILE_DATASET_URI)));    Assert.assertEquals("Should not have rolled back", 0, remaining(in));    Assert.assertEquals("Should have saved the bad event", Sets.newHashSet(AvroFlumeEvent.newBuilder().setBody(ByteBuffer.wrap(badEvent.getBody())).setHeaders(toUtf8Map(badEvent.getHeaders())).build()), read(Datasets.load(ERROR_DATASET_URI, AvroFlumeEvent.class)));}
e6af8661ad0f03ace2dbf3260cee7e62515d22d5d1c2d314fdc4d11831505b54
testSerializedWithIncompatibleSchemasWithSavePolicy
public void testSerializedWithIncompatibleSchemasWithSavePolicy() throws EventDeliveryException
{    if (Datasets.exists(ERROR_DATASET_URI)) {        Datasets.delete(ERROR_DATASET_URI);    }    config.put(DatasetSinkConstants.CONFIG_FAILURE_POLICY, DatasetSinkConstants.SAVE_FAILURE_POLICY);    config.put(DatasetSinkConstants.CONFIG_KITE_ERROR_DATASET_URI, ERROR_DATASET_URI);    final DatasetSink sink = sink(in, config);    GenericRecordBuilder builder = new GenericRecordBuilder(INCOMPATIBLE_SCHEMA);    GenericData.Record rec = builder.set("username", "koala").build();            Event badEvent = event(rec, INCOMPATIBLE_SCHEMA, SCHEMA_FILE, true);    putToChannel(in, badEvent);        sink.start();    sink.process();    sink.stop();    Assert.assertEquals("Good records should have been written", Sets.newHashSet(expected), read(Datasets.load(FILE_DATASET_URI)));    Assert.assertEquals("Should not have rolled back", 0, remaining(in));    Assert.assertEquals("Should have saved the bad event", Sets.newHashSet(AvroFlumeEvent.newBuilder().setBody(ByteBuffer.wrap(badEvent.getBody())).setHeaders(toUtf8Map(badEvent.getHeaders())).build()), read(Datasets.load(ERROR_DATASET_URI, AvroFlumeEvent.class)));}
37293e2d6ff7aaba120c768f22c8627292a737b043f18809075f9719fa14bb74
testSerializedWithIncompatibleSchemas
public void testSerializedWithIncompatibleSchemas() throws EventDeliveryException
{    final DatasetSink sink = sink(in, config);    GenericRecordBuilder builder = new GenericRecordBuilder(INCOMPATIBLE_SCHEMA);    GenericData.Record rec = builder.set("username", "koala").build();            putToChannel(in, event(rec, INCOMPATIBLE_SCHEMA, SCHEMA_FILE, true));        sink.start();    assertThrows("Should fail", EventDeliveryException.class, new Callable() {        @Override        public Object call() throws EventDeliveryException {            sink.process();            return null;        }    });    sink.stop();    Assert.assertEquals("Should have rolled back", expected.size() + 1, remaining(in));}
cf0cc9d91f4d61ab3cd00dcf497818d42c3b3708d257acb0d9ac7ce7334058b2
call
public Object call() throws EventDeliveryException
{    sink.process();    return null;}
d1da70837638514603642d147d0580a8f38385ad6e85b7e3d0fdd82ba4cac7af
testCommitOnBatch
public void testCommitOnBatch() throws EventDeliveryException
{    DatasetSink sink = sink(in, config);        sink.start();    sink.process();        Assert.assertEquals("Should have committed", 0, remaining(in));        Assert.assertEquals(0, read(Datasets.load(FILE_DATASET_URI)).size());    sink.stop();    Assert.assertEquals(Sets.newHashSet(expected), read(Datasets.load(FILE_DATASET_URI)));}
4b322d18d59cdf132d1fb62dcc131fa3989c539859ee0f56376e7b19c757c2e3
testCommitOnBatchFalse
public void testCommitOnBatchFalse() throws EventDeliveryException
{    config.put(DatasetSinkConstants.CONFIG_FLUSHABLE_COMMIT_ON_BATCH, Boolean.toString(false));    config.put(DatasetSinkConstants.CONFIG_SYNCABLE_SYNC_ON_BATCH, Boolean.toString(false));    DatasetSink sink = sink(in, config);        sink.start();    sink.process();        assertThrows("Transaction should still be open", IllegalStateException.class, new Callable() {        @Override        public Object call() throws EventDeliveryException {            in.getTransaction().begin();            return null;        }    });        Assert.assertEquals(0, read(Datasets.load(FILE_DATASET_URI)).size());    sink.stop();    Assert.assertEquals(Sets.newHashSet(expected), read(Datasets.load(FILE_DATASET_URI)));        Assert.assertEquals("Should have committed", 0, remaining(in));}
cf0cc9d91f4d61ab3cd00dcf497818d42c3b3708d257acb0d9ac7ce7334058b2
call
public Object call() throws EventDeliveryException
{    in.getTransaction().begin();    return null;}
5caec57ba400b4ea47fb80d5fa07ad9337979ae281a8931c43b55264e573e4c7
testCommitOnBatchFalseSyncOnBatchTrue
public void testCommitOnBatchFalseSyncOnBatchTrue() throws EventDeliveryException
{    config.put(DatasetSinkConstants.CONFIG_FLUSHABLE_COMMIT_ON_BATCH, Boolean.toString(false));    config.put(DatasetSinkConstants.CONFIG_SYNCABLE_SYNC_ON_BATCH, Boolean.toString(true));    try {        sink(in, config);        Assert.fail("Should have thrown IllegalArgumentException");    } catch (IllegalArgumentException ex) {        }}
95ec6542499d6ddb3e83def7cc67ec371f9c12b9ee89ef79e7007e81e34e343d
testCloseAndCreateWriter
public void testCloseAndCreateWriter() throws EventDeliveryException
{    config.put(DatasetSinkConstants.CONFIG_FLUSHABLE_COMMIT_ON_BATCH, Boolean.toString(false));    config.put(DatasetSinkConstants.CONFIG_SYNCABLE_SYNC_ON_BATCH, Boolean.toString(false));    DatasetSink sink = sink(in, config);        sink.start();    sink.process();    sink.closeWriter();    sink.commitTransaction();    sink.createWriter();    Assert.assertNotNull("Writer should not be null", sink.getWriter());    Assert.assertEquals("Should have committed", 0, remaining(in));    sink.stop();    Assert.assertEquals(Sets.newHashSet(expected), read(Datasets.load(FILE_DATASET_URI)));}
c7db01f7d0490d6467d22062b3488e51dac9e21100b9b3846156c3eafc119010
testCloseWriter
public void testCloseWriter() throws EventDeliveryException
{    config.put(DatasetSinkConstants.CONFIG_FLUSHABLE_COMMIT_ON_BATCH, Boolean.toString(false));    config.put(DatasetSinkConstants.CONFIG_SYNCABLE_SYNC_ON_BATCH, Boolean.toString(false));    DatasetSink sink = sink(in, config);        sink.start();    sink.process();    sink.closeWriter();    sink.commitTransaction();    Assert.assertNull("Writer should be null", sink.getWriter());    Assert.assertEquals("Should have committed", 0, remaining(in));    sink.stop();    Assert.assertEquals(Sets.newHashSet(expected), read(Datasets.load(FILE_DATASET_URI)));}
2bb8318e8f6dd7589bd75210b2c53afc2624993457aec55d8f8b9dbf0846a664
testCreateWriter
public void testCreateWriter() throws EventDeliveryException
{    config.put(DatasetSinkConstants.CONFIG_FLUSHABLE_COMMIT_ON_BATCH, Boolean.toString(false));    config.put(DatasetSinkConstants.CONFIG_SYNCABLE_SYNC_ON_BATCH, Boolean.toString(false));    DatasetSink sink = sink(in, config);        sink.start();    sink.process();    sink.commitTransaction();    sink.createWriter();    Assert.assertNotNull("Writer should not be null", sink.getWriter());    Assert.assertEquals("Should have committed", 0, remaining(in));    sink.stop();    Assert.assertEquals(0, read(Datasets.load(FILE_DATASET_URI)).size());}
16bbab8121b174047f8039b929c44a66667611ed6e32a2667d55ef45eb0c4340
testAppendWriteExceptionInvokesPolicy
public void testAppendWriteExceptionInvokesPolicy() throws EventDeliveryException, NonRecoverableEventException
{    DatasetSink sink = sink(in, config);        sink.start();    sink.process();        Event mockEvent = mock(Event.class);    when(mockEvent.getBody()).thenReturn(new byte[] { 0x01 });        GenericRecord mockRecord = mock(GenericRecord.class);        EntityParser<GenericRecord> mockParser = mock(EntityParser.class);    when(mockParser.parse(eq(mockEvent), any(GenericRecord.class))).thenReturn(mockRecord);    sink.setParser(mockParser);        FailurePolicy mockFailurePolicy = mock(FailurePolicy.class);    sink.setFailurePolicy(mockFailurePolicy);        DatasetWriter<GenericRecord> mockWriter = mock(DatasetWriter.class);    doThrow(new DataFileWriter.AppendWriteException(new IOException())).when(mockWriter).write(mockRecord);    sink.setWriter(mockWriter);    sink.write(mockEvent);        verify(mockFailurePolicy).handle(eq(mockEvent), any(Throwable.class));    sink.stop();}
fb16f9ca8c11d9c1bf087e5a84cd77ee63c8bf15e59b477e73dbbf44b264ccdb
testRuntimeExceptionThrowsEventDeliveryException
public void testRuntimeExceptionThrowsEventDeliveryException() throws EventDeliveryException, NonRecoverableEventException
{    DatasetSink sink = sink(in, config);        sink.start();    sink.process();        Event mockEvent = mock(Event.class);    when(mockEvent.getBody()).thenReturn(new byte[] { 0x01 });        GenericRecord mockRecord = mock(GenericRecord.class);        EntityParser<GenericRecord> mockParser = mock(EntityParser.class);    when(mockParser.parse(eq(mockEvent), any(GenericRecord.class))).thenReturn(mockRecord);    sink.setParser(mockParser);        FailurePolicy mockFailurePolicy = mock(FailurePolicy.class);    sink.setFailurePolicy(mockFailurePolicy);        DatasetWriter<GenericRecord> mockWriter = mock(DatasetWriter.class);    doThrow(new RuntimeException()).when(mockWriter).write(mockRecord);    sink.setWriter(mockWriter);    try {        sink.write(mockEvent);        Assert.fail("Should throw EventDeliveryException");    } catch (EventDeliveryException ex) {    }        verify(mockFailurePolicy, never()).handle(eq(mockEvent), any(Throwable.class));    sink.stop();}
b38bce6f2ba02f13cd249478ce8db905ea0129eb0614c07ca122c3e03bc139c7
testProcessHandlesNullWriter
public void testProcessHandlesNullWriter() throws EventDeliveryException, NonRecoverableEventException, NonRecoverableEventException
{    DatasetSink sink = sink(in, config);        sink.start();    sink.process();        sink.setWriter(null);        sink.process();    sink.stop();    Assert.assertEquals("Should have committed", 0, remaining(in));}
51ead6a46f6862ef0e087a223e0612ece7bbc29702316a6007406a0521371611
sink
public static DatasetSink sink(Channel in, Context config)
{    DatasetSink sink = new DatasetSink();    sink.setChannel(in);    Configurables.configure(sink, config);    return sink;}
cf389938f35dace4ea56c7683d7c897a1087f4185fb16906975ebc2eaaac895a
read
public static HashSet<T> read(View<T> view)
{    DatasetReader<T> reader = null;    try {        reader = view.newReader();        return Sets.newHashSet(reader.iterator());    } finally {        if (reader != null) {            reader.close();        }    }}
e580c94cd519fbd6505bf80b0927c640b04ae60fd7ed48ecf390fdd692fc30b0
remaining
public static int remaining(Channel ch) throws EventDeliveryException
{    Transaction t = ch.getTransaction();    try {        t.begin();        int count = 0;        while (ch.take() != null) {            count += 1;        }        t.commit();        return count;    } catch (Throwable th) {        t.rollback();        Throwables.propagateIfInstanceOf(th, Error.class);        Throwables.propagateIfInstanceOf(th, EventDeliveryException.class);        throw new EventDeliveryException(th);    } finally {        t.close();    }}
4ddb535b184bcaca374f3e31e254f7ab615739725d85d333238f2fa7bb8c0429
putToChannel
public static void putToChannel(Channel in, Event... records) throws EventDeliveryException
{    putToChannel(in, Arrays.asList(records));}
33e966c09bde3e0183d0a7d0bf7737a9793688073d978a84d9f41851793d35b1
putToChannel
public static void putToChannel(Channel in, Iterable<Event> records) throws EventDeliveryException
{    Transaction t = in.getTransaction();    try {        t.begin();        for (Event record : records) {            in.put(record);        }        t.commit();    } catch (Throwable th) {        t.rollback();        Throwables.propagateIfInstanceOf(th, Error.class);        Throwables.propagateIfInstanceOf(th, EventDeliveryException.class);        throw new EventDeliveryException(th);    } finally {        t.close();    }}
39eca75495668b699b9b763c8ef1304325eab5b0939675a4c7cb4a85f40d2ad7
event
public static Event event(Object datum, Schema schema, File file, boolean useURI)
{    Map<String, String> headers = Maps.newHashMap();    if (useURI) {        headers.put(DatasetSinkConstants.AVRO_SCHEMA_URL_HEADER, file.getAbsoluteFile().toURI().toString());    } else {        headers.put(DatasetSinkConstants.AVRO_SCHEMA_LITERAL_HEADER, schema.toString());    }    Event e = new SimpleEvent();    e.setBody(serialize(datum, schema));    e.setHeaders(headers);    return e;}
f3d7024b1f394a9a21254ca164e7f5d1dbee23dbe97570f7921c9c63bddff576
serialize
public static byte[] serialize(Object datum, Schema schema)
{    ByteArrayOutputStream out = new ByteArrayOutputStream();    Encoder encoder = EncoderFactory.get().binaryEncoder(out, null);    ReflectDatumWriter writer = new ReflectDatumWriter(schema);    try {        writer.write(datum, encoder);        encoder.flush();    } catch (IOException ex) {        Throwables.propagate(ex);    }    return out.toByteArray();}
d54ae37b15047137d77db38fa1b84620ac079ebc22c52523675be58707583c68
assertThrows
public static void assertThrows(String message, Class<? extends Exception> expected, Callable callable)
{    try {        callable.call();        Assert.fail("No exception was thrown (" + message + "), expected: " + expected.getName());    } catch (Exception actual) {        Assert.assertEquals(message, expected, actual.getClass());    }}
6601c0eaf12a9bfb3240aa076e08f350b654ae0b972194d42482b4f6a84ecff4
toUtf8Map
public static Map<CharSequence, CharSequence> toUtf8Map(Map<String, String> map)
{    Map<CharSequence, CharSequence> utf8Map = Maps.newHashMap();    for (Map.Entry<String, String> entry : map.entrySet()) {        utf8Map.put(new Utf8(entry.getKey()), new Utf8(entry.getValue()));    }    return utf8Map;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    configuredMinReplicas = context.getInteger("hdfs.minBlockReplicas");    if (configuredMinReplicas != null) {        Preconditions.checkArgument(configuredMinReplicas >= 0, "hdfs.minBlockReplicas must be greater than or equal to 0");    }    numberOfCloseRetries = context.getInteger("hdfs.closeTries", 1) - 1;    if (numberOfCloseRetries > 1) {        try {                        timeBetweenCloseRetries = context.getLong("hdfs.callTimeout", 30000L);        } catch (NumberFormatException e) {            logger.warn("hdfs.callTimeout can not be parsed to a long: " + context.getLong("hdfs.callTimeout"));        }        timeBetweenCloseRetries = Math.max(timeBetweenCloseRetries / numberOfCloseRetries, 1000);    }}
3f57fe3eab5634d7e5ea2fb83d8cbfcb4e31d6cc24efc504084354689b7b8aac
isUnderReplicated
public boolean isUnderReplicated()
{    try {        int numBlocks = getNumCurrentReplicas();        if (numBlocks == -1) {            return false;        }        int desiredBlocks;        if (configuredMinReplicas != null) {            desiredBlocks = configuredMinReplicas;        } else {            desiredBlocks = getFsDesiredReplication();        }        return numBlocks < desiredBlocks;    } catch (IllegalAccessException e) {        logger.error("Unexpected error while checking replication factor", e);    } catch (InvocationTargetException e) {        logger.error("Unexpected error while checking replication factor", e);    } catch (IllegalArgumentException e) {        logger.error("Unexpected error while checking replication factor", e);    }    return false;}
66f0b859f0a11b581afafab43d84d20c0a126ad4051039c15a23a977786910b8
registerCurrentStream
protected void registerCurrentStream(FSDataOutputStream outputStream, FileSystem fs, Path destPath)
{    Preconditions.checkNotNull(outputStream, "outputStream must not be null");    Preconditions.checkNotNull(fs, "fs must not be null");    Preconditions.checkNotNull(destPath, "destPath must not be null");    this.outputStream = outputStream;    this.fs = fs;    this.destPath = destPath;    this.refGetNumCurrentReplicas = reflectGetNumCurrentReplicas(outputStream);    this.refGetDefaultReplication = reflectGetDefaultReplication(fs);    this.refHflushOrSync = reflectHflushOrSync(outputStream);}
1f0b9c6a1dbd3e9f5f91339fb0948f52f10cb7698c25a45fc88d59b9100aac43
unregisterCurrentStream
protected void unregisterCurrentStream()
{    this.outputStream = null;    this.fs = null;    this.destPath = null;    this.refGetNumCurrentReplicas = null;    this.refGetDefaultReplication = null;}
afcd02cb47f89225d183a72f481eb1f9411fad3c97d08494df8de93539b7996f
getFsDesiredReplication
public int getFsDesiredReplication()
{    short replication = 0;    if (fs != null && destPath != null) {        if (refGetDefaultReplication != null) {            try {                replication = (Short) refGetDefaultReplication.invoke(fs, destPath);            } catch (IllegalAccessException e) {                logger.warn("Unexpected error calling getDefaultReplication(Path)", e);            } catch (InvocationTargetException e) {                logger.warn("Unexpected error calling getDefaultReplication(Path)", e);            }        } else {                        replication = fs.getDefaultReplication();        }    }    return replication;}
85773b291abb515b6647d6637a76de1f6bc3951594d02100a75da1d744e14a68
getNumCurrentReplicas
public int getNumCurrentReplicas() throws IllegalArgumentException, IllegalAccessException, InvocationTargetException
{    if (refGetNumCurrentReplicas != null && outputStream != null) {        OutputStream dfsOutputStream = outputStream.getWrappedStream();        if (dfsOutputStream != null) {            Object repl = refGetNumCurrentReplicas.invoke(dfsOutputStream, NO_ARGS);            if (repl instanceof Integer) {                return ((Integer) repl).intValue();            }        }    }    return -1;}
a45719e125624a6ffe267e30a78642c32d2db3dad5205f574493df3343132c0c
reflectGetNumCurrentReplicas
private Method reflectGetNumCurrentReplicas(FSDataOutputStream os)
{    Method m = null;    if (os != null) {        Class<? extends OutputStream> wrappedStreamClass = os.getWrappedStream().getClass();        try {            m = wrappedStreamClass.getDeclaredMethod("getNumCurrentReplicas", new Class<?>[] {});            m.setAccessible(true);        } catch (NoSuchMethodException e) {            logger.info("FileSystem's output stream doesn't support" + " getNumCurrentReplicas; --HDFS-826 not available; fsOut=" + wrappedStreamClass.getName() + "; err=" + e);        } catch (SecurityException e) {            logger.info("Doesn't have access to getNumCurrentReplicas on " + "FileSystems's output stream --HDFS-826 not available; fsOut=" + wrappedStreamClass.getName(), e);                        m = null;        }    }    if (m != null) {        logger.debug("Using getNumCurrentReplicas--HDFS-826");    }    return m;}
de8b048aacbe3b62a1b641bae94474a7e92c5b5b794ead6ea46cb7327b82ae80
reflectGetDefaultReplication
private Method reflectGetDefaultReplication(FileSystem fileSystem)
{    Method m = null;    if (fileSystem != null) {        Class<?> fsClass = fileSystem.getClass();        try {            m = fsClass.getMethod("getDefaultReplication", new Class<?>[] { Path.class });        } catch (NoSuchMethodException e) {            logger.debug("FileSystem implementation doesn't support" + " getDefaultReplication(Path); -- HADOOP-8014 not available; " + "className = " + fsClass.getName() + "; err = " + e);        } catch (SecurityException e) {            logger.debug("No access to getDefaultReplication(Path) on " + "FileSystem implementation -- HADOOP-8014 not available; " + "className = " + fsClass.getName() + "; err = " + e);        }    }    if (m != null) {        logger.debug("Using FileSystem.getDefaultReplication(Path) from " + "HADOOP-8014");    }    return m;}
ca6e80ce55815bef4d22fd0fde0aaf379999394448417e959082e6c9e307b182
reflectHflushOrSync
private Method reflectHflushOrSync(FSDataOutputStream os)
{    Method m = null;    if (os != null) {        Class<?> fsDataOutputStreamClass = os.getClass();        try {            m = fsDataOutputStreamClass.getMethod("hflush");        } catch (NoSuchMethodException ex) {            logger.debug("HFlush not found. Will use sync() instead");            try {                m = fsDataOutputStreamClass.getMethod("sync");            } catch (Exception ex1) {                String msg = "Neither hflush not sync were found. That seems to be " + "a problem!";                logger.error(msg);                throw new FlumeException(msg, ex1);            }        }    }    return m;}
d9594a97336367c9f114530003d6dc5c2cd5c1fd0a5d20f5fe6f353b04519a7a
hflushOrSync
protected void hflushOrSync(FSDataOutputStream os) throws IOException
{    try {                        this.refHflushOrSync.invoke(os);    } catch (InvocationTargetException e) {        String msg = "Error while trying to hflushOrSync!";        logger.error(msg);        Throwable cause = e.getCause();        if (cause != null && cause instanceof IOException) {            throw (IOException) cause;        }        throw new FlumeException(msg, e);    } catch (Exception e) {        String msg = "Error while trying to hflushOrSync!";        logger.error(msg);        throw new FlumeException(msg, e);    }}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    syncIntervalBytes = context.getInteger(SYNC_INTERVAL_BYTES, DEFAULT_SYNC_INTERVAL_BYTES);    compressionCodec = context.getString(COMPRESSION_CODEC, DEFAULT_COMPRESSION_CODEC);    staticSchemaURL = context.getString(STATIC_SCHEMA_URL, DEFAULT_STATIC_SCHEMA_URL);}
8e16e9a819af3299e39546ad020872007eb755dcb366430d3993b74dee1bacbf
afterCreate
public void afterCreate() throws IOException
{}
6b0e0eb6f48e834d2a656991dd837b62aa5933c8521ea4e91248dfcd2497a8b4
afterReopen
public void afterReopen() throws IOException
{        throw new UnsupportedOperationException("Avro API doesn't support append");}
4006d97185c9ea4783f6cf751ad0782e94ac872b01261a143985ae49fd402fec
write
public void write(Event event) throws IOException
{    if (dataFileWriter == null) {        initialize(event);    }    dataFileWriter.appendEncoded(ByteBuffer.wrap(event.getBody()));}
4664ac330cf2b00d3e7ee4ffcdc23fb5a2f987ecf89829d0b9c8fde8b31887ea
initialize
private void initialize(Event event) throws IOException
{    Schema schema = null;    String schemaUrl = event.getHeaders().get(AVRO_SCHEMA_URL_HEADER);    String schemaString = event.getHeaders().get(AVRO_SCHEMA_LITERAL_HEADER);    if (schemaUrl != null) {                schema = schemaCache.get(schemaUrl);        if (schema == null) {            schema = loadFromUrl(schemaUrl);            schemaCache.put(schemaUrl, schema);        }    } else if (schemaString != null) {                schema = new Schema.Parser().parse(schemaString);    } else if (staticSchemaURL != null) {                schema = schemaCache.get(staticSchemaURL);        if (schema == null) {            schema = loadFromUrl(staticSchemaURL);            schemaCache.put(staticSchemaURL, schema);        }    } else {                throw new FlumeException("Could not find schema for event " + event);    }    writer = new GenericDatumWriter<Object>(schema);    dataFileWriter = new DataFileWriter<Object>(writer);    dataFileWriter.setSyncInterval(syncIntervalBytes);    try {        CodecFactory codecFactory = CodecFactory.fromString(compressionCodec);        dataFileWriter.setCodec(codecFactory);    } catch (AvroRuntimeException e) {        logger.warn("Unable to instantiate avro codec with name (" + compressionCodec + "). Compression disabled. Exception follows.", e);    }    dataFileWriter.create(schema, out);}
6a0e1f82dea853660e6569ccbf9c8e6bb29df390ef4af47a31c701cdaf823ed2
loadFromUrl
private Schema loadFromUrl(String schemaUrl) throws IOException
{    Configuration conf = new Configuration();    Schema.Parser parser = new Schema.Parser();    if (schemaUrl.toLowerCase(Locale.ENGLISH).startsWith("hdfs://")) {        FileSystem fs = FileSystem.get(conf);        FSDataInputStream input = null;        try {            input = fs.open(new Path(schemaUrl));            return parser.parse(input);        } finally {            if (input != null) {                input.close();            }        }    } else {        InputStream is = null;        try {            is = new URL(schemaUrl).openStream();            return parser.parse(is);        } finally {            if (is != null) {                is.close();            }        }    }}
c3e67ec76f1b008887f1caba645a2614900cde6e477acca1bc3ecc36bf357fcf
flush
public void flush() throws IOException
{    dataFileWriter.flush();}
7a1f7a8f2fe39aaa0ecd2a186248a03a6459440636130fa195826e0616eafff7
beforeClose
public void beforeClose() throws IOException
{}
77bb5e791ef374371f37b37dfa587fb1895f9b41427ff7b2adba8629c2a9e150
supportsReopen
public boolean supportsReopen()
{    return false;}
74e8fa60d6fc51ca3723cb17e94c593fb7b56c215ce37ab9c280f06c5b880433
build
public EventSerializer build(Context context, OutputStream out)
{    AvroEventSerializer writer = new AvroEventSerializer(out);    writer.configure(context);    return writer;}
49a7ed15ca5f7aeac29e51db6e7af2d6dd560891b05709346a765e3bc57226dd
setFileSystem
 void setFileSystem(FileSystem fs)
{    this.fileSystem = fs;    mockFsInjected = true;}
ab6d696bbf0482da1ac47314686a75219533f6f25a68f159217d3aaef9ea537f
resetCounters
private void resetCounters()
{    eventCounter = 0;    processSize = 0;    batchCounter = 0;}
96713cdee6f9840062c152a5ee6634254ea4f08bb7f30238a569a72b99ee032f
getRefIsClosed
private Method getRefIsClosed()
{    try {        return fileSystem.getClass().getMethod("isFileClosed", Path.class);    } catch (Exception e) {        LOG.info("isFileClosed() is not available in the version of the " + "distributed filesystem being used. " + "Flume will not attempt to re-close files if the close fails " + "on the first attempt");        return null;    }}
1f76554023e6bbf31a17822340c4d48cec5da365a946c21c06b25486052a0da5
isFileClosed
private Boolean isFileClosed(FileSystem fs, Path tmpFilePath) throws Exception
{    return (Boolean) (isClosedMethod.invoke(fs, tmpFilePath));}
a2ac7b1b7bdf92a9740f43d0ca54a746bef58802f95b6facf34256530d710aa2
open
private void open() throws IOException, InterruptedException
{    if ((filePath == null) || (writer == null)) {        throw new IOException("Invalid file settings");    }    final Configuration config = new Configuration();        config.setBoolean("fs.automatic.close", false);        synchronized (staticLock) {        checkAndThrowInterruptedException();        try {            long counter = fileExtensionCounter.incrementAndGet();            String fullFileName = fileName + "." + counter;            if (fileSuffix != null && fileSuffix.length() > 0) {                fullFileName += fileSuffix;            } else if (codeC != null) {                fullFileName += codeC.getDefaultExtension();            }            bucketPath = filePath + "/" + inUsePrefix + fullFileName + inUseSuffix;            targetPath = filePath + "/" + fullFileName;            LOG.info("Creating " + bucketPath);            callWithTimeout(new CallRunner<Void>() {                @Override                public Void call() throws Exception {                    if (codeC == null) {                                                if (!mockFsInjected) {                            fileSystem = new Path(bucketPath).getFileSystem(config);                        }                        writer.open(bucketPath);                    } else {                                                if (!mockFsInjected) {                            fileSystem = new Path(bucketPath).getFileSystem(config);                        }                        writer.open(bucketPath, codeC, compType);                    }                    return null;                }            });        } catch (Exception ex) {            sinkCounter.incrementConnectionFailedCount();            if (ex instanceof IOException) {                throw (IOException) ex;            } else {                throw Throwables.propagate(ex);            }        }    }    isClosedMethod = getRefIsClosed();    sinkCounter.incrementConnectionCreatedCount();    resetCounters();        if (rollInterval > 0) {        Callable<Void> action = new Callable<Void>() {            public Void call() throws Exception {                LOG.debug("Rolling file ({}): Roll scheduled after {} sec elapsed.", bucketPath, rollInterval);                try {                                        close(true);                } catch (Throwable t) {                    LOG.error("Unexpected error", t);                }                return null;            }        };        timedRollFuture = timedRollerPool.schedule(action, rollInterval, TimeUnit.SECONDS);    }    isOpen = true;}
d12537fee0d4fb03a2b54ca4cc2cb7aeeb6659af2e7d4f187baf67a1d3ca17d2
call
public Void call() throws Exception
{    if (codeC == null) {                if (!mockFsInjected) {            fileSystem = new Path(bucketPath).getFileSystem(config);        }        writer.open(bucketPath);    } else {                if (!mockFsInjected) {            fileSystem = new Path(bucketPath).getFileSystem(config);        }        writer.open(bucketPath, codeC, compType);    }    return null;}
d12537fee0d4fb03a2b54ca4cc2cb7aeeb6659af2e7d4f187baf67a1d3ca17d2
call
public Void call() throws Exception
{    LOG.debug("Rolling file ({}): Roll scheduled after {} sec elapsed.", bucketPath, rollInterval);    try {                close(true);    } catch (Throwable t) {        LOG.error("Unexpected error", t);    }    return null;}
cf6704a4e9853ec7bfb4e2656092600923680217ceac778bb2648284c6beb757
close
public void close() throws InterruptedException
{    close(false);}
33a56f3230d48803c6a60e9529677761829e34ff3488dbef951ce8081948142f
createCloseCallRunner
private CallRunner<Void> createCloseCallRunner()
{    return new CallRunner<Void>() {        @Override        public Void call() throws Exception {                        writer.close();            return null;        }    };}
d12537fee0d4fb03a2b54ca4cc2cb7aeeb6659af2e7d4f187baf67a1d3ca17d2
call
public Void call() throws Exception
{        writer.close();    return null;}
d12537fee0d4fb03a2b54ca4cc2cb7aeeb6659af2e7d4f187baf67a1d3ca17d2
call
public Void call() throws Exception
{    close(false);    return null;}
e5d6a28f0bc3cf677370c5579e3d9fdd5185745453a5728c48796ce8b5b6332c
close
public void close(boolean immediate)
{    closeTries++;    boolean shouldRetry = closeTries < maxRetries && !immediate;    try {        callWithTimeout(createCloseCallRunner());        sinkCounter.incrementConnectionClosedCount();    } catch (InterruptedException | IOException e) {        LOG.warn("Closing file: " + path + " failed. Will " + "retry again in " + retryInterval + " seconds.", e);        if (timedRollerPool != null && !timedRollerPool.isTerminated()) {            if (shouldRetry) {                timedRollerPool.schedule(this, retryInterval, TimeUnit.SECONDS);            }        } else {            LOG.warn("Cannot retry close any more timedRollerPool is null or terminated");        }        if (!shouldRetry) {            LOG.warn("Unsuccessfully attempted to close " + path + " " + maxRetries + " times. Initializing lease recovery.");            sinkCounter.incrementConnectionFailedCount();            recoverLease();        }    }}
d12537fee0d4fb03a2b54ca4cc2cb7aeeb6659af2e7d4f187baf67a1d3ca17d2
call
public Void call() throws Exception
{    if (renameTries >= maxRetries) {        LOG.warn("Unsuccessfully attempted to rename " + path + " " + maxRetries + " times. File may still be open.");        return null;    }    renameTries++;    try {        renameBucket(path, finalPath, fs);    } catch (Exception e) {        LOG.warn("Renaming file: " + path + " failed. Will " + "retry again in " + retryInterval + " seconds.", e);        timedRollerPool.schedule(this, retryInterval, TimeUnit.SECONDS);        return null;    }    return null;}
aebeb8ccaef41c69b4cad347efb71361090013835d0f3fdb35893329e39f3d99
recoverLease
private synchronized void recoverLease()
{    if (bucketPath != null && fileSystem instanceof DistributedFileSystem) {        try {            LOG.debug("Starting lease recovery for {}", bucketPath);            ((DistributedFileSystem) fileSystem).recoverLease(new Path(bucketPath));        } catch (IOException ex) {            LOG.warn("Lease recovery failed for {}", bucketPath, ex);        }    }}
1b1342677e0581b22e002f5038f74d38f21b36297b527ae47f9549c6ecee4e62
close
public void close(boolean callCloseCallback) throws InterruptedException
{    close(callCloseCallback, false);}
3415b314325d2f2030080acb4574650d1f6dc5cd8dbcc4afaaf13c032cd51d79
close
public void close(boolean callCloseCallback, boolean immediate) throws InterruptedException
{    if (callCloseCallback) {        if (closed.compareAndSet(false, true)) {                        runCloseAction();        } else {            LOG.warn("This bucketWriter is already closing or closed.");        }    }    doClose(immediate);}
af049c8136cc9c393476d96befbe4d4a77f9c8263668c882199f39af04dc07f8
doClose
private synchronized void doClose(boolean immediate) throws InterruptedException
{    checkAndThrowInterruptedException();    try {        flush();    } catch (IOException e) {        LOG.warn("pre-close flush failed", e);    }    LOG.info("Closing {}", bucketPath);    if (isOpen) {        new CloseHandler().close(immediate);        isOpen = false;    } else {        LOG.info("HDFSWriter is already closed: {}", bucketPath);    }        if (timedRollFuture != null && !timedRollFuture.isDone()) {                timedRollFuture.cancel(false);        timedRollFuture = null;    }    if (idleFuture != null && !idleFuture.isDone()) {                idleFuture.cancel(false);        idleFuture = null;    }    if (bucketPath != null && fileSystem != null) {                try {            renameBucket(bucketPath, targetPath, fileSystem);        } catch (Exception e) {            LOG.warn("failed to rename() file (" + bucketPath + "). Exception follows.", e);            sinkCounter.incrementConnectionFailedCount();            final Callable<Void> scheduledRename = new ScheduledRenameCallable();            timedRollerPool.schedule(scheduledRename, retryInterval, TimeUnit.SECONDS);        }    }}
e9dee19c73f63b80de4d85e6e8065b2cd05d983643facfec6b01d2ac181ee08e
flush
public synchronized void flush() throws IOException, InterruptedException
{    checkAndThrowInterruptedException();    if (!isBatchComplete()) {        doFlush();        if (idleTimeout > 0) {                        if (idleFuture == null || idleFuture.cancel(false)) {                Callable<Void> idleAction = new Callable<Void>() {                    public Void call() throws Exception {                        LOG.info("Closing idle bucketWriter {} at {}", bucketPath, System.currentTimeMillis());                        if (isOpen) {                            close(true);                        }                        return null;                    }                };                idleFuture = timedRollerPool.schedule(idleAction, idleTimeout, TimeUnit.SECONDS);            }        }    }}
d12537fee0d4fb03a2b54ca4cc2cb7aeeb6659af2e7d4f187baf67a1d3ca17d2
call
public Void call() throws Exception
{    LOG.info("Closing idle bucketWriter {} at {}", bucketPath, System.currentTimeMillis());    if (isOpen) {        close(true);    }    return null;}
c3637f7be5c2e7a655814841f04cf8340eb8e11a64afd72b5eb8c837ac0c8ab7
runCloseAction
private void runCloseAction()
{    try {        if (onCloseCallback != null) {            onCloseCallback.run(onCloseCallbackPath);        }    } catch (Throwable t) {        LOG.error("Unexpected error", t);    }}
92cf939400ccbe57f8f20c13a819e508851ce32dc44863ab7f154104e6b51bb7
doFlush
private void doFlush() throws IOException, InterruptedException
{    callWithTimeout(new CallRunner<Void>() {        @Override        public Void call() throws Exception {                        writer.sync();            return null;        }    });    batchCounter = 0;}
d12537fee0d4fb03a2b54ca4cc2cb7aeeb6659af2e7d4f187baf67a1d3ca17d2
call
public Void call() throws Exception
{        writer.sync();    return null;}
1b238a3cb4d08a7c5ddfad04bb8e04627f065696979e3c06d8e38bd839274810
append
public synchronized void append(final Event event) throws IOException, InterruptedException
{    checkAndThrowInterruptedException();        if (idleFuture != null) {        idleFuture.cancel(false);                if (!idleFuture.isDone()) {            try {                idleFuture.get(callTimeout, TimeUnit.MILLISECONDS);            } catch (TimeoutException ex) {                LOG.warn("Timeout while trying to cancel closing of idle file. Idle" + " file close may have failed", ex);            } catch (Exception ex) {                LOG.warn("Error while trying to cancel closing of idle file. ", ex);            }        }        idleFuture = null;    }        if (!isOpen) {        if (closed.get()) {            throw new BucketClosedException("This bucket writer was closed and " + "this handle is thus no longer valid");        }        open();    }        if (shouldRotate()) {        boolean doRotate = true;        if (isUnderReplicated) {            if (maxConsecUnderReplRotations > 0 && consecutiveUnderReplRotateCount >= maxConsecUnderReplRotations) {                doRotate = false;                if (consecutiveUnderReplRotateCount == maxConsecUnderReplRotations) {                    LOG.error("Hit max consecutive under-replication rotations ({}); " + "will not continue rolling files under this path due to " + "under-replication", maxConsecUnderReplRotations);                }            } else {                LOG.warn("Block Under-replication detected. Rotating file.");            }            consecutiveUnderReplRotateCount++;        } else {            consecutiveUnderReplRotateCount = 0;        }        if (doRotate) {            close();            open();        }    }        try {        sinkCounter.incrementEventDrainAttemptCount();        callWithTimeout(new CallRunner<Void>() {            @Override            public Void call() throws Exception {                                writer.append(event);                return null;            }        });    } catch (IOException e) {        LOG.warn("Caught IOException writing to HDFSWriter ({}). Closing file (" + bucketPath + ") and rethrowing exception.", e.getMessage());        close(true);        throw e;    }        processSize += event.getBody().length;    eventCounter++;    batchCounter++;    if (batchCounter == batchSize) {        flush();    }}
d12537fee0d4fb03a2b54ca4cc2cb7aeeb6659af2e7d4f187baf67a1d3ca17d2
call
public Void call() throws Exception
{        writer.append(event);    return null;}
70eafedf9c4ac8818de91e26fd9d65e0d534e243429bd41e40474411279befc1
shouldRotate
private boolean shouldRotate()
{    boolean doRotate = false;    if (writer.isUnderReplicated()) {        this.isUnderReplicated = true;        doRotate = true;    } else {        this.isUnderReplicated = false;    }    if ((rollCount > 0) && (rollCount <= eventCounter)) {        LOG.debug("rolling: rollCount: {}, events: {}", rollCount, eventCounter);        doRotate = true;    }    if ((rollSize > 0) && (rollSize <= processSize)) {        LOG.debug("rolling: rollSize: {}, bytes: {}", rollSize, processSize);        doRotate = true;    }    return doRotate;}
6e580ba5a8ab6ba0414736a2a9b2b179aadba61704cc6fcd66b294bb2699a31c
renameBucket
private void renameBucket(String bucketPath, String targetPath, final FileSystem fs) throws IOException, InterruptedException
{    if (bucketPath.equals(targetPath)) {        return;    }    final Path srcPath = new Path(bucketPath);    final Path dstPath = new Path(targetPath);    callWithTimeout(new CallRunner<Void>() {        @Override        public Void call() throws Exception {            if (fs.exists(srcPath)) {                                LOG.info("Renaming " + srcPath + " to " + dstPath);                renameTries.incrementAndGet();                                fs.rename(srcPath, dstPath);            }            return null;        }    });}
d12537fee0d4fb03a2b54ca4cc2cb7aeeb6659af2e7d4f187baf67a1d3ca17d2
call
public Void call() throws Exception
{    if (fs.exists(srcPath)) {                LOG.info("Renaming " + srcPath + " to " + dstPath);        renameTries.incrementAndGet();                fs.rename(srcPath, dstPath);    }    return null;}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return "[ " + this.getClass().getSimpleName() + " targetPath = " + targetPath + ", bucketPath = " + bucketPath + " ]";}
09d954ecfb39618983422ed046af744d3f8a91e8ef357a62acfbebc704320931
isBatchComplete
private boolean isBatchComplete()
{    return (batchCounter == 0);}
8441a44ff142ad7dfad861811a9b5f8da35432c2ce8c7ec5e41194b76caf38e3
checkAndThrowInterruptedException
private static void checkAndThrowInterruptedException() throws InterruptedException
{    if (Thread.currentThread().interrupted()) {        throw new InterruptedException("Timed out before HDFS call was made. " + "Your hdfs.callTimeout might be set too low or HDFS calls are " + "taking too long.");    }}
91314e8a92e1db1cb69f00e76a14b6854e18b5169ff417591b26fee18658f2d6
callWithTimeout
private T callWithTimeout(final CallRunner<T> callRunner) throws IOException, InterruptedException
{    Future<T> future = callTimeoutPool.submit(new Callable<T>() {        @Override        public T call() throws Exception {            return proxyUser.execute(new PrivilegedExceptionAction<T>() {                @Override                public T run() throws Exception {                    return callRunner.call();                }            });        }    });    try {        if (callTimeout > 0) {            return future.get(callTimeout, TimeUnit.MILLISECONDS);        } else {            return future.get();        }    } catch (TimeoutException eT) {        future.cancel(true);        sinkCounter.incrementConnectionFailedCount();        throw new IOException("Callable timed out after " + callTimeout + " ms" + " on file: " + bucketPath, eT);    } catch (ExecutionException e1) {        sinkCounter.incrementConnectionFailedCount();        Throwable cause = e1.getCause();        if (cause instanceof IOException) {            throw (IOException) cause;        } else if (cause instanceof InterruptedException) {            throw (InterruptedException) cause;        } else if (cause instanceof RuntimeException) {            throw (RuntimeException) cause;        } else if (cause instanceof Error) {            throw (Error) cause;        } else {            throw new RuntimeException(e1);        }    } catch (CancellationException ce) {        throw new InterruptedException("Blocked callable interrupted by rotation event");    } catch (InterruptedException ex) {        LOG.warn("Unexpected Exception " + ex.getMessage(), ex);        throw ex;    }}
e7985d5eb6946b0938e026af2eef3520c2fd87a7715c008671b5977d3fe59768
call
public T call() throws Exception
{    return proxyUser.execute(new PrivilegedExceptionAction<T>() {        @Override        public T run() throws Exception {            return callRunner.call();        }    });}
80e4cefb45e1a333155332c96045a98621894cb98e26b1d4b82302ff50ab36c7
run
public T run() throws Exception
{    return callRunner.call();}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    super.configure(context);    serializerType = context.getString("serializer", "TEXT");    useRawLocalFileSystem = context.getBoolean("hdfs.useRawLocalFileSystem", false);    serializerContext = new Context(context.getSubProperties(EventSerializer.CTX_PREFIX));    logger.info("Serializer = " + serializerType + ", UseRawLocalFileSystem = " + useRawLocalFileSystem);}
a56fdb944898d4b84708496e3db760c3dfc8d960da338bef6af212f91dcd792c
open
public void open(String filePath) throws IOException
{    DefaultCodec defCodec = new DefaultCodec();    CompressionType cType = CompressionType.BLOCK;    open(filePath, defCodec, cType);}
4d3532d4dad48abce303bc71a086e69e55a53d5817b236612f2dcd6bf6660f82
open
public void open(String filePath, CompressionCodec codec, CompressionType cType) throws IOException
{    Configuration conf = new Configuration();    Path dstPath = new Path(filePath);    FileSystem hdfs = dstPath.getFileSystem(conf);    if (useRawLocalFileSystem) {        if (hdfs instanceof LocalFileSystem) {            hdfs = ((LocalFileSystem) hdfs).getRaw();        } else {            logger.warn("useRawLocalFileSystem is set to true but file system " + "is not of type LocalFileSystem: " + hdfs.getClass().getName());        }    }    boolean appending = false;    if (conf.getBoolean("hdfs.append.support", false) == true && hdfs.isFile(dstPath)) {        fsOut = hdfs.append(dstPath);        appending = true;    } else {        fsOut = hdfs.create(dstPath);    }    if (compressor == null) {        compressor = CodecPool.getCompressor(codec, conf);    }    cmpOut = codec.createOutputStream(fsOut, compressor);    serializer = EventSerializerFactory.getInstance(serializerType, serializerContext, cmpOut);    if (appending && !serializer.supportsReopen()) {        cmpOut.close();        serializer = null;        throw new IOException("serializer (" + serializerType + ") does not support append");    }    registerCurrentStream(fsOut, hdfs, dstPath);    if (appending) {        serializer.afterReopen();    } else {        serializer.afterCreate();    }    isFinished = false;}
48a57ccf62aed2b9c002062bad1819c4f51c3dcfbd2778df14c7a16c1538c5d4
append
public void append(Event e) throws IOException
{    if (isFinished) {        cmpOut.resetState();        isFinished = false;    }    serializer.write(e);}
ebf6369c0a538e889b3acec39360edad82f3c2ebed8c3c27b004adbf0ab4b95a
sync
public void sync() throws IOException
{                        serializer.flush();    if (!isFinished) {        cmpOut.finish();        isFinished = true;    }    fsOut.flush();    hflushOrSync(this.fsOut);}
e0823f55b3a09d41a3e1e792f7e6687db9199c2db9b29e9922d93cbdc6f1284b
close
public void close() throws IOException
{    serializer.flush();    serializer.beforeClose();    if (!isFinished) {        cmpOut.finish();        isFinished = true;    }    fsOut.flush();    hflushOrSync(fsOut);    cmpOut.close();    if (compressor != null) {        CodecPool.returnCompressor(compressor);        compressor = null;    }    unregisterCurrentStream();}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    super.configure(context);    serializerType = context.getString("serializer", "TEXT");    useRawLocalFileSystem = context.getBoolean("hdfs.useRawLocalFileSystem", false);    serializerContext = new Context(context.getSubProperties(EventSerializer.CTX_PREFIX));    logger.info("Serializer = " + serializerType + ", UseRawLocalFileSystem = " + useRawLocalFileSystem);}
f39e187e89894b635f21f76dc1d59966b71abc0a38d11f7787312713163a308c
getDfs
protected FileSystem getDfs(Configuration conf, Path dstPath) throws IOException
{    return dstPath.getFileSystem(conf);}
5913ddf07c7667be85c96cc1111bb8b42102f8efacb775a0a40c45395660d89d
doOpen
protected void doOpen(Configuration conf, Path dstPath, FileSystem hdfs) throws IOException
{    if (useRawLocalFileSystem) {        if (hdfs instanceof LocalFileSystem) {            hdfs = ((LocalFileSystem) hdfs).getRaw();        } else {            logger.warn("useRawLocalFileSystem is set to true but file system " + "is not of type LocalFileSystem: " + hdfs.getClass().getName());        }    }    boolean appending = false;    if (conf.getBoolean("hdfs.append.support", false) == true && hdfs.isFile(dstPath)) {        outStream = hdfs.append(dstPath);        appending = true;    } else {        outStream = hdfs.create(dstPath);    }    serializer = EventSerializerFactory.getInstance(serializerType, serializerContext, outStream);    if (appending && !serializer.supportsReopen()) {        outStream.close();        serializer = null;        throw new IOException("serializer (" + serializerType + ") does not support append");    }        registerCurrentStream(outStream, hdfs, dstPath);    if (appending) {        serializer.afterReopen();    } else {        serializer.afterCreate();    }}
a56fdb944898d4b84708496e3db760c3dfc8d960da338bef6af212f91dcd792c
open
public void open(String filePath) throws IOException
{    Configuration conf = new Configuration();    Path dstPath = new Path(filePath);    FileSystem hdfs = getDfs(conf, dstPath);    doOpen(conf, dstPath, hdfs);}
4d3532d4dad48abce303bc71a086e69e55a53d5817b236612f2dcd6bf6660f82
open
public void open(String filePath, CompressionCodec codec, CompressionType cType) throws IOException
{    open(filePath);}
48a57ccf62aed2b9c002062bad1819c4f51c3dcfbd2778df14c7a16c1538c5d4
append
public void append(Event e) throws IOException
{    serializer.write(e);}
ebf6369c0a538e889b3acec39360edad82f3c2ebed8c3c27b004adbf0ab4b95a
sync
public void sync() throws IOException
{    serializer.flush();    outStream.flush();    hflushOrSync(outStream);}
e0823f55b3a09d41a3e1e792f7e6687db9199c2db9b29e9922d93cbdc6f1284b
close
public void close() throws IOException
{    serializer.flush();    serializer.beforeClose();    outStream.flush();    hflushOrSync(outStream);    outStream.close();    unregisterCurrentStream();}
9490f7ebeaa83b12f6ce1820afdf187b337da4e005eeca6d911548ad7293985a
removeEldestEntry
protected boolean removeEldestEntry(Entry<String, BucketWriter> eldest)
{    if (size() > maxOpenFiles) {                try {            eldest.getValue().close();        } catch (InterruptedException e) {            LOG.warn(eldest.getKey().toString(), e);            Thread.currentThread().interrupt();        }        return true;    } else {        return false;    }}
b0bccb50d403469f46019739a17d715648dfbf0badcd5175d1b17b6964411467
getSfWriters
 Map<String, BucketWriter> getSfWriters()
{    return sfWriters;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    this.context = context;    filePath = Preconditions.checkNotNull(context.getString("hdfs.path"), "hdfs.path is required");    fileName = context.getString("hdfs.filePrefix", defaultFileName);    this.suffix = context.getString("hdfs.fileSuffix", defaultSuffix);    inUsePrefix = context.getString("hdfs.inUsePrefix", defaultInUsePrefix);    boolean emptyInUseSuffix = context.getBoolean("hdfs.emptyInUseSuffix", false);    if (emptyInUseSuffix) {        inUseSuffix = "";        String tmpInUseSuffix = context.getString(IN_USE_SUFFIX_PARAM_NAME);        if (tmpInUseSuffix != null) {            LOG.warn("Ignoring parameter " + IN_USE_SUFFIX_PARAM_NAME + " for hdfs sink: " + getName());        }    } else {        inUseSuffix = context.getString(IN_USE_SUFFIX_PARAM_NAME, defaultInUseSuffix);    }    String tzName = context.getString("hdfs.timeZone");    timeZone = tzName == null ? null : TimeZone.getTimeZone(tzName);    rollInterval = context.getLong("hdfs.rollInterval", defaultRollInterval);    rollSize = context.getLong("hdfs.rollSize", defaultRollSize);    rollCount = context.getLong("hdfs.rollCount", defaultRollCount);    batchSize = context.getLong("hdfs.batchSize", defaultBatchSize);    idleTimeout = context.getInteger("hdfs.idleTimeout", 0);    String codecName = context.getString("hdfs.codeC");    fileType = context.getString("hdfs.fileType", defaultFileType);    maxOpenFiles = context.getInteger("hdfs.maxOpenFiles", defaultMaxOpenFiles);    callTimeout = context.getLong("hdfs.callTimeout", defaultCallTimeout);    threadsPoolSize = context.getInteger("hdfs.threadsPoolSize", defaultThreadPoolSize);    rollTimerPoolSize = context.getInteger("hdfs.rollTimerPoolSize", defaultRollTimerPoolSize);    String kerbConfPrincipal = context.getString("hdfs.kerberosPrincipal");    String kerbKeytab = context.getString("hdfs.kerberosKeytab");    String proxyUser = context.getString("hdfs.proxyUser");    tryCount = context.getInteger("hdfs.closeTries", defaultTryCount);    if (tryCount <= 0) {        LOG.warn("Retry count value : " + tryCount + " is not " + "valid. The sink will try to close the file until the file " + "is eventually closed.");        tryCount = defaultTryCount;    }    retryInterval = context.getLong("hdfs.retryInterval", defaultRetryInterval);    if (retryInterval <= 0) {        LOG.warn("Retry Interval value: " + retryInterval + " is not " + "valid. If the first close of a file fails, " + "it may remain open and will not be renamed.");        tryCount = 1;    }    Preconditions.checkArgument(batchSize > 0, "batchSize must be greater than 0");    if (codecName == null) {        codeC = null;        compType = CompressionType.NONE;    } else {        codeC = getCodec(codecName);                compType = CompressionType.BLOCK;    }        if (fileType.equalsIgnoreCase(HDFSWriterFactory.DataStreamType) && codecName != null) {        throw new IllegalArgumentException("fileType: " + fileType + " which does NOT support compressed output. Please don't set codeC" + " or change the fileType if compressed output is desired.");    }    if (fileType.equalsIgnoreCase(HDFSWriterFactory.CompStreamType)) {        Preconditions.checkNotNull(codeC, "It's essential to set compress codec" + " when fileType is: " + fileType);    }        this.privExecutor = FlumeAuthenticationUtil.getAuthenticator(kerbConfPrincipal, kerbKeytab).proxyAs(proxyUser);    needRounding = context.getBoolean("hdfs.round", false);    if (needRounding) {        String unit = context.getString("hdfs.roundUnit", "second");        if (unit.equalsIgnoreCase("hour")) {            this.roundUnit = Calendar.HOUR_OF_DAY;        } else if (unit.equalsIgnoreCase("minute")) {            this.roundUnit = Calendar.MINUTE;        } else if (unit.equalsIgnoreCase("second")) {            this.roundUnit = Calendar.SECOND;        } else {            LOG.warn("Rounding unit is not valid, please set one of" + "minute, hour, or second. Rounding will be disabled");            needRounding = false;        }        this.roundValue = context.getInteger("hdfs.roundValue", 1);        if (roundUnit == Calendar.SECOND || roundUnit == Calendar.MINUTE) {            Preconditions.checkArgument(roundValue > 0 && roundValue <= 60, "Round value" + "must be > 0 and <= 60");        } else if (roundUnit == Calendar.HOUR_OF_DAY) {            Preconditions.checkArgument(roundValue > 0 && roundValue <= 24, "Round value" + "must be > 0 and <= 24");        }    }    this.useLocalTime = context.getBoolean("hdfs.useLocalTimeStamp", false);    if (useLocalTime) {        clock = new SystemClock();    }    if (sinkCounter == null) {        sinkCounter = new SinkCounter(getName());    }}
2ba7d04f9d5ce5cdb2762ce3cb7b20a913cf5075c039adf517aceb5d98971a3a
codecMatches
private static boolean codecMatches(Class<? extends CompressionCodec> cls, String codecName)
{    String simpleName = cls.getSimpleName();    if (cls.getName().equals(codecName) || simpleName.equalsIgnoreCase(codecName)) {        return true;    }    if (simpleName.endsWith("Codec")) {        String prefix = simpleName.substring(0, simpleName.length() - "Codec".length());        if (prefix.equalsIgnoreCase(codecName)) {            return true;        }    }    return false;}
8783b6140e91700e9b8176d56ff54c71dd6a02b632126922b58b6a7c3c9c4f1b
getCodec
 static CompressionCodec getCodec(String codecName)
{    Configuration conf = new Configuration();    List<Class<? extends CompressionCodec>> codecs = CompressionCodecFactory.getCodecClasses(conf);            CompressionCodec codec = null;    ArrayList<String> codecStrs = new ArrayList<String>();    codecStrs.add("None");    for (Class<? extends CompressionCodec> cls : codecs) {        codecStrs.add(cls.getSimpleName());        if (codecMatches(cls, codecName)) {            try {                codec = cls.newInstance();            } catch (InstantiationException e) {                LOG.error("Unable to instantiate " + cls + " class");            } catch (IllegalAccessException e) {                LOG.error("Unable to access " + cls + " class");            }        }    }    if (codec == null) {        if (!codecName.equalsIgnoreCase("None")) {            throw new IllegalArgumentException("Unsupported compression codec " + codecName + ".  Please choose from: " + codecStrs);        }    } else if (codec instanceof org.apache.hadoop.conf.Configurable) {                                ((org.apache.hadoop.conf.Configurable) codec).setConf(conf);    }    return codec;}
e52e5e378330fd7f87ee30351bbfcec47b751fee12ece2ef0cfdd77a08c906e1
process
public Status process() throws EventDeliveryException
{    Channel channel = getChannel();    Transaction transaction = channel.getTransaction();    transaction.begin();    try {        Set<BucketWriter> writers = new LinkedHashSet<>();        int txnEventCount = 0;        for (txnEventCount = 0; txnEventCount < batchSize; txnEventCount++) {            Event event = channel.take();            if (event == null) {                break;            }                        String realPath = BucketPath.escapeString(filePath, event.getHeaders(), timeZone, needRounding, roundUnit, roundValue, useLocalTime);            String realName = BucketPath.escapeString(fileName, event.getHeaders(), timeZone, needRounding, roundUnit, roundValue, useLocalTime);            String lookupPath = realPath + DIRECTORY_DELIMITER + realName;            BucketWriter bucketWriter;            HDFSWriter hdfsWriter = null;                                                WriterCallback closeCallback = new WriterCallback() {                @Override                public void run(String bucketPath) {                    LOG.info("Writer callback called.");                    synchronized (sfWritersLock) {                        sfWriters.remove(bucketPath);                    }                }            };            synchronized (sfWritersLock) {                bucketWriter = sfWriters.get(lookupPath);                                if (bucketWriter == null) {                    hdfsWriter = writerFactory.getWriter(fileType);                    bucketWriter = initializeBucketWriter(realPath, realName, lookupPath, hdfsWriter, closeCallback);                    sfWriters.put(lookupPath, bucketWriter);                }            }                        try {                bucketWriter.append(event);            } catch (BucketClosedException ex) {                LOG.info("Bucket was closed while trying to append, " + "reinitializing bucket and writing event.");                hdfsWriter = writerFactory.getWriter(fileType);                bucketWriter = initializeBucketWriter(realPath, realName, lookupPath, hdfsWriter, closeCallback);                synchronized (sfWritersLock) {                    sfWriters.put(lookupPath, bucketWriter);                }                bucketWriter.append(event);            }                        if (!writers.contains(bucketWriter)) {                writers.add(bucketWriter);            }        }        if (txnEventCount == 0) {            sinkCounter.incrementBatchEmptyCount();        } else if (txnEventCount == batchSize) {            sinkCounter.incrementBatchCompleteCount();        } else {            sinkCounter.incrementBatchUnderflowCount();        }                for (BucketWriter bucketWriter : writers) {            bucketWriter.flush();        }        transaction.commit();        if (txnEventCount < 1) {            return Status.BACKOFF;        } else {            sinkCounter.addToEventDrainSuccessCount(txnEventCount);            return Status.READY;        }    } catch (IOException eIO) {        transaction.rollback();        LOG.warn("HDFS IO error", eIO);        sinkCounter.incrementEventWriteFail();        return Status.BACKOFF;    } catch (Throwable th) {        transaction.rollback();        LOG.error("process failed", th);        sinkCounter.incrementEventWriteOrChannelFail(th);        if (th instanceof Error) {            throw (Error) th;        } else {            throw new EventDeliveryException(th);        }    } finally {        transaction.close();    }}
2892306290c38f0fa34bb6b0cc54867374a44ddf568529f2b2306a06ac05b50d
run
public void run(String bucketPath)
{    LOG.info("Writer callback called.");    synchronized (sfWritersLock) {        sfWriters.remove(bucketPath);    }}
f96da99aa3febf6d6b8e5cbfd6282b7f6dab67dbf09b0f7b43ce38e8f066aa91
initializeBucketWriter
 BucketWriter initializeBucketWriter(String realPath, String realName, String lookupPath, HDFSWriter hdfsWriter, WriterCallback closeCallback)
{    HDFSWriter actualHdfsWriter = mockFs == null ? hdfsWriter : mockWriter;    BucketWriter bucketWriter = new BucketWriter(rollInterval, rollSize, rollCount, batchSize, context, realPath, realName, inUsePrefix, inUseSuffix, suffix, codeC, compType, actualHdfsWriter, timedRollerPool, privExecutor, sinkCounter, idleTimeout, closeCallback, lookupPath, callTimeout, callTimeoutPool, retryInterval, tryCount);    if (mockFs != null) {        bucketWriter.setFileSystem(mockFs);    }    return bucketWriter;}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{        synchronized (sfWritersLock) {        for (Entry<String, BucketWriter> entry : sfWriters.entrySet()) {            LOG.info("Closing {}", entry.getKey());            try {                entry.getValue().close(false, true);            } catch (Exception ex) {                LOG.warn("Exception while closing " + entry.getKey() + ". " + "Exception follows.", ex);                if (ex instanceof InterruptedException) {                    Thread.currentThread().interrupt();                }            }        }    }        ExecutorService[] toShutdown = { callTimeoutPool, timedRollerPool };    for (ExecutorService execService : toShutdown) {        execService.shutdown();        try {            while (execService.isTerminated() == false) {                execService.awaitTermination(Math.max(defaultCallTimeout, callTimeout), TimeUnit.MILLISECONDS);            }        } catch (InterruptedException ex) {            LOG.warn("shutdown interrupted on " + execService, ex);        }    }    callTimeoutPool = null;    timedRollerPool = null;    synchronized (sfWritersLock) {        sfWriters.clear();        sfWriters = null;    }    sinkCounter.stop();    super.stop();}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    String timeoutName = "hdfs-" + getName() + "-call-runner-%d";    callTimeoutPool = Executors.newFixedThreadPool(threadsPoolSize, new ThreadFactoryBuilder().setNameFormat(timeoutName).build());    String rollerName = "hdfs-" + getName() + "-roll-timer-%d";    timedRollerPool = Executors.newScheduledThreadPool(rollTimerPoolSize, new ThreadFactoryBuilder().setNameFormat(rollerName).build());    this.sfWriters = new WriterLinkedHashMap(maxOpenFiles);    sinkCounter.start();    super.start();}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return "{ Sink type:" + getClass().getSimpleName() + ", name:" + getName() + " }";}
f857406d441f2d632d470955895bbd15b19ac94bd64dcd546d1b1af60e11fd96
setBucketClock
 void setBucketClock(Clock clock)
{    BucketPath.setClock(clock);}
ae4d6ae905bd84075a1dc4ec7f190bf53fa27ec4bf493cc5d39caef36a993ce5
setMockFs
 void setMockFs(FileSystem mockFs)
{    this.mockFs = mockFs;}
b8d7ab3933f89584c68add4ca27efa7b49e5b6b8f9323aa6c2d85590b24e300e
setMockWriter
 void setMockWriter(HDFSWriter writer)
{    this.mockWriter = writer;}
fbde2bbd1ccc7a1947843ff2d6e02c1ce8c4974909846d65d4fa224924dd91cf
getTryCount
 int getTryCount()
{    return tryCount;}
dcc511f35190533c2d6fcc6073d66b12e111f5004c64ff08ccc3609a06ab844d
getBatchSize
public long getBatchSize()
{    return batchSize;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    super.configure(context);        writeFormat = context.getString("hdfs.writeFormat", SequenceFileSerializerType.Writable.name());    useRawLocalFileSystem = context.getBoolean("hdfs.useRawLocalFileSystem", false);    serializerContext = new Context(context.getSubProperties(SequenceFileSerializerFactory.CTX_PREFIX));    serializer = SequenceFileSerializerFactory.getSerializer(writeFormat, serializerContext);    logger.info("writeFormat = " + writeFormat + ", UseRawLocalFileSystem = " + useRawLocalFileSystem);}
a56fdb944898d4b84708496e3db760c3dfc8d960da338bef6af212f91dcd792c
open
public void open(String filePath) throws IOException
{    open(filePath, null, CompressionType.NONE);}
a728ff7f18ab2097a2c17cd4c9d2ab4cf5f01277c160be6f02b99913f5d111f1
open
public void open(String filePath, CompressionCodec codeC, CompressionType compType) throws IOException
{    Configuration conf = new Configuration();    Path dstPath = new Path(filePath);    FileSystem hdfs = dstPath.getFileSystem(conf);    open(dstPath, codeC, compType, conf, hdfs);}
e67b1e57a1889b97cb7699157a4482e50605f9d8713fedd4e2b70df321a90a19
open
protected void open(Path dstPath, CompressionCodec codeC, CompressionType compType, Configuration conf, FileSystem hdfs) throws IOException
{    if (useRawLocalFileSystem) {        if (hdfs instanceof LocalFileSystem) {            hdfs = ((LocalFileSystem) hdfs).getRaw();        } else {            logger.warn("useRawLocalFileSystem is set to true but file system " + "is not of type LocalFileSystem: " + hdfs.getClass().getName());        }    }    if (conf.getBoolean("hdfs.append.support", false) == true && hdfs.isFile(dstPath)) {        outStream = hdfs.append(dstPath);    } else {        outStream = hdfs.create(dstPath);    }    writer = SequenceFile.createWriter(conf, outStream, serializer.getKeyClass(), serializer.getValueClass(), compType, codeC);    registerCurrentStream(outStream, hdfs, dstPath);}
48a57ccf62aed2b9c002062bad1819c4f51c3dcfbd2778df14c7a16c1538c5d4
append
public void append(Event e) throws IOException
{    for (SequenceFileSerializer.Record record : serializer.serialize(e)) {        writer.append(record.getKey(), record.getValue());    }}
ebf6369c0a538e889b3acec39360edad82f3c2ebed8c3c27b004adbf0ab4b95a
sync
public void sync() throws IOException
{    writer.sync();    hflushOrSync(outStream);}
e0823f55b3a09d41a3e1e792f7e6687db9199c2db9b29e9922d93cbdc6f1284b
close
public void close() throws IOException
{    writer.close();    outStream.close();    unregisterCurrentStream();}
0f9e06cfae9f6e146ad7359c534277fafe1c91efc7660e4cce0b65ac411b1b10
makeText
private Text makeText(Event e)
{    Text textObject = new Text();    textObject.set(e.getBody(), 0, e.getBody().length);    return textObject;}
497851d51831e2d2c3b9ffa2c4fbb21d9db1ca4b48fb4227c9d467396588093b
getKeyClass
public Class<LongWritable> getKeyClass()
{    return LongWritable.class;}
673f531eb5f9b9090eb89b742381c8ad164062b14afd80625246bd9f0b07f610
getValueClass
public Class<Text> getValueClass()
{    return Text.class;}
4ce555144ef7b5e330736046707696b8c538b4d4743a0e11e4f003b43efece0d
serialize
public Iterable<Record> serialize(Event e)
{    Object key = getKey(e);    Object value = getValue(e);    return Collections.singletonList(new Record(key, value));}
f152affa6090e543efd239c265c6b065f4b3ba7599dbf0d2d6da5aed662f1ba9
getKey
private Object getKey(Event e)
{        String timestamp = e.getHeaders().get("timestamp");    long eventStamp;    if (timestamp == null) {        eventStamp = System.currentTimeMillis();    } else {        eventStamp = Long.valueOf(timestamp);    }    return new LongWritable(eventStamp);}
28d3d1ae86737f7a2f610d04516e993f8dba85f0c34ba90c3badae2d0d422253
getValue
private Object getValue(Event e)
{    return makeText(e);}
1a3c6543e4b4a0817826da7dc96201bdc22504a59223b459d1b0e7a0a395a75a
build
public SequenceFileSerializer build(Context context)
{    return new HDFSTextSerializer();}
a31ac80df79162b5ae4ef059806bf1758b98b92a85d458cf99f4ae13f3f235f6
makeByteWritable
private BytesWritable makeByteWritable(Event e)
{    BytesWritable bytesObject = new BytesWritable();    bytesObject.set(e.getBody(), 0, e.getBody().length);    return bytesObject;}
497851d51831e2d2c3b9ffa2c4fbb21d9db1ca4b48fb4227c9d467396588093b
getKeyClass
public Class<LongWritable> getKeyClass()
{    return LongWritable.class;}
584acc7f38df787e54d064ec3ba0540838c9fe22f737ba012f8c707122a08c00
getValueClass
public Class<BytesWritable> getValueClass()
{    return BytesWritable.class;}
4ce555144ef7b5e330736046707696b8c538b4d4743a0e11e4f003b43efece0d
serialize
public Iterable<Record> serialize(Event e)
{    Object key = getKey(e);    Object value = getValue(e);    return Collections.singletonList(new Record(key, value));}
f152affa6090e543efd239c265c6b065f4b3ba7599dbf0d2d6da5aed662f1ba9
getKey
private Object getKey(Event e)
{    String timestamp = e.getHeaders().get("timestamp");    long eventStamp;    if (timestamp == null) {        eventStamp = System.currentTimeMillis();    } else {        eventStamp = Long.valueOf(timestamp);    }    return new LongWritable(eventStamp);}
28d3d1ae86737f7a2f610d04516e993f8dba85f0c34ba90c3badae2d0d422253
getValue
private Object getValue(Event e)
{    return makeByteWritable(e);}
1a3c6543e4b4a0817826da7dc96201bdc22504a59223b459d1b0e7a0a395a75a
build
public SequenceFileSerializer build(Context context)
{    return new HDFSWritableSerializer();}
7e793102fd9301788decac4e2b3dedf8191c85bcf4f85a963668bc8e6b5e02e9
getWriter
public HDFSWriter getWriter(String fileType) throws IOException
{    if (fileType.equalsIgnoreCase(SequenceFileType)) {        return new HDFSSequenceFile();    } else if (fileType.equalsIgnoreCase(DataStreamType)) {        return new HDFSDataStream();    } else if (fileType.equalsIgnoreCase(CompStreamType)) {        return new HDFSCompressedDataStream();    } else {        throw new IOException("File type " + fileType + " not supported");    }}
40e1cf9248326abb178dce50e316b4055970fcd93d8f6e734201f68ebbc066e3
getPrincipal
public String getPrincipal()
{    return principal;}
a05c4a1e8a08d59c9b8ca03c745f80a27acbb567aa7720bd5a5304c3e4d11cb1
getKeyTab
public String getKeyTab()
{    return keyTab;}
4afeb0868b55bdd8e18a00a3cb43d83e0714378d1c4bb36f0936daefc060e2e8
equals
public boolean equals(Object obj)
{    if (obj == null) {        return false;    }    if (getClass() != obj.getClass()) {        return false;    }    final KerberosUser other = (KerberosUser) obj;    if ((this.principal == null) ? (other.principal != null) : !this.principal.equals(other.principal)) {        return false;    }    if ((this.keyTab == null) ? (other.keyTab != null) : !this.keyTab.equals(other.keyTab)) {        return false;    }    return true;}
0ac42bf5188762fc1283b5cbd2b3bb1031e80963813b3b310b15c3fb47050003
hashCode
public int hashCode()
{    int hash = 7;    hash = 41 * hash + (this.principal != null ? this.principal.hashCode() : 0);    hash = 41 * hash + (this.keyTab != null ? this.keyTab.hashCode() : 0);    return hash;}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return "{ principal: " + principal + ", keytab: " + keyTab + " }";}
b2585874b87865eace30c330168a04230bae89eeda3d2fe20bf9bf198ae6751e
getKey
public Object getKey()
{    return key;}
cc9131919df0823e8e8ee6054b03ea6d4a394f817422ddb0f9240211f097bcaf
getValue
public Object getValue()
{    return value;}
b26bd430a5d5f7b2fd57c58ab821175662c8e20528f1f022ac378db8cb92ff73
getSerializer
 static SequenceFileSerializer getSerializer(String formatType, Context context)
{    Preconditions.checkNotNull(formatType, "serialize type must not be null");        SequenceFileSerializerType type;    try {        type = SequenceFileSerializerType.valueOf(formatType);    } catch (IllegalArgumentException e) {        logger.debug("Not in enum, loading builder class: {}", formatType);        type = SequenceFileSerializerType.Other;    }    Class<? extends SequenceFileSerializer.Builder> builderClass = type.getBuilderClass();        if (builderClass == null) {        try {            Class c = Class.forName(formatType);            if (c != null && SequenceFileSerializer.Builder.class.isAssignableFrom(c)) {                builderClass = (Class<? extends SequenceFileSerializer.Builder>) c;            } else {                logger.error("Unable to instantiate Builder from {}", formatType);                return null;            }        } catch (ClassNotFoundException ex) {            logger.error("Class not found: " + formatType, ex);            return null;        } catch (ClassCastException ex) {            logger.error("Class does not extend " + SequenceFileSerializer.Builder.class.getCanonicalName() + ": " + formatType, ex);            return null;        }    }        SequenceFileSerializer.Builder builder;    try {        builder = builderClass.newInstance();    } catch (InstantiationException ex) {        logger.error("Cannot instantiate builder: " + formatType, ex);        return null;    } catch (IllegalAccessException ex) {        logger.error("Cannot instantiate builder: " + formatType, ex);        return null;    }    return builder.build(context);}
9a3ae6a6417c641f30157ce2a23bffea4afbb388877f76d240aebebac9797188
getBuilderClass
public Class<? extends SequenceFileSerializer.Builder> getBuilderClass()
{    return builderClass;}
48a57ccf62aed2b9c002062bad1819c4f51c3dcfbd2778df14c7a16c1538c5d4
append
public void append(Event e) throws IOException
{    if (e.getHeaders().containsKey("fault")) {        throw new IOException("Injected fault");    } else if (e.getHeaders().containsKey("slow")) {        long waitTime = Long.parseLong(e.getHeaders().get("slow"));        try {            Thread.sleep(waitTime);        } catch (InterruptedException eT) {            throw new IOException("append interrupted", eT);        }    }    super.append(e);}
a728ff7f18ab2097a2c17cd4c9d2ab4cf5f01277c160be6f02b99913f5d111f1
open
public void open(String filePath, CompressionCodec codeC, CompressionType compType) throws IOException
{    super.open(filePath, codeC, compType);    if (closed) {        opened = true;    }}
48a57ccf62aed2b9c002062bad1819c4f51c3dcfbd2778df14c7a16c1538c5d4
append
public void append(Event e) throws IOException
{    if (e.getHeaders().containsKey("fault")) {        throw new IOException("Injected fault");    } else if (e.getHeaders().containsKey("fault-once")) {        e.getHeaders().remove("fault-once");        throw new IOException("Injected fault");    } else if (e.getHeaders().containsKey("fault-until-reopen")) {                if (openCount == 1) {            throw new IOException("Injected fault-until-reopen");        }    } else if (e.getHeaders().containsKey("slow")) {        long waitTime = Long.parseLong(e.getHeaders().get("slow"));        try {            Thread.sleep(waitTime);        } catch (InterruptedException eT) {            throw new IOException("append interrupted", eT);        }    }    super.append(e);}
e0823f55b3a09d41a3e1e792f7e6687db9199c2db9b29e9922d93cbdc6f1284b
close
public void close() throws IOException
{    closed = true;    super.close();}
7e793102fd9301788decac4e2b3dedf8191c85bcf4f85a963668bc8e6b5e02e9
getWriter
public HDFSWriter getWriter(String fileType) throws IOException
{    if (fileType == TestSequenceFileType) {        return new HDFSTestSeqWriter(openCount.incrementAndGet());    } else if (fileType == BadDataStreamType) {        return new HDFSBadDataStream();    } else {        throw new IOException("File type " + fileType + " not supported");    }}
f39e187e89894b635f21f76dc1d59966b71abc0a38d11f7787312713163a308c
getDfs
protected FileSystem getDfs(Configuration conf, Path dstPath) throws IOException
{    return fs;}
54c2d4395a421f905ed7190ae9fd2e5bec943a452d69245824a79d667390943b
append
public FSDataOutputStream append(Path arg0, int arg1, Progressable arg2) throws IOException
{    latestOutputStream = new MockFsDataOutputStream(fs.append(arg0, arg1, arg2), closeSucceed);    return latestOutputStream;}
a5a11c90e319ba18fa48c3abbfa751a14e8c133534edb6fa0da91a34f9fef214
create
public FSDataOutputStream create(Path arg0) throws IOException
{    latestOutputStream = new MockFsDataOutputStream(fs.create(arg0), closeSucceed);    return latestOutputStream;}
c69b81ec41c5187cf171b9a0095f146920e8cf1c6e01374299ffa73a48193d4e
create
public FSDataOutputStream create(Path arg0, FsPermission arg1, boolean arg2, int arg3, short arg4, long arg5, Progressable arg6) throws IOException
{    throw new IOException("Not a real file system");}
60b6f49bd932c3e990478e9303a609f3cf1a979619f58f147df41163e7095c71
delete
public boolean delete(Path arg0) throws IOException
{    return fs.delete(arg0);}
e4b476822586bb3890e2d307e290a9ab7263c73b4baf3564128c9a9a7c7ac2a5
delete
public boolean delete(Path arg0, boolean arg1) throws IOException
{    return fs.delete(arg0, arg1);}
34d9f1a5f41001f8d78dfb4cc3355ba8d284cc2fadaf4d5d2fb8a0370418b6fd
getFileStatus
public FileStatus getFileStatus(Path arg0) throws IOException
{    return fs.getFileStatus(arg0);}
4f32351934f6bb4372e27b1cbcd61023d7f2dbcd66e6c1cebbc891e10eed25f2
getUri
public URI getUri()
{    return fs.getUri();}
ca10d71f73326a11c1f986d8035825534dbaf18ac8f9d068102a4176fb509b6b
getWorkingDirectory
public Path getWorkingDirectory()
{    return fs.getWorkingDirectory();}
39eb55a7ee47589b0a8f0efabe85aeb96a3917e5c7bfb477d3e5512bca037051
listStatus
public FileStatus[] listStatus(Path arg0) throws IOException
{    return fs.listStatus(arg0);}
73e2e91e2289df10ff1da562338e2806cd4e8fc7e0c62f6a156a8f9574b98c90
mkdirs
public boolean mkdirs(Path arg0, FsPermission arg1) throws IOException
{        return fs.mkdirs(arg0, arg1);}
43dd09ee218edc79b02211efa7b9acec73848ecf346a108890dce89ab9954ff9
open
public FSDataInputStream open(Path arg0, int arg1) throws IOException
{    return fs.open(arg0, arg1);}
635a27349e9a64d61f4164792ea0eeac2e93a21898d65308ab6db52c0b94b2d5
rename
public boolean rename(Path arg0, Path arg1) throws IOException
{    currentRenameAttempts++;    logger.info("Attempting to Rename: '" + currentRenameAttempts + "' of '" + numberOfRetriesRequired + "'");    if (currentRenameAttempts >= numberOfRetriesRequired || numberOfRetriesRequired == 0) {        logger.info("Renaming file");        return fs.rename(arg0, arg1);    } else {        throw new IOException("MockIOException");    }}
c46631f216c1139ad54bc3bbb36f084e7d601cfcc7995580cfe8522152e84241
setWorkingDirectory
public void setWorkingDirectory(Path arg0)
{    fs.setWorkingDirectory(arg0);}
e0823f55b3a09d41a3e1e792f7e6687db9199c2db9b29e9922d93cbdc6f1284b
close
public void close() throws IOException
{    logger.info("Close Succeeded - " + closeSucceed);    if (closeSucceed) {        logger.info("closing file");        super.close();    } else {        throw new IOException("MockIOException");    }}
468bcef8ff74656bdd0c05119aea9a2a0633286a1f9d9f51ef69e3d293c0dcb2
getFilesOpened
public int getFilesOpened()
{    return filesOpened;}
94969d0b3c406ba1346e75f4151c25425f36ac7ce1e8a2f4c3e3d2610b250255
getFilesClosed
public int getFilesClosed()
{    return filesClosed;}
a9af5564521109b5a7c2fb8dfe125f7429206757d7faa0e70479fee011d010fc
getBytesWritten
public int getBytesWritten()
{    return bytesWritten;}
bf6978f1238dffe063c158ac475a9cc532ae3d81d3e44a89bd567650478a3d4c
getEventsWritten
public int getEventsWritten()
{    return eventsWritten;}
40f2fbe7225c06e59f270f65c9fa8a83779a0af93ae241226bec873a6075320f
getOpenedFilePath
public String getOpenedFilePath()
{    return filePath;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{}
a56fdb944898d4b84708496e3db760c3dfc8d960da338bef6af212f91dcd792c
open
public void open(String filePath) throws IOException
{    this.filePath = filePath;    filesOpened++;}
4d3532d4dad48abce303bc71a086e69e55a53d5817b236612f2dcd6bf6660f82
open
public void open(String filePath, CompressionCodec codec, CompressionType cType) throws IOException
{    this.filePath = filePath;    filesOpened++;}
48a57ccf62aed2b9c002062bad1819c4f51c3dcfbd2778df14c7a16c1538c5d4
append
public void append(Event e) throws IOException
{    eventsWritten++;    bytesWritten += e.getBody().length;}
ebf6369c0a538e889b3acec39360edad82f3c2ebed8c3c27b004adbf0ab4b95a
sync
public void sync() throws IOException
{}
e0823f55b3a09d41a3e1e792f7e6687db9199c2db9b29e9922d93cbdc6f1284b
close
public void close() throws IOException
{    filesClosed++;    int curr = currentCloseAttempts.incrementAndGet();    logger.info("Attempting to close: '" + currentCloseAttempts + "' of '" + numberOfRetriesRequired + "'");    if (curr >= numberOfRetriesRequired || numberOfRetriesRequired == 0) {        logger.info("closing file");    } else {        throw new IOException("MockIOException");    }}
3f57fe3eab5634d7e5ea2fb83d8cbfcb4e31d6cc24efc504084354689b7b8aac
isUnderReplicated
public boolean isUnderReplicated()
{    return false;}
497851d51831e2d2c3b9ffa2c4fbb21d9db1ca4b48fb4227c9d467396588093b
getKeyClass
public Class<LongWritable> getKeyClass()
{    return LongWritable.class;}
584acc7f38df787e54d064ec3ba0540838c9fe22f737ba012f8c707122a08c00
getValueClass
public Class<BytesWritable> getValueClass()
{    return BytesWritable.class;}
4ce555144ef7b5e330736046707696b8c538b4d4743a0e11e4f003b43efece0d
serialize
public Iterable<Record> serialize(Event e)
{    return Arrays.asList(new Record(new LongWritable(1234L), new BytesWritable(new byte[10])), new Record(new LongWritable(4567L), new BytesWritable(new byte[20])));}
1a3c6543e4b4a0817826da7dc96201bdc22504a59223b459d1b0e7a0a395a75a
build
public SequenceFileSerializer build(Context context)
{    return new MyCustomSerializer();}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    file = File.createTempFile(getClass().getSimpleName(), "");}
c6aaebb5a52567751db8dc8e1cb9dd4a4e582ef964a374b376c6a04f741802dc
tearDown
public void tearDown() throws Exception
{    file.delete();}
385ca6745967d288b12beaa2866a5f31aca3a9d3bb0c3735c6282cad9966915e
testNoCompression
public void testNoCompression() throws IOException
{    createAvroFile(file, null, false, false);    validateAvroFile(file);}
87bc872eb38ee104f20f27bac3e51dcf8d1dbf921e4a49008e9ac4202eda3f86
testNullCompression
public void testNullCompression() throws IOException
{    createAvroFile(file, "null", false, false);    validateAvroFile(file);}
2c820281932c2c49c0c056cf9921959d75c66014eb58ff0b6d1a3d2dfbad99c9
testDeflateCompression
public void testDeflateCompression() throws IOException
{    createAvroFile(file, "deflate", false, false);    validateAvroFile(file);}
0585388e7b458a00ea4f4718eae8499164a2d49907e50b2fb6f064f7f159da80
testSnappyCompression
public void testSnappyCompression() throws IOException
{    createAvroFile(file, "snappy", false, false);    validateAvroFile(file);}
dd268f30a9c0809307c1b0ecf61ef8ff6ccecfa64cfc6112d621eb0451aa5779
testSchemaUrl
public void testSchemaUrl() throws IOException
{    createAvroFile(file, null, true, false);    validateAvroFile(file);}
8449c685324c104fa223e27eb5c817323f60637507f57b579f6d0ef05d7a8d46
testStaticSchemaUrl
public void testStaticSchemaUrl() throws IOException
{    createAvroFile(file, null, false, true);    validateAvroFile(file);}
b50f97b6305073df73173fbd99ea87b853394d3c5aa63fb9dc6f3a28ccf0a9ed
testBothUrls
public void testBothUrls() throws IOException
{    createAvroFile(file, null, true, true);    validateAvroFile(file);}
ff447c004238a4f1acc72d1dd684a44dd86bafd8336680c10aa85237043888bc
createAvroFile
public void createAvroFile(File file, String codec, boolean useSchemaUrl, boolean useStaticSchemaUrl) throws IOException
{        OutputStream out = new FileOutputStream(file);    Context ctx = new Context();    if (codec != null) {        ctx.put("compressionCodec", codec);    }    Schema schema = Schema.createRecord("myrecord", null, null, false);    schema.setFields(Arrays.asList(new Schema.Field[] { new Schema.Field("message", Schema.create(Schema.Type.STRING), null, null) }));    GenericRecordBuilder recordBuilder = new GenericRecordBuilder(schema);    File schemaFile = null;    if (useSchemaUrl || useStaticSchemaUrl) {        schemaFile = File.createTempFile(getClass().getSimpleName(), ".avsc");        Files.write(schema.toString(), schemaFile, Charsets.UTF_8);    }    if (useStaticSchemaUrl) {        ctx.put(AvroEventSerializerConfigurationConstants.STATIC_SCHEMA_URL, schemaFile.toURI().toURL().toExternalForm());    }    EventSerializer.Builder builder = new AvroEventSerializer.Builder();    EventSerializer serializer = builder.build(ctx, out);    serializer.afterCreate();    for (int i = 0; i < 3; i++) {        GenericRecord record = recordBuilder.set("message", "Hello " + i).build();        Event event = EventBuilder.withBody(serializeAvro(record, schema));        if (schemaFile == null && !useSchemaUrl) {            event.getHeaders().put(AvroEventSerializer.AVRO_SCHEMA_LITERAL_HEADER, schema.toString());        } else if (useSchemaUrl) {            event.getHeaders().put(AvroEventSerializer.AVRO_SCHEMA_URL_HEADER, schemaFile.toURI().toURL().toExternalForm());        }        serializer.write(event);    }    serializer.flush();    serializer.beforeClose();    out.flush();    out.close();    if (schemaFile != null) {        schemaFile.delete();    }}
5f6a426528cb55fbc05d9fde7ff7e3554e48f563ae1b833b760e30c908ec9eb7
serializeAvro
private byte[] serializeAvro(Object datum, Schema schema) throws IOException
{    ByteArrayOutputStream out = new ByteArrayOutputStream();    ReflectDatumWriter<Object> writer = new ReflectDatumWriter<Object>(schema);    BinaryEncoder encoder = EncoderFactory.get().binaryEncoder(out, null);    out.reset();    writer.write(datum, encoder);    encoder.flush();    return out.toByteArray();}
053fdcaebd7b0cdcc4016d341256e033a7241b92108e9701373336ea51565b32
validateAvroFile
public void validateAvroFile(File file) throws IOException
{        DatumReader<GenericRecord> reader = new GenericDatumReader<GenericRecord>();    DataFileReader<GenericRecord> fileReader = new DataFileReader<GenericRecord>(file, reader);    GenericRecord record = new GenericData.Record(fileReader.getSchema());    int numEvents = 0;    while (fileReader.hasNext()) {        fileReader.next(record);        String bodyStr = record.get("message").toString();        System.out.println(bodyStr);        numEvents++;    }    fileReader.close();    Assert.assertEquals("Should have found a total of 3 events", 3, numEvents);}
edcd42501c51dedc18d88eff9c80e0ae0152927a978139173c7118e6961b6e90
setup
public static void setup()
{    timedRollerPool = Executors.newSingleThreadScheduledExecutor();    proxy = FlumeAuthenticationUtil.getAuthenticator(null, null).proxyAs(null);}
a03e1893d7de628033cafb361a2b62c2526f8749c8cea6395ba7cb32aa7521fd
teardown
public static void teardown() throws InterruptedException
{    timedRollerPool.shutdown();    timedRollerPool.awaitTermination(2, TimeUnit.SECONDS);    timedRollerPool.shutdownNow();}
2e658e20d50d3f6b4433e5573a5fad5c69a0bbaa0dfc3991436168d9d3fb8d51
testEventCountingRoller
public void testEventCountingRoller() throws IOException, InterruptedException
{    int maxEvents = 100;    MockHDFSWriter hdfsWriter = new MockHDFSWriter();    BucketWriter bucketWriter = new BucketWriterBuilder(hdfsWriter).setRollCount(maxEvents).build();    Event e = EventBuilder.withBody("foo", Charsets.UTF_8);    for (int i = 0; i < 1000; i++) {        bucketWriter.append(e);    }    logger.info("Number of events written: {}", hdfsWriter.getEventsWritten());    logger.info("Number of bytes written: {}", hdfsWriter.getBytesWritten());    logger.info("Number of files opened: {}", hdfsWriter.getFilesOpened());    Assert.assertEquals("events written", 1000, hdfsWriter.getEventsWritten());    Assert.assertEquals("bytes written", 3000, hdfsWriter.getBytesWritten());    Assert.assertEquals("files opened", 10, hdfsWriter.getFilesOpened());}
246ba506c801eb5b868847995bf5c0cd2bf5cb1115baea12d28c1bd8b087c8e0
testSizeRoller
public void testSizeRoller() throws IOException, InterruptedException
{    int maxBytes = 300;    MockHDFSWriter hdfsWriter = new MockHDFSWriter();    BucketWriter bucketWriter = new BucketWriterBuilder(hdfsWriter).setRollSize(maxBytes).build();    Event e = EventBuilder.withBody("foo", Charsets.UTF_8);    for (int i = 0; i < 1000; i++) {        bucketWriter.append(e);    }    logger.info("Number of events written: {}", hdfsWriter.getEventsWritten());    logger.info("Number of bytes written: {}", hdfsWriter.getBytesWritten());    logger.info("Number of files opened: {}", hdfsWriter.getFilesOpened());    Assert.assertEquals("events written", 1000, hdfsWriter.getEventsWritten());    Assert.assertEquals("bytes written", 3000, hdfsWriter.getBytesWritten());    Assert.assertEquals("files opened", 10, hdfsWriter.getFilesOpened());}
3ea5a9de7f78630734cb11cc24257ca0cb9280c7b57e0afb0fbdbc6a0e5faed1
testIntervalRoller
public void testIntervalRoller() throws IOException, InterruptedException
{        final int ROLL_INTERVAL = 1;    final int NUM_EVENTS = 10;    final AtomicBoolean calledBack = new AtomicBoolean(false);    MockHDFSWriter hdfsWriter = new MockHDFSWriter();    BucketWriter bucketWriter = new BucketWriterBuilder(hdfsWriter).setRollInterval(ROLL_INTERVAL).setOnCloseCallback(new HDFSEventSink.WriterCallback() {        @Override        public void run(String filePath) {            calledBack.set(true);        }    }).build();    Event e = EventBuilder.withBody("foo", Charsets.UTF_8);    long startNanos = System.nanoTime();    for (int i = 0; i < NUM_EVENTS - 1; i++) {        bucketWriter.append(e);    }        Thread.sleep(2 * ROLL_INTERVAL * 1000L);    Assert.assertTrue(bucketWriter.closed.get());    Assert.assertTrue(calledBack.get());    bucketWriter = new BucketWriterBuilder(hdfsWriter).setRollInterval(ROLL_INTERVAL).build();        bucketWriter.append(e);    long elapsedMillis = TimeUnit.MILLISECONDS.convert(System.nanoTime() - startNanos, TimeUnit.NANOSECONDS);    long elapsedSeconds = elapsedMillis / 1000L;    logger.info("Time elapsed: {} milliseconds", elapsedMillis);    logger.info("Number of events written: {}", hdfsWriter.getEventsWritten());    logger.info("Number of bytes written: {}", hdfsWriter.getBytesWritten());    logger.info("Number of files opened: {}", hdfsWriter.getFilesOpened());    logger.info("Number of files closed: {}", hdfsWriter.getFilesClosed());    Assert.assertEquals("events written", NUM_EVENTS, hdfsWriter.getEventsWritten());    Assert.assertEquals("bytes written", e.getBody().length * NUM_EVENTS, hdfsWriter.getBytesWritten());    Assert.assertEquals("files opened", 2, hdfsWriter.getFilesOpened());        Assert.assertEquals("files closed", 1, hdfsWriter.getFilesClosed());    logger.info("Waiting for roll...");    Thread.sleep(2 * ROLL_INTERVAL * 1000L);    logger.info("Number of files closed: {}", hdfsWriter.getFilesClosed());    Assert.assertEquals("files closed", 2, hdfsWriter.getFilesClosed());}
c24b2006638a8ea8c2a0f14ca3259c09dcd706a804b57e7bfa13fd604141f83e
run
public void run(String filePath)
{    calledBack.set(true);}
eff1afabd26ac68e7bcb9857809f2218cc223dd7dccb33329be74d997414f02d
testIntervalRollerBug
public void testIntervalRollerBug() throws IOException, InterruptedException
{        final int ROLL_INTERVAL = 1;    final int NUM_EVENTS = 10;    HDFSWriter hdfsWriter = new HDFSWriter() {        private volatile boolean open = false;        public void configure(Context context) {        }        public void sync() throws IOException {            if (!open) {                throw new IOException("closed");            }        }        public void open(String filePath, CompressionCodec codec, CompressionType cType) throws IOException {            open = true;        }        public void open(String filePath) throws IOException {            open = true;        }        public void close() throws IOException {            open = false;        }        @Override        public boolean isUnderReplicated() {            return false;        }        public void append(Event e) throws IOException {                        open = true;        }    };    File tmpFile = File.createTempFile("flume", "test");    tmpFile.deleteOnExit();    String path = tmpFile.getParent();    String name = tmpFile.getName();    BucketWriter bucketWriter = new BucketWriterBuilder(hdfsWriter).setRollInterval(ROLL_INTERVAL).setFilePath(path).setFileName(name).build();    Event e = EventBuilder.withBody("foo", Charsets.UTF_8);    for (int i = 0; i < NUM_EVENTS - 1; i++) {        bucketWriter.append(e);    }        Thread.sleep(2 * ROLL_INTERVAL * 1000L);        bucketWriter.flush();}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{}
ebf6369c0a538e889b3acec39360edad82f3c2ebed8c3c27b004adbf0ab4b95a
sync
public void sync() throws IOException
{    if (!open) {        throw new IOException("closed");    }}
4d3532d4dad48abce303bc71a086e69e55a53d5817b236612f2dcd6bf6660f82
open
public void open(String filePath, CompressionCodec codec, CompressionType cType) throws IOException
{    open = true;}
a56fdb944898d4b84708496e3db760c3dfc8d960da338bef6af212f91dcd792c
open
public void open(String filePath) throws IOException
{    open = true;}
e0823f55b3a09d41a3e1e792f7e6687db9199c2db9b29e9922d93cbdc6f1284b
close
public void close() throws IOException
{    open = false;}
3f57fe3eab5634d7e5ea2fb83d8cbfcb4e31d6cc24efc504084354689b7b8aac
isUnderReplicated
public boolean isUnderReplicated()
{    return false;}
48a57ccf62aed2b9c002062bad1819c4f51c3dcfbd2778df14c7a16c1538c5d4
append
public void append(Event e) throws IOException
{        open = true;}
d1667e381a6a43d55d2c15a4886fb2c716fc2ef54cf274cff3c0e7880f959872
testFileSuffixNotGiven
public void testFileSuffixNotGiven() throws IOException, InterruptedException
{        final int ROLL_INTERVAL = 1000;    final String suffix = null;        final long testTime = System.currentTimeMillis();    Clock testClock = new Clock() {        public long currentTimeMillis() {            return testTime;        }    };    MockHDFSWriter hdfsWriter = new MockHDFSWriter();    BucketWriter bucketWriter = new BucketWriterBuilder(hdfsWriter).setRollInterval(ROLL_INTERVAL).setFileSuffix(suffix).setClock(testClock).build();    Event e = EventBuilder.withBody("foo", Charsets.UTF_8);    bucketWriter.append(e);    Assert.assertTrue("Incorrect suffix", hdfsWriter.getOpenedFilePath().endsWith(Long.toString(testTime + 1) + ".tmp"));}
40832d7575f348110d4b53bc172a3cd3feb40023d7b53063d98f3ba0ab440aa6
currentTimeMillis
public long currentTimeMillis()
{    return testTime;}
3d71964a26e7dfa5b62805ddceffcea27d9bb60a16f915458b2b3f52ba3ae0b9
testFileSuffixGiven
public void testFileSuffixGiven() throws IOException, InterruptedException
{        final int ROLL_INTERVAL = 1000;    final String suffix = ".avro";        final long testTime = System.currentTimeMillis();    Clock testClock = new Clock() {        public long currentTimeMillis() {            return testTime;        }    };    MockHDFSWriter hdfsWriter = new MockHDFSWriter();    BucketWriter bucketWriter = new BucketWriterBuilder(hdfsWriter).setRollInterval(ROLL_INTERVAL).setFileSuffix(suffix).setClock(testClock).build();    Event e = EventBuilder.withBody("foo", Charsets.UTF_8);    bucketWriter.append(e);    Assert.assertTrue("Incorrect suffix", hdfsWriter.getOpenedFilePath().endsWith(Long.toString(testTime + 1) + suffix + ".tmp"));}
40832d7575f348110d4b53bc172a3cd3feb40023d7b53063d98f3ba0ab440aa6
currentTimeMillis
public long currentTimeMillis()
{    return testTime;}
3f2a093bbf6180dacfdc88a26ef3f9249478ec0a3a7ace632dac9dbd16434508
testFileSuffixCompressed
public void testFileSuffixCompressed() throws IOException, InterruptedException
{        final int ROLL_INTERVAL = 1000;    final String suffix = ".foo";    MockHDFSWriter hdfsWriter = new MockHDFSWriter();        final long testTime = System.currentTimeMillis();    Clock testClock = new Clock() {        public long currentTimeMillis() {            return testTime;        }    };    BucketWriter bucketWriter = new BucketWriterBuilder(hdfsWriter).setRollInterval(ROLL_INTERVAL).setFileSuffix(suffix).setCodeC(HDFSEventSink.getCodec("gzip")).setCompType(SequenceFile.CompressionType.BLOCK).setClock(testClock).build();    Event e = EventBuilder.withBody("foo", Charsets.UTF_8);    bucketWriter.append(e);    Assert.assertTrue("Incorrect suffix", hdfsWriter.getOpenedFilePath().endsWith(Long.toString(testTime + 1) + suffix + ".tmp"));}
40832d7575f348110d4b53bc172a3cd3feb40023d7b53063d98f3ba0ab440aa6
currentTimeMillis
public long currentTimeMillis()
{    return testTime;}
fe63bf2e86a5c83e5369d4948324aeafbae3ee9252c33ff93fa18d1359323e7d
testInUsePrefix
public void testInUsePrefix() throws IOException, InterruptedException
{        final int ROLL_INTERVAL = 1000;    final String PREFIX = "BRNO_IS_CITY_IN_CZECH_REPUBLIC";    MockHDFSWriter hdfsWriter = new MockHDFSWriter();    HDFSTextSerializer formatter = new HDFSTextSerializer();    BucketWriter bucketWriter = new BucketWriterBuilder(hdfsWriter).setRollInterval(ROLL_INTERVAL).setInUsePrefix(PREFIX).build();    Event e = EventBuilder.withBody("foo", Charsets.UTF_8);    bucketWriter.append(e);    Assert.assertTrue("Incorrect in use prefix", hdfsWriter.getOpenedFilePath().contains(PREFIX));}
61fb5cd2d62d51655ec1f50ba6d61fd289f705c10d737d9685f47ca388a94315
testInUseSuffix
public void testInUseSuffix() throws IOException, InterruptedException
{        final int ROLL_INTERVAL = 1000;    final String SUFFIX = "WELCOME_TO_THE_HELLMOUNTH";    MockHDFSWriter hdfsWriter = new MockHDFSWriter();    HDFSTextSerializer serializer = new HDFSTextSerializer();    BucketWriter bucketWriter = new BucketWriterBuilder(hdfsWriter).setRollInterval(ROLL_INTERVAL).setInUseSuffix(SUFFIX).build();    Event e = EventBuilder.withBody("foo", Charsets.UTF_8);    bucketWriter.append(e);    Assert.assertTrue("Incorrect in use suffix", hdfsWriter.getOpenedFilePath().contains(SUFFIX));}
18caa498e07324043c2cd334369c775473b3368394bd5ab6e5179a5d93618009
testCallbackOnClose
public void testCallbackOnClose() throws IOException, InterruptedException
{        final int ROLL_INTERVAL = 1000;    final String SUFFIX = "WELCOME_TO_THE_EREBOR";    final AtomicBoolean callbackCalled = new AtomicBoolean(false);    BucketWriter bucketWriter = new BucketWriterBuilder().setRollInterval(ROLL_INTERVAL).setInUseSuffix(SUFFIX).setOnCloseCallback(new HDFSEventSink.WriterCallback() {        @Override        public void run(String filePath) {            callbackCalled.set(true);        }    }).setOnCloseCallbackPath("blah").build();    Event e = EventBuilder.withBody("foo", Charsets.UTF_8);    bucketWriter.append(e);    bucketWriter.close(true);    Assert.assertTrue(callbackCalled.get());}
c24b2006638a8ea8c2a0f14ca3259c09dcd706a804b57e7bfa13fd604141f83e
run
public void run(String filePath)
{    callbackCalled.set(true);}
571dbf0dd43eeb627966feb6f0dfa0d6cd295fe18667217cdb98c8e5cfb3ec91
testSequenceFileRenameRetries
public void testSequenceFileRenameRetries() throws Exception
{    sequenceFileRenameRetryCoreTest(1, true);    sequenceFileRenameRetryCoreTest(5, true);    sequenceFileRenameRetryCoreTest(2, true);    sequenceFileRenameRetryCoreTest(1, false);    sequenceFileRenameRetryCoreTest(5, false);    sequenceFileRenameRetryCoreTest(2, false);}
e0bd53126e3b5b197e1fd9eeb4683ffdb32a8939c25ff355924a9eb144d041c4
testSequenceFileCloseRetries
public void testSequenceFileCloseRetries() throws Exception
{    sequenceFileCloseRetryCoreTest(5);    sequenceFileCloseRetryCoreTest(1);}
8f692e689579c02601575af194760c3d8b9dde218f6c6cfb4ce0fc98b2ffbdf3
sequenceFileRenameRetryCoreTest
public void sequenceFileRenameRetryCoreTest(int numberOfRetriesRequired, boolean closeSucceed) throws Exception
{    String hdfsPath = "file:///tmp/flume-test." + Calendar.getInstance().getTimeInMillis() + "." + Thread.currentThread().getId();    Context context = new Context();    Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);    Path dirPath = new Path(hdfsPath);    fs.delete(dirPath, true);    fs.mkdirs(dirPath);    context.put("hdfs.path", hdfsPath);    context.put("hdfs.closeTries", String.valueOf(numberOfRetriesRequired));    context.put("hdfs.rollCount", "1");    context.put("hdfs.retryInterval", "1");    context.put("hdfs.callTimeout", Long.toString(1000));    MockFileSystem mockFs = new MockFileSystem(fs, numberOfRetriesRequired, closeSucceed);    MockDataStream writer = new MockDataStream(mockFs);    BucketWriter bucketWriter = new BucketWriterBuilder(writer).setRollCount(1).setBatchSize(1).setFilePath(hdfsPath).setFileName(hdfsPath).setInUsePrefix("singleBucket").setCompType(null).setRetryInterval(1).setMaxCloseTries(numberOfRetriesRequired).setWriter(writer).build();    bucketWriter.setFileSystem(mockFs);            Event event = EventBuilder.withBody("test", Charsets.UTF_8);    bucketWriter.append(event);        bucketWriter.append(event);    TimeUnit.SECONDS.sleep(numberOfRetriesRequired + 2);    Assert.assertTrue("Expected " + numberOfRetriesRequired + " " + "but got " + bucketWriter.renameTries.get(), bucketWriter.renameTries.get() == numberOfRetriesRequired);}
e1f2f5c3b516012042f0df456397a3c312a12f39adbf11098c907bde96bea7aa
sequenceFileCloseRetryCoreTest
private void sequenceFileCloseRetryCoreTest(int numberOfRetriesRequired) throws Exception
{    String hdfsPath = "file:///tmp/flume-test." + Calendar.getInstance().getTimeInMillis() + "." + Thread.currentThread().getId();    Context context = new Context();    Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);    Path dirPath = new Path(hdfsPath);    fs.delete(dirPath, true);    fs.mkdirs(dirPath);    context.put("hdfs.path", hdfsPath);    context.put("hdfs.closeTries", String.valueOf(numberOfRetriesRequired));    context.put("hdfs.rollCount", "1");    context.put("hdfs.retryInterval", "1");    context.put("hdfs.callTimeout", Long.toString(1000));    MockHDFSWriter mockHDFSWriter = new MockHDFSWriter(Integer.MAX_VALUE);    ExecutorService executorService = Executors.newSingleThreadExecutor();    BucketWriter bucketWriter = new BucketWriter(0, 0, 1, 1, ctx, hdfsPath, hdfsPath, "singleBucket", ".tmp", null, null, null, mockHDFSWriter, timedRollerPool, proxy, new SinkCounter("test-bucket-writer-" + System.currentTimeMillis()), 0, null, null, 30000, executorService, 1, numberOfRetriesRequired);    Event event = EventBuilder.withBody("test", Charsets.UTF_8);    bucketWriter.append(event);    bucketWriter.close(false);    TimeUnit.SECONDS.sleep(numberOfRetriesRequired + 2);    Assert.assertEquals("ExcceutorService should be empty", executorService.shutdownNow().size(), 0);    Assert.assertEquals("Expected " + numberOfRetriesRequired + " " + "but got " + mockHDFSWriter.currentCloseAttempts, mockHDFSWriter.currentCloseAttempts.get(), numberOfRetriesRequired);}
cf4e1b0a0fced4112d0b884a6b79f6274bc0b5a322b53cf0872fb43b550d8390
testRotateBucketOnIOException
public void testRotateBucketOnIOException() throws IOException, InterruptedException
{    MockHDFSWriter hdfsWriter = Mockito.spy(new MockHDFSWriter());    PrivilegedExecutor ugiProxy = FlumeAuthenticationUtil.getAuthenticator(null, null).proxyAs("alice");        final int ROLL_COUNT = 1;    BucketWriter bucketWriter = new BucketWriterBuilder(hdfsWriter).setProxyUser(ugiProxy).setRollCount(ROLL_COUNT).build();    Event e = EventBuilder.withBody("foo", Charsets.UTF_8);        bucketWriter.append(e);        IOException expectedIOException = new IOException("Test injected IOException");    Mockito.doThrow(expectedIOException).when(hdfsWriter).append(Mockito.any(Event.class));        try {        bucketWriter.append(e);        Assert.fail("Expected IOException wasn't thrown during append");    } catch (IOException ex) {        Assert.assertEquals(expectedIOException, ex);        logger.info("Caught expected IOException", ex);    }        try {        bucketWriter.append(e);        Assert.fail("BucketWriter should be already closed, BucketClosedException expected");    } catch (BucketClosedException ex) {        logger.info("Caught expected BucketClosedException", ex);    }    Assert.assertEquals("events written", 1, hdfsWriter.getEventsWritten());    Assert.assertEquals("2 files should be closed", 2, hdfsWriter.getFilesClosed());}
87f6e7d1f3ba44e19958e8118f92972773439e04ff36eb153fe45c2e8a2a3cbb
setRollInterval
public BucketWriterBuilder setRollInterval(long rollInterval)
{    this.rollInterval = rollInterval;    return this;}
4714cacf13e537cc68984fda83c607f8d64a3e6dfa50312aff4d5b5ec440a10f
setRollSize
public BucketWriterBuilder setRollSize(long rollSize)
{    this.rollSize = rollSize;    return this;}
3133a510f9d04d327407eeaa576f6048557ac5cbd5fd98cadd6dc50a9877a99b
setRollCount
public BucketWriterBuilder setRollCount(long rollCount)
{    this.rollCount = rollCount;    return this;}
cdf32f612b66a9ecf65423f340b0d0badb201487a249cb47a01a5ffb68fa0717
setBatchSize
public BucketWriterBuilder setBatchSize(long batchSize)
{    this.batchSize = batchSize;    return this;}
eca465f65b5c87d7b9a7c62ba153b77c93e0a46343bb88da233a229bc3bd0e36
setContext
public BucketWriterBuilder setContext(Context context)
{    this.context = context;    return this;}
3c55bbd4373ad6882a7c76c4cafc8d64ded2284913bfce2b699beef6f0ebb2d0
setFilePath
public BucketWriterBuilder setFilePath(String filePath)
{    this.filePath = filePath;    return this;}
3bbcbbd8dc989c04847d0de3e6dd1bc585c0a93d9eb5317d5a09f10900a877ae
setFileName
public BucketWriterBuilder setFileName(String fileName)
{    this.fileName = fileName;    return this;}
63babd57cbbfc99805b922d217d7c5cc4be94aed1b4b26f45270d152fb16b20c
setInUsePrefix
public BucketWriterBuilder setInUsePrefix(String inUsePrefix)
{    this.inUsePrefix = inUsePrefix;    return this;}
08f96d9e80b76c7c11289b62241f3c8963d85bd327c3504b3f8fc210dd70cd03
setInUseSuffix
public BucketWriterBuilder setInUseSuffix(String inUseSuffix)
{    this.inUseSuffix = inUseSuffix;    return this;}
a86e728f323feb5d4ecd5cfa93567e744f4bb11c4222a71d01f25c8addc58754
setFileSuffix
public BucketWriterBuilder setFileSuffix(String fileSuffix)
{    this.fileSuffix = fileSuffix;    return this;}
ec95581324f2f10c54faad7cd60bd657417e331f29d7ff273332c57dacedb2f1
setCodeC
public BucketWriterBuilder setCodeC(CompressionCodec codeC)
{    this.codeC = codeC;    return this;}
2b81285ae4b4503a9791f1914704196c4d03ea971c2354193b620cb7da7b4e9a
setCompType
public BucketWriterBuilder setCompType(CompressionType compType)
{    this.compType = compType;    return this;}
5d55f1a5308c538d4da80341c251db801c2a62123097e3ed46da0d1140bae0e0
setTimedRollerPool
public BucketWriterBuilder setTimedRollerPool(ScheduledExecutorService timedRollerPool)
{    this.timedRollerPool = timedRollerPool;    return this;}
5188c475898b34b1622e0775d4a2cfdaf7984783256739021b4671a3b6ae8563
setProxyUser
public BucketWriterBuilder setProxyUser(PrivilegedExecutor proxyUser)
{    this.proxyUser = proxyUser;    return this;}
927595fe711a43e88709cbc3b7c2742479fa30a1632c364f9d825fc5a6c22c31
setSinkCounter
public BucketWriterBuilder setSinkCounter(SinkCounter sinkCounter)
{    this.sinkCounter = sinkCounter;    return this;}
a2cc1bd2d4f5c315603bfa19d9afdf092b84818fffc9737af1f3d5cb18ae0fbb
setIdleTimeout
public BucketWriterBuilder setIdleTimeout(int idleTimeout)
{    this.idleTimeout = idleTimeout;    return this;}
8b8e64610cc8417be111429e22979c4d2e980ea5eb90e2aae96149ea14614079
setOnCloseCallback
public BucketWriterBuilder setOnCloseCallback(WriterCallback onCloseCallback)
{    this.onCloseCallback = onCloseCallback;    return this;}
a651b91f92e527ce008f5dd5f411ae66336a9e799c6b294162b27704511321af
setOnCloseCallbackPath
public BucketWriterBuilder setOnCloseCallbackPath(String onCloseCallbackPath)
{    this.onCloseCallbackPath = onCloseCallbackPath;    return this;}
bd462f19374fe7b9514627ea4497937fe52c726b4aa2a3c369bef9042ef17e72
setCallTimeout
public BucketWriterBuilder setCallTimeout(long callTimeout)
{    this.callTimeout = callTimeout;    return this;}
36829219a15fc16bb0991580bbd7ce4d13f0e66d2b406b87df8fe8b08ee74fa3
setCallTimeoutPool
public BucketWriterBuilder setCallTimeoutPool(ExecutorService callTimeoutPool)
{    this.callTimeoutPool = callTimeoutPool;    return this;}
33e3abf70f171b973d8da81761b5b7a700f6f104691e97513936c845cae0ab8a
setRetryInterval
public BucketWriterBuilder setRetryInterval(long retryInterval)
{    this.retryInterval = retryInterval;    return this;}
46cff9c29f4fccccac4102adffd9e075961c3ae844400d6e6dec112ec2fc8814
setMaxCloseTries
public BucketWriterBuilder setMaxCloseTries(int maxCloseTries)
{    this.maxCloseTries = maxCloseTries;    return this;}
43bd7ff6edaff58f05de2639628f599a5d7315e3e1035c7d0f5eccaa5de0e1dd
setWriter
public BucketWriterBuilder setWriter(HDFSWriter writer)
{    this.writer = writer;    return this;}
5ec179cd2804be1939f3582196283ff988eca75c24d8506557d690d8a3ce05c7
setClock
public BucketWriterBuilder setClock(Clock clock)
{    this.clock = clock;    return this;}
62e1e54939e0655d7617e5b398930470355ebd54c9c43639a9e7f5ff9d920463
build
public BucketWriter build()
{    if (clock == null) {        clock = new SystemClock();    }    if (writer == null) {        writer = new MockHDFSWriter();    }    return new BucketWriter(rollInterval, rollSize, rollCount, batchSize, context, filePath, fileName, inUsePrefix, inUseSuffix, fileSuffix, codeC, compType, writer, timedRollerPool, proxyUser, sinkCounter, idleTimeout, onCloseCallback, onCloseCallbackPath, callTimeout, callTimeoutPool, retryInterval, maxCloseTries, clock);}
1359225215853f3f89f4af5641e298ce821f026f91f6d3bc4f753adf82ab1c74
init
public void init() throws Exception
{    this.file = new File("target/test/data/foo.gz");    this.fileURI = file.getAbsoluteFile().toURI().toString();    logger.info("File URI: {}", fileURI);    Configuration conf = new Configuration();        conf.set("fs.file.impl", "org.apache.hadoop.fs.RawLocalFileSystem");    Path path = new Path(fileURI);        path.getFileSystem(conf);    this.factory = new CompressionCodecFactory(conf);}
b833eac70cc93b2e8f4c1ca3751b8c33e1aa426139d6a10176db843d4ecf49f4
testGzipDurability
public void testGzipDurability() throws Exception
{    Context context = new Context();    HDFSCompressedDataStream writer = new HDFSCompressedDataStream();    writer.configure(context);    writer.open(fileURI, factory.getCodec(new Path(fileURI)), SequenceFile.CompressionType.BLOCK);    String[] bodies = { "yarf!" };    writeBodies(writer, bodies);    byte[] buf = new byte[256];    GZIPInputStream cmpIn = new GZIPInputStream(new FileInputStream(file));    int len = cmpIn.read(buf);    String result = new String(buf, 0, len, Charsets.UTF_8);        result = result.trim();    Assert.assertEquals("input and output must match", bodies[0], result);}
36f15ca2ca5af780a5674899ae89aee4b9f2db120718034f46533c5bfa9b08fc
testGzipDurabilityWithSerializer
public void testGzipDurabilityWithSerializer() throws Exception
{    Context context = new Context();    context.put("serializer", "AVRO_EVENT");    HDFSCompressedDataStream writer = new HDFSCompressedDataStream();    writer.configure(context);    writer.open(fileURI, factory.getCodec(new Path(fileURI)), SequenceFile.CompressionType.BLOCK);    String[] bodies = { "yarf!", "yarfing!" };    writeBodies(writer, bodies);    int found = 0;    int expected = bodies.length;    List<String> expectedBodies = Lists.newArrayList(bodies);    GZIPInputStream cmpIn = new GZIPInputStream(new FileInputStream(file));    DatumReader<GenericRecord> reader = new GenericDatumReader<GenericRecord>();    DataFileStream<GenericRecord> avroStream = new DataFileStream<GenericRecord>(cmpIn, reader);    GenericRecord record = new GenericData.Record(avroStream.getSchema());    while (avroStream.hasNext()) {        avroStream.next(record);        CharsetDecoder decoder = Charsets.UTF_8.newDecoder();        String bodyStr = decoder.decode((ByteBuffer) record.get("body")).toString();        expectedBodies.remove(bodyStr);        found++;    }    avroStream.close();    cmpIn.close();    Assert.assertTrue("Found = " + found + ", Expected = " + expected + ", Left = " + expectedBodies.size() + " " + expectedBodies, expectedBodies.size() == 0);}
5cdd0042af180b73322ebe8cb5c31172e93a9be8cb9be75a5ad0fdefb6ee9514
writeBodies
private void writeBodies(HDFSCompressedDataStream writer, String... bodies) throws Exception
{    for (String body : bodies) {        Event evt = EventBuilder.withBody(body, Charsets.UTF_8);        writer.append(evt);    }    writer.sync();}
f659410e64e9c27345bcb92204e8a54629cbab1c434d1bf85100ef45d9229866
dirCleanup
private void dirCleanup()
{    Configuration conf = new Configuration();    try {        FileSystem fs = FileSystem.get(conf);        Path dirPath = new Path(testPath);        if (fs.exists(dirPath)) {            fs.delete(dirPath, true);        }    } catch (IOException eIO) {        LOG.warn("IO Error in test cleanup", eIO);    }}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    LOG.debug("Starting...");    /*     * FIXME: Use a dynamic path to support concurrent test execution. Also,     * beware of the case where this path is used for something or when the     * Hadoop config points at file:/     * better way of testing HDFS related functionality.     */    testPath = "file:///tmp/flume-test." + Calendar.getInstance().getTimeInMillis() + "." + Thread.currentThread().getId();    sink = new HDFSEventSink();    sink.setName("HDFSEventSink-" + UUID.randomUUID().toString());    dirCleanup();}
39e5ba029cc67f6f1d45c6d20f0df595ec16bc61da20d7680fcbbdae4fe7f95b
tearDown
public void tearDown()
{    if (System.getenv("hdfs_keepFiles") == null)        dirCleanup();}
8b3767061137185d9d6e9d60caf0c18d580164594ecc3ceb11c10165ad0570a9
testTextBatchAppend
public void testTextBatchAppend() throws Exception
{    doTestTextBatchAppend(false);}
69eff98562fe6e4ac4f15c6564989087fc2b936744eb875647c8b8668caa5b0a
testTextBatchAppendRawFS
public void testTextBatchAppendRawFS() throws Exception
{    doTestTextBatchAppend(true);}
6d425c83625b31ed6bcb11ec3b6a3d23704f8c8e21e5485358c2c2f21660070a
doTestTextBatchAppend
public void doTestTextBatchAppend(boolean useRawLocalFileSystem) throws Exception
{    LOG.debug("Starting...");    final long rollCount = 10;    final long batchSize = 2;    final String fileName = "FlumeData";    String newPath = testPath + "/singleTextBucket";    int totalEvents = 0;    int i = 1, j = 1;        Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);    Path dirPath = new Path(newPath);    fs.delete(dirPath, true);    fs.mkdirs(dirPath);    Context context = new Context();        context.put("hdfs.path", newPath);    context.put("hdfs.filePrefix", fileName);    context.put("hdfs.rollCount", String.valueOf(rollCount));    context.put("hdfs.rollInterval", "0");    context.put("hdfs.rollSize", "0");    context.put("hdfs.batchSize", String.valueOf(batchSize));    context.put("hdfs.writeFormat", "Text");    context.put("hdfs.useRawLocalFileSystem", Boolean.toString(useRawLocalFileSystem));    context.put("hdfs.fileType", "DataStream");    Configurables.configure(sink, context);    Channel channel = new MemoryChannel();    Configurables.configure(channel, context);    sink.setChannel(channel);    sink.start();    Calendar eventDate = Calendar.getInstance();    List<String> bodies = Lists.newArrayList();        for (i = 1; i <= (rollCount * 10) / batchSize; i++) {        Transaction txn = channel.getTransaction();        txn.begin();        for (j = 1; j <= batchSize; j++) {            Event event = new SimpleEvent();            eventDate.clear();                        eventDate.set(2011, i, i, i, 0);            String body = "Test." + i + "." + j;            event.setBody(body.getBytes());            bodies.add(body);            channel.put(event);            totalEvents++;        }        txn.commit();        txn.close();                sink.process();    }    sink.stop();        FileStatus[] dirStat = fs.listStatus(dirPath);    Path[] fList = FileUtil.stat2Paths(dirStat);        long expectedFiles = totalEvents / rollCount;    if (totalEvents % rollCount > 0)        expectedFiles++;    Assert.assertEquals("num files wrong, found: " + Lists.newArrayList(fList), expectedFiles, fList.length);        verifyOutputTextFiles(fs, conf, dirPath.toUri().getPath(), fileName, bodies);}
8754cfc7c2886269b70adc953f20b408f6156ab75e440687220d2cfb32e01a7c
testLifecycle
public void testLifecycle() throws InterruptedException, LifecycleException
{    LOG.debug("Starting...");    Context context = new Context();    context.put("hdfs.path", testPath);    /*     * context.put("hdfs.rollInterval", String.class);     * context.get("hdfs.rollSize", String.class); context.get("hdfs.rollCount",     * String.class);     */    Configurables.configure(sink, context);    sink.setChannel(new MemoryChannel());    sink.start();    sink.stop();}
5c1738680294cc9e71851b6eca98d4a02e95631a6dc24d3f0f36499ef63e7604
testEmptyChannelResultsInStatusBackoff
public void testEmptyChannelResultsInStatusBackoff() throws InterruptedException, LifecycleException, EventDeliveryException
{    LOG.debug("Starting...");    Context context = new Context();    Channel channel = new MemoryChannel();    context.put("hdfs.path", testPath);    context.put("keep-alive", "0");    Configurables.configure(sink, context);    Configurables.configure(channel, context);    sink.setChannel(channel);    sink.start();    Assert.assertEquals(Status.BACKOFF, sink.process());    sink.stop();}
63c4b8b22297cc83d5620129b5daf77511bcd51b9378b9c87aa2954aa5f5f03c
testKerbFileAccess
public void testKerbFileAccess() throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{    LOG.debug("Starting testKerbFileAccess() ...");    final String fileName = "FlumeData";    final long rollCount = 5;    final long batchSize = 2;    String newPath = testPath + "/singleBucket";    String kerbConfPrincipal = "user1/localhost@EXAMPLE.COM";    String kerbKeytab = "/usr/lib/flume/nonexistkeytabfile";        Configuration conf = new Configuration();    conf.set(CommonConfigurationKeys.HADOOP_SECURITY_AUTHENTICATION, "kerberos");    UserGroupInformation.setConfiguration(conf);    Context context = new Context();    context.put("hdfs.path", newPath);    context.put("hdfs.filePrefix", fileName);    context.put("hdfs.rollCount", String.valueOf(rollCount));    context.put("hdfs.batchSize", String.valueOf(batchSize));    context.put("hdfs.kerberosPrincipal", kerbConfPrincipal);    context.put("hdfs.kerberosKeytab", kerbKeytab);    try {        Configurables.configure(sink, context);        Assert.fail("no exception thrown");    } catch (IllegalArgumentException expected) {        Assert.assertTrue(expected.getMessage().contains("Keytab is not a readable file"));    } finally {                conf.set(CommonConfigurationKeys.HADOOP_SECURITY_AUTHENTICATION, "simple");        UserGroupInformation.setConfiguration(conf);    }}
dd57610ed6a45aedefd6fee04cc23d89761fb8395a45f1b0cee9ca8316358e8a
testTextAppend
public void testTextAppend() throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{    LOG.debug("Starting...");    final long rollCount = 3;    final long batchSize = 2;    final String fileName = "FlumeData";    String newPath = testPath + "/singleTextBucket";    int totalEvents = 0;    int i = 1, j = 1;        Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);    Path dirPath = new Path(newPath);    fs.delete(dirPath, true);    fs.mkdirs(dirPath);    Context context = new Context();        context.put("hdfs.path", newPath);    context.put("hdfs.filePrefix", fileName);    context.put("hdfs.rollCount", String.valueOf(rollCount));    context.put("hdfs.batchSize", String.valueOf(batchSize));    context.put("hdfs.writeFormat", "Text");    context.put("hdfs.fileType", "DataStream");    Configurables.configure(sink, context);    Channel channel = new MemoryChannel();    Configurables.configure(channel, context);    sink.setChannel(channel);    sink.start();    Calendar eventDate = Calendar.getInstance();    List<String> bodies = Lists.newArrayList();        for (i = 1; i < 4; i++) {        Transaction txn = channel.getTransaction();        txn.begin();        for (j = 1; j <= batchSize; j++) {            Event event = new SimpleEvent();            eventDate.clear();                        eventDate.set(2011, i, i, i, 0);            event.getHeaders().put("timestamp", String.valueOf(eventDate.getTimeInMillis()));            event.getHeaders().put("hostname", "Host" + i);            String body = "Test." + i + "." + j;            event.setBody(body.getBytes());            bodies.add(body);            channel.put(event);            totalEvents++;        }        txn.commit();        txn.close();                sink.process();    }    sink.stop();        FileStatus[] dirStat = fs.listStatus(dirPath);    Path[] fList = FileUtil.stat2Paths(dirStat);        long expectedFiles = totalEvents / rollCount;    if (totalEvents % rollCount > 0)        expectedFiles++;    Assert.assertEquals("num files wrong, found: " + Lists.newArrayList(fList), expectedFiles, fList.length);    verifyOutputTextFiles(fs, conf, dirPath.toUri().getPath(), fileName, bodies);}
a1b826922b063d4767e0ac73e8ff84a8853dfe4a7125bdf7fdeba2bc683e8eb0
testAvroAppend
public void testAvroAppend() throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{    LOG.debug("Starting...");    final long rollCount = 3;    final long batchSize = 2;    final String fileName = "FlumeData";    String newPath = testPath + "/singleTextBucket";    int totalEvents = 0;    int i = 1, j = 1;        Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);    Path dirPath = new Path(newPath);    fs.delete(dirPath, true);    fs.mkdirs(dirPath);    Context context = new Context();        context.put("hdfs.path", newPath);    context.put("hdfs.filePrefix", fileName);    context.put("hdfs.rollCount", String.valueOf(rollCount));    context.put("hdfs.batchSize", String.valueOf(batchSize));    context.put("hdfs.writeFormat", "Text");    context.put("hdfs.fileType", "DataStream");    context.put("serializer", "AVRO_EVENT");    Configurables.configure(sink, context);    Channel channel = new MemoryChannel();    Configurables.configure(channel, context);    sink.setChannel(channel);    sink.start();    Calendar eventDate = Calendar.getInstance();    List<String> bodies = Lists.newArrayList();        for (i = 1; i < 4; i++) {        Transaction txn = channel.getTransaction();        txn.begin();        for (j = 1; j <= batchSize; j++) {            Event event = new SimpleEvent();            eventDate.clear();                        eventDate.set(2011, i, i, i, 0);            event.getHeaders().put("timestamp", String.valueOf(eventDate.getTimeInMillis()));            event.getHeaders().put("hostname", "Host" + i);            String body = "Test." + i + "." + j;            event.setBody(body.getBytes());            bodies.add(body);            channel.put(event);            totalEvents++;        }        txn.commit();        txn.close();                sink.process();    }    sink.stop();        FileStatus[] dirStat = fs.listStatus(dirPath);    Path[] fList = FileUtil.stat2Paths(dirStat);        long expectedFiles = totalEvents / rollCount;    if (totalEvents % rollCount > 0)        expectedFiles++;    Assert.assertEquals("num files wrong, found: " + Lists.newArrayList(fList), expectedFiles, fList.length);    verifyOutputAvroFiles(fs, conf, dirPath.toUri().getPath(), fileName, bodies);}
4ac81c2b6ff0871ed6469c9a6a80a1bddc13d8df1111a0a70868e009875c9e5b
testSimpleAppend
public void testSimpleAppend() throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{    LOG.debug("Starting...");    final String fileName = "FlumeData";    final long rollCount = 5;    final long batchSize = 2;    final int numBatches = 4;    String newPath = testPath + "/singleBucket";    int totalEvents = 0;    int i = 1, j = 1;        Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);    Path dirPath = new Path(newPath);    fs.delete(dirPath, true);    fs.mkdirs(dirPath);    Context context = new Context();    context.put("hdfs.path", newPath);    context.put("hdfs.filePrefix", fileName);    context.put("hdfs.rollCount", String.valueOf(rollCount));    context.put("hdfs.batchSize", String.valueOf(batchSize));    Configurables.configure(sink, context);    Channel channel = new MemoryChannel();    Configurables.configure(channel, context);    sink.setChannel(channel);    sink.start();    Calendar eventDate = Calendar.getInstance();    List<String> bodies = Lists.newArrayList();        for (i = 1; i < numBatches; i++) {        Transaction txn = channel.getTransaction();        txn.begin();        for (j = 1; j <= batchSize; j++) {            Event event = new SimpleEvent();            eventDate.clear();                        eventDate.set(2011, i, i, i, 0);            event.getHeaders().put("timestamp", String.valueOf(eventDate.getTimeInMillis()));            event.getHeaders().put("hostname", "Host" + i);            String body = "Test." + i + "." + j;            event.setBody(body.getBytes());            bodies.add(body);            channel.put(event);            totalEvents++;        }        txn.commit();        txn.close();                sink.process();    }    sink.stop();        FileStatus[] dirStat = fs.listStatus(dirPath);    Path[] fList = FileUtil.stat2Paths(dirStat);        long expectedFiles = totalEvents / rollCount;    if (totalEvents % rollCount > 0)        expectedFiles++;    Assert.assertEquals("num files wrong, found: " + Lists.newArrayList(fList), expectedFiles, fList.length);    verifyOutputSequenceFiles(fs, conf, dirPath.toUri().getPath(), fileName, bodies);}
6f57f41c704f3eeea8cb4d6df4183e52a10c98b49f32aabdffa1e84be31afccb
testSimpleAppendLocalTime
public void testSimpleAppendLocalTime() throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{    final long currentTime = System.currentTimeMillis();    Clock clk = new Clock() {        @Override        public long currentTimeMillis() {            return currentTime;        }    };    LOG.debug("Starting...");    final String fileName = "FlumeData";    final long rollCount = 5;    final long batchSize = 2;    final int numBatches = 4;    String newPath = testPath + "/singleBucket/%s";    String expectedPath = testPath + "/singleBucket/" + String.valueOf(currentTime / 1000);    int totalEvents = 0;    int i = 1, j = 1;        Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);    Path dirPath = new Path(expectedPath);    fs.delete(dirPath, true);    fs.mkdirs(dirPath);    Context context = new Context();    context.put("hdfs.path", newPath);    context.put("hdfs.filePrefix", fileName);    context.put("hdfs.rollCount", String.valueOf(rollCount));    context.put("hdfs.batchSize", String.valueOf(batchSize));    context.put("hdfs.useLocalTimeStamp", String.valueOf(true));    Configurables.configure(sink, context);    Channel channel = new MemoryChannel();    Configurables.configure(channel, context);    sink.setChannel(channel);    sink.setBucketClock(clk);    sink.start();    Calendar eventDate = Calendar.getInstance();    List<String> bodies = Lists.newArrayList();        for (i = 1; i < numBatches; i++) {        Transaction txn = channel.getTransaction();        txn.begin();        for (j = 1; j <= batchSize; j++) {            Event event = new SimpleEvent();            eventDate.clear();                        eventDate.set(2011, i, i, i, 0);            event.getHeaders().put("timestamp", String.valueOf(eventDate.getTimeInMillis()));            event.getHeaders().put("hostname", "Host" + i);            String body = "Test." + i + "." + j;            event.setBody(body.getBytes());            bodies.add(body);            channel.put(event);            totalEvents++;        }        txn.commit();        txn.close();                sink.process();    }    sink.stop();        FileStatus[] dirStat = fs.listStatus(dirPath);    Path[] fList = FileUtil.stat2Paths(dirStat);        long expectedFiles = totalEvents / rollCount;    if (totalEvents % rollCount > 0)        expectedFiles++;    Assert.assertEquals("num files wrong, found: " + Lists.newArrayList(fList), expectedFiles, fList.length);    verifyOutputSequenceFiles(fs, conf, dirPath.toUri().getPath(), fileName, bodies);        sink.setBucketClock(new SystemClock());}
40832d7575f348110d4b53bc172a3cd3feb40023d7b53063d98f3ba0ab440aa6
currentTimeMillis
public long currentTimeMillis()
{    return currentTime;}
e7460f209c33e568f2de4e9a8e071e12870a3412246fc9b837936014b50d2da7
testAppend
public void testAppend() throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{    LOG.debug("Starting...");    final long rollCount = 3;    final long batchSize = 2;    final String fileName = "FlumeData";        Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);    Path dirPath = new Path(testPath);    fs.delete(dirPath, true);    fs.mkdirs(dirPath);    Context context = new Context();    context.put("hdfs.path", testPath + "/%Y-%m-%d/%H");    context.put("hdfs.timeZone", "UTC");    context.put("hdfs.filePrefix", fileName);    context.put("hdfs.rollCount", String.valueOf(rollCount));    context.put("hdfs.batchSize", String.valueOf(batchSize));    Configurables.configure(sink, context);    Channel channel = new MemoryChannel();    Configurables.configure(channel, context);    sink.setChannel(channel);    sink.start();    Calendar eventDate = Calendar.getInstance();    List<String> bodies = Lists.newArrayList();        for (int i = 1; i < 4; i++) {        Transaction txn = channel.getTransaction();        txn.begin();        for (int j = 1; j <= batchSize; j++) {            Event event = new SimpleEvent();            eventDate.clear();                        eventDate.set(2011, i, i, i, 0);            event.getHeaders().put("timestamp", String.valueOf(eventDate.getTimeInMillis()));            event.getHeaders().put("hostname", "Host" + i);            String body = "Test." + i + "." + j;            event.setBody(body.getBytes());            bodies.add(body);            channel.put(event);        }        txn.commit();        txn.close();                sink.process();    }    sink.stop();    verifyOutputSequenceFiles(fs, conf, dirPath.toUri().getPath(), fileName, bodies);}
1f243529c2e908d19a83d1644bacea911ad13d2fb88f4fa89c3329e24d8f363a
testBadSimpleAppend
public void testBadSimpleAppend() throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{    LOG.debug("Starting...");    final String fileName = "FlumeData";    final long rollCount = 5;    final long batchSize = 2;    final int numBatches = 4;    String newPath = testPath + "/singleBucket";    int totalEvents = 0;    int i = 1, j = 1;    HDFSTestWriterFactory badWriterFactory = new HDFSTestWriterFactory();    sink = new HDFSEventSink(badWriterFactory);        Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);    Path dirPath = new Path(newPath);    fs.delete(dirPath, true);    fs.mkdirs(dirPath);    Context context = new Context();    context.put("hdfs.path", newPath);    context.put("hdfs.filePrefix", fileName);    context.put("hdfs.rollCount", String.valueOf(rollCount));    context.put("hdfs.batchSize", String.valueOf(batchSize));    context.put("hdfs.fileType", HDFSTestWriterFactory.TestSequenceFileType);    Configurables.configure(sink, context);    Channel channel = new MemoryChannel();    Configurables.configure(channel, context);    sink.setChannel(channel);    sink.start();    Calendar eventDate = Calendar.getInstance();    List<String> bodies = Lists.newArrayList();        for (i = 1; i < numBatches; i++) {        Transaction txn = channel.getTransaction();        txn.begin();        for (j = 1; j <= batchSize; j++) {            Event event = new SimpleEvent();            eventDate.clear();                        eventDate.set(2011, i, i, i, 0);            event.getHeaders().put("timestamp", String.valueOf(eventDate.getTimeInMillis()));            event.getHeaders().put("hostname", "Host" + i);            String body = "Test." + i + "." + j;            event.setBody(body.getBytes());            bodies.add(body);                        if ((totalEvents % 30) == 1) {                event.getHeaders().put("fault-once", "");            }            channel.put(event);            totalEvents++;        }        txn.commit();        txn.close();        LOG.info("Process events: " + sink.process());    }    LOG.info("Process events to end of transaction max: " + sink.process());    LOG.info("Process events to injected fault: " + sink.process());    LOG.info("Process events remaining events: " + sink.process());    sink.stop();    verifyOutputSequenceFiles(fs, conf, dirPath.toUri().getPath(), fileName, bodies);    SinkCounter sc = (SinkCounter) Whitebox.getInternalState(sink, "sinkCounter");    Assert.assertEquals(1, sc.getEventWriteFail());}
ed7f55f474e57aebc0eb78746fcd68a2dccb189eef535d3a5574244035d8117d
getAllFiles
private List<String> getAllFiles(String input)
{    List<String> output = Lists.newArrayList();    File dir = new File(input);    if (dir.isFile()) {        output.add(dir.getAbsolutePath());    } else if (dir.isDirectory()) {        for (String file : dir.list()) {            File subDir = new File(dir, file);            output.addAll(getAllFiles(subDir.getAbsolutePath()));        }    }    return output;}
4ca09f53f6d1797f808e2e1b45d0f45762fada14fe609f3284636aee277406c8
verifyOutputSequenceFiles
private void verifyOutputSequenceFiles(FileSystem fs, Configuration conf, String dir, String prefix, List<String> bodies) throws IOException
{    int found = 0;    int expected = bodies.size();    for (String outputFile : getAllFiles(dir)) {        String name = (new File(outputFile)).getName();        if (name.startsWith(prefix)) {            SequenceFile.Reader reader = new SequenceFile.Reader(fs, new Path(outputFile), conf);            LongWritable key = new LongWritable();            BytesWritable value = new BytesWritable();            while (reader.next(key, value)) {                String body = new String(value.getBytes(), 0, value.getLength());                if (bodies.contains(body)) {                    LOG.debug("Found event body: {}", body);                    bodies.remove(body);                    found++;                }            }            reader.close();        }    }    if (!bodies.isEmpty()) {        for (String body : bodies) {            LOG.error("Never found event body: {}", body);        }    }    Assert.assertTrue("Found = " + found + ", Expected = " + expected + ", Left = " + bodies.size() + " " + bodies, bodies.size() == 0);}
2ff73d30c0c60bdf2b581906b5ce36d15cc264732f053d70d3fd292d2872b8f8
verifyOutputTextFiles
private void verifyOutputTextFiles(FileSystem fs, Configuration conf, String dir, String prefix, List<String> bodies) throws IOException
{    int found = 0;    int expected = bodies.size();    for (String outputFile : getAllFiles(dir)) {        String name = (new File(outputFile)).getName();        if (name.startsWith(prefix)) {            FSDataInputStream input = fs.open(new Path(outputFile));            BufferedReader reader = new BufferedReader(new InputStreamReader(input));            String body = null;            while ((body = reader.readLine()) != null) {                bodies.remove(body);                found++;            }            reader.close();        }    }    Assert.assertTrue("Found = " + found + ", Expected = " + expected + ", Left = " + bodies.size() + " " + bodies, bodies.size() == 0);}
dca6820a4dc86607353131c487296a5ec0b7684e6e3bf90264eafc261015a09c
verifyOutputAvroFiles
private void verifyOutputAvroFiles(FileSystem fs, Configuration conf, String dir, String prefix, List<String> bodies) throws IOException
{    int found = 0;    int expected = bodies.size();    for (String outputFile : getAllFiles(dir)) {        String name = (new File(outputFile)).getName();        if (name.startsWith(prefix)) {            FSDataInputStream input = fs.open(new Path(outputFile));            DatumReader<GenericRecord> reader = new GenericDatumReader<GenericRecord>();            DataFileStream<GenericRecord> avroStream = new DataFileStream<GenericRecord>(input, reader);            GenericRecord record = new GenericData.Record(avroStream.getSchema());            while (avroStream.hasNext()) {                avroStream.next(record);                ByteBuffer body = (ByteBuffer) record.get("body");                CharsetDecoder decoder = Charsets.UTF_8.newDecoder();                String bodyStr = decoder.decode(body).toString();                LOG.debug("Removing event: {}", bodyStr);                bodies.remove(bodyStr);                found++;            }            avroStream.close();            input.close();        }    }    Assert.assertTrue("Found = " + found + ", Expected = " + expected + ", Left = " + bodies.size() + " " + bodies, bodies.size() == 0);}
46e0ab5918f612764989ccdb2c9fbb0cb07477af03b63734998f80d87411bfd1
testCloseReopen
public void testCloseReopen() throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{    LOG.debug("Starting...");    final int numBatches = 4;    final String fileName = "FlumeData";    final long rollCount = 5;    final long batchSize = 2;    String newPath = testPath + "/singleBucket";    int i = 1, j = 1;    HDFSTestWriterFactory badWriterFactory = new HDFSTestWriterFactory();    sink = new HDFSEventSink(badWriterFactory);        Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);    Path dirPath = new Path(newPath);    fs.delete(dirPath, true);    fs.mkdirs(dirPath);    Context context = new Context();    context.put("hdfs.path", newPath);    context.put("hdfs.filePrefix", fileName);    context.put("hdfs.rollCount", String.valueOf(rollCount));    context.put("hdfs.batchSize", String.valueOf(batchSize));    context.put("hdfs.fileType", HDFSTestWriterFactory.TestSequenceFileType);    Configurables.configure(sink, context);    MemoryChannel channel = new MemoryChannel();    Configurables.configure(channel, new Context());    sink.setChannel(channel);    sink.start();    Calendar eventDate = Calendar.getInstance();    List<String> bodies = Lists.newArrayList();        for (i = 1; i < numBatches; i++) {        channel.getTransaction().begin();        try {            for (j = 1; j <= batchSize; j++) {                Event event = new SimpleEvent();                eventDate.clear();                                eventDate.set(2011, i, i, i, 0);                event.getHeaders().put("timestamp", String.valueOf(eventDate.getTimeInMillis()));                event.getHeaders().put("hostname", "Host" + i);                String body = "Test." + i + "." + j;                event.setBody(body.getBytes());                bodies.add(body);                                event.getHeaders().put("fault-until-reopen", "");                channel.put(event);            }            channel.getTransaction().commit();        } finally {            channel.getTransaction().close();        }        LOG.info("execute sink to process the events: " + sink.process());    }    LOG.info("clear any events pending due to errors: " + sink.process());    sink.stop();    verifyOutputSequenceFiles(fs, conf, dirPath.toUri().getPath(), fileName, bodies);    SinkCounter sc = (SinkCounter) Whitebox.getInternalState(sink, "sinkCounter");    Assert.assertEquals(1, sc.getEventWriteFail());}
42a39a26b4b8e4bc2777404ad01d831d270b55f29fee4b68fff68fcae4045edb
testCloseReopenOnRollTime
public void testCloseReopenOnRollTime() throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{    LOG.debug("Starting...");    final int numBatches = 4;    final String fileName = "FlumeData";    final long batchSize = 2;    String newPath = testPath + "/singleBucket";    int i = 1, j = 1;    HDFSTestWriterFactory badWriterFactory = new HDFSTestWriterFactory();    sink = new HDFSEventSink(badWriterFactory);        Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);    Path dirPath = new Path(newPath);    fs.delete(dirPath, true);    fs.mkdirs(dirPath);    Context context = new Context();    context.put("hdfs.path", newPath);    context.put("hdfs.filePrefix", fileName);    context.put("hdfs.rollCount", String.valueOf(0));    context.put("hdfs.rollSize", String.valueOf(0));    context.put("hdfs.rollInterval", String.valueOf(2));    context.put("hdfs.batchSize", String.valueOf(batchSize));    context.put("hdfs.fileType", HDFSTestWriterFactory.TestSequenceFileType);    Configurables.configure(sink, context);    MemoryChannel channel = new MemoryChannel();    Configurables.configure(channel, new Context());    sink.setChannel(channel);    sink.start();    Calendar eventDate = Calendar.getInstance();    List<String> bodies = Lists.newArrayList();        for (i = 1; i < numBatches; i++) {        channel.getTransaction().begin();        try {            for (j = 1; j <= batchSize; j++) {                Event event = new SimpleEvent();                eventDate.clear();                                eventDate.set(2011, i, i, i, 0);                event.getHeaders().put("timestamp", String.valueOf(eventDate.getTimeInMillis()));                event.getHeaders().put("hostname", "Host" + i);                String body = "Test." + i + "." + j;                event.setBody(body.getBytes());                bodies.add(body);                                event.getHeaders().put("count-check", "");                channel.put(event);            }            channel.getTransaction().commit();        } finally {            channel.getTransaction().close();        }        LOG.info("execute sink to process the events: " + sink.process());                if (i == 1) {            Thread.sleep(2001);        }    }    LOG.info("clear any events pending due to errors: " + sink.process());    sink.stop();    Assert.assertTrue(badWriterFactory.openCount.get() >= 2);    LOG.info("Total number of bucket writers opened: {}", badWriterFactory.openCount.get());    verifyOutputSequenceFiles(fs, conf, dirPath.toUri().getPath(), fileName, bodies);}
ca17aea4ee8f7ed8eb9f0aaa54d78f43bb1d1d060a5c3783bb90c22e53fbb7a7
testCloseRemovesFromSFWriters
public void testCloseRemovesFromSFWriters() throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{    LOG.debug("Starting...");    final String fileName = "FlumeData";    final long batchSize = 2;    String newPath = testPath + "/singleBucket";    int i = 1, j = 1;    HDFSTestWriterFactory badWriterFactory = new HDFSTestWriterFactory();    sink = new HDFSEventSink(badWriterFactory);        Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);    Path dirPath = new Path(newPath);    fs.delete(dirPath, true);    fs.mkdirs(dirPath);    Context context = new Context();    context.put("hdfs.path", newPath);    context.put("hdfs.filePrefix", fileName);    context.put("hdfs.rollCount", String.valueOf(0));    context.put("hdfs.rollSize", String.valueOf(0));    context.put("hdfs.rollInterval", String.valueOf(1));    context.put("hdfs.batchSize", String.valueOf(batchSize));    context.put("hdfs.fileType", HDFSTestWriterFactory.TestSequenceFileType);    String expectedLookupPath = newPath + "/FlumeData";    Configurables.configure(sink, context);    MemoryChannel channel = new MemoryChannel();    Configurables.configure(channel, new Context());    sink.setChannel(channel);    sink.start();    Calendar eventDate = Calendar.getInstance();    List<String> bodies = Lists.newArrayList();        channel.getTransaction().begin();    try {        for (j = 1; j <= 2 * batchSize; j++) {            Event event = new SimpleEvent();            eventDate.clear();                        eventDate.set(2011, i, i, i, 0);            event.getHeaders().put("timestamp", String.valueOf(eventDate.getTimeInMillis()));            event.getHeaders().put("hostname", "Host" + i);            String body = "Test." + i + "." + j;            event.setBody(body.getBytes());            bodies.add(body);                        event.getHeaders().put("count-check", "");            channel.put(event);        }        channel.getTransaction().commit();    } finally {        channel.getTransaction().close();    }    LOG.info("execute sink to process the events: " + sink.process());    Assert.assertTrue(sink.getSfWriters().containsKey(expectedLookupPath));        Thread.sleep(2001);    Assert.assertFalse(sink.getSfWriters().containsKey(expectedLookupPath));    LOG.info("execute sink to process the events: " + sink.process());            Assert.assertTrue(sink.getSfWriters().containsKey(expectedLookupPath));    sink.stop();    LOG.info("Total number of bucket writers opened: {}", badWriterFactory.openCount.get());    verifyOutputSequenceFiles(fs, conf, dirPath.toUri().getPath(), fileName, bodies);}
ca04a6261fc09bd6d172632e60bb2646bbe63ad8533ced16720086660d5c5f61
testSlowAppendFailure
public void testSlowAppendFailure() throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{    LOG.debug("Starting...");    final String fileName = "FlumeData";    final long rollCount = 5;    final long batchSize = 2;    final int numBatches = 2;    String newPath = testPath + "/singleBucket";    int i = 1, j = 1;        Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);    Path dirPath = new Path(newPath);    fs.delete(dirPath, true);    fs.mkdirs(dirPath);        HDFSTestWriterFactory badWriterFactory = new HDFSTestWriterFactory();    sink = new HDFSEventSink(badWriterFactory);    Context context = new Context();    context.put("hdfs.path", newPath);    context.put("hdfs.filePrefix", fileName);    context.put("hdfs.rollCount", String.valueOf(rollCount));    context.put("hdfs.batchSize", String.valueOf(batchSize));    context.put("hdfs.fileType", HDFSTestWriterFactory.TestSequenceFileType);    context.put("hdfs.callTimeout", Long.toString(1000));    Configurables.configure(sink, context);    Channel channel = new MemoryChannel();    Configurables.configure(channel, context);    sink.setChannel(channel);    sink.start();    Calendar eventDate = Calendar.getInstance();        for (i = 0; i < numBatches; i++) {        Transaction txn = channel.getTransaction();        txn.begin();        for (j = 1; j <= batchSize; j++) {            Event event = new SimpleEvent();            eventDate.clear();                        eventDate.set(2011, i, i, i, 0);            event.getHeaders().put("timestamp", String.valueOf(eventDate.getTimeInMillis()));            event.getHeaders().put("hostname", "Host" + i);            event.getHeaders().put("slow", "1500");            event.setBody(("Test." + i + "." + j).getBytes());            channel.put(event);        }        txn.commit();        txn.close();                Status satus = sink.process();                Assert.assertEquals(satus, Status.BACKOFF);    }    sink.stop();    SinkCounter sc = (SinkCounter) Whitebox.getInternalState(sink, "sinkCounter");    Assert.assertEquals(2, sc.getEventWriteFail());}
388c28523a9e6f2a980252ce28e6c669677f49801e72c458b8438e7774627e1b
slowAppendTestHelper
private void slowAppendTestHelper(long appendTimeout) throws InterruptedException, IOException, LifecycleException, EventDeliveryException, IOException
{    final String fileName = "FlumeData";    final long rollCount = 5;    final long batchSize = 2;    final int numBatches = 2;    String newPath = testPath + "/singleBucket";    int totalEvents = 0;    int i = 1, j = 1;        Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);    Path dirPath = new Path(newPath);    fs.delete(dirPath, true);    fs.mkdirs(dirPath);        HDFSTestWriterFactory badWriterFactory = new HDFSTestWriterFactory();    sink = new HDFSEventSink(badWriterFactory);    Context context = new Context();    context.put("hdfs.path", newPath);    context.put("hdfs.filePrefix", fileName);    context.put("hdfs.rollCount", String.valueOf(rollCount));    context.put("hdfs.batchSize", String.valueOf(batchSize));    context.put("hdfs.fileType", HDFSTestWriterFactory.TestSequenceFileType);    context.put("hdfs.appendTimeout", String.valueOf(appendTimeout));    Configurables.configure(sink, context);    Channel channel = new MemoryChannel();    Configurables.configure(channel, context);    sink.setChannel(channel);    sink.start();    Calendar eventDate = Calendar.getInstance();    List<String> bodies = Lists.newArrayList();        for (i = 0; i < numBatches; i++) {        Transaction txn = channel.getTransaction();        txn.begin();        for (j = 1; j <= batchSize; j++) {            Event event = new SimpleEvent();            eventDate.clear();                        eventDate.set(2011, i, i, i, 0);            event.getHeaders().put("timestamp", String.valueOf(eventDate.getTimeInMillis()));            event.getHeaders().put("hostname", "Host" + i);            event.getHeaders().put("slow", "1500");            String body = "Test." + i + "." + j;            event.setBody(body.getBytes());            bodies.add(body);            channel.put(event);            totalEvents++;        }        txn.commit();        txn.close();                sink.process();    }    sink.stop();        FileStatus[] dirStat = fs.listStatus(dirPath);    Path[] fList = FileUtil.stat2Paths(dirStat);            long expectedFiles = totalEvents / rollCount;    if (totalEvents % rollCount > 0)        expectedFiles++;    Assert.assertEquals("num files wrong, found: " + Lists.newArrayList(fList), expectedFiles, fList.length);    verifyOutputSequenceFiles(fs, conf, dirPath.toUri().getPath(), fileName, bodies);}
306110b01220195c65e8dd307740b2de56c71ac6f0fccb7b4e55c10819aa1d37
testSlowAppendWithLongTimeout
public void testSlowAppendWithLongTimeout() throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{    LOG.debug("Starting...");    slowAppendTestHelper(3000);}
8b79bf9fe69893b347d8b22a2db0b8b88de623fc6f4255a2a56b0494b0ec91f5
testSlowAppendWithoutTimeout
public void testSlowAppendWithoutTimeout() throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{    LOG.debug("Starting...");    slowAppendTestHelper(0);}
d0d126270e4e821a5d60ac47c8e04a60ae918a6bc8eadcb499d9e64a4d3a448a
testCloseOnIdle
public void testCloseOnIdle() throws IOException, EventDeliveryException, InterruptedException
{    String hdfsPath = testPath + "/idleClose";    Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);    Path dirPath = new Path(hdfsPath);    fs.delete(dirPath, true);    fs.mkdirs(dirPath);    Context context = new Context();    context.put("hdfs.path", hdfsPath);    /*     * All three rolling methods are disabled so the only     * way a file can roll is through the idle timeout.     */    context.put("hdfs.rollCount", "0");    context.put("hdfs.rollSize", "0");    context.put("hdfs.rollInterval", "0");    context.put("hdfs.batchSize", "2");    context.put("hdfs.idleTimeout", "1");    Configurables.configure(sink, context);    Channel channel = new MemoryChannel();    Configurables.configure(channel, context);    sink.setChannel(channel);    sink.start();    Transaction txn = channel.getTransaction();    txn.begin();    for (int i = 0; i < 10; i++) {        Event event = new SimpleEvent();        event.setBody(("test event " + i).getBytes());        channel.put(event);    }    txn.commit();    txn.close();    sink.process();    sink.process();    Thread.sleep(1001);                        sink.process();    sink.process();        Thread.sleep(500);    sink.process();    sink.process();    sink.stop();    FileStatus[] dirStat = fs.listStatus(dirPath);    Path[] fList = FileUtil.stat2Paths(dirStat);    Assert.assertEquals("Incorrect content of the directory " + StringUtils.join(fList, ","), 2, fList.length);    Assert.assertTrue(!fList[0].getName().endsWith(".tmp") && !fList[1].getName().endsWith(".tmp"));    fs.close();}
1fe7a97c78a5ea0a1d9366ab562e66dbb7e1df7bc7cce66c837f451a4df3965e
testBlockCompressSequenceFileWriterSync
public void testBlockCompressSequenceFileWriterSync() throws IOException, EventDeliveryException
{    String hdfsPath = testPath + "/sequenceFileWriterSync";    FileSystem fs = FileSystem.get(new Configuration());        fs.setVerifyChecksum(false);    fs.setWriteChecksum(false);        String[] codecs = { "BZip2Codec", "DeflateCodec" };    for (String codec : codecs) {        sequenceFileWriteAndVerifyEvents(fs, hdfsPath, codec, Collections.singletonList("single-event"));        sequenceFileWriteAndVerifyEvents(fs, hdfsPath, codec, Arrays.asList("multiple-events-1", "multiple-events-2", "multiple-events-3", "multiple-events-4", "multiple-events-5"));    }    fs.close();}
54bd74d47e95336c5fc6473dcb877c02c89b765ab3a2168c741fdacd888920c9
sequenceFileWriteAndVerifyEvents
private void sequenceFileWriteAndVerifyEvents(FileSystem fs, String hdfsPath, String codec, Collection<String> eventBodies) throws IOException, EventDeliveryException
{    Path dirPath = new Path(hdfsPath);    fs.delete(dirPath, true);    fs.mkdirs(dirPath);    Context context = new Context();    context.put("hdfs.path", hdfsPath);        context.put("hdfs.rollCount", String.valueOf(eventBodies.size() + 1));    context.put("hdfs.rollSize", "0");    context.put("hdfs.rollInterval", "0");    context.put("hdfs.batchSize", "1");    context.put("hdfs.fileType", "SequenceFile");    context.put("hdfs.codeC", codec);    context.put("hdfs.writeFormat", "Writable");    Configurables.configure(sink, context);    Channel channel = new MemoryChannel();    Configurables.configure(channel, context);    sink.setChannel(channel);    sink.start();    for (String eventBody : eventBodies) {        Transaction txn = channel.getTransaction();        txn.begin();        Event event = new SimpleEvent();        event.setBody(eventBody.getBytes());        channel.put(event);        txn.commit();        txn.close();        sink.process();    }            FileStatus[] dirStat = fs.listStatus(dirPath);    Path[] paths = FileUtil.stat2Paths(dirStat);    Assert.assertEquals(1, paths.length);    SequenceFile.Reader reader = new SequenceFile.Reader(fs.getConf(), SequenceFile.Reader.stream(fs.open(paths[0])));    LongWritable key = new LongWritable();    BytesWritable value = new BytesWritable();    for (String eventBody : eventBodies) {        Assert.assertTrue(reader.next(key, value));        Assert.assertArrayEquals(eventBody.getBytes(), value.copyBytes());    }    Assert.assertFalse(reader.next(key, value));}
37489448d0b5a6c5eb7cc1e03c75fb5ee285a048d8d513aa4ac7ee6da1456c51
getContextForRetryTests
private Context getContextForRetryTests()
{    Context context = new Context();    context.put("hdfs.path", testPath + "/%{retryHeader}");    context.put("hdfs.filePrefix", "test");    context.put("hdfs.batchSize", String.valueOf(100));    context.put("hdfs.fileType", "DataStream");    context.put("hdfs.serializer", "text");    context.put("hdfs.closeTries", "3");    context.put("hdfs.rollCount", "1");    context.put("hdfs.retryInterval", "1");    return context;}
7ca39d09cf0302487fb8825c9b6e29ff3d6f8eb6494218867c4861332d52b923
testBadConfigurationForRetryIntervalZero
public void testBadConfigurationForRetryIntervalZero() throws Exception
{    Context context = getContextForRetryTests();    context.put("hdfs.retryInterval", "0");    Configurables.configure(sink, context);    Assert.assertEquals(1, sink.getTryCount());}
8b1293271540fed3f0553c38745277e83ebea217ad9e1b4ba56cbc7f241f51b1
testBadConfigurationForRetryIntervalNegative
public void testBadConfigurationForRetryIntervalNegative() throws Exception
{    Context context = getContextForRetryTests();    context.put("hdfs.retryInterval", "-1");    Configurables.configure(sink, context);    Assert.assertEquals(1, sink.getTryCount());}
fb743460a1a05f2c4c6ec6787cd8af644ebdf79ac69d23c59e10becc50f8a77d
testBadConfigurationForRetryCountZero
public void testBadConfigurationForRetryCountZero() throws Exception
{    Context context = getContextForRetryTests();    context.put("hdfs.closeTries", "0");    Configurables.configure(sink, context);    Assert.assertEquals(Integer.MAX_VALUE, sink.getTryCount());}
f1cce476ffbe84698bb402a3e7f09fb538502fadb16b4ca5b1fbb7e3d46fdbf4
testBadConfigurationForRetryCountNegative
public void testBadConfigurationForRetryCountNegative() throws Exception
{    Context context = getContextForRetryTests();    context.put("hdfs.closeTries", "-4");    Configurables.configure(sink, context);    Assert.assertEquals(Integer.MAX_VALUE, sink.getTryCount());}
d4b423e0314e0c0aa2c531f79b62291e9bc4fbb7b576a0717152a014c3900e6e
testRetryRename
public void testRetryRename() throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{    testRetryRename(true);    testRetryRename(false);}
eb17705e118fb69097b3cd2247f09d761d2cfd41426c97f5193e8cde002617bc
testRetryRename
private void testRetryRename(boolean closeSucceed) throws InterruptedException, LifecycleException, EventDeliveryException, IOException
{    LOG.debug("Starting...");    String newPath = testPath + "/retryBucket";        Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);    Path dirPath = new Path(newPath);    fs.delete(dirPath, true);    fs.mkdirs(dirPath);    MockFileSystem mockFs = new MockFileSystem(fs, 6, closeSucceed);    Context context = getContextForRetryTests();    Configurables.configure(sink, context);    Channel channel = new MemoryChannel();    Configurables.configure(channel, context);    sink.setChannel(channel);    sink.setMockFs(mockFs);    HDFSWriter hdfsWriter = new MockDataStream(mockFs);    hdfsWriter.configure(context);    sink.setMockWriter(hdfsWriter);    sink.start();        for (int i = 0; i < 2; i++) {        Transaction txn = channel.getTransaction();        txn.begin();        Map<String, String> hdr = Maps.newHashMap();        hdr.put("retryHeader", "v1");        channel.put(EventBuilder.withBody("random".getBytes(), hdr));        txn.commit();        txn.close();                sink.process();    }        for (int i = 0; i < 2; i++) {        Transaction txn = channel.getTransaction();        txn.begin();        Map<String, String> hdr = Maps.newHashMap();        hdr.put("retryHeader", "v2");        channel.put(EventBuilder.withBody("random".getBytes(), hdr));        txn.commit();        txn.close();                sink.process();    }        TimeUnit.SECONDS.sleep(5);    Collection<BucketWriter> writers = sink.getSfWriters().values();    int totalRenameAttempts = 0;    for (BucketWriter writer : writers) {        LOG.info("Rename tries = " + writer.renameTries.get());        totalRenameAttempts += writer.renameTries.get();    }            sink.stop();    Assert.assertEquals(6, totalRenameAttempts);}
94459be92a7ce31119c3902aa0195207c5a088ac3b07e8dc154e993d7dbff430
testFlushedIfAppendFailedWithBucketClosedException
public void testFlushedIfAppendFailedWithBucketClosedException() throws Exception
{    final Set<BucketWriter> bucketWriters = new HashSet<>();    sink = new HDFSEventSink() {        @Override        BucketWriter initializeBucketWriter(String realPath, String realName, String lookupPath, HDFSWriter hdfsWriter, WriterCallback closeCallback) {            BucketWriter bw = Mockito.spy(super.initializeBucketWriter(realPath, realName, lookupPath, hdfsWriter, closeCallback));            try {                                                Mockito.doCallRealMethod().doThrow(BucketClosedException.class).when(bw).append(Mockito.any(Event.class));            } catch (IOException | InterruptedException e) {                Assert.fail("This shouldn't happen, as append() is called during mocking.");            }            bucketWriters.add(bw);            return bw;        }    };    Context context = new Context(ImmutableMap.of("hdfs.path", testPath));    Configurables.configure(sink, context);    Channel channel = Mockito.spy(new MemoryChannel());    Configurables.configure(channel, new Context());    final Iterator<Event> events = Iterators.forArray(EventBuilder.withBody("test1".getBytes()), EventBuilder.withBody("test2".getBytes()));    Mockito.doAnswer(new Answer() {        @Override        public Object answer(InvocationOnMock invocation) throws Throwable {            return events.hasNext() ? events.next() : null;        }    }).when(channel).take();    sink.setChannel(channel);    sink.start();    sink.process();        Mockito.verify(channel, Mockito.times(3)).take();    FileSystem fs = FileSystem.get(new Configuration());    int fileCount = 0;    for (RemoteIterator<LocatedFileStatus> i = fs.listFiles(new Path(testPath), false); i.hasNext(); i.next()) {        fileCount++;    }    Assert.assertEquals(2, fileCount);    Assert.assertEquals(2, bucketWriters.size());        for (BucketWriter bw : bucketWriters) {        Mockito.verify(bw, Mockito.times(1)).flush();    }    sink.stop();}
f96da99aa3febf6d6b8e5cbfd6282b7f6dab67dbf09b0f7b43ce38e8f066aa91
initializeBucketWriter
 BucketWriter initializeBucketWriter(String realPath, String realName, String lookupPath, HDFSWriter hdfsWriter, WriterCallback closeCallback)
{    BucketWriter bw = Mockito.spy(super.initializeBucketWriter(realPath, realName, lookupPath, hdfsWriter, closeCallback));    try {                        Mockito.doCallRealMethod().doThrow(BucketClosedException.class).when(bw).append(Mockito.any(Event.class));    } catch (IOException | InterruptedException e) {        Assert.fail("This shouldn't happen, as append() is called during mocking.");    }    bucketWriters.add(bw);    return bw;}
ca2a9e4c867042d3d767960a38b0319d682d7859dce060976f7d87729e5d9387
answer
public Object answer(InvocationOnMock invocation) throws Throwable
{    return events.hasNext() ? events.next() : null;}
d3964a0a7bb0c6fee9f4243399ab05805ddd0eaa22706ae783f2f70c2cbb0a6d
testChannelException
public void testChannelException()
{    LOG.debug("Starting...");    Context context = new Context();    context.put("hdfs.path", testPath);    context.put("keep-alive", "0");    Configurables.configure(sink, context);    Channel channel = Mockito.mock(Channel.class);    Mockito.when(channel.take()).thenThrow(new ChannelException("dummy"));    Mockito.when(channel.getTransaction()).thenReturn(Mockito.mock(BasicTransactionSemantics.class));    sink.setChannel(channel);    sink.start();    try {        sink.process();    } catch (EventDeliveryException e) {        }    sink.stop();    SinkCounter sc = (SinkCounter) Whitebox.getInternalState(sink, "sinkCounter");    Assert.assertEquals(1, sc.getChannelReadFail());}
a7fef9e82e5dbd6101b6871afccea5ae42eec6e50cda4fbacfdef17ea8341d0c
testEmptyInUseSuffix
public void testEmptyInUseSuffix()
{    String inUseSuffixConf = "aaaa";    Context context = new Context();    context.put("hdfs.path", testPath);    context.put("hdfs.inUseSuffix", inUseSuffixConf);        Configurables.configure(sink, context);    String inUseSuffix = (String) Whitebox.getInternalState(sink, "inUseSuffix");    Assert.assertEquals(inUseSuffixConf, inUseSuffix);    context.put("hdfs.emptyInUseSuffix", "true");    Configurables.configure(sink, context);    inUseSuffix = (String) Whitebox.getInternalState(sink, "inUseSuffix");    Assert.assertEquals("", inUseSuffix);    context.put("hdfs.emptyInUseSuffix", "false");    Configurables.configure(sink, context);    inUseSuffix = (String) Whitebox.getInternalState(sink, "inUseSuffix");    Assert.assertEquals(inUseSuffixConf, inUseSuffix);}
e561e0fb33b6ecad74cfac95aff4a2ea7fe4834945d1691bd93c1963888a3ff8
main
public static void main(String... args)
{    HDFSEventSink sink = new HDFSEventSink();    sink.setName("HDFSEventSink");    Context context = new Context(ImmutableMap.of("hdfs.path", "file:///tmp/flume-test/bucket-%t", "hdfs.filePrefix", "flumetest", "hdfs.rollInterval", "1", "hdfs.maxOpenFiles", "1", "hdfs.useLocalTimeStamp", "true"));    Configurables.configure(sink, context);    Channel channel = new MemoryChannel();    Configurables.configure(channel, new Context());    final SequenceGeneratorSource source = new SequenceGeneratorSource();    Configurables.configure(source, new Context());    ChannelSelector rcs = new ReplicatingChannelSelector();    rcs.setChannels(Collections.singletonList(channel));    source.setChannelProcessor(new ChannelProcessor(rcs));    sink.setChannel(channel);    channel.start();    source.start();    SinkProcessor sinkProcessor = new DefaultSinkProcessor();    sinkProcessor.setSinks(Collections.singletonList(sink));    SinkRunner sinkRunner = new SinkRunner();    sinkRunner.setSink(sinkProcessor);    sinkRunner.start();    ScheduledExecutorService executor = Executors.newScheduledThreadPool(3);    executor.execute(new Runnable() {        @Override        public void run() {            int i = 0;            while (true) {                try {                    source.process();                    System.out.println(i++);                    if (i == 250) {                        System.out.println("No deadlock found after 250 iterations, exiting");                        System.exit(0);                    }                    Thread.sleep((long) (Math.random() * 100 + 950));                } catch (Exception e) {                                }            }        }    });    executor.scheduleAtFixedRate(new Runnable() {        @Override        public void run() {            ThreadMXBean bean = ManagementFactory.getThreadMXBean();            long[] threadIds = bean.findDeadlockedThreads();            if (threadIds != null) {                System.out.println("Deadlocked threads found");                printThreadStackTraces(threadIds);                System.exit(1);            }        }    }, 0, 1, TimeUnit.SECONDS);}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    int i = 0;    while (true) {        try {            source.process();            System.out.println(i++);            if (i == 250) {                System.out.println("No deadlock found after 250 iterations, exiting");                System.exit(0);            }            Thread.sleep((long) (Math.random() * 100 + 950));        } catch (Exception e) {                }    }}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    ThreadMXBean bean = ManagementFactory.getThreadMXBean();    long[] threadIds = bean.findDeadlockedThreads();    if (threadIds != null) {        System.out.println("Deadlocked threads found");        printThreadStackTraces(threadIds);        System.exit(1);    }}
ae4d7617a60af64029f1f4ab015a75aa2200eb313573f2ac72b31bcca173609b
printThreadStackTraces
private static void printThreadStackTraces(long[] threadIds)
{    Set<Long> threadIdSet = new HashSet<>(Longs.asList(threadIds));    for (Thread th : Thread.getAllStackTraces().keySet()) {        if (threadIdSet.contains(th.getId())) {            System.out.println("Thread: " + th);            for (StackTraceElement e : th.getStackTrace()) {                System.out.println("\t" + e);            }            System.out.println("-----------------------------");        }    }}
8decaa5a339a927e319c43ceb49b8b3e17c8d0f8f6a8be2168b396fce8cb01ce
setupClass
public static void setupClass() throws IOException
{        File dfsDir = new File(DFS_DIR);    if (!dfsDir.isDirectory()) {        dfsDir.mkdirs();    }        oldTestBuildDataProp = System.getProperty(TEST_BUILD_DATA_KEY);    System.setProperty(TEST_BUILD_DATA_KEY, DFS_DIR);}
cf16b52f4504e8e7a2710bbd9f5e11aecec4bf50469229535dc49ac47aec7072
getNameNodeURL
private static String getNameNodeURL(MiniDFSCluster cluster)
{    int nnPort = cluster.getNameNode().getNameNodeAddress().getPort();    return "hdfs://localhost:" + nnPort;}
67cf52287108b69635b68b8788c9028493a04957389c0f7ac088298b23671306
simpleHDFSTest
public void simpleHDFSTest() throws EventDeliveryException, IOException
{    cluster = new MiniDFSCluster(new Configuration(), 1, true, null);    cluster.waitActive();    String outputDir = "/flume/simpleHDFSTest";    Path outputDirPath = new Path(outputDir);    logger.info("Running test with output dir: {}", outputDir);    FileSystem fs = cluster.getFileSystem();        if (fs.exists(outputDirPath)) {        fs.delete(outputDirPath, true);    }    String nnURL = getNameNodeURL(cluster);    logger.info("Namenode address: {}", nnURL);    Context chanCtx = new Context();    MemoryChannel channel = new MemoryChannel();    channel.setName("simpleHDFSTest-mem-chan");    channel.configure(chanCtx);    channel.start();    Context sinkCtx = new Context();    sinkCtx.put("hdfs.path", nnURL + outputDir);    sinkCtx.put("hdfs.fileType", HDFSWriterFactory.DataStreamType);    sinkCtx.put("hdfs.batchSize", Integer.toString(1));    HDFSEventSink sink = new HDFSEventSink();    sink.setName("simpleHDFSTest-hdfs-sink");    sink.configure(sinkCtx);    sink.setChannel(channel);    sink.start();        String EVENT_BODY = "yarg!";    channel.getTransaction().begin();    try {        channel.put(EventBuilder.withBody(EVENT_BODY, Charsets.UTF_8));        channel.getTransaction().commit();    } finally {        channel.getTransaction().close();    }        sink.process();        sink.stop();    channel.stop();        FileStatus[] statuses = fs.listStatus(outputDirPath);    Assert.assertNotNull("No files found written to HDFS", statuses);    Assert.assertEquals("Only one file expected", 1, statuses.length);    for (FileStatus status : statuses) {        Path filePath = status.getPath();        logger.info("Found file on DFS: {}", filePath);        FSDataInputStream stream = fs.open(filePath);        BufferedReader reader = new BufferedReader(new InputStreamReader(stream));        String line = reader.readLine();        logger.info("First line in file {}: {}", filePath, line);        Assert.assertEquals(EVENT_BODY, line);    }    if (!KEEP_DATA) {        fs.delete(outputDirPath, true);    }    cluster.shutdown();    cluster = null;}
eaa21ea64c687566bb08fe7b537d5ee2cf483f689665de9aac09a75be6a0d13a
simpleHDFSGZipCompressedTest
public void simpleHDFSGZipCompressedTest() throws EventDeliveryException, IOException
{    cluster = new MiniDFSCluster(new Configuration(), 1, true, null);    cluster.waitActive();    String outputDir = "/flume/simpleHDFSGZipCompressedTest";    Path outputDirPath = new Path(outputDir);    logger.info("Running test with output dir: {}", outputDir);    FileSystem fs = cluster.getFileSystem();        if (fs.exists(outputDirPath)) {        fs.delete(outputDirPath, true);    }    String nnURL = getNameNodeURL(cluster);    logger.info("Namenode address: {}", nnURL);    Context chanCtx = new Context();    MemoryChannel channel = new MemoryChannel();    channel.setName("simpleHDFSTest-mem-chan");    channel.configure(chanCtx);    channel.start();    Context sinkCtx = new Context();    sinkCtx.put("hdfs.path", nnURL + outputDir);    sinkCtx.put("hdfs.fileType", HDFSWriterFactory.CompStreamType);    sinkCtx.put("hdfs.batchSize", Integer.toString(1));    sinkCtx.put("hdfs.codeC", "gzip");    HDFSEventSink sink = new HDFSEventSink();    sink.setName("simpleHDFSTest-hdfs-sink");    sink.configure(sinkCtx);    sink.setChannel(channel);    sink.start();        String EVENT_BODY_1 = "yarg1";    String EVENT_BODY_2 = "yarg2";    channel.getTransaction().begin();    try {        channel.put(EventBuilder.withBody(EVENT_BODY_1, Charsets.UTF_8));        channel.put(EventBuilder.withBody(EVENT_BODY_2, Charsets.UTF_8));        channel.getTransaction().commit();    } finally {        channel.getTransaction().close();    }        sink.process();        sink.stop();    channel.stop();        FileStatus[] statuses = fs.listStatus(outputDirPath);    Assert.assertNotNull("No files found written to HDFS", statuses);    Assert.assertEquals("Only one file expected", 1, statuses.length);    for (FileStatus status : statuses) {        Path filePath = status.getPath();        logger.info("Found file on DFS: {}", filePath);        FSDataInputStream stream = fs.open(filePath);        BufferedReader reader = new BufferedReader(new InputStreamReader(new GZIPInputStream(stream)));        String line = reader.readLine();        logger.info("First line in file {}: {}", filePath, line);        Assert.assertEquals(EVENT_BODY_1, line);                                                        }    if (!KEEP_DATA) {        fs.delete(outputDirPath, true);    }    cluster.shutdown();    cluster = null;}
d747b58e96112c821d54557873259918364a3da747f60451842a78a1b724ce1c
underReplicationTest
public void underReplicationTest() throws EventDeliveryException, IOException
{    Configuration conf = new Configuration();    conf.set("dfs.replication", String.valueOf(3));    cluster = new MiniDFSCluster(conf, 3, true, null);    cluster.waitActive();    String outputDir = "/flume/underReplicationTest";    Path outputDirPath = new Path(outputDir);    logger.info("Running test with output dir: {}", outputDir);    FileSystem fs = cluster.getFileSystem();        if (fs.exists(outputDirPath)) {        fs.delete(outputDirPath, true);    }    String nnURL = getNameNodeURL(cluster);    logger.info("Namenode address: {}", nnURL);    Context chanCtx = new Context();    MemoryChannel channel = new MemoryChannel();    channel.setName("simpleHDFSTest-mem-chan");    channel.configure(chanCtx);    channel.start();    Context sinkCtx = new Context();    sinkCtx.put("hdfs.path", nnURL + outputDir);    sinkCtx.put("hdfs.fileType", HDFSWriterFactory.DataStreamType);    sinkCtx.put("hdfs.batchSize", Integer.toString(1));        sinkCtx.put("hdfs.retryInterval", "10");    HDFSEventSink sink = new HDFSEventSink();    sink.setName("simpleHDFSTest-hdfs-sink");    sink.configure(sinkCtx);    sink.setChannel(channel);    sink.start();        channel.getTransaction().begin();    try {        channel.put(EventBuilder.withBody("yarg 1", Charsets.UTF_8));        channel.put(EventBuilder.withBody("yarg 2", Charsets.UTF_8));        channel.put(EventBuilder.withBody("yarg 3", Charsets.UTF_8));        channel.put(EventBuilder.withBody("yarg 4", Charsets.UTF_8));        channel.put(EventBuilder.withBody("yarg 5", Charsets.UTF_8));        channel.put(EventBuilder.withBody("yarg 5", Charsets.UTF_8));        channel.getTransaction().commit();    } finally {        channel.getTransaction().close();    }        logger.info("Running process(). Create new file.");        sink.process();    logger.info("Running process(). Same file.");    sink.process();        logger.info("Killing datanode #1...");    cluster.stopDataNode(0);                logger.info("Running process(). Create new file? (racy)");    sink.process();    logger.info("Running process(). Create new file.");    sink.process();    logger.info("Running process(). Create new file.");    sink.process();    logger.info("Running process(). Create new file.");    sink.process();        sink.stop();    channel.stop();        FileStatus[] statuses = fs.listStatus(outputDirPath);    Assert.assertNotNull("No files found written to HDFS", statuses);    for (FileStatus status : statuses) {        Path filePath = status.getPath();        logger.info("Found file on DFS: {}", filePath);        FSDataInputStream stream = fs.open(filePath);        BufferedReader reader = new BufferedReader(new InputStreamReader(stream));        String line = reader.readLine();        logger.info("First line in file {}: {}", filePath, line);        Assert.assertTrue(line.startsWith("yarg"));    }    Assert.assertTrue("4 or 5 files expected, found " + statuses.length, statuses.length == 4 || statuses.length == 5);    System.out.println("There are " + statuses.length + " files.");    if (!KEEP_DATA) {        fs.delete(outputDirPath, true);    }    cluster.shutdown();    cluster = null;}
47dee44a811d02564f3869b446c9826c1f4939bb0787ba9e054287e02c954467
maxUnderReplicationTest
public void maxUnderReplicationTest() throws EventDeliveryException, IOException
{    Configuration conf = new Configuration();    conf.set("dfs.replication", String.valueOf(3));    cluster = new MiniDFSCluster(conf, 3, true, null);    cluster.waitActive();    String outputDir = "/flume/underReplicationTest";    Path outputDirPath = new Path(outputDir);    logger.info("Running test with output dir: {}", outputDir);    FileSystem fs = cluster.getFileSystem();        if (fs.exists(outputDirPath)) {        fs.delete(outputDirPath, true);    }    String nnURL = getNameNodeURL(cluster);    logger.info("Namenode address: {}", nnURL);    Context chanCtx = new Context();    MemoryChannel channel = new MemoryChannel();    channel.setName("simpleHDFSTest-mem-chan");    channel.configure(chanCtx);    channel.start();    Context sinkCtx = new Context();    sinkCtx.put("hdfs.path", nnURL + outputDir);    sinkCtx.put("hdfs.fileType", HDFSWriterFactory.DataStreamType);    sinkCtx.put("hdfs.batchSize", Integer.toString(1));    HDFSEventSink sink = new HDFSEventSink();    sink.setName("simpleHDFSTest-hdfs-sink");    sink.configure(sinkCtx);    sink.setChannel(channel);    sink.start();        channel.getTransaction().begin();    try {        for (int i = 0; i < 50; i++) {            channel.put(EventBuilder.withBody("yarg " + i, Charsets.UTF_8));        }        channel.getTransaction().commit();    } finally {        channel.getTransaction().close();    }        logger.info("Running process(). Create new file.");        sink.process();    logger.info("Running process(). Same file.");    sink.process();        logger.info("Killing datanode #1...");    cluster.stopDataNode(0);                logger.info("Running process(). Create new file? (racy)");    sink.process();    for (int i = 3; i < 50; i++) {        logger.info("Running process().");        sink.process();    }        sink.stop();    channel.stop();        FileStatus[] statuses = fs.listStatus(outputDirPath);    Assert.assertNotNull("No files found written to HDFS", statuses);    for (FileStatus status : statuses) {        Path filePath = status.getPath();        logger.info("Found file on DFS: {}", filePath);        FSDataInputStream stream = fs.open(filePath);        BufferedReader reader = new BufferedReader(new InputStreamReader(stream));        String line = reader.readLine();        logger.info("First line in file {}: {}", filePath, line);        Assert.assertTrue(line.startsWith("yarg"));    }    System.out.println("There are " + statuses.length + " files.");    Assert.assertEquals("31 files expected, found " + statuses.length, 31, statuses.length);    if (!KEEP_DATA) {        fs.delete(outputDirPath, true);    }    cluster.shutdown();    cluster = null;}
b60018fbace85bbcf760347b68b5731fd94846b49e80c039dcc7a36b14f734ed
testLeaseRecoveredIfCloseThrowsIOException
public void testLeaseRecoveredIfCloseThrowsIOException() throws Exception
{    testLeaseRecoveredIfCloseFails(new Callable<Void>() {        @Override        public Void call() throws Exception {            throw new IOException();        }    });}
d12537fee0d4fb03a2b54ca4cc2cb7aeeb6659af2e7d4f187baf67a1d3ca17d2
call
public Void call() throws Exception
{    throw new IOException();}
3b7d282e954ba73ec5cf292fc11fc46d572454d86c71e76710cc093c50275a68
testLeaseRecoveredIfCloseTimesOut
public void testLeaseRecoveredIfCloseTimesOut() throws Exception
{    testLeaseRecoveredIfCloseFails(new Callable<Void>() {        @Override        public Void call() throws Exception {            TimeUnit.SECONDS.sleep(30);            return null;        }    });}
d12537fee0d4fb03a2b54ca4cc2cb7aeeb6659af2e7d4f187baf67a1d3ca17d2
call
public Void call() throws Exception
{    TimeUnit.SECONDS.sleep(30);    return null;}
09e83e27a00d2b7a8074545923f7b83df65c336b9649242c19b242ae32c3112c
testLeaseRecoveredIfCloseFails
private void testLeaseRecoveredIfCloseFails(final Callable<?> doThisInClose) throws Exception
{    cluster = new MiniDFSCluster.Builder(new Configuration()).numDataNodes(1).format(true).build();    cluster.waitActive();    String outputDir = "/flume/leaseRecovery";    Path outputDirPath = new Path(outputDir);    logger.info("Running test with output dir: {}", outputDir);    FileSystem fs = cluster.getFileSystem();        if (fs.exists(outputDirPath)) {        fs.delete(outputDirPath, true);    }    String nnURL = getNameNodeURL(cluster);    Context ctx = new Context();    MemoryChannel channel = new MemoryChannel();    channel.configure(ctx);    channel.start();    ctx.put("hdfs.path", nnURL + outputDir);    ctx.put("hdfs.fileType", HDFSWriterFactory.DataStreamType);    ctx.put("hdfs.batchSize", Integer.toString(1));    ctx.put("hdfs.callTimeout", Integer.toString(1000));        ctx.put("hdfs.retryInterval", "10");    HDFSWriter hdfsWriter = new HDFSDataStream() {        @Override        public void close() throws IOException {            try {                doThisInClose.call();            } catch (Throwable e) {                Throwables.propagateIfPossible(e, IOException.class);                throw new RuntimeException(e);            }        }    };    hdfsWriter.configure(ctx);    HDFSEventSink sink = new HDFSEventSink();    sink.configure(ctx);    sink.setMockFs(fs);    sink.setMockWriter(hdfsWriter);    sink.setChannel(channel);    sink.start();    Transaction txn = channel.getTransaction();    txn.begin();    try {        channel.put(EventBuilder.withBody("test", Charsets.UTF_8));        txn.commit();    } finally {        txn.close();    }    sink.process();    sink.stop();    channel.stop();    FileStatus[] statuses = fs.listStatus(outputDirPath);    Assert.assertEquals(1, statuses.length);    String filePath = statuses[0].getPath().toUri().getPath();        long leaseRenewalTime = NameNodeAdapter.getLeaseRenewalTime(cluster.getNameNode(), filePath);        for (int i = 0; (i < 10) && (leaseRenewalTime != -1L); i++) {        TimeUnit.SECONDS.sleep(1);        leaseRenewalTime = NameNodeAdapter.getLeaseRenewalTime(cluster.getNameNode(), filePath);    }            Assert.assertEquals(-1L, leaseRenewalTime);    if (!KEEP_DATA) {        fs.delete(outputDirPath, true);    }    cluster.shutdown();    cluster = null;}
e0823f55b3a09d41a3e1e792f7e6687db9199c2db9b29e9922d93cbdc6f1284b
close
public void close() throws IOException
{    try {        doThisInClose.call();    } catch (Throwable e) {        Throwables.propagateIfPossible(e, IOException.class);        throw new RuntimeException(e);    }}
569ccb1f159e23e0058d6ff60738ac629a21edff11167ca3dd53c1fed152a482
teardownClass
public static void teardownClass()
{        if (oldTestBuildDataProp != null) {        System.setProperty(TEST_BUILD_DATA_KEY, oldTestBuildDataProp);    }    if (!KEEP_DATA) {        FileUtils.deleteQuietly(new File(DFS_DIR));    }}
b053358c9ce0ae92745e259345850b5dde807f92983338f978a8c829e7ca82dd
getTextFormatter
public void getTextFormatter()
{    SequenceFileSerializer formatter = SequenceFileSerializerFactory.getSerializer("Text", new Context());    assertTrue(formatter != null);    assertTrue(formatter.getClass().getName(), formatter instanceof HDFSTextSerializer);}
57d4d9aa271f8ad1410779ee9b385fc4f8cd97b1339af83adfd5880e74fa3e10
getWritableFormatter
public void getWritableFormatter()
{    SequenceFileSerializer formatter = SequenceFileSerializerFactory.getSerializer("Writable", new Context());    assertTrue(formatter != null);    assertTrue(formatter.getClass().getName(), formatter instanceof HDFSWritableSerializer);}
17bada1b5e40f75e4b4c18189cbcc04a5f1cf2a1f0913bf8acae0d8241411e71
getCustomFormatter
public void getCustomFormatter()
{    SequenceFileSerializer formatter = SequenceFileSerializerFactory.getSerializer("org.apache.flume.sink.hdfs.MyCustomSerializer$Builder", new Context());    assertTrue(formatter != null);    assertTrue(formatter.getClass().getName(), formatter instanceof MyCustomSerializer);}
27681e68ec2a1eb903f955680ebe003ceb3707295c8aad884b692d378c6e37cf
setup
public void setup() throws Exception
{    baseDir = Files.createTempDir();    testFile = new File(baseDir.getAbsoluteFile(), "test");    context = new Context();    event = EventBuilder.withBody("test", Charsets.UTF_8);}
7c529460b940c419ef707bd1846a5575ea1bfc48c129127836c31f0184c1d8fb
teardown
public void teardown() throws Exception
{    FileUtils.deleteQuietly(baseDir);}
8ea1cf8f2665a8d7d2a51b7119cc9fe2755177bce0f73421cb7d7af305e4a205
testTestFile
public void testTestFile() throws Exception
{    String file = testFile.getCanonicalPath();    HDFSDataStream stream = new HDFSDataStream();    context.put("hdfs.useRawLocalFileSystem", "true");    stream.configure(context);    stream.open(file);    stream.append(event);    stream.sync();    Assert.assertTrue(testFile.length() > 0);}
216c2d41d89dabca4736fbceb7af4add13c809f5403507641bca604cb3e150db
testCompressedFile
public void testCompressedFile() throws Exception
{    String file = testFile.getCanonicalPath();    HDFSCompressedDataStream stream = new HDFSCompressedDataStream();    context.put("hdfs.useRawLocalFileSystem", "true");    stream.configure(context);    stream.open(file, new GzipCodec(), CompressionType.RECORD);    stream.append(event);    stream.sync();    Assert.assertTrue(testFile.length() > 0);}
5a1ccad786325189f96ba13204e52ee341ee23f50b43842d67c9d1fe6b325dc2
testSequenceFile
public void testSequenceFile() throws Exception
{    String file = testFile.getCanonicalPath();    HDFSSequenceFile stream = new HDFSSequenceFile();    context.put("hdfs.useRawLocalFileSystem", "true");    stream.configure(context);    stream.open(file);    stream.append(event);    stream.sync();    Assert.assertTrue(testFile.length() > 0);}
4303a14671829d3aa062e88897746e9098947218e65b039ca753e3ff7e277db0
write
public void write(TransactionBatch txnBatch, Event e) throws StreamingException, IOException, InterruptedException
{    txnBatch.write(e.getBody());}
efa293faeaa6350226fa5cc29817530b2b446833932eda515bd43d8def791925
write
public void write(TransactionBatch txnBatch, Collection<byte[]> events) throws StreamingException, IOException, InterruptedException
{    txnBatch.write(events);}
c90c3a2936e5eea761e47eae0e594935187df2011a96235e6a89b0c5a134eef4
createRecordWriter
public RecordWriter createRecordWriter(HiveEndPoint endPoint) throws StreamingException, IOException, ClassNotFoundException
{    if (serdeSeparator == null) {        return new DelimitedInputWriter(fieldToColMapping, delimiter, endPoint);    }    return new DelimitedInputWriter(fieldToColMapping, delimiter, endPoint, null, serdeSeparator);}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    delimiter = parseDelimiterSpec(context.getString(SERIALIZER_DELIMITER, defaultDelimiter));    String fieldNames = context.getString(SERIALIZER_FIELDNAMES);    if (fieldNames == null) {        throw new IllegalArgumentException("serializer.fieldnames is not specified " + "for serializer " + this.getClass().getName());    }    String serdeSeparatorStr = context.getString(SERIALIZER_SERDE_SEPARATOR);    this.serdeSeparator = parseSerdeSeparatorSpec(serdeSeparatorStr);        fieldToColMapping = fieldNames.trim().split(",", -1);}
e11b8f5ba11058eebe3703fd3b0d0074db2e8f1cc92b7946171e2c173ffd97b6
parseDelimiterSpec
private static String parseDelimiterSpec(String delimiter)
{    if (delimiter == null) {        return null;    }    if (delimiter.charAt(0) == '"' && delimiter.charAt(delimiter.length() - 1) == '"') {        return delimiter.substring(1, delimiter.length() - 1);    }    return delimiter;}
46637f1f44a9ca2f2a1f98c666641f507ddd7cd874ba2ca7016ad259c6549d7a
parseSerdeSeparatorSpec
private static Character parseSerdeSeparatorSpec(String separatorStr)
{    if (separatorStr == null) {        return null;    }    if (separatorStr.length() == 1) {        return separatorStr.charAt(0);    }    if (separatorStr.length() == 3 && separatorStr.charAt(2) == '\'' && separatorStr.charAt(separatorStr.length() - 1) == '\'') {        return separatorStr.charAt(1);    }    throw new IllegalArgumentException("serializer.serdeSeparator spec is invalid " + "for " + ALIAS + " serializer ");}
4303a14671829d3aa062e88897746e9098947218e65b039ca753e3ff7e277db0
write
public void write(TransactionBatch txnBatch, Event e) throws StreamingException, IOException, InterruptedException
{    txnBatch.write(e.getBody());}
efa293faeaa6350226fa5cc29817530b2b446833932eda515bd43d8def791925
write
public void write(TransactionBatch txnBatch, Collection<byte[]> events) throws StreamingException, IOException, InterruptedException
{    txnBatch.write(events);}
c90c3a2936e5eea761e47eae0e594935187df2011a96235e6a89b0c5a134eef4
createRecordWriter
public RecordWriter createRecordWriter(HiveEndPoint endPoint) throws StreamingException, IOException, ClassNotFoundException
{    return new StrictJsonWriter(endPoint);}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    return;}
d4964abcb0873d36d1f911ec176f4d898828ccaa49a5b38051fd7991b093161b
getAllWriters
 Map<HiveEndPoint, HiveWriter> getAllWriters()
{    return allWriters;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    metaStoreUri = context.getString(Config.HIVE_METASTORE);    if (metaStoreUri == null) {        throw new IllegalArgumentException(Config.HIVE_METASTORE + " config setting is not " + "specified for sink " + getName());    }    if (metaStoreUri.equalsIgnoreCase("null")) {                metaStoreUri = null;    }        proxyUser = null;    database = context.getString(Config.HIVE_DATABASE);    if (database == null) {        throw new IllegalArgumentException(Config.HIVE_DATABASE + " config setting is not " + "specified for sink " + getName());    }    table = context.getString(Config.HIVE_TABLE);    if (table == null) {        throw new IllegalArgumentException(Config.HIVE_TABLE + " config setting is not " + "specified for sink " + getName());    }    String partitions = context.getString(Config.HIVE_PARTITION);    if (partitions != null) {        partitionVals = Arrays.asList(partitions.split(","));    }    txnsPerBatchAsk = context.getInteger(Config.HIVE_TXNS_PER_BATCH_ASK, DEFAULT_TXNSPERBATCH);    if (txnsPerBatchAsk < 0) {        LOG.warn(getName() + ". hive.txnsPerBatchAsk must be  positive number. Defaulting to " + DEFAULT_TXNSPERBATCH);        txnsPerBatchAsk = DEFAULT_TXNSPERBATCH;    }    batchSize = context.getInteger(Config.BATCH_SIZE, DEFAULT_BATCHSIZE);    if (batchSize < 0) {        LOG.warn(getName() + ". batchSize must be  positive number. Defaulting to " + DEFAULT_BATCHSIZE);        batchSize = DEFAULT_BATCHSIZE;    }    idleTimeout = context.getInteger(Config.IDLE_TIMEOUT, DEFAULT_IDLETIMEOUT);    if (idleTimeout < 0) {        LOG.warn(getName() + ". idleTimeout must be  positive number. Defaulting to " + DEFAULT_IDLETIMEOUT);        idleTimeout = DEFAULT_IDLETIMEOUT;    }    callTimeout = context.getInteger(Config.CALL_TIMEOUT, DEFAULT_CALLTIMEOUT);    if (callTimeout < 0) {        LOG.warn(getName() + ". callTimeout must be  positive number. Defaulting to " + DEFAULT_CALLTIMEOUT);        callTimeout = DEFAULT_CALLTIMEOUT;    }    heartBeatInterval = context.getInteger(Config.HEART_BEAT_INTERVAL, DEFAULT_HEARTBEATINTERVAL);    if (heartBeatInterval < 0) {        LOG.warn(getName() + ". heartBeatInterval must be  positive number. Defaulting to " + DEFAULT_HEARTBEATINTERVAL);        heartBeatInterval = DEFAULT_HEARTBEATINTERVAL;    }    maxOpenConnections = context.getInteger(Config.MAX_OPEN_CONNECTIONS, DEFAULT_MAXOPENCONNECTIONS);    autoCreatePartitions = context.getBoolean("autoCreatePartitions", true);        useLocalTime = context.getBoolean(Config.USE_LOCAL_TIME_STAMP, false);    String tzName = context.getString(Config.TIME_ZONE);    timeZone = (tzName == null) ? null : TimeZone.getTimeZone(tzName);    needRounding = context.getBoolean(Config.ROUND, false);    String unit = context.getString(Config.ROUND_UNIT, Config.MINUTE);    if (unit.equalsIgnoreCase(Config.HOUR)) {        this.roundUnit = Calendar.HOUR_OF_DAY;    } else if (unit.equalsIgnoreCase(Config.MINUTE)) {        this.roundUnit = Calendar.MINUTE;    } else if (unit.equalsIgnoreCase(Config.SECOND)) {        this.roundUnit = Calendar.SECOND;    } else {        LOG.warn(getName() + ". Rounding unit is not valid, please set one of " + "minute, hour or second. Rounding will be disabled");        needRounding = false;    }    this.roundValue = context.getInteger(Config.ROUND_VALUE, 1);    if (roundUnit == Calendar.SECOND || roundUnit == Calendar.MINUTE) {        Preconditions.checkArgument(roundValue > 0 && roundValue <= 60, "Round value must be > 0 and <= 60");    } else if (roundUnit == Calendar.HOUR_OF_DAY) {        Preconditions.checkArgument(roundValue > 0 && roundValue <= 24, "Round value must be > 0 and <= 24");    }        serializerType = context.getString(Config.SERIALIZER, "");    if (serializerType.isEmpty()) {        throw new IllegalArgumentException("serializer config setting is not " + "specified for sink " + getName());    }    serializer = createSerializer(serializerType);    serializer.configure(context);    Preconditions.checkArgument(batchSize > 0, "batchSize must be greater than 0");    if (sinkCounter == null) {        sinkCounter = new SinkCounter(getName());    }}
0c031e8b4ff65446d7d972b4ecf171645495c1bce9e17c7657d35ea999c43db5
getCounter
protected SinkCounter getCounter()
{    return sinkCounter;}
0ceba7e74c8b612824f7bc9e4c3543e680ec08b308ecde24793638922414f35e
createSerializer
private HiveEventSerializer createSerializer(String serializerName)
{    if (serializerName.compareToIgnoreCase(HiveDelimitedTextSerializer.ALIAS) == 0 || serializerName.compareTo(HiveDelimitedTextSerializer.class.getName()) == 0) {        return new HiveDelimitedTextSerializer();    } else if (serializerName.compareToIgnoreCase(HiveJsonSerializer.ALIAS) == 0 || serializerName.compareTo(HiveJsonSerializer.class.getName()) == 0) {        return new HiveJsonSerializer();    }    try {        return (HiveEventSerializer) Class.forName(serializerName).newInstance();    } catch (Exception e) {        throw new IllegalArgumentException("Unable to instantiate serializer: " + serializerName + " on sink: " + getName(), e);    }}
e52e5e378330fd7f87ee30351bbfcec47b751fee12ece2ef0cfdd77a08c906e1
process
public Status process() throws EventDeliveryException
{        Channel channel = getChannel();    Transaction transaction = channel.getTransaction();    transaction.begin();    boolean success = false;    try {                if (timeToSendHeartBeat.compareAndSet(true, false)) {            enableHeartBeatOnAllWriters();        }                int txnEventCount = drainOneBatch(channel);        transaction.commit();        success = true;                if (txnEventCount < 1) {            return Status.BACKOFF;        } else {            return Status.READY;        }    } catch (InterruptedException err) {        LOG.warn(getName() + ": Thread was interrupted.", err);        return Status.BACKOFF;    } catch (Exception e) {        sinkCounter.incrementEventWriteOrChannelFail(e);        throw new EventDeliveryException(e);    } finally {        if (!success) {            transaction.rollback();        }        transaction.close();    }}
2155316da55eaae40c9cb6c2721a53b03e5c48deb4f551be91181e9de01eee22
drainOneBatch
private int drainOneBatch(Channel channel) throws HiveWriter.Failure, InterruptedException
{    int txnEventCount = 0;    try {        Map<HiveEndPoint, HiveWriter> activeWriters = Maps.newHashMap();        for (; txnEventCount < batchSize; ++txnEventCount) {                        Event event = channel.take();            if (event == null) {                break;            }                        HiveEndPoint endPoint = makeEndPoint(metaStoreUri, database, table, partitionVals, event.getHeaders(), timeZone, needRounding, roundUnit, roundValue, useLocalTime);                        HiveWriter writer = getOrCreateWriter(activeWriters, endPoint);                        LOG.debug("{} : Writing event to {}", getName(), endPoint);            writer.write(event);        }                if (txnEventCount == 0) {            sinkCounter.incrementBatchEmptyCount();        } else if (txnEventCount == batchSize) {            sinkCounter.incrementBatchCompleteCount();        } else {            sinkCounter.incrementBatchUnderflowCount();        }        sinkCounter.addToEventDrainAttemptCount(txnEventCount);                for (HiveWriter writer : activeWriters.values()) {            writer.flush(true);        }        sinkCounter.addToEventDrainSuccessCount(txnEventCount);        return txnEventCount;    } catch (HiveWriter.Failure e) {                LOG.warn(getName() + " : " + e.getMessage(), e);        abortAllWriters();        closeAllWriters();        throw e;    }}
94875e3b470d4180762c71ca68158a5baddbbda22e4232e3fc7fa37cf30c31fe
enableHeartBeatOnAllWriters
private void enableHeartBeatOnAllWriters()
{    for (HiveWriter writer : allWriters.values()) {        writer.setHearbeatNeeded();    }}
8fe00bbb9126e3408584b21b1bb096e899dd0a4f4e89ed8dcdf85da4a1dd3b23
getOrCreateWriter
private HiveWriter getOrCreateWriter(Map<HiveEndPoint, HiveWriter> activeWriters, HiveEndPoint endPoint) throws HiveWriter.ConnectException, InterruptedException
{    try {        HiveWriter writer = allWriters.get(endPoint);        if (writer == null) {            LOG.info(getName() + ": Creating Writer to Hive end point : " + endPoint);            writer = new HiveWriter(endPoint, txnsPerBatchAsk, autoCreatePartitions, callTimeout, callTimeoutPool, proxyUser, serializer, sinkCounter);            sinkCounter.incrementConnectionCreatedCount();            if (allWriters.size() > maxOpenConnections) {                int retired = closeIdleWriters();                if (retired == 0) {                    closeEldestWriter();                }            }            allWriters.put(endPoint, writer);            activeWriters.put(endPoint, writer);        } else {            if (activeWriters.get(endPoint) == null) {                activeWriters.put(endPoint, writer);            }        }        return writer;    } catch (HiveWriter.ConnectException e) {        sinkCounter.incrementConnectionFailedCount();        throw e;    }}
9eada11cdcf835c4e3ce39b3a32c7e77b23c8e52b37b92f7658f7c720768b09f
makeEndPoint
private HiveEndPoint makeEndPoint(String metaStoreUri, String database, String table, List<String> partVals, Map<String, String> headers, TimeZone timeZone, boolean needRounding, int roundUnit, Integer roundValue, boolean useLocalTime)
{    if (partVals == null) {        return new HiveEndPoint(metaStoreUri, database, table, null);    }    ArrayList<String> realPartVals = Lists.newArrayList();    for (String partVal : partVals) {        realPartVals.add(BucketPath.escapeString(partVal, headers, timeZone, needRounding, roundUnit, roundValue, useLocalTime));    }    return new HiveEndPoint(metaStoreUri, database, table, realPartVals);}
a22b1e9ec30ec314e050ea8819a58657126c122aee3768b48dd046d2647975d8
closeEldestWriter
private void closeEldestWriter() throws InterruptedException
{    long oldestTimeStamp = System.currentTimeMillis();    HiveEndPoint eldest = null;    for (Entry<HiveEndPoint, HiveWriter> entry : allWriters.entrySet()) {        if (entry.getValue().getLastUsed() < oldestTimeStamp) {            eldest = entry.getKey();            oldestTimeStamp = entry.getValue().getLastUsed();        }    }    try {        sinkCounter.incrementConnectionCreatedCount();        LOG.info(getName() + ": Closing least used Writer to Hive EndPoint : " + eldest);        allWriters.remove(eldest).close();    } catch (InterruptedException e) {        LOG.warn(getName() + ": Interrupted when attempting to close writer for end point: " + eldest, e);        throw e;    }}
e9623572bc72c2fd7dfb491bd6886d44c6dbd3038daa2be707e57e8aa51a41df
closeIdleWriters
private int closeIdleWriters() throws InterruptedException
{    int count = 0;    long now = System.currentTimeMillis();    ArrayList<HiveEndPoint> retirees = Lists.newArrayList();        for (Entry<HiveEndPoint, HiveWriter> entry : allWriters.entrySet()) {        if (now - entry.getValue().getLastUsed() > idleTimeout) {            ++count;            retirees.add(entry.getKey());        }    }        for (HiveEndPoint ep : retirees) {        sinkCounter.incrementConnectionClosedCount();        LOG.info(getName() + ": Closing idle Writer to Hive end point : {}", ep);        allWriters.remove(ep).close();    }    return count;}
dfc8ceaf036635aa8117e22811733e239b4a422593da58e1348603b6e189f5e9
closeAllWriters
private void closeAllWriters() throws InterruptedException
{        for (Entry<HiveEndPoint, HiveWriter> entry : allWriters.entrySet()) {        entry.getValue().close();    }        allWriters.clear();}
7c61438624219a6f87b9ca0fcdbd0d7f1b4a1a4373e8da1c8e7bba3be57fd912
abortAllWriters
private void abortAllWriters() throws InterruptedException
{    for (Entry<HiveEndPoint, HiveWriter> entry : allWriters.entrySet()) {        entry.getValue().abort();    }}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{        for (Entry<HiveEndPoint, HiveWriter> entry : allWriters.entrySet()) {        try {            HiveWriter w = entry.getValue();            w.close();        } catch (InterruptedException ex) {            Thread.currentThread().interrupt();        }    }        callTimeoutPool.shutdown();    try {        while (callTimeoutPool.isTerminated() == false) {            callTimeoutPool.awaitTermination(Math.max(DEFAULT_CALLTIMEOUT, callTimeout), TimeUnit.MILLISECONDS);        }    } catch (InterruptedException ex) {        LOG.warn(getName() + ":Shutdown interrupted on " + callTimeoutPool, ex);    }    callTimeoutPool = null;    allWriters.clear();    allWriters = null;    sinkCounter.stop();    super.stop();    LOG.info("Hive Sink {} stopped", getName());}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    String timeoutName = "hive-" + getName() + "-call-runner-%d";        callTimeoutPool = Executors.newFixedThreadPool(1, new ThreadFactoryBuilder().setNameFormat(timeoutName).build());    this.allWriters = Maps.newHashMap();    sinkCounter.start();    super.start();    setupHeartBeatTimer();    LOG.info(getName() + ": Hive Sink {} started", getName());}
89566d89dd737fbc3be73752e2254792252fc9d06dc7b64b054ea36c795c6127
setupHeartBeatTimer
private void setupHeartBeatTimer()
{    if (heartBeatInterval > 0) {        heartBeatTimer.schedule(new TimerTask() {            @Override            public void run() {                timeToSendHeartBeat.set(true);                setupHeartBeatTimer();            }        }, heartBeatInterval * 1000);    }}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    timeToSendHeartBeat.set(true);    setupHeartBeatTimer();}
dcc511f35190533c2d6fcc6073d66b12e111f5004c64ff08ccc3609a06ab844d
getBatchSize
public long getBatchSize()
{    return batchSize;}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return "{ Sink type:" + getClass().getSimpleName() + ", name:" + getName() + " }";}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return endPoint.toString();}
ab6d696bbf0482da1ac47314686a75219533f6f25a68f159217d3aaef9ea537f
resetCounters
private void resetCounters()
{    eventCounter = 0;    processSize = 0;    batchCounter = 0;}
0fc8e784e2d503ef17a0be2b3c5b94b96c4f85c3e744fa48299efeee36937e68
setHearbeatNeeded
 void setHearbeatNeeded()
{    hearbeatNeeded = true;}
a9f6eea5624e0611620f7529a346ce2c52f4e80223b515227f9408bee0c98338
getRemainingTxns
public int getRemainingTxns()
{    return txnBatch.remainingTransactions();}
a0d1034509fbe25b194616a01e98e3f902df47eea57d95d94f1c9d4c26cbb0a6
write
public synchronized void write(final Event event) throws WriteException, InterruptedException
{    if (closed) {        throw new IllegalStateException("Writer closed. Cannot write to : " + endPoint);    }    batch.add(event);    if (batch.size() == writeBatchSz) {                writeEventBatchToSerializer();    }        processSize += event.getBody().length;    eventCounter++;}
ef1cef23452be86986194e36319381c8010343ea3994f4b55d42f89ef971ea92
writeEventBatchToSerializer
private void writeEventBatchToSerializer() throws InterruptedException, WriteException
{    try {        timedCall(new CallRunner1<Void>() {            @Override            public Void call() throws InterruptedException, StreamingException {                try {                    for (Event event : batch) {                        try {                            serializer.write(txnBatch, event);                        } catch (SerializationError err) {                            LOG.info("Parse failed : {}  : {}", err.getMessage(), new String(event.getBody()));                        }                    }                    return null;                } catch (IOException e) {                    throw new StreamingIOFailure(e.getMessage(), e);                }            }        });        batch.clear();    } catch (StreamingException e) {        throw new WriteException(endPoint, txnBatch.getCurrentTxnId(), e);    } catch (TimeoutException e) {        throw new WriteException(endPoint, txnBatch.getCurrentTxnId(), e);    }}
473a319f41385b8ea44278205e7f8ba46bf290282af015889a5ffb141b5fc830
call
public Void call() throws InterruptedException, StreamingException
{    try {        for (Event event : batch) {            try {                serializer.write(txnBatch, event);            } catch (SerializationError err) {                LOG.info("Parse failed : {}  : {}", err.getMessage(), new String(event.getBody()));            }        }        return null;    } catch (IOException e) {        throw new StreamingIOFailure(e.getMessage(), e);    }}
bd19dfdab0786ff9b8c8f66b0411f529deaedd85c5958f579854c25d127f41e8
flush
public void flush(boolean rollToNext) throws CommitException, TxnBatchException, TxnFailure, InterruptedException, WriteException
{    if (!batch.isEmpty()) {        writeEventBatchToSerializer();        batch.clear();    }        if (hearbeatNeeded) {        hearbeatNeeded = false;        heartBeat();    }    lastUsed = System.currentTimeMillis();    try {                commitTxn();        if (txnBatch.remainingTransactions() == 0) {            closeTxnBatch();            txnBatch = null;            if (rollToNext) {                txnBatch = nextTxnBatch(recordWriter);            }        }                if (rollToNext) {            LOG.debug("Switching to next Txn for {}", endPoint);                        txnBatch.beginNextTransaction();        }    } catch (StreamingException e) {        throw new TxnFailure(txnBatch, e);    }}
eabea00033f2af28b40cf3916d95b301a032bd87a2eed23ddab41e8b35323af7
abort
public void abort() throws InterruptedException
{    batch.clear();    abortTxn();}
d783edb60bd31af02122c34260fdba9050873f025c0fef5b19beb35bb98ffdc2
heartBeat
public void heartBeat() throws InterruptedException
{        try {        timedCall(new CallRunner1<Void>() {            @Override            public Void call() throws StreamingException {                LOG.info("Sending heartbeat on batch " + txnBatch);                txnBatch.heartbeat();                return null;            }        });    } catch (InterruptedException e) {        throw e;    } catch (Exception e) {        LOG.warn("Unable to send heartbeat on Txn Batch " + txnBatch, e);        }}
0759615308f40cd430ca38cc033de6f9dc95bae51476b70ed18c6fe09394ea84
call
public Void call() throws StreamingException
{    LOG.info("Sending heartbeat on batch " + txnBatch);    txnBatch.heartbeat();    return null;}
cf6704a4e9853ec7bfb4e2656092600923680217ceac778bb2648284c6beb757
close
public void close() throws InterruptedException
{    batch.clear();    abortRemainingTxns();    closeTxnBatch();    closeConnection();    closed = true;}
c60a52d7018018b18412e1c0242abb4acb29baa1190e3ac9ef99e718fefdf194
abortRemainingTxns
private void abortRemainingTxns() throws InterruptedException
{    try {        if (!isClosed(txnBatch.getCurrentTransactionState())) {            abortCurrTxnHelper();        }                if (txnBatch.remainingTransactions() > 0) {            timedCall(new CallRunner1<Void>() {                @Override                public Void call() throws StreamingException, InterruptedException {                    txnBatch.beginNextTransaction();                    return null;                }            });            abortRemainingTxns();        }    } catch (StreamingException e) {        LOG.warn("Error when aborting remaining transactions in batch " + txnBatch, e);        return;    } catch (TimeoutException e) {        LOG.warn("Timed out when aborting remaining transactions in batch " + txnBatch, e);        return;    }}
39027dbeb82a12024b92e4ecef595c900ed14a7fa9c9ffd7eee511660e7775b0
call
public Void call() throws StreamingException, InterruptedException
{    txnBatch.beginNextTransaction();    return null;}
6ce5e1aecf66e28be29f3d22e9b861e57c1c6e75f6c8477e75b3fd0f583e3ba0
abortCurrTxnHelper
private void abortCurrTxnHelper() throws TimeoutException, InterruptedException
{    try {        timedCall(new CallRunner1<Void>() {            @Override            public Void call() throws StreamingException, InterruptedException {                txnBatch.abort();                LOG.info("Aborted txn " + txnBatch.getCurrentTxnId());                return null;            }        });    } catch (StreamingException e) {        LOG.warn("Unable to abort transaction " + txnBatch.getCurrentTxnId(), e);        }}
39027dbeb82a12024b92e4ecef595c900ed14a7fa9c9ffd7eee511660e7775b0
call
public Void call() throws StreamingException, InterruptedException
{    txnBatch.abort();    LOG.info("Aborted txn " + txnBatch.getCurrentTxnId());    return null;}
dcefde2c67b71ad5a1f740c78217318d656a2f817114f6155c5594173535ea8a
isClosed
private boolean isClosed(TransactionBatch.TxnState txnState)
{    if (txnState == TransactionBatch.TxnState.COMMITTED) {        return true;    }    if (txnState == TransactionBatch.TxnState.ABORTED) {        return true;    }    return false;}
62e29c224e6888a6b2ab81f4ee1cfcd49f5e28a63236823a01673f645d4b8b8d
closeConnection
public void closeConnection() throws InterruptedException
{    LOG.info("Closing connection to EndPoint : {}", endPoint);    try {        timedCall(new CallRunner1<Void>() {            @Override            public Void call() {                                connection.close();                return null;            }        });        sinkCounter.incrementConnectionClosedCount();    } catch (Exception e) {        LOG.warn("Error closing connection to EndPoint : " + endPoint, e);        }}
129e071a5acdf44209957699325f269c391c2463b78b7efe09056606615ae94b
call
public Void call()
{        connection.close();    return null;}
6bd2fa3740f3587c8d6f09b2073cbfed7cba16b18d556620165d65c7d1cedda1
commitTxn
private void commitTxn() throws CommitException, InterruptedException
{    if (LOG.isInfoEnabled()) {        LOG.info("Committing Txn " + txnBatch.getCurrentTxnId() + " on EndPoint: " + endPoint);    }    try {        timedCall(new CallRunner1<Void>() {            @Override            public Void call() throws StreamingException, InterruptedException {                                txnBatch.commit();                return null;            }        });    } catch (Exception e) {        throw new CommitException(endPoint, txnBatch.getCurrentTxnId(), e);    }}
39027dbeb82a12024b92e4ecef595c900ed14a7fa9c9ffd7eee511660e7775b0
call
public Void call() throws StreamingException, InterruptedException
{        txnBatch.commit();    return null;}
e335dc4dbc6ca7c49146070943b2e9f1c55ebc56d86f957990d477656a1b852c
abortTxn
private void abortTxn() throws InterruptedException
{    LOG.info("Aborting Txn id {} on End Point {}", txnBatch.getCurrentTxnId(), endPoint);    try {        timedCall(new CallRunner1<Void>() {            @Override            public Void call() throws StreamingException, InterruptedException {                                txnBatch.abort();                return null;            }        });    } catch (InterruptedException e) {        throw e;    } catch (TimeoutException e) {        LOG.warn("Timeout while aborting Txn " + txnBatch.getCurrentTxnId() + " on EndPoint: " + endPoint, e);    } catch (Exception e) {        LOG.warn("Error aborting Txn " + txnBatch.getCurrentTxnId() + " on EndPoint: " + endPoint, e);        }}
39027dbeb82a12024b92e4ecef595c900ed14a7fa9c9ffd7eee511660e7775b0
call
public Void call() throws StreamingException, InterruptedException
{        txnBatch.abort();    return null;}
3254604049b7aeb0492c8325842c6357ffc097bd1d4e31e33c693d3d160f5b03
newConnection
private StreamingConnection newConnection(final String proxyUser) throws InterruptedException, ConnectException
{    try {        return timedCall(new CallRunner1<StreamingConnection>() {            @Override            public StreamingConnection call() throws InterruptedException, StreamingException {                                return endPoint.newConnection(autoCreatePartitions);            }        });    } catch (Exception e) {        throw new ConnectException(endPoint, e);    }}
a2d2db87d91e4f2a887c24bb8994e54285ea027ab06f20bb29ba93519f44ebdb
call
public StreamingConnection call() throws InterruptedException, StreamingException
{        return endPoint.newConnection(autoCreatePartitions);}
da89b472910f5adb9afc7e7b8d127a0d01492e135a3b92958dc80581a98cf7d2
nextTxnBatch
private TransactionBatch nextTxnBatch(final RecordWriter recordWriter) throws InterruptedException, TxnBatchException
{    LOG.debug("Fetching new Txn Batch for {}", endPoint);    TransactionBatch batch = null;    try {        batch = timedCall(new CallRunner1<TransactionBatch>() {            @Override            public TransactionBatch call() throws InterruptedException, StreamingException {                                return connection.fetchTransactionBatch(txnsPerBatch, recordWriter);            }        });        LOG.info("Acquired Transaction batch {}", batch);    } catch (Exception e) {        throw new TxnBatchException(endPoint, e);    }    return batch;}
1e5cc3b0701420b9bfd756e68cb66e7c396a478659cb8ba40467a7c0cc1339f4
call
public TransactionBatch call() throws InterruptedException, StreamingException
{        return connection.fetchTransactionBatch(txnsPerBatch, recordWriter);}
9ea54bcd33e2a6446fd3015c6a4a2bf124a5862a242151c0b7fc6da88d3070f6
closeTxnBatch
private void closeTxnBatch() throws InterruptedException
{    try {        LOG.info("Closing Txn Batch {}.", txnBatch);        timedCall(new CallRunner1<Void>() {            @Override            public Void call() throws InterruptedException, StreamingException {                                txnBatch.close();                return null;            }        });    } catch (InterruptedException e) {        throw e;    } catch (Exception e) {        LOG.warn("Error closing Txn Batch " + txnBatch, e);        }}
473a319f41385b8ea44278205e7f8ba46bf290282af015889a5ffb141b5fc830
call
public Void call() throws InterruptedException, StreamingException
{        txnBatch.close();    return null;}
a503e2ef7848196976d2d8ed6679f7757fe02d7e51b3e10123d22f5cbc37a96b
timedCall
private T timedCall(final CallRunner1<T> callRunner) throws TimeoutException, InterruptedException, StreamingException
{    Future<T> future = callTimeoutPool.submit(new Callable<T>() {        @Override        public T call() throws StreamingException, InterruptedException, Failure {            return callRunner.call();        }    });    try {        if (callTimeout > 0) {            return future.get(callTimeout, TimeUnit.MILLISECONDS);        } else {            return future.get();        }    } catch (TimeoutException eT) {        future.cancel(true);        sinkCounter.incrementConnectionFailedCount();        throw eT;    } catch (ExecutionException e1) {        sinkCounter.incrementConnectionFailedCount();        Throwable cause = e1.getCause();        if (cause instanceof IOException) {            throw new StreamingException("I/O Failure", (IOException) cause);        } else if (cause instanceof StreamingException) {            throw (StreamingException) cause;        } else if (cause instanceof TimeoutException) {            throw new StreamingException("Operation Timed Out.", (TimeoutException) cause);        } else if (cause instanceof RuntimeException) {            throw (RuntimeException) cause;        } else if (cause instanceof InterruptedException) {            throw (InterruptedException) cause;        }        throw new StreamingException(e1.getMessage(), e1);    }}
e057f2d22294867c260e4c491285b0de0a751db0c75aa5b7dab0105bd836de66
call
public T call() throws StreamingException, InterruptedException, Failure
{    return callRunner.call();}
af301bc2a19341dbd38ea97b18e0c2708057a11c5180f7cf3385b39dfcb446f4
getLastUsed
 long getLastUsed()
{    return lastUsed;}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    TestUtil.dropDB(conf, dbName);    sink = new HiveSink();    sink.setName("HiveSink-" + UUID.randomUUID().toString());    String dbLocation = dbFolder.newFolder(dbName).getCanonicalPath() + ".db";        dbLocation = dbLocation.replaceAll("\\\\", "/");    TestUtil.createDbAndTable(driver, dbName, tblName, partitionVals, colNames, colTypes, partNames, dbLocation);}
14e172e7c286329c336ea2cdcdac2e56c0ba424cfd5dd91f46cf1e9667ddee88
tearDown
public void tearDown() throws MetaException, HiveException
{    TestUtil.dropDB(conf, dbName);}
8512ca9e6bba946cf1e01c12ba4dd7d774ec9b36380d3af90a930388685ed79c
testSingleWriter
public void testSingleWriter(boolean partitioned, String dbName, String tblName, Channel pChannel) throws Exception
{    int totalRecords = 4;    int batchSize = 2;    int batchCount = totalRecords / batchSize;    Context context = new Context();    context.put("hive.metastore", metaStoreURI);    context.put("hive.database", dbName);    context.put("hive.table", tblName);    if (partitioned) {        context.put("hive.partition", PART1_VALUE + "," + PART2_VALUE);    }    context.put("autoCreatePartitions", "false");    context.put("batchSize", "" + batchSize);    context.put("serializer", HiveDelimitedTextSerializer.ALIAS);    context.put("serializer.fieldnames", COL1 + ",," + COL2 + ",");    context.put("heartBeatInterval", "0");    Channel channel = startSink(sink, context, pChannel);    List<String> bodies = Lists.newArrayList();        Transaction txn = channel.getTransaction();    txn.begin();    for (int j = 1; j <= totalRecords; j++) {        Event event = new SimpleEvent();        String body = j + ",blah,This is a log message,other stuff";        event.setBody(body.getBytes());        bodies.add(body);        channel.put(event);    }        txn.commit();    txn.close();    checkRecordCountInTable(0, dbName, tblName);    for (int i = 0; i < batchCount; i++) {        sink.process();    }    checkRecordCountInTable(totalRecords, dbName, tblName);    sink.stop();    checkRecordCountInTable(totalRecords, dbName, tblName);}
ce030a2cc759664e34f0201ebbf1bd9ea54c9ae5734f6b9e0696149712f54d1d
testSingleWriterSimplePartitionedTable
public void testSingleWriterSimplePartitionedTable() throws Exception
{    testSingleWriter(true, dbName, tblName, null);}
43ac6e08456ca396937cd18e8bb45cfbed0e0b57c3ab0915f5fedf4c26a7b981
testSingleWriterSimpleUnPartitionedTable
public void testSingleWriterSimpleUnPartitionedTable() throws Exception
{    TestUtil.dropDB(conf, dbName2);    String dbLocation = dbFolder.newFolder(dbName2).getCanonicalPath() + ".db";        dbLocation = dbLocation.replaceAll("\\\\", "/");    TestUtil.createDbAndTable(driver, dbName2, tblName2, null, colNames2, colTypes2, null, dbLocation);    try {        testSingleWriter(false, dbName2, tblName2, null);    } finally {        TestUtil.dropDB(conf, dbName2);    }}
cb145f2b13ac44b39ebbac08d1ab4b575fd91e7292924defd31e224a7d9dd994
testSingleWriterUseHeaders
public void testSingleWriterUseHeaders() throws Exception
{    String[] colNames = { COL1, COL2 };    String PART1_NAME = "country";    String PART2_NAME = "hour";    String[] partNames = { PART1_NAME, PART2_NAME };    List<String> partitionVals = null;    String PART1_VALUE = "%{" + PART1_NAME + "}";    String PART2_VALUE = "%y-%m-%d-%k";    partitionVals = new ArrayList<String>(2);    partitionVals.add(PART1_VALUE);    partitionVals.add(PART2_VALUE);    String tblName = "hourlydata";    TestUtil.dropDB(conf, dbName2);    String dbLocation = dbFolder.newFolder(dbName2).getCanonicalPath() + ".db";        dbLocation = dbLocation.replaceAll("\\\\", "/");    TestUtil.createDbAndTable(driver, dbName2, tblName, partitionVals, colNames, colTypes, partNames, dbLocation);    int totalRecords = 4;    int batchSize = 2;    int batchCount = totalRecords / batchSize;    Context context = new Context();    context.put("hive.metastore", metaStoreURI);    context.put("hive.database", dbName2);    context.put("hive.table", tblName);    context.put("hive.partition", PART1_VALUE + "," + PART2_VALUE);    context.put("autoCreatePartitions", "true");    context.put("useLocalTimeStamp", "false");    context.put("batchSize", "" + batchSize);    context.put("serializer", HiveDelimitedTextSerializer.ALIAS);    context.put("serializer.fieldnames", COL1 + ",," + COL2 + ",");    context.put("heartBeatInterval", "0");    Channel channel = startSink(sink, context);    Calendar eventDate = Calendar.getInstance();    List<String> bodies = Lists.newArrayList();        Transaction txn = channel.getTransaction();    txn.begin();    for (int j = 1; j <= totalRecords; j++) {        Event event = new SimpleEvent();        String body = j + ",blah,This is a log message,other stuff";        event.setBody(body.getBytes());        eventDate.clear();                eventDate.set(2014, 03, 03, j % batchCount, 1);        event.getHeaders().put("timestamp", String.valueOf(eventDate.getTimeInMillis()));        event.getHeaders().put(PART1_NAME, "Asia");        bodies.add(body);        channel.put(event);    }        txn.commit();    txn.close();    checkRecordCountInTable(0, dbName2, tblName);    for (int i = 0; i < batchCount; i++) {        sink.process();    }    checkRecordCountInTable(totalRecords, dbName2, tblName);    sink.stop();        SinkCounter counter = sink.getCounter();    Assert.assertEquals(2, counter.getConnectionCreatedCount());    Assert.assertEquals(2, counter.getConnectionClosedCount());    Assert.assertEquals(2, counter.getBatchCompleteCount());    Assert.assertEquals(0, counter.getBatchEmptyCount());    Assert.assertEquals(0, counter.getConnectionFailedCount());    Assert.assertEquals(4, counter.getEventDrainAttemptCount());    Assert.assertEquals(4, counter.getEventDrainSuccessCount());}
19e2d3c6d4910d68bf5f6b43d410ad8004c62ca59c5777bc83da9daecfada878
testHeartBeat
public void testHeartBeat() throws EventDeliveryException, IOException, CommandNeedRetryException
{    int batchSize = 2;    int batchCount = 3;    int totalRecords = batchCount * batchSize;    Context context = new Context();    context.put("hive.metastore", metaStoreURI);    context.put("hive.database", dbName);    context.put("hive.table", tblName);    context.put("hive.partition", PART1_VALUE + "," + PART2_VALUE);    context.put("autoCreatePartitions", "true");    context.put("batchSize", "" + batchSize);    context.put("serializer", HiveDelimitedTextSerializer.ALIAS);    context.put("serializer.fieldnames", COL1 + ",," + COL2 + ",");    context.put("hive.txnsPerBatchAsk", "20");        context.put("heartBeatInterval", "3");    Channel channel = startSink(sink, context);    List<String> bodies = Lists.newArrayList();        for (int i = 0; i < batchCount; i++) {        Transaction txn = channel.getTransaction();        txn.begin();        for (int j = 1; j <= batchSize; j++) {            Event event = new SimpleEvent();            String body = i * j + ",blah,This is a log message,other stuff";            event.setBody(body.getBytes());            bodies.add(body);            channel.put(event);        }                txn.commit();        txn.close();        sink.process();                sleep(3000);    }    sink.stop();    checkRecordCountInTable(totalRecords, dbName, tblName);}
e79c64e9f29224d75e09d6edab764f1bb711a993a685e3824557650e76fa82b6
testJsonSerializer
public void testJsonSerializer() throws Exception
{    int batchSize = 2;    int batchCount = 2;    int totalRecords = batchCount * batchSize;    Context context = new Context();    context.put("hive.metastore", metaStoreURI);    context.put("hive.database", dbName);    context.put("hive.table", tblName);    context.put("hive.partition", PART1_VALUE + "," + PART2_VALUE);    context.put("autoCreatePartitions", "true");    context.put("batchSize", "" + batchSize);    context.put("serializer", HiveJsonSerializer.ALIAS);    context.put("serializer.fieldnames", COL1 + ",," + COL2 + ",");    context.put("heartBeatInterval", "0");    Channel channel = startSink(sink, context);    List<String> bodies = Lists.newArrayList();        for (int i = 0; i < batchCount; i++) {        Transaction txn = channel.getTransaction();        txn.begin();        for (int j = 1; j <= batchSize; j++) {            Event event = new SimpleEvent();            String body = "{\"id\" : 1, \"msg\" : \"using json serializer\"}";            event.setBody(body.getBytes());            bodies.add(body);            channel.put(event);        }                txn.commit();        txn.close();        sink.process();    }    checkRecordCountInTable(totalRecords, dbName, tblName);    sink.stop();    checkRecordCountInTable(totalRecords, dbName, tblName);}
799d52b0b8f2228a73f8f5f35d6cec3937029922705a37d30db2fb4c43d8d744
testErrorCounter
public void testErrorCounter() throws Exception
{    Channel channel = Mockito.mock(Channel.class);    Mockito.when(channel.take()).thenThrow(new ChannelException("dummy"));    Transaction transaction = Mockito.mock(BasicTransactionSemantics.class);    Mockito.when(channel.getTransaction()).thenReturn(transaction);    try {        testSingleWriter(true, dbName, tblName, channel);    } catch (EventDeliveryException e) {        }    SinkCounter sinkCounter = (SinkCounter) Whitebox.getInternalState(sink, "sinkCounter");    Assert.assertEquals(1, sinkCounter.getChannelReadFail());}
d1aaf654247e3c9819a638666d95905fcdbda251642f6cdf19aa9e93f7302e9e
sleep
private void sleep(int n)
{    try {        Thread.sleep(n);    } catch (InterruptedException e) {    }}
40b23dcc4c1bcc9e71b158af4435fafb1e984d01cb3ccea713819c14dc6db80f
startSink
private static Channel startSink(HiveSink sink, Context context)
{    return startSink(sink, context, null);}
bf2063458f414ad26286d07bec23ec8af8786fff90f9feea78039fe8e438d2e2
startSink
private static Channel startSink(HiveSink sink, Context context, Channel pChannel)
{    Configurables.configure(sink, context);    Channel channel = pChannel == null ? new MemoryChannel() : pChannel;    Configurables.configure(channel, context);    sink.setChannel(channel);    sink.start();    return channel;}
0a559fbe25e46be7ec8e55d37bb303757ce788f895c86722568a4fb564a58253
checkRecordCountInTable
private void checkRecordCountInTable(int expectedCount, String db, String tbl) throws CommandNeedRetryException, IOException
{    int count = TestUtil.listRecordsInTable(driver, db, tbl).size();    Assert.assertEquals(expectedCount, count);}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{        TxnDbUtil.cleanDb();    TxnDbUtil.prepDb();        TestUtil.dropDB(conf, dbName);    String dbLocation = dbFolder.newFolder(dbName).getCanonicalPath() + ".db";        dbLocation = dbLocation.replaceAll("\\\\", "/");    TestUtil.createDbAndTable(driver, dbName, tblName, partVals, colNames, colTypes, partNames, dbLocation);        Context ctx = new Context();    ctx.put("serializer.fieldnames", COL1 + ",," + COL2 + ",");    serializer = new HiveDelimitedTextSerializer();    serializer.configure(ctx);}
b425441f69a319b48988c3a41017dd26e42fa1d0be55dece651feb9634fea5ec
testInstantiate
public void testInstantiate() throws Exception
{    HiveEndPoint endPoint = new HiveEndPoint(metaStoreURI, dbName, tblName, partVals);    SinkCounter sinkCounter = new SinkCounter(this.getClass().getName());    HiveWriter writer = new HiveWriter(endPoint, 10, true, timeout, callTimeoutPool, "flumetest", serializer, sinkCounter);    writer.close();}
f131072afa55ab5ad9bcaade0c62585357b68aa3acbe0dc282f0b7e79a0f6818
testWriteBasic
public void testWriteBasic() throws Exception
{    HiveEndPoint endPoint = new HiveEndPoint(metaStoreURI, dbName, tblName, partVals);    SinkCounter sinkCounter = new SinkCounter(this.getClass().getName());    HiveWriter writer = new HiveWriter(endPoint, 10, true, timeout, callTimeoutPool, "flumetest", serializer, sinkCounter);    writeEvents(writer, 3);    writer.flush(false);    writer.close();    checkRecordCountInTable(3);}
77c02ff6437dbf46a00ae01f956819acffce60c0f01ebd9ac7d4aaeeba9dcf2f
testWriteMultiFlush
public void testWriteMultiFlush() throws Exception
{    HiveEndPoint endPoint = new HiveEndPoint(metaStoreURI, dbName, tblName, partVals);    SinkCounter sinkCounter = new SinkCounter(this.getClass().getName());    HiveWriter writer = new HiveWriter(endPoint, 10, true, timeout, callTimeoutPool, "flumetest", serializer, sinkCounter);    checkRecordCountInTable(0);    SimpleEvent event = new SimpleEvent();    String REC1 = "1,xyz,Hello world,abc";    event.setBody(REC1.getBytes());    writer.write(event);    checkRecordCountInTable(0);    writer.flush(true);    checkRecordCountInTable(1);    String REC2 = "2,xyz,Hello world,abc";    event.setBody(REC2.getBytes());    writer.write(event);    checkRecordCountInTable(1);    writer.flush(true);    checkRecordCountInTable(2);    String REC3 = "3,xyz,Hello world,abc";    event.setBody(REC3.getBytes());    writer.write(event);    writer.flush(true);    checkRecordCountInTable(3);    writer.close();    checkRecordCountInTable(3);}
079a3f85f86312edc45bb3df4cfff55f87cb48c127b2ba99c090263bc25f6f11
testTxnBatchConsumption
public void testTxnBatchConsumption() throws Exception
{            HiveEndPoint endPoint = new HiveEndPoint(metaStoreURI, dbName, tblName, partVals);    SinkCounter sinkCounter = new SinkCounter(this.getClass().getName());    int txnPerBatch = 3;    HiveWriter writer = new HiveWriter(endPoint, txnPerBatch, true, timeout, callTimeoutPool, "flumetest", serializer, sinkCounter);    Assert.assertEquals(writer.getRemainingTxns(), 2);    writer.flush(true);    Assert.assertEquals(writer.getRemainingTxns(), 1);    writer.flush(true);    Assert.assertEquals(writer.getRemainingTxns(), 0);    writer.flush(true);        Assert.assertEquals(writer.getRemainingTxns(), 2);    writer.flush(true);    Assert.assertEquals(writer.getRemainingTxns(), 1);    writer.close();}
7864601ace147442f00bb90213ae17111861c88941ba47f090fdc1a562b7dbfe
checkRecordCountInTable
private void checkRecordCountInTable(int expectedCount) throws CommandNeedRetryException, IOException
{    int count = TestUtil.listRecordsInTable(driver, dbName, tblName).size();    Assert.assertEquals(expectedCount, count);}
b045e1bff3c1de9143fa414a791297eebc691b7d0c2a7d4ef6b47485e66b30fa
testInOrderWrite
public void testInOrderWrite() throws Exception
{    HiveEndPoint endPoint = new HiveEndPoint(metaStoreURI, dbName, tblName, partVals);    SinkCounter sinkCounter = new SinkCounter(this.getClass().getName());        int timeout = 5000;    HiveDelimitedTextSerializer serializer2 = new HiveDelimitedTextSerializer();    Context ctx = new Context();    ctx.put("serializer.fieldnames", COL1 + "," + COL2);    ctx.put("serializer.serdeSeparator", ",");    serializer2.configure(ctx);    HiveWriter writer = new HiveWriter(endPoint, 10, true, timeout, callTimeoutPool, "flumetest", serializer2, sinkCounter);    SimpleEvent event = new SimpleEvent();    event.setBody("1,Hello world 1".getBytes());    writer.write(event);    event.setBody("2,Hello world 2".getBytes());    writer.write(event);    event.setBody("3,Hello world 3".getBytes());    writer.write(event);    writer.flush(false);    writer.close();}
ca225d9b10f1ecd67b1dc5d98fd8bf879edadc2808e6c1b69b3904ff270d553c
testSerdeSeparatorCharParsing
public void testSerdeSeparatorCharParsing() throws Exception
{    HiveEndPoint endPoint = new HiveEndPoint(metaStoreURI, dbName, tblName, partVals);    SinkCounter sinkCounter = new SinkCounter(this.getClass().getName());        int timeout = 10000;        HiveDelimitedTextSerializer serializer1 = new HiveDelimitedTextSerializer();    Context ctx = new Context();    ctx.put("serializer.fieldnames", COL1 + "," + COL2);    ctx.put("serializer.serdeSeparator", ",");    serializer1.configure(ctx);            HiveDelimitedTextSerializer serializer2 = new HiveDelimitedTextSerializer();    ctx = new Context();    ctx.put("serializer.fieldnames", COL1 + "," + COL2);    ctx.put("serializer.serdeSeparator", "'\t'");    serializer2.configure(ctx);            HiveDelimitedTextSerializer serializer3 = new HiveDelimitedTextSerializer();    ctx = new Context();    ctx.put("serializer.fieldnames", COL1 + "," + COL2);    ctx.put("serializer.serdeSeparator", "ab");    try {        serializer3.configure(ctx);        Assert.assertTrue("Bad serdeSeparator character was accepted", false);    } catch (Exception e) {        }}
5fbbac78f96dd6cfa586e67e448420edfc031cf3af4bbd1642849b403eb41051
testSecondWriterBeforeFirstCommits
public void testSecondWriterBeforeFirstCommits() throws Exception
{        HiveEndPoint endPoint1 = new HiveEndPoint(metaStoreURI, dbName, tblName, partVals);    ArrayList<String> partVals2 = new ArrayList<String>(2);    partVals2.add(PART1_VALUE);    partVals2.add("Nepal");    HiveEndPoint endPoint2 = new HiveEndPoint(metaStoreURI, dbName, tblName, partVals2);    SinkCounter sinkCounter1 = new SinkCounter(this.getClass().getName());    SinkCounter sinkCounter2 = new SinkCounter(this.getClass().getName());    HiveWriter writer1 = new HiveWriter(endPoint1, 10, true, timeout, callTimeoutPool, "flumetest", serializer, sinkCounter1);    writeEvents(writer1, 3);    HiveWriter writer2 = new HiveWriter(endPoint2, 10, true, timeout, callTimeoutPool, "flumetest", serializer, sinkCounter2);    writeEvents(writer2, 3);        writer2.flush(false);        writer1.flush(false);    writer1.close();    writer2.close();}
9f1790d4ba79375b7e020c480e2567b846025c9db8d4c5c4a9d7ae4f2fe62098
testSecondWriterAfterFirstCommits
public void testSecondWriterAfterFirstCommits() throws Exception
{        HiveEndPoint endPoint1 = new HiveEndPoint(metaStoreURI, dbName, tblName, partVals);    ArrayList<String> partVals2 = new ArrayList<String>(2);    partVals2.add(PART1_VALUE);    partVals2.add("Nepal");    HiveEndPoint endPoint2 = new HiveEndPoint(metaStoreURI, dbName, tblName, partVals2);    SinkCounter sinkCounter1 = new SinkCounter(this.getClass().getName());    SinkCounter sinkCounter2 = new SinkCounter(this.getClass().getName());    HiveWriter writer1 = new HiveWriter(endPoint1, 10, true, timeout, callTimeoutPool, "flumetest", serializer, sinkCounter1);    writeEvents(writer1, 3);        writer1.flush(false);    HiveWriter writer2 = new HiveWriter(endPoint2, 10, true, timeout, callTimeoutPool, "flumetest", serializer, sinkCounter2);    writeEvents(writer2, 3);        writer2.flush(false);    writer1.close();    writer2.close();}
550597062f5da6b5adadd35094ac665750cb1352c80611fb6f3ab26391659258
writeEvents
private void writeEvents(HiveWriter writer, int count) throws InterruptedException, HiveWriter.WriteException
{    SimpleEvent event = new SimpleEvent();    for (int i = 1; i <= count; i++) {        event.setBody((i + ",xyz,Hello world,abc").getBytes());        writer.write(event);    }}
b5f12f7105f05e73a3216249160ff0da0a1a0df2922d3ab79faa3bfb17f05e11
setConfValues
public static void setConfValues(HiveConf conf)
{    conf.setVar(HiveConf.ConfVars.HIVE_TXN_MANAGER, txnMgr);    conf.setBoolVar(HiveConf.ConfVars.HIVE_SUPPORT_CONCURRENCY, true);    conf.set("fs.raw.impl", RawFileSystem.class.getName());}
fc2426a1f337a16d53d4aea10057fc7a02ed703a022dd73d93015a5166b72671
createDbAndTable
public static void createDbAndTable(Driver driver, String databaseName, String tableName, List<String> partVals, String[] colNames, String[] colTypes, String[] partNames, String dbLocation) throws Exception
{    String dbUri = "raw://" + dbLocation;    String tableLoc = dbUri + Path.SEPARATOR + tableName;    runDDL(driver, "create database IF NOT EXISTS " + databaseName + " location '" + dbUri + "'");    runDDL(driver, "use " + databaseName);    String crtTbl = "create table " + tableName + " ( " + getTableColumnsStr(colNames, colTypes) + " )" + getPartitionStmtStr(partNames) + " clustered by ( " + colNames[0] + " )" + " into 10 buckets " + " stored as orc " + " location '" + tableLoc + "'" + " TBLPROPERTIES ('transactional'='true')";    runDDL(driver, crtTbl);    System.out.println("crtTbl = " + crtTbl);    if (partNames != null && partNames.length != 0) {        String addPart = "alter table " + tableName + " add partition ( " + getTablePartsStr2(partNames, partVals) + " )";        runDDL(driver, addPart);    }}
8860eaacbe550353391e19a93a5d6942213b3b6777cc868e18affdb74406d4d2
getPartitionStmtStr
private static String getPartitionStmtStr(String[] partNames)
{    if (partNames == null || partNames.length == 0) {        return "";    }    return " partitioned by (" + getTablePartsStr(partNames) + " )";}
788743fce4acac63daecbe8a6ccb095ddf525e0588f69b08b01fda22f70f6e8c
dropDB
public static void dropDB(HiveConf conf, String databaseName) throws HiveException, MetaException
{    IMetaStoreClient client = new HiveMetaStoreClient(conf);    try {        for (String table : client.listTableNamesByFilter(databaseName, "", (short) -1)) {            client.dropTable(databaseName, table, true, true);        }        client.dropDatabase(databaseName);    } catch (TException e) {        client.close();    }}
c8039e6fa16f0ae3454ef86ca168b80570566cda7d13a4380860eaa35d8ec681
getTableColumnsStr
private static String getTableColumnsStr(String[] colNames, String[] colTypes)
{    StringBuffer sb = new StringBuffer();    for (int i = 0; i < colNames.length; ++i) {        sb.append(colNames[i] + " " + colTypes[i]);        if (i < colNames.length - 1) {            sb.append(",");        }    }    return sb.toString();}
c11e46befe2ef370e25c2b709c4d60feb0135e7ecb78f09601584e951fa845c8
getTablePartsStr
private static String getTablePartsStr(String[] partNames)
{    if (partNames == null || partNames.length == 0) {        return "";    }    StringBuffer sb = new StringBuffer();    for (int i = 0; i < partNames.length; ++i) {        sb.append(partNames[i] + " string");        if (i < partNames.length - 1) {            sb.append(",");        }    }    return sb.toString();}
6050075ff2dba45a0f4b924818adf021e63eb4b3936b135b47ff00ea7c73d71c
getTablePartsStr2
private static String getTablePartsStr2(String[] partNames, List<String> partVals)
{    StringBuffer sb = new StringBuffer();    for (int i = 0; i < partVals.size(); ++i) {        sb.append(partNames[i] + " = '" + partVals.get(i) + "'");        if (i < partVals.size() - 1) {            sb.append(",");        }    }    return sb.toString();}
4b68033c698f95b5ba1c2870b30dd8359e6a625c3ff6ae88ab71fb5083861a62
listRecordsInTable
public static ArrayList<String> listRecordsInTable(Driver driver, String dbName, String tblName) throws CommandNeedRetryException, IOException
{    driver.run("select * from " + dbName + "." + tblName);    ArrayList<String> res = new ArrayList<String>();    driver.getResults(res);    return res;}
6d17b57acb23f6b29e9895b6f633cf76427aaca408412146a5fd2eb43dd36015
listRecordsInPartition
public static ArrayList<String> listRecordsInPartition(Driver driver, String dbName, String tblName, String continent, String country) throws CommandNeedRetryException, IOException
{    driver.run("select * from " + dbName + "." + tblName + " where continent='" + continent + "' and country='" + country + "'");    ArrayList<String> res = new ArrayList<String>();    driver.getResults(res);    return res;}
4f32351934f6bb4372e27b1cbcd61023d7f2dbcd66e6c1cebbc891e10eed25f2
getUri
public URI getUri()
{    return NAME;}
c80a39961ab2e20b20f1ee52999aae50d192b845e9fbcfc2a734cf95a3820e48
execCommand
 static String execCommand(File f, String... cmd) throws IOException
{    String[] args = new String[cmd.length + 1];    System.arraycopy(cmd, 0, args, 0, cmd.length);    args[cmd.length] = f.getCanonicalPath();    String output = Shell.execCommand(args);    return output;}
3950acea2a621fb000096fbf74526c9af903b247dcaf1d7b80fe883e3ba6e079
getFileStatus
public FileStatus getFileStatus(Path path) throws IOException
{    File file = pathToFile(path);    if (!file.exists()) {        throw new FileNotFoundException("Can't find " + path);    }        short mod = 0;    if (file.canRead()) {        mod |= 0444;    }    if (file.canWrite()) {        mod |= 0200;    }    if (file.canExecute()) {        mod |= 0111;    }    ShimLoader.getHadoopShims();    return new FileStatus(file.length(), file.isDirectory(), 1, 1024, file.lastModified(), file.lastModified(), FsPermission.createImmutable(mod), "owen", "users", path);}
8ff7e3949ea7e22b7992e36f4b8c949410417f4caade06a2aa500342846bc058
runDDL
private static boolean runDDL(Driver driver, String sql) throws QueryFailedException
{        int retryCount = 1;    for (int attempt = 0; attempt <= retryCount; ++attempt) {        try {            driver.run(sql);            return true;        } catch (CommandNeedRetryException e) {            if (attempt == retryCount) {                throw new QueryFailedException(sql, e);            }            continue;        }    }        return false;}
8cee43233aa48f3caa5c3d5c2d01c8ba609faa00eb89137aa76d2b04d2049a3e
configure
public final void configure(final Context context)
{    String configuredEndpoint = context.getString("endpoint", "");    LOG.info("Read endpoint URL from configuration : " + configuredEndpoint);    try {        endpointUrl = new URL(configuredEndpoint);    } catch (MalformedURLException e) {        throw new IllegalArgumentException("Endpoint URL invalid", e);    }    connectTimeout = context.getInteger("connectTimeout", DEFAULT_CONNECT_TIMEOUT);    if (connectTimeout <= 0) {        throw new IllegalArgumentException("Connect timeout must be a non-zero and positive");    }    LOG.info("Using connect timeout : " + connectTimeout);    requestTimeout = context.getInteger("requestTimeout", DEFAULT_REQUEST_TIMEOUT);    if (requestTimeout <= 0) {        throw new IllegalArgumentException("Request timeout must be a non-zero and positive");    }    LOG.info("Using request timeout : " + requestTimeout);    acceptHeader = context.getString("acceptHeader", DEFAULT_ACCEPT_HEADER);    LOG.info("Using Accept header value : " + acceptHeader);    contentTypeHeader = context.getString("contentTypeHeader", DEFAULT_CONTENT_TYPE);    LOG.info("Using Content-Type header value : " + contentTypeHeader);    defaultBackoff = context.getBoolean("defaultBackoff", true);    LOG.info("Channel backoff by default is " + defaultBackoff);    defaultRollback = context.getBoolean("defaultRollback", true);    LOG.info("Transaction rollback by default is " + defaultRollback);    defaultIncrementMetrics = context.getBoolean("defaultIncrementMetrics", false);    LOG.info("Incrementing metrics by default is " + defaultIncrementMetrics);    parseConfigOverrides("backoff", context, backoffOverrides);    parseConfigOverrides("rollback", context, rollbackOverrides);    parseConfigOverrides("incrementMetrics", context, incrementMetricsOverrides);    if (this.sinkCounter == null) {        this.sinkCounter = new SinkCounter(this.getName());    }    connectionBuilder = new ConnectionBuilder();}
016bac278a8f60aec7a89722089f1c9f9f835485f6ec65fc52d0e84186d25458
start
public final void start()
{    LOG.info("Starting HttpSink");    sinkCounter.start();}
7c3b320cc88c40453e5586c90a070a8f2408bb0d1eb4f11393111d7b61a62e74
stop
public final void stop()
{    LOG.info("Stopping HttpSink");    sinkCounter.stop();}
fadb7dfc9de29459e62866a60df2094011dbb09338207031da3fb8d7ea746dc6
process
public final Status process() throws EventDeliveryException
{    Status status = null;    OutputStream outputStream = null;    Channel ch = getChannel();    Transaction txn = ch.getTransaction();    txn.begin();    try {        Event event = ch.take();        byte[] eventBody = null;        if (event != null) {            eventBody = event.getBody();        }        if (eventBody != null && eventBody.length > 0) {            sinkCounter.incrementEventDrainAttemptCount();            LOG.debug("Sending request : " + new String(event.getBody()));            try {                HttpURLConnection connection = connectionBuilder.getConnection();                outputStream = connection.getOutputStream();                outputStream.write(eventBody);                outputStream.flush();                outputStream.close();                int httpStatusCode = connection.getResponseCode();                LOG.debug("Got status code : " + httpStatusCode);                if (httpStatusCode < HttpURLConnection.HTTP_BAD_REQUEST) {                    connection.getInputStream().close();                } else {                    LOG.debug("bad request");                    connection.getErrorStream().close();                }                LOG.debug("Response processed and closed");                if (httpStatusCode >= HTTP_STATUS_CONTINUE) {                    String httpStatusString = String.valueOf(httpStatusCode);                    boolean shouldRollback = findOverrideValue(httpStatusString, rollbackOverrides, defaultRollback);                    if (shouldRollback) {                        txn.rollback();                    } else {                        txn.commit();                    }                    boolean shouldBackoff = findOverrideValue(httpStatusString, backoffOverrides, defaultBackoff);                    if (shouldBackoff) {                        status = Status.BACKOFF;                    } else {                        status = Status.READY;                    }                    boolean shouldIncrementMetrics = findOverrideValue(httpStatusString, incrementMetricsOverrides, defaultIncrementMetrics);                    if (shouldIncrementMetrics) {                        sinkCounter.incrementEventDrainSuccessCount();                    }                    if (shouldRollback) {                        if (shouldBackoff) {                            LOG.info(String.format("Got status code %d from HTTP server." + " Rolled back event and backed off.", httpStatusCode));                        } else {                            LOG.info(String.format("Got status code %d from HTTP server." + " Rolled back event for retry.", httpStatusCode));                        }                    }                } else {                    txn.rollback();                    status = Status.BACKOFF;                    LOG.warn("Malformed response returned from server, retrying");                }            } catch (IOException e) {                txn.rollback();                status = Status.BACKOFF;                LOG.error("Error opening connection, or request timed out", e);                sinkCounter.incrementEventWriteFail();            }        } else {            txn.commit();            status = Status.BACKOFF;            LOG.warn("Processed empty event");        }    } catch (Throwable t) {        txn.rollback();        status = Status.BACKOFF;        LOG.error("Error sending HTTP request, retrying", t);        sinkCounter.incrementEventWriteOrChannelFail(t);                if (t instanceof Error) {            throw (Error) t;        }    } finally {        txn.close();        if (outputStream != null) {            try {                outputStream.close();            } catch (IOException e) {                        }        }    }    return status;}
7345a285f0950477852af64393886e320f7fd188a6dc60c0b891737904f8df48
parseConfigOverrides
private void parseConfigOverrides(final String propertyName, final Context context, final Map<String, Boolean> override)
{    Map<String, String> config = context.getSubProperties(propertyName + ".");    if (config != null) {        for (Map.Entry<String, String> value : config.entrySet()) {            LOG.info(String.format("Read %s value for status code %s as %s", propertyName, value.getKey(), value.getValue()));            if (override.containsKey(value.getKey())) {                LOG.warn(String.format("Ignoring duplicate config value for %s.%s", propertyName, value.getKey()));            } else {                override.put(value.getKey(), Boolean.valueOf(value.getValue()));            }        }    }}
b4e2dba146261b838efe4ce4412de1ce637d2f023de6b29a0c94fd6af5110d17
findOverrideValue
private boolean findOverrideValue(final String statusCode, final HashMap<String, Boolean> overrides, final boolean defaultValue)
{    Boolean overrideValue = overrides.get(statusCode);    if (overrideValue == null) {        overrideValue = overrides.get(statusCode.substring(0, 1) + "XX");        if (overrideValue == null) {            overrideValue = defaultValue;        }    }    return overrideValue;}
81ce9da9389cb164a0b14f90e944ed574a213939f30487be07ebe6c244ef63f2
setConnectionBuilder
 final void setConnectionBuilder(final ConnectionBuilder builder)
{    this.connectionBuilder = builder;}
275e331a88538e009a76dd7ff52bbed468f0610817e1b42da52ffe0cc4f93d85
setSinkCounter
 final void setSinkCounter(final SinkCounter newSinkCounter)
{    this.sinkCounter = newSinkCounter;}
4012639c4236be4ac8ca0022c3546cc12f092013a153918907a32ee6fb52e760
getConnection
public HttpURLConnection getConnection() throws IOException
{    HttpURLConnection connection = (HttpURLConnection) endpointUrl.openConnection();    connection.setRequestMethod("POST");    connection.setRequestProperty("Content-Type", contentTypeHeader);    connection.setRequestProperty("Accept", acceptHeader);    connection.setConnectTimeout(connectTimeout);    connection.setReadTimeout(requestTimeout);    connection.setDoOutput(true);    connection.setDoInput(true);    connection.connect();    return connection;}
01eb894aa928f15a7ac91c0997baf20fbc1d0afedd66ae25ee334563fe943649
ensureAllConfigurationOptionsRead
public void ensureAllConfigurationOptionsRead()
{    whenDefaultStringConfig();    whenDefaultBooleanConfig();    when(configContext.getInteger(eq("connectTimeout"), Mockito.anyInt())).thenReturn(1000);    when(configContext.getInteger(eq("requestTimeout"), Mockito.anyInt())).thenReturn(1000);    new HttpSink().configure(configContext);    verify(configContext).getString("endpoint", "");    verify(configContext).getInteger(eq("connectTimeout"), Mockito.anyInt());    verify(configContext).getInteger(eq("requestTimeout"), Mockito.anyInt());    verify(configContext).getString(eq("acceptHeader"), Mockito.anyString());    verify(configContext).getString(eq("contentTypeHeader"), Mockito.anyString());    verify(configContext).getBoolean("defaultBackoff", true);    verify(configContext).getBoolean("defaultRollback", true);    verify(configContext).getBoolean("defaultIncrementMetrics", false);}
819f5f0fc82efe550f8ad2e04babf5125aa59b38139aeca5b0259b3defa223bc
ensureExceptionIfEndpointUrlEmpty
public void ensureExceptionIfEndpointUrlEmpty()
{    when(configContext.getString("endpoint", "")).thenReturn("");    new HttpSink().configure(configContext);}
5e9d0e80960136166a15464215d55d08ec227aac2891cc405c225ab139d5afee
ensureExceptionIfEndpointUrlInvalid
public void ensureExceptionIfEndpointUrlInvalid()
{    when(configContext.getString("endpoint", "")).thenReturn("invalid url");    new HttpSink().configure(configContext);}
0c2590973d33f959ad9e5bf723973b92a88e5b6d2244efba29807e57f0bdca6d
ensureExceptionIfConnectTimeoutNegative
public void ensureExceptionIfConnectTimeoutNegative()
{    whenDefaultStringConfig();    when(configContext.getInteger("connectTimeout", 1000)).thenReturn(-1000);    when(configContext.getInteger(eq("requestTimeout"), Mockito.anyInt())).thenReturn(1000);    new HttpSink().configure(configContext);}
49a15c83251b65f225c87527c5dfd83253e07248ef8f59ffe8ad007697255d9e
ensureDefaultConnectTimeoutCorrect
public void ensureDefaultConnectTimeoutCorrect()
{    whenDefaultStringConfig();    when(configContext.getInteger("connectTimeout", DEFAULT_CONNECT_TIMEOUT)).thenReturn(1000);    when(configContext.getInteger(eq("requestTimeout"), Mockito.anyInt())).thenReturn(1000);    new HttpSink().configure(configContext);    verify(configContext).getInteger("connectTimeout", DEFAULT_CONNECT_TIMEOUT);}
4254f060823919a25f91d39d4b90fd3590bf931b40a1df1000f6d57aa4bca47f
ensureExceptionIfRequestTimeoutNegative
public void ensureExceptionIfRequestTimeoutNegative()
{    whenDefaultStringConfig();    when(configContext.getInteger("requestTimeout", 1000)).thenReturn(-1000);    when(configContext.getInteger(eq("connectTimeout"), Mockito.anyInt())).thenReturn(1000);    new HttpSink().configure(configContext);}
8dc8f88de743567ea3f2c9fd0e7edc42008083db06ac1486c07c98adcfe8a8fd
ensureDefaultRequestTimeoutCorrect
public void ensureDefaultRequestTimeoutCorrect()
{    whenDefaultStringConfig();    when(configContext.getInteger("requestTimeout", DEFAULT_REQUEST_TIMEOUT)).thenReturn(1000);    when(configContext.getInteger(eq("connectTimeout"), Mockito.anyInt())).thenReturn(1000);    new HttpSink().configure(configContext);    verify(configContext).getInteger("requestTimeout", DEFAULT_REQUEST_TIMEOUT);}
8afbc6221b7d9b9914e08dfe2b73bc89c3f9347ee657ddbc02641b5830639b59
ensureDefaultAcceptHeaderCorrect
public void ensureDefaultAcceptHeaderCorrect()
{    whenDefaultTimeouts();    whenDefaultStringConfig();    new HttpSink().configure(configContext);    verify(configContext).getString("acceptHeader", DEFAULT_ACCEPT_HEADER);}
8273785769b0e2f7e233a8fd0143e4b00d9ff5c829142e4fcfc3c3b8606732b3
ensureDefaultContentTypeHeaderCorrect
public void ensureDefaultContentTypeHeaderCorrect()
{    whenDefaultTimeouts();    whenDefaultStringConfig();    new HttpSink().configure(configContext);    verify(configContext).getString("contentTypeHeader", DEFAULT_CONTENT_TYPE_HEADER);}
30d5d9034cdff48e85a1ee5815bada1bd9597386ce2253437f775c4dd26e0f57
ensureBackoffOnNullEvent
public void ensureBackoffOnNullEvent() throws Exception
{    when(channel.take()).thenReturn(null);    executeWithMocks(true);}
7e54a57259f4904d19aff489c0087caf26b28d0b11bea0de2ed9ca01790edaad
ensureBackoffOnNullEventBody
public void ensureBackoffOnNullEventBody() throws Exception
{    when(channel.take()).thenReturn(event);    when(event.getBody()).thenReturn(null);    executeWithMocks(true);}
dfbd32ff9eb61c06c42fc24e2eec642673bdc3d581a8b872018095a8f91bd6b1
ensureBackoffOnEmptyEvent
public void ensureBackoffOnEmptyEvent() throws Exception
{    when(channel.take()).thenReturn(event);    when(event.getBody()).thenReturn(new byte[] {});    executeWithMocks(true);}
29b026dccedfe8831c43db8607785ea39f3c9fef95bb5a4e99744ce30ce21892
ensureRollbackBackoffAndIncrementMetricsIfConfigured
public void ensureRollbackBackoffAndIncrementMetricsIfConfigured() throws Exception
{    when(channel.take()).thenReturn(event);    when(event.getBody()).thenReturn("something".getBytes());    Context context = new Context();    context.put("defaultRollback", "true");    context.put("defaultBackoff", "true");    context.put("defaultIncrementMetrics", "true");    executeWithMocks(false, Status.BACKOFF, true, true, context, HttpURLConnection.HTTP_OK);}
c256cdd320281ee17948977198301375a2988b1bb4ec3a715725672de302af33
ensureCommitReadyAndNoIncrementMetricsIfConfigured
public void ensureCommitReadyAndNoIncrementMetricsIfConfigured() throws Exception
{    when(channel.take()).thenReturn(event);    when(event.getBody()).thenReturn("something".getBytes());    Context context = new Context();    context.put("defaultRollback", "false");    context.put("defaultBackoff", "false");    context.put("defaultIncrementMetrics", "false");    executeWithMocks(true, Status.READY, false, false, context, HttpURLConnection.HTTP_OK);}
e429c56fecc8cad2c31f849bc5a350d94145ec20b7d90dbb20f1ee6a7f778fe3
ensureSingleStatusConfigurationCorrectlyUsed
public void ensureSingleStatusConfigurationCorrectlyUsed() throws Exception
{    when(channel.take()).thenReturn(event);    when(event.getBody()).thenReturn("something".getBytes());    Context context = new Context();    context.put("defaultRollback", "true");    context.put("defaultBackoff", "true");    context.put("defaultIncrementMetrics", "false");    context.put("rollback.200", "false");    context.put("backoff.200", "false");    context.put("incrementMetrics.200", "true");    executeWithMocks(true, Status.READY, true, true, context, HttpURLConnection.HTTP_OK);}
799d52b0b8f2228a73f8f5f35d6cec3937029922705a37d30db2fb4c43d8d744
testErrorCounter
public void testErrorCounter() throws Exception
{    RuntimeException exception = new RuntimeException("dummy");    when(channel.take()).thenThrow(exception);    Context context = new Context();    context.put("defaultRollback", "false");    context.put("defaultBackoff", "false");    context.put("defaultIncrementMetrics", "false");    executeWithMocks(false, Status.BACKOFF, false, false, context, HttpURLConnection.HTTP_OK);    inOrder(sinkCounter).verify(sinkCounter).incrementEventWriteOrChannelFail(exception);}
3d0d5716b54bee94a68606843c6270ec665c06db4edbc81bd2c62ac9c586044f
ensureSingleErrorStatusConfigurationCorrectlyUsed
public void ensureSingleErrorStatusConfigurationCorrectlyUsed() throws Exception
{    when(channel.take()).thenReturn(event);    when(event.getBody()).thenReturn("something".getBytes());    Context context = new Context();    context.put("defaultRollback", "true");    context.put("defaultBackoff", "true");    context.put("defaultIncrementMetrics", "false");    context.put("rollback.401", "false");    context.put("backoff.401", "false");    context.put("incrementMetrics.401", "false");    executeWithMocks(true, Status.READY, false, true, context, HttpURLConnection.HTTP_UNAUTHORIZED);}
54151a66bd6eb3777e99a18fc3904680269328e55793ec9851952713142d0df3
ensureGroupConfigurationCorrectlyUsed
public void ensureGroupConfigurationCorrectlyUsed() throws Exception
{    when(channel.take()).thenReturn(event);    when(event.getBody()).thenReturn("something".getBytes());    Context context = new Context();    context.put("defaultRollback", "true");    context.put("defaultBackoff", "true");    context.put("defaultIncrementMetrics", "false");    context.put("rollback.2XX", "false");    context.put("backoff.2XX", "false");    context.put("incrementMetrics.2XX", "true");    executeWithMocks(true, Status.READY, true, true, context, HttpURLConnection.HTTP_OK);    executeWithMocks(true, Status.READY, true, true, context, HttpURLConnection.HTTP_NO_CONTENT);}
ab2ac9dda3bcda6ca75e103ac462ef401bb6a9b0855d54c18ea7755e7a3ba2de
ensureSingleStatusConfigurationOverridesGroupConfigurationCorrectly
public void ensureSingleStatusConfigurationOverridesGroupConfigurationCorrectly() throws Exception
{    when(channel.take()).thenReturn(event);    when(event.getBody()).thenReturn("something".getBytes());    Context context = new Context();    context.put("rollback.2XX", "false");    context.put("backoff.2XX", "false");    context.put("incrementMetrics.2XX", "true");    context.put("rollback.200", "true");    context.put("backoff.200", "true");    context.put("incrementMetrics.200", "false");    executeWithMocks(true, Status.READY, true, true, context, HttpURLConnection.HTTP_NO_CONTENT);    executeWithMocks(false, Status.BACKOFF, false, true, context, HttpURLConnection.HTTP_OK);}
ae4e433d03e3a603d01a03e8c1c06ffe80d733186708536642d5b035d163a04d
executeWithMocks
private void executeWithMocks(boolean commit) throws Exception
{    Context context = new Context();    executeWithMocks(commit, Status.BACKOFF, false, false, context, HttpURLConnection.HTTP_OK);}
cd89c5b7e60785357d37d11044aeb33165304bb1da345f65b1e29a9d7a4ea687
executeWithMocks
private void executeWithMocks(boolean expectedCommit, Status expectedStatus, boolean expectedIncrementSuccessMetrics, boolean expectedIncrementAttemptMetrics, Context context, int httpStatus) throws Exception
{    context.put("endpoint", "http://localhost:8080/endpoint");    HttpSink httpSink = new HttpSink();    httpSink.configure(context);    httpSink.setConnectionBuilder(httpSink.new ConnectionBuilder() {        @Override        public HttpURLConnection getConnection() throws IOException {            return httpURLConnection;        }    });    httpSink.setChannel(channel);    httpSink.setSinkCounter(sinkCounter);    when(channel.getTransaction()).thenReturn(transaction);    when(httpURLConnection.getOutputStream()).thenReturn(outputStream);    when(httpURLConnection.getInputStream()).thenReturn(inputStream);    when(httpURLConnection.getErrorStream()).thenReturn(inputStream);    when(httpURLConnection.getResponseCode()).thenReturn(httpStatus);    Status actualStatus = httpSink.process();    assert (actualStatus == expectedStatus);    inOrder(transaction).verify(transaction).begin();    if (expectedIncrementAttemptMetrics) {        inOrder(sinkCounter).verify(sinkCounter).incrementEventDrainAttemptCount();    }    if (expectedCommit) {        inOrder(transaction).verify(transaction).commit();    } else {        inOrder(transaction).verify(transaction).rollback();    }    if (expectedIncrementSuccessMetrics) {        inOrder(sinkCounter).verify(sinkCounter).incrementEventDrainSuccessCount();    }    inOrder(transaction).verify(transaction).close();}
4012639c4236be4ac8ca0022c3546cc12f092013a153918907a32ee6fb52e760
getConnection
public HttpURLConnection getConnection() throws IOException
{    return httpURLConnection;}
5b6ed379418d54fc13f68028a7da58ae4ea4b0a29dceca6a9ebe4ce80bfa6369
whenDefaultStringConfig
private void whenDefaultStringConfig()
{    when(configContext.getString("endpoint", "")).thenReturn("http://test.abc/");    when(configContext.getString("acceptHeader", "")).thenReturn("test/accept");    when(configContext.getString("contentTypeHeader", "")).thenReturn("test/content");}
bb9ce93ab38f496eecaf8257499a78cf0ec1fc1a3ff4c89a513e36f2bb0cd123
whenDefaultBooleanConfig
private void whenDefaultBooleanConfig()
{    when(configContext.getBoolean("defaultBackoff", true)).thenReturn(true);    when(configContext.getBoolean("defaultRollback", true)).thenReturn(true);    when(configContext.getBoolean("defaultIncrementMetrics", false)).thenReturn(true);}
b583e99f25d8e1d6c74449058b4aece695d94fa5ab8d80bb8fadc4ac518f7e8d
whenDefaultTimeouts
private void whenDefaultTimeouts()
{    when(configContext.getInteger(eq("requestTimeout"), Mockito.anyInt())).thenReturn(1000);    when(configContext.getInteger(eq("connectTimeout"), Mockito.anyInt())).thenReturn(1000);}
fd732d77c28d2f0126136bb0740a277252ed1e44adce8be7baadbf50b18cca83
findFreePort
private static int findFreePort()
{    try (ServerSocket socket = new ServerSocket(0)) {        return socket.getLocalPort();    } catch (IOException e) {        throw new AssertionError("Can not find free port.", e);    }}
4f20c8fd4e000de9d8a5723f027dc30ca07d6d3e2c4e7185b8998738a44a0d41
setupSink
public void setupSink()
{    if (httpSink == null) {        Context httpSinkContext = new Context();        httpSinkContext.put("endpoint", "http://localhost:" + port + "/endpoint");        httpSinkContext.put("requestTimeout", "2000");        httpSinkContext.put("connectTimeout", "1500");        httpSinkContext.put("acceptHeader", "application/json");        httpSinkContext.put("contentTypeHeader", "application/json");        httpSinkContext.put("backoff.200", "false");        httpSinkContext.put("rollback.200", "false");        httpSinkContext.put("backoff.401", "false");        httpSinkContext.put("rollback.401", "false");        httpSinkContext.put("incrementMetrics.200", "true");        Context memoryChannelContext = new Context();        channel = new MemoryChannel();        channel.configure(memoryChannelContext);        channel.start();        httpSink = new HttpSink();        httpSink.configure(httpSinkContext);        httpSink.setChannel(channel);        httpSink.start();    }}
7954f3bbfb3f4fb776d5702e4d36aef88a81e6d82578a3e8ec9026eaa80cca7c
waitForShutdown
public void waitForShutdown() throws InterruptedException
{    httpSink.stop();    Thread.sleep(500);}
f5eed2601eb757a0a1cedf3db5c4eebecd6eee90efe9cfb5c5d4fef2963aa0e1
ensureSuccessfulMessageDelivery
public void ensureSuccessfulMessageDelivery() throws Exception
{    service.stubFor(post(urlEqualTo("/endpoint")).withRequestBody(equalToJson(event("SUCCESS"))).willReturn(aResponse().withStatus(200)));    addEventToChannel(event("SUCCESS"));    service.verify(1, postRequestedFor(urlEqualTo("/endpoint")).withRequestBody(equalToJson(event("SUCCESS"))));}
29a8d3db31212260930d67a620c5d13d1a0431e9aa998a5ade57208482b0960a
ensureEventsResentOn503Failure
public void ensureEventsResentOn503Failure() throws Exception
{    String errorScenario = "Error Scenario";    service.stubFor(post(urlEqualTo("/endpoint")).inScenario(errorScenario).whenScenarioStateIs(STARTED).withRequestBody(equalToJson(event("TRANSIENT_ERROR"))).willReturn(aResponse().withStatus(503)).willSetStateTo("Error Sent"));    service.stubFor(post(urlEqualTo("/endpoint")).inScenario(errorScenario).whenScenarioStateIs("Error Sent").withRequestBody(equalToJson(event("TRANSIENT_ERROR"))).willReturn(aResponse().withStatus(200)));    addEventToChannel(event("TRANSIENT_ERROR"), Status.BACKOFF);    addEventToChannel(event("TRANSIENT_ERROR"), Status.READY);    service.verify(2, postRequestedFor(urlEqualTo("/endpoint")).withRequestBody(equalToJson(event("TRANSIENT_ERROR"))));}
4ea1a1f5b2d5e8e5a5e15f84c8a0be1d0ef6a367dc03321b2ce97783af04afcd
ensureEventsNotResentOn401Failure
public void ensureEventsNotResentOn401Failure() throws Exception
{    String errorScenario = "Error skip scenario";    service.stubFor(post(urlEqualTo("/endpoint")).inScenario(errorScenario).whenScenarioStateIs(STARTED).withRequestBody(equalToJson(event("UNAUTHORIZED REQUEST"))).willReturn(aResponse().withStatus(401).withHeader("Content-Type", "text/plain").withBody("Not allowed!")).willSetStateTo("Error Sent"));    service.stubFor(post(urlEqualTo("/endpoint")).inScenario(errorScenario).whenScenarioStateIs("Error Sent").withRequestBody(equalToJson(event("NEXT EVENT"))).willReturn(aResponse().withStatus(200)));    addEventToChannel(event("UNAUTHORIZED REQUEST"), Status.READY);    addEventToChannel(event("NEXT EVENT"), Status.READY);    service.verify(1, postRequestedFor(urlEqualTo("/endpoint")).withRequestBody(equalToJson(event("UNAUTHORIZED REQUEST"))));    service.verify(1, postRequestedFor(urlEqualTo("/endpoint")).withRequestBody(equalToJson(event("NEXT EVENT"))));}
a7b14378d1088dc350e0753dc0baaf6d178b3bc3ccbe24ceeef355632867cf71
ensureEventsResentOnNetworkFailure
public void ensureEventsResentOnNetworkFailure() throws Exception
{    String errorScenario = "Error Scenario";    service.stubFor(post(urlEqualTo("/endpoint")).inScenario(errorScenario).whenScenarioStateIs(STARTED).withRequestBody(equalToJson(event("NETWORK_ERROR"))).willReturn(aResponse().withFault(Fault.RANDOM_DATA_THEN_CLOSE)).willSetStateTo("Error Sent"));    service.stubFor(post(urlEqualTo("/endpoint")).inScenario(errorScenario).whenScenarioStateIs("Error Sent").withRequestBody(equalToJson(event("NETWORK_ERROR"))).willReturn(aResponse().withStatus(200)));    addEventToChannel(event("NETWORK_ERROR"), Status.BACKOFF);    addEventToChannel(event("NETWORK_ERROR"), Status.READY);    service.verify(2, postRequestedFor(urlEqualTo("/endpoint")).withRequestBody(equalToJson(event("NETWORK_ERROR"))));}
6097e65f65eb0793278008d50116904483d8b86c07b9f257da3b66b0827b8371
ensureEventsResentOnConnectionTimeout
public void ensureEventsResentOnConnectionTimeout() throws Exception
{    final CountDownLatch firstRequestReceived = new CountDownLatch(1);    service.addSocketAcceptDelay(new RequestDelaySpec(CONNECT_TIMEOUT));    service.addMockServiceRequestListener(new RequestListener() {        @Override        public void requestReceived(Request request, Response response) {            service.addSocketAcceptDelay(new RequestDelaySpec(0));            firstRequestReceived.countDown();        }    });    service.stubFor(post(urlEqualTo("/endpoint")).withRequestBody(equalToJson(event("SLOW_SOCKET"))).willReturn(aResponse().withStatus(200)));    addEventToChannel(event("SLOW_SOCKET"), Status.BACKOFF);        firstRequestReceived.await(2000, TimeUnit.MILLISECONDS);    addEventToChannel(event("SLOW_SOCKET"), Status.READY);    service.verify(2, postRequestedFor(urlEqualTo("/endpoint")).withRequestBody(equalToJson(event("SLOW_SOCKET"))));}
dabc5413a54f7143a5e4eed679cbc4cfd64d016d55bcdbeb8f7b49cfed55fe3b
requestReceived
public void requestReceived(Request request, Response response)
{    service.addSocketAcceptDelay(new RequestDelaySpec(0));    firstRequestReceived.countDown();}
4b81f86c814d188a3a4f635307b9397c0635f3eab828a151f894ea61cd5da120
ensureEventsResentOnRequestTimeout
public void ensureEventsResentOnRequestTimeout() throws Exception
{    String errorScenario = "Error Scenario";    service.stubFor(post(urlEqualTo("/endpoint")).inScenario(errorScenario).whenScenarioStateIs(STARTED).withRequestBody(equalToJson(event("SLOW_RESPONSE"))).willReturn(aResponse().withFixedDelay(RESPONSE_TIMEOUT).withStatus(200)).willSetStateTo("Slow Response Sent"));    service.stubFor(post(urlEqualTo("/endpoint")).inScenario(errorScenario).whenScenarioStateIs("Slow Response Sent").withRequestBody(equalToJson(event("SLOW_RESPONSE"))).willReturn(aResponse().withStatus(200)));    addEventToChannel(event("SLOW_RESPONSE"), Status.BACKOFF);    addEventToChannel(event("SLOW_RESPONSE"), Status.READY);    service.verify(2, postRequestedFor(urlEqualTo("/endpoint")).withRequestBody(equalToJson(event("SLOW_RESPONSE"))));}
371109635aff0804182602a0ec6101a2c93b882d788489709fd5eef9f8225098
ensureHttpConnectionReusedForSuccessfulRequests
public void ensureHttpConnectionReusedForSuccessfulRequests() throws Exception
{        service.addSocketAcceptDelay(new RequestDelaySpec(1000));    service.stubFor(post(urlEqualTo("/endpoint")).withRequestBody(equalToJson(event("SUCCESS"))).willReturn(aResponse().withStatus(200)));    long startTime = System.currentTimeMillis();    addEventToChannel(event("SUCCESS"), Status.READY);    addEventToChannel(event("SUCCESS"), Status.READY);    addEventToChannel(event("SUCCESS"), Status.READY);    long endTime = System.currentTimeMillis();    assertTrue("Test should have completed faster", endTime - startTime < 2500);    service.verify(3, postRequestedFor(urlEqualTo("/endpoint")).withRequestBody(equalToJson(event("SUCCESS"))));}
913438d539f671c3ee888486d9f98c54fbda3ba0ea9e675d9e0a512114d9a834
addEventToChannel
private void addEventToChannel(String line) throws EventDeliveryException
{    addEventToChannel(line, Status.READY);}
05b0f1adbf0f61d9865995790ba8880193a634201cc13b021c658fd2cf19923b
addEventToChannel
private void addEventToChannel(String line, Status expectedStatus) throws EventDeliveryException
{    SimpleEvent event = new SimpleEvent();    event.setBody(line.getBytes());    Transaction channelTransaction = channel.getTransaction();    channelTransaction.begin();    channel.put(event);    channelTransaction.commit();    channelTransaction.close();    Sink.Status status = httpSink.process();    assertEquals(expectedStatus, status);}
ee5cc9c0d60e4d9827f8fd4521369310a90dec4ba751dce98de2235f495126c4
event
private String event(String id)
{    return "{'id':'" + id + "'}";}
961fc6f8fa5105e0d8bc85b75f7e850fa43e52cc099bec4664ee2d1a46c7750f
onRegistered
public void onRegistered()
{}
35e6aefb44cb4b7ba0f202eff4af0f013012e12d1c0b458ed00f5fd6e1966e23
onDisconnected
public void onDisconnected()
{    logger.error("IRC sink disconnected");}
e79e56a978c8a707f6be75efd64349904f431bebc2eaece8fc56ee74e01a2673
onError
public void onError(String msg)
{    logger.error("IRC sink error: {}", msg);}
350f6f2a62eef9502a07c9fc1ea90279854dfeacb01d336cf4f80ca736909673
onError
public void onError(int num, String msg)
{    logger.error("IRC sink error: {} - {}", num, msg);}
b886b573eb6db031c874327af25a79c8ee51a3fe3403473c8f9bead1f7471ec6
onInvite
public void onInvite(String chan, IRCUser u, String nickPass)
{}
c8102fc8c5a00f51ce3afeed3e4a12498259067a063fbdb1eac92900cb8b35e4
onJoin
public void onJoin(String chan, IRCUser u)
{}
342961813f555f3b902a0ff0825288b60a6b7ec931fd7f49c3bf15156d7eec98
onKick
public void onKick(String chan, IRCUser u, String nickPass, String msg)
{}
a650a525614f6d179ecfd0d49bd612759abeffd54c4410afcb49e1e7e61f7f4d
onMode
public void onMode(IRCUser u, String nickPass, String mode)
{}
ac79a2c7b65a75051ecae2e6bfcf71a35ea842a63dbcba3269efca70cf971b1d
onMode
public void onMode(String chan, IRCUser u, IRCModeParser mp)
{}
6dfca3115bdb5f7f9dc96b3ef46dddff9d1b0290e7a2a25fdc367727a8ab3784
onNick
public void onNick(IRCUser u, String nickNew)
{}
b9e3150b290014025982e6efafb0504bc1300f94340657cdb966de4bd5d682a4
onNotice
public void onNotice(String target, IRCUser u, String msg)
{}
a95b0b045fabc0d476a81bef55b79ac86b7c9cc39ff82e1df0f7381871848962
onPart
public void onPart(String chan, IRCUser u, String msg)
{}
e5ee64d959bf7a7b6442a51298334e22ffe4cda33d4437e39cb3c09821d058b9
onPrivmsg
public void onPrivmsg(String chan, IRCUser u, String msg)
{}
217c2c08afa6338d9d77459f0755245550f9a18f32858e169a16d53391e5eaba
onQuit
public void onQuit(IRCUser u, String msg)
{}
208486bb7f4fd1352131f876945402110c728556a6111df8700fb7bdabe518c2
onReply
public void onReply(int num, String value, String msg)
{}
ec4151f484d58249a42db6e6645614e25a567b31f3bd7aad55c674e4d346756c
onTopic
public void onTopic(String chan, IRCUser u, String topic)
{}
ba0c03d2f05c9a749374f40644517699b3c259e4505ce9eb278f443e787cb4a9
onPing
public void onPing(String p)
{}
641f2da075617d3c3dcee500587ea1d86e55216e11dd601225439eeafc8100cc
unknown
public void unknown(String a, String b, String c, String d)
{}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    hostname = context.getString("hostname");    String portStr = context.getString("port");    nick = context.getString("nick");    password = context.getString("password");    user = context.getString("user");    name = context.getString("name");    chan = context.getString("chan");    splitLines = context.getBoolean("splitlines", false);    splitChars = context.getString("splitchars");    if (portStr != null) {        port = Integer.parseInt(portStr);    } else {        port = DEFAULT_PORT;    }    if (splitChars == null) {        splitChars = DEFAULT_SPLIT_CHARS;    }    Preconditions.checkState(hostname != null, "No hostname specified");    Preconditions.checkState(nick != null, "No nick specified");    Preconditions.checkState(chan != null, "No chan specified");}
c1baef299b1b0a4372b755e15722aa28fa75ddb5a69d1853a36c3e31c563ddc8
createConnection
private void createConnection() throws IOException
{    if (connection == null) {        logger.debug("Creating new connection to hostname:{} port:{}", hostname, port);        connection = new IRCConnection(hostname, new int[] { port }, password, nick, user, name);        connection.addIRCEventListener(new IRCConnectionListener());        connection.setEncoding("UTF-8");        connection.setPong(true);        connection.setDaemon(false);        connection.setColors(false);        connection.connect();        connection.send("join " + IRC_CHANNEL_PREFIX + chan);    }}
eb60ae841c2d2082e59317db5dad2d34255a87ba153c6718320fafe5da2c84c7
destroyConnection
private void destroyConnection()
{    if (connection != null) {        logger.debug("Destroying connection to: {}:{}", hostname, port);        connection.close();    }    connection = null;}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    logger.info("IRC sink starting");    try {        createConnection();    } catch (Exception e) {        logger.error("Unable to create irc client using hostname:" + hostname + " port:" + port + ". Exception follows.", e);        /* Try to prevent leaking resources. */        destroyConnection();        /* FIXME: Mark ourselves as failed. */        return;    }    super.start();    logger.debug("IRC sink {} started", this.getName());}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    logger.info("IRC sink {} stopping", this.getName());    destroyConnection();    super.stop();    logger.debug("IRC sink {} stopped. Metrics:{}", this.getName(), counterGroup);}
a09552105e67bec20d9b00e0f4e143dd667732c7901d9e5921aa49eb9d46229b
sendLine
private void sendLine(Event event)
{    String body = new String(event.getBody());    if (splitLines) {        String[] lines = body.split(splitChars);        for (String line : lines) {            connection.doPrivmsg(IRC_CHANNEL_PREFIX + this.chan, line);        }    } else {        connection.doPrivmsg(IRC_CHANNEL_PREFIX + this.chan, body);    }}
e52e5e378330fd7f87ee30351bbfcec47b751fee12ece2ef0cfdd77a08c906e1
process
public Status process() throws EventDeliveryException
{    Status status = Status.READY;    Channel channel = getChannel();    Transaction transaction = channel.getTransaction();    try {        transaction.begin();        createConnection();        Event event = channel.take();        if (event == null) {            counterGroup.incrementAndGet("event.empty");            status = Status.BACKOFF;        } else {            sendLine(event);            counterGroup.incrementAndGet("event.irc");        }        transaction.commit();    } catch (ChannelException e) {        transaction.rollback();        logger.error("Unable to get event from channel. Exception follows.", e);        status = Status.BACKOFF;    } catch (Exception e) {        transaction.rollback();        logger.error("Unable to communicate with IRC server. Exception follows.", e);        status = Status.BACKOFF;        destroyConnection();    } finally {        transaction.close();    }    return status;}
4d072973845457c68e0bdcaf8605a63c4e82cee51aa51c4f7db0b2f7a2d3a532
findFreePort
private static int findFreePort() throws IOException
{    ServerSocket socket = new ServerSocket(0);    int port = socket.getLocalPort();    socket.close();    return port;}
c536957a0359efaba4fa041a9429ed02027b66c9e6f5cc21d07eb308cc675a0d
setUp
public void setUp() throws IOException
{    ircServerPort = findFreePort();    dumbIRCServer = new DumbIRCServer(ircServerPort);    dumbIRCServer.start();    eventFile = folder.newFile("eventFile.txt");}
c6aaebb5a52567751db8dc8e1cb9dd4a4e582ef964a374b376c6a04f741802dc
tearDown
public void tearDown() throws Exception
{    dumbIRCServer.shutdownServer();}
f8cbbc1c88e35a86fe1d421a22dc06613bd71f20c76f750e8e04b538a3dc1895
testIRCSinkMissingSplitLineProperty
public void testIRCSinkMissingSplitLineProperty()
{    Sink ircSink = new IRCSink();    ircSink.setName("IRC Sink - " + UUID.randomUUID().toString());    Context context = new Context();    context.put("hostname", "localhost");    context.put("port", String.valueOf(ircServerPort));    context.put("nick", "flume");    context.put("password", "flume");    context.put("user", "flume");    context.put("name", "flume-dev");    context.put("chan", "flume");    context.put("splitchars", "false");    Configurables.configure(ircSink, context);    Channel memoryChannel = new MemoryChannel();    Configurables.configure(memoryChannel, context);    ircSink.setChannel(memoryChannel);    ircSink.start();    Transaction txn = memoryChannel.getTransaction();    txn.begin();    Event event = EventBuilder.withBody("Dummy Event".getBytes());    memoryChannel.put(event);    txn.commit();    txn.close();    try {        Sink.Status status = ircSink.process();        if (status == Sink.Status.BACKOFF) {            fail("Error occured");        }    } catch (EventDeliveryException eDelExcp) {        }}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    try {        ss = new ServerSocket(port);        while (true) {            try {                Socket socket = ss.accept();                process(socket);            } catch (Exception ex) {            /* noop */            }        }    } catch (IOException e) {        }}
c7989d2eff3cc69c7cf149421aa340ff2acba3223db267c038efdb38da04d8bf
shutdownServer
public void shutdownServer() throws Exception
{    ss.close();}
f6e43debb480e97b85c8ad829b98db2234fb6515b1b023c3b2728a2af62617e8
process
private void process(Socket socket) throws IOException
{    FileOutputStream fileOutputStream = FileUtils.openOutputStream(eventFile);    List<String> input = IOUtils.readLines(socket.getInputStream());    for (String next : input) {        if (isPrivMessage(next)) {            fileOutputStream.write(next.getBytes());            fileOutputStream.write("\n".getBytes());        }    }    fileOutputStream.close();    socket.close();}
d8a0d76881f64aa09b62e52b94e3b3016bdbaf2b36101198db54dbb59dcd0f77
isPrivMessage
private boolean isPrivMessage(String input)
{    return input.startsWith("PRIVMSG");}
5f9b23bc5ae6eb12760d7dd24241d99648550a2c178884da756373802f82c953
createIndexRequest
public IndexRequestBuilder createIndexRequest(Client client, String indexPrefix, String indexType, Event event) throws IOException
{    IndexRequestBuilder request = prepareIndex(client);    String realIndexPrefix = BucketPath.escapeString(indexPrefix, event.getHeaders());    String realIndexType = BucketPath.escapeString(indexType, event.getHeaders());    TimestampedEvent timestampedEvent = new TimestampedEvent(event);    long timestamp = timestampedEvent.getTimestamp();    String indexName = getIndexName(realIndexPrefix, timestamp);    prepareIndexRequest(request, indexName, realIndexType, timestampedEvent);    return request;}
6f4fdc48cda66c4f383ddfee800ad5e9d8ca7305b71a5797d5cdefbe29d0bc42
prepareIndex
 IndexRequestBuilder prepareIndex(Client client)
{    return client.prepareIndex();}
39325522884485487417364539e6b8d74200b95857bc5e4c87292918e6d5047a
getIndexName
protected String getIndexName(String indexPrefix, long timestamp)
{    return new StringBuilder(indexPrefix).append('-').append(fastDateFormat.format(timestamp)).toString();}
37a280b924cddb6cc2ece062a1a6a8aebfe6c992718ef5809a26b25ed1b1de16
getClient
public ElasticSearchClient getClient(String clientType, String[] hostNames, String clusterName, ElasticSearchEventSerializer serializer, ElasticSearchIndexRequestBuilderFactory indexBuilder) throws NoSuchClientTypeException
{    if (clientType.equalsIgnoreCase(TransportClient) && serializer != null) {        return new ElasticSearchTransportClient(hostNames, clusterName, serializer);    } else if (clientType.equalsIgnoreCase(TransportClient) && indexBuilder != null) {        return new ElasticSearchTransportClient(hostNames, clusterName, indexBuilder);    } else if (clientType.equalsIgnoreCase(RestClient) && serializer != null) {        return new ElasticSearchRestClient(hostNames, serializer);    }    throw new NoSuchClientTypeException();}
7f0bce67dac152297415c4bf5e082cb22707f30bdc0624fa5ca5eedd528b9508
getLocalClient
public ElasticSearchClient getLocalClient(String clientType, ElasticSearchEventSerializer serializer, ElasticSearchIndexRequestBuilderFactory indexBuilder) throws NoSuchClientTypeException
{    if (clientType.equalsIgnoreCase(TransportClient) && serializer != null) {        return new ElasticSearchTransportClient(serializer);    } else if (clientType.equalsIgnoreCase(TransportClient) && indexBuilder != null) {        return new ElasticSearchTransportClient(indexBuilder);    } else if (clientType.equalsIgnoreCase(RestClient)) {    }    throw new NoSuchClientTypeException();}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{}
413ec90abec4e9e7d9eb3277d2d7dc038a0d00ade2e2d1912d9064664e949d95
addEvent
public void addEvent(Event event, IndexNameBuilder indexNameBuilder, String indexType, long ttlMs) throws Exception
{    BytesReference content = serializer.getContentBuilder(event).bytes();    Map<String, Map<String, String>> parameters = new HashMap<String, Map<String, String>>();    Map<String, String> indexParameters = new HashMap<String, String>();    indexParameters.put(INDEX_PARAM, indexNameBuilder.getIndexName(event));    indexParameters.put(TYPE_PARAM, indexType);    if (ttlMs > 0) {        indexParameters.put(TTL_PARAM, Long.toString(ttlMs));    }    parameters.put(INDEX_OPERATION_NAME, indexParameters);    Gson gson = new Gson();    synchronized (bulkBuilder) {        bulkBuilder.append(gson.toJson(parameters));        bulkBuilder.append("\n");        bulkBuilder.append(content.toBytesArray().toUtf8());        bulkBuilder.append("\n");    }}
9d5e0b02050961cf4b46ac6bbfd6a5f22a2bc79b8e2062cef94c42c38f8e1616
execute
public void execute() throws Exception
{    int statusCode = 0, triesCount = 0;    HttpResponse response = null;    String entity;    synchronized (bulkBuilder) {        entity = bulkBuilder.toString();        bulkBuilder = new StringBuilder();    }    while (statusCode != HttpStatus.SC_OK && triesCount < serversList.size()) {        triesCount++;        String host = serversList.get();        String url = host + "/" + BULK_ENDPOINT;        HttpPost httpRequest = new HttpPost(url);        httpRequest.setEntity(new StringEntity(entity));        response = httpClient.execute(httpRequest);        statusCode = response.getStatusLine().getStatusCode();        logger.info("Status code from elasticsearch: " + statusCode);        if (response.getEntity() != null) {            logger.debug("Status message from elasticsearch: " + EntityUtils.toString(response.getEntity(), "UTF-8"));        }    }    if (statusCode != HttpStatus.SC_OK) {        if (response.getEntity() != null) {            throw new EventDeliveryException(EntityUtils.toString(response.getEntity(), "UTF-8"));        } else {            throw new EventDeliveryException("Elasticsearch status code was: " + statusCode);        }    }}
ed2af56c1950bfbb5bbc8db8c314ee020fe56fc0ab9c6ce8731b5e3b0a795387
getServerAddresses
 InetSocketTransportAddress[] getServerAddresses()
{    return serverAddresses;}
aacbe5e53f0e3630bbe01f8b61b013ee4f49bf3fb756146408e5856169ee519d
setBulkRequestBuilder
 void setBulkRequestBuilder(BulkRequestBuilder bulkRequestBuilder)
{    this.bulkRequestBuilder = bulkRequestBuilder;}
127dfb184e77c53e212c25114d2079edb944615ba448fbad6104fc2b87bfa6f3
configureHostnames
private void configureHostnames(String[] hostNames)
{    logger.warn(Arrays.toString(hostNames));    serverAddresses = new InetSocketTransportAddress[hostNames.length];    for (int i = 0; i < hostNames.length; i++) {        String[] hostPort = hostNames[i].trim().split(":");        String host = hostPort[0].trim();        int port = hostPort.length == 2 ? Integer.parseInt(hostPort[1].trim()) : DEFAULT_PORT;        serverAddresses[i] = new InetSocketTransportAddress(host, port);    }}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{    if (client != null) {        client.close();    }    client = null;}
413ec90abec4e9e7d9eb3277d2d7dc038a0d00ade2e2d1912d9064664e949d95
addEvent
public void addEvent(Event event, IndexNameBuilder indexNameBuilder, String indexType, long ttlMs) throws Exception
{    if (bulkRequestBuilder == null) {        bulkRequestBuilder = client.prepareBulk();    }    IndexRequestBuilder indexRequestBuilder = null;    if (indexRequestBuilderFactory == null) {        indexRequestBuilder = client.prepareIndex(indexNameBuilder.getIndexName(event), indexType).setSource(serializer.getContentBuilder(event).bytes());    } else {        indexRequestBuilder = indexRequestBuilderFactory.createIndexRequest(client, indexNameBuilder.getIndexPrefix(event), indexType, event);    }    if (ttlMs > 0) {        indexRequestBuilder.setTTL(ttlMs);    }    bulkRequestBuilder.add(indexRequestBuilder);}
9d5e0b02050961cf4b46ac6bbfd6a5f22a2bc79b8e2062cef94c42c38f8e1616
execute
public void execute() throws Exception
{    try {        BulkResponse bulkResponse = bulkRequestBuilder.execute().actionGet();        if (bulkResponse.hasFailures()) {            throw new EventDeliveryException(bulkResponse.buildFailureMessage());        }    } finally {        bulkRequestBuilder = client.prepareBulk();    }}
718dd163102f5a177e2b8b80d59173ef940f8683a4d7018bf591ddd8325064df
openClient
private void openClient(String clusterName)
{    logger.info("Using ElasticSearch hostnames: {} ", Arrays.toString(serverAddresses));    Settings settings = ImmutableSettings.settingsBuilder().put("cluster.name", clusterName).build();    TransportClient transportClient = new TransportClient(settings);    for (InetSocketTransportAddress host : serverAddresses) {        transportClient.addTransportAddress(host);    }    if (client != null) {        client.close();    }    client = transportClient;}
b1602384c3c9b3f107fffc8f37d2fe66ebfce6dd10b7544b78b9aa5f795eac88
openLocalDiscoveryClient
private void openLocalDiscoveryClient()
{    logger.info("Using ElasticSearch AutoDiscovery mode");    Node node = NodeBuilder.nodeBuilder().client(true).local(true).node();    if (client != null) {        client.close();    }    client = node.client();}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{}
0fa51e39e20e011dae03d3ffc42f2666c96f249a3616cfec11e86127b8293a77
get
public synchronized T get()
{    if (iterator.hasNext()) {        return iterator.next();    } else {        iterator = elements.iterator();        return iterator.next();    }}
72ef1e59027007ffe0950edfd2670ad03bb65cd6463d5d1d282dfeb1750435b0
size
public int size()
{    return elements.size();}
196e977794c5f8124f6d5479a1439d554a7deef3a9291075d3d60f5b77b047c2
appendField
public static void appendField(XContentBuilder builder, String field, byte[] data) throws IOException
{    XContentType contentType = XContentFactory.xContentType(data);    if (contentType == null) {        addSimpleField(builder, field, data);    } else {        addComplexField(builder, field, contentType, data);    }}
8a656c5ec18c9a958e288af124524bb201837a371700c4b66d219fc56d2d57d6
addSimpleField
public static void addSimpleField(XContentBuilder builder, String fieldName, byte[] data) throws IOException
{    builder.field(fieldName, new String(data, charset));}
0e53d84f7e30ff1c37d5668ea4393f3585d54bb0238add56b2f757dce2ba9930
addComplexField
public static void addComplexField(XContentBuilder builder, String fieldName, XContentType contentType, byte[] data) throws IOException
{    XContentParser parser = null;    try {                                                                parser = XContentFactory.xContent(contentType).createParser(data);        while (parser.nextToken() != null) {        }        ;                parser = XContentFactory.xContent(contentType).createParser(data);                builder.field(fieldName);                builder.copyCurrentStructure(parser);    } catch (JsonParseException ex) {                                addSimpleField(builder, fieldName, data);    } finally {        if (parser != null) {            parser.close();        }    }}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{}
57746d8a7acafcf5647f649109937334de6090302f29c32ed7da0df311700e35
configure
public void configure(ComponentConfiguration conf)
{}
106ac8240f1ae0b74c6d494e1ede202bac860f78106d637755ef4c472fe4ec85
getContentBuilder
public XContentBuilder getContentBuilder(Event event) throws IOException
{    XContentBuilder builder = jsonBuilder().startObject();    appendBody(builder, event);    appendHeaders(builder, event);    return builder;}
a04b36dafafe8cfdc2a73c921ae8757fbd2111a24d0691094ddd4cbdbe818352
appendBody
private void appendBody(XContentBuilder builder, Event event) throws IOException
{    ContentBuilderUtil.appendField(builder, "body", event.getBody());}
a2a30542361f3087c6ce1b8efa5b8ce56311376e019b01f7692570d165ffff6e
appendHeaders
private void appendHeaders(XContentBuilder builder, Event event) throws IOException
{    Map<String, String> headers = event.getHeaders();    for (String key : headers.keySet()) {        ContentBuilderUtil.appendField(builder, key, headers.get(key).getBytes(charset));    }}
106ac8240f1ae0b74c6d494e1ede202bac860f78106d637755ef4c472fe4ec85
getContentBuilder
public XContentBuilder getContentBuilder(Event event) throws IOException
{    XContentBuilder builder = jsonBuilder().startObject();    appendBody(builder, event);    appendHeaders(builder, event);    return builder;}
133398ff3a948efe3c5f40bc15f8328a00c66a91beb5ec422e2f73cbd88fac4a
appendBody
private void appendBody(XContentBuilder builder, Event event) throws IOException, UnsupportedEncodingException
{    byte[] body = event.getBody();    ContentBuilderUtil.appendField(builder, "@message", body);}
a2a30542361f3087c6ce1b8efa5b8ce56311376e019b01f7692570d165ffff6e
appendHeaders
private void appendHeaders(XContentBuilder builder, Event event) throws IOException
{    Map<String, String> headers = Maps.newHashMap(event.getHeaders());    String timestamp = headers.get("timestamp");    if (!StringUtils.isBlank(timestamp) && StringUtils.isBlank(headers.get("@timestamp"))) {        long timestampMs = Long.parseLong(timestamp);        builder.field("@timestamp", new Date(timestampMs));    }    String source = headers.get("source");    if (!StringUtils.isBlank(source) && StringUtils.isBlank(headers.get("@source"))) {        ContentBuilderUtil.appendField(builder, "@source", source.getBytes(charset));    }    String type = headers.get("type");    if (!StringUtils.isBlank(type) && StringUtils.isBlank(headers.get("@type"))) {        ContentBuilderUtil.appendField(builder, "@type", type.getBytes(charset));    }    String host = headers.get("host");    if (!StringUtils.isBlank(host) && StringUtils.isBlank(headers.get("@source_host"))) {        ContentBuilderUtil.appendField(builder, "@source_host", host.getBytes(charset));    }    String srcPath = headers.get("src_path");    if (!StringUtils.isBlank(srcPath) && StringUtils.isBlank(headers.get("@source_path"))) {        ContentBuilderUtil.appendField(builder, "@source_path", srcPath.getBytes(charset));    }    builder.startObject("@fields");    for (String key : headers.keySet()) {        byte[] val = headers.get(key).getBytes(charset);        ContentBuilderUtil.appendField(builder, key, val);    }    builder.endObject();}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{}
57746d8a7acafcf5647f649109937334de6090302f29c32ed7da0df311700e35
configure
public void configure(ComponentConfiguration conf)
{}
3127580cb8b8d8043d553dc8326f48a380e0efcd10de8b7b45f540f3e892a55f
getServerAddresses
 String[] getServerAddresses()
{    return serverAddresses;}
ecd68755c6f007989026e4172827c7defe793822ab1d8a2f570752ea3434950d
getClusterName
 String getClusterName()
{    return clusterName;}
5085c90ac3e38a7ad23d7a9cdff759f08850c63fc7fd6531928daa31e10311cb
getIndexName
 String getIndexName()
{    return indexName;}
33f3b145881ce7b1346b28e8d9a983287f2a493cd51860e401e387ce1c38f8e2
getIndexType
 String getIndexType()
{    return indexType;}
db5677cf5136173fee3c3db449bbe4619d04bcf2eda109ed4c7a78e9ba390526
getTTLMs
 long getTTLMs()
{    return ttlMs;}
4675f1f6bd757c7ace10e2cd4b70b6526599a2beef3d803224834b3e91fb9ad0
getEventSerializer
 ElasticSearchEventSerializer getEventSerializer()
{    return eventSerializer;}
e020ec77e6a3db5ced1751c66e27b6c2b5e0d2d1c9121426dab8cd76ac26e21b
getIndexNameBuilder
 IndexNameBuilder getIndexNameBuilder()
{    return indexNameBuilder;}
dcc511f35190533c2d6fcc6073d66b12e111f5004c64ff08ccc3609a06ab844d
getBatchSize
public long getBatchSize()
{    return batchSize;}
e52e5e378330fd7f87ee30351bbfcec47b751fee12ece2ef0cfdd77a08c906e1
process
public Status process() throws EventDeliveryException
{    logger.debug("processing...");    Status status = Status.READY;    Channel channel = getChannel();    Transaction txn = channel.getTransaction();    try {        txn.begin();        int count;        for (count = 0; count < batchSize; ++count) {            Event event = channel.take();            if (event == null) {                break;            }            String realIndexType = BucketPath.escapeString(indexType, event.getHeaders());            client.addEvent(event, indexNameBuilder, realIndexType, ttlMs);        }        if (count <= 0) {            sinkCounter.incrementBatchEmptyCount();            counterGroup.incrementAndGet("channel.underflow");            status = Status.BACKOFF;        } else {            if (count < batchSize) {                sinkCounter.incrementBatchUnderflowCount();                status = Status.BACKOFF;            } else {                sinkCounter.incrementBatchCompleteCount();            }            sinkCounter.addToEventDrainAttemptCount(count);            client.execute();        }        txn.commit();        sinkCounter.addToEventDrainSuccessCount(count);        counterGroup.incrementAndGet("transaction.success");    } catch (Throwable ex) {        try {            txn.rollback();            counterGroup.incrementAndGet("transaction.rollback");        } catch (Exception ex2) {            logger.error("Exception in rollback. Rollback might not have been successful.", ex2);        }        if (ex instanceof Error || ex instanceof RuntimeException) {            logger.error("Failed to commit transaction. Transaction rolled back.", ex);            Throwables.propagate(ex);        } else {            logger.error("Failed to commit transaction. Transaction rolled back.", ex);            throw new EventDeliveryException("Failed to commit transaction. Transaction rolled back.", ex);        }    } finally {        txn.close();    }    return status;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    if (!isLocal) {        if (StringUtils.isNotBlank(context.getString(HOSTNAMES))) {            serverAddresses = StringUtils.deleteWhitespace(context.getString(HOSTNAMES)).split(",");        }        Preconditions.checkState(serverAddresses != null && serverAddresses.length > 0, "Missing Param:" + HOSTNAMES);    }    if (StringUtils.isNotBlank(context.getString(INDEX_NAME))) {        this.indexName = context.getString(INDEX_NAME);    }    if (StringUtils.isNotBlank(context.getString(INDEX_TYPE))) {        this.indexType = context.getString(INDEX_TYPE);    }    if (StringUtils.isNotBlank(context.getString(CLUSTER_NAME))) {        this.clusterName = context.getString(CLUSTER_NAME);    }    if (StringUtils.isNotBlank(context.getString(BATCH_SIZE))) {        this.batchSize = Integer.parseInt(context.getString(BATCH_SIZE));    }    if (StringUtils.isNotBlank(context.getString(TTL))) {        this.ttlMs = parseTTL(context.getString(TTL));        Preconditions.checkState(ttlMs > 0, TTL + " must be greater than 0 or not set.");    }    if (StringUtils.isNotBlank(context.getString(CLIENT_TYPE))) {        clientType = context.getString(CLIENT_TYPE);    }    elasticSearchClientContext = new Context();    elasticSearchClientContext.putAll(context.getSubProperties(CLIENT_PREFIX));    String serializerClazz = DEFAULT_SERIALIZER_CLASS;    if (StringUtils.isNotBlank(context.getString(SERIALIZER))) {        serializerClazz = context.getString(SERIALIZER);    }    Context serializerContext = new Context();    serializerContext.putAll(context.getSubProperties(SERIALIZER_PREFIX));    try {        @SuppressWarnings("unchecked")        Class<? extends Configurable> clazz = (Class<? extends Configurable>) Class.forName(serializerClazz);        Configurable serializer = clazz.newInstance();        if (serializer instanceof ElasticSearchIndexRequestBuilderFactory) {            indexRequestFactory = (ElasticSearchIndexRequestBuilderFactory) serializer;            indexRequestFactory.configure(serializerContext);        } else if (serializer instanceof ElasticSearchEventSerializer) {            eventSerializer = (ElasticSearchEventSerializer) serializer;            eventSerializer.configure(serializerContext);        } else {            throw new IllegalArgumentException(serializerClazz + " is not an ElasticSearchEventSerializer");        }    } catch (Exception e) {        logger.error("Could not instantiate event serializer.", e);        Throwables.propagate(e);    }    if (sinkCounter == null) {        sinkCounter = new SinkCounter(getName());    }    String indexNameBuilderClass = DEFAULT_INDEX_NAME_BUILDER_CLASS;    if (StringUtils.isNotBlank(context.getString(INDEX_NAME_BUILDER))) {        indexNameBuilderClass = context.getString(INDEX_NAME_BUILDER);    }    Context indexnameBuilderContext = new Context();    serializerContext.putAll(context.getSubProperties(INDEX_NAME_BUILDER_PREFIX));    try {        @SuppressWarnings("unchecked")        Class<? extends IndexNameBuilder> clazz = (Class<? extends IndexNameBuilder>) Class.forName(indexNameBuilderClass);        indexNameBuilder = clazz.newInstance();        indexnameBuilderContext.put(INDEX_NAME, indexName);        indexNameBuilder.configure(indexnameBuilderContext);    } catch (Exception e) {        logger.error("Could not instantiate index name builder.", e);        Throwables.propagate(e);    }    if (sinkCounter == null) {        sinkCounter = new SinkCounter(getName());    }    Preconditions.checkState(StringUtils.isNotBlank(indexName), "Missing Param:" + INDEX_NAME);    Preconditions.checkState(StringUtils.isNotBlank(indexType), "Missing Param:" + INDEX_TYPE);    Preconditions.checkState(StringUtils.isNotBlank(clusterName), "Missing Param:" + CLUSTER_NAME);    Preconditions.checkState(batchSize >= 1, BATCH_SIZE + " must be greater than 0");}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    ElasticSearchClientFactory clientFactory = new ElasticSearchClientFactory();    logger.info("ElasticSearch sink {} started");    sinkCounter.start();    try {        if (isLocal) {            client = clientFactory.getLocalClient(clientType, eventSerializer, indexRequestFactory);        } else {            client = clientFactory.getClient(clientType, serverAddresses, clusterName, eventSerializer, indexRequestFactory);            client.configure(elasticSearchClientContext);        }        sinkCounter.incrementConnectionCreatedCount();    } catch (Exception ex) {        ex.printStackTrace();        sinkCounter.incrementConnectionFailedCount();        if (client != null) {            client.close();            sinkCounter.incrementConnectionClosedCount();        }    }    super.start();}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    logger.info("ElasticSearch sink {} stopping");    if (client != null) {        client.close();    }    sinkCounter.incrementConnectionClosedCount();    sinkCounter.stop();    super.stop();}
dddc0ed495a1790b946738fc798266751c34ddf4b36c3f56885bf299302687a6
parseTTL
private long parseTTL(String ttl)
{    matcher = matcher.reset(ttl);    while (matcher.find()) {        if (matcher.group(2).equals("ms")) {            return Long.parseLong(matcher.group(1));        } else if (matcher.group(2).equals("s")) {            return TimeUnit.SECONDS.toMillis(Integer.parseInt(matcher.group(1)));        } else if (matcher.group(2).equals("m")) {            return TimeUnit.MINUTES.toMillis(Integer.parseInt(matcher.group(1)));        } else if (matcher.group(2).equals("h")) {            return TimeUnit.HOURS.toMillis(Integer.parseInt(matcher.group(1)));        } else if (matcher.group(2).equals("d")) {            return TimeUnit.DAYS.toMillis(Integer.parseInt(matcher.group(1)));        } else if (matcher.group(2).equals("w")) {            return TimeUnit.DAYS.toMillis(7 * Integer.parseInt(matcher.group(1)));        } else if (matcher.group(2).equals("")) {            logger.info("TTL qualifier is empty. Defaulting to day qualifier.");            return TimeUnit.DAYS.toMillis(Integer.parseInt(matcher.group(1)));        } else {            logger.debug("Unknown TTL qualifier provided. Setting TTL to 0.");            return 0;        }    }    logger.info("TTL not provided. Skipping the TTL config by returning 0.");    return 0;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    serializer.configure(context);}
6e177f7da3a9d152f22b4db9c19686ff985a9d06778c1d360540ded68bec4314
configure
public void configure(ComponentConfiguration config)
{    serializer.configure(config);}
e7f5809c279ec938be28820ee389cf315701d5781bd2864823688bf933e195a8
prepareIndexRequest
protected void prepareIndexRequest(IndexRequestBuilder indexRequest, String indexName, String indexType, Event event) throws IOException
{    BytesStream contentBuilder = serializer.getContentBuilder(event);    indexRequest.setIndex(indexName).setType(indexType).setSource(contentBuilder.bytes());}
9144d4107a2482ec0178ed8ac3f9273244c20f91397e2acddf3ec80563a1ffe6
getIndexName
public String getIndexName(Event event)
{    return BucketPath.escapeString(indexName, event.getHeaders());}
ed233f2389e8e05ccd563b74ef705f3f3db0b842cc3a2877742fc2d53de8b65c
getIndexPrefix
public String getIndexPrefix(Event event)
{    return BucketPath.escapeString(indexName, event.getHeaders());}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    indexName = context.getString(ElasticSearchSinkConstants.INDEX_NAME);}
57746d8a7acafcf5647f649109937334de6090302f29c32ed7da0df311700e35
configure
public void configure(ComponentConfiguration conf)
{}
8a4dca0802dcf90f49edbe29c8aa978be23115b30f8be0a3afe82700819bd8b2
getFastDateFormat
 FastDateFormat getFastDateFormat()
{    return fastDateFormat;}
9144d4107a2482ec0178ed8ac3f9273244c20f91397e2acddf3ec80563a1ffe6
getIndexName
public String getIndexName(Event event)
{    TimestampedEvent timestampedEvent = new TimestampedEvent(event);    long timestamp = timestampedEvent.getTimestamp();    String realIndexPrefix = BucketPath.escapeString(indexPrefix, event.getHeaders());    return new StringBuilder(realIndexPrefix).append('-').append(fastDateFormat.format(timestamp)).toString();}
ed233f2389e8e05ccd563b74ef705f3f3db0b842cc3a2877742fc2d53de8b65c
getIndexPrefix
public String getIndexPrefix(Event event)
{    return BucketPath.escapeString(indexPrefix, event.getHeaders());}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    String dateFormatString = context.getString(DATE_FORMAT);    String timeZoneString = context.getString(TIME_ZONE);    if (StringUtils.isBlank(dateFormatString)) {        dateFormatString = DEFAULT_DATE_FORMAT;    }    if (StringUtils.isBlank(timeZoneString)) {        timeZoneString = DEFAULT_TIME_ZONE;    }    fastDateFormat = FastDateFormat.getInstance(dateFormatString, TimeZone.getTimeZone(timeZoneString));    indexPrefix = context.getString(ElasticSearchSinkConstants.INDEX_NAME);}
57746d8a7acafcf5647f649109937334de6090302f29c32ed7da0df311700e35
configure
public void configure(ComponentConfiguration conf)
{}
dce8365b0751cce97cf57faf360727c0d4495c7faa65cac31829b0c744169ed2
getTimestamp
 long getTimestamp()
{    return timestamp;}
9f5c1319f646525f1ab6dd43bb8182d5263d95b09ebde9644d59a88ef00c14de
initDefaults
 void initDefaults()
{    parameters = Maps.newHashMap();    parameters.put(INDEX_NAME, DEFAULT_INDEX_NAME);    parameters.put(INDEX_TYPE, DEFAULT_INDEX_TYPE);    parameters.put(CLUSTER_NAME, DEFAULT_CLUSTER_NAME);    parameters.put(BATCH_SIZE, "1");    parameters.put(TTL, "5");    timestampedIndexName = DEFAULT_INDEX_NAME + '-' + ElasticSearchIndexRequestBuilderFactory.df.format(FIXED_TIME_MILLIS);}
df4fac4d09e72e4b2666f93c5958af784222e55fd13a47e05f95fd2da97b8744
createNodes
 void createNodes() throws Exception
{    Settings settings = ImmutableSettings.settingsBuilder().put("number_of_shards", 1).put("number_of_replicas", 0).put("routing.hash.type", "simple").put("gateway.type", "none").put("path.data", "target/es-test").build();    node = NodeBuilder.nodeBuilder().settings(settings).local(true).node();    client = node.client();    client.admin().cluster().prepareHealth().setWaitForGreenStatus().execute().actionGet();}
3ed2be98ca359676bf49f5df600614d6b0c944d019a23d7e79d1d05edb9bbee5
shutdownNodes
 void shutdownNodes() throws Exception
{    ((InternalNode) node).injector().getInstance(Gateway.class).reset();    client.close();    node.close();}
b5346228de2e45995d887f7b34cc01222a1b3b6964d1bf6b886741801a215c7f
setFixedJodaTime
public void setFixedJodaTime()
{    DateTimeUtils.setCurrentMillisFixed(FIXED_TIME_MILLIS);}
0d4d95237df40183e29ba29cdc3c9e9707011dbacd85bb333faaea0db901ac60
resetJodaTime
public void resetJodaTime()
{    DateTimeUtils.setCurrentMillisSystem();}
cd32f24fe05fa16adcba5af88f4acb6e31adfc6536b1f3f3097fe3e852c28c34
bindAndStartChannel
 Channel bindAndStartChannel(ElasticSearchSink fixture)
{        Channel channel = new MemoryChannel();    Configurables.configure(channel, new Context());        fixture.setChannel(channel);    fixture.start();    return channel;}
cee6680d0aad6c19aa78864a375ac0a48bb62121b3ab78ea06d2e60fb7947b93
assertMatchAllQuery
 void assertMatchAllQuery(int expectedHits, Event... events)
{    assertSearch(expectedHits, performSearch(QueryBuilders.matchAllQuery()), null, events);}
1147c4a31c57acbc757b8ef0de3ae816f476b5e53e8f15fd59bef963e1b6d5e2
assertBodyQuery
 void assertBodyQuery(int expectedHits, Event... events)
{        assertSearch(expectedHits, performSearch(QueryBuilders.fieldQuery("@message", "event")), null, events);}
e4381b7202c5896b7362840483ef3d7753691b891742b331329b88ac2a6940a8
performSearch
 SearchResponse performSearch(QueryBuilder query)
{    return client.prepareSearch(timestampedIndexName).setTypes(DEFAULT_INDEX_TYPE).setQuery(query).execute().actionGet();}
15f0932a42b1dfdeeaa6f848a76edc98a4ea16663c1627b227d6a4c061adc752
assertSearch
 void assertSearch(int expectedHits, SearchResponse response, Map<String, Object> expectedBody, Event... events)
{    SearchHits hitResponse = response.getHits();    assertEquals(expectedHits, hitResponse.getTotalHits());    SearchHit[] hits = hitResponse.getHits();    Arrays.sort(hits, new Comparator<SearchHit>() {        @Override        public int compare(SearchHit o1, SearchHit o2) {            return o1.getSourceAsString().compareTo(o2.getSourceAsString());        }    });    for (int i = 0; i < events.length; i++) {        Event event = events[i];        SearchHit hit = hits[i];        Map<String, Object> source = hit.getSource();        if (expectedBody == null) {            assertEquals(new String(event.getBody()), source.get("@message"));        } else {            assertEquals(expectedBody, source.get("@message"));        }    }}
7e491230f138e3334f00d183afb866b1e0513e85917fdebfaec34f6e0dca37ea
compare
public int compare(SearchHit o1, SearchHit o2)
{    return o1.getSourceAsString().compareTo(o2.getSourceAsString());}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    fixture = new RoundRobinList<String>(Arrays.asList("test1", "test2"));}
3a8aebd5a715b452bce3ac0ea669ce3e0021fdab4afd4244620e35c00327a4f1
shouldReturnNextElement
public void shouldReturnNextElement()
{    assertEquals("test1", fixture.get());    assertEquals("test2", fixture.get());    assertEquals("test1", fixture.get());    assertEquals("test2", fixture.get());    assertEquals("test1", fixture.get());}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    initMocks(this);    factory = new ElasticSearchClientFactory();}
611977272fe2c5504e147efbf841ea13cbb815242c3d81c3676eb4580ea7fb36
shouldReturnTransportClient
public void shouldReturnTransportClient() throws Exception
{    String[] hostNames = { "127.0.0.1" };    Object o = factory.getClient(ElasticSearchClientFactory.TransportClient, hostNames, "test", serializer, null);    assertThat(o, instanceOf(ElasticSearchTransportClient.class));}
c748d5667326c0365640c1d157645d1d65e4b39478cb1bf8767983af5dd027e6
shouldReturnRestClient
public void shouldReturnRestClient() throws NoSuchClientTypeException
{    String[] hostNames = { "127.0.0.1" };    Object o = factory.getClient(ElasticSearchClientFactory.RestClient, hostNames, "test", serializer, null);    assertThat(o, instanceOf(ElasticSearchRestClient.class));}
90a3d1dc71245d247307d800da1941c732120e34a2ae615537bebaf5965b0025
shouldThrowNoSuchClientTypeException
public void shouldThrowNoSuchClientTypeException() throws NoSuchClientTypeException
{    String[] hostNames = { "127.0.0.1" };    factory.getClient("not_existing_client", hostNames, "test", null, null);}
c536957a0359efaba4fa041a9429ed02027b66c9e6f5cc21d07eb308cc675a0d
setUp
public void setUp() throws IOException
{    initMocks(this);    BytesReference bytesReference = mock(BytesReference.class);    BytesStream bytesStream = mock(BytesStream.class);    when(nameBuilder.getIndexName(any(Event.class))).thenReturn(INDEX_NAME);    when(bytesReference.toBytesArray()).thenReturn(new BytesArray(MESSAGE_CONTENT));    when(bytesStream.bytes()).thenReturn(bytesReference);    when(serializer.getContentBuilder(any(Event.class))).thenReturn(bytesStream);    fixture = new ElasticSearchRestClient(HOSTS, serializer, httpClient);}
5f39581ecdf6f2467fa513a54a9a97653d85e25213a69e375523903bf238bdc1
shouldAddNewEventWithoutTTL
public void shouldAddNewEventWithoutTTL() throws Exception
{    ArgumentCaptor<HttpPost> argument = ArgumentCaptor.forClass(HttpPost.class);    when(httpStatus.getStatusCode()).thenReturn(HttpStatus.SC_OK);    when(httpResponse.getStatusLine()).thenReturn(httpStatus);    when(httpClient.execute(any(HttpUriRequest.class))).thenReturn(httpResponse);    fixture.addEvent(event, nameBuilder, "bar_type", -1);    fixture.execute();    verify(httpClient).execute(isA(HttpUriRequest.class));    verify(httpClient).execute(argument.capture());    assertEquals("http://host1/_bulk", argument.getValue().getURI().toString());    assertTrue(verifyJsonEvents("{\"index\":{\"_type\":\"bar_type\", \"_index\":\"foo_index\"}}\n", MESSAGE_CONTENT, EntityUtils.toString(argument.getValue().getEntity())));}
03e90590a0f1ce413fcde112cac18df441e7e111b3a1f8b5f3840404a0806e32
shouldAddNewEventWithTTL
public void shouldAddNewEventWithTTL() throws Exception
{    ArgumentCaptor<HttpPost> argument = ArgumentCaptor.forClass(HttpPost.class);    when(httpStatus.getStatusCode()).thenReturn(HttpStatus.SC_OK);    when(httpResponse.getStatusLine()).thenReturn(httpStatus);    when(httpClient.execute(any(HttpUriRequest.class))).thenReturn(httpResponse);    fixture.addEvent(event, nameBuilder, "bar_type", 123);    fixture.execute();    verify(httpClient).execute(isA(HttpUriRequest.class));    verify(httpClient).execute(argument.capture());    assertEquals("http://host1/_bulk", argument.getValue().getURI().toString());    assertTrue(verifyJsonEvents("{\"index\":{\"_type\":\"bar_type\",\"_index\":\"foo_index\",\"_ttl\":\"123\"}}\n", MESSAGE_CONTENT, EntityUtils.toString(argument.getValue().getEntity())));}
601abcee6b3a04f37d1e80e66222afb74355cb2f2bba8f88cf2358db00d3c3ba
verifyJsonEvents
private boolean verifyJsonEvents(String expectedIndex, String expectedBody, String actual)
{    Iterator<String> it = Splitter.on("\n").split(actual).iterator();    JsonParser parser = new JsonParser();    JsonObject[] arr = new JsonObject[2];    for (int i = 0; i < 2; i++) {        arr[i] = (JsonObject) parser.parse(it.next());    }    return arr[0].equals(parser.parse(expectedIndex)) && arr[1].equals(parser.parse(expectedBody));}
8311ce9cc94e5b9dea41517b7fa9e70aa1d76b1a2d4be255712165f53690c2f1
shouldThrowEventDeliveryException
public void shouldThrowEventDeliveryException() throws Exception
{    ArgumentCaptor<HttpPost> argument = ArgumentCaptor.forClass(HttpPost.class);    when(httpStatus.getStatusCode()).thenReturn(HttpStatus.SC_INTERNAL_SERVER_ERROR);    when(httpResponse.getStatusLine()).thenReturn(httpStatus);    when(httpClient.execute(any(HttpUriRequest.class))).thenReturn(httpResponse);    fixture.addEvent(event, nameBuilder, "bar_type", 123);    fixture.execute();}
25681d0d9b4c9ac1cd1869629165fb371d385c9bb2f6bc979cbfcbfb170d03b6
shouldRetryBulkOperation
public void shouldRetryBulkOperation() throws Exception
{    ArgumentCaptor<HttpPost> argument = ArgumentCaptor.forClass(HttpPost.class);    when(httpStatus.getStatusCode()).thenReturn(HttpStatus.SC_INTERNAL_SERVER_ERROR, HttpStatus.SC_OK);    when(httpResponse.getStatusLine()).thenReturn(httpStatus);    when(httpClient.execute(any(HttpUriRequest.class))).thenReturn(httpResponse);    fixture.addEvent(event, nameBuilder, "bar_type", 123);    fixture.execute();    verify(httpClient, times(2)).execute(isA(HttpUriRequest.class));    verify(httpClient, times(2)).execute(argument.capture());    List<HttpPost> allValues = argument.getAllValues();    assertEquals("http://host1/_bulk", allValues.get(0).getURI().toString());    assertEquals("http://host2/_bulk", allValues.get(1).getURI().toString());}
c536957a0359efaba4fa041a9429ed02027b66c9e6f5cc21d07eb308cc675a0d
setUp
public void setUp() throws IOException
{    initMocks(this);    BytesReference bytesReference = mock(BytesReference.class);    BytesStream bytesStream = mock(BytesStream.class);    when(nameBuilder.getIndexName(any(Event.class))).thenReturn("foo_index");    when(bytesReference.toBytes()).thenReturn("{\"body\":\"test\"}".getBytes());    when(bytesStream.bytes()).thenReturn(bytesReference);    when(serializer.getContentBuilder(any(Event.class))).thenReturn(bytesStream);    when(elasticSearchClient.prepareIndex(anyString(), anyString())).thenReturn(indexRequestBuilder);    when(indexRequestBuilder.setSource(bytesReference)).thenReturn(indexRequestBuilder);    fixture = new ElasticSearchTransportClient(elasticSearchClient, serializer);    fixture.setBulkRequestBuilder(bulkRequestBuilder);}
5f39581ecdf6f2467fa513a54a9a97653d85e25213a69e375523903bf238bdc1
shouldAddNewEventWithoutTTL
public void shouldAddNewEventWithoutTTL() throws Exception
{    fixture.addEvent(event, nameBuilder, "bar_type", -1);    verify(indexRequestBuilder).setSource(serializer.getContentBuilder(event).bytes());    verify(bulkRequestBuilder).add(indexRequestBuilder);}
03e90590a0f1ce413fcde112cac18df441e7e111b3a1f8b5f3840404a0806e32
shouldAddNewEventWithTTL
public void shouldAddNewEventWithTTL() throws Exception
{    fixture.addEvent(event, nameBuilder, "bar_type", 10);    verify(indexRequestBuilder).setTTL(10);    verify(indexRequestBuilder).setSource(serializer.getContentBuilder(event).bytes());}
f121807319d5c0edc00c1783cd765f139c004fda8f4eda8a2acb8a82e076cabc
shouldExecuteBulkRequestBuilder
public void shouldExecuteBulkRequestBuilder() throws Exception
{    ListenableActionFuture<BulkResponse> action = (ListenableActionFuture<BulkResponse>) mock(ListenableActionFuture.class);    BulkResponse response = mock(BulkResponse.class);    when(bulkRequestBuilder.execute()).thenReturn(action);    when(action.actionGet()).thenReturn(response);    when(response.hasFailures()).thenReturn(false);    fixture.addEvent(event, nameBuilder, "bar_type", 10);    fixture.execute();    verify(bulkRequestBuilder).execute();}
5313053604753ae0cc22b2b810b2aaa2013c6efb985c6bbb9bb9d65d8a39378a
shouldThrowExceptionOnExecuteFailed
public void shouldThrowExceptionOnExecuteFailed() throws Exception
{    ListenableActionFuture<BulkResponse> action = (ListenableActionFuture<BulkResponse>) mock(ListenableActionFuture.class);    BulkResponse response = mock(BulkResponse.class);    when(bulkRequestBuilder.execute()).thenReturn(action);    when(action.actionGet()).thenReturn(response);    when(response.hasFailures()).thenReturn(true);    fixture.addEvent(event, nameBuilder, "bar_type", 10);    fixture.execute();}
175ca2a6df96dc2306a34b227ceecd2fcb6d585f5455132898d34515f7fd6e2c
testRoundTrip
public void testRoundTrip() throws Exception
{    ElasticSearchDynamicSerializer fixture = new ElasticSearchDynamicSerializer();    Context context = new Context();    fixture.configure(context);    String message = "test body";    Map<String, String> headers = Maps.newHashMap();    headers.put("headerNameOne", "headerValueOne");    headers.put("headerNameTwo", "headerValueTwo");    headers.put("headerNameThree", "headerValueThree");    Event event = EventBuilder.withBody(message.getBytes(charset));    event.setHeaders(headers);    XContentBuilder expected = jsonBuilder().startObject();    expected.field("body", new String(message.getBytes(), charset));    for (String headerName : headers.keySet()) {        expected.field(headerName, new String(headers.get(headerName).getBytes(), charset));    }    expected.endObject();    XContentBuilder actual = fixture.getContentBuilder(event);    assertEquals(new String(expected.bytes().array()), new String(actual.bytes().array()));}
a35b5301e3b9653a5bf05666c9f180686759ab680c78a1f045f295f59236af26
setupFactory
public void setupFactory() throws Exception
{    serializer = new FakeEventSerializer();    factory = new EventSerializerIndexRequestBuilderFactory(serializer) {        @Override        IndexRequestBuilder prepareIndex(Client client) {            return new IndexRequestBuilder(FAKE_CLIENT);        }    };}
6f4fdc48cda66c4f383ddfee800ad5e9d8ca7305b71a5797d5cdefbe29d0bc42
prepareIndex
 IndexRequestBuilder prepareIndex(Client client)
{    return new IndexRequestBuilder(FAKE_CLIENT);}
74614ef384956e0866bad341327949f5be7e8de551673a80dfd3f24e063f4318
shouldUseUtcAsBasisForDateFormat
public void shouldUseUtcAsBasisForDateFormat()
{    assertEquals("Coordinated Universal Time", factory.fastDateFormat.getTimeZone().getDisplayName());}
812a5953df9262097465b502ed8eff79f3c82cada545f96f78eb309cde0ecda7
indexNameShouldBePrefixDashFormattedTimestamp
public void indexNameShouldBePrefixDashFormattedTimestamp()
{    long millis = 987654321L;    assertEquals("prefix-" + factory.fastDateFormat.format(millis), factory.getIndexName("prefix", millis));}
0e86e450739fee4847b9837e8186ed388dfeca8a3c347712a01d19356f80aa62
shouldEnsureTimestampHeaderPresentInTimestampedEvent
public void shouldEnsureTimestampHeaderPresentInTimestampedEvent()
{    SimpleEvent base = new SimpleEvent();    TimestampedEvent timestampedEvent = new TimestampedEvent(base);    assertEquals(FIXED_TIME_MILLIS, timestampedEvent.getTimestamp());    assertEquals(String.valueOf(FIXED_TIME_MILLIS), timestampedEvent.getHeaders().get("timestamp"));}
769fa416b74c3ae53a04ea50e29ae8adec7e3c8c5a965fcaa0411dde3e7e5bb6
shouldUseExistingTimestampHeaderInTimestampedEvent
public void shouldUseExistingTimestampHeaderInTimestampedEvent()
{    SimpleEvent base = new SimpleEvent();    Map<String, String> headersWithTimestamp = Maps.newHashMap();    headersWithTimestamp.put("timestamp", "-321");    base.setHeaders(headersWithTimestamp);    TimestampedEvent timestampedEvent = new TimestampedEvent(base);    assertEquals(-321L, timestampedEvent.getTimestamp());    assertEquals("-321", timestampedEvent.getHeaders().get("timestamp"));}
b20b9f7f1f2c1747ebfb9962dd78ac8309af3bdc766bb2fb0580539f01701cd3
shouldUseExistingAtTimestampHeaderInTimestampedEvent
public void shouldUseExistingAtTimestampHeaderInTimestampedEvent()
{    SimpleEvent base = new SimpleEvent();    Map<String, String> headersWithTimestamp = Maps.newHashMap();    headersWithTimestamp.put("@timestamp", "-999");    base.setHeaders(headersWithTimestamp);    TimestampedEvent timestampedEvent = new TimestampedEvent(base);    assertEquals(-999L, timestampedEvent.getTimestamp());    assertEquals("-999", timestampedEvent.getHeaders().get("@timestamp"));    assertNull(timestampedEvent.getHeaders().get("timestamp"));}
bc39ba8b3d4316b1e1bb5ca061f71feb6f6627c24889c7781ef4984981504b7b
shouldPreserveBodyAndNonTimestampHeadersInTimestampedEvent
public void shouldPreserveBodyAndNonTimestampHeadersInTimestampedEvent()
{    SimpleEvent base = new SimpleEvent();    base.setBody(new byte[] { 1, 2, 3, 4 });    Map<String, String> headersWithTimestamp = Maps.newHashMap();    headersWithTimestamp.put("foo", "bar");    base.setHeaders(headersWithTimestamp);    TimestampedEvent timestampedEvent = new TimestampedEvent(base);    assertEquals("bar", timestampedEvent.getHeaders().get("foo"));    assertArrayEquals(base.getBody(), timestampedEvent.getBody());}
800a86826da62d42a24b0a13c14ae19d9b65f97f73106f6b61f842bf67b8237c
shouldSetIndexNameTypeAndSerializedEventIntoIndexRequest
public void shouldSetIndexNameTypeAndSerializedEventIntoIndexRequest() throws Exception
{    String indexPrefix = "qwerty";    String indexType = "uiop";    Event event = new SimpleEvent();    IndexRequestBuilder indexRequestBuilder = factory.createIndexRequest(FAKE_CLIENT, indexPrefix, indexType, event);    assertEquals(indexPrefix + '-' + ElasticSearchIndexRequestBuilderFactory.df.format(FIXED_TIME_MILLIS), indexRequestBuilder.request().index());    assertEquals(indexType, indexRequestBuilder.request().type());    assertArrayEquals(FakeEventSerializer.FAKE_BYTES, indexRequestBuilder.request().source().array());}
65126bb543ed50cb0f9603fb7552d09d80650a72b34034c8b7dee137a1ff787f
shouldSetIndexNameFromTimestampHeaderWhenPresent
public void shouldSetIndexNameFromTimestampHeaderWhenPresent() throws Exception
{    String indexPrefix = "qwerty";    String indexType = "uiop";    Event event = new SimpleEvent();    event.getHeaders().put("timestamp", "1213141516");    IndexRequestBuilder indexRequestBuilder = factory.createIndexRequest(null, indexPrefix, indexType, event);    assertEquals(indexPrefix + '-' + ElasticSearchIndexRequestBuilderFactory.df.format(1213141516L), indexRequestBuilder.request().index());}
f16939915c439f86f973148fb0d4f6d085b8b2929dae957075ef5d40500330f3
shouldSetIndexNameTypeFromHeaderWhenPresent
public void shouldSetIndexNameTypeFromHeaderWhenPresent() throws Exception
{    String indexPrefix = "%{index-name}";    String indexType = "%{index-type}";    String indexValue = "testing-index-name-from-headers";    String typeValue = "testing-index-type-from-headers";    Event event = new SimpleEvent();    event.getHeaders().put("index-name", indexValue);    event.getHeaders().put("index-type", typeValue);    IndexRequestBuilder indexRequestBuilder = factory.createIndexRequest(null, indexPrefix, indexType, event);    assertEquals(indexValue + '-' + ElasticSearchIndexRequestBuilderFactory.df.format(FIXED_TIME_MILLIS), indexRequestBuilder.request().index());    assertEquals(typeValue, indexRequestBuilder.request().type());}
db3784e42bd46cfd325cdc88e834ba74de64b6cfca5445a92307b25d8d44dc2d
shouldConfigureEventSerializer
public void shouldConfigureEventSerializer() throws Exception
{    assertFalse(serializer.configuredWithContext);    factory.configure(new Context());    assertTrue(serializer.configuredWithContext);    assertFalse(serializer.configuredWithComponentConfiguration);    factory.configure(new SinkConfiguration("name"));    assertTrue(serializer.configuredWithComponentConfiguration);}
1ac45d8d3700b449a1614146c5fb11cafc42ed1884f8eaa4e7ccb50d5093d21a
getContentBuilder
public BytesStream getContentBuilder(Event event) throws IOException
{    FastByteArrayOutputStream fbaos = new FastByteArrayOutputStream(4);    fbaos.write(FAKE_BYTES);    return fbaos;}
831ce21591a09012662aaaae570affb5cfbdae1d467406cdc38950e2a861d04d
configure
public void configure(Context arg0)
{    configuredWithContext = true;}
b57d480d9330fd6fb8eac29a211d75065be50a1d7f03db360104d53193808642
configure
public void configure(ComponentConfiguration arg0)
{    configuredWithComponentConfiguration = true;}
175ca2a6df96dc2306a34b227ceecd2fcb6d585f5455132898d34515f7fd6e2c
testRoundTrip
public void testRoundTrip() throws Exception
{    ElasticSearchLogStashEventSerializer fixture = new ElasticSearchLogStashEventSerializer();    Context context = new Context();    fixture.configure(context);    String message = "test body";    Map<String, String> headers = Maps.newHashMap();    long timestamp = System.currentTimeMillis();    headers.put("timestamp", String.valueOf(timestamp));    headers.put("source", "flume_tail_src");    headers.put("host", "test@localhost");    headers.put("src_path", "/tmp/test");    headers.put("headerNameOne", "headerValueOne");    headers.put("headerNameTwo", "headerValueTwo");    headers.put("type", "sometype");    Event event = EventBuilder.withBody(message.getBytes(charset));    event.setHeaders(headers);    XContentBuilder expected = jsonBuilder().startObject();    expected.field("@message", new String(message.getBytes(), charset));    expected.field("@timestamp", new Date(timestamp));    expected.field("@source", "flume_tail_src");    expected.field("@type", "sometype");    expected.field("@source_host", "test@localhost");    expected.field("@source_path", "/tmp/test");    expected.startObject("@fields");    expected.field("timestamp", String.valueOf(timestamp));    expected.field("src_path", "/tmp/test");    expected.field("host", "test@localhost");    expected.field("headerNameTwo", "headerValueTwo");    expected.field("source", "flume_tail_src");    expected.field("headerNameOne", "headerValueOne");    expected.field("type", "sometype");    expected.endObject();    expected.endObject();    XContentBuilder actual = fixture.getContentBuilder(event);    JsonParser parser = new JsonParser();    assertEquals(parser.parse(expected.string()), parser.parse(actual.string()));}
ed9515d7bf5026225dcdc6db0f7248f7fcad8a1a1f0192f9aeaa9221dfb3073c
shouldHandleInvalidJSONDuringComplexParsing
public void shouldHandleInvalidJSONDuringComplexParsing() throws Exception
{    ElasticSearchLogStashEventSerializer fixture = new ElasticSearchLogStashEventSerializer();    Context context = new Context();    fixture.configure(context);    String message = "{flume: somethingnotvalid}";    Map<String, String> headers = Maps.newHashMap();    long timestamp = System.currentTimeMillis();    headers.put("timestamp", String.valueOf(timestamp));    headers.put("source", "flume_tail_src");    headers.put("host", "test@localhost");    headers.put("src_path", "/tmp/test");    headers.put("headerNameOne", "headerValueOne");    headers.put("headerNameTwo", "headerValueTwo");    headers.put("type", "sometype");    Event event = EventBuilder.withBody(message.getBytes(charset));    event.setHeaders(headers);    XContentBuilder expected = jsonBuilder().startObject();    expected.field("@message", new String(message.getBytes(), charset));    expected.field("@timestamp", new Date(timestamp));    expected.field("@source", "flume_tail_src");    expected.field("@type", "sometype");    expected.field("@source_host", "test@localhost");    expected.field("@source_path", "/tmp/test");    expected.startObject("@fields");    expected.field("timestamp", String.valueOf(timestamp));    expected.field("src_path", "/tmp/test");    expected.field("host", "test@localhost");    expected.field("headerNameTwo", "headerValueTwo");    expected.field("source", "flume_tail_src");    expected.field("headerNameOne", "headerValueOne");    expected.field("type", "sometype");    expected.endObject();    expected.endObject();    XContentBuilder actual = fixture.getContentBuilder(event);    JsonParser parser = new JsonParser();    assertEquals(parser.parse(expected.string()), parser.parse(actual.string()));}
1359225215853f3f89f4af5641e298ce821f026f91f6d3bc4f753adf82ab1c74
init
public void init() throws Exception
{    initDefaults();    createNodes();    fixture = new ElasticSearchSink(true);    fixture.setName("ElasticSearchSink-" + UUID.randomUUID().toString());}
c6aaebb5a52567751db8dc8e1cb9dd4a4e582ef964a374b376c6a04f741802dc
tearDown
public void tearDown() throws Exception
{    shutdownNodes();}
332d0bbf0f17ef330d6d9a83640f4c2cf4255ca1120b2818e219bec84418ccff
shouldIndexOneEvent
public void shouldIndexOneEvent() throws Exception
{    Configurables.configure(fixture, new Context(parameters));    Channel channel = bindAndStartChannel(fixture);    Transaction tx = channel.getTransaction();    tx.begin();    Event event = EventBuilder.withBody("event #1 or 1".getBytes());    channel.put(event);    tx.commit();    tx.close();    fixture.process();    fixture.stop();    client.admin().indices().refresh(Requests.refreshRequest(timestampedIndexName)).actionGet();    assertMatchAllQuery(1, event);    assertBodyQuery(1, event);}
1537e66b30d739b585ef971aaea687429c64e5a37316d474334327dc5185cf42
shouldIndexInvalidComplexJsonBody
public void shouldIndexInvalidComplexJsonBody() throws Exception
{    parameters.put(BATCH_SIZE, "3");    Configurables.configure(fixture, new Context(parameters));    Channel channel = bindAndStartChannel(fixture);    Transaction tx = channel.getTransaction();    tx.begin();    Event event1 = EventBuilder.withBody("TEST1 {test}".getBytes());    channel.put(event1);    Event event2 = EventBuilder.withBody("{test: TEST2 }".getBytes());    channel.put(event2);    Event event3 = EventBuilder.withBody("{\"test\":{ TEST3 {test} }}".getBytes());    channel.put(event3);    tx.commit();    tx.close();    fixture.process();    fixture.stop();    client.admin().indices().refresh(Requests.refreshRequest(timestampedIndexName)).actionGet();    assertMatchAllQuery(3);    assertSearch(1, performSearch(QueryBuilders.fieldQuery("@message", "TEST1")), null, event1);    assertSearch(1, performSearch(QueryBuilders.fieldQuery("@message", "TEST2")), null, event2);    assertSearch(1, performSearch(QueryBuilders.fieldQuery("@message", "TEST3")), null, event3);}
7f86eec39cc25f5b5803603374c3591573da81f62134aebf5245dd27d17668aa
shouldIndexComplexJsonEvent
public void shouldIndexComplexJsonEvent() throws Exception
{    Configurables.configure(fixture, new Context(parameters));    Channel channel = bindAndStartChannel(fixture);    Transaction tx = channel.getTransaction();    tx.begin();    Event event = EventBuilder.withBody("{\"event\":\"json content\",\"num\":1}".getBytes());    channel.put(event);    tx.commit();    tx.close();    fixture.process();    fixture.stop();    client.admin().indices().refresh(Requests.refreshRequest(timestampedIndexName)).actionGet();    Map<String, Object> expectedBody = new HashMap<String, Object>();    expectedBody.put("event", "json content");    expectedBody.put("num", 1);    assertSearch(1, performSearch(QueryBuilders.matchAllQuery()), expectedBody, event);    assertSearch(1, performSearch(QueryBuilders.fieldQuery("@message.event", "json")), expectedBody, event);}
b8a13ae688db6b7aade775f653538377d481dc05f8c355554f4f9263720ee5be
shouldIndexFiveEvents
public void shouldIndexFiveEvents() throws Exception
{        parameters.put(BATCH_SIZE, "5");    Configurables.configure(fixture, new Context(parameters));    Channel channel = bindAndStartChannel(fixture);    int numberOfEvents = 5;    Event[] events = new Event[numberOfEvents];    Transaction tx = channel.getTransaction();    tx.begin();    for (int i = 0; i < numberOfEvents; i++) {        String body = "event #" + i + " of " + numberOfEvents;        Event event = EventBuilder.withBody(body.getBytes());        events[i] = event;        channel.put(event);    }    tx.commit();    tx.close();    fixture.process();    fixture.stop();    client.admin().indices().refresh(Requests.refreshRequest(timestampedIndexName)).actionGet();    assertMatchAllQuery(numberOfEvents, events);    assertBodyQuery(5, events);}
ac29f5201f1c4bf309a57aaf3db386de040908efa4e8b382bf9b0449a832fc1c
shouldIndexFiveEventsOverThreeBatches
public void shouldIndexFiveEventsOverThreeBatches() throws Exception
{    parameters.put(BATCH_SIZE, "2");    Configurables.configure(fixture, new Context(parameters));    Channel channel = bindAndStartChannel(fixture);    int numberOfEvents = 5;    Event[] events = new Event[numberOfEvents];    Transaction tx = channel.getTransaction();    tx.begin();    for (int i = 0; i < numberOfEvents; i++) {        String body = "event #" + i + " of " + numberOfEvents;        Event event = EventBuilder.withBody(body.getBytes());        events[i] = event;        channel.put(event);    }    tx.commit();    tx.close();    int count = 0;    Status status = Status.READY;    while (status != Status.BACKOFF) {        count++;        status = fixture.process();    }    fixture.stop();    assertEquals(3, count);    client.admin().indices().refresh(Requests.refreshRequest(timestampedIndexName)).actionGet();    assertMatchAllQuery(numberOfEvents, events);    assertBodyQuery(5, events);}
bad52ab520cc309c99168be79ccdf263f8e1cd31b8751eae568ce242d4243315
shouldParseConfiguration
public void shouldParseConfiguration()
{    parameters.put(HOSTNAMES, "10.5.5.27");    parameters.put(CLUSTER_NAME, "testing-cluster-name");    parameters.put(INDEX_NAME, "testing-index-name");    parameters.put(INDEX_TYPE, "testing-index-type");    parameters.put(TTL, "10");    fixture = new ElasticSearchSink();    fixture.configure(new Context(parameters));    String[] expected = { "10.5.5.27" };    assertEquals("testing-cluster-name", fixture.getClusterName());    assertEquals("testing-index-name", fixture.getIndexName());    assertEquals("testing-index-type", fixture.getIndexType());    assertEquals(TimeUnit.DAYS.toMillis(10), fixture.getTTLMs());    assertArrayEquals(expected, fixture.getServerAddresses());}
40991ad12ec9a69dd2597ba46d5afb8d2aab2d52a91428be5c1cd77bfb7a4415
shouldParseConfigurationUsingDefaults
public void shouldParseConfigurationUsingDefaults()
{    parameters.put(HOSTNAMES, "10.5.5.27");    parameters.remove(INDEX_NAME);    parameters.remove(INDEX_TYPE);    parameters.remove(CLUSTER_NAME);    fixture = new ElasticSearchSink();    fixture.configure(new Context(parameters));    String[] expected = { "10.5.5.27" };    assertEquals(DEFAULT_INDEX_NAME, fixture.getIndexName());    assertEquals(DEFAULT_INDEX_TYPE, fixture.getIndexType());    assertEquals(DEFAULT_CLUSTER_NAME, fixture.getClusterName());    assertArrayEquals(expected, fixture.getServerAddresses());}
4ddc892a0b2b696d7f976620bec7c2204963f23d9d9fd93baa30501a87827a79
shouldParseMultipleHostUsingDefaultPorts
public void shouldParseMultipleHostUsingDefaultPorts()
{    parameters.put(HOSTNAMES, "10.5.5.27,10.5.5.28,10.5.5.29");    fixture = new ElasticSearchSink();    fixture.configure(new Context(parameters));    String[] expected = { "10.5.5.27", "10.5.5.28", "10.5.5.29" };    assertArrayEquals(expected, fixture.getServerAddresses());}
fea08adac05ffdeca19fd854bffc43d54d96c44d48279c7ef5e4e4c891f8ddfb
shouldParseMultipleHostWithWhitespacesUsingDefaultPorts
public void shouldParseMultipleHostWithWhitespacesUsingDefaultPorts()
{    parameters.put(HOSTNAMES, " 10.5.5.27 , 10.5.5.28 , 10.5.5.29 ");    fixture = new ElasticSearchSink();    fixture.configure(new Context(parameters));    String[] expected = { "10.5.5.27", "10.5.5.28", "10.5.5.29" };    assertArrayEquals(expected, fixture.getServerAddresses());}
4885ee7f23500d806e47a5632ba38de9ea1b8875f5c0b24a400fec0eaa33c67f
shouldParseMultipleHostAndPorts
public void shouldParseMultipleHostAndPorts()
{    parameters.put(HOSTNAMES, "10.5.5.27:9300,10.5.5.28:9301,10.5.5.29:9302");    fixture = new ElasticSearchSink();    fixture.configure(new Context(parameters));    String[] expected = { "10.5.5.27:9300", "10.5.5.28:9301", "10.5.5.29:9302" };    assertArrayEquals(expected, fixture.getServerAddresses());}
4888047ccfe0253a734efc426b855435708673a659fc8b756b393891cf242376
shouldParseMultipleHostAndPortsWithWhitespaces
public void shouldParseMultipleHostAndPortsWithWhitespaces()
{    parameters.put(HOSTNAMES, " 10.5.5.27 : 9300 , 10.5.5.28 : 9301 , 10.5.5.29 : 9302 ");    fixture = new ElasticSearchSink();    fixture.configure(new Context(parameters));    String[] expected = { "10.5.5.27:9300", "10.5.5.28:9301", "10.5.5.29:9302" };    assertArrayEquals(expected, fixture.getServerAddresses());}
60857746fc6a1c4b01440c7630515f5c30f44a2abf2629e30bce42c02f4d32cf
shouldAllowCustomElasticSearchIndexRequestBuilderFactory
public void shouldAllowCustomElasticSearchIndexRequestBuilderFactory() throws Exception
{    parameters.put(SERIALIZER, CustomElasticSearchIndexRequestBuilderFactory.class.getName());    fixture.configure(new Context(parameters));    Channel channel = bindAndStartChannel(fixture);    Transaction tx = channel.getTransaction();    tx.begin();    String body = "{ foo: \"bar\" }";    Event event = EventBuilder.withBody(body.getBytes());    channel.put(event);    tx.commit();    tx.close();    fixture.process();    fixture.stop();    assertEquals(fixture.getIndexName() + "-05_17_36_789", CustomElasticSearchIndexRequestBuilderFactory.actualIndexName);    assertEquals(fixture.getIndexType(), CustomElasticSearchIndexRequestBuilderFactory.actualIndexType);    assertArrayEquals(event.getBody(), CustomElasticSearchIndexRequestBuilderFactory.actualEventBody);    assertTrue(CustomElasticSearchIndexRequestBuilderFactory.hasContext);}
059f16754d823844f939e3a6d1ebf13f9e67227d4be400524be1aa1c45e4f584
shouldParseFullyQualifiedTTLs
public void shouldParseFullyQualifiedTTLs()
{    Map<String, Long> testTTLMap = new HashMap<String, Long>();    testTTLMap.put("1ms", Long.valueOf(1));    testTTLMap.put("1s", Long.valueOf(1000));    testTTLMap.put("1m", Long.valueOf(60000));    testTTLMap.put("1h", Long.valueOf(3600000));    testTTLMap.put("1d", Long.valueOf(86400000));    testTTLMap.put("1w", Long.valueOf(604800000));    testTTLMap.put("1", Long.valueOf(86400000));    parameters.put(HOSTNAMES, "10.5.5.27");    parameters.put(CLUSTER_NAME, "testing-cluster-name");    parameters.put(INDEX_NAME, "testing-index-name");    parameters.put(INDEX_TYPE, "testing-index-type");    for (String ttl : testTTLMap.keySet()) {        parameters.put(TTL, ttl);        fixture = new ElasticSearchSink();        fixture.configure(new Context(parameters));        String[] expected = { "10.5.5.27" };        assertEquals("testing-cluster-name", fixture.getClusterName());        assertEquals("testing-index-name", fixture.getIndexName());        assertEquals("testing-index-type", fixture.getIndexType());        assertEquals((long) testTTLMap.get(ttl), fixture.getTTLMs());        assertArrayEquals(expected, fixture.getServerAddresses());    }}
e7f5809c279ec938be28820ee389cf315701d5781bd2864823688bf933e195a8
prepareIndexRequest
protected void prepareIndexRequest(IndexRequestBuilder indexRequest, String indexName, String indexType, Event event) throws IOException
{    actualIndexName = indexName;    actualIndexType = indexType;    actualEventBody = event.getBody();    indexRequest.setIndex(indexName).setType(indexType).setSource(event.getBody());}
831ce21591a09012662aaaae570affb5cfbdae1d467406cdc38950e2a861d04d
configure
public void configure(Context arg0)
{    hasContext = true;}
b57d480d9330fd6fb8eac29a211d75065be50a1d7f03db360104d53193808642
configure
public void configure(ComponentConfiguration arg0)
{}
9bccb1f45ae76cabd613c2ac6a916b0ce0e3bd44fe410ab0aba146c3ec7a7d77
shouldFailToConfigureWithInvalidSerializerClass
public void shouldFailToConfigureWithInvalidSerializerClass() throws Exception
{    parameters.put(SERIALIZER, "java.lang.String");    try {        Configurables.configure(fixture, new Context(parameters));    } catch (ClassCastException e) {        }    parameters.put(SERIALIZER, FakeConfigurable.class.getName());    try {        Configurables.configure(fixture, new Context(parameters));    } catch (IllegalArgumentException e) {        }}
5579e707a9f26d489d4d8ad7848dde004d1fa9e0c0c382f35ffff9e73dbf3ef6
shouldUseSpecifiedSerializer
public void shouldUseSpecifiedSerializer() throws Exception
{    Context context = new Context();    context.put(SERIALIZER, "org.apache.flume.sink.elasticsearch.FakeEventSerializer");    assertNull(fixture.getEventSerializer());    fixture.configure(context);    assertTrue(fixture.getEventSerializer() instanceof FakeEventSerializer);}
3e2da1824cb19e4974d97831fae4213168882bb29fc573013bd6eafe077ec1d1
shouldUseSpecifiedIndexNameBuilder
public void shouldUseSpecifiedIndexNameBuilder() throws Exception
{    Context context = new Context();    context.put(ElasticSearchSinkConstants.INDEX_NAME_BUILDER, "org.apache.flume.sink.elasticsearch.FakeIndexNameBuilder");    assertNull(fixture.getIndexNameBuilder());    fixture.configure(context);    assertTrue(fixture.getIndexNameBuilder() instanceof FakeIndexNameBuilder);}
831ce21591a09012662aaaae570affb5cfbdae1d467406cdc38950e2a861d04d
configure
public void configure(Context arg0)
{}
1ac45d8d3700b449a1614146c5fb11cafc42ed1884f8eaa4e7ccb50d5093d21a
getContentBuilder
public BytesStream getContentBuilder(Event event) throws IOException
{    FastByteArrayOutputStream fbaos = new FastByteArrayOutputStream(4);    fbaos.write(FAKE_BYTES);    return fbaos;}
831ce21591a09012662aaaae570affb5cfbdae1d467406cdc38950e2a861d04d
configure
public void configure(Context arg0)
{    configuredWithContext = true;}
b57d480d9330fd6fb8eac29a211d75065be50a1d7f03db360104d53193808642
configure
public void configure(ComponentConfiguration arg0)
{    configuredWithComponentConfiguration = true;}
9144d4107a2482ec0178ed8ac3f9273244c20f91397e2acddf3ec80563a1ffe6
getIndexName
public String getIndexName(Event event)
{    return INDEX_NAME;}
ed233f2389e8e05ccd563b74ef705f3f3db0b842cc3a2877742fc2d53de8b65c
getIndexPrefix
public String getIndexPrefix(Event event)
{    return INDEX_NAME;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{}
57746d8a7acafcf5647f649109937334de6090302f29c32ed7da0df311700e35
configure
public void configure(ComponentConfiguration conf)
{}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    sinkFactory = new DefaultSinkFactory();}
5274c226b630d9fd7c9cfa2368f625e10db12c5b1cdbe04968f1c296196c2408
verifySinkCreation
private void verifySinkCreation(String name, String type, Class<?> typeClass) throws FlumeException
{    Sink sink = sinkFactory.create(name, type);    Assert.assertNotNull(sink);    Assert.assertTrue(typeClass.isInstance(sink));}
66cf42a2fbf2ff4192d473ea28dd3a2c1d7389f68a166b0f208cb4cd791d921b
testSinkCreation
public void testSinkCreation()
{    verifySinkCreation("elasticsearch-sink", "elasticsearch", ElasticSearchSink.class);}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    Context context = new Context();    context.put(ElasticSearchSinkConstants.INDEX_NAME, "prefix");    indexNameBuilder = new TimeBasedIndexNameBuilder();    indexNameBuilder.configure(context);}
74614ef384956e0866bad341327949f5be7e8de551673a80dfd3f24e063f4318
shouldUseUtcAsBasisForDateFormat
public void shouldUseUtcAsBasisForDateFormat()
{    assertEquals("Coordinated Universal Time", indexNameBuilder.getFastDateFormat().getTimeZone().getDisplayName());}
812a5953df9262097465b502ed8eff79f3c82cada545f96f78eb309cde0ecda7
indexNameShouldBePrefixDashFormattedTimestamp
public void indexNameShouldBePrefixDashFormattedTimestamp()
{    long time = 987654321L;    Event event = new SimpleEvent();    Map<String, String> headers = new HashMap<String, String>();    headers.put("timestamp", Long.toString(time));    event.setHeaders(headers);    assertEquals("prefix-" + indexNameBuilder.getFastDateFormat().format(time), indexNameBuilder.getIndexName(event));}
b5346228de2e45995d887f7b34cc01222a1b3b6964d1bf6b886741801a215c7f
setFixedJodaTime
public void setFixedJodaTime()
{    DateTimeUtils.setCurrentMillisFixed(FIXED_TIME_MILLIS);}
0e86e450739fee4847b9837e8186ed388dfeca8a3c347712a01d19356f80aa62
shouldEnsureTimestampHeaderPresentInTimestampedEvent
public void shouldEnsureTimestampHeaderPresentInTimestampedEvent()
{    SimpleEvent base = new SimpleEvent();    TimestampedEvent timestampedEvent = new TimestampedEvent(base);    assertEquals(FIXED_TIME_MILLIS, timestampedEvent.getTimestamp());    assertEquals(String.valueOf(FIXED_TIME_MILLIS), timestampedEvent.getHeaders().get("timestamp"));}
769fa416b74c3ae53a04ea50e29ae8adec7e3c8c5a965fcaa0411dde3e7e5bb6
shouldUseExistingTimestampHeaderInTimestampedEvent
public void shouldUseExistingTimestampHeaderInTimestampedEvent()
{    SimpleEvent base = new SimpleEvent();    Map<String, String> headersWithTimestamp = Maps.newHashMap();    headersWithTimestamp.put("timestamp", "-321");    base.setHeaders(headersWithTimestamp);    TimestampedEvent timestampedEvent = new TimestampedEvent(base);    assertEquals(-321L, timestampedEvent.getTimestamp());    assertEquals("-321", timestampedEvent.getHeaders().get("timestamp"));}
b20b9f7f1f2c1747ebfb9962dd78ac8309af3bdc766bb2fb0580539f01701cd3
shouldUseExistingAtTimestampHeaderInTimestampedEvent
public void shouldUseExistingAtTimestampHeaderInTimestampedEvent()
{    SimpleEvent base = new SimpleEvent();    Map<String, String> headersWithTimestamp = Maps.newHashMap();    headersWithTimestamp.put("@timestamp", "-999");    base.setHeaders(headersWithTimestamp);    TimestampedEvent timestampedEvent = new TimestampedEvent(base);    assertEquals(-999L, timestampedEvent.getTimestamp());    assertEquals("-999", timestampedEvent.getHeaders().get("@timestamp"));    assertNull(timestampedEvent.getHeaders().get("timestamp"));}
bc39ba8b3d4316b1e1bb5ca061f71feb6f6627c24889c7781ef4984981504b7b
shouldPreserveBodyAndNonTimestampHeadersInTimestampedEvent
public void shouldPreserveBodyAndNonTimestampHeadersInTimestampedEvent()
{    SimpleEvent base = new SimpleEvent();    base.setBody(new byte[] { 1, 2, 3, 4 });    Map<String, String> headersWithTimestamp = Maps.newHashMap();    headersWithTimestamp.put("foo", "bar");    base.setHeaders(headersWithTimestamp);    TimestampedEvent timestampedEvent = new TimestampedEvent(base);    assertEquals("bar", timestampedEvent.getHeaders().get("foo"));    assertArrayEquals(base.getBody(), timestampedEvent.getBody());}
e52e5e378330fd7f87ee30351bbfcec47b751fee12ece2ef0cfdd77a08c906e1
process
public Status process() throws EventDeliveryException
{    /*     * Reference to the boolean representing failure of the current transaction.     * Since each txn gets a new boolean, failure of one txn will not affect     * the next even if errbacks for the current txn get called while     * the next one is being processed.     *     */    if (!open) {        throw new EventDeliveryException("Sink was never opened. " + "Please fix the configuration.");    }    if (client == null) {        client = initHBaseClient();        if (client == null) {            throw new EventDeliveryException("Could not establish connection to HBase!");        }    }    AtomicBoolean txnFail = new AtomicBoolean(false);    AtomicInteger callbacksReceived = new AtomicInteger(0);    AtomicInteger callbacksExpected = new AtomicInteger(0);    final Lock lock = new ReentrantLock();    final Condition condition = lock.newCondition();    if (incrementBuffer != null) {        incrementBuffer.clear();    }    /*     * Callbacks can be reused per transaction, since they share the same     * locks and conditions.     */    Callback<Object, Object> putSuccessCallback = new SuccessCallback<Object, Object>(lock, callbacksReceived, condition);    Callback<Object, Exception> putFailureCallback = new FailureCallback<Object, Exception>(lock, callbacksReceived, txnFail, condition);    Callback<Long, Long> incrementSuccessCallback = new SuccessCallback<Long, Long>(lock, callbacksReceived, condition);    Callback<Long, Exception> incrementFailureCallback = new FailureCallback<Long, Exception>(lock, callbacksReceived, txnFail, condition);    Status status = Status.READY;    Channel channel = getChannel();    txn = channel.getTransaction();    txn.begin();    int i = 0;    try {        for (; i < batchSize; i++) {            Event event = channel.take();            if (event == null) {                status = Status.BACKOFF;                if (i == 0) {                    sinkCounter.incrementBatchEmptyCount();                } else {                    sinkCounter.incrementBatchUnderflowCount();                }                break;            } else {                serializer.setEvent(event);                List<PutRequest> actions = serializer.getActions();                List<AtomicIncrementRequest> increments = serializer.getIncrements();                callbacksExpected.addAndGet(actions.size());                if (!batchIncrements) {                    callbacksExpected.addAndGet(increments.size());                }                for (PutRequest action : actions) {                    action.setDurable(enableWal);                    client.put(action).addCallbacks(putSuccessCallback, putFailureCallback);                }                for (AtomicIncrementRequest increment : increments) {                    if (batchIncrements) {                        CellIdentifier identifier = new CellIdentifier(increment.key(), increment.qualifier());                        AtomicIncrementRequest request = incrementBuffer.get(identifier);                        if (request == null) {                            incrementBuffer.put(identifier, increment);                        } else {                            request.setAmount(request.getAmount() + increment.getAmount());                        }                    } else {                        client.atomicIncrement(increment).addCallbacks(incrementSuccessCallback, incrementFailureCallback);                    }                }            }        }        if (batchIncrements) {            Collection<AtomicIncrementRequest> increments = incrementBuffer.values();            for (AtomicIncrementRequest increment : increments) {                client.atomicIncrement(increment).addCallbacks(incrementSuccessCallback, incrementFailureCallback);            }            callbacksExpected.addAndGet(increments.size());        }        client.flush();    } catch (Throwable e) {        this.handleTransactionFailure(txn);        this.checkIfChannelExceptionAndThrow(e);    }    if (i == batchSize) {        sinkCounter.incrementBatchCompleteCount();    }    sinkCounter.addToEventDrainAttemptCount(i);    lock.lock();    long startTime = System.nanoTime();    long timeRemaining;    try {        while ((callbacksReceived.get() < callbacksExpected.get()) && !txnFail.get()) {            timeRemaining = timeout - (System.nanoTime() - startTime);            timeRemaining = (timeRemaining >= 0) ? timeRemaining : 0;            try {                if (!condition.await(timeRemaining, TimeUnit.NANOSECONDS)) {                    txnFail.set(true);                    logger.warn("HBase callbacks timed out. " + "Transaction will be rolled back.");                }            } catch (Exception ex) {                logger.error("Exception while waiting for callbacks from HBase.");                this.handleTransactionFailure(txn);                Throwables.propagate(ex);            }        }    } finally {        lock.unlock();    }    if (isCoalesceTest) {        totalCallbacksReceived += callbacksReceived.get();    }    /*     * At this point, either the txn has failed     * or all callbacks received and txn is successful.     *     * This need not be in the monitor, since all callbacks for this txn     * have been received. So txnFail will not be modified any more(even if     * it is, it is set from true to true only - false happens only     * in the next process call).     *     */    if (txnFail.get()) {                if (lastTxnFailed) {            consecutiveHBaseFailures++;        }        lastTxnFailed = true;        this.handleTransactionFailure(txn);        throw new EventDeliveryException("Could not write events to Hbase. " + "Transaction failed, and rolled back.");    } else {        try {            lastTxnFailed = false;            consecutiveHBaseFailures = 0;            txn.commit();            txn.close();            sinkCounter.addToEventDrainSuccessCount(i);        } catch (Throwable e) {            this.handleTransactionFailure(txn);            this.checkIfChannelExceptionAndThrow(e);        }    }    return status;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    if (!HBaseVersionCheck.hasVersionLessThan2(logger)) {        throw new ConfigurationException("HBase major version number must be less than 2 for asynchbase sink. ");    }    tableName = context.getString(HBaseSinkConfigurationConstants.CONFIG_TABLE);    String cf = context.getString(HBaseSinkConfigurationConstants.CONFIG_COLUMN_FAMILY);    batchSize = context.getLong(HBaseSinkConfigurationConstants.CONFIG_BATCHSIZE, new Long(100));    serializerContext = new Context();        eventSerializerType = context.getString(HBaseSinkConfigurationConstants.CONFIG_SERIALIZER);    Preconditions.checkNotNull(tableName, "Table name cannot be empty, please specify in configuration file");    Preconditions.checkNotNull(cf, "Column family cannot be empty, please specify in configuration file");        if (eventSerializerType == null || eventSerializerType.isEmpty()) {        eventSerializerType = "org.apache.flume.sink.hbase.SimpleAsyncHbaseEventSerializer";        logger.info("No serializer defined, Will use default");    }    serializerContext.putAll(context.getSubProperties(HBaseSinkConfigurationConstants.CONFIG_SERIALIZER_PREFIX));    columnFamily = cf.getBytes(Charsets.UTF_8);    try {        @SuppressWarnings("unchecked")        Class<? extends AsyncHbaseEventSerializer> clazz = (Class<? extends AsyncHbaseEventSerializer>) Class.forName(eventSerializerType);        serializer = clazz.newInstance();        serializer.configure(serializerContext);        serializer.initialize(tableName.getBytes(Charsets.UTF_8), columnFamily);    } catch (Exception e) {        logger.error("Could not instantiate event serializer.", e);        Throwables.propagate(e);    }    if (sinkCounter == null) {        sinkCounter = new SinkCounter(this.getName());    }    timeout = context.getLong(HBaseSinkConfigurationConstants.CONFIG_TIMEOUT, HBaseSinkConfigurationConstants.DEFAULT_TIMEOUT);    if (timeout <= 0) {        logger.warn("Timeout should be positive for Hbase sink. " + "Sink will not timeout.");        timeout = HBaseSinkConfigurationConstants.DEFAULT_TIMEOUT;    }        timeout = TimeUnit.MILLISECONDS.toNanos(timeout);    zkQuorum = context.getString(HBaseSinkConfigurationConstants.ZK_QUORUM, "").trim();    if (!zkQuorum.isEmpty()) {        zkBaseDir = context.getString(HBaseSinkConfigurationConstants.ZK_ZNODE_PARENT, HBaseSinkConfigurationConstants.DEFAULT_ZK_ZNODE_PARENT);    } else {        if (conf == null) {                        conf = HBaseConfiguration.create();        }        zkQuorum = ZKConfig.getZKQuorumServersString(conf);        zkBaseDir = conf.get(HConstants.ZOOKEEPER_ZNODE_PARENT, HConstants.DEFAULT_ZOOKEEPER_ZNODE_PARENT);    }    Preconditions.checkState(zkQuorum != null && !zkQuorum.isEmpty(), "The Zookeeper quorum cannot be null and should be specified.");    enableWal = context.getBoolean(HBaseSinkConfigurationConstants.CONFIG_ENABLE_WAL, HBaseSinkConfigurationConstants.DEFAULT_ENABLE_WAL);    logger.info("The write to WAL option is set to: " + String.valueOf(enableWal));    if (!enableWal) {        logger.warn("AsyncHBaseSink's enableWal configuration is set to false. " + "All writes to HBase will have WAL disabled, and any data in the " + "memstore of this region in the Region Server could be lost!");    }    batchIncrements = context.getBoolean(HBaseSinkConfigurationConstants.CONFIG_COALESCE_INCREMENTS, HBaseSinkConfigurationConstants.DEFAULT_COALESCE_INCREMENTS);    if (batchIncrements) {        incrementBuffer = Maps.newHashMap();        logger.info("Increment coalescing is enabled. Increments will be " + "buffered.");    }    maxConsecutiveFails = context.getInteger(HBaseSinkConfigurationConstants.CONFIG_MAX_CONSECUTIVE_FAILS, HBaseSinkConfigurationConstants.DEFAULT_MAX_CONSECUTIVE_FAILS);    Map<String, String> asyncProperties = context.getSubProperties(HBaseSinkConfigurationConstants.ASYNC_PREFIX);    asyncClientConfig = new Config();    asyncClientConfig.overrideConfig(HBaseSinkConfigurationConstants.ASYNC_ZK_QUORUM_KEY, zkQuorum);    asyncClientConfig.overrideConfig(HBaseSinkConfigurationConstants.ASYNC_ZK_BASEPATH_KEY, zkBaseDir);    for (String property : asyncProperties.keySet()) {        asyncClientConfig.overrideConfig(property, asyncProperties.get(property));    }}
66be00971cd69f6f60a4d4bc1e8c1bb5ab7d7f07803e2153745b0fd98d38b5c5
getTotalCallbacksReceived
 int getTotalCallbacksReceived()
{    return totalCallbacksReceived;}
326836ce65f26c1d32fd73674ff2d666a586b95eda2a3fba12cdc3b78595e33e
isConfNull
 boolean isConfNull()
{    return conf == null;}
dcc511f35190533c2d6fcc6073d66b12e111f5004c64ff08ccc3609a06ab844d
getBatchSize
public long getBatchSize()
{    return batchSize;}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    Preconditions.checkArgument(client == null, "Please call stop " + "before calling start on an old instance.");    sinkCounter.start();    sinkCounter.incrementConnectionCreatedCount();    client = initHBaseClient();    super.start();}
83b9efda84d5cff2c19b868bd71934c726f4436ead577d0bbafd5625e5df62e6
initHBaseClient
private HBaseClient initHBaseClient()
{    logger.info("Initializing HBase Client");    sinkCallbackPool = Executors.newCachedThreadPool(new ThreadFactoryBuilder().setNameFormat(this.getName() + " HBase Call Pool").build());    logger.info("Callback pool created");    client = new HBaseClient(asyncClientConfig, new NioClientSocketChannelFactory(sinkCallbackPool, sinkCallbackPool));    final CountDownLatch latch = new CountDownLatch(1);    final AtomicBoolean fail = new AtomicBoolean(false);    client.ensureTableFamilyExists(tableName.getBytes(Charsets.UTF_8), columnFamily).addCallbacks(new Callback<Object, Object>() {        @Override        public Object call(Object arg) throws Exception {            latch.countDown();            logger.info("table found");            return null;        }    }, new Callback<Object, Object>() {        @Override        public Object call(Object arg) throws Exception {            fail.set(true);            latch.countDown();            return null;        }    });    try {        logger.info("waiting on callback");        latch.await();        logger.info("callback received");    } catch (InterruptedException e) {        sinkCounter.incrementConnectionFailedCount();        throw new FlumeException("Interrupted while waiting for Hbase Callbacks", e);    }    if (fail.get()) {        sinkCounter.incrementConnectionFailedCount();        if (client != null) {            shutdownHBaseClient();        }        throw new FlumeException("Could not start sink. " + "Table or column family does not exist in Hbase.");    } else {        open = true;    }    client.setFlushInterval((short) 0);    return client;}
d181ba5914acba0cefa14a17b2e2fdfa525bf546ce7d1a1f27ea25957b03fe6a
call
public Object call(Object arg) throws Exception
{    latch.countDown();    logger.info("table found");    return null;}
d181ba5914acba0cefa14a17b2e2fdfa525bf546ce7d1a1f27ea25957b03fe6a
call
public Object call(Object arg) throws Exception
{    fail.set(true);    latch.countDown();    return null;}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    serializer.cleanUp();    if (client != null) {        shutdownHBaseClient();    }    sinkCounter.incrementConnectionClosedCount();    sinkCounter.stop();    try {        if (sinkCallbackPool != null) {            sinkCallbackPool.shutdown();            if (!sinkCallbackPool.awaitTermination(5, TimeUnit.SECONDS)) {                sinkCallbackPool.shutdownNow();            }        }    } catch (InterruptedException e) {        logger.error("Interrupted while waiting for asynchbase sink pool to " + "die", e);        if (sinkCallbackPool != null) {            sinkCallbackPool.shutdownNow();        }    }    sinkCallbackPool = null;    client = null;    conf = null;    open = false;    super.stop();}
997b3a00d8c6d238e516d7e34058f2a0c03db89ca7b9f37d69d7a93b09de5cb5
shutdownHBaseClient
private void shutdownHBaseClient()
{    logger.info("Shutting down HBase Client");    final CountDownLatch waiter = new CountDownLatch(1);    try {        client.shutdown().addCallback(new Callback<Object, Object>() {            @Override            public Object call(Object arg) throws Exception {                waiter.countDown();                return null;            }        }).addErrback(new Callback<Object, Object>() {            @Override            public Object call(Object arg) throws Exception {                logger.error("Failed to shutdown HBase client cleanly! HBase cluster might be down");                waiter.countDown();                return null;            }        });        if (!waiter.await(timeout, TimeUnit.NANOSECONDS)) {            logger.error("HBase connection could not be closed within timeout! HBase cluster might " + "be down!");        }    } catch (Exception ex) {        logger.warn("Error while attempting to close connections to HBase");    } finally {                client = null;    }}
d181ba5914acba0cefa14a17b2e2fdfa525bf546ce7d1a1f27ea25957b03fe6a
call
public Object call(Object arg) throws Exception
{    waiter.countDown();    return null;}
d181ba5914acba0cefa14a17b2e2fdfa525bf546ce7d1a1f27ea25957b03fe6a
call
public Object call(Object arg) throws Exception
{    logger.error("Failed to shutdown HBase client cleanly! HBase cluster might be down");    waiter.countDown();    return null;}
59bd165426b80ff3d7357ae0165b27be9e397c86f29e6e1ac7628267b27c6645
handleTransactionFailure
private void handleTransactionFailure(Transaction txn) throws EventDeliveryException
{    if (maxConsecutiveFails > 0 && consecutiveHBaseFailures >= maxConsecutiveFails) {        if (client != null) {            shutdownHBaseClient();        }        consecutiveHBaseFailures = 0;    }    try {        txn.rollback();    } catch (Throwable e) {        logger.error("Failed to commit transaction." + "Transaction rolled back.", e);        if (e instanceof Error || e instanceof RuntimeException) {            logger.error("Failed to commit transaction." + "Transaction rolled back.", e);            Throwables.propagate(e);        } else {            logger.error("Failed to commit transaction." + "Transaction rolled back.", e);            throw new EventDeliveryException("Failed to commit transaction." + "Transaction rolled back.", e);        }    } finally {        txn.close();    }}
5802fedbc38b77d65bb197611e309b076fc7492e29b7e0a3548a48f733faf881
call
public R call(T arg) throws Exception
{    if (isTimeoutTesting) {        try {                        TimeUnit.NANOSECONDS.sleep(TimeUnit.SECONDS.toNanos(4));        } catch (InterruptedException e) {                }    }    doCall();    return null;}
b679534ce6ddd6cb451d1bdee12519cb8bef962f72cf899fa4ceea5d89d3b326
doCall
private void doCall() throws Exception
{    callbacksReceived.incrementAndGet();    lock.lock();    try {        condition.signal();    } finally {        lock.unlock();    }}
5802fedbc38b77d65bb197611e309b076fc7492e29b7e0a3548a48f733faf881
call
public R call(T arg) throws Exception
{    logger.error("failure callback:", arg);    if (isTimeoutTesting) {                try {            TimeUnit.NANOSECONDS.sleep(TimeUnit.SECONDS.toNanos(4));        } catch (InterruptedException e) {                }    }    doCall();    return null;}
b679534ce6ddd6cb451d1bdee12519cb8bef962f72cf899fa4ceea5d89d3b326
doCall
private void doCall() throws Exception
{    callbacksReceived.incrementAndGet();    this.txnFail.set(true);    lock.lock();    try {        condition.signal();    } finally {        lock.unlock();    }}
3036628a101d731271cebfc03b1da69ce37704604242e212ae9ec0fba92ce8af
checkIfChannelExceptionAndThrow
private void checkIfChannelExceptionAndThrow(Throwable e) throws EventDeliveryException
{    if (e instanceof ChannelException) {        throw new EventDeliveryException("Error in processing transaction.", e);    } else if (e instanceof Error || e instanceof RuntimeException) {        Throwables.propagate(e);    }    throw new EventDeliveryException("Error in processing transaction.", e);}
0ac42bf5188762fc1283b5cbd2b3bb1031e80963813b3b310b15c3fb47050003
hashCode
public int hashCode()
{    return hashCode;}
74e378df448c6c3cd090d6daf881cfac8957dd555869ea4c13a46bdc6cdcf9a6
equals
public boolean equals(Object other)
{    CellIdentifier o = (CellIdentifier) other;    if (other == null) {        return false;    } else {        return (COMPARATOR.compare(row, o.row) == 0 && COMPARATOR.compare(column, o.column) == 0);    }}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    Preconditions.checkArgument(table == null, "Please call stop " + "before calling start on an old instance.");    try {        privilegedExecutor = FlumeAuthenticationUtil.getAuthenticator(kerberosPrincipal, kerberosKeytab);    } catch (Exception ex) {        sinkCounter.incrementConnectionFailedCount();        throw new FlumeException("Failed to login to HBase using " + "provided credentials.", ex);    }    try {        table = privilegedExecutor.execute(new PrivilegedExceptionAction<HTable>() {            @Override            public HTable run() throws Exception {                HTable table = new HTable(config, tableName);                table.setAutoFlush(false);                                return table;            }        });    } catch (Exception e) {        sinkCounter.incrementConnectionFailedCount();        logger.error("Could not load table, " + tableName + " from HBase", e);        throw new FlumeException("Could not load table, " + tableName + " from HBase", e);    }    try {        if (!privilegedExecutor.execute(new PrivilegedExceptionAction<Boolean>() {            @Override            public Boolean run() throws IOException {                return table.getTableDescriptor().hasFamily(columnFamily);            }        })) {            throw new IOException("Table " + tableName + " has no such column family " + Bytes.toString(columnFamily));        }    } catch (Exception e) {                        sinkCounter.incrementConnectionFailedCount();        throw new FlumeException("Error getting column family from HBase." + "Please verify that the table " + tableName + " and Column Family, " + Bytes.toString(columnFamily) + " exists in HBase, and the" + " current user has permissions to access that table.", e);    }    super.start();    sinkCounter.incrementConnectionCreatedCount();    sinkCounter.start();}
0e65a9e49771972b533139d04b480e0854c6e67c6d1f36f4ab7ac2595a9877f6
run
public HTable run() throws Exception
{    HTable table = new HTable(config, tableName);    table.setAutoFlush(false);        return table;}
cc792fefb111c924fde7f977d5d5d7da8731ed3aa76e2277b80e9663397c586d
run
public Boolean run() throws IOException
{    return table.getTableDescriptor().hasFamily(columnFamily);}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    try {        if (table != null) {            table.close();        }        table = null;    } catch (IOException e) {        throw new FlumeException("Error closing table.", e);    }    sinkCounter.incrementConnectionClosedCount();    sinkCounter.stop();}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    if (!HBaseVersionCheck.hasVersionLessThan2(logger)) {        throw new ConfigurationException("HBase major version number must be less than 2 for hbase-sink.");    }    tableName = context.getString(HBaseSinkConfigurationConstants.CONFIG_TABLE);    String cf = context.getString(HBaseSinkConfigurationConstants.CONFIG_COLUMN_FAMILY);    batchSize = context.getLong(HBaseSinkConfigurationConstants.CONFIG_BATCHSIZE, new Long(100));    serializerContext = new Context();        eventSerializerType = context.getString(HBaseSinkConfigurationConstants.CONFIG_SERIALIZER);    Preconditions.checkNotNull(tableName, "Table name cannot be empty, please specify in configuration file");    Preconditions.checkNotNull(cf, "Column family cannot be empty, please specify in configuration file");        if (eventSerializerType == null || eventSerializerType.isEmpty()) {        eventSerializerType = "org.apache.flume.sink.hbase.SimpleHbaseEventSerializer";        logger.info("No serializer defined, Will use default");    }    serializerContext.putAll(context.getSubProperties(HBaseSinkConfigurationConstants.CONFIG_SERIALIZER_PREFIX));    columnFamily = cf.getBytes(Charsets.UTF_8);    try {        Class<? extends HbaseEventSerializer> clazz = (Class<? extends HbaseEventSerializer>) Class.forName(eventSerializerType);        serializer = clazz.newInstance();        serializer.configure(serializerContext);    } catch (Exception e) {        logger.error("Could not instantiate event serializer.", e);        Throwables.propagate(e);    }    kerberosKeytab = context.getString(HBaseSinkConfigurationConstants.CONFIG_KEYTAB);    kerberosPrincipal = context.getString(HBaseSinkConfigurationConstants.CONFIG_PRINCIPAL);    enableWal = context.getBoolean(HBaseSinkConfigurationConstants.CONFIG_ENABLE_WAL, HBaseSinkConfigurationConstants.DEFAULT_ENABLE_WAL);    logger.info("The write to WAL option is set to: " + String.valueOf(enableWal));    if (!enableWal) {        logger.warn("HBase Sink's enableWal configuration is set to false. All " + "writes to HBase will have WAL disabled, and any data in the " + "memstore of this region in the Region Server could be lost!");    }    batchIncrements = context.getBoolean(HBaseSinkConfigurationConstants.CONFIG_COALESCE_INCREMENTS, HBaseSinkConfigurationConstants.DEFAULT_COALESCE_INCREMENTS);    if (batchIncrements) {        logger.info("Increment coalescing is enabled. Increments will be " + "buffered.");        refGetFamilyMap = reflectLookupGetFamilyMap();    }    String zkQuorum = context.getString(HBaseSinkConfigurationConstants.ZK_QUORUM);    Integer port = null;    /**     * HBase allows multiple nodes in the quorum, but all need to use the     * same client port. So get the nodes in host:port format,     * and ignore the ports for all nodes except the first one. If no port is     * specified, use default.     */    if (zkQuorum != null && !zkQuorum.isEmpty()) {        StringBuilder zkBuilder = new StringBuilder();        logger.info("Using ZK Quorum: " + zkQuorum);        String[] zkHosts = zkQuorum.split(",");        int length = zkHosts.length;        for (int i = 0; i < length; i++) {            String[] zkHostAndPort = zkHosts[i].split(":");            zkBuilder.append(zkHostAndPort[0].trim());            if (i != length - 1) {                zkBuilder.append(",");            } else {                zkQuorum = zkBuilder.toString();            }            if (zkHostAndPort[1] == null) {                throw new FlumeException("Expected client port for the ZK node!");            }            if (port == null) {                port = Integer.parseInt(zkHostAndPort[1].trim());            } else if (!port.equals(Integer.parseInt(zkHostAndPort[1].trim()))) {                throw new FlumeException("All Zookeeper nodes in the quorum must " + "use the same client port.");            }        }        if (port == null) {            port = HConstants.DEFAULT_ZOOKEPER_CLIENT_PORT;        }        this.config.set(HConstants.ZOOKEEPER_QUORUM, zkQuorum);        this.config.setInt(HConstants.ZOOKEEPER_CLIENT_PORT, port);    }    String hbaseZnode = context.getString(HBaseSinkConfigurationConstants.ZK_ZNODE_PARENT);    if (hbaseZnode != null && !hbaseZnode.isEmpty()) {        this.config.set(HConstants.ZOOKEEPER_ZNODE_PARENT, hbaseZnode);    }    sinkCounter = new SinkCounter(this.getName());}
15fc7b435a67fff3a8a6d4f3247065fc8d3a4a40e90958e753eaafbc7f71ad66
getConfig
public Configuration getConfig()
{    return config;}
e52e5e378330fd7f87ee30351bbfcec47b751fee12ece2ef0cfdd77a08c906e1
process
public Status process() throws EventDeliveryException
{    Status status = Status.READY;    Channel channel = getChannel();    Transaction txn = channel.getTransaction();    List<Row> actions = new LinkedList<Row>();    List<Increment> incs = new LinkedList<Increment>();    try {        txn.begin();        if (serializer instanceof BatchAware) {            ((BatchAware) serializer).onBatchStart();        }        long i = 0;        for (; i < batchSize; i++) {            Event event = channel.take();            if (event == null) {                if (i == 0) {                    status = Status.BACKOFF;                    sinkCounter.incrementBatchEmptyCount();                } else {                    sinkCounter.incrementBatchUnderflowCount();                }                break;            } else {                serializer.initialize(event, columnFamily);                actions.addAll(serializer.getActions());                incs.addAll(serializer.getIncrements());            }        }        if (i == batchSize) {            sinkCounter.incrementBatchCompleteCount();        }        sinkCounter.addToEventDrainAttemptCount(i);        putEventsAndCommit(actions, incs, txn);    } catch (Throwable e) {        try {            txn.rollback();        } catch (Exception e2) {            logger.error("Exception in rollback. Rollback might not have been " + "successful.", e2);        }        logger.error("Failed to commit transaction." + "Transaction rolled back.", e);        if (e instanceof Error || e instanceof RuntimeException) {            logger.error("Failed to commit transaction." + "Transaction rolled back.", e);            Throwables.propagate(e);        } else {            logger.error("Failed to commit transaction." + "Transaction rolled back.", e);            throw new EventDeliveryException("Failed to commit transaction." + "Transaction rolled back.", e);        }    } finally {        txn.close();    }    return status;}
641f81b345b46ee6656bb18ab736a7c2dd0536395d9eaf8cdb7a092fa1ee7818
putEventsAndCommit
private void putEventsAndCommit(final List<Row> actions, final List<Increment> incs, Transaction txn) throws Exception
{    privilegedExecutor.execute(new PrivilegedExceptionAction<Void>() {        @Override        public Void run() throws Exception {            for (Row r : actions) {                if (r instanceof Put) {                    ((Put) r).setWriteToWAL(enableWal);                }                                if (r instanceof Increment) {                    ((Increment) r).setWriteToWAL(enableWal);                }            }            table.batch(actions);            return null;        }    });    privilegedExecutor.execute(new PrivilegedExceptionAction<Void>() {        @Override        public Void run() throws Exception {            List<Increment> processedIncrements;            if (batchIncrements) {                processedIncrements = coalesceIncrements(incs);            } else {                processedIncrements = incs;            }                        if (debugIncrCallback != null) {                debugIncrCallback.onAfterCoalesce(processedIncrements);            }            for (final Increment i : processedIncrements) {                i.setWriteToWAL(enableWal);                table.increment(i);            }            return null;        }    });    txn.commit();    sinkCounter.addToEventDrainSuccessCount(actions.size());}
8a477b1c63bebaa1d51a297399bc7774041611fd3fc9834474bf58ff4e4a5406
run
public Void run() throws Exception
{    for (Row r : actions) {        if (r instanceof Put) {            ((Put) r).setWriteToWAL(enableWal);        }                if (r instanceof Increment) {            ((Increment) r).setWriteToWAL(enableWal);        }    }    table.batch(actions);    return null;}
8a477b1c63bebaa1d51a297399bc7774041611fd3fc9834474bf58ff4e4a5406
run
public Void run() throws Exception
{    List<Increment> processedIncrements;    if (batchIncrements) {        processedIncrements = coalesceIncrements(incs);    } else {        processedIncrements = incs;    }        if (debugIncrCallback != null) {        debugIncrCallback.onAfterCoalesce(processedIncrements);    }    for (final Increment i : processedIncrements) {        i.setWriteToWAL(enableWal);        table.increment(i);    }    return null;}
594e5f5780099d107908bd518d029692ed427f20f12a04d74f93b149d04497bb
reflectLookupGetFamilyMap
 static Method reflectLookupGetFamilyMap()
{    Method m = null;    String[] methodNames = { "getFamilyMapOfLongs", "getFamilyMap" };    for (String methodName : methodNames) {        try {            m = Increment.class.getMethod(methodName);            if (m != null && m.getReturnType().equals(Map.class)) {                logger.debug("Using Increment.{} for coalesce", methodName);                break;            }        } catch (NoSuchMethodException e) {            logger.debug("Increment.{} does not exist. Exception follows.", methodName, e);        } catch (SecurityException e) {            logger.debug("No access to Increment.{}; Exception follows.", methodName, e);        }    }    if (m == null) {        throw new UnsupportedOperationException("Cannot find Increment.getFamilyMap()");    }    return m;}
65f96773081e3df143ada852dae0b0994e63ea12d5b2a16fea20fecaf8bb38df
getFamilyMap
private Map<byte[], NavigableMap<byte[], Long>> getFamilyMap(Increment inc)
{    Preconditions.checkNotNull(refGetFamilyMap, "Increment.getFamilymap() not found");    Preconditions.checkNotNull(inc, "Increment required");    Map<byte[], NavigableMap<byte[], Long>> familyMap = null;    try {        Object familyObj = refGetFamilyMap.invoke(inc);        familyMap = (Map<byte[], NavigableMap<byte[], Long>>) familyObj;    } catch (IllegalAccessException e) {        logger.warn("Unexpected error calling getFamilyMap()", e);        Throwables.propagate(e);    } catch (InvocationTargetException e) {        logger.warn("Unexpected error calling getFamilyMap()", e);        Throwables.propagate(e);    }    return familyMap;}
3b2e979c13d5f43f2635cb287c4a27f0e0eb50841c2bb3e828b13cf80c02147a
coalesceIncrements
private List<Increment> coalesceIncrements(Iterable<Increment> incs)
{    Preconditions.checkNotNull(incs, "List of Increments must not be null");            Map<byte[], Map<byte[], NavigableMap<byte[], Long>>> counters = Maps.newTreeMap(Bytes.BYTES_COMPARATOR);    for (Increment inc : incs) {        byte[] row = inc.getRow();        Map<byte[], NavigableMap<byte[], Long>> families = getFamilyMap(inc);        for (Map.Entry<byte[], NavigableMap<byte[], Long>> familyEntry : families.entrySet()) {            byte[] family = familyEntry.getKey();            NavigableMap<byte[], Long> qualifiers = familyEntry.getValue();            for (Map.Entry<byte[], Long> qualifierEntry : qualifiers.entrySet()) {                byte[] qualifier = qualifierEntry.getKey();                Long count = qualifierEntry.getValue();                incrementCounter(counters, row, family, qualifier, count);            }        }    }        List<Increment> coalesced = Lists.newLinkedList();    for (Map.Entry<byte[], Map<byte[], NavigableMap<byte[], Long>>> rowEntry : counters.entrySet()) {        byte[] row = rowEntry.getKey();        Map<byte[], NavigableMap<byte[], Long>> families = rowEntry.getValue();        Increment inc = new Increment(row);        for (Map.Entry<byte[], NavigableMap<byte[], Long>> familyEntry : families.entrySet()) {            byte[] family = familyEntry.getKey();            NavigableMap<byte[], Long> qualifiers = familyEntry.getValue();            for (Map.Entry<byte[], Long> qualifierEntry : qualifiers.entrySet()) {                byte[] qualifier = qualifierEntry.getKey();                long count = qualifierEntry.getValue();                inc.addColumn(family, qualifier, count);            }        }        coalesced.add(inc);    }    return coalesced;}
c0fd3a9260c47a5d7fa52067a6ffef6e4dcc22e15e68d3a229fef932d388d359
incrementCounter
private void incrementCounter(Map<byte[], Map<byte[], NavigableMap<byte[], Long>>> counters, byte[] row, byte[] family, byte[] qualifier, Long count)
{    Map<byte[], NavigableMap<byte[], Long>> families = counters.get(row);    if (families == null) {        families = Maps.newTreeMap(Bytes.BYTES_COMPARATOR);        counters.put(row, families);    }    NavigableMap<byte[], Long> qualifiers = families.get(family);    if (qualifiers == null) {        qualifiers = Maps.newTreeMap(Bytes.BYTES_COMPARATOR);        families.put(family, qualifiers);    }    Long existingValue = qualifiers.get(qualifier);    if (existingValue == null) {        qualifiers.put(qualifier, count);    } else {        qualifiers.put(qualifier, existingValue + count);    }}
f4133f6fccb75652405a5f0504d750653432d4a082ed83a46683efbe2853b154
getSerializer
 HbaseEventSerializer getSerializer()
{    return serializer;}
dcc511f35190533c2d6fcc6073d66b12e111f5004c64ff08ccc3609a06ab844d
getBatchSize
public long getBatchSize()
{    return batchSize;}
acc709f5ad4c9c6a0e01aea0521d1460ded83af20eb18dc74dabd8420eaac07d
getMajorVersion
private static int getMajorVersion(String version) throws NumberFormatException
{    return Integer.parseInt(version.split("\\.")[0]);}
071a71d26e9d29a5d356cbcedbb522d89caa4d4e68d0f8e2d5217813c6c68b0d
hasVersionLessThan2
 static boolean hasVersionLessThan2(Logger logger)
{    String version = VersionInfo.getVersion();    try {        if (getMajorVersion(version) < 2) {            return true;        }    } catch (NumberFormatException ex) {        logger.error(ex.getMessage());    }    logger.error("Invalid HBase version:" + version);    return false;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    String regex = context.getString(REGEX_CONFIG, REGEX_DEFAULT);    regexIgnoreCase = context.getBoolean(IGNORE_CASE_CONFIG, IGNORE_CASE_DEFAULT);    depositHeaders = context.getBoolean(DEPOSIT_HEADERS_CONFIG, DEPOSIT_HEADERS_DEFAULT);    inputPattern = Pattern.compile(regex, Pattern.DOTALL + (regexIgnoreCase ? Pattern.CASE_INSENSITIVE : 0));    charset = Charset.forName(context.getString(CHARSET_CONFIG, CHARSET_DEFAULT));    String colNameStr = context.getString(COL_NAME_CONFIG, COLUMN_NAME_DEFAULT);    String[] columnNames = colNameStr.split(",");    for (String s : columnNames) {        colNames.add(s.getBytes(charset));    }        rowKeyIndex = context.getInteger(ROW_KEY_INDEX_CONFIG, -1);        if (rowKeyIndex >= 0) {        if (rowKeyIndex >= columnNames.length) {            throw new IllegalArgumentException(ROW_KEY_INDEX_CONFIG + " must be " + "less than num columns " + columnNames.length);        }        if (!ROW_KEY_NAME.equalsIgnoreCase(columnNames[rowKeyIndex])) {            throw new IllegalArgumentException("Column at " + rowKeyIndex + " must be " + ROW_KEY_NAME + " and is " + columnNames[rowKeyIndex]);        }    }}
57746d8a7acafcf5647f649109937334de6090302f29c32ed7da0df311700e35
configure
public void configure(ComponentConfiguration conf)
{}
f72c511dfbc4e6d86273515cc0b62b8c1b4636d26d61e1784f67de94e1a6722c
initialize
public void initialize(Event event, byte[] columnFamily)
{    this.headers = event.getHeaders();    this.payload = event.getBody();    this.cf = columnFamily;}
3bc9a2898081d6e57a180f44ee76b1941a578d44f384af17bc015dadf56497a3
getRowKey
protected byte[] getRowKey(Calendar cal)
{    /* NOTE: This key generation strategy has the following properties:     *      * 1) Within a single JVM, the same row key will never be duplicated.     * 2) Amongst any two JVM's operating at different time periods (according     *    to their respective clocks), the same row key will never be      *    duplicated.     * 3) Amongst any two JVM's operating concurrently (according to their     *    respective clocks), the odds of duplicating a row-key are non-zero     *    but infinitesimal. This would require simultaneous collision in (a)      *    the timestamp (b) the respective nonce and (c) the random string.     *    The string is necessary since (a) and (b) could collide if a fleet     *    of Flume agents are restarted in tandem.     *         *  Row-key uniqueness is important because conflicting row-keys will cause     *  data loss. */    String rowKey = String.format("%s-%s-%s", cal.getTimeInMillis(), randomKey, nonce.getAndIncrement());    return rowKey.getBytes(charset);}
fa04a120c620eb491746134bf656460ba7b99f32ae0215b5223a6769cf008f6d
getRowKey
protected byte[] getRowKey()
{    return getRowKey(Calendar.getInstance());}
dc71e0855cdad821f5c5816dac8946a22b961a0e027f83663aa27e3d1d935379
getActions
public List<Row> getActions() throws FlumeException
{    List<Row> actions = Lists.newArrayList();    byte[] rowKey;    Matcher m = inputPattern.matcher(new String(payload, charset));    if (!m.matches()) {        return Lists.newArrayList();    }    if (m.groupCount() != colNames.size()) {        return Lists.newArrayList();    }    try {        if (rowKeyIndex < 0) {            rowKey = getRowKey();        } else {            rowKey = m.group(rowKeyIndex + 1).getBytes(Charsets.UTF_8);        }        Put put = new Put(rowKey);        for (int i = 0; i < colNames.size(); i++) {            if (i != rowKeyIndex) {                put.add(cf, colNames.get(i), m.group(i + 1).getBytes(Charsets.UTF_8));            }        }        if (depositHeaders) {            for (Map.Entry<String, String> entry : headers.entrySet()) {                put.add(cf, entry.getKey().getBytes(charset), entry.getValue().getBytes(charset));            }        }        actions.add(put);    } catch (Exception e) {        throw new FlumeException("Could not get row key!", e);    }    return actions;}
30f5c2bb6c32ae5f4ae7d54354298647a3d168c0ed3177fbac8f4e79028a6044
getIncrements
public List<Increment> getIncrements()
{    return Lists.newArrayList();}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{}
de6737495181137135aeac6cbcfa79b5fb2d3774da8e5371984f0a7fe38d54a8
initialize
public void initialize(byte[] table, byte[] cf)
{    this.table = table;    this.cf = cf;}
7a8e4e3a1010c91584e01d248b6e75839267cdaafe5d1641cc139c62b49b7738
getActions
public List<PutRequest> getActions()
{    List<PutRequest> actions = new ArrayList<PutRequest>();    if (payloadColumn != null) {        byte[] rowKey;        try {            switch(keyType) {                case TS:                    rowKey = SimpleRowKeyGenerator.getTimestampKey(rowPrefix);                    break;                case TSNANO:                    rowKey = SimpleRowKeyGenerator.getNanoTimestampKey(rowPrefix);                    break;                case RANDOM:                    rowKey = SimpleRowKeyGenerator.getRandomKey(rowPrefix);                    break;                default:                    rowKey = SimpleRowKeyGenerator.getUUIDKey(rowPrefix);                    break;            }            PutRequest putRequest = new PutRequest(table, rowKey, cf, payloadColumn, payload);            actions.add(putRequest);        } catch (Exception e) {            throw new FlumeException("Could not get row key!", e);        }    }    return actions;}
9aea8c252f02c6c876c8599b54e8f83aae2bd5bffb111b194f2a0b0a5a3718fd
getIncrements
public List<AtomicIncrementRequest> getIncrements()
{    List<AtomicIncrementRequest> actions = new ArrayList<AtomicIncrementRequest>();    if (incrementColumn != null) {        AtomicIncrementRequest inc = new AtomicIncrementRequest(table, incrementRow, cf, incrementColumn);        actions.add(inc);    }    return actions;}
8d9ec964cb2b1702f35510b65dc80717f83aa9b6d06f2d7caf8545c5d3f9a1d1
cleanUp
public void cleanUp()
{}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    String pCol = context.getString("payloadColumn", "pCol");    String iCol = context.getString("incrementColumn", "iCol");    rowPrefix = context.getString("rowPrefix", "default");    String suffix = context.getString("suffix", "uuid");    if (pCol != null && !pCol.isEmpty()) {        if (suffix.equals("timestamp")) {            keyType = KeyType.TS;        } else if (suffix.equals("random")) {            keyType = KeyType.RANDOM;        } else if (suffix.equals("nano")) {            keyType = KeyType.TSNANO;        } else {            keyType = KeyType.UUID;        }        payloadColumn = pCol.getBytes(Charsets.UTF_8);    }    if (iCol != null && !iCol.isEmpty()) {        incrementColumn = iCol.getBytes(Charsets.UTF_8);    }    incrementRow = context.getString("incrementRow", "incRow").getBytes(Charsets.UTF_8);}
47363d3a7e3fdbdcd42bd21dcb85d78d78a6adb7b2b0b2799237b52c0523fdb0
setEvent
public void setEvent(Event event)
{    this.payload = event.getBody();}
57746d8a7acafcf5647f649109937334de6090302f29c32ed7da0df311700e35
configure
public void configure(ComponentConfiguration conf)
{}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    rowPrefix = context.getString("rowPrefix", "default");    incrementRow = context.getString("incrementRow", "incRow").getBytes(Charsets.UTF_8);    String suffix = context.getString("suffix", "uuid");    String payloadColumn = context.getString("payloadColumn", "pCol");    String incColumn = context.getString("incrementColumn", "iCol");    if (payloadColumn != null && !payloadColumn.isEmpty()) {        if (suffix.equals("timestamp")) {            keyType = KeyType.TS;        } else if (suffix.equals("random")) {            keyType = KeyType.RANDOM;        } else if (suffix.equals("nano")) {            keyType = KeyType.TSNANO;        } else {            keyType = KeyType.UUID;        }        plCol = payloadColumn.getBytes(Charsets.UTF_8);    }    if (incColumn != null && !incColumn.isEmpty()) {        incCol = incColumn.getBytes(Charsets.UTF_8);    }}
57746d8a7acafcf5647f649109937334de6090302f29c32ed7da0df311700e35
configure
public void configure(ComponentConfiguration conf)
{}
1e3a2697d7a8ae5b31238efacec1090b7d4313e62f34b514c08131ba1b656038
initialize
public void initialize(Event event, byte[] cf)
{    this.payload = event.getBody();    this.cf = cf;}
dc71e0855cdad821f5c5816dac8946a22b961a0e027f83663aa27e3d1d935379
getActions
public List<Row> getActions() throws FlumeException
{    List<Row> actions = new LinkedList<Row>();    if (plCol != null) {        byte[] rowKey;        try {            if (keyType == KeyType.TS) {                rowKey = SimpleRowKeyGenerator.getTimestampKey(rowPrefix);            } else if (keyType == KeyType.RANDOM) {                rowKey = SimpleRowKeyGenerator.getRandomKey(rowPrefix);            } else if (keyType == KeyType.TSNANO) {                rowKey = SimpleRowKeyGenerator.getNanoTimestampKey(rowPrefix);            } else {                rowKey = SimpleRowKeyGenerator.getUUIDKey(rowPrefix);            }            Put put = new Put(rowKey);            put.add(cf, plCol, payload);            actions.add(put);        } catch (Exception e) {            throw new FlumeException("Could not get row key!", e);        }    }    return actions;}
30f5c2bb6c32ae5f4ae7d54354298647a3d168c0ed3177fbac8f4e79028a6044
getIncrements
public List<Increment> getIncrements()
{    List<Increment> incs = new LinkedList<Increment>();    if (incCol != null) {        Increment inc = new Increment(incrementRow);        inc.addColumn(cf, incCol, 1);        incs.add(inc);    }    return incs;}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{}
c7130b8afbcc7ce9fe32c2b14f444b3f25813dacdbad0a87c31d2dcff90f020f
getUUIDKey
public static byte[] getUUIDKey(String prefix) throws UnsupportedEncodingException
{    return (prefix + UUID.randomUUID().toString()).getBytes("UTF8");}
a177b3e67a82d5686d56866e34769238013256e67dc03c231cd8a70cc7bc159a
getRandomKey
public static byte[] getRandomKey(String prefix) throws UnsupportedEncodingException
{    return (prefix + String.valueOf(new Random().nextLong())).getBytes("UTF8");}
4c43d08f084023c5daea80c36221f054db0477eba47af98d8d7612f6f928f466
getTimestampKey
public static byte[] getTimestampKey(String prefix) throws UnsupportedEncodingException
{    return (prefix + String.valueOf(System.currentTimeMillis())).getBytes("UTF8");}
8a860669c59e13a99489f103db96c928b4a20c55fb151764983167f38e29afe8
getNanoTimestampKey
public static byte[] getNanoTimestampKey(String prefix) throws UnsupportedEncodingException
{    return (prefix + String.valueOf(System.nanoTime())).getBytes("UTF8");}
de6737495181137135aeac6cbcfa79b5fb2d3774da8e5371984f0a7fe38d54a8
initialize
public void initialize(byte[] table, byte[] cf)
{    this.table = table;    this.cf = cf;}
47363d3a7e3fdbdcd42bd21dcb85d78d78a6adb7b2b0b2799237b52c0523fdb0
setEvent
public void setEvent(Event event)
{    this.currentEvent = event;}
7a8e4e3a1010c91584e01d248b6e75839267cdaafe5d1641cc139c62b49b7738
getActions
public List<PutRequest> getActions()
{    return Collections.emptyList();}
9aea8c252f02c6c876c8599b54e8f83aae2bd5bffb111b194f2a0b0a5a3718fd
getIncrements
public List<AtomicIncrementRequest> getIncrements()
{    List<AtomicIncrementRequest> incrs = new ArrayList<AtomicIncrementRequest>();    AtomicIncrementRequest incr = new AtomicIncrementRequest(table, currentEvent.getBody(), cf, column, 1);    incrs.add(incr);    return incrs;}
8d9ec964cb2b1702f35510b65dc80717f83aa9b6d06f2d7caf8545c5d3f9a1d1
cleanUp
public void cleanUp()
{}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    column = context.getString("column", "col").getBytes();}
57746d8a7acafcf5647f649109937334de6090302f29c32ed7da0df311700e35
configure
public void configure(ComponentConfiguration conf)
{}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{}
57746d8a7acafcf5647f649109937334de6090302f29c32ed7da0df311700e35
configure
public void configure(ComponentConfiguration conf)
{}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{}
f72c511dfbc4e6d86273515cc0b62b8c1b4636d26d61e1784f67de94e1a6722c
initialize
public void initialize(Event event, byte[] columnFamily)
{    this.event = event;    this.family = columnFamily;}
6a7d67d80ca0653acaa8148e627f5cff1686e1b28feba4e7c314b569249d834d
getActions
public List<Row> getActions()
{    return Collections.emptyList();}
30f5c2bb6c32ae5f4ae7d54354298647a3d168c0ed3177fbac8f4e79028a6044
getIncrements
public List<Increment> getIncrements()
{    List<Increment> increments = Lists.newArrayList();    String body = new String(event.getBody(), Charsets.UTF_8);    String[] pieces = body.split(":");    String row = pieces[0];    String qualifier = pieces[1];    Increment inc = new Increment(row.getBytes(Charsets.UTF_8));    inc.addColumn(family, qualifier.getBytes(Charsets.UTF_8), 1L);    increments.add(inc);    return increments;}
a196e3eb093f17c5939a62e311dd520f2babe5f04026ca0e27f7d2fadc8abbfe
onBatchStart
public void onBatchStart()
{    numBatchesStarted++;}
1a6f98b4d962deb6896b6be1fcf50bda9fe32d3b065444013fbee63607d7b049
getNumBatchesStarted
public int getNumBatchesStarted()
{    return numBatchesStarted;}
dc71e0855cdad821f5c5816dac8946a22b961a0e027f83663aa27e3d1d935379
getActions
public List<Row> getActions() throws FlumeException
{    if (throwException) {        throw new FlumeException("Exception for testing");    }    return super.getActions();}
d471c3328e3ae0971417113aa4471685bb392547c42536a61bb7d27d34a796f1
setUp
public static void setUp() throws Exception
{    testUtility.startMiniCluster();    Map<String, String> ctxMap = new HashMap<String, String>();    ctxMap.put("table", tableName);    ctxMap.put("columnFamily", columnFamily);    ctxMap.put("serializer", "org.apache.flume.sink.hbase.SimpleAsyncHbaseEventSerializer");    ctxMap.put("serializer.payloadColumn", plCol);    ctxMap.put("serializer.incrementColumn", inColumn);    ctxMap.put("keep-alive", "0");    ctxMap.put("timeout", "10000");    ctx.putAll(ctxMap);    os = ManagementFactory.getOperatingSystemMXBean();}
91092076c3c5d98d14320b9514a066b23c5f91393fd9e53f99aac45daa12cd77
tearDown
public static void tearDown() throws Exception
{    testUtility.shutdownMiniCluster();}
924be818da79eae0dc1b306d7e406b7aa61e97ec3d49cdae94670169255e3305
tearDownTest
public void tearDownTest() throws Exception
{    if (deleteTable) {        testUtility.deleteTable(tableName.getBytes());    }}
166ec667ea0b32d61d4516f23e7e6ca766427a663b608ab260190838a691ea21
testOneEventWithDefaults
public void testOneEventWithDefaults() throws Exception
{    Map<String, String> ctxMap = new HashMap<String, String>();    ctxMap.put("table", tableName);    ctxMap.put("columnFamily", columnFamily);    ctxMap.put("serializer", "org.apache.flume.sink.hbase.SimpleAsyncHbaseEventSerializer");    ctxMap.put("keep-alive", "0");    ctxMap.put("timeout", "10000");    Context tmpctx = new Context();    tmpctx.putAll(ctxMap);    testUtility.createTable(tableName.getBytes(), columnFamily.getBytes());    deleteTable = true;    AsyncHBaseSink sink = new AsyncHBaseSink(testUtility.getConfiguration());    Configurables.configure(sink, tmpctx);    Channel channel = new MemoryChannel();    Configurables.configure(channel, tmpctx);    sink.setChannel(channel);    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    Event e = EventBuilder.withBody(Bytes.toBytes(valBase));    channel.put(e);    tx.commit();    tx.close();    Assert.assertFalse(sink.isConfNull());    sink.process();    sink.stop();    HTable table = new HTable(testUtility.getConfiguration(), tableName);    byte[][] results = getResults(table, 1);    byte[] out = results[0];    Assert.assertArrayEquals(e.getBody(), out);    out = results[1];    Assert.assertArrayEquals(Longs.toByteArray(1), out);}
0a8cf36588251f47ca1cf7facc48a8cdeae477e351d60ef85141ac1e8acd21e9
testOneEvent
public void testOneEvent() throws Exception
{    testUtility.createTable(tableName.getBytes(), columnFamily.getBytes());    deleteTable = true;    AsyncHBaseSink sink = new AsyncHBaseSink(testUtility.getConfiguration());    Configurables.configure(sink, ctx);    Channel channel = new MemoryChannel();    Configurables.configure(channel, ctx);    sink.setChannel(channel);    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    Event e = EventBuilder.withBody(Bytes.toBytes(valBase));    channel.put(e);    tx.commit();    tx.close();    Assert.assertFalse(sink.isConfNull());    sink.process();    sink.stop();    HTable table = new HTable(testUtility.getConfiguration(), tableName);    byte[][] results = getResults(table, 1);    byte[] out = results[0];    Assert.assertArrayEquals(e.getBody(), out);    out = results[1];    Assert.assertArrayEquals(Longs.toByteArray(1), out);}
c05b4c34d243c1058c356a62aa114fa3d7342e85de534d3ddbb238798e624217
testThreeEvents
public void testThreeEvents() throws Exception
{    testUtility.createTable(tableName.getBytes(), columnFamily.getBytes());    deleteTable = true;    AsyncHBaseSink sink = new AsyncHBaseSink(testUtility.getConfiguration());    Configurables.configure(sink, ctx);    Channel channel = new MemoryChannel();    Configurables.configure(channel, ctx);    sink.setChannel(channel);    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    for (int i = 0; i < 3; i++) {        Event e = EventBuilder.withBody(Bytes.toBytes(valBase + "-" + i));        channel.put(e);    }    tx.commit();    tx.close();    Assert.assertFalse(sink.isConfNull());    sink.process();    sink.stop();    HTable table = new HTable(testUtility.getConfiguration(), tableName);    byte[][] results = getResults(table, 3);    byte[] out;    int found = 0;    for (int i = 0; i < 3; i++) {        for (int j = 0; j < 3; j++) {            if (Arrays.equals(results[j], Bytes.toBytes(valBase + "-" + i))) {                found++;                break;            }        }    }    Assert.assertEquals(3, found);    out = results[3];    Assert.assertArrayEquals(Longs.toByteArray(3), out);}
c10854cdc9e9ef41417896220765acdc2e660a0e599311085c288e9bc33a2783
testTimeOut
public void testTimeOut() throws Exception
{    testUtility.createTable(tableName.getBytes(), columnFamily.getBytes());    deleteTable = true;    AsyncHBaseSink sink = new AsyncHBaseSink(testUtility.getConfiguration(), true, false);    Configurables.configure(sink, ctx);    Channel channel = new MemoryChannel();    Configurables.configure(channel, ctx);    sink.setChannel(channel);    channel.start();    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    for (int i = 0; i < 3; i++) {        Event e = EventBuilder.withBody(Bytes.toBytes(valBase + "-" + i));        channel.put(e);    }    tx.commit();    tx.close();    Assert.assertFalse(sink.isConfNull());    sink.process();    Assert.fail();}
3f903b698636f8b14fa3e1fe8deb6aecf348bfca091441835349ecd20a459d28
testMultipleBatches
public void testMultipleBatches() throws Exception
{    testUtility.createTable(tableName.getBytes(), columnFamily.getBytes());    deleteTable = true;    ctx.put("batchSize", "2");    AsyncHBaseSink sink = new AsyncHBaseSink(testUtility.getConfiguration());    Configurables.configure(sink, ctx);        ctx.put("batchSize", "100");    Channel channel = new MemoryChannel();    Configurables.configure(channel, ctx);    sink.setChannel(channel);    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    for (int i = 0; i < 3; i++) {        Event e = EventBuilder.withBody(Bytes.toBytes(valBase + "-" + i));        channel.put(e);    }    tx.commit();    tx.close();    int count = 0;    Status status = Status.READY;    while (status != Status.BACKOFF) {        count++;        status = sink.process();    }    Assert.assertFalse(sink.isConfNull());    sink.stop();    Assert.assertEquals(2, count);    HTable table = new HTable(testUtility.getConfiguration(), tableName);    byte[][] results = getResults(table, 3);    byte[] out;    int found = 0;    for (int i = 0; i < 3; i++) {        for (int j = 0; j < 3; j++) {            if (Arrays.equals(results[j], Bytes.toBytes(valBase + "-" + i))) {                found++;                break;            }        }    }    Assert.assertEquals(3, found);    out = results[3];    Assert.assertArrayEquals(Longs.toByteArray(3), out);}
c5b03690679d9bcc37883c710098a133a2d8aae8dacd653abddb968f446c7891
testMultipleBatchesBatchIncrementsWithCoalescing
public void testMultipleBatchesBatchIncrementsWithCoalescing() throws Exception
{    doTestMultipleBatchesBatchIncrements(true);}
594f48aa1448c558623cfc90231561c890ed5031aae7185044e1b6fe43fa31eb
testMultipleBatchesBatchIncrementsNoCoalescing
public void testMultipleBatchesBatchIncrementsNoCoalescing() throws Exception
{    doTestMultipleBatchesBatchIncrements(false);}
92698da556036a8dfd7de7d703f0b8517e8e9b1f1ad7ba04e1b46ccd7e41547b
doTestMultipleBatchesBatchIncrements
public void doTestMultipleBatchesBatchIncrements(boolean coalesce) throws Exception
{    testUtility.createTable(tableName.getBytes(), columnFamily.getBytes());    deleteTable = true;    AsyncHBaseSink sink = new AsyncHBaseSink(testUtility.getConfiguration(), false, true);    if (coalesce) {        ctx.put(HBaseSinkConfigurationConstants.CONFIG_COALESCE_INCREMENTS, "true");    }    ctx.put("batchSize", "2");    ctx.put("serializer", IncrementAsyncHBaseSerializer.class.getName());    ctx.put("serializer.column", "test");    Configurables.configure(sink, ctx);        ctx.put("batchSize", "100");        ctx.put("serializer", SimpleAsyncHbaseEventSerializer.class.getName());        ctx.put(HBaseSinkConfigurationConstants.CONFIG_COALESCE_INCREMENTS, "false");    Channel channel = new MemoryChannel();    Configurables.configure(channel, ctx);    sink.setChannel(channel);    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    for (int i = 0; i < 4; i++) {        for (int j = 0; j < 3; j++) {            Event e = EventBuilder.withBody(Bytes.toBytes(valBase + "-" + i));            channel.put(e);        }    }    tx.commit();    tx.close();    int count = 0;    Status status = Status.READY;    while (status != Status.BACKOFF) {        count++;        status = sink.process();    }    Assert.assertFalse(sink.isConfNull());    sink.stop();    Assert.assertEquals(7, count);    HTable table = new HTable(testUtility.getConfiguration(), tableName);    Scan scan = new Scan();    scan.addColumn(columnFamily.getBytes(), "test".getBytes());    scan.setStartRow(Bytes.toBytes(valBase));    ResultScanner rs = table.getScanner(scan);    int i = 0;    try {        for (Result r = rs.next(); r != null; r = rs.next()) {            byte[] out = r.getValue(columnFamily.getBytes(), "test".getBytes());            Assert.assertArrayEquals(Longs.toByteArray(3), out);            Assert.assertTrue(new String(r.getRow()).startsWith(valBase));            i++;        }    } finally {        rs.close();    }    Assert.assertEquals(4, i);    if (coalesce) {        Assert.assertEquals(8, sink.getTotalCallbacksReceived());    } else {        Assert.assertEquals(12, sink.getTotalCallbacksReceived());    }}
0e9b2a5968e2172ff1e8d345e371f21c9ae1ac933bcfba3c98b09b4491a8eab7
testWithoutConfigurationObject
public void testWithoutConfigurationObject() throws Exception
{    testUtility.createTable(tableName.getBytes(), columnFamily.getBytes());    deleteTable = true;    ctx.put("batchSize", "2");    ctx.put(HBaseSinkConfigurationConstants.ZK_QUORUM, ZKConfig.getZKQuorumServersString(testUtility.getConfiguration()));    ctx.put(HBaseSinkConfigurationConstants.ZK_ZNODE_PARENT, testUtility.getConfiguration().get(HConstants.ZOOKEEPER_ZNODE_PARENT));    AsyncHBaseSink sink = new AsyncHBaseSink();    Configurables.configure(sink, ctx);        ctx.put(HBaseSinkConfigurationConstants.ZK_QUORUM, null);    ctx.put(HBaseSinkConfigurationConstants.ZK_ZNODE_PARENT, null);    ctx.put("batchSize", "100");    Channel channel = new MemoryChannel();    Configurables.configure(channel, ctx);    sink.setChannel(channel);    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    for (int i = 0; i < 3; i++) {        Event e = EventBuilder.withBody(Bytes.toBytes(valBase + "-" + i));        channel.put(e);    }    tx.commit();    tx.close();    int count = 0;    Status status = Status.READY;    while (status != Status.BACKOFF) {        count++;        status = sink.process();    }    /*     * Make sure that the configuration was picked up from the context itself     * and not from a configuration object which was created by the sink.     */    Assert.assertTrue(sink.isConfNull());    sink.stop();    Assert.assertEquals(2, count);    HTable table = new HTable(testUtility.getConfiguration(), tableName);    byte[][] results = getResults(table, 3);    byte[] out;    int found = 0;    for (int i = 0; i < 3; i++) {        for (int j = 0; j < 3; j++) {            if (Arrays.equals(results[j], Bytes.toBytes(valBase + "-" + i))) {                found++;                break;            }        }    }    Assert.assertEquals(3, found);    out = results[3];    Assert.assertArrayEquals(Longs.toByteArray(3), out);}
e8aa60f990984f01933584d8ef5e772704995dd8b1d21a2a2d1c83e52649d4c5
testMissingTable
public void testMissingTable() throws Exception
{    deleteTable = false;    ctx.put("batchSize", "2");    AsyncHBaseSink sink = new AsyncHBaseSink(testUtility.getConfiguration());    Configurables.configure(sink, ctx);        ctx.put("batchSize", "100");    Channel channel = new MemoryChannel();    Configurables.configure(channel, ctx);    sink.setChannel(channel);    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    for (int i = 0; i < 3; i++) {        Event e = EventBuilder.withBody(Bytes.toBytes(valBase + "-" + i));        channel.put(e);    }    tx.commit();    tx.close();    sink.process();    Assert.assertFalse(sink.isConfNull());    HTable table = new HTable(testUtility.getConfiguration(), tableName);    byte[][] results = getResults(table, 2);    byte[] out;    int found = 0;    for (int i = 0; i < 2; i++) {        for (int j = 0; j < 2; j++) {            if (Arrays.equals(results[j], Bytes.toBytes(valBase + "-" + i))) {                found++;                break;            }        }    }    Assert.assertEquals(2, found);    out = results[2];    Assert.assertArrayEquals(Longs.toByteArray(2), out);    sink.process();    sink.stop();}
7d7d396b734257a30caf8b976b1534900f9cbc0414a63431e31b9e8de75e9be2
getOpenFileDescriptorCount
private long getOpenFileDescriptorCount()
{    if (os instanceof UnixOperatingSystemMXBean) {        return ((UnixOperatingSystemMXBean) os).getOpenFileDescriptorCount();    } else {        return -1;    }}
bf7850c857f59080c41a2cb86bcff103ba69cc4da1a33d4b8c12d731dd510034
testFDLeakOnShutdown
public void testFDLeakOnShutdown() throws Exception
{    if (getOpenFileDescriptorCount() < 0) {        return;    }    testUtility.createTable(tableName.getBytes(), columnFamily.getBytes());    deleteTable = true;    AsyncHBaseSink sink = new AsyncHBaseSink(testUtility.getConfiguration(), true, false);    ctx.put("maxConsecutiveFails", "1");    Configurables.configure(sink, ctx);    Channel channel = new MemoryChannel();    Configurables.configure(channel, ctx);    sink.setChannel(channel);    channel.start();    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    for (int i = 0; i < 3; i++) {        Event e = EventBuilder.withBody(Bytes.toBytes(valBase + "-" + i));        channel.put(e);    }    tx.commit();    tx.close();    Assert.assertFalse(sink.isConfNull());    long initialFDCount = getOpenFileDescriptorCount();        for (int i = 0; i < 10; i++) {        try {            sink.process();        } catch (EventDeliveryException ex) {        }    }    long increaseInFD = getOpenFileDescriptorCount() - initialFDCount;    Assert.assertTrue("File Descriptor leak detected. FDs have increased by " + increaseInFD + " from an initial FD count of " + initialFDCount, increaseInFD < 50);}
355c37328e8976d2ec4c6df516e928071228ec26717881cd804abf1b95f10070
testHBaseFailure
public void testHBaseFailure() throws Exception
{    ctx.put("batchSize", "2");    testUtility.createTable(tableName.getBytes(), columnFamily.getBytes());    deleteTable = false;    AsyncHBaseSink sink = new AsyncHBaseSink(testUtility.getConfiguration());    Configurables.configure(sink, ctx);        ctx.put("batchSize", "100");    Channel channel = new MemoryChannel();    Configurables.configure(channel, ctx);    sink.setChannel(channel);    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    for (int i = 0; i < 3; i++) {        Event e = EventBuilder.withBody(Bytes.toBytes(valBase + "-" + i));        channel.put(e);    }    tx.commit();    tx.close();    sink.process();    Assert.assertFalse(sink.isConfNull());    HTable table = new HTable(testUtility.getConfiguration(), tableName);    byte[][] results = getResults(table, 2);    byte[] out;    int found = 0;    for (int i = 0; i < 2; i++) {        for (int j = 0; j < 2; j++) {            if (Arrays.equals(results[j], Bytes.toBytes(valBase + "-" + i))) {                found++;                break;            }        }    }    Assert.assertEquals(2, found);    out = results[2];    Assert.assertArrayEquals(Longs.toByteArray(2), out);    testUtility.shutdownMiniCluster();    sink.process();    sink.stop();}
ce84f8d9e7759c0f0ebbaf2020657daabcdb4b8d4dc44e2e6c91e2a538833adc
getResults
private byte[][] getResults(HTable table, int numEvents) throws IOException
{    byte[][] results = new byte[numEvents + 1][];    Scan scan = new Scan();    scan.addColumn(columnFamily.getBytes(), plCol.getBytes());    scan.setStartRow(Bytes.toBytes("default"));    ResultScanner rs = table.getScanner(scan);    byte[] out = null;    int i = 0;    try {        for (Result r = rs.next(); r != null; r = rs.next()) {            out = r.getValue(columnFamily.getBytes(), plCol.getBytes());            if (i >= results.length - 1) {                rs.close();                throw new FlumeException("More results than expected in the table." + "Expected = " + numEvents + ". Found = " + i);            }            results[i++] = out;            System.out.println(out);        }    } finally {        rs.close();    }    Assert.assertEquals(i, results.length - 1);    scan = new Scan();    scan.addColumn(columnFamily.getBytes(), inColumn.getBytes());    scan.setStartRow(Bytes.toBytes("incRow"));    rs = table.getScanner(scan);    out = null;    try {        for (Result r = rs.next(); r != null; r = rs.next()) {            out = r.getValue(columnFamily.getBytes(), inColumn.getBytes());            results[i++] = out;            System.out.println(out);        }    } finally {        rs.close();    }    return results;}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    Map<String, String> ctxMap = new HashMap<>();    ctxMap.put("table", tableName);    ctxMap.put("columnFamily", columnFamily);    ctx = new Context();    ctx.putAll(ctxMap);}
c765b8f37b00a3ab1817600aced6e2afb5842c8e32e79b600082d8886c954c54
testAsyncConfigBackwardCompatibility
public void testAsyncConfigBackwardCompatibility() throws Exception
{        String oldZkQuorumTestValue = "old_zookeeper_quorum_test_value";    String oldZkZnodeParentValue = "old_zookeeper_znode_parent_test_value";    ctx.put(HBaseSinkConfigurationConstants.ZK_QUORUM, oldZkQuorumTestValue);    ctx.put(HBaseSinkConfigurationConstants.ZK_ZNODE_PARENT, oldZkZnodeParentValue);    AsyncHBaseSink sink = new AsyncHBaseSink();    Configurables.configure(sink, ctx);    Assert.assertEquals(oldZkQuorumTestValue, sink.asyncClientConfig.getString(HBaseSinkConfigurationConstants.ASYNC_ZK_QUORUM_KEY));    Assert.assertEquals(oldZkZnodeParentValue, sink.asyncClientConfig.getString(HBaseSinkConfigurationConstants.ASYNC_ZK_BASEPATH_KEY));}
744c568282cb40c2ddb9ffbf4243c9067043bc77dc2463f787a8491db32365b5
testAsyncConfigNewStyleOverwriteOldOne
public void testAsyncConfigNewStyleOverwriteOldOne() throws Exception
{        String oldZkQuorumTestValue = "old_zookeeper_quorum_test_value";    String oldZkZnodeParentValue = "old_zookeeper_znode_parent_test_value";    ctx.put(HBaseSinkConfigurationConstants.ZK_QUORUM, oldZkQuorumTestValue);    ctx.put(HBaseSinkConfigurationConstants.ZK_ZNODE_PARENT, oldZkZnodeParentValue);    String newZkQuorumTestValue = "new_zookeeper_quorum_test_value";    String newZkZnodeParentValue = "new_zookeeper_znode_parent_test_value";    ctx.put(HBaseSinkConfigurationConstants.ASYNC_PREFIX + HBaseSinkConfigurationConstants.ASYNC_ZK_QUORUM_KEY, newZkQuorumTestValue);    ctx.put(HBaseSinkConfigurationConstants.ASYNC_PREFIX + HBaseSinkConfigurationConstants.ASYNC_ZK_BASEPATH_KEY, newZkZnodeParentValue);    AsyncHBaseSink sink = new AsyncHBaseSink();    Configurables.configure(sink, ctx);    Assert.assertEquals(newZkQuorumTestValue, sink.asyncClientConfig.getString(HBaseSinkConfigurationConstants.ASYNC_ZK_QUORUM_KEY));    Assert.assertEquals(newZkZnodeParentValue, sink.asyncClientConfig.getString(HBaseSinkConfigurationConstants.ASYNC_ZK_BASEPATH_KEY));}
1bec77c96a271e9ba8422e60f42e68448b21d91c118e721c69ca2e215928b494
testAsyncConfigAnyKeyCanBePassed
public void testAsyncConfigAnyKeyCanBePassed() throws Exception
{    String valueOfANewProp = "vale of the new property";    String keyOfANewProp = "some.key.to.be.passed";    ctx.put(HBaseSinkConfigurationConstants.ASYNC_PREFIX + keyOfANewProp, valueOfANewProp);    AsyncHBaseSink sink = new AsyncHBaseSink();    Configurables.configure(sink, ctx);    Assert.assertEquals(valueOfANewProp, sink.asyncClientConfig.getString(keyOfANewProp));}
ced4aede7c26d4b8c5fcbaf3c0e5acc033cd3ca9b285b7a9dd487898263fae25
setUpOnce
public static void setUpOnce() throws Exception
{    testUtility.startMiniCluster();}
7b231424694ad77be7196fe8ea50e232e329c5c7152a1231b645bfd43d46fbd0
tearDownOnce
public static void tearDownOnce() throws Exception
{    testUtility.shutdownMiniCluster();}
c536957a0359efaba4fa041a9429ed02027b66c9e6f5cc21d07eb308cc675a0d
setUp
public void setUp() throws IOException
{    conf = new Configuration(testUtility.getConfiguration());    ctx = new Context();    testUtility.createTable(tableName.getBytes(), columnFamily.getBytes());}
b15ec24534831cd8187de4c70ba4518879af91358fd307c4f306a42afcccad2c
tearDown
public void tearDown() throws IOException
{    testUtility.deleteTable(tableName.getBytes());}
c35f6c70f7b6411d8b1b2fb5cba120d477c7900601cd7da62130d3bc089094f0
initContextForSimpleHbaseEventSerializer
private void initContextForSimpleHbaseEventSerializer()
{    ctx = new Context();    ctx.put("table", tableName);    ctx.put("columnFamily", columnFamily);    ctx.put("serializer", SimpleHbaseEventSerializer.class.getName());    ctx.put("serializer.payloadColumn", plCol);    ctx.put("serializer.incrementColumn", inColumn);}
ea78833ab356e252756fb095767c524db95fc94f17f9ab23c0e8bff50b4171c8
initContextForIncrementHBaseSerializer
private void initContextForIncrementHBaseSerializer()
{    ctx = new Context();    ctx.put("table", tableName);    ctx.put("columnFamily", columnFamily);    ctx.put("serializer", IncrementHBaseSerializer.class.getName());}
166ec667ea0b32d61d4516f23e7e6ca766427a663b608ab260190838a691ea21
testOneEventWithDefaults
public void testOneEventWithDefaults() throws Exception
{        ctx = new Context();    ctx.put("table", tableName);    ctx.put("columnFamily", columnFamily);    ctx.put("serializer", SimpleHbaseEventSerializer.class.getName());    HBaseSink sink = new HBaseSink(conf);    Configurables.configure(sink, ctx);    Channel channel = new MemoryChannel();    Configurables.configure(channel, new Context());    sink.setChannel(channel);    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    Event e = EventBuilder.withBody(Bytes.toBytes(valBase));    channel.put(e);    tx.commit();    tx.close();    sink.process();    sink.stop();    HTable table = new HTable(conf, tableName);    byte[][] results = getResults(table, 1);    byte[] out = results[0];    Assert.assertArrayEquals(e.getBody(), out);    out = results[1];    Assert.assertArrayEquals(Longs.toByteArray(1), out);}
0a8cf36588251f47ca1cf7facc48a8cdeae477e351d60ef85141ac1e8acd21e9
testOneEvent
public void testOneEvent() throws Exception
{    initContextForSimpleHbaseEventSerializer();    HBaseSink sink = new HBaseSink(conf);    Configurables.configure(sink, ctx);    Channel channel = new MemoryChannel();    Configurables.configure(channel, new Context());    sink.setChannel(channel);    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    Event e = EventBuilder.withBody(Bytes.toBytes(valBase));    channel.put(e);    tx.commit();    tx.close();    sink.process();    sink.stop();    HTable table = new HTable(conf, tableName);    byte[][] results = getResults(table, 1);    byte[] out = results[0];    Assert.assertArrayEquals(e.getBody(), out);    out = results[1];    Assert.assertArrayEquals(Longs.toByteArray(1), out);}
c05b4c34d243c1058c356a62aa114fa3d7342e85de534d3ddbb238798e624217
testThreeEvents
public void testThreeEvents() throws Exception
{    initContextForSimpleHbaseEventSerializer();    ctx.put("batchSize", "3");    HBaseSink sink = new HBaseSink(conf);    Configurables.configure(sink, ctx);    Channel channel = new MemoryChannel();    Configurables.configure(channel, new Context());    sink.setChannel(channel);    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    for (int i = 0; i < 3; i++) {        Event e = EventBuilder.withBody(Bytes.toBytes(valBase + "-" + i));        channel.put(e);    }    tx.commit();    tx.close();    sink.process();    sink.stop();    HTable table = new HTable(conf, tableName);    byte[][] results = getResults(table, 3);    byte[] out;    int found = 0;    for (int i = 0; i < 3; i++) {        for (int j = 0; j < 3; j++) {            if (Arrays.equals(results[j], Bytes.toBytes(valBase + "-" + i))) {                found++;                break;            }        }    }    Assert.assertEquals(3, found);    out = results[3];    Assert.assertArrayEquals(Longs.toByteArray(3), out);}
3f903b698636f8b14fa3e1fe8deb6aecf348bfca091441835349ecd20a459d28
testMultipleBatches
public void testMultipleBatches() throws Exception
{    initContextForSimpleHbaseEventSerializer();    ctx.put("batchSize", "2");    HBaseSink sink = new HBaseSink(conf);    Configurables.configure(sink, ctx);        ctx.put("batchSize", "100");    Channel channel = new MemoryChannel();    Configurables.configure(channel, new Context());    sink.setChannel(channel);    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    for (int i = 0; i < 3; i++) {        Event e = EventBuilder.withBody(Bytes.toBytes(valBase + "-" + i));        channel.put(e);    }    tx.commit();    tx.close();    int count = 0;    while (sink.process() != Status.BACKOFF) {        count++;    }    sink.stop();    Assert.assertEquals(2, count);    HTable table = new HTable(conf, tableName);    byte[][] results = getResults(table, 3);    byte[] out;    int found = 0;    for (int i = 0; i < 3; i++) {        for (int j = 0; j < 3; j++) {            if (Arrays.equals(results[j], Bytes.toBytes(valBase + "-" + i))) {                found++;                break;            }        }    }    Assert.assertEquals(3, found);    out = results[3];    Assert.assertArrayEquals(Longs.toByteArray(3), out);}
e8aa60f990984f01933584d8ef5e772704995dd8b1d21a2a2d1c83e52649d4c5
testMissingTable
public void testMissingTable() throws Exception
{    logger.info("Running testMissingTable()");    initContextForSimpleHbaseEventSerializer();        logger.info("Deleting table {}", tableName);    testUtility.deleteTable(tableName.getBytes());    ctx.put("batchSize", "2");    HBaseSink sink = new HBaseSink(conf);    Configurables.configure(sink, ctx);        ctx.put("batchSize", "100");    Channel channel = new MemoryChannel();    Configurables.configure(channel, new Context());    sink.setChannel(channel);    logger.info("Writing data into channel");    Transaction tx = channel.getTransaction();    tx.begin();    for (int i = 0; i < 3; i++) {        Event e = EventBuilder.withBody(Bytes.toBytes(valBase + "-" + i));        channel.put(e);    }    tx.commit();    tx.close();    logger.info("Starting sink and processing events");    try {        logger.info("Calling sink.start()");                sink.start();                logger.error("Unexpected error: Calling sink.process()");        sink.process();        logger.error("Unexpected error: Calling sink.stop()");        sink.stop();    } finally {                testUtility.createTable(tableName.getBytes(), columnFamily.getBytes());    }        Assert.fail();    HTable table = new HTable(conf, tableName);    byte[][] results = getResults(table, 2);    byte[] out;    int found = 0;    for (int i = 0; i < 2; i++) {        for (int j = 0; j < 2; j++) {            if (Arrays.equals(results[j], Bytes.toBytes(valBase + "-" + i))) {                found++;                break;            }        }    }    Assert.assertEquals(2, found);    out = results[2];    Assert.assertArrayEquals(Longs.toByteArray(2), out);    sink.process();}
355c37328e8976d2ec4c6df516e928071228ec26717881cd804abf1b95f10070
testHBaseFailure
public void testHBaseFailure() throws Exception
{    initContextForSimpleHbaseEventSerializer();    ctx.put("batchSize", "2");    HBaseSink sink = new HBaseSink(conf);    Configurables.configure(sink, ctx);        ctx.put("batchSize", "100");    Channel channel = new MemoryChannel();    Configurables.configure(channel, new Context());    sink.setChannel(channel);    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    for (int i = 0; i < 3; i++) {        Event e = EventBuilder.withBody(Bytes.toBytes(valBase + "-" + i));        channel.put(e);    }    tx.commit();    tx.close();    sink.process();    HTable table = new HTable(conf, tableName);    byte[][] results = getResults(table, 2);    byte[] out;    int found = 0;    for (int i = 0; i < 2; i++) {        for (int j = 0; j < 2; j++) {            if (Arrays.equals(results[j], Bytes.toBytes(valBase + "-" + i))) {                found++;                break;            }        }    }    Assert.assertEquals(2, found);    out = results[2];    Assert.assertArrayEquals(Longs.toByteArray(2), out);    testUtility.shutdownMiniCluster();    sink.process();    sink.stop();}
ce84f8d9e7759c0f0ebbaf2020657daabcdb4b8d4dc44e2e6c91e2a538833adc
getResults
private byte[][] getResults(HTable table, int numEvents) throws IOException
{    byte[][] results = new byte[numEvents + 1][];    Scan scan = new Scan();    scan.addColumn(columnFamily.getBytes(), plCol.getBytes());    scan.setStartRow(Bytes.toBytes("default"));    ResultScanner rs = table.getScanner(scan);    byte[] out = null;    int i = 0;    try {        for (Result r = rs.next(); r != null; r = rs.next()) {            out = r.getValue(columnFamily.getBytes(), plCol.getBytes());            if (i >= results.length - 1) {                rs.close();                throw new FlumeException("More results than expected in the table." + "Expected = " + numEvents + ". Found = " + i);            }            results[i++] = out;            System.out.println(out);        }    } finally {        rs.close();    }    Assert.assertEquals(i, results.length - 1);    scan = new Scan();    scan.addColumn(columnFamily.getBytes(), inColumn.getBytes());    scan.setStartRow(Bytes.toBytes("incRow"));    rs = table.getScanner(scan);    out = null;    try {        for (Result r = rs.next(); r != null; r = rs.next()) {            out = r.getValue(columnFamily.getBytes(), inColumn.getBytes());            results[i++] = out;            System.out.println(out);        }    } finally {        rs.close();    }    return results;}
c8512dff1849f0fb0813d4c33c541ec33b4fbc83492688d67bcf2073693248a6
testTransactionStateOnChannelException
public void testTransactionStateOnChannelException() throws Exception
{    initContextForSimpleHbaseEventSerializer();    ctx.put("batchSize", "1");    HBaseSink sink = new HBaseSink(conf);    Configurables.configure(sink, ctx);        Channel channel = spy(new MemoryChannel());    Configurables.configure(channel, new Context());    sink.setChannel(channel);    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    Event e = EventBuilder.withBody(Bytes.toBytes(valBase + "-" + 0));    channel.put(e);    tx.commit();    tx.close();    doThrow(new ChannelException("Mock Exception")).when(channel).take();    try {        sink.process();        Assert.fail("take() method should throw exception");    } catch (ChannelException ex) {        Assert.assertEquals("Mock Exception", ex.getMessage());    }    doReturn(e).when(channel).take();    sink.process();    sink.stop();    HTable table = new HTable(conf, tableName);    byte[][] results = getResults(table, 1);    byte[] out = results[0];    Assert.assertArrayEquals(e.getBody(), out);    out = results[1];    Assert.assertArrayEquals(Longs.toByteArray(1), out);}
12e7e84bacf1e16cebd5d17e96d276a68f64edcf710170b8b999fc2e31195a14
testTransactionStateOnSerializationException
public void testTransactionStateOnSerializationException() throws Exception
{    initContextForSimpleHbaseEventSerializer();    ctx.put("batchSize", "1");    ctx.put(HBaseSinkConfigurationConstants.CONFIG_SERIALIZER, "org.apache.flume.sink.hbase.MockSimpleHbaseEventSerializer");    HBaseSink sink = new HBaseSink(conf);    Configurables.configure(sink, ctx);        ctx.put("batchSize", "100");    Channel channel = new MemoryChannel();    Configurables.configure(channel, new Context());    sink.setChannel(channel);    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    Event e = EventBuilder.withBody(Bytes.toBytes(valBase + "-" + 0));    channel.put(e);    tx.commit();    tx.close();    try {        MockSimpleHbaseEventSerializer.throwException = true;        sink.process();        Assert.fail("FlumeException expected from serilazer");    } catch (FlumeException ex) {        Assert.assertEquals("Exception for testing", ex.getMessage());    }    MockSimpleHbaseEventSerializer.throwException = false;    sink.process();    sink.stop();    HTable table = new HTable(conf, tableName);    byte[][] results = getResults(table, 1);    byte[] out = results[0];    Assert.assertArrayEquals(e.getBody(), out);    out = results[1];    Assert.assertArrayEquals(Longs.toByteArray(1), out);}
0e9b2a5968e2172ff1e8d345e371f21c9ae1ac933bcfba3c98b09b4491a8eab7
testWithoutConfigurationObject
public void testWithoutConfigurationObject() throws Exception
{    initContextForSimpleHbaseEventSerializer();    Context tmpContext = new Context(ctx.getParameters());    tmpContext.put("batchSize", "2");    tmpContext.put(HBaseSinkConfigurationConstants.ZK_QUORUM, ZKConfig.getZKQuorumServersString(conf));    System.out.print(ctx.getString(HBaseSinkConfigurationConstants.ZK_QUORUM));    tmpContext.put(HBaseSinkConfigurationConstants.ZK_ZNODE_PARENT, conf.get(HConstants.ZOOKEEPER_ZNODE_PARENT, HConstants.DEFAULT_ZOOKEEPER_ZNODE_PARENT));    HBaseSink sink = new HBaseSink();    Configurables.configure(sink, tmpContext);    Channel channel = new MemoryChannel();    Configurables.configure(channel, ctx);    sink.setChannel(channel);    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    for (int i = 0; i < 3; i++) {        Event e = EventBuilder.withBody(Bytes.toBytes(valBase + "-" + i));        channel.put(e);    }    tx.commit();    tx.close();    Status status = Status.READY;    while (status != Status.BACKOFF) {        status = sink.process();    }    sink.stop();    HTable table = new HTable(conf, tableName);    byte[][] results = getResults(table, 3);    byte[] out;    int found = 0;    for (int i = 0; i < 3; i++) {        for (int j = 0; j < 3; j++) {            if (Arrays.equals(results[j], Bytes.toBytes(valBase + "-" + i))) {                found++;                break;            }        }    }    Assert.assertEquals(3, found);    out = results[3];    Assert.assertArrayEquals(Longs.toByteArray(3), out);}
4201c9c540210b2150f4b43823f4a177e7bbd5a8a486fd809ed6eb797706c5af
testZKQuorum
public void testZKQuorum() throws Exception
{    initContextForSimpleHbaseEventSerializer();    Context tmpContext = new Context(ctx.getParameters());    String zkQuorum = "zk1.flume.apache.org:3342, zk2.flume.apache.org:3342, " + "zk3.flume.apache.org:3342";    tmpContext.put("batchSize", "2");    tmpContext.put(HBaseSinkConfigurationConstants.ZK_QUORUM, zkQuorum);    tmpContext.put(HBaseSinkConfigurationConstants.ZK_ZNODE_PARENT, conf.get(HConstants.ZOOKEEPER_ZNODE_PARENT, HConstants.DEFAULT_ZOOKEEPER_ZNODE_PARENT));    HBaseSink sink = new HBaseSink();    Configurables.configure(sink, tmpContext);    Assert.assertEquals("zk1.flume.apache.org,zk2.flume.apache.org," + "zk3.flume.apache.org", sink.getConfig().get(HConstants.ZOOKEEPER_QUORUM));    Assert.assertEquals(String.valueOf(3342), sink.getConfig().get(HConstants.ZOOKEEPER_CLIENT_PORT));}
16628512aff2c6df2f0fad6a2972538f9b37de86327c298937774caeadf35499
testZKQuorumIncorrectPorts
public void testZKQuorumIncorrectPorts() throws Exception
{    initContextForSimpleHbaseEventSerializer();    Context tmpContext = new Context(ctx.getParameters());    String zkQuorum = "zk1.flume.apache.org:3345, zk2.flume.apache.org:3342, " + "zk3.flume.apache.org:3342";    tmpContext.put("batchSize", "2");    tmpContext.put(HBaseSinkConfigurationConstants.ZK_QUORUM, zkQuorum);    tmpContext.put(HBaseSinkConfigurationConstants.ZK_ZNODE_PARENT, conf.get(HConstants.ZOOKEEPER_ZNODE_PARENT, HConstants.DEFAULT_ZOOKEEPER_ZNODE_PARENT));    HBaseSink sink = new HBaseSink();    Configurables.configure(sink, tmpContext);    Assert.fail();}
bfe59d0a2b5221060dfd2533cbc873055c810f24864acc7828bea6b71ede7f99
testCoalesce
public void testCoalesce() throws EventDeliveryException
{    initContextForIncrementHBaseSerializer();    ctx.put("batchSize", "100");    ctx.put(HBaseSinkConfigurationConstants.CONFIG_COALESCE_INCREMENTS, String.valueOf(true));    final Map<String, Long> expectedCounts = Maps.newHashMap();    expectedCounts.put("r1:c1", 10L);    expectedCounts.put("r1:c2", 20L);    expectedCounts.put("r2:c1", 7L);    expectedCounts.put("r2:c3", 63L);    HBaseSink.DebugIncrementsCallback cb = new CoalesceValidator(expectedCounts);    HBaseSink sink = new HBaseSink(testUtility.getConfiguration(), cb);    Configurables.configure(sink, ctx);    Channel channel = createAndConfigureMemoryChannel(sink);    List<Event> events = Lists.newLinkedList();    generateEvents(events, expectedCounts);    putEvents(channel, events);    sink.start();        sink.process();    sink.stop();}
ca970f8fdc1c2a52c1cbc93b4c32e7e9e3318cc5ce980e670aa3cddfbde84ea1
negativeTestCoalesce
public void negativeTestCoalesce() throws EventDeliveryException
{    initContextForIncrementHBaseSerializer();    ctx.put("batchSize", "10");    final Map<String, Long> expectedCounts = Maps.newHashMap();    expectedCounts.put("r1:c1", 10L);    HBaseSink.DebugIncrementsCallback cb = new CoalesceValidator(expectedCounts);    HBaseSink sink = new HBaseSink(testUtility.getConfiguration(), cb);    Configurables.configure(sink, ctx);    Channel channel = createAndConfigureMemoryChannel(sink);    List<Event> events = Lists.newLinkedList();    generateEvents(events, expectedCounts);    putEvents(channel, events);    sink.start();        sink.process();    sink.stop();}
0f0a2f6fa5f54c55df2635833d9ba0db35411959916e8b54298b187a36862ff7
testBatchAware
public void testBatchAware() throws EventDeliveryException
{    logger.info("Running testBatchAware()");    initContextForIncrementHBaseSerializer();    HBaseSink sink = new HBaseSink(testUtility.getConfiguration());    Configurables.configure(sink, ctx);    Channel channel = createAndConfigureMemoryChannel(sink);    sink.start();    int batchCount = 3;    for (int i = 0; i < batchCount; i++) {        sink.process();    }    sink.stop();    Assert.assertEquals(batchCount, ((IncrementHBaseSerializer) sink.getSerializer()).getNumBatchesStarted());}
0fb64ed9d23ed0fe7f55d32667ff30b1560720036f07d6b35bfe62ab8789b6ba
onAfterCoalesce
public void onAfterCoalesce(Iterable<Increment> increments)
{    for (Increment inc : increments) {        byte[] row = inc.getRow();        Map<byte[], NavigableMap<byte[], Long>> families = null;        try {            families = (Map<byte[], NavigableMap<byte[], Long>>) refGetFamilyMap.invoke(inc);        } catch (Exception e) {            Throwables.propagate(e);        }        for (byte[] family : families.keySet()) {            NavigableMap<byte[], Long> qualifiers = families.get(family);            for (Map.Entry<byte[], Long> entry : qualifiers.entrySet()) {                byte[] qualifier = entry.getKey();                Long count = entry.getValue();                StringBuilder b = new StringBuilder(20);                b.append(new String(row, Charsets.UTF_8));                b.append(':');                b.append(new String(qualifier, Charsets.UTF_8));                String key = b.toString();                Assert.assertEquals("Expected counts don't match observed for " + key, expectedCounts.get(key), count);            }        }    }}
de41a71161ec218beb33163177cf5b3ce7abbb42dbaf02236c46f21d366ee3bd
generateEvents
private void generateEvents(List<Event> events, Map<String, Long> counts)
{    for (String key : counts.keySet()) {        long count = counts.get(key);        for (long i = 0; i < count; i++) {            events.add(EventBuilder.withBody(key, Charsets.UTF_8));        }    }}
e44ae6501c79232dfa9b3daa58313b12780e8986acafb13a0b032b1d8c10ae67
createAndConfigureMemoryChannel
private Channel createAndConfigureMemoryChannel(HBaseSink sink)
{    Channel channel = new MemoryChannel();    Context channelCtx = new Context();    channelCtx.put("capacity", String.valueOf(1000L));    channelCtx.put("transactionCapacity", String.valueOf(1000L));    Configurables.configure(channel, channelCtx);    sink.setChannel(channel);    channel.start();    return channel;}
133c1ab001d9dd606bfe001f085e1e4f56d116d1276bca38fb1ed654e6925f59
putEvents
private void putEvents(Channel channel, Iterable<Event> events)
{    Transaction tx = channel.getTransaction();    tx.begin();    for (Event event : events) {        channel.put(event);    }    tx.commit();    tx.close();}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    sinkFactory = new DefaultSinkFactory();}
5274c226b630d9fd7c9cfa2368f625e10db12c5b1cdbe04968f1c296196c2408
verifySinkCreation
private void verifySinkCreation(String name, String type, Class<?> typeClass) throws FlumeException
{    Sink sink = sinkFactory.create(name, type);    Assert.assertNotNull(sink);    Assert.assertTrue(typeClass.isInstance(sink));}
66cf42a2fbf2ff4192d473ea28dd3a2c1d7389f68a166b0f208cb4cd791d921b
testSinkCreation
public void testSinkCreation()
{    verifySinkCreation("hbase-sink", "hbase", HBaseSink.class);    verifySinkCreation("asynchbase-sink", "asynchbase", AsyncHBaseSink.class);}
979dfbb00031b336e7b6d78731005bed4c3b9615e0032261d4248de2bfe94fb6
testDefaultBehavior
public void testDefaultBehavior() throws Exception
{    RegexHbaseEventSerializer s = new RegexHbaseEventSerializer();    Context context = new Context();    s.configure(context);    String logMsg = "The sky is falling!";    Event e = EventBuilder.withBody(Bytes.toBytes(logMsg));    s.initialize(e, "CF".getBytes());    List<Row> actions = s.getActions();    assertTrue(actions.size() == 1);    assertTrue(actions.get(0) instanceof Put);    Put put = (Put) actions.get(0);    assertTrue(put.getFamilyMap().containsKey(s.cf));    List<KeyValue> kvPairs = put.getFamilyMap().get(s.cf);    assertTrue(kvPairs.size() == 1);    Map<String, String> resultMap = Maps.newHashMap();    for (KeyValue kv : kvPairs) {        resultMap.put(new String(kv.getQualifier()), new String(kv.getValue()));    }    assertTrue(resultMap.containsKey(RegexHbaseEventSerializer.COLUMN_NAME_DEFAULT));    assertEquals("The sky is falling!", resultMap.get(RegexHbaseEventSerializer.COLUMN_NAME_DEFAULT));}
2f694841bfe643eba83a4ad5d847f1e22e37ca84e094710fbfac521982cde508
testRowIndexKey
public void testRowIndexKey() throws Exception
{    RegexHbaseEventSerializer s = new RegexHbaseEventSerializer();    Context context = new Context();    context.put(RegexHbaseEventSerializer.REGEX_CONFIG, "^([^\t]+)\t([^\t]+)\t" + "([^\t]+)$");    context.put(RegexHbaseEventSerializer.COL_NAME_CONFIG, "col1,col2,ROW_KEY");    context.put("rowKeyIndex", "2");    s.configure(context);    String body = "val1\tval2\trow1";    Event e = EventBuilder.withBody(Bytes.toBytes(body));    s.initialize(e, "CF".getBytes());    List<Row> actions = s.getActions();    Put put = (Put) actions.get(0);    List<KeyValue> kvPairs = put.getFamilyMap().get(s.cf);    assertTrue(kvPairs.size() == 2);    Map<String, String> resultMap = Maps.newHashMap();    for (KeyValue kv : kvPairs) {        resultMap.put(new String(kv.getQualifier()), new String(kv.getValue()));    }    assertEquals("val1", resultMap.get("col1"));    assertEquals("val2", resultMap.get("col2"));    assertEquals("row1", Bytes.toString(put.getRow()));}
252e1eaadb8c8953331476ffe9c761e4b7026415d73bdb16659a4862f51d6f76
testApacheRegex
public void testApacheRegex() throws Exception
{    RegexHbaseEventSerializer s = new RegexHbaseEventSerializer();    Context context = new Context();    context.put(RegexHbaseEventSerializer.REGEX_CONFIG, "([^ ]*) ([^ ]*) ([^ ]*) (-|\\[[^\\]]*\\]) \"([^ ]+) ([^ ]+)" + " ([^\"]+)\" (-|[0-9]*) (-|[0-9]*)(?: ([^ \"]*|\"[^\"]*\")" + " ([^ \"]*|\"[^\"]*\"))?");    context.put(RegexHbaseEventSerializer.COL_NAME_CONFIG, "host,identity,user,time,method,request,protocol,status,size," + "referer,agent");    s.configure(context);    String logMsg = "33.22.11.00 - - [20/May/2011:07:01:19 +0000] " + "\"GET /wp-admin/css/install.css HTTP/1.0\" 200 813 " + "\"http://www.cloudera.com/wp-admin/install.php\" \"Mozilla/5.0 (comp" + "atible; Yahoo! Slurp; http://help.yahoo.com/help/us/ysearch/slurp)\"";    Event e = EventBuilder.withBody(Bytes.toBytes(logMsg));    s.initialize(e, "CF".getBytes());    List<Row> actions = s.getActions();    assertEquals(1, s.getActions().size());    assertTrue(actions.get(0) instanceof Put);    Put put = (Put) actions.get(0);    assertTrue(put.getFamilyMap().containsKey(s.cf));    List<KeyValue> kvPairs = put.getFamilyMap().get(s.cf);    assertTrue(kvPairs.size() == 11);    Map<String, String> resultMap = Maps.newHashMap();    for (KeyValue kv : kvPairs) {        resultMap.put(new String(kv.getQualifier()), new String(kv.getValue()));    }    assertEquals("33.22.11.00", resultMap.get("host"));    assertEquals("-", resultMap.get("identity"));    assertEquals("-", resultMap.get("user"));    assertEquals("[20/May/2011:07:01:19 +0000]", resultMap.get("time"));    assertEquals("GET", resultMap.get("method"));    assertEquals("/wp-admin/css/install.css", resultMap.get("request"));    assertEquals("HTTP/1.0", resultMap.get("protocol"));    assertEquals("200", resultMap.get("status"));    assertEquals("813", resultMap.get("size"));    assertEquals("\"http://www.cloudera.com/wp-admin/install.php\"", resultMap.get("referer"));    assertEquals("\"Mozilla/5.0 (compatible; Yahoo! Slurp; " + "http://help.yahoo.com/help/us/ysearch/slurp)\"", resultMap.get("agent"));    List<Increment> increments = s.getIncrements();    assertEquals(0, increments.size());}
6f872d3644c0cb9a429b536caaa6c0d0915c033caaf1cb96f5414383b3db156d
testRowKeyGeneration
public void testRowKeyGeneration()
{    Context context = new Context();    RegexHbaseEventSerializer s1 = new RegexHbaseEventSerializer();    s1.configure(context);    RegexHbaseEventSerializer s2 = new RegexHbaseEventSerializer();    s2.configure(context);        RegexHbaseEventSerializer.nonce.set(0);    String randomString = RegexHbaseEventSerializer.randomKey;    Event e1 = EventBuilder.withBody(Bytes.toBytes("body"));    Event e2 = EventBuilder.withBody(Bytes.toBytes("body"));    Event e3 = EventBuilder.withBody(Bytes.toBytes("body"));    Calendar cal = mock(Calendar.class);    when(cal.getTimeInMillis()).thenReturn(1L);    s1.initialize(e1, "CF".getBytes());    String rk1 = new String(s1.getRowKey(cal));    assertEquals("1-" + randomString + "-0", rk1);    when(cal.getTimeInMillis()).thenReturn(10L);    s1.initialize(e2, "CF".getBytes());    String rk2 = new String(s1.getRowKey(cal));    assertEquals("10-" + randomString + "-1", rk2);    when(cal.getTimeInMillis()).thenReturn(100L);    s2.initialize(e3, "CF".getBytes());    String rk3 = new String(s2.getRowKey(cal));    assertEquals("100-" + randomString + "-2", rk3);}
ef2312732288af0f7a3192ca99173af7a63416dd2807b3d83cf8d3693bcd6294
testDepositHeaders
public void testDepositHeaders() throws Exception
{    Charset charset = Charset.forName("KOI8-R");    RegexHbaseEventSerializer s = new RegexHbaseEventSerializer();    Context context = new Context();    context.put(RegexHbaseEventSerializer.DEPOSIT_HEADERS_CONFIG, "true");    context.put(RegexHbaseEventSerializer.CHARSET_CONFIG, charset.toString());    s.configure(context);    String body = "body";    Map<String, String> headers = Maps.newHashMap();    headers.put("header1", "value1");    headers.put("заголовок2", "значение2");    Event e = EventBuilder.withBody(Bytes.toBytes(body), headers);    s.initialize(e, "CF".getBytes());    List<Row> actions = s.getActions();    assertEquals(1, s.getActions().size());    assertTrue(actions.get(0) instanceof Put);    Put put = (Put) actions.get(0);    assertTrue(put.getFamilyMap().containsKey(s.cf));    List<KeyValue> kvPairs = put.getFamilyMap().get(s.cf);    assertTrue(kvPairs.size() == 3);    Map<String, byte[]> resultMap = Maps.newHashMap();    for (KeyValue kv : kvPairs) {        resultMap.put(new String(kv.getQualifier(), charset), kv.getValue());    }    assertEquals(body, new String(resultMap.get(RegexHbaseEventSerializer.COLUMN_NAME_DEFAULT), charset));    assertEquals("value1", new String(resultMap.get("header1"), charset));    assertArrayEquals("значение2".getBytes(charset), resultMap.get("заголовок2"));    assertEquals("значение2".length(), resultMap.get("заголовок2").length);    List<Increment> increments = s.getIncrements();    assertEquals(0, increments.size());}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    Preconditions.checkArgument(table == null, "Please call stop " + "before calling start on an old instance.");    try {        privilegedExecutor = FlumeAuthenticationUtil.getAuthenticator(kerberosPrincipal, kerberosKeytab);    } catch (Exception ex) {        sinkCounter.incrementConnectionFailedCount();        throw new FlumeException("Failed to login to HBase using " + "provided credentials.", ex);    }    try {        conn = privilegedExecutor.execute((PrivilegedExceptionAction<Connection>) () -> {            conn = ConnectionFactory.createConnection(config);            return conn;        });                        table = conn.getBufferedMutator(TableName.valueOf(tableName));    } catch (Exception e) {        sinkCounter.incrementConnectionFailedCount();        logger.error("Could not load table, " + tableName + " from HBase", e);        throw new FlumeException("Could not load table, " + tableName + " from HBase", e);    }    try {        if (!privilegedExecutor.execute((PrivilegedExceptionAction<Boolean>) () -> {            Table t = null;            try {                t = conn.getTable(TableName.valueOf(tableName));                return t.getTableDescriptor().hasFamily(columnFamily);            } finally {                if (t != null) {                    t.close();                }            }        })) {            throw new IOException("Table " + tableName + " has no such column family " + Bytes.toString(columnFamily));        }    } catch (Exception e) {                        sinkCounter.incrementConnectionFailedCount();        throw new FlumeException("Error getting column family from HBase." + "Please verify that the table " + tableName + " and Column Family, " + Bytes.toString(columnFamily) + " exists in HBase, and the" + " current user has permissions to access that table.", e);    }    super.start();    sinkCounter.incrementConnectionCreatedCount();    sinkCounter.start();}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    try {        if (table != null) {            table.close();        }        table = null;    } catch (IOException e) {        throw new FlumeException("Error closing table.", e);    }    try {        if (conn != null) {            conn.close();        }        conn = null;    } catch (IOException e) {        throw new FlumeException("Error closing connection.", e);    }    sinkCounter.incrementConnectionClosedCount();    sinkCounter.stop();}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    if (!this.hasVersionAtLeast2()) {        throw new ConfigurationException("HBase major version number must be at least 2 for hbase2sink");    }    tableName = context.getString(HBase2SinkConfigurationConstants.CONFIG_TABLE);    String cf = context.getString(HBase2SinkConfigurationConstants.CONFIG_COLUMN_FAMILY);    batchSize = context.getLong(HBase2SinkConfigurationConstants.CONFIG_BATCHSIZE, 100L);    Context serializerContext = new Context();        String eventSerializerType = context.getString(HBase2SinkConfigurationConstants.CONFIG_SERIALIZER);    Preconditions.checkNotNull(tableName, "Table name cannot be empty, please specify in configuration file");    Preconditions.checkNotNull(cf, "Column family cannot be empty, please specify in configuration file");        if (eventSerializerType == null || eventSerializerType.isEmpty()) {        eventSerializerType = "org.apache.flume.sink.hbase2.SimpleHBase2EventSerializer";        logger.info("No serializer defined, Will use default");    }    serializerContext.putAll(context.getSubProperties(HBase2SinkConfigurationConstants.CONFIG_SERIALIZER_PREFIX));    columnFamily = cf.getBytes(Charsets.UTF_8);    try {        Class<? extends HBase2EventSerializer> clazz = (Class<? extends HBase2EventSerializer>) Class.forName(eventSerializerType);        serializer = clazz.newInstance();        serializer.configure(serializerContext);    } catch (Exception e) {        logger.error("Could not instantiate event serializer.", e);        Throwables.propagate(e);    }    kerberosKeytab = context.getString(HBase2SinkConfigurationConstants.CONFIG_KEYTAB);    kerberosPrincipal = context.getString(HBase2SinkConfigurationConstants.CONFIG_PRINCIPAL);    enableWal = context.getBoolean(HBase2SinkConfigurationConstants.CONFIG_ENABLE_WAL, HBase2SinkConfigurationConstants.DEFAULT_ENABLE_WAL);    logger.info("The write to WAL option is set to: " + String.valueOf(enableWal));    if (!enableWal) {        logger.warn("HBase Sink's enableWal configuration is set to false. All " + "writes to HBase will have WAL disabled, and any data in the " + "memstore of this region in the Region Server could be lost!");    }    batchIncrements = context.getBoolean(HBase2SinkConfigurationConstants.CONFIG_COALESCE_INCREMENTS, HBase2SinkConfigurationConstants.DEFAULT_COALESCE_INCREMENTS);    if (batchIncrements) {        logger.info("Increment coalescing is enabled. Increments will be " + "buffered.");    }    String zkQuorum = context.getString(HBase2SinkConfigurationConstants.ZK_QUORUM);    Integer port = null;    /*     * HBase allows multiple nodes in the quorum, but all need to use the     * same client port. So get the nodes in host:port format,     * and ignore the ports for all nodes except the first one. If no port is     * specified, use default.     */    if (zkQuorum != null && !zkQuorum.isEmpty()) {        StringBuilder zkBuilder = new StringBuilder();        logger.info("Using ZK Quorum: " + zkQuorum);        String[] zkHosts = zkQuorum.split(",");        int length = zkHosts.length;        for (int i = 0; i < length; i++) {            String[] zkHostAndPort = zkHosts[i].split(":");            zkBuilder.append(zkHostAndPort[0].trim());            if (i != length - 1) {                zkBuilder.append(",");            } else {                zkQuorum = zkBuilder.toString();            }            if (zkHostAndPort[1] == null) {                throw new FlumeException("Expected client port for the ZK node!");            }            if (port == null) {                port = Integer.parseInt(zkHostAndPort[1].trim());            } else if (!port.equals(Integer.parseInt(zkHostAndPort[1].trim()))) {                throw new FlumeException("All Zookeeper nodes in the quorum must " + "use the same client port.");            }        }        if (port == null) {            port = HConstants.DEFAULT_ZOOKEPER_CLIENT_PORT;        }        this.config.set(HConstants.ZOOKEEPER_QUORUM, zkQuorum);        this.config.setInt(HConstants.ZOOKEEPER_CLIENT_PORT, port);    }    String hbaseZnode = context.getString(HBase2SinkConfigurationConstants.ZK_ZNODE_PARENT);    if (hbaseZnode != null && !hbaseZnode.isEmpty()) {        this.config.set(HConstants.ZOOKEEPER_ZNODE_PARENT, hbaseZnode);    }    sinkCounter = new SinkCounter(this.getName());}
15fc7b435a67fff3a8a6d4f3247065fc8d3a4a40e90958e753eaafbc7f71ad66
getConfig
public Configuration getConfig()
{    return config;}
e52e5e378330fd7f87ee30351bbfcec47b751fee12ece2ef0cfdd77a08c906e1
process
public Status process() throws EventDeliveryException
{    Status status = Status.READY;    Channel channel = getChannel();    Transaction txn = channel.getTransaction();    List<Row> actions = new LinkedList<>();    List<Increment> incs = new LinkedList<>();    try {        txn.begin();        if (serializer instanceof BatchAware) {            ((BatchAware) serializer).onBatchStart();        }        long i = 0;        for (; i < batchSize; i++) {            Event event = channel.take();            if (event == null) {                if (i == 0) {                    status = Status.BACKOFF;                    sinkCounter.incrementBatchEmptyCount();                } else {                    sinkCounter.incrementBatchUnderflowCount();                }                break;            } else {                serializer.initialize(event, columnFamily);                actions.addAll(serializer.getActions());                incs.addAll(serializer.getIncrements());            }        }        if (i == batchSize) {            sinkCounter.incrementBatchCompleteCount();        }        sinkCounter.addToEventDrainAttemptCount(i);        putEventsAndCommit(actions, incs, txn);    } catch (Throwable e) {        try {            txn.rollback();        } catch (Exception e2) {            logger.error("Exception in rollback. Rollback might not have been " + "successful.", e2);        }        logger.error("Failed to commit transaction." + "Transaction rolled back.", e);        sinkCounter.incrementEventWriteOrChannelFail(e);        if (e instanceof Error || e instanceof RuntimeException) {            logger.error("Failed to commit transaction." + "Transaction rolled back.", e);            Throwables.propagate(e);        } else {            logger.error("Failed to commit transaction." + "Transaction rolled back.", e);            throw new EventDeliveryException("Failed to commit transaction." + "Transaction rolled back.", e);        }    } finally {        txn.close();    }    return status;}
641f81b345b46ee6656bb18ab736a7c2dd0536395d9eaf8cdb7a092fa1ee7818
putEventsAndCommit
private void putEventsAndCommit(final List<Row> actions, final List<Increment> incs, Transaction txn) throws Exception
{    privilegedExecutor.execute((PrivilegedExceptionAction<Void>) () -> {        final List<Mutation> mutations = new ArrayList<>(actions.size());        for (Row r : actions) {            if (r instanceof Put) {                ((Put) r).setDurability(enableWal ? Durability.USE_DEFAULT : Durability.SKIP_WAL);            }                        if (r instanceof Increment) {                ((Increment) r).setDurability(enableWal ? Durability.USE_DEFAULT : Durability.SKIP_WAL);            }            if (r instanceof Mutation) {                mutations.add((Mutation) r);            } else {                logger.warn("dropping row " + r + " since it is not an Increment or Put");            }        }        table.mutate(mutations);        table.flush();        return null;    });    privilegedExecutor.execute((PrivilegedExceptionAction<Void>) () -> {        List<Increment> processedIncrements;        if (batchIncrements) {            processedIncrements = coalesceIncrements(incs);        } else {            processedIncrements = incs;        }                if (debugIncrCallback != null) {            debugIncrCallback.onAfterCoalesce(processedIncrements);        }        for (final Increment i : processedIncrements) {            i.setDurability(enableWal ? Durability.USE_DEFAULT : Durability.SKIP_WAL);            table.mutate(i);        }        table.flush();        return null;    });    txn.commit();    sinkCounter.addToEventDrainSuccessCount(actions.size());}
65f96773081e3df143ada852dae0b0994e63ea12d5b2a16fea20fecaf8bb38df
getFamilyMap
private Map<byte[], NavigableMap<byte[], Long>> getFamilyMap(Increment inc)
{    Preconditions.checkNotNull(inc, "Increment required");    return inc.getFamilyMapOfLongs();}
3b2e979c13d5f43f2635cb287c4a27f0e0eb50841c2bb3e828b13cf80c02147a
coalesceIncrements
private List<Increment> coalesceIncrements(Iterable<Increment> incs)
{    Preconditions.checkNotNull(incs, "List of Increments must not be null");            Map<byte[], Map<byte[], NavigableMap<byte[], Long>>> counters = Maps.newTreeMap(Bytes.BYTES_COMPARATOR);    for (Increment inc : incs) {        byte[] row = inc.getRow();        Map<byte[], NavigableMap<byte[], Long>> families = getFamilyMap(inc);        for (Map.Entry<byte[], NavigableMap<byte[], Long>> familyEntry : families.entrySet()) {            byte[] family = familyEntry.getKey();            NavigableMap<byte[], Long> qualifiers = familyEntry.getValue();            for (Map.Entry<byte[], Long> qualifierEntry : qualifiers.entrySet()) {                byte[] qualifier = qualifierEntry.getKey();                Long count = qualifierEntry.getValue();                incrementCounter(counters, row, family, qualifier, count);            }        }    }        List<Increment> coalesced = Lists.newLinkedList();    for (Map.Entry<byte[], Map<byte[], NavigableMap<byte[], Long>>> rowEntry : counters.entrySet()) {        byte[] row = rowEntry.getKey();        Map<byte[], NavigableMap<byte[], Long>> families = rowEntry.getValue();        Increment inc = new Increment(row);        for (Map.Entry<byte[], NavigableMap<byte[], Long>> familyEntry : families.entrySet()) {            byte[] family = familyEntry.getKey();            NavigableMap<byte[], Long> qualifiers = familyEntry.getValue();            for (Map.Entry<byte[], Long> qualifierEntry : qualifiers.entrySet()) {                byte[] qualifier = qualifierEntry.getKey();                long count = qualifierEntry.getValue();                inc.addColumn(family, qualifier, count);            }        }        coalesced.add(inc);    }    return coalesced;}
c0fd3a9260c47a5d7fa52067a6ffef6e4dcc22e15e68d3a229fef932d388d359
incrementCounter
private void incrementCounter(Map<byte[], Map<byte[], NavigableMap<byte[], Long>>> counters, byte[] row, byte[] family, byte[] qualifier, Long count)
{    Map<byte[], NavigableMap<byte[], Long>> families = counters.computeIfAbsent(row, k -> Maps.newTreeMap(Bytes.BYTES_COMPARATOR));    NavigableMap<byte[], Long> qualifiers = families.computeIfAbsent(family, k -> Maps.newTreeMap(Bytes.BYTES_COMPARATOR));    qualifiers.merge(qualifier, count, (a, b) -> a + b);}
cf816977517d1abc78860134c9e8e5b62d2ae99604d896ea7f27299a7123fb56
getHBbaseVersionString
 String getHBbaseVersionString()
{    return VersionInfo.getVersion();}
8c813677eae853b3bb0f638dba68fa3fc5da08daa894a206e97e616d04d87de6
getMajorVersion
private int getMajorVersion(String version) throws NumberFormatException
{    return Integer.parseInt(version.split("\\.")[0]);}
d86743adc99ad09b74f6c225c2207694aae4c465a428bdc37184fe709d843593
hasVersionAtLeast2
private boolean hasVersionAtLeast2()
{    String version = getHBbaseVersionString();    try {        if (this.getMajorVersion(version) >= 2) {            return true;        }    } catch (NumberFormatException ex) {        logger.error(ex.getMessage());    }    logger.error("Invalid HBase version for hbase2sink:" + version);    return false;}
85477afc47250d36f3c97a7f45e77e93f5cf628a5475129c129a2c001f80fb8a
getSerializer
 HBase2EventSerializer getSerializer()
{    return serializer;}
dcc511f35190533c2d6fcc6073d66b12e111f5004c64ff08ccc3609a06ab844d
getBatchSize
public long getBatchSize()
{    return batchSize;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    String regex = context.getString(REGEX_CONFIG, REGEX_DEFAULT);    boolean regexIgnoreCase = context.getBoolean(IGNORE_CASE_CONFIG, IGNORE_CASE_DEFAULT);    depositHeaders = context.getBoolean(DEPOSIT_HEADERS_CONFIG, DEPOSIT_HEADERS_DEFAULT);    inputPattern = Pattern.compile(regex, Pattern.DOTALL + (regexIgnoreCase ? Pattern.CASE_INSENSITIVE : 0));    charset = Charset.forName(context.getString(CHARSET_CONFIG, CHARSET_DEFAULT));    String colNameStr = context.getString(COL_NAME_CONFIG, COLUMN_NAME_DEFAULT);    String[] columnNames = colNameStr.split(",");    for (String s : columnNames) {        colNames.add(s.getBytes(charset));    }        rowKeyIndex = context.getInteger(ROW_KEY_INDEX_CONFIG, -1);        if (rowKeyIndex >= 0) {        if (rowKeyIndex >= columnNames.length) {            throw new IllegalArgumentException(ROW_KEY_INDEX_CONFIG + " must be " + "less than num columns " + columnNames.length);        }        if (!ROW_KEY_NAME.equalsIgnoreCase(columnNames[rowKeyIndex])) {            throw new IllegalArgumentException("Column at " + rowKeyIndex + " must be " + ROW_KEY_NAME + " and is " + columnNames[rowKeyIndex]);        }    }}
57746d8a7acafcf5647f649109937334de6090302f29c32ed7da0df311700e35
configure
public void configure(ComponentConfiguration conf)
{}
f72c511dfbc4e6d86273515cc0b62b8c1b4636d26d61e1784f67de94e1a6722c
initialize
public void initialize(Event event, byte[] columnFamily)
{    this.headers = event.getHeaders();    this.payload = event.getBody();    this.cf = columnFamily;}
3bc9a2898081d6e57a180f44ee76b1941a578d44f384af17bc015dadf56497a3
getRowKey
protected byte[] getRowKey(Calendar cal)
{    /* NOTE: This key generation strategy has the following properties:     *      * 1) Within a single JVM, the same row key will never be duplicated.     * 2) Amongst any two JVM's operating at different time periods (according     *    to their respective clocks), the same row key will never be      *    duplicated.     * 3) Amongst any two JVM's operating concurrently (according to their     *    respective clocks), the odds of duplicating a row-key are non-zero     *    but infinitesimal. This would require simultaneous collision in (a)      *    the timestamp (b) the respective nonce and (c) the random string.     *    The string is necessary since (a) and (b) could collide if a fleet     *    of Flume agents are restarted in tandem.     *         *  Row-key uniqueness is important because conflicting row-keys will cause     *  data loss. */    String rowKey = String.format("%s-%s-%s", cal.getTimeInMillis(), randomKey, nonce.getAndIncrement());    return rowKey.getBytes(charset);}
fa04a120c620eb491746134bf656460ba7b99f32ae0215b5223a6769cf008f6d
getRowKey
protected byte[] getRowKey()
{    return getRowKey(Calendar.getInstance());}
dc71e0855cdad821f5c5816dac8946a22b961a0e027f83663aa27e3d1d935379
getActions
public List<Row> getActions() throws FlumeException
{    List<Row> actions = Lists.newArrayList();    byte[] rowKey;    Matcher m = inputPattern.matcher(new String(payload, charset));    if (!m.matches()) {        return Lists.newArrayList();    }    if (m.groupCount() != colNames.size()) {        return Lists.newArrayList();    }    try {        if (rowKeyIndex < 0) {            rowKey = getRowKey();        } else {            rowKey = m.group(rowKeyIndex + 1).getBytes(Charsets.UTF_8);        }        Put put = new Put(rowKey);        for (int i = 0; i < colNames.size(); i++) {            if (i != rowKeyIndex) {                put.addColumn(cf, colNames.get(i), m.group(i + 1).getBytes(Charsets.UTF_8));            }        }        if (depositHeaders) {            for (Map.Entry<String, String> entry : headers.entrySet()) {                put.addColumn(cf, entry.getKey().getBytes(charset), entry.getValue().getBytes(charset));            }        }        actions.add(put);    } catch (Exception e) {        throw new FlumeException("Could not get row key!", e);    }    return actions;}
30f5c2bb6c32ae5f4ae7d54354298647a3d168c0ed3177fbac8f4e79028a6044
getIncrements
public List<Increment> getIncrements()
{    return Lists.newArrayList();}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    rowPrefix = context.getString("rowPrefix", "default");    incrementRow = context.getString("incrementRow", "incRow").getBytes(Charsets.UTF_8);    String suffix = context.getString("suffix", "uuid");    String payloadColumn = context.getString("payloadColumn", "pCol");    String incColumn = context.getString("incrementColumn", "iCol");    if (payloadColumn != null && !payloadColumn.isEmpty()) {        switch(suffix) {            case "timestamp":                keyType = KeyType.TS;                break;            case "random":                keyType = KeyType.RANDOM;                break;            case "nano":                keyType = KeyType.TSNANO;                break;            default:                keyType = KeyType.UUID;                break;        }        plCol = payloadColumn.getBytes(Charsets.UTF_8);    }    if (incColumn != null && !incColumn.isEmpty()) {        incCol = incColumn.getBytes(Charsets.UTF_8);    }}
57746d8a7acafcf5647f649109937334de6090302f29c32ed7da0df311700e35
configure
public void configure(ComponentConfiguration conf)
{}
1e3a2697d7a8ae5b31238efacec1090b7d4313e62f34b514c08131ba1b656038
initialize
public void initialize(Event event, byte[] cf)
{    this.payload = event.getBody();    this.cf = cf;}
dc71e0855cdad821f5c5816dac8946a22b961a0e027f83663aa27e3d1d935379
getActions
public List<Row> getActions() throws FlumeException
{    List<Row> actions = new LinkedList<>();    if (plCol != null) {        byte[] rowKey;        try {            if (keyType == KeyType.TS) {                rowKey = SimpleRowKeyGenerator.getTimestampKey(rowPrefix);            } else if (keyType == KeyType.RANDOM) {                rowKey = SimpleRowKeyGenerator.getRandomKey(rowPrefix);            } else if (keyType == KeyType.TSNANO) {                rowKey = SimpleRowKeyGenerator.getNanoTimestampKey(rowPrefix);            } else {                rowKey = SimpleRowKeyGenerator.getUUIDKey(rowPrefix);            }            Put put = new Put(rowKey);            put.addColumn(cf, plCol, payload);            actions.add(put);        } catch (Exception e) {            throw new FlumeException("Could not get row key!", e);        }    }    return actions;}
30f5c2bb6c32ae5f4ae7d54354298647a3d168c0ed3177fbac8f4e79028a6044
getIncrements
public List<Increment> getIncrements()
{    List<Increment> incs = new LinkedList<>();    if (incCol != null) {        Increment inc = new Increment(incrementRow);        inc.addColumn(cf, incCol, 1);        incs.add(inc);    }    return incs;}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{}
c7130b8afbcc7ce9fe32c2b14f444b3f25813dacdbad0a87c31d2dcff90f020f
getUUIDKey
public static byte[] getUUIDKey(String prefix) throws UnsupportedEncodingException
{    return (prefix + UUID.randomUUID().toString()).getBytes("UTF8");}
a177b3e67a82d5686d56866e34769238013256e67dc03c231cd8a70cc7bc159a
getRandomKey
public static byte[] getRandomKey(String prefix) throws UnsupportedEncodingException
{    return (prefix + String.valueOf(new Random().nextLong())).getBytes("UTF8");}
4c43d08f084023c5daea80c36221f054db0477eba47af98d8d7612f6f928f466
getTimestampKey
public static byte[] getTimestampKey(String prefix) throws UnsupportedEncodingException
{    return (prefix + String.valueOf(System.currentTimeMillis())).getBytes("UTF8");}
8a860669c59e13a99489f103db96c928b4a20c55fb151764983167f38e29afe8
getNanoTimestampKey
public static byte[] getNanoTimestampKey(String prefix) throws UnsupportedEncodingException
{    return (prefix + String.valueOf(System.nanoTime())).getBytes("UTF8");}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{}
57746d8a7acafcf5647f649109937334de6090302f29c32ed7da0df311700e35
configure
public void configure(ComponentConfiguration conf)
{}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{}
f72c511dfbc4e6d86273515cc0b62b8c1b4636d26d61e1784f67de94e1a6722c
initialize
public void initialize(Event event, byte[] columnFamily)
{    this.event = event;    this.family = columnFamily;}
6a7d67d80ca0653acaa8148e627f5cff1686e1b28feba4e7c314b569249d834d
getActions
public List<Row> getActions()
{    return Collections.emptyList();}
30f5c2bb6c32ae5f4ae7d54354298647a3d168c0ed3177fbac8f4e79028a6044
getIncrements
public List<Increment> getIncrements()
{    List<Increment> increments = Lists.newArrayList();    String body = new String(event.getBody(), Charsets.UTF_8);    String[] pieces = body.split(":");    String row = pieces[0];    String qualifier = pieces[1];    Increment inc = new Increment(row.getBytes(Charsets.UTF_8));    inc.addColumn(family, qualifier.getBytes(Charsets.UTF_8), 1L);    increments.add(inc);    return increments;}
a196e3eb093f17c5939a62e311dd520f2babe5f04026ca0e27f7d2fadc8abbfe
onBatchStart
public void onBatchStart()
{    numBatchesStarted++;}
1a6f98b4d962deb6896b6be1fcf50bda9fe32d3b065444013fbee63607d7b049
getNumBatchesStarted
public int getNumBatchesStarted()
{    return numBatchesStarted;}
dc71e0855cdad821f5c5816dac8946a22b961a0e027f83663aa27e3d1d935379
getActions
public List<Row> getActions() throws FlumeException
{    if (throwException) {        throw new FlumeException("Exception for testing");    }    return super.getActions();}
ced4aede7c26d4b8c5fcbaf3c0e5acc033cd3ca9b285b7a9dd487898263fae25
setUpOnce
public static void setUpOnce() throws Exception
{    String hbaseVer = org.apache.hadoop.hbase.util.VersionInfo.getVersion();    System.out.println("HBASE VERSION:" + hbaseVer);    Configuration conf = HBaseConfiguration.create();    conf.setBoolean("hbase.localcluster.assign.random.ports", true);    testUtility = new HBaseTestingUtility(conf);    testUtility.startMiniCluster();}
7b231424694ad77be7196fe8ea50e232e329c5c7152a1231b645bfd43d46fbd0
tearDownOnce
public static void tearDownOnce() throws Exception
{    testUtility.shutdownMiniCluster();}
c536957a0359efaba4fa041a9429ed02027b66c9e6f5cc21d07eb308cc675a0d
setUp
public void setUp() throws IOException
{    conf = new Configuration(testUtility.getConfiguration());    testUtility.createTable(TableName.valueOf(tableName), columnFamily.getBytes());}
b15ec24534831cd8187de4c70ba4518879af91358fd307c4f306a42afcccad2c
tearDown
public void tearDown() throws IOException
{    testUtility.deleteTable(TableName.valueOf(tableName));}
d6c67d7281a9a8fe10af4aa22cdbc40c2adb6bacb0658ed8f614e41949cc3ab7
getContextForSimpleHBase2EventSerializer
private Context getContextForSimpleHBase2EventSerializer()
{    Context ctx = new Context();    ctx.put("table", tableName);    ctx.put("columnFamily", columnFamily);    ctx.put("serializer", SimpleHBase2EventSerializer.class.getName());    ctx.put("serializer.payloadColumn", plCol);    ctx.put("serializer.incrementColumn", inColumn);    return ctx;}
1084e40f2ddb18456bfd6c42e87f47f3be49cff1c440e2b81b83e95f2b0dae1c
getContextForIncrementHBaseSerializer
private Context getContextForIncrementHBaseSerializer()
{    Context ctx = new Context();    ctx.put("table", tableName);    ctx.put("columnFamily", columnFamily);    ctx.put("serializer", IncrementHBase2Serializer.class.getName());    return ctx;}
bf6e78280c893c32d77c77382cd2697f70353fd6828bef0d97edff04fab5fe66
getContextWithoutIncrementHBaseSerializer
private Context getContextWithoutIncrementHBaseSerializer()
{        Context ctx = new Context();    ctx.put("table", tableName);    ctx.put("columnFamily", columnFamily);    ctx.put("serializer", SimpleHBase2EventSerializer.class.getName());    return ctx;}
166ec667ea0b32d61d4516f23e7e6ca766427a663b608ab260190838a691ea21
testOneEventWithDefaults
public void testOneEventWithDefaults() throws Exception
{    Context ctx = getContextWithoutIncrementHBaseSerializer();    HBase2Sink sink = new HBase2Sink(conf);    Configurables.configure(sink, ctx);    Channel channel = new MemoryChannel();    Configurables.configure(channel, new Context());    sink.setChannel(channel);    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    Event e = EventBuilder.withBody(Bytes.toBytes(valBase));    channel.put(e);    tx.commit();    tx.close();    sink.process();    sink.stop();    try (Connection connection = ConnectionFactory.createConnection(conf);        Table table = connection.getTable(TableName.valueOf(tableName))) {        byte[][] results = getResults(table, 1);        byte[] out = results[0];        Assert.assertArrayEquals(e.getBody(), out);        out = results[1];        Assert.assertArrayEquals(Longs.toByteArray(1), out);    }}
0a8cf36588251f47ca1cf7facc48a8cdeae477e351d60ef85141ac1e8acd21e9
testOneEvent
public void testOneEvent() throws Exception
{    Context ctx = getContextForSimpleHBase2EventSerializer();    HBase2Sink sink = new HBase2Sink(conf);    Configurables.configure(sink, ctx);    Channel channel = new MemoryChannel();    Configurables.configure(channel, new Context());    sink.setChannel(channel);    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    Event e = EventBuilder.withBody(Bytes.toBytes(valBase));    channel.put(e);    tx.commit();    tx.close();    sink.process();    sink.stop();    try (Connection connection = ConnectionFactory.createConnection(conf);        Table table = connection.getTable(TableName.valueOf(tableName))) {        byte[][] results = getResults(table, 1);        byte[] out = results[0];        Assert.assertArrayEquals(e.getBody(), out);        out = results[1];        Assert.assertArrayEquals(Longs.toByteArray(1), out);    }}
c05b4c34d243c1058c356a62aa114fa3d7342e85de534d3ddbb238798e624217
testThreeEvents
public void testThreeEvents() throws Exception
{    Context ctx = getContextForSimpleHBase2EventSerializer();    ctx.put("batchSize", "3");    HBase2Sink sink = new HBase2Sink(conf);    Configurables.configure(sink, ctx);    Channel channel = new MemoryChannel();    Configurables.configure(channel, new Context());    sink.setChannel(channel);    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    for (int i = 0; i < 3; i++) {        Event e = EventBuilder.withBody(Bytes.toBytes(valBase + "-" + i));        channel.put(e);    }    tx.commit();    tx.close();    sink.process();    sink.stop();    try (Connection connection = ConnectionFactory.createConnection(conf);        Table table = connection.getTable(TableName.valueOf(tableName))) {        byte[][] results = getResults(table, 3);        byte[] out;        int found = 0;        for (int i = 0; i < 3; i++) {            for (int j = 0; j < 3; j++) {                if (Arrays.equals(results[j], Bytes.toBytes(valBase + "-" + i))) {                    found++;                    break;                }            }        }        Assert.assertEquals(3, found);        out = results[3];        Assert.assertArrayEquals(Longs.toByteArray(3), out);    }}
3f903b698636f8b14fa3e1fe8deb6aecf348bfca091441835349ecd20a459d28
testMultipleBatches
public void testMultipleBatches() throws Exception
{    Context ctx = getContextForSimpleHBase2EventSerializer();    ctx.put("batchSize", "2");    HBase2Sink sink = new HBase2Sink(conf);    Configurables.configure(sink, ctx);        ctx.put("batchSize", "100");    Channel channel = new MemoryChannel();    Configurables.configure(channel, new Context());    sink.setChannel(channel);    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    for (int i = 0; i < 3; i++) {        Event e = EventBuilder.withBody(Bytes.toBytes(valBase + "-" + i));        channel.put(e);    }    tx.commit();    tx.close();    int count = 0;    while (sink.process() != Status.BACKOFF) {        count++;    }    sink.stop();    Assert.assertEquals(2, count);    try (Connection connection = ConnectionFactory.createConnection(conf)) {        Table table = connection.getTable(TableName.valueOf(tableName));        byte[][] results = getResults(table, 3);        byte[] out;        int found = 0;        for (int i = 0; i < 3; i++) {            for (int j = 0; j < 3; j++) {                if (Arrays.equals(results[j], Bytes.toBytes(valBase + "-" + i))) {                    found++;                    break;                }            }        }        Assert.assertEquals(3, found);        out = results[3];        Assert.assertArrayEquals(Longs.toByteArray(3), out);    }}
e8aa60f990984f01933584d8ef5e772704995dd8b1d21a2a2d1c83e52649d4c5
testMissingTable
public void testMissingTable() throws Exception
{    logger.info("Running testMissingTable()");    Context ctx = getContextForSimpleHBase2EventSerializer();        logger.info("Deleting table {}", tableName);    testUtility.deleteTable(TableName.valueOf(tableName));    ctx.put("batchSize", "2");    HBase2Sink sink = new HBase2Sink(conf);    Configurables.configure(sink, ctx);        ctx.put("batchSize", "100");    Channel channel = new MemoryChannel();    Configurables.configure(channel, new Context());    sink.setChannel(channel);    logger.info("Writing data into channel");    Transaction tx = channel.getTransaction();    tx.begin();    for (int i = 0; i < 3; i++) {        Event e = EventBuilder.withBody(Bytes.toBytes(valBase + "-" + i));        channel.put(e);    }    tx.commit();    tx.close();    logger.info("Starting sink and processing events");    try {        logger.info("Calling sink.start()");                sink.start();                logger.error("Unexpected error: Calling sink.process()");        sink.process();        logger.error("Unexpected error: Calling sink.stop()");        sink.stop();    } finally {                testUtility.createTable(TableName.valueOf(tableName), columnFamily.getBytes());    }        Assert.fail();}
355c37328e8976d2ec4c6df516e928071228ec26717881cd804abf1b95f10070
testHBaseFailure
public void testHBaseFailure() throws Exception
{    Context ctx = getContextForSimpleHBase2EventSerializer();    ctx.put("batchSize", "2");    HBase2Sink sink = new HBase2Sink(conf);    Configurables.configure(sink, ctx);        ctx.put("batchSize", "100");    Channel channel = new MemoryChannel();    Configurables.configure(channel, new Context());    sink.setChannel(channel);    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    for (int i = 0; i < 3; i++) {        Event e = EventBuilder.withBody(Bytes.toBytes(valBase + "-" + i));        channel.put(e);    }    tx.commit();    tx.close();    sink.process();    try (Connection connection = ConnectionFactory.createConnection(conf);        Table table = connection.getTable(TableName.valueOf(tableName))) {        byte[][] results = getResults(table, 2);        byte[] out;        int found = 0;        for (int i = 0; i < 2; i++) {            for (int j = 0; j < 2; j++) {                if (Arrays.equals(results[j], Bytes.toBytes(valBase + "-" + i))) {                    found++;                    break;                }            }        }        Assert.assertEquals(2, found);        out = results[2];        Assert.assertArrayEquals(Longs.toByteArray(2), out);    }    testUtility.shutdownMiniCluster();    sink.process();    sink.stop();}
2e227dae2ea8ea2688a0d2c9583e6ba49ddec4915ec9fbc0b016103eb8b0e4e9
getResults
private byte[][] getResults(Table table, int numEvents) throws IOException
{    byte[][] results = new byte[numEvents + 1][];    Scan scan = new Scan();    scan.addColumn(columnFamily.getBytes(), plCol.getBytes());    scan.withStartRow(Bytes.toBytes("default"));    ResultScanner rs = table.getScanner(scan);    byte[] out;    int i = 0;    try {        for (Result r = rs.next(); r != null; r = rs.next()) {            out = r.getValue(columnFamily.getBytes(), plCol.getBytes());            if (i >= results.length - 1) {                rs.close();                throw new FlumeException("More results than expected in the table." + "Expected = " + numEvents + ". Found = " + i);            }            results[i++] = out;            System.out.println(out);        }    } finally {        rs.close();    }    Assert.assertEquals(i, results.length - 1);    scan = new Scan();    scan.addColumn(columnFamily.getBytes(), inColumn.getBytes());    scan.withStartRow(Bytes.toBytes("incRow"));    rs = table.getScanner(scan);    try {        for (Result r = rs.next(); r != null; r = rs.next()) {            out = r.getValue(columnFamily.getBytes(), inColumn.getBytes());            results[i++] = out;            System.out.println(out);        }    } finally {        rs.close();    }    return results;}
c8512dff1849f0fb0813d4c33c541ec33b4fbc83492688d67bcf2073693248a6
testTransactionStateOnChannelException
public void testTransactionStateOnChannelException() throws Exception
{    Context ctx = getContextForSimpleHBase2EventSerializer();    ctx.put("batchSize", "1");    HBase2Sink sink = new HBase2Sink(conf);    Configurables.configure(sink, ctx);        Channel channel = spy(new MemoryChannel());    Configurables.configure(channel, new Context());    sink.setChannel(channel);    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    Event e = EventBuilder.withBody(Bytes.toBytes(valBase + "-" + 0));    channel.put(e);    tx.commit();    tx.close();    doThrow(new ChannelException("Mock Exception")).when(channel).take();    try {        sink.process();        Assert.fail("take() method should throw exception");    } catch (ChannelException ex) {        Assert.assertEquals("Mock Exception", ex.getMessage());        SinkCounter sinkCounter = (SinkCounter) Whitebox.getInternalState(sink, "sinkCounter");        Assert.assertEquals(1, sinkCounter.getChannelReadFail());    }    doReturn(e).when(channel).take();    sink.process();    sink.stop();    try (Connection connection = ConnectionFactory.createConnection(conf);        Table table = connection.getTable(TableName.valueOf(tableName))) {        byte[][] results = getResults(table, 1);        byte[] out = results[0];        Assert.assertArrayEquals(e.getBody(), out);        out = results[1];        Assert.assertArrayEquals(Longs.toByteArray(1), out);    }}
12e7e84bacf1e16cebd5d17e96d276a68f64edcf710170b8b999fc2e31195a14
testTransactionStateOnSerializationException
public void testTransactionStateOnSerializationException() throws Exception
{    Context ctx = getContextForSimpleHBase2EventSerializer();    ctx.put("batchSize", "1");    ctx.put(HBase2SinkConfigurationConstants.CONFIG_SERIALIZER, "org.apache.flume.sink.hbase2.MockSimpleHBase2EventSerializer");    HBase2Sink sink = new HBase2Sink(conf);    Configurables.configure(sink, ctx);        ctx.put("batchSize", "100");    Channel channel = new MemoryChannel();    Configurables.configure(channel, new Context());    sink.setChannel(channel);    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    Event e = EventBuilder.withBody(Bytes.toBytes(valBase + "-" + 0));    channel.put(e);    tx.commit();    tx.close();    try {        MockSimpleHBase2EventSerializer.throwException = true;        sink.process();        Assert.fail("FlumeException expected from serializer");    } catch (FlumeException ex) {        Assert.assertEquals("Exception for testing", ex.getMessage());        SinkCounter sinkCounter = (SinkCounter) Whitebox.getInternalState(sink, "sinkCounter");        Assert.assertEquals(1, sinkCounter.getEventWriteFail());    }    MockSimpleHBase2EventSerializer.throwException = false;    sink.process();    sink.stop();    try (Connection connection = ConnectionFactory.createConnection(conf);        Table table = connection.getTable(TableName.valueOf(tableName))) {        byte[][] results = getResults(table, 1);        byte[] out = results[0];        Assert.assertArrayEquals(e.getBody(), out);        out = results[1];        Assert.assertArrayEquals(Longs.toByteArray(1), out);    }}
0e9b2a5968e2172ff1e8d345e371f21c9ae1ac933bcfba3c98b09b4491a8eab7
testWithoutConfigurationObject
public void testWithoutConfigurationObject() throws Exception
{    Context ctx = getContextForSimpleHBase2EventSerializer();    Context tmpContext = new Context(ctx.getParameters());    tmpContext.put("batchSize", "2");    tmpContext.put(HBase2SinkConfigurationConstants.ZK_QUORUM, ZKConfig.getZKQuorumServersString(conf));    System.out.print(ctx.getString(HBase2SinkConfigurationConstants.ZK_QUORUM));    tmpContext.put(HBase2SinkConfigurationConstants.ZK_ZNODE_PARENT, conf.get(HConstants.ZOOKEEPER_ZNODE_PARENT, HConstants.DEFAULT_ZOOKEEPER_ZNODE_PARENT));    HBase2Sink sink = new HBase2Sink();    Configurables.configure(sink, tmpContext);    Channel channel = new MemoryChannel();    Configurables.configure(channel, ctx);    sink.setChannel(channel);    sink.start();    Transaction tx = channel.getTransaction();    tx.begin();    for (int i = 0; i < 3; i++) {        Event e = EventBuilder.withBody(Bytes.toBytes(valBase + "-" + i));        channel.put(e);    }    tx.commit();    tx.close();    Status status = Status.READY;    while (status != Status.BACKOFF) {        status = sink.process();    }    sink.stop();    try (Connection connection = ConnectionFactory.createConnection(conf);        Table table = connection.getTable(TableName.valueOf(tableName))) {        byte[][] results = getResults(table, 3);        byte[] out;        int found = 0;        for (int i = 0; i < 3; i++) {            for (int j = 0; j < 3; j++) {                if (Arrays.equals(results[j], Bytes.toBytes(valBase + "-" + i))) {                    found++;                    break;                }            }        }        Assert.assertEquals(3, found);        out = results[3];        Assert.assertArrayEquals(Longs.toByteArray(3), out);    }}
4201c9c540210b2150f4b43823f4a177e7bbd5a8a486fd809ed6eb797706c5af
testZKQuorum
public void testZKQuorum() throws Exception
{    Context ctx = getContextForSimpleHBase2EventSerializer();    Context tmpContext = new Context(ctx.getParameters());    String zkQuorum = "zk1.flume.apache.org:3342, zk2.flume.apache.org:3342, " + "zk3.flume.apache.org:3342";    tmpContext.put("batchSize", "2");    tmpContext.put(HBase2SinkConfigurationConstants.ZK_QUORUM, zkQuorum);    tmpContext.put(HBase2SinkConfigurationConstants.ZK_ZNODE_PARENT, conf.get(HConstants.ZOOKEEPER_ZNODE_PARENT, HConstants.DEFAULT_ZOOKEEPER_ZNODE_PARENT));    HBase2Sink sink = new HBase2Sink();    Configurables.configure(sink, tmpContext);    Assert.assertEquals("zk1.flume.apache.org,zk2.flume.apache.org," + "zk3.flume.apache.org", sink.getConfig().get(HConstants.ZOOKEEPER_QUORUM));    Assert.assertEquals(String.valueOf(3342), sink.getConfig().get(HConstants.ZOOKEEPER_CLIENT_PORT));}
16628512aff2c6df2f0fad6a2972538f9b37de86327c298937774caeadf35499
testZKQuorumIncorrectPorts
public void testZKQuorumIncorrectPorts() throws Exception
{    Context ctx = getContextForSimpleHBase2EventSerializer();    Context tmpContext = new Context(ctx.getParameters());    String zkQuorum = "zk1.flume.apache.org:3345, zk2.flume.apache.org:3342, " + "zk3.flume.apache.org:3342";    tmpContext.put("batchSize", "2");    tmpContext.put(HBase2SinkConfigurationConstants.ZK_QUORUM, zkQuorum);    tmpContext.put(HBase2SinkConfigurationConstants.ZK_ZNODE_PARENT, conf.get(HConstants.ZOOKEEPER_ZNODE_PARENT, HConstants.DEFAULT_ZOOKEEPER_ZNODE_PARENT));    HBase2Sink sink = new HBase2Sink();    Configurables.configure(sink, tmpContext);    Assert.fail();}
bfe59d0a2b5221060dfd2533cbc873055c810f24864acc7828bea6b71ede7f99
testCoalesce
public void testCoalesce() throws EventDeliveryException
{    Context ctx = getContextForIncrementHBaseSerializer();    ctx.put("batchSize", "100");    ctx.put(HBase2SinkConfigurationConstants.CONFIG_COALESCE_INCREMENTS, String.valueOf(true));    final Map<String, Long> expectedCounts = Maps.newHashMap();    expectedCounts.put("r1:c1", 10L);    expectedCounts.put("r1:c2", 20L);    expectedCounts.put("r2:c1", 7L);    expectedCounts.put("r2:c3", 63L);    HBase2Sink.DebugIncrementsCallback cb = new CoalesceValidator(expectedCounts);    HBase2Sink sink = new HBase2Sink(testUtility.getConfiguration(), cb);    Configurables.configure(sink, ctx);    Channel channel = createAndConfigureMemoryChannel(sink);    List<Event> events = Lists.newLinkedList();    generateEvents(events, expectedCounts);    putEvents(channel, events);    sink.start();        sink.process();    sink.stop();}
ca970f8fdc1c2a52c1cbc93b4c32e7e9e3318cc5ce980e670aa3cddfbde84ea1
negativeTestCoalesce
public void negativeTestCoalesce() throws EventDeliveryException
{    Context ctx = getContextForIncrementHBaseSerializer();    ctx.put("batchSize", "10");    final Map<String, Long> expectedCounts = Maps.newHashMap();    expectedCounts.put("r1:c1", 10L);    HBase2Sink.DebugIncrementsCallback cb = new CoalesceValidator(expectedCounts);    HBase2Sink sink = new HBase2Sink(testUtility.getConfiguration(), cb);    Configurables.configure(sink, ctx);    Channel channel = createAndConfigureMemoryChannel(sink);    List<Event> events = Lists.newLinkedList();    generateEvents(events, expectedCounts);    putEvents(channel, events);    sink.start();        sink.process();    sink.stop();}
0f0a2f6fa5f54c55df2635833d9ba0db35411959916e8b54298b187a36862ff7
testBatchAware
public void testBatchAware() throws EventDeliveryException
{    logger.info("Running testBatchAware()");    Context ctx = getContextForIncrementHBaseSerializer();    HBase2Sink sink = new HBase2Sink(testUtility.getConfiguration());    Configurables.configure(sink, ctx);    Channel channel = createAndConfigureMemoryChannel(sink);    sink.start();    int batchCount = 3;    for (int i = 0; i < batchCount; i++) {        sink.process();    }    sink.stop();    Assert.assertEquals(batchCount, ((IncrementHBase2Serializer) sink.getSerializer()).getNumBatchesStarted());}
8e9b42c4fc1bbe91dc4bfbd3441e366ca6a9c65ed460861b11e3c4d68cb7d49b
testHBaseVersionCheck
public void testHBaseVersionCheck() throws Exception
{    Context ctx = getContextWithoutIncrementHBaseSerializer();    HBase2Sink sink = mock(HBase2Sink.class);    doCallRealMethod().when(sink).configure(any());    when(sink.getHBbaseVersionString()).thenReturn("1.0.0");    Configurables.configure(sink, ctx);}
41dcd1bc8b33859c1710d00e1248dd6a93020c7310a1e076609f834d26299782
testHBaseVersionCheckNotANumber
public void testHBaseVersionCheckNotANumber() throws Exception
{    Context ctx = getContextWithoutIncrementHBaseSerializer();    HBase2Sink sink = mock(HBase2Sink.class);    doCallRealMethod().when(sink).configure(any());    when(sink.getHBbaseVersionString()).thenReturn("Dummy text");    Configurables.configure(sink, ctx);}
0fb64ed9d23ed0fe7f55d32667ff30b1560720036f07d6b35bfe62ab8789b6ba
onAfterCoalesce
public void onAfterCoalesce(Iterable<Increment> increments)
{    for (Increment inc : increments) {        byte[] row = inc.getRow();        Map<byte[], NavigableMap<byte[], Long>> families = null;        try {            families = inc.getFamilyMapOfLongs();        } catch (Exception e) {            Throwables.propagate(e);        }        assert families != null;        for (byte[] family : families.keySet()) {            NavigableMap<byte[], Long> qualifiers = families.get(family);            for (Map.Entry<byte[], Long> entry : qualifiers.entrySet()) {                byte[] qualifier = entry.getKey();                Long count = entry.getValue();                String key = new String(row, Charsets.UTF_8) + ':' + new String(qualifier, Charsets.UTF_8);                Assert.assertEquals("Expected counts don't match observed for " + key, expectedCounts.get(key), count);            }        }    }}
de41a71161ec218beb33163177cf5b3ce7abbb42dbaf02236c46f21d366ee3bd
generateEvents
private void generateEvents(List<Event> events, Map<String, Long> counts)
{    for (String key : counts.keySet()) {        long count = counts.get(key);        for (long i = 0; i < count; i++) {            events.add(EventBuilder.withBody(key, Charsets.UTF_8));        }    }}
b35aed107c2ca4364923b1bf27a41e206d559b1c22d68913bc2a3228d2594773
createAndConfigureMemoryChannel
private Channel createAndConfigureMemoryChannel(HBase2Sink sink)
{    Channel channel = new MemoryChannel();    Context channelCtx = new Context();    channelCtx.put("capacity", String.valueOf(1000L));    channelCtx.put("transactionCapacity", String.valueOf(1000L));    Configurables.configure(channel, channelCtx);    sink.setChannel(channel);    channel.start();    return channel;}
133c1ab001d9dd606bfe001f085e1e4f56d116d1276bca38fb1ed654e6925f59
putEvents
private void putEvents(Channel channel, Iterable<Event> events)
{    Transaction tx = channel.getTransaction();    tx.begin();    for (Event event : events) {        channel.put(event);    }    tx.commit();    tx.close();}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    sinkFactory = new DefaultSinkFactory();}
a948c8605d79f4de0f42bd0d76886f29b107f8cb28b477b92fc54bbfa2f6ff83
verifySinkCreation
private void verifySinkCreation(Class<?> typeClass) throws FlumeException
{    Sink sink = sinkFactory.create("hbase2-sink", "hbase2");    Assert.assertNotNull(sink);    Assert.assertTrue(typeClass.isInstance(sink));}
66cf42a2fbf2ff4192d473ea28dd3a2c1d7389f68a166b0f208cb4cd791d921b
testSinkCreation
public void testSinkCreation()
{    verifySinkCreation(HBase2Sink.class);}
979dfbb00031b336e7b6d78731005bed4c3b9615e0032261d4248de2bfe94fb6
testDefaultBehavior
public void testDefaultBehavior() throws Exception
{    RegexHBase2EventSerializer s = new RegexHBase2EventSerializer();    Context context = new Context();    s.configure(context);    String logMsg = "The sky is falling!";    Event e = EventBuilder.withBody(Bytes.toBytes(logMsg));    s.initialize(e, "CF".getBytes());    List<Row> actions = s.getActions();    assertTrue(actions.size() == 1);    assertTrue(actions.get(0) instanceof Put);    Put put = (Put) actions.get(0);    assertTrue(put.getFamilyCellMap().containsKey(s.cf));    List<Cell> cells = put.getFamilyCellMap().get(s.cf);    assertTrue(cells.size() == 1);    Map<String, String> resultMap = Maps.newHashMap();    for (Cell cell : cells) {        resultMap.put(new String(CellUtil.cloneQualifier(cell)), new String(CellUtil.cloneValue(cell)));    }    assertTrue(resultMap.containsKey(RegexHBase2EventSerializer.COLUMN_NAME_DEFAULT));    assertEquals("The sky is falling!", resultMap.get(RegexHBase2EventSerializer.COLUMN_NAME_DEFAULT));}
2f694841bfe643eba83a4ad5d847f1e22e37ca84e094710fbfac521982cde508
testRowIndexKey
public void testRowIndexKey() throws Exception
{    RegexHBase2EventSerializer s = new RegexHBase2EventSerializer();    Context context = new Context();    context.put(RegexHBase2EventSerializer.REGEX_CONFIG, "^([^\t]+)\t([^\t]+)\t" + "([^\t]+)$");    context.put(RegexHBase2EventSerializer.COL_NAME_CONFIG, "col1,col2,ROW_KEY");    context.put("rowKeyIndex", "2");    s.configure(context);    String body = "val1\tval2\trow1";    Event e = EventBuilder.withBody(Bytes.toBytes(body));    s.initialize(e, "CF".getBytes());    List<Row> actions = s.getActions();    Put put = (Put) actions.get(0);    List<Cell> cells = put.getFamilyCellMap().get(s.cf);    assertTrue(cells.size() == 2);    Map<String, String> resultMap = Maps.newHashMap();    for (Cell cell : cells) {        resultMap.put(new String(CellUtil.cloneQualifier(cell)), new String(CellUtil.cloneValue(cell)));    }    assertEquals("val1", resultMap.get("col1"));    assertEquals("val2", resultMap.get("col2"));    assertEquals("row1", Bytes.toString(put.getRow()));}
252e1eaadb8c8953331476ffe9c761e4b7026415d73bdb16659a4862f51d6f76
testApacheRegex
public void testApacheRegex() throws Exception
{    RegexHBase2EventSerializer s = new RegexHBase2EventSerializer();    Context context = new Context();    context.put(RegexHBase2EventSerializer.REGEX_CONFIG, "([^ ]*) ([^ ]*) ([^ ]*) (-|\\[[^\\]]*\\]) \"([^ ]+) ([^ ]+)" + " ([^\"]+)\" (-|[0-9]*) (-|[0-9]*)(?: ([^ \"]*|\"[^\"]*\")" + " ([^ \"]*|\"[^\"]*\"))?");    context.put(RegexHBase2EventSerializer.COL_NAME_CONFIG, "host,identity,user,time,method,request,protocol,status,size," + "referer,agent");    s.configure(context);    String logMsg = "33.22.11.00 - - [20/May/2011:07:01:19 +0000] " + "\"GET /wp-admin/css/install.css HTTP/1.0\" 200 813 " + "\"http://www.cloudera.com/wp-admin/install.php\" \"Mozilla/5.0 (comp" + "atible; Yahoo! Slurp; http://help.yahoo.com/help/us/ysearch/slurp)\"";    Event e = EventBuilder.withBody(Bytes.toBytes(logMsg));    s.initialize(e, "CF".getBytes());    List<Row> actions = s.getActions();    assertEquals(1, s.getActions().size());    assertTrue(actions.get(0) instanceof Put);    Put put = (Put) actions.get(0);    assertTrue(put.getFamilyCellMap().containsKey(s.cf));    List<Cell> cells = put.getFamilyCellMap().get(s.cf);    assertTrue(cells.size() == 11);    Map<String, String> resultMap = Maps.newHashMap();    for (Cell cell : cells) {        resultMap.put(new String(CellUtil.cloneQualifier(cell)), new String(CellUtil.cloneValue(cell)));    }    assertEquals("33.22.11.00", resultMap.get("host"));    assertEquals("-", resultMap.get("identity"));    assertEquals("-", resultMap.get("user"));    assertEquals("[20/May/2011:07:01:19 +0000]", resultMap.get("time"));    assertEquals("GET", resultMap.get("method"));    assertEquals("/wp-admin/css/install.css", resultMap.get("request"));    assertEquals("HTTP/1.0", resultMap.get("protocol"));    assertEquals("200", resultMap.get("status"));    assertEquals("813", resultMap.get("size"));    assertEquals("\"http://www.cloudera.com/wp-admin/install.php\"", resultMap.get("referer"));    assertEquals("\"Mozilla/5.0 (compatible; Yahoo! Slurp; " + "http://help.yahoo.com/help/us/ysearch/slurp)\"", resultMap.get("agent"));    List<Increment> increments = s.getIncrements();    assertEquals(0, increments.size());}
6f872d3644c0cb9a429b536caaa6c0d0915c033caaf1cb96f5414383b3db156d
testRowKeyGeneration
public void testRowKeyGeneration()
{    Context context = new Context();    RegexHBase2EventSerializer s1 = new RegexHBase2EventSerializer();    s1.configure(context);    RegexHBase2EventSerializer s2 = new RegexHBase2EventSerializer();    s2.configure(context);        RegexHBase2EventSerializer.nonce.set(0);    String randomString = RegexHBase2EventSerializer.randomKey;    Event e1 = EventBuilder.withBody(Bytes.toBytes("body"));    Event e2 = EventBuilder.withBody(Bytes.toBytes("body"));    Event e3 = EventBuilder.withBody(Bytes.toBytes("body"));    Calendar cal = mock(Calendar.class);    when(cal.getTimeInMillis()).thenReturn(1L);    s1.initialize(e1, "CF".getBytes());    String rk1 = new String(s1.getRowKey(cal));    assertEquals("1-" + randomString + "-0", rk1);    when(cal.getTimeInMillis()).thenReturn(10L);    s1.initialize(e2, "CF".getBytes());    String rk2 = new String(s1.getRowKey(cal));    assertEquals("10-" + randomString + "-1", rk2);    when(cal.getTimeInMillis()).thenReturn(100L);    s2.initialize(e3, "CF".getBytes());    String rk3 = new String(s2.getRowKey(cal));    assertEquals("100-" + randomString + "-2", rk3);}
ef2312732288af0f7a3192ca99173af7a63416dd2807b3d83cf8d3693bcd6294
testDepositHeaders
public void testDepositHeaders() throws Exception
{    Charset charset = Charset.forName("KOI8-R");    RegexHBase2EventSerializer s = new RegexHBase2EventSerializer();    Context context = new Context();    context.put(RegexHBase2EventSerializer.DEPOSIT_HEADERS_CONFIG, "true");    context.put(RegexHBase2EventSerializer.CHARSET_CONFIG, charset.toString());    s.configure(context);    String body = "body";    Map<String, String> headers = Maps.newHashMap();    headers.put("header1", "value1");    headers.put("заголовок2", "значение2");    Event e = EventBuilder.withBody(Bytes.toBytes(body), headers);    s.initialize(e, "CF".getBytes());    List<Row> actions = s.getActions();    assertEquals(1, s.getActions().size());    assertTrue(actions.get(0) instanceof Put);    Put put = (Put) actions.get(0);    assertTrue(put.getFamilyCellMap().containsKey(s.cf));    List<Cell> cells = put.getFamilyCellMap().get(s.cf);    assertTrue(cells.size() == 3);    Map<String, byte[]> resultMap = Maps.newHashMap();    for (Cell cell : cells) {        resultMap.put(new String(CellUtil.cloneQualifier(cell), charset), CellUtil.cloneValue(cell));    }    assertEquals(body, new String(resultMap.get(RegexHBase2EventSerializer.COLUMN_NAME_DEFAULT), charset));    assertEquals("value1", new String(resultMap.get("header1"), charset));    assertArrayEquals("значение2".getBytes(charset), resultMap.get("заголовок2"));    assertEquals("значение2".length(), resultMap.get("заголовок2").length);    List<Increment> increments = s.getIncrements();    assertEquals(0, increments.size());}
5cc916dd00109baf65cc6b38ab7b9c11ea1d9703de82ba7e1fa5dc88db776b80
getTopic
public String getTopic()
{    return topic;}
dcc511f35190533c2d6fcc6073d66b12e111f5004c64ff08ccc3609a06ab844d
getBatchSize
public long getBatchSize()
{    return batchSize;}
e52e5e378330fd7f87ee30351bbfcec47b751fee12ece2ef0cfdd77a08c906e1
process
public Status process() throws EventDeliveryException
{    Status result = Status.READY;    Channel channel = getChannel();    Transaction transaction = null;    Event event = null;    String eventTopic = null;    String eventKey = null;    try {        long processedEvents = 0;        transaction = channel.getTransaction();        transaction.begin();        kafkaFutures.clear();        long batchStartTime = System.nanoTime();        for (; processedEvents < batchSize; processedEvents += 1) {            event = channel.take();            if (event == null) {                                if (processedEvents == 0) {                    result = Status.BACKOFF;                    counter.incrementBatchEmptyCount();                } else {                    counter.incrementBatchUnderflowCount();                }                break;            }            counter.incrementEventDrainAttemptCount();            byte[] eventBody = event.getBody();            Map<String, String> headers = event.getHeaders();            if (allowTopicOverride) {                eventTopic = headers.get(topicHeader);                if (eventTopic == null) {                    eventTopic = BucketPath.escapeString(topic, event.getHeaders());                    logger.debug("{} was set to true but header {} was null. Producing to {}" + " topic instead.", new Object[] { KafkaSinkConstants.ALLOW_TOPIC_OVERRIDE_HEADER, topicHeader, eventTopic });                }            } else {                eventTopic = topic;            }            eventKey = headers.get(KEY_HEADER);            if (logger.isTraceEnabled()) {                if (LogPrivacyUtil.allowLogRawData()) {                    logger.trace("{Event} " + eventTopic + " : " + eventKey + " : " + new String(eventBody, "UTF-8"));                } else {                    logger.trace("{Event} " + eventTopic + " : " + eventKey);                }            }            logger.debug("event #{}", processedEvents);                        long startTime = System.currentTimeMillis();            Integer partitionId = null;            try {                ProducerRecord<String, byte[]> record;                if (staticPartitionId != null) {                    partitionId = staticPartitionId;                }                                if (partitionHeader != null) {                    String headerVal = event.getHeaders().get(partitionHeader);                    if (headerVal != null) {                        partitionId = Integer.parseInt(headerVal);                    }                }                if (partitionId != null) {                    record = new ProducerRecord<String, byte[]>(eventTopic, partitionId, eventKey, serializeEvent(event, useAvroEventFormat));                } else {                    record = new ProducerRecord<String, byte[]>(eventTopic, eventKey, serializeEvent(event, useAvroEventFormat));                }                kafkaFutures.add(producer.send(record, new SinkCallback(startTime)));            } catch (NumberFormatException ex) {                throw new EventDeliveryException("Non integer partition id specified", ex);            } catch (Exception ex) {                                throw new EventDeliveryException("Could not send event", ex);            }        }                producer.flush();                if (processedEvents > 0) {            for (Future<RecordMetadata> future : kafkaFutures) {                future.get();            }            long endTime = System.nanoTime();            counter.addToKafkaEventSendTimer((endTime - batchStartTime) / (1000 * 1000));            counter.addToEventDrainSuccessCount(Long.valueOf(kafkaFutures.size()));        }        transaction.commit();    } catch (Exception ex) {        String errorMsg = "Failed to publish events";        logger.error("Failed to publish events", ex);        counter.incrementEventWriteOrChannelFail(ex);        result = Status.BACKOFF;        if (transaction != null) {            try {                kafkaFutures.clear();                transaction.rollback();                counter.incrementRollbackCount();            } catch (Exception e) {                logger.error("Transaction rollback failed", e);                throw Throwables.propagate(e);            }        }        throw new EventDeliveryException(errorMsg, ex);    } finally {        if (transaction != null) {            transaction.close();        }    }    return result;}
5b05914888e421f26bff6f39231facdd35759f746a9af780ebac2cf5b2c81932
start
public synchronized void start()
{        producer = new KafkaProducer<String, byte[]>(kafkaProps);    counter.start();    super.start();}
06e1ddba8663c90da407ac517f29ed70555cfe57b0332c9a96e7c696e0255364
stop
public synchronized void stop()
{    producer.close();    counter.stop();    logger.info("Kafka Sink {} stopped. Metrics: {}", getName(), counter);    super.stop();}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    translateOldProps(context);    String topicStr = context.getString(TOPIC_CONFIG);    if (topicStr == null || topicStr.isEmpty()) {        topicStr = DEFAULT_TOPIC;        logger.warn("Topic was not specified. Using {} as the topic.", topicStr);    } else {        logger.info("Using the static topic {}. This may be overridden by event headers", topicStr);    }    topic = topicStr;    batchSize = context.getInteger(BATCH_SIZE, DEFAULT_BATCH_SIZE);    if (logger.isDebugEnabled()) {        logger.debug("Using batch size: {}", batchSize);    }    useAvroEventFormat = context.getBoolean(KafkaSinkConstants.AVRO_EVENT, KafkaSinkConstants.DEFAULT_AVRO_EVENT);    partitionHeader = context.getString(KafkaSinkConstants.PARTITION_HEADER_NAME);    staticPartitionId = context.getInteger(KafkaSinkConstants.STATIC_PARTITION_CONF);    allowTopicOverride = context.getBoolean(KafkaSinkConstants.ALLOW_TOPIC_OVERRIDE_HEADER, KafkaSinkConstants.DEFAULT_ALLOW_TOPIC_OVERRIDE_HEADER);    topicHeader = context.getString(KafkaSinkConstants.TOPIC_OVERRIDE_HEADER, KafkaSinkConstants.DEFAULT_TOPIC_OVERRIDE_HEADER);    if (logger.isDebugEnabled()) {        logger.debug(KafkaSinkConstants.AVRO_EVENT + " set to: {}", useAvroEventFormat);    }    kafkaFutures = new LinkedList<Future<RecordMetadata>>();    String bootStrapServers = context.getString(BOOTSTRAP_SERVERS_CONFIG);    if (bootStrapServers == null || bootStrapServers.isEmpty()) {        throw new ConfigurationException("Bootstrap Servers must be specified");    }    setProducerProps(context, bootStrapServers);    if (logger.isDebugEnabled() && LogPrivacyUtil.allowLogPrintConfig()) {        logger.debug("Kafka producer properties: {}", kafkaProps);    }    if (counter == null) {        counter = new KafkaSinkCounter(getName());    }}
9565e04e40844b638e2d6f16cea61410d649b230a2ee9cd04ac50dcfc8690cb8
translateOldProps
private void translateOldProps(Context ctx)
{    if (!(ctx.containsKey(TOPIC_CONFIG))) {        ctx.put(TOPIC_CONFIG, ctx.getString("topic"));        logger.warn("{} is deprecated. Please use the parameter {}", "topic", TOPIC_CONFIG);    }        if (!(ctx.containsKey(BOOTSTRAP_SERVERS_CONFIG))) {        String brokerList = ctx.getString(BROKER_LIST_FLUME_KEY);        if (brokerList == null || brokerList.isEmpty()) {            throw new ConfigurationException("Bootstrap Servers must be specified");        } else {            ctx.put(BOOTSTRAP_SERVERS_CONFIG, brokerList);            logger.warn("{} is deprecated. Please use the parameter {}", BROKER_LIST_FLUME_KEY, BOOTSTRAP_SERVERS_CONFIG);        }    }        if (!(ctx.containsKey(BATCH_SIZE))) {        String oldBatchSize = ctx.getString(OLD_BATCH_SIZE);        if (oldBatchSize != null && !oldBatchSize.isEmpty()) {            ctx.put(BATCH_SIZE, oldBatchSize);            logger.warn("{} is deprecated. Please use the parameter {}", OLD_BATCH_SIZE, BATCH_SIZE);        }    }        if (!(ctx.containsKey(KAFKA_PRODUCER_PREFIX + ProducerConfig.ACKS_CONFIG))) {        String requiredKey = ctx.getString(KafkaSinkConstants.REQUIRED_ACKS_FLUME_KEY);        if (!(requiredKey == null) && !(requiredKey.isEmpty())) {            ctx.put(KAFKA_PRODUCER_PREFIX + ProducerConfig.ACKS_CONFIG, requiredKey);            logger.warn("{} is deprecated. Please use the parameter {}", REQUIRED_ACKS_FLUME_KEY, KAFKA_PRODUCER_PREFIX + ProducerConfig.ACKS_CONFIG);        }    }    if (ctx.containsKey(KEY_SERIALIZER_KEY)) {        logger.warn("{} is deprecated. Flume now uses the latest Kafka producer which implements " + "a different interface for serializers. Please use the parameter {}", KEY_SERIALIZER_KEY, KAFKA_PRODUCER_PREFIX + ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG);    }    if (ctx.containsKey(MESSAGE_SERIALIZER_KEY)) {        logger.warn("{} is deprecated. Flume now uses the latest Kafka producer which implements " + "a different interface for serializers. Please use the parameter {}", MESSAGE_SERIALIZER_KEY, KAFKA_PRODUCER_PREFIX + ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG);    }}
9f9a75480582a1cadff3eca07d51280900901ace8387358e626c49198bbc0699
setProducerProps
private void setProducerProps(Context context, String bootStrapServers)
{    kafkaProps.clear();    kafkaProps.put(ProducerConfig.ACKS_CONFIG, DEFAULT_ACKS);        kafkaProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, DEFAULT_KEY_SERIALIZER);    kafkaProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, DEFAULT_VALUE_SERIAIZER);    kafkaProps.putAll(context.getSubProperties(KAFKA_PRODUCER_PREFIX));    kafkaProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootStrapServers);    KafkaSSLUtil.addGlobalSSLParameters(kafkaProps);}
f77f3e771a795d8622a619190164f8e045eacdb03862a4997178fe410a9bfc14
getKafkaProps
protected Properties getKafkaProps()
{    return kafkaProps;}
f1ae8a84c31390d068f427b10932cc549de689d0306546bfa2db055ccac4bab3
serializeEvent
private byte[] serializeEvent(Event event, boolean useAvroEventFormat) throws IOException
{    byte[] bytes;    if (useAvroEventFormat) {        if (!tempOutStream.isPresent()) {            tempOutStream = Optional.of(new ByteArrayOutputStream());        }        if (!writer.isPresent()) {            writer = Optional.of(new SpecificDatumWriter<AvroFlumeEvent>(AvroFlumeEvent.class));        }        tempOutStream.get().reset();        AvroFlumeEvent e = new AvroFlumeEvent(toCharSeqMap(event.getHeaders()), ByteBuffer.wrap(event.getBody()));        encoder = EncoderFactory.get().directBinaryEncoder(tempOutStream.get(), encoder);        writer.get().write(e, encoder);        encoder.flush();        bytes = tempOutStream.get().toByteArray();    } else {        bytes = event.getBody();    }    return bytes;}
ca70404cb05aa6f426a79eb036db13b49ea4f886fb6ea56db781f7474943c006
toCharSeqMap
private static Map<CharSequence, CharSequence> toCharSeqMap(Map<String, String> stringMap)
{    Map<CharSequence, CharSequence> charSeqMap = new HashMap<CharSequence, CharSequence>();    for (Map.Entry<String, String> entry : stringMap.entrySet()) {        charSeqMap.put(entry.getKey(), entry.getValue());    }    return charSeqMap;}
b915c65ba01f7e32012a43ee05a76416b6d754633b4081b5f849aa6a507799b3
onCompletion
public void onCompletion(RecordMetadata metadata, Exception exception)
{    if (exception != null) {        logger.debug("Error sending message to Kafka {} ", exception.getMessage());    }    if (logger.isDebugEnabled()) {        long eventElapsedTime = System.currentTimeMillis() - startTime;        if (metadata != null) {            logger.debug("Acked message partition:{} ofset:{}", metadata.partition(), metadata.offset());        }        logger.debug("Elapsed time for send: {}", eventElapsedTime);    }}
edcd42501c51dedc18d88eff9c80e0ae0152927a978139173c7118e6961b6e90
setup
public static void setup()
{    testUtil.prepare();    List<String> topics = new ArrayList<String>(3);    topics.add(DEFAULT_TOPIC);    topics.add(TestConstants.STATIC_TOPIC);    topics.add(TestConstants.CUSTOM_TOPIC);    topics.add(TestConstants.HEADER_1_VALUE + "-topic");    testUtil.initTopicList(topics);}
7bc01499962f9db4f29ce028fa1e575b4b5f7e9b37f763467d82ccb96ea15886
tearDown
public static void tearDown()
{    testUtil.tearDown();}
05e9ebb2ea5d6fc8706ff4d1a603edd39078834a3f64abc932e99cb149003f10
testKafkaProperties
public void testKafkaProperties()
{    KafkaSink kafkaSink = new KafkaSink();    Context context = new Context();    context.put(KAFKA_PREFIX + TOPIC_CONFIG, "");    context.put(KAFKA_PRODUCER_PREFIX + ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, "override.default.serializer");    context.put("kafka.producer.fake.property", "kafka.property.value");    context.put("kafka.bootstrap.servers", "localhost:9092,localhost:9092");    context.put("brokerList", "real-broker-list");    Configurables.configure(kafkaSink, context);    Properties kafkaProps = kafkaSink.getKafkaProps();        assertEquals(kafkaProps.getProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG), DEFAULT_KEY_SERIALIZER);        assertEquals(kafkaProps.getProperty(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG), "override.default.serializer");        assertEquals(kafkaProps.getProperty("fake.property"), "kafka.property.value");        assertEquals(kafkaProps.getProperty("bootstrap.servers"), "localhost:9092,localhost:9092");}
9db2f5281407be7210c57ebb9f1298717c8e7937404a90d1f2391c063dbfa5cb
testOldProperties
public void testOldProperties()
{    KafkaSink kafkaSink = new KafkaSink();    Context context = new Context();    context.put("topic", "test-topic");    context.put(OLD_BATCH_SIZE, "300");    context.put(BROKER_LIST_FLUME_KEY, "localhost:9092,localhost:9092");    context.put(REQUIRED_ACKS_FLUME_KEY, "all");    Configurables.configure(kafkaSink, context);    Properties kafkaProps = kafkaSink.getKafkaProps();    assertEquals(kafkaSink.getTopic(), "test-topic");    assertEquals(kafkaSink.getBatchSize(), 300);    assertEquals(kafkaProps.getProperty(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG), "localhost:9092,localhost:9092");    assertEquals(kafkaProps.getProperty(ProducerConfig.ACKS_CONFIG), "all");}
82a4bf93a2a6bd535b7f46676e2469b2cd4cf8d9196537b5b6d79f41e029daec
testDefaultTopic
public void testDefaultTopic()
{    Sink kafkaSink = new KafkaSink();    Context context = prepareDefaultContext();    Configurables.configure(kafkaSink, context);    Channel memoryChannel = new MemoryChannel();    Configurables.configure(memoryChannel, context);    kafkaSink.setChannel(memoryChannel);    kafkaSink.start();    String msg = "default-topic-test";    Transaction tx = memoryChannel.getTransaction();    tx.begin();    Event event = EventBuilder.withBody(msg.getBytes());    memoryChannel.put(event);    tx.commit();    tx.close();    try {        Sink.Status status = kafkaSink.process();        if (status == Sink.Status.BACKOFF) {            fail("Error Occurred");        }    } catch (EventDeliveryException ex) {        }    checkMessageArrived(msg, DEFAULT_TOPIC);}
2e2cb40a72b3e87ea1233098255e80c00a2f5d93a1480b967d100ec8109c01c6
checkMessageArrived
private void checkMessageArrived(String msg, String topic)
{    ConsumerRecords recs = pollConsumerRecords(topic);    assertNotNull(recs);    assertTrue(recs.count() > 0);    ConsumerRecord consumerRecord = (ConsumerRecord) recs.iterator().next();    assertEquals(msg, consumerRecord.value());}
32a2267f978f5a7c4e74ee3ca81e13b2f678b54f3844db6ee4c7350d4705f3e3
testStaticTopic
public void testStaticTopic()
{    Context context = prepareDefaultContext();        context.put(TOPIC_CONFIG, TestConstants.STATIC_TOPIC);    String msg = "static-topic-test";    try {        Sink.Status status = prepareAndSend(context, msg);        if (status == Sink.Status.BACKOFF) {            fail("Error Occurred");        }    } catch (EventDeliveryException ex) {        }    checkMessageArrived(msg, TestConstants.STATIC_TOPIC);}
3c8e4123e0359340d1c0fa716e8ee7db6e92ba50afe7a735024d3e69ed45b3f2
testTopicAndKeyFromHeader
public void testTopicAndKeyFromHeader()
{    Sink kafkaSink = new KafkaSink();    Context context = prepareDefaultContext();    Configurables.configure(kafkaSink, context);    Channel memoryChannel = new MemoryChannel();    Configurables.configure(memoryChannel, context);    kafkaSink.setChannel(memoryChannel);    kafkaSink.start();    String msg = "test-topic-and-key-from-header";    Map<String, String> headers = new HashMap<String, String>();    headers.put("topic", TestConstants.CUSTOM_TOPIC);    headers.put("key", TestConstants.CUSTOM_KEY);    Transaction tx = memoryChannel.getTransaction();    tx.begin();    Event event = EventBuilder.withBody(msg.getBytes(), headers);    memoryChannel.put(event);    tx.commit();    tx.close();    try {        Sink.Status status = kafkaSink.process();        if (status == Sink.Status.BACKOFF) {            fail("Error Occurred");        }    } catch (EventDeliveryException ex) {        }    checkMessageArrived(msg, TestConstants.CUSTOM_TOPIC);}
1653896c34b0a6abfa5abf23b8e0b75afd06d0d2dd248c856e26f7999731e327
testTopicFromConfHeader
public void testTopicFromConfHeader()
{    String customTopicHeader = "customTopicHeader";    Sink kafkaSink = new KafkaSink();    Context context = prepareDefaultContext();    context.put(KafkaSinkConstants.TOPIC_OVERRIDE_HEADER, customTopicHeader);    Configurables.configure(kafkaSink, context);    Channel memoryChannel = new MemoryChannel();    Configurables.configure(memoryChannel, context);    kafkaSink.setChannel(memoryChannel);    kafkaSink.start();    String msg = "test-topic-from-config-header";    Map<String, String> headers = new HashMap<String, String>();    headers.put(customTopicHeader, TestConstants.CUSTOM_TOPIC);    Transaction tx = memoryChannel.getTransaction();    tx.begin();    Event event = EventBuilder.withBody(msg.getBytes(), headers);    memoryChannel.put(event);    tx.commit();    tx.close();    try {        Sink.Status status = kafkaSink.process();        if (status == Sink.Status.BACKOFF) {            fail("Error Occurred");        }    } catch (EventDeliveryException ex) {        }    checkMessageArrived(msg, TestConstants.CUSTOM_TOPIC);}
6b4648400519b561db3399b87327878f1c2c42b9d410fc6fe5feb702e56355a0
testTopicNotFromConfHeader
public void testTopicNotFromConfHeader()
{    Sink kafkaSink = new KafkaSink();    Context context = prepareDefaultContext();    context.put(KafkaSinkConstants.ALLOW_TOPIC_OVERRIDE_HEADER, "false");    context.put(KafkaSinkConstants.TOPIC_OVERRIDE_HEADER, "foo");    Configurables.configure(kafkaSink, context);    Channel memoryChannel = new MemoryChannel();    Configurables.configure(memoryChannel, context);    kafkaSink.setChannel(memoryChannel);    kafkaSink.start();    String msg = "test-topic-from-config-header";    Map<String, String> headers = new HashMap<String, String>();    headers.put(KafkaSinkConstants.DEFAULT_TOPIC_OVERRIDE_HEADER, TestConstants.CUSTOM_TOPIC);    headers.put("foo", TestConstants.CUSTOM_TOPIC);    Transaction tx = memoryChannel.getTransaction();    tx.begin();    Event event = EventBuilder.withBody(msg.getBytes(), headers);    memoryChannel.put(event);    tx.commit();    tx.close();    try {        Sink.Status status = kafkaSink.process();        if (status == Sink.Status.BACKOFF) {            fail("Error Occurred");        }    } catch (EventDeliveryException ex) {        }    checkMessageArrived(msg, DEFAULT_TOPIC);}
b7fb236f26c4ad5350a16a30820bbe7b5b1175a2ae377cbaaa0e07374749b59a
testReplaceSubStringOfTopicWithHeaders
public void testReplaceSubStringOfTopicWithHeaders()
{    String topic = TestConstants.HEADER_1_VALUE + "-topic";    Sink kafkaSink = new KafkaSink();    Context context = prepareDefaultContext();    context.put(TOPIC_CONFIG, TestConstants.HEADER_TOPIC);    Configurables.configure(kafkaSink, context);    Channel memoryChannel = new MemoryChannel();    Configurables.configure(memoryChannel, context);    kafkaSink.setChannel(memoryChannel);    kafkaSink.start();    String msg = "test-replace-substring-of-topic-with-headers";    Map<String, String> headers = new HashMap<>();    headers.put(TestConstants.HEADER_1_KEY, TestConstants.HEADER_1_VALUE);    Transaction tx = memoryChannel.getTransaction();    tx.begin();    Event event = EventBuilder.withBody(msg.getBytes(), headers);    memoryChannel.put(event);    tx.commit();    tx.close();    try {        Sink.Status status = kafkaSink.process();        if (status == Sink.Status.BACKOFF) {            fail("Error Occurred");        }    } catch (EventDeliveryException ex) {        }    checkMessageArrived(msg, topic);}
f54c729bad7e98803e4010fc49b5d3c4a2a1c209d4aec5a24bbec794087bc612
testAvroEvent
public void testAvroEvent() throws IOException
{    Sink kafkaSink = new KafkaSink();    Context context = prepareDefaultContext();    context.put(AVRO_EVENT, "true");    Configurables.configure(kafkaSink, context);    Channel memoryChannel = new MemoryChannel();    Configurables.configure(memoryChannel, context);    kafkaSink.setChannel(memoryChannel);    kafkaSink.start();    String msg = "test-avro-event";    Map<String, String> headers = new HashMap<String, String>();    headers.put("topic", TestConstants.CUSTOM_TOPIC);    headers.put("key", TestConstants.CUSTOM_KEY);    headers.put(TestConstants.HEADER_1_KEY, TestConstants.HEADER_1_VALUE);    Transaction tx = memoryChannel.getTransaction();    tx.begin();    Event event = EventBuilder.withBody(msg.getBytes(), headers);    memoryChannel.put(event);    tx.commit();    tx.close();    try {        Sink.Status status = kafkaSink.process();        if (status == Sink.Status.BACKOFF) {            fail("Error Occurred");        }    } catch (EventDeliveryException ex) {        }    String topic = TestConstants.CUSTOM_TOPIC;    ConsumerRecords<String, String> recs = pollConsumerRecords(topic);    assertNotNull(recs);    assertTrue(recs.count() > 0);    ConsumerRecord<String, String> consumerRecord = recs.iterator().next();    ByteArrayInputStream in = new ByteArrayInputStream(consumerRecord.value().getBytes());    BinaryDecoder decoder = DecoderFactory.get().directBinaryDecoder(in, null);    SpecificDatumReader<AvroFlumeEvent> reader = new SpecificDatumReader<>(AvroFlumeEvent.class);    AvroFlumeEvent avroevent = reader.read(null, decoder);    String eventBody = new String(avroevent.getBody().array(), Charsets.UTF_8);    Map<CharSequence, CharSequence> eventHeaders = avroevent.getHeaders();    assertEquals(msg, eventBody);    assertEquals(TestConstants.CUSTOM_KEY, consumerRecord.key());    assertEquals(TestConstants.HEADER_1_VALUE, eventHeaders.get(new Utf8(TestConstants.HEADER_1_KEY)).toString());    assertEquals(TestConstants.CUSTOM_KEY, eventHeaders.get(new Utf8("key")).toString());}
eeb8eddad93fcac081d85e46d2664b1fe4a368ebfbeb9df8a9722d15624ff05e
pollConsumerRecords
private ConsumerRecords<String, String> pollConsumerRecords(String topic)
{    return pollConsumerRecords(topic, 20);}
94c78cc53153ae752709f6e139a06178bd22be33924f48f823463f591cc95042
pollConsumerRecords
private ConsumerRecords<String, String> pollConsumerRecords(String topic, int maxIter)
{    ConsumerRecords<String, String> recs = null;    for (int i = 0; i < maxIter; i++) {        recs = testUtil.getNextMessageFromConsumer(topic);        if (recs.count() > 0)            break;        try {            Thread.sleep(1000L);        } catch (InterruptedException e) {                }    }    return recs;}
5610d544b39408110a99306d8637fb0aabd0351ccebb58978f1400f1252a73cf
testEmptyChannel
public void testEmptyChannel() throws EventDeliveryException
{    Sink kafkaSink = new KafkaSink();    Context context = prepareDefaultContext();    Configurables.configure(kafkaSink, context);    Channel memoryChannel = new MemoryChannel();    Configurables.configure(memoryChannel, context);    kafkaSink.setChannel(memoryChannel);    kafkaSink.start();    Sink.Status status = kafkaSink.process();    if (status != Sink.Status.BACKOFF) {        fail("Error Occurred");    }    ConsumerRecords recs = pollConsumerRecords(DEFAULT_TOPIC, 2);    assertNotNull(recs);    assertEquals(recs.count(), 0);}
439d573a8fe6b9f67a27cb60e2850e6a12d6480c39c2bbdf25dd441abd3588d4
testPartitionHeaderSet
public void testPartitionHeaderSet() throws Exception
{    doPartitionHeader(PartitionTestScenario.PARTITION_ID_HEADER_ONLY);}
aa3bd505695f5347aecf0584c09825cc85b68fedd4e1a15a589bb064aea95eea
testPartitionHeaderNotSet
public void testPartitionHeaderNotSet() throws Exception
{    doPartitionHeader(PartitionTestScenario.NO_PARTITION_HEADERS);}
2694c4434a057bdd807b5b20e95415c2ed1d9b91a19744eafb63da3ea4601d47
testStaticPartitionAndHeaderSet
public void testStaticPartitionAndHeaderSet() throws Exception
{    doPartitionHeader(PartitionTestScenario.STATIC_HEADER_AND_PARTITION_ID);}
5eaa1a43820208b4c4e044780230d07518ef48fcad085c3a7ce2d9472037a50e
testStaticPartitionHeaderNotSet
public void testStaticPartitionHeaderNotSet() throws Exception
{    doPartitionHeader(PartitionTestScenario.STATIC_HEADER_ONLY);}
22202a1c65bf8e178130f9ea56f5104fd95be5bbcdce9664f0c4709798313016
testPartitionHeaderMissing
public void testPartitionHeaderMissing() throws Exception
{    doPartitionErrors(PartitionOption.NOTSET);}
428921eedf5c0fe05642b500b5eff30c5f5a633b42f3e5d6e097c0a2fc8a4d53
testPartitionHeaderOutOfRange
public void testPartitionHeaderOutOfRange() throws Exception
{    Sink kafkaSink = new KafkaSink();    try {        doPartitionErrors(PartitionOption.VALIDBUTOUTOFRANGE, kafkaSink);        fail();    } catch (EventDeliveryException e) {        }    SinkCounter sinkCounter = (SinkCounter) Whitebox.getInternalState(kafkaSink, "counter");    assertEquals(1, sinkCounter.getEventWriteFail());}
079276eeaa368790038bc1fb2fa30a09c7ad5d93e60756a45a19a82242cb84a6
testPartitionHeaderInvalid
public void testPartitionHeaderInvalid() throws Exception
{    doPartitionErrors(PartitionOption.NOTANUMBER);}
2e02b9191a1ea976625862610cf1d4be36583e71f2e258adb94dacb91684eff9
testDefaultSettingsOnReConfigure
public void testDefaultSettingsOnReConfigure()
{    String sampleProducerProp = "compression.type";    String sampleProducerVal = "snappy";    Context context = prepareDefaultContext();    context.put(KafkaSinkConstants.KAFKA_PRODUCER_PREFIX + sampleProducerProp, sampleProducerVal);    KafkaSink kafkaSink = new KafkaSink();    Configurables.configure(kafkaSink, context);    Assert.assertEquals(sampleProducerVal, kafkaSink.getKafkaProps().getProperty(sampleProducerProp));    context = prepareDefaultContext();    Configurables.configure(kafkaSink, context);    Assert.assertNull(kafkaSink.getKafkaProps().getProperty(sampleProducerProp));}
f26d2592b519db23f19acfb585a34e0fb1a58018e1c22759fef53da8065bb883
doPartitionErrors
private void doPartitionErrors(PartitionOption option) throws Exception
{    doPartitionErrors(option, new KafkaSink());}
ac45e631b680189c68b57bcac4a70830460629ca89f98c0242d52dc5fae1ee00
doPartitionErrors
private void doPartitionErrors(PartitionOption option, Sink kafkaSink) throws Exception
{    Context context = prepareDefaultContext();    context.put(KafkaSinkConstants.PARTITION_HEADER_NAME, "partition-header");    Configurables.configure(kafkaSink, context);    Channel memoryChannel = new MemoryChannel();    Configurables.configure(memoryChannel, context);    kafkaSink.setChannel(memoryChannel);    kafkaSink.start();    String topic = findUnusedTopic();    createTopic(topic, 5);    Transaction tx = memoryChannel.getTransaction();    tx.begin();    Map<String, String> headers = new HashMap<String, String>();    headers.put("topic", topic);    switch(option) {        case VALIDBUTOUTOFRANGE:            headers.put("partition-header", "9");            break;        case NOTSET:            headers.put("wrong-header", "2");            break;        case NOTANUMBER:            headers.put("partition-header", "not-a-number");            break;        default:            break;    }    Event event = EventBuilder.withBody(String.valueOf(9).getBytes(), headers);    memoryChannel.put(event);    tx.commit();    tx.close();    Sink.Status status = kafkaSink.process();    assertEquals(Sink.Status.READY, status);    deleteTopic(topic);}
019b2ec0724485a6c391f6dc7e4ecc873c4ff11d039c6295eee9328aff3b82bf
doPartitionHeader
private void doPartitionHeader(PartitionTestScenario scenario) throws Exception
{    final int numPtns = 5;    final int numMsgs = numPtns * 10;    final Integer staticPtn = 3;    String topic = findUnusedTopic();    createTopic(topic, numPtns);    Context context = prepareDefaultContext();    context.put(BATCH_SIZE, "100");    if (scenario == PartitionTestScenario.PARTITION_ID_HEADER_ONLY || scenario == PartitionTestScenario.STATIC_HEADER_AND_PARTITION_ID) {        context.put(KafkaSinkConstants.PARTITION_HEADER_NAME, KafkaPartitionTestUtil.PARTITION_HEADER);    }    if (scenario == PartitionTestScenario.STATIC_HEADER_AND_PARTITION_ID || scenario == PartitionTestScenario.STATIC_HEADER_ONLY) {        context.put(KafkaSinkConstants.STATIC_PARTITION_CONF, staticPtn.toString());    }    Sink kafkaSink = new KafkaSink();    Configurables.configure(kafkaSink, context);    Channel memoryChannel = new MemoryChannel();    Configurables.configure(memoryChannel, context);    kafkaSink.setChannel(memoryChannel);    kafkaSink.start();        Map<Integer, List<Event>> partitionMap = new HashMap<Integer, List<Event>>(numPtns);    for (int i = 0; i < numPtns; i++) {        partitionMap.put(i, new ArrayList<Event>());    }    Transaction tx = memoryChannel.getTransaction();    tx.begin();    List<Event> orderedEvents = KafkaPartitionTestUtil.generateSkewedMessageList(scenario, numMsgs, partitionMap, numPtns, staticPtn);    for (Event event : orderedEvents) {        event.getHeaders().put("topic", topic);        memoryChannel.put(event);    }    tx.commit();    tx.close();    Sink.Status status = kafkaSink.process();    assertEquals(Sink.Status.READY, status);    Properties props = new Properties();    props.put("bootstrap.servers", testUtil.getKafkaServerUrl());    props.put("group.id", "group_1");    props.put("enable.auto.commit", "true");    props.put("auto.commit.interval.ms", "1000");    props.put("session.timeout.ms", "30000");    props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");    props.put("value.deserializer", "org.apache.kafka.common.serialization.ByteArrayDeserializer");    props.put("auto.offset.reset", "earliest");    Map<Integer, List<byte[]>> resultsMap = KafkaPartitionTestUtil.retrieveRecordsFromPartitions(topic, numPtns, props);    KafkaPartitionTestUtil.checkResultsAgainstSkew(scenario, partitionMap, resultsMap, staticPtn, numMsgs);    memoryChannel.stop();    kafkaSink.stop();    deleteTopic(topic);}
09de868060ca9127d38c902ecf6d76970dcd8c4c418e7cb416844787f7ff1829
prepareDefaultContext
private Context prepareDefaultContext()
{        Context context = new Context();    context.put(BOOTSTRAP_SERVERS_CONFIG, testUtil.getKafkaServerUrl());    context.put(BATCH_SIZE, "1");    return context;}
0eae960b0970c28e6d79466ac1d5825bbbdf7064f99f009aa37ab4bef3832e4d
prepareAndSend
private Sink.Status prepareAndSend(Context context, String msg) throws EventDeliveryException
{    Sink kafkaSink = new KafkaSink();    Configurables.configure(kafkaSink, context);    Channel memoryChannel = new MemoryChannel();    Configurables.configure(memoryChannel, context);    kafkaSink.setChannel(memoryChannel);    kafkaSink.start();    Transaction tx = memoryChannel.getTransaction();    tx.begin();    Event event = EventBuilder.withBody(msg.getBytes());    memoryChannel.put(event);    tx.commit();    tx.close();    return kafkaSink.process();}
e9baac089ea323b9f0869aa8d82572e222d387315258a8204e1979f16cf8b3c2
createTopic
private void createTopic(String topicName, int numPartitions)
{    testUtil.createTopics(Collections.singletonList(topicName), numPartitions);}
1634f15b1d50dc52573fdb6c1402531d94b7ba882a7a7e6539bdac119851ff36
deleteTopic
private void deleteTopic(String topicName)
{    testUtil.deleteTopic(topicName);}
15dc3c896c7cad8ca2a656daf7d26f78e2838db5191776887f8f1a77aa9d973c
findUnusedTopic
private String findUnusedTopic()
{    String newTopic = null;    boolean topicFound = false;    while (!topicFound) {        newTopic = RandomStringUtils.randomAlphabetic(8);        if (!usedTopics.contains(newTopic)) {            usedTopics.add(newTopic);            topicFound = true;        }    }    return newTopic;}
90ba0dddc593bd95e2a0c0c039c523b81bfb91f87814ebcb222c3914ca772ead
start
public void start() throws Exception
{    kafka.startup();}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    kafka.shutdown();}
ea778c068405e6f502c67334820c2f3df34edc9a2a6695fda587ab4d2e3f10e7
getInstance
public static TestUtil getInstance()
{    return instance;}
d4ed25ac8ad321cf30617caf76c4576654e12017af8058c0917f5c720521f0ec
init
private void init()
{    try {        Properties settings = new Properties();        InputStream in = Class.class.getResourceAsStream("/testutil.properties");        if (in != null) {            settings.load(in);        }        externalServers = "true".equalsIgnoreCase(settings.getProperty("external-servers"));        if (externalServers) {            kafkaServerUrl = settings.getProperty("kafka-server-url");            zkServerUrl = settings.getProperty("zk-server-url");        } else {            String hostname = InetAddress.getLocalHost().getHostName();            zkLocalPort = getNextPort();            kafkaLocalPort = getNextPort();            kafkaServerUrl = hostname + ":" + kafkaLocalPort;            zkServerUrl = hostname + ":" + zkLocalPort;        }        clientProps = createClientProperties();    } catch (Exception e) {        logger.error("Unexpected error", e);        throw new RuntimeException("Unexpected error", e);    }}
aa07b8f693914f3c5fc9102bafeb85ab13f2599a70f3acac6d11cc74a6fbca2e
startEmbeddedKafkaServer
private boolean startEmbeddedKafkaServer()
{    Properties kafkaProperties = new Properties();    Properties zkProperties = new Properties();    logger.info("Starting kafka server.");    try {                zkProperties.load(Class.class.getResourceAsStream("/zookeeper.properties"));                        zkProperties.setProperty("clientPort", Integer.toString(zkLocalPort));        new ZooKeeperLocal(zkProperties);        logger.info("ZooKeeper instance is successfully started on port " + zkLocalPort);        kafkaProperties.load(Class.class.getResourceAsStream("/kafka-server.properties"));                kafkaProperties.setProperty("zookeeper.connect", getZkUrl());                kafkaProperties.setProperty("port", Integer.toString(kafkaLocalPort));        kafkaServer = new KafkaLocal(kafkaProperties);        kafkaServer.start();        logger.info("Kafka Server is successfully started on port " + kafkaLocalPort);        return true;    } catch (Exception e) {        logger.error("Error starting the Kafka Server.", e);        return false;    }}
21c8e88f2aba63ceddf81c968c31b5787a66d0f1fdbc3d164477305faefbfce7
getAdminClient
private AdminClient getAdminClient()
{    if (adminClient == null) {        Properties adminClientProps = createAdminClientProperties();        adminClient = AdminClient.create(adminClientProps);    }    return adminClient;}
a00e4089643c3a99135a2484ef872b67c3222aaab317625d0dc24ead3639d438
createClientProperties
private Properties createClientProperties()
{    final Properties props = createAdminClientProperties();    props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());    props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());    props.put("auto.commit.interval.ms", "1000");    props.put("auto.offset.reset", "earliest");    props.put("consumer.timeout.ms", "10000");    props.put("max.poll.interval.ms", "10000");        return props;}
c00f5289a77dd5456dba715a83b19e4cb16cbd17483d26e59ef16cbf6c377bef
createAdminClientProperties
private Properties createAdminClientProperties()
{    final Properties props = new Properties();    props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, getKafkaServerUrl());    props.put(ConsumerConfig.GROUP_ID_CONFIG, "group_1");    return props;}
220813fefcf0ddf9397344f873e8ed83f0eedbf9528729c8177c0cf728d7d50b
initTopicList
public void initTopicList(List<String> topics)
{    consumer = new KafkaConsumer<>(clientProps);    consumer.subscribe(topics);}
520844fa881edeeb146a4c0d7db7887da80e7d416dc1c05f349ad3d05ac57703
createTopics
public void createTopics(List<String> topicNames, int numPartitions)
{    List<NewTopic> newTopics = new ArrayList<>();    for (String topicName : topicNames) {        NewTopic newTopic = new NewTopic(topicName, numPartitions, (short) 1);        newTopics.add(newTopic);    }    getAdminClient().createTopics(newTopics);        DescribeTopicsResult dtr = getAdminClient().describeTopics(topicNames);    try {        dtr.all().get(10, TimeUnit.SECONDS);    } catch (Exception e) {        throw new RuntimeException("Error getting topic info", e);    }}
821ede1f0ff3ff957283751b815aaa1cf1059f331929c61b6851ea8369a0ee7f
deleteTopic
public void deleteTopic(String topicName)
{    getAdminClient().deleteTopics(Collections.singletonList(topicName));}
c6c44dc315137b4ad29b73d8a80471a874c1a36365ebf791c1ccb88c3fbb885d
getNextMessageFromConsumer
public ConsumerRecords<String, String> getNextMessageFromConsumer(String topic)
{    return consumer.poll(Duration.ofMillis(1000L));}
f542f82c964a89fc9bbd653cf6eb1d7b239b8f16b2a3715c4fbfb5ff4a41e9da
prepare
public void prepare()
{    if (externalServers) {        return;    }    boolean startStatus = startEmbeddedKafkaServer();    if (!startStatus) {        throw new RuntimeException("Error starting the server!");    }    try {                Thread.sleep(3 * 1000);        } catch (InterruptedException e) {        }    logger.info("Completed the prepare phase.");}
39e5ba029cc67f6f1d45c6d20f0df595ec16bc61da20d7680fcbbdae4fe7f95b
tearDown
public void tearDown()
{    logger.info("Shutting down the Kafka Consumer.");    if (consumer != null) {        consumer.close();    }    if (adminClient != null) {        adminClient.close();        adminClient = null;    }    try {                Thread.sleep(3 * 1000);        } catch (InterruptedException e) {        }    if (kafkaServer != null) {        logger.info("Shutting down the kafka Server.");        kafkaServer.stop();    }    logger.info("Completed the tearDown phase.");}
098c2a450866d5c469e2e2684b0ae1e31442d0e653bcc9b290d32beb85489ce7
getNextPort
private synchronized int getNextPort() throws IOException
{    try (ServerSocket socket = new ServerSocket(0)) {        return socket.getLocalPort();    }}
7ce29d613164ff4a5d5cc69fa066f9b30afff256ebb3eed56ff2487ef47eed45
getZkUrl
public String getZkUrl()
{    return zkServerUrl;}
db8686bc69a2d56f524769252006d1404569ac79621f32b1c162272e9267f6ab
getKafkaServerUrl
public String getKafkaServerUrl()
{    return kafkaServerUrl;}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    try {        zooKeeperServer.runFromConfig(configuration);    } catch (IOException e) {        logger.error("Zookeeper startup failed.", e);    }}
faacd45ce21d1cbb584374a868166f2921664ee3631184fbc58c2a737d41fefb
readEvent
public Event readEvent() throws IOException
{    ensureOpen();    ByteArrayOutputStream blob = null;    byte[] buf = new byte[Math.min(maxBlobLength, DEFAULT_BUFFER_SIZE)];    int blobLength = 0;    int n = 0;    while ((n = in.read(buf, 0, Math.min(buf.length, maxBlobLength - blobLength))) != -1) {        if (blob == null) {            blob = new ByteArrayOutputStream(n);        }        blob.write(buf, 0, n);        blobLength += n;        if (blobLength >= maxBlobLength) {            LOGGER.warn("File length exceeds maxBlobLength ({}), truncating BLOB event!", maxBlobLength);            break;        }    }    if (blob == null) {        return null;    } else {        return EventBuilder.withBody(blob.toByteArray());    }}
54fb38a1d197eddb2b60ecdecace63039e95c1beccdbf2a178d1f6dbdaf9e966
readEvents
public List<Event> readEvents(int numEvents) throws IOException
{    ensureOpen();    List<Event> events = Lists.newLinkedList();    for (int i = 0; i < numEvents; i++) {        Event event = readEvent();        if (event != null) {            events.add(event);        } else {            break;        }    }    return events;}
740b2d69a871de3f06de1d6974b0a76e5d58ff23733964f6f17d60eedfcb816d
mark
public void mark() throws IOException
{    ensureOpen();    in.mark();}
39fd2a669bd97a959085d10145da4dcd11d83878afcd67b2123354de7e8771d9
reset
public void reset() throws IOException
{    ensureOpen();    in.reset();}
e0823f55b3a09d41a3e1e792f7e6687db9199c2db9b29e9922d93cbdc6f1284b
close
public void close() throws IOException
{    if (isOpen) {        reset();        in.close();        isOpen = false;    }}
558d14d22f2b89dd49d031eee7a0a0504b3594b3e64004bdfc806522c4e44f4f
ensureOpen
private void ensureOpen()
{    if (!isOpen) {        throw new IllegalStateException("Serializer has been closed");    }}
206ee954f054795c205ae2e9046137c4d143cba3bc17fe6202459274600e9751
build
public BlobDeserializer build(Context context, ResettableInputStream in)
{    return new BlobDeserializer(context, in);}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    this.maxBlobLength = context.getInteger(MAX_BLOB_LENGTH_KEY, MAX_BLOB_LENGTH_DEFAULT);    if (this.maxBlobLength <= 0) {        throw new ConfigurationException("Configuration parameter " + MAX_BLOB_LENGTH_KEY + " must be greater than zero: " + maxBlobLength);    }}
6149235d1cca31f74c8a1b0176ec8d5eeed9c336bcd1197b00e3d5d634691bd6
getEvents
public List<Event> getEvents(HttpServletRequest request) throws Exception
{    Map<String, String> headers = getHeaders(request);    InputStream in = request.getInputStream();    try {        ByteArrayOutputStream blob = null;        byte[] buf = new byte[Math.min(maxBlobLength, DEFAULT_BUFFER_SIZE)];        int blobLength = 0;        int n = 0;        while ((n = in.read(buf, 0, Math.min(buf.length, maxBlobLength - blobLength))) != -1) {            if (blob == null) {                blob = new ByteArrayOutputStream(n);            }            blob.write(buf, 0, n);            blobLength += n;            if (blobLength >= maxBlobLength) {                LOGGER.warn("Request length exceeds maxBlobLength ({}), truncating BLOB event!", maxBlobLength);                break;            }        }        byte[] array = blob != null ? blob.toByteArray() : new byte[0];        Event event = EventBuilder.withBody(array, headers);        if (LOGGER.isDebugEnabled() && LogPrivacyUtil.allowLogRawData()) {            LOGGER.debug("blobEvent: {}", event);        }        return Collections.singletonList(event);    } finally {        in.close();    }}
7368f059b5abc7d0cf867ddad89400804638afd207cb26e9fbf2f4b39de5c794
getHeaders
private Map<String, String> getHeaders(HttpServletRequest request)
{    if (LOGGER.isDebugEnabled() && LogPrivacyUtil.allowLogRawData()) {        Map requestHeaders = new HashMap();        Enumeration iter = request.getHeaderNames();        while (iter.hasMoreElements()) {            String name = (String) iter.nextElement();            requestHeaders.put(name, request.getHeader(name));        }        LOGGER.debug("requestHeaders: {}", requestHeaders);    }    Map<String, String> headers = new HashMap();    if (request.getContentType() != null) {        headers.put(Metadata.CONTENT_TYPE, request.getContentType());    }    Enumeration iter = request.getParameterNames();    while (iter.hasMoreElements()) {        String name = (String) iter.nextElement();        headers.put(name, request.getParameter(name));    }    return headers;}
9ca60cbd686d74ff9099c9ae7a88568b735cff50172c77ff53bff7393a04259e
setMorphlineContext
 void setMorphlineContext(MorphlineContext morphlineContext)
{    this.morphlineContext = morphlineContext;}
70e15f6e23b3d6568445435d8b0567c90ee50963eb00dd97f9bb47c3852b4892
setFinalChild
 void setFinalChild(Command finalChild)
{    this.finalChild = finalChild;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    String morphlineFile = context.getString(MORPHLINE_FILE_PARAM);    String morphlineId = context.getString(MORPHLINE_ID_PARAM);    if (morphlineFile == null || morphlineFile.trim().length() == 0) {        throw new MorphlineCompilationException("Missing parameter: " + MORPHLINE_FILE_PARAM, null);    }    morphlineFileAndId = morphlineFile + "@" + morphlineId;    if (morphlineContext == null) {        FaultTolerance faultTolerance = new FaultTolerance(context.getBoolean(FaultTolerance.IS_PRODUCTION_MODE, false), context.getBoolean(FaultTolerance.IS_IGNORING_RECOVERABLE_EXCEPTIONS, false), context.getString(FaultTolerance.RECOVERABLE_EXCEPTION_CLASSES));        morphlineContext = new MorphlineContext.Builder().setExceptionHandler(faultTolerance).setMetricRegistry(SharedMetricRegistries.getOrCreate(morphlineFileAndId)).build();    }    Config override = ConfigFactory.parseMap(context.getSubProperties(MORPHLINE_VARIABLE_PARAM + "."));    morphline = new Compiler().compile(new File(morphlineFile), morphlineId, morphlineContext, finalChild, override);    this.mappingTimer = morphlineContext.getMetricRegistry().timer(MetricRegistry.name("morphline.app", Metrics.ELAPSED_TIME));    this.numRecords = morphlineContext.getMetricRegistry().meter(MetricRegistry.name("morphline.app", Metrics.NUM_RECORDS));    this.numFailedRecords = morphlineContext.getMetricRegistry().meter(MetricRegistry.name("morphline.app", "numFailedRecords"));    this.numExceptionRecords = morphlineContext.getMetricRegistry().meter(MetricRegistry.name("morphline.app", "numExceptionRecords"));}
83de1d0e2daf56d606c3f2aac4f9e3b49b3097e66f740f1a3e76f24eafcb8add
process
public void process(Event event)
{    numRecords.mark();    Timer.Context timerContext = mappingTimer.time();    try {        Record record = new Record();        for (Entry<String, String> entry : event.getHeaders().entrySet()) {            record.put(entry.getKey(), entry.getValue());        }        byte[] bytes = event.getBody();        if (bytes != null && bytes.length > 0) {            record.put(Fields.ATTACHMENT_BODY, bytes);        }        try {            Notifications.notifyStartSession(morphline);            if (!morphline.process(record)) {                numFailedRecords.mark();                LOG.warn("Morphline {} failed to process record: {}", morphlineFileAndId, record);            }        } catch (RuntimeException t) {            numExceptionRecords.mark();            morphlineContext.getExceptionHandler().handleException(t, record);        }    } finally {        timerContext.stop();    }}
37ab21a35abe4fea4abec3910286daa48c697b75a02600b47e5c42b06fe4891f
beginTransaction
public void beginTransaction()
{    Notifications.notifyBeginTransaction(morphline);}
2ac18a9e084b5e2401d9f9c0683f9227d737fcd43b7838f3c63791b7a26dff2d
commitTransaction
public void commitTransaction()
{    Notifications.notifyCommitTransaction(morphline);}
4d148169bf2449ec0d9add5e6771a9a33c3468cf54d342f62483b2634022474c
rollbackTransaction
public void rollbackTransaction()
{    Notifications.notifyRollbackTransaction(morphline);}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    Notifications.notifyShutdown(morphline);}
46ffa8d56c2364376c7a2fb00ff1e97ead501825886406f582f8797ba07e934c
initialize
public void initialize()
{}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{    LocalMorphlineInterceptor interceptor;    while ((interceptor = pool.poll()) != null) {        interceptor.close();    }}
b7fd8a02f88da0ddad8327ade8d4986c180b70eb77329c7227efb6274c9c0a2b
intercept
public List<Event> intercept(List<Event> events)
{    LocalMorphlineInterceptor interceptor = borrowFromPool();    List<Event> results = interceptor.intercept(events);    returnToPool(interceptor);    return results;}
fa63d27bd1bea8d2c8a54d25059a5646f17912afe7a54c75ebd7cfd8635b0016
intercept
public Event intercept(Event event)
{    LocalMorphlineInterceptor interceptor = borrowFromPool();    Event result = interceptor.intercept(event);    returnToPool(interceptor);    return result;}
22476a1d5073953979f95583f07943e0cd7343716452cb3d50e20aca100bc977
returnToPool
private void returnToPool(LocalMorphlineInterceptor interceptor)
{    pool.add(interceptor);}
41a380ea5f425b0f2868bd3a78f892ec3cb0c1bb9dba5cfb6116d2e7cb44cb3c
borrowFromPool
private LocalMorphlineInterceptor borrowFromPool()
{    LocalMorphlineInterceptor interceptor = pool.poll();    if (interceptor == null) {        interceptor = new LocalMorphlineInterceptor(context);    }    return interceptor;}
cefe43d4f97cd65f82274392d6b7e65614856f765afedfe5dff1c74a2da683b2
build
public MorphlineInterceptor build()
{    return new MorphlineInterceptor(context);}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    this.context = context;}
46ffa8d56c2364376c7a2fb00ff1e97ead501825886406f582f8797ba07e934c
initialize
public void initialize()
{}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{    morphline.stop();}
b7fd8a02f88da0ddad8327ade8d4986c180b70eb77329c7227efb6274c9c0a2b
intercept
public List<Event> intercept(List<Event> events)
{    List results = new ArrayList(events.size());    for (Event event : events) {        event = intercept(event);        if (event != null) {            results.add(event);        }    }    return results;}
fa63d27bd1bea8d2c8a54d25059a5646f17912afe7a54c75ebd7cfd8635b0016
intercept
public Event intercept(Event event)
{    collector.reset();    morphline.process(event);    List<Record> results = collector.getRecords();    if (results.size() == 0) {        return null;    }    if (results.size() > 1) {        throw new FlumeException(getClass().getName() + " must not generate more than one output record per input event");    }    Event result = toEvent(results.get(0));    return result;}
e46970ce47e50eaa6a47ad2c68af7a9e2b967ee80ef14068ea56193deb9e6ef2
toEvent
private Event toEvent(Record record)
{    Map<String, String> headers = new HashMap();    Map<String, Collection<Object>> recordMap = record.getFields().asMap();    byte[] body = null;    for (Map.Entry<String, Collection<Object>> entry : recordMap.entrySet()) {        if (entry.getValue().size() > 1) {            throw new FlumeException(getClass().getName() + " must not generate more than one output value per record field");        }                assert entry.getValue().size() != 0;        Object firstValue = entry.getValue().iterator().next();        if (Fields.ATTACHMENT_BODY.equals(entry.getKey())) {            if (firstValue instanceof byte[]) {                body = (byte[]) firstValue;            } else if (firstValue instanceof InputStream) {                try {                    body = ByteStreams.toByteArray((InputStream) firstValue);                } catch (IOException e) {                    throw new FlumeException(e);                }            } else {                throw new FlumeException(getClass().getName() + " must non generate attachments that are not a byte[] or InputStream");            }        } else {            headers.put(entry.getKey(), firstValue.toString());        }    }    return EventBuilder.withBody(body, headers);}
32c579c114fb4a597273e55b7f8ec732611bc4a62280766cfce0c2b1ce17b615
getRecords
public List<Record> getRecords()
{    return results;}
97d2d353f08aa5a1da8b18b0800b6e778df65f48d34726e5f17800df7e0d88e2
reset
public void reset()
{    results.clear();}
f7aea6d89415c00bb69e6aab26e5c85b36b931704c0d92fa4cbb44c8a9b082b8
getParent
public Command getParent()
{    return null;}
c556ee5149baf7cd6f2feac861b108f93b04065cfe2a3cd8e40f40fba26ffdad
notify
public void notify(Record notification)
{}
5ffaf1526dceea9e992b8d0162553d95b9c4a0b7825e1e8bb68a019c81ea29f9
process
public boolean process(Record record)
{    Preconditions.checkNotNull(record);    results.add(record);    return true;}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    this.context = context;    maxBatchSize = context.getInteger(BATCH_SIZE, maxBatchSize);    maxBatchDurationMillis = context.getLong(BATCH_DURATION_MILLIS, maxBatchDurationMillis);    handlerClass = context.getString(HANDLER_CLASS, MorphlineHandlerImpl.class.getName());    if (sinkCounter == null) {        sinkCounter = new SinkCounter(getName());    }}
e93ffe92ac0738aed3ca585767e41a9c0c54362a2d82fe6ea2be8f61f94e4894
getMaxBatchSize
private int getMaxBatchSize()
{    return maxBatchSize;}
4f17fc99415a11ef9ccf9b758ec0ace671662c6d25c3cc98ba999df7a82120c1
getMaxBatchDurationMillis
private long getMaxBatchDurationMillis()
{    return maxBatchDurationMillis;}
5b05914888e421f26bff6f39231facdd35759f746a9af780ebac2cf5b2c81932
start
public synchronized void start()
{    LOGGER.info("Starting Morphline Sink {} ...", this);    sinkCounter.start();    if (handler == null) {        MorphlineHandler tmpHandler;        try {            tmpHandler = (MorphlineHandler) Class.forName(handlerClass).newInstance();        } catch (Exception e) {            throw new ConfigurationException(e);        }        tmpHandler.configure(context);        handler = tmpHandler;    }    super.start();    LOGGER.info("Morphline Sink {} started.", getName());}
06e1ddba8663c90da407ac517f29ed70555cfe57b0332c9a96e7c696e0255364
stop
public synchronized void stop()
{    LOGGER.info("Morphline Sink {} stopping...", getName());    try {        if (handler != null) {            handler.stop();        }        sinkCounter.stop();        LOGGER.info("Morphline Sink {} stopped. Metrics: {}, {}", getName(), sinkCounter);    } finally {        super.stop();    }}
e52e5e378330fd7f87ee30351bbfcec47b751fee12ece2ef0cfdd77a08c906e1
process
public Status process() throws EventDeliveryException
{    int batchSize = getMaxBatchSize();    long batchEndTime = System.currentTimeMillis() + getMaxBatchDurationMillis();    Channel myChannel = getChannel();    Transaction txn = myChannel.getTransaction();    txn.begin();    boolean isMorphlineTransactionCommitted = true;    try {        int numEventsTaken = 0;        handler.beginTransaction();        isMorphlineTransactionCommitted = false;                for (int i = 0; i < batchSize; i++) {            Event event = myChannel.take();            if (event == null) {                break;            }            sinkCounter.incrementEventDrainAttemptCount();            numEventsTaken++;            if (LOGGER.isTraceEnabled() && LogPrivacyUtil.allowLogRawData()) {                LOGGER.trace("Flume event arrived {}", event);            }                        handler.process(event);            if (System.currentTimeMillis() >= batchEndTime) {                break;            }        }                if (numEventsTaken == 0) {            sinkCounter.incrementBatchEmptyCount();        }        if (numEventsTaken < batchSize) {            sinkCounter.incrementBatchUnderflowCount();        } else {            sinkCounter.incrementBatchCompleteCount();        }        handler.commitTransaction();        isMorphlineTransactionCommitted = true;        txn.commit();        sinkCounter.addToEventDrainSuccessCount(numEventsTaken);        return numEventsTaken == 0 ? Status.BACKOFF : Status.READY;    } catch (Throwable t) {                LOGGER.error("Morphline Sink " + getName() + ": Unable to process event from channel " + myChannel.getName() + ". Exception follows.", t);        sinkCounter.incrementEventWriteOrChannelFail(t);        try {            if (!isMorphlineTransactionCommitted) {                handler.rollbackTransaction();            }        } catch (Throwable t2) {            LOGGER.error("Morphline Sink " + getName() + ": Unable to rollback morphline transaction. Exception follows.", t2);        } finally {            try {                txn.rollback();            } catch (Throwable t4) {                LOGGER.error("Morphline Sink " + getName() + ": Unable to rollback Flume transaction. " + "Exception follows.", t4);            }        }        if (t instanceof Error) {                        throw (Error) t;        } else if (t instanceof ChannelException) {            return Status.BACKOFF;        } else {                        throw new EventDeliveryException("Failed to send events", t);        }    } finally {        txn.close();    }}
dcc511f35190533c2d6fcc6073d66b12e111f5004c64ff08ccc3609a06ab844d
getBatchSize
public long getBatchSize()
{    return getMaxBatchSize();}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    int i = getClass().getName().lastIndexOf('.') + 1;    String shortClassName = getClass().getName().substring(i);    return getName() + " (" + shortClassName + ")";}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    if (context.getString(FaultTolerance.RECOVERABLE_EXCEPTION_CLASSES) == null) {        context.put(FaultTolerance.RECOVERABLE_EXCEPTION_CLASSES, "org.apache.solr.client.solrj.SolrServerException");    }    super.configure(context);}
46ffa8d56c2364376c7a2fb00ff1e97ead501825886406f582f8797ba07e934c
initialize
public void initialize()
{}
05abaca2590b621808664a4cdc4682be077d6364546cf617a36e4f1eb8a6b649
getPrefix
protected String getPrefix()
{    return prefix;}
4502d16872b3bda1ed0062a7b6f58d72151a27033f56bc7f087f3286120e105b
generateUUID
protected String generateUUID()
{    return getPrefix() + UUID.randomUUID().toString();}
27e7ecd6c3c291466481036be82380dcf2430af5ae6fbfb68bddcd2c2041792b
isMatch
protected boolean isMatch(Event event)
{    return true;}
fa63d27bd1bea8d2c8a54d25059a5646f17912afe7a54c75ebd7cfd8635b0016
intercept
public Event intercept(Event event)
{    Map<String, String> headers = event.getHeaders();    if (preserveExisting && headers.containsKey(headerName)) {        } else if (isMatch(event)) {        headers.put(headerName, generateUUID());    }    return event;}
b7fd8a02f88da0ddad8327ade8d4986c180b70eb77329c7227efb6274c9c0a2b
intercept
public List<Event> intercept(List<Event> events)
{    List results = new ArrayList(events.size());    for (Event event : events) {        event = intercept(event);        if (event != null) {            results.add(event);        }    }    return results;}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{}
ad58ee78bde53be64531a2553c03080ec9e8be2f9898c8dc3177c37b00f2a3d1
build
public UUIDInterceptor build()
{    return new UUIDInterceptor(context);}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    this.context = context;}
db73629102e1d00332649be711797af5195f37f5634721ff7c9070e4b74b9c8f
load
public void load(Event event) throws EventDeliveryException
{    getChannelProcessor().processEvent(event);    sink.process();}
1bf2b39f43b3253bab1d2c24609080eb3d5bfb35415e281e2c6cac32c182b58d
load
public void load(List<Event> events) throws EventDeliveryException
{    getChannelProcessor().processEventBatch(events);    sink.process();}
58b8f2fb86ad0f0d38d8270683e2ddf9f267d37ccbf8fb77ec76fba4b799959c
isFinished
public boolean isFinished()
{    throw new UnsupportedOperationException("Not supported yet.");}
586d69414c54ba6467cd376c67aba0fe5e6acbea25d49028f8dffabf13fff625
isReady
public boolean isReady()
{    throw new UnsupportedOperationException("Not supported yet.");}
f74be92d4cd739e5a07af484ade837f6e73e350675ee4253bec7cfe00ecd2503
setReadListener
public void setReadListener(ReadListener readListener)
{    throw new UnsupportedOperationException("Not supported yet.");}
00c6cb892813c6b89e072a7f09dccdece629f30849daab28245b06f3e679bf54
read
public int read() throws IOException
{    return in.read();}
a5e1ecdf74f7bf6b03b8893d7dc4cfd597218d7dd1f689ae4130c6098d6c953d
getAuthType
public String getAuthType()
{    throw new UnsupportedOperationException("Not supported yet.");}
ac1ec2bb87fdfa82ab2b8fa5fd84af00d909d23eccf6c28a5caa65a0069afc9f
getCookies
public Cookie[] getCookies()
{    throw new UnsupportedOperationException("Not supported yet.");}
9e92fd3d658a0df3524c102cacb49bef3aa8ae46e55fd93435c4be453a05287e
getDateHeader
public long getDateHeader(String name)
{    throw new UnsupportedOperationException("Not supported yet.");}
ce222e9e26ff92f109221120401e746a4137a63055fa3f4c459b71bc3b9a3f7b
getHeader
public String getHeader(String name)
{    throw new UnsupportedOperationException("Not supported yet.");}
ce7b38ade347dc1577f353c2a53a22f7dca6b4906ea407160becab5abad88f18
getHeaders
public Enumeration getHeaders(String name)
{    throw new UnsupportedOperationException("Not supported yet.");}
5db598881e03cb23b7c32a7f8c42c1623000751561212c5a67bf06ba5b8e7068
getHeaderNames
public Enumeration getHeaderNames()
{    return Collections.enumeration(Collections.EMPTY_LIST);}
74306b64876c9b5783bd20f2a526e5915d1622b58f033098ad1c25aec724bcbe
getIntHeader
public int getIntHeader(String name)
{    throw new UnsupportedOperationException("Not supported yet.");}
1b04a48e342452eec0b4d88df8c129ec91df7eef97b2ef3d27b577702117da62
getMethod
public String getMethod()
{    throw new UnsupportedOperationException("Not supported yet.");}
b0572b00526a00d95ab79c671b4a8944b16ce663f94319e13a5d4a2ac449cbea
getPathInfo
public String getPathInfo()
{    throw new UnsupportedOperationException("Not supported yet.");}
ba4e6b322fc6b4428b75274638015c9390b2b19d785d00c10f55752af475f678
getPathTranslated
public String getPathTranslated()
{    throw new UnsupportedOperationException("Not supported yet.");}
42d7437c151b9dbb6f43ec28cbadef8c4353e27e2d8f78e6b214d4a521205a61
getContextPath
public String getContextPath()
{    throw new UnsupportedOperationException("Not supported yet.");}
c7e000b510b9e11ec345d0fca397786eb5eabc475ef4adfe46dbc1cdbfb67ac4
getQueryString
public String getQueryString()
{    throw new UnsupportedOperationException("Not supported yet.");}
7a704082341a235e83c8e8512683bfd4e606683c2a7331adb94e42fe0c4f6ad7
getRemoteUser
public String getRemoteUser()
{    throw new UnsupportedOperationException("Not supported yet.");}
79438252e97fceeb1d82609d90f6afad95f8f768ff65fb71c428a92b0146e2ed
isUserInRole
public boolean isUserInRole(String role)
{    throw new UnsupportedOperationException("Not supported yet.");}
5d9bb0cdc7b2aa820d5d654cc4e191bb6fca3070733bad6303dfb3f7744ead0a
getUserPrincipal
public Principal getUserPrincipal()
{    throw new UnsupportedOperationException("Not supported yet.");}
e56b1108091fe9672e1528ce5995ac3fa13b44b9f1217b7ea3a1e9e5b52833e5
getRequestedSessionId
public String getRequestedSessionId()
{    throw new UnsupportedOperationException("Not supported yet.");}
36b26a68930fb147c2256251e6144032adb25b7313e9bfd66b646c5b3311234a
getRequestURI
public String getRequestURI()
{    throw new UnsupportedOperationException("Not supported yet.");}
66f1c944211008a90ffacd9aed8af6e5b661104535214981ba2202efd8fb54ec
getRequestURL
public StringBuffer getRequestURL()
{    throw new UnsupportedOperationException("Not supported yet.");}
b05723a1cff0d36c5ac027abcbfe10f6b028aaf2fb08552c33e326a54e901818
getServletPath
public String getServletPath()
{    throw new UnsupportedOperationException("Not supported yet.");}
602a1ce6dc0819d1dcba30a60fc4377d9a00548c7e823ee6cef63a939cb2c79f
getSession
public HttpSession getSession(boolean create)
{    throw new UnsupportedOperationException("Not supported yet.");}
8671a3c391a4c1d16d46e234fe9b96b92ea0cef19bac007dc5f02541a7b0c75b
getSession
public HttpSession getSession()
{    throw new UnsupportedOperationException("Not supported yet.");}
ba084856e7597fba3995d87a09f865466046b950a345c327961652b9c6da8111
changeSessionId
public String changeSessionId()
{    return null;}
d9652c8fd847ec1d437759518061822e590079dafd23aa8ac8f148d365ca0301
isRequestedSessionIdValid
public boolean isRequestedSessionIdValid()
{    throw new UnsupportedOperationException("Not supported yet.");}
58571e473a7f2b59034411ca74271c20a7e9688d55f221aaced3111991a37006
isRequestedSessionIdFromCookie
public boolean isRequestedSessionIdFromCookie()
{    throw new UnsupportedOperationException("Not supported yet.");}
ae3f8403b41004eed4053f56fbcb00d1bcffbde205053e065abaad4caeedd167
isRequestedSessionIdFromURL
public boolean isRequestedSessionIdFromURL()
{    throw new UnsupportedOperationException("Not supported yet.");}
91fe83cc24a51476b247823443d2e339ad738ac0b2c5dcc936fc91135461a066
isRequestedSessionIdFromUrl
public boolean isRequestedSessionIdFromUrl()
{    throw new UnsupportedOperationException("Not supported yet.");}
6ac9687c0cbeb18dc5b2a9ae5355182d4904001f4caecec5b9259aced4264b26
authenticate
public boolean authenticate(HttpServletResponse response) throws IOException, ServletException
{    throw new UnsupportedOperationException("Not supported yet.");}
41f844b792d77695a83695310587878093199ca90167c20d4895369f3d1d7d6d
login
public void login(String username, String password) throws ServletException
{    throw new UnsupportedOperationException("Not supported yet.");}
a67df56b0b1e4d64ff144a3b770219afcba09841521b77ab852ba8816bb83f2f
logout
public void logout() throws ServletException
{    throw new UnsupportedOperationException("Not supported yet.");}
3788804bb4373016732d3f3ba97c666c2f54ec75b69747dfd2650725b51eb5fd
getParts
public Collection<Part> getParts() throws IOException, ServletException
{    throw new UnsupportedOperationException("Not supported yet.");}
6cd91e488a22108405d06609a2e6f3040bebbd588bd3c39379a7ecfdabb5d3f9
getPart
public Part getPart(String name) throws IOException, ServletException
{    throw new UnsupportedOperationException("Not supported yet.");}
7ba230d97689695694b46ad5713a9ceb7a7f956e8ebcab6da6292a7b3bce41e2
upgrade
public T upgrade(Class<T> handlerClass) throws IOException, ServletException
{    throw new UnsupportedOperationException("Not supported yet.");}
96440be7e79088e99a89c61b00b69b2672e3676f355e6cd72bbcc7b6ce9f52e7
getAttribute
public Object getAttribute(String name)
{    throw new UnsupportedOperationException("Not supported yet.");}
fe04c2f676a8d24a57ed5bfda43fbcfda44366dca8b7629b3c6ec9df33a7155e
getAttributeNames
public Enumeration<String> getAttributeNames()
{    throw new UnsupportedOperationException("Not supported yet.");}
2186a2d07d275933cee1ccdc23594c721a23eef874c7db3eaac48dc460261076
getCharacterEncoding
public String getCharacterEncoding()
{    return charset;}
1146ccfd8fbd52ac06edfd387636418325962c8bd3986593ba8477c262a05709
setCharacterEncoding
public void setCharacterEncoding(String env) throws UnsupportedEncodingException
{    this.charset = env;}
e46fa6eda177f5a73935edebc9250d53a0f24aff114a05533c5485d430532a0c
getContentLength
public int getContentLength()
{    throw new UnsupportedOperationException("Not supported yet.");}
ad88cb8c83027755533559c9cdaf0551ae9742b3e37c33f4e8688212d795ab55
getContentLengthLong
public long getContentLengthLong()
{    return 0;}
baea39c86756a5efaaec8e2f01175d687e0a60e86379d9b91d98a3d4089abf86
getContentType
public String getContentType()
{    return null;}
bf6e925563f9c2ae72d990408dc442b0450abe4f49c7342f20f60383d755aefa
getInputStream
public ServletInputStream getInputStream() throws IOException
{    return stream;}
c74d5696b207ef199f062aa5cb98dab40366de6923677c46f82a5be4d0be9c6a
getParameter
public String getParameter(String name)
{    throw new UnsupportedOperationException("Not supported yet.");}
da1edb550971d2db36a5e70ce4124ef54b6deaddfabb363dca98459dc7e4101a
getParameterNames
public Enumeration getParameterNames()
{    return Collections.enumeration(Collections.EMPTY_LIST);}
d504a649d3f21a51cd09758546ba9d7dd553d645200658cda85ea3fb5bced486
getParameterValues
public String[] getParameterValues(String name)
{    throw new UnsupportedOperationException("Not supported yet.");}
efd00dc861b6d618d3678f028beaabd1ee182c9104b354bc9e18cc2728dce1f6
getParameterMap
public Map getParameterMap()
{    throw new UnsupportedOperationException("Not supported yet.");}
6a5c52ec96402a32005f10b5e3e237a089c21a231622163ebe5dea143f2fdbbe
getProtocol
public String getProtocol()
{    throw new UnsupportedOperationException("Not supported yet.");}
e061928b565977a057ff8a6d86fe57cbf8a9d77f4650b89ecccf6a3fad75b041
getScheme
public String getScheme()
{    throw new UnsupportedOperationException("Not supported yet.");}
295e56d955a85a3ecf1251e130a26abbf506ec6fe560fa3e0abe83095fba1f9a
getServerName
public String getServerName()
{    throw new UnsupportedOperationException("Not supported yet.");}
fb00e90a8ec104f857c0c29dc4ec4c66b82069eacd0acdce01e781796bfb2af5
getServerPort
public int getServerPort()
{    throw new UnsupportedOperationException("Not supported yet.");}
86b2b71b7b98edff9f5113d051d8f5d57c4ffe08d33c255c11978eda6ae8852e
getReader
public BufferedReader getReader() throws IOException
{    throw new UnsupportedOperationException("Not supported yet.");}
b129b8faa1ae3da62e0297e32d848abc7421f1c3ebcf5e63c0471b443bdf881b
getRemoteAddr
public String getRemoteAddr()
{    throw new UnsupportedOperationException("Not supported yet.");}
fa9749b81b10c14461936619cc780fa60a31019edb5168107252ae924f220fce
getRemoteHost
public String getRemoteHost()
{    throw new UnsupportedOperationException("Not supported yet.");}
945a35d3fb518a0c55804c2d155dc288910a9bdad8c692b09944714f67a4b5d0
setAttribute
public void setAttribute(String name, Object o)
{    throw new UnsupportedOperationException("Not supported yet.");}
ebd826e2f5ea1795265bbd6a04f646d353eadedf491f3582776219967aa556df
removeAttribute
public void removeAttribute(String name)
{    throw new UnsupportedOperationException("Not supported yet.");}
62c15d02f6b13e14cb41947626ab4f45983b517eef0d7b1c1622bc399cd93159
getLocale
public Locale getLocale()
{    throw new UnsupportedOperationException("Not supported yet.");}
fd32db1eab8cac484748888f74cf98e1fc3ce0e7fac178a6d95afaef6a975a17
getLocales
public Enumeration<Locale> getLocales()
{    throw new UnsupportedOperationException("Not supported yet.");}
c6a8b35027b486f9efda96936274975b221803473bdc28c586ea3371f63c78bd
isSecure
public boolean isSecure()
{    throw new UnsupportedOperationException("Not supported yet.");}
261bef39e3b74518d9c03fb40ced3026ed4a9a50ba03b84a7d71cf95e6caaf64
getRequestDispatcher
public RequestDispatcher getRequestDispatcher(String path)
{    throw new UnsupportedOperationException("Not supported yet.");}
ddc87359e020d4228fdab5b6243687c240939f8507efa0581636dcf1e6cdbdf1
getRealPath
public String getRealPath(String path)
{    throw new UnsupportedOperationException("Not supported yet.");}
9c5c1eedb87aa6332e5956f6ee46498fe5e4bb3e3a11f5ee878d0dd6b5ba22ad
getRemotePort
public int getRemotePort()
{    throw new UnsupportedOperationException("Not supported yet.");}
d1e8aa28b8adf9b8d244c889974bf7ae0383bb51d67dd63248f2c0c9b4e4c8db
getLocalName
public String getLocalName()
{    throw new UnsupportedOperationException("Not supported yet.");}
0bc6bc164c2b7fbabb37c3d670ec3211f1ce84575579d2adcc3a34a0b0bd9056
getLocalAddr
public String getLocalAddr()
{    throw new UnsupportedOperationException("Not supported yet.");}
0f9342907a55818619d2e2cfa5fa813892dc2783be692f8ecc0da9029bc998d0
getLocalPort
public int getLocalPort()
{    throw new UnsupportedOperationException("Not supported yet.");}
080e6dfeffad4589787f1a6fda9a213672aea9ede479cb0719278c34fafc3319
getServletContext
public ServletContext getServletContext()
{    throw new UnsupportedOperationException("Not supported yet.");}
154a6bd872ba0d39f3ed62089a137afd64d911175701322fc9c622d6a8f1b523
startAsync
public AsyncContext startAsync() throws IllegalStateException
{    throw new UnsupportedOperationException("Not supported yet.");}
f8608163962a2d8aded2eaa20e9fea1e9ca8c0f5ccff8f591173b69ebcd1842e
startAsync
public AsyncContext startAsync(ServletRequest servletRequest, ServletResponse servletResponse) throws IllegalStateException
{    throw new UnsupportedOperationException("Not supported yet.");}
f317c516ab0d1c2358099c3604dd9fcf3e25af304bb62be5a6ac6e47e937c9d1
isAsyncStarted
public boolean isAsyncStarted()
{    throw new UnsupportedOperationException("Not supported yet.");}
b33ca950ff93e2cf1f82311fa73d014537b855c5167fb191c39d6826cbb52b13
isAsyncSupported
public boolean isAsyncSupported()
{    throw new UnsupportedOperationException("Not supported yet.");}
5e489504343d251f353e96081a17ff43164a17f5ac571bcf117c9249ccfe8a54
getAsyncContext
public AsyncContext getAsyncContext()
{    throw new UnsupportedOperationException("Not supported yet.");}
3823289235931b640c6d381d0692a0b4d3d4c6a63a4b6249b9d1f44cec867b93
getDispatcherType
public DispatcherType getDispatcherType()
{    throw new UnsupportedOperationException("Not supported yet.");}
f79d05b42c11ee1f4b1e4e4ab6d21344c052d3a318f2568b7f96a49637f98b76
readChar
public int readChar() throws IOException
{    throw new UnsupportedOperationException("This test class doesn't return " + "strings!");}
740b2d69a871de3f06de1d6974b0a76e5d58ff23733964f6f17d60eedfcb816d
mark
public void mark() throws IOException
{    markPos = curPos;}
39fd2a669bd97a959085d10145da4dcd11d83878afcd67b2123354de7e8771d9
reset
public void reset() throws IOException
{    curPos = markPos;}
62032bfd4a1c0bb1c932a4c527e1d71aebf93308af8494a3c9f3705168a09088
seek
public void seek(long position) throws IOException
{    throw new UnsupportedOperationException("Unimplemented in test class");}
0efa2bd8fc7bc3d72996c492a3eaca80646290caeceea873a5afabb84aa9504c
tell
public long tell() throws IOException
{    throw new UnsupportedOperationException("Unimplemented in test class");}
00c6cb892813c6b89e072a7f09dccdece629f30849daab28245b06f3e679bf54
read
public int read() throws IOException
{    if (curPos >= str.length()) {        return -1;    }    return str.charAt(curPos++);}
56e08d87e6bd0be2a60f9b2de3195d58bc9d56a2637f6fed6210d21e832632ea
read
public int read(byte[] b, int off, int len) throws IOException
{    if (curPos >= str.length()) {        return -1;    }    int n = 0;    while (len > 0 && curPos < str.length()) {        b[off++] = (byte) str.charAt(curPos++);        n++;        len--;    }    return n;}
e0823f55b3a09d41a3e1e792f7e6687db9199c2db9b29e9922d93cbdc6f1284b
close
public void close() throws IOException
{}
5ff0b8f7d2b080bcc6214fa5f91be74727145ea81cacb63a99c8d0f3106c089f
setup
public void setup()
{    StringBuilder sb = new StringBuilder();    sb.append("line 1\n");    sb.append("line 2\n");    mini = sb.toString();}
32a84367eb013cb94c7ed1f29a1624497de1920a58948a2e1df03fccabd66c62
testSimple
public void testSimple() throws IOException
{    ResettableInputStream in = new ResettableTestStringInputStream(mini);    EventDeserializer des = new BlobDeserializer(new Context(), in);    validateMiniParse(des);}
f497c90b97ac6150ded473fcbc9852cd06a58f33d996face04ec89cb2ee12187
testSimpleViaBuilder
public void testSimpleViaBuilder() throws IOException
{    ResettableInputStream in = new ResettableTestStringInputStream(mini);    EventDeserializer.Builder builder = new BlobDeserializer.Builder();    EventDeserializer des = builder.build(new Context(), in);    validateMiniParse(des);}
6ec2c359dd933b344ad5dfe4c5fce80cdbacb465064151cea418f82a9dc5a5be
testSimpleViaFactory
public void testSimpleViaFactory() throws IOException
{    ResettableInputStream in = new ResettableTestStringInputStream(mini);    EventDeserializer des;    des = EventDeserializerFactory.getInstance(BlobDeserializer.Builder.class.getName(), new Context(), in);    validateMiniParse(des);}
acb7c05d6d1c6eae20d98d66bef35127a15fff8c529d9b477c929594b70eaf93
testBatch
public void testBatch() throws IOException
{    ResettableInputStream in = new ResettableTestStringInputStream(mini);    EventDeserializer des = new BlobDeserializer(new Context(), in);    List<Event> events;        events = des.readEvents(10);    assertEquals(1, events.size());    assertEventBodyEquals(mini, events.get(0));    des.mark();    des.close();}
6ef8c18bb46f92dbe2f36b9f66520a306c35dff6a795a9cb9ffab7d05de8dc07
testMaxLineLength
public void testMaxLineLength() throws IOException
{    String longLine = "abcdefghijklmnopqrstuvwxyz\n";    Context ctx = new Context();    ctx.put(BlobDeserializer.MAX_BLOB_LENGTH_KEY, "10");    ResettableInputStream in = new ResettableTestStringInputStream(longLine);    EventDeserializer des = new BlobDeserializer(ctx, in);    assertEventBodyEquals("abcdefghij", des.readEvent());    assertEventBodyEquals("klmnopqrst", des.readEvent());    assertEventBodyEquals("uvwxyz\n", des.readEvent());    assertNull(des.readEvent());}
05e3edadce85d5800c7a30094e91f4722af2211c20b5089f20718edb9e6f953d
assertEventBodyEquals
private void assertEventBodyEquals(String expected, Event event)
{    String bodyStr = new String(event.getBody(), Charsets.UTF_8);    assertEquals(expected, bodyStr);}
67ad278bfd37e5c8ef4f08d61f76c86b25a937db01dc8fa22335bd85aa8729a2
validateMiniParse
private void validateMiniParse(EventDeserializer des) throws IOException
{    Event evt;    des.mark();    evt = des.readEvent();    assertEquals(new String(evt.getBody()), mini);        des.reset();    evt = des.readEvent();    assertEquals("data should be repeated, " + "because we reset() the stream", new String(evt.getBody()), mini);    evt = des.readEvent();    assertNull("Event should be null because there are no lines " + "left to read", evt);    des.mark();    des.close();}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    handler = new BlobHandler();}
cff45a0d39426061b080e44b420ee4494425129e7aeafde8ca1a634bec77f50a
testSingleEvent
public void testSingleEvent() throws Exception
{    byte[] json = "foo".getBytes("UTF-8");    HttpServletRequest req = new FlumeHttpServletRequestWrapper(json);    List<Event> deserialized = handler.getEvents(req);    assertEquals(1, deserialized.size());    Event e = deserialized.get(0);    assertEquals(0, e.getHeaders().size());    assertEquals("foo", new String(e.getBody(), "UTF-8"));}
3ca80d6453012f79d6bf35282c5266f1a1df58abb6413de7604ce74ebcebbcdf
testEmptyEvent
public void testEmptyEvent() throws Exception
{    byte[] json = "".getBytes("UTF-8");    HttpServletRequest req = new FlumeHttpServletRequestWrapper(json);    List<Event> deserialized = handler.getEvents(req);    assertEquals(1, deserialized.size());    Event e = deserialized.get(0);    assertEquals(0, e.getHeaders().size());    assertEquals("", new String(e.getBody(), "UTF-8"));}
d2c3d738e59fcec085da08860f62ecedf71c28d69034e0d781bc5f3e675aa004
testEnvironment
public void testEnvironment() throws UnknownHostException
{    super.testEnvironment();}
29c604177e2187259506e26c32f9acdf0e8eaac86e397042b5c2ac9f71d5aa9a
testNoOperation
public void testNoOperation() throws Exception
{    Context context = new Context();    context.put(MorphlineHandlerImpl.MORPHLINE_FILE_PARAM, RESOURCES_DIR + "/test-morphlines/noOperation.conf");    Event input = EventBuilder.withBody("foo", Charsets.UTF_8);    input.getHeaders().put("name", "nadja");    MorphlineInterceptor interceptor = build(context);    Event actual = interceptor.intercept(input);    interceptor.close();    Event expected = EventBuilder.withBody("foo".getBytes("UTF-8"), ImmutableMap.of("name", "nadja"));    assertEqualsEvent(expected, actual);    List<Event> actualList = build(context).intercept(Collections.singletonList(input));    List<Event> expectedList = Collections.singletonList(expected);    assertEqualsEventList(expectedList, actualList);}
7395698686159fc1a0c3f22ae9ccb533526af392f17c98bd9fe000ae2f8ad454
testReadClob
public void testReadClob() throws Exception
{    Context context = new Context();    context.put(MorphlineHandlerImpl.MORPHLINE_FILE_PARAM, RESOURCES_DIR + "/test-morphlines/readClob.conf");    Event input = EventBuilder.withBody("foo", Charsets.UTF_8);    input.getHeaders().put("name", "nadja");    Event actual = build(context).intercept(input);    Event expected = EventBuilder.withBody(null, ImmutableMap.of("name", "nadja", Fields.MESSAGE, "foo"));    assertEqualsEvent(expected, actual);    List<Event> actualList = build(context).intercept(Collections.singletonList(input));    List<Event> expectedList = Collections.singletonList(expected);    assertEqualsEventList(expectedList, actualList);}
cd3df4aa27b30809d7cfcf12046ba7345aca38bb14e34caa222ac1108325fc55
testGrokIfNotMatchDropEventRetain
public void testGrokIfNotMatchDropEventRetain() throws Exception
{    Context context = new Context();    context.put(MorphlineHandlerImpl.MORPHLINE_FILE_PARAM, RESOURCES_DIR + "/test-morphlines/grokIfNotMatchDropRecord.conf");    String msg = "<164>Feb  4 10:46:14 syslog sshd[607]: Server listening on 0.0.0.0 port 22.";    Event input = EventBuilder.withBody(null, ImmutableMap.of(Fields.MESSAGE, msg));    Event actual = build(context).intercept(input);    Map<String, String> expected = new HashMap();    expected.put(Fields.MESSAGE, msg);    expected.put("syslog_pri", "164");    expected.put("syslog_timestamp", "Feb  4 10:46:14");    expected.put("syslog_hostname", "syslog");    expected.put("syslog_program", "sshd");    expected.put("syslog_pid", "607");    expected.put("syslog_message", "Server listening on 0.0.0.0 port 22.");    Event expectedEvent = EventBuilder.withBody(null, expected);    assertEqualsEvent(expectedEvent, actual);}
8b746787ebe6bd70b2f6b1722f44ad404a11152d2ec66a696f2dfd5c8ad7134d
testGrokIfNotMatchDropEventDrop
public void testGrokIfNotMatchDropEventDrop() throws Exception
{    Context context = new Context();    context.put(MorphlineHandlerImpl.MORPHLINE_FILE_PARAM, RESOURCES_DIR + "/test-morphlines/grokIfNotMatchDropRecord.conf");    String msg = "<XXXXXXXXXXXXX164>Feb  4 10:46:14 syslog sshd[607]: Server listening on 0.0.0.0" + " port 22.";    Event input = EventBuilder.withBody(null, ImmutableMap.of(Fields.MESSAGE, msg));    Event actual = build(context).intercept(input);    assertNull(actual);}
71c5ec31682ae2f6163f1e83b6222e55705384308e911339515ec5d71d5a79f5
testIfDetectMimeTypeRouteToSouthPole
public void testIfDetectMimeTypeRouteToSouthPole() throws Exception
{    Context context = new Context();    context.put(MorphlineHandlerImpl.MORPHLINE_FILE_PARAM, RESOURCES_DIR + "/test-morphlines/ifDetectMimeType.conf");    context.put(MorphlineHandlerImpl.MORPHLINE_VARIABLE_PARAM + ".MY.MIME_TYPE", "avro/binary");    Event input = EventBuilder.withBody(Files.toByteArray(new File(RESOURCES_DIR + "/test-documents/sample-statuses-20120906-141433.avro")));    Event actual = build(context).intercept(input);    Map<String, String> expected = new HashMap();    expected.put(Fields.ATTACHMENT_MIME_TYPE, "avro/binary");    expected.put("flume.selector.header", "goToSouthPole");    Event expectedEvent = EventBuilder.withBody(input.getBody(), expected);    assertEqualsEvent(expectedEvent, actual);}
b6d53f8fa38d9557ac30e648a4764e1a3ac38f410696c1cb08a589d1183d943b
testIfDetectMimeTypeRouteToNorthPole
public void testIfDetectMimeTypeRouteToNorthPole() throws Exception
{    Context context = new Context();    context.put(MorphlineHandlerImpl.MORPHLINE_FILE_PARAM, RESOURCES_DIR + "/test-morphlines/ifDetectMimeType.conf");    context.put(MorphlineHandlerImpl.MORPHLINE_VARIABLE_PARAM + ".MY.MIME_TYPE", "avro/binary");    Event input = EventBuilder.withBody(Files.toByteArray(new File(RESOURCES_DIR + "/test-documents/testPDF.pdf")));    Event actual = build(context).intercept(input);    Map<String, String> expected = new HashMap();    expected.put(Fields.ATTACHMENT_MIME_TYPE, "application/pdf");    expected.put("flume.selector.header", "goToNorthPole");    Event expectedEvent = EventBuilder.withBody(input.getBody(), expected);    assertEqualsEvent(expectedEvent, actual);}
5bf5e509998a336aa9048cb7fe3ac83384775d2283be6a6d4d55486e6823ad7f
build
private MorphlineInterceptor build(Context context)
{    MorphlineInterceptor.Builder builder = new MorphlineInterceptor.Builder();    builder.configure(context);    return builder.build();}
dff916a83d4e257df29f717806123a245dc11321cb85b1bd1fc1d7a93d18f023
assertEqualsEvent
private void assertEqualsEvent(Event x, Event y)
{    assertEquals(x.getHeaders(), y.getHeaders());    assertArrayEquals(x.getBody(), y.getBody());}
c66cab352d8a04d431c4841f8e8abc46eb7e412805aa903e143e9d2c09014786
assertEqualsEventList
private void assertEqualsEventList(List<Event> x, List<Event> y)
{    assertEquals(x.size(), y.size());    for (int i = 0; i < x.size(); i++) {        assertEqualsEvent(x.get(i), y.get(i));    }}
81e78d1f1080f58927e894cc7af89e38108e891ad2362929e9acf0f15a045e30
beforeClass
public static void beforeClass() throws Exception
{    initCore(RESOURCES_DIR + "/solr/collection1/conf/solrconfig.xml", RESOURCES_DIR + "/solr/collection1/conf/schema.xml", RESOURCES_DIR + "/solr");}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    super.setUp();    String path = RESOURCES_DIR + "/test-documents";    expectedRecords = new HashMap();    expectedRecords.put(path + "/sample-statuses-20120906-141433.avro", 2);    expectedRecords.put(path + "/sample-statuses-20120906-141433", 2);    expectedRecords.put(path + "/sample-statuses-20120906-141433.gz", 2);    expectedRecords.put(path + "/sample-statuses-20120906-141433.bz2", 2);    expectedRecords.put(path + "/cars.csv", 5);    expectedRecords.put(path + "/cars.csv.gz", 5);    expectedRecords.put(path + "/cars.tar.gz", 4);    expectedRecords.put(path + "/cars.tsv", 5);    expectedRecords.put(path + "/cars.ssv", 5);    final Map<String, String> context = new HashMap();    if (EXTERNAL_SOLR_SERVER_URL != null) {        throw new UnsupportedOperationException();                } else {        if (TEST_WITH_EMBEDDED_SOLR_SERVER) {            solrServer = new TestEmbeddedSolrServer(h.getCoreContainer(), "");        } else {            throw new RuntimeException("Not yet implemented");                }    }    Map<String, String> channelContext = new HashMap();    channelContext.put("capacity", "1000000");        channelContext.put("keep-alive", "0");    Channel channel = new MemoryChannel();    channel.setName(channel.getClass().getName() + SEQ_NUM.getAndIncrement());    Configurables.configure(channel, new Context(channelContext));    class MySolrSink extends MorphlineSolrSink {        public MySolrSink(MorphlineHandlerImpl indexer) {            super(indexer);        }    }    int batchSize = SEQ_NUM2.incrementAndGet() % 2 == 0 ? 100 : 1;    DocumentLoader testServer = new SolrServerDocumentLoader(solrServer, batchSize);    MorphlineContext solrMorphlineContext = new SolrMorphlineContext.Builder().setDocumentLoader(testServer).setExceptionHandler(new FaultTolerance(false, false, SolrServerException.class.getName())).setMetricRegistry(new MetricRegistry()).build();    MorphlineHandlerImpl impl = new MorphlineHandlerImpl();    impl.setMorphlineContext(solrMorphlineContext);    class MySolrLocator extends     SolrLocator {        public MySolrLocator(MorphlineContext indexer) {            super(indexer);        }    }    SolrLocator locator = new MySolrLocator(solrMorphlineContext);    locator.setSolrHomeDir(testSolrHome + "/collection1");    String str1 = "SOLR_LOCATOR : " + locator.toString();            File morphlineFile = new File("target/test-classes/test-morphlines/solrCellDocumentTypes.conf");    String str2 = Files.toString(morphlineFile, Charsets.UTF_8);    tmpFile = File.createTempFile("morphline", ".conf");    tmpFile.deleteOnExit();    Files.write(str1 + "\n" + str2, tmpFile, Charsets.UTF_8);    context.put("morphlineFile", tmpFile.getPath());    impl.configure(new Context(context));    sink = new MySolrSink(impl);    sink.setName(sink.getClass().getName() + SEQ_NUM.getAndIncrement());    sink.configure(new Context(context));    sink.setChannel(channel);    sink.start();    source = new EmbeddedSource(sink);    ChannelSelector rcs = new ReplicatingChannelSelector();    rcs.setChannels(Collections.singletonList(channel));    ChannelProcessor chp = new ChannelProcessor(rcs);    Context chpContext = new Context();    chpContext.put("interceptors", "uuidinterceptor");    chpContext.put("interceptors.uuidinterceptor.type", UUIDInterceptor.Builder.class.getName());    chp.configure(chpContext);    source.setChannelProcessor(chp);    deleteAllDocuments();}
879f92aa13309fcc79d3e9cda22a631a7578f981a82b5ad06f7bdedf285ef2ab
deleteAllDocuments
private void deleteAllDocuments() throws SolrServerException, IOException
{    SolrServer s = solrServer;        s.deleteByQuery("*:*");    s.commit();}
c6aaebb5a52567751db8dc8e1cb9dd4a4e582ef964a374b376c6a04f741802dc
tearDown
public void tearDown() throws Exception
{    try {        if (source != null) {            source.stop();            source = null;        }        if (sink != null) {            sink.stop();            sink = null;        }        if (tmpFile != null) {            tmpFile.delete();        }    } finally {        solrServer = null;        expectedRecords = null;        super.tearDown();    }}
aa0080af5c542afec65e5e0905031767176ba3a8b414aa5dc9c5022f79a7872f
testDocumentTypes
public void testDocumentTypes() throws Exception
{    String path = RESOURCES_DIR + "/test-documents";    String[] files = new String[] { path + "/testBMPfp.txt", path + "/boilerplate.html", path + "/NullHeader.docx", path + "/testWORD_various.doc", path + "/testPDF.pdf", path + "/testJPEG_EXIF.jpg", path + "/testXML.xml",     path + "/sample-statuses-20120906-141433.avro", path + "/sample-statuses-20120906-141433", path + "/sample-statuses-20120906-141433.gz", path + "/sample-statuses-20120906-141433.bz2" };    testDocumentTypesInternal(files);}
83a7bd6ed69f270fbb235f605c0ba1862ac707a02c46b815451df15d82b7cdbb
testDocumentTypes2
public void testDocumentTypes2() throws Exception
{    String path = RESOURCES_DIR + "/test-documents";    String[] files = new String[] { path + "/testPPT_various.ppt", path + "/testPPT_various.pptx", path + "/testEXCEL.xlsx", path + "/testEXCEL.xls", path + "/testPages.pages", path + "/testNumbers.numbers", path + "/testKeynote.key", path + "/testRTFVarious.rtf", path + "/complex.mbox", path + "/test-outlook.msg", path + "/testEMLX.emlx",     path + "/rsstest.rss", path + "/testMP3i18n.mp3", path + "/testAIFF.aif", path + "/testFLAC.flac",     path + "/testMP4.m4a", path + "/testWAV.wav", path + "/testFLV.flv", path + "/testBMP.bmp", path + "/testPNG.png", path + "/testPSD.psd", path + "/testSVG.svg", path + "/testTIFF.tif",     path + "/testTrueType.ttf", path + "/testVISIO.vsd"                 };    testDocumentTypesInternal(files);}
372d76569b82137cc5011f1824442b986efe1a923733b253995be02256a9b325
testErrorCounters
public void testErrorCounters() throws Exception
{    Channel channel = Mockito.mock(Channel.class);    Mockito.when(channel.take()).thenThrow(new ChannelException("dummy"));    Transaction transaction = Mockito.mock(BasicTransactionSemantics.class);    Mockito.when(channel.getTransaction()).thenReturn(transaction);    sink.setChannel(channel);    sink.process();    SinkCounter sinkCounter = (SinkCounter) Whitebox.getInternalState(sink, "sinkCounter");    assertEquals(1, sinkCounter.getChannelReadFail());}
8fa222a5cd67866eff8c237ca1c24db0b3e90517941f6dd869fd32685b32f1d8
testAvroRoundTrip
public void testAvroRoundTrip() throws Exception
{    String file = RESOURCES_DIR + "/test-documents" + "/sample-statuses-20120906-141433.avro";    testDocumentTypesInternal(file);    QueryResponse rsp = query("*:*");    Iterator<SolrDocument> iter = rsp.getResults().iterator();    ListMultimap<String, String> expectedFieldValues;    expectedFieldValues = ImmutableListMultimap.of("id", "1234567890", "text", "sample tweet one", "user_screen_name", "fake_user1");    assertEquals(expectedFieldValues, next(iter));    expectedFieldValues = ImmutableListMultimap.of("id", "2345678901", "text", "sample tweet two", "user_screen_name", "fake_user2");    assertEquals(expectedFieldValues, next(iter));    assertFalse(iter.hasNext());}
833bbbeb27294a8feb64ea69574623e0416ea6b687cfcddb8a95fa60fc41d385
next
private ListMultimap<String, Object> next(Iterator<SolrDocument> iter)
{    SolrDocument doc = iter.next();    Record record = toRecord(doc);        record.removeAll("_version_");    return record.getFields();}
6c242705b6211f654a6828154276e9fb72fbbb911748057a51c771ba8917f60e
toRecord
private Record toRecord(SolrDocument doc)
{    Record record = new Record();    for (String key : doc.keySet()) {        record.getFields().replaceValues(key, doc.getFieldValues(key));    }    return record;}
39f56991251fb44a9753f86f6300fe41778785cf4e2b7e21e1bb502b89012f00
testDocumentTypesInternal
private void testDocumentTypesInternal(String... files) throws Exception
{    int numDocs = 0;    long startTime = System.currentTimeMillis();    assertEquals(numDocs, queryResultSetSize("*:*"));        for (int i = 0; i < 1; i++) {        for (String file : files) {            File f = new File(file);            byte[] body = Files.toByteArray(f);            Event event = EventBuilder.withBody(body);            event.getHeaders().put(Fields.ATTACHMENT_NAME, f.getName());            load(event);            Integer count = expectedRecords.get(file);            if (count != null) {                numDocs += count;            } else {                numDocs++;            }            assertEquals(numDocs, queryResultSetSize("*:*"));        }        LOGGER.trace("iter: {}", i);    }    LOGGER.trace("all done with put at {}", System.currentTimeMillis() - startTime);    assertEquals(numDocs, queryResultSetSize("*:*"));    LOGGER.trace("sink: ", sink);}
f13d75330367268f835fdd670fcac03753d4e3a012ac56322df8e6de8c61b0d3
benchmarkDocumentTypes
public void benchmarkDocumentTypes() throws Exception
{    int iters = 200;        assertEquals(0, queryResultSetSize("*:*"));    String path = RESOURCES_DIR + "/test-documents";    String[] files = new String[] {     path + "/sample-statuses-20120906-141433-medium.avro" };    List<Event> events = new ArrayList();    for (String file : files) {        File f = new File(file);        byte[] body = Files.toByteArray(f);        Event event = EventBuilder.withBody(body);                events.add(event);    }    long startTime = System.currentTimeMillis();    for (int i = 0; i < iters; i++) {        if (i % 10000 == 0) {            LOGGER.info("iter: {}", i);        }        for (Event event : events) {            event = EventBuilder.withBody(event.getBody(), new HashMap(event.getHeaders()));            event.getHeaders().put("id", UUID.randomUUID().toString());            load(event);        }    }    float secs = (System.currentTimeMillis() - startTime) / 1000.0f;    long numDocs = queryResultSetSize("*:*");    LOGGER.info("Took secs: " + secs + ", iters/sec: " + (iters / secs));    LOGGER.info("Took secs: " + secs + ", docs/sec: " + (numDocs / secs));    LOGGER.info("Iterations: " + iters + ", numDocs: " + numDocs);    LOGGER.info("sink: ", sink);}
8c072c64158b0f52e3af6034da0959ab5879618a868324012a1ad168fa575dd0
load
private void load(Event event) throws EventDeliveryException
{    source.load(event);}
c48eb0113618884320980b5d3c8660ec1df8ce603ec74845cf2ae82a8afb4206
commit
private void commit() throws SolrServerException, IOException
{    solrServer.commit(false, true, true);}
6ff2bdd51d2face4334dd25d4173308e268ac54908fdd969243cafb10019078d
queryResultSetSize
private int queryResultSetSize(String query) throws SolrServerException, IOException
{    commit();    QueryResponse rsp = query(query);    LOGGER.debug("rsp: {}", rsp);    int size = rsp.getResults().size();    return size;}
43ccdeb920c3f9b5ae3c24a0597e34534521ec921bb3c34852c2a28e9657174a
query
private QueryResponse query(String query) throws SolrServerException, IOException
{    commit();    QueryResponse rsp = solrServer.query(new SolrQuery(query).setRows(Integer.MAX_VALUE));    LOGGER.debug("rsp: {}", rsp);    return rsp;}
374f30b9565fa26944e766e4b0405ecb054a03175df55727b3e28dc9fd8468ac
testBasic
public void testBasic() throws Exception
{    Context context = new Context();    context.put(UUIDInterceptor.HEADER_NAME, ID);    context.put(UUIDInterceptor.PRESERVE_EXISTING_NAME, "true");    Event event = new SimpleEvent();    assertTrue(build(context).intercept(event).getHeaders().get(ID).length() > 0);}
25b9eacb20d80a2ae8a041c992568940b2b0e4719257679a08c99782005a6e98
testPreserveExisting
public void testPreserveExisting() throws Exception
{    Context context = new Context();    context.put(UUIDInterceptor.HEADER_NAME, ID);    context.put(UUIDInterceptor.PRESERVE_EXISTING_NAME, "true");    Event event = new SimpleEvent();    event.getHeaders().put(ID, "foo");    assertEquals("foo", build(context).intercept(event).getHeaders().get(ID));}
211fe5981d1c2d523147e4319878d903a75390843a8a7c5ae38f9b3b3d41aac8
testPrefix
public void testPrefix() throws Exception
{    Context context = new Context();    context.put(UUIDInterceptor.HEADER_NAME, ID);    context.put(UUIDInterceptor.PREFIX_NAME, "bar#");    Event event = new SimpleEvent();    assertTrue(build(context).intercept(event).getHeaders().get(ID).startsWith("bar#"));}
acb8e3eb4c0c6768a82610b28a774d49b4c421e9ef889b0beed948e0250d9278
build
private UUIDInterceptor build(Context context)
{    UUIDInterceptor.Builder builder = new UUIDInterceptor.Builder();    builder.configure(context);    return builder.build();}
f9265f02ba18402a279cd162c0dfe2d2bd83ddd12bfb06e14c4fc2254ee6e748
build
public JMSMessageConverter build(Context context)
{    return new DefaultJMSMessageConverter(context.getString(JMSSourceConfiguration.CONVERTER_CHARSET, JMSSourceConfiguration.CONVERTER_CHARSET_DEFAULT).trim());}
27bda62e0f43687123a1918f1f7dfa8ae41b6c947693dad532b5807d20da03ef
convert
public List<Event> convert(Message message) throws JMSException
{    Event event = new SimpleEvent();    Map<String, String> headers = event.getHeaders();    @SuppressWarnings("rawtypes")    Enumeration propertyNames = message.getPropertyNames();    while (propertyNames.hasMoreElements()) {        String name = propertyNames.nextElement().toString();        String value = message.getStringProperty(name);        headers.put(name, value);    }    if (message instanceof BytesMessage) {        BytesMessage bytesMessage = (BytesMessage) message;        long length = bytesMessage.getBodyLength();        if (length > 0L) {            if (length > Integer.MAX_VALUE) {                throw new JMSException("Unable to process message " + "of size " + length);            }            byte[] body = new byte[(int) length];            int count = bytesMessage.readBytes(body);            if (count != length) {                throw new JMSException("Unable to read full message. " + "Read " + count + " of total " + length);            }            event.setBody(body);        }    } else if (message instanceof TextMessage) {        TextMessage textMessage = (TextMessage) message;        String text = textMessage.getText();        if (text != null) {            event.setBody(text.getBytes(charset));        }    } else if (message instanceof ObjectMessage) {        ObjectMessage objectMessage = (ObjectMessage) message;        Object object = objectMessage.getObject();        if (object != null) {            ByteArrayOutputStream bos = new ByteArrayOutputStream();            ObjectOutput out = null;            try {                out = new ObjectOutputStream(bos);                out.writeObject(object);                event.setBody(bos.toByteArray());            } catch (IOException e) {                throw new FlumeException("Error serializing object", e);            } finally {                try {                    if (out != null) {                        out.close();                    }                } catch (IOException e) {                    throw new FlumeException("Error closing ObjectOutputStream", e);                }                try {                    if (bos != null) {                        bos.close();                    }                } catch (IOException e) {                    throw new FlumeException("Error closing ByteArrayOutputStream", e);                }            }        }    }    List<Event> events = new ArrayList<Event>(1);    events.add(event);    return events;}
aeeed91e7dd58062f6602440595fe8b203ee0352f5d74f880ba09cd1eb7b92e2
create
public InitialContext create(Properties properties) throws NamingException
{    return new InitialContext(properties);}
930162e542cf88ed4f92ab50fda102f2026e4d41f3714bf11ecf90451972aa82
take
 List<Event> take() throws JMSException
{    List<Event> result = new ArrayList<Event>(batchSize);    Message message;    message = receive();    if (message != null) {        result.addAll(messageConverter.convert(message));        int max = batchSize - 1;        for (int i = 0; i < max; i++) {            message = receiveNoWait();            if (message == null) {                break;            }            result.addAll(messageConverter.convert(message));        }    }    if (logger.isDebugEnabled()) {        logger.debug(String.format("Took batch of %s from %s", result.size(), destination));    }    return result;}
c5f66d172defe0af7ef7fe11551d401971d51af440f6e233a94150f2d0e89d67
receive
private Message receive() throws JMSException
{    try {        return messageConsumer.receive(pollTimeout);    } catch (RuntimeException runtimeException) {        JMSException jmsException = new JMSException("JMS provider has thrown runtime exception: " + runtimeException.getMessage());        jmsException.setLinkedException(runtimeException);        throw jmsException;    }}
107c52887b2f325e9760e76e75920a392805ef7b5e2ba1016f2784b17e61eb1f
receiveNoWait
private Message receiveNoWait() throws JMSException
{    try {        return messageConsumer.receiveNoWait();    } catch (RuntimeException runtimeException) {        JMSException jmsException = new JMSException("JMS provider has thrown runtime exception: " + runtimeException.getMessage());        jmsException.setLinkedException(runtimeException);        throw jmsException;    }}
82f9c6f7631c0032308657a9e04cd5550ffab5bb618af8d3bb87b0ed5b361235
commit
 void commit()
{    try {        session.commit();    } catch (JMSException jmsException) {        logger.warn("JMS Exception processing commit", jmsException);    } catch (RuntimeException runtimeException) {        logger.warn("Runtime Exception processing commit", runtimeException);    }}
2e94081e2d28268b3596b83003c951145926cd92b19c7bbf8e1284e49141ffe9
rollback
 void rollback()
{    try {        session.rollback();    } catch (JMSException jmsException) {        logger.warn("JMS Exception processing rollback", jmsException);    } catch (RuntimeException runtimeException) {        logger.warn("Runtime Exception processing rollback", runtimeException);    }}
c2864e5a4894768906844a2ddb5f229fc8d93aa73ebb06368e7b1ddbe43efd96
close
 void close()
{    try {        if (session != null) {            session.close();        }    } catch (JMSException e) {        logger.error("Could not destroy session", e);    }    try {        if (connection != null) {            connection.close();        }    } catch (JMSException e) {        logger.error("Could not destroy connection", e);    }}
142257108f477bf2e124e1838bfbce41c0a617c37f4ee7c5e0f8eb9232c79477
doConfigure
protected void doConfigure(Context context) throws FlumeException
{    sourceCounter = new SourceCounter(getName());    initialContextFactoryName = context.getString(JMSSourceConfiguration.INITIAL_CONTEXT_FACTORY, "").trim();    providerUrl = context.getString(JMSSourceConfiguration.PROVIDER_URL, "").trim();    destinationName = context.getString(JMSSourceConfiguration.DESTINATION_NAME, "").trim();    String destinationTypeName = context.getString(JMSSourceConfiguration.DESTINATION_TYPE, "").trim().toUpperCase(Locale.ENGLISH);    String destinationLocatorName = context.getString(JMSSourceConfiguration.DESTINATION_LOCATOR, JMSSourceConfiguration.DESTINATION_LOCATOR_DEFAULT).trim().toUpperCase(Locale.ENGLISH);    messageSelector = context.getString(JMSSourceConfiguration.MESSAGE_SELECTOR, "").trim();    batchSize = context.getInteger(JMSSourceConfiguration.BATCH_SIZE, JMSSourceConfiguration.BATCH_SIZE_DEFAULT);    errorThreshold = context.getInteger(JMSSourceConfiguration.ERROR_THRESHOLD, JMSSourceConfiguration.ERROR_THRESHOLD_DEFAULT);    userName = Optional.fromNullable(context.getString(JMSSourceConfiguration.USERNAME));    pollTimeout = context.getLong(JMSSourceConfiguration.POLL_TIMEOUT, JMSSourceConfiguration.POLL_TIMEOUT_DEFAULT);    clientId = Optional.fromNullable(context.getString(JMSSourceConfiguration.CLIENT_ID));    createDurableSubscription = context.getBoolean(JMSSourceConfiguration.CREATE_DURABLE_SUBSCRIPTION, JMSSourceConfiguration.DEFAULT_CREATE_DURABLE_SUBSCRIPTION);    durableSubscriptionName = context.getString(JMSSourceConfiguration.DURABLE_SUBSCRIPTION_NAME, JMSSourceConfiguration.DEFAULT_DURABLE_SUBSCRIPTION_NAME);    String passwordFile = context.getString(JMSSourceConfiguration.PASSWORD_FILE, "").trim();    if (passwordFile.isEmpty()) {        password = Optional.absent();    } else {        try {            password = Optional.of(Files.toString(new File(passwordFile), Charsets.UTF_8).trim());        } catch (IOException e) {            throw new FlumeException(String.format("Could not read password file %s", passwordFile), e);        }    }    String converterClassName = context.getString(JMSSourceConfiguration.CONVERTER_TYPE, JMSSourceConfiguration.CONVERTER_TYPE_DEFAULT).trim();    if (JMSSourceConfiguration.CONVERTER_TYPE_DEFAULT.equalsIgnoreCase(converterClassName)) {        converterClassName = DefaultJMSMessageConverter.Builder.class.getName();    }    Context converterContext = new Context(context.getSubProperties(JMSSourceConfiguration.CONVERTER + "."));    try {        @SuppressWarnings("rawtypes")        Class clazz = Class.forName(converterClassName);        boolean isBuilder = JMSMessageConverter.Builder.class.isAssignableFrom(clazz);        if (isBuilder) {            JMSMessageConverter.Builder builder = (JMSMessageConverter.Builder) clazz.newInstance();            converter = builder.build(converterContext);        } else {            Preconditions.checkState(JMSMessageConverter.class.isAssignableFrom(clazz), String.format("Class %s is not a subclass of JMSMessageConverter", clazz.getName()));            converter = (JMSMessageConverter) clazz.newInstance();            boolean configured = Configurables.configure(converter, converterContext);            if (logger.isDebugEnabled()) {                logger.debug(String.format("Attempted configuration of %s, result = %s", converterClassName, String.valueOf(configured)));            }        }    } catch (Exception e) {        throw new FlumeException(String.format("Unable to create instance of converter %s", converterClassName), e);    }    String connectionFactoryName = context.getString(JMSSourceConfiguration.CONNECTION_FACTORY, JMSSourceConfiguration.CONNECTION_FACTORY_DEFAULT).trim();    assertNotEmpty(initialContextFactoryName, String.format("Initial Context Factory is empty. This is specified by %s", JMSSourceConfiguration.INITIAL_CONTEXT_FACTORY));    assertNotEmpty(providerUrl, String.format("Provider URL is empty. This is specified by %s", JMSSourceConfiguration.PROVIDER_URL));    assertNotEmpty(destinationName, String.format("Destination Name is empty. This is specified by %s", JMSSourceConfiguration.DESTINATION_NAME));    assertNotEmpty(destinationTypeName, String.format("Destination Type is empty. This is specified by %s", JMSSourceConfiguration.DESTINATION_TYPE));    try {        destinationType = JMSDestinationType.valueOf(destinationTypeName);    } catch (IllegalArgumentException e) {        throw new FlumeException(String.format("Destination type '%s' is " + "invalid.", destinationTypeName), e);    }    if (createDurableSubscription) {        if (JMSDestinationType.TOPIC != destinationType) {            throw new FlumeException(String.format("Only Destination type '%s' supports durable subscriptions.", JMSDestinationType.TOPIC.toString()));        }        if (!clientId.isPresent()) {            throw new FlumeException(String.format("You have to specify '%s' when using durable subscriptions.", JMSSourceConfiguration.CLIENT_ID));        }        if (StringUtils.isEmpty(durableSubscriptionName)) {            throw new FlumeException(String.format("If '%s' is set to true, '%s' has to be specified.", JMSSourceConfiguration.CREATE_DURABLE_SUBSCRIPTION, JMSSourceConfiguration.DURABLE_SUBSCRIPTION_NAME));        }    } else if (!StringUtils.isEmpty(durableSubscriptionName)) {        logger.warn(String.format("'%s' is set, but '%s' is false." + "If you want to create a durable subscription, set %s to true.", JMSSourceConfiguration.DURABLE_SUBSCRIPTION_NAME, JMSSourceConfiguration.CREATE_DURABLE_SUBSCRIPTION, JMSSourceConfiguration.CREATE_DURABLE_SUBSCRIPTION));    }    try {        destinationLocator = JMSDestinationLocator.valueOf(destinationLocatorName);    } catch (IllegalArgumentException e) {        throw new FlumeException(String.format("Destination locator '%s' is " + "invalid.", destinationLocatorName), e);    }    Preconditions.checkArgument(batchSize > 0, "Batch size must be greater than 0");    try {        Properties contextProperties = new Properties();        contextProperties.setProperty(javax.naming.Context.INITIAL_CONTEXT_FACTORY, initialContextFactoryName);        contextProperties.setProperty(javax.naming.Context.PROVIDER_URL, providerUrl);                if (this.userName.isPresent()) {            contextProperties.setProperty(javax.naming.Context.SECURITY_PRINCIPAL, this.userName.get());        }        if (this.password.isPresent()) {            contextProperties.setProperty(javax.naming.Context.SECURITY_CREDENTIALS, this.password.get());        }        initialContext = initialContextFactory.create(contextProperties);    } catch (NamingException e) {        throw new FlumeException(String.format("Could not create initial context %s provider %s", initialContextFactoryName, providerUrl), e);    }    try {        connectionFactory = (ConnectionFactory) initialContext.lookup(connectionFactoryName);    } catch (NamingException e) {        throw new FlumeException("Could not lookup ConnectionFactory", e);    }}
84ae63578fc4ee42d9e31d9e431ac4bb95fb8a103f036c739960330486d1f8fc
assertNotEmpty
private void assertNotEmpty(String arg, String msg)
{    Preconditions.checkArgument(!arg.isEmpty(), msg);}
1086e0ff57f22cac738fb734741a27b2dbdc5e34c3bc92ebc9dbe96d61a0d6cf
doProcess
protected synchronized Status doProcess() throws EventDeliveryException
{    boolean error = true;    try {        if (consumer == null) {            consumer = createConsumer();        }        List<Event> events = consumer.take();        int size = events.size();        if (size == 0) {            error = false;            return Status.BACKOFF;        }        sourceCounter.incrementAppendBatchReceivedCount();        sourceCounter.addToEventReceivedCount(size);        getChannelProcessor().processEventBatch(events);        error = false;        sourceCounter.addToEventAcceptedCount(size);        sourceCounter.incrementAppendBatchAcceptedCount();        return Status.READY;    } catch (ChannelException channelException) {        logger.warn("Error appending event to channel. " + "Channel might be full. Consider increasing the channel " + "capacity or make sure the sinks perform faster.", channelException);        sourceCounter.incrementChannelWriteFail();    } catch (JMSException jmsException) {        logger.warn("JMSException consuming events", jmsException);        if (++jmsExceptionCounter > errorThreshold) {            if (consumer != null) {                logger.warn("Exceeded JMSException threshold, closing consumer");                sourceCounter.incrementEventReadFail();                consumer.rollback();                consumer.close();                consumer = null;            }        }    } catch (Throwable throwable) {        logger.error("Unexpected error processing events", throwable);        sourceCounter.incrementEventReadFail();        if (throwable instanceof Error) {            throw (Error) throwable;        }    } finally {        if (error) {            if (consumer != null) {                consumer.rollback();            }        } else {            if (consumer != null) {                consumer.commit();                jmsExceptionCounter = 0;            }        }    }    return Status.BACKOFF;}
9594f4936abfafc277e55c2838806b4427638be1f13bf4e76b337a9aeabd5848
doStart
protected synchronized void doStart()
{    try {        consumer = createConsumer();        jmsExceptionCounter = 0;        sourceCounter.start();    } catch (JMSException e) {        throw new FlumeException("Unable to create consumer", e);    }}
399c3f61916ffbc00d21a97769d2df76a5cc9f62430d76c9a406a8072d56cb0c
doStop
protected synchronized void doStop()
{    if (consumer != null) {        consumer.close();        consumer = null;    }    sourceCounter.stop();}
b927a106f5ea346da26155f1c16dc8756dea3717edbdaf4fc5c9c64a8d47aef6
createConsumer
 JMSMessageConsumer createConsumer() throws JMSException
{    logger.info("Creating new consumer for " + destinationName);    JMSMessageConsumer consumer = new JMSMessageConsumer(initialContext, connectionFactory, destinationName, destinationLocator, destinationType, messageSelector, batchSize, pollTimeout, converter, userName, password, clientId, createDurableSubscription, durableSubscriptionName);    jmsExceptionCounter = 0;    return consumer;}
dcc511f35190533c2d6fcc6073d66b12e111f5004c64ff08ccc3609a06ab844d
getBatchSize
public long getBatchSize()
{    return batchSize;}
27681e68ec2a1eb903f955680ebe003ceb3707295c8aad884b692d378c6e37cf
setup
public void setup() throws Exception
{    beforeSetup();    connectionFactory = mock(ConnectionFactory.class);    connection = mock(Connection.class);    session = mock(Session.class);    queue = mock(Queue.class);    topic = mock(Topic.class);    messageConsumer = mock(MessageConsumer.class);    message = mock(TextMessage.class);    when(message.getPropertyNames()).thenReturn(new Enumeration<Object>() {        @Override        public boolean hasMoreElements() {            return false;        }        @Override        public Object nextElement() {            throw new UnsupportedOperationException();        }    });    when(message.getText()).thenReturn(TEXT);    when(connectionFactory.createConnection(USERNAME, PASSWORD)).thenReturn(connection);    when(connection.createSession(true, Session.SESSION_TRANSACTED)).thenReturn(session);    when(session.createQueue(destinationName)).thenReturn(queue);    when(session.createConsumer(any(Destination.class), anyString())).thenReturn(messageConsumer);    when(messageConsumer.receiveNoWait()).thenReturn(message);    when(messageConsumer.receive(anyLong())).thenReturn(message);    destinationName = DESTINATION_NAME;    destinationType = JMSDestinationType.QUEUE;    destinationLocator = JMSDestinationLocator.CDI;    messageSelector = SELECTOR;    batchSize = 10;    pollTimeout = 500L;    context = new Context();    converter = new DefaultJMSMessageConverter.Builder().build(context);    event = converter.convert(message).iterator().next();    userName = Optional.of(USERNAME);    password = Optional.of(PASSWORD);    afterSetup();}
da08cdf75cc560a035cb95d54ab8d7f8ebf15cea6ebb6681d933f83f69d95057
hasMoreElements
public boolean hasMoreElements()
{    return false;}
ab967648282c1bb864bc31d2d8541e8e516e46281b5ebab3e9741a241bc4238d
nextElement
public Object nextElement()
{    throw new UnsupportedOperationException();}
f0b7eac63c52dc4f2c92702a1b10c1881414a565581ec1008316db47cccfca98
beforeSetup
 void beforeSetup() throws Exception
{}
917bd10e5f4f3ab1605b293ed0709693feeeca97ec913f44f7037d124847a317
afterSetup
 void afterSetup() throws Exception
{}
5b9be9d7ebb8dd725e02113254815ae92d555bb2075030b40a39b03d7840bb46
beforeTearDown
 void beforeTearDown() throws Exception
{}
9981c2431a53a3a0bd5e0a6f3ee35e1fd71cdadd9bfe8557607b55ee4285c215
afterTearDown
 void afterTearDown() throws Exception
{}
fbc414969543c05384864e2ec6c88057a061fda60ec58295989d9682388fe362
assertBodyIsExpected
 void assertBodyIsExpected(List<Event> events)
{    for (Event event : events) {        assertEquals(TEXT, new String(event.getBody(), Charsets.UTF_8));    }}
52cde602063caf2e376068f3bc5d2a33017a7b7e0dca55f8e8b30727f2f7e364
create
 JMSMessageConsumer create()
{    return new JMSMessageConsumer(WONT_USE, connectionFactory, destinationName, destinationLocator, destinationType, messageSelector, batchSize, pollTimeout, converter, userName, password, Optional.<String>absent(), false, "");}
c6aaebb5a52567751db8dc8e1cb9dd4a4e582ef964a374b376c6a04f741802dc
tearDown
public void tearDown() throws Exception
{    beforeTearDown();    if (consumer != null) {        consumer.close();    }    afterTearDown();}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    headers = Maps.newHashMap();    context = new Context();    converter = new DefaultJMSMessageConverter.Builder().build(context);}
6bca8e547d85f8cc1b5a461a6e43d11471612afa7703b785743f1ea5f610f1e4
createTextMessage
 void createTextMessage() throws Exception
{    TextMessage message = mock(TextMessage.class);    when(message.getText()).thenReturn(TEXT);    this.message = message;}
456db8d56de30f26f3dc629741612c8262d9e04bf4886226daf9e25589be9c73
createNullTextMessage
 void createNullTextMessage() throws Exception
{    TextMessage message = mock(TextMessage.class);    when(message.getText()).thenReturn(null);    this.message = message;}
28a442b892422253e4a9f8ae5e56cfe42d856ac0db5e77f27a026fc473f09c37
createBytesMessage
 void createBytesMessage() throws Exception
{    BytesMessage message = mock(BytesMessage.class);    when(message.getBodyLength()).thenReturn((long) BYTES.length);    when(message.readBytes(any(byte[].class))).then(new Answer<Integer>() {        @Override        public Integer answer(InvocationOnMock invocation) throws Throwable {            byte[] buffer = (byte[]) invocation.getArguments()[0];            if (buffer != null) {                assertEquals(buffer.length, BYTES.length);                System.arraycopy(BYTES, 0, buffer, 0, BYTES.length);            }            return BYTES.length;        }    });    this.message = message;}
085b33efd03f68ce42cbf20f76ea3958df86d9dcf37cfdfc086289ccf503efcb
answer
public Integer answer(InvocationOnMock invocation) throws Throwable
{    byte[] buffer = (byte[]) invocation.getArguments()[0];    if (buffer != null) {        assertEquals(buffer.length, BYTES.length);        System.arraycopy(BYTES, 0, buffer, 0, BYTES.length);    }    return BYTES.length;}
d493dbbb749f1495896a360729049cd9436beb4735dac1068e7a886cab545fa1
createObjectMessage
 void createObjectMessage() throws Exception
{    ObjectMessage message = mock(ObjectMessage.class);    when(message.getObject()).thenReturn(TEXT);    this.message = message;}
e639cd569e318134fe36198f529c047c634e0bfae5fdc2bcb88baea09fd390da
createHeaders
 void createHeaders() throws Exception
{    final Iterator<String> keys = headers.keySet().iterator();    when(message.getPropertyNames()).thenReturn(new Enumeration<Object>() {        @Override        public boolean hasMoreElements() {            return keys.hasNext();        }        @Override        public Object nextElement() {            return keys.next();        }    });    when(message.getStringProperty(anyString())).then(new Answer<String>() {        @Override        public String answer(InvocationOnMock invocation) throws Throwable {            return headers.get(invocation.getArguments()[0]);        }    });}
da08cdf75cc560a035cb95d54ab8d7f8ebf15cea6ebb6681d933f83f69d95057
hasMoreElements
public boolean hasMoreElements()
{    return keys.hasNext();}
ab967648282c1bb864bc31d2d8541e8e516e46281b5ebab3e9741a241bc4238d
nextElement
public Object nextElement()
{    return keys.next();}
6369d055b5afd07a36e3cae071c64d6109532718d4a87874fd94e2b586aed6be
answer
public String answer(InvocationOnMock invocation) throws Throwable
{    return headers.get(invocation.getArguments()[0]);}
3827c19b112cc0ddee5c9bbc79f63ba62d1029be115272e570e9f87ec7ec64f2
testTextMessage
public void testTextMessage() throws Exception
{    createTextMessage();    headers.put("key1", "value1");    headers.put("key2", "value2");    createHeaders();    Event event = converter.convert(message).iterator().next();    assertEquals(headers, event.getHeaders());    assertEquals(TEXT, new String(event.getBody(), Charsets.UTF_8));}
f6d354adaa4c6c715b0d30fb5c3c5bf8b46feafc706025414f73327406ee911b
testNullTextMessage
public void testNullTextMessage() throws Exception
{    createNullTextMessage();    headers.put("key1", "value1");    headers.put("key2", "value2");    createHeaders();    Event event = converter.convert(message).iterator().next();    assertEquals(headers, event.getHeaders());            assertEquals(event.getBody().length, 0);}
45d413369c057cfe4b9eed916d713f816f605978ebc30d43e3bfb8d3fa64f47c
testBytesMessage
public void testBytesMessage() throws Exception
{    createBytesMessage();    headers.put("key1", "value1");    headers.put("key2", "value2");    createHeaders();    Event event = converter.convert(message).iterator().next();    assertEquals(headers, event.getHeaders());    assertArrayEquals(BYTES, event.getBody());}
fbe429d79d653fe078b8e9e67eb3a0a593cde713aca041a87a491ea9877057c3
testBytesMessageTooLarge
public void testBytesMessageTooLarge() throws Exception
{    createBytesMessage();    when(((BytesMessage) message).getBodyLength()).thenReturn(Long.MAX_VALUE);    createHeaders();    converter.convert(message);}
35b7382cdd3e1d28910640fd18a82fe7d10f8a23e29baf0ac24c563e481f1404
testBytesMessagePartialReturn
public void testBytesMessagePartialReturn() throws Exception
{    createBytesMessage();    when(((BytesMessage) message).readBytes(any(byte[].class))).thenReturn(BYTES.length + 1);    createHeaders();    converter.convert(message);}
dc861f238561bfd6908de688df001769c6472065f33c43537fd08af2a9726e98
testObjectMessage
public void testObjectMessage() throws Exception
{    createObjectMessage();    headers.put("key1", "value1");    headers.put("key2", "value2");    createHeaders();    Event event = converter.convert(message).iterator().next();    assertEquals(headers, event.getHeaders());    ByteArrayOutputStream bos = new ByteArrayOutputStream();    ObjectOutput out = new ObjectOutputStream(bos);    out.writeObject(TEXT);    assertArrayEquals(bos.toByteArray(), event.getBody());}
9a72bcff5b864bf7d63572af9e93d3a98033039237f49d7b62fed7aa4f5daa22
testNoHeaders
public void testNoHeaders() throws Exception
{    createTextMessage();    createHeaders();    Event event = converter.convert(message).iterator().next();    assertEquals(Collections.EMPTY_MAP, event.getHeaders());    assertEquals(TEXT, new String(event.getBody(), Charsets.UTF_8));}
0b1c973ae8f2e6d02578f2c851596e5d27eaa670a7d108812f6d2d3eb9ea270e
parameters
public static Collection<Object[]> parameters()
{    return Arrays.asList(new Object[][] { { TestMode.WITH_AUTHENTICATION }, { TestMode.WITHOUT_AUTHENTICATION } });}
27681e68ec2a1eb903f955680ebe003ceb3707295c8aad884b692d378c6e37cf
setup
public void setup() throws Exception
{    baseDir = Files.createTempDir();    tmpDir = new File(baseDir, "tmp");    dataDir = new File(baseDir, "data");    Assert.assertTrue(tmpDir.mkdir());    broker = new BrokerService();    broker.addConnector(BROKER_BIND_URL);    broker.setTmpDataDirectory(tmpDir);    broker.setDataDirectoryFile(dataDir);    context = new Context();    context.put(JMSSourceConfiguration.INITIAL_CONTEXT_FACTORY, INITIAL_CONTEXT_FACTORY);    context.put(JMSSourceConfiguration.PROVIDER_URL, BROKER_BIND_URL);    context.put(JMSSourceConfiguration.DESTINATION_NAME, DESTINATION_NAME);    if (jmsUserName != null) {        File passwordFile = new File(baseDir, "password");        Files.write(jmsPassword.getBytes(Charsets.UTF_8), passwordFile);        AuthenticationUser jmsUser = new AuthenticationUser(jmsUserName, jmsPassword, "");        List<AuthenticationUser> users = Collections.singletonList(jmsUser);        SimpleAuthenticationPlugin authentication = new SimpleAuthenticationPlugin(users);        broker.setPlugins(new BrokerPlugin[] { authentication });        context.put(JMSSourceConfiguration.USERNAME, jmsUserName);        context.put(JMSSourceConfiguration.PASSWORD_FILE, passwordFile.getAbsolutePath());    }    broker.start();    events = Lists.newArrayList();    source = new JMSSource();    source.setName("JMSSource-" + UUID.randomUUID());    ChannelProcessor channelProcessor = mock(ChannelProcessor.class);    doAnswer(new Answer<Void>() {        @Override        public Void answer(InvocationOnMock invocation) throws Throwable {            events.addAll((List<Event>) invocation.getArguments()[0]);            return null;        }    }).when(channelProcessor).processEventBatch(any(List.class));    source.setChannelProcessor(channelProcessor);}
95bf71523ce2b266f318cc556abf31d0edd833353a1498e854e22b8b3a97d573
answer
public Void answer(InvocationOnMock invocation) throws Throwable
{    events.addAll((List<Event>) invocation.getArguments()[0]);    return null;}
c6aaebb5a52567751db8dc8e1cb9dd4a4e582ef964a374b376c6a04f741802dc
tearDown
public void tearDown() throws Exception
{    if (source != null) {        source.stop();    }    if (broker != null) {        broker.stop();    }    FileUtils.deleteDirectory(baseDir);}
b8b1198ca8ceb708671b6d7d1105f76fed18f4f04d35df622fb71fad72a148ea
putQueue
private void putQueue(List<String> events) throws Exception
{    ConnectionFactory factory = new ActiveMQConnectionFactory(jmsUserName, jmsPassword, BROKER_BIND_URL);    Connection connection = factory.createConnection();    connection.start();    Session session = connection.createSession(true, Session.AUTO_ACKNOWLEDGE);    Destination destination = session.createQueue(DESTINATION_NAME);    MessageProducer producer = session.createProducer(destination);    for (String event : events) {        TextMessage message = session.createTextMessage();        message.setText(event);        producer.send(message);    }    session.commit();    session.close();    connection.close();}
eaf89e80ca2ae52ecbb42a97e2d27d0e0ab952b0037c7914c546f733f88a2b8d
putTopic
private void putTopic(List<String> events) throws Exception
{    ConnectionFactory factory = new ActiveMQConnectionFactory(jmsUserName, jmsPassword, BROKER_BIND_URL);    Connection connection = factory.createConnection();    connection.start();    Session session = connection.createSession(true, Session.AUTO_ACKNOWLEDGE);    Destination destination = session.createTopic(DESTINATION_NAME);    MessageProducer producer = session.createProducer(destination);    for (String event : events) {        TextMessage message = session.createTextMessage();        message.setText(event);        producer.send(message);    }    session.commit();    session.close();    connection.close();}
0731a8d8b914c72a2c09e0d268624eaad5ce3bcaf5e86769c703fdc621cee4ee
testQueueLocatedWithJndi
public void testQueueLocatedWithJndi() throws Exception
{    context.put(JMSSourceConfiguration.DESTINATION_NAME, JNDI_PREFIX + DESTINATION_NAME);    context.put(JMSSourceConfiguration.DESTINATION_LOCATOR, JMSDestinationLocator.JNDI.name());    testQueue();}
6c75aec4e2f4168286807cf62a185f2d3f0bdde1c6b07a68f8f0aee67aeed02a
testQueue
public void testQueue() throws Exception
{    context.put(JMSSourceConfiguration.DESTINATION_TYPE, JMSSourceConfiguration.DESTINATION_TYPE_QUEUE);    source.configure(context);    source.start();    Thread.sleep(500L);    List<String> expected = Lists.newArrayList();    for (int i = 0; i < 10; i++) {        expected.add(String.valueOf(i));    }    putQueue(expected);    Thread.sleep(500L);    Assert.assertEquals(Status.READY, source.process());    Assert.assertEquals(Status.BACKOFF, source.process());    Assert.assertEquals(expected.size(), events.size());    List<String> actual = Lists.newArrayList();    for (Event event : events) {        actual.add(new String(event.getBody(), Charsets.UTF_8));    }    Collections.sort(expected);    Collections.sort(actual);    Assert.assertEquals(expected, actual);}
f3f7588eb38d647ec841d18eb800746277efd0f123eca12c7778e0d8ed0b6e60
testTopic
public void testTopic() throws Exception
{    context.put(JMSSourceConfiguration.DESTINATION_TYPE, JMSSourceConfiguration.DESTINATION_TYPE_TOPIC);    source.configure(context);    source.start();    Thread.sleep(500L);    List<String> expected = Lists.newArrayList();    for (int i = 0; i < 10; i++) {        expected.add(String.valueOf(i));    }    putTopic(expected);    Thread.sleep(500L);    Assert.assertEquals(Status.READY, source.process());    Assert.assertEquals(Status.BACKOFF, source.process());    Assert.assertEquals(expected.size(), events.size());    List<String> actual = Lists.newArrayList();    for (Event event : events) {        actual.add(new String(event.getBody(), Charsets.UTF_8));    }    Collections.sort(expected);    Collections.sort(actual);    Assert.assertEquals(expected, actual);}
ac495116afd424e95023964c635e930f07402bfca5cfedbb944bcbe2123fc020
testDurableSubscription
public void testDurableSubscription() throws Exception
{    context.put(JMSSourceConfiguration.DESTINATION_TYPE, JMSSourceConfiguration.DESTINATION_TYPE_TOPIC);    context.put(JMSSourceConfiguration.CLIENT_ID, "FLUME");    context.put(JMSSourceConfiguration.DURABLE_SUBSCRIPTION_NAME, "SOURCE1");    context.put(JMSSourceConfiguration.CREATE_DURABLE_SUBSCRIPTION, "true");    context.put(JMSSourceConfiguration.BATCH_SIZE, "10");    source.configure(context);    source.start();    Thread.sleep(5000L);    List<String> expected = Lists.newArrayList();    List<String> input = Lists.newArrayList();    for (int i = 0; i < 10; i++) {        input.add("before " + String.valueOf(i));    }    expected.addAll(input);    putTopic(input);    Thread.sleep(500L);    Assert.assertEquals(Status.READY, source.process());    Assert.assertEquals(Status.BACKOFF, source.process());    source.stop();    Thread.sleep(500L);    input = Lists.newArrayList();    for (int i = 0; i < 10; i++) {        input.add("during " + String.valueOf(i));    }    expected.addAll(input);    putTopic(input);    source.start();    Thread.sleep(500L);    input = Lists.newArrayList();    for (int i = 0; i < 10; i++) {        input.add("after " + String.valueOf(i));    }    expected.addAll(input);    putTopic(input);    Assert.assertEquals(Status.READY, source.process());    Assert.assertEquals(Status.READY, source.process());    Assert.assertEquals(Status.BACKOFF, source.process());    Assert.assertEquals(expected.size(), events.size());    List<String> actual = Lists.newArrayList();    for (Event event : events) {        actual.add(new String(event.getBody(), Charsets.UTF_8));    }    Collections.sort(expected);    Collections.sort(actual);    Assert.assertEquals(expected, actual);}
cf545cc7439d98a63d5bf7fe5e0a4434aeb3d3636f4a53f2e74baf83508f79bb
testCreateConnectionFails
public void testCreateConnectionFails() throws Exception
{    when(connectionFactory.createConnection(USERNAME, PASSWORD)).thenThrow(new JMSException(""));    create();}
d1887ef4e0d81e63bd6f1e0d021dd7850eb6e8f07bea6f16e372cc9c908f11d4
testCreateSessionFails
public void testCreateSessionFails() throws Exception
{    when(connection.createSession(true, Session.SESSION_TRANSACTED)).thenThrow(new JMSException(""));    try {        create();        fail("Expected exception: org.apache.flume.FlumeException");    } catch (FlumeException e) {        verify(connection).close();    }}
c74acdc94506a0b120506b41adcbab12a2cea344775ed1f3dfc2cdc21bf56538
testCreateQueueFails
public void testCreateQueueFails() throws Exception
{    when(session.createQueue(destinationName)).thenThrow(new JMSException(""));    try {        create();        fail("Expected exception: org.apache.flume.FlumeException");    } catch (FlumeException e) {        verify(session).close();        verify(connection).close();    }}
bb8e8bc18ded64084a34c41c31fe706852126bf02ef0a8693aee34ea48963bca
testCreateTopicFails
public void testCreateTopicFails() throws Exception
{    destinationType = JMSDestinationType.TOPIC;    when(session.createTopic(destinationName)).thenThrow(new JMSException(""));    try {        create();        fail("Expected exception: org.apache.flume.FlumeException");    } catch (FlumeException e) {        verify(session).close();        verify(connection).close();    }}
da555a8315698ef54852483f673cee78a4493c053403a0e3a7c67b1aa90a40e3
testCreateConsumerFails
public void testCreateConsumerFails() throws Exception
{    when(session.createConsumer(any(Destination.class), anyString())).thenThrow(new JMSException(""));    try {        create();        fail("Expected exception: org.apache.flume.FlumeException");    } catch (FlumeException e) {        verify(session).close();        verify(connection).close();    }}
751cb036b1b5397e5431af99ec39723a69f63e874ca69996ee3608bbba87f294
testInvalidBatchSizeZero
public void testInvalidBatchSizeZero() throws Exception
{    batchSize = 0;    create();}
e166f0d6f49f5e8387eae6be74fe1abce702ca39acceae12c987fdea68c41ef3
testInvalidPollTime
public void testInvalidPollTime() throws Exception
{    pollTimeout = -1L;    create();}
0286970ff304ca3e5e91d98a638b2cc275798423cb0f21246c957f710ca80cfa
testInvalidBatchSizeNegative
public void testInvalidBatchSizeNegative() throws Exception
{    batchSize = -1;    create();}
6c75aec4e2f4168286807cf62a185f2d3f0bdde1c6b07a68f8f0aee67aeed02a
testQueue
public void testQueue() throws Exception
{    destinationType = JMSDestinationType.QUEUE;    when(session.createQueue(destinationName)).thenReturn(queue);    consumer = create();    List<Event> events = consumer.take();    assertEquals(batchSize, events.size());    assertBodyIsExpected(events);    verify(session, never()).createTopic(anyString());}
f3f7588eb38d647ec841d18eb800746277efd0f123eca12c7778e0d8ed0b6e60
testTopic
public void testTopic() throws Exception
{    destinationType = JMSDestinationType.TOPIC;    when(session.createTopic(destinationName)).thenReturn(topic);    consumer = create();    List<Event> events = consumer.take();    assertEquals(batchSize, events.size());    assertBodyIsExpected(events);    verify(session, never()).createQueue(anyString());}
48d882b91a2fba8558d556338ac0322c8f62b87065ac044cf72f2542e8f0468b
testUserPass
public void testUserPass() throws Exception
{    consumer = create();    List<Event> events = consumer.take();    assertEquals(batchSize, events.size());    assertBodyIsExpected(events);}
45c4ce5db2f4d7cea6371c26fb3306a706b9d6d9b5260af08f90c576e9aa217b
testNoUserPass
public void testNoUserPass() throws Exception
{    userName = Optional.absent();    when(connectionFactory.createConnection(USERNAME, PASSWORD)).thenThrow(new AssertionError());    when(connectionFactory.createConnection()).thenReturn(connection);    consumer = create();    List<Event> events = consumer.take();    assertEquals(batchSize, events.size());    assertBodyIsExpected(events);}
c9849d46073cffa30c7ed3c1f7e677c880abe932f4676a4a9c8e276ca949f56d
testNoEvents
public void testNoEvents() throws Exception
{    when(messageConsumer.receive(anyLong())).thenReturn(null);    consumer = create();    List<Event> events = consumer.take();    assertEquals(0, events.size());    verify(messageConsumer, times(1)).receive(anyLong());    verifyNoMoreInteractions(messageConsumer);}
cff45a0d39426061b080e44b420ee4494425129e7aeafde8ca1a634bec77f50a
testSingleEvent
public void testSingleEvent() throws Exception
{    when(messageConsumer.receiveNoWait()).thenReturn(null);    consumer = create();    List<Event> events = consumer.take();    assertEquals(1, events.size());    assertBodyIsExpected(events);}
962057c1b04a6f849ec21af6253d32ac2df4d781080859f875f4f4afc7ea9852
testPartialBatch
public void testPartialBatch() throws Exception
{    when(messageConsumer.receiveNoWait()).thenReturn(message, (Message) null);    consumer = create();    List<Event> events = consumer.take();    assertEquals(2, events.size());    assertBodyIsExpected(events);}
ba537a4033bcce6a4e22a4e0615f2c5ff7f0efe39f89fcecc86b329abcb2d0ab
testCommit
public void testCommit() throws Exception
{    consumer = create();    consumer.commit();    verify(session, times(1)).commit();}
1a470055af66eed510e4b5167bd848fa8f486da38b8381d9513321b76947b118
testRollback
public void testRollback() throws Exception
{    consumer = create();    consumer.rollback();    verify(session, times(1)).rollback();}
f501440ec66029ff9305f7fcfbfd80ab4f1b38f77acbc6e96d4a6012978b32fc
testClose
public void testClose() throws Exception
{    doThrow(new JMSException("")).when(session).close();    consumer = create();    consumer.close();    verify(session, times(1)).close();    verify(connection, times(1)).close();}
1555d57e338eb4f10c4f849e846e37eb1ac22dd89b4afb973d4692af9957b242
testCreateDurableSubscription
public void testCreateDurableSubscription() throws Exception
{    String name = "SUBSCRIPTION_NAME";    String clientID = "CLIENT_ID";    TopicSubscriber mockTopicSubscriber = mock(TopicSubscriber.class);    when(session.createDurableSubscriber(any(Topic.class), anyString(), anyString(), anyBoolean())).thenReturn(mockTopicSubscriber);    when(session.createTopic(destinationName)).thenReturn(topic);    new JMSMessageConsumer(WONT_USE, connectionFactory, destinationName, destinationLocator, JMSDestinationType.TOPIC, messageSelector, batchSize, pollTimeout, converter, userName, password, Optional.of(clientID), true, name);    verify(connection, times(1)).setClientID(clientID);    verify(session, times(1)).createDurableSubscriber(topic, name, messageSelector, true);}
438d2106dddfc505981ac1597f5e9f462de24647bfca3ff6b70b6d042bbbde0f
testTakeFailsDueToJMSExceptionFromReceive
public void testTakeFailsDueToJMSExceptionFromReceive() throws JMSException
{    when(messageConsumer.receive(anyLong())).thenThrow(new JMSException(""));    consumer = create();    consumer.take();}
9bf43148ce0f1d71cd44765b6a2e81a4242d2ab6dae11503a42a2cb854f66fc3
testTakeFailsDueToRuntimeExceptionFromReceive
public void testTakeFailsDueToRuntimeExceptionFromReceive() throws JMSException
{    when(messageConsumer.receive(anyLong())).thenThrow(new RuntimeException());    consumer = create();    consumer.take();}
1fb7211f5ec3e9cb230e317aa25c1ecd2576ba84a64181b80486fa4cf0e4eb51
testTakeFailsDueToJMSExceptionFromReceiveNoWait
public void testTakeFailsDueToJMSExceptionFromReceiveNoWait() throws JMSException
{    when(messageConsumer.receiveNoWait()).thenThrow(new JMSException(""));    consumer = create();    consumer.take();}
236af639725e8c267b094370f61bd39e74dcea3001f48bbd2047da24f8618fa1
testTakeFailsDueToRuntimeExceptionFromReceiveNoWait
public void testTakeFailsDueToRuntimeExceptionFromReceiveNoWait() throws JMSException
{    when(messageConsumer.receiveNoWait()).thenThrow(new RuntimeException());    consumer = create();    consumer.take();}
ed998d44ce08977f8fadf6e5aaee50e78e51c5de0f67ab1c24568ce08e7e1995
testCommitFailsDueToJMSException
public void testCommitFailsDueToJMSException() throws JMSException
{    doThrow(new JMSException("")).when(session).commit();    consumer = create();    consumer.commit();}
d2960d1e0760486084adaf51b67bd4b9bdff9debeaa9e976f01ea45ff3acae6b
testCommitFailsDueToRuntimeException
public void testCommitFailsDueToRuntimeException() throws JMSException
{    doThrow(new RuntimeException()).when(session).commit();    consumer = create();    consumer.commit();}
0a0deb6f7ee09510aab7466a0756ce1c18dbdfab690bea5d79e087bc38797d49
testRollbackFailsDueToJMSException
public void testRollbackFailsDueToJMSException() throws JMSException
{    doThrow(new JMSException("")).when(session).rollback();    consumer = create();    consumer.rollback();}
b36cc645fc36de9756df9ae829ff924025481d5e1e9599b260c4d1826fd4306a
testRollbackFailsDueToRuntimeException
public void testRollbackFailsDueToRuntimeException() throws JMSException
{    doThrow(new RuntimeException()).when(session).rollback();    consumer = create();    consumer.rollback();}
917bd10e5f4f3ab1605b293ed0709693feeeca97ec913f44f7037d124847a317
afterSetup
 void afterSetup() throws Exception
{    baseDir = Files.createTempDir();    passwordFile = new File(baseDir, "password");    Assert.assertTrue(passwordFile.createNewFile());    initialContext = mock(InitialContext.class);    channelProcessor = mock(ChannelProcessor.class);    events = Lists.newArrayList();    doAnswer(new Answer<Void>() {        @Override        public Void answer(InvocationOnMock invocation) throws Throwable {            events.addAll((List<Event>) invocation.getArguments()[0]);            return null;        }    }).when(channelProcessor).processEventBatch(any(List.class));    consumer = spy(create());    when(initialContext.lookup(anyString())).thenReturn(connectionFactory);    contextFactory = mock(InitialContextFactory.class);    when(contextFactory.create(any(Properties.class))).thenReturn(initialContext);    source = spy(new JMSSource(contextFactory));    doReturn(consumer).when(source).createConsumer();    source.setName("JMSSource-" + UUID.randomUUID());    source.setChannelProcessor(channelProcessor);    context = new Context();    context.put(JMSSourceConfiguration.BATCH_SIZE, String.valueOf(batchSize));    context.put(JMSSourceConfiguration.DESTINATION_NAME, "INBOUND");    context.put(JMSSourceConfiguration.DESTINATION_TYPE, JMSSourceConfiguration.DESTINATION_TYPE_QUEUE);    context.put(JMSSourceConfiguration.PROVIDER_URL, "dummy:1414");    context.put(JMSSourceConfiguration.INITIAL_CONTEXT_FACTORY, "ldap://dummy:389");}
95bf71523ce2b266f318cc556abf31d0edd833353a1498e854e22b8b3a97d573
answer
public Void answer(InvocationOnMock invocation) throws Throwable
{    events.addAll((List<Event>) invocation.getArguments()[0]);    return null;}
9981c2431a53a3a0bd5e0a6f3ee35e1fd71cdadd9bfe8557607b55ee4285c215
afterTearDown
 void afterTearDown() throws Exception
{    FileUtils.deleteDirectory(baseDir);}
707da24348264b464707f355d5e271dbe11f743743ae99c554cdc746ed4ff3ea
testStop
public void testStop() throws Exception
{    source.configure(context);    source.start();    source.stop();    verify(consumer).close();}
1827fd39a20d7c15a2399f209a7ccd5be073b4aea59f507181523db259bd657e
testConfigureWithoutInitialContextFactory
public void testConfigureWithoutInitialContextFactory() throws Exception
{    context.put(JMSSourceConfiguration.INITIAL_CONTEXT_FACTORY, "");    source.configure(context);}
0eff67f9ff63db252429face0f316e08c74fa981882ae70f0860d7ac3d56fc9c
testConfigureWithoutProviderURL
public void testConfigureWithoutProviderURL() throws Exception
{    context.put(JMSSourceConfiguration.PROVIDER_URL, "");    source.configure(context);}
eb4765046ebe97cc4d7dad1dd6e1ba7aa1a7cc9dd13f09dd662aedbbb65834d9
testConfigureWithoutDestinationName
public void testConfigureWithoutDestinationName() throws Exception
{    context.put(JMSSourceConfiguration.DESTINATION_NAME, "");    source.configure(context);}
47de140f05562adb2dbb3f7837d1ee622caef1dc15ee2eadf312e37b8d95a102
testConfigureWithBadDestinationType
public void testConfigureWithBadDestinationType() throws Exception
{    context.put(JMSSourceConfiguration.DESTINATION_TYPE, "DUMMY");    source.configure(context);}
76e0fa8ab32c5f9c847b42ccd9ed99902f26271b6b0a1696e30191015f83c59f
testConfigureWithEmptyDestinationType
public void testConfigureWithEmptyDestinationType() throws Exception
{    context.put(JMSSourceConfiguration.DESTINATION_TYPE, "");    source.configure(context);}
ce97f82fa12f45aef2fdd99d6a6c7b2b7a3dfef717771125d8cb4925353f9aaf
testStartConsumerCreateThrowsException
public void testStartConsumerCreateThrowsException() throws Exception
{    doThrow(new RuntimeException("Expected")).when(source).createConsumer();    source.configure(context);    source.start();    try {        source.process();        Assert.fail();    } catch (FlumeException expected) {    }}
11c5e84f8e2d152a48a5cf3754c56f10df2120d8a3347cf7141c6b495d719e36
testConfigureWithContextLookupThrowsException
public void testConfigureWithContextLookupThrowsException() throws Exception
{    when(initialContext.lookup(anyString())).thenThrow(new NamingException());    source.configure(context);}
4602051b700ff7325854d719962ef531841fa54bf0ca97dc0ea4743357bfa4c1
testConfigureWithContextCreateThrowsException
public void testConfigureWithContextCreateThrowsException() throws Exception
{    when(contextFactory.create(any(Properties.class))).thenThrow(new NamingException());    source.configure(context);}
5c99447abf9a478ddbdd3cbf71b20eabd89205ea6f92c8060f437c3ce866b84f
testConfigureWithInvalidBatchSize
public void testConfigureWithInvalidBatchSize() throws Exception
{    context.put(JMSSourceConfiguration.BATCH_SIZE, "0");    source.configure(context);}
67a54bf1d35374ef19aeab2a3816e493bcda7021828fb21dc7087d19da2c2043
testConfigureWithInvalidPasswordFile
public void testConfigureWithInvalidPasswordFile() throws Exception
{    context.put(JMSSourceConfiguration.PASSWORD_FILE, "/dev/does/not/exist/nor/will/ever/exist");    source.configure(context);}
f9930f85b677eb82a8c8b857843b4e7f1c8942dd06d829e7a0e70ba1faa83a4a
testConfigureWithUserNameButNoPasswordFile
public void testConfigureWithUserNameButNoPasswordFile() throws Exception
{    context.put(JMSSourceConfiguration.USERNAME, "dummy");    source.configure(context);    source.start();    Assert.assertEquals(Status.READY, source.process());    Assert.assertEquals(batchSize, events.size());    assertBodyIsExpected(events);}
e0113fda0754d099de59c6aaf926fbc4e55ec90826ab37f21ad4979386d67a06
testConfigureWithUserNameAndPasswordFile
public void testConfigureWithUserNameAndPasswordFile() throws Exception
{    context.put(JMSSourceConfiguration.USERNAME, "dummy");    context.put(JMSSourceConfiguration.PASSWORD_FILE, passwordFile.getAbsolutePath());    source.configure(context);    source.start();    Assert.assertEquals(Status.READY, source.process());    Assert.assertEquals(batchSize, events.size());    assertBodyIsExpected(events);}
68f1991b32c84a59a49bfcb14772294c94069a448a0503135b0b4a572edeeb7d
testConfigureWithInvalidConverterClass
public void testConfigureWithInvalidConverterClass() throws Exception
{    context.put(JMSSourceConfiguration.CONVERTER_TYPE, "not a valid classname");    source.configure(context);}
d86f388e5af9c2ecba24a547957e332d053579497415a81d6cc767572e4534f0
testProcessNoStart
public void testProcessNoStart() throws Exception
{    try {        source.process();        Assert.fail();    } catch (EventDeliveryException expected) {    }}
3de687282a3f504806bcad77aaced4c7320cd47f13fecc35608391fbacdb142e
testNonDefaultConverter
public void testNonDefaultConverter() throws Exception
{        context.put(JMSSourceConfiguration.CONVERTER_TYPE, DefaultJMSMessageConverter.Builder.class.getName());    source.configure(context);    source.start();    Assert.assertEquals(Status.READY, source.process());    Assert.assertEquals(batchSize, events.size());    assertBodyIsExpected(events);    verify(consumer).commit();}
27bda62e0f43687123a1918f1f7dfa8ae41b6c947693dad532b5807d20da03ef
convert
public List<Event> convert(Message message) throws JMSException
{    throw new UnsupportedOperationException();}
27bda62e0f43687123a1918f1f7dfa8ae41b6c947693dad532b5807d20da03ef
convert
public List<Event> convert(Message message) throws JMSException
{    throw new UnsupportedOperationException();}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{}
77138a2103d77e83e2be7ba5b7eb845837a70fa377216fb32a82f0381c8183d2
testNonBuilderConfigurableConverter
public void testNonBuilderConfigurableConverter() throws Exception
{        context.put(JMSSourceConfiguration.CONVERTER_TYPE, NonBuilderConfigurableConverter.class.getName());    source.configure(context);    source.start();    Assert.assertEquals(Status.READY, source.process());    Assert.assertEquals(batchSize, events.size());    assertBodyIsExpected(events);    verify(consumer).commit();}
e4119dc874abe5740f825d675433c2abc8f4b38134618d53b5ad5f7ebadd669f
testNonBuilderNonConfigurableConverter
public void testNonBuilderNonConfigurableConverter() throws Exception
{        context.put(JMSSourceConfiguration.CONVERTER_TYPE, NonBuilderNonConfigurableConverter.class.getName());    source.configure(context);    source.start();    Assert.assertEquals(Status.READY, source.process());    Assert.assertEquals(batchSize, events.size());    assertBodyIsExpected(events);    verify(consumer).commit();}
ca419278e19ba30217e6bcf953a2bb332149a23fb9a968ebcb1075d291eb0e0a
testProcessFullBatch
public void testProcessFullBatch() throws Exception
{    source.configure(context);    source.start();    Assert.assertEquals(Status.READY, source.process());    Assert.assertEquals(batchSize, events.size());    assertBodyIsExpected(events);    verify(consumer).commit();}
6343f19a96a59a7089b72d962e6083ac7288d6c4b7ef17c5641d315b1800d898
testProcessNoEvents
public void testProcessNoEvents() throws Exception
{    when(messageConsumer.receive(anyLong())).thenReturn(null);    source.configure(context);    source.start();    Assert.assertEquals(Status.BACKOFF, source.process());    Assert.assertEquals(0, events.size());    verify(consumer).commit();}
27dd2d4c9be3fb6bbc936a30fa7377edd6e975d49c1c6fb32c103706390dcf79
testProcessPartialBatch
public void testProcessPartialBatch() throws Exception
{    when(messageConsumer.receiveNoWait()).thenReturn(message, (Message) null);    source.configure(context);    source.start();    Assert.assertEquals(Status.READY, source.process());    Assert.assertEquals(2, events.size());    assertBodyIsExpected(events);    verify(consumer).commit();}
381ca70322e59c8d5599a460cb08955bcf9072d1c2878410372488b9d38d70c7
testProcessChannelProcessorThrowsChannelException
public void testProcessChannelProcessorThrowsChannelException() throws Exception
{    doThrow(new ChannelException("dummy")).when(channelProcessor).processEventBatch(any(List.class));    source.configure(context);    source.start();    Assert.assertEquals(Status.BACKOFF, source.process());    verify(consumer).rollback();}
14d1d2b543ec2bb51129fcd55f090abb01126ec4fd7e9791077af1b53909c52c
testProcessChannelProcessorThrowsError
public void testProcessChannelProcessorThrowsError() throws Exception
{    doThrow(new Error()).when(channelProcessor).processEventBatch(any(List.class));    source.configure(context);    source.start();    try {        source.process();        Assert.fail();    } catch (Error ignores) {    }    verify(consumer).rollback();}
1e670fcf0b89cb337b9f1f7366793c467e49351ba85fba511c6ea4baf45b2db2
testProcessReconnect
public void testProcessReconnect() throws Exception
{    source.configure(context);    source.start();    when(consumer.take()).thenThrow(new JMSException("dummy"));    int attempts = JMSSourceConfiguration.ERROR_THRESHOLD_DEFAULT;    for (int i = 0; i < attempts; i++) {        Assert.assertEquals(Status.BACKOFF, source.process());    }    Assert.assertEquals(Status.BACKOFF, source.process());    SourceCounter sc = (SourceCounter) Whitebox.getInternalState(source, "sourceCounter");    Assert.assertEquals(1, sc.getEventReadFail());    verify(consumer, times(attempts + 1)).rollback();    verify(consumer, times(1)).close();}
fadbbf1e2a2f05fb22a914b78a0f9a0c8d7951630987c1cecefddbf7a5ee31a8
testErrorCounterEventReadFail
public void testErrorCounterEventReadFail() throws Exception
{    source.configure(context);    source.start();    when(consumer.take()).thenThrow(new RuntimeException("dummy"));    source.process();    SourceCounter sc = (SourceCounter) Whitebox.getInternalState(source, "sourceCounter");    Assert.assertEquals(1, sc.getEventReadFail());}
842ce523cd5b575230a4e53c3d57d7b83c10bc784cdf87d5c299626f97ef80e0
testErrorCounterChannelWriteFail
public void testErrorCounterChannelWriteFail() throws Exception
{    source.configure(context);    source.start();    when(source.getChannelProcessor()).thenThrow(new ChannelException("dummy"));    source.process();    SourceCounter sc = (SourceCounter) Whitebox.getInternalState(source, "sourceCounter");    Assert.assertEquals(1, sc.getChannelWriteFail());}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    sourceFactory = new DefaultSourceFactory();}
1433bdf58cd83adfebfdd4d701bb6ffb3e820874d870f37db8effd8b6da28669
verifySourceCreation
private void verifySourceCreation(String name, String type, Class<?> typeClass) throws FlumeException
{    Source src = sourceFactory.create(name, type);    Assert.assertNotNull(src);    Assert.assertTrue(typeClass.isInstance(src));}
6252273eec0e60e03a9a676ac0d56a9f913cf374f1421391fdf370e8fd7c5b3a
testJMSSourceCreation
public void testJMSSourceCreation()
{    verifySourceCreation("jms-src", "jms", JMSSource.class);}
dcc511f35190533c2d6fcc6073d66b12e111f5004c64ff08ccc3609a06ab844d
getBatchSize
public long getBatchSize()
{    return batchUpperLimit;}
f92b71e18fa63d96cf2b628ad8520702b897423512edea5de9dd0e96f471f5ff
get
public T get()
{    return null;}
fef2bfa516c0fd67c44b4999a4cf9265fc33c4656141dba30acf18373b1db960
subscribe
public void subscribe(KafkaConsumer<?, ?> consumer, SourceRebalanceListener listener)
{    consumer.subscribe(topicList, listener);}
1ecd0406e9c4a083da6ce9e47021d4c10eb12e4df4e16151c091fc9658574209
get
public List<String> get()
{    return topicList;}
fef2bfa516c0fd67c44b4999a4cf9265fc33c4656141dba30acf18373b1db960
subscribe
public void subscribe(KafkaConsumer<?, ?> consumer, SourceRebalanceListener listener)
{    consumer.subscribe(pattern, listener);}
0f7ebbcef71f1646b1e09340437260c8ed15e014878bbc7510f6cf681b5d430f
get
public Pattern get()
{    return pattern;}
a30bb502129b437d7473071d9300950cf74e2295abc5081e9e1dca626bc22835
doProcess
protected Status doProcess() throws EventDeliveryException
{    final String batchUUID = UUID.randomUUID().toString();    String kafkaKey;    Event event;    byte[] eventBody;    try {                final long nanoBatchStartTime = System.nanoTime();        final long batchStartTime = System.currentTimeMillis();        final long maxBatchEndTime = System.currentTimeMillis() + maxBatchDurationMillis;        while (eventList.size() < batchUpperLimit && System.currentTimeMillis() < maxBatchEndTime) {            if (it == null || !it.hasNext()) {                                                long durMs = Math.max(0L, maxBatchEndTime - System.currentTimeMillis());                Duration duration = Duration.ofMillis(durMs);                ConsumerRecords<String, byte[]> records = consumer.poll(duration);                it = records.iterator();                                if (rebalanceFlag.compareAndSet(true, false)) {                    break;                }                                if (!it.hasNext()) {                    counter.incrementKafkaEmptyCount();                    log.debug("Returning with backoff. No more data to read");                                        break;                }            }                        ConsumerRecord<String, byte[]> message = it.next();            kafkaKey = message.key();            if (useAvroEventFormat) {                                                ByteArrayInputStream in = new ByteArrayInputStream(message.value());                decoder = DecoderFactory.get().directBinaryDecoder(in, decoder);                if (!reader.isPresent()) {                    reader = Optional.of(new SpecificDatumReader<AvroFlumeEvent>(AvroFlumeEvent.class));                }                                                AvroFlumeEvent avroevent = reader.get().read(null, decoder);                eventBody = avroevent.getBody().array();                headers = toStringMap(avroevent.getHeaders());            } else {                eventBody = message.value();                headers.clear();                headers = new HashMap<String, String>(4);            }                        if (!headers.containsKey(KafkaSourceConstants.TIMESTAMP_HEADER)) {                headers.put(KafkaSourceConstants.TIMESTAMP_HEADER, String.valueOf(System.currentTimeMillis()));            }                        if (setTopicHeader && !headers.containsKey(topicHeader)) {                headers.put(topicHeader, message.topic());            }            if (!headers.containsKey(KafkaSourceConstants.PARTITION_HEADER)) {                headers.put(KafkaSourceConstants.PARTITION_HEADER, String.valueOf(message.partition()));            }            if (!headers.containsKey(OFFSET_HEADER)) {                headers.put(OFFSET_HEADER, String.valueOf(message.offset()));            }            if (kafkaKey != null) {                headers.put(KafkaSourceConstants.KEY_HEADER, kafkaKey);            }            if (log.isTraceEnabled()) {                if (LogPrivacyUtil.allowLogRawData()) {                    log.trace("Topic: {} Partition: {} Message: {}", new String[] { message.topic(), String.valueOf(message.partition()), new String(eventBody) });                } else {                    log.trace("Topic: {} Partition: {} Message arrived.", message.topic(), String.valueOf(message.partition()));                }            }            event = EventBuilder.withBody(eventBody, headers);            eventList.add(event);            if (log.isDebugEnabled()) {                log.debug("Waited: {} ", System.currentTimeMillis() - batchStartTime);                log.debug("Event #: {}", eventList.size());            }                        tpAndOffsetMetadata.put(new TopicPartition(message.topic(), message.partition()), new OffsetAndMetadata(message.offset() + 1, batchUUID));        }        if (eventList.size() > 0) {            counter.addToKafkaEventGetTimer((System.nanoTime() - nanoBatchStartTime) / (1000 * 1000));            counter.addToEventReceivedCount((long) eventList.size());            getChannelProcessor().processEventBatch(eventList);            counter.addToEventAcceptedCount(eventList.size());            if (log.isDebugEnabled()) {                log.debug("Wrote {} events to channel", eventList.size());            }            eventList.clear();            if (!tpAndOffsetMetadata.isEmpty()) {                long commitStartTime = System.nanoTime();                consumer.commitSync(tpAndOffsetMetadata);                long commitEndTime = System.nanoTime();                counter.addToKafkaCommitTimer((commitEndTime - commitStartTime) / (1000 * 1000));                tpAndOffsetMetadata.clear();            }            return Status.READY;        }        return Status.BACKOFF;    } catch (Exception e) {        log.error("KafkaSource EXCEPTION, {}", e);        counter.incrementEventReadOrChannelFail(e);        return Status.BACKOFF;    }}
142257108f477bf2e124e1838bfbce41c0a617c37f4ee7c5e0f8eb9232c79477
doConfigure
protected void doConfigure(Context context) throws FlumeException
{    this.context = context;    headers = new HashMap<String, String>(4);    tpAndOffsetMetadata = new HashMap<TopicPartition, OffsetAndMetadata>();    rebalanceFlag = new AtomicBoolean(false);    kafkaProps = new Properties();            translateOldProperties(context);    String topicProperty = context.getString(KafkaSourceConstants.TOPICS_REGEX);    if (topicProperty != null && !topicProperty.isEmpty()) {                subscriber = new PatternSubscriber(topicProperty);    } else if ((topicProperty = context.getString(KafkaSourceConstants.TOPICS)) != null && !topicProperty.isEmpty()) {                subscriber = new TopicListSubscriber(topicProperty);    } else if (subscriber == null) {        throw new ConfigurationException("At least one Kafka topic must be specified.");    }    batchUpperLimit = context.getInteger(KafkaSourceConstants.BATCH_SIZE, KafkaSourceConstants.DEFAULT_BATCH_SIZE);    maxBatchDurationMillis = context.getInteger(KafkaSourceConstants.BATCH_DURATION_MS, KafkaSourceConstants.DEFAULT_BATCH_DURATION);    useAvroEventFormat = context.getBoolean(KafkaSourceConstants.AVRO_EVENT, KafkaSourceConstants.DEFAULT_AVRO_EVENT);    if (log.isDebugEnabled()) {        log.debug(KafkaSourceConstants.AVRO_EVENT + " set to: {}", useAvroEventFormat);    }    zookeeperConnect = context.getString(ZOOKEEPER_CONNECT_FLUME_KEY);    migrateZookeeperOffsets = context.getBoolean(MIGRATE_ZOOKEEPER_OFFSETS, DEFAULT_MIGRATE_ZOOKEEPER_OFFSETS);    bootstrapServers = context.getString(KafkaSourceConstants.BOOTSTRAP_SERVERS);    if (bootstrapServers == null || bootstrapServers.isEmpty()) {        if (zookeeperConnect == null || zookeeperConnect.isEmpty()) {            throw new ConfigurationException("Bootstrap Servers must be specified");        } else {                        log.warn("{} is deprecated. Please use the parameter {}", KafkaSourceConstants.ZOOKEEPER_CONNECT_FLUME_KEY, KafkaSourceConstants.BOOTSTRAP_SERVERS);                        String securityProtocolStr = context.getSubProperties(KafkaSourceConstants.KAFKA_CONSUMER_PREFIX).get(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG);            if (securityProtocolStr == null || securityProtocolStr.isEmpty()) {                securityProtocolStr = CommonClientConfigs.DEFAULT_SECURITY_PROTOCOL;            }            bootstrapServers = lookupBootstrap(zookeeperConnect, SecurityProtocol.valueOf(securityProtocolStr));        }    }    String groupIdProperty = context.getString(KAFKA_CONSUMER_PREFIX + ConsumerConfig.GROUP_ID_CONFIG);    if (groupIdProperty != null && !groupIdProperty.isEmpty()) {                groupId = groupIdProperty;    }    if (groupId == null || groupId.isEmpty()) {        groupId = DEFAULT_GROUP_ID;        log.info("Group ID was not specified. Using {} as the group id.", groupId);    }    setTopicHeader = context.getBoolean(KafkaSourceConstants.SET_TOPIC_HEADER, KafkaSourceConstants.DEFAULT_SET_TOPIC_HEADER);    topicHeader = context.getString(KafkaSourceConstants.TOPIC_HEADER, KafkaSourceConstants.DEFAULT_TOPIC_HEADER);    setConsumerProps(context);    if (log.isDebugEnabled() && LogPrivacyUtil.allowLogPrintConfig()) {        log.debug("Kafka consumer properties: {}", kafkaProps);    }    if (counter == null) {        counter = new KafkaSourceCounter(getName());    }}
ab9c5710161fb9fafb68332fe5e7219c1c7d566627c8bfd375a94713ac10fc69
translateOldProperties
private void translateOldProperties(Context ctx)
{        String topic = context.getString(KafkaSourceConstants.TOPIC);    if (topic != null && !topic.isEmpty()) {        subscriber = new TopicListSubscriber(topic);        log.warn("{} is deprecated. Please use the parameter {}", KafkaSourceConstants.TOPIC, KafkaSourceConstants.TOPICS);    }        groupId = ctx.getString(KafkaSourceConstants.OLD_GROUP_ID);    if (groupId != null && !groupId.isEmpty()) {        log.warn("{} is deprecated. Please use the parameter {}", KafkaSourceConstants.OLD_GROUP_ID, KafkaSourceConstants.KAFKA_CONSUMER_PREFIX + ConsumerConfig.GROUP_ID_CONFIG);    }}
3030542ceab277b2a4dc44f0120e9393b66d8b7a478d9f9aa25df5cca919e8c5
setConsumerProps
private void setConsumerProps(Context ctx)
{    kafkaProps.clear();    kafkaProps.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, KafkaSourceConstants.DEFAULT_KEY_DESERIALIZER);    kafkaProps.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, KafkaSourceConstants.DEFAULT_VALUE_DESERIALIZER);        kafkaProps.putAll(ctx.getSubProperties(KafkaSourceConstants.KAFKA_CONSUMER_PREFIX));        kafkaProps.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);    if (groupId != null) {        kafkaProps.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);    }    kafkaProps.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, KafkaSourceConstants.DEFAULT_AUTO_COMMIT);    KafkaSSLUtil.addGlobalSSLParameters(kafkaProps);}
e33d27a14e28e831c5508999c7dbcd152034cf3087d39e8211ce2db562894887
lookupBootstrap
private String lookupBootstrap(String zookeeperConnect, SecurityProtocol securityProtocol)
{    try (KafkaZkClient zkClient = KafkaZkClient.apply(zookeeperConnect, JaasUtils.isZkSecurityEnabled(), ZK_SESSION_TIMEOUT, ZK_CONNECTION_TIMEOUT, 10, Time.SYSTEM, "kafka.server", "SessionExpireListener")) {        List<Broker> brokerList = JavaConverters.seqAsJavaListConverter(zkClient.getAllBrokersInCluster()).asJava();        List<BrokerEndPoint> endPoints = brokerList.stream().map(broker -> broker.brokerEndPoint(ListenerName.forSecurityProtocol(securityProtocol))).collect(Collectors.toList());        List<String> connections = new ArrayList<>();        for (BrokerEndPoint endPoint : endPoints) {            connections.add(endPoint.connectionString());        }        return StringUtils.join(connections, ',');    }}
65a1748d5e42876477cae30937a937a50b3a7ab3fedae459eaa486882a6d8b03
getBootstrapServers
 String getBootstrapServers()
{    return bootstrapServers;}
a90eaa3671470db54f76932b9f8a9b7d87f69907654bcca8644d98433135a035
getConsumerProps
 Properties getConsumerProps()
{    return kafkaProps;}
2e58b3ac498ab3927896f17dd5b1322f2b5601df3bbefc5d05d04de291b821f1
toStringMap
private static Map<String, String> toStringMap(Map<CharSequence, CharSequence> charSeqMap)
{    Map<String, String> stringMap = new HashMap<String, String>();    for (Map.Entry<CharSequence, CharSequence> entry : charSeqMap.entrySet()) {        stringMap.put(entry.getKey().toString(), entry.getValue().toString());    }    return stringMap;}
a1c3e6a68082be982cfc79e41303310c4dd94a9443ca8bb03dc816cc27d5921f
getSubscriber
 Subscriber<T> getSubscriber()
{    return subscriber;}
9dc3ff24bcdde4c0d9a8a91bf810de54f264a0f1ca17b695fea6381be65d7456
doStart
protected void doStart() throws FlumeException
{    log.info("Starting {}...", this);        if (migrateZookeeperOffsets && zookeeperConnect != null && !zookeeperConnect.isEmpty()) {                if (subscriber instanceof TopicListSubscriber && ((TopicListSubscriber) subscriber).get().size() == 1) {            String topicStr = ((TopicListSubscriber) subscriber).get().get(0);            migrateOffsets(topicStr);        } else {            log.info("Will not attempt to migrate offsets " + "because multiple topics or a pattern are defined");        }    }        consumer = new KafkaConsumer<String, byte[]>(kafkaProps);        subscriber.subscribe(consumer, new SourceRebalanceListener(rebalanceFlag));    log.info("Kafka source {} started.", getName());    counter.start();}
984404ddc9435f386a11b7a4633a4b527dc0cdb6ff0eb2dfeb17ad1c4907be8b
doStop
protected void doStop() throws FlumeException
{    if (consumer != null) {        consumer.wakeup();        consumer.close();    }    if (counter != null) {        counter.stop();    }    log.info("Kafka Source {} stopped. Metrics: {}", getName(), counter);}
01f1ece81bdc7692cbbf6c7138b99df85bfa8e7ad7b95d0d49031021049911f2
migrateOffsets
private void migrateOffsets(String topicStr)
{    try (KafkaZkClient zkClient = KafkaZkClient.apply(zookeeperConnect, JaasUtils.isZkSecurityEnabled(), ZK_SESSION_TIMEOUT, ZK_CONNECTION_TIMEOUT, 10, Time.SYSTEM, "kafka.server", "SessionExpireListener");        KafkaConsumer<String, byte[]> consumer = new KafkaConsumer<>(kafkaProps)) {        Map<TopicPartition, OffsetAndMetadata> kafkaOffsets = getKafkaOffsets(consumer, topicStr);        if (kafkaOffsets == null) {            log.warn("Topic " + topicStr + " not found in Kafka. Offset migration will be skipped.");            return;        }        if (!kafkaOffsets.isEmpty()) {            log.info("Found Kafka offsets for topic " + topicStr + ". Will not migrate from zookeeper");            log.debug("Offsets found: {}", kafkaOffsets);            return;        }        log.info("No Kafka offsets found. Migrating zookeeper offsets");        Map<TopicPartition, OffsetAndMetadata> zookeeperOffsets = getZookeeperOffsets(zkClient, consumer, topicStr);        if (zookeeperOffsets.isEmpty()) {            log.warn("No offsets to migrate found in Zookeeper");            return;        }        log.info("Committing Zookeeper offsets to Kafka");        log.debug("Offsets to commit: {}", zookeeperOffsets);        consumer.commitSync(zookeeperOffsets);                Map<TopicPartition, OffsetAndMetadata> newKafkaOffsets = getKafkaOffsets(consumer, topicStr);        log.debug("Offsets committed: {}", newKafkaOffsets);        if (newKafkaOffsets == null || !newKafkaOffsets.keySet().containsAll(zookeeperOffsets.keySet())) {            throw new FlumeException("Offsets could not be committed");        }    }}
22c71deff64d6462d4e3fa7c919198b0e735e4f01af58bff6a1c5183c0c43089
getKafkaOffsets
private Map<TopicPartition, OffsetAndMetadata> getKafkaOffsets(KafkaConsumer<String, byte[]> client, String topicStr)
{    Map<TopicPartition, OffsetAndMetadata> offsets = null;    List<PartitionInfo> partitions = client.partitionsFor(topicStr);    if (partitions != null) {        offsets = new HashMap<>();        for (PartitionInfo partition : partitions) {            TopicPartition key = new TopicPartition(topicStr, partition.partition());            OffsetAndMetadata offsetAndMetadata = client.committed(key);            if (offsetAndMetadata != null) {                offsets.put(key, offsetAndMetadata);            }        }    }    return offsets;}
4676e976768235137fb2d272c13fd27fd2feffa2c5e3511179a32e8f136245bb
getZookeeperOffsets
private Map<TopicPartition, OffsetAndMetadata> getZookeeperOffsets(KafkaZkClient zkClient, KafkaConsumer<String, byte[]> consumer, String topicStr)
{    Map<TopicPartition, OffsetAndMetadata> offsets = new HashMap<>();    List<PartitionInfo> partitions = consumer.partitionsFor(topicStr);    for (PartitionInfo partition : partitions) {        TopicPartition topicPartition = new TopicPartition(topicStr, partition.partition());        Option<Object> optionOffset = zkClient.getConsumerOffset(groupId, topicPartition);        if (optionOffset.nonEmpty()) {            Long offset = (Long) optionOffset.get();            OffsetAndMetadata offsetAndMetadata = new OffsetAndMetadata(offset);            offsets.put(topicPartition, offsetAndMetadata);        }    }    return offsets;}
cac5d34fe0051519b8bdcb32fd429171075d1bd2c0191749047730ecbb52d987
onPartitionsRevoked
public void onPartitionsRevoked(Collection<TopicPartition> partitions)
{    for (TopicPartition partition : partitions) {        log.info("topic {} - partition {} revoked.", partition.topic(), partition.partition());        rebalanceFlag.set(true);    }}
0592fcd4dbb7085351acc388587ef8b2537c35944360fa0b76c763a3c7ab1a6e
onPartitionsAssigned
public void onPartitionsAssigned(Collection<TopicPartition> partitions)
{    for (TopicPartition partition : partitions) {        log.info("topic {} - partition {} assigned.", partition.topic(), partition.partition());    }}
fd732d77c28d2f0126136bb0740a277252ed1e44adce8be7baadbf50b18cca83
findFreePort
private static int findFreePort()
{    try (ServerSocket socket = new ServerSocket(0)) {        return socket.getLocalPort();    } catch (IOException e) {        throw new AssertionError("Can not find free port.", e);    }}
e431b2172904a46f506a2c97ba44a3df72e0057d82ce8f9714a53e2efce2a010
stop
public void stop() throws IOException
{    producer.close();    kafkaServer.shutdown();    zookeeper.stopZookeeper();}
84bf2628b52fbc7745fd1ae799f4d8d69e81f718079819d39591f764ad60088b
getZkConnectString
public String getZkConnectString()
{    return zookeeper.getConnectString();}
dd2535e955406a07c3e1afe7764ea0b4850ecacac58a56aeb24b1811f76d371c
getBootstrapServers
public String getBootstrapServers()
{    return HOST + ":" + serverPort;}
3cac6daba60d52698ccef5e823b8ea2e58df4dfe7f4400d690ee551c1bb2d3c2
initProducer
private void initProducer()
{    Properties props = new Properties();    props.put("bootstrap.servers", HOST + ":" + serverPort);    props.put("acks", "1");    producer = new KafkaProducer<String, byte[]>(props, new StringSerializer(), new ByteArraySerializer());}
5958e0c217a415280f90d7468f8f0657fd9d69f51198e98c1bb7b50eb50948bd
produce
public void produce(String topic, String k, String v)
{    produce(topic, k, v.getBytes());}
e23998bfc0c29ca1fd1b8407fb392f7a32eb49a7be9e6ea39642bf3a6f324e36
produce
public void produce(String topic, String k, byte[] v)
{    ProducerRecord<String, byte[]> rec = new ProducerRecord<String, byte[]>(topic, k, v);    try {        producer.send(rec).get();    } catch (InterruptedException e) {        e.printStackTrace();    } catch (ExecutionException e) {        e.printStackTrace();    }}
3700de8cc11d5ac82faa88e90cb733a9065f32c845779140ce8fabb01428c581
produce
public void produce(String topic, int partition, String k, String v)
{    produce(topic, partition, k, v.getBytes());}
9ab91254c0f0f335d1eea0e473c89c9bde5dd176d6bff7a714a46e0f269b66f4
produce
public void produce(String topic, int partition, String k, byte[] v)
{    ProducerRecord<String, byte[]> rec = new ProducerRecord<String, byte[]>(topic, partition, k, v);    try {        producer.send(rec).get();    } catch (InterruptedException e) {        e.printStackTrace();    } catch (ExecutionException e) {        e.printStackTrace();    }}
fb567152915d10690bcb0c8eed90e2489ee9271af1fc2406edbc325eaa3d4beb
createTopic
public void createTopic(String topicName, int numPartitions)
{    AdminClient adminClient = getAdminClient();    NewTopic newTopic = new NewTopic(topicName, numPartitions, (short) 1);    adminClient.createTopics(Collections.singletonList(newTopic));        DescribeTopicsResult dtr = adminClient.describeTopics(Collections.singletonList(topicName));    try {        dtr.all().get(10, TimeUnit.SECONDS);    } catch (Exception e) {        throw new RuntimeException("Error getting topic info", e);    }}
21c8e88f2aba63ceddf81c968c31b5787a66d0f1fdbc3d164477305faefbfce7
getAdminClient
private AdminClient getAdminClient()
{    if (adminClient == null) {        final Properties props = new Properties();        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, HOST + ":" + serverPort);        props.put(ConsumerConfig.GROUP_ID_CONFIG, "group_1");        adminClient = AdminClient.create(props);    }    return adminClient;}
129a20b08d340c4f36659e1c53c552350054a193ddb0ed0b681419fd43f9af94
deleteTopics
public void deleteTopics(List<String> topic)
{    getAdminClient().deleteTopics(topic);}
420469e944a9944ca728805c6a216f037396f43ef3d2bc0e4cec4e6e0228fc06
stopZookeeper
public void stopZookeeper() throws IOException
{    zookeeper.shutdown();    factory.shutdown();    FileUtils.deleteDirectory(dir);}
d3e6eb9a0d8bc55e5a7a67cb50bc193600cea2e68478ce0daf2fac60142e695c
getConnectString
public String getConnectString()
{    return KafkaSourceEmbeddedKafka.HOST + ":" + zkPort;}
ee067a67b3da4170c858e32d52208fb87c409c1184de10f0310717976a24ca5c
startKafkaServer
public static void startKafkaServer()
{    kafkaServer = new KafkaSourceEmbeddedKafka(null);    startupCheck();}
27681e68ec2a1eb903f955680ebe003ceb3707295c8aad884b692d378c6e37cf
setup
public void setup() throws Exception
{    kafkaSource = new KafkaSource();    try {        topic0 = findUnusedTopic();        kafkaServer.createTopic(topic0, 1);        usedTopics.add(topic0);        topic1 = findUnusedTopic();        kafkaServer.createTopic(topic1, 3);        usedTopics.add(topic1);    } catch (TopicExistsException e) {                e.printStackTrace();    }    context = prepareDefaultContext("flume-group");    kafkaSource.setChannelProcessor(createGoodChannel());}
7e8d26ac4e14ea3a506d75f93530ba1f3a924554927da813d794f0369b149c98
startupCheck
private static void startupCheck()
{    String startupTopic = "startupCheck";    KafkaConsumer<String, String> startupConsumer;    kafkaServer.createTopic(startupTopic, 1);    final Properties props = new Properties();    props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaServer.getBootstrapServers());    props.put(ConsumerConfig.GROUP_ID_CONFIG, "group_1");    props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());    props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);    consumer.subscribe(Collections.singletonList(startupTopic));    log.info("Checking Startup");    boolean success = false;    for (int i = 0; i < 20; i++) {        kafkaServer.produce(startupTopic, "", "record");        ConsumerRecords recs = consumer.poll(Duration.ofMillis(1000L));        if (!recs.isEmpty()) {            success = true;            break;        }    }    if (!success) {        fail("Kafka server startup failed");    }    log.info("Kafka server startup success");    consumer.close();    kafkaServer.deleteTopics(Collections.singletonList(startupTopic));}
d550a6fc86f21fcca8c6378439746538e724ef97b096cf065cde601d864468ba
prepareDefaultContext
private Context prepareDefaultContext(String groupId)
{    Context context = new Context();    context.put(BOOTSTRAP_SERVERS, kafkaServer.getBootstrapServers());    context.put(KAFKA_CONSUMER_PREFIX + "group.id", groupId);    return context;}
c6aaebb5a52567751db8dc8e1cb9dd4a4e582ef964a374b376c6a04f741802dc
tearDown
public void tearDown() throws Exception
{    try {        kafkaSource.stop();    } catch (Exception e) {        log.warn("Error stopping kafkaSource", e);    }    topic0 = null;    topic1 = null;    kafkaServer.deleteTopics(usedTopics);    usedTopics.clear();}
f838e82f314f851c8021a6f0dd2ecda7d2938733abc9ee3ec85371e1f44e5187
stopKafkaServer
public static void stopKafkaServer() throws Exception
{    kafkaServer.stop();}
1cb93f201219407dc7640c8df744688426d6be87c91fbafac713b4acb3ff6748
startKafkaSource
private void startKafkaSource() throws EventDeliveryException, InterruptedException
{    kafkaSource.start();    /* Timing magic: We call the process method, that executes a consumer.poll()      A thread.sleep(10000L) does not work even though it takes longer */    for (int i = 0; i < 3; i++) {        kafkaSource.process();        Thread.sleep(1000);    }}
2b74b00744ad05d8db9f3d139757a4e3bdabd54ce951ddf7710d007507237ceb
testOffsets
public void testOffsets() throws InterruptedException, EventDeliveryException
{    long batchDuration = 2000;    context.put(TOPICS, topic1);    context.put(BATCH_DURATION_MS, String.valueOf(batchDuration));    context.put(BATCH_SIZE, "3");    kafkaSource.configure(context);    startKafkaSource();    Thread.sleep(500L);    Status status = kafkaSource.process();    assertEquals(Status.BACKOFF, status);    assertEquals(0, events.size());    kafkaServer.produce(topic1, "", "record1");    kafkaServer.produce(topic1, "", "record2");    Thread.sleep(500L);    status = kafkaSource.process();    assertEquals(Status.READY, status);    assertEquals(2, events.size());    events.clear();    kafkaServer.produce(topic1, "", "record3");    kafkaServer.produce(topic1, "", "record4");    kafkaServer.produce(topic1, "", "record5");    Thread.sleep(500L);    assertEquals(Status.READY, kafkaSource.process());    assertEquals(3, events.size());    assertEquals("record3", new String(events.get(0).getBody(), Charsets.UTF_8));    assertEquals("record4", new String(events.get(1).getBody(), Charsets.UTF_8));    assertEquals("record5", new String(events.get(2).getBody(), Charsets.UTF_8));    events.clear();    kafkaServer.produce(topic1, "", "record6");    kafkaServer.produce(topic1, "", "record7");    kafkaServer.produce(topic1, "", "record8");    kafkaServer.produce(topic1, "", "record9");    kafkaServer.produce(topic1, "", "record10");    Thread.sleep(500L);    assertEquals(Status.READY, kafkaSource.process());    assertEquals(3, events.size());    assertEquals("record6", new String(events.get(0).getBody(), Charsets.UTF_8));    assertEquals("record7", new String(events.get(1).getBody(), Charsets.UTF_8));    assertEquals("record8", new String(events.get(2).getBody(), Charsets.UTF_8));    events.clear();    kafkaServer.produce(topic1, "", "record11");        assertEquals(Status.READY, kafkaSource.process());    assertEquals(3, events.size());    assertEquals("record9", new String(events.get(0).getBody(), Charsets.UTF_8));    assertEquals("record10", new String(events.get(1).getBody(), Charsets.UTF_8));    assertEquals("record11", new String(events.get(2).getBody(), Charsets.UTF_8));    events.clear();    kafkaServer.produce(topic1, "", "record12");    kafkaServer.produce(topic1, "", "record13");        kafkaSource.stop();        kafkaSource = new KafkaSource();    kafkaSource.setChannelProcessor(createGoodChannel());    kafkaSource.configure(context);    startKafkaSource();    kafkaServer.produce(topic1, "", "record14");    Thread.sleep(1000L);    assertEquals(Status.READY, kafkaSource.process());    assertEquals(3, events.size());    assertEquals("record12", new String(events.get(0).getBody(), Charsets.UTF_8));    assertEquals("record13", new String(events.get(1).getBody(), Charsets.UTF_8));    assertEquals("record14", new String(events.get(2).getBody(), Charsets.UTF_8));    events.clear();}
851f43b569d5837663f096db81ea3a70d28e55f15ca20f9b0e23549e2d24c4ba
testProcessItNotEmpty
public void testProcessItNotEmpty() throws EventDeliveryException, SecurityException, NoSuchFieldException, IllegalArgumentException, IllegalAccessException, InterruptedException
{    context.put(TOPICS, topic0);    context.put(BATCH_SIZE, "1");    kafkaSource.configure(context);    startKafkaSource();    Thread.sleep(500L);    kafkaServer.produce(topic0, "", "hello, world");    Thread.sleep(500L);    Assert.assertEquals(Status.READY, kafkaSource.process());    Assert.assertEquals(Status.BACKOFF, kafkaSource.process());    Assert.assertEquals(1, events.size());    Assert.assertEquals("hello, world", new String(events.get(0).getBody(), Charsets.UTF_8));}
4a792401bcf7a6cc20bbaf516b1ff340b32b186770636ae5c9c88b5a2680f5f0
testProcessItNotEmptyBatch
public void testProcessItNotEmptyBatch() throws EventDeliveryException, SecurityException, NoSuchFieldException, IllegalArgumentException, IllegalAccessException, InterruptedException
{    context.put(TOPICS, topic0);    context.put(BATCH_SIZE, "2");    kafkaSource.configure(context);    startKafkaSource();    Thread.sleep(500L);    kafkaServer.produce(topic0, "", "hello, world");    kafkaServer.produce(topic0, "", "foo, bar");    Thread.sleep(500L);    Status status = kafkaSource.process();    assertEquals(Status.READY, status);    Assert.assertEquals("hello, world", new String(events.get(0).getBody(), Charsets.UTF_8));    Assert.assertEquals("foo, bar", new String(events.get(1).getBody(), Charsets.UTF_8));}
5ae29b3147f16788bf3d6f8ace879105b5266ac01ad73ea12ee0da09d8ea4154
testProcessItEmpty
public void testProcessItEmpty() throws EventDeliveryException, SecurityException, NoSuchFieldException, IllegalArgumentException, IllegalAccessException, InterruptedException
{    context.put(TOPICS, topic0);    kafkaSource.configure(context);    startKafkaSource();    Thread.sleep(500L);    Status status = kafkaSource.process();    assertEquals(Status.BACKOFF, status);}
304411532d53e9a07972a503836bdf1876d132ea58a2b11b3f97ddcd6192db1f
testNonExistingTopic
public void testNonExistingTopic() throws EventDeliveryException, SecurityException, NoSuchFieldException, IllegalArgumentException, IllegalAccessException, InterruptedException
{    context.put(TOPICS, "faketopic");    kafkaSource.configure(context);    startKafkaSource();    Thread.sleep(500L);    assertEquals(LifecycleState.START, kafkaSource.getLifecycleState());    Status status = kafkaSource.process();    assertEquals(Status.BACKOFF, status);}
ef0f79f1d96c5d4ba30c724161e2c30078eb9a4408d3e73da50ab60090c0bf73
testNonExistingKafkaServer
public void testNonExistingKafkaServer() throws EventDeliveryException, SecurityException, NoSuchFieldException, IllegalArgumentException, IllegalAccessException, InterruptedException
{    context.put(TOPICS, topic0);    context.put(BOOTSTRAP_SERVERS, "blabla:666");    kafkaSource.configure(context);    startKafkaSource();    Thread.sleep(500L);    Status status = kafkaSource.process();    assertEquals(Status.BACKOFF, status);}
2e60d60c6bfdd293f04c33c4ea19e08a0f932c885a010ddb94c51c901b369d34
testBatchTime
public void testBatchTime() throws InterruptedException, EventDeliveryException
{    context.put(TOPICS, topic0);    context.put(BATCH_DURATION_MS, "250");    kafkaSource.configure(context);    startKafkaSource();        kafkaSource.process();    Thread.sleep(500L);    for (int i = 1; i < 5000; i++) {        kafkaServer.produce(topic0, "", "hello, world " + i);    }    Thread.sleep(500L);    long error = 50;    long startTime = System.currentTimeMillis();    Status status = kafkaSource.process();    long endTime = System.currentTimeMillis();    assertEquals(Status.READY, status);    assertTrue(endTime - startTime < (context.getLong(BATCH_DURATION_MS) + error));}
254b92225d966bfe51c69cd02f2dd1121dae8714ce58bde97ebb640909269d0d
testCommit
public void testCommit() throws InterruptedException, EventDeliveryException
{    context.put(TOPICS, topic0);    context.put(BATCH_SIZE, "1");    kafkaSource.configure(context);    startKafkaSource();    Thread.sleep(500L);    kafkaServer.produce(topic0, "", "hello, world");    Thread.sleep(500L);    Assert.assertEquals(Status.READY, kafkaSource.process());    kafkaSource.stop();    Thread.sleep(500L);    startKafkaSource();    Thread.sleep(500L);    Assert.assertEquals(Status.BACKOFF, kafkaSource.process());}
d7f11b2967c9b7a3bcd3fa88886f88c20ae94776f3c18a69f464bbe221fdc872
testNonCommit
public void testNonCommit() throws EventDeliveryException, InterruptedException
{    context.put(TOPICS, topic0);    context.put(BATCH_SIZE, "1");    context.put(BATCH_DURATION_MS, "30000");    kafkaSource.configure(context);    startKafkaSource();    Thread.sleep(500L);    kafkaServer.produce(topic0, "", "hello, world");    Thread.sleep(500L);    kafkaSource.setChannelProcessor(createBadChannel());    log.debug("processing from kafka to bad channel");    Assert.assertEquals(Status.BACKOFF, kafkaSource.process());    log.debug("repairing channel");    kafkaSource.setChannelProcessor(createGoodChannel());    log.debug("re-process to good channel - this should work");    kafkaSource.process();    Assert.assertEquals("hello, world", new String(events.get(0).getBody(), Charsets.UTF_8));}
022d0894faa67f0bf2d0f889eccce80e39ab84fc87a3fd91f60512ae774c4fa1
testTwoBatches
public void testTwoBatches() throws InterruptedException, EventDeliveryException
{    context.put(TOPICS, topic0);    context.put(BATCH_SIZE, "1");    context.put(BATCH_DURATION_MS, "30000");    kafkaSource.configure(context);    startKafkaSource();    Thread.sleep(500L);    kafkaServer.produce(topic0, "", "event 1");    Thread.sleep(500L);    kafkaSource.process();    Assert.assertEquals("event 1", new String(events.get(0).getBody(), Charsets.UTF_8));    events.clear();    kafkaServer.produce(topic0, "", "event 2");    Thread.sleep(500L);    kafkaSource.process();    Assert.assertEquals("event 2", new String(events.get(0).getBody(), Charsets.UTF_8));}
be624945a34aa4659090b5c268977e93b97e5fb412813d9f41014178bab724ac
testTwoBatchesWithAutocommit
public void testTwoBatchesWithAutocommit() throws InterruptedException, EventDeliveryException
{    context.put(TOPICS, topic0);    context.put(BATCH_SIZE, "1");    context.put(BATCH_DURATION_MS, "30000");    context.put(KAFKA_CONSUMER_PREFIX + "enable.auto.commit", "true");    kafkaSource.configure(context);    startKafkaSource();    Thread.sleep(500L);    kafkaServer.produce(topic0, "", "event 1");    Thread.sleep(500L);    kafkaSource.process();    Assert.assertEquals("event 1", new String(events.get(0).getBody(), Charsets.UTF_8));    events.clear();    kafkaServer.produce(topic0, "", "event 2");    Thread.sleep(500L);    kafkaSource.process();    Assert.assertEquals("event 2", new String(events.get(0).getBody(), Charsets.UTF_8));}
a45dc3b500234ba3323e4ca68aeddc302bc93e29461245d18b5fa92b0a9a7e93
testNullKey
public void testNullKey() throws EventDeliveryException, SecurityException, NoSuchFieldException, IllegalArgumentException, IllegalAccessException, InterruptedException
{    context.put(TOPICS, topic0);    context.put(BATCH_SIZE, "1");    kafkaSource.configure(context);    startKafkaSource();    Thread.sleep(500L);    kafkaServer.produce(topic0, null, "hello, world");    Thread.sleep(500L);    Assert.assertEquals(Status.READY, kafkaSource.process());    Assert.assertEquals(Status.BACKOFF, kafkaSource.process());    Assert.assertEquals(1, events.size());    Assert.assertEquals("hello, world", new String(events.get(0).getBody(), Charsets.UTF_8));}
b020c6e9b9b084e0a009aa95e2b60452da66515c719d4f21f688e3c5999ce59b
testErrorCounters
public void testErrorCounters() throws InterruptedException, EventDeliveryException
{    context.put(TOPICS, topic0);    context.put(BATCH_SIZE, "1");    kafkaSource.configure(context);    ChannelProcessor cp = Mockito.mock(ChannelProcessor.class);    doThrow(new ChannelException("dummy")).doThrow(new RuntimeException("dummy")).when(cp).processEventBatch(any(List.class));    kafkaSource.setChannelProcessor(cp);    startKafkaSource();    Thread.sleep(500L);    kafkaServer.produce(topic0, "", "hello, world");    Thread.sleep(500L);    kafkaSource.doProcess();    kafkaSource.doProcess();    SourceCounter sc = (SourceCounter) Whitebox.getInternalState(kafkaSource, "counter");    Assert.assertEquals(1, sc.getChannelWriteFail());    Assert.assertEquals(1, sc.getEventReadFail());    kafkaSource.stop();}
58c19b7d53d356e73d960119b6896ff391eae2ad650aebc59140a5191347182e
testSourceProperties
public void testSourceProperties()
{    Context context = new Context();    context.put(TOPICS, "test1, test2");    context.put(TOPICS_REGEX, "^stream[0-9]$");    context.put(BOOTSTRAP_SERVERS, "bootstrap-servers-list");    KafkaSource source = new KafkaSource();    source.doConfigure(context);            KafkaSource.Subscriber<Pattern> subscriber = source.getSubscriber();    Pattern pattern = subscriber.get();    Assert.assertTrue(pattern.matcher("stream1").find());}
05e9ebb2ea5d6fc8706ff4d1a603edd39078834a3f64abc932e99cb149003f10
testKafkaProperties
public void testKafkaProperties()
{    Context context = new Context();    context.put(TOPICS, "test1, test2");    context.put(KAFKA_CONSUMER_PREFIX + ConsumerConfig.GROUP_ID_CONFIG, "override.default.group.id");    context.put(KAFKA_CONSUMER_PREFIX + "fake.property", "kafka.property.value");    context.put(BOOTSTRAP_SERVERS, "real-bootstrap-servers-list");    context.put(KAFKA_CONSUMER_PREFIX + "bootstrap.servers", "bad-bootstrap-servers-list");    KafkaSource source = new KafkaSource();    source.doConfigure(context);    Properties kafkaProps = source.getConsumerProps();        assertEquals(String.valueOf(DEFAULT_AUTO_COMMIT), kafkaProps.getProperty(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG));        assertEquals("override.default.group.id", kafkaProps.getProperty(ConsumerConfig.GROUP_ID_CONFIG));        assertEquals("kafka.property.value", kafkaProps.getProperty("fake.property"));        assertEquals("real-bootstrap-servers-list", kafkaProps.getProperty("bootstrap.servers"));}
9db2f5281407be7210c57ebb9f1298717c8e7937404a90d1f2391c063dbfa5cb
testOldProperties
public void testOldProperties()
{    Context context = new Context();    context.put(TOPIC, "old.topic");    context.put(OLD_GROUP_ID, "old.groupId");    context.put(BOOTSTRAP_SERVERS, "real-bootstrap-servers-list");    KafkaSource source = new KafkaSource();    source.doConfigure(context);    Properties kafkaProps = source.getConsumerProps();    KafkaSource.Subscriber<List<String>> subscriber = source.getSubscriber();        assertEquals("old.topic", subscriber.get().get(0));        assertEquals("old.groupId", kafkaProps.getProperty(ConsumerConfig.GROUP_ID_CONFIG));    source = new KafkaSource();    context.put(KAFKA_CONSUMER_PREFIX + ConsumerConfig.GROUP_ID_CONFIG, "override.old.group.id");    source.doConfigure(context);    kafkaProps = source.getConsumerProps();        assertEquals("override.old.group.id", kafkaProps.getProperty(ConsumerConfig.GROUP_ID_CONFIG));    context.clear();    context.put(BOOTSTRAP_SERVERS, "real-bootstrap-servers-list");    context.put(TOPIC, "old.topic");    source = new KafkaSource();    source.doConfigure(context);    kafkaProps = source.getConsumerProps();        assertEquals(KafkaSourceConstants.DEFAULT_GROUP_ID, kafkaProps.getProperty(ConsumerConfig.GROUP_ID_CONFIG));}
f0cf744c316e42cb4657737a7b8f7cae48454e352448f45a91e1ac4cbfc49ce9
testPatternBasedSubscription
public void testPatternBasedSubscription()
{    Context context = new Context();    context.put(TOPICS_REGEX, "^topic[0-9]$");    context.put(OLD_GROUP_ID, "old.groupId");    context.put(BOOTSTRAP_SERVERS, "real-bootstrap-servers-list");    KafkaSource source = new KafkaSource();    source.doConfigure(context);    KafkaSource.Subscriber<Pattern> subscriber = source.getSubscriber();    for (int i = 0; i < 10; i++) {        Assert.assertTrue(subscriber.get().matcher("topic" + i).find());    }    Assert.assertFalse(subscriber.get().matcher("topic").find());}
d9af01ea0d6af55a7b371e7502ae1e56673391690f15ad3731fa8eccb78c914d
testAvroEvent
public void testAvroEvent() throws InterruptedException, EventDeliveryException, IOException
{    SpecificDatumWriter<AvroFlumeEvent> writer;    ByteArrayOutputStream tempOutStream;    BinaryEncoder encoder;    byte[] bytes;    context.put(TOPICS, topic0);    context.put(BATCH_SIZE, "1");    context.put(AVRO_EVENT, "true");    kafkaSource.configure(context);    startKafkaSource();    Thread.sleep(500L);    tempOutStream = new ByteArrayOutputStream();    writer = new SpecificDatumWriter<AvroFlumeEvent>(AvroFlumeEvent.class);    Map<CharSequence, CharSequence> headers = new HashMap<CharSequence, CharSequence>();    headers.put("header1", "value1");    headers.put("header2", "value2");    AvroFlumeEvent e = new AvroFlumeEvent(headers, ByteBuffer.wrap("hello, world".getBytes()));    encoder = EncoderFactory.get().directBinaryEncoder(tempOutStream, null);    writer.write(e, encoder);    encoder.flush();    bytes = tempOutStream.toByteArray();    kafkaServer.produce(topic0, "", bytes);    String currentTimestamp = Long.toString(System.currentTimeMillis());    headers.put(TIMESTAMP_HEADER, currentTimestamp);    headers.put(PARTITION_HEADER, "1");    headers.put(DEFAULT_TOPIC_HEADER, "topic0");    e = new AvroFlumeEvent(headers, ByteBuffer.wrap("hello, world2".getBytes()));    tempOutStream.reset();    encoder = EncoderFactory.get().directBinaryEncoder(tempOutStream, null);    writer.write(e, encoder);    encoder.flush();    bytes = tempOutStream.toByteArray();    kafkaServer.produce(topic0, "", bytes);    Thread.sleep(500L);    Assert.assertEquals(Status.READY, kafkaSource.process());    Assert.assertEquals(Status.READY, kafkaSource.process());    Assert.assertEquals(Status.BACKOFF, kafkaSource.process());    Assert.assertEquals(2, events.size());    Event event = events.get(0);    Assert.assertEquals("hello, world", new String(event.getBody(), Charsets.UTF_8));    Assert.assertEquals("value1", e.getHeaders().get("header1"));    Assert.assertEquals("value2", e.getHeaders().get("header2"));    event = events.get(1);    Assert.assertEquals("hello, world2", new String(event.getBody(), Charsets.UTF_8));    Assert.assertEquals("value1", e.getHeaders().get("header1"));    Assert.assertEquals("value2", e.getHeaders().get("header2"));    Assert.assertEquals(currentTimestamp, e.getHeaders().get(TIMESTAMP_HEADER));    Assert.assertEquals(e.getHeaders().get(PARTITION_HEADER), "1");    Assert.assertEquals(e.getHeaders().get(DEFAULT_TOPIC_HEADER), "topic0");}
559549aa4e620c4880d1b58479ed857409924307cc83c30cc2a2760796251e62
testBootstrapLookup
public void testBootstrapLookup()
{    Context context = new Context();    context.put(ZOOKEEPER_CONNECT_FLUME_KEY, kafkaServer.getZkConnectString());    context.put(TOPIC, "old.topic");    context.put(OLD_GROUP_ID, "old.groupId");    KafkaSource source = new KafkaSource();    source.doConfigure(context);    String bootstrapServers = source.getBootstrapServers();    Assert.assertEquals(kafkaServer.getBootstrapServers(), bootstrapServers);}
9013435a7d2832768d92dce6d230707c75d638ff04a3ac9af59726d076fcc3fe
testMigrateOffsetsNone
public void testMigrateOffsetsNone() throws Exception
{    doTestMigrateZookeeperOffsets(false, false, "testMigrateOffsets-none");}
46e3a714348321e56822d77382d1ab3684d504556fc564d42334d3ce3950a209
testMigrateOffsetsZookeeper
public void testMigrateOffsetsZookeeper() throws Exception
{    doTestMigrateZookeeperOffsets(true, false, "testMigrateOffsets-zookeeper");}
8a8d3c57baf073c92f55a995afb1fea6ae5a93a5b5f6905a6b8ec7ac46a87985
testMigrateOffsetsKafka
public void testMigrateOffsetsKafka() throws Exception
{    doTestMigrateZookeeperOffsets(false, true, "testMigrateOffsets-kafka");}
1ec8e570babff831d12e16c7e88fd169155e884dc0355f52292055fe9543b209
testMigrateOffsetsBoth
public void testMigrateOffsetsBoth() throws Exception
{    doTestMigrateZookeeperOffsets(true, true, "testMigrateOffsets-both");}
0e4714e6d888c30281b241800fa458d5a1273a29dcd7a1691fb2a6944b23faf9
testDefaultSettingsOnReConfigure
public void testDefaultSettingsOnReConfigure() throws Exception
{    String sampleConsumerProp = "auto.offset.reset";    String sampleConsumerVal = "earliest";    String group = "group";    Context context = prepareDefaultContext(group);    context.put(KafkaSourceConstants.KAFKA_CONSUMER_PREFIX + sampleConsumerProp, sampleConsumerVal);    context.put(TOPIC, "random-topic");    kafkaSource.configure(context);    Assert.assertEquals(sampleConsumerVal, kafkaSource.getConsumerProps().getProperty(sampleConsumerProp));    context = prepareDefaultContext(group);    context.put(TOPIC, "random-topic");    kafkaSource.configure(context);    Assert.assertNull(kafkaSource.getConsumerProps().getProperty(sampleConsumerProp));}
66d8e07e81c64d77c3f008603dd88493b6741ed64b093f055a04d9dbba893b8d
testTopicHeaderSet
public void testTopicHeaderSet() throws InterruptedException, EventDeliveryException
{    context.put(TOPICS, topic0);    kafkaSource.configure(context);    startKafkaSource();    Thread.sleep(500L);    kafkaServer.produce(topic0, "", "hello, world");    Thread.sleep(500L);    Status status = kafkaSource.process();    assertEquals(Status.READY, status);    Assert.assertEquals("hello, world", new String(events.get(0).getBody(), Charsets.UTF_8));    Assert.assertEquals(topic0, events.get(0).getHeaders().get("topic"));    kafkaSource.stop();    events.clear();}
9e87770e496675a7297eea2917f533d481e32284e14362c10c93761ab3ae5f25
testTopicCustomHeaderSet
public void testTopicCustomHeaderSet() throws InterruptedException, EventDeliveryException
{    context.put(TOPICS, topic0);    context.put(KafkaSourceConstants.TOPIC_HEADER, "customTopicHeader");    kafkaSource.configure(context);    startKafkaSource();    Thread.sleep(500L);    kafkaServer.produce(topic0, "", "hello, world2");    Thread.sleep(500L);    Status status = kafkaSource.process();    assertEquals(Status.READY, status);    Assert.assertEquals("hello, world2", new String(events.get(0).getBody(), Charsets.UTF_8));    Assert.assertEquals(topic0, events.get(0).getHeaders().get("customTopicHeader"));    kafkaSource.stop();    events.clear();}
b85b7718e7e666268a0b9f770230a0894a7b44a3de44336cb8699d706141cbd6
testTopicCustomHeaderNotSet
public void testTopicCustomHeaderNotSet() throws InterruptedException, EventDeliveryException
{    context.put(TOPICS, topic0);    context.put(KafkaSourceConstants.SET_TOPIC_HEADER, "false");    kafkaSource.configure(context);    startKafkaSource();    Thread.sleep(500L);    kafkaServer.produce(topic0, "", "hello, world3");    Thread.sleep(500L);    Status status = kafkaSource.process();    assertEquals(Status.READY, status);    Assert.assertEquals("hello, world3", new String(events.get(0).getBody(), Charsets.UTF_8));    Assert.assertNull(events.get(0).getHeaders().get("customTopicHeader"));    kafkaSource.stop();}
991597c704b93a56b51bceb0265ec8fb52e75cbd137270191bd756d3b6a75837
doTestMigrateZookeeperOffsets
private void doTestMigrateZookeeperOffsets(boolean hasZookeeperOffsets, boolean hasKafkaOffsets, String group) throws Exception
{        String topic = findUnusedTopic();    kafkaServer.createTopic(topic, 1);    Context context = prepareDefaultContext(group);    context.put(ZOOKEEPER_CONNECT_FLUME_KEY, kafkaServer.getZkConnectString());    context.put(TOPIC, topic);    KafkaSource source = new KafkaSource();    source.doConfigure(context);        Long fifthOffset = 0L;    Long tenthOffset = 0L;    Properties props = createProducerProps(kafkaServer.getBootstrapServers());    KafkaProducer<String, byte[]> producer = new KafkaProducer<>(props);    for (int i = 1; i <= 50; i++) {        ProducerRecord<String, byte[]> data = new ProducerRecord<>(topic, null, String.valueOf(i).getBytes());        RecordMetadata recordMetadata = producer.send(data).get();        if (i == 5) {            fifthOffset = recordMetadata.offset();        }        if (i == 10) {            tenthOffset = recordMetadata.offset();        }    }        if (hasZookeeperOffsets) {        KafkaZkClient zkClient = KafkaZkClient.apply(kafkaServer.getZkConnectString(), JaasUtils.isZkSecurityEnabled(), 30000, 30000, 10, Time.SYSTEM, "kafka.server", "SessionExpireListener");        zkClient.getConsumerOffset(group, new TopicPartition(topic, 0));        Long offset = tenthOffset + 1;        zkClient.setOrCreateConsumerOffset(group, new TopicPartition(topic, 0), offset);        zkClient.close();    }        if (hasKafkaOffsets) {        Map<TopicPartition, OffsetAndMetadata> offsets = new HashMap<>();        offsets.put(new TopicPartition(topic, 0), new OffsetAndMetadata(fifthOffset + 1));        KafkaConsumer<String, byte[]> consumer = new KafkaConsumer<>(source.getConsumerProps());        consumer.commitSync(offsets);        consumer.close();    }        source.setChannelProcessor(createGoodChannel());    source.start();    for (int i = 0; i < 3; i++) {        source.process();        Thread.sleep(1000);    }    Thread.sleep(500L);    source.process();    List<Integer> finals = new ArrayList<Integer>(40);    for (Event event : events) {        finals.add(Integer.parseInt(new String(event.getBody())));    }    source.stop();    if (!hasKafkaOffsets && !hasZookeeperOffsets) {                org.junit.Assert.assertTrue("Source should read no messages", finals.isEmpty());    } else if (hasKafkaOffsets && hasZookeeperOffsets) {                org.junit.Assert.assertFalse("Source should not read the 5th message", finals.contains(5));        org.junit.Assert.assertTrue("Source should read the 6th message", finals.contains(6));    } else if (hasKafkaOffsets) {                org.junit.Assert.assertFalse("Source should not read the 5th message", finals.contains(5));        org.junit.Assert.assertTrue("Source should read the 6th message", finals.contains(6));    } else {                org.junit.Assert.assertFalse("Source should not read the 10th message", finals.contains(10));        org.junit.Assert.assertTrue("Source should read the 11th message", finals.contains(11));    }}
ef8dbf440fb66cb86787b44e402977ce22afa22b01d45709a90775db2e8043fa
testMigrateZookeeperOffsetsWhenTopicNotExists
public void testMigrateZookeeperOffsetsWhenTopicNotExists() throws Exception
{    String topic = findUnusedTopic();    Context context = prepareDefaultContext("testMigrateOffsets-nonExistingTopic");    context.put(ZOOKEEPER_CONNECT_FLUME_KEY, kafkaServer.getZkConnectString());    context.put(TOPIC, topic);    KafkaSource source = new KafkaSource();    source.doConfigure(context);    source.setChannelProcessor(createGoodChannel());    source.start();    assertEquals(LifecycleState.START, source.getLifecycleState());    Status status = source.process();    assertEquals(Status.BACKOFF, status);    source.stop();}
22c15e7cccddda194dbdbf4df86e8b69ebc091c39dc497237f5ef571f747611a
createGoodChannel
 ChannelProcessor createGoodChannel()
{    ChannelProcessor channelProcessor = mock(ChannelProcessor.class);    events = Lists.newArrayList();    doAnswer(new Answer<Void>() {        @Override        public Void answer(InvocationOnMock invocation) throws Throwable {            events.addAll((List<Event>) invocation.getArguments()[0]);            return null;        }    }).when(channelProcessor).processEventBatch(any(List.class));    return channelProcessor;}
95bf71523ce2b266f318cc556abf31d0edd833353a1498e854e22b8b3a97d573
answer
public Void answer(InvocationOnMock invocation) throws Throwable
{    events.addAll((List<Event>) invocation.getArguments()[0]);    return null;}
95bb58294fbbab515693ec245827986583ff8f76da488826400937bc0691465c
createBadChannel
 ChannelProcessor createBadChannel()
{    ChannelProcessor channelProcessor = mock(ChannelProcessor.class);    doAnswer(new Answer<Void>() {        @Override        public Void answer(InvocationOnMock invocation) throws Throwable {            throw new ChannelException("channel intentional broken");        }    }).when(channelProcessor).processEventBatch(any(List.class));    return channelProcessor;}
95bf71523ce2b266f318cc556abf31d0edd833353a1498e854e22b8b3a97d573
answer
public Void answer(InvocationOnMock invocation) throws Throwable
{    throw new ChannelException("channel intentional broken");}
f4ffef4df5153ad792d0abc7bb2da49d5d52e62ed81b4cc3d188c3430c28985f
findUnusedTopic
public String findUnusedTopic()
{    String newTopic = null;    boolean topicFound = false;    while (!topicFound) {        newTopic = RandomStringUtils.randomAlphabetic(8);        if (!usedTopics.contains(newTopic)) {            usedTopics.add(newTopic);            topicFound = true;        }    }    return newTopic;}
bf3d5c9289af77ff5763b2def29fd48b4de305bda56be0b2d4d47216f2ff2df0
createProducerProps
private Properties createProducerProps(String bootStrapServers)
{    Properties props = new Properties();    props.put(ProducerConfig.ACKS_CONFIG, "-1");    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringSerializer");    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.ByteArraySerializer");    props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootStrapServers);    return props;}
92e9e6589c16b4fde1efd2a77a414bb3a621362cc64c5ef5a21381d0e5b55b5f
findByThriftId
public static _Fields findByThriftId(int fieldId)
{    switch(fieldId) {        case         1:            return CATEGORY;        case         2:            return MESSAGE;        default:            return null;    }}
950148827ecab1253536a12003b5b2c41c2778a566a9ed4cb2487de641d6bde4
findByThriftIdOrThrow
public static _Fields findByThriftIdOrThrow(int fieldId)
{    _Fields fields = findByThriftId(fieldId);    if (fields == null)        throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");    return fields;}
eb44b9fdf7e05046f232aa9f1f3bb9a0cf815a486270439682862994e0d2c224
findByName
public static _Fields findByName(String name)
{    return byName.get(name);}
7f8fa4ecb4119b59b8047c285ac8f8729a909f121d1d3386d19ebfc6c04ab5df
getThriftFieldId
public short getThriftFieldId()
{    return _thriftId;}
68f4afd0e3cff42097dd5b6508fea1f7952d6d93f52ded3c1deea7186fff780c
getFieldName
public String getFieldName()
{    return _fieldName;}
766b3d71330a01c485bc3d5f837bca9e0aae01a6110a0f39a08b1dd483b64b44
deepCopy
public LogEntry deepCopy()
{    return new LogEntry(this);}
21ac40bb9a99614b6ac18fa4043acb6173fccff96066fdfab963dba597923aa8
clear
public void clear()
{    this.category = null;    this.message = null;}
2194ec2f3e02d468ab08ed5711773f90c930348c4617f76f232a2740b870a1df
getCategory
public String getCategory()
{    return this.category;}
d6cd56098f1ac6d12136c7d83f481184e124b21cc5ea1b644870f888ff155c7f
setCategory
public LogEntry setCategory(String category)
{    this.category = category;    return this;}
052f9a19f2271f9c2a1dee203d6981b1078ef3cad5fcbbc7652884b6027ff7f1
unsetCategory
public void unsetCategory()
{    this.category = null;}
d2372bcb60fe088426cafbfbf7fb5a3f793f7b37ff990d318e2e43ea13a62912
isSetCategory
public boolean isSetCategory()
{    return this.category != null;}
08e32fff7214abe130b12a59981ca1d47d37a2b58ce45989dae13c9a8a1a0c2c
setCategoryIsSet
public void setCategoryIsSet(boolean value)
{    if (!value) {        this.category = null;    }}
b46153cc21231cb60e014b6b3c49b437699575e4012681cb08026e5238c66751
getMessage
public String getMessage()
{    return this.message;}
2d82ac4dc1d8b8bf5ac17b48f28d3e601a52f357b67a21a87e000f059a232f75
setMessage
public LogEntry setMessage(String message)
{    this.message = message;    return this;}
3739345b182f004d16ad6d5a5bb6ca50ad75e47590d0fa191466dbea38ca48ef
unsetMessage
public void unsetMessage()
{    this.message = null;}
2abbd2162bddea2dd5f08796a5e9338d1e6d989a27f4cb22d1124219455a02c0
isSetMessage
public boolean isSetMessage()
{    return this.message != null;}
44bb4defd7d0685f83cd4a2dc36e829813bcefd4ff54b4d18b6d8cdbb37b7d4d
setMessageIsSet
public void setMessageIsSet(boolean value)
{    if (!value) {        this.message = null;    }}
56898e9e8fffee777f79916bb0318d8a0a1794f171b373787ede8ccabb314f39
setFieldValue
public void setFieldValue(_Fields field, Object value)
{    switch(field) {        case CATEGORY:            if (value == null) {                unsetCategory();            } else {                setCategory((String) value);            }            break;        case MESSAGE:            if (value == null) {                unsetMessage();            } else {                setMessage((String) value);            }            break;    }}
464d81fc54c8c50a21a786b4dc4dd56822e73892271735c454cff15126bc2dfd
getFieldValue
public Object getFieldValue(_Fields field)
{    switch(field) {        case CATEGORY:            return getCategory();        case MESSAGE:            return getMessage();    }    throw new IllegalStateException();}
71ed64fc282e6b120c36448a4f95d0d8102f98c0455e5f84713743b2826d64c9
isSet
public boolean isSet(_Fields field)
{    if (field == null) {        throw new IllegalArgumentException();    }    switch(field) {        case CATEGORY:            return isSetCategory();        case MESSAGE:            return isSetMessage();    }    throw new IllegalStateException();}
6b3ab298cb5d88dbb2c510c786f53e377489a40e2716e63c26a3e1691765f6c5
equals
public boolean equals(Object that)
{    if (that == null)        return false;    if (that instanceof LogEntry)        return this.equals((LogEntry) that);    return false;}
b659e110c00632a728b74cdc19ada2dd4bddbd6cd62b5facc69bb6d6cf458829
equals
public boolean equals(LogEntry that)
{    if (that == null)        return false;    boolean this_present_category = true && this.isSetCategory();    boolean that_present_category = true && that.isSetCategory();    if (this_present_category || that_present_category) {        if (!(this_present_category && that_present_category))            return false;        if (!this.category.equals(that.category))            return false;    }    boolean this_present_message = true && this.isSetMessage();    boolean that_present_message = true && that.isSetMessage();    if (this_present_message || that_present_message) {        if (!(this_present_message && that_present_message))            return false;        if (!this.message.equals(that.message))            return false;    }    return true;}
0ac42bf5188762fc1283b5cbd2b3bb1031e80963813b3b310b15c3fb47050003
hashCode
public int hashCode()
{    List<Object> list = new ArrayList<Object>();    boolean present_category = true && (isSetCategory());    list.add(present_category);    if (present_category)        list.add(category);    boolean present_message = true && (isSetMessage());    list.add(present_message);    if (present_message)        list.add(message);    return list.hashCode();}
d717e67606f37d99b2d0ce491e11ca61a6e13e6e0627fcd7522282cb77890d88
compareTo
public int compareTo(LogEntry other)
{    if (!getClass().equals(other.getClass())) {        return getClass().getName().compareTo(other.getClass().getName());    }    int lastComparison = 0;    lastComparison = Boolean.valueOf(isSetCategory()).compareTo(other.isSetCategory());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetCategory()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.category, other.category);        if (lastComparison != 0) {            return lastComparison;        }    }    lastComparison = Boolean.valueOf(isSetMessage()).compareTo(other.isSetMessage());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetMessage()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.message, other.message);        if (lastComparison != 0) {            return lastComparison;        }    }    return 0;}
8ce4cec748163fe422fba58a0ef1f5936a95d5ce0ec9e530aab7c5a59149b857
fieldForId
public _Fields fieldForId(int fieldId)
{    return _Fields.findByThriftId(fieldId);}
9c387dbc68e2929966a2f4d7377de396c1c24932dd7e709eba5cf9e1c90787af
read
public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException
{    schemes.get(iprot.getScheme()).getScheme().read(iprot, this);}
72f9005ef45238c38f6c8b9506f41c8599609ccde331e03c7044ee080e1472da
write
public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException
{    schemes.get(oprot.getScheme()).getScheme().write(oprot, this);}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    StringBuilder sb = new StringBuilder("LogEntry(");    boolean first = true;    sb.append("category:");    if (this.category == null) {        sb.append("null");    } else {        sb.append(this.category);    }    first = false;    if (!first)        sb.append(", ");    sb.append("message:");    if (this.message == null) {        sb.append("null");    } else {        sb.append(this.message);    }    first = false;    sb.append(")");    return sb.toString();}
e9a9838299550df368382cb18b6693a9d80b274b5c7bc089afc33713eceefbe1
validate
public void validate() throws org.apache.thrift.TException
{}
784e52bd99c637d4fd80e90272ace2edbc622a5a5ac2a515ab45f6d177fc378a
writeObject
private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException
{    try {        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
a2d949a3bc49af9f8b746197cee0585da9e196149570b4a376f3635b857a1744
readObject
private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException
{    try {        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
416c0b6fa4478407663e86af8c5b100ad24509d4c7c27ff3f8d6b343d6e37ba4
getScheme
public LogEntryStandardScheme getScheme()
{    return new LogEntryStandardScheme();}
e176426c23c02f610d250e7caa1aa6a35ef8c17fb03b9b8c821fa073f69acecd
read
public void read(org.apache.thrift.protocol.TProtocol iprot, LogEntry struct) throws org.apache.thrift.TException
{    org.apache.thrift.protocol.TField schemeField;    iprot.readStructBegin();    while (true) {        schemeField = iprot.readFieldBegin();        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) {            break;        }        switch(schemeField.id) {            case             1:                if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {                    struct.category = iprot.readString();                    struct.setCategoryIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            case             2:                if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {                    struct.message = iprot.readString();                    struct.setMessageIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            default:                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);        }        iprot.readFieldEnd();    }    iprot.readStructEnd();        struct.validate();}
7acb7c0c837a2a3ce86becf1f29bf858e8f10b0bb41b64d0111754ce6384fd12
write
public void write(org.apache.thrift.protocol.TProtocol oprot, LogEntry struct) throws org.apache.thrift.TException
{    struct.validate();    oprot.writeStructBegin(STRUCT_DESC);    if (struct.category != null) {        oprot.writeFieldBegin(CATEGORY_FIELD_DESC);        oprot.writeString(struct.category);        oprot.writeFieldEnd();    }    if (struct.message != null) {        oprot.writeFieldBegin(MESSAGE_FIELD_DESC);        oprot.writeString(struct.message);        oprot.writeFieldEnd();    }    oprot.writeFieldStop();    oprot.writeStructEnd();}
77e110a272e536065d34e888083e304d48a9301fe8f38aa1399b62bfdc64c993
getScheme
public LogEntryTupleScheme getScheme()
{    return new LogEntryTupleScheme();}
551ba48c1fc78ca62917709e0e9080e31685c841b971a35a7e980ce3fea5e41f
write
public void write(org.apache.thrift.protocol.TProtocol prot, LogEntry struct) throws org.apache.thrift.TException
{    TTupleProtocol oprot = (TTupleProtocol) prot;    BitSet optionals = new BitSet();    if (struct.isSetCategory()) {        optionals.set(0);    }    if (struct.isSetMessage()) {        optionals.set(1);    }    oprot.writeBitSet(optionals, 2);    if (struct.isSetCategory()) {        oprot.writeString(struct.category);    }    if (struct.isSetMessage()) {        oprot.writeString(struct.message);    }}
6024084cad5feed847447b6fe9cd8d5fc36b456134297c1eafb17bbe55e33c04
read
public void read(org.apache.thrift.protocol.TProtocol prot, LogEntry struct) throws org.apache.thrift.TException
{    TTupleProtocol iprot = (TTupleProtocol) prot;    BitSet incoming = iprot.readBitSet(2);    if (incoming.get(0)) {        struct.category = iprot.readString();        struct.setCategoryIsSet(true);    }    if (incoming.get(1)) {        struct.message = iprot.readString();        struct.setMessageIsSet(true);    }}
7f820eeb69ca0b6ba212f7fa738d25f53ebc1bc5cfb29c2200e154ad62791a65
getValue
public int getValue()
{    return value;}
a82454b5857cc8c0275eb1bca5a7fc985f27b33c5216009b58451c4000e5c85a
findByValue
public static ResultCode findByValue(int value)
{    switch(value) {        case 0:            return OK;        case 1:            return TRY_LATER;        default:            return null;    }}
c51e5cb6ab84996a366ca4c36408fdbb38461fdcc74ad26ed70818820572aaea
getClient
public Client getClient(org.apache.thrift.protocol.TProtocol prot)
{    return new Client(prot);}
f9e94ad26495767f197f0f23bc1a6ce01f90f5c97eede94dcba020bf0dbb3a1f
getClient
public Client getClient(org.apache.thrift.protocol.TProtocol iprot, org.apache.thrift.protocol.TProtocol oprot)
{    return new Client(iprot, oprot);}
04cd4e3c74f122bf8df5949011692b04d7225a0dc29808664e2cae7e8d4fb57c
Log
public ResultCode Log(List<LogEntry> messages) throws org.apache.thrift.TException
{    send_Log(messages);    return recv_Log();}
ddd7621b92602b74c365d62a0bbd633c856ffdf3573f95c4c4db1c78333ec0e2
send_Log
public void send_Log(List<LogEntry> messages) throws org.apache.thrift.TException
{    Log_args args = new Log_args();    args.setMessages(messages);    sendBase("Log", args);}
f67d718259af98c312e83a1be761f120827a1ce40c643f289f998ec9a1cfd861
recv_Log
public ResultCode recv_Log() throws org.apache.thrift.TException
{    Log_result result = new Log_result();    receiveBase(result, "Log");    if (result.isSetSuccess()) {        return result.success;    }    throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, "Log failed: unknown result");}
f3ce7d595d2009029c2fe49ca987d74d1a0cbb743047cd46460382cbee61e7ac
getAsyncClient
public AsyncClient getAsyncClient(org.apache.thrift.transport.TNonblockingTransport transport)
{    return new AsyncClient(protocolFactory, clientManager, transport);}
33470e2da7d88a6a2ea19a7f466f506e6c498b2491d8a28001095357001e59d4
Log
public void Log(List<LogEntry> messages, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException
{    checkReady();    Log_call method_call = new Log_call(messages, resultHandler, this, ___protocolFactory, ___transport);    this.___currentMethod = method_call;    ___manager.call(method_call);}
345dc223bb11c0c727744b96de56d5f0f1f3c374a491b829541ac5c66b1c1fe4
write_args
public void write_args(org.apache.thrift.protocol.TProtocol prot) throws org.apache.thrift.TException
{    prot.writeMessageBegin(new org.apache.thrift.protocol.TMessage("Log", org.apache.thrift.protocol.TMessageType.CALL, 0));    Log_args args = new Log_args();    args.setMessages(messages);    args.write(prot);    prot.writeMessageEnd();}
4a4ca9338a49891f5952f0dc36f1c5f6174bed7dde11796c8988a92f5e55832a
getResult
public ResultCode getResult() throws org.apache.thrift.TException
{    if (getState() != org.apache.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {        throw new IllegalStateException("Method call not finished!");    }    org.apache.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());    org.apache.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);    return (new Client(prot)).recv_Log();}
738d78d4660b6e44339a7f3c7826f5d36a27f149eba243598f194475b7236304
getProcessMap
private static Map<String, org.apache.thrift.ProcessFunction<I, ? extends org.apache.thrift.TBase>> getProcessMap(Map<String, org.apache.thrift.ProcessFunction<I, ? extends org.apache.thrift.TBase>> processMap)
{    processMap.put("Log", new Log());    return processMap;}
dee0e2f2f22f6958077225741581aaff7b744f0081f37bba2ea20f7becee08c3
getEmptyArgsInstance
public Log_args getEmptyArgsInstance()
{    return new Log_args();}
bebf296c86daa8f23132c9bae180b870c6dd9b8ba06fba8cc6695c835567cc77
isOneway
protected boolean isOneway()
{    return false;}
5aef8171d8d8270666a2a082e928d6834a2031128620ebc871ab8b2fc2f48d1e
getResult
public Log_result getResult(I iface, Log_args args) throws org.apache.thrift.TException
{    Log_result result = new Log_result();    result.success = iface.Log(args.messages);    return result;}
0409c31db10aa18694f957fa32b798fbeb64358a429f845b92d5de9db93dd0c4
getProcessMap
private static Map<String, org.apache.thrift.AsyncProcessFunction<I, ? extends org.apache.thrift.TBase, ?>> getProcessMap(Map<String, org.apache.thrift.AsyncProcessFunction<I, ? extends org.apache.thrift.TBase, ?>> processMap)
{    processMap.put("Log", new Log());    return processMap;}
dee0e2f2f22f6958077225741581aaff7b744f0081f37bba2ea20f7becee08c3
getEmptyArgsInstance
public Log_args getEmptyArgsInstance()
{    return new Log_args();}
0d46406ce3448995f1eae08ef34549b2f15348f378e08c22c3927abdbcf2196f
getResultHandler
public AsyncMethodCallback<ResultCode> getResultHandler(final AsyncFrameBuffer fb, final int seqid)
{    final org.apache.thrift.AsyncProcessFunction fcall = this;    return new AsyncMethodCallback<ResultCode>() {        public void onComplete(ResultCode o) {            Log_result result = new Log_result();            result.success = o;            try {                fcall.sendResponse(fb, result, org.apache.thrift.protocol.TMessageType.REPLY, seqid);                return;            } catch (Exception e) {                LOGGER.error("Exception writing to internal frame buffer", e);            }            fb.close();        }        public void onError(Exception e) {            byte msgType = org.apache.thrift.protocol.TMessageType.REPLY;            org.apache.thrift.TBase msg;            Log_result result = new Log_result();            {                msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;                msg = (org.apache.thrift.TBase) new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());            }            try {                fcall.sendResponse(fb, msg, msgType, seqid);                return;            } catch (Exception ex) {                LOGGER.error("Exception writing to internal frame buffer", ex);            }            fb.close();        }    };}
91cf233df61b3d41a104874b090a03df64338c069622842ae4800f52071a21c7
onComplete
public void onComplete(ResultCode o)
{    Log_result result = new Log_result();    result.success = o;    try {        fcall.sendResponse(fb, result, org.apache.thrift.protocol.TMessageType.REPLY, seqid);        return;    } catch (Exception e) {        LOGGER.error("Exception writing to internal frame buffer", e);    }    fb.close();}
50d81b3017874db254d9688aef6f4422ecef15f2cd874858a2f0d6437f81587e
onError
public void onError(Exception e)
{    byte msgType = org.apache.thrift.protocol.TMessageType.REPLY;    org.apache.thrift.TBase msg;    Log_result result = new Log_result();    {        msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;        msg = (org.apache.thrift.TBase) new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());    }    try {        fcall.sendResponse(fb, msg, msgType, seqid);        return;    } catch (Exception ex) {        LOGGER.error("Exception writing to internal frame buffer", ex);    }    fb.close();}
bebf296c86daa8f23132c9bae180b870c6dd9b8ba06fba8cc6695c835567cc77
isOneway
protected boolean isOneway()
{    return false;}
d89b6928cd48e6e727d9f7cef8bd049a892e769d28989aded2fced69c68b6bc8
start
public void start(I iface, Log_args args, org.apache.thrift.async.AsyncMethodCallback<ResultCode> resultHandler) throws TException
{    iface.Log(args.messages, resultHandler);}
92e9e6589c16b4fde1efd2a77a414bb3a621362cc64c5ef5a21381d0e5b55b5f
findByThriftId
public static _Fields findByThriftId(int fieldId)
{    switch(fieldId) {        case         1:            return MESSAGES;        default:            return null;    }}
950148827ecab1253536a12003b5b2c41c2778a566a9ed4cb2487de641d6bde4
findByThriftIdOrThrow
public static _Fields findByThriftIdOrThrow(int fieldId)
{    _Fields fields = findByThriftId(fieldId);    if (fields == null)        throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");    return fields;}
eb44b9fdf7e05046f232aa9f1f3bb9a0cf815a486270439682862994e0d2c224
findByName
public static _Fields findByName(String name)
{    return byName.get(name);}
7f8fa4ecb4119b59b8047c285ac8f8729a909f121d1d3386d19ebfc6c04ab5df
getThriftFieldId
public short getThriftFieldId()
{    return _thriftId;}
68f4afd0e3cff42097dd5b6508fea1f7952d6d93f52ded3c1deea7186fff780c
getFieldName
public String getFieldName()
{    return _fieldName;}
5ae72e885057da2a3245d2386634e644910c3ecc765c5bf0775fb1d8c82066e3
deepCopy
public Log_args deepCopy()
{    return new Log_args(this);}
21ac40bb9a99614b6ac18fa4043acb6173fccff96066fdfab963dba597923aa8
clear
public void clear()
{    this.messages = null;}
a7aa257ea0120590521f8835e2ac02913748667b92bbb7ce0c583fb8014546d7
getMessagesSize
public int getMessagesSize()
{    return (this.messages == null) ? 0 : this.messages.size();}
098b9085d8212c292c26d6e44ac51a78b1bb809a0eace9dc4f3edc7c1e671f00
getMessagesIterator
public java.util.Iterator<LogEntry> getMessagesIterator()
{    return (this.messages == null) ? null : this.messages.iterator();}
5f1a1cd9f62db939fea8dc59ee13afb3fad8736862c411521e61a49d21363bb2
addToMessages
public void addToMessages(LogEntry elem)
{    if (this.messages == null) {        this.messages = new ArrayList<LogEntry>();    }    this.messages.add(elem);}
5436d29f43d45af9d1a26f079382e679b684817b6bcf4dacd3ea1fb1ed782dd6
getMessages
public List<LogEntry> getMessages()
{    return this.messages;}
fc84e698f472447dd459d17d1a2a7c1369a991e8265d6d0c8f3361494c797cf1
setMessages
public Log_args setMessages(List<LogEntry> messages)
{    this.messages = messages;    return this;}
b37eb745c7d936e16f085cf361aafb4db2b1851885962b4f4400b337431298e1
unsetMessages
public void unsetMessages()
{    this.messages = null;}
19ce24315ea1574c3651e86b1115b7dc285586955ae925a9d54a2170fd9b8ad6
isSetMessages
public boolean isSetMessages()
{    return this.messages != null;}
bbce328dd879616c2d4e7ea004715b7eb5c2553ef86683e6ba11fab09fa16faf
setMessagesIsSet
public void setMessagesIsSet(boolean value)
{    if (!value) {        this.messages = null;    }}
56898e9e8fffee777f79916bb0318d8a0a1794f171b373787ede8ccabb314f39
setFieldValue
public void setFieldValue(_Fields field, Object value)
{    switch(field) {        case MESSAGES:            if (value == null) {                unsetMessages();            } else {                setMessages((List<LogEntry>) value);            }            break;    }}
464d81fc54c8c50a21a786b4dc4dd56822e73892271735c454cff15126bc2dfd
getFieldValue
public Object getFieldValue(_Fields field)
{    switch(field) {        case MESSAGES:            return getMessages();    }    throw new IllegalStateException();}
71ed64fc282e6b120c36448a4f95d0d8102f98c0455e5f84713743b2826d64c9
isSet
public boolean isSet(_Fields field)
{    if (field == null) {        throw new IllegalArgumentException();    }    switch(field) {        case MESSAGES:            return isSetMessages();    }    throw new IllegalStateException();}
6b3ab298cb5d88dbb2c510c786f53e377489a40e2716e63c26a3e1691765f6c5
equals
public boolean equals(Object that)
{    if (that == null)        return false;    if (that instanceof Log_args)        return this.equals((Log_args) that);    return false;}
d710b965a8e1f11527c85288dce3c4be19e9c9624cda63d7640abf23397e437e
equals
public boolean equals(Log_args that)
{    if (that == null)        return false;    boolean this_present_messages = true && this.isSetMessages();    boolean that_present_messages = true && that.isSetMessages();    if (this_present_messages || that_present_messages) {        if (!(this_present_messages && that_present_messages))            return false;        if (!this.messages.equals(that.messages))            return false;    }    return true;}
0ac42bf5188762fc1283b5cbd2b3bb1031e80963813b3b310b15c3fb47050003
hashCode
public int hashCode()
{    List<Object> list = new ArrayList<Object>();    boolean present_messages = true && (isSetMessages());    list.add(present_messages);    if (present_messages)        list.add(messages);    return list.hashCode();}
c64a778b56601d398aafb9b8389d2911a9c0658cb6529d31103859d50498346a
compareTo
public int compareTo(Log_args other)
{    if (!getClass().equals(other.getClass())) {        return getClass().getName().compareTo(other.getClass().getName());    }    int lastComparison = 0;    lastComparison = Boolean.valueOf(isSetMessages()).compareTo(other.isSetMessages());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetMessages()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.messages, other.messages);        if (lastComparison != 0) {            return lastComparison;        }    }    return 0;}
8ce4cec748163fe422fba58a0ef1f5936a95d5ce0ec9e530aab7c5a59149b857
fieldForId
public _Fields fieldForId(int fieldId)
{    return _Fields.findByThriftId(fieldId);}
9c387dbc68e2929966a2f4d7377de396c1c24932dd7e709eba5cf9e1c90787af
read
public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException
{    schemes.get(iprot.getScheme()).getScheme().read(iprot, this);}
72f9005ef45238c38f6c8b9506f41c8599609ccde331e03c7044ee080e1472da
write
public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException
{    schemes.get(oprot.getScheme()).getScheme().write(oprot, this);}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    StringBuilder sb = new StringBuilder("Log_args(");    boolean first = true;    sb.append("messages:");    if (this.messages == null) {        sb.append("null");    } else {        sb.append(this.messages);    }    first = false;    sb.append(")");    return sb.toString();}
e9a9838299550df368382cb18b6693a9d80b274b5c7bc089afc33713eceefbe1
validate
public void validate() throws org.apache.thrift.TException
{}
784e52bd99c637d4fd80e90272ace2edbc622a5a5ac2a515ab45f6d177fc378a
writeObject
private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException
{    try {        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
a2d949a3bc49af9f8b746197cee0585da9e196149570b4a376f3635b857a1744
readObject
private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException
{    try {        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
214872331b873c44102cbf05b44521dd3082ef10b4ef5aacc39096730e16a3ba
getScheme
public Log_argsStandardScheme getScheme()
{    return new Log_argsStandardScheme();}
5b9e2fa4c623f44da3d45f21b722661f6d5ea66699100f06bded07cdf945bc10
read
public void read(org.apache.thrift.protocol.TProtocol iprot, Log_args struct) throws org.apache.thrift.TException
{    org.apache.thrift.protocol.TField schemeField;    iprot.readStructBegin();    while (true) {        schemeField = iprot.readFieldBegin();        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) {            break;        }        switch(schemeField.id) {            case             1:                if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {                    {                        org.apache.thrift.protocol.TList _list0 = iprot.readListBegin();                        struct.messages = new ArrayList<LogEntry>(_list0.size);                        LogEntry _elem1;                        for (int _i2 = 0; _i2 < _list0.size; ++_i2) {                            _elem1 = new LogEntry();                            _elem1.read(iprot);                            struct.messages.add(_elem1);                        }                        iprot.readListEnd();                    }                    struct.setMessagesIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            default:                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);        }        iprot.readFieldEnd();    }    iprot.readStructEnd();        struct.validate();}
aee27b113f74b3e917087eccd2b324360c790e4b4c4b08402e0c4e61a4c5a799
write
public void write(org.apache.thrift.protocol.TProtocol oprot, Log_args struct) throws org.apache.thrift.TException
{    struct.validate();    oprot.writeStructBegin(STRUCT_DESC);    if (struct.messages != null) {        oprot.writeFieldBegin(MESSAGES_FIELD_DESC);        {            oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, struct.messages.size()));            for (LogEntry _iter3 : struct.messages) {                _iter3.write(oprot);            }            oprot.writeListEnd();        }        oprot.writeFieldEnd();    }    oprot.writeFieldStop();    oprot.writeStructEnd();}
41cdf75dc603ba5fc56478b8b4de39b7852598f13288a7629d2aa881e36a882c
getScheme
public Log_argsTupleScheme getScheme()
{    return new Log_argsTupleScheme();}
2593861b604432f257b2f49dabb3f004c810615c80b0f7331edbdc9c0a99c6bd
write
public void write(org.apache.thrift.protocol.TProtocol prot, Log_args struct) throws org.apache.thrift.TException
{    TTupleProtocol oprot = (TTupleProtocol) prot;    BitSet optionals = new BitSet();    if (struct.isSetMessages()) {        optionals.set(0);    }    oprot.writeBitSet(optionals, 1);    if (struct.isSetMessages()) {        {            oprot.writeI32(struct.messages.size());            for (LogEntry _iter4 : struct.messages) {                _iter4.write(oprot);            }        }    }}
1f3109abbf9331f53f6dfedeeec8f455c6585123e8088444ce4c19461ac10f19
read
public void read(org.apache.thrift.protocol.TProtocol prot, Log_args struct) throws org.apache.thrift.TException
{    TTupleProtocol iprot = (TTupleProtocol) prot;    BitSet incoming = iprot.readBitSet(1);    if (incoming.get(0)) {        {            org.apache.thrift.protocol.TList _list5 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());            struct.messages = new ArrayList<LogEntry>(_list5.size);            LogEntry _elem6;            for (int _i7 = 0; _i7 < _list5.size; ++_i7) {                _elem6 = new LogEntry();                _elem6.read(iprot);                struct.messages.add(_elem6);            }        }        struct.setMessagesIsSet(true);    }}
92e9e6589c16b4fde1efd2a77a414bb3a621362cc64c5ef5a21381d0e5b55b5f
findByThriftId
public static _Fields findByThriftId(int fieldId)
{    switch(fieldId) {        case         0:            return SUCCESS;        default:            return null;    }}
950148827ecab1253536a12003b5b2c41c2778a566a9ed4cb2487de641d6bde4
findByThriftIdOrThrow
public static _Fields findByThriftIdOrThrow(int fieldId)
{    _Fields fields = findByThriftId(fieldId);    if (fields == null)        throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");    return fields;}
eb44b9fdf7e05046f232aa9f1f3bb9a0cf815a486270439682862994e0d2c224
findByName
public static _Fields findByName(String name)
{    return byName.get(name);}
7f8fa4ecb4119b59b8047c285ac8f8729a909f121d1d3386d19ebfc6c04ab5df
getThriftFieldId
public short getThriftFieldId()
{    return _thriftId;}
68f4afd0e3cff42097dd5b6508fea1f7952d6d93f52ded3c1deea7186fff780c
getFieldName
public String getFieldName()
{    return _fieldName;}
f016ba2670f5558f8f5a3a3db7430fd4c586aad34b327bc5f1cb6d68248af4ea
deepCopy
public Log_result deepCopy()
{    return new Log_result(this);}
21ac40bb9a99614b6ac18fa4043acb6173fccff96066fdfab963dba597923aa8
clear
public void clear()
{    this.success = null;}
534b1b07ea37e552a80c4c5bddeaae976df3e7293ba73465d5d7af7f4dec0aad
getSuccess
public ResultCode getSuccess()
{    return this.success;}
bde1a19baf058ecf274397e1e3ddf7b748c05008dedea69caf9ffbdd94c5e345
setSuccess
public Log_result setSuccess(ResultCode success)
{    this.success = success;    return this;}
b11d50af86567118806a3c839311a4bbc691cc019f2b233dae1d90d66ba25d35
unsetSuccess
public void unsetSuccess()
{    this.success = null;}
94737a429af3ca2ae08f628bc393ecee61310b6ae56ecb9e65d11a0d4edf2fb9
isSetSuccess
public boolean isSetSuccess()
{    return this.success != null;}
ade9d0378b151827122f3a20ecdf75cbb0fad960c542ca429237092ddfa5078b
setSuccessIsSet
public void setSuccessIsSet(boolean value)
{    if (!value) {        this.success = null;    }}
56898e9e8fffee777f79916bb0318d8a0a1794f171b373787ede8ccabb314f39
setFieldValue
public void setFieldValue(_Fields field, Object value)
{    switch(field) {        case SUCCESS:            if (value == null) {                unsetSuccess();            } else {                setSuccess((ResultCode) value);            }            break;    }}
464d81fc54c8c50a21a786b4dc4dd56822e73892271735c454cff15126bc2dfd
getFieldValue
public Object getFieldValue(_Fields field)
{    switch(field) {        case SUCCESS:            return getSuccess();    }    throw new IllegalStateException();}
71ed64fc282e6b120c36448a4f95d0d8102f98c0455e5f84713743b2826d64c9
isSet
public boolean isSet(_Fields field)
{    if (field == null) {        throw new IllegalArgumentException();    }    switch(field) {        case SUCCESS:            return isSetSuccess();    }    throw new IllegalStateException();}
6b3ab298cb5d88dbb2c510c786f53e377489a40e2716e63c26a3e1691765f6c5
equals
public boolean equals(Object that)
{    if (that == null)        return false;    if (that instanceof Log_result)        return this.equals((Log_result) that);    return false;}
837a6b467459f3dc99f40bcff01c7b7aeca181fca946c033b5c82fcdb46a33c4
equals
public boolean equals(Log_result that)
{    if (that == null)        return false;    boolean this_present_success = true && this.isSetSuccess();    boolean that_present_success = true && that.isSetSuccess();    if (this_present_success || that_present_success) {        if (!(this_present_success && that_present_success))            return false;        if (!this.success.equals(that.success))            return false;    }    return true;}
0ac42bf5188762fc1283b5cbd2b3bb1031e80963813b3b310b15c3fb47050003
hashCode
public int hashCode()
{    List<Object> list = new ArrayList<Object>();    boolean present_success = true && (isSetSuccess());    list.add(present_success);    if (present_success)        list.add(success.getValue());    return list.hashCode();}
28003c9548a884acfca10a7eef992e477ef1b23edb006e609797f7da22301e98
compareTo
public int compareTo(Log_result other)
{    if (!getClass().equals(other.getClass())) {        return getClass().getName().compareTo(other.getClass().getName());    }    int lastComparison = 0;    lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(other.isSetSuccess());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetSuccess()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.success, other.success);        if (lastComparison != 0) {            return lastComparison;        }    }    return 0;}
8ce4cec748163fe422fba58a0ef1f5936a95d5ce0ec9e530aab7c5a59149b857
fieldForId
public _Fields fieldForId(int fieldId)
{    return _Fields.findByThriftId(fieldId);}
9c387dbc68e2929966a2f4d7377de396c1c24932dd7e709eba5cf9e1c90787af
read
public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException
{    schemes.get(iprot.getScheme()).getScheme().read(iprot, this);}
72f9005ef45238c38f6c8b9506f41c8599609ccde331e03c7044ee080e1472da
write
public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException
{    schemes.get(oprot.getScheme()).getScheme().write(oprot, this);}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    StringBuilder sb = new StringBuilder("Log_result(");    boolean first = true;    sb.append("success:");    if (this.success == null) {        sb.append("null");    } else {        sb.append(this.success);    }    first = false;    sb.append(")");    return sb.toString();}
e9a9838299550df368382cb18b6693a9d80b274b5c7bc089afc33713eceefbe1
validate
public void validate() throws org.apache.thrift.TException
{}
784e52bd99c637d4fd80e90272ace2edbc622a5a5ac2a515ab45f6d177fc378a
writeObject
private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException
{    try {        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
a2d949a3bc49af9f8b746197cee0585da9e196149570b4a376f3635b857a1744
readObject
private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException
{    try {        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
446d334943e9134028008da75dd728abf9dea8d27564ca237256d696faf4802e
getScheme
public Log_resultStandardScheme getScheme()
{    return new Log_resultStandardScheme();}
fbf150af2efe43a2f07b04ae686e8a8ab27966088e6aa36e56360e3b82746e89
read
public void read(org.apache.thrift.protocol.TProtocol iprot, Log_result struct) throws org.apache.thrift.TException
{    org.apache.thrift.protocol.TField schemeField;    iprot.readStructBegin();    while (true) {        schemeField = iprot.readFieldBegin();        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) {            break;        }        switch(schemeField.id) {            case             0:                if (schemeField.type == org.apache.thrift.protocol.TType.I32) {                    struct.success = org.apache.flume.source.scribe.ResultCode.findByValue(iprot.readI32());                    struct.setSuccessIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            default:                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);        }        iprot.readFieldEnd();    }    iprot.readStructEnd();        struct.validate();}
b7207b236760167c8b53d13f7475e25ae5b07680093540b7cfcc34ea4c3c956b
write
public void write(org.apache.thrift.protocol.TProtocol oprot, Log_result struct) throws org.apache.thrift.TException
{    struct.validate();    oprot.writeStructBegin(STRUCT_DESC);    if (struct.success != null) {        oprot.writeFieldBegin(SUCCESS_FIELD_DESC);        oprot.writeI32(struct.success.getValue());        oprot.writeFieldEnd();    }    oprot.writeFieldStop();    oprot.writeStructEnd();}
a2049f0882a4116d97e13c05fde20e5a8d0d86f43682e44e34b88f130294cb28
getScheme
public Log_resultTupleScheme getScheme()
{    return new Log_resultTupleScheme();}
ab93743777e2868260adefb2d4f1b5ab85bdcbdf03caf71a6b40d80d588efee9
write
public void write(org.apache.thrift.protocol.TProtocol prot, Log_result struct) throws org.apache.thrift.TException
{    TTupleProtocol oprot = (TTupleProtocol) prot;    BitSet optionals = new BitSet();    if (struct.isSetSuccess()) {        optionals.set(0);    }    oprot.writeBitSet(optionals, 1);    if (struct.isSetSuccess()) {        oprot.writeI32(struct.success.getValue());    }}
d46ed68ab60ceff4c4a5afa55a09fdeb3a269d6a3d0a3c2fd8fea5643201fce4
read
public void read(org.apache.thrift.protocol.TProtocol prot, Log_result struct) throws org.apache.thrift.TException
{    TTupleProtocol iprot = (TTupleProtocol) prot;    BitSet incoming = iprot.readBitSet(1);    if (incoming.get(0)) {        struct.success = org.apache.flume.source.scribe.ResultCode.findByValue(iprot.readI32());        struct.setSuccessIsSet(true);    }}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    port = context.getInteger("port", DEFAULT_PORT);    maxReadBufferBytes = context.getInteger("maxReadBufferBytes", DEFAULT_MAX_READ_BUFFER_BYTES);    if (maxReadBufferBytes <= 0) {        maxReadBufferBytes = DEFAULT_MAX_READ_BUFFER_BYTES;    }    workers = context.getInteger("workerThreads", DEFAULT_WORKERS);    if (workers <= 0) {        workers = DEFAULT_WORKERS;    }    if (sourceCounter == null) {        sourceCounter = new SourceCounter(getName());    }}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    try {        Scribe.Processor processor = new Scribe.Processor(new Receiver());        TNonblockingServerTransport transport = new TNonblockingServerSocket(port);        THsHaServer.Args args = new THsHaServer.Args(transport);        args.minWorkerThreads(workers);        args.maxWorkerThreads(workers);        args.processor(processor);        args.transportFactory(new TFramedTransport.Factory(maxReadBufferBytes));        args.protocolFactory(new TBinaryProtocol.Factory(false, false));        args.maxReadBufferBytes = maxReadBufferBytes;        server = new THsHaServer(args);        LOG.info("Starting Scribe Source on port " + port);        server.serve();    } catch (Exception e) {        LOG.warn("Scribe failed", e);    }}
fe470100a468aa20bc462dab09f768d6e2ce225f184a550d87d7243e3d0f5667
start
public void start()
{    Startup startupThread = new Startup();    startupThread.start();    try {        Thread.sleep(3000);    } catch (InterruptedException e) {    }    if (!server.isServing()) {        throw new IllegalStateException("Failed initialization of ScribeSource");    }    sourceCounter.start();    super.start();}
4e5c4125627f8fae3fcb8fa1c2fa25ff160d3eec452770c97bbb601a580fe141
stop
public void stop()
{    LOG.info("Scribe source stopping");    if (server != null) {        server.stop();    }    sourceCounter.stop();    super.stop();    LOG.info("Scribe source stopped. Metrics:{}", sourceCounter);}
98c1ce6818da0f5db59f96dfea12d82212bb25b78fe09cd576e9ce86c13d4d5a
Log
public ResultCode Log(List<LogEntry> list) throws TException
{    if (list != null) {        sourceCounter.addToEventReceivedCount(list.size());        try {            List<Event> events = new ArrayList<Event>(list.size());            for (LogEntry entry : list) {                Map<String, String> headers = new HashMap<String, String>(1, 1);                String category = entry.getCategory();                if (category != null) {                    headers.put(SCRIBE_CATEGORY, category);                }                Event event = EventBuilder.withBody(entry.getMessage().getBytes(), headers);                events.add(event);            }            if (events.size() > 0) {                getChannelProcessor().processEventBatch(events);            }            sourceCounter.addToEventAcceptedCount(list.size());            return ResultCode.OK;        } catch (Exception e) {            LOG.warn("Scribe source handling failure", e);            sourceCounter.incrementEventReadOrChannelFail(e);        }    }    return ResultCode.TRY_LATER;}
4d072973845457c68e0bdcaf8605a63c4e82cee51aa51c4f7db0b2f7a2d3a532
findFreePort
private static int findFreePort() throws IOException
{    ServerSocket socket = new ServerSocket(0);    int port = socket.getLocalPort();    socket.close();    return port;}
7f0f73b325bcd37632c396c02bb87ddfe4bb9da1a35fac272192ae84740eb688
setUpClass
public static void setUpClass() throws Exception
{    port = findFreePort();    Context context = new Context();    context.put("port", String.valueOf(port));    scribeSource = new ScribeSource();    scribeSource.setName("Scribe Source");    Configurables.configure(scribeSource, context);    memoryChannel = new MemoryChannel();    Configurables.configure(memoryChannel, context);    List<Channel> channels = new ArrayList<Channel>(1);    channels.add(memoryChannel);    ChannelSelector rcs = new ReplicatingChannelSelector();    rcs.setChannels(channels);    memoryChannel.start();    scribeSource.setChannelProcessor(new ChannelProcessor(rcs));    scribeSource.start();}
66846889942e7095d3461e8df89f21f48b99aa3cf60993184e69d061298e401c
sendSingle
private void sendSingle() throws org.apache.thrift.TException
{    TTransport transport = new TFramedTransport(new TSocket("localhost", port));    TProtocol protocol = new TBinaryProtocol(transport);    Scribe.Client client = new Scribe.Client(protocol);    transport.open();    LogEntry logEntry = new LogEntry("INFO", "Sending info msg to scribe source");    List<LogEntry> logEntries = new ArrayList<LogEntry>(1);    logEntries.add(logEntry);    client.Log(logEntries);}
957dcf4585308440a14d6603dbb7af8403b246bae881d48d5d906acef3d1e578
testScribeMessage
public void testScribeMessage() throws Exception
{    sendSingle();        Transaction tx = memoryChannel.getTransaction();    tx.begin();    Event e = memoryChannel.take();    Assert.assertNotNull(e);    Assert.assertEquals("Sending info msg to scribe source", new String(e.getBody()));    tx.commit();    tx.close();}
035776ba733f45298c824de1017f12e6cc46c1262376bb1c94e226152ada56e8
testScribeMultipleMessages
public void testScribeMultipleMessages() throws Exception
{    TTransport transport = new TFramedTransport(new TSocket("localhost", port));    TProtocol protocol = new TBinaryProtocol(transport);    Scribe.Client client = new Scribe.Client(protocol);    transport.open();    List<LogEntry> logEntries = new ArrayList<LogEntry>(10);    for (int i = 0; i < 10; i++) {        LogEntry logEntry = new LogEntry("INFO", String.format("Sending info msg# %d to scribe source", i));        logEntries.add(logEntry);    }    client.Log(logEntries);        Transaction tx = memoryChannel.getTransaction();    tx.begin();    for (int i = 0; i < 10; i++) {        Event e = memoryChannel.take();        Assert.assertNotNull(e);        Assert.assertEquals(String.format("Sending info msg# %d to scribe source", i), new String(e.getBody()));    }    tx.commit();    tx.close();}
799d52b0b8f2228a73f8f5f35d6cec3937029922705a37d30db2fb4c43d8d744
testErrorCounter
public void testErrorCounter() throws Exception
{    ChannelProcessor cp = mock(ChannelProcessor.class);    doThrow(new ChannelException("dummy")).when(cp).processEventBatch(anyListOf(Event.class));    ChannelProcessor origCp = scribeSource.getChannelProcessor();    scribeSource.setChannelProcessor(cp);    sendSingle();    scribeSource.setChannelProcessor(origCp);    SourceCounter sc = (SourceCounter) Whitebox.getInternalState(scribeSource, "sourceCounter");    org.junit.Assert.assertEquals(1, sc.getChannelWriteFail());}
6a5ea8b0a96f10849d9ee4bf738dcf31f9bf401b5bf72e2586c3485ffaed0e38
cleanup
public static void cleanup()
{    memoryChannel.stop();    scribeSource.stop();}
d003012c4c2319f11da05c24dc16625ebb90c8d3d4f6f4461e693c6356897ead
loadPositionFile
public void loadPositionFile(String filePath)
{    Long inode, pos;    String path;    FileReader fr = null;    JsonReader jr = null;    try {        fr = new FileReader(filePath);        jr = new JsonReader(fr);        jr.beginArray();        while (jr.hasNext()) {            inode = null;            pos = null;            path = null;            jr.beginObject();            while (jr.hasNext()) {                switch(jr.nextName()) {                    case "inode":                        inode = jr.nextLong();                        break;                    case "pos":                        pos = jr.nextLong();                        break;                    case "file":                        path = jr.nextString();                        break;                }            }            jr.endObject();            for (Object v : Arrays.asList(inode, pos, path)) {                Preconditions.checkNotNull(v, "Detected missing value in position file. " + "inode: " + inode + ", pos: " + pos + ", path: " + path);            }            TailFile tf = tailFiles.get(inode);            if (tf != null && tf.updatePos(path, inode, pos)) {                tailFiles.put(inode, tf);            } else {                logger.info("Missing file: " + path + ", inode: " + inode + ", pos: " + pos);            }        }        jr.endArray();    } catch (FileNotFoundException e) {        logger.info("File not found: " + filePath + ", not updating position");    } catch (IOException e) {        logger.error("Failed loading positionFile: " + filePath, e);    } finally {        try {            if (fr != null)                fr.close();            if (jr != null)                jr.close();        } catch (IOException e) {            logger.error("Error: " + e.getMessage(), e);        }    }}
aa0cda15934da1d4fbbe41b3f96675d252754bf95fe2aa75e850d23547646267
getTailFiles
public Map<Long, TailFile> getTailFiles()
{    return tailFiles;}
1b0465d8c8599e90754c593ac3aaeb62341011551cb9c44ed9ccb34591ae1cf6
setCurrentFile
public void setCurrentFile(TailFile currentFile)
{    this.currentFile = currentFile;}
faacd45ce21d1cbb584374a868166f2921664ee3631184fbc58c2a737d41fefb
readEvent
public Event readEvent() throws IOException
{    List<Event> events = readEvents(1);    if (events.isEmpty()) {        return null;    }    return events.get(0);}
54fb38a1d197eddb2b60ecdecace63039e95c1beccdbf2a178d1f6dbdaf9e966
readEvents
public List<Event> readEvents(int numEvents) throws IOException
{    return readEvents(numEvents, false);}
5f63bb24e4619ecc697de5cbb69ba124df1227fc6914cf93997bf490960a9d05
readEvents
public List<Event> readEvents(TailFile tf, int numEvents) throws IOException
{    setCurrentFile(tf);    return readEvents(numEvents, true);}
32b7d4300e7e146b65671ebbcc3da1e01fc3cd3fa2b8f4f4090973d6422e30e7
readEvents
public List<Event> readEvents(int numEvents, boolean backoffWithoutNL) throws IOException
{    if (!committed) {        if (currentFile == null) {            throw new IllegalStateException("current file does not exist. " + currentFile.getPath());        }        logger.info("Last read was never committed - resetting position");        long lastPos = currentFile.getPos();        currentFile.updateFilePos(lastPos);    }    List<Event> events = currentFile.readEvents(numEvents, backoffWithoutNL, addByteOffset);    if (events.isEmpty()) {        return events;    }    Map<String, String> headers = currentFile.getHeaders();    if (annotateFileName || (headers != null && !headers.isEmpty())) {        for (Event event : events) {            if (headers != null && !headers.isEmpty()) {                event.getHeaders().putAll(headers);            }            if (annotateFileName) {                event.getHeaders().put(fileNameHeader, currentFile.getPath());            }        }    }    committed = false;    return events;}
e0823f55b3a09d41a3e1e792f7e6687db9199c2db9b29e9922d93cbdc6f1284b
close
public void close() throws IOException
{    for (TailFile tf : tailFiles.values()) {        if (tf.getRaf() != null)            tf.getRaf().close();    }}
9686b51f14ae68fc049f472c7635d5385053dc8384dae21aaed20cdf86644fa0
commit
public void commit() throws IOException
{    if (!committed && currentFile != null) {        long pos = currentFile.getLineReadPos();        currentFile.setPos(pos);        currentFile.setLastUpdated(updateTime);        committed = true;    }}
864d36fbcb51f11c441d6048e51eea752184778f95c2a5861135d7aee9c63623
updateTailFiles
public List<Long> updateTailFiles(boolean skipToEnd) throws IOException
{    updateTime = System.currentTimeMillis();    List<Long> updatedInodes = Lists.newArrayList();    for (TaildirMatcher taildir : taildirCache) {        Map<String, String> headers = headerTable.row(taildir.getFileGroup());        for (File f : taildir.getMatchingFiles()) {            long inode;            try {                inode = getInode(f);            } catch (NoSuchFileException e) {                logger.info("File has been deleted in the meantime: " + e.getMessage());                continue;            }            TailFile tf = tailFiles.get(inode);            if (tf == null || !tf.getPath().equals(f.getAbsolutePath())) {                long startPos = skipToEnd ? f.length() : 0;                tf = openFile(f, headers, inode, startPos);            } else {                boolean updated = tf.getLastUpdated() < f.lastModified() || tf.getPos() != f.length();                if (updated) {                    if (tf.getRaf() == null) {                        tf = openFile(f, headers, inode, tf.getPos());                    }                    if (f.length() < tf.getPos()) {                        logger.info("Pos " + tf.getPos() + " is larger than file size! " + "Restarting from pos 0, file: " + tf.getPath() + ", inode: " + inode);                        tf.updatePos(tf.getPath(), inode, 0);                    }                }                tf.setNeedTail(updated);            }            tailFiles.put(inode, tf);            updatedInodes.add(inode);        }    }    return updatedInodes;}
fec426356c641a719ccff46badefd124f660481a37f8aed1496ba7fe7553f26b
updateTailFiles
public List<Long> updateTailFiles() throws IOException
{    return updateTailFiles(false);}
4f3b7645599f3f91b381c16d1a9b5ae32f7f4e8c574d991f6aa42bb211865145
getInode
private long getInode(File file) throws IOException
{    long inode = (long) Files.getAttribute(file.toPath(), "unix:ino");    return inode;}
270940c6845b6bf98bf0ed352975569dda5f3bb61e589e4735b553290017a877
openFile
private TailFile openFile(File file, Map<String, String> headers, long inode, long pos)
{    try {        logger.info("Opening file: " + file + ", inode: " + inode + ", pos: " + pos);        return new TailFile(file, headers, inode, pos);    } catch (IOException e) {        throw new FlumeException("Failed opening file: " + file, e);    }}
06d1633e842ef407fdb310f9015a44a3de353ebc77d92b4e6760960e7fcac719
filePaths
public Builder filePaths(Map<String, String> filePaths)
{    this.filePaths = filePaths;    return this;}
3a6cd73148978e5272a2eb789776c741b4611f4e91de54313be5229a08d4cefc
headerTable
public Builder headerTable(Table<String, String, String> headerTable)
{    this.headerTable = headerTable;    return this;}
1a279437244168614b130eb36c5649b1f9a8bef3761d8269f65aaa6859fbcea9
positionFilePath
public Builder positionFilePath(String positionFilePath)
{    this.positionFilePath = positionFilePath;    return this;}
9bff8e16f0b36cba488a106f78f0c5dce1fd595ccbbe331ead8e225557156109
skipToEnd
public Builder skipToEnd(boolean skipToEnd)
{    this.skipToEnd = skipToEnd;    return this;}
9c865c501e9621b6fe395a848325bd1aa11f0b6fa1d587430069ae551680bf98
addByteOffset
public Builder addByteOffset(boolean addByteOffset)
{    this.addByteOffset = addByteOffset;    return this;}
0c242b8b53d69ef924fd0ae1a278131a4a9756f9a74c57fcec43562141f91b98
cachePatternMatching
public Builder cachePatternMatching(boolean cachePatternMatching)
{    this.cachePatternMatching = cachePatternMatching;    return this;}
ed137c8d103a806216f89c9d48b6a2b762da0449a672ea611940e38f0062660d
annotateFileName
public Builder annotateFileName(boolean annotateFileName)
{    this.annotateFileName = annotateFileName;    return this;}
53247e4bffb761586708fd2345c8c0bc70564feb02006216a5af0c09d165a476
fileNameHeader
public Builder fileNameHeader(String fileNameHeader)
{    this.fileNameHeader = fileNameHeader;    return this;}
072d15fe6b26e5c66c7dccc9524415a249022148dd2df167aae578c538ba3c03
build
public ReliableTaildirEventReader build() throws IOException
{    return new ReliableTaildirEventReader(filePaths, headerTable, positionFilePath, skipToEnd, addByteOffset, cachePatternMatching, annotateFileName, fileNameHeader);}
455b39278ca02c72fdc0a48df8c95c4fb0d3bbe32ff962b302c56fd584cabca4
accept
public boolean accept(Path entry) throws IOException
{    return matcher.matches(entry.getFileName()) && !Files.isDirectory(entry);}
4b8c924e08b3e6104f9da583261554d9dc8e3b44e4f2a0529752adf8e8fc5755
getMatchingFiles
 List<File> getMatchingFiles()
{    long now = TimeUnit.SECONDS.toMillis(TimeUnit.MILLISECONDS.toSeconds(System.currentTimeMillis()));    long currentParentDirMTime = parentDir.lastModified();    List<File> result;        if (!cachePatternMatching || lastSeenParentDirMTime < currentParentDirMTime || !(currentParentDirMTime < lastCheckedTime)) {        lastMatchedFiles = sortByLastModifiedTime(getMatchingFilesNoCache());        lastSeenParentDirMTime = currentParentDirMTime;        lastCheckedTime = now;    }    return lastMatchedFiles;}
c1fa47b1188a0d5dd2685ea20be367caceb8e73bf8cfa38f7a9cfe4adf8a8b98
getMatchingFilesNoCache
private List<File> getMatchingFilesNoCache()
{    List<File> result = Lists.newArrayList();    try (DirectoryStream<Path> stream = Files.newDirectoryStream(parentDir.toPath(), fileFilter)) {        for (Path entry : stream) {            result.add(entry.toFile());        }    } catch (IOException e) {        logger.error("I/O exception occurred while listing parent directory. " + "Files already matched will be returned. " + parentDir.toPath(), e);    }    return result;}
197988d3cd37171fc4961f029fc9331ef3c6758452c85e15137deab7862f4cfd
sortByLastModifiedTime
private static List<File> sortByLastModifiedTime(List<File> files)
{    final HashMap<File, Long> lastModificationTimes = new HashMap<File, Long>(files.size());    for (File f : files) {        lastModificationTimes.put(f, f.lastModified());    }    Collections.sort(files, new Comparator<File>() {        @Override        public int compare(File o1, File o2) {            return lastModificationTimes.get(o1).compareTo(lastModificationTimes.get(o2));        }    });    return files;}
6839c12feb29f4c058a4da429666bc9c963be53674393df89ab6de5e2d15ad6b
compare
public int compare(File o1, File o2)
{    return lastModificationTimes.get(o1).compareTo(lastModificationTimes.get(o2));}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return "{" + "filegroup='" + fileGroup + '\'' + ", filePattern='" + filePattern + '\'' + ", cached=" + cachePatternMatching + '}';}
8d37d11c7ecfc0d0589696a89cb385888c83bd3e43ea0c95a3b4ae4ef78180ce
equals
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    TaildirMatcher that = (TaildirMatcher) o;    return fileGroup.equals(that.fileGroup);}
0ac42bf5188762fc1283b5cbd2b3bb1031e80963813b3b310b15c3fb47050003
hashCode
public int hashCode()
{    return fileGroup.hashCode();}
f8692446dfd58403723e282f1329b348ddad3f1b3a6103d480e52043c1d18c48
getFileGroup
public String getFileGroup()
{    return fileGroup;}
5b05914888e421f26bff6f39231facdd35759f746a9af780ebac2cf5b2c81932
start
public synchronized void start()
{    logger.info("{} TaildirSource source starting with directory: {}", getName(), filePaths);    try {        reader = new ReliableTaildirEventReader.Builder().filePaths(filePaths).headerTable(headerTable).positionFilePath(positionFilePath).skipToEnd(skipToEnd).addByteOffset(byteOffsetHeader).cachePatternMatching(cachePatternMatching).annotateFileName(fileHeader).fileNameHeader(fileHeaderKey).build();    } catch (IOException e) {        throw new FlumeException("Error instantiating ReliableTaildirEventReader", e);    }    idleFileChecker = Executors.newSingleThreadScheduledExecutor(new ThreadFactoryBuilder().setNameFormat("idleFileChecker").build());    idleFileChecker.scheduleWithFixedDelay(new idleFileCheckerRunnable(), idleTimeout, checkIdleInterval, TimeUnit.MILLISECONDS);    positionWriter = Executors.newSingleThreadScheduledExecutor(new ThreadFactoryBuilder().setNameFormat("positionWriter").build());    positionWriter.scheduleWithFixedDelay(new PositionWriterRunnable(), writePosInitDelay, writePosInterval, TimeUnit.MILLISECONDS);    super.start();    logger.debug("TaildirSource started");    sourceCounter.start();}
06e1ddba8663c90da407ac517f29ed70555cfe57b0332c9a96e7c696e0255364
stop
public synchronized void stop()
{    try {        super.stop();        ExecutorService[] services = { idleFileChecker, positionWriter };        for (ExecutorService service : services) {            service.shutdown();            if (!service.awaitTermination(1, TimeUnit.SECONDS)) {                service.shutdownNow();            }        }                writePosition();        reader.close();    } catch (InterruptedException e) {        logger.info("Interrupted while awaiting termination", e);    } catch (IOException e) {        logger.info("Failed: " + e.getMessage(), e);    }    sourceCounter.stop();    logger.info("Taildir source {} stopped. Metrics: {}", getName(), sourceCounter);}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return String.format("Taildir source: { positionFile: %s, skipToEnd: %s, " + "byteOffsetHeader: %s, idleTimeout: %s, writePosInterval: %s }", positionFilePath, skipToEnd, byteOffsetHeader, idleTimeout, writePosInterval);}
a2af24a400c0da4ba99526694f737263b89979f4f1b86b18d58f395203b06daa
configure
public synchronized void configure(Context context)
{    String fileGroups = context.getString(FILE_GROUPS);    Preconditions.checkState(fileGroups != null, "Missing param: " + FILE_GROUPS);    filePaths = selectByKeys(context.getSubProperties(FILE_GROUPS_PREFIX), fileGroups.split("\\s+"));    Preconditions.checkState(!filePaths.isEmpty(), "Mapping for tailing files is empty or invalid: '" + FILE_GROUPS_PREFIX + "'");    String homePath = System.getProperty("user.home").replace('\\', '/');    positionFilePath = context.getString(POSITION_FILE, homePath + DEFAULT_POSITION_FILE);    Path positionFile = Paths.get(positionFilePath);    try {        Files.createDirectories(positionFile.getParent());    } catch (IOException e) {        throw new FlumeException("Error creating positionFile parent directories", e);    }    headerTable = getTable(context, HEADERS_PREFIX);    batchSize = context.getInteger(BATCH_SIZE, DEFAULT_BATCH_SIZE);    skipToEnd = context.getBoolean(SKIP_TO_END, DEFAULT_SKIP_TO_END);    byteOffsetHeader = context.getBoolean(BYTE_OFFSET_HEADER, DEFAULT_BYTE_OFFSET_HEADER);    idleTimeout = context.getInteger(IDLE_TIMEOUT, DEFAULT_IDLE_TIMEOUT);    writePosInterval = context.getInteger(WRITE_POS_INTERVAL, DEFAULT_WRITE_POS_INTERVAL);    cachePatternMatching = context.getBoolean(CACHE_PATTERN_MATCHING, DEFAULT_CACHE_PATTERN_MATCHING);    backoffSleepIncrement = context.getLong(PollableSourceConstants.BACKOFF_SLEEP_INCREMENT, PollableSourceConstants.DEFAULT_BACKOFF_SLEEP_INCREMENT);    maxBackOffSleepInterval = context.getLong(PollableSourceConstants.MAX_BACKOFF_SLEEP, PollableSourceConstants.DEFAULT_MAX_BACKOFF_SLEEP);    fileHeader = context.getBoolean(FILENAME_HEADER, DEFAULT_FILE_HEADER);    fileHeaderKey = context.getString(FILENAME_HEADER_KEY, DEFAULT_FILENAME_HEADER_KEY);    maxBatchCount = context.getLong(MAX_BATCH_COUNT, DEFAULT_MAX_BATCH_COUNT);    if (maxBatchCount <= 0) {        maxBatchCount = DEFAULT_MAX_BATCH_COUNT;        logger.warn("Invalid maxBatchCount specified, initializing source " + "default maxBatchCount of {}", maxBatchCount);    }    if (sourceCounter == null) {        sourceCounter = new SourceCounter(getName());    }}
dcc511f35190533c2d6fcc6073d66b12e111f5004c64ff08ccc3609a06ab844d
getBatchSize
public long getBatchSize()
{    return batchSize;}
49bb38f4c50dbeece08e08567cd932ae9401c4293054e68c76961866505ea1b8
selectByKeys
private Map<String, String> selectByKeys(Map<String, String> map, String[] keys)
{    Map<String, String> result = Maps.newHashMap();    for (String key : keys) {        if (map.containsKey(key)) {            result.put(key, map.get(key));        }    }    return result;}
39b348c39a3b1da7873387fcf4e0457520900f8c61d4379b46da95640d0593b3
getTable
private Table<String, String, String> getTable(Context context, String prefix)
{    Table<String, String, String> table = HashBasedTable.create();    for (Entry<String, String> e : context.getSubProperties(prefix).entrySet()) {        String[] parts = e.getKey().split("\\.", 2);        table.put(parts[0], parts[1], e.getValue());    }    return table;}
b05ca35750b98c4eff8ae76009aba8e2bbea887f602a6883787de337ec3f4cef
getSourceCounter
protected SourceCounter getSourceCounter()
{    return sourceCounter;}
a807961d253ba1577729173c133e7049727da1b31814e2335bed0426bb75739d
process
public Status process()
{    Status status = Status.BACKOFF;    try {        existingInodes.clear();        existingInodes.addAll(reader.updateTailFiles());        for (long inode : existingInodes) {            TailFile tf = reader.getTailFiles().get(inode);            if (tf.needTail()) {                boolean hasMoreLines = tailFileProcess(tf, true);                if (hasMoreLines) {                    status = Status.READY;                }            }        }        closeTailFiles();    } catch (Throwable t) {        logger.error("Unable to tail files", t);        sourceCounter.incrementEventReadFail();        status = Status.BACKOFF;    }    return status;}
0c2bf215960a91e6d67dc2ecb6d4080c5643555055eb51cae826ed4203acda99
getBackOffSleepIncrement
public long getBackOffSleepIncrement()
{    return backoffSleepIncrement;}
09defa6fbcbcba505a3608243e14bdec0cc8c0e18b7feec629a8be8d48285381
getMaxBackOffSleepInterval
public long getMaxBackOffSleepInterval()
{    return maxBackOffSleepInterval;}
a0754086736e147a3bad7b0db30142caf4450d1b7ec83a5a957238498d9d55f7
tailFileProcess
private boolean tailFileProcess(TailFile tf, boolean backoffWithoutNL) throws IOException, InterruptedException
{    long batchCount = 0;    while (true) {        reader.setCurrentFile(tf);        List<Event> events = reader.readEvents(batchSize, backoffWithoutNL);        if (events.isEmpty()) {            return false;        }        sourceCounter.addToEventReceivedCount(events.size());        sourceCounter.incrementAppendBatchReceivedCount();        try {            getChannelProcessor().processEventBatch(events);            reader.commit();        } catch (ChannelException ex) {            logger.warn("The channel is full or unexpected failure. " + "The source will try again after " + retryInterval + " ms");            sourceCounter.incrementChannelWriteFail();            TimeUnit.MILLISECONDS.sleep(retryInterval);            retryInterval = retryInterval << 1;            retryInterval = Math.min(retryInterval, maxRetryInterval);            continue;        }        retryInterval = 1000;        sourceCounter.addToEventAcceptedCount(events.size());        sourceCounter.incrementAppendBatchAcceptedCount();        if (events.size() < batchSize) {            logger.debug("The events taken from " + tf.getPath() + " is less than " + batchSize);            return false;        }        if (++batchCount >= maxBatchCount) {            logger.debug("The batches read from the same file is larger than " + maxBatchCount);            return true;        }    }}
7fdb98ed960d38a5049defd978300eada77c59a4a9b8708bb48b8f592898a835
closeTailFiles
private void closeTailFiles() throws IOException, InterruptedException
{    for (long inode : idleInodes) {        TailFile tf = reader.getTailFiles().get(inode);        if (tf.getRaf() != null) {                        tailFileProcess(tf, false);            tf.close();            logger.info("Closed file: " + tf.getPath() + ", inode: " + inode + ", pos: " + tf.getPos());        }    }    idleInodes.clear();}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    try {        long now = System.currentTimeMillis();        for (TailFile tf : reader.getTailFiles().values()) {            if (tf.getLastUpdated() + idleTimeout < now && tf.getRaf() != null) {                idleInodes.add(tf.getInode());            }        }    } catch (Throwable t) {        logger.error("Uncaught exception in IdleFileChecker thread", t);        sourceCounter.incrementGenericProcessingFail();    }}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    writePosition();}
0f96babcd740d1ca402e6a0805b39fb2ae6e2d4e63600dac2ec32353ca54bd4a
writePosition
private void writePosition()
{    File file = new File(positionFilePath);    FileWriter writer = null;    try {        writer = new FileWriter(file);        if (!existingInodes.isEmpty()) {            String json = toPosInfoJson();            writer.write(json);        }    } catch (Throwable t) {        logger.error("Failed writing positionFile", t);        sourceCounter.incrementGenericProcessingFail();    } finally {        try {            if (writer != null)                writer.close();        } catch (IOException e) {            logger.error("Error: " + e.getMessage(), e);            sourceCounter.incrementGenericProcessingFail();        }    }}
a5a64f44485c42871f0bf950a018085260e7e2d142ae81abb35633090c8bf24b
toPosInfoJson
private String toPosInfoJson()
{    @SuppressWarnings("rawtypes")    List<Map> posInfos = Lists.newArrayList();    for (Long inode : existingInodes) {        TailFile tf = reader.getTailFiles().get(inode);        posInfos.add(ImmutableMap.of("inode", inode, "pos", tf.getPos(), "file", tf.getPath()));    }    return new Gson().toJson(posInfos);}
01ad2b0fa174658caf7b096cb57168c9f45530254eb733685e3066bf20afef9b
getRaf
public RandomAccessFile getRaf()
{    return raf;}
58e7b527ecd5014eaf5f30fc9c50ba33e1f005f8ce9d24246253d62377788662
getPath
public String getPath()
{    return path;}
b253f63fa1bd81241984e2b334bb8924786f0eaa3fbecc99584fe0d661609fd9
getInode
public long getInode()
{    return inode;}
85c9e8103213800a008e1513fd902875fca6ec188d881a20c3f992c4f66c2d87
getPos
public long getPos()
{    return pos;}
59642834210b810e5b75c031a2c85e59551d73940beeb3bd9c08e2093cbf164b
getLastUpdated
public long getLastUpdated()
{    return lastUpdated;}
1b253a950191ef104d08f0a2b8700d122ab2559c67da59b1da75cbe727cda654
needTail
public boolean needTail()
{    return needTail;}
9a691e59a635186c5f7258710b8e44f5caf3510a02999c2c0ea95c8238b813ad
getHeaders
public Map<String, String> getHeaders()
{    return headers;}
07abafd9249b5f378c0e0b600882228c101e2176d8f568732e4fd85f31a2fb45
getLineReadPos
public long getLineReadPos()
{    return lineReadPos;}
d11fb15035577bc983257ab3dac677877d39c9b7d2b517816300411411734f72
setPos
public void setPos(long pos)
{    this.pos = pos;}
ed93fe1fd80f796bdee77282b54c58c514cfe2fdfc7384e6664cb15e27c44b9f
setLastUpdated
public void setLastUpdated(long lastUpdated)
{    this.lastUpdated = lastUpdated;}
f7f9528980e5fd0eb89b520e25a54ea946843950fe549d6893abb17826816e00
setNeedTail
public void setNeedTail(boolean needTail)
{    this.needTail = needTail;}
97071c19371e4d0a934ceaa85ebc34091637d7f794dda2c646fcd0d4daf1975e
setLineReadPos
public void setLineReadPos(long lineReadPos)
{    this.lineReadPos = lineReadPos;}
339aa03ac61443c7c426b920e79c6241c7c002869d7c846837d790a681e37dfe
updatePos
public boolean updatePos(String path, long inode, long pos) throws IOException
{    if (this.inode == inode && this.path.equals(path)) {        setPos(pos);        updateFilePos(pos);        logger.info("Updated position, file: " + path + ", inode: " + inode + ", pos: " + pos);        return true;    }    return false;}
27f08d12d3c18c3f8d84fcf7f82f38012b6437dbee392110ce08430e340c33cc
updateFilePos
public void updateFilePos(long pos) throws IOException
{    raf.seek(pos);    lineReadPos = pos;    bufferPos = NEED_READING;    oldBuffer = new byte[0];}
c8b6f64190f0760c6d318801abdb6ac9c9272563f8dab746c58ac2db5377cab5
readEvents
public List<Event> readEvents(int numEvents, boolean backoffWithoutNL, boolean addByteOffset) throws IOException
{    List<Event> events = Lists.newLinkedList();    for (int i = 0; i < numEvents; i++) {        Event event = readEvent(backoffWithoutNL, addByteOffset);        if (event == null) {            break;        }        events.add(event);    }    return events;}
66e96ee3140612dd0f992df1ed3b0f7e7c4cd15d136766cc352a3ffecdf472b8
readEvent
private Event readEvent(boolean backoffWithoutNL, boolean addByteOffset) throws IOException
{    Long posTmp = getLineReadPos();    LineResult line = readLine();    if (line == null) {        return null;    }    if (backoffWithoutNL && !line.lineSepInclude) {        logger.info("Backing off in file without newline: " + path + ", inode: " + inode + ", pos: " + raf.getFilePointer());        updateFilePos(posTmp);        return null;    }    Event event = EventBuilder.withBody(line.line);    if (addByteOffset == true) {        event.getHeaders().put(BYTE_OFFSET_HEADER_KEY, posTmp.toString());    }    return event;}
fb0c879e9bbd42f659504084f70fac7b4629770e7038261e5bccfa0af3725cea
readFile
private void readFile() throws IOException
{    if ((raf.length() - raf.getFilePointer()) < BUFFER_SIZE) {        buffer = new byte[(int) (raf.length() - raf.getFilePointer())];    } else {        buffer = new byte[BUFFER_SIZE];    }    raf.read(buffer, 0, buffer.length);    bufferPos = 0;}
0d1d58ddca7ed591a33a929dfa52ca4bbfa6bcef3f812a7f8983eabbf99a345b
concatByteArrays
private byte[] concatByteArrays(byte[] a, int startIdxA, int lenA, byte[] b, int startIdxB, int lenB)
{    byte[] c = new byte[lenA + lenB];    System.arraycopy(a, startIdxA, c, 0, lenA);    System.arraycopy(b, startIdxB, c, lenA, lenB);    return c;}
e2ad31d69b83e1f077b68bae4ecd06d03a38af3387762d68e79b1a041844c6f0
readLine
public LineResult readLine() throws IOException
{    LineResult lineResult = null;    while (true) {        if (bufferPos == NEED_READING) {            if (raf.getFilePointer() < raf.length()) {                readFile();            } else {                if (oldBuffer.length > 0) {                    lineResult = new LineResult(false, oldBuffer);                    oldBuffer = new byte[0];                    setLineReadPos(lineReadPos + lineResult.line.length);                }                break;            }        }        for (int i = bufferPos; i < buffer.length; i++) {            if (buffer[i] == BYTE_NL) {                int oldLen = oldBuffer.length;                                int lineLen = i - bufferPos;                                if (i > 0 && buffer[i - 1] == BYTE_CR) {                    lineLen -= 1;                } else if (oldBuffer.length > 0 && oldBuffer[oldBuffer.length - 1] == BYTE_CR) {                    oldLen -= 1;                }                lineResult = new LineResult(true, concatByteArrays(oldBuffer, 0, oldLen, buffer, bufferPos, lineLen));                setLineReadPos(lineReadPos + (oldBuffer.length + (i - bufferPos + 1)));                oldBuffer = new byte[0];                if (i + 1 < buffer.length) {                    bufferPos = i + 1;                } else {                    bufferPos = NEED_READING;                }                break;            }        }        if (lineResult != null) {            break;        }                oldBuffer = concatByteArrays(oldBuffer, 0, oldBuffer.length, buffer, bufferPos, buffer.length - bufferPos);        bufferPos = NEED_READING;    }    return lineResult;}
5df6118bc0e745d8b18e0a6a99b2e3f2ddba8140cbeb1423ce2df50a9f140574
close
public void close()
{    try {        raf.close();        raf = null;        long now = System.currentTimeMillis();        setLastUpdated(now);    } catch (IOException e) {        logger.error("Failed closing file: " + path + ", inode: " + inode, e);    }}
31079920c19ef1bc5082e4aaf9d0287aa0ab23ae14f15b062e79ecb5b42a5442
bodyAsString
public static String bodyAsString(Event event)
{    return new String(event.getBody());}
28e08ca5ceb7a59e19e4f28f271fed6443ff355e9e1aaaa56a13fc2ef24d57b0
bodiesAsStrings
 static List<String> bodiesAsStrings(List<Event> events)
{    List<String> bodies = Lists.newArrayListWithCapacity(events.size());    for (Event event : events) {        bodies.add(new String(event.getBody()));    }    return bodies;}
c073a02ad584acb1768aad9f947732cc6628a8c71de60e866abced537b82a1ae
headersAsStrings
 static List<String> headersAsStrings(List<Event> events, String headerKey)
{    List<String> headers = Lists.newArrayListWithCapacity(events.size());    for (Event event : events) {        headers.add(new String(event.getHeaders().get(headerKey)));    }    return headers;}
d9764af6bdd0437b946dea380c63a0ba29938431713f26103f1f1daffb9a3426
getReader
private ReliableTaildirEventReader getReader(Map<String, String> filePaths, Table<String, String, String> headerTable, boolean addByteOffset, boolean cachedPatternMatching)
{    ReliableTaildirEventReader reader;    try {        reader = new ReliableTaildirEventReader.Builder().filePaths(filePaths).headerTable(headerTable).positionFilePath(posFilePath).skipToEnd(false).addByteOffset(addByteOffset).cachePatternMatching(cachedPatternMatching).build();        reader.updateTailFiles();    } catch (IOException ioe) {        throw Throwables.propagate(ioe);    }    return reader;}
27a3223962489e23bf19c9be3773328a06f24f65fbbf82b7cfb13871198a6b61
getReader
private ReliableTaildirEventReader getReader(boolean addByteOffset, boolean cachedPatternMatching)
{    Map<String, String> filePaths = ImmutableMap.of("testFiles", tmpDir.getAbsolutePath() + "/file.*");    Table<String, String, String> headerTable = HashBasedTable.create();    return getReader(filePaths, headerTable, addByteOffset, cachedPatternMatching);}
5b220051fd0894d0a67b8aa44a20df36d8d6d125551f4ece28ddee25b41a1ba9
getReader
private ReliableTaildirEventReader getReader()
{    return getReader(false, false);}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    tmpDir = Files.createTempDir();    posFilePath = tmpDir.getAbsolutePath() + "/taildir_position_test.json";}
39e5ba029cc67f6f1d45c6d20f0df595ec16bc61da20d7680fcbbdae4fe7f95b
tearDown
public void tearDown()
{    for (File f : tmpDir.listFiles()) {        if (f.isDirectory()) {            for (File sdf : f.listFiles()) {                sdf.delete();            }        }        f.delete();    }    tmpDir.delete();}
a84bd814faceb95ec2bf84f2fedb6727a249f000b81603d71732e258da98d3a2
testBasicReadFiles
public void testBasicReadFiles() throws IOException
{    File f1 = new File(tmpDir, "file1");    File f2 = new File(tmpDir, "file2");    File f3 = new File(tmpDir, "file3");    Files.write("file1line1\nfile1line2\n", f1, Charsets.UTF_8);    Files.write("file2line1\nfile2line2\n", f2, Charsets.UTF_8);    Files.write("file3line1\nfile3line2\n", f3, Charsets.UTF_8);    ReliableTaildirEventReader reader = getReader();    List<String> out = Lists.newArrayList();    for (TailFile tf : reader.getTailFiles().values()) {        List<String> bodies = bodiesAsStrings(reader.readEvents(tf, 2));        out.addAll(bodies);        reader.commit();    }    assertEquals(6, out.size());        assertTrue(out.contains("file1line1"));    assertTrue(out.contains("file1line2"));    assertTrue(out.contains("file2line1"));    assertTrue(out.contains("file2line2"));    assertTrue(out.contains("file3line1"));    assertTrue(out.contains("file3line2"));    Files.append("file3line3\nfile3line4\n", f3, Charsets.UTF_8);    reader.updateTailFiles();    for (TailFile tf : reader.getTailFiles().values()) {        List<String> bodies = bodiesAsStrings(reader.readEvents(tf, 2));        out.addAll(bodies);        reader.commit();    }    assertEquals(8, out.size());    assertTrue(out.contains("file3line3"));    assertTrue(out.contains("file3line4"));}
5ab5fd8de53b0827e0ec7145fece76289bba4d9035cc0bc1de779f965586a821
testDeleteFiles
public void testDeleteFiles() throws IOException
{    File f1 = new File(tmpDir, "file1");    Files.write("file1line1\nfile1line2\n", f1, Charsets.UTF_8);            ReliableTaildirEventReader reader = getReader(false, true);    File dir = f1.getParentFile();    long lastModified = dir.lastModified();    f1.delete();        dir.setLastModified(lastModified - 1000);    reader.updateTailFiles();}
e1597201e68f9b92bf241f766dde9d15bce7785c4132615ebb5b02c9cabb3b4c
testInitiallyEmptyDirAndBehaviorAfterReadingAll
public void testInitiallyEmptyDirAndBehaviorAfterReadingAll() throws IOException
{    ReliableTaildirEventReader reader = getReader();    List<Long> fileInodes = reader.updateTailFiles();    assertEquals(0, fileInodes.size());    File f1 = new File(tmpDir, "file1");    Files.write("file1line1\nfile1line2\n", f1, Charsets.UTF_8);    reader.updateTailFiles();    List<String> out = null;    for (TailFile tf : reader.getTailFiles().values()) {        out = bodiesAsStrings(reader.readEvents(tf, 2));        reader.commit();    }    assertEquals(2, out.size());        assertTrue(out.contains("file1line1"));    assertTrue(out.contains("file1line2"));    reader.updateTailFiles();    List<String> empty = null;    for (TailFile tf : reader.getTailFiles().values()) {        empty = bodiesAsStrings(reader.readEvents(tf, 15));        reader.commit();    }    assertEquals(0, empty.size());}
912f79fa391cbb5d5b58ac2c1b5f42f329ed0f0feef0d13e45284b6815cfd9f8
testBasicCommitFailure
public void testBasicCommitFailure() throws IOException
{    File f1 = new File(tmpDir, "file1");    Files.write("file1line1\nfile1line2\nfile1line3\nfile1line4\n" + "file1line5\nfile1line6\nfile1line7\nfile1line8\n" + "file1line9\nfile1line10\nfile1line11\nfile1line12\n", f1, Charsets.UTF_8);    ReliableTaildirEventReader reader = getReader();    List<String> out1 = null;    for (TailFile tf : reader.getTailFiles().values()) {        out1 = bodiesAsStrings(reader.readEvents(tf, 4));    }    assertTrue(out1.contains("file1line1"));    assertTrue(out1.contains("file1line2"));    assertTrue(out1.contains("file1line3"));    assertTrue(out1.contains("file1line4"));    List<String> out2 = bodiesAsStrings(reader.readEvents(4));    assertTrue(out2.contains("file1line1"));    assertTrue(out2.contains("file1line2"));    assertTrue(out2.contains("file1line3"));    assertTrue(out2.contains("file1line4"));    reader.commit();    List<String> out3 = bodiesAsStrings(reader.readEvents(4));    assertTrue(out3.contains("file1line5"));    assertTrue(out3.contains("file1line6"));    assertTrue(out3.contains("file1line7"));    assertTrue(out3.contains("file1line8"));    reader.commit();    List<String> out4 = bodiesAsStrings(reader.readEvents(4));    assertEquals(4, out4.size());    assertTrue(out4.contains("file1line9"));    assertTrue(out4.contains("file1line10"));    assertTrue(out4.contains("file1line11"));    assertTrue(out4.contains("file1line12"));}
846bd658b53712178f8766cbddb7c1f816a3c4b239c2a676152bd5637107742b
testBasicCommitFailureAndBatchSizeChanges
public void testBasicCommitFailureAndBatchSizeChanges() throws IOException
{    File f1 = new File(tmpDir, "file1");    Files.write("file1line1\nfile1line2\nfile1line3\nfile1line4\n" + "file1line5\nfile1line6\nfile1line7\nfile1line8\n", f1, Charsets.UTF_8);    ReliableTaildirEventReader reader = getReader();    List<String> out1 = null;    for (TailFile tf : reader.getTailFiles().values()) {        out1 = bodiesAsStrings(reader.readEvents(tf, 5));    }    assertTrue(out1.contains("file1line1"));    assertTrue(out1.contains("file1line2"));    assertTrue(out1.contains("file1line3"));    assertTrue(out1.contains("file1line4"));    assertTrue(out1.contains("file1line5"));    List<String> out2 = bodiesAsStrings(reader.readEvents(2));    assertTrue(out2.contains("file1line1"));    assertTrue(out2.contains("file1line2"));    reader.commit();    List<String> out3 = bodiesAsStrings(reader.readEvents(2));    assertTrue(out3.contains("file1line3"));    assertTrue(out3.contains("file1line4"));    reader.commit();    List<String> out4 = bodiesAsStrings(reader.readEvents(15));    assertTrue(out4.contains("file1line5"));    assertTrue(out4.contains("file1line6"));    assertTrue(out4.contains("file1line7"));    assertTrue(out4.contains("file1line8"));}
0d3967032200e64671e4fbbc121656f31521e9257608139030ef4ece5896578c
testIncludeEmptyFile
public void testIncludeEmptyFile() throws IOException
{    File f1 = new File(tmpDir, "file1");    File f2 = new File(tmpDir, "file2");    Files.write("file1line1\nfile1line2\n", f1, Charsets.UTF_8);    Files.touch(f2);    ReliableTaildirEventReader reader = getReader();        List<String> out = Lists.newArrayList();    for (TailFile tf : reader.getTailFiles().values()) {        out.addAll(bodiesAsStrings(reader.readEvents(tf, 5)));        reader.commit();    }    assertEquals(2, out.size());    assertTrue(out.contains("file1line1"));    assertTrue(out.contains("file1line2"));    assertNull(reader.readEvent());}
1a0311f4a3700faf5294a95cca48204d9cf7e7404d4b08442d77290c9303bbe4
testBackoffWithoutNewLine
public void testBackoffWithoutNewLine() throws IOException
{    File f1 = new File(tmpDir, "file1");    Files.write("file1line1\nfile1", f1, Charsets.UTF_8);    ReliableTaildirEventReader reader = getReader();    List<String> out = Lists.newArrayList();        for (TailFile tf : reader.getTailFiles().values()) {        out.addAll(bodiesAsStrings(reader.readEvents(tf, 5)));        reader.commit();    }    assertEquals(1, out.size());    assertTrue(out.contains("file1line1"));    Files.append("line2\nfile1line3\nfile1line4", f1, Charsets.UTF_8);    for (TailFile tf : reader.getTailFiles().values()) {        out.addAll(bodiesAsStrings(reader.readEvents(tf, 5)));        reader.commit();    }    assertEquals(3, out.size());    assertTrue(out.contains("file1line2"));    assertTrue(out.contains("file1line3"));        out.addAll(bodiesAsStrings(reader.readEvents(5, false)));    reader.commit();    assertEquals(4, out.size());    assertTrue(out.contains("file1line4"));}
b2a1ed011c80eaa0b4be5688648b1a226d6a387667cee7f975aa79abf29ffd56
testBatchedReadsAcrossFileBoundary
public void testBatchedReadsAcrossFileBoundary() throws IOException
{    File f1 = new File(tmpDir, "file1");    Files.write("file1line1\nfile1line2\nfile1line3\nfile1line4\n" + "file1line5\nfile1line6\nfile1line7\nfile1line8\n", f1, Charsets.UTF_8);    ReliableTaildirEventReader reader = getReader();    List<String> out1 = Lists.newArrayList();    for (TailFile tf : reader.getTailFiles().values()) {        out1.addAll(bodiesAsStrings(reader.readEvents(tf, 5)));        reader.commit();    }    File f2 = new File(tmpDir, "file2");    Files.write("file2line1\nfile2line2\nfile2line3\nfile2line4\n" + "file2line5\nfile2line6\nfile2line7\nfile2line8\n", f2, Charsets.UTF_8);    List<String> out2 = bodiesAsStrings(reader.readEvents(5));    reader.commit();    reader.updateTailFiles();    List<String> out3 = Lists.newArrayList();    for (TailFile tf : reader.getTailFiles().values()) {        out3.addAll(bodiesAsStrings(reader.readEvents(tf, 5)));        reader.commit();    }        assertEquals(5, out1.size());    assertTrue(out1.contains("file1line1"));    assertTrue(out1.contains("file1line2"));    assertTrue(out1.contains("file1line3"));    assertTrue(out1.contains("file1line4"));    assertTrue(out1.contains("file1line5"));        assertEquals(3, out2.size());    assertTrue(out2.contains("file1line6"));    assertTrue(out2.contains("file1line7"));    assertTrue(out2.contains("file1line8"));        assertEquals(5, out3.size());    assertTrue(out3.contains("file2line1"));    assertTrue(out3.contains("file2line2"));    assertTrue(out3.contains("file2line3"));    assertTrue(out3.contains("file2line4"));    assertTrue(out3.contains("file2line5"));}
aa44da9ccdc1193a743485768bd0447331a55609fe02f81671912341fb088e17
testLargeNumberOfFiles
public void testLargeNumberOfFiles() throws IOException
{    int fileNum = 1000;    Set<String> expected = Sets.newHashSet();    for (int i = 0; i < fileNum; i++) {        String data = "data" + i;        File f = new File(tmpDir, "file" + i);        Files.write(data + "\n", f, Charsets.UTF_8);        expected.add(data);    }    ReliableTaildirEventReader reader = getReader();    for (TailFile tf : reader.getTailFiles().values()) {        List<Event> events = reader.readEvents(tf, 10);        for (Event e : events) {            expected.remove(new String(e.getBody()));        }        reader.commit();    }    assertEquals(0, expected.size());}
bea5a996d4789482abf57b2aeded2c37c09336cb666c8b4ff7693517828d02de
testLoadPositionFile
public void testLoadPositionFile() throws IOException
{    File f1 = new File(tmpDir, "file1");    File f2 = new File(tmpDir, "file2");    File f3 = new File(tmpDir, "file3");    Files.write("file1line1\nfile1line2\nfile1line3\n", f1, Charsets.UTF_8);    Files.write("file2line1\nfile2line2\n", f2, Charsets.UTF_8);    Files.write("file3line1\n", f3, Charsets.UTF_8);    ReliableTaildirEventReader reader = getReader();    Map<Long, TailFile> tailFiles = reader.getTailFiles();    long pos = f2.length();    int i = 1;    File posFile = new File(posFilePath);    for (TailFile tf : tailFiles.values()) {        Files.append(i == 1 ? "[" : "", posFile, Charsets.UTF_8);        Files.append(String.format("{\"inode\":%s,\"pos\":%s,\"file\":\"%s\"}", tf.getInode(), pos, tf.getPath()), posFile, Charsets.UTF_8);        Files.append(i == 3 ? "]" : ",", posFile, Charsets.UTF_8);        i++;    }    reader.loadPositionFile(posFilePath);    for (TailFile tf : tailFiles.values()) {        if (tf.getPath().equals(tmpDir + "file3")) {                        assertEquals(0, tf.getPos());        } else {            assertEquals(pos, tf.getPos());        }    }}
8374bbef3cf3581df0aed551274e2e2be229cffb4c915d6d707f31780dbb127b
testSkipToEndPosition
public void testSkipToEndPosition() throws IOException
{    ReliableTaildirEventReader reader = getReader();    File f1 = new File(tmpDir, "file1");    Files.write("file1line1\nfile1line2\n", f1, Charsets.UTF_8);    reader.updateTailFiles();    for (TailFile tf : reader.getTailFiles().values()) {        if (tf.getPath().equals(tmpDir + "file1")) {            assertEquals(0, tf.getPos());        }    }    File f2 = new File(tmpDir, "file2");    Files.write("file2line1\nfile2line2\n", f2, Charsets.UTF_8);        reader.updateTailFiles(true);    for (TailFile tf : reader.getTailFiles().values()) {        if (tf.getPath().equals(tmpDir + "file2")) {            assertEquals(f2.length(), tf.getPos());        }    }}
f91f91465904427c09b89024c1826ed4b02069283b884b5068ff42d0e25b944e
testByteOffsetHeader
public void testByteOffsetHeader() throws IOException
{    File f1 = new File(tmpDir, "file1");    String line1 = "file1line1\n";    String line2 = "file1line2\n";    String line3 = "file1line3\n";    Files.write(line1 + line2 + line3, f1, Charsets.UTF_8);    ReliableTaildirEventReader reader = getReader(true, false);    List<String> headers = null;    for (TailFile tf : reader.getTailFiles().values()) {        headers = headersAsStrings(reader.readEvents(tf, 5), BYTE_OFFSET_HEADER_KEY);        reader.commit();    }    assertEquals(3, headers.size());        assertTrue(headers.contains(String.valueOf(0)));    assertTrue(headers.contains(String.valueOf(line1.length())));    assertTrue(headers.contains(String.valueOf((line1 + line2).length())));}
13f2704c95fc13b01c2ce1dce35fef8a1dee72d9098fab27d2090ae1a3565c1d
testNewLineBoundaries
public void testNewLineBoundaries() throws IOException
{    File f1 = new File(tmpDir, "file1");    Files.write("file1line1\nfile1line2\rfile1line2\nfile1line3\r\nfile1line4\n", f1, Charsets.UTF_8);    ReliableTaildirEventReader reader = getReader();    List<String> out = Lists.newArrayList();    for (TailFile tf : reader.getTailFiles().values()) {        out.addAll(bodiesAsStrings(reader.readEvents(tf, 5)));        reader.commit();    }    assertEquals(4, out.size());        assertTrue(out.contains("file1line1"));        assertTrue(out.contains("file1line2\rfile1line2"));        assertTrue(out.contains("file1line3"));    assertTrue(out.contains("file1line4"));}
1adaebbe09a0cde4027b17fff903e52d05708fce58af1ba23126eabfae6e3fc3
testUpdateWhenLastUpdatedSameAsModificationTime
public void testUpdateWhenLastUpdatedSameAsModificationTime() throws IOException
{    File file = new File(tmpDir, "file");    Files.write("line1\n", file, Charsets.UTF_8);    ReliableTaildirEventReader reader = getReader();    for (TailFile tf : reader.getTailFiles().values()) {        reader.readEvents(tf, 1);        reader.commit();    }    Files.append("line2\n", file, Charsets.UTF_8);    for (TailFile tf : reader.getTailFiles().values()) {        tf.setLastUpdated(file.lastModified());    }    reader.updateTailFiles();    for (TailFile tf : reader.getTailFiles().values()) {        assertEquals(true, tf.needTail());    }}
3bd3ccb7f692b505aa21ea50ff81dc63f66bbe63d533148d6c6ade3fd6620fac
append
private void append(String fileName) throws IOException
{    File f;    if (!files.containsKey(fileName)) {        f = new File(tmpDir, fileName);        files.put(fileName, f);    } else {        f = files.get(fileName);    }    Files.append(fileName + "line\n", f, Charsets.UTF_8);}
9301d018c9d40c4215bc389a9331017e3c65e2fb9a923eb26422f29e842f5a3b
filesToNames
private static List<String> filesToNames(List<File> origList)
{    Function<File, String> file2nameFn = new Function<File, String>() {        @Override        public String apply(File input) {            return input.getName();        }    };    return Lists.transform(origList, file2nameFn);}
f535189bb1139d36745a869929d29bec87ea02ba8440f2d58e6e76cdcf17a0b4
apply
public String apply(File input)
{    return input.getName();}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    files = Maps.newHashMap();    tmpDir = Files.createTempDir();}
c6aaebb5a52567751db8dc8e1cb9dd4a4e582ef964a374b376c6a04f741802dc
tearDown
public void tearDown() throws Exception
{    for (File f : tmpDir.listFiles()) {        if (f.isDirectory()) {            for (File sdf : f.listFiles()) {                sdf.delete();            }        }        f.delete();    }    tmpDir.delete();    files = null;}
bc99f27b4475b4f9266a3d350ecbf586150ca1d54a0b5ea615620fc4d8c96ca7
getMatchingFiles
public void getMatchingFiles() throws Exception
{    append("file0");    append("file1");    TaildirMatcher tm = new TaildirMatcher("f1", tmpDir.getAbsolutePath() + File.separator + "file.*", isCachingNeeded);    List<String> files = filesToNames(tm.getMatchingFiles());    assertEquals(msgAlreadyExistingFile, 2, files.size());    assertTrue(msgAlreadyExistingFile, files.contains("file1"));    append("file1");    files = filesToNames(tm.getMatchingFiles());    assertEquals(msgAfterNewFileCreated, 2, files.size());    assertTrue(msgAfterNewFileCreated, files.contains("file0"));    assertTrue(msgAfterNewFileCreated, files.contains("file1"));    append("file2");    append("file3");    files = filesToNames(tm.getMatchingFiles());    assertEquals(msgAfterAppend, 4, files.size());    assertTrue(msgAfterAppend, files.contains("file0"));    assertTrue(msgAfterAppend, files.contains("file1"));    assertTrue(msgAfterAppend, files.contains("file2"));    assertTrue(msgAfterAppend, files.contains("file3"));    this.files.get("file0").delete();    files = filesToNames(tm.getMatchingFiles());    assertEquals(msgAfterDelete, 3, files.size());    assertFalse(msgAfterDelete, files.contains("file0"));    assertTrue(msgNoChange, files.contains("file1"));    assertTrue(msgNoChange, files.contains("file2"));    assertTrue(msgNoChange, files.contains("file3"));}
18414878be9c691df1f6b4bbcc2b1c758ee138b80ae5fe683b7c821aeb597bb1
getMatchingFilesNoCache
public void getMatchingFilesNoCache() throws Exception
{    append("file0");    append("file1");    TaildirMatcher tm = new TaildirMatcher("f1", tmpDir.getAbsolutePath() + File.separator + "file.*", false);    List<String> files = filesToNames(tm.getMatchingFiles());    assertEquals(msgAlreadyExistingFile, 2, files.size());    assertTrue(msgAlreadyExistingFile, files.contains("file1"));    append("file1");    files = filesToNames(tm.getMatchingFiles());    assertEquals(msgAfterAppend, 2, files.size());    assertTrue(msgAfterAppend, files.contains("file0"));    assertTrue(msgAfterAppend, files.contains("file1"));    append("file2");    append("file3");    files = filesToNames(tm.getMatchingFiles());    assertEquals(msgAfterNewFileCreated, 4, files.size());    assertTrue(msgAfterNewFileCreated, files.contains("file0"));    assertTrue(msgAfterNewFileCreated, files.contains("file1"));    assertTrue(msgAfterNewFileCreated, files.contains("file2"));    assertTrue(msgAfterNewFileCreated, files.contains("file3"));    this.files.get("file0").delete();    files = filesToNames(tm.getMatchingFiles());    assertEquals(msgAfterDelete, 3, files.size());    assertFalse(msgAfterDelete, files.contains("file0"));    assertTrue(msgNoChange, files.contains("file1"));    assertTrue(msgNoChange, files.contains("file2"));    assertTrue(msgNoChange, files.contains("file3"));}
92541756d26fe790db265623bdbaba4a24defc0449c62e7a4c4b1e8834181102
testEmtpyDirMatching
public void testEmtpyDirMatching() throws Exception
{    TaildirMatcher tm = new TaildirMatcher("empty", tmpDir.getAbsolutePath() + File.separator + ".*", isCachingNeeded);    List<File> files = tm.getMatchingFiles();    assertNotNull(msgEmptyDir, files);    assertTrue(msgEmptyDir, files.isEmpty());}
7c7f5596e40c2fbd6a5a4557f58077d77ae2f91b7c1070d73a8b1fbf3c5888d8
testNoMatching
public void testNoMatching() throws Exception
{    TaildirMatcher tm = new TaildirMatcher("nomatch", tmpDir.getAbsolutePath() + File.separator + "abracadabra_nonexisting", isCachingNeeded);    List<File> files = tm.getMatchingFiles();    assertNotNull(msgNoMatch, files);    assertTrue(msgNoMatch, files.isEmpty());}
7298b9c8e75b4f53651acddd9d749719ab52a52db718d9ba2c65db89a64751d1
testNonExistingDir
public void testNonExistingDir()
{    TaildirMatcher tm = new TaildirMatcher("exception", "/abracadabra/doesntexist/.*", isCachingNeeded);}
244de178846373f139b8968d57ec5d4974dc3ce3b80fb071da929caab0ee0141
testDirectoriesAreNotListed
public void testDirectoriesAreNotListed() throws Exception
{    new File(tmpDir, "outerFile").createNewFile();    new File(tmpDir, "recursiveDir").mkdir();    new File(tmpDir + File.separator + "recursiveDir", "innerFile").createNewFile();    TaildirMatcher tm = new TaildirMatcher("f1", tmpDir.getAbsolutePath() + File.separator + ".*", isCachingNeeded);    List<String> files = filesToNames(tm.getMatchingFiles());    assertEquals(msgSubDirs, 1, files.size());    assertTrue(msgSubDirs, files.contains("outerFile"));}
0c7b02074eef4c95614096c87211609b87b1c4ff4f657e134a07e1aca3f62557
testRegexFileNameFiltering
public void testRegexFileNameFiltering() throws IOException
{    append("a.log");    append("a.log.1");    append("b.log");    append("c.log.yyyy.MM-01");    append("c.log.yyyy.MM-02");        TaildirMatcher tm1 = new TaildirMatcher("ab", tmpDir.getAbsolutePath() + File.separator + "[ab].log", isCachingNeeded);        TaildirMatcher tm2 = new TaildirMatcher("c", tmpDir.getAbsolutePath() + File.separator + "c.log.*", isCachingNeeded);    List<String> files1 = filesToNames(tm1.getMatchingFiles());    List<String> files2 = filesToNames(tm2.getMatchingFiles());    assertEquals(2, files1.size());    assertEquals(2, files2.size());        assertTrue("Regex pattern for ab should have matched a.log file", files1.contains("a.log"));    assertFalse("Regex pattern for ab should NOT have matched a.log.1 file", files1.contains("a.log.1"));    assertTrue("Regex pattern for ab should have matched b.log file", files1.contains("b.log"));    assertTrue("Regex pattern for c should have matched c.log.yyyy-MM-01 file", files2.contains("c.log.yyyy.MM-01"));    assertTrue("Regex pattern for c should have matched c.log.yyyy-MM-02 file", files2.contains("c.log.yyyy.MM-02"));}
4adaefafec562702d887f5960a1408e5f9d1add92c42fab7cb857d701c42d2a2
setUp
public void setUp()
{    source = new TaildirSource();    channel = new MemoryChannel();    Configurables.configure(channel, new Context());    List<Channel> channels = new ArrayList<Channel>();    channels.add(channel);    ChannelSelector rcs = new ReplicatingChannelSelector();    rcs.setChannels(channels);    source.setChannelProcessor(new ChannelProcessor(rcs));    tmpDir = Files.createTempDir();    posFilePath = tmpDir.getAbsolutePath() + "/taildir_position_test.json";}
39e5ba029cc67f6f1d45c6d20f0df595ec16bc61da20d7680fcbbdae4fe7f95b
tearDown
public void tearDown()
{    for (File f : tmpDir.listFiles()) {        f.delete();    }    tmpDir.delete();}
92af7a4c91248205965faaac5178ceb7ad9b30ba6012d1fc420bfd19a65720be
testRegexFileNameFilteringEndToEnd
public void testRegexFileNameFilteringEndToEnd() throws IOException
{    File f1 = new File(tmpDir, "a.log");    File f2 = new File(tmpDir, "a.log.1");    File f3 = new File(tmpDir, "b.log");    File f4 = new File(tmpDir, "c.log.yyyy-MM-01");    File f5 = new File(tmpDir, "c.log.yyyy-MM-02");    Files.write("a.log\n", f1, Charsets.UTF_8);    Files.write("a.log.1\n", f2, Charsets.UTF_8);    Files.write("b.log\n", f3, Charsets.UTF_8);    Files.write("c.log.yyyy-MM-01\n", f4, Charsets.UTF_8);    Files.write("c.log.yyyy-MM-02\n", f5, Charsets.UTF_8);    Context context = new Context();    context.put(POSITION_FILE, posFilePath);    context.put(FILE_GROUPS, "ab c");        context.put(FILE_GROUPS_PREFIX + "ab", tmpDir.getAbsolutePath() + "/[ab].log");        context.put(FILE_GROUPS_PREFIX + "c", tmpDir.getAbsolutePath() + "/c.log.*");    Configurables.configure(source, context);    source.start();    source.process();    Transaction txn = channel.getTransaction();    txn.begin();    List<String> out = Lists.newArrayList();    for (int i = 0; i < 5; i++) {        Event e = channel.take();        if (e != null) {            out.add(TestTaildirEventReader.bodyAsString(e));        }    }    txn.commit();    txn.close();    assertEquals(4, out.size());        assertTrue(out.contains("a.log"));    assertFalse(out.contains("a.log.1"));    assertTrue(out.contains("b.log"));    assertTrue(out.contains("c.log.yyyy-MM-01"));    assertTrue(out.contains("c.log.yyyy-MM-02"));}
2c8665c2c908d6acde5bda145b25e811931fce599918d729a7fe526c39219d3d
testHeaderMapping
public void testHeaderMapping() throws IOException
{    File f1 = new File(tmpDir, "file1");    File f2 = new File(tmpDir, "file2");    File f3 = new File(tmpDir, "file3");    Files.write("file1line1\nfile1line2\n", f1, Charsets.UTF_8);    Files.write("file2line1\nfile2line2\n", f2, Charsets.UTF_8);    Files.write("file3line1\nfile3line2\n", f3, Charsets.UTF_8);    Context context = new Context();    context.put(POSITION_FILE, posFilePath);    context.put(FILE_GROUPS, "f1 f2 f3");    context.put(FILE_GROUPS_PREFIX + "f1", tmpDir.getAbsolutePath() + "/file1$");    context.put(FILE_GROUPS_PREFIX + "f2", tmpDir.getAbsolutePath() + "/file2$");    context.put(FILE_GROUPS_PREFIX + "f3", tmpDir.getAbsolutePath() + "/file3$");    context.put(HEADERS_PREFIX + "f1.headerKeyTest", "value1");    context.put(HEADERS_PREFIX + "f2.headerKeyTest", "value2");    context.put(HEADERS_PREFIX + "f2.headerKeyTest2", "value2-2");    Configurables.configure(source, context);    source.start();    source.process();    Transaction txn = channel.getTransaction();    txn.begin();    for (int i = 0; i < 6; i++) {        Event e = channel.take();        String body = new String(e.getBody(), Charsets.UTF_8);        String headerValue = e.getHeaders().get("headerKeyTest");        String headerValue2 = e.getHeaders().get("headerKeyTest2");        if (body.startsWith("file1")) {            assertEquals("value1", headerValue);            assertNull(headerValue2);        } else if (body.startsWith("file2")) {            assertEquals("value2", headerValue);            assertEquals("value2-2", headerValue2);        } else if (body.startsWith("file3")) {                        assertNull(headerValue);            assertNull(headerValue2);        }    }    txn.commit();    txn.close();}
3b5d94ab890b4e2664ec6567db687a95e9b3b2e71331c545033c973fe005e8ae
testLifecycle
public void testLifecycle() throws IOException, InterruptedException
{    File f1 = new File(tmpDir, "file1");    Files.write("file1line1\nfile1line2\n", f1, Charsets.UTF_8);    Context context = new Context();    context.put(POSITION_FILE, posFilePath);    context.put(FILE_GROUPS, "f1");    context.put(FILE_GROUPS_PREFIX + "f1", tmpDir.getAbsolutePath() + "/file1$");    Configurables.configure(source, context);    for (int i = 0; i < 3; i++) {        source.start();        source.process();        assertTrue("Reached start or error", LifecycleController.waitForOneOf(source, LifecycleState.START_OR_ERROR));        assertEquals("Server is started", LifecycleState.START, source.getLifecycleState());        source.stop();        assertTrue("Reached stop or error", LifecycleController.waitForOneOf(source, LifecycleState.STOP_OR_ERROR));        assertEquals("Server is stopped", LifecycleState.STOP, source.getLifecycleState());    }}
1b0154fb6599df577a8c84fc48b6e17bccddf55ce93fc19125b42e2729023195
prepareFileConsumeOrder
private ArrayList<String> prepareFileConsumeOrder() throws IOException
{    System.out.println(tmpDir.toString());        File f1 = new File(tmpDir, "file1");    String line1 = "file1line1\n";    String line2 = "file1line2\n";    String line3 = "file1line3\n";    Files.write(line1 + line2 + line3, f1, Charsets.UTF_8);    try {                Thread.sleep(1000);    } catch (InterruptedException e) {    }        String line1b = "file2line1\n";    String line2b = "file2line2\n";    String line3b = "file2line3\n";    File f2 = new File(tmpDir, "file2");    Files.write(line1b + line2b + line3b, f2, Charsets.UTF_8);    try {                Thread.sleep(1000);    } catch (InterruptedException e) {    }        String line1c = "file3line1\n";    String line2c = "file3line2\n";    String line3c = "file3line3\n";    File f3 = new File(tmpDir, "file3");    Files.write(line1c + line2c + line3c, f3, Charsets.UTF_8);    try {                Thread.sleep(1000);    } catch (InterruptedException e) {    }        String line1d = "file4line1\n";    String line2d = "file4line2\n";    String line3d = "file4line3\n";    File f4 = new File(tmpDir, "file4");    Files.write(line1d + line2d + line3d, f4, Charsets.UTF_8);    try {                Thread.sleep(1000);    } catch (InterruptedException e) {    }        f3.setLastModified(System.currentTimeMillis());        Context context = new Context();    context.put(POSITION_FILE, posFilePath);    context.put(FILE_GROUPS, "g1");    context.put(FILE_GROUPS_PREFIX + "g1", tmpDir.getAbsolutePath() + "/.*");    Configurables.configure(source, context);        ArrayList<String> expected =     Lists.newArrayList(    line1,     line2,     line3,     line1b,     line2b,     line3b,     line1d,     line2d,     line3d,     line1c,     line2c,     line3c);    for (int i = 0; i != expected.size(); ++i) {        expected.set(i, expected.get(i).trim());    }    return expected;}
2e509f0e8ef66fb8376020c91ed2676665992c705f1199a1373354d92f5a6594
testFileConsumeOrder
public void testFileConsumeOrder() throws IOException
{    ArrayList<String> consumedOrder = Lists.newArrayList();    ArrayList<String> expected = prepareFileConsumeOrder();    source.start();    source.process();    Transaction txn = channel.getTransaction();    txn.begin();    for (int i = 0; i < 12; i++) {        Event e = channel.take();        String body = new String(e.getBody(), Charsets.UTF_8);        consumedOrder.add(body);    }    txn.commit();    txn.close();    System.out.println(consumedOrder);    assertArrayEquals("Files not consumed in expected order", expected.toArray(), consumedOrder.toArray());}
a1694c7bbc956fb43d62213800640dfc1bf1d50d09676cfbd16fc5b8959576de
configureSource
private File configureSource() throws IOException
{    File f1 = new File(tmpDir, "file1");    Files.write("f1\n", f1, Charsets.UTF_8);    Context context = new Context();    context.put(POSITION_FILE, posFilePath);    context.put(FILE_GROUPS, "fg");    context.put(FILE_GROUPS_PREFIX + "fg", tmpDir.getAbsolutePath() + "/file.*");    context.put(FILENAME_HEADER, "true");    context.put(FILENAME_HEADER_KEY, "path");    Configurables.configure(source, context);    return f1;}
d5f66fd79f8e46f09e3ef4da516bfd3626a344ff75ee4403fff53e5e68f4c7af
testPutFilenameHeader
public void testPutFilenameHeader() throws IOException
{    File f1 = configureSource();    source.start();    source.process();    Transaction txn = channel.getTransaction();    txn.begin();    Event e = channel.take();    txn.commit();    txn.close();    assertNotNull(e.getHeaders().get("path"));    assertEquals(f1.getAbsolutePath(), e.getHeaders().get("path"));}
fadbbf1e2a2f05fb22a914b78a0f9a0c8d7951630987c1cecefddbf7a5ee31a8
testErrorCounterEventReadFail
public void testErrorCounterEventReadFail() throws Exception
{    configureSource();    source.start();    ReliableTaildirEventReader reader = Mockito.mock(ReliableTaildirEventReader.class);    Whitebox.setInternalState(source, "reader", reader);    when(reader.updateTailFiles()).thenReturn(Collections.singletonList(123L));    when(reader.getTailFiles()).thenThrow(new RuntimeException("hello"));    source.process();    assertEquals(1, source.getSourceCounter().getEventReadFail());    source.stop();}
0bfdc63b4a5a77cf61a6050da8f120c8a6033f5994d41bd2669a25a1c42692cc
testErrorCounterFileHandlingFail
public void testErrorCounterFileHandlingFail() throws Exception
{    configureSource();    Whitebox.setInternalState(source, "idleTimeout", 0);    Whitebox.setInternalState(source, "checkIdleInterval", 60);    source.start();    ReliableTaildirEventReader reader = Mockito.mock(ReliableTaildirEventReader.class);    when(reader.getTailFiles()).thenThrow(new RuntimeException("hello"));    Whitebox.setInternalState(source, "reader", reader);    TimeUnit.MILLISECONDS.sleep(200);    assertTrue(0 < source.getSourceCounter().getGenericProcessingFail());    source.stop();}
842ce523cd5b575230a4e53c3d57d7b83c10bc784cdf87d5c299626f97ef80e0
testErrorCounterChannelWriteFail
public void testErrorCounterChannelWriteFail() throws Exception
{    prepareFileConsumeOrder();    ChannelProcessor cp = Mockito.mock(ChannelProcessor.class);    source.setChannelProcessor(cp);    doThrow(new ChannelException("dummy")).doNothing().when(cp).processEventBatch(anyListOf(Event.class));    source.start();    source.process();    assertEquals(1, source.getSourceCounter().getChannelWriteFail());    source.stop();}
55f7d9be4620ccf0ca3207eacb3cda54412e738af435c8c106a782dbbb6352d8
testMaxBatchCount
public void testMaxBatchCount() throws IOException
{    File f1 = new File(tmpDir, "file1");    File f2 = new File(tmpDir, "file2");    Files.write("file1line1\nfile1line2\n" + "file1line3\nfile1line4\n", f1, Charsets.UTF_8);    Files.write("file2line1\nfile2line2\n" + "file2line3\nfile2line4\n", f2, Charsets.UTF_8);    Context context = new Context();    context.put(POSITION_FILE, posFilePath);    context.put(FILE_GROUPS, "fg");    context.put(FILE_GROUPS_PREFIX + "fg", tmpDir.getAbsolutePath() + "/file.*");    context.put(BATCH_SIZE, String.valueOf(1));    context.put(MAX_BATCH_COUNT, String.valueOf(2));    Configurables.configure(source, context);    source.start();        source.process();    source.process();    List<Event> eventList = new ArrayList<Event>();    for (int i = 0; i < 8; i++) {        Transaction txn = channel.getTransaction();        txn.begin();        Event e = channel.take();        txn.commit();        txn.close();        if (e == null) {            break;        }        eventList.add(e);    }    assertEquals("1", context.getString(BATCH_SIZE));    assertEquals("2", context.getString(MAX_BATCH_COUNT));    assertEquals(8, eventList.size());        String firstFile = new String(eventList.get(0).getBody()).substring(0, 5);    String secondFile = firstFile.equals("file1") ? "file2" : "file1";    assertEquals(firstFile + "line1", new String(eventList.get(0).getBody()));    assertEquals(firstFile + "line2", new String(eventList.get(1).getBody()));    assertEquals(secondFile + "line1", new String(eventList.get(2).getBody()));    assertEquals(secondFile + "line2", new String(eventList.get(3).getBody()));    assertEquals(firstFile + "line3", new String(eventList.get(4).getBody()));    assertEquals(firstFile + "line4", new String(eventList.get(5).getBody()));    assertEquals(secondFile + "line3", new String(eventList.get(6).getBody()));    assertEquals(secondFile + "line4", new String(eventList.get(7).getBody()));}
8086acfec27baee89c0d98bd2c3925137c5a0cd9afd9af5b41f7a89eb37115d8
testStatus
public void testStatus() throws IOException
{    File f1 = new File(tmpDir, "file1");    File f2 = new File(tmpDir, "file2");    Files.write("file1line1\nfile1line2\n" + "file1line3\nfile1line4\nfile1line5\n", f1, Charsets.UTF_8);    Files.write("file2line1\nfile2line2\n" + "file2line3\n", f2, Charsets.UTF_8);    Context context = new Context();    context.put(POSITION_FILE, posFilePath);    context.put(FILE_GROUPS, "fg");    context.put(FILE_GROUPS_PREFIX + "fg", tmpDir.getAbsolutePath() + "/file.*");    context.put(BATCH_SIZE, String.valueOf(1));    context.put(MAX_BATCH_COUNT, String.valueOf(2));    Configurables.configure(source, context);    source.start();    Status status;    status = source.process();    assertEquals(Status.READY, status);    status = source.process();    assertEquals(Status.READY, status);    status = source.process();    assertEquals(Status.BACKOFF, status);    status = source.process();    assertEquals(Status.BACKOFF, status);}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    String consumerKey = context.getString("consumerKey");    String consumerSecret = context.getString("consumerSecret");    String accessToken = context.getString("accessToken");    String accessTokenSecret = context.getString("accessTokenSecret");    twitterStream = new TwitterStreamFactory().getInstance();    twitterStream.setOAuthConsumer(consumerKey, consumerSecret);    twitterStream.setOAuthAccessToken(new AccessToken(accessToken, accessTokenSecret));    twitterStream.addListener(this);    avroSchema = createAvroSchema();    dataFileWriter = new DataFileWriter<GenericRecord>(new GenericDatumWriter<GenericRecord>(avroSchema));    maxBatchSize = context.getInteger("maxBatchSize", maxBatchSize);    maxBatchDurationMillis = context.getInteger("maxBatchDurationMillis", maxBatchDurationMillis);}
5b05914888e421f26bff6f39231facdd35759f746a9af780ebac2cf5b2c81932
start
public synchronized void start()
{    LOGGER.info("Starting twitter source {} ...", this);    docCount = 0;    startTime = System.currentTimeMillis();    exceptionCount = 0;    totalTextIndexed = 0;    skippedDocs = 0;    batchEndTime = System.currentTimeMillis() + maxBatchDurationMillis;    twitterStream.sample();    LOGGER.info("Twitter source {} started.", getName());                        super.start();}
06e1ddba8663c90da407ac517f29ed70555cfe57b0332c9a96e7c696e0255364
stop
public synchronized void stop()
{    LOGGER.info("Twitter source {} stopping...", getName());    twitterStream.shutdown();    super.stop();    LOGGER.info("Twitter source {} stopped.", getName());}
b6c37b29f4a076ee48f69741dd6b7ba0dadec8a8eff6d346a2b68e761f16dc8f
onStatus
public void onStatus(Status status)
{    Record doc = extractRecord("", avroSchema, status);    if (doc == null) {                return;    }    docs.add(doc);    if (docs.size() >= maxBatchSize || System.currentTimeMillis() >= batchEndTime) {        batchEndTime = System.currentTimeMillis() + maxBatchDurationMillis;        byte[] bytes;        try {            bytes = serializeToAvro(avroSchema, docs);        } catch (IOException e) {            LOGGER.error("Exception while serializing tweet", e);                        return;        }        Event event = EventBuilder.withBody(bytes);                getChannelProcessor().processEvent(event);        docs.clear();    }    docCount++;    if ((docCount % REPORT_INTERVAL) == 0) {        LOGGER.info(String.format("Processed %s docs", numFormatter.format(docCount)));    }    if ((docCount % STATS_INTERVAL) == 0) {        logStats();    }}
bacb5958c010a67d823532083d9317985ac3096b010740e2460d7de5d47a6c6f
createAvroSchema
private Schema createAvroSchema()
{    Schema avroSchema = Schema.createRecord("Doc", "adoc", null, false);    List<Field> fields = new ArrayList<Field>();    fields.add(new Field("id", Schema.create(Type.STRING), null, null));    fields.add(new Field("user_friends_count", createOptional(Schema.create(Type.INT)), null, null));    fields.add(new Field("user_location", createOptional(Schema.create(Type.STRING)), null, null));    fields.add(new Field("user_description", createOptional(Schema.create(Type.STRING)), null, null));    fields.add(new Field("user_statuses_count", createOptional(Schema.create(Type.INT)), null, null));    fields.add(new Field("user_followers_count", createOptional(Schema.create(Type.INT)), null, null));    fields.add(new Field("user_name", createOptional(Schema.create(Type.STRING)), null, null));    fields.add(new Field("user_screen_name", createOptional(Schema.create(Type.STRING)), null, null));    fields.add(new Field("created_at", createOptional(Schema.create(Type.STRING)), null, null));    fields.add(new Field("text", createOptional(Schema.create(Type.STRING)), null, null));    fields.add(new Field("retweet_count", createOptional(Schema.create(Type.LONG)), null, null));    fields.add(new Field("retweeted", createOptional(Schema.create(Type.BOOLEAN)), null, null));    fields.add(new Field("in_reply_to_user_id", createOptional(Schema.create(Type.LONG)), null, null));    fields.add(new Field("source", createOptional(Schema.create(Type.STRING)), null, null));    fields.add(new Field("in_reply_to_status_id", createOptional(Schema.create(Type.LONG)), null, null));    fields.add(new Field("media_url_https", createOptional(Schema.create(Type.STRING)), null, null));    fields.add(new Field("expanded_url", createOptional(Schema.create(Type.STRING)), null, null));    avroSchema.setFields(fields);    return avroSchema;}
d41c3b267562427f94eac59360f675a4742a4983009d2c84cbfd33dc2c41073b
extractRecord
private Record extractRecord(String idPrefix, Schema avroSchema, Status status)
{    User user = status.getUser();    Record doc = new Record(avroSchema);    doc.put("id", idPrefix + status.getId());    doc.put("created_at", formatterTo.format(status.getCreatedAt()));    doc.put("retweet_count", status.getRetweetCount());    doc.put("retweeted", status.isRetweet());    doc.put("in_reply_to_user_id", status.getInReplyToUserId());    doc.put("in_reply_to_status_id", status.getInReplyToStatusId());    addString(doc, "source", status.getSource());    addString(doc, "text", status.getText());    MediaEntity[] mediaEntities = status.getMediaEntities();    if (mediaEntities.length > 0) {        addString(doc, "media_url_https", mediaEntities[0].getMediaURLHttps());        addString(doc, "expanded_url", mediaEntities[0].getExpandedURL());    }    doc.put("user_friends_count", user.getFriendsCount());    doc.put("user_statuses_count", user.getStatusesCount());    doc.put("user_followers_count", user.getFollowersCount());    addString(doc, "user_location", user.getLocation());    addString(doc, "user_description", user.getDescription());    addString(doc, "user_screen_name", user.getScreenName());    addString(doc, "user_name", user.getName());    return doc;}
3a0baa9e8c249f2a1bbfe714caa9141b66b656a14839b84a7a374ed2d1cbf9b7
serializeToAvro
private byte[] serializeToAvro(Schema avroSchema, List<Record> docList) throws IOException
{    serializationBuffer.reset();    dataFileWriter.create(avroSchema, serializationBuffer);    for (Record doc2 : docList) {        dataFileWriter.append(doc2);    }    dataFileWriter.close();    return serializationBuffer.toByteArray();}
f7982740048bc368e251dc268f9509ed13c44caad0293c0bc3eba4dbf01a8484
createOptional
private Schema createOptional(Schema schema)
{    return Schema.createUnion(Arrays.asList(new Schema[] { schema, Schema.create(Type.NULL) }));}
2d9f4e05ef379c04f21f2c5a248993a01ec8f43e71dbfcdbc4ff3350fb8b5f53
addString
private void addString(Record doc, String avroField, String val)
{    if (val == null) {        return;    }    doc.put(avroField, val);    totalTextIndexed += val.length();}
e2bf19b21d89391f1d0e8dec1c9238e30d6e4816d44de2dc55d067a0d2e23d32
logStats
private void logStats()
{    double mbIndexed = totalTextIndexed / (1024 * 1024.0);    long seconds = (System.currentTimeMillis() - startTime) / 1000;    seconds = Math.max(seconds, 1);    LOGGER.info(String.format("Total docs indexed: %s, total skipped docs: %s", numFormatter.format(docCount), numFormatter.format(skippedDocs)));    LOGGER.info(String.format("    %s docs/second", numFormatter.format(docCount / seconds)));    LOGGER.info(String.format("Run took %s seconds and processed:", numFormatter.format(seconds)));    LOGGER.info(String.format("    %s MB/sec sent to index", numFormatter.format(((float) totalTextIndexed / (1024 * 1024)) / seconds)));    LOGGER.info(String.format("    %s MB text sent to index", numFormatter.format(mbIndexed)));    LOGGER.info(String.format("There were %s exceptions ignored: ", numFormatter.format(exceptionCount)));}
a0ff56882a0415f5df3a4a87d1b6fb3c26de85f50834c3bf27cf28056cb9bf32
onDeletionNotice
public void onDeletionNotice(StatusDeletionNotice statusDeletionNotice)
{}
75bec7d8a77dbf99075b7f7ba283293563ee7bc56cfbbcfd02399ec051e9be7e
onScrubGeo
public void onScrubGeo(long userId, long upToStatusId)
{}
e69c9a8ddf03a4bf3e5220da80edb8f77ada4a8c5afeb52911d0e21885985daf
onStallWarning
public void onStallWarning(StallWarning warning)
{}
a973a4def2413c71eeb8f37946a54527189c6317a86155ebc53579f8d839f2e1
onTrackLimitationNotice
public void onTrackLimitationNotice(int numberOfLimitedStatuses)
{}
617f4cd653f643c8c7c231e123eb247ca0cd35f929876ce3dfd190e7818e0eb3
onException
public void onException(Exception e)
{    LOGGER.error("Exception while streaming tweets", e);}
dcc511f35190533c2d6fcc6073d66b12e111f5004c64ff08ccc3609a06ab844d
getBatchSize
public long getBatchSize()
{    return maxBatchSize;}
ca86f0db8b699367a1e071192b0ab724903096b25a11d522de42a85bae0700a9
setUp
public static void setUp()
{    try {        Assume.assumeNotNull(InetAddress.getByName("stream.twitter.com"));    } catch (UnknownHostException e) {                Assume.assumeTrue(false);    }}
374f30b9565fa26944e766e4b0405ecb054a03175df55727b3e28dc9fd8468ac
testBasic
public void testBasic() throws Exception
{    String consumerKey = System.getProperty("twitter.consumerKey");    Assume.assumeNotNull(consumerKey);    String consumerSecret = System.getProperty("twitter.consumerSecret");    Assume.assumeNotNull(consumerSecret);    String accessToken = System.getProperty("twitter.accessToken");    Assume.assumeNotNull(accessToken);    String accessTokenSecret = System.getProperty("twitter.accessTokenSecret");    Assume.assumeNotNull(accessTokenSecret);    Context context = new Context();    context.put("consumerKey", consumerKey);    context.put("consumerSecret", consumerSecret);    context.put("accessToken", accessToken);    context.put("accessTokenSecret", accessTokenSecret);    context.put("maxBatchDurationMillis", "1000");    TwitterSource source = new TwitterSource();    source.configure(context);    Map<String, String> channelContext = new HashMap();    channelContext.put("capacity", "1000000");        channelContext.put("keep-alive", "0");    Channel channel = new MemoryChannel();    Configurables.configure(channel, new Context(channelContext));    Sink sink = new LoggerSink();    sink.setChannel(channel);    sink.start();    DefaultSinkProcessor proc = new DefaultSinkProcessor();    proc.setSinks(Collections.singletonList(sink));    SinkRunner sinkRunner = new SinkRunner(proc);    sinkRunner.start();    ChannelSelector rcs = new ReplicatingChannelSelector();    rcs.setChannels(Collections.singletonList(channel));    ChannelProcessor chp = new ChannelProcessor(rcs);    source.setChannelProcessor(chp);    source.start();    Thread.sleep(5000);    source.stop();    sinkRunner.stop();    sink.stop();}
1fbdd031aa810786750ed47645a8232198074b1443098663501be8e51a52c351
testCarrotDateFormatBug
public void testCarrotDateFormatBug() throws Exception
{    SimpleDateFormat formatterFrom = new SimpleDateFormat("EEE MMM dd HH:mm:ss Z yyyy");    formatterFrom.parse("Fri Oct 26 22:53:55 +0000 2012");}
27681e68ec2a1eb903f955680ebe003ceb3707295c8aad884b692d378c6e37cf
setup
public void setup() throws Exception
{    File agentDir = StagedInstall.getInstance().getStageDir();    LOGGER.debug("Using agent stage dir: {}", agentDir);    File testDir = new File(agentDir, TestConfig.class.getName());    if (testDir.exists()) {        FileUtils.deleteDirectory(testDir);    }    assertTrue(testDir.mkdirs());    agentProps = new Properties();    agentEnv = new HashMap<>();    agentOptions = new HashMap<>();    agentOptions.put("-C", getAdditionalClassPath());        agentProps.put("agent.sources.seq-01.type", "seq");    agentProps.put("agent.sources.seq-01.totalEvents", "100");    agentProps.put("agent.sources.seq-01.channels", "mem-01 mem-02 mem-03");    agentProps.put("agent.channels.mem-01.type", "MEMORY");    agentProps.put("agent.channels.mem-01.capacity", String.valueOf(100000));    agentProps.put("agent.channels.mem-02.type", "MEMORY");    agentProps.put("agent.channels.mem-02.capacity", String.valueOf(100000));    agentProps.put("agent.channels.mem-03.type", "MEMORY");    agentProps.put("agent.channels.mem-04.capacity", String.valueOf(100000));    sinkOutputDir1 = new File(testDir, "out1");    assertTrue("Unable to create sink output dir: " + sinkOutputDir1.getPath(), sinkOutputDir1.mkdir());    sinkOutputDir2 = new File(testDir, "out2");    assertTrue("Unable to create sink output dir: " + sinkOutputDir2.getPath(), sinkOutputDir2.mkdir());    sinkOutputDir3 = new File(testDir, "out3");    assertTrue("Unable to create sink output dir: " + sinkOutputDir3.getPath(), sinkOutputDir3.mkdir());    environmentVariables.set("HADOOP_CREDSTORE_PASSWORD", "envSecret");    agentEnv.put("dirname_env", sinkOutputDir1.getAbsolutePath());    agentEnv.put("HADOOP_CREDSTORE_PASSWORD", "envSecret");    hadoopCredStore = new File(testDir, "credstore.jceks");    String providerPath = "jceks://file/" + hadoopCredStore.getAbsolutePath();    ToolRunner.run(new Configuration(), new CredentialShell(), ("create dirname_hadoop -value " + sinkOutputDir3.getAbsolutePath() + " -provider " + providerPath).split(" "));    agentProps.put("agent.sinks.roll-01.channel", "mem-01");    agentProps.put("agent.sinks.roll-01.type", "FILE_ROLL");    agentProps.put("agent.sinks.roll-01.sink.directory", "${filter-01[\"dirname_env\"]}");    agentProps.put("agent.sinks.roll-01.sink.rollInterval", "0");    agentProps.put("agent.sinks.roll-02.channel", "mem-02");    agentProps.put("agent.sinks.roll-02.type", "FILE_ROLL");    agentProps.put("agent.sinks.roll-02.sink.directory", sinkOutputDir2.getParentFile().getAbsolutePath() + "/${filter-02['out2']}");    agentProps.put("agent.sinks.roll-02.sink.rollInterval", "0");    agentProps.put("agent.sinks.roll-03.channel", "mem-03");    agentProps.put("agent.sinks.roll-03.type", "FILE_ROLL");    agentProps.put("agent.sinks.roll-03.sink.directory", "${filter-03[dirname_hadoop]}");    agentProps.put("agent.sinks.roll-03.sink.rollInterval", "0");    agentProps.put("agent.configfilters.filter-01.type", "env");    agentProps.put("agent.configfilters.filter-02.type", "external");    agentProps.put("agent.configfilters.filter-02.command", "echo");    agentProps.put("agent.configfilters.filter-03.type", "hadoop");    agentProps.put("agent.configfilters.filter-03.credential.provider.path", providerPath);    agentProps.put("agent.sources", "seq-01");    agentProps.put("agent.channels", "mem-01 mem-02 mem-03");    agentProps.put("agent.sinks", "roll-01 roll-02 roll-03");    agentProps.put("agent.configfilters", "filter-01 filter-02 filter-03");}
7a7c70ca2d0fd1f25ac7dea2b6b17eafc4260071f98d06d5046e4d48d3b68ed4
getAdditionalClassPath
private String getAdditionalClassPath() throws Exception
{    URL resource = this.getClass().getClassLoader().getResource("classpath.txt");    Path path = Paths.get(Objects.requireNonNull(resource).getPath());    return Files.readAllLines(path).stream().findFirst().orElse("");}
7c529460b940c419ef707bd1846a5575ea1bfc48c129127836c31f0184c1d8fb
teardown
public void teardown() throws Exception
{    StagedInstall.getInstance().stopAgent();}
0d9f94ca50d01f54e604a02505cbe32cb5eebcee9b30c93dc2f98f4b7d36be17
validateSeenEvents
private void validateSeenEvents(File outDir, int outFiles, int events) throws IOException
{    File[] sinkOutputDirChildren = outDir.listFiles();    assertEquals("Unexpected number of files in output dir", outFiles, sinkOutputDirChildren.length);    Set<String> seenEvents = new HashSet<>();    for (File outFile : sinkOutputDirChildren) {        Scanner scanner = new Scanner(outFile);        while (scanner.hasNext()) {            seenEvents.add(scanner.nextLine());        }    }    for (int event = 0; event < events; event++) {        assertTrue("Missing event: {" + event + "}", seenEvents.contains(String.valueOf(event)));    }}
2cd70cf69603ac84d29a8a8454417d6d2a25e21e185b85e41f67995f77875cd0
testConfigReplacement
public void testConfigReplacement() throws Exception
{    LOGGER.debug("testConfigReplacement() started.");    StagedInstall.getInstance().startAgent("agent", agentProps, agentEnv, agentOptions);        TimeUnit.SECONDS.sleep(10);        validateSeenEvents(sinkOutputDir1, 1, 100);    validateSeenEvents(sinkOutputDir2, 1, 100);    validateSeenEvents(sinkOutputDir3, 1, 100);    LOGGER.debug("Processed all the events!");    LOGGER.debug("testConfigReplacement() ended.");}
9f0c3e7ce014ca78e85378f101e12fdd0bb70d3e555049235ebe849b941c2c22
testConfigReload
public void testConfigReload() throws Exception
{    LOGGER.debug("testConfigReplacement() started.");    agentProps.put("agent.channels.mem-01.transactionCapacity", "10");    agentProps.put("agent.sinks.roll-01.sink.batchSize", "20");    StagedInstall.getInstance().startAgent("agent", agentProps, agentEnv, agentOptions);        TimeUnit.SECONDS.sleep(10);        validateSeenEvents(sinkOutputDir1, 0, 0);        validateSeenEvents(sinkOutputDir2, 1, 100);    validateSeenEvents(sinkOutputDir3, 1, 100);    LOGGER.debug("Processed all the events!");        agentProps.put("agent.channels.mem-01.transactionCapacity", "20");    StagedInstall.getInstance().reconfigure(agentProps);        TimeUnit.SECONDS.sleep(40);        validateSeenEvents(sinkOutputDir1, 1, 100);    LOGGER.debug("testConfigReplacement() ended.");}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    /* Create 3 temp dirs, each used as value within agentProps */    final File sinkOutputDir = Files.createTempDir();    tempResources.add(sinkOutputDir);    final String sinkOutputDirPath = sinkOutputDir.getCanonicalPath();    LOGGER.info("Created rolling file sink's output dir: " + sinkOutputDirPath);    final File channelCheckpointDir = Files.createTempDir();    tempResources.add(channelCheckpointDir);    final String channelCheckpointDirPath = channelCheckpointDir.getCanonicalPath();    LOGGER.info("Created file channel's checkpoint dir: " + channelCheckpointDirPath);    final File channelDataDir = Files.createTempDir();    tempResources.add(channelDataDir);    final String channelDataDirPath = channelDataDir.getCanonicalPath();    LOGGER.info("Created file channel's data dir: " + channelDataDirPath);    /* Build props to pass to flume agent */    Properties agentProps = new Properties();        agentProps.put("a1.channels", "c1");    agentProps.put("a1.sources", "r1");    agentProps.put("a1.sinks", "k1");        agentProps.put("a1.channels.c1.type", "FILE");    agentProps.put("a1.channels.c1.checkpointDir", channelCheckpointDirPath);    agentProps.put("a1.channels.c1.dataDirs", channelDataDirPath);        agentProps.put("a1.sources.r1.channels", "c1");    agentProps.put("a1.sources.r1.type", "EXEC");    agentProps.put("a1.sources.r1.command", "seq 1 100");        agentProps.put("a1.sinks.k1.channel", "c1");    agentProps.put("a1.sinks.k1.type", "FILE_ROLL");    agentProps.put("a1.sinks.k1.sink.directory", sinkOutputDirPath);    agentProps.put("a1.sinks.k1.sink.rollInterval", "0");    this.agentProps = agentProps;    this.sinkOutputDir = sinkOutputDir;}
c6aaebb5a52567751db8dc8e1cb9dd4a4e582ef964a374b376c6a04f741802dc
tearDown
public void tearDown() throws Exception
{    StagedInstall.getInstance().stopAgent();    for (File tempResource : tempResources) {        tempResource.delete();    }    agentProps = null;}
c357c100c203401a8ca39d09584bfa818f5393ec95301366289f86b413fd4e5c
testInOut
public void testInOut() throws Exception
{    LOGGER.debug("testInOut() started.");    StagedInstall.getInstance().startAgent("a1", agentProps);        TimeUnit.SECONDS.sleep(10);        /* Create expected output */    StringBuffer sb = new StringBuffer();    for (int i = 1; i <= 100; i++) {        sb.append(i).append("\n");    }    String expectedOutput = sb.toString();    LOGGER.info("Created expected output: " + expectedOutput);    /* Create actual output file */    File[] sinkOutputDirChildren = sinkOutputDir.listFiles();        Assert.assertEquals("Expected FILE_ROLL sink's dir to have only 1 child," + " but found " + sinkOutputDirChildren.length + " children.", 1, sinkOutputDirChildren.length);    File actualOutput = sinkOutputDirChildren[0];    if (!Files.toString(actualOutput, Charsets.UTF_8).equals(expectedOutput)) {        LOGGER.error("Actual output doesn't match expected output.\n");        throw new AssertionError("FILE_ROLL sink's actual output doesn't " + "match expected output.");    }    LOGGER.debug("testInOut() ended.");}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    port = StagedInstall.getInstance().startAgent("rpccagent", CONFIG_FILE_PRCCLIENT_TEST);}
c6aaebb5a52567751db8dc8e1cb9dd4a4e582ef964a374b376c6a04f741802dc
tearDown
public void tearDown() throws Exception
{    StagedInstall.getInstance().stopAgent();}
1ad8c3b429dfdc0d4b37583e04bb4647bb3f30bf8c6176d0248b761001e040ac
testRpcClient
public void testRpcClient() throws Exception
{    StagedInstall.waitUntilPortOpens("localhost", port, 20000);    RpcClient client = RpcClientFactory.getDefaultInstance("localhost", port);    String[] text = { "foo", "bar", "xyz", "abc" };    for (String str : text) {        client.append(EventBuilder.withBody(str.getBytes()));    }}
259a7bcd21565e0c4543988b7492069953660bb71c81d98797380438fa6bbd17
testFailure
public void testFailure() throws Exception
{    try {        int port = StagedInstall.getInstance().startAgent("rpccagent", CONFIG_FILE_PRCCLIENT_TEST);        StagedInstall.waitUntilPortOpens("localhost", port, 20000);        RpcClient client = RpcClientFactory.getDefaultInstance("localhost", port);        String[] text = { "foo", "bar", "xyz", "abc" };        for (String str : text) {            client.append(EventBuilder.withBody(str.getBytes()));        }                StagedInstall.getInstance().stopAgent();                try {            client.append(EventBuilder.withBody("test".getBytes()));            Assert.fail("EventDeliveryException expected but not raised");        } catch (EventDeliveryException ex) {            System.out.println("Attempting to close client");            client.close();        }    } finally {        if (StagedInstall.getInstance().isRunning()) {            StagedInstall.getInstance().stopAgent();        }    }}
27681e68ec2a1eb903f955680ebe003ceb3707295c8aad884b692d378c6e37cf
setup
public void setup() throws Exception
{    File agentDir = StagedInstall.getInstance().getStageDir();    LOGGER.debug("Using agent stage dir: {}", agentDir);    File testDir = new File(agentDir, TestSpooldirSource.class.getName());    assertTrue(testDir.mkdirs());    File spoolParentDir = new File(testDir, "spools");    assertTrue("Unable to create sink output dir: " + spoolParentDir.getPath(), spoolParentDir.mkdir());    final int NUM_SOURCES = 100;    agentProps = new Properties();    List<String> spooldirSrcNames = Lists.newArrayList();    String channelName = "mem-01";        for (int i = 0; i < NUM_SOURCES; i++) {        String srcName = String.format("spooldir-%03d", i);        File spoolDir = new File(spoolParentDir, srcName);        assertTrue(spoolDir.mkdir());        spooldirSrcNames.add(srcName);        spoolDirs.add(spoolDir);        agentProps.put(String.format("agent.sources.%s.type", srcName), "SPOOLDIR");        agentProps.put(String.format("agent.sources.%s.spoolDir", srcName), spoolDir.getPath());        agentProps.put(String.format("agent.sources.%s.channels", srcName), channelName);    }        agentProps.put("agent.channels.mem-01.type", "MEMORY");    agentProps.put("agent.channels.mem-01.capacity", String.valueOf(100000));    sinkOutputDir = new File(testDir, "out");    assertTrue("Unable to create sink output dir: " + sinkOutputDir.getPath(), sinkOutputDir.mkdir());    agentProps.put("agent.sinks.roll-01.channel", channelName);    agentProps.put("agent.sinks.roll-01.type", "FILE_ROLL");    agentProps.put("agent.sinks.roll-01.sink.directory", sinkOutputDir.getPath());    agentProps.put("agent.sinks.roll-01.sink.rollInterval", "0");    agentProps.put("agent.sources", Joiner.on(" ").join(spooldirSrcNames));    agentProps.put("agent.channels", channelName);    agentProps.put("agent.sinks", "roll-01");}
7c529460b940c419ef707bd1846a5575ea1bfc48c129127836c31f0184c1d8fb
teardown
public void teardown() throws Exception
{    StagedInstall.getInstance().stopAgent();}
0383249285bbda17290b2afeae630e3d915b801008d36a270d6bf6a9e5b90a79
getTestString
private String getTestString(int dirNum, int fileNum)
{    return String.format("Test dir %03d, test file %03d.\n", dirNum, fileNum);}
143f9db0c6117b109b581d1295a626465c8f672677098106010ec12ddacfd7cf
createInputTestFiles
private void createInputTestFiles(List<File> spoolDirs, int numFiles, int startNum) throws IOException
{    int numSpoolDirs = spoolDirs.size();    for (int dirNum = 0; dirNum < numSpoolDirs; dirNum++) {        File spoolDir = spoolDirs.get(dirNum);        for (int fileNum = startNum; fileNum < numFiles; fileNum++) {                        File tmp = new File(spoolDir.getParent(), UUID.randomUUID().toString());            Files.append(getTestString(dirNum, fileNum), tmp, Charsets.UTF_8);            File dst = new File(spoolDir, String.format("test-file-%03d", fileNum));                        assertTrue(String.format("Failed to rename %s to %s", tmp, dst), tmp.renameTo(dst));        }    }}
cc0aa5e48aafa45c1283ec64e2a7e7d1b3084af0b61cde717cb2a5ef81e9c01b
validateSeenEvents
private void validateSeenEvents(File outDir, int outFiles, int dirs, int events) throws IOException
{    File[] sinkOutputDirChildren = outDir.listFiles();    assertEquals("Unexpected number of files in output dir", outFiles, sinkOutputDirChildren.length);    Set<String> seenEvents = Sets.newHashSet();    for (File outFile : sinkOutputDirChildren) {        List<String> lines = Files.readLines(outFile, Charsets.UTF_8);        for (String line : lines) {            seenEvents.add(line);        }    }    for (int dirNum = 0; dirNum < dirs; dirNum++) {        for (int fileNum = 0; fileNum < events; fileNum++) {            String event = getTestString(dirNum, fileNum).trim();            assertTrue("Missing event: {" + event + "}", seenEvents.contains(event));        }    }}
4502784dc61e99ed49948f9bfa08e3adee2284ac20d82a1346e8e51b5e5a282c
testManySpooldirs
public void testManySpooldirs() throws Exception
{    LOGGER.debug("testManySpooldirs() started.");    StagedInstall.getInstance().startAgent("agent", agentProps);    final int NUM_FILES_PER_DIR = 10;    createInputTestFiles(spoolDirs, NUM_FILES_PER_DIR, 0);        TimeUnit.SECONDS.sleep(10);        validateSeenEvents(sinkOutputDir, 1, spoolDirs.size(), NUM_FILES_PER_DIR);    LOGGER.debug("Processed all the events!");    LOGGER.debug("testManySpooldirs() ended.");}
1436851f419a4586d6007a609e137a03737805e51d6ab6dcd955389a6758ba8e
syslogSourceTypes
public static Collection syslogSourceTypes()
{    List<Object[]> sourceTypes = new ArrayList<Object[]>();    for (SyslogAgent.SyslogSourceType sourceType : SyslogAgent.SyslogSourceType.values()) {        sourceTypes.add(new Object[] { sourceType });    }    return sourceTypes;}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    agent = new SyslogAgent();    agent.configure(sourceType);}
c6aaebb5a52567751db8dc8e1cb9dd4a4e582ef964a374b376c6a04f741802dc
tearDown
public void tearDown() throws Exception
{    if (agent != null) {        agent.stop();        agent = null;    }}
08e9736a31f90f6022ae77301ad0dc3756d01e9ebf00b8fd465df2157ecfd366
testKeepFields
public void testKeepFields() throws Exception
{    LOGGER.debug("testKeepFields() started.");    agent.start("all");    agent.runKeepFieldsTest();    LOGGER.debug("testKeepFields() ended.");}
925ac0b40137df147b2faeda6854e697f7fad98533cb13ef73c9dc54837c6604
testRemoveFields
public void testRemoveFields() throws Exception
{    LOGGER.debug("testRemoveFields() started.");    agent.start("none");    agent.runKeepFieldsTest();    LOGGER.debug("testRemoveFields() ended.");}
b83ebfd22a5f4e166b2342360a92947f3055dcb029bd398298a35f3ab1d0f93e
testKeepTimestampAndHostname
public void testKeepTimestampAndHostname() throws Exception
{    LOGGER.debug("testKeepTimestampAndHostname() started.");    agent.start("timestamp hostname");    agent.runKeepFieldsTest();    LOGGER.debug("testKeepTimestampAndHostname() ended.");}
b2a29f25fad6f120b197a27fe1f5d62bd86fa5454c183bfb77b4de29719428a2
getInstance
public static synchronized StagedInstall getInstance() throws Exception
{    if (INSTANCE == null) {        INSTANCE = new StagedInstall();    }    return INSTANCE;}
f58e9e53336cee2bb46812921ff061ab7bc6b7570618f9c4f6ecdfb9fa1cf35a
findFreePort
public static int findFreePort() throws IOException
{    try (ServerSocket socket = new ServerSocket(0)) {        return socket.getLocalPort();    }}
da131b0ed0c7b2bdf57720a0dd0895fccf8c1752f3352e4aabdb173e4fcb4b1f
isRunning
public synchronized boolean isRunning()
{    return process != null;}
a6b8dee44817390a78d1a64883ae40a4870eb3198dd4c40bfe45e6beaade4c34
stopAgent
public synchronized void stopAgent() throws Exception
{    if (process == null) {        throw new Exception("Process not found");    }    LOGGER.info("Shutting down agent process");    process.destroy();    process.waitFor();    process = null;    consumer.interrupt();    consumer = null;    configFilePath = null;    Runtime.getRuntime().removeShutdownHook(shutdownHook);    shutdownHook = null;        Thread.sleep(3000);}
4a72c227a609f492b6ce3e0d85d30e2ddc83a9af4c8e8eeb7c2a4cd6b123eb53
startAgent
public synchronized int startAgent(String name, String configResource) throws Exception
{    if (process != null) {        throw new Exception("A process is already running");    }    int port = findFreePort();    Properties props = new Properties();    props.load(ClassLoader.getSystemResourceAsStream(configResource));    props.put("rpccagent.sources.src1.port", String.valueOf(port));    startAgent(name, props);    return port;}
24e184938bca7fdf8f79a0028459c6048a12a63f1888e91f196b9226be4668ea
startAgent
public synchronized void startAgent(String name, Properties properties) throws Exception
{    startAgent(name, properties, new HashMap<>(), new HashMap<>());}
1fda7198ee39a19cf519edd0800646c08486617d7962c177f3120b197570dea9
startAgent
public synchronized void startAgent(String name, Properties properties, Map<String, String> environmentVariables, Map<String, String> commandOptions) throws Exception
{    Preconditions.checkArgument(!name.isEmpty(), "agent name must not be empty");    Preconditions.checkNotNull(properties, "properties object must not be null");    agentName = name;    if (process != null) {        throw new Exception("A process is already running");    }    LOGGER.info("Starting process for agent: " + agentName + " using config: " + properties);    File configFile = createConfigurationFile(agentName, properties);    configFilePath = configFile.getCanonicalPath();    String configFileName = configFile.getName();    String logFileName = "flume-" + agentName + "-" + configFileName.substring(0, configFileName.indexOf('.')) + ".log";    LOGGER.info("Created configuration file: " + configFilePath);    ImmutableList.Builder<String> builder = new ImmutableList.Builder<String>();    builder.add(launchScriptPath);    builder.add("agent");    builder.add("--conf", confDirPath);    builder.add("--conf-file", configFilePath);    builder.add("--name", agentName);    builder.add("-D" + ENV_FLUME_LOG_DIR + "=" + logDirPath);    builder.add("-D" + ENV_FLUME_ROOT_LOGGER + "=" + ENV_FLUME_ROOT_LOGGER_VALUE);    builder.add("-D" + ENV_FLUME_LOG_FILE + "=" + logFileName);    commandOptions.forEach((key, value) -> builder.add(key, value));    List<String> cmdArgs = builder.build();    LOGGER.info("Using command: " + Joiner.on(" ").join(cmdArgs));    ProcessBuilder pb = new ProcessBuilder(cmdArgs);    Map<String, String> env = pb.environment();    env.putAll(environmentVariables);    LOGGER.debug("process environment: " + env);    pb.directory(baseDir);    pb.redirectErrorStream(true);    process = pb.start();    consumer = new ProcessInputStreamConsumer(process.getInputStream());    consumer.start();    shutdownHook = new ProcessShutdownHook();    Runtime.getRuntime().addShutdownHook(shutdownHook);        Thread.sleep(3000);}
9a081136c515323b5614160502ecf63b2afe755901fa101e39a388edab074e16
reconfigure
public synchronized void reconfigure(Properties properties) throws Exception
{    File configFile = createConfigurationFile(agentName, properties);    Files.copy(configFile, new File(configFilePath));    configFile.delete();    LOGGER.info("Updated agent config file: " + configFilePath);}
5257abdf678761184c69efb2011491f5cbf058661602d17ca659dc9b02da988c
getStageDir
public synchronized File getStageDir()
{    return stageDir;}
267d35f5680019747983da163429060c2a71b1ad292a0e69ede6627e3d52ae84
createConfigurationFile
private File createConfigurationFile(String agentName, Properties properties) throws Exception
{    Preconditions.checkNotNull(properties, "properties object must not be null");    File file = File.createTempFile("agent", "config.properties", stageDir);    OutputStream os = null;    try {        os = new FileOutputStream(file);        properties.store(os, "Config file for agent: " + agentName);    } catch (Exception ex) {        LOGGER.error("Failed to create config file: " + file, ex);        throw ex;    } finally {        if (os != null) {            try {                os.close();            } catch (Exception ex) {                LOGGER.warn("Unable to close config file stream", ex);            }        }    }    return file;}
c18f15ad3eb0307673fbddc4b209c3976b9fdcf02ede401d096590652c60e63d
giveExecutePermissions
private void giveExecutePermissions(File file) throws Exception
{    String[] args = { "chmod", "+x", file.getCanonicalPath() };    Runtime.getRuntime().exec(args);    LOGGER.info("Set execute permissions on " + file);}
da089fc0a8b636080b9b95b936aa9506953cf570cf79d83c6550e1366a9ca918
untarTarFile
private void untarTarFile(File tarFile, File destDir) throws Exception
{    TarArchiveInputStream tarInputStream = null;    try {        tarInputStream = new TarArchiveInputStream(new FileInputStream(tarFile));        TarArchiveEntry entry = null;        while ((entry = tarInputStream.getNextTarEntry()) != null) {            String name = entry.getName();            LOGGER.debug("Next file: " + name);            File destFile = new File(destDir, entry.getName());            if (entry.isDirectory()) {                destFile.mkdirs();                continue;            }            File destParent = destFile.getParentFile();            destParent.mkdirs();            OutputStream entryOutputStream = null;            try {                entryOutputStream = new FileOutputStream(destFile);                byte[] buffer = new byte[2048];                int length = 0;                while ((length = tarInputStream.read(buffer, 0, 2048)) != -1) {                    entryOutputStream.write(buffer, 0, length);                }            } catch (Exception ex) {                LOGGER.error("Exception while expanding tar file", ex);                throw ex;            } finally {                if (entryOutputStream != null) {                    try {                        entryOutputStream.close();                    } catch (Exception ex) {                        LOGGER.warn("Failed to close entry output stream", ex);                    }                }            }        }    } catch (Exception ex) {        LOGGER.error("Exception caught while untarring tar file: " + tarFile.getAbsolutePath(), ex);        throw ex;    } finally {        if (tarInputStream != null) {            try {                tarInputStream.close();            } catch (Exception ex) {                LOGGER.warn("Unable to close tar input stream: " + tarFile.getCanonicalPath(), ex);            }        }    }}
100bdf35a41efc506858ee3d0e19b6deb097aff78f24da8ece4ba5691f5aa6f8
gunzipDistTarball
private File gunzipDistTarball(File tarballFile, File destDir) throws Exception
{    File tarFile = null;    InputStream tarballInputStream = null;    OutputStream tarFileOutputStream = null;    try {        tarballInputStream = new GZIPInputStream(new FileInputStream(tarballFile));        File temp2File = File.createTempFile("flume", "-bin", destDir);        String temp2FilePath = temp2File.getCanonicalPath();        temp2File.delete();        tarFile = new File(temp2FilePath + ".tar");        LOGGER.info("Tarball being unzipped to: " + tarFile.getCanonicalPath());        tarFileOutputStream = new FileOutputStream(tarFile);        int length = 0;        byte[] buffer = new byte[10240];        while ((length = tarballInputStream.read(buffer, 0, 10240)) != -1) {            tarFileOutputStream.write(buffer, 0, length);        }    } catch (Exception ex) {        LOGGER.error("Exception caught while unpacking the tarball", ex);        throw ex;    } finally {        if (tarballInputStream != null) {            try {                tarballInputStream.close();            } catch (Exception ex) {                LOGGER.warn("Unable to close input stream to tarball", ex);            }        }        if (tarFileOutputStream != null) {            try {                tarFileOutputStream.close();            } catch (Exception ex) {                LOGGER.warn("Unable to close tarfile output stream", ex);            }        }    }    return tarFile;}
fd00eb9491516c8637dff4cde5261e6c01651e3ff1c1a97896b3754e272a3d73
getStagingDirectory
private File getStagingDirectory() throws Exception
{    File targetDir = new File("target");    if (!targetDir.exists() || !targetDir.isDirectory()) {                targetDir = new File(System.getProperty("java.io.tmpdir"));    }    File testDir = new File(targetDir, "test");    testDir.mkdirs();    File tempFile = File.createTempFile("flume", "_stage", testDir);    String absFileName = tempFile.getCanonicalPath();    tempFile.delete();    File stageDir = new File(absFileName + "_dir");    if (stageDir.exists()) {        throw new Exception("Stage directory exists: " + stageDir.getCanonicalPath());    }    stageDir.mkdirs();    LOGGER.info("Staging Directory: " + stageDir.getCanonicalPath());    return stageDir;}
a05b965572f6d53c43deec264419ed1d2a9aad0c9778a563fcf3e032d943c348
getRelativeTarballPath
private String getRelativeTarballPath() throws Exception
{    String tarballPath = null;    File dir = new File("..");    while (dir != null && dir.isDirectory()) {        File testFile = new File(dir, "flume-ng-dist/target");        if (testFile.exists() && testFile.isDirectory()) {            LOGGER.info("Found candidate dir: " + testFile.getCanonicalPath());            File[] candidateFiles = testFile.listFiles(new FileFilter() {                @Override                public boolean accept(File pathname) {                    String name = pathname.getName();                    if (name != null && name.startsWith("apache-flume-") && name.endsWith("-bin.tar.gz")) {                        return true;                    }                    return false;                }            });                        if (candidateFiles != null && candidateFiles.length > 0) {                if (candidateFiles.length == 1) {                                        File file = candidateFiles[0];                    if (file.isFile() && file.canRead()) {                        tarballPath = file.getCanonicalPath();                        LOGGER.info("Found file: " + tarballPath);                        break;                    } else {                        LOGGER.warn("Invalid file: " + file.getCanonicalPath());                    }                } else {                    StringBuilder sb = new StringBuilder("Multiple candate tarballs");                    sb.append(" found in directory ");                    sb.append(testFile.getCanonicalPath()).append(": ");                    boolean first = true;                    for (File file : candidateFiles) {                        if (first) {                            first = false;                            sb.append(" ");                        } else {                            sb.append(", ");                        }                        sb.append(file.getCanonicalPath());                    }                    sb.append(". All these files will be ignored.");                    LOGGER.warn(sb.toString());                }            }        }        dir = dir.getParentFile();    }    return tarballPath;}
155bb26e6e044e511a6b4e1abe493e1d98e838ec86fc602edcf25c1a5b9f7f03
accept
public boolean accept(File pathname)
{    String name = pathname.getName();    if (name != null && name.startsWith("apache-flume-") && name.endsWith("-bin.tar.gz")) {        return true;    }    return false;}
a1766d9b4c41339e7c2d581d322204c90d5885e2639ae1ffc0671fba4f715339
waitUntilPortOpens
public static void waitUntilPortOpens(String host, int port, long timeout) throws IOException, InterruptedException
{    long startTime = System.currentTimeMillis();    Socket socket;    boolean connected = false;        while (System.currentTimeMillis() - startTime < timeout) {        try {            socket = new Socket(host, port);            socket.close();            connected = true;            break;        } catch (IOException e) {            Thread.sleep(2000);        }    }    if (!connected) {        throw new IOException("Port not opened within specified timeout.");    }}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    synchronized (StagedInstall.this) {        if (StagedInstall.this.process != null) {            process.destroy();        }    }}
4560d80c2474cc2770be19fbc06c60741920c59992e6b13524f8a5b688ec285a
run
public void run()
{    try {        byte[] buffer = new byte[1024];        int length = 0;        while ((length = is.read(buffer, 0, 1024)) != -1) {            LOGGER.info("[process-out] " + new String(buffer, 0, length));        }    } catch (Exception ex) {        LOGGER.warn("Error while reading process stream", ex);    }}
210eee3d731623cb7c6189497cc462f9c459d9c81b6e0fe12b4b36ce53a197b7
toString
public String toString()
{    return syslogSourceType;}
a189ef8e4d6ba45417b4ec9324b0ec5dcb6a4edad5f044b5cfb962c48acf2725
setRandomPort
public void setRandomPort() throws IOException
{    ServerSocket s = new ServerSocket(0);    port = s.getLocalPort();    s.close();}
8e3403958d2004e4be3603d1a090d61b821cccadfed513206d47f97ae8134d1e
configure
public void configure(SyslogSourceType sourceType) throws IOException
{    /* Create 3 temp dirs, each used as value within agentProps */    sinkOutputDir = Files.createTempDir();    tempResources.add(sinkOutputDir);    final String sinkOutputDirPath = sinkOutputDir.getCanonicalPath();    LOGGER.info("Created rolling file sink's output dir: " + sinkOutputDirPath);    /* Build props to pass to flume agent */    agentProps = new Properties();        agentProps.put("a1.channels", "c1");    agentProps.put("a1.sources", "r1");    agentProps.put("a1.sinks", "k1");        agentProps.put("a1.channels.c1.type", "memory");    agentProps.put("a1.channels.c1.capacity", "1000");    agentProps.put("a1.channels.c1.transactionCapacity", "100");        agentProps.put("a1.sources.r1.channels", "c1");    agentProps.put("a1.sources.r1.type", sourceType.toString());    agentProps.put("a1.sources.r1.host", hostname);    if (sourceType.equals(SyslogSourceType.MULTIPORTTCP)) {        agentProps.put("a1.sources.r1.ports", Integer.toString(port));    } else {        agentProps.put("a1.sources.r1.port", Integer.toString(port));    }        agentProps.put("a1.sinks.k1.channel", "c1");    agentProps.put("a1.sinks.k1.sink.directory", sinkOutputDirPath);    agentProps.put("a1.sinks.k1.type", "FILE_ROLL");    agentProps.put("a1.sinks.k1.sink.rollInterval", "0");}
e2aa19c6f210bbc1de8d5546f8da15e01bf6e0ac63dcf71c88674bcea9f02091
start
public void start(String keepFields) throws Exception
{    this.keepFields = keepFields;        agentProps.put("a1.sources.r1.keepFields", keepFields);        sinkOutputDir.mkdir();    /* Start flume agent */    StagedInstall.getInstance().startAgent("a1", agentProps);    LOGGER.info("Started flume agent with syslog source on port " + port);        int numberOfAttempts = 0;    while (client == null) {        try {            client = new BufferedOutputStream(new Socket(hostname, port).getOutputStream());        } catch (IOException e) {            if (++numberOfAttempts >= DEFAULT_ATTEMPTS) {                throw new AssertionError("Could not connect to source after " + DEFAULT_ATTEMPTS + " attempts with " + DEFAULT_TIMEOUT + " ms timeout.");            }            TimeUnit.MILLISECONDS.sleep(DEFAULT_TIMEOUT);        }    }}
6dfaaf5b0c085b5947807833c5756e8b8afecf8d55cd6115082aa827fa20ad38
isRunning
public boolean isRunning() throws Exception
{    return StagedInstall.getInstance().isRunning();}
58a3bb0fa8ecc3e0a1306beb26f516223d2bf3d47efcbf1262a44af030c64a22
stop
public void stop() throws Exception
{    if (client != null) {        client.close();    }    client = null;    StagedInstall.getInstance().stopAgent();    for (File tempResource : tempResources) {                FileUtils.deleteDirectory(tempResource);    }}
6173d4738a4aadd62c2e6441611daa5ad159f00a603b6cce0abc8fe64ab808e0
runKeepFieldsTest
public void runKeepFieldsTest() throws Exception
{    /* Create expected output and log message */    String logMessage = "<34>1 Oct 11 22:14:15 mymachine su: Test\n";    String expectedOutput = "su: Test\n";    if (keepFields.equals("true") || keepFields.equals("all")) {        expectedOutput = logMessage;    } else if (!keepFields.equals("false") && !keepFields.equals("none")) {        if (keepFields.indexOf("hostname") != -1) {            expectedOutput = "mymachine " + expectedOutput;        }        if (keepFields.indexOf("timestamp") != -1) {            expectedOutput = "Oct 11 22:14:15 " + expectedOutput;        }        if (keepFields.indexOf("version") != -1) {            expectedOutput = "1 " + expectedOutput;        }        if (keepFields.indexOf("priority") != -1) {            expectedOutput = "<34>" + expectedOutput;        }    }    LOGGER.info("Created expected output: " + expectedOutput);    /* Send test message to agent */    sendMessage(logMessage);    /* Wait for output file */    int numberOfListDirAttempts = 0;    while (sinkOutputDir.listFiles().length == 0) {        if (++numberOfListDirAttempts >= DEFAULT_ATTEMPTS) {            throw new AssertionError("FILE_ROLL sink hasn't written any files after " + DEFAULT_ATTEMPTS + " attempts with " + DEFAULT_TIMEOUT + " ms timeout.");        }        TimeUnit.MILLISECONDS.sleep(DEFAULT_TIMEOUT);    }        File[] sinkOutputDirChildren = sinkOutputDir.listFiles();    Assert.assertEquals("Expected FILE_ROLL sink's dir to have only 1 child," + " but found " + sinkOutputDirChildren.length + " children.", 1, sinkOutputDirChildren.length);    /* Wait for output file stats to be as expected. */    File outputDirChild = sinkOutputDirChildren[0];    int numberOfStatsAttempts = 0;    while (outputDirChild.length() != expectedOutput.length()) {        if (++numberOfStatsAttempts >= DEFAULT_ATTEMPTS) {            throw new AssertionError("Expected output and FILE_ROLL sink's" + " lengths did not match after " + DEFAULT_ATTEMPTS + " attempts with " + DEFAULT_TIMEOUT + " ms timeout.");        }        TimeUnit.MILLISECONDS.sleep(DEFAULT_TIMEOUT);    }    File actualOutput = sinkOutputDirChildren[0];    if (!Files.toString(actualOutput, Charsets.UTF_8).equals(expectedOutput)) {        LOGGER.error("Actual output doesn't match expected output.\n");        LOGGER.debug("Output: " + Files.toString(actualOutput, Charsets.UTF_8));        throw new AssertionError("FILE_ROLL sink's actual output doesn't " + "match expected output.");    }}
a8ec987eb7cbeaeb8e1f70b367ebccc95d9f0360053926f5724a1d0fa17d1f6c
sendMessage
private void sendMessage(String message) throws IOException
{    client.write(message.getBytes());    client.flush();}
44e47e646d211ca5a1d8346ca9ebd1a4d426a5461d5f758df202e3bc651a0cf4
addGlobalSSLParameters
public static void addGlobalSSLParameters(Properties kafkaProps)
{    if (isSSLEnabled(kafkaProps)) {        addGlobalSSLParameter(kafkaProps, SslConfigs.SSL_KEYSTORE_LOCATION_CONFIG, SSLUtil.getGlobalKeystorePath());        addGlobalSSLParameter(kafkaProps, SslConfigs.SSL_KEYSTORE_PASSWORD_CONFIG, SSLUtil.getGlobalKeystorePassword());        addGlobalSSLParameter(kafkaProps, SslConfigs.SSL_KEYSTORE_TYPE_CONFIG, SSLUtil.getGlobalKeystoreType(null));        addGlobalSSLParameter(kafkaProps, SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, SSLUtil.getGlobalTruststorePath());        addGlobalSSLParameter(kafkaProps, SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, SSLUtil.getGlobalTruststorePassword());        addGlobalSSLParameter(kafkaProps, SslConfigs.SSL_TRUSTSTORE_TYPE_CONFIG, SSLUtil.getGlobalTruststoreType(null));    }}
5480689e9a94a02b3b03d9da6dd19b7650d0510a7ec7f37b1c14afde17a4b35f
addGlobalSSLParameter
private static void addGlobalSSLParameter(Properties kafkaProps, String propName, String globalValue)
{    if (!kafkaProps.containsKey(propName) && globalValue != null) {        kafkaProps.put(propName, globalValue);    }}
6f1c970ae173c77d3688a290c8219ac28bbc32856356c84dad9b26215219a272
isSSLEnabled
private static boolean isSSLEnabled(Properties kafkaProps)
{    String securityProtocol = kafkaProps.getProperty(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG);    return securityProtocol != null && (securityProtocol.equals(SecurityProtocol.SSL.name) || securityProtocol.equals(SecurityProtocol.SASL_SSL.name));}
54cf930d7985a2024b4fca7b84abc2f5ab1a663b227f4fe4db2d19dcf074887a
initSystemProperties
public void initSystemProperties()
{    System.setProperty("javax.net.ssl.keyStore", "global-keystore-path");    System.setProperty("javax.net.ssl.keyStorePassword", "global-keystore-password");    System.setProperty("javax.net.ssl.keyStoreType", "global-keystore-type");    System.setProperty("javax.net.ssl.trustStore", "global-truststore-path");    System.setProperty("javax.net.ssl.trustStorePassword", "global-truststore-password");    System.setProperty("javax.net.ssl.trustStoreType", "global-truststore-type");}
56c3a48d3908790f87b1266e7ee889924061228d823b3669b99775ba369cc62c
clearSystemProperties
public void clearSystemProperties()
{    System.clearProperty("javax.net.ssl.keyStore");    System.clearProperty("javax.net.ssl.keyStorePassword");    System.clearProperty("javax.net.ssl.keyStoreType");    System.clearProperty("javax.net.ssl.trustStore");    System.clearProperty("javax.net.ssl.trustStorePassword");    System.clearProperty("javax.net.ssl.trustStoreType");}
244730c45227e825b88747985a1726d68c63a093b2d0f2b7082ad75dd64f8b78
testSecurityProtocol_PLAINTEXT
public void testSecurityProtocol_PLAINTEXT()
{    Properties kafkaProps = new Properties();    kafkaProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, SecurityProtocol.PLAINTEXT.name);    KafkaSSLUtil.addGlobalSSLParameters(kafkaProps);    assertNoSSLParameters(kafkaProps);}
cb8bab250697dc79a8ea66d1180252e429036ed26e98af5c4009aa23fcbf91e0
testSecurityProtocol_SASL_PLAINTEXT
public void testSecurityProtocol_SASL_PLAINTEXT()
{    Properties kafkaProps = new Properties();    kafkaProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, SecurityProtocol.SASL_PLAINTEXT.name);    KafkaSSLUtil.addGlobalSSLParameters(kafkaProps);    assertNoSSLParameters(kafkaProps);}
d7c5b0f6974e357a44484872998bd87c2e9749fddaf9a288243f55f1691270e6
testSecurityProtocol_SSL
public void testSecurityProtocol_SSL()
{    Properties kafkaProps = new Properties();    kafkaProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, SecurityProtocol.SSL.name);    KafkaSSLUtil.addGlobalSSLParameters(kafkaProps);    assertGlobalSSLParameters(kafkaProps);}
215cffc50093a93c644d45bfcb3bea1f0cdb6a6e488cc9b25e63f2fa08fed962
testSecurityProtocol_SASL_SSL
public void testSecurityProtocol_SASL_SSL()
{    Properties kafkaProps = new Properties();    kafkaProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, SecurityProtocol.SASL_SSL.name);    KafkaSSLUtil.addGlobalSSLParameters(kafkaProps);    assertGlobalSSLParameters(kafkaProps);}
c975e4eb3546b7979c502e687ac67e0fce23956b0832ecbd65694e9e95fdbd46
testComponentParametersNotOverridden
public void testComponentParametersNotOverridden()
{    Properties kafkaProps = new Properties();    kafkaProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, SecurityProtocol.SSL.name);    kafkaProps.put(SslConfigs.SSL_KEYSTORE_LOCATION_CONFIG, "component-keystore-path");    kafkaProps.put(SslConfigs.SSL_KEYSTORE_PASSWORD_CONFIG, "component-keystore-password");    kafkaProps.put(SslConfigs.SSL_KEYSTORE_TYPE_CONFIG, "component-keystore-type");    kafkaProps.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, "component-truststore-path");    kafkaProps.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, "component-truststore-password");    kafkaProps.put(SslConfigs.SSL_TRUSTSTORE_TYPE_CONFIG, "component-truststore-type");    KafkaSSLUtil.addGlobalSSLParameters(kafkaProps);    assertComponentSSLParameters(kafkaProps);}
bbb68a74f04195461bffd047ba3925ad597030c01fd4a8067f2003b8c9ebc2c3
testEmptyGlobalParametersNotAdded
public void testEmptyGlobalParametersNotAdded()
{    Properties kafkaProps = new Properties();    kafkaProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, SecurityProtocol.SSL.name);    clearSystemProperties();    KafkaSSLUtil.addGlobalSSLParameters(kafkaProps);    assertNoSSLParameters(kafkaProps);}
8bda5a9a26f219d13b871ec4f3433783430d29df5daa811feb73e7775a5a2495
assertNoSSLParameters
private void assertNoSSLParameters(Properties kafkaProps)
{    assertFalse(kafkaProps.containsKey(SslConfigs.SSL_KEYSTORE_LOCATION_CONFIG));    assertFalse(kafkaProps.containsKey(SslConfigs.SSL_KEYSTORE_PASSWORD_CONFIG));    assertFalse(kafkaProps.containsKey(SslConfigs.SSL_KEYSTORE_TYPE_CONFIG));    assertFalse(kafkaProps.containsKey(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));    assertFalse(kafkaProps.containsKey(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG));    assertFalse(kafkaProps.containsKey(SslConfigs.SSL_TRUSTSTORE_TYPE_CONFIG));}
b0b6040a4e916069dfc53ef3949e325c075839da846313a865dfa775399d228c
assertGlobalSSLParameters
private void assertGlobalSSLParameters(Properties kafkaProps)
{    assertEquals("global-keystore-path", kafkaProps.getProperty(SslConfigs.SSL_KEYSTORE_LOCATION_CONFIG));    assertEquals("global-keystore-password", kafkaProps.getProperty(SslConfigs.SSL_KEYSTORE_PASSWORD_CONFIG));    assertEquals("global-keystore-type", kafkaProps.getProperty(SslConfigs.SSL_KEYSTORE_TYPE_CONFIG));    assertEquals("global-truststore-path", kafkaProps.getProperty(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));    assertEquals("global-truststore-password", kafkaProps.getProperty(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG));    assertEquals("global-truststore-type", kafkaProps.getProperty(SslConfigs.SSL_TRUSTSTORE_TYPE_CONFIG));}
513f2e64a1889d3babd5b372db4c8fd92461989d8c92ecfbaba3b1312172bd7d
assertComponentSSLParameters
private void assertComponentSSLParameters(Properties kafkaProps)
{    assertEquals("component-keystore-path", kafkaProps.getProperty(SslConfigs.SSL_KEYSTORE_LOCATION_CONFIG));    assertEquals("component-keystore-password", kafkaProps.getProperty(SslConfigs.SSL_KEYSTORE_PASSWORD_CONFIG));    assertEquals("component-keystore-type", kafkaProps.getProperty(SslConfigs.SSL_KEYSTORE_TYPE_CONFIG));    assertEquals("component-truststore-path", kafkaProps.getProperty(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG));    assertEquals("component-truststore-password", kafkaProps.getProperty(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG));    assertEquals("component-truststore-type", kafkaProps.getProperty(SslConfigs.SSL_TRUSTSTORE_TYPE_CONFIG));}
2b241f91993eb608d6e1613642e99a07a715a5f34dbf53c0055a3fd1339c43f4
checkResultsAgainstSkew
public static void checkResultsAgainstSkew(PartitionTestScenario scenario, Map<Integer, List<Event>> partitionMap, Map<Integer, List<byte[]>> resultsMap, int staticPtn, int numMsgs)
{    int numPtns = partitionMap.size();    if (scenario == PartitionTestScenario.NO_PARTITION_HEADERS && numMsgs % numPtns != 0) {        throw new IllegalArgumentException("This method is not designed to work with scenarios" + " where there is expected to be a non-even distribution of messages");    }    for (int ptn = 0; ptn < numPtns; ptn++) {        List<Event> expectedResults = partitionMap.get(ptn);        List<byte[]> actualResults = resultsMap.get(ptn);        if (scenario == PartitionTestScenario.PARTITION_ID_HEADER_ONLY || scenario == PartitionTestScenario.STATIC_HEADER_AND_PARTITION_ID) {                        Assert.assertEquals(expectedResults.size(), actualResults.size());                        for (int idx = 0; idx < expectedResults.size(); idx++) {                Assert.assertArrayEquals(expectedResults.get(idx).getBody(), actualResults.get(idx));            }        } else if (scenario == PartitionTestScenario.STATIC_HEADER_ONLY) {                        if (ptn == staticPtn) {                Assert.assertEquals(numMsgs, actualResults.size());            } else {                Assert.assertEquals(0, actualResults.size());            }        } else if (scenario == PartitionTestScenario.NO_PARTITION_HEADERS) {                        Assert.assertEquals(numMsgs / numPtns, actualResults.size());        }    }}
323fe338e56cbfc864c17694c9e7fc6cc9cde3b847f7ac8e66efd753c705ffba
generateSkewedMessageList
public static List<Event> generateSkewedMessageList(PartitionTestScenario scenario, int numMsgs, Map<Integer, List<Event>> partitionMap, int numPtns, int staticPtn)
{    List<Event> msgs = new ArrayList<Event>(numMsgs);        if (numMsgs < 0) {        throw new IllegalArgumentException("Number of messages must be greater than zero");    }    if (staticPtn >= numPtns) {        throw new IllegalArgumentException("The static partition must be less than the " + "number of partitions");    }    if (numPtns < 5) {        throw new IllegalArgumentException("This method is designed to work with at least 5 " + "partitions");    }    if (partitionMap.size() != numPtns) {        throw new IllegalArgumentException("partitionMap has not been correctly initialised");    }    for (int i = 0; i < numMsgs; i++) {        Map<String, String> headers = new HashMap<String, String>();        Integer partition = null;        if (scenario == PartitionTestScenario.NO_PARTITION_HEADERS) {                } else if (scenario == PartitionTestScenario.STATIC_HEADER_ONLY) {            partition = staticPtn;        } else {                        if (i % 5 == 0) {                partition = 4;                headers.put(PARTITION_HEADER, String.valueOf(partition));            } else if (i % 3 == 0) {                partition = 3;                headers.put(PARTITION_HEADER, String.valueOf(partition));            } else if (scenario == PartitionTestScenario.STATIC_HEADER_AND_PARTITION_ID) {                                                partition = staticPtn;            } else if (scenario == PartitionTestScenario.PARTITION_ID_HEADER_ONLY) {                partition = 2;                headers.put(PARTITION_HEADER, String.valueOf(partition));            }                }                Event event = EventBuilder.withBody(String.valueOf(i).getBytes(), headers);        if (scenario != PartitionTestScenario.NO_PARTITION_HEADERS) {                        partitionMap.get(partition).add(event);        }                msgs.add(event);    }    return msgs;}
e846b7114cc24a537c679c382637a1e8346294337e8ad5ab6cb62a1714ca3aad
retrieveRecordsFromPartitions
public static Map<Integer, List<byte[]>> retrieveRecordsFromPartitions(String topic, int numPtns, Properties consumerProperties)
{    Map<Integer, List<byte[]>> resultsMap = new HashMap<Integer, List<byte[]>>();    for (int i = 0; i < numPtns; i++) {        List<byte[]> partitionResults = new ArrayList<byte[]>();        resultsMap.put(i, partitionResults);        KafkaConsumer<String, byte[]> consumer = new KafkaConsumer<String, byte[]>(consumerProperties);        TopicPartition partition = new TopicPartition(topic, i);        consumer.assign(Arrays.asList(partition));        ConsumerRecords<String, byte[]> records = consumer.poll(1000);        for (ConsumerRecord<String, byte[]> record : records) {            partitionResults.add(record.value());        }        consumer.close();    }    return resultsMap;}
08df4ab301071b0c94b69d41cf8b43b3183c2dac7e95f863ebf0907c51f14d01
validateEvent
public boolean validateEvent(Event event)
{    return true;}
b31fdbda5b2fe0f51387a3557684d377c11b431713c63ffcc9c9981bfe2e6eec
run
public void run(String[] args) throws IOException, ParseException
{    boolean shouldContinue = parseCommandLineOpts(args);    if (!shouldContinue) {        LOG.error("Could not parse command line options. Exiting ...");        System.exit(1);    }    for (File dataDir : dataDirs) {        File[] dataFiles = dataDir.listFiles(new FilenameFilter() {            @Override            public boolean accept(File dir, String name) {                if (!name.endsWith(Serialization.METADATA_FILENAME) && !name.endsWith(Serialization.METADATA_TMP_FILENAME) && !name.endsWith(Serialization.OLD_METADATA_FILENAME) && !name.equals(Log.FILE_LOCK)) {                    return true;                }                return false;            }        });        if (dataFiles != null && dataFiles.length > 0) {            for (File dataFile : dataFiles) {                LOG.info("Checking for corruption in " + dataFile.toString());                LogFile.SequentialReader reader = new LogFileV3.SequentialReader(dataFile, null, true);                LogFile.OperationRecordUpdater updater = new LogFile.OperationRecordUpdater(dataFile);                boolean fileDone = false;                boolean fileBackedup = false;                while (!fileDone) {                    long eventPosition = 0;                    try {                                                                        eventPosition = reader.getPosition();                                                                                                LogRecord record = reader.next();                        totalChannelEvents++;                        if (record != null) {                            TransactionEventRecord recordEvent = record.getEvent();                            Event event = EventUtils.getEventFromTransactionEvent(recordEvent);                            if (event != null) {                                totalPutEvents++;                                try {                                    if (!eventValidator.validateEvent(event)) {                                        if (!fileBackedup) {                                            Serialization.copyFile(dataFile, new File(dataFile.getParent(), dataFile.getName() + ".bak"));                                            fileBackedup = true;                                        }                                        invalidEvents++;                                        updater.markRecordAsNoop(eventPosition);                                    } else {                                        validEvents++;                                    }                                } catch (Exception e) {                                                                                                                                                System.err.println("Encountered Exception while validating event, " + "marking as invalid");                                    updater.markRecordAsNoop(eventPosition);                                    eventsWithException++;                                }                            }                        } else {                            fileDone = true;                        }                    } catch (CorruptEventException e) {                        corruptEvents++;                        totalChannelEvents++;                        LOG.warn("Corruption found in " + dataFile.toString() + " at " + eventPosition);                        if (!fileBackedup) {                            Serialization.copyFile(dataFile, new File(dataFile.getParent(), dataFile.getName() + ".bak"));                            fileBackedup = true;                        }                        updater.markRecordAsNoop(eventPosition);                    }                }                updater.close();                reader.close();            }        }    }    printSummary();}
ca62bfdc0472b2de6468644412d9ad6b432937742edcb5ca65b1f23b694b5853
accept
public boolean accept(File dir, String name)
{    if (!name.endsWith(Serialization.METADATA_FILENAME) && !name.endsWith(Serialization.METADATA_TMP_FILENAME) && !name.endsWith(Serialization.OLD_METADATA_FILENAME) && !name.equals(Log.FILE_LOCK)) {        return true;    }    return false;}
2cb62c62daa6ab479de318637749651da1c1b91c602972c78a0b806d6d6bbb23
parseCommandLineOpts
private boolean parseCommandLineOpts(String[] args) throws ParseException
{    Options options = new Options();    options.addOption("l", "dataDirs", true, "Comma-separated list of data " + "directories which the tool must verify. This option is mandatory").addOption("h", "help", false, "Display help").addOption("e", "eventValidator", true, "Fully Qualified Name of Event Validator Implementation");    Option property = OptionBuilder.withArgName("property=value").hasArgs(2).withValueSeparator().withDescription("custom properties").create("D");    options.addOption(property);    CommandLineParser parser = new GnuParser();    CommandLine commandLine = parser.parse(options, args);    if (commandLine.hasOption("help")) {        new HelpFormatter().printHelp("bin/flume-ng tool fcintegritytool ", options, true);        return false;    }    if (!commandLine.hasOption("dataDirs")) {        new HelpFormatter().printHelp("bin/flume-ng tool fcintegritytool ", "", options, "dataDirs is required.", true);        return false;    } else {        String[] dataDirStr = commandLine.getOptionValue("dataDirs").split(",");        for (String dataDir : dataDirStr) {            File f = new File(dataDir);            if (!f.exists()) {                throw new FlumeException("Data directory, " + dataDir + " does not exist.");            }            dataDirs.add(f);        }    }    if (commandLine.hasOption("eventValidator")) {        try {            Class<? extends EventValidator.Builder> eventValidatorClassName = (Class<? extends EventValidator.Builder>) Class.forName(commandLine.getOptionValue("eventValidator"));            EventValidator.Builder eventValidatorBuilder = eventValidatorClassName.newInstance();                        Properties systemProperties = commandLine.getOptionProperties("D");            Context context = new Context();            Set<String> keys = systemProperties.stringPropertyNames();            for (String key : keys) {                context.put(key, systemProperties.getProperty(key));            }            eventValidatorBuilder.configure(context);            eventValidator = eventValidatorBuilder.build();        } catch (Exception e) {            System.err.println(String.format("Could find class %s in lib folder", commandLine.getOptionValue("eventValidator")));            e.printStackTrace();            return false;        }    }    return true;}
25503b2799676d62423e4894562d6aade401bc066cb8967828aa2be1070e7e76
printSummary
private void printSummary()
{    System.out.println("---------- Summary --------------------");    System.out.println("Number of Events in the Channel = " + totalChannelEvents++);    System.out.println("Number of Put Events Processed = " + totalPutEvents);    System.out.println("Number of Valid Put Events = " + validEvents);    System.out.println("Number of Invalid Put Events = " + invalidEvents);    System.out.println("Number of Put Events that threw Exception during validation = " + eventsWithException);    System.out.println("Number of Corrupt Events = " + corruptEvents);    System.out.println("---------------------------------------");}
b6047c2d62e0dd012f9e8fbf9c3b04878ae171af7f5ab52171412c0b606ca520
main
public static void main(String[] args) throws Exception
{    new FlumeToolsMain().run(args);}
be024bdaeee324745a1c8d50136902d17202cafcf99c1ba3727d44103eaa3123
run
public void run(String[] args) throws Exception
{    String error = "Expected name of tool and arguments for" + " tool to be passed in on the command line. Please pass one of the " + "following as arguments to this command: \n";    StringBuilder builder = new StringBuilder(error);    for (FlumeToolType type : FlumeToolType.values()) {        builder.append(type.name()).append("\n");    }    if (args == null || args.length == 0) {        System.out.println(builder.toString());        System.exit(1);    }    String toolName = args[0];    FlumeTool tool = null;    for (FlumeToolType type : FlumeToolType.values()) {        if (toolName.equalsIgnoreCase(type.name())) {            tool = type.getClassInstance().newInstance();            break;        }    }    Preconditions.checkNotNull(tool, "Cannot find tool matching " + toolName + ". Please select one of: \n " + FlumeToolType.getNames());    if (args.length == 1) {        tool.run(new String[0]);    } else {        tool.run(Arrays.asList(args).subList(1, args.length).toArray(new String[0]));    }}
52e4e10596127d9e2b2c1e38886377c369d4eeb085f51c6f2ec96142ab25ae3f
getClassInstance
public Class<? extends FlumeTool> getClassInstance()
{    return this.klass;}
aab6ffa82ec539543d0fa0a103aa1b2c3dfcb965474f017f73a6d3a0acece5cd
getNames
public static String getNames()
{    StringBuilder builder = new StringBuilder();    for (FlumeToolType type : values()) {        builder.append(type.name().toLowerCase(Locale.ENGLISH) + "\n");    }    return builder.toString();}
7f0f73b325bcd37632c396c02bb87ddfe4bb9da1a35fac272192ae84740eb688
setUpClass
public static void setUpClass() throws Exception
{    createDataFiles();}
9d69bfd2a279cacda04001b1c50c6f6698b00750596931407928c5a8169d56b7
setUp
public void setUp() throws Exception
{    checkpointDir = new File(baseDir, "checkpoint");    dataDir = new File(baseDir, "dataDir");    Assert.assertTrue(checkpointDir.mkdirs() || checkpointDir.isDirectory());    Assert.assertTrue(dataDir.mkdirs() || dataDir.isDirectory());    File[] dataFiles = origDataDir.listFiles(new FilenameFilter() {        @Override        public boolean accept(File dir, String name) {            if (name.contains("lock")) {                return false;            }            return true;        }    });    for (File dataFile : dataFiles) {        Serialization.copyFile(dataFile, new File(dataDir, dataFile.getName()));    }}
ca62bfdc0472b2de6468644412d9ad6b432937742edcb5ca65b1f23b694b5853
accept
public boolean accept(File dir, String name)
{    if (name.contains("lock")) {        return false;    }    return true;}
c6aaebb5a52567751db8dc8e1cb9dd4a4e582ef964a374b376c6a04f741802dc
tearDown
public void tearDown() throws Exception
{    FileUtils.deleteDirectory(checkpointDir);    FileUtils.deleteDirectory(dataDir);}
57356f1c78bbffcbadab516b764dcc9a36fc07f0e28b2d56b001ac2d49131cb2
tearDownClass
public static void tearDownClass() throws Exception
{    FileUtils.deleteDirectory(origCheckpointDir);    FileUtils.deleteDirectory(origDataDir);}
afe6035ae783b93d369866f8d4c0c5399ac52891c4dbe7ebf03057f8affa2d27
testFixCorruptRecordsWithCheckpoint
public void testFixCorruptRecordsWithCheckpoint() throws Exception
{    doTestFixCorruptEvents(true);}
cac642b48c2fbc9389baef54150a251c5fabcbb3a56b67b9dc746912b2285919
testFixCorruptRecords
public void testFixCorruptRecords() throws Exception
{    doTestFixCorruptEvents(false);}
e54262801bddf33643d59f8f962cc0d766eff12b8b71d9211011eab06420f4a8
testFixInvalidRecords
public void testFixInvalidRecords() throws Exception
{    doTestFixInvalidEvents(false, DummyEventVerifier.Builder.class.getName());}
a4164ad83e065bcd26fe036ec44a5fa1c1b63b7f9e9ddd63f99c893c3db2d2e4
testFixInvalidRecordsWithCheckpoint
public void testFixInvalidRecordsWithCheckpoint() throws Exception
{    doTestFixInvalidEvents(true, DummyEventVerifier.Builder.class.getName());}
83d123c4a6dfdf8c4c267632fc877634a84864a9fe4712ea1fb3762fd72516f5
doTestFixInvalidEvents
public void doTestFixInvalidEvents(boolean withCheckpoint, String eventHandler) throws Exception
{    FileChannelIntegrityTool tool = new FileChannelIntegrityTool();    tool.run(new String[] { "-l", dataDir.toString(), "-e", eventHandler, "-DvalidatorValue=0" });    FileChannel channel = new FileChannel();    channel.setName("channel");    if (withCheckpoint) {        File[] cpFiles = origCheckpointDir.listFiles(new FilenameFilter() {            @Override            public boolean accept(File dir, String name) {                if (name.contains("lock") || name.contains("queueset")) {                    return false;                }                return true;            }        });        for (File cpFile : cpFiles) {            Serialization.copyFile(cpFile, new File(checkpointDir, cpFile.getName()));        }    } else {        FileUtils.deleteDirectory(checkpointDir);        Assert.assertTrue(checkpointDir.mkdirs());    }    ctx.put(FileChannelConfiguration.CHECKPOINT_DIR, checkpointDir.toString());    ctx.put(FileChannelConfiguration.DATA_DIRS, dataDir.toString());    channel.configure(ctx);    channel.start();    Transaction tx = channel.getTransaction();    tx.begin();    int i = 0;    while (channel.take() != null) {        i++;    }    tx.commit();    tx.close();    channel.stop();    Assert.assertTrue(invalidEvent != 0);    Assert.assertEquals(25 - invalidEvent, i);}
ca62bfdc0472b2de6468644412d9ad6b432937742edcb5ca65b1f23b694b5853
accept
public boolean accept(File dir, String name)
{    if (name.contains("lock") || name.contains("queueset")) {        return false;    }    return true;}
bcdb00d85d74b4e0a078c4318c52fa49c15c9aaa3daabafae094882a43d8a8c3
doTestFixCorruptEvents
public void doTestFixCorruptEvents(boolean withCheckpoint) throws Exception
{    Set<String> corruptFiles = new HashSet<String>();    File[] files = dataDir.listFiles(new FilenameFilter() {        @Override        public boolean accept(File dir, String name) {            if (name.contains("lock") || name.contains("meta")) {                return false;            }            return true;        }    });    Random random = new Random();    int corrupted = 0;    for (File dataFile : files) {        LogFile.SequentialReader reader = new LogFileV3.SequentialReader(dataFile, null, true);        RandomAccessFile handle = new RandomAccessFile(dataFile, "rw");        long eventPosition1 = reader.getPosition();        LogRecord rec = reader.next();                if (rec == null || rec.getEvent().getClass().getName().equals("org.apache.flume.channel.file.Commit")) {            handle.close();            reader.close();            continue;        }        long eventPosition2 = reader.getPosition();        rec = reader.next();        handle.seek(eventPosition1 + 100);        handle.writeInt(random.nextInt());        corrupted++;        corruptFiles.add(dataFile.getName());        if (rec == null || rec.getEvent().getClass().getName().equals("org.apache.flume.channel.file.Commit")) {            handle.close();            reader.close();            continue;        }        handle.seek(eventPosition2 + 100);        handle.writeInt(random.nextInt());        corrupted++;        handle.close();        reader.close();    }    FileChannelIntegrityTool tool = new FileChannelIntegrityTool();    tool.run(new String[] { "-l", dataDir.toString() });    FileChannel channel = new FileChannel();    channel.setName("channel");    if (withCheckpoint) {        File[] cpFiles = origCheckpointDir.listFiles(new FilenameFilter() {            @Override            public boolean accept(File dir, String name) {                if (name.contains("lock") || name.contains("queueset")) {                    return false;                }                return true;            }        });        for (File cpFile : cpFiles) {            Serialization.copyFile(cpFile, new File(checkpointDir, cpFile.getName()));        }    } else {        FileUtils.deleteDirectory(checkpointDir);        Assert.assertTrue(checkpointDir.mkdirs());    }    ctx.put(FileChannelConfiguration.CHECKPOINT_DIR, checkpointDir.toString());    ctx.put(FileChannelConfiguration.DATA_DIRS, dataDir.toString());    channel.configure(ctx);    channel.start();    Transaction tx = channel.getTransaction();    tx.begin();    int i = 0;    while (channel.take() != null) {        i++;    }    tx.commit();    tx.close();    channel.stop();    Assert.assertEquals(25 - corrupted, i);    files = dataDir.listFiles(new FilenameFilter() {        @Override        public boolean accept(File dir, String name) {            if (name.contains(".bak")) {                return true;            }            return false;        }    });    Assert.assertEquals(corruptFiles.size(), files.length);    for (File file : files) {        String name = file.getName();        name = name.replaceAll(".bak", "");        Assert.assertTrue(corruptFiles.remove(name));    }    Assert.assertTrue(corruptFiles.isEmpty());}
ca62bfdc0472b2de6468644412d9ad6b432937742edcb5ca65b1f23b694b5853
accept
public boolean accept(File dir, String name)
{    if (name.contains("lock") || name.contains("meta")) {        return false;    }    return true;}
ca62bfdc0472b2de6468644412d9ad6b432937742edcb5ca65b1f23b694b5853
accept
public boolean accept(File dir, String name)
{    if (name.contains("lock") || name.contains("queueset")) {        return false;    }    return true;}
ca62bfdc0472b2de6468644412d9ad6b432937742edcb5ca65b1f23b694b5853
accept
public boolean accept(File dir, String name)
{    if (name.contains(".bak")) {        return true;    }    return false;}
f6d9703f283de0206428edceadeca3492e49f7d2a89e297e22265fcc45b447e0
createDataFiles
private static void createDataFiles() throws Exception
{    final byte[] eventData = new byte[2000];    for (int i = 0; i < 2000; i++) {        eventData[i] = 1;    }    WriteOrderOracle.setSeed(System.currentTimeMillis());    event = EventBuilder.withBody(eventData);    baseDir = Files.createTempDir();    if (baseDir.exists()) {        FileUtils.deleteDirectory(baseDir);    }    baseDir = Files.createTempDir();    origCheckpointDir = new File(baseDir, "chkpt");    Assert.assertTrue(origCheckpointDir.mkdirs() || origCheckpointDir.isDirectory());    origDataDir = new File(baseDir, "data");    Assert.assertTrue(origDataDir.mkdirs() || origDataDir.isDirectory());    FileChannel channel = new FileChannel();    channel.setName("channel");    ctx = new Context();    ctx.put(FileChannelConfiguration.CAPACITY, "1000");    ctx.put(FileChannelConfiguration.CHECKPOINT_DIR, origCheckpointDir.toString());    ctx.put(FileChannelConfiguration.DATA_DIRS, origDataDir.toString());    ctx.put(FileChannelConfiguration.MAX_FILE_SIZE, "10000");    ctx.put(FileChannelConfiguration.TRANSACTION_CAPACITY, "100");    channel.configure(ctx);    channel.start();    for (int j = 0; j < 5; j++) {        Transaction tx = channel.getTransaction();        tx.begin();        for (int i = 0; i < 5; i++) {            if (i % 3 == 0) {                event.getBody()[0] = 0;                invalidEvent++;            } else {                event.getBody()[0] = 1;            }            channel.put(event);        }        tx.commit();        tx.close();    }    Log log = field("log").ofType(Log.class).in(channel).get();    Assert.assertTrue("writeCheckpoint returned false", method("writeCheckpoint").withReturnType(Boolean.class).withParameterTypes(Boolean.class).in(log).invoke(true));    channel.stop();}
08df4ab301071b0c94b69d41cf8b43b3183c2dac7e95f863ebf0907c51f14d01
validateEvent
public boolean validateEvent(Event event)
{    return event.getBody()[0] != value;}
ec3c47dd4371ab0b1362b77e9ca28689dcaa973ab7cf96b534c6aeabbff9d33d
build
public EventValidator build()
{    return new DummyEventVerifier(binaryValidator);}
4bdb49b3534c0229d85ad5220e7acc8ff335a4f6fec8d844d9fe786219ab0d39
configure
public void configure(Context context)
{    binaryValidator = context.getInteger("validatorValue");}
