public T mahout_f0_0()
{    if (obj == null) {        obj = deserialize(buf);    }    return obj;}
private byte[] mahout_f1_0(Writable w)
{    ByteArrayOutputStream bos = new ByteArrayOutputStream();    try {        ObjectOutputStream oos = new ObjectOutputStream(bos);        w.write(oos);        oos.close();    } catch (IOException e) {        return null;    }    return bos.toByteArray();}
private T mahout_f2_0(byte[] buf)
{    T ret = null;    try (ByteArrayInputStream bis = new ByteArrayInputStream(buf)) {        ObjectInputStream ois = new ObjectInputStream(bis);        if (isMatrix) {            MatrixWritable w = new MatrixWritable();            w.readFields(ois);            ret = (T) w.get();        } else {            VectorWritable w = new VectorWritable();            w.readFields(ois);            ret = (T) w.get();        }    } catch (IOException e) {        e.printStackTrace();    }    return ret;}
public void mahout_f3_0() throws IOException
{}
private void mahout_f4_0()
{    if (cow != null) {        return;    }    if (chks[0].isSparse()) {        cow = new SparseMatrix(chks[0].len(), chks.length);    } else {        cow = new DenseMatrix(chks[0].len(), chks.length);    }    for (int c = 0; c < chks.length; c++) {        for (int r = 0; r < chks[0].len(); r++) {            cow.setQuick(r, c, chks[c].atd(r));        }    }}
public void mahout_f5_0(int row, int col, double val)
{    cow();    cow.setQuick(row, col, val);}
public Matrix mahout_f6_0(int nrow, int ncol)
{    if (chks[0].isSparse()) {        return new SparseMatrix(nrow, ncol);    } else {        return new DenseMatrix(nrow, ncol);    }}
public Matrix mahout_f7_0()
{    if (chks[0].isSparse()) {        return new SparseMatrix(rowSize(), columnSize());    } else {        return new DenseMatrix(rowSize(), columnSize());    }}
public double mahout_f8_0(int row, int col)
{    if (cow != null) {        return cow.getQuick(row, col);    } else {        return chks[col].atd(row);    }}
public Matrix mahout_f9_0(int row, Vector v)
{    cow();    cow.assignRow(row, v);    return cow;}
public Matrix mahout_f10_0(int col, Vector v)
{    cow();    cow.assignColumn(col, v);    return cow;}
public MatrixFlavor mahout_f11_0()
{    if (cow != null) {        return cow.getFlavor();    } else if (chks[0].isSparse()) {        return MatrixFlavor.SPARSELIKE;    } else {        return MatrixFlavor.DENSELIKE;    }}
public static boolean mahout_f12_0(String filename)
{    try {        Configuration conf = new Configuration();        Path path = new Path(filename);        FileSystem fs = FileSystem.get(URI.create(filename), conf);        FSDataInputStream fin = fs.open(path);        byte[] seq = new byte[3];        fin.read(seq);        fin.close();        return seq[0] == 'S' && seq[1] == 'E' && seq[2] == 'Q';    } catch (IOException e) {        return false;    }}
public static H2ODrm mahout_f13_0(String filename, int parMin)
{    try {        if (isSeqfile(filename)) {            return drmFromSeqfile(filename, parMin);        } else {            return new H2ODrm(FrameUtils.parseFrame(null, new File(filename)));        }    } catch (IOException e) {        return null;    }}
public static H2ODrm mahout_f14_0(String filename, int parMin)
{    long rows = 0;    int cols = 0;    Frame frame = null;    Vec labels = null;    SequenceFile.Reader reader = null;    try {        Configuration conf = new Configuration();        Path path = new Path(filename);        FileSystem fs = FileSystem.get(URI.create(filename), conf);        Vec.Writer[] writers;        Vec.Writer labelwriter = null;        boolean isIntKey = false, isLongKey = false, isStringKey = false;        reader = new SequenceFile.Reader(fs, path, conf);        if (reader.getValueClass() != VectorWritable.class) {            System.out.println("ValueClass in file " + filename + "must be VectorWritable, but found " + reader.getValueClassName());            return null;        }        Writable key = (Writable) ReflectionUtils.newInstance(reader.getKeyClass(), conf);        VectorWritable value = (VectorWritable) ReflectionUtils.newInstance(reader.getValueClass(), conf);        long start = reader.getPosition();        if (reader.getKeyClass() == Text.class) {            isStringKey = true;        } else if (reader.getKeyClass() == LongWritable.class) {            isLongKey = true;        } else {            isIntKey = true;        }        while (reader.next(key, value)) {            if (cols == 0) {                Vector v = value.get();                cols = Math.max(v.size(), cols);            }            if (isLongKey) {                rows = Math.max(((LongWritable) (key)).get() + 1, rows);            }            if (isIntKey) {                rows = Math.max(((IntWritable) (key)).get() + 1, rows);            }            if (isStringKey) {                rows++;            }        }        reader.seek(start);        frame = H2OHelper.emptyFrame(rows, cols, parMin, -1);        writers = new Vec.Writer[cols];        for (int i = 0; i < writers.length; i++) {            writers[i] = frame.vecs()[i].open();        }        if (reader.getKeyClass() == Text.class) {            labels = H2OHelper.makeEmptyStrVec(frame.anyVec());            labelwriter = labels.open();        }        long r = 0;        while (reader.next(key, value)) {            Vector v = value.get();            if (isLongKey) {                r = ((LongWritable) (key)).get();            }            if (isIntKey) {                r = ((IntWritable) (key)).get();            }            for (int c = 0; c < v.size(); c++) {                writers[c].set(r, v.getQuick(c));            }            if (labels != null) {                labelwriter.set(r, (key).toString());            }            if (isStringKey) {                r++;            }        }        Futures fus = new Futures();        for (Vec.Writer w : writers) {            w.close(fus);        }        if (labelwriter != null) {            labelwriter.close(fus);        }        fus.blockForPending();    } catch (java.io.IOException e) {        return null;    } finally {        IOUtils.closeStream(reader);    }    return new H2ODrm(frame, labels);}
public static void mahout_f15_0(String filename, H2ODrm drm) throws java.io.IOException
{    Frame frame = drm.frame;    Vec labels = drm.keys;    Configuration conf = new Configuration();    Path path = new Path(filename);    FileSystem fs = FileSystem.get(URI.create(filename), conf);    SequenceFile.Writer writer;    boolean isSparse = H2OHelper.isSparse(frame);    ValueString vstr = new ValueString();    if (labels != null) {        writer = SequenceFile.createWriter(fs, conf, path, Text.class, VectorWritable.class);    } else {        writer = SequenceFile.createWriter(fs, conf, path, IntWritable.class, VectorWritable.class);    }    for (long r = 0; r < frame.anyVec().length(); r++) {        Vector v;        if (isSparse) {            v = new SequentialAccessSparseVector(frame.numCols());        } else {            v = new DenseVector(frame.numCols());        }        for (int c = 0; c < frame.numCols(); c++) {            v.setQuick(c, frame.vecs()[c].at(r));        }        if (labels != null) {            writer.append(new Text(labels.atStr(vstr, r).toString()), new VectorWritable(v));        } else {            writer.append(new IntWritable((int) r), new VectorWritable(v));        }    }    writer.close();}
public static boolean mahout_f16_0(Frame frame)
{    long rows = frame.numRows();    long cols = frame.numCols();    /**     * MRTask to aggregate precalculated per-chunk sparse lengths     */    class MRTaskNZ extends MRTask<MRTaskNZ> {        long sparselen;        @Override        public void map(Chunk[] chks) {            for (Chunk chk : chks) {                sparselen += chk.sparseLen();            }        }        @Override        public void reduce(MRTaskNZ other) {            sparselen += other.sparselen;        }    }    long sparselen = new MRTaskNZ().doAll(frame).sparselen;    return (((rows * cols) / (sparselen + 1)) > 32);}
public void mahout_f17_0(Chunk[] chks)
{    for (Chunk chk : chks) {        sparselen += chk.sparseLen();    }}
public void mahout_f18_0(MRTaskNZ other)
{    sparselen += other.sparselen;}
public static Matrix mahout_f19_0(H2ODrm drm)
{    Frame frame = drm.frame;    Vec labels = drm.keys;    Matrix m;    if (isSparse(frame)) {        m = new SparseMatrix((int) frame.numRows(), frame.numCols());    } else {        m = new DenseMatrix((int) frame.numRows(), frame.numCols());    }    int c = 0;        for (Vec v : frame.vecs()) {        for (int r = 0; r < frame.numRows(); r++) {            double d;            if (!v.isNA(r) && ((d = v.at(r)) != 0.0)) {                m.setQuick(r, c, d);            }        }        c++;    }        if (labels != null) {        Map<String, Integer> map = new HashMap<>();        ValueString vstr = new ValueString();        for (long i = 0; i < labels.length(); i++) {            map.put(labels.atStr(vstr, i).toString(), (int) i);        }        m.setRowLabelBindings(map);    }    return m;}
public static Vector mahout_f20_0(Frame frame)
{    double[] means = new double[frame.numCols()];    for (int i = 0; i < frame.numCols(); i++) {        means[i] = frame.vecs()[i].mean();    }    return new DenseVector(means);}
public static Vector mahout_f21_0(Frame frame)
{    /**     * MRTask to calculate sums of elements in all columns.     */    class MRTaskSum extends MRTask<MRTaskSum> {        public double[] sums;        @Override        public void map(Chunk[] chks) {            sums = new double[chks.length];            for (int c = 0; c < chks.length; c++) {                for (int r = 0; r < chks[c].len(); r++) {                    sums[c] += chks[c].atd(r);                }            }        }        @Override        public void reduce(MRTaskSum other) {            ArrayUtils.add(sums, other.sums);        }    }    return new DenseVector(new MRTaskSum().doAll(frame).sums);}
public void mahout_f22_0(Chunk[] chks)
{    sums = new double[chks.length];    for (int c = 0; c < chks.length; c++) {        for (int r = 0; r < chks[c].len(); r++) {            sums[c] += chks[c].atd(r);        }    }}
public void mahout_f23_0(MRTaskSum other)
{    ArrayUtils.add(sums, other.sums);}
public static double mahout_f24_0(Frame frame)
{    /**     * MRTask to calculate sums of squares of all elements.     */    class MRTaskSumSqr extends MRTask<MRTaskSumSqr> {        public double sumSqr;        @Override        public void map(Chunk[] chks) {            for (Chunk chk : chks) {                for (int r = 0; r < chk.len(); r++) {                    sumSqr += (chk.atd(r) * chk.atd(r));                }            }        }        @Override        public void reduce(MRTaskSumSqr other) {            sumSqr += other.sumSqr;        }    }    return new MRTaskSumSqr().doAll(frame).sumSqr;}
public void mahout_f25_0(Chunk[] chks)
{    for (Chunk chk : chks) {        for (int r = 0; r < chk.len(); r++) {            sumSqr += (chk.atd(r) * chk.atd(r));        }    }}
public void mahout_f26_0(MRTaskSumSqr other)
{    sumSqr += other.sumSqr;}
public static Vector mahout_f27_0(Frame frame)
{    /**     * MRTask to count all non-zero elements.     */    class MRTaskNonZero extends MRTask<MRTaskNonZero> {        public double[] sums;        @Override        public void map(Chunk[] chks) {            sums = new double[chks.length];            for (int c = 0; c < chks.length; c++) {                for (int r = 0; r < chks[c].len(); r++) {                    if ((long) chks[c].atd(r) != 0) {                        sums[c]++;                    }                }            }        }        @Override        public void reduce(MRTaskNonZero other) {            ArrayUtils.add(sums, other.sums);        }    }    return new DenseVector(new MRTaskNonZero().doAll(frame).sums);}
public void mahout_f28_0(Chunk[] chks)
{    sums = new double[chks.length];    for (int c = 0; c < chks.length; c++) {        for (int r = 0; r < chks[c].len(); r++) {            if ((long) chks[c].atd(r) != 0) {                sums[c]++;            }        }    }}
public void mahout_f29_0(MRTaskNonZero other)
{    ArrayUtils.add(sums, other.sums);}
private static Map<Integer, String> mahout_f30_0(Map<String, Integer> map)
{    if (map == null) {        return null;    }    Map<Integer, String> rmap = new HashMap<>();    for (Map.Entry<String, Integer> entry : map.entrySet()) {        rmap.put(entry.getValue(), entry.getKey());    }    return rmap;}
private static int mahout_f31_0(long nrow, int minHint, int exactHint)
{    int chunkSz;    int partsHint = Math.max(minHint, exactHint);    if (partsHint < 1) {        /* XXX: calculate based on cloud size and # of cpu */        partsHint = 4;    }    chunkSz = (int) (((nrow - 1) / partsHint) + 1);    if (exactHint > 0) {        return chunkSz;    }    if (chunkSz > 1e6) {        chunkSz = (int) 1e6;    }    if (minHint > 0) {        return chunkSz;    }    if (chunkSz < 1e3) {        chunkSz = (int) 1e3;    }    return chunkSz;}
public static H2ODrm mahout_f32_0(Matrix m, int minHint, int exactHint)
{        Frame frame = emptyFrame(m.rowSize(), m.columnSize(), minHint, exactHint);    Vec labels = null;    Vec.Writer[] writers = new Vec.Writer[m.columnSize()];    Futures closer = new Futures();        for (int i = 0; i < writers.length; i++) {        writers[i] = frame.vecs()[i].open();    }    for (int r = 0; r < m.rowSize(); r++) {        for (int c = 0; c < m.columnSize(); c++) {            writers[c].set(r, m.getQuick(r, c));        }    }    for (int c = 0; c < m.columnSize(); c++) {        writers[c].close(closer);    }        Map<String, Integer> map = m.getRowLabelBindings();    if (map != null) {                labels = makeEmptyStrVec(frame.anyVec());        Vec.Writer writer = labels.open();        Map<Integer, String> rmap = reverseMap(map);        for (int r = 0; r < m.rowSize(); r++) {            writer.set(r, rmap.get(r));        }        writer.close(closer);    }    closer.blockForPending();    return new H2ODrm(frame, labels);}
public static Frame mahout_f33_0(long nrow, int ncol, int minHint, int exactHint)
{    Vec.VectorGroup vg = new Vec.VectorGroup();    return emptyFrame(nrow, ncol, minHint, exactHint, vg);}
public static Frame mahout_f34_0(long nrow, int ncol, int minHint, int exactHint, Vec.VectorGroup vg)
{    int chunkSz = chunkSize(nrow, minHint, exactHint);        int nchunks = (int) ((nrow - 1) / chunkSz) + 1;    long[] espc = new long[nchunks + 1];    for (int i = 0; i < nchunks; i++) {        espc[i] = i * chunkSz;    }    espc[nchunks] = nrow;        Vec vtemplate = new Vec(vg.addVec(), espc);        Vec[] vecs = vtemplate.makeCons(ncol, 0, null, null);    return new Frame(vecs);}
public static Vec mahout_f35_0(final Vec template)
{    final int nChunks = template.nChunks();    Key<Vec> key = template.group().addVec();    final Vec emptystr = new Vec(key, template._espc, null, Vec.T_NUM);    new MRTask() {        @Override        protected void setupLocal() {            for (int i = 0; i < nChunks; i++) {                Key k = emptystr.chunkKey(i);                int chklen = vecChunkLen(template, i);                int[] stridx = new int[chklen];                byte[] b = new byte[1];                b[0] = 0;                for (int j = 0; j < chklen; j++) stridx[j] = -1;                if (k.home())                    DKV.put(k, new CStrChunk(1, b, chklen, stridx), _fs);            }            if (emptystr._key.home())                DKV.put(emptystr._key, emptystr, _fs);        }    }.doAllNodes();    return emptystr;}
protected void mahout_f36_0()
{    for (int i = 0; i < nChunks; i++) {        Key k = emptystr.chunkKey(i);        int chklen = vecChunkLen(template, i);        int[] stridx = new int[chklen];        byte[] b = new byte[1];        b[0] = 0;        for (int j = 0; j < chklen; j++) stridx[j] = -1;        if (k.home())            DKV.put(k, new CStrChunk(1, b, chklen, stridx), _fs);    }    if (emptystr._key.home())        DKV.put(emptystr._key, emptystr, _fs);}
public static int mahout_f37_0(Vec template, int chunk)
{    return (int) (template._espc[chunk + 1] - template._espc[chunk]);}
public static H2ODrm mahout_f38_0(long nrow, int ncol, int minHint, int exactHint)
{    return new H2ODrm(emptyFrame(nrow, ncol, minHint, exactHint));}
public static Matrix mahout_f39_0(H2ODrm drmA, Object bmfn, Object rfn)
{    class MRTaskMR extends MRTask<MRTaskMR> {        H2OBCast<Matrix> bmf_out;        Serializable bmf;        Serializable rf;        public MRTaskMR(Object _bmf, Object _rf) {            bmf = (Serializable) _bmf;            rf = (Serializable) _rf;        }        @Override        public void map(Chunk[] chks) {            Function1 f = (Function1) bmf;            bmf_out = new H2OBCast((Matrix) f.apply(new scala.Tuple2(null, new H2OBlockMatrix(chks))));        }        @Override        public void reduce(MRTaskMR that) {            Function2 f = (Function2) rf;            bmf_out = new H2OBCast((Matrix) f.apply(this.bmf_out.value(), that.bmf_out.value()));        }    }    return new MRTaskMR(bmfn, rfn).doAll(drmA.frame).bmf_out.value();}
public void mahout_f40_0(Chunk[] chks)
{    Function1 f = (Function1) bmf;    bmf_out = new H2OBCast((Matrix) f.apply(new scala.Tuple2(null, new H2OBlockMatrix(chks))));}
public void mahout_f41_0(MRTaskMR that)
{    Function2 f = (Function2) rf;    bmf_out = new H2OBCast((Matrix) f.apply(this.bmf_out.value(), that.bmf_out.value()));}
public static H2ODrm mahout_f42_0(H2ODrm drmA, H2ODrm drmB)
{    Frame A = drmA.frame;    Vec keys = drmA.keys;    final Frame B = drmB.frame;    int ABt_cols = (int) B.numRows();                        Frame ABt = new MRTask() {        public void map(Chunk[] chks, NewChunk[] ncs) {            int chunkSize = chks[0].len();            Vec[] B_vecs = B.vecs();            for (int c = 0; c < ncs.length; c++) {                for (int r = 0; r < chunkSize; r++) {                    double v = 0;                    for (int i = 0; i < chks.length; i++) {                        v += (chks[i].atd(r) * B_vecs[i].at(c));                    }                    ncs[c].addNum(v);                }            }        }    }.doAll(ABt_cols, A).outputFrame(null, null);        return new H2ODrm(ABt, keys);}
public void mahout_f43_0(Chunk[] chks, NewChunk[] ncs)
{    int chunkSize = chks[0].len();    Vec[] B_vecs = B.vecs();    for (int c = 0; c < ncs.length; c++) {        for (int r = 0; r < chunkSize; r++) {            double v = 0;            for (int i = 0; i < chks.length; i++) {                v += (chks[i].atd(r) * B_vecs[i].at(c));            }            ncs[c].addNum(v);        }    }}
public static H2ODrm mahout_f44_0(H2ODrm drmA, H2ODrm drmB, final String op)
{    final Frame A = drmA.frame;    final Frame B = drmB.frame;    Vec keys = drmA.keys;    int AewB_cols = A.numCols();                        Frame AewB = new MRTask() {        private double opfn(String op, double a, double b) {            if (a == 0.0 && b == 0.0) {                return 0.0;            }            if (op.equals("+")) {                return a + b;            } else if (op.equals("-")) {                return a - b;            } else if (op.equals("*")) {                return a * b;            } else if (op.equals("/")) {                return a / b;            }            return 0.0;        }        @Override        public void map(Chunk[] chks, NewChunk[] ncs) {            int chunkSize = chks[0].len();            Vec[] B_vecs = B.vecs();            long start = chks[0].start();            for (int c = 0; c < chks.length; c++) {                for (int r = 0; r < chunkSize; r++) {                    ncs[c].addNum(opfn(op, chks[c].atd(r), B_vecs[c].at(start + r)));                }            }        }    }.doAll(AewB_cols, A).outputFrame(null, null);        return new H2ODrm(AewB, keys);}
private double mahout_f45_0(String op, double a, double b)
{    if (a == 0.0 && b == 0.0) {        return 0.0;    }    if (op.equals("+")) {        return a + b;    } else if (op.equals("-")) {        return a - b;    } else if (op.equals("*")) {        return a * b;    } else if (op.equals("/")) {        return a / b;    }    return 0.0;}
public void mahout_f46_0(Chunk[] chks, NewChunk[] ncs)
{    int chunkSize = chks[0].len();    Vec[] B_vecs = B.vecs();    long start = chks[0].start();    for (int c = 0; c < chks.length; c++) {        for (int r = 0; r < chunkSize; r++) {            ncs[c].addNum(opfn(op, chks[c].atd(r), B_vecs[c].at(start + r)));        }    }}
public static H2ODrm mahout_f47_0(H2ODrm drmA, final double s, final String op)
{    Frame A = drmA.frame;    Vec keys = drmA.keys;    int AewScalar_cols = A.numCols();            Frame AewScalar = new MRTask() {        private double opfn(String op, double a, double b) {            if (a == 0.0 && b == 0.0) {                return 0.0;            }            if (op.equals("+")) {                return a + b;            } else if (op.equals("-")) {                return a - b;            } else if (op.equals("*")) {                return a * b;            } else if (op.equals("/")) {                return a / b;            }            return 0.0;        }        public void map(Chunk[] chks, NewChunk[] ncs) {            int chunkSize = chks[0].len();            long start = chks[0].start();            for (int c = 0; c < chks.length; c++) {                for (int r = 0; r < chunkSize; r++) {                    ncs[c].addNum(opfn(op, chks[c].atd(r), s));                }            }        }    }.doAll(AewScalar_cols, A).outputFrame(null, null);        return new H2ODrm(AewScalar, keys);}
private double mahout_f48_0(String op, double a, double b)
{    if (a == 0.0 && b == 0.0) {        return 0.0;    }    if (op.equals("+")) {        return a + b;    } else if (op.equals("-")) {        return a - b;    } else if (op.equals("*")) {        return a * b;    } else if (op.equals("/")) {        return a / b;    }    return 0.0;}
public void mahout_f49_0(Chunk[] chks, NewChunk[] ncs)
{    int chunkSize = chks[0].len();    long start = chks[0].start();    for (int c = 0; c < chks.length; c++) {        for (int r = 0; r < chunkSize; r++) {            ncs[c].addNum(opfn(op, chks[c].atd(r), s));        }    }}
public static H2ODrm mahout_f50_0(H2ODrm drmA, Object f, final boolean evalZeros)
{    Frame A = drmA.frame;    Vec keys = drmA.keys;    final int ncol = A.numCols();    /**     * MRTask to execute fn on all elements.     */    class MRTaskAewUnary extends MRTask<MRTaskAewUnary> {        Serializable fn;        MRTaskAewUnary(Object _fn) {            fn = (Serializable) _fn;        }        public void map(Chunk[] chks, NewChunk[] ncs) {            for (int c = 0; c < chks.length; c++) {                Chunk chk = chks[c];                Function1 f = (Function1) fn;                int ChunkLen = chk.len();                if (!evalZeros && chk.isSparse()) {                    /* sparse and skip zeros */                    int prev_offset = -1;                    for (int r = chk.nextNZ(-1); r < ChunkLen; r = chk.nextNZ(prev_offset)) {                        if (r - prev_offset > 1)                            ncs[c].addZeros(r - prev_offset - 1);                        ncs[c].addNum((double) f.apply(chk.atd(r)));                        prev_offset = r;                    }                    if (ChunkLen - prev_offset > 1)                        ncs[c].addZeros(chk._len - prev_offset - 1);                } else {                    /* dense or non-skip zeros */                    for (int r = 0; r < ChunkLen; r++) {                        ncs[c].addNum((double) f.apply(chk.atd(r)));                    }                }            }        }    }    Frame fmap = new MRTaskAewUnary(f).doAll(ncol, A).outputFrame(null, null);    return new H2ODrm(fmap, keys);}
public void mahout_f51_0(Chunk[] chks, NewChunk[] ncs)
{    for (int c = 0; c < chks.length; c++) {        Chunk chk = chks[c];        Function1 f = (Function1) fn;        int ChunkLen = chk.len();        if (!evalZeros && chk.isSparse()) {            /* sparse and skip zeros */            int prev_offset = -1;            for (int r = chk.nextNZ(-1); r < ChunkLen; r = chk.nextNZ(prev_offset)) {                if (r - prev_offset > 1)                    ncs[c].addZeros(r - prev_offset - 1);                ncs[c].addNum((double) f.apply(chk.atd(r)));                prev_offset = r;            }            if (ChunkLen - prev_offset > 1)                ncs[c].addZeros(chk._len - prev_offset - 1);        } else {            /* dense or non-skip zeros */            for (int r = 0; r < ChunkLen; r++) {                ncs[c].addNum((double) f.apply(chk.atd(r)));            }        }    }}
public static H2ODrm mahout_f52_0(H2ODrm drmA)
{    final Frame A = drmA.frame;            Frame At = H2OHelper.emptyFrame(A.numCols(), (int) A.numRows(), -1, -1);            new MRTask() {        public void map(Chunk[] chks) {            int chunkSize = chks[0].len();            long start = chks[0].start();            Vec[] A_vecs = A.vecs();            for (int c = 0; c < chks.length; c++) {                for (int r = 0; r < chunkSize; r++) {                    chks[c].set(r, A_vecs[(int) (start + r)].at(c));                }            }        }    }.doAll(At);        return new H2ODrm(At);}
public void mahout_f53_0(Chunk[] chks)
{    int chunkSize = chks[0].len();    long start = chks[0].start();    Vec[] A_vecs = A.vecs();    for (int c = 0; c < chks.length; c++) {        for (int r = 0; r < chunkSize; r++) {            chks[c].set(r, A_vecs[(int) (start + r)].at(c));        }    }}
public static H2ODrm mahout_f54_0(H2ODrm drmA)
{    final Frame A = drmA.frame;        Frame AtA = H2OHelper.emptyFrame(A.numCols(), A.numCols(), -1, -1);                    new MRTask() {        public void map(Chunk[] chks) {            int chunkSize = chks[0].len();            long start = chks[0].start();            Vec[] A_vecs = A.vecs();            long A_rows = A.numRows();            for (int c = 0; c < chks.length; c++) {                for (int r = 0; r < chunkSize; r++) {                    double v = 0;                    for (long i = 0; i < A_rows; i++) {                        v += (A_vecs[(int) (start + r)].at(i) * A_vecs[c].at(i));                    }                    chks[c].set(r, v);                }            }        }    }.doAll(AtA);        return new H2ODrm(AtA);}
public void mahout_f55_0(Chunk[] chks)
{    int chunkSize = chks[0].len();    long start = chks[0].start();    Vec[] A_vecs = A.vecs();    long A_rows = A.numRows();    for (int c = 0; c < chks.length; c++) {        for (int r = 0; r < chunkSize; r++) {            double v = 0;            for (long i = 0; i < A_rows; i++) {                v += (A_vecs[(int) (start + r)].at(i) * A_vecs[c].at(i));            }            chks[c].set(r, v);        }    }}
public static H2ODrm mahout_f56_0(H2ODrm drmA, H2ODrm drmB)
{    final Frame A = drmA.frame;    final Frame B = drmB.frame;        Frame AtB = H2OHelper.emptyFrame(A.numCols(), B.numCols(), -1, -1);                    new MRTask() {        public void map(Chunk[] chks) {            int chunkSize = chks[0].len();            long start = chks[0].start();            long A_rows = A.numRows();            Vec[] A_vecs = A.vecs();            Vec[] B_vecs = B.vecs();            for (int c = 0; c < chks.length; c++) {                for (int r = 0; r < chunkSize; r++) {                    double v = 0;                    for (long i = 0; i < A_rows; i++) {                        v += (A_vecs[(int) (start + r)].at(i) * B_vecs[c].at(i));                    }                    chks[c].set(r, v);                }            }        }    }.doAll(AtB);        return new H2ODrm(AtB);}
public void mahout_f57_0(Chunk[] chks)
{    int chunkSize = chks[0].len();    long start = chks[0].start();    long A_rows = A.numRows();    Vec[] A_vecs = A.vecs();    Vec[] B_vecs = B.vecs();    for (int c = 0; c < chks.length; c++) {        for (int r = 0; r < chunkSize; r++) {            double v = 0;            for (long i = 0; i < A_rows; i++) {                v += (A_vecs[(int) (start + r)].at(i) * B_vecs[c].at(i));            }            chks[c].set(r, v);        }    }}
public static H2ODrm mahout_f58_0(H2ODrm drmA, Vector x)
{    Frame A = drmA.frame;    final H2OBCast<Vector> bx = new H2OBCast<>(x);        class MRTaskAtx extends MRTask<MRTaskAtx> {        double[] atx;        public void map(Chunk[] chks) {            int chunkSize = chks[0].len();            Vector x = bx.value();            long start = chks[0].start();            atx = new double[chks.length];            for (int r = 0; r < chunkSize; r++) {                double d = x.getQuick((int) start + r);                for (int c = 0; c < chks.length; c++) {                    atx[c] += (chks[c].atd(r) * d);                }            }        }        public void reduce(MRTaskAtx other) {            ArrayUtils.add(atx, other.atx);        }    }                Vector v = new DenseVector(new MRTaskAtx().doAll(A).atx);    Matrix m = new DenseMatrix(A.numCols(), 1);    m.assignColumn(0, v);    return H2OHelper.drmFromMatrix(m, -1, -1);}
public void mahout_f59_0(Chunk[] chks)
{    int chunkSize = chks[0].len();    Vector x = bx.value();    long start = chks[0].start();    atx = new double[chks.length];    for (int r = 0; r < chunkSize; r++) {        double d = x.getQuick((int) start + r);        for (int c = 0; c < chks.length; c++) {            atx[c] += (chks[c].atd(r) * d);        }    }}
public void mahout_f60_0(MRTaskAtx other)
{    ArrayUtils.add(atx, other.atx);}
public static H2ODrm mahout_f61_0(H2ODrm drmA, Vector x)
{    Frame A = drmA.frame;    Vec keys = drmA.keys;    final H2OBCast<Vector> bx = new H2OBCast<>(x);                    Frame Ax = new MRTask() {        public void map(Chunk[] chks, NewChunk nc) {            int chunkSize = chks[0].len();            Vector x = bx.value();            for (int r = 0; r < chunkSize; r++) {                double v = 0;                for (int c = 0; c < chks.length; c++) {                    v += (chks[c].atd(r) * x.getQuick(c));                }                nc.addNum(v);            }        }    }.doAll(1, A).outputFrame(null, null);        return new H2ODrm(Ax, keys);}
public void mahout_f62_0(Chunk[] chks, NewChunk nc)
{    int chunkSize = chks[0].len();    Vector x = bx.value();    for (int r = 0; r < chunkSize; r++) {        double v = 0;        for (int c = 0; c < chks.length; c++) {            v += (chks[c].atd(r) * x.getQuick(c));        }        nc.addNum(v);    }}
public static H2ODrm mahout_f63_0(H2ODrm drmA, H2ODrm drmB)
{    Frame fra = drmA.frame;    Vec keysa = drmA.keys;    Frame frb = drmB.frame;    Vec keysb = drmB.keys;        if (fra.anyVec().group() == frb.anyVec().group()) {                return zip(fra, keysa, frb, keysb);    } else {                return join(fra, keysa, frb, keysb);    }}
private static H2ODrm mahout_f64_0(final Frame fra, final Vec keysa, final Frame frb, final Vec keysb)
{        Vec[] vecs = new Vec[fra.vecs().length + frb.vecs().length];    int d = 0;        for (Vec vfra : fra.vecs()) {        vecs[d++] = vfra;    }        for (Vec vfrb : frb.vecs()) {        vecs[d++] = vfrb;    }        Frame fr = new Frame(vecs);    /* Finally, inherit A's string labels into the result */    return new H2ODrm(fr, keysa);}
private static H2ODrm mahout_f65_0(final Frame fra, final Vec keysa, final Frame frb, final Vec keysb)
{        Vec[] bvecs = new Vec[frb.vecs().length];    for (int i = 0; i < bvecs.length; i++) {                bvecs[i] = fra.anyVec().makeZero();    }            new MRTask() {        public void map(Chunk[] chks) {            int chunkSize = chks[0].len();            long start = chks[0].start();            Vec[] vecs = frb.vecs();            for (int r = 0; r < chunkSize; r++) {                for (int c = 0; c < chks.length; c++) {                                        chks[c].set(r, vecs[c].at(start + r));                }            }        }    }.doAll(bvecs);        return zip(fra, keysa, new Frame(bvecs), null);}
public void mahout_f66_0(Chunk[] chks)
{    int chunkSize = chks[0].len();    long start = chks[0].start();    Vec[] vecs = frb.vecs();    for (int r = 0; r < chunkSize; r++) {        for (int c = 0; c < chks.length; c++) {                        chks[c].set(r, vecs[c].at(start + r));        }    }}
public static H2ODrm mahout_f67_0(H2ODrm drmA, double scalar, boolean leftbind)
{    Frame fra = drmA.frame;    Vec newcol = fra.anyVec().makeCon(scalar);    Vec[] vecs = new Vec[fra.vecs().length + 1];    int d = 0;    if (leftbind)        vecs[d++] = newcol;    for (Vec vfra : fra.vecs()) vecs[d++] = vfra;    if (!leftbind)        vecs[d++] = newcol;    return new H2ODrm(new Frame(vecs), drmA.keys);}
public static H2ODrm mahout_f68_0(H2ODrm drmA, int ncol, Object bmf, final boolean isRstr, final ClassTag<K> k, final ClassTag<R> r)
{    Frame A = drmA.frame;    Vec keys = drmA.keys;    /**     * MRTask to execute bmf on partitions. Partitions are     * made accessible to bmf in the form of H2OBlockMatrix.     */    class MRTaskBMF extends MRTask<MRTaskBMF> {        Serializable bmf;        Vec labels;        MRTaskBMF(Object _bmf, Vec _labels) {                                                                                                bmf = (Serializable) _bmf;            labels = _labels;        }        /**         * Create H2OBlockMatrix from the partition         */        private Matrix blockify(Chunk[] chks) {            return new H2OBlockMatrix(chks);        }        /**         * Ingest the output of bmf into the output partition         */        private void deblockify(Matrix out, NewChunk[] ncs) {                        for (int c = 0; c < out.columnSize(); c++) {                for (int r = 0; r < out.rowSize(); r++) {                    ncs[c].addNum(out.getQuick(r, c));                }            }        }                                                                                                                public void map(Chunk[] chks, NewChunk[] ncs) {            long start = chks[0].start();            NewChunk nclabel = isRstr ? ncs[ncs.length - 1] : null;            deblockify(MapBlockHelper.exec(bmf, blockify(chks), start, labels, nclabel, k, r), ncs);                }    }    int ncolRes = ncol + (isRstr ? 1 : 0);    Frame fmap = new MRTaskBMF(bmf, keys).doAll(ncolRes, A).outputFrame(null, null);    Vec vmap = null;    if (isRstr) {                                vmap = fmap.vecs()[ncol];        fmap = new Frame(Arrays.copyOfRange(fmap.vecs(), 0, ncol));    }    return new H2ODrm(fmap, vmap);}
private Matrix mahout_f69_0(Chunk[] chks)
{    return new H2OBlockMatrix(chks);}
private void mahout_f70_0(Matrix out, NewChunk[] ncs)
{        for (int c = 0; c < out.columnSize(); c++) {        for (int r = 0; r < out.rowSize(); r++) {            ncs[c].addNum(out.getQuick(r, c));        }    }}
public void mahout_f71_0(Chunk[] chks, NewChunk[] ncs)
{    long start = chks[0].start();    NewChunk nclabel = isRstr ? ncs[ncs.length - 1] : null;    deblockify(MapBlockHelper.exec(bmf, blockify(chks), start, labels, nclabel, k, r), ncs);}
public static H2ODrm mahout_f72_0(H2ODrm drmA, int min, int exact)
{    final Frame frin = drmA.frame;    final Vec vin = drmA.keys;        Frame frout = H2OHelper.emptyFrame(frin.numRows(), frin.numCols(), min, exact);    Vec vout = null;    if (vin != null) {                                                                vout = new MRTask() {            public void map(Chunk[] chks, NewChunk nc) {                int chunkSize = chks[0].len();                Vec[] vins = frin.vecs();                long start = chks[0].start();                ValueString vstr = new ValueString();                for (int r = 0; r < chunkSize; r++) {                    for (int c = 0; c < chks.length; c++) {                        chks[c].set(r, vins[c].at(start + r));                    }                    nc.addStr(vin.atStr(vstr, start + r));                }            }        }.doAll(1, frout).outputFrame(null, null).anyVec();    } else {                        new MRTask() {            public void map(Chunk[] chks) {                int chunkSize = chks[0].len();                Vec[] vins = frin.vecs();                long start = chks[0].start();                for (int r = 0; r < chunkSize; r++) {                    for (int c = 0; c < chks.length; c++) {                        chks[c].set(r, vins[c].at(start + r));                    }                }            }        }.doAll(frout);    }    return new H2ODrm(frout, vout);}
public void mahout_f73_0(Chunk[] chks, NewChunk nc)
{    int chunkSize = chks[0].len();    Vec[] vins = frin.vecs();    long start = chks[0].start();    ValueString vstr = new ValueString();    for (int r = 0; r < chunkSize; r++) {        for (int c = 0; c < chks.length; c++) {            chks[c].set(r, vins[c].at(start + r));        }        nc.addStr(vin.atStr(vstr, start + r));    }}
public void mahout_f74_0(Chunk[] chks)
{    int chunkSize = chks[0].len();    Vec[] vins = frin.vecs();    long start = chks[0].start();    for (int r = 0; r < chunkSize; r++) {        for (int c = 0; c < chks.length; c++) {            chks[c].set(r, vins[c].at(start + r));        }    }}
public static H2ODrm mahout_f75_0(H2ODrm drmA, H2ODrm drmB)
{    final Frame fra = drmA.frame;    final Vec keysa = drmA.keys;    final Frame frb = drmB.frame;    final Vec keysb = drmB.keys;                Frame frbind = H2OHelper.emptyFrame(fra.numRows() + frb.numRows(), fra.numCols(), -1, -1, fra.anyVec().group());    Vec keys = null;    MRTask task = new MRTask() {        public void map(Chunk[] chks, NewChunk nc) {            Vec[] A_vecs = fra.vecs();            Vec[] B_vecs = frb.vecs();            long A_rows = fra.numRows();            long B_rows = frb.numRows();            long start = chks[0].start();            int chunkSize = chks[0].len();            ValueString vstr = new ValueString();            for (int r = 0; r < chunkSize; r++) {                for (int c = 0; c < chks.length; c++) {                    if (r + start < A_rows) {                        chks[c].set(r, A_vecs[c].at(r + start));                        if (keysa != null) {                            nc.addStr(keysa.atStr(vstr, r + start));                        }                    } else {                        chks[c].set(r, B_vecs[c].at(r + start - A_rows));                        if (keysb != null) {                            nc.addStr(keysb.atStr(vstr, r + start - A_rows));                        }                    }                }            }        }    };    if (keysa == null) {        keys = task.doAll(1, frbind).outputFrame(null, null).anyVec();    } else {        task.doAll(frbind);    }    return new H2ODrm(frbind, keys);}
public void mahout_f76_0(Chunk[] chks, NewChunk nc)
{    Vec[] A_vecs = fra.vecs();    Vec[] B_vecs = frb.vecs();    long A_rows = fra.numRows();    long B_rows = frb.numRows();    long start = chks[0].start();    int chunkSize = chks[0].len();    ValueString vstr = new ValueString();    for (int r = 0; r < chunkSize; r++) {        for (int c = 0; c < chks.length; c++) {            if (r + start < A_rows) {                chks[c].set(r, A_vecs[c].at(r + start));                if (keysa != null) {                    nc.addStr(keysa.atStr(vstr, r + start));                }            } else {                chks[c].set(r, B_vecs[c].at(r + start - A_rows));                if (keysb != null) {                    nc.addStr(keysb.atStr(vstr, r + start - A_rows));                }            }        }    }}
public static H2ODrm mahout_f77_0(H2ODrm drmA, final Range R)
{    Frame A = drmA.frame;    Vec keys = drmA.keys;            Frame Arr = new MRTask() {        public void map(Chunk[] chks, NewChunk[] ncs) {            int chunkSize = chks[0].len();            long chunkStart = chks[0].start();                        if (chunkStart > R.end() || (chunkStart + chunkSize) < R.start()) {                return;            }                        for (int r = 0; r < chunkSize; r++) {                if (!R.contains(chunkStart + r)) {                    continue;                }                for (int c = 0; c < chks.length; c++) {                    ncs[c].addNum(chks[c].atd(r));                }            }        }    }.doAll(A.numCols(), A).outputFrame(null, null);    Vec Vrr = (keys == null) ? null : new MRTask() {                        public void map(Chunk chk, NewChunk nc) {            int chunkSize = chk.len();            long chunkStart = chk.start();            ValueString vstr = new ValueString();            if (chunkStart > R.end() || (chunkStart + chunkSize) < R.start()) {                return;            }            for (int r = 0; r < chunkSize; r++) {                if (!R.contains(chunkStart + r)) {                    continue;                }                nc.addStr(chk.atStr(vstr, r));            }        }    }.doAll(1, keys).outputFrame(null, null).anyVec();    return new H2ODrm(Arr, Vrr);}
public void mahout_f78_0(Chunk[] chks, NewChunk[] ncs)
{    int chunkSize = chks[0].len();    long chunkStart = chks[0].start();        if (chunkStart > R.end() || (chunkStart + chunkSize) < R.start()) {        return;    }        for (int r = 0; r < chunkSize; r++) {        if (!R.contains(chunkStart + r)) {            continue;        }        for (int c = 0; c < chks.length; c++) {            ncs[c].addNum(chks[c].atd(r));        }    }}
public void mahout_f79_0(Chunk chk, NewChunk nc)
{    int chunkSize = chk.len();    long chunkStart = chk.start();    ValueString vstr = new ValueString();    if (chunkStart > R.end() || (chunkStart + chunkSize) < R.start()) {        return;    }    for (int r = 0; r < chunkSize; r++) {        if (!R.contains(chunkStart + r)) {            continue;        }        nc.addStr(chk.atStr(vstr, r));    }}
public static H2ODrm mahout_f80_0(H2ODrm drmA, Matrix B)
{    Frame A = drmA.frame;    Vec keys = drmA.keys;    Frame AinCoreB = null;    if (B instanceof DiagonalMatrix) {        AinCoreB = execDiagonal(A, B.viewDiagonal());    } else {        AinCoreB = execCommon(A, B);    }    return new H2ODrm(AinCoreB, keys);}
private static Frame mahout_f81_0(final Frame A, Vector d)
{    final H2OBCast<Vector> bd = new H2OBCast<>(d);    return new MRTask() {        public void map(Chunk[] chks, NewChunk[] ncs) {            Vector D = bd.value();            int chunkSize = chks[0].len();            for (int c = 0; c < ncs.length; c++) {                for (int r = 0; r < chunkSize; r++) {                    double v = (chks[c].atd(r) * D.getQuick(c));                    ncs[c].addNum(v);                }            }        }    }.doAll(d.size(), A).outputFrame(null, null);}
public void mahout_f82_0(Chunk[] chks, NewChunk[] ncs)
{    Vector D = bd.value();    int chunkSize = chks[0].len();    for (int c = 0; c < ncs.length; c++) {        for (int r = 0; r < chunkSize; r++) {            double v = (chks[c].atd(r) * D.getQuick(c));            ncs[c].addNum(v);        }    }}
private static Frame mahout_f83_0(final Frame A, Matrix b)
{    final H2OBCast<Matrix> bb = new H2OBCast<>(b);    return new MRTask() {        public void map(Chunk[] chks, NewChunk[] ncs) {            Matrix B = bb.value();            int chunkSize = chks[0].len();            for (int c = 0; c < ncs.length; c++) {                for (int r = 0; r < chunkSize; r++) {                    double v = 0;                    for (int i = 0; i < chks.length; i++) {                        v += (chks[i].atd(r) * B.getQuick(i, c));                    }                    ncs[c].addNum(v);                }            }        }    }.doAll(b.columnSize(), A).outputFrame(null, null);}
public void mahout_f84_0(Chunk[] chks, NewChunk[] ncs)
{    Matrix B = bb.value();    int chunkSize = chks[0].len();    for (int c = 0; c < ncs.length; c++) {        for (int r = 0; r < chunkSize; r++) {            double v = 0;            for (int i = 0; i < chks.length; i++) {                v += (chks[i].atd(r) * B.getQuick(i, c));            }            ncs[c].addNum(v);        }    }}
protected int mahout_f85_0()
{    return BenchmarkRunner.randIndex();}
protected boolean mahout_f86_0()
{    return BenchmarkRunner.randBool();}
protected boolean mahout_f87_0(Vector v)
{    return randIndex() < v.getNumNondefaultElements();}
protected int mahout_f88_0()
{    return BenchmarkRunner.randIndex();}
protected boolean mahout_f89_0()
{    return BenchmarkRunner.randBool();}
protected boolean mahout_f90_0(Vector v)
{    return randIndex() < v.getNumNondefaultElements();}
private static int mahout_f91_0()
{    return R.nextInt(BUCKET_SIZE);}
private static boolean mahout_f92_0()
{    return R.nextBoolean();}
public TimingStatistics mahout_f93_0(BenchmarkFn function)
{    TimingStatistics stats = new TimingStatistics();    boolean result = false;    while (true) {        int i = R.nextInt(BUCKET_SIZE);        TimingStatistics.Call call = stats.newCall(leadTimeUsec);        result = result ^ function.apply(i);        if (call.end(maxTimeUsec)) {            break;        }    }    return stats;}
public TimingStatistics mahout_f94_0(BenchmarkFnD function)
{    TimingStatistics stats = new TimingStatistics();    double result = 0;    while (true) {        int i = R.nextInt(BUCKET_SIZE);        TimingStatistics.Call call = stats.newCall(leadTimeUsec);        result += function.apply(i);        if (call.end(maxTimeUsec)) {            break;        }    }        System.err.println("Result = " + result);    return stats;}
public void mahout_f95_0()
{    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            mark.vectors[0][mark.vIndex(i)] = mark.vectors[0][mark.vIndex(i)].clone();            return depends(mark.vectors[0][mark.vIndex(i)]);        }    }), CLONE, DENSE_VECTOR);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            mark.vectors[1][mark.vIndex(i)] = mark.vectors[1][mark.vIndex(i)].clone();            return depends(mark.vectors[1][mark.vIndex(i)]);        }    }), CLONE, RAND_SPARSE_VECTOR);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            mark.vectors[2][mark.vIndex(i)] = mark.vectors[2][mark.vIndex(i)].clone();            return depends(mark.vectors[2][mark.vIndex(i)]);        }    }), CLONE, SEQ_SPARSE_VECTOR);}
public Boolean mahout_f96_0(Integer i)
{    mark.vectors[0][mark.vIndex(i)] = mark.vectors[0][mark.vIndex(i)].clone();    return depends(mark.vectors[0][mark.vIndex(i)]);}
public Boolean mahout_f97_0(Integer i)
{    mark.vectors[1][mark.vIndex(i)] = mark.vectors[1][mark.vIndex(i)].clone();    return depends(mark.vectors[1][mark.vIndex(i)]);}
public Boolean mahout_f98_0(Integer i)
{    mark.vectors[2][mark.vIndex(i)] = mark.vectors[2][mark.vIndex(i)].clone();    return depends(mark.vectors[2][mark.vIndex(i)]);}
public void mahout_f99_0(DistanceMeasure measure) throws IOException
{    SparseMatrix clusterDistances = new SparseMatrix(mark.numClusters, mark.numClusters);    for (int i = 0; i < mark.numClusters; i++) {        for (int j = 0; j < mark.numClusters; j++) {            double distance = Double.POSITIVE_INFINITY;            if (i != j) {                distance = measure.distance(mark.clusters[i], mark.clusters[j]);            }            clusterDistances.setQuick(i, j, distance);        }    }    long distanceCalculations = 0;    TimingStatistics stats = new TimingStatistics();    for (int l = 0; l < mark.loop; l++) {        TimingStatistics.Call call = stats.newCall(mark.leadTimeUsec);        for (int i = 0; i < mark.numVectors; i++) {            Vector vector = mark.vectors[1][mark.vIndex(i)];            double minDistance = Double.MAX_VALUE;            for (int k = 0; k < mark.numClusters; k++) {                double distance = measure.distance(vector, mark.clusters[k]);                distanceCalculations++;                if (distance < minDistance) {                    minDistance = distance;                }            }        }        if (call.end(mark.maxTimeUsec)) {            break;        }    }    mark.printStats(stats, measure.getClass().getName(), "Closest C w/o Elkan's trick", "distanceCalculations = " + distanceCalculations);    distanceCalculations = 0;    stats = new TimingStatistics();    Random rand = RandomUtils.getRandom();    for (int l = 0; l < mark.loop; l++) {        TimingStatistics.Call call = stats.newCall(mark.leadTimeUsec);        for (int i = 0; i < mark.numVectors; i++) {            Vector vector = mark.vectors[1][mark.vIndex(i)];            int closestCentroid = rand.nextInt(mark.numClusters);            double dist = measure.distance(vector, mark.clusters[closestCentroid]);            distanceCalculations++;            for (int k = 0; k < mark.numClusters; k++) {                if (closestCentroid != k) {                    double centroidDist = clusterDistances.getQuick(k, closestCentroid);                    if (centroidDist < 2 * dist) {                        dist = measure.distance(vector, mark.clusters[k]);                        closestCentroid = k;                        distanceCalculations++;                    }                }            }        }        if (call.end(mark.maxTimeUsec)) {            break;        }    }    mark.printStats(stats, measure.getClass().getName(), "Closest C w/ Elkan's trick", "distanceCalculations = " + distanceCalculations);}
public void mahout_f100_0(final DistanceMeasure measure)
{    mark.printStats(mark.getRunner().benchmarkD(new BenchmarkFnD() {        @Override        public Double apply(Integer i) {            return measure.distance(mark.vectors[0][mark.vIndex(i)], mark.vectors[0][mark.vIndex(randIndex())]);        }    }), measure.getClass().getName(), DENSE_VECTOR);    mark.printStats(mark.getRunner().benchmarkD(new BenchmarkFnD() {        @Override        public Double apply(Integer i) {            return measure.distance(mark.vectors[1][mark.vIndex(i)], mark.vectors[1][mark.vIndex(randIndex())]);        }    }), measure.getClass().getName(), RAND_SPARSE_VECTOR);    mark.printStats(mark.getRunner().benchmarkD(new BenchmarkFnD() {        @Override        public Double apply(Integer i) {            return measure.distance(mark.vectors[2][mark.vIndex(i)], mark.vectors[2][mark.vIndex(randIndex())]);        }    }), measure.getClass().getName(), SEQ_SPARSE_VECTOR);    mark.printStats(mark.getRunner().benchmarkD(new BenchmarkFnD() {        @Override        public Double apply(Integer i) {            return measure.distance(mark.vectors[0][mark.vIndex(i)], mark.vectors[1][mark.vIndex(randIndex())]);        }    }), measure.getClass().getName(), DENSE_FN_RAND);    mark.printStats(mark.getRunner().benchmarkD(new BenchmarkFnD() {        @Override        public Double apply(Integer i) {            return measure.distance(mark.vectors[0][mark.vIndex(i)], mark.vectors[2][mark.vIndex(randIndex())]);        }    }), measure.getClass().getName(), DENSE_FN_SEQ);    mark.printStats(mark.getRunner().benchmarkD(new BenchmarkFnD() {        @Override        public Double apply(Integer i) {            return measure.distance(mark.vectors[1][mark.vIndex(i)], mark.vectors[0][mark.vIndex(randIndex())]);        }    }), measure.getClass().getName(), RAND_FN_DENSE);    mark.printStats(mark.getRunner().benchmarkD(new BenchmarkFnD() {        @Override        public Double apply(Integer i) {            return measure.distance(mark.vectors[1][mark.vIndex(i)], mark.vectors[2][mark.vIndex(randIndex())]);        }    }), measure.getClass().getName(), RAND_FN_SEQ);    mark.printStats(mark.getRunner().benchmarkD(new BenchmarkFnD() {        @Override        public Double apply(Integer i) {            return measure.distance(mark.vectors[2][mark.vIndex(i)], mark.vectors[0][mark.vIndex(randIndex())]);        }    }), measure.getClass().getName(), SEQ_FN_DENSE);    mark.printStats(mark.getRunner().benchmarkD(new BenchmarkFnD() {        @Override        public Double apply(Integer i) {            return measure.distance(mark.vectors[2][mark.vIndex(i)], mark.vectors[1][mark.vIndex(randIndex())]);        }    }), measure.getClass().getName(), SEQ_FN_RAND);}
public Double mahout_f101_0(Integer i)
{    return measure.distance(mark.vectors[0][mark.vIndex(i)], mark.vectors[0][mark.vIndex(randIndex())]);}
public Double mahout_f102_0(Integer i)
{    return measure.distance(mark.vectors[1][mark.vIndex(i)], mark.vectors[1][mark.vIndex(randIndex())]);}
public Double mahout_f103_0(Integer i)
{    return measure.distance(mark.vectors[2][mark.vIndex(i)], mark.vectors[2][mark.vIndex(randIndex())]);}
public Double mahout_f104_0(Integer i)
{    return measure.distance(mark.vectors[0][mark.vIndex(i)], mark.vectors[1][mark.vIndex(randIndex())]);}
public Double mahout_f105_0(Integer i)
{    return measure.distance(mark.vectors[0][mark.vIndex(i)], mark.vectors[2][mark.vIndex(randIndex())]);}
public Double mahout_f106_0(Integer i)
{    return measure.distance(mark.vectors[1][mark.vIndex(i)], mark.vectors[0][mark.vIndex(randIndex())]);}
public Double mahout_f107_0(Integer i)
{    return measure.distance(mark.vectors[1][mark.vIndex(i)], mark.vectors[2][mark.vIndex(randIndex())]);}
public Double mahout_f108_0(Integer i)
{    return measure.distance(mark.vectors[2][mark.vIndex(i)], mark.vectors[0][mark.vIndex(randIndex())]);}
public Double mahout_f109_0(Integer i)
{    return measure.distance(mark.vectors[2][mark.vIndex(i)], mark.vectors[1][mark.vIndex(randIndex())]);}
public void mahout_f110_0()
{    benchmarkDot();    benchmarkNorm1();    benchmarkNorm2();    benchmarkLogNormalize();}
private void mahout_f111_0()
{    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            return depends(mark.vectors[0][mark.vIndex(i)].logNormalize());        }    }), LOG_NORMALIZE, DENSE_VECTOR);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            return depends(mark.vectors[1][mark.vIndex(i)].logNormalize());        }    }), LOG_NORMALIZE, RAND_SPARSE_VECTOR);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            return depends(mark.vectors[2][mark.vIndex(i)].logNormalize());        }    }), LOG_NORMALIZE, SEQ_SPARSE_VECTOR);}
public Boolean mahout_f112_0(Integer i)
{    return depends(mark.vectors[0][mark.vIndex(i)].logNormalize());}
public Boolean mahout_f113_0(Integer i)
{    return depends(mark.vectors[1][mark.vIndex(i)].logNormalize());}
public Boolean mahout_f114_0(Integer i)
{    return depends(mark.vectors[2][mark.vIndex(i)].logNormalize());}
private void mahout_f115_0()
{    mark.printStats(mark.getRunner().benchmarkD(new BenchmarkFnD() {        @Override        public Double apply(Integer i) {            return mark.vectors[0][mark.vIndex(i)].norm(1);        }    }), NORM1, DENSE_VECTOR);    mark.printStats(mark.getRunner().benchmarkD(new BenchmarkFnD() {        @Override        public Double apply(Integer i) {            return mark.vectors[1][mark.vIndex(i)].norm(1);        }    }), NORM1, RAND_SPARSE_VECTOR);    mark.printStats(mark.getRunner().benchmarkD(new BenchmarkFnD() {        @Override        public Double apply(Integer i) {            return mark.vectors[2][mark.vIndex(i)].norm(1);        }    }), NORM1, SEQ_SPARSE_VECTOR);}
public Double mahout_f116_0(Integer i)
{    return mark.vectors[0][mark.vIndex(i)].norm(1);}
public Double mahout_f117_0(Integer i)
{    return mark.vectors[1][mark.vIndex(i)].norm(1);}
public Double mahout_f118_0(Integer i)
{    return mark.vectors[2][mark.vIndex(i)].norm(1);}
private void mahout_f119_0()
{    mark.printStats(mark.getRunner().benchmarkD(new BenchmarkFnD() {        @Override        public Double apply(Integer i) {            return mark.vectors[0][mark.vIndex(i)].norm(2);        }    }), NORM2, DENSE_VECTOR);    mark.printStats(mark.getRunner().benchmarkD(new BenchmarkFnD() {        @Override        public Double apply(Integer i) {            return mark.vectors[1][mark.vIndex(i)].norm(2);        }    }), NORM2, RAND_SPARSE_VECTOR);    mark.printStats(mark.getRunner().benchmarkD(new BenchmarkFnD() {        @Override        public Double apply(Integer i) {            return mark.vectors[2][mark.vIndex(i)].norm(2);        }    }), NORM2, SEQ_SPARSE_VECTOR);}
public Double mahout_f120_0(Integer i)
{    return mark.vectors[0][mark.vIndex(i)].norm(2);}
public Double mahout_f121_0(Integer i)
{    return mark.vectors[1][mark.vIndex(i)].norm(2);}
public Double mahout_f122_0(Integer i)
{    return mark.vectors[2][mark.vIndex(i)].norm(2);}
private void mahout_f123_0()
{    mark.printStats(mark.getRunner().benchmarkD(new BenchmarkFnD() {        @Override        public Double apply(Integer i) {            return mark.vectors[0][mark.vIndex(i)].dot(mark.vectors[0][mark.vIndex(randIndex())]);        }    }), DOT_PRODUCT, DENSE_VECTOR);    mark.printStats(mark.getRunner().benchmarkD(new BenchmarkFnD() {        @Override        public Double apply(Integer i) {            return mark.vectors[1][mark.vIndex(i)].dot(mark.vectors[1][mark.vIndex(randIndex())]);        }    }), DOT_PRODUCT, RAND_SPARSE_VECTOR);    mark.printStats(mark.getRunner().benchmarkD(new BenchmarkFnD() {        @Override        public Double apply(Integer i) {            return mark.vectors[2][mark.vIndex(i)].dot(mark.vectors[2][mark.vIndex(randIndex())]);        }    }), DOT_PRODUCT, SEQ_SPARSE_VECTOR);    mark.printStats(mark.getRunner().benchmarkD(new BenchmarkFnD() {        @Override        public Double apply(Integer i) {            return mark.vectors[0][mark.vIndex(i)].dot(mark.vectors[1][mark.vIndex(randIndex())]);        }    }), DOT_PRODUCT, DENSE_FN_RAND);    mark.printStats(mark.getRunner().benchmarkD(new BenchmarkFnD() {        @Override        public Double apply(Integer i) {            return mark.vectors[0][mark.vIndex(i)].dot(mark.vectors[2][mark.vIndex(randIndex())]);        }    }), DOT_PRODUCT, DENSE_FN_SEQ);    mark.printStats(mark.getRunner().benchmarkD(new BenchmarkFnD() {        @Override        public Double apply(Integer i) {            return mark.vectors[1][mark.vIndex(i)].dot(mark.vectors[0][mark.vIndex(randIndex())]);        }    }), DOT_PRODUCT, RAND_FN_DENSE);    mark.printStats(mark.getRunner().benchmarkD(new BenchmarkFnD() {        @Override        public Double apply(Integer i) {            return mark.vectors[1][mark.vIndex(i)].dot(mark.vectors[2][mark.vIndex(randIndex())]);        }    }), DOT_PRODUCT, RAND_FN_SEQ);    mark.printStats(mark.getRunner().benchmarkD(new BenchmarkFnD() {        @Override        public Double apply(Integer i) {            return mark.vectors[2][mark.vIndex(i)].dot(mark.vectors[0][mark.vIndex(randIndex())]);        }    }), DOT_PRODUCT, SEQ_FN_DENSE);    mark.printStats(mark.getRunner().benchmarkD(new BenchmarkFnD() {        @Override        public Double apply(Integer i) {            return mark.vectors[2][mark.vIndex(i)].dot(mark.vectors[1][mark.vIndex(randIndex())]);        }    }), DOT_PRODUCT, SEQ_FN_RAND);}
public Double mahout_f124_0(Integer i)
{    return mark.vectors[0][mark.vIndex(i)].dot(mark.vectors[0][mark.vIndex(randIndex())]);}
public Double mahout_f125_0(Integer i)
{    return mark.vectors[1][mark.vIndex(i)].dot(mark.vectors[1][mark.vIndex(randIndex())]);}
public Double mahout_f126_0(Integer i)
{    return mark.vectors[2][mark.vIndex(i)].dot(mark.vectors[2][mark.vIndex(randIndex())]);}
public Double mahout_f127_0(Integer i)
{    return mark.vectors[0][mark.vIndex(i)].dot(mark.vectors[1][mark.vIndex(randIndex())]);}
public Double mahout_f128_0(Integer i)
{    return mark.vectors[0][mark.vIndex(i)].dot(mark.vectors[2][mark.vIndex(randIndex())]);}
public Double mahout_f129_0(Integer i)
{    return mark.vectors[1][mark.vIndex(i)].dot(mark.vectors[0][mark.vIndex(randIndex())]);}
public Double mahout_f130_0(Integer i)
{    return mark.vectors[1][mark.vIndex(i)].dot(mark.vectors[2][mark.vIndex(randIndex())]);}
public Double mahout_f131_0(Integer i)
{    return mark.vectors[2][mark.vIndex(i)].dot(mark.vectors[0][mark.vIndex(randIndex())]);}
public Double mahout_f132_0(Integer i)
{    return mark.vectors[2][mark.vIndex(i)].dot(mark.vectors[1][mark.vIndex(randIndex())]);}
public static void mahout_f133_0(String[] args)
{    VectorBenchmarks mark = new VectorBenchmarks(1000000, 100, 1000, 10, 1);    mark.createData();    new DotBenchmark(mark).benchmarkNorm2();    System.out.println(mark);}
public void mahout_f134_0()
{    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[0][mark.vIndex(i)].minus(mark.vectors[0][mark.vIndex(randIndex())]);            return depends(v);        }    }), MINUS, DENSE_VECTOR);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[1][mark.vIndex(i)].minus(mark.vectors[1][mark.vIndex(randIndex())]);            return depends(v);        }    }), MINUS, RAND_SPARSE_VECTOR);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[2][mark.vIndex(i)].minus(mark.vectors[2][mark.vIndex(randIndex())]);            return depends(v);        }    }), MINUS, SEQ_SPARSE_VECTOR);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[0][mark.vIndex(i)].minus(mark.vectors[1][mark.vIndex(randIndex())]);            return depends(v);        }    }), MINUS, DENSE_FN_RAND);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[0][mark.vIndex(i)].minus(mark.vectors[2][mark.vIndex(randIndex())]);            return depends(v);        }    }), MINUS, DENSE_FN_SEQ);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[1][mark.vIndex(i)].minus(mark.vectors[0][mark.vIndex(randIndex())]);            return depends(v);        }    }), MINUS, RAND_FN_DENSE);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[1][mark.vIndex(i)].minus(mark.vectors[2][mark.vIndex(randIndex())]);            return depends(v);        }    }), MINUS, RAND_FN_SEQ);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[2][mark.vIndex(i)].minus(mark.vectors[0][mark.vIndex(randIndex())]);            return depends(v);        }    }), MINUS, SEQ_FN_DENSE);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[2][mark.vIndex(i)].minus(mark.vectors[1][mark.vIndex(randIndex())]);            return depends(v);        }    }), MINUS, SEQ_FN_RAND);}
public Boolean mahout_f135_0(Integer i)
{    Vector v = mark.vectors[0][mark.vIndex(i)].minus(mark.vectors[0][mark.vIndex(randIndex())]);    return depends(v);}
public Boolean mahout_f136_0(Integer i)
{    Vector v = mark.vectors[1][mark.vIndex(i)].minus(mark.vectors[1][mark.vIndex(randIndex())]);    return depends(v);}
public Boolean mahout_f137_0(Integer i)
{    Vector v = mark.vectors[2][mark.vIndex(i)].minus(mark.vectors[2][mark.vIndex(randIndex())]);    return depends(v);}
public Boolean mahout_f138_0(Integer i)
{    Vector v = mark.vectors[0][mark.vIndex(i)].minus(mark.vectors[1][mark.vIndex(randIndex())]);    return depends(v);}
public Boolean mahout_f139_0(Integer i)
{    Vector v = mark.vectors[0][mark.vIndex(i)].minus(mark.vectors[2][mark.vIndex(randIndex())]);    return depends(v);}
public Boolean mahout_f140_0(Integer i)
{    Vector v = mark.vectors[1][mark.vIndex(i)].minus(mark.vectors[0][mark.vIndex(randIndex())]);    return depends(v);}
public Boolean mahout_f141_0(Integer i)
{    Vector v = mark.vectors[1][mark.vIndex(i)].minus(mark.vectors[2][mark.vIndex(randIndex())]);    return depends(v);}
public Boolean mahout_f142_0(Integer i)
{    Vector v = mark.vectors[2][mark.vIndex(i)].minus(mark.vectors[0][mark.vIndex(randIndex())]);    return depends(v);}
public Boolean mahout_f143_0(Integer i)
{    Vector v = mark.vectors[2][mark.vIndex(i)].minus(mark.vectors[1][mark.vIndex(randIndex())]);    return depends(v);}
public void mahout_f144_0()
{    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[0][mark.vIndex(i)].plus(mark.vectors[0][mark.vIndex(randIndex())]);            return depends(v);        }    }), PLUS, DENSE_VECTOR);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[1][mark.vIndex(i)].plus(mark.vectors[1][mark.vIndex(randIndex())]);            return depends(v);        }    }), PLUS, RAND_SPARSE_VECTOR);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[2][mark.vIndex(i)].plus(mark.vectors[2][mark.vIndex(randIndex())]);            return depends(v);        }    }), PLUS, SEQ_SPARSE_VECTOR);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[0][mark.vIndex(i)].plus(mark.vectors[1][mark.vIndex(randIndex())]);            return depends(v);        }    }), PLUS, DENSE_FN_RAND);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[0][mark.vIndex(i)].plus(mark.vectors[2][mark.vIndex(randIndex())]);            return depends(v);        }    }), PLUS, DENSE_FN_SEQ);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[1][mark.vIndex(i)].plus(mark.vectors[0][mark.vIndex(randIndex())]);            return depends(v);        }    }), PLUS, RAND_FN_DENSE);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[1][mark.vIndex(i)].plus(mark.vectors[2][mark.vIndex(randIndex())]);            return depends(v);        }    }), PLUS, RAND_FN_SEQ);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[2][mark.vIndex(i)].plus(mark.vectors[0][mark.vIndex(randIndex())]);            return depends(v);        }    }), PLUS, SEQ_FN_DENSE);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[2][mark.vIndex(i)].plus(mark.vectors[1][mark.vIndex(randIndex())]);            return depends(v);        }    }), PLUS, SEQ_FN_RAND);}
public Boolean mahout_f145_0(Integer i)
{    Vector v = mark.vectors[0][mark.vIndex(i)].plus(mark.vectors[0][mark.vIndex(randIndex())]);    return depends(v);}
public Boolean mahout_f146_0(Integer i)
{    Vector v = mark.vectors[1][mark.vIndex(i)].plus(mark.vectors[1][mark.vIndex(randIndex())]);    return depends(v);}
public Boolean mahout_f147_0(Integer i)
{    Vector v = mark.vectors[2][mark.vIndex(i)].plus(mark.vectors[2][mark.vIndex(randIndex())]);    return depends(v);}
public Boolean mahout_f148_0(Integer i)
{    Vector v = mark.vectors[0][mark.vIndex(i)].plus(mark.vectors[1][mark.vIndex(randIndex())]);    return depends(v);}
public Boolean mahout_f149_0(Integer i)
{    Vector v = mark.vectors[0][mark.vIndex(i)].plus(mark.vectors[2][mark.vIndex(randIndex())]);    return depends(v);}
public Boolean mahout_f150_0(Integer i)
{    Vector v = mark.vectors[1][mark.vIndex(i)].plus(mark.vectors[0][mark.vIndex(randIndex())]);    return depends(v);}
public Boolean mahout_f151_0(Integer i)
{    Vector v = mark.vectors[1][mark.vIndex(i)].plus(mark.vectors[2][mark.vIndex(randIndex())]);    return depends(v);}
public Boolean mahout_f152_0(Integer i)
{    Vector v = mark.vectors[2][mark.vIndex(i)].plus(mark.vectors[0][mark.vIndex(randIndex())]);    return depends(v);}
public Boolean mahout_f153_0(Integer i)
{    Vector v = mark.vectors[2][mark.vIndex(i)].plus(mark.vectors[1][mark.vIndex(randIndex())]);    return depends(v);}
public void mahout_f154_0() throws IOException
{    serializeBenchmark();    deserializeBenchmark();}
public void mahout_f155_0() throws IOException
{    Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);    Writable one = new IntWritable(0);    VectorWritable vec = new VectorWritable();    TimingStatistics stats = new TimingStatistics();    try (SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, new Path("/tmp/dense-vector"), IntWritable.class, VectorWritable.class)) {        for (int i = 0; i < mark.loop; i++) {            TimingStatistics.Call call = stats.newCall(mark.leadTimeUsec);            vec.set(mark.vectors[0][mark.vIndex(i)]);            writer.append(one, vec);            if (call.end(mark.maxTimeUsec)) {                break;            }        }    }    mark.printStats(stats, SERIALIZE, DENSE_VECTOR);    stats = new TimingStatistics();    try (SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, new Path("/tmp/randsparse-vector"), IntWritable.class, VectorWritable.class)) {        for (int i = 0; i < mark.loop; i++) {            TimingStatistics.Call call = stats.newCall(mark.leadTimeUsec);            vec.set(mark.vectors[1][mark.vIndex(i)]);            writer.append(one, vec);            if (call.end(mark.maxTimeUsec)) {                break;            }        }    }    mark.printStats(stats, SERIALIZE, RAND_SPARSE_VECTOR);    stats = new TimingStatistics();    try (SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, new Path("/tmp/seqsparse-vector"), IntWritable.class, VectorWritable.class)) {        for (int i = 0; i < mark.loop; i++) {            TimingStatistics.Call call = stats.newCall(mark.leadTimeUsec);            vec.set(mark.vectors[2][mark.vIndex(i)]);            writer.append(one, vec);            if (call.end(mark.maxTimeUsec)) {                break;            }        }    }    mark.printStats(stats, SERIALIZE, SEQ_SPARSE_VECTOR);}
public void mahout_f156_0() throws IOException
{    doDeserializeBenchmark(DENSE_VECTOR, "/tmp/dense-vector");    doDeserializeBenchmark(RAND_SPARSE_VECTOR, "/tmp/randsparse-vector");    doDeserializeBenchmark(SEQ_SPARSE_VECTOR, "/tmp/seqsparse-vector");}
private void mahout_f157_0(String name, String pathString) throws IOException
{    TimingStatistics stats = new TimingStatistics();    TimingStatistics.Call call = stats.newCall(mark.leadTimeUsec);    SequenceFileValueIterator<Writable> iterator = new SequenceFileValueIterator<>(new Path(pathString), true, new Configuration());    while (iterator.hasNext()) {        iterator.next();        call.end();        call = stats.newCall(mark.leadTimeUsec);    }    iterator.close();    mark.printStats(stats, DESERIALIZE, name);}
public void mahout_f158_0()
{    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[0][mark.vIndex(i)].times(mark.vectors[0][mark.vIndex(randIndex())]);            return depends(v);        }    }), TIMES, DENSE_VECTOR);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[1][mark.vIndex(i)].times(mark.vectors[1][mark.vIndex(randIndex())]);            return depends(v);        }    }), TIMES, RAND_SPARSE_VECTOR);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[2][mark.vIndex(i)].times(mark.vectors[2][mark.vIndex(randIndex())]);            return depends(v);        }    }), TIMES, SEQ_SPARSE_VECTOR);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[0][mark.vIndex(i)].times(mark.vectors[1][mark.vIndex(randIndex())]);            return depends(v);        }    }), TIMES, DENSE_FN_RAND);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[0][mark.vIndex(i)].times(mark.vectors[2][mark.vIndex(randIndex())]);            return depends(v);        }    }), TIMES, DENSE_FN_SEQ);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[1][mark.vIndex(i)].times(mark.vectors[0][mark.vIndex(randIndex())]);            return depends(v);        }    }), TIMES, RAND_FN_DENSE);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[1][mark.vIndex(i)].times(mark.vectors[2][mark.vIndex(randIndex())]);            return depends(v);        }    }), TIMES, RAND_FN_SEQ);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[2][mark.vIndex(i)].times(mark.vectors[0][mark.vIndex(randIndex())]);            return depends(v);        }    }), TIMES, SEQ_FN_DENSE);    mark.printStats(mark.getRunner().benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            Vector v = mark.vectors[2][mark.vIndex(i)].times(mark.vectors[1][mark.vIndex(randIndex())]);            return depends(v);        }    }), TIMES, SEQ_FN_RAND);}
public Boolean mahout_f159_0(Integer i)
{    Vector v = mark.vectors[0][mark.vIndex(i)].times(mark.vectors[0][mark.vIndex(randIndex())]);    return depends(v);}
public Boolean mahout_f160_0(Integer i)
{    Vector v = mark.vectors[1][mark.vIndex(i)].times(mark.vectors[1][mark.vIndex(randIndex())]);    return depends(v);}
public Boolean mahout_f161_0(Integer i)
{    Vector v = mark.vectors[2][mark.vIndex(i)].times(mark.vectors[2][mark.vIndex(randIndex())]);    return depends(v);}
public Boolean mahout_f162_0(Integer i)
{    Vector v = mark.vectors[0][mark.vIndex(i)].times(mark.vectors[1][mark.vIndex(randIndex())]);    return depends(v);}
public Boolean mahout_f163_0(Integer i)
{    Vector v = mark.vectors[0][mark.vIndex(i)].times(mark.vectors[2][mark.vIndex(randIndex())]);    return depends(v);}
public Boolean mahout_f164_0(Integer i)
{    Vector v = mark.vectors[1][mark.vIndex(i)].times(mark.vectors[0][mark.vIndex(randIndex())]);    return depends(v);}
public Boolean mahout_f165_0(Integer i)
{    Vector v = mark.vectors[1][mark.vIndex(i)].times(mark.vectors[2][mark.vIndex(randIndex())]);    return depends(v);}
public Boolean mahout_f166_0(Integer i)
{    Vector v = mark.vectors[2][mark.vIndex(i)].times(mark.vectors[0][mark.vIndex(randIndex())]);    return depends(v);}
public Boolean mahout_f167_0(Integer i)
{    Vector v = mark.vectors[2][mark.vIndex(i)].times(mark.vectors[1][mark.vIndex(randIndex())]);    return depends(v);}
private void mahout_f168_0(int cardinality, int numNonZeros, int numVectors)
{    for (int i = 0; i < numVectors; i++) {                Vector v = new SequentialAccessSparseVector(cardinality, numNonZeros);        BitSet featureSpace = new BitSet(cardinality);        int[] indexes = new int[numNonZeros];        double[] values = new double[numNonZeros];        int j = 0;        while (j < numNonZeros) {            double value = r.nextGaussian();            int index = r.nextInt(cardinality);            if (!featureSpace.get(index) && value != 0) {                featureSpace.set(index);                indexes[j] = index;                values[j++] = value;                v.set(index, value);            }        }        randomVectorIndices.add(indexes);        randomVectorValues.add(values);        randomVectors.add(v);    }}
 void mahout_f169_0(TimingStatistics stats, String benchmarkName, String implName, String content)
{    printStats(stats, benchmarkName, implName, content, 1);}
 void mahout_f170_0(TimingStatistics stats, String benchmarkName, String implName)
{    printStats(stats, benchmarkName, implName, "", 1);}
private void mahout_f171_1(TimingStatistics stats, String benchmarkName, String implName, String content, int multiplier)
{    float speed = multiplier * stats.getNCalls() * (numNonZeros * 1000.0f * 12 / stats.getSumTime());    float opsPerSec = stats.getNCalls() * 1000000000.0f / stats.getSumTime();        if (!implType.containsKey(implName)) {        implType.put(implName, implType.size());    }    int implId = implType.get(implName);    if (!statsMap.containsKey(benchmarkName)) {        statsMap.put(benchmarkName, new ArrayList<String[]>());    }    List<String[]> implStats = statsMap.get(benchmarkName);    while (implStats.size() < implId + 1) {        implStats.add(EMPTY);    }    implStats.set(implId, TAB_NEWLINE_PATTERN.split(stats + "\tSpeed  = " + DF.format(opsPerSec) + " /sec\tRate   = " + DF.format(speed) + " MB/s"));}
public void mahout_f172_0()
{    for (int i = 0; i < Math.max(numVectors, numClusters); ++i) {        vectors[0][vIndex(i)] = new DenseVector(randomVectors.get(vIndex(i)));        vectors[1][vIndex(i)] = new RandomAccessSparseVector(randomVectors.get(vIndex(i)));        vectors[2][vIndex(i)] = new SequentialAccessSparseVector(randomVectors.get(vIndex(i)));        if (numClusters > 0) {            clusters[cIndex(i)] = new RandomAccessSparseVector(randomVectors.get(vIndex(i)));        }    }}
public void mahout_f173_0()
{    printStats(runner.benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            vectors[0][vIndex(i)] = new DenseVector(randomVectors.get(vIndex(i)));            return depends(vectors[0][vIndex(i)]);        }    }), CREATE_COPY, DENSE_VECTOR);    printStats(runner.benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            vectors[1][vIndex(i)] = new RandomAccessSparseVector(randomVectors.get(vIndex(i)));            return depends(vectors[1][vIndex(i)]);        }    }), CREATE_COPY, RAND_SPARSE_VECTOR);    printStats(runner.benchmark(new BenchmarkFn() {        @Override        public Boolean apply(Integer i) {            vectors[2][vIndex(i)] = new SequentialAccessSparseVector(randomVectors.get(vIndex(i)));            return depends(vectors[2][vIndex(i)]);        }    }), CREATE_COPY, SEQ_SPARSE_VECTOR);    if (numClusters > 0) {        printStats(runner.benchmark(new BenchmarkFn() {            @Override            public Boolean apply(Integer i) {                clusters[cIndex(i)] = new RandomAccessSparseVector(randomVectors.get(vIndex(i)));                return depends(clusters[cIndex(i)]);            }        }), CREATE_COPY, CLUSTERS);    }}
public Boolean mahout_f174_0(Integer i)
{    vectors[0][vIndex(i)] = new DenseVector(randomVectors.get(vIndex(i)));    return depends(vectors[0][vIndex(i)]);}
public Boolean mahout_f175_0(Integer i)
{    vectors[1][vIndex(i)] = new RandomAccessSparseVector(randomVectors.get(vIndex(i)));    return depends(vectors[1][vIndex(i)]);}
public Boolean mahout_f176_0(Integer i)
{    vectors[2][vIndex(i)] = new SequentialAccessSparseVector(randomVectors.get(vIndex(i)));    return depends(vectors[2][vIndex(i)]);}
public Boolean mahout_f177_0(Integer i)
{    clusters[cIndex(i)] = new RandomAccessSparseVector(randomVectors.get(vIndex(i)));    return depends(clusters[cIndex(i)]);}
private boolean mahout_f178_0(TimingStatistics stats, int randomIndex, Vector v, boolean useSetQuick)
{    int[] indexes = randomVectorIndices.get(randomIndex);    double[] values = randomVectorValues.get(randomIndex);    List<Integer> randomOrder = new ArrayList<>();    for (int i = 0; i < indexes.length; i++) {        randomOrder.add(i);    }    Collections.shuffle(randomOrder);    int[] permutation = new int[randomOrder.size()];    for (int i = 0; i < randomOrder.size(); i++) {        permutation[i] = randomOrder.get(i);    }    TimingStatistics.Call call = stats.newCall(leadTimeUsec);    if (useSetQuick) {        for (int i : permutation) {            v.setQuick(indexes[i], values[i]);        }    } else {        for (int i : permutation) {            v.set(indexes[i], values[i]);        }    }    return call.end(maxTimeUsec);}
public void mahout_f179_0()
{    TimingStatistics stats = new TimingStatistics();    for (int i = 0; i < loop; i++) {        vectors[0][vIndex(i)] = new DenseVector(cardinality);        if (buildVectorIncrementally(stats, vIndex(i), vectors[0][vIndex(i)], false)) {            break;        }    }    printStats(stats, CREATE_INCREMENTALLY, DENSE_VECTOR);    stats = new TimingStatistics();    for (int i = 0; i < loop; i++) {        vectors[1][vIndex(i)] = new RandomAccessSparseVector(cardinality);        if (buildVectorIncrementally(stats, vIndex(i), vectors[1][vIndex(i)], false)) {            break;        }    }    printStats(stats, CREATE_INCREMENTALLY, RAND_SPARSE_VECTOR);    stats = new TimingStatistics();    for (int i = 0; i < loop; i++) {        vectors[2][vIndex(i)] = new SequentialAccessSparseVector(cardinality);        if (buildVectorIncrementally(stats, vIndex(i), vectors[2][vIndex(i)], false)) {            break;        }    }    printStats(stats, CREATE_INCREMENTALLY, SEQ_SPARSE_VECTOR);    if (numClusters > 0) {        stats = new TimingStatistics();        for (int i = 0; i < loop; i++) {            clusters[cIndex(i)] = new RandomAccessSparseVector(cardinality);            if (buildVectorIncrementally(stats, vIndex(i), clusters[cIndex(i)], false)) {                break;            }        }        printStats(stats, CREATE_INCREMENTALLY, CLUSTERS);    }}
public int mahout_f180_0(int i)
{    return i % numVectors;}
public int mahout_f181_0(int i)
{    return i % numClusters;}
public static void mahout_f182_1(String[] args) throws IOException
{    DefaultOptionBuilder obuilder = new DefaultOptionBuilder();    ArgumentBuilder abuilder = new ArgumentBuilder();    GroupBuilder gbuilder = new GroupBuilder();    Option vectorSizeOpt = obuilder.withLongName("vectorSize").withRequired(false).withArgument(abuilder.withName("vs").withDefault(1000000).create()).withDescription("Cardinality of the vector. Default: 1000000").withShortName("vs").create();    Option numNonZeroOpt = obuilder.withLongName("numNonZero").withRequired(false).withArgument(abuilder.withName("nz").withDefault(1000).create()).withDescription("Size of the vector. Default: 1000").withShortName("nz").create();    Option numVectorsOpt = obuilder.withLongName("numVectors").withRequired(false).withArgument(abuilder.withName("nv").withDefault(25).create()).withDescription("Number of Vectors to create. Default: 25").withShortName("nv").create();    Option numClustersOpt = obuilder.withLongName("numClusters").withRequired(false).withArgument(abuilder.withName("nc").withDefault(0).create()).withDescription("Number of clusters to create. Set to non zero to run cluster benchmark. Default: 0").withShortName("nc").create();    Option numOpsOpt = obuilder.withLongName("numOps").withRequired(false).withArgument(abuilder.withName("numOps").withDefault(10).create()).withDescription("Number of operations to do per timer. " + "E.g In distance measure, the distance is calculated numOps times" + " and the total time is measured. Default: 10").withShortName("no").create();    Option helpOpt = DefaultOptionCreator.helpOption();    Group group = gbuilder.withName("Options").withOption(vectorSizeOpt).withOption(numNonZeroOpt).withOption(numVectorsOpt).withOption(numOpsOpt).withOption(numClustersOpt).withOption(helpOpt).create();    try {        Parser parser = new Parser();        parser.setGroup(group);        CommandLine cmdLine = parser.parse(args);        if (cmdLine.hasOption(helpOpt)) {            CommandLineUtil.printHelpWithGenericOptions(group);            return;        }        int cardinality = 1000000;        if (cmdLine.hasOption(vectorSizeOpt)) {            cardinality = Integer.parseInt((String) cmdLine.getValue(vectorSizeOpt));        }        int numClusters = 0;        if (cmdLine.hasOption(numClustersOpt)) {            numClusters = Integer.parseInt((String) cmdLine.getValue(numClustersOpt));        }        int numNonZero = 1000;        if (cmdLine.hasOption(numNonZeroOpt)) {            numNonZero = Integer.parseInt((String) cmdLine.getValue(numNonZeroOpt));        }        int numVectors = 25;        if (cmdLine.hasOption(numVectorsOpt)) {            numVectors = Integer.parseInt((String) cmdLine.getValue(numVectorsOpt));        }        int numOps = 10;        if (cmdLine.hasOption(numOpsOpt)) {            numOps = Integer.parseInt((String) cmdLine.getValue(numOpsOpt));        }        VectorBenchmarks mark = new VectorBenchmarks(cardinality, numNonZero, numVectors, numClusters, numOps);        runBenchmark(mark);                    } catch (OptionException e) {        CommandLineUtil.printHelp(group);    }}
private static void mahout_f183_0(VectorBenchmarks mark) throws IOException
{        mark.createData();    mark.createBenchmark();    if (mark.cardinality < 200000) {                mark.incrementalCreateBenchmark();    }    new CloneBenchmark(mark).benchmark();    new DotBenchmark(mark).benchmark();    new PlusBenchmark(mark).benchmark();    new MinusBenchmark(mark).benchmark();    new TimesBenchmark(mark).benchmark();    new SerializationBenchmark(mark).benchmark();    DistanceBenchmark distanceBenchmark = new DistanceBenchmark(mark);    distanceBenchmark.benchmark(new CosineDistanceMeasure());    distanceBenchmark.benchmark(new SquaredEuclideanDistanceMeasure());    distanceBenchmark.benchmark(new EuclideanDistanceMeasure());    distanceBenchmark.benchmark(new ManhattanDistanceMeasure());    distanceBenchmark.benchmark(new TanimotoDistanceMeasure());    distanceBenchmark.benchmark(new ChebyshevDistanceMeasure());    distanceBenchmark.benchmark(new MinkowskiDistanceMeasure());    if (mark.numClusters > 0) {        ClosestCentroidBenchmark centroidBenchmark = new ClosestCentroidBenchmark(mark);        centroidBenchmark.benchmark(new CosineDistanceMeasure());        centroidBenchmark.benchmark(new SquaredEuclideanDistanceMeasure());        centroidBenchmark.benchmark(new EuclideanDistanceMeasure());        centroidBenchmark.benchmark(new ManhattanDistanceMeasure());        centroidBenchmark.benchmark(new TanimotoDistanceMeasure());        centroidBenchmark.benchmark(new ChebyshevDistanceMeasure());        centroidBenchmark.benchmark(new MinkowskiDistanceMeasure());    }}
private String mahout_f184_0()
{    List<String> keys = new ArrayList<>(statsMap.keySet());    Collections.sort(keys);    Map<Integer, String> implMap = new HashMap<>();    for (Entry<String, Integer> e : implType.entrySet()) {        implMap.put(e.getValue(), e.getKey());    }    StringBuilder sb = new StringBuilder(1000);    for (String benchmarkName : keys) {        int i = 0;        for (String[] stats : statsMap.get(benchmarkName)) {            if (stats.length < 8) {                continue;            }            sb.append(benchmarkName).append(',');            sb.append(implMap.get(i++)).append(',');            sb.append(stats[7].trim().split("=|/")[1].trim());            sb.append('\n');        }    }    sb.append('\n');    return sb.toString();}
public String mahout_f185_0()
{    int pad = 24;    StringBuilder sb = new StringBuilder(1000);    sb.append(StringUtils.rightPad("BenchMarks", pad));    for (int i = 0; i < implType.size(); i++) {        for (Entry<String, Integer> e : implType.entrySet()) {            if (e.getValue() == i) {                sb.append(StringUtils.rightPad(e.getKey(), pad).substring(0, pad));                break;            }        }    }    sb.append('\n');    List<String> keys = new ArrayList<>(statsMap.keySet());    Collections.sort(keys);    for (String benchmarkName : keys) {        List<String[]> implTokenizedStats = statsMap.get(benchmarkName);        int maxStats = 0;        for (String[] stat : implTokenizedStats) {            maxStats = Math.max(maxStats, stat.length);        }        for (int i = 0; i < maxStats; i++) {            boolean printedName = false;            for (String[] stats : implTokenizedStats) {                if (i == 0 && !printedName) {                    sb.append(StringUtils.rightPad(benchmarkName, pad));                    printedName = true;                } else if (!printedName) {                    printedName = true;                    sb.append(StringUtils.rightPad("", pad));                }                if (stats.length > i) {                    sb.append(StringUtils.rightPad(stats[i], pad));                } else {                    sb.append(StringUtils.rightPad("", pad));                }            }            sb.append('\n');        }        sb.append('\n');    }    return sb.toString();}
public BenchmarkRunner mahout_f186_0()
{    return runner;}
public LongPrimitiveIterator mahout_f187_0()
{    SliceQuery<Long, Long, ?> query = buildNoValueSliceQuery(USER_IDS_CF);    query.setKey(ID_ROW_KEY);    FastIDSet userIDs = new FastIDSet();    for (HColumn<Long, ?> userIDColumn : query.execute().get().getColumns()) {        userIDs.add(userIDColumn.getName());    }    return userIDs.iterator();}
public PreferenceArray mahout_f188_0(long userID) throws TasteException
{    return userCache.get(userID);}
public FastIDSet mahout_f189_0(long userID) throws TasteException
{    return itemIDsFromUserCache.get(userID);}
public LongPrimitiveIterator mahout_f190_0()
{    SliceQuery<Long, Long, ?> query = buildNoValueSliceQuery(ITEM_IDS_CF);    query.setKey(ID_ROW_KEY);    FastIDSet itemIDs = new FastIDSet();    for (HColumn<Long, ?> itemIDColumn : query.execute().get().getColumns()) {        itemIDs.add(itemIDColumn.getName());    }    return itemIDs.iterator();}
public PreferenceArray mahout_f191_0(long itemID) throws TasteException
{    return itemCache.get(itemID);}
public Float mahout_f192_0(long userID, long itemID)
{    ColumnQuery<Long, Long, Float> query = HFactory.createColumnQuery(keyspace, LongSerializer.get(), LongSerializer.get(), FloatSerializer.get());    query.setColumnFamily(USERS_CF);    query.setKey(userID);    query.setName(itemID);    HColumn<Long, Float> column = query.execute().get();    return column == null ? null : column.getValue();}
public Long mahout_f193_0(long userID, long itemID)
{    ColumnQuery<Long, Long, ?> query = HFactory.createColumnQuery(keyspace, LongSerializer.get(), LongSerializer.get(), BytesArraySerializer.get());    query.setColumnFamily(USERS_CF);    query.setKey(userID);    query.setName(itemID);    HColumn<Long, ?> result = query.execute().get();    return result == null ? null : result.getClock();}
public int mahout_f194_0()
{    Integer itemCount = itemCountCache.get();    if (itemCount == null) {        CountQuery<Long, Long> countQuery = HFactory.createCountQuery(keyspace, LongSerializer.get(), LongSerializer.get());        countQuery.setKey(ID_ROW_KEY);        countQuery.setColumnFamily(ITEM_IDS_CF);        countQuery.setRange(null, null, Integer.MAX_VALUE);        itemCount = countQuery.execute().get();        itemCountCache.set(itemCount);    }    return itemCount;}
public int mahout_f195_0()
{    Integer userCount = userCountCache.get();    if (userCount == null) {        CountQuery<Long, Long> countQuery = HFactory.createCountQuery(keyspace, LongSerializer.get(), LongSerializer.get());        countQuery.setKey(ID_ROW_KEY);        countQuery.setColumnFamily(USER_IDS_CF);        countQuery.setRange(null, null, Integer.MAX_VALUE);        userCount = countQuery.execute().get();        userCountCache.set(userCount);    }    return userCount;}
public int mahout_f196_0(long itemID) throws TasteException
{    /*    CountQuery<Long,Long> query = HFactory.createCountQuery(keyspace, LongSerializer.get(), LongSerializer.get());    query.setColumnFamily(ITEMS_CF);    query.setKey(itemID);    query.setRange(null, null, Integer.MAX_VALUE);    return query.execute().get();     */    return userIDsFromItemCache.get(itemID).size();}
public int mahout_f197_0(long itemID1, long itemID2) throws TasteException
{    FastIDSet userIDs1 = userIDsFromItemCache.get(itemID1);    FastIDSet userIDs2 = userIDsFromItemCache.get(itemID2);    return userIDs1.size() < userIDs2.size() ? userIDs2.intersectionSize(userIDs1) : userIDs1.intersectionSize(userIDs2);}
public void mahout_f198_0(long userID, long itemID, float value)
{    if (Float.isNaN(value)) {        value = 1.0f;    }    long now = System.currentTimeMillis();    Mutator<Long> mutator = HFactory.createMutator(keyspace, LongSerializer.get());    HColumn<Long, Float> itemForUsers = new HColumnImpl<>(LongSerializer.get(), FloatSerializer.get());    itemForUsers.setName(itemID);    itemForUsers.setClock(now);    itemForUsers.setValue(value);    mutator.addInsertion(userID, USERS_CF, itemForUsers);    HColumn<Long, Float> userForItems = new HColumnImpl<>(LongSerializer.get(), FloatSerializer.get());    userForItems.setName(userID);    userForItems.setClock(now);    userForItems.setValue(value);    mutator.addInsertion(itemID, ITEMS_CF, userForItems);    HColumn<Long, byte[]> userIDs = new HColumnImpl<>(LongSerializer.get(), BytesArraySerializer.get());    userIDs.setName(userID);    userIDs.setClock(now);    userIDs.setValue(EMPTY);    mutator.addInsertion(ID_ROW_KEY, USER_IDS_CF, userIDs);    HColumn<Long, byte[]> itemIDs = new HColumnImpl<>(LongSerializer.get(), BytesArraySerializer.get());    itemIDs.setName(itemID);    itemIDs.setClock(now);    itemIDs.setValue(EMPTY);    mutator.addInsertion(ID_ROW_KEY, ITEM_IDS_CF, itemIDs);    mutator.execute();}
public void mahout_f199_0(long userID, long itemID)
{    Mutator<Long> mutator = HFactory.createMutator(keyspace, LongSerializer.get());    mutator.addDeletion(userID, USERS_CF, itemID, LongSerializer.get());    mutator.addDeletion(itemID, ITEMS_CF, userID, LongSerializer.get());    mutator.execute();}
public boolean mahout_f200_0()
{    return true;}
public float mahout_f201_0()
{    return Float.NaN;}
public float mahout_f202_0()
{    return Float.NaN;}
public void mahout_f203_0(Collection<Refreshable> alreadyRefreshed)
{    userCache.clear();    itemCache.clear();    userIDsFromItemCache.clear();    itemIDsFromUserCache.clear();    userCountCache.set(null);    itemCountCache.set(null);}
public String mahout_f204_0()
{    return "CassandraDataModel[" + keyspace + ']';}
public void mahout_f205_0()
{    HFactory.shutdownCluster(cluster);}
private SliceQuery<Long, Long, byte[]> mahout_f206_0(String cf)
{    SliceQuery<Long, Long, byte[]> query = HFactory.createSliceQuery(keyspace, LongSerializer.get(), LongSerializer.get(), BytesArraySerializer.get());    query.setColumnFamily(cf);    query.setRange(null, null, false, Integer.MAX_VALUE);    return query;}
private SliceQuery<Long, Long, Float> mahout_f207_0(String cf)
{    SliceQuery<Long, Long, Float> query = HFactory.createSliceQuery(keyspace, LongSerializer.get(), LongSerializer.get(), FloatSerializer.get());    query.setColumnFamily(cf);    query.setRange(null, null, false, Integer.MAX_VALUE);    return query;}
public HConsistencyLevel mahout_f208_0(OperationType op)
{    return HConsistencyLevel.ONE;}
public HConsistencyLevel mahout_f209_0(OperationType op, String cfName)
{    return HConsistencyLevel.ONE;}
public PreferenceArray mahout_f210_0(Long userID) throws TasteException
{    SliceQuery<Long, Long, Float> query = buildValueSliceQuery(USERS_CF);    query.setKey(userID);    ColumnSlice<Long, Float> result = query.execute().get();    if (result == null) {        throw new NoSuchUserException(userID);    }    List<HColumn<Long, Float>> itemIDColumns = result.getColumns();    if (itemIDColumns.isEmpty()) {        throw new NoSuchUserException(userID);    }    int size = itemIDColumns.size();    PreferenceArray prefs = new GenericUserPreferenceArray(size);    prefs.setUserID(0, userID);    for (int i = 0; i < size; i++) {        HColumn<Long, Float> itemIDColumn = itemIDColumns.get(i);        prefs.setItemID(i, itemIDColumn.getName());        prefs.setValue(i, itemIDColumn.getValue());    }    return prefs;}
public PreferenceArray mahout_f211_0(Long itemID) throws TasteException
{    SliceQuery<Long, Long, Float> query = buildValueSliceQuery(ITEMS_CF);    query.setKey(itemID);    ColumnSlice<Long, Float> result = query.execute().get();    if (result == null) {        throw new NoSuchItemException(itemID);    }    List<HColumn<Long, Float>> userIDColumns = result.getColumns();    if (userIDColumns.isEmpty()) {        throw new NoSuchItemException(itemID);    }    int size = userIDColumns.size();    PreferenceArray prefs = new GenericItemPreferenceArray(size);    prefs.setItemID(0, itemID);    for (int i = 0; i < size; i++) {        HColumn<Long, Float> userIDColumn = userIDColumns.get(i);        prefs.setUserID(i, userIDColumn.getName());        prefs.setValue(i, userIDColumn.getValue());    }    return prefs;}
public FastIDSet mahout_f212_0(Long itemID) throws TasteException
{    SliceQuery<Long, Long, byte[]> query = buildNoValueSliceQuery(ITEMS_CF);    query.setKey(itemID);    ColumnSlice<Long, byte[]> result = query.execute().get();    if (result == null) {        throw new NoSuchItemException(itemID);    }    List<HColumn<Long, byte[]>> columns = result.getColumns();    FastIDSet userIDs = new FastIDSet(columns.size());    for (HColumn<Long, ?> userIDColumn : columns) {        userIDs.add(userIDColumn.getName());    }    return userIDs;}
public FastIDSet mahout_f213_0(Long userID) throws TasteException
{    SliceQuery<Long, Long, byte[]> query = buildNoValueSliceQuery(USERS_CF);    query.setKey(userID);    FastIDSet itemIDs = new FastIDSet();    ColumnSlice<Long, byte[]> result = query.execute().get();    if (result == null) {        throw new NoSuchUserException(userID);    }    List<HColumn<Long, byte[]>> columns = result.getColumns();    if (columns.isEmpty()) {        throw new NoSuchUserException(userID);    }    for (HColumn<Long, ?> itemIDColumn : columns) {        itemIDs.add(itemIDColumn.getName());    }    return itemIDs;}
public String mahout_f214_0()
{    return tableName;}
private void mahout_f215_1(Configuration conf) throws IOException
{    HTableDescriptor tDesc = new HTableDescriptor(Bytes.toBytes(tableName));    tDesc.addFamily(new HColumnDescriptor(USERS_CF));    tDesc.addFamily(new HColumnDescriptor(ITEMS_CF));    try (HBaseAdmin admin = new HBaseAdmin(conf)) {        admin.createTable(tDesc);            }}
private static byte[] mahout_f216_0(long userID)
{    ByteBuffer bb = ByteBuffer.allocate(9);        bb.put((byte) 0x75);    bb.putLong(userID);    return bb.array();}
private static byte[] mahout_f217_0(long itemID)
{    ByteBuffer bb = ByteBuffer.allocate(9);        bb.put((byte) 0x69);    bb.putLong(itemID);    return bb.array();}
private static long mahout_f218_0(byte[] ba)
{    ByteBuffer bb = ByteBuffer.wrap(ba);    return bb.getLong(1);}
public LongPrimitiveIterator mahout_f219_0()
{    return userIDs.iterator();}
public PreferenceArray mahout_f220_0(long userID) throws TasteException
{    Result result;    try {        HTableInterface table = pool.getTable(tableName);        Get get = new Get(userToBytes(userID));        get.addFamily(ITEMS_CF);        result = table.get(get);        table.close();    } catch (IOException e) {        throw new TasteException("Failed to retrieve user preferences from HBase", e);    }    if (result.isEmpty()) {        throw new NoSuchUserException(userID);    }    SortedMap<byte[], byte[]> families = result.getFamilyMap(ITEMS_CF);    PreferenceArray prefs = new GenericUserPreferenceArray(families.size());    prefs.setUserID(0, userID);    int i = 0;    for (Map.Entry<byte[], byte[]> entry : families.entrySet()) {        prefs.setItemID(i, Bytes.toLong(entry.getKey()));        prefs.setValue(i, Bytes.toFloat(entry.getValue()));        i++;    }    return prefs;}
public FastIDSet mahout_f221_0(long userID) throws TasteException
{    Result result;    try {        HTableInterface table = pool.getTable(tableName);        Get get = new Get(userToBytes(userID));        get.addFamily(ITEMS_CF);        result = table.get(get);        table.close();    } catch (IOException e) {        throw new TasteException("Failed to retrieve item IDs from HBase", e);    }    if (result.isEmpty()) {        throw new NoSuchUserException(userID);    }    SortedMap<byte[], byte[]> families = result.getFamilyMap(ITEMS_CF);    FastIDSet ids = new FastIDSet(families.size());    for (byte[] family : families.keySet()) {        ids.add(Bytes.toLong(family));    }    return ids;}
public LongPrimitiveIterator mahout_f222_0()
{    return itemIDs.iterator();}
public PreferenceArray mahout_f223_0(long itemID) throws TasteException
{    Result result;    try {        HTableInterface table = pool.getTable(tableName);        Get get = new Get(itemToBytes(itemID));        get.addFamily(USERS_CF);        result = table.get(get);        table.close();    } catch (IOException e) {        throw new TasteException("Failed to retrieve item preferences from HBase", e);    }    if (result.isEmpty()) {        throw new NoSuchItemException(itemID);    }    SortedMap<byte[], byte[]> families = result.getFamilyMap(USERS_CF);    PreferenceArray prefs = new GenericItemPreferenceArray(families.size());    prefs.setItemID(0, itemID);    int i = 0;    for (Map.Entry<byte[], byte[]> entry : families.entrySet()) {        prefs.setUserID(i, Bytes.toLong(entry.getKey()));        prefs.setValue(i, Bytes.toFloat(entry.getValue()));        i++;    }    return prefs;}
public Float mahout_f224_0(long userID, long itemID) throws TasteException
{    Result result;    try {        HTableInterface table = pool.getTable(tableName);        Get get = new Get(userToBytes(userID));        get.addColumn(ITEMS_CF, Bytes.toBytes(itemID));        result = table.get(get);        table.close();    } catch (IOException e) {        throw new TasteException("Failed to retrieve user preferences from HBase", e);    }    if (result.isEmpty()) {        throw new NoSuchUserException(userID);    }    if (result.containsColumn(ITEMS_CF, Bytes.toBytes(itemID))) {        return Bytes.toFloat(result.getValue(ITEMS_CF, Bytes.toBytes(itemID)));    } else {        return null;    }}
public Long mahout_f225_0(long userID, long itemID) throws TasteException
{    Result result;    try {        HTableInterface table = pool.getTable(tableName);        Get get = new Get(userToBytes(userID));        get.addColumn(ITEMS_CF, Bytes.toBytes(itemID));        result = table.get(get);        table.close();    } catch (IOException e) {        throw new TasteException("Failed to retrieve user preferences from HBase", e);    }    if (result.isEmpty()) {        throw new NoSuchUserException(userID);    }    if (result.containsColumn(ITEMS_CF, Bytes.toBytes(itemID))) {        KeyValue kv = result.getColumnLatest(ITEMS_CF, Bytes.toBytes(itemID));        return kv.getTimestamp();    } else {        return null;    }}
public int mahout_f226_0()
{    return itemIDs.size();}
public int mahout_f227_0()
{    return userIDs.size();}
public int mahout_f228_0(long itemID) throws TasteException
{    PreferenceArray prefs = getPreferencesForItem(itemID);    return prefs.length();}
public int mahout_f229_0(long itemID1, long itemID2) throws TasteException
{    Result[] results;    try {        HTableInterface table = pool.getTable(tableName);        List<Get> gets = new ArrayList<>(2);        gets.add(new Get(itemToBytes(itemID1)));        gets.add(new Get(itemToBytes(itemID2)));        gets.get(0).addFamily(USERS_CF);        gets.get(1).addFamily(USERS_CF);        results = table.get(gets);        table.close();    } catch (IOException e) {        throw new TasteException("Failed to retrieve item preferences from HBase", e);    }    if (results[0].isEmpty()) {        throw new NoSuchItemException(itemID1);    }    if (results[1].isEmpty()) {        throw new NoSuchItemException(itemID2);    }        Result result = results[0];    SortedMap<byte[], byte[]> families = result.getFamilyMap(USERS_CF);    FastIDSet idSet1 = new FastIDSet(families.size());    for (byte[] id : families.keySet()) {        idSet1.add(Bytes.toLong(id));    }        result = results[1];    families = result.getFamilyMap(USERS_CF);    FastIDSet idSet2 = new FastIDSet(families.size());    for (byte[] id : families.keySet()) {        idSet2.add(Bytes.toLong(id));    }    return idSet1.intersectionSize(idSet2);}
public void mahout_f230_0(long userID, long itemID, float value) throws TasteException
{    try {        HTableInterface table = pool.getTable(tableName);        List<Put> puts = new ArrayList<>(2);        puts.add(new Put(userToBytes(userID)));        puts.add(new Put(itemToBytes(itemID)));        puts.get(0).add(ITEMS_CF, Bytes.toBytes(itemID), Bytes.toBytes(value));        puts.get(1).add(USERS_CF, Bytes.toBytes(userID), Bytes.toBytes(value));        table.put(puts);        table.close();    } catch (IOException e) {        throw new TasteException("Failed to store preference in HBase", e);    }}
public void mahout_f231_0(long userID, long itemID) throws TasteException
{    try {        HTableInterface table = pool.getTable(tableName);        List<Delete> deletes = new ArrayList<>(2);        deletes.add(new Delete(userToBytes(userID)));        deletes.add(new Delete(itemToBytes(itemID)));        deletes.get(0).deleteColumns(ITEMS_CF, Bytes.toBytes(itemID));        deletes.get(1).deleteColumns(USERS_CF, Bytes.toBytes(userID));        table.delete(deletes);        table.close();    } catch (IOException e) {        throw new TasteException("Failed to remove preference from HBase", e);    }}
public boolean mahout_f232_0()
{    return true;}
public float mahout_f233_0()
{    throw new UnsupportedOperationException();}
public float mahout_f234_0()
{    throw new UnsupportedOperationException();}
public void mahout_f235_0() throws IOException
{    pool.close();}
public void mahout_f236_1(Collection<Refreshable> alreadyRefreshed)
{    if (alreadyRefreshed == null || !alreadyRefreshed.contains(this)) {        try {                        long t1 = System.currentTimeMillis();            refreshItemIDs();            refreshUserIDs();            long t2 = System.currentTimeMillis();                    } catch (IOException e) {            throw new IllegalStateException("Could not reload DataModel", e);        }    }}
private synchronized void mahout_f237_0() throws IOException
{        HTableInterface table = pool.getTable(tableName);    Scan scan = new Scan(new byte[] { 0x69 }, new byte[] { 0x70 });    scan.setFilter(new FilterList(FilterList.Operator.MUST_PASS_ALL, new KeyOnlyFilter(), new FirstKeyOnlyFilter()));    ResultScanner scanner = table.getScanner(scan);    Collection<Long> ids = new LinkedList<>();    for (Result result : scanner) {        ids.add(bytesToUserOrItemID(result.getRow()));    }    table.close();        FastIDSet itemIDs = new FastIDSet(ids.size());    for (long l : ids) {        itemIDs.add(l);    }        this.itemIDs = itemIDs;}
private synchronized void mahout_f238_0() throws IOException
{        HTableInterface table = pool.getTable(tableName);    Scan scan = new Scan(new byte[] { 0x75 }, new byte[] { 0x76 });    scan.setFilter(new FilterList(FilterList.Operator.MUST_PASS_ALL, new KeyOnlyFilter(), new FirstKeyOnlyFilter()));    ResultScanner scanner = table.getScanner(scan);    Collection<Long> ids = new LinkedList<>();    for (Result result : scanner) {        ids.add(bytesToUserOrItemID(result.getRow()));    }    table.close();        FastIDSet userIDs = new FastIDSet(ids.size());    for (long l : ids) {        userIDs.add(l);    }        this.userIDs = userIDs;}
protected Preference mahout_f239_0(ResultSet rs) throws SQLException
{    return new BooleanPreference(getLongColumn(rs, 1), getLongColumn(rs, 2));}
 String mahout_f240_0()
{    return setPreferenceSQL;}
public void mahout_f241_1(long userID, long itemID, float value) throws TasteException
{    Preconditions.checkArgument(!Float.isNaN(value), "NaN value");        Connection conn = null;    PreparedStatement stmt = null;    try {        conn = getDataSource().getConnection();        stmt = conn.prepareStatement(setPreferenceSQL);        setLongParameter(stmt, 1, userID);        setLongParameter(stmt, 2, itemID);                stmt.executeUpdate();    } catch (SQLException sqle) {                throw new TasteException(sqle);    } finally {        IOUtils.quietClose(null, stmt, conn);    }}
public boolean mahout_f242_0()
{    return false;}
public float mahout_f243_0()
{    return 1.0f;}
public float mahout_f244_0()
{    return 1.0f;}
public DataSource mahout_f245_0()
{    return dataSource;}
public String mahout_f246_0()
{    return preferenceTable;}
public String mahout_f247_0()
{    return userIDColumn;}
public String mahout_f248_0()
{    return itemIDColumn;}
public String mahout_f249_0()
{    return preferenceColumn;}
 String mahout_f250_0()
{    return setPreferenceSQL;}
public LongPrimitiveIterator mahout_f251_1() throws TasteException
{        try {        return new ResultSetIDIterator(getUsersSQL);    } catch (SQLException sqle) {        throw new TasteException(sqle);    }}
public PreferenceArray mahout_f252_1(long userID) throws TasteException
{        Connection conn = null;    PreparedStatement stmt = null;    ResultSet rs = null;    try {        conn = dataSource.getConnection();        stmt = conn.prepareStatement(getUserSQL, ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY);        stmt.setFetchDirection(ResultSet.FETCH_FORWARD);        stmt.setFetchSize(getFetchSize());        setLongParameter(stmt, 1, userID);                rs = stmt.executeQuery();        List<Preference> prefs = new ArrayList<>();        while (rs.next()) {            prefs.add(buildPreference(rs));        }        if (prefs.isEmpty()) {            throw new NoSuchUserException(userID);        }        return new GenericUserPreferenceArray(prefs);    } catch (SQLException sqle) {                throw new TasteException(sqle);    } finally {        IOUtils.quietClose(rs, stmt, conn);    }}
public FastByIDMap<PreferenceArray> mahout_f253_1() throws TasteException
{        Connection conn = null;    Statement stmt = null;    ResultSet rs = null;    FastByIDMap<PreferenceArray> result = new FastByIDMap<>();    try {        conn = dataSource.getConnection();        stmt = conn.createStatement(ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY);        stmt.setFetchDirection(ResultSet.FETCH_FORWARD);        stmt.setFetchSize(getFetchSize());                rs = stmt.executeQuery(getAllUsersSQL);        Long currentUserID = null;        List<Preference> currentPrefs = new ArrayList<>();        while (rs.next()) {            long nextUserID = getLongColumn(rs, 1);            if (currentUserID != null && !currentUserID.equals(nextUserID) && !currentPrefs.isEmpty()) {                result.put(currentUserID, new GenericUserPreferenceArray(currentPrefs));                currentPrefs.clear();            }            currentPrefs.add(buildPreference(rs));            currentUserID = nextUserID;        }        if (!currentPrefs.isEmpty()) {            result.put(currentUserID, new GenericUserPreferenceArray(currentPrefs));        }        return result;    } catch (SQLException sqle) {                throw new TasteException(sqle);    } finally {        IOUtils.quietClose(rs, stmt, conn);    }}
public FastByIDMap<FastIDSet> mahout_f254_1() throws TasteException
{        Connection conn = null;    Statement stmt = null;    ResultSet rs = null;    FastByIDMap<FastIDSet> result = new FastByIDMap<>();    try {        conn = dataSource.getConnection();        stmt = conn.createStatement(ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY);        stmt.setFetchDirection(ResultSet.FETCH_FORWARD);        stmt.setFetchSize(getFetchSize());                rs = stmt.executeQuery(getAllUsersSQL);        boolean currentUserIDSet = false;                long currentUserID = 0L;        FastIDSet currentItemIDs = new FastIDSet(2);        while (rs.next()) {            long nextUserID = getLongColumn(rs, 1);            if (currentUserIDSet && currentUserID != nextUserID && !currentItemIDs.isEmpty()) {                result.put(currentUserID, currentItemIDs);                currentItemIDs = new FastIDSet(2);            }            currentItemIDs.add(getLongColumn(rs, 2));            currentUserID = nextUserID;            currentUserIDSet = true;        }        if (!currentItemIDs.isEmpty()) {            result.put(currentUserID, currentItemIDs);        }        return result;    } catch (SQLException sqle) {                throw new TasteException(sqle);    } finally {        IOUtils.quietClose(rs, stmt, conn);    }}
public FastIDSet mahout_f255_1(long userID) throws TasteException
{        Connection conn = null;    PreparedStatement stmt = null;    ResultSet rs = null;    try {        conn = dataSource.getConnection();        stmt = conn.prepareStatement(getUserSQL, ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY);        stmt.setFetchDirection(ResultSet.FETCH_FORWARD);        stmt.setFetchSize(getFetchSize());        setLongParameter(stmt, 1, userID);                rs = stmt.executeQuery();        FastIDSet result = new FastIDSet();        while (rs.next()) {            result.add(getLongColumn(rs, 2));        }        if (result.isEmpty()) {            throw new NoSuchUserException(userID);        }        return result;    } catch (SQLException sqle) {                throw new TasteException(sqle);    } finally {        IOUtils.quietClose(rs, stmt, conn);    }}
public Float mahout_f256_1(long userID, long itemID) throws TasteException
{        Connection conn = null;    PreparedStatement stmt = null;    ResultSet rs = null;    try {        conn = dataSource.getConnection();        stmt = conn.prepareStatement(getPreferenceSQL, ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY);        stmt.setFetchDirection(ResultSet.FETCH_FORWARD);        stmt.setFetchSize(1);        setLongParameter(stmt, 1, userID);        setLongParameter(stmt, 2, itemID);                rs = stmt.executeQuery();        if (rs.next()) {            return rs.getFloat(1);        } else {            return null;        }    } catch (SQLException sqle) {                throw new TasteException(sqle);    } finally {        IOUtils.quietClose(rs, stmt, conn);    }}
public Long mahout_f257_1(long userID, long itemID) throws TasteException
{    if (getPreferenceTimeSQL == null) {        return null;    }        Connection conn = null;    PreparedStatement stmt = null;    ResultSet rs = null;    try {        conn = dataSource.getConnection();        stmt = conn.prepareStatement(getPreferenceTimeSQL, ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY);        stmt.setFetchDirection(ResultSet.FETCH_FORWARD);        stmt.setFetchSize(1);        setLongParameter(stmt, 1, userID);        setLongParameter(stmt, 2, itemID);                rs = stmt.executeQuery();        if (rs.next()) {            return rs.getLong(1);        } else {            return null;        }    } catch (SQLException sqle) {                throw new TasteException(sqle);    } finally {        IOUtils.quietClose(rs, stmt, conn);    }}
public LongPrimitiveIterator mahout_f258_1() throws TasteException
{        try {        return new ResultSetIDIterator(getItemsSQL);    } catch (SQLException sqle) {        throw new TasteException(sqle);    }}
public PreferenceArray mahout_f259_0(long itemID) throws TasteException
{    List<Preference> list = doGetPreferencesForItem(itemID);    if (list.isEmpty()) {        throw new NoSuchItemException(itemID);    }    return new GenericItemPreferenceArray(list);}
protected List<Preference> mahout_f260_1(long itemID) throws TasteException
{        Connection conn = null;    PreparedStatement stmt = null;    ResultSet rs = null;    try {        conn = dataSource.getConnection();        stmt = conn.prepareStatement(getPrefsForItemSQL, ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY);        stmt.setFetchDirection(ResultSet.FETCH_FORWARD);        stmt.setFetchSize(getFetchSize());        setLongParameter(stmt, 1, itemID);                rs = stmt.executeQuery();        List<Preference> prefs = new ArrayList<>();        while (rs.next()) {            prefs.add(buildPreference(rs));        }        return prefs;    } catch (SQLException sqle) {                throw new TasteException(sqle);    } finally {        IOUtils.quietClose(rs, stmt, conn);    }}
public int mahout_f261_0() throws TasteException
{    if (cachedNumItems < 0) {        cachedNumItems = getNumThings("items", getNumItemsSQL);    }    return cachedNumItems;}
public int mahout_f262_0() throws TasteException
{    if (cachedNumUsers < 0) {        cachedNumUsers = getNumThings("users", getNumUsersSQL);    }    return cachedNumUsers;}
public int mahout_f263_0(long itemID) throws TasteException
{    return itemPrefCounts.get(itemID);}
public int mahout_f264_0(long itemID1, long itemID2) throws TasteException
{    return getNumThings("user preferring items", getNumPreferenceForItemsSQL, itemID1, itemID2);}
private int mahout_f265_1(String name, String sql, long... args) throws TasteException
{        Connection conn = null;    PreparedStatement stmt = null;    ResultSet rs = null;    try {        conn = dataSource.getConnection();        stmt = conn.prepareStatement(sql, ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY);        stmt.setFetchDirection(ResultSet.FETCH_FORWARD);        stmt.setFetchSize(getFetchSize());        if (args != null) {            for (int i = 1; i <= args.length; i++) {                setLongParameter(stmt, i, args[i - 1]);            }        }                rs = stmt.executeQuery();        rs.next();        return rs.getInt(1);    } catch (SQLException sqle) {                throw new TasteException(sqle);    } finally {        IOUtils.quietClose(rs, stmt, conn);    }}
public void mahout_f266_1(long userID, long itemID, float value) throws TasteException
{    Preconditions.checkArgument(!Float.isNaN(value), "NaN value");        Connection conn = null;    PreparedStatement stmt = null;    try {        conn = dataSource.getConnection();        stmt = conn.prepareStatement(setPreferenceSQL);        setLongParameter(stmt, 1, userID);        setLongParameter(stmt, 2, itemID);        stmt.setDouble(3, value);        stmt.setDouble(4, value);                stmt.executeUpdate();    } catch (SQLException sqle) {                throw new TasteException(sqle);    } finally {        IOUtils.quietClose(null, stmt, conn);    }}
public void mahout_f267_1(long userID, long itemID) throws TasteException
{        Connection conn = null;    PreparedStatement stmt = null;    try {        conn = dataSource.getConnection();        stmt = conn.prepareStatement(removePreferenceSQL);        setLongParameter(stmt, 1, userID);        setLongParameter(stmt, 2, itemID);                stmt.executeUpdate();    } catch (SQLException sqle) {                throw new TasteException(sqle);    } finally {        IOUtils.quietClose(null, stmt, conn);    }}
public void mahout_f268_0(Collection<Refreshable> alreadyRefreshed)
{    cachedNumUsers = -1;    cachedNumItems = -1;    minPreference = Float.NaN;    maxPreference = Float.NaN;    itemPrefCounts.clear();}
public boolean mahout_f269_0()
{    return true;}
public float mahout_f270_1()
{    if (Float.isNaN(maxPreference)) {        Connection conn = null;        PreparedStatement stmt = null;        ResultSet rs = null;        try {            conn = dataSource.getConnection();            stmt = conn.prepareStatement(getMaxPreferenceSQL);                        rs = stmt.executeQuery();            rs.next();            maxPreference = rs.getFloat(1);        } catch (SQLException sqle) {                            } finally {            IOUtils.quietClose(rs, stmt, conn);        }    }    return maxPreference;}
public float mahout_f271_1()
{    if (Float.isNaN(minPreference)) {        Connection conn = null;        PreparedStatement stmt = null;        ResultSet rs = null;        try {            conn = dataSource.getConnection();            stmt = conn.prepareStatement(getMinPreferenceSQL);                        rs = stmt.executeQuery();            rs.next();            minPreference = rs.getFloat(1);        } catch (SQLException sqle) {                            } finally {            IOUtils.quietClose(rs, stmt, conn);        }    }    return minPreference;}
protected Preference mahout_f272_0(ResultSet rs) throws SQLException
{    return new GenericPreference(getLongColumn(rs, 1), getLongColumn(rs, 2), rs.getFloat(3));}
protected long mahout_f273_0(ResultSet rs, int position) throws SQLException
{    return rs.getLong(position);}
protected void mahout_f274_0(PreparedStatement stmt, int position, long value) throws SQLException
{    stmt.setLong(position, value);}
protected Long mahout_f275_0(ResultSet resultSet) throws SQLException
{    return getLongColumn(resultSet, 1);}
public long mahout_f276_0()
{    return next();}
public long mahout_f277_0()
{        throw new UnsupportedOperationException();}
public Integer mahout_f278_0(Long key) throws TasteException
{    return getNumThings("user preferring item", getNumPreferenceForItemSQL, key);}
public Connection mahout_f279_0() throws SQLException
{    return delegate.getConnection();}
public Connection mahout_f280_0(String username, String password) throws SQLException
{    return delegate.getConnection(username, password);}
public PrintWriter mahout_f281_0() throws SQLException
{    return delegate.getLogWriter();}
public void mahout_f282_0(PrintWriter printWriter) throws SQLException
{    delegate.setLogWriter(printWriter);}
public void mahout_f283_0(int timeout) throws SQLException
{    delegate.setLoginTimeout(timeout);}
public int mahout_f284_0() throws SQLException
{    return delegate.getLoginTimeout();}
public T mahout_f285_0(Class<T> iface) throws SQLException
{    return delegate.unwrap(iface);}
public boolean mahout_f286_0(Class<?> iface) throws SQLException
{    return delegate.isWrapperFor(iface);}
public Logger mahout_f287_0() throws SQLFeatureNotSupportedException
{    throw new SQLFeatureNotSupportedException();}
public Connection mahout_f288_0() throws SQLException
{    Connection connection = underlyingDataSource.getConnection();    connection.setTransactionIsolation(Connection.TRANSACTION_READ_UNCOMMITTED);    connection.setHoldability(ResultSet.CLOSE_CURSORS_AT_COMMIT);    return connection;}
private static Properties mahout_f289_0(File file) throws TasteException
{    try {        return getPropertiesFromStream(new FileInputStream(file));    } catch (FileNotFoundException fnfe) {        throw new TasteException(fnfe);    }}
private static Properties mahout_f290_0(InputStream is) throws TasteException
{    try {        try {            Properties props = new Properties();            props.load(is);            return props;        } finally {            Closeables.close(is, true);        }    } catch (IOException ioe) {        throw new TasteException(ioe);    }}
protected int mahout_f291_0()
{        return Integer.MIN_VALUE;}
protected int mahout_f292_0()
{        return Integer.MIN_VALUE;}
public void mahout_f293_1(long userID, long itemID, float value) throws TasteException
{    Preconditions.checkArgument(!Float.isNaN(value), "NaN value");        String setPreferenceSQL = getSetPreferenceSQL();    Connection conn = null;    PreparedStatement stmt = null;    try {        conn = getDataSource().getConnection();        stmt = conn.prepareStatement(setPreferenceSQL);        setLongParameter(stmt, 1, userID);        setLongParameter(stmt, 2, itemID);                stmt.executeUpdate();    } catch (SQLException sqle) {        if (!POSTGRESQL_DUPLICATE_KEY_STATE.equals(sqle.getSQLState())) {                        throw new TasteException(sqle);        }    } finally {        IOUtils.quietClose(null, stmt, conn);    }}
public void mahout_f294_1(long userID, long itemID, float value) throws TasteException
{    Preconditions.checkArgument(!Float.isNaN(value), "NaN value");        String setPreferenceSQL = getSetPreferenceSQL();    Connection conn = null;    PreparedStatement stmt1 = null;    PreparedStatement stmt2 = null;    try {        conn = getDataSource().getConnection();        stmt1 = conn.prepareStatement(setPreferenceSQL);        setLongParameter(stmt1, 1, userID);        setLongParameter(stmt1, 2, itemID);        stmt1.setDouble(3, value);                try {            stmt1.executeUpdate();        } catch (SQLException sqle) {            if (!POSTGRESQL_DUPLICATE_KEY_STATE.equals(sqle.getSQLState())) {                throw sqle;            }        }                stmt2 = conn.prepareStatement(getUpdatePreferenceSQL());        stmt2.setDouble(1, value);        setLongParameter(stmt2, 2, userID);        setLongParameter(stmt2, 3, itemID);                stmt2.executeUpdate();    } catch (SQLException sqle) {                throw new TasteException(sqle);    } finally {        IOUtils.quietClose(null, stmt1, null);        IOUtils.quietClose(null, stmt2, null);        IOUtils.quietClose(null, null, conn);    }}
public Void mahout_f295_0()
{    reload();        return null;}
public void mahout_f296_0(Collection<Refreshable> alreadyRefreshed)
{    refreshHelper.refresh(alreadyRefreshed);}
private void mahout_f297_1()
{    try {                        DataModel newDelegateInMemory = delegate.hasPreferenceValues() ? new GenericDataModel(delegate.exportWithPrefs()) : new GenericBooleanPrefDataModel(delegate.exportWithIDsOnly());                        delegateInMemory = newDelegateInMemory;    } catch (TasteException te) {                }}
public JDBCDataModel mahout_f298_0()
{    return delegate;}
public DataModel mahout_f299_0()
{    return delegateInMemory;}
public LongPrimitiveIterator mahout_f300_0() throws TasteException
{    return delegateInMemory.getUserIDs();}
public PreferenceArray mahout_f301_0(long id) throws TasteException
{    return delegateInMemory.getPreferencesFromUser(id);}
public FastIDSet mahout_f302_0(long id) throws TasteException
{    return delegateInMemory.getItemIDsFromUser(id);}
public Float mahout_f303_0(long userID, long itemID) throws TasteException
{    return delegateInMemory.getPreferenceValue(userID, itemID);}
public Long mahout_f304_0(long userID, long itemID) throws TasteException
{    return delegateInMemory.getPreferenceTime(userID, itemID);}
public LongPrimitiveIterator mahout_f305_0() throws TasteException
{    return delegateInMemory.getItemIDs();}
public PreferenceArray mahout_f306_0(long itemID) throws TasteException
{    return delegateInMemory.getPreferencesForItem(itemID);}
public int mahout_f307_0() throws TasteException
{    return delegateInMemory.getNumItems();}
public int mahout_f308_0() throws TasteException
{    return delegateInMemory.getNumUsers();}
public int mahout_f309_0(long itemID) throws TasteException
{    return delegateInMemory.getNumUsersWithPreferenceFor(itemID);}
public int mahout_f310_0(long itemID1, long itemID2) throws TasteException
{    return delegateInMemory.getNumUsersWithPreferenceFor(itemID1, itemID2);}
public void mahout_f311_0(long userID, long itemID, float value) throws TasteException
{    delegateInMemory.setPreference(userID, itemID, value);}
public void mahout_f312_0(long userID, long itemID) throws TasteException
{    delegateInMemory.removePreference(userID, itemID);}
public boolean mahout_f313_0()
{    return delegateInMemory.hasPreferenceValues();}
public float mahout_f314_0()
{    return delegateInMemory.getMaxPreference();}
public float mahout_f315_0()
{    return delegateInMemory.getMinPreference();}
protected String mahout_f316_0()
{    return verifyPreferenceSQL;}
public void mahout_f317_1(long userID, long itemID, float value) throws TasteException
{    Preconditions.checkArgument(!Float.isNaN(value), "NaN value");        String setPreferenceSQL = getSetPreferenceSQL();    Connection conn = null;    PreparedStatement stmt1 = null;    PreparedStatement stmt2 = null;    ResultSet rs = null;    try {        conn = getDataSource().getConnection();        stmt1 = conn.prepareStatement(verifyPreferenceSQL, ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY);        setLongParameter(stmt1, 1, userID);        setLongParameter(stmt1, 2, itemID);        rs = stmt1.executeQuery();                if (!rs.first()) {            stmt2 = conn.prepareStatement(setPreferenceSQL);            setLongParameter(stmt2, 1, userID);            setLongParameter(stmt2, 2, itemID);            stmt2.setDouble(3, value);                        stmt2.executeUpdate();        }    } catch (SQLException sqle) {                throw new TasteException(sqle);    } finally {        IOUtils.quietClose(rs);        IOUtils.quietClose(stmt1);        IOUtils.quietClose(stmt2);        IOUtils.quietClose(conn);    }}
protected String mahout_f318_0()
{    return updatePreferenceSQL;}
protected String mahout_f319_0()
{    return verifyPreferenceSQL;}
public void mahout_f320_1(long userID, long itemID, float value) throws TasteException
{    Preconditions.checkArgument(!Float.isNaN(value), "NaN value");        String setPreferenceSQL = getSetPreferenceSQL();    Connection conn = null;    PreparedStatement stmt1 = null;    PreparedStatement stmt2 = null;    PreparedStatement stmt3 = null;    ResultSet rs = null;    try {        conn = getDataSource().getConnection();        stmt1 = conn.prepareStatement(verifyPreferenceSQL, ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY);        setLongParameter(stmt1, 1, userID);        setLongParameter(stmt1, 2, itemID);        rs = stmt1.executeQuery();                if (rs.first()) {                        stmt2 = conn.prepareStatement(updatePreferenceSQL);            stmt2.setDouble(1, value);            setLongParameter(stmt2, 2, userID);            setLongParameter(stmt2, 3, itemID);                        stmt2.executeUpdate();        } else {                        stmt3 = conn.prepareStatement(setPreferenceSQL);            setLongParameter(stmt3, 1, userID);            setLongParameter(stmt3, 2, itemID);            stmt3.setDouble(3, value);                        stmt3.executeUpdate();        }    } catch (SQLException sqle) {                throw new TasteException(sqle);    } finally {        IOUtils.quietClose(rs);        IOUtils.quietClose(stmt1);        IOUtils.quietClose(stmt2);        IOUtils.quietClose(stmt3);        IOUtils.quietClose(conn);    }}
public void mahout_f321_0(String userID, Iterable<List<String>> items, boolean add) throws NoSuchUserException, NoSuchItemException
{    checkData(userID, items, add);    long id = Long.parseLong(fromIdToLong(userID, true));    for (List<String> item : items) {        item.set(0, fromIdToLong(item.get(0), false));    }    if (reloadLock.tryLock()) {        try {            if (add) {                delegate = addUserItem(id, items);            } else {                delegate = removeUserItem(id, items);            }        } finally {            reloadLock.unlock();        }    }}
public void mahout_f322_1(Collection<Refreshable> alreadyRefreshed)
{    BasicDBObject query = new BasicDBObject();    query.put("deleted_at", new BasicDBObject("$gt", mongoTimestamp));    DBCursor cursor = collection.find(query);    Date ts = new Date(0);    while (cursor.hasNext()) {        Map<String, Object> user = (Map<String, Object>) cursor.next().toMap();        String userID = getID(user.get(mongoUserID), true);        Collection<List<String>> items = new ArrayList<>();        List<String> item = new ArrayList<>();        item.add(getID(user.get(mongoItemID), false));        item.add(Float.toString(getPreference(user.get(mongoPreference))));        items.add(item);        try {            refreshData(userID, items, false);        } catch (NoSuchUserException e) {                    } catch (NoSuchItemException e) {                    }        if (ts.compareTo(getDate(user.get("created_at"))) < 0) {            ts = getDate(user.get("created_at"));        }    }    query = new BasicDBObject();    query.put("created_at", new BasicDBObject("$gt", mongoTimestamp));    cursor = collection.find(query);    while (cursor.hasNext()) {        Map<String, Object> user = (Map<String, Object>) cursor.next().toMap();        if (!user.containsKey("deleted_at")) {            String userID = getID(user.get(mongoUserID), true);            Collection<List<String>> items = new ArrayList<>();            List<String> item = new ArrayList<>();            item.add(getID(user.get(mongoItemID), false));            item.add(Float.toString(getPreference(user.get(mongoPreference))));            items.add(item);            try {                refreshData(userID, items, true);            } catch (NoSuchUserException e) {                            } catch (NoSuchItemException e) {                            }            if (ts.compareTo(getDate(user.get("created_at"))) < 0) {                ts = getDate(user.get("created_at"));            }        }    }    if (mongoTimestamp.compareTo(ts) < 0) {        mongoTimestamp = ts;    }}
public String mahout_f323_1(String id, boolean isUser)
{    DBObject objectIdLong = collectionMap.findOne(new BasicDBObject("element_id", id));    if (objectIdLong != null) {        Map<String, Object> idLong = (Map<String, Object>) objectIdLong.toMap();        Object value = idLong.get("long_value");        return value == null ? null : value.toString();    } else {        objectIdLong = new BasicDBObject();        String longValue = Long.toString(idCounter++);        objectIdLong.put("element_id", id);        objectIdLong.put("long_value", longValue);        collectionMap.insert(objectIdLong);                return longValue;    }}
public String mahout_f324_0(long id)
{    DBObject objectIdLong = collectionMap.findOne(new BasicDBObject("long_value", Long.toString(id)));    Map<String, Object> idLong = (Map<String, Object>) objectIdLong.toMap();    Object value = idLong.get("element_id");    return value == null ? null : value.toString();}
public boolean mahout_f325_0(String ID)
{    DBObject objectIdLong = collectionMap.findOne(new BasicDBObject("element_id", ID));    return objectIdLong != null;}
public Date mahout_f326_0()
{    return mongoTimestamp;}
private void mahout_f327_0() throws UnknownHostException
{    userIsObject = false;    itemIsObject = false;    idCounter = 0;    preferenceIsString = true;    Mongo mongoDDBB = new Mongo(mongoHost, mongoPort);    DB db = mongoDDBB.getDB(mongoDB);    mongoTimestamp = new Date(0);    FastByIDMap<Collection<Preference>> userIDPrefMap = new FastByIDMap<>();    if (!mongoAuth || db.authenticate(mongoUsername, mongoPassword.toCharArray())) {        collection = db.getCollection(mongoCollection);        collectionMap = db.getCollection(mongoMapCollection);        DBObject indexObj = new BasicDBObject();        indexObj.put("element_id", 1);        collectionMap.ensureIndex(indexObj);        indexObj = new BasicDBObject();        indexObj.put("long_value", 1);        collectionMap.ensureIndex(indexObj);        collectionMap.remove(new BasicDBObject());        DBCursor cursor = collection.find();        while (cursor.hasNext()) {            Map<String, Object> user = (Map<String, Object>) cursor.next().toMap();            if (!user.containsKey("deleted_at")) {                long userID = Long.parseLong(fromIdToLong(getID(user.get(mongoUserID), true), true));                long itemID = Long.parseLong(fromIdToLong(getID(user.get(mongoItemID), false), false));                float ratingValue = getPreference(user.get(mongoPreference));                Collection<Preference> userPrefs = userIDPrefMap.get(userID);                if (userPrefs == null) {                    userPrefs = new ArrayList<>(2);                    userIDPrefMap.put(userID, userPrefs);                }                userPrefs.add(new GenericPreference(userID, itemID, ratingValue));                if (user.containsKey("created_at") && mongoTimestamp.compareTo(getDate(user.get("created_at"))) < 0) {                    mongoTimestamp = getDate(user.get("created_at"));                }            }        }    }    delegate = new GenericDataModel(GenericDataModel.toDataMap(userIDPrefMap, true));}
private void mahout_f328_1(String userID, String itemID)
{    String userId = fromLongToId(Long.parseLong(userID));    String itemId = fromLongToId(Long.parseLong(itemID));    if (isUserItemInDB(userId, itemId)) {        mongoTimestamp = new Date();        BasicDBObject query = new BasicDBObject();        query.put(mongoUserID, userIsObject ? new ObjectId(userId) : userId);        query.put(mongoItemID, itemIsObject ? new ObjectId(itemId) : itemId);        if (mongoFinalRemove) {                    } else {            BasicDBObject update = new BasicDBObject();            update.put("$set", new BasicDBObject("deleted_at", mongoTimestamp));                    }            }}
private void mahout_f329_1(String userID, String itemID, String preferenceValue)
{    String userId = fromLongToId(Long.parseLong(userID));    String itemId = fromLongToId(Long.parseLong(itemID));    if (!isUserItemInDB(userId, itemId)) {        mongoTimestamp = new Date();        BasicDBObject user = new BasicDBObject();        Object userIdObject = userIsObject ? new ObjectId(userId) : userId;        Object itemIdObject = itemIsObject ? new ObjectId(itemId) : itemId;        user.put(mongoUserID, userIdObject);        user.put(mongoItemID, itemIdObject);        user.put(mongoPreference, preferenceIsString ? preferenceValue : Double.parseDouble(preferenceValue));        user.put("created_at", mongoTimestamp);        collection.insert(user);            }}
private boolean mahout_f330_0(String userID, String itemID)
{    BasicDBObject query = new BasicDBObject();    Object userId = userIsObject ? new ObjectId(userID) : userID;    Object itemId = itemIsObject ? new ObjectId(itemID) : itemID;    query.put(mongoUserID, userId);    query.put(mongoItemID, itemId);    return collection.findOne(query) != null;}
private DataModel mahout_f331_1(long userID, Iterable<List<String>> items)
{    FastByIDMap<PreferenceArray> rawData = ((GenericDataModel) delegate).getRawUserData();    for (List<String> item : items) {        PreferenceArray prefs = rawData.get(userID);        long itemID = Long.parseLong(item.get(0));        if (prefs != null) {            boolean exists = false;            int length = prefs.length();            for (int i = 0; i < length; i++) {                if (prefs.getItemID(i) == itemID) {                    exists = true;                    break;                }            }            if (exists) {                rawData.remove(userID);                if (length > 1) {                    PreferenceArray newPrefs = new GenericUserPreferenceArray(length - 1);                    for (int i = 0, j = 0; i < length; i++, j++) {                        if (prefs.getItemID(i) == itemID) {                            j--;                        } else {                            newPrefs.set(j, prefs.get(i));                        }                    }                    rawData.put(userID, newPrefs);                }                                if (mongoManage) {                    removeMongoUserItem(Long.toString(userID), Long.toString(itemID));                }            }        }    }    return new GenericDataModel(rawData);}
private DataModel mahout_f332_1(long userID, Iterable<List<String>> items)
{    FastByIDMap<PreferenceArray> rawData = ((GenericDataModel) delegate).getRawUserData();    PreferenceArray prefs = rawData.get(userID);    for (List<String> item : items) {        long itemID = Long.parseLong(item.get(0));        float preferenceValue = Float.parseFloat(item.get(1));        boolean exists = false;        if (prefs != null) {            for (int i = 0; i < prefs.length(); i++) {                if (prefs.getItemID(i) == itemID) {                    exists = true;                    prefs.setValue(i, preferenceValue);                    break;                }            }        }        if (!exists) {            if (prefs == null) {                prefs = new GenericUserPreferenceArray(1);            } else {                PreferenceArray newPrefs = new GenericUserPreferenceArray(prefs.length() + 1);                for (int i = 0, j = 1; i < prefs.length(); i++, j++) {                    newPrefs.set(j, prefs.get(i));                }                prefs = newPrefs;            }            prefs.setUserID(0, userID);            prefs.setItemID(0, itemID);            prefs.setValue(0, preferenceValue);                        rawData.put(userID, prefs);            if (mongoManage) {                addMongoUserItem(Long.toString(userID), Long.toString(itemID), Float.toString(preferenceValue));            }        }    }    return new GenericDataModel(rawData);}
private Date mahout_f333_1(Object date)
{    if (date.getClass().getName().contains("Date")) {        return (Date) date;    }    if (date.getClass().getName().contains("String")) {        try {            synchronized (dateFormat) {                return dateFormat.parse(date.toString());            }        } catch (ParseException ioe) {                    }    }    return new Date(0);}
private float mahout_f334_0(Object value)
{    if (value != null) {        if (value.getClass().getName().contains("String")) {            preferenceIsString = true;            return Float.parseFloat(value.toString());        } else {            preferenceIsString = false;            return Double.valueOf(value.toString()).floatValue();        }    } else {        return 0.5f;    }}
private String mahout_f335_0(Object id, boolean isUser)
{    if (id.getClass().getName().contains("ObjectId")) {        if (isUser) {            userIsObject = true;        } else {            itemIsObject = true;        }        return ((ObjectId) id).toStringMongod();    } else {        return id.toString();    }}
private void mahout_f336_0(String userID, Iterable<List<String>> items, boolean add) throws NoSuchUserException, NoSuchItemException
{    Preconditions.checkNotNull(userID);    Preconditions.checkNotNull(items);    Preconditions.checkArgument(!userID.isEmpty(), "userID is empty");    for (List<String> item : items) {        Preconditions.checkNotNull(item.get(0));        Preconditions.checkArgument(!item.get(0).isEmpty(), "item is empty");    }    if (userIsObject && !ID_PATTERN.matcher(userID).matches()) {        throw new IllegalArgumentException();    }    for (List<String> item : items) {        if (itemIsObject && !ID_PATTERN.matcher(item.get(0)).matches()) {            throw new IllegalArgumentException();        }    }    if (!add && !isIDInModel(userID)) {        throw new NoSuchUserException();    }    for (List<String> item : items) {        if (!add && !isIDInModel(item.get(0))) {            throw new NoSuchItemException();        }    }}
public void mahout_f337_0()
{    collectionMap.drop();}
public LongPrimitiveIterator mahout_f338_0() throws TasteException
{    return delegate.getUserIDs();}
public PreferenceArray mahout_f339_0(long id) throws TasteException
{    return delegate.getPreferencesFromUser(id);}
public FastIDSet mahout_f340_0(long userID) throws TasteException
{    return delegate.getItemIDsFromUser(userID);}
public LongPrimitiveIterator mahout_f341_0() throws TasteException
{    return delegate.getItemIDs();}
public PreferenceArray mahout_f342_0(long itemID) throws TasteException
{    return delegate.getPreferencesForItem(itemID);}
public Float mahout_f343_0(long userID, long itemID) throws TasteException
{    return delegate.getPreferenceValue(userID, itemID);}
public Long mahout_f344_0(long userID, long itemID) throws TasteException
{    return delegate.getPreferenceTime(userID, itemID);}
public int mahout_f345_0() throws TasteException
{    return delegate.getNumItems();}
public int mahout_f346_0() throws TasteException
{    return delegate.getNumUsers();}
public int mahout_f347_0(long itemID) throws TasteException
{    return delegate.getNumUsersWithPreferenceFor(itemID);}
public int mahout_f348_0(long itemID1, long itemID2) throws TasteException
{    return delegate.getNumUsersWithPreferenceFor(itemID1, itemID2);}
public void mahout_f349_0(long userID, long itemID, float value)
{    throw new UnsupportedOperationException();}
public void mahout_f350_0(long userID, long itemID)
{    throw new UnsupportedOperationException();}
public boolean mahout_f351_0()
{    return delegate.hasPreferenceValues();}
public float mahout_f352_0()
{    return delegate.getMaxPreference();}
public float mahout_f353_0()
{    return delegate.getMinPreference();}
public String mahout_f354_0()
{    return "MongoDBDataModel";}
public double mahout_f355_0(long itemID1, long itemID2) throws TasteException
{    return delegate.itemSimilarity(itemID1, itemID2);}
public double[] mahout_f356_0(long itemID1, long[] itemID2s) throws TasteException
{    return delegate.itemSimilarities(itemID1, itemID2s);}
public long[] mahout_f357_0(long itemID) throws TasteException
{    return delegate.allSimilarItemIDs(itemID);}
public void mahout_f358_1(Collection<Refreshable> alreadyRefreshed)
{        reload();}
protected void mahout_f359_0()
{    if (reloadLock.tryLock()) {        try {            delegate = new GenericItemSimilarity(new JDBCSimilaritiesIterable(dataSource, getAllItemSimilaritiesSQL));        } finally {            reloadLock.unlock();        }    }}
public Iterator<GenericItemSimilarity.ItemItemSimilarity> mahout_f360_0()
{    try {        return new JDBCSimilaritiesIterator(dataSource, getAllItemSimilaritiesSQL);    } catch (SQLException sqle) {        throw new IllegalStateException(sqle);    }}
protected GenericItemSimilarity.ItemItemSimilarity mahout_f361_0(ResultSet resultSet) throws SQLException
{    return new GenericItemSimilarity.ItemItemSimilarity(resultSet.getLong(1), resultSet.getLong(2), resultSet.getDouble(3));}
protected String mahout_f362_0()
{    return similarityTable;}
protected String mahout_f363_0()
{    return itemAIDColumn;}
protected String mahout_f364_0()
{    return itemBIDColumn;}
protected String mahout_f365_0()
{    return similarityColumn;}
public double mahout_f366_1(long itemID1, long itemID2) throws TasteException
{    if (itemID1 == itemID2) {        return 1.0;    }    Connection conn = null;    PreparedStatement stmt = null;    try {        conn = dataSource.getConnection();        stmt = conn.prepareStatement(getItemItemSimilaritySQL, ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY);        stmt.setFetchDirection(ResultSet.FETCH_FORWARD);        stmt.setFetchSize(getFetchSize());        return doItemSimilarity(stmt, itemID1, itemID2);    } catch (SQLException sqle) {                throw new TasteException(sqle);    } finally {        IOUtils.quietClose(null, stmt, conn);    }}
public double[] mahout_f367_1(long itemID1, long[] itemID2s) throws TasteException
{    double[] result = new double[itemID2s.length];    Connection conn = null;    PreparedStatement stmt = null;    try {        conn = dataSource.getConnection();        stmt = conn.prepareStatement(getItemItemSimilaritySQL, ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY);        stmt.setFetchDirection(ResultSet.FETCH_FORWARD);        stmt.setFetchSize(getFetchSize());        for (int i = 0; i < itemID2s.length; i++) {            result[i] = doItemSimilarity(stmt, itemID1, itemID2s[i]);        }    } catch (SQLException sqle) {                throw new TasteException(sqle);    } finally {        IOUtils.quietClose(null, stmt, conn);    }    return result;}
public long[] mahout_f368_1(long itemID) throws TasteException
{    FastIDSet allSimilarItemIDs = new FastIDSet();    Connection conn = null;    PreparedStatement stmt = null;    ResultSet rs = null;    try {        conn = dataSource.getConnection();        stmt = conn.prepareStatement(getAllSimilarItemIDsSQL, ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY);        stmt.setFetchDirection(ResultSet.FETCH_FORWARD);        stmt.setFetchSize(getFetchSize());        stmt.setLong(1, itemID);        stmt.setLong(2, itemID);        rs = stmt.executeQuery();        while (rs.next()) {            allSimilarItemIDs.add(rs.getLong(1));            allSimilarItemIDs.add(rs.getLong(2));        }    } catch (SQLException sqle) {                throw new TasteException(sqle);    } finally {        IOUtils.quietClose(rs, stmt, conn);    }    allSimilarItemIDs.remove(itemID);    return allSimilarItemIDs.toArray();}
public void mahout_f369_0(Collection<Refreshable> alreadyRefreshed)
{}
private double mahout_f370_1(PreparedStatement stmt, long itemID1, long itemID2) throws SQLException
{        if (itemID1 > itemID2) {        long temp = itemID1;        itemID1 = itemID2;        itemID2 = temp;    }    stmt.setLong(1, itemID1);    stmt.setLong(2, itemID2);        ResultSet rs = null;    try {        rs = stmt.executeQuery();                return rs.next() ? rs.getDouble(1) : Double.NaN;    } finally {        IOUtils.quietClose(rs);    }}
protected int mahout_f371_0()
{        return Integer.MIN_VALUE;}
protected int mahout_f372_0()
{        return Integer.MIN_VALUE;}
public void mahout_f373_0(ServletConfig config) throws ServletException
{    super.init(config);    String recommenderClassName = config.getInitParameter("recommender-class");    if (recommenderClassName == null) {        throw new ServletException("Servlet init-param \"recommender-class\" is not defined");    }    RecommenderSingleton.initializeIfNeeded(recommenderClassName);    recommender = RecommenderSingleton.getInstance().getRecommender();}
public void mahout_f374_0(HttpServletRequest request, HttpServletResponse response) throws ServletException
{    String userIDString = request.getParameter("userID");    if (userIDString == null) {        throw new ServletException("userID was not specified");    }    long userID = Long.parseLong(userIDString);    String howManyString = request.getParameter("howMany");    int howMany = howManyString == null ? DEFAULT_HOW_MANY : Integer.parseInt(howManyString);    boolean debug = Boolean.parseBoolean(request.getParameter("debug"));    String format = request.getParameter("format");    if (format == null) {        format = "text";    }    try {        List<RecommendedItem> items = recommender.recommend(userID, howMany);        if ("text".equals(format)) {            writePlainText(response, userID, debug, items);        } else if ("xml".equals(format)) {            writeXML(response, items);        } else if ("json".equals(format)) {            writeJSON(response, items);        } else {            throw new ServletException("Bad format parameter: " + format);        }    } catch (TasteException | IOException te) {        throw new ServletException(te);    }}
private static void mahout_f375_0(HttpServletResponse response, Iterable<RecommendedItem> items) throws IOException
{    response.setContentType("application/xml");    response.setCharacterEncoding("UTF-8");    response.setHeader("Cache-Control", "no-cache");    PrintWriter writer = response.getWriter();    writer.print("<?xml version=\"1.0\" encoding=\"UTF-8\"?><recommendedItems>");    for (RecommendedItem recommendedItem : items) {        writer.print("<item><value>");        writer.print(recommendedItem.getValue());        writer.print("</value><id>");        writer.print(recommendedItem.getItemID());        writer.print("</id></item>");    }    writer.println("</recommendedItems>");}
private static void mahout_f376_0(HttpServletResponse response, Iterable<RecommendedItem> items) throws IOException
{    response.setContentType("application/json");    response.setCharacterEncoding("UTF-8");    response.setHeader("Cache-Control", "no-cache");    PrintWriter writer = response.getWriter();    writer.print("{\"recommendedItems\":{\"item\":[");    boolean first = true;    for (RecommendedItem recommendedItem : items) {        if (first) {            first = false;        } else {            writer.print(',');        }        writer.print("{\"value\":\"");        writer.print(recommendedItem.getValue());        writer.print("\",\"id\":\"");        writer.print(recommendedItem.getItemID());        writer.print("\"}");    }    writer.println("]}}");}
private void mahout_f377_0(HttpServletResponse response, long userID, boolean debug, Iterable<RecommendedItem> items) throws IOException, TasteException
{    response.setContentType("text/plain");    response.setCharacterEncoding("UTF-8");    response.setHeader("Cache-Control", "no-cache");    PrintWriter writer = response.getWriter();    if (debug) {        writeDebugRecommendations(userID, items, writer);    } else {        writeRecommendations(items, writer);    }}
private static void mahout_f378_0(Iterable<RecommendedItem> items, PrintWriter writer)
{    for (RecommendedItem recommendedItem : items) {        writer.print(recommendedItem.getValue());        writer.print('\t');        writer.println(recommendedItem.getItemID());    }}
private void mahout_f379_0(long userID, Iterable<RecommendedItem> items, PrintWriter writer) throws TasteException
{    DataModel dataModel = recommender.getDataModel();    writer.print("User:");    writer.println(userID);    writer.print("Recommender: ");    writer.println(recommender);    writer.println();    writer.print("Top ");    writer.print(NUM_TOP_PREFERENCES);    writer.println(" Preferences:");    PreferenceArray rawPrefs = dataModel.getPreferencesFromUser(userID);    int length = rawPrefs.length();    PreferenceArray sortedPrefs = rawPrefs.clone();    sortedPrefs.sortByValueReversed();        int max = Math.min(NUM_TOP_PREFERENCES, length);    for (int i = 0; i < max; i++) {        Preference pref = sortedPrefs.get(i);        writer.print(pref.getValue());        writer.print('\t');        writer.println(pref.getItemID());    }    writer.println();    writer.println("Recommendations:");    for (RecommendedItem recommendedItem : items) {        writer.print(recommendedItem.getValue());        writer.print('\t');        writer.println(recommendedItem.getItemID());    }}
public void mahout_f380_0(HttpServletRequest request, HttpServletResponse response) throws ServletException
{    doGet(request, response);}
public String mahout_f381_0()
{    return "RecommenderServlet[recommender:" + recommender + ']';}
public static synchronized RecommenderSingleton mahout_f382_0()
{    if (instance == null) {        throw new IllegalStateException("Not initialized");    }    return instance;}
public static synchronized void mahout_f383_0(String recommenderClassName)
{    if (instance == null) {        instance = new RecommenderSingleton(recommenderClassName);    }}
public Recommender mahout_f384_0()
{    return recommender;}
public List<RecommendedItem> mahout_f385_0(long userID, int howMany) throws TasteException
{    return delegate.recommend(userID, howMany);}
public List<RecommendedItem> mahout_f386_0(long userID, int howMany, IDRescorer rescorer) throws TasteException
{    return delegate.recommend(userID, howMany, rescorer);}
public float mahout_f387_0(long userID, long itemID) throws TasteException
{    return delegate.estimatePreference(userID, itemID);}
public void mahout_f388_0(long userID, long itemID, float value) throws TasteException
{    delegate.setPreference(userID, itemID, value);}
public void mahout_f389_0(long userID, long itemID) throws TasteException
{    delegate.removePreference(userID, itemID);}
public DataModel mahout_f390_0()
{    return delegate.getDataModel();}
public void mahout_f391_0(Collection<Refreshable> alreadyRefreshed)
{    delegate.refresh(alreadyRefreshed);}
public static File mahout_f392_1(String resourceName) throws IOException
{    String absoluteResource = resourceName.startsWith("/") ? resourceName : '/' + resourceName;        InputSupplier<? extends InputStream> inSupplier;    try {        URL resourceURL = Resources.getResource(RecommenderWrapper.class, absoluteResource);        inSupplier = Resources.newInputStreamSupplier(resourceURL);    } catch (IllegalArgumentException iae) {        File resourceFile = new File(resourceName);                inSupplier = Files.newInputStreamSupplier(resourceFile);    }    File tempFile = File.createTempFile("taste", null);    tempFile.deleteOnExit();    Files.copy(inSupplier, tempFile);    return tempFile;}
public static void mahout_f393_0(String[] args) throws Exception
{    ToolRunner.run(new ConfusionMatrixDumper(), args);}
public int mahout_f394_0(String[] args) throws IOException
{    addInputOption();        addOption("output", "o", "Output path", null);    addOption(DefaultOptionCreator.overwriteOption().create());    addFlag("html", null, "Create complete HTML page");    addFlag("text", null, "Dump simple text");    Map<String, List<String>> parsedArgs = parseArguments(args);    if (parsedArgs == null) {        return -1;    }    Path inputPath = getInputPath();    String outputFile = hasOption("output") ? getOption("output") : null;    boolean text = parsedArgs.containsKey("--text");    boolean wrapHtml = parsedArgs.containsKey("--html");    PrintStream out = getPrintStream(outputFile);    if (text) {        exportText(inputPath, out);    } else {        exportTable(inputPath, out, wrapHtml);    }    out.flush();    if (out != System.out) {        out.close();    }    return 0;}
private static void mahout_f395_0(Path inputPath, PrintStream out) throws IOException
{    MatrixWritable mw = new MatrixWritable();    Text key = new Text();    readSeqFile(inputPath, key, mw);    Matrix m = mw.get();    ConfusionMatrix cm = new ConfusionMatrix(m);    out.println(String.format("%-40s", "Label") + TAB_SEPARATOR + String.format("%-10s", "Total") + TAB_SEPARATOR + String.format("%-10s", "Correct") + TAB_SEPARATOR + String.format("%-6s", "%") + TAB_SEPARATOR);    out.println(String.format("%-70s", "-").replace(' ', '-'));    List<String> labels = stripDefault(cm);    for (String label : labels) {        int correct = cm.getCorrect(label);        double accuracy = cm.getAccuracy(label);        int count = getCount(cm, label);        out.println(String.format("%-40s", label) + TAB_SEPARATOR + String.format("%-10s", count) + TAB_SEPARATOR + String.format("%-10s", correct) + TAB_SEPARATOR + String.format("%-6s", (int) Math.round(accuracy)) + TAB_SEPARATOR);    }    out.println(String.format("%-70s", "-").replace(' ', '-'));    out.println(cm.toString());}
private static void mahout_f396_0(Path inputPath, PrintStream out, boolean wrapHtml) throws IOException
{    MatrixWritable mw = new MatrixWritable();    Text key = new Text();    readSeqFile(inputPath, key, mw);    String fileName = inputPath.getName();    fileName = fileName.substring(fileName.lastIndexOf('/') + 1, fileName.length());    Matrix m = mw.get();    ConfusionMatrix cm = new ConfusionMatrix(m);    if (wrapHtml) {        printHeader(out, fileName);    }    out.println("<p/>");    printSummaryTable(cm, out);    out.println("<p/>");    printGrayTable(cm, out);    out.println("<p/>");    printCountsTable(cm, out);    out.println("<p/>");    printTextInBox(cm, out);    out.println("<p/>");    if (wrapHtml) {        printFooter(out);    }}
private static List<String> mahout_f397_0(ConfusionMatrix cm)
{    List<String> stripped = Lists.newArrayList(cm.getLabels().iterator());    String defaultLabel = cm.getDefaultLabel();    int unclassified = cm.getTotal(defaultLabel);    if (unclassified > 0) {        return stripped;    }    stripped.remove(defaultLabel);    return stripped;}
private static void mahout_f398_0(Path path, Text key, MatrixWritable m) throws IOException
{    Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);    SequenceFile.Reader reader = new SequenceFile.Reader(fs, path, conf);    reader.next(key, m);}
private static PrintStream mahout_f399_0(String outputFilename) throws IOException
{    if (outputFilename != null) {        File outputFile = new File(outputFilename);        if (outputFile.exists()) {            outputFile.delete();        }        outputFile.createNewFile();        OutputStream os = new FileOutputStream(outputFile);        return new PrintStream(os, false, Charsets.UTF_8.displayName());    } else {        return System.out;    }}
private static int mahout_f400_0(ConfusionMatrix cm, String rowLabel)
{    Iterator<String> iter = cm.getLabels().iterator();    int count = 0;    while (iter.hasNext()) {        count += cm.getCount(rowLabel, iter.next());    }    return count;}
private static void mahout_f401_0(ConfusionMatrix cm, PrintStream out)
{    out.println("<div style='width:90%;overflow:scroll;'>");    out.println("<pre>");    out.println(cm.toString());    out.println("</pre>");    out.println("</div>");}
public static void mahout_f402_0(ConfusionMatrix cm, PrintStream out)
{    format("<table class='%s'>\n", out, CSS_TABLE);    format("<tr class='%s'>", out, CSS_LABEL);    out.println("<td>Label</td><td>Total</td><td>Correct</td><td>%</td>");    out.println("</tr>");    List<String> labels = stripDefault(cm);    for (String label : labels) {        printSummaryRow(cm, out, label);    }    out.println("</table>");}
private static void mahout_f403_0(ConfusionMatrix cm, PrintStream out, String label)
{    format("<tr class='%s'>", out, CSS_CELL);    int correct = cm.getCorrect(label);    double accuracy = cm.getAccuracy(label);    int count = getCount(cm, label);    format("<td class='%s'>%s</td><td>%d</td><td>%d</td><td>%d</td>", out, CSS_CELL, label, count, correct, (int) Math.round(accuracy));    out.println("</tr>");}
private static int mahout_f404_0(ConfusionMatrix cm, String label)
{    int count = 0;    for (String s : cm.getLabels()) {        count += cm.getCount(label, s);    }    return count;}
public static void mahout_f405_0(ConfusionMatrix cm, PrintStream out)
{    format("<table class='%s'>\n", out, CSS_TABLE);    printCountsHeader(cm, out, true);    printGrayRows(cm, out);    out.println("</table>");}
private static void mahout_f406_0(ConfusionMatrix cm, PrintStream out)
{    List<String> labels = stripDefault(cm);    for (String label : labels) {        printGrayRow(cm, out, labels, label);    }}
private static void mahout_f407_0(ConfusionMatrix cm, PrintStream out, Iterable<String> labels, String rowLabel)
{    format("<tr class='%s'>", out, CSS_LABEL);    format("<td>%s</td>", out, rowLabel);    int total = getLabelTotal(cm, rowLabel);    for (String columnLabel : labels) {        printGrayCell(cm, out, total, rowLabel, columnLabel);    }    out.println("</tr>");}
private static void mahout_f408_0(ConfusionMatrix cm, PrintStream out, int total, String rowLabel, String columnLabel)
{    int count = cm.getCount(rowLabel, columnLabel);    if (count == 0) {        out.format("<td class='%s'/>", CSS_EMPTY);    } else {                int rating = (int) ((count / (double) total) * 4);        String css = CSS_GRAY_CELLS[rating];        format("<td class='%s' title='%s'>%s</td>", out, css, columnLabel, count);    }}
public static void mahout_f409_0(ConfusionMatrix cm, PrintStream out)
{    format("<table class='%s'>\n", out, CSS_TABLE);    printCountsHeader(cm, out, false);    printCountsRows(cm, out);    out.println("</table>");}
private static void mahout_f410_0(ConfusionMatrix cm, PrintStream out)
{    List<String> labels = stripDefault(cm);    for (String label : labels) {        printCountsRow(cm, out, labels, label);    }}
private static void mahout_f411_0(ConfusionMatrix cm, PrintStream out, Iterable<String> labels, String rowLabel)
{    out.println("<tr>");    format("<td class='%s'>%s</td>", out, CSS_LABEL, rowLabel);    for (String columnLabel : labels) {        printCountsCell(cm, out, rowLabel, columnLabel);    }    out.println("</tr>");}
private static void mahout_f412_0(ConfusionMatrix cm, PrintStream out, String rowLabel, String columnLabel)
{    int count = cm.getCount(rowLabel, columnLabel);    String s = count == 0 ? "" : Integer.toString(count);    format("<td class='%s' title='%s'>%s</td>", out, CSS_CELL, columnLabel, s);}
private static void mahout_f413_0(ConfusionMatrix cm, PrintStream out, boolean vertical)
{    List<String> labels = stripDefault(cm);    int longest = getLongestHeader(labels);    if (vertical) {                out.format("<tr class='%s' style='height:%dem'><th>&nbsp;</th>%n", CSS_TALL_HEADER, longest / 2);        for (String label : labels) {            out.format("<th><div class='%s'>%s</div></th>", CSS_VERTICAL, label);        }        out.println("</tr>");    } else {                out.format("<tr class='%s'><td class='%s'></td>%n", CSS_TABLE, CSS_LABEL);        for (String label : labels) {            out.format("<td>%s</td>", label);        }        out.format("</tr>");    }}
private static int mahout_f414_0(Iterable<String> labels)
{    int max = 0;    for (String label : labels) {        max = Math.max(label.length(), max);    }    return max;}
private static void mahout_f415_0(String format, PrintStream out, Object... args)
{    String format2 = String.format(format, args);    out.println(format2);}
public static void mahout_f416_0(PrintStream out, CharSequence title)
{    out.println(HEADER.replace("TITLE", title));}
public static void mahout_f417_0(PrintStream out)
{    out.println(FOOTER);}
private static List<Cluster> mahout_f418_0(Configuration conf, Path clustersIn)
{    List<Cluster> clusters = new ArrayList<>();    for (ClusterWritable clusterWritable : new SequenceFileDirValueIterable<ClusterWritable>(clustersIn, PathType.LIST, PathFilters.logsCRCFilter(), conf)) {        Cluster cluster = clusterWritable.getValue();        clusters.add(cluster);    }    return clusters;}
private void mahout_f419_0(int cI)
{    List<VectorWritable> repPts = representativePoints.get(cI);    GaussianAccumulator accumulator = new OnlineGaussianAccumulator();    for (VectorWritable vw : repPts) {        accumulator.observe(vw.get(), 1.0);    }    accumulator.compute();    double d = accumulator.getAverageStd();    stDevs.put(cI, d);}
private double mahout_f420_0(Vector uIJ, int cI, int cJ, double avgStd)
{    List<VectorWritable> repI = representativePoints.get(cI);    List<VectorWritable> repJ = representativePoints.get(cJ);    double sum = 0.0;        for (VectorWritable vwI : repI) {        if (uIJ != null && measure.distance(uIJ, vwI.get()) <= avgStd) {            sum++;        }    }    for (VectorWritable vwJ : repJ) {        if (uIJ != null && measure.distance(uIJ, vwJ.get()) <= avgStd) {            sum++;        }    }    int nI = repI.size();    int nJ = repJ.size();    return sum / (nI + nJ);}
public double mahout_f421_0()
{    return intraClusterDensity() * separation();}
public double mahout_f422_0()
{    double avgDensity = 0;    int count = 0;    for (Element elem : intraClusterDensities().nonZeroes()) {        double value = elem.get();        if (!Double.isNaN(value)) {            avgDensity += value;            count++;        }    }    return avgDensity / count;}
public Map<Integer, Map<Integer, Double>> mahout_f423_1()
{    if (interClusterDensities != null) {        return interClusterDensities;    }    interClusterDensities = new TreeMap<>();        for (int i = 0; i < clusters.size(); i++) {        int cI = clusters.get(i).getId();        Map<Integer, Double> map = new TreeMap<>();        interClusterDensities.put(cI, map);        for (int j = i + 1; j < clusters.size(); j++) {            int cJ = clusters.get(j).getId();                        double minDistance = minimumDistance(cI, cJ);                        Vector uIJ = midpointVector(cI, cJ);            double stdSum = stDevs.get(cI) + stDevs.get(cJ);            double density = density(uIJ, cI, cJ, stdSum / 2);            double interDensity = minDistance * density / stdSum;            map.put(cJ, interDensity);            if (log.isDebugEnabled()) {                                                            }        }    }    return interClusterDensities;}
public double mahout_f424_0()
{    double minDistanceSum = 0;    Map<Integer, Map<Integer, Double>> distances = minimumDistances();    for (Map<Integer, Double> map : distances.values()) {        for (Double dist : map.values()) {            if (!Double.isInfinite(dist)) {                                minDistanceSum += dist * 2;            }        }    }    return minDistanceSum / (1.0 + interClusterDensity());}
public double mahout_f425_1()
{    if (interClusterDensity != null) {        return interClusterDensity;    }    double sum = 0.0;    int count = 0;    Map<Integer, Map<Integer, Double>> distances = interClusterDensities();    for (Map<Integer, Double> row : distances.values()) {        for (Double density : row.values()) {            if (!Double.isNaN(density)) {                sum += density;                count++;            }        }    }        interClusterDensity = sum / count;    return interClusterDensity;}
public Vector mahout_f426_0()
{    Vector densities = new RandomAccessSparseVector(Integer.MAX_VALUE);        double stdev = 0.0;    for (Integer cI : representativePoints.keySet()) {        stdev += stDevs.get(cI);    }    int c = representativePoints.size();    stdev /= c;    for (Cluster cluster : clusters) {        Integer cI = cluster.getId();        List<VectorWritable> repPtsI = representativePoints.get(cI);        int r = repPtsI.size();        double sumJ = 0.0;                for (VectorWritable pt : repPtsI) {                        Vector repJ = pt.get();            double densityIJ = measure.distance(cluster.getCenter(), repJ) <= stdev ? 1.0 : 0.0;                        sumJ += densityIJ / stdev;        }        densities.set(cI, sumJ / r);    }    return densities;}
private Map<Integer, Map<Integer, Double>> mahout_f427_0()
{    if (minimumDistances != null) {        return minimumDistances;    }    minimumDistances = new TreeMap<>();    closestRepPointIndices = new TreeMap<>();    for (int i = 0; i < clusters.size(); i++) {        Integer cI = clusters.get(i).getId();        Map<Integer, Double> map = new TreeMap<>();        Map<Integer, int[]> treeMap = new TreeMap<>();        closestRepPointIndices.put(cI, treeMap);        minimumDistances.put(cI, map);        List<VectorWritable> closRepI = representativePoints.get(cI);        for (int j = i + 1; j < clusters.size(); j++) {                        Integer cJ = clusters.get(j).getId();            List<VectorWritable> closRepJ = representativePoints.get(cJ);            double minDistance = Double.MAX_VALUE;            int[] midPointIndices = null;            for (int xI = 0; xI < closRepI.size(); xI++) {                VectorWritable aRepI = closRepI.get(xI);                for (int xJ = 0; xJ < closRepJ.size(); xJ++) {                    VectorWritable aRepJ = closRepJ.get(xJ);                    double distance = measure.distance(aRepI.get(), aRepJ.get());                    if (distance < minDistance) {                        minDistance = distance;                        midPointIndices = new int[] { xI, xJ };                    }                }            }            map.put(cJ, minDistance);            treeMap.put(cJ, midPointIndices);        }    }    return minimumDistances;}
private double mahout_f428_0(int cI, int cJ)
{    Map<Integer, Double> distances = minimumDistances().get(cI);    if (distances != null) {        return distances.get(cJ);    } else {        return minimumDistances().get(cJ).get(cI);    }}
private Vector mahout_f429_0(int cI, int cJ)
{    Map<Integer, Double> distances = minimumDistances().get(cI);    if (distances != null) {        int[] ks = closestRepPointIndices.get(cI).get(cJ);        if (ks == null) {            return null;        }        return representativePoints.get(cI).get(ks[0]).get().plus(representativePoints.get(cJ).get(ks[1]).get()).divide(2);    } else {        int[] ks = closestRepPointIndices.get(cJ).get(cI);        if (ks == null) {            return null;        }        return representativePoints.get(cJ).get(ks[1]).get().plus(representativePoints.get(cI).get(ks[0]).get()).divide(2);    }}
public static void mahout_f430_1(String[] args) throws IOException, InterruptedException, ClassNotFoundException
{    DefaultOptionBuilder obuilder = new DefaultOptionBuilder();    ArgumentBuilder abuilder = new ArgumentBuilder();    GroupBuilder gbuilder = new GroupBuilder();    Option inputOpt = DefaultOptionCreator.inputOption().withRequired(false).create();    Option outputOpt = DefaultOptionCreator.outputOption().withRequired(false).create();    Option vectorOpt = obuilder.withLongName("vector").withRequired(false).withArgument(abuilder.withName("v").withMinimum(1).withMaximum(1).create()).withDescription("The vector implementation to use.").withShortName("v").create();    Option helpOpt = DefaultOptionCreator.helpOption();    Group group = gbuilder.withName("Options").withOption(inputOpt).withOption(outputOpt).withOption(vectorOpt).withOption(helpOpt).create();    try {        Parser parser = new Parser();        parser.setGroup(group);        CommandLine cmdLine = parser.parse(args);        if (cmdLine.hasOption(helpOpt)) {            CommandLineUtil.printHelp(group);            return;        }        Path input = new Path(cmdLine.getValue(inputOpt, "testdata").toString());        Path output = new Path(cmdLine.getValue(outputOpt, "output").toString());        String vectorClassName = cmdLine.getValue(vectorOpt, "org.apache.mahout.math.RandomAccessSparseVector").toString();        runJob(input, output, vectorClassName);    } catch (OptionException e) {                CommandLineUtil.printHelp(group);    }}
public static void mahout_f431_0(Path input, Path output, String vectorClassName) throws IOException, InterruptedException, ClassNotFoundException
{    Configuration conf = new Configuration();    conf.set("vector.implementation.class.name", vectorClassName);    Job job = new Job(conf, "Input Driver running over input: " + input);    job.setOutputKeyClass(Text.class);    job.setOutputValueClass(VectorWritable.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    job.setMapperClass(InputMapper.class);    job.setNumReduceTasks(0);    job.setJarByClass(InputDriver.class);    FileInputFormat.addInputPath(job, input);    FileOutputFormat.setOutputPath(job, output);    boolean succeeded = job.waitForCompletion(true);    if (!succeeded) {        throw new IllegalStateException("Job failed!");    }}
protected void mahout_f432_0(LongWritable key, Text values, Context context) throws IOException, InterruptedException
{    String[] numbers = SPACE.split(values.toString());        Collection<Double> doubles = new ArrayList<>();    for (String value : numbers) {        if (!value.isEmpty()) {            doubles.add(Double.valueOf(value));        }    }        if (!doubles.isEmpty()) {        try {            Vector result = (Vector) constructor.newInstance(doubles.size());            int index = 0;            for (Double d : doubles) {                result.set(index++, d);            }            VectorWritable vectorWritable = new VectorWritable(result);            context.write(new Text(String.valueOf(index)), vectorWritable);        } catch (InstantiationException | IllegalAccessException | InvocationTargetException e) {            throw new IllegalStateException(e);        }    }}
protected void mahout_f433_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    Configuration conf = context.getConfiguration();    String vectorImplClassName = conf.get("vector.implementation.class.name");    try {        Class<? extends Vector> outputClass = conf.getClassByName(vectorImplClassName).asSubclass(Vector.class);        constructor = outputClass.getConstructor(int.class);    } catch (NoSuchMethodException | ClassNotFoundException e) {        throw new IllegalStateException(e);    }}
private static List<Cluster> mahout_f434_0(Configuration conf, Path clustersIn)
{    List<Cluster> clusters = new ArrayList<>();    for (ClusterWritable clusterWritable : new SequenceFileDirValueIterable<ClusterWritable>(clustersIn, PathType.LIST, PathFilters.logsCRCFilter(), conf)) {        Cluster cluster = clusterWritable.getValue();        clusters.add(cluster);    }    return clusters;}
public double mahout_f435_1()
{    double max = Double.NEGATIVE_INFINITY;    double min = Double.POSITIVE_INFINITY;    double sum = 0;    int count = 0;    Map<Integer, Vector> distances = interClusterDistances();    for (Vector row : distances.values()) {        for (Element element : row.nonZeroes()) {            double d = element.get();            min = Math.min(d, min);            max = Math.max(d, max);            sum += d;            count++;        }    }    double density = (sum / count - min) / (max - min);        return density;}
public Map<Integer, Vector> mahout_f436_0()
{    Map<Integer, Vector> distances = new TreeMap<>();    for (int i = 0; i < clusters.size(); i++) {        Cluster clusterI = clusters.get(i);        RandomAccessSparseVector row = new RandomAccessSparseVector(Integer.MAX_VALUE);        distances.put(clusterI.getId(), row);        for (int j = i + 1; j < clusters.size(); j++) {            Cluster clusterJ = clusters.get(j);            double d = measure.distance(clusterI.getCenter(), clusterJ.getCenter());            row.set(clusterJ.getId(), d);        }    }    return distances;}
public double mahout_f437_1()
{    double avgDensity = 0;    int count = 0;    for (Element elem : intraClusterDensities().nonZeroes()) {        double value = elem.get();        if (!Double.isNaN(value)) {            avgDensity += value;            count++;        }    }    avgDensity = clusters.isEmpty() ? 0 : avgDensity / count;        return avgDensity;}
public Vector mahout_f438_1()
{    Vector densities = new RandomAccessSparseVector(Integer.MAX_VALUE);    for (Cluster cluster : clusters) {        int count = 0;        double max = Double.NEGATIVE_INFINITY;        double min = Double.POSITIVE_INFINITY;        double sum = 0;        List<VectorWritable> repPoints = representativePoints.get(cluster.getId());        for (int i = 0; i < repPoints.size(); i++) {            for (int j = i + 1; j < repPoints.size(); j++) {                Vector v1 = repPoints.get(i).get();                Vector v2 = repPoints.get(j).get();                double d = measure.distance(v1, v2);                min = Math.min(d, min);                max = Math.max(d, max);                sum += d;                count++;            }        }        double density = (sum / count - min) / (max - min);        densities.set(cluster.getId(), density);            }    return densities;}
public static void mahout_f439_0(String[] args) throws Exception
{    ToolRunner.run(new Configuration(), new RepresentativePointsDriver(), args);}
public int mahout_f440_0(String[] args) throws ClassNotFoundException, IOException, InterruptedException
{    addInputOption();    addOutputOption();    addOption("clusteredPoints", "cp", "The path to the clustered points", true);    addOption(DefaultOptionCreator.distanceMeasureOption().create());    addOption(DefaultOptionCreator.maxIterationsOption().create());    addOption(DefaultOptionCreator.methodOption().create());    if (parseArguments(args) == null) {        return -1;    }    Path input = getInputPath();    Path output = getOutputPath();    String distanceMeasureClass = getOption(DefaultOptionCreator.DISTANCE_MEASURE_OPTION);    int maxIterations = Integer.parseInt(getOption(DefaultOptionCreator.MAX_ITERATIONS_OPTION));    boolean runSequential = getOption(DefaultOptionCreator.METHOD_OPTION).equalsIgnoreCase(DefaultOptionCreator.SEQUENTIAL_METHOD);    DistanceMeasure measure = ClassUtils.instantiateAs(distanceMeasureClass, DistanceMeasure.class);    Path clusteredPoints = new Path(getOption("clusteredPoints"));    run(getConf(), input, clusteredPoints, output, measure, maxIterations, runSequential);    return 0;}
public static void mahout_f441_0(Path output, int numIterations)
{    for (int i = 0; i <= numIterations; i++) {        Path out = new Path(output, "representativePoints-" + i);        System.out.println("Representative Points for iteration " + i);        Configuration conf = new Configuration();        for (Pair<IntWritable, VectorWritable> record : new SequenceFileDirIterable<IntWritable, VectorWritable>(out, PathType.LIST, PathFilters.logsCRCFilter(), null, true, conf)) {            System.out.println("\tC-" + record.getFirst().get() + ": " + AbstractCluster.formatVector(record.getSecond().get(), null));        }    }}
public static void mahout_f442_1(Configuration conf, Path clustersIn, Path clusteredPointsIn, Path output, DistanceMeasure measure, int numIterations, boolean runSequential) throws IOException, InterruptedException, ClassNotFoundException
{    Path stateIn = new Path(output, "representativePoints-0");    writeInitialState(stateIn, clustersIn);    for (int iteration = 0; iteration < numIterations; iteration++) {                        Path stateOut = new Path(output, "representativePoints-" + (iteration + 1));        runIteration(conf, clusteredPointsIn, stateIn, stateOut, measure, runSequential);                stateIn = stateOut;    }    conf.set(STATE_IN_KEY, stateIn.toString());    conf.set(DISTANCE_MEASURE_KEY, measure.getClass().getName());}
private static void mahout_f443_1(Path output, Path clustersIn) throws IOException
{    Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(output.toUri(), conf);    for (FileStatus dir : fs.globStatus(clustersIn)) {        Path inPath = dir.getPath();        for (FileStatus part : fs.listStatus(inPath, PathFilters.logsCRCFilter())) {            Path inPart = part.getPath();            Path path = new Path(output, inPart.getName());            try (SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, path, IntWritable.class, VectorWritable.class)) {                for (ClusterWritable clusterWritable : new SequenceFileValueIterable<ClusterWritable>(inPart, true, conf)) {                    Cluster cluster = clusterWritable.getValue();                    if (log.isDebugEnabled()) {                                            }                    writer.append(new IntWritable(cluster.getId()), new VectorWritable(cluster.getCenter()));                }            }        }    }}
private static void mahout_f444_0(Configuration conf, Path clusteredPointsIn, Path stateIn, Path stateOut, DistanceMeasure measure, boolean runSequential) throws IOException, InterruptedException, ClassNotFoundException
{    if (runSequential) {        runIterationSeq(conf, clusteredPointsIn, stateIn, stateOut, measure);    } else {        runIterationMR(conf, clusteredPointsIn, stateIn, stateOut, measure);    }}
private static void mahout_f445_0(Configuration conf, Path clusteredPointsIn, Path stateIn, Path stateOut, DistanceMeasure measure) throws IOException
{    Map<Integer, List<VectorWritable>> repPoints = RepresentativePointsMapper.getRepresentativePoints(conf, stateIn);    Map<Integer, WeightedVectorWritable> mostDistantPoints = new HashMap<>();    FileSystem fs = FileSystem.get(clusteredPointsIn.toUri(), conf);    for (Pair<IntWritable, WeightedVectorWritable> record : new SequenceFileDirIterable<IntWritable, WeightedVectorWritable>(clusteredPointsIn, PathType.LIST, PathFilters.logsCRCFilter(), null, true, conf)) {        RepresentativePointsMapper.mapPoint(record.getFirst(), record.getSecond(), measure, repPoints, mostDistantPoints);    }    int part = 0;    try (SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, new Path(stateOut, "part-m-" + part++), IntWritable.class, VectorWritable.class)) {        for (Entry<Integer, List<VectorWritable>> entry : repPoints.entrySet()) {            for (VectorWritable vw : entry.getValue()) {                writer.append(new IntWritable(entry.getKey()), vw);            }        }    }    try (SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, new Path(stateOut, "part-m-" + part++), IntWritable.class, VectorWritable.class)) {        for (Map.Entry<Integer, WeightedVectorWritable> entry : mostDistantPoints.entrySet()) {            writer.append(new IntWritable(entry.getKey()), new VectorWritable(entry.getValue().getVector()));        }    }}
private static void mahout_f446_0(Configuration conf, Path input, Path stateIn, Path stateOut, DistanceMeasure measure) throws IOException, InterruptedException, ClassNotFoundException
{    conf.set(STATE_IN_KEY, stateIn.toString());    conf.set(DISTANCE_MEASURE_KEY, measure.getClass().getName());    Job job = new Job(conf, "Representative Points Driver running over input: " + input);    job.setJarByClass(RepresentativePointsDriver.class);    job.setOutputKeyClass(IntWritable.class);    job.setOutputValueClass(VectorWritable.class);    job.setMapOutputKeyClass(IntWritable.class);    job.setMapOutputValueClass(WeightedVectorWritable.class);    FileInputFormat.setInputPaths(job, input);    FileOutputFormat.setOutputPath(job, stateOut);    job.setMapperClass(RepresentativePointsMapper.class);    job.setReducerClass(RepresentativePointsReducer.class);    job.setInputFormatClass(SequenceFileInputFormat.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    boolean succeeded = job.waitForCompletion(true);    if (!succeeded) {        throw new IllegalStateException("Job failed!");    }}
protected void mahout_f447_0(Context context) throws IOException, InterruptedException
{    for (Map.Entry<Integer, WeightedVectorWritable> entry : mostDistantPoints.entrySet()) {        context.write(new IntWritable(entry.getKey()), entry.getValue());    }    super.cleanup(context);}
protected void mahout_f448_0(IntWritable clusterId, WeightedVectorWritable point, Context context) throws IOException, InterruptedException
{    mapPoint(clusterId, point, measure, representativePoints, mostDistantPoints);}
public static void mahout_f449_0(IntWritable clusterId, WeightedVectorWritable point, DistanceMeasure measure, Map<Integer, List<VectorWritable>> representativePoints, Map<Integer, WeightedVectorWritable> mostDistantPoints)
{    int key = clusterId.get();    WeightedVectorWritable currentMDP = mostDistantPoints.get(key);    List<VectorWritable> repPoints = representativePoints.get(key);    double totalDistance = 0.0;    if (repPoints != null) {        for (VectorWritable refPoint : repPoints) {            totalDistance += measure.distance(refPoint.get(), point.getVector());        }    }    if (currentMDP == null || currentMDP.getWeight() < totalDistance) {        mostDistantPoints.put(key, new WeightedVectorWritable(totalDistance, point.getVector().clone()));    }}
protected void mahout_f450_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    Configuration conf = context.getConfiguration();    measure = ClassUtils.instantiateAs(conf.get(RepresentativePointsDriver.DISTANCE_MEASURE_KEY), DistanceMeasure.class);    representativePoints = getRepresentativePoints(conf);}
public void mahout_f451_0(Map<Integer, List<VectorWritable>> referencePoints, DistanceMeasure measure)
{    this.representativePoints = referencePoints;    this.measure = measure;}
public static Map<Integer, List<VectorWritable>> mahout_f452_0(Configuration conf)
{    String statePath = conf.get(RepresentativePointsDriver.STATE_IN_KEY);    return getRepresentativePoints(conf, new Path(statePath));}
public static Map<Integer, List<VectorWritable>> mahout_f453_0(Configuration conf, Path statePath)
{    Map<Integer, List<VectorWritable>> representativePoints = new HashMap<>();    for (Pair<IntWritable, VectorWritable> record : new SequenceFileDirIterable<IntWritable, VectorWritable>(statePath, PathType.LIST, PathFilters.logsCRCFilter(), conf)) {        int keyValue = record.getFirst().get();        List<VectorWritable> repPoints = representativePoints.get(keyValue);        if (repPoints == null) {            repPoints = new ArrayList<>();            representativePoints.put(keyValue, repPoints);        }        repPoints.add(record.getSecond());    }    return representativePoints;}
protected void mahout_f454_0(Context context) throws IOException, InterruptedException
{    for (Map.Entry<Integer, List<VectorWritable>> entry : representativePoints.entrySet()) {        IntWritable iw = new IntWritable(entry.getKey());        for (VectorWritable vw : entry.getValue()) {            context.write(iw, vw);        }    }    super.cleanup(context);}
protected void mahout_f455_0(IntWritable key, Iterable<WeightedVectorWritable> values, Context context) throws IOException, InterruptedException
{        WeightedVectorWritable mdp = null;    for (WeightedVectorWritable dpw : values) {        if (mdp == null || mdp.getWeight() < dpw.getWeight()) {            mdp = new WeightedVectorWritable(dpw.getWeight(), dpw.getVector());        }    }    context.write(new IntWritable(key.get()), new VectorWritable(mdp.getVector()));}
protected void mahout_f456_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    Configuration conf = context.getConfiguration();    representativePoints = RepresentativePointsMapper.getRepresentativePoints(conf);}
public void mahout_f457_0(Map<Integer, List<VectorWritable>> representativePoints)
{    this.representativePoints = representativePoints;}
private static void mahout_f458_0(Collection<Queue<Pair<String, Double>>> queues, int k)
{    for (int i = queues.size(); i <= k; ++i) {        queues.add(new PriorityQueue<Pair<String, Double>>());    }}
public static void mahout_f459_0(String[] args) throws Exception
{    DefaultOptionBuilder obuilder = new DefaultOptionBuilder();    ArgumentBuilder abuilder = new ArgumentBuilder();    GroupBuilder gbuilder = new GroupBuilder();    Option inputOpt = DefaultOptionCreator.inputOption().create();    Option dictOpt = obuilder.withLongName("dict").withRequired(true).withArgument(abuilder.withName("dict").withMinimum(1).withMaximum(1).create()).withDescription("Dictionary to read in, in the same format as one created by " + "org.apache.mahout.utils.vectors.lucene.Driver").withShortName("d").create();    Option outOpt = DefaultOptionCreator.outputOption().create();    Option wordOpt = obuilder.withLongName("words").withRequired(false).withArgument(abuilder.withName("words").withMinimum(0).withMaximum(1).withDefault("20").create()).withDescription("Number of words to print").withShortName("w").create();    Option dictTypeOpt = obuilder.withLongName("dictionaryType").withRequired(false).withArgument(abuilder.withName("dictionaryType").withMinimum(1).withMaximum(1).create()).withDescription("The dictionary file type (text|sequencefile)").withShortName("dt").create();    Option helpOpt = obuilder.withLongName("help").withDescription("Print out help").withShortName("h").create();    Group group = gbuilder.withName("Options").withOption(dictOpt).withOption(outOpt).withOption(wordOpt).withOption(inputOpt).withOption(dictTypeOpt).create();    try {        Parser parser = new Parser();        parser.setGroup(group);        CommandLine cmdLine = parser.parse(args);        if (cmdLine.hasOption(helpOpt)) {            CommandLineUtil.printHelp(group);            return;        }        String input = cmdLine.getValue(inputOpt).toString();        String dictFile = cmdLine.getValue(dictOpt).toString();        int numWords = 20;        if (cmdLine.hasOption(wordOpt)) {            numWords = Integer.parseInt(cmdLine.getValue(wordOpt).toString());        }        Configuration config = new Configuration();        String dictionaryType = "text";        if (cmdLine.hasOption(dictTypeOpt)) {            dictionaryType = cmdLine.getValue(dictTypeOpt).toString();        }        List<String> wordList;        if ("text".equals(dictionaryType)) {            wordList = Arrays.asList(VectorHelper.loadTermDictionary(new File(dictFile)));        } else if ("sequencefile".equals(dictionaryType)) {            wordList = Arrays.asList(VectorHelper.loadTermDictionary(config, dictFile));        } else {            throw new IllegalArgumentException("Invalid dictionary format");        }        List<Queue<Pair<String, Double>>> topWords = topWordsForTopics(input, config, wordList, numWords);        File output = null;        if (cmdLine.hasOption(outOpt)) {            output = new File(cmdLine.getValue(outOpt).toString());            if (!output.exists() && !output.mkdirs()) {                throw new IOException("Could not create directory: " + output);            }        }        printTopWords(topWords, output);    } catch (OptionException e) {        CommandLineUtil.printHelp(group);        throw e;    }}
private static void mahout_f460_0(Queue<Pair<String, Double>> q, String word, double score, int numWordsToPrint)
{    if (q.size() >= numWordsToPrint && score > q.peek().getSecond()) {        q.poll();    }    if (q.size() < numWordsToPrint) {        q.add(new Pair<>(word, score));    }}
private static void mahout_f461_0(List<Queue<Pair<String, Double>>> topWords, File outputDir) throws IOException
{    for (int i = 0; i < topWords.size(); ++i) {        Collection<Pair<String, Double>> topK = topWords.get(i);        Writer out = null;        boolean printingToSystemOut = false;        try {            if (outputDir != null) {                out = new OutputStreamWriter(new FileOutputStream(new File(outputDir, "topic_" + i)), Charsets.UTF_8);            } else {                out = new OutputStreamWriter(System.out, Charsets.UTF_8);                printingToSystemOut = true;                out.write("Topic " + i);                out.write('\n');                out.write("===========");                out.write('\n');            }            List<Pair<String, Double>> topKasList = new ArrayList<>(topK.size());            for (Pair<String, Double> wordWithScore : topK) {                topKasList.add(wordWithScore);            }            Collections.sort(topKasList, new Comparator<Pair<String, Double>>() {                @Override                public int compare(Pair<String, Double> pair1, Pair<String, Double> pair2) {                    return pair2.getSecond().compareTo(pair1.getSecond());                }            });            for (Pair<String, Double> wordWithScore : topKasList) {                out.write(wordWithScore.getFirst() + " [p(" + wordWithScore.getFirst() + "|topic_" + i + ") = " + wordWithScore.getSecond());                out.write('\n');            }        } finally {            if (!printingToSystemOut) {                Closeables.close(out, false);            } else {                out.flush();            }        }    }}
public int mahout_f462_0(Pair<String, Double> pair1, Pair<String, Double> pair2)
{    return pair2.getSecond().compareTo(pair1.getSecond());}
private static List<Queue<Pair<String, Double>>> mahout_f463_0(String dir, Configuration job, List<String> wordList, int numWordsToPrint)
{    List<Queue<Pair<String, Double>>> queues = new ArrayList<>();    Map<Integer, Double> expSums = new HashMap<>();    for (Pair<IntPairWritable, DoubleWritable> record : new SequenceFileDirIterable<IntPairWritable, DoubleWritable>(new Path(dir, "part-*"), PathType.GLOB, null, null, true, job)) {        IntPairWritable key = record.getFirst();        int topic = key.getFirst();        int word = key.getSecond();        ensureQueueSize(queues, topic);        if (word >= 0 && topic >= 0) {            double score = record.getSecond().get();            if (expSums.get(topic) == null) {                expSums.put(topic, 0.0);            }            expSums.put(topic, expSums.get(topic) + Math.exp(score));            String realWord = wordList.get(word);            maybeEnqueue(queues.get(topic), realWord, score, numWordsToPrint);        }    }    for (int i = 0; i < queues.size(); i++) {        Queue<Pair<String, Double>> queue = queues.get(i);        Queue<Pair<String, Double>> newQueue = new PriorityQueue<>(queue.size());        double norm = expSums.get(i);        for (Pair<String, Double> pair : queue) {            newQueue.add(new Pair<>(pair.getFirst(), Math.exp(pair.getSecond()) / norm));        }        queues.set(i, newQueue);    }    return queues;}
protected TokenStreamComponents mahout_f464_0(String fieldName)
{    Tokenizer tokenizer = new StandardTokenizer();    TokenStream result = new StandardFilter(tokenizer);    result = new LowerCaseFilter(result);    result = new ASCIIFoldingFilter(result);    result = new AlphaNumericMaxLengthFilter(result);    result = new StopFilter(result, STOP_SET);    result = new PorterStemFilter(result);    return new TokenStreamComponents(tokenizer, result);}
public final boolean mahout_f465_0() throws IOException
{        while (input.incrementToken()) {        int length = termAtt.length();        if (length >= 2 && length <= 28) {            char[] buf = termAtt.buffer();            int at = 0;            for (int c = 0; c < length; c++) {                char ch = buf[c];                if (ch != '\'') {                    output[at++] = ch;                }            }            String term = new String(output, 0, at);            MATCHER.reset(term);            if (MATCHER.matches() && !term.startsWith("a0")) {                termAtt.setEmpty();                termAtt.append(term);                return true;            }        }    }    return false;}
public RecordReader<IntWritable, BytesWritable> mahout_f466_0(InputSplit inputSplit, TaskAttemptContext taskAttemptContext) throws IOException
{    return new CombineFileRecordReader<>((CombineFileSplit) inputSplit, taskAttemptContext, WholeFileRecordReader.class);}
protected void mahout_f467_0(FileStatus fst, Path current) throws IOException
{    FileSystem fs = getFs();    ChunkedWriter writer = getWriter();    if (fst.isDir()) {        String dirPath = getPrefix() + Path.SEPARATOR + current.getName() + Path.SEPARATOR + fst.getPath().getName();        fs.listStatus(fst.getPath(), new PrefixAdditionFilter(getConf(), dirPath, getOptions(), writer, getCharset(), fs));    } else {        try (InputStream in = fs.open(fst.getPath())) {            StringBuilder file = new StringBuilder();            for (String aFit : new FileLineIterable(in, getCharset(), false)) {                file.append(aFit).append('\n');            }            String name = current.getName().equals(fst.getPath().getName()) ? current.getName() : current.getName() + Path.SEPARATOR + fst.getPath().getName();            writer.write(getPrefix() + Path.SEPARATOR + name, file.toString());        }    }}
public static void mahout_f468_0(String[] args) throws Exception
{    ToolRunner.run(new SequenceFilesFromDirectory(), args);}
public int mahout_f469_0(String[] args) throws Exception
{    addOptions();    addOption(DefaultOptionCreator.methodOption().create());    addOption(DefaultOptionCreator.overwriteOption().create());    if (parseArguments(args) == null) {        return -1;    }    Map<String, String> options = parseOptions();    Path output = getOutputPath();    if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {        HadoopUtil.delete(getConf(), output);    }    if (getOption(DefaultOptionCreator.METHOD_OPTION, DefaultOptionCreator.MAPREDUCE_METHOD).equals(DefaultOptionCreator.SEQUENTIAL_METHOD)) {        runSequential(getConf(), getInputPath(), output, options);    } else {        runMapReduce(getInputPath(), output);    }    return 0;}
private int mahout_f470_0(Configuration conf, Path input, Path output, Map<String, String> options) throws IOException, InterruptedException, NoSuchMethodException
{        Charset charset = Charset.forName(getOption(CHARSET_OPTION[0]));    String keyPrefix = getOption(KEY_PREFIX_OPTION[0]);    FileSystem fs = FileSystem.get(input.toUri(), conf);    try (ChunkedWriter writer = new ChunkedWriter(conf, Integer.parseInt(options.get(CHUNK_SIZE_OPTION[0])), output)) {        SequenceFilesFromDirectoryFilter pathFilter;        String fileFilterClassName = options.get(FILE_FILTER_CLASS_OPTION[0]);        if (PrefixAdditionFilter.class.getName().equals(fileFilterClassName)) {            pathFilter = new PrefixAdditionFilter(conf, keyPrefix, options, writer, charset, fs);        } else {            pathFilter = ClassUtils.instantiateAs(fileFilterClassName, SequenceFilesFromDirectoryFilter.class, new Class[] { Configuration.class, String.class, Map.class, ChunkedWriter.class, Charset.class, FileSystem.class }, new Object[] { conf, keyPrefix, options, writer, charset, fs });        }        fs.listStatus(input, pathFilter);    }    return 0;}
private int mahout_f471_0(Path input, Path output) throws IOException, ClassNotFoundException, InterruptedException
{    int chunkSizeInMB = 64;    if (hasOption(CHUNK_SIZE_OPTION[0])) {        chunkSizeInMB = Integer.parseInt(getOption(CHUNK_SIZE_OPTION[0]));    }    String keyPrefix = null;    if (hasOption(KEY_PREFIX_OPTION[0])) {        keyPrefix = getOption(KEY_PREFIX_OPTION[0]);    }    String fileFilterClassName = null;    if (hasOption(FILE_FILTER_CLASS_OPTION[0])) {        fileFilterClassName = getOption(FILE_FILTER_CLASS_OPTION[0]);    }    PathFilter pathFilter = null;        if (!StringUtils.isBlank(fileFilterClassName) && !PrefixAdditionFilter.class.getName().equals(fileFilterClassName)) {        try {            pathFilter = (PathFilter) Class.forName(fileFilterClassName).newInstance();        } catch (InstantiationException | IllegalAccessException e) {            throw new IllegalStateException(e);        }    }        Job job = prepareJob(input, output, MultipleTextFileInputFormat.class, SequenceFilesFromDirectoryMapper.class, Text.class, Text.class, SequenceFileOutputFormat.class, "SequenceFilesFromDirectory");    Configuration jobConfig = job.getConfiguration();    jobConfig.set(KEY_PREFIX_OPTION[0], keyPrefix);    jobConfig.set(FILE_FILTER_CLASS_OPTION[0], fileFilterClassName);    FileSystem fs = FileSystem.get(jobConfig);    FileStatus fsFileStatus = fs.getFileStatus(input);    String inputDirList;    if (pathFilter != null) {        inputDirList = HadoopUtil.buildDirList(fs, fsFileStatus, pathFilter);    } else {        inputDirList = HadoopUtil.buildDirList(fs, fsFileStatus);    }    jobConfig.set(BASE_INPUT_PATH, input.toString());    long chunkSizeInBytes = chunkSizeInMB * 1024 * 1024;        jobConfig.set("mapreduce.job.max.split.locations", String.valueOf(MAX_JOB_SPLIT_LOCATIONS));    FileInputFormat.setInputPaths(job, inputDirList);        FileInputFormat.setMaxInputSplitSize(job, chunkSizeInBytes);    FileOutputFormat.setCompressOutput(job, true);    boolean succeeded = job.waitForCompletion(true);    if (!succeeded) {        return -1;    }    return 0;}
protected void mahout_f472_0()
{    addInputOption();    addOutputOption();    addOption(DefaultOptionCreator.overwriteOption().create());    addOption(DefaultOptionCreator.methodOption().create());    addOption(CHUNK_SIZE_OPTION[0], CHUNK_SIZE_OPTION[1], "The chunkSize in MegaBytes. Defaults to 64", "64");    addOption(FILE_FILTER_CLASS_OPTION[0], FILE_FILTER_CLASS_OPTION[1], "The name of the class to use for file parsing. Default: " + PREFIX_ADDITION_FILTER, PREFIX_ADDITION_FILTER);    addOption(KEY_PREFIX_OPTION[0], KEY_PREFIX_OPTION[1], "The prefix to be prepended to the key", "");    addOption(CHARSET_OPTION[0], CHARSET_OPTION[1], "The name of the character encoding of the input files. Default to UTF-8", "UTF-8");}
protected Map<String, String> mahout_f473_0()
{    Map<String, String> options = new HashMap<>();    options.put(CHUNK_SIZE_OPTION[0], getOption(CHUNK_SIZE_OPTION[0]));    options.put(FILE_FILTER_CLASS_OPTION[0], getOption(FILE_FILTER_CLASS_OPTION[0]));    options.put(CHARSET_OPTION[0], getOption(CHARSET_OPTION[0]));    return options;}
protected final String mahout_f474_0()
{    return prefix;}
protected final ChunkedWriter mahout_f475_0()
{    return writer;}
protected final Charset mahout_f476_0()
{    return charset;}
protected final FileSystem mahout_f477_0()
{    return fs;}
protected final Map<String, String> mahout_f478_0()
{    return options;}
protected final Configuration mahout_f479_0()
{    return conf;}
public final boolean mahout_f480_1(Path current)
{        try {        for (FileStatus fst : fs.listStatus(current)) {                        process(fst, current);        }    } catch (IOException ioe) {        throw new IllegalStateException(ioe);    }    return false;}
protected void mahout_f481_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    this.keyPrefix = context.getConfiguration().get(KEY_PREFIX_OPTION[0], "");}
public void mahout_f482_0(IntWritable key, BytesWritable value, Context context) throws IOException, InterruptedException
{    Configuration configuration = context.getConfiguration();    Path filePath = ((CombineFileSplit) context.getInputSplit()).getPath(key.get());    String relativeFilePath = HadoopUtil.calcRelativeFilePath(configuration, filePath);    String filename = this.keyPrefix.length() > 0 ? this.keyPrefix + Path.SEPARATOR + relativeFilePath : Path.SEPARATOR + relativeFilePath;    fileValue.set(value.getBytes(), 0, value.getBytes().length);    context.write(new Text(filename), fileValue);}
public void mahout_f483_1(MailOptions options) throws IOException
{    try (ChunkedWriter writer = new ChunkedWriter(getConf(), options.getChunkSize(), new Path(options.getOutputDir()))) {        MailProcessor processor = new MailProcessor(options, options.getPrefix(), writer);        if (options.getInput().isDirectory()) {            PrefixAdditionDirectoryWalker walker = new PrefixAdditionDirectoryWalker(processor, writer);            walker.walk(options.getInput());                    } else {            long start = System.currentTimeMillis();            long cnt = processor.parseMboxLineByLine(options.getInput());            long finish = System.currentTimeMillis();                    }    }}
public void mahout_f484_0(File startDirectory) throws IOException
{    super.walk(startDirectory, null);}
public long mahout_f485_0()
{    return messageCounts.getFirst();}
protected void mahout_f486_1(File current, int depth, Collection<Object> results) throws IOException
{    if (depth > 0) {                MailProcessor processor = processors.getFirst();        MailProcessor subDirProcessor = new MailProcessor(processor.getOptions(), processor.getPrefix() + File.separator + current.getName(), writer);        processors.push(subDirProcessor);        messageCounts.push(0L);    }}
protected File[] mahout_f487_0(File directory, int depth, File[] files) throws IOException
{    Arrays.sort(files, FILE_COMPARATOR);    return files;}
protected void mahout_f488_0(File current, int depth, Collection<Object> results) throws IOException
{    MailProcessor processor = processors.getFirst();    long currentDirMessageCount = messageCounts.pop();    try {        currentDirMessageCount += processor.parseMboxLineByLine(current);    } catch (IOException e) {        throw new IllegalStateException("Error processing " + current, e);    }    messageCounts.push(currentDirMessageCount);}
protected void mahout_f489_1(File current, int depth, Collection<Object> results) throws IOException
{    if (depth > 0) {        final long currentDirMessageCount = messageCounts.pop();                processors.pop();                long parentDirMessageCount = messageCounts.pop();        parentDirMessageCount += currentDirMessageCount;        messageCounts.push(parentDirMessageCount);    }}
public static void mahout_f490_0(String[] args) throws Exception
{    ToolRunner.run(new Configuration(), new SequenceFilesFromMailArchives(), args);}
public int mahout_f491_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption(DefaultOptionCreator.methodOption().create());    addOption(CHUNK_SIZE_OPTION[0], CHUNK_SIZE_OPTION[1], "The chunkSize in MegaBytes. Defaults to 64", "64");    addOption(KEY_PREFIX_OPTION[0], KEY_PREFIX_OPTION[1], "The prefix to be prepended to the key", "");    addOption(CHARSET_OPTION[0], CHARSET_OPTION[1], "The name of the character encoding of the input files. Default to UTF-8", "UTF-8");    addFlag(SUBJECT_OPTION[0], SUBJECT_OPTION[1], "Include the Mail subject as part of the text.  Default is false");    addFlag(TO_OPTION[0], TO_OPTION[1], "Include the to field in the text.  Default is false");    addFlag(FROM_OPTION[0], FROM_OPTION[1], "Include the from field in the text.  Default is false");    addFlag(REFERENCES_OPTION[0], REFERENCES_OPTION[1], "Include the references field in the text.  Default is false");    addFlag(BODY_OPTION[0], BODY_OPTION[1], "Include the body in the output.  Default is false");    addFlag(STRIP_QUOTED_OPTION[0], STRIP_QUOTED_OPTION[1], "Strip (remove) quoted email text in the body.  Default is false");    addOption(QUOTED_REGEX_OPTION[0], QUOTED_REGEX_OPTION[1], "Specify the regex that identifies quoted text.  " + "Default is to look for > or | at the beginning of the line.");    addOption(SEPARATOR_OPTION[0], SEPARATOR_OPTION[1], "The separator to use between metadata items (to, from, etc.).  Default is \\n", "\n");    addOption(BODY_SEPARATOR_OPTION[0], BODY_SEPARATOR_OPTION[1], "The separator to use between lines in the body.  Default is \\n.  " + "Useful to change if you wish to have the message be on one line", "\n");    addOption(DefaultOptionCreator.helpOption());    Map<String, List<String>> parsedArgs = parseArguments(args);    if (parsedArgs == null) {        return -1;    }    File input = getInputFile();    String outputDir = getOutputPath().toString();    int chunkSize = 64;    if (hasOption(CHUNK_SIZE_OPTION[0])) {        chunkSize = Integer.parseInt(getOption(CHUNK_SIZE_OPTION[0]));    }    String prefix = "";    if (hasOption(KEY_PREFIX_OPTION[0])) {        prefix = getOption(KEY_PREFIX_OPTION[0]);    }    Charset charset = Charset.forName(getOption(CHARSET_OPTION[0]));    MailOptions options = new MailOptions();    options.setInput(input);    options.setOutputDir(outputDir);    options.setPrefix(prefix);    options.setChunkSize(chunkSize);    options.setCharset(charset);    List<Pattern> patterns = new ArrayList<>(5);                Map<String, Integer> patternOrder = new HashMap<>();    int order = 0;    if (hasOption(FROM_OPTION[0])) {        patterns.add(MailProcessor.FROM_PREFIX);        patternOrder.put(MailOptions.FROM, order++);    }    if (hasOption(TO_OPTION[0])) {        patterns.add(MailProcessor.TO_PREFIX);        patternOrder.put(MailOptions.TO, order++);    }    if (hasOption(REFERENCES_OPTION[0])) {        patterns.add(MailProcessor.REFS_PREFIX);        patternOrder.put(MailOptions.REFS, order++);    }    if (hasOption(SUBJECT_OPTION[0])) {        patterns.add(MailProcessor.SUBJECT_PREFIX);        patternOrder.put(MailOptions.SUBJECT, order += 1);    }    options.setStripQuotedText(hasOption(STRIP_QUOTED_OPTION[0]));    options.setPatternsToMatch(patterns.toArray(new Pattern[patterns.size()]));    options.setPatternOrder(patternOrder);    options.setIncludeBody(hasOption(BODY_OPTION[0]));    if (hasOption(SEPARATOR_OPTION[0])) {        options.setSeparator(getOption(SEPARATOR_OPTION[0]));    } else {        options.setSeparator("\n");    }    if (hasOption(BODY_SEPARATOR_OPTION[0])) {        options.setBodySeparator(getOption(BODY_SEPARATOR_OPTION[0]));    }    if (hasOption(QUOTED_REGEX_OPTION[0])) {        options.setQuotedTextPattern(Pattern.compile(getOption(QUOTED_REGEX_OPTION[0])));    }    if (getOption(DefaultOptionCreator.METHOD_OPTION, DefaultOptionCreator.MAPREDUCE_METHOD).equals(DefaultOptionCreator.SEQUENTIAL_METHOD)) {        runSequential(options);    } else {        runMapReduce(getInputPath(), getOutputPath());    }    return 0;}
private int mahout_f492_1(MailOptions options) throws IOException, InterruptedException, NoSuchMethodException
{    long start = System.currentTimeMillis();    createSequenceFiles(options);    long finish = System.currentTimeMillis();        return 0;}
private int mahout_f493_0(Path input, Path output) throws IOException, InterruptedException, ClassNotFoundException
{    Job job = prepareJob(input, output, MultipleTextFileInputFormat.class, SequenceFilesFromMailArchivesMapper.class, Text.class, Text.class, SequenceFileOutputFormat.class, "SequentialFilesFromMailArchives");    Configuration jobConfig = job.getConfiguration();    if (hasOption(KEY_PREFIX_OPTION[0])) {        jobConfig.set(KEY_PREFIX_OPTION[1], getOption(KEY_PREFIX_OPTION[0]));    }    int chunkSize = 0;    if (hasOption(CHUNK_SIZE_OPTION[0])) {        chunkSize = Integer.parseInt(getOption(CHUNK_SIZE_OPTION[0]));        jobConfig.set(CHUNK_SIZE_OPTION[0], String.valueOf(chunkSize));    }    Charset charset;    if (hasOption(CHARSET_OPTION[0])) {        charset = Charset.forName(getOption(CHARSET_OPTION[0]));        jobConfig.set(CHARSET_OPTION[0], charset.displayName());    }    if (hasOption(FROM_OPTION[0])) {        jobConfig.set(FROM_OPTION[1], "true");    }    if (hasOption(TO_OPTION[0])) {        jobConfig.set(TO_OPTION[1], "true");    }    if (hasOption(REFERENCES_OPTION[0])) {        jobConfig.set(REFERENCES_OPTION[1], "true");    }    if (hasOption(SUBJECT_OPTION[0])) {        jobConfig.set(SUBJECT_OPTION[1], "true");    }    if (hasOption(QUOTED_REGEX_OPTION[0])) {        jobConfig.set(QUOTED_REGEX_OPTION[1], Pattern.compile(getOption(QUOTED_REGEX_OPTION[0])).toString());    }    if (hasOption(SEPARATOR_OPTION[0])) {        jobConfig.set(SEPARATOR_OPTION[1], getOption(SEPARATOR_OPTION[0]));    } else {        jobConfig.set(SEPARATOR_OPTION[1], "\n");    }    if (hasOption(BODY_OPTION[0])) {        jobConfig.set(BODY_OPTION[1], "true");    } else {        jobConfig.set(BODY_OPTION[1], "false");    }    if (hasOption(BODY_SEPARATOR_OPTION[0])) {        jobConfig.set(BODY_SEPARATOR_OPTION[1], getOption(BODY_SEPARATOR_OPTION[0]));    } else {        jobConfig.set(BODY_SEPARATOR_OPTION[1], "\n");    }    FileSystem fs = FileSystem.get(jobConfig);    FileStatus fsFileStatus = fs.getFileStatus(inputPath);    jobConfig.set(BASE_INPUT_PATH, inputPath.toString());    String inputDirList = HadoopUtil.buildDirList(fs, fsFileStatus);    FileInputFormat.setInputPaths(job, inputDirList);    long chunkSizeInBytes = chunkSize * 1024 * 1024;        FileInputFormat.setMaxInputSplitSize(job, chunkSizeInBytes);        jobConfig.set("mapreduce.job.max.split.locations", String.valueOf(MAX_JOB_SPLIT_LOCATIONS));    boolean succeeded = job.waitForCompletion(true);    if (!succeeded) {        return -1;    }    return 0;}
public void mahout_f494_0(Context context) throws IOException, InterruptedException
{    Configuration configuration = context.getConfiguration();        this.options = new MailOptions();    options.setPrefix(configuration.get(KEY_PREFIX_OPTION[1], ""));    if (!configuration.get(CHUNK_SIZE_OPTION[0], "").equals("")) {        options.setChunkSize(configuration.getInt(CHUNK_SIZE_OPTION[0], 64));    }    if (!configuration.get(CHARSET_OPTION[0], "").equals("")) {        Charset charset = Charset.forName(configuration.get(CHARSET_OPTION[0], "UTF-8"));        options.setCharset(charset);    } else {        Charset charset = Charset.forName("UTF-8");        options.setCharset(charset);    }    List<Pattern> patterns = Lists.newArrayListWithCapacity(5);                        Map<String, Integer> patternOrder = Maps.newHashMap();    int order = 0;    if (!configuration.get(FROM_OPTION[1], "").equals("")) {        patterns.add(MailProcessor.FROM_PREFIX);        patternOrder.put(MailOptions.FROM, order++);    }    if (!configuration.get(TO_OPTION[1], "").equals("")) {        patterns.add(MailProcessor.TO_PREFIX);        patternOrder.put(MailOptions.TO, order++);    }    if (!configuration.get(REFERENCES_OPTION[1], "").equals("")) {        patterns.add(MailProcessor.REFS_PREFIX);        patternOrder.put(MailOptions.REFS, order++);    }    if (!configuration.get(SUBJECT_OPTION[1], "").equals("")) {        patterns.add(MailProcessor.SUBJECT_PREFIX);        patternOrder.put(MailOptions.SUBJECT, order += 1);    }    options.setStripQuotedText(configuration.getBoolean(STRIP_QUOTED_OPTION[1], false));    options.setPatternsToMatch(patterns.toArray(new Pattern[patterns.size()]));    options.setPatternOrder(patternOrder);    options.setIncludeBody(configuration.getBoolean(BODY_OPTION[1], false));    options.setSeparator("\n");    if (!configuration.get(SEPARATOR_OPTION[1], "").equals("")) {        options.setSeparator(configuration.get(SEPARATOR_OPTION[1], ""));    }    if (!configuration.get(BODY_SEPARATOR_OPTION[1], "").equals("")) {        options.setBodySeparator(configuration.get(BODY_SEPARATOR_OPTION[1], ""));    }    if (!configuration.get(QUOTED_REGEX_OPTION[1], "").equals("")) {        options.setQuotedTextPattern(Pattern.compile(configuration.get(QUOTED_REGEX_OPTION[1], "")));    }}
public long mahout_f495_0(String filename, InputStream mailBoxInputStream, Context context) throws IOException, InterruptedException
{    long messageCount = 0;    try {        StringBuilder contents = new StringBuilder();        StringBuilder body = new StringBuilder();        Matcher messageIdMatcher = MESSAGE_ID_PREFIX.matcher("");        Matcher messageBoundaryMatcher = MESSAGE_START.matcher("");        String[] patternResults = new String[options.getPatternsToMatch().length];        Matcher[] matches = new Matcher[options.getPatternsToMatch().length];        for (int i = 0; i < matches.length; i++) {            matches[i] = options.getPatternsToMatch()[i].matcher("");        }        String messageId = null;        boolean inBody = false;        Pattern quotedTextPattern = options.getQuotedTextPattern();        for (String nextLine : new FileLineIterable(mailBoxInputStream, options.getCharset(), false, filename)) {            if (!options.isStripQuotedText() || !quotedTextPattern.matcher(nextLine).find()) {                for (int i = 0; i < matches.length; i++) {                    Matcher matcher = matches[i];                    matcher.reset(nextLine);                    if (matcher.matches()) {                        patternResults[i] = matcher.group(1);                    }                }                                if (messageId != null) {                                        messageBoundaryMatcher.reset(nextLine);                    if (messageBoundaryMatcher.matches()) {                                                String key = generateKey(filename, options.getPrefix(), messageId);                                                                        writeContent(options.getSeparator(), contents, body, patternResults);                        this.outKey.set(key);                        this.outValue.set(contents.toString());                        context.write(this.outKey, this.outValue);                                                contents.setLength(0);                        body.setLength(0);                        messageId = null;                        inBody = false;                    } else {                        if (inBody && options.isIncludeBody()) {                            if (!nextLine.isEmpty()) {                                body.append(nextLine).append(options.getBodySeparator());                            }                        } else {                                                                                    inBody = nextLine.isEmpty();                        }                    }                } else {                    if (nextLine.length() > 14) {                        messageIdMatcher.reset(nextLine);                        if (messageIdMatcher.matches()) {                            messageId = messageIdMatcher.group(1);                            ++messageCount;                        }                    }                }            }        }                if (messageId != null) {            String key = generateKey(filename, options.getPrefix(), messageId);            writeContent(options.getSeparator(), contents, body, patternResults);            this.outKey.set(key);            this.outValue.set(contents.toString());            context.write(this.outKey, this.outValue);                        contents.setLength(0);        }    } catch (FileNotFoundException ignored) {    }    return messageCount;}
protected static String mahout_f496_0(String mboxFilename, String prefix, String messageId)
{    return Joiner.on(Path.SEPARATOR).join(Lists.newArrayList(prefix, mboxFilename, messageId).iterator());}
private static void mahout_f497_0(String separator, StringBuilder contents, CharSequence body, String[] matches)
{    String matchesString = Joiner.on(separator).useForNull("").join(Arrays.asList(matches).iterator());    contents.append(matchesString).append(separator).append(body);}
public void mahout_f498_0(IntWritable key, BytesWritable value, Context context) throws IOException, InterruptedException
{    Configuration configuration = context.getConfiguration();    Path filePath = ((CombineFileSplit) context.getInputSplit()).getPath(key.get());    String relativeFilePath = HadoopUtil.calcRelativeFilePath(configuration, filePath);    ByteArrayInputStream is = new ByteArrayInputStream(value.getBytes());    parseMailboxLineByLine(relativeFilePath, is, context);}
public int mahout_f499_0(String[] strings) throws Exception
{    Configuration originalConf = getConf();    Job job = prepareJob(new Path(originalConf.get("mapred.input.dir")), new Path(originalConf.get("mapred.output.dir")), SequenceFileInputFormat.class, SplitMap.class, Text.class, Text.class, Reducer.class, Text.class, Text.class, SequenceFileOutputFormat.class);    job.setNumReduceTasks(0);    boolean succeeded = job.waitForCompletion(true);    return succeeded ? 0 : -1;}
protected void mahout_f500_0(Text key, Text text, Context context) throws IOException, InterruptedException
{    Text outText = new Text();    int loc = 0;    while (loc >= 0 && loc < text.getLength()) {        int nextLoc = text.find("\n\n", loc + 1);        if (nextLoc > 0) {            outText.set(text.getBytes(), loc, nextLoc - loc);            context.write(key, outText);        }        loc = nextLoc;    }}
public static void mahout_f501_0(String[] args) throws Exception
{    ToolRunner.run(new TextParagraphSplittingJob(), args);}
public IntWritable mahout_f502_0()
{    return index;}
public BytesWritable mahout_f503_0()
{    return value;}
public float mahout_f504_0() throws IOException
{    return processed ? 1.0f : 0.0f;}
public void mahout_f505_0(InputSplit inputSplit, TaskAttemptContext taskAttemptContext) throws IOException, InterruptedException
{    if (!StringUtils.isBlank(fileFilterClassName) && !PrefixAdditionFilter.class.getName().equals(fileFilterClassName)) {        try {            pathFilter = (PathFilter) Class.forName(fileFilterClassName).newInstance();        } catch (ClassNotFoundException | InstantiationException | IllegalAccessException e) {            throw new IllegalStateException(e);        }    }}
public boolean mahout_f506_0() throws IOException
{    if (!processed) {        byte[] contents = new byte[(int) fileSplit.getLength()];        Path file = fileSplit.getPath();        FileSystem fs = file.getFileSystem(this.configuration);        if (!fs.isFile(file)) {            return false;        }        FileStatus[] fileStatuses;        if (pathFilter != null) {            fileStatuses = fs.listStatus(file, pathFilter);        } else {            fileStatuses = fs.listStatus(file);        }        if (fileStatuses.length == 1) {            try (FSDataInputStream in = fs.open(fileStatuses[0].getPath())) {                IOUtils.readFully(in, contents, 0, contents.length);                value.setCapacity(contents.length);                value.set(contents, 0, contents.length);            }            processed = true;            return true;        }    }    return false;}
public void mahout_f507_0() throws IOException
{}
protected TokenStreamComponents mahout_f508_0(String fieldName)
{    Tokenizer tokenizer = new WikipediaTokenizer();    TokenStream result = new StandardFilter(tokenizer);    result = new LowerCaseFilter(result);    result = new StopFilter(result, getStopwordSet());    return new TokenStreamComponents(tokenizer, result);}
public static void mahout_f509_1(String[] args) throws IOException, InterruptedException
{    DefaultOptionBuilder obuilder = new DefaultOptionBuilder();    ArgumentBuilder abuilder = new ArgumentBuilder();    GroupBuilder gbuilder = new GroupBuilder();    Option dirInputPathOpt = DefaultOptionCreator.inputOption().create();    Option dirOutputPathOpt = DefaultOptionCreator.outputOption().create();    Option categoriesOpt = obuilder.withLongName("categories").withRequired(true).withArgument(abuilder.withName("categories").withMinimum(1).withMaximum(1).create()).withDescription("Location of the categories file.  One entry per line. " + "Will be used to make a string match in Wikipedia Category field").withShortName("c").create();    Option exactMatchOpt = obuilder.withLongName("exactMatch").withDescription("If set, then the category name must exactly match the " + "entry in the categories file. Default is false").withShortName("e").create();    Option analyzerOpt = obuilder.withLongName("analyzer").withRequired(false).withArgument(abuilder.withName("analyzer").withMinimum(1).withMaximum(1).create()).withDescription("The analyzer to use, must have a no argument constructor").withShortName("a").create();    Option helpOpt = DefaultOptionCreator.helpOption();    Group group = gbuilder.withName("Options").withOption(categoriesOpt).withOption(dirInputPathOpt).withOption(dirOutputPathOpt).withOption(exactMatchOpt).withOption(analyzerOpt).withOption(helpOpt).create();    Parser parser = new Parser();    parser.setGroup(group);    try {        CommandLine cmdLine = parser.parse(args);        if (cmdLine.hasOption(helpOpt)) {            CommandLineUtil.printHelp(group);            return;        }        String inputPath = (String) cmdLine.getValue(dirInputPathOpt);        String outputPath = (String) cmdLine.getValue(dirOutputPathOpt);        String catFile = (String) cmdLine.getValue(categoriesOpt);        Class<? extends Analyzer> analyzerClass = WikipediaAnalyzer.class;        if (cmdLine.hasOption(analyzerOpt)) {            String className = cmdLine.getValue(analyzerOpt).toString();            analyzerClass = Class.forName(className).asSubclass(Analyzer.class);                                    ClassUtils.instantiateAs(analyzerClass, Analyzer.class);        }        runJob(inputPath, outputPath, catFile, cmdLine.hasOption(exactMatchOpt), analyzerClass);    } catch (OptionException e) {                CommandLineUtil.printHelp(group);    } catch (ClassNotFoundException e) {                CommandLineUtil.printHelp(group);    }}
public static void mahout_f510_1(String input, String output, String catFile, boolean exactMatchOnly, Class<? extends Analyzer> analyzerClass) throws IOException, InterruptedException, ClassNotFoundException
{    Configuration conf = new Configuration();    conf.set("key.value.separator.in.input.line", " ");    conf.set("xmlinput.start", "<page>");    conf.set("xmlinput.end", "</page>");    conf.setBoolean("exact.match.only", exactMatchOnly);    conf.set("analyzer.class", analyzerClass.getName());    conf.set("io.serializations", "org.apache.hadoop.io.serializer.JavaSerialization," + "org.apache.hadoop.io.serializer.WritableSerialization");            Set<String> categories = new HashSet<>();    for (String line : new FileLineIterable(new File(catFile))) {        categories.add(line.trim().toLowerCase(Locale.ENGLISH));    }    Stringifier<Set<String>> setStringifier = new DefaultStringifier<>(conf, GenericsUtil.getClass(categories));    String categoriesStr = setStringifier.toString(categories);    conf.set("wikipedia.categories", categoriesStr);    Job job = new Job(conf);        job.setJarByClass(WikipediaDatasetCreatorDriver.class);    job.setOutputKeyClass(Text.class);    job.setOutputValueClass(Text.class);    job.setMapperClass(WikipediaDatasetCreatorMapper.class);        job.setInputFormatClass(XmlInputFormat.class);    job.setReducerClass(WikipediaDatasetCreatorReducer.class);    job.setOutputFormatClass(TextOutputFormat.class);    FileInputFormat.setInputPaths(job, new Path(input));    Path outPath = new Path(output);    FileOutputFormat.setOutputPath(job, outPath);    HadoopUtil.delete(conf, outPath);    boolean succeeded = job.waitForCompletion(true);    if (!succeeded) {        throw new IllegalStateException("Job failed!");    }}
protected void mahout_f511_0(LongWritable key, Text value, Context context) throws IOException, InterruptedException
{    String document = value.toString();    document = StringEscapeUtils.unescapeHtml4(CLOSE_TEXT_TAG_PATTERN.matcher(OPEN_TEXT_TAG_PATTERN.matcher(document).replaceFirst("")).replaceAll(""));    String catMatch = findMatchingCategory(document);    if (!"Unknown".equals(catMatch)) {        StringBuilder contents = new StringBuilder(1000);        TokenStream stream = analyzer.tokenStream(catMatch, new StringReader(document));        CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);        stream.reset();        while (stream.incrementToken()) {            contents.append(termAtt.buffer(), 0, termAtt.length()).append(' ');        }        context.write(new Text(SPACE_NON_ALPHA_PATTERN.matcher(catMatch).replaceAll("_")), new Text(contents.toString()));        stream.end();        Closeables.close(stream, true);    }}
protected void mahout_f512_1(Context context) throws IOException, InterruptedException
{    super.setup(context);    Configuration conf = context.getConfiguration();    if (inputCategories == null) {        Set<String> newCategories = new HashSet<>();        DefaultStringifier<Set<String>> setStringifier = new DefaultStringifier<>(conf, GenericsUtil.getClass(newCategories));        String categoriesStr = conf.get("wikipedia.categories", setStringifier.toString(newCategories));        Set<String> inputCategoriesSet = setStringifier.fromString(categoriesStr);        inputCategories = new ArrayList<>(inputCategoriesSet);        inputCategoryPatterns = new ArrayList<>(inputCategories.size());        for (String inputCategory : inputCategories) {            inputCategoryPatterns.add(Pattern.compile(".*\\b" + inputCategory + "\\b.*"));        }    }    exactMatchOnly = conf.getBoolean("exact.match.only", false);    if (analyzer == null) {        String analyzerStr = conf.get("analyzer.class", WikipediaAnalyzer.class.getName());        analyzer = ClassUtils.instantiateAs(analyzerStr, Analyzer.class);    }    }
private String mahout_f513_0(String document)
{    int startIndex = 0;    int categoryIndex;    while ((categoryIndex = document.indexOf("[[Category:", startIndex)) != -1) {        categoryIndex += 11;        int endIndex = document.indexOf("]]", categoryIndex);        if (endIndex >= document.length() || endIndex < 0) {            break;        }        String category = document.substring(categoryIndex, endIndex).toLowerCase(Locale.ENGLISH).trim();                if (exactMatchOnly && inputCategories.contains(category)) {            return category;        }        if (!exactMatchOnly) {            for (int i = 0; i < inputCategories.size(); i++) {                String inputCategory = inputCategories.get(i);                Pattern inputCategoryPattern = inputCategoryPatterns.get(i);                if (inputCategoryPattern.matcher(category).matches()) {                                        return inputCategory;                }            }        }        startIndex = endIndex;    }    return "Unknown";}
protected void mahout_f514_0(Text key, Iterable<Text> values, Context context) throws IOException, InterruptedException
{        for (Text value : values) {        context.write(key, value);    }}
protected void mahout_f515_0(LongWritable key, Text value, Context context) throws IOException, InterruptedException
{    String content = value.toString();    if (content.contains(REDIRECT)) {        return;    }    String document;    String title;    try {        document = getDocument(content);        title = getTitle(content);    } catch (RuntimeException e) {                return;    }    String catMatch = findMatchingCategory(document);    if (!all) {        if ("Unknown".equals(catMatch)) {            return;        }    }    document = StringEscapeUtils.unescapeHtml4(document);    if (removeLabels) {        document = removeCategoriesFromText(document);                if (document == null) {            return;        }    }        String category = "/" + catMatch.toLowerCase(Locale.ENGLISH) + "/" + SPACE_NON_ALPHA_PATTERN.matcher(title).replaceAll("_");    context.write(new Text(category), new Text(document));}
protected void mahout_f516_1(Context context) throws IOException, InterruptedException
{    super.setup(context);    Configuration conf = context.getConfiguration();    Set<String> newCategories = new HashSet<>();    DefaultStringifier<Set<String>> setStringifier = new DefaultStringifier<>(conf, GenericsUtil.getClass(newCategories));    String categoriesStr = conf.get("wikipedia.categories");    inputCategories = setStringifier.fromString(categoriesStr);    exactMatchOnly = conf.getBoolean("exact.match.only", false);    all = conf.getBoolean("all.files", false);    removeLabels = conf.getBoolean("remove.labels", false);    }
private static String mahout_f517_0(String xml)
{    int start = xml.indexOf(START_DOC) + START_DOC.length();    int end = xml.indexOf(END_DOC, start);    return xml.substring(start, end);}
private static String mahout_f518_0(CharSequence xml)
{    Matcher m = TITLE.matcher(xml);    return m.find() ? m.group(1) : "";}
private String mahout_f519_0(String document)
{    int startIndex = 0;    int categoryIndex;    while ((categoryIndex = document.indexOf("[[Category:", startIndex)) != -1) {        categoryIndex += 11;        int endIndex = document.indexOf("]]", categoryIndex);        if (endIndex >= document.length() || endIndex < 0) {            break;        }        String category = document.substring(categoryIndex, endIndex).toLowerCase(Locale.ENGLISH).trim();        if (exactMatchOnly && inputCategories.contains(category)) {            return category.toLowerCase(Locale.ENGLISH);        }        if (!exactMatchOnly) {            for (String inputCategory : inputCategories) {                if (category.contains(inputCategory)) {                                        return inputCategory.toLowerCase(Locale.ENGLISH);                }            }        }        startIndex = endIndex;    }    return "Unknown";}
private String mahout_f520_0(String document)
{    int startIndex = 0;    int categoryIndex;    try {        while ((categoryIndex = document.indexOf("[[Category:", startIndex)) != -1) {            int endIndex = document.indexOf("]]", categoryIndex);            if (endIndex >= document.length() || endIndex < 0) {                break;            }            document = document.replace(document.substring(categoryIndex, endIndex + 2), "");            if (categoryIndex < document.length()) {                startIndex = categoryIndex;            } else {                break;            }        }    } catch (StringIndexOutOfBoundsException e) {        return null;    }    return document;}
public static void mahout_f521_1(String[] args) throws IOException
{    DefaultOptionBuilder obuilder = new DefaultOptionBuilder();    ArgumentBuilder abuilder = new ArgumentBuilder();    GroupBuilder gbuilder = new GroupBuilder();    Option dumpFileOpt = obuilder.withLongName("dumpFile").withRequired(true).withArgument(abuilder.withName("dumpFile").withMinimum(1).withMaximum(1).create()).withDescription("The path to the wikipedia dump file (.bz2 or uncompressed)").withShortName("d").create();    Option outputDirOpt = obuilder.withLongName("outputDir").withRequired(true).withArgument(abuilder.withName("outputDir").withMinimum(1).withMaximum(1).create()).withDescription("The output directory to place the splits in:\n" + "local files:\n\t/var/data/wikipedia-xml-chunks or\n\tfile:///var/data/wikipedia-xml-chunks\n" + "Hadoop DFS:\n\thdfs://wikipedia-xml-chunks\n" + "AWS S3 (blocks):\n\ts3://bucket-name/wikipedia-xml-chunks\n" + "AWS S3 (native files):\n\ts3n://bucket-name/wikipedia-xml-chunks\n").withShortName("o").create();    Option s3IdOpt = obuilder.withLongName("s3ID").withRequired(false).withArgument(abuilder.withName("s3Id").withMinimum(1).withMaximum(1).create()).withDescription("Amazon S3 ID key").withShortName("i").create();    Option s3SecretOpt = obuilder.withLongName("s3Secret").withRequired(false).withArgument(abuilder.withName("s3Secret").withMinimum(1).withMaximum(1).create()).withDescription("Amazon S3 secret key").withShortName("s").create();    Option chunkSizeOpt = obuilder.withLongName("chunkSize").withRequired(true).withArgument(abuilder.withName("chunkSize").withMinimum(1).withMaximum(1).create()).withDescription("The Size of the chunk, in megabytes").withShortName("c").create();    Option numChunksOpt = obuilder.withLongName("numChunks").withRequired(false).withArgument(abuilder.withName("numChunks").withMinimum(1).withMaximum(1).create()).withDescription("The maximum number of chunks to create.  If specified, program will only create a subset of the chunks").withShortName("n").create();    Group group = gbuilder.withName("Options").withOption(dumpFileOpt).withOption(outputDirOpt).withOption(chunkSizeOpt).withOption(numChunksOpt).withOption(s3IdOpt).withOption(s3SecretOpt).create();    Parser parser = new Parser();    parser.setGroup(group);    CommandLine cmdLine;    try {        cmdLine = parser.parse(args);    } catch (OptionException e) {                CommandLineUtil.printHelp(group);        return;    }    Configuration conf = new Configuration();    String dumpFilePath = (String) cmdLine.getValue(dumpFileOpt);    String outputDirPath = (String) cmdLine.getValue(outputDirOpt);    if (cmdLine.hasOption(s3IdOpt)) {        String id = (String) cmdLine.getValue(s3IdOpt);        conf.set("fs.s3n.awsAccessKeyId", id);        conf.set("fs.s3.awsAccessKeyId", id);    }    if (cmdLine.hasOption(s3SecretOpt)) {        String secret = (String) cmdLine.getValue(s3SecretOpt);        conf.set("fs.s3n.awsSecretAccessKey", secret);        conf.set("fs.s3.awsSecretAccessKey", secret);    }        conf.set("fs.file.impl", "org.apache.hadoop.fs.RawLocalFileSystem");    FileSystem fs = FileSystem.get(URI.create(outputDirPath), conf);    int chunkSize = 1024 * 1024 * Integer.parseInt((String) cmdLine.getValue(chunkSizeOpt));    int numChunks = Integer.MAX_VALUE;    if (cmdLine.hasOption(numChunksOpt)) {        numChunks = Integer.parseInt((String) cmdLine.getValue(numChunksOpt));    }    String header = "<mediawiki xmlns=\"http://www.mediawiki.org/xml/export-0.3/\" " + "xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" " + "xsi:schemaLocation=\"http://www.mediawiki.org/xml/export-0.3/ " + "http://www.mediawiki.org/xml/export-0.3.xsd\" " + "version=\"0.3\" " + "xml:lang=\"en\">\n" + "  <siteinfo>\n" + "<sitename>Wikipedia</sitename>\n" + "    <base>http://en.wikipedia.org/wiki/Main_Page</base>\n" + "    <generator>MediaWiki 1.13alpha</generator>\n" + "    <case>first-letter</case>\n" + "    <namespaces>\n" + "      <namespace key=\"-2\">Media</namespace>\n" + "      <namespace key=\"-1\">Special</namespace>\n" + "      <namespace key=\"0\" />\n" + "      <namespace key=\"1\">Talk</namespace>\n" + "      <namespace key=\"2\">User</namespace>\n" + "      <namespace key=\"3\">User talk</namespace>\n" + "      <namespace key=\"4\">Wikipedia</namespace>\n" + "      <namespace key=\"5\">Wikipedia talk</namespace>\n" + "      <namespace key=\"6\">Image</namespace>\n" + "      <namespace key=\"7\">Image talk</namespace>\n" + "      <namespace key=\"8\">MediaWiki</namespace>\n" + "      <namespace key=\"9\">MediaWiki talk</namespace>\n" + "      <namespace key=\"10\">Template</namespace>\n" + "      <namespace key=\"11\">Template talk</namespace>\n" + "      <namespace key=\"12\">Help</namespace>\n" + "      <namespace key=\"13\">Help talk</namespace>\n" + "      <namespace key=\"14\">Category</namespace>\n" + "      <namespace key=\"15\">Category talk</namespace>\n" + "      <namespace key=\"100\">Portal</namespace>\n" + "      <namespace key=\"101\">Portal talk</namespace>\n" + "    </namespaces>\n" + "  </siteinfo>\n";    StringBuilder content = new StringBuilder();    content.append(header);    NumberFormat decimalFormatter = new DecimalFormat("0000");    File dumpFile = new File(dumpFilePath);        if (!dumpFile.exists()) {                return;    }    FileLineIterator it;    if (dumpFilePath.endsWith(".bz2")) {                CompressionCodec codec = new BZip2Codec();        it = new FileLineIterator(codec.createInputStream(new FileInputStream(dumpFile)));    } else {                it = new FileLineIterator(dumpFile);    }    int fileNumber = 0;    while (it.hasNext()) {        String thisLine = it.next();        if (thisLine.trim().startsWith("<page>")) {            boolean end = false;            while (!thisLine.trim().startsWith("</page>")) {                content.append(thisLine).append('\n');                if (it.hasNext()) {                    thisLine = it.next();                } else {                    end = true;                    break;                }            }            content.append(thisLine).append('\n');            if (content.length() > chunkSize || end) {                content.append("</mediawiki>");                fileNumber++;                String filename = outputDirPath + "/chunk-" + decimalFormatter.format(fileNumber) + ".xml";                try (BufferedWriter chunkWriter = new BufferedWriter(new OutputStreamWriter(fs.create(new Path(filename)), "UTF-8"))) {                    chunkWriter.write(content.toString(), 0, content.length());                }                if (fileNumber >= numChunks) {                    break;                }                content = new StringBuilder();                content.append(header);            }        }    }}
public RecordReader<LongWritable, Text> mahout_f522_1(InputSplit split, TaskAttemptContext context)
{    try {        return new XmlRecordReader((FileSplit) split, context.getConfiguration());    } catch (IOException ioe) {                return null;    }}
private boolean mahout_f523_0(LongWritable key, Text value) throws IOException
{    if (fsin.getPos() < end && readUntilMatch(startTag, false)) {        try {            buffer.write(startTag);            if (readUntilMatch(endTag, true)) {                key.set(fsin.getPos());                value.set(buffer.getData(), 0, buffer.getLength());                return true;            }        } finally {            buffer.reset();        }    }    return false;}
public void mahout_f524_0() throws IOException
{    Closeables.close(fsin, true);}
public float mahout_f525_0() throws IOException
{    return (fsin.getPos() - start) / (float) (end - start);}
private boolean mahout_f526_0(byte[] match, boolean withinBlock) throws IOException
{    int i = 0;    while (true) {        int b = fsin.read();                if (b == -1) {            return false;        }                if (withinBlock) {            buffer.write(b);        }                if (b == match[i]) {            i++;            if (i >= match.length) {                return true;            }        } else {            i = 0;        }                if (!withinBlock && i == 0 && fsin.getPos() >= end) {            return false;        }    }}
public LongWritable mahout_f527_0() throws IOException, InterruptedException
{    return currentKey;}
public Text mahout_f528_0() throws IOException, InterruptedException
{    return currentValue;}
public void mahout_f529_0(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException
{}
public boolean mahout_f530_0() throws IOException, InterruptedException
{    currentKey = new LongWritable();    currentValue = new Text();    return next(currentKey, currentValue);}
public static void mahout_f531_1(String[] args) throws IOException
{    DefaultOptionBuilder obuilder = new DefaultOptionBuilder();    ArgumentBuilder abuilder = new ArgumentBuilder();    GroupBuilder gbuilder = new GroupBuilder();    Option dirInputPathOpt = DefaultOptionCreator.inputOption().create();    Option dirOutputPathOpt = DefaultOptionCreator.outputOption().create();    Option categoriesOpt = obuilder.withLongName("categories").withArgument(abuilder.withName("categories").withMinimum(1).withMaximum(1).create()).withDescription("Location of the categories file.  One entry per line. " + "Will be used to make a string match in Wikipedia Category field").withShortName("c").create();    Option exactMatchOpt = obuilder.withLongName("exactMatch").withDescription("If set, then the category name must exactly match the " + "entry in the categories file. Default is false").withShortName("e").create();    Option allOpt = obuilder.withLongName("all").withDescription("If set, Select all files. Default is false").withShortName("all").create();    Option removeLabelOpt = obuilder.withLongName("removeLabels").withDescription("If set, remove [[Category:labels]] from document text after extracting label." + "Default is false").withShortName("rl").create();    Option helpOpt = DefaultOptionCreator.helpOption();    Group group = gbuilder.withName("Options").withOption(categoriesOpt).withOption(dirInputPathOpt).withOption(dirOutputPathOpt).withOption(exactMatchOpt).withOption(allOpt).withOption(helpOpt).withOption(removeLabelOpt).create();    Parser parser = new Parser();    parser.setGroup(group);    parser.setHelpOption(helpOpt);    try {        CommandLine cmdLine = parser.parse(args);        if (cmdLine.hasOption(helpOpt)) {            CommandLineUtil.printHelp(group);            return;        }        String inputPath = (String) cmdLine.getValue(dirInputPathOpt);        String outputPath = (String) cmdLine.getValue(dirOutputPathOpt);        String catFile = "";        if (cmdLine.hasOption(categoriesOpt)) {            catFile = (String) cmdLine.getValue(categoriesOpt);        }        boolean all = false;        if (cmdLine.hasOption(allOpt)) {            all = true;        }        boolean removeLabels = false;        if (cmdLine.hasOption(removeLabelOpt)) {            removeLabels = true;        }        runJob(inputPath, outputPath, catFile, cmdLine.hasOption(exactMatchOpt), all, removeLabels);    } catch (OptionException | InterruptedException | ClassNotFoundException e) {                CommandLineUtil.printHelp(group);    }}
public static void mahout_f532_1(String input, String output, String catFile, boolean exactMatchOnly, boolean all, boolean removeLabels) throws IOException, InterruptedException, ClassNotFoundException
{    Configuration conf = new Configuration();    conf.set("xmlinput.start", "<page>");    conf.set("xmlinput.end", "</page>");    conf.setBoolean("exact.match.only", exactMatchOnly);    conf.setBoolean("all.files", all);    conf.setBoolean("remove.labels", removeLabels);    conf.set("io.serializations", "org.apache.hadoop.io.serializer.JavaSerialization," + "org.apache.hadoop.io.serializer.WritableSerialization");    Set<String> categories = new HashSet<>();    if (!catFile.isEmpty()) {        for (String line : new FileLineIterable(new File(catFile))) {            categories.add(line.trim().toLowerCase(Locale.ENGLISH));        }    }    Stringifier<Set<String>> setStringifier = new DefaultStringifier<>(conf, GenericsUtil.getClass(categories));    String categoriesStr = setStringifier.toString(categories);    conf.set("wikipedia.categories", categoriesStr);    Job job = new Job(conf);        job.setOutputKeyClass(Text.class);    job.setOutputValueClass(Text.class);    FileInputFormat.setInputPaths(job, new Path(input));    Path outPath = new Path(output);    FileOutputFormat.setOutputPath(job, outPath);    job.setMapperClass(WikipediaMapper.class);    job.setInputFormatClass(XmlInputFormat.class);    job.setReducerClass(Reducer.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    job.setJarByClass(WikipediaToSequenceFile.class);    /*     * conf.set("mapred.compress.map.output", "true"); conf.set("mapred.map.output.compression.type",     * "BLOCK"); conf.set("mapred.output.compress", "true"); conf.set("mapred.output.compression.type",     * "BLOCK"); conf.set("mapred.output.compression.codec", "org.apache.hadoop.io.compress.GzipCodec");     */    HadoopUtil.delete(conf, outPath);    boolean succeeded = job.waitForCompletion(true);    if (!succeeded) {        throw new IllegalStateException("Job failed!");    }}
 static int mahout_f533_0(double value, double base)
{    double scale = value / base;        int i = 0;    while (i < BUMPS.length - 1 && BUMPS[i + 1] <= scale) {        i++;    }    return BUMPS[i];}
 static long mahout_f534_0(double value)
{    return Math.max(1, (long) Math.pow(10, (int) Math.floor(Math.log10(value))));}
public long mahout_f535_0()
{    long delta;    if (counter >= 10) {        long base = base(counter / 4.0);        int scale = scale(counter / 4.0, base);        delta = base * scale;    } else {        delta = 1;    }    counter += delta;    return counter;}
protected Writer mahout_f536_0()
{    return writer;}
protected Map<Integer, List<WeightedPropertyVectorWritable>> mahout_f537_0()
{    return clusterIdToPoints;}
public static String mahout_f538_0(Vector vector, String[] dictionary, int numTerms)
{    StringBuilder sb = new StringBuilder(100);    for (Pair<String, Double> item : getTopPairs(vector, dictionary, numTerms)) {        String term = item.getFirst();        sb.append("\n\t\t");        sb.append(StringUtils.rightPad(term, 40));        sb.append("=>");        sb.append(StringUtils.leftPad(item.getSecond().toString(), 20));    }    return sb.toString();}
public static String mahout_f539_0(Vector vector, String[] dictionary, int numTerms)
{    StringBuilder sb = new StringBuilder(100);    for (Pair<String, Double> item : getTopPairs(vector, dictionary, numTerms)) {        String term = item.getFirst();        sb.append(term).append('_');    }    sb.deleteCharAt(sb.length() - 1);    return sb.toString();}
public long mahout_f540_0(Iterable<ClusterWritable> iterable) throws IOException
{    return write(iterable, Long.MAX_VALUE);}
public void mahout_f541_0() throws IOException
{    writer.close();}
public long mahout_f542_0(Iterable<ClusterWritable> iterable, long maxDocs) throws IOException
{    long result = 0;    Iterator<ClusterWritable> iterator = iterable.iterator();    while (result < maxDocs && iterator.hasNext()) {        write(iterator.next());        result++;    }    return result;}
private static Collection<Pair<String, Double>> mahout_f543_1(Vector vector, String[] dictionary, int numTerms)
{    List<TermIndexWeight> vectorTerms = Lists.newArrayList();    for (Vector.Element elt : vector.nonZeroes()) {        vectorTerms.add(new TermIndexWeight(elt.index(), elt.get()));    }        Collections.sort(vectorTerms, new Comparator<TermIndexWeight>() {        @Override        public int compare(TermIndexWeight one, TermIndexWeight two) {            return Double.compare(two.weight, one.weight);        }    });    Collection<Pair<String, Double>> topTerms = Lists.newLinkedList();    for (int i = 0; i < vectorTerms.size() && i < numTerms; i++) {        int index = vectorTerms.get(i).index;        String dictTerm = dictionary[index];        if (dictTerm == null) {                        continue;        }        topTerms.add(new Pair<>(dictTerm, vectorTerms.get(i).weight));    }    return topTerms;}
public int mahout_f544_0(TermIndexWeight one, TermIndexWeight two)
{    return Double.compare(two.weight, one.weight);}
public static void mahout_f545_0(String[] args) throws Exception
{    new ClusterDumper().run(args);}
public int mahout_f546_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption(OUTPUT_FORMAT_OPT, "of", "The optional output format for the results.  Options: TEXT, CSV, JSON or GRAPH_ML", "TEXT");    addOption(SUBSTRING_OPTION, "b", "The number of chars of the asFormatString() to print");    addOption(NUM_WORDS_OPTION, "n", "The number of top terms to print");    addOption(POINTS_DIR_OPTION, "p", "The directory containing points sequence files mapping input vectors to their cluster.  " + "If specified, then the program will output the points associated with a cluster");    addOption(SAMPLE_POINTS, "sp", "Specifies the maximum number of points to include _per_ cluster.  The default " + "is to include all points");    addOption(DICTIONARY_OPTION, "d", "The dictionary file");    addOption(DICTIONARY_TYPE_OPTION, "dt", "The dictionary file type (text|sequencefile)", "text");    addOption(buildOption(EVALUATE_CLUSTERS, "e", "Run ClusterEvaluator and CDbwEvaluator over the input.  " + "The output will be appended to the rest of the output at the end.", false, false, null));    addOption(DefaultOptionCreator.distanceMeasureOption().create());        if (parseArguments(args, false, true) == null) {        return -1;    }    seqFileDir = getInputPath();    if (hasOption(POINTS_DIR_OPTION)) {        pointsDir = new Path(getOption(POINTS_DIR_OPTION));    }    outputFile = getOutputFile();    if (hasOption(SUBSTRING_OPTION)) {        int sub = Integer.parseInt(getOption(SUBSTRING_OPTION));        if (sub >= 0) {            subString = sub;        }    }    termDictionary = getOption(DICTIONARY_OPTION);    dictionaryFormat = getOption(DICTIONARY_TYPE_OPTION);    if (hasOption(NUM_WORDS_OPTION)) {        numTopFeatures = Integer.parseInt(getOption(NUM_WORDS_OPTION));    }    if (hasOption(OUTPUT_FORMAT_OPT)) {        outputFormat = OUTPUT_FORMAT.valueOf(getOption(OUTPUT_FORMAT_OPT));    }    if (hasOption(SAMPLE_POINTS)) {        maxPointsPerCluster = Long.parseLong(getOption(SAMPLE_POINTS));    } else {        maxPointsPerCluster = Long.MAX_VALUE;    }    runEvaluation = hasOption(EVALUATE_CLUSTERS);    String distanceMeasureClass = getOption(DefaultOptionCreator.DISTANCE_MEASURE_OPTION);    measure = ClassUtils.instantiateAs(distanceMeasureClass, DistanceMeasure.class);    init();    printClusters(null);    return 0;}
public void mahout_f547_1(String[] dictionary) throws Exception
{    Configuration conf = new Configuration();    if (this.termDictionary != null) {        if ("text".equals(dictionaryFormat)) {            dictionary = VectorHelper.loadTermDictionary(new File(this.termDictionary));        } else if ("sequencefile".equals(dictionaryFormat)) {            dictionary = VectorHelper.loadTermDictionary(conf, this.termDictionary);        } else {            throw new IllegalArgumentException("Invalid dictionary format");        }    }    Writer writer;    boolean shouldClose;    if (this.outputFile == null) {        shouldClose = false;        writer = new OutputStreamWriter(System.out, Charsets.UTF_8);    } else {        shouldClose = true;        if (outputFile.getName().startsWith("s3n://")) {            Path p = outputPath;            FileSystem fs = FileSystem.get(p.toUri(), conf);            writer = new OutputStreamWriter(fs.create(p), Charsets.UTF_8);        } else {            Files.createParentDirs(outputFile);            writer = Files.newWriter(this.outputFile, Charsets.UTF_8);        }    }    ClusterWriter clusterWriter = createClusterWriter(writer, dictionary);    try {        long numWritten = clusterWriter.write(new SequenceFileDirValueIterable<ClusterWritable>(new Path(seqFileDir, "part-*"), PathType.GLOB, conf));        writer.flush();        if (runEvaluation) {            HadoopUtil.delete(conf, new Path("tmp/representative"));            int numIters = 5;            RepresentativePointsDriver.main(new String[] { "--input", seqFileDir.toString(), "--output", "tmp/representative", "--clusteredPoints", pointsDir.toString(), "--distanceMeasure", measure.getClass().getName(), "--maxIter", String.valueOf(numIters) });            conf.set(RepresentativePointsDriver.DISTANCE_MEASURE_KEY, measure.getClass().getName());            conf.set(RepresentativePointsDriver.STATE_IN_KEY, "tmp/representative/representativePoints-" + numIters);            ClusterEvaluator ce = new ClusterEvaluator(conf, seqFileDir);            writer.append("\n");            writer.append("Inter-Cluster Density: ").append(String.valueOf(ce.interClusterDensity())).append("\n");            writer.append("Intra-Cluster Density: ").append(String.valueOf(ce.intraClusterDensity())).append("\n");            CDbwEvaluator cdbw = new CDbwEvaluator(conf, seqFileDir);            writer.append("CDbw Inter-Cluster Density: ").append(String.valueOf(cdbw.interClusterDensity())).append("\n");            writer.append("CDbw Intra-Cluster Density: ").append(String.valueOf(cdbw.intraClusterDensity())).append("\n");            writer.append("CDbw Separation: ").append(String.valueOf(cdbw.separation())).append("\n");            writer.flush();        }            } finally {        if (shouldClose) {            Closeables.close(clusterWriter, false);        } else {            if (clusterWriter instanceof GraphMLClusterWriter) {                clusterWriter.close();            }        }    }}
 ClusterWriter mahout_f548_0(Writer writer, String[] dictionary) throws IOException
{    ClusterWriter result;    switch(outputFormat) {        case TEXT:            result = new ClusterDumperWriter(writer, clusterIdToPoints, measure, numTopFeatures, dictionary, subString);            break;        case CSV:            result = new CSVClusterWriter(writer, clusterIdToPoints, measure);            break;        case GRAPH_ML:            result = new GraphMLClusterWriter(writer, clusterIdToPoints, measure, numTopFeatures, dictionary, subString);            break;        case JSON:            result = new JsonClusterWriter(writer, clusterIdToPoints, measure, numTopFeatures, dictionary);            break;        default:            throw new IllegalStateException("Unknown outputformat: " + outputFormat);    }    return result;}
public void mahout_f549_0(OUTPUT_FORMAT of)
{    outputFormat = of;}
private void mahout_f550_0()
{    if (this.pointsDir != null) {        Configuration conf = new Configuration();                clusterIdToPoints = readPoints(this.pointsDir, maxPointsPerCluster, conf);    } else {        clusterIdToPoints = Collections.emptyMap();    }}
public int mahout_f551_0()
{    return subString;}
public void mahout_f552_0(int subString)
{    this.subString = subString;}
public Map<Integer, List<WeightedPropertyVectorWritable>> mahout_f553_0()
{    return clusterIdToPoints;}
public String mahout_f554_0()
{    return termDictionary;}
public void mahout_f555_0(String termDictionary, String dictionaryType)
{    this.termDictionary = termDictionary;    this.dictionaryFormat = dictionaryType;}
public void mahout_f556_0(int num)
{    this.numTopFeatures = num;}
public int mahout_f557_0()
{    return this.numTopFeatures;}
public long mahout_f558_0()
{    return maxPointsPerCluster;}
public void mahout_f559_0(long maxPointsPerCluster)
{    this.maxPointsPerCluster = maxPointsPerCluster;}
public static Map<Integer, List<WeightedPropertyVectorWritable>> mahout_f560_0(Path pointsPathDir, long maxPointsPerCluster, Configuration conf)
{    Map<Integer, List<WeightedPropertyVectorWritable>> result = new TreeMap<>();    for (Pair<IntWritable, WeightedPropertyVectorWritable> record : new SequenceFileDirIterable<IntWritable, WeightedPropertyVectorWritable>(pointsPathDir, PathType.LIST, PathFilters.logsCRCFilter(), conf)) {                                int keyValue = record.getFirst().get();        List<WeightedPropertyVectorWritable> pointList = result.get(keyValue);        if (pointList == null) {            pointList = new ArrayList<>();            result.put(keyValue, pointList);        }        if (pointList.size() < maxPointsPerCluster) {            pointList.add(record.getSecond());        }    }    return result;}
public void mahout_f561_0(ClusterWritable clusterWritable) throws IOException
{    Cluster cluster = clusterWritable.getValue();    String fmtStr = cluster.asFormatString(dictionary);    Writer writer = getWriter();    if (subString > 0 && fmtStr.length() > subString) {        writer.write(':');        writer.write(fmtStr, 0, Math.min(subString, fmtStr.length()));    } else {        writer.write(fmtStr);    }    writer.write('\n');    if (dictionary != null) {        String topTerms = getTopFeatures(clusterWritable.getValue().getCenter(), dictionary, numTopFeatures);        writer.write("\tTop Terms: ");        writer.write(topTerms);        writer.write('\n');    }    Map<Integer, List<WeightedPropertyVectorWritable>> clusterIdToPoints = getClusterIdToPoints();    List<WeightedPropertyVectorWritable> points = clusterIdToPoints.get(clusterWritable.getValue().getId());    if (points != null) {        writer.write("\tWeight : [props - optional]:  Point:\n\t");        for (Iterator<WeightedPropertyVectorWritable> iterator = points.iterator(); iterator.hasNext(); ) {            WeightedPropertyVectorWritable point = iterator.next();            writer.write(String.valueOf(point.getWeight()));            Map<Text, Text> map = point.getProperties();                        writer.write(" : [");            if (map != null) {                for (Map.Entry<Text, Text> entry : map.entrySet()) {                    writer.write(entry.getKey().toString());                    writer.write("=");                    writer.write(entry.getValue().toString());                }            }            writer.write("]");            writer.write(": ");            writer.write(AbstractCluster.formatVector(point.getVector(), dictionary));            if (iterator.hasNext()) {                writer.write("\n\t");            }        }        writer.write('\n');    }}
public void mahout_f562_0(ClusterWritable clusterWritable) throws IOException
{    StringBuilder line = new StringBuilder();    Cluster cluster = clusterWritable.getValue();    line.append(cluster.getId());    List<WeightedPropertyVectorWritable> points = getClusterIdToPoints().get(cluster.getId());    if (points != null) {        for (WeightedPropertyVectorWritable point : points) {            Vector theVec = point.getVector();            line.append(',');            if (theVec instanceof NamedVector) {                line.append(((NamedVector) theVec).getName());            } else {                String vecStr = theVec.asFormatString();                                vecStr = VEC_PATTERN.matcher(vecStr).replaceAll("_");                line.append(vecStr);            }        }        getWriter().append(line).append("\n");    }}
private void mahout_f563_0(Writer writer) throws IOException
{    writer.append("<?xml version=\"1.0\" encoding=\"UTF-8\"?>");    writer.append("<graphml xmlns=\"http://graphml.graphdrawing.org/xmlns\"\n" + "xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n" + "xsi:schemaLocation=\"http://graphml.graphdrawing.org/xmlns\n" + "http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd\">");        writer.append("<key attr.name=\"r\" attr.type=\"int\" for=\"node\" id=\"r\"/>\n" + "<key attr.name=\"g\" attr.type=\"int\" for=\"node\" id=\"g\"/>\n" + "<key attr.name=\"b\" attr.type=\"int\" for=\"node\" id=\"b\"/>" + "<key attr.name=\"size\" attr.type=\"int\" for=\"node\" id=\"size\"/>" + "<key attr.name=\"weight\" attr.type=\"float\" for=\"edge\" id=\"weight\"/>" + "<key attr.name=\"x\" attr.type=\"float\" for=\"node\" id=\"x\"/>" + "<key attr.name=\"y\" attr.type=\"float\" for=\"node\" id=\"y\"/>");    writer.append("<graph edgedefault=\"undirected\">");    lastClusterColor = new Color();    posStep = (int) (0.1 * clusterIdToPoints.size()) + 100;    random = RandomUtils.getRandom();}
public void mahout_f564_0(ClusterWritable clusterWritable) throws IOException
{    StringBuilder line = new StringBuilder();    Cluster cluster = clusterWritable.getValue();    Color rgb = getColor(cluster.getId());    String topTerms = "";    if (dictionary != null) {        topTerms = getTopTerms(cluster.getCenter(), dictionary, numTopFeatures);    }    String clusterLabel = String.valueOf(cluster.getId()) + '_' + topTerms;            float x = lastX + 1000;    float y = lastY;    if (x > (1000 + posStep)) {        y = lastY + 1000;        x = 0;    }    line.append(createNode(clusterLabel, rgb, x, y));    List<WeightedPropertyVectorWritable> points = clusterIdToPoints.get(cluster.getId());    if (points != null) {        for (WeightedVectorWritable point : points) {            Vector theVec = point.getVector();            double distance = 1;            if (measure != null) {                                distance = measure.distance(cluster.getCenter().getLengthSquared(), cluster.getCenter(), theVec) * 500;            }            String vecStr;                        int angle = random.nextInt(360);            double angleRads = Math.toRadians(angle);            float targetX = x + (float) (distance * Math.cos(angleRads));            float targetY = y + (float) (distance * Math.sin(angleRads));            if (theVec instanceof NamedVector) {                vecStr = ((NamedVector) theVec).getName();            } else {                vecStr = theVec.asFormatString();                                vecStr = VEC_PATTERN.matcher(vecStr).replaceAll("_");            }            if (subString > 0 && vecStr.length() > subString) {                vecStr = vecStr.substring(0, subString);            }            line.append(createNode(vecStr, rgb, targetX, targetY));            line.append(createEdge(clusterLabel, vecStr, distance));        }    }    lastClusterColor = rgb;    lastX = x;    lastY = y;    getWriter().append(line).append("\n");}
private Color mahout_f565_0(int clusterId)
{    Color result = colors.get(clusterId);    if (result == null) {        result = new Color();                int incR = 0;        int incG = 0;        int incB = 0;        if (lastClusterColor.r + 20 < 256 && lastClusterColor.g + 20 < 256 && lastClusterColor.b + 20 < 256) {            incR = 20;            incG = 0;            incB = 0;        } else if (lastClusterColor.r + 20 >= 256 && lastClusterColor.g + 20 < 256 && lastClusterColor.b + 20 < 256) {            incG = 20;            incB = 0;        } else if (lastClusterColor.r + 20 >= 256 && lastClusterColor.g + 20 >= 256 && lastClusterColor.b + 20 < 256) {            incB = 20;        } else {            incR += 3;            incG += 3;            incR += 3;        }        result.r = (lastClusterColor.r + incR) % 256;        result.g = (lastClusterColor.g + incG) % 256;        result.b = (lastClusterColor.b + incB) % 256;        colors.put(clusterId, result);    }    return result;}
private static String mahout_f566_0(String left, String right, double distance)
{    left = StringUtils.escapeXML(left);    right = StringUtils.escapeXML(right);    return "<edge id=\"" + left + '_' + right + "\" source=\"" + left + "\" target=\"" + right + "\">" + "<data key=\"weight\">" + distance + "</data></edge>";}
private static String mahout_f567_0(String s, Color rgb, float x, float y)
{    return "<node id=\"" + StringUtils.escapeXML(s) + "\"><data key=\"r\">" + rgb.r + "</data>" + "<data key=\"g\">" + rgb.g + "</data>" + "<data key=\"b\">" + rgb.b + "</data>" + "<data key=\"x\">" + x + "</data>" + "<data key=\"y\">" + y + "</data>" + "</node>";}
public void mahout_f568_0() throws IOException
{    getWriter().append("</graph>").append("</graphml>");    super.close();}
public void mahout_f569_0(ClusterWritable clusterWritable) throws IOException
{    Map<String, Object> res = new HashMap<>();        if (dictionary != null) {        List<Object> topTerms = getTopFeaturesList(clusterWritable.getValue().getCenter(), dictionary, numTopFeatures);        res.put("top_terms", topTerms);    } else {        res.put("top_terms", new ArrayList<>());    }        Cluster cluster = clusterWritable.getValue();    res.put("cluster_id", cluster.getId());    if (dictionary != null) {        Map<String, Object> fmtStr = cluster.asJson(dictionary);        res.put("cluster", fmtStr);                List<Object> points = getPoints(cluster, dictionary);        res.put("points", points);    } else {        res.put("cluster", new HashMap<>());        res.put("points", new ArrayList<>());    }        Writer writer = getWriter();    writer.write(jxn.writeValueAsString(res) + "\n");}
public List<Object> mahout_f570_1(Vector vector, String[] dictionary, int numTerms)
{    List<TermIndexWeight> vectorTerms = new ArrayList<>();    for (Vector.Element elt : vector.nonZeroes()) {        vectorTerms.add(new TermIndexWeight(elt.index(), elt.get()));    }        Collections.sort(vectorTerms, new Comparator<TermIndexWeight>() {        @Override        public int compare(TermIndexWeight one, TermIndexWeight two) {            return Double.compare(two.weight, one.weight);        }    });    List<Object> topTerms = new ArrayList<>();    for (int i = 0; i < vectorTerms.size() && i < numTerms; i++) {        int index = vectorTerms.get(i).index;        String dictTerm = dictionary[index];        if (dictTerm == null) {                        continue;        }        Map<String, Object> term_entry = new HashMap<>();        term_entry.put(dictTerm, vectorTerms.get(i).weight);        topTerms.add(term_entry);    }    return topTerms;}
public int mahout_f571_0(TermIndexWeight one, TermIndexWeight two)
{    return Double.compare(two.weight, one.weight);}
public List<Object> mahout_f572_1(Cluster cluster, String[] dictionary)
{    List<Object> vectorObjs = new ArrayList<>();    List<WeightedPropertyVectorWritable> points = getClusterIdToPoints().get(cluster.getId());    if (points != null) {        for (WeightedPropertyVectorWritable point : points) {            Map<String, Object> entry = new HashMap<>();            Vector theVec = point.getVector();            if (theVec instanceof NamedVector) {                entry.put("vector_name", ((NamedVector) theVec).getName());            } else {                String vecStr = theVec.asFormatString();                                vecStr = VEC_PATTERN.matcher(vecStr).replaceAll("_");                entry.put("vector_name", vecStr);            }            entry.put("weight", String.valueOf(point.getWeight()));            try {                entry.put("point", AbstractCluster.formatVectorAsJson(point.getVector(), dictionary));            } catch (IOException e) {                            }            vectorObjs.add(entry);        }    }    return vectorObjs;}
public File mahout_f573_0()
{    return input;}
public void mahout_f574_0(File input)
{    this.input = input;}
public String mahout_f575_0()
{    return outputDir;}
public void mahout_f576_0(String outputDir)
{    this.outputDir = outputDir;}
public String mahout_f577_0()
{    return prefix;}
public void mahout_f578_0(String prefix)
{    this.prefix = prefix;}
public int mahout_f579_0()
{    return chunkSize;}
public void mahout_f580_0(int chunkSize)
{    this.chunkSize = chunkSize;}
public Charset mahout_f581_0()
{    return charset;}
public void mahout_f582_0(Charset charset)
{    this.charset = charset;}
public String mahout_f583_0()
{    return separator;}
public void mahout_f584_0(String separator)
{    this.separator = separator;}
public String mahout_f585_0()
{    return bodySeparator;}
public void mahout_f586_0(String bodySeparator)
{    this.bodySeparator = bodySeparator;}
public boolean mahout_f587_0()
{    return includeBody;}
public void mahout_f588_0(boolean includeBody)
{    this.includeBody = includeBody;}
public Pattern[] mahout_f589_0()
{    return patternsToMatch;}
public void mahout_f590_0(Pattern[] patternsToMatch)
{    this.patternsToMatch = patternsToMatch;}
public Map<String, Integer> mahout_f591_0()
{    return patternOrder;}
public void mahout_f592_0(Map<String, Integer> patternOrder)
{    this.patternOrder = patternOrder;}
public boolean mahout_f593_0()
{    return stripQuotedText;}
public void mahout_f594_0(boolean stripQuotedText)
{    this.stripQuotedText = stripQuotedText;}
public Pattern mahout_f595_0()
{    return quotedTextPattern;}
public void mahout_f596_0(Pattern quotedTextPattern)
{    this.quotedTextPattern = quotedTextPattern;}
public long mahout_f597_1(File mboxFile) throws IOException
{    long messageCount = 0;    try {        StringBuilder contents = new StringBuilder();                StringBuilder body = new StringBuilder();        Matcher messageIdMatcher = MESSAGE_ID_PREFIX.matcher("");        Matcher messageBoundaryMatcher = MESSAGE_START.matcher("");        String[] patternResults = new String[options.getPatternsToMatch().length];        Matcher[] matchers = new Matcher[options.getPatternsToMatch().length];        for (int i = 0; i < matchers.length; i++) {            matchers[i] = options.getPatternsToMatch()[i].matcher("");        }        String messageId = null;        boolean inBody = false;        Pattern quotedTextPattern = options.getQuotedTextPattern();        for (String nextLine : new FileLineIterable(mboxFile, options.getCharset(), false)) {            if (options.isStripQuotedText() && quotedTextPattern.matcher(nextLine).find()) {                continue;            }            for (int i = 0; i < matchers.length; i++) {                Matcher matcher = matchers[i];                matcher.reset(nextLine);                if (matcher.matches()) {                    patternResults[i] = matcher.group(1);                }            }                        if (messageId != null) {                                messageBoundaryMatcher.reset(nextLine);                if (messageBoundaryMatcher.matches()) {                                        String key = generateKey(mboxFile, prefix, messageId);                                        writeContent(options.getSeparator(), contents, body, patternResults);                    writer.write(key, contents.toString());                                        contents.setLength(0);                    body.setLength(0);                    messageId = null;                    inBody = false;                } else {                    if (inBody && options.isIncludeBody()) {                        if (!nextLine.isEmpty()) {                            body.append(nextLine).append(options.getBodySeparator());                        }                    } else {                                                                        inBody = nextLine.isEmpty();                    }                }            } else {                if (nextLine.length() > 14) {                    messageIdMatcher.reset(nextLine);                    if (messageIdMatcher.matches()) {                        messageId = messageIdMatcher.group(1);                        ++messageCount;                    }                }            }        }                if (messageId != null) {            String key = generateKey(mboxFile, prefix, messageId);            writeContent(options.getSeparator(), contents, body, patternResults);            writer.write(key, contents.toString());                        contents.setLength(0);        }    } catch (FileNotFoundException e) {                    }        return messageCount;}
protected static String mahout_f598_0(File mboxFile, String prefix, String messageId)
{    return prefix + File.separator + mboxFile.getName() + File.separator + messageId;}
public String mahout_f599_0()
{    return prefix;}
public MailOptions mahout_f600_0()
{    return options;}
private static void mahout_f601_0(String separator, StringBuilder contents, CharSequence body, String[] matches)
{    for (String match : matches) {        if (match != null) {            contents.append(match).append(separator);        } else {            contents.append(separator);        }    }    contents.append('\n').append(body);}
public void mahout_f602_0(String key, String value) throws IOException
{    writer.write(key, value);}
public void mahout_f603_0() throws IOException
{    writer.close();}
private Path mahout_f604_0(int chunkID)
{    return new Path(output, "chunk-" + chunkID);}
public void mahout_f605_0(String key, String value) throws IOException
{    if (currentChunkSize > maxChunkSizeInBytes) {        Closeables.close(writer, false);        currentChunkID++;        writer = new SequenceFile.Writer(fs, conf, getPath(currentChunkID), Text.class, Text.class);        currentChunkSize = 0;    }    Text keyT = new Text(key);    Text valueT = new Text(value);        currentChunkSize += keyT.getBytes().length + valueT.getBytes().length;    writer.append(keyT, valueT);}
public void mahout_f606_0() throws IOException
{    Closeables.close(writer, false);}
public void mahout_f607_0(String key, String value) throws IOException
{    writer.write(key + ' ' + value);}
public void mahout_f608_0() throws IOException
{    writer.close();}
public static void mahout_f609_0(String[] args) throws Exception
{    ToolRunner.run(new MatrixDumper(), args);}
public int mahout_f610_0(String[] args) throws Exception
{    addInputOption();        addOption("output", "o", "Output path", null);    Map<String, List<String>> parsedArgs = parseArguments(args);    if (parsedArgs == null) {        return -1;    }    String outputFile = hasOption("output") ? getOption("output") : null;    exportCSV(getInputPath(), outputFile, false);    return 0;}
private static void mahout_f611_0(Path inputPath, String outputFile, boolean doLabels) throws IOException
{    SequenceFileValueIterator<MatrixWritable> it = new SequenceFileValueIterator<>(inputPath, true, new Configuration());    Matrix m = it.next().get();    it.close();    PrintStream ps = getPrintStream(outputFile);    String[] columnLabels = getLabels(m.numCols(), m.getColumnLabelBindings(), "col");    String[] rowLabels = getLabels(m.numRows(), m.getRowLabelBindings(), "row");    if (doLabels) {        ps.print("rowid,");        ps.print(columnLabels[0]);        for (int c = 1; c < m.numCols(); c++) {            ps.print(',' + columnLabels[c]);        }        ps.println();    }    for (int r = 0; r < m.numRows(); r++) {        if (doLabels) {            ps.print(rowLabels[0] + ',');        }        ps.print(Double.toString(m.getQuick(r, 0)));        for (int c = 1; c < m.numCols(); c++) {            ps.print(",");            ps.print(Double.toString(m.getQuick(r, c)));        }        ps.println();    }    if (ps != System.out) {        ps.close();    }}
private static PrintStream mahout_f612_0(String outputPath) throws IOException
{    if (outputPath == null) {        return System.out;    }    File outputFile = new File(outputPath);    if (outputFile.exists()) {        outputFile.delete();    }    outputFile.createNewFile();    OutputStream os = new FileOutputStream(outputFile);    return new PrintStream(os, false, Charsets.UTF_8.displayName());}
private static String[] mahout_f613_0(int length, Map<String, Integer> labels, String start)
{    if (labels != null) {        return sortLabels(labels);    }    String[] sorted = new String[length];    for (int i = 1; i <= length; i++) {        sorted[i] = start + i;    }    return sorted;}
private static String[] mahout_f614_0(Map<String, Integer> labels)
{    String[] sorted = new String[labels.size()];    for (Map.Entry<String, Integer> entry : labels.entrySet()) {        sorted[entry.getValue()] = entry.getKey();    }    return sorted;}
public boolean mahout_f615_0() throws IOException
{    while (input.incrementToken()) {        ByteBuffer bytes = encoder.encode(CharBuffer.wrap(termAtt.buffer(), 0, termAtt.length()));        key.set(bytes.array(), 1.0f);        boolean member = filter.membershipTest(key);        if ((keepMembers && member) || (!keepMembers && !member)) {            return true;        }    }    return false;}
public String mahout_f616_0(String match)
{    StringBuilder result = new StringBuilder();    try (TokenStream ts = analyzer.tokenStream(fieldName, new StringReader(match))) {        ts.addAttribute(CharTermAttribute.class);        ts.reset();        TokenStreamIterator iter = new TokenStreamIterator(ts);        while (iter.hasNext()) {            result.append(iter.next()).append(' ');        }        ts.end();    } catch (IOException e) {        throw new IllegalStateException(e);    }    return result.toString();}
public Analyzer mahout_f617_0()
{    return analyzer;}
public void mahout_f618_0(Analyzer analyzer)
{    this.analyzer = analyzer;}
public String mahout_f619_0(String match)
{    String result = match;    for (RegexTransformer transformer : chain) {        result = transformer.transformMatch(result);    }    return result;}
public List<RegexTransformer> mahout_f620_0()
{    return chain;}
public void mahout_f621_0(List<RegexTransformer> chain)
{    this.chain = chain;}
public String mahout_f622_0(String toFormat)
{    return '\t' + WHITESPACE.matcher(toFormat).replaceAll("|");}
public String mahout_f623_0(String toFormat)
{    return toFormat;}
public String mahout_f624_0(String match)
{    return match;}
public int mahout_f625_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption(DefaultOptionCreator.overwriteOption().create());    addOption("regex", "regex", "The regular expression to use", true);    addOption("groupsToKeep", "g", "The number of the capturing groups to keep", false);    addOption("transformerClass", "t", "The optional class specifying the Regex Transformer", false);    addOption("formatterClass", "t", "The optional class specifying the Regex Formatter", false);    addOption(DefaultOptionCreator.analyzerOption().create());    if (parseArguments(args) == null) {        return -1;    }    Configuration conf = getConf();            conf.set(RegexMapper.REGEX, getOption("regex"));    String gtk = getOption("groupsToKeep");    if (gtk != null) {        conf.set(RegexMapper.GROUP_MATCHERS, gtk);    }    String trans = getOption("transformerClass");    if (trans != null) {        if ("url".equalsIgnoreCase(trans)) {            trans = URLDecodeTransformer.class.getName();        }        conf.set(RegexMapper.TRANSFORMER_CLASS, trans);    }    String formatter = getOption("formatterClass");    if (formatter != null) {        if ("fpg".equalsIgnoreCase(formatter)) {            formatter = FPGFormatter.class.getName();        }        conf.set(RegexMapper.FORMATTER_CLASS, formatter);    }    Path input = getInputPath();    Path output = getOutputPath();    if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {        HadoopUtil.delete(getConf(), output);    }    Class<? extends Analyzer> analyzerClass = getAnalyzerClassFromOption();    if (analyzerClass != null) {        conf.set(RegexMapper.ANALYZER_NAME, analyzerClass.getName());    }    Job job = prepareJob(input, output, TextInputFormat.class, RegexMapper.class, LongWritable.class, Text.class, TextOutputFormat.class);    boolean succeeded = job.waitForCompletion(true);    return succeeded ? 0 : -1;}
public static void mahout_f626_0(String[] args) throws Exception
{    ToolRunner.run(new RegexConverterDriver(), args);}
protected void mahout_f627_0(Context context) throws IOException, InterruptedException
{    groupsToKeep = new ArrayList<>();    Configuration config = context.getConfiguration();    String regexStr = config.get(REGEX);    regex = Pattern.compile(regexStr);    String[] groups = config.getStrings(GROUP_MATCHERS);    if (groups != null) {        for (String group : groups) {            groupsToKeep.add(Integer.parseInt(group));        }    }    transformer = ClassUtils.instantiateAs(config.get(TRANSFORMER_CLASS, IdentityTransformer.class.getName()), RegexTransformer.class);    String analyzerName = config.get(ANALYZER_NAME);    if (analyzerName != null && transformer instanceof AnalyzerTransformer) {        Analyzer analyzer = ClassUtils.instantiateAs(analyzerName, Analyzer.class);        ((AnalyzerTransformer) transformer).setAnalyzer(analyzer);    }    formatter = ClassUtils.instantiateAs(config.get(FORMATTER_CLASS, IdentityFormatter.class.getName()), RegexFormatter.class);}
protected void mahout_f628_0(LongWritable key, Text text, Context context) throws IOException, InterruptedException
{    String result = RegexUtils.extract(text.toString(), regex, groupsToKeep, " ", transformer);    if (!result.isEmpty()) {        String format = formatter.format(result);        context.write(key, new Text(format));    }}
public static String mahout_f629_0(CharSequence line, Pattern pattern, Collection<Integer> groupsToKeep, String separator, RegexTransformer transformer)
{    StringBuilder bldr = new StringBuilder();    extract(line, bldr, pattern, groupsToKeep, separator, transformer);    return bldr.toString();}
public static void mahout_f630_0(CharSequence line, StringBuilder outputBuffer, Pattern pattern, Collection<Integer> groupsToKeep, String separator, RegexTransformer transformer)
{    if (transformer == null) {        transformer = IDENTITY_TRANSFORMER;    }    Matcher matcher = pattern.matcher(line);    String match;    if (groupsToKeep.isEmpty()) {        while (matcher.find()) {            match = matcher.group();            if (match != null) {                outputBuffer.append(transformer.transformMatch(match)).append(separator);            }        }    } else {        while (matcher.find()) {            for (Integer groupNum : groupsToKeep) {                match = matcher.group(groupNum);                if (match != null) {                    outputBuffer.append(transformer.transformMatch(match)).append(separator);                }            }        }    }        if (outputBuffer.length() > 0) {        outputBuffer.setLength(outputBuffer.length() - separator.length());    }}
public String mahout_f631_0(String match)
{    try {        return URLDecoder.decode(match, enc);    } catch (UnsupportedEncodingException e) {        throw new IllegalStateException(e);    }}
public int mahout_f632_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption("substring", "b", "The number of chars to print out per value", false);    addOption(buildOption("count", "c", "Report the count only", false, false, null));    addOption("numItems", "n", "Output at most <n> key value pairs", false);    addOption(buildOption("facets", "fa", "Output the counts per key.  Note, if there are a lot of unique keys, " + "this can take up a fair amount of memory", false, false, null));    addOption(buildOption("quiet", "q", "Print only file contents.", false, false, null));    if (parseArguments(args, false, true) == null) {        return -1;    }    Path[] pathArr;    Configuration conf = new Configuration();    Path input = getInputPath();    FileSystem fs = input.getFileSystem(conf);    if (fs.getFileStatus(input).isDir()) {        pathArr = FileUtil.stat2Paths(fs.listStatus(input, PathFilters.logsCRCFilter()));    } else {        pathArr = new Path[1];        pathArr[0] = input;    }    Writer writer;    boolean shouldClose;    if (hasOption("output")) {        shouldClose = true;        writer = Files.newWriter(new File(getOption("output")), Charsets.UTF_8);    } else {        shouldClose = false;        writer = new OutputStreamWriter(System.out, Charsets.UTF_8);    }    try {        for (Path path : pathArr) {            if (!hasOption("quiet")) {                writer.append("Input Path: ").append(String.valueOf(path)).append('\n');            }            int sub = Integer.MAX_VALUE;            if (hasOption("substring")) {                sub = Integer.parseInt(getOption("substring"));            }            boolean countOnly = hasOption("count");            SequenceFileIterator<?, ?> iterator = new SequenceFileIterator<>(path, true, conf);            if (!hasOption("quiet")) {                writer.append("Key class: ").append(iterator.getKeyClass().toString());                writer.append(" Value Class: ").append(iterator.getValueClass().toString()).append('\n');            }            OpenObjectIntHashMap<String> facets = null;            if (hasOption("facets")) {                facets = new OpenObjectIntHashMap<>();            }            long count = 0;            if (countOnly) {                while (iterator.hasNext()) {                    Pair<?, ?> record = iterator.next();                    String key = record.getFirst().toString();                    if (facets != null) {                                                facets.adjustOrPutValue(key, 1, 1);                    }                    count++;                }                writer.append("Count: ").append(String.valueOf(count)).append('\n');            } else {                long numItems = Long.MAX_VALUE;                if (hasOption("numItems")) {                    numItems = Long.parseLong(getOption("numItems"));                    if (!hasOption("quiet")) {                        writer.append("Max Items to dump: ").append(String.valueOf(numItems)).append("\n");                    }                }                while (iterator.hasNext() && count < numItems) {                    Pair<?, ?> record = iterator.next();                    String key = record.getFirst().toString();                    writer.append("Key: ").append(key);                    String str = record.getSecond().toString();                    writer.append(": Value: ").append(str.length() > sub ? str.substring(0, sub) : str);                    writer.write('\n');                    if (facets != null) {                                                facets.adjustOrPutValue(key, 1, 1);                    }                    count++;                }                if (!hasOption("quiet")) {                    writer.append("Count: ").append(String.valueOf(count)).append('\n');                }            }            if (facets != null) {                List<String> keyList = new ArrayList<>(facets.size());                IntArrayList valueList = new IntArrayList(facets.size());                facets.pairsSortedByKey(keyList, valueList);                writer.append("-----Facets---\n");                writer.append("Key\t\tCount\n");                int i = 0;                for (String key : keyList) {                    writer.append(key).append("\t\t").append(String.valueOf(valueList.get(i++))).append('\n');                }            }        }        writer.flush();    } finally {        if (shouldClose) {            Closeables.close(writer, false);        }    }    return 0;}
public static void mahout_f633_0(String[] args) throws Exception
{    new SequenceFileDumper().run(args);}
public int mahout_f634_0(String[] args) throws Exception
{    if (parseArgs(args)) {        splitDirectory();    }    return 0;}
public static void mahout_f635_0(String[] args) throws Exception
{    ToolRunner.run(new Configuration(), new SplitInput(), args);}
private boolean mahout_f636_1(String[] args) throws Exception
{    addInputOption();    addOption("trainingOutput", "tr", "The training data output directory", false);    addOption("testOutput", "te", "The test data output directory", false);    addOption("testSplitSize", "ss", "The number of documents held back as test data for each category", false);    addOption("testSplitPct", "sp", "The % of documents held back as test data for each category", false);    addOption("splitLocation", "sl", "Location for start of test data expressed as a percentage of the input file " + "size (0=start, 50=middle, 100=end", false);    addOption("randomSelectionSize", "rs", "The number of items to be randomly selected as test data ", false);    addOption("randomSelectionPct", "rp", "Percentage of items to be randomly selected as test data when using " + "mapreduce mode", false);    addOption("charset", "c", "The name of the character encoding of the input files (not needed if using " + "SequenceFiles)", false);    addOption(buildOption("sequenceFiles", "seq", "Set if the input files are sequence files.  Default is false", false, false, "false"));    addOption(DefaultOptionCreator.methodOption().create());    addOption(DefaultOptionCreator.overwriteOption().create());        addOption("keepPct", "k", "The percentage of total data to keep in map-reduce mode, the rest will be ignored.  " + "Default is 100%", false);    addOption("mapRedOutputDir", "mro", "Output directory for map reduce jobs", false);    if (parseArguments(args) == null) {        return false;    }    try {        inputDirectory = getInputPath();        useMapRed = getOption(DefaultOptionCreator.METHOD_OPTION).equalsIgnoreCase(DefaultOptionCreator.MAPREDUCE_METHOD);        if (useMapRed) {            if (!hasOption("randomSelectionPct")) {                throw new OptionException(getCLIOption("randomSelectionPct"), "must set randomSelectionPct when mapRed option is used");            }            if (!hasOption("mapRedOutputDir")) {                throw new OptionException(getCLIOption("mapRedOutputDir"), "mapRedOutputDir must be set when mapRed option is used");            }            mapRedOutputDirectory = new Path(getOption("mapRedOutputDir"));            if (hasOption("keepPct")) {                keepPct = Integer.parseInt(getOption("keepPct"));            }            if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {                HadoopUtil.delete(getConf(), mapRedOutputDirectory);            }        } else {            if (!hasOption("trainingOutput") || !hasOption("testOutput")) {                throw new OptionException(getCLIOption("trainingOutput"), "trainingOutput and testOutput must be set if mapRed option is not used");            }            if (!hasOption("testSplitSize") && !hasOption("testSplitPct") && !hasOption("randomSelectionPct") && !hasOption("randomSelectionSize")) {                throw new OptionException(getCLIOption("testSplitSize"), "must set one of test split size/percentage or randomSelectionSize/percentage");            }            trainingOutputDirectory = new Path(getOption("trainingOutput"));            testOutputDirectory = new Path(getOption("testOutput"));            FileSystem fs = trainingOutputDirectory.getFileSystem(getConf());            if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {                HadoopUtil.delete(fs.getConf(), trainingOutputDirectory);                HadoopUtil.delete(fs.getConf(), testOutputDirectory);            }            fs.mkdirs(trainingOutputDirectory);            fs.mkdirs(testOutputDirectory);        }        if (hasOption("charset")) {            charset = Charset.forName(getOption("charset"));        }        if (hasOption("testSplitSize") && hasOption("testSplitPct")) {            throw new OptionException(getCLIOption("testSplitPct"), "must have either split size or split percentage " + "option, not BOTH");        }        if (hasOption("testSplitSize")) {            setTestSplitSize(Integer.parseInt(getOption("testSplitSize")));        }        if (hasOption("testSplitPct")) {            setTestSplitPct(Integer.parseInt(getOption("testSplitPct")));        }        if (hasOption("splitLocation")) {            setSplitLocation(Integer.parseInt(getOption("splitLocation")));        }        if (hasOption("randomSelectionSize")) {            setTestRandomSelectionSize(Integer.parseInt(getOption("randomSelectionSize")));        }        if (hasOption("randomSelectionPct")) {            setTestRandomSelectionPct(Integer.parseInt(getOption("randomSelectionPct")));        }        useSequence = hasOption("sequenceFiles");    } catch (OptionException e) {                CommandLineUtil.printHelp(getGroup());        return false;    }    validate();    return true;}
public void mahout_f637_0() throws IOException, ClassNotFoundException, InterruptedException
{    this.splitDirectory(inputDirectory);}
public void mahout_f638_0(Path inputDir) throws IOException, ClassNotFoundException, InterruptedException
{    Configuration conf = getConf();    splitDirectory(conf, inputDir);}
public void mahout_f639_0(Configuration conf, Path inputDir) throws IOException, ClassNotFoundException, InterruptedException
{    FileSystem fs = inputDir.getFileSystem(conf);    if (fs.getFileStatus(inputDir) == null) {        throw new IOException(inputDir + " does not exist");    }    if (!fs.getFileStatus(inputDir).isDir()) {        throw new IOException(inputDir + " is not a directory");    }    if (useMapRed) {        SplitInputJob.run(conf, inputDir, mapRedOutputDirectory, keepPct, testRandomSelectionPct);    } else {                FileStatus[] fileStats = fs.listStatus(inputDir, PathFilters.logsCRCFilter());        for (FileStatus inputFile : fileStats) {            if (!inputFile.isDir()) {                splitFile(inputFile.getPath());            }        }    }}
public void mahout_f640_1(Path inputFile) throws IOException
{    Configuration conf = getConf();    FileSystem fs = inputFile.getFileSystem(conf);    if (fs.getFileStatus(inputFile) == null) {        throw new IOException(inputFile + " does not exist");    }    if (fs.getFileStatus(inputFile).isDir()) {        throw new IOException(inputFile + " is a directory");    }    validate();    Path testOutputFile = new Path(testOutputDirectory, inputFile.getName());    Path trainingOutputFile = new Path(trainingOutputDirectory, inputFile.getName());    int lineCount = countLines(fs, inputFile, charset);        int testSplitStart = 0;        int testSplitSize = this.testSplitSize;    BitSet randomSel = null;    if (testRandomSelectionPct > 0 || testRandomSelectionSize > 0) {        testSplitSize = this.testRandomSelectionSize;        if (testRandomSelectionPct > 0) {            testSplitSize = Math.round(lineCount * testRandomSelectionPct / 100.0f);        }                long[] ridx = new long[testSplitSize];        RandomSampler.sample(testSplitSize, lineCount - 1, testSplitSize, 0, ridx, 0, RandomUtils.getRandom());        randomSel = new BitSet(lineCount);        for (long idx : ridx) {            randomSel.set((int) idx + 1);        }    } else {        if (testSplitPct > 0) {                        testSplitSize = Math.round(lineCount * testSplitPct / 100.0f);                    } else {                    }        if (splitLocation > 0) {                        testSplitStart = Math.round(lineCount * splitLocation / 100.0f);            if (lineCount - testSplitStart < testSplitSize) {                                testSplitStart = lineCount - testSplitSize;            }                    }        if (testSplitStart < 0) {            throw new IllegalArgumentException("test split size for " + inputFile + " is too large, it would produce an " + "empty training set from the initial set of " + lineCount + " examples");        } else if (lineCount - testSplitSize < testSplitSize) {                    }    }    int trainCount = 0;    int testCount = 0;    if (!useSequence) {        try (BufferedReader reader = new BufferedReader(new InputStreamReader(fs.open(inputFile), charset));            Writer trainingWriter = new OutputStreamWriter(fs.create(trainingOutputFile), charset);            Writer testWriter = new OutputStreamWriter(fs.create(testOutputFile), charset)) {            String line;            int pos = 0;            while ((line = reader.readLine()) != null) {                pos++;                Writer writer;                if (testRandomSelectionPct > 0) {                                        writer = randomSel.get(pos) ? testWriter : trainingWriter;                } else {                                        writer = pos > testSplitStart ? testWriter : trainingWriter;                }                if (writer == testWriter) {                    if (testCount >= testSplitSize) {                        writer = trainingWriter;                    } else {                        testCount++;                    }                }                if (writer == trainingWriter) {                    trainCount++;                }                writer.write(line);                writer.write('\n');            }        }    } else {        try (SequenceFileIterator<Writable, Writable> iterator = new SequenceFileIterator<>(inputFile, false, fs.getConf());            SequenceFile.Writer trainingWriter = SequenceFile.createWriter(fs, fs.getConf(), trainingOutputFile, iterator.getKeyClass(), iterator.getValueClass());            SequenceFile.Writer testWriter = SequenceFile.createWriter(fs, fs.getConf(), testOutputFile, iterator.getKeyClass(), iterator.getValueClass())) {            int pos = 0;            while (iterator.hasNext()) {                pos++;                SequenceFile.Writer writer;                if (testRandomSelectionPct > 0) {                                        writer = randomSel.get(pos) ? testWriter : trainingWriter;                } else {                                        writer = pos > testSplitStart ? testWriter : trainingWriter;                }                if (writer == testWriter) {                    if (testCount >= testSplitSize) {                        writer = trainingWriter;                    } else {                        testCount++;                    }                }                if (writer == trainingWriter) {                    trainCount++;                }                Pair<Writable, Writable> pair = iterator.next();                writer.append(pair.getFirst(), pair.getSecond());            }        }    }            if (callback != null) {        callback.splitComplete(inputFile, lineCount, trainCount, testCount, testSplitStart);    }}
public int mahout_f641_0()
{    return testSplitSize;}
public void mahout_f642_0(int testSplitSize)
{    this.testSplitSize = testSplitSize;}
public int mahout_f643_0()
{    return testSplitPct;}
public void mahout_f644_0(int testSplitPct)
{    this.testSplitPct = testSplitPct;}
public void mahout_f645_0(int keepPct)
{    this.keepPct = keepPct;}
public void mahout_f646_0(boolean useMapRed)
{    this.useMapRed = useMapRed;}
public void mahout_f647_0(Path mapRedOutputDirectory)
{    this.mapRedOutputDirectory = mapRedOutputDirectory;}
public int mahout_f648_0()
{    return splitLocation;}
public void mahout_f649_0(int splitLocation)
{    this.splitLocation = splitLocation;}
public Charset mahout_f650_0()
{    return charset;}
public void mahout_f651_0(Charset charset)
{    this.charset = charset;}
public Path mahout_f652_0()
{    return inputDirectory;}
public void mahout_f653_0(Path inputDir)
{    this.inputDirectory = inputDir;}
public Path mahout_f654_0()
{    return trainingOutputDirectory;}
public void mahout_f655_0(Path trainingOutputDir)
{    this.trainingOutputDirectory = trainingOutputDir;}
public Path mahout_f656_0()
{    return testOutputDirectory;}
public void mahout_f657_0(Path testOutputDir)
{    this.testOutputDirectory = testOutputDir;}
public SplitCallback mahout_f658_0()
{    return callback;}
public void mahout_f659_0(SplitCallback callback)
{    this.callback = callback;}
public int mahout_f660_0()
{    return testRandomSelectionSize;}
public void mahout_f661_0(int testRandomSelectionSize)
{    this.testRandomSelectionSize = testRandomSelectionSize;}
public int mahout_f662_0()
{    return testRandomSelectionPct;}
public void mahout_f663_0(int randomSelectionPct)
{    this.testRandomSelectionPct = randomSelectionPct;}
public void mahout_f664_0() throws IOException
{    Preconditions.checkArgument(testSplitSize >= 1 || testSplitSize == -1, "Invalid testSplitSize: " + testSplitSize + ". Must be: testSplitSize >= 1 or testSplitSize = -1");    Preconditions.checkArgument(splitLocation >= 0 && splitLocation <= 100 || splitLocation == -1, "Invalid splitLocation percentage: " + splitLocation + ". Must be: 0 <= splitLocation <= 100 or splitLocation = -1");    Preconditions.checkArgument(testSplitPct >= 0 && testSplitPct <= 100 || testSplitPct == -1, "Invalid testSplitPct percentage: " + testSplitPct + ". Must be: 0 <= testSplitPct <= 100 or testSplitPct = -1");    Preconditions.checkArgument(testRandomSelectionPct >= 0 && testRandomSelectionPct <= 100 || testRandomSelectionPct == -1, "Invalid testRandomSelectionPct percentage: " + testRandomSelectionPct + ". Must be: 0 <= testRandomSelectionPct <= 100 or testRandomSelectionPct = -1");    Preconditions.checkArgument(trainingOutputDirectory != null || useMapRed, "No training output directory was specified");    Preconditions.checkArgument(testOutputDirectory != null || useMapRed, "No test output directory was specified");        int count = 0;    if (testSplitSize > 0) {        count++;    }    if (testSplitPct > 0) {        count++;    }    if (testRandomSelectionSize > 0) {        count++;    }    if (testRandomSelectionPct > 0) {        count++;    }    Preconditions.checkArgument(count == 1, "Exactly one of testSplitSize, testSplitPct, testRandomSelectionSize, " + "testRandomSelectionPct should be set");    if (!useMapRed) {        Configuration conf = getConf();        FileSystem fs = trainingOutputDirectory.getFileSystem(conf);        FileStatus trainingOutputDirStatus = fs.getFileStatus(trainingOutputDirectory);        Preconditions.checkArgument(trainingOutputDirStatus != null && trainingOutputDirStatus.isDir(), "%s is not a directory", trainingOutputDirectory);        FileStatus testOutputDirStatus = fs.getFileStatus(testOutputDirectory);        Preconditions.checkArgument(testOutputDirStatus != null && testOutputDirStatus.isDir(), "%s is not a directory", testOutputDirectory);    }}
public static int mahout_f665_0(FileSystem fs, Path inputFile, Charset charset) throws IOException
{    int lineCount = 0;    try (BufferedReader reader = new BufferedReader(new InputStreamReader(fs.open(inputFile), charset))) {        while (reader.readLine() != null) {            lineCount++;        }    }    return lineCount;}
public static void mahout_f666_0(Configuration initialConf, Path inputPath, Path outputPath, int keepPct, float randomSelectionPercent) throws IOException, ClassNotFoundException, InterruptedException
{    int downsamplingFactor = (int) (100.0 / keepPct);    initialConf.setInt(DOWNSAMPLING_FACTOR, downsamplingFactor);    initialConf.setFloat(RANDOM_SELECTION_PCT, randomSelectionPercent);        FileSystem fs = FileSystem.get(initialConf);    SequenceFileDirIterator<? extends WritableComparable, Writable> iterator = new SequenceFileDirIterator<>(inputPath, PathType.LIST, PathFilters.partFilter(), null, false, fs.getConf());    Class<? extends WritableComparable> keyClass;    Class<? extends Writable> valueClass;    if (iterator.hasNext()) {        Pair<? extends WritableComparable, Writable> pair = iterator.next();        keyClass = pair.getFirst().getClass();        valueClass = pair.getSecond().getClass();    } else {        throw new IllegalStateException("Couldn't determine class of the input values");    }    Job job = new Job(new Configuration(initialConf));    MultipleOutputs.addNamedOutput(job, TRAINING_TAG, SequenceFileOutputFormat.class, keyClass, valueClass);    MultipleOutputs.addNamedOutput(job, TEST_TAG, SequenceFileOutputFormat.class, keyClass, valueClass);    job.setJarByClass(SplitInputJob.class);    FileInputFormat.addInputPath(job, inputPath);    FileOutputFormat.setOutputPath(job, outputPath);    job.setNumReduceTasks(1);    job.setInputFormatClass(SequenceFileInputFormat.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    job.setMapperClass(SplitInputMapper.class);    job.setReducerClass(SplitInputReducer.class);    job.setSortComparatorClass(SplitInputComparator.class);    job.setOutputKeyClass(keyClass);    job.setOutputValueClass(valueClass);    job.submit();    boolean succeeded = job.waitForCompletion(true);    if (!succeeded) {        throw new IllegalStateException("Job failed!");    }}
public void mahout_f667_0(Context ctx)
{    downsamplingFactor = ctx.getConfiguration().getInt(DOWNSAMPLING_FACTOR, 1);}
public void mahout_f668_0(Context context) throws IOException, InterruptedException
{    setup(context);    int i = 0;    while (context.nextKeyValue()) {        if (i % downsamplingFactor == 0) {            map(context.getCurrentKey(), context.getCurrentValue(), context);        }        i++;    }    cleanup(context);}
protected void mahout_f669_0(Context ctx) throws IOException
{    randomSelectionPercent = ctx.getConfiguration().getFloat(RANDOM_SELECTION_PCT, 0);    multipleOutputs = new MultipleOutputs(ctx);}
protected void mahout_f670_0(WritableComparable<?> key, Iterable<Writable> values, Context context) throws IOException, InterruptedException
{    for (Writable value : values) {        if (rnd.nextInt(100) < randomSelectionPercent) {            multipleOutputs.write(TEST_TAG, key, value);        } else {            multipleOutputs.write(TRAINING_TAG, key, value);        }    }}
protected void mahout_f671_0(Context context) throws IOException
{    try {        multipleOutputs.close();    } catch (InterruptedException e) {        throw new IOException(e);    }}
public int mahout_f672_0(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2)
{    if (rnd.nextBoolean()) {        return 1;    } else {        return -1;    }}
protected Vector mahout_f673_0()
{    String line;    try {        while ((line = reader.readLine()) != null) {            line = line.trim();            if (!line.isEmpty() && !line.startsWith(ARFFModel.ARFF_COMMENT)) {                break;            }        }    } catch (IOException ioe) {        throw new IllegalStateException(ioe);    }    if (line == null) {        try {            Closeables.close(reader, true);        } catch (IOException e) {            throw new IllegalStateException(e);        }        return endOfData();    }    Vector result;    Matcher contents = DATA_PATTERN.matcher(line);    if (contents.find()) {        line = contents.group(1);        String[] splits = splitCSV(line);        result = new RandomAccessSparseVector(model.getLabelSize());        for (String split : splits) {            int idIndex = split.indexOf(' ');            int idx = Integer.parseInt(split.substring(0, idIndex).trim());            String data = split.substring(idIndex).trim();            if (!"?".equals(data)) {                result.setQuick(idx, model.getValue(data, idx));            }        }    } else {        result = new DenseVector(model.getLabelSize());        String[] splits = splitCSV(line);        for (int i = 0; i < splits.length; i++) {            String split = splits[i];            split = split.trim();            if (WORDS_WITHOUT_SPARSE.matcher(split).matches() && !"?".equals(split)) {                result.setQuick(i, model.getValue(split, i));            }        }    }    return result;}
public static String[] mahout_f674_0(String line)
{    StringBuilder sb = new StringBuilder(128);    List<String> tokens = new ArrayList<>();    char escapeChar = '\0';    for (int i = 0; i < line.length(); i++) {        char c = line.charAt(i);        if (c == '\\') {            i++;            sb.append(line.charAt(i));        } else if (c == '"' || c == '\'') {                        if (c == escapeChar) {                escapeChar = '\0';            } else if (escapeChar == '\0') {                escapeChar = c;            }            sb.append(c);        } else if (c == ',') {            if (escapeChar == '\0') {                tokens.add(sb.toString().trim());                                sb.setLength(0);            } else {                sb.append(c);            }        } else {            sb.append(c);        }    }    if (sb.length() > 0) {        tokens.add(sb.toString().trim());    }    return tokens.toArray(new String[tokens.size()]);}
public String mahout_f675_0()
{    return indicator;}
public String mahout_f676_0(String line)
{    int idx = line.lastIndexOf(indicator);    return removeQuotes(line.substring(ARFFModel.ATTRIBUTE.length(), idx));}
public static String mahout_f677_0(String str)
{    String cleaned = str;    if (cleaned != null) {        cleaned = cleaned.trim();        boolean isQuoted = cleaned.length() > 1 && (cleaned.startsWith("\"") && cleaned.endsWith("\"") || cleaned.startsWith("'") && cleaned.endsWith("'"));        if (isQuoted) {            cleaned = cleaned.substring(1, cleaned.length() - 1);        }    }    return cleaned;}
public Iterator<Vector> mahout_f678_0()
{    return new ARFFIterator(buff, model);}
public ARFFModel mahout_f679_0()
{    return model;}
public static void mahout_f680_1(String[] args) throws IOException
{    DefaultOptionBuilder obuilder = new DefaultOptionBuilder();    ArgumentBuilder abuilder = new ArgumentBuilder();    GroupBuilder gbuilder = new GroupBuilder();    Option inputOpt = obuilder.withLongName("input").withRequired(true).withArgument(abuilder.withName("input").withMinimum(1).withMaximum(1).create()).withDescription("The file or directory containing the ARFF files.  If it is a directory, all .arff files will be converted").withShortName("d").create();    Option outputOpt = obuilder.withLongName("output").withRequired(true).withArgument(abuilder.withName("output").withMinimum(1).withMaximum(1).create()).withDescription("The output directory.  Files will have the same name as the input, but with the extension .mvc").withShortName("o").create();    Option maxOpt = obuilder.withLongName("max").withRequired(false).withArgument(abuilder.withName("max").withMinimum(1).withMaximum(1).create()).withDescription("The maximum number of vectors to output.  If not specified, then it will loop over all docs").withShortName("m").create();    Option dictOutOpt = obuilder.withLongName("dictOut").withRequired(true).withArgument(abuilder.withName("dictOut").withMinimum(1).withMaximum(1).create()).withDescription("The file to output the label bindings").withShortName("t").create();    Option jsonDictonaryOpt = obuilder.withLongName("json-dictonary").withRequired(false).withDescription("Write dictonary in JSON format").withShortName("j").create();    Option delimiterOpt = obuilder.withLongName("delimiter").withRequired(false).withArgument(abuilder.withName("delimiter").withMinimum(1).withMaximum(1).create()).withDescription("The delimiter for outputing the dictionary").withShortName("l").create();    Option helpOpt = obuilder.withLongName("help").withDescription("Print out help").withShortName("h").create();    Group group = gbuilder.withName("Options").withOption(inputOpt).withOption(outputOpt).withOption(maxOpt).withOption(helpOpt).withOption(dictOutOpt).withOption(jsonDictonaryOpt).withOption(delimiterOpt).create();    try {        Parser parser = new Parser();        parser.setGroup(group);        CommandLine cmdLine = parser.parse(args);        if (cmdLine.hasOption(helpOpt)) {            CommandLineUtil.printHelp(group);            return;        }        if (cmdLine.hasOption(inputOpt)) {                        File input = new File(cmdLine.getValue(inputOpt).toString());            long maxDocs = Long.MAX_VALUE;            if (cmdLine.hasOption(maxOpt)) {                maxDocs = Long.parseLong(cmdLine.getValue(maxOpt).toString());            }            if (maxDocs < 0) {                throw new IllegalArgumentException("maxDocs must be >= 0");            }            String outDir = cmdLine.getValue(outputOpt).toString();                        String delimiter = cmdLine.hasOption(delimiterOpt) ? cmdLine.getValue(delimiterOpt).toString() : "\t";            File dictOut = new File(cmdLine.getValue(dictOutOpt).toString());            boolean jsonDictonary = cmdLine.hasOption(jsonDictonaryOpt);            ARFFModel model = new MapBackedARFFModel();            if (input.exists() && input.isDirectory()) {                File[] files = input.listFiles(new FilenameFilter() {                    @Override                    public boolean accept(File file, String name) {                        return name.endsWith(".arff");                    }                });                for (File file : files) {                    writeFile(outDir, file, maxDocs, model, dictOut, delimiter, jsonDictonary);                }            } else {                writeFile(outDir, input, maxDocs, model, dictOut, delimiter, jsonDictonary);            }        }    } catch (OptionException e) {                CommandLineUtil.printHelp(group);    }}
public boolean mahout_f681_0(File file, String name)
{    return name.endsWith(".arff");}
protected static void mahout_f682_0(File dictOut, ARFFModel arffModel, String delimiter, boolean jsonDictonary) throws IOException
{    try (Writer writer = Files.newWriterSupplier(dictOut, Charsets.UTF_8, true).getOutput()) {        if (jsonDictonary) {            writeLabelBindingsJSON(writer, arffModel);        } else {            writeLabelBindings(writer, arffModel, delimiter);        }    }}
protected static void mahout_f683_0(Writer writer, ARFFModel arffModel) throws IOException
{        List<Entry<String, Integer>> attributes = new ArrayList<>();    attributes.addAll(arffModel.getLabelBindings().entrySet());    Collections.sort(attributes, new Comparator<Map.Entry<String, Integer>>() {        @Override        public int compare(Entry<String, Integer> t, Entry<String, Integer> t1) {            return t.getValue().compareTo(t1.getValue());        }    });        List<Map<String, Object>> jsonObjects = new LinkedList<>();    for (int i = 0; i < attributes.size(); i++) {        Entry<String, Integer> modelRepresentation = attributes.get(i);        Map<String, Object> jsonRepresentation = new HashMap<>();        jsonObjects.add(jsonRepresentation);                jsonRepresentation.put("label", i < (attributes.size() - 1) ? String.valueOf(false) : String.valueOf(true));        String attribute = modelRepresentation.getKey();        jsonRepresentation.put("attribute", attribute);        Map<String, Integer> nominalValues = arffModel.getNominalMap().get(attribute);        if (nominalValues != null) {            String[] values = nominalValues.keySet().toArray(new String[1]);            jsonRepresentation.put("values", values);            jsonRepresentation.put("type", "categorical");        } else {            jsonRepresentation.put("type", "numerical");        }    }    writer.write(OBJECT_MAPPER.writeValueAsString(jsonObjects));}
public int mahout_f684_0(Entry<String, Integer> t, Entry<String, Integer> t1)
{    return t.getValue().compareTo(t1.getValue());}
protected static void mahout_f685_0(Writer writer, ARFFModel arffModel, String delimiter) throws IOException
{    Map<String, Integer> labels = arffModel.getLabelBindings();    writer.write("Label bindings for Relation " + arffModel.getRelation() + '\n');    for (Map.Entry<String, Integer> entry : labels.entrySet()) {        writer.write(entry.getKey());        writer.write(delimiter);        writer.write(String.valueOf(entry.getValue()));        writer.write('\n');    }    writer.write('\n');    writer.write("Values for nominal attributes\n");        Map<String, Map<String, Integer>> nominalMap = arffModel.getNominalMap();        writer.write(String.valueOf(nominalMap.size()) + "\n");    for (Entry<String, Map<String, Integer>> entry : nominalMap.entrySet()) {                writer.write(entry.getKey() + "\n");        Set<Entry<String, Integer>> attributeValues = entry.getValue().entrySet();                writer.write(attributeValues.size() + "\n");        for (Map.Entry<String, Integer> value : attributeValues) {                        writer.write(String.format("%s%s%s\n", value.getKey(), delimiter, value.getValue().toString()));        }    }}
protected static void mahout_f686_1(String outDir, File file, long maxDocs, ARFFModel arffModel, File dictOut, String delimiter, boolean jsonDictonary) throws IOException
{        ARFFModel model = new MapBackedARFFModel(arffModel.getWords(), arffModel.getWordCount() + 1, arffModel.getNominalMap());    Iterable<Vector> iteratable = new ARFFVectorIterable(file, model);    String outFile = outDir + '/' + file.getName() + ".mvc";    try (VectorWriter vectorWriter = getSeqFileWriter(outFile)) {        long numDocs = vectorWriter.write(iteratable, maxDocs);        writeLabelBindings(dictOut, model, delimiter, jsonDictonary);            }}
private static VectorWriter mahout_f687_0(String outFile) throws IOException
{    Path path = new Path(outFile);    Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);    SequenceFile.Writer seqWriter = SequenceFile.createWriter(fs, conf, path, LongWritable.class, VectorWritable.class);    return new SequenceFileVectorWriter(seqWriter);}
public String mahout_f688_0()
{    return relation;}
public void mahout_f689_0(String relation)
{    this.relation = relation;}
public double mahout_f690_0(String data, int idx)
{    ARFFType type = typeMap.get(idx);    if (type == null) {        throw new IllegalArgumentException("Attribute type cannot be NULL, attribute index was: " + idx);    }    data = QUOTE_PATTERN.matcher(data).replaceAll("");    data = data.trim();    double result;    switch(type) {        case NUMERIC:        case INTEGER:        case REAL:            result = processNumeric(data);            break;        case DATE:            result = processDate(data, idx);            break;        case STRING:                        result = processString(data);            break;        case NOMINAL:            String label = idxLabel.get(idx);            result = processNominal(label, data);            break;        default:            throw new IllegalStateException("Unknown type: " + type);    }    return result;}
protected double mahout_f691_0(String label, String data)
{    double result;    Map<String, Integer> classes = nominalMap.get(label);    if (classes != null) {        Integer ord = classes.get(ARFFType.removeQuotes(data));        if (ord != null) {            result = ord;        } else {            throw new IllegalStateException("Invalid nominal: " + data + " for label: " + label);        }    } else {        throw new IllegalArgumentException("Invalid nominal label: " + label + " Data: " + data);    }    return result;}
protected double mahout_f692_0(String data)
{    data = QUOTE_PATTERN.matcher(data).replaceAll("");        Long theLong = words.get(data);    if (theLong == null) {        theLong = wordCount++;        words.put(data, theLong);    }    return theLong;}
protected static double mahout_f693_0(String data)
{    if (isNumeric(data)) {        return Double.parseDouble(data);    }    return Double.NaN;}
public static boolean mahout_f694_0(String str)
{    NumberFormat formatter = NumberFormat.getInstance();    ParsePosition parsePosition = new ParsePosition(0);    formatter.parse(str, parsePosition);    return str.length() == parsePosition.getIndex();}
protected double mahout_f695_0(String data, int idx)
{    DateFormat format = dateMap.get(idx);    if (format == null) {        format = new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss", Locale.ENGLISH);    }    double result;    try {        Date date = format.parse(data);                result = date.getTime();    } catch (ParseException e) {        throw new IllegalArgumentException(e);    }    return result;}
public Map<String, Integer> mahout_f696_0()
{    return Collections.unmodifiableMap(labelBindings);}
public Map<Integer, ARFFType> mahout_f697_0()
{    return Collections.unmodifiableMap(typeMap);}
public Map<Integer, DateFormat> mahout_f698_0()
{    return Collections.unmodifiableMap(dateMap);}
public Map<String, Map<String, Integer>> mahout_f699_0()
{    return nominalMap;}
public Map<String, Long> mahout_f700_0()
{    return words;}
public Integer mahout_f701_0(String label, String nominal)
{    return nominalMap.get(label).get(nominal);}
public void mahout_f702_0(String label, String nominal, int idx)
{    Map<String, Integer> noms = nominalMap.get(label);    if (noms == null) {        noms = new HashMap<>();        nominalMap.put(label, noms);    }    noms.put(nominal, idx);}
public DateFormat mahout_f703_0(Integer idx)
{    return dateMap.get(idx);}
public void mahout_f704_0(Integer idx, DateFormat format)
{    dateMap.put(idx, format);}
public Integer mahout_f705_0(String label)
{    return labelBindings.get(label);}
public void mahout_f706_0(String label, Integer idx)
{    labelBindings.put(label, idx);    idxLabel.put(idx, label);}
public ARFFType mahout_f707_0(Integer idx)
{    return typeMap.get(idx);}
public void mahout_f708_0(Integer idx, ARFFType type)
{    typeMap.put(idx, type);}
public long mahout_f709_0()
{    return wordCount;}
public int mahout_f710_0()
{    return labelBindings.size();}
protected Vector mahout_f711_0()
{    String[] line;    try {        line = parser.getLine();    } catch (IOException e) {        throw new IllegalStateException(e);    }    if (line == null) {        return endOfData();    }    Vector result = new DenseVector(line.length);    for (int i = 0; i < line.length; i++) {        result.setQuick(i, Double.parseDouble(line[i]));    }    return result;}
public void mahout_f712_0(TermInfo ti) throws IOException
{    Iterator<TermEntry> entIter = ti.getAllEntries();    try {        writer.write(String.valueOf(ti.totalTerms(field)));        writer.write('\n');        writer.write("#term" + delimiter + "doc freq" + delimiter + "idx");        writer.write('\n');        while (entIter.hasNext()) {            TermEntry entry = entIter.next();            writer.write(entry.getTerm());            writer.write(delimiter);            writer.write(String.valueOf(entry.getDocFreq()));            writer.write(delimiter);            writer.write(String.valueOf(entry.getTermIdx()));            writer.write('\n');        }    } finally {        Closeables.close(writer, false);    }}
public void mahout_f713_0()
{}
public long mahout_f714_0(Iterable<Vector> iterable, long maxDocs) throws IOException
{    for (Vector point : iterable) {        if (recNum >= maxDocs) {            break;        }        if (point != null) {            writer.append(new LongWritable(recNum++), new VectorWritable(point));        }    }    return recNum;}
public void mahout_f715_0(Vector vector) throws IOException
{    writer.append(new LongWritable(recNum++), new VectorWritable(vector));}
public long mahout_f716_0(Iterable<Vector> iterable) throws IOException
{    return write(iterable, Long.MAX_VALUE);}
public void mahout_f717_0() throws IOException
{    Closeables.close(writer, false);}
public SequenceFile.Writer mahout_f718_0()
{    return writer;}
protected Writer mahout_f719_0()
{    return writer;}
public long mahout_f720_0(Iterable<Vector> iterable) throws IOException
{    return write(iterable, Long.MAX_VALUE);}
public long mahout_f721_0(Iterable<Vector> iterable, long maxDocs) throws IOException
{    long result = 0;    for (Vector vector : iterable) {        if (result >= maxDocs) {            break;        }        write(vector);        result++;    }    return result;}
public void mahout_f722_0(Vector vector) throws IOException
{    writer.write(vector.asFormatString());    writer.write('\n');}
public void mahout_f723_0() throws IOException
{    Closeables.close(writer, false);}
protected Vector mahout_f724_1()
{    try {        int doc;        Terms termFreqVector;        String name;        do {            doc = this.nextDocId;            nextDocId++;            if (doc >= indexReader.maxDoc()) {                return endOfData();            }            termFreqVector = indexReader.getTermVector(doc, field);            name = getVectorName(doc);            if (termFreqVector == null) {                numErrorDocs++;                if (numErrorDocs >= maxErrorDocs) {                                        throw new IllegalStateException("There are too many documents that do not have a term vector for " + field);                }                if (numErrorDocs >= nextLogRecord) {                    if (skippedErrorMessages == 0) {                                            } else {                                            }                    nextLogRecord = bump.increment();                    skippedErrorMessages = 0;                } else {                    skippedErrorMessages++;                }            }        } while (termFreqVector == null);                TermsEnum te = termFreqVector.iterator();        BytesRef term;        TFDFMapper mapper = new TFDFMapper(indexReader.numDocs(), weight, this.terminfo);        mapper.setExpectations(field, termFreqVector.size());        while ((term = te.next()) != null) {            mapper.map(term, (int) te.totalTermFreq());        }        Vector result = mapper.getVector();        if (result == null) {                        return null;        }        if (normPower == LuceneIterable.NO_NORMALIZING) {            result = new NamedVector(result, name);        } else {            result = new NamedVector(result.normalize(normPower), name);        }        return result;    } catch (IOException ioe) {        throw new IllegalStateException(ioe);    }}
public int mahout_f725_0(String field)
{    return termEntries.size();}
public TermEntry mahout_f726_0(String field, String term)
{    if (!this.field.equals(field)) {        return null;    }    return termEntries.get(term);}
public Iterator<TermEntry> mahout_f727_0()
{    return termEntries.values().iterator();}
public void mahout_f728_0() throws IOException
{    try (Writer writer = (this.output == null) ? new OutputStreamWriter(System.out, Charsets.UTF_8) : Files.newWriter(new File(this.output), Charsets.UTF_8)) {        for (Map.Entry<Integer, List<WeightedPropertyVectorWritable>> integerListEntry : clusterIdToPoints.entrySet()) {            List<WeightedPropertyVectorWritable> wpvws = integerListEntry.getValue();            List<TermInfoClusterInOut> termInfos = getClusterLabels(integerListEntry.getKey(), wpvws);            if (termInfos != null) {                writer.write('\n');                writer.write("Top labels for Cluster ");                writer.write(String.valueOf(integerListEntry.getKey()));                writer.write(" containing ");                writer.write(String.valueOf(wpvws.size()));                writer.write(" vectors");                writer.write('\n');                writer.write("Term \t\t LLR \t\t In-ClusterDF \t\t Out-ClusterDF ");                writer.write('\n');                for (TermInfoClusterInOut termInfo : termInfos) {                    writer.write(termInfo.getTerm());                    writer.write("\t\t");                    writer.write(String.valueOf(termInfo.getLogLikelihoodRatio()));                    writer.write("\t\t");                    writer.write(String.valueOf(termInfo.getInClusterDF()));                    writer.write("\t\t");                    writer.write(String.valueOf(termInfo.getOutClusterDF()));                    writer.write('\n');                }            }        }    }}
protected List<TermInfoClusterInOut> mahout_f729_1(Integer integer, Collection<WeightedPropertyVectorWritable> wpvws) throws IOException
{    if (wpvws.size() < minNumIds) {                return null;    }        Directory dir = FSDirectory.open(Paths.get(this.indexDir));    IndexReader reader = DirectoryReader.open(dir);        Collection<String> idSet = new HashSet<>();    for (WeightedPropertyVectorWritable wpvw : wpvws) {        Vector vector = wpvw.getVector();        if (vector instanceof NamedVector) {            idSet.add(((NamedVector) vector).getName());        }    }    int numDocs = reader.numDocs();    FixedBitSet clusterDocBitset = getClusterDocBitset(reader, idSet, this.idField);        /**     * This code is as that of CachedTermInfo, with one major change, which is to get the document frequency.     *     * Since we have deleted the documents out of the cluster, the document frequency for a term should only     * include the in-cluster documents. The document frequency obtained from TermEnum reflects the frequency     * in the entire index. To get the in-cluster frequency, we need to query the index to get the term     * frequencies in each document. The number of results of this call will be the in-cluster document     * frequency.     */    Terms t = MultiFields.getTerms(reader, contentField);    TermsEnum te = t.iterator();    Map<String, TermEntry> termEntryMap = new LinkedHashMap<>();        Bits liveDocs = MultiFields.getLiveDocs(reader);    int count = 0;    BytesRef term;    while ((term = te.next()) != null) {        FixedBitSet termBitset = new FixedBitSet(reader.maxDoc());        PostingsEnum docsEnum = MultiFields.getTermDocsEnum(reader, contentField, term);        int docID;        while ((docID = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {                        if (liveDocs != null && !liveDocs.get(docID)) {                                termBitset.set(docsEnum.docID());            }        }                        termBitset.and(clusterDocBitset);        int inclusterDF = (int) termBitset.cardinality();        TermEntry entry = new TermEntry(term.utf8ToString(), count++, inclusterDF);        termEntryMap.put(entry.getTerm(), entry);    }    List<TermInfoClusterInOut> clusteredTermInfo = new LinkedList<>();    int clusterSize = wpvws.size();    for (TermEntry termEntry : termEntryMap.values()) {        int corpusDF = reader.docFreq(new Term(this.contentField, termEntry.getTerm()));        int outDF = corpusDF - termEntry.getDocFreq();        int inDF = termEntry.getDocFreq();        double logLikelihoodRatio = scoreDocumentFrequencies(inDF, outDF, clusterSize, numDocs);        TermInfoClusterInOut termInfoCluster = new TermInfoClusterInOut(termEntry.getTerm(), inDF, outDF, logLikelihoodRatio);        clusteredTermInfo.add(termInfoCluster);    }    Collections.sort(clusteredTermInfo);        Closeables.close(reader, true);    termEntryMap.clear();    return clusteredTermInfo.subList(0, Math.min(clusteredTermInfo.size(), maxLabels));}
private static FixedBitSet mahout_f730_1(IndexReader reader, Collection<String> idSet, String idField) throws IOException
{    int numDocs = reader.numDocs();    FixedBitSet bitset = new FixedBitSet(numDocs);    Set<String> idFieldSelector = null;    if (idField != null) {        idFieldSelector = new TreeSet<>();        idFieldSelector.add(idField);    }    for (int i = 0; i < numDocs; i++) {        String id;                if (idField == null) {            id = Integer.toString(i);        } else {            id = reader.document(i, idFieldSelector).get(idField);        }        if (idSet.contains(id)) {            bitset.set(i);        }    }        return bitset;}
private static double mahout_f731_0(long inDF, long outDF, long clusterSize, long corpusSize)
{    long k12 = clusterSize - inDF;    long k22 = corpusSize - clusterSize - outDF;    return LogLikelihood.logLikelihoodRatio(inDF, k12, outDF, k22);}
public String mahout_f732_0()
{    return idField;}
public void mahout_f733_0(String idField)
{    this.idField = idField;}
public String mahout_f734_0()
{    return output;}
public void mahout_f735_0(String output)
{    this.output = output;}
public static void mahout_f736_1(String[] args)
{    DefaultOptionBuilder obuilder = new DefaultOptionBuilder();    ArgumentBuilder abuilder = new ArgumentBuilder();    GroupBuilder gbuilder = new GroupBuilder();    Option indexOpt = obuilder.withLongName("dir").withRequired(true).withArgument(abuilder.withName("dir").withMinimum(1).withMaximum(1).create()).withDescription("The Lucene index directory").withShortName("d").create();    Option outputOpt = obuilder.withLongName("output").withRequired(false).withArgument(abuilder.withName("output").withMinimum(1).withMaximum(1).create()).withDescription("The output file. If not specified, the result is printed on console.").withShortName("o").create();    Option fieldOpt = obuilder.withLongName("field").withRequired(true).withArgument(abuilder.withName("field").withMinimum(1).withMaximum(1).create()).withDescription("The content field in the index").withShortName("f").create();    Option idFieldOpt = obuilder.withLongName("idField").withRequired(false).withArgument(abuilder.withName("idField").withMinimum(1).withMaximum(1).create()).withDescription("The field for the document ID in the index.  If null, then the Lucene internal doc " + "id is used which is prone to error if the underlying index changes").withShortName("i").create();    Option seqOpt = obuilder.withLongName("seqFileDir").withRequired(true).withArgument(abuilder.withName("seqFileDir").withMinimum(1).withMaximum(1).create()).withDescription("The directory containing Sequence Files for the Clusters").withShortName("s").create();    Option pointsOpt = obuilder.withLongName("pointsDir").withRequired(true).withArgument(abuilder.withName("pointsDir").withMinimum(1).withMaximum(1).create()).withDescription("The directory containing points sequence files mapping input vectors to their cluster.  ").withShortName("p").create();    Option minClusterSizeOpt = obuilder.withLongName("minClusterSize").withRequired(false).withArgument(abuilder.withName("minClusterSize").withMinimum(1).withMaximum(1).create()).withDescription("The minimum number of points required in a cluster to print the labels for").withShortName("m").create();    Option maxLabelsOpt = obuilder.withLongName("maxLabels").withRequired(false).withArgument(abuilder.withName("maxLabels").withMinimum(1).withMaximum(1).create()).withDescription("The maximum number of labels to print per cluster").withShortName("x").create();    Option helpOpt = DefaultOptionCreator.helpOption();    Group group = gbuilder.withName("Options").withOption(indexOpt).withOption(idFieldOpt).withOption(outputOpt).withOption(fieldOpt).withOption(seqOpt).withOption(pointsOpt).withOption(helpOpt).withOption(maxLabelsOpt).withOption(minClusterSizeOpt).create();    try {        Parser parser = new Parser();        parser.setGroup(group);        CommandLine cmdLine = parser.parse(args);        if (cmdLine.hasOption(helpOpt)) {            CommandLineUtil.printHelp(group);            return;        }        Path seqFileDir = new Path(cmdLine.getValue(seqOpt).toString());        Path pointsDir = new Path(cmdLine.getValue(pointsOpt).toString());        String indexDir = cmdLine.getValue(indexOpt).toString();        String contentField = cmdLine.getValue(fieldOpt).toString();        String idField = null;        if (cmdLine.hasOption(idFieldOpt)) {            idField = cmdLine.getValue(idFieldOpt).toString();        }        String output = null;        if (cmdLine.hasOption(outputOpt)) {            output = cmdLine.getValue(outputOpt).toString();        }        int maxLabels = DEFAULT_MAX_LABELS;        if (cmdLine.hasOption(maxLabelsOpt)) {            maxLabels = Integer.parseInt(cmdLine.getValue(maxLabelsOpt).toString());        }        int minSize = DEFAULT_MIN_IDS;        if (cmdLine.hasOption(minClusterSizeOpt)) {            minSize = Integer.parseInt(cmdLine.getValue(minClusterSizeOpt).toString());        }        ClusterLabels clusterLabel = new ClusterLabels(seqFileDir, pointsDir, indexDir, contentField, minSize, maxLabels);        if (idField != null) {            clusterLabel.setIdField(idField);        }        if (output != null) {            clusterLabel.setOutput(output);        }        clusterLabel.getLabels();    } catch (OptionException e) {                CommandLineUtil.printHelp(group);    } catch (IOException e) {            }}
public void mahout_f737_1() throws IOException
{    File file = new File(luceneDir);    Preconditions.checkArgument(file.isDirectory(), "Lucene directory: " + file.getAbsolutePath() + " does not exist or is not a directory");    Preconditions.checkArgument(maxDocs >= 0, "maxDocs must be >= 0");    Preconditions.checkArgument(minDf >= 1, "minDf must be >= 1");    Preconditions.checkArgument(maxDFPercent <= 99, "maxDFPercent must be <= 99");    Directory dir = FSDirectory.open(Paths.get(file.getAbsolutePath()));    IndexReader reader = DirectoryReader.open(dir);    Weight weight;    if ("tf".equalsIgnoreCase(weightType)) {        weight = new TF();    } else if ("tfidf".equalsIgnoreCase(weightType)) {        weight = new TFIDF();    } else {        throw new IllegalArgumentException("Weight type " + weightType + " is not supported");    }    TermInfo termInfo = new CachedTermInfo(reader, field, minDf, maxDFPercent);    LuceneIterable iterable;    if (norm == LuceneIterable.NO_NORMALIZING) {        iterable = new LuceneIterable(reader, idField, field, termInfo, weight, LuceneIterable.NO_NORMALIZING, maxPercentErrorDocs);    } else {        iterable = new LuceneIterable(reader, idField, field, termInfo, weight, norm, maxPercentErrorDocs);    }        try (VectorWriter vectorWriter = getSeqFileWriter(outFile)) {        long numDocs = vectorWriter.write(iterable, maxDocs);            }    File dictOutFile = new File(dictOut);        Writer writer = Files.newWriter(dictOutFile, Charsets.UTF_8);    try (DelimitedTermInfoWriter tiWriter = new DelimitedTermInfoWriter(writer, delimiter, field)) {        tiWriter.write(termInfo);    }    if (!"".equals(seqDictOut)) {                Path path = new Path(seqDictOut);        Configuration conf = new Configuration();        FileSystem fs = FileSystem.get(conf);        try (SequenceFile.Writer seqWriter = SequenceFile.createWriter(fs, conf, path, Text.class, IntWritable.class)) {            Text term = new Text();            IntWritable termIndex = new IntWritable();            Iterator<TermEntry> termEntries = termInfo.getAllEntries();            while (termEntries.hasNext()) {                TermEntry termEntry = termEntries.next();                term.set(termEntry.getTerm());                termIndex.set(termEntry.getTermIdx());                seqWriter.append(term, termIndex);            }        }    }}
public static void mahout_f738_1(String[] args) throws IOException
{    DefaultOptionBuilder obuilder = new DefaultOptionBuilder();    ArgumentBuilder abuilder = new ArgumentBuilder();    GroupBuilder gbuilder = new GroupBuilder();    Option inputOpt = obuilder.withLongName("dir").withRequired(true).withArgument(abuilder.withName("dir").withMinimum(1).withMaximum(1).create()).withDescription("The Lucene directory").withShortName("d").create();    Option outputOpt = obuilder.withLongName("output").withRequired(true).withArgument(abuilder.withName("output").withMinimum(1).withMaximum(1).create()).withDescription("The output file").withShortName("o").create();    Option fieldOpt = obuilder.withLongName("field").withRequired(true).withArgument(abuilder.withName("field").withMinimum(1).withMaximum(1).create()).withDescription("The field in the index").withShortName("f").create();    Option idFieldOpt = obuilder.withLongName("idField").withRequired(false).withArgument(abuilder.withName("idField").withMinimum(1).withMaximum(1).create()).withDescription("The field in the index containing the index.  If null, then the Lucene internal doc " + "id is used which is prone to error if the underlying index changes").create();    Option dictOutOpt = obuilder.withLongName("dictOut").withRequired(true).withArgument(abuilder.withName("dictOut").withMinimum(1).withMaximum(1).create()).withDescription("The output of the dictionary").withShortName("t").create();    Option seqDictOutOpt = obuilder.withLongName("seqDictOut").withRequired(false).withArgument(abuilder.withName("seqDictOut").withMinimum(1).withMaximum(1).create()).withDescription("The output of the dictionary as sequence file").withShortName("st").create();    Option weightOpt = obuilder.withLongName("weight").withRequired(false).withArgument(abuilder.withName("weight").withMinimum(1).withMaximum(1).create()).withDescription("The kind of weight to use. Currently TF or TFIDF").withShortName("w").create();    Option delimiterOpt = obuilder.withLongName("delimiter").withRequired(false).withArgument(abuilder.withName("delimiter").withMinimum(1).withMaximum(1).create()).withDescription("The delimiter for outputting the dictionary").withShortName("l").create();    Option powerOpt = obuilder.withLongName("norm").withRequired(false).withArgument(abuilder.withName("norm").withMinimum(1).withMaximum(1).create()).withDescription("The norm to use, expressed as either a double or \"INF\" if you want to use the Infinite norm.  " + "Must be greater or equal to 0.  The default is not to normalize").withShortName("n").create();    Option maxOpt = obuilder.withLongName("max").withRequired(false).withArgument(abuilder.withName("max").withMinimum(1).withMaximum(1).create()).withDescription("The maximum number of vectors to output.  If not specified, then it will loop over all docs").withShortName("m").create();    Option minDFOpt = obuilder.withLongName("minDF").withRequired(false).withArgument(abuilder.withName("minDF").withMinimum(1).withMaximum(1).create()).withDescription("The minimum document frequency.  Default is 1").withShortName("md").create();    Option maxDFPercentOpt = obuilder.withLongName("maxDFPercent").withRequired(false).withArgument(abuilder.withName("maxDFPercent").withMinimum(1).withMaximum(1).create()).withDescription("The max percentage of docs for the DF.  Can be used to remove really high frequency terms." + "  Expressed as an integer between 0 and 100. Default is 99.").withShortName("x").create();    Option maxPercentErrorDocsOpt = obuilder.withLongName("maxPercentErrorDocs").withRequired(false).withArgument(abuilder.withName("maxPercentErrorDocs").withMinimum(1).withMaximum(1).create()).withDescription("The max percentage of docs that can have a null term vector. These are noise document and can occur if the " + "analyzer used strips out all terms in the target field. This percentage is expressed as a value " + "between 0 and 1. The default is 0.").withShortName("err").create();    Option helpOpt = obuilder.withLongName("help").withDescription("Print out help").withShortName("h").create();    Group group = gbuilder.withName("Options").withOption(inputOpt).withOption(idFieldOpt).withOption(outputOpt).withOption(delimiterOpt).withOption(helpOpt).withOption(fieldOpt).withOption(maxOpt).withOption(dictOutOpt).withOption(seqDictOutOpt).withOption(powerOpt).withOption(maxDFPercentOpt).withOption(weightOpt).withOption(minDFOpt).withOption(maxPercentErrorDocsOpt).create();    try {        Parser parser = new Parser();        parser.setGroup(group);        CommandLine cmdLine = parser.parse(args);        if (cmdLine.hasOption(helpOpt)) {            CommandLineUtil.printHelp(group);            return;        }        if (cmdLine.hasOption(inputOpt)) {                        Driver luceneDriver = new Driver();            luceneDriver.setLuceneDir(cmdLine.getValue(inputOpt).toString());            if (cmdLine.hasOption(maxOpt)) {                luceneDriver.setMaxDocs(Long.parseLong(cmdLine.getValue(maxOpt).toString()));            }            if (cmdLine.hasOption(weightOpt)) {                luceneDriver.setWeightType(cmdLine.getValue(weightOpt).toString());            }            luceneDriver.setField(cmdLine.getValue(fieldOpt).toString());            if (cmdLine.hasOption(minDFOpt)) {                luceneDriver.setMinDf(Integer.parseInt(cmdLine.getValue(minDFOpt).toString()));            }            if (cmdLine.hasOption(maxDFPercentOpt)) {                luceneDriver.setMaxDFPercent(Integer.parseInt(cmdLine.getValue(maxDFPercentOpt).toString()));            }            if (cmdLine.hasOption(powerOpt)) {                String power = cmdLine.getValue(powerOpt).toString();                if ("INF".equals(power)) {                    luceneDriver.setNorm(Double.POSITIVE_INFINITY);                } else {                    luceneDriver.setNorm(Double.parseDouble(power));                }            }            if (cmdLine.hasOption(idFieldOpt)) {                luceneDriver.setIdField(cmdLine.getValue(idFieldOpt).toString());            }            if (cmdLine.hasOption(maxPercentErrorDocsOpt)) {                luceneDriver.setMaxPercentErrorDocs(Double.parseDouble(cmdLine.getValue(maxPercentErrorDocsOpt).toString()));            }            luceneDriver.setOutFile(cmdLine.getValue(outputOpt).toString());            luceneDriver.setDelimiter(cmdLine.hasOption(delimiterOpt) ? cmdLine.getValue(delimiterOpt).toString() : "\t");            luceneDriver.setDictOut(cmdLine.getValue(dictOutOpt).toString());            if (cmdLine.hasOption(seqDictOutOpt)) {                luceneDriver.setSeqDictOut(cmdLine.getValue(seqDictOutOpt).toString());            }            luceneDriver.dumpVectors();        }    } catch (OptionException e) {                CommandLineUtil.printHelp(group);    }}
private static VectorWriter mahout_f739_0(String outFile) throws IOException
{    Path path = new Path(outFile);    Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);        SequenceFile.Writer seqWriter = SequenceFile.createWriter(fs, conf, path, LongWritable.class, VectorWritable.class);    return new SequenceFileVectorWriter(seqWriter);}
public void mahout_f740_0(String luceneDir)
{    this.luceneDir = luceneDir;}
public void mahout_f741_0(long maxDocs)
{    this.maxDocs = maxDocs;}
public void mahout_f742_0(String weightType)
{    this.weightType = weightType;}
public void mahout_f743_0(String field)
{    this.field = field;}
public void mahout_f744_0(int minDf)
{    this.minDf = minDf;}
public void mahout_f745_0(int maxDFPercent)
{    this.maxDFPercent = maxDFPercent;}
public void mahout_f746_0(double norm)
{    this.norm = norm;}
public void mahout_f747_0(String idField)
{    this.idField = idField;}
public void mahout_f748_0(String outFile)
{    this.outFile = outFile;}
public void mahout_f749_0(String delimiter)
{    this.delimiter = delimiter;}
public void mahout_f750_0(String dictOut)
{    this.dictOut = dictOut;}
public void mahout_f751_0(String seqDictOut)
{    this.seqDictOut = seqDictOut;}
public void mahout_f752_0(double maxPercentErrorDocs)
{    this.maxPercentErrorDocs = maxPercentErrorDocs;}
public Iterator<Vector> mahout_f753_0()
{    return new LuceneIterator(indexReader, idField, field, terminfo, weight, normPower, maxPercentErrorDocs);}
protected String mahout_f754_0(int documentIndex) throws IOException
{    String name;    if (idField != null) {        name = indexReader.document(documentIndex, idFieldSelector).get(idField);    } else {        name = String.valueOf(documentIndex);    }    return name;}
public int mahout_f755_0()
{    return term.hashCode() ^ inClusterDF ^ outClusterDF ^ RandomUtils.hashDouble(logLikelihoodRatio);}
public boolean mahout_f756_0(Object o)
{    if (!(o instanceof TermInfoClusterInOut)) {        return false;    }    TermInfoClusterInOut other = (TermInfoClusterInOut) o;    return term.equals(other.getTerm()) && inClusterDF == other.getInClusterDF() && outClusterDF == other.getOutClusterDF() && logLikelihoodRatio == other.getLogLikelihoodRatio();}
public int mahout_f757_0(TermInfoClusterInOut that)
{    int res = Double.compare(that.logLikelihoodRatio, logLikelihoodRatio);    if (res == 0) {        res = term.compareTo(that.term);    }    return res;}
public int mahout_f758_0()
{    return this.inClusterDF - this.outClusterDF;}
 String mahout_f759_0()
{    return term;}
 int mahout_f760_0()
{    return inClusterDF;}
 int mahout_f761_0()
{    return outClusterDF;}
 double mahout_f762_0()
{    return logLikelihoodRatio;}
public void mahout_f763_0(String field, long numTerms)
{    this.field = field;    vector = new RandomAccessSparseVector(termInfo.totalTerms(field));    this.numTerms = numTerms;}
public void mahout_f764_0(BytesRef term, int frequency)
{    TermEntry entry = termInfo.getTermEntry(field, term.utf8ToString());    if (entry != null) {        vector.setQuick(entry.getTermIdx(), weight.calculate(frequency, entry.getDocFreq(), (int) numTerms, numDocs));    }}
public Vector mahout_f765_0()
{    return this.vector;}
public int mahout_f766_1(String[] args) throws Exception
{    addInputOption();    addOutputOption();    Map<String, List<String>> parsedArgs = parseArguments(args);    if (parsedArgs == null) {        return -1;    }    Configuration conf = getConf();    FileSystem fs = FileSystem.get(conf);    Path outputPath = getOutputPath();    Path indexPath = new Path(outputPath, "docIndex");    Path matrixPath = new Path(outputPath, "matrix");    try (SequenceFile.Writer indexWriter = SequenceFile.createWriter(fs, conf, indexPath, IntWritable.class, Text.class);        SequenceFile.Writer matrixWriter = SequenceFile.createWriter(fs, conf, matrixPath, IntWritable.class, VectorWritable.class)) {        IntWritable docId = new IntWritable();        int i = 0;        int numCols = 0;        for (Pair<Text, VectorWritable> record : new SequenceFileDirIterable<Text, VectorWritable>(getInputPath(), PathType.LIST, PathFilters.logsCRCFilter(), null, true, conf)) {            VectorWritable value = record.getSecond();            docId.set(i);            indexWriter.append(docId, record.getFirst());            matrixWriter.append(docId, value);            i++;            numCols = value.get().size();        }                return 0;    }}
public static void mahout_f767_0(String[] args) throws Exception
{    ToolRunner.run(new RowIdJob(), args);}
public String mahout_f768_0()
{    return term;}
public int mahout_f769_0()
{    return termIdx;}
public int mahout_f770_0()
{    return docFreq;}
public int mahout_f771_1(String[] args) throws Exception
{    /**     *     Option seqOpt = obuilder.withLongName("seqFile").withRequired(false).withArgument(     *     abuilder.withName("seqFile").withMinimum(1).withMaximum(1).create()).withDescription(     *     "The Sequence File containing the Vectors").withShortName("s").create();     *     Option dirOpt = obuilder.withLongName("seqDirectory").withRequired(false).withArgument(     *     abuilder.withName("seqDirectory").withMinimum(1).withMaximum(1).create())     *     .withDescription("The directory containing Sequence File of Vectors")     *     .withShortName("d").create();     */    addInputOption();    addOutputOption();    addOption("useKey", "u", "If the Key is a vector than dump that instead");    addOption("printKey", "p", "Print out the key as well, delimited by tab (or the value if useKey is true");    addOption("dictionary", "d", "The dictionary file.", false);    addOption("dictionaryType", "dt", "The dictionary file type (text|seqfile)", false);    addOption("csv", "c", "Output the Vector as CSV.  Otherwise it substitutes in the terms for vector cell entries");    addOption("namesAsComments", "n", "If using CSV output, optionally add a comment line for each NamedVector " + "(if the vector is one) printing out the name");    addOption("nameOnly", "N", "Use the name as the value for each NamedVector (skip other vectors)");    addOption("sortVectors", "sort", "Sort output key/value pairs of the vector entries in abs magnitude " + "descending order");    addOption("quiet", "q", "Print only file contents");    addOption("sizeOnly", "sz", "Dump only the size of the vector");    addOption("numItems", "ni", "Output at most <n> vecors", false);    addOption("vectorSize", "vs", "Truncate vectors to <vs> length when dumping (most useful when in" + " conjunction with -sort", false);    addOption(buildOption("filter", "fi", "Only dump out those vectors whose name matches the filter." + "  Multiple items may be specified by repeating the argument.", true, 1, Integer.MAX_VALUE, false, null));    if (parseArguments(args, false, true) == null) {        return -1;    }    Path[] pathArr;    Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);    Path input = getInputPath();    FileStatus fileStatus = fs.getFileStatus(input);    if (fileStatus.isDir()) {        pathArr = FileUtil.stat2Paths(fs.listStatus(input, PathFilters.logsCRCFilter()));    } else {        FileStatus[] inputPaths = fs.globStatus(input);        pathArr = new Path[inputPaths.length];        int i = 0;        for (FileStatus fstatus : inputPaths) {            pathArr[i++] = fstatus.getPath();        }    }    String dictionaryType = getOption("dictionaryType", "text");    boolean sortVectors = hasOption("sortVectors");    boolean quiet = hasOption("quiet");    if (!quiet) {            }    String[] dictionary = null;    if (hasOption("dictionary")) {        String dictFile = getOption("dictionary");        switch(dictionaryType) {            case "text":                dictionary = VectorHelper.loadTermDictionary(new File(dictFile));                break;            case "sequencefile":                dictionary = VectorHelper.loadTermDictionary(conf, dictFile);                break;            default:                                throw new IOException("Invalid dictionary type: " + dictionaryType);        }    }    Set<String> filters;    if (hasOption("filter")) {        filters = Sets.newHashSet(getOptions("filter"));    } else {        filters = null;    }    boolean useCSV = hasOption("csv");    boolean sizeOnly = hasOption("sizeOnly");    boolean nameOnly = hasOption("nameOnly");    boolean namesAsComments = hasOption("namesAsComments");    boolean transposeKeyValue = hasOption("vectorAsKey");    Writer writer;    boolean shouldClose;    File output = getOutputFile();    if (output != null) {        shouldClose = true;                Files.createParentDirs(output);        writer = Files.newWriter(output, Charsets.UTF_8);    } else {        shouldClose = false;        writer = new OutputStreamWriter(System.out, Charsets.UTF_8);    }    try {        boolean printKey = hasOption("printKey");        if (useCSV && dictionary != null) {            writer.write("#");            for (int j = 0; j < dictionary.length; j++) {                writer.write(dictionary[j]);                if (j < dictionary.length - 1) {                    writer.write(',');                }            }            writer.write('\n');        }        Long numItems = null;        if (hasOption("numItems")) {            numItems = Long.parseLong(getOption("numItems"));            if (quiet) {                writer.append("#Max Items to dump: ").append(String.valueOf(numItems)).append('\n');            }        }        int maxIndexesPerVector = hasOption("vectorSize") ? Integer.parseInt(getOption("vectorSize")) : Integer.MAX_VALUE;        long itemCount = 0;        int fileCount = 0;        for (Path path : pathArr) {            if (numItems != null && numItems <= itemCount) {                break;            }            if (quiet) {                            }            SequenceFileIterable<Writable, Writable> iterable = new SequenceFileIterable<>(path, true, conf);            Iterator<Pair<Writable, Writable>> iterator = iterable.iterator();            long i = 0;            while (iterator.hasNext() && (numItems == null || itemCount < numItems)) {                Pair<Writable, Writable> record = iterator.next();                Writable keyWritable = record.getFirst();                Writable valueWritable = record.getSecond();                if (printKey) {                    Writable notTheVectorWritable = transposeKeyValue ? valueWritable : keyWritable;                    writer.write(notTheVectorWritable.toString());                    writer.write('\t');                }                Vector vector;                try {                    vector = ((VectorWritable) (transposeKeyValue ? keyWritable : valueWritable)).get();                } catch (ClassCastException e) {                    if ((transposeKeyValue ? keyWritable : valueWritable) instanceof WeightedPropertyVectorWritable) {                        vector = ((WeightedPropertyVectorWritable) (transposeKeyValue ? keyWritable : valueWritable)).getVector();                    } else {                        throw e;                    }                }                if (filters == null || !(vector instanceof NamedVector) || filters.contains(((NamedVector) vector).getName())) {                    if (sizeOnly) {                        if (vector instanceof NamedVector) {                            writer.write(((NamedVector) vector).getName());                            writer.write(":");                        } else {                            writer.write(String.valueOf(i++));                            writer.write(":");                        }                        writer.write(String.valueOf(vector.size()));                        writer.write('\n');                    } else if (nameOnly) {                        if (vector instanceof NamedVector) {                            writer.write(((NamedVector) vector).getName());                            writer.write('\n');                        }                    } else {                        String fmtStr;                        if (useCSV) {                            fmtStr = VectorHelper.vectorToCSVString(vector, namesAsComments);                        } else {                            fmtStr = VectorHelper.vectorToJson(vector, dictionary, maxIndexesPerVector, sortVectors);                        }                        writer.write(fmtStr);                        writer.write('\n');                    }                    itemCount++;                }            }        }        writer.flush();    } finally {        if (shouldClose) {            Closeables.close(writer, false);        }    }    return 0;}
public static void mahout_f772_0(String[] args) throws Exception
{    ToolRunner.run(new Configuration(), new VectorDumper(), args);}
public static String mahout_f773_0(Vector vector, boolean namesAsComments) throws IOException
{    Appendable bldr = new StringBuilder(2048);    vectorToCSVString(vector, namesAsComments, bldr);    return bldr.toString();}
public static String mahout_f774_0(Iterable<Pair<String, Double>> iterable)
{    return buildJson(iterable, new StringBuilder(2048));}
public static String mahout_f775_0(Iterable<Pair<String, Double>> iterable, StringBuilder bldr)
{    bldr.append('{');    for (Pair<String, Double> p : iterable) {        bldr.append(p.getFirst());        bldr.append(':');        bldr.append(p.getSecond());        bldr.append(',');    }    if (bldr.length() > 1) {        bldr.setCharAt(bldr.length() - 1, '}');    }    return bldr.toString();}
public static List<Pair<Integer, Double>> mahout_f776_0(Vector vector, int maxEntries)
{        int sizeOfNonZeroElementsInVector = vector.getNumNonZeroElements();        if (sizeOfNonZeroElementsInVector < maxEntries) {        maxEntries = sizeOfNonZeroElementsInVector;    }    PriorityQueue<Pair<Integer, Double>> queue = new TDoublePQ<>(-1, maxEntries);    for (Element e : vector.nonZeroes()) {        queue.insertWithOverflow(Pair.of(e.index(), e.get()));    }    List<Pair<Integer, Double>> entries = new ArrayList<>();    Pair<Integer, Double> pair;    while ((pair = queue.pop()) != null) {        if (pair.getFirst() > -1) {            entries.add(pair);        }    }    Collections.sort(entries, new Comparator<Pair<Integer, Double>>() {        @Override        public int compare(Pair<Integer, Double> a, Pair<Integer, Double> b) {            return b.getSecond().compareTo(a.getSecond());        }    });    return entries;}
public int mahout_f777_0(Pair<Integer, Double> a, Pair<Integer, Double> b)
{    return b.getSecond().compareTo(a.getSecond());}
public static List<Pair<Integer, Double>> mahout_f778_0(Vector vector, int maxEntries)
{    List<Pair<Integer, Double>> entries = new ArrayList<>();    Iterator<Vector.Element> it = vector.nonZeroes().iterator();    int i = 0;    while (it.hasNext() && i++ < maxEntries) {        Vector.Element e = it.next();        entries.add(Pair.of(e.index(), e.get()));    }    return entries;}
public static List<Pair<String, Double>> mahout_f779_0(Collection<Pair<Integer, Double>> entries, final String[] dictionary)
{    if (dictionary != null) {        return new ArrayList<>(Collections2.transform(entries, new Function<Pair<Integer, Double>, Pair<String, Double>>() {            @Override            public Pair<String, Double> apply(Pair<Integer, Double> p) {                return Pair.of(dictionary[p.getFirst()], p.getSecond());            }        }));    } else {        return new ArrayList<>(Collections2.transform(entries, new Function<Pair<Integer, Double>, Pair<String, Double>>() {            @Override            public Pair<String, Double> apply(Pair<Integer, Double> p) {                return Pair.of(Integer.toString(p.getFirst()), p.getSecond());            }        }));    }}
public Pair<String, Double> mahout_f780_0(Pair<Integer, Double> p)
{    return Pair.of(dictionary[p.getFirst()], p.getSecond());}
public Pair<String, Double> mahout_f781_0(Pair<Integer, Double> p)
{    return Pair.of(Integer.toString(p.getFirst()), p.getSecond());}
public static String mahout_f782_0(Vector vector, String[] dictionary, int maxEntries, boolean sort)
{    return buildJson(toWeightedTerms(sort ? topEntries(vector, maxEntries) : firstEntries(vector, maxEntries), dictionary));}
public static void mahout_f783_0(Vector vector, boolean namesAsComments, Appendable bldr) throws IOException
{    if (namesAsComments && vector instanceof NamedVector) {        bldr.append('#').append(((NamedVector) vector).getName()).append('\n');    }    Iterator<Vector.Element> iter = vector.all().iterator();    boolean first = true;    while (iter.hasNext()) {        if (first) {            first = false;        } else {            bldr.append(',');        }        Vector.Element elt = iter.next();        bldr.append(String.valueOf(elt.get()));    }    bldr.append('\n');}
public static String[] mahout_f784_0(File dictFile) throws IOException
{    try (InputStream in = new FileInputStream(dictFile)) {        return loadTermDictionary(in);    }}
public static String[] mahout_f785_0(Configuration conf, String filePattern)
{    OpenObjectIntHashMap<String> dict = new OpenObjectIntHashMap<>();    int maxIndexValue = 0;    for (Pair<Text, IntWritable> record : new SequenceFileDirIterable<Text, IntWritable>(new Path(filePattern), PathType.GLOB, null, null, true, conf)) {        dict.put(record.getFirst().toString(), record.getSecond().get());        if (record.getSecond().get() > maxIndexValue) {            maxIndexValue = record.getSecond().get();        }    }        int maxDictionarySize = maxIndexValue + 1 > dict.size() ? maxIndexValue + 1 : dict.size();    String[] dictionary = new String[maxDictionarySize];    for (String feature : dict.keys()) {        dictionary[dict.get(feature)] = feature;    }    return dictionary;}
private static String[] mahout_f786_0(InputStream is) throws IOException
{    FileLineIterator it = new FileLineIterator(is);    int numEntries = Integer.parseInt(it.next());    String[] result = new String[numEntries];    while (it.hasNext()) {        String line = it.next();        if (line.startsWith("#")) {            continue;        }        String[] tokens = TAB_PATTERN.split(line);        if (tokens.length < 3) {            continue;        }                int index = Integer.parseInt(tokens[2]);        result[index] = tokens[0];    }    return result;}
protected boolean mahout_f787_0(Pair<T, Double> a, Pair<T, Double> b)
{    return a.getSecond().compareTo(b.getSecond()) < 0;}
protected Pair<T, Double> mahout_f788_0()
{    return Pair.of(sentinel, Double.NEGATIVE_INFINITY);}
public void mahout_f789_0() throws Exception
{    DataSource dataSource = EasyMock.createMock(DataSource.class);    Connection connection = EasyMock.createMock(Connection.class);    PreparedStatement statement = EasyMock.createMock(PreparedStatement.class);    ResultSet resultSet = EasyMock.createMock(ResultSet.class);    EasyMock.expect(dataSource.getConnection()).andReturn(connection);    EasyMock.expect(connection.prepareStatement(MySQLJDBCInMemoryItemSimilarity.DEFAULT_GET_ALL_ITEMSIMILARITIES_SQL, ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY)).andReturn(statement);    statement.setFetchDirection(ResultSet.FETCH_FORWARD);    EasyMock.expect(statement.executeQuery()).andReturn(resultSet);    EasyMock.expect(resultSet.next()).andReturn(true);    EasyMock.expect(resultSet.getLong(1)).andReturn(1L);    EasyMock.expect(resultSet.getLong(2)).andReturn(2L);    EasyMock.expect(resultSet.getDouble(3)).andReturn(0.5);    EasyMock.expect(resultSet.next()).andReturn(true);    EasyMock.expect(resultSet.getLong(1)).andReturn(1L);    EasyMock.expect(resultSet.getLong(2)).andReturn(3L);    EasyMock.expect(resultSet.getDouble(3)).andReturn(0.4);    EasyMock.expect(resultSet.next()).andReturn(true);    EasyMock.expect(resultSet.getLong(1)).andReturn(3L);    EasyMock.expect(resultSet.getLong(2)).andReturn(4L);    EasyMock.expect(resultSet.getDouble(3)).andReturn(0.1);    EasyMock.expect(resultSet.next()).andReturn(false);    resultSet.close();    statement.close();    connection.close();    EasyMock.replay(dataSource, connection, statement, resultSet);    ItemSimilarity similarity = new MySQLJDBCInMemoryItemSimilarity(dataSource);    assertEquals(0.5, similarity.itemSimilarity(1L, 2L), EPSILON);    assertEquals(0.4, similarity.itemSimilarity(1L, 3L), EPSILON);    assertEquals(0.1, similarity.itemSimilarity(3L, 4L), EPSILON);    assertTrue(Double.isNaN(similarity.itemSimilarity(1L, 4L)));    EasyMock.verify(dataSource, connection, statement, resultSet);}
public void mahout_f790_0() throws Exception
{    super.setUp();    conf = getConfiguration();    fs = FileSystem.get(conf);    testdata = getTestTempDirPath("testdata");    output = getTestTempDirPath("output");        referenceData = TestKmeansClustering.getPointsWritable(REFERENCE);        generateSamples();}
private void mahout_f791_0(double dC, double dP, DistanceMeasure measure)
{    clusters = new ArrayList<>();    clusters.add(new Canopy(new DenseVector(new double[] { -dC, -dC }), 1, measure));    clusters.add(new Canopy(new DenseVector(new double[] { -dC, dC }), 3, measure));    clusters.add(new Canopy(new DenseVector(new double[] { dC, dC }), 5, measure));    clusters.add(new Canopy(new DenseVector(new double[] { dC, -dC }), 7, measure));    representativePoints = new HashMap<>();    for (Cluster cluster : clusters) {        List<VectorWritable> points = new ArrayList<>();        representativePoints.put(cluster.getId(), points);        points.add(new VectorWritable(cluster.getCenter().clone()));        points.add(new VectorWritable(cluster.getCenter().plus(new DenseVector(new double[] { dP, dP }))));        points.add(new VectorWritable(cluster.getCenter().plus(new DenseVector(new double[] { dP, -dP }))));        points.add(new VectorWritable(cluster.getCenter().plus(new DenseVector(new double[] { -dP, -dP }))));        points.add(new VectorWritable(cluster.getCenter().plus(new DenseVector(new double[] { -dP, dP }))));    }}
private void mahout_f792_1(int num, double mx, double my, double sd)
{        for (int i = 0; i < num; i++) {        sampleData.add(new VectorWritable(new DenseVector(new double[] { UncommonDistributions.rNorm(mx, sd), UncommonDistributions.rNorm(my, sd) })));    }}
private void mahout_f793_0()
{    generateSamples(500, 1, 1, 3);    generateSamples(300, 1, 0, 0.5);    generateSamples(300, 0, 2, 0.1);}
public void mahout_f794_0() throws IOException
{    ClusteringTestUtils.writePointsToFile(referenceData, getTestTempFilePath("testdata/file1"), fs, conf);    DistanceMeasure measure = new EuclideanDistanceMeasure();    initData(1, 0.25, measure);    CDbwEvaluator evaluator = new CDbwEvaluator(representativePoints, clusters, measure);    System.out.println("CDbw = " + evaluator.getCDbw());    System.out.println("Intra-cluster density = " + evaluator.intraClusterDensity());    System.out.println("Inter-cluster density = " + evaluator.interClusterDensity());    System.out.println("Separation = " + evaluator.separation());}
public void mahout_f795_0() throws IOException
{    ClusteringTestUtils.writePointsToFile(referenceData, getTestTempFilePath("testdata/file1"), fs, conf);    DistanceMeasure measure = new EuclideanDistanceMeasure();    initData(1, 0.5, measure);    CDbwEvaluator evaluator = new CDbwEvaluator(representativePoints, clusters, measure);    System.out.println("CDbw = " + evaluator.getCDbw());    System.out.println("Intra-cluster density = " + evaluator.intraClusterDensity());    System.out.println("Inter-cluster density = " + evaluator.interClusterDensity());    System.out.println("Separation = " + evaluator.separation());}
public void mahout_f796_0() throws IOException
{    ClusteringTestUtils.writePointsToFile(referenceData, getTestTempFilePath("testdata/file1"), fs, conf);    DistanceMeasure measure = new EuclideanDistanceMeasure();    initData(1, 0.75, measure);    CDbwEvaluator evaluator = new CDbwEvaluator(representativePoints, clusters, measure);    System.out.println("CDbw = " + evaluator.getCDbw());    System.out.println("Intra-cluster density = " + evaluator.intraClusterDensity());    System.out.println("Inter-cluster density = " + evaluator.interClusterDensity());    System.out.println("Separation = " + evaluator.separation());}
public void mahout_f797_0() throws IOException
{    ClusteringTestUtils.writePointsToFile(referenceData, getTestTempFilePath("testdata/file1"), fs, conf);    DistanceMeasure measure = new EuclideanDistanceMeasure();    initData(1, 0.25, measure);    Canopy cluster = new Canopy(new DenseVector(new double[] { 10, 10 }), 19, measure);    clusters.add(cluster);    List<VectorWritable> points = new ArrayList<>();    representativePoints.put(cluster.getId(), points);    CDbwEvaluator evaluator = new CDbwEvaluator(representativePoints, clusters, measure);    System.out.println("CDbw = " + evaluator.getCDbw());    System.out.println("Intra-cluster density = " + evaluator.intraClusterDensity());    System.out.println("Inter-cluster density = " + evaluator.interClusterDensity());    System.out.println("Separation = " + evaluator.separation());}
public void mahout_f798_0() throws IOException
{    ClusteringTestUtils.writePointsToFile(referenceData, getTestTempFilePath("testdata/file1"), fs, conf);    DistanceMeasure measure = new EuclideanDistanceMeasure();    initData(1, 0.25, measure);    Canopy cluster = new Canopy(new DenseVector(new double[] { 0, 0 }), 19, measure);    clusters.add(cluster);    List<VectorWritable> points = new ArrayList<>();    points.add(new VectorWritable(cluster.getCenter().plus(new DenseVector(new double[] { 1, 1 }))));    representativePoints.put(cluster.getId(), points);    CDbwEvaluator evaluator = new CDbwEvaluator(representativePoints, clusters, measure);    System.out.println("CDbw = " + evaluator.getCDbw());    System.out.println("Intra-cluster density = " + evaluator.intraClusterDensity());    System.out.println("Inter-cluster density = " + evaluator.interClusterDensity());    System.out.println("Separation = " + evaluator.separation());}
public void mahout_f799_0() throws IOException
{    ClusteringTestUtils.writePointsToFile(referenceData, getTestTempFilePath("testdata/file1"), fs, conf);    DistanceMeasure measure = new EuclideanDistanceMeasure();    initData(1, 0.25, measure);    Canopy cluster = new Canopy(new DenseVector(new double[] { 0, 0 }), 19, measure);    clusters.add(cluster);    List<VectorWritable> points = new ArrayList<>();    points.add(new VectorWritable(cluster.getCenter()));    points.add(new VectorWritable(cluster.getCenter()));    points.add(new VectorWritable(cluster.getCenter()));    representativePoints.put(cluster.getId(), points);    CDbwEvaluator evaluator = new CDbwEvaluator(representativePoints, clusters, measure);    System.out.println("CDbw = " + evaluator.getCDbw());    System.out.println("Intra-cluster density = " + evaluator.intraClusterDensity());    System.out.println("Inter-cluster density = " + evaluator.interClusterDensity());    System.out.println("Separation = " + evaluator.separation());}
public void mahout_f800_0() throws IOException
{    ClusteringTestUtils.writePointsToFile(referenceData, getTestTempFilePath("testdata/file1"), fs, conf);    DistanceMeasure measure = new EuclideanDistanceMeasure();    initData(1, 0.25, measure);    Canopy cluster = new Canopy(new DenseVector(new double[] { 0, 0 }), 19, measure);    clusters.add(cluster);    List<VectorWritable> points = new ArrayList<>();    Vector delta = new DenseVector(new double[] { 0, Double.MIN_NORMAL });    points.add(new VectorWritable(delta.clone()));    points.add(new VectorWritable(delta.clone()));    points.add(new VectorWritable(delta.clone()));    points.add(new VectorWritable(delta.clone()));    points.add(new VectorWritable(delta.clone()));    representativePoints.put(cluster.getId(), points);    CDbwEvaluator evaluator = new CDbwEvaluator(representativePoints, clusters, measure);    System.out.println("CDbw = " + evaluator.getCDbw());    System.out.println("Intra-cluster density = " + evaluator.intraClusterDensity());    System.out.println("Inter-cluster density = " + evaluator.interClusterDensity());    System.out.println("Separation = " + evaluator.separation());}
public void mahout_f801_0() throws Exception
{    ClusteringTestUtils.writePointsToFile(sampleData, getTestTempFilePath("testdata/file1"), fs, conf);    DistanceMeasure measure = new EuclideanDistanceMeasure();    CanopyDriver.run(getConfiguration(), testdata, output, measure, 3.1, 2.1, true, 0.0, true);    int numIterations = 10;    Path clustersIn = new Path(output, "clusters-0-final");    RepresentativePointsDriver.run(conf, clustersIn, new Path(output, "clusteredPoints"), output, measure, numIterations, true);    CDbwEvaluator evaluator = new CDbwEvaluator(conf, clustersIn);            System.out.println("Canopy CDbw = " + evaluator.getCDbw());    System.out.println("Intra-cluster density = " + evaluator.intraClusterDensity());    System.out.println("Inter-cluster density = " + evaluator.interClusterDensity());    System.out.println("Separation = " + evaluator.separation());}
public void mahout_f802_0() throws Exception
{    ClusteringTestUtils.writePointsToFile(sampleData, getTestTempFilePath("testdata/file1"), fs, conf);    DistanceMeasure measure = new EuclideanDistanceMeasure();        CanopyDriver.run(getConfiguration(), testdata, output, measure, 3.1, 2.1, false, 0.0, true);        Path kmeansOutput = new Path(output, "kmeans");    KMeansDriver.run(testdata, new Path(output, "clusters-0-final"), kmeansOutput, 0.001, 10, true, 0.0, true);    int numIterations = 10;    Path clustersIn = new Path(kmeansOutput, "clusters-10-final");    RepresentativePointsDriver.run(conf, clustersIn, new Path(kmeansOutput, "clusteredPoints"), kmeansOutput, measure, numIterations, true);    CDbwEvaluator evaluator = new CDbwEvaluator(conf, clustersIn);    RepresentativePointsDriver.printRepresentativePoints(kmeansOutput, numIterations);        System.out.println("K-Means CDbw = " + evaluator.getCDbw());    System.out.println("Intra-cluster density = " + evaluator.intraClusterDensity());    System.out.println("Inter-cluster density = " + evaluator.interClusterDensity());    System.out.println("Separation = " + evaluator.separation());}
public void mahout_f803_0() throws Exception
{    ClusteringTestUtils.writePointsToFile(sampleData, getTestTempFilePath("testdata/file1"), fs, conf);    DistanceMeasure measure = new EuclideanDistanceMeasure();        CanopyDriver.run(getConfiguration(), testdata, output, measure, 3.1, 2.1, false, 0.0, true);    Path fuzzyKMeansOutput = new Path(output, "fuzzyk");        FuzzyKMeansDriver.run(testdata, new Path(output, "clusters-0-final"), fuzzyKMeansOutput, 0.001, 10, 2, true, true, 0, true);    int numIterations = 10;    Path clustersIn = new Path(fuzzyKMeansOutput, "clusters-4");    RepresentativePointsDriver.run(conf, clustersIn, new Path(fuzzyKMeansOutput, "clusteredPoints"), fuzzyKMeansOutput, measure, numIterations, true);    CDbwEvaluator evaluator = new CDbwEvaluator(conf, clustersIn);    RepresentativePointsDriver.printRepresentativePoints(fuzzyKMeansOutput, numIterations);        System.out.println("Fuzzy K-Means CDbw = " + evaluator.getCDbw());    System.out.println("Intra-cluster density = " + evaluator.intraClusterDensity());    System.out.println("Inter-cluster density = " + evaluator.interClusterDensity());    System.out.println("Separation = " + evaluator.separation());}
public void mahout_f804_0() throws Exception
{    super.setUp();    Configuration conf = getConfiguration();    FileSystem fs = FileSystem.get(conf);        getSampleData(DOCS);    ClusteringTestUtils.writePointsToFile(sampleData, true, getTestTempFilePath("testdata/file1"), fs, conf);}
private void mahout_f805_0(String[] docs2) throws IOException
{    sampleData = new ArrayList<>();    RAMDirectory directory = new RAMDirectory();    try (IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(new StandardAnalyzer()))) {        for (int i = 0; i < docs2.length; i++) {            Document doc = new Document();            Field id = new StringField("id", "doc_" + i, Field.Store.YES);            doc.add(id);                        FieldType fieldType = new FieldType();            fieldType.setStored(false);            fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);            fieldType.setTokenized(true);            fieldType.setStoreTermVectors(true);            fieldType.setStoreTermVectorPositions(true);            fieldType.setStoreTermVectorOffsets(true);            fieldType.freeze();            Field text = new Field("content", docs2[i], fieldType);            doc.add(text);            writer.addDocument(doc);        }    }    IndexReader reader = DirectoryReader.open(directory);    Weight weight = new TFIDF();    TermInfo termInfo = new CachedTermInfo(reader, "content", 1, 100);    int numTerms = 0;    for (Iterator<TermEntry> it = termInfo.getAllEntries(); it.hasNext(); ) {        it.next();        numTerms++;    }    termDictionary = new String[numTerms];    int i = 0;    for (Iterator<TermEntry> it = termInfo.getAllEntries(); it.hasNext(); ) {        String term = it.next().getTerm();        termDictionary[i] = term;        System.out.println(i + " " + term);        i++;    }    Iterable<Vector> iterable = new LuceneIterable(reader, "id", "content", termInfo, weight);    i = 0;    for (Vector vector : iterable) {        assertNotNull(vector);        NamedVector namedVector;        if (vector instanceof NamedVector) {                        namedVector = new NamedVector(((NamedVector) vector).getDelegate(), "P(" + i + ')');        } else {            namedVector = new NamedVector(vector, "P(" + i + ')');        }        System.out.println(AbstractCluster.formatVector(namedVector, termDictionary));        sampleData.add(new VectorWritable(namedVector));        i++;    }}
private static Path mahout_f806_0(Configuration conf, Path output, int maxIterations) throws IOException
{    FileSystem fs = FileSystem.get(conf);    for (int i = maxIterations; i >= 0; i--) {        Path clusters = new Path(output, "clusters-" + i + "-final");        if (fs.exists(clusters)) {            return clusters;        }    }    return null;}
public void mahout_f807_0() throws Exception
{    DistanceMeasure measure = new EuclideanDistanceMeasure();    Path input = getTestTempFilePath("input");    Path output = getTestTempDirPath("output");    Path initialPoints = new Path(output, Cluster.CLUSTERS_DIR + '0' + Cluster.FINAL_ITERATION_SUFFIX);    Configuration conf = getConfiguration();    FileSystem fs = FileSystem.get(conf);        ClusteringTestUtils.writePointsToFile(sampleData, input, fs, conf);        RandomSeedGenerator.buildRandom(conf, input, initialPoints, 8, measure, 1L);        Path kMeansOutput = new Path(output, "kmeans");    KMeansDriver.run(conf, getTestTempDirPath("testdata"), initialPoints, kMeansOutput, 0.001, 10, true, 0.0, false);        ClusterDumper clusterDumper = new ClusterDumper(finalClusterPath(conf, output, 10), new Path(kMeansOutput, "clusteredPoints"));    clusterDumper.printClusters(termDictionary);}
public void mahout_f808_0() throws Exception
{    DistanceMeasure measure = new EuclideanDistanceMeasure();    Path input = getTestTempFilePath("input");    Path output = getTestTempDirPath("output");    Path initialPoints = new Path(output, Cluster.CLUSTERS_DIR + '0' + Cluster.FINAL_ITERATION_SUFFIX);    Configuration conf = getConfiguration();    FileSystem fs = FileSystem.get(conf);        ClusteringTestUtils.writePointsToFile(sampleData, input, fs, conf);        RandomSeedGenerator.buildRandom(conf, input, initialPoints, 8, measure, 1L);        Path kmeansOutput = new Path(output, "kmeans");    KMeansDriver.run(conf, getTestTempDirPath("testdata"), initialPoints, kmeansOutput, 0.001, 10, true, 0.0, false);        ClusterDumper clusterDumper = new ClusterDumper(finalClusterPath(conf, output, 10), new Path(kmeansOutput, "clusteredPoints"));    clusterDumper.setOutputFormat(ClusterDumper.OUTPUT_FORMAT.JSON);    clusterDumper.printClusters(termDictionary);}
public void mahout_f809_0() throws Exception
{    DistanceMeasure measure = new EuclideanDistanceMeasure();    Path input = getTestTempFilePath("input");    Path output = getTestTempDirPath("output");    Path initialPoints = new Path(output, Cluster.CLUSTERS_DIR + '0' + Cluster.FINAL_ITERATION_SUFFIX);    Configuration conf = getConfiguration();    FileSystem fs = FileSystem.get(conf);        ClusteringTestUtils.writePointsToFile(sampleData, input, fs, conf);        RandomSeedGenerator.buildRandom(conf, input, initialPoints, 8, measure, 1L);        Path kMeansOutput = new Path(output, "kmeans");    FuzzyKMeansDriver.run(conf, getTestTempDirPath("testdata"), initialPoints, kMeansOutput, 0.001, 10, 1.1f, true, true, 0, true);        ClusterDumper clusterDumper = new ClusterDumper(finalClusterPath(conf, output, 10), new Path(kMeansOutput, "clusteredPoints"));    clusterDumper.printClusters(termDictionary);}
public void mahout_f810_0() throws Exception
{    super.setUp();    conf = getConfiguration();    fs = FileSystem.get(conf);    testdata = getTestTempDirPath("testdata");    output = getTestTempDirPath("output");        referenceData = TestKmeansClustering.getPointsWritable(REFERENCE);        generateSamples();}
private void mahout_f811_1(int num, double mx, double my, double sd)
{        for (int i = 0; i < num; i++) {        sampleData.add(new VectorWritable(new DenseVector(new double[] { UncommonDistributions.rNorm(mx, sd), UncommonDistributions.rNorm(my, sd) })));    }}
private void mahout_f812_0()
{    generateSamples(500, 1, 1, 3);    generateSamples(300, 1, 0, 0.5);    generateSamples(300, 0, 2, 0.1);}
private void mahout_f813_0(int numIterations)
{    RepresentativePointsDriver.printRepresentativePoints(output, numIterations);}
private void mahout_f814_0(double dC, double dP, DistanceMeasure measure)
{    clusters = Lists.newArrayList();    clusters.add(new Canopy(new DenseVector(new double[] { -dC, -dC }), 1, measure));    clusters.add(new Canopy(new DenseVector(new double[] { -dC, dC }), 3, measure));    clusters.add(new Canopy(new DenseVector(new double[] { dC, dC }), 5, measure));    clusters.add(new Canopy(new DenseVector(new double[] { dC, -dC }), 7, measure));    representativePoints = Maps.newHashMap();    for (Cluster cluster : clusters) {        List<VectorWritable> points = Lists.newArrayList();        representativePoints.put(cluster.getId(), points);        points.add(new VectorWritable(cluster.getCenter().clone()));        points.add(new VectorWritable(cluster.getCenter().plus(new DenseVector(new double[] { dP, dP }))));        points.add(new VectorWritable(cluster.getCenter().plus(new DenseVector(new double[] { dP, -dP }))));        points.add(new VectorWritable(cluster.getCenter().plus(new DenseVector(new double[] { -dP, -dP }))));        points.add(new VectorWritable(cluster.getCenter().plus(new DenseVector(new double[] { -dP, dP }))));    }}
public void mahout_f815_0() throws Exception
{    ClusteringTestUtils.writePointsToFile(referenceData, new Path(testdata, "file1"), fs, conf);    DistanceMeasure measure = new EuclideanDistanceMeasure();    Configuration conf = getConfiguration();        CanopyDriver.run(conf, testdata, output, measure, 3.1, 1.1, true, 0.0, true);    int numIterations = 2;    Path clustersIn = new Path(output, "clusters-0-final");    RepresentativePointsDriver.run(conf, clustersIn, new Path(output, "clusteredPoints"), output, measure, numIterations, false);    printRepPoints(numIterations);    ClusterEvaluator evaluatorMR = new ClusterEvaluator(conf, clustersIn);        HadoopUtil.delete(conf, output);    CanopyDriver.run(conf, testdata, output, measure, 3.1, 1.1, true, 0.0, true);    RepresentativePointsDriver.run(conf, clustersIn, new Path(output, "clusteredPoints"), output, measure, numIterations, true);    printRepPoints(numIterations);    ClusterEvaluator evaluatorSeq = new ClusterEvaluator(conf, clustersIn);        assertEquals("InterCluster Density", evaluatorMR.interClusterDensity(), evaluatorSeq.interClusterDensity(), EPSILON);    assertEquals("IntraCluster Density", evaluatorMR.intraClusterDensity(), evaluatorSeq.intraClusterDensity(), EPSILON);}
public void mahout_f816_0() throws IOException
{    ClusteringTestUtils.writePointsToFile(referenceData, new Path(testdata, "file1"), fs, conf);    DistanceMeasure measure = new EuclideanDistanceMeasure();    initData(1, 0.25, measure);    ClusterEvaluator evaluator = new ClusterEvaluator(representativePoints, clusters, measure);    assertEquals("inter cluster density", 0.33333333333333315, evaluator.interClusterDensity(), EPSILON);    assertEquals("intra cluster density", 0.3656854249492381, evaluator.intraClusterDensity(), EPSILON);}
public void mahout_f817_0() throws IOException
{    ClusteringTestUtils.writePointsToFile(referenceData, new Path(testdata, "file1"), fs, conf);    DistanceMeasure measure = new EuclideanDistanceMeasure();    initData(1, 0.5, measure);    ClusterEvaluator evaluator = new ClusterEvaluator(representativePoints, clusters, measure);    assertEquals("inter cluster density", 0.33333333333333315, evaluator.interClusterDensity(), EPSILON);    assertEquals("intra cluster density", 0.3656854249492381, evaluator.intraClusterDensity(), EPSILON);}
public void mahout_f818_0() throws IOException
{    ClusteringTestUtils.writePointsToFile(referenceData, new Path(testdata, "file1"), fs, conf);    DistanceMeasure measure = new EuclideanDistanceMeasure();    initData(1, 0.75, measure);    ClusterEvaluator evaluator = new ClusterEvaluator(representativePoints, clusters, measure);    assertEquals("inter cluster density", 0.33333333333333315, evaluator.interClusterDensity(), EPSILON);    assertEquals("intra cluster density", 0.3656854249492381, evaluator.intraClusterDensity(), EPSILON);}
public void mahout_f819_0() throws IOException
{    ClusteringTestUtils.writePointsToFile(referenceData, new Path(testdata, "file1"), fs, conf);    DistanceMeasure measure = new EuclideanDistanceMeasure();    initData(1, 0.25, measure);    Canopy cluster = new Canopy(new DenseVector(new double[] { 10, 10 }), 19, measure);    clusters.add(cluster);    List<VectorWritable> points = Lists.newArrayList();    representativePoints.put(cluster.getId(), points);    ClusterEvaluator evaluator = new ClusterEvaluator(representativePoints, clusters, measure);    assertEquals("inter cluster density", 0.371534146934532, evaluator.interClusterDensity(), EPSILON);    assertEquals("intra cluster density", 0.3656854249492381, evaluator.intraClusterDensity(), EPSILON);}
public void mahout_f820_0() throws IOException
{    ClusteringTestUtils.writePointsToFile(referenceData, new Path(testdata, "file1"), fs, conf);    DistanceMeasure measure = new EuclideanDistanceMeasure();    initData(1, 0.25, measure);    Canopy cluster = new Canopy(new DenseVector(new double[] { 0, 0 }), 19, measure);    clusters.add(cluster);    List<VectorWritable> points = Lists.newArrayList();    points.add(new VectorWritable(cluster.getCenter().plus(new DenseVector(new double[] { 1, 1 }))));    representativePoints.put(cluster.getId(), points);    ClusterEvaluator evaluator = new ClusterEvaluator(representativePoints, clusters, measure);    assertEquals("inter cluster density", 0.3656854249492381, evaluator.interClusterDensity(), EPSILON);    assertEquals("intra cluster density", 0.3656854249492381, evaluator.intraClusterDensity(), EPSILON);}
public void mahout_f821_0() throws IOException
{    ClusteringTestUtils.writePointsToFile(referenceData, new Path(testdata, "file1"), fs, conf);    DistanceMeasure measure = new EuclideanDistanceMeasure();    initData(1, 0.25, measure);    Canopy cluster = new Canopy(new DenseVector(new double[] { 0, 0 }), 19, measure);    clusters.add(cluster);    List<VectorWritable> points = Lists.newArrayList();    points.add(new VectorWritable(cluster.getCenter()));    points.add(new VectorWritable(cluster.getCenter()));    points.add(new VectorWritable(cluster.getCenter()));    representativePoints.put(cluster.getId(), points);    ClusterEvaluator evaluator = new ClusterEvaluator(representativePoints, clusters, measure);    assertEquals("inter cluster density", 0.3656854249492381, evaluator.interClusterDensity(), EPSILON);    assertEquals("intra cluster density", 0.3656854249492381, evaluator.intraClusterDensity(), EPSILON);}
public void mahout_f822_0() throws Exception
{    ClusteringTestUtils.writePointsToFile(sampleData, new Path(testdata, "file1"), fs, conf);    DistanceMeasure measure = new EuclideanDistanceMeasure();    Configuration conf = getConfiguration();    CanopyDriver.run(conf, testdata, output, measure, 3.1, 1.1, true, 0.0, true);    int numIterations = 10;    Path clustersIn = new Path(output, "clusters-0-final");    RepresentativePointsDriver.run(conf, clustersIn, new Path(output, "clusteredPoints"), output, measure, numIterations, true);        ClusterEvaluator evaluator = new ClusterEvaluator(conf, clustersIn);        System.out.println("Intra-cluster density = " + evaluator.intraClusterDensity());    System.out.println("Inter-cluster density = " + evaluator.interClusterDensity());}
public void mahout_f823_0() throws Exception
{    ClusteringTestUtils.writePointsToFile(sampleData, new Path(testdata, "file1"), fs, conf);    DistanceMeasure measure = new EuclideanDistanceMeasure();        Configuration conf = getConfiguration();    CanopyDriver.run(conf, testdata, output, measure, 3.1, 1.1, false, 0.0, true);        Path kmeansOutput = new Path(output, "kmeans");    KMeansDriver.run(testdata, new Path(output, "clusters-0-final"), kmeansOutput, 0.001, 10, true, 0.0, true);    int numIterations = 10;    Path clustersIn = new Path(kmeansOutput, "clusters-2");    RepresentativePointsDriver.run(conf, clustersIn, new Path(kmeansOutput, "clusteredPoints"), kmeansOutput, measure, numIterations, true);    RepresentativePointsDriver.printRepresentativePoints(kmeansOutput, numIterations);    ClusterEvaluator evaluator = new ClusterEvaluator(conf, clustersIn);        System.out.println("Intra-cluster density = " + evaluator.intraClusterDensity());    System.out.println("Inter-cluster density = " + evaluator.interClusterDensity());}
public void mahout_f824_0() throws Exception
{    ClusteringTestUtils.writePointsToFile(sampleData, new Path(testdata, "file1"), fs, conf);    DistanceMeasure measure = new EuclideanDistanceMeasure();        Configuration conf = getConfiguration();    CanopyDriver.run(conf, testdata, output, measure, 3.1, 1.1, false, 0.0, true);    Path fuzzyKMeansOutput = new Path(output, "fuzzyk");        FuzzyKMeansDriver.run(testdata, new Path(output, "clusters-0-final"), fuzzyKMeansOutput, 0.001, 10, 2, true, true, 0, true);    int numIterations = 10;    Path clustersIn = new Path(fuzzyKMeansOutput, "clusters-4");    RepresentativePointsDriver.run(conf, clustersIn, new Path(fuzzyKMeansOutput, "clusteredPoints"), fuzzyKMeansOutput, measure, numIterations, true);    RepresentativePointsDriver.printRepresentativePoints(fuzzyKMeansOutput, numIterations);    ClusterEvaluator evaluator = new ClusterEvaluator(conf, clustersIn);        System.out.println("Intra-cluster density = " + evaluator.intraClusterDensity());    System.out.println("Inter-cluster density = " + evaluator.interClusterDensity());}
public String mahout_f825_0()
{    return field1;}
public String mahout_f826_0()
{    return field2;}
public Document mahout_f827_0()
{    Document document = super.asLuceneDocument();    document.add(new TextField(FIELD1, this.field1, Field.Store.YES));    document.add(new TextField(FIELD2, this.field2, Field.Store.YES));    return document;}
public Document mahout_f828_0()
{    Document document = new Document();    document.add(new StringField(ID_FIELD, getId(), Field.Store.YES));    document.add(new TextField(FIELD, getField(), Field.Store.YES));    document.add(new IntField(NUMERIC_FIELD, numericField, Field.Store.YES));    return document;}
public int mahout_f829_0()
{    return numericField;}
public String mahout_f830_0()
{    return id;}
public String mahout_f831_0()
{    return field;}
public Document mahout_f832_0()
{    Document document = new Document();    Field idField = new StringField(ID_FIELD, getId(), Field.Store.YES);    Field field = new TextField(FIELD, getField(), Field.Store.YES);    document.add(idField);    document.add(field);    return document;}
public Document mahout_f833_0()
{    Document document = super.asLuceneDocument();    document.add(new StringField(UNSTORED_FIELD, "", Field.Store.NO));    return document;}
public void mahout_f834_0() throws Exception
{    Analyzer analyzer = new MailArchivesClusteringAnalyzer();    String text = "A test message\n" + "atokenthatistoolongtobeusefulforclustertextanalysis\n" + "Mahout is a scalable, machine-learning LIBRARY\n" + "we've added some additional stopwords such as html, mailto, regards\t" + "apache_hadoop provides the foundation for scalability\n" + "www.nabble.com general-help@incubator.apache.org\n" + "public void int protected package";    Reader reader = new StringReader(text);            String[] expectedTokens = { "test", "mahout", "scalabl", "machin", "learn", "librari", "weve", "ad", "stopword", "apache_hadoop", "provid", "foundat", "scalabl" };    TokenStream tokenStream = analyzer.tokenStream("test", reader);    assertNotNull(tokenStream);    tokenStream.reset();    CharTermAttribute termAtt = tokenStream.addAttribute(CharTermAttribute.class);    int e = 0;    while (tokenStream.incrementToken() && e < expectedTokens.length) {        assertEquals(expectedTokens[e++], termAtt.toString());    }    assertEquals(e, expectedTokens.length);    tokenStream.end();    tokenStream.close();}
public void mahout_f835_0() throws Exception
{    super.setUp();    inputDir = getTestTempDir("mail-archives-in");        File subDir = new File(inputDir, "subdir");    subDir.mkdir();    File gzFile = new File(subDir, "mail-messages.gz");    try (GZIPOutputStream gzOut = new GZIPOutputStream(new FileOutputStream(gzFile))) {        gzOut.write(testMailMessages.getBytes("UTF-8"));        gzOut.finish();    }    File subDir2 = new File(subDir, "subsubdir");    subDir2.mkdir();    File gzFile2 = new File(subDir2, "mail-messages-2.gz");    try (GZIPOutputStream gzOut = new GZIPOutputStream(new FileOutputStream(gzFile2))) {        gzOut.write(testMailMessages.getBytes("UTF-8"));        gzOut.finish();    }}
public void mahout_f836_0() throws Exception
{    File outputDir = this.getTestTempDir("mail-archives-out");    String[] args = { "--input", inputDir.getAbsolutePath(), "--output", outputDir.getAbsolutePath(), "--charset", "UTF-8", "--keyPrefix", "TEST", "--method", "sequential", "--body", "--subject", "--separator", "" };        SequenceFilesFromMailArchives.main(args);        File expectedChunkFile = new File(outputDir, "chunk-0");    String expectedChunkPath = expectedChunkFile.getAbsolutePath();    Assert.assertTrue("Expected chunk file " + expectedChunkPath + " not found!", expectedChunkFile.isFile());    Configuration conf = getConfiguration();    SequenceFileIterator<Text, Text> iterator = new SequenceFileIterator<>(new Path(expectedChunkPath), true, conf);    Assert.assertTrue("First key/value pair not found!", iterator.hasNext());    Pair<Text, Text> record = iterator.next();    File parentFile = new File(new File(new File("TEST"), "subdir"), "mail-messages.gz");    Assert.assertEquals(new File(parentFile, testVars[0][0]).toString(), record.getFirst().toString());    Assert.assertEquals(testVars[0][1] + testVars[0][2], record.getSecond().toString());    Assert.assertTrue("Second key/value pair not found!", iterator.hasNext());    record = iterator.next();    Assert.assertEquals(new File(parentFile, testVars[1][0]).toString(), record.getFirst().toString());    Assert.assertEquals(testVars[1][1] + testVars[1][2], record.getSecond().toString());    record = iterator.next();    File parentFileSubSubDir = new File(new File(new File(new File("TEST"), "subdir"), "subsubdir"), "mail-messages-2.gz");    Assert.assertEquals(new File(parentFileSubSubDir, testVars[0][0]).toString(), record.getFirst().toString());    Assert.assertEquals(testVars[0][1] + testVars[0][2], record.getSecond().toString());    Assert.assertTrue("Second key/value pair not found!", iterator.hasNext());    record = iterator.next();    Assert.assertEquals(new File(parentFileSubSubDir, testVars[1][0]).toString(), record.getFirst().toString());    Assert.assertEquals(testVars[1][1] + testVars[1][2], record.getSecond().toString());    Assert.assertFalse("Only two key/value pairs expected!", iterator.hasNext());}
public void mahout_f837_0() throws Exception
{    Path tmpDir = getTestTempDirPath();    Path mrOutputDir = new Path(tmpDir, "mail-archives-out-mr");    Configuration configuration = getConfiguration();    FileSystem fs = FileSystem.get(configuration);    File expectedInputFile = new File(inputDir.toString());    String[] args = { "-Dhadoop.tmp.dir=" + configuration.get("hadoop.tmp.dir"), "--input", expectedInputFile.getAbsolutePath(), "--output", mrOutputDir.toString(), "--charset", "UTF-8", "--keyPrefix", "TEST", "--method", "mapreduce", "--body", "--subject", "--separator", "" };        SequenceFilesFromMailArchives.main(args);        FileStatus[] fileStatuses = fs.listStatus(mrOutputDir.suffix("/part-m-00000"));        assertEquals(1, fileStatuses.length);    assertEquals("part-m-00000", fileStatuses[0].getPath().getName());    SequenceFileIterator<Text, Text> iterator = new SequenceFileIterator<>(mrOutputDir.suffix("/part-m-00000"), true, configuration);    Assert.assertTrue("First key/value pair not found!", iterator.hasNext());    Pair<Text, Text> record = iterator.next();    File parentFileSubSubDir = new File(new File(new File(new File("TEST"), "subdir"), "subsubdir"), "mail-messages-2.gz");    String expected = record.getFirst().toString();    if (SystemUtils.IS_OS_WINDOWS) {        expected = expected.replace("/", "\\");    }    Assert.assertEquals(new File(parentFileSubSubDir, testVars[0][0]).toString(), expected);    Assert.assertEquals(testVars[0][1] + testVars[0][2], record.getSecond().toString());    Assert.assertTrue("Second key/value pair not found!", iterator.hasNext());    record = iterator.next();    expected = record.getFirst().toString();    if (SystemUtils.IS_OS_WINDOWS) {        expected = expected.replace("/", "\\");    }    Assert.assertEquals(new File(parentFileSubSubDir, testVars[1][0]).toString(), expected);    Assert.assertEquals(testVars[1][1] + testVars[1][2], record.getSecond().toString());        File parentFile = new File(new File(new File("TEST"), "subdir"), "mail-messages.gz");    record = iterator.next();    expected = record.getFirst().toString();    if (SystemUtils.IS_OS_WINDOWS) {        expected = expected.replace("/", "\\");    }    Assert.assertEquals(new File(parentFile, testVars[0][0]).toString(), expected);    Assert.assertEquals(testVars[0][1] + testVars[0][2], record.getSecond().toString());    Assert.assertTrue("Second key/value pair not found!", iterator.hasNext());    record = iterator.next();    expected = record.getFirst().toString();    if (SystemUtils.IS_OS_WINDOWS) {        expected = expected.replace("/", "\\");    }    Assert.assertEquals(new File(parentFile, testVars[1][0]).toString(), expected);    Assert.assertEquals(testVars[1][1] + testVars[1][2], record.getSecond().toString());    Assert.assertFalse("Only four key/value pairs expected!", iterator.hasNext());}
public boolean mahout_f838_0(Path path)
{    return path.getName().startsWith("t") || path.getName().startsWith("r") || path.getName().startsWith("f");}
public void mahout_f839_0() throws Exception
{        Configuration configuration = getConfiguration();    FileSystem fs = FileSystem.get(configuration);        Path tmpDir = this.getTestTempDirPath();    Path inputDir = new Path(tmpDir, "inputDir");    fs.mkdirs(inputDir);    Path outputDir = new Path(tmpDir, "outputDir");    Path outputDirRecursive = new Path(tmpDir, "outputDirRecursive");    Path inputDirRecursive = new Path(tmpDir, "inputDirRecur");    fs.mkdirs(inputDirRecursive);        createFilesFromArrays(configuration, inputDir, DATA1);    SequenceFilesFromDirectory.main(new String[] { "--input", inputDir.toString(), "--output", outputDir.toString(), "--chunkSize", "64", "--charset", Charsets.UTF_8.name(), "--keyPrefix", "UID", "--method", "sequential" });        checkChunkFiles(configuration, outputDir, DATA1, "UID");    createRecursiveDirFilesFromArrays(configuration, inputDirRecursive, DATA2);    FileStatus fstInputPath = fs.getFileStatus(inputDirRecursive);    String dirs = HadoopUtil.buildDirList(fs, fstInputPath);    System.out.println("\n\n ----- recursive dirs: " + dirs);    SequenceFilesFromDirectory.main(new String[] { "--input", inputDirRecursive.toString(), "--output", outputDirRecursive.toString(), "--chunkSize", "64", "--charset", Charsets.UTF_8.name(), "--keyPrefix", "UID", "--method", "sequential" });    checkRecursiveChunkFiles(configuration, outputDirRecursive, DATA2, "UID");}
public void mahout_f840_1() throws Exception
{    Configuration conf = getConfiguration();    FileSystem fs = FileSystem.get(conf);        Path tmpDir = this.getTestTempDirPath();    Path inputDir = new Path(tmpDir, "inputDir");    fs.mkdirs(inputDir);    Path inputDirRecur = new Path(tmpDir, "inputDirRecur");    fs.mkdirs(inputDirRecur);    Path mrOutputDir = new Path(tmpDir, "mrOutputDir");    Path mrOutputDirRecur = new Path(tmpDir, "mrOutputDirRecur");    createFilesFromArrays(conf, inputDir, DATA1);    SequenceFilesFromDirectory.main(new String[] { "-Dhadoop.tmp.dir=" + conf.get("hadoop.tmp.dir"), "--input", inputDir.toString(), "--output", mrOutputDir.toString(), "--chunkSize", "64", "--charset", Charsets.UTF_8.name(), "--method", "mapreduce", "--keyPrefix", "UID", "--fileFilterClass", "org.apache.mahout.text.TestPathFilter" });    checkMRResultFiles(conf, mrOutputDir, DATA1, "UID");    createRecursiveDirFilesFromArrays(conf, inputDirRecur, DATA2);    FileStatus fst_input_path = fs.getFileStatus(inputDirRecur);    String dirs = HadoopUtil.buildDirList(fs, fst_input_path);        SequenceFilesFromDirectory.main(new String[] { "-Dhadoop.tmp.dir=" + conf.get("hadoop.tmp.dir"), "--input", inputDirRecur.toString(), "--output", mrOutputDirRecur.toString(), "--chunkSize", "64", "--charset", Charsets.UTF_8.name(), "--method", "mapreduce", "--keyPrefix", "UID", "--fileFilterClass", "org.apache.mahout.text.TestPathFilter" });    checkMRResultFilesRecursive(conf, mrOutputDirRecur, DATA2, "UID");}
private static void mahout_f841_0(Configuration conf, Path inputDir, String[][] data) throws IOException
{    FileSystem fs = FileSystem.get(conf);    for (String[] aData : data) {        try (OutputStreamWriter writer = new OutputStreamWriter(fs.create(new Path(inputDir, aData[0])), Charsets.UTF_8)) {            writer.write(aData[1]);        }    }}
private static void mahout_f842_1(Configuration configuration, Path inputDir, String[][] data) throws IOException
{    FileSystem fs = FileSystem.get(configuration);        Path curPath;    String currentRecursiveDir = inputDir.toString();    for (String[] aData : data) {        currentRecursiveDir += "/" + aData[0];        File subDir = new File(currentRecursiveDir);        subDir.mkdir();        curPath = new Path(subDir.toString(), "file.txt");                try (OutputStreamWriter writer = new OutputStreamWriter(fs.create(curPath), Charsets.UTF_8)) {            writer.write(aData[1]);        }    }}
private static void mahout_f843_0(Configuration configuration, Path outputDir, String[][] data, String prefix) throws IOException
{    FileSystem fs = FileSystem.get(configuration);        FileStatus[] fileStatuses = fs.listStatus(outputDir, PathFilters.logsCRCFilter());        assertEquals(1, fileStatuses.length);    assertEquals("chunk-0", fileStatuses[0].getPath().getName());    Map<String, String> fileToData = new HashMap<>();    for (String[] aData : data) {        fileToData.put(prefix + Path.SEPARATOR + aData[0], aData[1]);    }        try (SequenceFileIterator<Text, Text> iterator = new SequenceFileIterator<>(fileStatuses[0].getPath(), true, configuration)) {        while (iterator.hasNext()) {            Pair<Text, Text> record = iterator.next();            String retrievedData = fileToData.get(record.getFirst().toString().trim());            assertNotNull(retrievedData);            assertEquals(retrievedData, record.getSecond().toString().trim());        }    }}
private static void mahout_f844_0(Configuration configuration, Path outputDir, String[][] data, String prefix) throws IOException
{    FileSystem fs = FileSystem.get(configuration);    System.out.println(" ----------- check_Recursive_ChunkFiles ------------");        FileStatus[] fileStatuses = fs.listStatus(outputDir, PathFilters.logsCRCFilter());        assertEquals(1, fileStatuses.length);    assertEquals("chunk-0", fileStatuses[0].getPath().getName());    Map<String, String> fileToData = new HashMap<>();    String currentPath = prefix;    for (String[] aData : data) {        currentPath += Path.SEPARATOR + aData[0];        fileToData.put(currentPath + Path.SEPARATOR + "file.txt", aData[1]);    }        try (SequenceFileIterator<Text, Text> iterator = new SequenceFileIterator<>(fileStatuses[0].getPath(), true, configuration)) {        while (iterator.hasNext()) {            Pair<Text, Text> record = iterator.next();            String retrievedData = fileToData.get(record.getFirst().toString().trim());            System.out.printf("%s >> %s\n", record.getFirst().toString().trim(), record.getSecond().toString().trim());            assertNotNull(retrievedData);            assertEquals(retrievedData, record.getSecond().toString().trim());            System.out.printf(">>> k: %s, v: %s\n", record.getFirst().toString(), record.getSecond().toString());        }    }}
private static void mahout_f845_0(Configuration conf, Path outputDir, String[][] data, String prefix) throws IOException
{    FileSystem fs = FileSystem.get(conf);        FileStatus[] fileStatuses = fs.listStatus(outputDir.suffix("/part-m-00000"), PathFilters.logsCRCFilter());        assertEquals(1, fileStatuses.length);    assertEquals("part-m-00000", fileStatuses[0].getPath().getName());    Map<String, String> fileToData = new HashMap<>();    for (String[] aData : data) {        System.out.printf("map.put: %s %s\n", prefix + Path.SEPARATOR + aData[0], aData[1]);        fileToData.put(prefix + Path.SEPARATOR + aData[0], aData[1]);    }        try (SequenceFileIterator<Text, Text> iterator = new SequenceFileIterator<>(fileStatuses[0].getPath(), true, conf)) {        while (iterator.hasNext()) {            Pair<Text, Text> record = iterator.next();            String retrievedData = fileToData.get(record.getFirst().toString().trim());            System.out.printf("MR> %s >> %s\n", record.getFirst().toString().trim(), record.getSecond().toString().trim());            assertNotNull(retrievedData);            assertEquals(retrievedData, record.getSecond().toString().trim());        }    }}
private static void mahout_f846_0(Configuration configuration, Path outputDir, String[][] data, String prefix) throws IOException
{    FileSystem fs = FileSystem.get(configuration);        FileStatus[] fileStatuses = fs.listStatus(outputDir.suffix("/part-m-00000"), PathFilters.logsCRCFilter());        assertEquals(1, fileStatuses.length);    assertEquals("part-m-00000", fileStatuses[0].getPath().getName());    Map<String, String> fileToData = new HashMap<>();    String currentPath = prefix;    for (String[] aData : data) {        currentPath += Path.SEPARATOR + aData[0];        fileToData.put(currentPath + Path.SEPARATOR + "file.txt", aData[1]);    }        try (SequenceFileIterator<Text, Text> iterator = new SequenceFileIterator<>(fileStatuses[0].getPath(), true, configuration)) {        while (iterator.hasNext()) {            Pair<Text, Text> record = iterator.next();            System.out.printf("MR-Recur > Trying to check: %s\n", record.getFirst().toString().trim());            String retrievedData = fileToData.get(record.getFirst().toString().trim());            assertNotNull(retrievedData);            assertEquals(retrievedData, record.getSecond().toString().trim());        }    }}
public void mahout_f847_0() throws Exception
{    Iterator<Integer> ref = Lists.newArrayList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16, 18, 20, 25, 30, 35, 40, 50, 60, 70, 80, 100, 120, 140, 160, 180, 200, 250, 300, 350, 400, 500, 600, 700, 800, 1000, 1200, 1400, 1600, 1800, 2000, 2500, 3000, 3500, 4000, 5000, 6000, 7000).iterator();    Bump125 b = new Bump125();    for (int i = 0; i < 50; i++) {        long x = b.increment();        assertEquals(ref.next().longValue(), x);    }}
public void mahout_f848_0() throws Exception
{    StringWriter writer = new StringWriter();    MailOptions options = new MailOptions();    options.setSeparator(":::");    options.setCharset(Charsets.UTF_8);    options.setPatternsToMatch(new Pattern[] { MailProcessor.FROM_PREFIX, MailProcessor.SUBJECT_PREFIX, MailProcessor.TO_PREFIX });    options.setInput(new File(System.getProperty("user.dir")));    MailProcessor proc = new MailProcessor(options, "", writer);    URL url = MailProcessorTest.class.getClassLoader().getResource("test.mbox");    File file = new File(url.toURI());    long count = proc.parseMboxLineByLine(file);    assertEquals(7, count);}
public void mahout_f849_0() throws Exception
{    StringWriter writer = new StringWriter();    MailOptions options = new MailOptions();    options.setSeparator(":::");    options.setCharset(Charsets.UTF_8);    options.setPatternsToMatch(new Pattern[] { MailProcessor.SUBJECT_PREFIX });    options.setInput(new File(System.getProperty("user.dir")));    options.setIncludeBody(true);    MailProcessor proc = new MailProcessor(options, "", writer);    URL url = MailProcessorTest.class.getClassLoader().getResource("test.mbox");    File file = new File(url.toURI());    long count = proc.parseMboxLineByLine(file);    assertEquals(7, count);    assertTrue(writer.getBuffer().toString().contains("> Cocoon Cron Block Configurable Clustering"));    writer = new StringWriter();    proc = new MailProcessor(options, "", writer);    options.setStripQuotedText(true);    count = proc.parseMboxLineByLine(file);    assertEquals(7, count);    assertFalse(writer.getBuffer().toString().contains("> Cocoon Cron Block Configurable Clustering"));}
public void mahout_f850_0() throws IOException
{    Filter filter = getFilter(filterTokens);    Key k = new Key();    for (String s : filterTokens) {        setKey(k, s);        assertTrue("Key for string " + s + " should be filter member", filter.membershipTest(k));    }    for (String s : notFilterTokens) {        setKey(k, s);        assertFalse("Key for string " + s + " should not be filter member", filter.membershipTest(k));    }}
public void mahout_f851_0() throws IOException
{    Reader reader = new StringReader(input);    Analyzer analyzer = new WhitespaceAnalyzer();    TokenStream ts = analyzer.tokenStream(null, reader);    ts.reset();    validateTokens(allTokens, ts);    ts.end();    ts.close();}
public void mahout_f852_0() throws IOException
{    Reader reader = new StringReader(input);    Analyzer analyzer = new WhitespaceAnalyzer();    TokenStream ts = analyzer.tokenStream(null, reader);    ts.reset();    TokenStream f = new BloomTokenFilter(getFilter(filterTokens), false, /* toss matching tokens */    ts);    validateTokens(expectedNonKeepTokens, f);    ts.end();    ts.close();}
public void mahout_f853_0() throws IOException
{    Reader reader = new StringReader(input);    Analyzer analyzer = new WhitespaceAnalyzer();    TokenStream ts = analyzer.tokenStream(null, reader);    ts.reset();    TokenStream f = new BloomTokenFilter(getFilter(filterTokens), true, /* keep matching tokens */    ts);    validateTokens(expectedKeepTokens, f);    ts.end();    ts.close();}
public void mahout_f854_0() throws IOException
{    Reader reader = new StringReader(input);    Analyzer analyzer = new WhitespaceAnalyzer();    TokenStream ts = analyzer.tokenStream(null, reader);    ts.reset();    ShingleFilter sf = new ShingleFilter(ts, 3);    TokenStream f = new BloomTokenFilter(getFilter(shingleKeepTokens), true, sf);    validateTokens(expectedShingleTokens, f);    ts.end();    ts.close();}
private static void mahout_f855_0(Key k, String s) throws IOException
{    ByteBuffer buffer = encoder.encode(CharBuffer.wrap(s.toCharArray()));    k.set(buffer.array(), 1.0);}
private static void mahout_f856_0(String[] expected, TokenStream ts) throws IOException
{    int pos = 0;    while (ts.incrementToken()) {        assertTrue("Analyzer produced too many tokens", pos <= expected.length);        CharTermAttribute termAttr = ts.getAttribute(CharTermAttribute.class);        assertEquals("Unexpected term", expected[pos++], termAttr.toString());    }    assertEquals("Analyzer produced too few terms", expected.length, pos);}
private static Filter mahout_f857_0(String[] tokens) throws IOException
{    Filter filter = new BloomFilter(100, 50, Hash.JENKINS_HASH);    Key k = new Key();    for (String s : tokens) {        setKey(k, s);        filter.add(k);    }    return filter;}
public void mahout_f858_0() throws Exception
{    RegexMapper mapper = new RegexMapper();    Configuration conf = getConfiguration();    conf.set(RegexMapper.REGEX, "(?<=(\\?|&)q=).*?(?=&|$)");    conf.set(RegexMapper.TRANSFORMER_CLASS, URLDecodeTransformer.class.getName());    DummyRecordWriter<LongWritable, Text> mapWriter = new DummyRecordWriter<>();    Mapper<LongWritable, Text, LongWritable, Text>.Context mapContext = DummyRecordWriter.build(mapper, conf, mapWriter);    mapper.setup(mapContext);    for (int i = 0; i < RegexUtilsTest.TEST_STRS.length; i++) {        String testStr = RegexUtilsTest.TEST_STRS[i];        LongWritable key = new LongWritable(i);        mapper.map(key, new Text(testStr), mapContext);        List<Text> value = mapWriter.getValue(key);        if (!RegexUtilsTest.GOLD[i].isEmpty()) {            assertEquals(1, value.size());            assertEquals(RegexUtilsTest.GOLD[i], value.get(0).toString());        }    }}
public void mahout_f859_0() throws Exception
{    RegexMapper mapper = new RegexMapper();    Configuration conf = getConfiguration();    conf.set(RegexMapper.REGEX, "(\\d+)\\.(\\d+)\\.(\\d+)");    conf.set(RegexMapper.TRANSFORMER_CLASS, URLDecodeTransformer.class.getName());    conf.setStrings(RegexMapper.GROUP_MATCHERS, "1", "3");    DummyRecordWriter<LongWritable, Text> mapWriter = new DummyRecordWriter<>();    Mapper<LongWritable, Text, LongWritable, Text>.Context mapContext = DummyRecordWriter.build(mapper, conf, mapWriter);    mapper.setup(mapContext);    for (int i = 0; i < RegexUtilsTest.TEST_STRS.length; i++) {        String testStr = RegexUtilsTest.TEST_STRS[i];        LongWritable key = new LongWritable(i);        mapper.map(key, new Text(testStr), mapContext);        List<Text> value = mapWriter.getValue(key);        assertEquals(1, value.size());        assertEquals("127 0", value.get(0).toString());    }}
public void mahout_f860_0() throws Exception
{    RegexMapper mapper = new RegexMapper();    Configuration conf = getConfiguration();    conf.set(RegexMapper.REGEX, "(?<=(\\?|&)q=).*?(?=&|$)");    conf.set(RegexMapper.TRANSFORMER_CLASS, URLDecodeTransformer.class.getName());    conf.set(RegexMapper.FORMATTER_CLASS, FPGFormatter.class.getName());    DummyRecordWriter<LongWritable, Text> mapWriter = new DummyRecordWriter<>();    Mapper<LongWritable, Text, LongWritable, Text>.Context mapContext = DummyRecordWriter.build(mapper, conf, mapWriter);    mapper.setup(mapContext);    RegexFormatter formatter = new FPGFormatter();    for (int i = 0; i < RegexUtilsTest.TEST_STRS.length; i++) {        String testStr = RegexUtilsTest.TEST_STRS[i];        LongWritable key = new LongWritable(i);        mapper.map(key, new Text(testStr), mapContext);        List<Text> value = mapWriter.getValue(key);        if (!RegexUtilsTest.GOLD[i].isEmpty()) {            assertEquals(1, value.size());            assertEquals(formatter.format(RegexUtilsTest.GOLD[i]), value.get(0).toString());        }    }}
public void mahout_f861_0() throws Exception
{    Pattern pattern = Pattern.compile("(?<=(\\?|&)q=).*?(?=&|$)");    String line = "127.0.0.1 -  -  [24/05/2010:01:19:22 +0000] \"GET /solr/select?q=import statement&start=1 HTTP/1.1\" 200 37571";    String res = RegexUtils.extract(line, pattern, Collections.<Integer>emptyList(), " ", RegexUtils.IDENTITY_TRANSFORMER);    assertEquals(res, "import statement", res);    for (int i = 0; i < TEST_STRS.length; i++) {        String testStr = TEST_STRS[i];        res = RegexUtils.extract(testStr, pattern, Collections.<Integer>emptyList(), " ", new URLDecodeTransformer());        assertEquals(GOLD[i], res);    }    pattern = Pattern.compile("((?<=(\\?|&)q=)(.*?)(?=(&|$))|(?<=((\\?|&)start=))(\\d+))");    res = RegexUtils.extract(line, pattern, Collections.<Integer>emptyList(), " ", RegexUtils.IDENTITY_TRANSFORMER);    assertEquals(res, "import statement 1", res);    pattern = Pattern.compile("(start=1) HTTP");    Collection<Integer> groupsToKeep = new ArrayList<>();    groupsToKeep.add(1);    res = RegexUtils.extract(line, pattern, groupsToKeep, " ", RegexUtils.IDENTITY_TRANSFORMER);    assertEquals(res, "start=1", res);}
public void mahout_f862_0() throws Exception
{    Configuration conf = getConfiguration();    fs = FileSystem.get(conf);    super.setUp();    countMap = new OpenObjectIntHashMap<>();    charset = Charsets.UTF_8;    tempSequenceDirectory = getTestTempFilePath("tmpsequence");    tempInputFile = getTestTempFilePath("bayesinputfile");    tempTrainingDirectory = getTestTempDirPath("bayestrain");    tempTestDirectory = getTestTempDirPath("bayestest");    tempMapRedOutputDirectory = new Path(getTestTempDirPath(), "mapRedOutput");    tempInputDirectory = getTestTempDirPath("bayesinputdir");    si = new SplitInput();    si.setTrainingOutputDirectory(tempTrainingDirectory);    si.setTestOutputDirectory(tempTestDirectory);    si.setInputDirectory(tempInputDirectory);}
private void mahout_f863_0() throws IOException
{    Writer writer = null;    String currentLabel = null;    try {        for (String[] entry : ClassifierData.DATA) {            if (!entry[0].equals(currentLabel)) {                currentLabel = entry[0];                Closeables.close(writer, false);                writer = new BufferedWriter(new OutputStreamWriter(fs.create(new Path(tempInputDirectory, currentLabel)), Charsets.UTF_8));            }            countMap.adjustOrPutValue(currentLabel, 1, 1);            writer.write(currentLabel + '\t' + entry[1] + '\n');        }    } finally {        Closeables.close(writer, false);    }}
private void mahout_f864_0() throws IOException
{    Writer writer = new BufferedWriter(new OutputStreamWriter(fs.create(tempInputFile), Charsets.UTF_8));    try {        for (String[] entry : ClassifierData.DATA) {            writer.write(entry[0] + '\t' + entry[1] + '\n');        }    } finally {        Closeables.close(writer, true);    }}
public void mahout_f865_0() throws Exception
{    writeMultipleInputFiles();    final int testSplitSize = 1;    si.setTestSplitSize(testSplitSize);    si.setCallback(new SplitInput.SplitCallback() {        @Override        public void splitComplete(Path inputFile, int lineCount, int trainCount, int testCount, int testSplitStart) {            int trainingLines = countMap.get(inputFile.getName()) - testSplitSize;            assertSplit(fs, inputFile, charset, testSplitSize, trainingLines, tempTrainingDirectory, tempTestDirectory);        }    });    si.splitDirectory(tempInputDirectory);}
public void mahout_f866_0(Path inputFile, int lineCount, int trainCount, int testCount, int testSplitStart)
{    int trainingLines = countMap.get(inputFile.getName()) - testSplitSize;    assertSplit(fs, inputFile, charset, testSplitSize, trainingLines, tempTrainingDirectory, tempTestDirectory);}
public void mahout_f867_0() throws Exception
{    writeSingleInputFile();    si.setTestSplitSize(2);    si.setCallback(new TestCallback(2, 10));    si.splitFile(tempInputFile);}
public void mahout_f868_0() throws Exception
{    writeSingleInputFile();    si.setTestSplitSize(2);    si.setSplitLocation(50);    si.setCallback(new TestCallback(2, 10));    si.splitFile(tempInputFile);}
public void mahout_f869_0() throws Exception
{    writeSingleInputFile();    si.setTestSplitPct(25);    si.setCallback(new TestCallback(3, 9));    si.splitFile(tempInputFile);}
public void mahout_f870_0() throws Exception
{    writeSingleInputFile();    si.setTestSplitPct(25);    si.setSplitLocation(50);    si.setCallback(new TestCallback(3, 9));    si.splitFile(tempInputFile);}
public void mahout_f871_0() throws Exception
{    writeSingleInputFile();    si.setTestRandomSelectionSize(5);    si.setCallback(new TestCallback(5, 7));    si.splitFile(tempInputFile);}
public void mahout_f872_0() throws Exception
{    writeSingleInputFile();    si.setTestRandomSelectionPct(25);    si.setCallback(new TestCallback(3, 9));    si.splitFile(tempInputFile);}
private void mahout_f873_0(Path path, int testPoints) throws IOException
{    Path tempSequenceFile = new Path(path, "part-00000");    Configuration conf = getConfiguration();    IntWritable key = new IntWritable();    VectorWritable value = new VectorWritable();    try (SequenceFile.Writer writer = SequenceFile.createWriter(fs, conf, tempSequenceFile, IntWritable.class, VectorWritable.class)) {        for (int i = 0; i < testPoints; i++) {            key.set(i);            Vector v = new SequentialAccessSparseVector(4);            v.assign(i);            value.set(v);            writer.append(key, value);        }    }}
private void mahout_f874_0(Path path, int testPoints) throws IOException
{    Path tempSequenceFile = new Path(path, "part-00000");    Configuration conf = getConfiguration();    Text key = new Text();    Text value = new Text();    try (SequenceFile.Writer writer = SequenceFile.createWriter(fs, conf, tempSequenceFile, Text.class, Text.class)) {        for (int i = 0; i < testPoints; i++) {            key.set(Integer.toString(i));            value.set("Line " + i);            writer.append(key, value);        }    }}
private void mahout_f875_0(Path sequenceFilePath) throws IOException
{    for (Pair<?, ?> record : new SequenceFileIterable<>(sequenceFilePath, true, getConfiguration())) {        System.out.println(record.getFirst() + "\t" + record.getSecond());    }}
private int mahout_f876_0(Path sequenceFilePath) throws IOException
{    int numberRecords = 0;    for (Object value : new SequenceFileValueIterable<>(sequenceFilePath, true, getConfiguration())) {        numberRecords++;    }    return numberRecords;}
public void mahout_f877_0() throws Exception
{    writeTextSequenceFile(tempSequenceDirectory, 1000);    testSplitInputMapReduce(1000);}
public void mahout_f878_0() throws Exception
{    writeTextSequenceFile(tempSequenceDirectory, 1000);    testSplitInputMapReduceCli(1000);}
public void mahout_f879_0() throws Exception
{    writeVectorSequenceFile(tempSequenceDirectory, 1000);    testSplitInputMapReduce(1000);}
public void mahout_f880_0() throws Exception
{    writeVectorSequenceFile(tempSequenceDirectory, 1000);    testSplitInputMapReduceCli(1000);}
private void mahout_f881_0(int numPoints) throws Exception
{    int randomSelectionPct = 25;    int keepPct = 10;    String[] args = { "--method", "mapreduce", "--input", tempSequenceDirectory.toString(), "--mapRedOutputDir", tempMapRedOutputDirectory.toString(), "--randomSelectionPct", Integer.toString(randomSelectionPct), "--keepPct", Integer.toString(keepPct), "-ow" };    ToolRunner.run(getConfiguration(), new SplitInput(), args);    validateSplitInputMapReduce(numPoints, randomSelectionPct, keepPct);}
private void mahout_f882_0(int numPoints) throws Exception
{    int randomSelectionPct = 25;    si.setTestRandomSelectionPct(randomSelectionPct);    int keepPct = 10;    si.setKeepPct(keepPct);    si.setMapRedOutputDirectory(tempMapRedOutputDirectory);    si.setUseMapRed(true);    si.splitDirectory(getConfiguration(), tempSequenceDirectory);    validateSplitInputMapReduce(numPoints, randomSelectionPct, keepPct);}
private void mahout_f883_0(int numPoints, int randomSelectionPct, int keepPct) throws IOException
{    Path testPath = new Path(tempMapRedOutputDirectory, "test-r-00000");    Path trainingPath = new Path(tempMapRedOutputDirectory, "training-r-00000");    int numberTestRecords = getNumberRecords(testPath);    int numberTrainingRecords = getNumberRecords(trainingPath);    System.out.printf("Test data: %d records\n", numberTestRecords);    displaySequenceFile(testPath);    System.out.printf("Training data: %d records\n", numberTrainingRecords);    displaySequenceFile(trainingPath);    assertEquals((randomSelectionPct / 100.0) * (keepPct / 100.0) * numPoints, numberTestRecords, 2);    assertEquals((1 - randomSelectionPct / 100.0) * (keepPct / 100.0) * numPoints, numberTrainingRecords, 2);}
public void mahout_f884_0() throws Exception
{    SplitInput st = new SplitInput();    assertValidateException(st);    st.setTestSplitSize(100);    assertValidateException(st);    st.setTestOutputDirectory(tempTestDirectory);    assertValidateException(st);    st.setTrainingOutputDirectory(tempTrainingDirectory);    st.validate();    st.setTestSplitPct(50);    assertValidateException(st);    st = new SplitInput();    st.setTestRandomSelectionPct(50);    st.setTestOutputDirectory(tempTestDirectory);    st.setTrainingOutputDirectory(tempTrainingDirectory);    st.validate();    st.setTestSplitPct(50);    assertValidateException(st);    st = new SplitInput();    st.setTestRandomSelectionPct(50);    st.setTestOutputDirectory(tempTestDirectory);    st.setTrainingOutputDirectory(tempTrainingDirectory);    st.validate();    st.setTestSplitSize(100);    assertValidateException(st);}
public void mahout_f885_0(Path inputFile, int lineCount, int trainCount, int testCount, int testSplitStart)
{    assertSplit(fs, tempInputFile, charset, testSplitSize, trainingLines, tempTrainingDirectory, tempTestDirectory);}
private static void mahout_f886_0(SplitInput st) throws IOException
{    try {        st.validate();        fail("Expected IllegalArgumentException");    } catch (IllegalArgumentException iae) {        }}
private static void mahout_f887_0(FileSystem fs, Path tempInputFile, Charset charset, int testSplitSize, int trainingLines, Path tempTrainingDirectory, Path tempTestDirectory)
{    try {        Path testFile = new Path(tempTestDirectory, tempInputFile.getName());                assertEquals("test line count", testSplitSize, SplitInput.countLines(fs, testFile, charset));        Path trainingFile = new Path(tempTrainingDirectory, tempInputFile.getName());                assertEquals("training line count", trainingLines, SplitInput.countLines(fs, trainingFile, charset));    } catch (IOException ioe) {        fail(ioe.toString());    }}
public void mahout_f888_0()
{    assertNull(ARFFType.removeQuotes(null));    assertEquals("", ARFFType.removeQuotes("\"\""));    assertEquals("", ARFFType.removeQuotes("''"));    assertEquals("", ARFFType.removeQuotes(""));    assertEquals("", ARFFType.removeQuotes("  "));    assertEquals("single", ARFFType.removeQuotes("'single'"));    assertEquals("double", ARFFType.removeQuotes("\"double\""));    assertEquals("trim", ARFFType.removeQuotes(" trim "));}
public void mahout_f889_0() throws Exception
{    ARFFVectorIterable iterable = readModelFromResource("sample.arff");    assertEquals("Mahout", iterable.getModel().getRelation());    Map<String, Integer> bindings = iterable.getModel().getLabelBindings();    assertNotNull(bindings);    assertEquals(5, bindings.size());    Iterator<Vector> iter = iterable.iterator();    assertTrue(iter.hasNext());    Vector next = iter.next();    assertNotNull(next);    assertTrue("Wrong instanceof", next instanceof DenseVector);    assertEquals(1.0, next.get(0), EPSILON);    assertEquals(2.0, next.get(1), EPSILON);    assertTrue(iter.hasNext());    next = iter.next();    assertNotNull(next);    assertTrue("Wrong instanceof", next instanceof DenseVector);    assertEquals(2.0, next.get(0), EPSILON);    assertEquals(3.0, next.get(1), EPSILON);    assertTrue(iter.hasNext());    next = iter.next();    assertNotNull(next);    assertTrue("Wrong instanceof", next instanceof RandomAccessSparseVector);    assertEquals(5.0, next.get(0), EPSILON);    assertEquals(23.0, next.get(1), EPSILON);    assertFalse(iter.hasNext());}
public void mahout_f890_0() throws Exception
{    Iterable<Vector> iterable = readModelFromResource("sample-dense.arff");    Vector firstVector = iterable.iterator().next();    assertEquals(1.0, firstVector.get(0), 0);    assertEquals(65.0, firstVector.get(1), 0);    assertEquals(1.0, firstVector.get(3), 0);    assertEquals(1.0, firstVector.get(4), 0);    int count = 0;    for (Vector vector : iterable) {        assertTrue("Vector is not dense", vector instanceof DenseVector);        count++;    }    assertEquals(5, count);}
public void mahout_f891_0() throws Exception
{    Iterable<Vector> iterable = readModelFromResource("sample-sparse.arff");    Vector firstVector = iterable.iterator().next();    assertEquals(23.1, firstVector.get(1), 0);    assertEquals(3.23, firstVector.get(2), 0);    assertEquals(1.2, firstVector.get(3), 0);    int count = 0;    for (Vector vector : iterable) {        assertTrue("Vector is not dense", vector instanceof RandomAccessSparseVector);        count++;    }    assertEquals(9, count);}
public void mahout_f892_0() throws Exception
{    MapBackedARFFModel model = new MapBackedARFFModel();    ARFFVectorIterable iterable = getVectors("non-numeric-1.arff", model);    int count = 0;    for (Vector vector : iterable) {        assertTrue("Vector is not dense", vector instanceof RandomAccessSparseVector);        count++;    }    iterable = getVectors("non-numeric-1.arff", model);    Iterator<Vector> iter = iterable.iterator();    Vector firstVector = iter.next();    assertEquals(1.0, firstVector.get(2), 0);    assertEquals(10, count);    Map<String, Map<String, Integer>> nominalMap = iterable.getModel().getNominalMap();    assertNotNull(nominalMap);    assertEquals(1, nominalMap.size());    Map<String, Integer> noms = nominalMap.get("bar");    assertNotNull("nominals for bar are null", noms);    assertEquals(5, noms.size());    Map<Integer, ARFFType> integerARFFTypeMap = model.getTypeMap();    assertNotNull("Type map null", integerARFFTypeMap);    assertEquals(5, integerARFFTypeMap.size());    Map<String, Long> words = model.getWords();    assertNotNull("words null", words);    assertEquals(10, words.size());    Map<Integer, DateFormat> integerDateFormatMap = model.getDateMap();    assertNotNull("date format null", integerDateFormatMap);    assertEquals(1, integerDateFormatMap.size());}
public void mahout_f893_0() throws Exception
{    ARFFVectorIterable iterable = readModelFromResource("date.arff");    Iterator<Vector> iter = iterable.iterator();    Vector firstVector = iter.next();    DateFormat format = new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss", Locale.ENGLISH);    Date date = format.parse("2001-07-04T12:08:56");    long result = date.getTime();    assertEquals(result, firstVector.get(1), 0);    format = new SimpleDateFormat("yyyy.MM.dd G 'at' HH:mm:ss z", Locale.ENGLISH);    date = format.parse("2001.07.04 AD at 12:08:56 PDT");    result = date.getTime();    assertEquals(result, firstVector.get(2), 0);    format = new SimpleDateFormat("EEE, MMM d, ''yy", Locale.ENGLISH);    date = format.parse("Wed, Jul 4, '01,4 0:08 PM, PDT");    result = date.getTime();    assertEquals(result, firstVector.get(3), 0);    format = new SimpleDateFormat("K:mm a, z", Locale.ENGLISH);    date = format.parse("0:08 PM, PDT");    result = date.getTime();    assertEquals(result, firstVector.get(4), 0);    format = new SimpleDateFormat("yyyyy.MMMMM.dd GGG hh:mm aaa", Locale.ENGLISH);    date = format.parse("02001.July.04 AD 12:08 PM");    result = date.getTime();    assertEquals(result, firstVector.get(5), 0);    format = new SimpleDateFormat("EEE, d MMM yyyy HH:mm:ss Z", Locale.ENGLISH);    date = format.parse("Wed, 4 Jul 2001 12:08:56 -0700");    result = date.getTime();    assertEquals(result, firstVector.get(6), 0);}
public void mahout_f894_0() throws Exception
{    MapBackedARFFModel model = new MapBackedARFFModel();    ARFFVectorIterable iterable = getVectors("non-numeric-1.arff", model);    int count = 0;    for (Vector vector : iterable) {        assertTrue("Vector is not dense", vector instanceof RandomAccessSparseVector);        count++;    }    assertEquals(10, count);    Map<String, Map<String, Integer>> nominalMap = iterable.getModel().getNominalMap();    assertNotNull(nominalMap);    assertEquals(1, nominalMap.size());    Map<String, Integer> noms = nominalMap.get("bar");    assertNotNull("nominals for bar are null", noms);    assertEquals(5, noms.size());    Map<Integer, ARFFType> integerARFFTypeMap = model.getTypeMap();    assertNotNull("Type map null", integerARFFTypeMap);    assertEquals(5, integerARFFTypeMap.size());    Map<String, Long> words = model.getWords();    assertNotNull("words null", words);    assertEquals(10, words.size());    Map<Integer, DateFormat> integerDateFormatMap = model.getDateMap();    assertNotNull("date format null", integerDateFormatMap);    assertEquals(1, integerDateFormatMap.size());    iterable = getVectors("non-numeric-2.arff", model);    count = 0;    for (Vector vector : iterable) {        assertTrue("Vector is not dense", vector instanceof RandomAccessSparseVector);        count++;    }    nominalMap = model.getNominalMap();    assertNotNull(nominalMap);    assertEquals(2, nominalMap.size());    noms = nominalMap.get("test");    assertNotNull("nominals for bar are null", noms);    assertEquals(2, noms.size());}
public void mahout_f895_0() throws Exception
{    String arff = "@RELATION numerics\n" + "@ATTRIBUTE theNumeric NUMERIC\n" + "@ATTRIBUTE theInteger INTEGER\n" + "@ATTRIBUTE theReal REAL\n" + "@DATA\n" + "1.0,2,3.0";    ARFFModel model = new MapBackedARFFModel();    ARFFVectorIterable iterable = new ARFFVectorIterable(arff, model);    model = iterable.getModel();    assertNotNull(model);    assertEquals(3, model.getLabelSize());    assertEquals(ARFFType.NUMERIC, model.getARFFType(0));    assertEquals(ARFFType.INTEGER, model.getARFFType(1));    assertEquals(ARFFType.REAL, model.getARFFType(2));    Iterator<Vector> it = iterable.iterator();    Vector vector = it.next();    assertEquals(1.0, vector.get(0), EPSILON);    assertEquals(2.0, vector.get(1), EPSILON);    assertEquals(3.0, vector.get(2), EPSILON);}
public void mahout_f896_0() throws Exception
{        ARFFModel model = new MapBackedARFFModel();    ARFFVectorIterable iterable = getVectors("quoted-id.arff", model);    model = iterable.getModel();    assertNotNull(model);    assertEquals("quotes", model.getRelation());        assertEquals(4, model.getLabelSize());    assertEquals(ARFFType.NUMERIC, model.getARFFType(0));    assertEquals(ARFFType.INTEGER, model.getARFFType(1));    assertEquals(ARFFType.REAL, model.getARFFType(2));    assertEquals(ARFFType.NOMINAL, model.getARFFType(3));    Map<String, Integer> labelBindings = model.getLabelBindings();    assertTrue(labelBindings.keySet().contains("thenumeric"));    assertTrue(labelBindings.keySet().contains("theinteger"));    assertTrue(labelBindings.keySet().contains("thereal"));    assertTrue(labelBindings.keySet().contains("thenominal"));        Map<String, Integer> nominalMap = model.getNominalMap().get("thenominal");    assertNotNull(nominalMap);    assertEquals(3, nominalMap.size());    assertTrue(nominalMap.keySet().contains("double-quote"));    assertTrue(nominalMap.keySet().contains("single-quote"));    assertTrue(nominalMap.keySet().contains("no-quote"));        Iterator<Vector> it = iterable.iterator();    Vector vector = it.next();    assertEquals(nominalMap.get("no-quote"), vector.get(3), EPSILON);    assertEquals(nominalMap.get("single-quote"), it.next().get(3), EPSILON);    assertEquals(nominalMap.get("double-quote"), it.next().get(3), EPSILON);}
 static ARFFVectorIterable mahout_f897_0(String resourceName, ARFFModel model) throws IOException
{    String sample = Resources.toString(Resources.getResource(resourceName), Charsets.UTF_8);    return new ARFFVectorIterable(sample, model);}
private static ARFFVectorIterable mahout_f898_0(String resourceName) throws IOException
{    ARFFModel model = new MapBackedARFFModel();    return getVectors(resourceName, model);}
public void mahout_f899_0() throws IOException
{    ARFFModel model = new MapBackedARFFModel();    ARFFVectorIterableTest.getVectors("sample-dense.arff", model);    StringWriter writer = new StringWriter();    Driver.writeLabelBindings(writer, model, ",");    String expected1 = Resources.toString(Resources.getResource("expected-arff-dictionary.csv"), Charsets.UTF_8);    String expected2 = Resources.toString(Resources.getResource("expected-arff-dictionary-2.csv"), Charsets.UTF_8);    assertTrue(expected1.equals(writer.toString()) || expected2.equals(writer.toString()));}
public void mahout_f900_0() throws IOException
{    ARFFModel model = new MapBackedARFFModel();    ARFFVectorIterableTest.getVectors("sample-dense.arff", model);    StringWriter writer = new StringWriter();    Driver.writeLabelBindingsJSON(writer, model);    String expected1 = Resources.toString(Resources.getResource("expected-arff-schema.json"), Charsets.UTF_8);    String expected2 = Resources.toString(Resources.getResource("expected-arff-schema-2.json"), Charsets.UTF_8);    assertTrue(expected1.equals(writer.toString()) || expected2.equals(writer.toString()));}
public void mahout_f901_0()
{    String windy = "windy";    String breezy = "breezy";    ARFFModel model = new MapBackedARFFModel();    model.addNominal(windy, breezy, 77);    model.addNominal(windy, "strong", 23);    model.addNominal(windy, "nuking", 55);    Map<String, Map<String, Integer>> nominalMap = model.getNominalMap();    assertEquals(1, nominalMap.size());    Map<String, Integer> windyValues = nominalMap.get(windy);    assertEquals(77, windyValues.get(breezy).intValue());}
public void mahout_f902_0()
{    ARFFModel model = new MapBackedARFFModel();    model.addLabel("b1shkt70694difsmmmdv0ikmoh", 77);    model.addType(77, ARFFType.REAL);    assertTrue(Double.isNaN(model.getValue("b1shkt70694difsmmmdv0ikmoh", 77)));}
public void mahout_f903_0()
{    ARFFModel model = new MapBackedARFFModel();    model.addLabel("1234", 77);    model.addType(77, ARFFType.INTEGER);    assertTrue(1234 == model.getValue("1234", 77));    model.addLabel("131.34", 78);    model.addType(78, ARFFType.REAL);    assertTrue(131.34 == model.getValue("131.34", 78));}
public void mahout_f904_0() throws Exception
{    StringWriter sWriter = new StringWriter();    try (TextualVectorWriter writer = new TextualVectorWriter(sWriter) {        @Override        public void write(Vector vector) throws IOException {            String vecStr = VectorHelper.vectorToCSVString(vector, false);            getWriter().write(vecStr);        }    }) {        Iterable<Vector> iter = new RandomVectorIterable(50);        writer.write(iter);    }    Iterator<Vector> csvIter = new CSVVectorIterator(new StringReader(sWriter.getBuffer().toString()));    int count = 0;    while (csvIter.hasNext()) {        csvIter.next();        count++;    }    assertEquals(50, count);}
public void mahout_f905_0(Vector vector) throws IOException
{    String vecStr = VectorHelper.vectorToCSVString(vector, false);    getWriter().write(vecStr);}
public void mahout_f906_0() throws Exception
{    Path path = getTestTempFilePath("sfvw");    Configuration conf = getConfiguration();    FileSystem fs = FileSystem.get(conf);    SequenceFile.Writer seqWriter = new SequenceFile.Writer(fs, conf, path, LongWritable.class, VectorWritable.class);    try (SequenceFileVectorWriter writer = new SequenceFileVectorWriter(seqWriter)) {        writer.write(new RandomVectorIterable(50));    }    long count = HadoopUtil.countRecords(path, conf);    assertEquals(50, count);}
public void mahout_f907_0() throws Exception
{    StringWriter strWriter = new StringWriter();    try (VectorWriter writer = new TextualVectorWriter(strWriter)) {        Collection<Vector> vectors = new ArrayList<>();        vectors.add(new DenseVector(new double[] { 0.3, 1.5, 4.5 }));        vectors.add(new DenseVector(new double[] { 1.3, 1.5, 3.5 }));        writer.write(vectors);    }    String buffer = strWriter.toString();    assertNotNull(buffer);    assertFalse(buffer.isEmpty());}
public void mahout_f908_0() throws IOException
{    directory = new RAMDirectory();    FieldType fieldType = new FieldType();    fieldType.setStored(false);    fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);    fieldType.setTokenized(true);    fieldType.setStoreTermVectors(false);    fieldType.setStoreTermVectorPositions(false);    fieldType.setStoreTermVectorOffsets(false);    fieldType.freeze();    directory = createTestIndex(fieldType, directory, 0);}
public void mahout_f909_0() throws Exception
{    IndexReader reader = DirectoryReader.open(directory);    CachedTermInfo cti = new CachedTermInfo(reader, "content", 0, 100);    assertEquals(3, cti.totalTerms("content"));    assertNotNull(cti.getTermEntry("content", "a"));    assertNull(cti.getTermEntry("content", "e"));        cti = new CachedTermInfo(reader, "content", 3, 100);    assertEquals(2, cti.totalTerms("content"));    assertNotNull(cti.getTermEntry("content", "a"));    assertNull(cti.getTermEntry("content", "c"));        cti = new CachedTermInfo(reader, "content", 0, 85);    assertEquals(2, cti.totalTerms("content"));    assertNotNull(cti.getTermEntry("content", "b"));    assertNotNull(cti.getTermEntry("content", "c"));    assertNull(cti.getTermEntry("content", "a"));}
 static RAMDirectory mahout_f910_0(FieldType fieldType, RAMDirectory directory, int startingId) throws IOException
{    IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(new WhitespaceAnalyzer()));    try {        for (int i = 0; i < DOCS.length; i++) {            Document doc = new Document();            Field id = new StringField("id", "doc_" + (i + startingId), Field.Store.YES);            doc.add(id);            Field text = new Field("content", DOCS[i], fieldType);            doc.add(text);            Field text2 = new Field("content2", DOCS2[i], fieldType);            doc.add(text2);            writer.addDocument(doc);        }    } finally {        Closeables.close(writer, false);    }    return directory;}
public void mahout_f911_0() throws Exception
{    super.setUp();    indexDir = getTestTempDir("intermediate");    indexDir.delete();    outputDir = getTestTempDir("output");    outputDir.delete();    conf = getConfiguration();}
private Document mahout_f912_0(String line)
{    Document doc = new Document();    doc.add(new TextFieldWithTermVectors("text", line));    return doc;}
public void mahout_f913_0() throws IOException
{    Directory index = new SimpleFSDirectory(Paths.get(indexDir.getAbsolutePath()));    Analyzer analyzer = new StandardAnalyzer();    IndexWriterConfig config = new IndexWriterConfig(analyzer);    config.setCommitOnClose(true);    final IndexWriter writer = new IndexWriter(index, config);    try {        writer.addDocument(asDocument("One Ring to rule them all"));        writer.addDocument(asDocument("One Ring to find them,"));        writer.addDocument(asDocument("One Ring to bring them all"));        writer.addDocument(asDocument("and in the darkness bind them"));    } finally {        writer.close();    }    File seqDict = new File(outputDir, "dict.seq");    Driver.main(new String[] { "--dir", indexDir.getAbsolutePath(), "--output", new File(outputDir, "out").getAbsolutePath(), "--field", "text", "--dictOut", new File(outputDir, "dict.txt").getAbsolutePath(), "--seqDictOut", seqDict.getAbsolutePath() });    SequenceFile.Reader reader = null;    Set<String> indexTerms = Sets.newHashSet();    try {        reader = new SequenceFile.Reader(FileSystem.getLocal(conf), new Path(seqDict.getAbsolutePath()), conf);        Text term = new Text();        IntWritable termIndex = new IntWritable();        while (reader.next(term, termIndex)) {            indexTerms.add(term.toString());        }    } finally {        Closeables.close(reader, true);    }    Set<String> expectedIndexTerms = Sets.newHashSet("all", "bind", "bring", "darkness", "find", "one", "ring", "rule");        assertEquals(expectedIndexTerms.size(), Sets.union(expectedIndexTerms, indexTerms).size());}
public void mahout_f914_0() throws IOException
{    TYPE_NO_TERM_VECTORS.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);    TYPE_NO_TERM_VECTORS.setTokenized(true);    TYPE_NO_TERM_VECTORS.setStoreTermVectors(false);    TYPE_NO_TERM_VECTORS.setStoreTermVectorPositions(false);    TYPE_NO_TERM_VECTORS.setStoreTermVectorOffsets(false);    TYPE_NO_TERM_VECTORS.freeze();    TYPE_TERM_VECTORS.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);    TYPE_TERM_VECTORS.setTokenized(true);    TYPE_TERM_VECTORS.setStored(true);    TYPE_TERM_VECTORS.setStoreTermVectors(true);    TYPE_TERM_VECTORS.setStoreTermVectorPositions(true);    TYPE_TERM_VECTORS.setStoreTermVectorOffsets(true);    TYPE_TERM_VECTORS.freeze();    directory = createTestIndex(TYPE_TERM_VECTORS);}
public void mahout_f915_0() throws Exception
{    IndexReader reader = DirectoryReader.open(directory);    Weight weight = new TFIDF();    TermInfo termInfo = new CachedTermInfo(reader, "content", 1, 100);    LuceneIterable iterable = new LuceneIterable(reader, "id", "content", termInfo, weight);        for (Vector vector : iterable) {        assertNotNull(vector);        assertTrue("vector is not an instanceof " + NamedVector.class, vector instanceof NamedVector);        assertTrue("vector Size: " + vector.size() + " is not greater than: " + 0, vector.size() > 0);        assertTrue(((NamedVector) vector).getName().startsWith("doc_"));    }    iterable = new LuceneIterable(reader, "id", "content", termInfo, weight, 3);        for (Vector vector : iterable) {        assertNotNull(vector);        assertTrue("vector is not an instanceof " + NamedVector.class, vector instanceof NamedVector);        assertTrue("vector Size: " + vector.size() + " is not greater than: " + 0, vector.size() > 0);        assertTrue(((NamedVector) vector).getName().startsWith("doc_"));    }}
public void mahout_f916_0() throws IOException
{    RAMDirectory directory = createTestIndex(TYPE_NO_TERM_VECTORS);    IndexReader reader = DirectoryReader.open(directory);    Weight weight = new TFIDF();    TermInfo termInfo = new CachedTermInfo(reader, "content", 1, 100);    LuceneIterable iterable = new LuceneIterable(reader, "id", "content", termInfo, weight);    Iterator<Vector> iterator = iterable.iterator();    Iterators.advance(iterator, 1);}
public void mahout_f917_0() throws IOException
{        RAMDirectory directory = createTestIndex(TYPE_TERM_VECTORS, new RAMDirectory(), 0);        createTestIndex(TYPE_NO_TERM_VECTORS, directory, 5);    IndexReader reader = DirectoryReader.open(directory);    Weight weight = new TFIDF();    TermInfo termInfo = new CachedTermInfo(reader, "content", 1, 100);    boolean exceptionThrown;        LuceneIterable iterable = new LuceneIterable(reader, "id", "content", termInfo, weight);    try {        Iterables.skip(iterable, Iterables.size(iterable));        exceptionThrown = false;    } catch (IllegalStateException ise) {        exceptionThrown = true;    }    assertTrue(exceptionThrown);        iterable = new LuceneIterable(reader, "id", "content", termInfo, weight, -1, 1.0);    try {        Iterables.skip(iterable, Iterables.size(iterable));        exceptionThrown = false;    } catch (IllegalStateException ise) {        exceptionThrown = true;    }    assertFalse(exceptionThrown);        iterable = new LuceneIterable(reader, "id", "content", termInfo, weight, -1, 0.5);    Iterator<Vector> iterator = iterable.iterator();    Iterators.advance(iterator, 5);    try {        Iterators.advance(iterator, Iterators.size(iterator));        exceptionThrown = false;    } catch (IllegalStateException ise) {        exceptionThrown = true;    }    assertTrue(exceptionThrown);}
 static RAMDirectory mahout_f918_0(FieldType fieldType) throws IOException
{    return createTestIndex(fieldType, new RAMDirectory(), 0);}
 static RAMDirectory mahout_f919_0(FieldType fieldType, RAMDirectory directory, int startingId) throws IOException
{    try (IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(new StandardAnalyzer()))) {        for (int i = 0; i < DOCS.length; i++) {            Document doc = new Document();            Field id = new StringField("id", "doc_" + (i + startingId), Field.Store.YES);            doc.add(id);                        Field text = new Field("content", DOCS[i], fieldType);            doc.add(text);            Field text2 = new Field("content2", DOCS[i], fieldType);            doc.add(text2);            writer.addDocument(doc);        }    }    return directory;}
public Iterator<Vector> mahout_f920_0()
{    return Iterators.transform(new CountingIterator(numItems), new Function<Integer, Vector>() {        private final Random random = RandomUtils.getRandom();        @Override        public Vector apply(Integer dummy) {            Vector result = type == VectorType.SPARSE ? new RandomAccessSparseVector(numItems) : new DenseVector(numItems);            result.assign(new DoubleFunction() {                @Override                public double apply(double ignored) {                    return random.nextDouble();                }            });            return result;        }    });}
public Vector mahout_f921_0(Integer dummy)
{    Vector result = type == VectorType.SPARSE ? new RandomAccessSparseVector(numItems) : new DenseVector(numItems);    result.assign(new DoubleFunction() {        @Override        public double apply(double ignored) {            return random.nextDouble();        }    });    return result;}
public double mahout_f922_0(double ignored)
{    return random.nextDouble();}
public void mahout_f923_0() throws Exception
{    super.setUp();    conf = getConfiguration();    inputPathOne = getTestTempFilePath("documents/docs-one.file");    FileSystem fs = FileSystem.get(inputPathOne.toUri(), conf);    try (SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, inputPathOne, Text.class, IntWritable.class)) {        Random rd = RandomUtils.getRandom();        for (int i = 0; i < NUM_DOCS; i++) {                        writer.append(new Text("Document::ID::" + i), new IntWritable(NUM_DOCS + rd.nextInt(NUM_DOCS)));        }    }    inputPathTwo = getTestTempFilePath("documents/docs-two.file");    fs = FileSystem.get(inputPathTwo.toUri(), conf);    try (SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, inputPathTwo, Text.class, IntWritable.class)) {        Random rd = RandomUtils.getRandom();        for (int i = 0; i < NUM_DOCS; i++) {                        writer.append(new Text("Document::ID::" + i), new IntWritable(rd.nextInt(NUM_DOCS)));        }    }}
public void mahout_f924_0() throws Exception
{    Vector v = new SequentialAccessSparseVector(10);    v.set(2, 3.1);    v.set(4, 1.0);    v.set(6, 8.1);    v.set(7, -100);    v.set(9, 12.2);    String UNUSED = "UNUSED";    String[] dictionary = { UNUSED, UNUSED, "two", UNUSED, "four", UNUSED, "six", "seven", UNUSED, "nine" };    assertEquals("sorted json form incorrect: ", "{nine:12.2,six:8.1,two:3.1}", VectorHelper.vectorToJson(v, dictionary, 3, true));    assertEquals("unsorted form incorrect: ", "{two:3.1,four:1.0}", VectorHelper.vectorToJson(v, dictionary, 2, false));    assertEquals("sorted json form incorrect: ", "{nine:12.2,six:8.1,two:3.1,four:1.0}", VectorHelper.vectorToJson(v, dictionary, 4, true));    assertEquals("sorted json form incorrect: ", "{nine:12.2,six:8.1,two:3.1,four:1.0,seven:-100.0}", VectorHelper.vectorToJson(v, dictionary, 5, true));    assertEquals("sorted json form incorrect: ", "{nine:12.2,six:8.1}", VectorHelper.vectorToJson(v, dictionary, 2, true));    assertEquals("unsorted form incorrect: ", "{two:3.1,four:1.0}", VectorHelper.vectorToJson(v, dictionary, 2, false));}
public void mahout_f925_0() throws Exception
{    Vector v = new SequentialAccessSparseVector(10);    v.set(2, 3.1);    v.set(4, 1.0);    v.set(6, 8.1);    v.set(7, -100);    v.set(9, 12.2);    v.set(1, 0.0);    v.set(3, 0.0);    v.set(8, 2.7);        assertEquals(6, VectorHelper.topEntries(v, 6).size());        assertTrue(VectorHelper.topEntries(v, 9).size() < 9);        assertTrue(VectorHelper.topEntries(v, 5).size() < v.getNumNonZeroElements());}
public void mahout_f926_0() throws Exception
{    Vector v = new SequentialAccessSparseVector(10);    v.set(2, 0.0);    v.set(4, 0.0);    v.set(6, 0.0);    v.set(7, 0);    v.set(9, 0.0);    v.set(1, 0.0);    v.set(3, 0.0);    v.set(8, 0.0);    assertEquals(0, VectorHelper.topEntries(v, 6).size());}
public void mahout_f927_0() throws Exception
{        VectorHelper.loadTermDictionary(conf, inputPathOne.toString());        VectorHelper.loadTermDictionary(conf, inputPathTwo.toString());}
 static Vector mahout_f928_0(Path dir, Configuration conf) throws IOException
{    Iterator<VectorWritable> iterator = new SequenceFileDirValueIterator<>(dir, PathType.LIST, PathFilters.partFilter(), null, true, conf);    return iterator.hasNext() ? iterator.next().get() : null;}
public static OpenIntObjectHashMap<Vector> mahout_f929_0(int numEntities, Configuration conf) throws IOException
{    IntWritable rowIndex = new IntWritable();    VectorWritable row = new VectorWritable();    OpenIntObjectHashMap<Vector> featureMatrix = numEntities > 0 ? new OpenIntObjectHashMap<Vector>(numEntities) : new OpenIntObjectHashMap<Vector>();    Path[] cachedFiles = HadoopUtil.getCachedFiles(conf);    LocalFileSystem localFs = FileSystem.getLocal(conf);    for (Path cachedFile : cachedFiles) {        try (SequenceFile.Reader reader = new SequenceFile.Reader(localFs.getConf(), SequenceFile.Reader.file(cachedFile))) {            while (reader.next(rowIndex, row)) {                featureMatrix.put(rowIndex.get(), row.get());            }        }    }    Preconditions.checkState(!featureMatrix.isEmpty(), "Feature matrix is empty");    return featureMatrix;}
public static OpenIntObjectHashMap<Vector> mahout_f930_0(Path dir, Configuration conf)
{    OpenIntObjectHashMap<Vector> matrix = new OpenIntObjectHashMap<>();    for (Pair<IntWritable, VectorWritable> pair : new SequenceFileDirIterable<IntWritable, VectorWritable>(dir, PathType.LIST, PathFilters.partFilter(), conf)) {        int rowIndex = pair.getFirst().get();        Vector row = pair.getSecond().get();        matrix.put(rowIndex, row);    }    return matrix;}
public static Vector mahout_f931_0(VectorWritable ratingsWritable, OpenIntObjectHashMap<Vector> uOrM, double lambda, int numFeatures)
{    Vector ratings = ratingsWritable.get();    List<Vector> featureVectors = new ArrayList<>(ratings.getNumNondefaultElements());    for (Vector.Element e : ratings.nonZeroes()) {        int index = e.index();        featureVectors.add(uOrM.get(index));    }    return AlternatingLeastSquaresSolver.solve(featureVectors, ratings, lambda, numFeatures);}
public static void mahout_f932_0(String[] args) throws Exception
{    ToolRunner.run(new DatasetSplitter(), args);}
public int mahout_f933_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption("trainingPercentage", "t", "percentage of the data to use as training set (default: " + DEFAULT_TRAINING_PERCENTAGE + ')', String.valueOf(DEFAULT_TRAINING_PERCENTAGE));    addOption("probePercentage", "p", "percentage of the data to use as probe set (default: " + DEFAULT_PROBE_PERCENTAGE + ')', String.valueOf(DEFAULT_PROBE_PERCENTAGE));    Map<String, List<String>> parsedArgs = parseArguments(args);    if (parsedArgs == null) {        return -1;    }    double trainingPercentage = Double.parseDouble(getOption("trainingPercentage"));    double probePercentage = Double.parseDouble(getOption("probePercentage"));    String tempDir = getOption("tempDir");    Path markedPrefs = new Path(tempDir, "markedPreferences");    Path trainingSetPath = new Path(getOutputPath(), "trainingSet");    Path probeSetPath = new Path(getOutputPath(), "probeSet");    Job markPreferences = prepareJob(getInputPath(), markedPrefs, TextInputFormat.class, MarkPreferencesMapper.class, Text.class, Text.class, SequenceFileOutputFormat.class);    markPreferences.getConfiguration().set(TRAINING_PERCENTAGE, String.valueOf(trainingPercentage));    markPreferences.getConfiguration().set(PROBE_PERCENTAGE, String.valueOf(probePercentage));    boolean succeeded = markPreferences.waitForCompletion(true);    if (!succeeded) {        return -1;    }    Job createTrainingSet = prepareJob(markedPrefs, trainingSetPath, SequenceFileInputFormat.class, WritePrefsMapper.class, NullWritable.class, Text.class, TextOutputFormat.class);    createTrainingSet.getConfiguration().set(PART_TO_USE, INTO_TRAINING_SET.toString());    succeeded = createTrainingSet.waitForCompletion(true);    if (!succeeded) {        return -1;    }    Job createProbeSet = prepareJob(markedPrefs, probeSetPath, SequenceFileInputFormat.class, WritePrefsMapper.class, NullWritable.class, Text.class, TextOutputFormat.class);    createProbeSet.getConfiguration().set(PART_TO_USE, INTO_PROBE_SET.toString());    succeeded = createProbeSet.waitForCompletion(true);    if (!succeeded) {        return -1;    }    return 0;}
protected void mahout_f934_0(Context ctx) throws IOException, InterruptedException
{    random = RandomUtils.getRandom();    trainingBound = Double.parseDouble(ctx.getConfiguration().get(TRAINING_PERCENTAGE));    probeBound = trainingBound + Double.parseDouble(ctx.getConfiguration().get(PROBE_PERCENTAGE));}
protected void mahout_f935_0(LongWritable key, Text text, Context ctx) throws IOException, InterruptedException
{    double randomValue = random.nextDouble();    if (randomValue <= trainingBound) {        ctx.write(INTO_TRAINING_SET, text);    } else if (randomValue <= probeBound) {        ctx.write(INTO_PROBE_SET, text);    }}
protected void mahout_f936_0(Context ctx) throws IOException, InterruptedException
{    partToUse = ctx.getConfiguration().get(PART_TO_USE);}
protected void mahout_f937_0(Text key, Text text, Context ctx) throws IOException, InterruptedException
{    if (partToUse.equals(key.toString())) {        ctx.write(NullWritable.get(), text);    }}
public static void mahout_f938_0(String[] args) throws Exception
{    ToolRunner.run(new FactorizationEvaluator(), args);}
public int mahout_f939_0(String[] args) throws Exception
{    addInputOption();    addOption("userFeatures", null, "path to the user feature matrix", true);    addOption("itemFeatures", null, "path to the item feature matrix", true);    addOption("usesLongIDs", null, "input contains long IDs that need to be translated");    addOutputOption();    Map<String, List<String>> parsedArgs = parseArguments(args);    if (parsedArgs == null) {        return -1;    }    Path errors = getTempPath("errors");    Job predictRatings = prepareJob(getInputPath(), errors, TextInputFormat.class, PredictRatingsMapper.class, DoubleWritable.class, NullWritable.class, SequenceFileOutputFormat.class);    Configuration conf = predictRatings.getConfiguration();    conf.set(USER_FEATURES_PATH, getOption("userFeatures"));    conf.set(ITEM_FEATURES_PATH, getOption("itemFeatures"));    boolean usesLongIDs = Boolean.parseBoolean(getOption("usesLongIDs"));    if (usesLongIDs) {        conf.set(ParallelALSFactorizationJob.USES_LONG_IDS, String.valueOf(true));    }    boolean succeeded = predictRatings.waitForCompletion(true);    if (!succeeded) {        return -1;    }    FileSystem fs = FileSystem.get(getOutputPath().toUri(), getConf());    FSDataOutputStream outputStream = fs.create(getOutputPath("rmse.txt"));    try (BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(outputStream, Charsets.UTF_8))) {        double rmse = computeRmse(errors);        writer.write(String.valueOf(rmse));    }    return 0;}
private double mahout_f940_0(Path errors)
{    RunningAverage average = new FullRunningAverage();    for (Pair<DoubleWritable, NullWritable> entry : new SequenceFileDirIterable<DoubleWritable, NullWritable>(errors, PathType.LIST, PathFilters.logsCRCFilter(), getConf())) {        DoubleWritable error = entry.getFirst();        average.addDatum(error.get() * error.get());    }    return Math.sqrt(average.getAverage());}
protected void mahout_f941_0(Context ctx) throws IOException, InterruptedException
{    Configuration conf = ctx.getConfiguration();    Path pathToU = new Path(conf.get(USER_FEATURES_PATH));    Path pathToM = new Path(conf.get(ITEM_FEATURES_PATH));    U = ALS.readMatrixByRows(pathToU, conf);    M = ALS.readMatrixByRows(pathToM, conf);    usesLongIDs = conf.getBoolean(ParallelALSFactorizationJob.USES_LONG_IDS, false);}
protected void mahout_f942_0(LongWritable key, Text value, Context ctx) throws IOException, InterruptedException
{    String[] tokens = TasteHadoopUtils.splitPrefTokens(value.toString());    int userID = TasteHadoopUtils.readID(tokens[TasteHadoopUtils.USER_ID_POS], usesLongIDs);    int itemID = TasteHadoopUtils.readID(tokens[TasteHadoopUtils.ITEM_ID_POS], usesLongIDs);    double rating = Double.parseDouble(tokens[2]);    if (U.containsKey(userID) && M.containsKey(itemID)) {        double estimate = U.get(userID).dot(M.get(itemID));        error.set(rating - estimate);        ctx.write(error, NullWritable.get());    }}
public void mahout_f943_0(Context ctx) throws IOException, InterruptedException
{    Class<Mapper<K1, V1, K2, V2>> mapperClass = MultithreadedSharingMapper.getMapperClass((JobContext) ctx);    Preconditions.checkNotNull(mapperClass, "Could not find Multithreaded Mapper class.");    Configuration conf = ctx.getConfiguration();        Mapper<K1, V1, K2, V2> mapper1 = ReflectionUtils.newInstance(mapperClass, conf);    SharingMapper<K1, V1, K2, V2, ?> mapper = null;    if (mapper1 instanceof SharingMapper) {        mapper = (SharingMapper<K1, V1, K2, V2, ?>) mapper1;    }    Preconditions.checkNotNull(mapper, "Could not instantiate SharingMapper. Class was: %s", mapper1.getClass().getName());        mapper.setupSharedInstance(ctx);        super.run(ctx);}
public static void mahout_f944_0(String[] args) throws Exception
{    ToolRunner.run(new ParallelALSFactorizationJob(), args);}
public int mahout_f945_1(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption("lambda", null, "regularization parameter", true);    addOption("implicitFeedback", null, "data consists of implicit feedback?", String.valueOf(false));    addOption("alpha", null, "confidence parameter (only used on implicit feedback)", String.valueOf(40));    addOption("numFeatures", null, "dimension of the feature space", true);    addOption("numIterations", null, "number of iterations", true);    addOption("numThreadsPerSolver", null, "threads per solver mapper", String.valueOf(1));    addOption("usesLongIDs", null, "input contains long IDs that need to be translated");    Map<String, List<String>> parsedArgs = parseArguments(args);    if (parsedArgs == null) {        return -1;    }    numFeatures = Integer.parseInt(getOption("numFeatures"));    numIterations = Integer.parseInt(getOption("numIterations"));    lambda = Double.parseDouble(getOption("lambda"));    alpha = Double.parseDouble(getOption("alpha"));    implicitFeedback = Boolean.parseBoolean(getOption("implicitFeedback"));    numThreadsPerSolver = Integer.parseInt(getOption("numThreadsPerSolver"));    boolean usesLongIDs = Boolean.parseBoolean(getOption("usesLongIDs", String.valueOf(false)));    if (usesLongIDs) {        Job mapUsers = prepareJob(getInputPath(), getOutputPath("userIDIndex"), TextInputFormat.class, MapLongIDsMapper.class, VarIntWritable.class, VarLongWritable.class, IDMapReducer.class, VarIntWritable.class, VarLongWritable.class, SequenceFileOutputFormat.class);        mapUsers.getConfiguration().set(TOKEN_POS, String.valueOf(TasteHadoopUtils.USER_ID_POS));        mapUsers.waitForCompletion(true);        Job mapItems = prepareJob(getInputPath(), getOutputPath("itemIDIndex"), TextInputFormat.class, MapLongIDsMapper.class, VarIntWritable.class, VarLongWritable.class, IDMapReducer.class, VarIntWritable.class, VarLongWritable.class, SequenceFileOutputFormat.class);        mapItems.getConfiguration().set(TOKEN_POS, String.valueOf(TasteHadoopUtils.ITEM_ID_POS));        mapItems.waitForCompletion(true);    }    /* create A' */    Job itemRatings = prepareJob(getInputPath(), pathToItemRatings(), TextInputFormat.class, ItemRatingVectorsMapper.class, IntWritable.class, VectorWritable.class, VectorSumReducer.class, IntWritable.class, VectorWritable.class, SequenceFileOutputFormat.class);    itemRatings.setCombinerClass(VectorSumCombiner.class);    itemRatings.getConfiguration().set(USES_LONG_IDS, String.valueOf(usesLongIDs));    boolean succeeded = itemRatings.waitForCompletion(true);    if (!succeeded) {        return -1;    }    /* create A */    Job userRatings = prepareJob(pathToItemRatings(), pathToUserRatings(), TransposeMapper.class, IntWritable.class, VectorWritable.class, MergeUserVectorsReducer.class, IntWritable.class, VectorWritable.class);    userRatings.setCombinerClass(MergeVectorsCombiner.class);    succeeded = userRatings.waitForCompletion(true);    if (!succeeded) {        return -1;    }        Job averageItemRatings = prepareJob(pathToItemRatings(), getTempPath("averageRatings"), AverageRatingMapper.class, IntWritable.class, VectorWritable.class, MergeVectorsReducer.class, IntWritable.class, VectorWritable.class);    averageItemRatings.setCombinerClass(MergeVectorsCombiner.class);    succeeded = averageItemRatings.waitForCompletion(true);    if (!succeeded) {        return -1;    }    Vector averageRatings = ALS.readFirstRow(getTempPath("averageRatings"), getConf());    int numItems = averageRatings.getNumNondefaultElements();    int numUsers = (int) userRatings.getCounters().findCounter(Stats.NUM_USERS).getValue();        /* create an initial M */    initializeM(averageRatings);    for (int currentIteration = 0; currentIteration < numIterations; currentIteration++) {        /* broadcast M, read A row-wise, recompute U row-wise */                runSolver(pathToUserRatings(), pathToU(currentIteration), pathToM(currentIteration - 1), currentIteration, "U", numItems);        /* broadcast U, read A' row-wise, recompute M row-wise */                runSolver(pathToItemRatings(), pathToM(currentIteration), pathToU(currentIteration), currentIteration, "M", numUsers);    }    return 0;}
private void mahout_f946_0(Vector averageRatings) throws IOException
{    Random random = RandomUtils.getRandom();    FileSystem fs = FileSystem.get(pathToM(-1).toUri(), getConf());    try (SequenceFile.Writer writer = new SequenceFile.Writer(fs, getConf(), new Path(pathToM(-1), "part-m-00000"), IntWritable.class, VectorWritable.class)) {        IntWritable index = new IntWritable();        VectorWritable featureVector = new VectorWritable();        for (Vector.Element e : averageRatings.nonZeroes()) {            Vector row = new DenseVector(numFeatures);            row.setQuick(0, e.get());            for (int m = 1; m < numFeatures; m++) {                row.setQuick(m, random.nextDouble());            }            index.set(e.index());            featureVector.set(row);            writer.append(index, featureVector);        }    }}
protected void mahout_f947_0(WritableComparable<?> key, Iterable<VectorWritable> values, Context ctx) throws IOException, InterruptedException
{    Vector sum = Vectors.sum(values.iterator());    result.set(new SequentialAccessSparseVector(sum));    ctx.write(key, result);}
public void mahout_f948_0(WritableComparable<?> key, Iterable<VectorWritable> vectors, Context ctx) throws IOException, InterruptedException
{    Vector merged = VectorWritable.merge(vectors.iterator()).get();    result.set(new SequentialAccessSparseVector(merged));    ctx.write(key, result);    ctx.getCounter(Stats.NUM_USERS).increment(1);}
protected void mahout_f949_0(Context ctx) throws IOException, InterruptedException
{    usesLongIDs = ctx.getConfiguration().getBoolean(USES_LONG_IDS, false);}
protected void mahout_f950_0(LongWritable offset, Text line, Context ctx) throws IOException, InterruptedException
{    String[] tokens = TasteHadoopUtils.splitPrefTokens(line.toString());    int userID = TasteHadoopUtils.readID(tokens[TasteHadoopUtils.USER_ID_POS], usesLongIDs);    int itemID = TasteHadoopUtils.readID(tokens[TasteHadoopUtils.ITEM_ID_POS], usesLongIDs);    float rating = Float.parseFloat(tokens[2]);    ratings.setQuick(userID, rating);    itemIDWritable.set(itemID);    ratingsWritable.set(ratings);    ctx.write(itemIDWritable, ratingsWritable);        ratings.setQuick(userID, 0.0d);}
private void mahout_f951_1(Path ratings, Path output, Path pathToUorM, int currentIteration, String matrixName, int numEntities) throws ClassNotFoundException, IOException, InterruptedException
{        SharingMapper.reset();    Class<? extends Mapper<IntWritable, VectorWritable, IntWritable, VectorWritable>> solverMapperClassInternal;    String name;    if (implicitFeedback) {        solverMapperClassInternal = SolveImplicitFeedbackMapper.class;        name = "Recompute " + matrixName + ", iteration (" + currentIteration + '/' + numIterations + "), " + '(' + numThreadsPerSolver + " threads, " + numFeatures + " features, implicit feedback)";    } else {        solverMapperClassInternal = SolveExplicitFeedbackMapper.class;        name = "Recompute " + matrixName + ", iteration (" + currentIteration + '/' + numIterations + "), " + '(' + numThreadsPerSolver + " threads, " + numFeatures + " features, explicit feedback)";    }    Job solverForUorI = prepareJob(ratings, output, SequenceFileInputFormat.class, MultithreadedSharingMapper.class, IntWritable.class, VectorWritable.class, SequenceFileOutputFormat.class, name);    Configuration solverConf = solverForUorI.getConfiguration();    solverConf.set(LAMBDA, String.valueOf(lambda));    solverConf.set(ALPHA, String.valueOf(alpha));    solverConf.setInt(NUM_FEATURES, numFeatures);    solverConf.set(NUM_ENTITIES, String.valueOf(numEntities));    FileSystem fs = FileSystem.get(pathToUorM.toUri(), solverConf);    FileStatus[] parts = fs.listStatus(pathToUorM, PathFilters.partFilter());    for (FileStatus part : parts) {        if (log.isDebugEnabled()) {                    }        DistributedCache.addCacheFile(part.getPath().toUri(), solverConf);    }    MultithreadedMapper.setMapperClass(solverForUorI, solverMapperClassInternal);    MultithreadedMapper.setNumberOfThreads(solverForUorI, numThreadsPerSolver);    boolean succeeded = solverForUorI.waitForCompletion(true);    if (!succeeded) {        throw new IllegalStateException("Job failed!");    }}
protected void mahout_f952_0(IntWritable r, VectorWritable v, Context ctx) throws IOException, InterruptedException
{    RunningAverage avg = new FullRunningAverage();    for (Vector.Element e : v.get().nonZeroes()) {        avg.addDatum(e.get());    }    featureVector.setQuick(r.get(), avg.getAverage());    featureVectorWritable.set(featureVector);    ctx.write(firstIndex, featureVectorWritable);        featureVector.setQuick(r.get(), 0.0d);}
protected void mahout_f953_0(Context ctx) throws IOException, InterruptedException
{    tokenPos = ctx.getConfiguration().getInt(TOKEN_POS, -1);    Preconditions.checkState(tokenPos >= 0);}
protected void mahout_f954_0(LongWritable key, Text line, Context ctx) throws IOException, InterruptedException
{    String[] tokens = TasteHadoopUtils.splitPrefTokens(line.toString());    long id = Long.parseLong(tokens[tokenPos]);    index.set(TasteHadoopUtils.idToIndex(id));    idWritable.set(id);    ctx.write(index, idWritable);}
protected void mahout_f955_0(VarIntWritable index, Iterable<VarLongWritable> ids, Context ctx) throws IOException, InterruptedException
{    ctx.write(index, ids.iterator().next());}
private Path mahout_f956_0(int iteration)
{    return iteration == numIterations - 1 ? getOutputPath("M") : getTempPath("M-" + iteration);}
private Path mahout_f957_0(int iteration)
{    return iteration == numIterations - 1 ? getOutputPath("U") : getTempPath("U-" + iteration);}
private Path mahout_f958_0()
{    return getTempPath("itemRatings");}
private Path mahout_f959_0()
{    return getOutputPath("userRatings");}
 Pair<OpenIntObjectHashMap<Vector>, OpenIntObjectHashMap<Vector>> mahout_f960_0(Context ctx)
{    Configuration conf = ctx.getConfiguration();    Path pathToU = new Path(conf.get(RecommenderJob.USER_FEATURES_PATH));    Path pathToM = new Path(conf.get(RecommenderJob.ITEM_FEATURES_PATH));    OpenIntObjectHashMap<Vector> U = ALS.readMatrixByRows(pathToU, conf);    OpenIntObjectHashMap<Vector> M = ALS.readMatrixByRows(pathToM, conf);    return new Pair<>(U, M);}
protected void mahout_f961_0(Context ctx) throws IOException, InterruptedException
{    Configuration conf = ctx.getConfiguration();    recommendationsPerUser = conf.getInt(RecommenderJob.NUM_RECOMMENDATIONS, RecommenderJob.DEFAULT_NUM_RECOMMENDATIONS);    maxRating = Float.parseFloat(conf.get(RecommenderJob.MAX_RATING));    usesLongIDs = conf.getBoolean(ParallelALSFactorizationJob.USES_LONG_IDS, false);    if (usesLongIDs) {        userIDIndex = TasteHadoopUtils.readIDIndexMap(conf.get(RecommenderJob.USER_INDEX_PATH), conf);        itemIDIndex = TasteHadoopUtils.readIDIndexMap(conf.get(RecommenderJob.ITEM_INDEX_PATH), conf);    }}
protected void mahout_f962_0(IntWritable userIndexWritable, VectorWritable ratingsWritable, Context ctx) throws IOException, InterruptedException
{    Pair<OpenIntObjectHashMap<Vector>, OpenIntObjectHashMap<Vector>> uAndM = getSharedInstance();    OpenIntObjectHashMap<Vector> U = uAndM.getFirst();    OpenIntObjectHashMap<Vector> M = uAndM.getSecond();    Vector ratings = ratingsWritable.get();    int userIndex = userIndexWritable.get();    final OpenIntHashSet alreadyRatedItems = new OpenIntHashSet(ratings.getNumNondefaultElements());    for (Vector.Element e : ratings.nonZeroes()) {        alreadyRatedItems.add(e.index());    }    final TopItemsQueue topItemsQueue = new TopItemsQueue(recommendationsPerUser);    final Vector userFeatures = U.get(userIndex);    M.forEachPair(new IntObjectProcedure<Vector>() {        @Override        public boolean apply(int itemID, Vector itemFeatures) {            if (!alreadyRatedItems.contains(itemID)) {                double predictedRating = userFeatures.dot(itemFeatures);                MutableRecommendedItem top = topItemsQueue.top();                if (predictedRating > top.getValue()) {                    top.set(itemID, (float) predictedRating);                    topItemsQueue.updateTop();                }            }            return true;        }    });    List<RecommendedItem> recommendedItems = topItemsQueue.getTopItems();    if (!recommendedItems.isEmpty()) {                for (RecommendedItem topItem : recommendedItems) {            ((MutableRecommendedItem) topItem).capToMaxValue(maxRating);        }        if (usesLongIDs) {            long userID = userIDIndex.get(userIndex);            userIDWritable.set(userID);            for (RecommendedItem topItem : recommendedItems) {                                long itemID = itemIDIndex.get((int) topItem.getItemID());                ((MutableRecommendedItem) topItem).setItemID(itemID);            }        } else {            userIDWritable.set(userIndex);        }        recommendations.set(recommendedItems);        ctx.write(userIDWritable, recommendations);    }}
public boolean mahout_f963_0(int itemID, Vector itemFeatures)
{    if (!alreadyRatedItems.contains(itemID)) {        double predictedRating = userFeatures.dot(itemFeatures);        MutableRecommendedItem top = topItemsQueue.top();        if (predictedRating > top.getValue()) {            top.set(itemID, (float) predictedRating);            topItemsQueue.updateTop();        }    }    return true;}
public static void mahout_f964_0(String[] args) throws Exception
{    ToolRunner.run(new RecommenderJob(), args);}
public int mahout_f965_0(String[] args) throws Exception
{    addInputOption();    addOption("userFeatures", null, "path to the user feature matrix", true);    addOption("itemFeatures", null, "path to the item feature matrix", true);    addOption("numRecommendations", null, "number of recommendations per user", String.valueOf(DEFAULT_NUM_RECOMMENDATIONS));    addOption("maxRating", null, "maximum rating available", true);    addOption("numThreads", null, "threads per mapper", String.valueOf(1));    addOption("usesLongIDs", null, "input contains long IDs that need to be translated");    addOption("userIDIndex", null, "index for user long IDs (necessary if usesLongIDs is true)");    addOption("itemIDIndex", null, "index for user long IDs (necessary if usesLongIDs is true)");    addOutputOption();    Map<String, List<String>> parsedArgs = parseArguments(args);    if (parsedArgs == null) {        return -1;    }    Job prediction = prepareJob(getInputPath(), getOutputPath(), SequenceFileInputFormat.class, MultithreadedSharingMapper.class, IntWritable.class, RecommendedItemsWritable.class, TextOutputFormat.class);    Configuration conf = prediction.getConfiguration();    int numThreads = Integer.parseInt(getOption("numThreads"));    conf.setInt(NUM_RECOMMENDATIONS, Integer.parseInt(getOption("numRecommendations")));    conf.set(USER_FEATURES_PATH, getOption("userFeatures"));    conf.set(ITEM_FEATURES_PATH, getOption("itemFeatures"));    conf.set(MAX_RATING, getOption("maxRating"));    boolean usesLongIDs = Boolean.parseBoolean(getOption("usesLongIDs"));    if (usesLongIDs) {        conf.set(ParallelALSFactorizationJob.USES_LONG_IDS, String.valueOf(true));        conf.set(USER_INDEX_PATH, getOption("userIDIndex"));        conf.set(ITEM_INDEX_PATH, getOption("itemIDIndex"));    }    MultithreadedMapper.setMapperClass(prediction, PredictionMapper.class);    MultithreadedMapper.setNumberOfThreads(prediction, numThreads);    boolean succeeded = prediction.waitForCompletion(true);    if (!succeeded) {        return -1;    }    return 0;}
 final void mahout_f966_0(Context context) throws IOException
{    if (SHARED_INSTANCE == null) {        SHARED_INSTANCE = createSharedInstance(context);    }}
 final S mahout_f967_0()
{    return (S) SHARED_INSTANCE;}
 static void mahout_f968_0()
{    SHARED_INSTANCE = null;}
 OpenIntObjectHashMap<Vector> mahout_f969_0(Context ctx) throws IOException
{    Configuration conf = ctx.getConfiguration();    int numEntities = Integer.parseInt(conf.get(ParallelALSFactorizationJob.NUM_ENTITIES));    return ALS.readMatrixByRowsFromDistributedCache(numEntities, conf);}
protected void mahout_f970_0(Mapper.Context ctx) throws IOException, InterruptedException
{    lambda = Double.parseDouble(ctx.getConfiguration().get(ParallelALSFactorizationJob.LAMBDA));    numFeatures = ctx.getConfiguration().getInt(ParallelALSFactorizationJob.NUM_FEATURES, -1);    Preconditions.checkArgument(numFeatures > 0, "numFeatures must be greater then 0!");}
protected void mahout_f971_0(IntWritable userOrItemID, VectorWritable ratingsWritable, Context ctx) throws IOException, InterruptedException
{    OpenIntObjectHashMap<Vector> uOrM = getSharedInstance();    uiOrmj.set(ALS.solveExplicit(ratingsWritable, uOrM, lambda, numFeatures));    ctx.write(userOrItemID, uiOrmj);}
 ImplicitFeedbackAlternatingLeastSquaresSolver mahout_f972_0(Context ctx) throws IOException
{    Configuration conf = ctx.getConfiguration();    double lambda = Double.parseDouble(conf.get(ParallelALSFactorizationJob.LAMBDA));    double alpha = Double.parseDouble(conf.get(ParallelALSFactorizationJob.ALPHA));    int numFeatures = conf.getInt(ParallelALSFactorizationJob.NUM_FEATURES, -1);    int numEntities = Integer.parseInt(conf.get(ParallelALSFactorizationJob.NUM_ENTITIES));    Preconditions.checkArgument(numFeatures > 0, "numFeatures must be greater then 0!");    return new ImplicitFeedbackAlternatingLeastSquaresSolver(numFeatures, lambda, alpha, ALS.readMatrixByRowsFromDistributedCache(numEntities, conf), 1);}
protected void mahout_f973_0(IntWritable userOrItemID, VectorWritable ratingsWritable, Context ctx) throws IOException, InterruptedException
{    ImplicitFeedbackAlternatingLeastSquaresSolver solver = getSharedInstance();    uiOrmj.set(solver.solve(ratingsWritable.get()));    ctx.write(userOrItemID, uiOrmj);}
 long mahout_f974_0()
{    return aID;}
 long mahout_f975_0()
{    return bID;}
public void mahout_f976_0(DataOutput out) throws IOException
{    Varint.writeSignedVarLong(aID, out);    Varint.writeSignedVarLong(bID, out);}
public void mahout_f977_0(DataInput in) throws IOException
{    aID = Varint.readSignedVarLong(in);    bID = Varint.readSignedVarLong(in);}
public int mahout_f978_0(EntityEntityWritable that)
{    int aCompare = compare(aID, that.getAID());    return aCompare == 0 ? compare(bID, that.getBID()) : aCompare;}
private static int mahout_f979_0(long a, long b)
{    return a < b ? -1 : a > b ? 1 : 0;}
public int mahout_f980_0()
{    return Longs.hashCode(aID) + 31 * Longs.hashCode(bID);}
public boolean mahout_f981_0(Object o)
{    if (o instanceof EntityEntityWritable) {        EntityEntityWritable that = (EntityEntityWritable) o;        return aID == that.getAID() && bID == that.getBID();    }    return false;}
public String mahout_f982_0()
{    return aID + "\t" + bID;}
public EntityEntityWritable mahout_f983_0()
{    return new EntityEntityWritable(aID, bID);}
public long mahout_f984_0()
{    return get();}
public float mahout_f985_0()
{    return prefValue;}
public void mahout_f986_0(DataOutput out) throws IOException
{    super.write(out);    out.writeFloat(prefValue);}
public void mahout_f987_0(DataInput in) throws IOException
{    super.readFields(in);    prefValue = in.readFloat();}
public int mahout_f988_0()
{    return super.hashCode() ^ RandomUtils.hashFloat(prefValue);}
public boolean mahout_f989_0(Object o)
{    if (!(o instanceof EntityPrefWritable)) {        return false;    }    EntityPrefWritable other = (EntityPrefWritable) o;    return get() == other.get() && prefValue == other.getPrefValue();}
public String mahout_f990_0()
{    return get() + "\t" + prefValue;}
public EntityPrefWritable mahout_f991_0()
{    return new EntityPrefWritable(get(), prefValue);}
protected void mahout_f992_0(Context context) throws IOException
{    Configuration conf = context.getConfiguration();    recommendationsPerUser = conf.getInt(NUM_RECOMMENDATIONS, DEFAULT_NUM_RECOMMENDATIONS);    booleanData = conf.getBoolean(RecommenderJob.BOOLEAN_DATA, false);    indexItemIDMap = TasteHadoopUtils.readIDIndexMap(conf.get(ITEMID_INDEX_PATH), conf);    idReader = new IDReader(conf);    idReader.readIDs();    itemsToRecommendFor = idReader.getItemIds();}
protected void mahout_f993_0(VarLongWritable userID, Iterable<PrefAndSimilarityColumnWritable> values, Context context) throws IOException, InterruptedException
{    if (booleanData) {        reduceBooleanData(userID, values, context);    } else {        reduceNonBooleanData(userID, values, context);    }}
private void mahout_f994_0(VarLongWritable userID, Iterable<PrefAndSimilarityColumnWritable> values, Context context) throws IOException, InterruptedException
{    /* having boolean data, each estimated preference can only be 1,     * however we can't use this to rank the recommended items,     * so we use the sum of similarities for that. */    Iterator<PrefAndSimilarityColumnWritable> columns = values.iterator();    Vector predictions = columns.next().getSimilarityColumn();    while (columns.hasNext()) {        predictions.assign(columns.next().getSimilarityColumn(), Functions.PLUS);    }    writeRecommendedItems(userID, predictions, context);}
private void mahout_f995_0(VarLongWritable userID, Iterable<PrefAndSimilarityColumnWritable> values, Context context) throws IOException, InterruptedException
{    /* each entry here is the sum in the numerator of the prediction formula */    Vector numerators = null;    /* each entry here is the sum in the denominator of the prediction formula */    Vector denominators = null;    /* each entry here is the number of similar items used in the prediction formula */    Vector numberOfSimilarItemsUsed = new RandomAccessSparseVector(Integer.MAX_VALUE, 100);    for (PrefAndSimilarityColumnWritable prefAndSimilarityColumn : values) {        Vector simColumn = prefAndSimilarityColumn.getSimilarityColumn();        float prefValue = prefAndSimilarityColumn.getPrefValue();        /* count the number of items used for each prediction */        for (Element e : simColumn.nonZeroes()) {            int itemIDIndex = e.index();            numberOfSimilarItemsUsed.setQuick(itemIDIndex, numberOfSimilarItemsUsed.getQuick(itemIDIndex) + 1);        }        if (denominators == null) {            denominators = simColumn.clone();        } else {            denominators.assign(simColumn, Functions.PLUS_ABS);        }        if (numerators == null) {            numerators = simColumn.clone();            if (prefValue != BOOLEAN_PREF_VALUE) {                numerators.assign(Functions.MULT, prefValue);            }        } else {            if (prefValue != BOOLEAN_PREF_VALUE) {                simColumn.assign(Functions.MULT, prefValue);            }            numerators.assign(simColumn, Functions.PLUS);        }    }    if (numerators == null) {        return;    }    Vector recommendationVector = new RandomAccessSparseVector(Integer.MAX_VALUE, 100);    for (Element element : numerators.nonZeroes()) {        int itemIDIndex = element.index();        /* preference estimations must be based on at least 2 datapoints */        if (numberOfSimilarItemsUsed.getQuick(itemIDIndex) > 1) {            /* compute normalized prediction */            double prediction = element.get() / denominators.getQuick(itemIDIndex);            recommendationVector.setQuick(itemIDIndex, prediction);        }    }    writeRecommendedItems(userID, recommendationVector, context);}
private void mahout_f996_0(VarLongWritable userID, Vector recommendationVector, Context context) throws IOException, InterruptedException
{    TopItemsQueue topKItems = new TopItemsQueue(recommendationsPerUser);    FastIDSet itemsForUser = null;    if (idReader != null && idReader.isUserItemFilterSpecified()) {        itemsForUser = idReader.getItemsToRecommendForUser(userID.get());    }    for (Element element : recommendationVector.nonZeroes()) {        int index = element.index();        long itemID;        if (indexItemIDMap != null && !indexItemIDMap.isEmpty()) {            itemID = indexItemIDMap.get(index);        } else {                        itemID = index;        }        if (shouldIncludeItemIntoRecommendations(itemID, itemsToRecommendFor, itemsForUser)) {            float value = (float) element.get();            if (!Float.isNaN(value)) {                MutableRecommendedItem topItem = topKItems.top();                if (value > topItem.getValue()) {                    topItem.set(itemID, value);                    topKItems.updateTop();                }            }        }    }    List<RecommendedItem> topItems = topKItems.getTopItems();    if (!topItems.isEmpty()) {        recommendedItems.set(topItems);        context.write(userID, recommendedItems);    }}
private boolean mahout_f997_0(long itemID, FastIDSet allItemsToRecommendFor, FastIDSet itemsForUser)
{    if (allItemsToRecommendFor == null && itemsForUser == null) {        return true;    } else if (itemsForUser != null) {        return itemsForUser.contains(itemID);    } else {        return allItemsToRecommendFor.contains(itemID);    }}
public void mahout_f998_0() throws IOException, IllegalStateException
{    if (isUserItemFileSpecified()) {        readUserItemFilterIfNeeded();    }    if (isUsersFileSpecified() || isUserItemFilterSpecified()) {        readUserIds();    }    if (isItemsFileSpecified() || isUserItemFilterSpecified()) {        readItemIds();    }}
public FastIDSet mahout_f999_0(Long userId)
{    if (isUserItemFilterSpecified() && userItemFilter.containsKey(userId)) {        return userItemFilter.get(userId);    } else {        return emptySet;    }}
private void mahout_f1000_0() throws IOException, IllegalStateException
{    if (isUsersFileSpecified() && !isUserItemFileSpecified()) {        userIds = readIDList(usersFile);    } else if (isUserItemFileSpecified() && !isUsersFileSpecified()) {        readUserItemFilterIfNeeded();        userIds = extractAllUserIdsFromUserItemFilter(userItemFilter);    } else if (!isUsersFileSpecified()) {        throw new IllegalStateException("Neither usersFile nor userItemFile options are specified");    } else {        throw new IllegalStateException("usersFile and userItemFile options cannot be used simultaneously");    }}
private void mahout_f1001_0() throws IOException, IllegalStateException
{    if (isItemsFileSpecified() && !isUserItemFileSpecified()) {        itemIds = readIDList(itemsFile);    } else if (isUserItemFileSpecified() && !isItemsFileSpecified()) {        readUserItemFilterIfNeeded();        itemIds = extractAllItemIdsFromUserItemFilter(userItemFilter);    } else if (!isItemsFileSpecified()) {        throw new IllegalStateException("Neither itemsFile nor userItemFile options are specified");    } else {        throw new IllegalStateException("itemsFile and userItemFile options cannot be specified simultaneously");    }}
private void mahout_f1002_0() throws IOException
{    if (!isUserItemFilterSpecified() && isUserItemFileSpecified()) {        userItemFilter = readUserItemFilter(userItemFile);    }}
private Map<Long, FastIDSet> mahout_f1003_1(String pathString) throws IOException
{    Map<Long, FastIDSet> result = new HashMap<>();    try (InputStream in = openFile(pathString)) {        for (String line : new FileLineIterable(in)) {            try {                String[] tokens = SEPARATOR.split(line);                Long userId = Long.parseLong(tokens[0]);                Long itemId = Long.parseLong(tokens[1]);                addUserAndItemIdToUserItemFilter(result, userId, itemId);            } catch (NumberFormatException nfe) {                            }        }    }    return result;}
 void mahout_f1004_0(Map<Long, FastIDSet> filter, Long userId, Long itemId)
{    FastIDSet itemIds;    if (filter.containsKey(userId)) {        itemIds = filter.get(userId);    } else {        itemIds = new FastIDSet();        filter.put(userId, itemIds);    }    itemIds.add(itemId);}
 static FastIDSet mahout_f1005_0(Map<Long, FastIDSet> filter)
{    FastIDSet result = new FastIDSet();    for (Long userId : filter.keySet()) {        result.add(userId);    }    return result;}
private FastIDSet mahout_f1006_0(Map<Long, FastIDSet> filter)
{    FastIDSet result = new FastIDSet();    for (FastIDSet itemIds : filter.values()) {        result.addAll(itemIds);    }    return result;}
private FastIDSet mahout_f1007_1(String pathString) throws IOException
{    FastIDSet result = null;    if (pathString != null) {        result = new FastIDSet();        try (InputStream in = openFile(pathString)) {            for (String line : new FileLineIterable(in)) {                try {                    result.add(Long.parseLong(line));                } catch (NumberFormatException nfe) {                                    }            }        }    }    return result;}
private InputStream mahout_f1008_0(String pathString) throws IOException
{    return HadoopUtil.openStream(new Path(pathString), conf);}
public boolean mahout_f1009_0()
{    return usersFile != null;}
public boolean mahout_f1010_0()
{    return itemsFile != null;}
public boolean mahout_f1011_0()
{    return userItemFile != null;}
public boolean mahout_f1012_0()
{    return userItemFilter != null;}
public FastIDSet mahout_f1013_0()
{    return userIds;}
public FastIDSet mahout_f1014_0()
{    return itemIds;}
protected void mahout_f1015_0(VarLongWritable itemID, Iterable<VarLongWritable> values, Context ctx) throws IOException, InterruptedException
{    int itemIDIndex = TasteHadoopUtils.idToIndex(itemID.get());    Vector vector = new RandomAccessSparseVector(Integer.MAX_VALUE, 1);    /* artificial NaN summand to exclude this item from the recommendations for all users specified in userIDs */    vector.set(itemIDIndex, Double.NaN);    List<Long> userIDs = new ArrayList<>();    List<Float> prefValues = new ArrayList<>();    for (VarLongWritable userID : values) {        userIDs.add(userID.get());        prefValues.add(1.0f);    }    itemIDIndexWritable.set(itemIDIndex);    vectorAndPrefs.set(vector, userIDs, prefValues);    ctx.write(itemIDIndexWritable, vectorAndPrefs);}
protected void mahout_f1016_0(LongWritable key, Text line, Context ctx) throws IOException, InterruptedException
{    String[] tokens = SEPARATOR.split(line.toString());    long userID = Long.parseLong(tokens[0]);    long itemID = Long.parseLong(tokens[1]);    itemIDWritable.set(itemID);    userIDWritable.set(userID);    ctx.write(itemIDWritable, userIDWritable);}
protected void mahout_f1017_0(Context context)
{    Configuration jobConf = context.getConfiguration();    transpose = jobConf.getBoolean(ToEntityPrefsMapper.TRANSPOSE_USER_ITEM, false);}
protected void mahout_f1018_0(LongWritable key, Text value, Context context) throws IOException, InterruptedException
{    String[] tokens = TasteHadoopUtils.splitPrefTokens(value.toString());    long itemID = Long.parseLong(tokens[transpose ? 0 : 1]);    int index = TasteHadoopUtils.idToIndex(itemID);    indexWritable.set(index);    itemIDWritable.set(itemID);    context.write(indexWritable, itemIDWritable);}
protected void mahout_f1019_0(VarIntWritable index, Iterable<VarLongWritable> possibleItemIDs, Context context) throws IOException, InterruptedException
{    long minimumItemID = Long.MAX_VALUE;    for (VarLongWritable varLongWritable : possibleItemIDs) {        long itemID = varLongWritable.get();        if (itemID < minimumItemID) {            minimumItemID = itemID;        }    }    if (minimumItemID != Long.MAX_VALUE) {        minimumItemIDWritable.set(minimumItemID);        context.write(index, minimumItemIDWritable);    }}
protected void mahout_f1020_0(VarIntWritable key, VectorAndPrefsWritable vectorAndPrefsWritable, Context context) throws IOException, InterruptedException
{    Vector similarityMatrixColumn = vectorAndPrefsWritable.getVector();    List<Long> userIDs = vectorAndPrefsWritable.getUserIDs();    List<Float> prefValues = vectorAndPrefsWritable.getValues();    for (int i = 0; i < userIDs.size(); i++) {        long userID = userIDs.get(i);        float prefValue = prefValues.get(i);        if (!Float.isNaN(prefValue)) {            prefAndSimilarityColumn.set(prefValue, similarityMatrixColumn);            userIDWritable.set(userID);            context.write(userIDWritable, prefAndSimilarityColumn);        }    }}
public void mahout_f1021_0(float prefValue, Vector similarityColumn)
{    this.prefValue = prefValue;    this.similarityColumn = similarityColumn;}
public float mahout_f1022_0()
{    return prefValue;}
public Vector mahout_f1023_0()
{    return similarityColumn;}
public void mahout_f1024_0(DataInput in) throws IOException
{    prefValue = in.readFloat();    VectorWritable vw = new VectorWritable();    vw.readFields(in);    similarityColumn = vw.get();}
public void mahout_f1025_0(DataOutput out) throws IOException
{    out.writeFloat(prefValue);    VectorWritable vw = new VectorWritable(similarityColumn);    vw.setWritesLaxPrecision(true);    vw.write(out);}
public boolean mahout_f1026_0(Object obj)
{    if (obj instanceof PrefAndSimilarityColumnWritable) {        PrefAndSimilarityColumnWritable other = (PrefAndSimilarityColumnWritable) obj;        return prefValue == other.prefValue && similarityColumn.equals(other.similarityColumn);    }    return false;}
public int mahout_f1027_0()
{    return RandomUtils.hashFloat(prefValue) + 31 * similarityColumn.hashCode();}
public int mahout_f1028_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption("numRecommendations", "n", "Number of recommendations per user", String.valueOf(AggregateAndRecommendReducer.DEFAULT_NUM_RECOMMENDATIONS));    addOption("usersFile", null, "File of users to recommend for", null);    addOption("itemsFile", null, "File of items to recommend for", null);    addOption("filterFile", "f", "File containing comma-separated userID,itemID pairs. Used to exclude the item from " + "the recommendations for that user (optional)", null);    addOption("userItemFile", "uif", "File containing comma-separated userID,itemID pairs (optional). " + "Used to include only these items into recommendations. " + "Cannot be used together with usersFile or itemsFile", null);    addOption("booleanData", "b", "Treat input as without pref values", Boolean.FALSE.toString());    addOption("maxPrefsPerUser", "mxp", "Maximum number of preferences considered per user in final recommendation phase", String.valueOf(UserVectorSplitterMapper.DEFAULT_MAX_PREFS_PER_USER_CONSIDERED));    addOption("minPrefsPerUser", "mp", "ignore users with less preferences than this in the similarity computation " + "(default: " + DEFAULT_MIN_PREFS_PER_USER + ')', String.valueOf(DEFAULT_MIN_PREFS_PER_USER));    addOption("maxSimilaritiesPerItem", "m", "Maximum number of similarities considered per item ", String.valueOf(DEFAULT_MAX_SIMILARITIES_PER_ITEM));    addOption("maxPrefsInItemSimilarity", "mpiis", "max number of preferences to consider per user or item in the " + "item similarity computation phase, users or items with more preferences will be sampled down (default: " + DEFAULT_MAX_PREFS + ')', String.valueOf(DEFAULT_MAX_PREFS));    addOption("similarityClassname", "s", "Name of distributed similarity measures class to instantiate, " + "alternatively use one of the predefined similarities (" + VectorSimilarityMeasures.list() + ')', true);    addOption("threshold", "tr", "discard item pairs with a similarity value below this", false);    addOption("outputPathForSimilarityMatrix", "opfsm", "write the item similarity matrix to this path (optional)", false);    addOption("randomSeed", null, "use this seed for sampling", false);    addFlag("sequencefileOutput", null, "write the output into a SequenceFile instead of a text file");    Map<String, List<String>> parsedArgs = parseArguments(args);    if (parsedArgs == null) {        return -1;    }    Path outputPath = getOutputPath();    int numRecommendations = Integer.parseInt(getOption("numRecommendations"));    String usersFile = getOption("usersFile");    String itemsFile = getOption("itemsFile");    String filterFile = getOption("filterFile");    String userItemFile = getOption("userItemFile");    boolean booleanData = Boolean.valueOf(getOption("booleanData"));    int maxPrefsPerUser = Integer.parseInt(getOption("maxPrefsPerUser"));    int minPrefsPerUser = Integer.parseInt(getOption("minPrefsPerUser"));    int maxPrefsInItemSimilarity = Integer.parseInt(getOption("maxPrefsInItemSimilarity"));    int maxSimilaritiesPerItem = Integer.parseInt(getOption("maxSimilaritiesPerItem"));    String similarityClassname = getOption("similarityClassname");    double threshold = hasOption("threshold") ? Double.parseDouble(getOption("threshold")) : RowSimilarityJob.NO_THRESHOLD;    long randomSeed = hasOption("randomSeed") ? Long.parseLong(getOption("randomSeed")) : RowSimilarityJob.NO_FIXED_RANDOM_SEED;    Path prepPath = getTempPath(DEFAULT_PREPARE_PATH);    Path similarityMatrixPath = getTempPath("similarityMatrix");    Path explicitFilterPath = getTempPath("explicitFilterPath");    Path partialMultiplyPath = getTempPath("partialMultiply");    AtomicInteger currentPhase = new AtomicInteger();    int numberOfUsers = -1;    if (shouldRunNextPhase(parsedArgs, currentPhase)) {        ToolRunner.run(getConf(), new PreparePreferenceMatrixJob(), new String[] { "--input", getInputPath().toString(), "--output", prepPath.toString(), "--minPrefsPerUser", String.valueOf(minPrefsPerUser), "--booleanData", String.valueOf(booleanData), "--tempDir", getTempPath().toString() });        numberOfUsers = HadoopUtil.readInt(new Path(prepPath, PreparePreferenceMatrixJob.NUM_USERS), getConf());    }    if (shouldRunNextPhase(parsedArgs, currentPhase)) {        /* special behavior if phase 1 is skipped */        if (numberOfUsers == -1) {            numberOfUsers = (int) HadoopUtil.countRecords(new Path(prepPath, PreparePreferenceMatrixJob.USER_VECTORS), PathType.LIST, null, getConf());        }                ToolRunner.run(getConf(), new RowSimilarityJob(), new String[] { "--input", new Path(prepPath, PreparePreferenceMatrixJob.RATING_MATRIX).toString(), "--output", similarityMatrixPath.toString(), "--numberOfColumns", String.valueOf(numberOfUsers), "--similarityClassname", similarityClassname, "--maxObservationsPerRow", String.valueOf(maxPrefsInItemSimilarity), "--maxObservationsPerColumn", String.valueOf(maxPrefsInItemSimilarity), "--maxSimilaritiesPerRow", String.valueOf(maxSimilaritiesPerItem), "--excludeSelfSimilarity", String.valueOf(Boolean.TRUE), "--threshold", String.valueOf(threshold), "--randomSeed", String.valueOf(randomSeed), "--tempDir", getTempPath().toString() });                if (hasOption("outputPathForSimilarityMatrix")) {            Path outputPathForSimilarityMatrix = new Path(getOption("outputPathForSimilarityMatrix"));            Job outputSimilarityMatrix = prepareJob(similarityMatrixPath, outputPathForSimilarityMatrix, SequenceFileInputFormat.class, ItemSimilarityJob.MostSimilarItemPairsMapper.class, EntityEntityWritable.class, DoubleWritable.class, ItemSimilarityJob.MostSimilarItemPairsReducer.class, EntityEntityWritable.class, DoubleWritable.class, TextOutputFormat.class);            Configuration mostSimilarItemsConf = outputSimilarityMatrix.getConfiguration();            mostSimilarItemsConf.set(ItemSimilarityJob.ITEM_ID_INDEX_PATH_STR, new Path(prepPath, PreparePreferenceMatrixJob.ITEMID_INDEX).toString());            mostSimilarItemsConf.setInt(ItemSimilarityJob.MAX_SIMILARITIES_PER_ITEM, maxSimilaritiesPerItem);            outputSimilarityMatrix.waitForCompletion(true);        }    }        if (shouldRunNextPhase(parsedArgs, currentPhase)) {        Job partialMultiply = Job.getInstance(getConf(), "partialMultiply");        Configuration partialMultiplyConf = partialMultiply.getConfiguration();        MultipleInputs.addInputPath(partialMultiply, similarityMatrixPath, SequenceFileInputFormat.class, SimilarityMatrixRowWrapperMapper.class);        MultipleInputs.addInputPath(partialMultiply, new Path(prepPath, PreparePreferenceMatrixJob.USER_VECTORS), SequenceFileInputFormat.class, UserVectorSplitterMapper.class);        partialMultiply.setJarByClass(ToVectorAndPrefReducer.class);        partialMultiply.setMapOutputKeyClass(VarIntWritable.class);        partialMultiply.setMapOutputValueClass(VectorOrPrefWritable.class);        partialMultiply.setReducerClass(ToVectorAndPrefReducer.class);        partialMultiply.setOutputFormatClass(SequenceFileOutputFormat.class);        partialMultiply.setOutputKeyClass(VarIntWritable.class);        partialMultiply.setOutputValueClass(VectorAndPrefsWritable.class);        partialMultiplyConf.setBoolean("mapred.compress.map.output", true);        partialMultiplyConf.set("mapred.output.dir", partialMultiplyPath.toString());        if (usersFile != null) {            partialMultiplyConf.set(UserVectorSplitterMapper.USERS_FILE, usersFile);        }        if (userItemFile != null) {            partialMultiplyConf.set(IDReader.USER_ITEM_FILE, userItemFile);        }        partialMultiplyConf.setInt(UserVectorSplitterMapper.MAX_PREFS_PER_USER_CONSIDERED, maxPrefsPerUser);        boolean succeeded = partialMultiply.waitForCompletion(true);        if (!succeeded) {            return -1;        }    }    if (shouldRunNextPhase(parsedArgs, currentPhase)) {        /* convert the user/item pairs to filter if a filterfile has been specified */        if (filterFile != null) {            Job itemFiltering = prepareJob(new Path(filterFile), explicitFilterPath, TextInputFormat.class, ItemFilterMapper.class, VarLongWritable.class, VarLongWritable.class, ItemFilterAsVectorAndPrefsReducer.class, VarIntWritable.class, VectorAndPrefsWritable.class, SequenceFileOutputFormat.class);            boolean succeeded = itemFiltering.waitForCompletion(true);            if (!succeeded) {                return -1;            }        }        String aggregateAndRecommendInput = partialMultiplyPath.toString();        if (filterFile != null) {            aggregateAndRecommendInput += "," + explicitFilterPath;        }        Class<? extends OutputFormat> outputFormat = parsedArgs.containsKey("--sequencefileOutput") ? SequenceFileOutputFormat.class : TextOutputFormat.class;                Job aggregateAndRecommend = prepareJob(new Path(aggregateAndRecommendInput), outputPath, SequenceFileInputFormat.class, PartialMultiplyMapper.class, VarLongWritable.class, PrefAndSimilarityColumnWritable.class, AggregateAndRecommendReducer.class, VarLongWritable.class, RecommendedItemsWritable.class, outputFormat);        Configuration aggregateAndRecommendConf = aggregateAndRecommend.getConfiguration();        if (itemsFile != null) {            aggregateAndRecommendConf.set(AggregateAndRecommendReducer.ITEMS_FILE, itemsFile);        }        if (userItemFile != null) {            aggregateAndRecommendConf.set(IDReader.USER_ITEM_FILE, userItemFile);        }        if (filterFile != null) {            setS3SafeCombinedInputPath(aggregateAndRecommend, getTempPath(), partialMultiplyPath, explicitFilterPath);        }        setIOSort(aggregateAndRecommend);        aggregateAndRecommendConf.set(AggregateAndRecommendReducer.ITEMID_INDEX_PATH, new Path(prepPath, PreparePreferenceMatrixJob.ITEMID_INDEX).toString());        aggregateAndRecommendConf.setInt(AggregateAndRecommendReducer.NUM_RECOMMENDATIONS, numRecommendations);        aggregateAndRecommendConf.setBoolean(BOOLEAN_DATA, booleanData);        boolean succeeded = aggregateAndRecommend.waitForCompletion(true);        if (!succeeded) {            return -1;        }    }    return 0;}
private static void mahout_f1029_0(JobContext job)
{    Configuration conf = job.getConfiguration();    conf.setInt("io.sort.factor", 100);        String javaOpts = conf.get("mapred.map.child.java.opts");    if (javaOpts == null) {                javaOpts = conf.get("mapred.child.java.opts");    }    int assumedHeapSize = 512;    if (javaOpts != null) {        Matcher m = Pattern.compile("-Xmx([0-9]+)([mMgG])").matcher(javaOpts);        if (m.find()) {            assumedHeapSize = Integer.parseInt(m.group(1));            String megabyteOrGigabyte = m.group(2);            if ("g".equalsIgnoreCase(megabyteOrGigabyte)) {                assumedHeapSize *= 1024;            }        }    }        conf.setInt("io.sort.mb", Math.min(assumedHeapSize / 2, 1024));            conf.setInt("mapred.task.timeout", 60 * 60 * 1000);}
public static void mahout_f1030_0(String[] args) throws Exception
{    ToolRunner.run(new Configuration(), new RecommenderJob(), args);}
protected void mahout_f1031_0(IntWritable key, VectorWritable value, Context context) throws IOException, InterruptedException
{    Vector similarityMatrixRow = value.get();    /* remove self similarity */    similarityMatrixRow.set(key.get(), Double.NaN);    index.set(key.get());    vectorOrPref.set(similarityMatrixRow);    context.write(index, vectorOrPref);}
protected void mahout_f1032_0(Context ctx) throws IOException, InterruptedException
{    super.setup(ctx);    minPreferences = ctx.getConfiguration().getInt(MIN_PREFERENCES_PER_USER, 1);}
protected void mahout_f1033_0(VarLongWritable userID, Iterable<VarLongWritable> itemPrefs, Context context) throws IOException, InterruptedException
{    Vector userVector = new RandomAccessSparseVector(Integer.MAX_VALUE, 100);    for (VarLongWritable itemPref : itemPrefs) {        int index = TasteHadoopUtils.idToIndex(itemPref.get());        float value = itemPref instanceof EntityPrefWritable ? ((EntityPrefWritable) itemPref).getPrefValue() : 1.0f;        userVector.set(index, value);    }    if (userVector.getNumNondefaultElements() >= minPreferences) {        userVectorWritable.set(userVector);        userVectorWritable.setWritesLaxPrecision(true);        context.getCounter(Counters.USERS).increment(1);        context.write(userID, userVectorWritable);    }}
protected void mahout_f1034_0(VarIntWritable key, Iterable<VectorOrPrefWritable> values, Context context) throws IOException, InterruptedException
{    List<Long> userIDs = new ArrayList<>();    List<Float> prefValues = new ArrayList<>();    Vector similarityMatrixColumn = null;    for (VectorOrPrefWritable value : values) {        if (value.getVector() == null) {                        userIDs.add(value.getUserID());            prefValues.add(value.getValue());        } else {                        if (similarityMatrixColumn != null) {                throw new IllegalStateException("Found two similarity-matrix columns for item index " + key.get());            }            similarityMatrixColumn = value.getVector();        }    }    if (similarityMatrixColumn == null) {        return;    }    vectorAndPrefs.set(similarityMatrixColumn, userIDs, prefValues);    context.write(key, vectorAndPrefs);}
protected void mahout_f1035_0(Context context) throws IOException
{    Configuration jobConf = context.getConfiguration();    maxPrefsPerUserConsidered = jobConf.getInt(MAX_PREFS_PER_USER_CONSIDERED, DEFAULT_MAX_PREFS_PER_USER_CONSIDERED);    IDReader idReader = new IDReader(jobConf);    idReader.readIDs();    usersToRecommendFor = idReader.getUserIds();}
protected void mahout_f1036_1(VarLongWritable key, VectorWritable value, Context context) throws IOException, InterruptedException
{    long userID = key.get();        if (usersToRecommendFor != null && !usersToRecommendFor.contains(userID)) {        return;    }    Vector userVector = maybePruneUserVector(value.get());    for (Element e : userVector.nonZeroes()) {        itemIndexWritable.set(e.index());        vectorOrPref.set(userID, (float) e.get());        context.write(itemIndexWritable, vectorOrPref);    }}
private Vector mahout_f1037_0(Vector userVector)
{    if (userVector.getNumNondefaultElements() <= maxPrefsPerUserConsidered) {        return userVector;    }    float smallestLargeValue = findSmallestLargeValue(userVector);        for (Element e : userVector.nonZeroes()) {        float absValue = Math.abs((float) e.get());        if (absValue < smallestLargeValue) {            e.set(Float.NaN);        }    }    return userVector;}
private float mahout_f1038_0(Vector userVector)
{    PriorityQueue<Float> topPrefValues = new PriorityQueue<Float>(maxPrefsPerUserConsidered) {        @Override        protected boolean lessThan(Float f1, Float f2) {            return f1 < f2;        }    };    for (Element e : userVector.nonZeroes()) {        float absValue = Math.abs((float) e.get());        topPrefValues.insertWithOverflow(absValue);    }    return topPrefValues.top();}
protected boolean mahout_f1039_0(Float f1, Float f2)
{    return f1 < f2;}
public void mahout_f1040_0(Vector vector, List<Long> userIDs, List<Float> values)
{    this.vector = vector;    this.userIDs = userIDs;    this.values = values;}
public Vector mahout_f1041_0()
{    return vector;}
public List<Long> mahout_f1042_0()
{    return userIDs;}
public List<Float> mahout_f1043_0()
{    return values;}
public void mahout_f1044_0(DataOutput out) throws IOException
{    VectorWritable vw = new VectorWritable(vector);    vw.setWritesLaxPrecision(true);    vw.write(out);    Varint.writeUnsignedVarInt(userIDs.size(), out);    for (int i = 0; i < userIDs.size(); i++) {        Varint.writeSignedVarLong(userIDs.get(i), out);        out.writeFloat(values.get(i));    }}
public void mahout_f1045_0(DataInput in) throws IOException
{    VectorWritable writable = new VectorWritable();    writable.readFields(in);    vector = writable.get();    int size = Varint.readUnsignedVarInt(in);    userIDs = new ArrayList<>(size);    values = new ArrayList<>(size);    for (int i = 0; i < size; i++) {        userIDs.add(Varint.readSignedVarLong(in));        values.add(in.readFloat());    }}
public String mahout_f1046_0()
{    return vector + "\t" + userIDs + '\t' + values;}
public Vector mahout_f1047_0()
{    return vector;}
public long mahout_f1048_0()
{    return userID;}
public float mahout_f1049_0()
{    return value;}
 void mahout_f1050_0(Vector vector)
{    this.vector = vector;    this.userID = Long.MIN_VALUE;    this.value = Float.NaN;}
public void mahout_f1051_0(long userID, float value)
{    this.vector = null;    this.userID = userID;    this.value = value;}
public void mahout_f1052_0(DataOutput out) throws IOException
{    if (vector == null) {        out.writeBoolean(false);        Varint.writeSignedVarLong(userID, out);        out.writeFloat(value);    } else {        out.writeBoolean(true);        VectorWritable vw = new VectorWritable(vector);        vw.setWritesLaxPrecision(true);        vw.write(out);    }}
public void mahout_f1053_0(DataInput in) throws IOException
{    boolean hasVector = in.readBoolean();    if (hasVector) {        VectorWritable writable = new VectorWritable();        writable.readFields(in);        set(writable.get());    } else {        long theUserID = Varint.readSignedVarLong(in);        float theValue = in.readFloat();        set(theUserID, theValue);    }}
public String mahout_f1054_0()
{    return vector == null ? userID + ":" + value : vector.toString();}
public long mahout_f1055_0()
{    return itemID;}
public float mahout_f1056_0()
{    return value;}
public void mahout_f1057_0(long itemID)
{    this.itemID = itemID;}
public void mahout_f1058_0(long itemID, float value)
{    this.itemID = itemID;    this.value = value;}
public void mahout_f1059_0(float maxValue)
{    if (value > maxValue) {        value = maxValue;    }}
public String mahout_f1060_0()
{    return "MutableRecommendedItem[item:" + itemID + ", value:" + value + ']';}
public int mahout_f1061_0()
{    return (int) itemID ^ RandomUtils.hashFloat(value);}
public boolean mahout_f1062_0(Object o)
{    if (!(o instanceof MutableRecommendedItem)) {        return false;    }    RecommendedItem other = (RecommendedItem) o;    return itemID == other.getItemID() && value == other.getValue();}
public static void mahout_f1063_0(String[] args) throws Exception
{    ToolRunner.run(new PreparePreferenceMatrixJob(), args);}
public int mahout_f1064_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption("minPrefsPerUser", "mp", "ignore users with less preferences than this " + "(default: " + DEFAULT_MIN_PREFS_PER_USER + ')', String.valueOf(DEFAULT_MIN_PREFS_PER_USER));    addOption("booleanData", "b", "Treat input as without pref values", Boolean.FALSE.toString());    addOption("ratingShift", "rs", "shift ratings by this value", "0.0");    Map<String, List<String>> parsedArgs = parseArguments(args);    if (parsedArgs == null) {        return -1;    }    int minPrefsPerUser = Integer.parseInt(getOption("minPrefsPerUser"));    boolean booleanData = Boolean.valueOf(getOption("booleanData"));    float ratingShift = Float.parseFloat(getOption("ratingShift"));        Job itemIDIndex = prepareJob(getInputPath(), getOutputPath(ITEMID_INDEX), TextInputFormat.class, ItemIDIndexMapper.class, VarIntWritable.class, VarLongWritable.class, ItemIDIndexReducer.class, VarIntWritable.class, VarLongWritable.class, SequenceFileOutputFormat.class);    itemIDIndex.setCombinerClass(ItemIDIndexReducer.class);    boolean succeeded = itemIDIndex.waitForCompletion(true);    if (!succeeded) {        return -1;    }        Job toUserVectors = prepareJob(getInputPath(), getOutputPath(USER_VECTORS), TextInputFormat.class, ToItemPrefsMapper.class, VarLongWritable.class, booleanData ? VarLongWritable.class : EntityPrefWritable.class, ToUserVectorsReducer.class, VarLongWritable.class, VectorWritable.class, SequenceFileOutputFormat.class);    toUserVectors.getConfiguration().setBoolean(RecommenderJob.BOOLEAN_DATA, booleanData);    toUserVectors.getConfiguration().setInt(ToUserVectorsReducer.MIN_PREFERENCES_PER_USER, minPrefsPerUser);    toUserVectors.getConfiguration().set(ToEntityPrefsMapper.RATING_SHIFT, String.valueOf(ratingShift));    succeeded = toUserVectors.waitForCompletion(true);    if (!succeeded) {        return -1;    }        int numberOfUsers = (int) toUserVectors.getCounters().findCounter(ToUserVectorsReducer.Counters.USERS).getValue();    HadoopUtil.writeInt(numberOfUsers, getOutputPath(NUM_USERS), getConf());        Job toItemVectors = prepareJob(getOutputPath(USER_VECTORS), getOutputPath(RATING_MATRIX), ToItemVectorsMapper.class, IntWritable.class, VectorWritable.class, ToItemVectorsReducer.class, IntWritable.class, VectorWritable.class);    toItemVectors.setCombinerClass(ToItemVectorsReducer.class);    succeeded = toItemVectors.waitForCompletion(true);    if (!succeeded) {        return -1;    }    return 0;}
protected void mahout_f1065_0(VarLongWritable rowIndex, VectorWritable vectorWritable, Context ctx) throws IOException, InterruptedException
{    Vector userRatings = vectorWritable.get();    int column = TasteHadoopUtils.idToIndex(rowIndex.get());    itemVectorWritable.setWritesLaxPrecision(true);    Vector itemVector = new RandomAccessSparseVector(Integer.MAX_VALUE, 1);    for (Vector.Element elem : userRatings.nonZeroes()) {        itemID.set(elem.index());        itemVector.setQuick(column, elem.get());        itemVectorWritable.set(itemVector);        ctx.write(itemID, itemVectorWritable);                itemVector.setQuick(elem.index(), 0.0);    }}
protected void mahout_f1066_0(IntWritable row, Iterable<VectorWritable> vectors, Context ctx) throws IOException, InterruptedException
{    merged.setWritesLaxPrecision(true);    merged.set(VectorWritable.mergeToVector(vectors.iterator()));    ctx.write(row, merged);}
public List<RecommendedItem> mahout_f1067_0()
{    return recommended;}
public void mahout_f1068_0(List<RecommendedItem> recommended)
{    this.recommended = recommended;}
public void mahout_f1069_0(DataOutput out) throws IOException
{    out.writeInt(recommended.size());    for (RecommendedItem item : recommended) {        Varint.writeSignedVarLong(item.getItemID(), out);        out.writeFloat(item.getValue());    }}
public void mahout_f1070_0(DataInput in) throws IOException
{    int size = in.readInt();    recommended = new ArrayList<>(size);    for (int i = 0; i < size; i++) {        long itemID = Varint.readSignedVarLong(in);        float value = in.readFloat();        RecommendedItem recommendedItem = new GenericRecommendedItem(itemID, value);        recommended.add(recommendedItem);    }}
public String mahout_f1071_0()
{    StringBuilder result = new StringBuilder(200);    result.append('[');    boolean first = true;    for (RecommendedItem item : recommended) {        if (first) {            first = false;        } else {            result.append(',');        }        result.append(String.valueOf(item.getItemID()));        result.append(':');        result.append(String.valueOf(item.getValue()));    }    result.append(']');    return result.toString();}
public static void mahout_f1072_0(String[] args) throws Exception
{    ToolRunner.run(new ItemSimilarityJob(), args);}
public int mahout_f1073_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption("similarityClassname", "s", "Name of distributed similarity measures class to instantiate, " + "alternatively use one of the predefined similarities (" + VectorSimilarityMeasures.list() + ')');    addOption("maxSimilaritiesPerItem", "m", "try to cap the number of similar items per item to this number " + "(default: " + DEFAULT_MAX_SIMILAR_ITEMS_PER_ITEM + ')', String.valueOf(DEFAULT_MAX_SIMILAR_ITEMS_PER_ITEM));    addOption("maxPrefs", "mppu", "max number of preferences to consider per user or item, " + "users or items with more preferences will be sampled down (default: " + DEFAULT_MAX_PREFS + ')', String.valueOf(DEFAULT_MAX_PREFS));    addOption("minPrefsPerUser", "mp", "ignore users with less preferences than this " + "(default: " + DEFAULT_MIN_PREFS_PER_USER + ')', String.valueOf(DEFAULT_MIN_PREFS_PER_USER));    addOption("booleanData", "b", "Treat input as without pref values", String.valueOf(Boolean.FALSE));    addOption("threshold", "tr", "discard item pairs with a similarity value below this", false);    addOption("randomSeed", null, "use this seed for sampling", false);    Map<String, List<String>> parsedArgs = parseArguments(args);    if (parsedArgs == null) {        return -1;    }    String similarityClassName = getOption("similarityClassname");    int maxSimilarItemsPerItem = Integer.parseInt(getOption("maxSimilaritiesPerItem"));    int maxPrefs = Integer.parseInt(getOption("maxPrefs"));    int minPrefsPerUser = Integer.parseInt(getOption("minPrefsPerUser"));    boolean booleanData = Boolean.valueOf(getOption("booleanData"));    double threshold = hasOption("threshold") ? Double.parseDouble(getOption("threshold")) : RowSimilarityJob.NO_THRESHOLD;    long randomSeed = hasOption("randomSeed") ? Long.parseLong(getOption("randomSeed")) : RowSimilarityJob.NO_FIXED_RANDOM_SEED;    Path similarityMatrixPath = getTempPath("similarityMatrix");    Path prepPath = getTempPath("prepareRatingMatrix");    AtomicInteger currentPhase = new AtomicInteger();    if (shouldRunNextPhase(parsedArgs, currentPhase)) {        ToolRunner.run(getConf(), new PreparePreferenceMatrixJob(), new String[] { "--input", getInputPath().toString(), "--output", prepPath.toString(), "--minPrefsPerUser", String.valueOf(minPrefsPerUser), "--booleanData", String.valueOf(booleanData), "--tempDir", getTempPath().toString() });    }    if (shouldRunNextPhase(parsedArgs, currentPhase)) {        int numberOfUsers = HadoopUtil.readInt(new Path(prepPath, PreparePreferenceMatrixJob.NUM_USERS), getConf());        ToolRunner.run(getConf(), new RowSimilarityJob(), new String[] { "--input", new Path(prepPath, PreparePreferenceMatrixJob.RATING_MATRIX).toString(), "--output", similarityMatrixPath.toString(), "--numberOfColumns", String.valueOf(numberOfUsers), "--similarityClassname", similarityClassName, "--maxObservationsPerRow", String.valueOf(maxPrefs), "--maxObservationsPerColumn", String.valueOf(maxPrefs), "--maxSimilaritiesPerRow", String.valueOf(maxSimilarItemsPerItem), "--excludeSelfSimilarity", String.valueOf(Boolean.TRUE), "--threshold", String.valueOf(threshold), "--randomSeed", String.valueOf(randomSeed), "--tempDir", getTempPath().toString() });    }    if (shouldRunNextPhase(parsedArgs, currentPhase)) {        Job mostSimilarItems = prepareJob(similarityMatrixPath, getOutputPath(), SequenceFileInputFormat.class, MostSimilarItemPairsMapper.class, EntityEntityWritable.class, DoubleWritable.class, MostSimilarItemPairsReducer.class, EntityEntityWritable.class, DoubleWritable.class, TextOutputFormat.class);        Configuration mostSimilarItemsConf = mostSimilarItems.getConfiguration();        mostSimilarItemsConf.set(ITEM_ID_INDEX_PATH_STR, new Path(prepPath, PreparePreferenceMatrixJob.ITEMID_INDEX).toString());        mostSimilarItemsConf.setInt(MAX_SIMILARITIES_PER_ITEM, maxSimilarItemsPerItem);        boolean succeeded = mostSimilarItems.waitForCompletion(true);        if (!succeeded) {            return -1;        }    }    return 0;}
protected void mahout_f1074_0(Context ctx)
{    Configuration conf = ctx.getConfiguration();    maxSimilarItemsPerItem = conf.getInt(MAX_SIMILARITIES_PER_ITEM, -1);    indexItemIDMap = TasteHadoopUtils.readIDIndexMap(conf.get(ITEM_ID_INDEX_PATH_STR), conf);    Preconditions.checkArgument(maxSimilarItemsPerItem > 0, "maxSimilarItemsPerItem must be greater then 0!");}
protected void mahout_f1075_0(IntWritable itemIDIndexWritable, VectorWritable similarityVector, Context ctx) throws IOException, InterruptedException
{    int itemIDIndex = itemIDIndexWritable.get();    TopSimilarItemsQueue topKMostSimilarItems = new TopSimilarItemsQueue(maxSimilarItemsPerItem);    for (Vector.Element element : similarityVector.get().nonZeroes()) {        SimilarItem top = topKMostSimilarItems.top();        double candidateSimilarity = element.get();        if (candidateSimilarity > top.getSimilarity()) {            top.set(indexItemIDMap.get(element.index()), candidateSimilarity);            topKMostSimilarItems.updateTop();        }    }    long itemID = indexItemIDMap.get(itemIDIndex);    for (SimilarItem similarItem : topKMostSimilarItems.getTopItems()) {        long otherItemID = similarItem.getItemID();        if (itemID < otherItemID) {            ctx.write(new EntityEntityWritable(itemID, otherItemID), new DoubleWritable(similarItem.getSimilarity()));        } else {            ctx.write(new EntityEntityWritable(otherItemID, itemID), new DoubleWritable(similarItem.getSimilarity()));        }    }}
protected void mahout_f1076_0(EntityEntityWritable pair, Iterable<DoubleWritable> values, Context ctx) throws IOException, InterruptedException
{    ctx.write(pair, values.iterator().next());}
public List<SimilarItem> mahout_f1077_0()
{    List<SimilarItem> items = new ArrayList<>(maxSize);    while (size() > 0) {        SimilarItem topItem = pop();                if (topItem.getItemID() != SENTINEL_ID) {            items.add(topItem);        }    }    Collections.reverse(items);    return items;}
protected boolean mahout_f1078_0(SimilarItem one, SimilarItem two)
{    return one.getSimilarity() < two.getSimilarity();}
protected SimilarItem mahout_f1079_0()
{    return new SimilarItem(SENTINEL_ID, Double.MIN_VALUE);}
public static String[] mahout_f1080_0(CharSequence line)
{    return PREFERENCE_TOKEN_DELIMITER.split(line);}
public static int mahout_f1081_0(long id)
{    return 0x7FFFFFFF & Longs.hashCode(id) % 0x7FFFFFFE;}
public static int mahout_f1082_0(String token, boolean usesLongIDs)
{    return usesLongIDs ? idToIndex(Long.parseLong(token)) : Integer.parseInt(token);}
public static OpenIntLongHashMap mahout_f1083_0(String idIndexPathStr, Configuration conf)
{    OpenIntLongHashMap indexIDMap = new OpenIntLongHashMap();    Path itemIDIndexPath = new Path(idIndexPathStr);    for (Pair<VarIntWritable, VarLongWritable> record : new SequenceFileDirIterable<VarIntWritable, VarLongWritable>(itemIDIndexPath, PathType.LIST, PathFilters.partFilter(), null, true, conf)) {        indexIDMap.put(record.getFirst().get(), record.getSecond().get());    }    return indexIDMap;}
protected void mahout_f1084_0(Context context)
{    Configuration jobConf = context.getConfiguration();    booleanData = jobConf.getBoolean(RecommenderJob.BOOLEAN_DATA, false);    transpose = jobConf.getBoolean(TRANSPOSE_USER_ITEM, false);    ratingShift = Float.parseFloat(jobConf.get(RATING_SHIFT, "0.0"));}
public void mahout_f1085_0(LongWritable key, Text value, Context context) throws IOException, InterruptedException
{    String[] tokens = DELIMITER.split(value.toString());    long userID = Long.parseLong(tokens[0]);    long itemID = Long.parseLong(tokens[1]);    if (itemKey ^ transpose) {                                long temp = userID;        userID = itemID;        itemID = temp;    }    if (booleanData) {        context.write(new VarLongWritable(userID), new VarLongWritable(itemID));    } else {        float prefValue = tokens.length > 2 ? Float.parseFloat(tokens[2]) + ratingShift : 1.0f;        context.write(new VarLongWritable(userID), new EntityPrefWritable(itemID, prefValue));    }}
public List<RecommendedItem> mahout_f1086_0()
{    List<RecommendedItem> recommendedItems = new ArrayList<>(maxSize);    while (size() > 0) {        MutableRecommendedItem topItem = pop();                if (topItem.getItemID() != SENTINEL_ID) {            recommendedItems.add(topItem);        }    }    Collections.reverse(recommendedItems);    return recommendedItems;}
protected boolean mahout_f1087_0(MutableRecommendedItem one, MutableRecommendedItem two)
{    return one.getValue() < two.getValue();}
protected MutableRecommendedItem mahout_f1088_0()
{    return new MutableRecommendedItem(SENTINEL_ID, Float.MIN_VALUE);}
public Long mahout_f1089_0()
{    return nextLong();}
 boolean mahout_f1090_0(int index)
{        return (bits[index >>> 6] & 1L << (index & 0x3F)) != 0L;}
 void mahout_f1091_0(int index)
{        bits[index >>> 6] |= 1L << (index & 0x3F);}
 void mahout_f1092_0(int index)
{        bits[index >>> 6] &= ~(1L << (index & 0x3F));}
 void mahout_f1093_0()
{    int length = bits.length;    for (int i = 0; i < length; i++) {        bits[i] = 0L;    }}
public BitSet mahout_f1094_0()
{    return new BitSet(bits.clone());}
public int mahout_f1095_0()
{    return Arrays.hashCode(bits);}
public boolean mahout_f1096_0(Object o)
{    if (!(o instanceof BitSet)) {        return false;    }    BitSet other = (BitSet) o;    return Arrays.equals(bits, other.bits);}
public String mahout_f1097_0()
{    StringBuilder result = new StringBuilder(64 * bits.length);    for (long l : bits) {        for (int j = 0; j < 64; j++) {            result.append((l & 1L << j) == 0 ? '0' : '1');        }        result.append(' ');    }    return result.toString();}
public V mahout_f1098_0(K key) throws TasteException
{    V value;    synchronized (cache) {        value = cache.get(key);    }    if (value == null) {        return getAndCacheValue(key);    }    return value == NULL ? null : value;}
public void mahout_f1099_0(K key)
{    synchronized (cache) {        cache.remove(key);    }}
public void mahout_f1100_0(MatchPredicate<K> predicate)
{    synchronized (cache) {        Iterator<K> it = cache.keySet().iterator();        while (it.hasNext()) {            K key = it.next();            if (predicate.matches(key)) {                it.remove();            }        }    }}
public void mahout_f1101_0(MatchPredicate<V> predicate)
{    synchronized (cache) {        Iterator<V> it = cache.values().iterator();        while (it.hasNext()) {            V value = it.next();            if (predicate.matches(value)) {                it.remove();            }        }    }}
public void mahout_f1102_0()
{    synchronized (cache) {        cache.clear();    }}
private V mahout_f1103_0(K key) throws TasteException
{    V value = retriever.get(key);    if (value == null) {        value = (V) NULL;    }    synchronized (cache) {        cache.put(key, value);    }    return value;}
public String mahout_f1104_0()
{    return "Cache[retriever:" + retriever + ']';}
private int mahout_f1105_0(long key)
{        int theHashCode = (int) key & 0x7FFFFFFF;    long[] keys = this.keys;    int hashSize = keys.length;    int jump = 1 + theHashCode % (hashSize - 2);    int index = theHashCode % hashSize;    long currentKey = keys[index];    while (currentKey != NULL && key != currentKey) {        index -= index < jump ? jump - hashSize : jump;        currentKey = keys[index];    }    return index;}
private int mahout_f1106_0(long key)
{        int theHashCode = (int) key & 0x7FFFFFFF;    long[] keys = this.keys;    int hashSize = keys.length;    int jump = 1 + theHashCode % (hashSize - 2);    int index = theHashCode % hashSize;    long currentKey = keys[index];    while (currentKey != NULL && currentKey != REMOVED && key != currentKey) {        index -= index < jump ? jump - hashSize : jump;        currentKey = keys[index];    }    if (currentKey != REMOVED) {        return index;    }        int addIndex = index;    while (currentKey != NULL && key != currentKey) {        index -= index < jump ? jump - hashSize : jump;        currentKey = keys[index];    }    return key == currentKey ? index : addIndex;}
public V mahout_f1107_0(long key)
{    if (key == NULL) {        return null;    }    int index = find(key);    if (countingAccesses) {        recentlyAccessed.set(index);    }    return values[index];}
public int mahout_f1108_0()
{    return numEntries;}
public boolean mahout_f1109_0()
{    return numEntries == 0;}
public boolean mahout_f1110_0(long key)
{    return key != NULL && key != REMOVED && keys[find(key)] != NULL;}
public boolean mahout_f1111_0(Object value)
{    if (value == null) {        return false;    }    for (V theValue : values) {        if (theValue != null && value.equals(theValue)) {            return true;        }    }    return false;}
public V mahout_f1112_0(long key, V value)
{    Preconditions.checkArgument(key != NULL && key != REMOVED);    Preconditions.checkNotNull(value);        if (numSlotsUsed * loadFactor >= keys.length) {                if (numEntries * loadFactor >= numSlotsUsed) {            growAndRehash();        } else {                        rehash();        }    }        int index = findForAdd(key);    long keyIndex = keys[index];    if (keyIndex == key) {        V oldValue = values[index];        values[index] = value;        return oldValue;    }        if (countingAccesses && numEntries >= maxSize) {                clearStaleEntry(index);    }    keys[index] = key;    values[index] = value;    numEntries++;    if (keyIndex == NULL) {        numSlotsUsed++;    }    return null;}
private void mahout_f1113_0(int index)
{    while (true) {        long currentKey;        do {            if (index == 0) {                index = keys.length - 1;            } else {                index--;            }            currentKey = keys[index];        } while (currentKey == NULL || currentKey == REMOVED);        if (recentlyAccessed.get(index)) {            recentlyAccessed.clear(index);        } else {            break;        }    }        keys[index] = REMOVED;    numEntries--;    values[index] = null;}
public V mahout_f1114_0(long key)
{    if (key == NULL || key == REMOVED) {        return null;    }    int index = find(key);    if (keys[index] == NULL) {        return null;    } else {        keys[index] = REMOVED;        numEntries--;        V oldValue = values[index];        values[index] = null;                return oldValue;    }}
public void mahout_f1115_0()
{    numEntries = 0;    numSlotsUsed = 0;    Arrays.fill(keys, NULL);    Arrays.fill(values, null);    if (countingAccesses) {        recentlyAccessed.clear();    }}
public LongPrimitiveIterator mahout_f1116_0()
{    return new KeyIterator();}
public Set<Map.Entry<Long, V>> mahout_f1117_0()
{    return new EntrySet();}
public Collection<V> mahout_f1118_0()
{    return new ValueCollection();}
public void mahout_f1119_0()
{    rehash(RandomUtils.nextTwinPrime((int) (loadFactor * numEntries)));}
private void mahout_f1120_0()
{    if (keys.length * loadFactor >= RandomUtils.MAX_INT_SMALLER_TWIN_PRIME) {        throw new IllegalStateException("Can't grow any more");    }    rehash(RandomUtils.nextTwinPrime((int) (loadFactor * keys.length)));}
private void mahout_f1121_0(int newHashSize)
{    long[] oldKeys = keys;    V[] oldValues = values;    numEntries = 0;    numSlotsUsed = 0;    if (countingAccesses) {        recentlyAccessed = new BitSet(newHashSize);    }    keys = new long[newHashSize];    Arrays.fill(keys, NULL);    values = (V[]) new Object[newHashSize];    int length = oldKeys.length;    for (int i = 0; i < length; i++) {        long key = oldKeys[i];        if (key != NULL && key != REMOVED) {            put(key, oldValues[i]);        }    }}
 void mahout_f1122_0(int lastNext)
{    if (lastNext >= values.length) {        throw new NoSuchElementException();    }    if (lastNext < 0) {        throw new IllegalStateException();    }    values[lastNext] = null;    keys[lastNext] = REMOVED;    numEntries--;}
public FastByIDMap<V> mahout_f1123_0()
{    FastByIDMap<V> clone;    try {        clone = (FastByIDMap<V>) super.clone();    } catch (CloneNotSupportedException cnse) {        throw new AssertionError();    }    clone.keys = keys.clone();    clone.values = values.clone();    clone.recentlyAccessed = countingAccesses ? new BitSet(keys.length) : null;    return clone;}
public String mahout_f1124_0()
{    if (isEmpty()) {        return "{}";    }    StringBuilder result = new StringBuilder();    result.append('{');    for (int i = 0; i < keys.length; i++) {        long key = keys[i];        if (key != NULL && key != REMOVED) {            result.append(key).append('=').append(values[i]).append(',');        }    }    result.setCharAt(result.length() - 1, '}');    return result.toString();}
public int mahout_f1125_0()
{    int hash = 0;    long[] keys = this.keys;    int max = keys.length;    for (int i = 0; i < max; i++) {        long key = keys[i];        if (key != NULL && key != REMOVED) {            hash = 31 * hash + ((int) (key >> 32) ^ (int) key);            hash = 31 * hash + values[i].hashCode();        }    }    return hash;}
public boolean mahout_f1126_0(Object other)
{    if (!(other instanceof FastByIDMap)) {        return false;    }    FastByIDMap<V> otherMap = (FastByIDMap<V>) other;    long[] otherKeys = otherMap.keys;    V[] otherValues = otherMap.values;    int length = keys.length;    int otherLength = otherKeys.length;    int max = Math.min(length, otherLength);    int i = 0;    while (i < max) {        long key = keys[i];        long otherKey = otherKeys[i];        if (key == NULL || key == REMOVED) {            if (otherKey != NULL && otherKey != REMOVED) {                return false;            }        } else {            if (key != otherKey || !values[i].equals(otherValues[i])) {                return false;            }        }        i++;    }    while (i < length) {        long key = keys[i];        if (key != NULL && key != REMOVED) {            return false;        }        i++;    }    while (i < otherLength) {        long key = otherKeys[i];        if (key != NULL && key != REMOVED) {            return false;        }        i++;    }    return true;}
public boolean mahout_f1127_0()
{    goToNext();    return position < keys.length;}
public long mahout_f1128_0()
{    goToNext();    lastNext = position;    if (position >= keys.length) {        throw new NoSuchElementException();    }    return keys[position++];}
public long mahout_f1129_0()
{    goToNext();    if (position >= keys.length) {        throw new NoSuchElementException();    }    return keys[position];}
private void mahout_f1130_0()
{    int length = values.length;    while (position < length && values[position] == null) {        position++;    }}
public void mahout_f1131_0()
{    iteratorRemove(lastNext);}
public void mahout_f1132_0(int n)
{    position += n;}
public int mahout_f1133_0()
{    return FastByIDMap.this.size();}
public boolean mahout_f1134_0()
{    return FastByIDMap.this.isEmpty();}
public boolean mahout_f1135_0(Object o)
{    return containsKey((Long) o);}
public Iterator<Map.Entry<Long, V>> mahout_f1136_0()
{    return new EntryIterator();}
public boolean mahout_f1137_0(Map.Entry<Long, V> t)
{    throw new UnsupportedOperationException();}
public boolean mahout_f1138_0(Object o)
{    throw new UnsupportedOperationException();}
public boolean mahout_f1139_0(Collection<? extends Map.Entry<Long, V>> ts)
{    throw new UnsupportedOperationException();}
public boolean mahout_f1140_0(Collection<?> objects)
{    throw new UnsupportedOperationException();}
public boolean mahout_f1141_0(Collection<?> objects)
{    throw new UnsupportedOperationException();}
public void mahout_f1142_0()
{    FastByIDMap.this.clear();}
public Long mahout_f1143_0()
{    return keys[index];}
public V mahout_f1144_0()
{    return values[index];}
public V mahout_f1145_0(V value)
{    Preconditions.checkArgument(value != null);    V oldValue = values[index];    values[index] = value;    return oldValue;}
public boolean mahout_f1146_0()
{    goToNext();    return position < keys.length;}
public Map.Entry<Long, V> mahout_f1147_0()
{    goToNext();    lastNext = position;    if (position >= keys.length) {        throw new NoSuchElementException();    }    return new MapEntry(position++);}
private void mahout_f1148_0()
{    int length = values.length;    while (position < length && values[position] == null) {        position++;    }}
public void mahout_f1149_0()
{    iteratorRemove(lastNext);}
public int mahout_f1150_0()
{    return FastByIDMap.this.size();}
public boolean mahout_f1151_0()
{    return FastByIDMap.this.isEmpty();}
public boolean mahout_f1152_0(Object o)
{    return containsValue(o);}
public Iterator<V> mahout_f1153_0()
{    return new ValueIterator();}
public boolean mahout_f1154_0(V v)
{    throw new UnsupportedOperationException();}
public boolean mahout_f1155_0(Object o)
{    throw new UnsupportedOperationException();}
public boolean mahout_f1156_0(Collection<? extends V> vs)
{    throw new UnsupportedOperationException();}
public boolean mahout_f1157_0(Collection<?> objects)
{    throw new UnsupportedOperationException();}
public boolean mahout_f1158_0(Collection<?> objects)
{    throw new UnsupportedOperationException();}
public void mahout_f1159_0()
{    FastByIDMap.this.clear();}
public boolean mahout_f1160_0()
{    goToNext();    return position < values.length;}
public V mahout_f1161_0()
{    goToNext();    lastNext = position;    if (position >= values.length) {        throw new NoSuchElementException();    }    return values[position++];}
private void mahout_f1162_0()
{    int length = values.length;    while (position < length && values[position] == null) {        position++;    }}
public void mahout_f1163_0()
{    iteratorRemove(lastNext);}
private int mahout_f1164_0(long key)
{        int theHashCode = (int) key & 0x7FFFFFFF;    long[] keys = this.keys;    int hashSize = keys.length;    int jump = 1 + theHashCode % (hashSize - 2);    int index = theHashCode % hashSize;    long currentKey = keys[index];    while (currentKey != NULL && key != currentKey) {                index -= index < jump ? jump - hashSize : jump;        currentKey = keys[index];    }    return index;}
private int mahout_f1165_0(long key)
{        int theHashCode = (int) key & 0x7FFFFFFF;    long[] keys = this.keys;    int hashSize = keys.length;    int jump = 1 + theHashCode % (hashSize - 2);    int index = theHashCode % hashSize;    long currentKey = keys[index];    while (currentKey != NULL && currentKey != REMOVED && key != currentKey) {        index -= index < jump ? jump - hashSize : jump;        currentKey = keys[index];    }    if (currentKey != REMOVED) {        return index;    }        int addIndex = index;    while (currentKey != NULL && key != currentKey) {        index -= index < jump ? jump - hashSize : jump;        currentKey = keys[index];    }    return key == currentKey ? index : addIndex;}
public int mahout_f1166_0()
{    return numEntries;}
public boolean mahout_f1167_0()
{    return numEntries == 0;}
public boolean mahout_f1168_0(long key)
{    return key != NULL && key != REMOVED && keys[find(key)] != NULL;}
public boolean mahout_f1169_0(long key)
{    Preconditions.checkArgument(key != NULL && key != REMOVED);        if (numSlotsUsed * loadFactor >= keys.length) {                if (numEntries * loadFactor >= numSlotsUsed) {            growAndRehash();        } else {                        rehash();        }    }        int index = findForAdd(key);    long keyIndex = keys[index];    if (keyIndex != key) {        keys[index] = key;        numEntries++;        if (keyIndex == NULL) {            numSlotsUsed++;        }        return true;    }    return false;}
public LongPrimitiveIterator mahout_f1170_0()
{    return new KeyIterator();}
public long[] mahout_f1171_0()
{    long[] result = new long[numEntries];    for (int i = 0, position = 0; i < result.length; i++) {        while (keys[position] == NULL || keys[position] == REMOVED) {            position++;        }        result[i] = keys[position++];    }    return result;}
public boolean mahout_f1172_0(long key)
{    if (key == NULL || key == REMOVED) {        return false;    }    int index = find(key);    if (keys[index] == NULL) {        return false;    } else {        keys[index] = REMOVED;        numEntries--;        return true;    }}
public boolean mahout_f1173_0(long[] c)
{    boolean changed = false;    for (long k : c) {        if (add(k)) {            changed = true;        }    }    return changed;}
public boolean mahout_f1174_0(FastIDSet c)
{    boolean changed = false;    for (long k : c.keys) {        if (k != NULL && k != REMOVED && add(k)) {            changed = true;        }    }    return changed;}
public boolean mahout_f1175_0(long[] c)
{    boolean changed = false;    for (long o : c) {        if (remove(o)) {            changed = true;        }    }    return changed;}
public boolean mahout_f1176_0(FastIDSet c)
{    boolean changed = false;    for (long k : c.keys) {        if (k != NULL && k != REMOVED && remove(k)) {            changed = true;        }    }    return changed;}
public boolean mahout_f1177_0(FastIDSet c)
{    boolean changed = false;    for (int i = 0; i < keys.length; i++) {        long k = keys[i];        if (k != NULL && k != REMOVED && !c.contains(k)) {            keys[i] = REMOVED;            numEntries--;            changed = true;        }    }    return changed;}
public void mahout_f1178_0()
{    numEntries = 0;    numSlotsUsed = 0;    Arrays.fill(keys, NULL);}
private void mahout_f1179_0()
{    if (keys.length * loadFactor >= RandomUtils.MAX_INT_SMALLER_TWIN_PRIME) {        throw new IllegalStateException("Can't grow any more");    }    rehash(RandomUtils.nextTwinPrime((int) (loadFactor * keys.length)));}
public void mahout_f1180_0()
{    rehash(RandomUtils.nextTwinPrime((int) (loadFactor * numEntries)));}
private void mahout_f1181_0(int newHashSize)
{    long[] oldKeys = keys;    numEntries = 0;    numSlotsUsed = 0;    keys = new long[newHashSize];    Arrays.fill(keys, NULL);    for (long key : oldKeys) {        if (key != NULL && key != REMOVED) {            add(key);        }    }}
public int mahout_f1182_0(FastIDSet other)
{    int count = 0;    for (long key : other.keys) {        if (key != NULL && key != REMOVED && keys[find(key)] != NULL) {            count++;        }    }    return count;}
public FastIDSet mahout_f1183_0()
{    FastIDSet clone;    try {        clone = (FastIDSet) super.clone();    } catch (CloneNotSupportedException cnse) {        throw new AssertionError();    }    clone.keys = keys.clone();    return clone;}
public int mahout_f1184_0()
{    int hash = 0;    long[] keys = this.keys;    for (long key : keys) {        if (key != NULL && key != REMOVED) {            hash = 31 * hash + ((int) (key >> 32) ^ (int) key);        }    }    return hash;}
public boolean mahout_f1185_0(Object other)
{    if (!(other instanceof FastIDSet)) {        return false;    }    FastIDSet otherMap = (FastIDSet) other;    long[] otherKeys = otherMap.keys;    int length = keys.length;    int otherLength = otherKeys.length;    int max = Math.min(length, otherLength);    int i = 0;    while (i < max) {        long key = keys[i];        long otherKey = otherKeys[i];        if (key == NULL || key == REMOVED) {            if (otherKey != NULL && otherKey != REMOVED) {                return false;            }        } else {            if (key != otherKey) {                return false;            }        }        i++;    }    while (i < length) {        long key = keys[i];        if (key != NULL && key != REMOVED) {            return false;        }        i++;    }    while (i < otherLength) {        long key = otherKeys[i];        if (key != NULL && key != REMOVED) {            return false;        }        i++;    }    return true;}
public String mahout_f1186_0()
{    if (isEmpty()) {        return "[]";    }    StringBuilder result = new StringBuilder();    result.append('[');    for (long key : keys) {        if (key != NULL && key != REMOVED) {            result.append(key).append(',');        }    }    result.setCharAt(result.length() - 1, ']');    return result.toString();}
public boolean mahout_f1187_0()
{    goToNext();    return position < keys.length;}
public long mahout_f1188_0()
{    goToNext();    lastNext = position;    if (position >= keys.length) {        throw new NoSuchElementException();    }    return keys[position++];}
public long mahout_f1189_0()
{    goToNext();    if (position >= keys.length) {        throw new NoSuchElementException();    }    return keys[position];}
private void mahout_f1190_0()
{    int length = keys.length;    while (position < length && (keys[position] == NULL || keys[position] == REMOVED)) {        position++;    }}
public void mahout_f1191_0()
{    if (lastNext >= keys.length) {        throw new NoSuchElementException();    }    if (lastNext < 0) {        throw new IllegalStateException();    }    keys[lastNext] = REMOVED;    numEntries--;}
public Iterator<Long> mahout_f1192_0()
{    return new KeyIterator();}
public void mahout_f1193_0(int n)
{    position += n;}
private int mahout_f1194_0(Object key)
{        int theHashCode = key.hashCode() & 0x7FFFFFFF;    K[] keys = this.keys;    int hashSize = keys.length;    int jump = 1 + theHashCode % (hashSize - 2);    int index = theHashCode % hashSize;    K currentKey = keys[index];    while (currentKey != null && !key.equals(currentKey)) {        index -= index < jump ? jump - hashSize : jump;        currentKey = keys[index];    }    return index;}
private int mahout_f1195_0(Object key)
{        int theHashCode = key.hashCode() & 0x7FFFFFFF;    K[] keys = this.keys;    int hashSize = keys.length;    int jump = 1 + theHashCode % (hashSize - 2);    int index = theHashCode % hashSize;    K currentKey = keys[index];    while (currentKey != null && currentKey != REMOVED && key != currentKey) {        index -= index < jump ? jump - hashSize : jump;        currentKey = keys[index];    }    if (currentKey != REMOVED) {        return index;    }        int addIndex = index;    while (currentKey != null && key != currentKey) {        index -= index < jump ? jump - hashSize : jump;        currentKey = keys[index];    }    return key == currentKey ? index : addIndex;}
public V mahout_f1196_0(Object key)
{    if (key == null) {        return null;    }    int index = find(key);    if (countingAccesses) {        recentlyAccessed.set(index);    }    return values[index];}
public int mahout_f1197_0()
{    return numEntries;}
public boolean mahout_f1198_0()
{    return numEntries == 0;}
public boolean mahout_f1199_0(Object key)
{    return key != null && keys[find(key)] != null;}
public boolean mahout_f1200_0(Object value)
{    if (value == null) {        return false;    }    for (V theValue : values) {        if (theValue != null && value.equals(theValue)) {            return true;        }    }    return false;}
public V mahout_f1201_0(K key, V value)
{    Preconditions.checkNotNull(key);    Preconditions.checkNotNull(value);        if (numSlotsUsed * loadFactor >= keys.length) {                if (numEntries * loadFactor >= numSlotsUsed) {            growAndRehash();        } else {                        rehash();        }    }        int index = findForAdd(key);    if (keys[index] == key) {        V oldValue = values[index];        values[index] = value;        return oldValue;    }        if (countingAccesses && numEntries >= maxSize) {                clearStaleEntry(index);    }    keys[index] = key;    values[index] = value;    numEntries++;    numSlotsUsed++;    return null;}
private void mahout_f1202_0(int index)
{    while (true) {        K currentKey;        do {            if (index == 0) {                index = keys.length - 1;            } else {                index--;            }            currentKey = keys[index];        } while (currentKey == null || currentKey == REMOVED);        if (recentlyAccessed.get(index)) {            recentlyAccessed.clear(index);        } else {            break;        }    }        ((Object[]) keys)[index] = REMOVED;    numEntries--;    values[index] = null;}
public void mahout_f1203_0(Map<? extends K, ? extends V> map)
{    for (Entry<? extends K, ? extends V> entry : map.entrySet()) {        put(entry.getKey(), entry.getValue());    }}
public V mahout_f1204_0(Object key)
{    if (key == null) {        return null;    }    int index = find(key);    if (keys[index] == null) {        return null;    } else {        ((Object[]) keys)[index] = REMOVED;        numEntries--;        V oldValue = values[index];        values[index] = null;                return oldValue;    }}
public void mahout_f1205_0()
{    numEntries = 0;    numSlotsUsed = 0;    Arrays.fill(keys, null);    Arrays.fill(values, null);    if (countingAccesses) {        recentlyAccessed.clear();    }}
public Set<K> mahout_f1206_0()
{    return new KeySet();}
public Collection<V> mahout_f1207_0()
{    return new ValueCollection();}
public Set<Entry<K, V>> mahout_f1208_0()
{    return new EntrySet();}
public void mahout_f1209_0()
{    rehash(RandomUtils.nextTwinPrime((int) (loadFactor * numEntries)));}
private void mahout_f1210_0()
{    if (keys.length * loadFactor >= RandomUtils.MAX_INT_SMALLER_TWIN_PRIME) {        throw new IllegalStateException("Can't grow any more");    }    rehash(RandomUtils.nextTwinPrime((int) (loadFactor * keys.length)));}
private void mahout_f1211_0(int newHashSize)
{    K[] oldKeys = keys;    V[] oldValues = values;    numEntries = 0;    numSlotsUsed = 0;    if (countingAccesses) {        recentlyAccessed = new BitSet(newHashSize);    }    keys = (K[]) new Object[newHashSize];    values = (V[]) new Object[newHashSize];    int length = oldKeys.length;    for (int i = 0; i < length; i++) {        K key = oldKeys[i];        if (key != null && key != REMOVED) {            put(key, oldValues[i]);        }    }}
 void mahout_f1212_0(int lastNext)
{    if (lastNext >= values.length) {        throw new NoSuchElementException();    }    if (lastNext < 0) {        throw new IllegalStateException();    }    values[lastNext] = null;    ((Object[]) keys)[lastNext] = REMOVED;    numEntries--;}
public FastMap<K, V> mahout_f1213_0()
{    FastMap<K, V> clone;    try {        clone = (FastMap<K, V>) super.clone();    } catch (CloneNotSupportedException cnse) {        throw new AssertionError();    }    clone.keys = keys.clone();    clone.values = values.clone();    clone.recentlyAccessed = countingAccesses ? new BitSet(keys.length) : null;    return clone;}
public int mahout_f1214_0()
{    int hash = 0;    K[] keys = this.keys;    int max = keys.length;    for (int i = 0; i < max; i++) {        K key = keys[i];        if (key != null && key != REMOVED) {            hash = 31 * hash + key.hashCode();            hash = 31 * hash + values[i].hashCode();        }    }    return hash;}
public boolean mahout_f1215_0(Object other)
{    if (!(other instanceof FastMap)) {        return false;    }    FastMap<K, V> otherMap = (FastMap<K, V>) other;    K[] otherKeys = otherMap.keys;    V[] otherValues = otherMap.values;    int length = keys.length;    int otherLength = otherKeys.length;    int max = Math.min(length, otherLength);    int i = 0;    while (i < max) {        K key = keys[i];        K otherKey = otherKeys[i];        if (key == null || key == REMOVED) {            if (otherKey != null && otherKey != REMOVED) {                return false;            }        } else {            if (key != otherKey || !values[i].equals(otherValues[i])) {                return false;            }        }        i++;    }    while (i < length) {        K key = keys[i];        if (key != null && key != REMOVED) {            return false;        }        i++;    }    while (i < otherLength) {        K key = otherKeys[i];        if (key != null && key != REMOVED) {            return false;        }        i++;    }    return true;}
public String mahout_f1216_0()
{    if (isEmpty()) {        return "{}";    }    StringBuilder result = new StringBuilder();    result.append('{');    for (int i = 0; i < keys.length; i++) {        K key = keys[i];        if (key != null && key != REMOVED) {            result.append(key).append('=').append(values[i]).append(',');        }    }    result.setCharAt(result.length() - 1, '}');    return result.toString();}
public int mahout_f1217_0()
{    return FastMap.this.size();}
public boolean mahout_f1218_0()
{    return FastMap.this.isEmpty();}
public boolean mahout_f1219_0(Object o)
{    return containsKey(o);}
public Iterator<Entry<K, V>> mahout_f1220_0()
{    return new EntryIterator();}
public boolean mahout_f1221_0(Entry<K, V> t)
{    throw new UnsupportedOperationException();}
public boolean mahout_f1222_0(Object o)
{    throw new UnsupportedOperationException();}
public boolean mahout_f1223_0(Collection<? extends Entry<K, V>> ts)
{    throw new UnsupportedOperationException();}
public boolean mahout_f1224_0(Collection<?> objects)
{    throw new UnsupportedOperationException();}
public boolean mahout_f1225_0(Collection<?> objects)
{    throw new UnsupportedOperationException();}
public void mahout_f1226_0()
{    FastMap.this.clear();}
public K mahout_f1227_0()
{    return keys[index];}
public V mahout_f1228_0()
{    return values[index];}
public V mahout_f1229_0(V value)
{    Preconditions.checkArgument(value != null);    V oldValue = values[index];    values[index] = value;    return oldValue;}
public boolean mahout_f1230_0()
{    goToNext();    return position < keys.length;}
public Entry<K, V> mahout_f1231_0()
{    goToNext();    lastNext = position;    if (position >= keys.length) {        throw new NoSuchElementException();    }    return new MapEntry(position++);}
private void mahout_f1232_0()
{    int length = values.length;    while (position < length && values[position] == null) {        position++;    }}
public void mahout_f1233_0()
{    iteratorRemove(lastNext);}
public int mahout_f1234_0()
{    return FastMap.this.size();}
public boolean mahout_f1235_0()
{    return FastMap.this.isEmpty();}
public boolean mahout_f1236_0(Object o)
{    return containsKey(o);}
public Iterator<K> mahout_f1237_0()
{    return new KeyIterator();}
public boolean mahout_f1238_0(K t)
{    throw new UnsupportedOperationException();}
public boolean mahout_f1239_0(Object o)
{    throw new UnsupportedOperationException();}
public boolean mahout_f1240_0(Collection<? extends K> ts)
{    throw new UnsupportedOperationException();}
public boolean mahout_f1241_0(Collection<?> objects)
{    throw new UnsupportedOperationException();}
public boolean mahout_f1242_0(Collection<?> objects)
{    throw new UnsupportedOperationException();}
public void mahout_f1243_0()
{    FastMap.this.clear();}
public boolean mahout_f1244_0()
{    goToNext();    return position < keys.length;}
public K mahout_f1245_0()
{    goToNext();    lastNext = position;    if (position >= keys.length) {        throw new NoSuchElementException();    }    return keys[position++];}
private void mahout_f1246_0()
{    int length = values.length;    while (position < length && values[position] == null) {        position++;    }}
public void mahout_f1247_0()
{    iteratorRemove(lastNext);}
public int mahout_f1248_0()
{    return FastMap.this.size();}
public boolean mahout_f1249_0()
{    return FastMap.this.isEmpty();}
public boolean mahout_f1250_0(Object o)
{    return containsValue(o);}
public Iterator<V> mahout_f1251_0()
{    return new ValueIterator();}
public boolean mahout_f1252_0(V v)
{    throw new UnsupportedOperationException();}
public boolean mahout_f1253_0(Object o)
{    throw new UnsupportedOperationException();}
public boolean mahout_f1254_0(Collection<? extends V> vs)
{    throw new UnsupportedOperationException();}
public boolean mahout_f1255_0(Collection<?> objects)
{    throw new UnsupportedOperationException();}
public boolean mahout_f1256_0(Collection<?> objects)
{    throw new UnsupportedOperationException();}
public void mahout_f1257_0()
{    FastMap.this.clear();}
public boolean mahout_f1258_0()
{    goToNext();    return position < values.length;}
public V mahout_f1259_0()
{    goToNext();    lastNext = position;    if (position >= values.length) {        throw new NoSuchElementException();    }    return values[position++];}
private void mahout_f1260_0()
{    int length = values.length;    while (position < length && values[position] == null) {        position++;    }}
public void mahout_f1261_0()
{    iteratorRemove(lastNext);}
public synchronized void mahout_f1262_0(double datum)
{    throw new UnsupportedOperationException();}
public synchronized void mahout_f1263_0(double datum)
{    throw new UnsupportedOperationException();}
public synchronized void mahout_f1264_0(double delta)
{    throw new UnsupportedOperationException();}
public synchronized int mahout_f1265_0()
{    return count;}
public synchronized double mahout_f1266_0()
{    return average;}
public RunningAverage mahout_f1267_0()
{    return new InvertedRunningAverage(this);}
public synchronized String mahout_f1268_0()
{    return String.valueOf(average);}
public RunningAverageAndStdDev mahout_f1269_0()
{    return new InvertedRunningAverageAndStdDev(this);}
public synchronized String mahout_f1270_0()
{    return super.toString() + ',' + stdDev;}
public double mahout_f1271_0()
{    return stdDev;}
public synchronized void mahout_f1272_0(double datum)
{    if (++count == 1) {        average = datum;    } else {        average = average * (count - 1) / count + datum / count;    }}
public synchronized void mahout_f1273_0(double datum)
{    if (count == 0) {        throw new IllegalStateException();    }    if (--count == 0) {        average = Double.NaN;    } else {        average = average * (count + 1) / count - datum / count;    }}
public synchronized void mahout_f1274_0(double delta)
{    if (count == 0) {        throw new IllegalStateException();    }    average += delta / count;}
public synchronized int mahout_f1275_0()
{    return count;}
public synchronized double mahout_f1276_0()
{    return average;}
public RunningAverage mahout_f1277_0()
{    return new InvertedRunningAverage(this);}
public synchronized String mahout_f1278_0()
{    return String.valueOf(average);}
public double mahout_f1279_0()
{    return mk;}
public double mahout_f1280_0()
{    return sk;}
public synchronized double mahout_f1281_0()
{    return stdDev;}
public synchronized void mahout_f1282_0(double datum)
{    super.addDatum(datum);    int count = getCount();    if (count == 1) {        mk = datum;        sk = 0.0;    } else {        double oldmk = mk;        double diff = datum - oldmk;        mk += diff / count;        sk += diff * (datum - mk);    }    recomputeStdDev();}
public synchronized void mahout_f1283_0(double datum)
{    int oldCount = getCount();    super.removeDatum(datum);    double oldmk = mk;    mk = (oldCount * oldmk - datum) / (oldCount - 1);    sk -= (datum - mk) * (datum - oldmk);    recomputeStdDev();}
public void mahout_f1284_0(double delta)
{    throw new UnsupportedOperationException();}
private synchronized void mahout_f1285_0()
{    int count = getCount();    stdDev = count > 1 ? Math.sqrt(sk / (count - 1)) : Double.NaN;}
public RunningAverageAndStdDev mahout_f1286_0()
{    return new InvertedRunningAverageAndStdDev(this);}
public synchronized String mahout_f1287_0()
{    return String.valueOf(String.valueOf(getAverage()) + ',' + stdDev);}
public void mahout_f1288_0(double datum)
{    throw new UnsupportedOperationException();}
public void mahout_f1289_0(double datum)
{    throw new UnsupportedOperationException();}
public void mahout_f1290_0(double delta)
{    throw new UnsupportedOperationException();}
public int mahout_f1291_0()
{    return delegate.getCount();}
public double mahout_f1292_0()
{    return -delegate.getAverage();}
public RunningAverage mahout_f1293_0()
{    return delegate;}
public void mahout_f1294_0(double datum)
{    throw new UnsupportedOperationException();}
public void mahout_f1295_0(double datum)
{    throw new UnsupportedOperationException();}
public void mahout_f1296_0(double delta)
{    throw new UnsupportedOperationException();}
public int mahout_f1297_0()
{    return delegate.getCount();}
public double mahout_f1298_0()
{    return -delegate.getAverage();}
public double mahout_f1299_0()
{    return delegate.getStandardDeviation();}
public RunningAverageAndStdDev mahout_f1300_0()
{    return delegate;}
protected static void mahout_f1301_1(String argName, Object value)
{    Preconditions.checkArgument(value != null && !value.toString().isEmpty(), argName + " is null or empty");    }
protected static void mahout_f1302_0(String argName, Object[] values)
{    Preconditions.checkArgument(values != null && values.length != 0, argName + " is null or zero-length");    for (Object value : values) {        checkNotNullAndLog(argName, value);    }}
protected int mahout_f1304_0()
{    return DEFAULT_FETCH_SIZE;}
protected ResultSet mahout_f1305_0()
{    try {        if (resultSet.next()) {            return resultSet;        } else {            close();            return null;        }    } catch (SQLException sqle) {        close();        throw new IllegalStateException(sqle);    }}
public void mahout_f1306_0(int n) throws SQLException
{    try {        resultSet.relative(n);    } catch (SQLException sqle) {                int i = 0;        while (i < n && resultSet.next()) {            i++;        }    }}
public void mahout_f1307_0()
{    IOUtils.quietClose(resultSet, statement, connection);    endOfData();}
public T mahout_f1308_0(ResultSet from)
{    try {        return parseElement(from);    } catch (SQLException sqle) {        throw new IllegalStateException(sqle);    }}
protected Iterator<T> mahout_f1309_0()
{    return delegate;}
public void mahout_f1310_0(int n)
{    if (n >= 1) {        try {            rowDelegate.skip(n);        } catch (SQLException sqle) {            throw new IllegalStateException(sqle);        }    }}
public boolean mahout_f1311_0()
{    return position < max;}
public Long mahout_f1312_0()
{    return nextLong();}
public long mahout_f1313_0()
{    if (position >= array.length) {        throw new NoSuchElementException();    }    return array[position++];}
public long mahout_f1314_0()
{    if (position >= array.length) {        throw new NoSuchElementException();    }    return array[position];}
public void mahout_f1315_0()
{    throw new UnsupportedOperationException();}
public void mahout_f1316_0(int n)
{    if (n > 0) {        position += n;    }}
public String mahout_f1317_0()
{    return "LongPrimitiveArrayIterator";}
public void mahout_f1318_0(Refreshable refreshable)
{    if (refreshable != null) {        dependencies.add(refreshable);    }}
public void mahout_f1319_0(Refreshable refreshable)
{    if (refreshable != null) {        dependencies.remove(refreshable);    }}
public void mahout_f1320_1(Collection<Refreshable> alreadyRefreshed)
{    if (refreshLock.tryLock()) {        try {            alreadyRefreshed = buildRefreshed(alreadyRefreshed);            for (Refreshable dependency : dependencies) {                maybeRefresh(alreadyRefreshed, dependency);            }            if (refreshRunnable != null) {                try {                    refreshRunnable.call();                } catch (Exception e) {                                    }            }        } finally {            refreshLock.unlock();        }    }}
public static Collection<Refreshable> mahout_f1321_0(Collection<Refreshable> currentAlreadyRefreshed)
{    return currentAlreadyRefreshed == null ? new HashSet<Refreshable>(3) : currentAlreadyRefreshed;}
public static void mahout_f1322_1(Collection<Refreshable> alreadyRefreshed, Refreshable refreshable)
{    if (!alreadyRefreshed.contains(refreshable)) {        alreadyRefreshed.add(refreshable);                refreshable.refresh(alreadyRefreshed);            }}
public boolean mahout_f1323_0()
{    return hasNext;}
public long mahout_f1324_0()
{    if (hasNext) {        long result = next;        doNext();        return result;    }    throw new NoSuchElementException();}
public long mahout_f1325_0()
{    if (hasNext) {        return next;    }    throw new NoSuchElementException();}
private void mahout_f1326_0()
{    int toSkip = geometricDistribution.sample();    delegate.skip(toSkip);    if (delegate.hasNext()) {        next = delegate.next();    } else {        hasNext = false;    }}
public void mahout_f1327_0()
{    throw new UnsupportedOperationException();}
public void mahout_f1328_0(int n)
{    int toSkip = 0;    for (int i = 0; i < n; i++) {        toSkip += geometricDistribution.sample();    }    delegate.skip(toSkip);    if (delegate.hasNext()) {        next = delegate.next();    } else {        hasNext = false;    }}
public static LongPrimitiveIterator mahout_f1329_0(LongPrimitiveIterator delegate, double samplingRate)
{    return samplingRate >= 1.0 ? delegate : new SamplingLongPrimitiveIterator(delegate, samplingRate);}
public synchronized void mahout_f1330_0(double datum)
{    addDatum(datum, 1.0);}
public synchronized void mahout_f1331_0(double datum, double weight)
{    double oldTotalWeight = totalWeight;    totalWeight += weight;    if (oldTotalWeight <= 0.0) {        average = datum;    } else {        average = average * oldTotalWeight / totalWeight + datum * weight / totalWeight;    }}
public synchronized void mahout_f1332_0(double datum)
{    removeDatum(datum, 1.0);}
public synchronized void mahout_f1333_0(double datum, double weight)
{    double oldTotalWeight = totalWeight;    totalWeight -= weight;    if (totalWeight <= 0.0) {        average = Double.NaN;        totalWeight = 0.0;    } else {        average = average * oldTotalWeight / totalWeight - datum * weight / totalWeight;    }}
public synchronized void mahout_f1334_0(double delta)
{    changeDatum(delta, 1.0);}
public synchronized void mahout_f1335_0(double delta, double weight)
{    Preconditions.checkArgument(weight <= totalWeight, "weight must be <= totalWeight");    average += delta * weight / totalWeight;}
public synchronized double mahout_f1336_0()
{    return totalWeight;}
public synchronized int mahout_f1337_0()
{    return (int) totalWeight;}
public synchronized double mahout_f1338_0()
{    return average;}
public RunningAverage mahout_f1339_0()
{    return new InvertedRunningAverage(this);}
public synchronized String mahout_f1340_0()
{    return String.valueOf(average);}
public synchronized void mahout_f1341_0(double datum, double weight)
{    super.addDatum(datum, weight);    totalSquaredWeight += weight * weight;    double weightedData = datum * weight;    totalWeightedData += weightedData;    totalWeightedSquaredData += weightedData * datum;}
public synchronized void mahout_f1342_0(double datum, double weight)
{    super.removeDatum(datum, weight);    totalSquaredWeight -= weight * weight;    if (totalSquaredWeight <= 0.0) {        totalSquaredWeight = 0.0;    }    double weightedData = datum * weight;    totalWeightedData -= weightedData;    if (totalWeightedData <= 0.0) {        totalWeightedData = 0.0;    }    totalWeightedSquaredData -= weightedData * datum;    if (totalWeightedSquaredData <= 0.0) {        totalWeightedSquaredData = 0.0;    }}
public synchronized void mahout_f1343_0(double delta, double weight)
{    throw new UnsupportedOperationException();}
public synchronized double mahout_f1344_0()
{    double totalWeight = getTotalWeight();    return Math.sqrt((totalWeightedSquaredData * totalWeight - totalWeightedData * totalWeightedData) / (totalWeight * totalWeight - totalSquaredWeight));}
public RunningAverageAndStdDev mahout_f1345_0()
{    return new InvertedRunningAverageAndStdDev(this);}
public synchronized String mahout_f1346_0()
{    return String.valueOf(String.valueOf(getAverage()) + ',' + getStandardDeviation());}
public final float mahout_f1347_0()
{    return maxPreference;}
public final void mahout_f1348_0(float maxPreference)
{    this.maxPreference = maxPreference;}
public final float mahout_f1349_0()
{    return minPreference;}
public final void mahout_f1350_0(float minPreference)
{    this.minPreference = minPreference;}
public double mahout_f1351_1(RecommenderBuilder recommenderBuilder, DataModelBuilder dataModelBuilder, DataModel dataModel, double trainingPercentage, double evaluationPercentage) throws TasteException
{    Preconditions.checkNotNull(recommenderBuilder);    Preconditions.checkNotNull(dataModel);    Preconditions.checkArgument(trainingPercentage >= 0.0 && trainingPercentage <= 1.0, "Invalid trainingPercentage: " + trainingPercentage + ". Must be: 0.0 <= trainingPercentage <= 1.0");    Preconditions.checkArgument(evaluationPercentage >= 0.0 && evaluationPercentage <= 1.0, "Invalid evaluationPercentage: " + evaluationPercentage + ". Must be: 0.0 <= evaluationPercentage <= 1.0");        int numUsers = dataModel.getNumUsers();    FastByIDMap<PreferenceArray> trainingPrefs = new FastByIDMap<>(1 + (int) (evaluationPercentage * numUsers));    FastByIDMap<PreferenceArray> testPrefs = new FastByIDMap<>(1 + (int) (evaluationPercentage * numUsers));    LongPrimitiveIterator it = dataModel.getUserIDs();    while (it.hasNext()) {        long userID = it.nextLong();        if (random.nextDouble() < evaluationPercentage) {            splitOneUsersPrefs(trainingPercentage, trainingPrefs, testPrefs, userID, dataModel);        }    }    DataModel trainingModel = dataModelBuilder == null ? new GenericDataModel(trainingPrefs) : dataModelBuilder.buildDataModel(trainingPrefs);    Recommender recommender = recommenderBuilder.buildRecommender(trainingModel);    double result = getEvaluation(testPrefs, recommender);        return result;}
private void mahout_f1352_0(double trainingPercentage, FastByIDMap<PreferenceArray> trainingPrefs, FastByIDMap<PreferenceArray> testPrefs, long userID, DataModel dataModel) throws TasteException
{    List<Preference> oneUserTrainingPrefs = null;    List<Preference> oneUserTestPrefs = null;    PreferenceArray prefs = dataModel.getPreferencesFromUser(userID);    int size = prefs.length();    for (int i = 0; i < size; i++) {        Preference newPref = new GenericPreference(userID, prefs.getItemID(i), prefs.getValue(i));        if (random.nextDouble() < trainingPercentage) {            if (oneUserTrainingPrefs == null) {                oneUserTrainingPrefs = new ArrayList<>(3);            }            oneUserTrainingPrefs.add(newPref);        } else {            if (oneUserTestPrefs == null) {                oneUserTestPrefs = new ArrayList<>(3);            }            oneUserTestPrefs.add(newPref);        }    }    if (oneUserTrainingPrefs != null) {        trainingPrefs.put(userID, new GenericUserPreferenceArray(oneUserTrainingPrefs));        if (oneUserTestPrefs != null) {            testPrefs.put(userID, new GenericUserPreferenceArray(oneUserTestPrefs));        }    }}
private float mahout_f1353_0(float estimate)
{    if (estimate > maxPreference) {        return maxPreference;    }    if (estimate < minPreference) {        return minPreference;    }    return estimate;}
private double mahout_f1354_1(FastByIDMap<PreferenceArray> testPrefs, Recommender recommender) throws TasteException
{    reset();    Collection<Callable<Void>> estimateCallables = new ArrayList<>();    AtomicInteger noEstimateCounter = new AtomicInteger();    for (Map.Entry<Long, PreferenceArray> entry : testPrefs.entrySet()) {        estimateCallables.add(new PreferenceEstimateCallable(recommender, entry.getKey(), entry.getValue(), noEstimateCounter));    }        RunningAverageAndStdDev timing = new FullRunningAverageAndStdDev();    execute(estimateCallables, noEstimateCounter, timing);    return computeFinalEvaluation();}
protected static void mahout_f1355_1(Collection<Callable<Void>> callables, AtomicInteger noEstimateCounter, RunningAverageAndStdDev timing) throws TasteException
{    Collection<Callable<Void>> wrappedCallables = wrapWithStatsCallables(callables, noEstimateCounter, timing);    int numProcessors = Runtime.getRuntime().availableProcessors();    ExecutorService executor = Executors.newFixedThreadPool(numProcessors);        try {        List<Future<Void>> futures = executor.invokeAll(wrappedCallables);                for (Future<Void> future : futures) {            future.get();        }    } catch (InterruptedException ie) {        throw new TasteException(ie);    } catch (ExecutionException ee) {        throw new TasteException(ee.getCause());    }    executor.shutdown();    try {        executor.awaitTermination(10, TimeUnit.SECONDS);    } catch (InterruptedException e) {        throw new TasteException(e.getCause());    }}
private static Collection<Callable<Void>> mahout_f1356_0(Iterable<Callable<Void>> callables, AtomicInteger noEstimateCounter, RunningAverageAndStdDev timing)
{    Collection<Callable<Void>> wrapped = new ArrayList<>();    int count = 0;    for (Callable<Void> callable : callables) {                boolean logStats = count++ % 1000 == 0;        wrapped.add(new StatsCallable(callable, logStats, timing, noEstimateCounter));    }    return wrapped;}
public Void mahout_f1357_1() throws TasteException
{    for (Preference realPref : prefs) {        float estimatedPreference = Float.NaN;        try {            estimatedPreference = recommender.estimatePreference(testUserID, realPref.getItemID());        } catch (NoSuchUserException nsue) {                                            } catch (NoSuchItemException nsie) {                    }        if (Float.isNaN(estimatedPreference)) {            noEstimateCounter.incrementAndGet();        } else {            estimatedPreference = capEstimatedPreference(estimatedPreference);            processOneEstimate(estimatedPreference, realPref);        }    }    return null;}
protected void mahout_f1358_0()
{    average = new FullRunningAverage();}
protected void mahout_f1359_0(float estimatedPreference, Preference realPref)
{    average.addDatum(Math.abs(realPref.getValue() - estimatedPreference));}
protected double mahout_f1360_0()
{    return average.getAverage();}
public String mahout_f1361_0()
{    return "AverageAbsoluteDifferenceRecommenderEvaluator";}
public IRStatistics mahout_f1362_1(RecommenderBuilder recommenderBuilder, DataModelBuilder dataModelBuilder, DataModel dataModel, IDRescorer rescorer, int at, double relevanceThreshold, double evaluationPercentage) throws TasteException
{    Preconditions.checkArgument(recommenderBuilder != null, "recommenderBuilder is null");    Preconditions.checkArgument(dataModel != null, "dataModel is null");    Preconditions.checkArgument(at >= 1, "at must be at least 1");    Preconditions.checkArgument(evaluationPercentage > 0.0 && evaluationPercentage <= 1.0, "Invalid evaluationPercentage: " + evaluationPercentage + ". Must be: 0.0 < evaluationPercentage <= 1.0");    int numItems = dataModel.getNumItems();    RunningAverage precision = new FullRunningAverage();    RunningAverage recall = new FullRunningAverage();    RunningAverage fallOut = new FullRunningAverage();    RunningAverage nDCG = new FullRunningAverage();    int numUsersRecommendedFor = 0;    int numUsersWithRecommendations = 0;    LongPrimitiveIterator it = dataModel.getUserIDs();    while (it.hasNext()) {        long userID = it.nextLong();        if (random.nextDouble() >= evaluationPercentage) {                        continue;        }        long start = System.currentTimeMillis();        PreferenceArray prefs = dataModel.getPreferencesFromUser(userID);                double theRelevanceThreshold = Double.isNaN(relevanceThreshold) ? computeThreshold(prefs) : relevanceThreshold;        FastIDSet relevantItemIDs = dataSplitter.getRelevantItemsIDs(userID, at, theRelevanceThreshold, dataModel);        int numRelevantItems = relevantItemIDs.size();        if (numRelevantItems <= 0) {            continue;        }        FastByIDMap<PreferenceArray> trainingUsers = new FastByIDMap<>(dataModel.getNumUsers());        LongPrimitiveIterator it2 = dataModel.getUserIDs();        while (it2.hasNext()) {            dataSplitter.processOtherUser(userID, relevantItemIDs, trainingUsers, it2.nextLong(), dataModel);        }        DataModel trainingModel = dataModelBuilder == null ? new GenericDataModel(trainingUsers) : dataModelBuilder.buildDataModel(trainingUsers);        try {            trainingModel.getPreferencesFromUser(userID);        } catch (NoSuchUserException nsee) {                        continue;        }        int size = numRelevantItems + trainingModel.getItemIDsFromUser(userID).size();        if (size < 2 * at) {                        continue;        }        Recommender recommender = recommenderBuilder.buildRecommender(trainingModel);        int intersectionSize = 0;        List<RecommendedItem> recommendedItems = recommender.recommend(userID, at, rescorer);        for (RecommendedItem recommendedItem : recommendedItems) {            if (relevantItemIDs.contains(recommendedItem.getItemID())) {                intersectionSize++;            }        }        int numRecommendedItems = recommendedItems.size();                if (numRecommendedItems > 0) {            precision.addDatum((double) intersectionSize / (double) numRecommendedItems);        }                recall.addDatum((double) intersectionSize / (double) numRelevantItems);                if (numRelevantItems < size) {            fallOut.addDatum((double) (numRecommendedItems - intersectionSize) / (double) (numItems - numRelevantItems));        }                        double cumulativeGain = 0.0;        double idealizedGain = 0.0;        for (int i = 0; i < numRecommendedItems; i++) {            RecommendedItem item = recommendedItems.get(i);                        double discount = 1.0 / log2(i + 2.0);            if (relevantItemIDs.contains(item.getItemID())) {                cumulativeGain += discount;            }                        if (i < numRelevantItems) {                idealizedGain += discount;            }        }        if (idealizedGain > 0.0) {            nDCG.addDatum(cumulativeGain / idealizedGain);        }                numUsersRecommendedFor++;        if (numRecommendedItems > 0) {            numUsersWithRecommendations++;        }        long end = System.currentTimeMillis();                    }    return new IRStatisticsImpl(precision.getAverage(), recall.getAverage(), fallOut.getAverage(), nDCG.getAverage(), (double) numUsersWithRecommendations / (double) numUsersRecommendedFor);}
private static double mahout_f1363_0(PreferenceArray prefs)
{    if (prefs.length() < 2) {                return Double.NEGATIVE_INFINITY;    }    RunningAverageAndStdDev stdDev = new FullRunningAverageAndStdDev();    int size = prefs.length();    for (int i = 0; i < size; i++) {        stdDev.addDatum(prefs.getValue(i));    }    return stdDev.getAverage() + stdDev.getStandardDeviation();}
private static double mahout_f1364_0(double value)
{    return Math.log(value) / LOG2;}
public FastIDSet mahout_f1365_0(long userID, int at, double relevanceThreshold, DataModel dataModel) throws TasteException
{    PreferenceArray prefs = dataModel.getPreferencesFromUser(userID);    FastIDSet relevantItemIDs = new FastIDSet(at);    prefs.sortByValueReversed();    for (int i = 0; i < prefs.length() && relevantItemIDs.size() < at; i++) {        if (prefs.getValue(i) >= relevanceThreshold) {            relevantItemIDs.add(prefs.getItemID(i));        }    }    return relevantItemIDs;}
public void mahout_f1366_0(long userID, FastIDSet relevantItemIDs, FastByIDMap<PreferenceArray> trainingUsers, long otherUserID, DataModel dataModel) throws TasteException
{    PreferenceArray prefs2Array = dataModel.getPreferencesFromUser(otherUserID);        if (userID == otherUserID) {                List<Preference> prefs2 = new ArrayList<>(prefs2Array.length());        for (Preference pref : prefs2Array) {            prefs2.add(pref);        }        for (Iterator<Preference> iterator = prefs2.iterator(); iterator.hasNext(); ) {            Preference pref = iterator.next();            if (relevantItemIDs.contains(pref.getItemID())) {                iterator.remove();            }        }        if (!prefs2.isEmpty()) {            trainingUsers.put(otherUserID, new GenericUserPreferenceArray(prefs2));        }    } else {                trainingUsers.put(otherUserID, prefs2Array);    }}
public double mahout_f1367_0()
{    return precision;}
public double mahout_f1368_0()
{    return recall;}
public double mahout_f1369_0()
{    return fallOut;}
public double mahout_f1370_0()
{    return getFNMeasure(1.0);}
public double mahout_f1371_0(double b)
{    double b2 = b * b;    double sum = b2 * precision + recall;    return sum == 0.0 ? Double.NaN : (1.0 + b2) * precision * recall / sum;}
public double mahout_f1372_0()
{    return ndcg;}
public double mahout_f1373_0()
{    return reach;}
public String mahout_f1374_0()
{    return "IRStatisticsImpl[precision:" + precision + ",recall:" + recall + ",fallOut:" + fallOut + ",nDCG:" + ndcg + ",reach:" + reach + ']';}
public Void mahout_f1375_0() throws Exception
{    recommender.recommend(userID, 10);    return null;}
public static LoadStatistics mahout_f1376_0(Recommender recommender) throws TasteException
{    return runLoad(recommender, 10);}
public static LoadStatistics mahout_f1377_0(Recommender recommender, int howMany) throws TasteException
{    DataModel dataModel = recommender.getDataModel();    int numUsers = dataModel.getNumUsers();    double sampleRate = 1000.0 / numUsers;    LongPrimitiveIterator userSampler = SamplingLongPrimitiveIterator.maybeWrapIterator(dataModel.getUserIDs(), sampleRate);        recommender.recommend(userSampler.next(), howMany);    Collection<Callable<Void>> callables = new ArrayList<>();    while (userSampler.hasNext()) {        callables.add(new LoadCallable(recommender, userSampler.next()));    }    AtomicInteger noEstimateCounter = new AtomicInteger();    RunningAverageAndStdDev timing = new FullRunningAverageAndStdDev();    AbstractDifferenceRecommenderEvaluator.execute(callables, noEstimateCounter, timing);    return new LoadStatistics(timing);}
public RunningAverage mahout_f1378_0()
{    return timing;}
public static void mahout_f1379_0(Recommender recommender1, Recommender recommender2, int samples, RunningAverage tracker, String tag) throws TasteException
{    printHeader();    LongPrimitiveIterator users = recommender1.getDataModel().getUserIDs();    while (users.hasNext()) {        long userID = users.nextLong();        List<RecommendedItem> recs1 = recommender1.recommend(userID, samples);        List<RecommendedItem> recs2 = recommender2.recommend(userID, samples);        FastIDSet commonSet = new FastIDSet();        long maxItemID = setBits(commonSet, recs1, samples);        FastIDSet otherSet = new FastIDSet();        maxItemID = Math.max(maxItemID, setBits(otherSet, recs2, samples));        int max = mask(commonSet, otherSet, maxItemID);        max = Math.min(max, samples);        if (max < 2) {            continue;        }        Long[] items1 = getCommonItems(commonSet, recs1, max);        Long[] items2 = getCommonItems(commonSet, recs2, max);        double variance = scoreCommonSubset(tag, userID, samples, max, items1, items2);        tracker.addDatum(variance);    }}
public static void mahout_f1380_0(Recommender recommender, DataModel model, int samples, RunningAverage tracker, String tag) throws TasteException
{    printHeader();    LongPrimitiveIterator users = recommender.getDataModel().getUserIDs();    while (users.hasNext()) {        long userID = users.nextLong();        List<RecommendedItem> recs1 = recommender.recommend(userID, model.getNumItems());        PreferenceArray prefs2 = model.getPreferencesFromUser(userID);        prefs2.sortByValueReversed();        FastIDSet commonSet = new FastIDSet();        long maxItemID = setBits(commonSet, recs1, samples);        FastIDSet otherSet = new FastIDSet();        maxItemID = Math.max(maxItemID, setBits(otherSet, prefs2, samples));        int max = mask(commonSet, otherSet, maxItemID);        max = Math.min(max, samples);        if (max < 2) {            continue;        }        Long[] items1 = getCommonItems(commonSet, recs1, max);        Long[] items2 = getCommonItems(commonSet, prefs2, max);        double variance = scoreCommonSubset(tag, userID, samples, max, items1, items2);        tracker.addDatum(variance);    }}
public static void mahout_f1381_0(DataModel model1, DataModel model2, int samples, RunningAverage tracker, String tag) throws TasteException
{    printHeader();    LongPrimitiveIterator users = model1.getUserIDs();    while (users.hasNext()) {        long userID = users.nextLong();        PreferenceArray prefs1 = model1.getPreferencesFromUser(userID);        PreferenceArray prefs2 = model2.getPreferencesFromUser(userID);        prefs1.sortByValueReversed();        prefs2.sortByValueReversed();        FastIDSet commonSet = new FastIDSet();        long maxItemID = setBits(commonSet, prefs1, samples);        FastIDSet otherSet = new FastIDSet();        maxItemID = Math.max(maxItemID, setBits(otherSet, prefs2, samples));        int max = mask(commonSet, otherSet, maxItemID);        max = Math.min(max, samples);        if (max < 2) {            continue;        }        Long[] items1 = getCommonItems(commonSet, prefs1, max);        Long[] items2 = getCommonItems(commonSet, prefs2, max);        double variance = scoreCommonSubset(tag, userID, samples, max, items1, items2);        tracker.addDatum(variance);    }}
private static int mahout_f1382_0(FastIDSet commonSet, FastIDSet otherSet, long maxItemID)
{    int count = 0;    for (int i = 0; i <= maxItemID; i++) {        if (commonSet.contains(i)) {            if (otherSet.contains(i)) {                count++;            } else {                commonSet.remove(i);            }        }    }    return count;}
private static Long[] mahout_f1383_0(FastIDSet commonSet, Iterable<RecommendedItem> recs, int max)
{    Long[] commonItems = new Long[max];    int index = 0;    for (RecommendedItem rec : recs) {        Long item = rec.getItemID();        if (commonSet.contains(item)) {            commonItems[index++] = item;        }        if (index == max) {            break;        }    }    return commonItems;}
private static Long[] mahout_f1384_0(FastIDSet commonSet, PreferenceArray prefs1, int max)
{    Long[] commonItems = new Long[max];    int index = 0;    for (int i = 0; i < prefs1.length(); i++) {        Long item = prefs1.getItemID(i);        if (commonSet.contains(item)) {            commonItems[index++] = item;        }        if (index == max) {            break;        }    }    return commonItems;}
private static long mahout_f1385_0(FastIDSet modelSet, List<RecommendedItem> items, int max)
{    long maxItem = -1;    for (int i = 0; i < items.size() && i < max; i++) {        long itemID = items.get(i).getItemID();        modelSet.add(itemID);        if (itemID > maxItem) {            maxItem = itemID;        }    }    return maxItem;}
private static long mahout_f1386_0(FastIDSet modelSet, PreferenceArray prefs, int max)
{    long maxItem = -1;    for (int i = 0; i < prefs.length() && i < max; i++) {        long itemID = prefs.getItemID(i);        modelSet.add(itemID);        if (itemID > maxItem) {            maxItem = itemID;        }    }    return maxItem;}
private static void mahout_f1387_1()
{    }
private static double mahout_f1388_1(String tag, long userID, int samples, int subset, Long[] itemsL, Long[] itemsR)
{    int[] vectorZ = new int[subset];    int[] vectorZabs = new int[subset];    long bubble = sort(itemsL, itemsR);    int hamming = slidingWindowHamming(itemsR, itemsL);    if (hamming > samples) {        throw new IllegalStateException();    }    getVectorZ(itemsR, itemsL, vectorZ, vectorZabs);    double normalW = normalWilcoxon(vectorZ, vectorZabs);    double meanRank = getMeanRank(vectorZabs);        double variance = Math.sqrt(meanRank);        return variance;}
private static int mahout_f1389_0(Long[] itemsR, Long[] itemsL)
{    int count = 0;    int samples = itemsR.length;    if (itemsR[0].equals(itemsL[0]) || itemsR[0].equals(itemsL[1])) {        count++;    }    for (int i = 1; i < samples - 1; i++) {        long itemID = itemsL[i];        if (itemsR[i] == itemID || itemsR[i - 1] == itemID || itemsR[i + 1] == itemID) {            count++;        }    }    if (itemsR[samples - 1].equals(itemsL[samples - 1]) || itemsR[samples - 1].equals(itemsL[samples - 2])) {        count++;    }    return count;}
 static double mahout_f1390_0(int[] vectorZ, int[] vectorZabs)
{    int nitems = vectorZ.length;    double[] ranks = new double[nitems];    double[] ranksAbs = new double[nitems];    wilcoxonRanks(vectorZ, vectorZabs, ranks, ranksAbs);    return Math.min(getMeanWplus(ranks), getMeanWminus(ranks));}
private static void mahout_f1391_0(Long[] itemsR, Long[] itemsL, int[] vectorZ, int[] vectorZabs)
{    int nitems = itemsR.length;    int bottom = 0;    int top = nitems - 1;    for (int i = 0; i < nitems; i++) {        long itemID = itemsR[i];        for (int j = bottom; j <= top; j++) {            if (itemsL[j] == null) {                continue;            }            long test = itemsL[j];            if (itemID == test) {                vectorZ[i] = i - j;                vectorZabs[i] = Math.abs(i - j);                if (j == bottom) {                    bottom++;                } else if (j == top) {                    top--;                } else {                    itemsL[j] = null;                }                break;            }        }    }}
private static void mahout_f1392_0(int[] vectorZ, int[] vectorZabs, double[] ranks, double[] ranksAbs)
{    int nitems = vectorZ.length;    int[] sorted = vectorZabs.clone();    Arrays.sort(sorted);    int zeros = 0;    for (; zeros < nitems; zeros++) {        if (sorted[zeros] > 0) {            break;        }    }    for (int i = 0; i < nitems; i++) {        double rank = 0.0;        int count = 0;        int score = vectorZabs[i];        for (int j = 0; j < nitems; j++) {            if (score == sorted[j]) {                rank += j + 1 - zeros;                count++;            } else if (score < sorted[j]) {                break;            }        }        if (vectorZ[i] != 0) {                        ranks[i] = (rank / count) * (vectorZ[i] < 0 ? -1 : 1);            ranksAbs[i] = Math.abs(ranks[i]);        }    }}
private static double mahout_f1393_0(int[] ranks)
{    int nitems = ranks.length;    double sum = 0.0;    for (int rank : ranks) {        sum += rank;    }    return sum / nitems;}
private static double mahout_f1394_0(double[] ranks)
{    int nitems = ranks.length;    double sum = 0.0;    for (double rank : ranks) {        if (rank > 0) {            sum += rank;        }    }    return sum / nitems;}
private static double mahout_f1395_0(double[] ranks)
{    int nitems = ranks.length;    double sum = 0.0;    for (double rank : ranks) {        if (rank < 0) {            sum -= rank;        }    }    return sum / nitems;}
 static long mahout_f1396_0(Long[] itemsL, Long[] itemsR)
{    int length = itemsL.length;    if (length < 2) {        return 0;    }    if (length == 2) {        return itemsL[0].longValue() == itemsR[0].longValue() ? 0 : 1;    }        long[] reference = new long[length];    long[] sortable = new long[length];    for (int i = 0; i < length; i++) {        reference[i] = itemsL[i];        sortable[i] = itemsR[i];    }    int sorted = 0;    long swaps = 0;    while (sorted < length - 1) {                while (length > 0 && reference[length - 1] == sortable[length - 1]) {            length--;        }        if (length == 0) {            break;        }        if (reference[sorted] == sortable[sorted]) {            sorted++;        } else {            for (int j = sorted; j < length - 1; j++) {                                int jump = 1;                if (reference[j] == sortable[j]) {                    while (j + jump < length && reference[j + jump] == sortable[j + jump]) {                        jump++;                    }                }                if (j + jump < length && !(reference[j] == sortable[j] && reference[j + jump] == sortable[j + jump])) {                    long tmp = sortable[j];                    sortable[j] = sortable[j + 1];                    sortable[j + 1] = tmp;                    swaps++;                }            }        }    }    return swaps;}
protected void mahout_f1397_0()
{    average = new FullRunningAverage();}
protected void mahout_f1398_0(float estimatedPreference, Preference realPref)
{    double diff = realPref.getValue() - estimatedPreference;    average.addDatum(diff * diff);}
protected double mahout_f1399_0()
{    return Math.sqrt(average.getAverage());}
public String mahout_f1400_0()
{    return "RMSRecommenderEvaluator";}
public Void mahout_f1401_1() throws Exception
{    long start = System.currentTimeMillis();    delegate.call();    long end = System.currentTimeMillis();    timing.addDatum(end - start);    if (logStats) {        Runtime runtime = Runtime.getRuntime();        int average = (int) timing.getAverage();                long totalMemory = runtime.totalMemory();        long memory = totalMemory - runtime.freeMemory();                    }    return null;}
public float mahout_f1402_0()
{    return maxPreference;}
protected void mahout_f1403_0(float maxPreference)
{    this.maxPreference = maxPreference;}
public float mahout_f1404_0()
{    return minPreference;}
protected void mahout_f1405_0(float minPreference)
{    this.minPreference = minPreference;}
protected final long mahout_f1406_0(String value)
{    byte[] md5hash;    synchronized (md5Digest) {        md5hash = md5Digest.digest(value.getBytes(Charsets.UTF_8));        md5Digest.reset();    }    long hash = 0L;    for (int i = 0; i < 8; i++) {        hash = hash << 8 | md5hash[i] & 0x00000000000000FFL;    }    return hash;}
public long mahout_f1407_0(String stringID)
{    return hash(stringID);}
public void mahout_f1408_0(Collection<Refreshable> alreadyRefreshed)
{}
public final void mahout_f1409_0(long longID, String stringID) throws TasteException
{    Connection conn = null;    PreparedStatement stmt = null;    try {        conn = dataSource.getConnection();        stmt = conn.prepareStatement(storeMappingSQL);        stmt.setLong(1, longID);        stmt.setString(2, stringID);        stmt.executeUpdate();    } catch (SQLException sqle) {        throw new TasteException(sqle);    } finally {        IOUtils.quietClose(null, stmt, conn);    }}
public final String mahout_f1410_0(long longID) throws TasteException
{    Connection conn = null;    PreparedStatement stmt = null;    ResultSet rs = null;    try {        conn = dataSource.getConnection();        stmt = conn.prepareStatement(getStringIDSQL, ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY);        stmt.setFetchDirection(ResultSet.FETCH_FORWARD);        stmt.setFetchSize(1);        stmt.setLong(1, longID);        rs = stmt.executeQuery();        if (rs.next()) {            return rs.getString(1);        } else {            return null;        }    } catch (SQLException sqle) {        throw new TasteException(sqle);    } finally {        IOUtils.quietClose(rs, stmt, conn);    }}
public void mahout_f1411_0(Iterable<String> stringIDs) throws TasteException
{    for (String stringID : stringIDs) {        storeMapping(toLongID(stringID), stringID);    }}
public int mahout_f1412_0()
{    return ids.length;}
public Preference mahout_f1413_0(int i)
{    return new PreferenceView(i);}
public void mahout_f1414_0(int i, Preference pref)
{    id = pref.getItemID();    ids[i] = pref.getUserID();}
public long mahout_f1415_0(int i)
{    return ids[i];}
public void mahout_f1416_0(int i, long userID)
{    ids[i] = userID;}
public long mahout_f1417_0(int i)
{    return id;}
public void mahout_f1418_0(int i, long itemID)
{    id = itemID;}
public long[] mahout_f1419_0()
{    return ids;}
public float mahout_f1420_0(int i)
{    return 1.0f;}
public void mahout_f1421_0(int i, float value)
{    throw new UnsupportedOperationException();}
public void mahout_f1422_0()
{    Arrays.sort(ids);}
public void mahout_f1423_0()
{}
public void mahout_f1424_0()
{}
public void mahout_f1425_0()
{}
public boolean mahout_f1426_0(long userID)
{    for (long id : ids) {        if (userID == id) {            return true;        }    }    return false;}
public boolean mahout_f1427_0(long itemID)
{    return id == itemID;}
public BooleanItemPreferenceArray mahout_f1428_0()
{    return new BooleanItemPreferenceArray(ids.clone(), id);}
public int mahout_f1429_0()
{    return (int) (id >> 32) ^ (int) id ^ Arrays.hashCode(ids);}
public boolean mahout_f1430_0(Object other)
{    if (!(other instanceof BooleanItemPreferenceArray)) {        return false;    }    BooleanItemPreferenceArray otherArray = (BooleanItemPreferenceArray) other;    return id == otherArray.id && Arrays.equals(ids, otherArray.ids);}
public Iterator<Preference> mahout_f1431_0()
{    return Iterators.transform(new CountingIterator(length()), new Function<Integer, Preference>() {        @Override        public Preference apply(Integer from) {            return new PreferenceView(from);        }    });}
public Preference mahout_f1432_0(Integer from)
{    return new PreferenceView(from);}
public String mahout_f1433_0()
{    StringBuilder result = new StringBuilder(10 * ids.length);    result.append("BooleanItemPreferenceArray[itemID:");    result.append(id);    result.append(",{");    for (int i = 0; i < ids.length; i++) {        if (i > 0) {            result.append(',');        }        result.append(ids[i]);    }    result.append("}]");    return result.toString();}
public long mahout_f1434_0()
{    return BooleanItemPreferenceArray.this.getUserID(i);}
public long mahout_f1435_0()
{    return BooleanItemPreferenceArray.this.getItemID(i);}
public float mahout_f1436_0()
{    return 1.0f;}
public void mahout_f1437_0(float value)
{    throw new UnsupportedOperationException();}
public long mahout_f1438_0()
{    return userID;}
public long mahout_f1439_0()
{    return itemID;}
public float mahout_f1440_0()
{    return 1.0f;}
public void mahout_f1441_0(float value)
{    throw new UnsupportedOperationException();}
public String mahout_f1442_0()
{    return "BooleanPreference[userID: " + userID + ", itemID:" + itemID + ']';}
public int mahout_f1443_0()
{    return ids.length;}
public Preference mahout_f1444_0(int i)
{    return new PreferenceView(i);}
public void mahout_f1445_0(int i, Preference pref)
{    id = pref.getUserID();    ids[i] = pref.getItemID();}
public long mahout_f1446_0(int i)
{    return id;}
public void mahout_f1447_0(int i, long userID)
{    id = userID;}
public long mahout_f1448_0(int i)
{    return ids[i];}
public void mahout_f1449_0(int i, long itemID)
{    ids[i] = itemID;}
public long[] mahout_f1450_0()
{    return ids;}
public float mahout_f1451_0(int i)
{    return 1.0f;}
public void mahout_f1452_0(int i, float value)
{    throw new UnsupportedOperationException();}
public void mahout_f1453_0()
{}
public void mahout_f1454_0()
{    Arrays.sort(ids);}
public void mahout_f1455_0()
{}
public void mahout_f1456_0()
{}
public boolean mahout_f1457_0(long userID)
{    return id == userID;}
public boolean mahout_f1458_0(long itemID)
{    for (long id : ids) {        if (itemID == id) {            return true;        }    }    return false;}
public BooleanUserPreferenceArray mahout_f1459_0()
{    return new BooleanUserPreferenceArray(ids.clone(), id);}
public int mahout_f1460_0()
{    return (int) (id >> 32) ^ (int) id ^ Arrays.hashCode(ids);}
public boolean mahout_f1461_0(Object other)
{    if (!(other instanceof BooleanUserPreferenceArray)) {        return false;    }    BooleanUserPreferenceArray otherArray = (BooleanUserPreferenceArray) other;    return id == otherArray.id && Arrays.equals(ids, otherArray.ids);}
public Iterator<Preference> mahout_f1462_0()
{    return Iterators.transform(new CountingIterator(length()), new Function<Integer, Preference>() {        @Override        public Preference apply(Integer from) {            return new PreferenceView(from);        }    });}
public Preference mahout_f1463_0(Integer from)
{    return new PreferenceView(from);}
public String mahout_f1464_0()
{    StringBuilder result = new StringBuilder(10 * ids.length);    result.append("BooleanUserPreferenceArray[userID:");    result.append(id);    result.append(",{");    for (int i = 0; i < ids.length; i++) {        if (i > 0) {            result.append(',');        }        result.append(ids[i]);    }    result.append("}]");    return result.toString();}
public long mahout_f1465_0()
{    return BooleanUserPreferenceArray.this.getUserID(i);}
public long mahout_f1466_0()
{    return BooleanUserPreferenceArray.this.getItemID(i);}
public float mahout_f1467_0()
{    return 1.0f;}
public void mahout_f1468_0(float value)
{    throw new UnsupportedOperationException();}
public File mahout_f1469_0()
{    return dataFile;}
protected void mahout_f1470_1()
{    if (reloadLock.tryLock()) {        try {            delegate = buildModel();        } catch (IOException ioe) {                    } finally {            reloadLock.unlock();        }    }}
protected DataModel mahout_f1471_0() throws IOException
{    long newLastModified = dataFile.lastModified();    long newLastUpdateFileModified = readLastUpdateFileModified();    boolean loadFreshData = delegate == null || newLastModified > lastModified + minReloadIntervalMS;    long oldLastUpdateFileModifieid = lastUpdateFileModified;    lastModified = newLastModified;    lastUpdateFileModified = newLastUpdateFileModified;    FastByIDMap<FastByIDMap<Long>> timestamps = new FastByIDMap<>();    if (hasPrefValues) {        if (loadFreshData) {            FastByIDMap<Collection<Preference>> data = new FastByIDMap<>();            FileLineIterator iterator = new FileLineIterator(dataFile, false);            processFile(iterator, data, timestamps, false);            for (File updateFile : findUpdateFilesAfter(newLastModified)) {                processFile(new FileLineIterator(updateFile, false), data, timestamps, false);            }            return new GenericDataModel(GenericDataModel.toDataMap(data, true), timestamps);        } else {            FastByIDMap<PreferenceArray> rawData = ((GenericDataModel) delegate).getRawUserData();            for (File updateFile : findUpdateFilesAfter(Math.max(oldLastUpdateFileModifieid, newLastModified))) {                processFile(new FileLineIterator(updateFile, false), rawData, timestamps, true);            }            return new GenericDataModel(rawData, timestamps);        }    } else {        if (loadFreshData) {            FastByIDMap<FastIDSet> data = new FastByIDMap<>();            FileLineIterator iterator = new FileLineIterator(dataFile, false);            processFileWithoutID(iterator, data, timestamps);            for (File updateFile : findUpdateFilesAfter(newLastModified)) {                processFileWithoutID(new FileLineIterator(updateFile, false), data, timestamps);            }            return new GenericBooleanPrefDataModel(data, timestamps);        } else {            FastByIDMap<FastIDSet> rawData = ((GenericBooleanPrefDataModel) delegate).getRawUserData();            for (File updateFile : findUpdateFilesAfter(Math.max(oldLastUpdateFileModifieid, newLastModified))) {                processFileWithoutID(new FileLineIterator(updateFile, false), rawData, timestamps);            }            return new GenericBooleanPrefDataModel(rawData, timestamps);        }    }}
private Iterable<File> mahout_f1472_0(long minimumLastModified)
{    String dataFileName = dataFile.getName();    int period = dataFileName.indexOf('.');    String startName = period < 0 ? dataFileName : dataFileName.substring(0, period);    File parentDir = dataFile.getParentFile();    Map<Long, File> modTimeToUpdateFile = new TreeMap<>();    FileFilter onlyFiles = new FileFilter() {        @Override        public boolean accept(File file) {            return !file.isDirectory();        }    };    for (File updateFile : parentDir.listFiles(onlyFiles)) {        String updateFileName = updateFile.getName();        if (updateFileName.startsWith(startName) && !updateFileName.equals(dataFileName) && updateFile.lastModified() >= minimumLastModified) {            modTimeToUpdateFile.put(updateFile.lastModified(), updateFile);        }    }    return modTimeToUpdateFile.values();}
public boolean mahout_f1473_0(File file)
{    return !file.isDirectory();}
private long mahout_f1474_0()
{    long mostRecentModification = Long.MIN_VALUE;    for (File updateFile : findUpdateFilesAfter(0L)) {        mostRecentModification = Math.max(mostRecentModification, updateFile.lastModified());    }    return mostRecentModification;}
public static char mahout_f1475_0(String line)
{    for (char possibleDelimieter : DELIMIETERS) {        if (line.indexOf(possibleDelimieter) >= 0) {            return possibleDelimieter;        }    }    throw new IllegalArgumentException("Did not find a delimiter in first line");}
protected void mahout_f1476_1(FileLineIterator dataOrUpdateFileIterator, FastByIDMap<?> data, FastByIDMap<FastByIDMap<Long>> timestamps, boolean fromPriorData)
{        int count = 0;    while (dataOrUpdateFileIterator.hasNext()) {        String line = dataOrUpdateFileIterator.next();        if (!line.isEmpty()) {            processLine(line, data, timestamps, fromPriorData);            if (++count % 1000000 == 0) {                            }        }    }    }
protected void mahout_f1477_0(String line, FastByIDMap<?> data, FastByIDMap<FastByIDMap<Long>> timestamps, boolean fromPriorData)
{        if (line.isEmpty() || line.charAt(0) == COMMENT_CHAR) {        return;    }    Iterator<String> tokens = delimiterPattern.split(line).iterator();    String userIDString = tokens.next();    String itemIDString = tokens.next();    String preferenceValueString = tokens.next();    boolean hasTimestamp = tokens.hasNext();    String timestampString = hasTimestamp ? tokens.next() : null;    long userID = readUserIDFromString(userIDString);    long itemID = readItemIDFromString(itemIDString);    if (transpose) {        long tmp = userID;        userID = itemID;        itemID = tmp;    }        Object maybePrefs = data.get(userID);    if (fromPriorData) {                PreferenceArray prefs = (PreferenceArray) maybePrefs;        if (!hasTimestamp && preferenceValueString.isEmpty()) {                        if (prefs != null) {                boolean exists = false;                int length = prefs.length();                for (int i = 0; i < length; i++) {                    if (prefs.getItemID(i) == itemID) {                        exists = true;                        break;                    }                }                if (exists) {                    if (length == 1) {                        data.remove(userID);                    } else {                        PreferenceArray newPrefs = new GenericUserPreferenceArray(length - 1);                        for (int i = 0, j = 0; i < length; i++, j++) {                            if (prefs.getItemID(i) == itemID) {                                j--;                            } else {                                newPrefs.set(j, prefs.get(i));                            }                        }                        ((FastByIDMap<PreferenceArray>) data).put(userID, newPrefs);                    }                }            }            removeTimestamp(userID, itemID, timestamps);        } else {            float preferenceValue = Float.parseFloat(preferenceValueString);            boolean exists = false;            if (prefs != null) {                for (int i = 0; i < prefs.length(); i++) {                    if (prefs.getItemID(i) == itemID) {                        exists = true;                        prefs.setValue(i, preferenceValue);                        break;                    }                }            }            if (!exists) {                if (prefs == null) {                    prefs = new GenericUserPreferenceArray(1);                } else {                    PreferenceArray newPrefs = new GenericUserPreferenceArray(prefs.length() + 1);                    for (int i = 0, j = 1; i < prefs.length(); i++, j++) {                        newPrefs.set(j, prefs.get(i));                    }                    prefs = newPrefs;                }                prefs.setUserID(0, userID);                prefs.setItemID(0, itemID);                prefs.setValue(0, preferenceValue);                ((FastByIDMap<PreferenceArray>) data).put(userID, prefs);            }        }        addTimestamp(userID, itemID, timestampString, timestamps);    } else {                Collection<Preference> prefs = (Collection<Preference>) maybePrefs;        if (!hasTimestamp && preferenceValueString.isEmpty()) {                        if (prefs != null) {                                Iterator<Preference> prefsIterator = prefs.iterator();                while (prefsIterator.hasNext()) {                    Preference pref = prefsIterator.next();                    if (pref.getItemID() == itemID) {                        prefsIterator.remove();                        break;                    }                }            }            removeTimestamp(userID, itemID, timestamps);        } else {            float preferenceValue = Float.parseFloat(preferenceValueString);            boolean exists = false;            if (prefs != null) {                for (Preference pref : prefs) {                    if (pref.getItemID() == itemID) {                        exists = true;                        pref.setValue(preferenceValue);                        break;                    }                }            }            if (!exists) {                if (prefs == null) {                    prefs = new ArrayList<>(2);                    ((FastByIDMap<Collection<Preference>>) data).put(userID, prefs);                }                prefs.add(new GenericPreference(userID, itemID, preferenceValue));            }            addTimestamp(userID, itemID, timestampString, timestamps);        }    }}
protected void mahout_f1478_1(FileLineIterator dataOrUpdateFileIterator, FastByIDMap<FastIDSet> data, FastByIDMap<FastByIDMap<Long>> timestamps)
{        int count = 0;    while (dataOrUpdateFileIterator.hasNext()) {        String line = dataOrUpdateFileIterator.next();        if (!line.isEmpty()) {            processLineWithoutID(line, data, timestamps);            if (++count % 100000 == 0) {                            }        }    }    }
protected void mahout_f1479_0(String line, FastByIDMap<FastIDSet> data, FastByIDMap<FastByIDMap<Long>> timestamps)
{    if (line.isEmpty() || line.charAt(0) == COMMENT_CHAR) {        return;    }    Iterator<String> tokens = delimiterPattern.split(line).iterator();    String userIDString = tokens.next();    String itemIDString = tokens.next();    boolean hasPreference = tokens.hasNext();    String preferenceValueString = hasPreference ? tokens.next() : "";    boolean hasTimestamp = tokens.hasNext();    String timestampString = hasTimestamp ? tokens.next() : null;    long userID = readUserIDFromString(userIDString);    long itemID = readItemIDFromString(itemIDString);    if (transpose) {        long tmp = userID;        userID = itemID;        itemID = tmp;    }    if (hasPreference && !hasTimestamp && preferenceValueString.isEmpty()) {                FastIDSet itemIDs = data.get(userID);        if (itemIDs != null) {            itemIDs.remove(itemID);        }        removeTimestamp(userID, itemID, timestamps);    } else {        FastIDSet itemIDs = data.get(userID);        if (itemIDs == null) {            itemIDs = new FastIDSet(2);            data.put(userID, itemIDs);        }        itemIDs.add(itemID);        addTimestamp(userID, itemID, timestampString, timestamps);    }}
private void mahout_f1480_0(long userID, long itemID, String timestampString, FastByIDMap<FastByIDMap<Long>> timestamps)
{    if (timestampString != null) {        FastByIDMap<Long> itemTimestamps = timestamps.get(userID);        if (itemTimestamps == null) {            itemTimestamps = new FastByIDMap<>();            timestamps.put(userID, itemTimestamps);        }        long timestamp = readTimestampFromString(timestampString);        itemTimestamps.put(itemID, timestamp);    }}
private static void mahout_f1481_0(long userID, long itemID, FastByIDMap<FastByIDMap<Long>> timestamps)
{    FastByIDMap<Long> itemTimestamps = timestamps.get(userID);    if (itemTimestamps != null) {        itemTimestamps.remove(itemID);    }}
protected long mahout_f1482_0(String value)
{    return Long.parseLong(value);}
protected long mahout_f1483_0(String value)
{    return Long.parseLong(value);}
protected long mahout_f1484_0(String value)
{    return Long.parseLong(value);}
public LongPrimitiveIterator mahout_f1485_0() throws TasteException
{    return delegate.getUserIDs();}
public PreferenceArray mahout_f1486_0(long userID) throws TasteException
{    return delegate.getPreferencesFromUser(userID);}
public FastIDSet mahout_f1487_0(long userID) throws TasteException
{    return delegate.getItemIDsFromUser(userID);}
public LongPrimitiveIterator mahout_f1488_0() throws TasteException
{    return delegate.getItemIDs();}
public PreferenceArray mahout_f1489_0(long itemID) throws TasteException
{    return delegate.getPreferencesForItem(itemID);}
public Float mahout_f1490_0(long userID, long itemID) throws TasteException
{    return delegate.getPreferenceValue(userID, itemID);}
public Long mahout_f1491_0(long userID, long itemID) throws TasteException
{    return delegate.getPreferenceTime(userID, itemID);}
public int mahout_f1492_0() throws TasteException
{    return delegate.getNumItems();}
public int mahout_f1493_0() throws TasteException
{    return delegate.getNumUsers();}
public int mahout_f1494_0(long itemID) throws TasteException
{    return delegate.getNumUsersWithPreferenceFor(itemID);}
public int mahout_f1495_0(long itemID1, long itemID2) throws TasteException
{    return delegate.getNumUsersWithPreferenceFor(itemID1, itemID2);}
public void mahout_f1496_0(long userID, long itemID, float value) throws TasteException
{    delegate.setPreference(userID, itemID, value);}
public void mahout_f1497_0(long userID, long itemID) throws TasteException
{    delegate.removePreference(userID, itemID);}
public boolean mahout_f1499_0()
{    return delegate.hasPreferenceValues();}
public float mahout_f1500_0()
{    return delegate.getMaxPreference();}
public float mahout_f1501_0()
{    return delegate.getMinPreference();}
public String mahout_f1502_0()
{    return "FileDataModel[dataFile:" + dataFile + ']';}
public String mahout_f1503_0(long longID)
{    return longToString.get(longID);}
private void mahout_f1504_0()
{    if (reloadLock.tryLock()) {        try {            longToString = buildMapping();        } catch (IOException ioe) {            throw new IllegalStateException(ioe);        } finally {            reloadLock.unlock();        }    }}
private FastByIDMap<String> mahout_f1505_0() throws IOException
{    FastByIDMap<String> mapping = new FastByIDMap<>();    for (String line : new FileLineIterable(dataFile)) {        mapping.put(toLongID(line), line);    }    lastModified = dataFile.lastModified();    return mapping;}
public String mahout_f1507_0()
{    return "FileIDMigrator[dataFile:" + dataFile + ']';}
public static FastByIDMap<FastIDSet> mahout_f1508_0(DataModel dataModel) throws TasteException
{    FastByIDMap<FastIDSet> data = new FastByIDMap<>(dataModel.getNumUsers());    LongPrimitiveIterator it = dataModel.getUserIDs();    while (it.hasNext()) {        long userID = it.nextLong();        data.put(userID, dataModel.getItemIDsFromUser(userID));    }    return data;}
public static FastByIDMap<FastIDSet> mahout_f1509_0(FastByIDMap<PreferenceArray> data)
{    for (Map.Entry<Long, Object> entry : ((FastByIDMap<Object>) (FastByIDMap<?>) data).entrySet()) {        PreferenceArray prefArray = (PreferenceArray) entry.getValue();        int size = prefArray.length();        FastIDSet itemIDs = new FastIDSet(size);        for (int i = 0; i < size; i++) {            itemIDs.add(prefArray.getItemID(i));        }        entry.setValue(itemIDs);    }    return (FastByIDMap<FastIDSet>) (FastByIDMap<?>) data;}
public FastByIDMap<FastIDSet> mahout_f1510_0()
{    return this.preferenceFromUsers;}
public FastByIDMap<FastIDSet> mahout_f1511_0()
{    return this.preferenceForItems;}
public LongPrimitiveArrayIterator mahout_f1512_0()
{    return new LongPrimitiveArrayIterator(userIDs);}
public PreferenceArray mahout_f1513_0(long userID) throws NoSuchUserException
{    FastIDSet itemIDs = preferenceFromUsers.get(userID);    if (itemIDs == null) {        throw new NoSuchUserException(userID);    }    PreferenceArray prefArray = new BooleanUserPreferenceArray(itemIDs.size());    int i = 0;    LongPrimitiveIterator it = itemIDs.iterator();    while (it.hasNext()) {        prefArray.setUserID(i, userID);        prefArray.setItemID(i, it.nextLong());        i++;    }    return prefArray;}
public FastIDSet mahout_f1514_0(long userID) throws TasteException
{    FastIDSet itemIDs = preferenceFromUsers.get(userID);    if (itemIDs == null) {        throw new NoSuchUserException(userID);    }    return itemIDs;}
public LongPrimitiveArrayIterator mahout_f1515_0()
{    return new LongPrimitiveArrayIterator(itemIDs);}
public PreferenceArray mahout_f1516_0(long itemID) throws NoSuchItemException
{    FastIDSet userIDs = preferenceForItems.get(itemID);    if (userIDs == null) {        throw new NoSuchItemException(itemID);    }    PreferenceArray prefArray = new BooleanItemPreferenceArray(userIDs.size());    int i = 0;    LongPrimitiveIterator it = userIDs.iterator();    while (it.hasNext()) {        prefArray.setUserID(i, it.nextLong());        prefArray.setItemID(i, itemID);        i++;    }    return prefArray;}
public Float mahout_f1517_0(long userID, long itemID) throws NoSuchUserException
{    FastIDSet itemIDs = preferenceFromUsers.get(userID);    if (itemIDs == null) {        throw new NoSuchUserException(userID);    }    if (itemIDs.contains(itemID)) {        return 1.0f;    }    return null;}
public Long mahout_f1518_0(long userID, long itemID) throws TasteException
{    if (timestamps == null) {        return null;    }    FastByIDMap<Long> itemTimestamps = timestamps.get(userID);    if (itemTimestamps == null) {        throw new NoSuchUserException(userID);    }    return itemTimestamps.get(itemID);}
public int mahout_f1519_0()
{    return itemIDs.length;}
public int mahout_f1520_0()
{    return userIDs.length;}
public int mahout_f1521_0(long itemID)
{    FastIDSet userIDs1 = preferenceForItems.get(itemID);    return userIDs1 == null ? 0 : userIDs1.size();}
public int mahout_f1522_0(long itemID1, long itemID2)
{    FastIDSet userIDs1 = preferenceForItems.get(itemID1);    if (userIDs1 == null) {        return 0;    }    FastIDSet userIDs2 = preferenceForItems.get(itemID2);    if (userIDs2 == null) {        return 0;    }    return userIDs1.size() < userIDs2.size() ? userIDs2.intersectionSize(userIDs1) : userIDs1.intersectionSize(userIDs2);}
public void mahout_f1523_0(long userID, long itemID)
{    throw new UnsupportedOperationException();}
public void mahout_f1524_0(long userID, long itemID, float value)
{    throw new UnsupportedOperationException();}
public void mahout_f1525_0(Collection<Refreshable> alreadyRefreshed)
{}
public boolean mahout_f1526_0()
{    return false;}
public String mahout_f1527_0()
{    StringBuilder result = new StringBuilder(200);    result.append("GenericBooleanPrefDataModel[users:");    for (int i = 0; i < Math.min(3, userIDs.length); i++) {        if (i > 0) {            result.append(',');        }        result.append(userIDs[i]);    }    if (userIDs.length > 3) {        result.append("...");    }    result.append(']');    return result.toString();}
public static FastByIDMap<PreferenceArray> mahout_f1528_0(FastByIDMap<Collection<Preference>> data, boolean byUser)
{    for (Map.Entry<Long, Object> entry : ((FastByIDMap<Object>) (FastByIDMap<?>) data).entrySet()) {        List<Preference> prefList = (List<Preference>) entry.getValue();        entry.setValue(byUser ? new GenericUserPreferenceArray(prefList) : new GenericItemPreferenceArray(prefList));    }    return (FastByIDMap<PreferenceArray>) (FastByIDMap<?>) data;}
public static FastByIDMap<PreferenceArray> mahout_f1529_0(DataModel dataModel) throws TasteException
{    FastByIDMap<PreferenceArray> data = new FastByIDMap<>(dataModel.getNumUsers());    LongPrimitiveIterator it = dataModel.getUserIDs();    while (it.hasNext()) {        long userID = it.nextLong();        data.put(userID, dataModel.getPreferencesFromUser(userID));    }    return data;}
public FastByIDMap<PreferenceArray> mahout_f1530_0()
{    return this.preferenceFromUsers;}
public FastByIDMap<PreferenceArray> mahout_f1531_0()
{    return this.preferenceForItems;}
public LongPrimitiveArrayIterator mahout_f1532_0()
{    return new LongPrimitiveArrayIterator(userIDs);}
public PreferenceArray mahout_f1533_0(long userID) throws NoSuchUserException
{    PreferenceArray prefs = preferenceFromUsers.get(userID);    if (prefs == null) {        throw new NoSuchUserException(userID);    }    return prefs;}
public FastIDSet mahout_f1534_0(long userID) throws TasteException
{    PreferenceArray prefs = getPreferencesFromUser(userID);    int size = prefs.length();    FastIDSet result = new FastIDSet(size);    for (int i = 0; i < size; i++) {        result.add(prefs.getItemID(i));    }    return result;}
public LongPrimitiveArrayIterator mahout_f1535_0()
{    return new LongPrimitiveArrayIterator(itemIDs);}
public PreferenceArray mahout_f1536_0(long itemID) throws NoSuchItemException
{    PreferenceArray prefs = preferenceForItems.get(itemID);    if (prefs == null) {        throw new NoSuchItemException(itemID);    }    return prefs;}
public Float mahout_f1537_0(long userID, long itemID) throws TasteException
{    PreferenceArray prefs = getPreferencesFromUser(userID);    int size = prefs.length();    for (int i = 0; i < size; i++) {        if (prefs.getItemID(i) == itemID) {            return prefs.getValue(i);        }    }    return null;}
public Long mahout_f1538_0(long userID, long itemID) throws TasteException
{    if (timestamps == null) {        return null;    }    FastByIDMap<Long> itemTimestamps = timestamps.get(userID);    if (itemTimestamps == null) {        throw new NoSuchUserException(userID);    }    return itemTimestamps.get(itemID);}
public int mahout_f1539_0()
{    return itemIDs.length;}
public int mahout_f1540_0()
{    return userIDs.length;}
public int mahout_f1541_0(long itemID)
{    PreferenceArray prefs1 = preferenceForItems.get(itemID);    return prefs1 == null ? 0 : prefs1.length();}
public int mahout_f1542_0(long itemID1, long itemID2)
{    PreferenceArray prefs1 = preferenceForItems.get(itemID1);    if (prefs1 == null) {        return 0;    }    PreferenceArray prefs2 = preferenceForItems.get(itemID2);    if (prefs2 == null) {        return 0;    }    int size1 = prefs1.length();    int size2 = prefs2.length();    int count = 0;    int i = 0;    int j = 0;    long userID1 = prefs1.getUserID(0);    long userID2 = prefs2.getUserID(0);    while (true) {        if (userID1 < userID2) {            if (++i == size1) {                break;            }            userID1 = prefs1.getUserID(i);        } else if (userID1 > userID2) {            if (++j == size2) {                break;            }            userID2 = prefs2.getUserID(j);        } else {            count++;            if (++i == size1 || ++j == size2) {                break;            }            userID1 = prefs1.getUserID(i);            userID2 = prefs2.getUserID(j);        }    }    return count;}
public void mahout_f1543_0(long userID, long itemID)
{    throw new UnsupportedOperationException();}
public void mahout_f1544_0(long userID, long itemID, float value)
{    throw new UnsupportedOperationException();}
public void mahout_f1545_0(Collection<Refreshable> alreadyRefreshed)
{}
public boolean mahout_f1546_0()
{    return true;}
public String mahout_f1547_0()
{    StringBuilder result = new StringBuilder(200);    result.append("GenericDataModel[users:");    for (int i = 0; i < Math.min(3, userIDs.length); i++) {        if (i > 0) {            result.append(',');        }        result.append(userIDs[i]);    }    if (userIDs.length > 3) {        result.append("...");    }    result.append(']');    return result.toString();}
public int mahout_f1548_0()
{    return ids.length;}
public Preference mahout_f1549_0(int i)
{    return new PreferenceView(i);}
public void mahout_f1550_0(int i, Preference pref)
{    id = pref.getItemID();    ids[i] = pref.getUserID();    values[i] = pref.getValue();}
public long mahout_f1551_0(int i)
{    return ids[i];}
public void mahout_f1552_0(int i, long userID)
{    ids[i] = userID;}
public long mahout_f1553_0(int i)
{    return id;}
public void mahout_f1554_0(int i, long itemID)
{    id = itemID;}
public long[] mahout_f1555_0()
{    return ids;}
public float mahout_f1556_0(int i)
{    return values[i];}
public void mahout_f1557_0(int i, float value)
{    values[i] = value;}
public void mahout_f1558_0()
{    lateralSort(USER);}
public void mahout_f1559_0()
{}
public void mahout_f1560_0()
{    lateralSort(VALUE);}
public void mahout_f1561_0()
{    lateralSort(VALUE_REVERSED);}
public boolean mahout_f1562_0(long userID)
{    for (long id : ids) {        if (userID == id) {            return true;        }    }    return false;}
public boolean mahout_f1563_0(long itemID)
{    return id == itemID;}
private void mahout_f1564_0(int type)
{        int length = length();    int gap = length;    boolean swapped = false;    while (gap > 1 || swapped) {        if (gap > 1) {                        gap /= 1.247330950103979;        }        swapped = false;        int max = length - gap;        for (int i = 0; i < max; i++) {            int other = i + gap;            if (isLess(other, i, type)) {                swap(i, other);                swapped = true;            }        }    }}
private boolean mahout_f1565_0(int i, int j, int type)
{    switch(type) {        case USER:            return ids[i] < ids[j];        case VALUE:            return values[i] < values[j];        case VALUE_REVERSED:            return values[i] > values[j];        default:            throw new IllegalStateException();    }}
private void mahout_f1566_0(int i, int j)
{    long temp1 = ids[i];    float temp2 = values[i];    ids[i] = ids[j];    values[i] = values[j];    ids[j] = temp1;    values[j] = temp2;}
public GenericItemPreferenceArray mahout_f1567_0()
{    return new GenericItemPreferenceArray(ids.clone(), id, values.clone());}
public int mahout_f1568_0()
{    return (int) (id >> 32) ^ (int) id ^ Arrays.hashCode(ids) ^ Arrays.hashCode(values);}
public boolean mahout_f1569_0(Object other)
{    if (!(other instanceof GenericItemPreferenceArray)) {        return false;    }    GenericItemPreferenceArray otherArray = (GenericItemPreferenceArray) other;    return id == otherArray.id && Arrays.equals(ids, otherArray.ids) && Arrays.equals(values, otherArray.values);}
public Iterator<Preference> mahout_f1570_0()
{    return Iterators.transform(new CountingIterator(length()), new Function<Integer, Preference>() {        @Override        public Preference apply(Integer from) {            return new PreferenceView(from);        }    });}
public Preference mahout_f1571_0(Integer from)
{    return new PreferenceView(from);}
public String mahout_f1572_0()
{    if (ids == null || ids.length == 0) {        return "GenericItemPreferenceArray[{}]";    }    StringBuilder result = new StringBuilder(20 * ids.length);    result.append("GenericItemPreferenceArray[itemID:");    result.append(id);    result.append(",{");    for (int i = 0; i < ids.length; i++) {        if (i > 0) {            result.append(',');        }        result.append(ids[i]);        result.append('=');        result.append(values[i]);    }    result.append("}]");    return result.toString();}
public long mahout_f1573_0()
{    return GenericItemPreferenceArray.this.getUserID(i);}
public long mahout_f1574_0()
{    return GenericItemPreferenceArray.this.getItemID(i);}
public float mahout_f1575_0()
{    return values[i];}
public void mahout_f1576_0(float value)
{    values[i] = value;}
public long mahout_f1577_0()
{    return userID;}
public long mahout_f1578_0()
{    return itemID;}
public float mahout_f1579_0()
{    return value;}
public void mahout_f1580_0(float value)
{    Preconditions.checkArgument(!Float.isNaN(value), "NaN value");    this.value = value;}
public String mahout_f1581_0()
{    return "GenericPreference[userID: " + userID + ", itemID:" + itemID + ", value:" + value + ']';}
public int mahout_f1582_0()
{    return ids.length;}
public Preference mahout_f1583_0(int i)
{    return new PreferenceView(i);}
public void mahout_f1584_0(int i, Preference pref)
{    id = pref.getUserID();    ids[i] = pref.getItemID();    values[i] = pref.getValue();}
public long mahout_f1585_0(int i)
{    return id;}
public void mahout_f1586_0(int i, long userID)
{    id = userID;}
public long mahout_f1587_0(int i)
{    return ids[i];}
public void mahout_f1588_0(int i, long itemID)
{    ids[i] = itemID;}
public long[] mahout_f1589_0()
{    return ids;}
public float mahout_f1590_0(int i)
{    return values[i];}
public void mahout_f1591_0(int i, float value)
{    values[i] = value;}
public void mahout_f1592_0()
{}
public void mahout_f1593_0()
{    lateralSort(ITEM);}
public void mahout_f1594_0()
{    lateralSort(VALUE);}
public void mahout_f1595_0()
{    lateralSort(VALUE_REVERSED);}
public boolean mahout_f1596_0(long userID)
{    return id == userID;}
public boolean mahout_f1597_0(long itemID)
{    for (long id : ids) {        if (itemID == id) {            return true;        }    }    return false;}
private void mahout_f1598_0(int type)
{        int length = length();    int gap = length;    boolean swapped = false;    while (gap > 1 || swapped) {        if (gap > 1) {                        gap /= 1.247330950103979;        }        swapped = false;        int max = length - gap;        for (int i = 0; i < max; i++) {            int other = i + gap;            if (isLess(other, i, type)) {                swap(i, other);                swapped = true;            }        }    }}
private boolean mahout_f1599_0(int i, int j, int type)
{    switch(type) {        case ITEM:            return ids[i] < ids[j];        case VALUE:            return values[i] < values[j];        case VALUE_REVERSED:            return values[i] > values[j];        default:            throw new IllegalStateException();    }}
private void mahout_f1600_0(int i, int j)
{    long temp1 = ids[i];    float temp2 = values[i];    ids[i] = ids[j];    values[i] = values[j];    ids[j] = temp1;    values[j] = temp2;}
public GenericUserPreferenceArray mahout_f1601_0()
{    return new GenericUserPreferenceArray(ids.clone(), id, values.clone());}
public int mahout_f1602_0()
{    return (int) (id >> 32) ^ (int) id ^ Arrays.hashCode(ids) ^ Arrays.hashCode(values);}
public boolean mahout_f1603_0(Object other)
{    if (!(other instanceof GenericUserPreferenceArray)) {        return false;    }    GenericUserPreferenceArray otherArray = (GenericUserPreferenceArray) other;    return id == otherArray.id && Arrays.equals(ids, otherArray.ids) && Arrays.equals(values, otherArray.values);}
public Iterator<Preference> mahout_f1604_0()
{    return Iterators.transform(new CountingIterator(length()), new Function<Integer, Preference>() {        @Override        public Preference apply(Integer from) {            return new PreferenceView(from);        }    });}
public Preference mahout_f1605_0(Integer from)
{    return new PreferenceView(from);}
public String mahout_f1606_0()
{    if (ids == null || ids.length == 0) {        return "GenericUserPreferenceArray[{}]";    }    StringBuilder result = new StringBuilder(20 * ids.length);    result.append("GenericUserPreferenceArray[userID:");    result.append(id);    result.append(",{");    for (int i = 0; i < ids.length; i++) {        if (i > 0) {            result.append(',');        }        result.append(ids[i]);        result.append('=');        result.append(values[i]);    }    result.append("}]");    return result.toString();}
public long mahout_f1607_0()
{    return GenericUserPreferenceArray.this.getUserID(i);}
public long mahout_f1608_0()
{    return GenericUserPreferenceArray.this.getItemID(i);}
public float mahout_f1609_0()
{    return values[i];}
public void mahout_f1610_0(float value)
{    values[i] = value;}
public void mahout_f1611_0(long longID, String stringID)
{    synchronized (longToString) {        longToString.put(longID, stringID);    }}
public String mahout_f1612_0(long longID)
{    synchronized (longToString) {        return longToString.get(longID);    }}
public void mahout_f1613_0(Iterable<String> stringIDs)
{    for (String stringID : stringIDs) {        storeMapping(toLongID(stringID), stringID);    }}
private void mahout_f1614_0(int usersPoolSize)
{    usersPool = new ConcurrentLinkedQueue<>();    for (int i = 0; i < usersPoolSize; i++) {        usersPool.add(TEMP_USER_ID + i);    }}
public Long mahout_f1615_0()
{    Long takenUserID = usersPool.poll();    if (takenUserID != null) {                tempPrefs.put(takenUserID, new GenericUserPreferenceArray(0));        return takenUserID;    }    return null;}
public boolean mahout_f1616_0(Long userID)
{    if (tempPrefs.containsKey(userID)) {        this.clearTempPrefs(userID);                usersPool.offer(userID);        return true;    }    return false;}
private boolean mahout_f1617_0(long userID)
{    return tempPrefs.containsKey(userID);}
public void mahout_f1618_0(PreferenceArray prefs, long anonymousUserID)
{    Preconditions.checkArgument(prefs != null && prefs.length() > 0, "prefs is null or empty");    this.tempPrefs.put(anonymousUserID, prefs);    FastIDSet userPrefItemIDs = new FastIDSet();    for (int i = 0; i < prefs.length(); i++) {        userPrefItemIDs.add(prefs.getItemID(i));    }    this.prefItemIDs.put(anonymousUserID, userPrefItemIDs);}
public void mahout_f1619_0(long anonymousUserID)
{    this.tempPrefs.remove(anonymousUserID);    this.prefItemIDs.remove(anonymousUserID);}
public LongPrimitiveIterator mahout_f1620_0() throws TasteException
{        return getDelegate().getUserIDs();}
public PreferenceArray mahout_f1621_0(long userID) throws TasteException
{    if (isAnonymousUser(userID)) {        return tempPrefs.get(userID);    }    return getDelegate().getPreferencesFromUser(userID);}
public FastIDSet mahout_f1622_0(long userID) throws TasteException
{    if (isAnonymousUser(userID)) {        return prefItemIDs.get(userID);    }    return getDelegate().getItemIDsFromUser(userID);}
public PreferenceArray mahout_f1623_1(long itemID) throws TasteException
{    if (tempPrefs.isEmpty()) {        return getDelegate().getPreferencesForItem(itemID);    }    PreferenceArray delegatePrefs = null;    try {        delegatePrefs = getDelegate().getPreferencesForItem(itemID);    } catch (NoSuchItemException nsie) {                if (log.isDebugEnabled()) {                    }    }    List<Preference> anonymousPreferences = Lists.newArrayList();    for (Map.Entry<Long, PreferenceArray> prefsMap : tempPrefs.entrySet()) {        PreferenceArray singleUserTempPrefs = prefsMap.getValue();        for (int i = 0; i < singleUserTempPrefs.length(); i++) {            if (singleUserTempPrefs.getItemID(i) == itemID) {                anonymousPreferences.add(singleUserTempPrefs.get(i));            }        }    }    int delegateLength = delegatePrefs == null ? 0 : delegatePrefs.length();    int anonymousPrefsLength = anonymousPreferences.size();    int prefsCounter = 0;        PreferenceArray newPreferenceArray = new GenericItemPreferenceArray(delegateLength + anonymousPrefsLength);    for (int i = 0; i < delegateLength; i++) {        newPreferenceArray.set(prefsCounter++, delegatePrefs.get(i));    }    for (Preference anonymousPreference : anonymousPreferences) {        newPreferenceArray.set(prefsCounter++, anonymousPreference);    }    if (newPreferenceArray.length() == 0) {                throw new NoSuchItemException(itemID);    }    return newPreferenceArray;}
public Float mahout_f1624_0(long userID, long itemID) throws TasteException
{    if (isAnonymousUser(userID)) {        PreferenceArray singleUserTempPrefs = tempPrefs.get(userID);        for (int i = 0; i < singleUserTempPrefs.length(); i++) {            if (singleUserTempPrefs.getItemID(i) == itemID) {                return singleUserTempPrefs.getValue(i);            }        }        return null;    }    return getDelegate().getPreferenceValue(userID, itemID);}
public Long mahout_f1625_0(long userID, long itemID) throws TasteException
{    if (isAnonymousUser(userID)) {                return null;    }    return getDelegate().getPreferenceTime(userID, itemID);}
public int mahout_f1626_0() throws TasteException
{        return getDelegate().getNumUsers();}
public int mahout_f1627_0(long itemID) throws TasteException
{    if (tempPrefs.isEmpty()) {        return getDelegate().getNumUsersWithPreferenceFor(itemID);    }    int countAnonymousUsersWithPreferenceFor = 0;    for (Map.Entry<Long, PreferenceArray> singleUserTempPrefs : tempPrefs.entrySet()) {        for (int i = 0; i < singleUserTempPrefs.getValue().length(); i++) {            if (singleUserTempPrefs.getValue().getItemID(i) == itemID) {                countAnonymousUsersWithPreferenceFor++;                break;            }        }    }    return getDelegate().getNumUsersWithPreferenceFor(itemID) + countAnonymousUsersWithPreferenceFor;}
public int mahout_f1628_0(long itemID1, long itemID2) throws TasteException
{    if (tempPrefs.isEmpty()) {        return getDelegate().getNumUsersWithPreferenceFor(itemID1, itemID2);    }    int countAnonymousUsersWithPreferenceFor = 0;    for (Map.Entry<Long, PreferenceArray> singleUserTempPrefs : tempPrefs.entrySet()) {        boolean found1 = false;        boolean found2 = false;        for (int i = 0; i < singleUserTempPrefs.getValue().length() && !(found1 && found2); i++) {            long itemID = singleUserTempPrefs.getValue().getItemID(i);            if (itemID == itemID1) {                found1 = true;            }            if (itemID == itemID2) {                found2 = true;            }        }        if (found1 && found2) {            countAnonymousUsersWithPreferenceFor++;        }    }    return getDelegate().getNumUsersWithPreferenceFor(itemID1, itemID2) + countAnonymousUsersWithPreferenceFor;}
public void mahout_f1629_0(long userID, long itemID, float value) throws TasteException
{    if (isAnonymousUser(userID)) {        throw new UnsupportedOperationException();    }    getDelegate().setPreference(userID, itemID, value);}
public void mahout_f1630_0(long userID, long itemID) throws TasteException
{    if (isAnonymousUser(userID)) {        throw new UnsupportedOperationException();    }    getDelegate().removePreference(userID, itemID);}
protected DataModel mahout_f1631_0()
{    return delegate;}
public void mahout_f1632_0(PreferenceArray prefs)
{    Preconditions.checkArgument(prefs != null && prefs.length() > 0, "prefs is null or empty");    this.tempPrefs = prefs;    this.prefItemIDs.clear();    for (int i = 0; i < prefs.length(); i++) {        this.prefItemIDs.add(prefs.getItemID(i));    }}
public void mahout_f1633_0()
{    tempPrefs = null;    prefItemIDs.clear();}
public LongPrimitiveIterator mahout_f1634_0() throws TasteException
{    if (tempPrefs == null) {        return delegate.getUserIDs();    }    return new PlusAnonymousUserLongPrimitiveIterator(delegate.getUserIDs(), TEMP_USER_ID);}
public PreferenceArray mahout_f1635_0(long userID) throws TasteException
{    if (userID == TEMP_USER_ID) {        if (tempPrefs == null) {            throw new NoSuchUserException(TEMP_USER_ID);        }        return tempPrefs;    }    return delegate.getPreferencesFromUser(userID);}
public FastIDSet mahout_f1636_0(long userID) throws TasteException
{    if (userID == TEMP_USER_ID) {        if (tempPrefs == null) {            throw new NoSuchUserException(TEMP_USER_ID);        }        return prefItemIDs;    }    return delegate.getItemIDsFromUser(userID);}
public LongPrimitiveIterator mahout_f1637_0() throws TasteException
{    return delegate.getItemIDs();}
public PreferenceArray mahout_f1638_1(long itemID) throws TasteException
{    if (tempPrefs == null) {        return delegate.getPreferencesForItem(itemID);    }    PreferenceArray delegatePrefs = null;    try {        delegatePrefs = delegate.getPreferencesForItem(itemID);    } catch (NoSuchItemException nsie) {                if (log.isDebugEnabled()) {                    }    }    for (int i = 0; i < tempPrefs.length(); i++) {        if (tempPrefs.getItemID(i) == itemID) {            return cloneAndMergeInto(delegatePrefs, itemID, tempPrefs.getUserID(i), tempPrefs.getValue(i));        }    }    if (delegatePrefs == null) {                throw new NoSuchItemException(itemID);    }    return delegatePrefs;}
private static PreferenceArray mahout_f1639_0(PreferenceArray delegatePrefs, long itemID, long newUserID, float value)
{    int length = delegatePrefs == null ? 0 : delegatePrefs.length();    int newLength = length + 1;    PreferenceArray newPreferenceArray = new GenericItemPreferenceArray(newLength);        newPreferenceArray.setItemID(0, itemID);    int positionToInsert = 0;    while (positionToInsert < length && newUserID > delegatePrefs.getUserID(positionToInsert)) {        positionToInsert++;    }    for (int i = 0; i < positionToInsert; i++) {        newPreferenceArray.setUserID(i, delegatePrefs.getUserID(i));        newPreferenceArray.setValue(i, delegatePrefs.getValue(i));    }    newPreferenceArray.setUserID(positionToInsert, newUserID);    newPreferenceArray.setValue(positionToInsert, value);    for (int i = positionToInsert + 1; i < newLength; i++) {        newPreferenceArray.setUserID(i, delegatePrefs.getUserID(i - 1));        newPreferenceArray.setValue(i, delegatePrefs.getValue(i - 1));    }    return newPreferenceArray;}
public Float mahout_f1640_0(long userID, long itemID) throws TasteException
{    if (userID == TEMP_USER_ID) {        if (tempPrefs == null) {            throw new NoSuchUserException(TEMP_USER_ID);        }        for (int i = 0; i < tempPrefs.length(); i++) {            if (tempPrefs.getItemID(i) == itemID) {                return tempPrefs.getValue(i);            }        }        return null;    }    return delegate.getPreferenceValue(userID, itemID);}
public Long mahout_f1641_0(long userID, long itemID) throws TasteException
{    if (userID == TEMP_USER_ID) {        if (tempPrefs == null) {            throw new NoSuchUserException(TEMP_USER_ID);        }        return null;    }    return delegate.getPreferenceTime(userID, itemID);}
public int mahout_f1642_0() throws TasteException
{    return delegate.getNumItems();}
public int mahout_f1643_0() throws TasteException
{    return delegate.getNumUsers() + (tempPrefs == null ? 0 : 1);}
public int mahout_f1644_0(long itemID) throws TasteException
{    if (tempPrefs == null) {        return delegate.getNumUsersWithPreferenceFor(itemID);    }    boolean found = false;    for (int i = 0; i < tempPrefs.length(); i++) {        if (tempPrefs.getItemID(i) == itemID) {            found = true;            break;        }    }    return delegate.getNumUsersWithPreferenceFor(itemID) + (found ? 1 : 0);}
public int mahout_f1645_0(long itemID1, long itemID2) throws TasteException
{    if (tempPrefs == null) {        return delegate.getNumUsersWithPreferenceFor(itemID1, itemID2);    }    boolean found1 = false;    boolean found2 = false;    for (int i = 0; i < tempPrefs.length() && !(found1 && found2); i++) {        long itemID = tempPrefs.getItemID(i);        if (itemID == itemID1) {            found1 = true;        }        if (itemID == itemID2) {            found2 = true;        }    }    return delegate.getNumUsersWithPreferenceFor(itemID1, itemID2) + (found1 && found2 ? 1 : 0);}
public void mahout_f1646_0(long userID, long itemID, float value) throws TasteException
{    if (userID == TEMP_USER_ID) {        if (tempPrefs == null) {            throw new NoSuchUserException(TEMP_USER_ID);        }        throw new UnsupportedOperationException();    }    delegate.setPreference(userID, itemID, value);}
public void mahout_f1647_0(long userID, long itemID) throws TasteException
{    if (userID == TEMP_USER_ID) {        if (tempPrefs == null) {            throw new NoSuchUserException(TEMP_USER_ID);        }        throw new UnsupportedOperationException();    }    delegate.removePreference(userID, itemID);}
public void mahout_f1648_0(Collection<Refreshable> alreadyRefreshed)
{    delegate.refresh(alreadyRefreshed);}
public boolean mahout_f1649_0()
{    return delegate.hasPreferenceValues();}
public float mahout_f1650_0()
{    return delegate.getMaxPreference();}
public float mahout_f1651_0()
{    return delegate.getMinPreference();}
public long mahout_f1652_0()
{    if (datumConsumed) {        return delegate.nextLong();    } else {        if (delegate.hasNext()) {            long delegateNext = delegate.peek();            if (extraDatum <= delegateNext) {                datumConsumed = true;                return extraDatum;            } else {                return delegate.next();            }        } else {            datumConsumed = true;            return extraDatum;        }    }}
public long mahout_f1653_0()
{    if (datumConsumed) {        return delegate.peek();    } else {        if (delegate.hasNext()) {            long delegateNext = delegate.peek();            if (extraDatum <= delegateNext) {                return extraDatum;            } else {                return delegateNext;            }        } else {            return extraDatum;        }    }}
public boolean mahout_f1654_0()
{    return !datumConsumed || delegate.hasNext();}
public void mahout_f1655_0()
{    throw new UnsupportedOperationException();}
public void mahout_f1656_0(int n)
{    for (int i = 0; i < n; i++) {        nextLong();    }}
 final UserSimilarity mahout_f1657_0()
{    return userSimilarity;}
 final DataModel mahout_f1658_0()
{    return dataModel;}
 final double mahout_f1659_0()
{    return samplingRate;}
public final void mahout_f1660_0(Collection<Refreshable> alreadyRefreshed)
{    refreshHelper.refresh(alreadyRefreshed);}
public long[] mahout_f1661_0(long userID) throws TasteException
{    return neighborhoodCache.get(userID);}
public void mahout_f1662_0(Collection<Refreshable> alreadyRefreshed)
{    neighborhoodCache.clear();    Collection<Refreshable> refreshed = RefreshHelper.buildRefreshed(alreadyRefreshed);    RefreshHelper.maybeRefresh(refreshed, neighborhood);}
public long[] mahout_f1663_0(Long key) throws TasteException
{    return neighborhood.getUserNeighborhood(key);}
public long[] mahout_f1664_0(long userID) throws TasteException
{    DataModel dataModel = getDataModel();    UserSimilarity userSimilarityImpl = getUserSimilarity();    TopItems.Estimator<Long> estimator = new Estimator(userSimilarityImpl, userID, minSimilarity);    LongPrimitiveIterator userIDs = SamplingLongPrimitiveIterator.maybeWrapIterator(dataModel.getUserIDs(), getSamplingRate());    return TopItems.getTopUsers(n, userIDs, null, estimator);}
public String mahout_f1665_0()
{    return "NearestNUserNeighborhood";}
public double mahout_f1666_0(Long userID) throws TasteException
{    if (userID == theUserID) {        return Double.NaN;    }    double sim = userSimilarityImpl.userSimilarity(theUserID, userID);    return sim >= minSim ? sim : Double.NaN;}
public long[] mahout_f1667_0(long userID) throws TasteException
{    DataModel dataModel = getDataModel();    FastIDSet neighborhood = new FastIDSet();    LongPrimitiveIterator usersIterable = SamplingLongPrimitiveIterator.maybeWrapIterator(dataModel.getUserIDs(), getSamplingRate());    UserSimilarity userSimilarityImpl = getUserSimilarity();    while (usersIterable.hasNext()) {        long otherUserID = usersIterable.next();        if (userID != otherUserID) {            double theSimilarity = userSimilarityImpl.userSimilarity(userID, otherUserID);            if (!Double.isNaN(theSimilarity) && theSimilarity >= threshold) {                neighborhood.add(otherUserID);            }        }    }    return neighborhood.toArray();}
public String mahout_f1668_0()
{    return "ThresholdUserNeighborhood";}
protected FastIDSet mahout_f1669_0(long[] preferredItemIDs, DataModel dataModel) throws TasteException
{    return doGetCandidateItems(preferredItemIDs, dataModel, false);}
public FastIDSet mahout_f1670_0(long userID, PreferenceArray preferencesFromUser, DataModel dataModel, boolean includeKnownItems) throws TasteException
{    return doGetCandidateItems(preferencesFromUser.getIDs(), dataModel, includeKnownItems);}
public FastIDSet mahout_f1671_0(long[] itemIDs, DataModel dataModel) throws TasteException
{    return doGetCandidateItems(itemIDs, dataModel, false);}
public void mahout_f1672_0(Collection<Refreshable> alreadyRefreshed)
{}
protected static CandidateItemsStrategy mahout_f1673_0()
{    return new PreferredItemsNeighborhoodCandidateItemsStrategy();}
public List<RecommendedItem> mahout_f1674_0(long userID, int howMany) throws TasteException
{    return recommend(userID, howMany, null, false);}
public List<RecommendedItem> mahout_f1675_0(long userID, int howMany, boolean includeKnownItems) throws TasteException
{    return recommend(userID, howMany, null, includeKnownItems);}
public List<RecommendedItem> mahout_f1676_0(long userID, int howMany, IDRescorer rescorer) throws TasteException
{    return recommend(userID, howMany, rescorer, false);}
public void mahout_f1677_1(long userID, long itemID, float value) throws TasteException
{    Preconditions.checkArgument(!Float.isNaN(value), "NaN value");        dataModel.setPreference(userID, itemID, value);}
public void mahout_f1678_1(long userID, long itemID) throws TasteException
{        dataModel.removePreference(userID, itemID);}
public DataModel mahout_f1679_0()
{    return dataModel;}
protected FastIDSet mahout_f1680_0(long userID, PreferenceArray preferencesFromUser, boolean includeKnownItems) throws TasteException
{    return candidateItemsStrategy.getCandidateItems(userID, preferencesFromUser, dataModel, includeKnownItems);}
protected FastIDSet mahout_f1681_0(long[] preferredItemIDs, DataModel dataModel, boolean includeKnownItems) throws TasteException
{    FastIDSet candidateItemIDs = new FastIDSet();    for (long itemID : preferredItemIDs) {        candidateItemIDs.addAll(similarity.allSimilarItemIDs(itemID));    }    if (!includeKnownItems) {        candidateItemIDs.removeAll(preferredItemIDs);    }    return candidateItemIDs;}
protected FastIDSet mahout_f1682_0(long[] preferredItemIDs, DataModel dataModel, boolean includeKnownItems) throws TasteException
{    FastIDSet possibleItemIDs = new FastIDSet(dataModel.getNumItems());    LongPrimitiveIterator allItemIDs = dataModel.getItemIDs();    while (allItemIDs.hasNext()) {        possibleItemIDs.add(allItemIDs.nextLong());    }    if (!includeKnownItems) {        possibleItemIDs.removeAll(preferredItemIDs);    }    return possibleItemIDs;}
public int mahout_f1683_0(RecommendedItem o1, RecommendedItem o2)
{    double rescored1;    double rescored2;    if (rescorer == null) {        rescored1 = o1.getValue();        rescored2 = o2.getValue();    } else {        rescored1 = rescorer.rescore(o1.getItemID(), o1.getValue());        rescored2 = rescorer.rescore(o2.getItemID(), o2.getValue());    }    if (rescored1 < rescored2) {        return 1;    } else if (rescored1 > rescored2) {        return -1;    } else {        return 0;    }}
public String mahout_f1684_0()
{    return "ByRescoreComparator[rescorer:" + rescorer + ']';}
public static Comparator<RecommendedItem> mahout_f1685_0()
{    return INSTANCE;}
public int mahout_f1686_0(RecommendedItem o1, RecommendedItem o2)
{    float value1 = o1.getValue();    float value2 = o2.getValue();    return value1 > value2 ? -1 : value1 < value2 ? 1 : 0;}
public Object mahout_f1687_0()
{    clear();    return null;}
private void mahout_f1688_0(IDRescorer rescorer)
{    if (rescorer == null) {        if (currentRescorer != null) {            currentRescorer = null;            clear();        }    } else {        if (!rescorer.equals(currentRescorer)) {            currentRescorer = rescorer;            clear();        }    }}
public void mahout_f1689_0(boolean currentlyIncludeKnownItems)
{    this.currentlyIncludeKnownItems = currentlyIncludeKnownItems;}
public List<RecommendedItem> mahout_f1690_0(long userID, int howMany) throws TasteException
{    return recommend(userID, howMany, null, false);}
public List<RecommendedItem> mahout_f1691_0(long userID, int howMany, boolean includeKnownItems) throws TasteException
{    return recommend(userID, howMany, null, includeKnownItems);}
public List<RecommendedItem> mahout_f1692_0(long userID, int howMany, IDRescorer rescorer) throws TasteException
{    return recommend(userID, howMany, rescorer, false);}
public List<RecommendedItem> mahout_f1693_0(long userID, int howMany, IDRescorer rescorer, boolean includeKnownItems) throws TasteException
{    Preconditions.checkArgument(howMany >= 1, "howMany must be at least 1");    synchronized (maxHowMany) {        if (howMany > maxHowMany[0]) {            maxHowMany[0] = howMany;        }    }        if (userID == PlusAnonymousUserDataModel.TEMP_USER_ID) {        return recommendationsRetriever.get(PlusAnonymousUserDataModel.TEMP_USER_ID).getItems();    }    setCurrentRescorer(rescorer);    setCurrentlyIncludeKnownItems(includeKnownItems);    Recommendations recommendations = recommendationCache.get(userID);    if (recommendations.getItems().size() < howMany && !recommendations.isNoMoreRecommendableItems()) {        clear(userID);        recommendations = recommendationCache.get(userID);        if (recommendations.getItems().size() < howMany) {            recommendations.setNoMoreRecommendableItems(true);        }    }    List<RecommendedItem> recommendedItems = recommendations.getItems();    return recommendedItems.size() > howMany ? recommendedItems.subList(0, howMany) : recommendedItems;}
public float mahout_f1694_0(long userID, long itemID) throws TasteException
{    return estimatedPrefCache.get(new LongPair(userID, itemID));}
public void mahout_f1695_0(long userID, long itemID, float value) throws TasteException
{    recommender.setPreference(userID, itemID, value);    clear(userID);}
public void mahout_f1696_0(long userID, long itemID) throws TasteException
{    recommender.removePreference(userID, itemID);    clear(userID);}
public DataModel mahout_f1697_0()
{    return recommender.getDataModel();}
public void mahout_f1698_0(Collection<Refreshable> alreadyRefreshed)
{    refreshHelper.refresh(alreadyRefreshed);}
public void mahout_f1699_1(final long userID)
{        recommendationCache.remove(userID);    estimatedPrefCache.removeKeysMatching(new Cache.MatchPredicate<LongPair>() {        @Override        public boolean matches(LongPair userItemPair) {            return userItemPair.getFirst() == userID;        }    });}
public boolean mahout_f1700_0(LongPair userItemPair)
{    return userItemPair.getFirst() == userID;}
public void mahout_f1701_1()
{        recommendationCache.clear();    estimatedPrefCache.clear();}
public String mahout_f1702_0()
{    return "CachingRecommender[recommender:" + recommender + ']';}
public Recommendations mahout_f1703_1(Long key) throws TasteException
{        int howMany = maxHowMany[0];    IDRescorer rescorer = currentRescorer;    List<RecommendedItem> recommendations = rescorer == null ? recommender.recommend(key, howMany, null, currentlyIncludeKnownItems) : recommender.recommend(key, howMany, rescorer, currentlyIncludeKnownItems);    return new Recommendations(Collections.unmodifiableList(recommendations));}
public Float mahout_f1704_1(LongPair key) throws TasteException
{    long userID = key.getFirst();    long itemID = key.getSecond();        return recommender.estimatePreference(userID, itemID);}
 List<RecommendedItem> mahout_f1705_0()
{    return items;}
 boolean mahout_f1706_0()
{    return noMoreRecommendableItems;}
 void mahout_f1707_0(boolean noMoreRecommendableItems)
{    this.noMoreRecommendableItems = noMoreRecommendableItems;}
public float mahout_f1708_0(float estimate)
{    if (estimate > max) {        estimate = max;    } else if (estimate < min) {        estimate = min;    }    return estimate;}
protected float mahout_f1709_0(long userID, PreferenceArray preferencesFromUser, long itemID) throws TasteException
{    double[] similarities = getSimilarity().itemSimilarities(itemID, preferencesFromUser.getIDs());    boolean foundAPref = false;    double totalSimilarity = 0.0;    for (double theSimilarity : similarities) {        if (!Double.isNaN(theSimilarity)) {            foundAPref = true;            totalSimilarity += theSimilarity;        }    }    return foundAPref ? (float) totalSimilarity : Float.NaN;}
public String mahout_f1710_0()
{    return "GenericBooleanPrefItemBasedRecommender";}
protected float mahout_f1711_0(long theUserID, long[] theNeighborhood, long itemID) throws TasteException
{    if (theNeighborhood.length == 0) {        return Float.NaN;    }    DataModel dataModel = getDataModel();    UserSimilarity similarity = getSimilarity();    float totalSimilarity = 0.0f;    boolean foundAPref = false;    for (long userID : theNeighborhood) {                if (userID != theUserID && dataModel.getPreferenceValue(userID, itemID) != null) {            foundAPref = true;            totalSimilarity += (float) similarity.userSimilarity(theUserID, userID);        }    }    return foundAPref ? totalSimilarity : Float.NaN;}
protected FastIDSet mahout_f1712_0(long[] theNeighborhood, long theUserID, boolean includeKnownItems) throws TasteException
{    DataModel dataModel = getDataModel();    FastIDSet possibleItemIDs = new FastIDSet();    for (long userID : theNeighborhood) {        possibleItemIDs.addAll(dataModel.getItemIDsFromUser(userID));    }    if (!includeKnownItems) {        possibleItemIDs.removeAll(dataModel.getItemIDsFromUser(theUserID));    }    return possibleItemIDs;}
public String mahout_f1713_0()
{    return "GenericBooleanPrefUserBasedRecommender";}
public Void mahout_f1714_0()
{    capper = buildCapper();    return null;}
protected static MostSimilarItemsCandidateItemsStrategy mahout_f1715_0()
{    return new PreferredItemsNeighborhoodCandidateItemsStrategy();}
public ItemSimilarity mahout_f1716_0()
{    return similarity;}
public List<RecommendedItem> mahout_f1717_1(long userID, int howMany, IDRescorer rescorer, boolean includeKnownItems) throws TasteException
{    Preconditions.checkArgument(howMany >= 1, "howMany must be at least 1");        PreferenceArray preferencesFromUser = getDataModel().getPreferencesFromUser(userID);    if (preferencesFromUser.length() == 0) {        return Collections.emptyList();    }    FastIDSet possibleItemIDs = getAllOtherItems(userID, preferencesFromUser, includeKnownItems);    TopItems.Estimator<Long> estimator = new Estimator(userID, preferencesFromUser);    List<RecommendedItem> topItems = TopItems.getTopItems(howMany, possibleItemIDs.iterator(), rescorer, estimator);        return topItems;}
public float mahout_f1718_0(long userID, long itemID) throws TasteException
{    PreferenceArray preferencesFromUser = getDataModel().getPreferencesFromUser(userID);    Float actualPref = getPreferenceForItem(preferencesFromUser, itemID);    if (actualPref != null) {        return actualPref;    }    return doEstimatePreference(userID, preferencesFromUser, itemID);}
private static Float mahout_f1719_0(PreferenceArray preferencesFromUser, long itemID)
{    int size = preferencesFromUser.length();    for (int i = 0; i < size; i++) {        if (preferencesFromUser.getItemID(i) == itemID) {            return preferencesFromUser.getValue(i);        }    }    return null;}
public List<RecommendedItem> mahout_f1720_0(long itemID, int howMany) throws TasteException
{    return mostSimilarItems(itemID, howMany, null);}
public List<RecommendedItem> mahout_f1721_0(long itemID, int howMany, Rescorer<LongPair> rescorer) throws TasteException
{    TopItems.Estimator<Long> estimator = new MostSimilarEstimator(itemID, similarity, rescorer);    return doMostSimilarItems(new long[] { itemID }, howMany, estimator);}
public List<RecommendedItem> mahout_f1722_0(long[] itemIDs, int howMany) throws TasteException
{    TopItems.Estimator<Long> estimator = new MultiMostSimilarEstimator(itemIDs, similarity, null, EXCLUDE_ITEM_IF_NOT_SIMILAR_TO_ALL_BY_DEFAULT);    return doMostSimilarItems(itemIDs, howMany, estimator);}
public List<RecommendedItem> mahout_f1723_0(long[] itemIDs, int howMany, Rescorer<LongPair> rescorer) throws TasteException
{    TopItems.Estimator<Long> estimator = new MultiMostSimilarEstimator(itemIDs, similarity, rescorer, EXCLUDE_ITEM_IF_NOT_SIMILAR_TO_ALL_BY_DEFAULT);    return doMostSimilarItems(itemIDs, howMany, estimator);}
public List<RecommendedItem> mahout_f1724_0(long[] itemIDs, int howMany, boolean excludeItemIfNotSimilarToAll) throws TasteException
{    TopItems.Estimator<Long> estimator = new MultiMostSimilarEstimator(itemIDs, similarity, null, excludeItemIfNotSimilarToAll);    return doMostSimilarItems(itemIDs, howMany, estimator);}
public List<RecommendedItem> mahout_f1725_0(long[] itemIDs, int howMany, Rescorer<LongPair> rescorer, boolean excludeItemIfNotSimilarToAll) throws TasteException
{    TopItems.Estimator<Long> estimator = new MultiMostSimilarEstimator(itemIDs, similarity, rescorer, excludeItemIfNotSimilarToAll);    return doMostSimilarItems(itemIDs, howMany, estimator);}
public List<RecommendedItem> mahout_f1726_0(long userID, long itemID, int howMany) throws TasteException
{    Preconditions.checkArgument(howMany >= 1, "howMany must be at least 1");    DataModel model = getDataModel();    TopItems.Estimator<Long> estimator = new RecommendedBecauseEstimator(userID, itemID);    PreferenceArray prefs = model.getPreferencesFromUser(userID);    int size = prefs.length();    FastIDSet allUserItems = new FastIDSet(size);    for (int i = 0; i < size; i++) {        allUserItems.add(prefs.getItemID(i));    }    allUserItems.remove(itemID);    return TopItems.getTopItems(howMany, allUserItems.iterator(), null, estimator);}
private List<RecommendedItem> mahout_f1727_0(long[] itemIDs, int howMany, TopItems.Estimator<Long> estimator) throws TasteException
{    FastIDSet possibleItemIDs = mostSimilarItemsCandidateItemsStrategy.getCandidateItems(itemIDs, getDataModel());    return TopItems.getTopItems(howMany, possibleItemIDs.iterator(), null, estimator);}
protected float mahout_f1728_0(long userID, PreferenceArray preferencesFromUser, long itemID) throws TasteException
{    double preference = 0.0;    double totalSimilarity = 0.0;    int count = 0;    double[] similarities = similarity.itemSimilarities(itemID, preferencesFromUser.getIDs());    for (int i = 0; i < similarities.length; i++) {        double theSimilarity = similarities[i];        if (!Double.isNaN(theSimilarity)) {                        preference += theSimilarity * preferencesFromUser.getValue(i);            totalSimilarity += theSimilarity;            count++;        }    }        if (count <= 1) {        return Float.NaN;    }    float estimate = (float) (preference / totalSimilarity);    if (capper != null) {        estimate = capper.capEstimate(estimate);    }    return estimate;}
public void mahout_f1729_0(Collection<Refreshable> alreadyRefreshed)
{    refreshHelper.refresh(alreadyRefreshed);}
public String mahout_f1730_0()
{    return "GenericItemBasedRecommender[similarity:" + similarity + ']';}
private EstimatedPreferenceCapper mahout_f1731_0()
{    DataModel dataModel = getDataModel();    if (Float.isNaN(dataModel.getMinPreference()) && Float.isNaN(dataModel.getMaxPreference())) {        return null;    } else {        return new EstimatedPreferenceCapper(dataModel);    }}
public double mahout_f1732_0(Long itemID) throws TasteException
{    LongPair pair = new LongPair(toItemID, itemID);    if (rescorer != null && rescorer.isFiltered(pair)) {        return Double.NaN;    }    double originalEstimate = similarity.itemSimilarity(toItemID, itemID);    return rescorer == null ? originalEstimate : rescorer.rescore(pair, originalEstimate);}
public double mahout_f1733_0(Long itemID) throws TasteException
{    return doEstimatePreference(userID, preferencesFromUser, itemID);}
public double mahout_f1734_0(Long itemID) throws TasteException
{    RunningAverage average = new FullRunningAverage();    double[] similarities = similarity.itemSimilarities(itemID, toItemIDs);    for (int i = 0; i < toItemIDs.length; i++) {        long toItemID = toItemIDs[i];        LongPair pair = new LongPair(toItemID, itemID);        if (rescorer != null && rescorer.isFiltered(pair)) {            continue;        }        double estimate = similarities[i];        if (rescorer != null) {            estimate = rescorer.rescore(pair, estimate);        }        if (excludeItemIfNotSimilarToAll || !Double.isNaN(estimate)) {            average.addDatum(estimate);        }    }    double averageEstimate = average.getAverage();    return averageEstimate == 0 ? Double.NaN : averageEstimate;}
public double mahout_f1735_0(Long itemID) throws TasteException
{    Float pref = getDataModel().getPreferenceValue(userID, itemID);    if (pref == null) {        return Float.NaN;    }    double similarityValue = similarity.itemSimilarity(recommendedItemID, itemID);    return (1.0 + similarityValue) * pref;}
public long mahout_f1736_0()
{    return itemID;}
public float mahout_f1737_0()
{    return value;}
public String mahout_f1738_0()
{    return "RecommendedItem[item:" + itemID + ", value:" + value + ']';}
public int mahout_f1739_0()
{    return (int) itemID ^ RandomUtils.hashFloat(value);}
public boolean mahout_f1740_0(Object o)
{    if (!(o instanceof GenericRecommendedItem)) {        return false;    }    RecommendedItem other = (RecommendedItem) o;    return itemID == other.getItemID() && value == other.getValue();}
public Void mahout_f1741_0()
{    capper = buildCapper();    return null;}
public UserSimilarity mahout_f1742_0()
{    return similarity;}
public List<RecommendedItem> mahout_f1743_1(long userID, int howMany, IDRescorer rescorer, boolean includeKnownItems) throws TasteException
{    Preconditions.checkArgument(howMany >= 1, "howMany must be at least 1");        long[] theNeighborhood = neighborhood.getUserNeighborhood(userID);    if (theNeighborhood.length == 0) {        return Collections.emptyList();    }    FastIDSet allItemIDs = getAllOtherItems(theNeighborhood, userID, includeKnownItems);    TopItems.Estimator<Long> estimator = new Estimator(userID, theNeighborhood);    List<RecommendedItem> topItems = TopItems.getTopItems(howMany, allItemIDs.iterator(), rescorer, estimator);        return topItems;}
public float mahout_f1744_0(long userID, long itemID) throws TasteException
{    DataModel model = getDataModel();    Float actualPref = model.getPreferenceValue(userID, itemID);    if (actualPref != null) {        return actualPref;    }    long[] theNeighborhood = neighborhood.getUserNeighborhood(userID);    return doEstimatePreference(userID, theNeighborhood, itemID);}
public long[] mahout_f1745_0(long userID, int howMany) throws TasteException
{    return mostSimilarUserIDs(userID, howMany, null);}
public long[] mahout_f1746_0(long userID, int howMany, Rescorer<LongPair> rescorer) throws TasteException
{    TopItems.Estimator<Long> estimator = new MostSimilarEstimator(userID, similarity, rescorer);    return doMostSimilarUsers(howMany, estimator);}
private long[] mahout_f1747_0(int howMany, TopItems.Estimator<Long> estimator) throws TasteException
{    DataModel model = getDataModel();    return TopItems.getTopUsers(howMany, model.getUserIDs(), null, estimator);}
protected float mahout_f1748_0(long theUserID, long[] theNeighborhood, long itemID) throws TasteException
{    if (theNeighborhood.length == 0) {        return Float.NaN;    }    DataModel dataModel = getDataModel();    double preference = 0.0;    double totalSimilarity = 0.0;    int count = 0;    for (long userID : theNeighborhood) {        if (userID != theUserID) {                        Float pref = dataModel.getPreferenceValue(userID, itemID);            if (pref != null) {                double theSimilarity = similarity.userSimilarity(theUserID, userID);                if (!Double.isNaN(theSimilarity)) {                    preference += theSimilarity * pref;                    totalSimilarity += theSimilarity;                    count++;                }            }        }    }        if (count <= 1) {        return Float.NaN;    }    float estimate = (float) (preference / totalSimilarity);    if (capper != null) {        estimate = capper.capEstimate(estimate);    }    return estimate;}
protected FastIDSet mahout_f1749_0(long[] theNeighborhood, long theUserID, boolean includeKnownItems) throws TasteException
{    DataModel dataModel = getDataModel();    FastIDSet possibleItemIDs = new FastIDSet();    for (long userID : theNeighborhood) {        possibleItemIDs.addAll(dataModel.getItemIDsFromUser(userID));    }    if (!includeKnownItems) {        possibleItemIDs.removeAll(dataModel.getItemIDsFromUser(theUserID));    }    return possibleItemIDs;}
public void mahout_f1750_0(Collection<Refreshable> alreadyRefreshed)
{    refreshHelper.refresh(alreadyRefreshed);}
public String mahout_f1751_0()
{    return "GenericUserBasedRecommender[neighborhood:" + neighborhood + ']';}
private EstimatedPreferenceCapper mahout_f1752_0()
{    DataModel dataModel = getDataModel();    if (Float.isNaN(dataModel.getMinPreference()) && Float.isNaN(dataModel.getMaxPreference())) {        return null;    } else {        return new EstimatedPreferenceCapper(dataModel);    }}
public double mahout_f1753_0(Long userID) throws TasteException
{        if (userID == toUserID) {        return Double.NaN;    }    if (rescorer == null) {        return similarity.userSimilarity(toUserID, userID);    } else {        LongPair pair = new LongPair(toUserID, userID);        if (rescorer.isFiltered(pair)) {            return Double.NaN;        }        double originalEstimate = similarity.userSimilarity(toUserID, userID);        return rescorer.rescore(pair, originalEstimate);    }}
public double mahout_f1754_0(Long itemID) throws TasteException
{    return doEstimatePreference(theUserID, theNeighborhood, itemID);}
public Object mahout_f1755_0() throws TasteException
{    buildAverageDiffs();    return null;}
public List<RecommendedItem> mahout_f1756_1(long userID, int howMany, IDRescorer rescorer, boolean includeKnownItems) throws TasteException
{    Preconditions.checkArgument(howMany >= 1, "howMany must be at least 1");        PreferenceArray preferencesFromUser = getDataModel().getPreferencesFromUser(userID);    FastIDSet possibleItemIDs = getAllOtherItems(userID, preferencesFromUser, includeKnownItems);    TopItems.Estimator<Long> estimator = new Estimator();    List<RecommendedItem> topItems = TopItems.getTopItems(howMany, possibleItemIDs.iterator(), rescorer, estimator);        return topItems;}
public float mahout_f1757_0(long userID, long itemID) throws TasteException
{    DataModel dataModel = getDataModel();    Float actualPref = dataModel.getPreferenceValue(userID, itemID);    if (actualPref != null) {        return actualPref;    }    return doEstimatePreference(itemID);}
private float mahout_f1758_0(long itemID)
{    buildAveragesLock.readLock().lock();    try {        RunningAverage average = itemAverages.get(itemID);        return average == null ? Float.NaN : (float) average.getAverage();    } finally {        buildAveragesLock.readLock().unlock();    }}
private void mahout_f1759_0() throws TasteException
{    try {        buildAveragesLock.writeLock().lock();        DataModel dataModel = getDataModel();        LongPrimitiveIterator it = dataModel.getUserIDs();        while (it.hasNext()) {            PreferenceArray prefs = dataModel.getPreferencesFromUser(it.nextLong());            int size = prefs.length();            for (int i = 0; i < size; i++) {                long itemID = prefs.getItemID(i);                RunningAverage average = itemAverages.get(itemID);                if (average == null) {                    average = new FullRunningAverage();                    itemAverages.put(itemID, average);                }                average.addDatum(prefs.getValue(i));            }        }    } finally {        buildAveragesLock.writeLock().unlock();    }}
public void mahout_f1760_0(long userID, long itemID, float value) throws TasteException
{    DataModel dataModel = getDataModel();    double prefDelta;    try {        Float oldPref = dataModel.getPreferenceValue(userID, itemID);        prefDelta = oldPref == null ? value : value - oldPref;    } catch (NoSuchUserException nsee) {        prefDelta = value;    }    super.setPreference(userID, itemID, value);    try {        buildAveragesLock.writeLock().lock();        RunningAverage average = itemAverages.get(itemID);        if (average == null) {            RunningAverage newAverage = new FullRunningAverage();            newAverage.addDatum(prefDelta);            itemAverages.put(itemID, newAverage);        } else {            average.changeDatum(prefDelta);        }    } finally {        buildAveragesLock.writeLock().unlock();    }}
public void mahout_f1761_0(long userID, long itemID) throws TasteException
{    DataModel dataModel = getDataModel();    Float oldPref = dataModel.getPreferenceValue(userID, itemID);    super.removePreference(userID, itemID);    if (oldPref != null) {        try {            buildAveragesLock.writeLock().lock();            RunningAverage average = itemAverages.get(itemID);            if (average == null) {                throw new IllegalStateException("No preferences exist for item ID: " + itemID);            } else {                average.removeDatum(oldPref);            }        } finally {            buildAveragesLock.writeLock().unlock();        }    }}
public void mahout_f1762_0(Collection<Refreshable> alreadyRefreshed)
{    refreshHelper.refresh(alreadyRefreshed);}
public String mahout_f1763_0()
{    return "ItemAverageRecommender";}
public double mahout_f1764_0(Long itemID)
{    return doEstimatePreference(itemID);}
public Object mahout_f1765_0() throws TasteException
{    buildAverageDiffs();    return null;}
public List<RecommendedItem> mahout_f1766_1(long userID, int howMany, IDRescorer rescorer, boolean includeKnownItems) throws TasteException
{    Preconditions.checkArgument(howMany >= 1, "howMany must be at least 1");        PreferenceArray preferencesFromUser = getDataModel().getPreferencesFromUser(userID);    FastIDSet possibleItemIDs = getAllOtherItems(userID, preferencesFromUser, includeKnownItems);    TopItems.Estimator<Long> estimator = new Estimator(userID);    List<RecommendedItem> topItems = TopItems.getTopItems(howMany, possibleItemIDs.iterator(), rescorer, estimator);        return topItems;}
public float mahout_f1767_0(long userID, long itemID) throws TasteException
{    DataModel dataModel = getDataModel();    Float actualPref = dataModel.getPreferenceValue(userID, itemID);    if (actualPref != null) {        return actualPref;    }    return doEstimatePreference(userID, itemID);}
private float mahout_f1768_0(long userID, long itemID)
{    buildAveragesLock.readLock().lock();    try {        RunningAverage itemAverage = itemAverages.get(itemID);        if (itemAverage == null) {            return Float.NaN;        }        RunningAverage userAverage = userAverages.get(userID);        if (userAverage == null) {            return Float.NaN;        }        double userDiff = userAverage.getAverage() - overallAveragePrefValue.getAverage();        return (float) (itemAverage.getAverage() + userDiff);    } finally {        buildAveragesLock.readLock().unlock();    }}
private void mahout_f1769_0() throws TasteException
{    try {        buildAveragesLock.writeLock().lock();        DataModel dataModel = getDataModel();        LongPrimitiveIterator it = dataModel.getUserIDs();        while (it.hasNext()) {            long userID = it.nextLong();            PreferenceArray prefs = dataModel.getPreferencesFromUser(userID);            int size = prefs.length();            for (int i = 0; i < size; i++) {                long itemID = prefs.getItemID(i);                float value = prefs.getValue(i);                addDatumAndCreateIfNeeded(itemID, value, itemAverages);                addDatumAndCreateIfNeeded(userID, value, userAverages);                overallAveragePrefValue.addDatum(value);            }        }    } finally {        buildAveragesLock.writeLock().unlock();    }}
private static void mahout_f1770_0(long itemID, float value, FastByIDMap<RunningAverage> averages)
{    RunningAverage itemAverage = averages.get(itemID);    if (itemAverage == null) {        itemAverage = new FullRunningAverage();        averages.put(itemID, itemAverage);    }    itemAverage.addDatum(value);}
public void mahout_f1771_0(long userID, long itemID, float value) throws TasteException
{    DataModel dataModel = getDataModel();    double prefDelta;    try {        Float oldPref = dataModel.getPreferenceValue(userID, itemID);        prefDelta = oldPref == null ? value : value - oldPref;    } catch (NoSuchUserException nsee) {        prefDelta = value;    }    super.setPreference(userID, itemID, value);    try {        buildAveragesLock.writeLock().lock();        RunningAverage itemAverage = itemAverages.get(itemID);        if (itemAverage == null) {            RunningAverage newItemAverage = new FullRunningAverage();            newItemAverage.addDatum(prefDelta);            itemAverages.put(itemID, newItemAverage);        } else {            itemAverage.changeDatum(prefDelta);        }        RunningAverage userAverage = userAverages.get(userID);        if (userAverage == null) {            RunningAverage newUserAveragae = new FullRunningAverage();            newUserAveragae.addDatum(prefDelta);            userAverages.put(userID, newUserAveragae);        } else {            userAverage.changeDatum(prefDelta);        }        overallAveragePrefValue.changeDatum(prefDelta);    } finally {        buildAveragesLock.writeLock().unlock();    }}
public void mahout_f1772_0(long userID, long itemID) throws TasteException
{    DataModel dataModel = getDataModel();    Float oldPref = dataModel.getPreferenceValue(userID, itemID);    super.removePreference(userID, itemID);    if (oldPref != null) {        try {            buildAveragesLock.writeLock().lock();            RunningAverage itemAverage = itemAverages.get(itemID);            if (itemAverage == null) {                throw new IllegalStateException("No preferences exist for item ID: " + itemID);            }            itemAverage.removeDatum(oldPref);            RunningAverage userAverage = userAverages.get(userID);            if (userAverage == null) {                throw new IllegalStateException("No preferences exist for user ID: " + userID);            }            userAverage.removeDatum(oldPref);            overallAveragePrefValue.removeDatum(oldPref);        } finally {            buildAveragesLock.writeLock().unlock();        }    }}
public void mahout_f1773_0(Collection<Refreshable> alreadyRefreshed)
{    refreshHelper.refresh(alreadyRefreshed);}
public String mahout_f1774_0()
{    return "ItemUserAverageRecommender";}
public double mahout_f1775_0(Long itemID)
{    return doEstimatePreference(userID, itemID);}
public static IDRescorer mahout_f1776_0()
{    return USER_OR_ITEM_INSTANCE;}
public static IDRescorer mahout_f1777_0()
{    return USER_OR_ITEM_INSTANCE;}
public static Rescorer<LongPair> mahout_f1778_0()
{    return ITEM_ITEM_PAIR_INSTANCE;}
public static Rescorer<LongPair> mahout_f1779_0()
{    return USER_USER_PAIR_INSTANCE;}
public double mahout_f1780_0(T thing, double originalScore)
{    return originalScore;}
public boolean mahout_f1781_0(T thing)
{    return false;}
public double mahout_f1782_0(long id, double originalScore)
{    return originalScore;}
public boolean mahout_f1783_0(long id)
{    return false;}
public String mahout_f1784_0()
{    return "NullRescorer";}
protected FastIDSet mahout_f1785_0(long[] preferredItemIDs, DataModel dataModel, boolean includeKnownItems) throws TasteException
{    FastIDSet possibleItemsIDs = new FastIDSet();    for (long itemID : preferredItemIDs) {        PreferenceArray itemPreferences = dataModel.getPreferencesForItem(itemID);        int numUsersPreferringItem = itemPreferences.length();        for (int index = 0; index < numUsersPreferringItem; index++) {            possibleItemsIDs.addAll(dataModel.getItemIDsFromUser(itemPreferences.getUserID(index)));        }    }    if (!includeKnownItems) {        possibleItemsIDs.removeAll(preferredItemIDs);    }    return possibleItemsIDs;}
public List<RecommendedItem> mahout_f1786_0(long userID, int howMany, IDRescorer rescorer, boolean includeKnownItems) throws TasteException
{    DataModel dataModel = getDataModel();    int numItems = dataModel.getNumItems();    List<RecommendedItem> result = new ArrayList<>(howMany);    while (result.size() < howMany) {        LongPrimitiveIterator it = dataModel.getItemIDs();        it.skip(random.nextInt(numItems));        long itemID = it.next();        if (includeKnownItems || dataModel.getPreferenceValue(userID, itemID) == null) {            result.add(new GenericRecommendedItem(itemID, randomPref()));        }    }    return result;}
public float mahout_f1787_0(long userID, long itemID)
{    return randomPref();}
private float mahout_f1788_0()
{    return minPref + random.nextFloat() * (maxPref - minPref);}
public void mahout_f1789_0(Collection<Refreshable> alreadyRefreshed)
{    getDataModel().refresh(alreadyRefreshed);}
private static int mahout_f1790_0(int factor, int numThings)
{    if (factor == NO_LIMIT_FACTOR) {        return MAX_LIMIT;    }    long max = (long) (factor * (1.0 + Math.log(numThings) / LOG2));    return max > MAX_LIMIT ? MAX_LIMIT : (int) max;}
protected FastIDSet mahout_f1791_0(long[] preferredItemIDs, DataModel dataModel, boolean includeKnownItems) throws TasteException
{    LongPrimitiveIterator preferredItemIDsIterator = new LongPrimitiveArrayIterator(preferredItemIDs);    if (preferredItemIDs.length > maxItems) {        double samplingRate = (double) maxItems / preferredItemIDs.length;                preferredItemIDsIterator = new SamplingLongPrimitiveIterator(preferredItemIDsIterator, samplingRate);    }    FastIDSet possibleItemsIDs = new FastIDSet();    while (preferredItemIDsIterator.hasNext()) {        long itemID = preferredItemIDsIterator.nextLong();        PreferenceArray prefs = dataModel.getPreferencesForItem(itemID);        int prefsLength = prefs.length();        if (prefsLength > maxUsersPerItem) {            Iterator<Preference> sampledPrefs = new FixedSizeSamplingIterator<>(maxUsersPerItem, prefs.iterator());            while (sampledPrefs.hasNext()) {                addSomeOf(possibleItemsIDs, dataModel.getItemIDsFromUser(sampledPrefs.next().getUserID()));            }        } else {            for (int i = 0; i < prefsLength; i++) {                addSomeOf(possibleItemsIDs, dataModel.getItemIDsFromUser(prefs.getUserID(i)));            }        }    }    if (!includeKnownItems) {        possibleItemsIDs.removeAll(preferredItemIDs);    }    return possibleItemsIDs;}
private void mahout_f1792_0(FastIDSet possibleItemIDs, FastIDSet itemIDs)
{    if (itemIDs.size() > maxItemsPerUser) {        LongPrimitiveIterator it = new SamplingLongPrimitiveIterator(itemIDs.iterator(), (double) maxItemsPerUser / itemIDs.size());        while (it.hasNext()) {            possibleItemIDs.add(it.nextLong());        }    } else {        possibleItemIDs.addAll(itemIDs);    }}
 long mahout_f1793_0()
{    return userID;}
 double mahout_f1794_0()
{    return similarity;}
public int mahout_f1795_0()
{    return (int) userID ^ RandomUtils.hashDouble(similarity);}
public boolean mahout_f1796_0(Object o)
{    if (!(o instanceof SimilarUser)) {        return false;    }    SimilarUser other = (SimilarUser) o;    return userID == other.getUserID() && similarity == other.getSimilarity();}
public String mahout_f1797_0()
{    return "SimilarUser[user:" + userID + ", similarity:" + similarity + ']';}
public int mahout_f1798_0(SimilarUser other)
{    double otherSimilarity = other.getSimilarity();    if (similarity > otherSimilarity) {        return -1;    }    if (similarity < otherSimilarity) {        return 1;    }    long otherUserID = other.getUserID();    if (userID < otherUserID) {        return -1;    }    if (userID > otherUserID) {        return 1;    }    return 0;}
public Object mahout_f1799_0() throws TasteException
{    buildMappings();    return null;}
private void mahout_f1800_0() throws TasteException
{    userIDMapping = createIDMapping(dataModel.getNumUsers(), dataModel.getUserIDs());    itemIDMapping = createIDMapping(dataModel.getNumItems(), dataModel.getItemIDs());}
protected Factorization mahout_f1801_0(double[][] userFeatures, double[][] itemFeatures)
{    return new Factorization(userIDMapping, itemIDMapping, userFeatures, itemFeatures);}
protected Integer mahout_f1802_0(long userID)
{    Integer userIndex = userIDMapping.get(userID);    if (userIndex == null) {        userIndex = userIDMapping.size();        userIDMapping.put(userID, userIndex);    }    return userIndex;}
protected Integer mahout_f1803_0(long itemID)
{    Integer itemIndex = itemIDMapping.get(itemID);    if (itemIndex == null) {        itemIndex = itemIDMapping.size();        itemIDMapping.put(itemID, itemIndex);    }    return itemIndex;}
private static FastByIDMap<Integer> mahout_f1804_0(int size, LongPrimitiveIterator idIterator)
{    FastByIDMap<Integer> mapping = new FastByIDMap<>(size);    int index = 0;    while (idIterator.hasNext()) {        mapping.put(idIterator.nextLong(), index++);    }    return mapping;}
public void mahout_f1805_0(Collection<Refreshable> alreadyRefreshed)
{    refreshHelper.refresh(alreadyRefreshed);}
 double[][] mahout_f1806_0()
{    return M;}
 double[][] mahout_f1807_0()
{    return U;}
 Vector mahout_f1808_0(int index)
{    return new DenseVector(U[index]);}
 Vector mahout_f1809_0(int index)
{    return new DenseVector(M[index]);}
 void mahout_f1810_0(int idIndex, Vector vector)
{    setFeatureColumn(U, idIndex, vector);}
 void mahout_f1811_0(int idIndex, Vector vector)
{    setFeatureColumn(M, idIndex, vector);}
protected void mahout_f1812_0(double[][] matrix, int idIndex, Vector vector)
{    for (int feature = 0; feature < numFeatures; feature++) {        matrix[idIndex][feature] = vector.get(feature);    }}
protected double mahout_f1813_0(long itemID) throws TasteException
{    PreferenceArray prefs = dataModel.getPreferencesForItem(itemID);    RunningAverage avg = new FullRunningAverage();    for (Preference pref : prefs) {        avg.addDatum(pref.getValue());    }    return avg.getAverage();}
public Factorization mahout_f1814_1() throws TasteException
{        final Features features = new Features(this);    /* feature maps necessary for solving for implicit feedback */    OpenIntObjectHashMap<Vector> userY = null;    OpenIntObjectHashMap<Vector> itemY = null;    if (usesImplicitFeedback) {        userY = userFeaturesMapping(dataModel.getUserIDs(), dataModel.getNumUsers(), features.getU());        itemY = itemFeaturesMapping(dataModel.getItemIDs(), dataModel.getNumItems(), features.getM());    }    for (int iteration = 0; iteration < numIterations; iteration++) {                /* fix M - compute U */        ExecutorService queue = createQueue();        LongPrimitiveIterator userIDsIterator = dataModel.getUserIDs();        try {            final ImplicitFeedbackAlternatingLeastSquaresSolver implicitFeedbackSolver = usesImplicitFeedback ? new ImplicitFeedbackAlternatingLeastSquaresSolver(numFeatures, lambda, alpha, itemY, numTrainingThreads) : null;            while (userIDsIterator.hasNext()) {                final long userID = userIDsIterator.nextLong();                final LongPrimitiveIterator itemIDsFromUser = dataModel.getItemIDsFromUser(userID).iterator();                final PreferenceArray userPrefs = dataModel.getPreferencesFromUser(userID);                queue.execute(new Runnable() {                    @Override                    public void run() {                        List<Vector> featureVectors = new ArrayList<>();                        while (itemIDsFromUser.hasNext()) {                            long itemID = itemIDsFromUser.nextLong();                            featureVectors.add(features.getItemFeatureColumn(itemIndex(itemID)));                        }                        Vector userFeatures = usesImplicitFeedback ? implicitFeedbackSolver.solve(sparseUserRatingVector(userPrefs)) : AlternatingLeastSquaresSolver.solve(featureVectors, ratingVector(userPrefs), lambda, numFeatures);                        features.setFeatureColumnInU(userIndex(userID), userFeatures);                    }                });            }        } finally {            queue.shutdown();            try {                queue.awaitTermination(dataModel.getNumUsers(), TimeUnit.SECONDS);            } catch (InterruptedException e) {                            }        }        /* fix U - compute M */        queue = createQueue();        LongPrimitiveIterator itemIDsIterator = dataModel.getItemIDs();        try {            final ImplicitFeedbackAlternatingLeastSquaresSolver implicitFeedbackSolver = usesImplicitFeedback ? new ImplicitFeedbackAlternatingLeastSquaresSolver(numFeatures, lambda, alpha, userY, numTrainingThreads) : null;            while (itemIDsIterator.hasNext()) {                final long itemID = itemIDsIterator.nextLong();                final PreferenceArray itemPrefs = dataModel.getPreferencesForItem(itemID);                queue.execute(new Runnable() {                    @Override                    public void run() {                        List<Vector> featureVectors = new ArrayList<>();                        for (Preference pref : itemPrefs) {                            long userID = pref.getUserID();                            featureVectors.add(features.getUserFeatureColumn(userIndex(userID)));                        }                        Vector itemFeatures = usesImplicitFeedback ? implicitFeedbackSolver.solve(sparseItemRatingVector(itemPrefs)) : AlternatingLeastSquaresSolver.solve(featureVectors, ratingVector(itemPrefs), lambda, numFeatures);                        features.setFeatureColumnInM(itemIndex(itemID), itemFeatures);                    }                });            }        } finally {            queue.shutdown();            try {                queue.awaitTermination(dataModel.getNumItems(), TimeUnit.SECONDS);            } catch (InterruptedException e) {                            }        }    }        return createFactorization(features.getU(), features.getM());}
public void mahout_f1815_0()
{    List<Vector> featureVectors = new ArrayList<>();    while (itemIDsFromUser.hasNext()) {        long itemID = itemIDsFromUser.nextLong();        featureVectors.add(features.getItemFeatureColumn(itemIndex(itemID)));    }    Vector userFeatures = usesImplicitFeedback ? implicitFeedbackSolver.solve(sparseUserRatingVector(userPrefs)) : AlternatingLeastSquaresSolver.solve(featureVectors, ratingVector(userPrefs), lambda, numFeatures);    features.setFeatureColumnInU(userIndex(userID), userFeatures);}
public void mahout_f1816_0()
{    List<Vector> featureVectors = new ArrayList<>();    for (Preference pref : itemPrefs) {        long userID = pref.getUserID();        featureVectors.add(features.getUserFeatureColumn(userIndex(userID)));    }    Vector itemFeatures = usesImplicitFeedback ? implicitFeedbackSolver.solve(sparseItemRatingVector(itemPrefs)) : AlternatingLeastSquaresSolver.solve(featureVectors, ratingVector(itemPrefs), lambda, numFeatures);    features.setFeatureColumnInM(itemIndex(itemID), itemFeatures);}
protected ExecutorService mahout_f1817_0()
{    return Executors.newFixedThreadPool(numTrainingThreads);}
protected static Vector mahout_f1818_0(PreferenceArray prefs)
{    double[] ratings = new double[prefs.length()];    for (int n = 0; n < prefs.length(); n++) {        ratings[n] = prefs.get(n).getValue();    }    return new DenseVector(ratings, true);}
protected OpenIntObjectHashMap<Vector> mahout_f1819_0(LongPrimitiveIterator itemIDs, int numItems, double[][] featureMatrix)
{    OpenIntObjectHashMap<Vector> mapping = new OpenIntObjectHashMap<>(numItems);    while (itemIDs.hasNext()) {        long itemID = itemIDs.next();        int itemIndex = itemIndex(itemID);        mapping.put(itemIndex, new DenseVector(featureMatrix[itemIndex(itemID)], true));    }    return mapping;}
protected OpenIntObjectHashMap<Vector> mahout_f1820_0(LongPrimitiveIterator userIDs, int numUsers, double[][] featureMatrix)
{    OpenIntObjectHashMap<Vector> mapping = new OpenIntObjectHashMap<>(numUsers);    while (userIDs.hasNext()) {        long userID = userIDs.next();        int userIndex = userIndex(userID);        mapping.put(userIndex, new DenseVector(featureMatrix[userIndex(userID)], true));    }    return mapping;}
protected Vector mahout_f1821_0(PreferenceArray prefs)
{    SequentialAccessSparseVector ratings = new SequentialAccessSparseVector(Integer.MAX_VALUE, prefs.length());    for (Preference preference : prefs) {        ratings.set(userIndex(preference.getUserID()), preference.getValue());    }    return ratings;}
protected Vector mahout_f1822_0(PreferenceArray prefs)
{    SequentialAccessSparseVector ratings = new SequentialAccessSparseVector(Integer.MAX_VALUE, prefs.length());    for (Preference preference : prefs) {        ratings.set(itemIndex(preference.getItemID()), preference.getValue());    }    return ratings;}
public double[][] mahout_f1823_0()
{    return userFeatures;}
public double[] mahout_f1824_0(long userID) throws NoSuchUserException
{    Integer index = userIDMapping.get(userID);    if (index == null) {        throw new NoSuchUserException(userID);    }    return userFeatures[index];}
public double[][] mahout_f1825_0()
{    return itemFeatures;}
public double[] mahout_f1826_0(long itemID) throws NoSuchItemException
{    Integer index = itemIDMapping.get(itemID);    if (index == null) {        throw new NoSuchItemException(itemID);    }    return itemFeatures[index];}
public int mahout_f1827_0(long userID) throws NoSuchUserException
{    Integer index = userIDMapping.get(userID);    if (index == null) {        throw new NoSuchUserException(userID);    }    return index;}
public Iterable<Map.Entry<Long, Integer>> mahout_f1828_0()
{    return userIDMapping.entrySet();}
public LongPrimitiveIterator mahout_f1829_0()
{    return userIDMapping.keySetIterator();}
public int mahout_f1830_0(long itemID) throws NoSuchItemException
{    Integer index = itemIDMapping.get(itemID);    if (index == null) {        throw new NoSuchItemException(itemID);    }    return index;}
public Iterable<Map.Entry<Long, Integer>> mahout_f1831_0()
{    return itemIDMapping.entrySet();}
public LongPrimitiveIterator mahout_f1832_0()
{    return itemIDMapping.keySetIterator();}
public int mahout_f1833_0()
{    return userFeatures.length > 0 ? userFeatures[0].length : 0;}
public int mahout_f1834_0()
{    return userIDMapping.size();}
public int mahout_f1835_0()
{    return itemIDMapping.size();}
public boolean mahout_f1836_0(Object o)
{    if (o instanceof Factorization) {        Factorization other = (Factorization) o;        return userIDMapping.equals(other.userIDMapping) && itemIDMapping.equals(other.itemIDMapping) && Arrays.deepEquals(userFeatures, other.userFeatures) && Arrays.deepEquals(itemFeatures, other.itemFeatures);    }    return false;}
public int mahout_f1837_0()
{    int hashCode = 31 * userIDMapping.hashCode() + itemIDMapping.hashCode();    hashCode = 31 * hashCode + Arrays.deepHashCode(userFeatures);    hashCode = 31 * hashCode + Arrays.deepHashCode(itemFeatures);    return hashCode;}
public Factorization mahout_f1838_1() throws IOException
{    if (!file.exists()) {                return null;    }    try (DataInputStream in = new DataInputStream(new BufferedInputStream(new FileInputStream(file)))) {                return readBinary(in);    }}
public void mahout_f1839_1(Factorization factorization) throws IOException
{    try (DataOutputStream out = new DataOutputStream(new BufferedOutputStream(new FileOutputStream(file)))) {                writeBinary(factorization, out);    }}
protected static void mahout_f1840_0(Factorization factorization, DataOutput out) throws IOException
{    out.writeInt(factorization.numFeatures());    out.writeInt(factorization.numUsers());    out.writeInt(factorization.numItems());    for (Map.Entry<Long, Integer> mappingEntry : factorization.getUserIDMappings()) {        long userID = mappingEntry.getKey();        out.writeInt(mappingEntry.getValue());        out.writeLong(userID);        try {            double[] userFeatures = factorization.getUserFeatures(userID);            for (int feature = 0; feature < factorization.numFeatures(); feature++) {                out.writeDouble(userFeatures[feature]);            }        } catch (NoSuchUserException e) {            throw new IOException("Unable to persist factorization", e);        }    }    for (Map.Entry<Long, Integer> entry : factorization.getItemIDMappings()) {        long itemID = entry.getKey();        out.writeInt(entry.getValue());        out.writeLong(itemID);        try {            double[] itemFeatures = factorization.getItemFeatures(itemID);            for (int feature = 0; feature < factorization.numFeatures(); feature++) {                out.writeDouble(itemFeatures[feature]);            }        } catch (NoSuchItemException e) {            throw new IOException("Unable to persist factorization", e);        }    }}
public static Factorization mahout_f1841_0(DataInput in) throws IOException
{    int numFeatures = in.readInt();    int numUsers = in.readInt();    int numItems = in.readInt();    FastByIDMap<Integer> userIDMapping = new FastByIDMap<>(numUsers);    double[][] userFeatures = new double[numUsers][numFeatures];    for (int n = 0; n < numUsers; n++) {        int userIndex = in.readInt();        long userID = in.readLong();        userIDMapping.put(userID, userIndex);        for (int feature = 0; feature < numFeatures; feature++) {            userFeatures[userIndex][feature] = in.readDouble();        }    }    FastByIDMap<Integer> itemIDMapping = new FastByIDMap<>(numItems);    double[][] itemFeatures = new double[numItems][numFeatures];    for (int n = 0; n < numItems; n++) {        int itemIndex = in.readInt();        long itemID = in.readLong();        itemIDMapping.put(itemID, itemIndex);        for (int feature = 0; feature < numFeatures; feature++) {            itemFeatures[itemIndex][feature] = in.readDouble();        }    }    return new Factorization(userIDMapping, itemIDMapping, userFeatures, itemFeatures);}
public Factorization mahout_f1842_0() throws IOException
{    return null;}
public void mahout_f1843_0(Factorization factorization) throws IOException
{}
private int mahout_f1844_0(DataModel dataModel) throws TasteException
{    int numPreferences = 0;    LongPrimitiveIterator userIDs = dataModel.getUserIDs();    while (userIDs.hasNext()) {        PreferenceArray preferencesFromUser = dataModel.getPreferencesFromUser(userIDs.nextLong());        numPreferences += preferencesFromUser.length();    }    return numPreferences;}
private void mahout_f1845_0(DataModel dataModel) throws TasteException
{    int numPreferences = countPreferences(dataModel);    preferences = new Preference[numPreferences];    LongPrimitiveIterator userIDs = dataModel.getUserIDs();    int index = 0;    while (userIDs.hasNext()) {        long userID = userIDs.nextLong();        PreferenceArray preferencesFromUser = dataModel.getPreferencesFromUser(userID);        for (Preference preference : preferencesFromUser) {            preferences[index++] = preference;        }    }}
public final void mahout_f1846_0()
{    unstagedPreferences = preferences.clone();    /* Durstenfeld shuffle */    for (int i = unstagedPreferences.length - 1; i > 0; i--) {        int rand = random.nextInt(i + 1);        swapCachedPreferences(i, rand);    }}
private void mahout_f1847_0(int x, int y)
{    Preference p = unstagedPreferences[x];    unstagedPreferences[x] = unstagedPreferences[y];    unstagedPreferences[y] = p;}
public final void mahout_f1848_0()
{    preferences = unstagedPreferences;}
public Preference mahout_f1849_0(int i)
{    return preferences[i];}
public int mahout_f1850_0()
{    return preferences.length;}
protected void mahout_f1851_0() throws TasteException
{    RandomWrapper random = RandomUtils.getRandom();    userVectors = new double[dataModel.getNumUsers()][rank];    itemVectors = new double[dataModel.getNumItems()][rank];    double globalAverage = getAveragePreference();    for (int userIndex = 0; userIndex < userVectors.length; userIndex++) {        userVectors[userIndex][0] = globalAverage;                userVectors[userIndex][USER_BIAS_INDEX] = 0;                userVectors[userIndex][ITEM_BIAS_INDEX] = 1;        for (int feature = FEATURE_OFFSET; feature < rank; feature++) {            userVectors[userIndex][feature] = random.nextGaussian() * NOISE;        }    }    for (int itemIndex = 0; itemIndex < itemVectors.length; itemIndex++) {                itemVectors[itemIndex][0] = 1;                itemVectors[itemIndex][USER_BIAS_INDEX] = 1;                itemVectors[itemIndex][ITEM_BIAS_INDEX] = 0;        for (int feature = FEATURE_OFFSET; feature < rank; feature++) {            itemVectors[itemIndex][feature] = random.nextGaussian() * NOISE;        }    }}
private double mahout_f1852_0(int i)
{    return mu0 * Math.pow(decayFactor, i - 1) * Math.pow(i + stepOffset, forgettingExponent);}
public Factorization mahout_f1853_1() throws TasteException
{    initialize();    if (logger.isInfoEnabled()) {            }    for (epoch = 1; epoch <= numEpochs; epoch++) {        shuffler.stage();        final double mu = getMu(epoch);        int subSize = shuffler.size() / numThreads + 1;        ExecutorService executor = Executors.newFixedThreadPool(numThreads);        try {            for (int t = 0; t < numThreads; t++) {                final int iStart = t * subSize;                final int iEnd = Math.min((t + 1) * subSize, shuffler.size());                executor.execute(new Runnable() {                    @Override                    public void run() {                        for (int i = iStart; i < iEnd; i++) {                            update(shuffler.get(i), mu);                        }                    }                });            }        } finally {            executor.shutdown();            shuffler.shuffle();            try {                boolean terminated = executor.awaitTermination(numEpochs * shuffler.size(), TimeUnit.MICROSECONDS);                if (!terminated) {                                    }            } catch (InterruptedException e) {                throw new TasteException("waiting fof termination interrupted", e);            }        }    }    return createFactorization(userVectors, itemVectors);}
public void mahout_f1854_0()
{    for (int i = iStart; i < iEnd; i++) {        update(shuffler.get(i), mu);    }}
 double mahout_f1855_0() throws TasteException
{    RunningAverage average = new FullRunningAverage();    LongPrimitiveIterator it = dataModel.getUserIDs();    while (it.hasNext()) {        for (Preference pref : dataModel.getPreferencesFromUser(it.nextLong())) {            average.addDatum(pref.getValue());        }    }    return average.getAverage();}
protected void mahout_f1856_0(Preference preference, double mu)
{    int userIndex = userIndex(preference.getUserID());    int itemIndex = itemIndex(preference.getItemID());    double[] userVector = userVectors[userIndex];    double[] itemVector = itemVectors[itemIndex];    double prediction = dot(userVector, itemVector);    double err = preference.getValue() - prediction;        for (int k = FEATURE_OFFSET; k < rank; k++) {        double userFeature = userVector[k];        double itemFeature = itemVector[k];        userVector[k] += mu * (err * itemFeature - lambda * userFeature);        itemVector[k] += mu * (err * userFeature - lambda * itemFeature);    }        userVector[USER_BIAS_INDEX] += biasMuRatio * mu * (err - biasLambdaRatio * lambda * userVector[USER_BIAS_INDEX]);    itemVector[ITEM_BIAS_INDEX] += biasMuRatio * mu * (err - biasLambdaRatio * lambda * itemVector[ITEM_BIAS_INDEX]);}
private double mahout_f1857_0(double[] userVector, double[] itemVector)
{    double sum = 0;    for (int k = 0; k < rank; k++) {        sum += userVector[k] * itemVector[k];    }    return sum;}
protected void mahout_f1858_0() throws TasteException
{    RandomWrapper random = RandomUtils.getRandom();    userVectors = new double[dataModel.getNumUsers()][numFeatures];    itemVectors = new double[dataModel.getNumItems()][numFeatures];    double globalAverage = getAveragePreference();    for (int userIndex = 0; userIndex < userVectors.length; userIndex++) {        userVectors[userIndex][0] = globalAverage;                userVectors[userIndex][USER_BIAS_INDEX] = 0;                userVectors[userIndex][ITEM_BIAS_INDEX] = 1;        for (int feature = FEATURE_OFFSET; feature < numFeatures; feature++) {            userVectors[userIndex][feature] = random.nextGaussian() * randomNoise;        }    }    for (int itemIndex = 0; itemIndex < itemVectors.length; itemIndex++) {                itemVectors[itemIndex][0] = 1;                itemVectors[itemIndex][USER_BIAS_INDEX] = 1;                itemVectors[itemIndex][ITEM_BIAS_INDEX] = 0;        for (int feature = FEATURE_OFFSET; feature < numFeatures; feature++) {            itemVectors[itemIndex][feature] = random.nextGaussian() * randomNoise;        }    }    cachePreferences();    shufflePreferences();}
private int mahout_f1859_0() throws TasteException
{    int numPreferences = 0;    LongPrimitiveIterator userIDs = dataModel.getUserIDs();    while (userIDs.hasNext()) {        PreferenceArray preferencesFromUser = dataModel.getPreferencesFromUser(userIDs.nextLong());        numPreferences += preferencesFromUser.length();    }    return numPreferences;}
private void mahout_f1860_0() throws TasteException
{    int numPreferences = countPreferences();    cachedUserIDs = new long[numPreferences];    cachedItemIDs = new long[numPreferences];    LongPrimitiveIterator userIDs = dataModel.getUserIDs();    int index = 0;    while (userIDs.hasNext()) {        long userID = userIDs.nextLong();        PreferenceArray preferencesFromUser = dataModel.getPreferencesFromUser(userID);        for (Preference preference : preferencesFromUser) {            cachedUserIDs[index] = userID;            cachedItemIDs[index] = preference.getItemID();            index++;        }    }}
protected void mahout_f1861_0()
{    RandomWrapper random = RandomUtils.getRandom();    /* Durstenfeld shuffle */    for (int currentPos = cachedUserIDs.length - 1; currentPos > 0; currentPos--) {        int swapPos = random.nextInt(currentPos + 1);        swapCachedPreferences(currentPos, swapPos);    }}
private void mahout_f1862_0(int posA, int posB)
{    long tmpUserIndex = cachedUserIDs[posA];    long tmpItemIndex = cachedItemIDs[posA];    cachedUserIDs[posA] = cachedUserIDs[posB];    cachedItemIDs[posA] = cachedItemIDs[posB];    cachedUserIDs[posB] = tmpUserIndex;    cachedItemIDs[posB] = tmpItemIndex;}
public Factorization mahout_f1863_0() throws TasteException
{    prepareTraining();    double currentLearningRate = learningRate;    for (int it = 0; it < numIterations; it++) {        for (int index = 0; index < cachedUserIDs.length; index++) {            long userId = cachedUserIDs[index];            long itemId = cachedItemIDs[index];            float rating = dataModel.getPreferenceValue(userId, itemId);            updateParameters(userId, itemId, rating, currentLearningRate);        }        currentLearningRate *= learningRateDecay;    }    return createFactorization(userVectors, itemVectors);}
 double mahout_f1864_0() throws TasteException
{    RunningAverage average = new FullRunningAverage();    LongPrimitiveIterator it = dataModel.getUserIDs();    while (it.hasNext()) {        for (Preference pref : dataModel.getPreferencesFromUser(it.nextLong())) {            average.addDatum(pref.getValue());        }    }    return average.getAverage();}
protected void mahout_f1865_0(long userID, long itemID, float rating, double currentLearningRate)
{    int userIndex = userIndex(userID);    int itemIndex = itemIndex(itemID);    double[] userVector = userVectors[userIndex];    double[] itemVector = itemVectors[itemIndex];    double prediction = predictRating(userIndex, itemIndex);    double err = rating - prediction;        userVector[USER_BIAS_INDEX] += biasLearningRate * currentLearningRate * (err - biasReg * preventOverfitting * userVector[USER_BIAS_INDEX]);        itemVector[ITEM_BIAS_INDEX] += biasLearningRate * currentLearningRate * (err - biasReg * preventOverfitting * itemVector[ITEM_BIAS_INDEX]);        for (int feature = FEATURE_OFFSET; feature < numFeatures; feature++) {        double userFeature = userVector[feature];        double itemFeature = itemVector[feature];        double deltaUserFeature = err * itemFeature - preventOverfitting * userFeature;        userVector[feature] += currentLearningRate * deltaUserFeature;        double deltaItemFeature = err * userFeature - preventOverfitting * itemFeature;        itemVector[feature] += currentLearningRate * deltaItemFeature;    }}
private double mahout_f1866_0(int userID, int itemID)
{    double sum = 0;    for (int feature = 0; feature < numFeatures; feature++) {        sum += userVectors[userID][feature] * itemVectors[itemID][feature];    }    return sum;}
protected void mahout_f1867_0() throws TasteException
{    super.prepareTraining();    Random random = RandomUtils.getRandom();    p = new double[dataModel.getNumUsers()][numFeatures];    for (int i = 0; i < p.length; i++) {        for (int feature = 0; feature < FEATURE_OFFSET; feature++) {            p[i][feature] = 0;        }        for (int feature = FEATURE_OFFSET; feature < numFeatures; feature++) {            p[i][feature] = random.nextGaussian() * randomNoise;        }    }    y = new double[dataModel.getNumItems()][numFeatures];    for (int i = 0; i < y.length; i++) {        for (int feature = 0; feature < FEATURE_OFFSET; feature++) {            y[i][feature] = 0;        }        for (int feature = FEATURE_OFFSET; feature < numFeatures; feature++) {            y[i][feature] = random.nextGaussian() * randomNoise;        }    }    /* get internal item IDs which we will need several times */    itemsByUser = new HashMap<>();    LongPrimitiveIterator userIDs = dataModel.getUserIDs();    while (userIDs.hasNext()) {        long userId = userIDs.nextLong();        int userIndex = userIndex(userId);        FastIDSet itemIDsFromUser = dataModel.getItemIDsFromUser(userId);        List<Integer> itemIndexes = new ArrayList<>(itemIDsFromUser.size());        itemsByUser.put(userIndex, itemIndexes);        for (long itemID2 : itemIDsFromUser) {            int i2 = itemIndex(itemID2);            itemIndexes.add(i2);        }    }}
public Factorization mahout_f1868_0() throws TasteException
{    prepareTraining();    super.factorize();    for (int userIndex = 0; userIndex < userVectors.length; userIndex++) {        for (int itemIndex : itemsByUser.get(userIndex)) {            for (int feature = FEATURE_OFFSET; feature < numFeatures; feature++) {                userVectors[userIndex][feature] += y[itemIndex][feature];            }        }        double denominator = Math.sqrt(itemsByUser.get(userIndex).size());        for (int feature = 0; feature < userVectors[userIndex].length; feature++) {            userVectors[userIndex][feature] = (float) (userVectors[userIndex][feature] / denominator + p[userIndex][feature]);        }    }    return createFactorization(userVectors, itemVectors);}
protected void mahout_f1869_0(long userID, long itemID, float rating, double currentLearningRate)
{    int userIndex = userIndex(userID);    int itemIndex = itemIndex(itemID);    double[] userVector = p[userIndex];    double[] itemVector = itemVectors[itemIndex];    double[] pPlusY = new double[numFeatures];    for (int i2 : itemsByUser.get(userIndex)) {        for (int f = FEATURE_OFFSET; f < numFeatures; f++) {            pPlusY[f] += y[i2][f];        }    }    double denominator = Math.sqrt(itemsByUser.get(userIndex).size());    for (int feature = 0; feature < pPlusY.length; feature++) {        pPlusY[feature] = (float) (pPlusY[feature] / denominator + p[userIndex][feature]);    }    double prediction = predictRating(pPlusY, itemIndex);    double err = rating - prediction;    double normalized_error = err / denominator;        userVector[USER_BIAS_INDEX] += biasLearningRate * currentLearningRate * (err - biasReg * preventOverfitting * userVector[USER_BIAS_INDEX]);        itemVector[ITEM_BIAS_INDEX] += biasLearningRate * currentLearningRate * (err - biasReg * preventOverfitting * itemVector[ITEM_BIAS_INDEX]);        for (int feature = FEATURE_OFFSET; feature < numFeatures; feature++) {        double pF = userVector[feature];        double iF = itemVector[feature];        double deltaU = err * iF - preventOverfitting * pF;        userVector[feature] += currentLearningRate * deltaU;        double deltaI = err * pPlusY[feature] - preventOverfitting * iF;        itemVector[feature] += currentLearningRate * deltaI;        double commonUpdate = normalized_error * iF;        for (int itemIndex2 : itemsByUser.get(userIndex)) {            double deltaI2 = commonUpdate - preventOverfitting * y[itemIndex2][feature];            y[itemIndex2][feature] += learningRate * deltaI2;        }    }}
private double mahout_f1870_0(double[] userVector, int itemID)
{    double sum = 0;    for (int feature = 0; feature < numFeatures; feature++) {        sum += userVector[feature] * itemVectors[itemID][feature];    }    return sum;}
public double mahout_f1871_0()
{    return cache;}
public void mahout_f1872_0(double value)
{    Preconditions.checkArgument(!Double.isNaN(value), "NaN cache value");    this.cache = value;}
public Object mahout_f1873_0() throws TasteException
{    train();    return null;}
 static PersistenceStrategy mahout_f1874_0()
{    return new NoPersistenceStrategy();}
private void mahout_f1875_0() throws TasteException
{    factorization = factorizer.factorize();    try {        persistenceStrategy.maybePersist(factorization);    } catch (IOException e) {        throw new TasteException("Error persisting factorization", e);    }}
public List<RecommendedItem> mahout_f1876_1(long userID, int howMany, IDRescorer rescorer, boolean includeKnownItems) throws TasteException
{    Preconditions.checkArgument(howMany >= 1, "howMany must be at least 1");        PreferenceArray preferencesFromUser = getDataModel().getPreferencesFromUser(userID);    FastIDSet possibleItemIDs = getAllOtherItems(userID, preferencesFromUser, includeKnownItems);    List<RecommendedItem> topItems = TopItems.getTopItems(howMany, possibleItemIDs.iterator(), rescorer, new Estimator(userID));        return topItems;}
public float mahout_f1877_0(long userID, long itemID) throws TasteException
{    double[] userFeatures = factorization.getUserFeatures(userID);    double[] itemFeatures = factorization.getItemFeatures(itemID);    double estimate = 0;    for (int feature = 0; feature < userFeatures.length; feature++) {        estimate += userFeatures[feature] * itemFeatures[feature];    }    return (float) estimate;}
public double mahout_f1878_0(Long itemID) throws TasteException
{    return estimatePreference(theUserID, itemID);}
public void mahout_f1879_0(Collection<Refreshable> alreadyRefreshed)
{    refreshHelper.refresh(alreadyRefreshed);}
public static List<RecommendedItem> mahout_f1880_0(int howMany, LongPrimitiveIterator possibleItemIDs, IDRescorer rescorer, Estimator<Long> estimator) throws TasteException
{    Preconditions.checkArgument(possibleItemIDs != null, "possibleItemIDs is null");    Preconditions.checkArgument(estimator != null, "estimator is null");    Queue<RecommendedItem> topItems = new PriorityQueue<>(howMany + 1, Collections.reverseOrder(ByValueRecommendedItemComparator.getInstance()));    boolean full = false;    double lowestTopValue = Double.NEGATIVE_INFINITY;    while (possibleItemIDs.hasNext()) {        long itemID = possibleItemIDs.next();        if (rescorer == null || !rescorer.isFiltered(itemID)) {            double preference;            try {                preference = estimator.estimate(itemID);            } catch (NoSuchItemException nsie) {                continue;            }            double rescoredPref = rescorer == null ? preference : rescorer.rescore(itemID, preference);            if (!Double.isNaN(rescoredPref) && (!full || rescoredPref > lowestTopValue)) {                topItems.add(new GenericRecommendedItem(itemID, (float) rescoredPref));                if (full) {                    topItems.poll();                } else if (topItems.size() > howMany) {                    full = true;                    topItems.poll();                }                lowestTopValue = topItems.peek().getValue();            }        }    }    int size = topItems.size();    if (size == 0) {        return Collections.emptyList();    }    List<RecommendedItem> result = new ArrayList<>(size);    result.addAll(topItems);    Collections.sort(result, ByValueRecommendedItemComparator.getInstance());    return result;}
public static long[] mahout_f1881_0(int howMany, LongPrimitiveIterator allUserIDs, IDRescorer rescorer, Estimator<Long> estimator) throws TasteException
{    Queue<SimilarUser> topUsers = new PriorityQueue<>(howMany + 1, Collections.reverseOrder());    boolean full = false;    double lowestTopValue = Double.NEGATIVE_INFINITY;    while (allUserIDs.hasNext()) {        long userID = allUserIDs.next();        if (rescorer != null && rescorer.isFiltered(userID)) {            continue;        }        double similarity;        try {            similarity = estimator.estimate(userID);        } catch (NoSuchUserException nsue) {            continue;        }        double rescoredSimilarity = rescorer == null ? similarity : rescorer.rescore(userID, similarity);        if (!Double.isNaN(rescoredSimilarity) && (!full || rescoredSimilarity > lowestTopValue)) {            topUsers.add(new SimilarUser(userID, rescoredSimilarity));            if (full) {                topUsers.poll();            } else if (topUsers.size() > howMany) {                full = true;                topUsers.poll();            }            lowestTopValue = topUsers.peek().getSimilarity();        }    }    int size = topUsers.size();    if (size == 0) {        return NO_IDS;    }    List<SimilarUser> sorted = new ArrayList<>(size);    sorted.addAll(topUsers);    Collections.sort(sorted);    long[] result = new long[size];    int i = 0;    for (SimilarUser similarUser : sorted) {        result[i++] = similarUser.getUserID();    }    return result;}
public static List<GenericItemSimilarity.ItemItemSimilarity> mahout_f1882_0(int howMany, Iterator<GenericItemSimilarity.ItemItemSimilarity> allSimilarities)
{    Queue<GenericItemSimilarity.ItemItemSimilarity> topSimilarities = new PriorityQueue<>(howMany + 1, Collections.reverseOrder());    boolean full = false;    double lowestTopValue = Double.NEGATIVE_INFINITY;    while (allSimilarities.hasNext()) {        GenericItemSimilarity.ItemItemSimilarity similarity = allSimilarities.next();        double value = similarity.getValue();        if (!Double.isNaN(value) && (!full || value > lowestTopValue)) {            topSimilarities.add(similarity);            if (full) {                topSimilarities.poll();            } else if (topSimilarities.size() > howMany) {                full = true;                topSimilarities.poll();            }            lowestTopValue = topSimilarities.peek().getValue();        }    }    int size = topSimilarities.size();    if (size == 0) {        return Collections.emptyList();    }    List<GenericItemSimilarity.ItemItemSimilarity> result = new ArrayList<>(size);    result.addAll(topSimilarities);    Collections.sort(result);    return result;}
public static List<GenericUserSimilarity.UserUserSimilarity> mahout_f1883_0(int howMany, Iterator<GenericUserSimilarity.UserUserSimilarity> allSimilarities)
{    Queue<GenericUserSimilarity.UserUserSimilarity> topSimilarities = new PriorityQueue<>(howMany + 1, Collections.reverseOrder());    boolean full = false;    double lowestTopValue = Double.NEGATIVE_INFINITY;    while (allSimilarities.hasNext()) {        GenericUserSimilarity.UserUserSimilarity similarity = allSimilarities.next();        double value = similarity.getValue();        if (!Double.isNaN(value) && (!full || value > lowestTopValue)) {            topSimilarities.add(similarity);            if (full) {                topSimilarities.poll();            } else if (topSimilarities.size() > howMany) {                full = true;                topSimilarities.poll();            }            lowestTopValue = topSimilarities.peek().getValue();        }    }    int size = topSimilarities.size();    if (size == 0) {        return Collections.emptyList();    }    List<GenericUserSimilarity.UserUserSimilarity> result = new ArrayList<>(size);    result.addAll(topSimilarities);    Collections.sort(result);    return result;}
protected DataModel mahout_f1884_0()
{    return dataModel;}
public long[] mahout_f1885_0(long itemID) throws TasteException
{    FastIDSet allSimilarItemIDs = new FastIDSet();    LongPrimitiveIterator allItemIDs = dataModel.getItemIDs();    while (allItemIDs.hasNext()) {        long possiblySimilarItemID = allItemIDs.nextLong();        if (!Double.isNaN(itemSimilarity(itemID, possiblySimilarItemID))) {            allSimilarItemIDs.add(possiblySimilarItemID);        }    }    return allSimilarItemIDs.toArray();}
public void mahout_f1886_0(Collection<Refreshable> alreadyRefreshed)
{    refreshHelper.refresh(alreadyRefreshed);}
public Object mahout_f1887_0() throws TasteException
{    cachedNumItems = dataModel.getNumItems();    cachedNumUsers = dataModel.getNumUsers();    return null;}
 final PreferenceInferrer mahout_f1888_0()
{    return inferrer;}
public final void mahout_f1889_0(PreferenceInferrer inferrer)
{    Preconditions.checkArgument(inferrer != null, "inferrer is null");    refreshHelper.addDependency(inferrer);    refreshHelper.removeDependency(this.inferrer);    this.inferrer = inferrer;}
 final boolean mahout_f1890_0()
{    return weighted;}
public double mahout_f1891_0(long userID1, long userID2) throws TasteException
{    DataModel dataModel = getDataModel();    PreferenceArray xPrefs = dataModel.getPreferencesFromUser(userID1);    PreferenceArray yPrefs = dataModel.getPreferencesFromUser(userID2);    int xLength = xPrefs.length();    int yLength = yPrefs.length();    if (xLength == 0 || yLength == 0) {        return Double.NaN;    }    long xIndex = xPrefs.getItemID(0);    long yIndex = yPrefs.getItemID(0);    int xPrefIndex = 0;    int yPrefIndex = 0;    double sumX = 0.0;    double sumX2 = 0.0;    double sumY = 0.0;    double sumY2 = 0.0;    double sumXY = 0.0;    double sumXYdiff2 = 0.0;    int count = 0;    boolean hasInferrer = inferrer != null;    while (true) {        int compare = xIndex < yIndex ? -1 : xIndex > yIndex ? 1 : 0;        if (hasInferrer || compare == 0) {            double x;            double y;            if (xIndex == yIndex) {                                x = xPrefs.getValue(xPrefIndex);                y = yPrefs.getValue(yPrefIndex);            } else {                                if (compare < 0) {                                        x = xPrefs.getValue(xPrefIndex);                    y = inferrer.inferPreference(userID2, xIndex);                } else {                                                            x = inferrer.inferPreference(userID1, yIndex);                    y = yPrefs.getValue(yPrefIndex);                }            }            sumXY += x * y;            sumX += x;            sumX2 += x * x;            sumY += y;            sumY2 += y * y;            double diff = x - y;            sumXYdiff2 += diff * diff;            count++;        }        if (compare <= 0) {            if (++xPrefIndex >= xLength) {                if (hasInferrer) {                                        if (yIndex == Long.MAX_VALUE) {                                                break;                    }                    xIndex = Long.MAX_VALUE;                } else {                    break;                }            } else {                xIndex = xPrefs.getItemID(xPrefIndex);            }        }        if (compare >= 0) {            if (++yPrefIndex >= yLength) {                if (hasInferrer) {                                        if (xIndex == Long.MAX_VALUE) {                                                break;                    }                    yIndex = Long.MAX_VALUE;                } else {                    break;                }            } else {                yIndex = yPrefs.getItemID(yPrefIndex);            }        }    }        double result;    if (centerData) {        double meanX = sumX / count;        double meanY = sumY / count;                double centeredSumXY = sumXY - meanY * sumX;                double centeredSumX2 = sumX2 - meanX * sumX;                double centeredSumY2 = sumY2 - meanY * sumY;        result = computeResult(count, centeredSumXY, centeredSumX2, centeredSumY2, sumXYdiff2);    } else {        result = computeResult(count, sumXY, sumX2, sumY2, sumXYdiff2);    }    if (!Double.isNaN(result)) {        result = normalizeWeightResult(result, count, cachedNumItems);    }    return result;}
public final double mahout_f1892_0(long itemID1, long itemID2) throws TasteException
{    DataModel dataModel = getDataModel();    PreferenceArray xPrefs = dataModel.getPreferencesForItem(itemID1);    PreferenceArray yPrefs = dataModel.getPreferencesForItem(itemID2);    int xLength = xPrefs.length();    int yLength = yPrefs.length();    if (xLength == 0 || yLength == 0) {        return Double.NaN;    }    long xIndex = xPrefs.getUserID(0);    long yIndex = yPrefs.getUserID(0);    int xPrefIndex = 0;    int yPrefIndex = 0;    double sumX = 0.0;    double sumX2 = 0.0;    double sumY = 0.0;    double sumY2 = 0.0;    double sumXY = 0.0;    double sumXYdiff2 = 0.0;    int count = 0;    while (true) {        int compare = xIndex < yIndex ? -1 : xIndex > yIndex ? 1 : 0;        if (compare == 0) {                        double x = xPrefs.getValue(xPrefIndex);            double y = yPrefs.getValue(yPrefIndex);            sumXY += x * y;            sumX += x;            sumX2 += x * x;            sumY += y;            sumY2 += y * y;            double diff = x - y;            sumXYdiff2 += diff * diff;            count++;        }        if (compare <= 0) {            if (++xPrefIndex == xLength) {                break;            }            xIndex = xPrefs.getUserID(xPrefIndex);        }        if (compare >= 0) {            if (++yPrefIndex == yLength) {                break;            }            yIndex = yPrefs.getUserID(yPrefIndex);        }    }    double result;    if (centerData) {                double n = (double) count;        double meanX = sumX / n;        double meanY = sumY / n;                double centeredSumXY = sumXY - meanY * sumX;                double centeredSumX2 = sumX2 - meanX * sumX;                double centeredSumY2 = sumY2 - meanY * sumY;        result = computeResult(count, centeredSumXY, centeredSumX2, centeredSumY2, sumXYdiff2);    } else {        result = computeResult(count, sumXY, sumX2, sumY2, sumXYdiff2);    }    if (!Double.isNaN(result)) {        result = normalizeWeightResult(result, count, cachedNumUsers);    }    return result;}
public double[] mahout_f1893_0(long itemID1, long[] itemID2s) throws TasteException
{    int length = itemID2s.length;    double[] result = new double[length];    for (int i = 0; i < length; i++) {        result[i] = itemSimilarity(itemID1, itemID2s[i]);    }    return result;}
 final double mahout_f1894_0(double result, int count, int num)
{    double normalizedResult = result;    if (weighted) {        double scaleFactor = 1.0 - (double) count / (double) (num + 1);        if (normalizedResult < 0.0) {            normalizedResult = -1.0 + scaleFactor * (1.0 + normalizedResult);        } else {            normalizedResult = 1.0 - scaleFactor * (1.0 - normalizedResult);        }    }        if (normalizedResult < -1.0) {        normalizedResult = -1.0;    } else if (normalizedResult > 1.0) {        normalizedResult = 1.0;    }    return normalizedResult;}
public final void mahout_f1895_0(Collection<Refreshable> alreadyRefreshed)
{    super.refresh(alreadyRefreshed);    refreshHelper.refresh(alreadyRefreshed);}
public final String mahout_f1896_0()
{    return this.getClass().getSimpleName() + "[dataModel:" + getDataModel() + ",inferrer:" + inferrer + ']';}
public float mahout_f1897_0(long userID, long itemID) throws TasteException
{    return averagePreferenceValue.get(userID);}
public void mahout_f1898_0(Collection<Refreshable> alreadyRefreshed)
{    averagePreferenceValue.clear();}
public Float mahout_f1899_0(Long key) throws TasteException
{    PreferenceArray prefs = dataModel.getPreferencesFromUser(key);    int size = prefs.length();    if (size == 0) {        return ZERO;    }    RunningAverage average = new FullRunningAverage();    for (int i = 0; i < size; i++) {        average.addDatum(prefs.getValue(i));    }    return (float) average.getAverage();}
public String mahout_f1900_0()
{    return "AveragingPreferenceInferrer";}
public Void mahout_f1901_0()
{    similarityCache.clear();    return null;}
public double mahout_f1902_0(long itemID1, long itemID2) throws TasteException
{    LongPair key = itemID1 < itemID2 ? new LongPair(itemID1, itemID2) : new LongPair(itemID2, itemID1);    return similarityCache.get(key);}
public double[] mahout_f1903_0(long itemID1, long[] itemID2s) throws TasteException
{    int length = itemID2s.length;    double[] result = new double[length];    for (int i = 0; i < length; i++) {        result[i] = itemSimilarity(itemID1, itemID2s[i]);    }    return result;}
public long[] mahout_f1904_0(long itemID) throws TasteException
{    return similarity.allSimilarItemIDs(itemID);}
public void mahout_f1905_0(Collection<Refreshable> alreadyRefreshed)
{    refreshHelper.refresh(alreadyRefreshed);}
public void mahout_f1906_0(long itemID)
{    similarityCache.removeKeysMatching(new LongPairMatchPredicate(itemID));}
public Double mahout_f1907_0(LongPair key) throws TasteException
{    return similarity.itemSimilarity(key.getFirst(), key.getSecond());}
public Void mahout_f1908_0()
{    similarityCache.clear();    return null;}
public double mahout_f1909_0(long userID1, long userID2) throws TasteException
{    LongPair key = userID1 < userID2 ? new LongPair(userID1, userID2) : new LongPair(userID2, userID1);    return similarityCache.get(key);}
public void mahout_f1910_0(PreferenceInferrer inferrer)
{    similarityCache.clear();    similarity.setPreferenceInferrer(inferrer);}
public void mahout_f1911_0(long userID)
{    similarityCache.removeKeysMatching(new LongPairMatchPredicate(userID));}
public void mahout_f1912_0(Collection<Refreshable> alreadyRefreshed)
{    refreshHelper.refresh(alreadyRefreshed);}
public Double mahout_f1913_0(LongPair key) throws TasteException
{    return similarity.userSimilarity(key.getFirst(), key.getSecond());}
public void mahout_f1914_0(PreferenceInferrer inferrer)
{    throw new UnsupportedOperationException();}
public void mahout_f1915_0(Collection<Refreshable> alreadyRefreshed)
{    Collection<Refreshable> refreshed = RefreshHelper.buildRefreshed(alreadyRefreshed);    RefreshHelper.maybeRefresh(refreshed, getDataModel());}
public double mahout_f1916_0(long itemID1, long itemID2) throws TasteException
{    DataModel dataModel = getDataModel();    int preferring1 = dataModel.getNumUsersWithPreferenceFor(itemID1);    int preferring2 = dataModel.getNumUsersWithPreferenceFor(itemID2);    int intersection = dataModel.getNumUsersWithPreferenceFor(itemID1, itemID2);    return doSimilarity(preferring1, preferring2, intersection);}
public double[] mahout_f1917_0(long itemID1, long[] itemID2s) throws TasteException
{    DataModel dataModel = getDataModel();    int preferring1 = dataModel.getNumUsersWithPreferenceFor(itemID1);    double[] distance = new double[itemID2s.length];    for (int i = 0; i < itemID2s.length; ++i) {        int preferring2 = dataModel.getNumUsersWithPreferenceFor(itemID2s[i]);        int intersection = dataModel.getNumUsersWithPreferenceFor(itemID1, itemID2s[i]);        distance[i] = doSimilarity(preferring1, preferring2, intersection);    }    return distance;}
public double mahout_f1918_0(long userID1, long userID2) throws TasteException
{    DataModel dataModel = getDataModel();    FastIDSet prefs1 = dataModel.getItemIDsFromUser(userID1);    FastIDSet prefs2 = dataModel.getItemIDsFromUser(userID2);    int prefs1Size = prefs1.size();    int prefs2Size = prefs2.size();    int intersectionSize = prefs1Size < prefs2Size ? prefs2.intersectionSize(prefs1) : prefs1.intersectionSize(prefs2);    return doSimilarity(prefs1Size, prefs2Size, intersectionSize);}
private static double mahout_f1919_0(int pref1, int pref2, int intersection)
{    int distance = pref1 + pref2 - 2 * intersection;    return 1.0 / (1.0 + distance);}
 double mahout_f1920_0(int n, double sumXY, double sumX2, double sumY2, double sumXYdiff2)
{    return 1.0 / (1.0 + Math.sqrt(sumXYdiff2) / Math.sqrt(n));}
public Iterator<GenericItemSimilarity.ItemItemSimilarity> mahout_f1921_0()
{    try {        return new FileItemItemSimilarityIterator(similaritiesFile);    } catch (IOException ioe) {        throw new IllegalStateException("Can't read " + similaritiesFile, ioe);    }}
public GenericItemSimilarity.ItemItemSimilarity mahout_f1922_0(String from)
{    String[] tokens = SEPARATOR.split(from);    return new GenericItemSimilarity.ItemItemSimilarity(Long.parseLong(tokens[0]), Long.parseLong(tokens[1]), Double.parseDouble(tokens[2]));}
protected Iterator<GenericItemSimilarity.ItemItemSimilarity> mahout_f1923_0()
{    return delegate;}
public double[] mahout_f1924_0(long itemID1, long[] itemID2s) throws TasteException
{    return delegate.itemSimilarities(itemID1, itemID2s);}
public long[] mahout_f1925_0(long itemID) throws TasteException
{    return delegate.allSimilarItemIDs(itemID);}
public double mahout_f1926_0(long itemID1, long itemID2) throws TasteException
{    return delegate.itemSimilarity(itemID1, itemID2);}
protected void mahout_f1928_0()
{    if (reloadLock.tryLock()) {        try {            long newLastModified = dataFile.lastModified();            delegate = new GenericItemSimilarity(new FileItemItemSimilarityIterable(dataFile));            lastModified = newLastModified;        } finally {            reloadLock.unlock();        }    }}
public String mahout_f1929_0()
{    return "FileItemSimilarity[dataFile:" + dataFile + ']';}
private void mahout_f1930_0(Iterator<ItemItemSimilarity> similarities)
{    while (similarities.hasNext()) {        ItemItemSimilarity iic = similarities.next();        long similarityItemID1 = iic.getItemID1();        long similarityItemID2 = iic.getItemID2();        if (similarityItemID1 != similarityItemID2) {                        long itemID1;            long itemID2;            if (similarityItemID1 < similarityItemID2) {                itemID1 = similarityItemID1;                itemID2 = similarityItemID2;            } else {                itemID1 = similarityItemID2;                itemID2 = similarityItemID1;            }            FastByIDMap<Double> map = similarityMaps.get(itemID1);            if (map == null) {                map = new FastByIDMap<>();                similarityMaps.put(itemID1, map);            }            map.put(itemID2, iic.getValue());            doIndex(itemID1, itemID2);            doIndex(itemID2, itemID1);        }        }}
private void mahout_f1931_0(long fromItemID, long toItemID)
{    FastIDSet similarItemIDs = similarItemIDsIndex.get(fromItemID);    if (similarItemIDs == null) {        similarItemIDs = new FastIDSet();        similarItemIDsIndex.put(fromItemID, similarItemIDs);    }    similarItemIDs.add(toItemID);}
public double mahout_f1932_0(long itemID1, long itemID2)
{    if (itemID1 == itemID2) {        return 1.0;    }    long firstID;    long secondID;    if (itemID1 < itemID2) {        firstID = itemID1;        secondID = itemID2;    } else {        firstID = itemID2;        secondID = itemID1;    }    FastByIDMap<Double> nextMap = similarityMaps.get(firstID);    if (nextMap == null) {        return Double.NaN;    }    Double similarity = nextMap.get(secondID);    return similarity == null ? Double.NaN : similarity;}
public double[] mahout_f1933_0(long itemID1, long[] itemID2s)
{    int length = itemID2s.length;    double[] result = new double[length];    for (int i = 0; i < length; i++) {        result[i] = itemSimilarity(itemID1, itemID2s[i]);    }    return result;}
public long[] mahout_f1934_0(long itemID)
{    FastIDSet similarItemIDs = similarItemIDsIndex.get(itemID);    return similarItemIDs != null ? similarItemIDs.toArray() : NO_IDS;}
public void mahout_f1935_0(Collection<Refreshable> alreadyRefreshed)
{}
public long mahout_f1936_0()
{    return itemID1;}
public long mahout_f1937_0()
{    return itemID2;}
public double mahout_f1938_0()
{    return value;}
public String mahout_f1939_0()
{    return "ItemItemSimilarity[" + itemID1 + ',' + itemID2 + ':' + value + ']';}
public int mahout_f1940_0(ItemItemSimilarity other)
{    double otherValue = other.getValue();    return value > otherValue ? -1 : value < otherValue ? 1 : 0;}
public boolean mahout_f1941_0(Object other)
{    if (!(other instanceof ItemItemSimilarity)) {        return false;    }    ItemItemSimilarity otherSimilarity = (ItemItemSimilarity) other;    return otherSimilarity.getItemID1() == itemID1 && otherSimilarity.getItemID2() == itemID2 && otherSimilarity.getValue() == value;}
public int mahout_f1942_0()
{    return (int) itemID1 ^ (int) itemID2 ^ RandomUtils.hashDouble(value);}
protected ItemItemSimilarity mahout_f1943_0()
{    int size = itemIDs.length;    ItemItemSimilarity result = null;    while (result == null && i < size - 1) {        long itemID2 = itemIDs[j];        double similarity;        try {            similarity = otherSimilarity.itemSimilarity(itemID1, itemID2);        } catch (TasteException te) {                        throw new IllegalStateException(te);        }        if (!Double.isNaN(similarity)) {            result = new ItemItemSimilarity(itemID1, itemID2, similarity);        }        if (++j == size) {            itemID1 = itemIDs[++i];            j = i + 1;        }    }    if (result == null) {        return endOfData();    } else {        return result;    }}
 static long[] mahout_f1944_0(LongPrimitiveIterator iterator)
{    long[] result = new long[5];    int size = 0;    while (iterator.hasNext()) {        if (size == result.length) {            long[] newResult = new long[result.length << 1];            System.arraycopy(result, 0, newResult, 0, result.length);            result = newResult;        }        result[size++] = iterator.next();    }    if (size != result.length) {        long[] newResult = new long[size];        System.arraycopy(result, 0, newResult, 0, size);        result = newResult;    }    return result;}
private void mahout_f1945_0(Iterator<UserUserSimilarity> similarities)
{    while (similarities.hasNext()) {        UserUserSimilarity uuc = similarities.next();        long similarityUser1 = uuc.getUserID1();        long similarityUser2 = uuc.getUserID2();        if (similarityUser1 != similarityUser2) {                        long user1;            long user2;            if (similarityUser1 < similarityUser2) {                user1 = similarityUser1;                user2 = similarityUser2;            } else {                user1 = similarityUser2;                user2 = similarityUser1;            }            FastByIDMap<Double> map = similarityMaps.get(user1);            if (map == null) {                map = new FastByIDMap<>();                similarityMaps.put(user1, map);            }            map.put(user2, uuc.getValue());        }        }}
public double mahout_f1946_0(long userID1, long userID2)
{    if (userID1 == userID2) {        return 1.0;    }    long first;    long second;    if (userID1 < userID2) {        first = userID1;        second = userID2;    } else {        first = userID2;        second = userID1;    }    FastByIDMap<Double> nextMap = similarityMaps.get(first);    if (nextMap == null) {        return Double.NaN;    }    Double similarity = nextMap.get(second);    return similarity == null ? Double.NaN : similarity;}
public void mahout_f1947_0(PreferenceInferrer inferrer)
{    throw new UnsupportedOperationException();}
public void mahout_f1948_0(Collection<Refreshable> alreadyRefreshed)
{}
public long mahout_f1949_0()
{    return userID1;}
public long mahout_f1950_0()
{    return userID2;}
public double mahout_f1951_0()
{    return value;}
public String mahout_f1952_0()
{    return "UserUserSimilarity[" + userID1 + ',' + userID2 + ':' + value + ']';}
public int mahout_f1953_0(UserUserSimilarity other)
{    double otherValue = other.getValue();    return value > otherValue ? -1 : value < otherValue ? 1 : 0;}
public boolean mahout_f1954_0(Object other)
{    if (!(other instanceof UserUserSimilarity)) {        return false;    }    UserUserSimilarity otherSimilarity = (UserUserSimilarity) other;    return otherSimilarity.getUserID1() == userID1 && otherSimilarity.getUserID2() == userID2 && otherSimilarity.getValue() == value;}
public int mahout_f1955_0()
{    return (int) userID1 ^ (int) userID2 ^ RandomUtils.hashDouble(value);}
protected UserUserSimilarity mahout_f1956_0()
{    int size = itemIDs.length;    while (i < size - 1) {        long itemID2 = itemIDs[j];        double similarity;        try {            similarity = otherSimilarity.userSimilarity(itemID1, itemID2);        } catch (TasteException te) {                        throw new IllegalStateException(te);        }        if (!Double.isNaN(similarity)) {            return new UserUserSimilarity(itemID1, itemID2, similarity);        }        if (++j == size) {            itemID1 = itemIDs[++i];            j = i + 1;        }    }    return endOfData();}
public void mahout_f1957_0(PreferenceInferrer inferrer)
{    throw new UnsupportedOperationException();}
public double mahout_f1958_0(long userID1, long userID2) throws TasteException
{    DataModel dataModel = getDataModel();    FastIDSet prefs1 = dataModel.getItemIDsFromUser(userID1);    FastIDSet prefs2 = dataModel.getItemIDsFromUser(userID2);    long prefs1Size = prefs1.size();    long prefs2Size = prefs2.size();    long intersectionSize = prefs1Size < prefs2Size ? prefs2.intersectionSize(prefs1) : prefs1.intersectionSize(prefs2);    if (intersectionSize == 0) {        return Double.NaN;    }    long numItems = dataModel.getNumItems();    double logLikelihood = LogLikelihood.logLikelihoodRatio(intersectionSize, prefs2Size - intersectionSize, prefs1Size - intersectionSize, numItems - prefs1Size - prefs2Size + intersectionSize);    return 1.0 - 1.0 / (1.0 + logLikelihood);}
public double mahout_f1959_0(long itemID1, long itemID2) throws TasteException
{    DataModel dataModel = getDataModel();    long preferring1 = dataModel.getNumUsersWithPreferenceFor(itemID1);    long numUsers = dataModel.getNumUsers();    return doItemSimilarity(itemID1, itemID2, preferring1, numUsers);}
public double[] mahout_f1960_0(long itemID1, long[] itemID2s) throws TasteException
{    DataModel dataModel = getDataModel();    long preferring1 = dataModel.getNumUsersWithPreferenceFor(itemID1);    long numUsers = dataModel.getNumUsers();    int length = itemID2s.length;    double[] result = new double[length];    for (int i = 0; i < length; i++) {        result[i] = doItemSimilarity(itemID1, itemID2s[i], preferring1, numUsers);    }    return result;}
private double mahout_f1961_0(long itemID1, long itemID2, long preferring1, long numUsers) throws TasteException
{    DataModel dataModel = getDataModel();    long preferring1and2 = dataModel.getNumUsersWithPreferenceFor(itemID1, itemID2);    if (preferring1and2 == 0) {        return Double.NaN;    }    long preferring2 = dataModel.getNumUsersWithPreferenceFor(itemID2);    double logLikelihood = LogLikelihood.logLikelihoodRatio(preferring1and2, preferring2 - preferring1and2, preferring1 - preferring1and2, numUsers - preferring1 - preferring2 + preferring1and2);    return 1.0 - 1.0 / (1.0 + logLikelihood);}
public void mahout_f1962_0(Collection<Refreshable> alreadyRefreshed)
{    alreadyRefreshed = RefreshHelper.buildRefreshed(alreadyRefreshed);    RefreshHelper.maybeRefresh(alreadyRefreshed, getDataModel());}
public String mahout_f1963_0()
{    return "LogLikelihoodSimilarity[dataModel:" + getDataModel() + ']';}
public boolean mahout_f1964_0(LongPair pair)
{    return pair.getFirst() == id || pair.getSecond() == id;}
 double mahout_f1965_0(int n, double sumXY, double sumX2, double sumY2, double sumXYdiff2)
{    if (n == 0) {        return Double.NaN;    }            double denominator = Math.sqrt(sumX2) * Math.sqrt(sumY2);    if (denominator == 0.0) {                return Double.NaN;    }    return sumXY / denominator;}
public void mahout_f1966_0() throws IOException
{    writer = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(file), Charsets.UTF_8));}
public void mahout_f1967_0(SimilarItems similarItems) throws IOException
{    String itemID = String.valueOf(similarItems.getItemID());    for (SimilarItem similarItem : similarItems.getSimilarItems()) {        writer.write(itemID);        writer.write(',');        writer.write(String.valueOf(similarItem.getItemID()));        writer.write(',');        writer.write(String.valueOf(similarItem.getSimilarity()));        writer.newLine();    }}
public void mahout_f1968_0() throws IOException
{    Closeables.close(writer, false);}
public int mahout_f1969_0(int degreeOfParallelism, int maxDurationInHours, SimilarItemsWriter writer) throws IOException
{    ExecutorService executorService = Executors.newFixedThreadPool(degreeOfParallelism + 1);    Output output = null;    try {        writer.open();        DataModel dataModel = getRecommender().getDataModel();        BlockingQueue<long[]> itemsIDsInBatches = queueItemIDsInBatches(dataModel, batchSize, degreeOfParallelism);        BlockingQueue<List<SimilarItems>> results = new LinkedBlockingQueue<>();        AtomicInteger numActiveWorkers = new AtomicInteger(degreeOfParallelism);        for (int n = 0; n < degreeOfParallelism; n++) {            executorService.execute(new SimilarItemsWorker(n, itemsIDsInBatches, results, numActiveWorkers));        }        output = new Output(results, writer, numActiveWorkers);        executorService.execute(output);    } catch (Exception e) {        throw new IOException(e);    } finally {        executorService.shutdown();        try {            boolean succeeded = executorService.awaitTermination(maxDurationInHours, TimeUnit.HOURS);            if (!succeeded) {                throw new RuntimeException("Unable to complete the computation in " + maxDurationInHours + " hours!");            }        } catch (InterruptedException e) {            throw new RuntimeException(e);        }        Closeables.close(writer, false);    }    return output.getNumSimilaritiesProcessed();}
private static BlockingQueue<long[]> mahout_f1970_1(DataModel dataModel, int batchSize, int degreeOfParallelism) throws TasteException
{    LongPrimitiveIterator itemIDs = dataModel.getItemIDs();    int numItems = dataModel.getNumItems();    BlockingQueue<long[]> itemIDBatches = new LinkedBlockingQueue<>((numItems / batchSize) + 1);    long[] batch = new long[batchSize];    int pos = 0;    while (itemIDs.hasNext()) {        batch[pos] = itemIDs.nextLong();        pos++;        if (pos == batchSize) {            itemIDBatches.add(batch.clone());            pos = 0;        }    }    if (pos > 0) {        long[] lastBatch = new long[pos];        System.arraycopy(batch, 0, lastBatch, 0, pos);        itemIDBatches.add(lastBatch);    }    if (itemIDBatches.size() < degreeOfParallelism) {        throw new IllegalStateException("Degree of parallelism [" + degreeOfParallelism + "] " + " is larger than number of batches [" + itemIDBatches.size() + "].");    }        return itemIDBatches;}
private int mahout_f1971_0()
{    return numSimilaritiesProcessed;}
public void mahout_f1972_0()
{    while (numActiveWorkers.get() != 0 || !results.isEmpty()) {        try {            List<SimilarItems> similarItemsOfABatch = results.poll(10, TimeUnit.MILLISECONDS);            if (similarItemsOfABatch != null) {                for (SimilarItems similarItems : similarItemsOfABatch) {                    writer.add(similarItems);                    numSimilaritiesProcessed += similarItems.numSimilarItems();                }            }        } catch (Exception e) {            throw new RuntimeException(e);        }    }}
public void mahout_f1973_1()
{    int numBatchesProcessed = 0;    while (!itemIDBatches.isEmpty()) {        try {            long[] itemIDBatch = itemIDBatches.take();            List<SimilarItems> similarItemsOfBatch = new ArrayList<>(itemIDBatch.length);            for (long itemID : itemIDBatch) {                List<RecommendedItem> similarItems = getRecommender().mostSimilarItems(itemID, getSimilarItemsPerItem());                similarItemsOfBatch.add(new SimilarItems(itemID, similarItems));            }            results.offer(similarItemsOfBatch);            if (++numBatchesProcessed % 5 == 0) {                            }        } catch (Exception e) {            throw new RuntimeException(e);        }    }        numActiveWorkers.decrementAndGet();}
public double mahout_f1974_0(long userID1, long userID2) throws TasteException
{    PreferenceArray xPrefs = dataModel.getPreferencesFromUser(userID1);    PreferenceArray yPrefs = dataModel.getPreferencesFromUser(userID2);    int xLength = xPrefs.length();    int yLength = yPrefs.length();    if (xLength <= 1 || yLength <= 1) {        return Double.NaN;    }        xPrefs = xPrefs.clone();    yPrefs = yPrefs.clone();        xPrefs.sortByValue();    yPrefs.sortByValue();        float nextRank = 1.0f;    for (int i = 0; i < xLength; i++) {                if (yPrefs.hasPrefWithItemID(xPrefs.getItemID(i))) {            xPrefs.setValue(i, nextRank);            nextRank += 1.0f;        }        }    nextRank = 1.0f;    for (int i = 0; i < yLength; i++) {        if (xPrefs.hasPrefWithItemID(yPrefs.getItemID(i))) {            yPrefs.setValue(i, nextRank);            nextRank += 1.0f;        }    }    xPrefs.sortByItem();    yPrefs.sortByItem();    long xIndex = xPrefs.getItemID(0);    long yIndex = yPrefs.getItemID(0);    int xPrefIndex = 0;    int yPrefIndex = 0;    double sumXYRankDiff2 = 0.0;    int count = 0;    while (true) {        int compare = xIndex < yIndex ? -1 : xIndex > yIndex ? 1 : 0;        if (compare == 0) {            double diff = xPrefs.getValue(xPrefIndex) - yPrefs.getValue(yPrefIndex);            sumXYRankDiff2 += diff * diff;            count++;        }        if (compare <= 0) {            if (++xPrefIndex >= xLength) {                break;            }            xIndex = xPrefs.getItemID(xPrefIndex);        }        if (compare >= 0) {            if (++yPrefIndex >= yLength) {                break;            }            yIndex = yPrefs.getItemID(yPrefIndex);        }    }    if (count <= 1) {        return Double.NaN;    }        return 1.0 - 6.0 * sumXYRankDiff2 / (count * (count * count - 1));}
public void mahout_f1975_0(PreferenceInferrer inferrer)
{    throw new UnsupportedOperationException();}
public void mahout_f1976_0(Collection<Refreshable> alreadyRefreshed)
{    alreadyRefreshed = RefreshHelper.buildRefreshed(alreadyRefreshed);    RefreshHelper.maybeRefresh(alreadyRefreshed, dataModel);}
public void mahout_f1977_0(PreferenceInferrer inferrer)
{    throw new UnsupportedOperationException();}
public double mahout_f1978_0(long userID1, long userID2) throws TasteException
{    DataModel dataModel = getDataModel();    FastIDSet xPrefs = dataModel.getItemIDsFromUser(userID1);    FastIDSet yPrefs = dataModel.getItemIDsFromUser(userID2);    int xPrefsSize = xPrefs.size();    int yPrefsSize = yPrefs.size();    if (xPrefsSize == 0 && yPrefsSize == 0) {        return Double.NaN;    }    if (xPrefsSize == 0 || yPrefsSize == 0) {        return 0.0;    }    int intersectionSize = xPrefsSize < yPrefsSize ? yPrefs.intersectionSize(xPrefs) : xPrefs.intersectionSize(yPrefs);    if (intersectionSize == 0) {        return Double.NaN;    }    int unionSize = xPrefsSize + yPrefsSize - intersectionSize;    return (double) intersectionSize / (double) unionSize;}
public double mahout_f1979_0(long itemID1, long itemID2) throws TasteException
{    int preferring1 = getDataModel().getNumUsersWithPreferenceFor(itemID1);    return doItemSimilarity(itemID1, itemID2, preferring1);}
public double[] mahout_f1980_0(long itemID1, long[] itemID2s) throws TasteException
{    int preferring1 = getDataModel().getNumUsersWithPreferenceFor(itemID1);    int length = itemID2s.length;    double[] result = new double[length];    for (int i = 0; i < length; i++) {        result[i] = doItemSimilarity(itemID1, itemID2s[i], preferring1);    }    return result;}
private double mahout_f1981_0(long itemID1, long itemID2, int preferring1) throws TasteException
{    DataModel dataModel = getDataModel();    int preferring1and2 = dataModel.getNumUsersWithPreferenceFor(itemID1, itemID2);    if (preferring1and2 == 0) {        return Double.NaN;    }    int preferring2 = dataModel.getNumUsersWithPreferenceFor(itemID2);    return (double) preferring1and2 / (double) (preferring1 + preferring2 - preferring1and2);}
public void mahout_f1982_0(Collection<Refreshable> alreadyRefreshed)
{    alreadyRefreshed = RefreshHelper.buildRefreshed(alreadyRefreshed);    RefreshHelper.maybeRefresh(alreadyRefreshed, getDataModel());}
public String mahout_f1983_0()
{    return "TanimotoCoefficientSimilarity[dataModel:" + getDataModel() + ']';}
 double mahout_f1984_0(int n, double sumXY, double sumX2, double sumY2, double sumXYdiff2)
{    if (n == 0) {        return Double.NaN;    }    double denominator = Math.sqrt(sumX2) * Math.sqrt(sumY2);    if (denominator == 0.0) {                return Double.NaN;    }    return sumXY / denominator;}
protected ItemBasedRecommender mahout_f1985_0()
{    return recommender;}
protected int mahout_f1986_0()
{    return similarItemsPerItem;}
public int mahout_f1987_0(SimilarItem s1, SimilarItem s2)
{    return Doubles.compare(s1.similarity, s2.similarity);}
public void mahout_f1988_0(long itemID, double similarity)
{    this.itemID = itemID;    this.similarity = similarity;}
public long mahout_f1989_0()
{    return itemID;}
public double mahout_f1990_0()
{    return similarity;}
public long mahout_f1991_0()
{    return itemID;}
public int mahout_f1992_0()
{    return similarItemIDs.length;}
public Iterable<SimilarItem> mahout_f1993_0()
{    return new Iterable<SimilarItem>() {        @Override        public Iterator<SimilarItem> iterator() {            return new SimilarItemsIterator();        }    };}
public Iterator<SimilarItem> mahout_f1994_0()
{    return new SimilarItemsIterator();}
public boolean mahout_f1995_0()
{    return index < (similarItemIDs.length - 1);}
public SimilarItem mahout_f1996_0()
{    if (!hasNext()) {        throw new NoSuchElementException();    }    index++;    return new SimilarItem(similarItemIDs[index], similarities[index]);}
public Vector mahout_f1997_0(Vector features)
{    throw new UnsupportedOperationException(this.getClass().getName() + " doesn't support classification without a link");}
public Vector mahout_f1998_0(Vector instance)
{    return classifyFull(new DenseVector(numCategories()), instance);}
public Vector mahout_f1999_0(Vector r, Vector instance)
{    r.viewPart(1, numCategories() - 1).assign(classify(instance));    r.setQuick(0, 1.0 - r.zSum());    return r;}
public Matrix mahout_f2000_0(Matrix data)
{    Matrix r = new DenseMatrix(data.numRows(), numCategories() - 1);    for (int row = 0; row < data.numRows(); row++) {        r.assignRow(row, classify(data.viewRow(row)));    }    return r;}
public Matrix mahout_f2001_0(Matrix data)
{    Matrix r = new DenseMatrix(data.numRows(), numCategories());    for (int row = 0; row < data.numRows(); row++) {        classifyFull(r.viewRow(row), data.viewRow(row));    }    return r;}
public Vector mahout_f2002_0(Matrix data)
{    Preconditions.checkArgument(numCategories() == 2, "Can only call classifyScalar with two categories");    Vector r = new DenseVector(data.numRows());    for (int row = 0; row < data.numRows(); row++) {        r.set(row, classifyScalar(data.viewRow(row)));    }    return r;}
public double mahout_f2003_0(int actual, Vector data)
{    if (numCategories() == 2) {        double p = classifyScalar(data);        if (actual > 0) {            return Math.max(MIN_LOG_LIKELIHOOD, Math.log(p));        } else {            return Math.max(MIN_LOG_LIKELIHOOD, Math.log1p(-p));        }    } else {        Vector p = classify(data);        if (actual > 0) {            return Math.max(MIN_LOG_LIKELIHOOD, Math.log(p.get(actual - 1)));        } else {            return Math.max(MIN_LOG_LIKELIHOOD, Math.log1p(-p.zSum()));        }    }}
public double mahout_f2004_0()
{    return logLikelihood;}
public void mahout_f2005_0(double logLikelihood)
{    this.logLikelihood = logLikelihood;}
public String mahout_f2006_0()
{    return label;}
public double mahout_f2007_0()
{    return score;}
public void mahout_f2008_0(String label)
{    this.label = label;}
public void mahout_f2009_0(double score)
{    this.score = score;}
public String mahout_f2010_0()
{    return "ClassifierResult{" + "category='" + label + '\'' + ", score=" + score + '}';}
public int[][] mahout_f2011_0()
{    return confusionMatrix;}
public Collection<String> mahout_f2012_0()
{    return Collections.unmodifiableCollection(labelMap.keySet());}
private int mahout_f2013_0()
{    return labelMap.size();}
public double mahout_f2014_0(String label)
{    int labelId = labelMap.get(label);    int labelTotal = 0;    int correct = 0;    for (int i = 0; i < numLabels(); i++) {        labelTotal += confusionMatrix[labelId][i];        if (i == labelId) {            correct += confusionMatrix[labelId][i];        }    }    return 100.0 * correct / labelTotal;}
public double mahout_f2015_0()
{    int total = 0;    int correct = 0;    for (int i = 0; i < numLabels(); i++) {        for (int j = 0; j < numLabels(); j++) {            total += confusionMatrix[i][j];            if (i == j) {                correct += confusionMatrix[i][j];            }        }    }    return 100.0 * correct / total;}
private int mahout_f2016_0(String label)
{    int labelId = labelMap.get(label);    int sum = 0;    for (int i = 0; i < numLabels(); i++) {        sum += confusionMatrix[labelId][i];    }    return sum;}
public double mahout_f2017_0(String label)
{    int labelId = labelMap.get(label);    int truePositives = confusionMatrix[labelId][labelId];    int falsePositives = 0;    for (int i = 0; i < numLabels(); i++) {        if (i == labelId) {            continue;        }        falsePositives += confusionMatrix[i][labelId];    }    if (truePositives + falsePositives == 0) {        return 0;    }    return ((double) truePositives) / (truePositives + falsePositives);}
public double mahout_f2018_0()
{    double[] precisions = new double[numLabels()];    double[] weights = new double[numLabels()];    int index = 0;    for (String label : labelMap.keySet()) {        precisions[index] = getPrecision(label);        weights[index] = getActualNumberOfTestExamplesForClass(label);        index++;    }    return new Mean().evaluate(precisions, weights);}
public double mahout_f2019_0(String label)
{    int labelId = labelMap.get(label);    int truePositives = confusionMatrix[labelId][labelId];    int falseNegatives = 0;    for (int i = 0; i < numLabels(); i++) {        if (i == labelId) {            continue;        }        falseNegatives += confusionMatrix[labelId][i];    }    if (truePositives + falseNegatives == 0) {        return 0;    }    return ((double) truePositives) / (truePositives + falseNegatives);}
public double mahout_f2020_0()
{    double[] recalls = new double[numLabels()];    double[] weights = new double[numLabels()];    int index = 0;    for (String label : labelMap.keySet()) {        recalls[index] = getRecall(label);        weights[index] = getActualNumberOfTestExamplesForClass(label);        index++;    }    return new Mean().evaluate(recalls, weights);}
public double mahout_f2021_0(String label)
{    double precision = getPrecision(label);    double recall = getRecall(label);    if (precision + recall == 0) {        return 0;    }    return 2 * precision * recall / (precision + recall);}
public double mahout_f2022_0()
{    double[] f1Scores = new double[numLabels()];    double[] weights = new double[numLabels()];    int index = 0;    for (String label : labelMap.keySet()) {        f1Scores[index] = getF1score(label);        weights[index] = getActualNumberOfTestExamplesForClass(label);        index++;    }    return new Mean().evaluate(f1Scores, weights);}
public double mahout_f2023_0()
{    int count = 0;    double accuracy = 0;    for (String label : labelMap.keySet()) {        if (!label.equals(defaultLabel)) {            accuracy += getAccuracy(label);        }        count++;    }    return accuracy / count;}
public double mahout_f2024_0()
{    double a = 0.0;    double b = 0.0;    for (int i = 0; i < confusionMatrix.length; i++) {        a += confusionMatrix[i][i];        double br = 0;        for (int j = 0; j < confusionMatrix.length; j++) {            br += confusionMatrix[i][j];        }        double bc = 0;        for (int[] vec : confusionMatrix) {            bc += vec[i];        }        b += br * bc;    }    return (samples * a - b) / (samples * samples - b);}
public RunningAverageAndStdDev mahout_f2025_0()
{    RunningAverageAndStdDev summer = new FullRunningAverageAndStdDev();    for (int d = 0; d < confusionMatrix.length; d++) {        double total = 0;        for (int j = 0; j < confusionMatrix.length; j++) {            total += confusionMatrix[d][j];        }        summer.addDatum(confusionMatrix[d][d] / (total + 0.000001));    }    return summer;}
public int mahout_f2026_0(String label)
{    int labelId = labelMap.get(label);    return confusionMatrix[labelId][labelId];}
public int mahout_f2027_0(String label)
{    int labelId = labelMap.get(label);    int labelTotal = 0;    for (int i = 0; i < labelMap.size(); i++) {        labelTotal += confusionMatrix[labelId][i];    }    return labelTotal;}
public void mahout_f2028_0(String correctLabel, ClassifierResult classifiedResult)
{    samples++;    incrementCount(correctLabel, classifiedResult.getLabel());}
public void mahout_f2029_0(String correctLabel, String classifiedLabel)
{    samples++;    incrementCount(correctLabel, classifiedLabel);}
public int mahout_f2030_1(String correctLabel, String classifiedLabel)
{    if (!labelMap.containsKey(correctLabel)) {                return 0;    }    Preconditions.checkArgument(labelMap.containsKey(classifiedLabel), "Label not found: " + classifiedLabel);    int correctId = labelMap.get(correctLabel);    int classifiedId = labelMap.get(classifiedLabel);    return confusionMatrix[correctId][classifiedId];}
public void mahout_f2031_1(String correctLabel, String classifiedLabel, int count)
{    if (!labelMap.containsKey(correctLabel)) {                return;    }    Preconditions.checkArgument(labelMap.containsKey(classifiedLabel), "Label not found: " + classifiedLabel);    int correctId = labelMap.get(correctLabel);    int classifiedId = labelMap.get(classifiedLabel);    if (confusionMatrix[correctId][classifiedId] == 0.0 && count != 0) {        samples++;    }    confusionMatrix[correctId][classifiedId] = count;}
public String mahout_f2032_0()
{    return defaultLabel;}
public void mahout_f2033_0(String correctLabel, String classifiedLabel, int count)
{    putCount(correctLabel, classifiedLabel, count + getCount(correctLabel, classifiedLabel));}
public void mahout_f2034_0(String correctLabel, String classifiedLabel)
{    incrementCount(correctLabel, classifiedLabel, 1);}
public ConfusionMatrix mahout_f2035_0(ConfusionMatrix b)
{    Preconditions.checkArgument(labelMap.size() == b.getLabels().size(), "The label sizes do not match");    for (String correctLabel : this.labelMap.keySet()) {        for (String classifiedLabel : this.labelMap.keySet()) {            incrementCount(correctLabel, classifiedLabel, b.getCount(correctLabel, classifiedLabel));        }    }    return this;}
public Matrix mahout_f2036_0()
{    int length = confusionMatrix.length;    Matrix m = new DenseMatrix(length, length);    for (int r = 0; r < length; r++) {        for (int c = 0; c < length; c++) {            m.set(r, c, confusionMatrix[r][c]);        }    }    Map<String, Integer> labels = new HashMap<>();    for (Map.Entry<String, Integer> entry : labelMap.entrySet()) {        labels.put(entry.getKey(), entry.getValue());    }    m.setRowLabelBindings(labels);    m.setColumnLabelBindings(labels);    return m;}
public void mahout_f2037_0(Matrix m)
{    int length = confusionMatrix.length;    if (m.numRows() != m.numCols()) {        throw new IllegalArgumentException("ConfusionMatrix: matrix(" + m.numRows() + ',' + m.numCols() + ") must be square");    }    for (int r = 0; r < length; r++) {        for (int c = 0; c < length; c++) {            confusionMatrix[r][c] = (int) Math.round(m.get(r, c));        }    }    Map<String, Integer> labels = m.getRowLabelBindings();    if (labels == null) {        labels = m.getColumnLabelBindings();    }    if (labels != null) {        String[] sorted = sortLabels(labels);        verifyLabels(length, sorted);        labelMap.clear();        for (int i = 0; i < length; i++) {            labelMap.put(sorted[i], i);        }    }}
private static String[] mahout_f2038_0(Map<String, Integer> labels)
{    String[] sorted = new String[labels.size()];    for (Map.Entry<String, Integer> entry : labels.entrySet()) {        sorted[entry.getValue()] = entry.getKey();    }    return sorted;}
private static void mahout_f2039_0(int length, String[] sorted)
{    Preconditions.checkArgument(sorted.length == length, "One label, one row");    for (int i = 0; i < length; i++) {        if (sorted[i] == null) {            Preconditions.checkArgument(false, "One label, one row");        }    }}
public String mahout_f2040_0()
{    StringBuilder returnString = new StringBuilder(200);    returnString.append("=======================================================").append('\n');    returnString.append("Confusion Matrix\n");    returnString.append("-------------------------------------------------------").append('\n');    int unclassified = getTotal(defaultLabel);    for (Map.Entry<String, Integer> entry : this.labelMap.entrySet()) {        if (entry.getKey().equals(defaultLabel) && unclassified == 0) {            continue;        }        returnString.append(StringUtils.rightPad(getSmallLabel(entry.getValue()), 5)).append('\t');    }    returnString.append("<--Classified as").append('\n');    for (Map.Entry<String, Integer> entry : this.labelMap.entrySet()) {        if (entry.getKey().equals(defaultLabel) && unclassified == 0) {            continue;        }        String correctLabel = entry.getKey();        int labelTotal = 0;        for (String classifiedLabel : this.labelMap.keySet()) {            if (classifiedLabel.equals(defaultLabel) && unclassified == 0) {                continue;            }            returnString.append(StringUtils.rightPad(Integer.toString(getCount(correctLabel, classifiedLabel)), 5)).append('\t');            labelTotal += getCount(correctLabel, classifiedLabel);        }        returnString.append(" |  ").append(StringUtils.rightPad(String.valueOf(labelTotal), 6)).append('\t').append(StringUtils.rightPad(getSmallLabel(entry.getValue()), 5)).append(" = ").append(correctLabel).append('\n');    }    if (unclassified > 0) {        returnString.append("Default Category: ").append(defaultLabel).append(": ").append(unclassified).append('\n');    }    returnString.append('\n');    return returnString.toString();}
 static String mahout_f2041_0(int i)
{    int val = i;    StringBuilder returnString = new StringBuilder();    do {        int n = val % 26;        returnString.insert(0, (char) ('a' + n));        val /= 26;    } while (val > 0);    return returnString.toString();}
public Node mahout_f2042_1(Random rng)
{        Arrays.fill(sampled, false);    Data bag = data.bagging(rng, sampled);        return treeBuilder.build(rng, bag);}
public void mahout_f2043_0(int m)
{    this.m = m;}
public void mahout_f2044_0(IgSplit igSplit)
{    this.igSplit = igSplit;}
public void mahout_f2045_0(boolean complemented)
{    this.complemented = complemented;}
public void mahout_f2046_0(int minSplitNum)
{    this.minSplitNum = minSplitNum;}
public void mahout_f2047_0(double minVarianceProportion)
{    this.minVarianceProportion = minVarianceProportion;}
public Node mahout_f2048_1(Random rng, Data data)
{    if (selected == null) {        selected = new boolean[data.getDataset().nbAttributes()];                selected[data.getDataset().getLabelId()] = true;    }    if (m == 0) {                double e = data.getDataset().nbAttributes() - 1;        if (data.getDataset().isNumerical(data.getDataset().getLabelId())) {                        m = (int) Math.ceil(e / 3.0);        } else {                        m = (int) Math.ceil(Math.sqrt(e));        }    }    if (data.isEmpty()) {        return new Leaf(Double.NaN);    }    double sum = 0.0;    if (data.getDataset().isNumerical(data.getDataset().getLabelId())) {                        double sumSquared = 0.0;        for (int i = 0; i < data.size(); i++) {            double label = data.getDataset().getLabel(data.get(i));            sum += label;            sumSquared += label * label;        }                double var = sumSquared - (sum * sum) / data.size();                if (Double.compare(minVariance, Double.NaN) == 0) {            minVariance = var / data.size() * minVarianceProportion;                    }                if ((var / data.size()) < minVariance) {                        return new Leaf(sum / data.size());        }    } else {                if (isIdentical(data)) {            return new Leaf(data.majorityLabel(rng));        }        if (data.identicalLabel()) {            return new Leaf(data.getDataset().getLabel(data.get(0)));        }    }        if (fullSet == null) {        fullSet = data;    }    int[] attributes = randomAttributes(rng, selected, m);    if (attributes == null || attributes.length == 0) {                double label;        if (data.getDataset().isNumerical(data.getDataset().getLabelId())) {                        label = sum / data.size();        } else {                        label = data.majorityLabel(rng);        }                return new Leaf(label);    }    if (igSplit == null) {        if (data.getDataset().isNumerical(data.getDataset().getLabelId())) {                        igSplit = new RegressionSplit();        } else {                        igSplit = new OptIgSplit();        }    }        Split best = null;    for (int attr : attributes) {        Split split = igSplit.computeSplit(data, attr);        if (best == null || best.getIg() < split.getIg()) {            best = split;        }    }        if (best.getIg() < EPSILON) {        double label;        if (data.getDataset().isNumerical(data.getDataset().getLabelId())) {            label = sum / data.size();        } else {            label = data.majorityLabel(rng);        }                return new Leaf(label);    }        boolean alreadySelected = selected[best.getAttr()];    if (alreadySelected) {                    }    Node childNode;    if (data.getDataset().isNumerical(best.getAttr())) {        boolean[] temp = null;        Data loSubset = data.subset(Condition.lesser(best.getAttr(), best.getSplit()));        Data hiSubset = data.subset(Condition.greaterOrEquals(best.getAttr(), best.getSplit()));        if (loSubset.isEmpty() || hiSubset.isEmpty()) {                        selected[best.getAttr()] = true;        } else {                        temp = selected;            selected = cloneCategoricalAttributes(data.getDataset(), selected);        }                if (loSubset.size() < minSplitNum || hiSubset.size() < minSplitNum) {                        double label;            if (data.getDataset().isNumerical(data.getDataset().getLabelId())) {                label = sum / data.size();            } else {                label = data.majorityLabel(rng);            }                        return new Leaf(label);        }        Node loChild = build(rng, loSubset);        Node hiChild = build(rng, hiSubset);                if (temp != null) {            selected = temp;        } else {            selected[best.getAttr()] = alreadySelected;        }        childNode = new NumericalNode(best.getAttr(), best.getSplit(), loChild, hiChild);    } else {                double[] values = data.values(best.getAttr());                Collection<Double> subsetValues = null;        if (complemented) {            subsetValues = new HashSet<>();            for (double value : values) {                subsetValues.add(value);            }            values = fullSet.values(best.getAttr());        }        int cnt = 0;        Data[] subsets = new Data[values.length];        for (int index = 0; index < values.length; index++) {            if (complemented && !subsetValues.contains(values[index])) {                continue;            }            subsets[index] = data.subset(Condition.equals(best.getAttr(), values[index]));            if (subsets[index].size() >= minSplitNum) {                cnt++;            }        }                if (cnt < 2) {                        double label;            if (data.getDataset().isNumerical(data.getDataset().getLabelId())) {                label = sum / data.size();            } else {                label = data.majorityLabel(rng);            }                        return new Leaf(label);        }        selected[best.getAttr()] = true;        Node[] children = new Node[values.length];        for (int index = 0; index < values.length; index++) {            if (complemented && (subsetValues == null || !subsetValues.contains(values[index]))) {                                double label;                if (data.getDataset().isNumerical(data.getDataset().getLabelId())) {                    label = sum / data.size();                } else {                    label = data.majorityLabel(rng);                }                                children[index] = new Leaf(label);                continue;            }            children[index] = build(rng, subsets[index]);        }        selected[best.getAttr()] = alreadySelected;        childNode = new CategoricalNode(best.getAttr(), values, children);    }    return childNode;}
private boolean mahout_f2049_0(Data data)
{    if (data.isEmpty()) {        return true;    }    Instance instance = data.get(0);    for (int attr = 0; attr < selected.length; attr++) {        if (selected[attr]) {            continue;        }        for (int index = 1; index < data.size(); index++) {            if (data.get(index).get(attr) != instance.get(attr)) {                return false;            }        }    }    return true;}
private static boolean[] mahout_f2050_0(Dataset dataset, boolean[] selected)
{    boolean[] cloned = new boolean[selected.length];    for (int i = 0; i < selected.length; i++) {        cloned[i] = !dataset.isNumerical(i) && selected[i];    }    cloned[dataset.getLabelId()] = true;    return cloned;}
private static int[] mahout_f2051_1(Random rng, boolean[] selected, int m)
{        int nbNonSelected = 0;    for (boolean sel : selected) {        if (!sel) {            nbNonSelected++;        }    }    if (nbNonSelected == 0) {                return NO_ATTRIBUTES;    }    int[] result;    if (nbNonSelected <= m) {                result = new int[nbNonSelected];        int index = 0;        for (int attr = 0; attr < selected.length; attr++) {            if (!selected[attr]) {                result[index++] = attr;            }        }    } else {        result = new int[m];        for (int index = 0; index < m; index++) {                        int rind;            do {                rind = rng.nextInt(selected.length);            } while (selected[rind]);            result[index] = rind;                        selected[rind] = true;        }                for (int attr : result) {            selected[attr] = false;        }    }    return result;}
public void mahout_f2052_0(int m)
{    this.m = m;}
public Node mahout_f2053_1(Random rng, Data data)
{    if (selected == null) {        selected = new boolean[data.getDataset().nbAttributes()];                selected[data.getDataset().getLabelId()] = true;    }    if (data.isEmpty()) {        return new Leaf(-1);    }    if (isIdentical(data)) {        return new Leaf(data.majorityLabel(rng));    }    if (data.identicalLabel()) {        return new Leaf(data.getDataset().getLabel(data.get(0)));    }    int[] attributes = randomAttributes(rng, selected, m);    if (attributes == null || attributes.length == 0) {                return new Leaf(data.majorityLabel(rng));    }        Split best = null;    for (int attr : attributes) {        Split split = igSplit.computeSplit(data, attr);        if (best == null || best.getIg() < split.getIg()) {            best = split;        }    }    boolean alreadySelected = selected[best.getAttr()];    if (alreadySelected) {                    }    Node childNode;    if (data.getDataset().isNumerical(best.getAttr())) {        boolean[] temp = null;        Data loSubset = data.subset(Condition.lesser(best.getAttr(), best.getSplit()));        Data hiSubset = data.subset(Condition.greaterOrEquals(best.getAttr(), best.getSplit()));        if (loSubset.isEmpty() || hiSubset.isEmpty()) {                        selected[best.getAttr()] = true;        } else {                        temp = selected;            selected = cloneCategoricalAttributes(data.getDataset(), selected);        }        Node loChild = build(rng, loSubset);        Node hiChild = build(rng, hiSubset);                if (temp != null) {            selected = temp;        } else {            selected[best.getAttr()] = alreadySelected;        }        childNode = new NumericalNode(best.getAttr(), best.getSplit(), loChild, hiChild);    } else {                selected[best.getAttr()] = true;        double[] values = data.values(best.getAttr());        Node[] children = new Node[values.length];        for (int index = 0; index < values.length; index++) {            Data subset = data.subset(Condition.equals(best.getAttr(), values[index]));            children[index] = build(rng, subset);        }        selected[best.getAttr()] = alreadySelected;        childNode = new CategoricalNode(best.getAttr(), values, children);    }    return childNode;}
private boolean mahout_f2054_0(Data data)
{    if (data.isEmpty()) {        return true;    }    Instance instance = data.get(0);    for (int attr = 0; attr < selected.length; attr++) {        if (selected[attr]) {            continue;        }        for (int index = 1; index < data.size(); index++) {            if (data.get(index).get(attr) != instance.get(attr)) {                return false;            }        }    }    return true;}
private static boolean[] mahout_f2055_0(Dataset dataset, boolean[] selected)
{    boolean[] cloned = new boolean[selected.length];    for (int i = 0; i < selected.length; i++) {        cloned[i] = !dataset.isNumerical(i) && selected[i];    }    return cloned;}
protected static int[] mahout_f2056_1(Random rng, boolean[] selected, int m)
{        int nbNonSelected = 0;    for (boolean sel : selected) {        if (!sel) {            nbNonSelected++;        }    }    if (nbNonSelected == 0) {                return NO_ATTRIBUTES;    }    int[] result;    if (nbNonSelected <= m) {                result = new int[nbNonSelected];        int index = 0;        for (int attr = 0; attr < selected.length; attr++) {            if (!selected[attr]) {                result[index++] = attr;            }        }    } else {        result = new int[m];        for (int index = 0; index < m; index++) {                        int rind;            do {                rind = rng.nextInt(selected.length);            } while (selected[rind]);            result[index] = rind;                        selected[rind] = true;        }                for (int attr : result) {            selected[attr] = false;        }    }    return result;}
public static Condition mahout_f2057_0(int attr, double value)
{    return new Equals(attr, value);}
public static Condition mahout_f2058_0(int attr, double value)
{    return new Lesser(attr, value);}
public static Condition mahout_f2059_0(int attr, double value)
{    return new GreaterOrEquals(attr, value);}
public boolean mahout_f2060_0(Instance instance)
{    return instance.get(attr) == value;}
public boolean mahout_f2061_0(Instance v)
{    return v.get(attr) >= value;}
public boolean mahout_f2062_0(Instance instance)
{    return instance.get(attr) < value;}
public int mahout_f2063_0()
{    return instances.size();}
public boolean mahout_f2064_0()
{    return instances.isEmpty();}
public boolean mahout_f2065_0(Instance v)
{    return instances.contains(v);}
public Instance mahout_f2066_0(int index)
{    return instances.get(index);}
public Data mahout_f2067_0(Condition condition)
{    List<Instance> subset = new ArrayList<>();    for (Instance instance : instances) {        if (condition.isTrueFor(instance)) {            subset.add(instance);        }    }    return new Data(dataset, subset);}
public Data mahout_f2068_0(Random rng)
{    int datasize = size();    List<Instance> bag = new ArrayList<>(datasize);    for (int i = 0; i < datasize; i++) {        bag.add(instances.get(rng.nextInt(datasize)));    }    return new Data(dataset, bag);}
public Data mahout_f2069_0(Random rng, boolean[] sampled)
{    int datasize = size();    List<Instance> bag = new ArrayList<>(datasize);    for (int i = 0; i < datasize; i++) {        int index = rng.nextInt(datasize);        bag.add(instances.get(index));        sampled[index] = true;    }    return new Data(dataset, bag);}
public Data mahout_f2070_0(Random rng, int subsize)
{    List<Instance> subset = new ArrayList<>(subsize);    for (int i = 0; i < subsize; i++) {        subset.add(instances.remove(rng.nextInt(instances.size())));    }    return new Data(dataset, subset);}
public boolean mahout_f2071_0()
{    if (isEmpty()) {        return true;    }    Instance instance = get(0);    for (int attr = 0; attr < dataset.nbAttributes(); attr++) {        for (int index = 1; index < size(); index++) {            if (get(index).get(attr) != instance.get(attr)) {                return false;            }        }    }    return true;}
public boolean mahout_f2072_0()
{    if (isEmpty()) {        return true;    }    double label = dataset.getLabel(get(0));    for (int index = 1; index < size(); index++) {        if (dataset.getLabel(get(index)) != label) {            return false;        }    }    return true;}
public double[] mahout_f2073_0(int attr)
{    Collection<Double> result = new HashSet<>();    for (Instance instance : instances) {        result.add(instance.get(attr));    }    double[] values = new double[result.size()];    int index = 0;    for (Double value : result) {        values[index++] = value;    }    return values;}
public Data mahout_f2074_0()
{    return new Data(dataset, new ArrayList<>(instances));}
public boolean mahout_f2075_0(Object obj)
{    if (this == obj) {        return true;    }    if (!(obj instanceof Data)) {        return false;    }    Data data = (Data) obj;    return instances.equals(data.instances) && dataset.equals(data.dataset);}
public int mahout_f2076_0()
{    return instances.hashCode() + dataset.hashCode();}
public double[] mahout_f2077_0()
{    double[] labels = new double[size()];    for (int index = 0; index < labels.length; index++) {        labels[index] = dataset.getLabel(get(index));    }    return labels;}
public int mahout_f2078_0(Random rng)
{        int[] counts = new int[dataset.nblabels()];    for (int index = 0; index < size(); index++) {        counts[(int) dataset.getLabel(get(index))]++;    }        return DataUtils.maxindex(rng, counts);}
public void mahout_f2079_0(int[] counts)
{    for (int index = 0; index < size(); index++) {        counts[(int) dataset.getLabel(get(index))]++;    }}
public Dataset mahout_f2080_0()
{    return dataset;}
public Instance mahout_f2081_0(CharSequence string)
{        int nball = dataset.nbAttributes() + dataset.getIgnored().length;    String[] tokens = COMMA_SPACE.split(string);    Preconditions.checkArgument(tokens.length == nball, "Wrong number of attributes in the string: " + tokens.length + ". Must be " + nball);    int nbattrs = dataset.nbAttributes();    DenseVector vector = new DenseVector(nbattrs);    int aId = 0;    for (int attr = 0; attr < nball; attr++) {        if (!ArrayUtils.contains(dataset.getIgnored(), attr)) {            String token = tokens[attr].trim();            if ("?".equals(token)) {                                return null;            }            if (dataset.isNumerical(aId)) {                vector.set(aId++, Double.parseDouble(token));            } else {                                vector.set(aId, dataset.valueOf(aId, token));                aId++;            }        }    }    return new Instance(vector);}
private static boolean mahout_f2082_0(Attribute[] attrs, Set<String>[] values, CharSequence string, boolean regression)
{    String[] tokens = SEPARATORS.split(string);    Preconditions.checkArgument(tokens.length == attrs.length, "Wrong number of attributes in the string: " + tokens.length + ". Must be: " + attrs.length);        for (int attr = 0; attr < attrs.length; attr++) {        if (!attrs[attr].isIgnored() && "?".equals(tokens[attr])) {                        return false;        }    }    for (int attr = 0; attr < attrs.length; attr++) {        if (!attrs[attr].isIgnored()) {            String token = tokens[attr];            if (attrs[attr].isCategorical() || (!regression && attrs[attr].isLabel())) {                                if (values[attr] == null) {                    values[attr] = new HashSet<>();                }                values[attr].add(token);            } else {                try {                    Double.parseDouble(token);                } catch (NumberFormatException e) {                    return false;                }            }        }    }    return true;}
public static Data mahout_f2083_1(Dataset dataset, FileSystem fs, Path fpath) throws IOException
{    FSDataInputStream input = fs.open(fpath);    Scanner scanner = new Scanner(input, "UTF-8");    List<Instance> instances = new ArrayList<>();    DataConverter converter = new DataConverter(dataset);    while (scanner.hasNextLine()) {        String line = scanner.nextLine();        if (!line.isEmpty()) {            Instance instance = converter.convert(line);            if (instance != null) {                instances.add(instance);            } else {                                            }        } else {                    }    }    scanner.close();    return new Data(dataset, instances);}
public static Data mahout_f2084_0(Dataset dataset, FileSystem fs, Path[] pathes) throws IOException
{    List<Instance> instances = new ArrayList<>();    for (Path path : pathes) {        Data loadedData = loadData(dataset, fs, path);        for (int index = 0; index <= loadedData.size(); index++) {            instances.add(loadedData.get(index));        }    }    return new Data(dataset, instances);}
public static Data mahout_f2085_1(Dataset dataset, String[] data)
{    List<Instance> instances = new ArrayList<>();    DataConverter converter = new DataConverter(dataset);    for (String line : data) {        if (!line.isEmpty()) {            Instance instance = converter.convert(line);            if (instance != null) {                instances.add(instance);            } else {                                            }        } else {                    }    }    return new Data(dataset, instances);}
public static Dataset mahout_f2086_0(CharSequence descriptor, boolean regression, FileSystem fs, Path path) throws DescriptorException, IOException
{    Attribute[] attrs = DescriptorUtils.parseDescriptor(descriptor);    FSDataInputStream input = fs.open(path);    Scanner scanner = new Scanner(input, "UTF-8");        @SuppressWarnings("unchecked")    Set<String>[] valsets = new Set[attrs.length];    int size = 0;    while (scanner.hasNextLine()) {        String line = scanner.nextLine();        if (!line.isEmpty()) {            if (parseString(attrs, valsets, line, regression)) {                size++;            }        }    }    scanner.close();    @SuppressWarnings("unchecked")    List<String>[] values = new List[attrs.length];    for (int i = 0; i < valsets.length; i++) {        if (valsets[i] != null) {            values[i] = Lists.newArrayList(valsets[i]);        }    }    return new Dataset(attrs, values, size, regression);}
public static Dataset mahout_f2087_0(CharSequence descriptor, boolean regression, String[] data) throws DescriptorException
{    Attribute[] attrs = DescriptorUtils.parseDescriptor(descriptor);        @SuppressWarnings("unchecked")    Set<String>[] valsets = new Set[attrs.length];    int size = 0;    for (String aData : data) {        if (!aData.isEmpty()) {            if (parseString(attrs, valsets, aData, regression)) {                size++;            }        }    }    @SuppressWarnings("unchecked")    List<String>[] values = new List[attrs.length];    for (int i = 0; i < valsets.length; i++) {        if (valsets[i] != null) {            values[i] = Lists.newArrayList(valsets[i]);        }    }    return new Dataset(attrs, values, size, regression);}
public boolean mahout_f2088_0()
{    return this == NUMERICAL;}
public boolean mahout_f2089_0()
{    return this == CATEGORICAL;}
public boolean mahout_f2090_0()
{    return this == LABEL;}
public boolean mahout_f2091_0()
{    return this == IGNORED;}
private static Attribute mahout_f2092_0(String from)
{    Attribute toReturn = LABEL;    if (NUMERICAL.toString().equalsIgnoreCase(from)) {        toReturn = NUMERICAL;    } else if (CATEGORICAL.toString().equalsIgnoreCase(from)) {        toReturn = CATEGORICAL;    } else if (IGNORED.toString().equalsIgnoreCase(from)) {        toReturn = IGNORED;    }    return toReturn;}
public int mahout_f2093_0(int attr)
{    return values[attr].length;}
public String[] mahout_f2094_0()
{    return Arrays.copyOf(values[labelId], nblabels());}
public int mahout_f2095_0()
{    return values[labelId].length;}
public int mahout_f2096_0()
{    return labelId;}
public double mahout_f2097_0(Instance instance)
{    return instance.get(getLabelId());}
public Attribute mahout_f2098_0(int attr)
{    return attributes[attr];}
public int mahout_f2099_0(String label)
{    return ArrayUtils.indexOf(values[labelId], label);}
public String mahout_f2100_0(double code)
{        if (Double.isNaN(code)) {        return "unknown";    }    return values[labelId][(int) code];}
public String mahout_f2101_0()
{    return "attributes=" + Arrays.toString(attributes);}
public int mahout_f2102_0(int attr, String token)
{    Preconditions.checkArgument(!isNumerical(attr), "Only for CATEGORICAL attributes");    Preconditions.checkArgument(values != null, "Values not found (equals null)");    return ArrayUtils.indexOf(values[attr], token);}
public int[] mahout_f2103_0()
{    return ignored;}
private static int mahout_f2104_0(Attribute[] attrs)
{    int nbattrs = 0;    for (Attribute attr : attrs) {        if (!attr.isIgnored()) {            nbattrs++;        }    }    return nbattrs;}
private static void mahout_f2105_0(Attribute[] attrs, List<String>[] values)
{    Preconditions.checkArgument(attrs.length == values.length, "attrs.length != values.length");    for (int attr = 0; attr < attrs.length; attr++) {        Preconditions.checkArgument(!attrs[attr].isCategorical() || values[attr] != null, "values not found for attribute " + attr);    }}
public int mahout_f2106_0()
{    return attributes.length;}
public boolean mahout_f2107_0(int attr)
{    return attributes[attr].isNumerical();}
public boolean mahout_f2108_0(Object obj)
{    if (this == obj) {        return true;    }    if (!(obj instanceof Dataset)) {        return false;    }    Dataset dataset = (Dataset) obj;    if (!Arrays.equals(attributes, dataset.attributes)) {        return false;    }    for (int attr = 0; attr < nbAttributes(); attr++) {        if (!Arrays.equals(values[attr], dataset.values[attr])) {            return false;        }    }    return labelId == dataset.labelId && nbInstances == dataset.nbInstances;}
public int mahout_f2109_0()
{    int hashCode = labelId + 31 * nbInstances;    for (Attribute attr : attributes) {        hashCode = 31 * hashCode + attr.hashCode();    }    for (String[] valueRow : values) {        if (valueRow == null) {            continue;        }        for (String value : valueRow) {            hashCode = 31 * hashCode + value.hashCode();        }    }    return hashCode;}
public static Dataset mahout_f2110_0(Configuration conf, Path path) throws IOException
{    FileSystem fs = path.getFileSystem(conf);    long bytesToRead = fs.getFileStatus(path).getLen();    byte[] buff = new byte[Long.valueOf(bytesToRead).intValue()];    FSDataInputStream input = fs.open(path);    try {        input.readFully(buff);    } finally {        Closeables.close(input, true);    }    String json = new String(buff, Charset.defaultCharset());    return fromJSON(json);}
public String mahout_f2111_0()
{    List<Map<String, Object>> toWrite = new LinkedList<>();        int ignoredCount = 0;    for (int i = 0; i < attributes.length + ignored.length; i++) {        Map<String, Object> attribute;        int attributesIndex = i - ignoredCount;        if (ignoredCount < ignored.length && i == ignored[ignoredCount]) {                        attribute = getMap(Attribute.IGNORED, null, false);            ignoredCount++;        } else if (attributesIndex == labelId) {                        attribute = getMap(attributes[attributesIndex], values[attributesIndex], true);        } else {                        attribute = getMap(attributes[attributesIndex], values[attributesIndex], false);        }        toWrite.add(attribute);    }    try {        return OBJECT_MAPPER.writeValueAsString(toWrite);    } catch (Exception ex) {        throw new RuntimeException(ex);    }}
public static Dataset mahout_f2112_0(String json)
{    List<Map<String, Object>> fromJSON;    try {        fromJSON = OBJECT_MAPPER.readValue(json, new TypeReference<List<Map<String, Object>>>() {        });    } catch (Exception ex) {        throw new RuntimeException(ex);    }    List<Attribute> attributes = new LinkedList<>();    List<Integer> ignored = new LinkedList<>();    String[][] nominalValues = new String[fromJSON.size()][];    Dataset dataset = new Dataset();    for (int i = 0; i < fromJSON.size(); i++) {        Map<String, Object> attribute = fromJSON.get(i);        if (Attribute.fromString((String) attribute.get(TYPE)) == Attribute.IGNORED) {            ignored.add(i);        } else {            Attribute asAttribute = Attribute.fromString((String) attribute.get(TYPE));            attributes.add(asAttribute);            if ((Boolean) attribute.get(LABEL)) {                dataset.labelId = i - ignored.size();            }            if (attribute.get(VALUES) != null) {                List<String> get = (List<String>) attribute.get(VALUES);                String[] array = get.toArray(new String[get.size()]);                nominalValues[i - ignored.size()] = array;            }        }    }    dataset.attributes = attributes.toArray(new Attribute[attributes.size()]);    dataset.ignored = new int[ignored.size()];    dataset.values = nominalValues;    for (int i = 0; i < dataset.ignored.length; i++) {        dataset.ignored[i] = ignored.get(i);    }    return dataset;}
private Map<String, Object> mahout_f2113_0(Attribute type, String[] values, boolean isLabel)
{    Map<String, Object> attribute = new HashMap<>();    attribute.put(TYPE, type.toString().toLowerCase(Locale.getDefault()));    attribute.put(VALUES, values);    attribute.put(LABEL, isLabel);    return attribute;}
public static int mahout_f2114_0(int[] values)
{    int sum = 0;    for (int value : values) {        sum += value;    }    return sum;}
public static void mahout_f2115_0(int[] array1, int[] array2)
{    Preconditions.checkArgument(array1.length == array2.length, "array1.length != array2.length");    for (int index = 0; index < array1.length; index++) {        array1[index] += array2[index];    }}
public static void mahout_f2116_0(int[] array1, int[] array2)
{    Preconditions.checkArgument(array1.length == array2.length, "array1.length != array2.length");    for (int index = 0; index < array1.length; index++) {        array1[index] -= array2[index];    }}
public static int mahout_f2117_0(Random rng, int[] values)
{    int max = 0;    List<Integer> maxindices = new ArrayList<>();    for (int index = 0; index < values.length; index++) {        if (values[index] > max) {            max = values[index];            maxindices.clear();            maxindices.add(index);        } else if (values[index] == max) {            maxindices.add(index);        }    }    return maxindices.size() > 1 ? maxindices.get(rng.nextInt(maxindices.size())) : maxindices.get(0);}
public static Attribute[] mahout_f2118_0(CharSequence descriptor) throws DescriptorException
{    List<Attribute> attributes = new ArrayList<>();    for (String token : SPACE.split(descriptor)) {        token = token.toUpperCase(Locale.ENGLISH);        if ("I".equals(token)) {            attributes.add(Attribute.IGNORED);        } else if ("N".equals(token)) {            attributes.add(Attribute.NUMERICAL);        } else if ("C".equals(token)) {            attributes.add(Attribute.CATEGORICAL);        } else if ("L".equals(token)) {            attributes.add(Attribute.LABEL);        } else {            throw new DescriptorException("Bad Token : " + token);        }    }    return attributes.toArray(new Attribute[attributes.size()]);}
public static String mahout_f2119_0(CharSequence description) throws DescriptorException
{    return generateDescriptor(SPACE.split(description));}
public static String mahout_f2120_0(Iterable<String> tokens) throws DescriptorException
{    StringBuilder descriptor = new StringBuilder();    int multiplicator = 0;    for (String token : tokens) {        try {                        int number = Integer.parseInt(token);            if (number <= 0) {                throw new DescriptorException("Multiplicator (" + number + ") must be > 0");            }            if (multiplicator > 0) {                throw new DescriptorException("A multiplicator cannot be followed by another multiplicator");            }            multiplicator = number;        } catch (NumberFormatException e) {                        if (multiplicator == 0) {                multiplicator = 1;            }            for (int index = 0; index < multiplicator; index++) {                descriptor.append(token).append(' ');            }            multiplicator = 0;        }    }    return descriptor.toString().trim();}
public double mahout_f2121_0(int index)
{    return attrs.getQuick(index);}
public void mahout_f2122_0(int index, double value)
{    attrs.set(index, value);}
public boolean mahout_f2123_0(Object obj)
{    if (this == obj) {        return true;    }    if (!(obj instanceof Instance)) {        return false;    }    Instance instance = (Instance) obj;    return /*id == instance.id &&*/    attrs.equals(instance.attrs);}
public int mahout_f2124_0()
{    return /*id +*/    attrs.hashCode();}
 List<Node> mahout_f2125_0()
{    return trees;}
public void mahout_f2126_0(Data data, double[][] predictions)
{    Preconditions.checkArgument(data.size() == predictions.length, "predictions.length must be equal to data.size()");    if (data.isEmpty()) {                return;    }    int treeId = 0;    for (Node tree : trees) {        for (int index = 0; index < data.size(); index++) {            if (predictions[index] == null) {                predictions[index] = new double[trees.size()];            }            predictions[index][treeId] = tree.classify(data.get(index));        }        treeId++;    }}
public double mahout_f2127_0(Dataset dataset, Random rng, Instance instance)
{    if (dataset.isNumerical(dataset.getLabelId())) {        double sum = 0;        int cnt = 0;        for (Node tree : trees) {            double prediction = tree.classify(instance);            if (!Double.isNaN(prediction)) {                sum += prediction;                cnt++;            }        }        if (cnt > 0) {            return sum / cnt;        } else {            return Double.NaN;        }    } else {        int[] predictions = new int[dataset.nblabels()];        for (Node tree : trees) {            double prediction = tree.classify(instance);            if (!Double.isNaN(prediction)) {                predictions[(int) prediction]++;            }        }        if (DataUtils.sum(predictions) == 0) {                        return Double.NaN;        }        return DataUtils.maxindex(rng, predictions);    }}
public long mahout_f2128_0()
{    long sum = 0;    for (Node tree : trees) {        sum += tree.nbNodes();    }    return sum / trees.size();}
public long mahout_f2129_0()
{    long sum = 0;    for (Node tree : trees) {        sum += tree.nbNodes();    }    return sum;}
public long mahout_f2130_0()
{    long sum = 0;    for (Node tree : trees) {        sum += tree.maxDepth();    }    return sum / trees.size();}
public boolean mahout_f2131_0(Object obj)
{    if (this == obj) {        return true;    }    if (!(obj instanceof DecisionForest)) {        return false;    }    DecisionForest rf = (DecisionForest) obj;    return trees.size() == rf.getTrees().size() && trees.containsAll(rf.getTrees());}
public int mahout_f2132_0()
{    return trees.hashCode();}
public void mahout_f2133_0(DataOutput dataOutput) throws IOException
{    dataOutput.writeInt(trees.size());    for (Node tree : trees) {        tree.write(dataOutput);    }}
public void mahout_f2134_0(DataInput dataInput) throws IOException
{    int size = dataInput.readInt();    for (int i = 0; i < size; i++) {        trees.add(Node.read(dataInput));    }}
public static DecisionForest mahout_f2135_0(DataInput dataInput) throws IOException
{    DecisionForest forest = new DecisionForest();    forest.readFields(dataInput);    return forest;}
public static DecisionForest mahout_f2136_0(Configuration conf, Path forestPath) throws IOException
{    FileSystem fs = forestPath.getFileSystem(conf);    Path[] files;    if (fs.getFileStatus(forestPath).isDir()) {        files = DFUtils.listOutputFiles(fs, forestPath);    } else {        files = new Path[] { forestPath };    }    DecisionForest forest = null;    for (Path path : files) {        try (FSDataInputStream dataInput = new FSDataInputStream(fs.open(path))) {            if (forest == null) {                forest = read(dataInput);            } else {                forest.readFields(dataInput);            }        }    }    return forest;}
public static void mahout_f2137_0(DataOutput out, Node[] array) throws IOException
{    out.writeInt(array.length);    for (Node w : array) {        w.write(out);    }}
public static Node[] mahout_f2138_0(DataInput in) throws IOException
{    int length = in.readInt();    Node[] nodes = new Node[length];    for (int index = 0; index < length; index++) {        nodes[index] = Node.read(in);    }    return nodes;}
public static void mahout_f2139_0(DataOutput out, double[] array) throws IOException
{    out.writeInt(array.length);    for (double value : array) {        out.writeDouble(value);    }}
public static double[] mahout_f2140_0(DataInput in) throws IOException
{    int length = in.readInt();    double[] array = new double[length];    for (int index = 0; index < length; index++) {        array[index] = in.readDouble();    }    return array;}
public static void mahout_f2141_0(DataOutput out, int[] array) throws IOException
{    out.writeInt(array.length);    for (int value : array) {        out.writeInt(value);    }}
public static int[] mahout_f2142_0(DataInput in) throws IOException
{    int length = in.readInt();    int[] array = new int[length];    for (int index = 0; index < length; index++) {        array[index] = in.readInt();    }    return array;}
public static Path[] mahout_f2143_0(FileSystem fs, Path outputPath) throws IOException
{    List<Path> outputFiles = new ArrayList<>();    for (FileStatus s : fs.listStatus(outputPath, PathFilters.logsCRCFilter())) {        if (!s.isDir() && !s.getPath().getName().startsWith("_")) {            outputFiles.add(s.getPath());        }    }    if (outputFiles.isEmpty()) {        throw new IOException("No output found !");    }    return outputFiles.toArray(new Path[outputFiles.size()]);}
public static String mahout_f2144_0(long milli)
{    long seconds = milli / 1000;    milli %= 1000;    long minutes = seconds / 60;    seconds %= 60;    long hours = minutes / 60;    minutes %= 60;    return hours + "h " + minutes + "m " + seconds + "s " + milli;}
public static void mahout_f2145_0(Configuration conf, Path path, Writable writable) throws IOException
{    FileSystem fs = path.getFileSystem(conf);    try (FSDataOutputStream out = fs.create(path)) {        writable.write(out);    }}
public static void mahout_f2146_0(Configuration conf, Path path, String string) throws IOException
{    try (DataOutputStream out = path.getFileSystem(conf).create(path)) {        out.write(string.getBytes(Charset.defaultCharset()));    }}
public static double mahout_f2147_0(double[] labels, double[] predictions)
{    Preconditions.checkArgument(labels.length == predictions.length, "labels.length != predictions.length");        double nberrors = 0;        double datasize = 0;    for (int index = 0; index < labels.length; index++) {        if (predictions[index] == -1) {                        continue;        }        if (predictions[index] != labels[index]) {            nberrors++;        }        datasize++;    }    return nberrors / datasize;}
protected Path mahout_f2148_0()
{    return dataPath;}
public static int mahout_f2149_0(Configuration conf)
{    return conf.getInt("mapred.map.tasks", -1);}
protected static boolean mahout_f2150_0(Configuration conf)
{    return conf.getBoolean("debug.mahout.rf.output", true);}
public static Long mahout_f2151_0(Configuration conf)
{    String seed = conf.get("mahout.rf.random.seed");    if (seed == null) {        return null;    }    return Long.valueOf(seed);}
private static void mahout_f2152_0(Configuration conf, long seed)
{    conf.setLong("mahout.rf.random.seed", seed);}
public static TreeBuilder mahout_f2153_0(Configuration conf)
{    String string = conf.get("mahout.rf.treebuilder");    if (string == null) {        return null;    }    return StringUtils.fromString(string);}
private static void mahout_f2154_0(Configuration conf, TreeBuilder treeBuilder)
{    conf.set("mahout.rf.treebuilder", StringUtils.toString(treeBuilder));}
public static int mahout_f2155_0(Configuration conf)
{    return conf.getInt("mahout.rf.nbtrees", -1);}
public static void mahout_f2156_0(Configuration conf, int nbTrees)
{    Preconditions.checkArgument(nbTrees > 0, "nbTrees should be greater than 0");    conf.setInt("mahout.rf.nbtrees", nbTrees);}
public void mahout_f2157_0(String name)
{    outputDirName = name;}
protected Path mahout_f2158_0(Configuration conf) throws IOException
{            FileSystem fs = FileSystem.get(conf);    return new Path(fs.getWorkingDirectory(), outputDirName);}
public static Path mahout_f2159_0(Configuration conf, int index) throws IOException
{    Path[] files = HadoopUtil.getCachedFiles(conf);    if (files.length <= index) {        throw new IOException("path not found in the DistributedCache");    }    return files[index];}
public static Dataset mahout_f2160_0(Configuration conf) throws IOException
{    Path datasetPath = getDistributedCacheFile(conf, 0);    return Dataset.load(conf, datasetPath);}
protected boolean mahout_f2161_0(Job job) throws ClassNotFoundException, IOException, InterruptedException
{    return job.waitForCompletion(true);}
public DecisionForest mahout_f2162_1(int nbTrees) throws IOException, ClassNotFoundException, InterruptedException
{        Path outputPath = getOutputPath(conf);    FileSystem fs = outputPath.getFileSystem(conf);        if (fs.exists(outputPath)) {        throw new IOException("Output path already exists : " + outputPath);    }    if (seed != null) {        setRandomSeed(conf, seed);    }    setNbTrees(conf, nbTrees);    setTreeBuilder(conf, treeBuilder);        DistributedCache.addCacheFile(datasetPath.toUri(), conf);    Job job = new Job(conf, "decision forest builder");        configureJob(job);        if (!runJob(job)) {                return null;    }    if (isOutput(conf)) {                DecisionForest forest = parseOutput(job);        HadoopUtil.delete(conf, outputPath);        return forest;    }    return null;}
public static void mahout_f2163_0(InputSplit[] splits)
{    Arrays.sort(splits, new Comparator<InputSplit>() {        @Override        public int compare(InputSplit a, InputSplit b) {            try {                long left = a.getLength();                long right = b.getLength();                if (left == right) {                    return 0;                } else if (left < right) {                    return 1;                } else {                    return -1;                }            } catch (IOException ie) {                throw new IllegalStateException("Problem getting input split size", ie);            } catch (InterruptedException ie) {                throw new IllegalStateException("Problem getting input split size", ie);            }        }    });}
public int mahout_f2164_0(InputSplit a, InputSplit b)
{    try {        long left = a.getLength();        long right = b.getLength();        if (left == right) {            return 0;        } else if (left < right) {            return 1;        } else {            return -1;        }    } catch (IOException ie) {        throw new IllegalStateException("Problem getting input split size", ie);    } catch (InterruptedException ie) {        throw new IllegalStateException("Problem getting input split size", ie);    }}
public double[][] mahout_f2165_0()
{    return results;}
private void mahout_f2166_0(Job job) throws IOException
{    job.setJarByClass(Classifier.class);    FileInputFormat.setInputPaths(job, inputPath);    FileOutputFormat.setOutputPath(job, mappersOutputPath);    job.setOutputKeyClass(DoubleWritable.class);    job.setOutputValueClass(Text.class);    job.setMapperClass(CMapper.class);        job.setNumReduceTasks(0);    job.setInputFormatClass(CTextInputFormat.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);}
public void mahout_f2167_1() throws IOException, ClassNotFoundException, InterruptedException
{    FileSystem fs = FileSystem.get(conf);        if (fs.exists(outputPath)) {        throw new IOException("Output path already exists : " + outputPath);    }            DistributedCache.addCacheFile(datasetPath.toUri(), conf);        DistributedCache.addCacheFile(forestPath.toUri(), conf);    Job job = new Job(conf, "decision forest classifier");        configureJob(job);        if (!job.waitForCompletion(true)) {        throw new IllegalStateException("Job failed!");    }    parseOutput(job);    HadoopUtil.delete(conf, mappersOutputPath);}
private void mahout_f2168_0(JobContext job) throws IOException
{    Configuration conf = job.getConfiguration();    FileSystem fs = mappersOutputPath.getFileSystem(conf);    Path[] outfiles = DFUtils.listOutputFiles(fs, mappersOutputPath);        List<double[]> resList = new ArrayList<>();    for (Path path : outfiles) {        FSDataOutputStream ofile = null;        try {            for (Pair<DoubleWritable, Text> record : new SequenceFileIterable<DoubleWritable, Text>(path, true, conf)) {                double key = record.getFirst().get();                String value = record.getSecond().toString();                if (ofile == null) {                                        ofile = fs.create(new Path(outputPath, value).suffix(".out"));                } else {                                                            ofile.writeChars(value);                    ofile.writeChar('\n');                    resList.add(new double[] { key, Double.valueOf(value) });                }            }        } finally {            Closeables.close(ofile, false);        }    }    results = new double[resList.size()][2];    resList.toArray(results);}
protected boolean mahout_f2169_0(JobContext jobContext, Path path)
{    return false;}
protected void mahout_f2170_0(Context context) throws IOException, InterruptedException
{        super.setup(context);    Configuration conf = context.getConfiguration();    Path[] files = HadoopUtil.getCachedFiles(conf);    if (files.length < 2) {        throw new IOException("not enough paths in the DistributedCache");    }    dataset = Dataset.load(conf, files[0]);    converter = new DataConverter(dataset);    forest = DecisionForest.load(conf, files[1]);    if (forest == null) {        throw new InterruptedException("DecisionForest not found!");    }}
protected void mahout_f2171_0(LongWritable key, Text value, Context context) throws IOException, InterruptedException
{    if (first) {        FileSplit split = (FileSplit) context.getInputSplit();                Path path = split.getPath();        lvalue.set(path.getName());        lkey.set(key.get());        context.write(lkey, lvalue);        first = false;    }    String line = value.toString();    if (!line.isEmpty()) {        Instance instance = converter.convert(line);        double prediction = forest.classify(dataset, rng, instance);        lkey.set(dataset.getLabel(instance));        lvalue.set(Double.toString(prediction));        context.write(lkey, lvalue);    }}
protected void mahout_f2172_0(Job job) throws IOException
{    Configuration conf = job.getConfiguration();    job.setJarByClass(InMemBuilder.class);    FileOutputFormat.setOutputPath(job, getOutputPath(conf));        DistributedCache.addCacheFile(getDataPath().toUri(), conf);    job.setOutputKeyClass(IntWritable.class);    job.setOutputValueClass(MapredOutput.class);    job.setMapperClass(InMemMapper.class);        job.setNumReduceTasks(0);    job.setInputFormatClass(InMemInputFormat.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);}
protected DecisionForest mahout_f2173_0(Job job) throws IOException
{    Configuration conf = job.getConfiguration();    Map<Integer, MapredOutput> output = new HashMap<>();    Path outputPath = getOutputPath(conf);    FileSystem fs = outputPath.getFileSystem(conf);    Path[] outfiles = DFUtils.listOutputFiles(fs, outputPath);        for (Path path : outfiles) {        for (Pair<IntWritable, MapredOutput> record : new SequenceFileIterable<IntWritable, MapredOutput>(path, conf)) {            output.put(record.getFirst().get(), record.getSecond());        }    }    return processOutput(output);}
private static DecisionForest mahout_f2174_0(Map<Integer, MapredOutput> output)
{    List<Node> trees = new ArrayList<>();    for (Map.Entry<Integer, MapredOutput> entry : output.entrySet()) {        MapredOutput value = entry.getValue();        trees.add(value.getTree());    }    return new DecisionForest(trees);}
private static boolean mahout_f2175_0(Configuration conf)
{    return conf.getBoolean("debug.mahout.rf.single.seed", false);}
public RecordReader<IntWritable, NullWritable> mahout_f2176_0(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException
{    Preconditions.checkArgument(split instanceof InMemInputSplit);    return new InMemRecordReader((InMemInputSplit) split);}
public List<InputSplit> mahout_f2177_0(JobContext context) throws IOException, InterruptedException
{    Configuration conf = context.getConfiguration();    int numSplits = conf.getInt("mapred.map.tasks", -1);    return getSplits(conf, numSplits);}
public List<InputSplit> mahout_f2178_1(Configuration conf, int numSplits)
{    int nbTrees = Builder.getNbTrees(conf);    int splitSize = nbTrees / numSplits;    seed = Builder.getRandomSeed(conf);    isSingleSeed = isSingleSeed(conf);    if (rng != null && seed != null) {            }    rng = seed == null || isSingleSeed ? null : RandomUtils.getRandom(seed);    int id = 0;    List<InputSplit> splits = new ArrayList<>(numSplits);    for (int index = 0; index < numSplits - 1; index++) {        splits.add(new InMemInputSplit(id, splitSize, nextSeed()));        id += splitSize;    }        splits.add(new InMemInputSplit(id, nbTrees - id, nextSeed()));    return splits;}
private Long mahout_f2179_0()
{    if (seed == null) {        return null;    } else if (isSingleSeed) {        return seed;    } else {        return rng.nextLong();    }}
public float mahout_f2180_0() throws IOException
{    return pos == 0 ? 0.0f : (float) (pos - 1) / split.nbTrees;}
public IntWritable mahout_f2181_0() throws IOException, InterruptedException
{    return key;}
public NullWritable mahout_f2182_0() throws IOException, InterruptedException
{    return value;}
public void mahout_f2183_0(InputSplit arg0, TaskAttemptContext arg1) throws IOException, InterruptedException
{    key = new IntWritable();    value = NullWritable.get();}
public boolean mahout_f2184_0() throws IOException, InterruptedException
{    if (pos < split.nbTrees) {        key.set(split.firstId + pos);        pos++;        return true;    } else {        return false;    }}
public void mahout_f2185_0() throws IOException
{}
public int mahout_f2186_0()
{    return firstId;}
public int mahout_f2187_0()
{    return nbTrees;}
public Long mahout_f2188_0()
{    return seed;}
public long mahout_f2189_0() throws IOException
{    return nbTrees;}
public String[] mahout_f2190_0() throws IOException
{    return NO_LOCATIONS;}
public boolean mahout_f2191_0(Object obj)
{    if (this == obj) {        return true;    }    if (!(obj instanceof InMemInputSplit)) {        return false;    }    InMemInputSplit split = (InMemInputSplit) obj;    if (firstId != split.firstId || nbTrees != split.nbTrees) {        return false;    }    if (seed == null) {        return split.seed == null;    } else {        return seed.equals(split.seed);    }}
public int mahout_f2192_0()
{    return firstId + nbTrees + (seed == null ? 0 : seed.intValue());}
public String mahout_f2193_0()
{    return String.format(Locale.ENGLISH, "[firstId:%d, nbTrees:%d, seed:%d]", firstId, nbTrees, seed);}
public void mahout_f2194_0(DataInput in) throws IOException
{    firstId = in.readInt();    nbTrees = in.readInt();    boolean isSeed = in.readBoolean();    seed = isSeed ? in.readLong() : null;}
public void mahout_f2195_0(DataOutput out) throws IOException
{    out.writeInt(firstId);    out.writeInt(nbTrees);    out.writeBoolean(seed != null);    if (seed != null) {        out.writeLong(seed);    }}
public static InMemInputSplit mahout_f2196_0(DataInput in) throws IOException
{    InMemInputSplit split = new InMemInputSplit();    split.readFields(in);    return split;}
private static Data mahout_f2197_0(Configuration conf, Dataset dataset) throws IOException
{    Path dataPath = Builder.getDistributedCacheFile(conf, 1);    FileSystem fs = FileSystem.get(dataPath.toUri(), conf);    return DataLoader.loadData(dataset, fs, dataPath);}
protected void mahout_f2198_1(Context context) throws IOException, InterruptedException
{    super.setup(context);    Configuration conf = context.getConfiguration();        Data data = loadData(conf, getDataset());        bagging = new Bagging(getTreeBuilder(), data);}
protected void mahout_f2199_0(IntWritable key, NullWritable value, Context context) throws IOException, InterruptedException
{    map(key, context);}
 void mahout_f2200_1(IntWritable key, Context context) throws IOException, InterruptedException
{    initRandom((InMemInputSplit) context.getInputSplit());        Node tree = bagging.build(rng);    if (isOutput()) {                MapredOutput mrOut = new MapredOutput(tree);        context.write(key, mrOut);    }}
 void mahout_f2201_1(InMemInputSplit split)
{    if (rng == null) {                Long seed = split.getSeed();                rng = seed == null ? RandomUtils.getRandom() : RandomUtils.getRandom(seed);    }}
protected boolean mahout_f2202_0()
{    return !noOutput;}
protected TreeBuilder mahout_f2203_0()
{    return treeBuilder;}
protected Dataset mahout_f2204_0()
{    return dataset;}
protected void mahout_f2205_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    Configuration conf = context.getConfiguration();    configure(!Builder.isOutput(conf), Builder.getTreeBuilder(conf), Builder.loadDataset(conf));}
protected void mahout_f2206_0(boolean noOutput, TreeBuilder treeBuilder, Dataset dataset)
{    Preconditions.checkArgument(treeBuilder != null, "TreeBuilder not found in the Job parameters");    this.noOutput = noOutput;    this.treeBuilder = treeBuilder;    this.dataset = dataset;}
public Node mahout_f2207_0()
{    return tree;}
 int[] mahout_f2208_0()
{    return predictions;}
public void mahout_f2209_0(DataInput in) throws IOException
{    boolean readTree = in.readBoolean();    if (readTree) {        tree = Node.read(in);    }    boolean readPredictions = in.readBoolean();    if (readPredictions) {        predictions = DFUtils.readIntArray(in);    }}
public void mahout_f2210_0(DataOutput out) throws IOException
{    out.writeBoolean(tree != null);    if (tree != null) {        tree.write(out);    }    out.writeBoolean(predictions != null);    if (predictions != null) {        DFUtils.writeArray(out, predictions);    }}
public MapredOutput mahout_f2211_0()
{    return new MapredOutput(tree, predictions);}
public boolean mahout_f2212_0(Object obj)
{    if (this == obj) {        return true;    }    if (!(obj instanceof MapredOutput)) {        return false;    }    MapredOutput mo = (MapredOutput) obj;    return ((tree == null && mo.getTree() == null) || (tree != null && tree.equals(mo.getTree()))) && Arrays.equals(predictions, mo.getPredictions());}
public int mahout_f2213_0()
{    int hashCode = tree == null ? 1 : tree.hashCode();    for (int prediction : predictions) {        hashCode = 31 * hashCode + prediction;    }    return hashCode;}
public String mahout_f2214_0()
{    return "{" + tree + " | " + Arrays.toString(predictions) + '}';}
protected void mahout_f2215_1(Job job) throws IOException
{    Configuration conf = job.getConfiguration();    job.setJarByClass(PartialBuilder.class);    FileInputFormat.setInputPaths(job, getDataPath());    FileOutputFormat.setOutputPath(job, getOutputPath(conf));    job.setOutputKeyClass(TreeID.class);    job.setOutputValueClass(MapredOutput.class);    job.setMapperClass(Step1Mapper.class);        job.setNumReduceTasks(0);    job.setInputFormatClass(TextInputFormat.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);            TextInputFormat inputFormat = new TextInputFormat();    List<?> splits = inputFormat.getSplits(job);    if (splits == null || splits.isEmpty()) {            } else {        int numSplits = splits.size();                conf.setInt("mapred.map.tasks", numSplits);    }}
protected DecisionForest mahout_f2216_0(Job job) throws IOException
{    Configuration conf = job.getConfiguration();    int numTrees = Builder.getNbTrees(conf);    Path outputPath = getOutputPath(conf);    TreeID[] keys = new TreeID[numTrees];    Node[] trees = new Node[numTrees];    processOutput(job, outputPath, keys, trees);    return new DecisionForest(Arrays.asList(trees));}
protected static void mahout_f2217_0(JobContext job, Path outputPath, TreeID[] keys, Node[] trees) throws IOException
{    Preconditions.checkArgument(keys == null && trees == null || keys != null && trees != null, "if keys is null, trees should also be null");    Preconditions.checkArgument(keys == null || keys.length == trees.length, "keys.length != trees.length");    Configuration conf = job.getConfiguration();    FileSystem fs = outputPath.getFileSystem(conf);    Path[] outfiles = DFUtils.listOutputFiles(fs, outputPath);        int index = 0;    for (Path path : outfiles) {        for (Pair<TreeID, MapredOutput> record : new SequenceFileIterable<TreeID, MapredOutput>(path, conf)) {            TreeID key = record.getFirst();            MapredOutput value = record.getSecond();            if (keys != null) {                keys[index] = key;            }            if (trees != null) {                trees[index] = value.getTree();            }            index++;        }    }        if (keys != null && index != keys.length) {        throw new IllegalStateException("Some key/values are missing from the output");    }}
public int mahout_f2218_0()
{    return firstTreeId;}
protected void mahout_f2219_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    Configuration conf = context.getConfiguration();    configure(Builder.getRandomSeed(conf), conf.getInt("mapred.task.partition", -1), Builder.getNumMaps(conf), Builder.getNbTrees(conf));}
protected void mahout_f2220_1(Long seed, int partition, int numMapTasks, int numTrees)
{    converter = new DataConverter(getDataset());            if (seed == null) {        rng = RandomUtils.getRandom();    } else {        rng = RandomUtils.getRandom(seed);    }        Preconditions.checkArgument(partition >= 0, "Wrong partition ID: " + partition + ". Partition must be >= 0!");    this.partition = partition;        nbTrees = nbTrees(numMapTasks, numTrees, partition);        firstTreeId = 0;    for (int p = 0; p < partition; p++) {        firstTreeId += nbTrees(numMapTasks, numTrees, p);    }            }
public static int mahout_f2221_0(int numMaps, int numTrees, int partition)
{    int treesPerMapper = numTrees / numMaps;    int remainder = numTrees - numMaps * treesPerMapper;    return treesPerMapper + (partition < remainder ? 1 : 0);}
protected void mahout_f2222_0(LongWritable key, Text value, Context context) throws IOException, InterruptedException
{    instances.add(converter.convert(value.toString()));}
protected void mahout_f2223_1(Context context) throws IOException, InterruptedException
{            Data data = new Data(getDataset(), instances);    Bagging bagging = new Bagging(getTreeBuilder(), data);    TreeID key = new TreeID();        for (int treeId = 0; treeId < nbTrees; treeId++) {                Node tree = bagging.build(rng);        key.set(partition, firstTreeId + treeId);        if (isOutput()) {            MapredOutput emOut = new MapredOutput(tree);            context.write(key, emOut);        }        context.progress();    }}
public void mahout_f2224_0(int partition, int treeId)
{    set((long) partition * MAX_TREEID + treeId);}
public int mahout_f2225_0()
{    return (int) (get() / MAX_TREEID);}
public int mahout_f2226_0()
{    return (int) (get() % MAX_TREEID);}
public TreeID mahout_f2227_0()
{    return new TreeID(partition(), treeId());}
public double mahout_f2228_0(Instance instance)
{    int index = ArrayUtils.indexOf(values, instance.get(attr));    if (index == -1) {                return Double.NaN;    }    return childs[index].classify(instance);}
public long mahout_f2229_0()
{    long max = 0;    for (Node child : childs) {        long depth = child.maxDepth();        if (depth > max) {            max = depth;        }    }    return 1 + max;}
public long mahout_f2230_0()
{    long nbNodes = 1;    for (Node child : childs) {        nbNodes += child.nbNodes();    }    return nbNodes;}
protected Type mahout_f2231_0()
{    return Type.CATEGORICAL;}
public boolean mahout_f2232_0(Object obj)
{    if (this == obj) {        return true;    }    if (!(obj instanceof CategoricalNode)) {        return false;    }    CategoricalNode node = (CategoricalNode) obj;    return attr == node.attr && Arrays.equals(values, node.values) && Arrays.equals(childs, node.childs);}
public int mahout_f2233_0()
{    int hashCode = attr;    for (double value : values) {        hashCode = 31 * hashCode + (int) Double.doubleToLongBits(value);    }    for (Node node : childs) {        hashCode = 31 * hashCode + node.hashCode();    }    return hashCode;}
protected String mahout_f2234_0()
{    StringBuilder buffer = new StringBuilder();    for (Node child : childs) {        buffer.append(child).append(',');    }    return buffer.toString();}
public void mahout_f2235_0(DataInput in) throws IOException
{    attr = in.readInt();    values = DFUtils.readDoubleArray(in);    childs = DFUtils.readNodeArray(in);}
protected void mahout_f2236_0(DataOutput out) throws IOException
{    out.writeInt(attr);    DFUtils.writeArray(out, values);    DFUtils.writeArray(out, childs);}
public double mahout_f2237_0(Instance instance)
{    return label;}
public long mahout_f2238_0()
{    return 1;}
public long mahout_f2239_0()
{    return 1;}
protected Type mahout_f2240_0()
{    return Type.LEAF;}
public boolean mahout_f2241_0(Object obj)
{    if (this == obj) {        return true;    }    if (!(obj instanceof Leaf)) {        return false;    }    Leaf leaf = (Leaf) obj;    return Math.abs(label - leaf.label) < EPSILON;}
public int mahout_f2242_0()
{    long bits = Double.doubleToLongBits(label);    return (int) (bits ^ (bits >>> 32));}
protected String mahout_f2243_0()
{    return "";}
public void mahout_f2244_0(DataInput in) throws IOException
{    label = in.readDouble();}
protected void mahout_f2245_0(DataOutput out) throws IOException
{    out.writeDouble(label);}
public static Node mahout_f2246_0(DataInput in) throws IOException
{    Type type = Type.values()[in.readInt()];    Node node;    switch(type) {        case LEAF:            node = new Leaf();            break;        case NUMERICAL:            node = new NumericalNode();            break;        case CATEGORICAL:            node = new CategoricalNode();            break;        default:            throw new IllegalStateException("This implementation is not currently supported");    }    node.readFields(in);    return node;}
public final String mahout_f2247_0()
{    return getType() + ":" + getString() + ';';}
public final void mahout_f2248_0(DataOutput out) throws IOException
{    out.writeInt(getType().ordinal());    writeNode(out);}
public double mahout_f2249_0(Instance instance)
{    if (instance.get(attr) < split) {        return loChild.classify(instance);    } else {        return hiChild.classify(instance);    }}
public long mahout_f2250_0()
{    return 1 + Math.max(loChild.maxDepth(), hiChild.maxDepth());}
public long mahout_f2251_0()
{    return 1 + loChild.nbNodes() + hiChild.nbNodes();}
protected Type mahout_f2252_0()
{    return Type.NUMERICAL;}
public boolean mahout_f2253_0(Object obj)
{    if (this == obj) {        return true;    }    if (!(obj instanceof NumericalNode)) {        return false;    }    NumericalNode node = (NumericalNode) obj;    return attr == node.attr && split == node.split && loChild.equals(node.loChild) && hiChild.equals(node.hiChild);}
public int mahout_f2254_0()
{    return attr + (int) Double.doubleToLongBits(split) + loChild.hashCode() + hiChild.hashCode();}
protected String mahout_f2255_0()
{    return loChild.toString() + ',' + hiChild.toString();}
public void mahout_f2256_0(DataInput in) throws IOException
{    attr = in.readInt();    split = in.readDouble();    loChild = Node.read(in);    hiChild = Node.read(in);}
protected void mahout_f2257_0(DataOutput out) throws IOException
{    out.writeInt(attr);    out.writeDouble(split);    loChild.write(out);    hiChild.write(out);}
public DecisionForest mahout_f2258_0(int nbTrees)
{    List<Node> trees = new ArrayList<>();    for (int treeId = 0; treeId < nbTrees; treeId++) {        trees.add(bagging.build(rng));        logProgress(((float) treeId + 1) / nbTrees);    }    return new DecisionForest(trees);}
private static void mahout_f2259_1(float progress)
{    int percent = (int) (progress * 100);    if (percent % 10 == 0) {            }}
public Split mahout_f2260_0(Data data, int attr)
{    if (data.getDataset().isNumerical(attr)) {        double[] values = data.values(attr);        double bestIg = -1;        double bestSplit = 0.0;        for (double value : values) {            double ig = numericalIg(data, attr, value);            if (ig > bestIg) {                bestIg = ig;                bestSplit = value;            }        }        return new Split(attr, bestIg, bestSplit);    } else {        double ig = categoricalIg(data, attr);        return new Split(attr, ig);    }}
 double mahout_f2261_0(Data data, int attr)
{    double[] values = data.values(attr);        double hy = entropy(data);        double hyx = 0.0;    double invDataSize = 1.0 / data.size();    for (double value : values) {        Data subset = data.subset(Condition.equals(attr, value));        hyx += subset.size() * invDataSize * entropy(subset);    }    return hy - hyx;}
 double mahout_f2262_0(Data data, int attr, double split)
{    double hy = entropy(data);    double invDataSize = 1.0 / data.size();        Data subset = data.subset(Condition.lesser(attr, split));    hy -= subset.size() * invDataSize * entropy(subset);        subset = data.subset(Condition.greaterOrEquals(attr, split));    hy -= subset.size() * invDataSize * entropy(subset);    return hy;}
protected double mahout_f2263_0(Data data)
{    double invDataSize = 1.0 / data.size();    if (counts == null) {        counts = new int[data.getDataset().nblabels()];    }    Arrays.fill(counts, 0);    data.countLabels(counts);    double entropy = 0.0;    for (int label = 0; label < data.getDataset().nblabels(); label++) {        int count = counts[label];        if (count == 0) {                        continue;        }        double p = count * invDataSize;        entropy += -p * Math.log(p) / LOG2;    }    return entropy;}
public Split mahout_f2264_0(Data data, int attr)
{    if (data.getDataset().isNumerical(attr)) {        return numericalSplit(data, attr);    } else {        return categoricalSplit(data, attr);    }}
private static Split mahout_f2265_0(Data data, int attr)
{    double[] values = data.values(attr).clone();    double[] splitPoints = chooseCategoricalSplitPoints(values);    int numLabels = data.getDataset().nblabels();    int[][] counts = new int[splitPoints.length][numLabels];    int[] countAll = new int[numLabels];    computeFrequencies(data, attr, splitPoints, counts, countAll);    int size = data.size();        double hy = entropy(countAll, size);        double hyx = 0.0;    double invDataSize = 1.0 / size;    for (int index = 0; index < splitPoints.length; index++) {        size = DataUtils.sum(counts[index]);        hyx += size * invDataSize * entropy(counts[index], size);    }    double ig = hy - hyx;    return new Split(attr, ig);}
 static void mahout_f2266_0(Data data, int attr, double[] splitPoints, int[][] counts, int[] countAll)
{    Dataset dataset = data.getDataset();    for (int index = 0; index < data.size(); index++) {        Instance instance = data.get(index);        int label = (int) dataset.getLabel(instance);        double value = instance.get(attr);        int split = 0;        while (split < splitPoints.length && value > splitPoints[split]) {            split++;        }        if (split < splitPoints.length) {            counts[split][label]++;        }                countAll[label]++;    }}
 static Split mahout_f2267_0(Data data, int attr)
{    double[] values = data.values(attr).clone();    Arrays.sort(values);    double[] splitPoints = chooseNumericSplitPoints(values);    int numLabels = data.getDataset().nblabels();    int[][] counts = new int[splitPoints.length][numLabels];    int[] countAll = new int[numLabels];    int[] countLess = new int[numLabels];    computeFrequencies(data, attr, splitPoints, counts, countAll);    int size = data.size();    double hy = entropy(countAll, size);    double invDataSize = 1.0 / size;    int best = -1;    double bestIg = -1.0;        for (int index = 0; index < splitPoints.length; index++) {        double ig = hy;        DataUtils.add(countLess, counts[index]);        DataUtils.dec(countAll, counts[index]);                size = DataUtils.sum(countLess);        ig -= size * invDataSize * entropy(countLess, size);                size = DataUtils.sum(countAll);        ig -= size * invDataSize * entropy(countAll, size);        if (ig > bestIg) {            bestIg = ig;            best = index;        }    }    if (best == -1) {        throw new IllegalStateException("no best split found !");    }    return new Split(attr, bestIg, splitPoints[best]);}
private static double[] mahout_f2268_0(double[] values)
{    if (values.length <= 1) {        return values;    }    if (values.length <= MAX_NUMERIC_SPLITS + 1) {        double[] splitPoints = new double[values.length - 1];        for (int i = 1; i < values.length; i++) {            splitPoints[i - 1] = (values[i] + values[i - 1]) / 2.0;        }        return splitPoints;    }    Percentile distribution = new Percentile();    distribution.setData(values);    double[] percentiles = new double[MAX_NUMERIC_SPLITS];    for (int i = 0; i < percentiles.length; i++) {        double p = 100.0 * ((i + 1.0) / (MAX_NUMERIC_SPLITS + 1.0));        percentiles[i] = distribution.evaluate(p);    }    return percentiles;}
private static double[] mahout_f2269_0(double[] values)
{                Collection<Double> uniqueOrderedCategories = new TreeSet<>();    for (double v : values) {        uniqueOrderedCategories.add(v);    }    double[] uniqueValues = new double[uniqueOrderedCategories.size()];    Iterator<Double> it = uniqueOrderedCategories.iterator();    for (int i = 0; i < uniqueValues.length; i++) {        uniqueValues[i] = it.next();    }    return uniqueValues;}
private static double mahout_f2270_0(int[] counts, int dataSize)
{    if (dataSize == 0) {        return 0.0;    }    double entropy = 0.0;    for (int count : counts) {        if (count > 0) {            double p = count / (double) dataSize;            entropy -= p * Math.log(p);        }    }    return entropy / LOG2;}
public int mahout_f2271_0(Instance arg0, Instance arg1)
{    return Double.compare(arg0.get(attr), arg1.get(attr));}
public Split mahout_f2272_0(Data data, int attr)
{    if (data.getDataset().isNumerical(attr)) {        return numericalSplit(data, attr);    } else {        return categoricalSplit(data, attr);    }}
private static Split mahout_f2273_0(Data data, int attr)
{    FullRunningAverage[] ra = new FullRunningAverage[data.getDataset().nbValues(attr)];    double[] sk = new double[data.getDataset().nbValues(attr)];    for (int i = 0; i < ra.length; i++) {        ra[i] = new FullRunningAverage();    }    FullRunningAverage totalRa = new FullRunningAverage();    double totalSk = 0.0;    for (int i = 0; i < data.size(); i++) {                Instance instance = data.get(i);        int value = (int) instance.get(attr);        double xk = data.getDataset().getLabel(instance);        if (ra[value].getCount() == 0) {            ra[value].addDatum(xk);            sk[value] = 0.0;        } else {            double mk = ra[value].getAverage();            ra[value].addDatum(xk);            sk[value] += (xk - mk) * (xk - ra[value].getAverage());        }                if (i == 0) {            totalRa.addDatum(xk);            totalSk = 0.0;        } else {            double mk = totalRa.getAverage();            totalRa.addDatum(xk);            totalSk += (xk - mk) * (xk - totalRa.getAverage());        }    }        double ig = totalSk;    for (double aSk : sk) {        ig -= aSk;    }    return new Split(attr, ig);}
private static Split mahout_f2274_0(Data data, int attr)
{    FullRunningAverage[] ra = new FullRunningAverage[2];    for (int i = 0; i < ra.length; i++) {        ra[i] = new FullRunningAverage();    }        Instance[] instances = new Instance[data.size()];    for (int i = 0; i < data.size(); i++) {        instances[i] = data.get(i);    }    Arrays.sort(instances, new InstanceComparator(attr));    double[] sk = new double[2];    for (Instance instance : instances) {        double xk = data.getDataset().getLabel(instance);        if (ra[1].getCount() == 0) {            ra[1].addDatum(xk);            sk[1] = 0.0;        } else {            double mk = ra[1].getAverage();            ra[1].addDatum(xk);            sk[1] += (xk - mk) * (xk - ra[1].getAverage());        }    }    double totalSk = sk[1];        double split = Double.NaN;    double preSplit = Double.NaN;    double bestVal = Double.MAX_VALUE;    double bestSk = 0.0;        for (Instance instance : instances) {        double xk = data.getDataset().getLabel(instance);        if (instance.get(attr) > preSplit) {            double curVal = sk[0] / ra[0].getCount() + sk[1] / ra[1].getCount();            if (curVal < bestVal) {                bestVal = curVal;                bestSk = sk[0] + sk[1];                split = (instance.get(attr) + preSplit) / 2.0;            }        }                if (ra[0].getCount() == 0) {            ra[0].addDatum(xk);            sk[0] = 0.0;        } else {            double mk = ra[0].getAverage();            ra[0].addDatum(xk);            sk[0] += (xk - mk) * (xk - ra[0].getAverage());        }        double mk = ra[1].getAverage();        ra[1].removeDatum(xk);        sk[1] -= (xk - mk) * (xk - ra[1].getAverage());        preSplit = instance.get(attr);    }        double ig = totalSk - bestSk;    return new Split(attr, ig, split);}
public int mahout_f2275_0()
{    return attr;}
public double mahout_f2276_0()
{    return ig;}
public double mahout_f2277_0()
{    return split;}
public String mahout_f2278_0()
{    return String.format(Locale.ENGLISH, "attr: %d, ig: %f, split: %f", attr, ig, split);}
public static int mahout_f2279_0(String[] args) throws Exception
{    return ToolRunner.run(new Describe(), args);}
public int mahout_f2280_1(String[] args) throws Exception
{    DefaultOptionBuilder obuilder = new DefaultOptionBuilder();    ArgumentBuilder abuilder = new ArgumentBuilder();    GroupBuilder gbuilder = new GroupBuilder();    Option pathOpt = obuilder.withLongName("path").withShortName("p").withRequired(true).withArgument(abuilder.withName("path").withMinimum(1).withMaximum(1).create()).withDescription("Data path").create();    Option descriptorOpt = obuilder.withLongName("descriptor").withShortName("d").withRequired(true).withArgument(abuilder.withName("descriptor").withMinimum(1).create()).withDescription("data descriptor").create();    Option descPathOpt = obuilder.withLongName("file").withShortName("f").withRequired(true).withArgument(abuilder.withName("file").withMinimum(1).withMaximum(1).create()).withDescription("Path to generated descriptor file").create();    Option regOpt = obuilder.withLongName("regression").withDescription("Regression Problem").withShortName("r").create();    Option helpOpt = obuilder.withLongName("help").withDescription("Print out help").withShortName("h").create();    Group group = gbuilder.withName("Options").withOption(pathOpt).withOption(descPathOpt).withOption(descriptorOpt).withOption(regOpt).withOption(helpOpt).create();    try {        Parser parser = new Parser();        parser.setGroup(group);        CommandLine cmdLine = parser.parse(args);        if (cmdLine.hasOption(helpOpt)) {            CommandLineUtil.printHelp(group);            return -1;        }        String dataPath = cmdLine.getValue(pathOpt).toString();        String descPath = cmdLine.getValue(descPathOpt).toString();        List<String> descriptor = convert(cmdLine.getValues(descriptorOpt));        boolean regression = cmdLine.hasOption(regOpt);                                        runTool(dataPath, descriptor, descPath, regression);    } catch (OptionException e) {                CommandLineUtil.printHelp(group);    }    return 0;}
private void mahout_f2281_1(String dataPath, Iterable<String> description, String filePath, boolean regression) throws DescriptorException, IOException
{        String descriptor = DescriptorUtils.generateDescriptor(description);    Path fPath = validateOutput(filePath);        Dataset dataset = generateDataset(descriptor, dataPath, regression);        String json = dataset.toJSON();    DFUtils.storeString(conf, fPath, json);}
private Dataset mahout_f2282_0(String descriptor, String dataPath, boolean regression) throws IOException, DescriptorException
{    Path path = new Path(dataPath);    FileSystem fs = path.getFileSystem(conf);    return DataLoader.generateDataset(descriptor, regression, fs, path);}
private Path mahout_f2283_0(String filePath) throws IOException
{    Path path = new Path(filePath);    FileSystem fs = path.getFileSystem(conf);    if (fs.exists(path)) {        throw new IllegalStateException("Descriptor's file already exists");    }    return path;}
private static List<String> mahout_f2284_0(Collection<?> values)
{    List<String> list = new ArrayList<>(values.size());    for (Object value : values) {        list.add(value.toString());    }    return list;}
public void mahout_f2285_0(Configuration entries)
{    this.conf = entries;}
public Configuration mahout_f2286_0()
{    return conf;}
public static String mahout_f2287_0(DecisionForest forest, Dataset dataset, String[] attrNames)
{    List<Node> trees;    try {        Method getTrees = forest.getClass().getDeclaredMethod("getTrees");        getTrees.setAccessible(true);        trees = (List<Node>) getTrees.invoke(forest);    } catch (IllegalAccessException e) {        throw new IllegalStateException(e);    } catch (InvocationTargetException e) {        throw new IllegalStateException(e);    } catch (NoSuchMethodException e) {        throw new IllegalStateException(e);    }    int cnt = 1;    StringBuilder buff = new StringBuilder();    for (Node tree : trees) {        buff.append("Tree[").append(cnt).append("]:");        buff.append(TreeVisualizer.toString(tree, dataset, attrNames));        buff.append('\n');        cnt++;    }    return buff.toString();}
public static String mahout_f2288_0(String forestPath, String datasetPath, String[] attrNames) throws IOException
{    Configuration conf = new Configuration();    DecisionForest forest = DecisionForest.load(conf, new Path(forestPath));    Dataset dataset = Dataset.load(conf, new Path(datasetPath));    return toString(forest, dataset, attrNames);}
public static void mahout_f2289_0(String forestPath, String datasetPath, String[] attrNames) throws IOException
{    System.out.println(toString(forestPath, datasetPath, attrNames));}
public static void mahout_f2290_1(String[] args)
{    DefaultOptionBuilder obuilder = new DefaultOptionBuilder();    ArgumentBuilder abuilder = new ArgumentBuilder();    GroupBuilder gbuilder = new GroupBuilder();    Option datasetOpt = obuilder.withLongName("dataset").withShortName("ds").withRequired(true).withArgument(abuilder.withName("dataset").withMinimum(1).withMaximum(1).create()).withDescription("Dataset path").create();    Option modelOpt = obuilder.withLongName("model").withShortName("m").withRequired(true).withArgument(abuilder.withName("path").withMinimum(1).withMaximum(1).create()).withDescription("Path to the Decision Forest").create();    Option attrNamesOpt = obuilder.withLongName("names").withShortName("n").withRequired(false).withArgument(abuilder.withName("names").withMinimum(1).create()).withDescription("Optional, Attribute names").create();    Option helpOpt = obuilder.withLongName("help").withShortName("h").withDescription("Print out help").create();    Group group = gbuilder.withName("Options").withOption(datasetOpt).withOption(modelOpt).withOption(attrNamesOpt).withOption(helpOpt).create();    try {        Parser parser = new Parser();        parser.setGroup(group);        CommandLine cmdLine = parser.parse(args);        if (cmdLine.hasOption("help")) {            CommandLineUtil.printHelp(group);            return;        }        String datasetName = cmdLine.getValue(datasetOpt).toString();        String modelName = cmdLine.getValue(modelOpt).toString();        String[] attrNames = null;        if (cmdLine.hasOption(attrNamesOpt)) {            Collection<String> names = (Collection<String>) cmdLine.getValues(attrNamesOpt);            if (!names.isEmpty()) {                attrNames = new String[names.size()];                names.toArray(attrNames);            }        }        print(modelName, datasetName, attrNames);    } catch (Exception e) {                CommandLineUtil.printHelp(group);    }}
public int mahout_f2291_1(String[] args) throws IOException, ClassNotFoundException, InterruptedException
{    DefaultOptionBuilder obuilder = new DefaultOptionBuilder();    ArgumentBuilder abuilder = new ArgumentBuilder();    GroupBuilder gbuilder = new GroupBuilder();    Option dataOpt = obuilder.withLongName("data").withShortName("d").withRequired(true).withArgument(abuilder.withName("path").withMinimum(1).withMaximum(1).create()).withDescription("Data path").create();    Option datasetOpt = obuilder.withLongName("dataset").withShortName("ds").withRequired(true).withArgument(abuilder.withName("path").withMinimum(1).create()).withDescription("dataset path").create();    Option helpOpt = obuilder.withLongName("help").withDescription("Print out help").withShortName("h").create();    Group group = gbuilder.withName("Options").withOption(dataOpt).withOption(datasetOpt).withOption(helpOpt).create();    try {        Parser parser = new Parser();        parser.setGroup(group);        CommandLine cmdLine = parser.parse(args);        if (cmdLine.hasOption(helpOpt)) {            CommandLineUtil.printHelp(group);            return 0;        }        String dataPath = cmdLine.getValue(dataOpt).toString();        String datasetPath = cmdLine.getValue(datasetOpt).toString();                        runTool(dataPath, datasetPath);    } catch (OptionException e) {                CommandLineUtil.printHelp(group);    }    return 0;}
private void mahout_f2292_1(String data, String dataset) throws IOException, ClassNotFoundException, InterruptedException
{    FileSystem fs = FileSystem.get(getConf());    Path workingDir = fs.getWorkingDirectory();    Path dataPath = new Path(data);    Path datasetPath = new Path(dataset);        FrequenciesJob job = new FrequenciesJob(new Path(workingDir, "output"), dataPath, datasetPath);    int[][] counts = job.run(getConf());            for (int[] count : counts) {            }}
public static void mahout_f2293_0(String[] args) throws Exception
{    ToolRunner.run(new Configuration(), new Frequencies(), args);}
public int[][] mahout_f2294_0(Configuration conf) throws IOException, ClassNotFoundException, InterruptedException
{        FileSystem fs = outputPath.getFileSystem(conf);    if (fs.exists(outputPath)) {        throw new IOException("Output path already exists : " + outputPath);    }        URI[] files = { datasetPath.toUri() };    DistributedCache.setCacheFiles(files, conf);    Job job = new Job(conf);    job.setJarByClass(FrequenciesJob.class);    FileInputFormat.setInputPaths(job, dataPath);    FileOutputFormat.setOutputPath(job, outputPath);    job.setMapOutputKeyClass(LongWritable.class);    job.setMapOutputValueClass(IntWritable.class);    job.setOutputKeyClass(LongWritable.class);    job.setOutputValueClass(Frequencies.class);    job.setMapperClass(FrequenciesMapper.class);    job.setReducerClass(FrequenciesReducer.class);    job.setInputFormatClass(TextInputFormat.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);        boolean succeeded = job.waitForCompletion(true);    if (!succeeded) {        throw new IllegalStateException("Job failed!");    }    int[][] counts = parseOutput(job);    HadoopUtil.delete(conf, outputPath);    return counts;}
 int[][] mahout_f2295_1(JobContext job) throws IOException
{    Configuration conf = job.getConfiguration();    int numMaps = conf.getInt("mapred.map.tasks", -1);        FileSystem fs = outputPath.getFileSystem(conf);    Path[] outfiles = DFUtils.listOutputFiles(fs, outputPath);    Frequencies[] values = new Frequencies[numMaps];        int index = 0;    for (Path path : outfiles) {        for (Frequencies value : new SequenceFileValueIterable<Frequencies>(path, conf)) {            values[index++] = value;        }    }    if (index < numMaps) {        throw new IllegalStateException("number of output Frequencies (" + index + ") is lesser than the number of mappers!");    }        Arrays.sort(values);    return Frequencies.extractCounts(values);}
protected void mahout_f2296_0(Context context) throws IOException, InterruptedException
{    Configuration conf = context.getConfiguration();    dataset = Builder.loadDataset(conf);    setup(dataset);}
 void mahout_f2297_0(Dataset dataset)
{    converter = new DataConverter(dataset);}
protected void mahout_f2298_0(LongWritable key, Text value, Context context) throws IOException, InterruptedException
{    if (firstId == null) {        firstId = new LongWritable(key.get());    }    Instance instance = converter.convert(value.toString());    context.write(firstId, new IntWritable((int) dataset.getLabel(instance)));}
protected void mahout_f2299_0(Context context) throws IOException, InterruptedException
{    Configuration conf = context.getConfiguration();    Dataset dataset = Builder.loadDataset(conf);    setup(dataset.nblabels());}
 void mahout_f2300_0(int nblabels)
{    this.nblabels = nblabels;}
protected void mahout_f2301_0(LongWritable key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException
{    int[] counts = new int[nblabels];    for (IntWritable value : values) {        counts[value.get()]++;    }    context.write(key, new Frequencies(key.get(), counts));}
public void mahout_f2302_0(DataInput in) throws IOException
{    firstId = in.readLong();    counts = DFUtils.readIntArray(in);}
public void mahout_f2303_0(DataOutput out) throws IOException
{    out.writeLong(firstId);    DFUtils.writeArray(out, counts);}
public boolean mahout_f2304_0(Object other)
{    return other instanceof Frequencies && firstId == ((Frequencies) other).firstId;}
public int mahout_f2305_0()
{    return (int) firstId;}
protected Frequencies mahout_f2306_0()
{    return new Frequencies(firstId, counts);}
public int mahout_f2307_0(Frequencies obj)
{    if (firstId < obj.firstId) {        return -1;    } else if (firstId > obj.firstId) {        return 1;    } else {        return 0;    }}
public static int[][] mahout_f2308_0(Frequencies[] partitions)
{    int[][] counts = new int[partitions.length][];    for (int p = 0; p < partitions.length; p++) {        counts[p] = partitions[p].counts;    }    return counts;}
private static String mahout_f2309_0(double value)
{    DecimalFormat df = new DecimalFormat("0.##");    return df.format(value);}
private static String mahout_f2310_0(Node node, Dataset dataset, String[] attrNames, Map<String, Field> fields, int layer)
{    StringBuilder buff = new StringBuilder();    try {        if (node instanceof CategoricalNode) {            CategoricalNode cnode = (CategoricalNode) node;            int attr = (Integer) fields.get("CategoricalNode.attr").get(cnode);            double[] values = (double[]) fields.get("CategoricalNode.values").get(cnode);            Node[] childs = (Node[]) fields.get("CategoricalNode.childs").get(cnode);            String[][] attrValues = (String[][]) fields.get("Dataset.values").get(dataset);            for (int i = 0; i < attrValues[attr].length; i++) {                int index = ArrayUtils.indexOf(values, i);                if (index < 0) {                    continue;                }                buff.append('\n');                for (int j = 0; j < layer; j++) {                    buff.append("|   ");                }                buff.append(attrNames == null ? attr : attrNames[attr]).append(" = ").append(attrValues[attr][i]);                buff.append(toStringNode(childs[index], dataset, attrNames, fields, layer + 1));            }        } else if (node instanceof NumericalNode) {            NumericalNode nnode = (NumericalNode) node;            int attr = (Integer) fields.get("NumericalNode.attr").get(nnode);            double split = (Double) fields.get("NumericalNode.split").get(nnode);            Node loChild = (Node) fields.get("NumericalNode.loChild").get(nnode);            Node hiChild = (Node) fields.get("NumericalNode.hiChild").get(nnode);            buff.append('\n');            for (int j = 0; j < layer; j++) {                buff.append("|   ");            }            buff.append(attrNames == null ? attr : attrNames[attr]).append(" < ").append(doubleToString(split));            buff.append(toStringNode(loChild, dataset, attrNames, fields, layer + 1));            buff.append('\n');            for (int j = 0; j < layer; j++) {                buff.append("|   ");            }            buff.append(attrNames == null ? attr : attrNames[attr]).append(" >= ").append(doubleToString(split));            buff.append(toStringNode(hiChild, dataset, attrNames, fields, layer + 1));        } else if (node instanceof Leaf) {            Leaf leaf = (Leaf) node;            double label = (Double) fields.get("Leaf.label").get(leaf);            if (dataset.isNumerical(dataset.getLabelId())) {                buff.append(" : ").append(doubleToString(label));            } else {                buff.append(" : ").append(dataset.getLabelString(label));            }        }    } catch (IllegalAccessException iae) {        throw new IllegalStateException(iae);    }    return buff.toString();}
private static Map<String, Field> mahout_f2311_0()
{    Map<String, Field> fields = new HashMap<>();    try {        Field m = CategoricalNode.class.getDeclaredField("attr");        m.setAccessible(true);        fields.put("CategoricalNode.attr", m);        m = CategoricalNode.class.getDeclaredField("values");        m.setAccessible(true);        fields.put("CategoricalNode.values", m);        m = CategoricalNode.class.getDeclaredField("childs");        m.setAccessible(true);        fields.put("CategoricalNode.childs", m);        m = NumericalNode.class.getDeclaredField("attr");        m.setAccessible(true);        fields.put("NumericalNode.attr", m);        m = NumericalNode.class.getDeclaredField("split");        m.setAccessible(true);        fields.put("NumericalNode.split", m);        m = NumericalNode.class.getDeclaredField("loChild");        m.setAccessible(true);        fields.put("NumericalNode.loChild", m);        m = NumericalNode.class.getDeclaredField("hiChild");        m.setAccessible(true);        fields.put("NumericalNode.hiChild", m);        m = Leaf.class.getDeclaredField("label");        m.setAccessible(true);        fields.put("Leaf.label", m);        m = Dataset.class.getDeclaredField("values");        m.setAccessible(true);        fields.put("Dataset.values", m);    } catch (NoSuchFieldException nsfe) {        throw new IllegalStateException(nsfe);    }    return fields;}
public static String mahout_f2312_0(Node tree, Dataset dataset, String[] attrNames)
{    return toStringNode(tree, dataset, attrNames, getReflectMap(), 0);}
public static void mahout_f2313_0(Node tree, Dataset dataset, String[] attrNames)
{    System.out.println(toString(tree, dataset, attrNames));}
private static String mahout_f2314_0(Node node, Instance instance, Dataset dataset, String[] attrNames, Map<String, Field> fields)
{    StringBuilder buff = new StringBuilder();    try {        if (node instanceof CategoricalNode) {            CategoricalNode cnode = (CategoricalNode) node;            int attr = (Integer) fields.get("CategoricalNode.attr").get(cnode);            double[] values = (double[]) fields.get("CategoricalNode.values").get(cnode);            Node[] childs = (Node[]) fields.get("CategoricalNode.childs").get(cnode);            String[][] attrValues = (String[][]) fields.get("Dataset.values").get(dataset);            int index = ArrayUtils.indexOf(values, instance.get(attr));            if (index >= 0) {                buff.append(attrNames == null ? attr : attrNames[attr]).append(" = ").append(attrValues[attr][(int) instance.get(attr)]);                buff.append(" -> ");                buff.append(toStringPredict(childs[index], instance, dataset, attrNames, fields));            }        } else if (node instanceof NumericalNode) {            NumericalNode nnode = (NumericalNode) node;            int attr = (Integer) fields.get("NumericalNode.attr").get(nnode);            double split = (Double) fields.get("NumericalNode.split").get(nnode);            Node loChild = (Node) fields.get("NumericalNode.loChild").get(nnode);            Node hiChild = (Node) fields.get("NumericalNode.hiChild").get(nnode);            if (instance.get(attr) < split) {                buff.append('(').append(attrNames == null ? attr : attrNames[attr]).append(" = ").append(doubleToString(instance.get(attr))).append(") < ").append(doubleToString(split));                buff.append(" -> ");                buff.append(toStringPredict(loChild, instance, dataset, attrNames, fields));            } else {                buff.append('(').append(attrNames == null ? attr : attrNames[attr]).append(" = ").append(doubleToString(instance.get(attr))).append(") >= ").append(doubleToString(split));                buff.append(" -> ");                buff.append(toStringPredict(hiChild, instance, dataset, attrNames, fields));            }        } else if (node instanceof Leaf) {            Leaf leaf = (Leaf) node;            double label = (Double) fields.get("Leaf.label").get(leaf);            if (dataset.isNumerical(dataset.getLabelId())) {                buff.append(doubleToString(label));            } else {                buff.append(dataset.getLabelString(label));            }        }    } catch (IllegalAccessException iae) {        throw new IllegalStateException(iae);    }    return buff.toString();}
public static String[] mahout_f2315_0(Node tree, Data data, String[] attrNames)
{    Map<String, Field> reflectMap = getReflectMap();    String[] prediction = new String[data.size()];    for (int i = 0; i < data.size(); i++) {        prediction[i] = toStringPredict(tree, data.get(i), data.getDataset(), attrNames, reflectMap);    }    return prediction;}
public static void mahout_f2316_0(Node tree, Data data, String[] attrNames)
{    Map<String, Field> reflectMap = getReflectMap();    for (int i = 0; i < data.size(); i++) {        System.out.println(toStringPredict(tree, data.get(i), data.getDataset(), attrNames, reflectMap));    }}
public static void mahout_f2317_1(String[] args) throws IOException
{    DefaultOptionBuilder obuilder = new DefaultOptionBuilder();    ArgumentBuilder abuilder = new ArgumentBuilder();    GroupBuilder gbuilder = new GroupBuilder();    Option dataOpt = obuilder.withLongName("data").withShortName("d").withRequired(true).withArgument(abuilder.withName("data").withMinimum(1).withMaximum(1).create()).withDescription("Data path").create();    Option datasetOpt = obuilder.withLongName("dataset").withShortName("ds").withRequired(true).withArgument(abuilder.withName("dataset").withMinimum(1).create()).withDescription("Dataset path").create();    Option outputOpt = obuilder.withLongName("output").withShortName("o").withRequired(true).withArgument(abuilder.withName("output").withMinimum(1).withMaximum(1).create()).withDescription("Path to generated files").create();    Option partitionsOpt = obuilder.withLongName("numpartitions").withShortName("p").withRequired(true).withArgument(abuilder.withName("numparts").withMinimum(1).withMinimum(1).create()).withDescription("Number of partitions to create").create();    Option helpOpt = obuilder.withLongName("help").withDescription("Print out help").withShortName("h").create();    Group group = gbuilder.withName("Options").withOption(dataOpt).withOption(outputOpt).withOption(datasetOpt).withOption(partitionsOpt).withOption(helpOpt).create();    try {        Parser parser = new Parser();        parser.setGroup(group);        CommandLine cmdLine = parser.parse(args);        if (cmdLine.hasOption(helpOpt)) {            CommandLineUtil.printHelp(group);            return;        }        String data = cmdLine.getValue(dataOpt).toString();        String dataset = cmdLine.getValue(datasetOpt).toString();        int numPartitions = Integer.parseInt(cmdLine.getValue(partitionsOpt).toString());        String output = cmdLine.getValue(outputOpt).toString();        runTool(data, dataset, output, numPartitions);    } catch (OptionException e) {                CommandLineUtil.printHelp(group);    }}
private static void mahout_f2318_1(String dataStr, String datasetStr, String output, int numPartitions) throws IOException
{    Preconditions.checkArgument(numPartitions > 0, "numPartitions <= 0");        Path outputPath = new Path(output);    Configuration conf = new Configuration();    FileSystem fs = outputPath.getFileSystem(conf);    Preconditions.checkArgument(!fs.exists(outputPath), "Output path already exists");                                File tempFile = FileUtil.createLocalTempFile(new File(""), "df.tools.UDistrib", true);    Path partsPath = new Path(tempFile.toString());    FileSystem pfs = partsPath.getFileSystem(conf);    Path[] partPaths = new Path[numPartitions];    FSDataOutputStream[] files = new FSDataOutputStream[numPartitions];    for (int p = 0; p < numPartitions; p++) {        partPaths[p] = new Path(partsPath, String.format(Locale.ENGLISH, "part.%03d", p));        files[p] = pfs.create(partPaths[p]);    }    Path datasetPath = new Path(datasetStr);    Dataset dataset = Dataset.load(conf, datasetPath);        int[] currents = new int[dataset.nblabels()];        Random random = RandomUtils.getRandom();    for (int c = 0; c < currents.length; c++) {        currents[c] = random.nextInt(numPartitions);    }        Path dataPath = new Path(dataStr);    FileSystem ifs = dataPath.getFileSystem(conf);    FSDataInputStream input = ifs.open(dataPath);    Scanner scanner = new Scanner(input, "UTF-8");    DataConverter converter = new DataConverter(dataset);    int id = 0;    while (scanner.hasNextLine()) {        if (id % 1000 == 0) {                    }        String line = scanner.nextLine();        if (line.isEmpty()) {                        continue;        }                Instance instance = converter.convert(line);        int label = (int) dataset.getLabel(instance);        files[currents[label]].writeBytes(line);        files[currents[label]].writeChar('\n');                currents[label]++;        if (currents[label] == numPartitions) {            currents[label] = 0;        }    }        scanner.close();    for (FSDataOutputStream file : files) {        Closeables.close(file, false);    }        FileUtil.copyMerge(pfs, partsPath, fs, outputPath, true, conf, null);/*     * FSDataOutputStream joined = fs.create(new Path(outputPath, "uniform.data")); for (int p = 0; p <     * numPartitions; p++) { FSDataInputStream partStream =     * fs.open(partPaths[p]);     *      * IOUtils.copyBytes(partStream, joined, conf, false);     *      * partStream.close(); }     *      * joined.close();     *      * fs.delete(partsPath, true);     */}
public void mahout_f2319_0(int trueValue, double score)
{    Preconditions.checkArgument(trueValue == 0 || trueValue == 1, "True value must be 0 or 1");    hasScore = true;    int predictedClass = score > threshold ? 1 : 0;    confusion.set(trueValue, predictedClass, confusion.get(trueValue, predictedClass) + 1);    samples++;    if (isProbabilityScore()) {        double limited = Math.max(1.0e-20, Math.min(score, 1 - 1.0e-20));        double v0 = entropy.get(trueValue, 0);        entropy.set(trueValue, 0, (Math.log1p(-limited) - v0) / samples + v0);        double v1 = entropy.get(trueValue, 1);        entropy.set(trueValue, 1, (Math.log(limited) - v1) / samples + v1);    }        DoubleArrayList buf = scores[trueValue];    if (buf.size() >= maxBufferSize) {                                                                                int index = rand.nextInt(samples);        if (index < buf.size()) {            buf.set(index, score);        }    } else {                                buf.add(score);    }}
public void mahout_f2320_0(int trueValue, int predictedClass)
{    hasScore = false;    Preconditions.checkArgument(trueValue == 0 || trueValue == 1, "True value must be 0 or 1");    confusion.set(trueValue, predictedClass, confusion.get(trueValue, predictedClass) + 1);}
public double mahout_f2321_0()
{    Preconditions.checkArgument(hasScore, "Can't compute AUC for classifier without a score");    scores[0].sort();    scores[1].sort();    double n0 = scores[0].size();    double n1 = scores[1].size();    if (n0 == 0 || n1 == 0) {        return 0.5;    }        int i0 = 0;    int i1 = 0;    int rank = 1;    double rankSum = 0;    while (i0 < n0 && i1 < n1) {        double v0 = scores[0].get(i0);        double v1 = scores[1].get(i1);        if (v0 < v1) {            i0++;            rank++;        } else if (v1 < v0) {            i1++;            rankSum += rank;            rank++;        } else {                        double tieScore = v0;                        int k0 = 0;            while (i0 < n0 && scores[0].get(i0) == tieScore) {                k0++;                i0++;            }                        int k1 = 0;            while (i1 < n1 && scores[1].get(i1) == tieScore) {                k1++;                i1++;            }                                                rankSum += (rank + (k0 + k1 - 1) / 2.0) * k1;            rank += k0 + k1;        }    }    if (i1 < n1) {        rankSum += (rank + (n1 - i1 - 1) / 2.0) * (n1 - i1);        rank += (int) (n1 - i1);    }    return (rankSum / n1 - (n1 + 1) / 2) / n0;}
public Matrix mahout_f2322_0()
{    return confusion;}
public Matrix mahout_f2323_0()
{    if (!hasScore) {                        double p = (0.5 + confusion.get(1, 1)) / (1 + confusion.get(0, 0) + confusion.get(1, 1));        entropy.set(0, 0, confusion.get(0, 0) * Math.log1p(-p));        entropy.set(0, 1, confusion.get(0, 1) * Math.log(p));        entropy.set(1, 0, confusion.get(1, 0) * Math.log1p(-p));        entropy.set(1, 1, confusion.get(1, 1) * Math.log(p));    }    return entropy;}
public void mahout_f2324_0(int maxBufferSize)
{    this.maxBufferSize = maxBufferSize;}
public boolean mahout_f2325_0()
{    return probabilityScore;}
public void mahout_f2326_0(boolean probabilityScore)
{    this.probabilityScore = probabilityScore;}
protected NaiveBayesModel mahout_f2327_0()
{    return model;}
protected double mahout_f2328_0(int label, Vector instance)
{    double result = 0.0;    for (Element e : instance.nonZeroes()) {        result += e.get() * getScoreForLabelFeature(label, e.index());    }    return result;}
public int mahout_f2329_0()
{    return model.numLabels();}
public Vector mahout_f2330_0(Vector instance)
{    return classifyFull(model.createScoringVector(), instance);}
public Vector mahout_f2331_0(Vector r, Vector instance)
{    for (int label = 0; label < model.numLabels(); label++) {        r.setQuick(label, getScoreForLabelInstance(label, instance));    }    return r;}
public double mahout_f2332_0(Vector instance)
{    throw new UnsupportedOperationException("Not supported in Naive Bayes");}
public Vector mahout_f2333_0(Vector instance)
{    throw new UnsupportedOperationException("probabilites not supported in Naive Bayes");}
public static NaiveBayesModel mahout_f2334_0(Path base, Configuration conf)
{    float alphaI = conf.getFloat(ThetaMapper.ALPHA_I, 1.0f);    boolean isComplementary = conf.getBoolean(NaiveBayesModel.COMPLEMENTARY_MODEL, true);        Vector scoresPerLabel = null;    Vector scoresPerFeature = null;    for (Pair<Text, VectorWritable> record : new SequenceFileDirIterable<Text, VectorWritable>(new Path(base, TrainNaiveBayesJob.WEIGHTS), PathType.LIST, PathFilters.partFilter(), conf)) {        String key = record.getFirst().toString();        VectorWritable value = record.getSecond();        if (key.equals(TrainNaiveBayesJob.WEIGHTS_PER_FEATURE)) {            scoresPerFeature = value.get();        } else if (key.equals(TrainNaiveBayesJob.WEIGHTS_PER_LABEL)) {            scoresPerLabel = value.get();        }    }    Preconditions.checkNotNull(scoresPerFeature);    Preconditions.checkNotNull(scoresPerLabel);    Matrix scoresPerLabelAndFeature = new SparseMatrix(scoresPerLabel.size(), scoresPerFeature.size());    for (Pair<IntWritable, VectorWritable> entry : new SequenceFileDirIterable<IntWritable, VectorWritable>(new Path(base, TrainNaiveBayesJob.SUMMED_OBSERVATIONS), PathType.LIST, PathFilters.partFilter(), conf)) {        scoresPerLabelAndFeature.assignRow(entry.getFirst().get(), entry.getSecond().get());    }        Vector perLabelThetaNormalizer = null;    if (isComplementary) {        perLabelThetaNormalizer = scoresPerLabel.like();        for (Pair<Text, VectorWritable> entry : new SequenceFileDirIterable<Text, VectorWritable>(new Path(base, TrainNaiveBayesJob.THETAS), PathType.LIST, PathFilters.partFilter(), conf)) {            if (entry.getFirst().toString().equals(TrainNaiveBayesJob.LABEL_THETA_NORMALIZER)) {                perLabelThetaNormalizer = entry.getSecond().get();            }        }        Preconditions.checkNotNull(perLabelThetaNormalizer);    }    return new NaiveBayesModel(scoresPerLabelAndFeature, scoresPerFeature, scoresPerLabel, perLabelThetaNormalizer, alphaI, isComplementary);}
public static int mahout_f2335_0(Configuration conf, Iterable<String> labels, Path indexPath) throws IOException
{    FileSystem fs = FileSystem.get(indexPath.toUri(), conf);    int i = 0;    try (SequenceFile.Writer writer = SequenceFile.createWriter(fs.getConf(), SequenceFile.Writer.file(indexPath), SequenceFile.Writer.keyClass(Text.class), SequenceFile.Writer.valueClass(IntWritable.class))) {        for (String label : labels) {            writer.append(new Text(label), new IntWritable(i++));        }    }    return i;}
public static int mahout_f2336_0(Configuration conf, Path indexPath, Iterable<Pair<Text, IntWritable>> labels) throws IOException
{    FileSystem fs = FileSystem.get(indexPath.toUri(), conf);    Collection<String> seen = new HashSet<>();    int i = 0;    try (SequenceFile.Writer writer = SequenceFile.createWriter(fs.getConf(), SequenceFile.Writer.file(indexPath), SequenceFile.Writer.keyClass(Text.class), SequenceFile.Writer.valueClass(IntWritable.class))) {        for (Object label : labels) {            String theLabel = SLASH.split(((Pair<?, ?>) label).getFirst().toString())[1];            if (!seen.contains(theLabel)) {                writer.append(new Text(theLabel), new IntWritable(i++));                seen.add(theLabel);            }        }    }    return i;}
public static Map<Integer, String> mahout_f2337_0(Configuration conf, Path indexPath)
{    Map<Integer, String> labelMap = new HashMap<>();    for (Pair<Text, IntWritable> pair : new SequenceFileIterable<Text, IntWritable>(indexPath, true, conf)) {        labelMap.put(pair.getSecond().get(), pair.getFirst().toString());    }    return labelMap;}
public static OpenObjectIntHashMap<String> mahout_f2338_0(Configuration conf) throws IOException
{    OpenObjectIntHashMap<String> index = new OpenObjectIntHashMap<>();    for (Pair<Writable, IntWritable> entry : new SequenceFileIterable<Writable, IntWritable>(HadoopUtil.getSingleCachedFile(conf), conf)) {        index.put(entry.getFirst().toString(), entry.getSecond().get());    }    return index;}
public static Map<String, Vector> mahout_f2339_0(Configuration conf) throws IOException
{    Map<String, Vector> sumVectors = new HashMap<>();    for (Pair<Text, VectorWritable> entry : new SequenceFileDirIterable<Text, VectorWritable>(HadoopUtil.getSingleCachedFile(conf), PathType.LIST, PathFilters.partFilter(), conf)) {        sumVectors.put(entry.getFirst().toString(), entry.getSecond().get());    }    return sumVectors;}
public double mahout_f2340_0(int label, int feature)
{    NaiveBayesModel model = getModel();    double weight = computeWeight(model.featureWeight(feature), model.weight(label, feature), model.totalWeightSum(), model.labelWeight(label), model.alphaI(), model.numFeatures());        return weight / model.thetaNormalizer(label);}
public static double mahout_f2341_0(double featureWeight, double featureLabelWeight, double totalWeight, double labelWeight, double alphaI, double numFeatures)
{    double numerator = featureWeight - featureLabelWeight + alphaI;    double denominator = totalWeight - labelWeight + alphaI * numFeatures;    return -Math.log(numerator / denominator);}
public double mahout_f2342_0(int label)
{    return weightsPerLabel.getQuick(label);}
public double mahout_f2343_0(int label)
{    return perlabelThetaNormalizer.get(label);}
public double mahout_f2344_0(int feature)
{    return weightsPerFeature.getQuick(feature);}
public double mahout_f2345_0(int label, int feature)
{    return weightsPerLabelAndFeature.getQuick(label, feature);}
public float mahout_f2346_0()
{    return alphaI;}
public double mahout_f2347_0()
{    return numFeatures;}
public double mahout_f2348_0()
{    return totalWeightSum;}
public int mahout_f2349_0()
{    return weightsPerLabel.size();}
public Vector mahout_f2350_0()
{    return weightsPerLabel.like();}
public boolean mahout_f2351_0()
{    return isComplementary;}
public static NaiveBayesModel mahout_f2352_0(Path output, Configuration conf) throws IOException
{    FileSystem fs = output.getFileSystem(conf);    Vector weightsPerLabel;    Vector perLabelThetaNormalizer = null;    Vector weightsPerFeature;    Matrix weightsPerLabelAndFeature;    float alphaI;    boolean isComplementary;    try (FSDataInputStream in = fs.open(new Path(output, "naiveBayesModel.bin"))) {        alphaI = in.readFloat();        isComplementary = in.readBoolean();        weightsPerFeature = VectorWritable.readVector(in);        weightsPerLabel = new DenseVector(VectorWritable.readVector(in));        if (isComplementary) {            perLabelThetaNormalizer = new DenseVector(VectorWritable.readVector(in));        }        weightsPerLabelAndFeature = new SparseRowMatrix(weightsPerLabel.size(), weightsPerFeature.size());        for (int label = 0; label < weightsPerLabelAndFeature.numRows(); label++) {            weightsPerLabelAndFeature.assignRow(label, VectorWritable.readVector(in));        }    }    NaiveBayesModel model = new NaiveBayesModel(weightsPerLabelAndFeature, weightsPerFeature, weightsPerLabel, perLabelThetaNormalizer, alphaI, isComplementary);    model.validate();    return model;}
public void mahout_f2353_0(Path output, Configuration conf) throws IOException
{    FileSystem fs = output.getFileSystem(conf);    try (FSDataOutputStream out = fs.create(new Path(output, "naiveBayesModel.bin"))) {        out.writeFloat(alphaI);        out.writeBoolean(isComplementary);        VectorWritable.writeVector(out, weightsPerFeature);        VectorWritable.writeVector(out, weightsPerLabel);        if (isComplementary) {            VectorWritable.writeVector(out, perlabelThetaNormalizer);        }        for (int row = 0; row < weightsPerLabelAndFeature.numRows(); row++) {            VectorWritable.writeVector(out, weightsPerLabelAndFeature.viewRow(row));        }    }}
public void mahout_f2354_0()
{    Preconditions.checkState(alphaI > 0, "alphaI has to be greater than 0!");    Preconditions.checkArgument(numFeatures > 0, "the vocab count has to be greater than 0!");    Preconditions.checkArgument(totalWeightSum > 0, "the totalWeightSum has to be greater than 0!");    Preconditions.checkNotNull(weightsPerLabel, "the number of labels has to be defined!");    Preconditions.checkArgument(weightsPerLabel.getNumNondefaultElements() > 0, "the number of labels has to be greater than 0!");    Preconditions.checkNotNull(weightsPerFeature, "the feature sums have to be defined");    Preconditions.checkArgument(weightsPerFeature.getNumNondefaultElements() > 0, "the feature sums have to be greater than 0!");    if (isComplementary) {        Preconditions.checkArgument(perlabelThetaNormalizer != null, "the theta normalizers have to be defined");        Preconditions.checkArgument(perlabelThetaNormalizer.getNumNondefaultElements() > 0, "the number of theta normalizers has to be greater than 0!");        Preconditions.checkArgument(Math.signum(perlabelThetaNormalizer.minValue()) == Math.signum(perlabelThetaNormalizer.maxValue()), "Theta normalizers do not all have the same sign");        Preconditions.checkArgument(perlabelThetaNormalizer.getNumNonZeroElements() == perlabelThetaNormalizer.size(), "Theta normalizers can not have zero value.");    }}
public double mahout_f2355_0(int label, int feature)
{    NaiveBayesModel model = getModel();        return computeWeight(model.weight(label, feature), model.labelWeight(label), model.alphaI(), model.numFeatures());}
public static double mahout_f2356_0(double featureLabelWeight, double labelWeight, double alphaI, double numFeatures)
{    double numerator = featureLabelWeight + alphaI;    double denominator = labelWeight + alphaI * numFeatures;    return Math.log(numerator / denominator);}
protected void mahout_f2357_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    Configuration conf = context.getConfiguration();    Path modelPath = HadoopUtil.getSingleCachedFile(conf);    NaiveBayesModel model = NaiveBayesModel.materialize(modelPath, conf);    boolean isComplementary = Boolean.parseBoolean(conf.get(TestNaiveBayesDriver.COMPLEMENTARY));        if (isComplementary) {        Preconditions.checkArgument((model.isComplemtary()), "Complementary mode in model is different than test mode");    }    if (isComplementary) {        classifier = new ComplementaryNaiveBayesClassifier(model);    } else {        classifier = new StandardNaiveBayesClassifier(model);    }}
protected void mahout_f2358_0(Text key, VectorWritable value, Context context) throws IOException, InterruptedException
{    Vector result = classifier.classifyFull(value.get());        context.write(new Text(SLASH.split(key.toString())[1]), new VectorWritable(result));}
public static void mahout_f2359_0(String[] args) throws Exception
{    ToolRunner.run(new Configuration(), new TestNaiveBayesDriver(), args);}
public int mahout_f2360_1(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption(addOption(DefaultOptionCreator.overwriteOption().create()));    addOption("model", "m", "The path to the model built during training", true);    addOption(buildOption("testComplementary", "c", "test complementary?", false, false, String.valueOf(false)));    addOption(buildOption("runSequential", "seq", "run sequential?", false, false, String.valueOf(false)));    addOption("labelIndex", "l", "The path to the location of the label index", true);    Map<String, List<String>> parsedArgs = parseArguments(args);    if (parsedArgs == null) {        return -1;    }    if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {        HadoopUtil.delete(getConf(), getOutputPath());    }    boolean sequential = hasOption("runSequential");    boolean succeeded;    if (sequential) {        runSequential();    } else {        succeeded = runMapReduce();        if (!succeeded) {            return -1;        }    }        Map<Integer, String> labelMap = BayesUtils.readLabelIndex(getConf(), new Path(getOption("labelIndex")));        SequenceFileDirIterable<Text, VectorWritable> dirIterable = new SequenceFileDirIterable<>(getOutputPath(), PathType.LIST, PathFilters.partFilter(), getConf());    ResultAnalyzer analyzer = new ResultAnalyzer(labelMap.values(), "DEFAULT");    analyzeResults(labelMap, dirIterable, analyzer);        return 0;}
private void mahout_f2361_0() throws IOException
{    boolean complementary = hasOption("testComplementary");    FileSystem fs = FileSystem.get(getConf());    NaiveBayesModel model = NaiveBayesModel.materialize(new Path(getOption("model")), getConf());        if (complementary) {        Preconditions.checkArgument((model.isComplemtary()), "Complementary mode in model is different from test mode");    }    AbstractNaiveBayesClassifier classifier;    if (complementary) {        classifier = new ComplementaryNaiveBayesClassifier(model);    } else {        classifier = new StandardNaiveBayesClassifier(model);    }    try (SequenceFile.Writer writer = SequenceFile.createWriter(fs, getConf(), new Path(getOutputPath(), "part-r-00000"), Text.class, VectorWritable.class)) {        SequenceFileDirIterable<Text, VectorWritable> dirIterable = new SequenceFileDirIterable<>(getInputPath(), PathType.LIST, PathFilters.partFilter(), getConf());                for (Pair<Text, VectorWritable> pair : dirIterable) {            writer.append(new Text(SLASH.split(pair.getFirst().toString())[1]), new VectorWritable(classifier.classifyFull(pair.getSecond().get())));        }    }}
private boolean mahout_f2362_0() throws IOException, InterruptedException, ClassNotFoundException
{    Path model = new Path(getOption("model"));    HadoopUtil.cacheFiles(model, getConf());        Job testJob = prepareJob(getInputPath(), getOutputPath(), SequenceFileInputFormat.class, BayesTestMapper.class, Text.class, VectorWritable.class, SequenceFileOutputFormat.class);        boolean complementary = hasOption("testComplementary");    testJob.getConfiguration().set(COMPLEMENTARY, String.valueOf(complementary));    return testJob.waitForCompletion(true);}
private static void mahout_f2363_0(Map<Integer, String> labelMap, SequenceFileDirIterable<Text, VectorWritable> dirIterable, ResultAnalyzer analyzer)
{    for (Pair<Text, VectorWritable> pair : dirIterable) {        int bestIdx = Integer.MIN_VALUE;        double bestScore = Long.MIN_VALUE;        for (Vector.Element element : pair.getSecond().get().all()) {            if (element.get() > bestScore) {                bestScore = element.get();                bestIdx = element.index();            }        }        if (bestIdx != Integer.MIN_VALUE) {            ClassifierResult classifierResult = new ClassifierResult(labelMap.get(bestIdx), bestScore);            analyzer.addInstance(pair.getFirst().toString(), classifierResult);        }    }}
public void mahout_f2364_0(int label, Vector perLabelWeight)
{    double labelWeight = labelWeight(label);        for (int i = 0; i < perLabelWeight.size(); i++) {        Vector.Element perLabelWeightElement = perLabelWeight.getElement(i);        updatePerLabelThetaNormalizer(label, ComplementaryNaiveBayesClassifier.computeWeight(featureWeight(perLabelWeightElement.index()), perLabelWeightElement.get(), totalWeightSum(), labelWeight, alphaI(), numFeatures()));    }}
protected double mahout_f2365_0()
{    return alphaI;}
protected double mahout_f2366_0()
{    return numFeatures;}
protected double mahout_f2367_0(int label)
{    return weightsPerLabel.get(label);}
protected double mahout_f2368_0()
{    return totalWeightSum;}
protected double mahout_f2369_0(int feature)
{    return weightsPerFeature.get(feature);}
protected void mahout_f2370_0(int label, double weight)
{    perLabelThetaNormalizer.set(label, perLabelThetaNormalizer.get(label) + Math.abs(weight));}
public Vector mahout_f2371_0()
{    return perLabelThetaNormalizer.clone();}
protected void mahout_f2372_0(Context ctx) throws IOException, InterruptedException
{    super.setup(ctx);    labelIndex = BayesUtils.readIndexFromCache(ctx.getConfiguration());}
protected void mahout_f2373_0(Text labelText, VectorWritable instance, Context ctx) throws IOException, InterruptedException
{    String label = SLASH.split(labelText.toString())[1];    if (labelIndex.containsKey(label)) {        ctx.write(new IntWritable(labelIndex.get(label)), instance);    } else {        ctx.getCounter(Counter.SKIPPED_INSTANCES).increment(1);    }}
protected void mahout_f2374_0(Context ctx) throws IOException, InterruptedException
{    super.setup(ctx);    Configuration conf = ctx.getConfiguration();    float alphaI = conf.getFloat(ALPHA_I, 1.0f);    Map<String, Vector> scores = BayesUtils.readScoresFromCache(conf);    trainer = new ComplementaryThetaTrainer(scores.get(TrainNaiveBayesJob.WEIGHTS_PER_FEATURE), scores.get(TrainNaiveBayesJob.WEIGHTS_PER_LABEL), alphaI);}
protected void mahout_f2375_0(IntWritable key, VectorWritable value, Context ctx) throws IOException, InterruptedException
{    trainer.train(key.get(), value.get());}
protected void mahout_f2376_0(Context ctx) throws IOException, InterruptedException
{    ctx.write(new Text(TrainNaiveBayesJob.LABEL_THETA_NORMALIZER), new VectorWritable(trainer.retrievePerLabelThetaNormalizer()));    super.cleanup(ctx);}
public static void mahout_f2377_0(String[] args) throws Exception
{    ToolRunner.run(new Configuration(), new TrainNaiveBayesJob(), args);}
public int mahout_f2378_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption(ALPHA_I, "a", "smoothing parameter", String.valueOf(1.0f));    addOption(buildOption(TRAIN_COMPLEMENTARY, "c", "train complementary?", false, false, String.valueOf(false)));    addOption(LABEL_INDEX, "li", "The path to store the label index in", false);    addOption(DefaultOptionCreator.overwriteOption().create());    Map<String, List<String>> parsedArgs = parseArguments(args);    if (parsedArgs == null) {        return -1;    }    if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {        HadoopUtil.delete(getConf(), getOutputPath());        HadoopUtil.delete(getConf(), getTempPath());    }    Path labPath;    String labPathStr = getOption(LABEL_INDEX);    if (labPathStr != null) {        labPath = new Path(labPathStr);    } else {        labPath = getTempPath(LABEL_INDEX);    }    long labelSize = createLabelIndex(labPath);    float alphaI = Float.parseFloat(getOption(ALPHA_I));    boolean trainComplementary = hasOption(TRAIN_COMPLEMENTARY);    HadoopUtil.setSerializations(getConf());    HadoopUtil.cacheFiles(labPath, getConf());        Job indexInstances = prepareJob(getInputPath(), getTempPath(SUMMED_OBSERVATIONS), SequenceFileInputFormat.class, IndexInstancesMapper.class, IntWritable.class, VectorWritable.class, VectorSumReducer.class, IntWritable.class, VectorWritable.class, SequenceFileOutputFormat.class);    indexInstances.setCombinerClass(VectorSumReducer.class);    boolean succeeded = indexInstances.waitForCompletion(true);    if (!succeeded) {        return -1;    }        Job weightSummer = prepareJob(getTempPath(SUMMED_OBSERVATIONS), getTempPath(WEIGHTS), SequenceFileInputFormat.class, WeightsMapper.class, Text.class, VectorWritable.class, VectorSumReducer.class, Text.class, VectorWritable.class, SequenceFileOutputFormat.class);    weightSummer.getConfiguration().set(WeightsMapper.NUM_LABELS, String.valueOf(labelSize));    weightSummer.setCombinerClass(VectorSumReducer.class);    succeeded = weightSummer.waitForCompletion(true);    if (!succeeded) {        return -1;    }        HadoopUtil.cacheFiles(getTempPath(WEIGHTS), getConf());    if (trainComplementary) {                        Job thetaSummer = prepareJob(getTempPath(SUMMED_OBSERVATIONS), getTempPath(THETAS), SequenceFileInputFormat.class, ThetaMapper.class, Text.class, VectorWritable.class, VectorSumReducer.class, Text.class, VectorWritable.class, SequenceFileOutputFormat.class);        thetaSummer.setCombinerClass(VectorSumReducer.class);        thetaSummer.getConfiguration().setFloat(ThetaMapper.ALPHA_I, alphaI);        thetaSummer.getConfiguration().setBoolean(ThetaMapper.TRAIN_COMPLEMENTARY, trainComplementary);        succeeded = thetaSummer.waitForCompletion(true);        if (!succeeded) {            return -1;        }    }        HadoopUtil.cacheFiles(getTempPath(THETAS), getConf());        getConf().setFloat(ThetaMapper.ALPHA_I, alphaI);    getConf().setBoolean(NaiveBayesModel.COMPLEMENTARY_MODEL, trainComplementary);    NaiveBayesModel naiveBayesModel = BayesUtils.readModelFromDir(getTempPath(), getConf());    naiveBayesModel.validate();    naiveBayesModel.serialize(getOutputPath(), getConf());    return 0;}
private long mahout_f2379_0(Path labPath) throws IOException
{    long labelSize = 0;    Iterable<Pair<Text, IntWritable>> iterable = new SequenceFileDirIterable<>(getInputPath(), PathType.LIST, PathFilters.logsCRCFilter(), getConf());    labelSize = BayesUtils.writeLabelIndex(getConf(), labPath, iterable);    return labelSize;}
protected void mahout_f2380_0(Context ctx) throws IOException, InterruptedException
{    super.setup(ctx);    int numLabels = Integer.parseInt(ctx.getConfiguration().get(NUM_LABELS));    Preconditions.checkArgument(numLabels > 0, "Wrong numLabels: " + numLabels + ". Must be > 0!");    weightsPerLabel = new DenseVector(numLabels);}
protected void mahout_f2381_0(IntWritable index, VectorWritable value, Context ctx) throws IOException, InterruptedException
{    Vector instance = value.get();    if (weightsPerFeature == null) {        weightsPerFeature = new RandomAccessSparseVector(instance.size(), instance.getNumNondefaultElements());    }    int label = index.get();    weightsPerFeature.assign(instance, Functions.PLUS);    weightsPerLabel.set(label, weightsPerLabel.get(label) + instance.zSum());}
protected void mahout_f2382_0(Context ctx) throws IOException, InterruptedException
{    if (weightsPerFeature != null) {        ctx.write(new Text(TrainNaiveBayesJob.WEIGHTS_PER_FEATURE), new VectorWritable(weightsPerFeature));        ctx.write(new Text(TrainNaiveBayesJob.WEIGHTS_PER_LABEL), new VectorWritable(weightsPerLabel));    }    super.cleanup(ctx);}
 double mahout_f2383_0()
{    return actual;}
 double mahout_f2384_0()
{    return result;}
public void mahout_f2385_0(double actual, double result)
{    if (results == null) {        results = new ArrayList<>();    }    results.add(new Result(actual, result));}
public void mahout_f2386_0(double[][] results)
{    for (double[] res : results) {        addInstance(res[0], res[1]);    }}
public String mahout_f2387_0()
{    double sumActual = 0.0;    double sumActualSquared = 0.0;    double sumResult = 0.0;    double sumResultSquared = 0.0;    double sumActualResult = 0.0;    double sumAbsolute = 0.0;    double sumAbsoluteSquared = 0.0;    int predictable = 0;    int unpredictable = 0;    for (Result res : results) {        double actual = res.getActual();        double result = res.getResult();        if (Double.isNaN(result)) {            unpredictable++;        } else {            sumActual += actual;            sumActualSquared += actual * actual;            sumResult += result;            sumResultSquared += result * result;            sumActualResult += actual * result;            double absolute = Math.abs(actual - result);            sumAbsolute += absolute;            sumAbsoluteSquared += absolute * absolute;            predictable++;        }    }    StringBuilder returnString = new StringBuilder();    returnString.append("=======================================================\n");    returnString.append("Summary\n");    returnString.append("-------------------------------------------------------\n");    if (predictable > 0) {        double varActual = sumActualSquared - sumActual * sumActual / predictable;        double varResult = sumResultSquared - sumResult * sumResult / predictable;        double varCo = sumActualResult - sumActual * sumResult / predictable;        double correlation;        if (varActual * varResult <= 0) {            correlation = 0.0;        } else {            correlation = varCo / Math.sqrt(varActual * varResult);        }        Locale.setDefault(Locale.US);        NumberFormat decimalFormatter = new DecimalFormat("0.####");        returnString.append(StringUtils.rightPad("Correlation coefficient", 40)).append(": ").append(StringUtils.leftPad(decimalFormatter.format(correlation), 10)).append('\n');        returnString.append(StringUtils.rightPad("Mean absolute error", 40)).append(": ").append(StringUtils.leftPad(decimalFormatter.format(sumAbsolute / predictable), 10)).append('\n');        returnString.append(StringUtils.rightPad("Root mean squared error", 40)).append(": ").append(StringUtils.leftPad(decimalFormatter.format(Math.sqrt(sumAbsoluteSquared / predictable)), 10)).append('\n');    }    returnString.append(StringUtils.rightPad("Predictable Instances", 40)).append(": ").append(StringUtils.leftPad(Integer.toString(predictable), 10)).append('\n');    returnString.append(StringUtils.rightPad("Unpredictable Instances", 40)).append(": ").append(StringUtils.leftPad(Integer.toString(unpredictable), 10)).append('\n');    returnString.append(StringUtils.rightPad("Total Regressed Instances", 40)).append(": ").append(StringUtils.leftPad(Integer.toString(results.size()), 10)).append('\n');    returnString.append('\n');    return returnString.toString();}
public ConfusionMatrix mahout_f2388_0()
{    return this.confusionMatrix;}
public boolean mahout_f2389_0(String correctLabel, ClassifierResult classifiedResult)
{    boolean result = correctLabel.equals(classifiedResult.getLabel());    if (result) {        correctlyClassified++;    } else {        incorrectlyClassified++;    }    confusionMatrix.addInstance(correctLabel, classifiedResult);    if (classifiedResult.getLogLikelihood() != Double.MAX_VALUE) {        summarizer.add(classifiedResult.getLogLikelihood());        hasLL = true;    }    return result;}
public String mahout_f2390_0()
{    StringBuilder returnString = new StringBuilder();    returnString.append('\n');    returnString.append("=======================================================\n");    returnString.append("Summary\n");    returnString.append("-------------------------------------------------------\n");    int totalClassified = correctlyClassified + incorrectlyClassified;    double percentageCorrect = (double) 100 * correctlyClassified / totalClassified;    double percentageIncorrect = (double) 100 * incorrectlyClassified / totalClassified;    NumberFormat decimalFormatter = new DecimalFormat("0.####");    returnString.append(StringUtils.rightPad("Correctly Classified Instances", 40)).append(": ").append(StringUtils.leftPad(Integer.toString(correctlyClassified), 10)).append('\t').append(StringUtils.leftPad(decimalFormatter.format(percentageCorrect), 10)).append("%\n");    returnString.append(StringUtils.rightPad("Incorrectly Classified Instances", 40)).append(": ").append(StringUtils.leftPad(Integer.toString(incorrectlyClassified), 10)).append('\t').append(StringUtils.leftPad(decimalFormatter.format(percentageIncorrect), 10)).append("%\n");    returnString.append(StringUtils.rightPad("Total Classified Instances", 40)).append(": ").append(StringUtils.leftPad(Integer.toString(totalClassified), 10)).append('\n');    returnString.append('\n');    returnString.append(confusionMatrix);    returnString.append("=======================================================\n");    returnString.append("Statistics\n");    returnString.append("-------------------------------------------------------\n");    RunningAverageAndStdDev normStats = confusionMatrix.getNormalizedStats();    returnString.append(StringUtils.rightPad("Kappa", 40)).append(StringUtils.leftPad(decimalFormatter.format(confusionMatrix.getKappa()), 10)).append('\n');    returnString.append(StringUtils.rightPad("Accuracy", 40)).append(StringUtils.leftPad(decimalFormatter.format(confusionMatrix.getAccuracy()), 10)).append("%\n");    returnString.append(StringUtils.rightPad("Reliability", 40)).append(StringUtils.leftPad(decimalFormatter.format(normStats.getAverage() * 100.00000001), 10)).append("%\n");    returnString.append(StringUtils.rightPad("Reliability (standard deviation)", 40)).append(StringUtils.leftPad(decimalFormatter.format(normStats.getStandardDeviation()), 10)).append('\n');    returnString.append(StringUtils.rightPad("Weighted precision", 40)).append(StringUtils.leftPad(decimalFormatter.format(confusionMatrix.getWeightedPrecision()), 10)).append('\n');    returnString.append(StringUtils.rightPad("Weighted recall", 40)).append(StringUtils.leftPad(decimalFormatter.format(confusionMatrix.getWeightedRecall()), 10)).append('\n');    returnString.append(StringUtils.rightPad("Weighted F1 score", 40)).append(StringUtils.leftPad(decimalFormatter.format(confusionMatrix.getWeightedF1score()), 10)).append('\n');    if (hasLL) {        returnString.append(StringUtils.rightPad("Log-likelihood", 30)).append("mean      : ").append(StringUtils.leftPad(decimalFormatter.format(summarizer.getMean()), 10)).append('\n');        returnString.append(StringUtils.rightPad("", 30)).append(StringUtils.rightPad("25%-ile   : ", 10)).append(StringUtils.leftPad(decimalFormatter.format(summarizer.getQuartile(1)), 10)).append('\n');        returnString.append(StringUtils.rightPad("", 30)).append(StringUtils.rightPad("75%-ile   : ", 10)).append(StringUtils.leftPad(decimalFormatter.format(summarizer.getQuartile(3)), 10)).append('\n');    }    return returnString.toString();}
public static void mahout_f2391_0(String[] args) throws IOException
{    DefaultOptionBuilder optionBuilder = new DefaultOptionBuilder();    ArgumentBuilder argumentBuilder = new ArgumentBuilder();    Option inputOption = DefaultOptionCreator.inputOption().create();    Option outputOption = DefaultOptionCreator.outputOption().create();    Option stateNumberOption = optionBuilder.withLongName("nrOfHiddenStates").withDescription("Number of hidden states").withShortName("nh").withArgument(argumentBuilder.withMaximum(1).withMinimum(1).withName("number").create()).withRequired(true).create();    Option observedStateNumberOption = optionBuilder.withLongName("nrOfObservedStates").withDescription("Number of observed states").withShortName("no").withArgument(argumentBuilder.withMaximum(1).withMinimum(1).withName("number").create()).withRequired(true).create();    Option epsilonOption = optionBuilder.withLongName("epsilon").withDescription("Convergence threshold").withShortName("e").withArgument(argumentBuilder.withMaximum(1).withMinimum(1).withName("number").create()).withRequired(true).create();    Option iterationsOption = optionBuilder.withLongName("max-iterations").withDescription("Maximum iterations number").withShortName("m").withArgument(argumentBuilder.withMaximum(1).withMinimum(1).withName("number").create()).withRequired(true).create();    Group optionGroup = new GroupBuilder().withOption(inputOption).withOption(outputOption).withOption(stateNumberOption).withOption(observedStateNumberOption).withOption(epsilonOption).withOption(iterationsOption).withName("Options").create();    try {        Parser parser = new Parser();        parser.setGroup(optionGroup);        CommandLine commandLine = parser.parse(args);        String input = (String) commandLine.getValue(inputOption);        String output = (String) commandLine.getValue(outputOption);        int nrOfHiddenStates = Integer.parseInt((String) commandLine.getValue(stateNumberOption));        int nrOfObservedStates = Integer.parseInt((String) commandLine.getValue(observedStateNumberOption));        double epsilon = Double.parseDouble((String) commandLine.getValue(epsilonOption));        int maxIterations = Integer.parseInt((String) commandLine.getValue(iterationsOption));                HmmModel model = new HmmModel(nrOfHiddenStates, nrOfObservedStates, new Date().getTime());        List<Integer> observations = new ArrayList<>();                try (Scanner scanner = new Scanner(new FileInputStream(input), "UTF-8")) {            while (scanner.hasNextInt()) {                observations.add(scanner.nextInt());            }        }        int[] observationsArray = new int[observations.size()];        for (int i = 0; i < observations.size(); ++i) {            observationsArray[i] = observations.get(i);        }                HmmModel trainedModel = HmmTrainer.trainBaumWelch(model, observationsArray, epsilon, maxIterations, true);                try (DataOutputStream stream = new DataOutputStream(new FileOutputStream(output))) {            LossyHmmSerializer.serialize(trainedModel, stream);        }                System.out.println("Initial probabilities: ");        for (int i = 0; i < trainedModel.getNrOfHiddenStates(); ++i) {            System.out.print(i + " ");        }        System.out.println();        for (int i = 0; i < trainedModel.getNrOfHiddenStates(); ++i) {            System.out.print(trainedModel.getInitialProbabilities().get(i) + " ");        }        System.out.println();        System.out.println("Transition matrix:");        System.out.print("  ");        for (int i = 0; i < trainedModel.getNrOfHiddenStates(); ++i) {            System.out.print(i + " ");        }        System.out.println();        for (int i = 0; i < trainedModel.getNrOfHiddenStates(); ++i) {            System.out.print(i + " ");            for (int j = 0; j < trainedModel.getNrOfHiddenStates(); ++j) {                System.out.print(trainedModel.getTransitionMatrix().get(i, j) + " ");            }            System.out.println();        }        System.out.println("Emission matrix: ");        System.out.print("  ");        for (int i = 0; i < trainedModel.getNrOfOutputStates(); ++i) {            System.out.print(i + " ");        }        System.out.println();        for (int i = 0; i < trainedModel.getNrOfHiddenStates(); ++i) {            System.out.print(i + " ");            for (int j = 0; j < trainedModel.getNrOfOutputStates(); ++j) {                System.out.print(trainedModel.getEmissionMatrix().get(i, j) + " ");            }            System.out.println();        }    } catch (OptionException e) {        CommandLineUtil.printHelp(optionGroup);    }}
public static Matrix mahout_f2392_0(HmmModel model, int[] observations, boolean scaled)
{    Matrix alpha = new DenseMatrix(observations.length, model.getNrOfHiddenStates());    forwardAlgorithm(alpha, model, observations, scaled);    return alpha;}
 static void mahout_f2393_0(Matrix alpha, HmmModel model, int[] observations, boolean scaled)
{        Vector ip = model.getInitialProbabilities();    Matrix b = model.getEmissionMatrix();    Matrix a = model.getTransitionMatrix();    if (scaled) {                for (int i = 0; i < model.getNrOfHiddenStates(); i++) {            alpha.setQuick(0, i, Math.log(ip.getQuick(i) * b.getQuick(i, observations[0])));        }                for (int t = 1; t < observations.length; t++) {            for (int i = 0; i < model.getNrOfHiddenStates(); i++) {                                double sum = Double.NEGATIVE_INFINITY;                for (int j = 0; j < model.getNrOfHiddenStates(); j++) {                    double tmp = alpha.getQuick(t - 1, j) + Math.log(a.getQuick(j, i));                    if (tmp > Double.NEGATIVE_INFINITY) {                                                sum = tmp + Math.log1p(Math.exp(sum - tmp));                    }                }                alpha.setQuick(t, i, sum + Math.log(b.getQuick(i, observations[t])));            }        }    } else {                for (int i = 0; i < model.getNrOfHiddenStates(); i++) {            alpha.setQuick(0, i, ip.getQuick(i) * b.getQuick(i, observations[0]));        }                for (int t = 1; t < observations.length; t++) {            for (int i = 0; i < model.getNrOfHiddenStates(); i++) {                double sum = 0.0;                for (int j = 0; j < model.getNrOfHiddenStates(); j++) {                    sum += alpha.getQuick(t - 1, j) * a.getQuick(j, i);                }                alpha.setQuick(t, i, sum * b.getQuick(i, observations[t]));            }        }    }}
public static Matrix mahout_f2394_0(HmmModel model, int[] observations, boolean scaled)
{        Matrix beta = new DenseMatrix(observations.length, model.getNrOfHiddenStates());        backwardAlgorithm(beta, model, observations, scaled);    return beta;}
 static void mahout_f2395_0(Matrix beta, HmmModel model, int[] observations, boolean scaled)
{        Matrix b = model.getEmissionMatrix();    Matrix a = model.getTransitionMatrix();    if (scaled) {                for (int i = 0; i < model.getNrOfHiddenStates(); i++) {            beta.setQuick(observations.length - 1, i, 0);        }                for (int t = observations.length - 2; t >= 0; t--) {            for (int i = 0; i < model.getNrOfHiddenStates(); i++) {                                double sum = Double.NEGATIVE_INFINITY;                for (int j = 0; j < model.getNrOfHiddenStates(); j++) {                    double tmp = beta.getQuick(t + 1, j) + Math.log(a.getQuick(i, j)) + Math.log(b.getQuick(j, observations[t + 1]));                    if (tmp > Double.NEGATIVE_INFINITY) {                                                sum = tmp + Math.log1p(Math.exp(sum - tmp));                    }                }                beta.setQuick(t, i, sum);            }        }    } else {                for (int i = 0; i < model.getNrOfHiddenStates(); i++) {            beta.setQuick(observations.length - 1, i, 1);        }                for (int t = observations.length - 2; t >= 0; t--) {            for (int i = 0; i < model.getNrOfHiddenStates(); i++) {                double sum = 0;                for (int j = 0; j < model.getNrOfHiddenStates(); j++) {                    sum += beta.getQuick(t + 1, j) * a.getQuick(i, j) * b.getQuick(j, observations[t + 1]);                }                beta.setQuick(t, i, sum);            }        }    }}
public static int[] mahout_f2396_0(HmmModel model, int[] observations, boolean scaled)
{            double[][] delta = new double[observations.length][model.getNrOfHiddenStates()];            int[][] phi = new int[observations.length - 1][model.getNrOfHiddenStates()];        int[] sequence = new int[observations.length];    viterbiAlgorithm(sequence, delta, phi, model, observations, scaled);    return sequence;}
 static void mahout_f2397_0(int[] sequence, double[][] delta, int[][] phi, HmmModel model, int[] observations, boolean scaled)
{        Vector ip = model.getInitialProbabilities();    Matrix b = model.getEmissionMatrix();    Matrix a = model.getTransitionMatrix();        if (scaled) {        for (int i = 0; i < model.getNrOfHiddenStates(); i++) {            delta[0][i] = Math.log(ip.getQuick(i) * b.getQuick(i, observations[0]));        }    } else {        for (int i = 0; i < model.getNrOfHiddenStates(); i++) {            delta[0][i] = ip.getQuick(i) * b.getQuick(i, observations[0]);        }    }        if (scaled) {        for (int t = 1; t < observations.length; t++) {                        for (int i = 0; i < model.getNrOfHiddenStates(); i++) {                                                                int maxState = 0;                double maxProb = delta[t - 1][0] + Math.log(a.getQuick(0, i));                for (int j = 1; j < model.getNrOfHiddenStates(); j++) {                    double prob = delta[t - 1][j] + Math.log(a.getQuick(j, i));                    if (prob > maxProb) {                        maxProb = prob;                        maxState = j;                    }                }                delta[t][i] = maxProb + Math.log(b.getQuick(i, observations[t]));                phi[t - 1][i] = maxState;            }        }    } else {        for (int t = 1; t < observations.length; t++) {                        for (int i = 0; i < model.getNrOfHiddenStates(); i++) {                                                                int maxState = 0;                double maxProb = delta[t - 1][0] * a.getQuick(0, i);                for (int j = 1; j < model.getNrOfHiddenStates(); j++) {                    double prob = delta[t - 1][j] * a.getQuick(j, i);                    if (prob > maxProb) {                        maxProb = prob;                        maxState = j;                    }                }                delta[t][i] = maxProb * b.getQuick(i, observations[t]);                phi[t - 1][i] = maxState;            }        }    }        double maxProb;    if (scaled) {        maxProb = Double.NEGATIVE_INFINITY;    } else {        maxProb = 0.0;    }    for (int i = 0; i < model.getNrOfHiddenStates(); i++) {        if (delta[observations.length - 1][i] > maxProb) {            maxProb = delta[observations.length - 1][i];            sequence[observations.length - 1] = i;        }    }        for (int t = observations.length - 2; t >= 0; t--) {        sequence[t] = phi[t][sequence[t + 1]];    }}
public static int[] mahout_f2398_0(HmmModel model, int steps)
{    return predict(model, steps, RandomUtils.getRandom());}
public static int[] mahout_f2399_0(HmmModel model, int steps, long seed)
{    return predict(model, steps, RandomUtils.getRandom(seed));}
private static int[] mahout_f2400_0(HmmModel model, int steps, Random rand)
{        Vector cip = HmmUtils.getCumulativeInitialProbabilities(model);    Matrix ctm = HmmUtils.getCumulativeTransitionMatrix(model);    Matrix com = HmmUtils.getCumulativeOutputMatrix(model);        int[] result = new int[steps];        int hiddenState = 0;    double randnr = rand.nextDouble();    while (cip.get(hiddenState) < randnr) {        hiddenState++;    }        for (int step = 0; step < steps; ++step) {                randnr = rand.nextDouble();        int outputState = 0;        while (com.get(hiddenState, outputState) < randnr) {            outputState++;        }        result[step] = outputState;                randnr = rand.nextDouble();        int nextHiddenState = 0;        while (ctm.get(hiddenState, nextHiddenState) < randnr) {            nextHiddenState++;        }        hiddenState = nextHiddenState;    }    return result;}
public static double mahout_f2401_0(HmmModel model, int[] outputSequence, boolean scaled)
{    return modelLikelihood(HmmAlgorithms.forwardAlgorithm(model, outputSequence, scaled), scaled);}
public static double mahout_f2402_0(Matrix alpha, boolean scaled)
{    double likelihood = 0;    if (scaled) {        for (int i = 0; i < alpha.numCols(); ++i) {            likelihood += Math.exp(alpha.getQuick(alpha.numRows() - 1, i));        }    } else {        for (int i = 0; i < alpha.numCols(); ++i) {            likelihood += alpha.getQuick(alpha.numRows() - 1, i);        }    }    return likelihood;}
public static double mahout_f2403_0(HmmModel model, int[] outputSequence, Matrix beta, boolean scaled)
{    double likelihood = 0;        Matrix e = model.getEmissionMatrix();    Vector pi = model.getInitialProbabilities();    int firstOutput = outputSequence[0];    if (scaled) {        for (int i = 0; i < model.getNrOfHiddenStates(); ++i) {            likelihood += pi.getQuick(i) * Math.exp(beta.getQuick(0, i)) * e.getQuick(i, firstOutput);        }    } else {        for (int i = 0; i < model.getNrOfHiddenStates(); ++i) {            likelihood += pi.getQuick(i) * beta.getQuick(0, i) * e.getQuick(i, firstOutput);        }    }    return likelihood;}
public static int[] mahout_f2404_0(HmmModel model, int[] observations, boolean scaled)
{    return HmmAlgorithms.viterbiAlgorithm(model, observations, scaled);}
public HmmModel mahout_f2405_0()
{    HmmModel model = new HmmModel(transitionMatrix.clone(), emissionMatrix.clone(), initialProbabilities.clone());    if (hiddenStateNames != null) {        model.hiddenStateNames = HashBiMap.create(hiddenStateNames);    }    if (outputStateNames != null) {        model.outputStateNames = HashBiMap.create(outputStateNames);    }    return model;}
public void mahout_f2406_0(HmmModel model)
{    this.nrOfHiddenStates = model.nrOfHiddenStates;    this.nrOfOutputStates = model.nrOfOutputStates;    this.hiddenStateNames = model.hiddenStateNames;    this.outputStateNames = model.outputStateNames;        this.initialProbabilities = model.initialProbabilities.clone();    this.emissionMatrix = model.emissionMatrix.clone();    this.transitionMatrix = model.transitionMatrix.clone();}
private void mahout_f2407_0(long seed)
{    Random rand;        if (seed == 0) {        rand = RandomUtils.getRandom();    } else {        rand = RandomUtils.getRandom(seed);    }            double sum = 0;    for (int i = 0; i < nrOfHiddenStates; i++) {        double nextRand = rand.nextDouble();        initialProbabilities.set(i, nextRand);        sum += nextRand;    }        initialProbabilities = initialProbabilities.divide(sum);        double[] values = new double[nrOfHiddenStates];    for (int i = 0; i < nrOfHiddenStates; i++) {        sum = 0;        for (int j = 0; j < nrOfHiddenStates; j++) {            values[j] = rand.nextDouble();            sum += values[j];        }                for (int j = 0; j < nrOfHiddenStates; j++) {            values[j] /= sum;        }                transitionMatrix.set(i, values);    }        values = new double[nrOfOutputStates];    for (int i = 0; i < nrOfHiddenStates; i++) {        sum = 0;        for (int j = 0; j < nrOfOutputStates; j++) {            values[j] = rand.nextDouble();            sum += values[j];        }                for (int j = 0; j < nrOfOutputStates; j++) {            values[j] /= sum;        }                emissionMatrix.set(i, values);    }}
public int mahout_f2408_0()
{    return nrOfHiddenStates;}
public int mahout_f2409_0()
{    return nrOfOutputStates;}
public Matrix mahout_f2410_0()
{    return transitionMatrix;}
public Matrix mahout_f2411_0()
{    return emissionMatrix;}
public Vector mahout_f2412_0()
{    return initialProbabilities;}
public Map<String, Integer> mahout_f2413_0()
{    return hiddenStateNames;}
public void mahout_f2414_0(String[] stateNames)
{    if (stateNames != null) {        hiddenStateNames = HashBiMap.create();        for (int i = 0; i < stateNames.length; ++i) {            hiddenStateNames.put(stateNames[i], i);        }    }}
public void mahout_f2415_0(Map<String, Integer> stateNames)
{    if (stateNames != null) {        hiddenStateNames = HashBiMap.create(stateNames);    }}
public String mahout_f2416_0(int id)
{    if (hiddenStateNames == null) {        return null;    }    return hiddenStateNames.inverse().get(id);}
public int mahout_f2417_0(String name)
{    if (hiddenStateNames == null) {        return -1;    }    Integer tmp = hiddenStateNames.get(name);    return tmp == null ? -1 : tmp;}
public Map<String, Integer> mahout_f2418_0()
{    return outputStateNames;}
public void mahout_f2419_0(String[] stateNames)
{    if (stateNames != null) {        outputStateNames = HashBiMap.create();        for (int i = 0; i < stateNames.length; ++i) {            outputStateNames.put(stateNames[i], i);        }    }}
public void mahout_f2420_0(Map<String, Integer> stateNames)
{    if (stateNames != null) {        outputStateNames = HashBiMap.create(stateNames);    }}
public String mahout_f2421_0(int id)
{    if (outputStateNames == null) {        return null;    }    return outputStateNames.inverse().get(id);}
public int mahout_f2422_0(String name)
{    if (outputStateNames == null) {        return -1;    }    Integer tmp = outputStateNames.get(name);    return tmp == null ? -1 : tmp;}
public static HmmModel mahout_f2423_0(int nrOfHiddenStates, int nrOfOutputStates, int[] observedSequence, int[] hiddenSequence, double pseudoCount)
{        pseudoCount = pseudoCount == 0 ? Double.MIN_VALUE : pseudoCount;        DenseMatrix transitionMatrix = new DenseMatrix(nrOfHiddenStates, nrOfHiddenStates);    DenseMatrix emissionMatrix = new DenseMatrix(nrOfHiddenStates, nrOfOutputStates);            transitionMatrix.assign(pseudoCount);    emissionMatrix.assign(pseudoCount);            DenseVector initialProbabilities = new DenseVector(nrOfHiddenStates);    initialProbabilities.assign(1.0 / nrOfHiddenStates);        countTransitions(transitionMatrix, emissionMatrix, observedSequence, hiddenSequence);        for (int i = 0; i < nrOfHiddenStates; i++) {                double sum = 0;        for (int j = 0; j < nrOfHiddenStates; j++) {            sum += transitionMatrix.getQuick(i, j);        }                for (int j = 0; j < nrOfHiddenStates; j++) {            transitionMatrix.setQuick(i, j, transitionMatrix.getQuick(i, j) / sum);        }                sum = 0;        for (int j = 0; j < nrOfOutputStates; j++) {            sum += emissionMatrix.getQuick(i, j);        }                for (int j = 0; j < nrOfOutputStates; j++) {            emissionMatrix.setQuick(i, j, emissionMatrix.getQuick(i, j) / sum);        }    }        return new HmmModel(transitionMatrix, emissionMatrix, initialProbabilities);}
private static void mahout_f2424_0(Matrix transitionMatrix, Matrix emissionMatrix, int[] observedSequence, int[] hiddenSequence)
{    emissionMatrix.setQuick(hiddenSequence[0], observedSequence[0], emissionMatrix.getQuick(hiddenSequence[0], observedSequence[0]) + 1);    for (int i = 1; i < observedSequence.length; ++i) {        transitionMatrix.setQuick(hiddenSequence[i - 1], hiddenSequence[i], transitionMatrix.getQuick(hiddenSequence[i - 1], hiddenSequence[i]) + 1);        emissionMatrix.setQuick(hiddenSequence[i], observedSequence[i], emissionMatrix.getQuick(hiddenSequence[i], observedSequence[i]) + 1);    }}
public static HmmModel mahout_f2425_0(int nrOfHiddenStates, int nrOfOutputStates, Collection<int[]> hiddenSequences, Collection<int[]> observedSequences, double pseudoCount)
{        pseudoCount = pseudoCount == 0 ? Double.MIN_VALUE : pseudoCount;        DenseMatrix transitionMatrix = new DenseMatrix(nrOfHiddenStates, nrOfHiddenStates);    DenseMatrix emissionMatrix = new DenseMatrix(nrOfHiddenStates, nrOfOutputStates);    DenseVector initialProbabilities = new DenseVector(nrOfHiddenStates);        transitionMatrix.assign(pseudoCount);    emissionMatrix.assign(pseudoCount);    initialProbabilities.assign(pseudoCount);        Iterator<int[]> hiddenSequenceIt = hiddenSequences.iterator();    Iterator<int[]> observedSequenceIt = observedSequences.iterator();    while (hiddenSequenceIt.hasNext() && observedSequenceIt.hasNext()) {                int[] hiddenSequence = hiddenSequenceIt.next();        int[] observedSequence = observedSequenceIt.next();                initialProbabilities.setQuick(hiddenSequence[0], initialProbabilities.getQuick(hiddenSequence[0]) + 1);        countTransitions(transitionMatrix, emissionMatrix, observedSequence, hiddenSequence);    }            double isum = 0;    for (int i = 0; i < nrOfHiddenStates; i++) {        isum += initialProbabilities.getQuick(i);                double sum = 0;        for (int j = 0; j < nrOfHiddenStates; j++) {            sum += transitionMatrix.getQuick(i, j);        }                for (int j = 0; j < nrOfHiddenStates; j++) {            transitionMatrix.setQuick(i, j, transitionMatrix.getQuick(i, j) / sum);        }                sum = 0;        for (int j = 0; j < nrOfOutputStates; j++) {            sum += emissionMatrix.getQuick(i, j);        }                for (int j = 0; j < nrOfOutputStates; j++) {            emissionMatrix.setQuick(i, j, emissionMatrix.getQuick(i, j) / sum);        }    }        for (int i = 0; i < nrOfHiddenStates; ++i) {        initialProbabilities.setQuick(i, initialProbabilities.getQuick(i) / isum);    }        return new HmmModel(transitionMatrix, emissionMatrix, initialProbabilities);}
public static HmmModel mahout_f2426_0(HmmModel initialModel, int[] observedSequence, double pseudoCount, double epsilon, int maxIterations, boolean scaled)
{        pseudoCount = pseudoCount == 0 ? Double.MIN_VALUE : pseudoCount;        HmmModel lastIteration = initialModel.clone();    HmmModel iteration = initialModel.clone();        int[] viterbiPath = new int[observedSequence.length];    int[][] phi = new int[observedSequence.length - 1][initialModel.getNrOfHiddenStates()];    double[][] delta = new double[observedSequence.length][initialModel.getNrOfHiddenStates()];        for (int i = 0; i < maxIterations; ++i) {                HmmAlgorithms.viterbiAlgorithm(viterbiPath, delta, phi, lastIteration, observedSequence, scaled);                        Matrix emissionMatrix = iteration.getEmissionMatrix();        Matrix transitionMatrix = iteration.getTransitionMatrix();                emissionMatrix.assign(pseudoCount);        transitionMatrix.assign(pseudoCount);                countTransitions(transitionMatrix, emissionMatrix, observedSequence, viterbiPath);                for (int j = 0; j < iteration.getNrOfHiddenStates(); ++j) {            double sum = 0;                        for (int k = 0; k < iteration.getNrOfHiddenStates(); ++k) {                sum += transitionMatrix.getQuick(j, k);            }            for (int k = 0; k < iteration.getNrOfHiddenStates(); ++k) {                transitionMatrix.setQuick(j, k, transitionMatrix.getQuick(j, k) / sum);            }                        sum = 0;            for (int k = 0; k < iteration.getNrOfOutputStates(); ++k) {                sum += emissionMatrix.getQuick(j, k);            }            for (int k = 0; k < iteration.getNrOfOutputStates(); ++k) {                emissionMatrix.setQuick(j, k, emissionMatrix.getQuick(j, k) / sum);            }        }                if (checkConvergence(lastIteration, iteration, epsilon)) {            break;        }                lastIteration.assign(iteration);    }        return iteration;}
public static HmmModel mahout_f2427_0(HmmModel initialModel, int[] observedSequence, double epsilon, int maxIterations, boolean scaled)
{        HmmModel lastIteration = initialModel.clone();    HmmModel iteration = initialModel.clone();        int hiddenCount = initialModel.getNrOfHiddenStates();    int visibleCount = observedSequence.length;    Matrix alpha = new DenseMatrix(visibleCount, hiddenCount);    Matrix beta = new DenseMatrix(visibleCount, hiddenCount);        for (int it = 0; it < maxIterations; ++it) {                Vector initialProbabilities = iteration.getInitialProbabilities();        Matrix emissionMatrix = iteration.getEmissionMatrix();        Matrix transitionMatrix = iteration.getTransitionMatrix();                HmmAlgorithms.forwardAlgorithm(alpha, iteration, observedSequence, scaled);        HmmAlgorithms.backwardAlgorithm(beta, iteration, observedSequence, scaled);        if (scaled) {            logScaledBaumWelch(observedSequence, iteration, alpha, beta);        } else {            unscaledBaumWelch(observedSequence, iteration, alpha, beta);        }                        double isum = 0;        for (int j = 0; j < iteration.getNrOfHiddenStates(); ++j) {            double sum = 0;                        for (int k = 0; k < iteration.getNrOfHiddenStates(); ++k) {                sum += transitionMatrix.getQuick(j, k);            }            for (int k = 0; k < iteration.getNrOfHiddenStates(); ++k) {                transitionMatrix.setQuick(j, k, transitionMatrix.getQuick(j, k) / sum);            }                        sum = 0;            for (int k = 0; k < iteration.getNrOfOutputStates(); ++k) {                sum += emissionMatrix.getQuick(j, k);            }            for (int k = 0; k < iteration.getNrOfOutputStates(); ++k) {                emissionMatrix.setQuick(j, k, emissionMatrix.getQuick(j, k) / sum);            }                        isum += initialProbabilities.getQuick(j);        }                for (int i = 0; i < iteration.getNrOfHiddenStates(); ++i) {            initialProbabilities.setQuick(i, initialProbabilities.getQuick(i) / isum);        }                if (checkConvergence(lastIteration, iteration, epsilon)) {            break;        }                lastIteration.assign(iteration);    }        return iteration;}
private static void mahout_f2428_0(int[] observedSequence, HmmModel iteration, Matrix alpha, Matrix beta)
{    Vector initialProbabilities = iteration.getInitialProbabilities();    Matrix emissionMatrix = iteration.getEmissionMatrix();    Matrix transitionMatrix = iteration.getTransitionMatrix();    double modelLikelihood = HmmEvaluator.modelLikelihood(alpha, false);    for (int i = 0; i < iteration.getNrOfHiddenStates(); ++i) {        initialProbabilities.setQuick(i, alpha.getQuick(0, i) * beta.getQuick(0, i));    }        for (int i = 0; i < iteration.getNrOfHiddenStates(); ++i) {        for (int j = 0; j < iteration.getNrOfHiddenStates(); ++j) {            double temp = 0;            for (int t = 0; t < observedSequence.length - 1; ++t) {                temp += alpha.getQuick(t, i) * emissionMatrix.getQuick(j, observedSequence[t + 1]) * beta.getQuick(t + 1, j);            }            transitionMatrix.setQuick(i, j, transitionMatrix.getQuick(i, j) * temp / modelLikelihood);        }    }        for (int i = 0; i < iteration.getNrOfHiddenStates(); ++i) {        for (int j = 0; j < iteration.getNrOfOutputStates(); ++j) {            double temp = 0;            for (int t = 0; t < observedSequence.length; ++t) {                                if (observedSequence[t] == j) {                    temp += alpha.getQuick(t, i) * beta.getQuick(t, i);                }            }            emissionMatrix.setQuick(i, j, temp / modelLikelihood);        }    }}
private static void mahout_f2429_0(int[] observedSequence, HmmModel iteration, Matrix alpha, Matrix beta)
{    Vector initialProbabilities = iteration.getInitialProbabilities();    Matrix emissionMatrix = iteration.getEmissionMatrix();    Matrix transitionMatrix = iteration.getTransitionMatrix();    double modelLikelihood = HmmEvaluator.modelLikelihood(alpha, true);    for (int i = 0; i < iteration.getNrOfHiddenStates(); ++i) {        initialProbabilities.setQuick(i, Math.exp(alpha.getQuick(0, i) + beta.getQuick(0, i)));    }        for (int i = 0; i < iteration.getNrOfHiddenStates(); ++i) {        for (int j = 0; j < iteration.getNrOfHiddenStates(); ++j) {                        double sum = Double.NEGATIVE_INFINITY;            for (int t = 0; t < observedSequence.length - 1; ++t) {                double temp = alpha.getQuick(t, i) + Math.log(emissionMatrix.getQuick(j, observedSequence[t + 1])) + beta.getQuick(t + 1, j);                if (temp > Double.NEGATIVE_INFINITY) {                                        sum = temp + Math.log1p(Math.exp(sum - temp));                }            }            transitionMatrix.setQuick(i, j, transitionMatrix.getQuick(i, j) * Math.exp(sum - modelLikelihood));        }    }        for (int i = 0; i < iteration.getNrOfHiddenStates(); ++i) {        for (int j = 0; j < iteration.getNrOfOutputStates(); ++j) {                        double sum = Double.NEGATIVE_INFINITY;            for (int t = 0; t < observedSequence.length; ++t) {                                if (observedSequence[t] == j) {                    double temp = alpha.getQuick(t, i) + beta.getQuick(t, i);                    if (temp > Double.NEGATIVE_INFINITY) {                                                sum = temp + Math.log1p(Math.exp(sum - temp));                    }                }            }            emissionMatrix.setQuick(i, j, Math.exp(sum - modelLikelihood));        }    }}
private static boolean mahout_f2430_0(HmmModel oldModel, HmmModel newModel, double epsilon)
{        Matrix oldTransitionMatrix = oldModel.getTransitionMatrix();    Matrix newTransitionMatrix = newModel.getTransitionMatrix();    double diff = 0;    for (int i = 0; i < oldModel.getNrOfHiddenStates(); ++i) {        for (int j = 0; j < oldModel.getNrOfHiddenStates(); ++j) {            double tmp = oldTransitionMatrix.getQuick(i, j) - newTransitionMatrix.getQuick(i, j);            diff += tmp * tmp;        }    }    double norm = Math.sqrt(diff);    diff = 0;        Matrix oldEmissionMatrix = oldModel.getEmissionMatrix();    Matrix newEmissionMatrix = newModel.getEmissionMatrix();    for (int i = 0; i < oldModel.getNrOfHiddenStates(); i++) {        for (int j = 0; j < oldModel.getNrOfOutputStates(); j++) {            double tmp = oldEmissionMatrix.getQuick(i, j) - newEmissionMatrix.getQuick(i, j);            diff += tmp * tmp;        }    }    norm += Math.sqrt(diff);        return norm < epsilon;}
public static Matrix mahout_f2431_0(HmmModel model)
{        int hiddenStates = model.getNrOfHiddenStates();    Matrix transitionMatrix = model.getTransitionMatrix();        Matrix resultMatrix = new DenseMatrix(hiddenStates, hiddenStates);    for (int i = 0; i < hiddenStates; ++i) {        double sum = 0;        for (int j = 0; j < hiddenStates; ++j) {            sum += transitionMatrix.get(i, j);            resultMatrix.set(i, j, sum);        }        resultMatrix.set(i, hiddenStates - 1, 1.0);                        }    return resultMatrix;}
public static Matrix mahout_f2432_0(HmmModel model)
{        int hiddenStates = model.getNrOfHiddenStates();    int outputStates = model.getNrOfOutputStates();    Matrix outputMatrix = model.getEmissionMatrix();        Matrix resultMatrix = new DenseMatrix(hiddenStates, outputStates);    for (int i = 0; i < hiddenStates; ++i) {        double sum = 0;        for (int j = 0; j < outputStates; ++j) {            sum += outputMatrix.get(i, j);            resultMatrix.set(i, j, sum);        }        resultMatrix.set(i, outputStates - 1, 1.0);                    }    return resultMatrix;}
public static Vector mahout_f2433_0(HmmModel model)
{        int hiddenStates = model.getNrOfHiddenStates();    Vector initialProbabilities = model.getInitialProbabilities();        Vector resultVector = new DenseVector(initialProbabilities.size());    double sum = 0;    for (int i = 0; i < hiddenStates; ++i) {        sum += initialProbabilities.get(i);        resultVector.set(i, sum);    }        resultVector.set(hiddenStates - 1, 1.0);        return resultVector;}
public static void mahout_f2434_0(HmmModel model)
{    if (model == null) {                return;    }    /*     * The number of hidden states is positive.     */    Preconditions.checkArgument(model.getNrOfHiddenStates() > 0, "Error: The number of hidden states has to be greater than 0");    /*     * The number of output states is positive.     */    Preconditions.checkArgument(model.getNrOfOutputStates() > 0, "Error: The number of output states has to be greater than 0!");    /*     * The size of the vector of initial probabilities is equal to the number of     * the hidden states. Each initial probability is non-negative. The sum of     * initial probabilities is equal to 1.     */    Preconditions.checkArgument(model.getInitialProbabilities() != null && model.getInitialProbabilities().size() == model.getNrOfHiddenStates(), "Error: The vector of initial probabilities is not initialized!");    double sum = 0;    for (int i = 0; i < model.getInitialProbabilities().size(); i++) {        Preconditions.checkArgument(model.getInitialProbabilities().get(i) >= 0, "Error: Initial probability of state %d is negative", i);        sum += model.getInitialProbabilities().get(i);    }    Preconditions.checkArgument(Math.abs(sum - 1) <= 0.00001, "Error: Initial probabilities do not add up to 1");    /*     * The row size of the output matrix is equal to the number of the hidden     * states. The column size is equal to the number of output states. Each     * probability of the matrix is non-negative. The sum of each row is equal     * to 1.     */    Preconditions.checkNotNull(model.getEmissionMatrix(), "Error: The output state matrix is not initialized!");    Preconditions.checkArgument(model.getEmissionMatrix().numRows() == model.getNrOfHiddenStates() && model.getEmissionMatrix().numCols() == model.getNrOfOutputStates(), "Error: The output state matrix is not of the form nrOfHiddenStates x nrOfOutputStates");    for (int i = 0; i < model.getEmissionMatrix().numRows(); i++) {        sum = 0;        for (int j = 0; j < model.getEmissionMatrix().numCols(); j++) {            Preconditions.checkArgument(model.getEmissionMatrix().get(i, j) >= 0, "The output state probability from hidden state " + i + " to output state " + j + " is negative");            sum += model.getEmissionMatrix().get(i, j);        }        Preconditions.checkArgument(Math.abs(sum - 1) <= 0.00001, "Error: The output state probabilities for hidden state %d don't add up to 1", i);    }    /*     * The size of both dimension of the transition matrix is equal to the     * number of the hidden states. Each probability of the matrix is     * non-negative. The sum of each row in transition matrix is equal to 1.     */    Preconditions.checkArgument(model.getTransitionMatrix() != null, "Error: The hidden state matrix is not initialized!");    Preconditions.checkArgument(model.getTransitionMatrix().numRows() == model.getNrOfHiddenStates() && model.getTransitionMatrix().numCols() == model.getNrOfHiddenStates(), "Error: The output state matrix is not of the form nrOfHiddenStates x nrOfHiddenStates");    for (int i = 0; i < model.getTransitionMatrix().numRows(); i++) {        sum = 0;        for (int j = 0; j < model.getTransitionMatrix().numCols(); j++) {            Preconditions.checkArgument(model.getTransitionMatrix().get(i, j) >= 0, "Error: The transition probability from hidden state %d to hidden state %d is negative", i, j);            sum += model.getTransitionMatrix().get(i, j);        }        Preconditions.checkArgument(Math.abs(sum - 1) <= 0.00001, "Error: The transition probabilities for hidden state " + i + " don't add up to 1.");    }}
public static int[] mahout_f2435_0(HmmModel model, Collection<String> sequence, boolean observed, int defaultValue)
{    int[] encoded = new int[sequence.size()];    Iterator<String> seqIter = sequence.iterator();    for (int i = 0; i < sequence.size(); ++i) {        String nextState = seqIter.next();        int nextID;        if (observed) {            nextID = model.getOutputStateID(nextState);        } else {            nextID = model.getHiddenStateID(nextState);        }                encoded[i] = nextID < 0 ? defaultValue : nextID;    }    return encoded;}
public static List<String> mahout_f2436_0(HmmModel model, int[] sequence, boolean observed, String defaultValue)
{    List<String> decoded = new ArrayList<>(sequence.length);    for (int position : sequence) {        String nextState;        if (observed) {            nextState = model.getOutputStateName(position);        } else {            nextState = model.getHiddenStateName(position);        }                decoded.add(nextState == null ? defaultValue : nextState);    }    return decoded;}
public static void mahout_f2437_0(HmmModel model)
{    Vector ip = model.getInitialProbabilities();    Matrix emission = model.getEmissionMatrix();    Matrix transition = model.getTransitionMatrix();        double isum = 0;    for (int i = 0; i < model.getNrOfHiddenStates(); ++i) {        isum += ip.getQuick(i);        double sum = 0;        for (int j = 0; j < model.getNrOfHiddenStates(); ++j) {            sum += transition.getQuick(i, j);        }        if (sum != 1.0) {            for (int j = 0; j < model.getNrOfHiddenStates(); ++j) {                transition.setQuick(i, j, transition.getQuick(i, j) / sum);            }        }        sum = 0;        for (int j = 0; j < model.getNrOfOutputStates(); ++j) {            sum += emission.getQuick(i, j);        }        if (sum != 1.0) {            for (int j = 0; j < model.getNrOfOutputStates(); ++j) {                emission.setQuick(i, j, emission.getQuick(i, j) / sum);            }        }    }    if (isum != 1.0) {        for (int i = 0; i < model.getNrOfHiddenStates(); ++i) {            ip.setQuick(i, ip.getQuick(i) / isum);        }    }}
public static HmmModel mahout_f2438_0(HmmModel model, double threshold)
{    Vector ip = model.getInitialProbabilities();    Matrix em = model.getEmissionMatrix();    Matrix tr = model.getTransitionMatrix();        RandomAccessSparseVector sparseIp = new RandomAccessSparseVector(model.getNrOfHiddenStates());    SparseMatrix sparseEm = new SparseMatrix(model.getNrOfHiddenStates(), model.getNrOfOutputStates());    SparseMatrix sparseTr = new SparseMatrix(model.getNrOfHiddenStates(), model.getNrOfHiddenStates());        for (int i = 0; i < model.getNrOfHiddenStates(); ++i) {        double value = ip.getQuick(i);        if (value > threshold) {            sparseIp.setQuick(i, value);        }        for (int j = 0; j < model.getNrOfHiddenStates(); ++j) {            value = tr.getQuick(i, j);            if (value > threshold) {                sparseTr.setQuick(i, j, value);            }        }        for (int j = 0; j < model.getNrOfOutputStates(); ++j) {            value = em.getQuick(i, j);            if (value > threshold) {                sparseEm.setQuick(i, j, value);            }        }    }        HmmModel sparseModel = new HmmModel(sparseTr, sparseEm, sparseIp);        normalizeModel(sparseModel);        sparseModel.registerHiddenStateNames(model.getHiddenStateNames());    sparseModel.registerOutputStateNames(model.getOutputStateNames());        return sparseModel;}
 static void mahout_f2439_0(HmmModel model, DataOutput output) throws IOException
{    MatrixWritable matrix = new MatrixWritable(model.getEmissionMatrix());    matrix.write(output);    matrix.set(model.getTransitionMatrix());    matrix.write(output);    VectorWritable vector = new VectorWritable(model.getInitialProbabilities());    vector.write(output);}
 static HmmModel mahout_f2440_0(DataInput input) throws IOException
{    MatrixWritable matrix = new MatrixWritable();    matrix.readFields(input);    Matrix emissionMatrix = matrix.get();    matrix.readFields(input);    Matrix transitionMatrix = matrix.get();    VectorWritable vector = new VectorWritable();    vector.readFields(input);    Vector initialProbabilities = vector.get();    return new HmmModel(transitionMatrix, emissionMatrix, initialProbabilities);}
public static void mahout_f2441_0(String[] args) throws IOException
{    DefaultOptionBuilder optionBuilder = new DefaultOptionBuilder();    ArgumentBuilder argumentBuilder = new ArgumentBuilder();    Option outputOption = optionBuilder.withLongName("output").withDescription("Output file with sequence of observed states").withShortName("o").withArgument(argumentBuilder.withMaximum(1).withMinimum(1).withName("path").create()).withRequired(false).create();    Option modelOption = optionBuilder.withLongName("model").withDescription("Path to serialized HMM model").withShortName("m").withArgument(argumentBuilder.withMaximum(1).withMinimum(1).withName("path").create()).withRequired(true).create();    Option lengthOption = optionBuilder.withLongName("length").withDescription("Length of generated sequence").withShortName("l").withArgument(argumentBuilder.withMaximum(1).withMinimum(1).withName("number").create()).withRequired(true).create();    Group optionGroup = new GroupBuilder().withOption(outputOption).withOption(modelOption).withOption(lengthOption).withName("Options").create();    try {        Parser parser = new Parser();        parser.setGroup(optionGroup);        CommandLine commandLine = parser.parse(args);        String output = (String) commandLine.getValue(outputOption);        String modelPath = (String) commandLine.getValue(modelOption);        int length = Integer.parseInt((String) commandLine.getValue(lengthOption));                HmmModel model;        try (DataInputStream modelStream = new DataInputStream(new FileInputStream(modelPath))) {            model = LossyHmmSerializer.deserialize(modelStream);        }                int[] observations = HmmEvaluator.predict(model, length, System.currentTimeMillis());                try (PrintWriter writer = new PrintWriter(new OutputStreamWriter(new FileOutputStream(output), Charsets.UTF_8), true)) {            for (int observation : observations) {                writer.print(observation);                writer.print(' ');            }        }    } catch (OptionException e) {        CommandLineUtil.printHelp(optionGroup);    }}
public static void mahout_f2442_0(String[] args) throws IOException
{    DefaultOptionBuilder optionBuilder = new DefaultOptionBuilder();    ArgumentBuilder argumentBuilder = new ArgumentBuilder();    Option inputOption = DefaultOptionCreator.inputOption().create();    Option outputOption = DefaultOptionCreator.outputOption().create();    Option modelOption = optionBuilder.withLongName("model").withDescription("Path to serialized HMM model").withShortName("m").withArgument(argumentBuilder.withMaximum(1).withMinimum(1).withName("path").create()).withRequired(true).create();    Option likelihoodOption = optionBuilder.withLongName("likelihood").withDescription("Compute likelihood of observed sequence").withShortName("l").withRequired(false).create();    Group optionGroup = new GroupBuilder().withOption(inputOption).withOption(outputOption).withOption(modelOption).withOption(likelihoodOption).withName("Options").create();    try {        Parser parser = new Parser();        parser.setGroup(optionGroup);        CommandLine commandLine = parser.parse(args);        String input = (String) commandLine.getValue(inputOption);        String output = (String) commandLine.getValue(outputOption);        String modelPath = (String) commandLine.getValue(modelOption);        boolean computeLikelihood = commandLine.hasOption(likelihoodOption);                ;        HmmModel model;        try (DataInputStream modelStream = new DataInputStream(new FileInputStream(modelPath))) {            model = LossyHmmSerializer.deserialize(modelStream);        }                List<Integer> observations = new ArrayList<>();        try (Scanner scanner = new Scanner(new FileInputStream(input), "UTF-8")) {            while (scanner.hasNextInt()) {                observations.add(scanner.nextInt());            }        }        int[] observationsArray = new int[observations.size()];        for (int i = 0; i < observations.size(); ++i) {            observationsArray[i] = observations.get(i);        }                int[] hiddenStates = HmmEvaluator.decode(model, observationsArray, true);                try (PrintWriter writer = new PrintWriter(new OutputStreamWriter(new FileOutputStream(output), Charsets.UTF_8), true)) {            for (int hiddenState : hiddenStates) {                writer.print(hiddenState);                writer.print(' ');            }        }        if (computeLikelihood) {            System.out.println("Likelihood: " + HmmEvaluator.modelLikelihood(model, observationsArray, true));        }    } catch (OptionException e) {        CommandLineUtil.printHelp(optionGroup);    }}
public AbstractOnlineLogisticRegression mahout_f2443_0(double lambda)
{    this.lambda = lambda;    return this;}
public static Vector mahout_f2444_0(Vector v)
{    double max = v.maxValue();    if (max >= 40) {                        v.assign(Functions.minus(max)).assign(Functions.EXP);        return v.divide(v.norm(1));    } else {        v.assign(Functions.EXP);        return v.divide(1 + v.norm(1));    }}
public static double mahout_f2445_0(double r)
{    if (r < 0.0) {        double s = Math.exp(r);        return s / (1.0 + s);    } else {        double s = Math.exp(-r);        return 1.0 / (1.0 + s);    }}
public Vector mahout_f2446_0(Vector instance)
{        regularize(instance);    return beta.times(instance);}
public double mahout_f2447_0(Vector instance)
{    return beta.viewRow(0).dot(instance);}
public Vector mahout_f2448_0(Vector instance)
{    return link(classifyNoLink(instance));}
public double mahout_f2449_0(Vector instance)
{    Preconditions.checkArgument(numCategories() == 2, "Can only call classifyScalar with two categories");        regularize(instance);        return link(classifyScalarNoLink(instance));}
public void mahout_f2450_0(long trackingKey, String groupKey, int actual, Vector instance)
{    unseal();    double learningRate = currentLearningRate();        regularize(instance);        Vector gradient = this.gradient.apply(groupKey, actual, instance, this);    for (int i = 0; i < numCategories - 1; i++) {        double gradientBase = gradient.get(i);                for (Element updateLocation : instance.nonZeroes()) {            int j = updateLocation.index();            double newValue = beta.getQuick(i, j) + gradientBase * learningRate * perTermLearningRate(j) * instance.get(j);            beta.setQuick(i, j, newValue);        }    }        for (Element element : instance.nonZeroes()) {        int j = element.index();        updateSteps.setQuick(j, getStep());        updateCounts.incrementQuick(j, 1);    }    nextStep();}
public void mahout_f2451_0(long trackingKey, int actual, Vector instance)
{    train(trackingKey, null, actual, instance);}
public void mahout_f2452_0(int actual, Vector instance)
{    train(0, null, actual, instance);}
public void mahout_f2453_0(Vector instance)
{    if (updateSteps == null || isSealed()) {        return;    }        double learningRate = currentLearningRate();        for (int i = 0; i < numCategories - 1; i++) {        for (Element updateLocation : instance.nonZeroes()) {            int j = updateLocation.index();            double missingUpdates = getStep() - updateSteps.get(j);            if (missingUpdates > 0) {                double rate = getLambda() * learningRate * perTermLearningRate(j);                double newValue = prior.age(beta.get(i, j), missingUpdates, rate);                beta.set(i, j, newValue);                updateSteps.set(j, getStep());            }        }    }}
public void mahout_f2454_0(PriorFunction prior)
{    this.prior = prior;}
public void mahout_f2455_0(Gradient gradient)
{    this.gradient = gradient;}
public PriorFunction mahout_f2456_0()
{    return prior;}
public Matrix mahout_f2457_0()
{    close();    return beta;}
public void mahout_f2458_0(int i, int j, double betaIJ)
{    beta.set(i, j, betaIJ);}
public int mahout_f2459_0()
{    return numCategories;}
public int mahout_f2460_0()
{    return beta.numCols();}
public double mahout_f2461_0()
{    return lambda;}
public int mahout_f2462_0()
{    return step;}
protected void mahout_f2463_0()
{    step++;}
public boolean mahout_f2464_0()
{    return sealed;}
protected void mahout_f2465_0()
{    sealed = false;}
private void mahout_f2466_0()
{    Vector all = new DenseVector(beta.numCols());    all.assign(1);    regularize(all);}
public void mahout_f2467_0()
{    if (!sealed) {        step++;        regularizeAll();        sealed = true;    }}
public void mahout_f2468_0(AbstractOnlineLogisticRegression other)
{        Preconditions.checkArgument(numCategories == other.numCategories, "Can't copy unless number of target categories is the same");    beta.assign(other.beta);    step = other.step;    updateSteps.assign(other.updateSteps);    updateCounts.assign(other.updateCounts);}
public boolean mahout_f2469_0()
{    double k = beta.aggregate(Functions.PLUS, new DoubleFunction() {        @Override        public double apply(double v) {            return Double.isNaN(v) || Double.isInfinite(v) ? 1 : 0;        }    });    return k < 1;}
public double mahout_f2470_0(double v)
{    return Double.isNaN(v) || Double.isInfinite(v) ? 1 : 0;}
public void mahout_f2471_0(int actual, Vector instance)
{    train(record, null, actual, instance);}
public void mahout_f2472_0(long trackingKey, int actual, Vector instance)
{    train(trackingKey, null, actual, instance);}
public void mahout_f2473_0(long trackingKey, String groupKey, int actual, Vector instance)
{    record++;    buffer.add(new TrainingExample(trackingKey, groupKey, actual, instance));        if (buffer.size() > bufferSize) {        trainWithBufferedExamples();    }}
private void mahout_f2474_1()
{    try {        this.best = ep.parallelDo(new EvolutionaryProcess.Function<Payload<CrossFoldLearner>>() {            @Override            public double apply(Payload<CrossFoldLearner> z, double[] params) {                Wrapper x = (Wrapper) z;                for (TrainingExample example : buffer) {                    x.train(example);                }                if (x.getLearner().validModel()) {                    if (x.getLearner().numCategories() == 2) {                        return x.wrapped.auc();                    } else {                        return x.wrapped.logLikelihood();                    }                } else {                    return Double.NaN;                }            }        });    } catch (InterruptedException e) {                    } catch (ExecutionException e) {        throw new IllegalStateException(e.getCause());    }    buffer.clear();    if (record > cutoff) {        cutoff = nextStep(record);                ep.mutatePopulation(SURVIVORS);        if (freezeSurvivors) {                        for (State<Wrapper, CrossFoldLearner> state : ep.getPopulation().subList(0, SURVIVORS)) {                Wrapper.freeze(state);            }        }    }}
public double mahout_f2475_0(Payload<CrossFoldLearner> z, double[] params)
{    Wrapper x = (Wrapper) z;    for (TrainingExample example : buffer) {        x.train(example);    }    if (x.getLearner().validModel()) {        if (x.getLearner().numCategories() == 2) {            return x.wrapped.auc();        } else {            return x.wrapped.logLikelihood();        }    } else {        return Double.NaN;    }}
public int mahout_f2476_0(int recordNumber)
{    int stepSize = stepSize(recordNumber, 2.6);    if (stepSize < minInterval) {        stepSize = minInterval;    }    if (stepSize > maxInterval) {        stepSize = maxInterval;    }    int newCutoff = stepSize * (recordNumber / stepSize + 1);    if (newCutoff < cutoff + currentStep) {        newCutoff = cutoff + currentStep;    } else {        this.currentStep = stepSize;    }    return newCutoff;}
public static int mahout_f2477_0(int recordNumber, double multiplier)
{    int[] bumps = { 1, 2, 5 };    double log = Math.floor(multiplier * Math.log10(recordNumber));    int bump = bumps[(int) log % bumps.length];    int scale = (int) Math.pow(10, Math.floor(log / bumps.length));    return bump * scale;}
public void mahout_f2478_1()
{    trainWithBufferedExamples();    try {        ep.parallelDo(new EvolutionaryProcess.Function<Payload<CrossFoldLearner>>() {            @Override            public double apply(Payload<CrossFoldLearner> payload, double[] params) {                CrossFoldLearner learner = ((Wrapper) payload).getLearner();                learner.close();                return learner.logLikelihood();            }        });    } catch (InterruptedException e) {            } catch (ExecutionException e) {        throw new IllegalStateException(e);    } finally {        ep.close();    }}
public double mahout_f2479_0(Payload<CrossFoldLearner> payload, double[] params)
{    CrossFoldLearner learner = ((Wrapper) payload).getLearner();    learner.close();    return learner.logLikelihood();}
public void mahout_f2480_0(int interval)
{    setInterval(interval, interval);}
public void mahout_f2481_0(int minInterval, int maxInterval)
{    this.minInterval = Math.max(200, minInterval);    this.maxInterval = Math.max(200, maxInterval);    this.cutoff = minInterval * (record / minInterval + 1);    this.currentStep = minInterval;    bufferSize = Math.min(minInterval, bufferSize);}
public final void mahout_f2482_0(int poolSize)
{    this.poolSize = poolSize;    setupOptimizer(poolSize);}
public void mahout_f2483_0(int threadCount)
{    this.threadCount = threadCount;    setupOptimizer(poolSize);}
public void mahout_f2484_0(OnlineAuc auc)
{    seed.getPayload().setAucEvaluator(auc);    setupOptimizer(poolSize);}
private void mahout_f2485_0(int poolSize)
{    ep = new EvolutionaryProcess<>(threadCount, poolSize, seed);}
public int mahout_f2486_0()
{    return numFeatures;}
public double mahout_f2487_0()
{    if (best == null) {        return Double.NaN;    } else {        Wrapper payload = best.getPayload();        return payload.getLearner().auc();    }}
public State<Wrapper, CrossFoldLearner> mahout_f2488_0()
{    return best;}
public void mahout_f2489_0(State<Wrapper, CrossFoldLearner> best)
{    this.best = best;}
public int mahout_f2490_0()
{    return record;}
public void mahout_f2491_0(int record)
{    this.record = record;}
public int mahout_f2492_0()
{    return minInterval;}
public int mahout_f2493_0()
{    return maxInterval;}
public int mahout_f2494_0()
{    return seed.getPayload().getLearner().numCategories();}
public PriorFunction mahout_f2495_0()
{    return seed.getPayload().getLearner().getPrior();}
public void mahout_f2496_0(List<TrainingExample> buffer)
{    this.buffer = buffer;}
public List<TrainingExample> mahout_f2497_0()
{    return buffer;}
public EvolutionaryProcess<Wrapper, CrossFoldLearner> mahout_f2498_0()
{    return ep;}
public void mahout_f2499_0(EvolutionaryProcess<Wrapper, CrossFoldLearner> ep)
{    this.ep = ep;}
public State<Wrapper, CrossFoldLearner> mahout_f2500_0()
{    return seed;}
public void mahout_f2501_0(State<Wrapper, CrossFoldLearner> seed)
{    this.seed = seed;}
public int mahout_f2502_0()
{    return numFeatures;}
public void mahout_f2503_0(int averagingWindow)
{    seed.getPayload().getLearner().setWindowSize(averagingWindow);    setupOptimizer(poolSize);}
public void mahout_f2504_0(boolean freezeSurvivors)
{    this.freezeSurvivors = freezeSurvivors;}
public Wrapper mahout_f2505_0()
{    Wrapper r = new Wrapper();    r.wrapped = wrapped.copy();    return r;}
public void mahout_f2506_0(double[] params)
{    int i = 0;    wrapped.lambda(params[i++]);    wrapped.learningRate(params[i]);    wrapped.stepOffset(1);    wrapped.alpha(1);    wrapped.decayExponent(0);}
public static void mahout_f2507_0(State<Wrapper, CrossFoldLearner> s)
{        double[] params = s.getParams();    params[1] -= 10;        s.setOmni(s.getOmni() / 20);    double[] step = s.getStep();    for (int i = 0; i < step.length; i++) {        step[i] /= 20;    }}
public static void mahout_f2508_0(State<Wrapper, CrossFoldLearner> x)
{    int i = 0;        x.setMap(i++, Mapping.logLimit(1.0e-8, 0.1));        x.setMap(i, Mapping.logLimit(1.0e-8, 1));}
public void mahout_f2509_0(TrainingExample example)
{    wrapped.train(example.getKey(), example.getGroupKey(), example.getActual(), example.getInstance());}
public CrossFoldLearner mahout_f2510_0()
{    return wrapped;}
public String mahout_f2511_0()
{    return String.format(Locale.ENGLISH, "auc=%.2f", wrapped.auc());}
public void mahout_f2512_0(OnlineAuc auc)
{    wrapped.setAucEvaluator(auc);}
public void mahout_f2513_0(DataOutput out) throws IOException
{    wrapped.write(out);}
public void mahout_f2514_0(DataInput input) throws IOException
{    wrapped = new CrossFoldLearner();    wrapped.readFields(input);}
public long mahout_f2515_0()
{    return key;}
public int mahout_f2516_0()
{    return actual;}
public Vector mahout_f2517_0()
{    return instance;}
public String mahout_f2518_0()
{    return groupKey;}
public void mahout_f2519_0(DataOutput out) throws IOException
{    out.writeLong(key);    if (groupKey != null) {        out.writeBoolean(true);        out.writeUTF(groupKey);    } else {        out.writeBoolean(false);    }    out.writeInt(actual);    VectorWritable.writeVector(out, instance, true);}
public void mahout_f2520_0(DataInput in) throws IOException
{    key = in.readLong();    if (in.readBoolean()) {        groupKey = in.readUTF();    }    actual = in.readInt();    instance = VectorWritable.readVector(in);}
public void mahout_f2521_0(DataOutput out) throws IOException
{    out.writeInt(record);    out.writeInt(cutoff);    out.writeInt(minInterval);    out.writeInt(maxInterval);    out.writeInt(currentStep);    out.writeInt(bufferSize);    out.writeInt(buffer.size());    for (TrainingExample example : buffer) {        example.write(out);    }    ep.write(out);    best.write(out);    out.writeInt(threadCount);    out.writeInt(poolSize);    seed.write(out);    out.writeInt(numFeatures);    out.writeBoolean(freezeSurvivors);}
public void mahout_f2522_0(DataInput in) throws IOException
{    record = in.readInt();    cutoff = in.readInt();    minInterval = in.readInt();    maxInterval = in.readInt();    currentStep = in.readInt();    bufferSize = in.readInt();    int n = in.readInt();    buffer = new ArrayList<>();    for (int i = 0; i < n; i++) {        TrainingExample example = new TrainingExample();        example.readFields(in);        buffer.add(example);    }    ep = new EvolutionaryProcess<>();    ep.readFields(in);    best = new State<>();    best.readFields(in);    threadCount = in.readInt();    poolSize = in.readInt();    seed = new State<>();    seed.readFields(in);    numFeatures = in.readInt();    freezeSurvivors = in.readBoolean();}
public CrossFoldLearner mahout_f2523_0(double v)
{    for (OnlineLogisticRegression model : models) {        model.lambda(v);    }    return this;}
public CrossFoldLearner mahout_f2524_0(double x)
{    for (OnlineLogisticRegression model : models) {        model.learningRate(x);    }    return this;}
public CrossFoldLearner mahout_f2525_0(int x)
{    for (OnlineLogisticRegression model : models) {        model.stepOffset(x);    }    return this;}
public CrossFoldLearner mahout_f2526_0(double x)
{    for (OnlineLogisticRegression model : models) {        model.decayExponent(x);    }    return this;}
public CrossFoldLearner mahout_f2527_0(double alpha)
{    for (OnlineLogisticRegression model : models) {        model.alpha(alpha);    }    return this;}
public void mahout_f2528_0(int actual, Vector instance)
{    train(record, null, actual, instance);}
public void mahout_f2529_0(long trackingKey, int actual, Vector instance)
{    train(trackingKey, null, actual, instance);}
public void mahout_f2530_0(long trackingKey, String groupKey, int actual, Vector instance)
{    record++;    int k = 0;    for (OnlineLogisticRegression model : models) {        if (k == mod(trackingKey, models.size())) {            Vector v = model.classifyFull(instance);            double score = Math.max(v.get(actual), MIN_SCORE);            logLikelihood += (Math.log(score) - logLikelihood) / Math.min(record, windowSize);            int correct = v.maxValueIndex() == actual ? 1 : 0;            percentCorrect += (correct - percentCorrect) / Math.min(record, windowSize);            if (numCategories() == 2) {                auc.addSample(actual, groupKey, v.get(1));            }        } else {            model.train(trackingKey, groupKey, actual, instance);        }        k++;    }}
private static long mahout_f2531_0(long x, int y)
{    long r = x % y;    return r < 0 ? r + y : r;}
public void mahout_f2532_0()
{    for (OnlineLogisticRegression m : models) {        m.close();    }}
public void mahout_f2533_0()
{    record = 0;}
public boolean mahout_f2534_0()
{    boolean r = true;    for (OnlineLogisticRegression model : models) {        r &= model.validModel();    }    return r;}
public Vector mahout_f2535_0(Vector instance)
{    Vector r = new DenseVector(numCategories() - 1);    DoubleDoubleFunction scale = Functions.plusMult(1.0 / models.size());    for (OnlineLogisticRegression model : models) {        r.assign(model.classify(instance), scale);    }    return r;}
public Vector mahout_f2536_0(Vector instance)
{    Vector r = new DenseVector(numCategories() - 1);    DoubleDoubleFunction scale = Functions.plusMult(1.0 / models.size());    for (OnlineLogisticRegression model : models) {        r.assign(model.classifyNoLink(instance), scale);    }    return r;}
public double mahout_f2537_0(Vector instance)
{    double r = 0;    int n = 0;    for (OnlineLogisticRegression model : models) {        n++;        r += model.classifyScalar(instance);    }    return r / n;}
public int mahout_f2538_0()
{    return models.get(0).numCategories();}
public double mahout_f2539_0()
{    return auc.auc();}
public double mahout_f2540_0()
{    return logLikelihood;}
public double mahout_f2541_0()
{    return percentCorrect;}
public CrossFoldLearner mahout_f2542_0()
{    CrossFoldLearner r = new CrossFoldLearner(models.size(), numCategories(), numFeatures, prior);    r.models.clear();    for (OnlineLogisticRegression model : models) {        model.close();        OnlineLogisticRegression newModel = new OnlineLogisticRegression(model.numCategories(), model.numFeatures(), model.prior);        newModel.copyFrom(model);        r.models.add(newModel);    }    return r;}
public int mahout_f2543_0()
{    return record;}
public void mahout_f2544_0(int record)
{    this.record = record;}
public OnlineAuc mahout_f2545_0()
{    return auc;}
public void mahout_f2546_0(OnlineAuc auc)
{    this.auc = auc;}
public double mahout_f2547_0()
{    return logLikelihood;}
public void mahout_f2548_0(double logLikelihood)
{    this.logLikelihood = logLikelihood;}
public List<OnlineLogisticRegression> mahout_f2549_0()
{    return models;}
public void mahout_f2550_0(OnlineLogisticRegression model)
{    models.add(model);}
public double[] mahout_f2551_0()
{    return parameters;}
public void mahout_f2552_0(double[] parameters)
{    this.parameters = parameters;}
public int mahout_f2553_0()
{    return numFeatures;}
public void mahout_f2554_0(int numFeatures)
{    this.numFeatures = numFeatures;}
public void mahout_f2555_0(int windowSize)
{    this.windowSize = windowSize;    auc.setWindowSize(windowSize);}
public PriorFunction mahout_f2556_0()
{    return prior;}
public void mahout_f2557_0(PriorFunction prior)
{    this.prior = prior;}
public void mahout_f2558_0(DataOutput out) throws IOException
{    out.writeInt(record);    PolymorphicWritable.write(out, auc);    out.writeDouble(logLikelihood);    out.writeInt(models.size());    for (OnlineLogisticRegression model : models) {        model.write(out);    }    for (double x : parameters) {        out.writeDouble(x);    }    out.writeInt(numFeatures);    PolymorphicWritable.write(out, prior);    out.writeDouble(percentCorrect);    out.writeInt(windowSize);}
public void mahout_f2559_0(DataInput in) throws IOException
{    record = in.readInt();    auc = PolymorphicWritable.read(in, OnlineAuc.class);    logLikelihood = in.readDouble();    int n = in.readInt();    for (int i = 0; i < n; i++) {        OnlineLogisticRegression olr = new OnlineLogisticRegression();        olr.readFields(in);        models.add(olr);    }    parameters = new double[4];    for (int i = 0; i < 4; i++) {        parameters[i] = in.readDouble();    }    numFeatures = in.readInt();    prior = PolymorphicWritable.read(in, PriorFunction.class);    percentCorrect = in.readDouble();    windowSize = in.readInt();}
private List<String> mahout_f2560_0(String line)
{    try {        return Arrays.asList(CSVUtils.parseLine(line));    } catch (IOException e) {        List<String> list = new ArrayList<>();        list.add(line);        return list;    }}
private List<String> mahout_f2561_0(CharSequence line)
{    return parseCsvLine(line.toString());}
public void mahout_f2562_0(List<String> values)
{    Preconditions.checkArgument(values.size() <= maxTargetValue, "Must have less than or equal to " + maxTargetValue + " categories for target variable, but found " + values.size());    if (maxTargetValue == Integer.MAX_VALUE) {        maxTargetValue = values.size();    }    for (String value : values) {        targetDictionary.intern(value);    }}
public CsvRecordFactory mahout_f2563_0(int max)
{    maxTargetValue = max;    return this;}
public boolean mahout_f2564_0()
{    return true;}
public void mahout_f2565_0(String line)
{        final Map<String, Integer> vars = new HashMap<>();    variableNames = parseCsvLine(line);    int column = 0;    for (String var : variableNames) {        vars.put(var, column++);    }        target = vars.get(targetName);        if (idName != null) {        id = vars.get(idName);    }        predictors = new ArrayList<>(Collections2.transform(typeMap.keySet(), new Function<String, Integer>() {        @Override        public Integer apply(String from) {            Integer r = vars.get(from);            Preconditions.checkArgument(r != null, "Can't find variable %s, only know about %s", from, vars);            return r;        }    }));    if (includeBiasTerm) {        predictors.add(-1);    }    Collections.sort(predictors);        predictorEncoders = new HashMap<>();    for (Integer predictor : predictors) {        String name;        Class<? extends FeatureVectorEncoder> c;        if (predictor == -1) {            name = INTERCEPT_TERM;            c = ConstantValueEncoder.class;        } else {            name = variableNames.get(predictor);            c = TYPE_DICTIONARY.get(typeMap.get(name));        }        try {            Preconditions.checkArgument(c != null, "Invalid type of variable %s,  wanted one of %s", typeMap.get(name), TYPE_DICTIONARY.keySet());            Constructor<? extends FeatureVectorEncoder> constructor = c.getConstructor(String.class);            Preconditions.checkArgument(constructor != null, "Can't find correct constructor for %s", typeMap.get(name));            FeatureVectorEncoder encoder = constructor.newInstance(name);            predictorEncoders.put(predictor, encoder);            encoder.setTraceDictionary(traceDictionary);        } catch (InstantiationException e) {            throw new IllegalStateException(CANNOT_CONSTRUCT_CONVERTER, e);        } catch (IllegalAccessException e) {            throw new IllegalStateException(CANNOT_CONSTRUCT_CONVERTER, e);        } catch (InvocationTargetException e) {            throw new IllegalStateException(CANNOT_CONSTRUCT_CONVERTER, e);        } catch (NoSuchMethodException e) {            throw new IllegalStateException(CANNOT_CONSTRUCT_CONVERTER, e);        }    }}
public Integer mahout_f2566_0(String from)
{    Integer r = vars.get(from);    Preconditions.checkArgument(r != null, "Can't find variable %s, only know about %s", from, vars);    return r;}
public int mahout_f2567_0(String line, Vector featureVector)
{    List<String> values = parseCsvLine(line);    int targetValue = targetDictionary.intern(values.get(target));    if (targetValue >= maxTargetValue) {        targetValue = maxTargetValue - 1;    }    for (Integer predictor : predictors) {        String value;        if (predictor >= 0) {            value = values.get(predictor);        } else {            value = null;        }        predictorEncoders.get(predictor).addToVector(value, featureVector);    }    return targetValue;}
public int mahout_f2568_0(CharSequence line, Vector featureVector, boolean returnTarget)
{    List<String> values = parseCsvLine(line);    int targetValue = -1;    if (returnTarget) {        targetValue = targetDictionary.intern(values.get(target));        if (targetValue >= maxTargetValue) {            targetValue = maxTargetValue - 1;        }    }    for (Integer predictor : predictors) {        String value = predictor >= 0 ? values.get(predictor) : null;        predictorEncoders.get(predictor).addToVector(value, featureVector);    }    return targetValue;}
public String mahout_f2569_0(CharSequence line)
{    List<String> values = parseCsvLine(line);    return values.get(target);}
public String mahout_f2570_0(int code)
{    for (String key : targetDictionary.values()) {        if (targetDictionary.intern(key) == code) {            return key;        }    }    return null;}
public String mahout_f2571_0(CharSequence line)
{    List<String> values = parseCsvLine(line);    return values.get(id);}
public Iterable<String> mahout_f2572_0()
{    return Lists.transform(predictors, new Function<Integer, String>() {        @Override        public String apply(Integer v) {            if (v >= 0) {                return variableNames.get(v);            } else {                return INTERCEPT_TERM;            }        }    });}
public String mahout_f2573_0(Integer v)
{    if (v >= 0) {        return variableNames.get(v);    } else {        return INTERCEPT_TERM;    }}
public Map<String, Set<Integer>> mahout_f2574_0()
{    return traceDictionary;}
public CsvRecordFactory mahout_f2575_0(boolean useBias)
{    includeBiasTerm = useBias;    return this;}
public List<String> mahout_f2576_0()
{    List<String> r = targetDictionary.values();    if (r.size() > maxTargetValue) {        r.subList(maxTargetValue, r.size()).clear();    }    return r;}
public String mahout_f2577_0()
{    return idName;}
public void mahout_f2578_0(String idName)
{    this.idName = idName;}
public final Vector mahout_f2579_0(String groupKey, int actual, Vector instance, AbstractVectorClassifier classifier)
{        Vector v = classifier.classify(instance);    Vector r = v.like();    if (actual != 0) {        r.setQuick(actual - 1, 1);    }    r.assign(v, Functions.MINUS);    return r;}
public double mahout_f2580_0(double oldValue, double generations, double learningRate)
{    oldValue *= Math.pow(1 - alphaByLambda * learningRate, generations);    double newValue = oldValue - Math.signum(oldValue) * learningRate * generations;    if (newValue * oldValue < 0.0) {                return 0.0;    } else {        return newValue;    }}
public double mahout_f2581_0(double betaIJ)
{    return l1.logP(betaIJ) + alphaByLambda * l2.logP(betaIJ);}
public void mahout_f2582_0(DataOutput out) throws IOException
{    out.writeDouble(alphaByLambda);    l1.write(out);    l2.write(out);}
public void mahout_f2583_0(DataInput in) throws IOException
{    alphaByLambda = in.readDouble();    l1 = new L1();    l1.readFields(in);    l2 = new L2();    l2.readFields(in);}
public void mahout_f2584_0(Random gen)
{    double hiddenFanIn = 1.0 / Math.sqrt(numFeatures);    for (int i = 0; i < numHidden; i++) {        for (int j = 0; j < numFeatures; j++) {            double val = (2.0 * gen.nextDouble() - 1.0) * hiddenFanIn;            hiddenWeights[i].setQuick(j, val);        }    }    double outputFanIn = 1.0 / Math.sqrt(numHidden);    for (int i = 0; i < numOutput; i++) {        for (int j = 0; j < numHidden; j++) {            double val = (2.0 * gen.nextDouble() - 1.0) * outputFanIn;            outputWeights[i].setQuick(j, val);        }    }}
public GradientMachine mahout_f2585_0(double learningRate)
{    this.learningRate = learningRate;    return this;}
public GradientMachine mahout_f2586_0(double regularization)
{    this.regularization = regularization;    return this;}
public GradientMachine mahout_f2587_0(double sparsity)
{    this.sparsity = sparsity;    return this;}
public GradientMachine mahout_f2588_0(double sparsityLearningRate)
{    this.sparsityLearningRate = sparsityLearningRate;    return this;}
public void mahout_f2589_0(GradientMachine other)
{    numFeatures = other.numFeatures;    numHidden = other.numHidden;    numOutput = other.numOutput;    learningRate = other.learningRate;    regularization = other.regularization;    sparsity = other.sparsity;    sparsityLearningRate = other.sparsityLearningRate;    hiddenWeights = new DenseVector[numHidden];    for (int i = 0; i < numHidden; i++) {        hiddenWeights[i] = other.hiddenWeights[i].clone();    }    hiddenBias = other.hiddenBias.clone();    outputWeights = new DenseVector[numOutput];    for (int i = 0; i < numOutput; i++) {        outputWeights[i] = other.outputWeights[i].clone();    }    outputBias = other.outputBias.clone();}
public int mahout_f2590_0()
{    return numOutput;}
public int mahout_f2591_0()
{    return numFeatures;}
public int mahout_f2592_0()
{    return numHidden;}
public DenseVector mahout_f2593_0(Vector input)
{    DenseVector activations = new DenseVector(numHidden);    for (int i = 0; i < numHidden; i++) {        activations.setQuick(i, hiddenWeights[i].dot(input));    }    activations.assign(hiddenBias, Functions.PLUS);    activations.assign(Functions.min(40.0)).assign(Functions.max(-40));    activations.assign(Functions.SIGMOID);    return activations;}
public DenseVector mahout_f2594_0(Vector hiddenActivation)
{    DenseVector activations = new DenseVector(numOutput);    for (int i = 0; i < numOutput; i++) {        activations.setQuick(i, outputWeights[i].dot(hiddenActivation));    }    activations.assign(outputBias, Functions.PLUS);    return activations;}
public void mahout_f2595_0(Vector hiddenActivation, Collection<Integer> goodLabels, int numTrials, Random gen)
{        if (goodLabels.size() >= numOutput) {        return;    }    for (Integer good : goodLabels) {        double goodScore = outputWeights[good].dot(hiddenActivation);        int highestBad = -1;        double highestBadScore = Double.NEGATIVE_INFINITY;        for (int i = 0; i < numTrials; i++) {            int bad = gen.nextInt(numOutput);            while (goodLabels.contains(bad)) {                bad = gen.nextInt(numOutput);            }            double badScore = outputWeights[bad].dot(hiddenActivation);            if (badScore > highestBadScore) {                highestBadScore = badScore;                highestBad = bad;            }        }        int bad = highestBad;        double loss = 1.0 - goodScore + highestBadScore;        if (loss < 0.0) {            continue;        }                                                        Vector gradGood = outputWeights[good].clone();        gradGood.assign(Functions.NEGATE);        Vector propHidden = gradGood.clone();        Vector gradBad = outputWeights[bad].clone();        propHidden.assign(gradBad, Functions.PLUS);        gradGood.assign(Functions.mult(-learningRate * (1.0 - regularization)));        outputWeights[good].assign(gradGood, Functions.PLUS);        gradBad.assign(Functions.mult(-learningRate * (1.0 + regularization)));        outputWeights[bad].assign(gradBad, Functions.PLUS);        outputBias.setQuick(good, outputBias.get(good) + learningRate);        outputBias.setQuick(bad, outputBias.get(bad) - learningRate);                Vector gradSig = hiddenActivation.clone();        gradSig.assign(Functions.SIGMOIDGRADIENT);                for (int i = 0; i < numHidden; i++) {            gradSig.setQuick(i, gradSig.get(i) * propHidden.get(i));        }        for (int i = 0; i < numHidden; i++) {            for (int j = 0; j < numFeatures; j++) {                double v = hiddenWeights[i].get(j);                v -= learningRate * (gradSig.get(i) + regularization * v);                hiddenWeights[i].setQuick(j, v);            }        }    }}
public Vector mahout_f2596_0(Vector instance)
{    Vector result = classifyNoLink(instance);        int max = result.maxValueIndex();    result.assign(0);    result.setQuick(max, 1.0);    return result.viewPart(1, result.size() - 1);}
public Vector mahout_f2597_0(Vector instance)
{    DenseVector hidden = inputToHidden(instance);    return hiddenToOutput(hidden);}
public double mahout_f2598_0(Vector instance)
{    Vector output = classifyNoLink(instance);    if (output.get(0) > output.get(1)) {        return 0;    }    return 1;}
public GradientMachine mahout_f2599_0()
{    close();    GradientMachine r = new GradientMachine(numFeatures(), numHidden(), numCategories());    r.copyFrom(this);    return r;}
public void mahout_f2600_0(DataOutput out) throws IOException
{    out.writeInt(WRITABLE_VERSION);    out.writeDouble(learningRate);    out.writeDouble(regularization);    out.writeDouble(sparsity);    out.writeDouble(sparsityLearningRate);    out.writeInt(numFeatures);    out.writeInt(numHidden);    out.writeInt(numOutput);    VectorWritable.writeVector(out, hiddenBias);    for (int i = 0; i < numHidden; i++) {        VectorWritable.writeVector(out, hiddenWeights[i]);    }    VectorWritable.writeVector(out, outputBias);    for (int i = 0; i < numOutput; i++) {        VectorWritable.writeVector(out, outputWeights[i]);    }}
public void mahout_f2601_0(DataInput in) throws IOException
{    int version = in.readInt();    if (version == WRITABLE_VERSION) {        learningRate = in.readDouble();        regularization = in.readDouble();        sparsity = in.readDouble();        sparsityLearningRate = in.readDouble();        numFeatures = in.readInt();        numHidden = in.readInt();        numOutput = in.readInt();        hiddenWeights = new DenseVector[numHidden];        hiddenBias = VectorWritable.readVector(in);        for (int i = 0; i < numHidden; i++) {            hiddenWeights[i] = VectorWritable.readVector(in);        }        outputWeights = new DenseVector[numOutput];        outputBias = VectorWritable.readVector(in);        for (int i = 0; i < numOutput; i++) {            outputWeights[i] = VectorWritable.readVector(in);        }    } else {        throw new IOException("Incorrect object version, wanted " + WRITABLE_VERSION + " got " + version);    }}
public void mahout_f2602_0()
{}
public void mahout_f2603_0(long trackingKey, String groupKey, int actual, Vector instance)
{    Vector hiddenActivation = inputToHidden(instance);    hiddenToOutput(hiddenActivation);    Collection<Integer> goodLabels = new HashSet<>();    goodLabels.add(actual);    updateRanking(hiddenActivation, goodLabels, 2, rnd);}
public void mahout_f2604_0(long trackingKey, int actual, Vector instance)
{    train(trackingKey, null, actual, instance);}
public void mahout_f2605_0(int actual, Vector instance)
{    train(0, null, actual, instance);}
public double mahout_f2606_0(double oldValue, double generations, double learningRate)
{    double newValue = oldValue - Math.signum(oldValue) * learningRate * generations;    if (newValue * oldValue < 0) {                return 0;    } else {        return newValue;    }}
public double mahout_f2607_0(double betaIJ)
{    return -Math.abs(betaIJ);}
public void mahout_f2608_0(DataOutput out) throws IOException
{}
public void mahout_f2609_0(DataInput dataInput) throws IOException
{}
public double mahout_f2610_0(double oldValue, double generations, double learningRate)
{    return oldValue * Math.pow(1.0 - learningRate / s2, generations);}
public double mahout_f2611_0(double betaIJ)
{    return -betaIJ * betaIJ / s2 / 2.0 - Math.log(s) - HALF_LOG_2PI;}
public void mahout_f2612_0(DataOutput out) throws IOException
{    out.writeDouble(s2);    out.writeDouble(s);}
public void mahout_f2613_0(DataInput in) throws IOException
{    s2 = in.readDouble();    s = in.readDouble();}
public Vector mahout_f2614_0(String groupKey, int actual, Vector instance, AbstractVectorClassifier classifier)
{    if (random.nextDouble() < alpha) {                if (!hasZero || !hasOne) {            throw new IllegalStateException();        }        return rank.apply(groupKey, actual, instance, classifier);    } else {        hasZero |= actual == 0;        hasOne |= actual == 1;                rank.addToHistory(actual, instance);        return basic.apply(groupKey, actual, instance, classifier);    }}
public void mahout_f2615_0(Vector features, Map<String, Set<Integer>> traceDictionary, AbstractVectorClassifier learner)
{        features.assign(0);    for (Map.Entry<String, Set<Integer>> entry : traceDictionary.entrySet()) {                String key = entry.getKey();        Set<Integer> value = entry.getValue();                if (!weightMap.containsKey(key)) {                        for (Integer where : value) {                features.set(where, 1);            }                        Vector v = learner.classifyNoLink(features);            weightMap.put(key, v);                        for (Integer where : value) {                features.set(where, 0);            }        }    }}
public List<Weight> mahout_f2616_0(int n)
{    Queue<Weight> pq = new PriorityQueue<>();    for (Map.Entry<String, Vector> entry : weightMap.entrySet()) {        pq.add(new Weight(entry.getKey(), entry.getValue()));        while (pq.size() > n) {            pq.poll();        }    }    List<Weight> r = new ArrayList<>(pq);    Collections.sort(r, Ordering.natural().reverse());    return r;}
public int mahout_f2617_0(Category o)
{    int r = Double.compare(Math.abs(weight), Math.abs(o.weight));    if (r == 0) {        if (o.index < index) {            return -1;        }        if (o.index > index) {            return 1;        }        return 0;    }    return r;}
public boolean mahout_f2618_0(Object o)
{    if (!(o instanceof Category)) {        return false;    }    Category other = (Category) o;    return index == other.index && weight == other.weight;}
public int mahout_f2619_0()
{    return RandomUtils.hashDouble(weight) ^ index;}
public int mahout_f2620_0(Weight other)
{    int r = Double.compare(Math.abs(this.value), Math.abs(other.value));    if (r == 0) {        return feature.compareTo(other.feature);    }    return r;}
public boolean mahout_f2621_0(Object o)
{    if (!(o instanceof Weight)) {        return false;    }    Weight other = (Weight) o;    return feature.equals(other.feature) && value == other.value && maxIndex == other.maxIndex && categories.equals(other.categories);}
public int mahout_f2622_0()
{    return feature.hashCode() ^ RandomUtils.hashDouble(value) ^ maxIndex ^ categories.hashCode();}
public String mahout_f2623_0()
{    return feature;}
public double mahout_f2624_0()
{    return value;}
public double mahout_f2625_0(int n)
{    return categories.get(n).weight;}
public double mahout_f2626_0(int n)
{    return categories.get(n).index;}
public int mahout_f2627_0()
{    return maxIndex;}
public static void mahout_f2628_0(String path, CrossFoldLearner model) throws IOException
{    try (DataOutputStream out = new DataOutputStream(new FileOutputStream(path))) {        PolymorphicWritable.write(out, model);    }}
public static void mahout_f2629_0(String path, OnlineLogisticRegression model) throws IOException
{    try (DataOutputStream out = new DataOutputStream(new FileOutputStream(path))) {        PolymorphicWritable.write(out, model);    }}
public static void mahout_f2630_0(String path, AdaptiveLogisticRegression model) throws IOException
{    try (DataOutputStream out = new DataOutputStream(new FileOutputStream(path))) {        PolymorphicWritable.write(out, model);    }}
public static T mahout_f2631_0(InputStream in, Class<T> clazz) throws IOException
{    DataInput dataIn = new DataInputStream(in);    try {        return PolymorphicWritable.read(dataIn, clazz);    } finally {        Closeables.close(in, false);    }}
public OnlineLogisticRegression mahout_f2632_0(double alpha)
{    this.decayFactor = alpha;    return this;}
public OnlineLogisticRegression mahout_f2633_0(double lambda)
{        super.lambda(lambda);    return this;}
public OnlineLogisticRegression mahout_f2634_0(double learningRate)
{    this.mu0 = learningRate;    return this;}
public OnlineLogisticRegression mahout_f2635_0(int stepOffset)
{    this.stepOffset = stepOffset;    return this;}
public OnlineLogisticRegression mahout_f2636_0(double decayExponent)
{    if (decayExponent > 0) {        decayExponent = -decayExponent;    }    this.forgettingExponent = decayExponent;    return this;}
public double mahout_f2637_0(int j)
{    return Math.sqrt(perTermAnnealingOffset / updateCounts.get(j));}
public double mahout_f2638_0()
{    return mu0 * Math.pow(decayFactor, getStep()) * Math.pow(getStep() + stepOffset, forgettingExponent);}
public void mahout_f2639_0(OnlineLogisticRegression other)
{    super.copyFrom(other);    mu0 = other.mu0;    decayFactor = other.decayFactor;    stepOffset = other.stepOffset;    forgettingExponent = other.forgettingExponent;    perTermAnnealingOffset = other.perTermAnnealingOffset;}
public OnlineLogisticRegression mahout_f2640_0()
{    close();    OnlineLogisticRegression r = new OnlineLogisticRegression(numCategories(), numFeatures(), prior);    r.copyFrom(this);    return r;}
public void mahout_f2641_0(DataOutput out) throws IOException
{    out.writeInt(WRITABLE_VERSION);    out.writeDouble(mu0);    out.writeDouble(getLambda());    out.writeDouble(decayFactor);    out.writeInt(stepOffset);    out.writeInt(step);    out.writeDouble(forgettingExponent);    out.writeInt(perTermAnnealingOffset);    out.writeInt(numCategories);    MatrixWritable.writeMatrix(out, beta);    PolymorphicWritable.write(out, prior);    VectorWritable.writeVector(out, updateCounts);    VectorWritable.writeVector(out, updateSteps);}
public void mahout_f2642_0(DataInput in) throws IOException
{    int version = in.readInt();    if (version == WRITABLE_VERSION) {        mu0 = in.readDouble();        lambda(in.readDouble());        decayFactor = in.readDouble();        stepOffset = in.readInt();        step = in.readInt();        forgettingExponent = in.readDouble();        perTermAnnealingOffset = in.readInt();        numCategories = in.readInt();        beta = MatrixWritable.readMatrix(in);        prior = PolymorphicWritable.read(in, PriorFunction.class);        updateCounts = VectorWritable.readVector(in);        updateSteps = VectorWritable.readVector(in);    } else {        throw new IOException("Incorrect object version, wanted " + WRITABLE_VERSION + " got " + version);    }}
public PassiveAggressive mahout_f2643_0(double learningRate)
{    this.learningRate = learningRate;    return this;}
public void mahout_f2644_0(PassiveAggressive other)
{    learningRate = other.learningRate;    numCategories = other.numCategories;    weights = other.weights;}
public int mahout_f2645_0()
{    return numCategories;}
public Vector mahout_f2646_0(Vector instance)
{    Vector result = classifyNoLink(instance);        double max = result.maxValue();    result.assign(Functions.minus(max)).assign(Functions.EXP);    result = result.divide(result.norm(1));    return result.viewPart(1, result.size() - 1);}
public Vector mahout_f2647_0(Vector instance)
{    Vector result = new DenseVector(weights.numRows());    result.assign(0);    for (int i = 0; i < weights.numRows(); i++) {        result.setQuick(i, weights.viewRow(i).dot(instance));    }    return result;}
public double mahout_f2648_0(Vector instance)
{    double v1 = weights.viewRow(0).dot(instance);    double v2 = weights.viewRow(1).dot(instance);    v1 = Math.exp(v1);    v2 = Math.exp(v2);    return v2 / (v1 + v2);}
public int mahout_f2649_0()
{    return weights.numCols();}
public PassiveAggressive mahout_f2650_0()
{    close();    PassiveAggressive r = new PassiveAggressive(numCategories(), numFeatures());    r.copyFrom(this);    return r;}
public void mahout_f2651_0(DataOutput out) throws IOException
{    out.writeInt(WRITABLE_VERSION);    out.writeDouble(learningRate);    out.writeInt(numCategories);    MatrixWritable.writeMatrix(out, weights);}
public void mahout_f2652_0(DataInput in) throws IOException
{    int version = in.readInt();    if (version == WRITABLE_VERSION) {        learningRate = in.readDouble();        numCategories = in.readInt();        weights = MatrixWritable.readMatrix(in);    } else {        throw new IOException("Incorrect object version, wanted " + WRITABLE_VERSION + " got " + version);    }}
public void mahout_f2653_0()
{}
public void mahout_f2654_1(long trackingKey, String groupKey, int actual, Vector instance)
{    if (lossCount > 1000) {                lossCount = 0;        lossSum = 0;    }    Vector result = classifyNoLink(instance);    double myScore = result.get(actual);        int otherIndex = result.maxValueIndex();    double otherValue = result.get(otherIndex);    if (otherIndex == actual) {        result.setQuick(otherIndex, Double.NEGATIVE_INFINITY);        otherIndex = result.maxValueIndex();        otherValue = result.get(otherIndex);    }    double loss = 1.0 - myScore + otherValue;    lossCount += 1;    if (loss >= 0) {        lossSum += loss;        double tau = loss / (instance.dot(instance) + 0.5 / learningRate);        Vector delta = instance.clone();        delta.assign(Functions.mult(tau));        weights.viewRow(actual).assign(delta, Functions.PLUS);                delta.assign(Functions.mult(-1));        weights.viewRow(otherIndex).assign(delta, Functions.PLUS);        }}
public void mahout_f2655_0(long trackingKey, int actual, Vector instance)
{    train(trackingKey, null, actual, instance);}
public void mahout_f2656_0(int actual, Vector instance)
{    train(0, null, actual, instance);}
public static void mahout_f2657_0(DataOutput dataOutput, T value) throws IOException
{    dataOutput.writeUTF(value.getClass().getName());    value.write(dataOutput);}
public static T mahout_f2658_0(DataInput dataInput, Class<? extends T> clazz) throws IOException
{    String className = dataInput.readUTF();    T r = ClassUtils.instantiateAs(className, clazz);    r.readFields(dataInput);    return r;}
public final Vector mahout_f2659_0(String groupKey, int actual, Vector instance, AbstractVectorClassifier classifier)
{    addToHistory(actual, instance);        Deque<Vector> otherSide = history.get(1 - actual);    int n = otherSide.size();    Vector r = null;    for (Vector other : otherSide) {        Vector g = BASIC.apply(groupKey, actual, instance.minus(other), classifier);        if (r == null) {            r = g;        } else {            r.assign(g, Functions.plusMult(1.0 / n));        }    }    return r;}
public void mahout_f2660_0(int actual, Vector instance)
{    while (history.size() <= actual) {        history.add(new ArrayDeque<Vector>(window));    }        Deque<Vector> ourSide = history.get(actual);    ourSide.add(instance);    while (ourSide.size() >= window) {        ourSide.pollFirst();    }}
public Gradient mahout_f2661_0()
{    return BASIC;}
public double mahout_f2662_0(double oldValue, double generations, double learningRate)
{    for (int i = 0; i < generations; i++) {        oldValue -= learningRate * oldValue * (df + 1.0) / (df + oldValue * oldValue);    }    return oldValue;}
public double mahout_f2663_0(double betaIJ)
{    return Gamma.logGamma((df + 1.0) / 2.0) - Math.log(df * Math.PI) - Gamma.logGamma(df / 2.0) - (df + 1.0) / 2.0 * Math.log1p(betaIJ * betaIJ);}
public void mahout_f2664_0(DataOutput out) throws IOException
{    out.writeDouble(df);}
public void mahout_f2665_0(DataInput in) throws IOException
{    df = in.readDouble();}
public double mahout_f2666_0(double oldValue, double generations, double learningRate)
{    return oldValue;}
public double mahout_f2667_0(double betaIJ)
{    return 0;}
public void mahout_f2668_0(DataOutput dataOutput) throws IOException
{}
public void mahout_f2669_0(DataInput dataInput) throws IOException
{}
public void mahout_f2670_0(DataOutput out) throws IOException
{    out.writeInt(id);    out.writeLong(getNumObservations());    out.writeLong(getTotalObservations());    VectorWritable.writeVector(out, getCenter());    VectorWritable.writeVector(out, getRadius());    out.writeDouble(s0);    VectorWritable.writeVector(out, s1);    VectorWritable.writeVector(out, s2);}
public void mahout_f2671_0(DataInput in) throws IOException
{    this.id = in.readInt();    this.setNumObservations(in.readLong());    this.setTotalObservations(in.readLong());    this.setCenter(VectorWritable.readVector(in));    this.setRadius(VectorWritable.readVector(in));    this.setS0(in.readDouble());    this.setS1(VectorWritable.readVector(in));    this.setS2(VectorWritable.readVector(in));}
public void mahout_f2672_0(Configuration job)
{}
public Collection<Parameter<?>> mahout_f2673_0()
{    return Collections.emptyList();}
public void mahout_f2674_0(String prefix, Configuration jobConf)
{}
public int mahout_f2675_0()
{    return id;}
protected void mahout_f2676_0(int id)
{    this.id = id;}
public long mahout_f2677_0()
{    return numObservations;}
protected void mahout_f2678_0(long l)
{    this.numObservations = l;}
public long mahout_f2679_0()
{    return totalObservations;}
protected void mahout_f2680_0(long totalPoints)
{    this.totalObservations = totalPoints;}
public Vector mahout_f2681_0()
{    return center;}
protected void mahout_f2682_0(Vector center)
{    this.center = center;}
public Vector mahout_f2683_0()
{    return radius;}
protected void mahout_f2684_0(Vector radius)
{    this.radius = radius;}
protected double mahout_f2685_0()
{    return s0;}
protected void mahout_f2686_0(double s0)
{    this.s0 = s0;}
protected Vector mahout_f2687_0()
{    return s1;}
protected void mahout_f2688_0(Vector s1)
{    this.s1 = s1;}
protected Vector mahout_f2689_0()
{    return s2;}
protected void mahout_f2690_0(Vector s2)
{    this.s2 = s2;}
public void mahout_f2691_0(Model<VectorWritable> x)
{    AbstractCluster cl = (AbstractCluster) x;    setS0(getS0() + cl.getS0());    setS1(getS1().plus(cl.getS1()));    setS2(getS2().plus(cl.getS2()));}
public void mahout_f2692_0(VectorWritable x)
{    observe(x.get());}
public void mahout_f2693_0(VectorWritable x, double weight)
{    observe(x.get(), weight);}
public void mahout_f2694_0(Vector x, double weight)
{    if (weight == 1.0) {        observe(x);    } else {        setS0(getS0() + weight);        Vector weightedX = x.times(weight);        if (getS1() == null) {            setS1(weightedX);        } else {            getS1().assign(weightedX, Functions.PLUS);        }        Vector x2 = x.times(x).times(weight);        if (getS2() == null) {            setS2(x2);        } else {            getS2().assign(x2, Functions.PLUS);        }    }}
public void mahout_f2695_0(Vector x)
{    setS0(getS0() + 1);    if (getS1() == null) {        setS1(x.clone());    } else {        getS1().assign(x, Functions.PLUS);    }    Vector x2 = x.times(x);    if (getS2() == null) {        setS2(x2);    } else {        getS2().assign(x2, Functions.PLUS);    }}
public void mahout_f2696_0()
{    if (getS0() == 0) {        return;    }    setNumObservations((long) getS0());    setTotalObservations(getTotalObservations() + getNumObservations());    setCenter(getS1().divide(getS0()));        if (getS0() > 1) {        setRadius(getS2().times(getS0()).minus(getS1().times(getS1())).assign(new SquareRootFunction()).divide(getS0()));    }    setS0(0);    setS1(center.like());    setS2(center.like());}
public String mahout_f2697_1(String[] bindings)
{    String fmtString = "";    try {        fmtString = jxn.writeValueAsString(asJson(bindings));    } catch (IOException e) {            }    return fmtString;}
public Map<String, Object> mahout_f2698_1(String[] bindings)
{    Map<String, Object> dict = new HashMap<>();    dict.put("identifier", getIdentifier());    dict.put("n", getNumObservations());    if (getCenter() != null) {        try {            dict.put("c", formatVectorAsJson(getCenter(), bindings));        } catch (IOException e) {                    }    }    if (getRadius() != null) {        try {            dict.put("r", formatVectorAsJson(getRadius(), bindings));        } catch (IOException e) {                    }    }    return dict;}
public Vector mahout_f2699_0()
{    return getS0() == 0 ? getCenter() : getS1().divide(getS0());}
public static String mahout_f2700_1(Vector v, String[] bindings)
{    String fmtString = "";    try {        fmtString = jxn.writeValueAsString(formatVectorAsJson(v, bindings));    } catch (IOException e) {            }    return fmtString;}
public static List<Object> mahout_f2701_0(Vector v, String[] bindings) throws IOException
{    boolean hasBindings = bindings != null;    boolean isSparse = v.getNumNonZeroElements() != v.size();        Vector provider = v.isSequentialAccess() ? v : new SequentialAccessSparseVector(v);    List<Object> terms = new LinkedList<>();    String term = "";    for (Element elem : provider.nonZeroes()) {        if (hasBindings && bindings.length >= elem.index() + 1 && bindings[elem.index()] != null) {            term = bindings[elem.index()];        } else if (hasBindings || isSparse) {            term = String.valueOf(elem.index());        }        Map<String, Object> term_entry = new HashMap<>();        double roundedWeight = (double) Math.round(elem.get() * 1000) / 1000;        if (hasBindings || isSparse) {            term_entry.put(term, roundedWeight);            terms.add(term_entry);        } else {            terms.add(roundedWeight);        }    }    return terms;}
public boolean mahout_f2702_0()
{        return false;}
public String mahout_f2703_0()
{    return "C" + this.getId() + ": " + this.computeCentroid().asFormatString();}
public String mahout_f2704_0()
{    return getIdentifier() + ": " + getCenter().asFormatString();}
public String mahout_f2705_0()
{    return "C-" + getId();}
public double mahout_f2706_0()
{    return t1;}
public double mahout_f2707_0()
{    return t2;}
public double mahout_f2708_0()
{    return t3;}
public double mahout_f2709_0()
{    return t4;}
public void mahout_f2710_0()
{    t1 = t3;    t2 = t4;}
public void mahout_f2711_1(Vector point, Collection<Canopy> canopies)
{    boolean pointStronglyBound = false;    for (Canopy canopy : canopies) {        double dist = measure.distance(canopy.getCenter().getLengthSquared(), canopy.getCenter(), point);        if (dist < t1) {            if (log.isDebugEnabled()) {                            }            canopy.observe(point);        }        pointStronglyBound = pointStronglyBound || dist < t2;    }    if (!pointStronglyBound) {        if (log.isDebugEnabled()) {                    }        canopies.add(new Canopy(point, nextCanopyId++, measure));    }}
public boolean mahout_f2712_0(Canopy canopy, Vector point)
{    return measure.distance(canopy.getCenter().getLengthSquared(), canopy.getCenter(), point) < t1;}
public static List<Canopy> mahout_f2713_0(List<Vector> points, DistanceMeasure measure, double t1, double t2)
{    List<Canopy> canopies = Lists.newArrayList();    /**     * Reference Implementation: Given a distance metric, one can create     * canopies as follows: Start with a list of the data points in any     * order, and with two distance thresholds, T1 and T2, where T1 > T2.     * (These thresholds can be set by the user, or selected by     * cross-validation.) Pick a point on the list and measure its distance     * to all other points. Put all points that are within distance     * threshold T1 into a canopy. Remove from the list all points that are     * within distance threshold T2. Repeat until the list is empty.     */    int nextCanopyId = 0;    while (!points.isEmpty()) {        Iterator<Vector> ptIter = points.iterator();        Vector p1 = ptIter.next();        ptIter.remove();        Canopy canopy = new Canopy(p1, nextCanopyId++, measure);        canopies.add(canopy);        while (ptIter.hasNext()) {            Vector p2 = ptIter.next();            double dist = measure.distance(p1, p2);                        if (dist < t1) {                canopy.observe(p2);            }                        if (dist < t2) {                ptIter.remove();            }        }        for (Canopy c : canopies) {            c.computeParameters();        }    }    return canopies;}
public static List<Vector> mahout_f2714_0(Iterable<Canopy> canopies)
{    List<Vector> result = Lists.newArrayList();    for (Canopy canopy : canopies) {        result.add(canopy.getCenter());    }    return result;}
public static void mahout_f2715_0(Iterable<Canopy> canopies)
{    for (Canopy canopy : canopies) {        canopy.computeParameters();    }}
public void mahout_f2716_0(double t3)
{    this.t3 = t3;}
public void mahout_f2717_0(double t4)
{    this.t4 = t4;}
public static CanopyClusterer mahout_f2718_0(Configuration configuration)
{    double t1 = Double.parseDouble(configuration.get(T1_KEY));    double t2 = Double.parseDouble(configuration.get(T2_KEY));    DistanceMeasure measure = ClassUtils.instantiateAs(configuration.get(DISTANCE_MEASURE_KEY), DistanceMeasure.class);    measure.configure(configuration);    CanopyClusterer canopyClusterer = new CanopyClusterer(measure, t1, t2);    String d = configuration.get(T3_KEY);    if (d != null) {        canopyClusterer.setT3(Double.parseDouble(d));    }    d = configuration.get(T4_KEY);    if (d != null) {        canopyClusterer.setT4(Double.parseDouble(d));    }    return canopyClusterer;}
public static void mahout_f2719_0(String[] args) throws Exception
{    ToolRunner.run(new Configuration(), new CanopyDriver(), args);}
public int mahout_f2720_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption(DefaultOptionCreator.distanceMeasureOption().create());    addOption(DefaultOptionCreator.t1Option().create());    addOption(DefaultOptionCreator.t2Option().create());    addOption(DefaultOptionCreator.t3Option().create());    addOption(DefaultOptionCreator.t4Option().create());    addOption(DefaultOptionCreator.clusterFilterOption().create());    addOption(DefaultOptionCreator.overwriteOption().create());    addOption(DefaultOptionCreator.clusteringOption().create());    addOption(DefaultOptionCreator.methodOption().create());    addOption(DefaultOptionCreator.outlierThresholdOption().create());    if (parseArguments(args) == null) {        return -1;    }    Path input = getInputPath();    Path output = getOutputPath();    Configuration conf = getConf();    if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {        HadoopUtil.delete(conf, output);    }    String measureClass = getOption(DefaultOptionCreator.DISTANCE_MEASURE_OPTION);    double t1 = Double.parseDouble(getOption(DefaultOptionCreator.T1_OPTION));    double t2 = Double.parseDouble(getOption(DefaultOptionCreator.T2_OPTION));    double t3 = t1;    if (hasOption(DefaultOptionCreator.T3_OPTION)) {        t3 = Double.parseDouble(getOption(DefaultOptionCreator.T3_OPTION));    }    double t4 = t2;    if (hasOption(DefaultOptionCreator.T4_OPTION)) {        t4 = Double.parseDouble(getOption(DefaultOptionCreator.T4_OPTION));    }    int clusterFilter = 0;    if (hasOption(DefaultOptionCreator.CLUSTER_FILTER_OPTION)) {        clusterFilter = Integer.parseInt(getOption(DefaultOptionCreator.CLUSTER_FILTER_OPTION));    }    boolean runClustering = hasOption(DefaultOptionCreator.CLUSTERING_OPTION);    boolean runSequential = getOption(DefaultOptionCreator.METHOD_OPTION).equalsIgnoreCase(DefaultOptionCreator.SEQUENTIAL_METHOD);    DistanceMeasure measure = ClassUtils.instantiateAs(measureClass, DistanceMeasure.class);    double clusterClassificationThreshold = 0.0;    if (hasOption(DefaultOptionCreator.OUTLIER_THRESHOLD)) {        clusterClassificationThreshold = Double.parseDouble(getOption(DefaultOptionCreator.OUTLIER_THRESHOLD));    }    run(conf, input, output, measure, t1, t2, t3, t4, clusterFilter, runClustering, clusterClassificationThreshold, runSequential);    return 0;}
public static void mahout_f2721_0(Configuration conf, Path input, Path output, DistanceMeasure measure, double t1, double t2, double t3, double t4, int clusterFilter, boolean runClustering, double clusterClassificationThreshold, boolean runSequential) throws IOException, InterruptedException, ClassNotFoundException
{    Path clustersOut = buildClusters(conf, input, output, measure, t1, t2, t3, t4, clusterFilter, runSequential);    if (runClustering) {        clusterData(conf, input, clustersOut, output, clusterClassificationThreshold, runSequential);    }}
public static void mahout_f2722_0(Configuration conf, Path input, Path output, DistanceMeasure measure, double t1, double t2, boolean runClustering, double clusterClassificationThreshold, boolean runSequential) throws IOException, InterruptedException, ClassNotFoundException
{    run(conf, input, output, measure, t1, t2, t1, t2, 0, runClustering, clusterClassificationThreshold, runSequential);}
public static void mahout_f2723_0(Path input, Path output, DistanceMeasure measure, double t1, double t2, boolean runClustering, double clusterClassificationThreshold, boolean runSequential) throws IOException, InterruptedException, ClassNotFoundException
{    run(new Configuration(), input, output, measure, t1, t2, runClustering, clusterClassificationThreshold, runSequential);}
public static Path mahout_f2724_0(Configuration conf, Path input, Path output, DistanceMeasure measure, double t1, double t2, int clusterFilter, boolean runSequential) throws IOException, InterruptedException, ClassNotFoundException
{    return buildClusters(conf, input, output, measure, t1, t2, t1, t2, clusterFilter, runSequential);}
public static Path mahout_f2725_1(Configuration conf, Path input, Path output, DistanceMeasure measure, double t1, double t2, double t3, double t4, int clusterFilter, boolean runSequential) throws IOException, InterruptedException, ClassNotFoundException
{        if (runSequential) {        return buildClustersSeq(input, output, measure, t1, t2, clusterFilter);    } else {        return buildClustersMR(conf, input, output, measure, t1, t2, t3, t4, clusterFilter);    }}
private static Path mahout_f2726_1(Path input, Path output, DistanceMeasure measure, double t1, double t2, int clusterFilter) throws IOException
{    CanopyClusterer clusterer = new CanopyClusterer(measure, t1, t2);    Collection<Canopy> canopies = Lists.newArrayList();    Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(input.toUri(), conf);    for (VectorWritable vw : new SequenceFileDirValueIterable<VectorWritable>(input, PathType.LIST, PathFilters.logsCRCFilter(), conf)) {        clusterer.addPointToCanopies(vw.get(), canopies);    }    Path canopyOutputDir = new Path(output, Cluster.CLUSTERS_DIR + '0' + Cluster.FINAL_ITERATION_SUFFIX);    Path path = new Path(canopyOutputDir, "part-r-00000");    SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, path, Text.class, ClusterWritable.class);    try {        ClusterWritable clusterWritable = new ClusterWritable();        for (Canopy canopy : canopies) {            canopy.computeParameters();            if (log.isDebugEnabled()) {                            }            if (canopy.getNumObservations() > clusterFilter) {                clusterWritable.setValue(canopy);                writer.append(new Text(canopy.getIdentifier()), clusterWritable);            }        }    } finally {        Closeables.close(writer, false);    }    return canopyOutputDir;}
private static Path mahout_f2727_0(Configuration conf, Path input, Path output, DistanceMeasure measure, double t1, double t2, double t3, double t4, int clusterFilter) throws IOException, InterruptedException, ClassNotFoundException
{    conf.set(CanopyConfigKeys.DISTANCE_MEASURE_KEY, measure.getClass().getName());    conf.set(CanopyConfigKeys.T1_KEY, String.valueOf(t1));    conf.set(CanopyConfigKeys.T2_KEY, String.valueOf(t2));    conf.set(CanopyConfigKeys.T3_KEY, String.valueOf(t3));    conf.set(CanopyConfigKeys.T4_KEY, String.valueOf(t4));    conf.set(CanopyConfigKeys.CF_KEY, String.valueOf(clusterFilter));    Job job = new Job(conf, "Canopy Driver running buildClusters over input: " + input);    job.setInputFormatClass(SequenceFileInputFormat.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    job.setMapperClass(CanopyMapper.class);    job.setMapOutputKeyClass(Text.class);    job.setMapOutputValueClass(VectorWritable.class);    job.setReducerClass(CanopyReducer.class);    job.setOutputKeyClass(Text.class);    job.setOutputValueClass(ClusterWritable.class);    job.setNumReduceTasks(1);    job.setJarByClass(CanopyDriver.class);    FileInputFormat.addInputPath(job, input);    Path canopyOutputDir = new Path(output, Cluster.CLUSTERS_DIR + '0' + Cluster.FINAL_ITERATION_SUFFIX);    FileOutputFormat.setOutputPath(job, canopyOutputDir);    if (!job.waitForCompletion(true)) {        throw new InterruptedException("Canopy Job failed processing " + input);    }    return canopyOutputDir;}
private static void mahout_f2728_0(Configuration conf, Path points, Path canopies, Path output, double clusterClassificationThreshold, boolean runSequential) throws IOException, InterruptedException, ClassNotFoundException
{    ClusterClassifier.writePolicy(new CanopyClusteringPolicy(), canopies);    ClusterClassificationDriver.run(conf, points, output, new Path(output, PathDirectory.CLUSTERED_POINTS_DIRECTORY), clusterClassificationThreshold, true, runSequential);}
protected void mahout_f2729_0(WritableComparable<?> key, VectorWritable point, Context context) throws IOException, InterruptedException
{    canopyClusterer.addPointToCanopies(point.get(), canopies);}
protected void mahout_f2730_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    canopyClusterer = CanopyConfigKeys.configureCanopyClusterer(context.getConfiguration());    clusterFilter = Integer.parseInt(context.getConfiguration().get(CanopyConfigKeys.CF_KEY));}
protected void mahout_f2731_0(Context context) throws IOException, InterruptedException
{    for (Canopy canopy : canopies) {        canopy.computeParameters();        if (canopy.getNumObservations() > clusterFilter) {            context.write(new Text("centroid"), new VectorWritable(canopy.getCenter()));        }    }    super.cleanup(context);}
 CanopyClusterer mahout_f2732_0()
{    return canopyClusterer;}
protected void mahout_f2733_0(Text arg0, Iterable<VectorWritable> values, Context context) throws IOException, InterruptedException
{    for (VectorWritable value : values) {        Vector point = value.get();        canopyClusterer.addPointToCanopies(point, canopies);    }    for (Canopy canopy : canopies) {        canopy.computeParameters();        if (canopy.getNumObservations() > clusterFilter) {            ClusterWritable clusterWritable = new ClusterWritable();            clusterWritable.setValue(canopy);            context.write(new Text(canopy.getIdentifier()), clusterWritable);        }    }}
protected void mahout_f2734_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    canopyClusterer = CanopyConfigKeys.configureCanopyClusterer(context.getConfiguration());    canopyClusterer.useT3T4();    clusterFilter = Integer.parseInt(context.getConfiguration().get(CanopyConfigKeys.CF_KEY));}
public int mahout_f2735_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption(DefaultOptionCreator.methodOption().create());    addOption(DefaultOptionCreator.clustersInOption().withDescription("The input centroids, as Vectors.  Must be a SequenceFile of Writable, Cluster/Canopy.").create());    if (parseArguments(args) == null) {        return -1;    }    Path input = getInputPath();    Path output = getOutputPath();    if (getConf() == null) {        setConf(new Configuration());    }    Path clustersIn = new Path(getOption(DefaultOptionCreator.CLUSTERS_IN_OPTION));    boolean runSequential = getOption(DefaultOptionCreator.METHOD_OPTION).equalsIgnoreCase(DefaultOptionCreator.SEQUENTIAL_METHOD);    double clusterClassificationThreshold = 0.0;    if (hasOption(DefaultOptionCreator.OUTLIER_THRESHOLD)) {        clusterClassificationThreshold = Double.parseDouble(getOption(DefaultOptionCreator.OUTLIER_THRESHOLD));    }    run(getConf(), input, clustersIn, output, clusterClassificationThreshold, true, runSequential);    return 0;}
public static void mahout_f2736_0(String[] args) throws Exception
{    ToolRunner.run(new Configuration(), new ClusterClassificationDriver(), args);}
public static void mahout_f2737_0(Configuration conf, Path input, Path clusteringOutputPath, Path output, Double clusterClassificationThreshold, boolean emitMostLikely, boolean runSequential) throws IOException, InterruptedException, ClassNotFoundException
{    if (runSequential) {        classifyClusterSeq(conf, input, clusteringOutputPath, output, clusterClassificationThreshold, emitMostLikely);    } else {        classifyClusterMR(conf, input, clusteringOutputPath, output, clusterClassificationThreshold, emitMostLikely);    }}
private static void mahout_f2738_0(Configuration conf, Path input, Path clusters, Path output, Double clusterClassificationThreshold, boolean emitMostLikely) throws IOException
{    List<Cluster> clusterModels = populateClusterModels(clusters, conf);    ClusteringPolicy policy = ClusterClassifier.readPolicy(finalClustersPath(conf, clusters));    ClusterClassifier clusterClassifier = new ClusterClassifier(clusterModels, policy);    selectCluster(input, clusterModels, clusterClassifier, output, clusterClassificationThreshold, emitMostLikely);}
private static List<Cluster> mahout_f2739_0(Path clusterOutputPath, Configuration conf) throws IOException
{    List<Cluster> clusterModels = new ArrayList<>();    Path finalClustersPath = finalClustersPath(conf, clusterOutputPath);    Iterator<?> it = new SequenceFileDirValueIterator<>(finalClustersPath, PathType.LIST, PathFilters.partFilter(), null, false, conf);    while (it.hasNext()) {        ClusterWritable next = (ClusterWritable) it.next();        Cluster cluster = next.getValue();        cluster.configure(conf);        clusterModels.add(cluster);    }    return clusterModels;}
private static Path mahout_f2740_0(Configuration conf, Path clusterOutputPath) throws IOException
{    FileSystem fileSystem = clusterOutputPath.getFileSystem(conf);    FileStatus[] clusterFiles = fileSystem.listStatus(clusterOutputPath, PathFilters.finalPartFilter());    return clusterFiles[0].getPath();}
private static void mahout_f2741_0(Path input, List<Cluster> clusterModels, ClusterClassifier clusterClassifier, Path output, Double clusterClassificationThreshold, boolean emitMostLikely) throws IOException
{    Configuration conf = new Configuration();    SequenceFile.Writer writer = new SequenceFile.Writer(input.getFileSystem(conf), conf, new Path(output, "part-m-" + 0), IntWritable.class, WeightedPropertyVectorWritable.class);    for (Pair<Writable, VectorWritable> vw : new SequenceFileDirIterable<Writable, VectorWritable>(input, PathType.LIST, PathFilters.logsCRCFilter(), conf)) {                        Class<? extends Writable> keyClass = vw.getFirst().getClass();        Vector vector = vw.getSecond().get();        if (!keyClass.equals(NamedVector.class)) {            if (keyClass.equals(Text.class)) {                vector = new NamedVector(vector, vw.getFirst().toString());            } else if (keyClass.equals(IntWritable.class)) {                vector = new NamedVector(vector, Integer.toString(((IntWritable) vw.getFirst()).get()));            }        }        Vector pdfPerCluster = clusterClassifier.classify(vector);        if (shouldClassify(pdfPerCluster, clusterClassificationThreshold)) {            classifyAndWrite(clusterModels, clusterClassificationThreshold, emitMostLikely, writer, new VectorWritable(vector), pdfPerCluster);        }    }    writer.close();}
private static void mahout_f2742_0(List<Cluster> clusterModels, Double clusterClassificationThreshold, boolean emitMostLikely, SequenceFile.Writer writer, VectorWritable vw, Vector pdfPerCluster) throws IOException
{    Map<Text, Text> props = new HashMap<>();    if (emitMostLikely) {        int maxValueIndex = pdfPerCluster.maxValueIndex();        WeightedPropertyVectorWritable weightedPropertyVectorWritable = new WeightedPropertyVectorWritable(pdfPerCluster.maxValue(), vw.get(), props);        write(clusterModels, writer, weightedPropertyVectorWritable, maxValueIndex);    } else {        writeAllAboveThreshold(clusterModels, clusterClassificationThreshold, writer, vw, pdfPerCluster);    }}
private static void mahout_f2743_0(List<Cluster> clusterModels, Double clusterClassificationThreshold, SequenceFile.Writer writer, VectorWritable vw, Vector pdfPerCluster) throws IOException
{    Map<Text, Text> props = new HashMap<>();    for (Element pdf : pdfPerCluster.nonZeroes()) {        if (pdf.get() >= clusterClassificationThreshold) {            WeightedPropertyVectorWritable wvw = new WeightedPropertyVectorWritable(pdf.get(), vw.get(), props);            int clusterIndex = pdf.index();            write(clusterModels, writer, wvw, clusterIndex);        }    }}
private static void mahout_f2744_0(List<Cluster> clusterModels, SequenceFile.Writer writer, WeightedPropertyVectorWritable weightedPropertyVectorWritable, int maxValueIndex) throws IOException
{    Cluster cluster = clusterModels.get(maxValueIndex);    DistanceMeasureCluster distanceMeasureCluster = (DistanceMeasureCluster) cluster;    DistanceMeasure distanceMeasure = distanceMeasureCluster.getMeasure();    double distance = distanceMeasure.distance(cluster.getCenter(), weightedPropertyVectorWritable.getVector());    weightedPropertyVectorWritable.getProperties().put(new Text("distance"), new Text(Double.toString(distance)));    writer.append(new IntWritable(cluster.getId()), weightedPropertyVectorWritable);}
private static boolean mahout_f2745_0(Vector pdfPerCluster, Double clusterClassificationThreshold)
{    return pdfPerCluster.maxValue() >= clusterClassificationThreshold;}
private static void mahout_f2746_0(Configuration conf, Path input, Path clustersIn, Path output, Double clusterClassificationThreshold, boolean emitMostLikely) throws IOException, InterruptedException, ClassNotFoundException
{    conf.setFloat(ClusterClassificationConfigKeys.OUTLIER_REMOVAL_THRESHOLD, clusterClassificationThreshold.floatValue());    conf.setBoolean(ClusterClassificationConfigKeys.EMIT_MOST_LIKELY, emitMostLikely);    conf.set(ClusterClassificationConfigKeys.CLUSTERS_IN, clustersIn.toUri().toString());    Job job = new Job(conf, "Cluster Classification Driver running over input: " + input);    job.setJarByClass(ClusterClassificationDriver.class);    job.setInputFormatClass(SequenceFileInputFormat.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    job.setMapperClass(ClusterClassificationMapper.class);    job.setNumReduceTasks(0);    job.setOutputKeyClass(IntWritable.class);    job.setOutputValueClass(WeightedPropertyVectorWritable.class);    FileInputFormat.addInputPath(job, input);    FileOutputFormat.setOutputPath(job, output);    if (!job.waitForCompletion(true)) {        throw new InterruptedException("Cluster Classification Driver Job failed processing " + input);    }}
public static void mahout_f2747_0(Configuration conf, Path input, Path clusteringOutputPath, Path output, double clusterClassificationThreshold, boolean emitMostLikely, boolean runSequential) throws IOException, InterruptedException, ClassNotFoundException
{    if (runSequential) {        classifyClusterSeq(conf, input, clusteringOutputPath, output, clusterClassificationThreshold, emitMostLikely);    } else {        classifyClusterMR(conf, input, clusteringOutputPath, output, clusterClassificationThreshold, emitMostLikely);    }}
protected void mahout_f2748_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    Configuration conf = context.getConfiguration();    String clustersIn = conf.get(ClusterClassificationConfigKeys.CLUSTERS_IN);    threshold = conf.getFloat(ClusterClassificationConfigKeys.OUTLIER_REMOVAL_THRESHOLD, 0.0f);    emitMostLikely = conf.getBoolean(ClusterClassificationConfigKeys.EMIT_MOST_LIKELY, false);    clusterModels = new ArrayList<>();    if (clustersIn != null && !clustersIn.isEmpty()) {        Path clustersInPath = new Path(clustersIn);        clusterModels = populateClusterModels(clustersInPath, conf);        ClusteringPolicy policy = ClusterClassifier.readPolicy(finalClustersPath(clustersInPath));        clusterClassifier = new ClusterClassifier(clusterModels, policy);    }    clusterId = new IntWritable();}
protected void mahout_f2749_0(WritableComparable<?> key, VectorWritable vw, Context context) throws IOException, InterruptedException
{    if (!clusterModels.isEmpty()) {                        Class<? extends Vector> vectorClass = vw.get().getClass();        Vector vector = vw.get();        if (!vectorClass.equals(NamedVector.class)) {            if (key.getClass().equals(Text.class)) {                vector = new NamedVector(vector, key.toString());            } else if (key.getClass().equals(IntWritable.class)) {                vector = new NamedVector(vector, Integer.toString(((IntWritable) key).get()));            }        }        Vector pdfPerCluster = clusterClassifier.classify(vector);        if (shouldClassify(pdfPerCluster)) {            if (emitMostLikely) {                int maxValueIndex = pdfPerCluster.maxValueIndex();                write(new VectorWritable(vector), context, maxValueIndex, 1.0);            } else {                writeAllAboveThreshold(new VectorWritable(vector), context, pdfPerCluster);            }        }    }}
private void mahout_f2750_0(VectorWritable vw, Context context, Vector pdfPerCluster) throws IOException, InterruptedException
{    for (Element pdf : pdfPerCluster.nonZeroes()) {        if (pdf.get() >= threshold) {            int clusterIndex = pdf.index();            write(vw, context, clusterIndex, pdf.get());        }    }}
private void mahout_f2751_0(VectorWritable vw, Context context, int clusterIndex, double weight) throws IOException, InterruptedException
{    Cluster cluster = clusterModels.get(clusterIndex);    clusterId.set(cluster.getId());    DistanceMeasureCluster distanceMeasureCluster = (DistanceMeasureCluster) cluster;    DistanceMeasure distanceMeasure = distanceMeasureCluster.getMeasure();    double distance = distanceMeasure.distance(cluster.getCenter(), vw.get());    Map<Text, Text> props = new HashMap<>();    props.put(new Text("distance"), new Text(Double.toString(distance)));    context.write(clusterId, new WeightedPropertyVectorWritable(weight, vw.get(), props));}
public static List<Cluster> mahout_f2752_0(Path clusterOutputPath, Configuration conf) throws IOException
{    List<Cluster> clusters = new ArrayList<>();    FileSystem fileSystem = clusterOutputPath.getFileSystem(conf);    FileStatus[] clusterFiles = fileSystem.listStatus(clusterOutputPath, PathFilters.finalPartFilter());    Iterator<?> it = new SequenceFileDirValueIterator<>(clusterFiles[0].getPath(), PathType.LIST, PathFilters.partFilter(), null, false, conf);    while (it.hasNext()) {        ClusterWritable next = (ClusterWritable) it.next();        Cluster cluster = next.getValue();        cluster.configure(conf);        clusters.add(cluster);    }    return clusters;}
private boolean mahout_f2753_0(Vector pdfPerCluster)
{    return pdfPerCluster.maxValue() >= threshold;}
private static Path mahout_f2754_0(Path clusterOutputPath) throws IOException
{    FileSystem fileSystem = clusterOutputPath.getFileSystem(new Configuration());    FileStatus[] clusterFiles = fileSystem.listStatus(clusterOutputPath, PathFilters.finalPartFilter());    return clusterFiles[0].getPath();}
public Vector mahout_f2755_0(Vector instance)
{    return policy.classify(instance, this);}
public double mahout_f2756_0(Vector instance)
{    if (models.size() == 2) {        double pdf0 = models.get(0).pdf(new VectorWritable(instance));        double pdf1 = models.get(1).pdf(new VectorWritable(instance));        return pdf0 / (pdf0 + pdf1);    }    throw new IllegalStateException();}
public int mahout_f2757_0()
{    return models.size();}
public void mahout_f2758_0(DataOutput out) throws IOException
{    out.writeInt(models.size());    out.writeUTF(modelClass);    new ClusteringPolicyWritable(policy).write(out);    for (Cluster cluster : models) {        cluster.write(out);    }}
public void mahout_f2759_0(DataInput in) throws IOException
{    int size = in.readInt();    modelClass = in.readUTF();    models = new ArrayList<>();    ClusteringPolicyWritable clusteringPolicyWritable = new ClusteringPolicyWritable();    clusteringPolicyWritable.readFields(in);    policy = clusteringPolicyWritable.getValue();    for (int i = 0; i < size; i++) {        Cluster element = ClassUtils.instantiateAs(modelClass, Cluster.class);        element.readFields(in);        models.add(element);    }}
public void mahout_f2760_0(int actual, Vector instance)
{    models.get(actual).observe(new VectorWritable(instance));}
public void mahout_f2761_0(int actual, Vector data, double weight)
{    models.get(actual).observe(new VectorWritable(data), weight);}
public void mahout_f2762_0(long trackingKey, String groupKey, int actual, Vector instance)
{    models.get(actual).observe(new VectorWritable(instance));}
public void mahout_f2763_0(long trackingKey, int actual, Vector instance)
{    models.get(actual).observe(new VectorWritable(instance));}
public void mahout_f2764_0()
{    policy.close(this);}
public List<Cluster> mahout_f2765_0()
{    return models;}
public ClusteringPolicy mahout_f2766_0()
{    return policy;}
public void mahout_f2767_0(Path path) throws IOException
{    writePolicy(policy, path);    Configuration config = new Configuration();    FileSystem fs = FileSystem.get(path.toUri(), config);    ClusterWritable cw = new ClusterWritable();    for (int i = 0; i < models.size(); i++) {        try (SequenceFile.Writer writer = new SequenceFile.Writer(fs, config, new Path(path, "part-" + String.format(Locale.ENGLISH, "%05d", i)), IntWritable.class, ClusterWritable.class)) {            Cluster cluster = models.get(i);            cw.setValue(cluster);            Writable key = new IntWritable(i);            writer.append(key, cw);        }    }}
public void mahout_f2768_0(Configuration conf, Path path) throws IOException
{    Configuration config = new Configuration();    List<Cluster> clusters = new ArrayList<>();    for (ClusterWritable cw : new SequenceFileDirValueIterable<ClusterWritable>(path, PathType.LIST, PathFilters.logsCRCFilter(), config)) {        Cluster cluster = cw.getValue();        cluster.configure(conf);        clusters.add(cluster);    }    this.models = clusters;    modelClass = models.get(0).getClass().getName();    this.policy = readPolicy(path);}
public static ClusteringPolicy mahout_f2769_0(Path path) throws IOException
{    Path policyPath = new Path(path, POLICY_FILE_NAME);    Configuration config = new Configuration();    FileSystem fs = FileSystem.get(policyPath.toUri(), config);    SequenceFile.Reader reader = new SequenceFile.Reader(fs, policyPath, config);    Text key = new Text();    ClusteringPolicyWritable cpw = new ClusteringPolicyWritable();    reader.next(key, cpw);    Closeables.close(reader, true);    return cpw.getValue();}
public static void mahout_f2770_0(ClusteringPolicy policy, Path path) throws IOException
{    Path policyPath = new Path(path, POLICY_FILE_NAME);    Configuration config = new Configuration();    FileSystem fs = FileSystem.get(policyPath.toUri(), config);    SequenceFile.Writer writer = new SequenceFile.Writer(fs, config, policyPath, Text.class, ClusteringPolicyWritable.class);    writer.append(new Text(), new ClusteringPolicyWritable(policy));    Closeables.close(writer, false);}
public Map<Text, Text> mahout_f2771_0()
{    return properties;}
public void mahout_f2772_0(Map<Text, Text> properties)
{    this.properties = properties;}
public void mahout_f2773_0(DataInput in) throws IOException
{    super.readFields(in);    int size = in.readInt();    if (size > 0) {        properties = new HashMap<>();        for (int i = 0; i < size; i++) {            Text key = new Text(in.readUTF());            Text val = new Text(in.readUTF());            properties.put(key, val);        }    }}
public void mahout_f2774_0(DataOutput out) throws IOException
{    super.write(out);    out.writeInt(properties != null ? properties.size() : 0);    if (properties != null) {        for (Map.Entry<Text, Text> entry : properties.entrySet()) {            out.writeUTF(entry.getKey().toString());            out.writeUTF(entry.getValue().toString());        }    }}
public String mahout_f2775_0()
{    Vector vector = getVector();    StringBuilder bldr = new StringBuilder("wt: ").append(getWeight()).append(' ');    if (properties != null && !properties.isEmpty()) {        for (Map.Entry<Text, Text> entry : properties.entrySet()) {            bldr.append(entry.getKey().toString()).append(": ").append(entry.getValue().toString()).append(' ');        }    }    bldr.append(" vec: ").append(vector == null ? "null" : AbstractCluster.formatVector(vector, null));    return bldr.toString();}
public Vector mahout_f2776_0()
{    return vectorWritable.get();}
public void mahout_f2777_0(Vector vector)
{    vectorWritable.set(vector);}
public double mahout_f2778_0()
{    return weight;}
public void mahout_f2779_0(DataInput in) throws IOException
{    vectorWritable.readFields(in);    weight = in.readDouble();}
public void mahout_f2780_0(DataOutput out) throws IOException
{    vectorWritable.write(out);    out.writeDouble(weight);}
public String mahout_f2781_0()
{    Vector vector = vectorWritable.get();    return weight + ": " + (vector == null ? "null" : AbstractCluster.formatVector(vector, null));}
public static List<OnlineSummarizer> mahout_f2782_0(Iterable<? extends Vector> datapoints, Iterable<? extends Vector> centroids, DistanceMeasure distanceMeasure)
{    UpdatableSearcher searcher = new ProjectionSearch(distanceMeasure, 3, 1);    searcher.addAll(centroids);    List<OnlineSummarizer> summarizers = new ArrayList<>();    if (searcher.size() == 0) {        return summarizers;    }    for (int i = 0; i < searcher.size(); ++i) {        summarizers.add(new OnlineSummarizer());    }    for (Vector v : datapoints) {        Centroid closest = (Centroid) searcher.search(v, 1).get(0).getValue();        OnlineSummarizer summarizer = summarizers.get(closest.getIndex());        summarizer.add(distanceMeasure.distance(v, closest));    }    return summarizers;}
public static double mahout_f2783_0(Iterable<? extends Vector> datapoints, Iterable<? extends Vector> centroids)
{    DistanceMeasure distanceMeasure = new EuclideanDistanceMeasure();    UpdatableSearcher searcher = new ProjectionSearch(distanceMeasure, 3, 1);    searcher.addAll(centroids);    return totalClusterCost(datapoints, searcher);}
public static double mahout_f2784_0(Iterable<? extends Vector> datapoints, Searcher centroids)
{    double totalCost = 0;    for (Vector vector : datapoints) {        totalCost += centroids.searchFirst(vector, false).getWeight();    }    return totalCost;}
public static double mahout_f2785_0(List<? extends Vector> data, DistanceMeasure distanceMeasure)
{    BruteSearch searcher = new BruteSearch(distanceMeasure);    searcher.addAll(data);    double minDistance = Double.POSITIVE_INFINITY;    for (Vector vector : data) {        double closest = searcher.searchFirst(vector, true).getWeight();        if (minDistance > 0 && closest < minDistance) {            minDistance = closest;        }        searcher.add(vector);    }    return minDistance;}
public static double mahout_f2786_0(Iterable<T> data, DistanceMeasure distanceMeasure, int sampleLimit)
{    return estimateDistanceCutoff(Lists.newArrayList(Iterables.limit(data, sampleLimit)), distanceMeasure);}
public static double mahout_f2787_0(List<? extends Vector> centroids, DistanceMeasure distanceMeasure, List<OnlineSummarizer> clusterDistanceSummaries)
{    Preconditions.checkArgument(centroids.size() == clusterDistanceSummaries.size(), "Number of centroids and cluster summaries differ.");    int n = centroids.size();    double totalDBIndex = 0;        for (int i = 0; i < n; ++i) {        double averageDistanceI = clusterDistanceSummaries.get(i).getMean();        double maxDBIndex = 0;        for (int j = 0; j < n; ++j) {            if (i != j) {                double dbIndex = (averageDistanceI + clusterDistanceSummaries.get(j).getMean()) / distanceMeasure.distance(centroids.get(i), centroids.get(j));                if (dbIndex > maxDBIndex) {                    maxDBIndex = dbIndex;                }            }        }        totalDBIndex += maxDBIndex;    }    return totalDBIndex / n;}
public static double mahout_f2788_0(List<? extends Vector> centroids, DistanceMeasure distanceMeasure, List<OnlineSummarizer> clusterDistanceSummaries)
{    Preconditions.checkArgument(centroids.size() == clusterDistanceSummaries.size(), "Number of centroids and cluster summaries differ.");    int n = centroids.size();                        double maxIntraClusterDistance = 0;    for (OnlineSummarizer summarizer : clusterDistanceSummaries) {        if (summarizer.getCount() > 0) {            double intraClusterDistance;            if (summarizer.getCount() == 1) {                intraClusterDistance = summarizer.getMean();            } else {                intraClusterDistance = summarizer.getMedian();            }            if (maxIntraClusterDistance < intraClusterDistance) {                maxIntraClusterDistance = intraClusterDistance;            }        }    }    double minDunnIndex = Double.POSITIVE_INFINITY;    for (int i = 0; i < n; ++i) {                for (int j = i + 1; j < n; ++j) {            double dunnIndex = distanceMeasure.distance(centroids.get(i), centroids.get(j));            if (minDunnIndex > dunnIndex) {                minDunnIndex = dunnIndex;            }        }    }    return minDunnIndex / maxIntraClusterDistance;}
public static double mahout_f2789_0(double n)
{    return n * (n - 1) / 2;}
public static Matrix mahout_f2790_0(List<? extends Vector> rowCentroids, List<? extends Vector> columnCentroids, Iterable<? extends Vector> datapoints, DistanceMeasure distanceMeasure)
{    Searcher rowSearcher = new BruteSearch(distanceMeasure);    rowSearcher.addAll(rowCentroids);    Searcher columnSearcher = new BruteSearch(distanceMeasure);    columnSearcher.addAll(columnCentroids);    int numRows = rowCentroids.size();    int numCols = columnCentroids.size();    Matrix confusionMatrix = new DenseMatrix(numRows, numCols);    for (Vector vector : datapoints) {        WeightedThing<Vector> closestRowCentroid = rowSearcher.search(vector, 1).get(0);        WeightedThing<Vector> closestColumnCentroid = columnSearcher.search(vector, 1).get(0);        int row = ((Centroid) closestRowCentroid.getValue()).getIndex();        int column = ((Centroid) closestColumnCentroid.getValue()).getIndex();        double vectorWeight;        if (vector instanceof WeightedVector) {            vectorWeight = ((WeightedVector) vector).getWeight();        } else {            vectorWeight = 1;        }        confusionMatrix.set(row, column, confusionMatrix.get(row, column) + vectorWeight);    }    return confusionMatrix;}
public static double mahout_f2791_0(Matrix confusionMatrix)
{    int numRows = confusionMatrix.numRows();    int numCols = confusionMatrix.numCols();    double rowChoiceSum = 0;    double columnChoiceSum = 0;    double totalChoiceSum = 0;    double total = 0;    for (int i = 0; i < numRows; ++i) {        double rowSum = 0;        for (int j = 0; j < numCols; ++j) {            rowSum += confusionMatrix.get(i, j);            totalChoiceSum += choose2(confusionMatrix.get(i, j));        }        total += rowSum;        rowChoiceSum += choose2(rowSum);    }    for (int j = 0; j < numCols; ++j) {        double columnSum = 0;        for (int i = 0; i < numRows; ++i) {            columnSum += confusionMatrix.get(i, j);        }        columnChoiceSum += choose2(columnSum);    }    double rowColumnChoiceSumDivTotal = rowChoiceSum * columnChoiceSum / choose2(total);    return (totalChoiceSum - rowColumnChoiceSumDivTotal) / ((rowChoiceSum + columnChoiceSum) / 2 - rowColumnChoiceSumDivTotal);}
public static double mahout_f2792_0(Iterable<? extends Vector> data)
{    double sum = 0;    for (Vector row : data) {        Preconditions.checkNotNull(row);        if (row instanceof WeightedVector) {            sum += ((WeightedVector) row).getWeight();        } else {            sum++;        }    }    return sum;}
public Vector mahout_f2793_0(Collection<SoftCluster> clusters, List<Double> clusterDistanceList)
{    Vector pi = new DenseVector(clusters.size());    for (int i = 0; i < clusters.size(); i++) {        double probWeight = computeProbWeight(clusterDistanceList.get(i), clusterDistanceList);        pi.set(i, probWeight);    }    return pi;}
public double mahout_f2794_0(double clusterDistance, Iterable<Double> clusterDistanceList)
{    if (clusterDistance == 0) {        clusterDistance = MINIMAL_VALUE;    }    double denom = 0.0;    for (double eachCDist : clusterDistanceList) {        if (eachCDist == 0.0) {            eachCDist = MINIMAL_VALUE;        }        denom += Math.pow(clusterDistance / eachCDist, 2.0 / (m - 1));    }    return 1.0 / denom;}
public void mahout_f2795_0(double m)
{    this.m = m;}
public static void mahout_f2796_0(String[] args) throws Exception
{    ToolRunner.run(new Configuration(), new FuzzyKMeansDriver(), args);}
public int mahout_f2797_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption(DefaultOptionCreator.distanceMeasureOption().create());    addOption(DefaultOptionCreator.clustersInOption().withDescription("The input centroids, as Vectors.  Must be a SequenceFile of Writable, Cluster/Canopy.  " + "If k is also specified, then a random set of vectors will be selected" + " and written out to this path first").create());    addOption(DefaultOptionCreator.numClustersOption().withDescription("The k in k-Means.  If specified, then a random selection of k Vectors will be chosen" + " as the Centroid and written to the clusters input path.").create());    addOption(DefaultOptionCreator.convergenceOption().create());    addOption(DefaultOptionCreator.maxIterationsOption().create());    addOption(DefaultOptionCreator.overwriteOption().create());    addOption(M_OPTION, M_OPTION, "coefficient normalization factor, must be greater than 1", true);    addOption(DefaultOptionCreator.clusteringOption().create());    addOption(DefaultOptionCreator.emitMostLikelyOption().create());    addOption(DefaultOptionCreator.thresholdOption().create());    addOption(DefaultOptionCreator.methodOption().create());    addOption(DefaultOptionCreator.useSetRandomSeedOption().create());    if (parseArguments(args) == null) {        return -1;    }    Path input = getInputPath();    Path clusters = new Path(getOption(DefaultOptionCreator.CLUSTERS_IN_OPTION));    Path output = getOutputPath();    String measureClass = getOption(DefaultOptionCreator.DISTANCE_MEASURE_OPTION);    if (measureClass == null) {        measureClass = SquaredEuclideanDistanceMeasure.class.getName();    }    double convergenceDelta = Double.parseDouble(getOption(DefaultOptionCreator.CONVERGENCE_DELTA_OPTION));    float fuzziness = Float.parseFloat(getOption(M_OPTION));    int maxIterations = Integer.parseInt(getOption(DefaultOptionCreator.MAX_ITERATIONS_OPTION));    if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {        HadoopUtil.delete(getConf(), output);    }    boolean emitMostLikely = Boolean.parseBoolean(getOption(DefaultOptionCreator.EMIT_MOST_LIKELY_OPTION));    double threshold = Double.parseDouble(getOption(DefaultOptionCreator.THRESHOLD_OPTION));    DistanceMeasure measure = ClassUtils.instantiateAs(measureClass, DistanceMeasure.class);    if (hasOption(DefaultOptionCreator.NUM_CLUSTERS_OPTION)) {        int numClusters = Integer.parseInt(getOption(DefaultOptionCreator.NUM_CLUSTERS_OPTION));        Long seed = null;        if (hasOption(DefaultOptionCreator.RANDOM_SEED)) {            seed = Long.parseLong(getOption(DefaultOptionCreator.RANDOM_SEED));        }        clusters = RandomSeedGenerator.buildRandom(getConf(), input, clusters, numClusters, measure, seed);    }    boolean runClustering = hasOption(DefaultOptionCreator.CLUSTERING_OPTION);    boolean runSequential = getOption(DefaultOptionCreator.METHOD_OPTION).equalsIgnoreCase(DefaultOptionCreator.SEQUENTIAL_METHOD);    run(getConf(), input, clusters, output, convergenceDelta, maxIterations, fuzziness, runClustering, emitMostLikely, threshold, runSequential);    return 0;}
public static void mahout_f2798_1(Path input, Path clustersIn, Path output, double convergenceDelta, int maxIterations, float m, boolean runClustering, boolean emitMostLikely, double threshold, boolean runSequential) throws IOException, ClassNotFoundException, InterruptedException
{    Configuration conf = new Configuration();    Path clustersOut = buildClusters(conf, input, clustersIn, output, convergenceDelta, maxIterations, m, runSequential);    if (runClustering) {                clusterData(conf, input, clustersOut, output, convergenceDelta, m, emitMostLikely, threshold, runSequential);    }}
public static void mahout_f2799_1(Configuration conf, Path input, Path clustersIn, Path output, double convergenceDelta, int maxIterations, float m, boolean runClustering, boolean emitMostLikely, double threshold, boolean runSequential) throws IOException, ClassNotFoundException, InterruptedException
{    Path clustersOut = buildClusters(conf, input, clustersIn, output, convergenceDelta, maxIterations, m, runSequential);    if (runClustering) {                clusterData(conf, input, clustersOut, output, convergenceDelta, m, emitMostLikely, threshold, runSequential);    }}
public static Path mahout_f2800_0(Configuration conf, Path input, Path clustersIn, Path output, double convergenceDelta, int maxIterations, float m, boolean runSequential) throws IOException, InterruptedException, ClassNotFoundException
{    List<Cluster> clusters = new ArrayList<>();    FuzzyKMeansUtil.configureWithClusterInfo(conf, clustersIn, clusters);    if (conf == null) {        conf = new Configuration();    }    if (clusters.isEmpty()) {        throw new IllegalStateException("No input clusters found in " + clustersIn + ". Check your -c argument.");    }    Path priorClustersPath = new Path(output, Cluster.INITIAL_CLUSTERS_DIR);    ClusteringPolicy policy = new FuzzyKMeansClusteringPolicy(m, convergenceDelta);    ClusterClassifier prior = new ClusterClassifier(clusters, policy);    prior.writeToSeqFiles(priorClustersPath);    if (runSequential) {        ClusterIterator.iterateSeq(conf, input, priorClustersPath, output, maxIterations);    } else {        ClusterIterator.iterateMR(conf, input, priorClustersPath, output, maxIterations);    }    return output;}
public static void mahout_f2801_0(Configuration conf, Path input, Path clustersIn, Path output, double convergenceDelta, float m, boolean emitMostLikely, double threshold, boolean runSequential) throws IOException, ClassNotFoundException, InterruptedException
{    ClusterClassifier.writePolicy(new FuzzyKMeansClusteringPolicy(m, convergenceDelta), clustersIn);    ClusterClassificationDriver.run(conf, input, output, new Path(output, PathDirectory.CLUSTERED_POINTS_DIRECTORY), threshold, emitMostLikely, runSequential);}
public static void mahout_f2802_0(Configuration conf, Path clusterPath, List<Cluster> clusters)
{    for (Writable value : new SequenceFileDirValueIterable<>(clusterPath, PathType.LIST, PathFilters.partFilter(), conf)) {        Class<? extends Writable> valueClass = value.getClass();        if (valueClass.equals(ClusterWritable.class)) {            ClusterWritable clusterWritable = (ClusterWritable) value;            value = clusterWritable.getValue();            valueClass = value.getClass();        }        if (valueClass.equals(Kluster.class)) {                        Kluster cluster = (Kluster) value;            clusters.add(new SoftCluster(cluster.getCenter(), cluster.getId(), cluster.getMeasure()));        } else if (valueClass.equals(SoftCluster.class)) {                        clusters.add((SoftCluster) value);        } else if (valueClass.equals(Canopy.class)) {                        Canopy canopy = (Canopy) value;            clusters.add(new SoftCluster(canopy.getCenter(), canopy.getId(), canopy.getMeasure()));        } else {            throw new IllegalStateException("Bad value class: " + valueClass);        }    }}
public String mahout_f2803_0()
{    return this.getIdentifier() + ": " + this.computeCentroid().asFormatString();}
public String mahout_f2804_0()
{    return (isConverged() ? "SV-" : "SC-") + getId();}
public double mahout_f2805_0(VectorWritable vw)
{        throw new UnsupportedOperationException("SoftCluster pdf cannot be calculated out of context. See FuzzyKMeansClusterer");}
public Vector mahout_f2806_0(Vector probabilities)
{    int maxValueIndex = probabilities.maxValueIndex();    Vector weights = new SequentialAccessSparseVector(probabilities.size());    weights.set(maxValueIndex, 1.0);    return weights;}
public void mahout_f2807_0(ClusterClassifier posterior)
{}
public Vector mahout_f2808_0(Vector data, ClusterClassifier prior)
{    List<Cluster> models = prior.getModels();    int i = 0;    Vector pdfs = new DenseVector(models.size());    for (Cluster model : models) {        pdfs.set(i++, model.pdf(new VectorWritable(data)));    }    return pdfs.assign(new TimesFunction(), 1.0 / pdfs.zSum());}
public void mahout_f2809_0(ClusterClassifier posterior)
{    for (Cluster cluster : posterior.getModels()) {        cluster.computeParameters();    }}
public Vector mahout_f2810_0(Vector probabilities)
{    int maxValueIndex = probabilities.maxValueIndex();    Vector weights = new SequentialAccessSparseVector(probabilities.size());    weights.set(maxValueIndex, 1.0);    return weights;}
public void mahout_f2811_0(DataOutput out) throws IOException
{    out.writeDouble(t1);    out.writeDouble(t2);}
public void mahout_f2812_0(DataInput in) throws IOException
{    this.t1 = in.readDouble();    this.t2 = in.readDouble();}
protected void mahout_f2813_0(Context context) throws IOException, InterruptedException
{    Configuration conf = context.getConfiguration();    String priorClustersPath = conf.get(ClusterIterator.PRIOR_PATH_KEY);    classifier = new ClusterClassifier();    classifier.readFromSeqFiles(conf, new Path(priorClustersPath));    policy = classifier.getPolicy();    policy.update(classifier);    super.setup(context);}
protected void mahout_f2814_0(WritableComparable<?> key, VectorWritable value, Context context) throws IOException, InterruptedException
{    Vector probabilities = classifier.classify(value.get());    Vector selections = policy.select(probabilities);    for (Element el : selections.nonZeroes()) {        classifier.train(el.index(), value.get(), el.get());    }}
protected void mahout_f2815_0(Context context) throws IOException, InterruptedException
{    List<Cluster> clusters = classifier.getModels();    ClusterWritable cw = new ClusterWritable();    for (int index = 0; index < clusters.size(); index++) {        cw.setValue(clusters.get(index));        context.write(new IntWritable(index), cw);    }    super.cleanup(context);}
protected void mahout_f2816_0(IntWritable key, Iterable<ClusterWritable> values, Context context) throws IOException, InterruptedException
{    Iterator<ClusterWritable> iter = values.iterator();        Cluster first = iter.next().getValue();    while (iter.hasNext()) {        Cluster cluster = iter.next().getValue();        first.observe(cluster);    }    List<Cluster> models = new ArrayList<>();    models.add(first);    classifier = new ClusterClassifier(models, policy);    classifier.close();    context.write(key, new ClusterWritable(first));}
protected void mahout_f2817_0(Context context) throws IOException, InterruptedException
{    Configuration conf = context.getConfiguration();    String priorClustersPath = conf.get(ClusterIterator.PRIOR_PATH_KEY);    classifier = new ClusterClassifier();    classifier.readFromSeqFiles(conf, new Path(priorClustersPath));    policy = classifier.getPolicy();    policy.update(classifier);    super.setup(context);}
public ClusteringPolicy mahout_f2818_0()
{    return value;}
public void mahout_f2819_0(ClusteringPolicy value)
{    this.value = value;}
public void mahout_f2820_0(DataOutput out) throws IOException
{    PolymorphicWritable.write(out, value);}
public void mahout_f2821_0(DataInput in) throws IOException
{    value = PolymorphicWritable.read(in, ClusteringPolicy.class);}
public static ClusterClassifier mahout_f2822_0(Iterable<Vector> data, ClusterClassifier classifier, int numIterations)
{    ClusteringPolicy policy = classifier.getPolicy();    for (int iteration = 1; iteration <= numIterations; iteration++) {        for (Vector vector : data) {                        policy.update(classifier);                        Vector probabilities = classifier.classify(vector);                        Vector weights = policy.select(probabilities);                        for (Vector.Element e : weights.nonZeroes()) {                int index = e.index();                classifier.train(index, vector, weights.get(index));            }        }                classifier.close();    }    return classifier;}
public static void mahout_f2823_0(Configuration conf, Path inPath, Path priorPath, Path outPath, int numIterations) throws IOException
{    ClusterClassifier classifier = new ClusterClassifier();    classifier.readFromSeqFiles(conf, priorPath);    Path clustersOut = null;    int iteration = 1;    while (iteration <= numIterations) {        for (VectorWritable vw : new SequenceFileDirValueIterable<VectorWritable>(inPath, PathType.LIST, PathFilters.logsCRCFilter(), conf)) {            Vector vector = vw.get();                        Vector probabilities = classifier.classify(vector);                        Vector weights = classifier.getPolicy().select(probabilities);                        for (Vector.Element e : weights.nonZeroes()) {                int index = e.index();                classifier.train(index, vector, weights.get(index));            }        }                classifier.close();                classifier.getPolicy().update(classifier);                clustersOut = new Path(outPath, Cluster.CLUSTERS_DIR + iteration);        classifier.writeToSeqFiles(clustersOut);        FileSystem fs = FileSystem.get(outPath.toUri(), conf);        iteration++;        if (isConverged(clustersOut, conf, fs)) {            break;        }    }    Path finalClustersIn = new Path(outPath, Cluster.CLUSTERS_DIR + (iteration - 1) + Cluster.FINAL_ITERATION_SUFFIX);    FileSystem.get(clustersOut.toUri(), conf).rename(clustersOut, finalClustersIn);}
public static void mahout_f2824_0(Configuration conf, Path inPath, Path priorPath, Path outPath, int numIterations) throws IOException, InterruptedException, ClassNotFoundException
{    ClusteringPolicy policy = ClusterClassifier.readPolicy(priorPath);    Path clustersOut = null;    int iteration = 1;    while (iteration <= numIterations) {        conf.set(PRIOR_PATH_KEY, priorPath.toString());        String jobName = "Cluster Iterator running iteration " + iteration + " over priorPath: " + priorPath;        Job job = new Job(conf, jobName);        job.setMapOutputKeyClass(IntWritable.class);        job.setMapOutputValueClass(ClusterWritable.class);        job.setOutputKeyClass(IntWritable.class);        job.setOutputValueClass(ClusterWritable.class);        job.setInputFormatClass(SequenceFileInputFormat.class);        job.setOutputFormatClass(SequenceFileOutputFormat.class);        job.setMapperClass(CIMapper.class);        job.setReducerClass(CIReducer.class);        FileInputFormat.addInputPath(job, inPath);        clustersOut = new Path(outPath, Cluster.CLUSTERS_DIR + iteration);        priorPath = clustersOut;        FileOutputFormat.setOutputPath(job, clustersOut);        job.setJarByClass(ClusterIterator.class);        if (!job.waitForCompletion(true)) {            throw new InterruptedException("Cluster Iteration " + iteration + " failed processing " + priorPath);        }        ClusterClassifier.writePolicy(policy, clustersOut);        FileSystem fs = FileSystem.get(outPath.toUri(), conf);        iteration++;        if (isConverged(clustersOut, conf, fs)) {            break;        }    }    Path finalClustersIn = new Path(outPath, Cluster.CLUSTERS_DIR + (iteration - 1) + Cluster.FINAL_ITERATION_SUFFIX);    FileSystem.get(clustersOut.toUri(), conf).rename(clustersOut, finalClustersIn);}
private static boolean mahout_f2825_0(Path filePath, Configuration conf, FileSystem fs) throws IOException
{    for (FileStatus part : fs.listStatus(filePath, PathFilters.partFilter())) {        SequenceFileValueIterator<ClusterWritable> iterator = new SequenceFileValueIterator<>(part.getPath(), true, conf);        while (iterator.hasNext()) {            ClusterWritable value = iterator.next();            if (!value.getValue().isConverged()) {                Closeables.close(iterator, true);                return false;            }        }    }    return true;}
public Cluster mahout_f2826_0()
{    return value;}
public void mahout_f2827_0(Cluster value)
{    this.value = value;}
public void mahout_f2828_0(DataOutput out) throws IOException
{    PolymorphicWritable.write(out, value);}
public void mahout_f2829_0(DataInput in) throws IOException
{    value = PolymorphicWritable.read(in, Cluster.class);}
public void mahout_f2830_0(Configuration job)
{    if (measure != null) {        measure.configure(job);    }}
public void mahout_f2831_0(DataInput in) throws IOException
{    String dm = in.readUTF();    this.measure = ClassUtils.instantiateAs(dm, DistanceMeasure.class);    super.readFields(in);}
public void mahout_f2832_0(DataOutput out) throws IOException
{    out.writeUTF(measure.getClass().getName());    super.write(out);}
public double mahout_f2833_0(VectorWritable vw)
{    return 1 / (1 + measure.distance(vw.get(), getCenter()));}
public Model<VectorWritable> mahout_f2834_0()
{    return new DistanceMeasureCluster(getCenter(), getId(), measure);}
public DistanceMeasure mahout_f2835_0()
{    return measure;}
public void mahout_f2836_0(DistanceMeasure measure)
{    this.measure = measure;}
public String mahout_f2837_0()
{    return "DMC:" + getId();}
public Vector mahout_f2838_0(Vector probabilities)
{    return probabilities;}
public Vector mahout_f2839_0(Vector data, ClusterClassifier prior)
{    Collection<SoftCluster> clusters = new ArrayList<>();    List<Double> distances = new ArrayList<>();    for (Cluster model : prior.getModels()) {        SoftCluster sc = (SoftCluster) model;        clusters.add(sc);        distances.add(sc.getMeasure().distance(data, sc.getCenter()));    }    FuzzyKMeansClusterer fuzzyKMeansClusterer = new FuzzyKMeansClusterer();    fuzzyKMeansClusterer.setM(m);    return fuzzyKMeansClusterer.computePi(clusters, distances);}
public void mahout_f2840_0(DataOutput out) throws IOException
{    out.writeDouble(m);    out.writeDouble(convergenceDelta);}
public void mahout_f2841_0(DataInput in) throws IOException
{    this.m = in.readDouble();    this.convergenceDelta = in.readDouble();}
public void mahout_f2842_0(ClusterClassifier posterior)
{    for (Cluster cluster : posterior.getModels()) {        ((org.apache.mahout.clustering.kmeans.Kluster) cluster).calculateConvergence(convergenceDelta);        cluster.computeParameters();    }}
public void mahout_f2843_0(DataOutput out) throws IOException
{    out.writeDouble(convergenceDelta);}
public void mahout_f2844_0(DataInput in) throws IOException
{    this.convergenceDelta = in.readDouble();}
public void mahout_f2845_0(ClusterClassifier posterior)
{    boolean allConverged = true;    for (Cluster cluster : posterior.getModels()) {        org.apache.mahout.clustering.kmeans.Kluster kluster = (org.apache.mahout.clustering.kmeans.Kluster) cluster;        boolean converged = kluster.calculateConvergence(convergenceDelta);        allConverged = allConverged && converged;        cluster.computeParameters();    }}
public double mahout_f2846_0(double distance, double h)
{    return distance < h ? 1.0 : 0.0;}
public static String mahout_f2847_0(Kluster cluster)
{    return cluster.getIdentifier() + ": " + cluster.computeCentroid().asFormatString();}
public String mahout_f2848_0()
{    return formatCluster(this);}
public void mahout_f2849_0(DataOutput out) throws IOException
{    super.write(out);    out.writeBoolean(converged);}
public void mahout_f2850_0(DataInput in) throws IOException
{    super.readFields(in);    this.converged = in.readBoolean();}
public String mahout_f2851_0()
{    return asFormatString(null);}
public String mahout_f2852_0()
{    return (converged ? "VL-" : "CL-") + getId();}
public boolean mahout_f2853_0(DistanceMeasure measure, double convergenceDelta)
{    Vector centroid = computeCentroid();    converged = measure.distance(centroid.getLengthSquared(), centroid, getCenter()) <= convergenceDelta;    return converged;}
public boolean mahout_f2854_0()
{    return converged;}
protected void mahout_f2855_0(boolean converged)
{    this.converged = converged;}
public boolean mahout_f2856_0(double convergenceDelta)
{    Vector centroid = computeCentroid();    converged = getMeasure().distance(centroid.getLengthSquared(), centroid, getCenter()) <= convergenceDelta;    return converged;}
public static void mahout_f2857_0(String[] args) throws Exception
{    ToolRunner.run(new Configuration(), new KMeansDriver(), args);}
public int mahout_f2858_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption(DefaultOptionCreator.distanceMeasureOption().create());    addOption(DefaultOptionCreator.clustersInOption().withDescription("The input centroids, as Vectors.  Must be a SequenceFile of Writable, Cluster/Canopy.  " + "If k is also specified, then a random set of vectors will be selected" + " and written out to this path first").create());    addOption(DefaultOptionCreator.numClustersOption().withDescription("The k in k-Means.  If specified, then a random selection of k Vectors will be chosen" + " as the Centroid and written to the clusters input path.").create());    addOption(DefaultOptionCreator.useSetRandomSeedOption().create());    addOption(DefaultOptionCreator.convergenceOption().create());    addOption(DefaultOptionCreator.maxIterationsOption().create());    addOption(DefaultOptionCreator.overwriteOption().create());    addOption(DefaultOptionCreator.clusteringOption().create());    addOption(DefaultOptionCreator.methodOption().create());    addOption(DefaultOptionCreator.outlierThresholdOption().create());    if (parseArguments(args) == null) {        return -1;    }    Path input = getInputPath();    Path clusters = new Path(getOption(DefaultOptionCreator.CLUSTERS_IN_OPTION));    Path output = getOutputPath();    String measureClass = getOption(DefaultOptionCreator.DISTANCE_MEASURE_OPTION);    if (measureClass == null) {        measureClass = SquaredEuclideanDistanceMeasure.class.getName();    }    double convergenceDelta = Double.parseDouble(getOption(DefaultOptionCreator.CONVERGENCE_DELTA_OPTION));    int maxIterations = Integer.parseInt(getOption(DefaultOptionCreator.MAX_ITERATIONS_OPTION));    if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {        HadoopUtil.delete(getConf(), output);    }    DistanceMeasure measure = ClassUtils.instantiateAs(measureClass, DistanceMeasure.class);    if (hasOption(DefaultOptionCreator.NUM_CLUSTERS_OPTION)) {        int numClusters = Integer.parseInt(getOption(DefaultOptionCreator.NUM_CLUSTERS_OPTION));        Long seed = null;        if (hasOption(DefaultOptionCreator.RANDOM_SEED)) {            seed = Long.parseLong(getOption(DefaultOptionCreator.RANDOM_SEED));        }        clusters = RandomSeedGenerator.buildRandom(getConf(), input, clusters, numClusters, measure, seed);    }    boolean runClustering = hasOption(DefaultOptionCreator.CLUSTERING_OPTION);    boolean runSequential = getOption(DefaultOptionCreator.METHOD_OPTION).equalsIgnoreCase(DefaultOptionCreator.SEQUENTIAL_METHOD);    double clusterClassificationThreshold = 0.0;    if (hasOption(DefaultOptionCreator.OUTLIER_THRESHOLD)) {        clusterClassificationThreshold = Double.parseDouble(getOption(DefaultOptionCreator.OUTLIER_THRESHOLD));    }    run(getConf(), input, clusters, output, convergenceDelta, maxIterations, runClustering, clusterClassificationThreshold, runSequential);    return 0;}
public static void mahout_f2859_1(Configuration conf, Path input, Path clustersIn, Path output, double convergenceDelta, int maxIterations, boolean runClustering, double clusterClassificationThreshold, boolean runSequential) throws IOException, InterruptedException, ClassNotFoundException
{        String delta = Double.toString(convergenceDelta);    if (log.isInfoEnabled()) {                    }    Path clustersOut = buildClusters(conf, input, clustersIn, output, maxIterations, delta, runSequential);    if (runClustering) {                clusterData(conf, input, clustersOut, output, clusterClassificationThreshold, runSequential);    }}
public static void mahout_f2860_0(Path input, Path clustersIn, Path output, double convergenceDelta, int maxIterations, boolean runClustering, double clusterClassificationThreshold, boolean runSequential) throws IOException, InterruptedException, ClassNotFoundException
{    run(new Configuration(), input, clustersIn, output, convergenceDelta, maxIterations, runClustering, clusterClassificationThreshold, runSequential);}
public static Path mahout_f2861_0(Configuration conf, Path input, Path clustersIn, Path output, int maxIterations, String delta, boolean runSequential) throws IOException, InterruptedException, ClassNotFoundException
{    double convergenceDelta = Double.parseDouble(delta);    List<Cluster> clusters = new ArrayList<>();    KMeansUtil.configureWithClusterInfo(conf, clustersIn, clusters);    if (clusters.isEmpty()) {        throw new IllegalStateException("No input clusters found in " + clustersIn + ". Check your -c argument.");    }    Path priorClustersPath = new Path(output, Cluster.INITIAL_CLUSTERS_DIR);    ClusteringPolicy policy = new KMeansClusteringPolicy(convergenceDelta);    ClusterClassifier prior = new ClusterClassifier(clusters, policy);    prior.writeToSeqFiles(priorClustersPath);    if (runSequential) {        ClusterIterator.iterateSeq(conf, input, priorClustersPath, output, maxIterations);    } else {        ClusterIterator.iterateMR(conf, input, priorClustersPath, output, maxIterations);    }    return output;}
public static void mahout_f2862_1(Configuration conf, Path input, Path clustersIn, Path output, double clusterClassificationThreshold, boolean runSequential) throws IOException, InterruptedException, ClassNotFoundException
{    if (log.isInfoEnabled()) {                    }    ClusterClassifier.writePolicy(new KMeansClusteringPolicy(), clustersIn);    ClusterClassificationDriver.run(conf, input, output, new Path(output, PathDirectory.CLUSTERED_POINTS_DIRECTORY), clusterClassificationThreshold, true, runSequential);}
public static void mahout_f2863_1(Configuration conf, Path clusterPath, Collection<Cluster> clusters)
{    for (Writable value : new SequenceFileDirValueIterable<>(clusterPath, PathType.LIST, PathFilters.partFilter(), conf)) {        Class<? extends Writable> valueClass = value.getClass();        if (valueClass.equals(ClusterWritable.class)) {            ClusterWritable clusterWritable = (ClusterWritable) value;            value = clusterWritable.getValue();            valueClass = value.getClass();        }                if (valueClass.equals(Kluster.class)) {                        clusters.add((Kluster) value);        } else if (valueClass.equals(Canopy.class)) {                        Canopy canopy = (Canopy) value;            clusters.add(new Kluster(canopy.getCenter(), canopy.getId(), canopy.getMeasure()));        } else {            throw new IllegalStateException("Bad value class: " + valueClass);        }    }}
public static Path mahout_f2864_0(Configuration conf, Path input, Path output, int k, DistanceMeasure measure) throws IOException
{    return buildRandom(conf, input, output, k, measure, null);}
public static Path mahout_f2865_1(Configuration conf, Path input, Path output, int k, DistanceMeasure measure, Long seed) throws IOException
{    Preconditions.checkArgument(k > 0, "Must be: k > 0, but k = " + k);        FileSystem fs = FileSystem.get(output.toUri(), conf);    HadoopUtil.delete(conf, output);    Path outFile = new Path(output, "part-randomSeed");    boolean newFile = fs.createNewFile(outFile);    if (newFile) {        Path inputPathPattern;        if (fs.getFileStatus(input).isDir()) {            inputPathPattern = new Path(input, "*");        } else {            inputPathPattern = input;        }        FileStatus[] inputFiles = fs.globStatus(inputPathPattern, PathFilters.logsCRCFilter());        Random random = (seed != null) ? RandomUtils.getRandom(seed) : RandomUtils.getRandom();        List<Text> chosenTexts = new ArrayList<>(k);        List<ClusterWritable> chosenClusters = new ArrayList<>(k);        int nextClusterId = 0;        int index = 0;        for (FileStatus fileStatus : inputFiles) {            if (!fileStatus.isDir()) {                for (Pair<Writable, VectorWritable> record : new SequenceFileIterable<Writable, VectorWritable>(fileStatus.getPath(), true, conf)) {                    Writable key = record.getFirst();                    VectorWritable value = record.getSecond();                    Kluster newCluster = new Kluster(value.get(), nextClusterId++, measure);                    newCluster.observe(value.get(), 1);                    Text newText = new Text(key.toString());                    int currentSize = chosenTexts.size();                    if (currentSize < k) {                        chosenTexts.add(newText);                        ClusterWritable clusterWritable = new ClusterWritable();                        clusterWritable.setValue(newCluster);                        chosenClusters.add(clusterWritable);                    } else {                        int j = random.nextInt(index);                        if (j < k) {                            chosenTexts.set(j, newText);                            ClusterWritable clusterWritable = new ClusterWritable();                            clusterWritable.setValue(newCluster);                            chosenClusters.set(j, clusterWritable);                        }                    }                    index++;                }            }        }        try (SequenceFile.Writer writer = SequenceFile.createWriter(fs, conf, outFile, Text.class, ClusterWritable.class)) {            for (int i = 0; i < chosenTexts.size(); i++) {                writer.append(chosenTexts.get(i), chosenClusters.get(i));            }                    }    }    return outFile;}
protected ModelTrainer mahout_f2866_0()
{    return modelTrainer;}
protected int mahout_f2867_0()
{    return maxIters;}
protected int mahout_f2868_0()
{    return numTopics;}
protected void mahout_f2869_1(Context context) throws IOException, InterruptedException
{        Configuration conf = context.getConfiguration();    float eta = conf.getFloat(CVB0Driver.TERM_TOPIC_SMOOTHING, Float.NaN);    float alpha = conf.getFloat(CVB0Driver.DOC_TOPIC_SMOOTHING, Float.NaN);    long seed = conf.getLong(CVB0Driver.RANDOM_SEED, 1234L);    numTopics = conf.getInt(CVB0Driver.NUM_TOPICS, -1);    int numTerms = conf.getInt(CVB0Driver.NUM_TERMS, -1);    int numUpdateThreads = conf.getInt(CVB0Driver.NUM_UPDATE_THREADS, 1);    int numTrainThreads = conf.getInt(CVB0Driver.NUM_TRAIN_THREADS, 4);    maxIters = conf.getInt(CVB0Driver.MAX_ITERATIONS_PER_DOC, 10);    float modelWeight = conf.getFloat(CVB0Driver.MODEL_WEIGHT, 1.0f);        Path[] modelPaths = CVB0Driver.getModelPaths(conf);    if (modelPaths != null && modelPaths.length > 0) {        readModel = new TopicModel(conf, eta, alpha, null, numUpdateThreads, modelWeight, modelPaths);    } else {                readModel = new TopicModel(numTopics, numTerms, eta, alpha, RandomUtils.getRandom(seed), null, numTrainThreads, modelWeight);    }        writeModel = modelWeight == 1 ? new TopicModel(numTopics, numTerms, eta, alpha, null, numUpdateThreads) : readModel;        modelTrainer = new ModelTrainer(readModel, writeModel, numTrainThreads, numTopics, numTerms);    modelTrainer.start();}
public void mahout_f2870_0(IntWritable docId, VectorWritable document, Context context) throws IOException, InterruptedException
{    /* where to get docTopics? */    Vector topicVector = new DenseVector(numTopics).assign(1.0 / numTopics);    modelTrainer.train(document.get(), topicVector, true, maxIters);}
protected void mahout_f2871_1(Context context) throws IOException, InterruptedException
{        modelTrainer.stop();        TopicModel readFrom = modelTrainer.getReadModel();    for (MatrixSlice topic : readFrom) {        context.write(new IntWritable(topic.index()), new VectorWritable(topic.vector()));    }    readModel.stop();    writeModel.stop();}
protected void mahout_f2872_1(Context context) throws IOException, InterruptedException
{    MemoryUtil.startMemoryLogger(5000);        Configuration conf = context.getConfiguration();    float eta = conf.getFloat(CVB0Driver.TERM_TOPIC_SMOOTHING, Float.NaN);    float alpha = conf.getFloat(CVB0Driver.DOC_TOPIC_SMOOTHING, Float.NaN);    long seed = conf.getLong(CVB0Driver.RANDOM_SEED, 1234L);    random = RandomUtils.getRandom(seed);    numTopics = conf.getInt(CVB0Driver.NUM_TOPICS, -1);    int numTerms = conf.getInt(CVB0Driver.NUM_TERMS, -1);    int numUpdateThreads = conf.getInt(CVB0Driver.NUM_UPDATE_THREADS, 1);    int numTrainThreads = conf.getInt(CVB0Driver.NUM_TRAIN_THREADS, 4);    maxIters = conf.getInt(CVB0Driver.MAX_ITERATIONS_PER_DOC, 10);    float modelWeight = conf.getFloat(CVB0Driver.MODEL_WEIGHT, 1.0f);    testFraction = conf.getFloat(CVB0Driver.TEST_SET_FRACTION, 0.1f);        Path[] modelPaths = CVB0Driver.getModelPaths(conf);    if (modelPaths != null && modelPaths.length > 0) {        readModel = new TopicModel(conf, eta, alpha, null, numUpdateThreads, modelWeight, modelPaths);    } else {                readModel = new TopicModel(numTopics, numTerms, eta, alpha, RandomUtils.getRandom(seed), null, numTrainThreads, modelWeight);    }        modelTrainer = new ModelTrainer(readModel, null, numTrainThreads, numTopics, numTerms);        topicVector = new DenseVector(new double[numTopics]);}
protected void mahout_f2873_0(Context context) throws IOException, InterruptedException
{    readModel.stop();    MemoryUtil.stopMemoryLogger();}
public void mahout_f2874_0(IntWritable docId, VectorWritable document, Context context) throws IOException, InterruptedException
{    if (testFraction < 1.0f && random.nextFloat() >= testFraction) {        return;    }    context.getCounter(Counters.SAMPLED_DOCUMENTS).increment(1);    outKey.set(document.get().norm(1));    outValue.set(modelTrainer.calculatePerplexity(document.get(), topicVector.assign(1.0 / numTopics), maxIters));    context.write(outKey, outValue);}
public void mahout_f2875_0(IntWritable docId, VectorWritable doc, Context context) throws IOException, InterruptedException
{    int numTopics = getNumTopics();    Vector docTopics = new DenseVector(numTopics).assign(1.0 / numTopics);    Matrix docModel = new SparseRowMatrix(numTopics, doc.get().size());    int maxIters = getMaxIters();    ModelTrainer modelTrainer = getModelTrainer();    for (int i = 0; i < maxIters; i++) {        modelTrainer.getReadModel().trainDocTopicModel(doc.get(), docTopics, docModel);    }    topics.set(docTopics);    context.write(docId, topics);}
protected void mahout_f2876_0(Context context)
{    getModelTrainer().stop();}
public int mahout_f2877_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption(DefaultOptionCreator.maxIterationsOption().create());    addOption(DefaultOptionCreator.CONVERGENCE_DELTA_OPTION, "cd", "The convergence delta value", String.valueOf(DEFAULT_CONVERGENCE_DELTA));    addOption(DefaultOptionCreator.overwriteOption().create());    addOption(NUM_TOPICS, "k", "Number of topics to learn", true);    addOption(NUM_TERMS, "nt", "Vocabulary size", false);    addOption(DOC_TOPIC_SMOOTHING, "a", "Smoothing for document/topic distribution", String.valueOf(DEFAULT_DOC_TOPIC_SMOOTHING));    addOption(TERM_TOPIC_SMOOTHING, "e", "Smoothing for topic/term distribution", String.valueOf(DEFAULT_TERM_TOPIC_SMOOTHING));    addOption(DICTIONARY, "dict", "Path to term-dictionary file(s) (glob expression supported)", false);    addOption(DOC_TOPIC_OUTPUT, "dt", "Output path for the training doc/topic distribution", false);    addOption(MODEL_TEMP_DIR, "mt", "Path to intermediate model path (useful for restarting)", false);    addOption(ITERATION_BLOCK_SIZE, "block", "Number of iterations per perplexity check", String.valueOf(DEFAULT_ITERATION_BLOCK_SIZE));    addOption(RANDOM_SEED, "seed", "Random seed", false);    addOption(TEST_SET_FRACTION, "tf", "Fraction of data to hold out for testing", String.valueOf(DEFAULT_TEST_SET_FRACTION));    addOption(NUM_TRAIN_THREADS, "ntt", "number of threads per mapper to train with", String.valueOf(DEFAULT_NUM_TRAIN_THREADS));    addOption(NUM_UPDATE_THREADS, "nut", "number of threads per mapper to update the model with", String.valueOf(DEFAULT_NUM_UPDATE_THREADS));    addOption(MAX_ITERATIONS_PER_DOC, "mipd", "max number of iterations per doc for p(topic|doc) learning", String.valueOf(DEFAULT_MAX_ITERATIONS_PER_DOC));    addOption(NUM_REDUCE_TASKS, null, "number of reducers to use during model estimation", String.valueOf(DEFAULT_NUM_REDUCE_TASKS));    addOption(buildOption(BACKFILL_PERPLEXITY, null, "enable backfilling of missing perplexity values", false, false, null));    if (parseArguments(args) == null) {        return -1;    }    int numTopics = Integer.parseInt(getOption(NUM_TOPICS));    Path inputPath = getInputPath();    Path topicModelOutputPath = getOutputPath();    int maxIterations = Integer.parseInt(getOption(DefaultOptionCreator.MAX_ITERATIONS_OPTION));    int iterationBlockSize = Integer.parseInt(getOption(ITERATION_BLOCK_SIZE));    double convergenceDelta = Double.parseDouble(getOption(DefaultOptionCreator.CONVERGENCE_DELTA_OPTION));    double alpha = Double.parseDouble(getOption(DOC_TOPIC_SMOOTHING));    double eta = Double.parseDouble(getOption(TERM_TOPIC_SMOOTHING));    int numTrainThreads = Integer.parseInt(getOption(NUM_TRAIN_THREADS));    int numUpdateThreads = Integer.parseInt(getOption(NUM_UPDATE_THREADS));    int maxItersPerDoc = Integer.parseInt(getOption(MAX_ITERATIONS_PER_DOC));    Path dictionaryPath = hasOption(DICTIONARY) ? new Path(getOption(DICTIONARY)) : null;    int numTerms = hasOption(NUM_TERMS) ? Integer.parseInt(getOption(NUM_TERMS)) : getNumTerms(getConf(), dictionaryPath);    Path docTopicOutputPath = hasOption(DOC_TOPIC_OUTPUT) ? new Path(getOption(DOC_TOPIC_OUTPUT)) : null;    Path modelTempPath = hasOption(MODEL_TEMP_DIR) ? new Path(getOption(MODEL_TEMP_DIR)) : getTempPath("topicModelState");    long seed = hasOption(RANDOM_SEED) ? Long.parseLong(getOption(RANDOM_SEED)) : System.nanoTime() % 10000;    float testFraction = hasOption(TEST_SET_FRACTION) ? Float.parseFloat(getOption(TEST_SET_FRACTION)) : 0.0f;    int numReduceTasks = Integer.parseInt(getOption(NUM_REDUCE_TASKS));    boolean backfillPerplexity = hasOption(BACKFILL_PERPLEXITY);    return run(getConf(), inputPath, topicModelOutputPath, numTopics, numTerms, alpha, eta, maxIterations, iterationBlockSize, convergenceDelta, dictionaryPath, docTopicOutputPath, modelTempPath, seed, testFraction, numTrainThreads, numUpdateThreads, maxItersPerDoc, numReduceTasks, backfillPerplexity);}
private static int mahout_f2878_0(Configuration conf, Path dictionaryPath) throws IOException
{    FileSystem fs = dictionaryPath.getFileSystem(conf);    Text key = new Text();    IntWritable value = new IntWritable();    int maxTermId = -1;    for (FileStatus stat : fs.globStatus(dictionaryPath)) {        SequenceFile.Reader reader = new SequenceFile.Reader(fs, stat.getPath(), conf);        while (reader.next(key, value)) {            maxTermId = Math.max(maxTermId, value.get());        }    }    return maxTermId + 1;}
private static double mahout_f2880_0(List<Double> perplexities)
{    int sz = perplexities.size();    if (sz < 2) {        return Double.MAX_VALUE;    }    return Math.abs(perplexities.get(sz - 1) - perplexities.get(sz - 2)) / perplexities.get(0);}
private double mahout_f2881_1(Configuration conf, Path corpusPath, Path modelPath, int iteration) throws IOException, ClassNotFoundException, InterruptedException
{    String jobName = "Calculating perplexity for " + modelPath;        Path outputPath = perplexityPath(modelPath.getParent(), iteration);    Job job = prepareJob(corpusPath, outputPath, CachingCVB0PerplexityMapper.class, DoubleWritable.class, DoubleWritable.class, DualDoubleSumReducer.class, DoubleWritable.class, DoubleWritable.class);    job.setJobName(jobName);    job.setCombinerClass(DualDoubleSumReducer.class);    job.setNumReduceTasks(1);    setModelPaths(job, modelPath);    HadoopUtil.delete(conf, outputPath);    if (!job.waitForCompletion(true)) {        throw new InterruptedException("Failed to calculate perplexity for: " + modelPath);    }    return readPerplexity(conf, modelPath.getParent(), iteration);}
public void mahout_f2882_0(Context context) throws IOException, InterruptedException
{    double keySum = 0.0;    double valueSum = 0.0;    while (context.nextKey()) {        keySum += context.getCurrentKey().get();        for (DoubleWritable value : context.getValues()) {            valueSum += value.get();        }    }    outKey.set(keySum);    outValue.set(valueSum);    context.write(outKey, outValue);}
public static double mahout_f2883_1(Configuration conf, Path topicModelStateTemp, int iteration) throws IOException
{    Path perplexityPath = perplexityPath(topicModelStateTemp, iteration);    FileSystem fs = FileSystem.get(perplexityPath.toUri(), conf);    if (!fs.exists(perplexityPath)) {                return Double.NaN;    }    double perplexity = 0;    double modelWeight = 0;    long n = 0;    for (Pair<DoubleWritable, DoubleWritable> pair : new SequenceFileDirIterable<DoubleWritable, DoubleWritable>(perplexityPath, PathType.LIST, PathFilters.partFilter(), null, true, conf)) {        modelWeight += pair.getFirst().get();        perplexity += pair.getSecond().get();        n++;    }        return perplexity / modelWeight;}
private Job mahout_f2884_1(Configuration conf, Path modelInput, Path output) throws IOException, InterruptedException, ClassNotFoundException
{    String jobName = String.format("Writing final topic/term distributions from %s to %s", modelInput, output);        Job job = prepareJob(modelInput, output, SequenceFileInputFormat.class, CVB0TopicTermVectorNormalizerMapper.class, IntWritable.class, VectorWritable.class, SequenceFileOutputFormat.class, jobName);    job.submit();    return job;}
private Job mahout_f2885_1(Configuration conf, Path corpus, Path modelInput, Path output) throws IOException, ClassNotFoundException, InterruptedException
{    String jobName = String.format("Writing final document/topic inference from %s to %s", corpus, output);        Job job = prepareJob(corpus, output, SequenceFileInputFormat.class, CVB0DocInferenceMapper.class, IntWritable.class, VectorWritable.class, SequenceFileOutputFormat.class, jobName);    FileSystem fs = FileSystem.get(corpus.toUri(), conf);    if (modelInput != null && fs.exists(modelInput)) {        FileStatus[] statuses = fs.listStatus(modelInput, PathFilters.partFilter());        URI[] modelUris = new URI[statuses.length];        for (int i = 0; i < statuses.length; i++) {            modelUris[i] = statuses[i].getPath().toUri();        }        DistributedCache.setCacheFiles(modelUris, conf);        setModelPaths(job, modelInput);    }    job.submit();    return job;}
public static Path mahout_f2886_0(Path topicModelStateTempPath, int iterationNumber)
{    return new Path(topicModelStateTempPath, "model-" + iterationNumber);}
public static Path mahout_f2887_0(Path topicModelStateTempPath, int iterationNumber)
{    return new Path(topicModelStateTempPath, "perplexity-" + iterationNumber);}
private static int mahout_f2888_1(Configuration config, Path modelTempDir, int maxIterations) throws IOException
{    FileSystem fs = FileSystem.get(modelTempDir.toUri(), config);    int iterationNumber = 1;    Path iterationPath = modelPath(modelTempDir, iterationNumber);    while (fs.exists(iterationPath) && iterationNumber <= maxIterations) {                iterationNumber++;        iterationPath = modelPath(modelTempDir, iterationNumber);    }    return iterationNumber - 1;}
public void mahout_f2889_1(Configuration conf, Path corpusInput, Path modelInput, Path modelOutput, int iterationNumber, int maxIterations, int numReduceTasks) throws IOException, ClassNotFoundException, InterruptedException
{    String jobName = String.format("Iteration %d of %d, input path: %s", iterationNumber, maxIterations, modelInput);        Job job = prepareJob(corpusInput, modelOutput, CachingCVB0Mapper.class, IntWritable.class, VectorWritable.class, VectorSumReducer.class, IntWritable.class, VectorWritable.class);    job.setCombinerClass(VectorSumReducer.class);    job.setNumReduceTasks(numReduceTasks);    job.setJobName(jobName);    setModelPaths(job, modelInput);    HadoopUtil.delete(conf, modelOutput);    if (!job.waitForCompletion(true)) {        throw new InterruptedException(String.format("Failed to complete iteration %d stage 1", iterationNumber));    }}
private static void mahout_f2890_0(Job job, Path modelPath) throws IOException
{    Configuration conf = job.getConfiguration();    if (modelPath == null || !FileSystem.get(modelPath.toUri(), conf).exists(modelPath)) {        return;    }    FileStatus[] statuses = FileSystem.get(modelPath.toUri(), conf).listStatus(modelPath, PathFilters.partFilter());    Preconditions.checkState(statuses.length > 0, "No part files found in model path '%s'", modelPath.toString());    String[] modelPaths = new String[statuses.length];    for (int i = 0; i < statuses.length; i++) {        modelPaths[i] = statuses[i].getPath().toUri().toString();    }    conf.setStrings(MODEL_PATHS, modelPaths);}
public static Path[] mahout_f2891_0(Configuration conf)
{    String[] modelPathNames = conf.getStrings(MODEL_PATHS);    if (modelPathNames == null || modelPathNames.length == 0) {        return null;    }    Path[] modelPaths = new Path[modelPathNames.length];    for (int i = 0; i < modelPathNames.length; i++) {        modelPaths[i] = new Path(modelPathNames[i]);    }    return modelPaths;}
public static void mahout_f2892_0(String[] args) throws Exception
{    ToolRunner.run(new Configuration(), new CVB0Driver(), args);}
protected void mahout_f2893_0(IntWritable key, VectorWritable value, Context context) throws IOException, InterruptedException
{    value.get().assign(Functions.div(value.get().norm(1.0)));    context.write(key, value);}
public void mahout_f2894_0(boolean verbose)
{    this.verbose = verbose;}
private void mahout_f2895_1()
{    totalCorpusWeight = 0;    int numNonZero = 0;    for (int i = 0; i < numDocuments; i++) {        Vector v = corpusWeights.viewRow(i);        double norm;        if (v != null && (norm = v.norm(1)) != 0) {            numNonZero += v.getNumNondefaultElements();            totalCorpusWeight += norm;        }    }    String s = "Initializing corpus with %d docs, %d terms, %d nonzero entries, total termWeight %f";    }
private void mahout_f2896_0()
{    TopicModel topicModel = new TopicModel(numTopics, numTerms, eta, alpha, RandomUtils.getRandom(), terms, numUpdatingThreads, initialModelCorpusFraction == 0 ? 1 : initialModelCorpusFraction * totalCorpusWeight);    topicModel.setConf(getConf());    TopicModel updatedModel = initialModelCorpusFraction == 0 ? new TopicModel(numTopics, numTerms, eta, alpha, null, terms, numUpdatingThreads, 1) : topicModel;    updatedModel.setConf(getConf());    docTopicCounts = new DenseMatrix(numDocuments, numTopics);    docTopicCounts.assign(1.0 / numTopics);    modelTrainer = new ModelTrainer(topicModel, updatedModel, numTrainingThreads, numTopics, numTerms);}
public void mahout_f2897_0()
{    trainDocuments(0);}
public void mahout_f2898_0(double testFraction)
{    long start = System.nanoTime();    modelTrainer.start();    for (int docId = 0; docId < corpusWeights.numRows(); docId++) {        if (testFraction == 0 || docId % (1 / testFraction) != 0) {                        Vector docTopics = new DenseVector(numTopics).assign(1.0 / numTopics);            modelTrainer.trainSync(corpusWeights.viewRow(docId), docTopics, true, 10);        }    }    modelTrainer.stop();    logTime("train documents", System.nanoTime() - start);}
public double mahout_f2899_0(double minFractionalErrorChange, int maxIterations, int minIter)
{    return iterateUntilConvergence(minFractionalErrorChange, maxIterations, minIter, 0);}
public double mahout_f2900_1(double minFractionalErrorChange, int maxIterations, int minIter, double testFraction)
{    int iter = 0;    double oldPerplexity = 0;    while (iter < minIter) {        trainDocuments(testFraction);        if (verbose) {                    }                oldPerplexity = modelTrainer.calculatePerplexity(corpusWeights, docTopicCounts, testFraction);                iter++;    }    double newPerplexity = 0;    double fractionalChange = Double.MAX_VALUE;    while (iter < maxIterations && fractionalChange > minFractionalErrorChange) {        trainDocuments();        if (verbose) {                    }        newPerplexity = modelTrainer.calculatePerplexity(corpusWeights, docTopicCounts, testFraction);                iter++;        fractionalChange = Math.abs(newPerplexity - oldPerplexity) / oldPerplexity;                oldPerplexity = newPerplexity;    }    if (iter < maxIterations) {            } else {            }    return newPerplexity;}
public void mahout_f2901_0(Path outputPath) throws IOException
{    modelTrainer.persist(outputPath);}
private static void mahout_f2902_1(String label, long nanos)
{    }
public static int mahout_f2903_1(String[] args, Configuration conf) throws Exception
{    DefaultOptionBuilder obuilder = new DefaultOptionBuilder();    ArgumentBuilder abuilder = new ArgumentBuilder();    GroupBuilder gbuilder = new GroupBuilder();    Option helpOpt = DefaultOptionCreator.helpOption();    Option inputDirOpt = obuilder.withLongName("input").withRequired(true).withArgument(abuilder.withName("input").withMinimum(1).withMaximum(1).create()).withDescription("The Directory on HDFS containing the collapsed, properly formatted files having " + "one doc per line").withShortName("i").create();    Option dictOpt = obuilder.withLongName("dictionary").withRequired(false).withArgument(abuilder.withName("dictionary").withMinimum(1).withMaximum(1).create()).withDescription("The path to the term-dictionary format is ... ").withShortName("d").create();    Option dfsOpt = obuilder.withLongName("dfs").withRequired(false).withArgument(abuilder.withName("dfs").withMinimum(1).withMaximum(1).create()).withDescription("HDFS namenode URI").withShortName("dfs").create();    Option numTopicsOpt = obuilder.withLongName("numTopics").withRequired(true).withArgument(abuilder.withName("numTopics").withMinimum(1).withMaximum(1).create()).withDescription("Number of topics to learn").withShortName("top").create();    Option outputTopicFileOpt = obuilder.withLongName("topicOutputFile").withRequired(true).withArgument(abuilder.withName("topicOutputFile").withMinimum(1).withMaximum(1).create()).withDescription("File to write out p(term | topic)").withShortName("to").create();    Option outputDocFileOpt = obuilder.withLongName("docOutputFile").withRequired(true).withArgument(abuilder.withName("docOutputFile").withMinimum(1).withMaximum(1).create()).withDescription("File to write out p(topic | docid)").withShortName("do").create();    Option alphaOpt = obuilder.withLongName("alpha").withRequired(false).withArgument(abuilder.withName("alpha").withMinimum(1).withMaximum(1).withDefault("0.1").create()).withDescription("Smoothing parameter for p(topic | document) prior").withShortName("a").create();    Option etaOpt = obuilder.withLongName("eta").withRequired(false).withArgument(abuilder.withName("eta").withMinimum(1).withMaximum(1).withDefault("0.1").create()).withDescription("Smoothing parameter for p(term | topic)").withShortName("e").create();    Option maxIterOpt = obuilder.withLongName("maxIterations").withRequired(false).withArgument(abuilder.withName("maxIterations").withMinimum(1).withMaximum(1).withDefault("10").create()).withDescription("Maximum number of training passes").withShortName("m").create();    Option modelCorpusFractionOption = obuilder.withLongName("modelCorpusFraction").withRequired(false).withArgument(abuilder.withName("modelCorpusFraction").withMinimum(1).withMaximum(1).withDefault("0.0").create()).withShortName("mcf").withDescription("For online updates, initial value of |model|/|corpus|").create();    Option burnInOpt = obuilder.withLongName("burnInIterations").withRequired(false).withArgument(abuilder.withName("burnInIterations").withMinimum(1).withMaximum(1).withDefault("5").create()).withDescription("Minimum number of iterations").withShortName("b").create();    Option convergenceOpt = obuilder.withLongName("convergence").withRequired(false).withArgument(abuilder.withName("convergence").withMinimum(1).withMaximum(1).withDefault("0.0").create()).withDescription("Fractional rate of perplexity to consider convergence").withShortName("c").create();    Option reInferDocTopicsOpt = obuilder.withLongName("reInferDocTopics").withRequired(false).withArgument(abuilder.withName("reInferDocTopics").withMinimum(1).withMaximum(1).withDefault("no").create()).withDescription("re-infer p(topic | doc) : [no | randstart | continue]").withShortName("rdt").create();    Option numTrainThreadsOpt = obuilder.withLongName("numTrainThreads").withRequired(false).withArgument(abuilder.withName("numTrainThreads").withMinimum(1).withMaximum(1).withDefault("1").create()).withDescription("number of threads to train with").withShortName("ntt").create();    Option numUpdateThreadsOpt = obuilder.withLongName("numUpdateThreads").withRequired(false).withArgument(abuilder.withName("numUpdateThreads").withMinimum(1).withMaximum(1).withDefault("1").create()).withDescription("number of threads to update the model with").withShortName("nut").create();    Option verboseOpt = obuilder.withLongName("verbose").withRequired(false).withArgument(abuilder.withName("verbose").withMinimum(1).withMaximum(1).withDefault("false").create()).withDescription("print verbose information, like top-terms in each topic, during iteration").withShortName("v").create();    Group group = gbuilder.withName("Options").withOption(inputDirOpt).withOption(numTopicsOpt).withOption(alphaOpt).withOption(etaOpt).withOption(maxIterOpt).withOption(burnInOpt).withOption(convergenceOpt).withOption(dictOpt).withOption(reInferDocTopicsOpt).withOption(outputDocFileOpt).withOption(outputTopicFileOpt).withOption(dfsOpt).withOption(numTrainThreadsOpt).withOption(numUpdateThreadsOpt).withOption(modelCorpusFractionOption).withOption(verboseOpt).create();    try {        Parser parser = new Parser();        parser.setGroup(group);        parser.setHelpOption(helpOpt);        CommandLine cmdLine = parser.parse(args);        if (cmdLine.hasOption(helpOpt)) {            CommandLineUtil.printHelp(group);            return -1;        }        String inputDirString = (String) cmdLine.getValue(inputDirOpt);        String dictDirString = cmdLine.hasOption(dictOpt) ? (String) cmdLine.getValue(dictOpt) : null;        int numTopics = Integer.parseInt((String) cmdLine.getValue(numTopicsOpt));        double alpha = Double.parseDouble((String) cmdLine.getValue(alphaOpt));        double eta = Double.parseDouble((String) cmdLine.getValue(etaOpt));        int maxIterations = Integer.parseInt((String) cmdLine.getValue(maxIterOpt));        int burnInIterations = Integer.parseInt((String) cmdLine.getValue(burnInOpt));        double minFractionalErrorChange = Double.parseDouble((String) cmdLine.getValue(convergenceOpt));        int numTrainThreads = Integer.parseInt((String) cmdLine.getValue(numTrainThreadsOpt));        int numUpdateThreads = Integer.parseInt((String) cmdLine.getValue(numUpdateThreadsOpt));        String topicOutFile = (String) cmdLine.getValue(outputTopicFileOpt);        String docOutFile = (String) cmdLine.getValue(outputDocFileOpt);                boolean verbose = Boolean.parseBoolean((String) cmdLine.getValue(verboseOpt));        double modelCorpusFraction = Double.parseDouble((String) cmdLine.getValue(modelCorpusFractionOption));        long start = System.nanoTime();        if (conf.get("fs.default.name") == null) {            String dfsNameNode = (String) cmdLine.getValue(dfsOpt);            conf.set("fs.default.name", dfsNameNode);        }        String[] terms = loadDictionary(dictDirString, conf);        logTime("dictionary loading", System.nanoTime() - start);        start = System.nanoTime();        Matrix corpus = loadVectors(inputDirString, conf);        logTime("vector seqfile corpus loading", System.nanoTime() - start);        start = System.nanoTime();        InMemoryCollapsedVariationalBayes0 cvb0 = new InMemoryCollapsedVariationalBayes0(corpus, terms, numTopics, alpha, eta, numTrainThreads, numUpdateThreads, modelCorpusFraction);        logTime("cvb0 init", System.nanoTime() - start);        start = System.nanoTime();        cvb0.setVerbose(verbose);        cvb0.iterateUntilConvergence(minFractionalErrorChange, maxIterations, burnInIterations);        logTime("total training time", System.nanoTime() - start);        /*      if ("randstart".equalsIgnoreCase(reInferDocTopics)) {        cvb0.inferDocuments(0.0, 100, true);      } else if ("continue".equalsIgnoreCase(reInferDocTopics)) {        cvb0.inferDocuments(0.0, 100, false);      }       */        start = System.nanoTime();        cvb0.writeModel(new Path(topicOutFile));        DistributedRowMatrixWriter.write(new Path(docOutFile), conf, cvb0.docTopicCounts);        logTime("printTopics", System.nanoTime() - start);    } catch (OptionException e) {                CommandLineUtil.printHelp(group);    }    return 0;}
private static String[] mahout_f2904_0(String dictionaryPath, Configuration conf)
{    if (dictionaryPath == null) {        return null;    }    Path dictionaryFile = new Path(dictionaryPath);    List<Pair<Integer, String>> termList = new ArrayList<>();    int maxTermId = 0;        for (Pair<Writable, IntWritable> record : new SequenceFileIterable<Writable, IntWritable>(dictionaryFile, true, conf)) {        termList.add(new Pair<>(record.getSecond().get(), record.getFirst().toString()));        maxTermId = Math.max(maxTermId, record.getSecond().get());    }    String[] terms = new String[maxTermId + 1];    for (Pair<Integer, String> pair : termList) {        terms[pair.getFirst()] = pair.getSecond();    }    return terms;}
public Configuration mahout_f2905_0()
{    return super.getConf();}
private static Matrix mahout_f2906_0(String vectorPathString, Configuration conf) throws IOException
{    Path vectorPath = new Path(vectorPathString);    FileSystem fs = vectorPath.getFileSystem(conf);    List<Path> subPaths = new ArrayList<>();    if (fs.isFile(vectorPath)) {        subPaths.add(vectorPath);    } else {        for (FileStatus fileStatus : fs.listStatus(vectorPath, PathFilters.logsCRCFilter())) {            subPaths.add(fileStatus.getPath());        }    }    List<Pair<Integer, Vector>> rowList = new ArrayList<>();    int numRows = Integer.MIN_VALUE;    int numCols = -1;    boolean sequentialAccess = false;    for (Path subPath : subPaths) {        for (Pair<IntWritable, VectorWritable> record : new SequenceFileIterable<IntWritable, VectorWritable>(subPath, true, conf)) {            int id = record.getFirst().get();            Vector vector = record.getSecond().get();            if (vector instanceof NamedVector) {                vector = ((NamedVector) vector).getDelegate();            }            if (numCols < 0) {                numCols = vector.size();                sequentialAccess = vector.isSequentialAccess();            }            rowList.add(Pair.of(id, vector));            numRows = Math.max(numRows, id);        }    }    numRows++;    Vector[] rowVectors = new Vector[numRows];    for (Pair<Integer, Vector> pair : rowList) {        rowVectors[pair.getFirst()] = pair.getSecond();    }    return new SparseRowMatrix(numRows, numCols, rowVectors, true, !sequentialAccess);}
public int mahout_f2907_0(String[] strings) throws Exception
{    return main2(strings, getConf());}
public static void mahout_f2908_0(String[] args) throws Exception
{    ToolRunner.run(new InMemoryCollapsedVariationalBayes0(), args);}
public TopicModel mahout_f2909_0()
{    return readModel;}
public void mahout_f2910_1()
{        workQueue = new ArrayBlockingQueue<>(numTrainThreads * 10);    threadPool = new ThreadPoolExecutor(numTrainThreads, numTrainThreads, 0, TimeUnit.SECONDS, workQueue);    threadPool.allowCoreThreadTimeOut(false);    threadPool.prestartAllCoreThreads();    writeModel.reset();}
public void mahout_f2911_0(VectorIterable matrix, VectorIterable docTopicCounts)
{    train(matrix, docTopicCounts, 1);}
public double mahout_f2912_0(VectorIterable matrix, VectorIterable docTopicCounts)
{    return calculatePerplexity(matrix, docTopicCounts, 0);}
public double mahout_f2913_0(VectorIterable matrix, VectorIterable docTopicCounts, double testFraction)
{    Iterator<MatrixSlice> docIterator = matrix.iterator();    Iterator<MatrixSlice> docTopicIterator = docTopicCounts.iterator();    double perplexity = 0;    double matrixNorm = 0;    while (docIterator.hasNext() && docTopicIterator.hasNext()) {        MatrixSlice docSlice = docIterator.next();        MatrixSlice topicSlice = docTopicIterator.next();        int docId = docSlice.index();        Vector document = docSlice.vector();        Vector topicDist = topicSlice.vector();        if (testFraction == 0 || docId % (1 / testFraction) == 0) {            trainSync(document, topicDist, false, 10);            perplexity += readModel.perplexity(document, topicDist);            matrixNorm += document.norm(1);        }    }    return perplexity / matrixNorm;}
public void mahout_f2914_1(VectorIterable matrix, VectorIterable docTopicCounts, int numDocTopicIters)
{    start();    Iterator<MatrixSlice> docIterator = matrix.iterator();    Iterator<MatrixSlice> docTopicIterator = docTopicCounts.iterator();    long startTime = System.nanoTime();    int i = 0;    double[] times = new double[100];    Map<Vector, Vector> batch = new HashMap<>();    int numTokensInBatch = 0;    long batchStart = System.nanoTime();    while (docIterator.hasNext() && docTopicIterator.hasNext()) {        i++;        Vector document = docIterator.next().vector();        Vector topicDist = docTopicIterator.next().vector();        if (isReadWrite) {            if (batch.size() < numTrainThreads) {                batch.put(document, topicDist);                if (log.isDebugEnabled()) {                    numTokensInBatch += document.getNumNondefaultElements();                }            } else {                batchTrain(batch, true, numDocTopicIters);                long time = System.nanoTime();                                batchStart = time;                numTokensInBatch = 0;            }        } else {            long start = System.nanoTime();            train(document, topicDist, true, numDocTopicIters);            if (log.isDebugEnabled()) {                times[i % times.length] = (System.nanoTime() - start) / (1.0e6 * document.getNumNondefaultElements());                if (i % 100 == 0) {                    long time = System.nanoTime() - startTime;                                        if (i % 500 == 0) {                        Arrays.sort(times);                                            }                }            }        }    }    stop();}
public void mahout_f2915_1(Map<Vector, Vector> batch, boolean update, int numDocTopicsIters)
{    while (true) {        try {            List<TrainerRunnable> runnables = new ArrayList<>();            for (Map.Entry<Vector, Vector> entry : batch.entrySet()) {                runnables.add(new TrainerRunnable(readModel, null, entry.getKey(), entry.getValue(), new SparseRowMatrix(numTopics, numTerms, true), numDocTopicsIters));            }            threadPool.invokeAll(runnables);            if (update) {                for (TrainerRunnable runnable : runnables) {                    writeModel.update(runnable.docTopicModel);                }            }            break;        } catch (InterruptedException e) {                    }    }}
public void mahout_f2916_1(Vector document, Vector docTopicCounts, boolean update, int numDocTopicIters)
{    while (true) {        try {            workQueue.put(new TrainerRunnable(readModel, update ? writeModel : null, document, docTopicCounts, new SparseRowMatrix(numTopics, numTerms, true), numDocTopicIters));            return;        } catch (InterruptedException e) {                    }    }}
public void mahout_f2917_0(Vector document, Vector docTopicCounts, boolean update, int numDocTopicIters)
{    new TrainerRunnable(readModel, update ? writeModel : null, document, docTopicCounts, new SparseRowMatrix(numTopics, numTerms, true), numDocTopicIters).run();}
public double mahout_f2918_0(Vector document, Vector docTopicCounts, int numDocTopicIters)
{    TrainerRunnable runner = new TrainerRunnable(readModel, null, document, docTopicCounts, new SparseRowMatrix(numTopics, numTerms, true), numDocTopicIters);    return runner.call();}
public void mahout_f2919_1()
{    long startTime = System.nanoTime();        try {        threadPool.shutdown();        if (!threadPool.awaitTermination(60, TimeUnit.SECONDS)) {                    }        long newTime = System.nanoTime();                startTime = newTime;        readModel.stop();        newTime = System.nanoTime();                startTime = newTime;        writeModel.stop();        newTime = System.nanoTime();                TopicModel tmpModel = writeModel;        writeModel = readModel;        readModel = tmpModel;    } catch (InterruptedException e) {            }}
public void mahout_f2920_0(Path outputPath) throws IOException
{    readModel.persist(outputPath, true);}
public void mahout_f2921_0()
{    for (int i = 0; i < numDocTopicIters; i++) {                readModel.trainDocTopicModel(document, docTopics, docTopicModel);    }    if (writeModel != null) {                                writeModel.update(docTopicModel);    }}
public Double mahout_f2922_0()
{    run();    return readModel.perplexity(document, docTopics);}
public int mahout_f2923_0()
{    return numTerms;}
public int mahout_f2924_0()
{    return numTopics;}
private static Vector mahout_f2925_0(Matrix m)
{    Vector v = new DenseVector(m.numRows());    for (MatrixSlice slice : m) {        v.set(slice.index(), slice.vector().norm(1));    }    return v;}
private synchronized void mahout_f2926_1()
{    if (threadPool != null) {        threadPool.shutdown();        try {            threadPool.awaitTermination(100, TimeUnit.SECONDS);        } catch (InterruptedException e) {                    }    }    threadPool = new ThreadPoolExecutor(numThreads, numThreads, 0, TimeUnit.SECONDS, new ArrayBlockingQueue<Runnable>(numThreads * 10));    threadPool.allowCoreThreadTimeOut(false);    updaters = new Updater[numThreads];    for (int i = 0; i < numThreads; i++) {        updaters[i] = new Updater();        threadPool.submit(updaters[i]);    }}
 Matrix mahout_f2927_0()
{    return topicTermCounts;}
public Iterator<MatrixSlice> mahout_f2928_0()
{    return topicTermCounts.iterateAll();}
public Vector mahout_f2929_0()
{    return topicSums;}
private static Pair<Matrix, Vector> mahout_f2930_0(int numTopics, int numTerms, Random random)
{    Matrix topicTermCounts = new DenseMatrix(numTopics, numTerms);    Vector topicSums = new DenseVector(numTopics);    if (random != null) {        for (int x = 0; x < numTopics; x++) {            for (int term = 0; term < numTerms; term++) {                topicTermCounts.viewRow(x).set(term, random.nextDouble());            }        }    }    for (int x = 0; x < numTopics; x++) {        topicSums.set(x, random == null ? 1.0 : topicTermCounts.viewRow(x).norm(1));    }    return Pair.of(topicTermCounts, topicSums);}
public static Pair<Matrix, Vector> mahout_f2931_0(Configuration conf, Path... modelPaths) throws IOException
{    int numTopics = -1;    int numTerms = -1;    List<Pair<Integer, Vector>> rows = new ArrayList<>();    for (Path modelPath : modelPaths) {        for (Pair<IntWritable, VectorWritable> row : new SequenceFileIterable<IntWritable, VectorWritable>(modelPath, true, conf)) {            rows.add(Pair.of(row.getFirst().get(), row.getSecond().get()));            numTopics = Math.max(numTopics, row.getFirst().get());            if (numTerms < 0) {                numTerms = row.getSecond().get().size();            }        }    }    if (rows.isEmpty()) {        throw new IOException(Arrays.toString(modelPaths) + " have no vectors in it");    }    numTopics++;    Matrix model = new DenseMatrix(numTopics, numTerms);    Vector topicSums = new DenseVector(numTopics);    for (Pair<Integer, Vector> pair : rows) {        model.viewRow(pair.getFirst()).assign(pair.getSecond());        topicSums.set(pair.getFirst(), pair.getSecond().norm(1));    }    return Pair.of(model, topicSums);}
public String mahout_f2932_0()
{    StringBuilder buf = new StringBuilder();    for (int x = 0; x < numTopics; x++) {        String v = dictionary != null ? vectorToSortedString(topicTermCounts.viewRow(x).normalize(1), dictionary) : topicTermCounts.viewRow(x).asFormatString();        buf.append(v).append('\n');    }    return buf.toString();}
public int mahout_f2933_0(Vector topicDistribution)
{    return sampler.sample(topicTermCounts.viewRow(sampler.sample(topicDistribution)));}
public int mahout_f2934_0(int topic)
{    return sampler.sample(topicTermCounts.viewRow(topic));}
public synchronized void mahout_f2935_0()
{    for (int x = 0; x < numTopics; x++) {        topicTermCounts.assignRow(x, new SequentialAccessSparseVector(numTerms));    }    topicSums.assign(1.0);    if (threadPool.isTerminated()) {        initializeThreadPool();    }}
public synchronized void mahout_f2936_1()
{    for (Updater updater : updaters) {        updater.shutdown();    }    threadPool.shutdown();    try {        if (!threadPool.awaitTermination(60, TimeUnit.SECONDS)) {                    }    } catch (InterruptedException e) {            }}
public void mahout_f2937_0()
{    for (int x = 0; x < numTopics; x++) {        topicTermCounts.assignRow(x, topicTermCounts.viewRow(x).normalize(1));        topicSums.assign(1.0);    }}
public void mahout_f2938_0(Vector original, Vector topics, Matrix docTopicModel)
{            pTopicGivenTerm(original, topics, docTopicModel);    normalizeByTopic(docTopicModel);        for (Element e : original.nonZeroes()) {        for (int x = 0; x < numTopics; x++) {            Vector docTopicModelRow = docTopicModel.viewRow(x);            docTopicModelRow.setQuick(e.index(), docTopicModelRow.getQuick(e.index()) * e.get());        }    }        topics.assign(0.0);    for (int x = 0; x < numTopics; x++) {        topics.set(x, docTopicModel.viewRow(x).norm(1));    }        topics.assign(Functions.mult(1 / topics.norm(1)));}
public Vector mahout_f2939_0(Vector original, Vector docTopics)
{    Vector pTerm = original.like();    for (Element e : original.nonZeroes()) {        int term = e.index();                double pA = 0;        for (int x = 0; x < numTopics; x++) {            pA += (topicTermCounts.viewRow(x).get(term) / topicSums.get(x)) * docTopics.get(x);        }        pTerm.set(term, pA);    }    return pTerm;}
public void mahout_f2940_0(Matrix docTopicCounts)
{    for (int x = 0; x < numTopics; x++) {        updaters[x % updaters.length].update(x, docTopicCounts.viewRow(x));    }}
public void mahout_f2941_0(int topic, Vector docTopicCounts)
{    topicTermCounts.viewRow(topic).assign(docTopicCounts, Functions.PLUS);    topicSums.set(topic, topicSums.get(topic) + docTopicCounts.norm(1));}
public void mahout_f2942_0(int termId, Vector topicCounts)
{    for (int x = 0; x < numTopics; x++) {        Vector v = topicTermCounts.viewRow(x);        v.set(termId, v.get(termId) + topicCounts.get(x));    }    topicSums.assign(topicCounts, Functions.PLUS);}
public void mahout_f2943_0(Path outputDir, boolean overwrite) throws IOException
{    FileSystem fs = outputDir.getFileSystem(conf);    if (overwrite) {                fs.delete(outputDir, true);    }    DistributedRowMatrixWriter.write(outputDir, conf, topicTermCounts);}
private void mahout_f2944_0(Vector document, Vector docTopics, Matrix termTopicDist)
{        for (int x = 0; x < numTopics; x++) {                double topicWeight = docTopics == null ? 1.0 : docTopics.get(x);                Vector topicTermRow = topicTermCounts.viewRow(x);                double topicSum = topicSums.get(x);                Vector termTopicRow = termTopicDist.viewRow(x);                for (Element e : document.nonZeroes()) {            int termIndex = e.index();                        double termTopicLikelihood = (topicTermRow.get(termIndex) + eta) * (topicWeight + alpha) / (topicSum + eta * numTerms);            termTopicRow.set(termIndex, termTopicLikelihood);        }    }}
public double mahout_f2945_0(Vector document, Vector docTopics)
{    double perplexity = 0;    double norm = docTopics.norm(1) + (docTopics.size() * alpha);    for (Element e : document.nonZeroes()) {        int term = e.index();        double prob = 0;        for (int x = 0; x < numTopics; x++) {            double d = (docTopics.get(x) + alpha) / norm;            double p = d * (topicTermCounts.viewRow(x).get(term) + eta) / (topicSums.get(x) + eta * numTerms);            prob += p;        }        perplexity += e.get() * Math.log(prob);    }    return -perplexity;}
private void mahout_f2946_0(Matrix perTopicSparseDistributions)
{        for (Element e : perTopicSparseDistributions.viewRow(0).nonZeroes()) {        int a = e.index();        double sum = 0;        for (int x = 0; x < numTopics; x++) {            sum += perTopicSparseDistributions.viewRow(x).get(a);        }        for (int x = 0; x < numTopics; x++) {            perTopicSparseDistributions.viewRow(x).set(a, perTopicSparseDistributions.viewRow(x).get(a) / sum);        }    }}
public static String mahout_f2947_0(Vector vector, String[] dictionary)
{    List<Pair<String, Double>> vectorValues = new ArrayList<>(vector.getNumNondefaultElements());    for (Element e : vector.nonZeroes()) {        vectorValues.add(Pair.of(dictionary != null ? dictionary[e.index()] : String.valueOf(e.index()), e.get()));    }    Collections.sort(vectorValues, new Comparator<Pair<String, Double>>() {        @Override        public int compare(Pair<String, Double> x, Pair<String, Double> y) {            return y.getSecond().compareTo(x.getSecond());        }    });    Iterator<Pair<String, Double>> listIt = vectorValues.iterator();    StringBuilder bldr = new StringBuilder(2048);    bldr.append('{');    int i = 0;    while (listIt.hasNext() && i < 25) {        i++;        Pair<String, Double> p = listIt.next();        bldr.append(p.getFirst());        bldr.append(':');        bldr.append(p.getSecond());        bldr.append(',');    }    if (bldr.length() > 1) {        bldr.setCharAt(bldr.length() - 1, '}');    }    return bldr.toString();}
public int mahout_f2948_0(Pair<String, Double> x, Pair<String, Double> y)
{    return y.getSecond().compareTo(x.getSecond());}
public void mahout_f2949_0(Configuration configuration)
{    this.conf = configuration;}
public Configuration mahout_f2950_0()
{    return conf;}
public void mahout_f2951_1()
{    try {        synchronized (this) {            while (!shutdownComplete) {                shutdown = true;                                wait(10000L);            }        }    } catch (InterruptedException e) {            }}
public boolean mahout_f2952_1(int topic, Vector v)
{    if (shutdown) {                throw new IllegalStateException("In SHUTDOWN state: cannot submit tasks");    }    while (true) {                try {                        queue.put(Pair.of(topic, v));                        return true;        } catch (InterruptedException e) {                    }    }}
public void mahout_f2953_1()
{    while (!shutdown) {        try {            Pair<Integer, Vector> pair = queue.poll(1, TimeUnit.SECONDS);            if (pair != null) {                updateTopic(pair.getFirst(), pair.getSecond());            }        } catch (InterruptedException e) {                    }    }        for (Pair<Integer, Vector> pair : queue) {        updateTopic(pair.getFirst(), pair.getSecond());    }    synchronized (this) {        shutdownComplete = true;        notifyAll();    }}
public double mahout_f2954_0()
{    return sumWeight;}
public Vector mahout_f2955_0()
{    return mean;}
public Vector mahout_f2956_0()
{    return variance.clone().assign(new SquareRootFunction());}
public void mahout_f2957_0(Vector x, double weight)
{    double temp = weight + sumWeight;    Vector q;    if (mean == null) {        mean = x.like();        q = x.clone();    } else {        q = x.minus(mean);    }    Vector r = q.times(weight).divide(temp);    if (s == null) {        s = q.times(sumWeight).times(r);    } else {        s = s.plus(q.times(sumWeight).times(r));    }    mean = mean.plus(r);    sumWeight = temp;        variance = s.divide(sumWeight - 1);}
public void mahout_f2958_0()
{}
public double mahout_f2959_0()
{    if (sumWeight == 0.0) {        return 0.0;    } else {        Vector std = getStd();        return std.zSum() / std.size();    }}
public Vector mahout_f2960_0()
{    return variance;}
public double mahout_f2961_0()
{    return s0;}
public Vector mahout_f2962_0()
{    return mean;}
public Vector mahout_f2963_0()
{    return std;}
public double mahout_f2964_0()
{    if (s0 == 0.0) {        return 0.0;    } else {        return std.zSum() / std.size();    }}
public Vector mahout_f2965_0()
{    return std.times(std);}
public void mahout_f2966_0(Vector x, double weight)
{    s0 += weight;    Vector weightedX = x.times(weight);    if (s1 == null) {        s1 = weightedX;    } else {        s1.assign(weightedX, Functions.PLUS);    }    Vector x2 = x.times(x).times(weight);    if (s2 == null) {        s2 = x2;    } else {        s2.assign(x2, Functions.PLUS);    }}
public void mahout_f2967_0()
{    if (s0 != 0.0) {        mean = s1.divide(s0);        std = s2.times(s0).minus(s1.times(s1)).assign(new SquareRootFunction()).divide(s0);    }}
public static void mahout_f2968_0(Path input, Path output, int rows, int cols) throws IOException, InterruptedException, ClassNotFoundException
{    Configuration conf = new Configuration();    HadoopUtil.delete(conf, output);    conf.setInt(Keys.AFFINITY_DIMENSIONS, rows);    Job job = new Job(conf, "AffinityMatrixInputJob: " + input + " -> M/R -> " + output);    job.setMapOutputKeyClass(IntWritable.class);    job.setMapOutputValueClass(DistributedRowMatrix.MatrixEntryWritable.class);    job.setOutputKeyClass(IntWritable.class);    job.setOutputValueClass(VectorWritable.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    job.setMapperClass(AffinityMatrixInputMapper.class);    job.setReducerClass(AffinityMatrixInputReducer.class);    FileInputFormat.addInputPath(job, input);    FileOutputFormat.setOutputPath(job, output);    job.setJarByClass(AffinityMatrixInputJob.class);    boolean succeeded = job.waitForCompletion(true);    if (!succeeded) {        throw new IllegalStateException("Job failed!");    }}
public static DistributedRowMatrix mahout_f2969_0(Path input, Path output, int dimensions) throws IOException, InterruptedException, ClassNotFoundException
{    Path seqFiles = new Path(output, "seqfiles-" + (System.nanoTime() & 0xFF));    runJob(input, seqFiles, dimensions, dimensions);    DistributedRowMatrix a = new DistributedRowMatrix(seqFiles, new Path(seqFiles, "seqtmp-" + (System.nanoTime() & 0xFF)), dimensions, dimensions);    a.setConf(new Configuration());    return a;}
protected void mahout_f2970_1(LongWritable key, Text value, Context context) throws IOException, InterruptedException
{    String[] elements = COMMA_PATTERN.split(value.toString());            if (elements.length != 3) {        throw new IOException("Expected input of length 3, received " + elements.length + ". Please make sure you adhere to " + "the structure of (i,j,value) for representing a graph in text. " + "Input line was: '" + value + "'.");    }    if (elements[0].isEmpty() || elements[1].isEmpty() || elements[2].isEmpty()) {        throw new IOException("Found an element of 0 length. Please be sure you adhere to the structure of " + "(i,j,value) for  representing a graph in text.");    }                DistributedRowMatrix.MatrixEntryWritable toAdd = new DistributedRowMatrix.MatrixEntryWritable();    IntWritable row = new IntWritable(Integer.valueOf(elements[0]));        toAdd.setRow(-1);    toAdd.setCol(Integer.valueOf(elements[1]));    toAdd.setVal(Double.valueOf(elements[2]));    context.write(row, toAdd);}
protected void mahout_f2971_1(IntWritable row, Iterable<DistributedRowMatrix.MatrixEntryWritable> values, Context context) throws IOException, InterruptedException
{    int size = context.getConfiguration().getInt(Keys.AFFINITY_DIMENSIONS, Integer.MAX_VALUE);    RandomAccessSparseVector out = new RandomAccessSparseVector(size, 100);    for (DistributedRowMatrix.MatrixEntryWritable element : values) {        out.setQuick(element.getCol(), element.getVal());        if (log.isDebugEnabled()) {                    }    }    SequentialAccessSparseVector output = new SequentialAccessSparseVector(out);    context.write(row, new VectorWritable(output));}
public void mahout_f2972_0(int k)
{    this.key = k;}
public void mahout_f2973_0(double v)
{    this.value = v;}
public void mahout_f2974_0(DataInput in) throws IOException
{    this.key = in.readInt();    this.value = in.readDouble();}
public void mahout_f2975_0(DataOutput out) throws IOException
{    out.writeInt(key);    out.writeDouble(value);}
public int mahout_f2976_0()
{    return key;}
public double mahout_f2977_0()
{    return value;}
public static Path mahout_f2978_1(Configuration conf, Path input, Path output, int k, DistanceMeasure measure) throws IOException
{        FileSystem fs = FileSystem.get(output.toUri(), conf);    HadoopUtil.delete(conf, output);    Path outFile = new Path(output, "part-eigenSeed");    boolean newFile = fs.createNewFile(outFile);    if (newFile) {        Path inputPathPattern;        if (fs.getFileStatus(input).isDir()) {            inputPathPattern = new Path(input, "*");        } else {            inputPathPattern = input;        }        FileStatus[] inputFiles = fs.globStatus(inputPathPattern, PathFilters.logsCRCFilter());                Map<Integer, Double> maxEigens = new HashMap<>(k);                                                Map<Integer, Text> chosenTexts = new HashMap<>(k);        Map<Integer, ClusterWritable> chosenClusters = new HashMap<>(k);        for (FileStatus fileStatus : inputFiles) {            if (!fileStatus.isDir()) {                for (Pair<Writable, VectorWritable> record : new SequenceFileIterable<Writable, VectorWritable>(fileStatus.getPath(), true, conf)) {                    Writable key = record.getFirst();                    VectorWritable value = record.getSecond();                    for (Vector.Element e : value.get().nonZeroes()) {                        int index = e.index();                        double v = Math.abs(e.get());                        if (!maxEigens.containsKey(index) || v > maxEigens.get(index)) {                            maxEigens.put(index, v);                            Text newText = new Text(key.toString());                            chosenTexts.put(index, newText);                            Kluster newCluster = new Kluster(value.get(), index, measure);                            newCluster.observe(value.get(), 1);                            ClusterWritable clusterWritable = new ClusterWritable();                            clusterWritable.setValue(newCluster);                            chosenClusters.put(index, clusterWritable);                        }                    }                }            }        }        try (SequenceFile.Writer writer = SequenceFile.createWriter(fs, conf, outFile, Text.class, ClusterWritable.class)) {            for (Integer key : maxEigens.keySet()) {                writer.append(chosenTexts.get(key), chosenClusters.get(key));            }                    }    }    return outFile;}
public static void mahout_f2979_0(String[] args) throws Exception
{    ToolRunner.run(new SpectralKMeansDriver(), args);}
public int mahout_f2980_0(String[] arg0) throws Exception
{    Configuration conf = getConf();    addInputOption();    addOutputOption();    addOption("dimensions", "d", "Square dimensions of affinity matrix", true);    addOption("clusters", "k", "Number of clusters and top eigenvectors", true);    addOption(DefaultOptionCreator.distanceMeasureOption().create());    addOption(DefaultOptionCreator.convergenceOption().create());    addOption(DefaultOptionCreator.maxIterationsOption().create());    addOption(DefaultOptionCreator.overwriteOption().create());    addFlag("usessvd", "ssvd", "Uses SSVD as the eigensolver. Default is the Lanczos solver.");    addOption("reduceTasks", "t", "Number of reducers for SSVD", String.valueOf(REDUCERS));    addOption("outerProdBlockHeight", "oh", "Block height of outer products for SSVD", String.valueOf(BLOCKHEIGHT));    addOption("oversampling", "p", "Oversampling parameter for SSVD", String.valueOf(OVERSAMPLING));    addOption("powerIter", "q", "Additional power iterations for SSVD", String.valueOf(POWERITERS));    Map<String, List<String>> parsedArgs = parseArguments(arg0);    if (parsedArgs == null) {        return 0;    }    Path input = getInputPath();    Path output = getOutputPath();    if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {        HadoopUtil.delete(conf, getTempPath());        HadoopUtil.delete(conf, getOutputPath());    }    int numDims = Integer.parseInt(getOption("dimensions"));    int clusters = Integer.parseInt(getOption("clusters"));    String measureClass = getOption(DefaultOptionCreator.DISTANCE_MEASURE_OPTION);    DistanceMeasure measure = ClassUtils.instantiateAs(measureClass, DistanceMeasure.class);    double convergenceDelta = Double.parseDouble(getOption(DefaultOptionCreator.CONVERGENCE_DELTA_OPTION));    int maxIterations = Integer.parseInt(getOption(DefaultOptionCreator.MAX_ITERATIONS_OPTION));    Path tempdir = new Path(getOption("tempDir"));    int reducers = Integer.parseInt(getOption("reduceTasks"));    int blockheight = Integer.parseInt(getOption("outerProdBlockHeight"));    int oversampling = Integer.parseInt(getOption("oversampling"));    int poweriters = Integer.parseInt(getOption("powerIter"));    run(conf, input, output, numDims, clusters, measure, convergenceDelta, maxIterations, tempdir, reducers, blockheight, oversampling, poweriters);    return 0;}
public static void mahout_f2981_0(Configuration conf, Path input, Path output, int numDims, int clusters, DistanceMeasure measure, double convergenceDelta, int maxIterations, Path tempDir) throws IOException, InterruptedException, ClassNotFoundException
{    run(conf, input, output, numDims, clusters, measure, convergenceDelta, maxIterations, tempDir, REDUCERS, BLOCKHEIGHT, OVERSAMPLING, POWERITERS);}
public static void mahout_f2982_1(Configuration conf, Path input, Path output, int numDims, int clusters, DistanceMeasure measure, double convergenceDelta, int maxIterations, Path tempDir, int numReducers, int blockHeight, int oversampling, int poweriters) throws IOException, InterruptedException, ClassNotFoundException
{    HadoopUtil.delete(conf, tempDir);    Path outputCalc = new Path(tempDir, "calculations");    Path outputTmp = new Path(tempDir, "temporary");                Path affSeqFiles = new Path(outputCalc, "seqfile");    AffinityMatrixInputJob.runJob(input, affSeqFiles, numDims, numDims);        DistributedRowMatrix A = new DistributedRowMatrix(affSeqFiles, new Path(outputTmp, "afftmp"), numDims, numDims);    Configuration depConf = new Configuration(conf);    A.setConf(depConf);        Vector D = MatrixDiagonalizeJob.runJob(affSeqFiles, numDims);        DistributedRowMatrix L = VectorMatrixMultiplicationJob.runJob(affSeqFiles, D, new Path(outputCalc, "laplacian"), new Path(outputCalc, outputCalc));    L.setConf(depConf);    Path data;        Path[] LPath = new Path[1];    LPath[0] = L.getRowPath();    Path SSVDout = new Path(outputCalc, "SSVD");    SSVDSolver solveIt = new SSVDSolver(depConf, LPath, SSVDout, blockHeight, clusters, oversampling, numReducers);    solveIt.setComputeV(false);    solveIt.setComputeU(true);    solveIt.setOverwrite(true);    solveIt.setQ(poweriters);        solveIt.run();    data = new Path(solveIt.getUPath());            Path unitVectors = new Path(outputCalc, "unitvectors");    UnitVectorizerJob.runJob(data, unitVectors);    DistributedRowMatrix Wt = new DistributedRowMatrix(unitVectors, new Path(unitVectors, "tmp"), clusters, numDims);    Wt.setConf(depConf);    data = Wt.getRowPath();            Path initialclusters = EigenSeedGenerator.buildFromEigens(conf, data, new Path(output, Cluster.INITIAL_CLUSTERS_DIR), clusters, measure);        Path answer = new Path(output, "kmeans_out");    KMeansDriver.run(conf, data, initialclusters, answer, convergenceDelta, maxIterations, true, 0.0, false);        Path mappingPath = new Path(new Path(conf.get("hadoop.tmp.dir")), "generic_input_mapping");    List<String> mapping = new ArrayList<>();    FileSystem fs = FileSystem.get(mappingPath.toUri(), conf);    if (fs.exists(mappingPath)) {        SequenceFile.Reader reader = new SequenceFile.Reader(fs, mappingPath, conf);        Text mappingValue = new Text();        IntWritable mappingIndex = new IntWritable();        while (reader.next(mappingIndex, mappingValue)) {            String s = mappingValue.toString();            mapping.add(s);        }        HadoopUtil.delete(conf, mappingPath);    } else {            }    Path clusteredPointsPath = new Path(answer, "clusteredPoints");    Path inputPath = new Path(clusteredPointsPath, "part-m-00000");    int id = 0;    for (Pair<IntWritable, WeightedVectorWritable> record : new SequenceFileIterable<IntWritable, WeightedVectorWritable>(inputPath, conf)) {        if (!mapping.isEmpty()) {                    } else {                    }    }}
public static Vector mahout_f2983_0(Path affInput, int dimensions) throws IOException, ClassNotFoundException, InterruptedException
{        Configuration conf = new Configuration();    Path diagOutput = new Path(affInput.getParent(), "diagonal");    HadoopUtil.delete(conf, diagOutput);    conf.setInt(Keys.AFFINITY_DIMENSIONS, dimensions);    Job job = new Job(conf, "MatrixDiagonalizeJob");    job.setInputFormatClass(SequenceFileInputFormat.class);    job.setMapOutputKeyClass(NullWritable.class);    job.setMapOutputValueClass(IntDoublePairWritable.class);    job.setOutputKeyClass(NullWritable.class);    job.setOutputValueClass(VectorWritable.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    job.setMapperClass(MatrixDiagonalizeMapper.class);    job.setReducerClass(MatrixDiagonalizeReducer.class);    FileInputFormat.addInputPath(job, affInput);    FileOutputFormat.setOutputPath(job, diagOutput);    job.setJarByClass(MatrixDiagonalizeJob.class);    boolean succeeded = job.waitForCompletion(true);    if (!succeeded) {        throw new IllegalStateException("Job failed!");    }        return VectorCache.load(conf, new Path(diagOutput, "part-r-00000"));}
protected void mahout_f2984_0(IntWritable key, VectorWritable row, Context context) throws IOException, InterruptedException
{        IntDoublePairWritable store = new IntDoublePairWritable(key.get(), row.get().zSum());    context.write(NullWritable.get(), store);}
protected void mahout_f2985_0(NullWritable key, Iterable<IntDoublePairWritable> values, Context context) throws IOException, InterruptedException
{        Vector retval = new DenseVector(context.getConfiguration().getInt(Keys.AFFINITY_DIMENSIONS, Integer.MAX_VALUE));        for (IntDoublePairWritable e : values) {        retval.setQuick(e.getKey(), e.getValue());    }        context.write(key, new VectorWritable(retval));}
public static void mahout_f2986_0(Path input, Path output) throws IOException, InterruptedException, ClassNotFoundException
{    Configuration conf = new Configuration();    Job job = new Job(conf, "UnitVectorizerJob");    job.setInputFormatClass(SequenceFileInputFormat.class);    job.setOutputKeyClass(IntWritable.class);    job.setOutputValueClass(VectorWritable.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    job.setMapperClass(UnitVectorizerMapper.class);    job.setNumReduceTasks(0);    FileInputFormat.addInputPath(job, input);    FileOutputFormat.setOutputPath(job, output);    job.setJarByClass(UnitVectorizerJob.class);    boolean succeeded = job.waitForCompletion(true);    if (!succeeded) {        throw new IllegalStateException("Job failed!");    }}
protected void mahout_f2987_0(IntWritable row, VectorWritable vector, Context context) throws IOException, InterruptedException
{    context.write(row, new VectorWritable(vector.get().normalize(2)));}
public static void mahout_f2988_0(Writable key, Vector vector, Path output, Configuration conf, boolean overwritePath, boolean deleteOnExit) throws IOException
{    FileSystem fs = FileSystem.get(output.toUri(), conf);    output = fs.makeQualified(output);    if (overwritePath) {        HadoopUtil.delete(conf, output);    }        DistributedCache.setCacheFiles(new URI[] { output.toUri() }, conf);        try (SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, output, IntWritable.class, VectorWritable.class)) {        writer.append(key, new VectorWritable(vector));    }    if (deleteOnExit) {        fs.deleteOnExit(output);    }}
public static void mahout_f2989_0(Writable key, Vector vector, Path output, Configuration conf) throws IOException
{    save(key, vector, output, conf, true, true);}
public static Vector mahout_f2990_1(Configuration conf) throws IOException
{    Path[] files = HadoopUtil.getCachedFiles(conf);    if (files.length != 1) {        throw new IOException("Cannot read Frequency list from Distributed Cache (" + files.length + ')');    }    if (log.isInfoEnabled()) {            }    return load(conf, files[0]);}
public static Vector mahout_f2991_1(Configuration conf, Path input) throws IOException
{        try (SequenceFileValueIterator<VectorWritable> iterator = new SequenceFileValueIterator<>(input, true, conf)) {        return iterator.next().get();    }}
public static DistributedRowMatrix mahout_f2992_0(Path markovPath, Vector diag, Path outputPath) throws IOException, ClassNotFoundException, InterruptedException
{    return runJob(markovPath, diag, outputPath, new Path(outputPath, "tmp"));}
public static DistributedRowMatrix mahout_f2993_0(Path markovPath, Vector diag, Path outputPath, Path tmpPath) throws IOException, ClassNotFoundException, InterruptedException
{        Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(markovPath.toUri(), conf);    markovPath = fs.makeQualified(markovPath);    outputPath = fs.makeQualified(outputPath);    Path vectorOutputPath = new Path(outputPath.getParent(), "vector");    VectorCache.save(new IntWritable(Keys.DIAGONAL_CACHE_INDEX), diag, vectorOutputPath, conf);        Job job = new Job(conf, "VectorMatrixMultiplication");    job.setInputFormatClass(SequenceFileInputFormat.class);    job.setOutputKeyClass(IntWritable.class);    job.setOutputValueClass(VectorWritable.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    job.setMapperClass(VectorMatrixMultiplicationMapper.class);    job.setNumReduceTasks(0);    FileInputFormat.addInputPath(job, markovPath);    FileOutputFormat.setOutputPath(job, outputPath);    job.setJarByClass(VectorMatrixMultiplicationJob.class);    boolean succeeded = job.waitForCompletion(true);    if (!succeeded) {        throw new IllegalStateException("Job failed!");    }        return new DistributedRowMatrix(outputPath, tmpPath, diag.size(), diag.size());}
protected void mahout_f2994_0(Context context) throws IOException, InterruptedException
{        super.setup(context);    Configuration config = context.getConfiguration();    diagonal = VectorCache.load(config);    if (diagonal == null) {        throw new IOException("No vector loaded from cache!");    }    if (!(diagonal instanceof DenseVector)) {        diagonal = new DenseVector(diagonal);    }}
protected void mahout_f2995_0(IntWritable key, VectorWritable row, Context ctx) throws IOException, InterruptedException
{    for (Vector.Element e : row.get().all()) {        double dii = Functions.SQRT.apply(diagonal.get(key.get()));        double djj = Functions.SQRT.apply(diagonal.get(e.index()));        double mij = e.get();        e.set(dii * mij * djj);    }    ctx.write(key, row);}
 void mahout_f2996_0(Vector diag)
{    this.diagonal = diag;}
public int mahout_f2997_0()
{    return i;}
public void mahout_f2998_0(int i)
{    this.i = i;}
public int mahout_f2999_0()
{    return j;}
public void mahout_f3000_0(int j)
{    this.j = j;}
public double mahout_f3001_0()
{    return value;}
public void mahout_f3002_0(double v)
{    this.value = v;}
public String mahout_f3003_0()
{    return type;}
public void mahout_f3004_0(String t)
{    this.type = t;}
public void mahout_f3005_0(DataInput arg0) throws IOException
{    this.i = arg0.readInt();    this.j = arg0.readInt();    this.value = arg0.readDouble();    this.type = arg0.readUTF();}
public void mahout_f3006_0(DataOutput arg0) throws IOException
{    arg0.writeInt(i);    arg0.writeInt(j);    arg0.writeDouble(value);    arg0.writeUTF(type);}
public Pair<List<? extends WeightedVector>, List<? extends WeightedVector>> mahout_f3007_0(List<? extends WeightedVector> datapoints)
{        if (testProbability == 0) {        return new Pair<List<? extends WeightedVector>, List<? extends WeightedVector>>(datapoints, new ArrayList<WeightedVector>());    }    int numTest = (int) (testProbability * datapoints.size());    Preconditions.checkArgument(numTest > 0 && numTest < datapoints.size(), "Must have nonzero number of training and test vectors. Asked for %.1f %% of %d vectors for test", testProbability * 100, datapoints.size());    Collections.shuffle(datapoints);    return new Pair<List<? extends WeightedVector>, List<? extends WeightedVector>>(datapoints.subList(numTest, datapoints.size()), datapoints.subList(0, numTest));}
public UpdatableSearcher mahout_f3008_0(List<? extends WeightedVector> datapoints)
{    Pair<List<? extends WeightedVector>, List<? extends WeightedVector>> trainTestSplit = splitTrainTest(datapoints);    List<Vector> bestCentroids = new ArrayList<>();    double cost = Double.POSITIVE_INFINITY;    double bestCost = Double.POSITIVE_INFINITY;    for (int i = 0; i < numRuns; ++i) {        centroids.clear();        if (kMeansPlusPlusInit) {                        initializeSeedsKMeansPlusPlus(trainTestSplit.getFirst());        } else {                        initializeSeedsRandomly(trainTestSplit.getFirst());        }                if (numRuns > 1) {                        iterativeAssignment(trainTestSplit.getFirst());                        cost = ClusteringUtils.totalClusterCost(splitTrainTest ? datapoints : trainTestSplit.getSecond(), centroids);            if (cost < bestCost) {                bestCost = cost;                bestCentroids.clear();                Iterables.addAll(bestCentroids, centroids);            }        } else {                        iterativeAssignment(datapoints);            return centroids;        }    }    if (bestCost == Double.POSITIVE_INFINITY) {        throw new RuntimeException("No valid clustering was found");    }    if (cost != bestCost) {        centroids.clear();        centroids.addAll(bestCentroids);    }    if (correctWeights) {        for (WeightedVector testDatapoint : trainTestSplit.getSecond()) {            WeightedVector closest = (WeightedVector) centroids.searchFirst(testDatapoint, false).getValue();            closest.setWeight(closest.getWeight() + testDatapoint.getWeight());        }    }    return centroids;}
private void mahout_f3009_0(List<? extends WeightedVector> datapoints)
{    int numDatapoints = datapoints.size();    double totalWeight = 0;    for (WeightedVector datapoint : datapoints) {        totalWeight += datapoint.getWeight();    }    Multinomial<Integer> seedSelector = new Multinomial<>();    for (int i = 0; i < numDatapoints; ++i) {        seedSelector.add(i, datapoints.get(i).getWeight() / totalWeight);    }    for (int i = 0; i < numClusters; ++i) {        int sample = seedSelector.sample();        seedSelector.delete(sample);        Centroid centroid = new Centroid(datapoints.get(sample));        centroid.setIndex(i);        centroids.add(centroid);    }}
private void mahout_f3010_0(List<? extends WeightedVector> datapoints)
{    Preconditions.checkArgument(datapoints.size() > 1, "Must have at least two datapoints points to cluster " + "sensibly");    Preconditions.checkArgument(datapoints.size() >= numClusters, String.format("Must have more datapoints [%d] than clusters [%d]", datapoints.size(), numClusters));        Centroid center = new Centroid(datapoints.iterator().next());    for (WeightedVector row : Iterables.skip(datapoints, 1)) {        center.update(row);    }            double deltaX = 0;    DistanceMeasure distanceMeasure = centroids.getDistanceMeasure();    for (WeightedVector row : datapoints) {        deltaX += distanceMeasure.distance(row, center);    }                                                                    Multinomial<Integer> seedSelector = new Multinomial<>();    for (int i = 0; i < datapoints.size(); ++i) {        double selectionProbability = deltaX + datapoints.size() * distanceMeasure.distance(datapoints.get(i), center);        seedSelector.add(i, selectionProbability);    }    int selected = random.nextInt(datapoints.size());    Centroid c_1 = new Centroid(datapoints.get(selected).clone());    c_1.setIndex(0);        for (int i = 0; i < datapoints.size(); ++i) {        WeightedVector row = datapoints.get(i);        double w = distanceMeasure.distance(c_1, row) * 2 * Math.log(1 + row.getWeight());        seedSelector.set(i, w);    }                            centroids.add(c_1);    int clusterIndex = 1;    while (centroids.size() < numClusters) {                int seedIndex = seedSelector.sample();        Centroid nextSeed = new Centroid(datapoints.get(seedIndex));        nextSeed.setIndex(clusterIndex++);        centroids.add(nextSeed);                seedSelector.delete(seedIndex);                for (int currSeedIndex : seedSelector) {            WeightedVector curr = datapoints.get(currSeedIndex);            double newWeight = nextSeed.getWeight() * distanceMeasure.distance(nextSeed, curr);            if (newWeight < seedSelector.getWeight(currSeedIndex)) {                seedSelector.set(currSeedIndex, newWeight);            }        }    }}
private void mahout_f3011_0(List<? extends WeightedVector> datapoints)
{    DistanceMeasure distanceMeasure = centroids.getDistanceMeasure();            List<Double> closestClusterDistances = new ArrayList<>(numClusters);                List<Integer> clusterAssignments = new ArrayList<>(Collections.nCopies(datapoints.size(), -1));    boolean changed = true;    for (int i = 0; changed && i < maxNumIterations; i++) {        changed = false;                                closestClusterDistances.clear();        for (Vector center : centroids) {                        Vector closestOtherCluster = centroids.searchFirst(center, true).getValue();            closestClusterDistances.add(distanceMeasure.distance(center, closestOtherCluster));        }                        List<Centroid> newCentroids = new ArrayList<>();        for (Vector centroid : centroids) {                        Centroid newCentroid = (Centroid) centroid.clone();            newCentroid.setWeight(0);            newCentroids.add(newCentroid);        }                for (int j = 0; j < datapoints.size(); ++j) {            WeightedVector datapoint = datapoints.get(j);                        WeightedThing<Vector> closestPair = centroids.searchFirst(datapoint, false);            int closestIndex = ((WeightedVector) closestPair.getValue()).getIndex();            double closestDistance = closestPair.getWeight();                        if (closestIndex != clusterAssignments.get(j)) {                changed = true;                clusterAssignments.set(j, closestIndex);            }                        if (closestDistance < trimFraction * closestClusterDistances.get(closestIndex)) {                newCentroids.get(closestIndex).update(datapoint);            }        }                centroids.clear();        centroids.addAll(newCentroids);    }    if (correctWeights) {        for (Vector v : centroids) {            ((Centroid) v).setWeight(0);        }        for (WeightedVector datapoint : datapoints) {            Centroid closestCentroid = (Centroid) centroids.searchFirst(datapoint, false).getValue();            closestCentroid.setWeight(closestCentroid.getWeight() + datapoint.getWeight());        }    }}
public Iterator<Centroid> mahout_f3012_0()
{    return Iterators.transform(centroids.iterator(), new Function<Vector, Centroid>() {        @Override        public Centroid apply(Vector input) {            Preconditions.checkArgument(input instanceof Centroid, "Non-centroid in centroids " + "searcher");                        return (Centroid) input;        }    });}
public Centroid mahout_f3013_0(Vector input)
{    Preconditions.checkArgument(input instanceof Centroid, "Non-centroid in centroids " + "searcher");        return (Centroid) input;}
public Iterator<Centroid> mahout_f3014_0()
{    return Iterators.transform(centroids.iterator(), new Function<Vector, Centroid>() {        @Override        public Centroid apply(Vector input) {            return (Centroid) input;        }    });}
public Centroid mahout_f3015_0(Vector input)
{    return (Centroid) input;}
public UpdatableSearcher mahout_f3016_0(Matrix data)
{    return cluster(Iterables.transform(data, new Function<MatrixSlice, Centroid>() {        @Override        public Centroid apply(MatrixSlice input) {                        return Centroid.create(input.index(), input.vector());        }    }));}
public Centroid mahout_f3017_0(MatrixSlice input)
{        return Centroid.create(input.index(), input.vector());}
public UpdatableSearcher mahout_f3018_0(Iterable<Centroid> datapoints)
{    return clusterInternal(datapoints, false);}
public UpdatableSearcher mahout_f3019_0(final Centroid datapoint)
{    return cluster(new Iterable<Centroid>() {        @Override        public Iterator<Centroid> iterator() {            return new Iterator<Centroid>() {                private boolean accessed = false;                @Override                public boolean hasNext() {                    return !accessed;                }                @Override                public Centroid next() {                    accessed = true;                    return datapoint;                }                @Override                public void remove() {                    throw new UnsupportedOperationException();                }            };        }    });}
public Iterator<Centroid> mahout_f3020_0()
{    return new Iterator<Centroid>() {        private boolean accessed = false;        @Override        public boolean hasNext() {            return !accessed;        }        @Override        public Centroid next() {            accessed = true;            return datapoint;        }        @Override        public void remove() {            throw new UnsupportedOperationException();        }    };}
public boolean mahout_f3021_0()
{    return !accessed;}
public Centroid mahout_f3022_0()
{    accessed = true;    return datapoint;}
public void mahout_f3023_0()
{    throw new UnsupportedOperationException();}
public int mahout_f3024_0()
{    return centroids.size();}
private UpdatableSearcher mahout_f3025_0(Iterable<Centroid> datapoints, boolean collapseClusters)
{    Iterator<Centroid> datapointsIterator = datapoints.iterator();    if (!datapointsIterator.hasNext()) {        return centroids;    }    int oldNumProcessedDataPoints = numProcessedDatapoints;        if (collapseClusters) {        centroids.clear();        numProcessedDatapoints = 0;    }    if (centroids.size() == 0) {                                centroids.add(datapointsIterator.next().clone());        ++numProcessedDatapoints;    }        while (datapointsIterator.hasNext()) {        Centroid row = datapointsIterator.next();                                WeightedThing<Vector> closestPair = centroids.searchFirst(row, false);                                                                double sample = random.nextDouble();        if (sample < row.getWeight() * closestPair.getWeight() / distanceCutoff) {                        centroids.add(row.clone());        } else {                                                            Centroid centroid = (Centroid) closestPair.getValue();                        if (!centroids.remove(centroid, Constants.EPSILON)) {                throw new RuntimeException("Unable to remove centroid");            }            centroid.update(row);            centroids.add(centroid);        }        ++numProcessedDatapoints;        if (!collapseClusters && centroids.size() > clusterOvershoot * numClusters) {            numClusters = (int) Math.max(numClusters, clusterLogFactor * Math.log(numProcessedDatapoints));            List<Centroid> shuffled = new ArrayList<>();            for (Vector vector : centroids) {                shuffled.add((Centroid) vector);            }            Collections.shuffle(shuffled);                                    clusterInternal(shuffled, true);            if (centroids.size() > numClusters) {                distanceCutoff *= beta;            }        }    }    if (collapseClusters) {        numProcessedDatapoints = oldNumProcessedDataPoints;    }    return centroids;}
public void mahout_f3026_0()
{    int numCentroids = 0;    for (Centroid centroid : this) {        centroid.setIndex(numCentroids++);    }}
public double mahout_f3027_0()
{    return distanceCutoff;}
public void mahout_f3028_0(double distanceCutoff)
{    this.distanceCutoff = distanceCutoff;}
public DistanceMeasure mahout_f3029_0()
{    return centroids.getDistanceMeasure();}
public Centroid mahout_f3030_0()
{    return centroid;}
public void mahout_f3031_0(DataOutput dataOutput) throws IOException
{    dataOutput.writeInt(centroid.getIndex());    dataOutput.writeDouble(centroid.getWeight());    VectorWritable.writeVector(dataOutput, centroid.getVector());}
public void mahout_f3032_0(DataInput dataInput) throws IOException
{    if (centroid == null) {        centroid = read(dataInput);        return;    }    centroid.setIndex(dataInput.readInt());    centroid.setWeight(dataInput.readDouble());    centroid.assign(VectorWritable.readVector(dataInput));}
public static Centroid mahout_f3033_0(DataInput dataInput) throws IOException
{    int index = dataInput.readInt();    double weight = dataInput.readDouble();    Vector v = VectorWritable.readVector(dataInput);    return new Centroid(index, v, weight);}
public boolean mahout_f3034_0(Object o)
{    if (this == o) {        return true;    }    if (!(o instanceof CentroidWritable)) {        return false;    }    CentroidWritable writable = (CentroidWritable) o;    return centroid.equals(writable.centroid);}
public int mahout_f3035_0()
{    return centroid.hashCode();}
public String mahout_f3036_0()
{    return centroid.toString();}
public int mahout_f3037_0(String[] args) throws Exception
{        addInputOption();    addOutputOption();    addOption(DefaultOptionCreator.overwriteOption().create());        addOption(DefaultOptionCreator.numClustersOption().withDescription("The k in k-Means. Approximately this many clusters will be generated.").create());                    addOption(ESTIMATED_NUM_MAP_CLUSTERS, "km", "The estimated number of clusters to use for the " + "Map phase of the job when running StreamingKMeans. This should be around k * log(n), " + "where k is the final number of clusters and n is the total number of data points to " + "cluster.", String.valueOf(1));    addOption(ESTIMATED_DISTANCE_CUTOFF, "e", "The initial estimated distance cutoff between two " + "points for forming new clusters. If no value is given, it's estimated from the data set", String.valueOf(INVALID_DISTANCE_CUTOFF));        addOption(MAX_NUM_ITERATIONS, "mi", "The maximum number of iterations to run for the " + "BallKMeans algorithm used by the reducer. If no value is given, defaults to 10.", String.valueOf(10));    addOption(TRIM_FRACTION, "tf", "The 'ball' aspect of ball k-means means that only the closest points " + "to the centroid will actually be used for updating. The fraction of the points to be used is those " + "points whose distance to the center is within trimFraction * distance to the closest other center. " + "If no value is given, defaults to 0.9.", String.valueOf(0.9));    addFlag(RANDOM_INIT, "ri", "Whether to use k-means++ initialization or random initialization " + "of the seed centroids. Essentially, k-means++ provides better clusters, but takes longer, whereas random " + "initialization takes less time, but produces worse clusters, and tends to fail more often and needs " + "multiple runs to compare to k-means++. If set, uses the random initialization.");    addFlag(IGNORE_WEIGHTS, "iw", "Whether to correct the weights of the centroids after the clustering is done. " + "The weights end up being wrong because of the trimFraction and possible train/test splits. In some cases, " + "especially in a pipeline, having an accurate count of the weights is useful. If set, ignores the final " + "weights");    addOption(TEST_PROBABILITY, "testp", "A double value between 0 and 1 that represents the percentage of " + "points to be used for 'testing' different clustering runs in the final BallKMeans " + "step. If no value is given, defaults to 0.1", String.valueOf(0.1));    addOption(NUM_BALLKMEANS_RUNS, "nbkm", "Number of BallKMeans runs to use at the end to try to cluster the " + "points. If no value is given, defaults to 4", String.valueOf(4));                        addOption(DefaultOptionCreator.distanceMeasureOption().create());            addOption(SEARCHER_CLASS_OPTION, "sc", "The type of searcher to be used when performing nearest " + "neighbor searches. Defaults to ProjectionSearch.", ProjectionSearch.class.getCanonicalName());        addOption(NUM_PROJECTIONS_OPTION, "np", "The number of projections considered in estimating the " + "distances between vectors. Only used when the distance measure requested is either " + "ProjectionSearch or FastProjectionSearch. If no value is given, defaults to 3.", String.valueOf(3));    addOption(SEARCH_SIZE_OPTION, "s", "In more efficient searches (non BruteSearch), " + "not all distances are calculated for determining the nearest neighbors. The number of " + "elements whose distances from the query vector is actually computer is proportional to " + "searchSize. If no value is given, defaults to 1.", String.valueOf(2));    addFlag(REDUCE_STREAMING_KMEANS, "rskm", "There might be too many intermediate clusters from the mapper " + "to fit into memory, so the reducer can run another pass of StreamingKMeans to collapse them down to a " + "fewer clusters");    addOption(DefaultOptionCreator.methodOption().create());    if (parseArguments(args) == null) {        return -1;    }    Path output = getOutputPath();    if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {        HadoopUtil.delete(getConf(), output);    }    configureOptionsForWorkers();    run(getConf(), getInputPath(), output);    return 0;}
private void mahout_f3038_1() throws ClassNotFoundException
{        String method = getOption(DefaultOptionCreator.METHOD_OPTION);    int numClusters = Integer.parseInt(getOption(DefaultOptionCreator.NUM_CLUSTERS_OPTION));        int estimatedNumMapClusters = Integer.parseInt(getOption(ESTIMATED_NUM_MAP_CLUSTERS));    float estimatedDistanceCutoff = Float.parseFloat(getOption(ESTIMATED_DISTANCE_CUTOFF));        int maxNumIterations = Integer.parseInt(getOption(MAX_NUM_ITERATIONS));    float trimFraction = Float.parseFloat(getOption(TRIM_FRACTION));    boolean randomInit = hasOption(RANDOM_INIT);    boolean ignoreWeights = hasOption(IGNORE_WEIGHTS);    float testProbability = Float.parseFloat(getOption(TEST_PROBABILITY));    int numBallKMeansRuns = Integer.parseInt(getOption(NUM_BALLKMEANS_RUNS));        String measureClass = getOption(DefaultOptionCreator.DISTANCE_MEASURE_OPTION);    String searcherClass = getOption(SEARCHER_CLASS_OPTION);                    boolean getSearchSize = false;    boolean getNumProjections = false;    if (!searcherClass.equals(BruteSearch.class.getName())) {        getSearchSize = true;        getNumProjections = true;    }        int searchSize = 0;    if (getSearchSize) {        searchSize = Integer.parseInt(getOption(SEARCH_SIZE_OPTION));    }                int numProjections = 0;    if (getNumProjections) {        numProjections = Integer.parseInt(getOption(NUM_PROJECTIONS_OPTION));    }    boolean reduceStreamingKMeans = hasOption(REDUCE_STREAMING_KMEANS);    configureOptionsForWorkers(getConf(), numClusters, /* StreamingKMeans */    estimatedNumMapClusters, estimatedDistanceCutoff, /* BallKMeans */    maxNumIterations, trimFraction, randomInit, ignoreWeights, testProbability, numBallKMeansRuns, /* Searcher */    measureClass, searcherClass, searchSize, numProjections, method, reduceStreamingKMeans);}
private static int mahout_f3041_1(Configuration conf, Path input, Path output) throws IOException, ExecutionException, InterruptedException
{    long start = System.currentTimeMillis();        ExecutorService pool = Executors.newCachedThreadPool();    List<Future<Iterable<Centroid>>> intermediateCentroidFutures = new ArrayList<>();    for (FileStatus status : HadoopUtil.listStatus(FileSystem.get(conf), input, PathFilters.logsCRCFilter())) {        intermediateCentroidFutures.add(pool.submit(new StreamingKMeansThread(status.getPath(), conf)));    }            List<Centroid> intermediateCentroids = new ArrayList<>();    for (Future<Iterable<Centroid>> futureIterable : intermediateCentroidFutures) {        for (Centroid centroid : futureIterable.get()) {            intermediateCentroids.add(centroid);        }    }    pool.shutdown();    pool.awaitTermination(Long.MAX_VALUE, TimeUnit.SECONDS);        SequenceFile.Writer writer = SequenceFile.createWriter(FileSystem.get(conf), conf, new Path(output, "part-r-00000"), IntWritable.class, CentroidWritable.class);    int numCentroids = 0;        for (Vector finalVector : StreamingKMeansReducer.getBestCentroids(intermediateCentroids, conf)) {        Centroid finalCentroid = (Centroid) finalVector;        writer.append(new IntWritable(numCentroids++), new CentroidWritable(finalCentroid));    }    writer.close();    long end = System.currentTimeMillis();        return 0;}
public static int mahout_f3042_1(Configuration conf, Path input, Path output) throws IOException, ClassNotFoundException, InterruptedException
{        Job job = HadoopUtil.prepareJob(input, output, SequenceFileInputFormat.class, StreamingKMeansMapper.class, IntWritable.class, CentroidWritable.class, StreamingKMeansReducer.class, IntWritable.class, CentroidWritable.class, SequenceFileOutputFormat.class, conf);    job.setJobName(HadoopUtil.getCustomJobName(StreamingKMeansDriver.class.getSimpleName(), job, StreamingKMeansMapper.class, StreamingKMeansReducer.class));            job.setNumReduceTasks(1);        job.setJarByClass(StreamingKMeansDriver.class);        long start = System.currentTimeMillis();    if (!job.waitForCompletion(true)) {        return -1;    }    long end = System.currentTimeMillis();        return 0;}
public static void mahout_f3043_0(String[] args) throws Exception
{    ToolRunner.run(new StreamingKMeansDriver(), args);}
public void mahout_f3044_0(Context context)
{            Configuration conf = context.getConfiguration();    UpdatableSearcher searcher = StreamingKMeansUtilsMR.searcherFromConfiguration(conf);    int numClusters = conf.getInt(StreamingKMeansDriver.ESTIMATED_NUM_MAP_CLUSTERS, 1);    double estimatedDistanceCutoff = conf.getFloat(StreamingKMeansDriver.ESTIMATED_DISTANCE_CUTOFF, StreamingKMeansDriver.INVALID_DISTANCE_CUTOFF);    if (estimatedDistanceCutoff == StreamingKMeansDriver.INVALID_DISTANCE_CUTOFF) {        estimateDistanceCutoff = true;        estimatePoints = new ArrayList<>();    }        clusterer = new StreamingKMeans(searcher, numClusters, estimatedDistanceCutoff);}
private void mahout_f3045_0()
{    clusterer.setDistanceCutoff(ClusteringUtils.estimateDistanceCutoff(estimatePoints, clusterer.getDistanceMeasure()));    clusterer.cluster(estimatePoints);    estimateDistanceCutoff = false;}
public void mahout_f3046_0(Writable key, VectorWritable point, Context context)
{    Centroid centroid = new Centroid(numPoints++, point.get(), 1);    if (estimateDistanceCutoff) {        if (numPoints < NUM_ESTIMATE_POINTS) {            estimatePoints.add(centroid);        } else if (numPoints == NUM_ESTIMATE_POINTS) {            clusterEstimatePoints();        }    } else {        clusterer.cluster(centroid);    }}
public void mahout_f3047_0(Context context) throws IOException, InterruptedException
{        if (estimateDistanceCutoff) {        clusterEstimatePoints();    }        clusterer.reindexCentroids();        for (Centroid centroid : clusterer) {        context.write(new IntWritable(0), new CentroidWritable(centroid));    }}
public void mahout_f3048_0(Context context)
{            conf = context.getConfiguration();}
public void mahout_f3049_0(IntWritable key, Iterable<CentroidWritable> centroids, Context context) throws IOException, InterruptedException
{    List<Centroid> intermediateCentroids;        if (conf.getBoolean(StreamingKMeansDriver.REDUCE_STREAMING_KMEANS, false)) {        intermediateCentroids = Lists.newArrayList(new StreamingKMeansThread(Iterables.transform(centroids, new Function<CentroidWritable, Centroid>() {            @Override            public Centroid apply(CentroidWritable input) {                Preconditions.checkNotNull(input);                return input.getCentroid().clone();            }        }), conf).call());    } else {        intermediateCentroids = centroidWritablesToList(centroids);    }    int index = 0;    for (Vector centroid : getBestCentroids(intermediateCentroids, conf)) {        context.write(new IntWritable(index), new CentroidWritable((Centroid) centroid));        ++index;    }}
public Centroid mahout_f3050_0(CentroidWritable input)
{    Preconditions.checkNotNull(input);    return input.getCentroid().clone();}
public static List<Centroid> mahout_f3051_0(Iterable<CentroidWritable> centroids)
{        return Lists.newArrayList(Iterables.transform(centroids, new Function<CentroidWritable, Centroid>() {        @Override        public Centroid apply(CentroidWritable input) {            Preconditions.checkNotNull(input);            return input.getCentroid().clone();        }    }));}
public Centroid mahout_f3052_0(CentroidWritable input)
{    Preconditions.checkNotNull(input);    return input.getCentroid().clone();}
public static Iterable<Vector> mahout_f3053_1(List<Centroid> centroids, Configuration conf)
{    if (log.isInfoEnabled()) {            }    int numClusters = conf.getInt(DefaultOptionCreator.NUM_CLUSTERS_OPTION, 1);    int maxNumIterations = conf.getInt(StreamingKMeansDriver.MAX_NUM_ITERATIONS, 10);    float trimFraction = conf.getFloat(StreamingKMeansDriver.TRIM_FRACTION, 0.9f);    boolean kMeansPlusPlusInit = !conf.getBoolean(StreamingKMeansDriver.RANDOM_INIT, false);    boolean correctWeights = !conf.getBoolean(StreamingKMeansDriver.IGNORE_WEIGHTS, false);    float testProbability = conf.getFloat(StreamingKMeansDriver.TEST_PROBABILITY, 0.1f);    int numRuns = conf.getInt(StreamingKMeansDriver.NUM_BALLKMEANS_RUNS, 3);    BallKMeans ballKMeansCluster = new BallKMeans(StreamingKMeansUtilsMR.searcherFromConfiguration(conf), numClusters, maxNumIterations, trimFraction, kMeansPlusPlusInit, correctWeights, testProbability, numRuns);    return ballKMeansCluster.cluster(centroids);}
public Iterable<Centroid> mahout_f3054_1()
{    UpdatableSearcher searcher = StreamingKMeansUtilsMR.searcherFromConfiguration(conf);    int numClusters = conf.getInt(StreamingKMeansDriver.ESTIMATED_NUM_MAP_CLUSTERS, 1);    double estimateDistanceCutoff = conf.getFloat(StreamingKMeansDriver.ESTIMATED_DISTANCE_CUTOFF, StreamingKMeansDriver.INVALID_DISTANCE_CUTOFF);    Iterator<Centroid> dataPointsIterator = dataPoints.iterator();    if (estimateDistanceCutoff == StreamingKMeansDriver.INVALID_DISTANCE_CUTOFF) {        List<Centroid> estimatePoints = new ArrayList<>(NUM_ESTIMATE_POINTS);        while (dataPointsIterator.hasNext() && estimatePoints.size() < NUM_ESTIMATE_POINTS) {            Centroid centroid = dataPointsIterator.next();            estimatePoints.add(centroid);        }        if (log.isInfoEnabled()) {                    }        estimateDistanceCutoff = ClusteringUtils.estimateDistanceCutoff(estimatePoints, searcher.getDistanceMeasure());    }    StreamingKMeans streamingKMeans = new StreamingKMeans(searcher, numClusters, estimateDistanceCutoff);        if (!dataPointsIterator.hasNext()) {        dataPointsIterator = dataPoints.iterator();    }    while (dataPointsIterator.hasNext()) {        streamingKMeans.cluster(dataPointsIterator.next());    }    streamingKMeans.reindexCentroids();    return streamingKMeans;}
public static UpdatableSearcher mahout_f3055_0(Configuration conf)
{    DistanceMeasure distanceMeasure;    String distanceMeasureClass = conf.get(DefaultOptionCreator.DISTANCE_MEASURE_OPTION);    try {        distanceMeasure = (DistanceMeasure) Class.forName(distanceMeasureClass).getConstructor().newInstance();    } catch (Exception e) {        throw new RuntimeException("Failed to instantiate distanceMeasure", e);    }    int numProjections = conf.getInt(StreamingKMeansDriver.NUM_PROJECTIONS_OPTION, 20);    int searchSize = conf.getInt(StreamingKMeansDriver.SEARCH_SIZE_OPTION, 10);    String searcherClass = conf.get(StreamingKMeansDriver.SEARCHER_CLASS_OPTION);    if (searcherClass.equals(BruteSearch.class.getName())) {        return ClassUtils.instantiateAs(searcherClass, UpdatableSearcher.class, new Class[] { DistanceMeasure.class }, new Object[] { distanceMeasure });    } else if (searcherClass.equals(FastProjectionSearch.class.getName()) || searcherClass.equals(ProjectionSearch.class.getName())) {        return ClassUtils.instantiateAs(searcherClass, UpdatableSearcher.class, new Class[] { DistanceMeasure.class, int.class, int.class }, new Object[] { distanceMeasure, numProjections, searchSize });    } else if (searcherClass.equals(LocalitySensitiveHashSearch.class.getName())) {        return ClassUtils.instantiateAs(searcherClass, LocalitySensitiveHashSearch.class, new Class[] { DistanceMeasure.class, int.class }, new Object[] { distanceMeasure, searchSize });    } else {        throw new IllegalStateException("Unknown class instantiation requested");    }}
public static Iterable<Centroid> mahout_f3056_0(Iterable<VectorWritable> inputIterable)
{    return Iterables.transform(inputIterable, new Function<VectorWritable, Centroid>() {        private int numVectors = 0;        @Override        public Centroid apply(VectorWritable input) {            Preconditions.checkNotNull(input);            return new Centroid(numVectors++, new RandomAccessSparseVector(input.get()), 1);        }    });}
public Centroid mahout_f3057_0(VectorWritable input)
{    Preconditions.checkNotNull(input);    return new Centroid(numVectors++, new RandomAccessSparseVector(input.get()), 1);}
public static Iterable<Centroid> mahout_f3058_0(Iterable<Vector> input)
{    return Iterables.transform(input, new Function<Vector, Centroid>() {        private int numVectors = 0;        @Override        public Centroid apply(Vector input) {            Preconditions.checkNotNull(input);            if (input instanceof Centroid) {                return (Centroid) input;            } else {                return new Centroid(numVectors++, input, 1);            }        }    });}
public Centroid mahout_f3059_0(Vector input)
{    Preconditions.checkNotNull(input);    if (input instanceof Centroid) {        return (Centroid) input;    } else {        return new Centroid(numVectors++, input, 1);    }}
public static void mahout_f3060_0(Iterable<Centroid> centroids, Path path, Configuration conf) throws IOException
{    try (SequenceFile.Writer writer = SequenceFile.createWriter(FileSystem.get(conf), conf, path, IntWritable.class, CentroidWritable.class)) {        int i = 0;        for (Centroid centroid : centroids) {            writer.append(new IntWritable(i++), new CentroidWritable(centroid));        }    }}
public static void mahout_f3061_0(Iterable<? extends Vector> datapoints, Path path, Configuration conf) throws IOException
{    try (SequenceFile.Writer writer = SequenceFile.createWriter(FileSystem.get(conf), conf, path, IntWritable.class, VectorWritable.class)) {        int i = 0;        for (Vector vector : datapoints) {            writer.append(new IntWritable(i++), new VectorWritable(vector));        }    }}
private void mahout_f3062_0(Iterator<Pair<Writable, Writable>> inputIterator, int numSplit, int numEntriesPerSplit) throws IOException
{    SequenceFile.Writer splitWriter = null;    for (int j = 0; j < numEntriesPerSplit; ++j) {        Pair<Writable, Writable> item = inputIterator.next();        if (splitWriter == null) {            splitWriter = SequenceFile.createWriter(fs, conf, new Path(outputFileBase + "-" + numSplit), item.getFirst().getClass(), item.getSecond().getClass());        }        splitWriter.append(item.getFirst(), item.getSecond());    }    if (splitWriter != null) {        splitWriter.close();    }}
private void mahout_f3063_0(PrintWriter printWriter) throws IOException
{    conf = new Configuration();    SequenceFileDirIterable<Writable, Writable> inputIterable = new SequenceFileDirIterable<>(new Path(inputFile), PathType.LIST, conf);    fs = FileSystem.get(conf);    int numEntries = Iterables.size(inputIterable);    int numEntriesPerSplit = numEntries / numSplits;    int numEntriesLastSplit = numEntriesPerSplit + numEntries - numEntriesPerSplit * numSplits;    Iterator<Pair<Writable, Writable>> inputIterator = inputIterable.iterator();    printWriter.printf("Writing %d splits\n", numSplits);    for (int i = 0; i < numSplits - 1; ++i) {        printWriter.printf("Writing split %d\n", i);        writeSplit(inputIterator, i, numEntriesPerSplit);    }    printWriter.printf("Writing split %d\n", numSplits - 1);    writeSplit(inputIterator, numSplits - 1, numEntriesLastSplit);}
private boolean mahout_f3064_0(String[] args)
{    DefaultOptionBuilder builder = new DefaultOptionBuilder();    Option help = builder.withLongName("help").withDescription("print this list").create();    ArgumentBuilder argumentBuilder = new ArgumentBuilder();    Option inputFileOption = builder.withLongName("input").withShortName("i").withRequired(true).withArgument(argumentBuilder.withName("input").withMaximum(1).create()).withDescription("what the base folder for sequence files is (they all must have the same key/value type").create();    Option outputFileOption = builder.withLongName("output").withShortName("o").withRequired(true).withArgument(argumentBuilder.withName("output").withMaximum(1).create()).withDescription("the base name of the file split that the files will be split it; the i'th split has the " + "suffix -i").create();    Option numSplitsOption = builder.withLongName("numSplits").withShortName("ns").withRequired(true).withArgument(argumentBuilder.withName("numSplits").withMaximum(1).create()).withDescription("how many splits to use for the given files").create();    Group normalArgs = new GroupBuilder().withOption(help).withOption(inputFileOption).withOption(outputFileOption).withOption(numSplitsOption).create();    Parser parser = new Parser();    parser.setHelpOption(help);    parser.setHelpTrigger("--help");    parser.setGroup(normalArgs);    parser.setHelpFormatter(new HelpFormatter(" ", "", " ", 130));    CommandLine cmdLine = parser.parseAndHelp(args);    if (cmdLine == null) {        return false;    }    inputFile = (String) cmdLine.getValue(inputFileOption);    outputFileBase = (String) cmdLine.getValue(outputFileOption);    numSplits = Integer.parseInt((String) cmdLine.getValue(numSplitsOption));    return true;}
public static void mahout_f3065_0(String[] args) throws IOException
{    ResplitSequenceFiles runner = new ResplitSequenceFiles();    if (runner.parseArgs(args)) {        runner.run(new PrintWriter(new OutputStreamWriter(System.out, Charsets.UTF_8), true));    }}
public static Path mahout_f3066_0(Path output)
{    return new Path(output + File.separator + TOP_LEVEL_CLUSTER_DIRECTORY);}
public static Path mahout_f3067_0(Path outputPathProvidedByUser)
{    return new Path(outputPathProvidedByUser + File.separator + POST_PROCESS_DIRECTORY);}
public static Path mahout_f3068_0(Path output)
{    return new Path(output + File.separator + CLUSTERED_POINTS_DIRECTORY + File.separator, "*");}
public static Path mahout_f3069_0(Path output, String clusterId)
{    return new Path(output + File.separator + BOTTOM_LEVEL_CLUSTER_DIRECTORY + File.separator + clusterId);}
public static Path mahout_f3070_0(Path clusterPostProcessorOutput, String clusterId)
{    return new Path(clusterPostProcessorOutput + File.separator + clusterId);}
public static int mahout_f3071_0(Path clusterOutputPath, Configuration conf) throws IOException
{    FileSystem fileSystem = clusterOutputPath.getFileSystem(conf);    FileStatus[] clusterFiles = fileSystem.listStatus(clusterOutputPath, PathFilters.finalPartFilter());    int numberOfClusters = 0;    Iterator<?> it = new SequenceFileDirValueIterator<>(clusterFiles[0].getPath(), PathType.LIST, PathFilters.partFilter(), null, true, conf);    while (it.hasNext()) {        it.next();        numberOfClusters++;    }    return numberOfClusters;}
public static Map<Integer, Integer> mahout_f3072_0(Path clusterOutputPath, Configuration conf, boolean keyIsClusterId) throws IOException
{    Map<Integer, Integer> clusterIds = new HashMap<>();    FileSystem fileSystem = clusterOutputPath.getFileSystem(conf);    FileStatus[] clusterFiles = fileSystem.listStatus(clusterOutputPath, PathFilters.finalPartFilter());        Iterator<ClusterWritable> it = new SequenceFileDirValueIterator<>(clusterFiles[0].getPath(), PathType.LIST, PathFilters.partFilter(), null, true, conf);    int i = 0;    while (it.hasNext()) {        Integer key;        Integer value;        if (keyIsClusterId) {                        key = it.next().getValue().getId();            value = i;        } else {            key = i;            value = it.next().getValue().getId();        }        clusterIds.put(key, value);        i++;    }    return clusterIds;}
public void mahout_f3073_0() throws IOException
{    createPostProcessDirectory();    for (Pair<?, WeightedVectorWritable> record : new SequenceFileDirIterable<Writable, WeightedVectorWritable>(clusteredPoints, PathType.GLOB, PathFilters.partFilter(), null, false, conf)) {        String clusterId = record.getFirst().toString().trim();        putVectorInRespectiveCluster(clusterId, record.getSecond());    }    IOUtils.close(writersForClusters.values());    writersForClusters.clear();}
private void mahout_f3074_0() throws IOException
{    if (!fileSystem.exists(clusterPostProcessorOutput) && !fileSystem.mkdirs(clusterPostProcessorOutput)) {        throw new IOException("Error creating cluster post processor directory");    }}
private void mahout_f3075_0(String clusterId, WeightedVectorWritable point) throws IOException
{    Writer writer = findWriterForVector(clusterId);    postProcessedClusterDirectories.put(clusterId, PathDirectory.getClusterPathForClusterId(clusterPostProcessorOutput, clusterId));    writeVectorToCluster(writer, point);}
private Writer mahout_f3076_0(String clusterId) throws IOException
{    Path clusterDirectory = PathDirectory.getClusterPathForClusterId(clusterPostProcessorOutput, clusterId);    Writer writer = writersForClusters.get(clusterId);    if (writer == null) {        Path pathToWrite = new Path(clusterDirectory, new Path("part-m-0"));        writer = new Writer(fileSystem, conf, pathToWrite, LongWritable.class, VectorWritable.class);        writersForClusters.put(clusterId, writer);    }    return writer;}
private void mahout_f3077_0(Writer writer, WeightedVectorWritable point) throws IOException
{    writer.append(new LongWritable(uniqueVectorId++), new VectorWritable(point.getVector()));    writer.sync();}
public Map<String, Path> mahout_f3078_0()
{    return postProcessedClusterDirectories;}
public void mahout_f3079_0(Path clusteredPoints)
{    this.clusteredPoints = clusteredPoints;}
public int mahout_f3080_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption(DefaultOptionCreator.methodOption().create());    addOption(DefaultOptionCreator.overwriteOption().create());    if (parseArguments(args) == null) {        return -1;    }    Path input = getInputPath();    Path output = getOutputPath();    if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {        HadoopUtil.delete(getConf(), output);    }    boolean runSequential = getOption(DefaultOptionCreator.METHOD_OPTION).equalsIgnoreCase(DefaultOptionCreator.SEQUENTIAL_METHOD);    run(input, output, runSequential);    return 0;}
public static void mahout_f3081_0(String[] args) throws Exception
{    ToolRunner.run(new Configuration(), new ClusterOutputPostProcessorDriver(), args);}
public static void mahout_f3082_0(Path input, Path output, boolean runSequential) throws IOException, InterruptedException, ClassNotFoundException
{    if (runSequential) {        postProcessSeq(input, output);    } else {        Configuration conf = new Configuration();        postProcessMR(conf, input, output);        movePartFilesToRespectiveDirectories(conf, output);    }}
private static void mahout_f3083_0(Path input, Path output) throws IOException
{    ClusterOutputPostProcessor clusterOutputPostProcessor = new ClusterOutputPostProcessor(input, output, new Configuration());    clusterOutputPostProcessor.process();}
private static void mahout_f3084_0(Configuration conf, Path input, Path output) throws IOException, InterruptedException, ClassNotFoundException
{    System.out.println("WARNING: If you are running in Hadoop local mode, please use the --sequential option, " + "as the MapReduce option will not work properly");    int numberOfClusters = ClusterCountReader.getNumberOfClusters(input, conf);    conf.set("clusterOutputPath", input.toString());    Job job = new Job(conf, "ClusterOutputPostProcessor Driver running over input: " + input);    job.setInputFormatClass(SequenceFileInputFormat.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    job.setMapperClass(ClusterOutputPostProcessorMapper.class);    job.setMapOutputKeyClass(IntWritable.class);    job.setMapOutputValueClass(VectorWritable.class);    job.setReducerClass(ClusterOutputPostProcessorReducer.class);    job.setOutputKeyClass(IntWritable.class);    job.setOutputValueClass(VectorWritable.class);    job.setNumReduceTasks(numberOfClusters);    job.setJarByClass(ClusterOutputPostProcessorDriver.class);    FileInputFormat.addInputPath(job, new Path(input, new Path("clusteredPoints")));    FileOutputFormat.setOutputPath(job, output);    if (!job.waitForCompletion(true)) {        throw new InterruptedException("ClusterOutputPostProcessor Job failed processing " + input);    }}
private static void mahout_f3085_0(Configuration conf, Path output) throws IOException
{    FileSystem fileSystem = output.getFileSystem(conf);    for (FileStatus fileStatus : fileSystem.listStatus(output, PathFilters.partFilter())) {        SequenceFileIterator<Writable, Writable> it = new SequenceFileIterator<>(fileStatus.getPath(), true, conf);        if (it.hasNext()) {            renameFile(it.next().getFirst(), fileStatus, conf);        }        it.close();    }}
private static void mahout_f3086_0(Writable key, FileStatus fileStatus, Configuration conf) throws IOException
{    Path path = fileStatus.getPath();    FileSystem fileSystem = path.getFileSystem(conf);    Path subDir = new Path(key.toString());    Path renameTo = new Path(path.getParent(), subDir);    fileSystem.mkdirs(renameTo);    fileSystem.rename(path, renameTo);}
public void mahout_f3087_0(Context context) throws IOException
{    Configuration conf = context.getConfiguration();        Path clusterOutputPath = new Path(conf.get("clusterOutputPath"));        newClusterMappings = ClusterCountReader.getClusterIDs(clusterOutputPath, conf, true);    outputVector = new VectorWritable();}
public void mahout_f3088_0(IntWritable key, WeightedVectorWritable val, Context context) throws IOException, InterruptedException
{            outputVector.set(val.getVector());    context.write(new IntWritable(newClusterMappings.get(key.get())), outputVector);}
public void mahout_f3089_0(Context context) throws IOException
{    Configuration conf = context.getConfiguration();    Path clusterOutputPath = new Path(conf.get("clusterOutputPath"));        reverseClusterMappings = ClusterCountReader.getClusterIDs(clusterOutputPath, conf, false);}
protected void mahout_f3090_0(IntWritable key, Iterable<VectorWritable> values, Context context) throws IOException, InterruptedException
{                IntWritable outKey = new IntWritable(reverseClusterMappings.get(key.get()));    System.out.println(outKey + " this: " + this);    for (VectorWritable value : values) {        context.write(outKey, value);    }}
public static double mahout_f3091_0(double k, double lambda)
{    boolean accept = false;    if (k >= 1.0) {                double b = k - Math.log(4.0);        double c = k + Math.sqrt(2.0 * k - 1.0);        double lam = Math.sqrt(2.0 * k - 1.0);        double cheng = 1.0 + Math.log(4.5);        double x;        do {            double u = RANDOM.nextDouble();            double v = RANDOM.nextDouble();            double y = 1.0 / lam * Math.log(v / (1.0 - v));            x = k * Math.exp(y);            double z = u * v * v;            double r = b + c * y - x;            if (r >= 4.5 * z - cheng || r >= Math.log(z)) {                accept = true;            }        } while (!accept);        return x / lambda;    } else {                double c = 1.0 / k;        double d = (1.0 - k) * Math.pow(k, k / (1.0 - k));        double x;        do {            double u = RANDOM.nextDouble();            double v = RANDOM.nextDouble();            double z = -Math.log(u);            double e = -Math.log(v);            x = Math.pow(z, c);            if (z + e >= d + x) {                accept = true;            }        } while (!accept);        return x / lambda;    }}
public static double mahout_f3092_0(double shape1, double shape2)
{    double gam1 = rGamma(shape1, 1.0);    double gam2 = rGamma(shape2, 1.0);    return gam1 / (gam1 + gam2);}
public static double mahout_f3093_0(double mean, double sd)
{    RealDistribution dist = new NormalDistribution(RANDOM.getRandomGenerator(), mean, sd, NormalDistribution.DEFAULT_INVERSE_ABSOLUTE_ACCURACY);    return dist.sample();}
public static int mahout_f3094_0(int n, double p)
{    if (p >= 1.0) {                return n;    }    double q = -Math.log1p(-p);    double sum = 0.0;    int x = 0;    while (sum <= q) {        double u = RANDOM.nextDouble();        double e = -Math.log(u);        sum += e / (n - x);        x++;    }    if (x == 0) {        return 0;    }    return x - 1;}
protected Path mahout_f3095_0()
{    return inputPath;}
protected Path mahout_f3096_0()
{    return outputPath;}
protected Path mahout_f3097_0(String path)
{    return new Path(outputPath, path);}
protected File mahout_f3098_0()
{    return inputFile;}
protected File mahout_f3099_0()
{    return outputFile;}
protected Path mahout_f3100_0()
{    return tempPath;}
protected Path mahout_f3101_0(String directory)
{    return new Path(tempPath, directory);}
public Configuration mahout_f3102_0()
{    Configuration result = super.getConf();    if (result == null) {        return new Configuration();    }    return result;}
protected void mahout_f3103_0(String name, String shortName, String description)
{    options.add(buildOption(name, shortName, description, false, false, null));}
protected void mahout_f3104_0(String name, String shortName, String description)
{    options.add(buildOption(name, shortName, description, true, false, null));}
protected void mahout_f3105_0(String name, String shortName, String description, boolean required)
{    options.add(buildOption(name, shortName, description, true, required, null));}
protected void mahout_f3106_0(String name, String shortName, String description, String defaultValue)
{    options.add(buildOption(name, shortName, description, true, false, defaultValue));}
protected Option mahout_f3107_0(Option option)
{    options.add(option);    return option;}
protected Group mahout_f3108_0()
{    return group;}
protected void mahout_f3109_0()
{    this.inputOption = addOption(DefaultOptionCreator.inputOption().create());}
protected void mahout_f3110_0()
{    this.outputOption = addOption(DefaultOptionCreator.outputOption().create());}
protected static Option mahout_f3111_0(String name, String shortName, String description, boolean hasArg, boolean required, String defaultValue)
{    return buildOption(name, shortName, description, hasArg, 1, 1, required, defaultValue);}
protected static Option mahout_f3112_0(String name, String shortName, String description, boolean hasArg, int min, int max, boolean required, String defaultValue)
{    DefaultOptionBuilder optBuilder = new DefaultOptionBuilder().withLongName(name).withDescription(description).withRequired(required);    if (shortName != null) {        optBuilder.withShortName(shortName);    }    if (hasArg) {        ArgumentBuilder argBuilder = new ArgumentBuilder().withName(name).withMinimum(min).withMaximum(max);        if (defaultValue != null) {            argBuilder = argBuilder.withDefault(defaultValue);        }        optBuilder.withArgument(argBuilder.create());    }    return optBuilder.create();}
protected Option mahout_f3113_0(String name)
{    for (Option option : options) {        if (option.getPreferredName().equals(name)) {            return option;        }    }    return null;}
public Map<String, List<String>> mahout_f3114_0(String[] args) throws IOException
{    return parseArguments(args, false, false);}
public Map<String, List<String>> mahout_f3115_1(String[] args, boolean inputOptional, boolean outputOptional) throws IOException
{    Option helpOpt = addOption(DefaultOptionCreator.helpOption());    addOption("tempDir", null, "Intermediate output directory", "temp");    addOption("startPhase", null, "First phase to run", "0");    addOption("endPhase", null, "Last phase to run", String.valueOf(Integer.MAX_VALUE));    GroupBuilder gBuilder = new GroupBuilder().withName("Job-Specific Options:");    for (Option opt : options) {        gBuilder = gBuilder.withOption(opt);    }    group = gBuilder.create();    CommandLine cmdLine;    try {        Parser parser = new Parser();        parser.setGroup(group);        parser.setHelpOption(helpOpt);        cmdLine = parser.parse(args);    } catch (OptionException e) {                CommandLineUtil.printHelpWithGenericOptions(group, e);        return null;    }    if (cmdLine.hasOption(helpOpt)) {        CommandLineUtil.printHelpWithGenericOptions(group);        return null;    }    try {        parseDirectories(cmdLine, inputOptional, outputOptional);    } catch (IllegalArgumentException e) {                CommandLineUtil.printHelpWithGenericOptions(group);        return null;    }    argMap = new TreeMap<>();    maybePut(argMap, cmdLine, this.options.toArray(new Option[this.options.size()]));    this.tempPath = new Path(getOption("tempDir"));    if (!hasOption("quiet")) {            }    return argMap;}
public static String mahout_f3116_0(String optionName)
{    return "--" + optionName;}
public String mahout_f3117_0(String optionName)
{    List<String> list = argMap.get(keyFor(optionName));    if (list != null && !list.isEmpty()) {        return list.get(0);    }    return null;}
public String mahout_f3118_0(String optionName, String defaultVal)
{    String res = getOption(optionName);    if (res == null) {        res = defaultVal;    }    return res;}
public int mahout_f3119_0(String optionName)
{    return Integer.parseInt(getOption(optionName));}
public int mahout_f3120_0(String optionName, int defaultVal)
{    return Integer.parseInt(getOption(optionName, String.valueOf(defaultVal)));}
public float mahout_f3121_0(String optionName)
{    return Float.parseFloat(getOption(optionName));}
public float mahout_f3122_0(String optionName, float defaultVal)
{    return Float.parseFloat(getOption(optionName, String.valueOf(defaultVal)));}
public List<String> mahout_f3123_0(String optionName)
{    return argMap.get(keyFor(optionName));}
public boolean mahout_f3124_0(String optionName)
{    return argMap.containsKey(keyFor(optionName));}
public int mahout_f3125_0(Path matrix) throws IOException
{    try (SequenceFile.Reader reader = new SequenceFile.Reader(FileSystem.get(getConf()), matrix, getConf())) {        Writable row = ClassUtils.instantiateAs(reader.getKeyClass().asSubclass(Writable.class), Writable.class);        Preconditions.checkArgument(reader.getValueClass().equals(VectorWritable.class), "value type of sequencefile must be a VectorWritable");        VectorWritable vectorWritable = new VectorWritable();        boolean hasAtLeastOneRow = reader.next(row, vectorWritable);        Preconditions.checkState(hasAtLeastOneRow, "matrix must have at least one row");        return vectorWritable.get().size();    }}
protected void mahout_f3126_0(CommandLine cmdLine, boolean inputOptional, boolean outputOptional)
{    Configuration conf = getConf();    if (inputOption != null && cmdLine.hasOption(inputOption)) {        this.inputPath = new Path(cmdLine.getValue(inputOption).toString());        this.inputFile = new File(cmdLine.getValue(inputOption).toString());    }    if (inputPath == null && conf.get("mapred.input.dir") != null) {        this.inputPath = new Path(conf.get("mapred.input.dir"));    }    if (outputOption != null && cmdLine.hasOption(outputOption)) {        this.outputPath = new Path(cmdLine.getValue(outputOption).toString());        this.outputFile = new File(cmdLine.getValue(outputOption).toString());    }    if (outputPath == null && conf.get("mapred.output.dir") != null) {        this.outputPath = new Path(conf.get("mapred.output.dir"));    }    Preconditions.checkArgument(inputOptional || inputOption == null || inputPath != null, "No input specified or -Dmapred.input.dir must be provided to specify input directory");    Preconditions.checkArgument(outputOptional || outputOption == null || outputPath != null, "No output specified:  or -Dmapred.output.dir must be provided to specify output directory");}
protected static void mahout_f3127_0(Map<String, List<String>> args, CommandLine cmdLine, Option... opt)
{    for (Option o : opt) {                if (cmdLine.hasOption(o) || cmdLine.getValue(o) != null || (cmdLine.getValues(o) != null && !cmdLine.getValues(o).isEmpty())) {                        List<?> vo = cmdLine.getValues(o);            if (vo != null && !vo.isEmpty()) {                List<String> vals = new ArrayList<>();                for (Object o1 : vo) {                    vals.add(o1.toString());                }                args.put(o.getPreferredName(), vals);            } else {                args.put(o.getPreferredName(), null);            }        }    }}
public static String mahout_f3128_0(Map<String, List<String>> args, String optName)
{    List<String> res = args.get(optName);    if (res != null && !res.isEmpty()) {        return res.get(0);    }    return null;}
protected static boolean mahout_f3129_1(Map<String, List<String>> args, AtomicInteger currentPhase)
{    int phase = currentPhase.getAndIncrement();    String startPhase = getOption(args, "--startPhase");    String endPhase = getOption(args, "--endPhase");    boolean phaseSkipped = (startPhase != null && phase < Integer.parseInt(startPhase)) || (endPhase != null && phase > Integer.parseInt(endPhase));    if (phaseSkipped) {            }    return !phaseSkipped;}
protected Job mahout_f3130_0(Path inputPath, Path outputPath, Class<? extends InputFormat> inputFormat, Class<? extends Mapper> mapper, Class<? extends Writable> mapperKey, Class<? extends Writable> mapperValue, Class<? extends OutputFormat> outputFormat) throws IOException
{    return prepareJob(inputPath, outputPath, inputFormat, mapper, mapperKey, mapperValue, outputFormat, null);}
protected Job mahout_f3131_0(Path inputPath, Path outputPath, Class<? extends InputFormat> inputFormat, Class<? extends Mapper> mapper, Class<? extends Writable> mapperKey, Class<? extends Writable> mapperValue, Class<? extends OutputFormat> outputFormat, String jobname) throws IOException
{    Job job = HadoopUtil.prepareJob(inputPath, outputPath, inputFormat, mapper, mapperKey, mapperValue, outputFormat, getConf());    String name = jobname != null ? jobname : HadoopUtil.getCustomJobName(getClass().getSimpleName(), job, mapper, Reducer.class);    job.setJobName(name);    return job;}
protected Job mahout_f3132_0(Path inputPath, Path outputPath, Class<? extends Mapper> mapper, Class<? extends Writable> mapperKey, Class<? extends Writable> mapperValue, Class<? extends Reducer> reducer, Class<? extends Writable> reducerKey, Class<? extends Writable> reducerValue) throws IOException
{    return prepareJob(inputPath, outputPath, SequenceFileInputFormat.class, mapper, mapperKey, mapperValue, reducer, reducerKey, reducerValue, SequenceFileOutputFormat.class);}
protected Job mahout_f3133_0(Path inputPath, Path outputPath, Class<? extends InputFormat> inputFormat, Class<? extends Mapper> mapper, Class<? extends Writable> mapperKey, Class<? extends Writable> mapperValue, Class<? extends Reducer> reducer, Class<? extends Writable> reducerKey, Class<? extends Writable> reducerValue, Class<? extends OutputFormat> outputFormat) throws IOException
{    Job job = HadoopUtil.prepareJob(inputPath, outputPath, inputFormat, mapper, mapperKey, mapperValue, reducer, reducerKey, reducerValue, outputFormat, getConf());    job.setJobName(HadoopUtil.getCustomJobName(getClass().getSimpleName(), job, mapper, Reducer.class));    return job;}
public static void mahout_f3134_0(Job job, Path referencePath, Path inputPathOne, Path inputPathTwo) throws IOException
{    FileSystem fs = FileSystem.get(referencePath.toUri(), job.getConfiguration());    FileInputFormat.setInputPaths(job, inputPathOne.makeQualified(fs), inputPathTwo.makeQualified(fs));}
protected Class<? extends Analyzer> mahout_f3135_0() throws ClassNotFoundException
{    Class<? extends Analyzer> analyzerClass = StandardAnalyzer.class;    if (hasOption(DefaultOptionCreator.ANALYZER_NAME_OPTION)) {        String className = getOption(DefaultOptionCreator.ANALYZER_NAME_OPTION);        analyzerClass = Class.forName(className).asSubclass(Analyzer.class);                                AnalyzerUtils.createAnalyzer(analyzerClass);    }    return analyzerClass;}
public void mahout_f3136_1(Configuration conf)
{    super.setConf(conf);            String oozieActionConfXml = System.getProperty("oozie.action.conf.xml");    if (oozieActionConfXml != null && conf != null) {        conf.addResource(new Path("file:///", oozieActionConfXml));            }}
public static T mahout_f3137_0(String classname, Class<T> asSubclassOfClass)
{    try {        return instantiateAs(Class.forName(classname).asSubclass(asSubclassOfClass), asSubclassOfClass);    } catch (ClassNotFoundException e) {        throw new IllegalStateException(e);    }}
public static T mahout_f3138_0(String classname, Class<T> asSubclassOfClass, Class<?>[] params, Object[] args)
{    try {        return instantiateAs(Class.forName(classname).asSubclass(asSubclassOfClass), asSubclassOfClass, params, args);    } catch (ClassNotFoundException e) {        throw new IllegalStateException(e);    }}
public static T mahout_f3139_0(Class<? extends T> clazz, Class<T> asSubclassOfClass, Class<?>[] params, Object[] args)
{    try {        return clazz.asSubclass(asSubclassOfClass).getConstructor(params).newInstance(args);    } catch (InstantiationException | IllegalAccessException | NoSuchMethodException | InvocationTargetException ie) {        throw new IllegalStateException(ie);    }}
public static T mahout_f3140_0(Class<? extends T> clazz, Class<T> asSubclassOfClass)
{    try {        return clazz.asSubclass(asSubclassOfClass).getConstructor().newInstance();    } catch (InstantiationException | IllegalAccessException | NoSuchMethodException | InvocationTargetException ie) {        throw new IllegalStateException(ie);    }}
public static Option mahout_f3141_0()
{    return new DefaultOptionBuilder().withLongName("help").withDescription("Print out help").withShortName("h").create();}
public static DefaultOptionBuilder mahout_f3142_0()
{    return new DefaultOptionBuilder().withLongName(INPUT_OPTION).withRequired(false).withShortName("i").withArgument(new ArgumentBuilder().withName(INPUT_OPTION).withMinimum(1).withMaximum(1).create()).withDescription("Path to job input directory.");}
public static DefaultOptionBuilder mahout_f3143_0()
{    return new DefaultOptionBuilder().withLongName(CLUSTERS_IN_OPTION).withRequired(true).withArgument(new ArgumentBuilder().withName(CLUSTERS_IN_OPTION).withMinimum(1).withMaximum(1).create()).withDescription("The path to the initial clusters directory. Must be a SequenceFile of some type of Cluster").withShortName("c");}
public static DefaultOptionBuilder mahout_f3144_0()
{    return new DefaultOptionBuilder().withLongName(OUTPUT_OPTION).withRequired(false).withShortName("o").withArgument(new ArgumentBuilder().withName(OUTPUT_OPTION).withMinimum(1).withMaximum(1).create()).withDescription("The directory pathname for output.");}
public static DefaultOptionBuilder mahout_f3145_0()
{    return new DefaultOptionBuilder().withLongName(OVERWRITE_OPTION).withRequired(false).withDescription("If present, overwrite the output directory before running job").withShortName("ow");}
public static DefaultOptionBuilder mahout_f3146_0()
{    return new DefaultOptionBuilder().withLongName(DISTANCE_MEASURE_OPTION).withRequired(false).withShortName("dm").withArgument(new ArgumentBuilder().withName(DISTANCE_MEASURE_OPTION).withDefault(SquaredEuclideanDistanceMeasure.class.getName()).withMinimum(1).withMaximum(1).create()).withDescription("The classname of the DistanceMeasure. Default is SquaredEuclidean");}
public static DefaultOptionBuilder mahout_f3147_0()
{    return new DefaultOptionBuilder().withLongName(METHOD_OPTION).withRequired(false).withShortName("xm").withArgument(new ArgumentBuilder().withName(METHOD_OPTION).withDefault(MAPREDUCE_METHOD).withMinimum(1).withMaximum(1).create()).withDescription("The execution method to use: sequential or mapreduce. Default is mapreduce");}
public static DefaultOptionBuilder mahout_f3148_0()
{    return new DefaultOptionBuilder().withLongName(T1_OPTION).withRequired(true).withArgument(new ArgumentBuilder().withName(T1_OPTION).withMinimum(1).withMaximum(1).create()).withDescription("T1 threshold value").withShortName(T1_OPTION);}
public static DefaultOptionBuilder mahout_f3149_0()
{    return new DefaultOptionBuilder().withLongName(T2_OPTION).withRequired(true).withArgument(new ArgumentBuilder().withName(T2_OPTION).withMinimum(1).withMaximum(1).create()).withDescription("T2 threshold value").withShortName(T2_OPTION);}
public static DefaultOptionBuilder mahout_f3150_0()
{    return new DefaultOptionBuilder().withLongName(T3_OPTION).withRequired(false).withArgument(new ArgumentBuilder().withName(T3_OPTION).withMinimum(1).withMaximum(1).create()).withDescription("T3 (Reducer T1) threshold value").withShortName(T3_OPTION);}
public static DefaultOptionBuilder mahout_f3151_0()
{    return new DefaultOptionBuilder().withLongName(T4_OPTION).withRequired(false).withArgument(new ArgumentBuilder().withName(T4_OPTION).withMinimum(1).withMaximum(1).create()).withDescription("T4 (Reducer T2) threshold value").withShortName(T4_OPTION);}
public static DefaultOptionBuilder mahout_f3152_0()
{    return new DefaultOptionBuilder().withLongName(CLUSTER_FILTER_OPTION).withShortName("cf").withRequired(false).withArgument(new ArgumentBuilder().withName(CLUSTER_FILTER_OPTION).withMinimum(1).withMaximum(1).create()).withDescription("Cluster filter suppresses small canopies from mapper").withShortName(CLUSTER_FILTER_OPTION);}
public static DefaultOptionBuilder mahout_f3153_0()
{        return new DefaultOptionBuilder().withLongName(MAX_ITERATIONS_OPTION).withRequired(true).withShortName("x").withArgument(new ArgumentBuilder().withName(MAX_ITERATIONS_OPTION).withDefault("-1").withMinimum(1).withMaximum(1).create()).withDescription("The maximum number of iterations.");}
public static DefaultOptionBuilder mahout_f3154_0()
{    return new DefaultOptionBuilder().withLongName(NUM_CLUSTERS_OPTION).withRequired(false).withArgument(new ArgumentBuilder().withName("k").withMinimum(1).withMaximum(1).create()).withDescription("The number of clusters to create").withShortName("k");}
public static DefaultOptionBuilder mahout_f3155_0()
{    return new DefaultOptionBuilder().withLongName(RANDOM_SEED).withRequired(false).withArgument(new ArgumentBuilder().withName(RANDOM_SEED).create()).withDescription("Seed to initaize Random Number Generator with").withShortName("rs");}
public static DefaultOptionBuilder mahout_f3156_0()
{    return new DefaultOptionBuilder().withLongName(CONVERGENCE_DELTA_OPTION).withRequired(false).withShortName("cd").withArgument(new ArgumentBuilder().withName(CONVERGENCE_DELTA_OPTION).withDefault("0.5").withMinimum(1).withMaximum(1).create()).withDescription("The convergence delta value. Default is 0.5");}
public static DefaultOptionBuilder mahout_f3157_0()
{    return new DefaultOptionBuilder().withLongName(MAX_REDUCERS_OPTION).withRequired(false).withShortName("r").withArgument(new ArgumentBuilder().withName(MAX_REDUCERS_OPTION).withDefault("2").withMinimum(1).withMaximum(1).create()).withDescription("The number of reduce tasks. Defaults to 2");}
public static DefaultOptionBuilder mahout_f3158_0()
{    return new DefaultOptionBuilder().withLongName(CLUSTERING_OPTION).withRequired(false).withDescription("If present, run clustering after the iterations have taken place").withShortName("cl");}
public static DefaultOptionBuilder mahout_f3159_0()
{    return new DefaultOptionBuilder().withLongName(ANALYZER_NAME_OPTION).withRequired(false).withDescription("If present, the name of a Lucene analyzer class to use").withArgument(new ArgumentBuilder().withName(ANALYZER_NAME_OPTION).withDefault(StandardAnalyzer.class.getName()).withMinimum(1).withMaximum(1).create()).withShortName("an");}
public static DefaultOptionBuilder mahout_f3160_0()
{    return new DefaultOptionBuilder().withLongName(EMIT_MOST_LIKELY_OPTION).withRequired(false).withShortName("e").withArgument(new ArgumentBuilder().withName(EMIT_MOST_LIKELY_OPTION).withDefault("true").withMinimum(1).withMaximum(1).create()).withDescription("True if clustering should emit the most likely point only, " + "false for threshold clustering. Default is true");}
public static DefaultOptionBuilder mahout_f3161_0()
{    return new DefaultOptionBuilder().withLongName(THRESHOLD_OPTION).withRequired(false).withShortName("t").withArgument(new ArgumentBuilder().withName(THRESHOLD_OPTION).withDefault("0").withMinimum(1).withMaximum(1).create()).withDescription("The pdf threshold used for cluster determination. Default is 0");}
public static DefaultOptionBuilder mahout_f3162_0()
{    return new DefaultOptionBuilder().withLongName(KERNEL_PROFILE_OPTION).withRequired(false).withShortName("kp").withArgument(new ArgumentBuilder().withName(KERNEL_PROFILE_OPTION).withDefault(TriangularKernelProfile.class.getName()).withMinimum(1).withMaximum(1).create()).withDescription("The classname of the IKernelProfile. Default is TriangularKernelProfile");}
public static DefaultOptionBuilder mahout_f3163_0()
{    return new DefaultOptionBuilder().withLongName(OUTLIER_THRESHOLD).withRequired(false).withArgument(new ArgumentBuilder().withName(OUTLIER_THRESHOLD).withMinimum(1).withMaximum(1).create()).withDescription("Outlier threshold value").withShortName(OUTLIER_THRESHOLD);}
public static void mahout_f3164_0(Group group)
{    HelpFormatter formatter = new HelpFormatter();    formatter.setGroup(group);    formatter.print();}
public static void mahout_f3165_0(Group group) throws IOException
{    new GenericOptionsParser(new Configuration(), new org.apache.commons.cli.Options(), new String[0]);    PrintWriter pw = new PrintWriter(new OutputStreamWriter(System.out, Charsets.UTF_8), true);    HelpFormatter formatter = new HelpFormatter();    formatter.setGroup(group);    formatter.setPrintWriter(pw);    formatter.setFooter("Specify HDFS directories while running on hadoop; else specify local file system directories");    formatter.print();}
public static void mahout_f3166_0(Group group, OptionException oe) throws IOException
{    new GenericOptionsParser(new Configuration(), new org.apache.commons.cli.Options(), new String[0]);    PrintWriter pw = new PrintWriter(new OutputStreamWriter(System.out, Charsets.UTF_8), true);    HelpFormatter formatter = new HelpFormatter();    formatter.setGroup(group);    formatter.setPrintWriter(pw);    formatter.setException(oe);    formatter.print();}
public void mahout_f3167_0(Configuration job)
{}
public Collection<Parameter<?>> mahout_f3168_0()
{    return Collections.emptyList();}
public void mahout_f3169_0(String prefix, Configuration jobConf)
{}
public double mahout_f3170_0(Vector v1, Vector v2)
{    if (v1.size() != v2.size()) {        throw new CardinalityException(v1.size(), v2.size());    }    return v1.aggregate(v2, Functions.MAX_ABS, Functions.MINUS);}
public double mahout_f3171_0(double centroidLengthSquare, Vector centroid, Vector v)
{        return distance(centroid, v);}
public void mahout_f3172_0(Configuration job)
{}
public Collection<Parameter<?>> mahout_f3173_0()
{    return Collections.emptyList();}
public void mahout_f3174_0(String prefix, Configuration jobConf)
{}
public static double mahout_f3175_0(double[] p1, double[] p2)
{    double dotProduct = 0.0;    double lengthSquaredp1 = 0.0;    double lengthSquaredp2 = 0.0;    for (int i = 0; i < p1.length; i++) {        lengthSquaredp1 += p1[i] * p1[i];        lengthSquaredp2 += p2[i] * p2[i];        dotProduct += p1[i] * p2[i];    }    double denominator = Math.sqrt(lengthSquaredp1) * Math.sqrt(lengthSquaredp2);        if (denominator < dotProduct) {        denominator = dotProduct;    }        if (denominator == 0 && dotProduct == 0) {        return 0;    }    return 1.0 - dotProduct / denominator;}
public double mahout_f3176_0(Vector v1, Vector v2)
{    if (v1.size() != v2.size()) {        throw new CardinalityException(v1.size(), v2.size());    }    double lengthSquaredv1 = v1.getLengthSquared();    double lengthSquaredv2 = v2.getLengthSquared();    double dotProduct = v2.dot(v1);    double denominator = Math.sqrt(lengthSquaredv1) * Math.sqrt(lengthSquaredv2);        if (denominator < dotProduct) {        denominator = dotProduct;    }        if (denominator == 0 && dotProduct == 0) {        return 0;    }    return 1.0 - dotProduct / denominator;}
public double mahout_f3177_0(double centroidLengthSquare, Vector centroid, Vector v)
{    double lengthSquaredv = v.getLengthSquared();    double dotProduct = v.dot(centroid);    double denominator = Math.sqrt(centroidLengthSquare) * Math.sqrt(lengthSquaredv);        if (denominator < dotProduct) {        denominator = dotProduct;    }        if (denominator == 0 && dotProduct == 0) {        return 0;    }    return 1.0 - dotProduct / denominator;}
public double mahout_f3178_0(Vector v1, Vector v2)
{    return Math.sqrt(super.distance(v1, v2));}
public double mahout_f3179_0(double centroidLengthSquare, Vector centroid, Vector v)
{    return Math.sqrt(super.distance(centroidLengthSquare, centroid, v));}
public void mahout_f3180_0(Configuration jobConf)
{    if (parameters == null) {        ParameteredGeneralizations.configureParameters(this, jobConf);    }    try {        if (inverseCovarianceFile.get() != null) {            FileSystem fs = FileSystem.get(inverseCovarianceFile.get().toUri(), jobConf);            MatrixWritable inverseCovarianceMatrix = ClassUtils.instantiateAs((Class<? extends MatrixWritable>) matrixClass.get(), MatrixWritable.class);            if (!fs.exists(inverseCovarianceFile.get())) {                throw new FileNotFoundException(inverseCovarianceFile.get().toString());            }            try (DataInputStream in = fs.open(inverseCovarianceFile.get())) {                inverseCovarianceMatrix.readFields(in);            }            this.inverseCovarianceMatrix = inverseCovarianceMatrix.get();            Preconditions.checkArgument(this.inverseCovarianceMatrix != null, "inverseCovarianceMatrix not initialized");        }        if (meanVectorFile.get() != null) {            FileSystem fs = FileSystem.get(meanVectorFile.get().toUri(), jobConf);            VectorWritable meanVector = ClassUtils.instantiateAs((Class<? extends VectorWritable>) vectorClass.get(), VectorWritable.class);            if (!fs.exists(meanVectorFile.get())) {                throw new FileNotFoundException(meanVectorFile.get().toString());            }            try (DataInputStream in = fs.open(meanVectorFile.get())) {                meanVector.readFields(in);            }            this.meanVector = meanVector.get();            Preconditions.checkArgument(this.meanVector != null, "meanVector not initialized");        }    } catch (IOException e) {        throw new IllegalStateException(e);    }}
public Collection<Parameter<?>> mahout_f3181_0()
{    return parameters;}
public void mahout_f3182_0(String prefix, Configuration jobConf)
{    parameters = new ArrayList<>();    inverseCovarianceFile = new PathParameter(prefix, "inverseCovarianceFile", jobConf, null, "Path on DFS to a file containing the inverse covariance matrix.");    parameters.add(inverseCovarianceFile);    matrixClass = new ClassParameter(prefix, "maxtrixClass", jobConf, DenseMatrix.class, "Class<Matix> file specified in parameter inverseCovarianceFile has been serialized with.");    parameters.add(matrixClass);    meanVectorFile = new PathParameter(prefix, "meanVectorFile", jobConf, null, "Path on DFS to a file containing the mean Vector.");    parameters.add(meanVectorFile);    vectorClass = new ClassParameter(prefix, "vectorClass", jobConf, DenseVector.class, "Class file specified in parameter meanVectorFile has been serialized with.");    parameters.add(vectorClass);}
public double mahout_f3183_0(Vector v)
{    return Math.sqrt(v.minus(meanVector).dot(Algebra.mult(inverseCovarianceMatrix, v.minus(meanVector))));}
public double mahout_f3184_0(Vector v1, Vector v2)
{    if (v1.size() != v2.size()) {        throw new CardinalityException(v1.size(), v2.size());    }    return Math.sqrt(v1.minus(v2).dot(Algebra.mult(inverseCovarianceMatrix, v1.minus(v2))));}
public double mahout_f3185_0(double centroidLengthSquare, Vector centroid, Vector v)
{        return distance(centroid, v);}
public void mahout_f3186_0(Matrix inverseCovarianceMatrix)
{    Preconditions.checkArgument(inverseCovarianceMatrix != null, "inverseCovarianceMatrix not initialized");    this.inverseCovarianceMatrix = inverseCovarianceMatrix;}
public void mahout_f3187_0(Matrix m)
{    if (m.numRows() != m.numCols()) {        throw new CardinalityException(m.numRows(), m.numCols());    }                SingularValueDecomposition svd = new SingularValueDecomposition(m);    Matrix sInv = svd.getS();        for (int i = 0; i < sInv.numRows(); i++) {        double diagElem = sInv.get(i, i);        if (diagElem > 0.0) {            sInv.set(i, i, 1 / diagElem);        } else {            throw new IllegalStateException("Eigen Value equals to 0 found.");        }    }    inverseCovarianceMatrix = svd.getU().times(sInv.times(svd.getU().transpose()));    Preconditions.checkArgument(inverseCovarianceMatrix != null, "inverseCovarianceMatrix not initialized");}
public Matrix mahout_f3188_0()
{    return inverseCovarianceMatrix;}
public void mahout_f3189_0(Vector meanVector)
{    Preconditions.checkArgument(meanVector != null, "meanVector not initialized");    this.meanVector = meanVector;}
public Vector mahout_f3190_0()
{    return meanVector;}
public static double mahout_f3191_0(double[] p1, double[] p2)
{    double result = 0.0;    for (int i = 0; i < p1.length; i++) {        result += Math.abs(p2[i] - p1[i]);    }    return result;}
public void mahout_f3192_0(Configuration job)
{}
public Collection<Parameter<?>> mahout_f3193_0()
{    return Collections.emptyList();}
public void mahout_f3194_0(String prefix, Configuration jobConf)
{}
public double mahout_f3195_0(Vector v1, Vector v2)
{    if (v1.size() != v2.size()) {        throw new CardinalityException(v1.size(), v2.size());    }    return v1.aggregate(v2, Functions.PLUS, Functions.MINUS_ABS);}
public double mahout_f3196_0(double centroidLengthSquare, Vector centroid, Vector v)
{        return distance(centroid, v);}
public void mahout_f3197_0(String prefix, Configuration conf)
{    parameters = new ArrayList<>();    Parameter<?> param = new DoubleParameter(prefix, "exponent", conf, EXPONENT, "Exponent for Fractional Lagrange distance");    parameters.add(param);}
public Collection<Parameter<?>> mahout_f3198_0()
{    return parameters;}
public void mahout_f3199_0(Configuration jobConf)
{    if (parameters == null) {        ParameteredGeneralizations.configureParameters(this, jobConf);    }}
public double mahout_f3200_0()
{    return exponent;}
public void mahout_f3201_0(double exponent)
{    this.exponent = exponent;}
public double mahout_f3202_0(Vector v1, Vector v2)
{    return Math.pow(v1.aggregate(v2, Functions.PLUS, Functions.minusAbsPow(exponent)), 1.0 / exponent);}
public double mahout_f3203_0(double centroidLengthSquare, Vector centroid, Vector v)
{        return distance(centroid, v);}
public void mahout_f3204_0(Configuration job)
{}
public Collection<Parameter<?>> mahout_f3205_0()
{    return Collections.emptyList();}
public void mahout_f3206_0(String prefix, Configuration jobConf)
{}
public double mahout_f3207_0(Vector v1, Vector v2)
{    return v2.getDistanceSquared(v1);}
public double mahout_f3208_0(double centroidLengthSquare, Vector centroid, Vector v)
{    return centroidLengthSquare - 2 * v.dot(centroid) + v.getLengthSquared();}
public double mahout_f3209_0(Vector a, Vector b)
{    double ab;    double denominator;    if (getWeights() != null) {        ab = a.times(b).aggregate(getWeights(), Functions.PLUS, Functions.MULT);        denominator = a.aggregate(getWeights(), Functions.PLUS, Functions.MULT_SQUARE_LEFT) + b.aggregate(getWeights(), Functions.PLUS, Functions.MULT_SQUARE_LEFT) - ab;    } else {                ab = b.dot(a);        denominator = a.getLengthSquared() + b.getLengthSquared() - ab;    }    if (denominator < ab) {                denominator = ab;    }    if (denominator > 0) {                return 1.0 - ab / denominator;    } else {        return 0.0;    }}
public double mahout_f3210_0(double centroidLengthSquare, Vector centroid, Vector v)
{        return distance(centroid, v);}
public void mahout_f3211_0(String prefix, Configuration jobConf)
{    parameters = new ArrayList<>();    weightsFile = new PathParameter(prefix, "weightsFile", jobConf, null, "Path on DFS to a file containing the weights.");    parameters.add(weightsFile);    vectorClass = new ClassParameter(prefix, "vectorClass", jobConf, DenseVector.class, "Class<Vector> file specified in parameter weightsFile has been serialized with.");    parameters.add(vectorClass);}
public Collection<Parameter<?>> mahout_f3212_0()
{    return parameters;}
public void mahout_f3213_0(Configuration jobConf)
{    if (parameters == null) {        ParameteredGeneralizations.configureParameters(this, jobConf);    }    try {        if (weightsFile.get() != null) {            FileSystem fs = FileSystem.get(weightsFile.get().toUri(), jobConf);            VectorWritable weights = ClassUtils.instantiateAs((Class<? extends VectorWritable>) vectorClass.get(), VectorWritable.class);            if (!fs.exists(weightsFile.get())) {                throw new FileNotFoundException(weightsFile.get().toString());            }            try (DataInputStream in = fs.open(weightsFile.get())) {                weights.readFields(in);            }            this.weights = weights.get();        }    } catch (IOException e) {        throw new IllegalStateException(e);    }}
public Vector mahout_f3214_0()
{    return weights;}
public void mahout_f3215_0(Vector weights)
{    this.weights = weights;}
public double mahout_f3216_0(Vector p1, Vector p2)
{    double result = 0;    Vector res = p2.minus(p1);    Vector theWeights = getWeights();    if (theWeights == null) {        for (Element elt : res.nonZeroes()) {            result += elt.get() * elt.get();        }    } else {        for (Element elt : res.nonZeroes()) {            result += elt.get() * elt.get() * theWeights.get(elt.index());        }    }    return Math.sqrt(result);}
public double mahout_f3217_0(double centroidLengthSquare, Vector centroid, Vector v)
{        return distance(centroid, v);}
public double mahout_f3218_0(Vector p1, Vector p2)
{    double result = 0;    Vector res = p2.minus(p1);    if (getWeights() == null) {        for (Element elt : res.nonZeroes()) {            result += Math.abs(elt.get());        }    } else {        for (Element elt : res.nonZeroes()) {            result += Math.abs(elt.get() * getWeights().get(elt.index()));        }    }    return result;}
public double mahout_f3219_0(double centroidLengthSquare, Vector centroid, Vector v)
{        return distance(centroid, v);}
public static Job mahout_f3220_0(Path inputPath, Path outputPath, Class<? extends InputFormat> inputFormat, Class<? extends Mapper> mapper, Class<? extends Writable> mapperKey, Class<? extends Writable> mapperValue, Class<? extends OutputFormat> outputFormat, Configuration conf) throws IOException
{    Job job = new Job(new Configuration(conf));    Configuration jobConf = job.getConfiguration();    if (mapper.equals(Mapper.class)) {        throw new IllegalStateException("Can't figure out the user class jar file from mapper/reducer");    }    job.setJarByClass(mapper);    job.setInputFormatClass(inputFormat);    jobConf.set("mapred.input.dir", inputPath.toString());    job.setMapperClass(mapper);    job.setMapOutputKeyClass(mapperKey);    job.setMapOutputValueClass(mapperValue);    job.setOutputKeyClass(mapperKey);    job.setOutputValueClass(mapperValue);    jobConf.setBoolean("mapred.compress.map.output", true);    job.setNumReduceTasks(0);    job.setOutputFormatClass(outputFormat);    jobConf.set("mapred.output.dir", outputPath.toString());    return job;}
public static Job mahout_f3221_0(Path inputPath, Path outputPath, Class<? extends InputFormat> inputFormat, Class<? extends Mapper> mapper, Class<? extends Writable> mapperKey, Class<? extends Writable> mapperValue, Class<? extends Reducer> reducer, Class<? extends Writable> reducerKey, Class<? extends Writable> reducerValue, Class<? extends OutputFormat> outputFormat, Configuration conf) throws IOException
{    Job job = new Job(new Configuration(conf));    Configuration jobConf = job.getConfiguration();    if (reducer.equals(Reducer.class)) {        if (mapper.equals(Mapper.class)) {            throw new IllegalStateException("Can't figure out the user class jar file from mapper/reducer");        }        job.setJarByClass(mapper);    } else {        job.setJarByClass(reducer);    }    job.setInputFormatClass(inputFormat);    jobConf.set("mapred.input.dir", inputPath.toString());    job.setMapperClass(mapper);    if (mapperKey != null) {        job.setMapOutputKeyClass(mapperKey);    }    if (mapperValue != null) {        job.setMapOutputValueClass(mapperValue);    }    jobConf.setBoolean("mapred.compress.map.output", true);    job.setReducerClass(reducer);    job.setOutputKeyClass(reducerKey);    job.setOutputValueClass(reducerValue);    job.setOutputFormatClass(outputFormat);    jobConf.set("mapred.output.dir", outputPath.toString());    return job;}
public static String mahout_f3222_0(String className, JobContext job, Class<? extends Mapper> mapper, Class<? extends Reducer> reducer)
{    StringBuilder name = new StringBuilder(100);    String customJobName = job.getJobName();    if (customJobName == null || customJobName.trim().isEmpty()) {        name.append(className);    } else {        name.append(customJobName);    }    name.append('-').append(mapper.getSimpleName());    name.append('-').append(reducer.getSimpleName());    return name.toString();}
public static void mahout_f3223_1(Configuration conf, Iterable<Path> paths) throws IOException
{    if (conf == null) {        conf = new Configuration();    }    for (Path path : paths) {        FileSystem fs = path.getFileSystem(conf);        if (fs.exists(path)) {                        fs.delete(path, true);        }    }}
public static void mahout_f3224_0(Configuration conf, Path... paths) throws IOException
{    delete(conf, Arrays.asList(paths));}
public static long mahout_f3225_0(Path path, Configuration conf) throws IOException
{    long count = 0;    Iterator<?> iterator = new SequenceFileValueIterator<>(path, true, conf);    while (iterator.hasNext()) {        iterator.next();        count++;    }    return count;}
public static long mahout_f3226_0(Path path, PathType pt, PathFilter filter, Configuration conf) throws IOException
{    long count = 0;    Iterator<?> iterator = new SequenceFileDirValueIterator<>(path, pt, filter, null, true, conf);    while (iterator.hasNext()) {        iterator.next();        count++;    }    return count;}
public static InputStream mahout_f3227_0(Path path, Configuration conf) throws IOException
{    FileSystem fs = FileSystem.get(path.toUri(), conf);    return fs.open(path.makeQualified(path.toUri(), path));}
public static FileStatus[] mahout_f3228_0(Path path, PathType pathType, PathFilter filter, Comparator<FileStatus> ordering, Configuration conf) throws IOException
{    FileStatus[] statuses;    FileSystem fs = path.getFileSystem(conf);    if (filter == null) {        statuses = pathType == PathType.GLOB ? fs.globStatus(path) : listStatus(fs, path);    } else {        statuses = pathType == PathType.GLOB ? fs.globStatus(path, filter) : listStatus(fs, path, filter);    }    if (ordering != null) {        Arrays.sort(statuses, ordering);    }    return statuses;}
public static FileStatus[] mahout_f3229_0(FileSystem fs, Path path) throws IOException
{    try {        return fs.listStatus(path);    } catch (FileNotFoundException e) {        return new FileStatus[0];    }}
public static FileStatus[] mahout_f3230_0(FileSystem fs, Path path, PathFilter filter) throws IOException
{    try {        return fs.listStatus(path, filter);    } catch (FileNotFoundException e) {        return new FileStatus[0];    }}
public static void mahout_f3231_0(Path fileToCache, Configuration conf)
{    DistributedCache.setCacheFiles(new URI[] { fileToCache.toUri() }, conf);}
public static Path mahout_f3232_0(Configuration conf) throws IOException
{    return getCachedFiles(conf)[0];}
public static Path[] mahout_f3233_0(Configuration conf) throws IOException
{    LocalFileSystem localFs = FileSystem.getLocal(conf);    Path[] cacheFiles = DistributedCache.getLocalCacheFiles(conf);    URI[] fallbackFiles = DistributedCache.getCacheFiles(conf);        if (cacheFiles == null) {        Preconditions.checkState(fallbackFiles != null, "Unable to find cached files!");        cacheFiles = new Path[fallbackFiles.length];        for (int n = 0; n < fallbackFiles.length; n++) {            cacheFiles[n] = new Path(fallbackFiles[n].getPath());        }    } else {        for (int n = 0; n < cacheFiles.length; n++) {            cacheFiles[n] = localFs.makeQualified(cacheFiles[n]);                        if (!localFs.exists(cacheFiles[n])) {                cacheFiles[n] = new Path(fallbackFiles[n].getPath());            }        }    }    Preconditions.checkState(cacheFiles.length > 0, "Unable to find cached files!");    return cacheFiles;}
public static void mahout_f3234_0(Configuration configuration)
{    configuration.set("io.serializations", "org.apache.hadoop.io.serializer.JavaSerialization," + "org.apache.hadoop.io.serializer.WritableSerialization");}
public static void mahout_f3235_0(int value, Path path, Configuration configuration) throws IOException
{    FileSystem fs = FileSystem.get(path.toUri(), configuration);    try (FSDataOutputStream out = fs.create(path)) {        out.writeInt(value);    }}
public static int mahout_f3236_0(Path path, Configuration configuration) throws IOException
{    FileSystem fs = FileSystem.get(path.toUri(), configuration);    try (FSDataInputStream in = fs.open(path)) {        return in.readInt();    }}
public static String mahout_f3237_0(FileSystem fs, FileStatus fileStatus) throws IOException
{    boolean containsFiles = false;    List<String> directoriesList = new ArrayList<>();    for (FileStatus childFileStatus : fs.listStatus(fileStatus.getPath())) {        if (childFileStatus.isDir()) {            String subDirectoryList = buildDirList(fs, childFileStatus);            directoriesList.add(subDirectoryList);        } else {            containsFiles = true;        }    }    if (containsFiles) {        directoriesList.add(fileStatus.getPath().toUri().getPath());    }    return Joiner.on(',').skipNulls().join(directoriesList.iterator());}
public static String mahout_f3238_0(FileSystem fs, FileStatus fileStatus, PathFilter pathFilter) throws IOException
{    boolean containsFiles = false;    List<String> directoriesList = new ArrayList<>();    for (FileStatus childFileStatus : fs.listStatus(fileStatus.getPath(), pathFilter)) {        if (childFileStatus.isDir()) {            String subDirectoryList = buildDirList(fs, childFileStatus);            directoriesList.add(subDirectoryList);        } else {            containsFiles = true;        }    }    if (containsFiles) {        directoriesList.add(fileStatus.getPath().toUri().getPath());    }    return Joiner.on(',').skipNulls().join(directoriesList.iterator());}
public static String mahout_f3239_0(Configuration configuration, Path filePath) throws IOException
{    FileSystem fs = filePath.getFileSystem(configuration);    FileStatus fst = fs.getFileStatus(filePath);    String currentPath = fst.getPath().toString().replaceFirst("file:", "");    String basePath = configuration.get("baseinputpath");    if (!basePath.endsWith("/")) {        basePath += "/";    }    basePath = basePath.replaceFirst("file:", "");    String[] parts = currentPath.split(basePath);    if (parts.length == 2) {        return parts[1];    } else if (parts.length == 1) {        return parts[0];    }    return currentPath;}
public static Path mahout_f3240_1(String partOfFilename, URI[] localFiles)
{    for (URI distCacheFile : localFiles) {                if (distCacheFile != null && distCacheFile.toString().contains(partOfFilename)) {                        return new Path(distCacheFile.getPath());        }    }    return null;}
public boolean mahout_f3241_0(Integer entry)
{    return tuple.add(entry);}
public Integer mahout_f3242_0(int index)
{    return tuple.get(index);}
public Integer mahout_f3243_0(int index, Integer newInteger)
{    return tuple.set(index, newInteger);}
public List<Integer> mahout_f3244_0()
{    return Collections.unmodifiableList(this.tuple);}
public int mahout_f3245_0()
{    return this.tuple.size();}
public String mahout_f3246_0()
{    return tuple.toString();}
public int mahout_f3247_0()
{    return tuple.hashCode();}
public boolean mahout_f3248_0(Object obj)
{    if (this == obj) {        return true;    }    if (obj == null) {        return false;    }    if (getClass() != obj.getClass()) {        return false;    }    IntegerTuple other = (IntegerTuple) obj;    if (tuple == null) {        if (other.tuple != null) {            return false;        }    } else if (!tuple.equals(other.tuple)) {        return false;    }    return true;}
public void mahout_f3249_0(DataInput in) throws IOException
{    int len = in.readInt();    tuple = Lists.newArrayListWithCapacity(len);    for (int i = 0; i < len; i++) {        int data = in.readInt();        tuple.add(data);    }}
public void mahout_f3250_0(DataOutput out) throws IOException
{    out.writeInt(tuple.size());    for (Integer entry : tuple) {        out.writeInt(entry);    }}
public int mahout_f3251_0(IntegerTuple otherTuple)
{    int thisLength = length();    int otherLength = otherTuple.length();    int min = Math.min(thisLength, otherLength);    for (int i = 0; i < min; i++) {        int ret = this.tuple.get(i).compareTo(otherTuple.integerAt(i));        if (ret == 0) {            continue;        }        return ret;    }    if (thisLength < otherLength) {        return -1;    } else if (thisLength > otherLength) {        return 1;    } else {        return 0;    }}
public void mahout_f3252_0(int x, int y)
{    putInt(x, b, 0);    putInt(y, b, INT_BYTE_LENGTH);}
public void mahout_f3253_0(int x)
{    putInt(x, b, 0);}
public int mahout_f3254_0()
{    return getInt(b, 0);}
public void mahout_f3255_0(int y)
{    putInt(y, b, INT_BYTE_LENGTH);}
public int mahout_f3256_0()
{    return getInt(b, INT_BYTE_LENGTH);}
public void mahout_f3257_0(DataInput in) throws IOException
{    in.readFully(b);}
public void mahout_f3258_0(DataOutput out) throws IOException
{    out.write(b);}
public int mahout_f3259_0()
{    return Arrays.hashCode(b);}
public boolean mahout_f3260_0(Object obj)
{    if (this == obj) {        return true;    }    if (!super.equals(obj)) {        return false;    }    if (!(obj instanceof IntPairWritable)) {        return false;    }    IntPairWritable other = (IntPairWritable) obj;    return Arrays.equals(b, other.b);}
public int mahout_f3261_0(BinaryComparable other)
{    return Comparator.doCompare(b, 0, ((IntPairWritable) other).b, 0);}
public Object mahout_f3262_0()
{    return new IntPairWritable(this);}
public String mahout_f3263_0()
{    return "(" + getFirst() + ", " + getSecond() + ')';}
public byte[] mahout_f3264_0()
{    return b;}
public int mahout_f3265_0()
{    return INT_PAIR_BYTE_LENGTH;}
private static void mahout_f3266_0(int value, byte[] b, int offset)
{    for (int i = offset, j = 24; j >= 0; i++, j -= 8) {        b[i] = (byte) (value >> j);    }}
private static int mahout_f3267_0(byte[] b, int offset)
{    int value = 0;    for (int i = offset, j = 24; j >= 0; i++, j -= 8) {        value |= (b[i] & 0xFF) << j;    }    return value;}
public int mahout_f3268_0(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2)
{    return doCompare(b1, s1, b2, s2);}
 static int mahout_f3269_0(byte[] b1, int s1, byte[] b2, int s2)
{    int compare1 = compareInts(b1, s1, b2, s2);    if (compare1 != 0) {        return compare1;    }    return compareInts(b1, s1 + INT_BYTE_LENGTH, b2, s2 + INT_BYTE_LENGTH);}
private static int mahout_f3270_0(byte[] b1, int s1, byte[] b2, int s2)
{        int end1 = s1 + INT_BYTE_LENGTH;    for (int i = s1, j = s2; i < end1; i++, j++) {        int a = b1[i];        int b = b2[j];        if (i > s1) {            a &= 0xff;            b &= 0xff;        }        if (a != b) {            return a - b;        }    }    return 0;}
public int mahout_f3271_0(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2)
{    int firstb1 = WritableComparator.readInt(b1, s1);    int firstb2 = WritableComparator.readInt(b2, s2);    if (firstb1 < firstb2) {        return -1;    } else if (firstb1 > firstb2) {        return 1;    } else {        return 0;    }}
public int mahout_f3272_0(Object o1, Object o2)
{    int firstb1 = ((IntPairWritable) o1).getFirst();    int firstb2 = ((IntPairWritable) o2).getFirst();    if (firstb1 < firstb2) {        return -1;    }    if (firstb1 > firstb2) {        return 1;    }    return 0;}
public double mahout_f3273_0()
{    return frequency;}
public IntPairWritable mahout_f3274_0()
{    return pair;}
public int mahout_f3275_0()
{    return pair.hashCode() + RandomUtils.hashDouble(frequency);}
public boolean mahout_f3276_0(Object right)
{    if (!(right instanceof Frequency)) {        return false;    }    Frequency that = (Frequency) right;    return pair.equals(that.pair) && frequency == that.frequency;}
public int mahout_f3277_0(Frequency that)
{    if (frequency < that.frequency) {        return -1;    }    if (frequency > that.frequency) {        return 1;    }    return 0;}
public String mahout_f3278_0()
{    return pair + "\t" + frequency;}
public T mahout_f3279_0(T from)
{    if (constructor == null) {        Class<T> elementClass = (Class<T>) from.getClass();        try {            constructor = elementClass.getConstructor(elementClass);        } catch (NoSuchMethodException e) {            throw new IllegalStateException(e);        }    }    try {        return constructor.newInstance(from);    } catch (InstantiationException | IllegalAccessException | InvocationTargetException e) {        throw new IllegalStateException(e);    }}
protected Iterator<T> mahout_f3280_0()
{    return delegate;}
protected Integer mahout_f3281_0()
{    if (count < to) {        return count++;    } else {        return endOfData();    }}
public Iterator<String> mahout_f3282_0()
{    try {        return new FileLineIterator(is, encoding, skipFirstLine, this.origFilename);    } catch (IOException ioe) {        throw new IllegalStateException(ioe);    }}
 static InputStream mahout_f3283_0(File file) throws IOException
{    InputStream is = new FileInputStream(file);    String name = file.getName();    if ("gz".equalsIgnoreCase(Files.getFileExtension(name.toLowerCase()))) {        return new GZIPInputStream(is);    } else if ("zip".equalsIgnoreCase(Files.getFileExtension(name.toLowerCase()))) {        return new ZipInputStream(is);    } else {        return is;    }}
protected String mahout_f3284_1()
{    String line;    try {        line = reader.readLine();    } catch (IOException ioe) {        try {            close();        } catch (IOException e) {                    }        throw new IllegalStateException(ioe);    }    return line == null ? endOfData() : line;}
public void mahout_f3285_0(int n)
{    try {        for (int i = 0; i < n; i++) {            if (reader.readLine() == null) {                break;            }        }    } catch (IOException ioe) {        try {            close();        } catch (IOException e) {            throw new IllegalStateException(e);        }    }}
public void mahout_f3286_0() throws IOException
{    endOfData();    Closeables.close(reader, true);}
protected Iterator<T> mahout_f3287_0()
{    return delegate;}
public Iterator<T> mahout_f3288_0()
{    return new SamplingIterator<>(delegate.iterator(), samplingRate);}
public static Iterable<T> mahout_f3289_0(Iterable<T> delegate, double samplingRate)
{    return samplingRate >= 1.0 ? delegate : new SamplingIterable<>(delegate, samplingRate);}
protected T mahout_f3290_0()
{    int toSkip = geometricDistribution.sample();    if (delegate instanceof SkippingIterator<?>) {        SkippingIterator<? extends T> skippingDelegate = (SkippingIterator<? extends T>) delegate;        skippingDelegate.skip(toSkip);        if (skippingDelegate.hasNext()) {            return skippingDelegate.next();        }    } else {        for (int i = 0; i < toSkip && delegate.hasNext(); i++) {            delegate.next();        }        if (delegate.hasNext()) {            return delegate.next();        }    }    return endOfData();}
public boolean mahout_f3291_0(Path path)
{    String name = path.getName();    return name.startsWith("part-") && !name.endsWith(".crc");}
public boolean mahout_f3292_0(Path path)
{    String name = path.getName();    return name.startsWith("clusters-") && name.endsWith("-final");}
public boolean mahout_f3293_0(Path path)
{    String name = path.getName();    return !(name.endsWith(".crc") || name.startsWith(".") || name.startsWith("_"));}
public static PathFilter mahout_f3294_0()
{    return PART_FILE_INSTANCE;}
public static PathFilter mahout_f3295_0()
{    return CLUSTER_FINAL;}
public static PathFilter mahout_f3296_0()
{    return LOGS_CRC_INSTANCE;}
public Iterator<Pair<K, V>> mahout_f3297_0()
{    try {        return new SequenceFileDirIterator<>(path, pathType, filter, ordering, reuseKeyValueInstances, conf);    } catch (IOException ioe) {        throw new IllegalStateException(path.toString(), ioe);    }}
private void mahout_f3298_0(FileStatus[] statuses, final boolean reuseKeyValueInstances, final Configuration conf)
{    /*     * prevent NPEs. Unfortunately, Hadoop would return null for list if nothing     * was qualified. In this case, which is a corner case, we should assume an     * empty iterator, not an NPE.     */    if (statuses == null) {        statuses = NO_STATUSES;    }    Iterator<FileStatus> fileStatusIterator = Iterators.forArray(statuses);    Iterator<Iterator<Pair<K, V>>> fsIterators = Iterators.transform(fileStatusIterator, new Function<FileStatus, Iterator<Pair<K, V>>>() {        @Override        public Iterator<Pair<K, V>> apply(FileStatus from) {            try {                SequenceFileIterator<K, V> iterator = new SequenceFileIterator<>(from.getPath(), reuseKeyValueInstances, conf);                iterators.add(iterator);                return iterator;            } catch (IOException ioe) {                throw new IllegalStateException(from.getPath().toString(), ioe);            }        }    });        Collections.reverse(iterators);    delegate = Iterators.concat(fsIterators);}
public Iterator<Pair<K, V>> mahout_f3299_0(FileStatus from)
{    try {        SequenceFileIterator<K, V> iterator = new SequenceFileIterator<>(from.getPath(), reuseKeyValueInstances, conf);        iterators.add(iterator);        return iterator;    } catch (IOException ioe) {        throw new IllegalStateException(from.getPath().toString(), ioe);    }}
protected Iterator<Pair<K, V>> mahout_f3300_0()
{    return delegate;}
public void mahout_f3301_0() throws IOException
{    IOUtils.close(iterators);    iterators.clear();}
public Iterator<V> mahout_f3302_0()
{    try {        return new SequenceFileDirValueIterator<>(path, pathType, filter, ordering, reuseKeyValueInstances, conf);    } catch (IOException ioe) {        throw new IllegalStateException(path.toString(), ioe);    }}
private void mahout_f3303_0(FileStatus[] statuses, Comparator<FileStatus> ordering, final boolean reuseKeyValueInstances, final Configuration conf) throws IOException
{    /*     * prevent NPEs. Unfortunately, Hadoop would return null for list if nothing     * was qualified. In this case, which is a corner case, we should assume an     * empty iterator, not an NPE.     */    if (statuses == null) {        statuses = NO_STATUSES;    }    if (ordering != null) {        Arrays.sort(statuses, ordering);    }    Iterator<FileStatus> fileStatusIterator = Iterators.forArray(statuses);    try {        Iterator<Iterator<V>> fsIterators = Iterators.transform(fileStatusIterator, new Function<FileStatus, Iterator<V>>() {            @Override            public Iterator<V> apply(FileStatus from) {                try {                    SequenceFileValueIterator<V> iterator = new SequenceFileValueIterator<>(from.getPath(), reuseKeyValueInstances, conf);                    iterators.add(iterator);                    return iterator;                } catch (IOException ioe) {                    throw new IllegalStateException(from.getPath().toString(), ioe);                }            }        });                Collections.reverse(iterators);        delegate = Iterators.concat(fsIterators);    } finally {        /*       * prevent file handle leaks in case one of handles fails to open. If some       * of the files fail to open, constructor will fail and close() will never       * be called. Thus, those handles that did open in constructor, would leak       * out, unless we specifically handle it here.       */        IOUtils.close(iterators);    }}
public Iterator<V> mahout_f3304_0(FileStatus from)
{    try {        SequenceFileValueIterator<V> iterator = new SequenceFileValueIterator<>(from.getPath(), reuseKeyValueInstances, conf);        iterators.add(iterator);        return iterator;    } catch (IOException ioe) {        throw new IllegalStateException(from.getPath().toString(), ioe);    }}
protected Iterator<V> mahout_f3305_0()
{    return delegate;}
public void mahout_f3306_0() throws IOException
{    IOUtils.close(iterators);}
public Iterator<Pair<K, V>> mahout_f3307_0()
{    try {        return new SequenceFileIterator<>(path, reuseKeyValueInstances, conf);    } catch (IOException ioe) {        throw new IllegalStateException(path.toString(), ioe);    }}
public Class<K> mahout_f3308_0()
{    return keyClass;}
public Class<V> mahout_f3309_0()
{    return valueClass;}
public void mahout_f3310_0() throws IOException
{    key = null;    value = null;    Closeables.close(reader, true);    endOfData();}
protected Pair<K, V> mahout_f3311_1()
{    if (!reuseKeyValueInstances || value == null) {        key = ReflectionUtils.newInstance(keyClass, conf);        if (!noValue) {            value = ReflectionUtils.newInstance(valueClass, conf);        }    }    try {        boolean available;        if (noValue) {            available = reader.next(key);        } else {            available = reader.next(key, value);        }        if (!available) {            close();            return null;        }        return new Pair<>(key, value);    } catch (IOException ioe) {        try {            close();        } catch (IOException e) {                    }        throw new IllegalStateException(ioe);    }}
public Iterator<V> mahout_f3312_0()
{    try {        return new SequenceFileValueIterator<>(path, reuseKeyValueInstances, conf);    } catch (IOException ioe) {        throw new IllegalStateException(path.toString(), ioe);    }}
public Class<V> mahout_f3313_0()
{    return valueClass;}
public void mahout_f3314_0() throws IOException
{    value = null;    Closeables.close(reader, true);    endOfData();}
protected V mahout_f3315_1()
{    if (!reuseKeyValueInstances || value == null) {        value = ReflectionUtils.newInstance(valueClass, conf);    }    try {        boolean available = reader.next(key, value);        if (!available) {            close();            return null;        }        return value;    } catch (IOException ioe) {        try {            close();        } catch (IOException e) {                    }        throw new IllegalStateException(ioe);    }}
public T mahout_f3316_0(Pair<Integer, T> from)
{    return from.getSecond();}
protected Iterator<T> mahout_f3317_0()
{    return delegate;}
public Pair<List<String>, Long> mahout_f3318_0(String from)
{    String[] items = splitter.split(from);    return new Pair<>(Arrays.asList(items), ONE);}
protected Iterator<Pair<List<String>, Long>> mahout_f3319_0()
{    return delegate;}
public long mahout_f3320_0()
{    return first;}
public long mahout_f3321_0()
{    return second;}
public LongPair mahout_f3322_0()
{    return new LongPair(second, first);}
public boolean mahout_f3323_0(Object obj)
{    if (!(obj instanceof LongPair)) {        return false;    }    LongPair otherPair = (LongPair) obj;    return first == otherPair.getFirst() && second == otherPair.getSecond();}
public int mahout_f3324_0()
{    int firstHash = Longs.hashCode(first);        return (firstHash >>> 16 | firstHash << 16) ^ Longs.hashCode(second);}
public String mahout_f3325_0()
{    return '(' + String.valueOf(first) + ',' + second + ')';}
public int mahout_f3326_0(LongPair o)
{    if (first < o.getFirst()) {        return -1;    } else if (first > o.getFirst()) {        return 1;    } else {        return second < o.getSecond() ? -1 : second > o.getSecond() ? 1 : 0;    }}
public static Analyzer mahout_f3327_0(String analyzerClassName) throws ClassNotFoundException
{    return createAnalyzer(analyzerClassName, Version.LUCENE_5_5_2);}
public static Analyzer mahout_f3328_0(String analyzerClassName, Version version) throws ClassNotFoundException
{    Class<? extends Analyzer> analyzerClass = Class.forName(analyzerClassName).asSubclass(Analyzer.class);    return createAnalyzer(analyzerClass, version);}
public static Analyzer mahout_f3329_0(Class<? extends Analyzer> analyzerClass)
{    return createAnalyzer(analyzerClass, Version.LUCENE_5_5_2);}
public static Analyzer mahout_f3330_0(Class<? extends Analyzer> analyzerClass, Version version)
{    try {        return ClassUtils.instantiateAs(analyzerClass, Analyzer.class, new Class<?>[] { Version.class }, new Object[] { version });    } catch (IllegalStateException e) {        return ClassUtils.instantiateAs(analyzerClass, Analyzer.class);    }}
public boolean mahout_f3331_0()
{    if (iterator.hasNext()) {        clearAttributes();        termAtt.append(iterator.next());        return true;    } else {        return false;    }}
protected String mahout_f3332_0()
{    try {        if (tokenStream.incrementToken()) {            return tokenStream.getAttribute(CharTermAttribute.class).toString();        } else {            tokenStream.end();            tokenStream.close();            return endOfData();        }    } catch (IOException e) {        throw new IllegalStateException("IO error while tokenizing", e);    }}
public void mahout_f3333_0(WritableComparable<?> key, Iterable<VectorWritable> vectors, Context ctx) throws IOException, InterruptedException
{    ctx.write(key, VectorWritable.merge(vectors.iterator()));}
public void mahout_f3334_0(WritableComparable<?> key, Iterable<VectorWritable> vectors, Context ctx) throws IOException, InterruptedException
{    Vector merged = VectorWritable.merge(vectors.iterator()).get();    result.set(new SequentialAccessSparseVector(merged));    ctx.write(key, result);}
protected void mahout_f3335_0(Context ctx) throws IOException, InterruptedException
{    newNumCols = ctx.getConfiguration().getInt(NEW_NUM_COLS_PARAM, Integer.MAX_VALUE);}
protected void mahout_f3336_0(IntWritable r, VectorWritable v, Context ctx) throws IOException, InterruptedException
{    int row = r.get();    for (Vector.Element e : v.get().nonZeroes()) {        RandomAccessSparseVector tmp = new RandomAccessSparseVector(newNumCols, 1);        tmp.setQuick(row, e.get());        r.set(e.index());        ctx.write(r, new VectorWritable(tmp));    }}
protected void mahout_f3337_0(WritableComparable<?> key, Iterable<VectorWritable> values, Context ctx) throws IOException, InterruptedException
{    result.set(Vectors.sum(values.iterator()));    ctx.write(key, result);}
protected void mahout_f3338_0(WritableComparable<?> key, Iterable<VectorWritable> values, Context ctx) throws IOException, InterruptedException
{    ctx.write(key, new VectorWritable(Vectors.sum(values.iterator())));}
public static void mahout_f3339_1()
{    Runtime runtime = Runtime.getRuntime();    long freeBytes = runtime.freeMemory();    long maxBytes = runtime.maxMemory();    long totalBytes = runtime.totalMemory();    long usedBytes = totalBytes - freeBytes;    }
public static void mahout_f3340_0(long rateInMillis)
{    stopMemoryLogger();    scheduler = Executors.newScheduledThreadPool(1, new ThreadFactory() {        private final ThreadFactory delegate = Executors.defaultThreadFactory();        @Override        public Thread newThread(Runnable r) {            Thread t = delegate.newThread(r);            t.setDaemon(true);            return t;        }    });    Runnable memoryLoogerRunnable = new Runnable() {        @Override        public void run() {            logMemoryStatistics();        }    };    scheduler.scheduleAtFixedRate(memoryLoogerRunnable, rateInMillis, rateInMillis, TimeUnit.MILLISECONDS);}
public Thread mahout_f3341_0(Runnable r)
{    Thread t = delegate.newThread(r);    t.setDaemon(true);    return t;}
public void mahout_f3342_0()
{    logMemoryStatistics();}
public static void mahout_f3343_0()
{    startMemoryLogger(1000);}
public static void mahout_f3344_0()
{    if (scheduler != null) {        scheduler.shutdownNow();        scheduler = null;    }}
public Map<String, List<String>> mahout_f3345_0()
{    Map<String, List<String>> returnDocument = Maps.newHashMap();    Iterator<String> tokenizer = SPACE_TAB.split(line).iterator();    List<String> tokens = Lists.newArrayList();    String labelName = tokenizer.next();    List<String> previousN1Grams = Lists.newArrayList();    while (tokenizer.hasNext()) {        String nextToken = tokenizer.next();        if (previousN1Grams.size() == gramSize) {            previousN1Grams.remove(0);        }        previousN1Grams.add(nextToken);        StringBuilder gramBuilder = new StringBuilder();        for (String gram : previousN1Grams) {            gramBuilder.append(gram);            String token = gramBuilder.toString();            tokens.add(token);            gramBuilder.append(' ');        }    }    returnDocument.put(labelName, tokens);    return returnDocument;}
public List<String> mahout_f3346_0()
{    List<String> tokens = Lists.newArrayList();    List<String> previousN1Grams = Lists.newArrayList();    for (String nextToken : SPACE_TAB.split(line)) {        if (previousN1Grams.size() == gramSize) {            previousN1Grams.remove(0);        }        previousN1Grams.add(nextToken);        StringBuilder gramBuilder = new StringBuilder();        for (String gram : previousN1Grams) {            gramBuilder.append(gram);            String token = gramBuilder.toString();            tokens.add(token);            gramBuilder.append(' ');        }    }    return tokens;}
public A mahout_f3347_0()
{    return first;}
public B mahout_f3348_0()
{    return second;}
public Pair<B, A> mahout_f3349_0()
{    return new Pair<>(second, first);}
public static Pair<A, B> mahout_f3350_0(A a, B b)
{    return new Pair<>(a, b);}
public boolean mahout_f3351_0(Object obj)
{    if (!(obj instanceof Pair<?, ?>)) {        return false;    }    Pair<?, ?> otherPair = (Pair<?, ?>) obj;    return isEqualOrNulls(first, otherPair.getFirst()) && isEqualOrNulls(second, otherPair.getSecond());}
private static boolean mahout_f3352_0(Object obj1, Object obj2)
{    return obj1 == null ? obj2 == null : obj1.equals(obj2);}
public int mahout_f3353_0()
{    int firstHash = hashCodeNull(first);        return (firstHash >>> 16 | firstHash << 16) ^ hashCodeNull(second);}
private static int mahout_f3354_0(Object obj)
{    return obj == null ? 0 : obj.hashCode();}
public String mahout_f3355_0()
{    return '(' + String.valueOf(first) + ',' + second + ')';}
public int mahout_f3356_0(Pair<A, B> other)
{    Comparable<A> thisFirst = (Comparable<A>) first;    A thatFirst = other.getFirst();    int compare = thisFirst.compareTo(thatFirst);    if (compare != 0) {        return compare;    }    Comparable<B> thisSecond = (Comparable<B>) second;    B thatSecond = other.getSecond();    return thisSecond.compareTo(thatSecond);}
public void mahout_f3357_0(Configuration jobConf)
{}
public void mahout_f3358_0(String prefix, Configuration jobConf)
{}
public String mahout_f3359_0()
{    if (value == null) {        return null;    }    return value.toString();}
public Collection<Parameter<?>> mahout_f3360_0()
{    return Collections.emptyList();}
public String mahout_f3361_0()
{    return prefix;}
public String mahout_f3362_0()
{    return name;}
public String mahout_f3363_0()
{    return description;}
public Class<T> mahout_f3364_0()
{    return type;}
public String mahout_f3365_0()
{    return defaultValue;}
public T mahout_f3366_0()
{    return value;}
public void mahout_f3367_0(T value)
{    this.value = value;}
public String mahout_f3368_0()
{    if (value != null) {        return value.toString();    } else {        return super.toString();    }}
public void mahout_f3369_0(String stringValue)
{    try {        set(Class.forName(stringValue));    } catch (ClassNotFoundException e) {        throw new IllegalStateException(e);    }}
public String mahout_f3370_0()
{    if (get() == null) {        return null;    }    return get().getName();}
public void mahout_f3371_0(String stringValue)
{    set(Double.valueOf(stringValue));}
public static void mahout_f3372_0(Parametered parametered, Configuration jobConf)
{    configureParameters(parametered.getClass().getSimpleName() + '.', parametered, jobConf);}
public static void mahout_f3373_0(String prefix, Parametered parametered, Configuration jobConf)
{    parametered.createParameters(prefix, jobConf);    configureParametersRecursively(parametered, prefix, jobConf);}
private static void mahout_f3374_1(Parametered parametered, String prefix, Configuration jobConf)
{    for (Parameter<?> parameter : parametered.getParameters()) {        if (log.isDebugEnabled()) {                    }        String name = prefix + parameter.name() + '.';        parameter.createParameters(name, jobConf);        parameter.configure(jobConf);        if (!parameter.getParameters().isEmpty()) {            configureParametersRecursively(parameter, name, jobConf);        }    }}
public static String mahout_f3375_0(Parametered parametered)
{    return new Help(parametered).toString();}
public static String mahout_f3376_0(Parametered parametered)
{    return new Conf(parametered).toString();}
public String mahout_f3377_0()
{    return sb.toString();}
private void mahout_f3378_0(Parametered parametered)
{    for (Parameter<?> parameter : parametered.getParameters()) {        int parameterNameLength = parameter.name().length();        if (parameterNameLength > longestName) {            longestName = parameterNameLength;        }        recurseCount(parameter);        numChars += parameter.description().length();    }}
private void mahout_f3379_0(Parametered parametered)
{    for (Parameter<?> parameter : parametered.getParameters()) {        sb.append(parameter.prefix());        sb.append(parameter.name());        int max = longestName - parameter.name().length() - parameter.prefix().length() + NAME_DESC_DISTANCE;        for (int i = 0; i < max; i++) {            sb.append(' ');        }        sb.append(parameter.description());        if (parameter.defaultValue() != null) {            sb.append(" (default value '");            sb.append(parameter.defaultValue());            sb.append("')");        }        sb.append('\n');        recurseWrite(parameter);    }}
public String mahout_f3380_0()
{    return sb.toString();}
private void mahout_f3381_0(Parametered parametered)
{    for (Parameter<?> parameter : parametered.getParameters()) {        int parameterNameLength = parameter.prefix().length() + parameter.name().length();        if (parameterNameLength > longestName) {            longestName = parameterNameLength;        }        numChars += parameterNameLength;                numChars += 5;        numChars += parameter.description().length();        if (parameter.getStringValue() != null) {            numChars += parameter.getStringValue().length();        }        recurseCount(parameter);    }}
private void mahout_f3382_0(Parametered parametered)
{    for (Parameter<?> parameter : parametered.getParameters()) {        sb.append("# ");        sb.append(parameter.description());        sb.append('\n');        sb.append(parameter.prefix());        sb.append(parameter.name());        sb.append(" = ");        if (parameter.getStringValue() != null) {            sb.append(parameter.getStringValue());        }        sb.append('\n');        sb.append('\n');        recurseWrite(parameter);    }}
public void mahout_f3383_0(String stringValue)
{    set(new Path(stringValue));}
public String mahout_f3384_0(String key)
{    return params.get(key);}
public String mahout_f3385_0(String key, String defaultValue)
{    String ret = params.get(key);    return ret == null ? defaultValue : ret;}
public void mahout_f3386_0(String key, String value)
{    params.put(key, value);}
public int mahout_f3387_0(String key, int defaultValue)
{    String ret = params.get(key);    return ret == null ? defaultValue : Integer.parseInt(ret);}
public String mahout_f3388_1()
{    Configuration conf = new Configuration();    conf.set("io.serializations", "org.apache.hadoop.io.serializer.JavaSerialization," + "org.apache.hadoop.io.serializer.WritableSerialization");    DefaultStringifier<Map<String, String>> mapStringifier = new DefaultStringifier<>(conf, GenericsUtil.getClass(params));    try {        return mapStringifier.toString(params);    } catch (IOException e) {                return "";    }}
public String mahout_f3389_0()
{    return params.toString();}
public static Map<String, String> mahout_f3390_0(String serializedString) throws IOException
{    Configuration conf = new Configuration();    conf.set("io.serializations", "org.apache.hadoop.io.serializer.JavaSerialization," + "org.apache.hadoop.io.serializer.WritableSerialization");    Map<String, String> params = Maps.newHashMap();    DefaultStringifier<Map<String, String>> mapStringifier = new DefaultStringifier<>(conf, GenericsUtil.getClass(params));    return mapStringifier.fromString(serializedString);}
public boolean mahout_f3391_0(String entry)
{    return tuple.add(entry);}
public String mahout_f3392_0(int index)
{    return tuple.get(index);}
public String mahout_f3393_0(int index, String newString)
{    return tuple.set(index, newString);}
public List<String> mahout_f3394_0()
{    return Collections.unmodifiableList(this.tuple);}
public int mahout_f3395_0()
{    return this.tuple.size();}
public String mahout_f3396_0()
{    return tuple.toString();}
public int mahout_f3397_0()
{    return tuple.hashCode();}
public boolean mahout_f3398_0(Object obj)
{    if (this == obj) {        return true;    }    if (obj == null) {        return false;    }    if (getClass() != obj.getClass()) {        return false;    }    StringTuple other = (StringTuple) obj;    if (tuple == null) {        if (other.tuple != null) {            return false;        }    } else if (!tuple.equals(other.tuple)) {        return false;    }    return true;}
public void mahout_f3399_0(DataInput in) throws IOException
{    int len = in.readInt();    tuple = Lists.newArrayListWithCapacity(len);    Text value = new Text();    for (int i = 0; i < len; i++) {        value.readFields(in);        tuple.add(value.toString());    }}
public void mahout_f3400_0(DataOutput out) throws IOException
{    out.writeInt(tuple.size());    Text value = new Text();    for (String entry : tuple) {        value.set(entry);        value.write(out);    }}
public int mahout_f3401_0(StringTuple otherTuple)
{    int thisLength = length();    int otherLength = otherTuple.length();    int min = Math.min(thisLength, otherLength);    for (int i = 0; i < min; i++) {        int ret = this.tuple.get(i).compareTo(otherTuple.stringAt(i));        if (ret != 0) {            return ret;        }    }    if (thisLength < otherLength) {        return -1;    } else if (thisLength > otherLength) {        return 1;    } else {        return 0;    }}
public static String mahout_f3402_0(Object obj)
{    return NEWLINE_PATTERN.matcher(XSTREAM.toXML(obj)).replaceAll("");}
public static T mahout_f3403_0(String str)
{    return (T) XSTREAM.fromXML(str);}
public static String mahout_f3404_0(CharSequence input)
{    return XMLRESERVED.matcher(input).replaceAll("_");}
public synchronized int mahout_f3405_0()
{    return nCalls;}
public synchronized long mahout_f3406_0()
{    return Math.max(0, minTime);}
public synchronized long mahout_f3407_0()
{    return maxTime;}
public synchronized long mahout_f3408_0()
{    return sumTime;}
public synchronized double mahout_f3409_0()
{    return sumSquaredTime;}
public synchronized long mahout_f3410_0()
{    return nCalls == 0 ? 0 : sumTime / nCalls;}
public synchronized long mahout_f3411_0()
{    if (nCalls == 0) {        return 0;    }    double mean = getMeanTime();    double meanSquared = mean * mean;    double meanOfSquares = sumSquaredTime / nCalls;    double variance = meanOfSquares - meanSquared;    if (variance < 0) {                return 0;    }    return (long) Math.sqrt(variance);}
public synchronized String mahout_f3412_0()
{    return '\n' + "nCalls = " + nCalls + ";\n" + "sum    = " + DF.format(sumTime / 1000000000.0) + "s;\n" + "min    = " + DF.format(minTime / 1000000.0) + "ms;\n" + "max    = " + DF.format(maxTime / 1000000.0) + "ms;\n" + "mean   = " + DF.format(getMeanTime() / 1000.0) + "us;\n" + "stdDev = " + DF.format(getStdDevTime() / 1000.0) + "us;";}
public Call mahout_f3413_0(long leadTimeUsec)
{    if (leadSumTime > leadTimeUsec) {        return new Call();    } else {        return new LeadTimeCall();    }}
public void mahout_f3414_0()
{    long elapsed = System.nanoTime() - startTime;    synchronized (TimingStatistics.this) {        leadSumTime += elapsed;    }}
public boolean mahout_f3415_0(long sumMaxUsec)
{    end();    return false;}
public void mahout_f3416_0()
{    long elapsed = System.nanoTime() - startTime;    synchronized (TimingStatistics.this) {        nCalls++;        if (elapsed < minTime || nCalls == 1) {            minTime = elapsed;        }        if (elapsed > maxTime) {            maxTime = elapsed;        }        sumTime += elapsed;        sumSquaredTime += elapsed * elapsed;    }}
public boolean mahout_f3417_0(long sumMaxUsec)
{    end();    return sumMaxUsec < sumTime;}
public static void mahout_f3418_1(String[] args) throws Throwable
{    Properties mainClasses = loadProperties("driver.classes.props");    if (mainClasses == null) {        mainClasses = loadProperties("driver.classes.default.props");    }    if (mainClasses == null) {        throw new IOException("Can't load any properties file?");    }    boolean foundShortName = false;    ProgramDriver programDriver = new ProgramDriver();    for (Object key : mainClasses.keySet()) {        String keyString = (String) key;        if (args.length > 0 && shortName(mainClasses.getProperty(keyString)).equals(args[0])) {            foundShortName = true;        }        if (args.length > 0 && keyString.equalsIgnoreCase(args[0]) && isDeprecated(mainClasses, keyString)) {                        return;        }        if (isDeprecated(mainClasses, keyString)) {            continue;        }        addClass(programDriver, keyString, mainClasses.getProperty(keyString));    }    if (args.length < 1 || args[0] == null || "-h".equals(args[0]) || "--help".equals(args[0])) {        programDriver.driver(args);        return;    }    String progName = args[0];    if (!foundShortName) {        addClass(programDriver, progName, progName);    }    shift(args);    Properties mainProps = loadProperties(progName + ".props");    if (mainProps == null) {                mainProps = new Properties();    }    Map<String, String[]> argMap = new HashMap<>();    int i = 0;    while (i < args.length && args[i] != null) {        List<String> argValues = new ArrayList<>();        String arg = args[i];        i++;        if (arg.startsWith("-D")) {                        String[] argSplit = arg.split("=");            arg = argSplit[0];            if (argSplit.length == 2) {                argValues.add(argSplit[1]);            }        } else {                        while (i < args.length && args[i] != null) {                if (args[i].startsWith("-")) {                    break;                }                argValues.add(args[i]);                i++;            }        }        argMap.put(arg, argValues.toArray(new String[argValues.size()]));    }        for (String key : mainProps.stringPropertyNames()) {        String[] argNamePair = key.split("\\|");        String shortArg = '-' + argNamePair[0].trim();        String longArg = argNamePair.length < 2 ? null : "--" + argNamePair[1].trim();        if (!argMap.containsKey(shortArg) && (longArg == null || !argMap.containsKey(longArg))) {            argMap.put(longArg, new String[] { mainProps.getProperty(key) });        }    }        List<String> argsList = new ArrayList<>();    argsList.add(progName);    for (Map.Entry<String, String[]> entry : argMap.entrySet()) {        String arg = entry.getKey();        if (arg.startsWith("-D")) {                        String[] argValues = entry.getValue();            if (argValues.length > 0 && !argValues[0].trim().isEmpty()) {                arg += '=' + argValues[0].trim();            }            argsList.add(1, arg);        } else {            argsList.add(arg);            for (String argValue : Arrays.asList(argMap.get(arg))) {                if (!argValue.isEmpty()) {                    argsList.add(argValue);                }            }        }    }    long start = System.currentTimeMillis();    programDriver.driver(argsList.toArray(new String[argsList.size()]));    if (log.isInfoEnabled()) {            }}
private static boolean mahout_f3419_0(Properties mainClasses, String keyString)
{    return "deprecated".equalsIgnoreCase(shortName(mainClasses.getProperty(keyString)));}
private static Properties mahout_f3420_0(String resource) throws IOException
{    InputStream propsStream = Thread.currentThread().getContextClassLoader().getResourceAsStream(resource);    if (propsStream != null) {        try {            Properties properties = new Properties();            properties.load(propsStream);            return properties;        } finally {            Closeables.close(propsStream, true);        }    }    return null;}
private static String[] mahout_f3421_0(String[] args)
{    System.arraycopy(args, 1, args, 0, args.length - 1);    args[args.length - 1] = null;    return args;}
private static String mahout_f3422_0(String valueString)
{    return valueString.contains(":") ? valueString.substring(0, valueString.indexOf(':')).trim() : valueString;}
private static String mahout_f3423_0(String valueString)
{    return valueString.contains(":") ? valueString.substring(valueString.indexOf(':')).trim() : valueString;}
private static void mahout_f3424_1(ProgramDriver driver, String classString, String descString)
{    try {        Class<?> clazz = Class.forName(classString);        driver.addClass(shortName(descString), clazz, desc(descString));    } catch (Throwable t) {            }}
private void mahout_f3425_0(int populationSize, State<T, U> seed)
{    population = Lists.newArrayList(seed);    for (int i = 0; i < populationSize; i++) {        population.add(seed.mutate());    }}
public void mahout_f3426_0(State<T, U> value)
{    population.add(value);}
public void mahout_f3427_0(int survivors)
{        Collections.sort(population);        List<State<T, U>> parents = new ArrayList<>(population.subList(0, survivors));    population.subList(survivors, population.size()).clear();        int i = 0;    while (population.size() < populationSize) {        population.add(parents.get(i % survivors).mutate());        i++;    }}
public State<T, U> mahout_f3428_0(final Function<Payload<U>> fn) throws InterruptedException, ExecutionException
{    Collection<Callable<State<T, U>>> tasks = new ArrayList<>();    for (final State<T, U> state : population) {        tasks.add(new Callable<State<T, U>>() {            @Override            public State<T, U> call() {                double v = fn.apply(state.getPayload(), state.getMappedParams());                state.setValue(v);                return state;            }        });    }    List<Future<State<T, U>>> r = pool.invokeAll(tasks);        double max = Double.NEGATIVE_INFINITY;    State<T, U> best = null;    for (Future<State<T, U>> future : r) {        State<T, U> s = future.get();        double value = s.getValue();        if (!Double.isNaN(value) && value >= max) {            max = value;            best = s;        }    }    if (best == null) {        best = r.get(0).get();    }    return best;}
public State<T, U> mahout_f3429_0()
{    double v = fn.apply(state.getPayload(), state.getMappedParams());    state.setValue(v);    return state;}
public void mahout_f3430_0(int threadCount)
{    this.threadCount = threadCount;    pool = Executors.newFixedThreadPool(threadCount);}
public int mahout_f3431_0()
{    return threadCount;}
public int mahout_f3432_0()
{    return populationSize;}
public List<State<T, U>> mahout_f3433_0()
{    return population;}
public void mahout_f3434_0()
{    List<Runnable> remainingTasks = pool.shutdownNow();    try {        pool.awaitTermination(10, TimeUnit.SECONDS);    } catch (InterruptedException e) {        throw new IllegalStateException("Had to forcefully shut down " + remainingTasks.size() + " tasks");    }    if (!remainingTasks.isEmpty()) {        throw new IllegalStateException("Had to forcefully shut down " + remainingTasks.size() + " tasks");    }}
public void mahout_f3435_0(DataOutput out) throws IOException
{    out.writeInt(threadCount);    out.writeInt(population.size());    for (State<T, U> state : population) {        PolymorphicWritable.write(out, state);    }}
public void mahout_f3436_0(DataInput input) throws IOException
{    setThreadCount(input.readInt());    int n = input.readInt();    population = new ArrayList<>();    for (int i = 0; i < n; i++) {        State<T, U> state = (State<T, U>) PolymorphicWritable.read(input, State.class);        population.add(state);    }}
public double mahout_f3437_0(double v)
{    return min + (max - min) * 1 / (1 + Math.exp(-v * scale));}
public void mahout_f3438_0(DataOutput out) throws IOException
{    out.writeDouble(min);    out.writeDouble(max);    out.writeDouble(scale);}
public void mahout_f3439_0(DataInput in) throws IOException
{    min = in.readDouble();    max = in.readDouble();    scale = in.readDouble();}
public double mahout_f3440_0(double v)
{    return Math.exp(wrapped.apply(v));}
public void mahout_f3441_0(DataOutput dataOutput) throws IOException
{    PolymorphicWritable.write(dataOutput, wrapped);}
public void mahout_f3442_0(DataInput in) throws IOException
{    wrapped = PolymorphicWritable.read(in, Mapping.class);}
public double mahout_f3443_0(double v)
{    return Math.exp(v * scale);}
public void mahout_f3444_0(DataOutput out) throws IOException
{    out.writeDouble(scale);}
public void mahout_f3445_0(DataInput in) throws IOException
{    scale = in.readDouble();}
public double mahout_f3446_0(double v)
{    return v;}
public void mahout_f3447_0(DataOutput dataOutput)
{}
public void mahout_f3448_0(DataInput dataInput)
{}
public static Mapping mahout_f3449_0(double min, double max, double scale)
{    return new SoftLimit(min, max, scale);}
public static Mapping mahout_f3450_0(double min, double max)
{    return softLimit(min, max, 1);}
public static Mapping mahout_f3451_0(double low, double high)
{    Preconditions.checkArgument(low > 0, "Lower bound for log limit must be > 0 but was %f", low);    Preconditions.checkArgument(high > 0, "Upper bound for log limit must be > 0 but was %f", high);    return new LogLimit(low, high);}
public static Mapping mahout_f3452_0()
{    return exponential(1);}
public static Mapping mahout_f3453_0(double scale)
{    return new Exponential(scale);}
public static Mapping mahout_f3454_0()
{    return new Identity();}
public State<T, U> mahout_f3455_0()
{    State<T, U> r = new State<>();    r.params = Arrays.copyOf(this.params, this.params.length);    r.omni = this.omni;    r.step = Arrays.copyOf(this.step, this.step.length);    r.maps = Arrays.copyOf(this.maps, this.maps.length);    if (this.payload != null) {        r.payload = (T) this.payload.copy();    }    r.gen = this.gen;    return r;}
public State<T, U> mahout_f3456_0()
{    double sum = 0;    for (double v : step) {        sum += v * v;    }    sum = Math.sqrt(sum);    double lambda = 1 + gen.nextGaussian();    State<T, U> r = this.copy();    double magnitude = 0.9 * omni + sum / 10;    r.omni = magnitude * -Math.log1p(-gen.nextDouble());    for (int i = 0; i < step.length; i++) {        r.step[i] = lambda * step[i] + r.omni * gen.nextGaussian();        r.params[i] += r.step[i];    }    if (this.payload != null) {        r.payload.update(r.getMappedParams());    }    return r;}
public void mahout_f3457_0(int i, Mapping m)
{    maps[i] = m;}
public double mahout_f3458_0(int i)
{    Mapping m = maps[i];    return m == null ? params[i] : m.apply(params[i]);}
public int mahout_f3459_0()
{    return id;}
public double[] mahout_f3460_0()
{    return params;}
public Mapping[] mahout_f3461_0()
{    return maps;}
public double[] mahout_f3462_0()
{    double[] r = Arrays.copyOf(params, params.length);    for (int i = 0; i < params.length; i++) {        r[i] = get(i);    }    return r;}
public double mahout_f3463_0()
{    return omni;}
public double[] mahout_f3464_0()
{    return step;}
public T mahout_f3465_0()
{    return payload;}
public double mahout_f3466_0()
{    return value;}
public void mahout_f3467_0(double omni)
{    this.omni = omni;}
public void mahout_f3468_0(int id)
{    this.id = id;}
public void mahout_f3469_0(double[] step)
{    this.step = step;}
public void mahout_f3470_0(Mapping[] maps)
{    this.maps = maps;}
public void mahout_f3471_0(Iterable<Mapping> maps)
{    Collection<Mapping> list = Lists.newArrayList(maps);    this.maps = list.toArray(new Mapping[list.size()]);}
public void mahout_f3472_0(double v)
{    value = v;}
public void mahout_f3473_0(T payload)
{    this.payload = payload;}
public boolean mahout_f3474_0(Object o)
{    if (!(o instanceof State)) {        return false;    }    State<?, ?> other = (State<?, ?>) o;    return id == other.id && value == other.value;}
public int mahout_f3475_0()
{    return RandomUtils.hashDouble(value) ^ id;}
public int mahout_f3476_0(State<T, U> other)
{    int r = Double.compare(other.value, this.value);    if (r != 0) {        return r;    }    if (this.id < other.id) {        return -1;    }    if (this.id > other.id) {        return 1;    }    return 0;}
public String mahout_f3477_0()
{    double sum = 0;    for (double v : step) {        sum += v * v;    }    return String.format(Locale.ENGLISH, "<S/%s %.3f %.3f>", payload, omni + Math.sqrt(sum), value);}
public void mahout_f3478_0(DataOutput out) throws IOException
{    out.writeInt(id);    out.writeInt(params.length);    for (double v : params) {        out.writeDouble(v);    }    for (Mapping map : maps) {        PolymorphicWritable.write(out, map);    }    out.writeDouble(omni);    for (double v : step) {        out.writeDouble(v);    }    out.writeDouble(value);    PolymorphicWritable.write(out, payload);}
public void mahout_f3479_0(DataInput input) throws IOException
{    id = input.readInt();    int n = input.readInt();    params = new double[n];    for (int i = 0; i < n; i++) {        params[i] = input.readDouble();    }    maps = new Mapping[n];    for (int i = 0; i < n; i++) {        maps[i] = PolymorphicWritable.read(input, Mapping.class);    }    omni = input.readDouble();    step = new double[n];    for (int i = 0; i < n; i++) {        step[i] = input.readDouble();    }    value = input.readDouble();    payload = (T) PolymorphicWritable.read(input, Payload.class);}
public static Vector mahout_f3480_0(Iterable<Vector> featureVectors, Vector ratingVector, double lambda, int numFeatures)
{    Preconditions.checkNotNull(featureVectors, "Feature Vectors cannot be null");    Preconditions.checkArgument(!Iterables.isEmpty(featureVectors));    Preconditions.checkNotNull(ratingVector, "Rating Vector cannot be null");    Preconditions.checkArgument(ratingVector.getNumNondefaultElements() > 0, "Rating Vector cannot be empty");    Preconditions.checkArgument(Iterables.size(featureVectors) == ratingVector.getNumNondefaultElements());    int nui = ratingVector.getNumNondefaultElements();    Matrix MiIi = createMiIi(featureVectors, numFeatures);    Matrix RiIiMaybeTransposed = createRiIiMaybeTransposed(ratingVector);    /* compute Ai = MiIi * t(MiIi) + lambda * nui * E */    Matrix Ai = miTimesMiTransposePlusLambdaTimesNuiTimesE(MiIi, lambda, nui);    /* compute Vi = MiIi * t(R(i,Ii)) */    Matrix Vi = MiIi.times(RiIiMaybeTransposed);    /* compute Ai * ui = Vi */    return solve(Ai, Vi);}
private static Vector mahout_f3481_0(Matrix Ai, Matrix Vi)
{    return new QRDecomposition(Ai).solve(Vi).viewColumn(0);}
 static Matrix mahout_f3482_0(Matrix matrix, double lambda, int nui)
{    Preconditions.checkArgument(matrix.numCols() == matrix.numRows(), "Must be a Square Matrix");    double lambdaTimesNui = lambda * nui;    int numCols = matrix.numCols();    for (int n = 0; n < numCols; n++) {        matrix.setQuick(n, n, matrix.getQuick(n, n) + lambdaTimesNui);    }    return matrix;}
private static Matrix mahout_f3483_0(Matrix MiIi, double lambda, int nui)
{    double lambdaTimesNui = lambda * nui;    int rows = MiIi.numRows();    double[][] result = new double[rows][rows];    for (int i = 0; i < rows; i++) {        for (int j = i; j < rows; j++) {            double dot = MiIi.viewRow(i).dot(MiIi.viewRow(j));            if (i != j) {                result[i][j] = dot;                result[j][i] = dot;            } else {                result[i][i] = dot + lambdaTimesNui;            }        }    }    return new DenseMatrix(result, true);}
 static Matrix mahout_f3484_0(Iterable<Vector> featureVectors, int numFeatures)
{    double[][] MiIi = new double[numFeatures][Iterables.size(featureVectors)];    int n = 0;    for (Vector featureVector : featureVectors) {        for (int m = 0; m < numFeatures; m++) {            MiIi[m][n] = featureVector.getQuick(m);        }        n++;    }    return new DenseMatrix(MiIi, true);}
 static Matrix mahout_f3485_0(Vector ratingVector)
{    Preconditions.checkArgument(ratingVector.isSequentialAccess(), "Ratings should be iterable in Index or Sequential Order");    double[][] RiIiMaybeTransposed = new double[ratingVector.getNumNondefaultElements()][1];    int index = 0;    for (Vector.Element elem : ratingVector.nonZeroes()) {        RiIiMaybeTransposed[index++][0] = elem.get();    }    return new DenseMatrix(RiIiMaybeTransposed, true);}
public Vector mahout_f3486_0(Vector ratings)
{    return solve(YtransposeY.plus(getYtransponseCuMinusIYPlusLambdaI(ratings)), getYtransponseCuPu(ratings));}
private static Vector mahout_f3487_0(Matrix A, Matrix y)
{    return new QRDecomposition(A).solve(y).viewColumn(0);}
 double mahout_f3488_0(double rating)
{    return 1 + alpha * rating;}
public Matrix mahout_f3489_1(final OpenIntObjectHashMap<Vector> Y)
{    ExecutorService queue = Executors.newFixedThreadPool(numTrainingThreads);    if (log.isInfoEnabled()) {            }    long startTime = System.nanoTime();    final IntArrayList indexes = Y.keys();    final int numIndexes = indexes.size();    final double[][] YtY = new double[numFeatures][numFeatures];        for (int i = 0; i < numFeatures; i++) {        for (int j = i; j < numFeatures; j++) {            final int ii = i;            final int jj = j;            queue.execute(new Runnable() {                @Override                public void run() {                    double dot = 0;                    for (int k = 0; k < numIndexes; k++) {                        Vector row = Y.get(indexes.getQuick(k));                        dot += row.getQuick(ii) * row.getQuick(jj);                    }                    YtY[ii][jj] = dot;                    if (ii != jj) {                        YtY[jj][ii] = dot;                    }                }            });        }    }    queue.shutdown();    try {        queue.awaitTermination(1, TimeUnit.DAYS);    } catch (InterruptedException e) {                throw new RuntimeException("Error during Y'Y queue shutdown");    }    if (log.isInfoEnabled()) {            }    return new DenseMatrix(YtY, true);}
public void mahout_f3490_0()
{    double dot = 0;    for (int k = 0; k < numIndexes; k++) {        Vector row = Y.get(indexes.getQuick(k));        dot += row.getQuick(ii) * row.getQuick(jj);    }    YtY[ii][jj] = dot;    if (ii != jj) {        YtY[jj][ii] = dot;    }}
private Matrix mahout_f3491_0(Vector userRatings)
{    Preconditions.checkArgument(userRatings.isSequentialAccess(), "need sequential access to ratings!");    /* (Cu -I) Y */    OpenIntObjectHashMap<Vector> CuMinusIY = new OpenIntObjectHashMap<>(userRatings.getNumNondefaultElements());    for (Element e : userRatings.nonZeroes()) {        CuMinusIY.put(e.index(), Y.get(e.index()).times(confidence(e.get()) - 1));    }    Matrix YtransponseCuMinusIY = new DenseMatrix(numFeatures, numFeatures);    /* Y' (Cu -I) Y by outer products */    for (Element e : userRatings.nonZeroes()) {        for (Element feature : Y.get(e.index()).all()) {            Vector partial = CuMinusIY.get(e.index()).times(feature.get());            YtransponseCuMinusIY.viewRow(feature.index()).assign(partial, Functions.PLUS);        }    }    /* Y' (Cu - I) Y + λ I  add lambda on the diagonal */    for (int feature = 0; feature < numFeatures; feature++) {        YtransponseCuMinusIY.setQuick(feature, feature, YtransponseCuMinusIY.getQuick(feature, feature) + lambda);    }    return YtransponseCuMinusIY;}
private Matrix mahout_f3492_0(Vector userRatings)
{    Preconditions.checkArgument(userRatings.isSequentialAccess(), "need sequential access to ratings!");    Vector YtransponseCuPu = new DenseVector(numFeatures);    for (Element e : userRatings.nonZeroes()) {        YtransponseCuPu.assign(Y.get(e.index()).times(confidence(e.get())), Functions.PLUS);    }    return columnVectorAsMatrix(YtransponseCuPu);}
private Matrix mahout_f3493_0(Vector v)
{    double[][] matrix = new double[numFeatures][1];    for (Element e : v.all()) {        matrix[e.index()][0] = e.get();    }    return new DenseMatrix(matrix, true);}
public synchronized EigenStatus mahout_f3494_0(VectorIterable corpus, Vector vector)
{    if (!finished && !started) {                status = new EigenStatus(-1, 0);        Vector vectorCopy = vector.clone();        threadPool.execute(new VerifierRunnable(corpus, vectorCopy));        started = true;    }    if (finished) {        finished = false;    }    return status;}
public void mahout_f3495_0()
{    this.threadPool.shutdownNow();}
protected EigenStatus mahout_f3496_0(VectorIterable corpus, Vector vector)
{    return super.verify(corpus, vector);}
public void mahout_f3497_0()
{    EigenStatus status = innerVerify(corpus, vector);    synchronized (AsyncEigenVerifier.this) {        AsyncEigenVerifier.this.status = status;        finished = true;        started = false;    }}
public double mahout_f3498_0()
{    return cosAngle;}
public double mahout_f3499_0()
{    return eigenValue;}
public boolean mahout_f3500_0()
{    return inProgress;}
 void mahout_f3501_0(boolean status)
{    inProgress = status;}
public TrainingState mahout_f3502_1(Matrix corpus, int desiredRank)
{    int cols = corpus.numCols();    Matrix eigens = new DenseMatrix(desiredRank, cols);    List<Double> eigenValues = new ArrayList<>();        /*     * The corpusProjections matrix is a running cache of the residual projection of each corpus vector against all     * of the previously found singular vectors.  Without this, if multiple passes over the data is made (per     * singular vector), recalculating these projections eventually dominates the computational complexity of the     * solver.     */    Matrix corpusProjections = new DenseMatrix(corpus.numRows(), desiredRank);    TrainingState state = new TrainingState(eigens, corpusProjections);    for (int i = 0; i < desiredRank; i++) {        Vector currentEigen = new DenseVector(cols);        Vector previousEigen = null;        while (hasNotConverged(currentEigen, corpus, state)) {            int randomStartingIndex = getRandomStartingIndex(corpus, eigens);            Vector initialTrainingVector = corpus.viewRow(randomStartingIndex);            state.setTrainingIndex(randomStartingIndex);            updater.update(currentEigen, initialTrainingVector, state);            for (int corpusRow = 0; corpusRow < corpus.numRows(); corpusRow++) {                state.setTrainingIndex(corpusRow);                if (corpusRow != randomStartingIndex) {                    updater.update(currentEigen, corpus.viewRow(corpusRow), state);                }            }            state.setFirstPass(false);            if (DEBUG) {                if (previousEigen == null) {                    previousEigen = currentEigen.clone();                } else {                    double dot = currentEigen.dot(previousEigen);                    if (dot > 0.0) {                        dot /= currentEigen.norm(2) * previousEigen.norm(2);                    }                                }            }        }                double eigenValue = state.getStatusProgress().get(state.getStatusProgress().size() - 1).getEigenValue();                        currentEigen.assign(new TimesFunction(), 1 / currentEigen.norm(2));        eigens.assignRow(i, currentEigen);        eigenValues.add(eigenValue);        state.setCurrentEigenValues(eigenValues);                /**         *  TODO: Persist intermediate output!         */        state.setFirstPass(true);        state.setNumEigensProcessed(state.getNumEigensProcessed() + 1);        state.setActivationDenominatorSquared(0);        state.setActivationNumerator(0);        state.getStatusProgress().clear();        numPasses = 0;    }    return state;}
private int mahout_f3503_0(Matrix corpus, Matrix eigens)
{    int index;    Vector v;    do {        double r = rng.nextDouble();        index = (int) (r * corpus.numRows());        v = corpus.viewRow(index);    } while (v == null || v.norm(2) == 0 || v.getNumNondefaultElements() < 5);    return index;}
protected boolean mahout_f3504_1(Vector currentPseudoEigen, Matrix corpus, TrainingState state)
{    numPasses++;    if (state.isFirstPass()) {                return true;    }    Matrix previousEigens = state.getCurrentEigens();        /*     * Step 1: orthogonalize currentPseudoEigen by subtracting off eigen(i) * helper.get(i)     * Step 2: zero-out the helper vector because it has already helped.     */    for (int i = 0; i < state.getNumEigensProcessed(); i++) {        Vector previousEigen = previousEigens.viewRow(i);        currentPseudoEigen.assign(previousEigen, new PlusMult(-state.getHelperVector().get(i)));        state.getHelperVector().set(i, 0);    }    if (currentPseudoEigen.norm(2) > 0) {        for (int i = 0; i < state.getNumEigensProcessed(); i++) {            Vector previousEigen = previousEigens.viewRow(i);                    }    }    /*     * Step 3: verify how eigen-like the prospective eigen is.  This is potentially asynchronous.     */    EigenStatus status = verify(corpus, currentPseudoEigen);    if (status.inProgress()) {            } else {                state.getStatusProgress().add(status);    }    return state.getStatusProgress().size() <= maxPassesPerEigen && 1.0 - status.getCosAngle() > convergenceTarget;}
protected EigenStatus mahout_f3505_0(Matrix corpus, Vector currentPseudoEigen)
{    return verifier.verify(corpus, currentPseudoEigen);}
public static void mahout_f3506_1(String[] args)
{    Properties props = new Properties();    String propertiesFile = args.length > 0 ? args[0] : "config/solver.properties";        String corpusDir = props.getProperty("solver.input.dir");    String outputDir = props.getProperty("solver.output.dir");    if (corpusDir == null || corpusDir.isEmpty() || outputDir == null || outputDir.isEmpty()) {                return;    }        int rank = Integer.parseInt(props.getProperty("solver.output.desiredRank"));    double convergence = Double.parseDouble(props.getProperty("solver.convergence"));    int maxPasses = Integer.parseInt(props.getProperty("solver.maxPasses"));        HebbianUpdater updater = new HebbianUpdater();    SingularVectorVerifier verifier = new AsyncEigenVerifier();    HebbianSolver solver = new HebbianSolver(updater, verifier, convergence, maxPasses);    Matrix corpus = null;    /*    if (numThreads <= 1) {          } else {          }     */    long now = System.currentTimeMillis();    TrainingState finalState = solver.solve(corpus, rank);    long time = (System.currentTimeMillis() - now) / 1000;    }
public void mahout_f3507_0(Vector pseudoEigen, Vector trainingVector, TrainingState currentState)
{    double trainingVectorNorm = trainingVector.norm(2);    int numPreviousEigens = currentState.getNumEigensProcessed();    if (numPreviousEigens > 0 && currentState.isFirstPass()) {        updateTrainingProjectionsVector(currentState, trainingVector, numPreviousEigens - 1);    }    if (currentState.getActivationDenominatorSquared() == 0 || trainingVectorNorm == 0) {        if (currentState.getActivationDenominatorSquared() == 0) {            pseudoEigen.assign(trainingVector, new PlusMult(1));            currentState.setHelperVector(currentState.currentTrainingProjection().clone());            double helperNorm = currentState.getHelperVector().norm(2);            currentState.setActivationDenominatorSquared(trainingVectorNorm * trainingVectorNorm - helperNorm * helperNorm);        }        return;    }    currentState.setActivationNumerator(pseudoEigen.dot(trainingVector));    currentState.setActivationNumerator(currentState.getActivationNumerator() - currentState.getHelperVector().dot(currentState.currentTrainingProjection()));    double activation = currentState.getActivationNumerator() / Math.sqrt(currentState.getActivationDenominatorSquared());    currentState.setActivationDenominatorSquared(currentState.getActivationDenominatorSquared() + 2 * activation * currentState.getActivationNumerator() + activation * activation * (trainingVector.getLengthSquared() - currentState.currentTrainingProjection().getLengthSquared()));    if (numPreviousEigens > 0) {        currentState.getHelperVector().assign(currentState.currentTrainingProjection(), new PlusMult(activation));    }    pseudoEigen.assign(trainingVector, new PlusMult(activation));}
private static void mahout_f3508_0(TrainingState state, Vector trainingVector, int previousEigenIndex)
{    Vector previousEigen = state.mostRecentEigen();    Vector currentTrainingVectorProjection = state.currentTrainingProjection();    double projection = previousEigen.dot(trainingVector);    currentTrainingVectorProjection.set(previousEigenIndex, projection);}
public Vector mahout_f3509_0()
{    return currentEigens.viewRow(numEigensProcessed - 1);}
public Vector mahout_f3510_0()
{    if (trainingProjections.viewRow(trainingIndex) == null) {        trainingProjections.assignRow(trainingIndex, new DenseVector(currentEigens.numCols()));    }    return trainingProjections.viewRow(trainingIndex);}
public Matrix mahout_f3511_0()
{    return currentEigens;}
public void mahout_f3512_0(Matrix currentEigens)
{    this.currentEigens = currentEigens;}
public int mahout_f3513_0()
{    return numEigensProcessed;}
public void mahout_f3514_0(int numEigensProcessed)
{    this.numEigensProcessed = numEigensProcessed;}
public List<Double> mahout_f3515_0()
{    return currentEigenValues;}
public void mahout_f3516_0(List<Double> currentEigenValues)
{    this.currentEigenValues = currentEigenValues;}
public Matrix mahout_f3517_0()
{    return trainingProjections;}
public void mahout_f3518_0(Matrix trainingProjections)
{    this.trainingProjections = trainingProjections;}
public int mahout_f3519_0()
{    return trainingIndex;}
public void mahout_f3520_0(int trainingIndex)
{    this.trainingIndex = trainingIndex;}
public Vector mahout_f3521_0()
{    return helperVector;}
public void mahout_f3522_0(Vector helperVector)
{    this.helperVector = helperVector;}
public boolean mahout_f3523_0()
{    return firstPass;}
public void mahout_f3524_0(boolean firstPass)
{    this.firstPass = firstPass;}
public List<EigenStatus> mahout_f3525_0()
{    return statusProgress;}
public void mahout_f3526_0(List<EigenStatus> statusProgress)
{    this.statusProgress = statusProgress;}
public double mahout_f3527_0()
{    return activationNumerator;}
public void mahout_f3528_0(double activationNumerator)
{    this.activationNumerator = activationNumerator;}
public double mahout_f3529_0()
{    return activationDenominatorSquared;}
public void mahout_f3530_0(double activationDenominatorSquared)
{    this.activationDenominatorSquared = activationDenominatorSquared;}
public double mahout_f3531_0(double arg1)
{    return arg1 * d;}
public void mahout_f3532_0(LanczosState state, int desiredRank)
{    solve(state, desiredRank, false);}
public void mahout_f3533_1(LanczosState state, int desiredRank, boolean isSymmetric)
{    VectorIterable corpus = state.getCorpus();        int i = state.getIterationNumber();    Vector currentVector = state.getBasisVector(i - 1);    Vector previousVector = state.getBasisVector(i - 2);    double beta = 0;    Matrix triDiag = state.getDiagonalMatrix();    while (i < desiredRank) {        startTime(TimingSection.ITERATE);        Vector nextVector = isSymmetric ? corpus.times(currentVector) : corpus.timesSquared(currentVector);                if (state.getScaleFactor() <= 0) {            state.setScaleFactor(calculateScaleFactor(nextVector));        }        nextVector.assign(new Scale(1.0 / state.getScaleFactor()));        if (previousVector != null) {            nextVector.assign(previousVector, new PlusMult(-beta));        }                double alpha = currentVector.dot(nextVector);        nextVector.assign(currentVector, new PlusMult(-alpha));        endTime(TimingSection.ITERATE);        startTime(TimingSection.ORTHOGANLIZE);        orthoganalizeAgainstAllButLast(nextVector, state);        endTime(TimingSection.ORTHOGANLIZE);                beta = nextVector.norm(2);        if (outOfRange(beta) || outOfRange(alpha)) {                        break;        }        nextVector.assign(new Scale(1 / beta));        state.setBasisVector(i, nextVector);        previousVector = currentVector;        currentVector = nextVector;                triDiag.set(i - 1, i - 1, alpha);        if (i < desiredRank - 1) {            triDiag.set(i - 1, i, beta);            triDiag.set(i, i - 1, beta);        }        state.setIterationNumber(++i);    }    startTime(TimingSection.TRIDIAG_DECOMP);            EigenDecomposition decomp = new EigenDecomposition(triDiag);    Matrix eigenVects = decomp.getV();    Vector eigenVals = decomp.getRealEigenvalues();    endTime(TimingSection.TRIDIAG_DECOMP);    startTime(TimingSection.FINAL_EIGEN_CREATE);    for (int row = 0; row < i; row++) {        Vector realEigen = null;        Vector ejCol = eigenVects.viewColumn(row);        int size = Math.min(ejCol.size(), state.getBasisSize());        for (int j = 0; j < size; j++) {            double d = ejCol.get(j);            Vector rowJ = state.getBasisVector(j);            if (realEigen == null) {                realEigen = rowJ.like();            }            realEigen.assign(rowJ, new PlusMult(d));        }        Preconditions.checkState(realEigen != null);        assert realEigen != null;        realEigen = realEigen.normalize();        state.setRightSingularVector(row, realEigen);        double e = eigenVals.get(row) * state.getScaleFactor();        if (!isSymmetric) {            e = Math.sqrt(e);        }                state.setSingularValue(row, e);    }        endTime(TimingSection.FINAL_EIGEN_CREATE);}
protected static double mahout_f3534_0(Vector nextVector)
{    return nextVector.norm(2);}
private static boolean mahout_f3535_0(double d)
{    return Double.isNaN(d) || d > SAFE_MAX || -d > SAFE_MAX;}
protected static void mahout_f3536_0(Vector nextVector, LanczosState state)
{    for (int i = 0; i < state.getIterationNumber(); i++) {        Vector basisVector = state.getBasisVector(i);        double alpha;        if (basisVector == null || (alpha = nextVector.dot(basisVector)) == 0.0) {            continue;        }        nextVector.assign(basisVector, new PlusMult(-alpha));    }}
private void mahout_f3537_0(TimingSection section)
{    startTimes.put(section, System.nanoTime());}
private void mahout_f3538_0(TimingSection section)
{    if (!times.containsKey(section)) {        times.put(section, 0L);    }    times.put(section, times.get(section) + System.nanoTime() - startTimes.get(section));}
private void mahout_f3539_0()
{    basis = Maps.newHashMap();    singularVectors = Maps.newHashMap();}
public Matrix mahout_f3540_0()
{    return diagonalMatrix;}
public int mahout_f3541_0()
{    return iterationNumber;}
public double mahout_f3542_0()
{    return scaleFactor;}
public VectorIterable mahout_f3543_0()
{    return corpus;}
public Vector mahout_f3544_0(int i)
{    return singularVectors.get(i);}
public Double mahout_f3545_0(int i)
{    return singularValues.get(i);}
public Vector mahout_f3546_0(int i)
{    return basis.get(i);}
public int mahout_f3547_0()
{    return basis.size();}
public void mahout_f3548_0(int i, Vector basisVector)
{    basis.put(i, basisVector);}
public void mahout_f3549_0(double scale)
{    scaleFactor = scale;}
public void mahout_f3550_0(int i)
{    iterationNumber = i;}
public void mahout_f3551_0(int i, Vector vector)
{    singularVectors.put(i, vector);}
public void mahout_f3552_0(int i, double value)
{    singularValues.put(i, value);}
public EigenStatus mahout_f3553_0(VectorIterable corpus, Vector vector)
{    Vector resultantVector = corpus.timesSquared(vector);    double newNorm = resultantVector.norm(2);    double oldNorm = vector.norm(2);    double eigenValue;    double cosAngle;    if (newNorm > 0 && oldNorm > 0) {        eigenValue = newNorm / oldNorm;        cosAngle = resultantVector.dot(vector) / newNorm * oldNorm;    } else {        eigenValue = 1.0;        cosAngle = 0.0;    }    return new EigenStatus(eigenValue, cosAngle, false);}
public static void mahout_f3554_0(Path outputDir, Configuration conf, Iterable<MatrixSlice> matrix) throws IOException
{    FileSystem fs = outputDir.getFileSystem(conf);    SequenceFile.Writer writer = SequenceFile.createWriter(fs, conf, outputDir, IntWritable.class, VectorWritable.class);    IntWritable topic = new IntWritable();    VectorWritable vector = new VectorWritable();    for (MatrixSlice slice : matrix) {        topic.set(slice.index());        vector.set(slice.vector());        writer.append(topic, vector);    }    writer.close();}
public static Vector mahout_f3555_0(VectorIterable corpus)
{    Vector initialVector = new DenseVector(corpus.numCols());    initialVector.assign(1.0 / Math.sqrt(corpus.numCols()));    return initialVector;}
public LanczosState mahout_f3556_0(Configuration originalConfig, LanczosState state, int desiredRank, boolean isSymmetric, String outputEigenVectorPathString) throws IOException
{    ((Configurable) state.getCorpus()).setConf(new Configuration(originalConfig));    setConf(originalConfig);    solve(state, desiredRank, isSymmetric);    serializeOutput(state, new Path(outputEigenVectorPathString));    return state;}
public LanczosState mahout_f3557_0(Configuration originalConfig, Path inputPath, Path outputTmpPath, int numRows, int numCols, boolean isSymmetric, int desiredRank, String outputEigenVectorPathString) throws IOException
{    DistributedRowMatrix matrix = new DistributedRowMatrix(inputPath, outputTmpPath, numRows, numCols);    matrix.setConf(new Configuration(originalConfig));    LanczosState state = new LanczosState(matrix, desiredRank, getInitialVector(matrix));    return runJob(originalConfig, state, desiredRank, isSymmetric, outputEigenVectorPathString);}
public int mahout_f3558_0(String[] strings) throws Exception
{    Path inputPath = new Path(AbstractJob.getOption(parsedArgs, "--input"));    Path outputPath = new Path(AbstractJob.getOption(parsedArgs, "--output"));    Path outputTmpPath = new Path(AbstractJob.getOption(parsedArgs, "--tempDir"));    Path workingDirPath = AbstractJob.getOption(parsedArgs, "--workingDir") != null ? new Path(AbstractJob.getOption(parsedArgs, "--workingDir")) : null;    int numRows = Integer.parseInt(AbstractJob.getOption(parsedArgs, "--numRows"));    int numCols = Integer.parseInt(AbstractJob.getOption(parsedArgs, "--numCols"));    boolean isSymmetric = Boolean.parseBoolean(AbstractJob.getOption(parsedArgs, "--symmetric"));    int desiredRank = Integer.parseInt(AbstractJob.getOption(parsedArgs, "--rank"));    boolean cleansvd = Boolean.parseBoolean(AbstractJob.getOption(parsedArgs, "--cleansvd"));    if (cleansvd) {        double maxError = Double.parseDouble(AbstractJob.getOption(parsedArgs, "--maxError"));        double minEigenvalue = Double.parseDouble(AbstractJob.getOption(parsedArgs, "--minEigenvalue"));        boolean inMemory = Boolean.parseBoolean(AbstractJob.getOption(parsedArgs, "--inMemory"));        return run(inputPath, outputPath, outputTmpPath, workingDirPath, numRows, numCols, isSymmetric, desiredRank, maxError, minEigenvalue, inMemory);    }    return run(inputPath, outputPath, outputTmpPath, workingDirPath, numRows, numCols, isSymmetric, desiredRank);}
public int mahout_f3559_0(Path inputPath, Path outputPath, Path outputTmpPath, Path workingDirPath, int numRows, int numCols, boolean isSymmetric, int desiredRank, double maxError, double minEigenvalue, boolean inMemory) throws Exception
{    int result = run(inputPath, outputPath, outputTmpPath, workingDirPath, numRows, numCols, isSymmetric, desiredRank);    if (result != 0) {        return result;    }    Path rawEigenVectorPath = new Path(outputPath, RAW_EIGENVECTORS);    return new EigenVerificationJob().run(inputPath, rawEigenVectorPath, outputPath, outputTmpPath, maxError, minEigenvalue, inMemory, getConf() != null ? new Configuration(getConf()) : new Configuration());}
public int mahout_f3560_0(Path inputPath, Path outputPath, Path outputTmpPath, Path workingDirPath, int numRows, int numCols, boolean isSymmetric, int desiredRank) throws Exception
{    DistributedRowMatrix matrix = new DistributedRowMatrix(inputPath, outputTmpPath, numRows, numCols);    matrix.setConf(new Configuration(getConf() != null ? getConf() : new Configuration()));    LanczosState state;    if (workingDirPath == null) {        state = new LanczosState(matrix, desiredRank, getInitialVector(matrix));    } else {        HdfsBackedLanczosState hState = new HdfsBackedLanczosState(matrix, desiredRank, getInitialVector(matrix), workingDirPath);        hState.setConf(matrix.getConf());        state = hState;    }    solve(state, desiredRank, isSymmetric);    Path outputEigenVectorPath = new Path(outputPath, RAW_EIGENVECTORS);    serializeOutput(state, outputEigenVectorPath);    return 0;}
public void mahout_f3561_1(LanczosState state, Path outputPath) throws IOException
{    int numEigenVectors = state.getIterationNumber();        Configuration conf = getConf() != null ? getConf() : new Configuration();    FileSystem fs = FileSystem.get(outputPath.toUri(), conf);    SequenceFile.Writer seqWriter = new SequenceFile.Writer(fs, conf, outputPath, IntWritable.class, VectorWritable.class);    try {        IntWritable iw = new IntWritable();        for (int i = 0; i < numEigenVectors; i++) {                        NamedVector v = new NamedVector(state.getRightSingularVector(numEigenVectors - 1 - i), "eigenVector" + i + ", eigenvalue = " + state.getSingularValue(numEigenVectors - 1 - i));            Writable vw = new VectorWritable(v);            iw.set(i);            seqWriter.append(iw, vw);        }    } finally {        Closeables.close(seqWriter, false);    }}
public void mahout_f3562_0(Configuration configuration)
{    conf = configuration;}
public Configuration mahout_f3563_0()
{    return conf;}
public DistributedLanczosSolverJob mahout_f3564_0()
{    return new DistributedLanczosSolverJob();}
public void mahout_f3565_0(Configuration conf)
{    DistributedLanczosSolver.this.setConf(conf);}
public Configuration mahout_f3566_0()
{    return DistributedLanczosSolver.this.getConf();}
public int mahout_f3567_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption("numRows", "nr", "Number of rows of the input matrix");    addOption("numCols", "nc", "Number of columns of the input matrix");    addOption("rank", "r", "Desired decomposition rank (note: only roughly 1/4 to 1/3 " + "of these will have the top portion of the spectrum)");    addOption("symmetric", "sym", "Is the input matrix square and symmetric?");    addOption("workingDir", "wd", "Working directory path to store Lanczos basis vectors " + "(to be used on restarts, and to avoid too much RAM usage)");        addOption("cleansvd", "cl", "Run the EigenVerificationJob to clean the eigenvectors after SVD", false);    addOption("maxError", "err", "Maximum acceptable error", "0.05");    addOption("minEigenvalue", "mev", "Minimum eigenvalue to keep the vector for", "0.0");    addOption("inMemory", "mem", "Buffer eigen matrix into memory (if you have enough!)", "false");    DistributedLanczosSolver.this.parsedArgs = parseArguments(args);    if (DistributedLanczosSolver.this.parsedArgs == null) {        return -1;    } else {        return DistributedLanczosSolver.this.run(args);    }}
public static void mahout_f3568_0(String[] args) throws Exception
{    ToolRunner.run(new DistributedLanczosSolver().job(), args);}
public double mahout_f3569_0()
{    return getEigenValue(getName());}
public double mahout_f3570_0()
{    return getCosAngleError(getName());}
public int mahout_f3571_0()
{    return getIndex(getName());}
public static double mahout_f3572_0(CharSequence name)
{    return parseMetaData(name)[1];}
public static double mahout_f3573_0(CharSequence name)
{    return parseMetaData(name)[2];}
public static int mahout_f3574_0(CharSequence name)
{    return (int) parseMetaData(name)[0];}
public static double[] mahout_f3575_0(CharSequence name)
{    double[] m = new double[3];    String[] s = EQUAL_PATTERN.split(name);    m[0] = Double.parseDouble(PIPE_PATTERN.split(s[0])[1]);    m[1] = Double.parseDouble(PIPE_PATTERN.split(s[1])[1]);    m[2] = Double.parseDouble(s[2].substring(1));    return m;}
protected double[] mahout_f3576_0()
{    return parseMetaData(getName());}
public void mahout_f3577_0(VectorIterable eigens)
{    eigensToVerify = eigens;}
public int mahout_f3578_0(String[] args) throws Exception
{    Map<String, List<String>> argMap = handleArgs(args);    if (argMap == null) {        return -1;    }    if (argMap.isEmpty()) {        return 0;    }        runJob(getConf(), new Path(getOption("eigenInput")), new Path(getOption("corpusInput")), getOutputPath(), getOption("inMemory") != null, Double.parseDouble(getOption("maxError")),     Integer.parseInt(getOption("maxEigens")));    return 0;}
public int mahout_f3579_0(Path corpusInput, Path eigenInput, Path output, Path tempOut, double maxError, double minEigenValue, boolean inMemory, Configuration conf) throws IOException
{    this.outPath = output;    this.tmpOut = tempOut;    this.maxError = maxError;    this.minEigenValue = minEigenValue;    if (eigenInput != null && eigensToVerify == null) {        prepareEigens(conf, eigenInput, inMemory);    }    DistributedRowMatrix c = new DistributedRowMatrix(corpusInput, tempOut, 1, 1);    c.setConf(conf);    corpus = c;        eigenVerifier = new SimpleEigenVerifier();            Map<MatrixSlice, EigenStatus> eigenMetaData = verifyEigens();    List<Map.Entry<MatrixSlice, EigenStatus>> prunedEigenMeta = pruneEigens(eigenMetaData);    saveCleanEigens(new Configuration(), prunedEigenMeta);    return 0;}
private Map<String, List<String>> mahout_f3580_0(String[] args) throws IOException
{    addOutputOption();    addOption("eigenInput", "ei", "The Path for purported eigenVector input files (SequenceFile<WritableComparable,VectorWritable>.", null);    addOption("corpusInput", "ci", "The Path for corpus input files (SequenceFile<WritableComparable,VectorWritable>.");    addOption(DefaultOptionCreator.outputOption().create());    addOption(DefaultOptionCreator.helpOption());    addOption("inMemory", "mem", "Buffer eigen matrix into memory (if you have enough!)", "false");    addOption("maxError", "err", "Maximum acceptable error", "0.05");    addOption("minEigenvalue", "mev", "Minimum eigenvalue to keep the vector for", "0.0");    addOption("maxEigens", "max", "Maximum number of eigenvectors to keep (0 means all)", "0");    return parseArguments(args);}
private void mahout_f3581_1(Configuration conf, Collection<Map.Entry<MatrixSlice, EigenStatus>> prunedEigenMeta) throws IOException
{    Path path = new Path(outPath, CLEAN_EIGENVECTORS);    FileSystem fs = FileSystem.get(path.toUri(), conf);    SequenceFile.Writer seqWriter = new SequenceFile.Writer(fs, conf, path, IntWritable.class, VectorWritable.class);    try {        IntWritable iw = new IntWritable();        int numEigensWritten = 0;        int index = 0;        for (Map.Entry<MatrixSlice, EigenStatus> pruneSlice : prunedEigenMeta) {            MatrixSlice s = pruneSlice.getKey();            EigenStatus meta = pruneSlice.getValue();            EigenVector ev = new EigenVector(s.vector(), meta.getEigenValue(), Math.abs(1 - meta.getCosAngle()), s.index());                        Writable vw = new VectorWritable(ev);            iw.set(index++);            seqWriter.append(iw, vw);                                                numEigensWritten++;            if (numEigensWritten == maxEigensToKeep) {                                break;            }        }    } finally {        Closeables.close(seqWriter, false);    }    cleanedEigensPath = path;}
private List<Map.Entry<MatrixSlice, EigenStatus>> mahout_f3582_0(Map<MatrixSlice, EigenStatus> eigenMetaData)
{    List<Map.Entry<MatrixSlice, EigenStatus>> prunedEigenMeta = Lists.newArrayList();    for (Map.Entry<MatrixSlice, EigenStatus> entry : eigenMetaData.entrySet()) {        if (Math.abs(1 - entry.getValue().getCosAngle()) < maxError && entry.getValue().getEigenValue() > minEigenValue) {            prunedEigenMeta.add(entry);        }    }    Collections.sort(prunedEigenMeta, new Comparator<Map.Entry<MatrixSlice, EigenStatus>>() {        @Override        public int compare(Map.Entry<MatrixSlice, EigenStatus> e1, Map.Entry<MatrixSlice, EigenStatus> e2) {                        Double eg1 = e1.getValue().getEigenValue();            Double eg2 = e2.getValue().getEigenValue();            return eg1.compareTo(eg2);        }    });        List<Map.Entry<MatrixSlice, EigenStatus>> selectedEigenMeta = Lists.newArrayList();    Map.Entry<MatrixSlice, EigenStatus> e1 = prunedEigenMeta.remove(0);    selectedEigenMeta.add(e1);    int selectedEigenMetaLength = selectedEigenMeta.size();    int prunedEigenMetaLength = prunedEigenMeta.size();    while (prunedEigenMetaLength > 0) {        double sum = Double.MAX_VALUE;        int index = 0;        for (int i = 0; i < prunedEigenMetaLength; i++) {            Map.Entry<MatrixSlice, EigenStatus> e = prunedEigenMeta.get(i);            double tmp = 0;            for (int j = 0; j < selectedEigenMetaLength; j++) {                Map.Entry<MatrixSlice, EigenStatus> ee = selectedEigenMeta.get(j);                tmp += ee.getKey().vector().times(e.getKey().vector()).norm(2);            }            if (tmp < sum) {                sum = tmp;                index = i;            }        }        Map.Entry<MatrixSlice, EigenStatus> e = prunedEigenMeta.remove(index);        selectedEigenMeta.add(e);        selectedEigenMetaLength++;        prunedEigenMetaLength--;    }    return selectedEigenMeta;}
public int mahout_f3583_0(Map.Entry<MatrixSlice, EigenStatus> e1, Map.Entry<MatrixSlice, EigenStatus> e2)
{        Double eg1 = e1.getValue().getEigenValue();    Double eg2 = e2.getValue().getEigenValue();    return eg1.compareTo(eg2);}
private Map<MatrixSlice, EigenStatus> mahout_f3584_0()
{    Map<MatrixSlice, EigenStatus> eigenMetaData = Maps.newHashMap();    for (MatrixSlice slice : eigensToVerify) {        EigenStatus status = eigenVerifier.verify(corpus, slice.vector());        eigenMetaData.put(slice, status);    }    return eigenMetaData;}
private void mahout_f3585_0(Configuration conf, Path eigenInput, boolean inMemory)
{    DistributedRowMatrix eigens = new DistributedRowMatrix(eigenInput, tmpOut, 1, 1);    eigens.setConf(conf);    if (inMemory) {        List<Vector> eigenVectors = Lists.newArrayList();        for (MatrixSlice slice : eigens) {            eigenVectors.add(slice.vector());        }        eigensToVerify = new SparseRowMatrix(eigenVectors.size(), eigenVectors.get(0).size(), eigenVectors.toArray(new Vector[eigenVectors.size()]), true, true);    } else {        eigensToVerify = eigens;    }}
public Path mahout_f3586_0()
{    return cleanedEigensPath;}
public static void mahout_f3587_0(String[] args) throws Exception
{    ToolRunner.run(new EigenVerificationJob(), args);}
public void mahout_f3588_0(Configuration conf, Path eigenInput, Path corpusInput, Path output, boolean inMemory, double maxError, int maxEigens) throws IOException
{        outPath = output;    tmpOut = new Path(outPath, "tmp");    maxEigensToKeep = maxEigens;    this.maxError = maxError;    if (eigenInput != null && eigensToVerify == null) {        prepareEigens(new Configuration(conf), eigenInput, inMemory);    }    DistributedRowMatrix c = new DistributedRowMatrix(corpusInput, tmpOut, 1, 1);    c.setConf(new Configuration(conf));    corpus = c;    eigenVerifier = new SimpleEigenVerifier();    Map<MatrixSlice, EigenStatus> eigenMetaData = verifyEigens();    List<Map.Entry<MatrixSlice, EigenStatus>> prunedEigenMeta = pruneEigens(eigenMetaData);    saveCleanEigens(conf, prunedEigenMeta);}
public void mahout_f3589_1(Configuration configuration)
{    conf = configuration;    try {        setupDirs();        updateHdfsState();    } catch (IOException e) {            }}
public Configuration mahout_f3590_0()
{    return conf;}
private void mahout_f3591_0() throws IOException
{    fs = baseDir.getFileSystem(conf);    createDirIfNotExist(baseDir);    createDirIfNotExist(basisPath);    createDirIfNotExist(singularVectorPath);}
private void mahout_f3592_0(Path path) throws IOException
{    if (!fs.exists(path) && !fs.mkdirs(path)) {        throw new IOException("Unable to create: " + path);    }}
public void mahout_f3593_1(int i)
{    super.setIterationNumber(i);    try {        updateHdfsState();    } catch (IOException e) {            }}
protected void mahout_f3594_0() throws IOException
{    if (conf == null) {        return;    }    int numBasisVectorsOnDisk = 0;    Path nextBasisVectorPath = new Path(basisPath, BASIS_PREFIX + '_' + numBasisVectorsOnDisk);    while (fs.exists(nextBasisVectorPath)) {        nextBasisVectorPath = new Path(basisPath, BASIS_PREFIX + '_' + ++numBasisVectorsOnDisk);    }    Vector nextVector;    while (numBasisVectorsOnDisk < iterationNumber && (nextVector = getBasisVector(numBasisVectorsOnDisk)) != null) {        persistVector(nextBasisVectorPath, numBasisVectorsOnDisk, nextVector);        nextBasisVectorPath = new Path(basisPath, BASIS_PREFIX + '_' + ++numBasisVectorsOnDisk);    }    if (scaleFactor <= 0) {                scaleFactor = getScaleFactor();    }        diagonalMatrix = getDiagonalMatrix();    Vector norms = new DenseVector(diagonalMatrix.numCols() - 1);    Vector projections = new DenseVector(diagonalMatrix.numCols());    int i = 0;    while (i < diagonalMatrix.numCols() - 1) {        norms.set(i, diagonalMatrix.get(i, i + 1));        projections.set(i, diagonalMatrix.get(i, i));        i++;    }    projections.set(i, diagonalMatrix.get(i, i));    persistVector(new Path(baseDir, "projections"), 0, projections);    persistVector(new Path(baseDir, "norms"), 0, norms);    persistVector(new Path(baseDir, "scaleFactor"), 0, new DenseVector(new double[] { scaleFactor }));    for (Map.Entry<Integer, Vector> entry : singularVectors.entrySet()) {        persistVector(new Path(singularVectorPath, SINGULAR_PREFIX + '_' + entry.getKey()), entry.getKey(), entry.getValue());    }    super.setIterationNumber(numBasisVectorsOnDisk);}
protected void mahout_f3595_1(Path p, int key, Vector vector) throws IOException
{    SequenceFile.Writer writer = null;    try {        if (fs.exists(p)) {                        fs.delete(p, true);        }        writer = new SequenceFile.Writer(fs, conf, p, IntWritable.class, VectorWritable.class);        writer.append(new IntWritable(key), new VectorWritable(vector));    } finally {        Closeables.close(writer, false);    }}
protected Vector mahout_f3596_0(Path p, int keyIndex) throws IOException
{    if (!fs.exists(p)) {        return null;    }    SequenceFile.Reader reader = new SequenceFile.Reader(fs, p, conf);    IntWritable key = new IntWritable();    VectorWritable vw = new VectorWritable();    while (reader.next(key, vw)) {        if (key.get() == keyIndex) {            return vw.get();        }    }    return null;}
public Vector mahout_f3597_1(int i)
{    if (!basis.containsKey(i)) {        try {            Vector v = fetchVector(new Path(basisPath, BASIS_PREFIX + '_' + i), i);            basis.put(i, v);        } catch (IOException e) {                    }    }    return super.getBasisVector(i);}
public Vector mahout_f3598_1(int i)
{    if (!singularVectors.containsKey(i)) {        try {            Vector v = fetchVector(new Path(singularVectorPath, BASIS_PREFIX + '_' + i), i);            singularVectors.put(i, v);        } catch (IOException e) {                    }    }    return super.getRightSingularVector(i);}
public double mahout_f3599_1()
{    if (scaleFactor <= 0) {        try {            Vector v = fetchVector(new Path(baseDir, "scaleFactor"), 0);            if (v != null && v.size() > 0) {                scaleFactor = v.get(0);            }        } catch (IOException e) {                    }    }    return scaleFactor;}
public Matrix mahout_f3600_1()
{    if (diagonalMatrix == null) {        diagonalMatrix = new DenseMatrix(desiredRank, desiredRank);    }    if (diagonalMatrix.get(0, 1) <= 0) {        try {            Vector norms = fetchVector(new Path(baseDir, "norms"), 0);            Vector projections = fetchVector(new Path(baseDir, "projections"), 0);            if (norms != null && projections != null) {                int i = 0;                while (i < projections.size() - 1) {                    diagonalMatrix.set(i, i, projections.get(i));                    diagonalMatrix.set(i, i + 1, norms.get(i));                    diagonalMatrix.set(i + 1, i, norms.get(i));                    i++;                }                diagonalMatrix.set(i, i, projections.get(i));            }        } catch (IOException e) {                    }    }    return diagonalMatrix;}
public Configuration mahout_f3601_0()
{    return conf;}
public void mahout_f3602_0(Configuration conf)
{    this.conf = conf;    try {        FileSystem fs = FileSystem.get(inputPath.toUri(), conf);        rowPath = fs.makeQualified(inputPath);        outputTmpBasePath = fs.makeQualified(outputTmpPath);        keepTempFiles = conf.getBoolean(KEEP_TEMP_FILES, false);    } catch (IOException ioe) {        throw new IllegalStateException(ioe);    }}
public Path mahout_f3603_0()
{    return rowPath;}
public Path mahout_f3604_0()
{    return outputTmpBasePath;}
public void mahout_f3605_1(String outPathString)
{    try {        outputTmpBasePath = FileSystem.get(conf).makeQualified(new Path(outPathString));    } catch (IOException ioe) {            }}
public Iterator<MatrixSlice> mahout_f3606_0()
{    return iterator();}
public Iterator<MatrixSlice> mahout_f3607_0()
{    try {        Path pathPattern = rowPath;        if (FileSystem.get(conf).getFileStatus(rowPath).isDir()) {            pathPattern = new Path(rowPath, "*");        }        return Iterators.transform(new SequenceFileDirIterator<IntWritable, VectorWritable>(pathPattern, PathType.GLOB, PathFilters.logsCRCFilter(), null, true, conf), new Function<Pair<IntWritable, VectorWritable>, MatrixSlice>() {            @Override            public MatrixSlice apply(Pair<IntWritable, VectorWritable> from) {                return new MatrixSlice(from.getSecond().get(), from.getFirst().get());            }        });    } catch (IOException ioe) {        throw new IllegalStateException(ioe);    }}
public MatrixSlice mahout_f3608_0(Pair<IntWritable, VectorWritable> from)
{    return new MatrixSlice(from.getSecond().get(), from.getFirst().get());}
public int mahout_f3609_0()
{    return numRows();}
public int mahout_f3610_0()
{    return numRows;}
public int mahout_f3611_0()
{    return numCols;}
public DistributedRowMatrix mahout_f3612_0(DistributedRowMatrix other) throws IOException
{    return times(other, new Path(outputTmpBasePath.getParent(), "productWith-" + (System.nanoTime() & 0xFF)));}
public DistributedRowMatrix mahout_f3613_0(DistributedRowMatrix other, Path outPath) throws IOException
{    if (numRows != other.numRows()) {        throw new CardinalityException(numRows, other.numRows());    }    Configuration initialConf = getConf() == null ? new Configuration() : getConf();    Configuration conf = MatrixMultiplicationJob.createMatrixMultiplyJobConf(initialConf, rowPath, other.rowPath, outPath, other.numCols);    JobClient.runJob(new JobConf(conf));    DistributedRowMatrix out = new DistributedRowMatrix(outPath, outputTmpPath, numCols, other.numCols());    out.setConf(conf);    return out;}
public Vector mahout_f3614_0() throws IOException
{    return columnMeans("SequentialAccessSparseVector");}
public Vector mahout_f3615_0(String vectorClass) throws IOException
{    Path outputVectorTmpPath = new Path(outputTmpBasePath, new Path(Long.toString(System.nanoTime())));    Configuration initialConf = getConf() == null ? new Configuration() : getConf();    String vectorClassFull = "org.apache.mahout.math." + vectorClass;    Vector mean = MatrixColumnMeansJob.run(initialConf, rowPath, outputVectorTmpPath, vectorClassFull);    if (!keepTempFiles) {        FileSystem fs = outputVectorTmpPath.getFileSystem(conf);        fs.delete(outputVectorTmpPath, true);    }    return mean;}
public DistributedRowMatrix mahout_f3616_0() throws IOException
{    Path outputPath = new Path(rowPath.getParent(), "transpose-" + (System.nanoTime() & 0xFF));    Configuration initialConf = getConf() == null ? new Configuration() : getConf();    Job transposeJob = TransposeJob.buildTransposeJob(initialConf, rowPath, outputPath, numRows);    try {        transposeJob.waitForCompletion(true);    } catch (Exception e) {        throw new IllegalStateException("transposition failed", e);    }    DistributedRowMatrix m = new DistributedRowMatrix(outputPath, outputTmpPath, numCols, numRows);    m.setConf(this.conf);    return m;}
public Vector mahout_f3617_0(Vector v)
{    try {        Configuration initialConf = getConf() == null ? new Configuration() : getConf();        Path outputVectorTmpPath = new Path(outputTmpBasePath, new Path(Long.toString(System.nanoTime())));        Job job = TimesSquaredJob.createTimesJob(initialConf, v, numRows, rowPath, outputVectorTmpPath);        try {            job.waitForCompletion(true);        } catch (Exception e) {            throw new IllegalStateException("times failed", e);        }        Vector result = TimesSquaredJob.retrieveTimesSquaredOutputVector(outputVectorTmpPath, conf);        if (!keepTempFiles) {            FileSystem fs = outputVectorTmpPath.getFileSystem(conf);            fs.delete(outputVectorTmpPath, true);        }        return result;    } catch (IOException ioe) {        throw new IllegalStateException(ioe);    }}
public Vector mahout_f3618_0(Vector v)
{    try {        Configuration initialConf = getConf() == null ? new Configuration() : getConf();        Path outputVectorTmpPath = new Path(outputTmpBasePath, new Path(Long.toString(System.nanoTime())));        Job job = TimesSquaredJob.createTimesSquaredJob(initialConf, v, rowPath, outputVectorTmpPath);        try {            job.waitForCompletion(true);        } catch (Exception e) {            throw new IllegalStateException("timesSquared failed", e);        }        Vector result = TimesSquaredJob.retrieveTimesSquaredOutputVector(outputVectorTmpPath, conf);        if (!keepTempFiles) {            FileSystem fs = outputVectorTmpPath.getFileSystem(conf);            fs.delete(outputVectorTmpPath, true);        }        return result;    } catch (IOException ioe) {        throw new IllegalStateException(ioe);    }}
public Iterator<MatrixSlice> mahout_f3619_0()
{    return iterateAll();}
public int mahout_f3620_0()
{    return row;}
public void mahout_f3621_0(int row)
{    this.row = row;}
public int mahout_f3622_0()
{    return col;}
public void mahout_f3623_0(int col)
{    this.col = col;}
public double mahout_f3624_0()
{    return val;}
public void mahout_f3625_0(double val)
{    this.val = val;}
public int mahout_f3626_0(MatrixEntryWritable o)
{    if (row > o.row) {        return 1;    } else if (row < o.row) {        return -1;    } else {        if (col > o.col) {            return 1;        } else if (col < o.col) {            return -1;        } else {            return 0;        }    }}
public boolean mahout_f3627_0(Object o)
{    if (!(o instanceof MatrixEntryWritable)) {        return false;    }    MatrixEntryWritable other = (MatrixEntryWritable) o;    return row == other.row && col == other.col;}
public int mahout_f3628_0()
{    return row + 31 * col;}
public void mahout_f3629_0(DataOutput out) throws IOException
{    out.writeInt(row);    out.writeInt(col);    out.writeDouble(val);}
public void mahout_f3630_0(DataInput in) throws IOException
{    row = in.readInt();    col = in.readInt();    val = in.readDouble();}
public String mahout_f3631_0()
{    return "(" + row + ',' + col + "):" + val;}
public static Vector mahout_f3632_0(Configuration conf, Path inputPath, Path outputVectorTmpPath) throws IOException
{    return run(conf, inputPath, outputVectorTmpPath, null);}
public static Vector mahout_f3633_0(Configuration initialConf, Path inputPath, Path outputVectorTmpPath, String vectorClass) throws IOException
{    try {        initialConf.set(VECTOR_CLASS, vectorClass == null ? DenseVector.class.getName() : vectorClass);        Job job = new Job(initialConf, "MatrixColumnMeansJob");        job.setJarByClass(MatrixColumnMeansJob.class);        FileOutputFormat.setOutputPath(job, outputVectorTmpPath);        outputVectorTmpPath.getFileSystem(job.getConfiguration()).delete(outputVectorTmpPath, true);        job.setNumReduceTasks(1);        FileOutputFormat.setOutputPath(job, outputVectorTmpPath);        FileInputFormat.addInputPath(job, inputPath);        job.setInputFormatClass(SequenceFileInputFormat.class);        job.setOutputFormatClass(SequenceFileOutputFormat.class);        FileOutputFormat.setOutputPath(job, outputVectorTmpPath);        job.setMapperClass(MatrixColumnMeansMapper.class);        job.setReducerClass(MatrixColumnMeansReducer.class);        job.setMapOutputKeyClass(NullWritable.class);        job.setMapOutputValueClass(VectorWritable.class);        job.setOutputKeyClass(IntWritable.class);        job.setOutputValueClass(VectorWritable.class);        job.submit();        job.waitForCompletion(true);        Path tmpFile = new Path(outputVectorTmpPath, "part-r-00000");        SequenceFileValueIterator<VectorWritable> iterator = new SequenceFileValueIterator<>(tmpFile, true, initialConf);        try {            if (iterator.hasNext()) {                return iterator.next().get();            } else {                return (Vector) Class.forName(vectorClass).getConstructor(int.class).newInstance(0);            }        } finally {            Closeables.close(iterator, true);        }    } catch (IOException ioe) {        throw ioe;    } catch (Throwable thr) {        throw new IOException(thr);    }}
public void mahout_f3634_0(Context context)
{    vectorClass = context.getConfiguration().get(VECTOR_CLASS);}
public void mahout_f3635_0(Writable r, VectorWritable v, Context context) throws IOException
{    if (runningSum == null) {        /*           * If this is the first vector the mapper has seen, instantiate a new           * vector using the parameter VECTOR_CLASS           */        runningSum = ClassUtils.instantiateAs(vectorClass, Vector.class, new Class<?>[] { int.class }, new Object[] { v.get().size() + 1 });        runningSum.set(0, 1);        runningSum.viewPart(1, v.get().size()).assign(v.get());    } else {        runningSum.set(0, runningSum.get(0) + 1);        runningSum.viewPart(1, v.get().size()).assign(v.get(), Functions.PLUS);    }}
public void mahout_f3636_0(Context context) throws InterruptedException, IOException
{    if (runningSum != null) {        context.write(NullWritable.get(), new VectorWritable(runningSum));    }}
public void mahout_f3637_0(Context context)
{    vectorClass = context.getConfiguration().get(VECTOR_CLASS);}
public void mahout_f3638_0(NullWritable n, Iterable<VectorWritable> vectors, Context context) throws IOException, InterruptedException
{    /**     * Add together partial column-wise sums from mappers     */    for (VectorWritable v : vectors) {        if (outputVector == null) {            outputVector = v.get();        } else {            outputVector.assign(v.get(), Functions.PLUS);        }    }    /**     * Divide total column-wise sum by count of vectors, which corresponds to     * the number of rows in the DistributedRowMatrix     */    if (outputVector != null) {        outputVectorWritable.set(outputVector.viewPart(1, outputVector.size() - 1).divide(outputVector.get(0)));        context.write(ONE, outputVectorWritable);    } else {        Vector emptyVector = ClassUtils.instantiateAs(vectorClass, Vector.class, new Class<?>[] { int.class }, new Object[] { 0 });        context.write(ONE, new VectorWritable(emptyVector));    }}
public static Configuration mahout_f3639_0(Path aPath, Path bPath, Path outPath, int outCardinality)
{    return createMatrixMultiplyJobConf(new Configuration(), aPath, bPath, outPath, outCardinality);}
public static Configuration mahout_f3640_0(Configuration initialConf, Path aPath, Path bPath, Path outPath, int outCardinality)
{    JobConf conf = new JobConf(initialConf, MatrixMultiplicationJob.class);    conf.setInputFormat(CompositeInputFormat.class);    conf.set("mapred.join.expr", CompositeInputFormat.compose("inner", SequenceFileInputFormat.class, aPath, bPath));    conf.setInt(OUT_CARD, outCardinality);    conf.setOutputFormat(SequenceFileOutputFormat.class);    FileOutputFormat.setOutputPath(conf, outPath);    conf.setMapperClass(MatrixMultiplyMapper.class);    conf.setCombinerClass(MatrixMultiplicationReducer.class);    conf.setReducerClass(MatrixMultiplicationReducer.class);    conf.setMapOutputKeyClass(IntWritable.class);    conf.setMapOutputValueClass(VectorWritable.class);    conf.setOutputKeyClass(IntWritable.class);    conf.setOutputValueClass(VectorWritable.class);    return conf;}
public static void mahout_f3641_0(String[] args) throws Exception
{    ToolRunner.run(new MatrixMultiplicationJob(), args);}
public int mahout_f3642_0(String[] strings) throws Exception
{    addOption("numRowsA", "nra", "Number of rows of the first input matrix", true);    addOption("numColsA", "nca", "Number of columns of the first input matrix", true);    addOption("numRowsB", "nrb", "Number of rows of the second input matrix", true);    addOption("numColsB", "ncb", "Number of columns of the second input matrix", true);    addOption("inputPathA", "ia", "Path to the first input matrix", true);    addOption("inputPathB", "ib", "Path to the second input matrix", true);    addOption("outputPath", "op", "Path to the output matrix", false);    Map<String, List<String>> argMap = parseArguments(strings);    if (argMap == null) {        return -1;    }    DistributedRowMatrix a = new DistributedRowMatrix(new Path(getOption("inputPathA")), new Path(getOption("tempDir")), Integer.parseInt(getOption("numRowsA")), Integer.parseInt(getOption("numColsA")));    DistributedRowMatrix b = new DistributedRowMatrix(new Path(getOption("inputPathB")), new Path(getOption("tempDir")), Integer.parseInt(getOption("numRowsB")), Integer.parseInt(getOption("numColsB")));    a.setConf(new Configuration(getConf()));    b.setConf(new Configuration(getConf()));    if (hasOption("outputPath")) {        a.times(b, new Path(getOption("outputPath")));    } else {        a.times(b);    }    return 0;}
public void mahout_f3643_0(JobConf conf)
{    outCardinality = conf.getInt(OUT_CARD, Integer.MAX_VALUE);}
public void mahout_f3644_0(IntWritable index, TupleWritable v, OutputCollector<IntWritable, VectorWritable> out, Reporter reporter) throws IOException
{    boolean firstIsOutFrag = ((VectorWritable) v.get(0)).get().size() == outCardinality;    Vector outFrag = firstIsOutFrag ? ((VectorWritable) v.get(0)).get() : ((VectorWritable) v.get(1)).get();    Vector multiplier = firstIsOutFrag ? ((VectorWritable) v.get(1)).get() : ((VectorWritable) v.get(0)).get();    VectorWritable outVector = new VectorWritable();    for (Vector.Element e : multiplier.nonZeroes()) {        row.set(e.index());        outVector.set(outFrag.times(e.get()));        out.collect(row, outVector);    }}
public void mahout_f3645_0(IntWritable rowNum, Iterator<VectorWritable> it, OutputCollector<IntWritable, VectorWritable> out, Reporter reporter) throws IOException
{    if (!it.hasNext()) {        return;    }    Vector accumulator = new RandomAccessSparseVector(it.next().get());    while (it.hasNext()) {        Vector row = it.next().get();        accumulator.assign(row, Functions.PLUS);    }    out.collect(rowNum, new VectorWritable(new SequentialAccessSparseVector(accumulator)));}
public double mahout_f3646_0(double dots, double normA, double normB, int numberOfColumns)
{    return 1.0 / (1.0 + normA + normB - 2 * dots);}
public double mahout_f3647_0(double dots, double normA, double normB, int numberOfColumns)
{    return dots;}
public boolean mahout_f3648_0(int numNonZeroEntriesA, int numNonZeroEntriesB, double maxValueA, double maxValueB, double threshold)
{    return numNonZeroEntriesA >= threshold && numNonZeroEntriesB >= threshold;}
public Vector mahout_f3649_0(Vector vector)
{    return vector.normalize();}
public double mahout_f3650_0(Vector vector)
{    return VectorSimilarityMeasure.NO_NORM;}
public double mahout_f3651_0(double valueA, double nonZeroValueB)
{    return valueA * nonZeroValueB;}
public double mahout_f3652_0(double dots, double normA, double normB, int numberOfColumns)
{    return dots;}
public boolean mahout_f3653_0(int numNonZeroEntriesA, int numNonZeroEntriesB, double maxValueA, double maxValueB, double threshold)
{    return numNonZeroEntriesB >= threshold / maxValueA && numNonZeroEntriesA >= threshold / maxValueB;}
public Vector mahout_f3654_0(Vector vector)
{    return vector;}
public double mahout_f3655_0(Vector vector)
{    return vector.norm(0);}
public double mahout_f3656_0(double valueA, double nonZeroValueB)
{    return 1;}
public boolean mahout_f3657_0(int numNonZeroEntriesA, int numNonZeroEntriesB, double maxValueA, double maxValueB, double threshold)
{    return true;}
public Vector mahout_f3658_0(Vector vector)
{    return vector;}
public double mahout_f3659_0(Vector vector)
{    double norm = 0;    for (Vector.Element e : vector.nonZeroes()) {        double value = e.get();        norm += value * value;    }    return norm;}
public double mahout_f3660_0(double valueA, double nonZeroValueB)
{    return valueA * nonZeroValueB;}
public double mahout_f3661_0(double dots, double normA, double normB, int numberOfColumns)
{            double euclideanDistance = Math.sqrt(Math.max(0.0, normA - 2 * dots + normB));    return 1.0 / (1.0 + euclideanDistance);}
public boolean mahout_f3662_0(int numNonZeroEntriesA, int numNonZeroEntriesB, double maxValueA, double maxValueB, double threshold)
{    return true;}
public double mahout_f3663_0(double summedAggregations, double normA, double normB, int numberOfColumns)
{    double logLikelihood = LogLikelihood.logLikelihoodRatio((long) summedAggregations, (long) (normB - summedAggregations), (long) (normA - summedAggregations), (long) (numberOfColumns - normA - normB + summedAggregations));    return 1.0 - 1.0 / (1.0 + logLikelihood);}
public Vector mahout_f3664_0(Vector vector)
{    if (vector.getNumNondefaultElements() == 0) {        return vector;    }        double average = vector.norm(1) / vector.getNumNonZeroElements();    for (Vector.Element e : vector.nonZeroes()) {        e.set(e.get() - average);    }    return super.normalize(vector);}
public double mahout_f3665_0(double dots, double normA, double normB, int numberOfColumns)
{        return dots / (normA + normB - dots);}
public boolean mahout_f3666_0(int numNonZeroEntriesA, int numNonZeroEntriesB, double maxValueA, double maxValueB, double threshold)
{    return numNonZeroEntriesA >= numNonZeroEntriesB * threshold && numNonZeroEntriesB >= numNonZeroEntriesA * threshold;}
public String mahout_f3667_0()
{    return implementingClass.getName();}
public static String mahout_f3668_0()
{    return Arrays.toString(values());}
public double mahout_f3669_0()
{    return value;}
public int mahout_f3670_0()
{    return index;}
public void mahout_f3671_0(int index)
{    this.index = index;}
public void mahout_f3672_0(double value)
{    this.value = value;}
public static void mahout_f3673_0(String[] args) throws Exception
{    ToolRunner.run(new RowSimilarityJob(), args);}
public int mahout_f3674_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption("numberOfColumns", "r", "Number of columns in the input matrix", false);    addOption("similarityClassname", "s", "Name of distributed similarity class to instantiate, alternatively use " + "one of the predefined similarities (" + VectorSimilarityMeasures.list() + ')');    addOption("maxSimilaritiesPerRow", "m", "Number of maximum similarities per row (default: " + DEFAULT_MAX_SIMILARITIES_PER_ROW + ')', String.valueOf(DEFAULT_MAX_SIMILARITIES_PER_ROW));    addOption("excludeSelfSimilarity", "ess", "compute similarity of rows to themselves?", String.valueOf(false));    addOption("threshold", "tr", "discard row pairs with a similarity value below this", false);    addOption("maxObservationsPerRow", null, "sample rows down to this number of entries", String.valueOf(DEFAULT_MAX_OBSERVATIONS_PER_ROW));    addOption("maxObservationsPerColumn", null, "sample columns down to this number of entries", String.valueOf(DEFAULT_MAX_OBSERVATIONS_PER_COLUMN));    addOption("randomSeed", null, "use this seed for sampling", false);    addOption(DefaultOptionCreator.overwriteOption().create());    Map<String, List<String>> parsedArgs = parseArguments(args);    if (parsedArgs == null) {        return -1;    }    int numberOfColumns;    if (hasOption("numberOfColumns")) {                numberOfColumns = Integer.parseInt(getOption("numberOfColumns"));    } else {                numberOfColumns = getDimensions(getInputPath());    }    String similarityClassnameArg = getOption("similarityClassname");    String similarityClassname;    try {        similarityClassname = VectorSimilarityMeasures.valueOf(similarityClassnameArg).getClassname();    } catch (IllegalArgumentException iae) {        similarityClassname = similarityClassnameArg;    }        if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {                HadoopUtil.delete(getConf(), getTempPath());                HadoopUtil.delete(getConf(), getOutputPath());    }    int maxSimilaritiesPerRow = Integer.parseInt(getOption("maxSimilaritiesPerRow"));    boolean excludeSelfSimilarity = Boolean.parseBoolean(getOption("excludeSelfSimilarity"));    double threshold = hasOption("threshold") ? Double.parseDouble(getOption("threshold")) : NO_THRESHOLD;    long randomSeed = hasOption("randomSeed") ? Long.parseLong(getOption("randomSeed")) : NO_FIXED_RANDOM_SEED;    int maxObservationsPerRow = Integer.parseInt(getOption("maxObservationsPerRow"));    int maxObservationsPerColumn = Integer.parseInt(getOption("maxObservationsPerColumn"));    Path weightsPath = getTempPath("weights");    Path normsPath = getTempPath("norms.bin");    Path numNonZeroEntriesPath = getTempPath("numNonZeroEntries.bin");    Path maxValuesPath = getTempPath("maxValues.bin");    Path pairwiseSimilarityPath = getTempPath("pairwiseSimilarity");    Path observationsPerColumnPath = getTempPath("observationsPerColumn.bin");    AtomicInteger currentPhase = new AtomicInteger();    Job countObservations = prepareJob(getInputPath(), getTempPath("notUsed"), CountObservationsMapper.class, NullWritable.class, VectorWritable.class, SumObservationsReducer.class, NullWritable.class, VectorWritable.class);    countObservations.setCombinerClass(VectorSumCombiner.class);    countObservations.getConfiguration().set(OBSERVATIONS_PER_COLUMN_PATH, observationsPerColumnPath.toString());    countObservations.setNumReduceTasks(1);    countObservations.waitForCompletion(true);    if (shouldRunNextPhase(parsedArgs, currentPhase)) {        Job normsAndTranspose = prepareJob(getInputPath(), weightsPath, VectorNormMapper.class, IntWritable.class, VectorWritable.class, MergeVectorsReducer.class, IntWritable.class, VectorWritable.class);        normsAndTranspose.setCombinerClass(MergeVectorsCombiner.class);        Configuration normsAndTransposeConf = normsAndTranspose.getConfiguration();        normsAndTransposeConf.set(THRESHOLD, String.valueOf(threshold));        normsAndTransposeConf.set(NORMS_PATH, normsPath.toString());        normsAndTransposeConf.set(NUM_NON_ZERO_ENTRIES_PATH, numNonZeroEntriesPath.toString());        normsAndTransposeConf.set(MAXVALUES_PATH, maxValuesPath.toString());        normsAndTransposeConf.set(SIMILARITY_CLASSNAME, similarityClassname);        normsAndTransposeConf.set(OBSERVATIONS_PER_COLUMN_PATH, observationsPerColumnPath.toString());        normsAndTransposeConf.set(MAX_OBSERVATIONS_PER_ROW, String.valueOf(maxObservationsPerRow));        normsAndTransposeConf.set(MAX_OBSERVATIONS_PER_COLUMN, String.valueOf(maxObservationsPerColumn));        normsAndTransposeConf.set(RANDOM_SEED, String.valueOf(randomSeed));        boolean succeeded = normsAndTranspose.waitForCompletion(true);        if (!succeeded) {            return -1;        }    }    if (shouldRunNextPhase(parsedArgs, currentPhase)) {        Job pairwiseSimilarity = prepareJob(weightsPath, pairwiseSimilarityPath, CooccurrencesMapper.class, IntWritable.class, VectorWritable.class, SimilarityReducer.class, IntWritable.class, VectorWritable.class);        pairwiseSimilarity.setCombinerClass(VectorSumReducer.class);        Configuration pairwiseConf = pairwiseSimilarity.getConfiguration();        pairwiseConf.set(THRESHOLD, String.valueOf(threshold));        pairwiseConf.set(NORMS_PATH, normsPath.toString());        pairwiseConf.set(NUM_NON_ZERO_ENTRIES_PATH, numNonZeroEntriesPath.toString());        pairwiseConf.set(MAXVALUES_PATH, maxValuesPath.toString());        pairwiseConf.set(SIMILARITY_CLASSNAME, similarityClassname);        pairwiseConf.setInt(NUMBER_OF_COLUMNS, numberOfColumns);        pairwiseConf.setBoolean(EXCLUDE_SELF_SIMILARITY, excludeSelfSimilarity);        boolean succeeded = pairwiseSimilarity.waitForCompletion(true);        if (!succeeded) {            return -1;        }    }    if (shouldRunNextPhase(parsedArgs, currentPhase)) {        Job asMatrix = prepareJob(pairwiseSimilarityPath, getOutputPath(), UnsymmetrifyMapper.class, IntWritable.class, VectorWritable.class, MergeToTopKSimilaritiesReducer.class, IntWritable.class, VectorWritable.class);        asMatrix.setCombinerClass(MergeToTopKSimilaritiesReducer.class);        asMatrix.getConfiguration().setInt(MAX_SIMILARITIES_PER_ROW, maxSimilaritiesPerRow);        boolean succeeded = asMatrix.waitForCompletion(true);        if (!succeeded) {            return -1;        }    }    return 0;}
protected void mahout_f3675_0(IntWritable rowIndex, VectorWritable rowVectorWritable, Context ctx) throws IOException, InterruptedException
{    Vector row = rowVectorWritable.get();    for (Vector.Element elem : row.nonZeroes()) {        columnCounts.setQuick(elem.index(), columnCounts.getQuick(elem.index()) + 1);    }}
protected void mahout_f3676_0(Context ctx) throws IOException, InterruptedException
{    ctx.write(NullWritable.get(), new VectorWritable(columnCounts));}
protected void mahout_f3677_0(NullWritable nullWritable, Iterable<VectorWritable> partialVectors, Context ctx) throws IOException, InterruptedException
{    Vector counts = Vectors.sum(partialVectors.iterator());    Vectors.write(counts, new Path(ctx.getConfiguration().get(OBSERVATIONS_PER_COLUMN_PATH)), ctx.getConfiguration());}
protected void mahout_f3678_0(Context ctx) throws IOException, InterruptedException
{    Configuration conf = ctx.getConfiguration();    similarity = ClassUtils.instantiateAs(conf.get(SIMILARITY_CLASSNAME), VectorSimilarityMeasure.class);    norms = new RandomAccessSparseVector(Integer.MAX_VALUE);    nonZeroEntries = new RandomAccessSparseVector(Integer.MAX_VALUE);    maxValues = new RandomAccessSparseVector(Integer.MAX_VALUE);    threshold = Double.parseDouble(conf.get(THRESHOLD));    observationsPerColumn = Vectors.readAsIntMap(new Path(conf.get(OBSERVATIONS_PER_COLUMN_PATH)), conf);    maxObservationsPerRow = conf.getInt(MAX_OBSERVATIONS_PER_ROW, DEFAULT_MAX_OBSERVATIONS_PER_ROW);    maxObservationsPerColumn = conf.getInt(MAX_OBSERVATIONS_PER_COLUMN, DEFAULT_MAX_OBSERVATIONS_PER_COLUMN);    long seed = Long.parseLong(conf.get(RANDOM_SEED));    if (seed == NO_FIXED_RANDOM_SEED) {        random = RandomUtils.getRandom();    } else {        random = RandomUtils.getRandom(seed);    }}
private Vector mahout_f3679_0(Vector rowVector, Context ctx)
{    int observationsPerRow = rowVector.getNumNondefaultElements();    double rowSampleRate = (double) Math.min(maxObservationsPerRow, observationsPerRow) / (double) observationsPerRow;    Vector downsampledRow = rowVector.like();    long usedObservations = 0;    long neglectedObservations = 0;    for (Vector.Element elem : rowVector.nonZeroes()) {        int columnCount = observationsPerColumn.get(elem.index());        double columnSampleRate = (double) Math.min(maxObservationsPerColumn, columnCount) / (double) columnCount;        if (random.nextDouble() <= Math.min(rowSampleRate, columnSampleRate)) {            downsampledRow.setQuick(elem.index(), elem.get());            usedObservations++;        } else {            neglectedObservations++;        }    }    ctx.getCounter(Counters.USED_OBSERVATIONS).increment(usedObservations);    ctx.getCounter(Counters.NEGLECTED_OBSERVATIONS).increment(neglectedObservations);    return downsampledRow;}
protected void mahout_f3680_0(IntWritable row, VectorWritable vectorWritable, Context ctx) throws IOException, InterruptedException
{    Vector sampledRowVector = sampleDown(vectorWritable.get(), ctx);    Vector rowVector = similarity.normalize(sampledRowVector);    int numNonZeroEntries = 0;    double maxValue = Double.MIN_VALUE;    for (Vector.Element element : rowVector.nonZeroes()) {        RandomAccessSparseVector partialColumnVector = new RandomAccessSparseVector(Integer.MAX_VALUE);        partialColumnVector.setQuick(row.get(), element.get());        ctx.write(new IntWritable(element.index()), new VectorWritable(partialColumnVector));        numNonZeroEntries++;        if (maxValue < element.get()) {            maxValue = element.get();        }    }    if (threshold != NO_THRESHOLD) {        nonZeroEntries.setQuick(row.get(), numNonZeroEntries);        maxValues.setQuick(row.get(), maxValue);    }    norms.setQuick(row.get(), similarity.norm(rowVector));    ctx.getCounter(Counters.ROWS).increment(1);}
protected void mahout_f3681_0(Context ctx) throws IOException, InterruptedException
{    ctx.write(new IntWritable(NORM_VECTOR_MARKER), new VectorWritable(norms));    ctx.write(new IntWritable(NUM_NON_ZERO_ENTRIES_VECTOR_MARKER), new VectorWritable(nonZeroEntries));    ctx.write(new IntWritable(MAXVALUE_VECTOR_MARKER), new VectorWritable(maxValues));}
protected void mahout_f3682_0(IntWritable row, Iterable<VectorWritable> partialVectors, Context ctx) throws IOException, InterruptedException
{    ctx.write(row, new VectorWritable(Vectors.merge(partialVectors)));}
protected void mahout_f3683_0(Context ctx) throws IOException, InterruptedException
{    normsPath = new Path(ctx.getConfiguration().get(NORMS_PATH));    numNonZeroEntriesPath = new Path(ctx.getConfiguration().get(NUM_NON_ZERO_ENTRIES_PATH));    maxValuesPath = new Path(ctx.getConfiguration().get(MAXVALUES_PATH));}
protected void mahout_f3684_0(IntWritable row, Iterable<VectorWritable> partialVectors, Context ctx) throws IOException, InterruptedException
{    Vector partialVector = Vectors.merge(partialVectors);    if (row.get() == NORM_VECTOR_MARKER) {        Vectors.write(partialVector, normsPath, ctx.getConfiguration());    } else if (row.get() == MAXVALUE_VECTOR_MARKER) {        Vectors.write(partialVector, maxValuesPath, ctx.getConfiguration());    } else if (row.get() == NUM_NON_ZERO_ENTRIES_VECTOR_MARKER) {        Vectors.write(partialVector, numNonZeroEntriesPath, ctx.getConfiguration(), true);    } else {        ctx.write(row, new VectorWritable(partialVector));    }}
public int mahout_f3685_0(Vector.Element one, Vector.Element two)
{    return Ints.compare(one.index(), two.index());}
protected void mahout_f3686_0(Context ctx) throws IOException, InterruptedException
{    similarity = ClassUtils.instantiateAs(ctx.getConfiguration().get(SIMILARITY_CLASSNAME), VectorSimilarityMeasure.class);    numNonZeroEntries = Vectors.readAsIntMap(new Path(ctx.getConfiguration().get(NUM_NON_ZERO_ENTRIES_PATH)), ctx.getConfiguration());    maxValues = Vectors.read(new Path(ctx.getConfiguration().get(MAXVALUES_PATH)), ctx.getConfiguration());    threshold = Double.parseDouble(ctx.getConfiguration().get(THRESHOLD));}
private boolean mahout_f3687_0(Vector.Element occurrenceA, Vector.Element occurrenceB)
{    int numNonZeroEntriesA = numNonZeroEntries.get(occurrenceA.index());    int numNonZeroEntriesB = numNonZeroEntries.get(occurrenceB.index());    double maxValueA = maxValues.get(occurrenceA.index());    double maxValueB = maxValues.get(occurrenceB.index());    return similarity.consider(numNonZeroEntriesA, numNonZeroEntriesB, maxValueA, maxValueB, threshold);}
protected void mahout_f3688_0(IntWritable column, VectorWritable occurrenceVector, Context ctx) throws IOException, InterruptedException
{    Vector.Element[] occurrences = Vectors.toArray(occurrenceVector);    Arrays.sort(occurrences, BY_INDEX);    int cooccurrences = 0;    int prunedCooccurrences = 0;    for (int n = 0; n < occurrences.length; n++) {        Vector.Element occurrenceA = occurrences[n];        Vector dots = new RandomAccessSparseVector(Integer.MAX_VALUE);        for (int m = n; m < occurrences.length; m++) {            Vector.Element occurrenceB = occurrences[m];            if (threshold == NO_THRESHOLD || consider(occurrenceA, occurrenceB)) {                dots.setQuick(occurrenceB.index(), similarity.aggregate(occurrenceA.get(), occurrenceB.get()));                cooccurrences++;            } else {                prunedCooccurrences++;            }        }        ctx.write(new IntWritable(occurrenceA.index()), new VectorWritable(dots));    }    ctx.getCounter(Counters.COOCCURRENCES).increment(cooccurrences);    ctx.getCounter(Counters.PRUNED_COOCCURRENCES).increment(prunedCooccurrences);}
protected void mahout_f3689_0(Context ctx) throws IOException, InterruptedException
{    similarity = ClassUtils.instantiateAs(ctx.getConfiguration().get(SIMILARITY_CLASSNAME), VectorSimilarityMeasure.class);    numberOfColumns = ctx.getConfiguration().getInt(NUMBER_OF_COLUMNS, -1);    Preconditions.checkArgument(numberOfColumns > 0, "Number of columns must be greater then 0! But numberOfColumns = " + numberOfColumns);    excludeSelfSimilarity = ctx.getConfiguration().getBoolean(EXCLUDE_SELF_SIMILARITY, false);    norms = Vectors.read(new Path(ctx.getConfiguration().get(NORMS_PATH)), ctx.getConfiguration());    treshold = Double.parseDouble(ctx.getConfiguration().get(THRESHOLD));}
protected void mahout_f3690_0(IntWritable row, Iterable<VectorWritable> partialDots, Context ctx) throws IOException, InterruptedException
{    Iterator<VectorWritable> partialDotsIterator = partialDots.iterator();    Vector dots = partialDotsIterator.next().get();    while (partialDotsIterator.hasNext()) {        Vector toAdd = partialDotsIterator.next().get();        for (Element nonZeroElement : toAdd.nonZeroes()) {            dots.setQuick(nonZeroElement.index(), dots.getQuick(nonZeroElement.index()) + nonZeroElement.get());        }    }    Vector similarities = dots.like();    double normA = norms.getQuick(row.get());    for (Element b : dots.nonZeroes()) {        double similarityValue = similarity.similarity(b.get(), normA, norms.getQuick(b.index()), numberOfColumns);        if (similarityValue >= treshold) {            similarities.set(b.index(), similarityValue);        }    }    if (excludeSelfSimilarity) {        similarities.setQuick(row.get(), 0);    }    ctx.write(row, new VectorWritable(similarities));}
protected void mahout_f3691_0(Mapper.Context ctx) throws IOException, InterruptedException
{    maxSimilaritiesPerRow = ctx.getConfiguration().getInt(MAX_SIMILARITIES_PER_ROW, 0);    Preconditions.checkArgument(maxSimilaritiesPerRow > 0, "Maximum number of similarities per row must be greater then 0!");}
protected void mahout_f3692_0(IntWritable row, VectorWritable similaritiesWritable, Context ctx) throws IOException, InterruptedException
{    Vector similarities = similaritiesWritable.get();        Vector transposedPartial = new RandomAccessSparseVector(similarities.size(), 1);    TopElementsQueue topKQueue = new TopElementsQueue(maxSimilaritiesPerRow);    for (Element nonZeroElement : similarities.nonZeroes()) {        MutableElement top = topKQueue.top();        double candidateValue = nonZeroElement.get();        if (candidateValue > top.get()) {            top.setIndex(nonZeroElement.index());            top.set(candidateValue);            topKQueue.updateTop();        }        transposedPartial.setQuick(row.get(), candidateValue);        ctx.write(new IntWritable(nonZeroElement.index()), new VectorWritable(transposedPartial));        transposedPartial.setQuick(row.get(), 0.0);    }    Vector topKSimilarities = new RandomAccessSparseVector(similarities.size(), maxSimilaritiesPerRow);    for (Vector.Element topKSimilarity : topKQueue.getTopElements()) {        topKSimilarities.setQuick(topKSimilarity.index(), topKSimilarity.get());    }    ctx.write(row, new VectorWritable(topKSimilarities));}
protected void mahout_f3693_0(Context ctx) throws IOException, InterruptedException
{    maxSimilaritiesPerRow = ctx.getConfiguration().getInt(MAX_SIMILARITIES_PER_ROW, 0);    Preconditions.checkArgument(maxSimilaritiesPerRow > 0, "Maximum number of similarities per row must be greater then 0!");}
protected void mahout_f3694_0(IntWritable row, Iterable<VectorWritable> partials, Context ctx) throws IOException, InterruptedException
{    Vector allSimilarities = Vectors.merge(partials);    Vector topKSimilarities = Vectors.topKElements(maxSimilaritiesPerRow, allSimilarities);    ctx.write(row, new VectorWritable(topKSimilarities));}
public List<MutableElement> mahout_f3695_0()
{    List<MutableElement> topElements = Lists.newArrayListWithCapacity(maxSize);    while (size() > 0) {        MutableElement top = pop();                if (top.index() != SENTINEL_INDEX) {            topElements.add(top);        }    }    Collections.reverse(topElements);    return topElements;}
protected MutableElement mahout_f3696_0()
{    return new MutableElement(SENTINEL_INDEX, Double.MIN_VALUE);}
protected boolean mahout_f3697_0(MutableElement e1, MutableElement e2)
{    return e1.get() < e2.get();}
public static Vector mahout_f3698_0(Vector original, int sampleSize)
{    if (original.getNumNondefaultElements() <= sampleSize) {        return original;    }    Vector sample = new RandomAccessSparseVector(original.size(), sampleSize);    Iterator<Element> sampledElements = new FixedSizeSamplingIterator<>(sampleSize, original.nonZeroes().iterator());    while (sampledElements.hasNext()) {        Element elem = sampledElements.next();        sample.setQuick(elem.index(), elem.get());    }    return sample;}
public static Vector mahout_f3699_0(int k, Vector original)
{    if (original.getNumNondefaultElements() <= k) {        return original;    }    TopElementsQueue topKQueue = new TopElementsQueue(k);    for (Element nonZeroElement : original.nonZeroes()) {        MutableElement top = topKQueue.top();        double candidateValue = nonZeroElement.get();        if (candidateValue > top.get()) {            top.setIndex(nonZeroElement.index());            top.set(candidateValue);            topKQueue.updateTop();        }    }    Vector topKSimilarities = new RandomAccessSparseVector(original.size(), k);    for (Vector.Element topKSimilarity : topKQueue.getTopElements()) {        topKSimilarities.setQuick(topKSimilarity.index(), topKSimilarity.get());    }    return topKSimilarities;}
public static Vector mahout_f3700_0(Iterable<VectorWritable> partialVectors)
{    Iterator<VectorWritable> vectors = partialVectors.iterator();    Vector accumulator = vectors.next().get();    while (vectors.hasNext()) {        VectorWritable v = vectors.next();        if (v != null) {            for (Element nonZeroElement : v.get().nonZeroes()) {                accumulator.setQuick(nonZeroElement.index(), nonZeroElement.get());            }        }    }    return accumulator;}
public static Vector mahout_f3701_0(Iterator<VectorWritable> vectors)
{    Vector sum = vectors.next().get();    while (vectors.hasNext()) {        sum.assign(vectors.next().get(), Functions.PLUS);    }    return sum;}
public double mahout_f3702_0()
{    return value;}
public int mahout_f3703_0()
{    return index;}
public void mahout_f3704_0(double value)
{    this.value = value;}
public static Vector.Element[] mahout_f3705_0(VectorWritable vectorWritable)
{    Vector.Element[] elements = new Vector.Element[vectorWritable.get().getNumNondefaultElements()];    int k = 0;    for (Element nonZeroElement : vectorWritable.get().nonZeroes()) {        elements[k++] = new TemporaryElement(nonZeroElement.index(), nonZeroElement.get());    }    return elements;}
public static void mahout_f3706_0(Vector vector, Path path, Configuration conf) throws IOException
{    write(vector, path, conf, false);}
public static void mahout_f3707_0(Vector vector, Path path, Configuration conf, boolean laxPrecision) throws IOException
{    FileSystem fs = FileSystem.get(path.toUri(), conf);    FSDataOutputStream out = fs.create(path);    try {        VectorWritable vectorWritable = new VectorWritable(vector);        vectorWritable.setWritesLaxPrecision(laxPrecision);        vectorWritable.write(out);    } finally {        Closeables.close(out, false);    }}
public static OpenIntIntHashMap mahout_f3708_0(Path path, Configuration conf) throws IOException
{    FileSystem fs = FileSystem.get(path.toUri(), conf);    FSDataInputStream in = fs.open(path);    try {        return readAsIntMap(in);    } finally {        Closeables.close(in, true);    }}
private static OpenIntIntHashMap mahout_f3709_0(DataInput in) throws IOException
{    int flags = in.readByte();    Preconditions.checkArgument(flags >> VectorWritable.NUM_FLAGS == 0, "Unknown flags set: %d", Integer.toString(flags, 2));    boolean dense = (flags & VectorWritable.FLAG_DENSE) != 0;    boolean sequential = (flags & VectorWritable.FLAG_SEQUENTIAL) != 0;    boolean laxPrecision = (flags & VectorWritable.FLAG_LAX_PRECISION) != 0;    Preconditions.checkState(!dense && !sequential, "Only for reading sparse vectors!");    Varint.readUnsignedVarInt(in);    OpenIntIntHashMap values = new OpenIntIntHashMap();    int numNonDefaultElements = Varint.readUnsignedVarInt(in);    for (int i = 0; i < numNonDefaultElements; i++) {        int index = Varint.readUnsignedVarInt(in);        double value = laxPrecision ? in.readFloat() : in.readDouble();        values.put(index, (int) value);    }    return values;}
public static Vector mahout_f3710_0(Path path, Configuration conf) throws IOException
{    FileSystem fs = FileSystem.get(path.toUri(), conf);    FSDataInputStream in = fs.open(path);    try {        return VectorWritable.readVector(in);    } finally {        Closeables.close(in, true);    }}
public static List<NamedVector> mahout_f3711_1(Configuration conf)
{    String seedPathStr = conf.get(VectorDistanceSimilarityJob.SEEDS_PATH_KEY);    if (seedPathStr == null || seedPathStr.isEmpty()) {        return Collections.emptyList();    }    List<NamedVector> seedVectors = Lists.newArrayList();    long item = 0;    for (Writable value : new SequenceFileDirValueIterable<>(new Path(seedPathStr), PathType.LIST, PathFilters.partFilter(), conf)) {        Class<? extends Writable> valueClass = value.getClass();        if (valueClass.equals(Kluster.class)) {                        Kluster cluster = (Kluster) value;            Vector vector = cluster.getCenter();            if (vector instanceof NamedVector) {                seedVectors.add((NamedVector) vector);            } else {                seedVectors.add(new NamedVector(vector, cluster.getIdentifier()));            }        } else if (valueClass.equals(Canopy.class)) {                        Canopy canopy = (Canopy) value;            Vector vector = canopy.getCenter();            if (vector instanceof NamedVector) {                seedVectors.add((NamedVector) vector);            } else {                seedVectors.add(new NamedVector(vector, canopy.getIdentifier()));            }        } else if (valueClass.equals(Vector.class)) {            Vector vector = (Vector) value;            if (vector instanceof NamedVector) {                seedVectors.add((NamedVector) vector);            } else {                seedVectors.add(new NamedVector(vector, seedPathStr + '.' + item++));            }        } else if (valueClass.equals(VectorWritable.class) || valueClass.isInstance(VectorWritable.class)) {            VectorWritable vw = (VectorWritable) value;            Vector vector = vw.get();            if (vector instanceof NamedVector) {                seedVectors.add((NamedVector) vector);            } else {                seedVectors.add(new NamedVector(vector, seedPathStr + '.' + item++));            }        } else {            throw new IllegalStateException("Bad value class: " + valueClass);        }    }    if (seedVectors.isEmpty()) {        throw new IllegalStateException("No seeds found. Check your path: " + seedPathStr);    }        return seedVectors;}
protected void mahout_f3712_0(WritableComparable<?> key, VectorWritable value, Context context) throws IOException, InterruptedException
{    String keyName;    Vector valVec = value.get();    if (valVec instanceof NamedVector) {        keyName = ((NamedVector) valVec).getName();    } else {        keyName = key.toString();    }    Vector outVec = new DenseVector(new double[seedVectors.size()]);    int i = 0;    for (NamedVector seedVector : seedVectors) {        outVec.setQuick(i++, measure.distance(seedVector, valVec));    }    context.write(new Text(keyName), new VectorWritable(outVec));}
protected void mahout_f3713_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    Configuration conf = context.getConfiguration();    measure = ClassUtils.instantiateAs(conf.get(VectorDistanceSimilarityJob.DISTANCE_MEASURE_KEY), DistanceMeasure.class);    measure.configure(conf);    seedVectors = SeedVectorUtil.loadSeedVectors(conf);}
protected void mahout_f3714_0(WritableComparable<?> key, VectorWritable value, Context context) throws IOException, InterruptedException
{    String keyName;    Vector valVec = value.get();    if (valVec instanceof NamedVector) {        keyName = ((NamedVector) valVec).getName();    } else {        keyName = key.toString();    }    for (NamedVector seedVector : seedVectors) {        double distance = measure.distance(seedVector, valVec);        if (!usesThreshold || distance <= maxDistance) {            StringTuple outKey = new StringTuple();            outKey.add(seedVector.getName());            outKey.add(keyName);            context.write(outKey, new DoubleWritable(distance));        }    }}
protected void mahout_f3715_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    Configuration conf = context.getConfiguration();    String maxDistanceParam = conf.get(VectorDistanceSimilarityJob.MAX_DISTANCE);    if (maxDistanceParam != null) {        usesThreshold = true;        maxDistance = Double.parseDouble(maxDistanceParam);    }    measure = ClassUtils.instantiateAs(conf.get(VectorDistanceSimilarityJob.DISTANCE_MEASURE_KEY), DistanceMeasure.class);    measure.configure(conf);    seedVectors = SeedVectorUtil.loadSeedVectors(conf);}
public static void mahout_f3716_0(String[] args) throws Exception
{    ToolRunner.run(new Configuration(), new VectorDistanceSimilarityJob(), args);}
public int mahout_f3717_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption(DefaultOptionCreator.distanceMeasureOption().create());    addOption(SEEDS, "s", "The set of vectors to compute distances against.  Must fit in memory on the mapper");    addOption(MAX_DISTANCE, "mx", "set an upper-bound on distance (double) such that any pair of vectors with a" + " distance greater than this value is ignored in the output. Ignored for non pairwise output!");    addOption(DefaultOptionCreator.overwriteOption().create());    addOption(OUT_TYPE_KEY, "ot", "[pw|v] -- Define the output style: pairwise, the default, (pw) or vector (v).  " + "Pairwise is a tuple of <seed, other, distance>, vector is <other, <Vector of size the number of seeds>>.", "pw");    if (parseArguments(args) == null) {        return -1;    }    Path input = getInputPath();    Path output = getOutputPath();    Path seeds = new Path(getOption(SEEDS));    String measureClass = getOption(DefaultOptionCreator.DISTANCE_MEASURE_OPTION);    if (measureClass == null) {        measureClass = SquaredEuclideanDistanceMeasure.class.getName();    }    if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {        HadoopUtil.delete(getConf(), output);    }    DistanceMeasure measure = ClassUtils.instantiateAs(measureClass, DistanceMeasure.class);    String outType = getOption(OUT_TYPE_KEY, "pw");    Double maxDistance = null;    if ("pw".equals(outType)) {        String maxDistanceArg = getOption(MAX_DISTANCE);        if (maxDistanceArg != null) {            maxDistance = Double.parseDouble(maxDistanceArg);            Preconditions.checkArgument(maxDistance > 0.0d, "value for " + MAX_DISTANCE + " must be greater than zero");        }    }    run(getConf(), input, seeds, output, measure, outType, maxDistance);    return 0;}
public static void mahout_f3718_0(Configuration conf, Path input, Path seeds, Path output, DistanceMeasure measure, String outType) throws IOException, ClassNotFoundException, InterruptedException
{    run(conf, input, seeds, output, measure, outType, null);}
public static void mahout_f3719_0(Configuration conf, Path input, Path seeds, Path output, DistanceMeasure measure, String outType, Double maxDistance) throws IOException, ClassNotFoundException, InterruptedException
{    if (maxDistance != null) {        conf.set(MAX_DISTANCE, String.valueOf(maxDistance));    }    conf.set(DISTANCE_MEASURE_KEY, measure.getClass().getName());    conf.set(SEEDS_PATH_KEY, seeds.toString());    Job job = new Job(conf, "Vector Distance Similarity: seeds: " + seeds + " input: " + input);    job.setInputFormatClass(SequenceFileInputFormat.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    if ("pw".equalsIgnoreCase(outType)) {        job.setMapOutputKeyClass(StringTuple.class);        job.setOutputKeyClass(StringTuple.class);        job.setMapOutputValueClass(DoubleWritable.class);        job.setOutputValueClass(DoubleWritable.class);        job.setMapperClass(VectorDistanceMapper.class);    } else if ("v".equalsIgnoreCase(outType)) {        job.setMapOutputKeyClass(Text.class);        job.setOutputKeyClass(Text.class);        job.setMapOutputValueClass(VectorWritable.class);        job.setOutputValueClass(VectorWritable.class);        job.setMapperClass(VectorDistanceInvertedMapper.class);    } else {        throw new IllegalArgumentException("Invalid outType specified: " + outType);    }    job.setNumReduceTasks(0);    FileInputFormat.addInputPath(job, input);    FileOutputFormat.setOutputPath(job, output);    job.setJarByClass(VectorDistanceSimilarityJob.class);    HadoopUtil.delete(conf, output);    if (!job.waitForCompletion(true)) {        throw new IllegalStateException("VectorDistance Similarity failed processing " + seeds);    }}
public Vector mahout_f3720_0(Path inputPath, Path tempPath, int numRows, int numCols, Vector b, Preconditioner preconditioner, int maxIterations, double maxError)
{    DistributedRowMatrix matrix = new DistributedRowMatrix(inputPath, tempPath, numRows, numCols);    matrix.setConf(conf);    return solve(matrix, b, preconditioner, maxIterations, maxError);}
public Configuration mahout_f3721_0()
{    return conf;}
public void mahout_f3722_0(Configuration conf)
{    this.conf = conf;}
public int mahout_f3723_0(String[] strings) throws Exception
{    Path inputPath = new Path(AbstractJob.getOption(parsedArgs, "--input"));    Path outputPath = new Path(AbstractJob.getOption(parsedArgs, "--output"));    Path tempPath = new Path(AbstractJob.getOption(parsedArgs, "--tempDir"));    Path vectorPath = new Path(AbstractJob.getOption(parsedArgs, "--vector"));    int numRows = Integer.parseInt(AbstractJob.getOption(parsedArgs, "--numRows"));    int numCols = Integer.parseInt(AbstractJob.getOption(parsedArgs, "--numCols"));    int maxIterations = parsedArgs.containsKey("--maxIter") ? Integer.parseInt(AbstractJob.getOption(parsedArgs, "--maxIter")) : numCols + 2;    double maxError = parsedArgs.containsKey("--maxError") ? Double.parseDouble(AbstractJob.getOption(parsedArgs, "--maxError")) : ConjugateGradientSolver.DEFAULT_MAX_ERROR;    Vector b = loadInputVector(vectorPath);    Vector x = runJob(inputPath, tempPath, numRows, numCols, b, null, maxIterations, maxError);    saveOutputVector(outputPath, x);    tempPath.getFileSystem(conf).delete(tempPath, true);    return 0;}
public DistributedConjugateGradientSolverJob mahout_f3724_0()
{    return new DistributedConjugateGradientSolverJob();}
private Vector mahout_f3725_0(Path path) throws IOException
{    FileSystem fs = path.getFileSystem(conf);    try (SequenceFile.Reader reader = new SequenceFile.Reader(fs, path, conf)) {        VectorWritable value = new VectorWritable();        if (!reader.next(new IntWritable(), value)) {            throw new IOException("Input vector file is empty.");        }        return value.get();    }}
private void mahout_f3726_0(Path path, Vector v) throws IOException
{    FileSystem fs = path.getFileSystem(conf);    try (SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, path, IntWritable.class, VectorWritable.class)) {        writer.append(new IntWritable(0), new VectorWritable(v));    }}
public void mahout_f3727_0(Configuration conf)
{    DistributedConjugateGradientSolver.this.setConf(conf);}
public Configuration mahout_f3728_0()
{    return DistributedConjugateGradientSolver.this.getConf();}
public int mahout_f3729_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption("numRows", "nr", "Number of rows in the input matrix", true);    addOption("numCols", "nc", "Number of columns in the input matrix", true);    addOption("vector", "b", "Vector to solve against", true);    addOption("lambda", "l", "Scalar in A + lambda * I [default = 0]", "0.0");    addOption("symmetric", "sym", "Is the input matrix square and symmetric?", "true");    addOption("maxIter", "x", "Maximum number of iterations to run");    addOption("maxError", "err", "Maximum residual error to allow before stopping");    DistributedConjugateGradientSolver.this.parsedArgs = parseArguments(args);    if (DistributedConjugateGradientSolver.this.parsedArgs == null) {        return -1;    } else {        Configuration conf = getConf();        if (conf == null) {            conf = new Configuration();        }        DistributedConjugateGradientSolver.this.setConf(conf);        return DistributedConjugateGradientSolver.this.run(args);    }}
public static void mahout_f3730_0(String[] args) throws Exception
{    ToolRunner.run(new DistributedConjugateGradientSolver().job(), args);}
public static double mahout_f3731_0(Path input, Path output, Configuration baseConf) throws IOException, InterruptedException, ClassNotFoundException
{    VarianceTotals varianceTotals = computeVarianceTotals(input, output, baseConf);    return varianceTotals.computeVariance();}
public static double mahout_f3732_0(Path input, Path output, double mean, Configuration baseConf) throws IOException, InterruptedException, ClassNotFoundException
{    VarianceTotals varianceTotals = computeVarianceTotals(input, output, baseConf);    return varianceTotals.computeVarianceForGivenMean(mean);}
private static VarianceTotals mahout_f3733_0(Path input, Path output, Configuration baseConf) throws IOException, InterruptedException, ClassNotFoundException
{    Configuration conf = new Configuration(baseConf);    conf.set("io.serializations", "org.apache.hadoop.io.serializer.JavaSerialization," + "org.apache.hadoop.io.serializer.WritableSerialization");    Job job = HadoopUtil.prepareJob(input, output, SequenceFileInputFormat.class, StandardDeviationCalculatorMapper.class, IntWritable.class, DoubleWritable.class, StandardDeviationCalculatorReducer.class, IntWritable.class, DoubleWritable.class, SequenceFileOutputFormat.class, conf);    HadoopUtil.delete(conf, output);    job.setCombinerClass(StandardDeviationCalculatorReducer.class);    boolean succeeded = job.waitForCompletion(true);    if (!succeeded) {        throw new IllegalStateException("Job failed!");    }        Path filesPattern = new Path(output, "part-*");    double sumOfSquares = 0;    double sum = 0;    double totalCount = 0;    for (Pair<Writable, Writable> record : new SequenceFileDirIterable<>(filesPattern, PathType.GLOB, null, null, true, conf)) {        int key = ((IntWritable) record.getFirst()).get();        if (key == StandardDeviationCalculatorMapper.SUM_OF_SQUARES.get()) {            sumOfSquares += ((DoubleWritable) record.getSecond()).get();        } else if (key == StandardDeviationCalculatorMapper.TOTAL_COUNT.get()) {            totalCount += ((DoubleWritable) record.getSecond()).get();        } else if (key == StandardDeviationCalculatorMapper.SUM.get()) {            sum += ((DoubleWritable) record.getSecond()).get();        }    }    VarianceTotals varianceTotals = new VarianceTotals();    varianceTotals.setSum(sum);    varianceTotals.setSumOfSquares(sumOfSquares);    varianceTotals.setTotalCount(totalCount);    return varianceTotals;}
public static double mahout_f3734_0(Path input, Path output, Configuration baseConf) throws IOException, InterruptedException, ClassNotFoundException
{    return Math.sqrt(variance(input, output, baseConf));}
public static double mahout_f3735_0(Path input, Path output, double mean, Configuration baseConf) throws IOException, InterruptedException, ClassNotFoundException
{    return Math.sqrt(varianceForGivenMean(input, output, mean, baseConf));}
protected void mahout_f3736_0(IntWritable key, Writable value, Context context) throws IOException, InterruptedException
{    if (key.get() == -1) {        return;    }        double df = Double.NaN;    if (value instanceof LongWritable) {        df = ((LongWritable) value).get();    } else if (value instanceof DoubleWritable) {        df = ((DoubleWritable) value).get();    }    if (!Double.isNaN(df)) {                context.write(SUM_OF_SQUARES, new DoubleWritable(df * df));        context.write(SUM, new DoubleWritable(df));                context.write(TOTAL_COUNT, new DoubleWritable(1));    }}
protected void mahout_f3737_0(IntWritable key, Iterable<DoubleWritable> values, Context context) throws IOException, InterruptedException
{    double sum = 0.0;    for (DoubleWritable value : values) {        sum += value.get();    }    context.write(key, new DoubleWritable(sum));}
public double mahout_f3738_0()
{    return sumOfSquares;}
public void mahout_f3739_0(double sumOfSquares)
{    this.sumOfSquares = sumOfSquares;}
public double mahout_f3740_0()
{    return sum;}
public void mahout_f3741_0(double sum)
{    this.sum = sum;}
public double mahout_f3742_0()
{    return totalCount;}
public void mahout_f3743_0(double totalCount)
{    this.totalCount = totalCount;}
public double mahout_f3744_0()
{    return sum / totalCount;}
public double mahout_f3745_0()
{    return ((totalCount * sumOfSquares) - (sum * sum)) / (totalCount * (totalCount - 1.0));}
public double mahout_f3746_0(double mean)
{    return (sumOfSquares - totalCount * mean * mean) / (totalCount - 1.0);}
protected void mahout_f3747_0(Writable key, VectorWritable value, Context context) throws IOException, InterruptedException
{    Vector vec = value.get();    int vecSize = vec.size();    if (aCols == null) {        aCols = new Vector[vecSize];    } else if (aCols.length < vecSize) {        aCols = Arrays.copyOf(aCols, vecSize);    }    if (vec.isDense()) {        for (int i = 0; i < vecSize; i++) {            extendAColIfNeeded(i, aRowCount + 1);            aCols[i].setQuick(aRowCount, vec.getQuick(i));        }    } else if (vec.size() > 0) {        for (Vector.Element vecEl : vec.nonZeroes()) {            int i = vecEl.index();            extendAColIfNeeded(i, aRowCount + 1);            aCols[i].setQuick(aRowCount, vecEl.get());        }    }    aRowCount++;}
private void mahout_f3748_0(int col, int rowCount)
{    if (aCols[col] == null) {        aCols[col] = new SequentialAccessSparseVector(rowCount < blockHeight ? blockHeight : rowCount, 1);    } else if (aCols[col].size() < rowCount) {        Vector newVec = new SequentialAccessSparseVector(rowCount + blockHeight, aCols[col].getNumNondefaultElements() << 1);        newVec.viewPart(0, aCols[col].size()).assign(aCols[col]);        aCols[col] = newVec;    }}
protected void mahout_f3749_0(Context context) throws IOException, InterruptedException
{    try {        yiCols = new double[kp][];        for (int i = 0; i < kp; i++) {            yiCols[i] = new double[Math.min(aRowCount, blockHeight)];        }        int numPasses = (aRowCount - 1) / blockHeight + 1;        String propBtPathStr = context.getConfiguration().get(PROP_BT_PATH);        Validate.notNull(propBtPathStr, "Bt input is not set");        Path btPath = new Path(propBtPathStr);        DenseBlockWritable dbw = new DenseBlockWritable();        /*         * so it turns out that it may be much more efficient to do a few         * independent passes over Bt accumulating the entire block in memory         * than pass huge amount of blocks out to combiner. so we aim of course         * to fit entire s x (k+p) dense block in memory where s is the number         * of A rows in this split. If A is much sparser than (k+p) avg # of         * elements per row then the block may exceed the split size. if this         * happens, and if the given blockHeight is not high enough to         * accomodate this (because of memory constraints), then we start         * splitting s into several passes. since computation is cpu-bound         * anyway, it should be o.k. for supersparse inputs. (as ok it can be         * that projection is thicker than the original anyway, why would one         * use that many k+p then).         */        int lastRowIndex = -1;        for (int pass = 0; pass < numPasses; pass++) {            if (distributedBt) {                btInput = new SequenceFileDirIterator<>(btLocalPath, true, localFsConfig);            } else {                btInput = new SequenceFileDirIterator<>(btPath, PathType.GLOB, null, null, true, context.getConfiguration());            }            closeables.addFirst(btInput);            Validate.isTrue(btInput.hasNext(), "Empty B' input!");            int aRowBegin = pass * blockHeight;            int bh = Math.min(blockHeight, aRowCount - aRowBegin);            /*           * check if we need to trim block allocation           */            if (pass > 0) {                if (bh == blockHeight) {                    for (int i = 0; i < kp; i++) {                        Arrays.fill(yiCols[i], 0.0);                    }                } else {                    for (int i = 0; i < kp; i++) {                        yiCols[i] = null;                    }                    for (int i = 0; i < kp; i++) {                        yiCols[i] = new double[bh];                    }                }            }            while (btInput.hasNext()) {                Pair<IntWritable, VectorWritable> btRec = btInput.next();                int btIndex = btRec.getFirst().get();                Vector btVec = btRec.getSecond().get();                Vector aCol;                if (btIndex > aCols.length || (aCol = aCols[btIndex]) == null || aCol.size() == 0) {                    /* 100% zero A column in the block, skip it as sparse */                    continue;                }                int j = -1;                for (Vector.Element aEl : aCol.nonZeroes()) {                    j = aEl.index();                    /*               * now we compute only swathes between aRowBegin..aRowBegin+bh               * exclusive. it seems like a deficiency but in fact i think it               * will balance itself out: either A is dense and then we               * shouldn't have more than one pass and therefore filter               * conditions will never kick in. Or, the only situation where we               * can't fit Y_i block in memory is when A input is much sparser               * than k+p per row. But if this is the case, then we'd be looking               * at very few elements without engaging them in any operations so               * even then it should be ok.               */                    if (j < aRowBegin) {                        continue;                    }                    if (j >= aRowBegin + bh) {                        break;                    }                    /*               * assume btVec is dense               */                    if (xi != null) {                        /*                 * MAHOUT-817: PCA correction for B'. I rewrite the whole                 * computation loop so i don't have to check if PCA correction                 * is needed at individual element level. It looks bulkier this                 * way but perhaps less wasteful on cpu.                 */                        for (int s = 0; s < kp; s++) {                                                        double xii = xi.size() > btIndex ? xi.get(btIndex) : 0.0;                            yiCols[s][j - aRowBegin] += aEl.get() * (btVec.getQuick(s) - xii * sq.get(s));                        }                    } else {                        /*                 * no PCA correction                 */                        for (int s = 0; s < kp; s++) {                            yiCols[s][j - aRowBegin] += aEl.get() * btVec.getQuick(s);                        }                    }                }                if (lastRowIndex < j) {                    lastRowIndex = j;                }            }            /*           * so now we have stuff in yi           */            dbw.setBlock(yiCols);            outKey.setTaskItemOrdinal(pass);            context.write(outKey, dbw);            closeables.remove(btInput);            btInput.close();        }    } finally {        IOUtils.close(closeables);    }}
protected void mahout_f3750_0(Context context) throws IOException, InterruptedException
{    Configuration conf = context.getConfiguration();    int k = Integer.parseInt(conf.get(QRFirstStep.PROP_K));    int p = Integer.parseInt(conf.get(QRFirstStep.PROP_P));    kp = k + p;    outKey = new SplitPartitionedWritable(context);    blockHeight = conf.getInt(BtJob.PROP_OUTER_PROD_BLOCK_HEIGHT, -1);    distributedBt = conf.get(PROP_BT_BROADCAST) != null;    if (distributedBt) {        btLocalPath = HadoopUtil.getCachedFiles(conf);        localFsConfig = new Configuration();        localFsConfig.set("fs.default.name", "file:///");    }    /*       * PCA -related corrections (MAHOUT-817)       */    String xiPathStr = conf.get(PROP_XI_PATH);    if (xiPathStr != null) {        xi = SSVDHelper.loadAndSumUpVectors(new Path(xiPathStr), conf);        sq = SSVDHelper.loadAndSumUpVectors(new Path(conf.get(PROP_SQ_PATH)), conf);    }}
protected void mahout_f3751_0(Context context) throws IOException, InterruptedException
{    Configuration conf = context.getConfiguration();    blockHeight = conf.getInt(BtJob.PROP_OUTER_PROD_BLOCK_HEIGHT, -1);    String sbPathStr = conf.get(PROP_SB_PATH);    /*       * PCA -related corrections (MAHOUT-817)       */    if (sbPathStr != null) {        sb = SSVDHelper.loadAndSumUpVectors(new Path(sbPathStr), conf);    }}
protected void mahout_f3752_0(Context context, SplitPartitionedWritable spw) throws InterruptedException, IOException
{    IOUtils.close(closeables);    qhatCollector = createOutputCollector(QJob.OUTPUT_QHAT, spw, context, DenseBlockWritable.class);    rhatCollector = createOutputCollector(QJob.OUTPUT_RHAT, spw, context, VectorWritable.class);    qr = new QRFirstStep(context.getConfiguration(), qhatCollector, rhatCollector);    closeables.addFirst(qr);    lastTaskId = spw.getTaskId();}
protected void mahout_f3753_0(SplitPartitionedWritable key, Iterable<DenseBlockWritable> values, Context context) throws IOException, InterruptedException
{    if (key.getTaskId() != lastTaskId) {        setupBlock(context, key);    }    Iterator<DenseBlockWritable> iter = values.iterator();    DenseBlockWritable dbw = iter.next();    double[][] yiCols = dbw.getBlock();    if (iter.hasNext()) {        throw new IOException("Unexpected extra Y_i block in reducer input.");    }    long blockBase = key.getTaskItemOrdinal() * blockHeight;    int bh = yiCols[0].length;    if (yiRow == null) {        yiRow = new DenseVector(yiCols.length);    }    for (int k = 0; k < bh; k++) {        for (int j = 0; j < yiCols.length; j++) {            yiRow.setQuick(j, yiCols[j][k]);        }        key.setTaskItemOrdinal(blockBase + k);                if (sb != null) {            yiRow.assign(sb, Functions.MINUS);        }        qr.collect(key, yiRow);    }}
private Path mahout_f3754_0(String name, SplitPartitionedWritable spw, Context context) throws InterruptedException, IOException
{    String uniqueFileName = FileOutputFormat.getUniqueFile(context, name, "");    uniqueFileName = uniqueFileName.replaceFirst("-r-", "-m-");    uniqueFileName = uniqueFileName.replaceFirst("\\d+$", Matcher.quoteReplacement(NUMBER_FORMAT.format(spw.getTaskId())));    return new Path(FileOutputFormat.getWorkOutputPath(context), uniqueFileName);}
private OutputCollector<K, V> mahout_f3755_0(String name, final SplitPartitionedWritable spw, Context ctx, Class<V> valueClass) throws IOException, InterruptedException
{    Path outputPath = getSplitFilePath(name, spw, ctx);    final SequenceFile.Writer w = SequenceFile.createWriter(FileSystem.get(outputPath.toUri(), ctx.getConfiguration()), ctx.getConfiguration(), outputPath, SplitPartitionedWritable.class, valueClass);    closeables.addFirst(w);    return new OutputCollector<K, V>() {        @Override        public void collect(K key, V val) throws IOException {            w.append(spw, val);        }    };}
public void mahout_f3756_0(K key, V val) throws IOException
{    w.append(spw, val);}
protected void mahout_f3757_0(Context context) throws IOException, InterruptedException
{    IOUtils.close(closeables);}
public static void mahout_f3758_0(Configuration conf, Path[] inputAPaths, Path inputBtGlob, Path xiPath, Path sqPath, Path sbPath, Path outputPath, int aBlockRows, int minSplitSize, int k, int p, int outerProdBlockHeight, int numReduceTasks, boolean broadcastBInput) throws ClassNotFoundException, InterruptedException, IOException
{    JobConf oldApiJob = new JobConf(conf);    Job job = new Job(oldApiJob);    job.setJobName("ABt-job");    job.setJarByClass(ABtDenseOutJob.class);    job.setInputFormatClass(SequenceFileInputFormat.class);    FileInputFormat.setInputPaths(job, inputAPaths);    if (minSplitSize > 0) {        FileInputFormat.setMinInputSplitSize(job, minSplitSize);    }    FileOutputFormat.setOutputPath(job, outputPath);    SequenceFileOutputFormat.setOutputCompressionType(job, CompressionType.BLOCK);    job.setMapOutputKeyClass(SplitPartitionedWritable.class);    job.setMapOutputValueClass(DenseBlockWritable.class);    job.setOutputKeyClass(SplitPartitionedWritable.class);    job.setOutputValueClass(VectorWritable.class);    job.setMapperClass(ABtMapper.class);    job.setReducerClass(QRReducer.class);    job.getConfiguration().setInt(QJob.PROP_AROWBLOCK_SIZE, aBlockRows);    job.getConfiguration().setInt(BtJob.PROP_OUTER_PROD_BLOCK_HEIGHT, outerProdBlockHeight);    job.getConfiguration().setInt(QRFirstStep.PROP_K, k);    job.getConfiguration().setInt(QRFirstStep.PROP_P, p);    job.getConfiguration().set(PROP_BT_PATH, inputBtGlob.toString());    /*     * PCA-related options, MAHOUT-817     */    if (xiPath != null) {        job.getConfiguration().set(PROP_XI_PATH, xiPath.toString());        job.getConfiguration().set(PROP_SB_PATH, sbPath.toString());        job.getConfiguration().set(PROP_SQ_PATH, sqPath.toString());    }    job.setNumReduceTasks(numReduceTasks);        if (broadcastBInput) {        job.getConfiguration().set(PROP_BT_BROADCAST, "y");        FileSystem fs = FileSystem.get(inputBtGlob.toUri(), conf);        FileStatus[] fstats = fs.globStatus(inputBtGlob);        if (fstats != null) {            for (FileStatus fstat : fstats) {                /*           * new api is not enabled yet in our dependencies at this time, still           * using deprecated one           */                DistributedCache.addCacheFile(fstat.getPath().toUri(), job.getConfiguration());            }        }    }    job.submit();    job.waitForCompletion(false);    if (!job.isSuccessful()) {        throw new IOException("ABt job unsuccessful.");    }}
protected void mahout_f3759_0(Writable key, VectorWritable value, Context context) throws IOException, InterruptedException
{    Vector vec = value.get();    int vecSize = vec.size();    if (aCols == null) {        aCols = new Vector[vecSize];    } else if (aCols.length < vecSize) {        aCols = Arrays.copyOf(aCols, vecSize);    }    if (vec.isDense()) {        for (int i = 0; i < vecSize; i++) {            extendAColIfNeeded(i, aRowCount + 1);            aCols[i].setQuick(aRowCount, vec.getQuick(i));        }    } else {        for (Vector.Element vecEl : vec.nonZeroes()) {            int i = vecEl.index();            extendAColIfNeeded(i, aRowCount + 1);            aCols[i].setQuick(aRowCount, vecEl.get());        }    }    aRowCount++;}
private void mahout_f3760_0(int col, int rowCount)
{    if (aCols[col] == null) {        aCols[col] = new SequentialAccessSparseVector(rowCount < 10000 ? 10000 : rowCount, 1);    } else if (aCols[col].size() < rowCount) {        Vector newVec = new SequentialAccessSparseVector(rowCount << 1, aCols[col].getNumNondefaultElements() << 1);        newVec.viewPart(0, aCols[col].size()).assign(aCols[col]);        aCols[col] = newVec;    }}
protected void mahout_f3761_0(Context context) throws IOException, InterruptedException
{    try {                int lastRowIndex = -1;        while (btInput.hasNext()) {            Pair<IntWritable, VectorWritable> btRec = btInput.next();            int btIndex = btRec.getFirst().get();            Vector btVec = btRec.getSecond().get();            Vector aCol;            if (btIndex > aCols.length || (aCol = aCols[btIndex]) == null) {                continue;            }            int j = -1;            for (Vector.Element aEl : aCol.nonZeroes()) {                j = aEl.index();                                                                                yiCollector.collect((long) j, btVec.times(aEl.get()));            }            if (lastRowIndex < j) {                lastRowIndex = j;            }        }        aCols = null;                                        Vector yDummy = new SequentialAccessSparseVector(kp);                for (lastRowIndex += 1; lastRowIndex < aRowCount; lastRowIndex++) {                                    yiCollector.collect((long) lastRowIndex, yDummy);        }    } finally {        IOUtils.close(closeables);    }}
protected void mahout_f3762_0(final Context context) throws IOException, InterruptedException
{    int k = Integer.parseInt(context.getConfiguration().get(QRFirstStep.PROP_K));    int p = Integer.parseInt(context.getConfiguration().get(QRFirstStep.PROP_P));    kp = k + p;    outKey = new SplitPartitionedWritable(context);    String propBtPathStr = context.getConfiguration().get(PROP_BT_PATH);    Validate.notNull(propBtPathStr, "Bt input is not set");    Path btPath = new Path(propBtPathStr);    boolean distributedBt = context.getConfiguration().get(PROP_BT_BROADCAST) != null;    if (distributedBt) {        Path[] btFiles = HadoopUtil.getCachedFiles(context.getConfiguration());                        StringBuilder btLocalPath = new StringBuilder();        for (Path btFile : btFiles) {            if (btLocalPath.length() > 0) {                btLocalPath.append(Path.SEPARATOR_CHAR);            }            btLocalPath.append(btFile);        }        btInput = new SequenceFileDirIterator<>(new Path(btLocalPath.toString()), PathType.LIST, null, null, true, context.getConfiguration());    } else {        btInput = new SequenceFileDirIterator<>(btPath, PathType.GLOB, null, null, true, context.getConfiguration());    }        closeables.addFirst(btInput);    OutputCollector<LongWritable, SparseRowBlockWritable> yiBlockCollector = new OutputCollector<LongWritable, SparseRowBlockWritable>() {        @Override        public void collect(LongWritable blockKey, SparseRowBlockWritable block) throws IOException {            outKey.setTaskItemOrdinal((int) blockKey.get());            try {                context.write(outKey, block);            } catch (InterruptedException exc) {                throw new IOException("Interrupted", exc);            }        }    };    blockHeight = context.getConfiguration().getInt(BtJob.PROP_OUTER_PROD_BLOCK_HEIGHT, -1);    yiCollector = new SparseRowBlockAccumulator(blockHeight, yiBlockCollector);    closeables.addFirst(yiCollector);}
public void mahout_f3763_0(LongWritable blockKey, SparseRowBlockWritable block) throws IOException
{    outKey.setTaskItemOrdinal((int) blockKey.get());    try {        context.write(outKey, block);    } catch (InterruptedException exc) {        throw new IOException("Interrupted", exc);    }}
protected void mahout_f3764_0(Context context) throws IOException, InterruptedException
{    blockHeight = context.getConfiguration().getInt(BtJob.PROP_OUTER_PROD_BLOCK_HEIGHT, -1);}
protected void mahout_f3765_0(Context context, SplitPartitionedWritable spw) throws InterruptedException, IOException
{    IOUtils.close(closeables);    qhatCollector = createOutputCollector(QJob.OUTPUT_QHAT, spw, context, DenseBlockWritable.class);    rhatCollector = createOutputCollector(QJob.OUTPUT_RHAT, spw, context, VectorWritable.class);    qr = new QRFirstStep(context.getConfiguration(), qhatCollector, rhatCollector);    closeables.addFirst(qr);    lastTaskId = spw.getTaskId();}
protected void mahout_f3766_0(SplitPartitionedWritable key, Iterable<SparseRowBlockWritable> values, Context context) throws IOException, InterruptedException
{    accum.clear();    for (SparseRowBlockWritable bw : values) {        accum.plusBlock(bw);    }    if (key.getTaskId() != lastTaskId) {        setupBlock(context, key);    }    long blockBase = key.getTaskItemOrdinal() * blockHeight;    for (int k = 0; k < accum.getNumRows(); k++) {        Vector yiRow = accum.getRows()[k];        key.setTaskItemOrdinal(blockBase + accum.getRowIndices()[k]);        qr.collect(key, yiRow);    }}
private Path mahout_f3767_0(String name, SplitPartitionedWritable spw, Context context) throws InterruptedException, IOException
{    String uniqueFileName = FileOutputFormat.getUniqueFile(context, name, "");    uniqueFileName = uniqueFileName.replaceFirst("-r-", "-m-");    uniqueFileName = uniqueFileName.replaceFirst("\\d+$", Matcher.quoteReplacement(NUMBER_FORMAT.format(spw.getTaskId())));    return new Path(FileOutputFormat.getWorkOutputPath(context), uniqueFileName);}
private OutputCollector<K, V> mahout_f3768_0(String name, final SplitPartitionedWritable spw, Context ctx, Class<V> valueClass) throws IOException, InterruptedException
{    Path outputPath = getSplitFilePath(name, spw, ctx);    final SequenceFile.Writer w = SequenceFile.createWriter(FileSystem.get(outputPath.toUri(), ctx.getConfiguration()), ctx.getConfiguration(), outputPath, SplitPartitionedWritable.class, valueClass);    closeables.addFirst(w);    return new OutputCollector<K, V>() {        @Override        public void collect(K key, V val) throws IOException {            w.append(spw, val);        }    };}
public void mahout_f3769_0(K key, V val) throws IOException
{    w.append(spw, val);}
protected void mahout_f3770_0(Context context) throws IOException, InterruptedException
{    IOUtils.close(closeables);}
public static void mahout_f3771_0(Configuration conf, Path[] inputAPaths, Path inputBtGlob, Path outputPath, int aBlockRows, int minSplitSize, int k, int p, int outerProdBlockHeight, int numReduceTasks, boolean broadcastBInput) throws ClassNotFoundException, InterruptedException, IOException
{    JobConf oldApiJob = new JobConf(conf);                                                        Job job = new Job(oldApiJob);    job.setJobName("ABt-job");    job.setJarByClass(ABtJob.class);    job.setInputFormatClass(SequenceFileInputFormat.class);    FileInputFormat.setInputPaths(job, inputAPaths);    if (minSplitSize > 0) {        FileInputFormat.setMinInputSplitSize(job, minSplitSize);    }    FileOutputFormat.setOutputPath(job, outputPath);    SequenceFileOutputFormat.setOutputCompressionType(job, CompressionType.BLOCK);    job.setMapOutputKeyClass(SplitPartitionedWritable.class);    job.setMapOutputValueClass(SparseRowBlockWritable.class);    job.setOutputKeyClass(SplitPartitionedWritable.class);    job.setOutputValueClass(VectorWritable.class);    job.setMapperClass(ABtMapper.class);    job.setCombinerClass(BtJob.OuterProductCombiner.class);    job.setReducerClass(QRReducer.class);    job.getConfiguration().setInt(QJob.PROP_AROWBLOCK_SIZE, aBlockRows);    job.getConfiguration().setInt(BtJob.PROP_OUTER_PROD_BLOCK_HEIGHT, outerProdBlockHeight);    job.getConfiguration().setInt(QRFirstStep.PROP_K, k);    job.getConfiguration().setInt(QRFirstStep.PROP_P, p);    job.getConfiguration().set(PROP_BT_PATH, inputBtGlob.toString());            job.setNumReduceTasks(numReduceTasks);        if (broadcastBInput) {        job.getConfiguration().set(PROP_BT_BROADCAST, "y");        FileSystem fs = FileSystem.get(inputBtGlob.toUri(), conf);        FileStatus[] fstats = fs.globStatus(inputBtGlob);        if (fstats != null) {            for (FileStatus fstat : fstats) {                /*           * new api is not enabled yet in our dependencies at this time, still           * using deprecated one           */                DistributedCache.addCacheFile(fstat.getPath().toUri(), conf);            }        }    }    job.submit();    job.waitForCompletion(false);    if (!job.isSuccessful()) {        throw new IOException("ABt job unsuccessful.");    }}
protected void mahout_f3772_0(Writable key, VectorWritable value, Context context) throws IOException, InterruptedException
{    mapContext = context;        Vector aRow = value.get();    Vector qRow = qr.next();    int kp = qRow.size();        outputQRow(key, qRow, aRow);        if (computeSq) {        if (sqAccum == null) {            sqAccum = new DenseVector(kp);        }        sqAccum.assign(qRow, Functions.PLUS);    }    if (btRow == null) {        btRow = new DenseVector(kp);    }    if (!aRow.isDense()) {        for (Vector.Element el : aRow.nonZeroes()) {            double mul = el.get();            for (int j = 0; j < kp; j++) {                btRow.setQuick(j, mul * qRow.getQuick(j));            }            btCollector.collect((long) el.index(), btRow);        }    } else {        int n = aRow.size();        for (int i = 0; i < n; i++) {            double mul = aRow.getQuick(i);            for (int j = 0; j < kp; j++) {                btRow.setQuick(j, mul * qRow.getQuick(j));            }            btCollector.collect((long) i, btRow);        }    }}
protected void mahout_f3773_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    Configuration conf = context.getConfiguration();    Path qJobPath = new Path(conf.get(PROP_QJOB_PATH));    /*       * actually this is kind of dangerous because this routine thinks we need       * to create file name for our current job and this will use -m- so it's       * just serendipity we are calling it from the mapper too as the QJob did.       */    Path qInputPath = new Path(qJobPath, FileOutputFormat.getUniqueFile(context, QJob.OUTPUT_QHAT, ""));    blockNum = context.getTaskAttemptID().getTaskID().getId();    SequenceFileValueIterator<DenseBlockWritable> qhatInput = new SequenceFileValueIterator<>(qInputPath, true, conf);    closeables.addFirst(qhatInput);    /*       * read all r files _in order of task ids_, i.e. partitions (aka group       * nums).       *       * Note: if broadcast option is used, this comes from distributed cache       * files rather than hdfs path.       */    SequenceFileDirValueIterator<VectorWritable> rhatInput;    boolean distributedRHat = conf.get(PROP_RHAT_BROADCAST) != null;    if (distributedRHat) {        Path[] rFiles = HadoopUtil.getCachedFiles(conf);        Validate.notNull(rFiles, "no RHat files in distributed cache job definition");                Configuration lconf = new Configuration();        lconf.set("fs.default.name", "file:///");        rhatInput = new SequenceFileDirValueIterator<>(rFiles, SSVDHelper.PARTITION_COMPARATOR, true, lconf);    } else {        Path rPath = new Path(qJobPath, QJob.OUTPUT_RHAT + "-*");        rhatInput = new SequenceFileDirValueIterator<>(rPath, PathType.GLOB, null, SSVDHelper.PARTITION_COMPARATOR, true, conf);    }    Validate.isTrue(rhatInput.hasNext(), "Empty R-hat input!");    closeables.addFirst(rhatInput);    outputs = new MultipleOutputs(new JobConf(conf));    closeables.addFirst(new IOUtils.MultipleOutputsCloseableAdapter(outputs));    qr = new QRLastStep(qhatInput, rhatInput, blockNum);    closeables.addFirst(qr);    /*       * it's so happens that current QRLastStep's implementation preloads R       * sequence into memory in the constructor so it's ok to close rhat input       * now.       */    if (!rhatInput.hasNext()) {        closeables.remove(rhatInput);        rhatInput.close();    }    OutputCollector<LongWritable, SparseRowBlockWritable> btBlockCollector = new OutputCollector<LongWritable, SparseRowBlockWritable>() {        @Override        public void collect(LongWritable blockKey, SparseRowBlockWritable block) throws IOException {            try {                mapContext.write(blockKey, block);            } catch (InterruptedException exc) {                throw new IOException("Interrupted.", exc);            }        }    };    btCollector = new SparseRowBlockAccumulator(conf.getInt(PROP_OUTER_PROD_BLOCK_HEIGHT, -1), btBlockCollector);    closeables.addFirst(btCollector);        computeSq = conf.get(PROP_XI_PATH) != null;        nv = conf.getBoolean(PROP_NV, false);}
public void mahout_f3774_0(LongWritable blockKey, SparseRowBlockWritable block) throws IOException
{    try {        mapContext.write(blockKey, block);    } catch (InterruptedException exc) {        throw new IOException("Interrupted.", exc);    }}
protected void mahout_f3775_0(Context context) throws IOException, InterruptedException
{    try {        if (sqAccum != null) {            /*           * hack: we will output sq partial sums with index -1 for summation.           */            SparseRowBlockWritable sbrw = new SparseRowBlockWritable(1);            sbrw.plusRow(0, sqAccum);            LongWritable lw = new LongWritable(-1);            context.write(lw, sbrw);        }    } finally {        IOUtils.close(closeables);    }}
private void mahout_f3776_0(Writable key, Vector qRow, Vector aRow) throws IOException
{    if (nv && (aRow instanceof NamedVector)) {        qRowValue.set(new NamedVector(qRow, ((NamedVector) aRow).getName()));    } else {        qRowValue.set(qRow);    }    outputs.getCollector(OUTPUT_Q, null).collect(key, qRowValue);}
protected void mahout_f3777_0(Context context) throws IOException, InterruptedException
{    blockHeight = context.getConfiguration().getInt(PROP_OUTER_PROD_BLOCK_HEIGHT, -1);}
protected void mahout_f3778_0(Writable key, Iterable<SparseRowBlockWritable> values, Context context) throws IOException, InterruptedException
{    for (SparseRowBlockWritable bw : values) {        accum.plusBlock(bw);    }    context.write(key, accum);    accum.clear();}
protected void mahout_f3779_0(Context context) throws IOException, InterruptedException
{    IOUtils.close(closeables);}
protected void mahout_f3780_0(Context context) throws IOException, InterruptedException
{    Configuration conf = context.getConfiguration();    blockHeight = conf.getInt(PROP_OUTER_PROD_BLOCK_HEIGHT, -1);    outputBBt = conf.getBoolean(PROP_OUPTUT_BBT_PRODUCTS, false);    if (outputBBt) {        int k = conf.getInt(QJob.PROP_K, -1);        int p = conf.getInt(QJob.PROP_P, -1);        Validate.isTrue(k > 0, "invalid k parameter");        Validate.isTrue(p >= 0, "invalid p parameter");        mBBt = new UpperTriangular(k + p);    }    String xiPathStr = conf.get(PROP_XI_PATH);    if (xiPathStr != null) {        xi = SSVDHelper.loadAndSumUpVectors(new Path(xiPathStr), conf);        if (xi == null) {            throw new IOException(String.format("unable to load mean path xi from %s.", xiPathStr));        }    }    if (outputBBt || xi != null) {        outputs = new MultipleOutputs(new JobConf(conf));        closeables.addFirst(new IOUtils.MultipleOutputsCloseableAdapter(outputs));    }}
protected void mahout_f3781_0(LongWritable key, Iterable<SparseRowBlockWritable> values, Context context) throws IOException, InterruptedException
{    accum.clear();    for (SparseRowBlockWritable bw : values) {        accum.plusBlock(bw);    }        if (key.get() == -1L) {        Vector sq = accum.getRows()[0];        @SuppressWarnings("unchecked")        OutputCollector<IntWritable, VectorWritable> sqOut = outputs.getCollector(OUTPUT_SQ, null);        sqOut.collect(new IntWritable(0), new VectorWritable(sq));        return;    }    for (int k = 0; k < accum.getNumRows(); k++) {        Vector btRow = accum.getRows()[k];        btKey.set((int) (key.get() * blockHeight + accum.getRowIndices()[k]));        btValue.set(btRow);        context.write(btKey, btValue);        if (outputBBt) {            int kp = mBBt.numRows();                        for (int i = 0; i < kp; i++) {                double vi = btRow.get(i);                if (vi != 0.0) {                    for (int j = i; j < kp; j++) {                        double vj = btRow.get(j);                        if (vj != 0.0) {                            mBBt.setQuick(i, j, mBBt.getQuick(i, j) + vi * vj);                        }                    }                }            }        }                if (xi != null) {                        int btIndex = btKey.get();            double xii = xi.size() > btIndex ? xi.getQuick(btIndex) : 0.0;                        pmult.setMultiplicator(xii);            if (sbAccum == null) {                sbAccum = new DenseVector(btRow.size());            }            sbAccum.assign(btRow, pmult);        }    }}
protected void mahout_f3782_0(Context context) throws IOException, InterruptedException
{        try {        if (outputBBt) {            @SuppressWarnings("unchecked")            OutputCollector<Writable, Writable> collector = outputs.getCollector(OUTPUT_BBT, null);            collector.collect(new IntWritable(), new VectorWritable(new DenseVector(mBBt.getData())));        }                if (sbAccum != null) {            @SuppressWarnings("unchecked")            OutputCollector<IntWritable, VectorWritable> collector = outputs.getCollector(OUTPUT_SB, null);            collector.collect(new IntWritable(), new VectorWritable(sbAccum));        }    } finally {        IOUtils.close(closeables);    }}
public static void mahout_f3783_0(Configuration conf, Path[] inputPathA, Path inputPathQJob, Path xiPath, Path outputPath, int minSplitSize, int k, int p, int btBlockHeight, int numReduceTasks, boolean broadcast, Class<? extends Writable> labelClass, boolean outputBBtProducts) throws ClassNotFoundException, InterruptedException, IOException
{    JobConf oldApiJob = new JobConf(conf);    MultipleOutputs.addNamedOutput(oldApiJob, OUTPUT_Q, org.apache.hadoop.mapred.SequenceFileOutputFormat.class, labelClass, VectorWritable.class);    if (outputBBtProducts) {        MultipleOutputs.addNamedOutput(oldApiJob, OUTPUT_BBT, org.apache.hadoop.mapred.SequenceFileOutputFormat.class, IntWritable.class, VectorWritable.class);        /*       * MAHOUT-1067: if we are asked to output BBT products then named vector       * names should be propagated to Q too so that UJob could pick them up       * from there.       */        oldApiJob.setBoolean(PROP_NV, true);    }    if (xiPath != null) {                MultipleOutputs.addNamedOutput(oldApiJob, OUTPUT_SQ, org.apache.hadoop.mapred.SequenceFileOutputFormat.class, IntWritable.class, VectorWritable.class);        MultipleOutputs.addNamedOutput(oldApiJob, OUTPUT_SB, org.apache.hadoop.mapred.SequenceFileOutputFormat.class, IntWritable.class, VectorWritable.class);    }    /*     * HACK: we use old api multiple outputs since they are not available in the     * new api of either 0.20.2 or 0.20.203 but wrap it into a new api job so we     * can use new api interfaces.     */    Job job = new Job(oldApiJob);    job.setJobName("Bt-job");    job.setJarByClass(BtJob.class);    job.setInputFormatClass(SequenceFileInputFormat.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    FileInputFormat.setInputPaths(job, inputPathA);    if (minSplitSize > 0) {        FileInputFormat.setMinInputSplitSize(job, minSplitSize);    }    FileOutputFormat.setOutputPath(job, outputPath);        job.getConfiguration().set("mapreduce.output.basename", OUTPUT_BT);    FileOutputFormat.setOutputCompressorClass(job, DefaultCodec.class);    SequenceFileOutputFormat.setOutputCompressionType(job, CompressionType.BLOCK);    job.setMapOutputKeyClass(LongWritable.class);    job.setMapOutputValueClass(SparseRowBlockWritable.class);    job.setOutputKeyClass(IntWritable.class);    job.setOutputValueClass(VectorWritable.class);    job.setMapperClass(BtMapper.class);    job.setCombinerClass(OuterProductCombiner.class);    job.setReducerClass(OuterProductReducer.class);    job.getConfiguration().setInt(QJob.PROP_K, k);    job.getConfiguration().setInt(QJob.PROP_P, p);    job.getConfiguration().set(PROP_QJOB_PATH, inputPathQJob.toString());    job.getConfiguration().setBoolean(PROP_OUPTUT_BBT_PRODUCTS, outputBBtProducts);    job.getConfiguration().setInt(PROP_OUTER_PROD_BLOCK_HEIGHT, btBlockHeight);    job.setNumReduceTasks(numReduceTasks);    /*     * PCA-related options, MAHOUT-817     */    if (xiPath != null) {        job.getConfiguration().set(PROP_XI_PATH, xiPath.toString());    }    if (broadcast) {        job.getConfiguration().set(PROP_RHAT_BROADCAST, "y");        FileSystem fs = FileSystem.get(inputPathQJob.toUri(), conf);        FileStatus[] fstats = fs.globStatus(new Path(inputPathQJob, QJob.OUTPUT_RHAT + "-*"));        if (fstats != null) {            for (FileStatus fstat : fstats) {                /*           * new api is not enabled yet in our dependencies at this time, still           * using deprecated one           */                DistributedCache.addCacheFile(fstat.getPath().toUri(), job.getConfiguration());            }        }    }    job.submit();    job.waitForCompletion(false);    if (!job.isSuccessful()) {        throw new IOException("Bt job unsuccessful.");    }}
public void mahout_f3784_0(double[][] block)
{    this.block = block;}
public double[][] mahout_f3785_0()
{    return block;}
public void mahout_f3786_0(DataInput in) throws IOException
{    int m = in.readInt();    int n = in.readInt();    if (block == null) {        block = new double[m][0];    } else if (block.length != m) {        block = Arrays.copyOf(block, m);    }    for (int i = 0; i < m; i++) {        if (block[i] == null || block[i].length != n) {            block[i] = new double[n];        }        for (int j = 0; j < n; j++) {            block[i][j] = in.readDouble();        }    }}
public void mahout_f3787_0(DataOutput out) throws IOException
{    int m = block.length;    int n = block.length == 0 ? 0 : block[0].length;    out.writeInt(m);    out.writeInt(n);    for (double[] aBlock : block) {        for (int j = 0; j < n; j++) {            out.writeDouble(aBlock[j]);        }    }}
public double mahout_f3788_0(int row, int column)
{    long hash = murmur64((long) row << Integer.SIZE | column, 8, seed);    return hash / UNIFORM_DIVISOR;}
public void mahout_f3789_0(Vector aRow, double[] yRow)
{        Arrays.fill(yRow, 0.0);    if (aRow.isDense()) {        int n = aRow.size();        for (int j = 0; j < n; j++) {            accumDots(j, aRow.getQuick(j), yRow);        }    } else {        for (Element el : aRow.nonZeroes()) {            accumDots(el.index(), el.get(), yRow);        }    }}
public void mahout_f3790_0(Vector aRow, Vector yRowOut)
{    yRowOut.assign(0.0);    if (aRow.isDense()) {        int n = aRow.size();        for (int j = 0; j < n; j++) {            accumDots(j, aRow.getQuick(j), yRowOut);        }    } else {        for (Element el : aRow.nonZeroes()) {            accumDots(el.index(), el.get(), yRowOut);        }    }}
public Vector mahout_f3791_0(final Vector v)
{    int nThreads = Runtime.getRuntime().availableProcessors();    ExecutorService es = new ThreadPoolExecutor(nThreads, nThreads, 1, TimeUnit.SECONDS, new ArrayBlockingQueue<Runnable>(kp));    try {        List<Future<Double>> dotFutures = Lists.newArrayListWithCapacity(kp);        for (int i = 0; i < kp; i++) {            final int index = i;            Future<Double> dotFuture = es.submit(new Callable<Double>() {                @Override                public Double call() throws Exception {                    double result = 0.0;                    if (v.isDense()) {                        for (int k = 0; k < v.size(); k++) {                                                        result += getQuick(k, index) * v.getQuick(k);                        }                    } else {                        for (Element el : v.nonZeroes()) {                            int k = el.index();                            result += getQuick(k, index) * el.get();                        }                    }                    return result;                }            });            dotFutures.add(dotFuture);        }        try {            Vector res = new DenseVector(kp);            for (int i = 0; i < kp; i++) {                res.setQuick(i, dotFutures.get(i).get());            }            return res;        } catch (InterruptedException exc) {            throw new IllegalStateException("Interrupted", exc);        } catch (ExecutionException exc) {            if (exc.getCause() instanceof RuntimeException) {                throw (RuntimeException) exc.getCause();            } else {                throw new IllegalStateException(exc.getCause());            }        }    } finally {        es.shutdown();    }}
public Double mahout_f3792_0() throws Exception
{    double result = 0.0;    if (v.isDense()) {        for (int k = 0; k < v.size(); k++) {                        result += getQuick(k, index) * v.getQuick(k);        }    } else {        for (Element el : v.nonZeroes()) {            int k = el.index();            result += getQuick(k, index) * el.get();        }    }    return result;}
protected void mahout_f3793_0(int aIndex, double aElement, double[] yRow)
{    for (int i = 0; i < kp; i++) {        yRow[i] += getQuick(aIndex, i) * aElement;    }}
protected void mahout_f3794_0(int aIndex, double aElement, Vector yRow)
{    for (int i = 0; i < kp; i++) {        yRow.setQuick(i, yRow.getQuick(i) + getQuick(aIndex, i) * aElement);    }}
public static long mahout_f3795_0(long val, int len, long seed)
{        long m = 0xc6a4a7935bd1e995L;    long h = seed ^ len * m;    long k = val;    k *= m;    int r = 47;    k ^= k >>> r;    k *= m;    h ^= k;    h *= m;    h ^= h >>> r;    h *= m;    h ^= h >>> r;    return h;}
public static long mahout_f3796_0(byte[] val, int offset, int len, long seed)
{    long m = 0xc6a4a7935bd1e995L;    int r = 47;    long h = seed ^ (len * m);    int lt = len >>> 3;    for (int i = 0; i < lt; i++, offset += 8) {        long k = 0;        for (int j = 0; j < 8; j++) {            k <<= 8;            k |= val[offset + j] & 0xff;        }        k *= m;        k ^= k >>> r;        k *= m;        h ^= k;        h *= m;    }    if (offset < len) {        long k = 0;        while (offset < len) {            k <<= 8;            k |= val[offset] & 0xff;            offset++;        }        h ^= k;        h *= m;    }    h ^= h >>> r;    h *= m;    h ^= h >>> r;    return h;}
protected void mahout_f3797_0(Context context) throws IOException, InterruptedException
{    Configuration conf = context.getConfiguration();    int k = Integer.parseInt(conf.get(PROP_K));    int p = Integer.parseInt(conf.get(PROP_P));    kp = k + p;    long omegaSeed = Long.parseLong(conf.get(PROP_OMEGA_SEED));    omega = new Omega(omegaSeed, k + p);    String sbPathStr = conf.get(PROP_SB_PATH);    if (sbPathStr != null) {        sb = SSVDHelper.loadAndSumUpVectors(new Path(sbPathStr), conf);        if (sb == null)            throw new IOException(String.format("Unable to load s_omega from path %s.", sbPathStr));    }    outputs = new MultipleOutputs(new JobConf(conf));    closeables.addFirst(new Closeable() {        @Override        public void close() throws IOException {            outputs.close();        }    });    qHatKey = new SplitPartitionedWritable(context);    rHatKey = new SplitPartitionedWritable(context);    OutputCollector<Writable, DenseBlockWritable> qhatCollector = new OutputCollector<Writable, DenseBlockWritable>() {        @Override        @SuppressWarnings("unchecked")        public void collect(Writable nil, DenseBlockWritable dbw) throws IOException {            outputs.getCollector(OUTPUT_QHAT, null).collect(qHatKey, dbw);            qHatKey.incrementItemOrdinal();        }    };    OutputCollector<Writable, VectorWritable> rhatCollector = new OutputCollector<Writable, VectorWritable>() {        @Override        @SuppressWarnings("unchecked")        public void collect(Writable nil, VectorWritable rhat) throws IOException {            outputs.getCollector(OUTPUT_RHAT, null).collect(rHatKey, rhat);            rHatKey.incrementItemOrdinal();        }    };    qr = new QRFirstStep(conf, qhatCollector, rhatCollector);        closeables.addFirst(qr);    yRow = new DenseVector(kp);}
public void mahout_f3798_0() throws IOException
{    outputs.close();}
public void mahout_f3799_0(Writable nil, DenseBlockWritable dbw) throws IOException
{    outputs.getCollector(OUTPUT_QHAT, null).collect(qHatKey, dbw);    qHatKey.incrementItemOrdinal();}
public void mahout_f3800_0(Writable nil, VectorWritable rhat) throws IOException
{    outputs.getCollector(OUTPUT_RHAT, null).collect(rHatKey, rhat);    rHatKey.incrementItemOrdinal();}
protected void mahout_f3801_0(Writable key, VectorWritable value, Context context) throws IOException, InterruptedException
{    omega.computeYRow(value.get(), yRow);    if (sb != null) {        yRow.assign(sb, Functions.MINUS);    }    qr.collect(key, yRow);}
protected void mahout_f3802_0(Context context) throws IOException, InterruptedException
{    IOUtils.close(closeables);}
public static void mahout_f3803_0(Configuration conf, Path[] inputPaths, Path sbPath, Path outputPath, int aBlockRows, int minSplitSize, int k, int p, long seed, int numReduceTasks) throws ClassNotFoundException, InterruptedException, IOException
{    JobConf oldApiJob = new JobConf(conf);    MultipleOutputs.addNamedOutput(oldApiJob, OUTPUT_QHAT, org.apache.hadoop.mapred.SequenceFileOutputFormat.class, SplitPartitionedWritable.class, DenseBlockWritable.class);    MultipleOutputs.addNamedOutput(oldApiJob, OUTPUT_RHAT, org.apache.hadoop.mapred.SequenceFileOutputFormat.class, SplitPartitionedWritable.class, VectorWritable.class);    Job job = new Job(oldApiJob);    job.setJobName("Q-job");    job.setJarByClass(QJob.class);    job.setInputFormatClass(SequenceFileInputFormat.class);    FileInputFormat.setInputPaths(job, inputPaths);    if (minSplitSize > 0) {        FileInputFormat.setMinInputSplitSize(job, minSplitSize);    }    FileOutputFormat.setOutputPath(job, outputPath);    FileOutputFormat.setCompressOutput(job, true);    FileOutputFormat.setOutputCompressorClass(job, DefaultCodec.class);    SequenceFileOutputFormat.setOutputCompressionType(job, CompressionType.BLOCK);    job.setMapOutputKeyClass(SplitPartitionedWritable.class);    job.setMapOutputValueClass(VectorWritable.class);    job.setOutputKeyClass(SplitPartitionedWritable.class);    job.setOutputValueClass(VectorWritable.class);    job.setMapperClass(QMapper.class);    job.getConfiguration().setInt(PROP_AROWBLOCK_SIZE, aBlockRows);    job.getConfiguration().setLong(PROP_OMEGA_SEED, seed);    job.getConfiguration().setInt(PROP_K, k);    job.getConfiguration().setInt(PROP_P, p);    if (sbPath != null) {        job.getConfiguration().set(PROP_SB_PATH, sbPath.toString());    }    /*     * number of reduce tasks doesn't matter. we don't actually send anything to     * reducers.     */    job.setNumReduceTasks(0);    job.submit();    job.waitForCompletion(false);    if (!job.isSuccessful()) {        throw new IOException("Q job unsuccessful.");    }}
public void mahout_f3804_0()
{    cnt = 0;}
public void mahout_f3805_0(Matrix a)
{    assert a.rowSize() == m;    assert a.columnSize() == n;    double[] aRow = new double[n];    for (int i = 0; i < m; i++) {        Vector aRowV = a.viewRow(i);        for (int j = 0; j < n; j++) {            aRow[j] = aRowV.getQuick(j);        }        appendRow(aRow);    }}
public boolean mahout_f3806_0()
{    return cnt == m;}
public int mahout_f3807_0()
{    return m;}
public int mahout_f3808_0()
{    return n;}
public int mahout_f3809_0()
{    return cnt;}
public void mahout_f3810_0(int newM)
{    if (newM == m) {                return;    }    if (newM < n) {        throw new IllegalArgumentException("new m can't be less than n");    }    if (newM < cnt) {        throw new IllegalArgumentException("new m can't be less than rows accumulated");    }    vQtRow = new double[newM];        if (newM > m) {                for (int i = 0; i < n; i++) {            mQt[i] = Arrays.copyOf(mQt[i], newM);            System.arraycopy(mQt[i], 0, mQt[i], newM - m, m);            Arrays.fill(mQt[i], 0, newM - m, 0);        }    } else {                for (int i = 0; i < n; i++) {            mQt[i] = Arrays.copyOfRange(mQt[i], m - newM, m);        }    }    m = newM;}
public void mahout_f3811_0()
{    adjust(cnt);}
public void mahout_f3812_0(double[] aRow)
{    if (cnt >= m) {        throw new IllegalStateException("thin QR solver fed more rows than initialized for");    }    try {        /*       * moving pointers around is inefficient but for the sanity's sake i am       * keeping it this way so i don't have to guess how R-tilde index maps to       * actual block index       */        Arrays.fill(vQtRow, 0);        vQtRow[m - cnt - 1] = 1;        int height = cnt > n ? n : cnt;        System.arraycopy(aRow, 0, vARow, 0, n);        if (height > 0) {            givens(vARow[0], getRRow(0)[0], cs);            applyGivensInPlace(cs[0], cs[1], vARow, getRRow(0), 0, n);            applyGivensInPlace(cs[0], cs[1], vQtRow, getQtRow(0), 0, m);        }        for (int i = 1; i < height; i++) {            givens(getRRow(i - 1)[i], getRRow(i)[i], cs);            applyGivensInPlace(cs[0], cs[1], getRRow(i - 1), getRRow(i), i, n - i);            applyGivensInPlace(cs[0], cs[1], getQtRow(i - 1), getQtRow(i), 0, m);        }        /*       * push qt and r-tilde 1 row down       *        * just swap the references to reduce GC churning       */        pushQtDown();        double[] swap = getQtRow(0);        setQtRow(0, vQtRow);        vQtRow = swap;        pushRDown();        swap = getRRow(0);        setRRow(0, vARow);        vARow = swap;    } finally {        cnt++;    }}
private double[] mahout_f3813_0(int row)
{    return mQt[(row += qtStartRow) >= n ? row - n : row];}
private void mahout_f3814_0(int row, double[] qtRow)
{    mQt[(row += qtStartRow) >= n ? row - n : row] = qtRow;}
private void mahout_f3815_0()
{    qtStartRow = qtStartRow == 0 ? n - 1 : qtStartRow - 1;}
private double[] mahout_f3816_0(int row)
{    row += rStartRow;    return mR[row >= n ? row - n : row];}
private void mahout_f3817_0(int row, double[] rrow)
{    mR[(row += rStartRow) >= n ? row - n : row] = rrow;}
private void mahout_f3818_0()
{    rStartRow = rStartRow == 0 ? n - 1 : rStartRow - 1;}
public UpperTriangular mahout_f3819_0()
{    UpperTriangular packedR = new UpperTriangular(n);    for (int i = 0; i < n; i++) {        packedR.assignNonZeroElementsInRow(i, getRRow(i));    }    return packedR;}
public double[][] mahout_f3820_0()
{    if (qtStartRow != 0) {        /*       * rotate qt rows into place       *        * double[~500][], once per block, not a big deal.       */        double[][] qt = new double[n][];        System.arraycopy(mQt, qtStartRow, qt, 0, n - qtStartRow);        System.arraycopy(mQt, 0, qt, n - qtStartRow, qtStartRow);        return qt;    }    return mQt;}
public static void mahout_f3821_0(double c, double s, double[] row1, double[] row2, int offset, int len)
{    int n = offset + len;    for (int j = offset; j < n; j++) {        double tau1 = row1[j];        double tau2 = row2[j];        row1[j] = c * tau1 - s * tau2;        row2[j] = s * tau1 + c * tau2;    }}
public static void mahout_f3822_0(double c, double s, Vector row1, Vector row2, int offset, int len)
{    int n = offset + len;    for (int j = offset; j < n; j++) {        double tau1 = row1.getQuick(j);        double tau2 = row2.getQuick(j);        row1.setQuick(j, c * tau1 - s * tau2);        row2.setQuick(j, s * tau1 + c * tau2);    }}
public static void mahout_f3823_0(double c, double s, int i, int k, Matrix mx)
{    int n = mx.columnSize();    for (int j = 0; j < n; j++) {        double tau1 = mx.get(i, j);        double tau2 = mx.get(k, j);        mx.set(i, j, c * tau1 - s * tau2);        mx.set(k, j, s * tau1 + c * tau2);    }}
public static void mahout_f3824_0(double rho, double[] csOut)
{    if (rho == 1) {        csOut[0] = 0;        csOut[1] = 1;        return;    }    if (Math.abs(rho) < 1) {        csOut[1] = 2 * rho;        csOut[0] = Math.sqrt(1 - csOut[1] * csOut[1]);        return;    }    csOut[0] = 2 / rho;    csOut[1] = Math.sqrt(1 - csOut[0] * csOut[0]);}
public static void mahout_f3825_0(double a, double b, double[] csOut)
{    if (b == 0) {        csOut[0] = 1;        csOut[1] = 0;        return;    }    if (Math.abs(b) > Math.abs(a)) {        double tau = -a / b;        csOut[1] = 1 / Math.sqrt(1 + tau * tau);        csOut[0] = csOut[1] * tau;    } else {        double tau = -b / a;        csOut[0] = 1 / Math.sqrt(1 + tau * tau);        csOut[1] = csOut[0] * tau;    }}
public static double mahout_f3826_0(double c, double s)
{    if (c == 0) {        return 1;    }    if (Math.abs(s) < Math.abs(c)) {        return Math.signum(c) * s / 2;    } else {        return Math.signum(s) * 2 / c;    }}
public static void mahout_f3827_0(UpperTriangular r1, UpperTriangular r2)
{    TriangularRowView r1Row = new TriangularRowView(r1);    TriangularRowView r2Row = new TriangularRowView(r2);    int kp = r1Row.size();    assert kp == r2Row.size();    double[] cs = new double[2];    for (int v = 0; v < kp; v++) {        for (int u = v; u < kp; u++) {            givens(r1Row.setViewedRow(u).get(u), r2Row.setViewedRow(u - v).get(u), cs);            applyGivensInPlace(cs[0], cs[1], r1Row, r2Row, u, kp - u);        }    }}
public static void mahout_f3828_0(double[][] r1, double[][] r2)
{    int kp = r1[0].length;    assert kp == r2[0].length;    double[] cs = new double[2];    for (int v = 0; v < kp; v++) {        for (int u = v; u < kp; u++) {            givens(r1[u][u], r2[u - v][u], cs);            applyGivensInPlace(cs[0], cs[1], r1[u], r2[u - v], u, kp - u);        }    }}
public static void mahout_f3829_0(UpperTriangular r1, UpperTriangular r2, double[][] qt1, double[][] qt2)
{    TriangularRowView r1Row = new TriangularRowView(r1);    TriangularRowView r2Row = new TriangularRowView(r2);    int kp = r1Row.size();    assert kp == r2Row.size();    assert kp == qt1.length;    assert kp == qt2.length;    int r = qt1[0].length;    assert qt2[0].length == r;    double[] cs = new double[2];    for (int v = 0; v < kp; v++) {        for (int u = v; u < kp; u++) {            givens(r1Row.setViewedRow(u).get(u), r2Row.setViewedRow(u - v).get(u), cs);            applyGivensInPlace(cs[0], cs[1], r1Row, r2Row, u, kp - u);            applyGivensInPlace(cs[0], cs[1], qt1[u], qt2[u - v], 0, r);        }    }}
public static void mahout_f3830_0(double[][] r1, double[][] r2, double[][] qt1, double[][] qt2)
{    int kp = r1[0].length;    assert kp == r2[0].length;    assert kp == qt1.length;    assert kp == qt2.length;    int r = qt1[0].length;    assert qt2[0].length == r;    double[] cs = new double[2];    /*     * pairwise givens(a,b) so that a come off main diagonal in r1 and bs come     * off u-th upper subdiagonal in r2.     */    for (int v = 0; v < kp; v++) {        for (int u = v; u < kp; u++) {            givens(r1[u][u], r2[u - v][u], cs);            applyGivensInPlace(cs[0], cs[1], r1[u], r2[u - v], u, kp - u);            applyGivensInPlace(cs[0], cs[1], qt1[u], qt2[u - v], 0, r);        }    }}
public static double[][] mahout_f3831_0(double[][] qt1, double[][] r1, double[][] r2)
{    int kp = qt1.length;    int r = qt1[0].length;    double[][] qTilde = new double[kp][];    for (int i = 0; i < kp; i++) {        qTilde[i] = new double[r];    }    mergeRonQ(r1, r2, qt1, qTilde);    return qt1;}
public static double[][] mahout_f3832_0(double[][] qt1, UpperTriangular r1, UpperTriangular r2)
{    int kp = qt1.length;    int r = qt1[0].length;    double[][] qTilde = new double[kp][];    for (int i = 0; i < kp; i++) {        qTilde[i] = new double[r];    }    mergeRonQ(r1, r2, qt1, qTilde);    return qt1;}
public static double[][] mahout_f3833_0(double[][] r1, double[][] qt2, double[][] r2)
{    int kp = qt2.length;    int r = qt2[0].length;    double[][] qTilde = new double[kp][];    for (int i = 0; i < kp; i++) {        qTilde[i] = new double[r];    }    mergeRonQ(r1, r2, qTilde, qt2);    return qTilde;}
public static double[][] mahout_f3834_0(UpperTriangular r1, double[][] qt2, UpperTriangular r2)
{    int kp = qt2.length;    int r = qt2[0].length;    double[][] qTilde = new double[kp][];    for (int i = 0; i < kp; i++) {        qTilde[i] = new double[r];    }    mergeRonQ(r1, r2, qTilde, qt2);    return qTilde;}
public static double[][] mahout_f3835_0(double[][] qt, int i, Iterator<UpperTriangular> rIter)
{    UpperTriangular rTilde = rIter.next();    for (int j = 1; j < i; j++) {        mergeR(rTilde, rIter.next());    }    if (i > 0) {        qt = mergeQrDown(rTilde, qt, rIter.next());    }    while (rIter.hasNext()) {        qt = mergeQrUp(qt, rTilde, rIter.next());    }    return qt;}
public static boolean mahout_f3836_0(double[][] qt, boolean insufficientRank, double epsilon)
{    int n = qt.length;    int rank = 0;    for (int i = 0; i < n; i++) {        Vector ei = new DenseVector(qt[i], true);        double norm = ei.norm(2);        if (Math.abs(1.0 - norm) < epsilon) {            rank++;        } else if (Math.abs(norm) > epsilon) {                        return false;        }        for (int j = 0; j <= i; j++) {            Vector ej = new DenseVector(qt[j], true);            double dot = ei.dot(ej);            if (!(Math.abs((i == j && rank > j ? 1.0 : 0.0) - dot) < epsilon)) {                return false;            }        }    }    return insufficientRank ? rank < n : rank == n;}
public static boolean mahout_f3837_0(Iterable<double[][]> qtHats, boolean insufficientRank, double epsilon)
{    int n = qtHats.iterator().next().length;    int rank = 0;    for (int i = 0; i < n; i++) {        List<Vector> ei = Lists.newArrayList();                for (double[][] qtHat : qtHats) {            ei.add(new DenseVector(qtHat[i], true));        }        double norm = 0;        for (Vector v : ei) {            norm += v.dot(v);        }        norm = Math.sqrt(norm);        if (Math.abs(1 - norm) < epsilon) {            rank++;        } else if (Math.abs(norm) > epsilon) {                        return false;        }        for (int j = 0; j <= i; j++) {            List<Vector> ej = Lists.newArrayList();            for (double[][] qtHat : qtHats) {                ej.add(new DenseVector(qtHat[j], true));            }                        double dot = 0;            for (int k = 0; k < ei.size(); k++) {                dot += ei.get(k).dot(ej.get(k));            }            if (!(Math.abs((i == j && rank > j ? 1 : 0) - dot) < epsilon)) {                return false;            }        }    }    return insufficientRank ? rank < n : rank == n;}
 TriangularRowView mahout_f3838_0(int row)
{    rowNum = row;    return this;}
public boolean mahout_f3839_0()
{    return true;}
public boolean mahout_f3840_0()
{    return false;}
public Iterator<Element> mahout_f3841_0()
{    throw new UnsupportedOperationException();}
public Iterator<Element> mahout_f3842_0()
{    throw new UnsupportedOperationException();}
public double mahout_f3843_0(int index)
{    return viewed.getQuick(rowNum, index);}
public Vector mahout_f3844_0()
{    throw new UnsupportedOperationException();}
public Vector mahout_f3845_0(int cardinality)
{    throw new UnsupportedOperationException();}
public void mahout_f3846_0(int index, double value)
{    viewed.setQuick(rowNum, index, value);}
public int mahout_f3847_0()
{    throw new UnsupportedOperationException();}
public double mahout_f3848_0()
{    return 1;}
public double mahout_f3849_0()
{    return 1;}
public boolean mahout_f3850_0()
{    return true;}
public Matrix mahout_f3851_0(int rows, int columns)
{    throw new UnsupportedOperationException();}
public void mahout_f3852_0(OrderedIntDoubleMapping updates)
{    int[] indices = updates.getIndices();    double[] values = updates.getValues();    for (int i = 0; i < updates.getNumMappings(); ++i) {        viewed.setQuick(rowNum, indices[i], values[i]);    }}
public static void mahout_f3853_0(Matrix mx)
{    int n = mx.numCols();    for (int c = 0; c < n; c++) {        Vector col = mx.viewColumn(c);        for (int c1 = 0; c1 < c; c1++) {            Vector viewC1 = mx.viewColumn(c1);            col.assign(col.minus(viewC1.times(viewC1.dot(col))));        }        final double norm2 = col.norm(2);        col.assign(new DoubleFunction() {            @Override            public double apply(double x) {                return x / norm2;            }        });    }}
public double mahout_f3854_0(double x)
{    return x / norm2;}
public void mahout_f3855_0() throws IOException
{    cleanup();}
public int mahout_f3856_0()
{    return kp;}
private void mahout_f3857_0() throws IOException
{    UpperTriangular r = qSolver.getRTilde();    double[][] qt = qSolver.getThinQtTilde();    rSubseq.add(r);    value.setBlock(qt);    getTempQw().append(tempKey, value);    /*     * this probably should be a sparse row matrix, but compressor should get it     * for disk and in memory we want it dense anyway, sparse random     * implementations would be a mostly a memory management disaster consisting     * of rehashes and GC      */    value.setBlock(null);    qSolver.reset();}
private void mahout_f3858_0() throws IOException
{    if (blockCnt == 1) {        /*       * only one block, no temp file, no second pass. should be the default       * mode for efficiency in most cases. Sure mapper should be able to load       * the entire split in memory -- and we don't require even that.       */        value.setBlock(qSolver.getThinQtTilde());        outputQHat(value);        outputR(new VectorWritable(new DenseVector(qSolver.getRTilde().getData(), true)));    } else {        secondPass();    }}
private void mahout_f3859_0(DenseBlockWritable value) throws IOException
{    qtHatOut.collect(NullWritable.get(), value);}
private void mahout_f3860_0(VectorWritable value) throws IOException
{    rHatOut.collect(NullWritable.get(), value);}
private void mahout_f3861_0() throws IOException
{        qSolver = null;    FileSystem localFs = FileSystem.getLocal(jobConf);    SequenceFile.Reader tempQr = new SequenceFile.Reader(localFs, tempQPath, jobConf);    closeables.addFirst(tempQr);    int qCnt = 0;    while (tempQr.next(tempKey, value)) {        value.setBlock(GivensThinSolver.computeQtHat(value.getBlock(), qCnt, new CopyConstructorIterator<>(rSubseq.iterator())));        if (qCnt == 1) {            /*         * just merge r[0] <- r[1] so it doesn't have to repeat in subsequent         * computeQHat iterators         */            GivensThinSolver.mergeR(rSubseq.get(0), rSubseq.remove(1));        } else {            qCnt++;        }        outputQHat(value);    }    assert rSubseq.size() == 1;    outputR(new VectorWritable(new DenseVector(rSubseq.get(0).getData(), true)));}
protected void mahout_f3862_0(Vector incomingYRow) throws IOException
{    double[] yRow;    if (yLookahead.size() == kp) {        if (qSolver.isFull()) {            flushSolver();            blockCnt++;        }        yRow = yLookahead.remove(0);        qSolver.appendRow(yRow);    } else {        yRow = new double[kp];    }    if (incomingYRow.isDense()) {        for (int i = 0; i < kp; i++) {            yRow[i] = incomingYRow.get(i);        }    } else {        Arrays.fill(yRow, 0);        for (Element yEl : incomingYRow.nonZeroes()) {            yRow[yEl.index()] = yEl.get();        }    }    yLookahead.add(yRow);}
protected void mahout_f3863_0()
{    int r = Integer.parseInt(jobConf.get(PROP_AROWBLOCK_SIZE));    int k = Integer.parseInt(jobConf.get(PROP_K));    int p = Integer.parseInt(jobConf.get(PROP_P));    kp = k + p;    yLookahead = Lists.newArrayListWithCapacity(kp);    qSolver = new GivensThinSolver(r, kp);    outputs = new MultipleOutputs(new JobConf(jobConf));    closeables.addFirst(new Closeable() {        @Override        public void close() throws IOException {            outputs.close();        }    });}
public void mahout_f3864_0() throws IOException
{    outputs.close();}
protected void mahout_f3865_0() throws IOException
{    try {        if (qSolver == null && yLookahead.isEmpty()) {            return;        }        if (qSolver == null) {            qSolver = new GivensThinSolver(yLookahead.size(), kp);        }                qSolver.adjust(qSolver.getCnt() + yLookahead.size());        while (!yLookahead.isEmpty()) {            qSolver.appendRow(yLookahead.remove(0));        }        assert qSolver.isFull();        if (++blockCnt > 1) {            flushSolver();            assert tempQw != null;            closeables.remove(tempQw);            Closeables.close(tempQw, false);        }        flushQBlocks();    } finally {        IOUtils.close(closeables);    }}
private SequenceFile.Writer mahout_f3866_0() throws IOException
{    if (tempQw == null) {        /*       * temporary Q output hopefully will not exceed size of IO cache in which       * case it is only good since it is going to be managed by kernel, not       * java GC. And if IO cache is not good enough, then at least it is always       * sequential.       */        String taskTmpDir = System.getProperty("java.io.tmpdir");        FileSystem localFs = FileSystem.getLocal(jobConf);        Path parent = new Path(taskTmpDir);        Path sub = new Path(parent, "qw_" + System.currentTimeMillis());        tempQPath = new Path(sub, "q-temp.seq");        tempQw = SequenceFile.createWriter(localFs, jobConf, tempQPath, IntWritable.class, DenseBlockWritable.class, CompressionType.BLOCK);        closeables.addFirst(tempQw);        closeables.addFirst(new IOUtils.DeleteFileOnClose(new File(tempQPath.toString())));    }    return tempQw;}
public void mahout_f3867_0(Writable key, Vector vw) throws IOException
{    map(vw);}
private boolean mahout_f3868_0()
{    boolean more = qHatInput.hasNext();    if (!more) {        return false;    }    DenseBlockWritable v = qHatInput.next();    mQt = GivensThinSolver.computeQtHat(v.getBlock(), blockNum == 0 ? 0 : 1, new CopyConstructorIterator<>(mRs.iterator()));    r = mQt[0].length;    kp = mQt.length;    if (qRow == null) {        qRow = new DenseVector(kp);    }    return true;}
public boolean mahout_f3869_0()
{    if (mQt != null && cnt == r) {        mQt = null;    }    boolean result = true;    if (mQt == null) {        result = loadNextQt();        cnt = 0;    }    return result;}
public Vector mahout_f3870_0()
{    if (!hasNext()) {        throw new NoSuchElementException();    }    Validate.isTrue(hasNext(), "Q input overrun");    /*     * because Q blocks are initially stored in inverse order     */    int qRowIndex = r - cnt - 1;    for (int j = 0; j < kp; j++) {        qRow.setQuick(j, mQt[j][qRowIndex]);    }    cnt++;    return qRow;}
public void mahout_f3871_0()
{    throw new UnsupportedOperationException();}
public void mahout_f3872_0() throws IOException
{    mQt = null;    mRs.clear();}
private void mahout_f3873_0() throws IOException
{    if (block == null || block.getNumRows() == 0) {        return;    }    blockKeyW.set(currentBlockNum);    delegate.collect(blockKeyW, block);    block.clear();}
public void mahout_f3874_0(Long rowIndex, Vector v) throws IOException
{    long blockKey = rowIndex / height;    if (blockKey != currentBlockNum) {        flushBlock();        if (block == null) {            block = new SparseRowBlockWritable(100);        }        currentBlockNum = blockKey;    }    block.plusRow((int) (rowIndex % height), v);}
public void mahout_f3875_0() throws IOException
{    flushBlock();}
public int[] mahout_f3876_0()
{    return rowIndices;}
public Vector[] mahout_f3877_0()
{    return rows;}
public void mahout_f3878_0(DataInput in) throws IOException
{    numRows = Varint.readUnsignedVarInt(in);    if (rows == null || rows.length < numRows) {        rows = new Vector[numRows];        rowIndices = new int[numRows];    }    VectorWritable vw = new VectorWritable();    for (int i = 0; i < numRows; i++) {        rowIndices[i] = Varint.readUnsignedVarInt(in);        vw.readFields(in);        rows[i] = vw.get().clone();    }}
public void mahout_f3879_0(DataOutput out) throws IOException
{    Varint.writeUnsignedVarInt(numRows, out);    VectorWritable vw = new VectorWritable();    for (int i = 0; i < numRows; i++) {        Varint.writeUnsignedVarInt(rowIndices[i], out);        vw.set(rows[i]);        vw.write(out);    }}
public void mahout_f3880_0(int index, Vector row)
{    /*     * often accumulation goes in row-increasing order, so check for this to     * avoid binary search (another log Height multiplier).     */    int pos = numRows == 0 || rowIndices[numRows - 1] < index ? -numRows - 1 : Arrays.binarySearch(rowIndices, 0, numRows, index);    if (pos >= 0) {        rows[pos].assign(row, PlusMult.plusMult(1));    } else {        insertIntoPos(-pos - 1, index, row);    }}
private void mahout_f3881_0(int pos, int rowIndex, Vector row)
{        if (numRows == rows.length) {        rows = Arrays.copyOf(rows, numRows + 1 << 1);        rowIndices = Arrays.copyOf(rowIndices, numRows + 1 << 1);    }        System.arraycopy(rows, pos, rows, pos + 1, numRows - pos);    System.arraycopy(rowIndices, pos, rowIndices, pos + 1, numRows - pos);        rowIndices[pos] = rowIndex;    rows[pos] = row.clone();    numRows++;}
public void mahout_f3882_0(SparseRowBlockWritable bOther)
{    /*     * since we maintained row indices in a sorted order, we can run sort merge     * to expedite this operation     */    int i = 0;    int j = 0;    while (i < numRows && j < bOther.numRows) {        while (i < numRows && rowIndices[i] < bOther.rowIndices[j]) {            i++;        }        if (i < numRows) {            if (rowIndices[i] == bOther.rowIndices[j]) {                rows[i].assign(bOther.rows[j], PlusMult.plusMult(1));            } else {                                insertIntoPos(i, bOther.rowIndices[j], bOther.rows[j]);            }                        i++;            j++;        }    }    for (; j < bOther.numRows; j++) {        insertIntoPos(numRows, bOther.rowIndices[j], bOther.rows[j]);    }}
public int mahout_f3883_0()
{    return numRows;}
public void mahout_f3884_0()
{    numRows = 0;    Arrays.fill(rows, null);}
public int mahout_f3885_0()
{    return taskId;}
public long mahout_f3886_0()
{    return taskItemOrdinal;}
public void mahout_f3887_0()
{    taskItemOrdinal++;}
public void mahout_f3888_0(long taskItemOrdinal)
{    this.taskItemOrdinal = taskItemOrdinal;}
public void mahout_f3889_0(DataInput in) throws IOException
{    taskId = Varint.readUnsignedVarInt(in);    taskItemOrdinal = Varint.readUnsignedVarLong(in);}
public void mahout_f3890_0(DataOutput out) throws IOException
{    Varint.writeUnsignedVarInt(taskId, out);    Varint.writeUnsignedVarLong(taskItemOrdinal, out);}
public int mahout_f3891_0()
{    int prime = 31;    int result = 1;    result = prime * result + taskId;    return result;}
public boolean mahout_f3892_0(Object obj)
{    if (this == obj) {        return true;    }    if (obj == null) {        return false;    }    if (getClass() != obj.getClass()) {        return false;    }    SplitPartitionedWritable other = (SplitPartitionedWritable) obj;    return taskId == other.taskId;}
public int mahout_f3893_0(SplitPartitionedWritable o)
{    if (taskId < o.taskId) {        return -1;    }    if (taskId > o.taskId) {        return 1;    }    if (taskItemOrdinal < o.taskItemOrdinal) {        return -1;    }    if (taskItemOrdinal > o.taskItemOrdinal) {        return 1;    }    return 0;}
public int mahout_f3894_0(Object a, Object b)
{    SplitPartitionedWritable o1 = (SplitPartitionedWritable) a;    SplitPartitionedWritable o2 = (SplitPartitionedWritable) b;    if (o1.taskId < o2.taskId) {        return -1;    }    if (o1.taskId > o2.taskId) {        return 1;    }    return 0;}
public int mahout_f3895_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption("rank", "k", "decomposition rank", true);    addOption("oversampling", "p", "oversampling", String.valueOf(15));    addOption("blockHeight", "r", "Y block height (must be > (k+p))", String.valueOf(10000));    addOption("outerProdBlockHeight", "oh", "block height of outer products during multiplication, increase for sparse inputs", String.valueOf(30000));    addOption("abtBlockHeight", "abth", "block height of Y_i in ABtJob during AB' multiplication, increase for extremely sparse inputs", String.valueOf(200000));    addOption("minSplitSize", "s", "minimum split size", String.valueOf(-1));    addOption("computeU", "U", "compute U (true/false)", String.valueOf(true));    addOption("uHalfSigma", "uhs", "Compute U * Sigma^0.5", String.valueOf(false));    addOption("uSigma", "us", "Compute U * Sigma", String.valueOf(false));    addOption("computeV", "V", "compute V (true/false)", String.valueOf(true));    addOption("vHalfSigma", "vhs", "compute V * Sigma^0.5", String.valueOf(false));    addOption("reduceTasks", "t", "number of reduce tasks (where applicable)", true);    addOption("powerIter", "q", "number of additional power iterations (0..2 is good)", String.valueOf(0));    addOption("broadcast", "br", "whether use distributed cache to broadcast matrices wherever possible", String.valueOf(true));    addOption("pca", "pca", "run in pca mode: compute column-wise mean and subtract from input", String.valueOf(false));    addOption("pcaOffset", "xi", "path(glob) of external pca mean (optional, dont compute, use external mean");    addOption(DefaultOptionCreator.overwriteOption().create());    Map<String, List<String>> pargs = parseArguments(args);    if (pargs == null) {        return -1;    }    int k = Integer.parseInt(getOption("rank"));    int p = Integer.parseInt(getOption("oversampling"));    int r = Integer.parseInt(getOption("blockHeight"));    int h = Integer.parseInt(getOption("outerProdBlockHeight"));    int abh = Integer.parseInt(getOption("abtBlockHeight"));    int q = Integer.parseInt(getOption("powerIter"));    int minSplitSize = Integer.parseInt(getOption("minSplitSize"));    boolean computeU = Boolean.parseBoolean(getOption("computeU"));    boolean computeV = Boolean.parseBoolean(getOption("computeV"));    boolean cUHalfSigma = Boolean.parseBoolean(getOption("uHalfSigma"));    boolean cUSigma = Boolean.parseBoolean(getOption("uSigma"));    boolean cVHalfSigma = Boolean.parseBoolean(getOption("vHalfSigma"));    int reduceTasks = Integer.parseInt(getOption("reduceTasks"));    boolean broadcast = Boolean.parseBoolean(getOption("broadcast"));    String xiPathStr = getOption("pcaOffset");    Path xiPath = xiPathStr == null ? null : new Path(xiPathStr);    boolean pca = Boolean.parseBoolean(getOption("pca")) || xiPath != null;    boolean overwrite = hasOption(DefaultOptionCreator.OVERWRITE_OPTION);    Configuration conf = getConf();    if (conf == null) {        throw new IOException("No Hadoop configuration present");    }    Path[] inputPaths = { getInputPath() };    Path tempPath = getTempPath();    FileSystem fs = FileSystem.get(getTempPath().toUri(), conf);        if (overwrite) {                HadoopUtil.delete(getConf(), getOutputPath());                HadoopUtil.delete(getConf(), getTempPath());    }    fs.mkdirs(getOutputPath());        if (pca && xiPath == null) {        xiPath = new Path(tempPath, "xi");        if (overwrite) {            fs.delete(xiPath, true);        }        MatrixColumnMeansJob.run(conf, inputPaths[0], xiPath);    }    SSVDSolver solver = new SSVDSolver(conf, inputPaths, new Path(tempPath, "ssvd"), r, k, p, reduceTasks);    solver.setMinSplitSize(minSplitSize);    solver.setComputeU(computeU);    solver.setComputeV(computeV);    solver.setcUHalfSigma(cUHalfSigma);    solver.setcVHalfSigma(cVHalfSigma);    solver.setcUSigma(cUSigma);    solver.setOuterBlockHeight(h);    solver.setAbtBlockHeight(abh);    solver.setQ(q);    solver.setBroadcast(broadcast);    solver.setOverwrite(overwrite);    if (xiPath != null) {        solver.setPcaMeanPath(new Path(xiPath, "part-*"));    }    solver.run();    Vector svalues = solver.getSingularValues().viewPart(0, k);    SSVDHelper.saveVector(svalues, getOutputPath("sigma"), conf);    if (computeU && !fs.rename(new Path(solver.getUPath()), getOutputPath())) {        throw new IOException("Unable to move U results to the output path.");    }    if (cUHalfSigma && !fs.rename(new Path(solver.getuHalfSigmaPath()), getOutputPath())) {        throw new IOException("Unable to move U*Sigma^0.5 results to the output path.");    }    if (cUSigma && !fs.rename(new Path(solver.getuSigmaPath()), getOutputPath())) {        throw new IOException("Unable to move U*Sigma results to the output path.");    }    if (computeV && !fs.rename(new Path(solver.getVPath()), getOutputPath())) {        throw new IOException("Unable to move V results to the output path.");    }    if (cVHalfSigma && !fs.rename(new Path(solver.getvHalfSigmaPath()), getOutputPath())) {        throw new IOException("Unable to move V*Sigma^0.5 results to the output path.");    }        fs.deleteOnExit(getTempPath());    return 0;}
public static void mahout_f3896_0(String[] args) throws Exception
{    ToolRunner.run(new SSVDCli(), args);}
 static Vector mahout_f3897_0(Path glob, Configuration conf) throws IOException
{    SequenceFileDirValueIterator<VectorWritable> iter = new SequenceFileDirValueIterator<>(glob, PathType.GLOB, null, null, true, conf);    try {        if (!iter.hasNext()) {            throw new IOException("Empty input while reading vector");        }        VectorWritable vw = iter.next();        if (iter.hasNext()) {            throw new IOException("Unexpected data after the end of vector file");        }        return vw.get();    } finally {        Closeables.close(iter, true);    }}
public static void mahout_f3898_0(Vector v, Path vectorFilePath, Configuration conf) throws IOException
{    VectorWritable vw = new VectorWritable(v);    FileSystem fs = FileSystem.get(conf);    try (SequenceFile.Writer w = new SequenceFile.Writer(fs, conf, vectorFilePath, IntWritable.class, VectorWritable.class)) {        w.append(new IntWritable(), vw);    }/*       * this is a writer, no quiet close please. we must bail out on incomplete       * close.       */}
 static Class<? extends Writable> mahout_f3899_0(Path[] inputPath, Configuration conf) throws IOException
{    FileSystem fs = FileSystem.get(conf);    for (Path p : inputPath) {        FileStatus[] fstats = fs.globStatus(p);        if (fstats == null || fstats.length == 0) {            continue;        }        FileStatus firstSeqFile;        if (fstats[0].isDir()) {            firstSeqFile = fs.listStatus(fstats[0].getPath(), PathFilters.logsCRCFilter())[0];        } else {            firstSeqFile = fstats[0];        }        SequenceFile.Reader r = null;        try {            r = new SequenceFile.Reader(fs, firstSeqFile.getPath(), conf);            return r.getKeyClass().asSubclass(Writable.class);        } finally {            Closeables.close(r, true);        }    }    throw new IOException("Unable to open input files to determine input label type.");}
public int mahout_f3900_0(FileStatus o1, FileStatus o2)
{    matcher.reset(o1.getPath().getName());    if (!matcher.matches()) {        throw new IllegalArgumentException("Unexpected file name, unable to deduce partition #:" + o1.getPath());    }    int p1 = Integer.parseInt(matcher.group(3));    matcher.reset(o2.getPath().getName());    if (!matcher.matches()) {        throw new IllegalArgumentException("Unexpected file name, unable to deduce partition #:" + o2.getPath());    }    int p2 = Integer.parseInt(matcher.group(3));    return p1 - p2;}
public static Iterator<Pair<Writable, Vector>> mahout_f3901_0(FileSystem fs, Path glob, Configuration conf, Deque<Closeable> closeables) throws IOException
{    SequenceFileDirIterator<Writable, VectorWritable> ret = new SequenceFileDirIterator<>(glob, PathType.GLOB, PathFilters.logsCRCFilter(), PARTITION_COMPARATOR, true, conf);    closeables.addFirst(ret);    return Iterators.transform(ret, new Function<Pair<Writable, VectorWritable>, Pair<Writable, Vector>>() {        @Override        public Pair<Writable, Vector> apply(Pair<Writable, VectorWritable> p) {            return new Pair(p.getFirst(), p.getSecond().get());        }    });}
public Pair<Writable, Vector> mahout_f3902_0(Pair<Writable, VectorWritable> p)
{    return new Pair(p.getFirst(), p.getSecond().get());}
public static DenseMatrix mahout_f3903_0(FileSystem fs, Path glob, Configuration conf) throws IOException
{    Deque<Closeable> closeables = new ArrayDeque<>();    try {        List<double[]> denseData = new ArrayList<>();        for (Iterator<Pair<Writable, Vector>> iter = drmIterator(fs, glob, conf, closeables); iter.hasNext(); ) {            Pair<Writable, Vector> p = iter.next();            Vector v = p.getSecond();            double[] dd = new double[v.size()];            if (v.isDense()) {                for (int i = 0; i < v.size(); i++) {                    dd[i] = v.getQuick(i);                }            } else {                for (Vector.Element el : v.nonZeroes()) {                    dd[el.index()] = el.get();                }            }            denseData.add(dd);        }        if (denseData.size() == 0) {            return null;        } else {            return new DenseMatrix(denseData.toArray(new double[denseData.size()][]));        }    } finally {        IOUtils.close(closeables);    }}
public static DenseSymmetricMatrix mahout_f3904_0(Path glob, Configuration conf) throws IOException
{    Vector v = loadAndSumUpVectors(glob, conf);    return v == null ? null : new DenseSymmetricMatrix(v);}
public static Vector mahout_f3905_0(Path glob, Configuration conf) throws IOException
{    SequenceFileDirValueIterator<VectorWritable> iter = new SequenceFileDirValueIterator<>(glob, PathType.GLOB, null, PARTITION_COMPARATOR, true, conf);    try {        Vector v = null;        while (iter.hasNext()) {            if (v == null) {                v = new DenseVector(iter.next().get());            } else {                v.assign(iter.next().get(), Functions.PLUS);            }        }        return v;    } finally {        Closeables.close(iter, true);    }}
public static UpperTriangular mahout_f3906_0(Path glob, Configuration conf) throws IOException
{    try (SequenceFileDirValueIterator<VectorWritable> iter = new SequenceFileDirValueIterator<>(glob, PathType.GLOB, null, null, true, conf)) {        if (!iter.hasNext()) {            throw new IOException("No triangular matrices found");        }        Vector v = iter.next().get();        UpperTriangular result = new UpperTriangular(v);        if (iter.hasNext()) {            throw new IOException("Unexpected overrun in upper triangular matrix files");        }        return result;    }}
public static double[][] mahout_f3907_0(Matrix m)
{    int rows = m.numRows();    int cols = m.numCols();    double[][] result = new double[rows][];    for (int i = 0; i < rows; i++) {        result[i] = new double[cols];        for (int j = 0; j < cols; j++) {            result[i][j] = m.getQuick(i, j);        }    }    return result;}
public int mahout_f3908_0()
{    return q;}
public void mahout_f3909_0(int q)
{    this.q = q;}
public void mahout_f3910_0(boolean val)
{    computeU = val;}
public void mahout_f3911_0(boolean val)
{    computeV = val;}
public void mahout_f3912_0(boolean cUHat)
{    this.cUHalfSigma = cUHat;}
public void mahout_f3913_0(boolean cVHat)
{    this.cVHalfSigma = cVHat;}
public void mahout_f3914_0(boolean cUSigma)
{    this.cUSigma = cUSigma;}
public void mahout_f3915_0(boolean cVSigma)
{    this.cVSigma = cVSigma;}
public void mahout_f3916_0(int size)
{    minSplitSize = size;}
public Vector mahout_f3917_0()
{    return svalues;}
public String mahout_f3918_0()
{    return uPath;}
public String mahout_f3919_0()
{    return vPath;}
public String mahout_f3920_0()
{    return uSigmaPath;}
public String mahout_f3921_0()
{    return uHalfSigmaPath;}
public String mahout_f3922_0()
{    return vSigmaPath;}
public String mahout_f3923_0()
{    return vHalfSigmaPath;}
public boolean mahout_f3924_0()
{    return overwrite;}
public void mahout_f3925_0(boolean overwrite)
{    this.overwrite = overwrite;}
public int mahout_f3926_0()
{    return outerBlockHeight;}
public void mahout_f3927_0(int outerBlockHeight)
{    this.outerBlockHeight = outerBlockHeight;}
public int mahout_f3928_0()
{    return abtBlockHeight;}
public void mahout_f3929_0(int abtBlockHeight)
{    this.abtBlockHeight = abtBlockHeight;}
public boolean mahout_f3930_0()
{    return broadcast;}
public void mahout_f3931_0(boolean broadcast)
{    this.broadcast = broadcast;}
public Path mahout_f3932_0()
{    return pcaMeanPath;}
public void mahout_f3933_0(Path pcaMeanPath)
{    this.pcaMeanPath = pcaMeanPath;}
 long mahout_f3934_0()
{    return omegaSeed;}
public void mahout_f3935_0() throws IOException
{    Deque<Closeable> closeables = Lists.newLinkedList();    try {        Class<? extends Writable> labelType = SSVDHelper.sniffInputLabelType(inputPath, conf);        FileSystem fs = FileSystem.get(conf);        Path qPath = new Path(outputPath, "Q-job");        Path btPath = new Path(outputPath, "Bt-job");        Path uHatPath = new Path(outputPath, "UHat");        Path svPath = new Path(outputPath, "Sigma");        Path uPath = new Path(outputPath, "U");        Path uSigmaPath = new Path(outputPath, "USigma");        Path uHalfSigmaPath = new Path(outputPath, "UHalfSigma");        Path vPath = new Path(outputPath, "V");        Path vHalfSigmaPath = new Path(outputPath, "VHalfSigma");        Path vSigmaPath = new Path(outputPath, "VSigma");        Path pcaBasePath = new Path(outputPath, "pca");        if (overwrite) {            fs.delete(outputPath, true);        }        if (pcaMeanPath != null) {            fs.mkdirs(pcaBasePath);        }        Random rnd = RandomUtils.getRandom();        omegaSeed = rnd.nextLong();        Path sbPath = null;        double xisquaredlen = 0.0;        if (pcaMeanPath != null) {            /*         * combute s_b0 if pca offset present.         *          * Just in case, we treat xi path as a possible reduce or otherwise         * multiple task output that we assume we need to sum up partial         * components. If it is just one file, it will work too.         */            Vector xi = SSVDHelper.loadAndSumUpVectors(pcaMeanPath, conf);            if (xi == null) {                throw new IOException(String.format("unable to load mean path xi from %s.", pcaMeanPath.toString()));            }            xisquaredlen = xi.dot(xi);            Omega omega = new Omega(omegaSeed, k + p);            Vector s_b0 = omega.mutlithreadedTRightMultiply(xi);            SSVDHelper.saveVector(s_b0, sbPath = new Path(pcaBasePath, "somega.seq"), conf);        }        /*       * if we work with pca offset, we need to precompute s_bq0 aka s_omega for       * jobs to use.       */        QJob.run(conf, inputPath, sbPath, qPath, ablockRows, minSplitSize, k, p, omegaSeed, reduceTasks);        /*       * restrict number of reducers to a reasonable number so we don't have to       * run too many additions in the frontend when reconstructing BBt for the       * last B' and BB' computations. The user may not realize that and gives a       * bit too many (I would be happy i that were ever the case though).       */        BtJob.run(conf, inputPath, qPath, pcaMeanPath, btPath, minSplitSize, k, p, outerBlockHeight, q <= 0 ? Math.min(1000, reduceTasks) : reduceTasks, broadcast, labelType, q <= 0);        sbPath = new Path(btPath, BtJob.OUTPUT_SB + "-*");        Path sqPath = new Path(btPath, BtJob.OUTPUT_SQ + "-*");                for (int i = 0; i < q; i++) {            qPath = new Path(outputPath, String.format("ABt-job-%d", i + 1));            Path btPathGlob = new Path(btPath, BtJob.OUTPUT_BT + "-*");            ABtDenseOutJob.run(conf, inputPath, btPathGlob, pcaMeanPath, sqPath, sbPath, qPath, ablockRows, minSplitSize, k, p, abtBlockHeight, reduceTasks, broadcast);            btPath = new Path(outputPath, String.format("Bt-job-%d", i + 1));            BtJob.run(conf, inputPath, qPath, pcaMeanPath, btPath, minSplitSize, k, p, outerBlockHeight, i == q - 1 ? Math.min(1000, reduceTasks) : reduceTasks, broadcast, labelType, i == q - 1);            sbPath = new Path(btPath, BtJob.OUTPUT_SB + "-*");            sqPath = new Path(btPath, BtJob.OUTPUT_SQ + "-*");        }        DenseSymmetricMatrix bbt = SSVDHelper.loadAndSumUpperTriangularMatricesAsSymmetric(new Path(btPath, BtJob.OUTPUT_BBT + "-*"), conf);                assert bbt.columnSize() == k + p;        /*       * we currently use a 3rd party in-core eigensolver. So we need just a       * dense array representation for it.       */        Matrix bbtSquare = new DenseMatrix(k + p, k + p);        bbtSquare.assign(bbt);                if (pcaMeanPath != null) {            Vector sq = SSVDHelper.loadAndSumUpVectors(sqPath, conf);            Vector sb = SSVDHelper.loadAndSumUpVectors(sbPath, conf);            Matrix mC = sq.cross(sb);            bbtSquare.assign(mC, Functions.MINUS);            bbtSquare.assign(mC.transpose(), Functions.MINUS);            Matrix outerSq = sq.cross(sq);            outerSq.assign(Functions.mult(xisquaredlen));            bbtSquare.assign(outerSq, Functions.PLUS);        }        EigenDecomposition eigen = new EigenDecomposition(bbtSquare);        Matrix uHat = eigen.getV();        svalues = eigen.getRealEigenvalues().clone();        svalues.assign(Functions.SQRT);                fs.mkdirs(uHatPath);        DistributedRowMatrixWriter.write(uHatPath = new Path(uHatPath, "uhat.seq"), conf, uHat);                SSVDHelper.saveVector(svalues, svPath = new Path(svPath, "svalues.seq"), conf);        UJob ujob = null;        if (computeU) {            ujob = new UJob();            ujob.run(conf, new Path(btPath, BtJob.OUTPUT_Q + "-*"), uHatPath, svPath, uPath, k, reduceTasks, labelType, OutputScalingEnum.NOSCALING);                }        UJob uhsjob = null;        if (cUHalfSigma) {            uhsjob = new UJob();            uhsjob.run(conf, new Path(btPath, BtJob.OUTPUT_Q + "-*"), uHatPath, svPath, uHalfSigmaPath, k, reduceTasks, labelType, OutputScalingEnum.HALFSIGMA);        }        UJob usjob = null;        if (cUSigma) {            usjob = new UJob();            usjob.run(conf, new Path(btPath, BtJob.OUTPUT_Q + "-*"), uHatPath, svPath, uSigmaPath, k, reduceTasks, labelType, OutputScalingEnum.SIGMA);        }        VJob vjob = null;        if (computeV) {            vjob = new VJob();            vjob.run(conf, new Path(btPath, BtJob.OUTPUT_BT + "-*"), pcaMeanPath, sqPath, uHatPath, svPath, vPath, k, reduceTasks, OutputScalingEnum.NOSCALING);        }        VJob vhsjob = null;        if (cVHalfSigma) {            vhsjob = new VJob();            vhsjob.run(conf, new Path(btPath, BtJob.OUTPUT_BT + "-*"), pcaMeanPath, sqPath, uHatPath, svPath, vHalfSigmaPath, k, reduceTasks, OutputScalingEnum.HALFSIGMA);        }        VJob vsjob = null;        if (cVSigma) {            vsjob = new VJob();            vsjob.run(conf, new Path(btPath, BtJob.OUTPUT_BT + "-*"), pcaMeanPath, sqPath, uHatPath, svPath, vSigmaPath, k, reduceTasks, OutputScalingEnum.SIGMA);        }        if (ujob != null) {            ujob.waitForCompletion();            this.uPath = uPath.toString();        }        if (uhsjob != null) {            uhsjob.waitForCompletion();            this.uHalfSigmaPath = uHalfSigmaPath.toString();        }        if (usjob != null) {            usjob.waitForCompletion();            this.uSigmaPath = uSigmaPath.toString();        }        if (vjob != null) {            vjob.waitForCompletion();            this.vPath = vPath.toString();        }        if (vhsjob != null) {            vhsjob.waitForCompletion();            this.vHalfSigmaPath = vHalfSigmaPath.toString();        }        if (vsjob != null) {            vsjob.waitForCompletion();            this.vSigmaPath = vSigmaPath.toString();        }    } catch (InterruptedException exc) {        throw new IOException("Interrupted", exc);    } catch (ClassNotFoundException exc) {        throw new IOException(exc);    } finally {        IOUtils.close(closeables);    }}
public void mahout_f3936_0(Configuration conf, Path inputPathQ, Path inputUHatPath, Path sigmaPath, Path outputPath, int k, int numReduceTasks, Class<? extends Writable> labelClass, SSVDSolver.OutputScalingEnum outputScaling) throws ClassNotFoundException, InterruptedException, IOException
{    job = new Job(conf);    job.setJobName("U-job");    job.setJarByClass(UJob.class);    job.setInputFormatClass(SequenceFileInputFormat.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    FileInputFormat.setInputPaths(job, inputPathQ);    FileOutputFormat.setOutputPath(job, outputPath);        job.getConfiguration().set("mapreduce.output.basename", OUTPUT_U);    FileOutputFormat.setCompressOutput(job, true);    FileOutputFormat.setOutputCompressorClass(job, DefaultCodec.class);    SequenceFileOutputFormat.setOutputCompressionType(job, CompressionType.BLOCK);    job.setMapperClass(UMapper.class);    job.setMapOutputKeyClass(IntWritable.class);    job.setMapOutputValueClass(VectorWritable.class);    job.setOutputKeyClass(labelClass);    job.setOutputValueClass(VectorWritable.class);    job.getConfiguration().set(PROP_UHAT_PATH, inputUHatPath.toString());    job.getConfiguration().set(PROP_SIGMA_PATH, sigmaPath.toString());    job.getConfiguration().set(PROP_OUTPUT_SCALING, outputScaling.name());    job.getConfiguration().setInt(PROP_K, k);    job.setNumReduceTasks(0);    job.submit();}
public void mahout_f3937_0() throws IOException, ClassNotFoundException, InterruptedException
{    job.waitForCompletion(false);    if (!job.isSuccessful()) {        throw new IOException("U job unsuccessful.");    }}
protected void mahout_f3938_0(Writable key, VectorWritable value, Context context) throws IOException, InterruptedException
{    Vector qRow = value.get();    if (sValues != null) {        for (int i = 0; i < k; i++) {            uRow.setQuick(i, qRow.dot(uHat.viewColumn(i)) * sValues.getQuick(i));        }    } else {        for (int i = 0; i < k; i++) {            uRow.setQuick(i, qRow.dot(uHat.viewColumn(i)));        }    }    /*       * MAHOUT-1067: inherit A names too.       */    if (qRow instanceof NamedVector) {        uRowWritable.set(new NamedVector(uRow, ((NamedVector) qRow).getName()));    } else {        uRowWritable.set(uRow);    }        context.write(key, uRowWritable);}
protected void mahout_f3939_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    Path uHatPath = new Path(context.getConfiguration().get(PROP_UHAT_PATH));    Path sigmaPath = new Path(context.getConfiguration().get(PROP_SIGMA_PATH));    FileSystem fs = FileSystem.get(uHatPath.toUri(), context.getConfiguration());    uHat = SSVDHelper.drmLoadAsDense(fs, uHatPath, context.getConfiguration());        kp = uHat.columnSize();    k = context.getConfiguration().getInt(PROP_K, kp);    uRow = new DenseVector(k);    uRowWritable = new VectorWritable(uRow);    SSVDSolver.OutputScalingEnum outputScaling = SSVDSolver.OutputScalingEnum.valueOf(context.getConfiguration().get(PROP_OUTPUT_SCALING));    switch(outputScaling) {        case SIGMA:            sValues = SSVDHelper.loadVector(sigmaPath, context.getConfiguration());            break;        case HALFSIGMA:            sValues = SSVDHelper.loadVector(sigmaPath, context.getConfiguration());            sValues.assign(Functions.SQRT);            break;        default:    }}
protected void mahout_f3940_0(IntWritable key, VectorWritable value, Context context) throws IOException, InterruptedException
{    Vector bCol = value.get();    /*       * MAHOUT-817: PCA correction for B': b_{col=i} -= s_q * xi_{i}       */    if (xi != null) {        /*         * code defensively against shortened xi which may be externally         * supplied         */        int btIndex = key.get();        double xii = xi.size() > btIndex ? xi.getQuick(btIndex) : 0.0;        plusMult.setMultiplicator(-xii);        bCol.assign(sq, plusMult);    }    for (int i = 0; i < k; i++) {        vRow.setQuick(i, bCol.dot(uHat.viewColumn(i)) / sValues.getQuick(i));    }    context.write(key, vRowWritable);}
protected void mahout_f3941_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    Configuration conf = context.getConfiguration();    FileSystem fs = FileSystem.get(conf);    Path uHatPath = new Path(conf.get(PROP_UHAT_PATH));    Path sigmaPath = new Path(conf.get(PROP_SIGMA_PATH));    uHat = SSVDHelper.drmLoadAsDense(fs, uHatPath, conf);        kp = uHat.columnSize();    k = context.getConfiguration().getInt(PROP_K, kp);    vRow = new DenseVector(k);    vRowWritable = new VectorWritable(vRow);    sValues = SSVDHelper.loadVector(sigmaPath, conf);    SSVDSolver.OutputScalingEnum outputScaling = SSVDSolver.OutputScalingEnum.valueOf(context.getConfiguration().get(PROP_OUTPUT_SCALING));    switch(outputScaling) {        case SIGMA:            sValues.assign(1.0);            break;        case HALFSIGMA:            sValues = SSVDHelper.loadVector(sigmaPath, context.getConfiguration());            sValues.assign(Functions.SQRT);            break;        default:    }    /*       * PCA -related corrections (MAHOUT-817)       */    String xiPathStr = conf.get(PROP_XI_PATH);    if (xiPathStr != null) {        xi = SSVDHelper.loadAndSumUpVectors(new Path(xiPathStr), conf);        sq = SSVDHelper.loadAndSumUpVectors(new Path(conf.get(PROP_SQ_PATH)), conf);    }}
public void mahout_f3942_0(Configuration conf, Path inputPathBt, Path xiPath, Path sqPath, Path inputUHatPath, Path inputSigmaPath, Path outputPath, int k, int numReduceTasks, SSVDSolver.OutputScalingEnum outputScaling) throws ClassNotFoundException, InterruptedException, IOException
{    job = new Job(conf);    job.setJobName("V-job");    job.setJarByClass(VJob.class);    job.setInputFormatClass(SequenceFileInputFormat.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    FileInputFormat.setInputPaths(job, inputPathBt);    FileOutputFormat.setOutputPath(job, outputPath);        job.getConfiguration().set("mapreduce.output.basename", OUTPUT_V);    FileOutputFormat.setCompressOutput(job, true);    FileOutputFormat.setOutputCompressorClass(job, DefaultCodec.class);    SequenceFileOutputFormat.setOutputCompressionType(job, CompressionType.BLOCK);    job.setMapOutputKeyClass(IntWritable.class);    job.setMapOutputValueClass(VectorWritable.class);    job.setOutputKeyClass(IntWritable.class);    job.setOutputValueClass(VectorWritable.class);    job.setMapperClass(VMapper.class);    job.getConfiguration().set(PROP_UHAT_PATH, inputUHatPath.toString());    job.getConfiguration().set(PROP_SIGMA_PATH, inputSigmaPath.toString());    job.getConfiguration().set(PROP_OUTPUT_SCALING, outputScaling.name());    job.getConfiguration().setInt(PROP_K, k);    job.setNumReduceTasks(0);    /*     * PCA-related options, MAHOUT-817     */    if (xiPath != null) {        job.getConfiguration().set(PROP_XI_PATH, xiPath.toString());        job.getConfiguration().set(PROP_SQ_PATH, sqPath.toString());    }    job.submit();}
public void mahout_f3943_0() throws IOException, ClassNotFoundException, InterruptedException
{    job.waitForCompletion(false);    if (!job.isSuccessful()) {        throw new IOException("V job unsuccessful.");    }}
protected void mahout_f3944_0(Context context) throws IOException, InterruptedException
{    int k = context.getConfiguration().getInt(PROP_K, -1);    int p = context.getConfiguration().getInt(PROP_P, -1);    Validate.isTrue(k > 0, "invalid k parameter");    Validate.isTrue(p > 0, "invalid p parameter");    kp = k + p;    long omegaSeed = Long.parseLong(context.getConfiguration().get(PROP_OMEGA_SEED));    omega = new Omega(omegaSeed, k + p);    mYtY = new UpperTriangular(kp);            yRow = new DenseVector(kp);}
protected void mahout_f3945_0(Writable key, VectorWritable value, Context context) throws IOException, InterruptedException
{    omega.computeYRow(value.get(), yRow);    if (yRow.isDense()) {        for (int i = 0; i < kp; i++) {            double yi;            if ((yi = yRow.getQuick(i)) == 0.0) {                                continue;            }            for (int j = i; j < kp; j++) {                double yj;                if ((yj = yRow.getQuick(j)) != 0.0) {                    mYtY.setQuick(i, j, mYtY.getQuick(i, j) + yi * yj);                }            }        }    } else {        /*         * the disadvantage of using sparse vector (aside from the fact that we         * are creating some short-lived references) here is that we obviously         * do two times more iterations then necessary if y row is pretty dense.         */        for (Vector.Element eli : yRow.nonZeroes()) {            int i = eli.index();            for (Vector.Element elj : yRow.nonZeroes()) {                int j = elj.index();                if (j < i) {                    continue;                }                mYtY.setQuick(i, j, mYtY.getQuick(i, j) + eli.get() * elj.get());            }        }    }}
protected void mahout_f3946_0(Context context) throws IOException, InterruptedException
{    context.write(new IntWritable(context.getTaskAttemptID().getTaskID().getId()), new VectorWritable(new DenseVector(mYtY.getData())));}
protected void mahout_f3947_0(Context context) throws IOException, InterruptedException
{    int k = context.getConfiguration().getInt(PROP_K, -1);    int p = context.getConfiguration().getInt(PROP_P, -1);    Validate.isTrue(k > 0, "invalid k parameter");    Validate.isTrue(p > 0, "invalid p parameter");    accum.set(acc = new DenseVector(k + p));}
protected void mahout_f3948_0(Context context) throws IOException, InterruptedException
{    context.write(new IntWritable(), accum);}
protected void mahout_f3949_0(IntWritable key, Iterable<VectorWritable> values, Context arg2) throws IOException, InterruptedException
{    for (VectorWritable vw : values) {        acc.addAll(vw.get());    }}
public static void mahout_f3950_0(Configuration conf, Path[] inputPaths, Path outputPath, int k, int p, long seed) throws ClassNotFoundException, InterruptedException, IOException
{    Job job = new Job(conf);    job.setJobName("YtY-job");    job.setJarByClass(YtYJob.class);    job.setInputFormatClass(SequenceFileInputFormat.class);    FileInputFormat.setInputPaths(job, inputPaths);    FileOutputFormat.setOutputPath(job, outputPath);    SequenceFileOutputFormat.setOutputCompressionType(job, CompressionType.BLOCK);    job.setMapOutputKeyClass(IntWritable.class);    job.setMapOutputValueClass(VectorWritable.class);    job.setOutputKeyClass(IntWritable.class);    job.setOutputValueClass(VectorWritable.class);    job.setMapperClass(YtYMapper.class);    job.getConfiguration().setLong(PROP_OMEGA_SEED, seed);    job.getConfiguration().setInt(PROP_K, k);    job.getConfiguration().setInt(PROP_P, p);    /*     * we must reduce to just one matrix which means we need only one reducer.     * But it's ok since each mapper outputs only one vector (a packed     * UpperTriangular) so even if there're thousands of mappers, one reducer     * should cope just fine.     */    job.setNumReduceTasks(1);    job.submit();    job.waitForCompletion(false);    if (!job.isSuccessful()) {        throw new IOException("YtY job unsuccessful.");    }}
public static Job mahout_f3951_0(Vector v, Path matrixInputPath, Path outputVectorPath) throws IOException
{    return createTimesSquaredJob(new Configuration(), v, matrixInputPath, outputVectorPath);}
public static Job mahout_f3952_0(Configuration initialConf, Vector v, Path matrixInputPath, Path outputVectorPath) throws IOException
{    return createTimesSquaredJob(initialConf, v, matrixInputPath, outputVectorPath, TimesSquaredMapper.class, VectorSummingReducer.class);}
public static Job mahout_f3953_0(Vector v, int outDim, Path matrixInputPath, Path outputVectorPath) throws IOException
{    return createTimesJob(new Configuration(), v, outDim, matrixInputPath, outputVectorPath);}
public static Job mahout_f3954_0(Configuration initialConf, Vector v, int outDim, Path matrixInputPath, Path outputVectorPath) throws IOException
{    return createTimesSquaredJob(initialConf, v, outDim, matrixInputPath, outputVectorPath, TimesMapper.class, VectorSummingReducer.class);}
public static Job mahout_f3955_0(Vector v, Path matrixInputPath, Path outputVectorPathBase, Class<? extends TimesSquaredMapper> mapClass, Class<? extends VectorSummingReducer> redClass) throws IOException
{    return createTimesSquaredJob(new Configuration(), v, matrixInputPath, outputVectorPathBase, mapClass, redClass);}
public static Job mahout_f3956_0(Configuration initialConf, Vector v, Path matrixInputPath, Path outputVectorPathBase, Class<? extends TimesSquaredMapper> mapClass, Class<? extends VectorSummingReducer> redClass) throws IOException
{    return createTimesSquaredJob(initialConf, v, v.size(), matrixInputPath, outputVectorPathBase, mapClass, redClass);}
public static Job mahout_f3957_0(Vector v, int outputVectorDim, Path matrixInputPath, Path outputVectorPathBase, Class<? extends TimesSquaredMapper> mapClass, Class<? extends VectorSummingReducer> redClass) throws IOException
{    return createTimesSquaredJob(new Configuration(), v, outputVectorDim, matrixInputPath, outputVectorPathBase, mapClass, redClass);}
public static Job mahout_f3958_0(Configuration initialConf, Vector v, int outputVectorDim, Path matrixInputPath, Path outputVectorPathBase, Class<? extends TimesSquaredMapper> mapClass, Class<? extends VectorSummingReducer> redClass) throws IOException
{    FileSystem fs = FileSystem.get(matrixInputPath.toUri(), initialConf);    matrixInputPath = fs.makeQualified(matrixInputPath);    outputVectorPathBase = fs.makeQualified(outputVectorPathBase);    long now = System.nanoTime();    Path inputVectorPath = new Path(outputVectorPathBase, INPUT_VECTOR + '/' + now);    SequenceFile.Writer inputVectorPathWriter = null;    try {        inputVectorPathWriter = new SequenceFile.Writer(fs, initialConf, inputVectorPath, NullWritable.class, VectorWritable.class);        inputVectorPathWriter.append(NullWritable.get(), new VectorWritable(v));    } finally {        Closeables.close(inputVectorPathWriter, false);    }    URI ivpURI = inputVectorPath.toUri();    DistributedCache.setCacheFiles(new URI[] { ivpURI }, initialConf);    Job job = HadoopUtil.prepareJob(matrixInputPath, new Path(outputVectorPathBase, OUTPUT_VECTOR_FILENAME), SequenceFileInputFormat.class, mapClass, NullWritable.class, VectorWritable.class, redClass, NullWritable.class, VectorWritable.class, SequenceFileOutputFormat.class, initialConf);    job.setCombinerClass(redClass);    job.setJobName("TimesSquaredJob: " + matrixInputPath);    Configuration conf = job.getConfiguration();    conf.set(INPUT_VECTOR, ivpURI.toString());    conf.setBoolean(IS_SPARSE_OUTPUT, !v.isDense());    conf.setInt(OUTPUT_VECTOR_DIMENSION, outputVectorDim);    return job;}
public static Vector mahout_f3959_0(Path outputVectorTmpPath, Configuration conf) throws IOException
{    Path outputFile = new Path(outputVectorTmpPath, OUTPUT_VECTOR_FILENAME + "/part-r-00000");    SequenceFileValueIterator<VectorWritable> iterator = new SequenceFileValueIterator<>(outputFile, true, conf);    try {        return iterator.next().get();    } finally {        Closeables.close(iterator, true);    }}
 Vector mahout_f3960_0()
{    return outputVector;}
protected void mahout_f3961_0(Context ctx) throws IOException, InterruptedException
{    try {        Configuration conf = ctx.getConfiguration();        Path[] localFiles = DistributedCache.getLocalCacheFiles(conf);        Preconditions.checkArgument(localFiles != null && localFiles.length >= 1, "missing paths from the DistributedCache");        Path inputVectorPath = HadoopUtil.getSingleCachedFile(conf);        SequenceFileValueIterator<VectorWritable> iterator = new SequenceFileValueIterator<>(inputVectorPath, true, conf);        try {            inputVector = iterator.next().get();        } finally {            Closeables.close(iterator, true);        }        int outDim = conf.getInt(OUTPUT_VECTOR_DIMENSION, Integer.MAX_VALUE);        outputVector = conf.getBoolean(IS_SPARSE_OUTPUT, false) ? new RandomAccessSparseVector(outDim, 10) : new DenseVector(outDim);    } catch (IOException ioe) {        throw new IllegalStateException(ioe);    }}
protected void mahout_f3962_0(T key, VectorWritable v, Context context) throws IOException, InterruptedException
{    double d = scale(v);    if (d == 1.0) {        outputVector.assign(v.get(), Functions.PLUS);    } else if (d != 0.0) {        outputVector.assign(v.get(), Functions.plusMult(d));    }}
protected double mahout_f3963_0(VectorWritable v)
{    return v.get().dot(inputVector);}
protected void mahout_f3964_0(Context ctx) throws IOException, InterruptedException
{    ctx.write(NullWritable.get(), new VectorWritable(outputVector));}
protected void mahout_f3965_0(IntWritable rowNum, VectorWritable v, Context context) throws IOException, InterruptedException
{    double d = scale(v);    if (d != 0.0) {        getOutputVector().setQuick(rowNum.get(), d);    }}
protected void mahout_f3966_0(Context ctx) throws IOException, InterruptedException
{    Configuration conf = ctx.getConfiguration();    int outputDimension = conf.getInt(OUTPUT_VECTOR_DIMENSION, Integer.MAX_VALUE);    outputVector = conf.getBoolean(IS_SPARSE_OUTPUT, false) ? new RandomAccessSparseVector(outputDimension, 10) : new DenseVector(outputDimension);}
protected void mahout_f3967_0(NullWritable key, Iterable<VectorWritable> vectors, Context ctx) throws IOException, InterruptedException
{    for (VectorWritable v : vectors) {        if (v != null) {            outputVector.assign(v.get(), Functions.PLUS);        }    }    ctx.write(NullWritable.get(), new VectorWritable(outputVector));}
public static void mahout_f3968_0(String[] args) throws Exception
{    ToolRunner.run(new TransposeJob(), args);}
public int mahout_f3969_0(String[] strings) throws Exception
{    addInputOption();    addOption("numRows", "nr", "Number of rows of the input matrix");    addOption("numCols", "nc", "Number of columns of the input matrix");    Map<String, List<String>> parsedArgs = parseArguments(strings);    if (parsedArgs == null) {        return -1;    }    int numRows = Integer.parseInt(getOption("numRows"));    int numCols = Integer.parseInt(getOption("numCols"));    DistributedRowMatrix matrix = new DistributedRowMatrix(getInputPath(), getTempPath(), numRows, numCols);    matrix.setConf(new Configuration(getConf()));    matrix.transpose();    return 0;}
public static Job mahout_f3970_0(Path matrixInputPath, Path matrixOutputPath, int numInputRows) throws IOException
{    return buildTransposeJob(new Configuration(), matrixInputPath, matrixOutputPath, numInputRows);}
public static Job mahout_f3971_0(Configuration initialConf, Path matrixInputPath, Path matrixOutputPath, int numInputRows) throws IOException
{    Job job = HadoopUtil.prepareJob(matrixInputPath, matrixOutputPath, SequenceFileInputFormat.class, TransposeMapper.class, IntWritable.class, VectorWritable.class, MergeVectorsReducer.class, IntWritable.class, VectorWritable.class, SequenceFileOutputFormat.class, initialConf);    job.setCombinerClass(MergeVectorsCombiner.class);    job.getConfiguration().setInt(TransposeMapper.NEW_NUM_COLS_PARAM, numInputRows);    job.setJobName("TransposeJob: " + matrixInputPath);    return job;}
public static void mahout_f3972_0(Path outputDir, Configuration conf, VectorIterable matrix) throws IOException
{    FileSystem fs = outputDir.getFileSystem(conf);    fs.delete(outputDir, true);    SequenceFile.Writer writer = SequenceFile.createWriter(fs, conf, outputDir, IntWritable.class, VectorWritable.class);    IntWritable topic = new IntWritable();    VectorWritable vector = new VectorWritable();    for (MatrixSlice slice : matrix) {        topic.set(slice.index());        vector.set(slice.vector());        writer.append(topic, vector);    }    writer.close();}
public static Matrix mahout_f3973_0(Configuration conf, Path... modelPaths) throws IOException
{    int numRows = -1;    int numCols = -1;    boolean sparse = false;    List<Pair<Integer, Vector>> rows = Lists.newArrayList();    for (Path modelPath : modelPaths) {        for (Pair<IntWritable, VectorWritable> row : new SequenceFileIterable<IntWritable, VectorWritable>(modelPath, true, conf)) {            rows.add(Pair.of(row.getFirst().get(), row.getSecond().get()));            numRows = Math.max(numRows, row.getFirst().get());            sparse = !row.getSecond().get().isDense();            if (numCols < 0) {                numCols = row.getSecond().get().size();            }        }    }    if (rows.isEmpty()) {        throw new IOException(Arrays.toString(modelPaths) + " have no vectors in it");    }    numRows++;    Vector[] arrayOfRows = new Vector[numRows];    for (Pair<Integer, Vector> pair : rows) {        arrayOfRows[pair.getFirst()] = pair.getSecond();    }    Matrix matrix;    if (sparse) {        matrix = new SparseRowMatrix(numRows, numCols, arrayOfRows);    } else {        matrix = new DenseMatrix(numRows, numCols);        for (int i = 0; i < numRows; i++) {            matrix.assignRow(i, arrayOfRows[i]);        }    }    return matrix;}
public static OpenObjectIntHashMap<String> mahout_f3974_0(Configuration conf, Path... dictPath)
{    OpenObjectIntHashMap<String> dictionary = new OpenObjectIntHashMap<>();    for (Path dictionaryFile : dictPath) {        for (Pair<Writable, IntWritable> record : new SequenceFileIterable<Writable, IntWritable>(dictionaryFile, true, conf)) {            dictionary.put(record.getFirst().toString(), record.getSecond().get());        }    }    return dictionary;}
public static String[] mahout_f3975_0(OpenObjectIntHashMap<String> termIdMap)
{    int maxTermId = -1;    for (String term : termIdMap.keys()) {        maxTermId = Math.max(maxTermId, termIdMap.get(term));    }    maxTermId++;    String[] dictionary = new String[maxTermId];    for (String term : termIdMap.keys()) {        dictionary[termIdMap.get(term)] = term;    }    return dictionary;}
public Vector mahout_f3976_0()
{    return vectorWritable.get();}
public void mahout_f3977_0(Vector vector)
{    vectorWritable.set(vector);}
public void mahout_f3978_0(int[] labels)
{    this.labels = labels;}
public int[] mahout_f3979_0()
{    return labels;}
public void mahout_f3980_0(DataInput in) throws IOException
{    vectorWritable.readFields(in);    int labelSize = in.readInt();    labels = new int[labelSize];    for (int i = 0; i < labelSize; i++) {        labels[i] = in.readInt();    }}
public void mahout_f3981_0(DataOutput out) throws IOException
{    vectorWritable.write(out);    out.writeInt(labels.length);    for (int label : labels) {        out.writeInt(label);    }}
public static MultiLabelVectorWritable mahout_f3982_0(DataInput in) throws IOException
{    MultiLabelVectorWritable writable = new MultiLabelVectorWritable();    writable.readFields(in);    return writable;}
public static void mahout_f3983_0(DataOutput out, SequentialAccessSparseVector ssv, int[] labels) throws IOException
{    new MultiLabelVectorWritable(ssv, labels).write(out);}
public void mahout_f3984_0(Vector vector)
{    referenceVectors.add(vector);}
public int mahout_f3985_0()
{    return referenceVectors.size();}
public List<WeightedThing<Vector>> mahout_f3986_0(Vector query, int limit)
{    Preconditions.checkArgument(limit > 0, "limit must be greater then 0!");    limit = Math.min(limit, referenceVectors.size());            PriorityQueue<WeightedThing<Integer>> bestNeighbors = new PriorityQueue<>(limit, Ordering.natural().reverse());        List<WeightedThing<Vector>> results = Lists.newArrayListWithCapacity(limit);    int rowNumber = 0;    for (Vector row : referenceVectors) {        double distance = distanceMeasure.distance(query, row);                if (bestNeighbors.size() < limit || bestNeighbors.peek().getWeight() > distance) {            bestNeighbors.add(new WeightedThing<>(rowNumber, distance));            if (bestNeighbors.size() > limit) {                bestNeighbors.poll();            } else {                                                results.add(null);            }        }        ++rowNumber;    }    for (int i = limit - 1; i >= 0; --i) {        WeightedThing<Integer> neighbor = bestNeighbors.poll();        results.set(i, new WeightedThing<>(referenceVectors.get(neighbor.getValue()), neighbor.getWeight()));    }    return results;}
public WeightedThing<Vector> mahout_f3987_0(Vector query, boolean differentThanQuery)
{    double bestDistance = Double.POSITIVE_INFINITY;    Vector bestVector = null;    for (Vector row : referenceVectors) {        double distance = distanceMeasure.distance(query, row);        if (distance < bestDistance && (!differentThanQuery || !row.equals(query))) {            bestDistance = distance;            bestVector = row;        }    }    return new WeightedThing<>(bestVector, bestDistance);}
public List<List<WeightedThing<Vector>>> mahout_f3988_0(Iterable<WeightedVector> queries, final int limit, int numThreads) throws InterruptedException
{    ExecutorService executor = Executors.newFixedThreadPool(numThreads);    List<Callable<Object>> tasks = Lists.newArrayList();    final List<List<WeightedThing<Vector>>> results = Lists.newArrayList();    int i = 0;    for (final Vector query : queries) {        results.add(null);        final int index = i++;        tasks.add(new Callable<Object>() {            @Override            public Object call() throws Exception {                results.set(index, BruteSearch.this.search(query, limit));                return null;            }        });    }    executor.invokeAll(tasks);    executor.shutdown();    return results;}
public Object mahout_f3989_0() throws Exception
{    results.set(index, BruteSearch.this.search(query, limit));    return null;}
public Iterator<Vector> mahout_f3990_0()
{    return referenceVectors.iterator();}
public boolean mahout_f3991_0(Vector query, double epsilon)
{    int rowNumber = 0;    for (Vector row : referenceVectors) {        double distance = distanceMeasure.distance(query, row);        if (distance < epsilon) {            referenceVectors.remove(rowNumber);            return true;        }        rowNumber++;    }    return false;}
public void mahout_f3992_0()
{    referenceVectors.clear();}
private void mahout_f3993_0(int numDimensions)
{    if (initialized) {        return;    }    basisMatrix = RandomProjector.generateBasisNormal(numProjections, numDimensions);    initialized = true;}
public void mahout_f3994_0(Vector vector)
{    initialize(vector.size());    pendingAdditions.add(vector);}
public int mahout_f3995_0()
{    return pendingAdditions.size() + scalarProjections.get(0).size() - numPendingRemovals;}
public List<WeightedThing<Vector>> mahout_f3996_0(Vector query, int limit)
{    reindex(false);    Set<Vector> candidates = Sets.newHashSet();    Vector projection = basisMatrix.times(query);    for (int i = 0; i < basisMatrix.numRows(); ++i) {        List<WeightedThing<Vector>> currProjections = scalarProjections.get(i);        int middle = Collections.binarySearch(currProjections, new WeightedThing<Vector>(projection.get(i)));        if (middle < 0) {            middle = -(middle + 1);        }        for (int j = Math.max(0, middle - searchSize); j < Math.min(currProjections.size(), middle + searchSize + 1); ++j) {            if (currProjections.get(j).getValue() == null) {                continue;            }            candidates.add(currProjections.get(j).getValue());        }    }    List<WeightedThing<Vector>> top = Lists.newArrayListWithCapacity(candidates.size() + pendingAdditions.size());    for (Vector candidate : Iterables.concat(candidates, pendingAdditions)) {        top.add(new WeightedThing<>(candidate, distanceMeasure.distance(candidate, query)));    }    Collections.sort(top);    return top.subList(0, Math.min(top.size(), limit));}
public WeightedThing<Vector> mahout_f3997_0(Vector query, boolean differentThanQuery)
{    reindex(false);    double bestDistance = Double.POSITIVE_INFINITY;    Vector bestVector = null;    Vector projection = basisMatrix.times(query);    for (int i = 0; i < basisMatrix.numRows(); ++i) {        List<WeightedThing<Vector>> currProjections = scalarProjections.get(i);        int middle = Collections.binarySearch(currProjections, new WeightedThing<Vector>(projection.get(i)));        if (middle < 0) {            middle = -(middle + 1);        }        for (int j = Math.max(0, middle - searchSize); j < Math.min(currProjections.size(), middle + searchSize + 1); ++j) {            if (currProjections.get(j).getValue() == null) {                continue;            }            Vector vector = currProjections.get(j).getValue();            double distance = distanceMeasure.distance(vector, query);            if (distance < bestDistance && (!differentThanQuery || !vector.equals(query))) {                bestDistance = distance;                bestVector = vector;            }        }    }    for (Vector vector : pendingAdditions) {        double distance = distanceMeasure.distance(vector, query);        if (distance < bestDistance && (!differentThanQuery || !vector.equals(query))) {            bestDistance = distance;            bestVector = vector;        }    }    return new WeightedThing<>(bestVector, bestDistance);}
public boolean mahout_f3998_0(Vector vector, double epsilon)
{    WeightedThing<Vector> closestPair = searchFirst(vector, false);    if (distanceMeasure.distance(closestPair.getValue(), vector) > epsilon) {        return false;    }    boolean isProjected = true;    Vector projection = basisMatrix.times(vector);    for (int i = 0; i < basisMatrix.numRows(); ++i) {        List<WeightedThing<Vector>> currProjections = scalarProjections.get(i);        WeightedThing<Vector> searchedThing = new WeightedThing<>(projection.get(i));        int middle = Collections.binarySearch(currProjections, searchedThing);        if (middle < 0) {            isProjected = false;            break;        }                        scalarProjections.get(i).set(middle, searchedThing);    }    if (isProjected) {        ++numPendingRemovals;        return true;    }    for (int i = 0; i < pendingAdditions.size(); ++i) {        if (pendingAdditions.get(i).equals(vector)) {            pendingAdditions.remove(i);            break;        }    }    return true;}
private void mahout_f3999_0(boolean force)
{    int numProjected = scalarProjections.get(0).size();    if (force || pendingAdditions.size() > ADDITION_THRESHOLD * numProjected || numPendingRemovals > REMOVAL_THRESHOLD * numProjected) {                                List<List<WeightedThing<Vector>>> scalarProjections = Lists.newArrayListWithCapacity(numProjections);        for (int i = 0; i < numProjections; ++i) {            if (i == 0) {                scalarProjections.add(Lists.newArrayList(this.scalarProjections.get(i)));            } else {                scalarProjections.add(this.scalarProjections.get(i));            }        }                for (Vector pending : pendingAdditions) {            Vector projection = basisMatrix.times(pending);            for (int i = 0; i < numProjections; ++i) {                scalarProjections.get(i).add(new WeightedThing<>(pending, projection.get(i)));            }        }        pendingAdditions.clear();                for (int i = 0; i < numProjections; ++i) {            List<WeightedThing<Vector>> currProjections = scalarProjections.get(i);            for (WeightedThing<Vector> v : currProjections) {                if (v.getValue() == null) {                    v.setWeight(Double.POSITIVE_INFINITY);                }            }            Collections.sort(currProjections);            for (int j = 0; j < numPendingRemovals; ++j) {                currProjections.remove(currProjections.size() - 1);            }        }        numPendingRemovals = 0;        this.scalarProjections = scalarProjections;    }}
public void mahout_f4000_0()
{    pendingAdditions.clear();    for (int i = 0; i < numProjections; ++i) {        scalarProjections.get(i).clear();    }    numPendingRemovals = 0;}
public Iterator<Vector> mahout_f4001_0()
{    reindex(true);    return new AbstractIterator<Vector>() {        private final Iterator<WeightedThing<Vector>> data = scalarProjections.get(0).iterator();        @Override        protected Vector computeNext() {            do {                if (!data.hasNext()) {                    return endOfData();                }                WeightedThing<Vector> next = data.next();                if (next.getValue() != null) {                    return next.getValue();                }            } while (true);        }    };}
protected Vector mahout_f4002_0()
{    do {        if (!data.hasNext()) {            return endOfData();        }        WeightedThing<Vector> next = data.next();        if (next.getValue() != null) {            return next.getValue();        }    } while (true);}
public static long mahout_f4003_0(Vector vector, Matrix projection)
{    long hash = 0;    for (Element element : projection.times(vector).nonZeroes()) {        if (element.get() > 0) {            hash += 1L << element.index();        }    }    return hash;}
public static HashedVector mahout_f4004_0(WeightedVector v, Matrix projection)
{    return hash(v, projection, 0);}
public static HashedVector mahout_f4005_0(WeightedVector v, Matrix projection, long mask)
{    return new HashedVector(v, projection, mask);}
public int mahout_f4006_0(long otherHash)
{    return Long.bitCount(hash ^ otherHash);}
public long mahout_f4007_0()
{    return hash;}
public String mahout_f4008_0()
{    return String.format("index=%d, hash=%08x, v=%s", getIndex(), hash, getVector());}
public boolean mahout_f4009_0(Object o)
{    if (this == o) {        return true;    }    if (!(o instanceof HashedVector)) {        return o instanceof Vector && this.minus((Vector) o).norm(1) == 0;    }    HashedVector v = (HashedVector) o;    return v.hash == this.hash && this.minus(v).norm(1) == 0;}
public int mahout_f4010_0()
{    int result = super.hashCode();    result = 31 * result + (int) (hash ^ (hash >>> 32));    return result;}
private void mahout_f4011_0(int numDimensions)
{    if (initialized) {        return;    }    initialized = true;    projection = RandomProjector.generateBasisNormal(BITS, numDimensions);}
private PriorityQueue<WeightedThing<Vector>> mahout_f4012_0(Vector query)
{    long queryHash = HashedVector.computeHash64(query, projection);        PriorityQueue<WeightedThing<Vector>> top = Searcher.getCandidateQueue(getSearchSize());                OnlineSummarizer[] distribution = new OnlineSummarizer[BITS + 1];    for (int i = 0; i < BITS + 1; i++) {        distribution[i] = new OnlineSummarizer();    }    distanceEvaluations = 0;            int[] hashCounts = new int[BITS + 1];            int hashLimit = BITS;    int limitCount = 0;    double distanceLimit = Double.POSITIVE_INFINITY;        for (HashedVector vector : trainingVectors) {                        int bitDot = vector.hammingDistance(queryHash);        if (bitDot <= hashLimit) {            distanceEvaluations++;            double distance = distanceMeasure.distance(query, vector);            distribution[bitDot].add(distance);            if (distance < distanceLimit) {                top.insertWithOverflow(new WeightedThing<Vector>(vector, distance));                if (top.size() == searchSize) {                    distanceLimit = top.top().getWeight();                }                hashCounts[bitDot]++;                limitCount++;                while (hashLimit > 0 && limitCount - hashCounts[hashLimit - 1] > searchSize) {                    hashLimit--;                    limitCount -= hashCounts[hashLimit];                }                if (hashLimitStrategy >= 0) {                    while (hashLimit < MAX_HASH_LIMIT && distribution[hashLimit].getCount() > MIN_DISTRIBUTION_COUNT && ((1 - hashLimitStrategy) * distribution[hashLimit].getQuartile(0) + hashLimitStrategy * distribution[hashLimit].getQuartile(1)) < distanceLimit) {                        limitCount += hashCounts[hashLimit];                        hashLimit++;                    }                }            }        }    }    return top;}
public List<WeightedThing<Vector>> mahout_f4013_0(Vector query, int limit)
{    PriorityQueue<WeightedThing<Vector>> top = searchInternal(query);    List<WeightedThing<Vector>> results = Lists.newArrayListWithExpectedSize(top.size());    while (top.size() != 0) {        WeightedThing<Vector> wv = top.pop();        results.add(new WeightedThing<>(((HashedVector) wv.getValue()).getVector(), wv.getWeight()));    }    Collections.reverse(results);    if (limit < results.size()) {        results = results.subList(0, limit);    }    return results;}
public WeightedThing<Vector> mahout_f4014_0(Vector query, boolean differentThanQuery)
{        PriorityQueue<WeightedThing<Vector>> top = searchInternal(query);        while (top.size() > 2) {        top.pop();    }        if (top.size() < 2) {        return removeHash(top.pop());    }        WeightedThing<Vector> secondBest = top.pop();    WeightedThing<Vector> best = top.pop();        if (differentThanQuery && best.getValue().equals(query)) {        best = secondBest;    }    return removeHash(best);}
protected static WeightedThing<Vector> mahout_f4015_0(WeightedThing<Vector> input)
{    return new WeightedThing<>(((HashedVector) input.getValue()).getVector(), input.getWeight());}
public void mahout_f4016_0(Vector vector)
{    initialize(vector.size());    trainingVectors.add(new HashedVector(vector, projection, HashedVector.INVALID_INDEX, BIT_MASK));}
public int mahout_f4017_0()
{    return trainingVectors.size();}
public int mahout_f4018_0()
{    return searchSize;}
public void mahout_f4019_0(int size)
{    searchSize = size;}
public void mahout_f4020_0(double strategy)
{    hashLimitStrategy = strategy;}
public int mahout_f4021_0()
{    int result = distanceEvaluations;    distanceEvaluations = 0;    return result;}
public Iterator<Vector> mahout_f4022_0()
{    return Iterators.transform(trainingVectors.iterator(), new Function<HashedVector, Vector>() {        @Override        public Vector apply(org.apache.mahout.math.neighborhood.HashedVector input) {            Preconditions.checkNotNull(input);                        return input.getVector();        }    });}
public Vector mahout_f4023_0(org.apache.mahout.math.neighborhood.HashedVector input)
{    Preconditions.checkNotNull(input);        return input.getVector();}
public boolean mahout_f4024_0(Vector v, double epsilon)
{    return trainingVectors.remove(new HashedVector(v, projection, HashedVector.INVALID_INDEX, BIT_MASK));}
public void mahout_f4025_0()
{    trainingVectors.clear();}
private void mahout_f4026_0(int numDimensions)
{    if (initialized) {        return;    }    initialized = true;    basisMatrix = RandomProjector.generateBasisNormal(numProjections, numDimensions);    scalarProjections = Lists.newArrayList();    for (int i = 0; i < numProjections; ++i) {        scalarProjections.add(TreeMultiset.<WeightedThing<Vector>>create());    }}
public void mahout_f4027_0(Vector vector)
{    initialize(vector.size());    Vector projection = basisMatrix.times(vector);        int i = 0;    for (TreeMultiset<WeightedThing<Vector>> s : scalarProjections) {        s.add(new WeightedThing<>(vector, projection.get(i++)));    }    int numVectors = scalarProjections.get(0).size();    for (TreeMultiset<WeightedThing<Vector>> s : scalarProjections) {        Preconditions.checkArgument(s.size() == numVectors, "Number of vectors in projection sets " + "differ");        double firstWeight = s.firstEntry().getElement().getWeight();        for (WeightedThing<Vector> w : s) {            Preconditions.checkArgument(firstWeight <= w.getWeight(), "Weights not in non-decreasing " + "order");            firstWeight = w.getWeight();        }    }}
public int mahout_f4028_0()
{    if (scalarProjections == null) {        return 0;    }    return scalarProjections.get(0).size();}
public List<WeightedThing<Vector>> mahout_f4029_0(Vector query, int limit)
{    Set<Vector> candidates = Sets.newHashSet();    Iterator<? extends Vector> projections = basisMatrix.iterator();    for (TreeMultiset<WeightedThing<Vector>> v : scalarProjections) {        Vector basisVector = projections.next();        WeightedThing<Vector> projectedQuery = new WeightedThing<>(query, query.dot(basisVector));        for (WeightedThing<Vector> candidate : Iterables.concat(Iterables.limit(v.tailMultiset(projectedQuery, BoundType.CLOSED), searchSize), Iterables.limit(v.headMultiset(projectedQuery, BoundType.OPEN).descendingMultiset(), searchSize))) {            candidates.add(candidate.getValue());        }    }            List<WeightedThing<Vector>> top = Lists.newArrayList();    for (Vector candidate : candidates) {        top.add(new WeightedThing<>(candidate, distanceMeasure.distance(query, candidate)));    }    Collections.sort(top);    return top.subList(0, Math.min(limit, top.size()));}
public WeightedThing<Vector> mahout_f4030_0(Vector query, boolean differentThanQuery)
{    double bestDistance = Double.POSITIVE_INFINITY;    Vector bestVector = null;    Iterator<? extends Vector> projections = basisMatrix.iterator();    for (TreeMultiset<WeightedThing<Vector>> v : scalarProjections) {        Vector basisVector = projections.next();        WeightedThing<Vector> projectedQuery = new WeightedThing<>(query, query.dot(basisVector));        for (WeightedThing<Vector> candidate : Iterables.concat(Iterables.limit(v.tailMultiset(projectedQuery, BoundType.CLOSED), searchSize), Iterables.limit(v.headMultiset(projectedQuery, BoundType.OPEN).descendingMultiset(), searchSize))) {            double distance = distanceMeasure.distance(query, candidate.getValue());            if (distance < bestDistance && (!differentThanQuery || !candidate.getValue().equals(query))) {                bestDistance = distance;                bestVector = candidate.getValue();            }        }    }    return new WeightedThing<>(bestVector, bestDistance);}
public Iterator<Vector> mahout_f4031_0()
{    return new AbstractIterator<Vector>() {        private final Iterator<WeightedThing<Vector>> projected = scalarProjections.get(0).iterator();        @Override        protected Vector computeNext() {            if (!projected.hasNext()) {                return endOfData();            }            return projected.next().getValue();        }    };}
protected Vector mahout_f4032_0()
{    if (!projected.hasNext()) {        return endOfData();    }    return projected.next().getValue();}
public boolean mahout_f4033_0(Vector vector, double epsilon)
{    WeightedThing<Vector> toRemove = searchFirst(vector, false);    if (toRemove.getWeight() < epsilon) {        Iterator<? extends Vector> basisVectors = basisMatrix.iterator();        for (TreeMultiset<WeightedThing<Vector>> projection : scalarProjections) {            if (!projection.remove(new WeightedThing<>(vector, vector.dot(basisVectors.next())))) {                throw new RuntimeException("Internal inconsistency in ProjectionSearch");            }        }        return true;    } else {        return false;    }}
public void mahout_f4034_0()
{    if (scalarProjections == null) {        return;    }    for (TreeMultiset<WeightedThing<Vector>> set : scalarProjections) {        set.clear();    }}
public DistanceMeasure mahout_f4035_0()
{    return distanceMeasure;}
public List<List<WeightedThing<Vector>>> mahout_f4036_0(Iterable<? extends Vector> queries, int limit)
{    List<List<WeightedThing<Vector>>> results = Lists.newArrayListWithExpectedSize(Iterables.size(queries));    for (Vector query : queries) {        results.add(search(query, limit));    }    return results;}
public List<WeightedThing<Vector>> mahout_f4037_0(Iterable<? extends Vector> queries, boolean differentThanQuery)
{    List<WeightedThing<Vector>> results = Lists.newArrayListWithExpectedSize(Iterables.size(queries));    for (Vector query : queries) {        results.add(searchFirst(query, differentThanQuery));    }    return results;}
public void mahout_f4038_0(Iterable<? extends Vector> data)
{    for (Vector vector : data) {        add(vector);    }}
public void mahout_f4039_0(Iterable<MatrixSlice> data)
{    for (MatrixSlice slice : data) {        add(slice.vector());    }}
public void mahout_f4040_0(Iterable<MatrixSlice> data)
{    for (MatrixSlice slice : data) {        add(new WeightedVector(slice.vector(), 1, slice.index()));    }}
public boolean mahout_f4041_0(Vector v, double epsilon)
{    throw new UnsupportedOperationException("Can't remove a vector from a " + this.getClass().getName());}
public void mahout_f4042_0()
{    throw new UnsupportedOperationException("Can't remove vectors from a " + this.getClass().getName());}
public static PriorityQueue<WeightedThing<Vector>> mahout_f4043_0(int limit)
{    return new PriorityQueue<WeightedThing<Vector>>(limit) {        @Override        protected boolean lessThan(WeightedThing<Vector> a, WeightedThing<Vector> b) {            return a.getWeight() > b.getWeight();        }    };}
protected boolean mahout_f4044_0(WeightedThing<Vector> a, WeightedThing<Vector> b)
{    return a.getWeight() > b.getWeight();}
public double mahout_f4045_0(double ignored)
{    return sample();}
public Integer mahout_f4046_0()
{    double u = rand.nextDouble() * (alpha + weight);    for (int j = 0; j < weights.size(); j++) {                if (u < weights.get(j) - discount) {            weights.set(j, weights.get(j) + 1);            weight++;            return j;        } else {            u -= weights.get(j) - discount;        }    }            weights.add(1);    weight++;    return weights.size() - 1;}
public int mahout_f4047_0()
{    return weights.size();}
public int mahout_f4048_0()
{    return (int) weight;}
public int mahout_f4049_0(int j)
{    Preconditions.checkArgument(j >= 0);    if (j < weights.size()) {        return (int) weights.get(j);    } else {        return 0;    }}
public Double mahout_f4050_0()
{    return sample(gen.nextDouble());}
public double mahout_f4051_0(double u)
{    if (exceedMinimum && u < x[0]) {                if (u == 0) {            u = 1.0e-16;        }        return y[0] + Math.log(u / x[0]) * x[0] * (y[1] - y[0]) / (x[1] - x[0]);    } else if (exceedMaximum && u > x[n - 1]) {        if (u == 1) {            u = 1 - 1.0e-16;        }                double dy = y[n - 1] - y[n - 2];        double dx = x[n - 1] - x[n - 2];        return y[n - 1] - Math.log((1 - u) / (1 - x[n - 1])) * (1 - x[n - 1]) * dy / dx;    } else {                for (int i = 1; i < n; i++) {            if (x[i] > u) {                double dy = y[i] - y[i - 1];                double dx = x[i] - x[i - 1];                return y[i - 1] + (u - x[i - 1]) * dy / dx;            }        }        throw new RuntimeException(String.format("Can't happen (%.3f is not in [%.3f,%.3f]", u, x[0], x[n - 1]));    }}
public static IndianBuffet<Integer> mahout_f4052_0(double alpha)
{    return new IndianBuffet<>(alpha, new IdentityConverter());}
public static IndianBuffet<String> mahout_f4053_0(double alpha)
{    return new IndianBuffet<>(alpha, new WordConverter());}
public List<T> mahout_f4054_0()
{    List<T> r = Lists.newArrayList();    if (documents == 0) {        double n = new PoissonSampler(alpha).sample();        for (int i = 0; i < n; i++) {            r.add(converter.convert(i));            count.add(1);        }        documents++;    } else {        documents++;        int i = 0;        for (double cnt : count) {            if (gen.nextDouble() < cnt / documents) {                r.add(converter.convert(i));                count.set(i, count.get(i) + 1);            }            i++;        }        int newItems = new PoissonSampler(alpha / documents).sample().intValue();        for (int j = 0; j < newItems; j++) {            r.add(converter.convert(i + j));            count.add(1);        }    }    return r;}
public Integer mahout_f4055_0(int i)
{    return i;}
public String mahout_f4056_0(int i)
{    return String.valueOf(i);}
public boolean mahout_f4057_0(String line)
{    Iterables.addAll(theWords, onSpace.split(line));    return true;}
public List<String> mahout_f4058_0()
{    return theWords;}
public String mahout_f4059_0(int i)
{    if (i < words.size()) {        return words.get(i);    } else {        return "w_" + i;    }}
public T mahout_f4060_0()
{    if (gen.nextDouble() >= p) {        return delegate.sample();    } else {        return missingMarker;    }}
public void mahout_f4061_0(T value, double w)
{    Preconditions.checkNotNull(value);    Preconditions.checkArgument(!items.containsKey(value));    int n = this.weight.size();    if (n == 1) {        weight.add(w);        values.add(value);        items.put(value, 1);    } else {                weight.add(weight.get(n / 2));        values.add(values.get(n / 2));        items.put(values.get(n / 2), n);        n++;                items.put(value, n);        this.weight.add(w);        values.add(value);                while (n > 1) {            n /= 2;            this.weight.set(n, this.weight.get(n) + w);        }    }}
public double mahout_f4062_0(T value)
{    if (items.containsKey(value)) {        return weight.get(items.get(value));    } else {        return 0;    }}
public double mahout_f4063_0(T value)
{    if (items.containsKey(value)) {        return weight.get(items.get(value)) / weight.get(1);    } else {        return 0;    }}
public double mahout_f4064_0()
{    if (weight.size() > 1) {        return weight.get(1);    } else {        return 0;    }}
public void mahout_f4065_0(T value)
{    set(value, 0);}
public void mahout_f4066_0(T value, double newP)
{    Preconditions.checkArgument(items.containsKey(value));    int n = items.get(value);    if (newP <= 0) {                        items.remove(value);    }    double oldP = weight.get(n);    while (n > 0) {        weight.set(n, weight.get(n) - oldP + newP);        n /= 2;    }}
public T mahout_f4067_0()
{    Preconditions.checkArgument(!weight.isEmpty());    return sample(rand.nextDouble());}
public T mahout_f4068_0(double u)
{    u *= weight.get(1);    int n = 1;    while (2 * n < weight.size()) {                double left = weight.get(2 * n);        if (u <= left) {            n = 2 * n;        } else {            u -= left;            n = 2 * n + 1;        }    }    return values.get(n);}
 List<Double> mahout_f4069_0()
{    List<Double> r = Lists.newArrayList();    int i = Integer.highestOneBit(weight.size());    while (i < weight.size()) {        r.add(weight.get(i));        i++;    }    i /= 2;    while (i < Integer.highestOneBit(weight.size())) {        r.add(weight.get(i));        i++;    }    return r;}
public Iterator<T> mahout_f4070_0()
{    return new AbstractIterator<T>() {        Iterator<T> valuesIterator = Iterables.skip(values, 1).iterator();        @Override        protected T computeNext() {            while (valuesIterator.hasNext()) {                T next = valuesIterator.next();                if (items.containsKey(next)) {                    return next;                }            }            return endOfData();        }    };}
protected T mahout_f4071_0()
{    while (valuesIterator.hasNext()) {        T next = valuesIterator.next();        if (items.containsKey(next)) {            return next;        }    }    return endOfData();}
public Vector mahout_f4072_0()
{    Vector v = new DenseVector(dimension).assign(new DoubleFunction() {        @Override        public double apply(double ignored) {            return gen.nextGaussian();        }    });    if (mean != null) {        if (scale != null) {            return scale.times(v).plus(mean);        } else {            return v.plus(mean);        }    } else {        if (scale != null) {            return scale.times(v);        } else {            return v;        }    }}
public double mahout_f4073_0(double ignored)
{    return gen.nextGaussian();}
public Vector mahout_f4074_0()
{    return mean;}
public Double mahout_f4075_0()
{    return rand.nextGaussian() * sd + mean;}
public Double mahout_f4076_0()
{    return sample(gen.nextDouble());}
 double mahout_f4077_0(double u)
{    if (u < limit) {        List<WeightedThing<Integer>> steps = Lists.newArrayList();        limit = 1;        int i = 0;        while (u / 20 < limit) {            double pdf = pd.probability(i);            limit -= pdf;            steps.add(new WeightedThing<>(i, pdf));            i++;        }        steps.add(new WeightedThing<>(steps.size(), limit));        partial = new Multinomial<>(steps);    }    return partial.sample(u);}
public static Matrix mahout_f4078_0(int projectedVectorSize, int vectorSize)
{    Matrix basisMatrix = new DenseMatrix(projectedVectorSize, vectorSize);    basisMatrix.assign(new Normal());    for (MatrixSlice row : basisMatrix) {        row.vector().assign(row.normalize());    }    return basisMatrix;}
public static Matrix mahout_f4079_0(int projectedVectorSize, int vectorSize)
{    Matrix basisMatrix = new DenseMatrix(projectedVectorSize, vectorSize);    for (int i = 0; i < projectedVectorSize; ++i) {        for (int j = 0; j < vectorSize; ++j) {            basisMatrix.set(i, j, RandomUtils.nextInt(2) == 0 ? 1 : -1);        }    }    for (MatrixSlice row : basisMatrix) {        row.vector().assign(row.normalize());    }    return basisMatrix;}
public static Matrix mahout_f4080_0(int projectedVectorSize, int vectorSize)
{    Matrix basisMatrix = new DenseMatrix(projectedVectorSize, vectorSize);    Multinomial<Double> choice = new Multinomial<>();    choice.add(0.0, 2 / 3.0);    choice.add(Math.sqrt(3.0), 1 / 6.0);    choice.add(-Math.sqrt(3.0), 1 / 6.0);    for (int i = 0; i < projectedVectorSize; ++i) {        for (int j = 0; j < vectorSize; ++j) {            basisMatrix.set(i, j, choice.sample());        }    }    for (MatrixSlice row : basisMatrix) {        row.vector().assign(row.normalize());    }    return basisMatrix;}
public static List<Vector> mahout_f4081_0(int projectedVectorSize, int vectorSize)
{    DoubleFunction random = new Normal();    List<Vector> basisVectors = Lists.newArrayList();    for (int i = 0; i < projectedVectorSize; ++i) {        Vector basisVector = new DenseVector(vectorSize);        basisVector.assign(random);        basisVector.normalize();        basisVectors.add(basisVector);    }    return basisVectors;}
public T mahout_f4082_0()
{    return value;}
public double mahout_f4083_0()
{    return weight;}
public void mahout_f4084_0(double weight)
{    this.weight = weight;}
public int mahout_f4085_0(WeightedThing<T> other)
{    return Double.compare(this.weight, other.weight);}
public boolean mahout_f4086_0(Object o)
{    if (o instanceof WeightedThing) {        @SuppressWarnings("unchecked")        WeightedThing<T> other = (WeightedThing<T>) o;        return weight == other.weight && value.equals(other.value);    }    return false;}
public int mahout_f4087_0()
{    return 31 * RandomUtils.hashDouble(weight) + value.hashCode();}
public Vector mahout_f4088_0()
{    return new DenseVector(svd.getSingularValues());}
public Matrix mahout_f4089_0()
{        return cd1.solveRight(y).times(svd.getU());}
public Matrix mahout_f4090_0()
{        return cd2.solveRight(b.transpose()).times(svd.getV());}
public void mahout_f4091_0(File tmpDir, int ncols) throws IOException
{        for (int j = 0; j < ncols; j += columnsPerSlice) {        File bPath = bFile(tmpDir, j);        if (bPath.exists()) {            MatrixWritable m = new MatrixWritable();            try (DataInputStream in = new DataInputStream(new FileInputStream(bPath))) {                m.readFields(in);            }            m.set(l2.solveRight(m.get().transpose()).times(svd.getV()));            try (DataOutputStream out = new DataOutputStream(new FileOutputStream(new File(tmpDir, String.format("V-%s", bPath.getName().replaceAll(".*-", "")))))) {                m.write(out);            }        }    }}
public void mahout_f4092_0(Iterable<File> partsOfA, File tmpDir) throws IOException
{        for (File file : partsOfA) {        MatrixWritable m = new MatrixWritable();        m.readFields(new DataInputStream(new FileInputStream(file)));        Matrix aI = m.get();        Matrix y = aI.times(new RandomTrinaryMatrix(seed, aI.numCols(), dim, false));        Matrix uI = r2.solveRight(y).times(svd.getU());        m.set(uI);        try (DataOutputStream out = new DataOutputStream(new FileOutputStream(new File(tmpDir, String.format("U-%s", file.getName().replaceAll(".*-", "")))))) {            m.write(out);        }    }}
private static void mahout_f4093_0(File file, Matrix matrix) throws IOException
{    MatrixWritable mw = new MatrixWritable();    if (file.exists()) {        try (DataInputStream in = new DataInputStream(new FileInputStream(file))) {            mw.readFields(in);        }        mw.get().assign(matrix, Functions.PLUS);    } else {        mw.set(matrix);    }    try (DataOutputStream out = new DataOutputStream(new FileOutputStream(file))) {        mw.write(out);    }}
private static File mahout_f4094_0(File tmpDir, int j)
{    return new File(tmpDir, String.format("B-%09d", j));}
public Vector mahout_f4095_0()
{    return new DenseVector(svd.getSingularValues());}
public double mahout_f4096_0(int category, String groupKey, double score)
{    return addSample(category, score);}
public double mahout_f4097_0(int category, double score)
{    int n = (int) samples.get(category);    if (n < HISTORY) {        scores.set(category, n, score);    } else {        switch(policy) {            case FIFO:                scores.set(category, n % HISTORY, score);                break;            case FAIR:                int j1 = random.nextInt(n + 1);                if (j1 < HISTORY) {                    scores.set(category, j1, score);                }                break;            case RANDOM:                int j2 = random.nextInt(HISTORY);                scores.set(category, j2, score);                break;            default:                throw new IllegalStateException("Unknown policy: " + policy);        }    }    samples.set(category, n + 1);    if (samples.minValue() >= 1) {                Vector row = scores.viewRow(1 - category);        double m = 0.0;        double count = 0.0;        for (Vector.Element element : row.all()) {            double v = element.get();            if (Double.isNaN(v)) {                continue;            }            count++;            if (score > v) {                m++;                                    } else if (score == v) {                m += 0.5;            }        }        averages.set(category, averages.get(category) + (m / count - averages.get(category)) / Math.min(windowSize, samples.get(category)));    }    return auc();}
public double mahout_f4098_0()
{        return (1 - averages.get(0) + averages.get(1)) / 2;}
public double mahout_f4099_0()
{    return auc();}
public void mahout_f4100_0(ReplacementPolicy policy)
{    this.policy = policy;}
public void mahout_f4101_0(int windowSize)
{    this.windowSize = windowSize;}
public void mahout_f4102_0(DataOutput out) throws IOException
{    out.writeInt(windowSize);    out.writeInt(policy.ordinal());    MatrixWritable.writeMatrix(out, scores);    VectorWritable.writeVector(out, averages);    VectorWritable.writeVector(out, samples);}
public void mahout_f4103_0(DataInput in) throws IOException
{    windowSize = in.readInt();    policy = ReplacementPolicy.values()[in.readInt()];    scores = MatrixWritable.readMatrix(in);    averages = VectorWritable.readVector(in);    samples = VectorWritable.readVector(in);}
public double mahout_f4104_0(int category, String groupKey, double score)
{    if (groupKey == null) {        addSample(category, score);    }    OnlineAuc group = map.get(groupKey);    if (group == null) {        group = new GlobalOnlineAuc();        if (policy != null) {            group.setPolicy(policy);        }        if (windowSize > 0) {            group.setWindowSize(windowSize);        }        map.put(groupKey, group);    }    return group.addSample(category, score);}
public double mahout_f4105_0(int category, double score)
{    throw new UnsupportedOperationException("Can't add to " + this.getClass() + " without group key");}
public double mahout_f4106_0()
{    double sum = 0;    for (OnlineAuc auc : map.values()) {        sum += auc.auc();    }    return sum / map.size();}
public void mahout_f4107_0(GlobalOnlineAuc.ReplacementPolicy policy)
{    this.policy = policy;    for (OnlineAuc auc : map.values()) {        auc.setPolicy(policy);    }}
public void mahout_f4108_0(int windowSize)
{    this.windowSize = windowSize;    for (OnlineAuc auc : map.values()) {        auc.setWindowSize(windowSize);    }}
public void mahout_f4109_0(DataOutput out) throws IOException
{    out.writeInt(map.size());    for (Map.Entry<String, OnlineAuc> entry : map.entrySet()) {        out.writeUTF(entry.getKey());        PolymorphicWritable.write(out, entry.getValue());    }    out.writeInt(policy.ordinal());    out.writeInt(windowSize);}
public void mahout_f4110_0(DataInput in) throws IOException
{    int n = in.readInt();    map.clear();    for (int i = 0; i < n; i++) {        String key = in.readUTF();        map.put(key, PolymorphicWritable.read(in, OnlineAuc.class));    }    policy = GlobalOnlineAuc.ReplacementPolicy.values()[in.readInt()];    windowSize = in.readInt();}
public void mahout_f4111_0(double sample)
{    n++;    double oldMean = mean;    mean += (sample - mean) / n;    double diff = (sample - mean) * (sample - oldMean);    variance += (diff - variance) / n;    quantiles.add(sample);}
public int mahout_f4112_0()
{    return n;}
public double mahout_f4113_0()
{    return mean;}
public double mahout_f4114_0()
{    return Math.sqrt(variance);}
public double mahout_f4115_0()
{    return getQuartile(0);}
public double mahout_f4116_0()
{    return getQuartile(4);}
public double mahout_f4117_0(int i)
{    return quantiles.quantile(0.25 * i);}
public double mahout_f4118_0(double q)
{    return quantiles.quantile(q);}
public double mahout_f4119_0()
{    return getQuartile(2);}
public int mahout_f4120_0(Vector distribution)
{    return sample(samplerFor(distribution));}
public int mahout_f4121_0()
{    Preconditions.checkNotNull(sampler, "Sampler must have been constructed with a distribution, or else sample(Vector) should be used to sample");    return sample(sampler);}
private static double[] mahout_f4122_0(Vector vectorDistribution)
{    int size = vectorDistribution.size();    double[] partition = new double[size];    double norm = vectorDistribution.norm(1);    double sum = 0;    for (int i = 0; i < size; i++) {        sum += vectorDistribution.get(i) / norm;        partition[i] = sum;    }    return partition;}
private int mahout_f4123_0(double[] sampler)
{    int index = Arrays.binarySearch(sampler, random.nextDouble());    return index < 0 ? -(index + 1) : index;}
protected void mahout_f4124_0(GramKey key, Iterable<Gram> values, Context context) throws IOException, InterruptedException
{    int freq = 0;    Gram value = null;        for (Gram value1 : values) {        value = value1;        freq += value.getFrequency();    }    if (value != null) {        value.setFrequency(freq);        context.write(key, value);    }}
public static void mahout_f4125_0(String[] args) throws Exception
{    ToolRunner.run(new CollocDriver(), args);}
public int mahout_f4126_1(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption(DefaultOptionCreator.numReducersOption().create());    addOption("maxNGramSize", "ng", "(Optional) The max size of ngrams to create (2 = bigrams, 3 = trigrams, etc) default: 2", String.valueOf(DEFAULT_MAX_NGRAM_SIZE));    addOption("minSupport", "s", "(Optional) Minimum Support. Default Value: " + CollocReducer.DEFAULT_MIN_SUPPORT, String.valueOf(CollocReducer.DEFAULT_MIN_SUPPORT));    addOption("minLLR", "ml", "(Optional)The minimum Log Likelihood Ratio(Float)  Default is " + LLRReducer.DEFAULT_MIN_LLR, String.valueOf(LLRReducer.DEFAULT_MIN_LLR));    addOption(DefaultOptionCreator.overwriteOption().create());    addOption("analyzerName", "a", "The class name of the analyzer to use for preprocessing", null);    addFlag("preprocess", "p", "If set, input is SequenceFile<Text,Text> where the value is the document, " + " which will be tokenized using the specified analyzer.");    addFlag("unigram", "u", "If set, unigrams will be emitted in the final output alongside collocations");    Map<String, List<String>> argMap = parseArguments(args);    if (argMap == null) {        return -1;    }    Path input = getInputPath();    Path output = getOutputPath();    int maxNGramSize = DEFAULT_MAX_NGRAM_SIZE;    if (hasOption("maxNGramSize")) {        try {            maxNGramSize = Integer.parseInt(getOption("maxNGramSize"));        } catch (NumberFormatException ex) {                    }    }        if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {        HadoopUtil.delete(getConf(), output);    }    int minSupport = CollocReducer.DEFAULT_MIN_SUPPORT;    if (getOption("minSupport") != null) {        minSupport = Integer.parseInt(getOption("minSupport"));    }        float minLLRValue = LLRReducer.DEFAULT_MIN_LLR;    if (getOption("minLLR") != null) {        minLLRValue = Float.parseFloat(getOption("minLLR"));    }        int reduceTasks = DEFAULT_PASS1_NUM_REDUCE_TASKS;    if (getOption("maxRed") != null) {        reduceTasks = Integer.parseInt(getOption("maxRed"));    }        boolean emitUnigrams = argMap.containsKey("emitUnigrams");    if (argMap.containsKey("preprocess")) {                Class<? extends Analyzer> analyzerClass = StandardAnalyzer.class;        if (getOption("analyzerName") != null) {            String className = getOption("analyzerName");            analyzerClass = Class.forName(className).asSubclass(Analyzer.class);                                    AnalyzerUtils.createAnalyzer(analyzerClass);        }        Path tokenizedPath = new Path(output, DocumentProcessor.TOKENIZED_DOCUMENT_OUTPUT_FOLDER);        DocumentProcessor.tokenizeDocuments(input, analyzerClass, tokenizedPath, getConf());        input = tokenizedPath;    } else {            }        long ngramCount = generateCollocations(input, output, getConf(), emitUnigrams, maxNGramSize, reduceTasks, minSupport);        computeNGramsPruneByLLR(output, getConf(), ngramCount, emitUnigrams, minLLRValue, reduceTasks);    return 0;}
public static void mahout_f4127_0(Path input, Path output, Configuration baseConf, int maxNGramSize, int minSupport, float minLLRValue, int reduceTasks) throws IOException, InterruptedException, ClassNotFoundException
{        long ngramCount = generateCollocations(input, output, baseConf, true, maxNGramSize, reduceTasks, minSupport);        computeNGramsPruneByLLR(output, baseConf, ngramCount, true, minLLRValue, reduceTasks);}
private static long mahout_f4128_0(Path input, Path output, Configuration baseConf, boolean emitUnigrams, int maxNGramSize, int reduceTasks, int minSupport) throws IOException, ClassNotFoundException, InterruptedException
{    Configuration con = new Configuration(baseConf);    con.setBoolean(EMIT_UNIGRAMS, emitUnigrams);    con.setInt(CollocMapper.MAX_SHINGLE_SIZE, maxNGramSize);    con.setInt(CollocReducer.MIN_SUPPORT, minSupport);    Job job = new Job(con);    job.setJobName(CollocDriver.class.getSimpleName() + ".generateCollocations:" + input);    job.setJarByClass(CollocDriver.class);    job.setMapOutputKeyClass(GramKey.class);    job.setMapOutputValueClass(Gram.class);    job.setPartitionerClass(GramKeyPartitioner.class);    job.setGroupingComparatorClass(GramKeyGroupComparator.class);    job.setOutputKeyClass(Gram.class);    job.setOutputValueClass(Gram.class);    job.setCombinerClass(CollocCombiner.class);    FileInputFormat.setInputPaths(job, input);    Path outputPath = new Path(output, SUBGRAM_OUTPUT_DIRECTORY);    FileOutputFormat.setOutputPath(job, outputPath);    job.setInputFormatClass(SequenceFileInputFormat.class);    job.setMapperClass(CollocMapper.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    job.setReducerClass(CollocReducer.class);    job.setNumReduceTasks(reduceTasks);    boolean succeeded = job.waitForCompletion(true);    if (!succeeded) {        throw new IllegalStateException("Job failed!");    }    return job.getCounters().findCounter(CollocMapper.Count.NGRAM_TOTAL).getValue();}
private static void mahout_f4129_0(Path output, Configuration baseConf, long nGramTotal, boolean emitUnigrams, float minLLRValue, int reduceTasks) throws IOException, InterruptedException, ClassNotFoundException
{    Configuration conf = new Configuration(baseConf);    conf.setLong(LLRReducer.NGRAM_TOTAL, nGramTotal);    conf.setBoolean(EMIT_UNIGRAMS, emitUnigrams);    conf.setFloat(LLRReducer.MIN_LLR, minLLRValue);    Job job = new Job(conf);    job.setJobName(CollocDriver.class.getSimpleName() + ".computeNGrams: " + output);    job.setJarByClass(CollocDriver.class);    job.setMapOutputKeyClass(Gram.class);    job.setMapOutputValueClass(Gram.class);    job.setOutputKeyClass(Text.class);    job.setOutputValueClass(DoubleWritable.class);    FileInputFormat.setInputPaths(job, new Path(output, SUBGRAM_OUTPUT_DIRECTORY));    Path outPath = new Path(output, NGRAM_OUTPUT_DIRECTORY);    FileOutputFormat.setOutputPath(job, outPath);    job.setMapperClass(Mapper.class);    job.setInputFormatClass(SequenceFileInputFormat.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    job.setReducerClass(LLRReducer.class);    job.setNumReduceTasks(reduceTasks);    boolean succeeded = job.waitForCompletion(true);    if (!succeeded) {        throw new IllegalStateException("Job failed!");    }}
protected void mahout_f4130_0(Text key, StringTuple value, final Context context) throws IOException, InterruptedException
{    try (ShingleFilter sf = new ShingleFilter(new IteratorTokenStream(value.getEntries().iterator()), maxShingleSize)) {        sf.reset();                int count = 0;        OpenObjectIntHashMap<String> ngrams = new OpenObjectIntHashMap<>(value.getEntries().size() * (maxShingleSize - 1));        OpenObjectIntHashMap<String> unigrams = new OpenObjectIntHashMap<>(value.getEntries().size());        do {            String term = sf.getAttribute(CharTermAttribute.class).toString();            String type = sf.getAttribute(TypeAttribute.class).type();            if ("shingle".equals(type)) {                count++;                ngrams.adjustOrPutValue(term, 1, 1);            } else if (emitUnigrams && !term.isEmpty()) {                                unigrams.adjustOrPutValue(term, 1, 1);            }        } while (sf.incrementToken());        final GramKey gramKey = new GramKey();        ngrams.forEachPair(new ObjectIntProcedure<String>() {            @Override            public boolean apply(String term, int frequency) {                                                int i = term.lastIndexOf(' ');                if (i != -1) {                    try {                        Gram ngram = new Gram(term, frequency, Gram.Type.NGRAM);                        Gram head = new Gram(term.substring(0, i), frequency, Gram.Type.HEAD);                        Gram tail = new Gram(term.substring(i + 1), frequency, Gram.Type.TAIL);                        gramKey.set(head, EMPTY);                        context.write(gramKey, head);                        gramKey.set(head, ngram.getBytes());                        context.write(gramKey, ngram);                        gramKey.set(tail, EMPTY);                        context.write(gramKey, tail);                        gramKey.set(tail, ngram.getBytes());                        context.write(gramKey, ngram);                    } catch (IOException | InterruptedException e) {                        throw new IllegalStateException(e);                    }                }                return true;            }        });        unigrams.forEachPair(new ObjectIntProcedure<String>() {            @Override            public boolean apply(String term, int frequency) {                try {                    Gram unigram = new Gram(term, frequency, Gram.Type.UNIGRAM);                    gramKey.set(unigram, EMPTY);                    context.write(gramKey, unigram);                } catch (IOException | InterruptedException e) {                    throw new IllegalStateException(e);                }                return true;            }        });        context.getCounter(Count.NGRAM_TOTAL).increment(count);        sf.end();    }}
public boolean mahout_f4131_0(String term, int frequency)
{            int i = term.lastIndexOf(' ');    if (i != -1) {        try {            Gram ngram = new Gram(term, frequency, Gram.Type.NGRAM);            Gram head = new Gram(term.substring(0, i), frequency, Gram.Type.HEAD);            Gram tail = new Gram(term.substring(i + 1), frequency, Gram.Type.TAIL);            gramKey.set(head, EMPTY);            context.write(gramKey, head);            gramKey.set(head, ngram.getBytes());            context.write(gramKey, ngram);            gramKey.set(tail, EMPTY);            context.write(gramKey, tail);            gramKey.set(tail, ngram.getBytes());            context.write(gramKey, ngram);        } catch (IOException | InterruptedException e) {            throw new IllegalStateException(e);        }    }    return true;}
public boolean mahout_f4132_0(String term, int frequency)
{    try {        Gram unigram = new Gram(term, frequency, Gram.Type.UNIGRAM);        gramKey.set(unigram, EMPTY);        context.write(gramKey, unigram);    } catch (IOException | InterruptedException e) {        throw new IllegalStateException(e);    }    return true;}
protected void mahout_f4133_1(Context context) throws IOException, InterruptedException
{    super.setup(context);    Configuration conf = context.getConfiguration();    this.maxShingleSize = conf.getInt(MAX_SHINGLE_SIZE, DEFAULT_MAX_SHINGLE_SIZE);    this.emitUnigrams = conf.getBoolean(CollocDriver.EMIT_UNIGRAMS, CollocDriver.DEFAULT_EMIT_UNIGRAMS);    if (log.isInfoEnabled()) {                    }}
protected void mahout_f4134_0(GramKey key, Iterable<Gram> values, Context context) throws IOException, InterruptedException
{    Gram.Type keyType = key.getType();    if (keyType == Gram.Type.UNIGRAM) {                processUnigram(values.iterator(), context);    } else if (keyType == Gram.Type.HEAD || keyType == Gram.Type.TAIL) {                processSubgram(values.iterator(), context);    } else {        context.getCounter(Skipped.MALFORMED_TYPES).increment(1);    }}
protected void mahout_f4135_1(Context context) throws IOException, InterruptedException
{    super.setup(context);    Configuration conf = context.getConfiguration();    this.minSupport = conf.getInt(MIN_SUPPORT, DEFAULT_MIN_SUPPORT);    boolean emitUnigrams = conf.getBoolean(CollocDriver.EMIT_UNIGRAMS, CollocDriver.DEFAULT_EMIT_UNIGRAMS);        }
protected void mahout_f4136_0(Iterator<Gram> values, Context context) throws IOException, InterruptedException
{    int freq = 0;    Gram value = null;        while (values.hasNext()) {        value = values.next();        freq += value.getFrequency();    }    if (freq < minSupport) {        context.getCounter(Skipped.LESS_THAN_MIN_SUPPORT).increment(1);        return;    }    value.setFrequency(freq);    context.write(value, value);}
protected void mahout_f4137_0(Iterator<Gram> values, Context context) throws IOException, InterruptedException
{    Gram subgram = null;    Gram currentNgram = null;    while (values.hasNext()) {        Gram value = values.next();        if (value.getType() == Gram.Type.HEAD || value.getType() == Gram.Type.TAIL) {                        if (subgram == null) {                subgram = new Gram(value);            } else {                subgram.incrementFrequency(value.getFrequency());            }        } else if (!value.equals(currentNgram)) {                        if (currentNgram != null) {                if (currentNgram.getFrequency() < minSupport) {                    context.getCounter(Skipped.LESS_THAN_MIN_SUPPORT).increment(1);                } else {                    context.write(currentNgram, subgram);                }            }            currentNgram = new Gram(value);        } else {            currentNgram.incrementFrequency(value.getFrequency());        }    }        if (currentNgram != null) {        if (currentNgram.getFrequency() < minSupport) {            context.getCounter(Skipped.LESS_THAN_MIN_SUPPORT).increment(1);            return;        }        context.write(currentNgram, subgram);    }}
public String mahout_f4138_0()
{    return String.valueOf(x);}
public byte[] mahout_f4139_0()
{    return bytes;}
public int mahout_f4140_0()
{    return length;}
public Type mahout_f4141_0()
{    return decodeType(bytes, 0);}
public String mahout_f4142_0()
{    try {        return Text.decode(bytes, 1, length - 1);    } catch (CharacterCodingException e) {        throw new IllegalStateException("Should not have happened " + e);    }}
public int mahout_f4143_0()
{    return frequency;}
public void mahout_f4144_0(int frequency)
{    this.frequency = frequency;}
public void mahout_f4145_0(int i)
{    this.frequency += i;}
public void mahout_f4146_0(DataInput in) throws IOException
{    int newLength = Varint.readUnsignedVarInt(in);    setCapacity(newLength, false);    in.readFully(bytes, 0, newLength);    int newFrequency = Varint.readUnsignedVarInt(in);    length = newLength;    frequency = newFrequency;}
public void mahout_f4147_0(DataOutput out) throws IOException
{    Varint.writeUnsignedVarInt(length, out);    out.write(bytes, 0, length);    Varint.writeUnsignedVarInt(frequency, out);}
private void mahout_f4148_0(int len, boolean keepData)
{        len++;    if (bytes == null || bytes.length < len) {        byte[] newBytes = new byte[len];        if (bytes != null && keepData) {            System.arraycopy(bytes, 0, newBytes, 0, length);        }        bytes = newBytes;    }}
public String mahout_f4149_0()
{    return '\'' + getString() + "'[" + getType() + "]:" + frequency;}
public static void mahout_f4150_0(Type type, byte[] buf, int offset)
{    switch(type) {        case HEAD:            buf[offset] = 0x1;            break;        case TAIL:            buf[offset] = 0x2;            break;        case UNIGRAM:            buf[offset] = 0x3;            break;        case NGRAM:            buf[offset] = 0x4;            break;        default:            throw new IllegalStateException("switch/case problem in encodeType");    }}
public static Type mahout_f4151_0(byte[] buf, int offset)
{    switch(buf[offset]) {        case 0x1:            return Type.HEAD;        case 0x2:            return Type.TAIL;        case 0x3:            return Type.UNIGRAM;        case 0x4:            return Type.NGRAM;        default:            throw new IllegalStateException("switch/case problem in decodeType");    }}
public void mahout_f4152_0(Gram gram, byte[] order)
{    primaryLength = gram.getLength();    length = primaryLength + order.length;    setCapacity(length, false);    System.arraycopy(gram.getBytes(), 0, bytes, 0, primaryLength);    if (order.length > 0) {        System.arraycopy(order, 0, bytes, primaryLength, order.length);    }}
public byte[] mahout_f4153_0()
{    return bytes;}
public int mahout_f4154_0()
{    return length;}
public int mahout_f4155_0()
{    return primaryLength;}
public void mahout_f4156_0(DataInput in) throws IOException
{    int newLength = Varint.readUnsignedVarInt(in);    int newPrimaryLength = Varint.readUnsignedVarInt(in);    setCapacity(newLength, false);    in.readFully(bytes, 0, newLength);    length = newLength;    primaryLength = newPrimaryLength;}
public void mahout_f4157_0(DataOutput out) throws IOException
{    Varint.writeUnsignedVarInt(length, out);    Varint.writeUnsignedVarInt(primaryLength, out);    out.write(bytes, 0, length);}
private void mahout_f4158_0(int len, boolean keepData)
{    if (bytes == null || bytes.length < len) {        byte[] newBytes = new byte[len];        if (bytes != null && keepData) {            System.arraycopy(bytes, 0, newBytes, 0, length);        }        bytes = newBytes;    }}
public Type mahout_f4159_0()
{    return Gram.decodeType(bytes, 0);}
public String mahout_f4160_0()
{    try {        return Text.decode(bytes, 1, primaryLength - 1);    } catch (CharacterCodingException e) {        throw new IllegalStateException(e);    }}
public String mahout_f4161_0()
{    return '\'' + getPrimaryString() + "'[" + getType() + ']';}
public int mahout_f4162_0(WritableComparable a, WritableComparable b)
{    GramKey gka = (GramKey) a;    GramKey gkb = (GramKey) b;    return WritableComparator.compareBytes(gka.getBytes(), 0, gka.getPrimaryLength(), gkb.getBytes(), 0, gkb.getPrimaryLength());}
public int mahout_f4163_0(GramKey key, Gram value, int numPartitions)
{    int hash = 1;    byte[] bytes = key.getBytes();    int length = key.getPrimaryLength();        for (int i = 1; i < length; i++) {        hash = (31 * hash) + bytes[i];    }    return (hash & Integer.MAX_VALUE) % numPartitions;}
protected void mahout_f4164_1(Gram ngram, Iterable<Gram> values, Context context) throws IOException, InterruptedException
{    int[] gramFreq = { -1, -1 };    if (ngram.getType() == Gram.Type.UNIGRAM && emitUnigrams) {        DoubleWritable dd = new DoubleWritable(ngram.getFrequency());        Text t = new Text(ngram.getString());        context.write(t, dd);        return;    }            String[] gram = new String[2];    for (Gram value : values) {        int pos = value.getType() == Gram.Type.HEAD ? 0 : 1;        if (gramFreq[pos] != -1) {                        if (value.getType() == Gram.Type.HEAD) {                context.getCounter(Skipped.EXTRA_HEAD).increment(1);            } else {                context.getCounter(Skipped.EXTRA_TAIL).increment(1);            }            return;        }        gram[pos] = value.getString();        gramFreq[pos] = value.getFrequency();    }    if (gramFreq[0] == -1) {                context.getCounter(Skipped.MISSING_HEAD).increment(1);        return;    }    if (gramFreq[1] == -1) {                context.getCounter(Skipped.MISSING_TAIL).increment(1);        return;    }    long k11 = ngram.getFrequency();    /* a&b */    long k12 = gramFreq[0] - ngram.getFrequency();    /* a&!b */    long k21 = gramFreq[1] - ngram.getFrequency();    /* !b&a */    long k22 = ngramTotal - (gramFreq[0] + gramFreq[1] - ngram.getFrequency());    /* !a&!b */    double llr;    try {        llr = ll.logLikelihoodRatio(k11, k12, k21, k22);    } catch (IllegalArgumentException ex) {        context.getCounter(Skipped.LLR_CALCULATION_ERROR).increment(1);                return;    }    if (llr < minLLRValue) {        context.getCounter(Skipped.LESS_THAN_MIN_LLR).increment(1);    } else {        context.write(new Text(ngram.getString()), new DoubleWritable(llr));    }}
protected void mahout_f4165_1(Context context) throws IOException, InterruptedException
{    super.setup(context);    Configuration conf = context.getConfiguration();    this.ngramTotal = conf.getLong(NGRAM_TOTAL, -1);    this.minLLRValue = conf.getFloat(MIN_LLR, DEFAULT_MIN_LLR);    this.emitUnigrams = conf.getBoolean(CollocDriver.EMIT_UNIGRAMS, CollocDriver.DEFAULT_EMIT_UNIGRAMS);        if (ngramTotal == -1) {        throw new IllegalStateException("No NGRAM_TOTAL available in job config");    }}
public double mahout_f4166_0(long k11, long k12, long k21, long k22)
{    return LogLikelihood.logLikelihoodRatio(k11, k12, k21, k22);}
public static void mahout_f4167_0(Iterable<Path> partialVectorPaths, Path output, Configuration baseConf, float normPower, boolean logNormalize, int dimension, boolean sequentialAccess, boolean namedVector, int numReducers) throws IOException, InterruptedException, ClassNotFoundException
{    Preconditions.checkArgument(normPower == NO_NORMALIZING || normPower >= 0, "If specified normPower must be nonnegative", normPower);    Preconditions.checkArgument(normPower == NO_NORMALIZING || (normPower > 1 && !Double.isInfinite(normPower)) || !logNormalize, "normPower must be > 1 and not infinite if log normalization is chosen", normPower);    Configuration conf = new Configuration(baseConf);        conf.set("io.serializations", "org.apache.hadoop.io.serializer.JavaSerialization," + "org.apache.hadoop.io.serializer.WritableSerialization");    conf.setBoolean(SEQUENTIAL_ACCESS, sequentialAccess);    conf.setBoolean(NAMED_VECTOR, namedVector);    conf.setInt(DIMENSION, dimension);    conf.setFloat(NORMALIZATION_POWER, normPower);    conf.setBoolean(LOG_NORMALIZE, logNormalize);    Job job = new Job(conf);    job.setJobName("PartialVectorMerger::MergePartialVectors");    job.setJarByClass(PartialVectorMerger.class);    job.setOutputKeyClass(Text.class);    job.setOutputValueClass(VectorWritable.class);    FileInputFormat.setInputPaths(job, getCommaSeparatedPaths(partialVectorPaths));    FileOutputFormat.setOutputPath(job, output);    job.setMapperClass(Mapper.class);    job.setInputFormatClass(SequenceFileInputFormat.class);    job.setReducerClass(PartialVectorMergeReducer.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    job.setNumReduceTasks(numReducers);    HadoopUtil.delete(conf, output);    boolean succeeded = job.waitForCompletion(true);    if (!succeeded) {        throw new IllegalStateException("Job failed!");    }}
private static String mahout_f4168_0(Iterable<Path> paths)
{    StringBuilder commaSeparatedPaths = new StringBuilder(100);    String sep = "";    for (Path path : paths) {        commaSeparatedPaths.append(sep).append(path.toString());        sep = ",";    }    return commaSeparatedPaths.toString();}
protected void mahout_f4169_0(WritableComparable<?> key, Iterable<VectorWritable> values, Context context) throws IOException, InterruptedException
{    Vector vector = new RandomAccessSparseVector(dimension, 10);    for (VectorWritable value : values) {        vector.assign(value.get(), Functions.PLUS);    }    if (normPower != PartialVectorMerger.NO_NORMALIZING) {        if (logNormalize) {            vector = vector.logNormalize(normPower);        } else {            vector = vector.normalize(normPower);        }    }    if (sequentialAccess) {        vector = new SequentialAccessSparseVector(vector);    }    if (namedVector) {        vector = new NamedVector(vector, key.toString());    }        if (vector.getNumNondefaultElements() > 0) {        VectorWritable vectorWritable = new VectorWritable(vector);        context.write(key, vectorWritable);    }}
protected void mahout_f4170_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    Configuration conf = context.getConfiguration();    normPower = conf.getFloat(PartialVectorMerger.NORMALIZATION_POWER, PartialVectorMerger.NO_NORMALIZING);    dimension = conf.getInt(PartialVectorMerger.DIMENSION, Integer.MAX_VALUE);    sequentialAccess = conf.getBoolean(PartialVectorMerger.SEQUENTIAL_ACCESS, false);    namedVector = conf.getBoolean(PartialVectorMerger.NAMED_VECTOR, false);    logNormalize = conf.getBoolean(PartialVectorMerger.LOG_NORMALIZE, false);}
public void mahout_f4171_0(Path input, Path output, VectorizerConfig config) throws IOException, ClassNotFoundException, InterruptedException
{    createTermFrequencyVectors(input, output, config.getTfDirName(), config.getConf(), config.getMinSupport(), config.getMaxNGramSize(), config.getMinLLRValue(), config.getNormPower(), config.isLogNormalize(), config.getNumReducers(), config.getChunkSizeInMegabytes(), config.isSequentialAccess(), config.isNamedVectors());}
public static void mahout_f4172_1(Path input, Path output, String tfVectorsFolderName, Configuration baseConf, int minSupport, int maxNGramSize, float minLLRValue, float normPower, boolean logNormalize, int numReducers, int chunkSizeInMegabytes, boolean sequentialAccess, boolean namedVectors) throws IOException, InterruptedException, ClassNotFoundException
{    Preconditions.checkArgument(normPower == PartialVectorMerger.NO_NORMALIZING || normPower >= 0, "If specified normPower must be nonnegative", normPower);    Preconditions.checkArgument(normPower == PartialVectorMerger.NO_NORMALIZING || (normPower > 1 && !Double.isInfinite(normPower)) || !logNormalize, "normPower must be > 1 and not infinite if log normalization is chosen", normPower);    if (chunkSizeInMegabytes < MIN_CHUNKSIZE) {        chunkSizeInMegabytes = MIN_CHUNKSIZE;    } else if (chunkSizeInMegabytes > MAX_CHUNKSIZE) {                chunkSizeInMegabytes = MAX_CHUNKSIZE;    }    if (minSupport < 0) {        minSupport = DEFAULT_MIN_SUPPORT;    }    Path dictionaryJobPath = new Path(output, DICTIONARY_JOB_FOLDER);        int[] maxTermDimension = new int[1];    List<Path> dictionaryChunks;    if (maxNGramSize == 1) {        startWordCounting(input, dictionaryJobPath, baseConf, minSupport);        dictionaryChunks = createDictionaryChunks(dictionaryJobPath, output, baseConf, chunkSizeInMegabytes, maxTermDimension);    } else {        CollocDriver.generateAllGrams(input, dictionaryJobPath, baseConf, maxNGramSize, minSupport, minLLRValue, numReducers);        dictionaryChunks = createDictionaryChunks(new Path(new Path(output, DICTIONARY_JOB_FOLDER), CollocDriver.NGRAM_OUTPUT_DIRECTORY), output, baseConf, chunkSizeInMegabytes, maxTermDimension);    }    int partialVectorIndex = 0;    Collection<Path> partialVectorPaths = Lists.newArrayList();    for (Path dictionaryChunk : dictionaryChunks) {        Path partialVectorOutputPath = new Path(output, VECTOR_OUTPUT_FOLDER + partialVectorIndex++);        partialVectorPaths.add(partialVectorOutputPath);        makePartialVectors(input, baseConf, maxNGramSize, dictionaryChunk, partialVectorOutputPath, maxTermDimension[0], sequentialAccess, namedVectors, numReducers);    }    Configuration conf = new Configuration(baseConf);    Path outputDir = new Path(output, tfVectorsFolderName);    PartialVectorMerger.mergePartialVectors(partialVectorPaths, outputDir, conf, normPower, logNormalize, maxTermDimension[0], sequentialAccess, namedVectors, numReducers);    HadoopUtil.delete(conf, partialVectorPaths);}
private static List<Path> mahout_f4173_0(Path wordCountPath, Path dictionaryPathBase, Configuration baseConf, int chunkSizeInMegabytes, int[] maxTermDimension) throws IOException
{    List<Path> chunkPaths = Lists.newArrayList();    Configuration conf = new Configuration(baseConf);    FileSystem fs = FileSystem.get(wordCountPath.toUri(), conf);    long chunkSizeLimit = chunkSizeInMegabytes * 1024L * 1024L;    int chunkIndex = 0;    Path chunkPath = new Path(dictionaryPathBase, DICTIONARY_FILE + chunkIndex);    chunkPaths.add(chunkPath);    SequenceFile.Writer dictWriter = new SequenceFile.Writer(fs, conf, chunkPath, Text.class, IntWritable.class);    try {        long currentChunkSize = 0;        Path filesPattern = new Path(wordCountPath, OUTPUT_FILES_PATTERN);        int i = 0;        for (Pair<Writable, Writable> record : new SequenceFileDirIterable<>(filesPattern, PathType.GLOB, null, null, true, conf)) {            if (currentChunkSize > chunkSizeLimit) {                Closeables.close(dictWriter, false);                chunkIndex++;                chunkPath = new Path(dictionaryPathBase, DICTIONARY_FILE + chunkIndex);                chunkPaths.add(chunkPath);                dictWriter = new SequenceFile.Writer(fs, conf, chunkPath, Text.class, IntWritable.class);                currentChunkSize = 0;            }            Writable key = record.getFirst();            int fieldSize = DICTIONARY_BYTE_OVERHEAD + key.toString().length() * 2 + Integer.SIZE / 8;            currentChunkSize += fieldSize;            dictWriter.append(key, new IntWritable(i++));        }        maxTermDimension[0] = i;    } finally {        Closeables.close(dictWriter, false);    }    return chunkPaths;}
private static void mahout_f4174_0(Path input, Configuration baseConf, int maxNGramSize, Path dictionaryFilePath, Path output, int dimension, boolean sequentialAccess, boolean namedVectors, int numReducers) throws IOException, InterruptedException, ClassNotFoundException
{    Configuration conf = new Configuration(baseConf);        conf.set("io.serializations", "org.apache.hadoop.io.serializer.JavaSerialization," + "org.apache.hadoop.io.serializer.WritableSerialization");    conf.setInt(PartialVectorMerger.DIMENSION, dimension);    conf.setBoolean(PartialVectorMerger.SEQUENTIAL_ACCESS, sequentialAccess);    conf.setBoolean(PartialVectorMerger.NAMED_VECTOR, namedVectors);    conf.setInt(MAX_NGRAMS, maxNGramSize);    DistributedCache.addCacheFile(dictionaryFilePath.toUri(), conf);    Job job = new Job(conf);    job.setJobName("DictionaryVectorizer::MakePartialVectors: input-folder: " + input + ", dictionary-file: " + dictionaryFilePath);    job.setJarByClass(DictionaryVectorizer.class);    job.setMapOutputKeyClass(Text.class);    job.setMapOutputValueClass(StringTuple.class);    job.setOutputKeyClass(Text.class);    job.setOutputValueClass(VectorWritable.class);    FileInputFormat.setInputPaths(job, input);    FileOutputFormat.setOutputPath(job, output);    job.setMapperClass(Mapper.class);    job.setInputFormatClass(SequenceFileInputFormat.class);    job.setReducerClass(TFPartialVectorReducer.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    job.setNumReduceTasks(numReducers);    HadoopUtil.delete(conf, output);    boolean succeeded = job.waitForCompletion(true);    if (!succeeded) {        throw new IllegalStateException("Job failed!");    }}
private static void mahout_f4175_0(Path input, Path output, Configuration baseConf, int minSupport) throws IOException, InterruptedException, ClassNotFoundException
{    Configuration conf = new Configuration(baseConf);        conf.set("io.serializations", "org.apache.hadoop.io.serializer.JavaSerialization," + "org.apache.hadoop.io.serializer.WritableSerialization");    conf.setInt(MIN_SUPPORT, minSupport);    Job job = new Job(conf);    job.setJobName("DictionaryVectorizer::WordCount: input-folder: " + input);    job.setJarByClass(DictionaryVectorizer.class);    job.setOutputKeyClass(Text.class);    job.setOutputValueClass(LongWritable.class);    FileInputFormat.setInputPaths(job, input);    FileOutputFormat.setOutputPath(job, output);    job.setMapperClass(TermCountMapper.class);    job.setInputFormatClass(SequenceFileInputFormat.class);    job.setCombinerClass(TermCountCombiner.class);    job.setReducerClass(TermCountReducer.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    HadoopUtil.delete(conf, output);    boolean succeeded = job.waitForCompletion(true);    if (!succeeded) {        throw new IllegalStateException("Job failed!");    }}
public int mahout_f4176_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption("tfDirName", "tf", "The folder to store the TF calculations", "tfDirName");    addOption("minSupport", "s", "(Optional) Minimum Support. Default Value: 2", "2");    addOption("maxNGramSize", "ng", "(Optional) The maximum size of ngrams to create" + " (2 = bigrams, 3 = trigrams, etc) Default Value:1");    addOption("minLLR", "ml", "(Optional)The minimum Log Likelihood Ratio(Float)  Default is " + LLRReducer.DEFAULT_MIN_LLR);    addOption("norm", "n", "The norm to use, expressed as either a float or \"INF\" " + "if you want to use the Infinite norm.  " + "Must be greater or equal to 0.  The default is not to normalize");    addOption("logNormalize", "lnorm", "(Optional) Whether output vectors should be logNormalize. " + "If set true else false", "false");    addOption(DefaultOptionCreator.numReducersOption().create());    addOption("chunkSize", "chunk", "The chunkSize in MegaBytes. 100-10000 MB", "100");    addOption(DefaultOptionCreator.methodOption().create());    addOption("namedVector", "nv", "(Optional) Whether output vectors should be NamedVectors. " + "If set true else false", "false");    if (parseArguments(args) == null) {        return -1;    }    String tfDirName = getOption("tfDirName", "tfDir");    int minSupport = getInt("minSupport", 2);    int maxNGramSize = getInt("maxNGramSize", 1);    float minLLRValue = getFloat("minLLR", LLRReducer.DEFAULT_MIN_LLR);    float normPower = getFloat("norm", PartialVectorMerger.NO_NORMALIZING);    boolean logNormalize = hasOption("logNormalize");    int numReducers = getInt(DefaultOptionCreator.MAX_REDUCERS_OPTION);    int chunkSizeInMegs = getInt("chunkSize", 100);    boolean sequential = hasOption("sequential");    boolean namedVecs = hasOption("namedVectors");        createTermFrequencyVectors(getInputPath(), getOutputPath(), tfDirName, getConf(), minSupport, maxNGramSize, minLLRValue, normPower, logNormalize, numReducers, chunkSizeInMegs, sequential, namedVecs);    return 0;}
public static void mahout_f4177_0(String[] args) throws Exception
{    ToolRunner.run(new DictionaryVectorizer(), args);}
protected void mahout_f4178_0(Text key, Text value, Context context) throws IOException, InterruptedException
{    TokenStream stream = analyzer.tokenStream(key.toString(), new StringReader(value.toString()));    CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);    stream.reset();    StringTuple document = new StringTuple();    while (stream.incrementToken()) {        if (termAtt.length() > 0) {            document.add(new String(termAtt.buffer(), 0, termAtt.length()));        }    }    stream.end();    Closeables.close(stream, true);    context.write(key, document);}
protected void mahout_f4179_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    String analyzerClassName = context.getConfiguration().get(DocumentProcessor.ANALYZER_CLASS, StandardAnalyzer.class.getName());    try {        analyzer = AnalyzerUtils.createAnalyzer(analyzerClassName);    } catch (ClassNotFoundException e) {        throw new IOException("Unable to create analyzer: " + analyzerClassName, e);    }}
public static void mahout_f4180_0(Path input, Class<? extends Analyzer> analyzerClass, Path output, Configuration baseConf) throws IOException, InterruptedException, ClassNotFoundException
{    Configuration conf = new Configuration(baseConf);        conf.set("io.serializations", "org.apache.hadoop.io.serializer.JavaSerialization," + "org.apache.hadoop.io.serializer.WritableSerialization");    conf.set(ANALYZER_CLASS, analyzerClass.getName());    Job job = new Job(conf);    job.setJobName("DocumentProcessor::DocumentTokenizer: input-folder: " + input);    job.setJarByClass(DocumentProcessor.class);    job.setOutputKeyClass(Text.class);    job.setOutputValueClass(StringTuple.class);    FileInputFormat.setInputPaths(job, input);    FileOutputFormat.setOutputPath(job, output);    job.setMapperClass(SequenceFileTokenizerMapper.class);    job.setInputFormatClass(SequenceFileInputFormat.class);    job.setNumReduceTasks(0);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    HadoopUtil.delete(conf, output);    boolean succeeded = job.waitForCompletion(true);    if (!succeeded) {        throw new IllegalStateException("Job failed!");    }}
public static void mahout_f4181_0(String[] args) throws Exception
{    ToolRunner.run(new Configuration(), new EncodedVectorsFromSequenceFiles(), args);}
public int mahout_f4182_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption(DefaultOptionCreator.analyzerOption().create());    addOption(buildOption("sequentialAccessVector", "seq", "(Optional) Whether output vectors should be SequentialAccessVectors. " + "If set true else false", false, false, null));    addOption(buildOption("namedVector", "nv", "Create named vectors using the key.  False by default", false, false, null));    addOption("cardinality", "c", "The cardinality to use for creating the vectors.  Default is 5000", "5000");    addOption("encoderFieldName", "en", "The name of the encoder to be passed to the FeatureVectorEncoder constructor. Default is text. " + "Note this is not the class name of a FeatureValueEncoder, but is instead the construction " + "argument.", "text");    addOption("encoderClass", "ec", "The class name of the encoder to be used. Default is " + LuceneTextValueEncoder.class.getName(), LuceneTextValueEncoder.class.getName());    addOption(DefaultOptionCreator.overwriteOption().create());    if (parseArguments(args) == null) {        return -1;    }    Path input = getInputPath();    Path output = getOutputPath();    if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {        HadoopUtil.delete(getConf(), output);    }    Class<? extends Analyzer> analyzerClass = getAnalyzerClassFromOption();    Configuration conf = getConf();    boolean sequentialAccessOutput = hasOption("sequentialAccessVector");    boolean namedVectors = hasOption("namedVector");    int cardinality = 5000;    if (hasOption("cardinality")) {        cardinality = Integer.parseInt(getOption("cardinality"));    }    String encoderName = "text";    if (hasOption("encoderFieldName")) {        encoderName = getOption("encoderFieldName");    }    String encoderClass = LuceneTextValueEncoder.class.getName();    if (hasOption("encoderClass")) {        encoderClass = getOption("encoderClass");        ClassUtils.instantiateAs(encoderClass, FeatureVectorEncoder.class, new Class[] { String.class },         new Object[] { encoderName });    }    SimpleTextEncodingVectorizer vectorizer = new SimpleTextEncodingVectorizer();    VectorizerConfig config = new VectorizerConfig(conf, analyzerClass.getName(), encoderClass, encoderName, sequentialAccessOutput, namedVectors, cardinality);    vectorizer.createVectors(input, output, config);    return 0;}
public void mahout_f4183_0(String originalForm, double weight, Vector data)
{    dictionary.add(originalForm);    super.addToVector(originalForm, weight, data);}
protected double mahout_f4184_0(byte[] originalForm, double w)
{    return w * weight(originalForm);}
protected double mahout_f4185_0(byte[] originalForm)
{                double thisWord = dictionary.count(new String(originalForm, Charsets.UTF_8)) + 0.5;    double allWords = dictionary.size() + dictionary.elementSet().size() * 0.5 + 0.5;    return -Math.log(thisWord / allWords);}
public Multiset<String> mahout_f4186_0()
{    return dictionary;}
private void mahout_f4187_0()
{    this.caches = new OpenIntIntHashMap[getProbes()];    for (int probe = 0; probe < getProbes(); probe++) {        caches[probe] = new OpenIntIntHashMap();    }}
 OpenIntIntHashMap[] mahout_f4188_0()
{    return caches;}
public void mahout_f4189_0(int probes)
{    super.setProbes(probes);    initCaches();}
protected int mahout_f4190_0(byte[] originalForm, int dataSize, String name, int probe)
{    Preconditions.checkArgument(dataSize == this.dataSize, "dataSize argument [" + dataSize + "] does not match expected dataSize [" + this.dataSize + ']');    int originalHashcode = Arrays.hashCode(originalForm);    if (caches[probe].containsKey(originalHashcode)) {        return caches[probe].get(originalHashcode);    }    int hash = super.hashForProbe(originalForm, dataSize, name, probe);    caches[probe].put(originalHashcode, hash);    return hash;}
private void mahout_f4191_0()
{    caches = new OpenIntIntHashMap[getProbes()];    for (int probe = 0; probe < getProbes(); probe++) {        caches[probe] = new OpenIntIntHashMap();    }}
 OpenIntIntHashMap[] mahout_f4192_0()
{    return caches;}
public void mahout_f4193_0(int probes)
{    super.setProbes(probes);    initCaches();}
protected int mahout_f4194_0(byte[] originalForm, int dataSize, String name, int probe)
{    Preconditions.checkArgument(dataSize == this.dataSize, "dataSize argument [" + dataSize + "] does not match expected dataSize [" + this.dataSize + ']');    int originalHashcode = Arrays.hashCode(originalForm);    if (caches[probe].containsKey(originalHashcode)) {        return caches[probe].get(originalHashcode);    }    int hash = super.hashForProbe(originalForm, dataSize, name, probe);    caches[probe].put(originalHashcode, hash);    return hash;}
public void mahout_f4195_0(int probes)
{    super.setProbes(probes);    cacheProbeLocations(getSeed());}
private void mahout_f4196_0(int seed)
{    cachedProbes = new int[getProbes()];    for (int i = 0; i < getProbes(); i++) {                cachedProbes[i] = (int) MurmurHash.hash64A(bytesForString(getName()), seed + i);    }}
protected int mahout_f4197_0(byte[] originalForm, int dataSize, String name, int probe)
{    int h = cachedProbes[probe] % dataSize;    if (h < 0) {        h += dataSize;    }    return h;}
public void mahout_f4198_0(byte[] originalForm, double weight, Vector data)
{    int probes = getProbes();    String name = getName();    for (int i = 0; i < probes; i++) {        int n = hashForProbe(originalForm, data.size(), name, i);        if (isTraceEnabled()) {            trace((String) null, n);        }        data.set(n, data.get(n) + getWeight(originalForm, weight));    }}
protected double mahout_f4199_0(byte[] originalForm, double w)
{    return w;}
public String mahout_f4200_0(String originalForm)
{    return getName();}
protected int mahout_f4201_0()
{    return 0;}
public void mahout_f4202_0(byte[] originalForm, double weight, Vector data)
{    int probes = getProbes();    String name = getName();    for (int i = 0; i < probes; i++) {        int n = hashForProbe(originalForm, data.size(), name, i);        if (isTraceEnabled()) {            trace((String) null, n);        }        data.set(n, data.get(n) + getWeight(originalForm, weight));    }}
protected double mahout_f4203_0(byte[] originalForm, double w)
{    if (originalForm == null) {        return w;    }    return w * Double.parseDouble(new String(originalForm, Charsets.UTF_8));}
public String mahout_f4204_0(String originalForm)
{    return getName() + ':' + originalForm;}
protected int mahout_f4205_0()
{    return CONTINUOUS_VALUE_HASH_SEED;}
public int mahout_f4206_0(String s)
{    if (!dict.containsKey(s)) {        dict.put(s, dict.size());    }    return dict.get(s);}
public List<String> mahout_f4207_0()
{        return new ArrayList<>(dict.keySet());}
public int mahout_f4208_0()
{    return dict.size();}
public static Dictionary mahout_f4209_0(Iterable<String> values)
{    Dictionary dict = new Dictionary();    for (String value : values) {        dict.intern(value);    }    return dict;}
public void mahout_f4210_0(String originalForm, Vector data)
{    addToVector(originalForm, 1.0, data);}
public void mahout_f4211_0(byte[] originalForm, Vector data)
{    addToVector(originalForm, 1.0, data);}
public void mahout_f4212_0(String originalForm, double weight, Vector data)
{    addToVector(bytesForString(originalForm), weight, data);}
protected Iterable<Integer> mahout_f4213_0(byte[] originalForm, int dataSize, String name, int probe)
{    return Collections.singletonList(hashForProbe(originalForm, dataSize, name, probe));}
protected double mahout_f4214_0(byte[] originalForm, double w)
{    return 1.0;}
protected int mahout_f4215_0(String term, int probe, int numFeatures)
{    long r = MurmurHash.hash64A(bytesForString(term), probe) % numFeatures;    if (r < 0) {        r += numFeatures;    }    return (int) r;}
protected static int mahout_f4216_0(byte[] term, int probe, int numFeatures)
{    long r = MurmurHash.hash64A(term, probe) % numFeatures;    if (r < 0) {        r += numFeatures;    }    return (int) r;}
protected static int mahout_f4217_0(String term1, String term2, int probe, int numFeatures)
{    long r = MurmurHash.hash64A(bytesForString(term1), probe);    r = MurmurHash.hash64A(bytesForString(term2), (int) r) % numFeatures;    if (r < 0) {        r += numFeatures;    }    return (int) r;}
protected int mahout_f4218_0(byte[] term1, byte[] term2, int probe, int numFeatures)
{    long r = MurmurHash.hash64A(term1, probe);    r = MurmurHash.hash64A(term2, (int) r) % numFeatures;    if (r < 0) {        r += numFeatures;    }    return (int) r;}
protected int mahout_f4219_0(String term1, String term2, String term3, String term4, int probe, int numFeatures)
{    long r = MurmurHash.hash64A(bytesForString(term1), probe);    r = MurmurHash.hash64A(bytesForString(term2), (int) r) % numFeatures;    r = MurmurHash.hash64A(bytesForString(term3), (int) r) % numFeatures;    r = MurmurHash.hash64A(bytesForString(term4), (int) r) % numFeatures;    if (r < 0) {        r += numFeatures;    }    return (int) r;}
public int mahout_f4220_0()
{    return probes;}
public void mahout_f4221_0(int probes)
{    this.probes = probes;}
public String mahout_f4222_0()
{    return name;}
protected boolean mahout_f4223_0()
{    return traceDictionary != null;}
protected void mahout_f4224_0(String subName, int n)
{    if (traceDictionary != null) {        String key = name;        if (subName != null) {            key = name + '=' + subName;        }        Set<Integer> trace = traceDictionary.get(key);        if (trace == null) {            trace = Sets.newHashSet(n);            traceDictionary.put(key, trace);        } else {            trace.add(n);        }    }}
protected void mahout_f4225_0(byte[] subName, int n)
{    trace(new String(subName, Charsets.UTF_8), n);}
public void mahout_f4226_0(Map<String, Set<Integer>> traceDictionary)
{    this.traceDictionary = traceDictionary;}
protected static byte[] mahout_f4227_0(String x)
{    return x == null ? EMPTY_ARRAY : x.getBytes(Charsets.UTF_8);}
public void mahout_f4228_0(String originalForm, double w, Vector data)
{    throw new UnsupportedOperationException("addToVector is not supported for InteractionVectorEncoder");}
public void mahout_f4229_0(byte[] originalForm, double w, Vector data)
{    throw new UnsupportedOperationException("addToVector is not supported for InteractionVectorEncoder");}
public void mahout_f4230_0(String original1, String original2, double weight, Vector data)
{    byte[] originalForm1 = bytesForString(original1);    byte[] originalForm2 = bytesForString(original2);    addInteractionToVector(originalForm1, originalForm2, weight, data);}
public void mahout_f4231_0(byte[] originalForm1, byte[] originalForm2, double weight, Vector data)
{    String name = getName();    double w = getWeight(originalForm1, originalForm2, weight);    for (int i = 0; i < probes(); i++) {        Iterable<Integer> jValues = secondEncoder.hashesForProbe(originalForm2, data.size(), name, i % secondEncoder.getProbes());        for (Integer k : firstEncoder.hashesForProbe(originalForm1, data.size(), name, i % firstEncoder.getProbes())) {            for (Integer j : jValues) {                int n = (k + j) % data.size();                if (isTraceEnabled()) {                    trace(String.format("%s:%s", new String(originalForm1, Charsets.UTF_8), new String(originalForm2, Charsets.UTF_8)), n);                }                data.set(n, data.get(n) + w);            }        }    }}
private int mahout_f4232_0()
{    return getProbes();}
protected double mahout_f4233_0(byte[] originalForm1, byte[] originalForm2, double w)
{    return firstEncoder.getWeight(originalForm1, 1.0) * secondEncoder.getWeight(originalForm2, 1.0) * w;}
public String mahout_f4234_0(String originalForm)
{    return String.format(Locale.ENGLISH, "%s:%s", getName(), originalForm);}
protected int mahout_f4235_0(byte[] originalForm, int dataSize, String name, int probe)
{    return hash(name, probe, dataSize);}
public void mahout_f4236_0(Analyzer analyzer)
{    this.analyzer = analyzer;}
protected Iterable<String> mahout_f4237_0(CharSequence originalForm)
{    TokenStream ts = analyzer.tokenStream(getName(), new CharSequenceReader(originalForm));    ts.addAttribute(CharTermAttribute.class);    return new LuceneTokenIterable(ts, false);}
public int mahout_f4238_0(char[] cbuf, int off, int len)
{    int toRead = Math.min(len, buf.remaining());    if (toRead > 0) {        buf.get(cbuf, off, toRead);        return toRead;    } else {        return -1;    }}
public void mahout_f4239_0()
{}
public Iterator<String> mahout_f4240_0()
{    if (firstTime) {        firstTime = false;    } else {        try {            tokenStream.reset();        } catch (IOException e) {            throw new IllegalStateException("This token stream can't be reset");        }    }    return new TokenStreamIterator(tokenStream);}
protected int mahout_f4241_0(byte[] originalForm, int dataSize, String name, int probe)
{    return hash(nameBytes, originalForm, WORD_LIKE_VALUE_HASH_SEED + probe, dataSize);}
public void mahout_f4242_0(Map<String, Double> dictionary)
{    this.dictionary = dictionary;    setMissingValueWeight(Collections.min(dictionary.values()) / 2);}
public void mahout_f4243_0(double missingValueWeight)
{    this.missingValueWeight = missingValueWeight;}
protected double mahout_f4244_0(byte[] originalForm)
{    double weight = missingValueWeight;    if (dictionary != null) {        String s = new String(originalForm, Charsets.UTF_8);        if (dictionary.containsKey(s)) {            weight = dictionary.get(s);        }    }    return weight;}
public void mahout_f4245_0(byte[] originalForm, double weight, Vector data)
{    addText(originalForm);    flush(weight, data);}
public void mahout_f4246_0(byte[] originalForm)
{    addText(new String(originalForm, Charsets.UTF_8));}
public void mahout_f4247_0(CharSequence text)
{    for (String word : tokenize(text)) {        counts.add(word);    }}
public void mahout_f4248_0(double weight, Vector data)
{    for (String word : counts.elementSet()) {                wordEncoder.addToVector(word, weight * Math.log1p(counts.count(word)) / LOG_2, data);    }    counts.clear();}
protected int mahout_f4249_0(byte[] originalForm, int dataSize, String name, int probe)
{    return 0;}
protected Iterable<Integer> mahout_f4250_0(byte[] originalForm, int dataSize, String name, int probe)
{    Collection<Integer> hashes = Lists.newArrayList();    for (String word : tokenize(new String(originalForm, Charsets.UTF_8))) {        hashes.add(hashForProbe(bytesForString(word), dataSize, name, probe));    }    return hashes;}
protected Iterable<String> mahout_f4251_0(CharSequence originalForm)
{    return ON_NON_WORD.split(originalForm);}
public String mahout_f4252_0(String originalForm)
{    StringBuilder r = new StringBuilder();    r.append('[');    for (String word : tokenize(originalForm)) {        if (r.length() > 1) {            r.append(", ");        }        r.append(wordEncoder.asString(word));    }    r.append(']');    return r.toString();}
public final void mahout_f4253_0(FeatureVectorEncoder wordEncoder)
{    this.wordEncoder = wordEncoder;}
public void mahout_f4254_0(byte[] originalForm, double w, Vector data)
{    int probes = getProbes();    String name = getName();    double weight = getWeight(originalForm, w);    for (int i = 0; i < probes; i++) {        int n = hashForProbe(originalForm, data.size(), name, i);        if (isTraceEnabled()) {            trace(originalForm, n);        }        data.set(n, data.get(n) + weight);    }}
protected double mahout_f4255_0(byte[] originalForm, double w)
{    return w * weight(originalForm);}
protected int mahout_f4256_0(byte[] originalForm, int dataSize, String name, int probe)
{    return hash(nameBytes, originalForm, WORD_LIKE_VALUE_HASH_SEED + probe, dataSize);}
public String mahout_f4257_0(String originalForm)
{    return String.format(Locale.ENGLISH, "%s:%s:%.4f", getName(), originalForm, weight(bytesForString(originalForm)));}
protected void mahout_f4258_0(Context context) throws IOException, InterruptedException
{    Configuration conf = context.getConfiguration();    sequentialVectors = conf.getBoolean(USE_SEQUENTIAL, false);    namedVectors = conf.getBoolean(USE_NAMED_VECTORS, false);    String analyzerName = conf.get(ANALYZER_NAME, StandardAnalyzer.class.getName());    Analyzer analyzer;    try {        analyzer = AnalyzerUtils.createAnalyzer(analyzerName);    } catch (ClassNotFoundException e) {                throw new IOException("Unable to create Analyzer for name: " + analyzerName, e);    }    String encoderName = conf.get(ENCODER_FIELD_NAME, "text");    cardinality = conf.getInt(CARDINALITY, 5000);    String encClass = conf.get(ENCODER_CLASS);    encoder = ClassUtils.instantiateAs(encClass, FeatureVectorEncoder.class, new Class[] { String.class }, new Object[] { encoderName });    if (encoder instanceof LuceneTextValueEncoder) {        ((LuceneTextValueEncoder) encoder).setAnalyzer(analyzer);    }}
protected void mahout_f4259_0(Text key, Text value, Context context) throws IOException, InterruptedException
{    Vector vector;    if (sequentialVectors) {        vector = new SequentialAccessSparseVector(cardinality);    } else {        vector = new RandomAccessSparseVector(cardinality);    }    if (namedVectors) {        vector = new NamedVector(vector, key.toString());    }    encoder.addToVector(value.toString(), vector);    context.write(new Text(key.toString()), new VectorWritable(vector));}
public static void mahout_f4260_0(Path tfDir, Path prunedTFDir, Path prunedPartialTFDir, long maxDF, long minDF, Configuration baseConf, Pair<Long[], List<Path>> docFrequenciesFeatures, float normPower, boolean logNormalize, int numReducers) throws IOException, InterruptedException, ClassNotFoundException
{    int partialVectorIndex = 0;    List<Path> partialVectorPaths = new ArrayList<>();    for (Path path : docFrequenciesFeatures.getSecond()) {        Path partialVectorOutputPath = new Path(prunedPartialTFDir, "partial-" + partialVectorIndex++);        partialVectorPaths.add(partialVectorOutputPath);        pruneVectorsPartial(tfDir, partialVectorOutputPath, path, maxDF, minDF, baseConf);    }    mergePartialVectors(partialVectorPaths, prunedTFDir, baseConf, normPower, logNormalize, numReducers);    HadoopUtil.delete(new Configuration(baseConf), prunedPartialTFDir);}
private static void mahout_f4261_0(Path input, Path output, Path dictionaryFilePath, long maxDF, long minDF, Configuration baseConf) throws IOException, InterruptedException, ClassNotFoundException
{    Configuration conf = new Configuration(baseConf);            conf.set("io.serializations", "org.apache.hadoop.io.serializer.JavaSerialization," + "org.apache.hadoop.io.serializer.WritableSerialization");    conf.setLong(MAX_DF, maxDF);    conf.setLong(MIN_DF, minDF);    DistributedCache.addCacheFile(dictionaryFilePath.toUri(), conf);    Job job = HadoopUtil.prepareJob(input, output, SequenceFileInputFormat.class, Mapper.class, null, null, WordsPrunerReducer.class, Text.class, VectorWritable.class, SequenceFileOutputFormat.class, conf);    job.setJobName(": Prune Vectors: input-folder: " + input + ", dictionary-file: " + dictionaryFilePath.toString());    HadoopUtil.delete(conf, output);    boolean succeeded = job.waitForCompletion(true);    if (!succeeded) {        throw new IllegalStateException("Job failed!");    }}
public static void mahout_f4262_0(Iterable<Path> partialVectorPaths, Path output, Configuration baseConf, float normPower, boolean logNormalize, int numReducers) throws IOException, InterruptedException, ClassNotFoundException
{    Configuration conf = new Configuration(baseConf);        conf.set("io.serializations", "org.apache.hadoop.io.serializer.JavaSerialization," + "org.apache.hadoop.io.serializer.WritableSerialization");    conf.setFloat(PartialVectorMerger.NORMALIZATION_POWER, normPower);    conf.setBoolean(PartialVectorMerger.LOG_NORMALIZE, logNormalize);    Job job = new Job(conf);    job.setJobName("PrunerPartialVectorMerger::MergePartialVectors");    job.setJarByClass(PartialVectorMerger.class);    job.setOutputKeyClass(Text.class);    job.setOutputValueClass(VectorWritable.class);    FileInputFormat.setInputPaths(job, getCommaSeparatedPaths(partialVectorPaths));    FileOutputFormat.setOutputPath(job, output);    job.setMapperClass(Mapper.class);    job.setInputFormatClass(SequenceFileInputFormat.class);    job.setReducerClass(PrunedPartialVectorMergeReducer.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    job.setNumReduceTasks(numReducers);    HadoopUtil.delete(conf, output);    boolean succeeded = job.waitForCompletion(true);    if (!succeeded) {        throw new IllegalStateException("Job failed!");    }}
private static String mahout_f4263_0(Iterable<Path> paths)
{    StringBuilder commaSeparatedPaths = new StringBuilder(100);    String sep = "";    for (Path path : paths) {        commaSeparatedPaths.append(sep).append(path.toString());        sep = ",";    }    return commaSeparatedPaths.toString();}
protected void mahout_f4264_0(WritableComparable<?> key, Iterable<VectorWritable> values, Context context) throws IOException, InterruptedException
{    Vector vector = null;    for (VectorWritable value : values) {        if (vector == null) {            vector = value.get().clone();            continue;        }                vector.assign(value.get(), Functions.PLUS);    }    if (vector != null && normPower != PartialVectorMerger.NO_NORMALIZING) {        vector = logNormalize ? vector.logNormalize(normPower) : vector.normalize(normPower);    }    VectorWritable vectorWritable = new VectorWritable(vector);    context.write(key, vectorWritable);}
protected void mahout_f4265_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    Configuration conf = context.getConfiguration();    normPower = conf.getFloat(PartialVectorMerger.NORMALIZATION_POWER, PartialVectorMerger.NO_NORMALIZING);    logNormalize = conf.getBoolean(PartialVectorMerger.LOG_NORMALIZE, false);}
protected void mahout_f4266_0(WritableComparable<?> key, Iterable<VectorWritable> values, Context context) throws IOException, InterruptedException
{    Iterator<VectorWritable> it = values.iterator();    if (!it.hasNext()) {        return;    }    Vector value = it.next().get();    Vector vector = value.clone();    if (maxDf != Long.MAX_VALUE || minDf > -1) {        for (Vector.Element e : value.nonZeroes()) {            if (!dictionary.containsKey(e.index())) {                vector.setQuick(e.index(), 0.0);                continue;            }            long df = dictionary.get(e.index());            if (df > maxDf || df < minDf) {                vector.setQuick(e.index(), 0.0);            }        }    }    VectorWritable vectorWritable = new VectorWritable(vector);    context.write(key, vectorWritable);}
protected void mahout_f4267_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    Configuration conf = context.getConfiguration();        maxDf = conf.getLong(HighDFWordsPruner.MAX_DF, Long.MAX_VALUE);    minDf = conf.getLong(HighDFWordsPruner.MIN_DF, -1);    Path dictionaryFile = HadoopUtil.getSingleCachedFile(conf);        for (Pair<IntWritable, LongWritable> record : new SequenceFileIterable<IntWritable, LongWritable>(dictionaryFile, true, conf)) {        dictionary.put(record.getFirst().get(), record.getSecond().get());    }}
public void mahout_f4268_1(Path input, Path output, VectorizerConfig config) throws IOException, ClassNotFoundException, InterruptedException
{        Job job = HadoopUtil.prepareJob(input, output, SequenceFileInputFormat.class, EncodingMapper.class, Text.class, VectorWritable.class, SequenceFileOutputFormat.class, config.getConf());    Configuration conf = job.getConfiguration();    conf.set(EncodingMapper.USE_SEQUENTIAL, String.valueOf(config.isSequentialAccess()));    conf.set(EncodingMapper.USE_NAMED_VECTORS, String.valueOf(config.isNamedVectors()));    conf.set(EncodingMapper.ANALYZER_NAME, config.getAnalyzerClassName());    conf.set(EncodingMapper.ENCODER_FIELD_NAME, config.getEncoderName());    conf.set(EncodingMapper.ENCODER_CLASS, config.getEncoderClass());    conf.set(EncodingMapper.CARDINALITY, String.valueOf(config.getCardinality()));    job.setNumReduceTasks(0);    boolean finished = job.waitForCompletion(true);        if (!finished) {        throw new IllegalStateException("Job failed!");    }}
public static void mahout_f4269_0(String[] args) throws Exception
{    ToolRunner.run(new SparseVectorsFromSequenceFiles(), args);}
public int mahout_f4270_1(String[] args) throws Exception
{    DefaultOptionBuilder obuilder = new DefaultOptionBuilder();    ArgumentBuilder abuilder = new ArgumentBuilder();    GroupBuilder gbuilder = new GroupBuilder();    Option inputDirOpt = DefaultOptionCreator.inputOption().create();    Option outputDirOpt = DefaultOptionCreator.outputOption().create();    Option minSupportOpt = obuilder.withLongName("minSupport").withArgument(abuilder.withName("minSupport").withMinimum(1).withMaximum(1).create()).withDescription("(Optional) Minimum Support. Default Value: 2").withShortName("s").create();    Option analyzerNameOpt = obuilder.withLongName("analyzerName").withArgument(abuilder.withName("analyzerName").withMinimum(1).withMaximum(1).create()).withDescription("The class name of the analyzer").withShortName("a").create();    Option chunkSizeOpt = obuilder.withLongName("chunkSize").withArgument(abuilder.withName("chunkSize").withMinimum(1).withMaximum(1).create()).withDescription("The chunkSize in MegaBytes. Default Value: 100MB").withShortName("chunk").create();    Option weightOpt = obuilder.withLongName("weight").withRequired(false).withArgument(abuilder.withName("weight").withMinimum(1).withMaximum(1).create()).withDescription("The kind of weight to use. Currently TF or TFIDF. Default: TFIDF").withShortName("wt").create();    Option minDFOpt = obuilder.withLongName("minDF").withRequired(false).withArgument(abuilder.withName("minDF").withMinimum(1).withMaximum(1).create()).withDescription("The minimum document frequency.  Default is 1").withShortName("md").create();    Option maxDFPercentOpt = obuilder.withLongName("maxDFPercent").withRequired(false).withArgument(abuilder.withName("maxDFPercent").withMinimum(1).withMaximum(1).create()).withDescription("The max percentage of docs for the DF.  Can be used to remove really high frequency terms." + " Expressed as an integer between 0 and 100. Default is 99.  If maxDFSigma is also set, " + "it will override this value.").withShortName("x").create();    Option maxDFSigmaOpt = obuilder.withLongName("maxDFSigma").withRequired(false).withArgument(abuilder.withName("maxDFSigma").withMinimum(1).withMaximum(1).create()).withDescription("What portion of the tf (tf-idf) vectors to be used, expressed in times the standard deviation (sigma) " + "of the document frequencies of these vectors. Can be used to remove really high frequency terms." + " Expressed as a double value. Good value to be specified is 3.0. In case the value is less " + "than 0 no vectors will be filtered out. Default is -1.0.  Overrides maxDFPercent").withShortName("xs").create();    Option minLLROpt = obuilder.withLongName("minLLR").withRequired(false).withArgument(abuilder.withName("minLLR").withMinimum(1).withMaximum(1).create()).withDescription("(Optional)The minimum Log Likelihood Ratio(Float)  Default is " + LLRReducer.DEFAULT_MIN_LLR).withShortName("ml").create();    Option numReduceTasksOpt = obuilder.withLongName("numReducers").withArgument(abuilder.withName("numReducers").withMinimum(1).withMaximum(1).create()).withDescription("(Optional) Number of reduce tasks. Default Value: 1").withShortName("nr").create();    Option powerOpt = obuilder.withLongName("norm").withRequired(false).withArgument(abuilder.withName("norm").withMinimum(1).withMaximum(1).create()).withDescription("The norm to use, expressed as either a float or \"INF\" if you want to use the Infinite norm.  " + "Must be greater or equal to 0.  The default is not to normalize").withShortName("n").create();    Option logNormalizeOpt = obuilder.withLongName("logNormalize").withRequired(false).withDescription("(Optional) Whether output vectors should be logNormalize. If set true else false").withShortName("lnorm").create();    Option maxNGramSizeOpt = obuilder.withLongName("maxNGramSize").withRequired(false).withArgument(abuilder.withName("ngramSize").withMinimum(1).withMaximum(1).create()).withDescription("(Optional) The maximum size of ngrams to create" + " (2 = bigrams, 3 = trigrams, etc) Default Value:1").withShortName("ng").create();    Option sequentialAccessVectorOpt = obuilder.withLongName("sequentialAccessVector").withRequired(false).withDescription("(Optional) Whether output vectors should be SequentialAccessVectors. If set true else false").withShortName("seq").create();    Option namedVectorOpt = obuilder.withLongName("namedVector").withRequired(false).withDescription("(Optional) Whether output vectors should be NamedVectors. If set true else false").withShortName("nv").create();    Option overwriteOutput = obuilder.withLongName("overwrite").withRequired(false).withDescription("If set, overwrite the output directory").withShortName("ow").create();    Option helpOpt = obuilder.withLongName("help").withDescription("Print out help").withShortName("h").create();    Group group = gbuilder.withName("Options").withOption(minSupportOpt).withOption(analyzerNameOpt).withOption(chunkSizeOpt).withOption(outputDirOpt).withOption(inputDirOpt).withOption(minDFOpt).withOption(maxDFSigmaOpt).withOption(maxDFPercentOpt).withOption(weightOpt).withOption(powerOpt).withOption(minLLROpt).withOption(numReduceTasksOpt).withOption(maxNGramSizeOpt).withOption(overwriteOutput).withOption(helpOpt).withOption(sequentialAccessVectorOpt).withOption(namedVectorOpt).withOption(logNormalizeOpt).create();    try {        Parser parser = new Parser();        parser.setGroup(group);        parser.setHelpOption(helpOpt);        CommandLine cmdLine = parser.parse(args);        if (cmdLine.hasOption(helpOpt)) {            CommandLineUtil.printHelp(group);            return -1;        }        Path inputDir = new Path((String) cmdLine.getValue(inputDirOpt));        Path outputDir = new Path((String) cmdLine.getValue(outputDirOpt));        int chunkSize = 100;        if (cmdLine.hasOption(chunkSizeOpt)) {            chunkSize = Integer.parseInt((String) cmdLine.getValue(chunkSizeOpt));        }        int minSupport = 2;        if (cmdLine.hasOption(minSupportOpt)) {            String minSupportString = (String) cmdLine.getValue(minSupportOpt);            minSupport = Integer.parseInt(minSupportString);        }        int maxNGramSize = 1;        if (cmdLine.hasOption(maxNGramSizeOpt)) {            try {                maxNGramSize = Integer.parseInt(cmdLine.getValue(maxNGramSizeOpt).toString());            } catch (NumberFormatException ex) {                            }        }                if (cmdLine.hasOption(overwriteOutput)) {            HadoopUtil.delete(getConf(), outputDir);        }        float minLLRValue = LLRReducer.DEFAULT_MIN_LLR;        if (cmdLine.hasOption(minLLROpt)) {            minLLRValue = Float.parseFloat(cmdLine.getValue(minLLROpt).toString());        }                int reduceTasks = 1;        if (cmdLine.hasOption(numReduceTasksOpt)) {            reduceTasks = Integer.parseInt(cmdLine.getValue(numReduceTasksOpt).toString());        }                Class<? extends Analyzer> analyzerClass = StandardAnalyzer.class;        if (cmdLine.hasOption(analyzerNameOpt)) {            String className = cmdLine.getValue(analyzerNameOpt).toString();            analyzerClass = Class.forName(className).asSubclass(Analyzer.class);                                    AnalyzerUtils.createAnalyzer(analyzerClass);        }        boolean processIdf;        if (cmdLine.hasOption(weightOpt)) {            String wString = cmdLine.getValue(weightOpt).toString();            if ("tf".equalsIgnoreCase(wString)) {                processIdf = false;            } else if ("tfidf".equalsIgnoreCase(wString)) {                processIdf = true;            } else {                throw new OptionException(weightOpt);            }        } else {            processIdf = true;        }        int minDf = 1;        if (cmdLine.hasOption(minDFOpt)) {            minDf = Integer.parseInt(cmdLine.getValue(minDFOpt).toString());        }        int maxDFPercent = 99;        if (cmdLine.hasOption(maxDFPercentOpt)) {            maxDFPercent = Integer.parseInt(cmdLine.getValue(maxDFPercentOpt).toString());        }        double maxDFSigma = -1.0;        if (cmdLine.hasOption(maxDFSigmaOpt)) {            maxDFSigma = Double.parseDouble(cmdLine.getValue(maxDFSigmaOpt).toString());        }        float norm = PartialVectorMerger.NO_NORMALIZING;        if (cmdLine.hasOption(powerOpt)) {            String power = cmdLine.getValue(powerOpt).toString();            if ("INF".equals(power)) {                norm = Float.POSITIVE_INFINITY;            } else {                norm = Float.parseFloat(power);            }        }        boolean logNormalize = false;        if (cmdLine.hasOption(logNormalizeOpt)) {            logNormalize = true;        }                Configuration conf = getConf();        Path tokenizedPath = new Path(outputDir, DocumentProcessor.TOKENIZED_DOCUMENT_OUTPUT_FOLDER);                        DocumentProcessor.tokenizeDocuments(inputDir, analyzerClass, tokenizedPath, conf);        boolean sequentialAccessOutput = false;        if (cmdLine.hasOption(sequentialAccessVectorOpt)) {            sequentialAccessOutput = true;        }        boolean namedVectors = false;        if (cmdLine.hasOption(namedVectorOpt)) {            namedVectors = true;        }        boolean shouldPrune = maxDFSigma >= 0.0 || maxDFPercent > 0.00;        String tfDirName = shouldPrune ? DictionaryVectorizer.DOCUMENT_VECTOR_OUTPUT_FOLDER + "-toprune" : DictionaryVectorizer.DOCUMENT_VECTOR_OUTPUT_FOLDER;                if (processIdf) {            DictionaryVectorizer.createTermFrequencyVectors(tokenizedPath, outputDir, tfDirName, conf, minSupport, maxNGramSize, minLLRValue, -1.0f, false, reduceTasks, chunkSize, sequentialAccessOutput, namedVectors);        } else {            DictionaryVectorizer.createTermFrequencyVectors(tokenizedPath, outputDir, tfDirName, conf, minSupport, maxNGramSize, minLLRValue, norm, logNormalize, reduceTasks, chunkSize, sequentialAccessOutput, namedVectors);        }        Pair<Long[], List<Path>> docFrequenciesFeatures = null;                if (shouldPrune || processIdf) {                        docFrequenciesFeatures = TFIDFConverter.calculateDF(new Path(outputDir, tfDirName), outputDir, conf, chunkSize);        }                long maxDF = maxDFPercent;        if (shouldPrune) {            long vectorCount = docFrequenciesFeatures.getFirst()[1];            if (maxDFSigma >= 0.0) {                Path dfDir = new Path(outputDir, TFIDFConverter.WORDCOUNT_OUTPUT_FOLDER);                Path stdCalcDir = new Path(outputDir, HighDFWordsPruner.STD_CALC_DIR);                                double stdDev = BasicStats.stdDevForGivenMean(dfDir, stdCalcDir, 0.0, conf);                maxDF = (int) (100.0 * maxDFSigma * stdDev / vectorCount);            }            long maxDFThreshold = (long) (vectorCount * (maxDF / 100.0f));                        Path tfDir = new Path(outputDir, tfDirName);            Path prunedTFDir = new Path(outputDir, DictionaryVectorizer.DOCUMENT_VECTOR_OUTPUT_FOLDER);            Path prunedPartialTFDir = new Path(outputDir, DictionaryVectorizer.DOCUMENT_VECTOR_OUTPUT_FOLDER + "-partial");                        if (processIdf) {                HighDFWordsPruner.pruneVectors(tfDir, prunedTFDir, prunedPartialTFDir, maxDFThreshold, minDf, conf, docFrequenciesFeatures, -1.0f, false, reduceTasks);            } else {                HighDFWordsPruner.pruneVectors(tfDir, prunedTFDir, prunedPartialTFDir, maxDFThreshold, minDf, conf, docFrequenciesFeatures, norm, logNormalize, reduceTasks);            }            HadoopUtil.delete(new Configuration(conf), tfDir);        }        if (processIdf) {            TFIDFConverter.processTfIdf(new Path(outputDir, DictionaryVectorizer.DOCUMENT_VECTOR_OUTPUT_FOLDER), outputDir, conf, docFrequenciesFeatures, minDf, maxDF, norm, logNormalize, sequentialAccessOutput, namedVectors, reduceTasks);        }    } catch (OptionException e) {                CommandLineUtil.printHelp(group);    }    return 0;}
protected void mahout_f4271_0(Text key, Iterable<LongWritable> values, Context context) throws IOException, InterruptedException
{    long sum = 0;    for (LongWritable value : values) {        sum += value.get();    }    context.write(key, new LongWritable(sum));}
protected void mahout_f4272_0(Text key, StringTuple value, final Context context) throws IOException, InterruptedException
{    OpenObjectLongHashMap<String> wordCount = new OpenObjectLongHashMap<>();    for (String word : value.getEntries()) {        if (wordCount.containsKey(word)) {            wordCount.put(word, wordCount.get(word) + 1);        } else {            wordCount.put(word, 1);        }    }    wordCount.forEachPair(new ObjectLongProcedure<String>() {        @Override        public boolean apply(String first, long second) {            try {                context.write(new Text(first), new LongWritable(second));            } catch (IOException e) {                context.getCounter("Exception", "Output IO Exception").increment(1);            } catch (InterruptedException e) {                context.getCounter("Exception", "Interrupted Exception").increment(1);            }            return true;        }    });}
public boolean mahout_f4273_0(String first, long second)
{    try {        context.write(new Text(first), new LongWritable(second));    } catch (IOException e) {        context.getCounter("Exception", "Output IO Exception").increment(1);    } catch (InterruptedException e) {        context.getCounter("Exception", "Interrupted Exception").increment(1);    }    return true;}
protected void mahout_f4274_0(Text key, Iterable<LongWritable> values, Context context) throws IOException, InterruptedException
{    long sum = 0;    for (LongWritable value : values) {        sum += value.get();    }    if (sum >= minSupport) {        context.write(key, new LongWritable(sum));    }}
protected void mahout_f4275_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    minSupport = context.getConfiguration().getInt(DictionaryVectorizer.MIN_SUPPORT, DictionaryVectorizer.DEFAULT_MIN_SUPPORT);}
protected void mahout_f4276_0(WritableComparable<?> key, VectorWritable value, Context context) throws IOException, InterruptedException
{    Vector vector = value.get();    for (Vector.Element e : vector.nonZeroes()) {        out.set(e.index());        context.write(out, ONE);    }    context.write(TOTAL_COUNT, ONE);}
protected void mahout_f4277_0(IntWritable key, Iterable<LongWritable> values, Context context) throws IOException, InterruptedException
{    long sum = 0;    for (LongWritable value : values) {        sum += value.get();    }    context.write(key, new LongWritable(sum));}
protected void mahout_f4278_0(Text key, Iterable<StringTuple> values, Context context) throws IOException, InterruptedException
{    Iterator<StringTuple> it = values.iterator();    if (!it.hasNext()) {        return;    }    List<String> value = Lists.newArrayList();    while (it.hasNext()) {        value.addAll(it.next().getEntries());    }        Vector vector = new RandomAccessSparseVector(dimension, value.size());    if (maxNGramSize >= 2) {        ShingleFilter sf = new ShingleFilter(new IteratorTokenStream(value.iterator()), maxNGramSize);        sf.reset();        try {            do {                String term = sf.getAttribute(CharTermAttribute.class).toString();                if (!term.isEmpty() && dictionary.containsKey(term)) {                                        int termId = dictionary.get(term);                    vector.setQuick(termId, vector.getQuick(termId) + 1);                }            } while (sf.incrementToken());            sf.end();        } finally {            Closeables.close(sf, true);        }    } else {        for (String term : value) {            if (!term.isEmpty() && dictionary.containsKey(term)) {                                int termId = dictionary.get(term);                vector.setQuick(termId, vector.getQuick(termId) + 1);            }        }    }    if (sequentialAccess) {        vector = new SequentialAccessSparseVector(vector);    }    if (namedVector) {        vector = new NamedVector(vector, key.toString());    }        if (vector.getNumNondefaultElements() > 0) {        VectorWritable vectorWritable = new VectorWritable(vector);        context.write(key, vectorWritable);    } else {        context.getCounter("TFPartialVectorReducer", "emptyVectorCount").increment(1);    }}
protected void mahout_f4279_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    Configuration conf = context.getConfiguration();    dimension = conf.getInt(PartialVectorMerger.DIMENSION, Integer.MAX_VALUE);    sequentialAccess = conf.getBoolean(PartialVectorMerger.SEQUENTIAL_ACCESS, false);    namedVector = conf.getBoolean(PartialVectorMerger.NAMED_VECTOR, false);    maxNGramSize = conf.getInt(DictionaryVectorizer.MAX_NGRAMS, maxNGramSize);    URI[] localFiles = DistributedCache.getCacheFiles(conf);    Path dictionaryFile = HadoopUtil.findInCacheByPartOfFilename(DictionaryVectorizer.DICTIONARY_FILE, localFiles);        for (Pair<Writable, IntWritable> record : new SequenceFileIterable<Writable, IntWritable>(dictionaryFile, true, conf)) {        dictionary.put(record.getFirst().toString(), record.getSecond().get());    }}
public double mahout_f4280_0(int tf, int df, int length, int numDocs)
{        return tf;}
public static void mahout_f4281_0(Path input, Path output, Configuration baseConf, Pair<Long[], List<Path>> datasetFeatures, int minDf, long maxDF, float normPower, boolean logNormalize, boolean sequentialAccessOutput, boolean namedVector, int numReducers) throws IOException, InterruptedException, ClassNotFoundException
{    Preconditions.checkArgument(normPower == PartialVectorMerger.NO_NORMALIZING || normPower >= 0, "If specified normPower must be nonnegative", normPower);    Preconditions.checkArgument(normPower == PartialVectorMerger.NO_NORMALIZING || (normPower > 1 && !Double.isInfinite(normPower)) || !logNormalize, "normPower must be > 1 and not infinite if log normalization is chosen", normPower);    int partialVectorIndex = 0;    List<Path> partialVectorPaths = Lists.newArrayList();    List<Path> dictionaryChunks = datasetFeatures.getSecond();    for (Path dictionaryChunk : dictionaryChunks) {        Path partialVectorOutputPath = new Path(output, VECTOR_OUTPUT_FOLDER + partialVectorIndex++);        partialVectorPaths.add(partialVectorOutputPath);        makePartialVectors(input, baseConf, datasetFeatures.getFirst()[0], datasetFeatures.getFirst()[1], minDf, maxDF, dictionaryChunk, partialVectorOutputPath, sequentialAccessOutput, namedVector);    }    Configuration conf = new Configuration(baseConf);    Path outputDir = new Path(output, DOCUMENT_VECTOR_OUTPUT_FOLDER);    PartialVectorMerger.mergePartialVectors(partialVectorPaths, outputDir, baseConf, normPower, logNormalize, datasetFeatures.getFirst()[0].intValue(), sequentialAccessOutput, namedVector, numReducers);    HadoopUtil.delete(conf, partialVectorPaths);}
public static Pair<Long[], List<Path>> mahout_f4282_0(Path input, Path output, Configuration baseConf, int chunkSizeInMegabytes) throws IOException, InterruptedException, ClassNotFoundException
{    if (chunkSizeInMegabytes < MIN_CHUNKSIZE) {        chunkSizeInMegabytes = MIN_CHUNKSIZE;    } else if (chunkSizeInMegabytes > MAX_CHUNKSIZE) {                chunkSizeInMegabytes = MAX_CHUNKSIZE;    }    Path wordCountPath = new Path(output, WORDCOUNT_OUTPUT_FOLDER);    startDFCounting(input, wordCountPath, baseConf);    return createDictionaryChunks(wordCountPath, output, baseConf, chunkSizeInMegabytes);}
private static Pair<Long[], List<Path>> mahout_f4283_0(Path featureCountPath, Path dictionaryPathBase, Configuration baseConf, int chunkSizeInMegabytes) throws IOException
{    List<Path> chunkPaths = Lists.newArrayList();    Configuration conf = new Configuration(baseConf);    FileSystem fs = FileSystem.get(featureCountPath.toUri(), conf);    long chunkSizeLimit = chunkSizeInMegabytes * 1024L * 1024L;    int chunkIndex = 0;    Path chunkPath = new Path(dictionaryPathBase, FREQUENCY_FILE + chunkIndex);    chunkPaths.add(chunkPath);    SequenceFile.Writer freqWriter = new SequenceFile.Writer(fs, conf, chunkPath, IntWritable.class, LongWritable.class);    try {        long currentChunkSize = 0;        long featureCount = 0;        long vectorCount = Long.MAX_VALUE;        Path filesPattern = new Path(featureCountPath, OUTPUT_FILES_PATTERN);        for (Pair<IntWritable, LongWritable> record : new SequenceFileDirIterable<IntWritable, LongWritable>(filesPattern, PathType.GLOB, null, null, true, conf)) {            if (currentChunkSize > chunkSizeLimit) {                Closeables.close(freqWriter, false);                chunkIndex++;                chunkPath = new Path(dictionaryPathBase, FREQUENCY_FILE + chunkIndex);                chunkPaths.add(chunkPath);                freqWriter = new SequenceFile.Writer(fs, conf, chunkPath, IntWritable.class, LongWritable.class);                currentChunkSize = 0;            }            int fieldSize = SEQUENCEFILE_BYTE_OVERHEAD + Integer.SIZE / 8 + Long.SIZE / 8;            currentChunkSize += fieldSize;            IntWritable key = record.getFirst();            LongWritable value = record.getSecond();            if (key.get() >= 0) {                freqWriter.append(key, value);            } else if (key.get() == -1) {                vectorCount = value.get();            }            featureCount = Math.max(key.get(), featureCount);        }        featureCount++;        Long[] counts = { featureCount, vectorCount };        return new Pair<>(counts, chunkPaths);    } finally {        Closeables.close(freqWriter, false);    }}
private static void mahout_f4284_0(Path input, Configuration baseConf, Long featureCount, Long vectorCount, int minDf, long maxDF, Path dictionaryFilePath, Path output, boolean sequentialAccess, boolean namedVector) throws IOException, InterruptedException, ClassNotFoundException
{    Configuration conf = new Configuration(baseConf);        conf.set("io.serializations", "org.apache.hadoop.io.serializer.JavaSerialization," + "org.apache.hadoop.io.serializer.WritableSerialization");    conf.setLong(FEATURE_COUNT, featureCount);    conf.setLong(VECTOR_COUNT, vectorCount);    conf.setInt(MIN_DF, minDf);    conf.setLong(MAX_DF, maxDF);    conf.setBoolean(PartialVectorMerger.SEQUENTIAL_ACCESS, sequentialAccess);    conf.setBoolean(PartialVectorMerger.NAMED_VECTOR, namedVector);    DistributedCache.addCacheFile(dictionaryFilePath.toUri(), conf);    Job job = new Job(conf);    job.setJobName(": MakePartialVectors: input-folder: " + input + ", dictionary-file: " + dictionaryFilePath.toString());    job.setJarByClass(TFIDFConverter.class);    job.setOutputKeyClass(Text.class);    job.setOutputValueClass(VectorWritable.class);    FileInputFormat.setInputPaths(job, input);    FileOutputFormat.setOutputPath(job, output);    job.setMapperClass(Mapper.class);    job.setInputFormatClass(SequenceFileInputFormat.class);    job.setReducerClass(TFIDFPartialVectorReducer.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    HadoopUtil.delete(conf, output);    boolean succeeded = job.waitForCompletion(true);    if (!succeeded) {        throw new IllegalStateException("Job failed!");    }}
private static void mahout_f4285_0(Path input, Path output, Configuration baseConf) throws IOException, InterruptedException, ClassNotFoundException
{    Configuration conf = new Configuration(baseConf);        conf.set("io.serializations", "org.apache.hadoop.io.serializer.JavaSerialization," + "org.apache.hadoop.io.serializer.WritableSerialization");    Job job = new Job(conf);    job.setJobName("VectorTfIdf Document Frequency Count running over input: " + input);    job.setJarByClass(TFIDFConverter.class);    job.setOutputKeyClass(IntWritable.class);    job.setOutputValueClass(LongWritable.class);    FileInputFormat.setInputPaths(job, input);    FileOutputFormat.setOutputPath(job, output);    job.setMapperClass(TermDocumentCountMapper.class);    job.setInputFormatClass(SequenceFileInputFormat.class);    job.setCombinerClass(TermDocumentCountReducer.class);    job.setReducerClass(TermDocumentCountReducer.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    HadoopUtil.delete(conf, output);    boolean succeeded = job.waitForCompletion(true);    if (!succeeded) {        throw new IllegalStateException("Job failed!");    }}
protected void mahout_f4286_0(WritableComparable<?> key, Iterable<VectorWritable> values, Context context) throws IOException, InterruptedException
{    Iterator<VectorWritable> it = values.iterator();    if (!it.hasNext()) {        return;    }    Vector value = it.next().get();    Vector vector = new RandomAccessSparseVector((int) featureCount, value.getNumNondefaultElements());    for (Vector.Element e : value.nonZeroes()) {        if (!dictionary.containsKey(e.index())) {            continue;        }        long df = dictionary.get(e.index());        if (maxDf > -1 && (100.0 * df) / vectorCount > maxDf) {            continue;        }        if (df < minDf) {            df = minDf;        }        vector.setQuick(e.index(), tfidf.calculate((int) e.get(), (int) df, (int) featureCount, (int) vectorCount));    }    if (sequentialAccess) {        vector = new SequentialAccessSparseVector(vector);    }    if (namedVector) {        vector = new NamedVector(vector, key.toString());    }    VectorWritable vectorWritable = new VectorWritable(vector);    context.write(key, vectorWritable);}
protected void mahout_f4287_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    Configuration conf = context.getConfiguration();    vectorCount = conf.getLong(TFIDFConverter.VECTOR_COUNT, 1);    featureCount = conf.getLong(TFIDFConverter.FEATURE_COUNT, 1);    minDf = conf.getInt(TFIDFConverter.MIN_DF, 1);    maxDf = conf.getLong(TFIDFConverter.MAX_DF, -1);    sequentialAccess = conf.getBoolean(PartialVectorMerger.SEQUENTIAL_ACCESS, false);    namedVector = conf.getBoolean(PartialVectorMerger.NAMED_VECTOR, false);    URI[] localFiles = DistributedCache.getCacheFiles(conf);    Path dictionaryFile = HadoopUtil.findInCacheByPartOfFilename(TFIDFConverter.FREQUENCY_FILE, localFiles);        for (Pair<IntWritable, LongWritable> record : new SequenceFileIterable<IntWritable, LongWritable>(dictionaryFile, true, conf)) {        dictionary.put(record.getFirst().get(), record.getSecond().get());    }}
public double mahout_f4288_0(int tf, int df, int length, int numDocs)
{        return sim.tf(tf) * sim.idf(df, numDocs);}
public Configuration mahout_f4289_0()
{    return conf;}
public void mahout_f4290_0(Configuration conf)
{    this.conf = conf;}
public String mahout_f4291_0()
{    return analyzerClassName;}
public void mahout_f4292_0(String analyzerClassName)
{    this.analyzerClassName = analyzerClassName;}
public String mahout_f4293_0()
{    return encoderName;}
public void mahout_f4294_0(String encoderName)
{    this.encoderName = encoderName;}
public boolean mahout_f4295_0()
{    return sequentialAccess;}
public void mahout_f4296_0(boolean sequentialAccess)
{    this.sequentialAccess = sequentialAccess;}
public String mahout_f4297_0()
{    return tfDirName;}
public void mahout_f4298_0(String tfDirName)
{    this.tfDirName = tfDirName;}
public boolean mahout_f4299_0()
{    return namedVectors;}
public void mahout_f4300_0(boolean namedVectors)
{    this.namedVectors = namedVectors;}
public int mahout_f4301_0()
{    return cardinality;}
public void mahout_f4302_0(int cardinality)
{    this.cardinality = cardinality;}
public String mahout_f4303_0()
{    return encoderClass;}
public void mahout_f4304_0(String encoderClass)
{    this.encoderClass = encoderClass;}
public int mahout_f4305_0()
{    return minSupport;}
public void mahout_f4306_0(int minSupport)
{    this.minSupport = minSupport;}
public int mahout_f4307_0()
{    return maxNGramSize;}
public void mahout_f4308_0(int maxNGramSize)
{    this.maxNGramSize = maxNGramSize;}
public float mahout_f4309_0()
{    return minLLRValue;}
public void mahout_f4310_0(float minLLRValue)
{    this.minLLRValue = minLLRValue;}
public float mahout_f4311_0()
{    return normPower;}
public void mahout_f4312_0(float normPower)
{    this.normPower = normPower;}
public boolean mahout_f4313_0()
{    return logNormalize;}
public void mahout_f4314_0(boolean logNormalize)
{    this.logNormalize = logNormalize;}
public int mahout_f4315_0()
{    return numReducers;}
public void mahout_f4316_0(int numReducers)
{    this.numReducers = numReducers;}
public int mahout_f4317_0()
{    return chunkSizeInMegabytes;}
public void mahout_f4318_0(int chunkSizeInMegabytes)
{    this.chunkSizeInMegabytes = chunkSizeInMegabytes;}
public static String mahout_f4319_0()
{    return Version.class.getPackage().getImplementationVersion();}
public static String mahout_f4320_0() throws IOException
{    return Resources.toString(Resources.getResource("version"), Charsets.UTF_8);}
public static void mahout_f4321_0(String[] args) throws IOException
{    System.out.println(version() + ' ' + versionFromResource());}
public void mahout_f4322_0()
{        TasteException te1 = new TasteException();    TasteException te2 = new TasteException(te1);    TasteException te3 = new TasteException(te2.toString(), te2);    TasteException te4 = new TasteException(te3.toString());    te4.printStackTrace(new PrintStream(new ByteArrayOutputStream()));    te4.printStackTrace(new PrintWriter(new OutputStreamWriter(new ByteArrayOutputStream())));}
public void mahout_f4323_0()
{        TasteException te1 = new NoSuchUserException();    TasteException te4 = new NoSuchUserException(te1.toString());    te4.printStackTrace(new PrintStream(new ByteArrayOutputStream()));    te4.printStackTrace(new PrintWriter(new OutputStreamWriter(new ByteArrayOutputStream())));}
public void mahout_f4324_0()
{        TasteException te1 = new NoSuchItemException();    TasteException te4 = new NoSuchItemException(te1.toString());    te4.printStackTrace(new PrintStream(new ByteArrayOutputStream()));    te4.printStackTrace(new PrintWriter(new OutputStreamWriter(new ByteArrayOutputStream())));}
public void mahout_f4325_0() throws Exception
{    super.setUp();    inputFile = getTestTempFile("prefs.txt");    intermediateDir = getTestTempDir("intermediate");    intermediateDir.delete();    outputDir = getTestTempDir("output");    outputDir.delete();    tmpDir = getTestTempDir("tmp");    conf = getConfiguration();        SharingMapper.reset();}
public void mahout_f4326_0() throws Exception
{    explicitExample(1);}
public void mahout_f4327_0() throws Exception
{    explicitExample(2);}
private void mahout_f4328_1(int numThreads) throws Exception
{    Double na = Double.NaN;    Matrix preferences = new SparseRowMatrix(4, 4, new Vector[] { new DenseVector(new double[] { 5.0, 5.0, 2.0, na }), new DenseVector(new double[] { 2.0, na, 3.0, 5.0 }), new DenseVector(new double[] { na, 5.0, na, 3.0 }), new DenseVector(new double[] { 3.0, na, na, 5.0 }) });    writeLines(inputFile, preferencesAsText(preferences));    ParallelALSFactorizationJob alsFactorization = new ParallelALSFactorizationJob();    alsFactorization.setConf(conf);    int numFeatures = 3;    int numIterations = 5;    double lambda = 0.065;    alsFactorization.run(new String[] { "--input", inputFile.getAbsolutePath(), "--output", outputDir.getAbsolutePath(), "--tempDir", tmpDir.getAbsolutePath(), "--lambda", String.valueOf(lambda), "--numFeatures", String.valueOf(numFeatures), "--numIterations", String.valueOf(numIterations), "--numThreadsPerSolver", String.valueOf(numThreads) });    Matrix u = MathHelper.readMatrix(conf, new Path(outputDir.getAbsolutePath(), "U/part-m-00000"), preferences.numRows(), numFeatures);    Matrix m = MathHelper.readMatrix(conf, new Path(outputDir.getAbsolutePath(), "M/part-m-00000"), preferences.numCols(), numFeatures);    StringBuilder info = new StringBuilder();    info.append("\nA - users x items\n\n");    info.append(MathHelper.nice(preferences));    info.append("\nU - users x features\n\n");    info.append(MathHelper.nice(u));    info.append("\nM - items x features\n\n");    info.append(MathHelper.nice(m));    Matrix Ak = u.times(m.transpose());    info.append("\nAk - users x items\n\n");    info.append(MathHelper.nice(Ak));    info.append('\n');        RunningAverage avg = new FullRunningAverage();    for (MatrixSlice slice : preferences) {        for (Element e : slice.nonZeroes()) {            if (!Double.isNaN(e.get())) {                double pref = e.get();                double estimate = u.viewRow(slice.index()).dot(m.viewRow(e.index()));                double err = pref - estimate;                avg.addDatum(err * err);                            }        }    }    double rmse = Math.sqrt(avg.getAverage());        assertTrue(rmse < 0.2);}
public void mahout_f4329_0() throws Exception
{    implicitExample(1);}
public void mahout_f4330_0() throws Exception
{    implicitExample(2);}
public void mahout_f4331_1(int numThreads) throws Exception
{    Matrix observations = new SparseRowMatrix(4, 4, new Vector[] { new DenseVector(new double[] { 5.0, 5.0, 2.0, 0 }), new DenseVector(new double[] { 2.0, 0, 3.0, 5.0 }), new DenseVector(new double[] { 0, 5.0, 0, 3.0 }), new DenseVector(new double[] { 3.0, 0, 0, 5.0 }) });    Matrix preferences = new SparseRowMatrix(4, 4, new Vector[] { new DenseVector(new double[] { 1.0, 1.0, 1.0, 0 }), new DenseVector(new double[] { 1.0, 0, 1.0, 1.0 }), new DenseVector(new double[] { 0, 1.0, 0, 1.0 }), new DenseVector(new double[] { 1.0, 0, 0, 1.0 }) });    writeLines(inputFile, preferencesAsText(observations));    ParallelALSFactorizationJob alsFactorization = new ParallelALSFactorizationJob();    alsFactorization.setConf(conf);    int numFeatures = 3;    int numIterations = 5;    double lambda = 0.065;    double alpha = 20;    alsFactorization.run(new String[] { "--input", inputFile.getAbsolutePath(), "--output", outputDir.getAbsolutePath(), "--tempDir", tmpDir.getAbsolutePath(), "--lambda", String.valueOf(lambda), "--implicitFeedback", String.valueOf(true), "--alpha", String.valueOf(alpha), "--numFeatures", String.valueOf(numFeatures), "--numIterations", String.valueOf(numIterations), "--numThreadsPerSolver", String.valueOf(numThreads) });    Matrix u = MathHelper.readMatrix(conf, new Path(outputDir.getAbsolutePath(), "U/part-m-00000"), observations.numRows(), numFeatures);    Matrix m = MathHelper.readMatrix(conf, new Path(outputDir.getAbsolutePath(), "M/part-m-00000"), observations.numCols(), numFeatures);    StringBuilder info = new StringBuilder();    info.append("\nObservations - users x items\n");    info.append(MathHelper.nice(observations));    info.append("\nA - users x items\n\n");    info.append(MathHelper.nice(preferences));    info.append("\nU - users x features\n\n");    info.append(MathHelper.nice(u));    info.append("\nM - items x features\n\n");    info.append(MathHelper.nice(m));    Matrix Ak = u.times(m.transpose());    info.append("\nAk - users x items\n\n");    info.append(MathHelper.nice(Ak));    info.append('\n');        RunningAverage avg = new FullRunningAverage();    for (MatrixSlice slice : preferences) {        for (Element e : slice.nonZeroes()) {            if (!Double.isNaN(e.get())) {                double pref = e.get();                double estimate = u.viewRow(slice.index()).dot(m.viewRow(e.index()));                double confidence = 1 + alpha * observations.getQuick(slice.index(), e.index());                double err = confidence * (pref - estimate) * (pref - estimate);                avg.addDatum(err);                            }        }    }    double rmse = Math.sqrt(avg.getAverage());        assertTrue(rmse < 0.4);}
public void mahout_f4332_1() throws Exception
{    String[] preferencesWithLongIDs = { "5568227754922264005,-4758971626494767444,5.0", "5568227754922264005,3688396615879561990,5.0", "5568227754922264005,4594226737871995304,2.0", "550945997885173934,-4758971626494767444,2.0", "550945997885173934,4594226737871995304,3.0", "550945997885173934,706816485922781596,5.0", "2448095297482319463,3688396615879561990,5.0", "2448095297482319463,706816485922781596,3.0", "6839920411763636962,-4758971626494767444,3.0", "6839920411763636962,706816485922781596,5.0" };    writeLines(inputFile, preferencesWithLongIDs);    ParallelALSFactorizationJob alsFactorization = new ParallelALSFactorizationJob();    alsFactorization.setConf(conf);    int numFeatures = 3;    int numIterations = 5;    double lambda = 0.065;    alsFactorization.run(new String[] { "--input", inputFile.getAbsolutePath(), "--output", outputDir.getAbsolutePath(), "--tempDir", tmpDir.getAbsolutePath(), "--lambda", String.valueOf(lambda), "--numFeatures", String.valueOf(numFeatures), "--numIterations", String.valueOf(numIterations), "--numThreadsPerSolver", String.valueOf(1), "--usesLongIDs", String.valueOf(true) });    OpenIntLongHashMap userIDIndex = TasteHadoopUtils.readIDIndexMap(outputDir.getAbsolutePath() + "/userIDIndex/part-r-00000", conf);    assertEquals(4, userIDIndex.size());    OpenIntLongHashMap itemIDIndex = TasteHadoopUtils.readIDIndexMap(outputDir.getAbsolutePath() + "/itemIDIndex/part-r-00000", conf);    assertEquals(4, itemIDIndex.size());    OpenIntObjectHashMap<Vector> u = MathHelper.readMatrixRows(conf, new Path(outputDir.getAbsolutePath(), "U/part-m-00000"));    OpenIntObjectHashMap<Vector> m = MathHelper.readMatrixRows(conf, new Path(outputDir.getAbsolutePath(), "M/part-m-00000"));    assertEquals(4, u.size());    assertEquals(4, m.size());    RunningAverage avg = new FullRunningAverage();    for (String line : preferencesWithLongIDs) {        String[] tokens = TasteHadoopUtils.splitPrefTokens(line);        long userID = Long.parseLong(tokens[TasteHadoopUtils.USER_ID_POS]);        long itemID = Long.parseLong(tokens[TasteHadoopUtils.ITEM_ID_POS]);        double rating = Double.parseDouble(tokens[2]);        Vector userFeatures = u.get(TasteHadoopUtils.idToIndex(userID));        Vector itemFeatures = m.get(TasteHadoopUtils.idToIndex(itemID));        double estimate = userFeatures.dot(itemFeatures);        double err = rating - estimate;        avg.addDatum(err * err);    }    double rmse = Math.sqrt(avg.getAverage());        assertTrue(rmse < 0.2);}
protected static String mahout_f4333_0(Matrix preferences)
{    StringBuilder prefsAsText = new StringBuilder();    String separator = "";    for (MatrixSlice slice : preferences) {        for (Element e : slice.nonZeroes()) {            if (!Double.isNaN(e.get())) {                prefsAsText.append(separator).append(slice.index()).append(',').append(e.index()).append(',').append(e.get());                separator = "\n";            }        }    }    System.out.println(prefsAsText.toString());    return prefsAsText.toString();}
public void mahout_f4334_0() throws Exception
{    String[] preferencesWithLongIDs = { "5568227754922264005,-4758971626494767444,5.0", "5568227754922264005,3688396615879561990,5.0", "5568227754922264005,4594226737871995304,2.0", "550945997885173934,-4758971626494767444,2.0", "550945997885173934,4594226737871995304,3.0", "550945997885173934,706816485922781596,5.0", "2448095297482319463,3688396615879561990,5.0", "2448095297482319463,706816485922781596,3.0", "6839920411763636962,-4758971626494767444,3.0", "6839920411763636962,706816485922781596,5.0" };    writeLines(inputFile, preferencesWithLongIDs);    ParallelALSFactorizationJob alsFactorization = new ParallelALSFactorizationJob();    alsFactorization.setConf(conf);    int numFeatures = 3;    int numIterations = 5;    double lambda = 0.065;    Configuration conf = getConfiguration();    int success = ToolRunner.run(alsFactorization, new String[] { "-Dhadoop.tmp.dir=" + conf.get("hadoop.tmp.dir"), "--input", inputFile.getAbsolutePath(), "--output", intermediateDir.getAbsolutePath(), "--tempDir", tmpDir.getAbsolutePath(), "--lambda", String.valueOf(lambda), "--numFeatures", String.valueOf(numFeatures), "--numIterations", String.valueOf(numIterations), "--numThreadsPerSolver", String.valueOf(1), "--usesLongIDs", String.valueOf(true) });    assertEquals(0, success);        SharingMapper.reset();    RecommenderJob recommender = new RecommenderJob();    success = ToolRunner.run(recommender, new String[] { "-Dhadoop.tmp.dir=" + conf.get("hadoop.tmp.dir"), "--input", intermediateDir.getAbsolutePath() + "/userRatings/", "--userFeatures", intermediateDir.getAbsolutePath() + "/U/", "--itemFeatures", intermediateDir.getAbsolutePath() + "/M/", "--numRecommendations", String.valueOf(2), "--maxRating", String.valueOf(5.0), "--numThreads", String.valueOf(2), "--usesLongIDs", String.valueOf(true), "--userIDIndex", intermediateDir.getAbsolutePath() + "/userIDIndex/", "--itemIDIndex", intermediateDir.getAbsolutePath() + "/itemIDIndex/", "--output", outputDir.getAbsolutePath() });    assertEquals(0, success);}
public void mahout_f4335_0() throws Exception
{    Configuration conf = getConfiguration();    IDReader idReader = new IDReader(conf);    Map<Long, FastIDSet> userItemFilter = new HashMap<>();    long user1 = 1;    long user2 = 2;    idReader.addUserAndItemIdToUserItemFilter(userItemFilter, user1, 100L);    idReader.addUserAndItemIdToUserItemFilter(userItemFilter, user1, 200L);    idReader.addUserAndItemIdToUserItemFilter(userItemFilter, user2, 300L);    FastIDSet userIds = IDReader.extractAllUserIdsFromUserItemFilter(userItemFilter);    assertEquals(2, userIds.size());    assertTrue(userIds.contains(user1));    assertTrue(userIds.contains(user1));    setField(idReader, USER_ITEM_FILTER_FIELD, userItemFilter);    FastIDSet itemsForUser1 = idReader.getItemsToRecommendForUser(user1);    assertEquals(2, itemsForUser1.size());    assertTrue(itemsForUser1.contains(100L));    assertTrue(itemsForUser1.contains(200L));    FastIDSet itemsForUser2 = idReader.getItemsToRecommendForUser(user2);    assertEquals(1, itemsForUser2.size());    assertTrue(itemsForUser2.contains(300L));    FastIDSet itemsForNonExistingUser = idReader.getItemsToRecommendForUser(3L);    assertTrue(itemsForNonExistingUser.isEmpty());}
public void mahout_f4336_0() throws Exception
{    Mapper<LongWritable, Text, VarIntWritable, VarLongWritable>.Context context = EasyMock.createMock(Mapper.Context.class);    context.write(new VarIntWritable(TasteHadoopUtils.idToIndex(789L)), new VarLongWritable(789L));    EasyMock.replay(context);    new ItemIDIndexMapper().map(new LongWritable(123L), new Text("456,789,5.0"), context);    EasyMock.verify(context);}
public void mahout_f4337_0() throws Exception
{    Reducer<VarIntWritable, VarLongWritable, VarIntWritable, VarLongWritable>.Context context = EasyMock.createMock(Reducer.Context.class);    context.write(new VarIntWritable(123), new VarLongWritable(45L));    EasyMock.replay(context);    new ItemIDIndexReducer().reduce(new VarIntWritable(123), Arrays.asList(new VarLongWritable(67L), new VarLongWritable(89L), new VarLongWritable(45L)), context);    EasyMock.verify(context);}
public void mahout_f4338_0() throws Exception
{    Mapper<LongWritable, Text, VarLongWritable, VarLongWritable>.Context context = EasyMock.createMock(Mapper.Context.class);    context.write(new VarLongWritable(12L), new EntityPrefWritable(34L, 1.0f));    context.write(new VarLongWritable(56L), new EntityPrefWritable(78L, 2.0f));    EasyMock.replay(context);    ToItemPrefsMapper mapper = new ToItemPrefsMapper();    mapper.map(new LongWritable(123L), new Text("12,34,1"), context);    mapper.map(new LongWritable(456L), new Text("56,78,2"), context);    EasyMock.verify(context);}
public void mahout_f4339_0() throws Exception
{    Mapper<LongWritable, Text, VarLongWritable, VarLongWritable>.Context context = EasyMock.createMock(Mapper.Context.class);    context.write(new VarLongWritable(12L), new VarLongWritable(34L));    context.write(new VarLongWritable(56L), new VarLongWritable(78L));    EasyMock.replay(context);    ToItemPrefsMapper mapper = new ToItemPrefsMapper();    setField(mapper, "booleanData", true);    mapper.map(new LongWritable(123L), new Text("12,34"), context);    mapper.map(new LongWritable(456L), new Text("56,78"), context);    EasyMock.verify(context);}
public void mahout_f4340_0() throws Exception
{    Reducer<VarLongWritable, VarLongWritable, VarLongWritable, VectorWritable>.Context context = EasyMock.createMock(Reducer.Context.class);    Counter userCounters = EasyMock.createMock(Counter.class);    EasyMock.expect(context.getCounter(ToUserVectorsReducer.Counters.USERS)).andReturn(userCounters);    userCounters.increment(1);    context.write(EasyMock.eq(new VarLongWritable(12L)), MathHelper.vectorMatches(MathHelper.elem(TasteHadoopUtils.idToIndex(34L), 1.0), MathHelper.elem(TasteHadoopUtils.idToIndex(56L), 2.0)));    EasyMock.replay(context, userCounters);    Collection<VarLongWritable> varLongWritables = Lists.newLinkedList();    varLongWritables.add(new EntityPrefWritable(34L, 1.0f));    varLongWritables.add(new EntityPrefWritable(56L, 2.0f));    new ToUserVectorsReducer().reduce(new VarLongWritable(12L), varLongWritables, context);    EasyMock.verify(context, userCounters);}
public void mahout_f4341_0() throws Exception
{    Reducer<VarLongWritable, VarLongWritable, VarLongWritable, VectorWritable>.Context context = EasyMock.createMock(Reducer.Context.class);    Counter userCounters = EasyMock.createMock(Counter.class);    EasyMock.expect(context.getCounter(ToUserVectorsReducer.Counters.USERS)).andReturn(userCounters);    userCounters.increment(1);    context.write(EasyMock.eq(new VarLongWritable(12L)), MathHelper.vectorMatches(MathHelper.elem(TasteHadoopUtils.idToIndex(34L), 1.0), MathHelper.elem(TasteHadoopUtils.idToIndex(56L), 1.0)));    EasyMock.replay(context, userCounters);    new ToUserVectorsReducer().reduce(new VarLongWritable(12L), Arrays.asList(new VarLongWritable(34L), new VarLongWritable(56L)), context);    EasyMock.verify(context, userCounters);}
public void mahout_f4342_0() throws Exception
{    Mapper<IntWritable, VectorWritable, VarIntWritable, VectorOrPrefWritable>.Context context = EasyMock.createMock(Mapper.Context.class);    context.write(EasyMock.eq(new VarIntWritable(12)), vectorOfVectorOrPrefWritableMatches(MathHelper.elem(34, 0.5), MathHelper.elem(56, 0.7)));    EasyMock.replay(context);    RandomAccessSparseVector vector = new RandomAccessSparseVector(Integer.MAX_VALUE, 100);    vector.set(12, 1.0);    vector.set(34, 0.5);    vector.set(56, 0.7);    new SimilarityMatrixRowWrapperMapper().map(new IntWritable(12), new VectorWritable(vector), context);    EasyMock.verify(context);}
private static VectorOrPrefWritable mahout_f4343_0(final Vector.Element... elements)
{    EasyMock.reportMatcher(new IArgumentMatcher() {        @Override        public boolean matches(Object argument) {            if (argument instanceof VectorOrPrefWritable) {                Vector v = ((VectorOrPrefWritable) argument).getVector();                return MathHelper.consistsOf(v, elements);            }            return false;        }        @Override        public void appendTo(StringBuffer buffer) {        }    });    return null;}
public boolean mahout_f4344_0(Object argument)
{    if (argument instanceof VectorOrPrefWritable) {        Vector v = ((VectorOrPrefWritable) argument).getVector();        return MathHelper.consistsOf(v, elements);    }    return false;}
public void mahout_f4345_0(StringBuffer buffer)
{}
public void mahout_f4346_0() throws Exception
{    Mapper<VarLongWritable, VectorWritable, VarIntWritable, VectorOrPrefWritable>.Context context = EasyMock.createMock(Mapper.Context.class);    context.write(EasyMock.eq(new VarIntWritable(34)), prefOfVectorOrPrefWritableMatches(123L, 0.5f));    context.write(EasyMock.eq(new VarIntWritable(56)), prefOfVectorOrPrefWritableMatches(123L, 0.7f));    EasyMock.replay(context);    UserVectorSplitterMapper mapper = new UserVectorSplitterMapper();    setField(mapper, "maxPrefsPerUserConsidered", 10);    RandomAccessSparseVector vector = new RandomAccessSparseVector(Integer.MAX_VALUE, 100);    vector.set(34, 0.5);    vector.set(56, 0.7);    mapper.map(new VarLongWritable(123L), new VectorWritable(vector), context);    EasyMock.verify(context);}
private static VectorOrPrefWritable mahout_f4347_0(final long userID, final float prefValue)
{    EasyMock.reportMatcher(new IArgumentMatcher() {        @Override        public boolean matches(Object argument) {            if (argument instanceof VectorOrPrefWritable) {                VectorOrPrefWritable pref = (VectorOrPrefWritable) argument;                return pref.getUserID() == userID && pref.getValue() == prefValue;            }            return false;        }        @Override        public void appendTo(StringBuffer buffer) {        }    });    return null;}
public boolean mahout_f4348_0(Object argument)
{    if (argument instanceof VectorOrPrefWritable) {        VectorOrPrefWritable pref = (VectorOrPrefWritable) argument;        return pref.getUserID() == userID && pref.getValue() == prefValue;    }    return false;}
public void mahout_f4349_0(StringBuffer buffer)
{}
public void mahout_f4350_0() throws Exception
{    Mapper<VarLongWritable, VectorWritable, VarIntWritable, VectorOrPrefWritable>.Context context = EasyMock.createMock(Mapper.Context.class);    context.write(EasyMock.eq(new VarIntWritable(34)), prefOfVectorOrPrefWritableMatches(123L, 0.5f));    context.write(EasyMock.eq(new VarIntWritable(56)), prefOfVectorOrPrefWritableMatches(123L, 0.7f));    EasyMock.replay(context);    FastIDSet usersToRecommendFor = new FastIDSet();    usersToRecommendFor.add(123L);    UserVectorSplitterMapper mapper = new UserVectorSplitterMapper();    setField(mapper, "maxPrefsPerUserConsidered", 10);    setField(mapper, "usersToRecommendFor", usersToRecommendFor);    RandomAccessSparseVector vector = new RandomAccessSparseVector(Integer.MAX_VALUE, 100);    vector.set(34, 0.5);    vector.set(56, 0.7);    mapper.map(new VarLongWritable(123L), new VectorWritable(vector), context);    mapper.map(new VarLongWritable(456L), new VectorWritable(vector), context);    EasyMock.verify(context);}
public void mahout_f4351_0() throws Exception
{    Mapper<VarLongWritable, VectorWritable, VarIntWritable, VectorOrPrefWritable>.Context context = EasyMock.createMock(Mapper.Context.class);    context.write(EasyMock.eq(new VarIntWritable(34)), prefOfVectorOrPrefWritableMatchesNaN(123L));    context.write(EasyMock.eq(new VarIntWritable(56)), prefOfVectorOrPrefWritableMatches(123L, 0.7f));    EasyMock.replay(context);    UserVectorSplitterMapper mapper = new UserVectorSplitterMapper();    setField(mapper, "maxPrefsPerUserConsidered", 1);    RandomAccessSparseVector vector = new RandomAccessSparseVector(Integer.MAX_VALUE, 100);    vector.set(34, 0.5);    vector.set(56, 0.7);    mapper.map(new VarLongWritable(123L), new VectorWritable(vector), context);    EasyMock.verify(context);}
private static VectorOrPrefWritable mahout_f4352_0(final long userID)
{    EasyMock.reportMatcher(new IArgumentMatcher() {        @Override        public boolean matches(Object argument) {            if (argument instanceof VectorOrPrefWritable) {                VectorOrPrefWritable pref = (VectorOrPrefWritable) argument;                return pref.getUserID() == userID && Float.isNaN(pref.getValue());            }            return false;        }        @Override        public void appendTo(StringBuffer buffer) {        }    });    return null;}
public boolean mahout_f4353_0(Object argument)
{    if (argument instanceof VectorOrPrefWritable) {        VectorOrPrefWritable pref = (VectorOrPrefWritable) argument;        return pref.getUserID() == userID && Float.isNaN(pref.getValue());    }    return false;}
public void mahout_f4354_0(StringBuffer buffer)
{}
public void mahout_f4355_0() throws Exception
{    Reducer<VarIntWritable, VectorOrPrefWritable, VarIntWritable, VectorAndPrefsWritable>.Context context = EasyMock.createMock(Reducer.Context.class);    context.write(EasyMock.eq(new VarIntWritable(1)), vectorAndPrefsWritableMatches(Arrays.asList(123L, 456L), Arrays.asList(1.0f, 2.0f), MathHelper.elem(3, 0.5), MathHelper.elem(7, 0.8)));    EasyMock.replay(context);    Vector similarityColumn = new RandomAccessSparseVector(Integer.MAX_VALUE, 100);    similarityColumn.set(3, 0.5);    similarityColumn.set(7, 0.8);    VectorOrPrefWritable itemPref1 = new VectorOrPrefWritable(123L, 1.0f);    VectorOrPrefWritable itemPref2 = new VectorOrPrefWritable(456L, 2.0f);    VectorOrPrefWritable similarities = new VectorOrPrefWritable(similarityColumn);    new ToVectorAndPrefReducer().reduce(new VarIntWritable(1), Arrays.asList(itemPref1, itemPref2, similarities), context);    EasyMock.verify(context);}
private static VectorAndPrefsWritable mahout_f4356_0(final List<Long> userIDs, final List<Float> prefValues, final Vector.Element... elements)
{    EasyMock.reportMatcher(new IArgumentMatcher() {        @Override        public boolean matches(Object argument) {            if (argument instanceof VectorAndPrefsWritable) {                VectorAndPrefsWritable vectorAndPrefs = (VectorAndPrefsWritable) argument;                if (!vectorAndPrefs.getUserIDs().equals(userIDs)) {                    return false;                }                if (!vectorAndPrefs.getValues().equals(prefValues)) {                    return false;                }                return MathHelper.consistsOf(vectorAndPrefs.getVector(), elements);            }            return false;        }        @Override        public void appendTo(StringBuffer buffer) {        }    });    return null;}
public boolean mahout_f4357_0(Object argument)
{    if (argument instanceof VectorAndPrefsWritable) {        VectorAndPrefsWritable vectorAndPrefs = (VectorAndPrefsWritable) argument;        if (!vectorAndPrefs.getUserIDs().equals(userIDs)) {            return false;        }        if (!vectorAndPrefs.getValues().equals(prefValues)) {            return false;        }        return MathHelper.consistsOf(vectorAndPrefs.getVector(), elements);    }    return false;}
public void mahout_f4358_0(StringBuffer buffer)
{}
public void mahout_f4359_0() throws Exception
{    Reducer<VarIntWritable, VectorOrPrefWritable, VarIntWritable, VectorAndPrefsWritable>.Context context = EasyMock.createMock(Reducer.Context.class);    EasyMock.replay(context);    Vector similarityColumn1 = new RandomAccessSparseVector(Integer.MAX_VALUE, 100);    Vector similarityColumn2 = new RandomAccessSparseVector(Integer.MAX_VALUE, 100);    VectorOrPrefWritable similarities1 = new VectorOrPrefWritable(similarityColumn1);    VectorOrPrefWritable similarities2 = new VectorOrPrefWritable(similarityColumn2);    try {        new ToVectorAndPrefReducer().reduce(new VarIntWritable(1), Arrays.asList(similarities1, similarities2), context);        fail();    } catch (IllegalStateException e) {        }    EasyMock.verify(context);}
public void mahout_f4360_0() throws Exception
{    Mapper<LongWritable, Text, VarLongWritable, VarLongWritable>.Context context = EasyMock.createMock(Mapper.Context.class);    context.write(new VarLongWritable(34L), new VarLongWritable(12L));    context.write(new VarLongWritable(78L), new VarLongWritable(56L));    EasyMock.replay(context);    ItemFilterMapper mapper = new ItemFilterMapper();    mapper.map(null, new Text("12,34"), context);    mapper.map(null, new Text("56,78"), context);    EasyMock.verify(context);}
public void mahout_f4361_0() throws Exception
{    Reducer<VarLongWritable, VarLongWritable, VarIntWritable, VectorAndPrefsWritable>.Context context = EasyMock.createMock(Reducer.Context.class);    int itemIDIndex = TasteHadoopUtils.idToIndex(123L);    context.write(EasyMock.eq(new VarIntWritable(itemIDIndex)), vectorAndPrefsForFilteringMatches(123L, 456L, 789L));    EasyMock.replay(context);    new ItemFilterAsVectorAndPrefsReducer().reduce(new VarLongWritable(123L), Arrays.asList(new VarLongWritable(456L), new VarLongWritable(789L)), context);    EasyMock.verify(context);}
 static VectorAndPrefsWritable mahout_f4362_0(final long itemID, final long... userIDs)
{    EasyMock.reportMatcher(new IArgumentMatcher() {        @Override        public boolean matches(Object argument) {            if (argument instanceof VectorAndPrefsWritable) {                VectorAndPrefsWritable vectorAndPrefs = (VectorAndPrefsWritable) argument;                Vector vector = vectorAndPrefs.getVector();                if (vector.getNumNondefaultElements() != 1) {                    return false;                }                if (!Double.isNaN(vector.get(TasteHadoopUtils.idToIndex(itemID)))) {                    return false;                }                if (userIDs.length != vectorAndPrefs.getUserIDs().size()) {                    return false;                }                for (long userID : userIDs) {                    if (!vectorAndPrefs.getUserIDs().contains(userID)) {                        return false;                    }                }                return true;            }            return false;        }        @Override        public void appendTo(StringBuffer buffer) {        }    });    return null;}
public boolean mahout_f4363_0(Object argument)
{    if (argument instanceof VectorAndPrefsWritable) {        VectorAndPrefsWritable vectorAndPrefs = (VectorAndPrefsWritable) argument;        Vector vector = vectorAndPrefs.getVector();        if (vector.getNumNondefaultElements() != 1) {            return false;        }        if (!Double.isNaN(vector.get(TasteHadoopUtils.idToIndex(itemID)))) {            return false;        }        if (userIDs.length != vectorAndPrefs.getUserIDs().size()) {            return false;        }        for (long userID : userIDs) {            if (!vectorAndPrefs.getUserIDs().contains(userID)) {                return false;            }        }        return true;    }    return false;}
public void mahout_f4364_0(StringBuffer buffer)
{}
public void mahout_f4365_0() throws Exception
{    Vector similarityColumn = new RandomAccessSparseVector(Integer.MAX_VALUE, 100);    similarityColumn.set(3, 0.5);    similarityColumn.set(7, 0.8);    Mapper<VarIntWritable, VectorAndPrefsWritable, VarLongWritable, PrefAndSimilarityColumnWritable>.Context context = EasyMock.createMock(Mapper.Context.class);    PrefAndSimilarityColumnWritable one = new PrefAndSimilarityColumnWritable();    PrefAndSimilarityColumnWritable two = new PrefAndSimilarityColumnWritable();    one.set(1.0f, similarityColumn);    two.set(3.0f, similarityColumn);    context.write(EasyMock.eq(new VarLongWritable(123L)), EasyMock.eq(one));    context.write(EasyMock.eq(new VarLongWritable(456L)), EasyMock.eq(two));    EasyMock.replay(context);    VectorAndPrefsWritable vectorAndPrefs = new VectorAndPrefsWritable(similarityColumn, Arrays.asList(123L, 456L), Arrays.asList(1.0f, 3.0f));    new PartialMultiplyMapper().map(new VarIntWritable(1), vectorAndPrefs, context);    EasyMock.verify(context);}
public void mahout_f4366_0() throws Exception
{    Reducer<VarLongWritable, PrefAndSimilarityColumnWritable, VarLongWritable, RecommendedItemsWritable>.Context context = EasyMock.createMock(Reducer.Context.class);    context.write(EasyMock.eq(new VarLongWritable(123L)), recommendationsMatch(new MutableRecommendedItem(1L, 2.8f), new MutableRecommendedItem(2L, 2.0f)));    EasyMock.replay(context);    RandomAccessSparseVector similarityColumnOne = new RandomAccessSparseVector(Integer.MAX_VALUE, 100);    similarityColumnOne.set(1, 0.1);    similarityColumnOne.set(2, 0.5);    RandomAccessSparseVector similarityColumnTwo = new RandomAccessSparseVector(Integer.MAX_VALUE, 100);    similarityColumnTwo.set(1, 0.9);    similarityColumnTwo.set(2, 0.5);    List<PrefAndSimilarityColumnWritable> values = Arrays.asList(new PrefAndSimilarityColumnWritable(1.0f, similarityColumnOne), new PrefAndSimilarityColumnWritable(3.0f, similarityColumnTwo));    OpenIntLongHashMap indexItemIDMap = new OpenIntLongHashMap();    indexItemIDMap.put(1, 1L);    indexItemIDMap.put(2, 2L);    AggregateAndRecommendReducer reducer = new AggregateAndRecommendReducer();    setField(reducer, "indexItemIDMap", indexItemIDMap);    setField(reducer, "recommendationsPerUser", 3);    reducer.reduce(new VarLongWritable(123L), values, context);    EasyMock.verify(context);}
public void mahout_f4367_0() throws Exception
{    Reducer<VarLongWritable, PrefAndSimilarityColumnWritable, VarLongWritable, RecommendedItemsWritable>.Context context = EasyMock.createMock(Reducer.Context.class);    context.write(EasyMock.eq(new VarLongWritable(123L)), recommendationsMatch(new MutableRecommendedItem(1L, 2.8f)));    EasyMock.replay(context);    RandomAccessSparseVector similarityColumnOne = new RandomAccessSparseVector(Integer.MAX_VALUE, 100);    similarityColumnOne.set(1, 0.1);    RandomAccessSparseVector similarityColumnTwo = new RandomAccessSparseVector(Integer.MAX_VALUE, 100);    similarityColumnTwo.set(1, 0.9);    similarityColumnTwo.set(2, 0.5);    List<PrefAndSimilarityColumnWritable> values = Arrays.asList(new PrefAndSimilarityColumnWritable(1.0f, similarityColumnOne), new PrefAndSimilarityColumnWritable(3.0f, similarityColumnTwo));    OpenIntLongHashMap indexItemIDMap = new OpenIntLongHashMap();    indexItemIDMap.put(1, 1L);    indexItemIDMap.put(2, 2L);    AggregateAndRecommendReducer reducer = new AggregateAndRecommendReducer();    setField(reducer, "indexItemIDMap", indexItemIDMap);    setField(reducer, "recommendationsPerUser", 3);    reducer.reduce(new VarLongWritable(123L), values, context);    EasyMock.verify(context);}
public void mahout_f4368_0() throws Exception
{    Reducer<VarLongWritable, PrefAndSimilarityColumnWritable, VarLongWritable, RecommendedItemsWritable>.Context context = EasyMock.createMock(Reducer.Context.class);    context.write(EasyMock.eq(new VarLongWritable(123L)), recommendationsMatch(new MutableRecommendedItem(1L, 2.8f)));    EasyMock.replay(context);    RandomAccessSparseVector similarityColumnOne = new RandomAccessSparseVector(Integer.MAX_VALUE, 100);    similarityColumnOne.set(1, 0.1);    similarityColumnOne.set(2, 0.5);    RandomAccessSparseVector similarityColumnTwo = new RandomAccessSparseVector(Integer.MAX_VALUE, 100);    similarityColumnTwo.set(1, 0.9);    similarityColumnTwo.set(2, 0.5);    List<PrefAndSimilarityColumnWritable> values = Arrays.asList(new PrefAndSimilarityColumnWritable(1.0f, similarityColumnOne), new PrefAndSimilarityColumnWritable(3.0f, similarityColumnTwo));    OpenIntLongHashMap indexItemIDMap = new OpenIntLongHashMap();    indexItemIDMap.put(1, 1L);    indexItemIDMap.put(2, 2L);    AggregateAndRecommendReducer reducer = new AggregateAndRecommendReducer();    setField(reducer, "indexItemIDMap", indexItemIDMap);    setField(reducer, "recommendationsPerUser", 1);    reducer.reduce(new VarLongWritable(123L), values, context);    EasyMock.verify(context);}
 static RecommendedItemsWritable mahout_f4369_0(final RecommendedItem... items)
{    EasyMock.reportMatcher(new IArgumentMatcher() {        @Override        public boolean matches(Object argument) {            if (argument instanceof RecommendedItemsWritable) {                RecommendedItemsWritable recommendedItemsWritable = (RecommendedItemsWritable) argument;                List<RecommendedItem> expectedItems = Arrays.asList(items);                return expectedItems.equals(recommendedItemsWritable.getRecommendedItems());            }            return false;        }        @Override        public void appendTo(StringBuffer buffer) {        }    });    return null;}
public boolean mahout_f4370_0(Object argument)
{    if (argument instanceof RecommendedItemsWritable) {        RecommendedItemsWritable recommendedItemsWritable = (RecommendedItemsWritable) argument;        List<RecommendedItem> expectedItems = Arrays.asList(items);        return expectedItems.equals(recommendedItemsWritable.getRecommendedItems());    }    return false;}
public void mahout_f4371_0(StringBuffer buffer)
{}
public void mahout_f4372_0() throws Exception
{    File inputFile = getTestTempFile("prefs.txt");    File outputDir = getTestTempDir("output");    outputDir.delete();    File similaritiesOutputDir = getTestTempDir("outputSimilarities");    similaritiesOutputDir.delete();    File tmpDir = getTestTempDir("tmp");    writeLines(inputFile, "1,1,5", "1,2,5", "1,3,2", "2,1,2", "2,3,3", "2,4,5", "3,2,5", "3,4,3", "4,1,3", "4,4,5");    RecommenderJob recommenderJob = new RecommenderJob();    Configuration conf = getConfiguration();    conf.set("mapred.input.dir", inputFile.getAbsolutePath());    conf.set("mapred.output.dir", outputDir.getAbsolutePath());    conf.setBoolean("mapred.output.compress", false);    recommenderJob.setConf(conf);    recommenderJob.run(new String[] { "--tempDir", tmpDir.getAbsolutePath(), "--similarityClassname", TanimotoCoefficientSimilarity.class.getName(), "--numRecommendations", "4", "--outputPathForSimilarityMatrix", similaritiesOutputDir.getAbsolutePath() });    Map<Long, List<RecommendedItem>> recommendations = readRecommendations(new File(outputDir, "part-r-00000"));    assertEquals(4, recommendations.size());    for (Entry<Long, List<RecommendedItem>> entry : recommendations.entrySet()) {        long userID = entry.getKey();        List<RecommendedItem> items = entry.getValue();        assertNotNull(items);        RecommendedItem item1 = items.get(0);        if (userID == 1L) {            assertEquals(1, items.size());            assertEquals(4L, item1.getItemID());            assertEquals(4.3, item1.getValue(), 0.05);        }        if (userID == 2L) {            assertEquals(1, items.size());            assertEquals(2L, item1.getItemID());            assertEquals(3.3, item1.getValue(), 0.05);        }        if (userID == 3L) {            assertEquals(2, items.size());            assertEquals(3L, item1.getItemID());            assertEquals(4.1, item1.getValue(), 0.05);            RecommendedItem item2 = items.get(1);            assertEquals(1L, item2.getItemID());            assertEquals(3.7, item2.getValue(), 0.05);        }        if (userID == 4L) {            assertEquals(2, items.size());            assertEquals(2L, item1.getItemID());            assertEquals(4.0, item1.getValue(), 0.05);            RecommendedItem item2 = items.get(1);            assertEquals(3L, item2.getItemID());            assertEquals(3.5, item2.getValue(), 0.05);        }    }    Map<Pair<Long, Long>, Double> similarities = readSimilarities(new File(similaritiesOutputDir, "part-r-00000"));    assertEquals(6, similarities.size());    assertEquals(0.25, similarities.get(new Pair<>(1L, 2L)), EPSILON);    assertEquals(0.6666666666666666, similarities.get(new Pair<>(1L, 3L)), EPSILON);    assertEquals(0.5, similarities.get(new Pair<>(1L, 4L)), EPSILON);    assertEquals(0.3333333333333333, similarities.get(new Pair<>(2L, 3L)), EPSILON);    assertEquals(0.25, similarities.get(new Pair<>(2L, 4L)), EPSILON);    assertEquals(0.25, similarities.get(new Pair<>(3L, 4L)), EPSILON);}
public void mahout_f4373_0() throws Exception
{    File inputFile = getTestTempFile("prefs.txt");    File outputDir = getTestTempDir("output");    outputDir.delete();    File tmpDir = getTestTempDir("tmp");    File usersFile = getTestTempFile("users.txt");    writeLines(usersFile, "3");    writeLines(inputFile, "1,1", "1,2", "1,3", "2,1", "2,3", "2,4", "3,2", "3,4", "4,1", "4,4");    RecommenderJob recommenderJob = new RecommenderJob();    Configuration conf = getConfiguration();    conf.set("mapred.input.dir", inputFile.getAbsolutePath());    conf.set("mapred.output.dir", outputDir.getAbsolutePath());    conf.setBoolean("mapred.output.compress", false);    recommenderJob.setConf(conf);    recommenderJob.run(new String[] { "--tempDir", tmpDir.getAbsolutePath(), "--similarityClassname", CooccurrenceCountSimilarity.class.getName(), "--booleanData", "true", "--usersFile", usersFile.getAbsolutePath() });    Map<Long, List<RecommendedItem>> recommendations = readRecommendations(new File(outputDir, "part-r-00000"));    List<RecommendedItem> recommendedToCow = recommendations.get(3L);    assertEquals(2, recommendedToCow.size());    RecommendedItem item1 = recommendedToCow.get(0);    RecommendedItem item2 = recommendedToCow.get(1);    assertEquals(1L, item1.getItemID());    assertEquals(3L, item2.getItemID());    /* predicted pref must be the sum of similarities:    *    item1: coocc(burger, hotdog) + coocc(burger, icecream) = 3     *    item2: coocc(berries, hotdog) + coocc(berries, icecream) = 2 */    assertEquals(3, item1.getValue(), 0.05);    assertEquals(2, item2.getValue(), 0.05);}
public void mahout_f4374_0() throws Exception
{    File inputFile = getTestTempFile("prefs.txt");    File userFile = getTestTempFile("users.txt");    File filterFile = getTestTempFile("filter.txt");    File outputDir = getTestTempDir("output");    outputDir.delete();    File tmpDir = getTestTempDir("tmp");    writeLines(inputFile, "1,1,5", "1,2,5", "1,3,2", "2,1,2", "2,3,3", "2,4,5", "3,2,5", "3,4,3", "4,1,3", "4,4,5");    /* only compute recommendations for the donkey */    writeLines(userFile, "4");    /* do not recommend the hotdog for the donkey */    writeLines(filterFile, "4,2");    RecommenderJob recommenderJob = new RecommenderJob();    Configuration conf = getConfiguration();    conf.set("mapred.input.dir", inputFile.getAbsolutePath());    conf.set("mapred.output.dir", outputDir.getAbsolutePath());    conf.setBoolean("mapred.output.compress", false);    recommenderJob.setConf(conf);    recommenderJob.run(new String[] { "--tempDir", tmpDir.getAbsolutePath(), "--similarityClassname", TanimotoCoefficientSimilarity.class.getName(), "--numRecommendations", "1", "--usersFile", userFile.getAbsolutePath(), "--filterFile", filterFile.getAbsolutePath() });    Map<Long, List<RecommendedItem>> recommendations = readRecommendations(new File(outputDir, "part-r-00000"));    assertEquals(1, recommendations.size());    assertTrue(recommendations.containsKey(4L));    assertEquals(1, recommendations.get(4L).size());    /* berries should have been recommended to the donkey */    RecommendedItem recommendedItem = recommendations.get(4L).get(0);    assertEquals(3L, recommendedItem.getItemID());    assertEquals(3.5, recommendedItem.getValue(), 0.05);}
 static Map<Pair<Long, Long>, Double> mahout_f4375_0(File file) throws IOException
{    Map<Pair<Long, Long>, Double> similarities = Maps.newHashMap();    for (String line : new FileLineIterable(file)) {        String[] parts = line.split("\t");        similarities.put(new Pair<>(Long.parseLong(parts[0]), Long.parseLong(parts[1])), Double.parseDouble(parts[2]));    }    return similarities;}
 static Map<Long, List<RecommendedItem>> mahout_f4376_0(File file) throws IOException
{    Map<Long, List<RecommendedItem>> recommendations = Maps.newHashMap();    for (String line : new FileLineIterable(file)) {        String[] keyValue = line.split("\t");        long userID = Long.parseLong(keyValue[0]);        String[] tokens = keyValue[1].replaceAll("\\[", "").replaceAll("\\]", "").split(",");        List<RecommendedItem> items = Lists.newLinkedList();        for (String token : tokens) {            String[] itemTokens = token.split(":");            long itemID = Long.parseLong(itemTokens[0]);            float value = Float.parseFloat(itemTokens[1]);            items.add(new GenericRecommendedItem(itemID, value));        }        recommendations.put(userID, items);    }    return recommendations;}
public void mahout_f4377_0() throws Exception
{    Reducer<VarLongWritable, VarLongWritable, VarLongWritable, VectorWritable>.Context context = EasyMock.createMock(Reducer.Context.class);    ToUserVectorsReducer reducer = new ToUserVectorsReducer();    setField(reducer, "minPreferences", 2);    EasyMock.replay(context);    reducer.reduce(new VarLongWritable(123), Collections.singletonList(new VarLongWritable(456)), context);    EasyMock.verify(context);}
public void mahout_f4378_0() throws Exception
{    Reducer<VarLongWritable, VarLongWritable, VarLongWritable, VectorWritable>.Context context = EasyMock.createMock(Reducer.Context.class);    Counter userCounters = EasyMock.createMock(Counter.class);    ToUserVectorsReducer reducer = new ToUserVectorsReducer();    setField(reducer, "minPreferences", 2);    EasyMock.expect(context.getCounter(ToUserVectorsReducer.Counters.USERS)).andReturn(userCounters);    userCounters.increment(1);    context.write(EasyMock.eq(new VarLongWritable(123)), MathHelper.vectorMatches(MathHelper.elem(TasteHadoopUtils.idToIndex(456L), 1.0), MathHelper.elem(TasteHadoopUtils.idToIndex(789L), 1.0)));    EasyMock.replay(context, userCounters);    reducer.reduce(new VarLongWritable(123), Arrays.asList(new VarLongWritable(456), new VarLongWritable(789)), context);    EasyMock.verify(context, userCounters);}
public void mahout_f4379_0() throws Exception
{    OpenIntLongHashMap indexItemIDMap = new OpenIntLongHashMap();    indexItemIDMap.put(12, 12L);    indexItemIDMap.put(34, 34L);    indexItemIDMap.put(56, 56L);    Mapper<IntWritable, VectorWritable, EntityEntityWritable, DoubleWritable>.Context context = EasyMock.createMock(Mapper.Context.class);    context.write(new EntityEntityWritable(34L, 56L), new DoubleWritable(0.9));    EasyMock.replay(context);    Vector vector = new RandomAccessSparseVector(Integer.MAX_VALUE);    vector.set(12, 0.2);    vector.set(56, 0.9);    ItemSimilarityJob.MostSimilarItemPairsMapper mapper = new ItemSimilarityJob.MostSimilarItemPairsMapper();    setField(mapper, "indexItemIDMap", indexItemIDMap);    setField(mapper, "maxSimilarItemsPerItem", 1);    mapper.map(new IntWritable(34), new VectorWritable(vector), context);    EasyMock.verify(context);}
public void mahout_f4380_0() throws Exception
{    Reducer<EntityEntityWritable, DoubleWritable, EntityEntityWritable, DoubleWritable>.Context context = EasyMock.createMock(Reducer.Context.class);    context.write(new EntityEntityWritable(123L, 456L), new DoubleWritable(0.5));    EasyMock.replay(context);    new ItemSimilarityJob.MostSimilarItemPairsReducer().reduce(new EntityEntityWritable(123L, 456L), Arrays.asList(new DoubleWritable(0.5), new DoubleWritable(0.5)), context);    EasyMock.verify(context);}
public void mahout_f4381_0() throws Exception
{    File inputFile = getTestTempFile("prefs.txt");    File outputDir = getTestTempDir("output");    outputDir.delete();    File tmpDir = getTestTempDir("tmp");    writeLines(inputFile, "2,1,1", "1,2,1", "3,4,1", "1,3,2", "2,3,1");    ItemSimilarityJob similarityJob = new ItemSimilarityJob();    Configuration conf = getConfiguration();    conf.set("mapred.input.dir", inputFile.getAbsolutePath());    conf.set("mapred.output.dir", outputDir.getAbsolutePath());    conf.setBoolean("mapred.output.compress", false);    similarityJob.setConf(conf);    similarityJob.run(new String[] { "--tempDir", tmpDir.getAbsolutePath(), "--similarityClassname", CosineSimilarity.class.getName() });    File outPart = outputDir.listFiles(new FilenameFilter() {        @Override        public boolean accept(File dir, String name) {            return name.startsWith("part-");        }    })[0];    BufferedReader reader = Files.newReader(outPart, Charsets.UTF_8);    String line;    int currentLine = 1;    while ((line = reader.readLine()) != null) {        String[] tokens = TAB.split(line);        long itemAID = Long.parseLong(tokens[0]);        long itemBID = Long.parseLong(tokens[1]);        double similarity = Double.parseDouble(tokens[2]);        if (currentLine == 1) {            assertEquals(1L, itemAID);            assertEquals(3L, itemBID);            assertEquals(0.45, similarity, 0.01);        }        if (currentLine == 2) {            assertEquals(2L, itemAID);            assertEquals(3L, itemBID);            assertEquals(0.89, similarity, 0.01);        }        currentLine++;    }    int linesWritten = currentLine - 1;    assertEquals(2, linesWritten);}
public boolean mahout_f4382_0(File dir, String name)
{    return name.startsWith("part-");}
public void mahout_f4383_0() throws Exception
{    File inputFile = getTestTempFile("prefsForMaxSimilarities.txt");    File outputDir = getTestTempDir("output");    outputDir.delete();    File tmpDir = getTestTempDir("tmp");    writeLines(inputFile, "1,1,1", "1,3,1", "2,2,1", "2,3,1", "3,1,1", "3,2,1", "4,1,1", "4,2,1", "4,3,1", "5,2,1", "6,1,1", "6,2,1");    ItemSimilarityJob similarityJob = new ItemSimilarityJob();    Configuration conf = getConfiguration();    conf.set("mapred.input.dir", inputFile.getAbsolutePath());    conf.set("mapred.output.dir", outputDir.getAbsolutePath());    conf.setBoolean("mapred.output.compress", false);    similarityJob.setConf(conf);    similarityJob.run(new String[] { "--tempDir", tmpDir.getAbsolutePath(), "--similarityClassname", TanimotoCoefficientSimilarity.class.getName(), "--maxSimilaritiesPerItem", "1" });    File outPart = outputDir.listFiles(new FilenameFilter() {        @Override        public boolean accept(File dir, String name) {            return name.startsWith("part-");        }    })[0];    BufferedReader reader = Files.newReader(outPart, Charsets.UTF_8);    String line;    int currentLine = 1;    while ((line = reader.readLine()) != null) {        String[] tokens = TAB.split(line);        long itemAID = Long.parseLong(tokens[0]);        long itemBID = Long.parseLong(tokens[1]);        double similarity = Double.parseDouble(tokens[2]);        if (currentLine == 1) {            assertEquals(1L, itemAID);            assertEquals(2L, itemBID);            assertEquals(0.5, similarity, 0.0001);        }        if (currentLine == 2) {            assertEquals(1L, itemAID);            assertEquals(3L, itemBID);            assertEquals(0.4, similarity, 0.0001);        }        currentLine++;    }    int linesWritten = currentLine - 1;    assertEquals(2, linesWritten);}
public boolean mahout_f4384_0(File dir, String name)
{    return name.startsWith("part-");}
public void mahout_f4385_0()
{    assertTrue(TasteHadoopUtils.idToIndex(0) >= 0);    assertTrue(TasteHadoopUtils.idToIndex(0) < Integer.MAX_VALUE);    assertTrue(TasteHadoopUtils.idToIndex(1) >= 0);    assertTrue(TasteHadoopUtils.idToIndex(1) < Integer.MAX_VALUE);    assertTrue(TasteHadoopUtils.idToIndex(Long.MAX_VALUE) >= 0);    assertTrue(TasteHadoopUtils.idToIndex(Long.MAX_VALUE) < Integer.MAX_VALUE);    assertTrue(TasteHadoopUtils.idToIndex(Integer.MAX_VALUE) >= 0);    assertTrue(TasteHadoopUtils.idToIndex(Integer.MAX_VALUE) < Integer.MAX_VALUE);}
public void mahout_f4386_0()
{    float[] ratings = { 0.5f, 0.6f, 0.7f, 2.0f, 0.0f };    List<RecommendedItem> topItems = findTop(ratings, 2);    assertEquals(2, topItems.size());    assertEquals(3L, topItems.get(0).getItemID());    assertEquals(2.0f, topItems.get(0).getValue(), MahoutTestCase.EPSILON);    assertEquals(2L, topItems.get(1).getItemID());    assertEquals(0.7f, topItems.get(1).getValue(), MahoutTestCase.EPSILON);}
public void mahout_f4387_0()
{    float[] ratings = { 0.7f, 2.0f };    List<RecommendedItem> topItems = findTop(ratings, 3);    assertEquals(2, topItems.size());    assertEquals(1L, topItems.get(0).getItemID());    assertEquals(2.0f, topItems.get(0).getValue(), MahoutTestCase.EPSILON);    assertEquals(0L, topItems.get(1).getItemID());    assertEquals(0.7f, topItems.get(1).getValue(), MahoutTestCase.EPSILON);}
private static List<RecommendedItem> mahout_f4388_0(float[] ratings, int k)
{    TopItemsQueue queue = new TopItemsQueue(k);    for (int item = 0; item < ratings.length; item++) {        MutableRecommendedItem top = queue.top();        if (ratings[item] > top.getValue()) {            top.set(item, ratings[item]);            queue.updateTop();        }    }    return queue.getTopItems();}
public void mahout_f4389_0()
{    BitSet bitSet = new BitSet(NUM_BITS);    for (int i = 0; i < NUM_BITS; i++) {        assertFalse(bitSet.get(i));    }    bitSet.set(0);    bitSet.set(NUM_BITS - 1);    assertTrue(bitSet.get(0));    assertTrue(bitSet.get(NUM_BITS - 1));}
public void mahout_f4390_0()
{    BitSet bitSet = new BitSet(NUM_BITS);    bitSet.set(1000);}
public void mahout_f4391_0()
{    BitSet bitSet = new BitSet(NUM_BITS);    bitSet.set(-1);}
public void mahout_f4392_0()
{    BitSet bitSet = new BitSet(NUM_BITS);    for (int i = 0; i < NUM_BITS; i++) {        bitSet.set(i);    }    for (int i = 0; i < NUM_BITS; i++) {        assertTrue(bitSet.get(i));    }    bitSet.clear();    for (int i = 0; i < NUM_BITS; i++) {        assertFalse(bitSet.get(i));    }}
public void mahout_f4393_0()
{    BitSet bitSet = new BitSet(NUM_BITS);    bitSet.set(NUM_BITS - 1);    bitSet = bitSet.clone();    assertTrue(bitSet.get(NUM_BITS - 1));}
public void mahout_f4394_0() throws TasteException
{    Retriever<Object, Object> retriever = new IdentityRetriever();    Cache<Object, Object> cache = new Cache<>(retriever, 1000);    for (int i = 0; i < 1000000; i++) {        assertEquals(i, cache.get(i));    }}
public void mahout_f4395_0() throws TasteException
{    Random random = RandomUtils.getRandom();    Retriever<Object, Object> retriever = new IdentityRetriever();    Cache<Object, Object> cache = new Cache<>(retriever, 1000);    for (int i = 0; i < 1000000; i++) {        double r = random.nextDouble();        if (r < 0.01) {            cache.clear();        } else if (r < 0.1) {            cache.remove(r - 100);        } else {            assertEquals(i, cache.get(i));        }    }}
public Object mahout_f4396_0(Object key) throws TasteException
{    return key;}
public void mahout_f4397_0()
{    FastByIDMap<Long> map = new FastByIDMap<>();    assertNull(map.get(500000L));    map.put(500000L, 2L);    assertEquals(2L, (long) map.get(500000L));}
public void mahout_f4398_0()
{    FastByIDMap<Long> map = new FastByIDMap<>();    map.put(500000L, 2L);    map.remove(500000L);    assertEquals(0, map.size());    assertTrue(map.isEmpty());    assertNull(map.get(500000L));}
public void mahout_f4399_0()
{    FastByIDMap<Long> map = new FastByIDMap<>();    map.put(500000L, 2L);    map.clear();    assertEquals(0, map.size());    assertTrue(map.isEmpty());    assertNull(map.get(500000L));}
public void mahout_f4400_0()
{    FastByIDMap<Long> map = new FastByIDMap<>();    assertEquals(0, map.size());    assertTrue(map.isEmpty());    map.put(500000L, 2L);    assertEquals(1, map.size());    assertFalse(map.isEmpty());    map.remove(500000L);    assertEquals(0, map.size());    assertTrue(map.isEmpty());}
public void mahout_f4401_0()
{    FastByIDMap<String> map = buildTestFastMap();    assertTrue(map.containsKey(500000L));    assertTrue(map.containsKey(47L));    assertTrue(map.containsKey(2L));    assertTrue(map.containsValue("alpha"));    assertTrue(map.containsValue("bang"));    assertTrue(map.containsValue("beta"));    assertFalse(map.containsKey(999));    assertFalse(map.containsValue("something"));}
public void mahout_f4402_0()
{    FastByIDMap<String> map = buildTestFastMap();    map.remove(500000L);    map.rehash();    assertNull(map.get(500000L));    assertEquals("bang", map.get(47L));}
public void mahout_f4403_0()
{    FastByIDMap<String> map = new FastByIDMap<>(1, 1);    map.put(500000L, "alpha");    map.put(47L, "bang");    assertNull(map.get(500000L));    assertEquals("bang", map.get(47L));}
public void mahout_f4404_0()
{    FastByIDMap<String> actual = new FastByIDMap<>();    Map<Long, String> expected = new HashMap<>(1000000);    Random r = RandomUtils.getRandom();    for (int i = 0; i < 1000000; i++) {        double d = r.nextDouble();        Long key = (long) r.nextInt(100);        if (d < 0.4) {            assertEquals(expected.get(key), actual.get(key));        } else {            if (d < 0.7) {                assertEquals(expected.put(key, "bang"), actual.put(key, "bang"));            } else {                assertEquals(expected.remove(key), actual.remove(key));            }            assertEquals(expected.size(), actual.size());            assertEquals(expected.isEmpty(), actual.isEmpty());        }    }}
public void mahout_f4405_0()
{    FastByIDMap<String> map = new FastByIDMap<>();    map.put(4, "bang");    assertEquals(1, map.size());    map.put(47L, "bang");    assertEquals(2, map.size());    assertNull(map.get(500000L));    map.put(47L, "buzz");    assertEquals(2, map.size());    assertEquals("buzz", map.get(47L));}
private static FastByIDMap<String> mahout_f4406_0()
{    FastByIDMap<String> map = new FastByIDMap<>();    map.put(500000L, "alpha");    map.put(47L, "bang");    map.put(2L, "beta");    return map;}
public void mahout_f4407_0()
{    FastIDSet set = new FastIDSet();    assertFalse(set.contains(1));    set.add(1);    assertTrue(set.contains(1));}
public void mahout_f4408_0()
{    FastIDSet set = new FastIDSet();    set.add(1);    set.remove(1);    assertEquals(0, set.size());    assertTrue(set.isEmpty());    assertFalse(set.contains(1));}
public void mahout_f4409_0()
{    FastIDSet set = new FastIDSet();    set.add(1);    set.clear();    assertEquals(0, set.size());    assertTrue(set.isEmpty());    assertFalse(set.contains(1));}
public void mahout_f4410_0()
{    FastIDSet set = new FastIDSet();    assertEquals(0, set.size());    assertTrue(set.isEmpty());    set.add(1);    assertEquals(1, set.size());    assertFalse(set.isEmpty());    set.remove(1);    assertEquals(0, set.size());    assertTrue(set.isEmpty());}
public void mahout_f4411_0()
{    FastIDSet set = buildTestFastSet();    assertTrue(set.contains(1));    assertTrue(set.contains(2));    assertTrue(set.contains(3));    assertFalse(set.contains(4));}
public void mahout_f4412_0()
{    FastIDSet set = new FastIDSet();    try {        set.add(Long.MIN_VALUE);        fail("Should have thrown IllegalArgumentException");    } catch (IllegalArgumentException iae) {        }    assertFalse(set.contains(Long.MIN_VALUE));    try {        set.add(Long.MAX_VALUE);        fail("Should have thrown IllegalArgumentException");    } catch (IllegalArgumentException iae) {        }    assertFalse(set.contains(Long.MAX_VALUE));}
public void mahout_f4413_0()
{    FastIDSet set = buildTestFastSet();    set.remove(1);    set.rehash();    assertFalse(set.contains(1));}
public void mahout_f4414_0()
{    FastIDSet set = new FastIDSet(1);    set.add(1);    set.add(2);    assertTrue(set.contains(1));    assertTrue(set.contains(2));}
public void mahout_f4415_0()
{    FastIDSet set = buildTestFastSet();    Collection<Long> expected = Sets.newHashSetWithExpectedSize(3);    expected.add(1L);    expected.add(2L);    expected.add(3L);    LongPrimitiveIterator it = set.iterator();    while (it.hasNext()) {        expected.remove(it.nextLong());    }    assertTrue(expected.isEmpty());}
public void mahout_f4416_0()
{    FastIDSet actual = new FastIDSet(1);    Collection<Integer> expected = Sets.newHashSetWithExpectedSize(1000000);    Random r = RandomUtils.getRandom();    for (int i = 0; i < 1000000; i++) {        double d = r.nextDouble();        Integer key = r.nextInt(100);        if (d < 0.4) {            assertEquals(expected.contains(key), actual.contains(key));        } else {            if (d < 0.7) {                assertEquals(expected.add(key), actual.add(key));            } else {                assertEquals(expected.remove(key), actual.remove(key));            }            assertEquals(expected.size(), actual.size());            assertEquals(expected.isEmpty(), actual.isEmpty());        }    }}
private static FastIDSet mahout_f4417_0()
{    FastIDSet set = new FastIDSet();    set.add(1);    set.add(2);    set.add(3);    return set;}
public void mahout_f4418_0()
{    Map<String, String> map = new FastMap<>();    assertNull(map.get("foo"));    map.put("foo", "bar");    assertEquals("bar", map.get("foo"));}
public void mahout_f4419_0()
{    Map<String, String> map = new FastMap<>();    map.put("foo", "bar");    map.remove("foo");    assertEquals(0, map.size());    assertTrue(map.isEmpty());    assertNull(map.get("foo"));}
public void mahout_f4420_0()
{    Map<String, String> map = new FastMap<>();    map.put("foo", "bar");    map.clear();    assertEquals(0, map.size());    assertTrue(map.isEmpty());    assertNull(map.get("foo"));}
public void mahout_f4421_0()
{    Map<String, String> map = new FastMap<>();    assertEquals(0, map.size());    assertTrue(map.isEmpty());    map.put("foo", "bar");    assertEquals(1, map.size());    assertFalse(map.isEmpty());    map.remove("foo");    assertEquals(0, map.size());    assertTrue(map.isEmpty());}
public void mahout_f4422_0()
{    FastMap<String, String> map = buildTestFastMap();    assertTrue(map.containsKey("foo"));    assertTrue(map.containsKey("baz"));    assertTrue(map.containsKey("alpha"));    assertTrue(map.containsValue("bar"));    assertTrue(map.containsValue("bang"));    assertTrue(map.containsValue("beta"));    assertFalse(map.containsKey("something"));    assertFalse(map.containsValue("something"));}
public void mahout_f4423_0()
{    Map<String, String> map = new FastMap<>();    assertNull(map.get(null));    map.put(null, "bar");}
public void mahout_f4424_0()
{    Map<String, String> map = new FastMap<>();    map.put("foo", null);}
public void mahout_f4425_0()
{    FastMap<String, String> map = buildTestFastMap();    map.remove("foo");    map.rehash();    assertNull(map.get("foo"));    assertEquals("bang", map.get("baz"));}
public void mahout_f4426_0()
{    Map<String, String> map = new FastMap<>(1, FastMap.NO_MAX_SIZE);    map.put("foo", "bar");    map.put("baz", "bang");    assertEquals("bar", map.get("foo"));    assertEquals("bang", map.get("baz"));}
public void mahout_f4427_0()
{    FastMap<String, String> map = buildTestFastMap();    Collection<String> expected = Sets.newHashSetWithExpectedSize(3);    expected.add("foo");    expected.add("baz");    expected.add("alpha");    Set<String> actual = map.keySet();    assertTrue(expected.containsAll(actual));    assertTrue(actual.containsAll(expected));    Iterator<String> it = actual.iterator();    while (it.hasNext()) {        String value = it.next();        if (!"baz".equals(value)) {            it.remove();        }    }    assertTrue(map.containsKey("baz"));    assertFalse(map.containsKey("foo"));    assertFalse(map.containsKey("alpha"));}
public void mahout_f4428_0()
{    FastMap<String, String> map = buildTestFastMap();    Collection<String> expected = Sets.newHashSetWithExpectedSize(3);    expected.add("bar");    expected.add("bang");    expected.add("beta");    Collection<String> actual = map.values();    assertTrue(expected.containsAll(actual));    assertTrue(actual.containsAll(expected));    Iterator<String> it = actual.iterator();    while (it.hasNext()) {        String value = it.next();        if (!"bang".equals(value)) {            it.remove();        }    }    assertTrue(map.containsValue("bang"));    assertFalse(map.containsValue("bar"));    assertFalse(map.containsValue("beta"));}
public void mahout_f4429_0()
{    FastMap<String, String> map = buildTestFastMap();    Set<Map.Entry<String, String>> actual = map.entrySet();    Collection<String> expectedKeys = Sets.newHashSetWithExpectedSize(3);    expectedKeys.add("foo");    expectedKeys.add("baz");    expectedKeys.add("alpha");    Collection<String> expectedValues = Sets.newHashSetWithExpectedSize(3);    expectedValues.add("bar");    expectedValues.add("bang");    expectedValues.add("beta");    assertEquals(3, actual.size());    for (Map.Entry<String, String> entry : actual) {        expectedKeys.remove(entry.getKey());        expectedValues.remove(entry.getValue());    }    assertEquals(0, expectedKeys.size());    assertEquals(0, expectedValues.size());}
public void mahout_f4430_0()
{    Map<Integer, String> actual = new FastMap<>(1, 1000000);    Map<Integer, String> expected = Maps.newHashMapWithExpectedSize(1000000);    Random r = RandomUtils.getRandom();    for (int i = 0; i < 1000000; i++) {        double d = r.nextDouble();        Integer key = r.nextInt(100);        if (d < 0.4) {            assertEquals(expected.get(key), actual.get(key));        } else {            if (d < 0.7) {                assertEquals(expected.put(key, "foo"), actual.put(key, "foo"));            } else {                assertEquals(expected.remove(key), actual.remove(key));            }            assertEquals(expected.size(), actual.size());            assertEquals(expected.isEmpty(), actual.isEmpty());        }    }}
public void mahout_f4431_0()
{    Map<String, String> map = new FastMap<>(1, 1);    map.put("foo", "bar");    assertEquals(1, map.size());    map.put("baz", "bang");    assertEquals(1, map.size());    assertNull(map.get("foo"));    map.put("baz", "buzz");    assertEquals(1, map.size());    assertEquals("buzz", map.get("baz"));}
private static FastMap<String, String> mahout_f4432_0()
{    FastMap<String, String> map = new FastMap<>();    map.put("foo", "bar");    map.put("baz", "bang");    map.put("alpha", "beta");    return map;}
public void mahout_f4433_0()
{    RunningAverage avg = new FullRunningAverage();    RunningAverage inverted = new InvertedRunningAverage(avg);    assertEquals(0, inverted.getCount());    avg.addDatum(1.0);    assertEquals(1, inverted.getCount());    assertEquals(-1.0, inverted.getAverage(), EPSILON);    avg.addDatum(2.0);    assertEquals(2, inverted.getCount());    assertEquals(-1.5, inverted.getAverage(), EPSILON);}
public void mahout_f4434_0()
{    RunningAverage inverted = new InvertedRunningAverage(new FullRunningAverage());    inverted.addDatum(1.0);}
public void mahout_f4435_0()
{    RunningAverage inverted = new InvertedRunningAverage(new FullRunningAverage());    inverted.changeDatum(1.0);}
public void mahout_f4436_0()
{    RunningAverage inverted = new InvertedRunningAverage(new FullRunningAverage());    inverted.removeDatum(1.0);}
public void mahout_f4437_0()
{    RunningAverageAndStdDev avg = new FullRunningAverageAndStdDev();    RunningAverageAndStdDev inverted = new InvertedRunningAverageAndStdDev(avg);    assertEquals(0, inverted.getCount());    avg.addDatum(1.0);    assertEquals(1, inverted.getCount());    assertEquals(-1.0, inverted.getAverage(), EPSILON);    avg.addDatum(2.0);    assertEquals(2, inverted.getCount());    assertEquals(-1.5, inverted.getAverage(), EPSILON);    assertEquals(Math.sqrt(2.0) / 2.0, inverted.getStandardDeviation(), EPSILON);}
public void mahout_f4438_0()
{    RunningAverage inverted = new InvertedRunningAverageAndStdDev(new FullRunningAverageAndStdDev());    inverted.addDatum(1.0);}
public void mahout_f4439_0()
{    RunningAverage inverted = new InvertedRunningAverageAndStdDev(new FullRunningAverageAndStdDev());    inverted.changeDatum(1.0);}
public void mahout_f4440_0()
{    RunningAverage inverted = new InvertedRunningAverageAndStdDev(new FullRunningAverageAndStdDev());    inverted.removeDatum(1.0);}
public void mahout_f4441_0()
{    LongPrimitiveIterator it = new LongPrimitiveArrayIterator(new long[0]);    assertFalse(it.hasNext());    it.next();}
public void mahout_f4442_0()
{    LongPrimitiveIterator it = new LongPrimitiveArrayIterator(new long[] { 3, 2, 1 });    assertTrue(it.hasNext());    assertEquals(3, (long) it.next());    assertTrue(it.hasNext());    assertEquals(2, it.nextLong());    assertTrue(it.hasNext());    assertEquals(1, (long) it.next());    assertFalse(it.hasNext());    it.nextLong();}
public void mahout_f4443_0()
{    LongPrimitiveIterator it = new LongPrimitiveArrayIterator(new long[] { 3, 2, 1 });    assertEquals(3, it.peek());    it.skip(2);    assertEquals(1, it.nextLong());    assertFalse(it.hasNext());}
public void mahout_f4444_0(Collection<Refreshable> alreadyRefreshed)
{    call();}
public Object mahout_f4445_0()
{    callCount++;    return null;}
 int mahout_f4446_0()
{    return callCount;}
public void mahout_f4447_0()
{    MockRefreshable mock = new MockRefreshable();    Refreshable helper = new RefreshHelper(mock);    helper.refresh(null);    assertEquals(1, mock.getCallCount());}
public void mahout_f4448_0()
{    Refreshable helper = new RefreshHelper(null);    helper.refresh(null);}
public void mahout_f4449_0()
{    RefreshHelper helper = new RefreshHelper(null);    MockRefreshable mock1 = new MockRefreshable();    MockRefreshable mock2 = new MockRefreshable();    helper.addDependency(mock1);    helper.addDependency(mock2);    helper.refresh(null);    assertEquals(1, mock1.getCallCount());    assertEquals(1, mock2.getCallCount());}
public void mahout_f4450_0()
{    RefreshHelper helper = new RefreshHelper(null);    MockRefreshable mock1 = new MockRefreshable();    MockRefreshable mock2 = new MockRefreshable();    helper.addDependency(mock1);    helper.addDependency(mock2);    Collection<Refreshable> alreadyRefreshed = Sets.newHashSetWithExpectedSize(1);    alreadyRefreshed.add(mock1);    helper.refresh(alreadyRefreshed);    assertEquals(0, mock1.getCallCount());    assertEquals(1, mock2.getCallCount());}
public void mahout_f4451_0()
{    RunningAverageAndStdDev average = new FullRunningAverageAndStdDev();    assertEquals(0, average.getCount());    assertTrue(Double.isNaN(average.getAverage()));    assertTrue(Double.isNaN(average.getStandardDeviation()));    average.addDatum(6.0);    assertEquals(1, average.getCount());    assertEquals(6.0, average.getAverage(), EPSILON);    assertTrue(Double.isNaN(average.getStandardDeviation()));    average.addDatum(6.0);    assertEquals(2, average.getCount());    assertEquals(6.0, average.getAverage(), EPSILON);    assertEquals(0.0, average.getStandardDeviation(), EPSILON);    average.removeDatum(6.0);    assertEquals(1, average.getCount());    assertEquals(6.0, average.getAverage(), EPSILON);    assertTrue(Double.isNaN(average.getStandardDeviation()));    average.addDatum(-4.0);    assertEquals(2, average.getCount());    assertEquals(1.0, average.getAverage(), EPSILON);    assertEquals(5.0 * 1.4142135623730951, average.getStandardDeviation(), EPSILON);    average.removeDatum(4.0);    assertEquals(1, average.getCount());    assertEquals(-2.0, average.getAverage(), EPSILON);    assertTrue(Double.isNaN(average.getStandardDeviation()));}
public void mahout_f4452_0()
{    RunningAverageAndStdDev average = new FullRunningAverageAndStdDev();    Random r = RandomUtils.getRandom();    for (int i = 0; i < 100000; i++) {        average.addDatum(r.nextDouble() * 1000.0);    }    assertEquals(500.0, average.getAverage(), SMALL_EPSILON);    assertEquals(1000.0 / Math.sqrt(12.0), average.getStandardDeviation(), SMALL_EPSILON);}
public void mahout_f4453_0()
{    RunningAverageAndStdDev runningAverage = new FullRunningAverageAndStdDev();    assertEquals(0, runningAverage.getCount());    assertTrue(Double.isNaN(runningAverage.getAverage()));    runningAverage.addDatum(1.0);    assertEquals(1, runningAverage.getCount());    assertEquals(1.0, runningAverage.getAverage(), EPSILON);    assertTrue(Double.isNaN(runningAverage.getStandardDeviation()));    runningAverage.addDatum(1.0);    assertEquals(2, runningAverage.getCount());    assertEquals(1.0, runningAverage.getAverage(), EPSILON);    assertEquals(0.0, runningAverage.getStandardDeviation(), EPSILON);    runningAverage.addDatum(7.0);    assertEquals(3, runningAverage.getCount());    assertEquals(3.0, runningAverage.getAverage(), EPSILON);    assertEquals(3.464101552963257, runningAverage.getStandardDeviation(), EPSILON);    runningAverage.addDatum(5.0);    assertEquals(4, runningAverage.getCount());    assertEquals(3.5, runningAverage.getAverage(), EPSILON);    assertEquals(3.0, runningAverage.getStandardDeviation(), EPSILON);}
public void mahout_f4454_0()
{    RunningAverage runningAverage = new FullRunningAverage();    assertEquals(0, runningAverage.getCount());    assertTrue(Double.isNaN(runningAverage.getAverage()));    runningAverage.addDatum(1.0);    assertEquals(1, runningAverage.getCount());    assertEquals(1.0, runningAverage.getAverage(), EPSILON);    runningAverage.addDatum(1.0);    assertEquals(2, runningAverage.getCount());    assertEquals(1.0, runningAverage.getAverage(), EPSILON);    runningAverage.addDatum(4.0);    assertEquals(3, runningAverage.getCount());    assertEquals(2.0, runningAverage.getAverage(), EPSILON);    runningAverage.addDatum(-4.0);    assertEquals(4, runningAverage.getCount());    assertEquals(0.5, runningAverage.getAverage(), EPSILON);    runningAverage.removeDatum(-4.0);    assertEquals(3, runningAverage.getCount());    assertEquals(2.0, runningAverage.getAverage(), EPSILON);    runningAverage.removeDatum(4.0);    assertEquals(2, runningAverage.getCount());    assertEquals(1.0, runningAverage.getAverage(), EPSILON);    runningAverage.changeDatum(0.0);    assertEquals(2, runningAverage.getCount());    assertEquals(1.0, runningAverage.getAverage(), EPSILON);    runningAverage.changeDatum(2.0);    assertEquals(2, runningAverage.getCount());    assertEquals(2.0, runningAverage.getAverage(), EPSILON);}
public void mahout_f4455_0()
{    RunningAverage runningAverage = new FullRunningAverage();    runningAverage.addDatum(1.0);    runningAverage.addDatum(1.0);    assertEquals(2, runningAverage.getCount());    assertEquals(1.0, runningAverage.getAverage(), EPSILON);    RunningAverage copy = new FullRunningAverage(runningAverage.getCount(), runningAverage.getAverage());    assertEquals(2, copy.getCount());    assertEquals(1.0, copy.getAverage(), EPSILON);}
public void mahout_f4456_0()
{    assertFalse(new SamplingLongPrimitiveIterator(countingIterator(0), 0.9999).hasNext());    assertFalse(new SamplingLongPrimitiveIterator(countingIterator(0), 1).hasNext());}
public void mahout_f4457_0()
{    SamplingLongPrimitiveIterator t = new SamplingLongPrimitiveIterator(countingIterator(1), 0.9999);    assertTrue(t.hasNext());    assertEquals(0L, t.nextLong());    assertFalse(t.hasNext());}
public void mahout_f4458_0()
{    new SamplingLongPrimitiveIterator(countingIterator(1), 0.0);}
public void mahout_f4459_0()
{    new SamplingLongPrimitiveIterator(countingIterator(1), 1.1);}
public void mahout_f4460_0()
{    SamplingLongPrimitiveIterator t = new SamplingLongPrimitiveIterator(countingIterator(10), 1);    for (int i = 0; i < 10; i++) {        assertTrue(t.hasNext());        assertEquals(i, t.next().intValue());    }    assertFalse(t.hasNext());}
public void mahout_f4461_0()
{    double p = 0.1;    int n = 1000;    double sd = Math.sqrt(n * p * (1.0 - p));    for (int i = 0; i < 1000; i++) {        SamplingLongPrimitiveIterator t = new SamplingLongPrimitiveIterator(countingIterator(n), p);        int k = 0;        while (t.hasNext()) {            long v = t.nextLong();            k++;            assertTrue(v >= 0L);            assertTrue(v < 1000L);        }                assertTrue(k >= 100 - 5 * sd);        assertTrue(k <= 100 + 5 * sd);    }}
private static LongPrimitiveArrayIterator mahout_f4462_0(int to)
{    long[] data = new long[to];    for (int i = 0; i < to; i++) {        data[i] = i;    }    return new LongPrimitiveArrayIterator(data);}
public void mahout_f4463_0()
{    WeightedRunningAverage runningAverage = new WeightedRunningAverage();    assertEquals(0, runningAverage.getCount());    assertTrue(Double.isNaN(runningAverage.getAverage()));    runningAverage.addDatum(1.0, 2.0);    assertEquals(1.0, runningAverage.getAverage(), EPSILON);    runningAverage.addDatum(1.0);    assertEquals(1.0, runningAverage.getAverage(), EPSILON);    runningAverage.addDatum(8.0, 0.5);    assertEquals(2.0, runningAverage.getAverage(), EPSILON);    runningAverage.addDatum(-4.0);    assertEquals(2.0 / 3.0, runningAverage.getAverage(), EPSILON);    runningAverage.removeDatum(-4.0);    assertEquals(2.0, runningAverage.getAverage(), EPSILON);    runningAverage.removeDatum(2.0, 2.0);    assertEquals(2.0, runningAverage.getAverage(), EPSILON);    runningAverage.changeDatum(0.0);    assertEquals(2.0, runningAverage.getAverage(), EPSILON);    runningAverage.changeDatum(4.0, 0.5);    assertEquals(5.0 / 1.5, runningAverage.getAverage(), EPSILON);}
public void mahout_f4464_0()
{    WeightedRunningAverageAndStdDev runningAverage = new WeightedRunningAverageAndStdDev();    assertEquals(0, runningAverage.getCount());    assertTrue(Double.isNaN(runningAverage.getAverage()));    assertTrue(Double.isNaN(runningAverage.getStandardDeviation()));    runningAverage.addDatum(1.0);    assertEquals(1.0, runningAverage.getAverage(), EPSILON);    assertTrue(Double.isNaN(runningAverage.getStandardDeviation()));    runningAverage.addDatum(1.0, 2.0);    assertEquals(1.0, runningAverage.getAverage(), EPSILON);    assertEquals(0.0, runningAverage.getStandardDeviation(), EPSILON);    runningAverage.addDatum(8.0, 0.5);    assertEquals(2.0, runningAverage.getAverage(), EPSILON);    assertEquals(Math.sqrt(10.5), runningAverage.getStandardDeviation(), EPSILON);    runningAverage.addDatum(-4.0);    assertEquals(2.0 / 3.0, runningAverage.getAverage(), EPSILON);    assertEquals(Math.sqrt(15.75), runningAverage.getStandardDeviation(), EPSILON);    runningAverage.removeDatum(-4.0);    assertEquals(2.0, runningAverage.getAverage(), EPSILON);    assertEquals(Math.sqrt(10.5), runningAverage.getStandardDeviation(), EPSILON);    runningAverage.removeDatum(2.0, 2.0);    assertEquals(2.0, runningAverage.getAverage(), EPSILON);    assertEquals(Math.sqrt(31.5), runningAverage.getStandardDeviation(), EPSILON);}
public void mahout_f4465_0() throws Exception
{    DataModel model = getBooleanDataModel();    RecommenderBuilder builder = new RecommenderBuilder() {        @Override        public Recommender buildRecommender(DataModel dataModel) {            return new GenericBooleanPrefItemBasedRecommender(dataModel, new LogLikelihoodSimilarity(dataModel));        }    };    DataModelBuilder dataModelBuilder = new DataModelBuilder() {        @Override        public DataModel buildDataModel(FastByIDMap<PreferenceArray> trainingData) {            return new GenericBooleanPrefDataModel(GenericBooleanPrefDataModel.toDataMap(trainingData));        }    };    RecommenderIRStatsEvaluator evaluator = new GenericRecommenderIRStatsEvaluator();    IRStatistics stats = evaluator.evaluate(builder, dataModelBuilder, model, null, 1, GenericRecommenderIRStatsEvaluator.CHOOSE_THRESHOLD, 1.0);    assertNotNull(stats);    assertEquals(0.666666666, stats.getPrecision(), EPSILON);    assertEquals(0.666666666, stats.getRecall(), EPSILON);    assertEquals(0.666666666, stats.getF1Measure(), EPSILON);    assertEquals(0.666666666, stats.getFNMeasure(2.0), EPSILON);    assertEquals(0.666666666, stats.getNormalizedDiscountedCumulativeGain(), EPSILON);}
public Recommender mahout_f4466_0(DataModel dataModel)
{    return new GenericBooleanPrefItemBasedRecommender(dataModel, new LogLikelihoodSimilarity(dataModel));}
public DataModel mahout_f4467_0(FastByIDMap<PreferenceArray> trainingData)
{    return new GenericBooleanPrefDataModel(GenericBooleanPrefDataModel.toDataMap(trainingData));}
public void mahout_f4468_0()
{    IRStatistics stats = new IRStatisticsImpl(0.3, 0.1, 0.2, 0.05, 0.15);    assertEquals(0.3, stats.getPrecision(), EPSILON);    assertEquals(0.1, stats.getRecall(), EPSILON);    assertEquals(0.15, stats.getF1Measure(), EPSILON);    assertEquals(0.11538461538462, stats.getFNMeasure(2.0), EPSILON);    assertEquals(0.05, stats.getNormalizedDiscountedCumulativeGain(), EPSILON);}
public static void mahout_f4469_0(String[] args) throws Exception
{    DataModel model = new FileDataModel(new File(args[0]));    int howMany = 10;    if (args.length > 1) {        howMany = Integer.parseInt(args[1]);    }    System.out.println("Run Items");    ItemSimilarity similarity = new EuclideanDistanceSimilarity(model);        Recommender recommender = new GenericItemBasedRecommender(model, similarity);    for (int i = 0; i < LOOPS; i++) {        LoadStatistics loadStats = LoadEvaluator.runLoad(recommender, howMany);        System.out.println(loadStats);    }    System.out.println("Run Users");    UserSimilarity userSim = new EuclideanDistanceSimilarity(model);    UserNeighborhood neighborhood = new NearestNUserNeighborhood(10, userSim, model);    recommender = new GenericUserBasedRecommender(model, neighborhood, userSim);    for (int i = 0; i < LOOPS; i++) {        LoadStatistics loadStats = LoadEvaluator.runLoad(recommender, howMany);        System.out.println(loadStats);    }}
public void mahout_f4470_0()
{    PreferenceArray prefs = new BooleanItemPreferenceArray(3);    assertEquals(3, prefs.length());    prefs.setItemID(0, 1L);    assertEquals(1L, prefs.getItemID(0));    assertEquals(1L, prefs.getItemID(1));    assertEquals(1L, prefs.getItemID(2));}
public void mahout_f4471_0()
{    PreferenceArray prefs = new BooleanItemPreferenceArray(3);    assertEquals(3, prefs.length());    prefs.setUserID(0, 1L);    prefs.setUserID(1, 2L);    prefs.setUserID(2, 3L);    assertEquals(1L, prefs.getUserID(0));    assertEquals(2L, prefs.getUserID(1));    assertEquals(3L, prefs.getUserID(2));}
public void mahout_f4472_0()
{    PreferenceArray prefs = new BooleanItemPreferenceArray(3);    assertEquals(3, prefs.length());    assertEquals(1.0f, prefs.getValue(2), EPSILON);    prefs.setValue(0, 1.0f);}
public void mahout_f4473_0()
{    PreferenceArray prefs = new BooleanItemPreferenceArray(3);    prefs.set(0, new GenericPreference(1L, 3L, 5.0f));    assertTrue(prefs.hasPrefWithItemID(3L));    assertTrue(prefs.hasPrefWithUserID(1L));    assertFalse(prefs.hasPrefWithItemID(2L));    assertFalse(prefs.hasPrefWithUserID(2L));}
public void mahout_f4474_0()
{    PreferenceArray prefs = new BooleanItemPreferenceArray(3);    prefs.set(0, new GenericPreference(3L, 1L, 5.0f));    prefs.set(1, new GenericPreference(1L, 1L, 5.0f));    prefs.set(2, new GenericPreference(2L, 1L, 5.0f));    prefs.sortByUser();    assertEquals(1L, prefs.getUserID(0));    assertEquals(2L, prefs.getUserID(1));    assertEquals(3L, prefs.getUserID(2));}
public void mahout_f4475_0()
{    BooleanItemPreferenceArray prefs = new BooleanItemPreferenceArray(3);    prefs.set(0, new BooleanPreference(3L, 1L));    prefs.set(1, new BooleanPreference(1L, 1L));    prefs.set(2, new BooleanPreference(2L, 1L));    prefs = prefs.clone();    assertEquals(3L, prefs.getUserID(0));    assertEquals(1L, prefs.getItemID(1));}
public void mahout_f4476_0()
{    PreferenceArray prefs = new BooleanUserPreferenceArray(3);    assertEquals(3, prefs.length());    prefs.setUserID(0, 1L);    assertEquals(1L, prefs.getUserID(0));    assertEquals(1L, prefs.getUserID(1));    assertEquals(1L, prefs.getUserID(2));}
public void mahout_f4477_0()
{    PreferenceArray prefs = new BooleanUserPreferenceArray(3);    assertEquals(3, prefs.length());    prefs.setItemID(0, 1L);    prefs.setItemID(1, 2L);    prefs.setItemID(2, 3L);    assertEquals(1L, prefs.getItemID(0));    assertEquals(2L, prefs.getItemID(1));    assertEquals(3L, prefs.getItemID(2));}
public void mahout_f4478_0()
{    PreferenceArray prefs = new BooleanUserPreferenceArray(3);    assertEquals(1.0f, prefs.getValue(2), EPSILON);    assertEquals(3, prefs.length());    prefs.setValue(0, 1.0f);}
public void mahout_f4479_0()
{    PreferenceArray prefs = new BooleanUserPreferenceArray(3);    prefs.set(0, new GenericPreference(1L, 3L, 5.0f));    assertTrue(prefs.hasPrefWithItemID(3L));    assertTrue(prefs.hasPrefWithUserID(1L));    assertFalse(prefs.hasPrefWithItemID(2L));    assertFalse(prefs.hasPrefWithUserID(2L));}
public void mahout_f4480_0()
{    PreferenceArray prefs = new BooleanUserPreferenceArray(3);    prefs.set(0, new BooleanPreference(1L, 3L));    prefs.set(1, new BooleanPreference(1L, 1L));    prefs.set(2, new BooleanPreference(1L, 2L));    prefs.sortByItem();    assertEquals(1L, prefs.getItemID(0));    assertEquals(2L, prefs.getItemID(1));    assertEquals(3L, prefs.getItemID(2));}
public void mahout_f4481_0()
{    BooleanUserPreferenceArray prefs = new BooleanUserPreferenceArray(3);    prefs.set(0, new BooleanPreference(1L, 3L));    prefs.set(1, new BooleanPreference(1L, 1L));    prefs.set(2, new BooleanPreference(1L, 2L));    prefs = prefs.clone();    assertEquals(3L, prefs.getItemID(0));    assertEquals(1L, prefs.getUserID(1));}
public void mahout_f4482_0() throws Exception
{    super.setUp();    testFile = getTestTempFile("test.txt");    writeLines(testFile, DATA);    model = new FileDataModel(testFile);}
public void mahout_f4483_0() throws Exception
{    File testFile = getTestTempFile("testRegex.txt");    writeLines(testFile, DATA_SPLITTED_WITH_TWO_SPACES);    FileDataModel model = new FileDataModel(testFile, "\\s+");    assertEquals(model.getItemIDsFromUser(123).size(), 3);    assertEquals(model.getItemIDsFromUser(456).size(), 4);}
public void mahout_f4484_0() throws Exception
{    UserSimilarity userSimilarity = new PearsonCorrelationSimilarity(model);    UserNeighborhood neighborhood = new NearestNUserNeighborhood(3, userSimilarity, model);    Recommender recommender = new GenericUserBasedRecommender(model, neighborhood, userSimilarity);    assertEquals(1, recommender.recommend(123, 3).size());    assertEquals(0, recommender.recommend(234, 3).size());    assertEquals(1, recommender.recommend(345, 3).size());        model.refresh(null);}
public void mahout_f4485_0() throws Exception
{    FileDataModel tModel = new FileDataModel(testFile, true, FileDataModel.DEFAULT_MIN_RELOAD_INTERVAL_MS);    PreferenceArray userPrefs = tModel.getPreferencesFromUser(456);    assertNotNull("user prefs are null and it shouldn't be", userPrefs);    PreferenceArray pref = tModel.getPreferencesForItem(123);    assertNotNull("pref is null and it shouldn't be", pref);    assertEquals("pref Size: " + pref.length() + " is not: " + 3, 3, pref.length());}
public void mahout_f4486_0() throws Exception
{    LongPrimitiveIterator it = model.getItemIDs();    assertNotNull(it);    assertTrue(it.hasNext());    assertEquals(123, it.nextLong());    assertTrue(it.hasNext());    assertEquals(234, it.nextLong());    assertTrue(it.hasNext());    assertEquals(456, it.nextLong());    assertTrue(it.hasNext());    assertEquals(654, it.nextLong());    assertTrue(it.hasNext());    assertEquals(789, it.nextLong());    assertTrue(it.hasNext());    assertEquals(999, it.nextLong());    assertFalse(it.hasNext());    it.next();}
public void mahout_f4487_0() throws Exception
{    PreferenceArray prefs = model.getPreferencesForItem(456);    assertNotNull(prefs);    Preference pref1 = prefs.get(0);    assertEquals(123, pref1.getUserID());    assertEquals(456, pref1.getItemID());    Preference pref2 = prefs.get(1);    assertEquals(456, pref2.getUserID());    assertEquals(456, pref2.getItemID());    assertEquals(2, prefs.length());}
public void mahout_f4488_0() throws Exception
{    assertEquals(4, model.getNumUsers());}
public void mahout_f4489_0() throws Exception
{    assertEquals(2, model.getNumUsersWithPreferenceFor(456));    assertEquals(0, model.getNumUsersWithPreferenceFor(111));    assertEquals(0, model.getNumUsersWithPreferenceFor(111, 456));    assertEquals(2, model.getNumUsersWithPreferenceFor(123, 234));}
public void mahout_f4490_0() throws Exception
{    final MutableBoolean initialized = new MutableBoolean(false);    Runnable initializer = new Runnable() {        @Override        public void run() {            try {                model.getNumUsers();                initialized.setValue(true);            } catch (TasteException te) {                        }        }    };    new Thread(initializer).start();        Thread.sleep(1000L);        model.getNumUsers();    assertTrue(initialized.booleanValue());    assertEquals(4, model.getNumUsers());}
public void mahout_f4491_0()
{    try {        model.getNumUsers();        initialized.setValue(true);    } catch (TasteException te) {        }}
public void mahout_f4492_0() throws Exception
{    File file = getTestTempFile("refresh");    writeLines(file, "123,456,3.0");    /* create a FileDataModel that always reloads when the underlying file has changed */    FileDataModel dataModel = new FileDataModel(file, false, 0L);    assertEquals(3.0f, dataModel.getPreferenceValue(123L, 456L), EPSILON);    /* change the underlying file,     * we have to wait at least a second to see the change in the file's lastModified timestamp */    Thread.sleep(2000L);    writeLines(file, "123,456,5.0");    dataModel.refresh(null);    assertEquals(5.0f, dataModel.getPreferenceValue(123L, 456L), EPSILON);}
public void mahout_f4493_0()
{    assertFalse(model.toString().isEmpty());}
public void mahout_f4494_0() throws Exception
{    File file = getTestTempFile("empty");        writeLines(file);    new FileDataModel(file);}
public void mahout_f4495_0() throws Exception
{    super.setUp();    testFile = getTestTempFile("test.txt");    writeLines(testFile, STRING_IDS);}
public void mahout_f4496_0() throws Exception
{    IDMigrator migrator = new FileIDMigrator(testFile);    long dogAsLong = migrator.toLongID("dog");    long cowAsLong = migrator.toLongID("cow");    long donkeyAsLong = migrator.toLongID("donkey");    assertEquals("dog", migrator.toStringID(dogAsLong));    assertEquals("cow", migrator.toStringID(cowAsLong));    assertNull(migrator.toStringID(donkeyAsLong));}
public void mahout_f4497_0() throws Exception
{    IDMigrator migrator = new FileIDMigrator(testFile, 0L);    /* call a method to make sure the original file is loaded */    long dogAsLong = migrator.toLongID("dog");    migrator.toStringID(dogAsLong);    /* change the underlying file,     * we have to wait at least a second to see the change in the file's lastModified timestamp */    Thread.sleep(2000L);    writeLines(testFile, UPDATED_STRING_IDS);    /* we shouldn't see any changes in the data as we have not yet refreshed */    long cowAsLong = migrator.toLongID("cow");    long donkeyAsLong = migrator.toLongID("donkey");    assertEquals("dog", migrator.toStringID(dogAsLong));    assertEquals("cow", migrator.toStringID(cowAsLong));    assertNull(migrator.toStringID(donkeyAsLong));}
public void mahout_f4498_0() throws Exception
{    IDMigrator migrator = new FileIDMigrator(testFile, 0L);    /* call a method to make sure the original file is loaded */    long dogAsLong = migrator.toLongID("dog");    migrator.toStringID(dogAsLong);    /* change the underlying file,     * we have to wait at least a second to see the change in the file's lastModified timestamp */    Thread.sleep(2000L);    writeLines(testFile, UPDATED_STRING_IDS);    migrator.refresh(null);    long cowAsLong = migrator.toLongID("cow");    long donkeyAsLong = migrator.toLongID("donkey");    assertEquals("dog", migrator.toStringID(dogAsLong));    assertEquals("cow", migrator.toStringID(cowAsLong));    assertEquals("donkey", migrator.toStringID(donkeyAsLong));}
public void mahout_f4499_0() throws Exception
{    GenericDataModel model = (GenericDataModel) getDataModel();    ByteArrayOutputStream baos = new ByteArrayOutputStream();    ObjectOutputStream out = new ObjectOutputStream(baos);    out.writeObject(model);    ByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray());    ObjectInputStream in = new ObjectInputStream(bais);    GenericDataModel newModel = (GenericDataModel) in.readObject();    assertEquals(model.getNumItems(), newModel.getNumItems());    assertEquals(model.getNumUsers(), newModel.getNumUsers());    assertEquals(model.getPreferencesFromUser(1L), newModel.getPreferencesFromUser(1L));    assertEquals(model.getPreferencesForItem(1L), newModel.getPreferencesForItem(1L));    assertEquals(model.getRawUserData(), newModel.getRawUserData());}
public void mahout_f4500_0()
{    PreferenceArray prefs = new GenericItemPreferenceArray(3);    assertEquals(3, prefs.length());    prefs.setItemID(0, 1L);    assertEquals(1L, prefs.getItemID(0));    assertEquals(1L, prefs.getItemID(1));    assertEquals(1L, prefs.getItemID(2));}
public void mahout_f4501_0()
{    PreferenceArray prefs = new GenericItemPreferenceArray(3);    assertEquals(3, prefs.length());    prefs.setUserID(0, 1L);    prefs.setUserID(1, 2L);    prefs.setUserID(2, 3L);    assertEquals(1L, prefs.getUserID(0));    assertEquals(2L, prefs.getUserID(1));    assertEquals(3L, prefs.getUserID(2));}
public void mahout_f4502_0()
{    PreferenceArray prefs = new GenericItemPreferenceArray(3);    assertEquals(3, prefs.length());    prefs.setValue(0, 1.0f);    prefs.setValue(1, 2.0f);    prefs.setValue(2, 3.0f);    assertEquals(1.0f, prefs.getValue(0), EPSILON);    assertEquals(2.0f, prefs.getValue(1), EPSILON);    assertEquals(3.0f, prefs.getValue(2), EPSILON);}
public void mahout_f4503_0()
{    PreferenceArray prefs = new GenericItemPreferenceArray(3);    prefs.set(0, new GenericPreference(1L, 3L, 5.0f));    assertTrue(prefs.hasPrefWithItemID(3L));    assertTrue(prefs.hasPrefWithUserID(1L));    assertFalse(prefs.hasPrefWithItemID(2L));    assertFalse(prefs.hasPrefWithUserID(2L));}
public void mahout_f4504_0()
{    PreferenceArray prefs = new GenericItemPreferenceArray(3);    prefs.set(0, new GenericPreference(3L, 1L, 5.0f));    prefs.set(1, new GenericPreference(1L, 1L, 5.0f));    prefs.set(2, new GenericPreference(2L, 1L, 5.0f));    prefs.sortByUser();    assertEquals(1L, prefs.getUserID(0));    assertEquals(2L, prefs.getUserID(1));    assertEquals(3L, prefs.getUserID(2));}
public void mahout_f4505_0()
{    PreferenceArray prefs = new GenericItemPreferenceArray(3);    prefs.set(0, new GenericPreference(3L, 1L, 5.0f));    prefs.set(1, new GenericPreference(1L, 1L, 4.0f));    prefs.set(2, new GenericPreference(2L, 1L, 3.0f));    prefs.sortByValue();    assertEquals(2L, prefs.getUserID(0));    assertEquals(1L, prefs.getUserID(1));    assertEquals(3L, prefs.getUserID(2));    prefs.sortByValueReversed();    assertEquals(3L, prefs.getUserID(0));    assertEquals(1L, prefs.getUserID(1));    assertEquals(2L, prefs.getUserID(2));}
public void mahout_f4506_0()
{    GenericItemPreferenceArray prefs = new GenericItemPreferenceArray(3);    prefs.set(0, new GenericPreference(3L, 1L, 5.0f));    prefs.set(1, new GenericPreference(1L, 1L, 4.0f));    prefs.set(2, new GenericPreference(2L, 1L, 3.0f));    prefs = prefs.clone();    assertEquals(3L, prefs.getUserID(0));    assertEquals(1L, prefs.getItemID(1));    assertEquals(3.0f, prefs.getValue(2), EPSILON);}
public void mahout_f4507_0()
{    PreferenceArray prefs = new GenericUserPreferenceArray(3);    assertEquals(3, prefs.length());    prefs.setUserID(0, 1L);    assertEquals(1L, prefs.getUserID(0));    assertEquals(1L, prefs.getUserID(1));    assertEquals(1L, prefs.getUserID(2));}
public void mahout_f4508_0()
{    PreferenceArray prefs = new GenericUserPreferenceArray(3);    assertEquals(3, prefs.length());    prefs.setItemID(0, 1L);    prefs.setItemID(1, 2L);    prefs.setItemID(2, 3L);    assertEquals(1L, prefs.getItemID(0));    assertEquals(2L, prefs.getItemID(1));    assertEquals(3L, prefs.getItemID(2));}
public void mahout_f4509_0()
{    PreferenceArray prefs = new GenericUserPreferenceArray(3);    assertEquals(3, prefs.length());    prefs.setValue(0, 1.0f);    prefs.setValue(1, 2.0f);    prefs.setValue(2, 3.0f);    assertEquals(1.0f, prefs.getValue(0), EPSILON);    assertEquals(2.0f, prefs.getValue(1), EPSILON);    assertEquals(3.0f, prefs.getValue(2), EPSILON);}
public void mahout_f4510_0()
{    PreferenceArray prefs = new GenericUserPreferenceArray(3);    prefs.set(0, new GenericPreference(1L, 3L, 5.0f));    assertTrue(prefs.hasPrefWithItemID(3L));    assertTrue(prefs.hasPrefWithUserID(1L));    assertFalse(prefs.hasPrefWithItemID(2L));    assertFalse(prefs.hasPrefWithUserID(2L));}
public void mahout_f4511_0()
{    PreferenceArray prefs = new GenericUserPreferenceArray(3);    prefs.set(0, new GenericPreference(1L, 3L, 5.0f));    prefs.set(1, new GenericPreference(1L, 1L, 5.0f));    prefs.set(2, new GenericPreference(1L, 2L, 5.0f));    prefs.sortByItem();    assertEquals(1L, prefs.getItemID(0));    assertEquals(2L, prefs.getItemID(1));    assertEquals(3L, prefs.getItemID(2));}
public void mahout_f4512_0()
{    PreferenceArray prefs = new GenericUserPreferenceArray(3);    prefs.set(0, new GenericPreference(1L, 3L, 5.0f));    prefs.set(1, new GenericPreference(1L, 1L, 4.0f));    prefs.set(2, new GenericPreference(1L, 2L, 3.0f));    prefs.sortByValue();    assertEquals(2L, prefs.getItemID(0));    assertEquals(1L, prefs.getItemID(1));    assertEquals(3L, prefs.getItemID(2));    prefs.sortByValueReversed();    assertEquals(3L, prefs.getItemID(0));    assertEquals(1L, prefs.getItemID(1));    assertEquals(2L, prefs.getItemID(2));}
public void mahout_f4513_0()
{    GenericUserPreferenceArray prefs = new GenericUserPreferenceArray(3);    prefs.set(0, new GenericPreference(1L, 3L, 5.0f));    prefs.set(1, new GenericPreference(1L, 1L, 4.0f));    prefs.set(2, new GenericPreference(1L, 2L, 3.0f));    prefs = prefs.clone();    assertEquals(3L, prefs.getItemID(0));    assertEquals(1L, prefs.getUserID(1));    assertEquals(3.0f, prefs.getValue(2), EPSILON);}
public void mahout_f4514_0()
{    IDMigrator migrator = new MemoryIDMigrator();    long id = migrator.toLongID(DUMMY_STRING);    assertEquals(DUMMY_ID, id);}
public void mahout_f4515_0() throws Exception
{    UpdatableIDMigrator migrator = new MemoryIDMigrator();    long id = migrator.toLongID(DUMMY_STRING);    assertNull(migrator.toStringID(id));    migrator.storeMapping(id, DUMMY_STRING);    assertEquals(DUMMY_STRING, migrator.toStringID(id));}
public void mahout_f4516_0() throws Exception
{    UpdatableIDMigrator migrator = new MemoryIDMigrator();    long id = migrator.toLongID(DUMMY_STRING);    assertNull(migrator.toStringID(id));    migrator.initialize(Collections.singleton(DUMMY_STRING));    assertEquals(DUMMY_STRING, migrator.toStringID(id));}
private static PlusAnonymousConcurrentUserDataModel mahout_f4517_0(int maxConcurrentUsers)
{    FastByIDMap<PreferenceArray> delegatePreferences = new FastByIDMap<>();    return new PlusAnonymousConcurrentUserDataModel(new GenericDataModel(delegatePreferences), maxConcurrentUsers);}
private static PlusAnonymousConcurrentUserDataModel mahout_f4518_0(int maxConcurrentUsers, FastByIDMap<PreferenceArray> delegatePreferences)
{    return new PlusAnonymousConcurrentUserDataModel(new GenericDataModel(delegatePreferences), maxConcurrentUsers);}
public void mahout_f4519_0()
{    PlusAnonymousConcurrentUserDataModel instance = getTestableWithoutDelegateData(10);    Long expResult = PlusAnonymousUserDataModel.TEMP_USER_ID;    Long result = instance.takeAvailableUser();    assertEquals(expResult, result);}
public void mahout_f4520_0()
{    PlusAnonymousConcurrentUserDataModel instance = getTestableWithoutDelegateData(10);        instance.takeAvailableUser();    Long result = instance.takeAvailableUser();    Long expResult = PlusAnonymousUserDataModel.TEMP_USER_ID + 1;    assertEquals(expResult, result);}
public void mahout_f4521_0()
{    PlusAnonymousConcurrentUserDataModel instance = getTestableWithoutDelegateData(1);        instance.takeAvailableUser();        assertNull(instance.takeAvailableUser());}
public void mahout_f4522_0()
{    PlusAnonymousConcurrentUserDataModel instance = getTestableWithoutDelegateData(10);    Long takenUserID = instance.takeAvailableUser();    assertTrue(instance.releaseUser(takenUserID));}
public void mahout_f4523_0()
{    PlusAnonymousConcurrentUserDataModel instance = getTestableWithoutDelegateData(10);    assertFalse(instance.releaseUser(Long.MAX_VALUE));}
public void mahout_f4524_0()
{    PlusAnonymousConcurrentUserDataModel instance = getTestableWithoutDelegateData(10);    Long takenUserID = instance.takeAvailableUser();    assertTrue(instance.releaseUser(takenUserID));    assertFalse(instance.releaseUser(takenUserID));}
public void mahout_f4525_0() throws TasteException
{    PlusAnonymousConcurrentUserDataModel instance = getTestableWithoutDelegateData(10);    Long anonymousUserID = instance.takeAvailableUser();    PreferenceArray tempPrefs = new GenericUserPreferenceArray(1);    tempPrefs.setUserID(0, anonymousUserID);    tempPrefs.setItemID(0, 1);    instance.setTempPrefs(tempPrefs, anonymousUserID);    assertEquals(tempPrefs, instance.getPreferencesFromUser(anonymousUserID));    instance.releaseUser(anonymousUserID);}
public void mahout_f4526_0() throws TasteException
{    PlusAnonymousConcurrentUserDataModel instance = getTestableWithoutDelegateData(10);    Long anonymousUserID1 = instance.takeAvailableUser();    Long anonymousUserID2 = instance.takeAvailableUser();    PreferenceArray tempPrefs1 = new GenericUserPreferenceArray(1);    tempPrefs1.setUserID(0, anonymousUserID1);    tempPrefs1.setItemID(0, 1);    PreferenceArray tempPrefs2 = new GenericUserPreferenceArray(2);    tempPrefs2.setUserID(0, anonymousUserID2);    tempPrefs2.setItemID(0, 2);    tempPrefs2.setUserID(1, anonymousUserID2);    tempPrefs2.setItemID(1, 3);    instance.setTempPrefs(tempPrefs1, anonymousUserID1);    instance.setTempPrefs(tempPrefs2, anonymousUserID2);    assertEquals(tempPrefs1, instance.getPreferencesFromUser(anonymousUserID1));    assertEquals(tempPrefs2, instance.getPreferencesFromUser(anonymousUserID2));}
public void mahout_f4527_0() throws TasteException
{    PreferenceArray prefs = new GenericUserPreferenceArray(1);    long sampleUserID = 1;    prefs.setUserID(0, sampleUserID);    long sampleItemID = 11;    prefs.setItemID(0, sampleItemID);    FastByIDMap<PreferenceArray> delegatePreferences = new FastByIDMap<>();    delegatePreferences.put(sampleUserID, prefs);    PlusAnonymousConcurrentUserDataModel instance = getTestableWithDelegateData(10, delegatePreferences);    assertEquals(1, instance.getNumUsers());}
public void mahout_f4528_0() throws TasteException
{    PlusAnonymousConcurrentUserDataModel instance = getTestableWithoutDelegateData(10);    Long anonymousUserID1 = instance.takeAvailableUser();    PreferenceArray tempPrefs1 = new GenericUserPreferenceArray(1);    tempPrefs1.setUserID(0, anonymousUserID1);    tempPrefs1.setItemID(0, 1);    instance.setTempPrefs(tempPrefs1, anonymousUserID1);        assertEquals(0, instance.getNumUsers());}
public void mahout_f4529_0() throws TasteException
{    PlusAnonymousConcurrentUserDataModel instance = getTestableWithoutDelegateData(10);    Long anonymousUserID = instance.takeAvailableUser();    PreferenceArray tempPrefs = new GenericUserPreferenceArray(1);    tempPrefs.setUserID(0, anonymousUserID);    long sampleItemID = 1;    tempPrefs.setItemID(0, sampleItemID);    tempPrefs.setValue(0, Float.MAX_VALUE);    instance.setTempPrefs(tempPrefs, anonymousUserID);    assertEquals(Float.MAX_VALUE, instance.getPreferenceValue(anonymousUserID, sampleItemID), EPSILON);}
public void mahout_f4530_0() throws TasteException
{    PreferenceArray prefs = new GenericUserPreferenceArray(1);    long sampleUserID = 1;    prefs.setUserID(0, sampleUserID);    long sampleItemID = 11;    prefs.setItemID(0, sampleItemID);    FastByIDMap<PreferenceArray> delegatePreferences = new FastByIDMap<>();    delegatePreferences.put(sampleUserID, prefs);    PlusAnonymousConcurrentUserDataModel instance = getTestableWithDelegateData(10, delegatePreferences);    assertEquals(prefs, instance.getPreferencesFromUser(sampleUserID));}
public void mahout_f4531_0() throws TasteException
{    PlusAnonymousConcurrentUserDataModel instance = getTestableWithoutDelegateData(10);        instance.getPreferencesFromUser(1);}
public void mahout_f4532_0() throws TasteException
{    PreferenceArray prefs = new GenericUserPreferenceArray(1);    long sampleUserID = 1;    prefs.setUserID(0, sampleUserID);    long sampleItemID = 11;    prefs.setItemID(0, sampleItemID);    FastByIDMap<PreferenceArray> delegatePreferences = new FastByIDMap<>();    delegatePreferences.put(sampleUserID, prefs);    PlusAnonymousConcurrentUserDataModel instance = getTestableWithDelegateData(10, delegatePreferences);    Long anonymousUserID = instance.takeAvailableUser();    PreferenceArray tempPrefs = new GenericUserPreferenceArray(1);    tempPrefs.setUserID(0, anonymousUserID);    tempPrefs.setItemID(0, 22);    instance.setTempPrefs(tempPrefs, anonymousUserID);    Iterator<Long> userIDs = instance.getUserIDs();    assertSame(sampleUserID, userIDs.next());    assertFalse(userIDs.hasNext());}
public void mahout_f4533_0() throws TasteException
{    PreferenceArray prefs = new GenericUserPreferenceArray(2);    long sampleUserID = 4;    prefs.setUserID(0, sampleUserID);    long sampleItemID = 11;    prefs.setItemID(0, sampleItemID);    prefs.setUserID(1, sampleUserID);    long sampleItemID2 = 22;    prefs.setItemID(1, sampleItemID2);    FastByIDMap<PreferenceArray> delegatePreferences = new FastByIDMap<>();    delegatePreferences.put(sampleUserID, prefs);    PlusAnonymousConcurrentUserDataModel instance = getTestableWithDelegateData(10, delegatePreferences);    Long anonymousUserID = instance.takeAvailableUser();    PreferenceArray tempPrefs = new GenericUserPreferenceArray(2);    tempPrefs.setUserID(0, anonymousUserID);    tempPrefs.setItemID(0, sampleItemID);    tempPrefs.setUserID(1, anonymousUserID);    long sampleItemID3 = 33;    tempPrefs.setItemID(1, sampleItemID3);    instance.setTempPrefs(tempPrefs, anonymousUserID);    assertEquals(sampleUserID, instance.getPreferencesForItem(sampleItemID).get(0).getUserID());    assertEquals(2, instance.getPreferencesForItem(sampleItemID).length());    assertEquals(1, instance.getPreferencesForItem(sampleItemID2).length());    assertEquals(1, instance.getPreferencesForItem(sampleItemID3).length());    assertEquals(2, instance.getNumUsersWithPreferenceFor(sampleItemID));    assertEquals(1, instance.getNumUsersWithPreferenceFor(sampleItemID, sampleItemID2));    assertEquals(1, instance.getNumUsersWithPreferenceFor(sampleItemID, sampleItemID3));}
public double mahout_f4534_0(long userID1, long userID2) throws TasteException
{    DataModel dataModel = getDataModel();    return 1.0 / (1.0 + Math.abs(dataModel.getPreferencesFromUser(userID1).get(0).getValue() - dataModel.getPreferencesFromUser(userID2).get(0).getValue()));}
public double mahout_f4535_0(long itemID1, long itemID2)
{        return 1.0 / (1.0 + Math.abs(itemID1 - itemID2));}
public double[] mahout_f4536_0(long itemID1, long[] itemID2s)
{    int length = itemID2s.length;    double[] result = new double[length];    for (int i = 0; i < length; i++) {        result[i] = itemSimilarity(itemID1, itemID2s[i]);    }    return result;}
public void mahout_f4537_0(PreferenceInferrer inferrer)
{    throw new UnsupportedOperationException();}
public void mahout_f4538_0(Collection<Refreshable> alreadyRefreshed)
{}
public void mahout_f4539_0() throws Exception
{    DataModel dataModel = getDataModel();    long[] neighborhood = new NearestNUserNeighborhood(1, new DummySimilarity(dataModel), dataModel).getUserNeighborhood(1);    assertNotNull(neighborhood);    assertEquals(1, neighborhood.length);    assertTrue(arrayContains(neighborhood, 2));    long[] neighborhood2 = new NearestNUserNeighborhood(2, new DummySimilarity(dataModel), dataModel).getUserNeighborhood(2);    assertNotNull(neighborhood2);    assertEquals(2, neighborhood2.length);    assertTrue(arrayContains(neighborhood2, 1));    assertTrue(arrayContains(neighborhood2, 3));    long[] neighborhood3 = new NearestNUserNeighborhood(4, new DummySimilarity(dataModel), dataModel).getUserNeighborhood(4);    assertNotNull(neighborhood3);    assertEquals(3, neighborhood3.length);    assertTrue(arrayContains(neighborhood3, 1));    assertTrue(arrayContains(neighborhood3, 2));    assertTrue(arrayContains(neighborhood3, 3));}
public void mahout_f4540_0() throws Exception
{    DataModel dataModel = getDataModel();    long[] neighborhood = new ThresholdUserNeighborhood(1.0, new DummySimilarity(dataModel), dataModel).getUserNeighborhood(1);    assertNotNull(neighborhood);    assertEquals(0, neighborhood.length);    long[] neighborhood2 = new ThresholdUserNeighborhood(0.8, new DummySimilarity(dataModel), dataModel).getUserNeighborhood(1);    assertNotNull(neighborhood2);    assertEquals(1, neighborhood2.length);    assertTrue(arrayContains(neighborhood2, 2));    long[] neighborhood3 = new ThresholdUserNeighborhood(0.6, new DummySimilarity(dataModel), dataModel).getUserNeighborhood(2);    assertNotNull(neighborhood3);    assertEquals(3, neighborhood3.length);    assertTrue(arrayContains(neighborhood3, 1));    assertTrue(arrayContains(neighborhood3, 3));    assertTrue(arrayContains(neighborhood3, 4));}
public void mahout_f4541_0() throws TasteException
{    FastIDSet allItemIDs = new FastIDSet();    allItemIDs.addAll(new long[] { 1L, 2L, 3L });    FastIDSet preferredItemIDs = new FastIDSet(1);    preferredItemIDs.add(2L);    DataModel dataModel = EasyMock.createMock(DataModel.class);    EasyMock.expect(dataModel.getNumItems()).andReturn(3);    EasyMock.expect(dataModel.getItemIDs()).andReturn(allItemIDs.iterator());    PreferenceArray prefArrayOfUser123 = new GenericUserPreferenceArray(Collections.singletonList(new GenericPreference(123L, 2L, 1.0f)));    CandidateItemsStrategy strategy = new AllUnknownItemsCandidateItemsStrategy();    EasyMock.replay(dataModel);    FastIDSet candidateItems = strategy.getCandidateItems(123L, prefArrayOfUser123, dataModel, false);    assertEquals(2, candidateItems.size());    assertTrue(candidateItems.contains(1L));    assertTrue(candidateItems.contains(3L));    EasyMock.verify(dataModel);}
public void mahout_f4542_0() throws Exception
{    MutableInt recommendCount = new MutableInt();    Recommender mockRecommender = new MockRecommender(recommendCount);    Recommender cachingRecommender = new CachingRecommender(mockRecommender);    cachingRecommender.recommend(1, 1);    assertEquals(1, recommendCount.intValue());    cachingRecommender.recommend(2, 1);    assertEquals(2, recommendCount.intValue());    cachingRecommender.recommend(1, 1);    assertEquals(2, recommendCount.intValue());    cachingRecommender.recommend(2, 1);    assertEquals(2, recommendCount.intValue());    cachingRecommender.refresh(null);    cachingRecommender.recommend(1, 1);    assertEquals(3, recommendCount.intValue());    cachingRecommender.recommend(2, 1);    assertEquals(4, recommendCount.intValue());    cachingRecommender.recommend(3, 1);    assertEquals(5, recommendCount.intValue());        IDRescorer rescorer = NullRescorer.getItemInstance();    cachingRecommender.refresh(null);    cachingRecommender.recommend(1, 1, rescorer);    assertEquals(6, recommendCount.intValue());    cachingRecommender.recommend(2, 1, rescorer);    assertEquals(7, recommendCount.intValue());    cachingRecommender.recommend(1, 1, rescorer);    assertEquals(7, recommendCount.intValue());    cachingRecommender.recommend(2, 1, rescorer);    assertEquals(7, recommendCount.intValue());        cachingRecommender.recommend(1, 1, null);    assertEquals(8, recommendCount.intValue());    cachingRecommender.recommend(2, 1, null);    assertEquals(9, recommendCount.intValue());    cachingRecommender.refresh(null);    cachingRecommender.estimatePreference(1, 1);    assertEquals(10, recommendCount.intValue());    cachingRecommender.estimatePreference(1, 2);    assertEquals(11, recommendCount.intValue());    cachingRecommender.estimatePreference(1, 2);    assertEquals(11, recommendCount.intValue());}
public void mahout_f4543_0() throws Exception
{    Recommender recommender = buildRecommender();    List<RecommendedItem> recommended = recommender.recommend(1, 1);    assertNotNull(recommended);    assertEquals(1, recommended.size());    RecommendedItem firstRecommended = recommended.get(0);    assertEquals(2, firstRecommended.getItemID());    assertEquals(0.1f, firstRecommended.getValue(), EPSILON);    recommender.refresh(null);    recommended = recommender.recommend(1, 1);    firstRecommended = recommended.get(0);    assertEquals(2, firstRecommended.getItemID());    assertEquals(0.1f, firstRecommended.getValue(), EPSILON);}
public void mahout_f4544_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2, 3, 4, 5 }, new Double[][] { { 0.1, 0.2 }, { 0.2, 0.3, 0.3, 0.6 }, { 0.4, 0.4, 0.5, 0.9 }, { 0.1, 0.4, 0.5, 0.8, 0.9, 1.0 }, { 0.2, 0.3, 0.6, 0.7, 0.1, 0.2 } });    Collection<GenericItemSimilarity.ItemItemSimilarity> similarities = Lists.newArrayList();    for (int i = 0; i < 6; i++) {        for (int j = i + 1; j < 6; j++) {            similarities.add(new GenericItemSimilarity.ItemItemSimilarity(i, j, 1.0 / (1.0 + i + j)));        }    }    ItemSimilarity similarity = new GenericItemSimilarity(similarities);    Recommender recommender = new GenericItemBasedRecommender(dataModel, similarity);    List<RecommendedItem> fewRecommended = recommender.recommend(1, 2);    List<RecommendedItem> moreRecommended = recommender.recommend(1, 4);    for (int i = 0; i < fewRecommended.size(); i++) {        assertEquals(fewRecommended.get(i).getItemID(), moreRecommended.get(i).getItemID());    }    recommender.refresh(null);    for (int i = 0; i < fewRecommended.size(); i++) {        assertEquals(fewRecommended.get(i).getItemID(), moreRecommended.get(i).getItemID());    }}
public void mahout_f4545_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2, 3 }, new Double[][] { { 0.1, 0.2 }, { 0.2, 0.3, 0.3, 0.6 }, { 0.4, 0.4, 0.5, 0.9 } });    Collection<GenericItemSimilarity.ItemItemSimilarity> similarities = Lists.newArrayList();    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(0, 1, 1.0));    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(0, 2, 0.5));    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(0, 3, 0.2));    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(1, 2, 0.7));    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(1, 3, 0.5));    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(2, 3, 0.9));    ItemSimilarity similarity = new GenericItemSimilarity(similarities);    Recommender recommender = new GenericItemBasedRecommender(dataModel, similarity);    List<RecommendedItem> originalRecommended = recommender.recommend(1, 2);    List<RecommendedItem> rescoredRecommended = recommender.recommend(1, 2, new ReversingRescorer<Long>());    assertNotNull(originalRecommended);    assertNotNull(rescoredRecommended);    assertEquals(2, originalRecommended.size());    assertEquals(2, rescoredRecommended.size());    assertEquals(originalRecommended.get(0).getItemID(), rescoredRecommended.get(1).getItemID());    assertEquals(originalRecommended.get(1).getItemID(), rescoredRecommended.get(0).getItemID());}
public void mahout_f4546_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2, 3 }, new Double[][] { { 0.1, 0.2 }, { 0.2, 0.3, 0.3, 0.6 }, { 0.4, 0.4, 0.5, 0.9 } });    Collection<GenericItemSimilarity.ItemItemSimilarity> similarities = Lists.newArrayList();    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(0, 1, 0.8));    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(0, 2, 0.5));    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(0, 3, 0.2));    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(1, 2, 0.7));    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(1, 3, 0.5));    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(2, 3, 0.9));    ItemSimilarity similarity = new GenericItemSimilarity(similarities);    Recommender recommender = new GenericItemBasedRecommender(dataModel, similarity);    List<RecommendedItem> originalRecommended = recommender.recommend(1, 4, null, true);    List<RecommendedItem> rescoredRecommended = recommender.recommend(1, 4, new ReversingRescorer<Long>(), true);    assertNotNull(originalRecommended);    assertNotNull(rescoredRecommended);    assertEquals(4, originalRecommended.size());    assertEquals(4, rescoredRecommended.size());    assertEquals(originalRecommended.get(0).getItemID(), rescoredRecommended.get(3).getItemID());    assertEquals(originalRecommended.get(3).getItemID(), rescoredRecommended.get(0).getItemID());}
public void mahout_f4547_0() throws Exception
{    Recommender recommender = buildRecommender();    assertEquals(0.1f, recommender.estimatePreference(1, 2), EPSILON);}
public void mahout_f4548_0() throws Exception
{    Recommender recommender = buildRecommender();    List<RecommendedItem> recommended = recommender.recommend(1, 1);    assertNotNull(recommended);    assertEquals(1, recommended.size());    RecommendedItem firstRecommended = recommended.get(0);        assertEquals(2, firstRecommended.getItemID());    assertEquals(0.1f, firstRecommended.getValue(), EPSILON);}
public void mahout_f4549_0() throws Exception
{    ItemBasedRecommender recommender = buildRecommender();    List<RecommendedItem> similar = recommender.mostSimilarItems(0, 2);    assertNotNull(similar);    assertEquals(2, similar.size());    RecommendedItem first = similar.get(0);    RecommendedItem second = similar.get(1);    assertEquals(1, first.getItemID());    assertEquals(1.0f, first.getValue(), EPSILON);    assertEquals(2, second.getItemID());    assertEquals(0.5f, second.getValue(), EPSILON);}
public void mahout_f4550_0() throws Exception
{    ItemBasedRecommender recommender = buildRecommender2();    List<RecommendedItem> similar = recommender.mostSimilarItems(new long[] { 0, 1 }, 2);    assertNotNull(similar);    assertEquals(2, similar.size());    RecommendedItem first = similar.get(0);    RecommendedItem second = similar.get(1);    assertEquals(2, first.getItemID());    assertEquals(0.85f, first.getValue(), EPSILON);    assertEquals(3, second.getItemID());    assertEquals(-0.3f, second.getValue(), EPSILON);}
public void mahout_f4551_0() throws Exception
{    ItemBasedRecommender recommender = buildRecommender2();    List<RecommendedItem> similar = recommender.mostSimilarItems(new long[] { 3, 4 }, 2);    assertNotNull(similar);    assertEquals(1, similar.size());    RecommendedItem first = similar.get(0);    assertEquals(0, first.getItemID());    assertEquals(0.2f, first.getValue(), EPSILON);}
public void mahout_f4552_0() throws Exception
{    ItemBasedRecommender recommender = buildRecommender2();    List<RecommendedItem> similar = recommender.mostSimilarItems(new long[] { 1, 2, 4 }, 10, false);    assertNotNull(similar);    assertEquals(2, similar.size());    RecommendedItem first = similar.get(0);    RecommendedItem second = similar.get(1);    assertEquals(0, first.getItemID());    assertEquals(0.933333333f, first.getValue(), EPSILON);    assertEquals(3, second.getItemID());    assertEquals(-0.2f, second.getValue(), EPSILON);}
public void mahout_f4553_0() throws Exception
{    ItemBasedRecommender recommender = buildRecommender2();    List<RecommendedItem> recommendedBecause = recommender.recommendedBecause(1, 4, 3);    assertNotNull(recommendedBecause);    assertEquals(3, recommendedBecause.size());    RecommendedItem first = recommendedBecause.get(0);    RecommendedItem second = recommendedBecause.get(1);    RecommendedItem third = recommendedBecause.get(2);    assertEquals(2, first.getItemID());    assertEquals(0.99f, first.getValue(), EPSILON);    assertEquals(3, second.getItemID());    assertEquals(0.4f, second.getValue(), EPSILON);    assertEquals(0, third.getItemID());    assertEquals(0.2f, third.getValue(), EPSILON);}
private static ItemBasedRecommender mahout_f4554_0()
{    DataModel dataModel = getDataModel();    Collection<GenericItemSimilarity.ItemItemSimilarity> similarities = Lists.newArrayList();    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(0, 1, 1.0));    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(0, 2, 0.5));    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(1, 2, 0.0));    ItemSimilarity similarity = new GenericItemSimilarity(similarities);    return new GenericItemBasedRecommender(dataModel, similarity);}
private static ItemBasedRecommender mahout_f4555_0()
{    DataModel dataModel = getDataModel(new long[] { 1, 2, 3, 4 }, new Double[][] { { 0.1, 0.3, 0.9, 0.8 }, { 0.2, 0.3, 0.3, 0.4 }, { 0.4, 0.3, 0.5, 0.1, 0.1 }, { 0.7, 0.3, 0.8, 0.5, 0.6 } });    Collection<GenericItemSimilarity.ItemItemSimilarity> similarities = Lists.newArrayList();    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(0, 1, 1.0));    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(0, 2, 0.8));    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(0, 3, -0.6));    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(0, 4, 1.0));    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(1, 2, 0.9));    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(1, 3, 0.0));    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(1, 1, 1.0));    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(2, 3, -0.1));    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(2, 4, 0.1));    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(3, 4, -0.5));    ItemSimilarity similarity = new GenericItemSimilarity(similarities);    return new GenericItemBasedRecommender(dataModel, similarity);}
public void mahout_f4556_0() throws Exception
{    DataModel dataModel = EasyMock.createMock(DataModel.class);    ItemSimilarity itemSimilarity = EasyMock.createMock(ItemSimilarity.class);    CandidateItemsStrategy candidateItemsStrategy = EasyMock.createMock(CandidateItemsStrategy.class);    MostSimilarItemsCandidateItemsStrategy mostSimilarItemsCandidateItemsStrategy = EasyMock.createMock(MostSimilarItemsCandidateItemsStrategy.class);    PreferenceArray preferencesFromUser = new GenericUserPreferenceArray(Arrays.asList(new GenericPreference(1L, 1L, 5.0f), new GenericPreference(1L, 2L, 4.0f)));    EasyMock.expect(dataModel.getMinPreference()).andReturn(Float.NaN);    EasyMock.expect(dataModel.getMaxPreference()).andReturn(Float.NaN);    EasyMock.expect(dataModel.getPreferencesFromUser(1L)).andReturn(preferencesFromUser);    EasyMock.expect(candidateItemsStrategy.getCandidateItems(1L, preferencesFromUser, dataModel, false)).andReturn(new FastIDSet(new long[] { 3L, 4L }));    EasyMock.expect(itemSimilarity.itemSimilarities(3L, preferencesFromUser.getIDs())).andReturn(new double[] { 0.5, 0.3 });    EasyMock.expect(itemSimilarity.itemSimilarities(4L, preferencesFromUser.getIDs())).andReturn(new double[] { 0.4, 0.1 });    EasyMock.replay(dataModel, itemSimilarity, candidateItemsStrategy, mostSimilarItemsCandidateItemsStrategy);    Recommender recommender = new GenericItemBasedRecommender(dataModel, itemSimilarity, candidateItemsStrategy, mostSimilarItemsCandidateItemsStrategy);    recommender.recommend(1L, 3);    EasyMock.verify(dataModel, itemSimilarity, candidateItemsStrategy, mostSimilarItemsCandidateItemsStrategy);}
public void mahout_f4557_0() throws Exception
{    Recommender recommender = buildRecommender();    List<RecommendedItem> recommended = recommender.recommend(1, 1);    assertNotNull(recommended);    assertEquals(1, recommended.size());    RecommendedItem firstRecommended = recommended.get(0);    assertEquals(2, firstRecommended.getItemID());    assertEquals(0.1f, firstRecommended.getValue(), EPSILON);    recommender.refresh(null);    assertEquals(2, firstRecommended.getItemID());    assertEquals(0.1f, firstRecommended.getValue(), EPSILON);}
public void mahout_f4558_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2, 3, 4, 5 }, new Double[][] { { 0.1, 0.2 }, { 0.2, 0.3, 0.3, 0.6 }, { 0.4, 0.4, 0.5, 0.9 }, { 0.1, 0.4, 0.5, 0.8, 0.9, 1.0 }, { 0.2, 0.3, 0.6, 0.7, 0.1, 0.2 } });    UserSimilarity similarity = new PearsonCorrelationSimilarity(dataModel);    UserNeighborhood neighborhood = new NearestNUserNeighborhood(2, similarity, dataModel);    Recommender recommender = new GenericUserBasedRecommender(dataModel, neighborhood, similarity);    List<RecommendedItem> fewRecommended = recommender.recommend(1, 2);    List<RecommendedItem> moreRecommended = recommender.recommend(1, 4);    for (int i = 0; i < fewRecommended.size(); i++) {        assertEquals(fewRecommended.get(i).getItemID(), moreRecommended.get(i).getItemID());    }    recommender.refresh(null);    for (int i = 0; i < fewRecommended.size(); i++) {        assertEquals(fewRecommended.get(i).getItemID(), moreRecommended.get(i).getItemID());    }}
public void mahout_f4559_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2, 3 }, new Double[][] { { 0.1, 0.2 }, { 0.2, 0.3, 0.3, 0.6 }, { 0.4, 0.5, 0.5, 0.9 } });    UserSimilarity similarity = new PearsonCorrelationSimilarity(dataModel);    UserNeighborhood neighborhood = new NearestNUserNeighborhood(2, similarity, dataModel);    Recommender recommender = new GenericUserBasedRecommender(dataModel, neighborhood, similarity);    List<RecommendedItem> originalRecommended = recommender.recommend(1, 2);    List<RecommendedItem> rescoredRecommended = recommender.recommend(1, 2, new ReversingRescorer<Long>());    assertNotNull(originalRecommended);    assertNotNull(rescoredRecommended);    assertEquals(2, originalRecommended.size());    assertEquals(2, rescoredRecommended.size());    assertEquals(originalRecommended.get(0).getItemID(), rescoredRecommended.get(1).getItemID());    assertEquals(originalRecommended.get(1).getItemID(), rescoredRecommended.get(0).getItemID());}
public void mahout_f4560_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2, 3 }, new Double[][] { { 0.1, 0.2 }, { 0.2, 0.3, 0.3, 0.6 }, { 0.4, 0.5, 0.5, 0.9 } });    UserSimilarity similarity = new PearsonCorrelationSimilarity(dataModel);    UserNeighborhood neighborhood = new NearestNUserNeighborhood(2, similarity, dataModel);    Recommender recommender = new GenericUserBasedRecommender(dataModel, neighborhood, similarity);    List<RecommendedItem> originalRecommended = recommender.recommend(1, 4, null, true);    List<RecommendedItem> rescoredRecommended = recommender.recommend(1, 4, new ReversingRescorer<Long>(), true);    assertNotNull(originalRecommended);    assertNotNull(rescoredRecommended);    assertEquals(4, originalRecommended.size());    assertEquals(4, rescoredRecommended.size());    assertEquals(originalRecommended.get(0).getItemID(), rescoredRecommended.get(3).getItemID());    assertEquals(originalRecommended.get(3).getItemID(), rescoredRecommended.get(0).getItemID());}
public void mahout_f4561_0() throws Exception
{    Recommender recommender = buildRecommender();    assertEquals(0.1f, recommender.estimatePreference(1, 2), EPSILON);}
public void mahout_f4562_0() throws Exception
{    Recommender recommender = buildRecommender();    List<RecommendedItem> recommended = recommender.recommend(1, 1);    assertNotNull(recommended);    assertEquals(1, recommended.size());    RecommendedItem firstRecommended = recommended.get(0);        assertEquals(2, firstRecommended.getItemID());    assertEquals(0.1f, firstRecommended.getValue(), EPSILON);}
public void mahout_f4563_0() throws Exception
{    UserBasedRecommender recommender = buildRecommender();    long[] similar = recommender.mostSimilarUserIDs(1, 2);    assertNotNull(similar);    assertEquals(2, similar.length);    assertEquals(2, similar[0]);    assertEquals(3, similar[1]);}
public void mahout_f4564_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2, 3, 4 }, new Double[][] { { 0.1, 0.2 }, { 0.2, 0.3, 0.3, 0.6 }, { 0.4, 0.4, 0.5, 0.9 }, { null, null, null, null, 1.0 } });    UserSimilarity similarity = new PearsonCorrelationSimilarity(dataModel);    UserNeighborhood neighborhood = new NearestNUserNeighborhood(3, similarity, dataModel);    UserBasedRecommender recommender = new GenericUserBasedRecommender(dataModel, neighborhood, similarity);    long[] mostSimilar = recommender.mostSimilarUserIDs(4, 3);    assertNotNull(mostSimilar);    assertEquals(0, mostSimilar.length);}
private static UserBasedRecommender mahout_f4565_0() throws TasteException
{    DataModel dataModel = getDataModel();    UserSimilarity similarity = new PearsonCorrelationSimilarity(dataModel);    UserNeighborhood neighborhood = new NearestNUserNeighborhood(2, similarity, dataModel);    return new GenericUserBasedRecommender(dataModel, neighborhood, similarity);}
public void mahout_f4566_0() throws Exception
{    Recommender recommender = new ItemAverageRecommender(getDataModel());    List<RecommendedItem> recommended = recommender.recommend(1, 1);    assertNotNull(recommended);    assertEquals(1, recommended.size());    RecommendedItem firstRecommended = recommended.get(0);    assertEquals(2, firstRecommended.getItemID());    assertEquals(0.53333336f, firstRecommended.getValue(), EPSILON);    recommender.refresh(null);    assertEquals(2, firstRecommended.getItemID());    assertEquals(0.53333336f, firstRecommended.getValue(), EPSILON);}
public void mahout_f4567_0() throws Exception
{    Recommender recommender = new ItemUserAverageRecommender(getDataModel());    List<RecommendedItem> recommended = recommender.recommend(1, 1);    assertNotNull(recommended);    assertEquals(1, recommended.size());    RecommendedItem firstRecommended = recommended.get(0);    assertEquals(2, firstRecommended.getItemID());    assertEquals(0.35151517f, firstRecommended.getValue(), EPSILON);    recommender.refresh(null);    assertEquals(2, firstRecommended.getItemID());    assertEquals(0.35151517f, firstRecommended.getValue(), EPSILON);}
public List<RecommendedItem> mahout_f4568_0(long userID, int howMany)
{    recommendCount.increment();    return Collections.<RecommendedItem>singletonList(new GenericRecommendedItem(1, 1.0f));}
public List<RecommendedItem> mahout_f4569_0(long userID, int howMany, boolean includeKnownItems)
{    return recommend(userID, howMany);}
public List<RecommendedItem> mahout_f4570_0(long userID, int howMany, IDRescorer rescorer)
{    return recommend(userID, howMany);}
public List<RecommendedItem> mahout_f4571_0(long userID, int howMany, IDRescorer rescorer, boolean includeKnownItems)
{    return recommend(userID, howMany);}
public float mahout_f4572_0(long userID, long itemID)
{    recommendCount.increment();    return 0.0f;}
public void mahout_f4573_0(long userID, long itemID, float value)
{}
public void mahout_f4574_0(long userID, long itemID)
{}
public DataModel mahout_f4575_0()
{    return TasteTestCase.getDataModel(new long[] { 1, 2, 3 }, new Double[][] { { 1.0 }, { 2.0 }, { 3.0 } });}
public void mahout_f4576_0(Collection<Refreshable> alreadyRefreshed)
{}
public void mahout_f4577_0() throws Exception
{    IDRescorer rescorer = NullRescorer.getItemInstance();    assertNotNull(rescorer);    assertEquals(1.0, rescorer.rescore(1L, 1.0), EPSILON);    assertEquals(1.0, rescorer.rescore(0L, 1.0), EPSILON);    assertEquals(0.0, rescorer.rescore(1L, 0.0), EPSILON);    assertTrue(Double.isNaN(rescorer.rescore(1L, Double.NaN)));}
public void mahout_f4578_0() throws Exception
{    IDRescorer rescorer = NullRescorer.getUserInstance();    assertNotNull(rescorer);    assertEquals(1.0, rescorer.rescore(1L, 1.0), EPSILON);    assertEquals(1.0, rescorer.rescore(0L, 1.0), EPSILON);    assertEquals(0.0, rescorer.rescore(1L, 0.0), EPSILON);    assertTrue(Double.isNaN(rescorer.rescore(1L, Double.NaN)));}
public void mahout_f4579_0() throws TasteException
{    FastIDSet itemIDsFromUser123 = new FastIDSet();    itemIDsFromUser123.add(1L);    FastIDSet itemIDsFromUser456 = new FastIDSet();    itemIDsFromUser456.add(1L);    itemIDsFromUser456.add(2L);    List<Preference> prefs = Lists.newArrayList();    prefs.add(new GenericPreference(123L, 1L, 1.0f));    prefs.add(new GenericPreference(456L, 1L, 1.0f));    PreferenceArray preferencesForItem1 = new GenericItemPreferenceArray(prefs);    DataModel dataModel = EasyMock.createMock(DataModel.class);    EasyMock.expect(dataModel.getPreferencesForItem(1L)).andReturn(preferencesForItem1);    EasyMock.expect(dataModel.getItemIDsFromUser(123L)).andReturn(itemIDsFromUser123);    EasyMock.expect(dataModel.getItemIDsFromUser(456L)).andReturn(itemIDsFromUser456);    PreferenceArray prefArrayOfUser123 = new GenericUserPreferenceArray(Collections.singletonList(new GenericPreference(123L, 1L, 1.0f)));    CandidateItemsStrategy strategy = new PreferredItemsNeighborhoodCandidateItemsStrategy();    EasyMock.replay(dataModel);    FastIDSet candidateItems = strategy.getCandidateItems(123L, prefArrayOfUser123, dataModel, false);    assertEquals(1, candidateItems.size());    assertTrue(candidateItems.contains(2L));    EasyMock.verify(dataModel);}
public void mahout_f4580_0() throws Exception
{    Recommender recommender = new RandomRecommender(getDataModel());    List<RecommendedItem> recommended = recommender.recommend(1, 1);    assertNotNull(recommended);    assertEquals(1, recommended.size());    RecommendedItem firstRecommended = recommended.get(0);    assertEquals(2, firstRecommended.getItemID());    recommender.refresh(null);    assertEquals(2, firstRecommended.getItemID());}
public double mahout_f4581_0(T thing, double originalScore)
{    return -originalScore;}
public boolean mahout_f4582_0(T thing)
{    return false;}
public double mahout_f4583_0(long ID, double originalScore)
{    return -originalScore;}
public boolean mahout_f4584_0(long ID)
{    return false;}
public void mahout_f4585_0() throws TasteException
{    List<Preference> prefsOfUser123 = Lists.newArrayList();    prefsOfUser123.add(new GenericPreference(123L, 1L, 1.0f));    List<Preference> prefsOfUser456 = Lists.newArrayList();    prefsOfUser456.add(new GenericPreference(456L, 1L, 1.0f));    prefsOfUser456.add(new GenericPreference(456L, 2L, 1.0f));    List<Preference> prefsOfUser789 = Lists.newArrayList();    prefsOfUser789.add(new GenericPreference(789L, 1L, 0.5f));    prefsOfUser789.add(new GenericPreference(789L, 3L, 1.0f));    PreferenceArray prefArrayOfUser123 = new GenericUserPreferenceArray(prefsOfUser123);    FastByIDMap<PreferenceArray> userData = new FastByIDMap<>();    userData.put(123L, prefArrayOfUser123);    userData.put(456L, new GenericUserPreferenceArray(prefsOfUser456));    userData.put(789L, new GenericUserPreferenceArray(prefsOfUser789));    DataModel dataModel = new GenericDataModel(userData);    CandidateItemsStrategy strategy = new SamplingCandidateItemsStrategy(1, 1, 1, dataModel.getNumUsers(), dataModel.getNumItems());    FastIDSet candidateItems = strategy.getCandidateItems(123L, prefArrayOfUser123, dataModel, false);    /* result can be either item2 or item3 or empty */    assertTrue(candidateItems.size() <= 1);    assertFalse(candidateItems.contains(1L));}
public void mahout_f4586_0() throws Exception
{    super.setUp();    FastByIDMap<PreferenceArray> userData = new FastByIDMap<>();    userData.put(1L, new GenericUserPreferenceArray(Arrays.asList(new GenericPreference(1L, 1L, 5.0f), new GenericPreference(1L, 2L, 5.0f), new GenericPreference(1L, 3L, 2.0f))));    userData.put(2L, new GenericUserPreferenceArray(Arrays.asList(new GenericPreference(2L, 1L, 2.0f), new GenericPreference(2L, 3L, 3.0f), new GenericPreference(2L, 4L, 5.0f))));    userData.put(3L, new GenericUserPreferenceArray(Arrays.asList(new GenericPreference(3L, 2L, 5.0f), new GenericPreference(3L, 4L, 3.0f))));    userData.put(4L, new GenericUserPreferenceArray(Arrays.asList(new GenericPreference(4L, 1L, 3.0f), new GenericPreference(4L, 4L, 5.0f))));    dataModel = new GenericDataModel(userData);    factorizer = new ALSWRFactorizer(dataModel, 3, 0.065, 10);}
public void mahout_f4587_0() throws Exception
{    ALSWRFactorizer.Features features = new ALSWRFactorizer.Features(factorizer);    Vector vector = new DenseVector(new double[] { 0.5, 2.0, 1.5 });    int index = 1;    features.setFeatureColumnInM(index, vector);    double[][] matrix = features.getM();    assertEquals(vector.get(0), matrix[index][0], EPSILON);    assertEquals(vector.get(1), matrix[index][1], EPSILON);    assertEquals(vector.get(2), matrix[index][2], EPSILON);}
public void mahout_f4588_0() throws Exception
{    PreferenceArray prefs = dataModel.getPreferencesFromUser(1);    Vector ratingVector = ALSWRFactorizer.ratingVector(prefs);    assertEquals(prefs.length(), ratingVector.getNumNondefaultElements());    assertEquals(prefs.get(0).getValue(), ratingVector.get(0), EPSILON);    assertEquals(prefs.get(1).getValue(), ratingVector.get(1), EPSILON);    assertEquals(prefs.get(2).getValue(), ratingVector.get(2), EPSILON);}
public void mahout_f4589_0() throws Exception
{    ALSWRFactorizer.Features features = new ALSWRFactorizer.Features(factorizer);    assertEquals(2.5, features.averateRating(3L), EPSILON);}
public void mahout_f4590_0() throws Exception
{    ALSWRFactorizer.Features features = new ALSWRFactorizer.Features(factorizer);    double[][] M = features.getM();    assertEquals(3.333333333, M[0][0], EPSILON);    assertEquals(5, M[1][0], EPSILON);    assertEquals(2.5, M[2][0], EPSILON);    assertEquals(4.333333333, M[3][0], EPSILON);    for (int itemIndex = 0; itemIndex < dataModel.getNumItems(); itemIndex++) {        for (int feature = 1; feature < 3; feature++) {            assertTrue(M[itemIndex][feature] >= 0);            assertTrue(M[itemIndex][feature] <= 0.1);        }    }}
public void mahout_f4591_0() throws Exception
{    SVDRecommender svdRecommender = new SVDRecommender(dataModel, factorizer);    /* a hold out test would be better, but this is just a toy example so we only check that the    * factorization is close to the original matrix */    RunningAverage avg = new FullRunningAverage();    LongPrimitiveIterator userIDs = dataModel.getUserIDs();    while (userIDs.hasNext()) {        long userID = userIDs.nextLong();        for (Preference pref : dataModel.getPreferencesFromUser(userID)) {            double rating = pref.getValue();            double estimate = svdRecommender.estimatePreference(userID, pref.getItemID());            double err = rating - estimate;            avg.addDatum(err * err);        }    }    double rmse = Math.sqrt(avg.getAverage());    assertTrue(rmse < 0.2);}
public void mahout_f4592_1() throws Exception
{    Matrix observations = new SparseRowMatrix(4, 4, new Vector[] { new DenseVector(new double[] { 5.0, 5.0, 2.0, 0 }), new DenseVector(new double[] { 2.0, 0, 3.0, 5.0 }), new DenseVector(new double[] { 0, 5.0, 0, 3.0 }), new DenseVector(new double[] { 3.0, 0, 0, 5.0 }) });    Matrix preferences = new SparseRowMatrix(4, 4, new Vector[] { new DenseVector(new double[] { 1.0, 1.0, 1.0, 0 }), new DenseVector(new double[] { 1.0, 0, 1.0, 1.0 }), new DenseVector(new double[] { 0, 1.0, 0, 1.0 }), new DenseVector(new double[] { 1.0, 0, 0, 1.0 }) });    double alpha = 20;    ALSWRFactorizer factorizer = new ALSWRFactorizer(dataModel, 3, 0.065, 5, true, alpha);    SVDRecommender svdRecommender = new SVDRecommender(dataModel, factorizer);    RunningAverage avg = new FullRunningAverage();    Iterator<MatrixSlice> sliceIterator = preferences.iterateAll();    while (sliceIterator.hasNext()) {        MatrixSlice slice = sliceIterator.next();        for (Vector.Element e : slice.vector().all()) {            long userID = slice.index() + 1;            long itemID = e.index() + 1;            if (!Double.isNaN(e.get())) {                double pref = e.get();                double estimate = svdRecommender.estimatePreference(userID, itemID);                double confidence = 1 + alpha * observations.getQuick(slice.index(), e.index());                double err = confidence * (pref - estimate) * (pref - estimate);                avg.addDatum(err);                            }        }    }    double rmse = Math.sqrt(avg.getAverage());        assertTrue(rmse < 0.4);}
public void mahout_f4593_0() throws Exception
{    FastByIDMap<Integer> userIDMapping = new FastByIDMap<>();    FastByIDMap<Integer> itemIDMapping = new FastByIDMap<>();    userIDMapping.put(123, 0);    userIDMapping.put(456, 1);    itemIDMapping.put(12, 0);    itemIDMapping.put(34, 1);    double[][] userFeatures = { { 0.1, 0.2, 0.3 }, { 0.4, 0.5, 0.6 } };    double[][] itemFeatures = { { 0.7, 0.8, 0.9 }, { 1.0, 1.1, 1.2 } };    Factorization original = new Factorization(userIDMapping, itemIDMapping, userFeatures, itemFeatures);    File storage = getTestTempFile("storage.bin");    PersistenceStrategy persistenceStrategy = new FilePersistenceStrategy(storage);    assertNull(persistenceStrategy.load());    persistenceStrategy.maybePersist(original);    Factorization clone = persistenceStrategy.load();    assertEquals(original, clone);}
private Matrix mahout_f4594_0(int numRows, int numColumns, double range)
{    double[][] data = new double[numRows][numColumns];    for (int i = 0; i < numRows; i++) {        for (int j = 0; j < numColumns; j++) {            double sqrtUniform = random.nextDouble();            data[i][j] = sqrtUniform * range;        }    }    return new DenseMatrix(data);}
private void mahout_f4595_0(Matrix source, final double range)
{    final double max = source.aggregateColumns(new VectorFunction() {        @Override        public double apply(Vector column) {            return column.maxValue();        }    }).maxValue();    final double min = source.aggregateColumns(new VectorFunction() {        @Override        public double apply(Vector column) {            return column.minValue();        }    }).minValue();    source.assign(new DoubleFunction() {        @Override        public double apply(double value) {            return (value - min) * range / (max - min);        }    });}
public double mahout_f4596_0(Vector column)
{    return column.maxValue();}
public double mahout_f4597_0(Vector column)
{    return column.minValue();}
public double mahout_f4598_0(double value)
{    return (value - min) * range / (max - min);}
public void mahout_f4599_0() throws Exception
{    int numUsers = 2000;    int numItems = 1000;    double sparsity = 0.5;    this.rank = 20;    this.lambda = 0.000000001;    this.numIterations = 100;    Matrix users = randomMatrix(numUsers, rank, 1);    Matrix items = randomMatrix(rank, numItems, 1);    Matrix ratings = users.times(items);    normalize(ratings, 5);    FastByIDMap<PreferenceArray> userData = new FastByIDMap<>();    for (int userIndex = 0; userIndex < numUsers; userIndex++) {        List<Preference> row = Lists.newArrayList();        for (int itemIndex = 0; itemIndex < numItems; itemIndex++) {            if (random.nextDouble() <= sparsity) {                row.add(new GenericPreference(userIndex, itemIndex, (float) ratings.get(userIndex, itemIndex)));            }        }        userData.put(userIndex, new GenericUserPreferenceArray(row));    }    dataModel = new GenericDataModel(userData);}
public void mahout_f4600_0() throws Exception
{    this.rank = 3;    this.lambda = 0.01;    this.numIterations = 1000;    FastByIDMap<PreferenceArray> userData = new FastByIDMap<>();    userData.put(1L, new GenericUserPreferenceArray(Arrays.asList(new GenericPreference(1L, 1L, 5.0f), new GenericPreference(1L, 2L, 5.0f), new GenericPreference(1L, 3L, 2.0f))));    userData.put(2L, new GenericUserPreferenceArray(Arrays.asList(new GenericPreference(2L, 1L, 2.0f), new GenericPreference(2L, 3L, 3.0f), new GenericPreference(2L, 4L, 5.0f))));    userData.put(3L, new GenericUserPreferenceArray(Arrays.asList(new GenericPreference(3L, 2L, 5.0f), new GenericPreference(3L, 4L, 3.0f))));    userData.put(4L, new GenericUserPreferenceArray(Arrays.asList(new GenericPreference(4L, 1L, 3.0f), new GenericPreference(4L, 4L, 5.0f))));    dataModel = new GenericDataModel(userData);}
public void mahout_f4601_0() throws Exception
{    setUpSyntheticData();    ParallelSGDFactorizer.PreferenceShuffler shuffler = new PreferenceShuffler(dataModel);    shuffler.shuffle();    shuffler.stage();    FastByIDMap<FastByIDMap<Boolean>> checked = new FastByIDMap<>();    for (int i = 0; i < shuffler.size(); i++) {        Preference pref = shuffler.get(i);        float value = dataModel.getPreferenceValue(pref.getUserID(), pref.getItemID());        assertEquals(pref.getValue(), value, 0.0);        if (!checked.containsKey(pref.getUserID())) {            checked.put(pref.getUserID(), new FastByIDMap<Boolean>());        }        assertNull(checked.get(pref.getUserID()).get(pref.getItemID()));        checked.get(pref.getUserID()).put(pref.getItemID(), true);    }    LongPrimitiveIterator userIDs = dataModel.getUserIDs();    int index = 0;    while (userIDs.hasNext()) {        long userID = userIDs.nextLong();        PreferenceArray preferencesFromUser = dataModel.getPreferencesFromUser(userID);        for (Preference preference : preferencesFromUser) {            assertTrue(checked.get(preference.getUserID()).get(preference.getItemID()));            index++;        }    }    assertEquals(index, shuffler.size());}
public void mahout_f4603_1() throws Exception
{    setUpToyData();    factorizer = new ParallelSGDFactorizer(dataModel, rank, lambda, numIterations, 0.01, 1, 0, 0);    svdRecommender = new SVDRecommender(dataModel, factorizer);    /* a hold out test would be better, but this is just a toy example so we only check that the     * factorization is close to the original matrix */    RunningAverage avg = new FullRunningAverage();    LongPrimitiveIterator userIDs = dataModel.getUserIDs();    while (userIDs.hasNext()) {        long userID = userIDs.nextLong();        for (Preference pref : dataModel.getPreferencesFromUser(userID)) {            double rating = pref.getValue();            double estimate = svdRecommender.estimatePreference(userID, pref.getItemID());            double err = rating - estimate;            avg.addDatum(err * err);        }    }    double rmse = Math.sqrt(avg.getAverage());        assertTrue(rmse < 0.2);}
public void mahout_f4605_1() throws Exception
{    setUpSyntheticData();    factorizer = new ParallelSGDFactorizer(dataModel, rank, lambda, numIterations, 0.01, 1, 0, 0);    svdRecommender = new SVDRecommender(dataModel, factorizer);    /* a hold out test would be better, but this is just a toy example so we only check that the     * factorization is close to the original matrix */    RunningAverage avg = new FullRunningAverage();    LongPrimitiveIterator userIDs = dataModel.getUserIDs();    while (userIDs.hasNext()) {        long userID = userIDs.nextLong();        for (Preference pref : dataModel.getPreferencesFromUser(userID)) {            double rating = pref.getValue();            double estimate = svdRecommender.estimatePreference(userID, pref.getItemID());            double err = rating - estimate;            avg.addDatum(err * err);        }    }    double rmse = Math.sqrt(avg.getAverage());        assertTrue(rmse < 0.2);}
public void mahout_f4606_0() throws Exception
{    DataModel dataModel = EasyMock.createMock(DataModel.class);    Factorizer factorizer = EasyMock.createMock(Factorizer.class);    Factorization factorization = EasyMock.createMock(Factorization.class);    EasyMock.expect(factorizer.factorize()).andReturn(factorization);    EasyMock.expect(factorization.getUserFeatures(1L)).andReturn(new double[] { 0.4, 2 });    EasyMock.expect(factorization.getItemFeatures(5L)).andReturn(new double[] { 1, 0.3 });    EasyMock.replay(dataModel, factorizer, factorization);    SVDRecommender svdRecommender = new SVDRecommender(dataModel, factorizer);    float estimate = svdRecommender.estimatePreference(1L, 5L);    assertEquals(1, estimate, EPSILON);    EasyMock.verify(dataModel, factorizer, factorization);}
public void mahout_f4607_0() throws Exception
{    DataModel dataModel = EasyMock.createMock(DataModel.class);    PreferenceArray preferencesFromUser = EasyMock.createMock(PreferenceArray.class);    CandidateItemsStrategy candidateItemsStrategy = EasyMock.createMock(CandidateItemsStrategy.class);    Factorizer factorizer = EasyMock.createMock(Factorizer.class);    Factorization factorization = EasyMock.createMock(Factorization.class);    FastIDSet candidateItems = new FastIDSet();    candidateItems.add(5L);    candidateItems.add(3L);    EasyMock.expect(factorizer.factorize()).andReturn(factorization);    EasyMock.expect(dataModel.getPreferencesFromUser(1L)).andReturn(preferencesFromUser);    EasyMock.expect(candidateItemsStrategy.getCandidateItems(1L, preferencesFromUser, dataModel, false)).andReturn(candidateItems);    EasyMock.expect(factorization.getUserFeatures(1L)).andReturn(new double[] { 0.4, 2 });    EasyMock.expect(factorization.getItemFeatures(5L)).andReturn(new double[] { 1, 0.3 });    EasyMock.expect(factorization.getUserFeatures(1L)).andReturn(new double[] { 0.4, 2 });    EasyMock.expect(factorization.getItemFeatures(3L)).andReturn(new double[] { 2, 0.6 });    EasyMock.replay(dataModel, candidateItemsStrategy, factorizer, factorization);    SVDRecommender svdRecommender = new SVDRecommender(dataModel, factorizer, candidateItemsStrategy);    List<RecommendedItem> recommendedItems = svdRecommender.recommend(1L, 5);    assertEquals(2, recommendedItems.size());    assertEquals(3L, recommendedItems.get(0).getItemID());    assertEquals(2.0f, recommendedItems.get(0).getValue(), EPSILON);    assertEquals(5L, recommendedItems.get(1).getItemID());    assertEquals(1.0f, recommendedItems.get(1).getValue(), EPSILON);    EasyMock.verify(dataModel, candidateItemsStrategy, factorizer, factorization);}
public void mahout_f4608_0() throws Exception
{    long[] ids = new long[100];    for (int i = 0; i < 100; i++) {        ids[i] = i;    }    LongPrimitiveIterator possibleItemIds = new LongPrimitiveArrayIterator(ids);    TopItems.Estimator<Long> estimator = new TopItems.Estimator<Long>() {        @Override        public double estimate(Long thing) {            return thing;        }    };    List<RecommendedItem> topItems = TopItems.getTopItems(10, possibleItemIds, null, estimator);    int gold = 99;    for (RecommendedItem topItem : topItems) {        assertEquals(gold, topItem.getItemID());        assertEquals(gold--, topItem.getValue(), 0.01);    }}
public double mahout_f4609_0(Long thing)
{    return thing;}
public void mahout_f4610_0() throws Exception
{    long[] ids = new long[100];    for (int i = 0; i < 100; i++) {        ids[i] = i;    }    LongPrimitiveIterator possibleItemIds = new LongPrimitiveArrayIterator(ids);    final Random random = RandomUtils.getRandom();    TopItems.Estimator<Long> estimator = new TopItems.Estimator<Long>() {        @Override        public double estimate(Long thing) {            return random.nextDouble();        }    };    List<RecommendedItem> topItems = TopItems.getTopItems(10, possibleItemIds, null, estimator);    assertEquals(10, topItems.size());    double last = 2.0;    for (RecommendedItem topItem : topItems) {        assertTrue(topItem.getValue() <= last);        last = topItem.getItemID();    }}
public double mahout_f4611_0(Long thing)
{    return random.nextDouble();}
public void mahout_f4612_0() throws Exception
{    long[] ids = new long[100];    for (int i = 0; i < 100; i++) {        ids[i] = i;    }    LongPrimitiveIterator possibleItemIds = new LongPrimitiveArrayIterator(ids);    TopItems.Estimator<Long> estimator = new TopItems.Estimator<Long>() {        @Override        public double estimate(Long thing) {            return thing;        }    };    long[] topItems = TopItems.getTopUsers(10, possibleItemIds, null, estimator);    int gold = 99;    for (long topItem : topItems) {        assertEquals(gold--, topItem);    }}
public double mahout_f4613_0(Long thing)
{    return thing;}
public void mahout_f4614_0() throws Exception
{    List<GenericItemSimilarity.ItemItemSimilarity> sims = Lists.newArrayList();    for (int i = 0; i < 99; i++) {        sims.add(new GenericItemSimilarity.ItemItemSimilarity(i, i + 1, i / 99.0));    }    List<GenericItemSimilarity.ItemItemSimilarity> res = TopItems.getTopItemItemSimilarities(10, sims.iterator());    int gold = 99;    for (GenericItemSimilarity.ItemItemSimilarity re : res) {                assertEquals(gold--, re.getItemID2());    }}
public void mahout_f4615_0() throws Exception
{    List<GenericItemSimilarity.ItemItemSimilarity> sims = Lists.newArrayList();    for (int i = 0; i < 99; i++) {        sims.add(new GenericItemSimilarity.ItemItemSimilarity(i, i + 1, 1 - (i / 99.0)));    }    List<GenericItemSimilarity.ItemItemSimilarity> res = TopItems.getTopItemItemSimilarities(10, sims.iterator());    int gold = 0;    for (GenericItemSimilarity.ItemItemSimilarity re : res) {                assertEquals(gold++, re.getItemID1());    }}
public void mahout_f4616_0() throws Exception
{    List<GenericUserSimilarity.UserUserSimilarity> sims = Lists.newArrayList();    for (int i = 0; i < 99; i++) {        sims.add(new GenericUserSimilarity.UserUserSimilarity(i, i + 1, i / 99.0));    }    List<GenericUserSimilarity.UserUserSimilarity> res = TopItems.getTopUserUserSimilarities(10, sims.iterator());    int gold = 99;    for (GenericUserSimilarity.UserUserSimilarity re : res) {                assertEquals(gold--, re.getUserID2());    }}
public void mahout_f4617_0() throws Exception
{    List<GenericUserSimilarity.UserUserSimilarity> sims = Lists.newArrayList();    for (int i = 0; i < 99; i++) {        sims.add(new GenericUserSimilarity.UserUserSimilarity(i, i + 1, 1 - (i / 99.0)));    }    List<GenericUserSimilarity.UserUserSimilarity> res = TopItems.getTopUserUserSimilarities(10, sims.iterator());    int gold = 0;    for (GenericUserSimilarity.UserUserSimilarity re : res) {                assertEquals(gold++, re.getUserID1());    }}
public void mahout_f4618_0() throws TasteException
{    DataModel model = getDataModel(new long[] { 1 }, new Double[][] { { 3.0, -2.0, 5.0 } });    PreferenceInferrer inferrer = new AveragingPreferenceInferrer(model);    double inferred = inferrer.inferPreference(1, 3);    assertEquals(2.0, inferred, EPSILON);}
public void mahout_f4619_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 3.0, -2.0 }, { 3.0, -2.0 } });    double correlation = new EuclideanDistanceSimilarity(dataModel).userSimilarity(1, 2);    assertCorrelationEquals(1.0, correlation);}
public void mahout_f4620_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 3.0, -2.0 }, { 3.0, -2.0 } });    double correlation = new EuclideanDistanceSimilarity(dataModel, Weighting.WEIGHTED).userSimilarity(1, 2);    assertCorrelationEquals(1.0, correlation);}
public void mahout_f4621_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 3.0, 3.0 }, { 3.0, 3.0 } });    double correlation = new EuclideanDistanceSimilarity(dataModel).userSimilarity(1, 2);    assertEquals(1.0, correlation, EPSILON);}
public void mahout_f4622_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 3.0, -2.0 }, { -3.0, 2.0 } });    double correlation = new EuclideanDistanceSimilarity(dataModel).userSimilarity(1, 2);    assertCorrelationEquals(0.1639607805437114, correlation);}
public void mahout_f4623_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 3.0, -2.0 }, { -3.0, 2.0 } });    double correlation = new EuclideanDistanceSimilarity(dataModel, Weighting.WEIGHTED).userSimilarity(1, 2);    assertCorrelationEquals(0.7213202601812372, correlation);}
public void mahout_f4624_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { null, 1.0, null }, { null, null, 1.0 } });    double correlation = new EuclideanDistanceSimilarity(dataModel).userSimilarity(1, 2);    assertTrue(Double.isNaN(correlation));}
public void mahout_f4625_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 90.0, 80.0, 70.0 }, { 70.0, 80.0, 90.0 } });    double correlation = new EuclideanDistanceSimilarity(dataModel).userSimilarity(1, 2);    assertCorrelationEquals(0.05770363219029305, correlation);}
public void mahout_f4626_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 1.0, 2.0, 3.0 }, { 2.0, 5.0, 6.0 } });    double correlation = new EuclideanDistanceSimilarity(dataModel).userSimilarity(1, 2);    assertCorrelationEquals(0.2843646522044218, correlation);}
public void mahout_f4627_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 1.0, 2.0, 3.0 }, { 2.0, 5.0, 6.0 } });    double correlation = new EuclideanDistanceSimilarity(dataModel, Weighting.WEIGHTED).userSimilarity(1, 2);    assertCorrelationEquals(0.8210911630511055, correlation);}
public void mahout_f4628_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 3.0, 3.0 }, { -2.0, -2.0 } });    double correlation = new EuclideanDistanceSimilarity(dataModel).itemSimilarity(0, 1);    assertCorrelationEquals(1.0, correlation);}
public void mahout_f4629_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 3.0, 3.0 }, { 3.0, 3.0 } });    double correlation = new EuclideanDistanceSimilarity(dataModel).itemSimilarity(0, 1);    assertEquals(1.0, correlation, EPSILON);}
public void mahout_f4630_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 3.0, -3.0 }, { -2.0, 2.0 } });    double correlation = new EuclideanDistanceSimilarity(dataModel).itemSimilarity(0, 1);    assertCorrelationEquals(0.1639607805437114, correlation);}
public void mahout_f4631_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { null, 1.0, null }, { null, null, 1.0 } });    double correlation = new EuclideanDistanceSimilarity(dataModel).itemSimilarity(1, 2);    assertTrue(Double.isNaN(correlation));}
public void mahout_f4632_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2, 3 }, new Double[][] { { 90.0, 70.0 }, { 80.0, 80.0 }, { 70.0, 90.0 } });    double correlation = new EuclideanDistanceSimilarity(dataModel).itemSimilarity(0, 1);    assertCorrelationEquals(0.05770363219029305, correlation);}
public void mahout_f4633_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2, 3 }, new Double[][] { { 1.0, 2.0 }, { 2.0, 5.0 }, { 3.0, 6.0 } });    double correlation = new EuclideanDistanceSimilarity(dataModel).itemSimilarity(0, 1);    assertCorrelationEquals(0.2843646522044218, correlation);}
public void mahout_f4634_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2, 3 }, new Double[][] { { 1.0, 2.0 }, { 2.0, 5.0 }, { 3.0, 6.0 } });    ItemSimilarity itemSimilarity = new EuclideanDistanceSimilarity(dataModel, Weighting.WEIGHTED);    double correlation = itemSimilarity.itemSimilarity(0, 1);    assertCorrelationEquals(0.8210911630511055, correlation);}
public void mahout_f4635_0() throws TasteException
{        new EuclideanDistanceSimilarity(getDataModel()).refresh(null);}
public void mahout_f4636_0() throws Exception
{    super.setUp();    testFile = getTestTempFile("test.txt");    writeLines(testFile, data);}
public void mahout_f4637_0() throws Exception
{    ItemSimilarity similarity = new FileItemSimilarity(testFile);    assertEquals(0.125, similarity.itemSimilarity(1L, 5L), EPSILON);    assertEquals(0.125, similarity.itemSimilarity(5L, 1L), EPSILON);    assertEquals(0.5, similarity.itemSimilarity(1L, 7L), EPSILON);    assertEquals(0.5, similarity.itemSimilarity(7L, 1L), EPSILON);    assertTrue(Double.isNaN(similarity.itemSimilarity(7L, 8L)));    double[] valuesForOne = similarity.itemSimilarities(1L, new long[] { 5L, 7L });    assertNotNull(valuesForOne);    assertEquals(2, valuesForOne.length);    assertEquals(0.125, valuesForOne[0], EPSILON);    assertEquals(0.5, valuesForOne[1], EPSILON);}
public void mahout_f4638_0() throws Exception
{    ItemSimilarity similarity = new FileItemSimilarity(testFile, 0L);    /* call a method to make sure the original file is loaded*/    similarity.itemSimilarity(1L, 5L);    /* change the underlying file,     * we have to wait at least a second to see the change in the file's lastModified timestamp */    Thread.sleep(2000L);    writeLines(testFile, changedData);    /* we shouldn't see any changes in the data as we have not yet refreshed */    assertEquals(0.5, similarity.itemSimilarity(1L, 7L), EPSILON);    assertEquals(0.5, similarity.itemSimilarity(7L, 1L), EPSILON);    assertTrue(Double.isNaN(similarity.itemSimilarity(7L, 8L)));}
public void mahout_f4639_0() throws Exception
{    ItemSimilarity similarity = new FileItemSimilarity(testFile, 0L);    /* call a method to make sure the original file is loaded */    similarity.itemSimilarity(1L, 5L);    /* change the underlying file,     * we have to wait at least a second to see the change in the file's lastModified timestamp */    Thread.sleep(2000L);    writeLines(testFile, changedData);    similarity.refresh(null);    /* we should now see the changes in the data */    assertEquals(0.9, similarity.itemSimilarity(1L, 7L), EPSILON);    assertEquals(0.9, similarity.itemSimilarity(7L, 1L), EPSILON);    assertEquals(0.125, similarity.itemSimilarity(1L, 5L), EPSILON);    assertEquals(0.125, similarity.itemSimilarity(5L, 1L), EPSILON);    assertFalse(Double.isNaN(similarity.itemSimilarity(7L, 8L)));    assertEquals(0.112, similarity.itemSimilarity(7L, 8L), EPSILON);    assertEquals(0.112, similarity.itemSimilarity(8L, 7L), EPSILON);}
public void mahout_f4640_0() throws Exception
{    new FileItemSimilarity(new File("xKsdfksdfsdf"));}
public void mahout_f4641_0() throws Exception
{    Iterable<ItemItemSimilarity> similarityIterable = new FileItemItemSimilarityIterable(testFile);    GenericItemSimilarity similarity = new GenericItemSimilarity(similarityIterable);    assertEquals(0.125, similarity.itemSimilarity(1L, 5L), EPSILON);    assertEquals(0.125, similarity.itemSimilarity(5L, 1L), EPSILON);    assertEquals(0.5, similarity.itemSimilarity(1L, 7L), EPSILON);    assertEquals(0.5, similarity.itemSimilarity(7L, 1L), EPSILON);    assertTrue(Double.isNaN(similarity.itemSimilarity(7L, 8L)));    double[] valuesForOne = similarity.itemSimilarities(1L, new long[] { 5L, 7L });    assertNotNull(valuesForOne);    assertEquals(2, valuesForOne.length);    assertEquals(0.125, valuesForOne[0], EPSILON);    assertEquals(0.5, valuesForOne[1], EPSILON);}
public void mahout_f4642_0() throws Exception
{    ItemSimilarity similarity = new FileItemSimilarity(testFile);    assertTrue(!similarity.toString().isEmpty());}
public void mahout_f4643_0()
{    List<GenericItemSimilarity.ItemItemSimilarity> similarities = Lists.newArrayList();    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(1, 2, 0.5));    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(2, 1, 0.6));    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(1, 1, 0.5));    similarities.add(new GenericItemSimilarity.ItemItemSimilarity(1, 3, 0.3));    GenericItemSimilarity itemCorrelation = new GenericItemSimilarity(similarities);    assertEquals(1.0, itemCorrelation.itemSimilarity(1, 1), EPSILON);    assertEquals(0.6, itemCorrelation.itemSimilarity(1, 2), EPSILON);    assertEquals(0.6, itemCorrelation.itemSimilarity(2, 1), EPSILON);    assertEquals(0.3, itemCorrelation.itemSimilarity(1, 3), EPSILON);    assertTrue(Double.isNaN(itemCorrelation.itemSimilarity(3, 4)));}
public void mahout_f4644_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2, 3 }, new Double[][] { { 1.0, 2.0 }, { 2.0, 5.0 }, { 3.0, 6.0 } });    ItemSimilarity otherSimilarity = new PearsonCorrelationSimilarity(dataModel);    ItemSimilarity itemSimilarity = new GenericItemSimilarity(otherSimilarity, dataModel);    assertCorrelationEquals(1.0, itemSimilarity.itemSimilarity(0, 0));    assertCorrelationEquals(0.960768922830523, itemSimilarity.itemSimilarity(0, 1));}
public void mahout_f4645_0() throws TasteException
{    List<GenericItemSimilarity.ItemItemSimilarity> itemItemSimilarities = Arrays.asList(new GenericItemSimilarity.ItemItemSimilarity(1L, 2L, 0.2), new GenericItemSimilarity.ItemItemSimilarity(1L, 3L, 0.2), new GenericItemSimilarity.ItemItemSimilarity(2L, 1L, 0.2), new GenericItemSimilarity.ItemItemSimilarity(3L, 5L, 0.2), new GenericItemSimilarity.ItemItemSimilarity(3L, 4L, 0.2));    ItemSimilarity similarity = new GenericItemSimilarity(itemItemSimilarities);    assertTrue(containsExactly(similarity.allSimilarItemIDs(1L), 2L, 3L));    assertTrue(containsExactly(similarity.allSimilarItemIDs(2L), 1L));    assertTrue(containsExactly(similarity.allSimilarItemIDs(3L), 1L, 5L, 4L));    assertTrue(containsExactly(similarity.allSimilarItemIDs(4L), 3L));    assertTrue(containsExactly(similarity.allSimilarItemIDs(5L), 3L));}
public void mahout_f4646_0() throws TasteException
{    List<GenericItemSimilarity.ItemItemSimilarity> itemItemSimilarities = Arrays.asList(new GenericItemSimilarity.ItemItemSimilarity(1L, 2L, 0.2), new GenericItemSimilarity.ItemItemSimilarity(1L, 3L, 0.2), new GenericItemSimilarity.ItemItemSimilarity(2L, 1L, 0.2), new GenericItemSimilarity.ItemItemSimilarity(3L, 5L, 0.2), new GenericItemSimilarity.ItemItemSimilarity(3L, 4L, 0.2));    ItemSimilarity similarity = new GenericItemSimilarity(itemItemSimilarities);    assertTrue(containsExactly(similarity.allSimilarItemIDs(1L), 2L, 3L));    assertTrue(containsExactly(similarity.allSimilarItemIDs(2L), 1L));    assertTrue(containsExactly(similarity.allSimilarItemIDs(3L), 1L, 5L, 4L));    assertTrue(containsExactly(similarity.allSimilarItemIDs(4L), 3L));    assertTrue(containsExactly(similarity.allSimilarItemIDs(5L), 3L));}
private static boolean mahout_f4647_0(long[] allIDs, long... shouldContainID)
{    return new FastIDSet(allIDs).intersectionSize(new FastIDSet(shouldContainID)) == shouldContainID.length;}
public void mahout_f4648_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2, 3, 4, 5 }, new Double[][] { { 1.0, 1.0 }, { 1.0, null, 1.0 }, { null, null, 1.0, 1.0, 1.0 }, { 1.0, 1.0, 1.0, 1.0, 1.0 }, { null, 1.0, 1.0, 1.0, 1.0 } });    LogLikelihoodSimilarity similarity = new LogLikelihoodSimilarity(dataModel);    assertCorrelationEquals(0.12160727029227925, similarity.itemSimilarity(1, 0));    assertCorrelationEquals(0.12160727029227925, similarity.itemSimilarity(0, 1));    assertCorrelationEquals(0.5423213660693732, similarity.itemSimilarity(1, 2));    assertCorrelationEquals(0.5423213660693732, similarity.itemSimilarity(2, 1));    assertCorrelationEquals(0.6905400104897509, similarity.itemSimilarity(2, 3));    assertCorrelationEquals(0.6905400104897509, similarity.itemSimilarity(3, 2));    assertCorrelationEquals(0.8706358464330881, similarity.itemSimilarity(3, 4));    assertCorrelationEquals(0.8706358464330881, similarity.itemSimilarity(4, 3));}
public void mahout_f4649_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2, 3, 4 }, new Double[][] { { 1.0, null, 1.0, 1.0 }, { 1.0, null, 1.0, 1.0 }, { null, 1.0, 1.0, 1.0 }, { null, 1.0, 1.0, 1.0 } });    LogLikelihoodSimilarity similarity = new LogLikelihoodSimilarity(dataModel);    assertCorrelationEquals(Double.NaN, similarity.itemSimilarity(1, 0));    assertCorrelationEquals(Double.NaN, similarity.itemSimilarity(0, 1));    assertCorrelationEquals(0.0, similarity.itemSimilarity(2, 3));    assertCorrelationEquals(0.0, similarity.itemSimilarity(3, 2));}
public void mahout_f4650_0()
{        new LogLikelihoodSimilarity(getDataModel()).refresh(null);}
public void mahout_f4651_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 3.0, -2.0 }, { 3.0, -2.0 } });    double correlation = new PearsonCorrelationSimilarity(dataModel).userSimilarity(1, 2);    assertCorrelationEquals(1.0, correlation);}
public void mahout_f4652_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 3.0, -2.0 }, { 3.0, -2.0 } });    double correlation = new PearsonCorrelationSimilarity(dataModel, Weighting.WEIGHTED).userSimilarity(1, 2);    assertCorrelationEquals(1.0, correlation);}
public void mahout_f4653_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 3.0, 3.0 }, { 3.0, 3.0 } });    double correlation = new PearsonCorrelationSimilarity(dataModel).userSimilarity(1, 2);        assertTrue(Double.isNaN(correlation));}
public void mahout_f4654_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 3.0, -2.0 }, { -3.0, 2.0 } });    double correlation = new PearsonCorrelationSimilarity(dataModel).userSimilarity(1, 2);    assertCorrelationEquals(-1.0, correlation);}
public void mahout_f4655_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 3.0, -2.0 }, { -3.0, 2.0 } });    double correlation = new PearsonCorrelationSimilarity(dataModel, Weighting.WEIGHTED).userSimilarity(1, 2);    assertCorrelationEquals(-1.0, correlation);}
public void mahout_f4656_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { null, 1.0, null }, { null, null, 1.0 } });    double correlation = new PearsonCorrelationSimilarity(dataModel).userSimilarity(1, 2);    assertTrue(Double.isNaN(correlation));}
public void mahout_f4657_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 90.0, 80.0, 70.0 }, { 70.0, 80.0, 90.0 } });    double correlation = new PearsonCorrelationSimilarity(dataModel).userSimilarity(1, 2);    assertCorrelationEquals(-1.0, correlation);}
public void mahout_f4658_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 1.0, 2.0, 3.0 }, { 2.0, 5.0, 6.0 } });    double correlation = new PearsonCorrelationSimilarity(dataModel).userSimilarity(1, 2);    assertCorrelationEquals(0.9607689228305227, correlation);}
public void mahout_f4659_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 1.0, 2.0, 3.0 }, { 2.0, 5.0, 6.0 } });    double correlation = new PearsonCorrelationSimilarity(dataModel, Weighting.WEIGHTED).userSimilarity(1, 2);    assertCorrelationEquals(0.9901922307076306, correlation);}
public void mahout_f4660_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 3.0, 3.0 }, { -2.0, -2.0 } });    double correlation = new PearsonCorrelationSimilarity(dataModel).itemSimilarity(0, 1);    assertCorrelationEquals(1.0, correlation);}
public void mahout_f4661_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 3.0, 3.0 }, { 3.0, 3.0 } });    double correlation = new PearsonCorrelationSimilarity(dataModel).itemSimilarity(0, 1);        assertTrue(Double.isNaN(correlation));}
public void mahout_f4662_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 3.0, -3.0 }, { 2.0, -2.0 } });    double correlation = new PearsonCorrelationSimilarity(dataModel).itemSimilarity(0, 1);    assertCorrelationEquals(-1.0, correlation);}
public void mahout_f4663_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { null, 1.0, null }, { null, null, 1.0 } });    double correlation = new PearsonCorrelationSimilarity(dataModel).itemSimilarity(1, 2);    assertTrue(Double.isNaN(correlation));}
public void mahout_f4664_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2, 3 }, new Double[][] { { 90.0, 70.0 }, { 80.0, 80.0 }, { 70.0, 90.0 } });    double correlation = new PearsonCorrelationSimilarity(dataModel).itemSimilarity(0, 1);    assertCorrelationEquals(-1.0, correlation);}
public void mahout_f4665_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2, 3 }, new Double[][] { { 1.0, 2.0 }, { 2.0, 5.0 }, { 3.0, 6.0 } });    double correlation = new PearsonCorrelationSimilarity(dataModel).itemSimilarity(0, 1);    assertCorrelationEquals(0.9607689228305227, correlation);}
public void mahout_f4666_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2, 3 }, new Double[][] { { 1.0, 2.0 }, { 2.0, 5.0 }, { 3.0, 6.0 } });    ItemSimilarity itemSimilarity = new PearsonCorrelationSimilarity(dataModel, Weighting.WEIGHTED);    double correlation = itemSimilarity.itemSimilarity(0, 1);    assertCorrelationEquals(0.9901922307076306, correlation);}
public void mahout_f4667_0() throws Exception
{        new PearsonCorrelationSimilarity(getDataModel()).refresh(null);}
public void mahout_f4668_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { null, 1.0, 2.0, null, null, 6.0 }, { 1.0, 8.0, null, 3.0, 4.0, null } });    UserSimilarity similarity = new PearsonCorrelationSimilarity(dataModel);    similarity.setPreferenceInferrer(new PreferenceInferrer() {        @Override        public float inferPreference(long userID, long itemID) {            return 1.0f;        }        @Override        public void refresh(Collection<Refreshable> alreadyRefreshed) {        }    });    assertEquals(-0.435285750066007, similarity.userSimilarity(1L, 2L), EPSILON);}
public float mahout_f4669_0(long userID, long itemID)
{    return 1.0f;}
public void mahout_f4670_0(Collection<Refreshable> alreadyRefreshed)
{}
public void mahout_f4671_0() throws Exception
{    FastByIDMap<PreferenceArray> userData = new FastByIDMap<>();    userData.put(1, new GenericUserPreferenceArray(Arrays.asList(new GenericPreference(1, 1, 1), new GenericPreference(1, 2, 1), new GenericPreference(1, 3, 1))));    userData.put(2, new GenericUserPreferenceArray(Arrays.asList(new GenericPreference(2, 1, 1), new GenericPreference(2, 2, 1), new GenericPreference(2, 4, 1))));    DataModel dataModel = new GenericDataModel(userData);    ItemBasedRecommender recommender = new GenericItemBasedRecommender(dataModel, new TanimotoCoefficientSimilarity(dataModel));    BatchItemSimilarities batchSimilarities = new MultithreadedBatchItemSimilarities(recommender, 10);    batchSimilarities.computeItemSimilarities(1, 1, mock(SimilarItemsWriter.class));}
public void mahout_f4672_0() throws Exception
{    FastByIDMap<PreferenceArray> userData = new FastByIDMap<>();    userData.put(1, new GenericUserPreferenceArray(Arrays.asList(new GenericPreference(1, 1, 1), new GenericPreference(1, 2, 1), new GenericPreference(1, 3, 1))));    userData.put(2, new GenericUserPreferenceArray(Arrays.asList(new GenericPreference(2, 1, 1), new GenericPreference(2, 2, 1), new GenericPreference(2, 4, 1))));    DataModel dataModel = new GenericDataModel(userData);    ItemBasedRecommender recommender = new GenericItemBasedRecommender(dataModel, new TanimotoCoefficientSimilarity(dataModel));    BatchItemSimilarities batchSimilarities = new MultithreadedBatchItemSimilarities(recommender, 10);        batchSimilarities.computeItemSimilarities(2, 1, mock(SimilarItemsWriter.class));    fail();}
public void mahout_f4673_0() throws Exception
{    FastByIDMap<PreferenceArray> userData = new FastByIDMap<>();    userData.put(1, new GenericUserPreferenceArray(Arrays.asList(new GenericPreference(1, 1, 1), new GenericPreference(1, 2, 1), new GenericPreference(1, 3, 1))));    userData.put(2, new GenericUserPreferenceArray(Arrays.asList(new GenericPreference(2, 1, 1), new GenericPreference(2, 2, 1), new GenericPreference(2, 4, 1))));    DataModel dataModel = new GenericDataModel(userData);    ItemBasedRecommender recommender = new GenericItemBasedRecommender(dataModel, new TanimotoCoefficientSimilarity(dataModel));    BatchItemSimilarities batchSimilarities = new MultithreadedBatchItemSimilarities(recommender, 10, 2);    int numOutputSimilarities = batchSimilarities.computeItemSimilarities(2, 1, mock(SimilarItemsWriter.class));    assertEquals(numOutputSimilarities, 10);}
 static void mahout_f4674_0(double expected, double actual)
{    if (Double.isNaN(expected)) {        assertTrue("Correlation is not NaN", Double.isNaN(actual));    } else {        assertTrue("Correlation is NaN", !Double.isNaN(actual));        assertTrue("Correlation > 1.0", actual <= 1.0);        assertTrue("Correlation < -1.0", actual >= -1.0);        assertEquals(expected, actual, EPSILON);    }}
public void mahout_f4675_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 1.0, 2.0, 3.0 }, { 1.0, 2.0, 3.0 } });    double correlation = new SpearmanCorrelationSimilarity(dataModel).userSimilarity(1, 2);    assertCorrelationEquals(1.0, correlation);}
public void mahout_f4676_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 1.0, 2.0, 3.0 }, { 4.0, 5.0, 6.0 } });    double correlation = new SpearmanCorrelationSimilarity(dataModel).userSimilarity(1, 2);    assertCorrelationEquals(1.0, correlation);}
public void mahout_f4677_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 1.0, 2.0, 3.0 }, { 3.0, 2.0, 1.0 } });    double correlation = new SpearmanCorrelationSimilarity(dataModel).userSimilarity(1, 2);    assertCorrelationEquals(-1.0, correlation);}
public void mahout_f4678_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 1.0, 2.0, 3.0 }, { 2.0, 3.0, 1.0 } });    double correlation = new SpearmanCorrelationSimilarity(dataModel).userSimilarity(1, 2);    assertCorrelationEquals(-0.5, correlation);}
public void mahout_f4679_0()
{        new SpearmanCorrelationSimilarity(getDataModel()).refresh(null);}
public void mahout_f4680_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { null, 2.0, 3.0 }, { 1.0 } });    double correlation = new TanimotoCoefficientSimilarity(dataModel).userSimilarity(1, 2);    assertCorrelationEquals(Double.NaN, correlation);}
public void mahout_f4681_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 1.0 }, { 1.0 } });    double correlation = new TanimotoCoefficientSimilarity(dataModel).userSimilarity(1, 2);    assertCorrelationEquals(1.0, correlation);}
public void mahout_f4682_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 1.0, 2.0, 3.0 }, { 1.0 } });    double correlation = new TanimotoCoefficientSimilarity(dataModel).userSimilarity(1, 2);    assertCorrelationEquals(0.3333333333333333, correlation);}
public void mahout_f4683_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { null, 2.0, 3.0 }, { 1.0, 1.0 } });    double correlation = new TanimotoCoefficientSimilarity(dataModel).userSimilarity(1, 2);    assertEquals(0.3333333333333333, correlation, EPSILON);}
public void mahout_f4684_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { null, 2.0, 3.0, 1.0 }, { 1.0, 1.0, null, 0.0 } });    double correlation = new TanimotoCoefficientSimilarity(dataModel).userSimilarity(1, 2);    assertEquals(0.5, correlation, EPSILON);}
public void mahout_f4685_0()
{        new TanimotoCoefficientSimilarity(getDataModel()).refresh(null);}
public void mahout_f4686_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { null, null, 3.0 }, { 1.0, 1.0, null } });    Double similarity = new TanimotoCoefficientSimilarity(dataModel).itemSimilarity(1, 2);    assertEquals(Double.NaN, similarity, EPSILON);}
public void mahout_f4687_0() throws Exception
{    DataModel dataModel = getDataModel(new long[] { 1, 2 }, new Double[][] { { 2.0, null, 2.0 }, { 1.0, 1.0, 1.0 } });    TanimotoCoefficientSimilarity tCS = new TanimotoCoefficientSimilarity(dataModel);    assertEquals(0.5, tCS.itemSimilarity(0, 1), EPSILON);    assertEquals(1, tCS.itemSimilarity(0, 2), EPSILON);    double[] similarities = tCS.itemSimilarities(0, new long[] { 1, 2 });    assertEquals(0.5, similarities[0], EPSILON);    assertEquals(1, similarities[1], EPSILON);}
public static DataModel mahout_f4688_0(long[] userIDs, Double[][] prefValues)
{    FastByIDMap<PreferenceArray> result = new FastByIDMap<>();    for (int i = 0; i < userIDs.length; i++) {        List<Preference> prefsList = Lists.newArrayList();        for (int j = 0; j < prefValues[i].length; j++) {            if (prefValues[i][j] != null) {                prefsList.add(new GenericPreference(userIDs[i], j, prefValues[i][j].floatValue()));            }        }        if (!prefsList.isEmpty()) {            result.put(userIDs[i], new GenericUserPreferenceArray(prefsList));        }    }    return new GenericDataModel(result);}
public static DataModel mahout_f4689_0(long[] userIDs, boolean[][] prefs)
{    FastByIDMap<FastIDSet> result = new FastByIDMap<>();    for (int i = 0; i < userIDs.length; i++) {        FastIDSet prefsSet = new FastIDSet();        for (int j = 0; j < prefs[i].length; j++) {            if (prefs[i][j]) {                prefsSet.add(j);            }        }        if (!prefsSet.isEmpty()) {            result.put(userIDs[i], prefsSet);        }    }    return new GenericBooleanPrefDataModel(result);}
protected static DataModel mahout_f4690_0()
{    return getDataModel(new long[] { 1, 2, 3, 4 }, new Double[][] { { 0.1, 0.3 }, { 0.2, 0.3, 0.3 }, { 0.4, 0.3, 0.5 }, { 0.7, 0.3, 0.8 } });}
protected static DataModel mahout_f4691_0()
{    return getBooleanDataModel(new long[] { 1, 2, 3, 4 }, new boolean[][] { { false, true, false }, { false, true, true, false }, { true, false, false, true }, { true, false, true, true } });}
protected static boolean mahout_f4692_0(long[] array, long value)
{    for (long l : array) {        if (l == value) {            return true;        }    }    return false;}
public void mahout_f4693_0()
{    List<RecommendedItem> recommendedItems = new ArrayList<>();    for (long itemId = 2; itemId < 10; itemId++) {        recommendedItems.add(new GenericRecommendedItem(itemId, itemId));    }    SimilarItems similarItems = new SimilarItems(1, recommendedItems);    assertThat(similarItems.getSimilarItems(), Matchers.<SimilarItem>iterableWithSize(recommendedItems.size()));    int byHandIndex = 0;    for (SimilarItem simItem : similarItems.getSimilarItems()) {        RecommendedItem recItem = recommendedItems.get(byHandIndex++);        assertEquals(simItem.getItemID(), recItem.getItemID());        assertEquals(simItem.getSimilarity(), recItem.getValue(), EPSILON);    }}
public void mahout_f4694_0()
{    ConfusionMatrix confusionMatrix = fillConfusionMatrix(VALUES, LABELS, DEFAULT_LABEL);    checkValues(confusionMatrix);    checkAccuracy(confusionMatrix);}
public void mahout_f4695_0()
{    ConfusionMatrix confusionMatrix = fillConfusionMatrix(VALUES, LABELS, DEFAULT_LABEL);    Matrix m = confusionMatrix.getMatrix();    Map<String, Integer> rowLabels = m.getRowLabelBindings();    assertEquals(confusionMatrix.getLabels().size(), m.numCols());    assertTrue(rowLabels.keySet().contains(LABELS[0]));    assertTrue(rowLabels.keySet().contains(LABELS[1]));    assertTrue(rowLabels.keySet().contains(DEFAULT_LABEL));    assertEquals(2, confusionMatrix.getCorrect(LABELS[0]));    assertEquals(20, confusionMatrix.getCorrect(LABELS[1]));    assertEquals(0, confusionMatrix.getCorrect(DEFAULT_LABEL));}
public void mahout_f4696_0()
{    Collection<String> labelList = Arrays.asList("0", "1", "2");    ConfusionMatrix confusionMatrix = new ConfusionMatrix(labelList, "DEFAULT");    confusionMatrix.putCount("0", "0", 2);    confusionMatrix.putCount("1", "0", 1);    confusionMatrix.putCount("1", "2", 1);    confusionMatrix.putCount("2", "1", 2);    double delta = 0.001;    assertEquals(0.222, confusionMatrix.getWeightedPrecision(), delta);    assertEquals(0.333, confusionMatrix.getWeightedRecall(), delta);    assertEquals(0.266, confusionMatrix.getWeightedF1score(), delta);}
private static void mahout_f4697_0(ConfusionMatrix cm)
{    int[][] counts = cm.getConfusionMatrix();    cm.toString();    assertEquals(counts.length, counts[0].length);    assertEquals(3, counts.length);    assertEquals(VALUES[0][0], counts[0][0]);    assertEquals(VALUES[0][1], counts[0][1]);    assertEquals(VALUES[1][0], counts[1][0]);    assertEquals(VALUES[1][1], counts[1][1]);        assertTrue(Arrays.equals(new int[3], counts[2]));    assertEquals(OTHER[0], counts[0][2]);    assertEquals(OTHER[1], counts[1][2]);    assertEquals(3, cm.getLabels().size());    assertTrue(cm.getLabels().contains(LABELS[0]));    assertTrue(cm.getLabels().contains(LABELS[1]));    assertTrue(cm.getLabels().contains(DEFAULT_LABEL));}
private static void mahout_f4698_0(ConfusionMatrix cm)
{    Collection<String> labelstrs = cm.getLabels();    assertEquals(3, labelstrs.size());    assertEquals(25.0, cm.getAccuracy("Label1"), EPSILON);    assertEquals(55.5555555, cm.getAccuracy("Label2"), EPSILON);    assertTrue(Double.isNaN(cm.getAccuracy("other")));}
private static ConfusionMatrix mahout_f4699_0(int[][] values, String[] labels, String defaultLabel)
{    Collection<String> labelList = Lists.newArrayList();    labelList.add(labels[0]);    labelList.add(labels[1]);    ConfusionMatrix confusionMatrix = new ConfusionMatrix(labelList, defaultLabel);    confusionMatrix.putCount("Label1", "Label1", values[0][0]);    confusionMatrix.putCount("Label1", "Label2", values[0][1]);    confusionMatrix.putCount("Label2", "Label1", values[1][0]);    confusionMatrix.putCount("Label2", "Label2", values[1][1]);    confusionMatrix.putCount("Label1", DEFAULT_LABEL, OTHER[0]);    confusionMatrix.putCount("Label2", DEFAULT_LABEL, OTHER[1]);    return confusionMatrix;}
public void mahout_f4700_0() throws Exception
{    Random rng = RandomUtils.getRandom();    int nbAttributes = rng.nextInt(100) + 1;    boolean[] selected = new boolean[nbAttributes];    for (int nloop = 0; nloop < 100; nloop++) {        Arrays.fill(selected, false);                int nbSelected = rng.nextInt(nbAttributes - 1);        for (int index = 0; index < nbSelected; index++) {            int attr;            do {                attr = rng.nextInt(nbAttributes);            } while (selected[attr]);            selected[attr] = true;        }        int m = rng.nextInt(nbAttributes);        Method randomAttributes = DecisionTreeBuilder.class.getDeclaredMethod("randomAttributes", Random.class, boolean[].class, int.class);        randomAttributes.setAccessible(true);        int[] attrs = (int[]) randomAttributes.invoke(null, rng, selected, m);        assertNotNull(attrs);        assertEquals(Math.min(m, nbAttributes - nbSelected), attrs.length);        for (int attr : attrs) {                        assertFalse("an attribute has already been selected", selected[attr]);                        assertTrue(attr >= 0);            assertTrue(attr < nbAttributes);                        assertEquals(ArrayUtils.indexOf(attrs, attr), ArrayUtils.lastIndexOf(attrs, attr));        }    }}
public void mahout_f4701_0() throws Exception
{    Random rng = RandomUtils.getRandom();    int nbAttributes = rng.nextInt(100) + 1;    boolean[] selected = new boolean[nbAttributes];    for (int nloop = 0; nloop < 100; nloop++) {        Arrays.fill(selected, false);                int nbSelected = rng.nextInt(nbAttributes - 1);        for (int index = 0; index < nbSelected; index++) {            int attr;            do {                attr = rng.nextInt(nbAttributes);            } while (selected[attr]);            selected[attr] = true;        }        int m = rng.nextInt(nbAttributes);        int[] attrs = DefaultTreeBuilder.randomAttributes(rng, selected, m);        assertNotNull(attrs);        assertEquals(Math.min(m, nbAttributes - nbSelected), attrs.length);        for (int attr : attrs) {                        assertFalse("an attribute has already been selected", selected[attr]);                        assertTrue(attr >= 0);            assertTrue(attr < nbAttributes);                        assertEquals(ArrayUtils.indexOf(attrs, attr), ArrayUtils.lastIndexOf(attrs, attr));        }    }}
public void mahout_f4702_0() throws Exception
{    Random rng = RandomUtils.getRandom();    String[] source = Utils.double2String(dData);    String descriptor = "N N N N N N N N L";    Dataset dataset = DataLoader.generateDataset(descriptor, false, source);    Data data = DataLoader.loadData(dataset, source);    TreeBuilder builder = new DecisionTreeBuilder();    builder.build(rng, data);        dataset = DataLoader.generateDataset(descriptor, true, source);    data = DataLoader.loadData(dataset, source);    builder = new DecisionTreeBuilder();    builder.build(rng, data);}
public void mahout_f4703_0() throws Exception
{    Random rng = RandomUtils.getRandom();    String descriptor = Utils.randomDescriptor(rng, ATTRIBUTE_COUNT);    double[][] source = Utils.randomDoubles(rng, descriptor, false, INSTANCE_COUNT);    String[] sData = Utils.double2String(source);    Dataset dataset = DataLoader.generateDataset(descriptor, false, sData);    Data data = DataLoader.loadData(dataset, sData);    DataConverter converter = new DataConverter(dataset);    for (int index = 0; index < data.size(); index++) {        assertEquals(data.get(index), converter.convert(sData[index]));    }        source = Utils.randomDoubles(rng, descriptor, true, INSTANCE_COUNT);    sData = Utils.double2String(source);    dataset = DataLoader.generateDataset(descriptor, true, sData);    data = DataLoader.loadData(dataset, sData);    converter = new DataConverter(dataset);    for (int index = 0; index < data.size(); index++) {        assertEquals(data.get(index), converter.convert(sData[index]));    }}
public void mahout_f4704_0() throws Exception
{    super.setUp();    rng = RandomUtils.getRandom();}
public void mahout_f4705_0() throws Exception
{    int nbAttributes = 10;    int datasize = 100;        String descriptor = Utils.randomDescriptor(rng, nbAttributes);    Attribute[] attrs = DescriptorUtils.parseDescriptor(descriptor);        double[][] data = Utils.randomDoubles(rng, descriptor, false, datasize);    Collection<Integer> missings = Lists.newArrayList();    String[] sData = prepareData(data, attrs, missings);    Dataset dataset = DataLoader.generateDataset(descriptor, false, sData);    Data loaded = DataLoader.loadData(dataset, sData);    testLoadedData(data, attrs, missings, loaded);    testLoadedDataset(data, attrs, missings, loaded);        data = Utils.randomDoubles(rng, descriptor, true, datasize);    missings = Lists.newArrayList();    sData = prepareData(data, attrs, missings);    dataset = DataLoader.generateDataset(descriptor, true, sData);    loaded = DataLoader.loadData(dataset, sData);    testLoadedData(data, attrs, missings, loaded);    testLoadedDataset(data, attrs, missings, loaded);}
public void mahout_f4706_0() throws Exception
{    int nbAttributes = 10;    int datasize = 100;        String descriptor = Utils.randomDescriptor(rng, nbAttributes);    Attribute[] attrs = DescriptorUtils.parseDescriptor(descriptor);        double[][] data = Utils.randomDoubles(rng, descriptor, false, datasize);    Collection<Integer> missings = Lists.newArrayList();    String[] sData = prepareData(data, attrs, missings);    Dataset expected = DataLoader.generateDataset(descriptor, false, sData);    Dataset dataset = DataLoader.generateDataset(descriptor, false, sData);    assertEquals(expected, dataset);        data = Utils.randomDoubles(rng, descriptor, true, datasize);    missings = Lists.newArrayList();    sData = prepareData(data, attrs, missings);    expected = DataLoader.generateDataset(descriptor, true, sData);    dataset = DataLoader.generateDataset(descriptor, true, sData);    assertEquals(expected, dataset);}
private String[] mahout_f4707_0(double[][] data, Attribute[] attrs, Collection<Integer> missings)
{    int nbAttributes = attrs.length;    String[] sData = new String[data.length];    for (int index = 0; index < data.length; index++) {        int missingAttr;        if (rng.nextDouble() < 0.0) {                        missings.add(index);                        do {                missingAttr = rng.nextInt(nbAttributes);            } while (attrs[missingAttr].isIgnored());        } else {            missingAttr = -1;        }        StringBuilder builder = new StringBuilder();        for (int attr = 0; attr < nbAttributes; attr++) {            if (attr == missingAttr) {                                builder.append('?').append(',');            } else {                builder.append(data[index][attr]).append(',');            }        }        sData[index] = builder.toString();    }    return sData;}
 static void mahout_f4708_0(double[][] data, Attribute[] attrs, Collection<Integer> missings, Data loaded)
{    int nbAttributes = attrs.length;        assertEquals("number of instance", data.length - missings.size(), loaded.size());        int lind = 0;    for (int index = 0; index < data.length; index++) {        if (missings.contains(index)) {            continue;        }                double[] vector = data[index];        Instance instance = loaded.get(lind);        int aId = 0;        for (int attr = 0; attr < nbAttributes; attr++) {            if (attrs[attr].isIgnored()) {                continue;            }            if (attrs[attr].isNumerical()) {                assertEquals(vector[attr], instance.get(aId), EPSILON);                aId++;            } else if (attrs[attr].isCategorical()) {                checkCategorical(data, missings, loaded, attr, aId, vector[attr], instance.get(aId));                aId++;            } else if (attrs[attr].isLabel()) {                if (loaded.getDataset().isNumerical(aId)) {                    assertEquals(vector[attr], instance.get(aId), EPSILON);                } else {                    checkCategorical(data, missings, loaded, attr, aId, vector[attr], instance.get(aId));                }                aId++;            }        }        lind++;    }}
 static void mahout_f4709_0(double[][] data, Attribute[] attrs, Collection<Integer> missings, Data loaded)
{    int nbAttributes = attrs.length;    int iId = 0;    for (int index = 0; index < data.length; index++) {        if (missings.contains(index)) {            continue;        }        Instance instance = loaded.get(iId++);        int aId = 0;        for (int attr = 0; attr < nbAttributes; attr++) {            if (attrs[attr].isIgnored()) {                continue;            }            if (attrs[attr].isLabel()) {                if (!loaded.getDataset().isNumerical(aId)) {                    double nValue = instance.get(aId);                    String oValue = Double.toString(data[index][attr]);                    assertEquals(loaded.getDataset().valueOf(aId, oValue), nValue, EPSILON);                }            } else {                assertEquals(attrs[attr].isNumerical(), loaded.getDataset().isNumerical(aId));                if (attrs[attr].isCategorical()) {                    double nValue = instance.get(aId);                    String oValue = Double.toString(data[index][attr]);                    assertEquals(loaded.getDataset().valueOf(aId, oValue), nValue, EPSILON);                }            }            aId++;        }    }}
public void mahout_f4710_0() throws Exception
{    int nbAttributes = 10;    int datasize = 100;        String descriptor = Utils.randomDescriptor(rng, nbAttributes);    Attribute[] attrs = DescriptorUtils.parseDescriptor(descriptor);        double[][] source = Utils.randomDoubles(rng, descriptor, false, datasize);    Collection<Integer> missings = Lists.newArrayList();    String[] sData = prepareData(source, attrs, missings);    Dataset dataset = DataLoader.generateDataset(descriptor, false, sData);    Path dataPath = Utils.writeDataToTestFile(sData);    FileSystem fs = dataPath.getFileSystem(getConfiguration());    Data loaded = DataLoader.loadData(dataset, fs, dataPath);    testLoadedData(source, attrs, missings, loaded);        source = Utils.randomDoubles(rng, descriptor, true, datasize);    missings = Lists.newArrayList();    sData = prepareData(source, attrs, missings);    dataset = DataLoader.generateDataset(descriptor, true, sData);    dataPath = Utils.writeDataToTestFile(sData);    fs = dataPath.getFileSystem(getConfiguration());    loaded = DataLoader.loadData(dataset, fs, dataPath);    testLoadedData(source, attrs, missings, loaded);}
public void mahout_f4711_0() throws Exception
{    int nbAttributes = 10;    int datasize = 100;        String descriptor = Utils.randomDescriptor(rng, nbAttributes);    Attribute[] attrs = DescriptorUtils.parseDescriptor(descriptor);        double[][] source = Utils.randomDoubles(rng, descriptor, false, datasize);    Collection<Integer> missings = Lists.newArrayList();    String[] sData = prepareData(source, attrs, missings);    Dataset expected = DataLoader.generateDataset(descriptor, false, sData);    Path path = Utils.writeDataToTestFile(sData);    FileSystem fs = path.getFileSystem(getConfiguration());    Dataset dataset = DataLoader.generateDataset(descriptor, false, fs, path);    assertEquals(expected, dataset);        source = Utils.randomDoubles(rng, descriptor, false, datasize);    missings = Lists.newArrayList();    sData = prepareData(source, attrs, missings);    expected = DataLoader.generateDataset(descriptor, false, sData);    path = Utils.writeDataToTestFile(sData);    fs = path.getFileSystem(getConfiguration());    dataset = DataLoader.generateDataset(descriptor, false, fs, path);    assertEquals(expected, dataset);}
 static void mahout_f4712_0(double[][] source, Collection<Integer> missings, Data loaded, int attr, int aId, double oValue, double nValue)
{    int lind = 0;    for (int index = 0; index < source.length; index++) {        if (missings.contains(index)) {            continue;        }        if (source[index][attr] == oValue) {            assertEquals(nValue, loaded.get(lind).get(aId), EPSILON);        } else {            assertFalse(nValue == loaded.get(lind).get(aId));        }        lind++;    }}
public void mahout_f4713_0() throws DescriptorException
{    Dataset to = DataLoader.generateDataset("N C I L", true, new String[] { "1 foo 2 3", "4 bar 5 6" });            assertEquals(3, to.nbAttributes());    assertEquals(1, to.getIgnored().length);    assertEquals(2, to.getIgnored()[0]);    assertEquals(2, to.getLabelId());    assertTrue(to.isNumerical(0));        Dataset fromJson = Dataset.fromJSON(to.toJSON());    assertEquals(3, fromJson.nbAttributes());    assertEquals(1, fromJson.getIgnored().length);    assertEquals(2, fromJson.getIgnored()[0]);    assertTrue(fromJson.isNumerical(0));        assertNotEquals(fromJson.valueOf(1, "bar"), fromJson.valueOf(1, "foo"));}
public void mahout_f4714_0() throws DescriptorException
{    ;    Dataset to = DataLoader.generateDataset("N C I L", false, new String[] { "1 foo 2 Red", "4 bar 5 Blue" });            assertEquals(3, to.nbAttributes());    assertEquals(1, to.getIgnored().length);    assertEquals(2, to.getIgnored()[0]);    assertEquals(2, to.getLabelId());    assertTrue(to.isNumerical(0));    assertNotEquals(to.valueOf(1, "bar"), to.valueOf(1, "foo"));    assertNotEquals(to.valueOf(2, "Red"), to.valueOf(2, "Blue"));        Dataset fromJson = Dataset.fromJSON(to.toJSON());    assertEquals(3, fromJson.nbAttributes());    assertEquals(1, fromJson.getIgnored().length);    assertEquals(2, fromJson.getIgnored()[0]);    assertTrue(fromJson.isNumerical(0));        assertNotEquals(fromJson.valueOf(1, "bar"), fromJson.valueOf(1, "foo"));    assertNotEquals(fromJson.valueOf(2, "Red"), fromJson.valueOf(2, "Blue"));}
public void mahout_f4715_0() throws Exception
{    super.setUp();    rng = RandomUtils.getRandom();    classifierData = Utils.randomData(rng, ATTRIBUTE_COUNT, false, DATA_SIZE);    regressionData = Utils.randomData(rng, ATTRIBUTE_COUNT, true, DATA_SIZE);}
public void mahout_f4716_0()
{    int n = 10;    for (int nloop = 0; nloop < n; nloop++) {        int attr = rng.nextInt(classifierData.getDataset().nbAttributes());        double[] values = classifierData.values(attr);        double value = values[rng.nextInt(values.length)];        Data eSubset = classifierData.subset(Condition.equals(attr, value));        Data lSubset = classifierData.subset(Condition.lesser(attr, value));        Data gSubset = classifierData.subset(Condition.greaterOrEquals(attr, value));        for (int index = 0; index < DATA_SIZE; index++) {            Instance instance = classifierData.get(index);            if (instance.get(attr) < value) {                assertTrue(lSubset.contains(instance));                assertFalse(eSubset.contains(instance));                assertFalse(gSubset.contains(instance));            } else if (instance.get(attr) == value) {                assertFalse(lSubset.contains(instance));                assertTrue(eSubset.contains(instance));                assertTrue(gSubset.contains(instance));            } else {                assertFalse(lSubset.contains(instance));                assertFalse(eSubset.contains(instance));                assertTrue(gSubset.contains(instance));            }        }                attr = rng.nextInt(regressionData.getDataset().nbAttributes());        values = regressionData.values(attr);        value = values[rng.nextInt(values.length)];        eSubset = regressionData.subset(Condition.equals(attr, value));        lSubset = regressionData.subset(Condition.lesser(attr, value));        gSubset = regressionData.subset(Condition.greaterOrEquals(attr, value));        for (int index = 0; index < DATA_SIZE; index++) {            Instance instance = regressionData.get(index);            if (instance.get(attr) < value) {                assertTrue(lSubset.contains(instance));                assertFalse(eSubset.contains(instance));                assertFalse(gSubset.contains(instance));            } else if (instance.get(attr) == value) {                assertFalse(lSubset.contains(instance));                assertTrue(eSubset.contains(instance));                assertTrue(gSubset.contains(instance));            } else {                assertFalse(lSubset.contains(instance));                assertFalse(eSubset.contains(instance));                assertTrue(gSubset.contains(instance));            }        }    }}
public void mahout_f4717_0() throws Exception
{    for (int attr = 0; attr < classifierData.getDataset().nbAttributes(); attr++) {        double[] values = classifierData.values(attr);                for (int index = 0; index < DATA_SIZE; index++) {            assertEquals(1, count(values, classifierData.get(index).get(attr)));        }    }    for (int attr = 0; attr < regressionData.getDataset().nbAttributes(); attr++) {        double[] values = regressionData.values(attr);                for (int index = 0; index < DATA_SIZE; index++) {            assertEquals(1, count(values, regressionData.get(index).get(attr)));        }    }}
private static int mahout_f4718_0(double[] values, double value)
{    int count = 0;    for (double v : values) {        if (v == value) {            count++;        }    }    return count;}
public void mahout_f4719_0() throws Exception
{        Dataset dataset = Utils.randomData(rng, ATTRIBUTE_COUNT, false, 1).getDataset();        Data empty = new Data(dataset);    assertTrue(empty.isIdentical());        Data identical = Utils.randomData(rng, ATTRIBUTE_COUNT, false, DATA_SIZE);    Instance model = identical.get(0);    for (int index = 1; index < DATA_SIZE; index++) {        for (int attr = 0; attr < identical.getDataset().nbAttributes(); attr++) {            identical.get(index).set(attr, model.get(attr));        }    }    assertTrue(identical.isIdentical());}
public void mahout_f4720_0() throws Exception
{    int n = 10;    for (int nloop = 0; nloop < n; nloop++) {        Data data = Utils.randomData(rng, ATTRIBUTE_COUNT, false, DATA_SIZE);                int index = rng.nextInt(DATA_SIZE);        Instance instance = data.get(index);                int attr = rng.nextInt(data.getDataset().nbAttributes());        instance.set(attr, instance.get(attr) + 1);        assertFalse(data.isIdentical());    }}
public void mahout_f4721_0() throws Exception
{        Dataset dataset = Utils.randomData(rng, ATTRIBUTE_COUNT, false, 1).getDataset();        Data empty = new Data(dataset);    assertTrue(empty.identicalLabel());        String descriptor = Utils.randomDescriptor(rng, ATTRIBUTE_COUNT);    double[][] source = Utils.randomDoublesWithSameLabel(rng, descriptor, false, DATA_SIZE, rng.nextInt());    String[] sData = Utils.double2String(source);    dataset = DataLoader.generateDataset(descriptor, false, sData);    Data data = DataLoader.loadData(dataset, sData);    assertTrue(data.identicalLabel());}
public void mahout_f4722_0() throws Exception
{    int n = 10;    for (int nloop = 0; nloop < n; nloop++) {        String descriptor = Utils.randomDescriptor(rng, ATTRIBUTE_COUNT);        int label = Utils.findLabel(descriptor);        double[][] source = Utils.randomDoublesWithSameLabel(rng, descriptor, false, DATA_SIZE, rng.nextInt());                int index = rng.nextInt(DATA_SIZE);        source[index][label]++;        String[] sData = Utils.double2String(source);        Dataset dataset = DataLoader.generateDataset(descriptor, false, sData);        Data data = DataLoader.loadData(dataset, sData);        assertFalse(data.identicalLabel());    }}
public void mahout_f4723_0()
{    Data bag = classifierData.bagging(rng);        assertEquals(classifierData.size(), bag.size());        boolean found = false;    for (int index = 0; index < classifierData.size() && !found; index++) {        found = !bag.contains(classifierData.get(index));    }    assertTrue("some instances from data should not be in the bag", found);        bag = regressionData.bagging(rng);        assertEquals(regressionData.size(), bag.size());        found = false;    for (int index = 0; index < regressionData.size() && !found; index++) {        found = !bag.contains(regressionData.get(index));    }    assertTrue("some instances from data should not be in the bag", found);}
public void mahout_f4724_0()
{        Data source = classifierData.clone();    Data subset = source.rsplit(rng, 0);    assertTrue("subset should be empty", subset.isEmpty());    assertEquals("source.size is incorrect", DATA_SIZE, source.size());        source = classifierData.clone();    subset = source.rsplit(rng, DATA_SIZE);    assertEquals("subset.size is incorrect", DATA_SIZE, subset.size());    assertTrue("source should be empty", source.isEmpty());        int subsize = rng.nextInt(DATA_SIZE);    source = classifierData.clone();    subset = source.rsplit(rng, subsize);    assertEquals("subset.size is incorrect", subsize, subset.size());    assertEquals("source.size is incorrect", DATA_SIZE - subsize, source.size());            source = regressionData.clone();    subset = source.rsplit(rng, 0);    assertTrue("subset should be empty", subset.isEmpty());    assertEquals("source.size is incorrect", DATA_SIZE, source.size());        source = regressionData.clone();    subset = source.rsplit(rng, DATA_SIZE);    assertEquals("subset.size is incorrect", DATA_SIZE, subset.size());    assertTrue("source should be empty", source.isEmpty());        subsize = rng.nextInt(DATA_SIZE);    source = regressionData.clone();    subset = source.rsplit(rng, subsize);    assertEquals("subset.size is incorrect", subsize, subset.size());    assertEquals("source.size is incorrect", DATA_SIZE - subsize, source.size());}
public void mahout_f4725_0() throws Exception
{    Dataset dataset = classifierData.getDataset();    int[] counts = new int[dataset.nblabels()];    int n = 10;    for (int nloop = 0; nloop < n; nloop++) {        Arrays.fill(counts, 0);        classifierData.countLabels(counts);        for (int index = 0; index < classifierData.size(); index++) {            counts[(int) dataset.getLabel(classifierData.get(index))]--;        }        for (int label = 0; label < classifierData.getDataset().nblabels(); label++) {            assertEquals("Wrong label 'equals' count", 0, counts[0]);        }    }}
public void mahout_f4726_0() throws Exception
{        String descriptor = Utils.randomDescriptor(rng, ATTRIBUTE_COUNT);    int label = Utils.findLabel(descriptor);    int label1 = rng.nextInt();    double[][] source = Utils.randomDoublesWithSameLabel(rng, descriptor, false, 100, label1);    String[] sData = Utils.double2String(source);    Dataset dataset = DataLoader.generateDataset(descriptor, false, sData);    Data data = DataLoader.loadData(dataset, sData);    int code1 = dataset.labelCode(Double.toString(label1));    assertEquals(code1, data.majorityLabel(rng));        int label2 = label1 + 1;    int nblabel2 = 51;    while (nblabel2 > 0) {        double[] vector = source[rng.nextInt(100)];        if (vector[label] != label2) {            vector[label] = label2;            nblabel2--;        }    }    sData = Utils.double2String(source);    dataset = DataLoader.generateDataset(descriptor, false, sData);    data = DataLoader.loadData(dataset, sData);    int code2 = dataset.labelCode(Double.toString(label2));        assertEquals(code2, data.majorityLabel(rng));        do {        double[] vector = source[rng.nextInt(100)];        if (vector[label] == label2) {            vector[label] = label1;            break;        }    } while (true);    sData = Utils.double2String(source);    data = DataLoader.loadData(dataset, sData);    code1 = dataset.labelCode(Double.toString(label1));    code2 = dataset.labelCode(Double.toString(label2));        boolean found1 = false;    boolean found2 = false;    for (int index = 0; index < 10 && (!found1 || !found2); index++) {        int major = data.majorityLabel(rng);        if (major == code1) {            found1 = true;        }        if (major == code2) {            found2 = true;        }    }    assertTrue(found1 && found2);}
public void mahout_f4727_0() throws Exception
{    int n = 10;    int maxnbAttributes = 100;    Random rng = RandomUtils.getRandom();    for (int nloop = 0; nloop < n; nloop++) {        int nbAttributes = rng.nextInt(maxnbAttributes) + 1;        char[] tokens = Utils.randomTokens(rng, nbAttributes);        Attribute[] attrs = DescriptorUtils.parseDescriptor(Utils.generateDescriptor(tokens));                assertEquals("attributes size", nbAttributes, attrs.length);        for (int attr = 0; attr < nbAttributes; attr++) {            switch(tokens[attr]) {                case 'I':                    assertTrue(attrs[attr].isIgnored());                    break;                case 'N':                    assertTrue(attrs[attr].isNumerical());                    break;                case 'C':                    assertTrue(attrs[attr].isCategorical());                    break;                case 'L':                    assertTrue(attrs[attr].isLabel());                    break;            }        }    }}
public void mahout_f4728_0() throws Exception
{    validate("", "");    validate("I L C C N N N C", "I L C C N N N C");    validate("I L C C N N N C", "I L 2 C 3 N C");    validate("I L C C N N N C", " I L  2 C 3 N C ");    try {        validate("", "I L 2 2 C 2 N C");        fail("2 consecutive multiplicators");    } catch (DescriptorException e) {    }    try {        validate("", "I L 2 C -2 N C");        fail("negative multiplicator");    } catch (DescriptorException e) {    }}
private static void mahout_f4729_0(String descriptor, CharSequence description) throws DescriptorException
{    assertEquals(descriptor, DescriptorUtils.generateDescriptor(description));}
public static char[] mahout_f4730_0(Random rng, int nbTokens)
{    char[] result = new char[nbTokens];    for (int token = 0; token < nbTokens; token++) {        double rand = rng.nextDouble();        if (rand < 0.1) {                        result[token] = 'I';        } else if (rand >= 0.5) {            result[token] = 'C';        } else {                        result[token] = 'N';        }        }        result[rng.nextInt(nbTokens)] = 'L';    return result;}
public static String mahout_f4731_0(char[] tokens)
{    StringBuilder builder = new StringBuilder();    for (char token : tokens) {        builder.append(token).append(' ');    }    return builder.toString();}
public static String mahout_f4732_0(Random rng, int nbAttributes)
{    return generateDescriptor(randomTokens(rng, nbAttributes));}
public static double[][] mahout_f4733_0(Random rng, CharSequence descriptor, boolean regression, int number) throws DescriptorException
{    Attribute[] attrs = DescriptorUtils.parseDescriptor(descriptor);    double[][] data = new double[number][];    for (int index = 0; index < number; index++) {        data[index] = randomVector(rng, attrs, regression);    }    return data;}
public static Data mahout_f4734_0(Random rng, int nbAttributes, boolean regression, int size) throws DescriptorException
{    String descriptor = randomDescriptor(rng, nbAttributes);    double[][] source = randomDoubles(rng, descriptor, regression, size);    String[] sData = double2String(source);    Dataset dataset = DataLoader.generateDataset(descriptor, regression, sData);    return DataLoader.loadData(dataset, sData);}
private static double[] mahout_f4735_0(Random rng, Attribute[] attrs, boolean regression)
{    double[] vector = new double[attrs.length];    for (int attr = 0; attr < attrs.length; attr++) {        if (attrs[attr].isIgnored()) {            vector[attr] = Double.NaN;        } else if (attrs[attr].isNumerical()) {            vector[attr] = rng.nextDouble();        } else if (attrs[attr].isCategorical()) {            vector[attr] = rng.nextInt(CATEGORICAL_RANGE);        } else {                        if (regression) {                vector[attr] = rng.nextDouble();            } else {                vector[attr] = rng.nextInt(CATEGORICAL_RANGE);            }        }    }    return vector;}
private static String mahout_f4736_0(double[] v)
{    StringBuilder builder = new StringBuilder();    for (double aV : v) {        builder.append(aV).append(',');    }    return builder.toString();}
public static String[] mahout_f4737_0(double[][] source)
{    String[] output = new String[source.length];    for (int index = 0; index < source.length; index++) {        output[index] = double2String(source[index]);    }    return output;}
public static double[][] mahout_f4738_0(Random rng, CharSequence descriptor, boolean regression, int number, int value) throws DescriptorException
{    int label = findLabel(descriptor);    double[][] source = randomDoubles(rng, descriptor, regression, number);    for (int index = 0; index < number; index++) {        source[index][label] = value;    }    return source;}
public static int mahout_f4739_0(CharSequence descriptor) throws DescriptorException
{    Attribute[] attrs = DescriptorUtils.parseDescriptor(descriptor);    return ArrayUtils.indexOf(attrs, Attribute.LABEL);}
private static void mahout_f4740_0(String[] sData, Path path) throws IOException
{    BufferedWriter output = null;    try {        output = Files.newWriter(new File(path.toString()), Charsets.UTF_8);        for (String line : sData) {            output.write(line);            output.write('\n');        }    } finally {        Closeables.close(output, false);    }}
public static Path mahout_f4741_0(String[] sData) throws IOException
{    Path testData = new Path("testdata/Data");    MahoutTestCase ca = new MahoutTestCase();    FileSystem fs = testData.getFileSystem(ca.getConfiguration());    if (!fs.exists(testData)) {        fs.mkdirs(testData);    }    Path path = new Path(testData, "DataLoaderTest.data");    writeDataToFile(sData, path);    return path;}
public static String[][] mahout_f4742_0(String[] sData, int numMaps)
{    int nbInstances = sData.length;    int partitionSize = nbInstances / numMaps;    String[][] splits = new String[numMaps][];    for (int partition = 0; partition < numMaps; partition++) {        int from = partition * partitionSize;        int to = partition == (numMaps - 1) ? nbInstances : (partition + 1) * partitionSize;        splits[partition] = Arrays.copyOfRange(sData, from, to);    }    return splits;}
public void mahout_f4743_0() throws Exception
{    super.setUp();    rng = RandomUtils.getRandom();}
private static Data[] mahout_f4744_0() throws DescriptorException
{        Dataset dataset = DataLoader.generateDataset("C N N C L", false, TRAIN_DATA);        Data data = DataLoader.loadData(dataset, TRAIN_DATA);    @SuppressWarnings("unchecked")    List<Instance>[] instances = new List[3];    for (int i = 0; i < instances.length; i++) {        instances[i] = Lists.newArrayList();    }    for (int i = 0; i < data.size(); i++) {        if (data.get(i).get(0) == 0.0d) {            instances[0].add(data.get(i));        } else {            instances[1].add(data.get(i));        }    }    Data[] datas = new Data[instances.length];    for (int i = 0; i < datas.length; i++) {        datas[i] = new Data(dataset, instances[i]);    }    return datas;}
private static Data[] mahout_f4745_0() throws DescriptorException
{        String[] trainData = new String[20];    for (int i = 0; i < trainData.length; i++) {        if (i % 3 == 0) {            trainData[i] = "A," + (40 - i) + ',' + (i + 20);        } else if (i % 3 == 1) {            trainData[i] = "B," + (i + 20) + ',' + (40 - i);        } else {            trainData[i] = "C," + (i + 20) + ',' + (i + 20);        }    }        Dataset dataset = DataLoader.generateDataset("C N L", true, trainData);    Data[] datas = new Data[3];    datas[0] = DataLoader.loadData(dataset, trainData);        trainData = new String[20];    for (int i = 0; i < trainData.length; i++) {        if (i % 2 == 0) {            trainData[i] = "A," + (50 - i) + ',' + (i + 10);        } else {            trainData[i] = "B," + (i + 10) + ',' + (50 - i);        }    }    datas[1] = DataLoader.loadData(dataset, trainData);        trainData = new String[10];    for (int i = 0; i < trainData.length; i++) {        trainData[i] = "A," + (40 - i) + ',' + (i + 20);    }    datas[2] = DataLoader.loadData(dataset, trainData);    return datas;}
private DecisionForest mahout_f4746_0(Data[] datas)
{    List<Node> trees = Lists.newArrayList();    for (Data data : datas) {                DecisionTreeBuilder builder = new DecisionTreeBuilder();        builder.setM(data.getDataset().nbAttributes() - 1);        builder.setMinSplitNum(0);        builder.setComplemented(false);        trees.add(builder.build(rng, data));    }    return new DecisionForest(trees);}
public void mahout_f4747_0() throws DescriptorException
{        Data[] datas = generateTrainingDataA();        DecisionForest forest = buildForest(datas);        Dataset dataset = datas[0].getDataset();    Data testData = DataLoader.loadData(dataset, TEST_DATA);    double noValue = dataset.valueOf(4, "no");    double yesValue = dataset.valueOf(4, "yes");    assertEquals(noValue, forest.classify(testData.getDataset(), rng, testData.get(0)), EPSILON);            assertEquals(noValue, forest.classify(testData.getDataset(), rng, testData.get(2)), EPSILON);}
public void mahout_f4748_0() throws DescriptorException
{        Data[] datas = generateTrainingDataA();        DecisionForest forest = buildForest(datas);        Dataset dataset = datas[0].getDataset();    Data testData = DataLoader.loadData(dataset, TEST_DATA);    double[][] predictions = new double[testData.size()][];    forest.classify(testData, predictions);    double noValue = dataset.valueOf(4, "no");    double yesValue = dataset.valueOf(4, "yes");    assertArrayEquals(new double[][] { { noValue, Double.NaN, Double.NaN }, { noValue, yesValue, Double.NaN }, { noValue, noValue, Double.NaN } }, predictions);}
public void mahout_f4749_0() throws DescriptorException
{    Data[] datas = generateTrainingDataB();    DecisionForest[] forests = new DecisionForest[datas.length];    for (int i = 0; i < datas.length; i++) {        Data[] subDatas = new Data[datas.length - 1];        int k = 0;        for (int j = 0; j < datas.length; j++) {            if (j != i) {                subDatas[k] = datas[j];                k++;            }        }        forests[i] = buildForest(subDatas);    }    double[][] predictions = new double[datas[0].size()][];    forests[0].classify(datas[0], predictions);    assertArrayEquals(new double[] { 20.0, 20.0 }, predictions[0], EPSILON);    assertArrayEquals(new double[] { 39.0, 29.0 }, predictions[1], EPSILON);    assertArrayEquals(new double[] { Double.NaN, 29.0 }, predictions[2], EPSILON);    assertArrayEquals(new double[] { Double.NaN, 23.0 }, predictions[17], EPSILON);    predictions = new double[datas[1].size()][];    forests[1].classify(datas[1], predictions);    assertArrayEquals(new double[] { 30.0, 29.0 }, predictions[19], EPSILON);    predictions = new double[datas[2].size()][];    forests[2].classify(datas[2], predictions);    assertArrayEquals(new double[] { 29.0, 28.0 }, predictions[9], EPSILON);    assertEquals(20.0, forests[0].classify(datas[0].getDataset(), rng, datas[0].get(0)), EPSILON);    assertEquals(34.0, forests[0].classify(datas[0].getDataset(), rng, datas[0].get(1)), EPSILON);    assertEquals(29.0, forests[0].classify(datas[0].getDataset(), rng, datas[0].get(2)), EPSILON);}
public void mahout_f4750_0() throws Exception
{    int n = 1;    int maxNumSplits = 100;    int maxNbTrees = 1000;    Random rng = RandomUtils.getRandom();    for (int nloop = 0; nloop < n; nloop++) {        int numSplits = rng.nextInt(maxNumSplits) + 1;        int nbTrees = rng.nextInt(maxNbTrees) + 1;        Configuration conf = getConfiguration();        Builder.setNbTrees(conf, nbTrees);        InMemInputFormat inputFormat = new InMemInputFormat();        List<InputSplit> splits = inputFormat.getSplits(conf, numSplits);        assertEquals(numSplits, splits.size());        int nbTreesPerSplit = nbTrees / numSplits;        int totalTrees = 0;        int expectedId = 0;        for (int index = 0; index < numSplits; index++) {            assertTrue(splits.get(index) instanceof InMemInputSplit);            InMemInputSplit split = (InMemInputSplit) splits.get(index);            assertEquals(expectedId, split.getFirstId());            if (index < numSplits - 1) {                assertEquals(nbTreesPerSplit, split.getNbTrees());            } else {                assertEquals(nbTrees - totalTrees, split.getNbTrees());            }            totalTrees += split.getNbTrees();            expectedId += split.getNbTrees();        }    }}
public void mahout_f4751_0() throws Exception
{    int n = 1;    int maxNumSplits = 100;    int maxNbTrees = 1000;    Random rng = RandomUtils.getRandom();    for (int nloop = 0; nloop < n; nloop++) {        int numSplits = rng.nextInt(maxNumSplits) + 1;        int nbTrees = rng.nextInt(maxNbTrees) + 1;        Configuration conf = getConfiguration();        Builder.setNbTrees(conf, nbTrees);        InMemInputFormat inputFormat = new InMemInputFormat();        List<InputSplit> splits = inputFormat.getSplits(conf, numSplits);        for (int index = 0; index < numSplits; index++) {            InMemInputSplit split = (InMemInputSplit) splits.get(index);            InMemRecordReader reader = new InMemRecordReader(split);            reader.initialize(split, null);            for (int tree = 0; tree < split.getNbTrees(); tree++) {                                assertEquals(tree < split.getNbTrees(), reader.nextKeyValue());                assertEquals(split.getFirstId() + tree, reader.getCurrentKey().get());            }        }    }}
public void mahout_f4752_0() throws Exception
{    super.setUp();    rng = RandomUtils.getRandom();    byteOutStream = new ByteArrayOutputStream();    out = new DataOutputStream(byteOutStream);}
public void mahout_f4753_0() throws Exception
{    InMemInputSplit split = new InMemInputSplit(rng.nextInt(), rng.nextInt(1000), rng.nextLong());    split.write(out);    assertEquals(split, readSplit());}
public void mahout_f4754_0() throws Exception
{    InMemInputSplit split = new InMemInputSplit(rng.nextInt(), rng.nextInt(1000), null);    split.write(out);    assertEquals(split, readSplit());}
private InMemInputSplit mahout_f4755_0() throws IOException
{    ByteArrayInputStream byteInStream = new ByteArrayInputStream(byteOutStream.toByteArray());    DataInput in = new DataInputStream(byteInStream);    return InMemInputSplit.read(in);}
public void mahout_f4756_0() throws Exception
{    Configuration conf = getConfiguration();    conf.setInt("mapred.map.tasks", NUM_MAPS);    Random rng = RandomUtils.getRandom();        TreeID[] keys = new TreeID[NUM_TREES];    MapredOutput[] values = new MapredOutput[NUM_TREES];    int[] firstIds = new int[NUM_MAPS];    randomKeyValues(rng, keys, values, firstIds);        Path base = getTestTempDirPath("testdata");    FileSystem fs = base.getFileSystem(conf);    Path outputFile = new Path(base, "PartialBuilderTest.seq");    Writer writer = SequenceFile.createWriter(fs, conf, outputFile, TreeID.class, MapredOutput.class);    try {        for (int index = 0; index < NUM_TREES; index++) {            writer.append(keys[index], values[index]);        }    } finally {        Closeables.close(writer, false);    }        TreeID[] newKeys = new TreeID[NUM_TREES];    Node[] newTrees = new Node[NUM_TREES];    PartialBuilder.processOutput(new Job(conf), base, newKeys, newTrees);        for (int tree = 0; tree < NUM_TREES; tree++) {        assertEquals(values[tree].getTree(), newTrees[tree]);    }    assertTrue("keys not equal", Arrays.deepEquals(keys, newKeys));}
public void mahout_f4757_0()
{    TreeBuilder treeBuilder = new DefaultTreeBuilder();    Path dataPath = new Path("notUsedDataPath");    Path datasetPath = new Path("notUsedDatasetPath");    Long seed = 5L;    new PartialBuilderChecker(treeBuilder, dataPath, datasetPath, seed);}
private static void mahout_f4758_0(Random rng, TreeID[] keys, MapredOutput[] values, int[] firstIds)
{    int index = 0;    int firstId = 0;    Collection<Integer> partitions = Lists.newArrayList();    for (int p = 0; p < NUM_MAPS; p++) {                int partition;        do {            partition = rng.nextInt(NUM_MAPS);        } while (partitions.contains(partition));        partitions.add(partition);        int nbTrees = Step1Mapper.nbTrees(NUM_MAPS, NUM_TREES, partition);        for (int treeId = 0; treeId < nbTrees; treeId++) {            Node tree = new Leaf(rng.nextInt(100));            keys[index] = new TreeID(partition, treeId);            values[index] = new MapredOutput(tree, nextIntArray(rng, NUM_INSTANCES));            index++;        }        firstIds[p] = firstId;        firstId += NUM_INSTANCES;    }}
private static int[] mahout_f4759_0(Random rng, int size)
{    int[] array = new int[size];    for (int index = 0; index < size; index++) {        array[index] = rng.nextInt(101) - 1;    }    return array;}
protected boolean mahout_f4760_0(Job job) throws IOException
{        Configuration conf = job.getConfiguration();    assertEquals(seed, getRandomSeed(conf));            assertEquals(1, conf.getInt("mapred.map.tasks", -1));    assertEquals(NUM_TREES, getNbTrees(conf));    assertFalse(isOutput(conf));    assertEquals(treeBuilder, getTreeBuilder(conf));    assertEquals(datasetPath, getDistributedCacheFile(conf, 0));    return true;}
public void mahout_f4761_0(Data data)
{    expected = data;}
public Node mahout_f4762_0(Random rng, Data data)
{    for (int index = 0; index < data.size(); index++) {        assertTrue(expected.contains(data.get(index)));    }    return new Leaf(Double.NaN);}
public void mahout_f4763_0(final TreeID value)
{    super.setValue(value.clone());}
public void mahout_f4764_0() throws Exception
{    Random rng = RandomUtils.getRandom();        String descriptor = Utils.randomDescriptor(rng, NUM_ATTRIBUTES);    double[][] source = Utils.randomDoubles(rng, descriptor, false, NUM_INSTANCES);    String[] sData = Utils.double2String(source);    Dataset dataset = DataLoader.generateDataset(descriptor, false, sData);    String[][] splits = Utils.splitData(sData, NUM_MAPPERS);    MockTreeBuilder treeBuilder = new MockTreeBuilder();    LongWritable key = new LongWritable();    Text value = new Text();    int treeIndex = 0;    for (int partition = 0; partition < NUM_MAPPERS; partition++) {        String[] split = splits[partition];        treeBuilder.setExpected(DataLoader.loadData(dataset, split));                int mapNbTrees = Step1Mapper.nbTrees(NUM_MAPPERS, NUM_TREES, partition);        Mapper.Context context = EasyMock.createNiceMock(Mapper.Context.class);        Capture<TreeID> capturedKeys = new TreeIDCapture();        context.write(EasyMock.capture(capturedKeys), EasyMock.anyObject());        EasyMock.expectLastCall().anyTimes();        EasyMock.replay(context);        MockStep1Mapper mapper = new MockStep1Mapper(treeBuilder, dataset, null, partition, NUM_MAPPERS, NUM_TREES);                assertEquals(treeIndex, mapper.getFirstTreeId());        for (int index = 0; index < split.length; index++) {            key.set(index);            value.set(split[index]);            mapper.map(key, value, context);        }        mapper.cleanup(context);        EasyMock.verify(context);                assertEquals(mapNbTrees, capturedKeys.getValues().size());                for (TreeID k : capturedKeys.getValues()) {            assertEquals(partition, k.partition());            assertEquals(treeIndex, k.treeId());            treeIndex++;        }    }}
public void mahout_f4765_0()
{    Random rng = RandomUtils.getRandom();    for (int nloop = 0; nloop < 1000000; nloop++) {        int partition = Math.abs(rng.nextInt());        int treeId = rng.nextInt(TreeID.MAX_TREEID);        TreeID t1 = new TreeID(partition, treeId);        assertEquals(partition, t1.partition());        assertEquals(treeId, t1.treeId());        TreeID t2 = new TreeID();        t2.set(partition, treeId);        assertEquals(partition, t2.partition());        assertEquals(treeId, t2.treeId());    }}
public void mahout_f4766_0() throws Exception
{    super.setUp();    rng = RandomUtils.getRandom();    byteOutStream = new ByteArrayOutputStream();    out = new DataOutputStream(byteOutStream);}
public void mahout_f4767_0() throws Exception
{    Node node1 = new CategoricalNode(rng.nextInt(), new double[] { rng.nextDouble(), rng.nextDouble() }, new Node[] { new Leaf(rng.nextDouble()), new Leaf(rng.nextDouble()) });    Node node2 = new NumericalNode(rng.nextInt(), rng.nextDouble(), new Leaf(rng.nextDouble()), new Leaf(rng.nextDouble()));    Node root = new CategoricalNode(rng.nextInt(), new double[] { rng.nextDouble(), rng.nextDouble(), rng.nextDouble() }, new Node[] { node1, node2, new Leaf(rng.nextDouble()) });        root.write(out);        assertEquals(root, readNode());}
 Node mahout_f4768_0() throws IOException
{    ByteArrayInputStream byteInStream = new ByteArrayInputStream(byteOutStream.toByteArray());    DataInput in = new DataInputStream(byteInStream);    return Node.read(in);}
public void mahout_f4769_0() throws Exception
{    Node leaf = new Leaf(rng.nextDouble());    leaf.write(out);    assertEquals(leaf, readNode());}
public void mahout_f4770_0() throws Exception
{    Node node = new NumericalNode(rng.nextInt(), rng.nextDouble(), new Leaf(rng.nextInt()), new Leaf(rng.nextDouble()));    node.write(out);    assertEquals(node, readNode());}
public void mahout_f4771_0() throws Exception
{    Node node = new CategoricalNode(rng.nextInt(), new double[] { rng.nextDouble(), rng.nextDouble(), rng.nextDouble() }, new Node[] { new Leaf(rng.nextDouble()), new Leaf(rng.nextDouble()), new Leaf(rng.nextDouble()) });    node.write(out);    assertEquals(node, readNode());}
public void mahout_f4772_0() throws Exception
{    Random rng = RandomUtils.getRandom();    String descriptor = Utils.randomDescriptor(rng, NUM_ATTRIBUTES);    int label = Utils.findLabel(descriptor);        double[][] temp = Utils.randomDoublesWithSameLabel(rng, descriptor, false, 100, 0);    String[] sData = Utils.double2String(temp);    Dataset dataset = DataLoader.generateDataset(descriptor, false, sData);    Data data = DataLoader.loadData(dataset, sData);    DefaultIgSplit iG = new DefaultIgSplit();    double expected = 0.0 - 1.0 * Math.log(1.0) / Math.log(2.0);    assertEquals(expected, iG.entropy(data), EPSILON);        for (int index = 0; index < 50; index++) {        temp[index][label] = 1.0;    }    sData = Utils.double2String(temp);    dataset = DataLoader.generateDataset(descriptor, false, sData);    data = DataLoader.loadData(dataset, sData);    iG = new DefaultIgSplit();    expected = 2.0 * -0.5 * Math.log(0.5) / Math.log(2.0);    assertEquals(expected, iG.entropy(data), EPSILON);        for (int index = 0; index < 15; index++) {        temp[index][label] = 2.0;    }    sData = Utils.double2String(temp);    dataset = DataLoader.generateDataset(descriptor, false, sData);    data = DataLoader.loadData(dataset, sData);    iG = new DefaultIgSplit();    expected = -0.15 * Math.log(0.15) / Math.log(2.0) - 0.35 * Math.log(0.35) / Math.log(2.0) - 0.5 * Math.log(0.5) / Math.log(2.0);    assertEquals(expected, iG.entropy(data), EPSILON);}
private static Data[] mahout_f4773_0() throws DescriptorException
{        String[] trainData = new String[20];    for (int i = 0; i < trainData.length; i++) {        if (i % 3 == 0) {            trainData[i] = "A," + (40 - i) + ',' + (i + 20);        } else if (i % 3 == 1) {            trainData[i] = "B," + (i + 20) + ',' + (40 - i);        } else {            trainData[i] = "C," + (i + 20) + ',' + (i + 20);        }    }        Dataset dataset = DataLoader.generateDataset("C N L", true, trainData);    Data[] datas = new Data[3];    datas[0] = DataLoader.loadData(dataset, trainData);        trainData = new String[20];    for (int i = 0; i < trainData.length; i++) {        if (i % 2 == 0) {            trainData[i] = "A," + (50 - i) + ',' + (i + 10);        } else {            trainData[i] = "B," + (i + 10) + ',' + (50 - i);        }    }    datas[1] = DataLoader.loadData(dataset, trainData);        trainData = new String[10];    for (int i = 0; i < trainData.length; i++) {        trainData[i] = "A," + (40 - i) + ',' + (i + 20);    }    datas[2] = DataLoader.loadData(dataset, trainData);    return datas;}
public void mahout_f4774_0() throws DescriptorException
{    Data[] datas = generateTrainingData();    RegressionSplit igSplit = new RegressionSplit();    Split split = igSplit.computeSplit(datas[0], 1);    assertEquals(180.0, split.getIg(), EPSILON);    assertEquals(38.0, split.getSplit(), EPSILON);    split = igSplit.computeSplit(datas[0].subset(Condition.lesser(1, 38.0)), 1);    assertEquals(76.5, split.getIg(), EPSILON);    assertEquals(21.5, split.getSplit(), EPSILON);    split = igSplit.computeSplit(datas[1], 0);    assertEquals(2205.0, split.getIg(), EPSILON);    assertEquals(Double.NaN, split.getSplit(), EPSILON);    split = igSplit.computeSplit(datas[1].subset(Condition.equals(0, 0.0)), 1);    assertEquals(250.0, split.getIg(), EPSILON);    assertEquals(41.0, split.getSplit(), EPSILON);}
public void mahout_f4775_0() throws Exception
{    super.setUp();    randomNumberGenerator = RandomUtils.getRandom(1);    Dataset dataset = DataLoader.generateDataset("C N N C L", false, TRAIN_DATA);    trainingData = DataLoader.loadData(dataset, TRAIN_DATA);    testData = DataLoader.loadData(dataset, TEST_DATA);}
public void mahout_f4776_0() throws Exception
{        DecisionTreeBuilder builder = new DecisionTreeBuilder();    builder.setM(trainingData.getDataset().nbAttributes() - 1);    Node tree = builder.build(randomNumberGenerator, trainingData);    String visualization = TreeVisualizer.toString(tree, trainingData.getDataset(), ATTRIBUTE_NAMES);    assertTrue((String.format("\n" + "outlook = rainy\n" + "|   windy = FALSE : yes\n" + "|   windy = TRUE : no\n" + "outlook = sunny\n" + "|   humidity < 77%s5 : yes\n" + "|   humidity >= 77%s5 : no\n" + "outlook = overcast : yes", DECIMAL_SEPARATOR, DECIMAL_SEPARATOR)).equals(visualization) || (String.format("\n" + "outlook = rainy\n" + "|   windy = TRUE : no\n" + "|   windy = FALSE : yes\n" + "outlook = overcast : yes\n" + "outlook = sunny\n" + "|   humidity < 77%s5 : yes\n" + "|   humidity >= 77%s5 : no", DECIMAL_SEPARATOR, DECIMAL_SEPARATOR)).equals(visualization));}
public void mahout_f4777_0() throws Exception
{        DecisionTreeBuilder builder = new DecisionTreeBuilder();    builder.setM(trainingData.getDataset().nbAttributes() - 1);    Node tree = builder.build(randomNumberGenerator, trainingData);    String[] prediction = TreeVisualizer.predictTrace(tree, testData, ATTRIBUTE_NAMES);    Assert.assertArrayEquals(new String[] { "outlook = rainy -> windy = TRUE -> no", "outlook = overcast -> yes", String.format("outlook = sunny -> (humidity = 90) >= 77%s5 -> no", DECIMAL_SEPARATOR) }, prediction);}
public void mahout_f4778_0() throws Exception
{        NumericalNode root = new NumericalNode(2, 90, new Leaf(0), new CategoricalNode(0, new double[] { 0, 1, 2 }, new Node[] { new NumericalNode(1, 71, new Leaf(0), new Leaf(1)), new Leaf(1), new Leaf(0) }));    List<Node> trees = new ArrayList<>();    trees.add(root);        DecisionForest forest = new DecisionForest(trees);    String visualization = ForestVisualizer.toString(forest, trainingData.getDataset(), null);    assertTrue(("Tree[1]:\n2 < 90 : yes\n2 >= 90\n" + "|   0 = rainy\n" + "|   |   1 < 71 : yes\n" + "|   |   1 >= 71 : no\n" + "|   0 = sunny : no\n" + "|   0 = overcast : yes\n").equals(visualization) || ("Tree[1]:\n" + "2 < 90 : no\n" + "2 >= 90\n" + "|   0 = rainy\n" + "|   |   1 < 71 : no\n" + "|   |   1 >= 71 : yes\n" + "|   0 = overcast : yes\n" + "|   0 = sunny : no\n").equals(visualization));    visualization = ForestVisualizer.toString(forest, trainingData.getDataset(), ATTRIBUTE_NAMES);    assertTrue(("Tree[1]:\n" + "humidity < 90 : yes\n" + "humidity >= 90\n" + "|   outlook = rainy\n" + "|   |   temperature < 71 : yes\n" + "|   |   temperature >= 71 : no\n" + "|   outlook = sunny : no\n" + "|   outlook = overcast : yes\n").equals(visualization) || ("Tree[1]:\n" + "humidity < 90 : no\n" + "humidity >= 90\n" + "|   outlook = rainy\n" + "|   |   temperature < 71 : no\n" + "|   |   temperature >= 71 : yes\n" + "|   outlook = overcast : yes\n" + "|   outlook = sunny : no\n").equals(visualization));}
public void mahout_f4779_0() throws Exception
{    List<Instance> instances = new ArrayList<>();    for (int i = 0; i < trainingData.size(); i++) {        if (trainingData.get(i).get(0) != 0.0d) {            instances.add(trainingData.get(i));        }    }    Data lessData = new Data(trainingData.getDataset(), instances);        DecisionTreeBuilder builder = new DecisionTreeBuilder();    builder.setM(trainingData.getDataset().nbAttributes() - 1);    builder.setMinSplitNum(0);    builder.setComplemented(false);    Node tree = builder.build(randomNumberGenerator, lessData);    String visualization = TreeVisualizer.toString(tree, trainingData.getDataset(), ATTRIBUTE_NAMES);    assertTrue((String.format("\noutlook = sunny\n" + "|   humidity < 77%s5 : yes\n" + "|   humidity >= 77%s5 : no\n" + "outlook = overcast : yes", DECIMAL_SEPARATOR, DECIMAL_SEPARATOR)).equals(visualization) || (String.format("\noutlook = overcast : yes\n" + "outlook = sunny\n" + "|   humidity < 77%s5 : yes\n" + "|   humidity >= 77%s5 : no", DECIMAL_SEPARATOR, DECIMAL_SEPARATOR)).equals(visualization));}
public void mahout_f4780_0() throws Exception
{    Data emptyData = new Data(trainingData.getDataset());        DecisionTreeBuilder builder = new DecisionTreeBuilder();    Node tree = builder.build(randomNumberGenerator, emptyData);    assertEquals(" : unknown", TreeVisualizer.toString(tree, trainingData.getDataset(), ATTRIBUTE_NAMES));}
public void mahout_f4781_0()
{    Auc auc = new Auc();    Random gen = RandomUtils.getRandom();    auc.setProbabilityScore(false);    for (int i = 0; i < 100000; i++) {        auc.add(0, gen.nextGaussian());        auc.add(1, gen.nextGaussian() + 1);    }    assertEquals(0.76, auc.auc(), 0.01);}
public void mahout_f4782_0()
{    Auc auc = new Auc();    Random gen = RandomUtils.getRandom();    auc.setProbabilityScore(false);    for (int i = 0; i < 100000; i++) {        auc.add(0, gen.nextGaussian());        auc.add(1, gen.nextGaussian() + 1);    }        auc.add(0, 5.0);    auc.add(0, 5.0);    auc.add(0, 5.0);    auc.add(0, 5.0);    auc.add(1, 5.0);    auc.add(1, 5.0);    auc.add(1, 5.0);    assertEquals(0.76, auc.auc(), 0.05);}
public void mahout_f4783_0()
{    Auc auc = new Auc();    Random gen = RandomUtils.getRandom();    Normal n0 = new Normal(-1, 1, gen);    Normal n1 = new Normal(1, 1, gen);    for (int i = 0; i < 100000; i++) {        double score = n0.nextDouble();        double p = n1.pdf(score) / (n0.pdf(score) + n1.pdf(score));        auc.add(0, p);        score = n1.nextDouble();        p = n1.pdf(score) / (n0.pdf(score) + n1.pdf(score));        auc.add(1, p);    }    Matrix m = auc.entropy();    assertEquals(-0.35, m.get(0, 0), 0.02);    assertEquals(-2.36, m.get(0, 1), 0.02);    assertEquals(-2.36, m.get(1, 0), 0.02);    assertEquals(-0.35, m.get(1, 1), 0.02);}
public void mahout_f4784_0() throws Exception
{    super.setUp();    NaiveBayesModel model = createComplementaryNaiveBayesModel();    classifier = new ComplementaryNaiveBayesClassifier(model);}
public void mahout_f4785_0() throws Exception
{    assertEquals(4, classifier.numCategories());    assertEquals(0, maxIndex(classifier.classifyFull(new DenseVector(new double[] { 1.0, 0.0, 0.0, 0.0 }))));    assertEquals(1, maxIndex(classifier.classifyFull(new DenseVector(new double[] { 0.0, 1.0, 0.0, 0.0 }))));    assertEquals(2, maxIndex(classifier.classifyFull(new DenseVector(new double[] { 0.0, 0.0, 1.0, 0.0 }))));    assertEquals(3, maxIndex(classifier.classifyFull(new DenseVector(new double[] { 0.0, 0.0, 0.0, 1.0 }))));}
public void mahout_f4786_0()
{        NaiveBayesModel standardModel = getStandardModel();        standardModel.validate();        NaiveBayesModel complementaryModel = getComplementaryModel();    complementaryModel.validate();}
public void mahout_f4787_0() throws Exception
{    super.setUp();    conf = getConfiguration();    inputFile = getTestTempFile("trainingInstances.seq");    outputDir = getTestTempDir("output");    outputDir.delete();    tempDir = getTestTempDir("tmp");    SequenceFile.Writer writer = new SequenceFile.Writer(FileSystem.get(conf), conf, new Path(inputFile.getAbsolutePath()), Text.class, VectorWritable.class);    try {        writer.append(LABEL_STOLEN, trainingInstance(COLOR_RED, TYPE_SPORTS, ORIGIN_DOMESTIC));        writer.append(LABEL_NOT_STOLEN, trainingInstance(COLOR_RED, TYPE_SPORTS, ORIGIN_DOMESTIC));        writer.append(LABEL_STOLEN, trainingInstance(COLOR_RED, TYPE_SPORTS, ORIGIN_DOMESTIC));        writer.append(LABEL_NOT_STOLEN, trainingInstance(COLOR_YELLOW, TYPE_SPORTS, ORIGIN_DOMESTIC));        writer.append(LABEL_STOLEN, trainingInstance(COLOR_YELLOW, TYPE_SPORTS, ORIGIN_IMPORTED));        writer.append(LABEL_NOT_STOLEN, trainingInstance(COLOR_YELLOW, TYPE_SUV, ORIGIN_IMPORTED));        writer.append(LABEL_STOLEN, trainingInstance(COLOR_YELLOW, TYPE_SUV, ORIGIN_IMPORTED));        writer.append(LABEL_NOT_STOLEN, trainingInstance(COLOR_YELLOW, TYPE_SUV, ORIGIN_DOMESTIC));        writer.append(LABEL_NOT_STOLEN, trainingInstance(COLOR_RED, TYPE_SUV, ORIGIN_IMPORTED));        writer.append(LABEL_STOLEN, trainingInstance(COLOR_RED, TYPE_SPORTS, ORIGIN_IMPORTED));    } finally {        Closeables.close(writer, false);    }}
public void mahout_f4788_0() throws Exception
{    TrainNaiveBayesJob trainNaiveBayes = new TrainNaiveBayesJob();    trainNaiveBayes.setConf(conf);    trainNaiveBayes.run(new String[] { "--input", inputFile.getAbsolutePath(), "--output", outputDir.getAbsolutePath(), "--tempDir", tempDir.getAbsolutePath() });    NaiveBayesModel naiveBayesModel = NaiveBayesModel.materialize(new Path(outputDir.getAbsolutePath()), conf);    AbstractVectorClassifier classifier = new StandardNaiveBayesClassifier(naiveBayesModel);    assertEquals(2, classifier.numCategories());    Vector prediction = classifier.classifyFull(trainingInstance(COLOR_RED, TYPE_SUV, ORIGIN_DOMESTIC).get());        assertTrue(prediction.get(0) < prediction.get(1));}
public void mahout_f4789_0() throws Exception
{    TrainNaiveBayesJob trainNaiveBayes = new TrainNaiveBayesJob();    trainNaiveBayes.setConf(conf);    trainNaiveBayes.run(new String[] { "--input", inputFile.getAbsolutePath(), "--output", outputDir.getAbsolutePath(), "--trainComplementary", "--tempDir", tempDir.getAbsolutePath() });    NaiveBayesModel naiveBayesModel = NaiveBayesModel.materialize(new Path(outputDir.getAbsolutePath()), conf);    AbstractVectorClassifier classifier = new ComplementaryNaiveBayesClassifier(naiveBayesModel);    assertEquals(2, classifier.numCategories());    Vector prediction = classifier.classifyFull(trainingInstance(COLOR_RED, TYPE_SUV, ORIGIN_DOMESTIC).get());        assertTrue(prediction.get(0) < prediction.get(1));}
 static VectorWritable mahout_f4790_0(Vector.Element... elems)
{    DenseVector trainingInstance = new DenseVector(6);    for (Vector.Element elem : elems) {        trainingInstance.set(elem.index(), elem.get());    }    return new VectorWritable(trainingInstance);}
public void mahout_f4791_0() throws Exception
{    super.setUp();    standardModel = createStandardNaiveBayesModel();    standardModel.validate();    complementaryModel = createComplementaryNaiveBayesModel();    complementaryModel.validate();}
protected NaiveBayesModel mahout_f4792_0()
{    return standardModel;}
protected NaiveBayesModel mahout_f4793_0()
{    return complementaryModel;}
protected static double mahout_f4794_0(int label, Matrix weightMatrix, Vector labelSum, Vector featureSum)
{    double weight = 0.0;    double alpha = 1.0;    for (int i = 0; i < featureSum.size(); i++) {        double score = weightMatrix.get(i, label);        double lSum = labelSum.get(label);        double fSum = featureSum.get(i);        double totalSum = featureSum.zSum();        double numerator = fSum - score + alpha;        double denominator = totalSum - lSum + featureSum.size();        weight += Math.abs(Math.log(numerator / denominator));    }    return weight;}
protected static double mahout_f4795_0(int label, Matrix weightMatrix, Vector labelSum, Vector featureSum)
{    double weight = 0.0;    double alpha = 1.0;    for (int feature = 0; feature < featureSum.size(); feature++) {        double score = weightMatrix.get(feature, label);        double lSum = labelSum.get(label);        double numerator = score + alpha;        double denominator = lSum + featureSum.size();        weight += Math.abs(Math.log(numerator / denominator));    }    return weight;}
protected static NaiveBayesModel mahout_f4796_0()
{    double[][] matrix = { { 0.7, 0.1, 0.1, 0.3 }, { 0.4, 0.4, 0.1, 0.1 }, { 0.1, 0.0, 0.8, 0.1 }, { 0.1, 0.1, 0.1, 0.7 } };    double[] labelSumArray = { 1.2, 1.0, 1.0, 1.0 };    double[] featureSumArray = { 1.3, 0.6, 1.1, 1.2 };    DenseMatrix weightMatrix = new DenseMatrix(matrix);    DenseVector labelSum = new DenseVector(labelSumArray);    DenseVector featureSum = new DenseVector(featureSumArray);        return new NaiveBayesModel(weightMatrix, featureSum, labelSum, null, 1.0f, false);}
protected static NaiveBayesModel mahout_f4797_0()
{    double[][] matrix = { { 0.7, 0.1, 0.1, 0.3 }, { 0.4, 0.4, 0.1, 0.1 }, { 0.1, 0.0, 0.8, 0.1 }, { 0.1, 0.1, 0.1, 0.7 } };    double[] labelSumArray = { 1.2, 1.0, 1.0, 1.0 };    double[] featureSumArray = { 1.3, 0.6, 1.1, 1.2 };    DenseMatrix weightMatrix = new DenseMatrix(matrix);    DenseVector labelSum = new DenseVector(labelSumArray);    DenseVector featureSum = new DenseVector(featureSumArray);    double[] thetaNormalizerSum = { complementaryNaiveBayesThetaWeight(0, weightMatrix, labelSum, featureSum), complementaryNaiveBayesThetaWeight(1, weightMatrix, labelSum, featureSum), complementaryNaiveBayesThetaWeight(2, weightMatrix, labelSum, featureSum), complementaryNaiveBayesThetaWeight(3, weightMatrix, labelSum, featureSum) };        return new NaiveBayesModel(weightMatrix, featureSum, labelSum, new DenseVector(thetaNormalizerSum), 1.0f, true);}
protected static int mahout_f4798_0(Vector instance)
{    int maxIndex = -1;    double maxScore = Integer.MIN_VALUE;    for (Element label : instance.all()) {        if (label.get() >= maxScore) {            maxIndex = label.index();            maxScore = label.get();        }    }    return maxIndex;}
public void mahout_f4799_0() throws Exception
{    super.setUp();    NaiveBayesModel model = createStandardNaiveBayesModel();    classifier = new StandardNaiveBayesClassifier(model);}
public void mahout_f4800_0() throws Exception
{    assertEquals(4, classifier.numCategories());    assertEquals(0, maxIndex(classifier.classifyFull(new DenseVector(new double[] { 1.0, 0.0, 0.0, 0.0 }))));    assertEquals(1, maxIndex(classifier.classifyFull(new DenseVector(new double[] { 0.0, 1.0, 0.0, 0.0 }))));    assertEquals(2, maxIndex(classifier.classifyFull(new DenseVector(new double[] { 0.0, 0.0, 1.0, 0.0 }))));    assertEquals(3, maxIndex(classifier.classifyFull(new DenseVector(new double[] { 0.0, 0.0, 0.0, 1.0 }))));}
public void mahout_f4801_0() throws Exception
{    super.setUp();    ctx = EasyMock.createMock(Mapper.Context.class);    instance = new VectorWritable(new DenseVector(new double[] { 1, 0, 1, 1, 0 }));    labelIndex = new OpenObjectIntHashMap<>();    labelIndex.put("bird", 0);    labelIndex.put("cat", 1);}
public void mahout_f4802_0() throws Exception
{    ctx.write(new IntWritable(0), instance);    EasyMock.replay(ctx);    IndexInstancesMapper indexInstances = new IndexInstancesMapper();    setField(indexInstances, "labelIndex", labelIndex);    indexInstances.map(new Text("/bird/"), instance, ctx);    EasyMock.verify(ctx);}
public void mahout_f4803_0() throws Exception
{    Counter skippedInstances = EasyMock.createMock(Counter.class);    EasyMock.expect(ctx.getCounter(IndexInstancesMapper.Counter.SKIPPED_INSTANCES)).andReturn(skippedInstances);    skippedInstances.increment(1);    EasyMock.replay(ctx, skippedInstances);    IndexInstancesMapper indexInstances = new IndexInstancesMapper();    setField(indexInstances, "labelIndex", labelIndex);    indexInstances.map(new Text("/fish/"), instance, ctx);    EasyMock.verify(ctx, skippedInstances);}
public void mahout_f4804_0() throws Exception
{    Mapper.Context ctx = EasyMock.createMock(Mapper.Context.class);    ComplementaryThetaTrainer trainer = EasyMock.createMock(ComplementaryThetaTrainer.class);    Vector instance1 = new DenseVector(new double[] { 1, 2, 3 });    Vector instance2 = new DenseVector(new double[] { 4, 5, 6 });    Vector perLabelThetaNormalizer = new DenseVector(new double[] { 7, 8 });    ThetaMapper thetaMapper = new ThetaMapper();    setField(thetaMapper, "trainer", trainer);    trainer.train(0, instance1);    trainer.train(1, instance2);    EasyMock.expect(trainer.retrievePerLabelThetaNormalizer()).andReturn(perLabelThetaNormalizer);    ctx.write(new Text(TrainNaiveBayesJob.LABEL_THETA_NORMALIZER), new VectorWritable(perLabelThetaNormalizer));    EasyMock.replay(ctx, trainer);    thetaMapper.map(new IntWritable(0), new VectorWritable(instance1), ctx);    thetaMapper.map(new IntWritable(1), new VectorWritable(instance2), ctx);    thetaMapper.cleanup(ctx);    EasyMock.verify(ctx, trainer);}
public void mahout_f4805_0() throws Exception
{    Mapper.Context ctx = EasyMock.createMock(Mapper.Context.class);    Vector instance1 = new DenseVector(new double[] { 1, 0, 0.5, 0.5, 0 });    Vector instance2 = new DenseVector(new double[] { 0, 0.5, 0, 0, 0 });    Vector instance3 = new DenseVector(new double[] { 1, 0.5, 1, 1.5, 1 });    Vector weightsPerLabel = new DenseVector(new double[] { 0, 0 });    ctx.write(new Text(TrainNaiveBayesJob.WEIGHTS_PER_FEATURE), new VectorWritable(new DenseVector(new double[] { 2, 1, 1.5, 2, 1 })));    ctx.write(new Text(TrainNaiveBayesJob.WEIGHTS_PER_LABEL), new VectorWritable(new DenseVector(new double[] { 2.5, 5 })));    EasyMock.replay(ctx);    WeightsMapper weights = new WeightsMapper();    setField(weights, "weightsPerLabel", weightsPerLabel);    weights.map(new IntWritable(0), new VectorWritable(instance1), ctx);    weights.map(new IntWritable(0), new VectorWritable(instance2), ctx);    weights.map(new IntWritable(1), new VectorWritable(instance3), ctx);    weights.cleanup(ctx);    EasyMock.verify(ctx);}
private static double[] mahout_f4806_0(CharSequence analysis)
{    double[] results = new double[3];    Matcher m = p1.matcher(analysis);    if (m.find()) {        results[0] = Double.parseDouble(m.group(1));    } else {        return null;    }    m = p2.matcher(analysis);    if (m.find()) {        results[1] = Double.parseDouble(m.group(1));    } else {        return null;    }    m = p3.matcher(analysis);    if (m.find()) {        results[2] = Double.parseDouble(m.group(1));    } else {        return null;    }    return results;}
private static int[] mahout_f4807_0(CharSequence analysis)
{    int[] results = new int[3];    Matcher m = p4.matcher(analysis);    if (m.find()) {        results[0] = Integer.parseInt(m.group(1));    }    m = p5.matcher(analysis);    if (m.find()) {        results[1] = Integer.parseInt(m.group(1));    }    m = p6.matcher(analysis);    if (m.find()) {        results[2] = Integer.parseInt(m.group(1));    }    return results;}
public void mahout_f4808_0()
{    double[][] results = new double[10][2];    for (int i = 0; i < results.length; i++) {        results[i][0] = i;        results[i][1] = i + 1;    }    RegressionResultAnalyzer analyzer = new RegressionResultAnalyzer();    analyzer.setInstances(results);    String analysis = analyzer.toString();    assertArrayEquals(new double[] { 1.0, 1.0, 1.0 }, parseAnalysis(analysis), 0);    for (int i = 0; i < results.length; i++) {        results[i][1] = Math.sqrt(i);    }    analyzer = new RegressionResultAnalyzer();    analyzer.setInstances(results);    analysis = analyzer.toString();    assertArrayEquals(new double[] { 0.9573, 2.5694, 3.2848 }, parseAnalysis(analysis), 0);    for (int i = 0; i < results.length; i++) {        results[i][0] = results.length - i;    }    analyzer = new RegressionResultAnalyzer();    analyzer.setInstances(results);    analysis = analyzer.toString();    assertArrayEquals(new double[] { -0.9573, 4.1351, 5.1573 }, parseAnalysis(analysis), 0);}
public void mahout_f4809_0()
{    double[][] results = new double[10][2];    for (int i = 0; i < results.length; i++) {        results[i][0] = i;        results[i][1] = Double.NaN;    }    RegressionResultAnalyzer analyzer = new RegressionResultAnalyzer();    analyzer.setInstances(results);    String analysis = analyzer.toString();    assertNull(parseAnalysis(analysis));    assertArrayEquals(new int[] { 0, 10, 10 }, parseAnalysisCount(analysis));    for (int i = 0; i < results.length - 3; i++) {        results[i][1] = Math.sqrt(i);    }    analyzer = new RegressionResultAnalyzer();    analyzer.setInstances(results);    analysis = analyzer.toString();    assertArrayEquals(new double[] { 0.9552, 1.4526, 1.9345 }, parseAnalysis(analysis), 0);    assertArrayEquals(new int[] { 7, 3, 10 }, parseAnalysisCount(analysis));}
public void mahout_f4810_0()
{        double[][] alphaExpectedA = { { 0.02, 0.0392, 0.002438, 0.00035456, 0.0011554672, 7.158497e-04, 4.614927e-05 }, { 0.01, 0.0054, 0.001824, 0.00069486, 0.0007586904, 2.514137e-04, 1.721505e-05 }, { 0.32, 0.0262, 0.002542, 0.00038026, 0.0001360234, 3.002345e-05, 9.659608e-05 }, { 0.03, 0.0000, 0.013428, 0.00951084, 0.0000000000, 0.000000e+00, 2.428986e-05 } };        Matrix alpha = HmmAlgorithms.forwardAlgorithm(getModel(), getSequence(), false);        assertNotNull(alpha);    assertEquals(4, alpha.numCols());    assertEquals(7, alpha.numRows());        for (int i = 0; i < 4; ++i) {        for (int j = 0; j < 7; ++j) {            assertEquals(alphaExpectedA[i][j], alpha.get(j, i), EPSILON);        }    }}
public void mahout_f4811_0()
{        double[][] alphaExpectedA = { { 0.02, 0.0392, 0.002438, 0.00035456, 0.0011554672, 7.158497e-04, 4.614927e-05 }, { 0.01, 0.0054, 0.001824, 0.00069486, 0.0007586904, 2.514137e-04, 1.721505e-05 }, { 0.32, 0.0262, 0.002542, 0.00038026, 0.0001360234, 3.002345e-05, 9.659608e-05 }, { 0.03, 0.0000, 0.013428, 0.00951084, 0.0000000000, 0.000000e+00, 2.428986e-05 } };        Matrix alpha = HmmAlgorithms.forwardAlgorithm(getModel(), getSequence(), true);        assertNotNull(alpha);    assertEquals(4, alpha.numCols());    assertEquals(7, alpha.numRows());        for (int i = 0; i < 4; ++i) {        for (int j = 0; j < 7; ++j) {            assertEquals(Math.log(alphaExpectedA[i][j]), alpha.get(j, i), EPSILON);        }    }}
public void mahout_f4812_0()
{        double[][] betaExpectedA = { { 0.0015730559, 0.003543656, 0.00738264, 0.040692, 0.0848, 0.17, 1 }, { 0.0017191865, 0.002386795, 0.00923652, 0.052232, 0.1018, 0.17, 1 }, { 0.0003825772, 0.001238558, 0.00259464, 0.012096, 0.0664, 0.66, 1 }, { 0.0004390858, 0.007076994, 0.01063512, 0.013556, 0.0304, 0.17, 1 } };        Matrix beta = HmmAlgorithms.backwardAlgorithm(getModel(), getSequence(), false);        assertNotNull(beta);    assertEquals(4, beta.numCols());    assertEquals(7, beta.numRows());        for (int i = 0; i < 4; ++i) {        for (int j = 0; j < 7; ++j) {            assertEquals(betaExpectedA[i][j], beta.get(j, i), EPSILON);        }    }}
public void mahout_f4813_0()
{        double[][] betaExpectedA = { { 0.0015730559, 0.003543656, 0.00738264, 0.040692, 0.0848, 0.17, 1 }, { 0.0017191865, 0.002386795, 0.00923652, 0.052232, 0.1018, 0.17, 1 }, { 0.0003825772, 0.001238558, 0.00259464, 0.012096, 0.0664, 0.66, 1 }, { 0.0004390858, 0.007076994, 0.01063512, 0.013556, 0.0304, 0.17, 1 } };        Matrix beta = HmmAlgorithms.backwardAlgorithm(getModel(), getSequence(), true);        assertNotNull(beta);    assertEquals(4, beta.numCols());    assertEquals(7, beta.numRows());        for (int i = 0; i < 4; ++i) {        for (int j = 0; j < 7; ++j) {            assertEquals(Math.log(betaExpectedA[i][j]), beta.get(j, i), EPSILON);        }    }}
public void mahout_f4814_0()
{        int[] expected = { 2, 0, 3, 3, 0, 0, 2 };        int[] computed = HmmAlgorithms.viterbiAlgorithm(getModel(), getSequence(), false);        assertNotNull(computed);    assertEquals(computed.length, getSequence().length);        for (int i = 0; i < getSequence().length; ++i) {        assertEquals(expected[i], computed[i]);    }}
public void mahout_f4815_0()
{        int[] expected = { 2, 0, 3, 3, 0, 0, 2 };        int[] computed = HmmAlgorithms.viterbiAlgorithm(getModel(), getSequence(), true);        assertNotNull(computed);    assertEquals(computed.length, getSequence().length);        for (int i = 0; i < getSequence().length; ++i) {        assertEquals(expected[i], computed[i]);    }}
public void mahout_f4816_0()
{        Matrix alpha = HmmAlgorithms.forwardAlgorithm(getModel(), getSequence(), false);    Matrix beta = HmmAlgorithms.backwardAlgorithm(getModel(), getSequence(), false);        double forwardLikelihood = HmmEvaluator.modelLikelihood(alpha, false);    double backwardLikelihood = HmmEvaluator.modelLikelihood(getModel(), getSequence(), beta, false);    assertEquals(forwardLikelihood, backwardLikelihood, EPSILON);        assertEquals(1.8425e-4, forwardLikelihood, EPSILON);}
public void mahout_f4817_0()
{        Matrix alpha = HmmAlgorithms.forwardAlgorithm(getModel(), getSequence(), true);    Matrix beta = HmmAlgorithms.backwardAlgorithm(getModel(), getSequence(), true);        double forwardLikelihood = HmmEvaluator.modelLikelihood(alpha, true);    double backwardLikelihood = HmmEvaluator.modelLikelihood(getModel(), getSequence(), beta, true);    assertEquals(forwardLikelihood, backwardLikelihood, EPSILON);        assertEquals(1.8425e-4, forwardLikelihood, EPSILON);}
public void mahout_f4818_0()
{        HmmModel model = new HmmModel(10, 20);        HmmUtils.validate(model);}
public void mahout_f4819_0() throws Exception
{    super.setUp();        String[] hiddenNames = { "H0", "H1", "H2", "H3" };    String[] outputNames = { "O0", "O1", "O2" };        double[][] transitionP = { { 0.5, 0.1, 0.1, 0.3 }, { 0.4, 0.4, 0.1, 0.1 }, { 0.1, 0.0, 0.8, 0.1 }, { 0.1, 0.1, 0.1, 0.7 } };        double[][] emissionP = { { 0.8, 0.1, 0.1 }, { 0.6, 0.1, 0.3 }, { 0.1, 0.8, 0.1 }, { 0.0, 0.1, 0.9 } };        double[] initialP = { 0.2, 0.1, 0.4, 0.3 };        model = new HmmModel(new DenseMatrix(transitionP), new DenseMatrix(emissionP), new DenseVector(initialP));    model.registerHiddenStateNames(hiddenNames);    model.registerOutputStateNames(outputNames);        HmmUtils.validate(model);}
protected HmmModel mahout_f4820_0()
{    return model;}
protected int[] mahout_f4821_0()
{    return sequence;}
public void mahout_f4822_0()
{            double[][] transitionE = { { 0.3125, 0.0625, 0.3125, 0.3125 }, { 0.25, 0.25, 0.25, 0.25 }, { 0.5, 0.071429, 0.357143, 0.071429 }, { 0.5, 0.1, 0.1, 0.3 } };        double[][] emissionE = { { 0.882353, 0.058824, 0.058824 }, { 0.333333, 0.333333, 0.3333333 }, { 0.076923, 0.846154, 0.076923 }, { 0.111111, 0.111111, 0.777778 } };        int[] observed = { 1, 0, 2, 2, 0, 0, 1, 1, 1, 0, 2, 0, 1, 0, 0 };    HmmModel trained = HmmTrainer.trainViterbi(getModel(), observed, 0.5, 0.1, 10, false);        Matrix emissionMatrix = trained.getEmissionMatrix();    Matrix transitionMatrix = trained.getTransitionMatrix();    for (int i = 0; i < trained.getNrOfHiddenStates(); ++i) {        for (int j = 0; j < trained.getNrOfHiddenStates(); ++j) {            assertEquals(transitionMatrix.getQuick(i, j), transitionE[i][j], EPSILON);        }        for (int j = 0; j < trained.getNrOfOutputStates(); ++j) {            assertEquals(emissionMatrix.getQuick(i, j), emissionE[i][j], EPSILON);        }    }}
public void mahout_f4823_0()
{            double[][] transitionE = { { 0.3125, 0.0625, 0.3125, 0.3125 }, { 0.25, 0.25, 0.25, 0.25 }, { 0.5, 0.071429, 0.357143, 0.071429 }, { 0.5, 0.1, 0.1, 0.3 } };        double[][] emissionE = { { 0.882353, 0.058824, 0.058824 }, { 0.333333, 0.333333, 0.3333333 }, { 0.076923, 0.846154, 0.076923 }, { 0.111111, 0.111111, 0.777778 } };        int[] observed = { 1, 0, 2, 2, 0, 0, 1, 1, 1, 0, 2, 0, 1, 0, 0 };    HmmModel trained = HmmTrainer.trainViterbi(getModel(), observed, 0.5, 0.1, 10, true);        Matrix emissionMatrix = trained.getEmissionMatrix();    Matrix transitionMatrix = trained.getTransitionMatrix();    for (int i = 0; i < trained.getNrOfHiddenStates(); ++i) {        for (int j = 0; j < trained.getNrOfHiddenStates(); ++j) {            assertEquals(transitionMatrix.getQuick(i, j), transitionE[i][j], EPSILON);        }        for (int j = 0; j < trained.getNrOfOutputStates(); ++j) {            assertEquals(emissionMatrix.getQuick(i, j), emissionE[i][j], EPSILON);        }    }}
public void mahout_f4824_0()
{        int[] observed = { 1, 0, 2, 2, 0, 0, 1, 1, 1, 0, 2, 0, 1, 0, 0 };        double[] initialExpected = { 0, 0, 1.0, 0 };    double[][] transitionExpected = { { 0.2319, 0.0993, 0.0005, 0.6683 }, { 0.0001, 0.3345, 0.6654, 0 }, { 0.5975, 0, 0.4025, 0 }, { 0.0024, 0.6657, 0, 0.3319 } };    double[][] emissionExpected = { { 0.9995, 0.0004, 0.0001 }, { 0.9943, 0.0036, 0.0021 }, { 0.0059, 0.9941, 0 }, { 0, 0, 1 } };    HmmModel trained = HmmTrainer.trainBaumWelch(getModel(), observed, 0.1, 10, false);    Vector initialProbabilities = trained.getInitialProbabilities();    Matrix emissionMatrix = trained.getEmissionMatrix();    Matrix transitionMatrix = trained.getTransitionMatrix();    for (int i = 0; i < trained.getNrOfHiddenStates(); ++i) {        assertEquals(initialProbabilities.get(i), initialExpected[i], 0.0001);        for (int j = 0; j < trained.getNrOfHiddenStates(); ++j) {            assertEquals(transitionMatrix.getQuick(i, j), transitionExpected[i][j], 0.0001);        }        for (int j = 0; j < trained.getNrOfOutputStates(); ++j) {            assertEquals(emissionMatrix.getQuick(i, j), emissionExpected[i][j], 0.0001);        }    }}
public void mahout_f4825_0()
{        int[] observed = { 1, 0, 2, 2, 0, 0, 1, 1, 1, 0, 2, 0, 1, 0, 0 };        double[] initialExpected = { 0, 0, 1.0, 0 };    double[][] transitionExpected = { { 0.2319, 0.0993, 0.0005, 0.6683 }, { 0.0001, 0.3345, 0.6654, 0 }, { 0.5975, 0, 0.4025, 0 }, { 0.0024, 0.6657, 0, 0.3319 } };    double[][] emissionExpected = { { 0.9995, 0.0004, 0.0001 }, { 0.9943, 0.0036, 0.0021 }, { 0.0059, 0.9941, 0 }, { 0, 0, 1 } };    HmmModel trained = HmmTrainer.trainBaumWelch(getModel(), observed, 0.1, 10, true);    Vector initialProbabilities = trained.getInitialProbabilities();    Matrix emissionMatrix = trained.getEmissionMatrix();    Matrix transitionMatrix = trained.getTransitionMatrix();    for (int i = 0; i < trained.getNrOfHiddenStates(); ++i) {        assertEquals(initialProbabilities.get(i), initialExpected[i], 0.0001);        for (int j = 0; j < trained.getNrOfHiddenStates(); ++j) {            assertEquals(transitionMatrix.getQuick(i, j), transitionExpected[i][j], 0.0001);        }        for (int j = 0; j < trained.getNrOfOutputStates(); ++j) {            assertEquals(emissionMatrix.getQuick(i, j), emissionExpected[i][j], 0.0001);        }    }}
public void mahout_f4826_0() throws Exception
{    super.setUp();    legal22 = new DenseMatrix(new double[][] { { 0.5, 0.5 }, { 0.3, 0.7 } });    legal23 = new DenseMatrix(new double[][] { { 0.2, 0.2, 0.6 }, { 0.3, 0.3, 0.4 } });    legal33 = new DenseMatrix(new double[][] { { 0.1, 0.1, 0.8 }, { 0.1, 0.2, 0.7 }, { 0.2, 0.3, 0.5 } });    legal2 = new DenseVector(new double[] { 0.4, 0.6 });    illegal22 = new DenseMatrix(new double[][] { { 1, 2 }, { 3, 4 } });}
public void mahout_f4827_0()
{    HmmUtils.validate(new HmmModel(legal22, legal23, legal2));}
public void mahout_f4828_0()
{    try {        HmmUtils.validate(new HmmModel(legal33, legal23, legal2));    } catch (IllegalArgumentException e) {                return;    }    fail();}
public void mahout_f4829_0()
{    try {        HmmUtils.validate(new HmmModel(illegal22, legal23, legal2));    } catch (IllegalArgumentException e) {                return;    }    fail();}
public void mahout_f4830_0()
{    String[] hiddenSequence = { "H1", "H2", "H0", "H3", "H4" };    String[] outputSequence = { "O1", "O2", "O4", "O0" };        int[] hiddenSequenceEnc = HmmUtils.encodeStateSequence(getModel(), Arrays.asList(hiddenSequence), false, -1);    int[] outputSequenceEnc = HmmUtils.encodeStateSequence(getModel(), Arrays.asList(outputSequence), true, -1);        int[] hiddenSequenceExp = { 1, 2, 0, 3, -1 };    int[] outputSequenceExp = { 1, 2, -1, 0 };        for (int i = 0; i < hiddenSequenceEnc.length; ++i) {        assertEquals(hiddenSequenceExp[i], hiddenSequenceEnc[i]);    }    for (int i = 0; i < outputSequenceEnc.length; ++i) {        assertEquals(outputSequenceExp[i], outputSequenceEnc[i]);    }}
public void mahout_f4831_0()
{    int[] hiddenSequence = { 1, 2, 0, 3, 10 };    int[] outputSequence = { 1, 2, 10, 0 };        List<String> hiddenSequenceDec = HmmUtils.decodeStateSequence(getModel(), hiddenSequence, false, "unknown");    List<String> outputSequenceDec = HmmUtils.decodeStateSequence(getModel(), outputSequence, true, "unknown");        String[] hiddenSequenceExp = { "H1", "H2", "H0", "H3", "unknown" };    String[] outputSequenceExp = { "O1", "O2", "unknown", "O0" };        for (int i = 0; i < hiddenSequenceExp.length; ++i) {        assertEquals(hiddenSequenceExp[i], hiddenSequenceDec.get(i));    }    for (int i = 0; i < outputSequenceExp.length; ++i) {        assertEquals(outputSequenceExp[i], outputSequenceDec.get(i));    }}
public void mahout_f4832_0()
{    DenseVector ip = new DenseVector(new double[] { 10, 20 });    DenseMatrix tr = new DenseMatrix(new double[][] { { 10, 10 }, { 20, 25 } });    DenseMatrix em = new DenseMatrix(new double[][] { { 5, 7 }, { 10, 15 } });    HmmModel model = new HmmModel(tr, em, ip);    HmmUtils.normalizeModel(model);        HmmUtils.validate(model);}
public void mahout_f4833_0()
{    DenseVector ip = new DenseVector(new double[] { 0.0001, 0.0001, 0.9998 });    DenseMatrix tr = new DenseMatrix(new double[][] { { 0.9998, 0.0001, 0.0001 }, { 0.0001, 0.9998, 0.0001 }, { 0.0001, 0.0001, 0.9998 } });    DenseMatrix em = new DenseMatrix(new double[][] { { 0.9998, 0.0001, 0.0001 }, { 0.0001, 0.9998, 0.0001 }, { 0.0001, 0.0001, 0.9998 } });    HmmModel model = new HmmModel(tr, em, ip);        HmmModel sparseModel = HmmUtils.truncateModel(model, 0.01);        HmmUtils.validate(sparseModel);        Vector sparse_ip = sparseModel.getInitialProbabilities();    Matrix sparse_tr = sparseModel.getTransitionMatrix();    Matrix sparse_em = sparseModel.getEmissionMatrix();    for (int i = 0; i < sparseModel.getNrOfHiddenStates(); ++i) {        assertEquals(i == 2 ? 1.0 : 0.0, sparse_ip.getQuick(i), EPSILON);        for (int j = 0; j < sparseModel.getNrOfHiddenStates(); ++j) {            if (i == j) {                assertEquals(1.0, sparse_tr.getQuick(i, j), EPSILON);                assertEquals(1.0, sparse_em.getQuick(i, j), EPSILON);            } else {                assertEquals(0.0, sparse_tr.getQuick(i, j), EPSILON);                assertEquals(0.0, sparse_em.getQuick(i, j), EPSILON);            }        }    }}
public void mahout_f4834_0()
{    Random gen = RandomUtils.getRandom();    Exponential exp = new Exponential(0.5, gen);    Vector beta = new DenseVector(200);    for (Vector.Element element : beta.all()) {        int sign = 1;        if (gen.nextDouble() < 0.5) {            sign = -1;        }        element.set(sign * exp.nextDouble());    }    AdaptiveLogisticRegression.Wrapper cl = new AdaptiveLogisticRegression.Wrapper(2, 200, new L1());    cl.update(new double[] { 1.0e-5, 1 });    for (int i = 0; i < 10000; i++) {        AdaptiveLogisticRegression.TrainingExample r = getExample(i, gen, beta);        cl.train(r);        if (i % 1000 == 0) {            System.out.printf("%10d %10.3f\n", i, cl.getLearner().auc());        }    }    assertEquals(1, cl.getLearner().auc(), 0.1);    AdaptiveLogisticRegression adaptiveLogisticRegression = new AdaptiveLogisticRegression(2, 200, new L1());    adaptiveLogisticRegression.setInterval(1000);    for (int i = 0; i < 20000; i++) {        AdaptiveLogisticRegression.TrainingExample r = getExample(i, gen, beta);        adaptiveLogisticRegression.train(r.getKey(), r.getActual(), r.getInstance());        if (i % 1000 == 0 && adaptiveLogisticRegression.getBest() != null) {            System.out.printf("%10d %10.4f %10.8f %.3f\n", i, adaptiveLogisticRegression.auc(), Math.log10(adaptiveLogisticRegression.getBest().getMappedParams()[0]), adaptiveLogisticRegression.getBest().getMappedParams()[1]);        }    }    assertEquals(1, adaptiveLogisticRegression.auc(), 0.1);    adaptiveLogisticRegression.close();}
private static AdaptiveLogisticRegression.TrainingExample mahout_f4835_0(int i, Random gen, Vector beta)
{    Vector data = new DenseVector(200);    for (Vector.Element element : data.all()) {        element.set(gen.nextDouble() < 0.3 ? 1 : 0);    }    double p = 1 / (1 + Math.exp(1.5 - data.dot(beta)));    int target = 0;    if (gen.nextDouble() < p) {        target = 1;    }    return new AdaptiveLogisticRegression.TrainingExample(i, null, target, data);}
public void mahout_f4836_0()
{    Random gen = RandomUtils.getRandom();    Exponential exp = new Exponential(0.5, gen);    Vector beta = new DenseVector(200);    for (Vector.Element element : beta.all()) {        int sign = 1;        if (gen.nextDouble() < 0.5) {            sign = -1;        }        element.set(sign * exp.nextDouble());    }        AdaptiveLogisticRegression.Wrapper w = new AdaptiveLogisticRegression.Wrapper(2, 200, new L1());    for (int i = 0; i < 3000; i++) {        AdaptiveLogisticRegression.TrainingExample r = getExample(i, gen, beta);        w.train(r);        if (i % 1000 == 0) {            System.out.printf("%10d %.3f\n", i, w.getLearner().auc());        }    }    System.out.printf("%10d %.3f\n", 3000, w.getLearner().auc());    double auc1 = w.getLearner().auc();        AdaptiveLogisticRegression.Wrapper w2 = w.copy();    for (int i = 0; i < 5000; i++) {        if (i % 1000 == 0) {            if (i == 0) {                assertEquals("Should have started with no data", 0.5, w2.getLearner().auc(), 0.0001);            }            if (i == 1000) {                double auc2 = w2.getLearner().auc();                assertTrue("Should have had head-start", Math.abs(auc2 - 0.5) > 0.1);                assertTrue("AUC should improve quickly on copy", auc1 < auc2);            }            System.out.printf("%10d %.3f\n", i, w2.getLearner().auc());        }        AdaptiveLogisticRegression.TrainingExample r = getExample(i, gen, beta);        w2.train(r);    }    assertEquals("Original should not change after copy is updated", auc1, w.getLearner().auc(), 1.0e-5);        assertTrue("AUC should improve significantly on copy", auc1 < w2.getLearner().auc() - 0.05);        assertEquals(auc1, w.getLearner().auc(), 0);}
public void mahout_f4837_0()
{    assertEquals(500, AdaptiveLogisticRegression.stepSize(15000, 2));    assertEquals(2000, AdaptiveLogisticRegression.stepSize(15000, 2.6));    assertEquals(5000, AdaptiveLogisticRegression.stepSize(24000, 2.6));    assertEquals(10000, AdaptiveLogisticRegression.stepSize(15000, 3));}
public void mahout_f4838_0()
{    AdaptiveLogisticRegression lr = new AdaptiveLogisticRegression(2, 1000, new L1());    lr.setInterval(5000);    assertEquals(20000, lr.nextStep(15000));    assertEquals(20000, lr.nextStep(15001));    assertEquals(20000, lr.nextStep(16500));    assertEquals(20000, lr.nextStep(19999));    lr.close();}
public void mahout_f4839_0()
{    AdaptiveLogisticRegression lr = new AdaptiveLogisticRegression(2, 1000, new L1());    lr.setInterval(2000, 10000);        for (int i = 2000; i < 20000; i += 2000) {        assertEquals(i + 2000, lr.nextStep(i));    }        for (int i = 20000; i < 50000; i += 5000) {        assertEquals(i + 5000, lr.nextStep(i));    }        for (int i = 50000; i < 500000; i += 10000) {        assertEquals(i + 10000, lr.nextStep(i));    }    lr.close();}
public void mahout_f4840_0()
{    RecordFactory csv = new CsvRecordFactory("y", ImmutableMap.of("x1", "n", "x2", "w", "x3", "t"));    csv.firstLine("z,x1,y,x2,x3,q");    csv.maxTargetValue(2);    Vector v = new DenseVector(2000);    int t = csv.processLine("ignore,3.1,yes,tiger, \"this is text\",ignore", v);    assertEquals(0, t);        assertEquals(9.0, v.norm(0), 0);        assertEquals(3.1, v.maxValue(), 0);    v.set(v.maxValueIndex(), 0);    assertEquals(8.0, v.norm(0), 0);    assertEquals(8.0, v.norm(1), 0);    assertEquals(1.0, v.maxValue(), 0);    v.assign(0);    t = csv.processLine("ignore,5.3,no,line, \"and more text and more\",ignore", v);    assertEquals(1, t);        assertEquals(9.0, v.norm(0), 0);        assertEquals(5.3, v.maxValue(), 0);    v.set(v.maxValueIndex(), 0);    assertEquals(8.0, v.norm(0), 0);    assertEquals(10.339850002884626, v.norm(1), 1.0e-6);    assertEquals(1.5849625007211563, v.maxValue(), 1.0e-6);    v.assign(0);    t = csv.processLine("ignore,5.3,invalid,line, \"and more text and more\",ignore", v);    assertEquals(1, t);        assertEquals(9.0, v.norm(0), 0);        assertEquals(5.3, v.maxValue(), 0);    v.set(v.maxValueIndex(), 0);    assertEquals(8.0, v.norm(0), 0);    assertEquals(10.339850002884626, v.norm(1), 1.0e-6);    assertEquals(1.5849625007211563, v.maxValue(), 1.0e-6);}
public void mahout_f4841_0()
{    Dictionary dict = new Dictionary();    dict.intern("a");    dict.intern("d");    dict.intern("c");    dict.intern("b");    dict.intern("qrz");    assertEquals("[a, d, c, b, qrz]", dict.values().toString());    Dictionary dict2 = Dictionary.fromList(dict.values());    assertEquals("[a, d, c, b, qrz]", dict2.values().toString());}
public void mahout_f4842_0() throws IOException
{    Vector target = readStandardData();    GradientMachine grad = new GradientMachine(8, 4, 2).learningRate(0.1).regularization(0.01);    Random gen = RandomUtils.getRandom();    grad.initWeights(gen);    train(getInput(), target, grad);        test(getInput(), target, grad, 1.0, 1);}
private static T mahout_f4843_0(T m, Class<T> clazz) throws IOException
{    ByteArrayOutputStream buf = new ByteArrayOutputStream(1000);    DataOutputStream dos = new DataOutputStream(buf);    try {        PolymorphicWritable.write(dos, m);    } finally {        Closeables.close(dos, false);    }    return PolymorphicWritable.read(new DataInputStream(new ByteArrayInputStream(buf.toByteArray())), clazz);}
public void mahout_f4844_0() throws IOException
{    RandomUtils.useTestSeed();    OnlineAuc auc1 = new GlobalOnlineAuc();    Random gen = RandomUtils.getRandom();    for (int i = 0; i < 10000; i++) {        auc1.addSample(0, gen.nextGaussian());        auc1.addSample(1, gen.nextGaussian() + 1);    }    assertEquals(0.76, auc1.auc(), 0.01);    OnlineAuc auc3 = roundTrip(auc1, OnlineAuc.class);    assertEquals(auc1.auc(), auc3.auc(), 0);    for (int i = 0; i < 1000; i++) {        auc1.addSample(0, gen.nextGaussian());        auc1.addSample(1, gen.nextGaussian() + 1);        auc3.addSample(0, gen.nextGaussian());        auc3.addSample(1, gen.nextGaussian() + 1);    }    assertEquals(auc1.auc(), auc3.auc(), 0.01);}
public void mahout_f4845_0() throws IOException
{    OnlineLogisticRegression olr = new OnlineLogisticRegression(2, 5, new L1());    train(olr, 100);    OnlineLogisticRegression olr3 = roundTrip(olr, OnlineLogisticRegression.class);    assertEquals(0, olr.getBeta().minus(olr3.getBeta()).aggregate(Functions.MAX, Functions.IDENTITY), 1.0e-6);    train(olr, 100);    train(olr3, 100);    assertEquals(0, olr.getBeta().minus(olr3.getBeta()).aggregate(Functions.MAX, Functions.IDENTITY), 1.0e-6);    olr.close();    olr3.close();}
public void mahout_f4846_0() throws IOException
{    CrossFoldLearner learner = new CrossFoldLearner(5, 2, 5, new L1());    train(learner, 100);    CrossFoldLearner olr3 = roundTrip(learner, CrossFoldLearner.class);    double auc1 = learner.auc();    assertTrue(auc1 > 0.85);    assertEquals(auc1, learner.auc(), 1.0e-6);    assertEquals(auc1, olr3.auc(), 1.0e-6);    train(learner, 100);    train(learner, 100);    train(olr3, 100);    assertEquals(learner.auc(), learner.auc(), 0.02);    assertEquals(learner.auc(), olr3.auc(), 0.02);    double auc2 = learner.auc();    assertTrue(auc2 > auc1);    learner.close();    olr3.close();}
public void mahout_f4847_0() throws IOException
{    AdaptiveLogisticRegression learner = new AdaptiveLogisticRegression(2, 5, new L1());    learner.setInterval(200);    train(learner, 400);    AdaptiveLogisticRegression olr3 = roundTrip(learner, AdaptiveLogisticRegression.class);    double auc1 = learner.auc();    assertTrue(auc1 > 0.85);    assertEquals(auc1, learner.auc(), 1.0e-6);    assertEquals(auc1, olr3.auc(), 1.0e-6);    train(learner, 1000);    train(learner, 1000);    train(olr3, 1000);    assertEquals(learner.auc(), learner.auc(), 0.005);    assertEquals(learner.auc(), olr3.auc(), 0.005);    double auc2 = learner.auc();    assertTrue(String.format("%.3f > %.3f", auc2, auc1), auc2 > auc1);    learner.close();    olr3.close();}
private static void mahout_f4848_0(OnlineLearner olr, int n)
{    Vector beta = new DenseVector(new double[] { 1, -1, 0, 0.5, -0.5 });    Random gen = RandomUtils.getRandom();    for (int i = 0; i < n; i++) {        Vector x = randomVector(gen, 5);        int target = gen.nextDouble() < beta.dot(x) ? 1 : 0;        olr.train(target, x);    }}
private static Vector mahout_f4849_0(final Random gen, int n)
{    Vector x = new DenseVector(n);    x.assign(new DoubleFunction() {        @Override        public double apply(double v) {            return gen.nextGaussian();        }    });    return x;}
public double mahout_f4850_0(double v)
{    return gen.nextGaussian();}
 Matrix mahout_f4851_0()
{    return input;}
 Vector mahout_f4852_0() throws IOException
{                input = readCsv("sgd.csv");        Vector target = new DenseVector(60);    target.assign(0);    target.viewPart(30, 30).assign(1);    return target;}
 static void mahout_f4853_0(Matrix input, Vector target, OnlineLearner lr)
{    RandomUtils.useTestSeed();    Random gen = RandomUtils.getRandom();        for (int row : permute(gen, 60)) {        lr.train((int) target.get(row), input.viewRow(row));    }    lr.close();}
 static void mahout_f4854_0(Matrix input, Vector target, AbstractVectorClassifier lr, double expected_mean_error, double expected_absolute_error)
{        Matrix tmp = lr.classify(input);        double meanAbsoluteError = tmp.viewColumn(0).minus(target).aggregate(Functions.PLUS, Functions.ABS) / 60;        double maxAbsoluteError = tmp.viewColumn(0).minus(target).aggregate(Functions.MAX, Functions.ABS);    System.out.printf("mAE = %.4f, maxAE = %.4f\n", meanAbsoluteError, maxAbsoluteError);    assertEquals(0, meanAbsoluteError, expected_mean_error);    assertEquals(0, maxAbsoluteError, expected_absolute_error);        Vector v = lr.classifyScalar(input);    assertEquals(0, v.minus(tmp.viewColumn(0)).norm(1), 1.0e-5);    v = lr.classifyFull(input).viewColumn(1);    assertEquals(0, v.minus(tmp.viewColumn(0)).norm(1), 1.0e-4);}
 static int[] mahout_f4855_0(Random gen, int max)
{    int[] permutation = new int[max];    permutation[0] = 0;    for (int i = 1; i < max; i++) {        int n = gen.nextInt(i + 1);        if (n == i) {            permutation[i] = i;        } else {            permutation[i] = permutation[n];            permutation[n] = i;        }    }    return permutation;}
 static Matrix mahout_f4856_0(String resourceName) throws IOException
{    Splitter onCommas = Splitter.on(',').trimResults(CharMatcher.anyOf(" \""));    Readable isr = new InputStreamReader(Resources.getResource(resourceName).openStream(), Charsets.UTF_8);    List<String> data = CharStreams.readLines(isr);    String first = data.get(0);    data = data.subList(1, data.size());    List<String> values = Lists.newArrayList(onCommas.split(first));    Matrix r = new DenseMatrix(data.size(), values.size());    int column = 0;    Map<String, Integer> labels = Maps.newHashMap();    for (String value : values) {        labels.put(value, column);        column++;    }    r.setColumnLabelBindings(labels);    int row = 0;    for (String line : data) {        column = 0;        values = Lists.newArrayList(onCommas.split(line));        for (String value : values) {            r.set(row, column, Double.parseDouble(value));            column++;        }        row++;    }    return r;}
public void mahout_f4857_0() throws IOException
{    Vector target = readStandardData();    CrossFoldLearner lr = new CrossFoldLearner(5, 2, 8, new L1()).lambda(1 * 1.0e-3).learningRate(50);    train(getInput(), target, lr);    System.out.printf("%.2f %.5f\n", lr.auc(), lr.logLikelihood());    test(getInput(), target, lr, 0.05, 0.3);}
public void mahout_f4858_0() throws IOException
{    RandomUtils.useTestSeed();    Random gen = RandomUtils.getRandom();    Matrix data = readCsv("cancer.csv");    CrossFoldLearner lr = new CrossFoldLearner(5, 2, 10, new L1()).stepOffset(10).decayExponent(0.7).lambda(1 * 1.0e-3).learningRate(5);    int k = 0;    int[] ordering = permute(gen, data.numRows());    for (int epoch = 0; epoch < 100; epoch++) {        for (int row : ordering) {            lr.train(row, (int) data.get(row, 9), data.viewRow(row));            System.out.printf("%d,%d,%.3f\n", epoch, k++, lr.auc());        }        assertEquals(1, lr.auc(), 0.2);    }    assertEquals(1, lr.auc(), 0.1);}
public void mahout_f4859_0()
{    OnlineLogisticRegression lr = new OnlineLogisticRegression(3, 2, new L2(1));        lr.setBeta(0, 0, -1);    lr.setBeta(1, 0, -2);        Vector v = lr.classify(new DenseVector(new double[] { 0, 0 }));    assertEquals(1 / 3.0, v.get(0), 1.0e-8);    assertEquals(1 / 3.0, v.get(1), 1.0e-8);    v = lr.classifyFull(new DenseVector(new double[] { 0, 0 }));    assertEquals(1.0, v.zSum(), 1.0e-8);    assertEquals(1 / 3.0, v.get(0), 1.0e-8);    assertEquals(1 / 3.0, v.get(1), 1.0e-8);    assertEquals(1 / 3.0, v.get(2), 1.0e-8);        v = lr.classify(new DenseVector(new double[] { 0, 1 }));    assertEquals(1 / 3.0, v.get(0), 1.0e-3);    assertEquals(1 / 3.0, v.get(1), 1.0e-3);    v = lr.classifyFull(new DenseVector(new double[] { 0, 1 }));    assertEquals(1.0, v.zSum(), 1.0e-8);    assertEquals(1 / 3.0, v.get(0), 1.0e-3);    assertEquals(1 / 3.0, v.get(1), 1.0e-3);    assertEquals(1 / 3.0, v.get(2), 1.0e-3);        v = lr.classify(new DenseVector(new double[] { 1, 0 }));    assertEquals(Math.exp(-1) / (1 + Math.exp(-1) + Math.exp(-2)), v.get(0), 1.0e-8);    assertEquals(Math.exp(-2) / (1 + Math.exp(-1) + Math.exp(-2)), v.get(1), 1.0e-8);    v = lr.classifyFull(new DenseVector(new double[] { 1, 0 }));    assertEquals(1.0, v.zSum(), 1.0e-8);    assertEquals(1 / (1 + Math.exp(-1) + Math.exp(-2)), v.get(0), 1.0e-8);    assertEquals(Math.exp(-1) / (1 + Math.exp(-1) + Math.exp(-2)), v.get(1), 1.0e-8);    assertEquals(Math.exp(-2) / (1 + Math.exp(-1) + Math.exp(-2)), v.get(2), 1.0e-8);    lr.setBeta(0, 1, 1);    v = lr.classifyFull(new DenseVector(new double[] { 1, 1 }));    assertEquals(1.0, v.zSum(), 1.0e-8);    assertEquals(Math.exp(0) / (1 + Math.exp(0) + Math.exp(-2)), v.get(1), 1.0e-3);    assertEquals(Math.exp(-2) / (1 + Math.exp(0) + Math.exp(-2)), v.get(2), 1.0e-3);    assertEquals(1 / (1 + Math.exp(0) + Math.exp(-2)), v.get(0), 1.0e-3);    lr.setBeta(1, 1, 3);    v = lr.classifyFull(new DenseVector(new double[] { 1, 1 }));    assertEquals(1.0, v.zSum(), 1.0e-8);    assertEquals(Math.exp(0) / (1 + Math.exp(0) + Math.exp(1)), v.get(1), 1.0e-8);    assertEquals(Math.exp(1) / (1 + Math.exp(0) + Math.exp(1)), v.get(2), 1.0e-8);    assertEquals(1 / (1 + Math.exp(0) + Math.exp(1)), v.get(0), 1.0e-8);}
public void mahout_f4860_1() throws IOException
{                                                                            RandomUtils.useTestSeed();    Splitter onComma = Splitter.on(",");        List<String> raw = Resources.readLines(Resources.getResource("iris.csv"), Charsets.UTF_8);        List<Vector> data = Lists.newArrayList();        List<Integer> target = Lists.newArrayList();        Dictionary dict = new Dictionary();        List<Integer> order = Lists.newArrayList();    for (String line : raw.subList(1, raw.size())) {                order.add(order.size());                Vector v = new DenseVector(5);        v.set(0, 1);        int i = 1;        Iterable<String> values = onComma.split(line);        for (String value : Iterables.limit(values, 4)) {            v.set(i++, Double.parseDouble(value));        }        data.add(v);                target.add(dict.intern(Iterables.get(values, 4)));    }            Random random = RandomUtils.getRandom();    Collections.shuffle(order, random);        List<Integer> train = order.subList(0, 100);    List<Integer> test = order.subList(100, 150);                int[] correct = new int[test.size() + 1];    for (int run = 0; run < 200; run++) {        OnlineLogisticRegression lr = new OnlineLogisticRegression(3, 5, new L2(1));                for (int pass = 0; pass < 30; pass++) {            Collections.shuffle(train, random);            for (int k : train) {                lr.train(target.get(k), data.get(k));            }        }                int x = 0;        int[] count = new int[3];        for (Integer k : test) {            int r = lr.classifyFull(data.get(k)).maxValueIndex();            count[r]++;            x += r == target.get(k) ? 1 : 0;        }        correct[x]++;    }        for (int i = 0; i < Math.floor(0.95 * test.size()); i++) {        assertEquals(String.format("%d trials had unacceptable accuracy of only %.0f%%: ", correct[i], 100.0 * i / test.size()), 0, correct[i]);    }        assertEquals(String.format("%d trials had unrealistic accuracy of 100%%", correct[test.size() - 1]), 0, correct[test.size()]);}
public void mahout_f4861_0() throws Exception
{    Vector target = readStandardData();                        OnlineLogisticRegression lr = new OnlineLogisticRegression(2, 8, new L1()).lambda(1 * 1.0e-3).learningRate(50);    train(getInput(), target, lr);    test(getInput(), target, lr, 0.05, 0.3);}
public void mahout_f4862_0() throws Exception
{    OnlineLogisticRegression lr = new OnlineLogisticRegression(2, 8, new L1()).lambda(1 * 1.0e-3).stepOffset(11).alpha(0.01).learningRate(50).decayExponent(-0.02);    lr.close();    byte[] output;    try (ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream();        DataOutputStream dataOutputStream = new DataOutputStream(byteArrayOutputStream)) {        PolymorphicWritable.write(dataOutputStream, lr);        output = byteArrayOutputStream.toByteArray();    }    OnlineLogisticRegression read;    try (ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(output);        DataInputStream dataInputStream = new DataInputStream(byteArrayInputStream)) {        read = PolymorphicWritable.read(dataInputStream, OnlineLogisticRegression.class);    }        Assert.assertEquals((1.0e-3), read.getLambda(), 1.0e-7);            Field stepOffset = lr.getClass().getDeclaredField("stepOffset");    stepOffset.setAccessible(true);    int stepOffsetVal = (Integer) stepOffset.get(lr);    Assert.assertEquals(11, stepOffsetVal);        Field decayFactor = lr.getClass().getDeclaredField("decayFactor");    decayFactor.setAccessible(true);    double decayFactorVal = (Double) decayFactor.get(lr);    Assert.assertEquals(0.01, decayFactorVal, 1.0e-7);        Field mu0 = lr.getClass().getDeclaredField("mu0");    mu0.setAccessible(true);    double mu0Val = (Double) mu0.get(lr);    Assert.assertEquals(50, mu0Val, 1.0e-7);        Field forgettingExponent = lr.getClass().getDeclaredField("forgettingExponent");    forgettingExponent.setAccessible(true);    double forgettingExponentVal = (Double) forgettingExponent.get(lr);    Assert.assertEquals(-0.02, forgettingExponentVal, 1.0e-7);}
public void mahout_f4863_0() throws IOException
{    Vector target = readStandardData();    PassiveAggressive pa = new PassiveAggressive(2, 8).learningRate(0.1);    train(getInput(), target, pa);    test(getInput(), target, pa, 0.11, 0.31);}
private static List<VectorWritable> mahout_f4864_0()
{    List<VectorWritable> points = Lists.newArrayList();    for (double[] fr : RAW) {        Vector vec = new RandomAccessSparseVector(fr.length);        vec.assign(fr);        points.add(new VectorWritable(vec));    }    return points;}
private static List<Vector> mahout_f4865_0()
{    List<Vector> points = Lists.newArrayList();    for (double[] fr : RAW) {        Vector vec = new RandomAccessSparseVector(fr.length);        vec.assign(fr);        points.add(vec);    }    return points;}
private static void mahout_f4866_0(Iterable<Canopy> canopies)
{    for (Canopy canopy : canopies) {        System.out.println(canopy.asFormatString(null));    }}
public void mahout_f4867_0() throws Exception
{    super.setUp();    fs = FileSystem.get(getConfiguration());    referenceManhattan = CanopyClusterer.createCanopies(getPoints(), manhattanDistanceMeasure, 3.1, 2.1);    manhattanCentroids = CanopyClusterer.getCenters(referenceManhattan);    referenceEuclidean = CanopyClusterer.createCanopies(getPoints(), euclideanDistanceMeasure, 3.1, 2.1);    euclideanCentroids = CanopyClusterer.getCenters(referenceEuclidean);}
public void mahout_f4868_0() throws Exception
{        printCanopies(referenceManhattan);    assertEquals("number of canopies", 3, referenceManhattan.size());    for (int canopyIx = 0; canopyIx < referenceManhattan.size(); canopyIx++) {        Canopy testCanopy = referenceManhattan.get(canopyIx);        int[] expectedNumPoints = { 4, 4, 3 };        double[][] expectedCentroids = { { 1.5, 1.5 }, { 4.0, 4.0 }, { 4.666666666666667, 4.6666666666666667 } };        assertEquals("canopy points " + canopyIx, testCanopy.getNumObservations(), expectedNumPoints[canopyIx]);        double[] refCentroid = expectedCentroids[canopyIx];        Vector testCentroid = testCanopy.computeCentroid();        for (int pointIx = 0; pointIx < refCentroid.length; pointIx++) {            assertEquals("canopy centroid " + canopyIx + '[' + pointIx + ']', refCentroid[pointIx], testCentroid.get(pointIx), EPSILON);        }    }}
public void mahout_f4869_0() throws Exception
{        printCanopies(referenceEuclidean);    assertEquals("number of canopies", 3, referenceEuclidean.size());    int[] expectedNumPoints = { 5, 5, 3 };    double[][] expectedCentroids = { { 1.8, 1.8 }, { 4.2, 4.2 }, { 4.666666666666667, 4.666666666666667 } };    for (int canopyIx = 0; canopyIx < referenceEuclidean.size(); canopyIx++) {        Canopy testCanopy = referenceEuclidean.get(canopyIx);        assertEquals("canopy points " + canopyIx, testCanopy.getNumObservations(), expectedNumPoints[canopyIx]);        double[] refCentroid = expectedCentroids[canopyIx];        Vector testCentroid = testCanopy.computeCentroid();        for (int pointIx = 0; pointIx < refCentroid.length; pointIx++) {            assertEquals("canopy centroid " + canopyIx + '[' + pointIx + ']', refCentroid[pointIx], testCentroid.get(pointIx), EPSILON);        }    }}
public void mahout_f4870_0() throws Exception
{    CanopyMapper mapper = new CanopyMapper();    Configuration conf = getConfiguration();    conf.set(CanopyConfigKeys.DISTANCE_MEASURE_KEY, manhattanDistanceMeasure.getClass().getName());    conf.set(CanopyConfigKeys.T1_KEY, String.valueOf(3.1));    conf.set(CanopyConfigKeys.T2_KEY, String.valueOf(2.1));    conf.set(CanopyConfigKeys.CF_KEY, "0");    DummyRecordWriter<Text, VectorWritable> writer = new DummyRecordWriter<>();    Mapper<WritableComparable<?>, VectorWritable, Text, VectorWritable>.Context context = DummyRecordWriter.build(mapper, conf, writer);    mapper.setup(context);    List<VectorWritable> points = getPointsWritable();        for (VectorWritable point : points) {        mapper.map(new Text(), point, context);    }    mapper.cleanup(context);    assertEquals("Number of map results", 1, writer.getData().size());        List<VectorWritable> data = writer.getValue(new Text("centroid"));    assertEquals("Number of centroids", 3, data.size());    for (int i = 0; i < data.size(); i++) {        assertEquals("Centroid error", manhattanCentroids.get(i).asFormatString(), data.get(i).get().asFormatString());    }}
public void mahout_f4871_0() throws Exception
{    CanopyMapper mapper = new CanopyMapper();    Configuration conf = getConfiguration();    conf.set(CanopyConfigKeys.DISTANCE_MEASURE_KEY, euclideanDistanceMeasure.getClass().getName());    conf.set(CanopyConfigKeys.T1_KEY, String.valueOf(3.1));    conf.set(CanopyConfigKeys.T2_KEY, String.valueOf(2.1));    conf.set(CanopyConfigKeys.CF_KEY, "0");    DummyRecordWriter<Text, VectorWritable> writer = new DummyRecordWriter<>();    Mapper<WritableComparable<?>, VectorWritable, Text, VectorWritable>.Context context = DummyRecordWriter.build(mapper, conf, writer);    mapper.setup(context);    List<VectorWritable> points = getPointsWritable();        for (VectorWritable point : points) {        mapper.map(new Text(), point, context);    }    mapper.cleanup(context);    assertEquals("Number of map results", 1, writer.getData().size());        List<VectorWritable> data = writer.getValue(new Text("centroid"));    assertEquals("Number of centroids", 3, data.size());    for (int i = 0; i < data.size(); i++) {        assertEquals("Centroid error", euclideanCentroids.get(i).asFormatString(), data.get(i).get().asFormatString());    }}
public void mahout_f4872_0() throws Exception
{    CanopyReducer reducer = new CanopyReducer();    Configuration conf = getConfiguration();    conf.set(CanopyConfigKeys.DISTANCE_MEASURE_KEY, "org.apache.mahout.common.distance.ManhattanDistanceMeasure");    conf.set(CanopyConfigKeys.T1_KEY, String.valueOf(3.1));    conf.set(CanopyConfigKeys.T2_KEY, String.valueOf(2.1));    conf.set(CanopyConfigKeys.CF_KEY, "0");    DummyRecordWriter<Text, ClusterWritable> writer = new DummyRecordWriter<>();    Reducer<Text, VectorWritable, Text, ClusterWritable>.Context context = DummyRecordWriter.build(reducer, conf, writer, Text.class, VectorWritable.class);    reducer.setup(context);    List<VectorWritable> points = getPointsWritable();    reducer.reduce(new Text("centroid"), points, context);    Iterable<Text> keys = writer.getKeysInInsertionOrder();    assertEquals("Number of centroids", 3, Iterables.size(keys));    int i = 0;    for (Text key : keys) {        List<ClusterWritable> data = writer.getValue(key);        ClusterWritable clusterWritable = data.get(0);        Canopy canopy = (Canopy) clusterWritable.getValue();        assertEquals(manhattanCentroids.get(i).asFormatString() + " is not equal to " + canopy.computeCentroid().asFormatString(), manhattanCentroids.get(i), canopy.computeCentroid());        i++;    }}
public void mahout_f4873_0() throws Exception
{    CanopyReducer reducer = new CanopyReducer();    Configuration conf = getConfiguration();    conf.set(CanopyConfigKeys.DISTANCE_MEASURE_KEY, "org.apache.mahout.common.distance.EuclideanDistanceMeasure");    conf.set(CanopyConfigKeys.T1_KEY, String.valueOf(3.1));    conf.set(CanopyConfigKeys.T2_KEY, String.valueOf(2.1));    conf.set(CanopyConfigKeys.CF_KEY, "0");    DummyRecordWriter<Text, ClusterWritable> writer = new DummyRecordWriter<>();    Reducer<Text, VectorWritable, Text, ClusterWritable>.Context context = DummyRecordWriter.build(reducer, conf, writer, Text.class, VectorWritable.class);    reducer.setup(context);    List<VectorWritable> points = getPointsWritable();    reducer.reduce(new Text("centroid"), points, context);    Iterable<Text> keys = writer.getKeysInInsertionOrder();    assertEquals("Number of centroids", 3, Iterables.size(keys));    int i = 0;    for (Text key : keys) {        List<ClusterWritable> data = writer.getValue(key);        ClusterWritable clusterWritable = data.get(0);        Canopy canopy = (Canopy) clusterWritable.getValue();        assertEquals(euclideanCentroids.get(i).asFormatString() + " is not equal to " + canopy.computeCentroid().asFormatString(), euclideanCentroids.get(i), canopy.computeCentroid());        i++;    }}
public void mahout_f4874_0() throws Exception
{    List<VectorWritable> points = getPointsWritable();    Configuration config = getConfiguration();    ClusteringTestUtils.writePointsToFile(points, getTestTempFilePath("testdata/file1"), fs, config);    ClusteringTestUtils.writePointsToFile(points, getTestTempFilePath("testdata/file2"), fs, config);        Path output = getTestTempDirPath("output");    CanopyDriver.run(config, getTestTempDirPath("testdata"), output, manhattanDistanceMeasure, 3.1, 2.1, false, 0.0, false);        Path path = new Path(output, "clusters-0-final/part-r-00000");    FileSystem fs = FileSystem.get(path.toUri(), config);    SequenceFile.Reader reader = new SequenceFile.Reader(fs, path, config);    try {        Writable key = new Text();        ClusterWritable clusterWritable = new ClusterWritable();        assertTrue("more to come", reader.next(key, clusterWritable));        assertEquals("1st key", "C-0", key.toString());        List<Pair<Double, Double>> refCenters = Lists.newArrayList();        refCenters.add(new Pair<>(1.5, 1.5));        refCenters.add(new Pair<>(4.333333333333334, 4.333333333333334));        Pair<Double, Double> c = new Pair<>(clusterWritable.getValue().getCenter().get(0), clusterWritable.getValue().getCenter().get(1));        assertTrue("center " + c + " not found", findAndRemove(c, refCenters, EPSILON));        assertTrue("more to come", reader.next(key, clusterWritable));        assertEquals("2nd key", "C-1", key.toString());        c = new Pair<>(clusterWritable.getValue().getCenter().get(0), clusterWritable.getValue().getCenter().get(1));        assertTrue("center " + c + " not found", findAndRemove(c, refCenters, EPSILON));        assertFalse("more to come", reader.next(key, clusterWritable));    } finally {        Closeables.close(reader, true);    }}
 static boolean mahout_f4875_0(Pair<Double, Double> target, Collection<Pair<Double, Double>> list, double epsilon)
{    for (Pair<Double, Double> curr : list) {        if ((Math.abs(target.getFirst() - curr.getFirst()) < epsilon) && (Math.abs(target.getSecond() - curr.getSecond()) < epsilon)) {            list.remove(curr);            return true;        }    }    return false;}
public void mahout_f4876_0() throws Exception
{    List<VectorWritable> points = getPointsWritable();    Configuration config = getConfiguration();    ClusteringTestUtils.writePointsToFile(points, getTestTempFilePath("testdata/file1"), fs, config);    ClusteringTestUtils.writePointsToFile(points, getTestTempFilePath("testdata/file2"), fs, config);        Path output = getTestTempDirPath("output");    CanopyDriver.run(config, getTestTempDirPath("testdata"), output, euclideanDistanceMeasure, 3.1, 2.1, false, 0.0, false);        Path path = new Path(output, "clusters-0-final/part-r-00000");    FileSystem fs = FileSystem.get(path.toUri(), config);    SequenceFile.Reader reader = new SequenceFile.Reader(fs, path, config);    try {        Writable key = new Text();        ClusterWritable clusterWritable = new ClusterWritable();        assertTrue("more to come", reader.next(key, clusterWritable));        assertEquals("1st key", "C-0", key.toString());        List<Pair<Double, Double>> refCenters = Lists.newArrayList();        refCenters.add(new Pair<>(1.8, 1.8));        refCenters.add(new Pair<>(4.433333333333334, 4.433333333333334));        Pair<Double, Double> c = new Pair<>(clusterWritable.getValue().getCenter().get(0), clusterWritable.getValue().getCenter().get(1));        assertTrue("center " + c + " not found", findAndRemove(c, refCenters, EPSILON));        assertTrue("more to come", reader.next(key, clusterWritable));        assertEquals("2nd key", "C-1", key.toString());        c = new Pair<>(clusterWritable.getValue().getCenter().get(0), clusterWritable.getValue().getCenter().get(1));        assertTrue("center " + c + " not found", findAndRemove(c, refCenters, EPSILON));        assertFalse("more to come", reader.next(key, clusterWritable));    } finally {        Closeables.close(reader, true);    }}
public void mahout_f4877_0() throws Exception
{    List<VectorWritable> points = getPointsWritable();    Configuration config = getConfiguration();    ClusteringTestUtils.writePointsToFile(points, getTestTempFilePath("testdata/file1"), fs, config);        Path output = getTestTempDirPath("output");    CanopyDriver.run(config, getTestTempDirPath("testdata"), output, manhattanDistanceMeasure, 3.1, 2.1, true, 0.0, true);        Path path = new Path(output, "clusters-0-final/part-r-00000");    int ix = 0;    for (ClusterWritable clusterWritable : new SequenceFileValueIterable<ClusterWritable>(path, true, config)) {        assertEquals("Center [" + ix + ']', manhattanCentroids.get(ix), clusterWritable.getValue().getCenter());        ix++;    }    path = new Path(output, "clusteredPoints/part-m-0");    long count = HadoopUtil.countRecords(path, config);    assertEquals("number of points", points.size(), count);}
public void mahout_f4878_0() throws Exception
{    List<VectorWritable> points = getPointsWritable();    Configuration config = getConfiguration();    ClusteringTestUtils.writePointsToFile(points, getTestTempFilePath("testdata/file1"), fs, config);        Path output = getTestTempDirPath("output");    String[] args = { optKey(DefaultOptionCreator.INPUT_OPTION), getTestTempDirPath("testdata").toString(), optKey(DefaultOptionCreator.OUTPUT_OPTION), output.toString(), optKey(DefaultOptionCreator.DISTANCE_MEASURE_OPTION), EuclideanDistanceMeasure.class.getName(), optKey(DefaultOptionCreator.T1_OPTION), "3.1", optKey(DefaultOptionCreator.T2_OPTION), "2.1", optKey(DefaultOptionCreator.CLUSTERING_OPTION), optKey(DefaultOptionCreator.OVERWRITE_OPTION), optKey(DefaultOptionCreator.METHOD_OPTION), DefaultOptionCreator.SEQUENTIAL_METHOD };    ToolRunner.run(config, new CanopyDriver(), args);        Path path = new Path(output, "clusters-0-final/part-r-00000");    int ix = 0;    for (ClusterWritable clusterWritable : new SequenceFileValueIterable<ClusterWritable>(path, true, config)) {        assertEquals("Center [" + ix + ']', euclideanCentroids.get(ix), clusterWritable.getValue().getCenter());        ix++;    }    path = new Path(output, "clusteredPoints/part-m-0");    long count = HadoopUtil.countRecords(path, config);    assertEquals("number of points", points.size(), count);}
public void mahout_f4879_0() throws Exception
{    List<VectorWritable> points = getPointsWritable();    Configuration config = getConfiguration();    ClusteringTestUtils.writePointsToFile(points, getTestTempFilePath("testdata/file1"), fs, config);        Path output = getTestTempDirPath("output");    String[] args = { optKey(DefaultOptionCreator.INPUT_OPTION), getTestTempDirPath("testdata").toString(), optKey(DefaultOptionCreator.OUTPUT_OPTION), output.toString(), optKey(DefaultOptionCreator.DISTANCE_MEASURE_OPTION), EuclideanDistanceMeasure.class.getName(), optKey(DefaultOptionCreator.T1_OPTION), "3.1", optKey(DefaultOptionCreator.T2_OPTION), "2.1", optKey(DefaultOptionCreator.OUTLIER_THRESHOLD), "0.5", optKey(DefaultOptionCreator.CLUSTERING_OPTION), optKey(DefaultOptionCreator.OVERWRITE_OPTION), optKey(DefaultOptionCreator.METHOD_OPTION), DefaultOptionCreator.SEQUENTIAL_METHOD };    ToolRunner.run(config, new CanopyDriver(), args);        Path path = new Path(output, "clusters-0-final/part-r-00000");    int ix = 0;    for (ClusterWritable clusterWritable : new SequenceFileValueIterable<ClusterWritable>(path, true, config)) {        assertEquals("Center [" + ix + ']', euclideanCentroids.get(ix), clusterWritable.getValue().getCenter());        ix++;    }    path = new Path(output, "clusteredPoints/part-m-0");    long count = HadoopUtil.countRecords(path, config);    int expectedPointsHavingPDFGreaterThanThreshold = 6;    assertEquals("number of points", expectedPointsHavingPDFGreaterThanThreshold, count);}
public void mahout_f4880_0() throws Exception
{    List<VectorWritable> points = getPointsWritable();    Configuration conf = getConfiguration();    ClusteringTestUtils.writePointsToFile(points, true, getTestTempFilePath("testdata/file1"), fs, conf);    ClusteringTestUtils.writePointsToFile(points, true, getTestTempFilePath("testdata/file2"), fs, conf);        Path output = getTestTempDirPath("output");    CanopyDriver.run(conf, getTestTempDirPath("testdata"), output, manhattanDistanceMeasure, 3.1, 2.1, true, 0.0, false);    Path path = new Path(output, "clusteredPoints/part-m-00000");    long count = HadoopUtil.countRecords(path, conf);    assertEquals("number of points", points.size(), count);}
public void mahout_f4881_0() throws Exception
{    List<VectorWritable> points = getPointsWritable();    Configuration conf = getConfiguration();    ClusteringTestUtils.writePointsToFile(points, true, getTestTempFilePath("testdata/file1"), fs, conf);    ClusteringTestUtils.writePointsToFile(points, true, getTestTempFilePath("testdata/file2"), fs, conf);        Path output = getTestTempDirPath("output");    String[] args = { optKey(DefaultOptionCreator.INPUT_OPTION), getTestTempDirPath("testdata").toString(), optKey(DefaultOptionCreator.OUTPUT_OPTION), output.toString(), optKey(DefaultOptionCreator.DISTANCE_MEASURE_OPTION), EuclideanDistanceMeasure.class.getName(), optKey(DefaultOptionCreator.T1_OPTION), "3.1", optKey(DefaultOptionCreator.T2_OPTION), "2.1", optKey(DefaultOptionCreator.CLUSTERING_OPTION), optKey(DefaultOptionCreator.OVERWRITE_OPTION) };    ToolRunner.run(getConfiguration(), new CanopyDriver(), args);    Path path = new Path(output, "clusteredPoints/part-m-00000");    long count = HadoopUtil.countRecords(path, conf);    assertEquals("number of points", points.size(), count);}
public void mahout_f4882_0() throws Exception
{    List<VectorWritable> points = getPointsWritable();    Configuration conf = getConfiguration();    ClusteringTestUtils.writePointsToFile(points, true, getTestTempFilePath("testdata/file1"), fs, conf);    ClusteringTestUtils.writePointsToFile(points, true, getTestTempFilePath("testdata/file2"), fs, conf);        Path output = getTestTempDirPath("output");    String[] args = { optKey(DefaultOptionCreator.INPUT_OPTION), getTestTempDirPath("testdata").toString(), optKey(DefaultOptionCreator.OUTPUT_OPTION), output.toString(), optKey(DefaultOptionCreator.DISTANCE_MEASURE_OPTION), EuclideanDistanceMeasure.class.getName(), optKey(DefaultOptionCreator.T1_OPTION), "3.1", optKey(DefaultOptionCreator.T2_OPTION), "2.1", optKey(DefaultOptionCreator.OUTLIER_THRESHOLD), "0.7", optKey(DefaultOptionCreator.CLUSTERING_OPTION), optKey(DefaultOptionCreator.OVERWRITE_OPTION) };    ToolRunner.run(getConfiguration(), new CanopyDriver(), args);    Path path = new Path(output, "clusteredPoints/part-m-00000");    long count = HadoopUtil.countRecords(path, conf);    int expectedPointsAfterOutlierRemoval = 8;    assertEquals("number of points", expectedPointsAfterOutlierRemoval, count);}
public void mahout_f4883_0() throws Exception
{    CanopyReducer reducer = new CanopyReducer();    Configuration conf = getConfiguration();    conf.set(CanopyConfigKeys.DISTANCE_MEASURE_KEY, "org.apache.mahout.common.distance.ManhattanDistanceMeasure");    conf.set(CanopyConfigKeys.T1_KEY, String.valueOf(3.1));    conf.set(CanopyConfigKeys.T2_KEY, String.valueOf(2.1));    conf.set(CanopyConfigKeys.T3_KEY, String.valueOf(1.1));    conf.set(CanopyConfigKeys.T4_KEY, String.valueOf(0.1));    conf.set(CanopyConfigKeys.CF_KEY, "0");    DummyRecordWriter<Text, ClusterWritable> writer = new DummyRecordWriter<>();    Reducer<Text, VectorWritable, Text, ClusterWritable>.Context context = DummyRecordWriter.build(reducer, conf, writer, Text.class, VectorWritable.class);    reducer.setup(context);    assertEquals(1.1, reducer.getCanopyClusterer().getT1(), EPSILON);    assertEquals(0.1, reducer.getCanopyClusterer().getT2(), EPSILON);}
public void mahout_f4884_0() throws Exception
{    CanopyMapper mapper = new CanopyMapper();    Configuration conf = getConfiguration();    conf.set(CanopyConfigKeys.DISTANCE_MEASURE_KEY, manhattanDistanceMeasure.getClass().getName());    conf.set(CanopyConfigKeys.T1_KEY, String.valueOf(3.1));    conf.set(CanopyConfigKeys.T2_KEY, String.valueOf(2.1));    conf.set(CanopyConfigKeys.CF_KEY, "3");    DummyRecordWriter<Text, VectorWritable> writer = new DummyRecordWriter<>();    Mapper<WritableComparable<?>, VectorWritable, Text, VectorWritable>.Context context = DummyRecordWriter.build(mapper, conf, writer);    mapper.setup(context);    List<VectorWritable> points = getPointsWritable();        for (VectorWritable point : points) {        mapper.map(new Text(), point, context);    }    mapper.cleanup(context);    assertEquals("Number of map results", 1, writer.getData().size());        List<VectorWritable> data = writer.getValue(new Text("centroid"));    assertEquals("Number of centroids", 2, data.size());}
public void mahout_f4885_0() throws Exception
{    CanopyReducer reducer = new CanopyReducer();    Configuration conf = getConfiguration();    conf.set(CanopyConfigKeys.DISTANCE_MEASURE_KEY, "org.apache.mahout.common.distance.ManhattanDistanceMeasure");    conf.set(CanopyConfigKeys.T1_KEY, String.valueOf(3.1));    conf.set(CanopyConfigKeys.T2_KEY, String.valueOf(2.1));    conf.set(CanopyConfigKeys.CF_KEY, "3");    DummyRecordWriter<Text, ClusterWritable> writer = new DummyRecordWriter<>();    Reducer<Text, VectorWritable, Text, ClusterWritable>.Context context = DummyRecordWriter.build(reducer, conf, writer, Text.class, VectorWritable.class);    reducer.setup(context);    List<VectorWritable> points = getPointsWritable();    reducer.reduce(new Text("centroid"), points, context);    Set<Text> keys = writer.getKeys();    assertEquals("Number of centroids", 2, keys.size());}
public void mahout_f4886_0() throws Exception
{    super.setUp();    Configuration conf = getConfiguration();    fs = FileSystem.get(conf);    firstCluster = Lists.newArrayList();    secondCluster = Lists.newArrayList();    thirdCluster = Lists.newArrayList();}
private static List<VectorWritable> mahout_f4887_0(double[][] raw)
{    List<VectorWritable> points = Lists.newArrayList();    for (double[] fr : raw) {        Vector vec = new RandomAccessSparseVector(fr.length);        vec.assign(fr);        points.add(new VectorWritable(vec));    }    return points;}
public void mahout_f4888_0() throws Exception
{    List<VectorWritable> points = getPointsWritable(REFERENCE);    pointsPath = getTestTempDirPath("points");    clusteringOutputPath = getTestTempDirPath("output");    classifiedOutputPath = getTestTempDirPath("classifiedClusters");    HadoopUtil.delete(conf, classifiedOutputPath);    conf = getConfiguration();    ClusteringTestUtils.writePointsToFile(points, true, new Path(pointsPath, "file1"), fs, conf);    runClustering(pointsPath, conf, false);    runClassificationWithOutlierRemoval(false);    collectVectorsForAssertion();    assertVectorsWithOutlierRemoval();}
public void mahout_f4889_0() throws Exception
{    List<VectorWritable> points = getPointsWritable(REFERENCE);    pointsPath = getTestTempDirPath("points");    clusteringOutputPath = getTestTempDirPath("output");    classifiedOutputPath = getTestTempDirPath("classify");    conf = getConfiguration();    ClusteringTestUtils.writePointsToFile(points, new Path(pointsPath, "file1"), fs, conf);    runClustering(pointsPath, conf, true);    runClassificationWithoutOutlierRemoval();    collectVectorsForAssertion();    assertVectorsWithoutOutlierRemoval();}
public void mahout_f4890_0() throws Exception
{    List<VectorWritable> points = getPointsWritable(REFERENCE);    pointsPath = getTestTempDirPath("points");    clusteringOutputPath = getTestTempDirPath("output");    classifiedOutputPath = getTestTempDirPath("classify");    conf = getConfiguration();    ClusteringTestUtils.writePointsToFile(points, new Path(pointsPath, "file1"), fs, conf);    runClustering(pointsPath, conf, true);    runClassificationWithOutlierRemoval(true);    collectVectorsForAssertion();    assertVectorsWithOutlierRemoval();}
private void mahout_f4891_0(Path pointsPath, Configuration conf, Boolean runSequential) throws IOException, InterruptedException, ClassNotFoundException
{    CanopyDriver.run(conf, pointsPath, clusteringOutputPath, new ManhattanDistanceMeasure(), 3.1, 2.1, false, 0.0, runSequential);    Path finalClustersPath = new Path(clusteringOutputPath, "clusters-0-final");    ClusterClassifier.writePolicy(new CanopyClusteringPolicy(), finalClustersPath);}
private void mahout_f4892_0() throws IOException, InterruptedException, ClassNotFoundException
{    ClusterClassificationDriver.run(getConfiguration(), pointsPath, clusteringOutputPath, classifiedOutputPath, 0.0, true, true);}
private void mahout_f4893_0(boolean runSequential) throws IOException, InterruptedException, ClassNotFoundException
{    ClusterClassificationDriver.run(getConfiguration(), pointsPath, clusteringOutputPath, classifiedOutputPath, 0.73, true, runSequential);}
private void mahout_f4894_0() throws IOException
{    Path[] partFilePaths = FileUtil.stat2Paths(fs.globStatus(classifiedOutputPath));    FileStatus[] listStatus = fs.listStatus(partFilePaths, PathFilters.partFilter());    for (FileStatus partFile : listStatus) {        SequenceFile.Reader classifiedVectors = new SequenceFile.Reader(fs, partFile.getPath(), conf);        Writable clusterIdAsKey = new IntWritable();        WeightedPropertyVectorWritable point = new WeightedPropertyVectorWritable();        while (classifiedVectors.next(clusterIdAsKey, point)) {            collectVector(clusterIdAsKey.toString(), point.getVector());        }    }}
private void mahout_f4895_0(String clusterId, Vector vector)
{    if ("0".equals(clusterId)) {        firstCluster.add(vector);    } else if ("1".equals(clusterId)) {        secondCluster.add(vector);    } else if ("2".equals(clusterId)) {        thirdCluster.add(vector);    }}
private void mahout_f4896_0()
{    checkClustersWithOutlierRemoval();}
private void mahout_f4897_0()
{    assertFirstClusterWithoutOutlierRemoval();    assertSecondClusterWithoutOutlierRemoval();    assertThirdClusterWithoutOutlierRemoval();}
private void mahout_f4898_0()
{    Assert.assertEquals(2, thirdCluster.size());    for (Vector vector : thirdCluster) {        Assert.assertTrue(ArrayUtils.contains(new String[] { "{0:9.0,1:9.0}", "{0:8.0,1:8.0}" }, vector.asFormatString()));    }}
private void mahout_f4899_0()
{    Assert.assertEquals(4, secondCluster.size());    for (Vector vector : secondCluster) {        Assert.assertTrue(ArrayUtils.contains(new String[] { "{0:4.0,1:4.0}", "{0:5.0,1:4.0}", "{0:4.0,1:5.0}", "{0:5.0,1:5.0}" }, vector.asFormatString()));    }}
private void mahout_f4900_0()
{    Assert.assertEquals(3, firstCluster.size());    for (Vector vector : firstCluster) {        Assert.assertTrue(ArrayUtils.contains(new String[] { "{0:1.0,1:1.0}", "{0:2.0,1:1.0}", "{0:1.0,1:2.0}" }, vector.asFormatString()));    }}
private void mahout_f4901_0()
{    Set<String> reference = Sets.newHashSet("{0:9.0,1:9.0}", "{0:1.0,1:1.0}");    List<List<Vector>> clusters = Lists.newArrayList();    clusters.add(firstCluster);    clusters.add(secondCluster);    clusters.add(thirdCluster);    int singletonCnt = 0;    int emptyCnt = 0;    for (List<Vector> vList : clusters) {        if (vList.isEmpty()) {            emptyCnt++;        } else {            singletonCnt++;            assertEquals("expecting only singleton clusters; got size=" + vList.size(), 1, vList.size());            if (vList.get(0).getClass().equals(NamedVector.class)) {                Assert.assertTrue("not expecting cluster:" + ((NamedVector) vList.get(0)).getDelegate().asFormatString(), reference.contains(((NamedVector) vList.get(0)).getDelegate().asFormatString()));                reference.remove(((NamedVector) vList.get(0)).getDelegate().asFormatString());            } else if (vList.get(0).getClass().equals(RandomAccessSparseVector.class)) {                Assert.assertTrue("not expecting cluster:" + vList.get(0).asFormatString(), reference.contains(vList.get(0).asFormatString()));                reference.remove(vList.get(0).asFormatString());            }        }    }    Assert.assertEquals("Different number of empty clusters than expected!", 1, emptyCnt);    Assert.assertEquals("Different number of singletons than expected!", 2, singletonCnt);    Assert.assertEquals("Didn't match all reference clusters!", 0, reference.size());}
public static void mahout_f4902_0(Iterable<VectorWritable> points, Path path, FileSystem fs, Configuration conf) throws IOException
{    writePointsToFile(points, false, path, fs, conf);}
public static void mahout_f4903_0(Iterable<VectorWritable> points, boolean intWritable, Path path, FileSystem fs, Configuration conf) throws IOException
{    SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, path, intWritable ? IntWritable.class : LongWritable.class, VectorWritable.class);    try {        int recNum = 0;        for (VectorWritable point : points) {            writer.append(intWritable ? new IntWritable(recNum++) : new LongWritable(recNum++), point);        }    } finally {        Closeables.close(writer, false);    }}
public static Matrix mahout_f4904_0(Matrix matrix, Random random, int numDocs, int numSamples, int numTopicsPerDoc)
{    Matrix corpus = new SparseRowMatrix(numDocs, matrix.numCols());    LDASampler modelSampler = new LDASampler(matrix, random);    Vector topicVector = new DenseVector(matrix.numRows());    for (int i = 0; i < numTopicsPerDoc; i++) {        int topic = random.nextInt(topicVector.size());        topicVector.set(topic, topicVector.get(topic) + 1);    }    for (int docId = 0; docId < numDocs; docId++) {        for (int sample : modelSampler.sample(topicVector, numSamples)) {            corpus.set(docId, sample, corpus.get(docId, sample) + 1);        }    }    return corpus;}
public static Matrix mahout_f4905_0(int numTopics, int numTerms)
{    return randomStructuredModel(numTopics, numTerms, new DoubleFunction() {        @Override        public double apply(double d) {            return 1.0 / (1 + Math.abs(d));        }    });}
public double mahout_f4906_0(double d)
{    return 1.0 / (1 + Math.abs(d));}
public static Matrix mahout_f4907_0(int numTopics, int numTerms, DoubleFunction decay)
{    Matrix model = new DenseMatrix(numTopics, numTerms);    int width = numTerms / numTopics;    for (int topic = 0; topic < numTopics; topic++) {        int topicCentroid = width * (1 + topic);        for (int i = 0; i < numTerms; i++) {            int distance = Math.abs(topicCentroid - i);            if (distance > numTerms / 2) {                distance = numTerms - distance;            }            double v = decay.apply(distance);            model.set(topic, i, v);        }    }    return model;}
public int[] mahout_f4908_0(Vector topicDistribution, int numSamples)
{    Preconditions.checkNotNull(topicDistribution);    Preconditions.checkArgument(numSamples > 0, "numSamples must be positive");    Preconditions.checkArgument(topicDistribution.size() == samplers.length, "topicDistribution must have same cardinality as the sampling model");    int[] samples = new int[numSamples];    Sampler topicSampler = new Sampler(random, topicDistribution);    for (int i = 0; i < numSamples; i++) {        samples[i] = samplers[topicSampler.sample()].sample();    }    return samples;}
public void mahout_f4909_0() throws Exception
{    super.setUp();    Configuration conf = getConfiguration();    fs = FileSystem.get(conf);}
private static Vector mahout_f4910_0(Vector point)
{    return point.plus(0.1);}
public void mahout_f4911_0() throws Exception
{    List<VectorWritable> points = TestKmeansClustering.getPointsWritable(TestKmeansClustering.REFERENCE);    Path pointsPath = getTestTempDirPath("points");    Path clustersPath = getTestTempDirPath("clusters");    Configuration conf = getConfiguration();    ClusteringTestUtils.writePointsToFile(points, new Path(pointsPath, "file1"), fs, conf);    for (int k = 0; k < points.size(); k++) {        System.out.println("testKFuzzyKMeansMRJob k= " + k);                SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, new Path(clustersPath, "part-00000"), Text.class, SoftCluster.class);        try {            for (int i = 0; i < k + 1; i++) {                Vector vec = tweakValue(points.get(i).get());                SoftCluster cluster = new SoftCluster(vec, i, measure);                /* add the center so the centroid will be correct upon output */                cluster.observe(cluster.getCenter(), 1);                                writer.append(new Text(cluster.getIdentifier()), cluster);            }        } finally {            Closeables.close(writer, false);        }                Path output = getTestTempDirPath("output" + k);        /*      FuzzyKMeansDriver.runJob(pointsPath,                                     clustersPath,                                     output,                                     EuclideanDistanceMeasure.class.getName(),                                     0.001,                                     2,                                     k + 1,                                     2,                                     false,                                     true,                                     0);      */        String[] args = { optKey(DefaultOptionCreator.INPUT_OPTION), pointsPath.toString(), optKey(DefaultOptionCreator.CLUSTERS_IN_OPTION), clustersPath.toString(), optKey(DefaultOptionCreator.OUTPUT_OPTION), output.toString(), optKey(DefaultOptionCreator.DISTANCE_MEASURE_OPTION), EuclideanDistanceMeasure.class.getName(), optKey(DefaultOptionCreator.CONVERGENCE_DELTA_OPTION), "0.001", optKey(DefaultOptionCreator.MAX_ITERATIONS_OPTION), "2", optKey(FuzzyKMeansDriver.M_OPTION), "2.0", optKey(DefaultOptionCreator.CLUSTERING_OPTION), optKey(DefaultOptionCreator.EMIT_MOST_LIKELY_OPTION), optKey(DefaultOptionCreator.OVERWRITE_OPTION), optKey(DefaultOptionCreator.METHOD_OPTION), DefaultOptionCreator.SEQUENTIAL_METHOD };        FuzzyKMeansDriver.main(args);        long count = HadoopUtil.countRecords(new Path(output, "clusteredPoints/part-m-0"), conf);        assertTrue(count > 0);    }}
public void mahout_f4912_0() throws Exception
{    List<VectorWritable> points = TestKmeansClustering.getPointsWritable(TestKmeansClustering.REFERENCE);    Path pointsPath = getTestTempDirPath("points");    Path clustersPath = getTestTempDirPath("clusters");    Configuration conf = getConfiguration();    ClusteringTestUtils.writePointsToFile(points, new Path(pointsPath, "file1"), fs, conf);    for (int k = 0; k < points.size(); k++) {        System.out.println("testKFuzzyKMeansMRJob k= " + k);                SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, new Path(clustersPath, "part-00000"), Text.class, SoftCluster.class);        try {            for (int i = 0; i < k + 1; i++) {                Vector vec = tweakValue(points.get(i).get());                SoftCluster cluster = new SoftCluster(vec, i, measure);                /* add the center so the centroid will be correct upon output */                cluster.observe(cluster.getCenter(), 1);                                writer.append(new Text(cluster.getIdentifier()), cluster);            }        } finally {            Closeables.close(writer, false);        }                Path output = getTestTempDirPath("output" + k);        /*      FuzzyKMeansDriver.runJob(pointsPath,                                     clustersPath,                                     output,                                     EuclideanDistanceMeasure.class.getName(),                                     0.001,                                     2,                                     k + 1,                                     2,                                     false,                                     true,                                     0);      */        String[] args = { optKey(DefaultOptionCreator.INPUT_OPTION), pointsPath.toString(), optKey(DefaultOptionCreator.CLUSTERS_IN_OPTION), clustersPath.toString(), optKey(DefaultOptionCreator.OUTPUT_OPTION), output.toString(), optKey(DefaultOptionCreator.DISTANCE_MEASURE_OPTION), EuclideanDistanceMeasure.class.getName(), optKey(DefaultOptionCreator.CONVERGENCE_DELTA_OPTION), "0.001", optKey(DefaultOptionCreator.MAX_ITERATIONS_OPTION), "2", optKey(FuzzyKMeansDriver.M_OPTION), "2.0", optKey(DefaultOptionCreator.CLUSTERING_OPTION), optKey(DefaultOptionCreator.EMIT_MOST_LIKELY_OPTION), optKey(DefaultOptionCreator.OVERWRITE_OPTION) };        ToolRunner.run(getConfiguration(), new FuzzyKMeansDriver(), args);        long count = HadoopUtil.countRecords(new Path(output, "clusteredPoints/part-m-00000"), conf);        assertTrue(count > 0);    }}
private static ClusterClassifier mahout_f4913_0()
{    List<Cluster> models = Lists.newArrayList();    DistanceMeasure measure = new ManhattanDistanceMeasure();    models.add(new DistanceMeasureCluster(new DenseVector(2).assign(1), 0, measure));    models.add(new DistanceMeasureCluster(new DenseVector(2), 1, measure));    models.add(new DistanceMeasureCluster(new DenseVector(2).assign(-1), 2, measure));    return new ClusterClassifier(models, new KMeansClusteringPolicy());}
private static ClusterClassifier mahout_f4914_0()
{    List<Cluster> models = Lists.newArrayList();    DistanceMeasure measure = new ManhattanDistanceMeasure();    models.add(new org.apache.mahout.clustering.kmeans.Kluster(new DenseVector(2).assign(1), 0, measure));    models.add(new org.apache.mahout.clustering.kmeans.Kluster(new DenseVector(2), 1, measure));    models.add(new org.apache.mahout.clustering.kmeans.Kluster(new DenseVector(2).assign(-1), 2, measure));    return new ClusterClassifier(models, new KMeansClusteringPolicy());}
private static ClusterClassifier mahout_f4915_0()
{    List<Cluster> models = Lists.newArrayList();    DistanceMeasure measure = new CosineDistanceMeasure();    models.add(new org.apache.mahout.clustering.kmeans.Kluster(new DenseVector(2).assign(1), 0, measure));    models.add(new org.apache.mahout.clustering.kmeans.Kluster(new DenseVector(2), 1, measure));    models.add(new org.apache.mahout.clustering.kmeans.Kluster(new DenseVector(2).assign(-1), 2, measure));    return new ClusterClassifier(models, new KMeansClusteringPolicy());}
private static ClusterClassifier mahout_f4916_0()
{    List<Cluster> models = Lists.newArrayList();    DistanceMeasure measure = new ManhattanDistanceMeasure();    models.add(new SoftCluster(new DenseVector(2).assign(1), 0, measure));    models.add(new SoftCluster(new DenseVector(2), 1, measure));    models.add(new SoftCluster(new DenseVector(2).assign(-1), 2, measure));    return new ClusterClassifier(models, new FuzzyKMeansClusteringPolicy());}
private ClusterClassifier mahout_f4917_0(ClusterClassifier classifier) throws IOException
{    Path path = new Path(getTestTempDirPath(), "output");    classifier.writeToSeqFiles(path);    ClusterClassifier newClassifier = new ClusterClassifier();    newClassifier.readFromSeqFiles(getConfiguration(), path);    return newClassifier;}
public void mahout_f4918_0()
{    ClusterClassifier classifier = newDMClassifier();    Vector pdf = classifier.classify(new DenseVector(2));    assertEquals("[0,0]", "[0.2,0.6,0.2]", AbstractCluster.formatVector(pdf, null));    pdf = classifier.classify(new DenseVector(2).assign(2));    assertEquals("[2,2]", "[0.493,0.296,0.211]", AbstractCluster.formatVector(pdf, null));}
public void mahout_f4919_0()
{    ClusterClassifier classifier = newKlusterClassifier();    Vector pdf = classifier.classify(new DenseVector(2));    assertEquals("[0,0]", "[0.2,0.6,0.2]", AbstractCluster.formatVector(pdf, null));    pdf = classifier.classify(new DenseVector(2).assign(2));    assertEquals("[2,2]", "[0.493,0.296,0.211]", AbstractCluster.formatVector(pdf, null));}
public void mahout_f4920_0()
{    ClusterClassifier classifier = newSoftClusterClassifier();    Vector pdf = classifier.classify(new DenseVector(2));    assertEquals("[0,0]", "[0.0,1.0,0.0]", AbstractCluster.formatVector(pdf, null));    pdf = classifier.classify(new DenseVector(2).assign(2));    assertEquals("[2,2]", "[0.735,0.184,0.082]", AbstractCluster.formatVector(pdf, null));}
public void mahout_f4921_0() throws Exception
{    ClusterClassifier classifier = newDMClassifier();    ClusterClassifier classifierOut = writeAndRead(classifier);    assertEquals(classifier.getModels().size(), classifierOut.getModels().size());    assertEquals(classifier.getModels().get(0).getClass().getName(), classifierOut.getModels().get(0).getClass().getName());}
public void mahout_f4922_0() throws Exception
{    ClusterClassifier classifier = newKlusterClassifier();    ClusterClassifier classifierOut = writeAndRead(classifier);    assertEquals(classifier.getModels().size(), classifierOut.getModels().size());    assertEquals(classifier.getModels().get(0).getClass().getName(), classifierOut.getModels().get(0).getClass().getName());}
public void mahout_f4923_0() throws Exception
{    ClusterClassifier classifier = newSoftClusterClassifier();    ClusterClassifier classifierOut = writeAndRead(classifier);    assertEquals(classifier.getModels().size(), classifierOut.getModels().size());    assertEquals(classifier.getModels().get(0).getClass().getName(), classifierOut.getModels().get(0).getClass().getName());}
public void mahout_f4924_0()
{    List<Vector> data = TestKmeansClustering.getPoints(TestKmeansClustering.REFERENCE);    ClusterClassifier prior = newKlusterClassifier();    ClusterClassifier posterior = ClusterIterator.iterate(data, prior, 5);    assertEquals(3, posterior.getModels().size());    for (Cluster cluster : posterior.getModels()) {        System.out.println(cluster.asFormatString(null));    }}
public void mahout_f4925_0()
{    List<Vector> data = TestKmeansClustering.getPoints(TestKmeansClustering.REFERENCE);    ClusterClassifier prior = newKlusterClassifier();    ClusterClassifier posterior = ClusterIterator.iterate(data, prior, 5);    assertEquals(3, posterior.getModels().size());    for (Cluster cluster : posterior.getModels()) {        System.out.println(cluster.asFormatString(null));    }}
public void mahout_f4926_0() throws IOException
{    Path pointsPath = getTestTempDirPath("points");    Path priorPath = getTestTempDirPath("prior");    Path outPath = getTestTempDirPath("output");    Configuration conf = getConfiguration();    FileSystem fs = FileSystem.get(pointsPath.toUri(), conf);    List<VectorWritable> points = TestKmeansClustering.getPointsWritable(TestKmeansClustering.REFERENCE);    ClusteringTestUtils.writePointsToFile(points, new Path(pointsPath, "file1"), fs, conf);    Path path = new Path(priorPath, "priorClassifier");    ClusterClassifier prior = newKlusterClassifier();    prior.writeToSeqFiles(path);    assertEquals(3, prior.getModels().size());    System.out.println("Prior");    for (Cluster cluster : prior.getModels()) {        System.out.println(cluster.asFormatString(null));    }    ClusterIterator.iterateSeq(conf, pointsPath, path, outPath, 5);    for (int i = 1; i <= 4; i++) {        System.out.println("Classifier-" + i);        ClusterClassifier posterior = new ClusterClassifier();        String name = i == 4 ? "clusters-4-final" : "clusters-" + i;        posterior.readFromSeqFiles(conf, new Path(outPath, name));        assertEquals(3, posterior.getModels().size());        for (Cluster cluster : posterior.getModels()) {            System.out.println(cluster.asFormatString(null));        }    }}
public void mahout_f4927_0() throws Exception
{    Path pointsPath = getTestTempDirPath("points");    Path priorPath = getTestTempDirPath("prior");    Path outPath = getTestTempDirPath("output");    Configuration conf = getConfiguration();    FileSystem fs = FileSystem.get(pointsPath.toUri(), conf);    List<VectorWritable> points = TestKmeansClustering.getPointsWritable(TestKmeansClustering.REFERENCE);    ClusteringTestUtils.writePointsToFile(points, new Path(pointsPath, "file1"), fs, conf);    Path path = new Path(priorPath, "priorClassifier");    ClusterClassifier prior = newKlusterClassifier();    prior.writeToSeqFiles(path);    ClusteringPolicy policy = new KMeansClusteringPolicy();    ClusterClassifier.writePolicy(policy, path);    assertEquals(3, prior.getModels().size());    System.out.println("Prior");    for (Cluster cluster : prior.getModels()) {        System.out.println(cluster.asFormatString(null));    }    ClusterIterator.iterateMR(conf, pointsPath, path, outPath, 5);    for (int i = 1; i <= 4; i++) {        System.out.println("Classifier-" + i);        ClusterClassifier posterior = new ClusterClassifier();        String name = i == 4 ? "clusters-4-final" : "clusters-" + i;        posterior.readFromSeqFiles(conf, new Path(outPath, name));        assertEquals(3, posterior.getModels().size());        for (Cluster cluster : posterior.getModels()) {            System.out.println(cluster.asFormatString(null));        }    }}
public void mahout_f4928_0()
{    ClusterClassifier classifier = newCosineKlusterClassifier();    Vector pdf = classifier.classify(new DenseVector(2));    assertEquals("[0,0]", "[0.333,0.333,0.333]", AbstractCluster.formatVector(pdf, null));    pdf = classifier.classify(new DenseVector(2).assign(2));    assertEquals("[2,2]", "[0.429,0.429,0.143]", AbstractCluster.formatVector(pdf, null));}
public void mahout_f4929_0() throws Exception
{    super.setUp();    Configuration conf = getConfiguration();    fs = FileSystem.get(conf);}
public static List<VectorWritable> mahout_f4930_0(double[][] raw)
{    List<VectorWritable> points = Lists.newArrayList();    for (double[] fr : raw) {        Vector vec = new RandomAccessSparseVector(fr.length);        vec.assign(fr);        points.add(new VectorWritable(vec));    }    return points;}
public static List<VectorWritable> mahout_f4931_0(double[][] raw)
{    List<VectorWritable> points = Lists.newArrayList();    for (double[] fr : raw) {        Vector vec = new DenseVector(fr.length);        vec.assign(fr);        points.add(new VectorWritable(vec));    }    return points;}
public static List<Vector> mahout_f4932_0(double[][] raw)
{    List<Vector> points = Lists.newArrayList();    for (double[] fr : raw) {        Vector vec = new SequentialAccessSparseVector(fr.length);        vec.assign(fr);        points.add(vec);    }    return points;}
public void mahout_f4933_0() throws Exception
{    DistanceMeasure measure = new EuclideanDistanceMeasure();    List<VectorWritable> points = getPointsWritable(REFERENCE);    Path pointsPath = getTestTempDirPath("points");    Path clustersPath = getTestTempDirPath("clusters");    Configuration conf = getConfiguration();    ClusteringTestUtils.writePointsToFile(points, true, new Path(pointsPath, "file1"), fs, conf);    ClusteringTestUtils.writePointsToFile(points, true, new Path(pointsPath, "file2"), fs, conf);    for (int k = 1; k < points.size(); k++) {        System.out.println("testKMeansMRJob k= " + k);                Path path = new Path(clustersPath, "part-00000");        FileSystem fs = FileSystem.get(path.toUri(), conf);        SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, path, Text.class, Kluster.class);        try {            for (int i = 0; i < k + 1; i++) {                Vector vec = points.get(i).get();                Kluster cluster = new Kluster(vec, i, measure);                                cluster.observe(cluster.getCenter(), 1);                writer.append(new Text(cluster.getIdentifier()), cluster);            }        } finally {            Closeables.close(writer, false);        }                Path outputPath = getTestTempDirPath("output" + k);        String[] args = { optKey(DefaultOptionCreator.INPUT_OPTION), pointsPath.toString(), optKey(DefaultOptionCreator.CLUSTERS_IN_OPTION), clustersPath.toString(), optKey(DefaultOptionCreator.OUTPUT_OPTION), outputPath.toString(), optKey(DefaultOptionCreator.DISTANCE_MEASURE_OPTION), EuclideanDistanceMeasure.class.getName(), optKey(DefaultOptionCreator.CONVERGENCE_DELTA_OPTION), "0.001", optKey(DefaultOptionCreator.MAX_ITERATIONS_OPTION), "2", optKey(DefaultOptionCreator.CLUSTERING_OPTION), optKey(DefaultOptionCreator.OVERWRITE_OPTION), optKey(DefaultOptionCreator.METHOD_OPTION), DefaultOptionCreator.SEQUENTIAL_METHOD };        ToolRunner.run(conf, new KMeansDriver(), args);                Path clusteredPointsPath = new Path(outputPath, "clusteredPoints");        int[] expect = EXPECTED_NUM_POINTS[k];        DummyOutputCollector<IntWritable, WeightedPropertyVectorWritable> collector = new DummyOutputCollector<>();                for (Pair<IntWritable, WeightedPropertyVectorWritable> record : new SequenceFileIterable<IntWritable, WeightedPropertyVectorWritable>(new Path(clusteredPointsPath, "part-m-0"), conf)) {            collector.collect(record.getFirst(), record.getSecond());        }        assertEquals("clusters[" + k + ']', expect.length, collector.getKeys().size());    }}
public void mahout_f4934_0() throws Exception
{    DistanceMeasure measure = new EuclideanDistanceMeasure();    List<VectorWritable> points = getPointsWritableDenseVector(REFERENCE);    Path pointsPath = getTestTempDirPath("points");    Path clustersPath = getTestTempDirPath("clusters");    Configuration conf = getConfiguration();    ClusteringTestUtils.writePointsToFile(points, true, new Path(pointsPath, "file1"), fs, conf);    ClusteringTestUtils.writePointsToFile(points, true, new Path(pointsPath, "file2"), fs, conf);    for (int k = 1; k < points.size(); k++) {        System.out.println("testKMeansMRJob k= " + k);                Path path = new Path(clustersPath, "part-00000");        FileSystem fs = FileSystem.get(path.toUri(), conf);        SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, path, Text.class, Kluster.class);        try {            for (int i = 0; i < k + 1; i++) {                Vector vec = points.get(i).get();                Kluster cluster = new Kluster(vec, i, measure);                                cluster.observe(cluster.getCenter(), 1);                writer.append(new Text(cluster.getIdentifier()), cluster);            }        } finally {            Closeables.close(writer, false);        }                Path outputPath = getTestTempDirPath("output" + k);        String[] args = { optKey(DefaultOptionCreator.INPUT_OPTION), pointsPath.toString(), optKey(DefaultOptionCreator.CLUSTERS_IN_OPTION), clustersPath.toString(), optKey(DefaultOptionCreator.OUTPUT_OPTION), outputPath.toString(), optKey(DefaultOptionCreator.DISTANCE_MEASURE_OPTION), EuclideanDistanceMeasure.class.getName(), optKey(DefaultOptionCreator.CONVERGENCE_DELTA_OPTION), "0.001", optKey(DefaultOptionCreator.MAX_ITERATIONS_OPTION), "2", optKey(DefaultOptionCreator.CLUSTERING_OPTION), optKey(DefaultOptionCreator.OVERWRITE_OPTION), optKey(DefaultOptionCreator.METHOD_OPTION), DefaultOptionCreator.SEQUENTIAL_METHOD };        ToolRunner.run(conf, new KMeansDriver(), args);                Path clusteredPointsPath = new Path(outputPath, "clusteredPoints");        int[] expect = EXPECTED_NUM_POINTS[k];        DummyOutputCollector<IntWritable, WeightedPropertyVectorWritable> collector = new DummyOutputCollector<>();                for (Pair<IntWritable, WeightedPropertyVectorWritable> record : new SequenceFileIterable<IntWritable, WeightedPropertyVectorWritable>(new Path(clusteredPointsPath, "part-m-0"), conf)) {            collector.collect(record.getFirst(), record.getSecond());        }        assertEquals("clusters[" + k + ']', expect.length, collector.getKeys().size());    }}
public void mahout_f4935_0() throws Exception
{    DistanceMeasure measure = new EuclideanDistanceMeasure();    List<VectorWritable> points = getPointsWritable(REFERENCE);    Path pointsPath = getTestTempDirPath("points");    Path clustersPath = getTestTempDirPath("clusters");    Configuration conf = getConfiguration();    ClusteringTestUtils.writePointsToFile(points, true, new Path(pointsPath, "file1"), fs, conf);    ClusteringTestUtils.writePointsToFile(points, true, new Path(pointsPath, "file2"), fs, conf);    for (int k = 1; k < points.size(); k += 3) {        System.out.println("testKMeansMRJob k= " + k);                Path path = new Path(clustersPath, "part-00000");        FileSystem fs = FileSystem.get(path.toUri(), conf);        SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, path, Text.class, Kluster.class);        try {            for (int i = 0; i < k + 1; i++) {                Vector vec = points.get(i).get();                Kluster cluster = new Kluster(vec, i, measure);                                cluster.observe(cluster.getCenter(), 1);                writer.append(new Text(cluster.getIdentifier()), cluster);            }        } finally {            Closeables.close(writer, false);        }                Path outputPath = getTestTempDirPath("output" + k);        String[] args = { optKey(DefaultOptionCreator.INPUT_OPTION), pointsPath.toString(), optKey(DefaultOptionCreator.CLUSTERS_IN_OPTION), clustersPath.toString(), optKey(DefaultOptionCreator.OUTPUT_OPTION), outputPath.toString(), optKey(DefaultOptionCreator.DISTANCE_MEASURE_OPTION), EuclideanDistanceMeasure.class.getName(), optKey(DefaultOptionCreator.CONVERGENCE_DELTA_OPTION), "0.001", optKey(DefaultOptionCreator.MAX_ITERATIONS_OPTION), "2", optKey(DefaultOptionCreator.CLUSTERING_OPTION), optKey(DefaultOptionCreator.OVERWRITE_OPTION) };        ToolRunner.run(getConfiguration(), new KMeansDriver(), args);                Path clusteredPointsPath = new Path(outputPath, "clusteredPoints");                int[] expect = EXPECTED_NUM_POINTS[k];        DummyOutputCollector<IntWritable, WeightedPropertyVectorWritable> collector = new DummyOutputCollector<>();                for (Pair<IntWritable, WeightedPropertyVectorWritable> record : new SequenceFileIterable<IntWritable, WeightedPropertyVectorWritable>(new Path(clusteredPointsPath, "part-m-00000"), conf)) {            collector.collect(record.getFirst(), record.getSecond());        }        assertEquals("clusters[" + k + ']', expect.length, collector.getKeys().size());    }}
public void mahout_f4936_0() throws Exception
{    List<VectorWritable> points = getPointsWritable(REFERENCE);    Path pointsPath = getTestTempDirPath("points");    Configuration conf = getConfiguration();    ClusteringTestUtils.writePointsToFile(points, true, new Path(pointsPath, "file1"), fs, conf);    ClusteringTestUtils.writePointsToFile(points, true, new Path(pointsPath, "file2"), fs, conf);    Path outputPath = getTestTempDirPath("output");        CanopyDriver.run(conf, pointsPath, outputPath, new ManhattanDistanceMeasure(), 3.1, 2.1, false, 0.0, false);    DummyOutputCollector<Text, ClusterWritable> collector1 = new DummyOutputCollector<>();    FileStatus[] outParts = FileSystem.get(conf).globStatus(new Path(outputPath, "clusters-0-final/*-0*"));    for (FileStatus outPartStat : outParts) {        for (Pair<Text, ClusterWritable> record : new SequenceFileIterable<Text, ClusterWritable>(outPartStat.getPath(), conf)) {            collector1.collect(record.getFirst(), record.getSecond());        }    }    boolean got15 = false;    boolean got43 = false;    int count = 0;    for (Text k : collector1.getKeys()) {        count++;        List<ClusterWritable> vl = collector1.getValue(k);        assertEquals("non-singleton centroid!", 1, vl.size());        ClusterWritable clusterWritable = vl.get(0);        Vector v = clusterWritable.getValue().getCenter();        assertEquals("cetriod vector is wrong length", 2, v.size());        if ((Math.abs(v.get(0) - 1.5) < EPSILON) && (Math.abs(v.get(1) - 1.5) < EPSILON) && !got15) {            got15 = true;        } else if ((Math.abs(v.get(0) - 4.333333333333334) < EPSILON) && (Math.abs(v.get(1) - 4.333333333333334) < EPSILON) && !got43) {            got43 = true;        } else {            fail("got unexpected center: " + v + " [" + v.getClass().toString() + ']');        }    }    assertEquals("got unexpected number of centers", 2, count);        Path kmeansOutput = new Path(outputPath, "kmeans");    KMeansDriver.run(getConfiguration(), pointsPath, new Path(outputPath, "clusters-0-final"), kmeansOutput, 0.001, 10, true, 0.0, false);        Path clusteredPointsPath = new Path(kmeansOutput, "clusteredPoints");    DummyOutputCollector<IntWritable, WeightedPropertyVectorWritable> collector = new DummyOutputCollector<>();        for (Pair<IntWritable, WeightedPropertyVectorWritable> record : new SequenceFileIterable<IntWritable, WeightedPropertyVectorWritable>(new Path(clusteredPointsPath, "part-m-00000"), conf)) {        collector.collect(record.getFirst(), record.getSecond());    }    for (IntWritable k : collector.getKeys()) {        List<WeightedPropertyVectorWritable> wpvList = collector.getValue(k);        assertTrue("empty cluster!", !wpvList.isEmpty());        if (wpvList.get(0).getVector().get(0) <= 2.0) {            for (WeightedPropertyVectorWritable wv : wpvList) {                Vector v = wv.getVector();                int idx = v.maxValueIndex();                assertTrue("bad cluster!", v.get(idx) <= 2.0);            }            assertEquals("Wrong size cluster", 4, wpvList.size());        } else {            for (WeightedPropertyVectorWritable wv : wpvList) {                Vector v = wv.getVector();                int idx = v.minValueIndex();                assertTrue("bad cluster!", v.get(idx) > 2.0);            }            assertEquals("Wrong size cluster", 5, wpvList.size());        }    }}
private static List<VectorWritable> mahout_f4937_0()
{    List<VectorWritable> points = Lists.newArrayList();    for (double[] fr : RAW) {        Vector vec = new RandomAccessSparseVector(fr.length);        vec.assign(fr);        points.add(new VectorWritable(vec));    }    return points;}
public void mahout_f4938_0() throws Exception
{    super.setUp();    Configuration conf = getConfiguration();    fs = FileSystem.get(conf);}
public void mahout_f4939_0() throws Exception
{    List<VectorWritable> points = getPoints();    Job job = new Job();    Configuration conf = job.getConfiguration();    job.setMapOutputValueClass(VectorWritable.class);    Path input = getTestTempFilePath("random-input");    Path output = getTestTempDirPath("random-output");    ClusteringTestUtils.writePointsToFile(points, input, fs, conf);    RandomSeedGenerator.buildRandom(conf, input, output, 4, new ManhattanDistanceMeasure());    int clusterCount = 0;    Collection<Integer> set = Sets.newHashSet();    for (ClusterWritable clusterWritable : new SequenceFileValueIterable<ClusterWritable>(new Path(output, "part-randomSeed"), true, conf)) {        clusterCount++;        Cluster cluster = clusterWritable.getValue();        int id = cluster.getId();                assertTrue(set.add(id));        Vector v = cluster.getCenter();                assertVectorEquals(RAW[id], v);    }        assertEquals(4, clusterCount);}
public void mahout_f4940_0() throws Exception
{    List<VectorWritable> points = getPoints();    Job job = new Job();    Configuration conf = job.getConfiguration();    job.setMapOutputValueClass(VectorWritable.class);    Path input = getTestTempFilePath("random-input");    Path output = getTestTempDirPath("random-output");    ClusteringTestUtils.writePointsToFile(points, input, fs, conf);    RandomSeedGenerator.buildRandom(conf, input, output, 4, new ManhattanDistanceMeasure(), 1L);    int clusterCount = 0;    Collection<Integer> set = Sets.newHashSet();    for (ClusterWritable clusterWritable : new SequenceFileValueIterable<ClusterWritable>(new Path(output, "part-randomSeed"), true, conf)) {        clusterCount++;        Cluster cluster = clusterWritable.getValue();        int id = cluster.getId();                assertTrue(set.add(id));        Vector v = cluster.getCenter();                assertVectorEquals(RAW[id], v);    }        assertEquals(4, clusterCount);}
public void mahout_f4941_0() throws Exception
{    List<VectorWritable> points = getPoints();    Job job = new Job();    Configuration conf = job.getConfiguration();    job.setMapOutputValueClass(VectorWritable.class);    Path input = getTestTempFilePath("random-input");    Path output = getTestTempDirPath("random-output");    ClusteringTestUtils.writePointsToFile(points, input, fs, conf);    long randSeed = 1;    RandomSeedGenerator.buildRandom(conf, input, output, 4, new ManhattanDistanceMeasure(), randSeed);    int[] clusterIDSeq = new int[4];    /**     * run through all clusters once and set sequence of IDs     */    int clusterCount = 0;    for (ClusterWritable clusterWritable : new SequenceFileValueIterable<ClusterWritable>(new Path(output, "part-randomSeed"), true, conf)) {        Cluster cluster = clusterWritable.getValue();        clusterIDSeq[clusterCount] = cluster.getId();        clusterCount++;    }    /* Rebuild cluster and run through again making sure all IDs are in the same random sequence     * Needs a better test because in this case passes when seeded with 1 and 2  fails with 1, 3     * passes when set to two */    RandomSeedGenerator.buildRandom(conf, input, output, 4, new ManhattanDistanceMeasure(), randSeed);    clusterCount = 0;    for (ClusterWritable clusterWritable : new SequenceFileValueIterable<ClusterWritable>(new Path(output, "part-randomSeed"), true, conf)) {        Cluster cluster = clusterWritable.getValue();                assertEquals(clusterIDSeq[clusterCount], cluster.getId());        clusterCount++;    }}
private static void mahout_f4942_0(double[] raw, Vector v)
{    assertEquals(raw.length, v.size());    for (int i = 0; i < raw.length; i++) {        assertEquals(raw[i], v.getQuick(i), EPSILON);    }}
public void mahout_f4943_0() throws Exception
{    String[] terms = new String[26];    for (int i = 0; i < terms.length; i++) {        terms[i] = String.valueOf((char) (i + 'a'));    }    int numGeneratingTopics = 3;    int numTerms = 26;    Matrix matrix = ClusteringTestUtils.randomStructuredModel(numGeneratingTopics, numTerms, new DoubleFunction() {        @Override        public double apply(double d) {            return 1.0 / Math.pow(d + 1.0, 2);        }    });    int numDocs = 100;    int numSamples = 20;    int numTopicsPerDoc = 1;    Matrix sampledCorpus = ClusteringTestUtils.sampledCorpus(matrix, RandomUtils.getRandom(), numDocs, numSamples, numTopicsPerDoc);    List<Double> perplexities = Lists.newArrayList();    int numTrials = 1;    for (int numTestTopics = 1; numTestTopics < 2 * numGeneratingTopics; numTestTopics++) {        double[] perps = new double[numTrials];        for (int trial = 0; trial < numTrials; trial++) {            InMemoryCollapsedVariationalBayes0 cvb = new InMemoryCollapsedVariationalBayes0(sampledCorpus, terms, numTestTopics, ALPHA, ETA, 2, 1, 0);            cvb.setVerbose(true);            perps[trial] = cvb.iterateUntilConvergence(0, 5, 0, 0.2);            System.out.println(perps[trial]);        }        Arrays.sort(perps);        System.out.println(Arrays.toString(perps));        perplexities.add(perps[0]);    }    System.out.println(Joiner.on(",").join(perplexities));}
public double mahout_f4944_0(double d)
{    return 1.0 / Math.pow(d + 1.0, 2);}
public void mahout_f4945_0() throws Exception
{    int numGeneratingTopics = 3;    int numTerms = 9;    Matrix matrix = ClusteringTestUtils.randomStructuredModel(numGeneratingTopics, numTerms, new DoubleFunction() {        @Override        public double apply(double d) {            return 1.0 / Math.pow(d + 1.0, 3);        }    });    int numDocs = 500;    int numSamples = 10;    int numTopicsPerDoc = 1;    Matrix sampledCorpus = ClusteringTestUtils.sampledCorpus(matrix, RandomUtils.getRandom(1234), numDocs, numSamples, numTopicsPerDoc);    Path sampleCorpusPath = getTestTempDirPath("corpus");    Configuration configuration = getConfiguration();    MatrixUtils.write(sampleCorpusPath, configuration, sampledCorpus);    int numIterations = 5;    List<Double> perplexities = Lists.newArrayList();    int startTopic = numGeneratingTopics - 1;    int numTestTopics = startTopic;    while (numTestTopics < numGeneratingTopics + 2) {        Path topicModelStateTempPath = getTestTempDirPath("topicTemp" + numTestTopics);        Configuration conf = getConfiguration();        CVB0Driver cvb0Driver = new CVB0Driver();        cvb0Driver.run(conf, sampleCorpusPath, null, numTestTopics, numTerms, ALPHA, ETA, numIterations, 1, 0, null, null, topicModelStateTempPath, 1234, 0.2f, 2, 1, 3, 1, false);        perplexities.add(lowestPerplexity(conf, topicModelStateTempPath));        numTestTopics++;    }    int bestTopic = -1;    double lowestPerplexity = Double.MAX_VALUE;    for (int t = 0; t < perplexities.size(); t++) {        if (perplexities.get(t) < lowestPerplexity) {            lowestPerplexity = perplexities.get(t);            bestTopic = t + startTopic;        }    }    assertEquals("The optimal number of topics is not that of the generating distribution", 4, bestTopic);    System.out.println("Perplexities: " + Joiner.on(", ").join(perplexities));}
public double mahout_f4946_0(double d)
{    return 1.0 / Math.pow(d + 1.0, 3);}
private static double mahout_f4947_0(Configuration conf, Path topicModelTemp) throws IOException
{    double lowest = Double.MAX_VALUE;    double current;    int iteration = 2;    while (!Double.isNaN(current = CVB0Driver.readPerplexity(conf, topicModelTemp, iteration))) {        lowest = Math.min(current, lowest);        iteration++;    }    return lowest;}
private static List<VectorWritable> mahout_f4948_0()
{    List<VectorWritable> points = Lists.newArrayList();    for (double[] fr : RAW) {        Vector vec = new RandomAccessSparseVector(fr.length);        vec.assign(fr);        points.add(new VectorWritable(vec));    }    return points;}
public void mahout_f4949_0() throws Exception
{    super.setUp();    Configuration conf = getConfiguration();    fs = FileSystem.get(conf);}
public void mahout_f4950_0() throws Exception
{    List<VectorWritable> points = getPoints();    Job job = new Job();    Configuration conf = job.getConfiguration();    job.setMapOutputValueClass(VectorWritable.class);    Path input = getTestTempFilePath("eigen-input");    Path output = getTestTempDirPath("eigen-output");    ClusteringTestUtils.writePointsToFile(points, input, fs, conf);    EigenSeedGenerator.buildFromEigens(conf, input, output, 3, new ManhattanDistanceMeasure());    int clusterCount = 0;    Collection<Integer> set = new HashSet<>();    Vector[] v = new Vector[3];    for (ClusterWritable clusterWritable : new SequenceFileValueIterable<ClusterWritable>(new Path(output, "part-eigenSeed"), true, conf)) {        Cluster cluster = clusterWritable.getValue();        int id = cluster.getId();                assertTrue(set.add(id));        v[id] = cluster.getCenter();        clusterCount++;    }        assertEquals(3, clusterCount);        assertEquals(0, v[0].dot(v[1]), 1E-10);    assertEquals(0, v[1].dot(v[2]), 1E-10);    assertEquals(0, v[0].dot(v[2]), 1E-10);}
public void mahout_f4951_0() throws Exception
{    AffinityMatrixInputMapper mapper = new AffinityMatrixInputMapper();    Configuration conf = getConfiguration();    conf.setInt(Keys.AFFINITY_DIMENSIONS, RAW_DIMENSIONS);        DummyRecordWriter<IntWritable, MatrixEntryWritable> writer = new DummyRecordWriter<>();    Mapper<LongWritable, Text, IntWritable, MatrixEntryWritable>.Context context = DummyRecordWriter.build(mapper, conf, writer);        for (String s : RAW) {        mapper.map(new LongWritable(), new Text(s), context);    }        assertEquals("Number of map results", RAW_DIMENSIONS, writer.getData().size());    Set<IntWritable> keys = writer.getData().keySet();    for (IntWritable i : keys) {        List<MatrixEntryWritable> row = writer.getData().get(i);        assertEquals("Number of items in row", RAW_DIMENSIONS, row.size());    }}
public void mahout_f4952_0() throws Exception
{    AffinityMatrixInputMapper mapper = new AffinityMatrixInputMapper();    Configuration conf = getConfiguration();    conf.setInt(Keys.AFFINITY_DIMENSIONS, RAW_DIMENSIONS);        DummyRecordWriter<IntWritable, MatrixEntryWritable> mapWriter = new DummyRecordWriter<>();    Mapper<LongWritable, Text, IntWritable, MatrixEntryWritable>.Context mapContext = DummyRecordWriter.build(mapper, conf, mapWriter);        for (String s : RAW) {        mapper.map(new LongWritable(), new Text(s), mapContext);    }        Map<IntWritable, List<MatrixEntryWritable>> map = mapWriter.getData();        AffinityMatrixInputReducer reducer = new AffinityMatrixInputReducer();    DummyRecordWriter<IntWritable, VectorWritable> redWriter = new DummyRecordWriter<>();    Reducer<IntWritable, MatrixEntryWritable, IntWritable, VectorWritable>.Context redContext = DummyRecordWriter.build(reducer, conf, redWriter, IntWritable.class, MatrixEntryWritable.class);    for (IntWritable key : mapWriter.getKeys()) {        reducer.reduce(key, mapWriter.getValue(key), redContext);    }        assertEquals("Number of reduce results", RAW_DIMENSIONS, redWriter.getData().size());    for (IntWritable row : redWriter.getKeys()) {        List<VectorWritable> list = redWriter.getValue(row);        assertEquals("Should only be one vector", 1, list.size());                Vector v = list.get(0).get();        for (Vector.Element e : v.all()) {                        MatrixEntryWritable toCompare = new MatrixEntryWritable();            toCompare.setRow(-1);            toCompare.setCol(e.index());            toCompare.setVal(e.get());            assertTrue("This entry was correctly placed in its row", map.get(row).contains(toCompare));        }    }}
private static double mahout_f4953_0(double[] row)
{    double sum = 0;    for (double r : row) {        sum += r;    }    return sum;}
public void mahout_f4954_0() throws Exception
{    MatrixDiagonalizeMapper mapper = new MatrixDiagonalizeMapper();    Configuration conf = getConfiguration();    conf.setInt(Keys.AFFINITY_DIMENSIONS, RAW_DIMENSIONS);        DummyRecordWriter<NullWritable, IntDoublePairWritable> writer = new DummyRecordWriter<>();    Mapper<IntWritable, VectorWritable, NullWritable, IntDoublePairWritable>.Context context = DummyRecordWriter.build(mapper, conf, writer);        for (int i = 0; i < RAW_DIMENSIONS; i++) {        RandomAccessSparseVector toAdd = new RandomAccessSparseVector(RAW_DIMENSIONS);        toAdd.assign(RAW[i]);        mapper.map(new IntWritable(i), new VectorWritable(toAdd), context);    }        assertEquals("Number of map results", RAW_DIMENSIONS, writer.getValue(NullWritable.get()).size());}
public void mahout_f4955_0() throws Exception
{    MatrixDiagonalizeMapper mapper = new MatrixDiagonalizeMapper();    Configuration conf = getConfiguration();    conf.setInt(Keys.AFFINITY_DIMENSIONS, RAW_DIMENSIONS);        DummyRecordWriter<NullWritable, IntDoublePairWritable> mapWriter = new DummyRecordWriter<>();    Mapper<IntWritable, VectorWritable, NullWritable, IntDoublePairWritable>.Context mapContext = DummyRecordWriter.build(mapper, conf, mapWriter);        for (int i = 0; i < RAW_DIMENSIONS; i++) {        RandomAccessSparseVector toAdd = new RandomAccessSparseVector(RAW_DIMENSIONS);        toAdd.assign(RAW[i]);        mapper.map(new IntWritable(i), new VectorWritable(toAdd), mapContext);    }        MatrixDiagonalizeReducer reducer = new MatrixDiagonalizeReducer();    DummyRecordWriter<NullWritable, VectorWritable> redWriter = new DummyRecordWriter<>();    Reducer<NullWritable, IntDoublePairWritable, NullWritable, VectorWritable>.Context redContext = DummyRecordWriter.build(reducer, conf, redWriter, NullWritable.class, IntDoublePairWritable.class);        reducer.reduce(NullWritable.get(), mapWriter.getValue(NullWritable.get()), redContext);        List<VectorWritable> list = redWriter.getValue(NullWritable.get());    assertEquals("Only a single resulting vector", 1, list.size());    Vector v = list.get(0).get();    for (int i = 0; i < v.size(); i++) {        assertEquals("Element sum is correct", rowSum(RAW[i]), v.get(i), 0.01);    }}
public void mahout_f4956_0() throws Exception
{    UnitVectorizerMapper mapper = new UnitVectorizerMapper();    Configuration conf = getConfiguration();        DummyRecordWriter<IntWritable, VectorWritable> writer = new DummyRecordWriter<>();    Mapper<IntWritable, VectorWritable, IntWritable, VectorWritable>.Context context = DummyRecordWriter.build(mapper, conf, writer);        for (int i = 0; i < RAW.length; i++) {        Vector vector = new RandomAccessSparseVector(RAW[i].length);        vector.assign(RAW[i]);        mapper.map(new IntWritable(i), new VectorWritable(vector), context);    }        assertEquals("Number of map results", RAW.length, writer.getData().size());    for (int i = 0; i < RAW.length; i++) {        IntWritable key = new IntWritable(i);        List<VectorWritable> list = writer.getValue(key);        assertEquals("Only one element per row", 1, list.size());        Vector v = list.get(0).get();        assertTrue("Unit vector sum is 1 or differs by 0.0001", Math.abs(v.norm(2) - 1) < 0.000001);    }}
public void mahout_f4957_0() throws Exception
{    Configuration conf = getConfiguration();    Writable key = new IntWritable(0);    Vector value = new DenseVector(VECTOR);    Path path = getTestTempDirPath("output");        VectorCache.save(key, value, path, conf, true, true);        SequenceFileValueIterator<VectorWritable> iterator = new SequenceFileValueIterator<>(path, true, conf);    try {        VectorWritable old = iterator.next();                assertEquals("Saved vector is identical to original", old.get(), value);    } finally {        Closeables.close(iterator, true);    }}
public void mahout_f4958_0() throws Exception
{        Configuration conf = getConfiguration();    Writable key = new IntWritable(0);    Vector value = new DenseVector(VECTOR);    Path path = getTestTempDirPath("output");    FileSystem fs = FileSystem.get(path.toUri(), conf);        path = fs.makeQualified(path);    fs.deleteOnExit(path);    HadoopUtil.delete(conf, path);    SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, path, IntWritable.class, VectorWritable.class);    try {        writer.append(key, new VectorWritable(value));    } finally {        Closeables.close(writer, false);    }    DistributedCache.setCacheFiles(new URI[] { path.toUri() }, conf);        Vector result = VectorCache.load(conf);        assertNotNull("Vector is null", result);    assertEquals("Loaded vector is not identical to original", result, value);}
public void mahout_f4959_0() throws Exception
{    Configuration conf = getConfiguration();    Vector v = new DenseVector(VECTOR);    Path toSave = getTestTempDirPath("output");    Writable key = new IntWritable(0);        VectorCache.save(key, v, toSave, conf);        Vector v2 = VectorCache.load(conf);        assertNotNull("Vector is null", v2);    assertEquals("Vectors are not identical", v2, v);}
public void mahout_f4960_0() throws Exception
{    VectorMatrixMultiplicationMapper mapper = new VectorMatrixMultiplicationMapper();    Configuration conf = getConfiguration();        Vector toSave = new DenseVector(VECTOR);    DummyRecordWriter<IntWritable, VectorWritable> writer = new DummyRecordWriter<>();    Mapper<IntWritable, VectorWritable, IntWritable, VectorWritable>.Context context = DummyRecordWriter.build(mapper, conf, writer);    mapper.setup(toSave);        for (int i = 0; i < MATRIX.length; i++) {        Vector v = new RandomAccessSparseVector(MATRIX[i].length);        v.assign(MATRIX[i]);        mapper.map(new IntWritable(i), new VectorWritable(v), context);    }        assertEquals("Number of map results", MATRIX.length, writer.getData().size());    for (int i = 0; i < MATRIX.length; i++) {        List<VectorWritable> list = writer.getValue(new IntWritable(i));        assertEquals("Only one vector per key", 1, list.size());        Vector v = list.get(0).get();        for (int j = 0; j < MATRIX[i].length; j++) {            double total = Math.sqrt(VECTOR[i]) * Math.sqrt(VECTOR[j]) * MATRIX[i][j];            assertEquals("Product matrix elements", total, v.get(j), EPSILON);        }    }}
public static void mahout_f4961_0()
{    RandomUtils.useTestSeed();    syntheticData = DataUtils.sampleMultiNormalHypercube(NUM_DIMENSIONS, NUM_DATA_POINTS, DISTRIBUTION_RADIUS);}
public void mahout_f4962_0()
{    for (int i = 1; i <= 10; ++i) {        BallKMeans clusterer = new BallKMeans(new BruteSearch(new SquaredEuclideanDistanceMeasure()), 1 << NUM_DIMENSIONS, NUM_ITERATIONS, true, i);        clusterer.cluster(syntheticData.getFirst());        double costKMeansPlusPlus = ClusteringUtils.totalClusterCost(syntheticData.getFirst(), clusterer);        clusterer = new BallKMeans(new BruteSearch(new SquaredEuclideanDistanceMeasure()), 1 << NUM_DIMENSIONS, NUM_ITERATIONS, false, i);        clusterer.cluster(syntheticData.getFirst());        double costKMeansRandom = ClusteringUtils.totalClusterCost(syntheticData.getFirst(), clusterer);        System.out.printf("%d runs; kmeans++: %f; random: %f\n", i, costKMeansPlusPlus, costKMeansRandom);        assertTrue("kmeans++ cost should be less than random cost", costKMeansPlusPlus < costKMeansRandom);    }}
public void mahout_f4963_0()
{    UpdatableSearcher searcher = new BruteSearch(new SquaredEuclideanDistanceMeasure());    BallKMeans clusterer = new BallKMeans(searcher, 1 << NUM_DIMENSIONS, NUM_ITERATIONS);    long startTime = System.currentTimeMillis();    Pair<List<Centroid>, List<Centroid>> data = syntheticData;    clusterer.cluster(data.getFirst());    long endTime = System.currentTimeMillis();    long hash = 0;    for (Centroid centroid : data.getFirst()) {        for (Vector.Element element : centroid.all()) {            hash = 31 * hash + 17 * element.index() + Double.toHexString(element.get()).hashCode();        }    }    System.out.printf("Hash = %08x\n", hash);    assertEquals("Total weight not preserved", totalWeight(syntheticData.getFirst()), totalWeight(clusterer), 1.0e-9);            OnlineSummarizer summarizer = new OnlineSummarizer();    for (Vector mean : syntheticData.getSecond()) {        WeightedThing<Vector> v = searcher.search(mean, 1).get(0);        summarizer.add(v.getWeight());    }    assertTrue(String.format("Median weight [%f] too large [>%f]", summarizer.getMedian(), DISTRIBUTION_RADIUS), summarizer.getMedian() < DISTRIBUTION_RADIUS);    double clusterTime = (endTime - startTime) / 1000.0;    System.out.printf("%s\n%.2f for clustering\n%.1f us per row\n\n", searcher.getClass().getName(), clusterTime, clusterTime / syntheticData.getFirst().size() * 1.0e6);        double[] cornerWeights = new double[1 << NUM_DIMENSIONS];    Searcher trueFinder = new BruteSearch(new EuclideanDistanceMeasure());    for (Vector trueCluster : syntheticData.getSecond()) {        trueFinder.add(trueCluster);    }    for (Centroid centroid : clusterer) {        WeightedThing<Vector> closest = trueFinder.search(centroid, 1).get(0);        cornerWeights[((Centroid) closest.getValue()).getIndex()] += centroid.getWeight();    }    int expectedNumPoints = NUM_DATA_POINTS / (1 << NUM_DIMENSIONS);    for (double v : cornerWeights) {        System.out.printf("%f ", v);    }    System.out.println();    for (double v : cornerWeights) {        assertEquals(expectedNumPoints, v, 0);    }}
public void mahout_f4964_0()
{        List<? extends WeightedVector> data = cubishTestData(0.01);        BallKMeans r = new BallKMeans(new BruteSearch(new SquaredEuclideanDistanceMeasure()), 6, 20);    r.cluster(data);        Matrix x = new DenseMatrix(6, 5);    int row = 0;    for (Centroid c : r) {        x.viewRow(row).assign(c.viewPart(0, 5));        row++;    }        final Vector columnNorms = x.aggregateColumns(new VectorFunction() {        @Override        public double apply(Vector f) {                        return Math.abs(f.minValue()) + Math.abs(f.maxValue() - 6) + Math.abs(f.norm(1) - 6);        }    });        assertEquals(0, columnNorms.norm(1) / columnNorms.size(), 0.1);        SingularValueDecomposition svd = new SingularValueDecomposition(x);    Vector s = svd.getS().viewDiagonal().assign(Functions.div(6));    assertEquals(5, s.getLengthSquared(), 0.05);    assertEquals(5, s.norm(1), 0.05);}
public double mahout_f4965_0(Vector f)
{        return Math.abs(f.minValue()) + Math.abs(f.maxValue() - 6) + Math.abs(f.norm(1) - 6);}
private static List<? extends WeightedVector> mahout_f4966_0(double radius)
{    List<WeightedVector> data = Lists.newArrayListWithCapacity(K1 + 5000);    int row = 0;    MultiNormal g = new MultiNormal(radius, new ConstantVector(0, 10));    for (int i = 0; i < K1; i++) {        data.add(new WeightedVector(g.sample(), 1, row++));    }    for (int i = 0; i < 5; i++) {        Vector m = new DenseVector(10);                m.set(i, 6);        MultiNormal gx = new MultiNormal(radius, m);        for (int j = 0; j < 1000; j++) {            data.add(new WeightedVector(gx.sample(), 1, row++));        }    }    return data;}
public static Pair<List<Centroid>, List<Centroid>> mahout_f4967_0(int numDimensions, int numDatapoints, double distributionRadius)
{    int pow2N = 1 << numDimensions;                List<Centroid> mean = Lists.newArrayListWithCapacity(pow2N);    List<MultiNormal> rowSamplers = Lists.newArrayList();    for (int i = 0; i < pow2N; i++) {        Vector v = new DenseVector(numDimensions);                int pow2J = 1 << (numDimensions - 1);        for (int j = 0; j < numDimensions; ++j) {            v.set(j, 1.0 / pow2J * (i & pow2J));            pow2J >>= 1;        }        mean.add(new Centroid(i, v, 1));        rowSamplers.add(new MultiNormal(distributionRadius, v));    }        List<Centroid> data = Lists.newArrayListWithCapacity(numDatapoints);    for (int i = 0; i < numDatapoints; ++i) {        data.add(new Centroid(i, rowSamplers.get(i % pow2N).sample(), 1));    }    return new Pair<>(data, mean);}
public static Pair<List<Centroid>, List<Centroid>> mahout_f4968_0(int numDimensions, int numDatapoints)
{    return sampleMultiNormalHypercube(numDimensions, numDatapoints, 0.01);}
public void mahout_f4969_0()
{    RandomUtils.useTestSeed();    syntheticData = DataUtils.sampleMultiNormalHypercube(NUM_DIMENSIONS, NUM_DATA_POINTS);}
public static List<Object[]> mahout_f4970_0()
{    return Arrays.asList(new Object[][] { { new ProjectionSearch(new SquaredEuclideanDistanceMeasure(), NUM_PROJECTIONS, SEARCH_SIZE), true }, { new FastProjectionSearch(new SquaredEuclideanDistanceMeasure(), NUM_PROJECTIONS, SEARCH_SIZE), true }, { new ProjectionSearch(new SquaredEuclideanDistanceMeasure(), NUM_PROJECTIONS, SEARCH_SIZE), false }, { new FastProjectionSearch(new SquaredEuclideanDistanceMeasure(), NUM_PROJECTIONS, SEARCH_SIZE), false } });}
public void mahout_f4971_0()
{    double avgDistanceCutoff = 0;    double avgNumClusters = 0;    int numTests = 1;    System.out.printf("Distance cutoff for %s\n", searcher.getClass().getName());    for (int i = 0; i < numTests; ++i) {        searcher.clear();        int numStreamingClusters = (int) Math.log(syntheticData.getFirst().size()) * (1 << NUM_DIMENSIONS);        double distanceCutoff = 1.0e-6;        double estimatedCutoff = ClusteringUtils.estimateDistanceCutoff(syntheticData.getFirst(), searcher.getDistanceMeasure(), 100);        System.out.printf("[%d] Generated synthetic data [magic] %f [estimate] %f\n", i, distanceCutoff, estimatedCutoff);        StreamingKMeans clusterer = new StreamingKMeans(searcher, numStreamingClusters, estimatedCutoff);        clusterer.cluster(syntheticData.getFirst());        avgDistanceCutoff += clusterer.getDistanceCutoff();        avgNumClusters += clusterer.getNumClusters();        System.out.printf("[%d] %f\n", i, clusterer.getDistanceCutoff());    }    avgDistanceCutoff /= numTests;    avgNumClusters /= numTests;    System.out.printf("Final: distanceCutoff: %f estNumClusters: %f\n", avgDistanceCutoff, avgNumClusters);}
public void mahout_f4972_0()
{    searcher.clear();    int numStreamingClusters = (int) Math.log(syntheticData.getFirst().size()) * (1 << NUM_DIMENSIONS);    System.out.printf("k log n = %d\n", numStreamingClusters);    double estimatedCutoff = ClusteringUtils.estimateDistanceCutoff(syntheticData.getFirst(), searcher.getDistanceMeasure(), 100);    StreamingKMeans clusterer = new StreamingKMeans(searcher, numStreamingClusters, estimatedCutoff);    long startTime = System.currentTimeMillis();    if (allAtOnce) {        clusterer.cluster(syntheticData.getFirst());    } else {        for (Centroid datapoint : syntheticData.getFirst()) {            clusterer.cluster(datapoint);        }    }    long endTime = System.currentTimeMillis();    System.out.printf("%s %s\n", searcher.getClass().getName(), searcher.getDistanceMeasure().getClass().getName());    System.out.printf("Total number of clusters %d\n", clusterer.getNumClusters());    System.out.printf("Weights: %f %f\n", ClusteringUtils.totalWeight(syntheticData.getFirst()), ClusteringUtils.totalWeight(clusterer));    assertEquals("Total weight not preserved", ClusteringUtils.totalWeight(syntheticData.getFirst()), ClusteringUtils.totalWeight(clusterer), 1.0e-9);        double maxWeight = 0;    for (Vector mean : syntheticData.getSecond()) {        WeightedThing<Vector> v = searcher.search(mean, 1).get(0);        maxWeight = Math.max(v.getWeight(), maxWeight);    }    assertTrue("Maximum weight too large " + maxWeight, maxWeight < 0.05);    double clusterTime = (endTime - startTime) / 1000.0;    System.out.printf("%s\n%.2f for clustering\n%.1f us per row\n\n", searcher.getClass().getName(), clusterTime, clusterTime / syntheticData.getFirst().size() * 1.0e6);        double[] cornerWeights = new double[1 << NUM_DIMENSIONS];    Searcher trueFinder = new BruteSearch(new EuclideanDistanceMeasure());    for (Vector trueCluster : syntheticData.getSecond()) {        trueFinder.add(trueCluster);    }    for (Centroid centroid : clusterer) {        WeightedThing<Vector> closest = trueFinder.search(centroid, 1).get(0);        cornerWeights[((Centroid) closest.getValue()).getIndex()] += centroid.getWeight();    }    int expectedNumPoints = NUM_DATA_POINTS / (1 << NUM_DIMENSIONS);    for (double v : cornerWeights) {        System.out.printf("%f ", v);    }    System.out.println();    for (double v : cornerWeights) {        assertEquals(expectedNumPoints, v, 0);    }}
public void mahout_f4973_0()
{    RandomUtils.useTestSeed();    syntheticData = DataUtils.sampleMultiNormalHypercube(NUM_DIMENSIONS, NUM_DATA_POINTS, 1.0e-4);}
private void mahout_f4974_0(Configuration configuration)
{    configuration.set(DefaultOptionCreator.DISTANCE_MEASURE_OPTION, distanceMeasureClassName);    configuration.setInt(StreamingKMeansDriver.SEARCH_SIZE_OPTION, SEARCH_SIZE);    configuration.setInt(StreamingKMeansDriver.NUM_PROJECTIONS_OPTION, NUM_PROJECTIONS);    configuration.set(StreamingKMeansDriver.SEARCHER_CLASS_OPTION, searcherClassName);    configuration.setInt(DefaultOptionCreator.NUM_CLUSTERS_OPTION, 1 << NUM_DIMENSIONS);    configuration.setInt(StreamingKMeansDriver.ESTIMATED_NUM_MAP_CLUSTERS, (1 << NUM_DIMENSIONS) * (int) Math.log(NUM_DATA_POINTS));    configuration.setFloat(StreamingKMeansDriver.ESTIMATED_DISTANCE_CUTOFF, (float) DISTANCE_CUTOFF);    configuration.setInt(StreamingKMeansDriver.MAX_NUM_ITERATIONS, MAX_NUM_ITERATIONS);        configuration.setBoolean(StreamingKMeansDriver.REDUCE_STREAMING_KMEANS, true);}
public static List<Object[]> mahout_f4975_0()
{    return Arrays.asList(new Object[][] { { ProjectionSearch.class.getName(), SquaredEuclideanDistanceMeasure.class.getName() }, { FastProjectionSearch.class.getName(), SquaredEuclideanDistanceMeasure.class.getName() }, { LocalitySensitiveHashSearch.class.getName(), SquaredEuclideanDistanceMeasure.class.getName() } });}
public void mahout_f4976_0() throws IOException
{    MapDriver<Writable, VectorWritable, IntWritable, CentroidWritable> mapDriver = MapDriver.newMapDriver(new StreamingKMeansMapper());    configure(mapDriver.getConfiguration());    System.out.printf("%s mapper test\n", mapDriver.getConfiguration().get(StreamingKMeansDriver.SEARCHER_CLASS_OPTION));    for (Centroid datapoint : syntheticData.getFirst()) {        mapDriver.addInput(new IntWritable(0), new VectorWritable(datapoint));    }    List<org.apache.hadoop.mrunit.types.Pair<IntWritable, CentroidWritable>> results = mapDriver.run();    BruteSearch resultSearcher = new BruteSearch(new SquaredEuclideanDistanceMeasure());    for (org.apache.hadoop.mrunit.types.Pair<IntWritable, CentroidWritable> result : results) {        resultSearcher.add(result.getSecond().getCentroid());    }    System.out.printf("Clustered the data into %d clusters\n", results.size());    for (Vector mean : syntheticData.getSecond()) {        WeightedThing<Vector> closest = resultSearcher.search(mean, 1).get(0);        assertTrue("Weight " + closest.getWeight() + " not less than 0.5", closest.getWeight() < 0.5);    }}
public void mahout_f4977_0() throws IOException
{        MapDriver<Writable, VectorWritable, IntWritable, CentroidWritable> mapDriver = MapDriver.newMapDriver(new StreamingKMeansMapper());    Configuration configuration = mapDriver.getConfiguration();    configure(configuration);    System.out.printf("%s mapper vs local test\n", mapDriver.getConfiguration().get(StreamingKMeansDriver.SEARCHER_CLASS_OPTION));    for (Centroid datapoint : syntheticData.getFirst()) {        mapDriver.addInput(new IntWritable(0), new VectorWritable(datapoint));    }    List<Centroid> mapperCentroids = Lists.newArrayList();    for (org.apache.hadoop.mrunit.types.Pair<IntWritable, CentroidWritable> pair : mapDriver.run()) {        mapperCentroids.add(pair.getSecond().getCentroid());    }        StreamingKMeans batchClusterer = new StreamingKMeans(StreamingKMeansUtilsMR.searcherFromConfiguration(configuration), mapDriver.getConfiguration().getInt("estimatedNumMapClusters", -1), DISTANCE_CUTOFF);    batchClusterer.cluster(syntheticData.getFirst());    List<Centroid> batchCentroids = Lists.newArrayList();    for (Vector v : batchClusterer) {        batchCentroids.add((Centroid) v);    }        StreamingKMeans perPointClusterer = new StreamingKMeans(StreamingKMeansUtilsMR.searcherFromConfiguration(configuration), (1 << NUM_DIMENSIONS) * (int) Math.log(NUM_DATA_POINTS), DISTANCE_CUTOFF);    for (Centroid datapoint : syntheticData.getFirst()) {        perPointClusterer.cluster(datapoint);    }    List<Centroid> perPointCentroids = Lists.newArrayList();    for (Vector v : perPointClusterer) {        perPointCentroids.add((Centroid) v);    }        double mapperCost = ClusteringUtils.totalClusterCost(syntheticData.getFirst(), mapperCentroids);    double localCost = ClusteringUtils.totalClusterCost(syntheticData.getFirst(), batchCentroids);    double perPointCost = ClusteringUtils.totalClusterCost(syntheticData.getFirst(), perPointCentroids);    System.out.printf("[Total cost] Mapper %f [%d] Local %f [%d] Perpoint local %f [%d];" + "[ratio m-vs-l %f] [ratio pp-vs-l %f]\n", mapperCost, mapperCentroids.size(), localCost, batchCentroids.size(), perPointCost, perPointCentroids.size(), mapperCost / localCost, perPointCost / localCost);            assertEquals("Mapper StreamingKMeans / Batch local StreamingKMeans total cost ratio too far from 1", 1.0, mapperCost / localCost, 0.8);    assertEquals("One by one local StreamingKMeans / Batch local StreamingKMeans total cost ratio too high", 1.0, perPointCost / localCost, 0.8);}
public void mahout_f4978_0() throws IOException
{    ReduceDriver<IntWritable, CentroidWritable, IntWritable, CentroidWritable> reduceDriver = ReduceDriver.newReduceDriver(new StreamingKMeansReducer());    Configuration configuration = reduceDriver.getConfiguration();    configure(configuration);    System.out.printf("%s reducer test\n", configuration.get(StreamingKMeansDriver.SEARCHER_CLASS_OPTION));    StreamingKMeans clusterer = new StreamingKMeans(StreamingKMeansUtilsMR.searcherFromConfiguration(configuration), (1 << NUM_DIMENSIONS) * (int) Math.log(NUM_DATA_POINTS), DISTANCE_CUTOFF);    long start = System.currentTimeMillis();    clusterer.cluster(syntheticData.getFirst());    long end = System.currentTimeMillis();    System.out.printf("%f [s]\n", (end - start) / 1000.0);    List<CentroidWritable> reducerInputs = Lists.newArrayList();    int postMapperTotalWeight = 0;    for (Centroid intermediateCentroid : clusterer) {        reducerInputs.add(new CentroidWritable(intermediateCentroid));        postMapperTotalWeight += intermediateCentroid.getWeight();    }    reduceDriver.addInput(new IntWritable(0), reducerInputs);    List<org.apache.hadoop.mrunit.types.Pair<IntWritable, CentroidWritable>> results = reduceDriver.run();    testReducerResults(postMapperTotalWeight, results);}
public void mahout_f4979_0() throws IOException
{    MapReduceDriver<Writable, VectorWritable, IntWritable, CentroidWritable, IntWritable, CentroidWritable> mapReduceDriver = new MapReduceDriver<>(new StreamingKMeansMapper(), new StreamingKMeansReducer());    Configuration configuration = mapReduceDriver.getConfiguration();    configure(configuration);    System.out.printf("%s full test\n", configuration.get(StreamingKMeansDriver.SEARCHER_CLASS_OPTION));    for (Centroid datapoint : syntheticData.getFirst()) {        mapReduceDriver.addInput(new IntWritable(0), new VectorWritable(datapoint));    }    List<org.apache.hadoop.mrunit.types.Pair<IntWritable, CentroidWritable>> results = mapReduceDriver.run();    testReducerResults(syntheticData.getFirst().size(), results);}
public void mahout_f4980_0() throws Exception
{    Configuration configuration = getConfiguration();    configure(configuration);    configuration.set(DefaultOptionCreator.METHOD_OPTION, DefaultOptionCreator.SEQUENTIAL_METHOD);    Path inputPath = new Path("testInput");    Path outputPath = new Path("testOutput");    StreamingKMeansUtilsMR.writeVectorsToSequenceFile(syntheticData.getFirst(), inputPath, configuration);    StreamingKMeansDriver.run(configuration, inputPath, outputPath);    testReducerResults(syntheticData.getFirst().size(), Lists.newArrayList(Iterables.transform(new SequenceFileIterable<IntWritable, CentroidWritable>(outputPath, configuration), new Function<Pair<IntWritable, CentroidWritable>, org.apache.hadoop.mrunit.types.Pair<IntWritable, CentroidWritable>>() {        @Override        public org.apache.hadoop.mrunit.types.Pair<IntWritable, CentroidWritable> apply(org.apache.mahout.common.Pair<IntWritable, CentroidWritable> input) {            return new org.apache.hadoop.mrunit.types.Pair<>(input.getFirst(), input.getSecond());        }    })));}
public org.apache.hadoop.mrunit.types.Pair<IntWritable, CentroidWritable> mahout_f4981_0(org.apache.mahout.common.Pair<IntWritable, CentroidWritable> input)
{    return new org.apache.hadoop.mrunit.types.Pair<>(input.getFirst(), input.getSecond());}
private static void mahout_f4982_0(int totalWeight, List<org.apache.hadoop.mrunit.types.Pair<IntWritable, CentroidWritable>> results)
{    int expectedNumClusters = 1 << NUM_DIMENSIONS;    double expectedWeight = (double) totalWeight / expectedNumClusters;    int numClusters = 0;    int numUnbalancedClusters = 0;    int totalReducerWeight = 0;    for (org.apache.hadoop.mrunit.types.Pair<IntWritable, CentroidWritable> result : results) {        if (result.getSecond().getCentroid().getWeight() != expectedWeight) {            System.out.printf("Unbalanced weight %f in centroid %d\n", result.getSecond().getCentroid().getWeight(), result.getSecond().getCentroid().getIndex());            ++numUnbalancedClusters;        }        assertEquals("Final centroid index is invalid", numClusters, result.getFirst().get());        totalReducerWeight += result.getSecond().getCentroid().getWeight();        ++numClusters;    }    System.out.printf("%d clusters are unbalanced\n", numUnbalancedClusters);    assertEquals("Invalid total weight", totalWeight, totalReducerWeight);    assertEquals("Invalid number of clusters", 1 << NUM_DIMENSIONS, numClusters);}
public void mahout_f4983_0() throws Exception
{    Path inputFile = new Path(getTestTempDirPath("input"), "test.seq");    Path output = getTestTempDirPath("output");    Configuration conf = new Configuration();    LocalFileSystem fs = FileSystem.getLocal(conf);    SequenceFile.Writer writer = null;    try {        writer = SequenceFile.createWriter(fs, conf, inputFile, IntWritable.class, IntWritable.class);        writer.append(new IntWritable(1), new IntWritable(1));        writer.append(new IntWritable(2), new IntWritable(2));        writer.append(new IntWritable(3), new IntWritable(3));        writer.append(new IntWritable(4), new IntWritable(4));        writer.append(new IntWritable(5), new IntWritable(5));        writer.append(new IntWritable(6), new IntWritable(6));        writer.append(new IntWritable(7), new IntWritable(7));        writer.append(new IntWritable(8), new IntWritable(8));    } finally {        Closeables.close(writer, false);    }    String splitPattern = "split";    int numSplits = 4;    ResplitSequenceFiles.main(new String[] { "--input", inputFile.toString(), "--output", output.toString() + "/" + splitPattern, "--numSplits", String.valueOf(numSplits) });    FileStatus[] statuses = HadoopUtil.getFileStatus(output, PathType.LIST, PathFilters.logsCRCFilter(), null, conf);    for (FileStatus status : statuses) {        String name = status.getPath().getName();        assertTrue(name.startsWith(splitPattern));        assertEquals(2, numEntries(status, conf));    }    assertEquals(numSplits, statuses.length);}
private int mahout_f4984_0(FileStatus status, Configuration conf)
{    return Iterables.size(new SequenceFileIterable(status.getPath(), conf));}
public void mahout_f4985_0()
{    double[] d = { 1.1, 2.2, 3.3 };    Vector m = new DenseVector(d);    Cluster cluster = new org.apache.mahout.clustering.kmeans.Kluster(m, 123, measure);    String formatString = cluster.asFormatString(null);    assertTrue(formatString.contains("\"r\":[]"));    assertTrue(formatString.contains("\"c\":[1.1,2.2,3.3]"));    assertTrue(formatString.contains("\"n\":0"));    assertTrue(formatString.contains("\"identifier\":\"CL-123\""));}
public void mahout_f4986_0()
{    double[] d = { 1.1, 0.0, 3.3 };    Vector m = new SequentialAccessSparseVector(3);    m.assign(d);    Cluster cluster = new org.apache.mahout.clustering.kmeans.Kluster(m, 123, measure);    String formatString = cluster.asFormatString(null);    assertTrue(formatString.contains("\"r\":[]"));    assertTrue(formatString.contains("\"c\":[{\"0\":1.1},{\"2\":3.3}]"));    assertTrue(formatString.contains("\"n\":0"));    assertTrue(formatString.contains("\"identifier\":\"CL-123\""));}
public void mahout_f4987_0()
{    double[] d = { 1.1, 2.2, 3.3 };    Vector m = new DenseVector(d);    Cluster cluster = new org.apache.mahout.clustering.kmeans.Kluster(m, 123, measure);    String[] bindings = { "fee", null, "foo" };    String formatString = cluster.asFormatString(bindings);    assertTrue(formatString.contains("\"r\":[]"));    assertTrue(formatString.contains("\"c\":[{\"fee\":1.1},{\"1\":2.2},{\"foo\":3.3}]"));    assertTrue(formatString.contains("\"n\":0"));    assertTrue(formatString.contains("\"identifier\":\"CL-123\""));}
public void mahout_f4988_0()
{    double[] d = { 1.1, 0.0, 3.3 };    Vector m = new SequentialAccessSparseVector(3);    m.assign(d);    Cluster cluster = new org.apache.mahout.clustering.kmeans.Kluster(m, 123, measure);    String formatString = cluster.asFormatString(null);    assertTrue(formatString.contains("\"r\":[]"));    assertTrue(formatString.contains("\"c\":[{\"0\":1.1},{\"2\":3.3}]"));    assertTrue(formatString.contains("\"n\":0"));    assertTrue(formatString.contains("\"identifier\":\"CL-123\""));}
public void mahout_f4989_1() throws Exception
{    super.setUp();    sampleData = Lists.newArrayList();    generateSamples();    sampleN = 0;    Vector sum = new DenseVector(2);    for (VectorWritable v : sampleData) {        sum.assign(v.get(), Functions.PLUS);        sampleN++;    }    sampleMean = sum.divide(sampleN);    Vector sampleVar = new DenseVector(2);    for (VectorWritable v : sampleData) {        Vector delta = v.get().minus(sampleMean);        sampleVar.assign(delta.times(delta), Functions.PLUS);    }    sampleVar = sampleVar.divide(sampleN - 1);    sampleStd = sampleVar.clone();    sampleStd.assign(new SquareRootFunction());    }
private void mahout_f4990_1(int num, double mx, double my, double sdx, double sdy)
{        for (int i = 0; i < num; i++) {        sampleData.add(new VectorWritable(new DenseVector(new double[] { UncommonDistributions.rNorm(mx, sdx), UncommonDistributions.rNorm(my, sdy) })));    }}
private void mahout_f4991_0()
{    generate2dSamples(50000, 1, 2, 3, 4);}
public void mahout_f4992_0()
{    GaussianAccumulator accumulator0 = new RunningSumsGaussianAccumulator();    GaussianAccumulator accumulator1 = new OnlineGaussianAccumulator();    accumulator0.compute();    accumulator1.compute();    assertEquals("N", accumulator0.getN(), accumulator1.getN(), EPSILON);    assertEquals("Means", accumulator0.getMean(), accumulator1.getMean());    assertEquals("Avg Stds", accumulator0.getAverageStd(), accumulator1.getAverageStd(), EPSILON);}
public void mahout_f4993_0()
{    GaussianAccumulator accumulator0 = new RunningSumsGaussianAccumulator();    GaussianAccumulator accumulator1 = new OnlineGaussianAccumulator();    Vector sample = new DenseVector(2);    accumulator0.observe(sample, 1.0);    accumulator1.observe(sample, 1.0);    accumulator0.compute();    accumulator1.compute();    assertEquals("N", accumulator0.getN(), accumulator1.getN(), EPSILON);    assertEquals("Means", accumulator0.getMean(), accumulator1.getMean());    assertEquals("Avg Stds", accumulator0.getAverageStd(), accumulator1.getAverageStd(), EPSILON);}
public void mahout_f4994_1()
{    GaussianAccumulator accumulator = new OnlineGaussianAccumulator();    for (VectorWritable vw : sampleData) {        accumulator.observe(vw.get(), 1.0);    }    accumulator.compute();        assertEquals("OL N", sampleN, accumulator.getN(), EPSILON);    assertEquals("OL Mean", sampleMean.zSum(), accumulator.getMean().zSum(), EPSILON);    assertEquals("OL Std", sampleStd.zSum(), accumulator.getStd().zSum(), EPSILON);}
public void mahout_f4995_1()
{    GaussianAccumulator accumulator = new RunningSumsGaussianAccumulator();    for (VectorWritable vw : sampleData) {        accumulator.observe(vw.get(), 1.0);    }    accumulator.compute();        assertEquals("OL N", sampleN, accumulator.getN(), EPSILON);    assertEquals("OL Mean", sampleMean.zSum(), accumulator.getMean().zSum(), EPSILON);    assertEquals("OL Std", sampleStd.zSum(), accumulator.getStd().zSum(), 0.0001);}
public void mahout_f4996_0()
{    GaussianAccumulator accumulator0 = new RunningSumsGaussianAccumulator();    GaussianAccumulator accumulator1 = new OnlineGaussianAccumulator();    for (VectorWritable vw : sampleData) {        accumulator0.observe(vw.get(), 0.5);        accumulator1.observe(vw.get(), 0.5);    }    accumulator0.compute();    accumulator1.compute();    assertEquals("N", accumulator0.getN(), accumulator1.getN(), EPSILON);    assertEquals("Means", accumulator0.getMean().zSum(), accumulator1.getMean().zSum(), EPSILON);    assertEquals("Stds", accumulator0.getStd().zSum(), accumulator1.getStd().zSum(), 0.001);    assertEquals("Variance", accumulator0.getVariance().zSum(), accumulator1.getVariance().zSum(), 0.01);}
public void mahout_f4997_0()
{    GaussianAccumulator accumulator0 = new RunningSumsGaussianAccumulator();    GaussianAccumulator accumulator1 = new OnlineGaussianAccumulator();    for (VectorWritable vw : sampleData) {        accumulator0.observe(vw.get(), 1.5);        accumulator1.observe(vw.get(), 1.5);    }    accumulator0.compute();    accumulator1.compute();    assertEquals("N", accumulator0.getN(), accumulator1.getN(), EPSILON);    assertEquals("Means", accumulator0.getMean().zSum(), accumulator1.getMean().zSum(), EPSILON);    assertEquals("Stds", accumulator0.getStd().zSum(), accumulator1.getStd().zSum(), 0.001);    assertEquals("Variance", accumulator0.getVariance().zSum(), accumulator1.getVariance().zSum(), 0.01);}
public void mahout_f4998_0()
{    Path expectedPath = new Path(output, PathDirectory.TOP_LEVEL_CLUSTER_DIRECTORY);    assertEquals(expectedPath, PathDirectory.getTopLevelClusterPath(output));}
public void mahout_f4999_0()
{    Path expectedPath = new Path(output, PathDirectory.POST_PROCESS_DIRECTORY);    assertEquals(expectedPath, PathDirectory.getClusterPostProcessorOutputDirectory(output));}
public void mahout_f5000_0()
{    Path expectedPath = new Path(output, PathDirectory.CLUSTERED_POINTS_DIRECTORY + File.separator + '*');    assertEquals(expectedPath, PathDirectory.getClusterOutputClusteredPoints(output));}
public void mahout_f5001_0()
{    Path expectedPath = new Path(output + File.separator + PathDirectory.BOTTOM_LEVEL_CLUSTER_DIRECTORY + File.separator + '1');    assertEquals(expectedPath, PathDirectory.getBottomLevelClusterPath(output, "1"));}
public void mahout_f5002_0()
{    Path expectedPath = new Path(PathDirectory.getClusterPostProcessorOutputDirectory(output), new Path("1"));    assertEquals(expectedPath, PathDirectory.getClusterPathForClusterId(PathDirectory.getClusterPostProcessorOutputDirectory(output), "1"));}
public void mahout_f5003_0() throws Exception
{    super.setUp();    Configuration conf = getConfiguration();    fs = FileSystem.get(conf);}
public static List<VectorWritable> mahout_f5004_0(double[][] raw)
{    List<VectorWritable> points = Lists.newArrayList();    for (double[] fr : raw) {        Vector vec = new RandomAccessSparseVector(fr.length);        vec.assign(fr);        points.add(new VectorWritable(vec));    }    return points;}
public void mahout_f5005_0() throws Exception
{    List<VectorWritable> points = getPointsWritable(REFERENCE);    Path pointsPath = getTestTempDirPath("points");    Configuration conf = getConfiguration();    ClusteringTestUtils.writePointsToFile(points, new Path(pointsPath, "file1"), fs, conf);    ClusteringTestUtils.writePointsToFile(points, new Path(pointsPath, "file2"), fs, conf);    outputPathForCanopy = getTestTempDirPath("canopy");    outputPathForKMeans = getTestTempDirPath("kmeans");    topLevelClustering(pointsPath, conf);    int numberOfClusters = ClusterCountReader.getNumberOfClusters(outputPathForKMeans, conf);    Assert.assertEquals(2, numberOfClusters);    verifyThatNumberOfClustersIsCorrect(conf, new Path(outputPathForKMeans, new Path("clusteredPoints")));}
private void mahout_f5006_0(Path pointsPath, Configuration conf) throws IOException, InterruptedException, ClassNotFoundException
{    DistanceMeasure measure = new ManhattanDistanceMeasure();    CanopyDriver.run(conf, pointsPath, outputPathForCanopy, measure, 4.0, 3.0, true, 0.0, true);    Path clustersIn = new Path(outputPathForCanopy, new Path(Cluster.CLUSTERS_DIR + '0' + Cluster.FINAL_ITERATION_SUFFIX));    KMeansDriver.run(conf, pointsPath, clustersIn, outputPathForKMeans, 1, 1, true, 0.0, true);}
private static void mahout_f5007_0(Configuration conf, Path clusteredPointsPath)
{    DummyOutputCollector<IntWritable, WeightedVectorWritable> collector = new DummyOutputCollector<>();        for (Pair<IntWritable, WeightedVectorWritable> record : new SequenceFileIterable<IntWritable, WeightedVectorWritable>(new Path(clusteredPointsPath, "part-m-0"), conf)) {        collector.collect(record.getFirst(), record.getSecond());    }    int clusterSize = collector.getKeys().size();    assertEquals(2, clusterSize);}
public void mahout_f5008_0() throws Exception
{    super.setUp();    Configuration conf = getConfiguration();    fs = FileSystem.get(conf);}
private static List<VectorWritable> mahout_f5009_0(double[][] raw)
{    List<VectorWritable> points = Lists.newArrayList();    for (double[] fr : raw) {        Vector vec = new RandomAccessSparseVector(fr.length);        vec.assign(fr);        points.add(new VectorWritable(vec));    }    return points;}
public void mahout_f5010_0() throws Exception
{    List<VectorWritable> points = getPointsWritable(REFERENCE);    Path pointsPath = getTestTempDirPath("points");    conf = getConfiguration();    ClusteringTestUtils.writePointsToFile(points, new Path(pointsPath, "file1"), fs, conf);    ClusteringTestUtils.writePointsToFile(points, new Path(pointsPath, "file2"), fs, conf);    outputPath = getTestTempDirPath("output");    topLevelClustering(pointsPath, conf);    Map<String, Path> postProcessedClusterDirectories = ouputPostProcessing(conf);    assertPostProcessedOutput(postProcessedClusterDirectories);    bottomLevelClustering(postProcessedClusterDirectories);}
private void mahout_f5011_0(Entry<String, Path> cluster)
{    String clusterId = cluster.getKey();    Path clusterPath = cluster.getValue();    try {        if ("0".equals(clusterId)) {            assertPointsInFirstTopLevelCluster(clusterPath);        } else if ("1".equals(clusterId)) {            assertPointsInSecondTopLevelCluster(clusterPath);        }    } catch (IOException e) {        Assert.fail("Exception occurred while asserting top level cluster.");    }}
private void mahout_f5012_0(Path clusterPath) throws IOException
{    List<Vector> vectorsInCluster = getVectorsInCluster(clusterPath);    for (Vector vector : vectorsInCluster) {        Assert.assertTrue(ArrayUtils.contains(new String[] { "{0:1.0,1:1.0}", "{0:2.0,1:1.0}", "{0:1.0,1:2.0}" }, vector.asFormatString()));    }}
private void mahout_f5013_0(Path clusterPath) throws IOException
{    List<Vector> vectorsInCluster = getVectorsInCluster(clusterPath);    for (Vector vector : vectorsInCluster) {        Assert.assertTrue(ArrayUtils.contains(new String[] { "{0:4.0,1:4.0}", "{0:5.0,1:4.0}", "{0:4.0,1:5.0}", "{0:5.0,1:5.0}" }, vector.asFormatString()));    }}
private List<Vector> mahout_f5014_0(Path clusterPath) throws IOException
{    Path[] partFilePaths = FileUtil.stat2Paths(fs.globStatus(clusterPath));    FileStatus[] listStatus = fs.listStatus(partFilePaths);    List<Vector> vectors = Lists.newArrayList();    for (FileStatus partFile : listStatus) {        SequenceFile.Reader topLevelClusterReader = new SequenceFile.Reader(fs, partFile.getPath(), conf);        Writable clusterIdAsKey = new LongWritable();        VectorWritable point = new VectorWritable();        while (topLevelClusterReader.next(clusterIdAsKey, point)) {            vectors.add(point.get());        }    }    return vectors;}
private void mahout_f5015_0(Map<String, Path> postProcessedClusterDirectories) throws IOException, InterruptedException, ClassNotFoundException
{    for (Entry<String, Path> topLevelCluster : postProcessedClusterDirectories.entrySet()) {        String clusterId = topLevelCluster.getKey();        Path topLevelclusterPath = topLevelCluster.getValue();        Path bottomLevelCluster = PathDirectory.getBottomLevelClusterPath(outputPath, clusterId);        CanopyDriver.run(conf, topLevelclusterPath, bottomLevelCluster, new ManhattanDistanceMeasure(), 2.1, 2.0, true, 0.0, true);        assertBottomLevelCluster(bottomLevelCluster);    }}
private void mahout_f5016_0(Path bottomLevelCluster)
{    Path clusteredPointsPath = new Path(bottomLevelCluster, "clusteredPoints");    DummyOutputCollector<IntWritable, WeightedVectorWritable> collector = new DummyOutputCollector<>();        for (Pair<IntWritable, WeightedVectorWritable> record : new SequenceFileIterable<IntWritable, WeightedVectorWritable>(new Path(clusteredPointsPath, "part-m-0"), conf)) {        collector.collect(record.getFirst(), record.getSecond());    }    int clusterSize = collector.getKeys().size();        assertTrue(clusterSize == 1 || clusterSize == 2);}
private void mahout_f5017_0(Map<String, Path> postProcessedClusterDirectories)
{    for (Entry<String, Path> cluster : postProcessedClusterDirectories.entrySet()) {        assertTopLevelCluster(cluster);    }}
private Map<String, Path> mahout_f5018_0(Configuration conf) throws IOException
{    ClusterOutputPostProcessor clusterOutputPostProcessor = new ClusterOutputPostProcessor(outputPath, outputPath, conf);    clusterOutputPostProcessor.process();    return clusterOutputPostProcessor.getPostProcessedClusterDirectories();}
private void mahout_f5019_0(Path pointsPath, Configuration conf) throws IOException, InterruptedException, ClassNotFoundException
{    CanopyDriver.run(conf, pointsPath, outputPath, new ManhattanDistanceMeasure(), 3.1, 2.1, true, 0.0, true);}
public void mahout_f5020_0() throws Exception
{    final Map<String, List<String>> testMap = Maps.newHashMap();    AbstractJobFactory fact = new AbstractJobFactory() {        @Override        public AbstractJob getJob() {            return new AbstractJob() {                @Override                public int run(String[] args) throws IOException {                    addFlag("testFlag", "t", "a simple test flag");                    Map<String, List<String>> argMap = parseArguments(args);                    testMap.clear();                    testMap.putAll(argMap);                    return 1;                }            };        }    };        ToolRunner.run(fact.getJob(), new String[0]);    assertFalse("test map for absent flag", testMap.containsKey("--testFlag"));    String[] withFlag = { "--testFlag" };    ToolRunner.run(fact.getJob(), withFlag);    assertTrue("test map for present flag", testMap.containsKey("--testFlag"));}
public AbstractJob mahout_f5021_0()
{    return new AbstractJob() {        @Override        public int run(String[] args) throws IOException {            addFlag("testFlag", "t", "a simple test flag");            Map<String, List<String>> argMap = parseArguments(args);            testMap.clear();            testMap.putAll(argMap);            return 1;        }    };}
public int mahout_f5022_0(String[] args) throws IOException
{    addFlag("testFlag", "t", "a simple test flag");    Map<String, List<String>> argMap = parseArguments(args);    testMap.clear();    testMap.putAll(argMap);    return 1;}
public void mahout_f5023_0() throws Exception
{    final Map<String, List<String>> testMap = Maps.newHashMap();    AbstractJobFactory fact = new AbstractJobFactory() {        @Override        public AbstractJob getJob() {            return new AbstractJob() {                @Override                public int run(String[] args) throws IOException {                    this.addOption(DefaultOptionCreator.overwriteOption().create());                    this.addOption("option", "o", "option");                    this.addOption("required", "r", "required", true);                    this.addOption("notRequired", "nr", "not required", false);                    this.addOption("hasDefault", "hd", "option w/ default", "defaultValue");                    Map<String, List<String>> argMap = parseArguments(args);                    if (argMap == null) {                        return -1;                    }                    testMap.clear();                    testMap.putAll(argMap);                    return 0;                }            };        }    };    int ret = ToolRunner.run(fact.getJob(), new String[0]);    assertEquals("-1 for missing required options", -1, ret);    ret = ToolRunner.run(fact.getJob(), new String[] { "--required", "requiredArg" });    assertEquals("0 for no missing required options", 0, ret);    assertEquals(Collections.singletonList("requiredArg"), testMap.get("--required"));    assertEquals(Collections.singletonList("defaultValue"), testMap.get("--hasDefault"));    assertNull(testMap.get("--option"));    assertNull(testMap.get("--notRequired"));    assertFalse(testMap.containsKey("--overwrite"));    ret = ToolRunner.run(fact.getJob(), new String[] { "--required", "requiredArg", "--unknownArg" });    assertEquals("-1 for including unknown options", -1, ret);    ret = ToolRunner.run(fact.getJob(), new String[] { "--required", "requiredArg", "--required", "requiredArg2" });    assertEquals("-1 for including duplicate options", -1, ret);    ret = ToolRunner.run(fact.getJob(), new String[] { "--required", "requiredArg", "--overwrite", "--hasDefault", "nonDefault", "--option", "optionValue", "--notRequired", "notRequired" });    assertEquals("0 for no missing required options", 0, ret);    assertEquals(Collections.singletonList("requiredArg"), testMap.get("--required"));    assertEquals(Collections.singletonList("nonDefault"), testMap.get("--hasDefault"));    assertEquals(Collections.singletonList("optionValue"), testMap.get("--option"));    assertEquals(Collections.singletonList("notRequired"), testMap.get("--notRequired"));    assertTrue(testMap.containsKey("--overwrite"));    ret = ToolRunner.run(fact.getJob(), new String[] { "-r", "requiredArg", "-ow", "-hd", "nonDefault", "-o", "optionValue", "-nr", "notRequired" });    assertEquals("0 for no missing required options", 0, ret);    assertEquals(Collections.singletonList("requiredArg"), testMap.get("--required"));    assertEquals(Collections.singletonList("nonDefault"), testMap.get("--hasDefault"));    assertEquals(Collections.singletonList("optionValue"), testMap.get("--option"));    assertEquals(Collections.singletonList("notRequired"), testMap.get("--notRequired"));    assertTrue(testMap.containsKey("--overwrite"));}
public AbstractJob mahout_f5024_0()
{    return new AbstractJob() {        @Override        public int run(String[] args) throws IOException {            this.addOption(DefaultOptionCreator.overwriteOption().create());            this.addOption("option", "o", "option");            this.addOption("required", "r", "required", true);            this.addOption("notRequired", "nr", "not required", false);            this.addOption("hasDefault", "hd", "option w/ default", "defaultValue");            Map<String, List<String>> argMap = parseArguments(args);            if (argMap == null) {                return -1;            }            testMap.clear();            testMap.putAll(argMap);            return 0;        }    };}
public int mahout_f5025_0(String[] args) throws IOException
{    this.addOption(DefaultOptionCreator.overwriteOption().create());    this.addOption("option", "o", "option");    this.addOption("required", "r", "required", true);    this.addOption("notRequired", "nr", "not required", false);    this.addOption("hasDefault", "hd", "option w/ default", "defaultValue");    Map<String, List<String>> argMap = parseArguments(args);    if (argMap == null) {        return -1;    }    testMap.clear();    testMap.putAll(argMap);    return 0;}
public void mahout_f5026_0() throws Exception
{    AbstractJobFactory fact = new AbstractJobFactory() {        @Override        public AbstractJob getJob() {            return new AbstractJob() {                @Override                public int run(String[] args) throws IOException {                    addInputOption();                    addOutputOption();                                        Map<String, List<String>> argMap = parseArguments(args);                    if (argMap == null) {                        return -1;                    }                    Path inputPath = getInputPath();                    assertNotNull("getInputPath() returns non-null", inputPath);                    Path outputPath = getInputPath();                    assertNotNull("getOutputPath() returns non-null", outputPath);                    return 0;                }            };        }    };    int ret = ToolRunner.run(fact.getJob(), new String[0]);    assertEquals("-1 for missing input option", -1, ret);    String testInputPath = "testInputPath";    AbstractJob job = fact.getJob();    ret = ToolRunner.run(job, new String[] { "--input", testInputPath });    assertEquals("-1 for missing output option", -1, ret);    assertEquals("input path is correct", testInputPath, job.getInputPath().toString());    job = fact.getJob();    String testOutputPath = "testOutputPath";    ret = ToolRunner.run(job, new String[] { "--output", testOutputPath });    assertEquals("-1 for missing input option", -1, ret);    assertEquals("output path is correct", testOutputPath, job.getOutputPath().toString());    job = fact.getJob();    ret = ToolRunner.run(job, new String[] { "--input", testInputPath, "--output", testOutputPath });    assertEquals("0 for complete options", 0, ret);    assertEquals("input path is correct", testInputPath, job.getInputPath().toString());    assertEquals("output path is correct", testOutputPath, job.getOutputPath().toString());    job = fact.getJob();    ret = ToolRunner.run(job, new String[] { "--input", testInputPath, "--output", testOutputPath });    assertEquals("0 for complete options", 0, ret);    assertEquals("input path is correct", testInputPath, job.getInputPath().toString());    assertEquals("output path is correct", testOutputPath, job.getOutputPath().toString());    job = fact.getJob();    String testInputPropertyPath = "testInputPropertyPath";    String testOutputPropertyPath = "testOutputPropertyPath";    ret = ToolRunner.run(job, new String[] { "-Dmapred.input.dir=" + testInputPropertyPath, "-Dmapred.output.dir=" + testOutputPropertyPath });    assertEquals("0 for complete options", 0, ret);    assertEquals("input path from property is correct", testInputPropertyPath, job.getInputPath().toString());    assertEquals("output path from property is correct", testOutputPropertyPath, job.getOutputPath().toString());    job = fact.getJob();    ret = ToolRunner.run(job, new String[] { "-Dmapred.input.dir=" + testInputPropertyPath, "-Dmapred.output.dir=" + testOutputPropertyPath, "--input", testInputPath, "--output", testOutputPath });    assertEquals("0 for complete options", 0, ret);    assertEquals("input command-line option precedes property", testInputPath, job.getInputPath().toString());    assertEquals("output command-line option precedes property", testOutputPath, job.getOutputPath().toString());}
public AbstractJob mahout_f5027_0()
{    return new AbstractJob() {        @Override        public int run(String[] args) throws IOException {            addInputOption();            addOutputOption();                        Map<String, List<String>> argMap = parseArguments(args);            if (argMap == null) {                return -1;            }            Path inputPath = getInputPath();            assertNotNull("getInputPath() returns non-null", inputPath);            Path outputPath = getInputPath();            assertNotNull("getOutputPath() returns non-null", outputPath);            return 0;        }    };}
public int mahout_f5028_0(String[] args) throws IOException
{    addInputOption();    addOutputOption();        Map<String, List<String>> argMap = parseArguments(args);    if (argMap == null) {        return -1;    }    Path inputPath = getInputPath();    assertNotNull("getInputPath() returns non-null", inputPath);    Path outputPath = getInputPath();    assertNotNull("getOutputPath() returns non-null", outputPath);    return 0;}
public void mahout_f5029_0()
{    DistanceMeasure distanceMeasure = new CosineDistanceMeasure();    Vector[] vectors = { new DenseVector(new double[] { 1, 0, 0, 0, 0, 0 }), new DenseVector(new double[] { 1, 1, 1, 0, 0, 0 }), new DenseVector(new double[] { 1, 1, 1, 1, 1, 1 }) };    double[][] distanceMatrix = new double[3][3];    for (int a = 0; a < 3; a++) {        for (int b = 0; b < 3; b++) {            distanceMatrix[a][b] = distanceMeasure.distance(vectors[a], vectors[b]);        }    }    assertEquals(0.0, distanceMatrix[0][0], EPSILON);    assertTrue(distanceMatrix[0][0] < distanceMatrix[0][1]);    assertTrue(distanceMatrix[0][1] < distanceMatrix[0][2]);    assertEquals(0.0, distanceMatrix[1][1], EPSILON);    assertTrue(distanceMatrix[1][0] > distanceMatrix[1][1]);    assertTrue(distanceMatrix[1][2] < distanceMatrix[1][0]);    assertEquals(0.0, distanceMatrix[2][2], EPSILON);    assertTrue(distanceMatrix[2][0] > distanceMatrix[2][1]);    assertTrue(distanceMatrix[2][1] > distanceMatrix[2][2]);        assertEquals(0, distanceMeasure.distance(new SequentialAccessSparseVector(1), new SequentialAccessSparseVector(1)), EPSILON);}
public void mahout_f5030_0()
{    DistanceMeasure distanceMeasure = distanceMeasureFactory();    Vector[] vectors = { new DenseVector(new double[] { 1, 1, 1, 1, 1, 1 }), new DenseVector(new double[] { 2, 2, 2, 2, 2, 2 }), new DenseVector(new double[] { 6, 6, 6, 6, 6, 6 }), new DenseVector(new double[] { -1, -1, -1, -1, -1, -1 }) };    compare(distanceMeasure, vectors);    vectors = new Vector[4];    vectors[0] = new RandomAccessSparseVector(5);    vectors[0].setQuick(0, 1);    vectors[0].setQuick(3, 1);    vectors[0].setQuick(4, 1);    vectors[1] = new RandomAccessSparseVector(5);    vectors[1].setQuick(0, 2);    vectors[1].setQuick(3, 2);    vectors[1].setQuick(4, 2);    vectors[2] = new RandomAccessSparseVector(5);    vectors[2].setQuick(0, 6);    vectors[2].setQuick(3, 6);    vectors[2].setQuick(4, 6);    vectors[3] = new RandomAccessSparseVector(5);    compare(distanceMeasure, vectors);}
private static void mahout_f5031_0(DistanceMeasure distanceMeasure, Vector[] vectors)
{    double[][] distanceMatrix = new double[4][4];    for (int a = 0; a < 4; a++) {        for (int b = 0; b < 4; b++) {            distanceMatrix[a][b] = distanceMeasure.distance(vectors[a], vectors[b]);        }    }    assertEquals("Distance from first vector to itself is not zero", 0.0, distanceMatrix[0][0], EPSILON);    assertTrue(distanceMatrix[0][0] < distanceMatrix[0][1]);    assertTrue(distanceMatrix[0][1] < distanceMatrix[0][2]);    assertEquals("Distance from second vector to itself is not zero", 0.0, distanceMatrix[1][1], EPSILON);    assertTrue(distanceMatrix[1][0] > distanceMatrix[1][1]);    assertTrue(distanceMatrix[1][2] > distanceMatrix[1][0]);    assertEquals("Distance from third vector to itself is not zero", 0.0, distanceMatrix[2][2], EPSILON);    assertTrue(distanceMatrix[2][0] > distanceMatrix[2][1]);    assertTrue(distanceMatrix[2][1] > distanceMatrix[2][2]);    for (int a = 0; a < 4; a++) {        for (int b = 0; b < 4; b++) {            assertTrue("Distance between vectors less than zero: " + distanceMatrix[a][b] + " = " + distanceMeasure + ".distance(" + vectors[a].asFormatString() + ", " + vectors[b].asFormatString() + ')', distanceMatrix[a][b] >= 0);            if (vectors[a].plus(vectors[b]).norm(2) == 0 && vectors[a].norm(2) > 0) {                assertTrue("Distance from v to -v is equal to zero" + vectors[a].asFormatString() + " = -" + vectors[b].asFormatString(), distanceMatrix[a][b] > 0);            }        }    }}
public void mahout_f5032_0()
{    WeightedDistanceMeasure distanceMeasure = distanceMeasureFactory();    Vector[] vectors = { new DenseVector(new double[] { 9, 9, 1 }), new DenseVector(new double[] { 1, 9, 9 }), new DenseVector(new double[] { 9, 1, 9 }) };    distanceMeasure.setWeights(new DenseVector(new double[] { 1, 1000, 1 }));    double[][] distanceMatrix = new double[3][3];    for (int a = 0; a < 3; a++) {        for (int b = 0; b < 3; b++) {            distanceMatrix[a][b] = distanceMeasure.distance(vectors[a], vectors[b]);        }    }    assertEquals(0.0, distanceMatrix[0][0], EPSILON);    assertTrue(distanceMatrix[0][1] < distanceMatrix[0][2]);}
public void mahout_f5033_0()
{    DistanceMeasure chebyshevDistanceMeasure = new ChebyshevDistanceMeasure();    Vector[] vectors = { new DenseVector(new double[] { 1, 0, 0, 0, 0, 0 }), new DenseVector(new double[] { 1, 1, 1, 0, 0, 0 }), new DenseVector(new double[] { 1, 1, 1, 1, 1, 1 }) };    double[][] distances = { { 0.0, 1.0, 1.0 }, { 1.0, 0.0, 1.0 }, { 1.0, 1.0, 0.0 } };    double[][] chebyshevDistanceMatrix = new double[3][3];    for (int a = 0; a < 3; a++) {        for (int b = 0; b < 3; b++) {            chebyshevDistanceMatrix[a][b] = chebyshevDistanceMeasure.distance(vectors[a], vectors[b]);        }    }    for (int a = 0; a < 3; a++) {        for (int b = 0; b < 3; b++) {            assertEquals(distances[a][b], chebyshevDistanceMatrix[a][b], EPSILON);        }    }    assertEquals(0.0, chebyshevDistanceMatrix[0][0], EPSILON);}
public DistanceMeasure mahout_f5034_0()
{    return new EuclideanDistanceMeasure();}
public void mahout_f5035_0()
{    double[][] invCovValues = { { 2.2, 0.4 }, { 0.4, 2.8 } };    double[] meanValues = { -2.3, -0.9 };    Matrix invCov = new DenseMatrix(invCovValues);    Vector meanVector = new DenseVector(meanValues);    MahalanobisDistanceMeasure distanceMeasure = new MahalanobisDistanceMeasure();    distanceMeasure.setInverseCovarianceMatrix(invCov);    distanceMeasure.setMeanVector(meanVector);    double[] v1 = { -1.9, -2.3 };    double[] v2 = { -2.9, -1.3 };    double dist = distanceMeasure.distance(new DenseVector(v1), new DenseVector(v2));    assertEquals(2.0493901531919194, dist, EPSILON);        distanceMeasure.setCovarianceMatrix(invCov);        Matrix identity = distanceMeasure.getInverseCovarianceMatrix().times(invCov);    assertEquals(1, identity.get(0, 0), EPSILON);    assertEquals(1, identity.get(1, 1), EPSILON);    assertEquals(0, identity.get(1, 0), EPSILON);    assertEquals(0, identity.get(0, 1), EPSILON);}
public DistanceMeasure mahout_f5036_0()
{    return new ManhattanDistanceMeasure();}
public void mahout_f5037_0()
{    DistanceMeasure minkowskiDistanceMeasure = new MinkowskiDistanceMeasure(1.5);    DistanceMeasure manhattanDistanceMeasure = new ManhattanDistanceMeasure();    DistanceMeasure euclideanDistanceMeasure = new EuclideanDistanceMeasure();    Vector[] vectors = { new DenseVector(new double[] { 1, 0, 0, 0, 0, 0 }), new DenseVector(new double[] { 1, 1, 1, 0, 0, 0 }), new DenseVector(new double[] { 1, 1, 1, 1, 1, 1 }) };    double[][] minkowskiDistanceMatrix = new double[3][3];    double[][] manhattanDistanceMatrix = new double[3][3];    double[][] euclideanDistanceMatrix = new double[3][3];    for (int a = 0; a < 3; a++) {        for (int b = 0; b < 3; b++) {            minkowskiDistanceMatrix[a][b] = minkowskiDistanceMeasure.distance(vectors[a], vectors[b]);            manhattanDistanceMatrix[a][b] = manhattanDistanceMeasure.distance(vectors[a], vectors[b]);            euclideanDistanceMatrix[a][b] = euclideanDistanceMeasure.distance(vectors[a], vectors[b]);        }    }    for (int a = 0; a < 3; a++) {        for (int b = 0; b < 3; b++) {            assertTrue(minkowskiDistanceMatrix[a][b] <= manhattanDistanceMatrix[a][b]);            assertTrue(minkowskiDistanceMatrix[a][b] >= euclideanDistanceMatrix[a][b]);        }    }    assertEquals(0.0, minkowskiDistanceMatrix[0][0], EPSILON);    assertTrue(minkowskiDistanceMatrix[0][0] < minkowskiDistanceMatrix[0][1]);    assertTrue(minkowskiDistanceMatrix[0][1] < minkowskiDistanceMatrix[0][2]);}
public TanimotoDistanceMeasure mahout_f5038_0()
{    return new TanimotoDistanceMeasure();}
public WeightedDistanceMeasure mahout_f5039_0()
{    return new WeightedEuclideanDistanceMeasure();}
public WeightedManhattanDistanceMeasure mahout_f5040_0()
{    return new WeightedManhattanDistanceMeasure();}
public void mahout_f5041_0()
{    Path path = HadoopUtil.findInCacheByPartOfFilename("no such file", DISTRIBUTED_CACHE_FILES);    assertNull(path);}
public void mahout_f5042_0()
{    Path path = HadoopUtil.findInCacheByPartOfFilename("want_to_find", DISTRIBUTED_CACHE_FILES);    assertNotNull(path);    assertEquals(FILE_I_WANT_TO_FIND.getName(), path.getName());}
public void mahout_f5043_0(K key, V values)
{    List<V> points = data.get(key);    if (points == null) {        points = Lists.newArrayList();        data.put(key, points);    }    points.add(values);}
public Map<K, List<V>> mahout_f5044_0()
{    return data;}
public List<V> mahout_f5045_0(K key)
{    return data.get(key);}
public Set<K> mahout_f5046_0()
{    return data.keySet();}
public void mahout_f5047_0(K key, V value)
{        try {        K keyToUse = key instanceof NullWritable ? key : (K) cloneWritable(key);        V valueToUse = (V) cloneWritable(value);        keysInInsertionOrder.add(keyToUse);        List<V> points = data.get(key);        if (points == null) {            points = Lists.newArrayList();            data.put(keyToUse, points);        }        points.add(valueToUse);    } catch (IOException e) {        throw new RuntimeException(e.getMessage(), e);    }}
private Writable mahout_f5048_0(Writable original) throws IOException
{    Writable clone;    try {        clone = original.getClass().asSubclass(Writable.class).newInstance();    } catch (Exception e) {        throw new RuntimeException("Unable to instantiate writable!", e);    }    ByteArrayOutputStream bytes = new ByteArrayOutputStream();    original.write(new DataOutputStream(bytes));    clone.readFields(new DataInputStream(new ByteArrayInputStream(bytes.toByteArray())));    return clone;}
public void mahout_f5049_0(TaskAttemptContext context)
{}
public Map<K, List<V>> mahout_f5050_0()
{    return data;}
public List<V> mahout_f5051_0(K key)
{    return data.get(key);}
public Set<K> mahout_f5052_0()
{    return data.keySet();}
public Iterable<K> mahout_f5053_0()
{    return keysInInsertionOrder;}
public static Mapper<K1, V1, K2, V2>.Context mahout_f5054_0(Mapper<K1, V1, K2, V2> mapper, Configuration configuration, RecordWriter<K2, V2> output)
{        try {        return buildNewMapperContext(configuration, output);    } catch (Exception | IncompatibleClassChangeError e) {        try {            return buildOldMapperContext(mapper, configuration, output);        } catch (Exception ex) {            throw new IllegalStateException(ex);        }    }}
public static Reducer<K1, V1, K2, V2>.Context mahout_f5055_0(Reducer<K1, V1, K2, V2> reducer, Configuration configuration, RecordWriter<K2, V2> output, Class<K1> keyClass, Class<V1> valueClass)
{        try {        return buildNewReducerContext(configuration, output, keyClass, valueClass);    } catch (Exception | IncompatibleClassChangeError e) {        try {            return buildOldReducerContext(reducer, configuration, output, keyClass, valueClass);        } catch (Exception ex) {            throw new IllegalStateException(ex);        }    }}
private static Mapper<K1, V1, K2, V2>.Context mahout_f5056_0(Configuration configuration, RecordWriter<K2, V2> output) throws Exception
{    Class<?> mapContextImplClass = Class.forName("org.apache.hadoop.mapreduce.task.MapContextImpl");    Constructor<?> cons = mapContextImplClass.getConstructors()[0];    Object mapContextImpl = cons.newInstance(configuration, new TaskAttemptID(), null, output, null, new DummyStatusReporter(), null);    Class<?> wrappedMapperClass = Class.forName("org.apache.hadoop.mapreduce.lib.map.WrappedMapper");    Object wrappedMapper = wrappedMapperClass.getConstructor().newInstance();    Method getMapContext = wrappedMapperClass.getMethod("getMapContext", MapContext.class);    return (Mapper.Context) getMapContext.invoke(wrappedMapper, mapContextImpl);}
private static Mapper<K1, V1, K2, V2>.Context mahout_f5057_0(Mapper<K1, V1, K2, V2> mapper, Configuration configuration, RecordWriter<K2, V2> output) throws Exception
{    Constructor<?> cons = getNestedContextConstructor(mapper.getClass());        return (Mapper.Context) cons.newInstance(mapper, configuration, new TaskAttemptID(), null, output, null, new DummyStatusReporter(), null);}
private static Reducer<K1, V1, K2, V2>.Context mahout_f5058_0(Configuration configuration, RecordWriter<K2, V2> output, Class<K1> keyClass, Class<V1> valueClass) throws Exception
{    Class<?> reduceContextImplClass = Class.forName("org.apache.hadoop.mapreduce.task.ReduceContextImpl");    Constructor<?> cons = reduceContextImplClass.getConstructors()[0];    Object reduceContextImpl = cons.newInstance(configuration, new TaskAttemptID(), new MockIterator(), null, null, output, null, new DummyStatusReporter(), null, keyClass, valueClass);    Class<?> wrappedReducerClass = Class.forName("org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer");    Object wrappedReducer = wrappedReducerClass.getConstructor().newInstance();    Method getReducerContext = wrappedReducerClass.getMethod("getReducerContext", ReduceContext.class);    return (Reducer.Context) getReducerContext.invoke(wrappedReducer, reduceContextImpl);}
private static Reducer<K1, V1, K2, V2>.Context mahout_f5059_0(Reducer<K1, V1, K2, V2> reducer, Configuration configuration, RecordWriter<K2, V2> output, Class<K1> keyClass, Class<V1> valueClass) throws Exception
{    Constructor<?> cons = getNestedContextConstructor(reducer.getClass());        return (Reducer.Context) cons.newInstance(reducer, configuration, new TaskAttemptID(), new MockIterator(), null, null, output, null, new DummyStatusReporter(), null, keyClass, valueClass);}
private static Constructor<?> mahout_f5060_0(Class<?> outerClass)
{    for (Class<?> nestedClass : outerClass.getClasses()) {        if ("Context".equals(nestedClass.getSimpleName())) {            return nestedClass.getConstructors()[0];        }    }    throw new IllegalStateException("Cannot find context class for " + outerClass);}
public void mahout_f5061_0()
{    DummyRecordWriter<IntWritable, VectorWritable> writer = new DummyRecordWriter<>();    IntWritable reusableIntWritable = new IntWritable();    VectorWritable reusableVectorWritable = new VectorWritable();    reusableIntWritable.set(0);    reusableVectorWritable.set(new DenseVector(new double[] { 1, 2, 3 }));    writer.write(reusableIntWritable, reusableVectorWritable);    reusableIntWritable.set(1);    reusableVectorWritable.set(new DenseVector(new double[] { 4, 5, 6 }));    writer.write(reusableIntWritable, reusableVectorWritable);    Assert.assertEquals("The writer must remember the two keys that is written to it", 2, writer.getKeys().size());}
private static Counter mahout_f5062_0()
{    try {                String c = "org.apache.hadoop.mapreduce.counters.GenericCounter";        return (Counter) EasyMock.createMockBuilder(Class.forName(c)).createMock();    } catch (ClassNotFoundException e) {                return EasyMock.createMockBuilder(Counter.class).createMock();    }}
public Counter mahout_f5063_0(Enum<?> name)
{    if (!counters.containsKey(name)) {        counters.put(name, newCounter());    }    return counters.get(name);}
public Counter mahout_f5064_0(String group, String name)
{    if (!counterGroups.containsKey(group + name)) {        counterGroups.put(group + name, newCounter());    }    return counterGroups.get(group + name);}
public void mahout_f5065_0()
{}
public void mahout_f5066_0(String status)
{}
public float mahout_f5067_0()
{    return 0.0f;}
public void mahout_f5068_0()
{    IntPairWritable n = new IntPairWritable();    assertEquals(0, n.getFirst());    assertEquals(0, n.getSecond());    n.setFirst(5);    n.setSecond(10);    assertEquals(5, n.getFirst());    assertEquals(10, n.getSecond());    n = new IntPairWritable(2, 4);    assertEquals(2, n.getFirst());    assertEquals(4, n.getSecond());}
public void mahout_f5069_0() throws Exception
{    IntPairWritable one = new IntPairWritable(1, 2);    IntPairWritable two = new IntPairWritable(3, 4);    assertEquals(1, one.getFirst());    assertEquals(2, one.getSecond());    assertEquals(3, two.getFirst());    assertEquals(4, two.getSecond());    ByteArrayOutputStream bout = new ByteArrayOutputStream();    DataOutput out = new DataOutputStream(bout);    two.write(out);    byte[] b = bout.toByteArray();    ByteArrayInputStream bin = new ByteArrayInputStream(b);    DataInput din = new DataInputStream(bin);    one.readFields(din);    assertEquals(two.getFirst(), one.getFirst());    assertEquals(two.getSecond(), one.getSecond());}
public void mahout_f5070_0()
{    IntPairWritable[] input = { new IntPairWritable(2, 3), new IntPairWritable(2, 2), new IntPairWritable(1, 3), new IntPairWritable(1, 2), new IntPairWritable(2, 1), new IntPairWritable(2, 2), new IntPairWritable(1, -2), new IntPairWritable(1, -1), new IntPairWritable(-2, -2), new IntPairWritable(-2, -1), new IntPairWritable(-1, -1), new IntPairWritable(-1, -2), new IntPairWritable(Integer.MAX_VALUE, 1), new IntPairWritable(Integer.MAX_VALUE / 2, 1), new IntPairWritable(Integer.MIN_VALUE, 1), new IntPairWritable(Integer.MIN_VALUE / 2, 1) };    IntPairWritable[] sorted = new IntPairWritable[input.length];    System.arraycopy(input, 0, sorted, 0, input.length);    Arrays.sort(sorted);    int[] expected = { 14, 15, 8, 9, 11, 10, 6, 7, 3, 2, 4, 1, 5, 0, 13, 12 };    for (int i = 0; i < input.length; i++) {        assertSame(input[expected[i]], sorted[i]);    }}
public void mahout_f5071_0()
{    assertFalse(new CountingIterator(0).hasNext());}
public void mahout_f5072_0()
{    Iterator<Integer> it = new CountingIterator(3);    assertTrue(it.hasNext());    assertEquals(0, (int) it.next());    assertTrue(it.hasNext());    assertEquals(1, (int) it.next());    assertTrue(it.hasNext());    assertEquals(2, (int) it.next());    assertFalse(it.hasNext());}
public void mahout_f5073_0()
{    assertFalse(createSampler(100, new CountingIterator(0)).hasNext());}
public void mahout_f5074_0()
{    Iterator<Integer> t = createSampler(10, new CountingIterator(1));    assertTrue(t.hasNext());    assertEquals(0, t.next().intValue());    assertFalse(t.hasNext());    t = createSampler(10, new CountingIterator(1));    assertTrue(t.hasNext());    assertEquals(0, t.next().intValue());    assertFalse(t.hasNext());}
public void mahout_f5075_0()
{    Iterator<Integer> t = createSampler(0, new CountingIterator(2));    assertFalse(t.hasNext());}
public void mahout_f5076_0()
{    Iterator<Integer> t = createSampler(10, new CountingIterator(10));    for (int i = 0; i < 10; i++) {        assertTrue(t.hasNext());        assertEquals(i, t.next().intValue());    }    assertFalse(t.hasNext());}
public void mahout_f5077_0()
{    Iterator<Integer> source = new CountingIterator(100);    Iterator<Integer> t = createSampler(15, source);        List<Integer> expectedValues = Arrays.asList(52, 28, 2, 60, 50, 32, 65, 79, 78, 9, 40, 33, 96, 25, 48);    if (isSorted()) {        Collections.sort(expectedValues);    }    Iterator<Integer> expected = expectedValues.iterator();    int last = Integer.MIN_VALUE;    for (int i = 0; i < 15; i++) {        assertTrue(t.hasNext());        int actual = t.next();        if (isSorted()) {            assertTrue(actual >= last);            last = actual;        } else {                        if (actual < 15) {                assertEquals(i, actual);            }        }        assertTrue(actual >= 0 && actual < 100);                assertEquals(expected.next().intValue(), actual);        assertFalse(source.hasNext());    }    assertFalse(t.hasNext());}
protected Iterator<Integer> mahout_f5078_0(int n, Iterator<Integer> source)
{    return new FixedSizeSamplingIterator<>(n, source);}
protected boolean mahout_f5079_0()
{    return false;}
public void mahout_f5080_0()
{    assertFalse(new SamplingIterator<>(new CountingIterator(0), 0.9999).hasNext());    assertFalse(new SamplingIterator<>(new CountingIterator(0), 1).hasNext());}
public void mahout_f5081_0()
{    Iterator<Integer> t = new SamplingIterator<>(new CountingIterator(1), 0.9999);    assertTrue(t.hasNext());    assertEquals(0, t.next().intValue());    assertFalse(t.hasNext());}
public void mahout_f5082_0()
{    new SamplingIterator<>(new CountingIterator(1), 0.0);}
public void mahout_f5083_0()
{    new SamplingIterator<>(new CountingIterator(1), 1.1);}
public void mahout_f5084_0()
{    Iterator<Integer> t = new SamplingIterator<>(new CountingIterator(10), 1);    for (int i = 0; i < 10; i++) {        assertTrue(t.hasNext());        assertEquals(i, t.next().intValue());    }    assertFalse(t.hasNext());}
public void mahout_f5085_0()
{    for (int i = 0; i < 1000; i++) {        Iterator<Integer> t = new SamplingIterator<>(new CountingIterator(1000), 0.1);        int k = 0;        while (t.hasNext()) {            int v = t.next();            k++;            assertTrue(v >= 0);            assertTrue(v < 1000);        }        double sd = Math.sqrt(0.9 * 0.1 * 1000);        assertTrue(k >= 100 - 4 * sd);        assertTrue(k <= 100 + 4 * sd);    }}
protected Iterator<Integer> mahout_f5086_0(int n, Iterator<Integer> source)
{    return new StableFixedSizeSamplingIterator<>(n, source);}
protected boolean mahout_f5087_0()
{    return true;}
public void mahout_f5088_0() throws Exception
{    assertNotNull(AnalyzerUtils.createAnalyzer(StandardAnalyzer.class.getName()));}
public void mahout_f5089_0() throws Exception
{    assertNotNull(AnalyzerUtils.createAnalyzer(CJKAnalyzer.class.getName()));}
public void mahout_f5090_0() throws Exception
{    super.setUp();    RandomUtils.useTestSeed();    testTempDirPath = null;    fs = null;}
public void mahout_f5091_0() throws Exception
{    if (testTempDirPath != null) {        try {            fs.delete(testTempDirPath, true);        } catch (IOException e) {            throw new IllegalStateException("Test file not found");        }        testTempDirPath = null;        fs = null;    }    super.tearDown();}
public final Configuration mahout_f5092_0() throws IOException
{    Configuration conf = new Configuration();    conf.set("hadoop.tmp.dir", getTestTempDir("hadoop" + Math.random()).getAbsolutePath());    return conf;}
protected final Path mahout_f5093_0() throws IOException
{    if (testTempDirPath == null) {        fs = FileSystem.get(getConfiguration());        long simpleRandomLong = (long) (Long.MAX_VALUE * Math.random());        testTempDirPath = fs.makeQualified(new Path("/tmp/mahout-" + getClass().getSimpleName() + '-' + simpleRandomLong));        if (!fs.mkdirs(testTempDirPath)) {            throw new IOException("Could not create " + testTempDirPath);        }        fs.deleteOnExit(testTempDirPath);    }    return testTempDirPath;}
protected final Path mahout_f5094_0(String name) throws IOException
{    return getTestTempFileOrDirPath(name, false);}
protected final Path mahout_f5095_0(String name) throws IOException
{    return getTestTempFileOrDirPath(name, true);}
private Path mahout_f5096_0(String name, boolean dir) throws IOException
{    Path testTempDirPath = getTestTempDirPath();    Path tempFileOrDir = fs.makeQualified(new Path(testTempDirPath, name));    fs.deleteOnExit(tempFileOrDir);    if (dir && !fs.mkdirs(tempFileOrDir)) {        throw new IOException("Could not create " + tempFileOrDir);    }    return tempFileOrDir;}
protected static void mahout_f5097_0(Object target, String fieldname, Object value) throws NoSuchFieldException, IllegalAccessException
{    Field field = findDeclaredField(target.getClass(), fieldname);    field.setAccessible(true);    field.set(target, value);}
private static Field mahout_f5098_0(Class<?> inClass, String fieldname) throws NoSuchFieldException
{    while (!Object.class.equals(inClass)) {        for (Field field : inClass.getDeclaredFields()) {            if (field.getName().equalsIgnoreCase(fieldname)) {                return field;            }        }        inClass = inClass.getSuperclass();    }    throw new NoSuchFieldException();}
protected static String mahout_f5099_0(String optionName)
{    return AbstractJob.keyFor(optionName);}
protected static void mahout_f5100_0(File file, String... lines) throws IOException
{    Writer writer = new OutputStreamWriter(new FileOutputStream(file), Charsets.UTF_8);    try {        for (String line : lines) {            writer.write(line);            writer.write('\n');        }    } finally {        Closeables.close(writer, false);    }}
public void mahout_f5101_0()
{}
public DataInputBuffer mahout_f5102_0()
{    return null;}
public Progress mahout_f5103_0()
{    return null;}
public DataInputBuffer mahout_f5104_0()
{    return null;}
public boolean mahout_f5105_0()
{    return true;}
public boolean mahout_f5106_0(Object obj)
{    if (this == obj) {        return true;    }    if (!(obj instanceof DummyTest)) {        return false;    }    DummyTest dt = (DummyTest) obj;    return field == dt.field;}
public int mahout_f5107_0()
{    return field;}
public int mahout_f5108_0()
{    return field;}
public void mahout_f5109_0() throws Exception
{    List<String> expected = Lists.newArrayList("A", "B", "C");    assertEquals(expected, StringUtils.fromString(StringUtils.toString(expected)));        DummyTest test = new DummyTest();    assertEquals(test, StringUtils.fromString(StringUtils.toString(test)));}
public void mahout_f5110_0() throws Exception
{    String res = StringUtils.escapeXML("\",\',&,>,<");    assertEquals("_,_,_,_,_", res);}
public void mahout_f5111_0() throws Throwable
{    MahoutDriver.main(new String[] { "canopy", "help" });}
public void mahout_f5112_0() throws Exception
{    State<Foo, Double> s0 = new State<>(new double[5], 1);    s0.setPayload(new Foo());    EvolutionaryProcess<Foo, Double> ep = new EvolutionaryProcess<>(10, 100, s0);    State<Foo, Double> best = null;    for (int i = 0; i < 20; i++) {        best = ep.parallelDo(new EvolutionaryProcess.Function<Payload<Double>>() {            @Override            public double apply(Payload<Double> payload, double[] params) {                int i = 1;                double sum = 0;                for (double x : params) {                    sum += i * (x - i) * (x - i);                    i++;                }                return -sum;            }        });        ep.mutatePopulation(3);        System.out.printf("%10.3f %.3f\n", best.getValue(), best.getOmni());    }    ep.close();    assertNotNull(best);    assertEquals(0.0, best.getValue(), 0.02);}
public double mahout_f5113_0(Payload<Double> payload, double[] params)
{    int i = 1;    double sum = 0;    for (double x : params) {        sum += i * (x - i) * (x - i);        i++;    }    return -sum;}
public Foo mahout_f5114_0()
{    return this;}
public void mahout_f5115_0(double[] params)
{}
public void mahout_f5116_0(DataOutput dataOutput) throws IOException
{}
public void mahout_f5117_0(DataInput dataInput) throws IOException
{}
public void mahout_f5118_0() throws Exception
{    super.setUp();    File symTestData = getTestTempDir("symTestData");    File asymTestData = getTestTempDir("asymTestData");    symCorpus = new TestDistributedRowMatrix().randomDistributedMatrix(100, 90, 80, 2, 10.0, true, symTestData.getAbsolutePath());    asymCorpus = new TestDistributedRowMatrix().randomDistributedMatrix(100, 90, 80, 2, 10.0, false, asymTestData.getAbsolutePath());}
private static String mahout_f5119_0(boolean symmetric)
{    return symmetric ? "_sym" : "_asym";}
private DistributedRowMatrix mahout_f5120_0(boolean symmetric)
{    return symmetric ? symCorpus : asymCorpus;}
private LanczosState mahout_f5121_0(boolean symmetric, int desiredRank, boolean hdfsBackedState) throws IOException
{    DistributedRowMatrix corpus = getCorpus(symmetric);    Configuration conf = getConfiguration();    corpus.setConf(conf);    DistributedLanczosSolver solver = new DistributedLanczosSolver();    Vector intitialVector = DistributedLanczosSolver.getInitialVector(corpus);    LanczosState state;    if (hdfsBackedState) {        HdfsBackedLanczosState hState = new HdfsBackedLanczosState(corpus, desiredRank, intitialVector, new Path(getTestTempDirPath(), "lanczosStateDir" + suf(symmetric) + counter));        hState.setConf(conf);        state = hState;    } else {        state = new LanczosState(corpus, desiredRank, intitialVector);    }    solver.solve(state, desiredRank, symmetric);    SolverTest.assertOrthonormal(state);    for (int i = 0; i < desiredRank / 2; i++) {        SolverTest.assertEigen(i, state.getRightSingularVector(i), corpus, 0.1, symmetric);    }    counter++;    return state;}
public void mahout_f5122_0(boolean symmetric) throws IOException
{    DistributedRowMatrix corpus = getCorpus(symmetric);    Configuration conf = getConfiguration();    corpus.setConf(conf);    DistributedLanczosSolver solver = new DistributedLanczosSolver();    int rank = 10;    Vector intitialVector = DistributedLanczosSolver.getInitialVector(corpus);    HdfsBackedLanczosState state = new HdfsBackedLanczosState(corpus, rank, intitialVector, new Path(getTestTempDirPath(), "lanczosStateDir" + suf(symmetric) + counter));    solver.solve(state, rank, symmetric);    rank *= 2;    state = new HdfsBackedLanczosState(corpus, rank, intitialVector, new Path(getTestTempDirPath(), "lanczosStateDir" + suf(symmetric) + counter));    solver = new DistributedLanczosSolver();    solver.solve(state, rank, symmetric);    LanczosState allAtOnceState = doTestDistributedLanczosSolver(symmetric, rank, false);    for (int i = 0; i < state.getIterationNumber(); i++) {        Vector v = state.getBasisVector(i).normalize();        Vector w = allAtOnceState.getBasisVector(i).normalize();        double diff = v.minus(w).norm(2);        assertTrue("basis " + i + " is too long: " + diff, diff < 0.1);    }    counter++;}
public void mahout_f5123_0() throws Exception
{    Path testData = getTestTempDirPath("testdata");    DistributedRowMatrix corpus = new TestDistributedRowMatrix().randomDenseHierarchicalDistributedMatrix(10, 9, false, testData.toString());    corpus.setConf(getConfiguration());    Path output = getTestTempDirPath("output");    Path tmp = getTestTempDirPath("tmp");    Path workingDir = getTestTempDirPath("working");    String[] args = { "-i", new Path(testData, "distMatrix").toString(), "-o", output.toString(), "--tempDir", tmp.toString(), "--numRows", "10", "--numCols", "9", "--rank", "6", "--symmetric", "false", "--workingDir", workingDir.toString() };    ToolRunner.run(getConfiguration(), new DistributedLanczosSolver().new DistributedLanczosSolverJob(), args);    output = getTestTempDirPath("output2");    tmp = getTestTempDirPath("tmp2");    args = new String[] { "-i", new Path(testData, "distMatrix").toString(), "-o", output.toString(), "--tempDir", tmp.toString(), "--numRows", "10", "--numCols", "9", "--rank", "7", "--symmetric", "false", "--workingDir", workingDir.toString() };    ToolRunner.run(getConfiguration(), new DistributedLanczosSolver().new DistributedLanczosSolverJob(), args);    Path rawEigenvectors = new Path(output, DistributedLanczosSolver.RAW_EIGENVECTORS);    Matrix eigenVectors = new DenseMatrix(7, corpus.numCols());    Configuration conf = getConfiguration();    int i = 0;    for (VectorWritable value : new SequenceFileValueIterable<VectorWritable>(rawEigenvectors, conf)) {        Vector v = value.get();        eigenVectors.assignRow(i, v);        i++;    }    assertEquals("number of eigenvectors", 7, i);}
public void mahout_f5124_1() throws Exception
{    Path testData = getTestTempDirPath("testdata");    DistributedRowMatrix corpus = new TestDistributedRowMatrix().randomDenseHierarchicalDistributedMatrix(10, 9, false, testData.toString());    corpus.setConf(getConfiguration());    Path output = getTestTempDirPath("output");    Path tmp = getTestTempDirPath("tmp");    String[] args = { "-i", new Path(testData, "distMatrix").toString(), "-o", output.toString(), "--tempDir", tmp.toString(), "--numRows", "10", "--numCols", "9", "--rank", "6", "--symmetric", "false", "--cleansvd", "true" };    ToolRunner.run(getConfiguration(), new DistributedLanczosSolver().new DistributedLanczosSolverJob(), args);    Path cleanEigenvectors = new Path(output, EigenVerificationJob.CLEAN_EIGENVECTORS);    Matrix eigenVectors = new DenseMatrix(6, corpus.numCols());    Collection<Double> eigenvalues = Lists.newArrayList();    output = getTestTempDirPath("output2");    tmp = getTestTempDirPath("tmp2");    args = new String[] { "-i", new Path(testData, "distMatrix").toString(), "-o", output.toString(), "--tempDir", tmp.toString(), "--numRows", "10", "--numCols", "9", "--rank", "7", "--symmetric", "false", "--cleansvd", "true" };    ToolRunner.run(getConfiguration(), new DistributedLanczosSolver().new DistributedLanczosSolverJob(), args);    Path cleanEigenvectors2 = new Path(output, EigenVerificationJob.CLEAN_EIGENVECTORS);    Matrix eigenVectors2 = new DenseMatrix(7, corpus.numCols());    Configuration conf = getConfiguration();    Collection<Double> newEigenValues = Lists.newArrayList();    int i = 0;    for (VectorWritable value : new SequenceFileValueIterable<VectorWritable>(cleanEigenvectors, conf)) {        NamedVector v = (NamedVector) value.get();        eigenVectors.assignRow(i, v);                if (EigenVector.getCosAngleError(v.getName()) < 1.0e-3) {            eigenvalues.add(EigenVector.getEigenValue(v.getName()));        }        i++;    }    assertEquals("number of clean eigenvectors", 3, i);    i = 0;    for (VectorWritable value : new SequenceFileValueIterable<VectorWritable>(cleanEigenvectors2, conf)) {        NamedVector v = (NamedVector) value.get();                eigenVectors2.assignRow(i, v);        newEigenValues.add(EigenVector.getEigenValue(v.getName()));        i++;    }    Collection<Integer> oldEigensFound = Lists.newArrayList();    for (int row = 0; row < eigenVectors.numRows(); row++) {        Vector oldEigen = eigenVectors.viewRow(row);        if (oldEigen == null) {            break;        }        for (int newRow = 0; newRow < eigenVectors2.numRows(); newRow++) {            Vector newEigen = eigenVectors2.viewRow(newRow);            if (newEigen != null && oldEigen.dot(newEigen) > 0.9) {                oldEigensFound.add(row);                break;            }        }    }    assertEquals("the number of new eigenvectors", 5, i);    Collection<Double> oldEigenValuesNotFound = Lists.newArrayList();    for (double d : eigenvalues) {        boolean found = false;        for (double newD : newEigenValues) {            if (Math.abs((d - newD) / d) < 0.1) {                found = true;            }        }        if (!found) {            oldEigenValuesNotFound.add(d);        }    }    assertEquals("number of old eigenvalues not found: " + Arrays.toString(oldEigenValuesNotFound.toArray(new Double[oldEigenValuesNotFound.size()])), 0, oldEigenValuesNotFound.size());    assertEquals("did not find enough old eigenvectors", 3, oldEigensFound.size());}
public static Vector.Element mahout_f5125_0(int index, double value)
{    return new ElementToCheck(index, value);}
public double mahout_f5126_0()
{    return value;}
public int mahout_f5127_0()
{    return index;}
public void mahout_f5128_0(double value)
{    this.value = value;}
public static VectorWritable mahout_f5129_0(final Vector.Element... elements)
{    EasyMock.reportMatcher(new IArgumentMatcher() {        @Override        public boolean matches(Object argument) {            if (argument instanceof VectorWritable) {                Vector v = ((VectorWritable) argument).get();                return consistsOf(v, elements);            }            return false;        }        @Override        public void appendTo(StringBuffer buffer) {        }    });    return null;}
public boolean mahout_f5130_0(Object argument)
{    if (argument instanceof VectorWritable) {        Vector v = ((VectorWritable) argument).get();        return consistsOf(v, elements);    }    return false;}
public void mahout_f5131_0(StringBuffer buffer)
{}
public static boolean mahout_f5132_0(Vector vector, Vector.Element... elements)
{    if (elements.length != numberOfNoNZeroNonNaNElements(vector)) {        return false;    }    for (Vector.Element element : elements) {        if (Math.abs(element.get() - vector.get(element.index())) > MahoutTestCase.EPSILON) {            return false;        }    }    return true;}
public static int mahout_f5133_0(Vector vector)
{    int elementsInVector = 0;    for (Element currentElement : vector.nonZeroes()) {        if (!Double.isNaN(currentElement.get())) {            elementsInVector++;        }    }    return elementsInVector;}
public static Matrix mahout_f5134_0(Configuration conf, Path path, int rows, int columns)
{    boolean readOneRow = false;    Matrix matrix = new DenseMatrix(rows, columns);    for (Pair<IntWritable, VectorWritable> record : new SequenceFileIterable<IntWritable, VectorWritable>(path, true, conf)) {        IntWritable key = record.getFirst();        VectorWritable value = record.getSecond();        readOneRow = true;        int row = key.get();        for (Element element : value.get().nonZeroes()) {            matrix.set(row, element.index(), element.get());        }    }    if (!readOneRow) {        throw new IllegalStateException("Not a single row read!");    }    return matrix;}
public static OpenIntObjectHashMap<Vector> mahout_f5135_0(Configuration conf, Path path)
{    boolean readOneRow = false;    OpenIntObjectHashMap<Vector> rows = new OpenIntObjectHashMap<>();    for (Pair<IntWritable, VectorWritable> record : new SequenceFileIterable<IntWritable, VectorWritable>(path, true, conf)) {        IntWritable key = record.getFirst();        readOneRow = true;        rows.put(key.get(), record.getSecond().get());    }    if (!readOneRow) {        throw new IllegalStateException("Not a single row read!");    }    return rows;}
public static void mahout_f5136_0(double[][] entries, FileSystem fs, Configuration conf, Path path) throws IOException
{    SequenceFile.Writer writer = null;    try {        writer = new SequenceFile.Writer(fs, conf, path, IntWritable.class, VectorWritable.class);        for (int n = 0; n < entries.length; n++) {            Vector v = new RandomAccessSparseVector(entries[n].length);            for (int m = 0; m < entries[n].length; m++) {                v.setQuick(m, entries[n][m]);            }            writer.append(new IntWritable(n), new VectorWritable(v));        }    } finally {        Closeables.close(writer, false);    }}
public static void mahout_f5137_0(Matrix expected, Matrix actual)
{    Assert.assertEquals(expected.numRows(), actual.numRows());    Assert.assertEquals(actual.numCols(), actual.numCols());    for (int row = 0; row < expected.numRows(); row++) {        for (int col = 0; col < expected.numCols(); col++) {            Assert.assertEquals("Non-matching values in [" + row + ',' + col + ']', expected.get(row, col), actual.get(row, col), MahoutTestCase.EPSILON);        }    }}
public static String mahout_f5138_0(Vector v)
{    if (!v.isSequentialAccess()) {        v = new DenseVector(v);    }    DecimalFormat df = new DecimalFormat("0.00", DecimalFormatSymbols.getInstance(Locale.ENGLISH));    StringBuilder buffer = new StringBuilder("[");    String separator = "";    for (Vector.Element e : v.all()) {        buffer.append(separator);        if (Double.isNaN(e.get())) {            buffer.append("  -  ");        } else {            if (e.get() >= 0) {                buffer.append(' ');            }            buffer.append(df.format(e.get()));        }        separator = "\t";    }    buffer.append(" ]");    return buffer.toString();}
public static String mahout_f5139_0(Matrix matrix)
{    StringBuilder info = new StringBuilder();    for (int n = 0; n < matrix.numRows(); n++) {        info.append(nice(matrix.viewRow(n))).append('\n');    }    return info.toString();}
 static double mahout_f5140_0(double[] one, double[] two, Class<? extends VectorSimilarityMeasure> similarityMeasureClass)
{    double rand = computeSimilarity(one, two, similarityMeasureClass, new RandomAccessSparseVector(one.length));    double seq = computeSimilarity(one, two, similarityMeasureClass, new SequentialAccessSparseVector(one.length));    double dense = computeSimilarity(one, two, similarityMeasureClass, new DenseVector(one.length));    assertEquals(seq, rand, 1.0e-10);    assertEquals(seq, dense, 1.0e-10);    assertEquals(dense, rand, 1.0e-10);    return seq;}
private static double mahout_f5141_0(double[] one, double[] two, Class<? extends VectorSimilarityMeasure> similarityMeasureClass, Vector like)
{    VectorSimilarityMeasure similarityMeasure = ClassUtils.instantiateAs(similarityMeasureClass, VectorSimilarityMeasure.class);    Vector oneNormalized = similarityMeasure.normalize(asVector(one, like));    Vector twoNormalized = similarityMeasure.normalize(asVector(two, like));    double normOne = similarityMeasure.norm(oneNormalized);    double normTwo = similarityMeasure.norm(twoNormalized);    double dot = 0;    for (int n = 0; n < one.length; n++) {        if (oneNormalized.get(n) != 0 && twoNormalized.get(n) != 0) {            dot += similarityMeasure.aggregate(oneNormalized.get(n), twoNormalized.get(n));        }    }    return similarityMeasure.similarity(dot, normOne, normTwo, one.length);}
 static Vector mahout_f5142_0(double[] values, Vector like)
{    Vector vector = like.like();    for (int dim = 0; dim < values.length; dim++) {        vector.set(dim, values[dim]);    }    return vector;}
public void mahout_f5143_0()
{    double similarity = distributedSimilarity(new double[] { 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0 }, new double[] { 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1 }, CooccurrenceCountSimilarity.class);    assertEquals(5.0, similarity, 0);}
public void mahout_f5144_0()
{    double similarity = distributedSimilarity(new double[] { 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0 }, new double[] { 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1 }, TanimotoCoefficientSimilarity.class);    assertEquals(0.454545455, similarity, EPSILON);}
public void mahout_f5145_0()
{    double similarity = distributedSimilarity(new double[] { 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0 }, new double[] { 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1 }, CityBlockSimilarity.class);    assertEquals(0.142857143, similarity, EPSILON);}
public void mahout_f5146_0()
{    double similarity = distributedSimilarity(new double[] { 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0 }, new double[] { 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1 }, LoglikelihoodSimilarity.class);    assertEquals(0.03320155369284261, similarity, EPSILON);}
public void mahout_f5147_0()
{    double similarity = distributedSimilarity(new double[] { 0, 2, 0, 0, 8, 3, 0, 6, 0, 1, 2, 2, 0 }, new double[] { 3, 0, 0, 0, 7, 0, 2, 2, 1, 3, 2, 1, 1 }, CosineSimilarity.class);    assertEquals(0.769846046, similarity, EPSILON);}
public void mahout_f5148_0()
{    double similarity = distributedSimilarity(new double[] { 0, 2, 0, 0, 8, 3, 0, 6, 0, 1, 1, 2, 1 }, new double[] { 3, 0, 0, 0, 7, 0, 2, 2, 1, 3, 2, 4, 3 }, PearsonCorrelationSimilarity.class);    assertEquals(0.5303300858899108, similarity, EPSILON);}
public void mahout_f5149_0()
{    double similarity = distributedSimilarity(new double[] { 0, 2, 0, 0, 8, 3, 0, 6, 0, 1, 1, 2, 1 }, new double[] { 3, 0, 0, 0, 7, 0, 2, 2, 1, 3, 2, 4, 4 }, EuclideanDistanceSimilarity.class);    assertEquals(0.11268865367232477, similarity, EPSILON);}
public void mahout_f5150_0() throws Exception
{    File inputFile = getTestTempFile("rows");    File outputDir = getTestTempDir("output");    outputDir.delete();    File tmpDir = getTestTempDir("tmp");    Configuration conf = getConfiguration();    Path inputPath = new Path(inputFile.getAbsolutePath());    FileSystem fs = FileSystem.get(inputPath.toUri(), conf);    MathHelper.writeDistributedRowMatrix(new double[][] { new double[] { 1, 0, 1, 1, 0 }, new double[] { 0, 0, 1, 1, 0 }, new double[] { 0, 0, 0, 0, 1 } }, fs, conf, inputPath);    RowSimilarityJob rowSimilarityJob = new RowSimilarityJob();    rowSimilarityJob.setConf(conf);    rowSimilarityJob.run(new String[] { "--input", inputFile.getAbsolutePath(), "--output", outputDir.getAbsolutePath(), "--numberOfColumns", String.valueOf(5), "--similarityClassname", TanimotoCoefficientSimilarity.class.getName(), "--tempDir", tmpDir.getAbsolutePath() });    OpenIntIntHashMap observationsPerColumn = Vectors.readAsIntMap(new Path(tmpDir.getAbsolutePath(), "observationsPerColumn.bin"), conf);    assertEquals(4, observationsPerColumn.size());    assertEquals(1, observationsPerColumn.get(0));    assertEquals(2, observationsPerColumn.get(2));    assertEquals(2, observationsPerColumn.get(3));    assertEquals(1, observationsPerColumn.get(4));    Matrix similarityMatrix = MathHelper.readMatrix(conf, new Path(outputDir.getAbsolutePath(), "part-r-00000"), 3, 3);    assertNotNull(similarityMatrix);    assertEquals(3, similarityMatrix.numCols());    assertEquals(3, similarityMatrix.numRows());    assertEquals(1.0, similarityMatrix.get(0, 0), EPSILON);    assertEquals(1.0, similarityMatrix.get(1, 1), EPSILON);    assertEquals(1.0, similarityMatrix.get(2, 2), EPSILON);    assertEquals(0.0, similarityMatrix.get(2, 0), EPSILON);    assertEquals(0.0, similarityMatrix.get(2, 1), EPSILON);    assertEquals(0.0, similarityMatrix.get(0, 2), EPSILON);    assertEquals(0.0, similarityMatrix.get(1, 2), EPSILON);    assertEquals(0.666666, similarityMatrix.get(0, 1), EPSILON);    assertEquals(0.666666, similarityMatrix.get(1, 0), EPSILON);}
public void mahout_f5151_0() throws Exception
{    File inputFile = getTestTempFile("rows");    File outputDir = getTestTempDir("output");    outputDir.delete();    File tmpDir = getTestTempDir("tmp");    Configuration conf = getConfiguration();    Path inputPath = new Path(inputFile.getAbsolutePath());    FileSystem fs = FileSystem.get(inputPath.toUri(), conf);    MathHelper.writeDistributedRowMatrix(new double[][] { new double[] { 1, 0, 1, 1, 0, 1 }, new double[] { 0, 1, 1, 1, 1, 1 }, new double[] { 1, 1, 0, 1, 0, 0 } }, fs, conf, inputPath);    RowSimilarityJob rowSimilarityJob = new RowSimilarityJob();    rowSimilarityJob.setConf(conf);    rowSimilarityJob.run(new String[] { "--input", inputFile.getAbsolutePath(), "--output", outputDir.getAbsolutePath(), "--numberOfColumns", String.valueOf(6), "--similarityClassname", TanimotoCoefficientSimilarity.class.getName(), "--maxSimilaritiesPerRow", String.valueOf(1), "--excludeSelfSimilarity", String.valueOf(true), "--tempDir", tmpDir.getAbsolutePath() });    Matrix similarityMatrix = MathHelper.readMatrix(conf, new Path(outputDir.getAbsolutePath(), "part-r-00000"), 3, 3);    assertNotNull(similarityMatrix);    assertEquals(3, similarityMatrix.numCols());    assertEquals(3, similarityMatrix.numRows());    assertEquals(0.0, similarityMatrix.get(0, 0), EPSILON);    assertEquals(0.5, similarityMatrix.get(0, 1), EPSILON);    assertEquals(0.0, similarityMatrix.get(0, 2), EPSILON);    assertEquals(0.5, similarityMatrix.get(1, 0), EPSILON);    assertEquals(0.0, similarityMatrix.get(1, 1), EPSILON);    assertEquals(0.0, similarityMatrix.get(1, 2), EPSILON);    assertEquals(0.4, similarityMatrix.get(2, 0), EPSILON);    assertEquals(0.0, similarityMatrix.get(2, 1), EPSILON);    assertEquals(0.0, similarityMatrix.get(2, 2), EPSILON);}
public void mahout_f5152_0() throws Exception
{    File inputFile = getTestTempFile("rows");    File outputDir = getTestTempDir("output");    outputDir.delete();    File tmpDir = getTestTempDir("tmp");    Configuration conf = getConfiguration();    Path inputPath = new Path(inputFile.getAbsolutePath());    FileSystem fs = FileSystem.get(inputPath.toUri(), conf);    MathHelper.writeDistributedRowMatrix(new double[][] { new double[] { 1, 0, 1, 1, 0, 1 }, new double[] { 0, 1, 1, 1, 1, 1 }, new double[] { 1, 1, 0, 1, 0, 0 } }, fs, conf, inputPath);    RowSimilarityJob rowSimilarityJob = new RowSimilarityJob();    rowSimilarityJob.setConf(conf);    rowSimilarityJob.run(new String[] { "--input", inputFile.getAbsolutePath(), "--output", outputDir.getAbsolutePath(), "--numberOfColumns", String.valueOf(6), "--similarityClassname", TanimotoCoefficientSimilarity.class.getName(), "--excludeSelfSimilarity", String.valueOf(true), "--threshold", String.valueOf(0.5), "--tempDir", tmpDir.getAbsolutePath() });    Matrix similarityMatrix = MathHelper.readMatrix(conf, new Path(outputDir.getAbsolutePath(), "part-r-00000"), 3, 3);    assertNotNull(similarityMatrix);    assertEquals(3, similarityMatrix.numCols());    assertEquals(3, similarityMatrix.numRows());    assertEquals(0.0, similarityMatrix.get(0, 0), EPSILON);    assertEquals(0.5, similarityMatrix.get(0, 1), EPSILON);    assertEquals(0.0, similarityMatrix.get(0, 2), EPSILON);    assertEquals(0.5, similarityMatrix.get(1, 0), EPSILON);    assertEquals(0.0, similarityMatrix.get(1, 1), EPSILON);    assertEquals(0.0, similarityMatrix.get(1, 2), EPSILON);    assertEquals(0.0, similarityMatrix.get(2, 0), EPSILON);    assertEquals(0.0, similarityMatrix.get(2, 1), EPSILON);    assertEquals(0.0, similarityMatrix.get(2, 2), EPSILON);}
public void mahout_f5153_0() throws Exception
{    File inputFile = getTestTempFile("rows");    Configuration conf = getConfiguration();    Path inputPath = new Path(inputFile.getAbsolutePath());    FileSystem fs = FileSystem.get(inputPath.toUri(), conf);    MathHelper.writeDistributedRowMatrix(new double[][] { new double[] { 1, 0, 1, 1, 0, 1 }, new double[] { 0, 1, 1, 1, 1, 1 }, new double[] { 1, 1, 0, 1, 0, 0 } }, fs, conf, inputPath);    RowSimilarityJob rowSimilarityJob = new RowSimilarityJob();    rowSimilarityJob.setConf(conf);    int numberOfColumns = rowSimilarityJob.getDimensions(inputPath);    assertEquals(6, numberOfColumns);}
public void mahout_f5154_0() throws Exception
{    super.setUp();    fs = FileSystem.get(getConfiguration());}
public void mahout_f5155_0() throws Exception
{    Mapper<WritableComparable<?>, VectorWritable, StringTuple, DoubleWritable>.Context context = EasyMock.createMock(Mapper.Context.class);    StringTuple tuple = new StringTuple();    tuple.add("foo");    tuple.add("123");    context.write(tuple, new DoubleWritable(Math.sqrt(2.0)));    tuple = new StringTuple();    tuple.add("foo2");    tuple.add("123");    context.write(tuple, new DoubleWritable(1));    EasyMock.replay(context);    Vector vector = new RandomAccessSparseVector(2);    vector.set(0, 2);    vector.set(1, 2);    VectorDistanceMapper mapper = new VectorDistanceMapper();    setField(mapper, "measure", new EuclideanDistanceMeasure());    Collection<NamedVector> seedVectors = Lists.newArrayList();    Vector seed1 = new RandomAccessSparseVector(2);    seed1.set(0, 1);    seed1.set(1, 1);    Vector seed2 = new RandomAccessSparseVector(2);    seed2.set(0, 2);    seed2.set(1, 1);    seedVectors.add(new NamedVector(seed1, "foo"));    seedVectors.add(new NamedVector(seed2, "foo2"));    setField(mapper, "seedVectors", seedVectors);    mapper.map(new IntWritable(123), new VectorWritable(vector), context);    EasyMock.verify(context);}
public void mahout_f5156_0() throws Exception
{    Mapper<WritableComparable<?>, VectorWritable, Text, VectorWritable>.Context context = EasyMock.createMock(Mapper.Context.class);    Vector expectVec = new DenseVector(new double[] { Math.sqrt(2.0), 1.0 });    context.write(new Text("other"), new VectorWritable(expectVec));    EasyMock.replay(context);    Vector vector = new NamedVector(new RandomAccessSparseVector(2), "other");    vector.set(0, 2);    vector.set(1, 2);    VectorDistanceInvertedMapper mapper = new VectorDistanceInvertedMapper();    setField(mapper, "measure", new EuclideanDistanceMeasure());    Collection<NamedVector> seedVectors = Lists.newArrayList();    Vector seed1 = new RandomAccessSparseVector(2);    seed1.set(0, 1);    seed1.set(1, 1);    Vector seed2 = new RandomAccessSparseVector(2);    seed2.set(0, 2);    seed2.set(1, 1);    seedVectors.add(new NamedVector(seed1, "foo"));    seedVectors.add(new NamedVector(seed2, "foo2"));    setField(mapper, "seedVectors", seedVectors);    mapper.map(new IntWritable(123), new VectorWritable(vector), context);    EasyMock.verify(context);}
public void mahout_f5157_0() throws Exception
{    Path input = getTestTempDirPath("input");    Path output = getTestTempDirPath("output");    Path seedsPath = getTestTempDirPath("seeds");    List<VectorWritable> points = getPointsWritable(REFERENCE);    List<VectorWritable> seeds = getPointsWritable(SEEDS);    Configuration conf = getConfiguration();    ClusteringTestUtils.writePointsToFile(points, true, new Path(input, "file1"), fs, conf);    ClusteringTestUtils.writePointsToFile(seeds, true, new Path(seedsPath, "part-seeds"), fs, conf);    String[] args = { optKey(DefaultOptionCreator.INPUT_OPTION), input.toString(), optKey(VectorDistanceSimilarityJob.SEEDS), seedsPath.toString(), optKey(DefaultOptionCreator.OUTPUT_OPTION), output.toString(), optKey(DefaultOptionCreator.DISTANCE_MEASURE_OPTION), EuclideanDistanceMeasure.class.getName() };    ToolRunner.run(getConfiguration(), new VectorDistanceSimilarityJob(), args);    int expectedOutputSize = SEEDS.length * REFERENCE.length;    int outputSize = Iterables.size(new SequenceFileIterable<StringTuple, DoubleWritable>(new Path(output, "part-m-00000"), conf));    assertEquals(expectedOutputSize, outputSize);}
public void mahout_f5158_0() throws Exception
{    Path input = getTestTempDirPath("input");    Path output = getTestTempDirPath("output");    Path seedsPath = getTestTempDirPath("seeds");    List<VectorWritable> points = getPointsWritable(REFERENCE);    List<VectorWritable> seeds = getPointsWritable(SEEDS);    Configuration conf = getConfiguration();    ClusteringTestUtils.writePointsToFile(points, true, new Path(input, "file1"), fs, conf);    ClusteringTestUtils.writePointsToFile(seeds, true, new Path(seedsPath, "part-seeds"), fs, conf);    double maxDistance = 10;    String[] args = { optKey(DefaultOptionCreator.INPUT_OPTION), input.toString(), optKey(VectorDistanceSimilarityJob.SEEDS), seedsPath.toString(), optKey(DefaultOptionCreator.OUTPUT_OPTION), output.toString(), optKey(DefaultOptionCreator.DISTANCE_MEASURE_OPTION), EuclideanDistanceMeasure.class.getName(), optKey(VectorDistanceSimilarityJob.MAX_DISTANCE), String.valueOf(maxDistance) };    ToolRunner.run(getConfiguration(), new VectorDistanceSimilarityJob(), args);    int outputSize = 0;    for (Pair<StringTuple, DoubleWritable> record : new SequenceFileIterable<StringTuple, DoubleWritable>(new Path(output, "part-m-00000"), conf)) {        outputSize++;        assertTrue(record.getSecond().get() <= maxDistance);    }    assertEquals(14, outputSize);}
public void mahout_f5159_0() throws Exception
{    Path input = getTestTempDirPath("input");    Path output = getTestTempDirPath("output");    Path seedsPath = getTestTempDirPath("seeds");    List<VectorWritable> points = getPointsWritable(REFERENCE);    List<VectorWritable> seeds = getPointsWritable(SEEDS);    Configuration conf = getConfiguration();    ClusteringTestUtils.writePointsToFile(points, true, new Path(input, "file1"), fs, conf);    ClusteringTestUtils.writePointsToFile(seeds, true, new Path(seedsPath, "part-seeds"), fs, conf);    String[] args = { optKey(DefaultOptionCreator.INPUT_OPTION), input.toString(), optKey(VectorDistanceSimilarityJob.SEEDS), seedsPath.toString(), optKey(DefaultOptionCreator.OUTPUT_OPTION), output.toString(), optKey(DefaultOptionCreator.DISTANCE_MEASURE_OPTION), EuclideanDistanceMeasure.class.getName(), optKey(VectorDistanceSimilarityJob.OUT_TYPE_KEY), "v" };    ToolRunner.run(getConfiguration(), new VectorDistanceSimilarityJob(), args);    DummyOutputCollector<Text, VectorWritable> collector = new DummyOutputCollector<>();    for (Pair<Text, VectorWritable> record : new SequenceFileIterable<Text, VectorWritable>(new Path(output, "part-m-00000"), conf)) {        collector.collect(record.getFirst(), record.getSecond());    }    assertEquals(REFERENCE.length, collector.getData().size());    for (Map.Entry<Text, List<VectorWritable>> entry : collector.getData().entrySet()) {        assertEquals(SEEDS.length, entry.getValue().iterator().next().get().size());    }}
private static List<VectorWritable> mahout_f5160_0(double[][] raw)
{    List<VectorWritable> points = Lists.newArrayList();    for (double[] fr : raw) {        Vector vec = new RandomAccessSparseVector(fr.length);        vec.assign(fr);        points.add(new VectorWritable(vec));    }    return points;}
private static Vector mahout_f5161_0(int size, double entryMean)
{    DenseVector v = new DenseVector(size);    Random r = RandomUtils.getRandom();    for (int i = 0; i < size; ++i) {        v.setQuick(i, r.nextGaussian() * entryMean);    }    return v;}
public void mahout_f5162_0() throws Exception
{    File testData = getTestTempDir("testdata");    DistributedRowMatrix matrix = new TestDistributedRowMatrix().randomDistributedMatrix(10, 10, 10, 10, 10.0, true, testData.getAbsolutePath());    matrix.setConf(getConfiguration());    Vector vector = randomVector(matrix.numCols(), 10.0);    DistributedConjugateGradientSolver solver = new DistributedConjugateGradientSolver();    Vector x = solver.solve(matrix, vector);    Vector solvedVector = matrix.times(x);    double distance = Math.sqrt(vector.getDistanceSquared(solvedVector));    assertEquals(0.0, distance, EPSILON);}
private static Vector mahout_f5163_0(int size, double entryMean)
{    Vector v = new DenseVector(size);    Random r = RandomUtils.getRandom();    for (int i = 0; i < size; ++i) {        v.setQuick(i, r.nextGaussian() * entryMean);    }    return v;}
private static Path mahout_f5164_0(Configuration conf, Path path, Vector v) throws IOException
{    FileSystem fs = path.getFileSystem(conf);    SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, path, IntWritable.class, VectorWritable.class);    try {        writer.append(new IntWritable(0), new VectorWritable(v));    } finally {        writer.close();    }    return path;}
private static Vector mahout_f5165_0(Configuration conf, Path path) throws IOException
{    FileSystem fs = path.getFileSystem(conf);    SequenceFile.Reader reader = new SequenceFile.Reader(fs, path, conf);    Writable key = new IntWritable();    VectorWritable value = new VectorWritable();    try {        if (!reader.next(key, value)) {            throw new IOException("Input vector file is empty.");        }        return value.get();    } finally {        reader.close();    }}
public void mahout_f5166_0() throws Exception
{    Configuration conf = getConfiguration();    Path testData = getTestTempDirPath("testdata");    DistributedRowMatrix matrix = new TestDistributedRowMatrix().randomDistributedMatrix(10, 10, 10, 10, 10.0, true, testData.toString());    matrix.setConf(conf);    Path output = getTestTempFilePath("output");    Path vectorPath = getTestTempFilePath("vector");    Path tempPath = getTestTempDirPath("tmp");    Vector vector = randomVector(matrix.numCols(), 10.0);    saveVector(conf, vectorPath, vector);    String[] args = { "-i", matrix.getRowPath().toString(), "-o", output.toString(), "--tempDir", tempPath.toString(), "--vector", vectorPath.toString(), "--numRows", "10", "--numCols", "10", "--symmetric", "true" };    DistributedConjugateGradientSolver solver = new DistributedConjugateGradientSolver();    ToolRunner.run(getConfiguration(), solver.job(), args);    Vector x = loadVector(conf, output);    Vector solvedVector = matrix.times(x);    double distance = Math.sqrt(vector.getDistanceSquared(solvedVector));    assertEquals(0.0, distance, EPSILON);}
public void mahout_f5167_0() throws Exception
{    super.setUp();    conf = getConfiguration();}
public void mahout_f5168_0() throws Exception
{    Path input = getTestTempFilePath("stdDev/counts.file");    Path output = getTestTempFilePath("stdDev/output.file");    produceTestData(input);    double v = BasicStats.variance(input, output, conf);    assertEquals(2.44, v, 0.01);}
public void mahout_f5169_0() throws Exception
{    Path input = getTestTempFilePath("stdDev/counts.file");    Path output = getTestTempFilePath("stdDev/output.file");    produceTestData(input);    double v = BasicStats.stdDev(input, output, conf);        assertEquals(1.56, v, 0.01);}
public void mahout_f5170_0() throws Exception
{    Path input = getTestTempFilePath("stdDev/counts.file");    Path output = getTestTempFilePath("stdDev/output.file");    produceTestData(input);    double v = BasicStats.stdDevForGivenMean(input, output, 0.0D, conf);        assertEquals(10.65, v, 0.01);}
private void mahout_f5171_0(Path input) throws Exception
{    FileSystem fs = FileSystem.get(input.toUri(), conf);    SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, input, IntWritable.class, DoubleWritable.class);        /*Normal normal = new Normal(5, 3, random);    for (int i = 0; i < 10000; i++) {      writer.append(new IntWritable(i), new DoubleWritable((long)normal.nextDouble()));    }*/    int i = 0;    writer.append(new IntWritable(i++), new DoubleWritable(7));    writer.append(new IntWritable(i++), new DoubleWritable(9));    writer.append(new IntWritable(i++), new DoubleWritable(9));    writer.append(new IntWritable(i++), new DoubleWritable(10));    writer.append(new IntWritable(i++), new DoubleWritable(10));    writer.append(new IntWritable(i++), new DoubleWritable(10));    writer.append(new IntWritable(i++), new DoubleWritable(10));    writer.append(new IntWritable(i++), new DoubleWritable(11));    writer.append(new IntWritable(i++), new DoubleWritable(11));    writer.append(new IntWritable(i++), new DoubleWritable(13));    writer.close();}
public void mahout_f5172_0() throws Exception
{    Path input = getTestTempFilePath("stdDev/counts.file");    Path output = getTestTempFilePath("stdDev/output.file");    FileSystem fs = FileSystem.get(input.toUri(), conf);    SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, input, IntWritable.class, DoubleWritable.class);    Random random = RandomUtils.getRandom();    Normal normal = new Normal(5, 3, random);    for (int i = 0; i < 1000000; i++) {        writer.append(new IntWritable(i), new DoubleWritable((long) normal.nextInt()));    }    writer.close();    double v = BasicStats.stdDev(input, output, conf);    assertEquals(3, v, 0.02);}
public void mahout_f5173_0()
{    final Random rnd = RandomUtils.getRandom();    final long seed = rnd.nextLong();    final int n = 2000;    final int kp = 100;    final Omega omega = new Omega(seed, kp);    final Matrix materializedOmega = new DenseMatrix(n, kp);    for (int i = 0; i < n; i++) for (int j = 0; j < kp; j++) materializedOmega.setQuick(i, j, omega.getQuick(i, j));    Vector xi = new DenseVector(n);    xi.assign(new DoubleFunction() {        @Override        public double apply(double x) {            return rnd.nextDouble() * 100;        }    });    Vector s_o = omega.mutlithreadedTRightMultiply(xi);    Matrix xiVector = new DenseMatrix(n, 1);    xiVector.assignColumn(0, xi);    Vector s_o_control = materializedOmega.transpose().times(xiVector).viewColumn(0);    assertEquals(0, s_o.minus(s_o_control).aggregate(Functions.PLUS, Functions.ABS), 1e-10);    System.out.printf("s_omega=\n%s\n", s_o);    System.out.printf("s_omega_control=\n%s\n", s_o_control);}
public double mahout_f5174_0(double x)
{    return rnd.nextDouble() * 100;}
public void mahout_f5175_0() throws IOException
{    runSSVDSolver(1);}
public void mahout_f5176_0() throws IOException
{    runSSVDSolver(0);}
public void mahout_f5177_0(int q) throws IOException
{    Configuration conf = new Configuration();    conf.set("mapred.job.tracker", "local");    conf.set("fs.default.name", "file:///");            Deque<Closeable> closeables = Lists.newLinkedList();    try {        Random rnd = RandomUtils.getRandom();        File tmpDir = getTestTempDir("svdtmp");        conf.set("hadoop.tmp.dir", tmpDir.getAbsolutePath());        Path aLocPath = new Path(getTestTempDirPath("svdtmp/A"), "A.seq");                SequenceFile.Writer w = SequenceFile.createWriter(FileSystem.getLocal(conf), conf, aLocPath, Text.class, VectorWritable.class, CompressionType.BLOCK, new DefaultCodec());        closeables.addFirst(w);        int n = 100;        int m = 2000;        double percent = 5;        VectorWritable vw = new VectorWritable();        Text rkey = new Text();        Vector xi = new DenseVector(n);        double muAmplitude = 50.0;        for (int i = 0; i < m; i++) {            Vector dv = new SequentialAccessSparseVector(n);            String rowname = "row-" + i;            NamedVector namedRow = new NamedVector(dv, rowname);            for (int j = 0; j < n * percent / 100; j++) {                dv.setQuick(rnd.nextInt(n), muAmplitude * (rnd.nextDouble() - 0.25));            }            rkey.set("row-i" + i);            vw.set(namedRow);            w.append(rkey, vw);            xi.assign(dv, Functions.PLUS);        }        closeables.remove(w);        Closeables.close(w, false);        xi.assign(Functions.mult(1.0 / m));        FileSystem fs = FileSystem.get(conf);        Path tempDirPath = getTestTempDirPath("svd-proc");        Path aPath = new Path(tempDirPath, "A/A.seq");        fs.copyFromLocalFile(aLocPath, aPath);        Path xiPath = new Path(tempDirPath, "xi/xi.seq");        SSVDHelper.saveVector(xi, xiPath, conf);        Path svdOutPath = new Path(tempDirPath, "SSVD-out");                fs.delete(svdOutPath, true);                System.out.println("Input prepared, starting solver...");        int ablockRows = 867;        int p = 60;        int k = 40;        SSVDSolver ssvd = new SSVDSolver(conf, new Path[] { aPath }, svdOutPath, ablockRows, k, p, 3);        ssvd.setOuterBlockHeight(500);        ssvd.setAbtBlockHeight(251);        ssvd.setPcaMeanPath(xiPath);        /*     * Removing V,U jobs from this test to reduce running time. i will keep them     * put in the dense test though.     *     * For PCA test, we also want to request U*Sigma output and check it for named     * vector propagation.     */        ssvd.setComputeU(false);        ssvd.setComputeV(false);        ssvd.setcUSigma(true);        ssvd.setOverwrite(true);        ssvd.setQ(q);        ssvd.setBroadcast(true);        ssvd.run();        Vector stochasticSValues = ssvd.getSingularValues();                Matrix a = SSVDHelper.drmLoadAsDense(fs, aPath, conf);        verifyInternals(svdOutPath, a, new Omega(ssvd.getOmegaSeed(), k + p), k + p, q);                for (int i = 0; i < m; i++) {            a.viewRow(i).assign(xi, Functions.MINUS);        }        SingularValueDecomposition svd2 = new SingularValueDecomposition(a);        Vector svalues2 = new DenseVector(svd2.getSingularValues());        System.out.println("--SSVD solver singular values:");        LocalSSVDSolverSparseSequentialTest.dumpSv(stochasticSValues);        System.out.println("--SVD solver singular values:");        LocalSSVDSolverSparseSequentialTest.dumpSv(svalues2);        for (int i = 0; i < k + p; i++) {            assertTrue(Math.abs(svalues2.getQuick(i) - stochasticSValues.getQuick(i)) <= s_epsilon);        }        DenseMatrix mQ = SSVDHelper.drmLoadAsDense(fs, new Path(svdOutPath, "Bt-job/" + BtJob.OUTPUT_Q + "-*"), conf);        SSVDCommonTest.assertOrthonormality(mQ, false, s_epsilon);                for (Iterator<Pair<Writable, Vector>> iter = SSVDHelper.drmIterator(fs, new Path(ssvd.getuSigmaPath() + "/*"), conf, closeables); iter.hasNext(); ) {            Pair<Writable, Vector> pair = iter.next();            Writable key = pair.getFirst();            Vector v = pair.getSecond();            assertTrue(v instanceof NamedVector);            assertTrue(key instanceof Text);        }    } finally {        IOUtils.close(closeables);    }}
private void mahout_f5178_0(Path tempDir, Matrix a, Omega omega, int kp, int q)
{    int m = a.numRows();    int n = a.numCols();    Vector xi = a.aggregateColumns(new VectorFunction() {        @Override        public double apply(Vector v) {            return v.zSum() / v.size();        }    });        Matrix momega = new DenseMatrix(n, kp);    for (int i = 0; i < n; i++) for (int j = 0; j < kp; j++) momega.setQuick(i, j, omega.getQuick(i, j));    Vector s_o = omega.mutlithreadedTRightMultiply(xi);    System.out.printf("s_omega=\n%s\n", s_o);    Matrix y = a.times(momega);    for (int i = 0; i < n; i++) y.viewRow(i).assign(s_o, Functions.MINUS);    QRDecomposition qr = new QRDecomposition(y);    Matrix qm = qr.getQ();    Vector s_q = qm.aggregateColumns(new VectorFunction() {        @Override        public double apply(Vector v) {            return v.zSum();        }    });    System.out.printf("s_q=\n%s\n", s_q);    Matrix b = qm.transpose().times(a);    Vector s_b = b.times(xi);    System.out.printf("s_b=\n%s\n", s_b);}
public double mahout_f5179_0(Vector v)
{    return v.zSum() / v.size();}
public double mahout_f5180_0(Vector v)
{    return v.zSum();}
public void mahout_f5181_0() throws IOException
{    runSSVDSolver(0);}
public void mahout_f5182_0() throws IOException
{    runSSVDSolver(1);}
public void mahout_f5183_0(int q) throws IOException
{    Configuration conf = getConfiguration();    conf.set("mapred.job.tracker", "local");    conf.set("fs.default.name", "file:///");            File tmpDir = getTestTempDir("svdtmp");    conf.set("hadoop.tmp.dir", tmpDir.getAbsolutePath());    Path aLocPath = new Path(getTestTempDirPath("svdtmp/A"), "A.seq");                                    int n = 100;    int m = 2000;    Vector singularValues = new DenseVector(new double[] { 10, 4, 1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1 });    SSVDTestsHelper.generateDenseInput(aLocPath, FileSystem.getLocal(conf), singularValues, m, n);    FileSystem fs = FileSystem.get(aLocPath.toUri(), conf);    Path tempDirPath = getTestTempDirPath("svd-proc");    Path aPath = new Path(tempDirPath, "A/A.seq");    fs.copyFromLocalFile(aLocPath, aPath);    Path svdOutPath = new Path(tempDirPath, "SSVD-out");        System.out.println("Input prepared, starting solver...");    int ablockRows = 867;    int p = 10;    int k = 3;    SSVDSolver ssvd = new SSVDSolver(conf, new Path[] { aPath }, svdOutPath, ablockRows, k, p, 3);    /*     * these are only tiny-test values to simulate high load cases, in reality     * one needs much bigger     */    ssvd.setOuterBlockHeight(500);    ssvd.setAbtBlockHeight(400);    ssvd.setOverwrite(true);    ssvd.setQ(q);    ssvd.setBroadcast(false);    ssvd.run();    Vector stochasticSValues = ssvd.getSingularValues();    System.out.println("--SSVD solver singular values:");    dumpSv(stochasticSValues);    for (int i = 0; i < k; i++) {        assertTrue(Math.abs((singularValues.getQuick(i) - stochasticSValues.getQuick(i)) / singularValues.getQuick(i)) <= s_precisionPct / 100);    }    DenseMatrix mQ = SSVDHelper.drmLoadAsDense(fs, new Path(svdOutPath, "Bt-job/" + BtJob.OUTPUT_Q + "-*"), conf);    SSVDCommonTest.assertOrthonormality(mQ, false, s_epsilon);    DenseMatrix u = SSVDHelper.drmLoadAsDense(fs, new Path(svdOutPath, "U/*"), conf);    SSVDCommonTest.assertOrthonormality(u, false, s_epsilon);    DenseMatrix v = SSVDHelper.drmLoadAsDense(fs, new Path(svdOutPath, "V/*"), conf);    SSVDCommonTest.assertOrthonormality(v, false, s_epsilon);}
 static void mahout_f5184_0(Vector s)
{    System.out.printf("svs: ");    for (Vector.Element el : s.all()) {        System.out.printf("%f  ", el.get());    }    System.out.println();}
public void mahout_f5185_0() throws IOException
{    runSSVDSolver(1);}
public void mahout_f5186_0(int q) throws IOException
{    Configuration conf = getConfiguration();    conf.set("mapred.job.tracker", "local");    conf.set("fs.default.name", "file:///");            Deque<Closeable> closeables = Lists.newLinkedList();    ;    Random rnd = RandomUtils.getRandom();    File tmpDir = getTestTempDir("svdtmp");    conf.set("hadoop.tmp.dir", tmpDir.getAbsolutePath());    Path aLocPath = new Path(getTestTempDirPath("svdtmp/A"), "A.seq");        SequenceFile.Writer w = SequenceFile.createWriter(FileSystem.getLocal(conf), conf, aLocPath, IntWritable.class, VectorWritable.class, CompressionType.BLOCK, new DefaultCodec());    closeables.addFirst(w);    int n = 100;    int m = 2000;    double percent = 5;    VectorWritable vw = new VectorWritable();    IntWritable roww = new IntWritable();    double muAmplitude = 50.0;    for (int i = 0; i < m; i++) {        Vector dv = new SequentialAccessSparseVector(n);        for (int j = 0; j < n * percent / 100; j++) {            dv.setQuick(rnd.nextInt(n), muAmplitude * (rnd.nextDouble() - 0.5));        }        roww.set(i);        vw.set(dv);        w.append(roww, vw);    }    closeables.remove(w);    Closeables.close(w, false);    FileSystem fs = FileSystem.get(aLocPath.toUri(), conf);    Path tempDirPath = getTestTempDirPath("svd-proc");    Path aPath = new Path(tempDirPath, "A/A.seq");    fs.copyFromLocalFile(aLocPath, aPath);    Path svdOutPath = new Path(tempDirPath, "SSVD-out");        fs.delete(svdOutPath, true);        System.out.println("Input prepared, starting solver...");    int ablockRows = 867;    int p = 60;    int k = 40;    SSVDSolver ssvd = new SSVDSolver(conf, new Path[] { aPath }, svdOutPath, ablockRows, k, p, 3);    ssvd.setOuterBlockHeight(500);    ssvd.setAbtBlockHeight(251);    /*     * removing V,U jobs from this test to reduce running time. i will keep them     * put in the dense test though.     */    ssvd.setComputeU(false);    ssvd.setComputeV(false);    ssvd.setOverwrite(true);    ssvd.setQ(q);    ssvd.setBroadcast(true);    ssvd.run();    Vector stochasticSValues = ssvd.getSingularValues();    System.out.println("--SSVD solver singular values:");    dumpSv(stochasticSValues);    System.out.println("--Colt SVD solver singular values:");        DenseMatrix a = SSVDHelper.drmLoadAsDense(fs, aPath, conf);            SingularValueDecomposition svd2 = new SingularValueDecomposition(a);    Vector svalues2 = new DenseVector(svd2.getSingularValues());    dumpSv(svalues2);    for (int i = 0; i < k + p; i++) {        assertTrue(Math.abs(svalues2.getQuick(i) - stochasticSValues.getQuick(i)) <= s_epsilon);    }    DenseMatrix mQ = SSVDHelper.drmLoadAsDense(fs, new Path(svdOutPath, "Bt-job/" + BtJob.OUTPUT_Q + "-*"), conf);    SSVDCommonTest.assertOrthonormality(mQ, false, s_epsilon);    IOUtils.close(closeables);}
 static void mahout_f5187_0(Vector s)
{    System.out.printf("svs: ");    for (Vector.Element el : s.all()) {        System.out.printf("%f  ", el.get());    }    System.out.println();}
 static void mahout_f5188_0(double[][] matrix)
{    for (double[] aMatrix : matrix) {        for (double anAMatrix : aMatrix) {            System.out.printf("%f  ", anAMatrix);        }        System.out.println();    }}
public void mahout_f5189_0() throws Exception
{        Matrix m = new DenseMatrix(3, 3);    m.assign(new DoubleFunction() {        private final Random rnd = RandomUtils.getRandom();        @Override        public double apply(double arg0) {            return rnd.nextDouble() * SCALE;        }    });    m.setQuick(0, 0, 1);    m.setQuick(0, 1, 2);    m.setQuick(0, 2, 3);    m.setQuick(1, 0, 4);    m.setQuick(1, 1, 5);    m.setQuick(1, 2, 6);    m.setQuick(2, 0, 7);    m.setQuick(2, 1, 8);    m.setQuick(2, 2, 9);    GivensThinSolver qrSolver = new GivensThinSolver(m.rowSize(), m.columnSize());    qrSolver.solve(m);    Matrix qtm = new DenseMatrix(qrSolver.getThinQtTilde());    assertOrthonormality(qtm.transpose(), false, SVD_EPSILON);    Matrix aClone = new DenseMatrix(qrSolver.getThinQtTilde()).transpose().times(qrSolver.getRTilde());    System.out.println("aclone : " + aClone);}
public double mahout_f5190_0(double arg0)
{    return rnd.nextDouble() * SCALE;}
public static void mahout_f5191_0(Matrix mtx, boolean insufficientRank, double epsilon)
{    int n = mtx.columnSize();    int rank = 0;    for (int i = 0; i < n; i++) {        Vector ei = mtx.viewColumn(i);        double norm = ei.norm(2);        if (Math.abs(1 - norm) < epsilon) {            rank++;        } else {            assertTrue(Math.abs(norm) < epsilon);        }        for (int j = 0; j <= i; j++) {            Vector e_j = mtx.viewColumn(j);            double dot = ei.dot(e_j);            assertTrue(Math.abs((i == j && rank > j ? 1 : 0) - dot) < epsilon);        }    }    assertTrue((!insufficientRank && rank == n) || (insufficientRank && rank < n));}
 static void mahout_f5192_0(Path outputPath, FileSystem dfs, Vector svalues, int m, int n) throws IOException
{    generateDenseInput(outputPath, dfs, svalues, m, n, 0);}
 static void mahout_f5193_0(Path outputPath, FileSystem dfs, Vector svalues, int m, int n, int startRowKey) throws IOException
{    Random rnd = RandomUtils.getRandom();    int svCnt = svalues.size();    Matrix v = generateDenseOrthonormalRandom(n, svCnt, rnd);    Matrix u = generateDenseOrthonormalRandom(m, svCnt, rnd);        Matrix mx = m > n ? v : u;    for (int i = 0; i < svCnt; i++) {        mx.assignColumn(i, mx.viewColumn(i).times(svalues.getQuick(i)));    }    SequenceFile.Writer w = SequenceFile.createWriter(dfs, dfs.getConf(), outputPath, IntWritable.class, VectorWritable.class);    try {        Vector outV = new DenseVector(n);        Writable vw = new VectorWritable(outV);        IntWritable iw = new IntWritable();        for (int i = 0; i < m; i++) {            iw.set(startRowKey + i);            for (int j = 0; j < n; j++) {                outV.setQuick(j, u.viewRow(i).dot(v.viewRow(j)));            }            w.append(iw, vw);        }    } finally {        w.close();    }}
 static Matrix mahout_f5194_0(int m, int n, Random rnd)
{    Matrix result = new DenseMatrix(m, n);    for (int j = 0; j < n; j++) {        for (int i = 0; i < m; i++) {            result.setQuick(i, j, rnd.nextDouble() - 0.5);        }    }    GramSchmidt.orthonormalizeColumns(result);    SSVDCommonTest.assertOrthonormality(result, false, 1.0e-10);    return result;}
public static void mahout_f5195_0(String[] args) throws Exception
{        MahoutTestCase ca = new MahoutTestCase();    Configuration conf = ca.getConfiguration();    FileSystem dfs = FileSystem.getLocal(conf);    Path outputDir = new Path("/tmp/DRM");    dfs.mkdirs(outputDir);                            /*     *  create 2Gb sparse 4.5 m x 4.5m input . (similar to wikipedia graph).     *       *  In order to get at 2Gb, we need to generate ~ 40 non-zero items per row average.     *        */    outputDir = new Path("/tmp/DRM-sparse");    Random rnd = RandomUtils.getRandom();    SequenceFile.Writer w = SequenceFile.createWriter(dfs, dfs.getConf(), new Path(outputDir, "sparse.seq"), IntWritable.class, VectorWritable.class);    try {        IntWritable iw = new IntWritable();        VectorWritable vw = new VectorWritable();        int avgNZero = 40;        int n = 4500000;        for (int i = 1; i < n; i++) {            Vector vector = new RandomAccessSparseVector(n);            double nz = Math.round(avgNZero * (rnd.nextGaussian() + 1));            if (nz < 0) {                nz = 0;            }            for (int j = 1; j < nz; j++) {                vector.set(rnd.nextInt(n), rnd.nextGaussian() * 25 + 3);            }            iw.set(i);            vw.set(vector);            w.append(iw, vw);        }    } finally {        w.close();    }}
private static void mahout_f5196_0(VectorIterable m, VectorIterable mtt, double errorTolerance)
{    Iterator<MatrixSlice> mIt = m.iterateAll();    Iterator<MatrixSlice> mttIt = mtt.iterateAll();    Map<Integer, Vector> mMap = Maps.newHashMap();    Map<Integer, Vector> mttMap = Maps.newHashMap();    while (mIt.hasNext() && mttIt.hasNext()) {        MatrixSlice ms = mIt.next();        mMap.put(ms.index(), ms.vector());        MatrixSlice mtts = mttIt.next();        mttMap.put(mtts.index(), mtts.vector());    }    for (Map.Entry<Integer, Vector> entry : mMap.entrySet()) {        Integer key = entry.getKey();        Vector value = entry.getValue();        if (value == null || mttMap.get(key) == null) {            assertTrue(value == null || value.norm(2) == 0);            assertTrue(mttMap.get(key) == null || mttMap.get(key).norm(2) == 0);        } else {            assertTrue(value.getDistanceSquared(mttMap.get(key)) < errorTolerance);        }    }}
public void mahout_f5197_0() throws Exception
{    DistributedRowMatrix m = randomDistributedMatrix(10, 9, 5, 4, 1.0, false);    m.setConf(getConfiguration());    DistributedRowMatrix mt = m.transpose();    mt.setConf(getConfiguration());    Path tmpPath = getTestTempDirPath();    m.setOutputTempPathString(tmpPath.toString());    Path tmpOutPath = new Path(tmpPath, "/tmpOutTranspose");    mt.setOutputTempPathString(tmpOutPath.toString());    HadoopUtil.delete(getConfiguration(), tmpOutPath);    DistributedRowMatrix mtt = mt.transpose();    assertEquals(m, mtt, EPSILON);}
public void mahout_f5198_0() throws Exception
{    Matrix m = SolverTest.randomSequentialAccessSparseMatrix(100, 90, 50, 20, 1.0);    DistributedRowMatrix dm = randomDistributedMatrix(100, 90, 50, 20, 1.0, false);    dm.setConf(getConfiguration());    Vector expected = new DenseVector(50);    for (int i = 0; i < m.numRows(); i++) {        expected.assign(m.viewRow(i), Functions.PLUS);    }    expected.assign(Functions.DIV, m.numRows());    Vector actual = dm.columnMeans("DenseVector");    assertEquals(0.0, expected.getDistanceSquared(actual), EPSILON);}
public void mahout_f5199_0() throws Exception
{    Matrix m = SolverTest.randomSequentialAccessSparseMatrix(100, 90, 0, 0, 1.0);    DistributedRowMatrix dm = randomDistributedMatrix(100, 90, 0, 0, 1.0, false);    dm.setConf(getConfiguration());    Vector expected = new DenseVector(0);    for (int i = 0; i < m.numRows(); i++) {        expected.assign(m.viewRow(i), Functions.PLUS);    }    expected.assign(Functions.DIV, m.numRows());    Vector actual = dm.columnMeans();    assertEquals(0.0, expected.getDistanceSquared(actual), EPSILON);}
public void mahout_f5200_0() throws Exception
{    Vector v = new RandomAccessSparseVector(50);    v.assign(1.0);    Matrix m = SolverTest.randomSequentialAccessSparseMatrix(100, 90, 50, 20, 1.0);    DistributedRowMatrix dm = randomDistributedMatrix(100, 90, 50, 20, 1.0, false);    dm.setConf(getConfiguration());    Vector expected = m.times(v);    Vector actual = dm.times(v);    assertEquals(0.0, expected.getDistanceSquared(actual), EPSILON);}
public void mahout_f5201_0() throws Exception
{    Vector v = new RandomAccessSparseVector(50);    v.assign(1.0);    Matrix m = SolverTest.randomSequentialAccessSparseMatrix(100, 90, 50, 20, 1.0);    DistributedRowMatrix dm = randomDistributedMatrix(100, 90, 50, 20, 1.0, false);    dm.setConf(getConfiguration());    Vector expected = m.timesSquared(v);    Vector actual = dm.timesSquared(v);    assertEquals(0.0, expected.getDistanceSquared(actual), 1.0e-9);}
public void mahout_f5202_0() throws Exception
{    Matrix inputA = SolverTest.randomSequentialAccessSparseMatrix(20, 19, 15, 5, 10.0);    Matrix inputB = SolverTest.randomSequentialAccessSparseMatrix(20, 13, 25, 10, 5.0);    Matrix expected = inputA.transpose().times(inputB);    DistributedRowMatrix distA = randomDistributedMatrix(20, 19, 15, 5, 10.0, false, "distA");    distA.setConf(getConfiguration());    DistributedRowMatrix distB = randomDistributedMatrix(20, 13, 25, 10, 5.0, false, "distB");    distB.setConf(getConfiguration());    DistributedRowMatrix product = distA.times(distB);    assertEquals(expected, product, EPSILON);}
public void mahout_f5203_0() throws Exception
{    Configuration initialConf = createInitialConf();    Path baseTmpDirPath = getTestTempDirPath("testpaths");    Path aPath = new Path(baseTmpDirPath, "a");    Path bPath = new Path(baseTmpDirPath, "b");    Path outPath = new Path(baseTmpDirPath, "out");    Configuration mmJobConf = MatrixMultiplicationJob.createMatrixMultiplyJobConf(aPath, bPath, outPath, 10);    Configuration mmCustomJobConf = MatrixMultiplicationJob.createMatrixMultiplyJobConf(initialConf, aPath, bPath, outPath, 10);    assertNull(mmJobConf.get(TEST_PROPERTY_KEY));    assertEquals(TEST_PROPERTY_VALUE, mmCustomJobConf.get(TEST_PROPERTY_KEY));}
public void mahout_f5204_0() throws Exception
{    Configuration initialConf = createInitialConf();    Path baseTmpDirPath = getTestTempDirPath("testpaths");    Path inputPath = new Path(baseTmpDirPath, "input");    Path outputPath = new Path(baseTmpDirPath, "output");    Configuration transposeJobConf = TransposeJob.buildTransposeJob(inputPath, outputPath, 10).getConfiguration();    Configuration transposeCustomJobConf = TransposeJob.buildTransposeJob(initialConf, inputPath, outputPath, 10).getConfiguration();    assertNull(transposeJobConf.get(TEST_PROPERTY_KEY));    assertEquals(TEST_PROPERTY_VALUE, transposeCustomJobConf.get(TEST_PROPERTY_KEY));}
public void mahout_f5205_0() throws Exception
{    Configuration initialConf = createInitialConf();    Path baseTmpDirPath = getTestTempDirPath("testpaths");    Path inputPath = new Path(baseTmpDirPath, "input");    Path outputPath = new Path(baseTmpDirPath, "output");    Vector v = new RandomAccessSparseVector(50);    v.assign(1.0);    Job timesSquaredJob1 = TimesSquaredJob.createTimesSquaredJob(v, inputPath, outputPath);    Job customTimesSquaredJob1 = TimesSquaredJob.createTimesSquaredJob(initialConf, v, inputPath, outputPath);    assertNull(timesSquaredJob1.getConfiguration().get(TEST_PROPERTY_KEY));    assertEquals(TEST_PROPERTY_VALUE, customTimesSquaredJob1.getConfiguration().get(TEST_PROPERTY_KEY));    Job timesJob = TimesSquaredJob.createTimesJob(v, 50, inputPath, outputPath);    Job customTimesJob = TimesSquaredJob.createTimesJob(initialConf, v, 50, inputPath, outputPath);    assertNull(timesJob.getConfiguration().get(TEST_PROPERTY_KEY));    assertEquals(TEST_PROPERTY_VALUE, customTimesJob.getConfiguration().get(TEST_PROPERTY_KEY));    Job timesSquaredJob2 = TimesSquaredJob.createTimesSquaredJob(v, inputPath, outputPath, TimesSquaredJob.TimesSquaredMapper.class, TimesSquaredJob.VectorSummingReducer.class);    Job customTimesSquaredJob2 = TimesSquaredJob.createTimesSquaredJob(initialConf, v, inputPath, outputPath, TimesSquaredJob.TimesSquaredMapper.class, TimesSquaredJob.VectorSummingReducer.class);    assertNull(timesSquaredJob2.getConfiguration().get(TEST_PROPERTY_KEY));    assertEquals(TEST_PROPERTY_VALUE, customTimesSquaredJob2.getConfiguration().get(TEST_PROPERTY_KEY));    Job timesSquaredJob3 = TimesSquaredJob.createTimesSquaredJob(v, 50, inputPath, outputPath, TimesSquaredJob.TimesSquaredMapper.class, TimesSquaredJob.VectorSummingReducer.class);    Job customTimesSquaredJob3 = TimesSquaredJob.createTimesSquaredJob(initialConf, v, 50, inputPath, outputPath, TimesSquaredJob.TimesSquaredMapper.class, TimesSquaredJob.VectorSummingReducer.class);    assertNull(timesSquaredJob3.getConfiguration().get(TEST_PROPERTY_KEY));    assertEquals(TEST_PROPERTY_VALUE, customTimesSquaredJob3.getConfiguration().get(TEST_PROPERTY_KEY));}
public void mahout_f5206_0() throws Exception
{    Configuration conf = getConfiguration();    Vector v = new RandomAccessSparseVector(50);    v.assign(1.0);    DistributedRowMatrix dm = randomDistributedMatrix(100, 90, 50, 20, 1.0, false);    dm.setConf(conf);    Path outputPath = dm.getOutputTempPath();    FileSystem fs = outputPath.getFileSystem(conf);    deleteContentsOfPath(conf, outputPath);    assertEquals(0, HadoopUtil.listStatus(fs, outputPath).length);    Vector result1 = dm.times(v);    assertEquals(0, HadoopUtil.listStatus(fs, outputPath).length);    deleteContentsOfPath(conf, outputPath);    assertEquals(0, HadoopUtil.listStatus(fs, outputPath).length);    conf.setBoolean(DistributedRowMatrix.KEEP_TEMP_FILES, true);    dm.setConf(conf);    Vector result2 = dm.times(v);    FileStatus[] outputStatuses = fs.listStatus(outputPath);    assertEquals(1, outputStatuses.length);    Path outputTempPath = outputStatuses[0].getPath();    Path inputVectorPath = new Path(outputTempPath, TimesSquaredJob.INPUT_VECTOR);    Path outputVectorPath = new Path(outputTempPath, TimesSquaredJob.OUTPUT_VECTOR_FILENAME);    assertEquals(1, fs.listStatus(inputVectorPath, PathFilters.logsCRCFilter()).length);    assertEquals(1, fs.listStatus(outputVectorPath, PathFilters.logsCRCFilter()).length);    assertEquals(0.0, result1.getDistanceSquared(result2), EPSILON);}
public void mahout_f5207_0() throws Exception
{    Configuration conf = getConfiguration();    Vector v = new RandomAccessSparseVector(50);    v.assign(1.0);    DistributedRowMatrix dm = randomDistributedMatrix(100, 90, 50, 20, 1.0, false);    dm.setConf(getConfiguration());    Path outputPath = dm.getOutputTempPath();    FileSystem fs = outputPath.getFileSystem(conf);    deleteContentsOfPath(conf, outputPath);    assertEquals(0, HadoopUtil.listStatus(fs, outputPath).length);    Vector result1 = dm.timesSquared(v);    assertEquals(0, HadoopUtil.listStatus(fs, outputPath).length);    deleteContentsOfPath(conf, outputPath);    assertEquals(0, HadoopUtil.listStatus(fs, outputPath).length);    conf.setBoolean(DistributedRowMatrix.KEEP_TEMP_FILES, true);    dm.setConf(conf);    Vector result2 = dm.timesSquared(v);    FileStatus[] outputStatuses = fs.listStatus(outputPath);    assertEquals(1, outputStatuses.length);    Path outputTempPath = outputStatuses[0].getPath();    Path inputVectorPath = new Path(outputTempPath, TimesSquaredJob.INPUT_VECTOR);    Path outputVectorPath = new Path(outputTempPath, TimesSquaredJob.OUTPUT_VECTOR_FILENAME);    assertEquals(1, fs.listStatus(inputVectorPath, PathFilters.logsCRCFilter()).length);    assertEquals(1, fs.listStatus(outputVectorPath, PathFilters.logsCRCFilter()).length);    assertEquals(0.0, result1.getDistanceSquared(result2), EPSILON);}
public Configuration mahout_f5208_0() throws IOException
{    Configuration initialConf = getConfiguration();    initialConf.set(TEST_PROPERTY_KEY, TEST_PROPERTY_VALUE);    return initialConf;}
private static void mahout_f5209_0(Configuration conf, Path path) throws Exception
{    FileSystem fs = path.getFileSystem(conf);    FileStatus[] statuses = HadoopUtil.listStatus(fs, path);    for (FileStatus status : statuses) {        fs.delete(status.getPath(), true);    }}
public DistributedRowMatrix mahout_f5210_0(int numRows, int nonNullRows, int numCols, int entriesPerRow, double entryMean, boolean isSymmetric) throws IOException
{    return randomDistributedMatrix(numRows, nonNullRows, numCols, entriesPerRow, entryMean, isSymmetric, "testdata");}
public DistributedRowMatrix mahout_f5211_0(int numRows, int numCols, boolean isSymmetric, String baseTmpDirSuffix) throws IOException
{    Path baseTmpDirPath = getTestTempDirPath(baseTmpDirSuffix);    Matrix c = SolverTest.randomHierarchicalMatrix(numRows, numCols, isSymmetric);    return saveToFs(c, baseTmpDirPath);}
public DistributedRowMatrix mahout_f5212_0(int numRows, int nonNullRows, int numCols, int entriesPerRow, double entryMean, boolean isSymmetric, String baseTmpDirSuffix) throws IOException
{    Path baseTmpDirPath = getTestTempDirPath(baseTmpDirSuffix);    Matrix c = SolverTest.randomSequentialAccessSparseMatrix(numRows, nonNullRows, numCols, entriesPerRow, entryMean);    if (isSymmetric) {        c = c.times(c.transpose());    }    return saveToFs(c, baseTmpDirPath);}
private DistributedRowMatrix mahout_f5213_0(final Matrix m, Path baseTmpDirPath) throws IOException
{    Configuration conf = getConfiguration();    FileSystem fs = FileSystem.get(baseTmpDirPath.toUri(), conf);    ClusteringTestUtils.writePointsToFile(new Iterable<VectorWritable>() {        @Override        public Iterator<VectorWritable> iterator() {            return Iterators.transform(m.iterator(), new Function<MatrixSlice, VectorWritable>() {                @Override                public VectorWritable apply(MatrixSlice input) {                    return new VectorWritable(input.vector());                }            });        }    }, true, new Path(baseTmpDirPath, "distMatrix/part-00000"), fs, conf);    DistributedRowMatrix distMatrix = new DistributedRowMatrix(new Path(baseTmpDirPath, "distMatrix"), new Path(baseTmpDirPath, "tmpOut"), m.numRows(), m.numCols());    distMatrix.setConf(new Configuration(conf));    return distMatrix;}
public Iterator<VectorWritable> mahout_f5214_0()
{    return Iterators.transform(m.iterator(), new Function<MatrixSlice, VectorWritable>() {        @Override        public VectorWritable apply(MatrixSlice input) {            return new VectorWritable(input.vector());        }    });}
public VectorWritable mahout_f5215_0(MatrixSlice input)
{    return new VectorWritable(input.vector());}
public void mahout_f5216_0() throws Exception
{    Matrix m = new SparseMatrix(5, 5);    m.set(1, 2, 3.0);    m.set(3, 4, 5.0);    Map<String, Integer> bindings = Maps.newHashMap();    bindings.put("A", 0);    bindings.put("B", 1);    bindings.put("C", 2);    bindings.put("D", 3);    bindings.put("default", 4);    m.setRowLabelBindings(bindings);    m.setColumnLabelBindings(bindings);    doTestMatrixWritableEquals(m);}
public void mahout_f5217_0() throws Exception
{    Matrix m = new SparseRowMatrix(5, 5);    m.set(1, 2, 3.0);    m.set(3, 4, 5.0);    Map<String, Integer> bindings = Maps.newHashMap();    bindings.put("A", 0);    bindings.put("B", 1);    bindings.put("C", 2);    bindings.put("D", 3);    bindings.put("default", 4);    m.setRowLabelBindings(bindings);    m.setColumnLabelBindings(bindings);    doTestMatrixWritableEquals(m);}
public void mahout_f5218_0() throws Exception
{    Matrix m = new DenseMatrix(5, 5);    m.set(1, 2, 3.0);    m.set(3, 4, 5.0);    Map<String, Integer> bindings = Maps.newHashMap();    bindings.put("A", 0);    bindings.put("B", 1);    bindings.put("C", 2);    bindings.put("D", 3);    bindings.put("default", 4);    m.setRowLabelBindings(bindings);    m.setColumnLabelBindings(bindings);    doTestMatrixWritableEquals(m);}
private static void mahout_f5219_0(Matrix m) throws IOException
{    Writable matrixWritable = new MatrixWritable(m);    MatrixWritable matrixWritable2 = new MatrixWritable();    writeAndRead(matrixWritable, matrixWritable2);    Matrix m2 = matrixWritable2.get();    compareMatrices(m, m2);    doCheckBindings(m2.getRowLabelBindings());    doCheckBindings(m2.getColumnLabelBindings());}
private static void mahout_f5220_0(Matrix m, Matrix m2)
{    assertEquals(m.numRows(), m2.numRows());    assertEquals(m.numCols(), m2.numCols());    for (int r = 0; r < m.numRows(); r++) {        for (int c = 0; c < m.numCols(); c++) {            assertEquals(m.get(r, c), m2.get(r, c), EPSILON);        }    }    Map<String, Integer> bindings = m.getRowLabelBindings();    Map<String, Integer> bindings2 = m2.getRowLabelBindings();    assertEquals(bindings == null, bindings2 == null);    if (bindings != null) {        assertEquals(bindings.size(), m.numRows());        assertEquals(bindings.size(), bindings2.size());        for (Map.Entry<String, Integer> entry : bindings.entrySet()) {            assertEquals(entry.getValue(), bindings2.get(entry.getKey()));        }    }    bindings = m.getColumnLabelBindings();    bindings2 = m2.getColumnLabelBindings();    assertEquals(bindings == null, bindings2 == null);    if (bindings != null) {        assertEquals(bindings.size(), bindings2.size());        for (Map.Entry<String, Integer> entry : bindings.entrySet()) {            assertEquals(entry.getValue(), bindings2.get(entry.getKey()));        }    }}
private static void mahout_f5221_0(Map<String, Integer> labels)
{    assertTrue("Missing label", labels.keySet().contains("A"));    assertTrue("Missing label", labels.keySet().contains("B"));    assertTrue("Missing label", labels.keySet().contains("C"));    assertTrue("Missing label", labels.keySet().contains("D"));    assertTrue("Missing label", labels.keySet().contains("default"));}
private static void mahout_f5222_0(Writable toWrite, Writable toRead) throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    DataOutputStream dos = new DataOutputStream(baos);    try {        toWrite.write(dos);    } finally {        Closeables.close(dos, false);    }    ByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray());    DataInputStream dis = new DataInputStream(bais);    try {        toRead.readFields(dis);    } finally {        Closeables.close(dis, true);    }}
public void mahout_f5223_0()
{    Matrix testData = new DenseMatrix(100000, 10);    final Normal gen = new Normal();    testData.assign(gen);    final EuclideanDistanceMeasure distance = new EuclideanDistanceMeasure();    BruteSearch ref = new BruteSearch(distance);    ref.addAllMatrixSlicesAsWeightedVectors(testData);    LocalitySensitiveHashSearch cut = new LocalitySensitiveHashSearch(distance, 10);    cut.addAllMatrixSlicesAsWeightedVectors(testData);    cut.setSearchSize(200);    cut.resetEvaluationCount();    System.out.printf("speedup,q1,q2,q3\n");    for (int i = 0; i < 12; i++) {        double strategy = (i - 1.0) / 10.0;        cut.setRaiseHashLimitStrategy(strategy);        OnlineSummarizer t1 = evaluateStrategy(testData, ref, cut);        int evals = cut.resetEvaluationCount();        final double speedup = 10.0e6 / evals;        System.out.printf("%.1f,%.2f,%.2f,%.2f\n", speedup, t1.getQuartile(1), t1.getQuartile(2), t1.getQuartile(3));        assertTrue(t1.getQuartile(2) > 0.45);        assertTrue(speedup > 4 || t1.getQuartile(2) > 0.9);        assertTrue(speedup > 15 || t1.getQuartile(2) > 0.8);    }}
private static OnlineSummarizer mahout_f5224_0(Matrix testData, BruteSearch ref, LocalitySensitiveHashSearch cut)
{    OnlineSummarizer t1 = new OnlineSummarizer();    for (int i = 0; i < 100; i++) {        final Vector q = testData.viewRow(i);        List<WeightedThing<Vector>> v1 = cut.search(q, 150);        BitSet b1 = new BitSet();        for (WeightedThing<Vector> v : v1) {            b1.set(((WeightedVector) v.getValue()).getIndex());        }        List<WeightedThing<Vector>> v2 = ref.search(q, 100);        BitSet b2 = new BitSet();        for (WeightedThing<Vector> v : v2) {            b2.set(((WeightedVector) v.getValue()).getIndex());        }        b1.and(b2);        t1.add(b1.cardinality());    }    return t1;}
public void mahout_f5225_0()
{    final Normal gen = new Normal();    Matrix projection = new DenseMatrix(64, 10);    projection.assign(gen);    Vector query = new DenseVector(10);    query.assign(gen);    long qhash = HashedVector.computeHash64(query, projection);    int[] count = new int[65];    Vector v = new DenseVector(10);    for (int i = 0; i < 500000; i++) {        v.assign(gen);        long hash = HashedVector.computeHash64(v, projection);        final int bitDot = Long.bitCount(qhash ^ hash);        count[bitDot]++;        if (count[bitDot] < 200) {            System.out.printf("%d, %.3f\n", bitDot, v.dot(query) / Math.sqrt(v.getLengthSquared() * query.getLengthSquared()));        }    }    for (int i = 0; i < 65; ++i) {        System.out.printf("%d, %d\n", i, count[i]);    }}
public static Matrix mahout_f5226_0(int numDataPoints, int numDimensions)
{    final Matrix data = new DenseMatrix(numDataPoints, numDimensions);    final LumpyData clusters = new LumpyData(numDimensions, 0.05, 10);    for (MatrixSlice row : data) {        row.vector().assign(clusters.sample());    }    return data;}
public Vector mahout_f5227_0()
{    int id = cluster.sample();    if (id >= centroids.size()) {                centroids.add(new MultiNormal(radius, centers.sample()));    }    return centroids.get(id).sample();}
public static List<Object[]> mahout_f5228_0()
{    RandomUtils.useTestSeed();    Matrix dataPoints = LumpyData.lumpyRandomData(NUM_DATA_POINTS, NUM_DIMENSIONS);    Matrix queries = LumpyData.lumpyRandomData(NUM_QUERIES, NUM_DIMENSIONS);    DistanceMeasure distanceMeasure = new CosineDistanceMeasure();    Searcher bruteSearcher = new BruteSearch(distanceMeasure);    bruteSearcher.addAll(dataPoints);    Pair<List<List<WeightedThing<Vector>>>, Long> reference = getResultsAndRuntime(bruteSearcher, queries);    Pair<List<WeightedThing<Vector>>, Long> referenceSearchFirst = getResultsAndRuntimeSearchFirst(bruteSearcher, queries);    double bruteSearchAvgTime = reference.getSecond() / (queries.numRows() * 1.0);    System.out.printf("BruteSearch: avg_time(1 query) %f[s]\n", bruteSearchAvgTime);    return Arrays.asList(new Object[][] {     { new ProjectionSearch(distanceMeasure, 3, 10), dataPoints, queries, reference, referenceSearchFirst }, { new FastProjectionSearch(distanceMeasure, 3, 10), dataPoints, queries, reference, referenceSearchFirst },     { new ProjectionSearch(distanceMeasure, 5, 5), dataPoints, queries, reference, referenceSearchFirst }, { new FastProjectionSearch(distanceMeasure, 5, 5), dataPoints, queries, reference, referenceSearchFirst } });}
public void mahout_f5229_0()
{    searcher.clear();    searcher.addAll(dataPoints);    Pair<List<WeightedThing<Vector>>, Long> results = getResultsAndRuntimeSearchFirst(searcher, queries);    int numFirstMatches = 0;    for (int i = 0; i < queries.numRows(); ++i) {        WeightedThing<Vector> referenceVector = referenceSearchFirst.getFirst().get(i);        WeightedThing<Vector> resultVector = results.getFirst().get(i);        if (referenceVector.getValue().equals(resultVector.getValue())) {            ++numFirstMatches;        }    }    double bruteSearchAvgTime = reference.getSecond() / (queries.numRows() * 1.0);    double searcherAvgTime = results.getSecond() / (queries.numRows() * 1.0);    System.out.printf("%s: first matches %d [%d]; avg_time(1 query) %f(s) [%f]\n", searcher.getClass().getName(), numFirstMatches, queries.numRows(), searcherAvgTime, bruteSearchAvgTime);    assertEquals("Closest vector returned doesn't match", queries.numRows(), numFirstMatches);    assertTrue("Searcher " + searcher.getClass().getName() + " slower than brute", bruteSearchAvgTime > searcherAvgTime);}
public void mahout_f5230_0()
{    searcher.clear();    searcher.addAll(dataPoints);    Pair<List<List<WeightedThing<Vector>>>, Long> results = getResultsAndRuntime(searcher, queries);    int numFirstMatches = 0;    int numMatches = 0;    StripWeight stripWeight = new StripWeight();    for (int i = 0; i < queries.numRows(); ++i) {        List<WeightedThing<Vector>> referenceVectors = reference.getFirst().get(i);        List<WeightedThing<Vector>> resultVectors = results.getFirst().get(i);        if (referenceVectors.get(0).getValue().equals(resultVectors.get(0).getValue())) {            ++numFirstMatches;        }        for (Vector v : Iterables.transform(referenceVectors, stripWeight)) {            for (Vector w : Iterables.transform(resultVectors, stripWeight)) {                if (v.equals(w)) {                    ++numMatches;                }            }        }    }    double bruteSearchAvgTime = reference.getSecond() / (queries.numRows() * 1.0);    double searcherAvgTime = results.getSecond() / (queries.numRows() * 1.0);    System.out.printf("%s: first matches %d [%d]; total matches %d [%d]; avg_time(1 query) %f(s) [%f]\n", searcher.getClass().getName(), numFirstMatches, queries.numRows(), numMatches, queries.numRows() * NUM_RESULTS, searcherAvgTime, bruteSearchAvgTime);    assertEquals("Closest vector returned doesn't match", queries.numRows(), numFirstMatches);    assertTrue("Searcher " + searcher.getClass().getName() + " slower than brute", bruteSearchAvgTime > searcherAvgTime);}
public static Pair<List<List<WeightedThing<Vector>>>, Long> mahout_f5231_0(Searcher searcher, Iterable<? extends Vector> queries)
{    long start = System.currentTimeMillis();    List<List<WeightedThing<Vector>>> results = searcher.search(queries, NUM_RESULTS);    long end = System.currentTimeMillis();    return new Pair<>(results, end - start);}
public static Pair<List<WeightedThing<Vector>>, Long> mahout_f5232_0(Searcher searcher, Iterable<? extends Vector> queries)
{    long start = System.currentTimeMillis();    List<WeightedThing<Vector>> results = searcher.searchFirst(queries, false);    long end = System.currentTimeMillis();    return new Pair<>(results, end - start);}
public Vector mahout_f5233_0(WeightedThing<Vector> input)
{    Preconditions.checkArgument(input != null, "input is null");        return input.getValue();}
protected static Matrix mahout_f5234_0(int numDataPoints, int numDimensions)
{    Matrix data = new DenseMatrix(numDataPoints, numDimensions);    MultiNormal gen = new MultiNormal(20);    for (MatrixSlice slice : data) {        slice.vector().assign(gen.sample());    }    return data;}
public static List<Object[]> mahout_f5235_0()
{    RandomUtils.useTestSeed();    Matrix dataPoints = multiNormalRandomData(NUM_DATA_POINTS, NUM_DIMENSIONS);    return Arrays.asList(new Object[][] { { new ProjectionSearch(new EuclideanDistanceMeasure(), NUM_PROJECTIONS, SEARCH_SIZE), dataPoints }, { new FastProjectionSearch(new EuclideanDistanceMeasure(), NUM_PROJECTIONS, SEARCH_SIZE), dataPoints }, { new LocalitySensitiveHashSearch(new EuclideanDistanceMeasure(), SEARCH_SIZE), dataPoints } });}
public void mahout_f5236_0()
{    searcher.clear();    Iterable<MatrixSlice> data = dataPoints;    final Iterable<MatrixSlice> batch1 = Iterables.limit(data, 300);    List<MatrixSlice> queries = Lists.newArrayList(Iterables.limit(batch1, 100));        searcher.addAllMatrixSlices(batch1);    assertEquals(300, searcher.size());    Vector q = Iterables.get(data, 0).vector();    List<WeightedThing<Vector>> r = searcher.search(q, 2);    assertEquals(0, r.get(0).getValue().minus(q).norm(1), 1.0e-8);    final Iterable<MatrixSlice> batch2 = Iterables.limit(Iterables.skip(data, 300), 10);    searcher.addAllMatrixSlices(batch2);    assertEquals(310, searcher.size());    q = Iterables.get(data, 302).vector();    r = searcher.search(q, 2);    assertEquals(0, r.get(0).getValue().minus(q).norm(1), 1.0e-8);    searcher.addAllMatrixSlices(Iterables.skip(data, 310));    assertEquals(dataPoints.numRows(), searcher.size());    for (MatrixSlice query : queries) {        r = searcher.search(query.vector(), 2);        assertEquals("Distance has to be about zero", 0, r.get(0).getWeight(), 1.0e-6);        assertEquals("Answer must be substantially the same as query", 0, r.get(0).getValue().minus(query.vector()).norm(1), 1.0e-8);        assertTrue("Wrong answer must have non-zero distance", r.get(1).getWeight() > r.get(0).getWeight());    }}
public void mahout_f5237_0()
{    searcher.clear();    List<MatrixSlice> queries = Lists.newArrayList(Iterables.limit(dataPoints, 100));    searcher.addAllMatrixSlicesAsWeightedVectors(dataPoints);    MultiNormal noise = new MultiNormal(0.01, new DenseVector(20));    for (MatrixSlice slice : queries) {        Vector query = slice.vector();        final Vector epsilon = noise.sample();        List<WeightedThing<Vector>> r = searcher.search(query, 2);        query = query.plus(epsilon);        assertEquals("Distance has to be small", epsilon.norm(2), r.get(0).getWeight(), 1.0e-1);        assertEquals("Answer must be substantially the same as query", epsilon.norm(2), r.get(0).getValue().minus(query).norm(2), 1.0e-1);        assertTrue("Wrong answer must be further away", r.get(1).getWeight() > r.get(0).getWeight());    }}
public void mahout_f5238_0()
{    searcher.clear();    Matrix queries = new DenseMatrix(100, 20);    MultiNormal gen = new MultiNormal(20);    for (int i = 0; i < 100; i++) {        queries.viewRow(i).assign(gen.sample());    }    searcher.addAllMatrixSlices(dataPoints);    for (MatrixSlice query : queries) {        List<WeightedThing<Vector>> r = searcher.search(query.vector(), 200);        double x = 0;        for (WeightedThing<Vector> thing : r) {            assertTrue("Scores must be monotonic increasing", thing.getWeight() >= x);            x = thing.getWeight();        }    }}
public void mahout_f5239_0()
{    searcher.clear();    searcher.addAllMatrixSlices(dataPoints);        if (searcher instanceof UpdatableSearcher) {        List<Vector> x = Lists.newArrayList(Iterables.limit(searcher, 2));        int size0 = searcher.size();        List<WeightedThing<Vector>> r0 = searcher.search(x.get(0), 2);        searcher.remove(x.get(0), 1.0e-7);        assertEquals(size0 - 1, searcher.size());        List<WeightedThing<Vector>> r = searcher.search(x.get(0), 1);        assertTrue("Vector should be gone", r.get(0).getWeight() > 0);        assertEquals("Previous second neighbor should be first", 0, r.get(0).getValue().minus(r0.get(1).getValue()).norm(1), 1.0e-8);        searcher.remove(x.get(1), 1.0e-7);        assertEquals(size0 - 2, searcher.size());        r = searcher.search(x.get(1), 1);        assertTrue("Vector should be gone", r.get(0).getWeight() > 0);                for (Vector v : searcher) {            assertTrue(x.get(0).minus(v).norm(1) > 1.0e-6);            assertTrue(x.get(1).minus(v).norm(1) > 1.0e-6);        }    } else {        try {            List<Vector> x = Lists.newArrayList(Iterables.limit(searcher, 2));            searcher.remove(x.get(0), 1.0e-7);            fail("Shouldn't be able to delete from " + searcher.getClass().getName());        } catch (UnsupportedOperationException e) {                }    }}
public void mahout_f5240_0()
{    searcher.clear();    searcher.addAll(dataPoints);    for (Vector datapoint : dataPoints) {        WeightedThing<Vector> first = searcher.searchFirst(datapoint, false);        WeightedThing<Vector> second = searcher.searchFirst(datapoint, true);        List<WeightedThing<Vector>> firstTwo = searcher.search(datapoint, 2);        assertEquals("First isn't self", 0, first.getWeight(), 0);        assertEquals("First isn't self", datapoint, first.getValue());        assertEquals("First doesn't match", first, firstTwo.get(0));        assertEquals("Second doesn't match", second, firstTwo.get(1));    }}
public void mahout_f5241_0()
{    searcher.clear();    searcher.addAll(dataPoints);    for (Vector datapoint : dataPoints) {        List<WeightedThing<Vector>> firstTwo = searcher.search(datapoint, 2);        assertThat("Search limit isn't respected", firstTwo.size(), is(lessThanOrEqualTo(2)));    }}
public void mahout_f5242_0()
{    searcher.clear();    for (int i = 0; i < dataPoints.rowSize(); ++i) {        Vector datapoint = dataPoints.viewRow(i);        searcher.add(datapoint);                if (i % 2 == 0) {            assertTrue("Failed to find self [search]", searcher.search(datapoint, 1).get(0).getWeight() < Constants.EPSILON);            assertTrue("Failed to find self [searchFirst]", searcher.searchFirst(datapoint, false).getWeight() < Constants.EPSILON);            assertTrue("Failed to remove self", searcher.remove(datapoint, Constants.EPSILON));        }    }}
public void mahout_f5243_0() throws Exception
{    super.setUp();    tmpDir = getTestTempDir("matrix");}
public void mahout_f5244_0() throws IOException
{    Matrix A = lowRankMatrix(tmpDir, "A", 200, 970, 1020);    List<File> partsOfA = Arrays.asList(tmpDir.listFiles(new FilenameFilter() {        @Override        public boolean accept(File file, String fileName) {            return fileName.matches("A-.*");        }    }));        partsOfA = Lists.reverse(partsOfA);    SequentialOutOfCoreSvd s = new SequentialOutOfCoreSvd(partsOfA, tmpDir, 100, 210);    SequentialBigSvd svd = new SequentialBigSvd(A, 100);    Vector reference = new DenseVector(svd.getSingularValues()).viewPart(0, 6);    Vector actual = s.getSingularValues().viewPart(0, 6);    assertEquals(0, reference.minus(actual).maxValue(), 1.0e-9);    s.computeU(partsOfA, tmpDir);    Matrix u = readBlockMatrix(Arrays.asList(tmpDir.listFiles(new FilenameFilter() {        @Override        public boolean accept(File file, String fileName) {            return fileName.matches("U-.*");        }    })));    s.computeV(tmpDir, A.columnSize());    Matrix v = readBlockMatrix(Arrays.asList(tmpDir.listFiles(new FilenameFilter() {        @Override        public boolean accept(File file, String fileName) {            return fileName.matches("V-.*");        }    })));        assertEquals(0, A.minus(u.times(new DiagonalMatrix(s.getSingularValues())).times(v.transpose())).aggregate(Functions.PLUS, Functions.ABS), 1.0e-7);}
public boolean mahout_f5245_0(File file, String fileName)
{    return fileName.matches("A-.*");}
public boolean mahout_f5246_0(File file, String fileName)
{    return fileName.matches("U-.*");}
public boolean mahout_f5247_0(File file, String fileName)
{    return fileName.matches("V-.*");}
private static Matrix mahout_f5248_0(List<File> files) throws IOException
{        Collections.sort(files);        int nrows = -1;    int ncols = -1;    Matrix r = null;    MatrixWritable m = new MatrixWritable();    int row = 0;    for (File file : files) {        DataInputStream in = new DataInputStream(new FileInputStream(file));        m.readFields(in);        in.close();        if (nrows == -1) {                        nrows = m.get().rowSize() * files.size();            ncols = m.get().columnSize();            r = new DenseMatrix(nrows, ncols);        }        r.viewPart(row, m.get().rowSize(), 0, r.columnSize()).assign(m.get());        row += m.get().rowSize();    }        if (row != nrows && r != null) {                r = r.viewPart(0, row, 0, ncols);    }    return r;}
public void mahout_f5249_0() throws IOException
{    Matrix A = lowRankMatrixInMemory(20, 20);    SequentialBigSvd s = new SequentialBigSvd(A, 6);    SingularValueDecomposition svd = new SingularValueDecomposition(A);        Matrix u1 = svd.getU().viewPart(0, 20, 0, 3).assign(Functions.ABS);    Matrix u2 = s.getU().viewPart(0, 20, 0, 3).assign(Functions.ABS);    assertEquals(u1, u2);}
private static Matrix mahout_f5250_0(int rows, int columns) throws IOException
{    return lowRankMatrix(null, null, 0, rows, columns);}
private static void mahout_f5251_0(Matrix u1, Matrix u2)
{    assertEquals(0.0, u1.minus(u2).aggregate(Functions.MAX, Functions.ABS), 1.0e-10);}
public void mahout_f5252_0() throws IOException
{    Matrix A = lowRankMatrixInMemory(20, 20);    SequentialBigSvd s = new SequentialBigSvd(A, 6);    SingularValueDecomposition svd = new SingularValueDecomposition(A);    Matrix v1 = svd.getV().viewPart(0, 20, 0, 3).assign(Functions.ABS);    Matrix v2 = s.getV().viewPart(0, 20, 0, 3).assign(Functions.ABS);    assertEquals(v1, v2);}
private static Matrix mahout_f5253_0(File tmpDir, String aBase, int rowsPerSlice, int rows, int columns) throws IOException
{    int rank = 10;    Matrix u = new RandomTrinaryMatrix(1, rows, rank, false);    Matrix d = new DenseMatrix(rank, rank);    d.set(0, 0, 5);    d.set(1, 1, 3);    d.set(2, 2, 1);    d.set(3, 3, 0.5);    Matrix v = new RandomTrinaryMatrix(2, columns, rank, false);    Matrix a = u.times(d).times(v.transpose());    if (tmpDir != null) {        for (int i = 0; i < a.rowSize(); i += rowsPerSlice) {            MatrixWritable m = new MatrixWritable(a.viewPart(i, Math.min(a.rowSize() - i, rowsPerSlice), 0, a.columnSize()));            DataOutputStream out = new DataOutputStream(new FileOutputStream(new File(tmpDir, String.format("%s-%09d", aBase, i))));            try {                m.write(out);            } finally {                out.close();            }        }    }    return a;}
public void mahout_f5254_0()
{    Random gen = RandomUtils.getRandom();    OnlineSummarizer[] stats = new OnlineSummarizer[4];    for (int i = 0; i < 4; i++) {        stats[i] = new OnlineSummarizer();    }    for (int i = 0; i < 100; i++) {        OnlineAuc a1 = new GlobalOnlineAuc();        a1.setPolicy(GlobalOnlineAuc.ReplacementPolicy.FAIR);        OnlineAuc a2 = new GlobalOnlineAuc();        a2.setPolicy(GlobalOnlineAuc.ReplacementPolicy.FIFO);        OnlineAuc a3 = new GlobalOnlineAuc();        a3.setPolicy(GlobalOnlineAuc.ReplacementPolicy.RANDOM);        Auc a4 = new Auc();        for (int j = 0; j < 10000; j++) {            double x = gen.nextGaussian();            a1.addSample(0, x);            a2.addSample(0, x);            a3.addSample(0, x);            a4.add(0, x);            x = gen.nextGaussian() + 1;            a1.addSample(1, x);            a2.addSample(1, x);            a3.addSample(1, x);            a4.add(1, x);        }        stats[0].add(a1.auc());        stats[1].add(a2.auc());        stats[2].add(a3.auc());        stats[3].add(a4.auc());    }    int i = 0;    for (GlobalOnlineAuc.ReplacementPolicy policy : new GlobalOnlineAuc.ReplacementPolicy[] { GlobalOnlineAuc.ReplacementPolicy.FAIR, GlobalOnlineAuc.ReplacementPolicy.FIFO, GlobalOnlineAuc.ReplacementPolicy.RANDOM, null }) {        OnlineSummarizer summary = stats[i++];        System.out.printf("%s,%.4f (min = %.4f, 25%%-ile=%.4f, 75%%-ile=%.4f, max=%.4f)\n", policy, summary.getMean(), summary.getQuartile(0), summary.getQuartile(1), summary.getQuartile(2), summary.getQuartile(3));    }        assertEquals(0.7603, stats[0].getMean(), 0.03);    assertEquals(0.7603, stats[0].getQuartile(1), 0.03);    assertEquals(0.7603, stats[0].getQuartile(3), 0.03);        assertEquals(0.7603, stats[1].getMean(), 0.001);    assertEquals(0.7603, stats[1].getQuartile(1), 0.006);    assertEquals(0.7603, stats[1].getQuartile(3), 0.006);        assertEquals(0.7603, stats[2].getMean(), 0.001);    assertEquals(0.7603, stats[2].getQuartile(1), 0.006);    assertEquals(0.7603, stats[2].getQuartile(1), 0.006);}
public void mahout_f5255_0()
{    OnlineAuc x = new GroupedOnlineAuc();    x.addSample(0, 3.14);}
public void mahout_f5256_0()
{    Random gen = RandomUtils.getRandom();    OnlineAuc x = new GroupedOnlineAuc();    OnlineAuc y = new GlobalOnlineAuc();    for (int i = 0; i < 10000; i++) {        x.addSample(0, "a", gen.nextGaussian());        x.addSample(1, "a", gen.nextGaussian() + 1);        x.addSample(0, "b", gen.nextGaussian() + 10);        x.addSample(1, "b", gen.nextGaussian() + 11);        y.addSample(0, "a", gen.nextGaussian());        y.addSample(1, "a", gen.nextGaussian() + 1);        y.addSample(0, "b", gen.nextGaussian() + 10);        y.addSample(1, "b", gen.nextGaussian() + 11);    }    assertEquals(0.7603, x.auc(), 0.01);    assertEquals((0.7603 + 0.5) / 2, y.auc(), 0.02);}
public void mahout_f5257_0()
{    Vector distribution = new DenseVector(new double[] { 1, 0, 2, 3, 5, 0 });    Sampler sampler = new Sampler(RandomUtils.getRandom(), distribution);    Vector sampledDistribution = distribution.like();    int i = 0;    while (i < 100000) {        int index = sampler.sample();        sampledDistribution.set(index, sampledDistribution.get(index) + 1);        i++;    }    assertTrue("sampled distribution is far from the original", l1Dist(distribution, sampledDistribution) < 1.0e-2);}
private static double mahout_f5258_0(Vector v, Vector w)
{    return v.normalize(1.0).minus(w.normalize(1)).norm(1.0);}
public void mahout_f5259_0() throws Exception
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    DataOutput out = new DataOutputStream(baos);    Varint.writeUnsignedVarLong(0L, out);    for (long i = 1L; i > 0L && i <= (1L << 62); i <<= 1) {        Varint.writeUnsignedVarLong(i - 1, out);        Varint.writeUnsignedVarLong(i, out);    }    Varint.writeUnsignedVarLong(Long.MAX_VALUE, out);    DataInput in = new DataInputStream(new ByteArrayInputStream(baos.toByteArray()));    assertEquals(0L, Varint.readUnsignedVarLong(in));    for (long i = 1L; i > 0L && i <= (1L << 62); i <<= 1) {        assertEquals(i - 1, Varint.readUnsignedVarLong(in));        assertEquals(i, Varint.readUnsignedVarLong(in));    }    assertEquals(Long.MAX_VALUE, Varint.readUnsignedVarLong(in));}
public void mahout_f5260_0() throws Exception
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    DataOutput out = new DataOutputStream(baos);    Varint.writeSignedVarLong(0L, out);    for (long i = 1L; i <= (1L << 61); i <<= 1) {        Varint.writeSignedVarLong(i - 1, out);        Varint.writeSignedVarLong(i, out);    }    Varint.writeSignedVarLong((1L << 62) - 1, out);    Varint.writeSignedVarLong((1L << 62), out);    Varint.writeSignedVarLong(Long.MAX_VALUE, out);    DataInput in = new DataInputStream(new ByteArrayInputStream(baos.toByteArray()));    assertEquals(0L, Varint.readSignedVarLong(in));    for (long i = 1L; i <= (1L << 61); i <<= 1) {        assertEquals(i - 1, Varint.readSignedVarLong(in));        assertEquals(i, Varint.readSignedVarLong(in));    }    assertEquals((1L << 62) - 1, Varint.readSignedVarLong(in));    assertEquals((1L << 62), Varint.readSignedVarLong(in));    assertEquals(Long.MAX_VALUE, Varint.readSignedVarLong(in));}
public void mahout_f5261_0() throws Exception
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    DataOutput out = new DataOutputStream(baos);    for (long i = -1L; i >= -(1L << 62); i <<= 1) {        Varint.writeSignedVarLong(i, out);        Varint.writeSignedVarLong(i + 1, out);    }    Varint.writeSignedVarLong(Long.MIN_VALUE, out);    Varint.writeSignedVarLong(Long.MIN_VALUE + 1, out);    DataInput in = new DataInputStream(new ByteArrayInputStream(baos.toByteArray()));    for (long i = -1L; i >= -(1L << 62); i <<= 1) {        assertEquals(i, Varint.readSignedVarLong(in));        assertEquals(i + 1, Varint.readSignedVarLong(in));    }    assertEquals(Long.MIN_VALUE, Varint.readSignedVarLong(in));    assertEquals(Long.MIN_VALUE + 1, Varint.readSignedVarLong(in));}
public void mahout_f5262_0() throws Exception
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    DataOutput out = new DataOutputStream(baos);    Varint.writeUnsignedVarInt(0, out);    for (int i = 1; i > 0 && i <= (1 << 30); i <<= 1) {        Varint.writeUnsignedVarLong(i - 1, out);        Varint.writeUnsignedVarLong(i, out);    }    Varint.writeUnsignedVarLong(Integer.MAX_VALUE, out);    DataInput in = new DataInputStream(new ByteArrayInputStream(baos.toByteArray()));    assertEquals(0, Varint.readUnsignedVarInt(in));    for (int i = 1; i > 0 && i <= (1 << 30); i <<= 1) {        assertEquals(i - 1, Varint.readUnsignedVarInt(in));        assertEquals(i, Varint.readUnsignedVarInt(in));    }    assertEquals(Integer.MAX_VALUE, Varint.readUnsignedVarInt(in));}
public void mahout_f5263_0() throws Exception
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    DataOutput out = new DataOutputStream(baos);    Varint.writeSignedVarInt(0, out);    for (int i = 1; i <= (1 << 29); i <<= 1) {        Varint.writeSignedVarLong(i - 1, out);        Varint.writeSignedVarLong(i, out);    }    Varint.writeSignedVarInt((1 << 30) - 1, out);    Varint.writeSignedVarInt((1 << 30), out);    Varint.writeSignedVarInt(Integer.MAX_VALUE, out);    DataInput in = new DataInputStream(new ByteArrayInputStream(baos.toByteArray()));    assertEquals(0, Varint.readSignedVarInt(in));    for (int i = 1; i <= (1 << 29); i <<= 1) {        assertEquals(i - 1, Varint.readSignedVarInt(in));        assertEquals(i, Varint.readSignedVarInt(in));    }    assertEquals((1L << 30) - 1, Varint.readSignedVarInt(in));    assertEquals((1L << 30), Varint.readSignedVarInt(in));    assertEquals(Integer.MAX_VALUE, Varint.readSignedVarInt(in));}
public void mahout_f5264_0() throws Exception
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    DataOutput out = new DataOutputStream(baos);    for (int i = -1; i >= -(1 << 30); i <<= 1) {        Varint.writeSignedVarInt(i, out);        Varint.writeSignedVarInt(i + 1, out);    }    Varint.writeSignedVarInt(Integer.MIN_VALUE, out);    Varint.writeSignedVarInt(Integer.MIN_VALUE + 1, out);    DataInput in = new DataInputStream(new ByteArrayInputStream(baos.toByteArray()));    for (int i = -1; i >= -(1 << 30); i <<= 1) {        assertEquals(i, Varint.readSignedVarInt(in));        assertEquals(i + 1, Varint.readSignedVarInt(in));    }    assertEquals(Integer.MIN_VALUE, Varint.readSignedVarInt(in));    assertEquals(Integer.MIN_VALUE + 1, Varint.readSignedVarInt(in));}
public void mahout_f5265_0() throws Exception
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    DataOutput out = new DataOutputStream(baos);    int expectedSize = 0;    for (int exponent = 0; exponent <= 62; exponent++) {        Varint.writeUnsignedVarLong(1L << exponent, out);        expectedSize += 1 + exponent / 7;        assertEquals(expectedSize, baos.size());    }}
public void mahout_f5266_0() throws Exception
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    DataOutput out = new DataOutputStream(baos);    int expectedSize = 0;    for (int exponent = 0; exponent <= 61; exponent++) {        Varint.writeSignedVarLong(1L << exponent, out);        expectedSize += 1 + ((exponent + 1) / 7);        assertEquals(expectedSize, baos.size());    }    for (int exponent = 0; exponent <= 61; exponent++) {        Varint.writeSignedVarLong(-(1L << exponent) - 1, out);        expectedSize += 1 + ((exponent + 1) / 7);        assertEquals(expectedSize, baos.size());    }}
public void mahout_f5267_0(Vector v)
{    int size = randomInt(v.size() - 1);    for (int i = 0; i < size; ++i) {        v.set(randomInt(v.size() - 1), randomDouble());    }    int zeros = Math.max(2, size / 4);    for (Element e : v.nonZeroes()) {        if (e.index() % zeros == 0) {            e.set(0.0);        }    }}
public void mahout_f5268_0() throws Exception
{    Vector v = new SequentialAccessSparseVector(MAX_VECTOR_SIZE);    createRandom(v);    Vector view = new VectorView(v, 0, v.size());    doTestVectorWritableEquals(view);}
public void mahout_f5269_0() throws Exception
{    Vector v = new SequentialAccessSparseVector(MAX_VECTOR_SIZE);    createRandom(v);    doTestVectorWritableEquals(v);}
public void mahout_f5270_0() throws Exception
{    Vector v = new RandomAccessSparseVector(MAX_VECTOR_SIZE);    createRandom(v);    doTestVectorWritableEquals(v);}
public void mahout_f5271_0() throws Exception
{    Vector v = new DenseVector(MAX_VECTOR_SIZE);    createRandom(v);    doTestVectorWritableEquals(v);}
public void mahout_f5272_0() throws Exception
{    Vector v = new DenseVector(MAX_VECTOR_SIZE);    v = new NamedVector(v, "Victor");    createRandom(v);    doTestVectorWritableEquals(v);}
private static void mahout_f5273_0(Vector v) throws IOException
{    Writable vectorWritable = new VectorWritable(v);    VectorWritable vectorWritable2 = new VectorWritable();    writeAndRead(vectorWritable, vectorWritable2);    Vector v2 = vectorWritable2.get();    if (v instanceof NamedVector) {        assertTrue(v2 instanceof NamedVector);        NamedVector nv = (NamedVector) v;        NamedVector nv2 = (NamedVector) v2;        assertEquals(nv.getName(), nv2.getName());        assertEquals("Victor", nv.getName());    }    assertEquals(v, v2);}
private static void mahout_f5274_0(Writable toWrite, Writable toRead) throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    DataOutputStream dos = new DataOutputStream(baos);    try {        toWrite.write(dos);    } finally {        Closeables.close(dos, false);    }    ByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray());    DataInputStream dis = new DataInputStream(bais);    try {        toRead.readFields(dis);    } finally {        Closeables.close(dos, true);    }}
public void mahout_f5275_0() throws Exception
{    super.setUp();    counter = EasyMock.createMock(Counter.class);    context = EasyMock.createMock(Context.class);}
public void mahout_f5276_0() throws Exception
{    Text key = new Text();    key.set("dummy-key");    String[] input = { "the", "best", "of", "times", "the", "worst", "of", "times" };    StringTuple inputTuple = new StringTuple();    for (String i : input) {        inputTuple.add(i);    }    String[][] values = { { "h_the", "the best" }, { "t_best", "the best" }, { "h_of", "of times" }, { "t_times", "of times" }, { "h_best", "best of" }, { "t_of", "best of" }, { "h_the", "the worst" }, { "t_worst", "the worst" }, { "h_times", "times the" }, { "t_the", "times the" }, { "h_worst", "worst of" }, { "t_of", "worst of" } };        Configuration conf = getConfiguration();    conf.set(CollocMapper.MAX_SHINGLE_SIZE, "2");    EasyMock.expect(context.getConfiguration()).andReturn(conf);    for (String[] v : values) {        Type p = v[0].startsWith("h") ? Gram.Type.HEAD : Gram.Type.TAIL;        int frequency = 1;        if ("of times".equals(v[1])) {            frequency = 2;        }        Gram subgram = new Gram(v[0].substring(2), frequency, p);        Gram ngram = new Gram(v[1], frequency, Gram.Type.NGRAM);        GramKey subgramKey = new GramKey(subgram, new byte[0]);        GramKey subgramNgramKey = new GramKey(subgram, ngram.getBytes());        context.write(subgramKey, subgram);        context.write(subgramNgramKey, ngram);    }    EasyMock.expect(context.getCounter(CollocMapper.Count.NGRAM_TOTAL)).andReturn(counter);    counter.increment(7);    EasyMock.replay(context, counter);    CollocMapper c = new CollocMapper();    c.setup(context);    c.map(key, inputTuple, context);    EasyMock.verify(context);}
public void mahout_f5277_0() throws Exception
{    Text key = new Text();    key.set("dummy-key");    String[] input = { "the", "best", "of", "times", "the", "worst", "of", "times" };    StringTuple inputTuple = new StringTuple();    for (String i : input) {        inputTuple.add(i);    }    String[][] values = { { "h_the", "the best" }, { "t_best", "the best" }, { "h_of", "of times" }, { "t_times", "of times" }, { "h_best", "best of" }, { "t_of", "best of" }, { "h_the", "the worst" }, { "t_worst", "the worst" }, { "h_times", "times the" }, { "t_the", "times the" }, { "h_worst", "worst of" }, { "t_of", "worst of" }, { "u_worst", "worst" }, { "u_of", "of" }, { "u_the", "the" }, { "u_best", "best" }, { "u_times", "times" } };        Configuration conf = getConfiguration();    conf.set(CollocMapper.MAX_SHINGLE_SIZE, "2");    conf.setBoolean(CollocDriver.EMIT_UNIGRAMS, true);    EasyMock.expect(context.getConfiguration()).andReturn(conf);    for (String[] v : values) {        Type p = v[0].startsWith("h") ? Gram.Type.HEAD : Gram.Type.TAIL;        p = v[0].startsWith("u") ? Gram.Type.UNIGRAM : p;        int frequency = 1;        if ("of times".equals(v[1]) || "of".equals(v[1]) || "times".equals(v[1]) || "the".equals(v[1])) {            frequency = 2;        }        if (p == Gram.Type.UNIGRAM) {            Gram unigram = new Gram(v[1], frequency, Gram.Type.UNIGRAM);            GramKey unigramKey = new GramKey(unigram, new byte[0]);            context.write(unigramKey, unigram);        } else {            Gram subgram = new Gram(v[0].substring(2), frequency, p);            Gram ngram = new Gram(v[1], frequency, Gram.Type.NGRAM);            GramKey subgramKey = new GramKey(subgram, new byte[0]);            GramKey subgramNgramKey = new GramKey(subgram, ngram.getBytes());            context.write(subgramKey, subgram);            context.write(subgramNgramKey, ngram);        }    }    EasyMock.expect(context.getCounter(CollocMapper.Count.NGRAM_TOTAL)).andReturn(counter);    counter.increment(7);    EasyMock.replay(context, counter);    CollocMapper c = new CollocMapper();    c.setup(context);    c.map(key, inputTuple, context);    EasyMock.verify(context);}
public void mahout_f5278_0() throws Exception
{    super.setUp();    context = EasyMock.createMock(Context.class);}
public void mahout_f5279_0() throws Exception
{                Gram[][] input = { { new Gram("the", Gram.Type.UNIGRAM), new Gram("the", Gram.Type.UNIGRAM), new Gram("the", Gram.Type.UNIGRAM) }, { new Gram("the", Gram.Type.HEAD), new Gram("the best", Gram.Type.NGRAM), new Gram("the worst", Gram.Type.NGRAM) }, { new Gram("of", Gram.Type.HEAD), new Gram("of times", Gram.Type.NGRAM), new Gram("of times", Gram.Type.NGRAM) }, { new Gram("times", Gram.Type.TAIL), new Gram("of times", Gram.Type.NGRAM), new Gram("of times", Gram.Type.NGRAM) } };        Gram[][] values = { { new Gram("the", 2, Gram.Type.UNIGRAM), new Gram("the", 2, Gram.Type.UNIGRAM) }, { new Gram("the best", 1, Gram.Type.NGRAM), new Gram("the", 2, Gram.Type.HEAD) }, { new Gram("the worst", 1, Gram.Type.NGRAM), new Gram("the", 2, Gram.Type.HEAD) }, { new Gram("of times", 2, Gram.Type.NGRAM), new Gram("of", 2, Gram.Type.HEAD) }, { new Gram("of times", 2, Gram.Type.NGRAM), new Gram("times", 2, Gram.Type.TAIL) } };        for (Gram[] v : values) {        context.write(v[0], v[1]);    }    EasyMock.replay(context);        CollocReducer c = new CollocReducer();    GramKey key = new GramKey();    byte[] empty = new byte[0];    for (Gram[] ii : input) {        key.set(ii[0], empty);        Collection<Gram> vv = Lists.newLinkedList();        vv.addAll(Arrays.asList(ii));        c.reduce(key, vv, context);    }    EasyMock.verify(context);}
public void mahout_f5280_0()
{    byte[] foo = new byte[1];    foo[0] = 1;    byte[] empty = new byte[0];        GramKey a = new GramKey(new Gram("foo", 1, Gram.Type.HEAD), empty);        GramKey b = new GramKey(new Gram("foo", 1, Gram.Type.HEAD), foo);        GramKey c = new GramKey(new Gram("foo", 2, Gram.Type.HEAD), empty);        GramKey d = new GramKey(new Gram("foo", 1, Gram.Type.TAIL), empty);        GramKey e = new GramKey(new Gram("bar", 5, Gram.Type.HEAD), empty);    GramKeyGroupComparator cmp = new GramKeyGroupComparator();    assertEquals(0, cmp.compare(a, b));    assertEquals(0, cmp.compare(a, c));    assertTrue(cmp.compare(a, d) < 0);    assertTrue(cmp.compare(a, e) > 0);    assertTrue(cmp.compare(d, e) > 0);}
public void mahout_f5281_0()
{    byte[] foo = new byte[1];    foo[0] = 1;    foo[0] = 2;    byte[] empty = new byte[0];    GramKey a = new GramKey(new Gram("foo", 1, Gram.Type.HEAD), empty);    GramKey b = new GramKey(new Gram("foo", 1, Gram.Type.HEAD), foo);    byte[] bar = new byte[1];    GramKey c = new GramKey(new Gram("foo", 2, Gram.Type.HEAD), bar);    GramKey d = new GramKey(new Gram("foo", 1, Gram.Type.TAIL), empty);    GramKey e = new GramKey(new Gram("foo", 2, Gram.Type.TAIL), foo);    Partitioner<GramKey, Gram> p = new GramKeyPartitioner();    int numPartitions = 5;    int ap = p.getPartition(a, null, numPartitions);    int bp = p.getPartition(b, null, numPartitions);    int cp = p.getPartition(c, null, numPartitions);    int dp = p.getPartition(d, null, numPartitions);    int ep = p.getPartition(e, null, numPartitions);    assertEquals(ap, bp);    assertEquals(ap, cp);    assertEquals(dp, ep);}
public void mahout_f5282_0()
{    byte[] foo = { 1 };            byte[] empty = new byte[0];    GramKey[] input = { new GramKey(new Gram("bar", 1, Gram.Type.UNIGRAM), empty), new GramKey(new Gram("bar", 1, Gram.Type.UNIGRAM), empty), new GramKey(new Gram("bar", 1, Gram.Type.UNIGRAM), foo), new GramKey(new Gram("bar", 8, Gram.Type.NGRAM), foo), new GramKey(new Gram("bar", 8, Gram.Type.NGRAM), empty), new GramKey(new Gram("foo", 2, Gram.Type.HEAD), foo), new GramKey(new Gram("foo", 3, Gram.Type.HEAD), empty), new GramKey(new Gram("foo", 4, Gram.Type.TAIL), foo), new GramKey(new Gram("foo", 5, Gram.Type.TAIL), foo), new GramKey(new Gram("bar", 6, Gram.Type.HEAD), foo), new GramKey(new Gram("bar", 7, Gram.Type.TAIL), empty) };    int[] expect = { 9, 6, 5, 10, 7, 8, 0, 1, 2, 4, 3 };    GramKey[] sorted = new GramKey[input.length];    System.arraycopy(input, 0, sorted, 0, input.length);    Arrays.sort(sorted);    for (int i = 0; i < input.length; i++) {        assertSame(input[expect[i]], sorted[i]);    }}
public void mahout_f5283_0() throws Exception
{    byte[] foo = new byte[0];    byte[] bar = { 2 };    GramKey one = new GramKey(new Gram("foo", 2, Gram.Type.HEAD), foo);    GramKey two = new GramKey(new Gram("foobar", 3, Gram.Type.UNIGRAM), bar);    assertEquals("foo", one.getPrimaryString());    assertEquals("foobar", two.getPrimaryString());    assertEquals(Gram.Type.UNIGRAM, two.getType());    ByteArrayOutputStream bout = new ByteArrayOutputStream();    DataOutputStream out = new DataOutputStream(bout);    try {        two.write(out);    } finally {        Closeables.close(out, false);    }    byte[] b = bout.toByteArray();    ByteArrayInputStream bin = new ByteArrayInputStream(b);    DataInputStream din = new DataInputStream(bin);    try {        one.readFields(din);    } finally {        Closeables.close(din, true);    }    assertTrue(Arrays.equals(two.getBytes(), one.getBytes()));    assertEquals(Gram.Type.UNIGRAM, one.getType());}
public void mahout_f5284_0()
{    Gram one = new Gram("foo", 2, Gram.Type.HEAD);    assertEquals("foo", one.getString());    assertEquals(2, one.getFrequency());    assertEquals(Gram.Type.HEAD, one.getType());    Gram oneClone = new Gram(one);    assertEquals("foo", oneClone.getString());    assertEquals(2, oneClone.getFrequency());    assertEquals(Gram.Type.HEAD, oneClone.getType());    Gram two = new Gram("foo", 3, Gram.Type.TAIL);    assertEquals(Gram.Type.TAIL, two.getType());    Gram three = new Gram("foo", 4, Gram.Type.UNIGRAM);    assertEquals(Gram.Type.UNIGRAM, three.getType());    Gram four = new Gram("foo", 5, Gram.Type.NGRAM);    assertEquals(Gram.Type.NGRAM, four.getType());}
public void mahout_f5285_0()
{    new Gram(null, 4, Gram.Type.UNIGRAM);}
public void mahout_f5286_0()
{    new Gram("foo", 4, null);}
public void mahout_f5287_0()
{    Gram one = new Gram("foo", 2, Gram.Type.HEAD);    Gram two = new Gram("foo", 3, Gram.Type.HEAD);    assertEquals(one, two);    assertEquals(two, one);    Gram three = new Gram("foo", 4, Gram.Type.TAIL);    Gram four = new Gram("foo", Gram.Type.UNIGRAM);    assertTrue(!three.equals(two));    assertTrue(!four.equals(one));    assertTrue(!one.equals(four));    Gram five = new Gram("foo", 5, Gram.Type.UNIGRAM);    assertEquals(four, five);    Gram six = new Gram("foo", 6, Gram.Type.NGRAM);    Gram seven = new Gram("foo", 7, Gram.Type.NGRAM);    assertTrue(!five.equals(six));    assertEquals(six, seven);    Gram eight = new Gram("foobar", 4, Gram.Type.TAIL);    assertTrue(!eight.equals(four));    assertTrue(!eight.equals(three));    assertTrue(!eight.equals(two));    assertTrue(!eight.equals(one));}
public void mahout_f5288_0()
{    Gram[] input = { new Gram("foo", 2, Gram.Type.HEAD), new Gram("foo", 3, Gram.Type.HEAD), new Gram("foo", 4, Gram.Type.TAIL), new Gram("foo", 5, Gram.Type.TAIL), new Gram("bar", 6, Gram.Type.HEAD), new Gram("bar", 7, Gram.Type.TAIL), new Gram("bar", 8, Gram.Type.NGRAM), new Gram("bar", Gram.Type.UNIGRAM) };    HashMap<Gram, Gram> map = new HashMap<>();    for (Gram n : input) {        Gram val = map.get(n);        if (val != null) {            val.incrementFrequency(n.getFrequency());        } else {            map.put(n, n);        }    }        int[] freq = { 5, 3, 9, 5, 6, 7, 8, 1 };        boolean[] memb = { true, false, true, false, true, true, true, true };    for (int i = 0; i < input.length; i++) {        assertEquals(freq[i], input[i].getFrequency());        assertEquals(memb[i], input[i] == map.get(input[i]));    }}
public void mahout_f5289_0() throws Exception
{    Gram one = new Gram("foo", 2, Gram.Type.HEAD);    Gram two = new Gram("foobar", 3, Gram.Type.UNIGRAM);    assertEquals("foo", one.getString());    assertEquals(2, one.getFrequency());    assertEquals(Gram.Type.HEAD, one.getType());    assertEquals("foobar", two.getString());    assertEquals(3, two.getFrequency());    assertEquals(Gram.Type.UNIGRAM, two.getType());    ByteArrayOutputStream bout = new ByteArrayOutputStream();    DataOutput out = new DataOutputStream(bout);    two.write(out);    byte[] b = bout.toByteArray();    ByteArrayInputStream bin = new ByteArrayInputStream(b);    DataInput din = new DataInputStream(bin);    one.readFields(din);    assertEquals("foobar", one.getString());    assertEquals(3, one.getFrequency());    assertEquals(Gram.Type.UNIGRAM, one.getType());}
public void mahout_f5290_0()
{    Gram[] input = { new Gram("foo", 2, Gram.Type.HEAD), new Gram("foo", 3, Gram.Type.HEAD), new Gram("foo", 4, Gram.Type.TAIL), new Gram("foo", 5, Gram.Type.TAIL), new Gram("bar", 6, Gram.Type.HEAD), new Gram("bar", 7, Gram.Type.TAIL), new Gram("bar", 8, Gram.Type.NGRAM), new Gram("bar", Gram.Type.UNIGRAM) };    Gram[] sorted = new Gram[input.length];    int[] expectations = { 4, 0, 1, 5, 2, 3, 7, 6 };    System.arraycopy(input, 0, sorted, 0, input.length);    Arrays.sort(sorted);    for (int i = 0; i < sorted.length; i++) {        assertSame(input[expectations[i]], sorted[i]);    }}
public void mahout_f5291_1() throws Exception
{    super.setUp();    context = EasyMock.createMock(Reducer.Context.class);    ll = EasyMock.createMock(LLCallback.class);    cl = new LLCallback() {        @Override        public double logLikelihoodRatio(long k11, long k12, long k21, long k22) {                        return LogLikelihood.logLikelihoodRatio(k11, k12, k21, k22);        }    };}
public double mahout_f5292_1(long k11, long k12, long k21, long k22)
{        return LogLikelihood.logLikelihoodRatio(k11, k12, k21, k22);}
public void mahout_f5293_0() throws Exception
{    LLRReducer reducer = new LLRReducer(ll);                Gram[][] input = { { new Gram("the best", 1, Gram.Type.NGRAM), new Gram("the", 2, Gram.Type.HEAD), new Gram("best", 1, Gram.Type.TAIL) }, { new Gram("best of", 1, Gram.Type.NGRAM), new Gram("best", 1, Gram.Type.HEAD), new Gram("of", 2, Gram.Type.TAIL) }, { new Gram("of times", 2, Gram.Type.NGRAM), new Gram("of", 2, Gram.Type.HEAD), new Gram("times", 2, Gram.Type.TAIL) }, { new Gram("times the", 1, Gram.Type.NGRAM), new Gram("times", 1, Gram.Type.HEAD), new Gram("the", 1, Gram.Type.TAIL) }, { new Gram("the worst", 1, Gram.Type.NGRAM), new Gram("the", 2, Gram.Type.HEAD), new Gram("worst", 1, Gram.Type.TAIL) }, { new Gram("worst of", 1, Gram.Type.NGRAM), new Gram("worst", 1, Gram.Type.HEAD), new Gram("of", 2, Gram.Type.TAIL) } };    int[][] expectations = {     { 1, 1, 0, 5 },     { 1, 0, 1, 5 },     { 2, 0, 0, 5 },     { 1, 0, 0, 6 },     { 1, 1, 0, 5 },     { 1, 0, 1, 5 } };    Configuration config = getConfiguration();    config.set(LLRReducer.NGRAM_TOTAL, "7");    EasyMock.expect(context.getConfiguration()).andReturn(config);    for (int i = 0; i < expectations.length; i++) {        int[] ee = expectations[i];        context.write(EasyMock.eq(new Text(input[i][0].getString())), (DoubleWritable) EasyMock.anyObject());        EasyMock.expect(ll.logLikelihoodRatio(ee[0], ee[1], ee[2], ee[3])).andDelegateTo(cl);    }    EasyMock.replay(context, ll);    reducer.setup(context);    for (Gram[] ii : input) {        Collection<Gram> vv = Lists.newLinkedList();        vv.addAll(Arrays.asList(ii).subList(1, ii.length));        reducer.reduce(ii[0], vv, context);    }    EasyMock.verify(ll);}
public void mahout_f5294_0() throws Exception
{    super.setUp();    Configuration conf = getConfiguration();    inputPath = getTestTempFilePath("documents/docs.file");    FileSystem fs = FileSystem.get(inputPath.toUri(), conf);    SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, inputPath, Text.class, Text.class);    try {        RandomDocumentGenerator gen = new RandomDocumentGenerator();        for (int i = 0; i < NUM_DOCS; i++) {            writer.append(new Text("Document::ID::" + i), new Text(gen.getRandomDocument()));            writer.append(new Text("Document::ID::" + i), new Text(SECOND_TEXT_BLOCK_IDENTIFIER));        }    } finally {        Closeables.close(writer, false);    }}
public void mahout_f5295_0() throws Exception
{    runTest(false, false);}
public void mahout_f5296_0() throws Exception
{    runTest(false, true);}
public void mahout_f5297_0() throws Exception
{    runTest(true, false);}
public void mahout_f5298_0() throws Exception
{    runTest(true, true);}
private void mahout_f5299_0(boolean sequential, boolean named) throws IOException, ClassNotFoundException, InterruptedException
{    Class<? extends Analyzer> analyzer = StandardAnalyzer.class;    Path tokenizedDocuments = getTestTempDirPath("output/tokenized-documents");    Path wordCount = getTestTempDirPath("output/wordcount");    Path tfVectors = new Path(wordCount, "tf-vectors");    Path tfidf = getTestTempDirPath("output/tfidf");    Path tfidfVectors = new Path(tfidf, "tfidf-vectors");    Configuration conf = getConfiguration();    DocumentProcessor.tokenizeDocuments(inputPath, analyzer, tokenizedDocuments, conf);    DictionaryVectorizer.createTermFrequencyVectors(tokenizedDocuments, wordCount, DictionaryVectorizer.DOCUMENT_VECTOR_OUTPUT_FOLDER, conf, 2, 1, 0.0f, -1.0f, true, 1, 100, sequential, named);    validateVectors(conf, NUM_DOCS, tfVectors, sequential, named);    Pair<Long[], List<Path>> docFrequenciesFeatures = TFIDFConverter.calculateDF(tfVectors, tfidf, conf, 100);    TFIDFConverter.processTfIdf(tfVectors, tfidf, conf, docFrequenciesFeatures, 1, -1, 2.0f, false, sequential, named, 1);    validateVectors(conf, NUM_DOCS, tfidfVectors, sequential, named);    Integer secondTextBlockIdentifierDimensionId = validateDictionary(wordCount, conf);    validateVectorContainingSecondTextBlock(conf, tfVectors, secondTextBlockIdentifierDimensionId);}
public static void mahout_f5300_0(Configuration conf, int numDocs, Path vectorPath, boolean sequential, boolean named)
{    int count = 0;    for (VectorWritable value : new SequenceFileDirValueIterable<VectorWritable>(vectorPath, PathType.LIST, PathFilters.partFilter(), null, true, conf)) {        count++;        Vector v = value.get();        if (named) {            assertTrue("Expected NamedVector", v instanceof NamedVector);            v = ((NamedVector) v).getDelegate();        }        if (sequential) {            assertTrue("Expected SequentialAccessSparseVector", v instanceof SequentialAccessSparseVector);        } else {            assertTrue("Expected RandomAccessSparseVector", v instanceof RandomAccessSparseVector);        }    }    assertEquals("Expected " + numDocs + " documents", numDocs, count);}
private Integer mahout_f5301_0(Path dictionaryDirectoryPath, Configuration conf)
{    PathFilter dictionaryChunkPathFilter = new PathFilter() {        @Override        public boolean accept(Path path) {            String name = path.getName();            return name.startsWith("dictionary.file");        }    };    Map<String, Integer> dictionary = new HashMap<>();    for (Pair<Text, IntWritable> value : new SequenceFileDirIterable<Text, IntWritable>(dictionaryDirectoryPath, PathType.LIST, dictionaryChunkPathFilter, null, true, conf)) {        dictionary.put(value.getFirst().toString(), value.getSecond().get());    }    Integer secondTextBlockIdentifierDimensionId = dictionary.get(SECOND_TEXT_BLOCK_IDENTIFIER.toLowerCase());    assertNotNull("Token '" + SECOND_TEXT_BLOCK_IDENTIFIER + "' must be in dictionary ", secondTextBlockIdentifierDimensionId);    assertTrue("Dictionary must contain more than just 1 element!", dictionary.size() > 1);    return secondTextBlockIdentifierDimensionId;}
public boolean mahout_f5302_0(Path path)
{    String name = path.getName();    return name.startsWith("dictionary.file");}
public static void mahout_f5303_0(Configuration conf, Path vectorPath, int dimensionId)
{    for (VectorWritable value : new SequenceFileDirValueIterable<VectorWritable>(vectorPath, PathType.LIST, PathFilters.partFilter(), null, true, conf)) {        assertTrue("The vector must contain the second text block", value.get().get(dimensionId) > 0);    }}
public void mahout_f5304_0() throws Exception
{    Configuration configuration = getConfiguration();    Path input = new Path(getTestTempDirPath(), "inputDir");    Path output = new Path(getTestTempDirPath(), "outputDir");    FileSystem fs = FileSystem.get(input.toUri(), configuration);    String documentId1 = "123";    String documentId2 = "456";    SequenceFile.Writer writer = new SequenceFile.Writer(fs, configuration, input, Text.class, Text.class);    try {        String text1 = "A test for the document processor";        writer.append(new Text(documentId1), new Text(text1));        String text2 = "and another one";        writer.append(new Text(documentId2), new Text(text2));    } finally {        Closeables.close(writer, false);    }    DocumentProcessor.tokenizeDocuments(input, StandardAnalyzer.class, output, configuration);    FileStatus[] statuses = fs.listStatus(output, PathFilters.logsCRCFilter());    assertEquals(1, statuses.length);    Path filePath = statuses[0].getPath();    SequenceFile.Reader reader = new SequenceFile.Reader(fs, filePath, configuration);    Text key = ClassUtils.instantiateAs((Class<? extends Text>) reader.getKeyClass(), Text.class);    StringTuple value = ClassUtils.instantiateAs((Class<? extends StringTuple>) reader.getValueClass(), StringTuple.class);    reader.next(key, value);    assertEquals(documentId1, key.toString());    assertEquals(Arrays.asList("test", "document", "processor"), value.getEntries());    reader.next(key, value);    assertEquals(documentId2, key.toString());    assertEquals(Arrays.asList("another", "one"), value.getEntries());}
public void mahout_f5305_0() throws Exception
{    super.setUp();    conf = getConfiguration();    inputPath = getTestTempFilePath("documents/docs.file");    FileSystem fs = FileSystem.get(inputPath.toUri(), conf);    SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, inputPath, Text.class, Text.class);    RandomDocumentGenerator gen = new RandomDocumentGenerator();    try {        for (int i = 0; i < NUM_DOCS; i++) {            writer.append(new Text("Document::ID::" + i), new Text(gen.getRandomDocument()));        }    } finally {        Closeables.close(writer, false);    }}
public void mahout_f5306_0() throws Exception
{    runTest(false, false);}
public void mahout_f5307_0() throws Exception
{    runTest(false, true);}
public void mahout_f5308_0() throws Exception
{    runTest(true, false);}
public void mahout_f5309_0() throws Exception
{    runTest(true, true);}
private void mahout_f5310_0(boolean sequential, boolean named) throws Exception
{    Path tmpPath = getTestTempDirPath();    Path outputPath = new Path(tmpPath, "output");    List<String> argList = Lists.newLinkedList();    ;    argList.add("-i");    argList.add(inputPath.toString());    argList.add("-o");    argList.add(outputPath.toString());    if (sequential) {        argList.add("-seq");    }    if (named) {        argList.add("-nv");    }    String[] args = argList.toArray(new String[argList.size()]);    ToolRunner.run(getConfiguration(), new EncodedVectorsFromSequenceFiles(), args);    SequenceFileDirIterator<Text, VectorWritable> iter = new SequenceFileDirIterator<>(outputPath, PathType.LIST, PathFilters.partFilter(), null, true, conf);    int seen = 0;    while (iter.hasNext()) {        Pair<Text, VectorWritable> next = iter.next();        if (sequential && !named) {            assertTrue(next.getSecond().get() instanceof SequentialAccessSparseVector);        } else if (named) {            assertTrue(next.getSecond().get() instanceof NamedVector);        }        seen++;    }    assertEquals("Missed some vectors", NUM_DOCS, seen);}
public void mahout_f5311_0()
{    CachingStaticWordValueEncoder encoder = new CachingStaticWordValueEncoder(NAME, CARDINALITY);    Vector v = new DenseVector(CARDINALITY);    encoder.addToVector(WORD, v);    assertFalse("testCacheAreUsedStaticWord: cache should have values", encoder.getCaches()[0].isEmpty());}
public void mahout_f5312_0()
{    CachingContinuousValueEncoder encoder = new CachingContinuousValueEncoder(NAME, CARDINALITY);    Vector v = new DenseVector(CARDINALITY);    encoder.addToVector(CONTINUOUSVAL, 1.0, v);    assertFalse("testCacheAreUsedContinuous: cache should have values", encoder.getCaches()[0].isEmpty());}
public void mahout_f5313_0()
{    FeatureVectorEncoder enc = new ConstantValueEncoder("foo");    Vector v1 = new DenseVector(20);    enc.addToVector((byte[]) null, -123, v1);    assertEquals(-123, v1.minValue(), 0);    assertEquals(0, v1.maxValue(), 0);    assertEquals(123, v1.norm(1), 0);    v1 = new DenseVector(20);    enc.addToVector((byte[]) null, 123, v1);    assertEquals(123, v1.maxValue(), 0);    assertEquals(0, v1.minValue(), 0);    assertEquals(123, v1.norm(1), 0);    Vector v2 = new DenseVector(20);    enc.setProbes(2);    enc.addToVector((byte[]) null, 123, v2);    assertEquals(123, v2.maxValue(), 0);    assertEquals(2 * 123, v2.norm(1), 0);            v1 = v2.minus(v1);    assertEquals(123, v1.maxValue(), 0);    assertEquals(123, v1.norm(1), 0);    Vector v3 = new DenseVector(20);    enc.setProbes(2);    enc.addToVector((byte[]) null, 100, v3);    v1 = v2.minus(v3);    assertEquals(23, v1.maxValue(), 0);    assertEquals(2 * 23, v1.norm(1), 0);    enc.addToVector((byte[]) null, 7, v1);    assertEquals(30, v1.maxValue(), 0);    assertEquals(2 * 30, v1.norm(1), 0);    assertEquals(30, v1.get(9), 0);    assertEquals(30, v1.get(10), 0);}
public void mahout_f5314_0()
{    FeatureVectorEncoder enc = new ConstantValueEncoder("foo");    assertEquals("foo", enc.asString("123"));}
public void mahout_f5315_0()
{    FeatureVectorEncoder enc = new ContinuousValueEncoder("foo");    Vector v1 = new DenseVector(20);    enc.addToVector("-123", v1);    assertEquals(-123, v1.minValue(), 0);    assertEquals(0, v1.maxValue(), 0);    assertEquals(123, v1.norm(1), 0);    v1 = new DenseVector(20);    enc.addToVector("123", v1);    assertEquals(123, v1.maxValue(), 0);    assertEquals(0, v1.minValue(), 0);    assertEquals(123, v1.norm(1), 0);    Vector v2 = new DenseVector(20);    enc.setProbes(2);    enc.addToVector("123", v2);    assertEquals(123, v2.maxValue(), 0);    assertEquals(2 * 123, v2.norm(1), 0);            v1 = v2.minus(v1);    assertEquals(123, v1.maxValue(), 0);    assertEquals(123, v1.norm(1), 0);    Vector v3 = new DenseVector(20);    enc.setProbes(2);    enc.addToVector("100", v3);    v1 = v2.minus(v3);    assertEquals(23, v1.maxValue(), 0);    assertEquals(2 * 23, v1.norm(1), 0);    enc.addToVector("7", v1);    assertEquals(30, v1.maxValue(), 0);    assertEquals(2 * 30, v1.norm(1), 0);    assertEquals(30, v1.get(10), 0);    assertEquals(30, v1.get(18), 0);    v2 = new DenseVector(20);    v3 = new DenseVector(20);    enc.setProbes(6);    enc.addToVector("145", v2);    enc.addToVector((byte[]) null, 145, v3);    assertEquals(0, v2.minus(v3).norm(1), 0);    try {        enc.addToVector("foobar", v1);        fail("Should have noticed bad numeric format");    } catch (NumberFormatException e) {        assertEquals("For input string: \"foobar\"", e.getMessage());    }}
public void mahout_f5316_0()
{    FeatureVectorEncoder enc = new ContinuousValueEncoder("foo");    assertEquals("foo:123", enc.asString("123"));}
public void mahout_f5317_0()
{    WordValueEncoder wv = new StaticWordValueEncoder("word");    ContinuousValueEncoder cv = new ContinuousValueEncoder("cont");    InteractionValueEncoder enc = new InteractionValueEncoder("interactions", wv, cv);    Vector v1 = new DenseVector(200);    enc.addInteractionToVector("a", "1.0", 1.0, v1);    int k = enc.getProbes();        assertEquals((float) k, v1.norm(1), 0);    assertEquals(1.0, v1.maxValue(), 0);        enc.addInteractionToVector("a", "1.0", 1.0, v1);    assertEquals((float) k * 2, v1.norm(1), 0);    assertEquals(2.0, v1.maxValue(), 0);    Vector v2 = new DenseVector(20000);    enc.addInteractionToVector("a", "1.0", 1.0, v2);    wv.addToVector("a", v2);    cv.addToVector("1.0", v2);    k = enc.getProbes();        assertEquals((float) (k + wv.getProbes() + cv.getProbes()), v2.norm(1), 1.0e-3);}
public void mahout_f5318_0()
{    WordValueEncoder wv = new StaticWordValueEncoder("word");    ContinuousValueEncoder cv = new ContinuousValueEncoder("cont");    InteractionValueEncoder enc = new InteractionValueEncoder("interactions", wv, cv);    Vector v1 = new DenseVector(200);    enc.addInteractionToVector("a", "0.9", 0.5, v1);    int k = enc.getProbes();        assertEquals((float) k * 0.5 * 0.9, v1.norm(1), 0);    assertEquals(0.5 * 0.9, v1.maxValue(), 0);}
public void mahout_f5319_0()
{    WordValueEncoder wv = new StaticWordValueEncoder("word");    TextValueEncoder tv = new TextValueEncoder("text");    InteractionValueEncoder enc = new InteractionValueEncoder("interactions", wv, tv);    Vector v1 = new DenseVector(200);    enc.addInteractionToVector("a", "some text here", 1.0, v1);    int k = enc.getProbes();        assertEquals((float) k * 3, v1.norm(1), 0);}
public void mahout_f5320_0()
{    StaticWordValueEncoder encoder1 = new StaticWordValueEncoder("first");    StaticWordValueEncoder encoder2 = new StaticWordValueEncoder("second");    Map<String, Set<Integer>> traceDictionary = Maps.newHashMap();    InteractionValueEncoder interactions = new InteractionValueEncoder("interactions", encoder1, encoder2);    interactions.setProbes(1);    interactions.setTraceDictionary(traceDictionary);    Vector v = new DenseVector(10);    interactions.addInteractionToVector("a", "b", 1, v);    assertEquals(1, v.getNumNonZeroElements());    assertEquals(1, traceDictionary.size());    assertEquals("interactions=a:b", getFirst(traceDictionary.keySet(), null));}
public void mahout_f5321_0()
{    TextValueEncoder enc = new TextValueEncoder("text");    Vector v1 = new DenseVector(200);    enc.addToVector("test1 and more", v1);    enc.flush(1, v1);        assertEquals(6.0, v1.norm(1), 0);    assertEquals(1.0, v1.maxValue(), 0);        StaticWordValueEncoder w = new StaticWordValueEncoder("text");    w.setDictionary(ImmutableMap.<String, Double>of("word1", 3.0, "word2", 1.5));    enc.setWordEncoder(w);        Vector v2 = new DenseVector(200);    enc.addToVector("test1 and more", v2);    enc.flush(1, v2);        Vector v3 = new DenseVector(200);    w.addToVector("test1", v3);    w.addToVector("and", v3);    w.addToVector("more", v3);    assertEquals(0, v3.minus(v2).norm(1), 0);        assertEquals(v3.zSum(), v3.dot(v1), 0);}
public void mahout_f5322_0()
{    Locale.setDefault(Locale.ENGLISH);    FeatureVectorEncoder enc = new TextValueEncoder("text");    assertEquals("[text:test1:1.0000, text:and:1.0000, text:more:1.0000]", enc.asString("test1 and more"));}
public void mahout_f5323_0() throws Exception
{    LuceneTextValueEncoder enc = new LuceneTextValueEncoder("text");    enc.setAnalyzer(new WhitespaceAnalyzer());    Vector v1 = new DenseVector(200);    enc.addToVector("test1 and more", v1);    enc.flush(1, v1);            assertEquals(6.0, v1.norm(1), 0);    assertEquals(1.0, v1.maxValue(), 0);    v1 = new DenseVector(200);    enc.addToVector("", v1);    enc.flush(1, v1);    assertEquals(0.0, v1.norm(1), 0);    assertEquals(0.0, v1.maxValue(), 0);    v1 = new DenseVector(200);    StringBuilder builder = new StringBuilder(5000);    for (int i = 0; i < 1000; i++) {                builder.append("token_").append(i).append(' ');    }    enc.addToVector(builder.toString(), v1);    enc.flush(1, v1);        assertEquals(2000.0, v1.norm(1), 0);    assertEquals(19.0, v1.maxValue(), 0);}
public void mahout_f5324_0()
{    FeatureVectorEncoder enc = new StaticWordValueEncoder("word");    Vector v = new DenseVector(200);    enc.addToVector("word1", v);    enc.addToVector("word2", v);    Iterator<Vector.Element> i = v.nonZeroes().iterator();    Iterator<Integer> j = ImmutableList.of(7, 118, 119, 199).iterator();    while (i.hasNext()) {        Vector.Element element = i.next();        assertEquals(j.next().intValue(), element.index());        assertEquals(1, element.get(), 0);    }    assertFalse(j.hasNext());}
public void mahout_f5325_0()
{    Locale.setDefault(Locale.ENGLISH);    FeatureVectorEncoder enc = new StaticWordValueEncoder("word");    assertEquals("word:w1:1.0000", enc.asString("w1"));}
public void mahout_f5326_0()
{    StaticWordValueEncoder enc = new StaticWordValueEncoder("word");    enc.setDictionary(ImmutableMap.<String, Double>of("word1", 3.0, "word2", 1.5));    Vector v = new DenseVector(200);    enc.addToVector("word1", v);    enc.addToVector("word2", v);    enc.addToVector("word3", v);    Iterator<Vector.Element> i = v.nonZeroes().iterator();    Iterator<Integer> j = ImmutableList.of(7, 101, 118, 119, 152, 199).iterator();    Iterator<Double> k = ImmutableList.of(3.0, 0.75, 1.5, 1.5, 0.75, 3.0).iterator();    while (i.hasNext()) {        Vector.Element element = i.next();        assertEquals(j.next().intValue(), element.index());    }    i = v.nonZeroes().iterator();    while (i.hasNext()) {        Vector.Element element = i.next();        assertEquals(String.format("checking v[%d]", element.index()), k.next(), element.get(), 0);    }    assertFalse(j.hasNext());}
public void mahout_f5327_0()
{    FeatureVectorEncoder enc = new AdaptiveWordValueEncoder("word");    Vector v = new DenseVector(200);        enc.addToVector("word1", v);        enc.addToVector("word2", v);        enc.addToVector("word1", v);        enc.addToVector("word3", v);    Iterator<Vector.Element> i = v.nonZeroes().iterator();    Iterator<Integer> j = ImmutableList.of(7, 101, 118, 119, 152, 199).iterator();    Iterator<Double> k = ImmutableList.of(Math.log(2 / 1.5) + Math.log(4.5 / 2.5), Math.log(6 / 1.5), Math.log(3.5 / 1.5), Math.log(3.5 / 1.5), Math.log(6 / 1.5), Math.log(2 / 1.5) + Math.log(4.5 / 2.5)).iterator();    while (i.hasNext()) {        Vector.Element element = i.next();        assertEquals(j.next().intValue(), element.index());        assertEquals(k.next(), element.get(), 1.0e-6);    }    assertFalse(j.hasNext());}
public void mahout_f5328_0() throws Exception
{    super.setUp();    conf = getConfiguration();    inputPath = getTestTempFilePath("documents/docs.file");    FileSystem fs = FileSystem.get(inputPath.toUri(), conf);    SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, inputPath, Text.class, Text.class);    RandomDocumentGenerator gen = new RandomDocumentGenerator();    for (int i = 0; i < NUM_DOCS; i++) {        writer.append(new Text("Document::ID::" + i), new Text(enhanceWithHighDFWords(gen.getRandomDocument())));    }    writer.close();}
private static String mahout_f5329_0(String initialDoc)
{    StringBuilder sb = new StringBuilder(initialDoc);    for (String word : HIGH_DF_WORDS) {        sb.append(' ').append(word);    }    return sb.toString();}
public void mahout_f5330_0() throws Exception
{    runTest(false);}
public void mahout_f5331_0() throws Exception
{    runTest(true);}
private void mahout_f5332_0(boolean prune) throws Exception
{    Path outputPath = getTestTempFilePath("output");    List<String> argList = Lists.newLinkedList();    argList.add("-i");    argList.add(inputPath.toString());    argList.add("-o");    argList.add(outputPath.toString());    if (prune) {        argList.add("-xs");                argList.add("3");    } else {        argList.add("--maxDFPercent");                argList.add("100");    }    argList.add("-seq");    argList.add("-nv");    String[] args = argList.toArray(new String[argList.size()]);    ToolRunner.run(conf, new SparseVectorsFromSequenceFiles(), args);    Path dictionary = new Path(outputPath, "dictionary.file-0");    Path tfVectors = new Path(outputPath, "tf-vectors");    Path tfidfVectors = new Path(outputPath, "tfidf-vectors");    int[] highDFWordsDictionaryIndices = getHighDFWordsDictionaryIndices(dictionary);    validateVectors(tfVectors, highDFWordsDictionaryIndices, prune);    validateVectors(tfidfVectors, highDFWordsDictionaryIndices, prune);}
private int[] mahout_f5333_0(Path dictionaryPath)
{    int[] highDFWordsDictionaryIndices = new int[HIGH_DF_WORDS.length];    List<String> highDFWordsList = Arrays.asList(HIGH_DF_WORDS);    for (Pair<Text, IntWritable> record : new SequenceFileDirIterable<Text, IntWritable>(dictionaryPath, PathType.GLOB, null, null, true, conf)) {        int index = highDFWordsList.indexOf(record.getFirst().toString());        if (index > -1) {            highDFWordsDictionaryIndices[index] = record.getSecond().get();        }    }    return highDFWordsDictionaryIndices;}
private void mahout_f5334_0(Path vectorPath, int[] highDFWordsDictionaryIndices, boolean prune) throws Exception
{    assertTrue("Path does not exist", vectorPath.getFileSystem(conf).exists(vectorPath));    for (VectorWritable value : new SequenceFileDirValueIterable<VectorWritable>(vectorPath, PathType.LIST, PathFilters.partFilter(), null, true, conf)) {        Vector v = ((NamedVector) value.get()).getDelegate();        for (int i = 0; i < highDFWordsDictionaryIndices.length; i++) {            if (prune) {                assertEquals("Found vector for which word '" + HIGH_DF_WORDS[i] + "' is not pruned", 0.0, v.get(highDFWordsDictionaryIndices[i]), 0.0);            } else {                assertTrue("Found vector for which word '" + HIGH_DF_WORDS[i] + "' is pruned, and shouldn't have been", v.get(highDFWordsDictionaryIndices[i]) != 0.0);            }        }    }}
private char mahout_f5335_0()
{    return DELIM.charAt(random.nextInt(DELIM.length()));}
public String mahout_f5336_0()
{    int length = (AVG_DOCUMENT_LENGTH >> 1) + random.nextInt(AVG_DOCUMENT_LENGTH);    StringBuilder sb = new StringBuilder(length * AVG_SENTENCE_LENGTH * AVG_WORD_LENGTH);    for (int i = 0; i < length; i++) {        sb.append(getRandomSentence());    }    return sb.toString();}
public String mahout_f5337_0()
{    int length = (AVG_SENTENCE_LENGTH >> 1) + random.nextInt(AVG_SENTENCE_LENGTH);    StringBuilder sb = new StringBuilder(length * AVG_WORD_LENGTH);    for (int i = 0; i < length; i++) {        sb.append(getRandomString()).append(' ');    }    sb.append(getRandomDelimiter());    return sb.toString();}
public String mahout_f5338_0()
{    int length = (AVG_WORD_LENGTH >> 1) + random.nextInt(AVG_WORD_LENGTH);    StringBuilder sb = new StringBuilder(length);    for (int i = 0; i < length; i++) {        sb.append(CHARSET.charAt(random.nextInt(CHARSET.length())));    }    if (random.nextInt(10) == 0) {        sb.append(ERRORSET.charAt(random.nextInt(ERRORSET.length())));    }    return sb.toString();}
private void mahout_f5339_0() throws IOException
{    conf = getConfiguration();    inputPath = getTestTempFilePath("documents/docs.file");    FileSystem fs = FileSystem.get(inputPath.toUri(), conf);    SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, inputPath, Text.class, Text.class);    RandomDocumentGenerator gen = new RandomDocumentGenerator();    try {        for (int i = 0; i < NUM_DOCS; i++) {            writer.append(new Text("Document::ID::" + i), new Text(gen.getRandomDocument()));        }    } finally {        Closeables.close(writer, false);    }}
public void mahout_f5340_0() throws Exception
{    setupDocs();    runTest(false, false, false, -1, NUM_DOCS);}
public void mahout_f5341_0() throws Exception
{    setupDocs();    runTest(false, false, true, -1, NUM_DOCS);}
public void mahout_f5342_0() throws Exception
{    setupDocs();    runTest(false, true, false, -1, NUM_DOCS);}
public void mahout_f5343_0() throws Exception
{    setupDocs();    runTest(false, true, true, -1, NUM_DOCS);}
public void mahout_f5344_0() throws Exception
{    conf = getConfiguration();    inputPath = getTestTempFilePath("documents/docs.file");    FileSystem fs = FileSystem.get(inputPath.toUri(), conf);    SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, inputPath, Text.class, Text.class);    String[] docs = { "a b c", "a a a a a b", "a a a a a c" };    try {        for (int i = 0; i < docs.length; i++) {            writer.append(new Text("Document::ID::" + i), new Text(docs[i]));        }    } finally {        Closeables.close(writer, false);    }    Path outPath = runTest(false, false, false, 2, docs.length);    Path tfidfVectors = new Path(outPath, "tfidf-vectors");    int count = 0;    Vector[] res = new Vector[docs.length];    for (VectorWritable value : new SequenceFileDirValueIterable<VectorWritable>(tfidfVectors, PathType.LIST, PathFilters.partFilter(), null, true, conf)) {        Vector v = value.get();        System.out.println(v);        assertEquals(2, v.size());        res[count] = v;        count++;    }    assertEquals(docs.length, count);        assertEquals(2, res[0].getNumNondefaultElements());    assertEquals(1, res[1].getNumNondefaultElements());    assertEquals(1, res[2].getNumNondefaultElements());}
public void mahout_f5345_0() throws Exception
{    conf = getConfiguration();    FileSystem fs = FileSystem.get(conf);    inputPath = getTestTempFilePath("documents/docs.file");    SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, inputPath, Text.class, Text.class);    String[] docs = { "a b c", "a a a a a b", "a a a a a c" };    try {        for (int i = 0; i < docs.length; i++) {            writer.append(new Text("Document::ID::" + i), new Text(docs[i]));        }    } finally {        Closeables.close(writer, false);    }    Path outPath = runTest(true, false, false, 2, docs.length);    Path tfVectors = new Path(outPath, "tf-vectors");    int count = 0;    Vector[] res = new Vector[docs.length];    for (VectorWritable value : new SequenceFileDirValueIterable<VectorWritable>(tfVectors, PathType.LIST, PathFilters.partFilter(), null, true, conf)) {        Vector v = value.get();        System.out.println(v);        assertEquals(2, v.size());        res[count] = v;        count++;    }    assertEquals(docs.length, count);        assertEquals(2, res[0].getNumNondefaultElements());    assertEquals(1, res[1].getNumNondefaultElements());    assertEquals(1, res[2].getNumNondefaultElements());}
private Path mahout_f5346_0(boolean tfWeighting, boolean sequential, boolean named, double maxDFSigma, int numDocs) throws Exception
{    Path outputPath = getTestTempFilePath("output");    List<String> argList = Lists.newLinkedList();    argList.add("-i");    argList.add(inputPath.toString());    argList.add("-o");    argList.add(outputPath.toString());    if (sequential) {        argList.add("-seq");    }    if (named) {        argList.add("-nv");    }    if (maxDFSigma >= 0) {        argList.add("--maxDFSigma");        argList.add(String.valueOf(maxDFSigma));    }    if (tfWeighting) {        argList.add("--weight");        argList.add("tf");    }    String[] args = argList.toArray(new String[argList.size()]);    ToolRunner.run(getConfiguration(), new SparseVectorsFromSequenceFiles(), args);    Path tfVectors = new Path(outputPath, "tf-vectors");    Path tfidfVectors = new Path(outputPath, "tfidf-vectors");    DictionaryVectorizerTest.validateVectors(conf, numDocs, tfVectors, sequential, named);    if (!tfWeighting) {        DictionaryVectorizerTest.validateVectors(conf, numDocs, tfidfVectors, sequential, named);    }    return outputPath;}
public List<RecommendedItem> mahout_f5347_0(long userID, int howMany) throws TasteException
{    return recommender.recommend(userID, howMany);}
public List<RecommendedItem> mahout_f5348_0(long userID, int howMany, boolean includeKnownItems) throws TasteException
{    return recommend(userID, howMany, null, includeKnownItems);}
public List<RecommendedItem> mahout_f5349_0(long userID, int howMany, IDRescorer rescorer) throws TasteException
{    return recommender.recommend(userID, howMany, rescorer, false);}
public List<RecommendedItem> mahout_f5350_0(long userID, int howMany, IDRescorer rescorer, boolean includeKnownItems) throws TasteException
{    return recommender.recommend(userID, howMany, rescorer, includeKnownItems);}
public float mahout_f5351_0(long userID, long itemID) throws TasteException
{    return recommender.estimatePreference(userID, itemID);}
public void mahout_f5352_0(long userID, long itemID, float value) throws TasteException
{    recommender.setPreference(userID, itemID, value);}
public void mahout_f5353_0(long userID, long itemID) throws TasteException
{    recommender.removePreference(userID, itemID);}
public DataModel mahout_f5354_0()
{    return recommender.getDataModel();}
public void mahout_f5355_0(Collection<Refreshable> alreadyRefreshed)
{    recommender.refresh(alreadyRefreshed);}
public String mahout_f5356_0()
{    return "BookCrossingBooleanRecommender[recommender:" + recommender + ']';}
public Recommender mahout_f5357_0(DataModel dataModel) throws TasteException
{    return new BookCrossingBooleanRecommender(dataModel);}
public static void mahout_f5358_1(String... args) throws IOException, TasteException, OptionException
{    RecommenderIRStatsEvaluator evaluator = new GenericRecommenderIRStatsEvaluator();    File ratingsFile = TasteOptionParser.getRatings(args);    DataModel model = ratingsFile == null ? new BookCrossingDataModel(true) : new BookCrossingDataModel(ratingsFile, true);    IRStatistics evaluation = evaluator.evaluate(new BookCrossingBooleanRecommenderBuilder(), new BookCrossingDataModelBuilder(), model, null, 3, Double.NEGATIVE_INFINITY, 1.0);    }
private static File mahout_f5359_0(File originalFile, boolean ignoreRatings) throws IOException
{    if (!originalFile.exists()) {        throw new FileNotFoundException(originalFile.toString());    }    File resultFile = new File(new File(System.getProperty("java.io.tmpdir")), "taste.bookcrossing.txt");    resultFile.delete();    Writer writer = null;    try {        writer = new OutputStreamWriter(new FileOutputStream(resultFile), Charsets.UTF_8);        for (String line : new FileLineIterable(originalFile, true)) {                        if (line.endsWith("\"0\"")) {                continue;            }                        String convertedLine = NON_DIGIT_SEMICOLON_PATTERN.matcher(line).replaceAll("").replace(';', ',');                        if (convertedLine.contains(",,")) {                continue;            }            if (ignoreRatings) {                                convertedLine = convertedLine.substring(0, convertedLine.lastIndexOf(','));            }            writer.write(convertedLine);            writer.write('\n');        }        writer.flush();    } catch (IOException ioe) {        resultFile.delete();        throw ioe;    } finally {        Closeables.close(writer, false);    }    return resultFile;}
public String mahout_f5360_0()
{    return "BookCrossingDataModel";}
public DataModel mahout_f5361_0(FastByIDMap<PreferenceArray> trainingData)
{    return new GenericBooleanPrefDataModel(GenericBooleanPrefDataModel.toDataMap(trainingData));}
public List<RecommendedItem> mahout_f5362_0(long userID, int howMany) throws TasteException
{    return recommender.recommend(userID, howMany);}
public List<RecommendedItem> mahout_f5363_0(long userID, int howMany, boolean includeKnownItems) throws TasteException
{    return recommend(userID, howMany, null, includeKnownItems);}
public List<RecommendedItem> mahout_f5364_0(long userID, int howMany, IDRescorer rescorer) throws TasteException
{    return recommender.recommend(userID, howMany, rescorer, false);}
public List<RecommendedItem> mahout_f5365_0(long userID, int howMany, IDRescorer rescorer, boolean includeKnownItems) throws TasteException
{    return recommender.recommend(userID, howMany, rescorer, false);}
public float mahout_f5366_0(long userID, long itemID) throws TasteException
{    return recommender.estimatePreference(userID, itemID);}
public void mahout_f5367_0(long userID, long itemID, float value) throws TasteException
{    recommender.setPreference(userID, itemID, value);}
public void mahout_f5368_0(long userID, long itemID) throws TasteException
{    recommender.removePreference(userID, itemID);}
public DataModel mahout_f5369_0()
{    return recommender.getDataModel();}
public void mahout_f5370_0(Collection<Refreshable> alreadyRefreshed)
{    recommender.refresh(alreadyRefreshed);}
public String mahout_f5371_0()
{    return "BookCrossingRecommender[recommender:" + recommender + ']';}
public Recommender mahout_f5372_0(DataModel dataModel) throws TasteException
{    return new BookCrossingRecommender(dataModel);}
public static void mahout_f5373_1(String... args) throws IOException, TasteException, OptionException
{    RecommenderEvaluator evaluator = new AverageAbsoluteDifferenceRecommenderEvaluator();    File ratingsFile = TasteOptionParser.getRatings(args);    DataModel model = ratingsFile == null ? new BookCrossingDataModel(false) : new BookCrossingDataModel(ratingsFile, false);    double evaluation = evaluator.evaluate(new BookCrossingRecommenderBuilder(), null, model, 0.9, 0.3);    }
public static String mahout_f5374_0(CharSequence address)
{        return ADDRESS_CLEANUP.matcher(address).replaceAll("");}
public static void mahout_f5375_0(Configuration conf, String fromPrefix, OpenObjectIntHashMap<String> fromDictionary, String msgIdPrefix, OpenObjectIntHashMap<String> msgIdDictionary) throws IOException
{    Path[] localFiles = HadoopUtil.getCachedFiles(conf);    FileSystem fs = FileSystem.getLocal(conf);    for (Path dictionaryFile : localFiles) {                OpenObjectIntHashMap<String> dictionary = null;        if (dictionaryFile.getName().startsWith(fromPrefix)) {            dictionary = fromDictionary;        } else if (dictionaryFile.getName().startsWith(msgIdPrefix)) {            dictionary = msgIdDictionary;        }        if (dictionary != null) {            dictionaryFile = fs.makeQualified(dictionaryFile);            for (Pair<Writable, IntWritable> record : new SequenceFileIterable<Writable, IntWritable>(dictionaryFile, true, conf)) {                dictionary.put(record.getFirst().toString(), record.getSecond().get());            }        }    }}
public static String[] mahout_f5376_0(CharSequence rawRefs)
{    String[] splits;    if (rawRefs != null && rawRefs.length() > 0) {        splits = SPACE_OR_CLOSE_ANGLE.split(rawRefs);        for (int i = 0; i < splits.length; i++) {            splits[i] = ANGLE_BRACES.matcher(splits[i]).replaceAll("");        }    } else {        splits = EMPTY;    }    return splits;}
protected void mahout_f5377_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    separator = context.getConfiguration().get(EmailUtility.SEPARATOR);}
protected void mahout_f5378_0(Text key, Text value, Context context) throws IOException, InterruptedException
{        String valStr = value.toString();    int idx = valStr.indexOf(separator);    if (idx == -1) {        context.getCounter(EmailUtility.Counters.NO_FROM_ADDRESS).increment(1);    } else {        String full = valStr.substring(0, idx);                                full = EmailUtility.cleanUpEmailAddress(full);        if (EmailUtility.WHITESPACE.matcher(full).matches()) {            context.getCounter(EmailUtility.Counters.NO_FROM_ADDRESS).increment(1);        } else {            context.write(new Text(full), new VarIntWritable(1));        }    }}
protected void mahout_f5379_0(Text key, Iterable<VarIntWritable> values, Context context) throws IOException, InterruptedException
{    int sum = 0;    for (VarIntWritable value : values) {        sum += value.get();    }    context.write(new Text(key), new VarIntWritable(sum));}
public static void mahout_f5380_0(String[] args) throws Exception
{    ToolRunner.run(new Configuration(), new MailToPrefsDriver(), args);}
public int mahout_f5381_1(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption(DefaultOptionCreator.overwriteOption().create());    addOption("chunkSize", "cs", "The size of chunks to write.  Default is 100 mb", "100");    addOption("separator", "sep", "The separator used in the input file to separate to, from, subject.  Default is \\n", "\n");    addOption("from", "f", "The position in the input text (value) where the from email is located, starting from " + "zero (0).", "0");    addOption("refs", "r", "The position in the input text (value) where the reference ids are located, " + "starting from zero (0).", "1");    addOption(buildOption("useCounts", "u", "If set, then use the number of times the user has interacted with a " + "thread as an indication of their preference.  Otherwise, use boolean preferences.", false, false, String.valueOf(true)));    Map<String, List<String>> parsedArgs = parseArguments(args);    Path input = getInputPath();    Path output = getOutputPath();    int chunkSize = Integer.parseInt(getOption("chunkSize"));    String separator = getOption("separator");    Configuration conf = getConf();    boolean useCounts = hasOption("useCounts");    AtomicInteger currentPhase = new AtomicInteger();    int[] msgDim = new int[1];        List<Path> msgIdChunks = null;    boolean overwrite = hasOption(DefaultOptionCreator.OVERWRITE_OPTION);        if (shouldRunNextPhase(parsedArgs, currentPhase)) {                        Path msgIdsPath = new Path(output, "msgIds");        if (overwrite) {            HadoopUtil.delete(conf, msgIdsPath);        }                Job createMsgIdDictionary = prepareJob(input, msgIdsPath, SequenceFileInputFormat.class, MsgIdToDictionaryMapper.class, Text.class, VarIntWritable.class, MailToDictionaryReducer.class, Text.class, VarIntWritable.class, SequenceFileOutputFormat.class);        boolean succeeded = createMsgIdDictionary.waitForCompletion(true);        if (!succeeded) {            return -1;        }                msgIdChunks = createDictionaryChunks(msgIdsPath, output, "msgIds-dictionary-", createMsgIdDictionary.getConfiguration(), chunkSize, msgDim);    }        List<Path> fromChunks = null;    if (shouldRunNextPhase(parsedArgs, currentPhase)) {        Path fromIdsPath = new Path(output, "fromIds");        if (overwrite) {            HadoopUtil.delete(conf, fromIdsPath);        }                Job createFromIdDictionary = prepareJob(input, fromIdsPath, SequenceFileInputFormat.class, FromEmailToDictionaryMapper.class, Text.class, VarIntWritable.class, MailToDictionaryReducer.class, Text.class, VarIntWritable.class, SequenceFileOutputFormat.class);        createFromIdDictionary.getConfiguration().set(EmailUtility.SEPARATOR, separator);        boolean succeeded = createFromIdDictionary.waitForCompletion(true);        if (!succeeded) {            return -1;        }                int[] fromDim = new int[1];        fromChunks = createDictionaryChunks(fromIdsPath, output, "fromIds-dictionary-", createFromIdDictionary.getConfiguration(), chunkSize, fromDim);    }        if (shouldRunNextPhase(parsedArgs, currentPhase) && fromChunks != null && msgIdChunks != null) {                                        Path vecPath = new Path(output, "recInput");        if (overwrite) {            HadoopUtil.delete(conf, vecPath);        }                conf.set(EmailUtility.MSG_ID_DIMENSION, String.valueOf(msgDim[0]));        conf.set(EmailUtility.FROM_PREFIX, "fromIds-dictionary-");        conf.set(EmailUtility.MSG_IDS_PREFIX, "msgIds-dictionary-");        conf.set(EmailUtility.FROM_INDEX, getOption("from"));        conf.set(EmailUtility.REFS_INDEX, getOption("refs"));        conf.set(EmailUtility.SEPARATOR, separator);        conf.set(MailToRecReducer.USE_COUNTS_PREFERENCE, String.valueOf(useCounts));        int j = 0;        int i = 0;        for (Path fromChunk : fromChunks) {            for (Path idChunk : msgIdChunks) {                Path out = new Path(vecPath, "tmp-" + i + '-' + j);                DistributedCache.setCacheFiles(new URI[] { fromChunk.toUri(), idChunk.toUri() }, conf);                Job createRecMatrix = prepareJob(input, out, SequenceFileInputFormat.class, MailToRecMapper.class, Text.class, LongWritable.class, MailToRecReducer.class, Text.class, NullWritable.class, TextOutputFormat.class);                createRecMatrix.getConfiguration().set("mapred.output.compress", "false");                boolean succeeded = createRecMatrix.waitForCompletion(true);                if (!succeeded) {                    return -1;                }                                                                FileStatus[] fs = HadoopUtil.getFileStatus(new Path(out, "*"), PathType.GLOB, PathFilters.partFilter(), null, conf);                for (int k = 0; k < fs.length; k++) {                    FileStatus f = fs[k];                    Path outPath = new Path(vecPath, "chunk-" + i + '-' + j + '-' + k);                    FileUtil.copy(f.getPath().getFileSystem(conf), f.getPath(), outPath.getFileSystem(conf), outPath, true, overwrite, conf);                }                HadoopUtil.delete(conf, out);                j++;            }            i++;        }        /*Path mergePath = new Path(output, "vectors.dat");      if (overwrite) {        HadoopUtil.delete(conf, mergePath);      }      */            }    return 0;}
private static List<Path> mahout_f5382_0(Path inputPath, Path dictionaryPathBase, String name, Configuration baseConf, int chunkSizeInMegabytes, int[] maxTermDimension) throws IOException
{    List<Path> chunkPaths = new ArrayList<>();    Configuration conf = new Configuration(baseConf);    FileSystem fs = FileSystem.get(inputPath.toUri(), conf);    long chunkSizeLimit = chunkSizeInMegabytes * 1024L * 1024L;    int chunkIndex = 0;    Path chunkPath = new Path(dictionaryPathBase, name + chunkIndex);    chunkPaths.add(chunkPath);    SequenceFile.Writer dictWriter = new SequenceFile.Writer(fs, conf, chunkPath, Text.class, IntWritable.class);    try {        long currentChunkSize = 0;        Path filesPattern = new Path(inputPath, OUTPUT_FILES_PATTERN);                int i = 1;        for (Pair<Writable, Writable> record : new SequenceFileDirIterable<>(filesPattern, PathType.GLOB, null, null, true, conf)) {            if (currentChunkSize > chunkSizeLimit) {                Closeables.close(dictWriter, false);                chunkIndex++;                chunkPath = new Path(dictionaryPathBase, name + chunkIndex);                chunkPaths.add(chunkPath);                dictWriter = new SequenceFile.Writer(fs, conf, chunkPath, Text.class, IntWritable.class);                currentChunkSize = 0;            }            Writable key = record.getFirst();            int fieldSize = DICTIONARY_BYTE_OVERHEAD + key.toString().length() * 2 + Integer.SIZE / 8;            currentChunkSize += fieldSize;            dictWriter.append(key, new IntWritable(i++));        }        maxTermDimension[0] = i;    } finally {        Closeables.close(dictWriter, false);    }    return chunkPaths;}
protected void mahout_f5383_1(Context context) throws IOException, InterruptedException
{    super.setup(context);    Configuration conf = context.getConfiguration();    String fromPrefix = conf.get(EmailUtility.FROM_PREFIX);    String msgPrefix = conf.get(EmailUtility.MSG_IDS_PREFIX);    fromIdx = conf.getInt(EmailUtility.FROM_INDEX, 0);    refsIdx = conf.getInt(EmailUtility.REFS_INDEX, 1);    EmailUtility.loadDictionaries(conf, fromPrefix, fromDictionary, msgPrefix, msgIdDictionary);        separator = context.getConfiguration().get(EmailUtility.SEPARATOR);}
protected void mahout_f5384_0(Text key, Text value, Context context) throws IOException, InterruptedException
{    int msgIdKey = Integer.MIN_VALUE;    int fromKey = Integer.MIN_VALUE;    String valStr = value.toString();    String[] splits = StringUtils.splitByWholeSeparatorPreserveAllTokens(valStr, separator);    if (splits != null && splits.length > 0) {        if (splits.length > refsIdx) {            String from = EmailUtility.cleanUpEmailAddress(splits[fromIdx]);            fromKey = fromDictionary.get(from);        }                if (splits.length > refsIdx) {            String[] theRefs = EmailUtility.parseReferences(splits[refsIdx]);            if (theRefs != null && theRefs.length > 0) {                                msgIdKey = msgIdDictionary.get(theRefs[0]);                context.getCounter(Counters.REFERENCE).increment(1);            }        }    }        if (msgIdKey == Integer.MIN_VALUE) {                String keyStr = key.toString();        int idx = keyStr.lastIndexOf('/');        if (idx != -1) {            String msgId = keyStr.substring(idx + 1);            msgIdKey = msgIdDictionary.get(msgId);            context.getCounter(Counters.ORIGINAL).increment(1);        }    }    if (msgIdKey != Integer.MIN_VALUE && fromKey != Integer.MIN_VALUE) {        context.write(new Text(fromKey + "," + msgIdKey), new LongWritable(1));    }}
protected void mahout_f5385_0(Context context) throws IOException, InterruptedException
{    useCounts = context.getConfiguration().getBoolean(USE_COUNTS_PREFERENCE, true);}
protected void mahout_f5386_0(Text key, Iterable<LongWritable> values, Context context) throws IOException, InterruptedException
{    if (useCounts) {        long sum = 0;        for (LongWritable value : values) {            sum++;        }        context.write(new Text(key.toString() + ',' + sum), null);    } else {        context.write(new Text(key.toString()), null);    }}
protected void mahout_f5387_0(Text key, Text value, Context context) throws IOException, InterruptedException
{        String keyStr = key.toString();        int idx = keyStr.lastIndexOf('@');    if (idx == -1) {        context.getCounter(EmailUtility.Counters.NO_MESSAGE_ID).increment(1);    } else {                idx = keyStr.lastIndexOf('/', idx);        String msgId = keyStr.substring(idx + 1);        if (EmailUtility.WHITESPACE.matcher(msgId).matches()) {            context.getCounter(EmailUtility.Counters.NO_MESSAGE_ID).increment(1);        } else {            context.write(new Text(msgId), new VarIntWritable(1));        }    }}
public Iterator<Pair<PreferenceArray, long[]>> mahout_f5388_0()
{    try {        return new DataFileIterator(dataFile);    } catch (IOException ioe) {        throw new IllegalStateException(ioe);    }}
protected Pair<PreferenceArray, long[]> mahout_f5389_0()
{    if (!lineIterator.hasNext()) {        return endOfData();    }    String line = lineIterator.next();        String[] tokens = PIPE_PATTERN.split(line);    long userID = Long.parseLong(tokens[0]);    int ratingsLeftToRead = Integer.parseInt(tokens[1]);    int ratingsRead = 0;    PreferenceArray currentUserPrefs = new GenericUserPreferenceArray(ratingsLeftToRead);    long[] timestamps = new long[ratingsLeftToRead];    while (ratingsLeftToRead > 0) {        line = lineIterator.next();                                tokens = TAB_PATTERN.split(line);        boolean hasPref = tokens.length == 2 || tokens.length == 4;        boolean hasDate = tokens.length > 2;        long itemID = Long.parseLong(tokens[0]);        currentUserPrefs.setUserID(0, userID);        currentUserPrefs.setItemID(ratingsRead, itemID);        if (hasPref) {            float preference = Float.parseFloat(tokens[1]);            currentUserPrefs.setValue(ratingsRead, preference);        }        if (hasDate) {            long timestamp;            if (hasPref) {                timestamp = parseFakeTimestamp(tokens[2], tokens[3]);            } else {                timestamp = parseFakeTimestamp(tokens[1], tokens[2]);            }            timestamps[ratingsRead] = timestamp;        }        ratingsRead++;        ratingsLeftToRead--;    }    return new Pair<>(currentUserPrefs, timestamps);}
public void mahout_f5390_0(int n)
{    for (int i = 0; i < n; i++) {        if (lineIterator.hasNext()) {            String line = lineIterator.next();                        String[] tokens = PIPE_PATTERN.split(line);            int linesToSKip = Integer.parseInt(tokens[1]);            lineIterator.skip(linesToSKip);        } else {            break;        }    }}
public void mahout_f5391_1()
{    endOfData();    try {        Closeables.close(lineIterator, true);    } catch (IOException e) {            }}
private static long mahout_f5392_0(String dateString, CharSequence timeString)
{    int days = Integer.parseInt(dateString);    String[] timeTokens = COLON_PATTERN.split(timeString);    int hours = Integer.parseInt(timeTokens[0]);    int minutes = Integer.parseInt(timeTokens[1]);    int seconds = Integer.parseInt(timeTokens[2]);    return 86400L * days + 3600L + hours + 60L * minutes + seconds;}
public File mahout_f5393_0()
{    return dataFileDirectory;}
public static File mahout_f5394_0(File dataFileDirectory)
{    return getFile(dataFileDirectory, "trainIdx");}
public static File mahout_f5395_0(File dataFileDirectory)
{    return getFile(dataFileDirectory, "validationIdx");}
public static File mahout_f5396_0(File dataFileDirectory)
{    return getFile(dataFileDirectory, "testIdx");}
public static File mahout_f5397_0(File dataFileDirectory)
{    return getFile(dataFileDirectory, "trackData");}
private static File mahout_f5398_0(File dataFileDirectory, String prefix)
{        for (int set : new int[] { 1, 2 }) {                for (String firstLinesOrNot : new String[] { "", ".firstLines" }) {            for (String gzippedOrNot : new String[] { ".gz", "" }) {                File dataFile = new File(dataFileDirectory, prefix + set + firstLinesOrNot + ".txt" + gzippedOrNot);                if (dataFile.exists()) {                    return dataFile;                }            }        }    }    throw new IllegalArgumentException("Can't find " + prefix + " file in " + dataFileDirectory);}
public LongPrimitiveIterator mahout_f5399_0() throws TasteException
{    return delegate.getUserIDs();}
public PreferenceArray mahout_f5400_0(long userID) throws TasteException
{    return delegate.getPreferencesFromUser(userID);}
public FastIDSet mahout_f5401_0(long userID) throws TasteException
{    return delegate.getItemIDsFromUser(userID);}
public LongPrimitiveIterator mahout_f5402_0() throws TasteException
{    return delegate.getItemIDs();}
public PreferenceArray mahout_f5403_0(long itemID) throws TasteException
{    return delegate.getPreferencesForItem(itemID);}
public Float mahout_f5404_0(long userID, long itemID) throws TasteException
{    return delegate.getPreferenceValue(userID, itemID);}
public Long mahout_f5405_0(long userID, long itemID) throws TasteException
{    return delegate.getPreferenceTime(userID, itemID);}
public int mahout_f5406_0() throws TasteException
{    return delegate.getNumItems();}
public int mahout_f5407_0() throws TasteException
{    return delegate.getNumUsers();}
public int mahout_f5408_0(long itemID) throws TasteException
{    return delegate.getNumUsersWithPreferenceFor(itemID);}
public int mahout_f5409_0(long itemID1, long itemID2) throws TasteException
{    return delegate.getNumUsersWithPreferenceFor(itemID1, itemID2);}
public void mahout_f5410_0(long userID, long itemID, float value) throws TasteException
{    delegate.setPreference(userID, itemID, value);}
public void mahout_f5411_0(long userID, long itemID) throws TasteException
{    delegate.removePreference(userID, itemID);}
public boolean mahout_f5412_0()
{    return delegate.hasPreferenceValues();}
public float mahout_f5413_0()
{    return 100.0f;}
public float mahout_f5414_0()
{    return 0.0f;}
public void mahout_f5415_0(Collection<Refreshable> alreadyRefreshed)
{}
public static void mahout_f5416_0(String[] args) throws Exception
{    File inputFile = new File(args[0]);    File outputFile = new File(args[1]);    int columnsToOutput = 4;    if (args.length >= 3) {        columnsToOutput = Integer.parseInt(args[2]);    }    OutputStream outStream = new GZIPOutputStream(new FileOutputStream(outputFile));    try (Writer outWriter = new BufferedWriter(new OutputStreamWriter(outStream, Charsets.UTF_8))) {        for (Pair<PreferenceArray, long[]> user : new DataFileIterable(inputFile)) {            PreferenceArray prefs = user.getFirst();            long[] timestamps = user.getSecond();            for (int i = 0; i < prefs.length(); i++) {                outWriter.write(String.valueOf(prefs.getUserID(i)));                outWriter.write(',');                outWriter.write(String.valueOf(prefs.getItemID(i)));                if (columnsToOutput > 2) {                    outWriter.write(',');                    outWriter.write(String.valueOf(prefs.getValue(i)));                }                if (columnsToOutput > 3) {                    outWriter.write(',');                    outWriter.write(String.valueOf(timestamps[i]));                }                outWriter.write('\n');            }        }    }}
public static byte mahout_f5417_1(double estimate, long userID, long itemID)
{    if (Double.isNaN(estimate)) {                return 0x7F;    } else {        int scaledEstimate = (int) (estimate * 2.55);        if (scaledEstimate > 255) {            scaledEstimate = 255;        } else if (scaledEstimate < 0) {            scaledEstimate = 0;        }        return (byte) scaledEstimate;    }}
public LongPrimitiveIterator mahout_f5418_0()
{    return userIDs.iterator();}
public LongPrimitiveIterator mahout_f5419_0()
{    return itemIDs.iterator();}
public Iterable<Preference> mahout_f5420_0()
{    return preferences;}
public float mahout_f5421_0()
{    return minPreference;}
public float mahout_f5422_0()
{    return maxPreference;}
public int mahout_f5423_0()
{    return userIDs.size();}
public int mahout_f5424_0()
{    return itemIDs.size();}
public int mahout_f5425_0()
{    return preferences.size();}
public LongPrimitiveIterator mahout_f5426_0()
{    return new FixedSizeLongIterator(numUsers());}
public LongPrimitiveIterator mahout_f5427_0()
{    return new FixedSizeLongIterator(numItems());}
public Iterable<Preference> mahout_f5428_0()
{    Iterable<Iterable<Preference>> prefIterators = Iterables.transform(new DataFileIterable(dataFile), new Function<Pair<PreferenceArray, long[]>, Iterable<Preference>>() {        @Override        public Iterable<Preference> apply(Pair<PreferenceArray, long[]> from) {            return from.getFirst();        }    });    return Iterables.concat(prefIterators);}
public Iterable<Preference> mahout_f5429_0(Pair<PreferenceArray, long[]> from)
{    return from.getFirst();}
public float mahout_f5430_0()
{    return 0;}
public float mahout_f5431_0()
{    return 100;}
public int mahout_f5432_0()
{    return 1000990;}
public int mahout_f5433_0()
{    return 624961;}
public int mahout_f5434_0()
{    return 252800275;}
public long mahout_f5435_0()
{    return currentValue++;}
public long mahout_f5436_0()
{    return currentValue;}
public void mahout_f5437_0(int n)
{    currentValue += n;}
public boolean mahout_f5438_0()
{    return currentValue < maximum;}
public void mahout_f5439_0()
{    throw new UnsupportedOperationException();}
public Factorization mahout_f5440_1() throws TasteException
{    for (int feature = 0; feature < numFeatures; feature++) {                shufflePreferences();                for (int currentIteration = 0; currentIteration < numIterations; currentIteration++) {            if (currentIteration == numIterations - 1) {                double rmse = trainingIterationWithRmse(feature);                            } else {                trainingIteration(feature);            }        }        if (feature < numFeatures - 1) {                        for (int index = 0; index < userIndexes.length; index++) {                cachedEstimates[index] = estimate(userIndexes[index], itemIndexes[index], feature, cachedEstimates[index], false);            }        }    }        return new Factorization(userIDMapping, itemIDMapping, userFeatures, itemFeatures);}
private void mahout_f5441_0(int feature)
{    for (int index = 0; index < userIndexes.length; index++) {        train(userIndexes[index], itemIndexes[index], feature, values[index], cachedEstimates[index]);    }}
private double mahout_f5442_0(int feature)
{    double rmse = 0.0;    for (int index = 0; index < userIndexes.length; index++) {        double error = train(userIndexes[index], itemIndexes[index], feature, values[index], cachedEstimates[index]);        rmse += error * error;    }    return Math.sqrt(rmse / userIndexes.length);}
private double mahout_f5443_0(int userIndex, int itemIndex, int feature, double cachedEstimate, boolean trailing)
{    double sum = cachedEstimate;    sum += userFeatures[userIndex][feature] * itemFeatures[itemIndex][feature];    if (trailing) {        sum += (numFeatures - feature - 1) * (defaultValue + interval) * (defaultValue + interval);        if (sum > maxPreference) {            sum = maxPreference;        } else if (sum < minPreference) {            sum = minPreference;        }    }    return sum;}
public double mahout_f5444_0(int userIndex, int itemIndex, int feature, double original, double cachedEstimate)
{    double error = original - estimate(userIndex, itemIndex, feature, cachedEstimate, true);    double[] userVector = userFeatures[userIndex];    double[] itemVector = itemFeatures[itemIndex];    userVector[feature] += learningRate * (error * itemVector[feature] - preventOverfitting * userVector[feature]);    itemVector[feature] += learningRate * (error * userVector[feature] - preventOverfitting * itemVector[feature]);    return error;}
protected void mahout_f5445_0()
{    /* Durstenfeld shuffle */    for (int currentPos = userIndexes.length - 1; currentPos > 0; currentPos--) {        int swapPos = random.nextInt(currentPos + 1);        swapPreferences(currentPos, swapPos);    }}
private void mahout_f5446_0(int posA, int posB)
{    int tmpUserIndex = userIndexes[posA];    int tmpItemIndex = itemIndexes[posA];    float tmpValue = values[posA];    double tmpEstimate = cachedEstimates[posA];    userIndexes[posA] = userIndexes[posB];    itemIndexes[posA] = itemIndexes[posB];    values[posA] = values[posB];    cachedEstimates[posA] = cachedEstimates[posB];    userIndexes[posB] = tmpUserIndex;    itemIndexes[posB] = tmpItemIndex;    values[posB] = tmpValue;    cachedEstimates[posB] = tmpEstimate;}
public void mahout_f5447_0(Collection<Refreshable> alreadyRefreshed)
{}
public static void mahout_f5448_1(String[] args) throws Exception
{    if (args.length != 2) {        System.err.println("Necessary arguments: <kddDataFileDirectory> <resultFile>");        return;    }    File dataFileDirectory = new File(args[0]);    if (!dataFileDirectory.exists() || !dataFileDirectory.isDirectory()) {        throw new IllegalArgumentException("Bad data file directory: " + dataFileDirectory);    }    File resultFile = new File(args[1]);    /* the knobs to turn */    int numFeatures = 20;    int numIterations = 5;    double learningRate = 0.0001;    double preventOverfitting = 0.002;    double randomNoise = 0.0001;    KDDCupFactorizablePreferences factorizablePreferences = new KDDCupFactorizablePreferences(KDDCupDataModel.getTrainingFile(dataFileDirectory));    Factorizer sgdFactorizer = new ParallelArraysSGDFactorizer(factorizablePreferences, numFeatures, numIterations, learningRate, preventOverfitting, randomNoise);    Factorization factorization = sgdFactorizer.factorize();        int prefsProcessed = 0;    RunningAverage average = new FullRunningAverage();    for (Pair<PreferenceArray, long[]> validationPair : new DataFileIterable(KDDCupDataModel.getValidationFile(dataFileDirectory))) {        for (Preference validationPref : validationPair.getFirst()) {            double estimate = estimatePreference(factorization, validationPref.getUserID(), validationPref.getItemID(), factorizablePreferences.getMinPreference(), factorizablePreferences.getMaxPreference());            double error = validationPref.getValue() - estimate;            average.addDatum(error * error);            prefsProcessed++;            if (prefsProcessed % 100000 == 0) {                            }        }    }        double rmse = Math.sqrt(average.getAverage());            OutputStream out = null;    try {        out = new BufferedOutputStream(new FileOutputStream(resultFile));        for (Pair<PreferenceArray, long[]> testPair : new DataFileIterable(KDDCupDataModel.getTestFile(dataFileDirectory))) {            for (Preference testPref : testPair.getFirst()) {                double estimate = estimatePreference(factorization, testPref.getUserID(), testPref.getItemID(), factorizablePreferences.getMinPreference(), factorizablePreferences.getMaxPreference());                byte result = EstimateConverter.convert(estimate, testPref.getUserID(), testPref.getItemID());                out.write(result);            }        }    } finally {        Closeables.close(out, false);    }    }
 static double mahout_f5449_0(Factorization factorization, long userID, long itemID, float minPreference, float maxPreference) throws NoSuchUserException, NoSuchItemException
{    double[] userFeatures = factorization.getUserFeatures(userID);    double[] itemFeatures = factorization.getItemFeatures(itemID);    double estimate = 0;    for (int feature = 0; feature < userFeatures.length; feature++) {        estimate += userFeatures[feature] * itemFeatures[feature];    }    if (estimate < minPreference) {        estimate = minPreference;    } else if (estimate > maxPreference) {        estimate = maxPreference;    }    return estimate;}
public List<RecommendedItem> mahout_f5451_0(long userID, int howMany) throws TasteException
{    return recommender.recommend(userID, howMany);}
public List<RecommendedItem> mahout_f5452_0(long userID, int howMany, boolean includeKnownItems) throws TasteException
{    return recommend(userID, howMany, null, includeKnownItems);}
public List<RecommendedItem> mahout_f5453_0(long userID, int howMany, IDRescorer rescorer) throws TasteException
{    return recommender.recommend(userID, howMany, rescorer, false);}
public List<RecommendedItem> mahout_f5454_0(long userID, int howMany, IDRescorer rescorer, boolean includeKnownItems) throws TasteException
{    return recommender.recommend(userID, howMany, rescorer, includeKnownItems);}
public float mahout_f5455_0(long userID, long itemID) throws TasteException
{    return recommender.estimatePreference(userID, itemID);}
public void mahout_f5456_0(long userID, long itemID, float value) throws TasteException
{    recommender.setPreference(userID, itemID, value);}
public void mahout_f5457_0(long userID, long itemID) throws TasteException
{    recommender.removePreference(userID, itemID);}
public DataModel mahout_f5458_0()
{    return recommender.getDataModel();}
public void mahout_f5459_0(Collection<Refreshable> alreadyRefreshed)
{    recommender.refresh(alreadyRefreshed);}
public String mahout_f5460_0()
{    return "Track1Recommender[recommender:" + recommender + ']';}
public Recommender mahout_f5461_0(DataModel dataModel) throws TasteException
{    return new Track1Recommender(dataModel);}
public double mahout_f5462_1(RecommenderBuilder recommenderBuilder, DataModelBuilder dataModelBuilder, DataModel dataModel, double trainingPercentage, double evaluationPercentage) throws TasteException
{    Recommender recommender = recommenderBuilder.buildRecommender(dataModel);    Collection<Callable<Void>> estimateCallables = Lists.newArrayList();    AtomicInteger noEstimateCounter = new AtomicInteger();    for (Pair<PreferenceArray, long[]> userData : new DataFileIterable(KDDCupDataModel.getValidationFile(dataFileDirectory))) {        PreferenceArray validationPrefs = userData.getFirst();        long userID = validationPrefs.get(0).getUserID();        estimateCallables.add(new PreferenceEstimateCallable(recommender, userID, validationPrefs, noEstimateCounter));    }    RunningAverageAndStdDev timing = new FullRunningAverageAndStdDev();    execute(estimateCallables, noEstimateCounter, timing);    double result = computeFinalEvaluation();        return result;}
protected void mahout_f5463_0()
{    average = new FullRunningAverage();}
protected void mahout_f5464_0(float estimatedPreference, Preference realPref)
{    double diff = realPref.getValue() - estimatedPreference;    average.addDatum(diff * diff);}
protected double mahout_f5465_0()
{    return Math.sqrt(average.getAverage());}
public static void mahout_f5466_1(String... args) throws IOException, TasteException, OptionException
{    File dataFileDirectory = TasteOptionParser.getRatings(args);    if (dataFileDirectory == null) {        throw new IllegalArgumentException("No data directory");    }    if (!dataFileDirectory.exists() || !dataFileDirectory.isDirectory()) {        throw new IllegalArgumentException("Bad data file directory: " + dataFileDirectory);    }    Track1RecommenderEvaluator evaluator = new Track1RecommenderEvaluator(dataFileDirectory);    DataModel model = new KDDCupDataModel(KDDCupDataModel.getTrainingFile(dataFileDirectory));    double evaluation = evaluator.evaluate(new Track1RecommenderBuilder(), null, model, Float.NaN, Float.NaN);    }
public static void mahout_f5467_1(String[] args) throws Exception
{    File dataFileDirectory = new File(args[0]);    if (!dataFileDirectory.exists() || !dataFileDirectory.isDirectory()) {        throw new IllegalArgumentException("Bad data file directory: " + dataFileDirectory);    }    long start = System.currentTimeMillis();    KDDCupDataModel model = new KDDCupDataModel(KDDCupDataModel.getTrainingFile(dataFileDirectory));    Track1Recommender recommender = new Track1Recommender(model);    long end = System.currentTimeMillis();        start = end;    Collection<Track1Callable> callables = new ArrayList<>();    for (Pair<PreferenceArray, long[]> tests : new DataFileIterable(KDDCupDataModel.getTestFile(dataFileDirectory))) {        PreferenceArray userTest = tests.getFirst();        callables.add(new Track1Callable(recommender, userTest));    }    int cores = Runtime.getRuntime().availableProcessors();        ExecutorService executor = Executors.newFixedThreadPool(cores);    List<Future<byte[]>> results = executor.invokeAll(callables);    executor.shutdown();    end = System.currentTimeMillis();        start = end;    try (OutputStream out = new BufferedOutputStream(new FileOutputStream(new File(args[1])))) {        for (Future<byte[]> result : results) {            for (byte estimate : result.get()) {                out.write(estimate);            }        }    }    end = System.currentTimeMillis();    }
public double mahout_f5468_0(long itemID1, long itemID2) throws TasteException
{    return contentSimilarity.itemSimilarity(itemID1, itemID2) * cfSimilarity.itemSimilarity(itemID1, itemID2);}
public double[] mahout_f5469_0(long itemID1, long[] itemID2s) throws TasteException
{    double[] result = contentSimilarity.itemSimilarities(itemID1, itemID2s);    double[] multipliers = cfSimilarity.itemSimilarities(itemID1, itemID2s);    for (int i = 0; i < result.length; i++) {        result[i] *= multipliers[i];    }    return result;}
public void mahout_f5470_0(Collection<Refreshable> alreadyRefreshed)
{    cfSimilarity.refresh(alreadyRefreshed);}
public List<RecommendedItem> mahout_f5472_0(long userID, int howMany) throws TasteException
{    return recommender.recommend(userID, howMany);}
public List<RecommendedItem> mahout_f5473_0(long userID, int howMany, boolean includeKnownItems) throws TasteException
{    return recommend(userID, howMany, null, includeKnownItems);}
public List<RecommendedItem> mahout_f5474_0(long userID, int howMany, IDRescorer rescorer) throws TasteException
{    return recommender.recommend(userID, howMany, rescorer, false);}
public List<RecommendedItem> mahout_f5475_0(long userID, int howMany, IDRescorer rescorer, boolean includeKnownItems) throws TasteException
{    return recommender.recommend(userID, howMany, rescorer, includeKnownItems);}
public float mahout_f5476_0(long userID, long itemID) throws TasteException
{    return recommender.estimatePreference(userID, itemID);}
public void mahout_f5477_0(long userID, long itemID, float value) throws TasteException
{    recommender.setPreference(userID, itemID, value);}
public void mahout_f5478_0(long userID, long itemID) throws TasteException
{    recommender.removePreference(userID, itemID);}
public DataModel mahout_f5479_0()
{    return recommender.getDataModel();}
public void mahout_f5480_0(Collection<Refreshable> alreadyRefreshed)
{    recommender.refresh(alreadyRefreshed);}
public String mahout_f5481_0()
{    return "Track1Recommender[recommender:" + recommender + ']';}
public Recommender mahout_f5482_0(DataModel dataModel) throws TasteException
{    return new Track2Recommender(dataModel, ((KDDCupDataModel) dataModel).getDataFileDirectory());}
public static void mahout_f5483_1(String[] args) throws Exception
{    File dataFileDirectory = new File(args[0]);    if (!dataFileDirectory.exists() || !dataFileDirectory.isDirectory()) {        throw new IllegalArgumentException("Bad data file directory: " + dataFileDirectory);    }    long start = System.currentTimeMillis();    KDDCupDataModel model = new KDDCupDataModel(KDDCupDataModel.getTrainingFile(dataFileDirectory));    Track2Recommender recommender = new Track2Recommender(model, dataFileDirectory);    long end = System.currentTimeMillis();        start = end;    Collection<Track2Callable> callables = new ArrayList<>();    for (Pair<PreferenceArray, long[]> tests : new DataFileIterable(KDDCupDataModel.getTestFile(dataFileDirectory))) {        PreferenceArray userTest = tests.getFirst();        callables.add(new Track2Callable(recommender, userTest));    }    int cores = Runtime.getRuntime().availableProcessors();        ExecutorService executor = Executors.newFixedThreadPool(cores);    List<Future<UserResult>> futures = executor.invokeAll(callables);    executor.shutdown();    end = System.currentTimeMillis();        start = end;    try (OutputStream out = new BufferedOutputStream(new FileOutputStream(new File(args[1])))) {        long lastUserID = Long.MIN_VALUE;        for (Future<UserResult> future : futures) {            UserResult result = future.get();            long userID = result.getUserID();            if (userID <= lastUserID) {                throw new IllegalStateException();            }            lastUserID = userID;            out.write(result.getResultBytes());        }    }    end = System.currentTimeMillis();    }
private static long mahout_f5484_0(String value)
{    return NO_VALUE.equals(value) ? NO_VALUE_ID : Long.parseLong(value);}
public long mahout_f5485_0()
{    return trackID;}
public long mahout_f5486_0()
{    return albumID;}
public long mahout_f5487_0()
{    return artistID;}
public FastIDSet mahout_f5488_0()
{    return genreIDs;}
public double mahout_f5489_0(long itemID1, long itemID2)
{    if (itemID1 == itemID2) {        return 1.0;    }    TrackData data1 = trackData.get(itemID1);    TrackData data2 = trackData.get(itemID2);    if (data1 == null || data2 == null) {        return 0.0;    }        if (data1.getAlbumID() != TrackData.NO_VALUE_ID && data1.getAlbumID() == data2.getAlbumID()) {        return 0.9;    }        if (data1.getArtistID() != TrackData.NO_VALUE_ID && data1.getArtistID() == data2.getArtistID()) {        return 0.7;    }        FastIDSet genres1 = data1.getGenreIDs();    FastIDSet genres2 = data2.getGenreIDs();    if (genres1 == null || genres2 == null) {        return 0.0;    }    int intersectionSize = genres1.intersectionSize(genres2);    if (intersectionSize == 0) {        return 0.0;    }    int unionSize = genres1.size() + genres2.size() - intersectionSize;    return intersectionSize / (4.0 * unionSize);}
public double[] mahout_f5490_0(long itemID1, long[] itemID2s)
{    int length = itemID2s.length;    double[] result = new double[length];    for (int i = 0; i < length; i++) {        result[i] = itemSimilarity(itemID1, itemID2s[i]);    }    return result;}
public long[] mahout_f5491_0(long itemID)
{    FastIDSet allSimilarItemIDs = new FastIDSet();    LongPrimitiveIterator allItemIDs = trackData.keySetIterator();    while (allItemIDs.hasNext()) {        long possiblySimilarItemID = allItemIDs.nextLong();        if (!Double.isNaN(itemSimilarity(itemID, possiblySimilarItemID))) {            allSimilarItemIDs.add(possiblySimilarItemID);        }    }    return allSimilarItemIDs.toArray();}
public void mahout_f5492_0(Collection<Refreshable> alreadyRefreshed)
{}
public long mahout_f5493_0()
{    return userID;}
public byte[] mahout_f5494_0()
{    return resultBytes;}
public static File mahout_f5495_0(String[] args) throws OptionException
{    DefaultOptionBuilder obuilder = new DefaultOptionBuilder();    ArgumentBuilder abuilder = new ArgumentBuilder();    GroupBuilder gbuilder = new GroupBuilder();    Option inputOpt = obuilder.withLongName("input").withRequired(false).withShortName("i").withArgument(abuilder.withName("input").withMinimum(1).withMaximum(1).create()).withDescription("The Path for input data directory.").create();    Option helpOpt = DefaultOptionCreator.helpOption();    Group group = gbuilder.withName("Options").withOption(inputOpt).withOption(helpOpt).create();    Parser parser = new Parser();    parser.setGroup(group);    CommandLine cmdLine = parser.parse(args);    if (cmdLine.hasOption(helpOpt)) {        CommandLineUtil.printHelp(group);        return null;    }    return cmdLine.hasOption(inputOpt) ? new File(cmdLine.getValue(inputOpt).toString()) : null;}
public static void mahout_f5496_1(String[] args) throws IOException
{    if (args.length != 4) {        System.err.println("Usage: NetflixDatasetConverter /path/to/training_set/ /path/to/qualifying.txt " + "/path/to/judging.txt /path/to/destination");        return;    }    String trainingDataDir = args[0];    String qualifyingTxt = args[1];    String judgingTxt = args[2];    Path outputPath = new Path(args[3]);    Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(outputPath.toUri(), conf);    Preconditions.checkArgument(trainingDataDir != null, "Training Data location needs to be specified");        try (BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(fs.create(new Path(outputPath, "trainingSet/ratings.tsv")), Charsets.UTF_8))) {        int ratingsProcessed = 0;        for (File movieRatings : new File(trainingDataDir).listFiles()) {            try (FileLineIterator lines = new FileLineIterator(movieRatings)) {                boolean firstLineRead = false;                String movieID = null;                while (lines.hasNext()) {                    String line = lines.next();                    if (firstLineRead) {                        String[] tokens = SEPARATOR.split(line);                        String userID = tokens[0];                        String rating = tokens[1];                        writer.write(userID + TAB + movieID + TAB + rating + NEWLINE);                        ratingsProcessed++;                        if (ratingsProcessed % 1000000 == 0) {                                                    }                    } else {                        movieID = line.replaceAll(MOVIE_DENOTER, "");                        firstLineRead = true;                    }                }            }        }            }        List<Preference> probes = new ArrayList<>(2817131);    long currentMovieID = -1;    for (String line : new FileLineIterable(new File(qualifyingTxt))) {        if (line.contains(MOVIE_DENOTER)) {            currentMovieID = Long.parseLong(line.replaceAll(MOVIE_DENOTER, ""));        } else {            long userID = Long.parseLong(SEPARATOR.split(line)[0]);            probes.add(new GenericPreference(userID, currentMovieID, 0));        }    }            try (BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(fs.create(new Path(outputPath, "probeSet/ratings.tsv")), Charsets.UTF_8))) {        int ratingsProcessed = 0;        for (String line : new FileLineIterable(new File(judgingTxt))) {            if (line.contains(MOVIE_DENOTER)) {                currentMovieID = Long.parseLong(line.replaceAll(MOVIE_DENOTER, ""));            } else {                float rating = Float.parseFloat(SEPARATOR.split(line)[0]);                Preference pref = probes.get(ratingsProcessed);                Preconditions.checkState(pref.getItemID() == currentMovieID);                ratingsProcessed++;                writer.write(pref.getUserID() + TAB + pref.getItemID() + TAB + rating + NEWLINE);                if (ratingsProcessed % 1000000 == 0) {                                    }            }        }            }}
public static void mahout_f5497_0(String[] args) throws Exception
{    if (args.length != 1) {        System.err.println("Need path to ratings.dat of the movielens1M dataset as argument!");        System.exit(-1);    }    File resultFile = new File(System.getProperty("java.io.tmpdir"), "similarities.csv");    if (resultFile.exists()) {        resultFile.delete();    }    DataModel dataModel = new GroupLensDataModel(new File(args[0]));    ItemBasedRecommender recommender = new GenericItemBasedRecommender(dataModel, new LogLikelihoodSimilarity(dataModel));    BatchItemSimilarities batch = new MultithreadedBatchItemSimilarities(recommender, 5);    int numSimilarities = batch.computeItemSimilarities(Runtime.getRuntime().availableProcessors(), 1, new FileSimilarItemsWriter(resultFile));    System.out.println("Computed " + numSimilarities + " similarities for " + dataModel.getNumItems() + " items " + "and saved them to " + resultFile.getAbsolutePath());}
private static File mahout_f5498_0(File originalFile) throws IOException
{        File resultFile = new File(new File(System.getProperty("java.io.tmpdir")), "ratings.txt");    if (resultFile.exists()) {        resultFile.delete();    }    try (Writer writer = new OutputStreamWriter(new FileOutputStream(resultFile), Charsets.UTF_8)) {        for (String line : new FileLineIterable(originalFile, false)) {            int lastDelimiterStart = line.lastIndexOf(COLON_DELIMTER);            if (lastDelimiterStart < 0) {                throw new IOException("Unexpected input format on line: " + line);            }            String subLine = line.substring(0, lastDelimiterStart);            String convertedLine = COLON_DELIMITER_PATTERN.matcher(subLine).replaceAll(",");            writer.write(convertedLine);            writer.write('\n');        }    } catch (IOException ioe) {        resultFile.delete();        throw ioe;    }    return resultFile;}
public static File mahout_f5499_0(String resourceName) throws IOException
{    InputSupplier<? extends InputStream> inSupplier;    try {        URL resourceURL = Resources.getResource(GroupLensDataModel.class, resourceName);        inSupplier = Resources.newInputStreamSupplier(resourceURL);    } catch (IllegalArgumentException iae) {        File resourceFile = new File("src/main/java" + resourceName);        inSupplier = Files.newInputStreamSupplier(resourceFile);    }    File tempFile = File.createTempFile("taste", null);    tempFile.deleteOnExit();    Files.copy(inSupplier, tempFile);    return tempFile;}
public String mahout_f5500_0()
{    return "GroupLensDataModel";}
protected void mahout_f5501_0(Context context) throws IOException, InterruptedException
{    useListName = Boolean.parseBoolean(context.getConfiguration().get(PrepEmailVectorsDriver.USE_LIST_NAME));}
protected void mahout_f5502_0(WritableComparable<?> key, VectorWritable value, Context context) throws IOException, InterruptedException
{    String input = key.toString();        String[] splits = SLASH.split(input);        if (splits.length >= 3) {        StringBuilder bldr = new StringBuilder();        bldr.append(escape(splits[1]));        if (useListName) {            bldr.append('_').append(escape(splits[2]));        }        context.write(new Text(bldr.toString()), value);    }}
private static String mahout_f5503_0(CharSequence value)
{    return DASH_DOT.matcher(value).replaceAll("_").toLowerCase(Locale.ENGLISH);}
protected void mahout_f5504_0(Context context) throws IOException, InterruptedException
{    maxItemsPerLabel = Long.parseLong(context.getConfiguration().get(PrepEmailVectorsDriver.ITEMS_PER_CLASS));}
protected void mahout_f5505_0(Text key, Iterable<VectorWritable> values, Context context) throws IOException, InterruptedException
{        long i = 0;    Iterator<VectorWritable> iterator = values.iterator();    while (i < maxItemsPerLabel && iterator.hasNext()) {        context.write(key, iterator.next());        i++;    }}
public static void mahout_f5506_0(String[] args) throws Exception
{    ToolRunner.run(new Configuration(), new PrepEmailVectorsDriver(), args);}
public int mahout_f5507_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption(DefaultOptionCreator.overwriteOption().create());    addOption("maxItemsPerLabel", "mipl", "The maximum number of items per label.  Can be useful for making the " + "training sets the same size", String.valueOf(100000));    addOption(buildOption("useListName", "ul", "Use the name of the list as part of the label.  If not set, then " + "just use the project name", false, false, "false"));    Map<String, List<String>> parsedArgs = parseArguments(args);    if (parsedArgs == null) {        return -1;    }    Path input = getInputPath();    Path output = getOutputPath();    if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {        HadoopUtil.delete(getConf(), output);    }    Job convertJob = prepareJob(input, output, SequenceFileInputFormat.class, PrepEmailMapper.class, Text.class, VectorWritable.class, PrepEmailReducer.class, Text.class, VectorWritable.class, SequenceFileOutputFormat.class);    convertJob.getConfiguration().set(ITEMS_PER_CLASS, getOption("maxItemsPerLabel"));    convertJob.getConfiguration().set(USE_LIST_NAME, String.valueOf(hasOption("useListName")));    boolean succeeded = convertJob.waitForCompletion(true);    return succeeded ? 0 : -1;}
public FeatureVectorEncoder mahout_f5508_0()
{    return encoder;}
public FeatureVectorEncoder mahout_f5509_0()
{    return bias;}
public Random mahout_f5510_0()
{    return rand;}
public Vector mahout_f5511_0(File file, int actual, int leakType, Multiset<String> overallCounts) throws IOException
{    long date = (long) (1000 * (DATE_REFERENCE + actual * MONTH + 1 * WEEK * rand.nextDouble()));    Multiset<String> words = ConcurrentHashMultiset.create();    try (BufferedReader reader = Files.newReader(file, Charsets.UTF_8)) {        String line = reader.readLine();        Reader dateString = new StringReader(DATE_FORMATS[leakType % 3].format(new Date(date)));        countWords(analyzer, words, dateString, overallCounts);        while (line != null && !line.isEmpty()) {            boolean countHeader = (line.startsWith("From:") || line.startsWith("Subject:") || line.startsWith("Keywords:") || line.startsWith("Summary:")) && leakType < 6;            do {                Reader in = new StringReader(line);                if (countHeader) {                    countWords(analyzer, words, in, overallCounts);                }                line = reader.readLine();            } while (line != null && line.startsWith(" "));        }        if (leakType < 3) {            countWords(analyzer, words, reader, overallCounts);        }    }    Vector v = new RandomAccessSparseVector(FEATURES);    bias.addToVector("", 1, v);    for (String word : words.elementSet()) {        encoder.addToVector(word, Math.log1p(words.count(word)), v);    }    return v;}
public static void mahout_f5512_0(Analyzer analyzer, Collection<String> words, Reader in, Multiset<String> overallCounts) throws IOException
{    TokenStream ts = analyzer.tokenStream("text", in);    ts.addAttribute(CharTermAttribute.class);    ts.reset();    while (ts.incrementToken()) {        String s = ts.getAttribute(CharTermAttribute.class).toString();        words.add(s);    }    overallCounts.addAll(words);    ts.end();    Closeables.close(ts, true);}
private static void mahout_f5513_0(String url, boolean assignIDs) throws IOException
{        hiddenSequences = new LinkedList<>();    observedSequences = new LinkedList<>();    readLines = 0;        List<Integer> observedSequence = new LinkedList<>();    List<Integer> hiddenSequence = new LinkedList<>();    for (String line : Resources.readLines(new URL(url), Charsets.UTF_8)) {        if (line.isEmpty()) {                        int[] observedSequenceArray = new int[observedSequence.size()];            int[] hiddenSequenceArray = new int[hiddenSequence.size()];            for (int i = 0; i < observedSequence.size(); ++i) {                observedSequenceArray[i] = observedSequence.get(i);                hiddenSequenceArray[i] = hiddenSequence.get(i);            }                        hiddenSequences.add(hiddenSequenceArray);            observedSequences.add(observedSequenceArray);                        observedSequence.clear();            hiddenSequence.clear();            continue;        }        readLines++;                String[] tags = SPACE.split(line);                if (assignIDs) {            if (!wordIDs.containsKey(tags[0])) {                wordIDs.put(tags[0], nextWordId++);            }            if (!tagIDs.containsKey(tags[1])) {                tagIDs.put(tags[1], nextTagId++);            }        }                Integer wordID = wordIDs.get(tags[0]);        Integer tagID = tagIDs.get(tags[1]);                if (wordID == null) {            observedSequence.add(0);        } else {            observedSequence.add(wordID);        }        if (tagID == null) {            hiddenSequence.add(0);        } else {            hiddenSequence.add(tagID);        }    }        if (!observedSequence.isEmpty()) {        int[] observedSequenceArray = new int[observedSequence.size()];        int[] hiddenSequenceArray = new int[hiddenSequence.size()];        for (int i = 0; i < observedSequence.size(); ++i) {            observedSequenceArray[i] = observedSequence.get(i);            hiddenSequenceArray[i] = hiddenSequence.get(i);        }                hiddenSequences.add(hiddenSequenceArray);        observedSequences.add(observedSequenceArray);    }}
private static void mahout_f5514_1(String trainingURL) throws IOException
{        tagIDs = new HashMap<>(44);        wordIDs = new HashMap<>(19122);            long start = System.currentTimeMillis();    readFromURL(trainingURL, true);    long end = System.currentTimeMillis();    double duration = (end - start) / 1000.0;            start = System.currentTimeMillis();    taggingModel = HmmTrainer.trainSupervisedSequence(nextTagId, nextWordId, hiddenSequences, observedSequences, 0.05);                Matrix emissions = taggingModel.getEmissionMatrix();    for (int i = 0; i < taggingModel.getNrOfHiddenStates(); ++i) {        emissions.setQuick(i, 0, 0.1 / taggingModel.getNrOfHiddenStates());    }    int nnptag = tagIDs.get("NNP");    emissions.setQuick(nnptag, 0, 1 / (double) taggingModel.getNrOfHiddenStates());        HmmUtils.normalizeModel(taggingModel);        taggingModel.registerHiddenStateNames(tagIDs);    taggingModel.registerOutputStateNames(wordIDs);    end = System.currentTimeMillis();    duration = (end - start) / 1000.0;    }
private static void mahout_f5515_1(String testingURL) throws IOException
{        long start = System.currentTimeMillis();    readFromURL(testingURL, false);    long end = System.currentTimeMillis();    double duration = (end - start) / 1000.0;            start = System.currentTimeMillis();    int errorCount = 0;    int totalCount = 0;    for (int i = 0; i < observedSequences.size(); ++i) {                int[] posEstimate = HmmEvaluator.decode(taggingModel, observedSequences.get(i), false);                int[] posExpected = hiddenSequences.get(i);        for (int j = 0; j < posExpected.length; ++j) {            totalCount++;            if (posEstimate[j] != posExpected[j]) {                errorCount++;            }        }    }    end = System.currentTimeMillis();    duration = (end - start) / 1000.0;        double errorRate = (double) errorCount / totalCount;    }
private static List<String> mahout_f5516_0(String sentence)
{            sentence = sentence.replaceAll("[,.!?:;\"]", " $0 ");    sentence = sentence.replaceAll("''", " '' ");        String[] tokens = SPACES.split(sentence);        int[] observedSequence = HmmUtils.encodeStateSequence(taggingModel, Arrays.asList(tokens), true, 0);        int[] hiddenSequence = HmmEvaluator.decode(taggingModel, observedSequence, false);        return HmmUtils.decodeStateSequence(taggingModel, hiddenSequence, false, null);}
public static void mahout_f5517_1(String[] args) throws IOException
{        trainModel("http://www.jaist.ac.jp/~hieuxuan/flexcrfs/CoNLL2000-NP/train.txt");    testModel("http://www.jaist.ac.jp/~hieuxuan/flexcrfs/CoNLL2000-NP/test.txt");        String test = "McDonalds is a huge company with many employees .";    String[] testWords = SPACE.split(test);    List<String> posTags = tagSentence(test);    for (int i = 0; i < posTags.size(); ++i) {            }}
public AdaptiveLogisticRegression mahout_f5518_0()
{    if (alr == null) {        alr = new AdaptiveLogisticRegression(getMaxTargetCategories(), getNumFeatures(), createPrior(prior, priorOption));        alr.setInterval(interval);        alr.setAveragingWindow(averageWindow);        alr.setThreadCount(threads);        alr.setAucEvaluator(createAUC(auc));    }    return alr;}
public void mahout_f5519_0()
{    if (prior != null) {        String priorUppercase = prior.toUpperCase(Locale.ENGLISH).trim();        if (("TP".equals(priorUppercase) || "EBP".equals(priorUppercase)) && Double.isNaN(priorOption)) {            throw new IllegalArgumentException("You must specify a double value for TPrior and ElasticBandPrior.");        }    }}
private static PriorFunction mahout_f5520_0(String cmd, double priorOption)
{    if (cmd == null) {        return null;    }    if ("L1".equals(cmd.toUpperCase(Locale.ENGLISH).trim())) {        return new L1();    }    if ("L2".equals(cmd.toUpperCase(Locale.ENGLISH).trim())) {        return new L2();    }    if ("UP".equals(cmd.toUpperCase(Locale.ENGLISH).trim())) {        return new UniformPrior();    }    if ("TP".equals(cmd.toUpperCase(Locale.ENGLISH).trim())) {        return new TPrior(priorOption);    }    if ("EBP".equals(cmd.toUpperCase(Locale.ENGLISH).trim())) {        return new ElasticBandPrior(priorOption);    }    return null;}
private static OnlineAuc mahout_f5521_0(String cmd)
{    if (cmd == null) {        return null;    }    if ("GLOBAL".equals(cmd.toUpperCase(Locale.ENGLISH).trim())) {        return new GlobalOnlineAuc();    }    if ("GROUPED".equals(cmd.toUpperCase(Locale.ENGLISH).trim())) {        return new GroupedOnlineAuc();    }    return null;}
public void mahout_f5522_0(OutputStream out) throws IOException
{    if (alr != null) {        alr.close();    }    setTargetCategories(getCsvRecordFactory().getTargetCategories());    write(new DataOutputStream(out));}
public void mahout_f5523_0(DataOutput out) throws IOException
{    out.writeUTF(getTargetVariable());    out.writeInt(getTypeMap().size());    for (Map.Entry<String, String> entry : getTypeMap().entrySet()) {        out.writeUTF(entry.getKey());        out.writeUTF(entry.getValue());    }    out.writeInt(getNumFeatures());    out.writeInt(getMaxTargetCategories());    out.writeInt(getTargetCategories().size());    for (String category : getTargetCategories()) {        out.writeUTF(category);    }    out.writeInt(interval);    out.writeInt(averageWindow);    out.writeInt(threads);    out.writeUTF(prior);    out.writeDouble(priorOption);    out.writeUTF(auc);        alr.write(out);}
public void mahout_f5524_0(DataInput in) throws IOException
{    setTargetVariable(in.readUTF());    int typeMapSize = in.readInt();    Map<String, String> typeMap = new HashMap<>(typeMapSize);    for (int i = 0; i < typeMapSize; i++) {        String key = in.readUTF();        String value = in.readUTF();        typeMap.put(key, value);    }    setTypeMap(typeMap);    setNumFeatures(in.readInt());    setMaxTargetCategories(in.readInt());    int targetCategoriesSize = in.readInt();    List<String> targetCategories = new ArrayList<>(targetCategoriesSize);    for (int i = 0; i < targetCategoriesSize; i++) {        targetCategories.add(in.readUTF());    }    setTargetCategories(targetCategories);    interval = in.readInt();    averageWindow = in.readInt();    threads = in.readInt();    prior = in.readUTF();    priorOption = in.readDouble();    auc = in.readUTF();    alr = new AdaptiveLogisticRegression();    alr.readFields(in);}
private static AdaptiveLogisticModelParameters mahout_f5525_0(InputStream in) throws IOException
{    AdaptiveLogisticModelParameters result = new AdaptiveLogisticModelParameters();    result.readFields(new DataInputStream(in));    return result;}
public static AdaptiveLogisticModelParameters mahout_f5526_0(File in) throws IOException
{    try (InputStream input = new FileInputStream(in)) {        return loadFromStream(input);    }}
public int mahout_f5527_0()
{    return interval;}
public void mahout_f5528_0(int interval)
{    this.interval = interval;}
public int mahout_f5529_0()
{    return averageWindow;}
public void mahout_f5530_0(int averageWindow)
{    this.averageWindow = averageWindow;}
public int mahout_f5531_0()
{    return threads;}
public void mahout_f5532_0(int threads)
{    this.threads = threads;}
public String mahout_f5533_0()
{    return prior;}
public void mahout_f5534_0(String prior)
{    this.prior = prior;}
public String mahout_f5535_0()
{    return auc;}
public void mahout_f5536_0(String auc)
{    this.auc = auc;}
public double mahout_f5537_0()
{    return priorOption;}
public void mahout_f5538_0(double priorOption)
{    this.priorOption = priorOption;}
public static void mahout_f5539_0(String[] args) throws Exception
{    List<TelephoneCall> calls = Lists.newArrayList(new TelephoneCallParser("bank-full.csv"));    double heldOutPercentage = 0.10;    for (int run = 0; run < 20; run++) {        Collections.shuffle(calls);        int cutoff = (int) (heldOutPercentage * calls.size());        List<TelephoneCall> test = calls.subList(0, cutoff);        List<TelephoneCall> train = calls.subList(cutoff, calls.size());        OnlineLogisticRegression lr = new OnlineLogisticRegression(NUM_CATEGORIES, TelephoneCall.FEATURES, new L1()).learningRate(1).alpha(1).lambda(0.000001).stepOffset(10000).decayExponent(0.2);        for (int pass = 0; pass < 20; pass++) {            for (TelephoneCall observation : train) {                lr.train(observation.getTarget(), observation.asVector());            }            if (pass % 5 == 0) {                Auc eval = new Auc(0.5);                for (TelephoneCall testCall : test) {                    eval.add(testCall.getTarget(), lr.classifyScalar(testCall.asVector()));                }                System.out.printf("%d, %.4f, %.4f\n", pass, lr.currentLearningRate(), eval.auc());            }        }    }}
public Vector mahout_f5540_0()
{    return vector;}
public int mahout_f5541_0()
{    return fields.get("y").equals("no") ? 0 : 1;}
public Iterator<TelephoneCall> mahout_f5542_0()
{    try {        return new AbstractIterator<TelephoneCall>() {            BufferedReader input = new BufferedReader(new InputStreamReader(Resources.getResource(resourceName).openStream()));            Iterable<String> fieldNames = onSemi.split(input.readLine());            @Override            protected TelephoneCall computeNext() {                try {                    String line = input.readLine();                    if (line == null) {                        return endOfData();                    }                    return new TelephoneCall(fieldNames, onSemi.split(line));                } catch (IOException e) {                    throw new RuntimeException("Error reading data", e);                }            }        };    } catch (IOException e) {        throw new RuntimeException("Error reading data", e);    }}
protected TelephoneCall mahout_f5543_0()
{    try {        String line = input.readLine();        if (line == null) {            return endOfData();        }        return new TelephoneCall(fieldNames, onSemi.split(line));    } catch (IOException e) {        throw new RuntimeException("Error reading data", e);    }}
public CsvRecordFactory mahout_f5544_0()
{    if (csv == null) {        csv = new CsvRecordFactory(getTargetVariable(), getTypeMap()).maxTargetValue(getMaxTargetCategories()).includeBiasTerm(useBias());        if (targetCategories != null) {            csv.defineTargetCategories(targetCategories);        }    }    return csv;}
public OnlineLogisticRegression mahout_f5545_0()
{    if (lr == null) {        lr = new OnlineLogisticRegression(getMaxTargetCategories(), getNumFeatures(), new L1()).lambda(getLambda()).learningRate(getLearningRate()).alpha(1 - 1.0e-3);    }    return lr;}
public void mahout_f5546_0(OutputStream out) throws IOException
{    Closeables.close(lr, false);    targetCategories = getCsvRecordFactory().getTargetCategories();    write(new DataOutputStream(out));}
public static LogisticModelParameters mahout_f5547_0(InputStream in) throws IOException
{    LogisticModelParameters result = new LogisticModelParameters();    result.readFields(new DataInputStream(in));    return result;}
public static LogisticModelParameters mahout_f5548_0(File in) throws IOException
{    try (InputStream input = new FileInputStream(in)) {        return loadFrom(input);    }}
public void mahout_f5549_0(DataOutput out) throws IOException
{    out.writeUTF(targetVariable);    out.writeInt(typeMap.size());    for (Map.Entry<String, String> entry : typeMap.entrySet()) {        out.writeUTF(entry.getKey());        out.writeUTF(entry.getValue());    }    out.writeInt(numFeatures);    out.writeBoolean(useBias);    out.writeInt(maxTargetCategories);    if (targetCategories == null) {        out.writeInt(0);    } else {        out.writeInt(targetCategories.size());        for (String category : targetCategories) {            out.writeUTF(category);        }    }    out.writeDouble(lambda);    out.writeDouble(learningRate);        lr.write(out);}
public void mahout_f5550_0(DataInput in) throws IOException
{    targetVariable = in.readUTF();    int typeMapSize = in.readInt();    typeMap = new HashMap<>(typeMapSize);    for (int i = 0; i < typeMapSize; i++) {        String key = in.readUTF();        String value = in.readUTF();        typeMap.put(key, value);    }    numFeatures = in.readInt();    useBias = in.readBoolean();    maxTargetCategories = in.readInt();    int targetCategoriesSize = in.readInt();    targetCategories = new ArrayList<>(targetCategoriesSize);    for (int i = 0; i < targetCategoriesSize; i++) {        targetCategories.add(in.readUTF());    }    lambda = in.readDouble();    learningRate = in.readDouble();    csv = null;    lr = new OnlineLogisticRegression();    lr.readFields(in);}
public void mahout_f5551_0(Iterable<String> predictorList, List<String> typeList)
{    Preconditions.checkArgument(!typeList.isEmpty(), "Must have at least one type specifier");    typeMap = new HashMap<>();    Iterator<String> iTypes = typeList.iterator();    String lastType = null;    for (Object x : predictorList) {                if (iTypes.hasNext()) {            lastType = iTypes.next();        }        typeMap.put(x.toString(), lastType);    }}
public void mahout_f5552_0(String targetVariable)
{    this.targetVariable = targetVariable;}
public void mahout_f5553_0(int maxTargetCategories)
{    this.maxTargetCategories = maxTargetCategories;}
public void mahout_f5554_0(int numFeatures)
{    this.numFeatures = numFeatures;}
public void mahout_f5555_0(List<String> targetCategories)
{    this.targetCategories = targetCategories;    maxTargetCategories = targetCategories.size();}
public List<String> mahout_f5556_0()
{    return this.targetCategories;}
public void mahout_f5557_0(boolean useBias)
{    this.useBias = useBias;}
public boolean mahout_f5558_0()
{    return useBias;}
public String mahout_f5559_0()
{    return targetVariable;}
public Map<String, String> mahout_f5560_0()
{    return typeMap;}
public void mahout_f5561_0(Map<String, String> map)
{    this.typeMap = map;}
public int mahout_f5562_0()
{    return numFeatures;}
public int mahout_f5563_0()
{    return maxTargetCategories;}
public double mahout_f5564_0()
{    return lambda;}
public void mahout_f5565_0(double lambda)
{    this.lambda = lambda;}
public double mahout_f5566_0()
{    return learningRate;}
public void mahout_f5567_0(double learningRate)
{    this.learningRate = learningRate;}
public static void mahout_f5568_0(String[] args) throws Exception
{    Preconditions.checkArgument(args.length == 1, "Must have a single argument that names a file or resource.");    try (BufferedReader in = TrainLogistic.open(args[0])) {        String line;        while ((line = in.readLine()) != null) {            System.out.println(line);        }    }}
public static void mahout_f5569_0(String[] args) throws Exception
{    mainToOutput(args, new PrintWriter(new OutputStreamWriter(System.out, Charsets.UTF_8), true));}
 static void mahout_f5570_0(String[] args, PrintWriter output) throws Exception
{    if (!parseArgs(args)) {        return;    }    AdaptiveLogisticModelParameters lmp = AdaptiveLogisticModelParameters.loadFromFile(new File(modelFile));    CsvRecordFactory csv = lmp.getCsvRecordFactory();    csv.setIdName(idColumn);    AdaptiveLogisticRegression lr = lmp.createAdaptiveLogisticRegression();    State<Wrapper, CrossFoldLearner> best = lr.getBest();    if (best == null) {        output.println("AdaptiveLogisticRegression has not be trained probably.");        return;    }    CrossFoldLearner learner = best.getPayload().getLearner();    BufferedReader in = TrainAdaptiveLogistic.open(inputFile);    int k = 0;    try (BufferedWriter out = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(outputFile), Charsets.UTF_8))) {        out.write(idColumn + ",target,score");        out.newLine();        String line = in.readLine();        csv.firstLine(line);        line = in.readLine();        Map<String, Double> results = new HashMap<>();        while (line != null) {            Vector v = new SequentialAccessSparseVector(lmp.getNumFeatures());            csv.processLine(line, v, false);            Vector scores = learner.classifyFull(v);            results.clear();            if (maxScoreOnly) {                results.put(csv.getTargetLabel(scores.maxValueIndex()), scores.maxValue());            } else {                for (int i = 0; i < scores.size(); i++) {                    results.put(csv.getTargetLabel(i), scores.get(i));                }            }            for (Map.Entry<String, Double> entry : results.entrySet()) {                out.write(csv.getIdString(line) + ',' + entry.getKey() + ',' + entry.getValue());                out.newLine();            }            k++;            if (k % 100 == 0) {                output.println(k + " records processed");            }            line = in.readLine();        }        out.flush();    }    output.println(k + " records processed totally.");}
private static boolean mahout_f5571_0(String[] args)
{    DefaultOptionBuilder builder = new DefaultOptionBuilder();    Option help = builder.withLongName("help").withDescription("print this list").create();    Option quiet = builder.withLongName("quiet").withDescription("be extra quiet").create();    ArgumentBuilder argumentBuilder = new ArgumentBuilder();    Option inputFileOption = builder.withLongName("input").withRequired(true).withArgument(argumentBuilder.withName("input").withMaximum(1).create()).withDescription("where to get training data").create();    Option modelFileOption = builder.withLongName("model").withRequired(true).withArgument(argumentBuilder.withName("model").withMaximum(1).create()).withDescription("where to get the trained model").create();    Option outputFileOption = builder.withLongName("output").withRequired(true).withDescription("the file path to output scores").withArgument(argumentBuilder.withName("output").withMaximum(1).create()).create();    Option idColumnOption = builder.withLongName("idcolumn").withRequired(true).withDescription("the name of the id column for each record").withArgument(argumentBuilder.withName("idcolumn").withMaximum(1).create()).create();    Option maxScoreOnlyOption = builder.withLongName("maxscoreonly").withDescription("only output the target label with max scores").create();    Group normalArgs = new GroupBuilder().withOption(help).withOption(quiet).withOption(inputFileOption).withOption(modelFileOption).withOption(outputFileOption).withOption(idColumnOption).withOption(maxScoreOnlyOption).create();    Parser parser = new Parser();    parser.setHelpOption(help);    parser.setHelpTrigger("--help");    parser.setGroup(normalArgs);    parser.setHelpFormatter(new HelpFormatter(" ", "", " ", 130));    CommandLine cmdLine = parser.parseAndHelp(args);    if (cmdLine == null) {        return false;    }    inputFile = getStringArgument(cmdLine, inputFileOption);    modelFile = getStringArgument(cmdLine, modelFileOption);    outputFile = getStringArgument(cmdLine, outputFileOption);    idColumn = getStringArgument(cmdLine, idColumnOption);    maxScoreOnly = getBooleanArgument(cmdLine, maxScoreOnlyOption);    return true;}
private static boolean mahout_f5572_0(CommandLine cmdLine, Option option)
{    return cmdLine.hasOption(option);}
private static String mahout_f5573_0(CommandLine cmdLine, Option inputFile)
{    return (String) cmdLine.getValue(inputFile);}
public static void mahout_f5574_0(String[] args) throws Exception
{    mainToOutput(args, new PrintWriter(new OutputStreamWriter(System.out, Charsets.UTF_8), true));}
 static void mahout_f5575_0(String[] args, PrintWriter output) throws Exception
{    if (parseArgs(args)) {        if (!showAuc && !showConfusion && !showScores) {            showAuc = true;            showConfusion = true;        }        Auc collector = new Auc();        LogisticModelParameters lmp = LogisticModelParameters.loadFrom(new File(modelFile));        CsvRecordFactory csv = lmp.getCsvRecordFactory();        OnlineLogisticRegression lr = lmp.createRegression();        BufferedReader in = TrainLogistic.open(inputFile);        String line = in.readLine();        csv.firstLine(line);        line = in.readLine();        if (showScores) {            output.println("\"target\",\"model-output\",\"log-likelihood\"");        }        while (line != null) {            Vector v = new SequentialAccessSparseVector(lmp.getNumFeatures());            int target = csv.processLine(line, v);            double score = lr.classifyScalar(v);            if (showScores) {                output.printf(Locale.ENGLISH, "%d,%.3f,%.6f%n", target, score, lr.logLikelihood(target, v));            }            collector.add(target, score);            line = in.readLine();        }        if (showAuc) {            output.printf(Locale.ENGLISH, "AUC = %.2f%n", collector.auc());        }        if (showConfusion) {            Matrix m = collector.confusion();            output.printf(Locale.ENGLISH, "confusion: [[%.1f, %.1f], [%.1f, %.1f]]%n", m.get(0, 0), m.get(1, 0), m.get(0, 1), m.get(1, 1));            m = collector.entropy();            output.printf(Locale.ENGLISH, "entropy: [[%.1f, %.1f], [%.1f, %.1f]]%n", m.get(0, 0), m.get(1, 0), m.get(0, 1), m.get(1, 1));        }    }}
private static boolean mahout_f5576_0(String[] args)
{    DefaultOptionBuilder builder = new DefaultOptionBuilder();    Option help = builder.withLongName("help").withDescription("print this list").create();    Option quiet = builder.withLongName("quiet").withDescription("be extra quiet").create();    Option auc = builder.withLongName("auc").withDescription("print AUC").create();    Option confusion = builder.withLongName("confusion").withDescription("print confusion matrix").create();    Option scores = builder.withLongName("scores").withDescription("print scores").create();    ArgumentBuilder argumentBuilder = new ArgumentBuilder();    Option inputFileOption = builder.withLongName("input").withRequired(true).withArgument(argumentBuilder.withName("input").withMaximum(1).create()).withDescription("where to get training data").create();    Option modelFileOption = builder.withLongName("model").withRequired(true).withArgument(argumentBuilder.withName("model").withMaximum(1).create()).withDescription("where to get a model").create();    Group normalArgs = new GroupBuilder().withOption(help).withOption(quiet).withOption(auc).withOption(scores).withOption(confusion).withOption(inputFileOption).withOption(modelFileOption).create();    Parser parser = new Parser();    parser.setHelpOption(help);    parser.setHelpTrigger("--help");    parser.setGroup(normalArgs);    parser.setHelpFormatter(new HelpFormatter(" ", "", " ", 130));    CommandLine cmdLine = parser.parseAndHelp(args);    if (cmdLine == null) {        return false;    }    inputFile = getStringArgument(cmdLine, inputFileOption);    modelFile = getStringArgument(cmdLine, modelFileOption);    showAuc = getBooleanArgument(cmdLine, auc);    showScores = getBooleanArgument(cmdLine, scores);    showConfusion = getBooleanArgument(cmdLine, confusion);    return true;}
private static boolean mahout_f5577_0(CommandLine cmdLine, Option option)
{    return cmdLine.hasOption(option);}
private static String mahout_f5578_0(CommandLine cmdLine, Option inputFile)
{    return (String) cmdLine.getValue(inputFile);}
public static void mahout_f5579_0(int leakType, Dictionary dictionary, AdaptiveLogisticRegression learningAlgorithm, Iterable<File> files, Multiset<String> overallCounts) throws IOException
{    CrossFoldLearner model = learningAlgorithm.getBest().getPayload().getLearner();    model.close();    Map<String, Set<Integer>> traceDictionary = new TreeMap<>();    ModelDissector md = new ModelDissector();    NewsgroupHelper helper = new NewsgroupHelper();    helper.getEncoder().setTraceDictionary(traceDictionary);    helper.getBias().setTraceDictionary(traceDictionary);    for (File file : permute(files, helper.getRandom()).subList(0, 500)) {        String ng = file.getParentFile().getName();        int actual = dictionary.intern(ng);        traceDictionary.clear();        Vector v = helper.encodeFeatureVector(file, actual, leakType, overallCounts);        md.update(v, traceDictionary, model);    }    List<String> ngNames = new ArrayList<>(dictionary.values());    List<ModelDissector.Weight> weights = md.summary(100);    System.out.println("============");    System.out.println("Model Dissection");    for (ModelDissector.Weight w : weights) {        System.out.printf("%s\t%.1f\t%s\t%.1f\t%s\t%.1f\t%s%n", w.getFeature(), w.getWeight(), ngNames.get(w.getMaxImpact() + 1), w.getCategory(1), w.getWeight(1), w.getCategory(2), w.getWeight(2));    }}
public static List<File> mahout_f5580_0(Iterable<File> files, Random rand)
{    List<File> r = new ArrayList<>();    for (File file : files) {        int i = rand.nextInt(r.size() + 1);        if (i == r.size()) {            r.add(file);        } else {            r.add(r.get(i));            r.set(i, file);        }    }    return r;}
 static void mahout_f5581_0(SGDInfo info, int leakType, int k, State<AdaptiveLogisticRegression.Wrapper, CrossFoldLearner> best) throws IOException
{    int bump = info.getBumps()[(int) Math.floor(info.getStep()) % info.getBumps().length];    int scale = (int) Math.pow(10, Math.floor(info.getStep() / info.getBumps().length));    double maxBeta;    double nonZeros;    double positive;    double norm;    double lambda = 0;    double mu = 0;    if (best != null) {        CrossFoldLearner state = best.getPayload().getLearner();        info.setAverageCorrect(state.percentCorrect());        info.setAverageLL(state.logLikelihood());        OnlineLogisticRegression model = state.getModels().get(0);                model.close();        Matrix beta = model.getBeta();        maxBeta = beta.aggregate(Functions.MAX, Functions.ABS);        nonZeros = beta.aggregate(Functions.PLUS, new DoubleFunction() {            @Override            public double apply(double v) {                return Math.abs(v) > 1.0e-6 ? 1 : 0;            }        });        positive = beta.aggregate(Functions.PLUS, new DoubleFunction() {            @Override            public double apply(double v) {                return v > 0 ? 1 : 0;            }        });        norm = beta.aggregate(Functions.PLUS, Functions.ABS);        lambda = best.getMappedParams()[0];        mu = best.getMappedParams()[1];    } else {        maxBeta = 0;        nonZeros = 0;        positive = 0;        norm = 0;    }    if (k % (bump * scale) == 0) {        if (best != null) {            File modelFile = new File(System.getProperty("java.io.tmpdir"), "news-group-" + k + ".model");            ModelSerializer.writeBinary(modelFile.getAbsolutePath(), best.getPayload().getLearner().getModels().get(0));        }        info.setStep(info.getStep() + 0.25);        System.out.printf("%.2f\t%.2f\t%.2f\t%.2f\t%.8g\t%.8g\t", maxBeta, nonZeros, positive, norm, lambda, mu);        System.out.printf("%d\t%.3f\t%.2f\t%s%n", k, info.getAverageLL(), info.getAverageCorrect() * 100, LEAK_LABELS[leakType % 3]);    }}
public double mahout_f5582_0(double v)
{    return Math.abs(v) > 1.0e-6 ? 1 : 0;}
public double mahout_f5583_0(double v)
{    return v > 0 ? 1 : 0;}
 double mahout_f5584_0()
{    return averageLL;}
 void mahout_f5585_0(double averageLL)
{    this.averageLL = averageLL;}
 double mahout_f5586_0()
{    return averageCorrect;}
 void mahout_f5587_0(double averageCorrect)
{    this.averageCorrect = averageCorrect;}
 double mahout_f5588_0()
{    return step;}
 void mahout_f5589_0(double step)
{    this.step = step;}
 int[] mahout_f5590_0()
{    return bumps;}
 void mahout_f5591_0(int[] bumps)
{    this.bumps = bumps;}
public static void mahout_f5592_0(String[] args) throws IOException
{    FeatureVectorEncoder[] encoder = new FeatureVectorEncoder[FIELDS];    for (int i = 0; i < FIELDS; i++) {        encoder[i] = new ConstantValueEncoder("v" + 1);    }    OnlineSummarizer[] s = new OnlineSummarizer[FIELDS];    for (int i = 0; i < FIELDS; i++) {        s[i] = new OnlineSummarizer();    }    long t0 = System.currentTimeMillis();    Vector v = new DenseVector(1000);    if ("--generate".equals(args[0])) {        try (PrintWriter out = new PrintWriter(new OutputStreamWriter(new FileOutputStream(new File(args[2])), Charsets.UTF_8))) {            int n = Integer.parseInt(args[1]);            for (int i = 0; i < n; i++) {                Line x = Line.generate();                out.println(x);            }        }    } else if ("--parse".equals(args[0])) {        try (BufferedReader in = Files.newReader(new File(args[1]), Charsets.UTF_8)) {            String line = in.readLine();            while (line != null) {                v.assign(0);                Line x = new Line(line);                for (int i = 0; i < FIELDS; i++) {                    s[i].add(x.getDouble(i));                    encoder[i].addToVector(x.get(i), v);                }                line = in.readLine();            }        }        String separator = "";        for (int i = 0; i < FIELDS; i++) {            System.out.printf("%s%.3f", separator, s[i].getMean());            separator = ",";        }    } else if ("--fast".equals(args[0])) {        try (FastLineReader in = new FastLineReader(new FileInputStream(args[1]))) {            FastLine line = in.read();            while (line != null) {                v.assign(0);                for (int i = 0; i < FIELDS; i++) {                    double z = line.getDouble(i);                    s[i].add(z);                    encoder[i].addToVector((byte[]) null, z, v);                }                line = in.read();            }        }        String separator = "";        for (int i = 0; i < FIELDS; i++) {            System.out.printf("%s%.3f", separator, s[i].getMean());            separator = ",";        }    }    System.out.printf("\nElapsed time = %.3f%n", (System.currentTimeMillis() - t0) / 1000.0);}
public double mahout_f5593_0(int field)
{    return Double.parseDouble(data.get(field));}
public static Line mahout_f5594_0()
{    Line r = new Line();    for (int i = 0; i < FIELDS; i++) {        double mean = ((i + 1) * 257) % 50 + 1;        r.data.add(Integer.toString(randomValue(mean)));    }    return r;}
private static int mahout_f5595_0(double mean)
{    return (int) (-mean * Math.log1p(-RAND.nextDouble()));}
public String mahout_f5596_0()
{    return WITH_COMMAS.join(data);}
public String mahout_f5597_0(int field)
{    return data.get(field);}
public static FastLine mahout_f5598_0(ByteBuffer buf)
{    FastLine r = new FastLine(buf);    r.start.add(buf.position());    int offset = buf.position();    while (offset < buf.limit()) {        int ch = buf.get();        offset = buf.position();        switch(ch) {            case '\n':                r.length.add(offset - r.start.get(r.length.size()) - 1);                return r;            case SEPARATOR_CHAR:                r.length.add(offset - r.start.get(r.length.size()) - 1);                r.start.add(offset);                break;            default:        }    }    throw new IllegalArgumentException("Not enough bytes in buffer");}
public double mahout_f5599_0(int field)
{    int offset = start.get(field);    int size = length.get(field);    switch(size) {        case 1:            return base.get(offset) - '0';        case 2:            return (base.get(offset) - '0') * 10 + base.get(offset + 1) - '0';        default:            double r = 0;            for (int i = 0; i < size; i++) {                r = 10 * r + base.get(offset + i) - '0';            }            return r;    }}
public FastLine mahout_f5600_0() throws IOException
{    fillBuffer();    if (buf.remaining() > 0) {        return FastLine.read(buf);    } else {        return null;    }}
private void mahout_f5601_0() throws IOException
{    if (buf.remaining() < 10000) {        buf.compact();        int n = in.read(buf.array(), buf.position(), buf.remaining());        if (n == -1) {            buf.flip();        } else {            buf.limit(buf.position() + n);            buf.position(0);        }    }}
public void mahout_f5602_1()
{    try {        Closeables.close(in, true);    } catch (IOException e) {            }}
public static void mahout_f5603_0(String[] args) throws IOException
{    TestASFEmail runner = new TestASFEmail();    if (runner.parseArgs(args)) {        runner.run(new PrintWriter(new OutputStreamWriter(System.out, Charsets.UTF_8), true));    }}
public void mahout_f5604_0(PrintWriter output) throws IOException
{    File base = new File(inputFile);        OnlineLogisticRegression classifier = ModelSerializer.readBinary(new FileInputStream(modelFile), OnlineLogisticRegression.class);    Dictionary asfDictionary = new Dictionary();    Configuration conf = new Configuration();    PathFilter testFilter = new PathFilter() {        @Override        public boolean accept(Path path) {            return path.getName().contains("test");        }    };    SequenceFileDirIterator<Text, VectorWritable> iter = new SequenceFileDirIterator<>(new Path(base.toString()), PathType.LIST, testFilter, null, true, conf);    long numItems = 0;    while (iter.hasNext()) {        Pair<Text, VectorWritable> next = iter.next();        asfDictionary.intern(next.getFirst().toString());        numItems++;    }    System.out.println(numItems + " test files");    ResultAnalyzer ra = new ResultAnalyzer(asfDictionary.values(), "DEFAULT");    iter = new SequenceFileDirIterator<>(new Path(base.toString()), PathType.LIST, testFilter, null, true, conf);    while (iter.hasNext()) {        Pair<Text, VectorWritable> next = iter.next();        String ng = next.getFirst().toString();        int actual = asfDictionary.intern(ng);        Vector result = classifier.classifyFull(next.getSecond().get());        int cat = result.maxValueIndex();        double score = result.maxValue();        double ll = classifier.logLikelihood(actual, next.getSecond().get());        ClassifierResult cr = new ClassifierResult(asfDictionary.values().get(cat), score, ll);        ra.addInstance(asfDictionary.values().get(actual), cr);    }    output.println(ra);}
public boolean mahout_f5605_0(Path path)
{    return path.getName().contains("test");}
 boolean mahout_f5606_0(String[] args)
{    DefaultOptionBuilder builder = new DefaultOptionBuilder();    Option help = builder.withLongName("help").withDescription("print this list").create();    ArgumentBuilder argumentBuilder = new ArgumentBuilder();    Option inputFileOption = builder.withLongName("input").withRequired(true).withArgument(argumentBuilder.withName("input").withMaximum(1).create()).withDescription("where to get training data").create();    Option modelFileOption = builder.withLongName("model").withRequired(true).withArgument(argumentBuilder.withName("model").withMaximum(1).create()).withDescription("where to get a model").create();    Group normalArgs = new GroupBuilder().withOption(help).withOption(inputFileOption).withOption(modelFileOption).create();    Parser parser = new Parser();    parser.setHelpOption(help);    parser.setHelpTrigger("--help");    parser.setGroup(normalArgs);    parser.setHelpFormatter(new HelpFormatter(" ", "", " ", 130));    CommandLine cmdLine = parser.parseAndHelp(args);    if (cmdLine == null) {        return false;    }    inputFile = (String) cmdLine.getValue(inputFileOption);    modelFile = (String) cmdLine.getValue(modelFileOption);    return true;}
public static void mahout_f5607_0(String[] args) throws IOException
{    TestNewsGroups runner = new TestNewsGroups();    if (runner.parseArgs(args)) {        runner.run(new PrintWriter(new OutputStreamWriter(System.out, Charsets.UTF_8), true));    }}
public void mahout_f5608_0(PrintWriter output) throws IOException
{    File base = new File(inputFile);        OnlineLogisticRegression classifier = ModelSerializer.readBinary(new FileInputStream(modelFile), OnlineLogisticRegression.class);    Dictionary newsGroups = new Dictionary();    Multiset<String> overallCounts = HashMultiset.create();    List<File> files = new ArrayList<>();    for (File newsgroup : base.listFiles()) {        if (newsgroup.isDirectory()) {            newsGroups.intern(newsgroup.getName());            files.addAll(Arrays.asList(newsgroup.listFiles()));        }    }    System.out.println(files.size() + " test files");    ResultAnalyzer ra = new ResultAnalyzer(newsGroups.values(), "DEFAULT");    for (File file : files) {        String ng = file.getParentFile().getName();        int actual = newsGroups.intern(ng);        NewsgroupHelper helper = new NewsgroupHelper();                Vector input = helper.encodeFeatureVector(file, actual, 0, overallCounts);        Vector result = classifier.classifyFull(input);        int cat = result.maxValueIndex();        double score = result.maxValue();        double ll = classifier.logLikelihood(actual, input);        ClassifierResult cr = new ClassifierResult(newsGroups.values().get(cat), score, ll);        ra.addInstance(newsGroups.values().get(actual), cr);    }    output.println(ra);}
 boolean mahout_f5609_0(String[] args)
{    DefaultOptionBuilder builder = new DefaultOptionBuilder();    Option help = builder.withLongName("help").withDescription("print this list").create();    ArgumentBuilder argumentBuilder = new ArgumentBuilder();    Option inputFileOption = builder.withLongName("input").withRequired(true).withArgument(argumentBuilder.withName("input").withMaximum(1).create()).withDescription("where to get training data").create();    Option modelFileOption = builder.withLongName("model").withRequired(true).withArgument(argumentBuilder.withName("model").withMaximum(1).create()).withDescription("where to get a model").create();    Group normalArgs = new GroupBuilder().withOption(help).withOption(inputFileOption).withOption(modelFileOption).create();    Parser parser = new Parser();    parser.setHelpOption(help);    parser.setHelpTrigger("--help");    parser.setGroup(normalArgs);    parser.setHelpFormatter(new HelpFormatter(" ", "", " ", 130));    CommandLine cmdLine = parser.parseAndHelp(args);    if (cmdLine == null) {        return false;    }    inputFile = (String) cmdLine.getValue(inputFileOption);    modelFile = (String) cmdLine.getValue(modelFileOption);    return true;}
public static void mahout_f5610_0(String[] args) throws Exception
{    mainToOutput(args, new PrintWriter(new OutputStreamWriter(System.out, Charsets.UTF_8), true));}
 static void mahout_f5611_0(String[] args, PrintWriter output) throws Exception
{    if (parseArgs(args)) {        CsvRecordFactory csv = lmp.getCsvRecordFactory();        model = lmp.createAdaptiveLogisticRegression();        State<Wrapper, CrossFoldLearner> best;        CrossFoldLearner learner = null;        int k = 0;        for (int pass = 0; pass < passes; pass++) {            BufferedReader in = open(inputFile);                        csv.firstLine(in.readLine());            String line = in.readLine();            while (line != null) {                                Vector input = new RandomAccessSparseVector(lmp.getNumFeatures());                int targetValue = csv.processLine(line, input);                                model.train(targetValue, input);                k++;                if (showperf && (k % (skipperfnum + 1) == 0)) {                    best = model.getBest();                    if (best != null) {                        learner = best.getPayload().getLearner();                    }                    if (learner != null) {                        double averageCorrect = learner.percentCorrect();                        double averageLL = learner.logLikelihood();                        output.printf("%d\t%.3f\t%.2f%n", k, averageLL, averageCorrect * 100);                    } else {                        output.printf(Locale.ENGLISH, "%10d %2d %s%n", k, targetValue, "AdaptiveLogisticRegression has not found a good model ......");                    }                }                line = in.readLine();            }            in.close();        }        best = model.getBest();        if (best != null) {            learner = best.getPayload().getLearner();        }        if (learner == null) {            output.println("AdaptiveLogisticRegression has failed to train a model.");            return;        }        try (OutputStream modelOutput = new FileOutputStream(outputFile)) {            lmp.saveTo(modelOutput);        }        OnlineLogisticRegression lr = learner.getModels().get(0);        output.println(lmp.getNumFeatures());        output.println(lmp.getTargetVariable() + " ~ ");        String sep = "";        for (String v : csv.getTraceDictionary().keySet()) {            double weight = predictorWeight(lr, 0, csv, v);            if (weight != 0) {                output.printf(Locale.ENGLISH, "%s%.3f*%s", sep, weight, v);                sep = " + ";            }        }        output.printf("%n");        for (int row = 0; row < lr.getBeta().numRows(); row++) {            for (String key : csv.getTraceDictionary().keySet()) {                double weight = predictorWeight(lr, row, csv, key);                if (weight != 0) {                    output.printf(Locale.ENGLISH, "%20s %.5f%n", key, weight);                }            }            for (int column = 0; column < lr.getBeta().numCols(); column++) {                output.printf(Locale.ENGLISH, "%15.9f ", lr.getBeta().get(row, column));            }            output.println();        }    }}
private static double mahout_f5612_0(OnlineLogisticRegression lr, int row, RecordFactory csv, String predictor)
{    double weight = 0;    for (Integer column : csv.getTraceDictionary().get(predictor)) {        weight += lr.getBeta().get(row, column);    }    return weight;}
private static boolean mahout_f5613_0(String[] args)
{    DefaultOptionBuilder builder = new DefaultOptionBuilder();    Option help = builder.withLongName("help").withDescription("print this list").create();    Option quiet = builder.withLongName("quiet").withDescription("be extra quiet").create();    ArgumentBuilder argumentBuilder = new ArgumentBuilder();    Option showperf = builder.withLongName("showperf").withDescription("output performance measures during training").create();    Option inputFile = builder.withLongName("input").withRequired(true).withArgument(argumentBuilder.withName("input").withMaximum(1).create()).withDescription("where to get training data").create();    Option outputFile = builder.withLongName("output").withRequired(true).withArgument(argumentBuilder.withName("output").withMaximum(1).create()).withDescription("where to write the model content").create();    Option threads = builder.withLongName("threads").withArgument(argumentBuilder.withName("threads").withDefault("4").create()).withDescription("the number of threads AdaptiveLogisticRegression uses").create();    Option predictors = builder.withLongName("predictors").withRequired(true).withArgument(argumentBuilder.withName("predictors").create()).withDescription("a list of predictor variables").create();    Option types = builder.withLongName("types").withRequired(true).withArgument(argumentBuilder.withName("types").create()).withDescription("a list of predictor variable types (numeric, word, or text)").create();    Option target = builder.withLongName("target").withDescription("the name of the target variable").withRequired(true).withArgument(argumentBuilder.withName("target").withMaximum(1).create()).create();    Option targetCategories = builder.withLongName("categories").withDescription("the number of target categories to be considered").withRequired(true).withArgument(argumentBuilder.withName("categories").withMaximum(1).create()).create();    Option features = builder.withLongName("features").withDescription("the number of internal hashed features to use").withArgument(argumentBuilder.withName("numFeatures").withDefault("1000").withMaximum(1).create()).create();    Option passes = builder.withLongName("passes").withDescription("the number of times to pass over the input data").withArgument(argumentBuilder.withName("passes").withDefault("2").withMaximum(1).create()).create();    Option interval = builder.withLongName("interval").withArgument(argumentBuilder.withName("interval").withDefault("500").create()).withDescription("the interval property of AdaptiveLogisticRegression").create();    Option window = builder.withLongName("window").withArgument(argumentBuilder.withName("window").withDefault("800").create()).withDescription("the average propery of AdaptiveLogisticRegression").create();    Option skipperfnum = builder.withLongName("skipperfnum").withArgument(argumentBuilder.withName("skipperfnum").withDefault("99").create()).withDescription("show performance measures every (skipperfnum + 1) rows").create();    Option prior = builder.withLongName("prior").withArgument(argumentBuilder.withName("prior").withDefault("L1").create()).withDescription("the prior algorithm to use: L1, L2, ebp, tp, up").create();    Option priorOption = builder.withLongName("prioroption").withArgument(argumentBuilder.withName("prioroption").create()).withDescription("constructor parameter for ElasticBandPrior and TPrior").create();    Option auc = builder.withLongName("auc").withArgument(argumentBuilder.withName("auc").withDefault("global").create()).withDescription("the auc to use: global or grouped").create();    Group normalArgs = new GroupBuilder().withOption(help).withOption(quiet).withOption(inputFile).withOption(outputFile).withOption(target).withOption(targetCategories).withOption(predictors).withOption(types).withOption(passes).withOption(interval).withOption(window).withOption(threads).withOption(prior).withOption(features).withOption(showperf).withOption(skipperfnum).withOption(priorOption).withOption(auc).create();    Parser parser = new Parser();    parser.setHelpOption(help);    parser.setHelpTrigger("--help");    parser.setGroup(normalArgs);    parser.setHelpFormatter(new HelpFormatter(" ", "", " ", 130));    CommandLine cmdLine = parser.parseAndHelp(args);    if (cmdLine == null) {        return false;    }    TrainAdaptiveLogistic.inputFile = getStringArgument(cmdLine, inputFile);    TrainAdaptiveLogistic.outputFile = getStringArgument(cmdLine, outputFile);    List<String> typeList = new ArrayList<>();    for (Object x : cmdLine.getValues(types)) {        typeList.add(x.toString());    }    List<String> predictorList = new ArrayList<>();    for (Object x : cmdLine.getValues(predictors)) {        predictorList.add(x.toString());    }    lmp = new AdaptiveLogisticModelParameters();    lmp.setTargetVariable(getStringArgument(cmdLine, target));    lmp.setMaxTargetCategories(getIntegerArgument(cmdLine, targetCategories));    lmp.setNumFeatures(getIntegerArgument(cmdLine, features));    lmp.setInterval(getIntegerArgument(cmdLine, interval));    lmp.setAverageWindow(getIntegerArgument(cmdLine, window));    lmp.setThreads(getIntegerArgument(cmdLine, threads));    lmp.setAuc(getStringArgument(cmdLine, auc));    lmp.setPrior(getStringArgument(cmdLine, prior));    if (cmdLine.getValue(priorOption) != null) {        lmp.setPriorOption(getDoubleArgument(cmdLine, priorOption));    }    lmp.setTypeMap(predictorList, typeList);    TrainAdaptiveLogistic.showperf = getBooleanArgument(cmdLine, showperf);    TrainAdaptiveLogistic.skipperfnum = getIntegerArgument(cmdLine, skipperfnum);    TrainAdaptiveLogistic.passes = getIntegerArgument(cmdLine, passes);    lmp.checkParameters();    return true;}
private static String mahout_f5614_0(CommandLine cmdLine, Option inputFile)
{    return (String) cmdLine.getValue(inputFile);}
private static boolean mahout_f5615_0(CommandLine cmdLine, Option option)
{    return cmdLine.hasOption(option);}
private static int mahout_f5616_0(CommandLine cmdLine, Option features)
{    return Integer.parseInt((String) cmdLine.getValue(features));}
private static double mahout_f5617_0(CommandLine cmdLine, Option op)
{    return Double.parseDouble((String) cmdLine.getValue(op));}
public static AdaptiveLogisticRegression mahout_f5618_0()
{    return model;}
public static LogisticModelParameters mahout_f5619_0()
{    return lmp;}
 static BufferedReader mahout_f5620_0(String inputFile) throws IOException
{    InputStream in;    try {        in = Resources.getResource(inputFile).openStream();    } catch (IllegalArgumentException e) {        in = new FileInputStream(new File(inputFile));    }    return new BufferedReader(new InputStreamReader(in, Charsets.UTF_8));}
public int mahout_f5621_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption("categories", "nc", "The number of categories to train on", true);    addOption("cardinality", "c", "The size of the vectors to use", "100000");    addOption("threads", "t", "The number of threads to use in the learner", "20");    addOption("poolSize", "p", "The number of CrossFoldLearners to use in the AdaptiveLogisticRegression. " + "Higher values require more memory.", "5");    if (parseArguments(args) == null) {        return -1;    }    File base = new File(getInputPath().toString());    Multiset<String> overallCounts = HashMultiset.create();    File output = new File(getOutputPath().toString());    output.mkdirs();    int numCats = Integer.parseInt(getOption("categories"));    int cardinality = Integer.parseInt(getOption("cardinality", "100000"));    int threadCount = Integer.parseInt(getOption("threads", "20"));    int poolSize = Integer.parseInt(getOption("poolSize", "5"));    Dictionary asfDictionary = new Dictionary();    AdaptiveLogisticRegression learningAlgorithm = new AdaptiveLogisticRegression(numCats, cardinality, new L1(), threadCount, poolSize);    learningAlgorithm.setInterval(800);    learningAlgorithm.setAveragingWindow(500);        Configuration conf = new Configuration();    PathFilter trainFilter = new PathFilter() {        @Override        public boolean accept(Path path) {            return path.getName().contains("training");        }    };    SequenceFileDirIterator<Text, VectorWritable> iter = new SequenceFileDirIterator<>(new Path(base.toString()), PathType.LIST, trainFilter, null, true, conf);    long numItems = 0;    while (iter.hasNext()) {        Pair<Text, VectorWritable> next = iter.next();        asfDictionary.intern(next.getFirst().toString());        numItems++;    }    System.out.println(numItems + " training files");    SGDInfo info = new SGDInfo();    iter = new SequenceFileDirIterator<>(new Path(base.toString()), PathType.LIST, trainFilter, null, true, conf);    int k = 0;    while (iter.hasNext()) {        Pair<Text, VectorWritable> next = iter.next();        String ng = next.getFirst().toString();        int actual = asfDictionary.intern(ng);                learningAlgorithm.train(actual, next.getSecond().get());        k++;        State<AdaptiveLogisticRegression.Wrapper, CrossFoldLearner> best = learningAlgorithm.getBest();        SGDHelper.analyzeState(info, 0, k, best);    }    learningAlgorithm.close();            System.out.println("exiting main, writing model to " + output);    ModelSerializer.writeBinary(output + "/asf.model", learningAlgorithm.getBest().getPayload().getLearner().getModels().get(0));    List<Integer> counts = new ArrayList<>();    System.out.println("Word counts");    for (String count : overallCounts.elementSet()) {        counts.add(overallCounts.count(count));    }    Collections.sort(counts, Ordering.natural().reverse());    k = 0;    for (Integer count : counts) {        System.out.println(k + "\t" + count);        k++;        if (k > 1000) {            break;        }    }    return 0;}
public boolean mahout_f5622_0(Path path)
{    return path.getName().contains("training");}
public static void mahout_f5623_0(String[] args) throws Exception
{    TrainASFEmail trainer = new TrainASFEmail();    trainer.run(args);}
public static void mahout_f5624_0(String[] args) throws Exception
{    mainToOutput(args, new PrintWriter(new OutputStreamWriter(System.out, Charsets.UTF_8), true));}
 static void mahout_f5625_0(String[] args, PrintWriter output) throws Exception
{    if (parseArgs(args)) {        double logPEstimate = 0;        int samples = 0;        CsvRecordFactory csv = lmp.getCsvRecordFactory();        OnlineLogisticRegression lr = lmp.createRegression();        for (int pass = 0; pass < passes; pass++) {            try (BufferedReader in = open(inputFile)) {                                csv.firstLine(in.readLine());                String line = in.readLine();                while (line != null) {                                        Vector input = new RandomAccessSparseVector(lmp.getNumFeatures());                    int targetValue = csv.processLine(line, input);                                        double logP = lr.logLikelihood(targetValue, input);                    if (!Double.isInfinite(logP)) {                        if (samples < 20) {                            logPEstimate = (samples * logPEstimate + logP) / (samples + 1);                        } else {                            logPEstimate = 0.95 * logPEstimate + 0.05 * logP;                        }                        samples++;                    }                    double p = lr.classifyScalar(input);                    if (scores) {                        output.printf(Locale.ENGLISH, "%10d %2d %10.2f %2.4f %10.4f %10.4f%n", samples, targetValue, lr.currentLearningRate(), p, logP, logPEstimate);                    }                                        lr.train(targetValue, input);                    line = in.readLine();                }            }        }        try (OutputStream modelOutput = new FileOutputStream(outputFile)) {            lmp.saveTo(modelOutput);        }        output.println(lmp.getNumFeatures());        output.println(lmp.getTargetVariable() + " ~ ");        String sep = "";        for (String v : csv.getTraceDictionary().keySet()) {            double weight = predictorWeight(lr, 0, csv, v);            if (weight != 0) {                output.printf(Locale.ENGLISH, "%s%.3f*%s", sep, weight, v);                sep = " + ";            }        }        output.printf("%n");        model = lr;        for (int row = 0; row < lr.getBeta().numRows(); row++) {            for (String key : csv.getTraceDictionary().keySet()) {                double weight = predictorWeight(lr, row, csv, key);                if (weight != 0) {                    output.printf(Locale.ENGLISH, "%20s %.5f%n", key, weight);                }            }            for (int column = 0; column < lr.getBeta().numCols(); column++) {                output.printf(Locale.ENGLISH, "%15.9f ", lr.getBeta().get(row, column));            }            output.println();        }    }}
private static double mahout_f5626_0(OnlineLogisticRegression lr, int row, RecordFactory csv, String predictor)
{    double weight = 0;    for (Integer column : csv.getTraceDictionary().get(predictor)) {        weight += lr.getBeta().get(row, column);    }    return weight;}
private static boolean mahout_f5627_0(String[] args)
{    DefaultOptionBuilder builder = new DefaultOptionBuilder();    Option help = builder.withLongName("help").withDescription("print this list").create();    Option quiet = builder.withLongName("quiet").withDescription("be extra quiet").create();    Option scores = builder.withLongName("scores").withDescription("output score diagnostics during training").create();    ArgumentBuilder argumentBuilder = new ArgumentBuilder();    Option inputFile = builder.withLongName("input").withRequired(true).withArgument(argumentBuilder.withName("input").withMaximum(1).create()).withDescription("where to get training data").create();    Option outputFile = builder.withLongName("output").withRequired(true).withArgument(argumentBuilder.withName("output").withMaximum(1).create()).withDescription("where to get training data").create();    Option predictors = builder.withLongName("predictors").withRequired(true).withArgument(argumentBuilder.withName("p").create()).withDescription("a list of predictor variables").create();    Option types = builder.withLongName("types").withRequired(true).withArgument(argumentBuilder.withName("t").create()).withDescription("a list of predictor variable types (numeric, word, or text)").create();    Option target = builder.withLongName("target").withRequired(true).withArgument(argumentBuilder.withName("target").withMaximum(1).create()).withDescription("the name of the target variable").create();    Option features = builder.withLongName("features").withArgument(argumentBuilder.withName("numFeatures").withDefault("1000").withMaximum(1).create()).withDescription("the number of internal hashed features to use").create();    Option passes = builder.withLongName("passes").withArgument(argumentBuilder.withName("passes").withDefault("2").withMaximum(1).create()).withDescription("the number of times to pass over the input data").create();    Option lambda = builder.withLongName("lambda").withArgument(argumentBuilder.withName("lambda").withDefault("1e-4").withMaximum(1).create()).withDescription("the amount of coefficient decay to use").create();    Option rate = builder.withLongName("rate").withArgument(argumentBuilder.withName("learningRate").withDefault("1e-3").withMaximum(1).create()).withDescription("the learning rate").create();    Option noBias = builder.withLongName("noBias").withDescription("don't include a bias term").create();    Option targetCategories = builder.withLongName("categories").withRequired(true).withArgument(argumentBuilder.withName("number").withMaximum(1).create()).withDescription("the number of target categories to be considered").create();    Group normalArgs = new GroupBuilder().withOption(help).withOption(quiet).withOption(inputFile).withOption(outputFile).withOption(target).withOption(targetCategories).withOption(predictors).withOption(types).withOption(passes).withOption(lambda).withOption(rate).withOption(noBias).withOption(features).create();    Parser parser = new Parser();    parser.setHelpOption(help);    parser.setHelpTrigger("--help");    parser.setGroup(normalArgs);    parser.setHelpFormatter(new HelpFormatter(" ", "", " ", 130));    CommandLine cmdLine = parser.parseAndHelp(args);    if (cmdLine == null) {        return false;    }    TrainLogistic.inputFile = getStringArgument(cmdLine, inputFile);    TrainLogistic.outputFile = getStringArgument(cmdLine, outputFile);    List<String> typeList = new ArrayList<>();    for (Object x : cmdLine.getValues(types)) {        typeList.add(x.toString());    }    List<String> predictorList = new ArrayList<>();    for (Object x : cmdLine.getValues(predictors)) {        predictorList.add(x.toString());    }    lmp = new LogisticModelParameters();    lmp.setTargetVariable(getStringArgument(cmdLine, target));    lmp.setMaxTargetCategories(getIntegerArgument(cmdLine, targetCategories));    lmp.setNumFeatures(getIntegerArgument(cmdLine, features));    lmp.setUseBias(!getBooleanArgument(cmdLine, noBias));    lmp.setTypeMap(predictorList, typeList);    lmp.setLambda(getDoubleArgument(cmdLine, lambda));    lmp.setLearningRate(getDoubleArgument(cmdLine, rate));    TrainLogistic.scores = getBooleanArgument(cmdLine, scores);    TrainLogistic.passes = getIntegerArgument(cmdLine, passes);    return true;}
private static String mahout_f5628_0(CommandLine cmdLine, Option inputFile)
{    return (String) cmdLine.getValue(inputFile);}
private static boolean mahout_f5629_0(CommandLine cmdLine, Option option)
{    return cmdLine.hasOption(option);}
private static int mahout_f5630_0(CommandLine cmdLine, Option features)
{    return Integer.parseInt((String) cmdLine.getValue(features));}
private static double mahout_f5631_0(CommandLine cmdLine, Option op)
{    return Double.parseDouble((String) cmdLine.getValue(op));}
public static OnlineLogisticRegression mahout_f5632_0()
{    return model;}
public static LogisticModelParameters mahout_f5633_0()
{    return lmp;}
 static BufferedReader mahout_f5634_0(String inputFile) throws IOException
{    InputStream in;    try {        in = Resources.getResource(inputFile).openStream();    } catch (IllegalArgumentException e) {        in = new FileInputStream(new File(inputFile));    }    return new BufferedReader(new InputStreamReader(in, Charsets.UTF_8));}
public static void mahout_f5635_0(String[] args) throws IOException
{    File base = new File(args[0]);    Multiset<String> overallCounts = HashMultiset.create();    int leakType = 0;    if (args.length > 1) {        leakType = Integer.parseInt(args[1]);    }    Dictionary newsGroups = new Dictionary();    NewsgroupHelper helper = new NewsgroupHelper();    helper.getEncoder().setProbes(2);    AdaptiveLogisticRegression learningAlgorithm = new AdaptiveLogisticRegression(20, NewsgroupHelper.FEATURES, new L1());    learningAlgorithm.setInterval(800);    learningAlgorithm.setAveragingWindow(500);    List<File> files = new ArrayList<>();    for (File newsgroup : base.listFiles()) {        if (newsgroup.isDirectory()) {            newsGroups.intern(newsgroup.getName());            files.addAll(Arrays.asList(newsgroup.listFiles()));        }    }    Collections.shuffle(files);    System.out.println(files.size() + " training files");    SGDInfo info = new SGDInfo();    int k = 0;    for (File file : files) {        String ng = file.getParentFile().getName();        int actual = newsGroups.intern(ng);        Vector v = helper.encodeFeatureVector(file, actual, leakType, overallCounts);        learningAlgorithm.train(actual, v);        k++;        State<AdaptiveLogisticRegression.Wrapper, CrossFoldLearner> best = learningAlgorithm.getBest();        SGDHelper.analyzeState(info, leakType, k, best);    }    learningAlgorithm.close();    SGDHelper.dissect(leakType, newsGroups, learningAlgorithm, files, overallCounts);    System.out.println("exiting main");    File modelFile = new File(System.getProperty("java.io.tmpdir"), "news-group.model");    ModelSerializer.writeBinary(modelFile.getAbsolutePath(), learningAlgorithm.getBest().getPayload().getLearner().getModels().get(0));    List<Integer> counts = new ArrayList<>();    System.out.println("Word counts");    for (String count : overallCounts.elementSet()) {        counts.add(overallCounts.count(count));    }    Collections.sort(counts, Ordering.natural().reverse());    k = 0;    for (Integer count : counts) {        System.out.println(k + "\t" + count);        k++;        if (k > 1000) {            break;        }    }}
public static void mahout_f5636_0(String[] args) throws IOException
{    mainToOutput(args, new PrintWriter(new OutputStreamWriter(System.out, Charsets.UTF_8), true));}
 static void mahout_f5637_0(String[] args, PrintWriter output) throws IOException
{    if (parseArgs(args)) {        if (!showAuc && !showConfusion && !showScores) {            showAuc = true;            showConfusion = true;        }        Auc collector = null;        AdaptiveLogisticModelParameters lmp = AdaptiveLogisticModelParameters.loadFromFile(new File(modelFile));        CsvRecordFactory csv = lmp.getCsvRecordFactory();        AdaptiveLogisticRegression lr = lmp.createAdaptiveLogisticRegression();        if (lmp.getTargetCategories().size() <= 2) {            collector = new Auc();        }        OnlineSummarizer slh = new OnlineSummarizer();        ConfusionMatrix cm = new ConfusionMatrix(lmp.getTargetCategories(), defaultCategory);        State<Wrapper, CrossFoldLearner> best = lr.getBest();        if (best == null) {            output.println("AdaptiveLogisticRegression has not be trained probably.");            return;        }        CrossFoldLearner learner = best.getPayload().getLearner();        BufferedReader in = TrainLogistic.open(inputFile);        String line = in.readLine();        csv.firstLine(line);        line = in.readLine();        if (showScores) {            output.println("\"target\", \"model-output\", \"log-likelihood\", \"average-likelihood\"");        }        while (line != null) {            Vector v = new SequentialAccessSparseVector(lmp.getNumFeatures());                        int target = csv.processLine(line, v);            double likelihood = learner.logLikelihood(target, v);            double score = learner.classifyFull(v).maxValue();            slh.add(likelihood);            cm.addInstance(csv.getTargetString(line), csv.getTargetLabel(target));            if (showScores) {                output.printf(Locale.ENGLISH, "%8d, %.12f, %.13f, %.13f%n", target, score, learner.logLikelihood(target, v), slh.getMean());            }            if (collector != null) {                collector.add(target, score);            }            line = in.readLine();        }        output.printf(Locale.ENGLISH, "\nLog-likelihood:");        output.printf(Locale.ENGLISH, "Min=%.2f, Max=%.2f, Mean=%.2f, Median=%.2f%n", slh.getMin(), slh.getMax(), slh.getMean(), slh.getMedian());        if (collector != null) {            output.printf(Locale.ENGLISH, "%nAUC = %.2f%n", collector.auc());        }        if (showConfusion) {            output.printf(Locale.ENGLISH, "%n%s%n%n", cm.toString());            if (collector != null) {                Matrix m = collector.entropy();                output.printf(Locale.ENGLISH, "Entropy Matrix: [[%.1f, %.1f], [%.1f, %.1f]]%n", m.get(0, 0), m.get(1, 0), m.get(0, 1), m.get(1, 1));            }        }    }}
private static boolean mahout_f5638_0(String[] args)
{    DefaultOptionBuilder builder = new DefaultOptionBuilder();    Option help = builder.withLongName("help").withDescription("print this list").create();    Option quiet = builder.withLongName("quiet").withDescription("be extra quiet").create();    Option auc = builder.withLongName("auc").withDescription("print AUC").create();    Option confusion = builder.withLongName("confusion").withDescription("print confusion matrix").create();    Option scores = builder.withLongName("scores").withDescription("print scores").create();    ArgumentBuilder argumentBuilder = new ArgumentBuilder();    Option inputFileOption = builder.withLongName("input").withRequired(true).withArgument(argumentBuilder.withName("input").withMaximum(1).create()).withDescription("where to get validate data").create();    Option modelFileOption = builder.withLongName("model").withRequired(true).withArgument(argumentBuilder.withName("model").withMaximum(1).create()).withDescription("where to get the trained model").create();    Option defaultCagetoryOption = builder.withLongName("defaultCategory").withRequired(false).withArgument(argumentBuilder.withName("defaultCategory").withMaximum(1).withDefault("unknown").create()).withDescription("the default category value to use").create();    Group normalArgs = new GroupBuilder().withOption(help).withOption(quiet).withOption(auc).withOption(scores).withOption(confusion).withOption(inputFileOption).withOption(modelFileOption).withOption(defaultCagetoryOption).create();    Parser parser = new Parser();    parser.setHelpOption(help);    parser.setHelpTrigger("--help");    parser.setGroup(normalArgs);    parser.setHelpFormatter(new HelpFormatter(" ", "", " ", 130));    CommandLine cmdLine = parser.parseAndHelp(args);    if (cmdLine == null) {        return false;    }    inputFile = getStringArgument(cmdLine, inputFileOption);    modelFile = getStringArgument(cmdLine, modelFileOption);    defaultCategory = getStringArgument(cmdLine, defaultCagetoryOption);    showAuc = getBooleanArgument(cmdLine, auc);    showScores = getBooleanArgument(cmdLine, scores);    showConfusion = getBooleanArgument(cmdLine, confusion);    return true;}
private static boolean mahout_f5639_0(CommandLine cmdLine, Option option)
{    return cmdLine.hasOption(option);}
private static String mahout_f5640_0(CommandLine cmdLine, Option inputFile)
{    return (String) cmdLine.getValue(inputFile);}
public boolean mahout_f5641_0(Path path)
{    String pathString = path.toString();    return pathString.contains("/clusters-");}
public void mahout_f5642_0(Graphics g)
{    plotSampleData((Graphics2D) g);    plotClusters((Graphics2D) g);}
protected static void mahout_f5643_0(Graphics2D g2)
{    int cx = CLUSTERS.size() - 1;    for (List<Cluster> clusters : CLUSTERS) {        for (Cluster cluster : clusters) {            if (isSignificant(cluster)) {                g2.setStroke(new BasicStroke(1));                g2.setColor(Color.BLUE);                double[] t1 = { T1, T1 };                plotEllipse(g2, cluster.getCenter(), new DenseVector(t1));                double[] t2 = { T2, T2 };                plotEllipse(g2, cluster.getCenter(), new DenseVector(t2));                g2.setColor(COLORS[Math.min(DisplayClustering.COLORS.length - 1, cx)]);                g2.setStroke(new BasicStroke(cx == 0 ? 3 : 1));                plotEllipse(g2, cluster.getCenter(), cluster.getRadius().times(3));            }        }        cx--;    }}
public static void mahout_f5644_0(String[] args) throws Exception
{    Path samples = new Path("samples");    Path output = new Path("output");    Configuration conf = new Configuration();    HadoopUtil.delete(conf, samples);    HadoopUtil.delete(conf, output);    RandomUtils.useTestSeed();    generateSamples();    writeSampleData(samples);    CanopyDriver.buildClusters(conf, samples, output, new ManhattanDistanceMeasure(), T1, T2, 0, true);    loadClustersWritable(output);    new DisplayCanopy();}
public void mahout_f5645_0()
{        res = Toolkit.getDefaultToolkit().getScreenResolution();        this.setSize(SIZE * res, SIZE * res);    this.setVisible(true);    this.setTitle("Asymmetric Sample Data");        this.addWindowListener(new WindowAdapter() {        @Override        public void windowClosing(WindowEvent e) {            System.exit(0);        }    });}
public void mahout_f5646_0(WindowEvent e)
{    System.exit(0);}
public static void mahout_f5647_0(String[] args) throws Exception
{    RandomUtils.useTestSeed();    generateSamples();    new DisplayClustering();}
public void mahout_f5648_0(Graphics g)
{    Graphics2D g2 = (Graphics2D) g;    plotSampleData(g2);    plotSampleParameters(g2);    plotClusters(g2);}
protected static void mahout_f5649_0(Graphics2D g2)
{    int cx = CLUSTERS.size() - 1;    for (List<Cluster> clusters : CLUSTERS) {        g2.setStroke(new BasicStroke(cx == 0 ? 3 : 1));        g2.setColor(COLORS[Math.min(COLORS.length - 1, cx--)]);        for (Cluster cluster : clusters) {            plotEllipse(g2, cluster.getCenter(), cluster.getRadius().times(3));        }    }}
protected static void mahout_f5650_0(Graphics2D g2)
{    Vector v = new DenseVector(2);    Vector dv = new DenseVector(2);    g2.setColor(Color.RED);    for (Vector param : SAMPLE_PARAMS) {        v.set(0, param.get(0));        v.set(1, param.get(1));        dv.set(0, param.get(2) * 3);        dv.set(1, param.get(3) * 3);        plotEllipse(g2, v, dv);    }}
protected static void mahout_f5651_0(Graphics2D g2)
{    double sx = (double) res / DS;    g2.setTransform(AffineTransform.getScaleInstance(sx, sx));        g2.setColor(Color.BLACK);    Vector dv = new DenseVector(2).assign(SIZE / 2.0);    plotRectangle(g2, new DenseVector(2).assign(2), dv);    plotRectangle(g2, new DenseVector(2).assign(-2), dv);        g2.setColor(Color.DARK_GRAY);    dv.assign(0.03);    for (VectorWritable v : SAMPLE_DATA) {        plotRectangle(g2, v.get(), dv);    }}
protected static void mahout_f5652_0(Graphics2D g2, Path data)
{    double sx = (double) res / DS;    g2.setTransform(AffineTransform.getScaleInstance(sx, sx));    g2.setColor(Color.BLACK);    Vector dv = new DenseVector(2).assign(SIZE / 2.0);    plotRectangle(g2, new DenseVector(2).assign(2), dv);    plotRectangle(g2, new DenseVector(2).assign(-2), dv);        dv.assign(0.03);    Path clusteredPointsPath = new Path(data, "clusteredPoints");    Path inputPath = new Path(clusteredPointsPath, "part-m-00000");    Map<Integer, Color> colors = new HashMap<>();    int point = 0;    for (Pair<IntWritable, WeightedVectorWritable> record : new SequenceFileIterable<IntWritable, WeightedVectorWritable>(inputPath, new Configuration())) {        int clusterId = record.getFirst().get();        VectorWritable v = SAMPLE_DATA.get(point++);        Integer key = clusterId;        if (!colors.containsKey(key)) {            colors.put(key, COLORS[Math.min(COLORS.length - 1, colors.size())]);        }        plotClusteredRectangle(g2, v.get(), dv, colors.get(key));    }}
protected static void mahout_f5653_0(Graphics2D g2, Vector v, Vector dv, Color color)
{    double[] flip = { 1, -1 };    Vector v2 = v.times(new DenseVector(flip));    v2 = v2.minus(dv.divide(2));    int h = SIZE / 2;    double x = v2.get(0) + h;    double y = v2.get(1) + h;    g2.setStroke(new BasicStroke(1));    g2.setColor(color);    g2.draw(new Rectangle2D.Double(x * DS, y * DS, dv.get(0) * DS, dv.get(1) * DS));}
protected static void mahout_f5654_0(Graphics2D g2, Vector v, Vector dv)
{    double[] flip = { 1, -1 };    Vector v2 = v.times(new DenseVector(flip));    v2 = v2.minus(dv.divide(2));    int h = SIZE / 2;    double x = v2.get(0) + h;    double y = v2.get(1) + h;    g2.draw(new Rectangle2D.Double(x * DS, y * DS, dv.get(0) * DS, dv.get(1) * DS));}
protected static void mahout_f5655_0(Graphics2D g2, Vector v, Vector dv)
{    double[] flip = { 1, -1 };    Vector v2 = v.times(new DenseVector(flip));    v2 = v2.minus(dv.divide(2));    int h = SIZE / 2;    double x = v2.get(0) + h;    double y = v2.get(1) + h;    g2.draw(new Ellipse2D.Double(x * DS, y * DS, dv.get(0) * DS, dv.get(1) * DS));}
protected static void mahout_f5656_0()
{    generateSamples(500, 1, 1, 3);    generateSamples(300, 1, 0, 0.5);    generateSamples(300, 0, 2, 0.1);}
protected static void mahout_f5657_0()
{    generate2dSamples(500, 1, 1, 3, 1);    generate2dSamples(300, 1, 0, 0.5, 1);    generate2dSamples(300, 0, 2, 0.1, 0.5);}
protected static void mahout_f5658_1(int num, double mx, double my, double sd)
{    double[] params = { mx, my, sd, sd };    SAMPLE_PARAMS.add(new DenseVector(params));        for (int i = 0; i < num; i++) {        SAMPLE_DATA.add(new VectorWritable(new DenseVector(new double[] { UncommonDistributions.rNorm(mx, sd), UncommonDistributions.rNorm(my, sd) })));    }}
protected static void mahout_f5659_0(Path output) throws IOException
{    Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(output.toUri(), conf);    try (SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, output, Text.class, VectorWritable.class)) {        int i = 0;        for (VectorWritable vw : SAMPLE_DATA) {            writer.append(new Text("sample_" + i++), vw);        }    }}
protected static List<Cluster> mahout_f5660_1(Path clustersIn)
{    List<Cluster> clusters = new ArrayList<>();    Configuration conf = new Configuration();    for (ClusterWritable value : new SequenceFileDirValueIterable<ClusterWritable>(clustersIn, PathType.LIST, PathFilters.logsCRCFilter(), conf)) {        Cluster cluster = value.getValue();                clusters.add(cluster);    }    return clusters;}
protected static void mahout_f5661_0(Path output) throws IOException
{    Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(output.toUri(), conf);    for (FileStatus s : fs.listStatus(output, new ClustersFilter())) {        List<Cluster> clusters = readClustersWritable(s.getPath());        CLUSTERS.add(clusters);    }}
protected static void mahout_f5662_1(int num, double mx, double my, double sdx, double sdy)
{    double[] params = { mx, my, sdx, sdy };    SAMPLE_PARAMS.add(new DenseVector(params));        for (int i = 0; i < num; i++) {        SAMPLE_DATA.add(new VectorWritable(new DenseVector(new double[] { UncommonDistributions.rNorm(mx, sdx), UncommonDistributions.rNorm(my, sdy) })));    }}
protected static boolean mahout_f5663_0(Cluster cluster)
{    return (double) cluster.getNumObservations() / SAMPLE_DATA.size() > significance;}
public void mahout_f5664_0(Graphics g)
{    plotSampleData((Graphics2D) g);    plotClusters((Graphics2D) g);}
public static void mahout_f5665_0(String[] args) throws Exception
{    DistanceMeasure measure = new ManhattanDistanceMeasure();    Path samples = new Path("samples");    Path output = new Path("output");    Configuration conf = new Configuration();    HadoopUtil.delete(conf, output);    HadoopUtil.delete(conf, samples);    RandomUtils.useTestSeed();    DisplayClustering.generateSamples();    writeSampleData(samples);    boolean runClusterer = true;    int maxIterations = 10;    float threshold = 0.001F;    float m = 1.1F;    if (runClusterer) {        runSequentialFuzzyKClusterer(conf, samples, output, measure, maxIterations, m, threshold);    } else {        int numClusters = 3;        runSequentialFuzzyKClassifier(conf, samples, output, measure, numClusters, maxIterations, m, threshold);    }    new DisplayFuzzyKMeans();}
private static void mahout_f5666_0(Configuration conf, Path samples, Path output, DistanceMeasure measure, int numClusters, int maxIterations, float m, double threshold) throws IOException
{    Collection<Vector> points = Lists.newArrayList();    for (int i = 0; i < numClusters; i++) {        points.add(SAMPLE_DATA.get(i).get());    }    List<Cluster> initialClusters = Lists.newArrayList();    int id = 0;    for (Vector point : points) {        initialClusters.add(new SoftCluster(point, id++, measure));    }    ClusterClassifier prior = new ClusterClassifier(initialClusters, new FuzzyKMeansClusteringPolicy(m, threshold));    Path priorPath = new Path(output, "classifier-0");    prior.writeToSeqFiles(priorPath);    ClusterIterator.iterateSeq(conf, samples, priorPath, output, maxIterations);    loadClustersWritable(output);}
private static void mahout_f5667_0(Configuration conf, Path samples, Path output, DistanceMeasure measure, int maxIterations, float m, double threshold) throws IOException, ClassNotFoundException, InterruptedException
{    Path clustersIn = new Path(output, "random-seeds");    RandomSeedGenerator.buildRandom(conf, samples, clustersIn, 3, measure);    FuzzyKMeansDriver.run(samples, clustersIn, output, threshold, maxIterations, m, true, true, threshold, true);    loadClustersWritable(output);}
public static void mahout_f5668_0(String[] args) throws Exception
{    DistanceMeasure measure = new ManhattanDistanceMeasure();    Path samples = new Path("samples");    Path output = new Path("output");    Configuration conf = new Configuration();    HadoopUtil.delete(conf, samples);    HadoopUtil.delete(conf, output);    RandomUtils.useTestSeed();    generateSamples();    writeSampleData(samples);    boolean runClusterer = true;    double convergenceDelta = 0.001;    int numClusters = 3;    int maxIterations = 10;    if (runClusterer) {        runSequentialKMeansClusterer(conf, samples, output, measure, numClusters, maxIterations, convergenceDelta);    } else {        runSequentialKMeansClassifier(conf, samples, output, measure, numClusters, maxIterations, convergenceDelta);    }    new DisplayKMeans();}
private static void mahout_f5669_0(Configuration conf, Path samples, Path output, DistanceMeasure measure, int numClusters, int maxIterations, double convergenceDelta) throws IOException
{    Collection<Vector> points = Lists.newArrayList();    for (int i = 0; i < numClusters; i++) {        points.add(SAMPLE_DATA.get(i).get());    }    List<Cluster> initialClusters = Lists.newArrayList();    int id = 0;    for (Vector point : points) {        initialClusters.add(new org.apache.mahout.clustering.kmeans.Kluster(point, id++, measure));    }    ClusterClassifier prior = new ClusterClassifier(initialClusters, new KMeansClusteringPolicy(convergenceDelta));    Path priorPath = new Path(output, Cluster.INITIAL_CLUSTERS_DIR);    prior.writeToSeqFiles(priorPath);    ClusterIterator.iterateSeq(conf, samples, priorPath, output, maxIterations);    loadClustersWritable(output);}
private static void mahout_f5670_0(Configuration conf, Path samples, Path output, DistanceMeasure measure, int numClusters, int maxIterations, double convergenceDelta) throws IOException, InterruptedException, ClassNotFoundException
{    Path clustersIn = new Path(output, "random-seeds");    RandomSeedGenerator.buildRandom(conf, samples, clustersIn, numClusters, measure);    KMeansDriver.run(samples, clustersIn, output, convergenceDelta, maxIterations, true, 0.0, true);    loadClustersWritable(output);}
public void mahout_f5671_0(Graphics g)
{    plotSampleData((Graphics2D) g);    plotClusters((Graphics2D) g);}
public static void mahout_f5672_0(String[] args) throws Exception
{    DistanceMeasure measure = new ManhattanDistanceMeasure();    Path samples = new Path(SAMPLES);    Path output = new Path(OUTPUT);    Path tempDir = new Path(TEMP);    Configuration conf = new Configuration();    HadoopUtil.delete(conf, samples);    HadoopUtil.delete(conf, output);    RandomUtils.useTestSeed();    DisplayClustering.generateSamples();    writeSampleData(samples);    Path affinities = new Path(output, AFFINITIES);    FileSystem fs = FileSystem.get(output.toUri(), conf);    if (!fs.exists(output)) {        fs.mkdirs(output);    }    try (Writer writer = new BufferedWriter(new FileWriter(affinities.toString()))) {        for (int i = 0; i < SAMPLE_DATA.size(); i++) {            for (int j = 0; j < SAMPLE_DATA.size(); j++) {                writer.write(i + "," + j + ',' + measure.distance(SAMPLE_DATA.get(i).get(), SAMPLE_DATA.get(j).get()) + '\n');            }        }    }    int maxIter = 10;    double convergenceDelta = 0.001;    SpectralKMeansDriver.run(new Configuration(), affinities, output, SAMPLE_DATA.size(), 3, measure, convergenceDelta, maxIter, tempDir);    new DisplaySpectralKMeans();}
public void mahout_f5673_0(Graphics g)
{    plotClusteredSampleData((Graphics2D) g, new Path(new Path(OUTPUT), "kmeans_out"));}
public void mahout_f5674_0(List<OnlineSummarizer> summarizers, String type)
{    printSummaries(summarizers, type, fileOut);}
public static void mahout_f5675_0(List<OnlineSummarizer> summarizers, String type, PrintWriter fileOut)
{    double maxDistance = 0;    for (int i = 0; i < summarizers.size(); ++i) {        OnlineSummarizer summarizer = summarizers.get(i);        if (summarizer.getCount() > 1) {            maxDistance = Math.max(maxDistance, summarizer.getMax());            System.out.printf("Average distance in cluster %d [%d]: %f\n", i, summarizer.getCount(), summarizer.getMean());                        if (fileOut != null) {                fileOut.printf("%d,%f,%f,%f,%f,%f,%f,%f,%d,%s\n", i, summarizer.getMean(), summarizer.getSD(), summarizer.getQuartile(0), summarizer.getQuartile(1), summarizer.getQuartile(2), summarizer.getQuartile(3), summarizer.getQuartile(4), summarizer.getCount(), type);            }        } else {            System.out.printf("Cluster %d is has %d data point. Need atleast 2 data points in a cluster for" + " OnlineSummarizer.\n", i, summarizer.getCount());        }    }    System.out.printf("Num clusters: %d; maxDistance: %f\n", summarizers.size(), maxDistance);}
public int mahout_f5676_0(String[] args) throws IOException
{    if (!parseArgs(args)) {        return -1;    }    Configuration conf = new Configuration();    try {        fileOut = new PrintWriter(new FileOutputStream(outputFile));        fileOut.printf("cluster,distance.mean,distance.sd,distance.q0,distance.q1,distance.q2,distance.q3," + "distance.q4,count,is.train\n");                List<Centroid> centroids;        List<Centroid> centroidsCompare = null;        if (mahoutKMeansFormat) {            SequenceFileDirValueIterable<ClusterWritable> clusterIterable = new SequenceFileDirValueIterable<>(new Path(centroidFile), PathType.GLOB, conf);            centroids = Lists.newArrayList(IOUtils.getCentroidsFromClusterWritableIterable(clusterIterable));        } else {            SequenceFileDirValueIterable<CentroidWritable> centroidIterable = new SequenceFileDirValueIterable<>(new Path(centroidFile), PathType.GLOB, conf);            centroids = Lists.newArrayList(IOUtils.getCentroidsFromCentroidWritableIterable(centroidIterable));        }        if (centroidCompareFile != null) {            if (mahoutKMeansFormatCompare) {                SequenceFileDirValueIterable<ClusterWritable> clusterCompareIterable = new SequenceFileDirValueIterable<>(new Path(centroidCompareFile), PathType.GLOB, conf);                centroidsCompare = Lists.newArrayList(IOUtils.getCentroidsFromClusterWritableIterable(clusterCompareIterable));            } else {                SequenceFileDirValueIterable<CentroidWritable> centroidCompareIterable = new SequenceFileDirValueIterable<>(new Path(centroidCompareFile), PathType.GLOB, conf);                centroidsCompare = Lists.newArrayList(IOUtils.getCentroidsFromCentroidWritableIterable(centroidCompareIterable));            }        }                SequenceFileDirValueIterable<VectorWritable> trainIterable = new SequenceFileDirValueIterable<>(new Path(trainFile), PathType.GLOB, conf);        Iterable<Vector> trainDatapoints = IOUtils.getVectorsFromVectorWritableIterable(trainIterable);        Iterable<Vector> datapoints = trainDatapoints;        printSummaries(ClusteringUtils.summarizeClusterDistances(trainDatapoints, centroids, new SquaredEuclideanDistanceMeasure()), "train");                if (testFile != null) {            SequenceFileDirValueIterable<VectorWritable> testIterable = new SequenceFileDirValueIterable<>(new Path(testFile), PathType.GLOB, conf);            Iterable<Vector> testDatapoints = IOUtils.getVectorsFromVectorWritableIterable(testIterable);            printSummaries(ClusteringUtils.summarizeClusterDistances(testDatapoints, centroids, new SquaredEuclideanDistanceMeasure()), "test");            datapoints = Iterables.concat(trainDatapoints, testDatapoints);        }                List<OnlineSummarizer> summaries = ClusteringUtils.summarizeClusterDistances(datapoints, centroids, distanceMeasure);        List<OnlineSummarizer> compareSummaries = null;        if (centroidsCompare != null) {            compareSummaries = ClusteringUtils.summarizeClusterDistances(datapoints, centroidsCompare, distanceMeasure);        }        System.out.printf("[Dunn Index] First: %f", ClusteringUtils.dunnIndex(centroids, distanceMeasure, summaries));        if (compareSummaries != null) {            System.out.printf(" Second: %f\n", ClusteringUtils.dunnIndex(centroidsCompare, distanceMeasure, compareSummaries));        } else {            System.out.printf("\n");        }        System.out.printf("[Davies-Bouldin Index] First: %f", ClusteringUtils.daviesBouldinIndex(centroids, distanceMeasure, summaries));        if (compareSummaries != null) {            System.out.printf(" Second: %f\n", ClusteringUtils.daviesBouldinIndex(centroidsCompare, distanceMeasure, compareSummaries));        } else {            System.out.printf("\n");        }    } catch (IOException e) {        System.out.println(e.getMessage());    } finally {        Closeables.close(fileOut, false);    }    return 0;}
private boolean mahout_f5677_0(String[] args)
{    DefaultOptionBuilder builder = new DefaultOptionBuilder();    Option help = builder.withLongName("help").withDescription("print this list").create();    ArgumentBuilder argumentBuilder = new ArgumentBuilder();    Option inputFileOption = builder.withLongName("input").withShortName("i").withRequired(true).withArgument(argumentBuilder.withName("input").withMaximum(1).create()).withDescription("where to get seq files with the vectors (training set)").create();    Option testInputFileOption = builder.withLongName("testInput").withShortName("itest").withArgument(argumentBuilder.withName("testInput").withMaximum(1).create()).withDescription("where to get seq files with the vectors (test set)").create();    Option centroidsFileOption = builder.withLongName("centroids").withShortName("c").withRequired(true).withArgument(argumentBuilder.withName("centroids").withMaximum(1).create()).withDescription("where to get seq files with the centroids (from Mahout KMeans or StreamingKMeansDriver)").create();    Option centroidsCompareFileOption = builder.withLongName("centroidsCompare").withShortName("cc").withRequired(false).withArgument(argumentBuilder.withName("centroidsCompare").withMaximum(1).create()).withDescription("where to get seq files with the second set of centroids (from Mahout KMeans or " + "StreamingKMeansDriver)").create();    Option outputFileOption = builder.withLongName("output").withShortName("o").withRequired(true).withArgument(argumentBuilder.withName("output").withMaximum(1).create()).withDescription("where to dump the CSV file with the results").create();    Option mahoutKMeansFormatOption = builder.withLongName("mahoutkmeansformat").withShortName("mkm").withDescription("if set, read files as (IntWritable, ClusterWritable) pairs").withArgument(argumentBuilder.withName("numpoints").withMaximum(1).create()).create();    Option mahoutKMeansCompareFormatOption = builder.withLongName("mahoutkmeansformatCompare").withShortName("mkmc").withDescription("if set, read files as (IntWritable, ClusterWritable) pairs").withArgument(argumentBuilder.withName("numpoints").withMaximum(1).create()).create();    Group normalArgs = new GroupBuilder().withOption(help).withOption(inputFileOption).withOption(testInputFileOption).withOption(outputFileOption).withOption(centroidsFileOption).withOption(centroidsCompareFileOption).withOption(mahoutKMeansFormatOption).withOption(mahoutKMeansCompareFormatOption).create();    Parser parser = new Parser();    parser.setHelpOption(help);    parser.setHelpTrigger("--help");    parser.setGroup(normalArgs);    parser.setHelpFormatter(new HelpFormatter(" ", "", " ", 150));    CommandLine cmdLine = parser.parseAndHelp(args);    if (cmdLine == null) {        return false;    }    trainFile = (String) cmdLine.getValue(inputFileOption);    if (cmdLine.hasOption(testInputFileOption)) {        testFile = (String) cmdLine.getValue(testInputFileOption);    }    centroidFile = (String) cmdLine.getValue(centroidsFileOption);    if (cmdLine.hasOption(centroidsCompareFileOption)) {        centroidCompareFile = (String) cmdLine.getValue(centroidsCompareFileOption);    }    outputFile = (String) cmdLine.getValue(outputFileOption);    if (cmdLine.hasOption(mahoutKMeansFormatOption)) {        mahoutKMeansFormat = true;    }    if (cmdLine.hasOption(mahoutKMeansCompareFormatOption)) {        mahoutKMeansFormatCompare = true;    }    return true;}
public static void mahout_f5678_0(String[] args) throws IOException
{    new ClusterQualitySummarizer().run(args);}
public static Iterable<Centroid> mahout_f5679_0(Iterable<CentroidWritable> dirIterable)
{    return Iterables.transform(dirIterable, new Function<CentroidWritable, Centroid>() {        @Override        public Centroid apply(CentroidWritable input) {            Preconditions.checkNotNull(input);            return input.getCentroid().clone();        }    });}
public Centroid mahout_f5680_0(CentroidWritable input)
{    Preconditions.checkNotNull(input);    return input.getCentroid().clone();}
public static Iterable<Centroid> mahout_f5681_0(Iterable<ClusterWritable> dirIterable)
{    return Iterables.transform(dirIterable, new Function<ClusterWritable, Centroid>() {        int numClusters = 0;        @Override        public Centroid apply(ClusterWritable input) {            Preconditions.checkNotNull(input);            return new Centroid(numClusters++, input.getValue().getCenter().clone(), input.getValue().getTotalObservations());        }    });}
public Centroid mahout_f5682_0(ClusterWritable input)
{    Preconditions.checkNotNull(input);    return new Centroid(numClusters++, input.getValue().getCenter().clone(), input.getValue().getTotalObservations());}
public static Iterable<Vector> mahout_f5683_0(Iterable<VectorWritable> dirIterable)
{    return Iterables.transform(dirIterable, new Function<VectorWritable, Vector>() {        @Override        public Vector apply(VectorWritable input) {            Preconditions.checkNotNull(input);            return input.get().clone();        }    });}
public Vector mahout_f5684_0(VectorWritable input)
{    Preconditions.checkNotNull(input);    return input.get().clone();}
public static void mahout_f5685_1(String[] args) throws Exception
{    if (args.length > 0) {                ToolRunner.run(new Configuration(), new Job(), args);    } else {                Path output = new Path("output");        HadoopUtil.delete(new Configuration(), output);        run(new Path("testdata"), output, new EuclideanDistanceMeasure(), 80, 55);    }}
private static void mahout_f5686_0(Path input, Path output, DistanceMeasure measure, double t1, double t2) throws Exception
{    Path directoryContainingConvertedInput = new Path(output, DIRECTORY_CONTAINING_CONVERTED_INPUT);    InputDriver.runJob(input, directoryContainingConvertedInput, "org.apache.mahout.math.RandomAccessSparseVector");    CanopyDriver.run(new Configuration(), directoryContainingConvertedInput, output, measure, t1, t2, true, 0.0, false);        ClusterDumper clusterDumper = new ClusterDumper(new Path(output, "clusters-0-final"), new Path(output, "clusteredPoints"));    clusterDumper.printClusters(null);}
public int mahout_f5687_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption(DefaultOptionCreator.distanceMeasureOption().create());    addOption(DefaultOptionCreator.t1Option().create());    addOption(DefaultOptionCreator.t2Option().create());    addOption(DefaultOptionCreator.overwriteOption().create());    Map<String, List<String>> argMap = parseArguments(args);    if (argMap == null) {        return -1;    }    Path input = getInputPath();    Path output = getOutputPath();    if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {        HadoopUtil.delete(new Configuration(), output);    }    String measureClass = getOption(DefaultOptionCreator.DISTANCE_MEASURE_OPTION);    double t1 = Double.parseDouble(getOption(DefaultOptionCreator.T1_OPTION));    double t2 = Double.parseDouble(getOption(DefaultOptionCreator.T2_OPTION));    DistanceMeasure measure = ClassUtils.instantiateAs(measureClass, DistanceMeasure.class);    run(input, output, measure, t1, t2);    return 0;}
public static void mahout_f5688_1(String[] args) throws Exception
{    if (args.length > 0) {                ToolRunner.run(new Configuration(), new Job(), args);    } else {                Path output = new Path("output");        Configuration conf = new Configuration();        HadoopUtil.delete(conf, output);        run(conf, new Path("testdata"), output, new EuclideanDistanceMeasure(), 80, 55, 10, 2.0f, 0.5);    }}
public int mahout_f5689_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption(DefaultOptionCreator.distanceMeasureOption().create());    addOption(DefaultOptionCreator.convergenceOption().create());    addOption(DefaultOptionCreator.maxIterationsOption().create());    addOption(DefaultOptionCreator.overwriteOption().create());    addOption(DefaultOptionCreator.t1Option().create());    addOption(DefaultOptionCreator.t2Option().create());    addOption(M_OPTION, M_OPTION, "coefficient normalization factor, must be greater than 1", true);    Map<String, List<String>> argMap = parseArguments(args);    if (argMap == null) {        return -1;    }    Path input = getInputPath();    Path output = getOutputPath();    String measureClass = getOption(DefaultOptionCreator.DISTANCE_MEASURE_OPTION);    if (measureClass == null) {        measureClass = SquaredEuclideanDistanceMeasure.class.getName();    }    double convergenceDelta = Double.parseDouble(getOption(DefaultOptionCreator.CONVERGENCE_DELTA_OPTION));    int maxIterations = Integer.parseInt(getOption(DefaultOptionCreator.MAX_ITERATIONS_OPTION));    float fuzziness = Float.parseFloat(getOption(M_OPTION));    addOption(new DefaultOptionBuilder().withLongName(M_OPTION).withRequired(true).withArgument(new ArgumentBuilder().withName(M_OPTION).withMinimum(1).withMaximum(1).create()).withDescription("coefficient normalization factor, must be greater than 1").withShortName(M_OPTION).create());    if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {        HadoopUtil.delete(getConf(), output);    }    DistanceMeasure measure = ClassUtils.instantiateAs(measureClass, DistanceMeasure.class);    double t1 = Double.parseDouble(getOption(DefaultOptionCreator.T1_OPTION));    double t2 = Double.parseDouble(getOption(DefaultOptionCreator.T2_OPTION));    run(getConf(), input, output, measure, t1, t2, maxIterations, fuzziness, convergenceDelta);    return 0;}
public static void mahout_f5690_1(Configuration conf, Path input, Path output, DistanceMeasure measure, double t1, double t2, int maxIterations, float fuzziness, double convergenceDelta) throws Exception
{    Path directoryContainingConvertedInput = new Path(output, DIRECTORY_CONTAINING_CONVERTED_INPUT);        InputDriver.runJob(input, directoryContainingConvertedInput, "org.apache.mahout.math.RandomAccessSparseVector");        Path canopyOutput = new Path(output, "canopies");    CanopyDriver.run(new Configuration(), directoryContainingConvertedInput, canopyOutput, measure, t1, t2, false, 0.0, false);        FuzzyKMeansDriver.run(directoryContainingConvertedInput, new Path(canopyOutput, "clusters-0-final"), output, convergenceDelta, maxIterations, fuzziness, true, true, 0.0, false);        ClusterDumper clusterDumper = new ClusterDumper(new Path(output, "clusters-*-final"), new Path(output, "clusteredPoints"));    clusterDumper.printClusters(null);}
public static void mahout_f5691_1(String[] args) throws Exception
{    if (args.length > 0) {                ToolRunner.run(new Configuration(), new Job(), args);    } else {                Path output = new Path("output");        Configuration conf = new Configuration();        HadoopUtil.delete(conf, output);        run(conf, new Path("testdata"), output, new EuclideanDistanceMeasure(), 6, 0.5, 10);    }}
public int mahout_f5692_0(String[] args) throws Exception
{    addInputOption();    addOutputOption();    addOption(DefaultOptionCreator.distanceMeasureOption().create());    addOption(DefaultOptionCreator.numClustersOption().create());    addOption(DefaultOptionCreator.t1Option().create());    addOption(DefaultOptionCreator.t2Option().create());    addOption(DefaultOptionCreator.convergenceOption().create());    addOption(DefaultOptionCreator.maxIterationsOption().create());    addOption(DefaultOptionCreator.overwriteOption().create());    Map<String, List<String>> argMap = parseArguments(args);    if (argMap == null) {        return -1;    }    Path input = getInputPath();    Path output = getOutputPath();    String measureClass = getOption(DefaultOptionCreator.DISTANCE_MEASURE_OPTION);    if (measureClass == null) {        measureClass = SquaredEuclideanDistanceMeasure.class.getName();    }    double convergenceDelta = Double.parseDouble(getOption(DefaultOptionCreator.CONVERGENCE_DELTA_OPTION));    int maxIterations = Integer.parseInt(getOption(DefaultOptionCreator.MAX_ITERATIONS_OPTION));    if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {        HadoopUtil.delete(getConf(), output);    }    DistanceMeasure measure = ClassUtils.instantiateAs(measureClass, DistanceMeasure.class);    if (hasOption(DefaultOptionCreator.NUM_CLUSTERS_OPTION)) {        int k = Integer.parseInt(getOption(DefaultOptionCreator.NUM_CLUSTERS_OPTION));        run(getConf(), input, output, measure, k, convergenceDelta, maxIterations);    } else {        double t1 = Double.parseDouble(getOption(DefaultOptionCreator.T1_OPTION));        double t2 = Double.parseDouble(getOption(DefaultOptionCreator.T2_OPTION));        run(getConf(), input, output, measure, t1, t2, convergenceDelta, maxIterations);    }    return 0;}
public static void mahout_f5693_1(Configuration conf, Path input, Path output, DistanceMeasure measure, int k, double convergenceDelta, int maxIterations) throws Exception
{    Path directoryContainingConvertedInput = new Path(output, DIRECTORY_CONTAINING_CONVERTED_INPUT);        InputDriver.runJob(input, directoryContainingConvertedInput, "org.apache.mahout.math.RandomAccessSparseVector");        Path clusters = new Path(output, "random-seeds");    clusters = RandomSeedGenerator.buildRandom(conf, directoryContainingConvertedInput, clusters, k, measure);        KMeansDriver.run(conf, directoryContainingConvertedInput, clusters, output, convergenceDelta, maxIterations, true, 0.0, false);        Path outGlob = new Path(output, "clusters-*-final");    Path clusteredPoints = new Path(output, "clusteredPoints");        ClusterDumper clusterDumper = new ClusterDumper(outGlob, clusteredPoints);    clusterDumper.printClusters(null);}
public static void mahout_f5694_1(Configuration conf, Path input, Path output, DistanceMeasure measure, double t1, double t2, double convergenceDelta, int maxIterations) throws Exception
{    Path directoryContainingConvertedInput = new Path(output, DIRECTORY_CONTAINING_CONVERTED_INPUT);        InputDriver.runJob(input, directoryContainingConvertedInput, "org.apache.mahout.math.RandomAccessSparseVector");        Path canopyOutput = new Path(output, "canopies");    CanopyDriver.run(new Configuration(), directoryContainingConvertedInput, canopyOutput, measure, t1, t2, false, 0.0, false);        KMeansDriver.run(conf, directoryContainingConvertedInput, new Path(canopyOutput, Cluster.INITIAL_CLUSTERS_DIR + "-final"), output, convergenceDelta, maxIterations, true, 0.0, false);        ClusterDumper clusterDumper = new ClusterDumper(new Path(output, "clusters-*-final"), new Path(output, "clusteredPoints"));    clusterDumper.printClusters(null);}
protected void mahout_f5695_0(Text key, Iterable<StringTuple> values, Context context) throws IOException, InterruptedException
{    Set<String> outputValues = new HashSet<>();    for (StringTuple value : values) {        outputValues.addAll(value.getEntries());    }    context.write(key, new StringTuple(outputValues));}
public static void mahout_f5696_0(Parameters params) throws IOException, InterruptedException, ClassNotFoundException
{    Configuration conf = new Configuration();    conf.set("job.parameters", params.toString());    conf.set("mapred.compress.map.output", "true");    conf.set("mapred.output.compression.type", "BLOCK");    conf.set("mapred.map.output.compression.codec", "org.apache.hadoop.io.compress.GzipCodec");    conf.set("io.serializations", "org.apache.hadoop.io.serializer.JavaSerialization," + "org.apache.hadoop.io.serializer.WritableSerialization");    String input = params.get("input");    Job job = new Job(conf, "Generating dataset based from input" + input);    job.setJarByClass(KeyBasedStringTupleGrouper.class);    job.setMapOutputKeyClass(Text.class);    job.setMapOutputValueClass(StringTuple.class);    job.setOutputKeyClass(Text.class);    job.setOutputValueClass(Text.class);    FileInputFormat.addInputPath(job, new Path(input));    Path outPath = new Path(params.get("output"));    FileOutputFormat.setOutputPath(job, outPath);    HadoopUtil.delete(conf, outPath);    job.setInputFormatClass(TextInputFormat.class);    job.setMapperClass(KeyBasedStringTupleMapper.class);    job.setCombinerClass(KeyBasedStringTupleCombiner.class);    job.setReducerClass(KeyBasedStringTupleReducer.class);    job.setOutputFormatClass(TextOutputFormat.class);    boolean succeeded = job.waitForCompletion(true);    if (!succeeded) {        throw new IllegalStateException("Job failed!");    }}
protected void mahout_f5697_1(LongWritable key, Text value, Context context) throws IOException, InterruptedException
{    String[] fields = splitter.split(value.toString());    if (fields.length != 4) {                context.getCounter("Map", "ERROR").increment(1);        return;    }    Collection<String> oKey = new ArrayList<>();    for (int groupingField : groupingFields) {        oKey.add(fields[groupingField]);        context.setStatus(fields[groupingField]);    }    List<String> oValue = new ArrayList<>();    for (int selectedField : selectedFields) {        oValue.add(fields[selectedField]);    }    context.write(new Text(oKey.toString()), new StringTuple(oValue));}
protected void mahout_f5698_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    Parameters params = new Parameters(context.getConfiguration().get("job.parameters", ""));    splitter = Pattern.compile(params.get("splitPattern", "[ \t]*\t[ \t]*"));    int selectedFieldCount = Integer.valueOf(params.get("selectedFieldCount", "0"));    selectedFields = new int[selectedFieldCount];    for (int i = 0; i < selectedFieldCount; i++) {        selectedFields[i] = Integer.valueOf(params.get("field" + i, "0"));    }    int groupingFieldCount = Integer.valueOf(params.get("groupingFieldCount", "0"));    groupingFields = new int[groupingFieldCount];    for (int i = 0; i < groupingFieldCount; i++) {        groupingFields[i] = Integer.valueOf(params.get("gfield" + i, "0"));    }}
protected void mahout_f5699_0(Text key, Iterable<StringTuple> values, Context context) throws IOException, InterruptedException
{    Collection<String> items = new HashSet<>();    for (StringTuple value : values) {        for (String field : value.getEntries()) {            items.add(field);        }    }    if (items.size() > 1) {        int i = 0;        StringBuilder sb = new StringBuilder();        String sep = "";        for (String field : items) {            if (i % maxTransactionLength == 0) {                if (i != 0) {                    context.write(null, new Text(sb.toString()));                }                sb.replace(0, sb.length(), "");                sep = "";            }            sb.append(sep).append(field);            sep = "\t";            i++;        }        if (sb.length() > 0) {            context.write(null, new Text(sb.toString()));        }    }}
protected void mahout_f5700_0(Context context) throws IOException, InterruptedException
{    super.setup(context);    Parameters params = new Parameters(context.getConfiguration().get("job.parameters", ""));    maxTransactionLength = Integer.valueOf(params.get("maxTransactionLength", "100"));}
public static void mahout_f5701_0(String[] args) throws IOException, InterruptedException, ClassNotFoundException
{    DefaultOptionBuilder obuilder = new DefaultOptionBuilder();    ArgumentBuilder abuilder = new ArgumentBuilder();    GroupBuilder gbuilder = new GroupBuilder();    Option inputDirOpt = DefaultOptionCreator.inputOption().create();    Option outputOpt = DefaultOptionCreator.outputOption().create();    Option helpOpt = DefaultOptionCreator.helpOption();    Option recordSplitterOpt = obuilder.withLongName("splitterPattern").withArgument(abuilder.withName("splitterPattern").withMinimum(1).withMaximum(1).create()).withDescription("Regular Expression pattern used to split given line into fields." + " Default value splits comma or tab separated fields." + " Default Value: \"[ ,\\t]*\\t[ ,\\t]*\" ").withShortName("regex").create();    Option encodingOpt = obuilder.withLongName("encoding").withArgument(abuilder.withName("encoding").withMinimum(1).withMaximum(1).create()).withDescription("(Optional) The file encoding.  Default value: UTF-8").withShortName("e").create();    Group group = gbuilder.withName("Options").withOption(inputDirOpt).withOption(outputOpt).withOption(helpOpt).withOption(recordSplitterOpt).withOption(encodingOpt).create();    try {        Parser parser = new Parser();        parser.setGroup(group);        CommandLine cmdLine = parser.parse(args);        if (cmdLine.hasOption(helpOpt)) {            CommandLineUtil.printHelp(group);            return;        }        Parameters params = new Parameters();        if (cmdLine.hasOption(recordSplitterOpt)) {            params.set("splitPattern", (String) cmdLine.getValue(recordSplitterOpt));        }        String encoding = "UTF-8";        if (cmdLine.hasOption(encodingOpt)) {            encoding = (String) cmdLine.getValue(encodingOpt);        }        params.set("encoding", encoding);        String inputDir = (String) cmdLine.getValue(inputDirOpt);        String outputDir = (String) cmdLine.getValue(outputOpt);        params.set("input", inputDir);        params.set("output", outputDir);        params.set("groupingFieldCount", "2");        params.set("gfield0", "1");        params.set("gfield1", "2");        params.set("selectedFieldCount", "1");        params.set("field0", "3");        params.set("maxTransactionLength", "100");        KeyBasedStringTupleGrouper.startJob(params);    } catch (OptionException ex) {        CommandLineUtil.printHelp(group);    }}
public void mahout_f5702_0() throws IOException
{    LogisticModelParameters params = new LogisticModelParameters();    params.setTargetVariable("foo");    params.setTypeMap(Collections.<String, String>emptyMap());    params.setTargetCategories(Arrays.asList("foo", "bar"));    params.setNumFeatures(1);    params.createRegression();        params.saveTo(new ByteArrayOutputStream());}
public void mahout_f5703_0()
{    ModelDissector.Weight w = new ModelDissector.Weight("a", new DenseVector(new double[] { -2, -5, 5, 2, 4, 1, 0 }), 4);    assertEquals(1, w.getCategory(0), 0);    assertEquals(-5, w.getWeight(0), 0);    assertEquals(2, w.getCategory(1), 0);    assertEquals(5, w.getWeight(1), 0);    assertEquals(4, w.getCategory(2), 0);    assertEquals(4, w.getWeight(2), 0);    assertEquals(0, w.getCategory(3), 0);    assertEquals(-2, w.getWeight(3), 0);}
public void mahout_f5704_0() throws Exception
{    String outputFile = getTestTempFile("model").getAbsolutePath();    StringWriter sw = new StringWriter();    PrintWriter pw = new PrintWriter(sw, true);    TrainLogistic.mainToOutput(new String[] { "--input", "donut.csv", "--output", outputFile, "--target", "color", "--categories", "2", "--predictors", "x", "y", "--types", "numeric", "--features", "20", "--passes", "100", "--rate", "50" }, pw);    String trainOut = sw.toString();    assertTrue(trainOut.contains("x -0.7"));    assertTrue(trainOut.contains("y -0.4"));    LogisticModelParameters lmp = TrainLogistic.getParameters();    assertEquals(1.0e-4, lmp.getLambda(), 1.0e-9);    assertEquals(20, lmp.getNumFeatures());    assertTrue(lmp.useBias());    assertEquals("color", lmp.getTargetVariable());    CsvRecordFactory csv = lmp.getCsvRecordFactory();    assertEquals("[1, 2]", new TreeSet<>(csv.getTargetCategories()).toString());    assertEquals("[Intercept Term, x, y]", Sets.newTreeSet(csv.getPredictors()).toString());        AbstractVectorClassifier model = TrainLogistic.getModel();    List<String> data = Resources.readLines(Resources.getResource("donut.csv"), Charsets.UTF_8);    Map<String, Double> expectedValues = ImmutableMap.of("x", -0.7, "y", -0.43, "Intercept Term", -0.15);    verifyModel(lmp, csv, data, model, expectedValues);        try (InputStream in = new FileInputStream(new File(outputFile))) {        LogisticModelParameters lmpOut = LogisticModelParameters.loadFrom(in);        CsvRecordFactory csvOut = lmpOut.getCsvRecordFactory();        csvOut.firstLine(data.get(0));        OnlineLogisticRegression lrOut = lmpOut.createRegression();        verifyModel(lmpOut, csvOut, data, lrOut, expectedValues);    }    sw = new StringWriter();    pw = new PrintWriter(sw, true);    RunLogistic.mainToOutput(new String[] { "--input", "donut.csv", "--model", outputFile, "--auc", "--confusion" }, pw);    trainOut = sw.toString();    assertTrue(trainOut.contains("AUC = 0.57"));    assertTrue(trainOut.contains("confusion: [[27.0, 13.0], [0.0, 0.0]]"));}
public void mahout_f5705_0() throws Exception
{    String outputFile = getTestTempFile("model").getAbsolutePath();    StringWriter sw = new StringWriter();    PrintWriter pw = new PrintWriter(sw, true);    TrainLogistic.mainToOutput(new String[] { "--input", "donut.csv", "--output", outputFile, "--target", "color", "--categories", "2", "--predictors", "x", "y", "a", "b", "c", "--types", "numeric", "--features", "20", "--passes", "100", "--rate", "50" }, pw);    String trainOut = sw.toString();    assertTrue(trainOut.contains("a 0."));    assertTrue(trainOut.contains("b -1."));    assertTrue(trainOut.contains("c -25."));    sw = new StringWriter();    pw = new PrintWriter(sw, true);    RunLogistic.mainToOutput(new String[] { "--input", "donut.csv", "--model", outputFile, "--auc", "--confusion" }, pw);    trainOut = sw.toString();    assertTrue(trainOut.contains("AUC = 1.00"));    sw = new StringWriter();    pw = new PrintWriter(sw, true);    RunLogistic.mainToOutput(new String[] { "--input", "donut-test.csv", "--model", outputFile, "--auc", "--confusion" }, pw);    trainOut = sw.toString();    assertTrue(trainOut.contains("AUC = 0.9"));}
private static void mahout_f5706_0(LogisticModelParameters lmp, RecordFactory csv, List<String> data, AbstractVectorClassifier model, Map<String, Double> expectedValues)
{    ModelDissector md = new ModelDissector();    for (String line : data.subList(1, data.size())) {        Vector v = new DenseVector(lmp.getNumFeatures());        csv.getTraceDictionary().clear();        csv.processLine(line, v);        md.update(v, csv.getTraceDictionary(), model);    }        List<ModelDissector.Weight> weights = md.summary(10);    Set<String> expected = Sets.newHashSet(expectedValues.keySet());    for (ModelDissector.Weight weight : weights) {        assertTrue(expected.remove(weight.getFeature()));        assertEquals(expectedValues.get(weight.getFeature()), weight.getWeight(), 0.1);    }    assertEquals(0, expected.size());}
public void mahout_f5707_0() throws Exception
{    super.setUp();    configuration = getConfiguration();    output = getTestTempDirPath();}
public void mahout_f5708_0() throws Exception
{    Path path0 = new Path(output, "clusters-0");    Path path1 = new Path(output, "clusters-1");    path0.getFileSystem(configuration).createNewFile(path0);    path1.getFileSystem(configuration).createNewFile(path1);    PathFilter clustersFilter = new ClustersFilter();    assertTrue(clustersFilter.accept(path0));    assertTrue(clustersFilter.accept(path1));}
public void mahout_f5709_0() throws IOException
{    Path path0 = new Path(output, "clusters-0");    Path path1 = new Path(output, "clusters-1");    Path path2 = new Path(output, "clusters-2");    Path path3Final = new Path(output, "clusters-3-final");    path0.getFileSystem(configuration).createNewFile(path0);    path1.getFileSystem(configuration).createNewFile(path1);    path2.getFileSystem(configuration).createNewFile(path2);    path3Final.getFileSystem(configuration).createNewFile(path3Final);    PathFilter clustersFilter = new ClustersFilter();    assertTrue(clustersFilter.accept(path0));    assertTrue(clustersFilter.accept(path1));    assertTrue(clustersFilter.accept(path2));    assertTrue(clustersFilter.accept(path3Final));}
public static double mahout_f5710_0(double n, long k)
{    if (k < 0) {        return 0;    }    if (k == 0) {        return 1;    }    if (k == 1) {        return n;    }        double a = n - k + 1;    double b = 1;    double binomial = 1;    for (long i = k; i-- > 0; ) {        binomial *= (a++) / (b++);    }    return binomial;}
public static double mahout_f5711_0(long n, long k)
{    if (k < 0) {        return 0;    }    if (k == 0 || k == n) {        return 1;    }    if (k == 1 || k == n - 1) {        return n;    }        if (n > k) {        int max = LONG_FACTORIALS.length + DOUBLE_FACTORIALS.length;        if (n < max) {                        double n_fac = factorial((int) n);            double k_fac = factorial((int) k);            double n_minus_k_fac = factorial((int) (n - k));            double nk = n_minus_k_fac * k_fac;            if (nk != Double.POSITIVE_INFINITY) {                                return n_fac / nk;            }        }        if (k > n / 2) {            k = n - k;        }        }        long a = n - k + 1;    long b = 1;    double binomial = 1;    for (long i = k; i-- > 0; ) {        binomial *= (double) a++ / (b++);    }    return binomial;}
public static long mahout_f5712_0(double value)
{    return Math.round(Math.ceil(value));}
public static double mahout_f5713_0(double x, double[] coef, int N)
{    int p = 0;    double b0 = coef[p++];    double b1 = 0.0;    int i = N - 1;    double b2;    do {        b2 = b1;        b1 = b0;        b0 = x * b1 - b2 + coef[p++];    } while (--i > 0);    return 0.5 * (b0 - b2);}
private static double mahout_f5714_0(int k)
{    if (k < 0) {        throw new IllegalArgumentException();    }    int length1 = LONG_FACTORIALS.length;    if (k < length1) {        return LONG_FACTORIALS[k];    }    int length2 = DOUBLE_FACTORIALS.length;    if (k < length1 + length2) {        return DOUBLE_FACTORIALS[k - length1];    } else {        return Double.POSITIVE_INFINITY;    }}
public static long mahout_f5715_0(double value)
{    return Math.round(Math.floor(value));}
public static double mahout_f5716_0(double base, double value)
{    return Math.log(value) / Math.log(base);}
public static double mahout_f5717_0(double value)
{        return Math.log(value) * 0.43429448190325176;}
public static double mahout_f5718_0(double value)
{        return Math.log(value) * 1.4426950408889634;}
public static double mahout_f5719_0(int k)
{    if (k >= 30) {        double r = 1.0 / k;        double rr = r * r;        double C7 = -5.95238095238095238e-04;        double C5 = 7.93650793650793651e-04;        double C3 = -2.77777777777777778e-03;        double C1 = 8.33333333333333333e-02;        double C0 = 9.18938533204672742e-01;        return (k + 0.5) * Math.log(k) - k + C0 + r * (C1 + rr * (C3 + rr * (C5 + rr * C7)));    } else {        return LOG_FACTORIALS[k];    }}
public static long mahout_f5720_0(int k)
{    if (k < 0) {        throw new IllegalArgumentException("Negative k");    }    if (k < LONG_FACTORIALS.length) {        return LONG_FACTORIALS[k];    }    throw new IllegalArgumentException("Overflow");}
public static double mahout_f5721_0(int k)
{    if (k > 30) {        double r = 1.0 / k;        double rr = r * r;                double C7 = -5.95238095238095238e-04;                double C5 = 7.93650793650793651e-04;                double C3 = -2.77777777777777778e-03;                double C1 = 8.33333333333333333e-02;        return r * (C1 + rr * (C3 + rr * (C5 + rr * C7)));    } else {        return STIRLING_CORRECTION[k];    }}
public static void mahout_f5722_0()
{    testSeed = true;    synchronized (INSTANCES) {        for (RandomWrapper rng : INSTANCES.keySet()) {            rng.resetToTestSeed();        }    }}
public static RandomWrapper mahout_f5723_0()
{    RandomWrapper random = new RandomWrapper();    if (testSeed) {        random.resetToTestSeed();    }    INSTANCES.put(random, Boolean.TRUE);    return random;}
public static Random mahout_f5724_0(long seed)
{    RandomWrapper random = new RandomWrapper(seed);    INSTANCES.put(random, Boolean.TRUE);    return random;}
public static int mahout_f5725_0(double value)
{    return Longs.hashCode(Double.doubleToLongBits(value));}
public static int mahout_f5726_0(float value)
{    return Float.floatToIntBits(value);}
public static int mahout_f5727_0(int n)
{    if (n > MAX_INT_SMALLER_TWIN_PRIME) {        throw new IllegalArgumentException();    }    if (n <= 3) {        return 5;    }    int next = Primes.nextPrime(n);    while (!Primes.isPrime(next + 2)) {        next = Primes.nextPrime(next + 4);    }    return next + 2;}
public void mahout_f5728_0(long seed)
{        if (random != null) {        random.setSeed(seed);    }}
 void mahout_f5729_0()
{    setSeed(STANDARD_SEED);}
public RandomGenerator mahout_f5730_0()
{    return random;}
protected int mahout_f5731_0(int bits)
{        throw new UnsupportedOperationException();}
public void mahout_f5732_0(byte[] bytes)
{    random.nextBytes(bytes);}
public int mahout_f5733_0()
{    return random.nextInt();}
public int mahout_f5734_0(int n)
{    return random.nextInt(n);}
public long mahout_f5735_0()
{    return random.nextLong();}
public boolean mahout_f5736_0()
{    return random.nextBoolean();}
public float mahout_f5737_0()
{    return random.nextFloat();}
public double mahout_f5738_0()
{    return random.nextDouble();}
public double mahout_f5739_0()
{    return random.nextGaussian();}
public int mahout_f5740_0()
{    return columns;}
public int mahout_f5741_0()
{    return rows;}
public Iterator<MatrixSlice> mahout_f5742_0()
{    return iterateAll();}
public Iterator<MatrixSlice> mahout_f5743_0()
{    return new AbstractIterator<MatrixSlice>() {        private int row;        @Override        protected MatrixSlice computeNext() {            if (row >= numRows()) {                return endOfData();            }            int i = row++;            return new MatrixSlice(viewRow(i), i);        }    };}
protected MatrixSlice mahout_f5744_0()
{    if (row >= numRows()) {        return endOfData();    }    int i = row++;    return new MatrixSlice(viewRow(i), i);}
public Iterator<MatrixSlice> mahout_f5745_0()
{    return iterator();}
public int mahout_f5746_0()
{    return numRows();}
public double mahout_f5747_0(String rowLabel, String columnLabel)
{    if (columnLabelBindings == null || rowLabelBindings == null) {        throw new IllegalStateException("Unbound label");    }    Integer row = rowLabelBindings.get(rowLabel);    Integer col = columnLabelBindings.get(columnLabel);    if (row == null || col == null) {        throw new IllegalStateException("Unbound label");    }    return get(row, col);}
public Map<String, Integer> mahout_f5748_0()
{    return columnLabelBindings;}
public Map<String, Integer> mahout_f5749_0()
{    return rowLabelBindings;}
public void mahout_f5750_0(String rowLabel, double[] rowData)
{    if (columnLabelBindings == null) {        throw new IllegalStateException("Unbound label");    }    Integer row = rowLabelBindings.get(rowLabel);    if (row == null) {        throw new IllegalStateException("Unbound label");    }    set(row, rowData);}
public void mahout_f5751_0(String rowLabel, int row, double[] rowData)
{    if (rowLabelBindings == null) {        rowLabelBindings = new HashMap<>();    }    rowLabelBindings.put(rowLabel, row);    set(row, rowData);}
public void mahout_f5752_0(String rowLabel, String columnLabel, double value)
{    if (columnLabelBindings == null || rowLabelBindings == null) {        throw new IllegalStateException("Unbound label");    }    Integer row = rowLabelBindings.get(rowLabel);    Integer col = columnLabelBindings.get(columnLabel);    if (row == null || col == null) {        throw new IllegalStateException("Unbound label");    }    set(row, col, value);}
public void mahout_f5753_0(String rowLabel, String columnLabel, int row, int column, double value)
{    if (rowLabelBindings == null) {        rowLabelBindings = new HashMap<>();    }    rowLabelBindings.put(rowLabel, row);    if (columnLabelBindings == null) {        columnLabelBindings = new HashMap<>();    }    columnLabelBindings.put(columnLabel, column);    set(row, column, value);}
public void mahout_f5754_0(Map<String, Integer> bindings)
{    columnLabelBindings = bindings;}
public void mahout_f5755_0(Map<String, Integer> bindings)
{    rowLabelBindings = bindings;}
public int mahout_f5756_0()
{    return rowSize();}
public int mahout_f5757_0()
{    return columnSize();}
public String mahout_f5758_0()
{    return toString();}
public Matrix mahout_f5759_0(double value)
{    int rows = rowSize();    int columns = columnSize();    for (int row = 0; row < rows; row++) {        for (int col = 0; col < columns; col++) {            setQuick(row, col, value);        }    }    return this;}
public Matrix mahout_f5760_0(double[][] values)
{    int rows = rowSize();    if (rows != values.length) {        throw new CardinalityException(rows, values.length);    }    int columns = columnSize();    for (int row = 0; row < rows; row++) {        if (columns == values[row].length) {            for (int col = 0; col < columns; col++) {                setQuick(row, col, values[row][col]);            }        } else {            throw new CardinalityException(columns, values[row].length);        }    }    return this;}
public Matrix mahout_f5761_0(Matrix other, DoubleDoubleFunction function)
{    int rows = rowSize();    if (rows != other.rowSize()) {        throw new CardinalityException(rows, other.rowSize());    }    int columns = columnSize();    if (columns != other.columnSize()) {        throw new CardinalityException(columns, other.columnSize());    }    for (int row = 0; row < rows; row++) {        for (int col = 0; col < columns; col++) {            setQuick(row, col, function.apply(getQuick(row, col), other.getQuick(row, col)));        }    }    return this;}
public Matrix mahout_f5762_0(Matrix other)
{    int rows = rowSize();    if (rows != other.rowSize()) {        throw new CardinalityException(rows, other.rowSize());    }    int columns = columnSize();    if (columns != other.columnSize()) {        throw new CardinalityException(columns, other.columnSize());    }    for (int row = 0; row < rows; row++) {        for (int col = 0; col < columns; col++) {            setQuick(row, col, other.getQuick(row, col));        }    }    return this;}
public Matrix mahout_f5763_0(DoubleFunction function)
{    int rows = rowSize();    int columns = columnSize();    for (int row = 0; row < rows; row++) {        for (int col = 0; col < columns; col++) {            setQuick(row, col, function.apply(getQuick(row, col)));        }    }    return this;}
public Vector mahout_f5764_0(VectorFunction f)
{    Vector r = new DenseVector(numRows());    int n = numRows();    for (int row = 0; row < n; row++) {        r.set(row, f.apply(viewRow(row)));    }    return r;}
public Vector mahout_f5765_0(int row)
{    return new MatrixVectorView(this, row, 0, 0, 1);}
public Vector mahout_f5766_0(int column)
{    return new MatrixVectorView(this, 0, column, 1, 0);}
public Vector mahout_f5767_0()
{    return new MatrixVectorView(this, 0, 0, 1, 1);}
public double mahout_f5768_0(final DoubleDoubleFunction combiner, final DoubleFunction mapper)
{    return aggregateRows(new VectorFunction() {        @Override        public double apply(Vector v) {            return v.aggregate(combiner, mapper);        }    }).aggregate(combiner, Functions.IDENTITY);}
public double mahout_f5769_0(Vector v)
{    return v.aggregate(combiner, mapper);}
public Vector mahout_f5770_0(VectorFunction f)
{    Vector r = new DenseVector(numCols());    for (int col = 0; col < numCols(); col++) {        r.set(col, f.apply(viewColumn(col)));    }    return r;}
public double mahout_f5771_0()
{    int rows = rowSize();    int columns = columnSize();    if (rows != columns) {        throw new CardinalityException(rows, columns);    }    if (rows == 2) {        return getQuick(0, 0) * getQuick(1, 1) - getQuick(0, 1) * getQuick(1, 0);    } else {                        int sign = 1;        double ret = 0;        for (int i = 0; i < columns; i++) {            Matrix minor = new DenseMatrix(rows - 1, columns - 1);            for (int j = 1; j < rows; j++) {                boolean flag = false;                /* column offset flag */                for (int k = 0; k < columns; k++) {                    if (k == i) {                        flag = true;                        continue;                    }                    minor.set(j - 1, flag ? k - 1 : k, getQuick(j, k));                }            }            ret += getQuick(0, i) * sign * minor.determinant();            sign *= -1;        }        return ret;    }}
public Matrix mahout_f5772_0()
{    AbstractMatrix clone;    try {        clone = (AbstractMatrix) super.clone();    } catch (CloneNotSupportedException cnse) {                throw new IllegalStateException(cnse);    }    if (rowLabelBindings != null) {        clone.rowLabelBindings = Maps.newHashMap(rowLabelBindings);    }    if (columnLabelBindings != null) {        clone.columnLabelBindings = Maps.newHashMap(columnLabelBindings);    }    return clone;}
public Matrix mahout_f5773_0(double x)
{    Matrix result = like();    for (int row = 0; row < rowSize(); row++) {        for (int col = 0; col < columnSize(); col++) {            result.setQuick(row, col, getQuick(row, col) / x);        }    }    return result;}
public double mahout_f5774_0(int row, int column)
{    if (row < 0 || row >= rowSize()) {        throw new IndexException(row, rowSize());    }    if (column < 0 || column >= columnSize()) {        throw new IndexException(column, columnSize());    }    return getQuick(row, column);}
public Matrix mahout_f5775_0(Matrix other)
{    int rows = rowSize();    if (rows != other.rowSize()) {        throw new CardinalityException(rows, other.rowSize());    }    int columns = columnSize();    if (columns != other.columnSize()) {        throw new CardinalityException(columns, other.columnSize());    }    Matrix result = like();    for (int row = 0; row < rows; row++) {        for (int col = 0; col < columns; col++) {            result.setQuick(row, col, getQuick(row, col) - other.getQuick(row, col));        }    }    return result;}
public Matrix mahout_f5776_0(double x)
{    Matrix result = like();    int rows = rowSize();    int columns = columnSize();    for (int row = 0; row < rows; row++) {        for (int col = 0; col < columns; col++) {            result.setQuick(row, col, getQuick(row, col) + x);        }    }    return result;}
public Matrix mahout_f5777_0(Matrix other)
{    int rows = rowSize();    if (rows != other.rowSize()) {        throw new CardinalityException(rows, other.rowSize());    }    int columns = columnSize();    if (columns != other.columnSize()) {        throw new CardinalityException(columns, other.columnSize());    }    Matrix result = like();    for (int row = 0; row < rows; row++) {        for (int col = 0; col < columns; col++) {            result.setQuick(row, col, getQuick(row, col) + other.getQuick(row, col));        }    }    return result;}
public void mahout_f5778_0(int row, int column, double value)
{    if (row < 0 || row >= rowSize()) {        throw new IndexException(row, rowSize());    }    if (column < 0 || column >= columnSize()) {        throw new IndexException(column, columnSize());    }    setQuick(row, column, value);}
public void mahout_f5779_0(int row, double[] data)
{    int columns = columnSize();    if (columns < data.length) {        throw new CardinalityException(columns, data.length);    }    int rows = rowSize();    if (row < 0 || row >= rows) {        throw new IndexException(row, rowSize());    }    for (int i = 0; i < columns; i++) {        setQuick(row, i, data[i]);    }}
public Matrix mahout_f5780_0(double x)
{    Matrix result = like();    int rows = rowSize();    int columns = columnSize();    for (int row = 0; row < rows; row++) {        for (int col = 0; col < columns; col++) {            result.setQuick(row, col, getQuick(row, col) * x);        }    }    return result;}
public Matrix mahout_f5781_0(Matrix other)
{    int columns = columnSize();    if (columns != other.rowSize()) {        throw new CardinalityException(columns, other.rowSize());    }    int rows = rowSize();    int otherColumns = other.columnSize();    Matrix result = like(rows, otherColumns);    for (int row = 0; row < rows; row++) {        for (int col = 0; col < otherColumns; col++) {            double sum = 0.0;            for (int k = 0; k < columns; k++) {                sum += getQuick(row, k) * other.getQuick(k, col);            }            result.setQuick(row, col, sum);        }    }    return result;}
public Vector mahout_f5782_0(Vector v)
{    int columns = columnSize();    if (columns != v.size()) {        throw new CardinalityException(columns, v.size());    }    int rows = rowSize();    Vector w = new DenseVector(rows);    for (int row = 0; row < rows; row++) {        w.setQuick(row, v.dot(viewRow(row)));    }    return w;}
public Vector mahout_f5783_0(Vector v)
{    int columns = columnSize();    if (columns != v.size()) {        throw new CardinalityException(columns, v.size());    }    int rows = rowSize();    Vector w = new DenseVector(columns);    for (int i = 0; i < rows; i++) {        Vector xi = viewRow(i);        double d = xi.dot(v);        if (d != 0.0) {            w.assign(xi, new PlusMult(d));        }    }    return w;}
public Matrix mahout_f5784_0()
{    int rows = rowSize();    int columns = columnSize();    Matrix result = like(columns, rows);    for (int row = 0; row < rows; row++) {        for (int col = 0; col < columns; col++) {            result.setQuick(col, row, getQuick(row, col));        }    }    return result;}
public Matrix mahout_f5785_0(int rowOffset, int rowsRequested, int columnOffset, int columnsRequested)
{    return viewPart(new int[] { rowOffset, columnOffset }, new int[] { rowsRequested, columnsRequested });}
public Matrix mahout_f5786_0(int[] offset, int[] size)
{    if (offset[ROW] < 0) {        throw new IndexException(offset[ROW], 0);    }    if (offset[ROW] + size[ROW] > rowSize()) {        throw new IndexException(offset[ROW] + size[ROW], rowSize());    }    if (offset[COL] < 0) {        throw new IndexException(offset[COL], 0);    }    if (offset[COL] + size[COL] > columnSize()) {        throw new IndexException(offset[COL] + size[COL], columnSize());    }    return new MatrixView(this, offset, size);}
public double mahout_f5787_0()
{    double result = 0;    for (int row = 0; row < rowSize(); row++) {        for (int col = 0; col < columnSize(); col++) {            result += getQuick(row, col);        }    }    return result;}
public int[] mahout_f5788_0()
{    return new int[] { rowSize(), columnSize() };}
public Vector mahout_f5789_0()
{    Vector v = new DenseVector(size());    v.assign(this, Functions.PLUS);    return v;}
public boolean mahout_f5790_0()
{    return true;}
public boolean mahout_f5791_0()
{    return true;}
protected Matrix mahout_f5792_0(int rows, int columns)
{    return matrix.like(rows, columns);}
public Iterator<Element> mahout_f5793_0()
{    return new AbstractIterator<Element>() {        private int i;        @Override        protected Element computeNext() {            if (i >= size()) {                return endOfData();            }            return getElement(i++);        }    };}
protected Element mahout_f5794_0()
{    if (i >= size()) {        return endOfData();    }    return getElement(i++);}
public Iterator<Element> mahout_f5795_0()
{    return iterator();}
public Element mahout_f5796_0(final int i)
{    return new Element() {        @Override        public double get() {            return getQuick(i);        }        @Override        public int index() {            return i;        }        @Override        public void set(double value) {            setQuick(i, value);        }    };}
public double mahout_f5797_0()
{    return getQuick(i);}
public int mahout_f5798_0()
{    return i;}
public void mahout_f5799_0(double value)
{    setQuick(i, value);}
public void mahout_f5800_0(OrderedIntDoubleMapping updates)
{    throw new UnsupportedOperationException("Cannot mutate TransposeViewVector");}
public double mahout_f5801_0(int index)
{    Vector v = rowToColumn ? matrix.viewColumn(index) : matrix.viewRow(index);    return v == null ? 0.0 : v.getQuick(transposeOffset);}
public void mahout_f5802_0(int index, double value)
{    Vector v = rowToColumn ? matrix.viewColumn(index) : matrix.viewRow(index);    if (v == null) {        v = newVector(numCols);        if (rowToColumn) {            matrix.assignColumn(index, v);        } else {            matrix.assignRow(index, v);        }    }    v.setQuick(transposeOffset, value);}
protected Vector mahout_f5803_0(int cardinality)
{    return new DenseVector(cardinality);}
public Vector mahout_f5804_0()
{    return new DenseVector(size());}
public Vector mahout_f5805_0(int cardinality)
{    return new DenseVector(cardinality);}
public int mahout_f5806_0()
{    return size();}
public double mahout_f5807_0()
{    return (rowToColumn ? matrix.viewColumn(0) : matrix.viewRow(0)).getLookupCost();}
public double mahout_f5808_0()
{    return (rowToColumn ? matrix.viewColumn(0) : matrix.viewRow(0)).getIteratorAdvanceCost();}
public boolean mahout_f5809_0()
{    return (rowToColumn ? matrix.viewColumn(0) : matrix.viewRow(0)).isAddConstantTime();}
public String mahout_f5810_0()
{    int row = 0;    int maxRowsToDisplay = 10;    int maxColsToDisplay = 20;    int colsToDisplay = maxColsToDisplay;    if (maxColsToDisplay > columnSize()) {        colsToDisplay = columnSize();    }    StringBuilder s = new StringBuilder("{\n");    Iterator<MatrixSlice> it = iterator();    while ((it.hasNext()) && (row < maxRowsToDisplay)) {        MatrixSlice next = it.next();        s.append(" ").append(next.index()).append(" =>\t").append(new VectorView(next.vector(), 0, colsToDisplay)).append('\n');        row++;    }    String returnString = s.toString();    if (maxColsToDisplay <= columnSize()) {        returnString = returnString.replace("}", " ... } ");    }    if (maxRowsToDisplay <= rowSize())        return returnString + ("... }");    else {        return returnString + ("}");    }}
public MatrixFlavor mahout_f5811_0()
{    throw new UnsupportedOperationException("Flavor support not implemented for this matrix.");}
public Iterable<Element> mahout_f5812_0()
{    return new Iterable<Element>() {        @Override        public Iterator<Element> iterator() {            return AbstractVector.this.iterator();        }    };}
public Iterator<Element> mahout_f5813_0()
{    return AbstractVector.this.iterator();}
public Iterable<Element> mahout_f5814_0()
{    return new Iterable<Element>() {        @Override        public Iterator<Element> iterator() {            return iterateNonZero();        }    };}
public Iterator<Element> mahout_f5815_0()
{    return iterateNonZero();}
public double mahout_f5816_0(DoubleDoubleFunction aggregator, DoubleFunction map)
{    if (size == 0) {        return 0;    }        if (aggregator.isAssociativeAndCommutative() && aggregator.isLikeLeftMult() && size > getNumNondefaultElements() && !map.isDensifying()) {        return 0;    }    double result;    if (isSequentialAccess() || aggregator.isAssociativeAndCommutative()) {        Iterator<Element> iterator;                if (!map.isDensifying() && aggregator.isLikeRightPlus()) {            iterator = iterateNonZero();            if (!iterator.hasNext()) {                return 0;            }        } else {            iterator = iterator();        }        Element element = iterator.next();        result = map.apply(element.get());        while (iterator.hasNext()) {            element = iterator.next();            result = aggregator.apply(result, map.apply(element.get()));        }    } else {        result = map.apply(getQuick(0));        for (int i = 1; i < size; i++) {            result = aggregator.apply(result, map.apply(getQuick(i)));        }    }    return result;}
public double mahout_f5817_0(Vector other, DoubleDoubleFunction aggregator, DoubleDoubleFunction combiner)
{    Preconditions.checkArgument(size == other.size(), "Vector sizes differ");    if (size == 0) {        return 0;    }    return VectorBinaryAggregate.aggregateBest(this, other, aggregator, combiner);}
public Vector mahout_f5818_0(int offset, int length)
{    if (offset < 0) {        throw new IndexException(offset, size);    }    if (offset + length > size) {        throw new IndexException(offset + length, size);    }    return new VectorView(this, offset, length);}
public Vector mahout_f5819_0()
{    try {        AbstractVector r = (AbstractVector) super.clone();        r.size = size;        r.lengthSquared = lengthSquared;        return r;    } catch (CloneNotSupportedException e) {        throw new IllegalStateException("Can't happen");    }}
public Vector mahout_f5820_0(double x)
{    if (x == 1.0) {        return clone();    }    Vector result = createOptimizedCopy();    for (Element element : result.nonZeroes()) {        element.set(element.get() / x);    }    return result;}
public double mahout_f5821_0(Vector x)
{    if (size != x.size()) {        throw new CardinalityException(size, x.size());    }    if (this == x) {        return getLengthSquared();    }    return aggregate(x, Functions.PLUS, Functions.MULT);}
protected double mahout_f5822_0()
{    return aggregate(Functions.PLUS, Functions.pow(2));}
public double mahout_f5823_0(int index)
{    if (index < 0 || index >= size) {        throw new IndexException(index, size);    }    return getQuick(index);}
public Element mahout_f5824_0(int index)
{    return new LocalElement(index);}
public Vector mahout_f5825_0()
{    return divide(Math.sqrt(getLengthSquared()));}
public Vector mahout_f5826_0(double power)
{    return divide(norm(power));}
public Vector mahout_f5827_0()
{    return logNormalize(2.0, Math.sqrt(getLengthSquared()));}
public Vector mahout_f5828_0(double power)
{    return logNormalize(power, norm(power));}
public Vector mahout_f5829_0(double power, double normLength)
{        if (Double.isInfinite(power) || power <= 1.0) {        throw new IllegalArgumentException("Power must be > 1 and < infinity");    } else {        double denominator = normLength * Math.log(power);        Vector result = createOptimizedCopy();        for (Element element : result.nonZeroes()) {            element.set(Math.log1p(element.get()) / denominator);        }        return result;    }}
public double mahout_f5830_0(double power)
{    if (power < 0.0) {        throw new IllegalArgumentException("Power must be >= 0");    }        if (Double.isInfinite(power)) {        return aggregate(Functions.MAX, Functions.ABS);    } else if (power == 2.0) {        return Math.sqrt(getLengthSquared());    } else if (power == 1.0) {        double result = 0.0;        Iterator<Element> iterator = this.iterateNonZero();        while (iterator.hasNext()) {            result += Math.abs(iterator.next().get());        }        return result;            } else if (power == 0.0) {        return getNumNonZeroElements();    } else {        return Math.pow(aggregate(Functions.PLUS, Functions.pow(power)), 1.0 / power);    }}
public double mahout_f5831_0()
{    if (lengthSquared >= 0.0) {        return lengthSquared;    }    return lengthSquared = dotSelf();}
public void mahout_f5832_0()
{    lengthSquared = -1;}
public double mahout_f5833_0(Vector that)
{    if (size != that.size()) {        throw new CardinalityException(size, that.size());    }    double thisLength = getLengthSquared();    double thatLength = that.getLengthSquared();    double dot = dot(that);    double distanceEstimate = thisLength + thatLength - 2 * dot;    if (distanceEstimate > 1.0e-3 * (thisLength + thatLength)) {                return Math.max(distanceEstimate, 0);    } else {        return aggregate(that, Functions.PLUS, Functions.MINUS_SQUARED);    }}
public double mahout_f5834_0()
{    if (size == 0) {        return Double.NEGATIVE_INFINITY;    }    return aggregate(Functions.MAX, Functions.IDENTITY);}
public int mahout_f5835_0()
{    int result = -1;    double max = Double.NEGATIVE_INFINITY;    int nonZeroElements = 0;    Iterator<Element> iter = this.iterateNonZero();    while (iter.hasNext()) {        nonZeroElements++;        Element element = iter.next();        double tmp = element.get();        if (tmp > max) {            max = tmp;            result = element.index();        }    }        if (nonZeroElements < size && max < 0.0) {        for (Element element : all()) {            if (element.get() == 0.0) {                return element.index();            }        }    }    return result;}
public double mahout_f5836_0()
{    if (size == 0) {        return Double.POSITIVE_INFINITY;    }    return aggregate(Functions.MIN, Functions.IDENTITY);}
public int mahout_f5837_0()
{    int result = -1;    double min = Double.POSITIVE_INFINITY;    int nonZeroElements = 0;    Iterator<Element> iter = this.iterateNonZero();    while (iter.hasNext()) {        nonZeroElements++;        Element element = iter.next();        double tmp = element.get();        if (tmp < min) {            min = tmp;            result = element.index();        }    }        if (nonZeroElements < size && min > 0.0) {        for (Element element : all()) {            if (element.get() == 0.0) {                return element.index();            }        }    }    return result;}
public Vector mahout_f5838_0(double x)
{    Vector result = createOptimizedCopy();    if (x == 0.0) {        return result;    }    return result.assign(Functions.plus(x));}
public Vector mahout_f5839_0(Vector that)
{    if (size != that.size()) {        throw new CardinalityException(size, that.size());    }    return createOptimizedCopy().assign(that, Functions.PLUS);}
public Vector mahout_f5840_0(Vector that)
{    if (size != that.size()) {        throw new CardinalityException(size, that.size());    }    return createOptimizedCopy().assign(that, Functions.MINUS);}
public void mahout_f5841_0(int index, double value)
{    if (index < 0 || index >= size) {        throw new IndexException(index, size);    }    setQuick(index, value);}
public void mahout_f5842_0(int index, double increment)
{    setQuick(index, getQuick(index) + increment);}
public Vector mahout_f5843_0(double x)
{    if (x == 0.0) {        return like();    }    return createOptimizedCopy().assign(Functions.mult(x));}
protected Vector mahout_f5844_0()
{    return createOptimizedCopy(this);}
private static Vector mahout_f5845_0(Vector vector)
{    Vector result;    if (vector.isDense()) {        result = vector.like().assign(vector, Functions.SECOND_LEFT_ZERO);    } else {        result = vector.clone();    }    return result;}
public Vector mahout_f5846_0(Vector that)
{    if (size != that.size()) {        throw new CardinalityException(size, that.size());    }    if (this.getNumNondefaultElements() <= that.getNumNondefaultElements()) {        return createOptimizedCopy(this).assign(that, Functions.MULT);    } else {        return createOptimizedCopy(that).assign(this, Functions.MULT);    }}
public double mahout_f5847_0()
{    return aggregate(Functions.PLUS, Functions.IDENTITY);}
public int mahout_f5848_0()
{    int count = 0;    Iterator<Element> it = iterateNonZero();    while (it.hasNext()) {        if (it.next().get() != 0.0) {            count++;        }    }    return count;}
public Vector mahout_f5849_0(double value)
{    Iterator<Element> it;    if (value == 0.0) {                it = iterateNonZero();        while (it.hasNext()) {            it.next().set(value);        }    } else {        if (isSequentialAccess() && !isAddConstantTime()) {                                    it = iterator();            OrderedIntDoubleMapping updates = new OrderedIntDoubleMapping();            while (it.hasNext()) {                Element element = it.next();                if (element.get() == 0.0) {                    updates.set(element.index(), value);                } else {                    element.set(value);                }            }            mergeUpdates(updates);        } else {            for (int i = 0; i < size; ++i) {                setQuick(i, value);            }        }    }    invalidateCachedLength();    return this;}
public Vector mahout_f5850_0(double[] values)
{    if (size != values.length) {        throw new CardinalityException(size, values.length);    }    if (isSequentialAccess() && !isAddConstantTime()) {        OrderedIntDoubleMapping updates = new OrderedIntDoubleMapping();        Iterator<Element> it = iterator();        while (it.hasNext()) {            Element element = it.next();            int index = element.index();            if (element.get() == 0.0) {                updates.set(index, values[index]);            } else {                element.set(values[index]);            }        }        mergeUpdates(updates);    } else {        for (int i = 0; i < size; ++i) {            setQuick(i, values[i]);        }    }    invalidateCachedLength();    return this;}
public Vector mahout_f5851_0(Vector other)
{    return assign(other, Functions.SECOND);}
public Vector mahout_f5852_0(DoubleDoubleFunction f, double y)
{    Iterator<Element> iterator = f.apply(0, y) == 0 ? iterateNonZero() : iterator();    while (iterator.hasNext()) {        Element element = iterator.next();        element.set(f.apply(element.get(), y));    }    invalidateCachedLength();    return this;}
public Vector mahout_f5853_0(DoubleFunction f)
{    Iterator<Element> iterator = !f.isDensifying() ? iterateNonZero() : iterator();    while (iterator.hasNext()) {        Element element = iterator.next();        element.set(f.apply(element.get()));    }    invalidateCachedLength();    return this;}
public Vector mahout_f5854_0(Vector other, DoubleDoubleFunction function)
{    if (size != other.size()) {        throw new CardinalityException(size, other.size());    }    VectorBinaryAssign.assignBest(this, other, function);    invalidateCachedLength();    return this;}
public Matrix mahout_f5855_0(Vector other)
{    Matrix result = matrixLike(size, other.size());    Iterator<Vector.Element> it = iterateNonZero();    while (it.hasNext()) {        Vector.Element e = it.next();        int row = e.index();        result.assignRow(row, other.times(getQuick(row)));    }    return result;}
public final int mahout_f5856_0()
{    return size;}
public String mahout_f5857_0()
{    return toString();}
public int mahout_f5858_0()
{    int result = size;    Iterator<Element> iter = iterateNonZero();    while (iter.hasNext()) {        Element ele = iter.next();        result += ele.index() * RandomUtils.hashDouble(ele.get());    }    return result;}
public boolean mahout_f5859_0(Object o)
{    if (this == o) {        return true;    }    if (!(o instanceof Vector)) {        return false;    }    Vector that = (Vector) o;    return size == that.size() && aggregate(that, Functions.PLUS, Functions.MINUS_ABS) == 0.0;}
public String mahout_f5860_0()
{    return toString(null);}
public String mahout_f5861_0(String[] dictionary)
{    StringBuilder result = new StringBuilder();    result.append('{');    for (int index = 0; index < size; index++) {        double value = getQuick(index);        if (value != 0.0) {            result.append(dictionary != null && dictionary.length > index ? dictionary[index] : index);            result.append(':');            result.append(value);            result.append(',');        }    }    if (result.length() > 1) {        result.setCharAt(result.length() - 1, '}');    } else {        result.append('}');    }    return result.toString();}
public String mahout_f5862_0()
{    Iterator<Element> it = iterateNonZero();    if (!it.hasNext()) {        return "{}";    } else {        StringBuilder result = new StringBuilder();        result.append('{');        while (it.hasNext()) {            Vector.Element e = it.next();            result.append(e.index());            result.append(':');            result.append(e.get());            result.append(',');        }        result.setCharAt(result.length() - 1, '}');        return result.toString();    }}
public double mahout_f5863_0()
{    return getQuick(index);}
public int mahout_f5864_0()
{    return index;}
public void mahout_f5865_0(double value)
{    setQuick(index, value);}
public static Vector mahout_f5866_0(Matrix m, Vector v)
{    if (m.numRows() != v.size()) {        throw new CardinalityException(m.numRows(), v.size());    }        Vector result = new DenseVector(m.numRows());    for (int i = 0; i < m.numRows(); i++) {        result.set(i, m.viewRow(i).dot(v));    }    return result;}
public static double mahout_f5867_0(double a, double b)
{    double r;    if (Math.abs(a) > Math.abs(b)) {        r = b / a;        r = Math.abs(a) * Math.sqrt(1 + r * r);    } else if (b != 0) {        r = a / b;        r = Math.abs(b) * Math.sqrt(1 + r * r);    } else {        r = 0.0;    }    return r;}
public static double mahout_f5868_0(Matrix m)
{    double max = 0.0;    for (int i = 0; i < m.numRows(); i++) {        int sum = 0;        Vector cv = m.viewRow(i);        for (int j = 0; j < cv.size(); j++) {            sum += (int) Math.abs(cv.getQuick(j));        }        if (sum > max) {            max = sum;        }    }    return max;}
public static Vector mahout_f5869_0(Iterable<Vector> featureVectors, Vector ratingVector, double lambda, int numFeatures)
{    Preconditions.checkNotNull(featureVectors, "Feature Vectors cannot be null");    Preconditions.checkArgument(!Iterables.isEmpty(featureVectors));    Preconditions.checkNotNull(ratingVector, "Rating Vector cannot be null");    Preconditions.checkArgument(ratingVector.getNumNondefaultElements() > 0, "Rating Vector cannot be empty");    Preconditions.checkArgument(Iterables.size(featureVectors) == ratingVector.getNumNondefaultElements());    int nui = ratingVector.getNumNondefaultElements();    Matrix MiIi = createMiIi(featureVectors, numFeatures);    Matrix RiIiMaybeTransposed = createRiIiMaybeTransposed(ratingVector);    /* compute Ai = MiIi * t(MiIi) + lambda * nui * E */    Matrix Ai = miTimesMiTransposePlusLambdaTimesNuiTimesE(MiIi, lambda, nui);    /* compute Vi = MiIi * t(R(i,Ii)) */    Matrix Vi = MiIi.times(RiIiMaybeTransposed);    /* compute Ai * ui = Vi */    return solve(Ai, Vi);}
private static Vector mahout_f5870_0(Matrix Ai, Matrix Vi)
{    return new QRDecomposition(Ai).solve(Vi).viewColumn(0);}
 static Matrix mahout_f5871_0(Matrix matrix, double lambda, int nui)
{    Preconditions.checkArgument(matrix.numCols() == matrix.numRows(), "Must be a Square Matrix");    double lambdaTimesNui = lambda * nui;    int numCols = matrix.numCols();    for (int n = 0; n < numCols; n++) {        matrix.setQuick(n, n, matrix.getQuick(n, n) + lambdaTimesNui);    }    return matrix;}
private static Matrix mahout_f5872_0(Matrix MiIi, double lambda, int nui)
{    double lambdaTimesNui = lambda * nui;    int rows = MiIi.numRows();    double[][] result = new double[rows][rows];    for (int i = 0; i < rows; i++) {        for (int j = i; j < rows; j++) {            double dot = MiIi.viewRow(i).dot(MiIi.viewRow(j));            if (i != j) {                result[i][j] = dot;                result[j][i] = dot;            } else {                result[i][i] = dot + lambdaTimesNui;            }        }    }    return new DenseMatrix(result, true);}
 static Matrix mahout_f5873_0(Iterable<Vector> featureVectors, int numFeatures)
{    double[][] MiIi = new double[numFeatures][Iterables.size(featureVectors)];    int n = 0;    for (Vector featureVector : featureVectors) {        for (int m = 0; m < numFeatures; m++) {            MiIi[m][n] = featureVector.getQuick(m);        }        n++;    }    return new DenseMatrix(MiIi, true);}
 static Matrix mahout_f5874_0(Vector ratingVector)
{    Preconditions.checkArgument(ratingVector.isSequentialAccess(), "Ratings should be iterable in Index or Sequential Order");    double[][] RiIiMaybeTransposed = new double[ratingVector.getNumNondefaultElements()][1];    int index = 0;    for (Vector.Element elem : ratingVector.nonZeroes()) {        RiIiMaybeTransposed[index++][0] = elem.get();    }    return new DenseMatrix(RiIiMaybeTransposed, true);}
public Vector mahout_f5875_0(Vector ratings)
{    return solve(YtransposeY.plus(getYtransponseCuMinusIYPlusLambdaI(ratings)), getYtransponseCuPu(ratings));}
private static Vector mahout_f5876_0(Matrix A, Matrix y)
{    return new QRDecomposition(A).solve(y).viewColumn(0);}
 double mahout_f5877_0(double rating)
{    return 1 + alpha * rating;}
public Matrix mahout_f5878_1(final OpenIntObjectHashMap<Vector> Y)
{    ExecutorService queue = Executors.newFixedThreadPool(numTrainingThreads);    if (log.isInfoEnabled()) {            }    long startTime = System.nanoTime();    final IntArrayList indexes = Y.keys();    final int numIndexes = indexes.size();    final double[][] YtY = new double[numFeatures][numFeatures];        for (int i = 0; i < numFeatures; i++) {        for (int j = i; j < numFeatures; j++) {            final int ii = i;            final int jj = j;            queue.execute(new Runnable() {                @Override                public void run() {                    double dot = 0;                    for (int k = 0; k < numIndexes; k++) {                        Vector row = Y.get(indexes.getQuick(k));                        dot += row.getQuick(ii) * row.getQuick(jj);                    }                    YtY[ii][jj] = dot;                    if (ii != jj) {                        YtY[jj][ii] = dot;                    }                }            });        }    }    queue.shutdown();    try {        queue.awaitTermination(1, TimeUnit.DAYS);    } catch (InterruptedException e) {                throw new RuntimeException("Error during Y'Y queue shutdown");    }    if (log.isInfoEnabled()) {            }    return new DenseMatrix(YtY, true);}
public void mahout_f5879_0()
{    double dot = 0;    for (int k = 0; k < numIndexes; k++) {        Vector row = Y.get(indexes.getQuick(k));        dot += row.getQuick(ii) * row.getQuick(jj);    }    YtY[ii][jj] = dot;    if (ii != jj) {        YtY[jj][ii] = dot;    }}
private Matrix mahout_f5880_0(Vector userRatings)
{    Preconditions.checkArgument(userRatings.isSequentialAccess(), "need sequential access to ratings!");    /* (Cu -I) Y */    OpenIntObjectHashMap<Vector> CuMinusIY = new OpenIntObjectHashMap<>(userRatings.getNumNondefaultElements());    for (Element e : userRatings.nonZeroes()) {        CuMinusIY.put(e.index(), Y.get(e.index()).times(confidence(e.get()) - 1));    }    Matrix YtransponseCuMinusIY = new DenseMatrix(numFeatures, numFeatures);    /* Y' (Cu -I) Y by outer products */    for (Element e : userRatings.nonZeroes()) {        for (Vector.Element feature : Y.get(e.index()).all()) {            Vector partial = CuMinusIY.get(e.index()).times(feature.get());            YtransponseCuMinusIY.viewRow(feature.index()).assign(partial, Functions.PLUS);        }    }    /* Y' (Cu - I) Y + λ I  add lambda on the diagonal */    for (int feature = 0; feature < numFeatures; feature++) {        YtransponseCuMinusIY.setQuick(feature, feature, YtransponseCuMinusIY.getQuick(feature, feature) + lambda);    }    return YtransponseCuMinusIY;}
private Matrix mahout_f5881_0(Vector userRatings)
{    Preconditions.checkArgument(userRatings.isSequentialAccess(), "need sequential access to ratings!");    Vector YtransponseCuPu = new DenseVector(numFeatures);    for (Element e : userRatings.nonZeroes()) {        YtransponseCuPu.assign(Y.get(e.index()).times(confidence(e.get())), Functions.PLUS);    }    return columnVectorAsMatrix(YtransponseCuPu);}
private Matrix mahout_f5882_0(Vector v)
{    double[][] matrix = new double[numFeatures][1];    for (Vector.Element e : v.all()) {        matrix[e.index()][0] = e.get();    }    return new DenseMatrix(matrix, true);}
public static byte[] mahout_f5883_0(byte[] array, int minCapacity)
{    int oldCapacity = array.length;    byte[] newArray;    if (minCapacity > oldCapacity) {        int newCapacity = (oldCapacity * 3) / 2 + 1;        if (newCapacity < minCapacity) {            newCapacity = minCapacity;        }        newArray = new byte[newCapacity];        System.arraycopy(array, 0, newArray, 0, oldCapacity);    } else {        newArray = array;    }    return newArray;}
public static char[] mahout_f5884_0(char[] array, int minCapacity)
{    int oldCapacity = array.length;    char[] newArray;    if (minCapacity > oldCapacity) {        int newCapacity = (oldCapacity * 3) / 2 + 1;        if (newCapacity < minCapacity) {            newCapacity = minCapacity;        }        newArray = new char[newCapacity];        System.arraycopy(array, 0, newArray, 0, oldCapacity);    } else {        newArray = array;    }    return newArray;}
public static double[] mahout_f5885_0(double[] array, int minCapacity)
{    int oldCapacity = array.length;    double[] newArray;    if (minCapacity > oldCapacity) {        int newCapacity = (oldCapacity * 3) / 2 + 1;        if (newCapacity < minCapacity) {            newCapacity = minCapacity;        }        newArray = new double[newCapacity];                System.arraycopy(array, 0, newArray, 0, oldCapacity);    } else {        newArray = array;    }    return newArray;}
public static float[] mahout_f5886_0(float[] array, int minCapacity)
{    int oldCapacity = array.length;    float[] newArray;    if (minCapacity > oldCapacity) {        int newCapacity = (oldCapacity * 3) / 2 + 1;        if (newCapacity < minCapacity) {            newCapacity = minCapacity;        }        newArray = new float[newCapacity];        System.arraycopy(array, 0, newArray, 0, oldCapacity);    } else {        newArray = array;    }    return newArray;}
public static int[] mahout_f5887_0(int[] array, int minCapacity)
{    int oldCapacity = array.length;    int[] newArray;    if (minCapacity > oldCapacity) {        int newCapacity = (oldCapacity * 3) / 2 + 1;        if (newCapacity < minCapacity) {            newCapacity = minCapacity;        }        newArray = new int[newCapacity];        System.arraycopy(array, 0, newArray, 0, oldCapacity);    } else {        newArray = array;    }    return newArray;}
public static long[] mahout_f5888_0(long[] array, int minCapacity)
{    int oldCapacity = array.length;    long[] newArray;    if (minCapacity > oldCapacity) {        int newCapacity = (oldCapacity * 3) / 2 + 1;        if (newCapacity < minCapacity) {            newCapacity = minCapacity;        }        newArray = new long[newCapacity];        System.arraycopy(array, 0, newArray, 0, oldCapacity);    } else {        newArray = array;    }    return newArray;}
public static Object[] mahout_f5889_0(Object[] array, int minCapacity)
{    int oldCapacity = array.length;    Object[] newArray;    if (minCapacity > oldCapacity) {        int newCapacity = (oldCapacity * 3) / 2 + 1;        if (newCapacity < minCapacity) {            newCapacity = minCapacity;        }        newArray = new Object[newCapacity];        System.arraycopy(array, 0, newArray, 0, oldCapacity);    } else {        newArray = array;    }    return newArray;}
public static short[] mahout_f5890_0(short[] array, int minCapacity)
{    int oldCapacity = array.length;    short[] newArray;    if (minCapacity > oldCapacity) {        int newCapacity = (oldCapacity * 3) / 2 + 1;        if (newCapacity < minCapacity) {            newCapacity = minCapacity;        }        newArray = new short[newCapacity];        System.arraycopy(array, 0, newArray, 0, oldCapacity);    } else {        newArray = array;    }    return newArray;}
public static boolean[] mahout_f5891_0(boolean[] array, int minCapacity)
{    int oldCapacity = array.length;    boolean[] newArray;    if (minCapacity > oldCapacity) {        int newCapacity = (oldCapacity * 3) / 2 + 1;        if (newCapacity < minCapacity) {            newCapacity = minCapacity;        }        newArray = new boolean[newCapacity];        System.arraycopy(array, 0, newArray, 0, oldCapacity);    } else {        newArray = array;    }    return newArray;}
public static String mahout_f5892_0(byte[] array)
{    StringBuilder buf = new StringBuilder();    buf.append('[');    int maxIndex = array.length - 1;    for (int i = 0; i <= maxIndex; i++) {        buf.append(array[i]);        if (i < maxIndex) {            buf.append(", ");        }    }    buf.append(']');    return buf.toString();}
public static String mahout_f5893_0(char[] array)
{    StringBuilder buf = new StringBuilder();    buf.append('[');    int maxIndex = array.length - 1;    for (int i = 0; i <= maxIndex; i++) {        buf.append(array[i]);        if (i < maxIndex) {            buf.append(", ");        }    }    buf.append(']');    return buf.toString();}
public static String mahout_f5894_0(double[] array)
{    StringBuilder buf = new StringBuilder();    buf.append('[');    int maxIndex = array.length - 1;    for (int i = 0; i <= maxIndex; i++) {        buf.append(array[i]);        if (i < maxIndex) {            buf.append(", ");        }    }    buf.append(']');    return buf.toString();}
public static String mahout_f5895_0(float[] array)
{    StringBuilder buf = new StringBuilder();    buf.append('[');    int maxIndex = array.length - 1;    for (int i = 0; i <= maxIndex; i++) {        buf.append(array[i]);        if (i < maxIndex) {            buf.append(", ");        }    }    buf.append(']');    return buf.toString();}
public static String mahout_f5896_0(int[] array)
{    StringBuilder buf = new StringBuilder();    buf.append('[');    int maxIndex = array.length - 1;    for (int i = 0; i <= maxIndex; i++) {        buf.append(array[i]);        if (i < maxIndex) {            buf.append(", ");        }    }    buf.append(']');    return buf.toString();}
public static String mahout_f5897_0(long[] array)
{    StringBuilder buf = new StringBuilder();    buf.append('[');    int maxIndex = array.length - 1;    for (int i = 0; i <= maxIndex; i++) {        buf.append(array[i]);        if (i < maxIndex) {            buf.append(", ");        }    }    buf.append(']');    return buf.toString();}
public static String mahout_f5898_0(Object[] array)
{    StringBuilder buf = new StringBuilder();    buf.append('[');    int maxIndex = array.length - 1;    for (int i = 0; i <= maxIndex; i++) {        buf.append(array[i]);        if (i < maxIndex) {            buf.append(", ");        }    }    buf.append(']');    return buf.toString();}
public static String mahout_f5899_0(short[] array)
{    StringBuilder buf = new StringBuilder();    buf.append('[');    int maxIndex = array.length - 1;    for (int i = 0; i <= maxIndex; i++) {        buf.append(array[i]);        if (i < maxIndex) {            buf.append(", ");        }    }    buf.append(']');    return buf.toString();}
public static String mahout_f5900_0(boolean[] array)
{    StringBuilder buf = new StringBuilder();    buf.append('[');    int maxIndex = array.length - 1;    for (int i = 0; i <= maxIndex; i++) {        buf.append(array[i]);        if (i < maxIndex) {            buf.append(", ");        }    }    buf.append(']');    return buf.toString();}
public static byte[] mahout_f5901_0(byte[] array, int maxCapacity)
{    if (array.length > maxCapacity) {        byte[] oldArray = array;        array = new byte[maxCapacity];        System.arraycopy(oldArray, 0, array, 0, maxCapacity);    }    return array;}
public static char[] mahout_f5902_0(char[] array, int maxCapacity)
{    if (array.length > maxCapacity) {        char[] oldArray = array;        array = new char[maxCapacity];        System.arraycopy(oldArray, 0, array, 0, maxCapacity);    }    return array;}
public static double[] mahout_f5903_0(double[] array, int maxCapacity)
{    if (array.length > maxCapacity) {        double[] oldArray = array;        array = new double[maxCapacity];        System.arraycopy(oldArray, 0, array, 0, maxCapacity);    }    return array;}
public static float[] mahout_f5904_0(float[] array, int maxCapacity)
{    if (array.length > maxCapacity) {        float[] oldArray = array;        array = new float[maxCapacity];        System.arraycopy(oldArray, 0, array, 0, maxCapacity);    }    return array;}
public static int[] mahout_f5905_0(int[] array, int maxCapacity)
{    if (array.length > maxCapacity) {        int[] oldArray = array;        array = new int[maxCapacity];        System.arraycopy(oldArray, 0, array, 0, maxCapacity);    }    return array;}
public static long[] mahout_f5906_0(long[] array, int maxCapacity)
{    if (array.length > maxCapacity) {        long[] oldArray = array;        array = new long[maxCapacity];        System.arraycopy(oldArray, 0, array, 0, maxCapacity);    }    return array;}
public static Object[] mahout_f5907_0(Object[] array, int maxCapacity)
{    if (array.length > maxCapacity) {        Object[] oldArray = array;        array = new Object[maxCapacity];        System.arraycopy(oldArray, 0, array, 0, maxCapacity);    }    return array;}
public static short[] mahout_f5908_0(short[] array, int maxCapacity)
{    if (array.length > maxCapacity) {        short[] oldArray = array;        array = new short[maxCapacity];        System.arraycopy(oldArray, 0, array, 0, maxCapacity);    }    return array;}
public static boolean[] mahout_f5909_0(boolean[] array, int maxCapacity)
{    if (array.length > maxCapacity) {        boolean[] oldArray = array;        array = new boolean[maxCapacity];        System.arraycopy(oldArray, 0, array, 0, maxCapacity);    }    return array;}
public static byte[] mahout_f5910_0(byte[] src, int length)
{    byte[] result = new byte[length];    System.arraycopy(src, 0, result, 0, Math.min(length, src.length));    return result;}
public static char[] mahout_f5911_0(char[] src, int length)
{    char[] result = new char[length];    System.arraycopy(src, 0, result, 0, Math.min(length, src.length));    return result;}
public static short[] mahout_f5912_0(short[] src, int length)
{    short[] result = new short[length];    System.arraycopy(src, 0, result, 0, Math.min(length, src.length));    return result;}
public static int[] mahout_f5913_0(int[] src, int length)
{    int[] result = new int[length];    System.arraycopy(src, 0, result, 0, Math.min(length, src.length));    return result;}
public static float[] mahout_f5914_0(float[] src, int length)
{    float[] result = new float[length];    System.arraycopy(src, 0, result, 0, Math.min(length, src.length));    return result;}
public static double[] mahout_f5915_0(double[] src, int length)
{    double[] result = new double[length];    System.arraycopy(src, 0, result, 0, Math.min(length, src.length));    return result;}
public static long[] mahout_f5916_0(long[] src, int length)
{    long[] result = new long[length];    System.arraycopy(src, 0, result, 0, Math.min(length, src.length));    return result;}
public static int mahout_f5917_0(byte[] array, byte value, int from, int to)
{    int mid = -1;    while (from <= to) {        mid = (from + to) >>> 1;        if (value > array[mid]) {            from = mid + 1;        } else if (value == array[mid]) {            return mid;        } else {            to = mid - 1;        }    }    if (mid < 0) {        return -1;    }    return -mid - (value < array[mid] ? 1 : 2);}
public static int mahout_f5918_0(char[] array, char value, int from, int to)
{    int mid = -1;    while (from <= to) {        mid = (from + to) >>> 1;        if (value > array[mid]) {            from = mid + 1;        } else if (value == array[mid]) {            return mid;        } else {            to = mid - 1;        }    }    if (mid < 0) {        return -1;    }    return -mid - (value < array[mid] ? 1 : 2);}
public static int mahout_f5919_0(double[] array, double value, int from, int to)
{    long longBits = Double.doubleToLongBits(value);    int mid = -1;    while (from <= to) {        mid = (from + to) >>> 1;        if (lessThan(array[mid], value)) {            from = mid + 1;        } else if (longBits == Double.doubleToLongBits(array[mid])) {            return mid;        } else {            to = mid - 1;        }    }    if (mid < 0) {        return -1;    }    return -mid - (lessThan(value, array[mid]) ? 1 : 2);}
public static int mahout_f5920_0(float[] array, float value, int from, int to)
{    int intBits = Float.floatToIntBits(value);    int mid = -1;    while (from <= to) {        mid = (from + to) >>> 1;        if (lessThan(array[mid], value)) {            from = mid + 1;        } else if (intBits == Float.floatToIntBits(array[mid])) {            return mid;        } else {            to = mid - 1;        }    }    if (mid < 0) {        return -1;    }    return -mid - (lessThan(value, array[mid]) ? 1 : 2);}
public static int mahout_f5921_0(int[] array, int value, int from, int to)
{    int mid = -1;    while (from <= to) {        mid = (from + to) >>> 1;        if (value > array[mid]) {            from = mid + 1;        } else if (value == array[mid]) {            return mid;        } else {            to = mid - 1;        }    }    if (mid < 0) {        return -1;    }    return -mid - (value < array[mid] ? 1 : 2);}
public static int mahout_f5922_0(long[] array, long value, int from, int to)
{    int mid = -1;    while (from <= to) {        mid = (from + to) >>> 1;        if (value > array[mid]) {            from = mid + 1;        } else if (value == array[mid]) {            return mid;        } else {            to = mid - 1;        }    }    if (mid < 0) {        return -1;    }    return -mid - (value < array[mid] ? 1 : 2);}
public static int mahout_f5923_0(T[] array, T object, int from, int to)
{    if (array.length == 0) {        return -1;    }    int mid = 0;    int result = 0;    while (from <= to) {        mid = (from + to) >>> 1;        if ((result = array[mid].compareTo(object)) < 0) {            from = mid + 1;        } else if (result == 0) {            return mid;        } else {            to = mid - 1;        }    }    return -mid - (result >= 0 ? 1 : 2);}
public static int mahout_f5924_0(T[] array, T object, int from, int to, Comparator<? super T> comparator)
{    int mid = 0;    int result = 0;    while (from <= to) {        mid = (from + to) >>> 1;        if ((result = comparator.compare(array[mid], object)) < 0) {            from = mid + 1;        } else if (result == 0) {            return mid;        } else {            to = mid - 1;        }    }    return -mid - (result >= 0 ? 1 : 2);}
public static int mahout_f5925_0(short[] array, short value, int from, int to)
{    int mid = -1;    while (from <= to) {        mid = (from + to) >>> 1;        if (value > array[mid]) {            from = mid + 1;        } else if (value == array[mid]) {            return mid;        } else {            to = mid - 1;        }    }    if (mid < 0) {        return -1;    }    return -mid - (value < array[mid] ? 1 : 2);}
private static boolean mahout_f5926_0(double double1, double double2)
{        if (double1 < double2) {        return true;    }    if (double1 > double2) {        return false;    }    if (double1 == double2 && double1 != 0.0) {        return false;    }        if (Double.isNaN(double1)) {        return false;    }    if (Double.isNaN(double2)) {        return true;    }        long d1 = Double.doubleToRawLongBits(double1);    long d2 = Double.doubleToRawLongBits(double2);    return d1 < d2;}
private static boolean mahout_f5927_0(float float1, float float2)
{        if (float1 < float2) {        return true;    }    if (float1 > float2) {        return false;    }    if (float1 == float2 && float1 != 0.0f) {        return false;    }        if (Float.isNaN(float1)) {        return false;    }    if (Float.isNaN(float2)) {        return true;    }        int f1 = Float.floatToRawIntBits(float1);    int f2 = Float.floatToRawIntBits(float2);    return f1 < f2;}
public static Centroid mahout_f5928_0(int key, Vector initialValue)
{    if (initialValue instanceof WeightedVector) {        return new Centroid(key, new DenseVector(initialValue), ((WeightedVector) initialValue).getWeight());    } else {        return new Centroid(key, new DenseVector(initialValue), 1);    }}
public void mahout_f5929_0(Vector v)
{    if (v instanceof Centroid) {        Centroid c = (Centroid) v;        update(c.delegate, c.getWeight());    } else {        update(v, 1);    }}
public void mahout_f5930_0(Vector other, final double wy)
{    final double wx = getWeight();    delegate.assign(other, Functions.reweigh(wx, wy));    setWeight(wx + wy);}
public Centroid mahout_f5931_0()
{    return new Centroid(getIndex(), getVector().like(), getWeight());}
public int mahout_f5932_0()
{    return getIndex();}
public void mahout_f5933_0(double newWeight)
{    setWeight(getWeight() + newWeight);}
public String mahout_f5934_0()
{    return String.format("key = %d, weight = %.2f, vector = %s", getIndex(), getWeight(), delegate);}
public Centroid mahout_f5935_0()
{    return new Centroid(this);}
private void mahout_f5936_0(Matrix a)
{    int n = a.rowSize();    L.assign(a);        double uberMax = L.viewDiagonal().aggregate(Functions.MAX, Functions.ABS);    for (int k = 0; k < n; k++) {        double max = 0;        int pivot = k;        for (int j = k; j < n; j++) {            if (L.get(j, j) > max) {                max = L.get(j, j);                pivot = j;                if (uberMax < Math.abs(max)) {                    uberMax = Math.abs(max);                }            }        }        L.swap(k, pivot);        double akk = L.get(k, k);        double epsilon = 1.0e-10 * Math.max(uberMax, L.viewColumn(k).aggregate(Functions.MAX, Functions.ABS));        if (akk < -epsilon) {                        throw new IllegalArgumentException("Matrix is not positive semi-definite");        } else if (akk <= epsilon) {                        L.viewColumn(k).assign(0);            isPositiveDefinite = false;                } else {                        akk = Math.sqrt(Math.max(0, akk));            L.viewColumn(k).viewPart(k, n - k).assign(Functions.div(akk));            L.viewColumn(k).viewPart(0, k).assign(0);                        for (int j = k + 1; j < n; j++) {                Vector columnJ = L.viewColumn(j).viewPart(k, n - k);                Vector columnK = L.viewColumn(k).viewPart(k, n - k);                columnJ.assign(columnK, Functions.minusMult(columnK.get(j - k)));            }        }    }}
private void mahout_f5937_0(Matrix a)
{    int n = a.rowSize();    L.assign(a);        for (int k = 0; k < n; k++) {        double akk = L.get(k, k);                L.viewColumn(k).viewPart(0, k).assign(0);        double epsilon = 1.0e-10 * L.viewColumn(k).aggregate(Functions.MAX, Functions.ABS);        if (akk <= epsilon) {                        L.viewColumn(k).viewPart(k, n - k).assign(0);            isPositiveDefinite = false;                } else {                        akk = Math.sqrt(Math.max(0, akk));            L.set(k, k, akk);            L.viewColumn(k).viewPart(k + 1, n - k - 1).assign(Functions.div(akk));                        for (int j = k + 1; j < n; j++) {                Vector columnJ = L.viewColumn(j).viewPart(j, n - j);                Vector columnK = L.viewColumn(k).viewPart(j, n - j);                columnJ.assign(columnK, Functions.minusMult(L.get(j, k)));            }        }    }}
public boolean mahout_f5938_0()
{    return isPositiveDefinite;}
public Matrix mahout_f5939_0()
{    return L.getBase();}
public PivotedMatrix mahout_f5940_0()
{    return L;}
public int[] mahout_f5941_0()
{    return L.getRowPivot();}
public int[] mahout_f5942_0()
{    return L.getInverseRowPivot();}
public Matrix mahout_f5943_0(Matrix z)
{    int n = L.columnSize();    int nx = z.columnSize();    Matrix X = new DenseMatrix(n, z.columnSize());    X.assign(z);        for (int internalK = 0; internalK < n; internalK++) {        int k = L.rowUnpivot(internalK);        for (int j = 0; j < nx; j++) {            for (int internalI = 0; internalI < internalK; internalI++) {                int i = L.rowUnpivot(internalI);                X.set(k, j, X.get(k, j) - X.get(i, j) * L.get(k, i));            }            if (L.get(k, k) != 0) {                X.set(k, j, X.get(k, j) / L.get(k, k));            } else {                X.set(k, j, 0);            }        }    }    return X;}
public Matrix mahout_f5944_0(Matrix z)
{    int n = z.columnSize();    int nx = z.rowSize();    Matrix x = new DenseMatrix(z.rowSize(), z.columnSize());    x.assign(z);        for (int internalK = 0; internalK < n; internalK++) {        int k = L.rowUnpivot(internalK);        for (int j = 0; j < nx; j++) {            for (int internalI = 0; internalI < k; internalI++) {                int i = L.rowUnpivot(internalI);                x.set(j, k, x.get(j, k) - x.get(j, i) * L.get(k, i));                if (Double.isInfinite(x.get(j, k)) || Double.isNaN(x.get(j, k))) {                    throw new IllegalStateException(String.format("Invalid value found at %d,%d (should not be possible)", j, k));                }            }            if (L.get(k, k) != 0) {                x.set(j, k, x.get(j, k) / L.get(k, k));            } else {                x.set(j, k, 0);            }            if (Double.isInfinite(x.get(j, k)) || Double.isNaN(x.get(j, k))) {                throw new IllegalStateException(String.format("Invalid value found at %d,%d (should not be possible)", j, k));            }        }    }    return x;}
protected Matrix mahout_f5945_0(int rows, int columns)
{    return new DenseMatrix(rows, columns);}
public void mahout_f5946_0(OrderedIntDoubleMapping updates)
{    throw new UnsupportedOperationException("Cannot mutate a ConstantVector");}
public boolean mahout_f5947_0()
{    return true;}
public boolean mahout_f5948_0()
{    return true;}
public Iterator<Element> mahout_f5949_0()
{    return new AbstractIterator<Element>() {        private int i = 0;        private final int n = size();        @Override        protected Element computeNext() {            if (i < n) {                return new LocalElement(i++);            } else {                return endOfData();            }        }    };}
protected Element mahout_f5950_0()
{    if (i < n) {        return new LocalElement(i++);    } else {        return endOfData();    }}
public Iterator<Element> mahout_f5951_0()
{    return iterator();}
public double mahout_f5952_0(int index)
{    return value;}
public Vector mahout_f5953_0()
{    return new DenseVector(size());}
public Vector mahout_f5954_0(int cardinality)
{    return new DenseVector(cardinality);}
public void mahout_f5955_0(int index, double value)
{    throw new UnsupportedOperationException("Can't set a value in a constant matrix");}
public int mahout_f5956_0()
{    return size();}
public double mahout_f5957_0()
{    return 1;}
public double mahout_f5958_0()
{    return 1;}
public boolean mahout_f5959_0()
{    throw new UnsupportedOperationException("Cannot mutate a ConstantVector");}
public synchronized EigenStatus mahout_f5960_0(VectorIterable corpus, Vector vector)
{    if (!finished && !started) {                status = new EigenStatus(-1, 0);        Vector vectorCopy = vector.clone();        threadPool.execute(new VerifierRunnable(corpus, vectorCopy));        started = true;    }    if (finished) {        finished = false;    }    return status;}
public void mahout_f5961_0()
{    this.threadPool.shutdownNow();}
protected EigenStatus mahout_f5962_0(VectorIterable corpus, Vector vector)
{    return super.verify(corpus, vector);}
public void mahout_f5963_0()
{    EigenStatus status = innerVerify(corpus, vector);    synchronized (AsyncEigenVerifier.this) {        AsyncEigenVerifier.this.status = status;        finished = true;        started = false;    }}
public double mahout_f5964_0()
{    return cosAngle;}
public double mahout_f5965_0()
{    return eigenValue;}
public boolean mahout_f5966_0()
{    return inProgress;}
 void mahout_f5967_0(boolean status)
{    inProgress = status;}
public TrainingState mahout_f5968_1(Matrix corpus, int desiredRank)
{    int cols = corpus.numCols();    Matrix eigens = new DenseMatrix(desiredRank, cols);    List<Double> eigenValues = new ArrayList<>();        /*     * The corpusProjections matrix is a running cache of the residual projection of each corpus vector against all     * of the previously found singular vectors.  Without this, if multiple passes over the data is made (per     * singular vector), recalculating these projections eventually dominates the computational complexity of the     * solver.     */    Matrix corpusProjections = new DenseMatrix(corpus.numRows(), desiredRank);    TrainingState state = new TrainingState(eigens, corpusProjections);    for (int i = 0; i < desiredRank; i++) {        Vector currentEigen = new DenseVector(cols);        Vector previousEigen = null;        while (hasNotConverged(currentEigen, corpus, state)) {            int randomStartingIndex = getRandomStartingIndex(corpus, eigens);            Vector initialTrainingVector = corpus.viewRow(randomStartingIndex);            state.setTrainingIndex(randomStartingIndex);            updater.update(currentEigen, initialTrainingVector, state);            for (int corpusRow = 0; corpusRow < corpus.numRows(); corpusRow++) {                state.setTrainingIndex(corpusRow);                if (corpusRow != randomStartingIndex) {                    updater.update(currentEigen, corpus.viewRow(corpusRow), state);                }            }            state.setFirstPass(false);            if (DEBUG) {                if (previousEigen == null) {                    previousEigen = currentEigen.clone();                } else {                    double dot = currentEigen.dot(previousEigen);                    if (dot > 0.0) {                        dot /= currentEigen.norm(2) * previousEigen.norm(2);                    }                                }            }        }                double eigenValue = state.getStatusProgress().get(state.getStatusProgress().size() - 1).getEigenValue();                        currentEigen.assign(new TimesFunction(), 1 / currentEigen.norm(2));        eigens.assignRow(i, currentEigen);        eigenValues.add(eigenValue);        state.setCurrentEigenValues(eigenValues);                /**         *  TODO: Persist intermediate output!         */        state.setFirstPass(true);        state.setNumEigensProcessed(state.getNumEigensProcessed() + 1);        state.setActivationDenominatorSquared(0);        state.setActivationNumerator(0);        state.getStatusProgress().clear();        numPasses = 0;    }    return state;}
private int mahout_f5969_0(Matrix corpus, Matrix eigens)
{    int index;    Vector v;    do {        double r = rng.nextDouble();        index = (int) (r * corpus.numRows());        v = corpus.viewRow(index);    } while (v == null || v.norm(2) == 0 || v.getNumNondefaultElements() < 5);    return index;}
protected boolean mahout_f5970_1(Vector currentPseudoEigen, Matrix corpus, TrainingState state)
{    numPasses++;    if (state.isFirstPass()) {                return true;    }    Matrix previousEigens = state.getCurrentEigens();        /*     * Step 1: orthogonalize currentPseudoEigen by subtracting off eigen(i) * helper.get(i)     * Step 2: zero-out the helper vector because it has already helped.     */    for (int i = 0; i < state.getNumEigensProcessed(); i++) {        Vector previousEigen = previousEigens.viewRow(i);        currentPseudoEigen.assign(previousEigen, new PlusMult(-state.getHelperVector().get(i)));        state.getHelperVector().set(i, 0);    }    if (currentPseudoEigen.norm(2) > 0) {        for (int i = 0; i < state.getNumEigensProcessed(); i++) {            Vector previousEigen = previousEigens.viewRow(i);                    }    }    /*     * Step 3: verify how eigen-like the prospective eigen is.  This is potentially asynchronous.     */    EigenStatus status = verify(corpus, currentPseudoEigen);    if (status.inProgress()) {            } else {                state.getStatusProgress().add(status);    }    return state.getStatusProgress().size() <= maxPassesPerEigen && 1.0 - status.getCosAngle() > convergenceTarget;}
protected EigenStatus mahout_f5971_0(Matrix corpus, Vector currentPseudoEigen)
{    return verifier.verify(corpus, currentPseudoEigen);}
public static void mahout_f5972_1(String[] args)
{    Properties props = new Properties();    String propertiesFile = args.length > 0 ? args[0] : "config/solver.properties";        String corpusDir = props.getProperty("solver.input.dir");    String outputDir = props.getProperty("solver.output.dir");    if (corpusDir == null || corpusDir.isEmpty() || outputDir == null || outputDir.isEmpty()) {                return;    }        int rank = Integer.parseInt(props.getProperty("solver.output.desiredRank"));    double convergence = Double.parseDouble(props.getProperty("solver.convergence"));    int maxPasses = Integer.parseInt(props.getProperty("solver.maxPasses"));        HebbianUpdater updater = new HebbianUpdater();    SingularVectorVerifier verifier = new AsyncEigenVerifier();    HebbianSolver solver = new HebbianSolver(updater, verifier, convergence, maxPasses);    Matrix corpus = null;    /*    if (numThreads <= 1) {          } else {          }     */    long now = System.currentTimeMillis();    TrainingState finalState = solver.solve(corpus, rank);    long time = (System.currentTimeMillis() - now) / 1000;    }
public void mahout_f5973_0(Vector pseudoEigen, Vector trainingVector, TrainingState currentState)
{    double trainingVectorNorm = trainingVector.norm(2);    int numPreviousEigens = currentState.getNumEigensProcessed();    if (numPreviousEigens > 0 && currentState.isFirstPass()) {        updateTrainingProjectionsVector(currentState, trainingVector, numPreviousEigens - 1);    }    if (currentState.getActivationDenominatorSquared() == 0 || trainingVectorNorm == 0) {        if (currentState.getActivationDenominatorSquared() == 0) {            pseudoEigen.assign(trainingVector, new PlusMult(1));            currentState.setHelperVector(currentState.currentTrainingProjection().clone());            double helperNorm = currentState.getHelperVector().norm(2);            currentState.setActivationDenominatorSquared(trainingVectorNorm * trainingVectorNorm - helperNorm * helperNorm);        }        return;    }    currentState.setActivationNumerator(pseudoEigen.dot(trainingVector));    currentState.setActivationNumerator(currentState.getActivationNumerator() - currentState.getHelperVector().dot(currentState.currentTrainingProjection()));    double activation = currentState.getActivationNumerator() / Math.sqrt(currentState.getActivationDenominatorSquared());    currentState.setActivationDenominatorSquared(currentState.getActivationDenominatorSquared() + 2 * activation * currentState.getActivationNumerator() + activation * activation * (trainingVector.getLengthSquared() - currentState.currentTrainingProjection().getLengthSquared()));    if (numPreviousEigens > 0) {        currentState.getHelperVector().assign(currentState.currentTrainingProjection(), new PlusMult(activation));    }    pseudoEigen.assign(trainingVector, new PlusMult(activation));}
private static void mahout_f5974_0(TrainingState state, Vector trainingVector, int previousEigenIndex)
{    Vector previousEigen = state.mostRecentEigen();    Vector currentTrainingVectorProjection = state.currentTrainingProjection();    double projection = previousEigen.dot(trainingVector);    currentTrainingVectorProjection.set(previousEigenIndex, projection);}
public Vector mahout_f5975_0()
{    return currentEigens.viewRow(numEigensProcessed - 1);}
public Vector mahout_f5976_0()
{    if (trainingProjections.viewRow(trainingIndex) == null) {        trainingProjections.assignRow(trainingIndex, new DenseVector(currentEigens.numCols()));    }    return trainingProjections.viewRow(trainingIndex);}
public Matrix mahout_f5977_0()
{    return currentEigens;}
public void mahout_f5978_0(Matrix currentEigens)
{    this.currentEigens = currentEigens;}
public int mahout_f5979_0()
{    return numEigensProcessed;}
public void mahout_f5980_0(int numEigensProcessed)
{    this.numEigensProcessed = numEigensProcessed;}
public List<Double> mahout_f5981_0()
{    return currentEigenValues;}
public void mahout_f5982_0(List<Double> currentEigenValues)
{    this.currentEigenValues = currentEigenValues;}
public Matrix mahout_f5983_0()
{    return trainingProjections;}
public void mahout_f5984_0(Matrix trainingProjections)
{    this.trainingProjections = trainingProjections;}
public int mahout_f5985_0()
{    return trainingIndex;}
public void mahout_f5986_0(int trainingIndex)
{    this.trainingIndex = trainingIndex;}
public Vector mahout_f5987_0()
{    return helperVector;}
public void mahout_f5988_0(Vector helperVector)
{    this.helperVector = helperVector;}
public boolean mahout_f5989_0()
{    return firstPass;}
public void mahout_f5990_0(boolean firstPass)
{    this.firstPass = firstPass;}
public List<EigenStatus> mahout_f5991_0()
{    return statusProgress;}
public void mahout_f5992_0(List<EigenStatus> statusProgress)
{    this.statusProgress = statusProgress;}
public double mahout_f5993_0()
{    return activationNumerator;}
public void mahout_f5994_0(double activationNumerator)
{    this.activationNumerator = activationNumerator;}
public double mahout_f5995_0()
{    return activationDenominatorSquared;}
public void mahout_f5996_0(double activationDenominatorSquared)
{    this.activationDenominatorSquared = activationDenominatorSquared;}
public double mahout_f5997_0(double arg1)
{    return arg1 * d;}
public void mahout_f5998_0(LanczosState state, int desiredRank)
{    solve(state, desiredRank, false);}
public void mahout_f5999_1(LanczosState state, int desiredRank, boolean isSymmetric)
{    VectorIterable corpus = state.getCorpus();        int i = state.getIterationNumber();    Vector currentVector = state.getBasisVector(i - 1);    Vector previousVector = state.getBasisVector(i - 2);    double beta = 0;    Matrix triDiag = state.getDiagonalMatrix();    while (i < desiredRank) {        startTime(TimingSection.ITERATE);        Vector nextVector = isSymmetric ? corpus.times(currentVector) : corpus.timesSquared(currentVector);                if (state.getScaleFactor() <= 0) {            state.setScaleFactor(calculateScaleFactor(nextVector));        }        nextVector.assign(new Scale(1.0 / state.getScaleFactor()));        if (previousVector != null) {            nextVector.assign(previousVector, new PlusMult(-beta));        }                double alpha = currentVector.dot(nextVector);        nextVector.assign(currentVector, new PlusMult(-alpha));        endTime(TimingSection.ITERATE);        startTime(TimingSection.ORTHOGANLIZE);        orthoganalizeAgainstAllButLast(nextVector, state);        endTime(TimingSection.ORTHOGANLIZE);                beta = nextVector.norm(2);        if (outOfRange(beta) || outOfRange(alpha)) {                        break;        }        nextVector.assign(new Scale(1 / beta));        state.setBasisVector(i, nextVector);        previousVector = currentVector;        currentVector = nextVector;                triDiag.set(i - 1, i - 1, alpha);        if (i < desiredRank - 1) {            triDiag.set(i - 1, i, beta);            triDiag.set(i, i - 1, beta);        }        state.setIterationNumber(++i);    }    startTime(TimingSection.TRIDIAG_DECOMP);            EigenDecomposition decomp = new EigenDecomposition(triDiag);    Matrix eigenVects = decomp.getV();    Vector eigenVals = decomp.getRealEigenvalues();    endTime(TimingSection.TRIDIAG_DECOMP);    startTime(TimingSection.FINAL_EIGEN_CREATE);    for (int row = 0; row < i; row++) {        Vector realEigen = null;        Vector ejCol = eigenVects.viewColumn(row);        int size = Math.min(ejCol.size(), state.getBasisSize());        for (int j = 0; j < size; j++) {            double d = ejCol.get(j);            Vector rowJ = state.getBasisVector(j);            if (realEigen == null) {                realEigen = rowJ.like();            }            realEigen.assign(rowJ, new PlusMult(d));        }        Preconditions.checkState(realEigen != null);        assert realEigen != null;        realEigen = realEigen.normalize();        state.setRightSingularVector(row, realEigen);        double e = eigenVals.get(row) * state.getScaleFactor();        if (!isSymmetric) {            e = Math.sqrt(e);        }                state.setSingularValue(row, e);    }        endTime(TimingSection.FINAL_EIGEN_CREATE);}
protected static double mahout_f6000_0(Vector nextVector)
{    return nextVector.norm(2);}
private static boolean mahout_f6001_0(double d)
{    return Double.isNaN(d) || d > SAFE_MAX || -d > SAFE_MAX;}
protected static void mahout_f6002_0(Vector nextVector, LanczosState state)
{    for (int i = 0; i < state.getIterationNumber(); i++) {        Vector basisVector = state.getBasisVector(i);        double alpha;        if (basisVector == null || (alpha = nextVector.dot(basisVector)) == 0.0) {            continue;        }        nextVector.assign(basisVector, new PlusMult(-alpha));    }}
private void mahout_f6003_0(TimingSection section)
{    startTimes.put(section, System.nanoTime());}
private void mahout_f6004_0(TimingSection section)
{    if (!times.containsKey(section)) {        times.put(section, 0L);    }    times.put(section, times.get(section) + System.nanoTime() - startTimes.get(section));}
private void mahout_f6005_0()
{    basis = Maps.newHashMap();    singularVectors = Maps.newHashMap();}
public Matrix mahout_f6006_0()
{    return diagonalMatrix;}
public int mahout_f6007_0()
{    return iterationNumber;}
public double mahout_f6008_0()
{    return scaleFactor;}
public VectorIterable mahout_f6009_0()
{    return corpus;}
public Vector mahout_f6010_0(int i)
{    return singularVectors.get(i);}
public Double mahout_f6011_0(int i)
{    return singularValues.get(i);}
public Vector mahout_f6012_0(int i)
{    return basis.get(i);}
public int mahout_f6013_0()
{    return basis.size();}
public void mahout_f6014_0(int i, Vector basisVector)
{    basis.put(i, basisVector);}
public void mahout_f6015_0(double scale)
{    scaleFactor = scale;}
public void mahout_f6016_0(int i)
{    iterationNumber = i;}
public void mahout_f6017_0(int i, Vector vector)
{    singularVectors.put(i, vector);}
public void mahout_f6018_0(int i, double value)
{    singularValues.put(i, value);}
public EigenStatus mahout_f6019_0(VectorIterable corpus, Vector vector)
{    Vector resultantVector = corpus.timesSquared(vector);    double newNorm = resultantVector.norm(2);    double oldNorm = vector.norm(2);    double eigenValue;    double cosAngle;    if (newNorm > 0 && oldNorm > 0) {        eigenValue = newNorm / oldNorm;        cosAngle = resultantVector.dot(vector) / newNorm * oldNorm;    } else {        eigenValue = 1.0;        cosAngle = 0.0;    }    return new EigenStatus(eigenValue, cosAngle, false);}
public Vector mahout_f6020_0()
{    return delegate;}
public double mahout_f6021_0(DoubleDoubleFunction aggregator, DoubleFunction map)
{    return delegate.aggregate(aggregator, map);}
public double mahout_f6022_0(Vector other, DoubleDoubleFunction aggregator, DoubleDoubleFunction combiner)
{    return delegate.aggregate(other, aggregator, combiner);}
public Vector mahout_f6023_0(int offset, int length)
{    return delegate.viewPart(offset, length);}
public Vector mahout_f6024_0()
{    DelegatingVector r;    try {        r = (DelegatingVector) super.clone();    } catch (CloneNotSupportedException e) {        throw new RuntimeException("Clone not supported for DelegatingVector, shouldn't be possible");    }        r.delegate = delegate.clone();    return r;}
public Iterable<Element> mahout_f6025_0()
{    return delegate.all();}
public Iterable<Element> mahout_f6026_0()
{    return delegate.nonZeroes();}
public Vector mahout_f6027_0(double x)
{    return delegate.divide(x);}
public double mahout_f6028_0(Vector x)
{    return delegate.dot(x);}
public double mahout_f6029_0(int index)
{    return delegate.get(index);}
public Element mahout_f6030_0(int index)
{    return delegate.getElement(index);}
public void mahout_f6031_0(OrderedIntDoubleMapping updates)
{    delegate.mergeUpdates(updates);}
public Vector mahout_f6032_0(Vector that)
{    return delegate.minus(that);}
public Vector mahout_f6033_0()
{    return delegate.normalize();}
public Vector mahout_f6034_0(double power)
{    return delegate.normalize(power);}
public Vector mahout_f6035_0()
{    return delegate.logNormalize();}
public Vector mahout_f6036_0(double power)
{    return delegate.logNormalize(power);}
public double mahout_f6037_0(double power)
{    return delegate.norm(power);}
public double mahout_f6038_0()
{    return delegate.getLengthSquared();}
public void mahout_f6039_0()
{    if (delegate instanceof LengthCachingVector) {        ((LengthCachingVector) delegate).invalidateCachedLength();    }}
public double mahout_f6040_0(Vector v)
{    return delegate.getDistanceSquared(v);}
public double mahout_f6041_0()
{    return delegate.getLookupCost();}
public double mahout_f6042_0()
{    return delegate.getIteratorAdvanceCost();}
public boolean mahout_f6043_0()
{    return delegate.isAddConstantTime();}
public double mahout_f6044_0()
{    return delegate.maxValue();}
public int mahout_f6045_0()
{    return delegate.maxValueIndex();}
public double mahout_f6046_0()
{    return delegate.minValue();}
public int mahout_f6047_0()
{    return delegate.minValueIndex();}
public Vector mahout_f6048_0(double x)
{    return delegate.plus(x);}
public Vector mahout_f6049_0(Vector x)
{    return delegate.plus(x);}
public void mahout_f6050_0(int index, double value)
{    delegate.set(index, value);}
public Vector mahout_f6051_0(double x)
{    return delegate.times(x);}
public Vector mahout_f6052_0(Vector x)
{    return delegate.times(x);}
public double mahout_f6053_0()
{    return delegate.zSum();}
public Vector mahout_f6054_0(double value)
{    delegate.assign(value);    return this;}
public Vector mahout_f6055_0(double[] values)
{    delegate.assign(values);    return this;}
public Vector mahout_f6056_0(Vector other)
{    delegate.assign(other);    return this;}
public Vector mahout_f6057_0(DoubleDoubleFunction f, double y)
{    delegate.assign(f, y);    return this;}
public Vector mahout_f6058_0(DoubleFunction function)
{    delegate.assign(function);    return this;}
public Vector mahout_f6059_0(Vector other, DoubleDoubleFunction function)
{    delegate.assign(other, function);    return this;}
public Matrix mahout_f6060_0(Vector other)
{    return delegate.cross(other);}
public int mahout_f6061_0()
{    return delegate.size();}
public String mahout_f6062_0()
{    return delegate.asFormatString();}
public int mahout_f6063_0()
{    return delegate.hashCode();}
public boolean mahout_f6064_0(Object o)
{    return delegate.equals(o);}
public String mahout_f6065_0()
{    return delegate.toString();}
public boolean mahout_f6066_0()
{    return delegate.isDense();}
public boolean mahout_f6067_0()
{    return delegate.isSequentialAccess();}
public double mahout_f6068_0(int index)
{    return delegate.getQuick(index);}
public Vector mahout_f6069_0()
{    return new DelegatingVector(delegate.like());}
public Vector mahout_f6070_0(int cardinality)
{    return new DelegatingVector(delegate.like(cardinality));}
public void mahout_f6071_0(int index, double value)
{    delegate.setQuick(index, value);}
public void mahout_f6072_0(int index, double increment)
{    delegate.incrementQuick(index, increment);}
public int mahout_f6073_0()
{    return delegate.getNumNondefaultElements();}
public int mahout_f6074_0()
{    return delegate.getNumNonZeroElements();}
public double[][] mahout_f6075_0()
{    return this.values;}
public Matrix mahout_f6076_0()
{    DenseMatrix clone = (DenseMatrix) super.clone();    clone.values = new double[values.length][];    for (int i = 0; i < values.length; i++) {        clone.values[i] = values[i].clone();    }    return clone;}
public double mahout_f6077_0(int row, int column)
{    return values[row][column];}
public Matrix mahout_f6078_0()
{    return like(rowSize(), columnSize());}
public Matrix mahout_f6079_0(int rows, int columns)
{    return new DenseMatrix(rows, columns);}
public void mahout_f6080_0(int row, int column, double value)
{    values[row][column] = value;}
public Matrix mahout_f6081_0(int[] offset, int[] size)
{    int rowOffset = offset[ROW];    int rowsRequested = size[ROW];    int columnOffset = offset[COL];    int columnsRequested = size[COL];    return viewPart(rowOffset, rowsRequested, columnOffset, columnsRequested);}
public Matrix mahout_f6082_0(int rowOffset, int rowsRequested, int columnOffset, int columnsRequested)
{    if (rowOffset < 0) {        throw new IndexException(rowOffset, rowSize());    }    if (rowOffset + rowsRequested > rowSize()) {        throw new IndexException(rowOffset + rowsRequested, rowSize());    }    if (columnOffset < 0) {        throw new IndexException(columnOffset, columnSize());    }    if (columnOffset + columnsRequested > columnSize()) {        throw new IndexException(columnOffset + columnsRequested, columnSize());    }    return new MatrixView(this, new int[] { rowOffset, columnOffset }, new int[] { rowsRequested, columnsRequested });}
public Matrix mahout_f6083_0(double value)
{    for (int row = 0; row < rowSize(); row++) {        Arrays.fill(values[row], value);    }    return this;}
public Matrix mahout_f6084_0(DenseMatrix matrix)
{        if (matrix.values[0].length != this.values[0].length || matrix.values.length != this.values.length) {        this.values = new double[matrix.values.length][matrix.values[0].length];    }        for (int i = 0; i < this.values.length; i++) {        System.arraycopy(matrix.values[i], 0, this.values[i], 0, this.values[0].length);    }    return this;}
public Matrix mahout_f6085_0(int column, Vector other)
{    if (rowSize() != other.size()) {        throw new CardinalityException(rowSize(), other.size());    }    if (column < 0 || column >= columnSize()) {        throw new IndexException(column, columnSize());    }    for (int row = 0; row < rowSize(); row++) {        values[row][column] = other.getQuick(row);    }    return this;}
public Matrix mahout_f6086_0(int row, Vector other)
{    if (columnSize() != other.size()) {        throw new CardinalityException(columnSize(), other.size());    }    if (row < 0 || row >= rowSize()) {        throw new IndexException(row, rowSize());    }    for (int col = 0; col < columnSize(); col++) {        values[row][col] = other.getQuick(col);    }    return this;}
public Vector mahout_f6087_0(int row)
{    if (row < 0 || row >= rowSize()) {        throw new IndexException(row, rowSize());    }    return new DenseVector(values[row], true);}
public MatrixFlavor mahout_f6088_0()
{    return MatrixFlavor.DENSELIKE;}
public double mahout_f6089_0(int row, int column)
{    if (column < row) {        int swap = row;        row = column;        column = swap;    }    return super.getQuick(row, column);}
public void mahout_f6090_0(int row, int column, double value)
{    if (column < row) {        int swap = row;        row = column;        column = swap;    }    super.setQuick(row, column, value);}
public double mahout_f6091_0(Vector x)
{    if (!x.isDense()) {        return super.dot(x);    } else {        int size = x.size();        if (values.length != size) {            throw new CardinalityException(values.length, size);        }        double sum = 0;        for (int n = 0; n < size; n++) {            sum += values[n] * x.getQuick(n);        }        return sum;    }}
protected Matrix mahout_f6092_0(int rows, int columns)
{    return new DenseMatrix(rows, columns);}
public DenseVector mahout_f6093_0()
{    return new DenseVector(values.clone());}
public boolean mahout_f6094_0()
{    return true;}
public boolean mahout_f6095_0()
{    return true;}
protected double mahout_f6096_0()
{    double result = 0.0;    int max = size();    for (int i = 0; i < max; i++) {        result += values[i] * values[i];    }    return result;}
public double mahout_f6097_0(int index)
{    return values[index];}
public DenseVector mahout_f6098_0()
{    return new DenseVector(size());}
public Vector mahout_f6099_0(int cardinality)
{    return new DenseVector(cardinality);}
public void mahout_f6100_0(int index, double value)
{    invalidateCachedLength();    values[index] = value;}
public void mahout_f6101_0(int index, double increment)
{    invalidateCachedLength();    values[index] += increment;}
public Vector mahout_f6102_0(double value)
{    invalidateCachedLength();    Arrays.fill(values, value);    return this;}
public int mahout_f6103_0()
{    return values.length;}
public int mahout_f6104_0()
{    int numNonZeros = 0;    for (int index = 0; index < values.length; index++) {        if (values[index] != 0) {            numNonZeros++;        }    }    return numNonZeros;}
public Vector mahout_f6105_0(DenseVector vector)
{        if (vector.values.length != this.values.length) {        this.values = new double[vector.values.length];    }        System.arraycopy(vector.values, 0, this.values, 0, this.values.length);    return this;}
public void mahout_f6106_0(OrderedIntDoubleMapping updates)
{    int numUpdates = updates.getNumMappings();    int[] indices = updates.getIndices();    double[] values = updates.getValues();    for (int i = 0; i < numUpdates; ++i) {        this.values[indices[i]] = values[i];    }}
public Vector mahout_f6107_0(int offset, int length)
{    if (offset < 0) {        throw new IndexException(offset, size());    }    if (offset + length > size()) {        throw new IndexException(offset + length, size());    }    return new DenseVectorView(this, offset, length);}
public double mahout_f6108_0()
{    return 1;}
public double mahout_f6109_0()
{    return 1;}
public boolean mahout_f6110_0()
{    return true;}
public Iterator<Element> mahout_f6111_0()
{    return new NonDefaultIterator();}
public Iterator<Element> mahout_f6112_0()
{    return new AllIterator();}
public boolean mahout_f6113_0(Object o)
{    if (o instanceof DenseVector) {                return Arrays.equals(values, ((DenseVector) o).values);    }    return super.equals(o);}
public void mahout_f6114_0(Vector v)
{    if (size() != v.size()) {        throw new CardinalityException(size(), v.size());    }    for (Element element : v.nonZeroes()) {        values[element.index()] += element.get();    }}
public boolean mahout_f6115_0()
{    if (lookAheadIndex == index) {                lookAhead();    }        return lookAheadIndex < size();}
private void mahout_f6116_0()
{    lookAheadIndex++;    while (lookAheadIndex < size() && values[lookAheadIndex] == 0.0) {        lookAheadIndex++;    }}
public Element mahout_f6117_0()
{    if (lookAheadIndex == index) {                lookAhead();    }    Preconditions.checkState(lookAheadIndex > index);    index = lookAheadIndex;    if (index >= size()) {                throw new NoSuchElementException();    }    element.index = index;    return element;}
public void mahout_f6118_0()
{    throw new UnsupportedOperationException();}
public boolean mahout_f6119_0()
{    return element.index + 1 < size();}
public Element mahout_f6120_0()
{    if (element.index + 1 >= size()) {                throw new NoSuchElementException();    }    element.index++;    return element;}
public void mahout_f6121_0()
{    throw new UnsupportedOperationException();}
public double mahout_f6122_0()
{    return values[index];}
public int mahout_f6123_0()
{    return index;}
public void mahout_f6124_0(double value)
{    invalidateCachedLength();    values[index] = value;}
public double mahout_f6125_0(Vector x)
{        if (x instanceof DenseVectorView) {        if (size() != x.size())            throw new IllegalArgumentException("Cardinality mismatch during dot(x,y).");        DenseVectorView xv = (DenseVectorView) x;        double[] thisValues = ((DenseVector) vector).values;        double[] thatValues = ((DenseVector) xv.vector).values;        int untilOffset = offset + size();        int i, j;        double sum = 0.0;                int until4 = offset + (size() & ~3);        for (i = offset, j = xv.offset; i < until4; i += 4, j += 4) {            sum += thisValues[i] * thatValues[j] + thisValues[i + 1] * thatValues[j + 1] + thisValues[i + 2] * thatValues[j + 2] + thisValues[i + 3] * thatValues[j + 3];        }                for (i = offset, j = xv.offset; i < untilOffset; ) {            sum += thisValues[i++] * thatValues[j++];        }        return sum;    } else if (x instanceof DenseVector) {        if (size() != x.size())            throw new IllegalArgumentException("Cardinality mismatch during dot(x,y).");        DenseVector xv = (DenseVector) x;        double[] thisValues = ((DenseVector) vector).values;        double[] thatValues = xv.values;        int untilOffset = offset + size();        int i, j;        double sum = 0.0;                int until4 = offset + (size() & ~3);        for (i = offset, j = 0; i < until4; i += 4, j += 4) {            sum += thisValues[i] * thatValues[j] + thisValues[i + 1] * thatValues[j + 1] + thisValues[i + 2] * thatValues[j + 2] + thisValues[i + 3] * thatValues[j + 3];        }                for (; i < untilOffset; ) {            sum += thisValues[i++] * thatValues[j++];        }        return sum;    } else {        return super.dot(x);    }}
public Vector mahout_f6126_0(int offset, int length)
{    if (offset < 0) {        throw new IndexException(offset, size());    }    if (offset + length > size()) {        throw new IndexException(offset + length, size());    }    return new DenseVectorView(vector, offset + this.offset, length);}
public static DiagonalMatrix mahout_f6127_0(int size)
{    return new DiagonalMatrix(1, size);}
public Matrix mahout_f6128_0(int column, Vector other)
{    throw new UnsupportedOperationException("Can't assign a column to a diagonal matrix");}
public Matrix mahout_f6129_0(int row, Vector other)
{    throw new UnsupportedOperationException("Can't assign a row to a diagonal matrix");}
public Vector mahout_f6130_0(int row)
{    return new SingleElementVector(row);}
public Vector mahout_f6131_0(int row)
{    return new SingleElementVector(row);}
public double mahout_f6132_0(int index)
{    if (index == this.index) {        return diagonal.get(index);    } else {        return 0;    }}
public void mahout_f6133_0(int index, double value)
{    if (index == this.index) {        diagonal.set(index, value);    } else {        throw new IllegalArgumentException("Can't set off-diagonal element of diagonal matrix");    }}
protected Iterator<Element> mahout_f6134_0()
{    return new Iterator<Element>() {        boolean more = true;        @Override        public boolean hasNext() {            return more;        }        @Override        public Element next() {            if (more) {                more = false;                return new Element() {                    @Override                    public double get() {                        return diagonal.get(index);                    }                    @Override                    public int index() {                        return index;                    }                    @Override                    public void set(double value) {                        diagonal.set(index, value);                    }                };            } else {                throw new NoSuchElementException("Only one non-zero element in a row or column of a diagonal matrix");            }        }        @Override        public void remove() {            throw new UnsupportedOperationException("Can't remove from vector view");        }    };}
public boolean mahout_f6135_0()
{    return more;}
public Element mahout_f6136_0()
{    if (more) {        more = false;        return new Element() {            @Override            public double get() {                return diagonal.get(index);            }            @Override            public int index() {                return index;            }            @Override            public void set(double value) {                diagonal.set(index, value);            }        };    } else {        throw new NoSuchElementException("Only one non-zero element in a row or column of a diagonal matrix");    }}
public double mahout_f6137_0()
{    return diagonal.get(index);}
public int mahout_f6138_0()
{    return index;}
public void mahout_f6139_0(double value)
{    diagonal.set(index, value);}
public void mahout_f6140_0()
{    throw new UnsupportedOperationException("Can't remove from vector view");}
protected Iterator<Element> mahout_f6141_0()
{    return new Iterator<Element>() {        int i = 0;        Element r = new Element() {            @Override            public double get() {                if (i == index) {                    return diagonal.get(index);                } else {                    return 0;                }            }            @Override            public int index() {                return i;            }            @Override            public void set(double value) {                if (i == index) {                    diagonal.set(index, value);                } else {                    throw new IllegalArgumentException("Can't set any element but diagonal");                }            }        };        @Override        public boolean hasNext() {            return i < diagonal.size() - 1;        }        @Override        public Element next() {            if (i < SingleElementVector.this.size() - 1) {                i++;                return r;            } else {                throw new NoSuchElementException("Attempted to access passed last element of vector");            }        }        @Override        public void remove() {            throw new UnsupportedOperationException("Default operation");        }    };}
public double mahout_f6142_0()
{    if (i == index) {        return diagonal.get(index);    } else {        return 0;    }}
public int mahout_f6143_0()
{    return i;}
public void mahout_f6144_0(double value)
{    if (i == index) {        diagonal.set(index, value);    } else {        throw new IllegalArgumentException("Can't set any element but diagonal");    }}
public boolean mahout_f6145_0()
{    return i < diagonal.size() - 1;}
public Element mahout_f6146_0()
{    if (i < SingleElementVector.this.size() - 1) {        i++;        return r;    } else {        throw new NoSuchElementException("Attempted to access passed last element of vector");    }}
public void mahout_f6147_0()
{    throw new UnsupportedOperationException("Default operation");}
protected Matrix mahout_f6148_0(int rows, int columns)
{    return new DiagonalMatrix(rows, columns);}
public boolean mahout_f6149_0()
{    return false;}
public boolean mahout_f6150_0()
{    return true;}
public void mahout_f6151_0(OrderedIntDoubleMapping updates)
{    throw new UnsupportedOperationException("Default operation");}
public Vector mahout_f6152_0()
{    return new DenseVector(size());}
public Vector mahout_f6153_0(int cardinality)
{    return new DenseVector(cardinality);}
public void mahout_f6154_0(int index, double value)
{    if (index == this.index) {        diagonal.set(this.index, value);    } else {        throw new IllegalArgumentException("Can't set off-diagonal element of DiagonalMatrix");    }}
public int mahout_f6155_0()
{    return 1;}
public double mahout_f6156_0()
{    return 0;}
public double mahout_f6157_0()
{    return 1;}
public boolean mahout_f6158_0()
{    return false;}
public Vector mahout_f6159_0()
{    return this.diagonal;}
public double mahout_f6160_0(int row, int column)
{    if (row == column) {        return diagonal.get(row);    } else {        return 0;    }}
public Matrix mahout_f6161_0()
{    return new SparseRowMatrix(rowSize(), columnSize());}
public Matrix mahout_f6162_0(int rows, int columns)
{    return new SparseRowMatrix(rows, columns);}
public void mahout_f6163_0(int row, int column, double value)
{    if (row == column) {        diagonal.set(row, value);    } else {        throw new UnsupportedOperationException("Can't set off-diagonal element");    }}
public int[] mahout_f6164_0()
{    throw new UnsupportedOperationException("Don't understand how to implement this");}
public Matrix mahout_f6165_0(int[] offset, int[] size)
{    return new MatrixView(this, offset, size);}
public Matrix mahout_f6166_0(Matrix other)
{    return timesRight(other);}
public Matrix mahout_f6167_0(Matrix that)
{    if (that.numRows() != diagonal.size()) {        throw new IllegalArgumentException("Incompatible number of rows in the right operand of matrix multiplication.");    }    Matrix m = that.like();    for (int row = 0; row < diagonal.size(); row++) {        m.assignRow(row, that.viewRow(row).times(diagonal.getQuick(row)));    }    return m;}
public Matrix mahout_f6168_0(Matrix that)
{    if (that.numCols() != diagonal.size()) {        throw new IllegalArgumentException("Incompatible number of rows in the left operand of matrix-matrix multiplication.");    }    Matrix m = that.like();    for (int col = 0; col < diagonal.size(); col++) {        m.assignColumn(col, that.viewColumn(col).times(diagonal.getQuick(col)));    }    return m;}
public MatrixFlavor mahout_f6169_0()
{    return MatrixFlavor.DIAGONALLIKE;}
private void mahout_f6170_0(DoubleBuffer content)
{    this.content.add(content);}
public void mahout_f6171_0(File f, boolean loadNow) throws IOException
{    Preconditions.checkArgument(f.length() == rows * columns * 8L, "File " + f + " is wrong length");    for (int i = 0; i < (rows + rowsPerBlock - 1) / rowsPerBlock; i++) {        long start = i * rowsPerBlock * columns * 8L;        long size = rowsPerBlock * columns * 8L;        MappedByteBuffer buf = new FileInputStream(f).getChannel().map(FileChannel.MapMode.READ_ONLY, start, Math.min(f.length() - start, size));        if (loadNow) {            buf.load();        }        addData(buf.asDoubleBuffer());    }}
public static void mahout_f6172_0(File f, Matrix m) throws IOException
{    Preconditions.checkArgument(f.canWrite(), "Can't write to output file");    FileOutputStream fos = new FileOutputStream(f);    try {        ByteBuffer buf = ByteBuffer.allocate(m.columnSize() * 8);        for (MatrixSlice row : m) {            buf.clear();            for (Vector.Element element : row.vector().all()) {                buf.putDouble(element.get());            }            buf.flip();            fos.write(buf.array());        }    } finally {        fos.close();    }}
public Matrix mahout_f6173_0(int column, Vector other)
{    throw new UnsupportedOperationException("Default operation");}
public Matrix mahout_f6174_0(int row, Vector other)
{    throw new UnsupportedOperationException("Default operation");}
public double mahout_f6175_0(int row, int column)
{    int block = row / rowsPerBlock;    return content.get(block).get((row % rowsPerBlock) * columns + column);}
public Matrix mahout_f6176_0()
{    throw new UnsupportedOperationException("Default operation");}
public Matrix mahout_f6177_0(int rows, int columns)
{    return new DenseMatrix(rows, columns);}
public void mahout_f6178_0(int row, int column, double value)
{    throw new UnsupportedOperationException("Default operation");}
public Matrix mahout_f6179_0(int[] offset, int[] size)
{    throw new UnsupportedOperationException("Default operation");}
public void mahout_f6180_0(File f) throws IOException
{    List<ByteBuffer> buffers = Lists.newArrayList();    FileChannel input = new FileInputStream(f).getChannel();    buffers.add(input.map(FileChannel.MapMode.READ_ONLY, 0, Math.min(Integer.MAX_VALUE, f.length())));    data.add(buffers.get(0).asIntBuffer());    Preconditions.checkArgument(buffers.get(0).getInt() == MAGIC_NUMBER_V0, "Wrong type of file");    int rows = buffers.get(0).getInt();    int cols = buffers.get(0).getInt();    Preconditions.checkArgument(rows == rowSize());    Preconditions.checkArgument(cols == columnSize());    rowOffset = new int[rows];    rowSize = new int[rows];    bufferIndex = new int[rows];    int offset = 12 + 4 * rows;    for (int i = 0; i < rows; i++) {        int size = buffers.get(0).getInt();        int buffer = 0;        while (buffer < buffers.size()) {            if (offset + size * 4 <= buffers.get(buffer).limit()) {                break;            } else {                offset -= buffers.get(buffer).capacity();            }        }        if (buffer == buffers.size()) {            buffers.add(input.map(FileChannel.MapMode.READ_ONLY, 0, Math.min(Integer.MAX_VALUE, f.length() - offset)));            data.add(buffers.get(buffer).asIntBuffer());        }        rowOffset[i] = offset / 4;        rowSize[i] = size;        bufferIndex[i] = buffer;                        offset += size * 4;    }}
public static void mahout_f6181_0(File f, Matrix m) throws IOException
{    Preconditions.checkArgument(f.canWrite(), "Can't write to output file");    FileOutputStream fos = new FileOutputStream(f);        DataOutputStream out = new DataOutputStream(fos);    out.writeInt(MAGIC_NUMBER_V0);    out.writeInt(m.rowSize());    out.writeInt(m.columnSize());        for (MatrixSlice row : m) {        int nondefaultElements = row.vector().getNumNondefaultElements();        out.writeInt(nondefaultElements);    }        for (MatrixSlice row : m) {        List<Integer> columns = Lists.newArrayList(Iterables.transform(row.vector().nonZeroes(), new Function<Vector.Element, Integer>() {            @Override            public Integer apply(Vector.Element element) {                return element.index();            }        }));        Collections.sort(columns);        for (Integer column : columns) {            out.writeInt(column);        }    }    out.close();    fos.close();}
public Integer mahout_f6182_0(Vector.Element element)
{    return element.index();}
public Matrix mahout_f6183_0(int column, Vector other)
{    throw new UnsupportedOperationException("Default operation");}
public Matrix mahout_f6184_0(int row, Vector other)
{    throw new UnsupportedOperationException("Default operation");}
public double mahout_f6185_0(int rowIndex, int columnIndex)
{    IntBuffer tmp = data.get(bufferIndex[rowIndex]).asReadOnlyBuffer();    tmp.position(rowOffset[rowIndex]);    tmp.limit(rowSize[rowIndex]);    tmp = tmp.slice();    return searchForIndex(tmp, columnIndex);}
private static double mahout_f6186_0(IntBuffer row, int columnIndex)
{    int high = row.limit();    if (high == 0) {        return 0;    }    int low = 0;    while (high > low) {        int mid = (low + high) / 2;        if (row.get(mid) < columnIndex) {            low = mid + 1;        } else {            high = mid;        }    }    if (low >= row.limit()) {        return 0;    } else if (high == low && row.get(low) == columnIndex) {        return 1;    } else {        return 0;    }}
public Matrix mahout_f6187_0()
{    throw new UnsupportedOperationException("Default operation");}
public Matrix mahout_f6188_0(int rows, int columns)
{    return new DenseMatrix(rows, columns);}
public void mahout_f6189_0(int row, int column, double value)
{    throw new UnsupportedOperationException("Default operation");}
public Matrix mahout_f6190_0(int[] offset, int[] size)
{    throw new UnsupportedOperationException("Default operation");}
public Vector mahout_f6191_0(int rowIndex)
{    IntBuffer tmp = data.get(bufferIndex[rowIndex]).asReadOnlyBuffer();    tmp.position(rowOffset[rowIndex]);    tmp.limit(rowOffset[rowIndex] + rowSize[rowIndex]);    tmp = tmp.slice();    return new SparseBinaryVector(tmp, columnSize());}
protected Matrix mahout_f6192_0(int rows, int columns)
{    throw new UnsupportedOperationException("Default operation");}
public void mahout_f6193_0(OrderedIntDoubleMapping updates)
{    throw new UnsupportedOperationException("Cannot mutate SparseBinaryVector");}
public boolean mahout_f6194_0()
{    return false;}
public boolean mahout_f6195_0()
{    return true;}
public Iterator<Element> mahout_f6196_0()
{    return new AbstractIterator<Element>() {        int i = 0;        @Override        protected Element computeNext() {            if (i < maxIndex) {                return new Element() {                    int index = i++;                    /**                     * @return the value of this vector element.                     */                    @Override                    public double get() {                        return getQuick(index);                    }                    /**                     * @return the index of this vector element.                     */                    @Override                    public int index() {                        return index;                    }                    /**                     * @param value Set the current element to value.                     */                    @Override                    public void set(double value) {                        throw new UnsupportedOperationException("Default operation");                    }                };            } else {                return endOfData();            }        }    };}
protected Element mahout_f6197_0()
{    if (i < maxIndex) {        return new Element() {            int index = i++;            /**             * @return the value of this vector element.             */            @Override            public double get() {                return getQuick(index);            }            /**             * @return the index of this vector element.             */            @Override            public int index() {                return index;            }            /**             * @param value Set the current element to value.             */            @Override            public void set(double value) {                throw new UnsupportedOperationException("Default operation");            }        };    } else {        return endOfData();    }}
public double mahout_f6198_0()
{    return getQuick(index);}
public int mahout_f6199_0()
{    return index;}
public void mahout_f6200_0(double value)
{    throw new UnsupportedOperationException("Default operation");}
public Iterator<Element> mahout_f6201_0()
{    return new AbstractIterator<Element>() {        int i = 0;        @Override        protected Element computeNext() {            if (i < buffer.limit()) {                return new BinaryReadOnlyElement(buffer.get(i++));            } else {                return endOfData();            }        }    };}
protected Element mahout_f6202_0()
{    if (i < buffer.limit()) {        return new BinaryReadOnlyElement(buffer.get(i++));    } else {        return endOfData();    }}
public double mahout_f6203_0(int index)
{    return searchForIndex(buffer, index);}
public Vector mahout_f6204_0()
{    return new RandomAccessSparseVector(size());}
public Vector mahout_f6205_0(int cardinality)
{    return new RandomAccessSparseVector(cardinality);}
protected Vector mahout_f6206_0()
{    return new RandomAccessSparseVector(size()).assign(this);}
public void mahout_f6207_0(int index, double value)
{    throw new UnsupportedOperationException("Read-only view");}
public void mahout_f6208_0(int index, double increment)
{    throw new UnsupportedOperationException("Read-only view");}
public int mahout_f6209_0()
{    return buffer.limit();}
public double mahout_f6210_0()
{    return 1;}
public double mahout_f6211_0()
{    return 1;}
public boolean mahout_f6212_0()
{    throw new UnsupportedOperationException("Can't add binary value");}
public double mahout_f6213_0()
{    return 1;}
public int mahout_f6214_0()
{    return index;}
public void mahout_f6215_0(double value)
{    throw new UnsupportedOperationException("Can't set binary value");}
public BackEnum mahout_f6216_0()
{    return pBacking;}
public TraversingStructureEnum mahout_f6217_0()
{    return pStructure;}
public boolean mahout_f6218_0()
{    return pDense;}
public boolean mahout_f6219_0()
{    return false;}
public boolean mahout_f6220_0()
{    return false;}
public boolean mahout_f6221_0()
{    return false;}
public boolean mahout_f6222_0()
{    return isLikeLeftMult() && isLikeRightMult();}
public boolean mahout_f6223_0()
{    return false;}
public boolean mahout_f6224_0()
{    return false;}
public boolean mahout_f6225_0()
{    return isAssociative() && isCommutative();}
public boolean mahout_f6226_0()
{    return apply(0.0, 0.0) != 0.0;}
public boolean mahout_f6227_0()
{    return Math.abs(apply(0.0)) != 0.0;}
public double mahout_f6228_0(double a)
{    return Math.abs(a);}
public double mahout_f6229_0(double a)
{    return Math.acos(a);}
public double mahout_f6230_0(double a)
{    return Math.asin(a);}
public double mahout_f6231_0(double a)
{    return Math.atan(a);}
public double mahout_f6232_0(double a)
{    return Math.ceil(a);}
public double mahout_f6233_0(double a)
{    return Math.cos(a);}
public double mahout_f6234_0(double a)
{    return Math.exp(a);}
public double mahout_f6235_0(double a)
{    return Math.floor(a);}
public double mahout_f6236_0(double a)
{    return a;}
public double mahout_f6237_0(double a)
{    return 1.0 / a;}
public double mahout_f6238_0(double a)
{    return Math.log(a);}
public double mahout_f6239_0(double a)
{    return Math.log(a) * 1.4426950408889634;}
public double mahout_f6240_0(double a)
{    return -a;}
public double mahout_f6241_0(double a)
{    return Math.rint(a);}
public double mahout_f6242_0(double a)
{    return a < 0 ? -1 : a > 0 ? 1 : 0;}
public double mahout_f6243_0(double a)
{    return Math.sin(a);}
public double mahout_f6244_0(double a)
{    return Math.sqrt(a);}
public double mahout_f6245_0(double a)
{    return a * a;}
public double mahout_f6246_0(double a)
{    return 1.0 / (1.0 + Math.exp(-a));}
public double mahout_f6247_0(double a)
{    return a * (1.0 - a);}
public double mahout_f6248_0(double a)
{    return Math.tan(a);}
public double mahout_f6249_0(double a, double b)
{    return Math.atan2(a, b);}
public double mahout_f6250_0(double a, double b)
{    return a < b ? -1 : a > b ? 1 : 0;}
public double mahout_f6251_0(double a, double b)
{    return a / b;}
public boolean mahout_f6252_0()
{    return false;}
public boolean mahout_f6253_0()
{    return false;}
public boolean mahout_f6254_0()
{    return false;}
public boolean mahout_f6255_0()
{    return false;}
public boolean mahout_f6256_0()
{    return false;}
public double mahout_f6257_0(double a, double b)
{    return a == b ? 1 : 0;}
public boolean mahout_f6258_0()
{    return true;}
public double mahout_f6259_0(double a, double b)
{    return a > b ? 1 : 0;}
public double mahout_f6260_0(double a, double b)
{    return Math.IEEEremainder(a, b);}
public boolean mahout_f6261_0(double a, double b)
{    return a == b;}
public boolean mahout_f6262_0(double a, double b)
{    return a < b;}
public boolean mahout_f6263_0(double a, double b)
{    return a > b;}
public double mahout_f6264_0(double a, double b)
{    return a < b ? 1 : 0;}
public double mahout_f6265_0(double a, double b)
{    return Math.log(a) / Math.log(b);}
public double mahout_f6266_0(double a, double b)
{    return Math.max(a, b);}
public boolean mahout_f6267_0()
{    return false;}
public boolean mahout_f6268_0()
{    return false;}
public boolean mahout_f6269_0()
{    return false;}
public boolean mahout_f6270_0()
{    return true;}
public boolean mahout_f6271_0()
{    return true;}
public double mahout_f6272_0(double a, double b)
{    return Math.max(Math.abs(a), Math.abs(b));}
public boolean mahout_f6273_0()
{    return true;}
public boolean mahout_f6274_0()
{    return false;}
public boolean mahout_f6275_0()
{    return false;}
public boolean mahout_f6276_0()
{    return true;}
public boolean mahout_f6277_0()
{    return true;}
public double mahout_f6278_0(double a, double b)
{    return Math.min(a, b);}
public boolean mahout_f6279_0()
{    return false;}
public boolean mahout_f6280_0()
{    return false;}
public boolean mahout_f6281_0()
{    return false;}
public boolean mahout_f6282_0()
{    return true;}
public boolean mahout_f6283_0()
{    return true;}
public double mahout_f6284_0(double x, double y)
{    return (x - y) * (x - y);}
public boolean mahout_f6285_0()
{    return false;}
public boolean mahout_f6286_0()
{    return false;}
public boolean mahout_f6287_0()
{    return false;}
public boolean mahout_f6288_0()
{    return true;}
public boolean mahout_f6289_0()
{    return false;}
public double mahout_f6290_0(double a, double b)
{    return a % b;}
public double mahout_f6291_0(double a, double b)
{    return Math.abs(a) + Math.abs(b);}
public boolean mahout_f6292_0()
{    return false;}
public boolean mahout_f6293_0()
{    return false;}
public boolean mahout_f6294_0()
{    return false;}
public boolean mahout_f6295_0()
{    return true;}
public boolean mahout_f6296_0()
{    return true;}
public double mahout_f6297_0(double x, double y)
{    return Math.abs(x - y);}
public boolean mahout_f6298_0()
{    return false;}
public boolean mahout_f6299_0()
{    return false;}
public boolean mahout_f6300_0()
{    return false;}
public boolean mahout_f6301_0()
{    return true;}
public boolean mahout_f6302_0()
{    return false;}
public double mahout_f6303_0(double a, double b)
{    return Math.pow(a, b);}
public boolean mahout_f6304_0()
{    return false;}
public boolean mahout_f6305_0()
{    return false;}
public boolean mahout_f6306_0()
{    return false;}
public boolean mahout_f6307_0()
{    return false;}
public boolean mahout_f6308_0()
{    return false;}
public double mahout_f6309_0(double x, double y)
{    return y;}
public boolean mahout_f6310_0()
{    return false;}
public boolean mahout_f6311_0()
{    return false;}
public boolean mahout_f6312_0()
{    return true;}
public boolean mahout_f6313_0()
{    return false;}
public boolean mahout_f6314_0()
{    return true;}
public double mahout_f6315_0(double x, double y)
{    Preconditions.checkArgument(x == 0, "This special version of SECOND needs x == 0");    return y;}
public boolean mahout_f6316_0()
{    return true;}
public boolean mahout_f6317_0()
{    return false;}
public boolean mahout_f6318_0()
{    return true;}
public boolean mahout_f6319_0()
{    return false;}
public boolean mahout_f6320_0()
{    return true;}
public double mahout_f6321_0(double x, double y)
{    return x * x * y;}
public boolean mahout_f6322_0()
{    return false;}
public boolean mahout_f6323_0()
{    return true;}
public boolean mahout_f6324_0()
{    return true;}
public boolean mahout_f6325_0()
{    return false;}
public boolean mahout_f6326_0()
{    return false;}
public double mahout_f6327_0(double x, double y)
{    return x * (y + 1);}
public boolean mahout_f6328_0()
{    return true;}
public boolean mahout_f6329_0()
{    return true;}
public boolean mahout_f6330_0()
{    return false;}
public boolean mahout_f6331_0()
{    return false;}
public boolean mahout_f6332_0()
{    return false;}
public static DoubleDoubleFunction mahout_f6333_0(final double wx, final double wy)
{    final double tw = wx + wy;    return new DoubleDoubleFunction() {        @Override        public double apply(double x, double y) {            return (wx * x + wy * y) / tw;        }        /**         * f(x, 0) = wx * x / tw = x iff wx = tw (practically, impossible, as tw = wx + wy and wy > 0)         * @return true iff f(x, 0) = x for any x         */        @Override        public boolean isLikeRightPlus() {            return wx == tw;        }        /**         * f(0, y) = wy * y / tw = 0 iff y = 0         * @return true iff f(0, y) = 0 for any y         */        @Override        public boolean isLikeLeftMult() {            return false;        }        /**         * f(x, 0) = wx * x / tw = 0 iff x = 0         * @return true iff f(x, 0) = 0 for any x         */        @Override        public boolean isLikeRightMult() {            return false;        }        /**         * wx * x + wy * y = wx * y + wy * x iff wx = wy         * @return true iff f(x, y) = f(y, x) for any x, y         */        @Override        public boolean isCommutative() {            return wx == wy;        }        /**         * @return true iff f(x, f(y, z)) = f(f(x, y), z) for any x, y, z         */        @Override        public boolean isAssociative() {            return false;        }    };}
public double mahout_f6334_0(double x, double y)
{    return (wx * x + wy * y) / tw;}
public boolean mahout_f6335_0()
{    return wx == tw;}
public boolean mahout_f6336_0()
{    return false;}
public boolean mahout_f6337_0()
{    return false;}
public boolean mahout_f6338_0()
{    return wx == wy;}
public boolean mahout_f6339_0()
{    return false;}
public static DoubleFunction mahout_f6340_0(final double from, final double to)
{    return new DoubleFunction() {        @Override        public double apply(double a) {            return from <= a && a <= to ? 1 : 0;        }    };}
public double mahout_f6341_0(double a)
{    return from <= a && a <= to ? 1 : 0;}
public static DoubleFunction mahout_f6342_0(final DoubleDoubleFunction function, final double c)
{    return new DoubleFunction() {        @Override        public double apply(double var) {            return function.apply(c, var);        }    };}
public double mahout_f6343_0(double var)
{    return function.apply(c, var);}
public static DoubleFunction mahout_f6344_0(final DoubleDoubleFunction function, final double c)
{    return new DoubleFunction() {        @Override        public double apply(double var) {            return function.apply(var, c);        }    };}
public double mahout_f6345_0(double var)
{    return function.apply(var, c);}
public static DoubleDoubleFunction mahout_f6346_0(final DoubleDoubleFunction f, final DoubleFunction g, final DoubleFunction h)
{    return new DoubleDoubleFunction() {        @Override        public double apply(double a, double b) {            return f.apply(g.apply(a), h.apply(b));        }        /**         * fx(c, 0) = f(g(x), h(0)) = f(g(x), 0) = g(x) = x if h(0) = 0 and f isLikeRightPlus and g(x) = x         * Impossible to check whether g(x) = x for any x, so we return false.         * @return true iff f(x, 0) = x for any x         */        @Override        public boolean isLikeRightPlus() {            return false;        }        /**         * fc(0, y) = f(g(0), h(y)) = f(0, h(y)) = 0 if g(0) = 0 and f isLikeLeftMult         * @return true iff f(0, y) = 0 for any y         */        @Override        public boolean isLikeLeftMult() {            return g.apply(0) == 0 && f.isLikeLeftMult();        }        /**         * fc(x, 0) = f(g(x), h(0)) = f(g(x), 0) = 0 if h(0) = 0 and f isLikeRightMult         * @return true iff f(x, 0) = 0 for any x         */        @Override        public boolean isLikeRightMult() {            return h.apply(0) == 0 && f.isLikeRightMult();        }        /**         * fc(x, y) = f(g(x), h(y)) = f(h(y), g(x))         * fc(y, x) = f(g(y), h(x)) = f(h(x), g(y))         * Either g(x) = g(y) for any x, y and h(x) = h(y) for any x, y or g = h and f isCommutative.         * Can only check if g = h (reference equality, assuming they're both the same static function in         * this file) and f isCommutative. There are however other scenarios when this might happen that are NOT         * covered by this definition.         * @return true iff f(x, y) = f(y, x) for any x, y         */        @Override        public boolean isCommutative() {            return g.equals(h) && f.isCommutative();        }        /**         * fc(x, fc(y, z)) = f(g(x), h(f(g(y), h(z))))         * fc(fc(x, y), z) = f(g(f(g(x), h(y))), h(z))         * Impossible to check.         * @return true iff f(x, f(y, z)) = f(f(x, y), z) for any x, y, z         */        @Override        public boolean isAssociative() {            return false;        }    };}
public double mahout_f6347_0(double a, double b)
{    return f.apply(g.apply(a), h.apply(b));}
public boolean mahout_f6348_0()
{    return false;}
public boolean mahout_f6349_0()
{    return g.apply(0) == 0 && f.isLikeLeftMult();}
public boolean mahout_f6350_0()
{    return h.apply(0) == 0 && f.isLikeRightMult();}
public boolean mahout_f6351_0()
{    return g.equals(h) && f.isCommutative();}
public boolean mahout_f6352_0()
{    return false;}
public static DoubleDoubleFunction mahout_f6353_0(final DoubleFunction g, final DoubleDoubleFunction h)
{    return new DoubleDoubleFunction() {        @Override        public double apply(double a, double b) {            return g.apply(h.apply(a, b));        }        /**         * g(h(x, 0)) = g(x) = x for any x iff g(x) = x and h isLikeRightPlus         * Impossible to check.         * @return true iff f(x, 0) = x for any x         */        @Override        public boolean isLikeRightPlus() {            return false;        }        /**         * g(h(0, y)) = g(0) = 0 for any y iff g(0) = 0 and h isLikeLeftMult         * @return true iff f(0, y) = 0 for any y         */        @Override        public boolean isLikeLeftMult() {            return !g.isDensifying() && h.isLikeLeftMult();        }        /**         * g(h(x, 0)) = g(0) = 0 for any x iff g(0) = 0 and h isLikeRightMult         * @return true iff f(x, 0) = 0 for any x         */        @Override        public boolean isLikeRightMult() {            return !g.isDensifying() && h.isLikeRightMult();        }        /**         * fc(x, y) = g(h(x, y)) = g(h(y, x)) = fc(y, x) iff h isCommutative         * @return true iff f(x, y) = f(y, x) for any x, y         */        @Override        public boolean isCommutative() {            return h.isCommutative();        }        /**         * fc(x, fc(y, z)) = g(h(x, g(h(y, z)))         * fc(fc(x, y), z) = g(h(g(h(x, y)), z))         * Impossible to check.         * @return true iff f(x, f(y, z)) = f(f(x, y), z) for any x, y, z         */        @Override        public boolean isAssociative() {            return false;        }    };}
public double mahout_f6354_0(double a, double b)
{    return g.apply(h.apply(a, b));}
public boolean mahout_f6355_0()
{    return false;}
public boolean mahout_f6356_0()
{    return !g.isDensifying() && h.isLikeLeftMult();}
public boolean mahout_f6357_0()
{    return !g.isDensifying() && h.isLikeRightMult();}
public boolean mahout_f6358_0()
{    return h.isCommutative();}
public boolean mahout_f6359_0()
{    return false;}
public static DoubleFunction mahout_f6360_0(final DoubleFunction g, final DoubleFunction h)
{    return new DoubleFunction() {        @Override        public double apply(double a) {            return g.apply(h.apply(a));        }    };}
public double mahout_f6361_0(double a)
{    return g.apply(h.apply(a));}
public static IntIntFunction mahout_f6362_0(final DoubleFunction g, final IntIntFunction h)
{    return new IntIntFunction() {        @Override        public double apply(int first, int second) {            return g.apply(h.apply(first, second));        }    };}
public double mahout_f6363_0(int first, int second)
{    return g.apply(h.apply(first, second));}
public static DoubleFunction mahout_f6364_0(final double b)
{    return new DoubleFunction() {        @Override        public double apply(double a) {            return a < b ? -1 : a > b ? 1 : 0;        }    };}
public double mahout_f6365_0(double a)
{    return a < b ? -1 : a > b ? 1 : 0;}
public static DoubleFunction mahout_f6366_0(final double c)
{    return new DoubleFunction() {        @Override        public double apply(double a) {            return c;        }    };}
public double mahout_f6367_0(double a)
{    return c;}
public static DoubleFunction mahout_f6368_0(double b)
{    return mult(1 / b);}
public static DoubleFunction mahout_f6369_0(final double b)
{    return new DoubleFunction() {        @Override        public double apply(double a) {            return a == b ? 1 : 0;        }    };}
public double mahout_f6370_0(double a)
{    return a == b ? 1 : 0;}
public static DoubleFunction mahout_f6371_0(final double b)
{    return new DoubleFunction() {        @Override        public double apply(double a) {            return a != b ? 1 : 0;        }    };}
public double mahout_f6372_0(double a)
{    return a != b ? 1 : 0;}
public static DoubleFunction mahout_f6373_0(final double b)
{    return new DoubleFunction() {        @Override        public double apply(double a) {            return a > b ? 1 : 0;        }    };}
public double mahout_f6374_0(double a)
{    return a > b ? 1 : 0;}
public static DoubleFunction mahout_f6375_0(final double b)
{    return new DoubleFunction() {        @Override        public double apply(double a) {            return Math.IEEEremainder(a, b);        }    };}
public double mahout_f6376_0(double a)
{    return Math.IEEEremainder(a, b);}
public static DoubleProcedure mahout_f6377_0(final double from, final double to)
{    return new DoubleProcedure() {        @Override        public boolean apply(double a) {            return from <= a && a <= to;        }    };}
public boolean mahout_f6378_0(double a)
{    return from <= a && a <= to;}
public static DoubleProcedure mahout_f6379_0(final double b)
{    return new DoubleProcedure() {        @Override        public boolean apply(double a) {            return a == b;        }    };}
public boolean mahout_f6380_0(double a)
{    return a == b;}
public static DoubleProcedure mahout_f6381_0(final double b)
{    return new DoubleProcedure() {        @Override        public boolean apply(double a) {            return a > b;        }    };}
public boolean mahout_f6382_0(double a)
{    return a > b;}
public static DoubleProcedure mahout_f6383_0(final double b)
{    return new DoubleProcedure() {        @Override        public boolean apply(double a) {            return a < b;        }    };}
public boolean mahout_f6384_0(double a)
{    return a < b;}
public static DoubleFunction mahout_f6385_0(final double b)
{    return new DoubleFunction() {        @Override        public double apply(double a) {            return a < b ? 1 : 0;        }    };}
public double mahout_f6386_0(double a)
{    return a < b ? 1 : 0;}
public static DoubleFunction mahout_f6387_0(final double b)
{    return new DoubleFunction() {                private final double logInv = 1 / Math.log(b);        @Override        public double apply(double a) {            return Math.log(a) * logInv;        }    };}
public double mahout_f6388_0(double a)
{    return Math.log(a) * logInv;}
public static DoubleFunction mahout_f6389_0(final double b)
{    return new DoubleFunction() {        @Override        public double apply(double a) {            return Math.max(a, b);        }    };}
public double mahout_f6390_0(double a)
{    return Math.max(a, b);}
public static DoubleFunction mahout_f6391_0(final double b)
{    return new DoubleFunction() {        @Override        public double apply(double a) {            return Math.min(a, b);        }    };}
public double mahout_f6392_0(double a)
{    return Math.min(a, b);}
public static DoubleFunction mahout_f6393_0(double b)
{    return plus(-b);}
public static DoubleDoubleFunction mahout_f6394_0(double constant)
{    return plusMult(-constant);}
public static DoubleFunction mahout_f6395_0(final double b)
{    return new DoubleFunction() {        @Override        public double apply(double a) {            return a % b;        }    };}
public double mahout_f6396_0(double a)
{    return a % b;}
public static DoubleFunction mahout_f6397_0(double b)
{    return new Mult(b);/*    return new DoubleFunction() {      public final double apply(double a) { return a * b; }    };    */}
public static DoubleFunction mahout_f6398_0(final double b)
{    return new DoubleFunction() {        @Override        public double apply(double a) {            return a + b;        }    };}
public double mahout_f6399_0(double a)
{    return a + b;}
public static DoubleDoubleFunction mahout_f6400_0(double constant)
{    return new PlusMult(constant);}
public static DoubleFunction mahout_f6401_0(final double b)
{    return new DoubleFunction() {        @Override        public double apply(double a) {            if (b == 2) {                return a * a;            } else {                return Math.pow(a, b);            }        }    };}
public double mahout_f6402_0(double a)
{    if (b == 2) {        return a * a;    } else {        return Math.pow(a, b);    }}
public static DoubleFunction mahout_f6403_0()
{    return new MersenneTwister(new Date());}
public static DoubleFunction mahout_f6404_0(final double precision)
{    return new DoubleFunction() {        @Override        public double apply(double a) {            return Math.rint(a / precision) * precision;        }    };}
public double mahout_f6405_0(double a)
{    return Math.rint(a / precision) * precision;}
public static DoubleDoubleFunction mahout_f6406_0(final DoubleDoubleFunction function)
{    return new DoubleDoubleFunction() {        @Override        public double apply(double a, double b) {            return function.apply(b, a);        }    };}
public double mahout_f6407_0(double a, double b)
{    return function.apply(b, a);}
public static DoubleDoubleFunction mahout_f6408_0(final double exponent)
{    return new DoubleDoubleFunction() {        @Override        public double apply(double x, double y) {            return Math.pow(Math.abs(x - y), exponent);        }        /**         * |x - 0|^p = |x|^p != x unless x > 0 and p = 1         * @return true iff f(x, 0) = x for any x         */        @Override        public boolean isLikeRightPlus() {            return false;        }        /**         * |0 - y|^p = |y|^p         * @return true iff f(0, y) = 0 for any y         */        @Override        public boolean isLikeLeftMult() {            return false;        }        /**         * |x - 0|^p = |x|^p         * @return true iff f(x, 0) = 0 for any x         */        @Override        public boolean isLikeRightMult() {            return false;        }        /**         * |x - y|^p = |y - x|^p         * @return true iff f(x, y) = f(y, x) for any x, y         */        @Override        public boolean isCommutative() {            return true;        }        /**         * |x - |y - z|^p|^p != ||x - y|^p - z|^p         * @return true iff f(x, f(y, z)) = f(f(x, y), z) for any x, y, z         */        @Override        public boolean isAssociative() {            return false;        }    };}
public double mahout_f6409_0(double x, double y)
{    return Math.pow(Math.abs(x - y), exponent);}
public boolean mahout_f6410_0()
{    return false;}
public boolean mahout_f6411_0()
{    return false;}
public boolean mahout_f6412_0()
{    return false;}
public boolean mahout_f6413_0()
{    return true;}
public boolean mahout_f6414_0()
{    return false;}
public double mahout_f6415_0(double a)
{    return a * multiplicator;}
public static Mult mahout_f6416_0(double constant)
{    return mult(1 / constant);}
public static Mult mahout_f6417_0(double constant)
{    return new Mult(constant);}
public double mahout_f6418_0()
{    return multiplicator;}
public void mahout_f6419_0(double multiplicator)
{    this.multiplicator = multiplicator;}
public double mahout_f6420_0(double a, double b)
{    return a + b * multiplicator;}
public static PlusMult mahout_f6421_0(double constant)
{    return new PlusMult(-constant);}
public static PlusMult mahout_f6422_0(double constant)
{    return new PlusMult(constant);}
public double mahout_f6423_0()
{    return multiplicator;}
public boolean mahout_f6424_0()
{    return true;}
public boolean mahout_f6425_0()
{    return false;}
public boolean mahout_f6426_0()
{    return false;}
public boolean mahout_f6427_0()
{    return Math.abs(multiplicator - 1.0) < Constants.EPSILON;}
public boolean mahout_f6428_0()
{    return Math.abs(multiplicator - 0.0) < Constants.EPSILON || Math.abs(multiplicator - 1.0) < Constants.EPSILON;}
public void mahout_f6429_0(double multiplicator)
{    this.multiplicator = multiplicator;}
public double mahout_f6430_0(double arg1)
{    return Math.sqrt(arg1);}
public double mahout_f6431_0(double x, double y)
{    return x * y;}
public boolean mahout_f6432_0()
{    return false;}
public boolean mahout_f6433_0()
{    return true;}
public boolean mahout_f6434_0()
{    return true;}
public boolean mahout_f6435_0()
{    return true;}
public boolean mahout_f6436_0()
{    return true;}
public Matrix mahout_f6437_0(int column, Vector other)
{    throw new UnsupportedOperationException("Assignment to a matrix not supported");}
public Matrix mahout_f6438_0(int row, Vector other)
{    throw new UnsupportedOperationException("Assignment to a matrix view not supported");}
public double mahout_f6439_0(int row, int column)
{    return gf.apply(row, column);}
public Matrix mahout_f6440_0()
{    return like(rows, columns);}
public Matrix mahout_f6441_0(int rows, int columns)
{    if (denseLike)        return new DenseMatrix(rows, columns);    else        return new SparseMatrix(rows, columns);}
public void mahout_f6442_0(int row, int column, double value)
{    throw new UnsupportedOperationException("Assignment to a matrix view not supported");}
public Vector mahout_f6443_0(int row)
{    return new MatrixVectorView(this, row, 0, 0, 1, denseLike);}
public Vector mahout_f6444_0(int column)
{    return new MatrixVectorView(this, 0, column, 1, 0, denseLike);}
public MatrixFlavor mahout_f6445_0()
{    return flavor;}
public static double mahout_f6446_0(long n, long k)
{    if (k < 0) {        return 0;    }    if (k == 0 || k == n) {        return 1;    }    if (k == 1 || k == n - 1) {        return n;    }        if (n > k) {        int max = FACTORIAL_TABLE.length + LARGE_FACTORIAL_TABLE.length;        if (n < max) {                        double nFactorial = factorial((int) n);            double kFactorial = factorial((int) k);            double nMinusKFactorial = factorial((int) (n - k));            double nk = nMinusKFactorial * kFactorial;            if (nk != Double.POSITIVE_INFINITY) {                                return nFactorial / nk;            }        }        if (k > n / 2) {            k = n - k;        }        }        long a = n - k + 1;    long b = 1;    double binomial = 1;    for (long i = k; i-- > 0; ) {        binomial *= (double) a++ / b++;    }    return binomial;}
private static double mahout_f6447_0(int k)
{    if (k < 0) {        throw new IllegalArgumentException();    }    int length1 = FACTORIAL_TABLE.length;    if (k < length1) {        return FACTORIAL_TABLE[k];    }    int length2 = LARGE_FACTORIAL_TABLE.length;    if (k < length1 + length2) {        return LARGE_FACTORIAL_TABLE[k - length1];    } else {        return Double.POSITIVE_INFINITY;    }}
public static double mahout_f6448_0(int k)
{    if (k >= 30) {        double r = 1.0 / k;        double rr = r * r;        double c7 = -5.95238095238095238e-04;        double c5 = 7.93650793650793651e-04;        double c3 = -2.77777777777777778e-03;        double c1 = 8.33333333333333333e-02;        double c0 = 9.18938533204672742e-01;        return (k + 0.5) * Math.log(k) - k + c0 + r * (c1 + rr * (c3 + rr * (c5 + rr * c7)));    } else {        return LOG_FACTORIAL_TABLE[k];    }}
public static double mahout_f6449_0(double x, double[] coef, int N)
{    double ans = x + coef[0];    for (int i = 1; i < N; i++) {        ans = ans * x + coef[i];    }    return ans;}
public static double mahout_f6450_0(double x, double[] coef, int N)
{    double ans = coef[0];    for (int i = 1; i <= N; i++) {        ans = ans * x + coef[i];    }    return ans;}
public double mahout_f6451_0(double x)
{    throw new UnsupportedOperationException("Can't compute pdf for " + this.getClass().getName());}
public double mahout_f6452_0(double x)
{    throw new UnsupportedOperationException("Can't compute pdf for " + this.getClass().getName());}
public int mahout_f6453_0()
{    return (int) Math.round(nextDouble());}
public double mahout_f6454_0()
{    return nextInt();}
protected Random mahout_f6455_0()
{    return randomGenerator;}
protected double mahout_f6456_0()
{    return randomGenerator.nextDouble();}
public double mahout_f6457_0(double dummy)
{    return nextDouble();}
public int mahout_f6458_0(int dummy)
{    return nextInt();}
public void mahout_f6459_0(Random randomGenerator)
{    this.randomGenerator = randomGenerator;}
 void mahout_f6460_0()
{    int y;    int kk;    for (kk = 0; kk < N - M; kk++) {        y = (mt[kk] & UPPER_MASK) | (mt[kk + 1] & LOWER_MASK);        mt[kk] = mt[kk + M] ^ (y >>> 1) ^ ((y & 0x1) == 0 ? MAG0 : MAG1);    }    for (; kk < N - 1; kk++) {        y = (mt[kk] & UPPER_MASK) | (mt[kk + 1] & LOWER_MASK);        mt[kk] = mt[kk + (M - N)] ^ (y >>> 1) ^ ((y & 0x1) == 0 ? MAG0 : MAG1);    }    y = (mt[N - 1] & UPPER_MASK) | (mt[0] & LOWER_MASK);    mt[N - 1] = mt[M - 1] ^ (y >>> 1) ^ ((y & 0x1) == 0 ? MAG0 : MAG1);    this.mti = 0;}
public int mahout_f6461_0()
{    /* Each single bit including the sign bit will be random */    if (mti == N) {        nextBlock();    }        int y = mt[mti++];        y ^= y >>> 11;        y ^= (y << 7) & TEMPERING_MASK_B;        y ^= (y << 15) & TEMPERING_MASK_C;            y ^= y >>> 18;    return y;}
 void mahout_f6462_0(int seed)
{    mt[0] = seed;    for (int i = 1; i < N; i++) {        mt[i] = 1812433253 * (mt[i - 1] ^ (mt[i - 1] >> 30)) + i;    /* See Knuth TAOCP Vol2. 3rd Ed. P.106 for multiplier. */    /* In the previous versions, MSBs of the seed affect   */    /* only MSBs of the array mt[].                        */    /* 2002/01/09 modified by Makoto Matsumoto             */        /* for >32 bit machines */    }        mti = N;}
 void mahout_f6463_0(int seed)
{    for (int i = 0; i < N; i++) {        mt[i] = seed & 0xffff0000;        seed = 69069 * seed + 1;        mt[i] |= (seed & 0xffff0000) >>> 16;        seed = 69069 * seed + 1;    }        mti = N;}
public double mahout_f6464_0(double dummy)
{    return raw();}
public int mahout_f6465_0(int dummy)
{    return nextInt();}
public double mahout_f6466_0()
{    double nextDouble;    do {                        nextDouble = (nextLong() - -9.223372036854776E18) * 5.421010862427522E-20;    } while (    !(nextDouble > 0.0 && nextDouble < 1.0));        return nextDouble;/*      nextLong == Long.MAX_VALUE         --> 1.0      nextLong == Long.MIN_VALUE         --> 0.0      nextLong == Long.MAX_VALUE-1       --> 1.0      nextLong == Long.MAX_VALUE-100000L --> 0.9999999999999946      nextLong == Long.MIN_VALUE+1       --> 0.0      nextLong == Long.MIN_VALUE-100000L --> 0.9999999999999946      nextLong == 1L                     --> 0.5      nextLong == -1L                    --> 0.5      nextLong == 2L                     --> 0.5      nextLong == -2L                    --> 0.5      nextLong == 2L+100000L             --> 0.5000000000000054      nextLong == -2L-100000L            --> 0.49999999999999456    */}
public float mahout_f6467_0()
{        float nextFloat;    do {        nextFloat = (float) raw();    } while (nextFloat >= 1.0f);        return nextFloat;}
public long mahout_f6468_0()
{        return ((nextInt() & 0xFFFFFFFFL) << 32) | (nextInt() & 0xFFFFFFFFL);}
public double mahout_f6469_0()
{    int nextInt;    do {                        nextInt = nextInt();    } while (nextInt == 0);        return (nextInt & 0xFFFFFFFFL) * 2.3283064365386963E-10;/*      nextInt == Integer.MAX_VALUE   --> 0.49999999976716936      nextInt == Integer.MIN_VALUE   --> 0.5      nextInt == Integer.MAX_VALUE-1 --> 0.4999999995343387      nextInt == Integer.MIN_VALUE+1 --> 0.5000000002328306      nextInt == 1                   --> 2.3283064365386963E-10      nextInt == -1                  --> 0.9999999997671694      nextInt == 2                   --> 4.6566128730773926E-10      nextInt == -2                  --> 0.9999999995343387    */}
public double mahout_f6470_0(double x)
{    if (x <= 0.0) {        return 0.0;    }    return 1.0 - Math.exp(-x * lambda);}
public double mahout_f6471_0()
{    return -Math.log1p(-randomDouble()) / lambda;}
public double mahout_f6472_0(double x)
{    if (x < 0.0) {        return 0.0;    }    return lambda * Math.exp(-x * lambda);}
public void mahout_f6473_0(double lambda)
{    this.lambda = lambda;}
public String mahout_f6474_0()
{    return String.format(Locale.ENGLISH, "%s(%.4f)", this.getClass().getName(), lambda);}
public double mahout_f6475_0(double x)
{    return Probability.gamma(alpha, rate, x);}
public double mahout_f6476_0()
{    return nextDouble(alpha, rate);}
public double mahout_f6477_0(double alpha, double rate)
{    if (alpha <= 0.0) {        throw new IllegalArgumentException();    }    if (rate <= 0.0) {        throw new IllegalArgumentException();    }    double gds;    double b = 0.0;    if (alpha < 1.0) {                        b = 1.0 + 0.36788794412 * alpha;        while (true) {            double p = b * randomDouble();            if (p <= 1.0) {                                gds = Math.exp(Math.log(p) / alpha);                if (Math.log(randomDouble()) <= -gds) {                    return gds / rate;                }            } else {                                gds = -Math.log((b - p) / alpha);                if (Math.log(randomDouble()) <= (alpha - 1.0) * Math.log(gds)) {                    return gds / rate;                }            }        }    } else {                double ss = 0.0;        double s = 0.0;        double d = 0.0;        if (alpha != -1.0) {                        ss = alpha - 0.5;            s = Math.sqrt(ss);            d = 5.656854249 - 12.0 * s;        }                double v12;        double v1;        do {            v1 = 2.0 * randomDouble() - 1.0;            double v2 = 2.0 * randomDouble() - 1.0;            v12 = v1 * v1 + v2 * v2;        } while (v12 > 1.0);        double t = v1 * Math.sqrt(-2.0 * Math.log(v12) / v12);        double x = s + 0.5 * t;        gds = x * x;        if (t >= 0.0) {            return gds / rate;        }                double u = randomDouble();        if (d * u <= t * t * t) {            return gds / rate;        }                double q0 = 0.0;        double si = 0.0;        double c = 0.0;        if (alpha != -1.0) {                        double r = 1.0 / alpha;            double q9 = 0.0001710320;            double q8 = -0.0004701849;            double q7 = 0.0006053049;            double q6 = 0.0003340332;            double q5 = -0.0003349403;            double q4 = 0.0015746717;            double q3 = 0.0079849875;            double q2 = 0.0208333723;            double q1 = 0.0416666664;            q0 = ((((((((q9 * r + q8) * r + q7) * r + q6) * r + q5) * r + q4) * r + q3) * r + q2) * r + q1) * r;            if (alpha > 3.686) {                if (alpha > 13.022) {                    b = 1.77;                    si = 0.75;                    c = 0.1515 / s;                } else {                    b = 1.654 + 0.0076 * ss;                    si = 1.68 / s + 0.275;                    c = 0.062 / s + 0.024;                }            } else {                b = 0.463 + s - 0.178 * ss;                si = 1.235;                c = 0.195 / s - 0.079 + 0.016 * s;            }        }        double v;        double q;        double a9 = 0.104089866;        double a8 = -0.112750886;        double a7 = 0.110368310;        double a6 = -0.124385581;        double a5 = 0.142873973;        double a4 = -0.166677482;        double a3 = 0.199999867;        double a2 = -0.249999949;        double a1 = 0.333333333;        if (x > 0.0) {                                    v = t / (s + s);            if (Math.abs(v) > 0.25) {                q = q0 - s * t + 0.25 * t * t + (ss + ss) * Math.log1p(v);            } else {                q = q0 + 0.5 * t * t * ((((((((a9 * v + a8) * v + a7) * v + a6) * v + a5) * v + a4) * v + a3) * v + a2) * v + a1) * v;            }                        if (Math.log1p(-u) <= q) {                return gds / rate;            }        }        double e7 = 0.000247453;        double e6 = 0.001353826;        double e5 = 0.008345522;        double e4 = 0.041664508;        double e3 = 0.166666848;        double e2 = 0.499999994;        double e1 = 1.000000000;        while (true) {                        double sign_u;            double e;            do {                e = -Math.log(randomDouble());                u = randomDouble();                u = u + u - 1.0;                sign_u = u > 0 ? 1.0 : -1.0;                t = b + e * si * sign_u;            } while (            t <= -0.71874483771719);                        v = t / (s + s);            if (Math.abs(v) > 0.25) {                q = q0 - s * t + 0.25 * t * t + (ss + ss) * Math.log1p(v);            } else {                q = q0 + 0.5 * t * t * ((((((((a9 * v + a8) * v + a7) * v + a6) * v + a5) * v + a4) * v + a3) * v + a2) * v + a1) * v;            }            if (q <= 0.0) {                continue;            }                        double w;            if (q > 0.5) {                w = Math.exp(q) - 1.0;            } else {                w = ((((((e7 * q + e6) * q + e5) * q + e4) * q + e3) * q + e2) * q + e1) * q;            }                        if (c * u * sign_u <= w * Math.exp(e - 0.5 * t * t)) {                x = s + 0.5 * t;                return x * x / rate;            }        }    }}
public double mahout_f6478_0(double x)
{    if (x < 0) {        throw new IllegalArgumentException();    }    if (x == 0) {        if (alpha == 1.0) {            return rate;        } else if (alpha < 1) {            return Double.POSITIVE_INFINITY;        } else {            return 0;        }    }    if (alpha == 1.0) {        return rate * Math.exp(-x * rate);    }    return rate * Math.exp((alpha - 1.0) * Math.log(x * rate) - x * rate - logGamma(alpha));}
public String mahout_f6479_0()
{    return this.getClass().getName() + '(' + rate + ',' + alpha + ')';}
public static double mahout_f6480_0(double x)
{    if (x <= 0.0) /* || x > 1.3e19 */    {        return -999;    }    double z;    for (z = 1.0; x < 11.0; x++) {        z *= x;    }    double r = 1.0 / (x * x);    double c6 = -1.9175269175269175e-03;    double c5 = 8.4175084175084175e-04;    double c4 = -5.9523809523809524e-04;    double c3 = 7.9365079365079365e-04;    double c2 = -2.7777777777777777e-03;    double c1 = 8.3333333333333333e-02;    double g = c1 + r * (c2 + r * (c3 + r * (c4 + r * (c5 + r + c6))));    double c0 = 9.1893853320467274e-01;    g = (x - 0.5) * Math.log(x) - x + c0 + g / x;    if (z == 1.0) {        return g;    }    return g - Math.log(z);}
public double mahout_f6481_0(int k)
{    return Probability.negativeBinomial(k, r, p);}
public double mahout_f6482_0(int k)
{    return Arithmetic.binomial(k + r - 1, r - 1) * Math.pow(p, r) * Math.pow(1.0 - p, k);}
public int mahout_f6483_0()
{    return nextInt(r, p);}
public int mahout_f6484_0(int r, double p)
{    return this.poisson.nextInt(gamma.nextDouble(r, p / (1.0 - p)));}
public String mahout_f6485_0()
{    return this.getClass().getName() + '(' + r + ',' + p + ')';}
public double mahout_f6486_0(double x)
{    return Probability.normal(mean, variance, x);}
public double mahout_f6487_0(double x)
{    double diff = x - mean;    return normalizer * Math.exp(-(diff * diff) / (2.0 * variance));}
public double mahout_f6488_0()
{        if (cacheFilled) {        cacheFilled = false;        return cache;    }    double x;    double y;    double r;    do {        x = 2.0 * randomDouble() - 1.0;        y = 2.0 * randomDouble() - 1.0;        r = x * x + y * y;    } while (r >= 1.0);    double z = Math.sqrt(-2.0 * Math.log(r) / r);    cache = this.mean + this.standardDeviation * x * z;    cacheFilled = true;    return this.mean + this.standardDeviation * y * z;}
public final void mahout_f6489_0(Random randomGenerator)
{    super.setRandomGenerator(randomGenerator);    this.cacheFilled = false;}
public final void mahout_f6490_0(double mean, double standardDeviation)
{    if (mean != this.mean || standardDeviation != this.standardDeviation) {        this.mean = mean;        this.standardDeviation = standardDeviation;        this.variance = standardDeviation * standardDeviation;        this.cacheFilled = false;        this.normalizer = 1.0 / Math.sqrt(2.0 * Math.PI * variance);    }}
public String mahout_f6491_0()
{    return String.format(Locale.ENGLISH, "%s(m=%f, sd=%f)", this.getClass().getName(), mean, standardDeviation);}
private static double mahout_f6492_0(int k, double lNu, double cPm)
{    return Math.exp(k * lNu - Arithmetic.logFactorial(k) - cPm);}
public int mahout_f6493_0()
{    return nextInt(mean);}
public int mahout_f6494_0(double theMean)
{    /**     * ***************************************************************     *                                                                 *     *  Poisson Distribution - Patchwork Rejection/Inversion           *     *                                                                 *     * *****************************************************************     *                                                                 *     *  For parameter  my < 10  Tabulated Inversion is applied.        *     *  For my >= 10  Patchwork Rejection is employed:                 *     *  The area below the histogram function f(x) is rearranged in    *     *  its body by certain point reflections. Within a large center   *     *  interval variates are sampled efficiently by rejection from    *     *  uniform hats. Rectangular immediate acceptance regions speed   *     *  up the generation. The remaining tails are covered by          *     *  exponential functions.                                         *     *                                                                 *     * ***************************************************************     */    Random gen = getRandomGenerator();                        int m;    if (theMean < SWITCH_MEAN) {                if (theMean != myOld) {            myOld = theMean;            llll = 0;            p = Math.exp(-theMean);            q = p;            p0 = p;                }        m = theMean > 1.0 ? (int) theMean : 1;        while (true) {            double u = gen.nextDouble();            int k = 0;            if (u <= p0) {                return k;            }            if (llll != 0) {                                int i = u > 0.458 ? Math.min(llll, m) : 1;                for (k = i; k <= llll; k++) {                    if (u <= pp[k]) {                        return k;                    }                }                if (llll == 35) {                    continue;                }            }            for (k = llll + 1; k <= 35; k++) {                                p *= theMean / k;                q += p;                pp[k] = q;                if (u <= q) {                    llll = k;                    return k;                }            }            llll = 35;        }        } else if (theMean < MEAN_MAX) {                                                m = (int) theMean;        if (theMean != myLast) {                        myLast = theMean;                        double Ds = Math.sqrt(theMean + 0.25);                                    k2 = (int) Math.ceil(theMean - 0.5 - Ds);            k4 = (int) (theMean - 0.5 + Ds);            k1 = k2 + k2 - m + 1;            k5 = k4 + k4 - m;                        dl = k2 - k1;            dr = k5 - k4;                        r1 = theMean / k1;            r2 = theMean / k2;            r4 = theMean / (k4 + 1);            r5 = theMean / (k5 + 1);                                    ll = Math.log(r1);                        lr = -Math.log(r5);                        lMy = Math.log(theMean);            cPm = m * lMy - Arithmetic.logFactorial(m);                        f2 = f(k2, lMy, cPm);            f4 = f(k4, lMy, cPm);            f1 = f(k1, lMy, cPm);            f5 = f(k5, lMy, cPm);                                                p1 = f2 * (dl + 1.0);                        p2 = f2 * dl + p1;                        p3 = f4 * (dr + 1.0) + p2;                        p4 = f4 * dr + p3;                        p5 = f1 / ll + p4;                        p6 = f5 / lr + p5;        }        while (true) {                                    double W;            double V;            double U;            int Y;            int X;            int Dk;            if ((U = gen.nextDouble() * p6) < p2) {                                if ((V = U - p1) < 0.0) {                    return k2 + (int) (U / f2);                }                                if ((W = V / dl) < f1) {                    return k1 + (int) (V / f1);                }                                                Dk = gen.nextInt((int) dl) + 1;                if (W <= f2 - Dk * (f2 - f2 / r2)) {                                        return k2 - Dk;                }                if ((V = f2 + f2 - W) < 1.0) {                                        Y = k2 + Dk;                    if (V <= f2 + Dk * (1.0 - f2) / (dl + 1.0)) {                                                return Y;                    }                    if (V <= f(Y, lMy, cPm)) {                        return Y;                    }                                }                X = k2 - Dk;            } else if (U < p4) {                                if ((V = U - p3) < 0.0) {                    return k4 - (int) ((U - p2) / f4);                }                                if ((W = V / dr) < f5) {                    return k5 - (int) (V / f5);                }                                                Dk = gen.nextInt((int) dr) + 1;                if (W <= f4 - Dk * (f4 - f4 * r4)) {                                        return k4 + Dk;                }                if ((V = f4 + f4 - W) < 1.0) {                                        Y = k4 - Dk;                    if (V <= f4 + Dk * (1.0 - f4) / dr) {                                                return Y;                    }                    if (V <= f(Y, lMy, cPm)) {                        return Y;                    }                                }                X = k4 + Dk;            } else {                W = gen.nextDouble();                if (U < p5) {                                        Dk = (int) (1.0 - Math.log(W) / ll);                    if ((X = k1 - Dk) < 0) {                        continue;                    }                                                            W *= (U - p4) * ll;                    if (W <= f1 - Dk * (f1 - f1 / r1)) {                        return X;                    }                                } else {                                        Dk = (int) (1.0 - Math.log(W) / lr);                                        X = k5 + Dk;                                        W *= (U - p5) * lr;                    if (W <= f5 - Dk * (f5 - f5 * r5)) {                        return X;                    }                                }            }                        if (Math.log(W) <= X * lMy - Arithmetic.logFactorial(X) - cPm) {                return X;            }        }    } else {                return (int) theMean;    }}
private static void mahout_f6495_0(long n, long N, int count, long low, long[] values, int fromIndex, Random randomGenerator)
{    /*  This algorithm is applicable if a large percentage (90%..100%) of N shall be sampled.      In such cases it is more efficient than sampleMethodA() and sampleMethodD().        The idea is that it is more efficient to express      sample(n,N,count) in terms of reject(N-n,N,count)       and then invert the result.      For example, sampling 99% turns into sampling 1% plus inversion.      This algorithm is the same as method sampleMethodD(...) with the exception that sampled elements are rejected,      and not sampled elements included in the result set.    */        n = N - n;        long chosen = -1 + low;                double nreal = n;    double ninv = 1.0 / nreal;    double Nreal = N;    double Vprime = Math.exp(Math.log(randomGenerator.nextDouble()) * ninv);    long qu1 = -n + 1 + N;    double qu1real = -nreal + 1.0 + Nreal;        long S;    while (n > 1 && count > 0) {                double nmin1inv = 1.0 / (-1.0 + nreal);        double negSreal;        while (true) {            double X;            while (true) {                                X = Nreal * (-Vprime + 1.0);                S = (long) X;                if (S < qu1) {                    break;                }                Vprime = Math.exp(Math.log(randomGenerator.nextDouble()) * ninv);            }            double U = randomGenerator.nextDouble();            negSreal = -S;                        double y1 = Math.exp(Math.log(U * Nreal / qu1real) * nmin1inv);            Vprime = y1 * (-X / Nreal + 1.0) * qu1real / (negSreal + qu1real);            if (Vprime <= 1.0) {                break;            }                                    double top = -1.0 + Nreal;            long limit;            double bottom;            if (n - 1 > S) {                bottom = -nreal + Nreal;                limit = -S + N;            } else {                bottom = -1.0 + negSreal + Nreal;                limit = qu1;            }            double y2 = 1.0;            for (long t = N - 1; t >= limit; t--) {                y2 *= top / bottom;                top--;                bottom--;            }            if (Nreal / (-X + Nreal) >= y1 * Math.exp(Math.log(y2) * nmin1inv)) {                                Vprime = Math.exp(Math.log(randomGenerator.nextDouble()) * nmin1inv);                                break;            }            Vprime = Math.exp(Math.log(randomGenerator.nextDouble()) * ninv);        }                        int iter = count;        if (S < iter) {            iter = (int) S;        }        count -= iter;        while (--iter >= 0) {            values[fromIndex++] = ++chosen;        }        chosen++;        N -= S + 1;        Nreal = negSreal - 1.0 + Nreal;        n--;        nreal--;        ninv = nmin1inv;        qu1 = -S + qu1;        qu1real = negSreal + qu1real;        }    if (count > 0) {                        S = (long) (N * Vprime);                int iter = count;        if (S < iter) {            iter = (int) S;        }        count -= iter;        while (--iter >= 0) {            values[fromIndex++] = ++chosen;        }        chosen++;                while (--count >= 0) {            values[fromIndex++] = ++chosen;        }    }}
public static void mahout_f6496_0(long n, long N, int count, long low, long[] values, int fromIndex, Random randomGenerator)
{    if (n <= 0 || count <= 0) {        return;    }    if (count > n) {        throw new IllegalArgumentException("count must not be greater than n");    }    if (randomGenerator == null) {        randomGenerator = RandomUtils.getRandom();    }    if (count == N) {                long val = low;        int limit = fromIndex + count;        for (int i = fromIndex; i < limit; i++) {            values[i] = val++;        }        return;    }    if (n < N * 0.95) {                sampleMethodD(n, N, count, low, values, fromIndex, randomGenerator);    } else {                rejectMethodD(n, N, count, low, values, fromIndex, randomGenerator);    }}
private static void mahout_f6497_0(long n, long N, int count, long low, long[] values, int fromIndex, Random randomGenerator)
{    long chosen = -1 + low;    double top = N - n;    double Nreal = N;    long S;    while (n >= 2 && count > 0) {        double V = randomGenerator.nextDouble();        S = 0;        double quot = top / Nreal;        while (quot > V) {            S++;            top--;            Nreal--;            quot *= top / Nreal;        }        chosen += S + 1;        values[fromIndex++] = chosen;        count--;        Nreal--;        n--;    }    if (count > 0) {                S = (long) (Math.round(Nreal) * randomGenerator.nextDouble());        chosen += S + 1;        values[fromIndex] = chosen;    }}
private static void mahout_f6498_0(long n, long N, int count, long low, long[] values, int fromIndex, Random randomGenerator)
{    long chosen = -1 + low;    double nreal = n;    double ninv = 1.0 / nreal;    double Nreal = N;    double vprime = Math.exp(Math.log(randomGenerator.nextDouble()) * ninv);    long qu1 = -n + 1 + N;    double qu1real = -nreal + 1.0 + Nreal;    long negalphainv = -13;            long threshold = -negalphainv * n;    long S;    while (n > 1 && count > 0 && threshold < N) {        double nmin1inv = 1.0 / (-1.0 + nreal);        double negSreal;        while (true) {            double X;            while (true) {                                X = Nreal * (-vprime + 1.0);                S = (long) X;                if (S < qu1) {                    break;                }                vprime = Math.exp(Math.log(randomGenerator.nextDouble()) * ninv);            }            double U = randomGenerator.nextDouble();            negSreal = -S;                        double y1 = Math.exp(Math.log(U * Nreal / qu1real) * nmin1inv);            vprime = y1 * (-X / Nreal + 1.0) * qu1real / (negSreal + qu1real);            if (vprime <= 1.0) {                break;            }                                    double top = -1.0 + Nreal;            long limit;            double bottom;            if (n - 1 > S) {                bottom = -nreal + Nreal;                limit = -S + N;            } else {                bottom = -1.0 + negSreal + Nreal;                limit = qu1;            }            double y2 = 1.0;            for (long t = N - 1; t >= limit; t--) {                y2 *= top / bottom;                top--;                bottom--;            }            if (Nreal / (-X + Nreal) >= y1 * Math.exp(Math.log(y2) * nmin1inv)) {                                vprime = Math.exp(Math.log(randomGenerator.nextDouble()) * nmin1inv);                                break;            }            vprime = Math.exp(Math.log(randomGenerator.nextDouble()) * ninv);        }                chosen += S + 1;        values[fromIndex++] = chosen;        /*            for (int iter=0; iter<S && count > 0; iter++) {        values[fromIndex++] = ++chosen;        count--;      }      chosen++;      */        count--;        N -= S + 1;        Nreal = negSreal - 1.0 + Nreal;        n--;        nreal--;        ninv = nmin1inv;        qu1 = -S + qu1;        qu1real = negSreal + qu1real;        threshold += negalphainv;    }    if (count > 0) {        if (n > 1) {                        sampleMethodA(n, N, count, chosen + 1, values, fromIndex, randomGenerator);        } else {                        S = (long) (N * vprime);            chosen += S + 1;            values[fromIndex++] = chosen;        }    }}
public double mahout_f6499_0(double x)
{    if (x <= min) {        return 0.0;    }    if (x >= max) {        return 1.0;    }    return (x - min) / (max - min);}
public boolean mahout_f6500_0()
{    return randomDouble() > 0.5;}
public double mahout_f6501_0()
{    return min + (max - min) * randomDouble();}
public double mahout_f6502_0(double from, double to)
{    return from + (to - from) * randomDouble();}
public float mahout_f6503_0(float from, float to)
{    return (float) nextDoubleFromTo(from, to);}
public int mahout_f6504_0(int from, int to)
{    return (int) (from + (long) ((1L + to - from) * randomDouble()));}
public long mahout_f6505_0(long from, long to)
{        if (from >= 0 && to < Long.MAX_VALUE) {        return from + (long) nextDoubleFromTo(0.0, to - from + 1);    }            double diff = (double) to - (double) from + 1.0;    if (diff <= Long.MAX_VALUE) {        return from + (long) nextDoubleFromTo(0.0, diff);    }            long random;    if (from == Long.MIN_VALUE) {        if (to == Long.MAX_VALUE) {                        int i1 = nextIntFromTo(Integer.MIN_VALUE, Integer.MAX_VALUE);            int i2 = nextIntFromTo(Integer.MIN_VALUE, Integer.MAX_VALUE);            return ((i1 & 0xFFFFFFFFL) << 32) | (i2 & 0xFFFFFFFFL);        }        random = Math.round(nextDoubleFromTo(Long.MIN_VALUE, to + 1));        if (random > to) {            random = Long.MIN_VALUE;        }    } else {        random = Math.round(nextDoubleFromTo(from - 1, to));        if (random < from) {            random = to;        }    }    return random;}
public double mahout_f6506_0(double x)
{    if (x <= min || x >= max) {        return 0.0;    }    return 1.0 / (max - min);}
public void mahout_f6507_0(double min, double max)
{    if (max < min) {        setState(max, min);        return;    }    this.min = min;    this.max = max;}
public String mahout_f6508_0()
{    return this.getClass().getName() + '(' + min + ',' + max + ')';}
public static double mahout_f6509_0(double alpha, double beta)
{    double y;    if (alpha < 40 && beta < 40) {        y = gamma(alpha + beta);        if (y == 0.0) {            return 1.0;        }        if (alpha > beta) {            y = gamma(alpha) / y;            y *= gamma(beta);        } else {            y = gamma(beta) / y;            y *= gamma(alpha);        }    } else {        y = Math.exp(logGamma(alpha) + logGamma(beta) - logGamma(alpha + beta));    }    return y;}
public static double mahout_f6510_0(double x)
{    double[] pCoefficient = { 1.60119522476751861407E-4, 1.19135147006586384913E-3, 1.04213797561761569935E-2, 4.76367800457137231464E-2, 2.07448227648435975150E-1, 4.94214826801497100753E-1, 9.99999999999999996796E-1 };    double[] qCoefficient = { -2.31581873324120129819E-5, 5.39605580493303397842E-4, -4.45641913851797240494E-3, 1.18139785222060435552E-2, 3.58236398605498653373E-2, -2.34591795718243348568E-1, 7.14304917030273074085E-2, 1.00000000000000000320E0 };            double p;    double z;    double q = Math.abs(x);    if (q > 33.0) {        if (x < 0.0) {            p = Math.floor(q);            if (p == q) {                throw new ArithmeticException("gamma: overflow");            }                        z = q - p;            if (z > 0.5) {                p += 1.0;                z = q - p;            }            z = q * Math.sin(Math.PI * z);            if (z == 0.0) {                throw new ArithmeticException("gamma: overflow");            }            z = Math.abs(z);            z = Math.PI / (z * stirlingFormula(q));            return -z;        } else {            return stirlingFormula(x);        }    }    z = 1.0;    while (x >= 3.0) {        x -= 1.0;        z *= x;    }    while (x < 0.0) {        if (x == 0.0) {            throw new ArithmeticException("gamma: singular");        }        if (x > -1.0e-9) {            return z / ((1.0 + 0.5772156649015329 * x) * x);        }        z /= x;        x += 1.0;    }    while (x < 2.0) {        if (x == 0.0) {            throw new ArithmeticException("gamma: singular");        }        if (x < 1.0e-9) {            return z / ((1.0 + 0.5772156649015329 * x) * x);        }        z /= x;        x += 1.0;    }    if ((x == 2.0) || (x == 3.0)) {        return z;    }    x -= 2.0;    p = Polynomial.polevl(x, pCoefficient, 6);    q = Polynomial.polevl(x, qCoefficient, 7);    return z * p / q;}
public static double mahout_f6511_0(double alpha, double beta, double xx)
{    if (alpha <= 0.0) {        throw new ArithmeticException("incompleteBeta: Domain error! alpha must be > 0, but was " + alpha);    }    if (beta <= 0.0) {        throw new ArithmeticException("incompleteBeta: Domain error! beta must be > 0, but was " + beta);    }    if (xx <= 0.0) {        return 0.0;    }    if (xx >= 1.0) {        return 1.0;    }    double t;    if ((beta * xx) <= 1.0 && xx <= 0.95) {        t = powerSeries(alpha, beta, xx);        return t;    }    double w = 1.0 - xx;    /* Reverse a and b if x is greater than the mean. */    double xc;    double x;    double b;    double a;    boolean flag = false;    if (xx > (alpha / (alpha + beta))) {        flag = true;        a = beta;        b = alpha;        xc = xx;        x = w;    } else {        a = alpha;        b = beta;        xc = w;        x = xx;    }    if (flag && (b * x) <= 1.0 && x <= 0.95) {        t = powerSeries(a, b, x);        t = t <= Constants.MACHEP ? 1.0 - Constants.MACHEP : 1.0 - t;        return t;    }    /* Choose expansion for better convergence. */    double y = x * (a + b - 2.0) - (a - 1.0);    w = y < 0.0 ? incompleteBetaFraction1(a, b, x) : incompleteBetaFraction2(a, b, x) / xc;    /* Multiply w by the factor       a      b   _             _     _      x  (1-x)   | (a+b) / ( a | (a) | (b) ) .   */    y = a * Math.log(x);    t = b * Math.log(xc);    if ((a + b) < Constants.MAXGAM && Math.abs(y) < Constants.MAXLOG && Math.abs(t) < Constants.MAXLOG) {        t = Math.pow(xc, b);        t *= Math.pow(x, a);        t /= a;        t *= w;        t *= gamma(a + b) / (gamma(a) * gamma(b));        if (flag) {            t = t <= Constants.MACHEP ? 1.0 - Constants.MACHEP : 1.0 - t;        }        return t;    }    /* Resort to logarithms.  */    y += t + logGamma(a + b) - logGamma(a) - logGamma(b);    y += Math.log(w / a);    t = y < Constants.MINLOG ? 0.0 : Math.exp(y);    if (flag) {        t = t <= Constants.MACHEP ? 1.0 - Constants.MACHEP : 1.0 - t;    }    return t;}
 static double mahout_f6512_0(double a, double b, double x)
{    double k1 = a;    double k2 = a + b;    double k3 = a;    double k4 = a + 1.0;    double k5 = 1.0;    double k6 = b - 1.0;    double k7 = k4;    double k8 = a + 2.0;    double pkm2 = 0.0;    double qkm2 = 1.0;    double pkm1 = 1.0;    double qkm1 = 1.0;    double ans = 1.0;    double r = 1.0;    int n = 0;    double thresh = 3.0 * Constants.MACHEP;    do {        double xk = -(x * k1 * k2) / (k3 * k4);        double pk = pkm1 + pkm2 * xk;        double qk = qkm1 + qkm2 * xk;        pkm2 = pkm1;        pkm1 = pk;        qkm2 = qkm1;        qkm1 = qk;        xk = (x * k5 * k6) / (k7 * k8);        pk = pkm1 + pkm2 * xk;        qk = qkm1 + qkm2 * xk;        pkm2 = pkm1;        pkm1 = pk;        qkm2 = qkm1;        qkm1 = qk;        if (qk != 0) {            r = pk / qk;        }        double t;        if (r != 0) {            t = Math.abs((ans - r) / r);            ans = r;        } else {            t = 1.0;        }        if (t < thresh) {            return ans;        }        k1 += 1.0;        k2 += 1.0;        k3 += 2.0;        k4 += 2.0;        k5 += 1.0;        k6 -= 1.0;        k7 += 2.0;        k8 += 2.0;        if ((Math.abs(qk) + Math.abs(pk)) > Constants.BIG) {            pkm2 *= Constants.BIG_INVERSE;            pkm1 *= Constants.BIG_INVERSE;            qkm2 *= Constants.BIG_INVERSE;            qkm1 *= Constants.BIG_INVERSE;        }        if ((Math.abs(qk) < Constants.BIG_INVERSE) || (Math.abs(pk) < Constants.BIG_INVERSE)) {            pkm2 *= Constants.BIG;            pkm1 *= Constants.BIG;            qkm2 *= Constants.BIG;            qkm1 *= Constants.BIG;        }    } while (++n < 300);    return ans;}
 static double mahout_f6513_0(double a, double b, double x)
{    double k1 = a;    double k2 = b - 1.0;    double k3 = a;    double k4 = a + 1.0;    double k5 = 1.0;    double k6 = a + b;    double k7 = a + 1.0;    double k8 = a + 2.0;    double pkm2 = 0.0;    double qkm2 = 1.0;    double pkm1 = 1.0;    double qkm1 = 1.0;    double z = x / (1.0 - x);    double ans = 1.0;    double r = 1.0;    int n = 0;    double thresh = 3.0 * Constants.MACHEP;    do {        double xk = -(z * k1 * k2) / (k3 * k4);        double pk = pkm1 + pkm2 * xk;        double qk = qkm1 + qkm2 * xk;        pkm2 = pkm1;        pkm1 = pk;        qkm2 = qkm1;        qkm1 = qk;        xk = (z * k5 * k6) / (k7 * k8);        pk = pkm1 + pkm2 * xk;        qk = qkm1 + qkm2 * xk;        pkm2 = pkm1;        pkm1 = pk;        qkm2 = qkm1;        qkm1 = qk;        if (qk != 0) {            r = pk / qk;        }        double t;        if (r != 0) {            t = Math.abs((ans - r) / r);            ans = r;        } else {            t = 1.0;        }        if (t < thresh) {            return ans;        }        k1 += 1.0;        k2 -= 1.0;        k3 += 2.0;        k4 += 2.0;        k5 += 1.0;        k6 += 1.0;        k7 += 2.0;        k8 += 2.0;        if ((Math.abs(qk) + Math.abs(pk)) > Constants.BIG) {            pkm2 *= Constants.BIG_INVERSE;            pkm1 *= Constants.BIG_INVERSE;            qkm2 *= Constants.BIG_INVERSE;            qkm1 *= Constants.BIG_INVERSE;        }        if ((Math.abs(qk) < Constants.BIG_INVERSE) || (Math.abs(pk) < Constants.BIG_INVERSE)) {            pkm2 *= Constants.BIG;            pkm1 *= Constants.BIG;            qkm2 *= Constants.BIG;            qkm1 *= Constants.BIG;        }    } while (++n < 300);    return ans;}
public static double mahout_f6514_0(double alpha, double x)
{    if (x <= 0 || alpha <= 0) {        return 0.0;    }    if (x > 1.0 && x > alpha) {        return 1.0 - incompleteGammaComplement(alpha, x);    }    /* Compute  x**a * exp(-x) / gamma(a)  */    double ax = alpha * Math.log(x) - x - logGamma(alpha);    if (ax < -Constants.MAXLOG) {        return 0.0;    }    ax = Math.exp(ax);    /* power series */    double r = alpha;    double c = 1.0;    double ans = 1.0;    do {        r += 1.0;        c *= x / r;        ans += c;    } while (c / ans > Constants.MACHEP);    return ans * ax / alpha;}
public static double mahout_f6515_0(double alpha, double x)
{    if (x <= 0 || alpha <= 0) {        return 1.0;    }    if (x < 1.0 || x < alpha) {        return 1.0 - incompleteGamma(alpha, x);    }    double ax = alpha * Math.log(x) - x - logGamma(alpha);    if (ax < -Constants.MAXLOG) {        return 0.0;    }    ax = Math.exp(ax);    /* continued fraction */    double y = 1.0 - alpha;    double z = x + y + 1.0;    double c = 0.0;    double pkm2 = 1.0;    double qkm2 = x;    double pkm1 = x + 1.0;    double qkm1 = z * x;    double ans = pkm1 / qkm1;    double t;    do {        c += 1.0;        y += 1.0;        z += 2.0;        double yc = y * c;        double pk = pkm1 * z - pkm2 * yc;        double qk = qkm1 * z - qkm2 * yc;        if (qk != 0) {            double r = pk / qk;            t = Math.abs((ans - r) / r);            ans = r;        } else {            t = 1.0;        }        pkm2 = pkm1;        pkm1 = pk;        qkm2 = qkm1;        qkm1 = qk;        if (Math.abs(pk) > Constants.BIG) {            pkm2 *= Constants.BIG_INVERSE;            pkm1 *= Constants.BIG_INVERSE;            qkm2 *= Constants.BIG_INVERSE;            qkm1 *= Constants.BIG_INVERSE;        }    } while (t > Constants.MACHEP);    return ans * ax;}
public static double mahout_f6516_0(double x)
{    double p;    double q;    double z;    double[] aCoefficient = { 8.11614167470508450300E-4, -5.95061904284301438324E-4, 7.93650340457716943945E-4, -2.77777777730099687205E-3, 8.33333333333331927722E-2 };    double[] bCoefficient = { -1.37825152569120859100E3, -3.88016315134637840924E4, -3.31612992738871184744E5, -1.16237097492762307383E6, -1.72173700820839662146E6, -8.53555664245765465627E5 };    double[] cCoefficient = { /* 1.00000000000000000000E0, */    -3.51815701436523470549E2, -1.70642106651881159223E4, -2.20528590553854454839E5, -1.13933444367982507207E6, -2.53252307177582951285E6, -2.01889141433532773231E6 };    if (x < -34.0) {        q = -x;        double w = logGamma(q);        p = Math.floor(q);        if (p == q) {            throw new ArithmeticException("lgam: Overflow");        }        z = q - p;        if (z > 0.5) {            p += 1.0;            z = p - q;        }        z = q * Math.sin(Math.PI * z);        if (z == 0.0) {            throw new ArithmeticException("lgamma: Overflow");        }        z = Constants.LOGPI - Math.log(z) - w;        return z;    }    if (x < 13.0) {        z = 1.0;        while (x >= 3.0) {            x -= 1.0;            z *= x;        }        while (x < 2.0) {            if (x == 0.0) {                throw new ArithmeticException("lgamma: Overflow");            }            z /= x;            x += 1.0;        }        if (z < 0.0) {            z = -z;        }        if (x == 2.0) {            return Math.log(z);        }        x -= 2.0;        p = x * Polynomial.polevl(x, bCoefficient, 5) / Polynomial.p1evl(x, cCoefficient, 6);        return Math.log(z) + p;    }    if (x > 2.556348e305) {        throw new ArithmeticException("lgamma: Overflow");    }    q = (x - 0.5) * Math.log(x) - x + 0.91893853320467274178;        if (x > 1.0e8) {        return q;    }    p = 1.0 / (x * x);    if (x >= 1000.0) {        q += ((7.9365079365079365079365e-4 * p - 2.7777777777777777777778e-3) * p + 0.0833333333333333333333) / x;    } else {        q += Polynomial.polevl(p, aCoefficient, 4) / x;    }    return q;}
private static double mahout_f6517_0(double a, double b, double x)
{    double ai = 1.0 / a;    double u = (1.0 - b) * x;    double v = u / (a + 1.0);    double t1 = v;    double t = u;    double n = 2.0;    double s = 0.0;    double z = Constants.MACHEP * ai;    while (Math.abs(v) > z) {        u = (n - b) * x / n;        t *= u;        v = t / (a + n);        s += v;        n += 1.0;    }    s += t1;    s += ai;    u = a * Math.log(x);    if ((a + b) < Constants.MAXGAM && Math.abs(u) < Constants.MAXLOG) {        t = gamma(a + b) / (gamma(a) * gamma(b));        s *= t * Math.pow(x, a);    } else {        t = logGamma(a + b) - logGamma(a) - logGamma(b) + u + Math.log(s);        s = t < Constants.MINLOG ? 0.0 : Math.exp(t);    }    return s;}
 static double mahout_f6518_0(double x)
{    double[] coefficients = { 7.87311395793093628397E-4, -2.29549961613378126380E-4, -2.68132617805781232825E-3, 3.47222221605458667310E-3, 8.33333333333482257126E-2 };    double w = 1.0 / x;    double y = Math.exp(x);    w = 1.0 + w * Polynomial.polevl(w, coefficients, 4);    if (x > MAXSTIR) {        /* Avoid overflow in Math.pow() */        double v = Math.pow(x, 0.5 * x - 0.25);        y = v * (v / y);    } else {        y = Math.pow(x, x - 0.5) / y;    }    y = Constants.SQTPI * y * w;    return y;}
public static double mahout_f6519_0(double a, double b, double x)
{    return Gamma.incompleteBeta(a, b, x);}
public static double mahout_f6520_0(double alpha, double beta, double x)
{    if (x < 0.0) {        return 0.0;    }    return Gamma.incompleteGamma(alpha, beta * x);}
public static double mahout_f6521_0(int k, int n, double p)
{    if (p < 0.0 || p > 1.0) {        throw new IllegalArgumentException();    }    if (k < 0) {        return 0.0;    }    return Gamma.incompleteBeta(n, k + 1, p);}
public static double mahout_f6522_0(double a)
{    if (a < 0) {        return 1 - normal(-a);    }    double b0 = 0.2316419;    double b1 = 0.319381530;    double b2 = -0.356563782;    double b3 = 1.781477937;    double b4 = -1.821255978;    double b5 = 1.330274429;    double t = 1 / (1 + b0 * a);    return 1 - UNIT_NORMAL.pdf(a) * t * (b1 + t * (b2 + t * (b3 + t * (b4 + t * b5))));}
public static double mahout_f6523_0(double mean, double variance, double x)
{    return normal((x - mean) / Math.sqrt(variance));}
public static double mahout_f6524_0(int k, double mean)
{    if (mean < 0) {        throw new IllegalArgumentException();    }    if (k < 0) {        return 0.0;    }    return Gamma.incompleteGammaComplement(k + 1, mean);}
public boolean mahout_f6525_0()
{    return size() == 0;}
protected static void mahout_f6526_0(int index, int theSize)
{    if (index >= theSize || index < 0) {        throw new IndexOutOfBoundsException("Index: " + index + ", Size: " + theSize);    }}
protected static void mahout_f6527_0(int from, int to, int theSize)
{    if (to == from - 1) {        return;    }    if (from < 0 || from > to || to >= theSize) {        throw new IndexOutOfBoundsException("from: " + from + ", to: " + to + ", size=" + theSize);    }}
public void mahout_f6528_0()
{    removeFromTo(0, size() - 1);}
public final void mahout_f6529_0()
{    mergeSortFromTo(0, size() - 1);}
public final void mahout_f6530_0()
{    quickSortFromTo(0, size() - 1);}
public void mahout_f6531_0(int index)
{    removeFromTo(index, index);}
public void mahout_f6532_0(int newSize)
{    if (newSize < 0) {        throw new IndexOutOfBoundsException("newSize:" + newSize);    }    int currentSize = size();    if (newSize != currentSize) {        if (newSize > currentSize) {            beforeInsertDummies(currentSize, newSize - currentSize);        } else if (newSize < currentSize) {            removeFromTo(newSize, currentSize - 1);        }    }}
public final void mahout_f6533_0()
{    sortFromTo(0, size() - 1);}
public void mahout_f6534_0(int from, int to)
{    quickSortFromTo(from, to);}
public void mahout_f6535_0()
{}
public void mahout_f6536_0(Collection<T> collection)
{    this.beforeInsertAllOf(size(), collection);}
public void mahout_f6537_0(int index, Collection<T> collection)
{    this.beforeInsertDummies(index, collection.size());    this.replaceFromWith(index, collection);}
public void mahout_f6538_0(T element)
{        if (size == elements.length) {        ensureCapacity(size + 1);    }    elements[size++] = element;}
public void mahout_f6539_0(int index, T element)
{        if (size == index) {        add(element);        return;    }    if (index > size || index < 0) {        throw new IndexOutOfBoundsException("Index: " + index + ", Size: " + size);    }    ensureCapacity(size + 1);    System.arraycopy(elements, index, elements, index + 1, size - index);    elements[index] = element;    size++;}
public Object mahout_f6540_0()
{        return new ObjectArrayList<>((T[]) elements.clone());}
public ObjectArrayList<T> mahout_f6541_0()
{    return (ObjectArrayList<T>) clone();}
public Q[] mahout_f6542_0()
{    return (Q[]) elements;}
public void mahout_f6543_0(T[] elements)
{    this.elements = elements;    this.size = elements.length;}
public void mahout_f6544_0(int minCapacity)
{    elements = org.apache.mahout.math.Arrays.ensureCapacity(elements, minCapacity);}
public boolean mahout_f6545_0(Object otherObj)
{        if (!(otherObj instanceof ObjectArrayList)) {        return super.equals(otherObj);    }    if (this == otherObj) {        return true;    }    if (otherObj == null) {        return false;    }    ObjectArrayList<?> other = (ObjectArrayList<?>) otherObj;    if (size() != other.size()) {        return false;    }    Object[] theElements = elements();    Object[] otherElements = other.elements();    for (int i = size(); --i >= 0; ) {        if (theElements[i] != otherElements[i]) {            return false;        }    }    return true;}
public boolean mahout_f6546_0(ObjectProcedure<T> procedure)
{    T[] theElements = (T[]) elements;    int theSize = size;    for (int i = 0; i < theSize; ) {        if (!procedure.apply(theElements[i++])) {            return false;        }    }    return true;}
public T mahout_f6547_0(int index)
{        if (index >= size || index < 0) {        throw new IndexOutOfBoundsException("Index: " + index + ", Size: " + size);    }    return (T) elements[index];}
public T mahout_f6548_0(int index)
{    return (T) elements[index];}
public int mahout_f6549_0(T element, int from, int to)
{        if (size == 0) {        return -1;    }    checkRangeFromTo(from, to, size);    Object[] theElements = elements;    for (int i = from; i <= to; i++) {        if (element == theElements[i]) {            return i;        }        }        return -1;}
public int mahout_f6550_0(T element, int from, int to)
{        if (size == 0) {        return -1;    }    checkRangeFromTo(from, to, size);    Object[] theElements = elements;    for (int i = to; i >= from; i--) {        if (element == theElements[i]) {            return i;        }        }        return -1;}
public AbstractObjectList<T> mahout_f6551_0(int from, int to)
{    if (size == 0) {        return new ObjectArrayList<>(0);    }    checkRangeFromTo(from, to, size);    Object[] part = new Object[to - from + 1];    System.arraycopy(elements, from, part, 0, to - from + 1);    return new ObjectArrayList<>((T[]) part);}
public void mahout_f6552_0()
{        int limit = size / 2;    int j = size - 1;    Object[] theElements = elements;    for (int i = 0; i < limit; ) {                Object tmp = theElements[i];        theElements[i++] = theElements[j];        theElements[j--] = tmp;    }}
public void mahout_f6553_0(int index, T element)
{        if (index >= size || index < 0) {        throw new IndexOutOfBoundsException("Index: " + index + ", Size: " + size);    }    elements[index] = element;}
public void mahout_f6554_0(int index, T element)
{    elements[index] = element;}
public void mahout_f6555_0()
{    elements = org.apache.mahout.math.Arrays.trimToCapacity(elements, size());}
public void mahout_f6556_0(int fromIndex, int toIndex)
{    throw new UnsupportedOperationException();}
public void mahout_f6557_0(int from, Collection<T> other)
{    throw new UnsupportedOperationException();}
protected void mahout_f6558_0(int index, int length)
{    throw new UnsupportedOperationException();}
public void mahout_f6559_0(int from, int to)
{    throw new UnsupportedOperationException();}
public void mahout_f6560_0(int from, int to)
{    throw new UnsupportedOperationException();}
public int mahout_f6561_0()
{    return size;}
public void mahout_f6562_0(int minCapacity)
{    elements = org.apache.mahout.math.Arrays.ensureCapacity(elements, minCapacity);}
protected long mahout_f6563_0(int index)
{    return elements[index];}
protected void mahout_f6564_0(int index, long element)
{    elements[index] = element;}
public void mahout_f6565_0()
{    elements = org.apache.mahout.math.Arrays.trimToCapacity(elements, size());}
public static int mahout_f6566_0(char value)
{    return value;}
public static int mahout_f6567_0(double value)
{    long bits = Double.doubleToLongBits(value);    return (int) (bits ^ (bits >>> 32));}
public static int mahout_f6568_0(float value)
{    return Float.floatToIntBits(value * 663608941.737f);}
public static int mahout_f6569_0(int value)
{    int h = value;    h ^= h >>> 16;    h *= 0x85ebca6b;    h ^= h >>> 13;    h *= 0xc2b2ae35;    h ^= h >>> 16;    return h;}
public static int mahout_f6570_0(long value)
{    return (int) (value ^ (value >> 32));/*    value &= 0x7FFFFFFFFFFFFFFFL;     int hashCode = 0;    do hashCode = 31*hashCode + (int) (value%10);    while ((value /= 10) > 0);    return 28629151*hashCode;     */}
public static int mahout_f6571_0(Object object)
{    return object == null ? 0 : object.hashCode();}
public static int mahout_f6572_0(short value)
{    return value;}
public static int mahout_f6573_0(boolean value)
{    return value ? 1231 : 1237;}
public void mahout_f6574_0()
{    Arrays.fill(this.state, FREE);    distinct = 0;        freeEntries = table.length;    trimToSize();}
public Object mahout_f6575_0()
{    OpenHashMap<K, V> copy = (OpenHashMap<K, V>) super.clone();    copy.table = copy.table.clone();    copy.values = copy.values.clone();    copy.state = copy.state.clone();    return copy;}
public boolean mahout_f6576_0(Object key)
{    return indexOfKey((K) key) >= 0;}
public boolean mahout_f6577_0(Object value)
{    return indexOfValue((V) value) >= 0;}
public void mahout_f6578_0(int minCapacity)
{    if (table.length < minCapacity) {        int newCapacity = nextPrime(minCapacity);        rehash(newCapacity);    }}
public boolean mahout_f6579_0(ObjectProcedure<K> procedure)
{    for (int i = table.length; i-- > 0; ) {        if (state[i] == FULL && !procedure.apply((K) table[i])) {            return false;        }    }    return true;}
public boolean mahout_f6580_0(ObjectObjectProcedure<K, V> procedure)
{    for (int i = table.length; i-- > 0; ) {        if (state[i] == FULL && !procedure.apply((K) table[i], (V) values[i])) {            return false;        }    }    return true;}
public V mahout_f6581_0(Object key)
{    int i = indexOfKey((K) key);    if (i < 0) {        return null;    }        return (V) values[i];}
protected int mahout_f6582_0(K key)
{    Object[] tab = table;    byte[] stat = state;    int length = tab.length;    int hash = key.hashCode() & 0x7FFFFFFF;    int i = hash % length;        int decrement = hash % (length - 2);        if (decrement == 0) {        decrement = 1;    }        while (stat[i] == FULL && !equalsMindTheNull(key, tab[i])) {        i -= decrement;                if (i < 0) {            i += length;        }    }    if (stat[i] == REMOVED) {                                int j = i;        while (stat[i] != FREE && (stat[i] == REMOVED || tab[i] != key)) {            i -= decrement;                        if (i < 0) {                i += length;            }        }        if (stat[i] == FREE) {            i = j;        }    }    if (stat[i] == FULL) {                return -i - 1;    }        return i;}
protected int mahout_f6583_0(K key)
{    Object[] tab = table;    byte[] stat = state;    int length = tab.length;    int hash = key.hashCode() & 0x7FFFFFFF;    int i = hash % length;        int decrement = hash % (length - 2);        if (decrement == 0) {        decrement = 1;    }        while (stat[i] != FREE && (stat[i] == REMOVED || !equalsMindTheNull(key, tab[i]))) {        i -= decrement;                if (i < 0) {            i += length;        }    }    if (stat[i] == FREE) {        return -1;    }        return i;}
protected int mahout_f6584_0(V value)
{    Object[] val = values;    byte[] stat = state;    for (int i = stat.length; --i >= 0; ) {        if (stat[i] == FULL && equalsMindTheNull(val[i], value)) {            return i;        }    }        return -1;}
public void mahout_f6585_0(List<K> list)
{    list.clear();    Object[] tab = table;    byte[] stat = state;    for (int i = tab.length; i-- > 0; ) {        if (stat[i] == FULL) {            list.add((K) tab[i]);        }    }}
public V mahout_f6586_0(K key, V value)
{    int i = indexOfInsertion(key);    if (i < 0) {                i = -i - 1;        V previous = (V) this.values[i];        this.values[i] = value;        return previous;    }    if (this.distinct > this.highWaterMark) {        int newCapacity = chooseGrowCapacity(this.distinct + 1, this.minLoadFactor, this.maxLoadFactor);        rehash(newCapacity);        return put(key, value);    }    this.table[i] = key;    this.values[i] = value;    if (this.state[i] == FREE) {        this.freeEntries--;    }    this.state[i] = FULL;    this.distinct++;    if (this.freeEntries < 1) {                int newCapacity = chooseGrowCapacity(this.distinct + 1, this.minLoadFactor, this.maxLoadFactor);        rehash(newCapacity);    }    return null;}
protected void mahout_f6587_0(int newCapacity)
{    int oldCapacity = table.length;        Object[] oldTable = table;    Object[] oldValues = values;    byte[] oldState = state;    Object[] newTable = new Object[newCapacity];    Object[] newValues = new Object[newCapacity];    byte[] newState = new byte[newCapacity];    this.lowWaterMark = chooseLowWaterMark(newCapacity, this.minLoadFactor);    this.highWaterMark = chooseHighWaterMark(newCapacity, this.maxLoadFactor);    this.table = newTable;    this.values = newValues;    this.state = newState;        this.freeEntries = newCapacity - this.distinct;    for (int i = oldCapacity; i-- > 0; ) {        if (oldState[i] == FULL) {            Object element = oldTable[i];            int index = indexOfInsertion((K) element);            newTable[index] = element;            newValues[index] = oldValues[i];            newState[index] = FULL;        }    }}
public V mahout_f6588_0(Object key)
{    int i = indexOfKey((K) key);    if (i < 0) {        return null;    }        V removed = (V) values[i];    this.state[i] = REMOVED;        this.distinct--;    if (this.distinct < this.lowWaterMark) {        int newCapacity = chooseShrinkCapacity(this.distinct, this.minLoadFactor, this.maxLoadFactor);        rehash(newCapacity);    }    return removed;}
protected void mahout_f6589_0(int initialCapacity, double minLoadFactor, double maxLoadFactor)
{    int capacity = initialCapacity;    super.setUp(capacity, minLoadFactor, maxLoadFactor);    capacity = nextPrime(capacity);    if (capacity == 0) {        capacity = 1;    }        this.table = new Object[capacity];    this.values = new Object[capacity];    this.state = new byte[capacity];        this.minLoadFactor = minLoadFactor;    if (capacity == PrimeFinder.LARGEST_PRIME) {        this.maxLoadFactor = 1.0;    } else {        this.maxLoadFactor = maxLoadFactor;    }    this.distinct = 0;        this.freeEntries = capacity;                    this.lowWaterMark = 0;    this.highWaterMark = chooseHighWaterMark(capacity, this.maxLoadFactor);}
public void mahout_f6590_0()
{            int newCapacity = nextPrime((int) (1 + 1.2 * size()));    if (table.length > newCapacity) {        rehash(newCapacity);    }}
 void mahout_f6591_0(int[] capacity, double[] minLoadFactor, double[] maxLoadFactor)
{    capacity[0] = table.length;    minLoadFactor[0] = this.minLoadFactor;    maxLoadFactor[0] = this.maxLoadFactor;}
public K mahout_f6592_0()
{    return key;}
public V mahout_f6593_0()
{    return value;}
public V mahout_f6594_0(V value)
{    throw new UnsupportedOperationException("Map.Entry.setValue not supported for OpenHashMap");}
public Set<java.util.Map.Entry<K, V>> mahout_f6595_0()
{    final Set<Entry<K, V>> entries = new OpenHashSet<>();    forEachPair(new ObjectObjectProcedure<K, V>() {        @Override        public boolean apply(K key, V value) {            entries.add(new MapEntry(key, value));            return true;        }    });    return entries;}
public boolean mahout_f6596_0(K key, V value)
{    entries.add(new MapEntry(key, value));    return true;}
public Set<K> mahout_f6597_0()
{    final Set<K> keys = new OpenHashSet<>();    forEachKey(new ObjectProcedure<K>() {        @Override        public boolean apply(K element) {            keys.add(element);            return true;        }    });    return keys;}
public boolean mahout_f6598_0(K element)
{    keys.add(element);    return true;}
public void mahout_f6599_0(Map<? extends K, ? extends V> m)
{    for (Map.Entry<? extends K, ? extends V> e : m.entrySet()) {        put(e.getKey(), e.getValue());    }}
public Collection<V> mahout_f6600_0()
{    final List<V> valueList = new ArrayList<>();    forEachPair(new ObjectObjectProcedure<K, V>() {        @Override        public boolean apply(K key, V value) {            valueList.add(value);            return true;        }    });    return valueList;}
public boolean mahout_f6601_0(K key, V value)
{    valueList.add(value);    return true;}
public boolean mahout_f6602_0(Object obj)
{    if (!(obj instanceof OpenHashMap)) {        return false;    }    final OpenHashMap<K, V> o = (OpenHashMap<K, V>) obj;    if (o.size() != size()) {        return false;    }    final boolean[] equal = new boolean[1];    equal[0] = true;    forEachPair(new ObjectObjectProcedure<K, V>() {        @Override        public boolean apply(K key, V value) {            Object ov = o.get(key);            if (!value.equals(ov)) {                equal[0] = false;                return false;            }            return true;        }    });    return equal[0];}
public boolean mahout_f6603_0(K key, V value)
{    Object ov = o.get(key);    if (!value.equals(ov)) {        equal[0] = false;        return false;    }    return true;}
public String mahout_f6604_0()
{    final StringBuilder sb = new StringBuilder();    sb.append('{');    forEachPair(new ObjectObjectProcedure<K, V>() {        @Override        public boolean apply(K key, V value) {            sb.append('[');            sb.append(key);            sb.append(" -> ");            sb.append(value);            sb.append("] ");            return true;        }    });    sb.append('}');    return sb.toString();}
public boolean mahout_f6605_0(K key, V value)
{    sb.append('[');    sb.append(key);    sb.append(" -> ");    sb.append(value);    sb.append("] ");    return true;}
public static int mahout_f6606_0(int desiredCapacity)
{    int i = java.util.Arrays.binarySearch(PRIME_CAPACITIES, desiredCapacity);    if (i < 0) {                        i = -i - 1;    }    return PRIME_CAPACITIES[i];}
public boolean mahout_f6607_0(int key, int value)
{    /*       This is open addressing with double hashing, using "Brent's variation".       Brent's variation slows insertions a bit down (not much) but reduces probes (collisions) for successful searches,       in particular for large load factors.       (It does not improve unsuccessful searches.)       See D. Knuth, Searching and Sorting, 3rd ed., p.533-545       h1(key) = hash % M       h2(key) = decrement = Max(1, hash/M % M)       M is prime = capacity = table.length       probing positions are table[(h1-j*h2) % M] for j=0,1,...       (M and h2 could also be chosen differently, but h2 is required to be relative prime to M.)    */    int[] tab = table;    byte[] stat = state;    int length = tab.length;    int hash = HashFunctions.hash(key) & 0x7FFFFFFF;    int i = hash % length;    int decrement = (hash / length) % length;    if (decrement == 0) {        decrement = 1;    }                    int t = 0;        int p0 = i;    while (stat[i] == FULL && tab[i] != key) {        t++;        i -= decrement;                if (i < 0) {            i += length;        }    }    if (stat[i] == FULL) {                this.values[i] = value;        return false;    }    if (this.distinct > this.highWaterMark) {        int newCapacity = chooseGrowCapacity(this.distinct + 1, this.minLoadFactor, this.maxLoadFactor);        rehash(newCapacity);        return put(key, value);    }    /*    Brent's variation does a local reorganization to reduce probes. It essentially means:    We test whether it is possible to move the association we probed first (table[p0]) out of the way.    If this is possible, it will reduce probes for the key to be inserted, since it takes its place;    it gets hit earlier.    However, future probes for the key that we move out of the way will increase.    Thus we only move it out of the way, if we have a net gain, that is, if we save more probes than we loose.    For the first probe we safe more than we loose if the number of probes we needed was >=2 (t>=2).    If the first probe cannot be moved out of the way, we try the next probe (p1).    Now we safe more than we loose if t>=3.    We repeat this until we find that we cannot gain or that we can indeed move p(x) out of the way.    Note: Under the great majority of insertions t<=1, so the loop is entered very infrequently.    */    while (t > 1) {        int key0 = tab[p0];        hash = HashFunctions.hash(key0) & 0x7FFFFFFF;        decrement = (hash / length) % length;        if (decrement == 0) {            decrement = 1;        }                int pc = p0 - decrement;        if (pc < 0) {            pc += length;        }        if (stat[pc] != FREE) {                        p0 = pc;            t--;        } else {                        tab[pc] = key0;            stat[pc] = FULL;            values[pc] = values[p0];                        i = p0;                        t = 0;        }    }    this.table[i] = key;    this.values[i] = value;    if (this.state[i] == FREE) {        this.freeEntries--;    }    this.state[i] = FULL;    this.distinct++;    if (this.freeEntries < 1) {                int newCapacity = chooseGrowCapacity(this.distinct + 1, this.minLoadFactor, this.maxLoadFactor);        rehash(newCapacity);    }    return true;}
protected void mahout_f6608_0(int newCapacity)
{    int oldCapacity = table.length;        int[] oldTable = table;    int[] oldValues = values;    byte[] oldState = state;    int[] newTable = new int[newCapacity];    int[] newValues = new int[newCapacity];    byte[] newState = new byte[newCapacity];    this.lowWaterMark = chooseLowWaterMark(newCapacity, this.minLoadFactor);    this.highWaterMark = chooseHighWaterMark(newCapacity, this.maxLoadFactor);    this.table = newTable;    this.values = newValues;    this.state = newState;        this.freeEntries = newCapacity - this.distinct;    int tmp = this.distinct;        this.distinct = Integer.MIN_VALUE;    for (int i = oldCapacity; i-- > 0; ) {        if (oldState[i] == FULL) {            put(oldTable[i], oldValues[i]);        /*        int element = oldTable[i];        int index = indexOfInsertion(element);        newTable[index]=element;        newValues[index]=oldValues[i];        newState[index]=FULL;        */        }    }    this.distinct = tmp;}
public static Matrix mahout_f6609_0(final int rows, final int columns, final IntIntFunction gf, final boolean denseLike)
{    return new FunctionalMatrixView(rows, columns, gf, denseLike);}
public static Matrix mahout_f6610_0(final int rows, final int columns, final IntIntFunction gf)
{    return new FunctionalMatrixView(rows, columns, gf);}
public static Matrix mahout_f6611_0(final Matrix m)
{    Preconditions.checkArgument(!(m instanceof SparseColumnMatrix));    if (m instanceof TransposedMatrixView) {        return ((TransposedMatrixView) m).getDelegate();    } else {        return new TransposedMatrixView(m);    }}
public static Matrix mahout_f6612_0(final int rows, final int columns, long seed)
{    return functionalMatrixView(rows, columns, gaussianGenerator(seed), true);}
public static Matrix mahout_f6613_0(final int rows, final int columns, int seed)
{    return functionalMatrixView(rows, columns, uniformSymmetricGenerator(seed), true);}
public static Matrix mahout_f6614_0(final int rows, final int columns, int seed)
{    return functionalMatrixView(rows, columns, uniformGenerator(seed), true);}
public static IntIntFunction mahout_f6615_0(final long seed)
{    final Random rnd = RandomUtils.getRandom(seed);    return new IntIntFunction() {        @Override        public double apply(int first, int second) {            rnd.setSeed(seed ^ (((long) first << 32) | (second & 0xffffffffL)));            return rnd.nextGaussian();        }    };}
public double mahout_f6616_0(int first, int second)
{    rnd.setSeed(seed ^ (((long) first << 32) | (second & 0xffffffffL)));    return rnd.nextGaussian();}
public static IntIntFunction mahout_f6617_0(final int seed)
{    return new IntIntFunction() {        private byte[] data = new byte[8];        @Override        public double apply(int row, int column) {            long d = ((long) row << Integer.SIZE) | (column & 0xffffffffL);            for (int i = 0; i < 8; i++, d >>>= 8) data[i] = (byte) d;            long hash = MurmurHash.hash64A(data, seed);            return hash / UNIFORM_DIVISOR;        }    };}
public double mahout_f6618_0(int row, int column)
{    long d = ((long) row << Integer.SIZE) | (column & 0xffffffffL);    for (int i = 0; i < 8; i++, d >>>= 8) data[i] = (byte) d;    long hash = MurmurHash.hash64A(data, seed);    return hash / UNIFORM_DIVISOR;}
public static IntIntFunction mahout_f6619_0(final int seed)
{    return Functions.chain(new DoubleFunction() {        @Override        public double apply(double x) {            return (x + 1.0) / 2.0;        }    }, uniformSymmetricGenerator(seed));}
public double mahout_f6620_0(double x)
{    return (x + 1.0) / 2.0;}
public Vector mahout_f6621_0()
{    return getVector();}
public int mahout_f6622_0()
{    return index;}
private static int mahout_f6623_0(Matrix matrix, int row, int column, int rowStride, int columnStride)
{    if (rowStride != 0 && columnStride != 0) {        int n1 = (matrix.numRows() - row) / rowStride;        int n2 = (matrix.numCols() - column) / columnStride;        return Math.min(n1, n2);    } else if (rowStride > 0) {        return (matrix.numRows() - row) / rowStride;    } else {        return (matrix.numCols() - column) / columnStride;    }}
public boolean mahout_f6624_0()
{    return isDense;}
public boolean mahout_f6625_0()
{    return true;}
public Iterator<Element> mahout_f6626_0()
{    final LocalElement r = new LocalElement(0);    return new Iterator<Element>() {        private int i;        @Override        public boolean hasNext() {            return i < size();        }        @Override        public Element next() {            if (i >= size()) {                throw new NoSuchElementException();            }            r.index = i++;            return r;        }        @Override        public void remove() {            throw new UnsupportedOperationException("Can't remove from a view");        }    };}
public boolean mahout_f6627_0()
{    return i < size();}
public Element mahout_f6628_0()
{    if (i >= size()) {        throw new NoSuchElementException();    }    r.index = i++;    return r;}
public void mahout_f6629_0()
{    throw new UnsupportedOperationException("Can't remove from a view");}
public Iterator<Element> mahout_f6630_0()
{    return new Iterator<Element>() {        class NonZeroElement implements Element {            int index;            @Override            public double get() {                return getQuick(index);            }            @Override            public int index() {                return index;            }            @Override            public void set(double value) {                invalidateCachedLength();                setQuick(index, value);            }        }        private final NonZeroElement element = new NonZeroElement();        private int index = -1;        private int lookAheadIndex = -1;        @Override        public boolean hasNext() {            if (lookAheadIndex == index) {                                lookAhead();            }                        return lookAheadIndex < size();        }        private void lookAhead() {            lookAheadIndex++;            while (lookAheadIndex < size() && getQuick(lookAheadIndex) == 0.0) {                lookAheadIndex++;            }        }        @Override        public Element next() {            if (lookAheadIndex == index) {                                lookAhead();            }            index = lookAheadIndex;            if (index >= size()) {                                throw new NoSuchElementException();            }            element.index = index;            return element;        }        @Override        public void remove() {            throw new UnsupportedOperationException();        }    };}
public double mahout_f6631_0()
{    return getQuick(index);}
public int mahout_f6632_0()
{    return index;}
public void mahout_f6633_0(double value)
{    invalidateCachedLength();    setQuick(index, value);}
public boolean mahout_f6634_0()
{    if (lookAheadIndex == index) {                lookAhead();    }        return lookAheadIndex < size();}
private void mahout_f6635_0()
{    lookAheadIndex++;    while (lookAheadIndex < size() && getQuick(lookAheadIndex) == 0.0) {        lookAheadIndex++;    }}
public Element mahout_f6636_0()
{    if (lookAheadIndex == index) {                lookAhead();    }    index = lookAheadIndex;    if (index >= size()) {                throw new NoSuchElementException();    }    element.index = index;    return element;}
public void mahout_f6637_0()
{    throw new UnsupportedOperationException();}
public double mahout_f6638_0(int index)
{    return matrix.getQuick(row + rowStride * index, column + columnStride * index);}
public Vector mahout_f6639_0()
{    return matrix.like(size(), 1).viewColumn(0);}
public Vector mahout_f6640_0(int cardinality)
{    return matrix.like(cardinality, 1).viewColumn(0);}
public void mahout_f6641_0(int index, double value)
{    matrix.setQuick(row + rowStride * index, column + columnStride * index, value);}
public int mahout_f6642_0()
{    return size();}
public double mahout_f6643_0()
{        return 1;}
public double mahout_f6644_0()
{        return 1;}
public boolean mahout_f6645_0()
{        return true;}
protected Matrix mahout_f6646_0(int rows, int columns)
{    return matrix.like(rows, columns);}
public Vector mahout_f6647_0()
{    MatrixVectorView r = (MatrixVectorView) super.clone();    r.matrix = matrix.clone();    r.row = row;    r.column = column;    r.rowStride = rowStride;    r.columnStride = columnStride;    return r;}
public void mahout_f6648_0(OrderedIntDoubleMapping updates)
{    int[] indices = updates.getIndices();    double[] values = updates.getValues();    for (int i = 0; i < updates.getNumMappings(); ++i) {        matrix.setQuick(row + rowStride * indices[i], column + columnStride * indices[i], values[i]);    }}
public Matrix mahout_f6649_0()
{    MatrixView clone = (MatrixView) super.clone();    clone.matrix = matrix.clone();    clone.offset = offset.clone();    return clone;}
public double mahout_f6650_0(int row, int column)
{    return matrix.getQuick(offset[ROW] + row, offset[COL] + column);}
public Matrix mahout_f6651_0()
{    return matrix.like(rowSize(), columnSize());}
public Matrix mahout_f6652_0(int rows, int columns)
{    return matrix.like(rows, columns);}
public void mahout_f6653_0(int row, int column, double value)
{    matrix.setQuick(offset[ROW] + row, offset[COL] + column, value);}
public int[] mahout_f6654_0()
{    return new int[] { rowSize(), columnSize() };}
public Matrix mahout_f6655_0(int[] offset, int[] size)
{    if (offset[ROW] < 0) {        throw new IndexException(offset[ROW], 0);    }    if (offset[ROW] + size[ROW] > rowSize()) {        throw new IndexException(offset[ROW] + size[ROW], rowSize());    }    if (offset[COL] < 0) {        throw new IndexException(offset[COL], 0);    }    if (offset[COL] + size[COL] > columnSize()) {        throw new IndexException(offset[COL] + size[COL], columnSize());    }    int[] origin = this.offset.clone();    origin[ROW] += offset[ROW];    origin[COL] += offset[COL];    return new MatrixView(matrix, origin, size);}
public Matrix mahout_f6656_0(int column, Vector other)
{    if (rowSize() != other.size()) {        throw new CardinalityException(rowSize(), other.size());    }    for (int row = 0; row < rowSize(); row++) {        matrix.setQuick(row + offset[ROW], column + offset[COL], other.getQuick(row));    }    return this;}
public Matrix mahout_f6657_0(int row, Vector other)
{    if (columnSize() != other.size()) {        throw new CardinalityException(columnSize(), other.size());    }    for (int col = 0; col < columnSize(); col++) {        matrix.setQuick(row + offset[ROW], col + offset[COL], other.getQuick(col));    }    return this;}
public Vector mahout_f6658_0(int column)
{    if (column < 0 || column >= columnSize()) {        throw new IndexException(column, columnSize());    }    return matrix.viewColumn(column + offset[COL]).viewPart(offset[ROW], rowSize());}
public Vector mahout_f6659_0(int row)
{    if (row < 0 || row >= rowSize()) {        throw new IndexException(row, rowSize());    }    return matrix.viewRow(row + offset[ROW]).viewPart(offset[COL], columnSize());}
public MatrixFlavor mahout_f6660_0()
{    return matrix.getFlavor();}
public static int mahout_f6661_0(int data, int seed)
{    return hash(ByteBuffer.wrap(Ints.toByteArray(data)), seed);}
public static int mahout_f6662_0(byte[] data, int seed)
{    return hash(ByteBuffer.wrap(data), seed);}
public static int mahout_f6663_0(byte[] data, int offset, int length, int seed)
{    return hash(ByteBuffer.wrap(data, offset, length), seed);}
public static int mahout_f6664_0(ByteBuffer buf, int seed)
{        ByteOrder byteOrder = buf.order();    buf.order(ByteOrder.LITTLE_ENDIAN);    int m = 0x5bd1e995;    int r = 24;    int h = seed ^ buf.remaining();    while (buf.remaining() >= 4) {        int k = buf.getInt();        k *= m;        k ^= k >>> r;        k *= m;        h *= m;        h ^= k;    }    if (buf.remaining() > 0) {        ByteBuffer finish = ByteBuffer.allocate(4).order(ByteOrder.LITTLE_ENDIAN);                        finish.put(buf).rewind();        h ^= finish.getInt();        h *= m;    }    h ^= h >>> 13;    h *= m;    h ^= h >>> 15;    buf.order(byteOrder);    return h;}
public static long mahout_f6665_0(byte[] data, int seed)
{    return hash64A(ByteBuffer.wrap(data), seed);}
public static long mahout_f6666_0(byte[] data, int offset, int length, int seed)
{    return hash64A(ByteBuffer.wrap(data, offset, length), seed);}
public static long mahout_f6667_0(ByteBuffer buf, int seed)
{    ByteOrder byteOrder = buf.order();    buf.order(ByteOrder.LITTLE_ENDIAN);    long m = 0xc6a4a7935bd1e995L;    int r = 47;    long h = seed ^ (buf.remaining() * m);    while (buf.remaining() >= 8) {        long k = buf.getLong();        k *= m;        k ^= k >>> r;        k *= m;        h ^= k;        h *= m;    }    if (buf.remaining() > 0) {        ByteBuffer finish = ByteBuffer.allocate(8).order(ByteOrder.LITTLE_ENDIAN);                        finish.put(buf).rewind();        h ^= finish.getLong();        h *= m;    }    h ^= h >>> r;    h *= m;    h ^= h >>> r;    buf.order(byteOrder);    return h;}
public static int mahout_f6668_0(byte[] data, int offset, int len, int seed)
{    int c1 = 0xcc9e2d51;    int c2 = 0x1b873593;    int h1 = seed;        int roundedEnd = offset + (len & 0xfffffffc);    for (int i = offset; i < roundedEnd; i += 4) {                int k1 = (data[i] & 0xff) | ((data[i + 1] & 0xff) << 8) | ((data[i + 2] & 0xff) << 16) | (data[i + 3] << 24);        k1 *= c1;                k1 = (k1 << 15) | (k1 >>> 17);        k1 *= c2;        h1 ^= k1;                h1 = (h1 << 13) | (h1 >>> 19);        h1 = h1 * 5 + 0xe6546b64;    }        int k1 = 0;    switch(len & 0x03) {        case 3:            k1 = (data[roundedEnd + 2] & 0xff) << 16;                case 2:            k1 |= (data[roundedEnd + 1] & 0xff) << 8;                case 1:            k1 |= data[roundedEnd] & 0xff;            k1 *= c1;                        k1 = (k1 << 15) | (k1 >>> 17);            k1 *= c2;            h1 ^= k1;        default:    }        h1 ^= len;        h1 ^= h1 >>> 16;    h1 *= 0x85ebca6b;    h1 ^= h1 >>> 13;    h1 *= 0xc2b2ae35;    h1 ^= h1 >>> 16;    return h1;}
public String mahout_f6669_0()
{    return name;}
public Vector mahout_f6670_0()
{    return delegate;}
public int mahout_f6671_0()
{    return delegate.hashCode();}
public boolean mahout_f6672_0(Object other)
{    return delegate.equals(other);}
public NamedVector mahout_f6673_0()
{    return new NamedVector(delegate.clone(), name);}
public Iterable<Element> mahout_f6674_0()
{    return delegate.all();}
public Iterable<Element> mahout_f6675_0()
{    return delegate.nonZeroes();}
public String mahout_f6676_0()
{    return toString();}
public String mahout_f6677_0()
{    StringBuilder bldr = new StringBuilder();    bldr.append(name).append(':').append(delegate.toString());    return bldr.toString();}
public Vector mahout_f6678_0(double value)
{    return delegate.assign(value);}
public Vector mahout_f6679_0(double[] values)
{    return delegate.assign(values);}
public Vector mahout_f6680_0(Vector other)
{    return delegate.assign(other);}
public Vector mahout_f6681_0(DoubleFunction function)
{    return delegate.assign(function);}
public Vector mahout_f6682_0(Vector other, DoubleDoubleFunction function)
{    return delegate.assign(other, function);}
public Vector mahout_f6683_0(DoubleDoubleFunction f, double y)
{    return delegate.assign(f, y);}
public int mahout_f6684_0()
{    return delegate.size();}
public boolean mahout_f6685_0()
{    return delegate.isDense();}
public boolean mahout_f6686_0()
{    return delegate.isSequentialAccess();}
public Element mahout_f6687_0(int index)
{    return delegate.getElement(index);}
public void mahout_f6688_0(OrderedIntDoubleMapping updates)
{    delegate.mergeUpdates(updates);}
public Vector mahout_f6689_0(double x)
{    return delegate.divide(x);}
public double mahout_f6690_0(Vector x)
{    return delegate.dot(x);}
public double mahout_f6691_0(int index)
{    return delegate.get(index);}
public double mahout_f6692_0(int index)
{    return delegate.getQuick(index);}
public NamedVector mahout_f6693_0()
{    return new NamedVector(delegate.like(), name);}
public Vector mahout_f6694_0(int cardinality)
{    return new NamedVector(delegate.like(cardinality), name);}
public Vector mahout_f6695_0(Vector x)
{    return delegate.minus(x);}
public Vector mahout_f6696_0()
{    return delegate.normalize();}
public Vector mahout_f6697_0(double power)
{    return delegate.normalize(power);}
public Vector mahout_f6698_0()
{    return delegate.logNormalize();}
public Vector mahout_f6699_0(double power)
{    return delegate.logNormalize(power);}
public double mahout_f6700_0(double power)
{    return delegate.norm(power);}
public double mahout_f6701_0()
{    return delegate.maxValue();}
public int mahout_f6702_0()
{    return delegate.maxValueIndex();}
public double mahout_f6703_0()
{    return delegate.minValue();}
public int mahout_f6704_0()
{    return delegate.minValueIndex();}
public Vector mahout_f6705_0(double x)
{    return delegate.plus(x);}
public Vector mahout_f6706_0(Vector x)
{    return delegate.plus(x);}
public void mahout_f6707_0(int index, double value)
{    delegate.set(index, value);}
public void mahout_f6708_0(int index, double value)
{    delegate.setQuick(index, value);}
public void mahout_f6709_0(int index, double increment)
{    delegate.incrementQuick(index, increment);}
public int mahout_f6710_0()
{    return delegate.getNumNonZeroElements();}
public int mahout_f6711_0()
{    return delegate.getNumNondefaultElements();}
public Vector mahout_f6712_0(double x)
{    return delegate.times(x);}
public Vector mahout_f6713_0(Vector x)
{    return delegate.times(x);}
public Vector mahout_f6714_0(int offset, int length)
{    return delegate.viewPart(offset, length);}
public double mahout_f6715_0()
{    return delegate.zSum();}
public Matrix mahout_f6716_0(Vector other)
{    return delegate.cross(other);}
public double mahout_f6717_0(DoubleDoubleFunction aggregator, DoubleFunction map)
{    return delegate.aggregate(aggregator, map);}
public double mahout_f6718_0(Vector other, DoubleDoubleFunction aggregator, DoubleDoubleFunction combiner)
{    return delegate.aggregate(other, aggregator, combiner);}
public double mahout_f6719_0()
{    return delegate.getLengthSquared();}
public double mahout_f6720_0(Vector v)
{    return delegate.getDistanceSquared(v);}
public double mahout_f6721_0()
{    return delegate.getLookupCost();}
public double mahout_f6722_0()
{    return delegate.getIteratorAdvanceCost();}
public boolean mahout_f6723_0()
{    return delegate.isAddConstantTime();}
public Matrix mahout_f6724_0()
{    int columns = Math.min(originalColumns, originalRows);    Matrix q = qr.like(originalRows, columns);    for (int k = columns - 1; k >= 0; k--) {        Vector QRcolk = qr.viewColumn(k).viewPart(k, originalRows - k);        q.set(k, k, 1);        for (int j = k; j < columns; j++) {            if (qr.get(k, k) != 0) {                Vector Qcolj = q.viewColumn(j).viewPart(k, originalRows - k);                double s = -QRcolk.dot(Qcolj) / qr.get(k, k);                Qcolj.assign(QRcolk, Functions.plusMult(s));            }        }    }    return q;}
public Matrix mahout_f6725_0()
{    int rows = Math.min(originalRows, originalColumns);    Matrix r = qr.like(rows, originalColumns);    for (int i = 0; i < rows; i++) {        for (int j = 0; j < originalColumns; j++) {            if (i < j) {                r.setQuick(i, j, qr.getQuick(i, j));            } else if (i == j) {                r.setQuick(i, j, rDiag.getQuick(i));            } else {                r.setQuick(i, j, 0);            }        }    }    return r;}
public boolean mahout_f6726_0()
{    for (int j = 0; j < originalColumns; j++) {        if (rDiag.getQuick(j) == 0) {            return false;        }    }    return true;}
public Matrix mahout_f6727_0(Matrix B)
{    if (B.numRows() != originalRows) {        throw new IllegalArgumentException("Matrix row dimensions must agree.");    }    int columns = B.numCols();    Matrix x = B.like(originalColumns, columns);                Matrix qt = getQ().transpose();    Matrix y = qt.times(B);    Matrix r = getR();    for (int k = Math.min(originalColumns, originalRows) - 1; k >= 0; k--) {                x.viewRow(k).assign(y.viewRow(k), Functions.plusMult(1 / r.get(k, k)));                Vector rColumn = r.viewColumn(k).viewPart(0, k);        for (int c = 0; c < columns; c++) {            y.viewColumn(c).viewPart(0, k).assign(rColumn, Functions.plusMult(-x.get(k, c)));        }    }    return x;}
public String mahout_f6728_0()
{    return String.format(Locale.ENGLISH, "QR(%d,%d,fullRank=%s)", originalColumns, originalRows, hasFullRank());}
public int[] mahout_f6729_0()
{    return indices;}
public int mahout_f6730_0(int offset)
{    return indices[offset];}
public void mahout_f6731_0(int offset, int index)
{    indices[offset] = index;}
public double[] mahout_f6732_0()
{    return values;}
public void mahout_f6733_0(int offset, double value)
{    values[offset] = value;}
public int mahout_f6734_0()
{    return numMappings;}
private void mahout_f6735_0(int newCapacity)
{    if (newCapacity > indices.length) {        int[] newIndices = new int[newCapacity];        System.arraycopy(indices, 0, newIndices, 0, numMappings);        indices = newIndices;        double[] newValues = new double[newCapacity];        System.arraycopy(values, 0, newValues, 0, numMappings);        values = newValues;    }}
private int mahout_f6736_0(int index)
{    int low = 0;    int high = numMappings - 1;    while (low <= high) {        int mid = low + (high - low >>> 1);        int midVal = indices[mid];        if (midVal < index) {            low = mid + 1;        } else if (midVal > index) {            high = mid - 1;        } else {            return mid;        }    }    return -(low + 1);}
public double mahout_f6737_0(int index)
{    int offset = find(index);    return offset >= 0 ? values[offset] : DEFAULT_VALUE;}
public void mahout_f6738_0(int index, double value)
{    if (numMappings == 0 || index > indices[numMappings - 1]) {        if (!noDefault || value != DEFAULT_VALUE) {            if (numMappings >= indices.length) {                growTo(Math.max((int) (1.2 * numMappings), numMappings + 1));            }            indices[numMappings] = index;            values[numMappings] = value;            ++numMappings;        }    } else {        int offset = find(index);        if (offset >= 0) {            insertOrUpdateValueIfPresent(offset, value);        } else {            insertValueIfNotDefault(index, offset, value);        }    }}
public void mahout_f6739_0(OrderedIntDoubleMapping updates)
{    int[] updateIndices = updates.getIndices();    double[] updateValues = updates.getValues();    int newNumMappings = numMappings + updates.getNumMappings();    int newCapacity = Math.max((int) (1.2 * newNumMappings), newNumMappings + 1);    int[] newIndices = new int[newCapacity];    double[] newValues = new double[newCapacity];    int k = 0;    int i = 0, j = 0;    for (; i < numMappings && j < updates.getNumMappings(); ++k) {        if (indices[i] < updateIndices[j]) {            newIndices[k] = indices[i];            newValues[k] = values[i];            ++i;        } else if (indices[i] > updateIndices[j]) {            newIndices[k] = updateIndices[j];            newValues[k] = updateValues[j];            ++j;        } else {            newIndices[k] = updateIndices[j];            newValues[k] = updateValues[j];            ++i;            ++j;        }    }    for (; i < numMappings; ++i, ++k) {        newIndices[k] = indices[i];        newValues[k] = values[i];    }    for (; j < updates.getNumMappings(); ++j, ++k) {        newIndices[k] = updateIndices[j];        newValues[k] = updateValues[j];    }    indices = newIndices;    values = newValues;    numMappings = k;}
public int mahout_f6740_0()
{    int result = 0;    for (int i = 0; i < numMappings; i++) {        result = 31 * result + indices[i];        result = 31 * result + (int) Double.doubleToRawLongBits(values[i]);    }    return result;}
public boolean mahout_f6741_0(Object o)
{    if (o instanceof OrderedIntDoubleMapping) {        OrderedIntDoubleMapping other = (OrderedIntDoubleMapping) o;        if (numMappings == other.numMappings) {            for (int i = 0; i < numMappings; i++) {                if (indices[i] != other.indices[i] || values[i] != other.values[i]) {                    return false;                }            }            return true;        }    }    return false;}
public String mahout_f6742_0()
{    StringBuilder result = new StringBuilder(10 * numMappings);    for (int i = 0; i < numMappings; i++) {        result.append('(');        result.append(indices[i]);        result.append(',');        result.append(values[i]);        result.append(')');    }    return result.toString();}
public OrderedIntDoubleMapping mahout_f6743_0()
{    return new OrderedIntDoubleMapping(indices.clone(), values.clone(), numMappings);}
public void mahout_f6744_0(int index, double increment)
{    int offset = find(index);    if (offset >= 0) {        double newValue = values[offset] + increment;        insertOrUpdateValueIfPresent(offset, newValue);    } else {        insertValueIfNotDefault(index, offset, increment);    }}
private void mahout_f6745_0(int index, int offset, double value)
{    if (!noDefault || value != DEFAULT_VALUE) {        if (numMappings >= indices.length) {            growTo(Math.max((int) (1.2 * numMappings), numMappings + 1));        }        int at = -offset - 1;        if (numMappings > at) {            for (int i = numMappings - 1, j = numMappings; i >= at; i--, j--) {                indices[j] = indices[i];                values[j] = values[i];            }        }        indices[at] = index;        values[at] = value;        numMappings++;    }}
private void mahout_f6746_0(int offset, double newValue)
{    if (noDefault && newValue == DEFAULT_VALUE) {        for (int i = offset + 1, j = offset; i < numMappings; i++, j++) {            indices[j] = indices[i];            values[j] = values[i];        }        numMappings--;    } else {        values[offset] = newValue;    }}
public static VectorIterable mahout_f6747_0(Iterable<MatrixSlice> basis)
{    DenseMatrix out = null;    for (MatrixSlice slice1 : basis) {        List<Double> dots = Lists.newArrayList();        for (MatrixSlice slice2 : basis) {            dots.add(slice1.vector().dot(slice2.vector()));        }        if (out == null) {            out = new DenseMatrix(dots.size(), dots.size());        }        for (int i = 0; i < dots.size(); i++) {            out.set(slice1.index(), i, dots.get(i));        }    }    return out;}
private static int[] mahout_f6748_0(int[] pivot)
{    int[] unpivot1 = new int[pivot.length];    for (int i = 0; i < pivot.length; i++) {        unpivot1[pivot[i]] = i;    }    return unpivot1;}
protected Matrix mahout_f6749_0(int rows, int columns)
{    if (vector.isDense()) {        return new DenseMatrix(rows, columns);    } else {        return new SparseRowMatrix(rows, columns);    }}
public void mahout_f6750_0(OrderedIntDoubleMapping updates)
{    for (int i = 0; i < updates.getNumMappings(); ++i) {        updates.setIndexAt(i, pivot[updates.indexAt(i)]);    }    vector.mergeUpdates(updates);}
public boolean mahout_f6751_0()
{    return vector.isDense();}
public boolean mahout_f6752_0()
{    return false;}
public Iterator<Element> mahout_f6753_0()
{    return new AbstractIterator<Element>() {        private final Iterator<Element> i = vector.all().iterator();        @Override        protected Vector.Element computeNext() {            if (i.hasNext()) {                final Element x = i.next();                return new Element() {                    private final int index = unpivot[x.index()];                    @Override                    public double get() {                        return x.get();                    }                    @Override                    public int index() {                        return index;                    }                    @Override                    public void set(double value) {                        x.set(value);                    }                };            } else {                return endOfData();            }        }    };}
protected Vector.Element mahout_f6754_0()
{    if (i.hasNext()) {        final Element x = i.next();        return new Element() {            private final int index = unpivot[x.index()];            @Override            public double get() {                return x.get();            }            @Override            public int index() {                return index;            }            @Override            public void set(double value) {                x.set(value);            }        };    } else {        return endOfData();    }}
public double mahout_f6755_0()
{    return x.get();}
public int mahout_f6756_0()
{    return index;}
public void mahout_f6757_0(double value)
{    x.set(value);}
public Iterator<Element> mahout_f6758_0()
{    return new AbstractIterator<Element>() {        private final Iterator<Element> i = vector.nonZeroes().iterator();        @Override        protected Vector.Element computeNext() {            if (i.hasNext()) {                final Element x = i.next();                return new Element() {                    private final int index = unpivot[x.index()];                    @Override                    public double get() {                        return x.get();                    }                    @Override                    public int index() {                        return index;                    }                    @Override                    public void set(double value) {                        x.set(value);                    }                };            } else {                return endOfData();            }        }    };}
protected Vector.Element mahout_f6759_0()
{    if (i.hasNext()) {        final Element x = i.next();        return new Element() {            private final int index = unpivot[x.index()];            @Override            public double get() {                return x.get();            }            @Override            public int index() {                return index;            }            @Override            public void set(double value) {                x.set(value);            }        };    } else {        return endOfData();    }}
public double mahout_f6760_0()
{    return x.get();}
public int mahout_f6761_0()
{    return index;}
public void mahout_f6762_0(double value)
{    x.set(value);}
public double mahout_f6763_0(int index)
{    return vector.getQuick(pivot[index]);}
public Vector mahout_f6764_0()
{    return vector.like();}
public Vector mahout_f6765_0(int cardinality)
{    return vector.like(cardinality);}
public void mahout_f6766_0(int index, double value)
{    vector.setQuick(pivot[index], value);}
public int mahout_f6767_0()
{    return vector.getNumNondefaultElements();}
public int mahout_f6768_0()
{        return vector.getNumNonZeroElements();}
public double mahout_f6769_0()
{    return vector.getLookupCost();}
public double mahout_f6770_0()
{    return vector.getIteratorAdvanceCost();}
public boolean mahout_f6771_0()
{    return vector.isAddConstantTime();}
public Object mahout_f6772_0()
{    try {        return super.clone();    } catch (CloneNotSupportedException exc) {                throw new InternalError();    }}
public void mahout_f6773_0(int i, int j)
{    swapRows(i, j);    swapColumns(i, j);}
public void mahout_f6774_0(int i, int j)
{    swap(rowPivot, rowUnpivot, i, j);}
public void mahout_f6775_0(int i, int j)
{    swap(columnPivot, columnUnpivot, i, j);}
private static void mahout_f6776_0(int[] pivot, int[] unpivot, int i, int j)
{    Preconditions.checkPositionIndex(i, pivot.length);    Preconditions.checkPositionIndex(j, pivot.length);    if (i != j) {        int tmp = pivot[i];        pivot[i] = pivot[j];        pivot[j] = tmp;        unpivot[pivot[i]] = i;        unpivot[pivot[j]] = j;    }}
public Matrix mahout_f6777_0(int column, Vector other)
{        return base.assignColumn(columnPivot[column], new PermutedVectorView(other, rowUnpivot, rowPivot));}
public Matrix mahout_f6778_0(int row, Vector other)
{        return base.assignRow(rowPivot[row], new PermutedVectorView(other, columnUnpivot, columnPivot));}
public Vector mahout_f6779_0(int column)
{    if (column < 0 || column >= columnSize()) {        throw new IndexException(column, columnSize());    }    return new PermutedVectorView(base.viewColumn(columnPivot[column]), rowPivot, rowUnpivot);}
public Vector mahout_f6780_0(int row)
{    if (row < 0 || row >= rowSize()) {        throw new IndexException(row, rowSize());    }    return new PermutedVectorView(base.viewRow(rowPivot[row]), columnPivot, columnUnpivot);}
public double mahout_f6781_0(int row, int column)
{    return base.getQuick(rowPivot[row], columnPivot[column]);}
public Matrix mahout_f6782_0()
{    return new PivotedMatrix(base.like());}
public Matrix mahout_f6783_0()
{    PivotedMatrix clone = (PivotedMatrix) super.clone();    base = base.clone();    rowPivot = rowPivot.clone();    rowUnpivot = rowUnpivot.clone();    columnPivot = columnPivot.clone();    columnUnpivot = columnUnpivot.clone();    return clone;}
public Matrix mahout_f6784_0(int rows, int columns)
{    return new PivotedMatrix(base.like(rows, columns));}
public void mahout_f6785_0(int row, int column, double value)
{    base.setQuick(rowPivot[row], columnPivot[column], value);}
public int[] mahout_f6786_0()
{    return base.getNumNondefaultElements();}
public Matrix mahout_f6787_0(int[] offset, int[] size)
{    return new MatrixView(this, offset, size);}
public int mahout_f6788_0(int k)
{    return rowUnpivot[k];}
public int mahout_f6789_0(int k)
{    return columnUnpivot[k];}
public int[] mahout_f6790_0()
{    return rowPivot;}
public int[] mahout_f6791_0()
{    return rowUnpivot;}
public int[] mahout_f6792_0()
{    return columnPivot;}
public int[] mahout_f6793_0()
{    return columnUnpivot;}
public Matrix mahout_f6794_0()
{    return base;}
private static int[] mahout_f6795_0(int n)
{    int[] pivot = new int[n];    for (int i = 0; i < n; i++) {        pivot[i] = i;    }    return pivot;}
private static int[] mahout_f6796_0(int[] pivot)
{    int[] x = new int[pivot.length];    for (int i = 0; i < pivot.length; i++) {        x[pivot[i]] = i;    }    return x;}
public Matrix mahout_f6797_0()
{    return q;}
public Matrix mahout_f6798_0()
{    return r;}
public boolean mahout_f6799_0()
{    return fullRank;}
public Matrix mahout_f6800_0(Matrix B)
{    if (B.numRows() != rows) {        throw new IllegalArgumentException("Matrix row dimensions must agree.");    }    int cols = B.numCols();    Matrix x = mType.like(columns, cols);                Matrix qt = getQ().transpose();    Matrix y = qt.times(B);    Matrix r = getR();    for (int k = Math.min(columns, rows) - 1; k >= 0; k--) {                x.viewRow(k).assign(y.viewRow(k), Functions.plusMult(1 / r.get(k, k)));                Vector rColumn = r.viewColumn(k).viewPart(0, k);        for (int c = 0; c < cols; c++) {            y.viewColumn(c).viewPart(0, k).assign(rColumn, Functions.plusMult(-x.get(k, c)));        }    }    return x;}
public String mahout_f6801_0()
{    return String.format(Locale.ENGLISH, "QR(%d x %d,fullRank=%s)", rows, columns, hasFullRank());}
public double mahout_f6802_0(double ignored)
{    return sample();}
public Integer mahout_f6803_0()
{    double u = rand.nextDouble() * (alpha + weight);    for (int j = 0; j < weights.size(); j++) {                if (u < weights.get(j) - discount) {            weights.set(j, weights.get(j) + 1);            weight++;            return j;        } else {            u -= weights.get(j) - discount;        }    }            weights.add(1);    weight++;    return weights.size() - 1;}
public int mahout_f6804_0()
{    return weights.size();}
public int mahout_f6805_0()
{    return (int) weight;}
public int mahout_f6806_0(int j)
{    Preconditions.checkArgument(j >= 0);    if (j < weights.size()) {        return (int) weights.get(j);    } else {        return 0;    }}
public Double mahout_f6807_0()
{    return sample(gen.nextDouble());}
public double mahout_f6808_0(double u)
{    if (exceedMinimum && u < x[0]) {                if (u == 0) {            u = 1.0e-16;        }        return y[0] + Math.log(u / x[0]) * x[0] * (y[1] - y[0]) / (x[1] - x[0]);    } else if (exceedMaximum && u > x[n - 1]) {        if (u == 1) {            u = 1 - 1.0e-16;        }                double dy = y[n - 1] - y[n - 2];        double dx = x[n - 1] - x[n - 2];        return y[n - 1] - Math.log((1 - u) / (1 - x[n - 1])) * (1 - x[n - 1]) * dy / dx;    } else {                for (int i = 1; i < n; i++) {            if (x[i] > u) {                double dy = y[i] - y[i - 1];                double dx = x[i] - x[i - 1];                return y[i - 1] + (u - x[i - 1]) * dy / dx;            }        }        throw new RuntimeException(String.format("Can't happen (%.3f is not in [%.3f,%.3f]", u, x[0], x[n - 1]));    }}
public static IndianBuffet<Integer> mahout_f6809_0(double alpha)
{    return new IndianBuffet<>(alpha, new IdentityConverter());}
public static IndianBuffet<String> mahout_f6810_0(double alpha)
{    return new IndianBuffet<>(alpha, new WordConverter());}
public List<T> mahout_f6811_0()
{    List<T> r = Lists.newArrayList();    if (documents == 0) {        double n = new PoissonSampler(alpha).sample();        for (int i = 0; i < n; i++) {            r.add(converter.convert(i));            count.add(1);        }        documents++;    } else {        documents++;        int i = 0;        for (double cnt : count) {            if (gen.nextDouble() < cnt / documents) {                r.add(converter.convert(i));                count.set(i, count.get(i) + 1);            }            i++;        }        int newItems = new PoissonSampler(alpha / documents).sample().intValue();        for (int j = 0; j < newItems; j++) {            r.add(converter.convert(i + j));            count.add(1);        }    }    return r;}
public Integer mahout_f6812_0(int i)
{    return i;}
public String mahout_f6813_0(int i)
{    return String.valueOf(i);}
public boolean mahout_f6814_0(String line)
{    Iterables.addAll(theWords, onSpace.split(line));    return true;}
public List<String> mahout_f6815_0()
{    return theWords;}
public String mahout_f6816_0(int i)
{    if (i < words.size()) {        return words.get(i);    } else {        return "w_" + i;    }}
public T mahout_f6817_0()
{    if (gen.nextDouble() >= p) {        return delegate.sample();    } else {        return missingMarker;    }}
public void mahout_f6818_0(T value, double w)
{    Preconditions.checkNotNull(value);    Preconditions.checkArgument(!items.containsKey(value));    int n = this.weight.size();    if (n == 1) {        weight.add(w);        values.add(value);        items.put(value, 1);    } else {                weight.add(weight.get(n / 2));        values.add(values.get(n / 2));        items.put(values.get(n / 2), n);        n++;                items.put(value, n);        this.weight.add(w);        values.add(value);                while (n > 1) {            n /= 2;            this.weight.set(n, this.weight.get(n) + w);        }    }}
public double mahout_f6819_0(T value)
{    if (items.containsKey(value)) {        return weight.get(items.get(value));    } else {        return 0;    }}
public double mahout_f6820_0(T value)
{    if (items.containsKey(value)) {        return weight.get(items.get(value)) / weight.get(1);    } else {        return 0;    }}
public double mahout_f6821_0()
{    if (weight.size() > 1) {        return weight.get(1);    } else {        return 0;    }}
public void mahout_f6822_0(T value)
{    set(value, 0);}
public void mahout_f6823_0(T value, double newP)
{    Preconditions.checkArgument(items.containsKey(value));    int n = items.get(value);    if (newP <= 0) {                        items.remove(value);    }    double oldP = weight.get(n);    while (n > 0) {        weight.set(n, weight.get(n) - oldP + newP);        n /= 2;    }}
public T mahout_f6824_0()
{    Preconditions.checkArgument(!weight.isEmpty());    return sample(rand.nextDouble());}
public T mahout_f6825_0(double u)
{    u *= weight.get(1);    int n = 1;    while (2 * n < weight.size()) {                double left = weight.get(2 * n);        if (u <= left) {            n = 2 * n;        } else {            u -= left;            n = 2 * n + 1;        }    }    return values.get(n);}
 List<Double> mahout_f6826_0()
{    List<Double> r = Lists.newArrayList();    int i = Integer.highestOneBit(weight.size());    while (i < weight.size()) {        r.add(weight.get(i));        i++;    }    i /= 2;    while (i < Integer.highestOneBit(weight.size())) {        r.add(weight.get(i));        i++;    }    return r;}
public Iterator<T> mahout_f6827_0()
{    return new AbstractIterator<T>() {        Iterator<T> valuesIterator = Iterables.skip(values, 1).iterator();        @Override        protected T computeNext() {            while (valuesIterator.hasNext()) {                T next = valuesIterator.next();                if (items.containsKey(next)) {                    return next;                }            }            return endOfData();        }    };}
protected T mahout_f6828_0()
{    while (valuesIterator.hasNext()) {        T next = valuesIterator.next();        if (items.containsKey(next)) {            return next;        }    }    return endOfData();}
public Vector mahout_f6829_0()
{    Vector v = new DenseVector(dimension).assign(new DoubleFunction() {        @Override        public double apply(double ignored) {            return gen.nextGaussian();        }    });    if (mean != null) {        if (scale != null) {            return scale.times(v).plus(mean);        } else {            return v.plus(mean);        }    } else {        if (scale != null) {            return scale.times(v);        } else {            return v;        }    }}
public double mahout_f6830_0(double ignored)
{    return gen.nextGaussian();}
public Vector mahout_f6831_0()
{    return mean;}
public Double mahout_f6832_0()
{    return rand.nextGaussian() * sd + mean;}
public Double mahout_f6833_0()
{    return sample(gen.nextDouble());}
 double mahout_f6834_0(double u)
{    if (u < limit) {        List<WeightedThing<Integer>> steps = Lists.newArrayList();        limit = 1;        int i = 0;        while (u / 20 < limit) {            double pdf = pd.probability(i);            limit -= pdf;            steps.add(new WeightedThing<>(i, pdf));            i++;        }        steps.add(new WeightedThing<>(steps.size(), limit));        partial = new Multinomial<>(steps);    }    return partial.sample(u);}
public T mahout_f6835_0()
{    return value;}
public double mahout_f6836_0()
{    return weight;}
public void mahout_f6837_0(double weight)
{    this.weight = weight;}
public int mahout_f6838_0(WeightedThing<T> other)
{    return Double.compare(this.weight, other.weight);}
public boolean mahout_f6839_0(Object o)
{    if (o instanceof WeightedThing) {        @SuppressWarnings("unchecked")        WeightedThing<T> other = (WeightedThing<T>) o;        return weight == other.weight && value.equals(other.value);    }    return false;}
public int mahout_f6840_0()
{    return 31 * RandomUtils.hashDouble(weight) + value.hashCode();}
protected Matrix mahout_f6841_0(int rows, int columns)
{    return new SparseMatrix(rows, columns);}
public RandomAccessSparseVector mahout_f6842_0()
{    return new RandomAccessSparseVector(size(), values.clone());}
public String mahout_f6843_0()
{    return sparseVectorToString();}
public Vector mahout_f6844_0(Vector other)
{    if (size() != other.size()) {        throw new CardinalityException(size(), other.size());    }    values.clear();    for (Element e : other.nonZeroes()) {        setQuick(e.index(), e.get());    }    return this;}
public void mahout_f6845_0(OrderedIntDoubleMapping updates)
{    for (int i = 0; i < updates.getNumMappings(); ++i) {        values.put(updates.getIndices()[i], updates.getValues()[i]);    }}
public boolean mahout_f6846_0()
{    return false;}
public boolean mahout_f6847_0()
{    return false;}
public double mahout_f6848_0(int index)
{    return values.get(index);}
public void mahout_f6849_0(int index, double value)
{    invalidateCachedLength();    if (value == 0.0) {        values.remove(index);    } else {        values.put(index, value);    }}
public void mahout_f6850_0(int index, double increment)
{    invalidateCachedLength();    values.addTo(index, increment);}
public RandomAccessSparseVector mahout_f6851_0()
{    return new RandomAccessSparseVector(size(), values.size());}
public Vector mahout_f6852_0(int cardinality)
{    return new RandomAccessSparseVector(cardinality, values.size());}
public int mahout_f6853_0()
{    return values.size();}
public int mahout_f6854_0()
{    final DoubleIterator iterator = values.values().iterator();    int numNonZeros = 0;    for (int i = values.size(); i-- != 0; ) if (iterator.nextDouble() != 0)        numNonZeros++;    return numNonZeros;}
public double mahout_f6855_0()
{    return 1;}
public double mahout_f6856_0()
{    return 1 + (AbstractSet.DEFAULT_MAX_LOAD_FACTOR + AbstractSet.DEFAULT_MIN_LOAD_FACTOR) / 2;}
public boolean mahout_f6857_0()
{    return true;}
public boolean mahout_f6858_0()
{    return fastIterator.hasNext();}
public Element mahout_f6859_0()
{    if (!hasNext())        throw new NoSuchElementException();    element.entry = fastIterator.next();    return element;}
public void mahout_f6860_0()
{    throw new UnsupportedOperationException();}
public double mahout_f6861_0()
{    return entry.getDoubleValue();}
public int mahout_f6862_0()
{    return entry.getIntKey();}
public void mahout_f6863_0(double value)
{    invalidateCachedLength();    if (value == 0.0)        fastIterator.remove();    else        entry.setValue(value);}
public Iterator<Element> mahout_f6864_0()
{    return new NonZeroIterator();}
public Iterator<Element> mahout_f6865_0()
{    return new AllIterator();}
public double mahout_f6866_0()
{    return value;}
public int mahout_f6867_0()
{    return index;}
public void mahout_f6868_0(double value)
{    invalidateCachedLength();    if (value == 0.0)        values.remove(index);    else        values.put(index, value);}
public boolean mahout_f6869_0()
{    return element.index + 1 < size();}
public Element mahout_f6870_0()
{    if (!hasNext()) {        throw new NoSuchElementException();    }    element.value = values.get(++element.index);    return element;}
public void mahout_f6871_0()
{    throw new UnsupportedOperationException();}
public Matrix mahout_f6872_0(int column, Vector other)
{    throw new UnsupportedOperationException("Can't assign to read-only matrix");}
public Matrix mahout_f6873_0(int row, Vector other)
{    throw new UnsupportedOperationException("Can't assign to read-only matrix");}
public double mahout_f6874_0(int row, int column)
{    if (highQuality) {        ByteBuffer buf = ByteBuffer.allocate(8);        buf.putInt(row);        buf.putInt(column);        buf.flip();        return (MurmurHash.hash64A(buf, seed) & (SCALE - 1)) / (double) SCALE;    } else {                return ((((row * PRIME1) + column * PRIME2 + row * column * PRIME3) & 8) * 0.25) - 1;    }}
public Matrix mahout_f6875_0()
{    return new DenseMatrix(rowSize(), columnSize());}
public Matrix mahout_f6876_0(int rows, int columns)
{    return new DenseMatrix(rows, columns);}
public void mahout_f6877_0(int row, int column, double value)
{    throw new UnsupportedOperationException("Can't assign to read-only matrix");}
public int[] mahout_f6878_0()
{    throw new UnsupportedOperationException("Can't assign to read-only matrix");}
public Matrix mahout_f6879_0(int[] offset, int[] size)
{    return new MatrixView(this, offset, size);}
private int mahout_f6880_0(Vector other)
{    int elementCount = other.getNumNondefaultElements();    OrderedElement[] sortableElements = new OrderedElement[elementCount];    int s = 0;    for (Element e : other.nonZeroes()) {        sortableElements[s++] = new OrderedElement(e.index(), e.get());    }    Arrays.sort(sortableElements);    for (int i = 0; i < sortableElements.length; i++) {        values.setIndexAt(i, sortableElements[i].index);        values.setValueAt(i, sortableElements[i].value);    }    values = new OrderedIntDoubleMapping(values.getIndices(), values.getValues(), elementCount);    return elementCount;}
protected Matrix mahout_f6881_0(int rows, int columns)
{        return new SparseMatrix(rows, columns);}
public SequentialAccessSparseVector mahout_f6882_0()
{    return new SequentialAccessSparseVector(size(), values.clone());}
public void mahout_f6883_0(OrderedIntDoubleMapping updates)
{    values.merge(updates);}
public String mahout_f6884_0()
{    return sparseVectorToString();}
public boolean mahout_f6885_0()
{    return false;}
public boolean mahout_f6886_0()
{    return true;}
public double mahout_f6887_0(int index)
{    return values.get(index);}
public void mahout_f6888_0(int index, double value)
{    invalidateCachedLength();    values.set(index, value);}
public void mahout_f6889_0(int index, double increment)
{    invalidateCachedLength();    values.increment(index, increment);}
public SequentialAccessSparseVector mahout_f6890_0()
{    return new SequentialAccessSparseVector(size(), values.getNumMappings());}
public Vector mahout_f6891_0(int cardinality)
{    return new SequentialAccessSparseVector(cardinality);}
public int mahout_f6892_0()
{    return values.getNumMappings();}
public int mahout_f6893_0()
{    double[] elementValues = values.getValues();    int numMappedElements = values.getNumMappings();    int numNonZeros = 0;    for (int index = 0; index < numMappedElements; index++) {        if (elementValues[index] != 0) {            numNonZeros++;        }    }    return numNonZeros;}
public double mahout_f6894_0()
{    return Math.max(1, Math.round(Functions.LOG2.apply(getNumNondefaultElements())));}
public double mahout_f6895_0()
{    return 1;}
public boolean mahout_f6896_0()
{    return false;}
public Iterator<Element> mahout_f6897_0()
{        return new NonDefaultIterator();}
public Iterator<Element> mahout_f6898_0()
{    return new AllIterator();}
public boolean mahout_f6899_0()
{    return element.getNextOffset() < values.getNumMappings();}
public Element mahout_f6900_0()
{    if (!hasNext()) {        throw new NoSuchElementException();    }    element.advanceOffset();    return element;}
public void mahout_f6901_0()
{    throw new UnsupportedOperationException();}
public boolean mahout_f6902_0()
{    return element.getNextIndex() < SequentialAccessSparseVector.this.size();}
public Element mahout_f6903_0()
{    if (!hasNext()) {        throw new NoSuchElementException();    }    element.advanceIndex();    return element;}
public void mahout_f6904_0()
{    throw new UnsupportedOperationException();}
 void mahout_f6905_0()
{    offset++;}
 int mahout_f6906_0()
{    return offset + 1;}
public double mahout_f6907_0()
{    return values.getValues()[offset];}
public int mahout_f6908_0()
{    return values.getIndices()[offset];}
public void mahout_f6909_0(double value)
{    invalidateCachedLength();    values.setValueAt(offset, value);}
 void mahout_f6910_0()
{    index++;    if (nextOffset < values.getNumMappings() && index > values.getIndices()[nextOffset]) {        nextOffset++;    }}
 int mahout_f6911_0()
{    return index + 1;}
public double mahout_f6912_0()
{    if (nextOffset < values.getNumMappings() && index == values.getIndices()[nextOffset]) {        return values.getValues()[nextOffset];    } else {        return OrderedIntDoubleMapping.DEFAULT_VALUE;    }}
public int mahout_f6913_0()
{    return index;}
public void mahout_f6914_0(double value)
{    invalidateCachedLength();    if (nextOffset < values.getNumMappings() && index == values.indexAt(nextOffset)) {        values.setValueAt(nextOffset, value);    } else {                values.set(index, value);    }}
public int mahout_f6915_0(OrderedElement that)
{        return this.index - that.index;}
public int mahout_f6916_0()
{    return index ^ Doubles.hashCode(value);}
public boolean mahout_f6917_0(Object o)
{    if (!(o instanceof OrderedElement)) {        return false;    }    OrderedElement other = (OrderedElement) o;    return index == other.index && value == other.value;}
protected int mahout_f6918_0(int size, double minLoad, double maxLoad)
{    return nextPrime(Math.max(size + 1, (int) ((4 * size / (3 * minLoad + maxLoad)))));}
protected int mahout_f6919_0(int capacity, double maxLoad)
{        return Math.min(capacity - 2, (int) (capacity * maxLoad));}
protected int mahout_f6920_0(int capacity, double minLoad)
{    return (int) (capacity * minLoad);}
protected int mahout_f6921_0(int size, double minLoad, double maxLoad)
{    return nextPrime(Math.max(size + 1, (int) ((2 * size / (minLoad + maxLoad)))));}
protected int mahout_f6922_0(int size, double minLoad, double maxLoad)
{    return nextPrime(Math.max(size + 1, (int) ((4 * size / (minLoad + 3 * maxLoad)))));}
public void mahout_f6923_0(int minCapacity)
{}
public boolean mahout_f6924_0()
{    return distinct == 0;}
protected int mahout_f6925_0(int desiredCapacity)
{    return PrimeFinder.nextPrime(desiredCapacity);}
protected void mahout_f6926_0(int initialCapacity, double minLoadFactor, double maxLoadFactor)
{    if (initialCapacity < 0) {        throw new IllegalArgumentException("Initial Capacity must not be less than zero: " + initialCapacity);    }    if (minLoadFactor < 0.0 || minLoadFactor >= 1.0) {        throw new IllegalArgumentException("Illegal minLoadFactor: " + minLoadFactor);    }    if (maxLoadFactor <= 0.0 || maxLoadFactor >= 1.0) {        throw new IllegalArgumentException("Illegal maxLoadFactor: " + maxLoadFactor);    }    if (minLoadFactor >= maxLoadFactor) {        throw new IllegalArgumentException("Illegal minLoadFactor: " + minLoadFactor + " and maxLoadFactor: " + maxLoadFactor);    }}
public int mahout_f6927_0()
{    return distinct;}
public void mahout_f6928_0()
{}
protected static boolean mahout_f6929_0(Object a, Object b)
{    if (a == null && b == null) {        return true;    }    if (a == null || b == null) {        return false;    }    return a.equals(b);}
public static int mahout_f6930_0(byte x)
{    return x;}
public static int mahout_f6931_0(short x)
{    return x;}
public static int mahout_f6932_0(char x)
{    return x;}
public static int mahout_f6933_0(int x)
{    return x;}
public static int mahout_f6934_0(float x)
{    return Float.floatToIntBits(x) >>> 3 + Float.floatToIntBits((float) (Math.PI * x));}
public static int mahout_f6935_0(double x)
{    return hash(17 * Double.doubleToLongBits(x));}
public static int mahout_f6936_0(long x)
{    return (int) ((x * 11) >>> 32 ^ x);}
public void mahout_f6937_0()
{    Arrays.fill(this.state, 0, state.length - 1, FREE);    distinct = 0;        freeEntries = table.length;    trimToSize();}
public Object mahout_f6938_0()
{    OpenHashSet<T> copy = (OpenHashSet<T>) super.clone();    copy.table = copy.table.clone();    copy.state = copy.state.clone();    return copy;}
public boolean mahout_f6939_0(Object key)
{    return indexOfKey((T) key) >= 0;}
public void mahout_f6940_0(int minCapacity)
{    if (table.length < minCapacity) {        int newCapacity = nextPrime(minCapacity);        rehash(newCapacity);    }}
public boolean mahout_f6941_0(ObjectProcedure<T> procedure)
{    for (int i = table.length; i-- > 0; ) {        if (state[i] == FULL) {            if (!procedure.apply((T) table[i])) {                return false;            }        }    }    return true;}
protected int mahout_f6942_0(T key)
{    Object[] tab = table;    byte[] stat = state;    int length = tab.length;    int hash = key.hashCode() & 0x7FFFFFFF;    int i = hash % length;        int decrement = hash % (length - 2);        if (decrement == 0) {        decrement = 1;    }        while (stat[i] == FULL && tab[i] != key) {        i -= decrement;                if (i < 0) {            i += length;        }    }    if (stat[i] == REMOVED) {                                int j = i;        while (stat[i] != FREE && (stat[i] == REMOVED || tab[i] != key)) {            i -= decrement;                        if (i < 0) {                i += length;            }        }        if (stat[i] == FREE) {            i = j;        }    }    if (stat[i] == FULL) {                return -i - 1;    }        return i;}
protected int mahout_f6943_0(T key)
{    Object[] tab = table;    byte[] stat = state;    int length = tab.length;    int hash = key.hashCode() & 0x7FFFFFFF;    int i = hash % length;        int decrement = hash % (length - 2);        if (decrement == 0) {        decrement = 1;    }        while (stat[i] != FREE && (stat[i] == REMOVED || (!key.equals(tab[i])))) {        i -= decrement;                if (i < 0) {            i += length;        }    }    if (stat[i] == FREE) {        return -1;    }        return i;}
public void mahout_f6944_0(List<T> list)
{    list.clear();    Object[] tab = table;    byte[] stat = state;    for (int i = tab.length; i-- > 0; ) {        if (stat[i] == FULL) {            list.add((T) tab[i]);        }    }}
public boolean mahout_f6945_0(Object key)
{    int i = indexOfInsertion((T) key);    if (i < 0) {                return false;    }    if (this.distinct > this.highWaterMark) {        int newCapacity = chooseGrowCapacity(this.distinct + 1, this.minLoadFactor, this.maxLoadFactor);        rehash(newCapacity);        return add(key);    }    this.table[i] = key;    if (this.state[i] == FREE) {        this.freeEntries--;    }    this.state[i] = FULL;    this.distinct++;    if (this.freeEntries < 1) {                int newCapacity = chooseGrowCapacity(this.distinct + 1, this.minLoadFactor, this.maxLoadFactor);        rehash(newCapacity);        return add(key);    }    return true;}
protected void mahout_f6946_0(int newCapacity)
{    int oldCapacity = table.length;        Object[] oldTable = table;    byte[] oldState = state;    Object[] newTable = new Object[newCapacity];    byte[] newState = new byte[newCapacity];    this.lowWaterMark = chooseLowWaterMark(newCapacity, this.minLoadFactor);    this.highWaterMark = chooseHighWaterMark(newCapacity, this.maxLoadFactor);    this.table = newTable;    this.state = newState;        this.freeEntries = newCapacity - this.distinct;    for (int i = oldCapacity; i-- > 0; ) {        if (oldState[i] == FULL) {            Object element = oldTable[i];            int index = indexOfInsertion((T) element);            newTable[index] = element;            newState[index] = FULL;        }    }}
public boolean mahout_f6947_0(Object key)
{    int i = indexOfKey((T) key);    if (i < 0) {        return false;    }        this.state[i] = REMOVED;    this.distinct--;    if (this.distinct < this.lowWaterMark) {        int newCapacity = chooseShrinkCapacity(this.distinct, this.minLoadFactor, this.maxLoadFactor);        rehash(newCapacity);    }    return true;}
protected final void mahout_f6948_0(int initialCapacity, double minLoadFactor, double maxLoadFactor)
{    int capacity = initialCapacity;    super.setUp(capacity, minLoadFactor, maxLoadFactor);    capacity = nextPrime(capacity);    if (capacity == 0) {        capacity = 1;    }        this.table = new Object[capacity];    this.state = new byte[capacity];        this.minLoadFactor = minLoadFactor;    if (capacity == PrimeFinder.LARGEST_PRIME) {        this.maxLoadFactor = 1.0;    } else {        this.maxLoadFactor = maxLoadFactor;    }    this.distinct = 0;        this.freeEntries = capacity;                    this.lowWaterMark = 0;    this.highWaterMark = chooseHighWaterMark(capacity, this.maxLoadFactor);}
public void mahout_f6949_0()
{            int newCapacity = nextPrime((int) (1 + 1.2 * size()));    if (table.length > newCapacity) {        rehash(newCapacity);    }}
 void mahout_f6950_0(int[] capacity, double[] minLoadFactor, double[] maxLoadFactor)
{    capacity[0] = table.length;    minLoadFactor[0] = this.minLoadFactor;    maxLoadFactor[0] = this.maxLoadFactor;}
public boolean mahout_f6951_0()
{    return size() == 0;}
public boolean mahout_f6952_0(Object obj)
{    if (obj == this) {        return true;    }    if (!(obj instanceof OpenHashSet)) {        return false;    }    final OpenHashSet<T> other = (OpenHashSet<T>) obj;    if (other.size() != size()) {        return false;    }    return forEachKey(new ObjectProcedure<T>() {        @Override        public boolean apply(T key) {            return other.contains(key);        }    });}
public boolean mahout_f6953_0(T key)
{    return other.contains(key);}
public int mahout_f6954_0()
{    ByteBuffer buf = ByteBuffer.allocate(size());    for (int i = 0; i < table.length; i++) {        Object v = table[i];        if (state[i] == FULL) {            buf.putInt(v.hashCode());        }    }    return MurmurHash.hash(buf, this.getClass().getName().hashCode());}
public Iterator<T> mahout_f6955_0()
{    List<T> keyList = new ArrayList<>();    keys(keyList);    return keyList.iterator();}
public Object[] mahout_f6956_0()
{    List<T> keyList = new ArrayList<>();    keys(keyList);    return keyList.toArray();}
public boolean mahout_f6957_0(Collection<? extends T> c)
{    boolean anyAdded = false;    for (T o : c) {        boolean added = add(o);        anyAdded |= added;    }    return anyAdded;}
public boolean mahout_f6958_0(Collection<?> c)
{    for (Object o : c) {        if (!contains(o)) {            return false;        }    }    return true;}
public boolean mahout_f6959_0(Collection<?> c)
{    boolean anyRemoved = false;    for (Object o : c) {        boolean removed = remove(o);        anyRemoved |= removed;    }    return anyRemoved;}
public boolean mahout_f6960_0(Collection<?> c)
{    final Collection<?> finalCollection = c;    final boolean[] modified = new boolean[1];    modified[0] = false;    forEachKey(new ObjectProcedure<T>() {        @Override        public boolean apply(T element) {            if (!finalCollection.contains(element)) {                remove(element);                modified[0] = true;            }            return true;        }    });    return modified[0];}
public boolean mahout_f6961_0(T element)
{    if (!finalCollection.contains(element)) {        remove(element);        modified[0] = true;    }    return true;}
public T1[] mahout_f6962_0(T1[] a)
{    return keys().toArray(a);}
public List<T> mahout_f6963_0()
{    List<T> keys = new ArrayList<>();    keys(keys);    return keys;}
public double mahout_f6964_0()
{    return s[0] / s[Math.min(m, n) - 1];}
public Matrix mahout_f6965_0()
{    double[][] s = new double[n][n];    for (int i = 0; i < n; i++) {        for (int j = 0; j < n; j++) {            s[i][j] = 0.0;        }        s[i][i] = this.s[i];    }    return new DenseMatrix(s);}
public double[] mahout_f6966_0()
{    return s;}
public Matrix mahout_f6967_0()
{    if (transpositionNeeded) {                return new DenseMatrix(v);    } else {        int numCols = Math.min(m + 1, n);        Matrix r = new DenseMatrix(m, numCols);        for (int i = 0; i < m; i++) {            for (int j = 0; j < numCols; j++) {                r.set(i, j, u[i][j]);            }        }        return r;    }}
public Matrix mahout_f6968_0()
{    if (transpositionNeeded) {                int numCols = Math.min(m + 1, n);        Matrix r = new DenseMatrix(m, numCols);        for (int i = 0; i < m; i++) {            for (int j = 0; j < numCols; j++) {                r.set(i, j, u[i][j]);            }        }        return r;    } else {        return new DenseMatrix(v);    }}
public double mahout_f6969_0()
{    return s[0];}
public int mahout_f6970_0()
{    double eps = Math.pow(2.0, -52.0);    double tol = Math.max(m, n) * s[0] * eps;    int r = 0;    for (double value : s) {        if (value > tol) {            r++;        }    }    return r;}
 Matrix mahout_f6971_0(double minSingularValue)
{    Matrix j = new DenseMatrix(s.length, s.length);    Matrix vMat = new DenseMatrix(this.v);    for (int i = 0; i < s.length; i++) {        j.set(i, i, s[i] >= minSingularValue ? 1 / (s[i] * s[i]) : 0.0);    }    return vMat.times(j).times(vMat.transpose());}
public String mahout_f6972_0()
{    StringBuilder buf = new StringBuilder();    buf.append("---------------------------------------------------------------------\n");    buf.append("SingularValueDecomposition(A) --> cond(A), rank(A), norm2(A), U, S, V\n");    buf.append("---------------------------------------------------------------------\n");    buf.append("cond = ");    String unknown = "Illegal operation or error: ";    try {        buf.append(String.valueOf(this.cond()));    } catch (IllegalArgumentException exc) {        buf.append(unknown).append(exc.getMessage());    }    buf.append("\nrank = ");    try {        buf.append(String.valueOf(this.rank()));    } catch (IllegalArgumentException exc) {        buf.append(unknown).append(exc.getMessage());    }    buf.append("\nnorm2 = ");    try {        buf.append(String.valueOf(this.norm2()));    } catch (IllegalArgumentException exc) {        buf.append(unknown).append(exc.getMessage());    }    buf.append("\n\nU = ");    try {        buf.append(String.valueOf(this.getU()));    } catch (IllegalArgumentException exc) {        buf.append(unknown).append(exc.getMessage());    }    buf.append("\n\nS = ");    try {        buf.append(String.valueOf(this.getS()));    } catch (IllegalArgumentException exc) {        buf.append(unknown).append(exc.getMessage());    }    buf.append("\n\nV = ");    try {        buf.append(String.valueOf(this.getV()));    } catch (IllegalArgumentException exc) {        buf.append(unknown).append(exc.getMessage());    }    return buf.toString();}
public Vector mahout_f6973_0(VectorIterable a, Vector b)
{    return solve(a, b, null, b.size() + 2, DEFAULT_MAX_ERROR);}
public Vector mahout_f6974_0(VectorIterable a, Vector b, Preconditioner precond)
{    return solve(a, b, precond, b.size() + 2, DEFAULT_MAX_ERROR);}
public Vector mahout_f6975_1(VectorIterable a, Vector b, Preconditioner preconditioner, int maxIterations, double maxError)
{    if (a.numRows() != a.numCols()) {        throw new IllegalArgumentException("Matrix must be square, symmetric and positive definite.");    }    if (a.numCols() != b.size()) {        throw new CardinalityException(a.numCols(), b.size());    }    if (maxIterations <= 0) {        throw new IllegalArgumentException("Max iterations must be positive.");    }    if (maxError < 0.0) {        throw new IllegalArgumentException("Max error must be non-negative.");    }    Vector x = new DenseVector(b.size());    iterations = 0;    Vector residual = b.minus(a.times(x));    residualNormSquared = residual.dot(residual);        double previousConditionedNormSqr = 0.0;    Vector updateDirection = null;    while (Math.sqrt(residualNormSquared) > maxError && iterations < maxIterations) {        Vector conditionedResidual;        double conditionedNormSqr;        if (preconditioner == null) {            conditionedResidual = residual;            conditionedNormSqr = residualNormSquared;        } else {            conditionedResidual = preconditioner.precondition(residual);            conditionedNormSqr = residual.dot(conditionedResidual);        }        ++iterations;        if (iterations == 1) {            updateDirection = new DenseVector(conditionedResidual);        } else {            double beta = conditionedNormSqr / previousConditionedNormSqr;                        updateDirection.assign(Functions.MULT, beta);            updateDirection.assign(conditionedResidual, Functions.PLUS);        }        Vector aTimesUpdate = a.times(updateDirection);        double alpha = conditionedNormSqr / updateDirection.dot(aTimesUpdate);                PLUS_MULT.setMultiplicator(alpha);        x.assign(updateDirection, PLUS_MULT);                PLUS_MULT.setMultiplicator(-alpha);        residual.assign(aTimesUpdate, PLUS_MULT);        previousConditionedNormSqr = conditionedNormSqr;        residualNormSquared = residual.dot(residual);            }    return x;}
public int mahout_f6976_0()
{    return iterations;}
public double mahout_f6977_0()
{    return Math.sqrt(residualNormSquared);}
public Matrix mahout_f6978_0()
{    return v.like().assign(v);}
public Vector mahout_f6979_0()
{    return d;}
public Vector mahout_f6980_0()
{    return e;}
public Matrix mahout_f6981_0()
{    Matrix x = new DenseMatrix(n, n);    x.assign(0);    x.viewDiagonal().assign(d);    for (int i = 0; i < n; i++) {        double v = e.getQuick(i);        if (v > 0) {            x.setQuick(i, i + 1, v);        } else if (v < 0) {            x.setQuick(i, i - 1, v);        }    }    return x;}
private void mahout_f6982_0()
{                    d.assign(v.viewColumn(n - 1));    for (int i = n - 1; i > 0; i--) {                double scale = d.viewPart(0, i).norm(1);        double h = 0.0;        if (scale == 0.0) {            e.setQuick(i, d.getQuick(i - 1));            for (int j = 0; j < i; j++) {                d.setQuick(j, v.getQuick(i - 1, j));                v.setQuick(i, j, 0.0);                v.setQuick(j, i, 0.0);            }        } else {            for (int k = 0; k < i; k++) {                d.setQuick(k, d.getQuick(k) / scale);                h += d.getQuick(k) * d.getQuick(k);            }            double f = d.getQuick(i - 1);            double g = Math.sqrt(h);            if (f > 0) {                g = -g;            }            e.setQuick(i, scale * g);            h -= f * g;            d.setQuick(i - 1, f - g);            for (int j = 0; j < i; j++) {                e.setQuick(j, 0.0);            }            for (int j = 0; j < i; j++) {                f = d.getQuick(j);                v.setQuick(j, i, f);                g = e.getQuick(j) + v.getQuick(j, j) * f;                for (int k = j + 1; k <= i - 1; k++) {                    g += v.getQuick(k, j) * d.getQuick(k);                    e.setQuick(k, e.getQuick(k) + v.getQuick(k, j) * f);                }                e.setQuick(j, g);            }            f = 0.0;            for (int j = 0; j < i; j++) {                e.setQuick(j, e.getQuick(j) / h);                f += e.getQuick(j) * d.getQuick(j);            }            double hh = f / (h + h);            for (int j = 0; j < i; j++) {                e.setQuick(j, e.getQuick(j) - hh * d.getQuick(j));            }            for (int j = 0; j < i; j++) {                f = d.getQuick(j);                g = e.getQuick(j);                for (int k = j; k <= i - 1; k++) {                    v.setQuick(k, j, v.getQuick(k, j) - (f * e.getQuick(k) + g * d.getQuick(k)));                }                d.setQuick(j, v.getQuick(i - 1, j));                v.setQuick(i, j, 0.0);            }        }        d.setQuick(i, h);    }    for (int i = 0; i < n - 1; i++) {        v.setQuick(n - 1, i, v.getQuick(i, i));        v.setQuick(i, i, 1.0);        double h = d.getQuick(i + 1);        if (h != 0.0) {            for (int k = 0; k <= i; k++) {                d.setQuick(k, v.getQuick(k, i + 1) / h);            }            for (int j = 0; j <= i; j++) {                double g = 0.0;                for (int k = 0; k <= i; k++) {                    g += v.getQuick(k, i + 1) * v.getQuick(k, j);                }                for (int k = 0; k <= i; k++) {                    v.setQuick(k, j, v.getQuick(k, j) - g * d.getQuick(k));                }            }        }        for (int k = 0; k <= i; k++) {            v.setQuick(k, i + 1, 0.0);        }    }    d.assign(v.viewRow(n - 1));    v.viewRow(n - 1).assign(0);    v.setQuick(n - 1, n - 1, 1.0);    e.setQuick(0, 0.0);}
private void mahout_f6983_0()
{                    e.viewPart(0, n - 1).assign(e.viewPart(1, n - 1));    e.setQuick(n - 1, 0.0);    double f = 0.0;    double tst1 = 0.0;    double eps = Math.pow(2.0, -52.0);    for (int l = 0; l < n; l++) {                tst1 = Math.max(tst1, Math.abs(d.getQuick(l)) + Math.abs(e.getQuick(l)));        int m = l;        while (m < n) {            if (Math.abs(e.getQuick(m)) <= eps * tst1) {                break;            }            m++;        }        if (m > l) {            do {                                double g = d.getQuick(l);                double p = (d.getQuick(l + 1) - g) / (2.0 * e.getQuick(l));                double r = Math.hypot(p, 1.0);                if (p < 0) {                    r = -r;                }                d.setQuick(l, e.getQuick(l) / (p + r));                d.setQuick(l + 1, e.getQuick(l) * (p + r));                double dl1 = d.getQuick(l + 1);                double h = g - d.getQuick(l);                for (int i = l + 2; i < n; i++) {                    d.setQuick(i, d.getQuick(i) - h);                }                f += h;                                p = d.getQuick(m);                double c = 1.0;                double c2 = c;                double c3 = c;                double el1 = e.getQuick(l + 1);                double s = 0.0;                double s2 = 0.0;                for (int i = m - 1; i >= l; i--) {                    c3 = c2;                    c2 = c;                    s2 = s;                    g = c * e.getQuick(i);                    h = c * p;                    r = Math.hypot(p, e.getQuick(i));                    e.setQuick(i + 1, s * r);                    s = e.getQuick(i) / r;                    c = p / r;                    p = c * d.getQuick(i) - s * g;                    d.setQuick(i + 1, h + s * (c * g + s * d.getQuick(i)));                    for (int k = 0; k < n; k++) {                        h = v.getQuick(k, i + 1);                        v.setQuick(k, i + 1, s * v.getQuick(k, i) + c * h);                        v.setQuick(k, i, c * v.getQuick(k, i) - s * h);                    }                }                p = -s * s2 * c3 * el1 * e.getQuick(l) / dl1;                e.setQuick(l, s * p);                d.setQuick(l, c * p);                        } while (Math.abs(e.getQuick(l)) > eps * tst1);        }        d.setQuick(l, d.getQuick(l) + f);        e.setQuick(l, 0.0);    }    for (int i = 0; i < n - 1; i++) {        int k = i;        double p = d.getQuick(i);        for (int j = i + 1; j < n; j++) {            if (d.getQuick(j) > p) {                k = j;                p = d.getQuick(j);            }        }        if (k != i) {            d.setQuick(k, d.getQuick(i));            d.setQuick(i, p);            for (int j = 0; j < n; j++) {                p = v.getQuick(j, i);                v.setQuick(j, i, v.getQuick(j, k));                v.setQuick(j, k, p);            }        }    }}
private Matrix mahout_f6984_0(Matrix x)
{        Vector ort = new DenseVector(n);    Matrix hessenBerg = new DenseMatrix(n, n).assign(x);                    int low = 0;    int high = n - 1;    for (int m = low + 1; m <= high - 1; m++) {                Vector hColumn = hessenBerg.viewColumn(m - 1).viewPart(m, high - m + 1);        double scale = hColumn.norm(1);        if (scale != 0.0) {                        ort.viewPart(m, high - m + 1).assign(hColumn, Functions.plusMult(1 / scale));            double h = ort.viewPart(m, high - m + 1).getLengthSquared();            double g = Math.sqrt(h);            if (ort.getQuick(m) > 0) {                g = -g;            }            h -= ort.getQuick(m) * g;            ort.setQuick(m, ort.getQuick(m) - g);                                    Vector ortPiece = ort.viewPart(m, high - m + 1);            for (int j = m; j < n; j++) {                double f = ortPiece.dot(hessenBerg.viewColumn(j).viewPart(m, high - m + 1)) / h;                hessenBerg.viewColumn(j).viewPart(m, high - m + 1).assign(ortPiece, Functions.plusMult(-f));            }            for (int i = 0; i <= high; i++) {                double f = ortPiece.dot(hessenBerg.viewRow(i).viewPart(m, high - m + 1)) / h;                hessenBerg.viewRow(i).viewPart(m, high - m + 1).assign(ortPiece, Functions.plusMult(-f));            }            ort.setQuick(m, scale * ort.getQuick(m));            hessenBerg.setQuick(m, m - 1, scale * g);        }    }        v.assign(0);    v.viewDiagonal().assign(1);    for (int m = high - 1; m >= low + 1; m--) {        if (hessenBerg.getQuick(m, m - 1) != 0.0) {            ort.viewPart(m + 1, high - m).assign(hessenBerg.viewColumn(m - 1).viewPart(m + 1, high - m));            for (int j = m; j <= high; j++) {                double g = ort.viewPart(m, high - m + 1).dot(v.viewColumn(j).viewPart(m, high - m + 1));                                g = g / ort.getQuick(m) / hessenBerg.getQuick(m, m - 1);                v.viewColumn(j).viewPart(m, high - m + 1).assign(ort.viewPart(m, high - m + 1), Functions.plusMult(g));            }        }    }    return hessenBerg;}
private void mahout_f6985_0(double xr, double xi, double yr, double yi)
{    double r;    double d;    if (Math.abs(yr) > Math.abs(yi)) {        r = yi / yr;        d = yr + r * yi;        cdivr = (xr + r * xi) / d;        cdivi = (xi - r * xr) / d;    } else {        r = yr / yi;        d = yi + r * yr;        cdivr = (r * xr + xi) / d;        cdivi = (r * xi - xr) / d;    }}
private void mahout_f6986_0(Matrix h)
{                        int nn = this.n;    int n = nn - 1;    int low = 0;    int high = nn - 1;    double eps = Math.pow(2.0, -52.0);    double exshift = 0.0;    double p = 0;    double q = 0;    double r = 0;    double s = 0;    double z = 0;    double w;    double x;    double y;        double norm = h.aggregate(Functions.PLUS, Functions.ABS);        int iter = 0;    while (n >= low) {                int l = n;        while (l > low) {            s = Math.abs(h.getQuick(l - 1, l - 1)) + Math.abs(h.getQuick(l, l));            if (s == 0.0) {                s = norm;            }            if (Math.abs(h.getQuick(l, l - 1)) < eps * s) {                break;            }            l--;        }        if (l == n) {                        h.setQuick(n, n, h.getQuick(n, n) + exshift);            d.setQuick(n, h.getQuick(n, n));            e.setQuick(n, 0.0);            n--;            iter = 0;        } else if (l == n - 1) {                        w = h.getQuick(n, n - 1) * h.getQuick(n - 1, n);            p = (h.getQuick(n - 1, n - 1) - h.getQuick(n, n)) / 2.0;            q = p * p + w;            z = Math.sqrt(Math.abs(q));            h.setQuick(n, n, h.getQuick(n, n) + exshift);            h.setQuick(n - 1, n - 1, h.getQuick(n - 1, n - 1) + exshift);            x = h.getQuick(n, n);                        if (q >= 0) {                if (p >= 0) {                    z = p + z;                } else {                    z = p - z;                }                d.setQuick(n - 1, x + z);                d.setQuick(n, d.getQuick(n - 1));                if (z != 0.0) {                    d.setQuick(n, x - w / z);                }                e.setQuick(n - 1, 0.0);                e.setQuick(n, 0.0);                x = h.getQuick(n, n - 1);                s = Math.abs(x) + Math.abs(z);                p = x / s;                q = z / s;                r = Math.sqrt(p * p + q * q);                p /= r;                q /= r;                for (int j = n - 1; j < nn; j++) {                    z = h.getQuick(n - 1, j);                    h.setQuick(n - 1, j, q * z + p * h.getQuick(n, j));                    h.setQuick(n, j, q * h.getQuick(n, j) - p * z);                }                for (int i = 0; i <= n; i++) {                    z = h.getQuick(i, n - 1);                    h.setQuick(i, n - 1, q * z + p * h.getQuick(i, n));                    h.setQuick(i, n, q * h.getQuick(i, n) - p * z);                }                for (int i = low; i <= high; i++) {                    z = v.getQuick(i, n - 1);                    v.setQuick(i, n - 1, q * z + p * v.getQuick(i, n));                    v.setQuick(i, n, q * v.getQuick(i, n) - p * z);                }                        } else {                d.setQuick(n - 1, x + p);                d.setQuick(n, x + p);                e.setQuick(n - 1, z);                e.setQuick(n, -z);            }            n -= 2;            iter = 0;                } else {                        x = h.getQuick(n, n);            y = 0.0;            w = 0.0;            if (l < n) {                y = h.getQuick(n - 1, n - 1);                w = h.getQuick(n, n - 1) * h.getQuick(n - 1, n);            }            if (iter == 10) {                exshift += x;                for (int i = low; i <= n; i++) {                    h.setQuick(i, i, x);                }                s = Math.abs(h.getQuick(n, n - 1)) + Math.abs(h.getQuick(n - 1, n - 2));                x = y = 0.75 * s;                w = -0.4375 * s * s;            }            if (iter == 30) {                s = (y - x) / 2.0;                s = s * s + w;                if (s > 0) {                    s = Math.sqrt(s);                    if (y < x) {                        s = -s;                    }                    s = x - w / ((y - x) / 2.0 + s);                    for (int i = low; i <= n; i++) {                        h.setQuick(i, i, h.getQuick(i, i) - s);                    }                    exshift += s;                    x = y = w = 0.964;                }            }                        iter++;                        int m = n - 2;            while (m >= l) {                z = h.getQuick(m, m);                r = x - z;                s = y - z;                p = (r * s - w) / h.getQuick(m + 1, m) + h.getQuick(m, m + 1);                q = h.getQuick(m + 1, m + 1) - z - r - s;                r = h.getQuick(m + 2, m + 1);                s = Math.abs(p) + Math.abs(q) + Math.abs(r);                p /= s;                q /= s;                r /= s;                if (m == l) {                    break;                }                double hmag = Math.abs(h.getQuick(m - 1, m - 1)) + Math.abs(h.getQuick(m + 1, m + 1));                double threshold = eps * Math.abs(p) * (Math.abs(z) + hmag);                if (Math.abs(h.getQuick(m, m - 1)) * (Math.abs(q) + Math.abs(r)) < threshold) {                    break;                }                m--;            }            for (int i = m + 2; i <= n; i++) {                h.setQuick(i, i - 2, 0.0);                if (i > m + 2) {                    h.setQuick(i, i - 3, 0.0);                }            }            for (int k = m; k <= n - 1; k++) {                boolean notlast = k != n - 1;                if (k != m) {                    p = h.getQuick(k, k - 1);                    q = h.getQuick(k + 1, k - 1);                    r = notlast ? h.getQuick(k + 2, k - 1) : 0.0;                    x = Math.abs(p) + Math.abs(q) + Math.abs(r);                    if (x != 0.0) {                        p /= x;                        q /= x;                        r /= x;                    }                }                if (x == 0.0) {                    break;                }                s = Math.sqrt(p * p + q * q + r * r);                if (p < 0) {                    s = -s;                }                if (s != 0) {                    if (k != m) {                        h.setQuick(k, k - 1, -s * x);                    } else if (l != m) {                        h.setQuick(k, k - 1, -h.getQuick(k, k - 1));                    }                    p += s;                    x = p / s;                    y = q / s;                    z = r / s;                    q /= p;                    r /= p;                    for (int j = k; j < nn; j++) {                        p = h.getQuick(k, j) + q * h.getQuick(k + 1, j);                        if (notlast) {                            p += r * h.getQuick(k + 2, j);                            h.setQuick(k + 2, j, h.getQuick(k + 2, j) - p * z);                        }                        h.setQuick(k, j, h.getQuick(k, j) - p * x);                        h.setQuick(k + 1, j, h.getQuick(k + 1, j) - p * y);                    }                    for (int i = 0; i <= Math.min(n, k + 3); i++) {                        p = x * h.getQuick(i, k) + y * h.getQuick(i, k + 1);                        if (notlast) {                            p += z * h.getQuick(i, k + 2);                            h.setQuick(i, k + 2, h.getQuick(i, k + 2) - p * r);                        }                        h.setQuick(i, k, h.getQuick(i, k) - p);                        h.setQuick(i, k + 1, h.getQuick(i, k + 1) - p * q);                    }                    for (int i = low; i <= high; i++) {                        p = x * v.getQuick(i, k) + y * v.getQuick(i, k + 1);                        if (notlast) {                            p += z * v.getQuick(i, k + 2);                            v.setQuick(i, k + 2, v.getQuick(i, k + 2) - p * r);                        }                        v.setQuick(i, k, v.getQuick(i, k) - p);                        v.setQuick(i, k + 1, v.getQuick(i, k + 1) - p * q);                    }                }                        }                }        }    if (norm == 0.0) {        return;    }    for (n = nn - 1; n >= 0; n--) {        p = d.getQuick(n);        q = e.getQuick(n);                double t;        if (q == 0) {            int l = n;            h.setQuick(n, n, 1.0);            for (int i = n - 1; i >= 0; i--) {                w = h.getQuick(i, i) - p;                r = 0.0;                for (int j = l; j <= n; j++) {                    r += h.getQuick(i, j) * h.getQuick(j, n);                }                if (e.getQuick(i) < 0.0) {                    z = w;                    s = r;                } else {                    l = i;                    if (e.getQuick(i) == 0.0) {                        if (w == 0.0) {                            h.setQuick(i, n, -r / (eps * norm));                        } else {                            h.setQuick(i, n, -r / w);                        }                                        } else {                        x = h.getQuick(i, i + 1);                        y = h.getQuick(i + 1, i);                        q = (d.getQuick(i) - p) * (d.getQuick(i) - p) + e.getQuick(i) * e.getQuick(i);                        t = (x * s - z * r) / q;                        h.setQuick(i, n, t);                        if (Math.abs(x) > Math.abs(z)) {                            h.setQuick(i + 1, n, (-r - w * t) / x);                        } else {                            h.setQuick(i + 1, n, (-s - y * t) / z);                        }                    }                                        t = Math.abs(h.getQuick(i, n));                    if (eps * t * t > 1) {                        for (int j = i; j <= n; j++) {                            h.setQuick(j, n, h.getQuick(j, n) / t);                        }                    }                }            }                } else if (q < 0) {            int l = n - 1;            if (Math.abs(h.getQuick(n, n - 1)) > Math.abs(h.getQuick(n - 1, n))) {                h.setQuick(n - 1, n - 1, q / h.getQuick(n, n - 1));                h.setQuick(n - 1, n, -(h.getQuick(n, n) - p) / h.getQuick(n, n - 1));            } else {                cdiv(0.0, -h.getQuick(n - 1, n), h.getQuick(n - 1, n - 1) - p, q);                h.setQuick(n - 1, n - 1, cdivr);                h.setQuick(n - 1, n, cdivi);            }            h.setQuick(n, n - 1, 0.0);            h.setQuick(n, n, 1.0);            for (int i = n - 2; i >= 0; i--) {                double ra = 0.0;                double sa = 0.0;                for (int j = l; j <= n; j++) {                    ra += h.getQuick(i, j) * h.getQuick(j, n - 1);                    sa += h.getQuick(i, j) * h.getQuick(j, n);                }                w = h.getQuick(i, i) - p;                if (e.getQuick(i) < 0.0) {                    z = w;                    r = ra;                    s = sa;                } else {                    l = i;                    if (e.getQuick(i) == 0) {                        cdiv(-ra, -sa, w, q);                        h.setQuick(i, n - 1, cdivr);                        h.setQuick(i, n, cdivi);                    } else {                                                x = h.getQuick(i, i + 1);                        y = h.getQuick(i + 1, i);                        double vr = (d.getQuick(i) - p) * (d.getQuick(i) - p) + e.getQuick(i) * e.getQuick(i) - q * q;                        double vi = (d.getQuick(i) - p) * 2.0 * q;                        if (vr == 0.0 && vi == 0.0) {                            double hmag = Math.abs(x) + Math.abs(y);                            vr = eps * norm * (Math.abs(w) + Math.abs(q) + hmag + Math.abs(z));                        }                        cdiv(x * r - z * ra + q * sa, x * s - z * sa - q * ra, vr, vi);                        h.setQuick(i, n - 1, cdivr);                        h.setQuick(i, n, cdivi);                        if (Math.abs(x) > (Math.abs(z) + Math.abs(q))) {                            h.setQuick(i + 1, n - 1, (-ra - w * h.getQuick(i, n - 1) + q * h.getQuick(i, n)) / x);                            h.setQuick(i + 1, n, (-sa - w * h.getQuick(i, n) - q * h.getQuick(i, n - 1)) / x);                        } else {                            cdiv(-r - y * h.getQuick(i, n - 1), -s - y * h.getQuick(i, n), z, q);                            h.setQuick(i + 1, n - 1, cdivr);                            h.setQuick(i + 1, n, cdivi);                        }                    }                                        t = Math.max(Math.abs(h.getQuick(i, n - 1)), Math.abs(h.getQuick(i, n)));                    if (eps * t * t > 1) {                        for (int j = i; j <= n; j++) {                            h.setQuick(j, n - 1, h.getQuick(j, n - 1) / t);                            h.setQuick(j, n, h.getQuick(j, n) / t);                        }                    }                }            }        }    }    for (int i = 0; i < nn; i++) {        if (i < low || i > high) {            for (int j = i; j < nn; j++) {                v.setQuick(i, j, h.getQuick(i, j));            }        }    }    for (int j = nn - 1; j >= low; j--) {        for (int i = low; i <= high; i++) {            z = 0.0;            for (int k = low; k <= Math.min(j, high); k++) {                z += v.getQuick(i, k) * h.getQuick(k, j);            }            v.setQuick(i, j, z);        }    }}
private static boolean mahout_f6987_0(Matrix a)
{    /*    Symmetry flag.    */    int n = a.columnSize();    boolean isSymmetric = true;    for (int j = 0; (j < n) && isSymmetric; j++) {        for (int i = 0; (i < n) && isSymmetric; i++) {            isSymmetric = a.getQuick(i, j) == a.getQuick(j, i);        }    }    return isSymmetric;}
public Vector mahout_f6988_0(Vector v)
{    return v.times(inverseDiagonal);}
public int mahout_f6989_0()
{    return iteration;}
public double mahout_f6990_0()
{    return residualNorm;}
public double mahout_f6991_0()
{    return normalEquationResidual;}
public double mahout_f6992_0()
{    return normA;}
public double mahout_f6993_0()
{    return condA;}
public double mahout_f6994_0()
{    return xNorm;}
public Vector mahout_f6995_1(Matrix A, Vector b)
{    /*        % Initialize.        hdg1 = '   itn      x(1)       norm r    norm A''r';        hdg2 = ' compatible   LS      norm A   cond A';        pfreq  = 20;   % print frequency (for repeating the heading)        pcount = 0;    % print counter        % Determine dimensions m and n, and        % form the first vectors u and v.        % These satisfy  beta*u = b,  alpha*v = A'u.    */            Matrix transposedA = A.transpose();    Vector u = b;    double beta = u.norm(2);    if (beta > 0) {        u = u.divide(beta);    }    Vector v = transposedA.times(u);    int m = A.numRows();    int n = A.numCols();    int minDim = Math.min(m, n);    if (iterationLimit == -1) {        iterationLimit = minDim;    }    if (log.isDebugEnabled()) {                    }    double alpha = v.norm(2);    if (alpha > 0) {        v.assign(Functions.div(alpha));    }        localPointer = 0;                    localV = new Vector[Math.min(localSize, minDim)];    boolean localOrtho = false;    if (localSize > 0) {        localOrtho = true;        localV[0] = v;    }        iteration = 0;    double zetabar = alpha * beta;    double alphabar = alpha;    Vector h = v;    Vector hbar = zeros(n);    Vector x = zeros(n);        double betadd = beta;        double aNorm = alpha * alpha;        double normb = beta;    double ctol = 0;    if (conditionLimit > 0) {        ctol = 1 / conditionLimit;    }    residualNorm = beta;        normalEquationResidual = alpha * beta;    if (normalEquationResidual == 0) {        return x;    }    if (log.isDebugEnabled()) {        double test2 = alpha / beta;                                double test1 = 1;            }                double rho = 1;    double rhobar = 1;    double cbar = 1;    double sbar = 0;    double betad = 0;    double rhodold = 1;    double tautildeold = 0;    double thetatilde = 0;    double zeta = 0;    double d = 0;    double maxrbar = 0;    double minrbar = 1.0e+100;    StopCode stop = StopCode.CONTINUE;    while (iteration <= iterationLimit && stop == StopCode.CONTINUE) {        iteration++;                                        u = A.times(v).minus(u.times(alpha));        beta = u.norm(2);        if (beta > 0) {            u.assign(Functions.div(beta));                        if (localOrtho) {                localVEnqueue(v);            }            v = transposedA.times(u).minus(v.times(beta));                        if (localOrtho) {                v = localVOrtho(v);            }            alpha = v.norm(2);            if (alpha > 0) {                v.assign(Functions.div(alpha));            }        }                        double alphahat = Math.hypot(alphabar, lambda);        double chat = alphabar / alphahat;        double shat = lambda / alphahat;                double rhoold = rho;        rho = Math.hypot(alphahat, beta);        double c = alphahat / rho;        double s = beta / rho;        double thetanew = s * alpha;        alphabar = c * alpha;                double rhobarold = rhobar;        double zetaold = zeta;        double thetabar = sbar * rho;        double rhotemp = cbar * rho;        rhobar = Math.hypot(cbar * rho, thetanew);        cbar = cbar * rho / rhobar;        sbar = thetanew / rhobar;        zeta = cbar * zetabar;        zetabar = -sbar * zetabar;                hbar = h.minus(hbar.times(thetabar * rho / (rhoold * rhobarold)));        x.assign(hbar.times(zeta / (rho * rhobar)), Functions.PLUS);        h = v.minus(h.times(thetanew / rho));                        double betaacute = chat * betadd;        double betacheck = -shat * betadd;                double betahat = c * betaacute;        betadd = -s * betaacute;                        double thetatildeold = thetatilde;        double rhotildeold = Math.hypot(rhodold, thetabar);        double ctildeold = rhodold / rhotildeold;        double stildeold = thetabar / rhotildeold;        thetatilde = stildeold * rhobar;        rhodold = ctildeold * rhobar;        betad = -stildeold * betad + ctildeold * betahat;                        tautildeold = (zetaold - thetatildeold * tautildeold) / rhotildeold;        double taud = (zeta - thetatilde * tautildeold) / rhodold;        d += betacheck * betacheck;        residualNorm = Math.sqrt(d + (betad - taud) * (betad - taud) + betadd * betadd);                aNorm += beta * beta;        normA = Math.sqrt(aNorm);        aNorm += alpha * alpha;                maxrbar = Math.max(maxrbar, rhobarold);        if (iteration > 1) {            minrbar = Math.min(minrbar, rhobarold);        }        condA = Math.max(maxrbar, rhotemp) / Math.min(minrbar, rhotemp);                        normalEquationResidual = Math.abs(zetabar);        xNorm = x.norm(2);                        double test1 = residualNorm / normb;        double test2 = normalEquationResidual / (normA * residualNorm);        double test3 = 1 / condA;        double t1 = test1 / (1 + normA * xNorm / normb);        double rtol = bTolerance + aTolerance * normA * xNorm / normb;        if (iteration > iterationLimit) {            stop = StopCode.ITERATION_LIMIT;        }        if (1 + test3 <= 1) {            stop = StopCode.CONDITION_MACHINE_TOLERANCE;        }        if (1 + test2 <= 1) {            stop = StopCode.LEAST_SQUARE_CONVERGED_MACHINE_TOLERANCE;        }        if (1 + t1 <= 1) {            stop = StopCode.CONVERGED_MACHINE_TOLERANCE;        }        if (test3 <= ctol) {            stop = StopCode.CONDITION;        }        if (test2 <= aTolerance) {            stop = StopCode.CONVERGED;        }        if (test1 <= rtol) {            stop = StopCode.TRIVIAL;        }                if (log.isDebugEnabled()) {            if ((n <= 40) || (iteration <= 10) || (iteration >= iterationLimit - 10) || ((iteration % 10) == 0) || (test3 <= 1.1 * ctol) || (test2 <= 1.1 * aTolerance) || (test1 <= 1.1 * rtol) || (stop != StopCode.CONTINUE)) {                statusDump(x, normA, condA, test1, test2);            }        }    }                return x;/*    if show      fprintf('\n\nLSMR finished')      fprintf('\n%s', msg(istop+1,:))      fprintf('\nistop =%8g    normr =%8.1e'     , istop, normr )      fprintf('    normA =%8.1e    normAr =%8.1e', normA, normAr)      fprintf('\nitn   =%8g    condA =%8.1e'     , itn  , condA )      fprintf('    normx =%8.1e\n', normx)    end    */}
private void mahout_f6996_1(Vector x, double normA, double condA, double test1, double test2)
{                }
private static Vector mahout_f6997_0(int n)
{    return new DenseVector(n);}
private void mahout_f6998_0(Vector v)
{    if (localV.length > 0) {        localV[localPointer] = v;        localPointer = (localPointer + 1) % localV.length;    }}
private Vector mahout_f6999_0(Vector v)
{    for (Vector old : localV) {        if (old != null) {            double x = v.dot(old);            v = v.minus(old.times(x));        }    }    return v;}
public String mahout_f7000_0()
{    return message;}
public void mahout_f7001_0(double aTolerance)
{    this.aTolerance = aTolerance;}
public void mahout_f7002_0(double bTolerance)
{    this.bTolerance = bTolerance;}
public void mahout_f7003_0(double conditionLimit)
{    this.conditionLimit = conditionLimit;}
public void mahout_f7004_0(int iterationLimit)
{    this.iterationLimit = iterationLimit;}
public void mahout_f7005_0(int localSize)
{    this.localSize = localSize;}
public double mahout_f7006_0()
{    return lambda;}
public double mahout_f7007_0()
{    return aTolerance;}
public double mahout_f7008_0()
{    return bTolerance;}
private static int mahout_f7009_0(T[] array, int a, int b, int c, Comparator<T> comp)
{    T x = array[a];    T y = array[b];    T z = array[c];    int comparisonxy = comp.compare(x, y);    int comparisonxz = comp.compare(x, z);    int comparisonyz = comp.compare(y, z);    return comparisonxy < 0 ? (comparisonyz < 0 ? b : (comparisonxz < 0 ? c : a)) : (comparisonyz > 0 ? b : (comparisonxz > 0 ? c : a));}
private static int mahout_f7010_0(byte[] array, int a, int b, int c, ByteComparator comp)
{    byte x = array[a];    byte y = array[b];    byte z = array[c];    int comparisonxy = comp.compare(x, y);    int comparisonxz = comp.compare(x, z);    int comparisonyz = comp.compare(y, z);    return comparisonxy < 0 ? (comparisonyz < 0 ? b : (comparisonxz < 0 ? c : a)) : (comparisonyz > 0 ? b : (comparisonxz > 0 ? c : a));}
private static int mahout_f7011_0(char[] array, int a, int b, int c, CharComparator comp)
{    char x = array[a];    char y = array[b];    char z = array[c];    int comparisonxy = comp.compare(x, y);    int comparisonxz = comp.compare(x, z);    int comparisonyz = comp.compare(y, z);    return comparisonxy < 0 ? (comparisonyz < 0 ? b : (comparisonxz < 0 ? c : a)) : (comparisonyz > 0 ? b : (comparisonxz > 0 ? c : a));}
private static int mahout_f7012_0(double[] array, int a, int b, int c, DoubleComparator comp)
{    double x = array[a];    double y = array[b];    double z = array[c];    int comparisonxy = comp.compare(x, y);    int comparisonxz = comp.compare(x, z);    int comparisonyz = comp.compare(y, z);    return comparisonxy < 0 ? (comparisonyz < 0 ? b : (comparisonxz < 0 ? c : a)) : (comparisonyz > 0 ? b : (comparisonxz > 0 ? c : a));}
private static int mahout_f7013_0(float[] array, int a, int b, int c, FloatComparator comp)
{    float x = array[a];    float y = array[b];    float z = array[c];    int comparisonxy = comp.compare(x, y);    int comparisonxz = comp.compare(x, z);    int comparisonyz = comp.compare(y, z);    return comparisonxy < 0 ? (comparisonyz < 0 ? b : (comparisonxz < 0 ? c : a)) : (comparisonyz > 0 ? b : (comparisonxz > 0 ? c : a));}
private static int mahout_f7014_0(int[] array, int a, int b, int c, IntComparator comp)
{    int x = array[a];    int y = array[b];    int z = array[c];    int comparisonxy = comp.compare(x, y);    int comparisonxz = comp.compare(x, z);    int comparisonyz = comp.compare(y, z);    return comparisonxy < 0 ? (comparisonyz < 0 ? b : (comparisonxz < 0 ? c : a)) : (comparisonyz > 0 ? b : (comparisonxz > 0 ? c : a));}
private static int mahout_f7015_0(int a, int b, int c, IntComparator comp)
{    int comparisonab = comp.compare(a, b);    int comparisonac = comp.compare(a, c);    int comparisonbc = comp.compare(b, c);    return comparisonab < 0 ? (comparisonbc < 0 ? b : (comparisonac < 0 ? c : a)) : (comparisonbc > 0 ? b : (comparisonac > 0 ? c : a));}
private static int mahout_f7016_0(long[] array, int a, int b, int c, LongComparator comp)
{    long x = array[a];    long y = array[b];    long z = array[c];    int comparisonxy = comp.compare(x, y);    int comparisonxz = comp.compare(x, z);    int comparisonyz = comp.compare(y, z);    return comparisonxy < 0 ? (comparisonyz < 0 ? b : (comparisonxz < 0 ? c : a)) : (comparisonyz > 0 ? b : (comparisonxz > 0 ? c : a));}
private static int mahout_f7017_0(short[] array, int a, int b, int c, ShortComparator comp)
{    short x = array[a];    short y = array[b];    short z = array[c];    int comparisonxy = comp.compare(x, y);    int comparisonxz = comp.compare(x, z);    int comparisonyz = comp.compare(y, z);    return comparisonxy < 0 ? (comparisonyz < 0 ? b : (comparisonxz < 0 ? c : a)) : (comparisonyz > 0 ? b : (comparisonxz > 0 ? c : a));}
public static void mahout_f7018_0(byte[] array, int start, int end, ByteComparator comp)
{    Preconditions.checkNotNull(array);    checkBounds(array.length, start, end);    quickSort0(start, end, array, comp);}
private static void mahout_f7019_0(int arrLength, int start, int end)
{    if (start > end) {                throw new IllegalArgumentException("Start index " + start + " is greater than end index " + end);    }    if (start < 0) {        throw new ArrayIndexOutOfBoundsException("Array index out of range " + start);    }    if (end > arrLength) {        throw new ArrayIndexOutOfBoundsException("Array index out of range " + end);    }}
private static void mahout_f7020_0(int start, int end, byte[] array, ByteComparator comp)
{    byte temp;    int length = end - start;    if (length < 7) {        for (int i = start + 1; i < end; i++) {            for (int j = i; j > start && comp.compare(array[j - 1], array[j]) > 0; j--) {                temp = array[j];                array[j] = array[j - 1];                array[j - 1] = temp;            }        }        return;    }    int middle = (start + end) / 2;    if (length > 7) {        int bottom = start;        int top = end - 1;        if (length > 40) {            length /= 8;            bottom = med3(array, bottom, bottom + length, bottom + (2 * length), comp);            middle = med3(array, middle - length, middle, middle + length, comp);            top = med3(array, top - (2 * length), top - length, top, comp);        }        middle = med3(array, bottom, middle, top, comp);    }    byte partionValue = array[middle];    int a = start;    int b = a;    int c = end - 1;    int d = c;    while (true) {        int comparison;        while (b <= c && (comparison = comp.compare(array[b], partionValue)) <= 0) {            if (comparison == 0) {                temp = array[a];                array[a++] = array[b];                array[b] = temp;            }            b++;        }        while (c >= b && (comparison = comp.compare(array[c], partionValue)) >= 0) {            if (comparison == 0) {                temp = array[c];                array[c] = array[d];                array[d--] = temp;            }            c--;        }        if (b > c) {            break;        }        temp = array[b];        array[b++] = array[c];        array[c--] = temp;    }    length = a - start < b - a ? a - start : b - a;    int l = start;    int h = b - length;    while (length-- > 0) {        temp = array[l];        array[l++] = array[h];        array[h++] = temp;    }    length = d - c < end - 1 - d ? d - c : end - 1 - d;    l = b;    h = end - length;    while (length-- > 0) {        temp = array[l];        array[l++] = array[h];        array[h++] = temp;    }    if ((length = b - a) > 0) {        quickSort0(start, start + length, array, comp);    }    if ((length = d - c) > 0) {        quickSort0(end - length, end, array, comp);    }}
public static void mahout_f7021_0(int start, int end, IntComparator comp, Swapper swap)
{    checkBounds(end + 1, start, end);    quickSort0(start, end, comp, swap);}
private static void mahout_f7022_0(int start, int end, IntComparator comp, Swapper swap)
{    int length = end - start;    if (length < 7) {        insertionSort(start, end, comp, swap);        return;    }    int middle = (start + end) / 2;    if (length > 7) {        int bottom = start;        int top = end - 1;        if (length > 40) {                        int skosh = length / 8;            bottom = med3(bottom, bottom + skosh, bottom + (2 * skosh), comp);            middle = med3(middle - skosh, middle, middle + skosh, comp);            top = med3(top - (2 * skosh), top - skosh, top, comp);        }        middle = med3(bottom, middle, top, comp);    }        int partitionIndex = middle;        int a = start;    int b = a;    int c = end - 1;    int d = c;    while (b <= c) {                        int comparison;        while (b <= c && (comparison = comp.compare(b, partitionIndex)) <= 0) {            if (comparison == 0) {                if (a == partitionIndex) {                    partitionIndex = b;                } else if (b == partitionIndex) {                    partitionIndex = a;                }                swap.swap(a, b);                a++;            }            b++;        }        while (c >= b && (comparison = comp.compare(c, partitionIndex)) >= 0) {            if (comparison == 0) {                if (c == partitionIndex) {                    partitionIndex = d;                } else if (d == partitionIndex) {                    partitionIndex = c;                }                swap.swap(c, d);                d--;            }            c--;        }        if (b <= c) {                        if (c == partitionIndex) {                partitionIndex = b;            } else if (b == partitionIndex) {                partitionIndex = d;            }            swap.swap(b, c);            b++;            c--;        }    }                            length = Math.min(a - start, b - a);    int l = start;    int h = b - length;    while (length-- > 0) {        swap.swap(l, h);        l++;        h++;    }        length = Math.min(d - c, end - 1 - d);    l = b;    h = end - length;    while (length-- > 0) {        swap.swap(l, h);        l++;        h++;    }        length = b - a;    if (length > 0) {        quickSort0(start, start + length, comp, swap);    }    length = d - c;    if (length > 0) {        quickSort0(end - length, end, comp, swap);    }}
private static void mahout_f7023_0(int start, int end, IntComparator comp, Swapper swap)
{    for (int i = start + 1; i < end; i++) {        for (int j = i; j > start && comp.compare(j - 1, j) > 0; j--) {            swap.swap(j - 1, j);        }    }}
public static void mahout_f7024_0(char[] array, int start, int end, CharComparator comp)
{    Preconditions.checkNotNull(array);    checkBounds(array.length, start, end);    quickSort0(start, end, array, comp);}
private static void mahout_f7025_0(int start, int end, char[] array, CharComparator comp)
{    char temp;    int length = end - start;    if (length < 7) {        for (int i = start + 1; i < end; i++) {            for (int j = i; j > start && comp.compare(array[j - 1], array[j]) > 0; j--) {                temp = array[j];                array[j] = array[j - 1];                array[j - 1] = temp;            }        }        return;    }    int middle = (start + end) / 2;    if (length > 7) {        int bottom = start;        int top = end - 1;        if (length > 40) {            length /= 8;            bottom = med3(array, bottom, bottom + length, bottom + (2 * length), comp);            middle = med3(array, middle - length, middle, middle + length, comp);            top = med3(array, top - (2 * length), top - length, top, comp);        }        middle = med3(array, bottom, middle, top, comp);    }    char partionValue = array[middle];    int a = start;    int b = a;    int c = end - 1;    int d = c;    while (true) {        int comparison;        while (b <= c && (comparison = comp.compare(array[b], partionValue)) <= 0) {            if (comparison == 0) {                temp = array[a];                array[a++] = array[b];                array[b] = temp;            }            b++;        }        while (c >= b && (comparison = comp.compare(array[c], partionValue)) >= 0) {            if (comparison == 0) {                temp = array[c];                array[c] = array[d];                array[d--] = temp;            }            c--;        }        if (b > c) {            break;        }        temp = array[b];        array[b++] = array[c];        array[c--] = temp;    }    length = a - start < b - a ? a - start : b - a;    int l = start;    int h = b - length;    while (length-- > 0) {        temp = array[l];        array[l++] = array[h];        array[h++] = temp;    }    length = d - c < end - 1 - d ? d - c : end - 1 - d;    l = b;    h = end - length;    while (length-- > 0) {        temp = array[l];        array[l++] = array[h];        array[h++] = temp;    }    if ((length = b - a) > 0) {        quickSort0(start, start + length, array, comp);    }    if ((length = d - c) > 0) {        quickSort0(end - length, end, array, comp);    }}
public static void mahout_f7026_0(double[] array, int start, int end, DoubleComparator comp)
{    Preconditions.checkNotNull(array);    checkBounds(array.length, start, end);    quickSort0(start, end, array, comp);}
private static void mahout_f7027_0(int start, int end, double[] array, DoubleComparator comp)
{    double temp;    int length = end - start;    if (length < 7) {        for (int i = start + 1; i < end; i++) {            for (int j = i; j > start && comp.compare(array[j], array[j - 1]) < 0; j--) {                temp = array[j];                array[j] = array[j - 1];                array[j - 1] = temp;            }        }        return;    }    int middle = (start + end) / 2;    if (length > 7) {        int bottom = start;        int top = end - 1;        if (length > 40) {            length /= 8;            bottom = med3(array, bottom, bottom + length, bottom + (2 * length), comp);            middle = med3(array, middle - length, middle, middle + length, comp);            top = med3(array, top - (2 * length), top - length, top, comp);        }        middle = med3(array, bottom, middle, top, comp);    }    double partionValue = array[middle];    int a = start;    int b = a;    int c = end - 1;    int d = c;    while (true) {        int comparison;        while (b <= c && (comparison = comp.compare(partionValue, array[b])) >= 0) {            if (comparison == 0) {                temp = array[a];                array[a++] = array[b];                array[b] = temp;            }            b++;        }        while (c >= b && (comparison = comp.compare(array[c], partionValue)) >= 0) {            if (comparison == 0) {                temp = array[c];                array[c] = array[d];                array[d--] = temp;            }            c--;        }        if (b > c) {            break;        }        temp = array[b];        array[b++] = array[c];        array[c--] = temp;    }    length = a - start < b - a ? a - start : b - a;    int l = start;    int h = b - length;    while (length-- > 0) {        temp = array[l];        array[l++] = array[h];        array[h++] = temp;    }    length = d - c < end - 1 - d ? d - c : end - 1 - d;    l = b;    h = end - length;    while (length-- > 0) {        temp = array[l];        array[l++] = array[h];        array[h++] = temp;    }    if ((length = b - a) > 0) {        quickSort0(start, start + length, array, comp);    }    if ((length = d - c) > 0) {        quickSort0(end - length, end, array, comp);    }}
public static void mahout_f7028_0(float[] array, int start, int end, FloatComparator comp)
{    Preconditions.checkNotNull(array);    checkBounds(array.length, start, end);    quickSort0(start, end, array, comp);}
private static void mahout_f7029_0(int start, int end, float[] array, FloatComparator comp)
{    float temp;    int length = end - start;    if (length < 7) {        for (int i = start + 1; i < end; i++) {            for (int j = i; j > start && comp.compare(array[j], array[j - 1]) < 0; j--) {                temp = array[j];                array[j] = array[j - 1];                array[j - 1] = temp;            }        }        return;    }    int middle = (start + end) / 2;    if (length > 7) {        int bottom = start;        int top = end - 1;        if (length > 40) {            length /= 8;            bottom = med3(array, bottom, bottom + length, bottom + (2 * length), comp);            middle = med3(array, middle - length, middle, middle + length, comp);            top = med3(array, top - (2 * length), top - length, top, comp);        }        middle = med3(array, bottom, middle, top, comp);    }    float partionValue = array[middle];    int a = start;    int b = a;    int c = end - 1;    int d = c;    while (true) {        int comparison;        while (b <= c && (comparison = comp.compare(partionValue, array[b])) >= 0) {            if (comparison == 0) {                temp = array[a];                array[a++] = array[b];                array[b] = temp;            }            b++;        }        while (c >= b && (comparison = comp.compare(array[c], partionValue)) >= 0) {            if (comparison == 0) {                temp = array[c];                array[c] = array[d];                array[d--] = temp;            }            c--;        }        if (b > c) {            break;        }        temp = array[b];        array[b++] = array[c];        array[c--] = temp;    }    length = a - start < b - a ? a - start : b - a;    int l = start;    int h = b - length;    while (length-- > 0) {        temp = array[l];        array[l++] = array[h];        array[h++] = temp;    }    length = d - c < end - 1 - d ? d - c : end - 1 - d;    l = b;    h = end - length;    while (length-- > 0) {        temp = array[l];        array[l++] = array[h];        array[h++] = temp;    }    if ((length = b - a) > 0) {        quickSort0(start, start + length, array, comp);    }    if ((length = d - c) > 0) {        quickSort0(end - length, end, array, comp);    }}
public static void mahout_f7030_0(int[] array, int start, int end, IntComparator comp)
{    Preconditions.checkNotNull(array);    checkBounds(array.length, start, end);    quickSort0(start, end, array, comp);}
private static void mahout_f7031_0(int start, int end, int[] array, IntComparator comp)
{    int temp;    int length = end - start;    if (length < 7) {        for (int i = start + 1; i < end; i++) {            for (int j = i; j > start && comp.compare(array[j - 1], array[j]) > 0; j--) {                temp = array[j];                array[j] = array[j - 1];                array[j - 1] = temp;            }        }        return;    }    int middle = (start + end) / 2;    if (length > 7) {        int bottom = start;        int top = end - 1;        if (length > 40) {            length /= 8;            bottom = med3(array, bottom, bottom + length, bottom + (2 * length), comp);            middle = med3(array, middle - length, middle, middle + length, comp);            top = med3(array, top - (2 * length), top - length, top, comp);        }        middle = med3(array, bottom, middle, top, comp);    }    int partionValue = array[middle];    int a = start;    int b = a;    int c = end - 1;    int d = c;    while (true) {        int comparison;        while (b <= c && (comparison = comp.compare(array[b], partionValue)) <= 0) {            if (comparison == 0) {                temp = array[a];                array[a++] = array[b];                array[b] = temp;            }            b++;        }        while (c >= b && (comparison = comp.compare(array[c], partionValue)) >= 0) {            if (comparison == 0) {                temp = array[c];                array[c] = array[d];                array[d--] = temp;            }            c--;        }        if (b > c) {            break;        }        temp = array[b];        array[b++] = array[c];        array[c--] = temp;    }    length = a - start < b - a ? a - start : b - a;    int l = start;    int h = b - length;    while (length-- > 0) {        temp = array[l];        array[l++] = array[h];        array[h++] = temp;    }    length = d - c < end - 1 - d ? d - c : end - 1 - d;    l = b;    h = end - length;    while (length-- > 0) {        temp = array[l];        array[l++] = array[h];        array[h++] = temp;    }    if ((length = b - a) > 0) {        quickSort0(start, start + length, array, comp);    }    if ((length = d - c) > 0) {        quickSort0(end - length, end, array, comp);    }}
public static void mahout_f7032_0(long[] array, int start, int end, LongComparator comp)
{    Preconditions.checkNotNull(array);    checkBounds(array.length, start, end);    quickSort0(start, end, array, comp);}
private static void mahout_f7033_0(int start, int end, long[] array, LongComparator comp)
{    long temp;    int length = end - start;    if (length < 7) {        for (int i = start + 1; i < end; i++) {            for (int j = i; j > start && comp.compare(array[j - 1], array[j]) > 0; j--) {                temp = array[j];                array[j] = array[j - 1];                array[j - 1] = temp;            }        }        return;    }    int middle = (start + end) / 2;    if (length > 7) {        int bottom = start;        int top = end - 1;        if (length > 40) {            length /= 8;            bottom = med3(array, bottom, bottom + length, bottom + (2 * length), comp);            middle = med3(array, middle - length, middle, middle + length, comp);            top = med3(array, top - (2 * length), top - length, top, comp);        }        middle = med3(array, bottom, middle, top, comp);    }    long partionValue = array[middle];    int a = start;    int b = a;    int c = end - 1;    int d = c;    while (true) {        int comparison;        while (b <= c && (comparison = comp.compare(array[b], partionValue)) <= 0) {            if (comparison == 0) {                temp = array[a];                array[a++] = array[b];                array[b] = temp;            }            b++;        }        while (c >= b && (comparison = comp.compare(array[c], partionValue)) >= 0) {            if (comparison == 0) {                temp = array[c];                array[c] = array[d];                array[d--] = temp;            }            c--;        }        if (b > c) {            break;        }        temp = array[b];        array[b++] = array[c];        array[c--] = temp;    }    length = a - start < b - a ? a - start : b - a;    int l = start;    int h = b - length;    while (length-- > 0) {        temp = array[l];        array[l++] = array[h];        array[h++] = temp;    }    length = d - c < end - 1 - d ? d - c : end - 1 - d;    l = b;    h = end - length;    while (length-- > 0) {        temp = array[l];        array[l++] = array[h];        array[h++] = temp;    }    if ((length = b - a) > 0) {        quickSort0(start, start + length, array, comp);    }    if ((length = d - c) > 0) {        quickSort0(end - length, end, array, comp);    }}
public static void mahout_f7034_0(T[] array, int start, int end, Comparator<T> comp)
{    Preconditions.checkNotNull(array);    checkBounds(array.length, start, end);    quickSort0(start, end, array, comp);}
public int mahout_f7035_0(T o1, T o2)
{    return o1.compareTo(o2);}
public static void mahout_f7036_0(T[] array, int start, int end)
{    quickSort(array, start, end, new ComparableAdaptor<T>());}
private static void mahout_f7037_0(int start, int end, T[] array, Comparator<T> comp)
{    T temp;    int length = end - start;    if (length < 7) {        for (int i = start + 1; i < end; i++) {            for (int j = i; j > start && comp.compare(array[j - 1], array[j]) > 0; j--) {                temp = array[j];                array[j] = array[j - 1];                array[j - 1] = temp;            }        }        return;    }    int middle = (start + end) / 2;    if (length > 7) {        int bottom = start;        int top = end - 1;        if (length > 40) {            length /= 8;            bottom = med3(array, bottom, bottom + length, bottom + (2 * length), comp);            middle = med3(array, middle - length, middle, middle + length, comp);            top = med3(array, top - (2 * length), top - length, top, comp);        }        middle = med3(array, bottom, middle, top, comp);    }    T partionValue = array[middle];    int a = start;    int b = a;    int c = end - 1;    int d = c;    while (true) {        int comparison;        while (b <= c && (comparison = comp.compare(array[b], partionValue)) <= 0) {            if (comparison == 0) {                temp = array[a];                array[a++] = array[b];                array[b] = temp;            }            b++;        }        while (c >= b && (comparison = comp.compare(array[c], partionValue)) >= 0) {            if (comparison == 0) {                temp = array[c];                array[c] = array[d];                array[d--] = temp;            }            c--;        }        if (b > c) {            break;        }        temp = array[b];        array[b++] = array[c];        array[c--] = temp;    }    length = a - start < b - a ? a - start : b - a;    int l = start;    int h = b - length;    while (length-- > 0) {        temp = array[l];        array[l++] = array[h];        array[h++] = temp;    }    length = d - c < end - 1 - d ? d - c : end - 1 - d;    l = b;    h = end - length;    while (length-- > 0) {        temp = array[l];        array[l++] = array[h];        array[h++] = temp;    }    if ((length = b - a) > 0) {        quickSort0(start, start + length, array, comp);    }    if ((length = d - c) > 0) {        quickSort0(end - length, end, array, comp);    }}
public static void mahout_f7038_0(short[] array, int start, int end, ShortComparator comp)
{    Preconditions.checkNotNull(array);    checkBounds(array.length, start, end);    quickSort0(start, end, array, comp);}
private static void mahout_f7039_0(int start, int end, short[] array, ShortComparator comp)
{    short temp;    int length = end - start;    if (length < 7) {        for (int i = start + 1; i < end; i++) {            for (int j = i; j > start && comp.compare(array[j - 1], array[j]) > 0; j--) {                temp = array[j];                array[j] = array[j - 1];                array[j - 1] = temp;            }        }        return;    }    int middle = (start + end) / 2;    if (length > 7) {        int bottom = start;        int top = end - 1;        if (length > 40) {            length /= 8;            bottom = med3(array, bottom, bottom + length, bottom + (2 * length), comp);            middle = med3(array, middle - length, middle, middle + length, comp);            top = med3(array, top - (2 * length), top - length, top, comp);        }        middle = med3(array, bottom, middle, top, comp);    }    short partionValue = array[middle];    int a = start;    int b = a;    int c = end - 1;    int d = c;    while (true) {        int comparison;        while (b <= c && (comparison = comp.compare(array[b], partionValue)) < 0) {            if (comparison == 0) {                temp = array[a];                array[a++] = array[b];                array[b] = temp;            }            b++;        }        while (c >= b && (comparison = comp.compare(array[c], partionValue)) > 0) {            if (comparison == 0) {                temp = array[c];                array[c] = array[d];                array[d--] = temp;            }            c--;        }        if (b > c) {            break;        }        temp = array[b];        array[b++] = array[c];        array[c--] = temp;    }    length = a - start < b - a ? a - start : b - a;    int l = start;    int h = b - length;    while (length-- > 0) {        temp = array[l];        array[l++] = array[h];        array[h++] = temp;    }    length = d - c < end - 1 - d ? d - c : end - 1 - d;    l = b;    h = end - length;    while (length-- > 0) {        temp = array[l];        array[l++] = array[h];        array[h++] = temp;    }    if ((length = b - a) > 0) {        quickSort0(start, start + length, array, comp);    }    if ((length = d - c) > 0) {        quickSort0(end - length, end, array, comp);    }}
public static void mahout_f7040_0(T[] array, int start, int end, Comparator<T> comp)
{    checkBounds(array.length, start, end);    int length = end - start;    if (length <= 0) {        return;    }    T[] out = (T[]) new Object[array.length];    System.arraycopy(array, start, out, start, length);    mergeSort(out, array, start, end, comp);}
public static void mahout_f7041_0(T[] array, int start, int end)
{    mergeSort(array, start, end, new ComparableAdaptor<T>());}
private static void mahout_f7042_0(T[] in, T[] out, int start, int end, Comparator<T> c)
{    int len = end - start;        if (len <= SIMPLE_LENGTH) {        for (int i = start + 1; i < end; i++) {            T current = out[i];            T prev = out[i - 1];            if (c.compare(prev, current) > 0) {                int j = i;                do {                    out[j--] = prev;                } while (j > start && (c.compare(prev = out[j - 1], current) > 0));                out[j] = current;            }        }        return;    }    int med = (end + start) >>> 1;    mergeSort(out, in, start, med, c);    mergeSort(out, in, med, end, c);        if (c.compare(in[med - 1], in[med]) <= 0) {        System.arraycopy(in, start, out, start, len);        return;    }    int r = med;    int i = start;        do {        T fromVal = in[start];        T rVal = in[r];        if (c.compare(fromVal, rVal) <= 0) {            int l_1 = find(in, rVal, -1, start + 1, med - 1, c);            int toCopy = l_1 - start + 1;            System.arraycopy(in, start, out, i, toCopy);            i += toCopy;            out[i++] = rVal;            r++;            start = l_1 + 1;        } else {            int r_1 = find(in, fromVal, 0, r + 1, end - 1, c);            int toCopy = r_1 - r + 1;            System.arraycopy(in, r, out, i, toCopy);            i += toCopy;            out[i++] = fromVal;            start++;            r = r_1 + 1;        }    } while ((end - r) > 0 && (med - start) > 0);        if ((end - r) <= 0) {        System.arraycopy(in, start, out, i, med - start);    } else {        System.arraycopy(in, r, out, i, end - r);    }}
private static int mahout_f7043_0(T[] arr, T val, int bnd, int l, int r, Comparator<T> c)
{    int m = l;    int d = 1;    while (m <= r) {        if (c.compare(val, arr[m]) > bnd) {            l = m + 1;        } else {            r = m - 1;            break;        }        m += d;        d <<= 1;    }    while (l <= r) {        m = (l + r) >>> 1;        if (c.compare(val, arr[m]) > bnd) {            l = m + 1;        } else {            r = m - 1;        }    }    return l - 1;}
public int mahout_f7044_0(byte o1, byte o2)
{    return o1 - o2;}
public static void mahout_f7045_0(byte[] array, int start, int end)
{    mergeSort(array, start, end, NATURAL_BYTE_COMPARISON);}
public static void mahout_f7046_0(byte[] array, int start, int end, ByteComparator comp)
{    checkBounds(array.length, start, end);    byte[] out = Arrays.copyOf(array, array.length);    mergeSort(out, array, start, end, comp);}
private static void mahout_f7047_0(byte[] in, byte[] out, int start, int end, ByteComparator c)
{    int len = end - start;        if (len <= SIMPLE_LENGTH) {        for (int i = start + 1; i < end; i++) {            byte current = out[i];            byte prev = out[i - 1];            if (c.compare(prev, current) > 0) {                int j = i;                do {                    out[j--] = prev;                } while (j > start && (c.compare(prev = out[j - 1], current) > 0));                out[j] = current;            }        }        return;    }    int med = (end + start) >>> 1;    mergeSort(out, in, start, med, c);    mergeSort(out, in, med, end, c);        if (c.compare(in[med - 1], in[med]) <= 0) {        System.arraycopy(in, start, out, start, len);        return;    }    int r = med;    int i = start;        do {        byte fromVal = in[start];        byte rVal = in[r];        if (c.compare(fromVal, rVal) <= 0) {            int l_1 = find(in, rVal, -1, start + 1, med - 1, c);            int toCopy = l_1 - start + 1;            System.arraycopy(in, start, out, i, toCopy);            i += toCopy;            out[i++] = rVal;            r++;            start = l_1 + 1;        } else {            int r_1 = find(in, fromVal, 0, r + 1, end - 1, c);            int toCopy = r_1 - r + 1;            System.arraycopy(in, r, out, i, toCopy);            i += toCopy;            out[i++] = fromVal;            start++;            r = r_1 + 1;        }    } while ((end - r) > 0 && (med - start) > 0);        if ((end - r) <= 0) {        System.arraycopy(in, start, out, i, med - start);    } else {        System.arraycopy(in, r, out, i, end - r);    }}
private static int mahout_f7048_0(byte[] arr, byte val, int bnd, int l, int r, ByteComparator c)
{    int m = l;    int d = 1;    while (m <= r) {        if (c.compare(val, arr[m]) > bnd) {            l = m + 1;        } else {            r = m - 1;            break;        }        m += d;        d <<= 1;    }    while (l <= r) {        m = (l + r) >>> 1;        if (c.compare(val, arr[m]) > bnd) {            l = m + 1;        } else {            r = m - 1;        }    }    return l - 1;}
public int mahout_f7049_0(char o1, char o2)
{    return o1 - o2;}
public static void mahout_f7050_0(char[] array, int start, int end)
{    mergeSort(array, start, end, NATURAL_CHAR_COMPARISON);}
public static void mahout_f7051_0(char[] array, int start, int end, CharComparator comp)
{    checkBounds(array.length, start, end);    char[] out = Arrays.copyOf(array, array.length);    mergeSort(out, array, start, end, comp);}
private static void mahout_f7052_0(char[] in, char[] out, int start, int end, CharComparator c)
{    int len = end - start;        if (len <= SIMPLE_LENGTH) {        for (int i = start + 1; i < end; i++) {            char current = out[i];            char prev = out[i - 1];            if (c.compare(prev, current) > 0) {                int j = i;                do {                    out[j--] = prev;                } while (j > start && (c.compare(prev = out[j - 1], current) > 0));                out[j] = current;            }        }        return;    }    int med = (end + start) >>> 1;    mergeSort(out, in, start, med, c);    mergeSort(out, in, med, end, c);        if (c.compare(in[med - 1], in[med]) <= 0) {        System.arraycopy(in, start, out, start, len);        return;    }    int r = med;    int i = start;        do {        char fromVal = in[start];        char rVal = in[r];        if (c.compare(fromVal, rVal) <= 0) {            int l_1 = find(in, rVal, -1, start + 1, med - 1, c);            int toCopy = l_1 - start + 1;            System.arraycopy(in, start, out, i, toCopy);            i += toCopy;            out[i++] = rVal;            r++;            start = l_1 + 1;        } else {            int r_1 = find(in, fromVal, 0, r + 1, end - 1, c);            int toCopy = r_1 - r + 1;            System.arraycopy(in, r, out, i, toCopy);            i += toCopy;            out[i++] = fromVal;            start++;            r = r_1 + 1;        }    } while ((end - r) > 0 && (med - start) > 0);        if ((end - r) <= 0) {        System.arraycopy(in, start, out, i, med - start);    } else {        System.arraycopy(in, r, out, i, end - r);    }}
private static int mahout_f7053_0(char[] arr, char val, int bnd, int l, int r, CharComparator c)
{    int m = l;    int d = 1;    while (m <= r) {        if (c.compare(val, arr[m]) > bnd) {            l = m + 1;        } else {            r = m - 1;            break;        }        m += d;        d <<= 1;    }    while (l <= r) {        m = (l + r) >>> 1;        if (c.compare(val, arr[m]) > bnd) {            l = m + 1;        } else {            r = m - 1;        }    }    return l - 1;}
public int mahout_f7054_0(short o1, short o2)
{    return o1 - o2;}
public static void mahout_f7055_0(short[] array, int start, int end)
{    mergeSort(array, start, end, NATURAL_SHORT_COMPARISON);}
public static void mahout_f7056_0(short[] array, int start, int end, ShortComparator comp)
{    checkBounds(array.length, start, end);    short[] out = Arrays.copyOf(array, array.length);    mergeSort(out, array, start, end, comp);}
private static void mahout_f7057_0(short[] in, short[] out, int start, int end, ShortComparator c)
{    int len = end - start;        if (len <= SIMPLE_LENGTH) {        for (int i = start + 1; i < end; i++) {            short current = out[i];            short prev = out[i - 1];            if (c.compare(prev, current) > 0) {                int j = i;                do {                    out[j--] = prev;                } while (j > start && (c.compare(prev = out[j - 1], current) > 0));                out[j] = current;            }        }        return;    }    int med = (end + start) >>> 1;    mergeSort(out, in, start, med, c);    mergeSort(out, in, med, end, c);        if (c.compare(in[med - 1], in[med]) <= 0) {        System.arraycopy(in, start, out, start, len);        return;    }    int r = med;    int i = start;        do {        short fromVal = in[start];        short rVal = in[r];        if (c.compare(fromVal, rVal) <= 0) {            int l_1 = find(in, rVal, -1, start + 1, med - 1, c);            int toCopy = l_1 - start + 1;            System.arraycopy(in, start, out, i, toCopy);            i += toCopy;            out[i++] = rVal;            r++;            start = l_1 + 1;        } else {            int r_1 = find(in, fromVal, 0, r + 1, end - 1, c);            int toCopy = r_1 - r + 1;            System.arraycopy(in, r, out, i, toCopy);            i += toCopy;            out[i++] = fromVal;            start++;            r = r_1 + 1;        }    } while ((end - r) > 0 && (med - start) > 0);        if ((end - r) <= 0) {        System.arraycopy(in, start, out, i, med - start);    } else {        System.arraycopy(in, r, out, i, end - r);    }}
private static int mahout_f7058_0(short[] arr, short val, int bnd, int l, int r, ShortComparator c)
{    int m = l;    int d = 1;    while (m <= r) {        if (c.compare(val, arr[m]) > bnd) {            l = m + 1;        } else {            r = m - 1;            break;        }        m += d;        d <<= 1;    }    while (l <= r) {        m = (l + r) >>> 1;        if (c.compare(val, arr[m]) > bnd) {            l = m + 1;        } else {            r = m - 1;        }    }    return l - 1;}
public int mahout_f7059_0(int o1, int o2)
{    return o1 < o2 ? -1 : o1 > o2 ? 1 : 0;}
public static void mahout_f7060_0(int[] array, int start, int end)
{    mergeSort(array, start, end, NATURAL_INT_COMPARISON);}
public static void mahout_f7061_0(int[] array, int start, int end, IntComparator comp)
{    checkBounds(array.length, start, end);    int[] out = Arrays.copyOf(array, array.length);    mergeSort(out, array, start, end, comp);}
private static void mahout_f7062_0(int[] in, int[] out, int start, int end, IntComparator c)
{    int len = end - start;        if (len <= SIMPLE_LENGTH) {        for (int i = start + 1; i < end; i++) {            int current = out[i];            int prev = out[i - 1];            if (c.compare(prev, current) > 0) {                int j = i;                do {                    out[j--] = prev;                } while (j > start && (c.compare(prev = out[j - 1], current) > 0));                out[j] = current;            }        }        return;    }    int med = (end + start) >>> 1;    mergeSort(out, in, start, med, c);    mergeSort(out, in, med, end, c);        if (c.compare(in[med - 1], in[med]) <= 0) {        System.arraycopy(in, start, out, start, len);        return;    }    int r = med;    int i = start;        do {        int fromVal = in[start];        int rVal = in[r];        if (c.compare(fromVal, rVal) <= 0) {            int l_1 = find(in, rVal, -1, start + 1, med - 1, c);            int toCopy = l_1 - start + 1;            System.arraycopy(in, start, out, i, toCopy);            i += toCopy;            out[i++] = rVal;            r++;            start = l_1 + 1;        } else {            int r_1 = find(in, fromVal, 0, r + 1, end - 1, c);            int toCopy = r_1 - r + 1;            System.arraycopy(in, r, out, i, toCopy);            i += toCopy;            out[i++] = fromVal;            start++;            r = r_1 + 1;        }    } while ((end - r) > 0 && (med - start) > 0);        if ((end - r) <= 0) {        System.arraycopy(in, start, out, i, med - start);    } else {        System.arraycopy(in, r, out, i, end - r);    }}
private static int mahout_f7063_0(int[] arr, int val, int bnd, int l, int r, IntComparator c)
{    int m = l;    int d = 1;    while (m <= r) {        if (c.compare(val, arr[m]) > bnd) {            l = m + 1;        } else {            r = m - 1;            break;        }        m += d;        d <<= 1;    }    while (l <= r) {        m = (l + r) >>> 1;        if (c.compare(val, arr[m]) > bnd) {            l = m + 1;        } else {            r = m - 1;        }    }    return l - 1;}
public int mahout_f7064_0(long o1, long o2)
{    return o1 < o2 ? -1 : o1 > o2 ? 1 : 0;}
public static void mahout_f7065_0(long[] array, int start, int end)
{    mergeSort(array, start, end, NATURAL_LONG_COMPARISON);}
public static void mahout_f7066_0(long[] array, int start, int end, LongComparator comp)
{    checkBounds(array.length, start, end);    long[] out = Arrays.copyOf(array, array.length);    mergeSort(out, array, start, end, comp);}
private static void mahout_f7067_0(long[] in, long[] out, int start, int end, LongComparator c)
{    int len = end - start;        if (len <= SIMPLE_LENGTH) {        for (int i = start + 1; i < end; i++) {            long current = out[i];            long prev = out[i - 1];            if (c.compare(prev, current) > 0) {                int j = i;                do {                    out[j--] = prev;                } while (j > start && (c.compare(prev = out[j - 1], current) > 0));                out[j] = current;            }        }        return;    }    int med = (end + start) >>> 1;    mergeSort(out, in, start, med, c);    mergeSort(out, in, med, end, c);        if (c.compare(in[med - 1], in[med]) <= 0) {        System.arraycopy(in, start, out, start, len);        return;    }    int r = med;    int i = start;        do {        long fromVal = in[start];        long rVal = in[r];        if (c.compare(fromVal, rVal) <= 0) {            int l_1 = find(in, rVal, -1, start + 1, med - 1, c);            int toCopy = l_1 - start + 1;            System.arraycopy(in, start, out, i, toCopy);            i += toCopy;            out[i++] = rVal;            r++;            start = l_1 + 1;        } else {            int r_1 = find(in, fromVal, 0, r + 1, end - 1, c);            int toCopy = r_1 - r + 1;            System.arraycopy(in, r, out, i, toCopy);            i += toCopy;            out[i++] = fromVal;            start++;            r = r_1 + 1;        }    } while ((end - r) > 0 && (med - start) > 0);        if ((end - r) <= 0) {        System.arraycopy(in, start, out, i, med - start);    } else {        System.arraycopy(in, r, out, i, end - r);    }}
private static int mahout_f7068_0(long[] arr, long val, int bnd, int l, int r, LongComparator c)
{    int m = l;    int d = 1;    while (m <= r) {        if (c.compare(val, arr[m]) > bnd) {            l = m + 1;        } else {            r = m - 1;            break;        }        m += d;        d <<= 1;    }    while (l <= r) {        m = (l + r) >>> 1;        if (c.compare(val, arr[m]) > bnd) {            l = m + 1;        } else {            r = m - 1;        }    }    return l - 1;}
public int mahout_f7069_0(float o1, float o2)
{    return Float.compare(o1, o2);}
public static void mahout_f7070_0(float[] array, int start, int end)
{    mergeSort(array, start, end, NATURAL_FLOAT_COMPARISON);}
public static void mahout_f7071_0(float[] array, int start, int end, FloatComparator comp)
{    checkBounds(array.length, start, end);    float[] out = Arrays.copyOf(array, array.length);    mergeSort(out, array, start, end, comp);}
private static void mahout_f7072_0(float[] in, float[] out, int start, int end, FloatComparator c)
{    int len = end - start;        if (len <= SIMPLE_LENGTH) {        for (int i = start + 1; i < end; i++) {            float current = out[i];            float prev = out[i - 1];            if (c.compare(prev, current) > 0) {                int j = i;                do {                    out[j--] = prev;                } while (j > start && (c.compare(prev = out[j - 1], current) > 0));                out[j] = current;            }        }        return;    }    int med = (end + start) >>> 1;    mergeSort(out, in, start, med, c);    mergeSort(out, in, med, end, c);        if (c.compare(in[med - 1], in[med]) <= 0) {        System.arraycopy(in, start, out, start, len);        return;    }    int r = med;    int i = start;        do {        float fromVal = in[start];        float rVal = in[r];        if (c.compare(fromVal, rVal) <= 0) {            int l_1 = find(in, rVal, -1, start + 1, med - 1, c);            int toCopy = l_1 - start + 1;            System.arraycopy(in, start, out, i, toCopy);            i += toCopy;            out[i++] = rVal;            r++;            start = l_1 + 1;        } else {            int r_1 = find(in, fromVal, 0, r + 1, end - 1, c);            int toCopy = r_1 - r + 1;            System.arraycopy(in, r, out, i, toCopy);            i += toCopy;            out[i++] = fromVal;            start++;            r = r_1 + 1;        }    } while ((end - r) > 0 && (med - start) > 0);        if ((end - r) <= 0) {        System.arraycopy(in, start, out, i, med - start);    } else {        System.arraycopy(in, r, out, i, end - r);    }}
private static int mahout_f7073_0(float[] arr, float val, int bnd, int l, int r, FloatComparator c)
{    int m = l;    int d = 1;    while (m <= r) {        if (c.compare(val, arr[m]) > bnd) {            l = m + 1;        } else {            r = m - 1;            break;        }        m += d;        d <<= 1;    }    while (l <= r) {        m = (l + r) >>> 1;        if (c.compare(val, arr[m]) > bnd) {            l = m + 1;        } else {            r = m - 1;        }    }    return l - 1;}
public int mahout_f7074_0(double o1, double o2)
{    return Double.compare(o1, o2);}
public static void mahout_f7075_0(double[] array, int start, int end)
{    mergeSort(array, start, end, NATURAL_DOUBLE_COMPARISON);}
public static void mahout_f7076_0(double[] array, int start, int end, DoubleComparator comp)
{    checkBounds(array.length, start, end);    double[] out = Arrays.copyOf(array, array.length);    mergeSort(out, array, start, end, comp);}
private static void mahout_f7077_0(double[] in, double[] out, int start, int end, DoubleComparator c)
{    int len = end - start;        if (len <= SIMPLE_LENGTH) {        for (int i = start + 1; i < end; i++) {            double current = out[i];            double prev = out[i - 1];            if (c.compare(prev, current) > 0) {                int j = i;                do {                    out[j--] = prev;                } while (j > start && (c.compare(prev = out[j - 1], current) > 0));                out[j] = current;            }        }        return;    }    int med = (end + start) >>> 1;    mergeSort(out, in, start, med, c);    mergeSort(out, in, med, end, c);        if (c.compare(in[med - 1], in[med]) <= 0) {        System.arraycopy(in, start, out, start, len);        return;    }    int r = med;    int i = start;        do {        double fromVal = in[start];        double rVal = in[r];        if (c.compare(fromVal, rVal) <= 0) {            int l_1 = find(in, rVal, -1, start + 1, med - 1, c);            int toCopy = l_1 - start + 1;            System.arraycopy(in, start, out, i, toCopy);            i += toCopy;            out[i++] = rVal;            r++;            start = l_1 + 1;        } else {            int r_1 = find(in, fromVal, 0, r + 1, end - 1, c);            int toCopy = r_1 - r + 1;            System.arraycopy(in, r, out, i, toCopy);            i += toCopy;            out[i++] = fromVal;            start++;            r = r_1 + 1;        }    } while ((end - r) > 0 && (med - start) > 0);        if ((end - r) <= 0) {        System.arraycopy(in, start, out, i, med - start);    } else {        System.arraycopy(in, r, out, i, end - r);    }}
private static int mahout_f7078_0(double[] arr, double val, int bnd, int l, int r, DoubleComparator c)
{    int m = l;    int d = 1;    while (m <= r) {        if (c.compare(val, arr[m]) > bnd) {            l = m + 1;        } else {            r = m - 1;            break;        }        m += d;        d <<= 1;    }    while (l <= r) {        m = (l + r) >>> 1;        if (c.compare(val, arr[m]) > bnd) {            l = m + 1;        } else {            r = m - 1;        }    }    return l - 1;}
 static void mahout_f7079_0(int first, int middle, int last, IntComparator comp, Swapper swapper)
{    if (first >= middle || middle >= last) {        return;    }    if (last - first == 2) {        if (comp.compare(middle, first) < 0) {            swapper.swap(first, middle);        }        return;    }    int firstCut;    int secondCut;    if (middle - first > last - middle) {        firstCut = first + (middle - first) / 2;        secondCut = lowerBound(middle, last, firstCut, comp);    } else {        secondCut = middle + (last - middle) / 2;        firstCut = upperBound(first, middle, secondCut, comp);    }                        int first2 = firstCut;    int middle2 = middle;    int last2 = secondCut;    if (middle2 != first2 && middle2 != last2) {        int first1 = first2;        int last1 = middle2;        while (first1 < --last1) {            swapper.swap(first1++, last1);        }        first1 = middle2;        last1 = last2;        while (first1 < --last1) {            swapper.swap(first1++, last1);        }        first1 = first2;        last1 = last2;        while (first1 < --last1) {            swapper.swap(first1++, last1);        }    }        middle = firstCut + (secondCut - middle);    inplaceMerge(first, firstCut, middle, comp, swapper);    inplaceMerge(middle, secondCut, last, comp, swapper);}
 static int mahout_f7080_0(int first, int last, int x, IntComparator comp)
{    int len = last - first;    while (len > 0) {        int half = len / 2;        int middle = first + half;        if (comp.compare(middle, x) < 0) {            first = middle + 1;            len -= half + 1;        } else {            len = half;        }    }    return first;}
public static void mahout_f7081_0(int fromIndex, int toIndex, IntComparator c, Swapper swapper)
{    /*      We retain the same method signature as quickSort.      Given only a comparator and swapper we do not know how to copy and move elements from/to temporary arrays.      Hence, in contrast to the JDK mergesorts this is an "in-place" mergesort, i.e. does not allocate any temporary      arrays.      A non-inplace mergesort would perhaps be faster in most cases, but would require non-intuitive delegate objects...    */    int length = toIndex - fromIndex;        if (length < SMALL) {        for (int i = fromIndex; i < toIndex; i++) {            for (int j = i; j > fromIndex && (c.compare(j - 1, j) > 0); j--) {                swapper.swap(j, j - 1);            }        }        return;    }        int mid = (fromIndex + toIndex) / 2;    mergeSort(fromIndex, mid, c, swapper);    mergeSort(mid, toIndex, c, swapper);        if (c.compare(mid - 1, mid) <= 0) {        return;    }        inplaceMerge(fromIndex, mid, toIndex, c, swapper);}
 static int mahout_f7082_0(int first, int last, int x, IntComparator comp)
{    int len = last - first;    while (len > 0) {        int half = len / 2;        int middle = first + half;        if (comp.compare(x, middle) < 0) {            len = half;        } else {            first = middle + 1;            len -= half + 1;        }    }    return first;}
public Matrix mahout_f7083_0()
{    SparseColumnMatrix clone = (SparseColumnMatrix) super.clone();    clone.columnVectors = new Vector[columnVectors.length];    for (int i = 0; i < columnVectors.length; i++) {        clone.columnVectors[i] = columnVectors[i].clone();    }    return clone;}
public int mahout_f7084_0()
{    return numCols();}
public double mahout_f7085_0(int row, int column)
{    return columnVectors[column] == null ? 0.0 : columnVectors[column].getQuick(row);}
public Matrix mahout_f7086_0()
{    return new SparseColumnMatrix(rowSize(), columnSize());}
public Matrix mahout_f7087_0(int rows, int columns)
{    return new SparseColumnMatrix(rows, columns);}
public void mahout_f7088_0(int row, int column, double value)
{    if (columnVectors[column] == null) {        columnVectors[column] = new RandomAccessSparseVector(rowSize());    }    columnVectors[column].setQuick(row, value);}
public int[] mahout_f7089_0()
{    int[] result = new int[2];    result[COL] = columnVectors.length;    for (int col = 0; col < columnSize(); col++) {        result[ROW] = Math.max(result[ROW], columnVectors[col].getNumNondefaultElements());    }    return result;}
public Matrix mahout_f7090_0(int[] offset, int[] size)
{    if (offset[ROW] < 0) {        throw new IndexException(offset[ROW], columnVectors[COL].size());    }    if (offset[ROW] + size[ROW] > columnVectors[COL].size()) {        throw new IndexException(offset[ROW] + size[ROW], columnVectors[COL].size());    }    if (offset[COL] < 0) {        throw new IndexException(offset[COL], columnVectors.length);    }    if (offset[COL] + size[COL] > columnVectors.length) {        throw new IndexException(offset[COL] + size[COL], columnVectors.length);    }    return new MatrixView(this, offset, size);}
public Matrix mahout_f7091_0(int column, Vector other)
{    if (rowSize() != other.size()) {        throw new CardinalityException(rowSize(), other.size());    }    if (column < 0 || column >= columnSize()) {        throw new IndexException(column, columnSize());    }    columnVectors[column].assign(other);    return this;}
public Matrix mahout_f7092_0(int row, Vector other)
{    if (columnSize() != other.size()) {        throw new CardinalityException(columnSize(), other.size());    }    if (row < 0 || row >= rowSize()) {        throw new IndexException(row, rowSize());    }    for (int col = 0; col < columnSize(); col++) {        columnVectors[col].setQuick(row, other.getQuick(col));    }    return this;}
public Vector mahout_f7093_0(int column)
{    if (column < 0 || column >= columnSize()) {        throw new IndexException(column, columnSize());    }    return columnVectors[column];}
public Matrix mahout_f7094_0()
{    SparseRowMatrix srm = new SparseRowMatrix(columns, rows);    for (int i = 0; i < columns; i++) {        Vector col = columnVectors[i];        if (col.getNumNonZeroElements() > 0)                        srm.assignRow(i, col);    }    return srm;}
public String mahout_f7095_0()
{    int row = 0;    int maxRowsToDisplay = 10;    int maxColsToDisplay = 20;    int colsToDisplay = maxColsToDisplay;    if (maxColsToDisplay > columnSize()) {        colsToDisplay = columnSize();    }    StringBuilder s = new StringBuilder("{\n");    for (MatrixSlice next : this.transpose()) {        if (row < maxRowsToDisplay) {            s.append(" ").append(next.index()).append(" =>\t").append(new VectorView(next.vector(), 0, colsToDisplay)).append('\n');            row++;        }    }    String returnString = s.toString();    if (maxColsToDisplay <= columnSize()) {        returnString = returnString.replace("}", " ... }");    }    if (maxRowsToDisplay <= rowSize()) {        return returnString + "... }";    } else {        return returnString + "}";    }}
public Matrix mahout_f7096_0()
{    SparseMatrix clone = new SparseMatrix(numRows(), numCols());    for (MatrixSlice slice : this) {        clone.rowVectors.put(slice.index(), slice.clone());    }    return clone;}
public int mahout_f7097_0()
{    return rowVectors.size();}
public Iterator<MatrixSlice> mahout_f7098_0()
{    final int[] keys = rowVectors.keySet().toIntArray();    return new AbstractIterator<MatrixSlice>() {        private int slice;        @Override        protected MatrixSlice computeNext() {            if (slice >= rowVectors.size()) {                return endOfData();            }            int i = keys[slice];            Vector row = rowVectors.get(i);            slice++;            return new MatrixSlice(row, i);        }    };}
protected MatrixSlice mahout_f7099_0()
{    if (slice >= rowVectors.size()) {        return endOfData();    }    int i = keys[slice];    Vector row = rowVectors.get(i);    slice++;    return new MatrixSlice(row, i);}
public double mahout_f7100_0(int row, int column)
{    Vector r = rowVectors.get(row);    return r == null ? 0.0 : r.getQuick(column);}
public Matrix mahout_f7101_0()
{    return new SparseMatrix(rowSize(), columnSize());}
public Matrix mahout_f7102_0(int rows, int columns)
{    return new SparseMatrix(rows, columns);}
public void mahout_f7103_0(int row, int column, double value)
{    Vector r = rowVectors.get(row);    if (r == null) {        r = new RandomAccessSparseVector(columnSize());        rowVectors.put(row, r);    }    r.setQuick(column, value);}
public int[] mahout_f7104_0()
{    int[] result = new int[2];    result[ROW] = rowVectors.size();    for (Vector row : rowVectors.values()) {        result[COL] = Math.max(result[COL], row.getNumNondefaultElements());    }    return result;}
public Matrix mahout_f7105_0(int[] offset, int[] size)
{    if (offset[ROW] < 0) {        throw new IndexException(offset[ROW], rowSize());    }    if (offset[ROW] + size[ROW] > rowSize()) {        throw new IndexException(offset[ROW] + size[ROW], rowSize());    }    if (offset[COL] < 0) {        throw new IndexException(offset[COL], columnSize());    }    if (offset[COL] + size[COL] > columnSize()) {        throw new IndexException(offset[COL] + size[COL], columnSize());    }    return new MatrixView(this, offset, size);}
public Matrix mahout_f7106_0(Matrix other, DoubleDoubleFunction function)
{        if (Functions.PLUS.equals(function) && other instanceof SparseMatrix) {        int rows = rowSize();        if (rows != other.rowSize()) {            throw new CardinalityException(rows, other.rowSize());        }        int columns = columnSize();        if (columns != other.columnSize()) {            throw new CardinalityException(columns, other.columnSize());        }        SparseMatrix otherSparse = (SparseMatrix) other;        for (ObjectIterator<Entry<Vector>> fastIterator = otherSparse.rowVectors.int2ObjectEntrySet().fastIterator(); fastIterator.hasNext(); ) {            final Entry<Vector> entry = fastIterator.next();            final int rowIndex = entry.getIntKey();            Vector row = rowVectors.get(rowIndex);            if (row == null) {                rowVectors.put(rowIndex, entry.getValue().clone());            } else {                row.assign(entry.getValue(), Functions.PLUS);            }        }        return this;    } else {        return super.assign(other, function);    }}
public Matrix mahout_f7107_0(int column, Vector other)
{    if (rowSize() != other.size()) {        throw new CardinalityException(rowSize(), other.size());    }    if (column < 0 || column >= columnSize()) {        throw new IndexException(column, columnSize());    }    for (int row = 0; row < rowSize(); row++) {        double val = other.getQuick(row);        if (val != 0.0) {            Vector r = rowVectors.get(row);            if (r == null) {                r = new RandomAccessSparseVector(columnSize());                rowVectors.put(row, r);            }            r.setQuick(column, val);        }    }    return this;}
public Matrix mahout_f7108_0(int row, Vector other)
{    if (columnSize() != other.size()) {        throw new CardinalityException(columnSize(), other.size());    }    if (row < 0 || row >= rowSize()) {        throw new IndexException(row, rowSize());    }    rowVectors.put(row, other);    return this;}
public Vector mahout_f7109_0(int row)
{    if (row < 0 || row >= rowSize()) {        throw new IndexException(row, rowSize());    }    Vector res = rowVectors.get(row);    if (res == null) {        res = new RandomAccessSparseVector(columnSize());        rowVectors.put(row, res);    }    return res;}
public IntArrayList mahout_f7110_0()
{    return new IntArrayList(rowVectors.keySet().toIntArray());}
public MatrixFlavor mahout_f7111_0()
{    return MatrixFlavor.SPARSEROWLIKE;}
public Matrix mahout_f7112_0()
{    SparseRowMatrix clone = (SparseRowMatrix) super.clone();    clone.rowVectors = new Vector[rowVectors.length];    for (int i = 0; i < rowVectors.length; i++) {        clone.rowVectors[i] = rowVectors[i].clone();    }    return clone;}
public double mahout_f7113_0(int row, int column)
{    return rowVectors[row] == null ? 0.0 : rowVectors[row].getQuick(column);}
public Matrix mahout_f7114_0()
{    return new SparseRowMatrix(rowSize(), columnSize(), randomAccessRows);}
public Matrix mahout_f7115_0(int rows, int columns)
{    return new SparseRowMatrix(rows, columns, randomAccessRows);}
public void mahout_f7116_0(int row, int column, double value)
{    rowVectors[row].setQuick(column, value);}
public int[] mahout_f7117_0()
{    int[] result = new int[2];    result[ROW] = rowVectors.length;    for (int row = 0; row < rowSize(); row++) {        result[COL] = Math.max(result[COL], rowVectors[row].getNumNondefaultElements());    }    return result;}
public Matrix mahout_f7118_0(int[] offset, int[] size)
{    if (offset[ROW] < 0) {        throw new IndexException(offset[ROW], rowVectors.length);    }    if (offset[ROW] + size[ROW] > rowVectors.length) {        throw new IndexException(offset[ROW] + size[ROW], rowVectors.length);    }    if (offset[COL] < 0) {        throw new IndexException(offset[COL], rowVectors[ROW].size());    }    if (offset[COL] + size[COL] > rowVectors[ROW].size()) {        throw new IndexException(offset[COL] + size[COL], rowVectors[ROW].size());    }    return new MatrixView(this, offset, size);}
public Matrix mahout_f7119_1(Matrix other, DoubleDoubleFunction function)
{    int rows = rowSize();    if (rows != other.rowSize()) {        throw new CardinalityException(rows, other.rowSize());    }    int columns = columnSize();    if (columns != other.columnSize()) {        throw new CardinalityException(columns, other.columnSize());    }    for (int row = 0; row < rows; row++) {        try {            Iterator<Vector.Element> sparseRowIterator = ((SequentialAccessSparseVector) this.rowVectors[row]).iterateNonZero();            if (function.isLikeMult()) {                                while (sparseRowIterator.hasNext()) {                    Vector.Element element = sparseRowIterator.next();                    int col = element.index();                    setQuick(row, col, function.apply(element.get(), other.getQuick(row, col)));                }            } else {                for (int col = 0; col < columns; col++) {                    setQuick(row, col, function.apply(getQuick(row, col), other.getQuick(row, col)));                }            }        } catch (ClassCastException e) {                                    for (int col = 0; col < columns; col++) {                setQuick(row, col, function.apply(getQuick(row, col), other.getQuick(row, col)));            }        }    }    return this;}
public Matrix mahout_f7120_0(int column, Vector other)
{    if (rowSize() != other.size()) {        throw new CardinalityException(rowSize(), other.size());    }    if (column < 0 || column >= columnSize()) {        throw new IndexException(column, columnSize());    }    for (int row = 0; row < rowSize(); row++) {        rowVectors[row].setQuick(column, other.getQuick(row));    }    return this;}
public Matrix mahout_f7121_0(int row, Vector other)
{    if (columnSize() != other.size()) {        throw new CardinalityException(columnSize(), other.size());    }    if (row < 0 || row >= rowSize()) {        throw new IndexException(row, rowSize());    }    rowVectors[row].assign(other);    return this;}
public Vector mahout_f7122_0(int row)
{    if (row < 0 || row >= rowSize()) {        throw new IndexException(row, rowSize());    }    return rowVectors[row];}
public Matrix mahout_f7123_0()
{    SparseColumnMatrix scm = new SparseColumnMatrix(columns, rows);    for (int i = 0; i < rows; i++) {        Vector row = rowVectors[i];        if (row.getNumNonZeroElements() > 0) {            scm.assignColumn(i, row);        }    }    return scm;}
public Matrix mahout_f7124_0(Matrix other)
{    if (columnSize() != other.rowSize()) {        throw new CardinalityException(columnSize(), other.rowSize());    }    if (other instanceof SparseRowMatrix) {        SparseRowMatrix y = (SparseRowMatrix) other;        SparseRowMatrix result = (SparseRowMatrix) like(rowSize(), other.columnSize());        for (int i = 0; i < rows; i++) {            Vector row = rowVectors[i];            for (Vector.Element element : row.nonZeroes()) {                result.rowVectors[i].assign(y.rowVectors[element.index()], Functions.plusMult(element.get()));            }        }        return result;    } else {        if (other.viewRow(0).isDense()) {                        Matrix result = other.like(rowSize(), other.columnSize());            for (int i = 0; i < rows; i++) {                Vector row = rowVectors[i];                Vector r = new DenseVector(other.columnSize());                for (Vector.Element element : row.nonZeroes()) {                    r.assign(other.viewRow(element.index()), Functions.plusMult(element.get()));                }                result.viewRow(i).assign(r);            }            return result;        } else {                        SparseRowMatrix result = (SparseRowMatrix) like(rowSize(), other.columnSize());            for (int i = 0; i < rows; i++) {                Vector row = rowVectors[i];                for (Vector.Element element : row.nonZeroes()) {                    result.rowVectors[i].assign(other.viewRow(element.index()), Functions.plusMult(element.get()));                }            }            return result;        }    }}
public MatrixFlavor mahout_f7125_0()
{    return MatrixFlavor.SPARSELIKE;}
public Vector mahout_f7126_0()
{    return new DenseVector(svd.getSingularValues());}
public Matrix mahout_f7127_0()
{        return cd1.solveRight(y).times(svd.getU());}
public Matrix mahout_f7128_0()
{        return cd2.solveRight(b.transpose()).times(svd.getV());}
public static double mahout_f7129_0(long... elements)
{    long sum = 0;    double result = 0.0;    for (long element : elements) {        Preconditions.checkArgument(element >= 0);        result += xLogX(element);        sum += element;    }    return xLogX(sum) - result;}
private static double mahout_f7130_0(long x)
{    return x == 0 ? 0.0 : x * Math.log(x);}
private static double mahout_f7131_0(long a, long b)
{    return xLogX(a + b) - xLogX(a) - xLogX(b);}
private static double mahout_f7132_0(long a, long b, long c, long d)
{    return xLogX(a + b + c + d) - xLogX(a) - xLogX(b) - xLogX(c) - xLogX(d);}
public static double mahout_f7133_0(long k11, long k12, long k21, long k22)
{    Preconditions.checkArgument(k11 >= 0 && k12 >= 0 && k21 >= 0 && k22 >= 0);        double rowEntropy = entropy(k11 + k12, k21 + k22);    double columnEntropy = entropy(k11 + k21, k12 + k22);    double matrixEntropy = entropy(k11, k12, k21, k22);    if (rowEntropy + columnEntropy < matrixEntropy) {                return 0.0;    }    return 2.0 * (rowEntropy + columnEntropy - matrixEntropy);}
public static double mahout_f7134_0(long k11, long k12, long k21, long k22)
{    double llr = logLikelihoodRatio(k11, k12, k21, k22);    double sqrt = Math.sqrt(llr);    if ((double) k11 / (k11 + k12) < (double) k21 / (k21 + k22)) {        sqrt = -sqrt;    }    return sqrt;}
public static List<ScoredItem<T>> mahout_f7135_0(Multiset<T> a, Multiset<T> b, int maxReturn, double threshold)
{    int totalA = a.size();    int totalB = b.size();    Ordering<ScoredItem<T>> byScoreAscending = new Ordering<ScoredItem<T>>() {        @Override        public int compare(ScoredItem<T> tScoredItem, ScoredItem<T> tScoredItem1) {            return Double.compare(tScoredItem.score, tScoredItem1.score);        }    };    Queue<ScoredItem<T>> best = new PriorityQueue<>(maxReturn + 1, byScoreAscending);    for (T t : a.elementSet()) {        compareAndAdd(a, b, maxReturn, threshold, totalA, totalB, best, t);    }        if (threshold < 0) {        for (T t : b.elementSet()) {                        if (a.count(t) == 0) {                compareAndAdd(a, b, maxReturn, threshold, totalA, totalB, best, t);            }        }    }    List<ScoredItem<T>> r = new ArrayList<>(best);    Collections.sort(r, byScoreAscending.reverse());    return r;}
public int mahout_f7136_0(ScoredItem<T> tScoredItem, ScoredItem<T> tScoredItem1)
{    return Double.compare(tScoredItem.score, tScoredItem1.score);}
private static void mahout_f7137_0(Multiset<T> a, Multiset<T> b, int maxReturn, double threshold, int totalA, int totalB, Queue<ScoredItem<T>> best, T t)
{    int kA = a.count(t);    int kB = b.count(t);    double score = rootLogLikelihoodRatio(kA, totalA - kA, kB, totalB - kB);    if (score >= threshold) {        ScoredItem<T> x = new ScoredItem<>(t, score);        best.add(x);        while (best.size() > maxReturn) {            best.poll();        }    }}
public double mahout_f7138_0()
{    return score;}
public T mahout_f7139_0()
{    return item;}
public void mahout_f7140_0(double t, double x)
{    double pi = Math.exp(-(t - lastT) / alpha);    s = x + pi * s;    w = 1.0 + pi * w;    this.t = t - lastT + pi * this.t;    lastT = t;}
public double mahout_f7141_0()
{    return s / w;}
public double mahout_f7142_0()
{    return s / t;}
public void mahout_f7143_0(double sample)
{    n++;    double oldMean = mean;    mean += (sample - mean) / n;    double diff = (sample - mean) * (sample - oldMean);    variance += (diff - variance) / n;}
public int mahout_f7144_0()
{    return n;}
public double mahout_f7145_0()
{    return mean;}
public double mahout_f7146_0()
{    return Math.sqrt(variance);}
public Matrix mahout_f7147_0(int column, Vector other)
{    m.assignRow(column, other);    return this;}
public Matrix mahout_f7148_0(int row, Vector other)
{    m.assignColumn(row, other);    return this;}
public double mahout_f7149_0(int row, int column)
{    return m.getQuick(column, row);}
public Matrix mahout_f7150_0()
{    return m.like(rows, columns);}
public Matrix mahout_f7151_0(int rows, int columns)
{    return m.like(rows, columns);}
public void mahout_f7152_0(int row, int column, double value)
{    m.setQuick(column, row, value);}
public Vector mahout_f7153_0(int row)
{    return m.viewColumn(row);}
public Vector mahout_f7154_0(int column)
{    return m.viewRow(column);}
public Matrix mahout_f7155_0(double value)
{    return m.assign(value);}
public Matrix mahout_f7156_0(Matrix other, DoubleDoubleFunction function)
{    if (other instanceof TransposedMatrixView) {        m.assign(((TransposedMatrixView) other).m, function);    } else {        m.assign(new TransposedMatrixView(other), function);    }    return this;}
public Matrix mahout_f7157_0(Matrix other)
{    if (other instanceof TransposedMatrixView) {        return m.assign(((TransposedMatrixView) other).m);    } else {        return m.assign(new TransposedMatrixView(other));    }}
public Matrix mahout_f7158_0(DoubleFunction function)
{    return m.assign(function);}
public MatrixFlavor mahout_f7159_0()
{    return flavor;}
public BackEnum mahout_f7160_0()
{    return m.getFlavor().getBacking();}
public TraversingStructureEnum mahout_f7161_0()
{    TraversingStructureEnum flavor = m.getFlavor().getStructure();    switch(flavor) {        case COLWISE:            return TraversingStructureEnum.ROWWISE;        case SPARSECOLWISE:            return TraversingStructureEnum.SPARSEROWWISE;        case ROWWISE:            return TraversingStructureEnum.COLWISE;        case SPARSEROWWISE:            return TraversingStructureEnum.SPARSECOLWISE;        default:            return flavor;    }}
public boolean mahout_f7162_0()
{    return m.getFlavor().isDense();}
 Matrix mahout_f7163_0()
{    return m;}
private static int mahout_f7164_0(int dataSize)
{    return (int) Math.round((-1 + Math.sqrt(1 + 8 * dataSize)) / 2);}
public Matrix mahout_f7165_0(int column, Vector other)
{    if (columnSize() != other.size()) {        throw new IndexException(columnSize(), other.size());    }    if (other.viewPart(column + 1, other.size() - column - 1).norm(1) > 1.0e-14) {        throw new IllegalArgumentException("Cannot set lower portion of triangular matrix to non-zero");    }    for (Vector.Element element : other.viewPart(0, column).all()) {        setQuick(element.index(), column, element.get());    }    return this;}
public Matrix mahout_f7166_0(int row, Vector other)
{    if (columnSize() != other.size()) {        throw new IndexException(numCols(), other.size());    }    for (int i = 0; i < row; i++) {        if (Math.abs(other.getQuick(i)) > EPSILON) {            throw new IllegalArgumentException("non-triangular source");        }    }    for (int i = row; i < rows; i++) {        setQuick(row, i, other.get(i));    }    return this;}
public Matrix mahout_f7167_0(int row, double[] other)
{    System.arraycopy(other, row, values, getL(row, row), rows - row);    return this;}
public double mahout_f7168_0(int row, int column)
{    if (row > column) {        return 0;    }    int i = getL(row, column);    return values[i];}
private int mahout_f7169_0(int row, int col)
{    /*     * each row starts with some zero elements that we don't store. this     * accumulates an offset of (row+1)*row/2     */    return col + row * numCols() - (row + 1) * row / 2;}
public Matrix mahout_f7170_0()
{    return like(rowSize(), columnSize());}
public Matrix mahout_f7171_0(int rows, int columns)
{    return new DenseMatrix(rows, columns);}
public void mahout_f7172_0(int row, int column, double value)
{    values[getL(row, column)] = value;}
public int[] mahout_f7173_0()
{    throw new UnsupportedOperationException();}
public Matrix mahout_f7174_0(int[] offset, int[] size)
{    return new MatrixView(this, offset, size);}
public double[] mahout_f7175_0()
{    return values;}
public MatrixFlavor mahout_f7176_0()
{        return new MatrixFlavor.FlavorImpl(BackEnum.JVMMEM, TraversingStructureEnum.VECTORBACKED, true);}
public static VectorBinaryAggregate mahout_f7177_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    int bestOperationIndex = -1;    double bestCost = Double.POSITIVE_INFINITY;    for (int i = 0; i < OPERATIONS.length; ++i) {        if (OPERATIONS[i].isValid(x, y, fa, fc)) {            double cost = OPERATIONS[i].estimateCost(x, y, fa, fc);            if (cost < bestCost) {                bestCost = cost;                bestOperationIndex = i;            }        }    }    return OPERATIONS[bestOperationIndex];}
public static double mahout_f7178_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    return getBestOperation(x, y, fa, fc).aggregate(x, y, fa, fc);}
public boolean mahout_f7179_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    return fa.isLikeRightPlus() && (fa.isAssociativeAndCommutative() || x.isSequentialAccess()) && fc.isLikeLeftMult();}
public double mahout_f7180_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    return x.getNumNondefaultElements() * x.getIteratorAdvanceCost() * y.getLookupCost();}
public double mahout_f7181_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    Iterator<Vector.Element> xi = x.nonZeroes().iterator();    if (!xi.hasNext()) {        return 0;    }    Vector.Element xe = xi.next();    double result = fc.apply(xe.get(), y.getQuick(xe.index()));    while (xi.hasNext()) {        xe = xi.next();        result = fa.apply(result, fc.apply(xe.get(), y.getQuick(xe.index())));    }    return result;}
public boolean mahout_f7182_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    return fa.isLikeRightPlus() && (fa.isAssociativeAndCommutative() || y.isSequentialAccess()) && fc.isLikeRightMult();}
public double mahout_f7183_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    return y.getNumNondefaultElements() * y.getIteratorAdvanceCost() * x.getLookupCost() * x.getLookupCost();}
public double mahout_f7184_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    Iterator<Vector.Element> yi = y.nonZeroes().iterator();    if (!yi.hasNext()) {        return 0;    }    Vector.Element ye = yi.next();    double result = fc.apply(x.getQuick(ye.index()), ye.get());    while (yi.hasNext()) {        ye = yi.next();        result = fa.apply(result, fc.apply(x.getQuick(ye.index()), ye.get()));    }    return result;}
public boolean mahout_f7185_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    return fa.isLikeRightPlus() && fc.isLikeMult() && x.isSequentialAccess() && y.isSequentialAccess();}
public double mahout_f7186_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    return Math.min(x.getNumNondefaultElements() * x.getIteratorAdvanceCost(), y.getNumNondefaultElements() * y.getIteratorAdvanceCost());}
public double mahout_f7187_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    Iterator<Vector.Element> xi = x.nonZeroes().iterator();    Iterator<Vector.Element> yi = y.nonZeroes().iterator();    Vector.Element xe = null;    Vector.Element ye = null;    boolean advanceThis = true;    boolean advanceThat = true;    boolean validResult = false;    double result = 0;    while (true) {        if (advanceThis) {            if (xi.hasNext()) {                xe = xi.next();            } else {                break;            }        }        if (advanceThat) {            if (yi.hasNext()) {                ye = yi.next();            } else {                break;            }        }        if (xe.index() == ye.index()) {            double thisResult = fc.apply(xe.get(), ye.get());            if (validResult) {                result = fa.apply(result, thisResult);            } else {                result = thisResult;                validResult = true;            }            advanceThis = true;            advanceThat = true;        } else {            if (xe.index() < ye.index()) {                                advanceThis = true;                advanceThat = false;            } else {                                advanceThis = false;                advanceThat = true;            }        }    }    return result;}
public boolean mahout_f7188_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    return fa.isLikeRightPlus() && !fc.isDensifying() && x.isSequentialAccess() && y.isSequentialAccess();}
public double mahout_f7189_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    return Math.max(x.getNumNondefaultElements() * x.getIteratorAdvanceCost(), y.getNumNondefaultElements() * y.getIteratorAdvanceCost());}
public double mahout_f7190_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    Iterator<Vector.Element> xi = x.nonZeroes().iterator();    Iterator<Vector.Element> yi = y.nonZeroes().iterator();    Vector.Element xe = null;    Vector.Element ye = null;    boolean advanceThis = true;    boolean advanceThat = true;    boolean validResult = false;    double result = 0;    while (true) {        if (advanceThis) {            if (xi.hasNext()) {                xe = xi.next();            } else {                xe = null;            }        }        if (advanceThat) {            if (yi.hasNext()) {                ye = yi.next();            } else {                ye = null;            }        }        double thisResult;        if (xe != null && ye != null) {                        if (xe.index() == ye.index()) {                thisResult = fc.apply(xe.get(), ye.get());                advanceThis = true;                advanceThat = true;            } else {                if (xe.index() < ye.index()) {                                        thisResult = fc.apply(xe.get(), 0);                    advanceThis = true;                    advanceThat = false;                } else {                    thisResult = fc.apply(0, ye.get());                    advanceThis = false;                    advanceThat = true;                }            }        } else if (xe != null) {                        thisResult = fc.apply(xe.get(), 0);            advanceThis = true;            advanceThat = false;        } else if (ye != null) {                        thisResult = fc.apply(0, ye.get());            advanceThis = false;            advanceThat = true;        } else {                        break;        }        if (validResult) {            result = fa.apply(result, thisResult);        } else {            result = thisResult;            validResult = true;        }    }    return result;}
public boolean mahout_f7191_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    return fa.isLikeRightPlus() && !fc.isDensifying() && (fa.isAssociativeAndCommutative() || (x.isSequentialAccess() && y.isSequentialAccess()));}
public double mahout_f7192_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    return Math.max(x.getNumNondefaultElements() * x.getIteratorAdvanceCost() * y.getLookupCost(), y.getNumNondefaultElements() * y.getIteratorAdvanceCost() * x.getLookupCost());}
public double mahout_f7193_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    OpenIntHashSet visited = new OpenIntHashSet();    Iterator<Vector.Element> xi = x.nonZeroes().iterator();    boolean validResult = false;    double result = 0;    double thisResult;    while (xi.hasNext()) {        Vector.Element xe = xi.next();        thisResult = fc.apply(xe.get(), y.getQuick(xe.index()));        if (validResult) {            result = fa.apply(result, thisResult);        } else {            result = thisResult;            validResult = true;        }        visited.add(xe.index());    }    Iterator<Vector.Element> yi = y.nonZeroes().iterator();    while (yi.hasNext()) {        Vector.Element ye = yi.next();        if (!visited.contains(ye.index())) {            thisResult = fc.apply(x.getQuick(ye.index()), ye.get());            if (validResult) {                result = fa.apply(result, thisResult);            } else {                result = thisResult;                validResult = true;            }        }    }    return result;}
public boolean mahout_f7194_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    return x.isSequentialAccess() && y.isSequentialAccess() && !x.isDense() && !y.isDense();}
public double mahout_f7195_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    return Math.max(x.size() * x.getIteratorAdvanceCost(), y.size() * y.getIteratorAdvanceCost());}
public double mahout_f7196_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    Iterator<Vector.Element> xi = x.all().iterator();    Iterator<Vector.Element> yi = y.all().iterator();    boolean validResult = false;    double result = 0;    while (xi.hasNext() && yi.hasNext()) {        Vector.Element xe = xi.next();        double thisResult = fc.apply(xe.get(), yi.next().get());        if (validResult) {            result = fa.apply(result, thisResult);        } else {            result = thisResult;            validResult = true;        }    }    return result;}
public boolean mahout_f7197_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    return (fa.isAssociativeAndCommutative() || x.isSequentialAccess()) && !x.isDense();}
public double mahout_f7198_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    return x.size() * x.getIteratorAdvanceCost() * y.getLookupCost();}
public double mahout_f7199_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    Iterator<Vector.Element> xi = x.all().iterator();    boolean validResult = false;    double result = 0;    while (xi.hasNext()) {        Vector.Element xe = xi.next();        double thisResult = fc.apply(xe.get(), y.getQuick(xe.index()));        if (validResult) {            result = fa.apply(result, thisResult);        } else {            result = thisResult;            validResult = true;        }    }    return result;}
public boolean mahout_f7200_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    return (fa.isAssociativeAndCommutative() || y.isSequentialAccess()) && !y.isDense();}
public double mahout_f7201_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    return y.size() * y.getIteratorAdvanceCost() * x.getLookupCost();}
public double mahout_f7202_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    Iterator<Vector.Element> yi = y.all().iterator();    boolean validResult = false;    double result = 0;    while (yi.hasNext()) {        Vector.Element ye = yi.next();        double thisResult = fc.apply(x.getQuick(ye.index()), ye.get());        if (validResult) {            result = fa.apply(result, thisResult);        } else {            result = thisResult;            validResult = true;        }    }    return result;}
public boolean mahout_f7203_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    return true;}
public double mahout_f7204_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    return x.size() * x.getLookupCost() * y.getLookupCost();}
public double mahout_f7205_0(Vector x, Vector y, DoubleDoubleFunction fa, DoubleDoubleFunction fc)
{    double result = fc.apply(x.getQuick(0), y.getQuick(0));    int s = x.size();    for (int i = 1; i < s; ++i) {        result = fa.apply(result, fc.apply(x.getQuick(i), y.getQuick(i)));    }    return result;}
public static VectorBinaryAssign mahout_f7206_0(Vector x, Vector y, DoubleDoubleFunction f)
{    int bestOperationIndex = -1;    double bestCost = Double.POSITIVE_INFINITY;    for (int i = 0; i < OPERATIONS.length; ++i) {        if (OPERATIONS[i].isValid(x, y, f)) {            double cost = OPERATIONS[i].estimateCost(x, y, f);            if (cost < bestCost) {                bestCost = cost;                bestOperationIndex = i;            }        }    }    return OPERATIONS[bestOperationIndex];}
public static Vector mahout_f7207_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return getBestOperation(x, y, f).assign(x, y, f);}
public boolean mahout_f7208_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return f.isLikeLeftMult();}
public double mahout_f7209_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return x.getNumNondefaultElements() * x.getIteratorAdvanceCost() * y.getLookupCost();}
public Vector mahout_f7210_0(Vector x, Vector y, DoubleDoubleFunction f)
{    for (Element xe : x.nonZeroes()) {        xe.set(f.apply(xe.get(), y.getQuick(xe.index())));    }    return x;}
public boolean mahout_f7211_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return f.isLikeRightPlus();}
public double mahout_f7212_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return y.getNumNondefaultElements() * y.getIteratorAdvanceCost() * x.getLookupCost() * x.getLookupCost();}
public Vector mahout_f7213_0(Vector x, Vector y, DoubleDoubleFunction f)
{    for (Element ye : y.nonZeroes()) {        x.setQuick(ye.index(), f.apply(x.getQuick(ye.index()), ye.get()));    }    return x;}
public boolean mahout_f7214_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return f.isLikeRightPlus() && y.isSequentialAccess() && !x.isAddConstantTime();}
public double mahout_f7215_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return y.getNumNondefaultElements() * y.getIteratorAdvanceCost() * y.getLookupCost();}
public Vector mahout_f7216_0(Vector x, Vector y, DoubleDoubleFunction f)
{    OrderedIntDoubleMapping updates = new OrderedIntDoubleMapping(false);    for (Element ye : y.nonZeroes()) {        updates.set(ye.index(), f.apply(x.getQuick(ye.index()), ye.get()));    }    x.mergeUpdates(updates);    return x;}
public boolean mahout_f7217_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return f.isLikeLeftMult() && f.isLikeRightPlus() && x.isSequentialAccess() && y.isSequentialAccess();}
public double mahout_f7218_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return Math.min(x.getNumNondefaultElements() * x.getIteratorAdvanceCost(), y.getNumNondefaultElements() * y.getIteratorAdvanceCost());}
public Vector mahout_f7219_0(Vector x, Vector y, DoubleDoubleFunction f)
{    Iterator<Vector.Element> xi = x.nonZeroes().iterator();    Iterator<Vector.Element> yi = y.nonZeroes().iterator();    Vector.Element xe = null;    Vector.Element ye = null;    boolean advanceThis = true;    boolean advanceThat = true;    while (true) {        if (advanceThis) {            if (xi.hasNext()) {                xe = xi.next();            } else {                break;            }        }        if (advanceThat) {            if (yi.hasNext()) {                ye = yi.next();            } else {                break;            }        }        if (xe.index() == ye.index()) {            xe.set(f.apply(xe.get(), ye.get()));            advanceThis = true;            advanceThat = true;        } else {            if (xe.index() < ye.index()) {                                advanceThis = true;                advanceThat = false;            } else {                                advanceThis = false;                advanceThat = true;            }        }    }    return x;}
public boolean mahout_f7220_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return !f.isDensifying() && x.isSequentialAccess() && y.isSequentialAccess() && !x.isAddConstantTime();}
public double mahout_f7221_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return Math.max(x.getNumNondefaultElements() * x.getIteratorAdvanceCost(), y.getNumNondefaultElements() * y.getIteratorAdvanceCost());}
public Vector mahout_f7222_0(Vector x, Vector y, DoubleDoubleFunction f)
{    Iterator<Vector.Element> xi = x.nonZeroes().iterator();    Iterator<Vector.Element> yi = y.nonZeroes().iterator();    Vector.Element xe = null;    Vector.Element ye = null;    boolean advanceThis = true;    boolean advanceThat = true;    OrderedIntDoubleMapping updates = new OrderedIntDoubleMapping(false);    while (true) {        if (advanceThis) {            if (xi.hasNext()) {                xe = xi.next();            } else {                xe = null;            }        }        if (advanceThat) {            if (yi.hasNext()) {                ye = yi.next();            } else {                ye = null;            }        }        if (xe != null && ye != null) {                        if (xe.index() == ye.index()) {                xe.set(f.apply(xe.get(), ye.get()));                advanceThis = true;                advanceThat = true;            } else {                if (xe.index() < ye.index()) {                                        xe.set(f.apply(xe.get(), 0));                    advanceThis = true;                    advanceThat = false;                } else {                    updates.set(ye.index(), f.apply(0, ye.get()));                    advanceThis = false;                    advanceThat = true;                }            }        } else if (xe != null) {                        xe.set(f.apply(xe.get(), 0));            advanceThis = true;            advanceThat = false;        } else if (ye != null) {                        updates.set(ye.index(), f.apply(0, ye.get()));            advanceThis = false;            advanceThat = true;        } else {                        break;        }    }    x.mergeUpdates(updates);    return x;}
public boolean mahout_f7223_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return !f.isDensifying() && x.isSequentialAccess() && y.isSequentialAccess() && x.isAddConstantTime();}
public double mahout_f7224_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return Math.max(x.getNumNondefaultElements() * x.getIteratorAdvanceCost(), y.getNumNondefaultElements() * y.getIteratorAdvanceCost());}
public Vector mahout_f7225_0(Vector x, Vector y, DoubleDoubleFunction f)
{    Iterator<Vector.Element> xi = x.nonZeroes().iterator();    Iterator<Vector.Element> yi = y.nonZeroes().iterator();    Vector.Element xe = null;    Vector.Element ye = null;    boolean advanceThis = true;    boolean advanceThat = true;    while (true) {        if (advanceThis) {            if (xi.hasNext()) {                xe = xi.next();            } else {                xe = null;            }        }        if (advanceThat) {            if (yi.hasNext()) {                ye = yi.next();            } else {                ye = null;            }        }        if (xe != null && ye != null) {                        if (xe.index() == ye.index()) {                xe.set(f.apply(xe.get(), ye.get()));                advanceThis = true;                advanceThat = true;            } else {                if (xe.index() < ye.index()) {                                        xe.set(f.apply(xe.get(), 0));                    advanceThis = true;                    advanceThat = false;                } else {                    x.setQuick(ye.index(), f.apply(0, ye.get()));                    advanceThis = false;                    advanceThat = true;                }            }        } else if (xe != null) {                        xe.set(f.apply(xe.get(), 0));            advanceThis = true;            advanceThat = false;        } else if (ye != null) {                        x.setQuick(ye.index(), f.apply(0, ye.get()));            advanceThis = false;            advanceThat = true;        } else {                        break;        }    }    return x;}
public boolean mahout_f7226_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return !f.isDensifying() && !x.isAddConstantTime() && y.isSequentialAccess();}
public double mahout_f7227_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return Math.max(x.getNumNondefaultElements() * x.getIteratorAdvanceCost() * y.getLookupCost(), y.getNumNondefaultElements() * y.getIteratorAdvanceCost() * x.getLookupCost());}
public Vector mahout_f7228_0(Vector x, Vector y, DoubleDoubleFunction f)
{    OpenIntHashSet visited = new OpenIntHashSet();    for (Element xe : x.nonZeroes()) {        xe.set(f.apply(xe.get(), y.getQuick(xe.index())));        visited.add(xe.index());    }    OrderedIntDoubleMapping updates = new OrderedIntDoubleMapping(false);    for (Element ye : y.nonZeroes()) {        if (!visited.contains(ye.index())) {            updates.set(ye.index(), f.apply(x.getQuick(ye.index()), ye.get()));        }    }    x.mergeUpdates(updates);    return x;}
public boolean mahout_f7229_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return !f.isDensifying() && x.isAddConstantTime();}
public double mahout_f7230_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return Math.max(x.getNumNondefaultElements() * x.getIteratorAdvanceCost() * y.getLookupCost(), y.getNumNondefaultElements() * y.getIteratorAdvanceCost() * x.getLookupCost());}
public Vector mahout_f7231_0(Vector x, Vector y, DoubleDoubleFunction f)
{    OpenIntHashSet visited = new OpenIntHashSet();    for (Element xe : x.nonZeroes()) {        xe.set(f.apply(xe.get(), y.getQuick(xe.index())));        visited.add(xe.index());    }    for (Element ye : y.nonZeroes()) {        if (!visited.contains(ye.index())) {            x.setQuick(ye.index(), f.apply(x.getQuick(ye.index()), ye.get()));        }    }    return x;}
public boolean mahout_f7232_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return x.isSequentialAccess() && y.isSequentialAccess() && !x.isAddConstantTime() && !x.isDense() && !y.isDense();}
public double mahout_f7233_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return Math.max(x.size() * x.getIteratorAdvanceCost(), y.size() * y.getIteratorAdvanceCost());}
public Vector mahout_f7234_0(Vector x, Vector y, DoubleDoubleFunction f)
{    Iterator<Vector.Element> xi = x.all().iterator();    Iterator<Vector.Element> yi = y.all().iterator();    OrderedIntDoubleMapping updates = new OrderedIntDoubleMapping(false);    while (xi.hasNext() && yi.hasNext()) {        Element xe = xi.next();        updates.set(xe.index(), f.apply(xe.get(), yi.next().get()));    }    x.mergeUpdates(updates);    return x;}
public boolean mahout_f7235_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return x.isSequentialAccess() && y.isSequentialAccess() && x.isAddConstantTime() && !x.isDense() && !y.isDense();}
public double mahout_f7236_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return Math.max(x.size() * x.getIteratorAdvanceCost(), y.size() * y.getIteratorAdvanceCost());}
public Vector mahout_f7237_0(Vector x, Vector y, DoubleDoubleFunction f)
{    Iterator<Vector.Element> xi = x.all().iterator();    Iterator<Vector.Element> yi = y.all().iterator();    while (xi.hasNext() && yi.hasNext()) {        Element xe = xi.next();        x.setQuick(xe.index(), f.apply(xe.get(), yi.next().get()));    }    return x;}
public boolean mahout_f7238_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return !x.isAddConstantTime() && !x.isDense();}
public double mahout_f7239_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return x.size() * x.getIteratorAdvanceCost() * y.getLookupCost();}
public Vector mahout_f7240_0(Vector x, Vector y, DoubleDoubleFunction f)
{    OrderedIntDoubleMapping updates = new OrderedIntDoubleMapping(false);    for (Element xe : x.all()) {        updates.set(xe.index(), f.apply(xe.get(), y.getQuick(xe.index())));    }    x.mergeUpdates(updates);    return x;}
public boolean mahout_f7241_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return x.isAddConstantTime() && !x.isDense();}
public double mahout_f7242_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return x.size() * x.getIteratorAdvanceCost() * y.getLookupCost();}
public Vector mahout_f7243_0(Vector x, Vector y, DoubleDoubleFunction f)
{    for (Element xe : x.all()) {        x.setQuick(xe.index(), f.apply(xe.get(), y.getQuick(xe.index())));    }    return x;}
public boolean mahout_f7244_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return !x.isAddConstantTime() && !y.isDense();}
public double mahout_f7245_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return y.size() * y.getIteratorAdvanceCost() * x.getLookupCost();}
public Vector mahout_f7246_0(Vector x, Vector y, DoubleDoubleFunction f)
{    OrderedIntDoubleMapping updates = new OrderedIntDoubleMapping(false);    for (Element ye : y.all()) {        updates.set(ye.index(), f.apply(x.getQuick(ye.index()), ye.get()));    }    x.mergeUpdates(updates);    return x;}
public boolean mahout_f7247_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return x.isAddConstantTime() && !y.isDense();}
public double mahout_f7248_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return y.size() * y.getIteratorAdvanceCost() * x.getLookupCost();}
public Vector mahout_f7249_0(Vector x, Vector y, DoubleDoubleFunction f)
{    for (Element ye : y.all()) {        x.setQuick(ye.index(), f.apply(x.getQuick(ye.index()), ye.get()));    }    return x;}
public boolean mahout_f7250_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return !x.isAddConstantTime();}
public double mahout_f7251_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return x.size() * x.getLookupCost() * y.getLookupCost();}
public Vector mahout_f7252_0(Vector x, Vector y, DoubleDoubleFunction f)
{    OrderedIntDoubleMapping updates = new OrderedIntDoubleMapping(false);    for (int i = 0; i < x.size(); ++i) {        updates.set(i, f.apply(x.getQuick(i), y.getQuick(i)));    }    x.mergeUpdates(updates);    return x;}
public boolean mahout_f7253_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return x.isAddConstantTime();}
public double mahout_f7254_0(Vector x, Vector y, DoubleDoubleFunction f)
{    return x.size() * x.getLookupCost() * y.getLookupCost();}
public Vector mahout_f7255_0(Vector x, Vector y, DoubleDoubleFunction f)
{    for (int i = 0; i < x.size(); ++i) {        x.setQuick(i, f.apply(x.getQuick(i), y.getQuick(i)));    }    return x;}
protected Matrix mahout_f7256_0(int rows, int columns)
{    return ((AbstractVector) vector).matrixLike(rows, columns);}
public Vector mahout_f7257_0()
{    VectorView r = (VectorView) super.clone();    r.vector = vector.clone();    r.offset = offset;    return r;}
public boolean mahout_f7258_0()
{    return vector.isDense();}
public boolean mahout_f7259_0()
{    return vector.isSequentialAccess();}
public VectorView mahout_f7260_0()
{    return new VectorView(vector.like(), offset, size());}
public Vector mahout_f7261_0(int cardinality)
{    return vector.like(cardinality);}
public double mahout_f7262_0(int index)
{    return vector.getQuick(offset + index);}
public void mahout_f7263_0(int index, double value)
{    vector.setQuick(offset + index, value);}
public int mahout_f7264_0()
{    return size();}
public Vector mahout_f7265_0(int offset, int length)
{    if (offset < 0) {        throw new IndexException(offset, size());    }    if (offset + length > size()) {        throw new IndexException(offset + length, size());    }    return new VectorView(vector, offset + this.offset, length);}
private boolean mahout_f7266_0(int index)
{    return index >= offset && index < offset + size();}
public Iterator<Element> mahout_f7267_0()
{    return new NonZeroIterator();}
public Iterator<Element> mahout_f7268_0()
{    return new AllIterator();}
protected Element mahout_f7269_0()
{    while (it.hasNext()) {        Element el = it.next();        if (isInView(el.index()) && el.get() != 0) {            Element decorated = el;            /* vector.getElement(el.index()); */            return new DecoratorElement(decorated);        }    }    return endOfData();}
protected Element mahout_f7270_0()
{    while (it.hasNext()) {        Element el = it.next();        if (isInView(el.index())) {            Element decorated = vector.getElement(el.index());            return new DecoratorElement(decorated);        }    }        return endOfData();}
public double mahout_f7271_0()
{    return decorated.get();}
public int mahout_f7272_0()
{    return decorated.index() - offset;}
public void mahout_f7273_0(double value)
{    decorated.set(value);}
public double mahout_f7274_0()
{    double result = 0.0;    int size = size();    for (int i = 0; i < size; i++) {        double value = getQuick(i);        result += value * value;    }    return result;}
public double mahout_f7275_0(Vector v)
{    double result = 0.0;    int size = size();    for (int i = 0; i < size; i++) {        double delta = getQuick(i) - v.getQuick(i);        result += delta * delta;    }    return result;}
public double mahout_f7276_0()
{    return vector.getLookupCost();}
public double mahout_f7277_0()
{        return 2 * vector.getIteratorAdvanceCost();}
public boolean mahout_f7278_0()
{    return vector.isAddConstantTime();}
public void mahout_f7279_0(OrderedIntDoubleMapping updates)
{    for (int i = 0; i < updates.getNumMappings(); ++i) {        updates.setIndexAt(i, updates.indexAt(i) + offset);    }    vector.mergeUpdates(updates);}
public static WeightedVector mahout_f7280_0(Vector v, Vector projection)
{    return project(v, projection, INVALID_INDEX);}
public static WeightedVector mahout_f7281_0(Vector v, Vector projection, int index)
{    return new WeightedVector(v, projection, index);}
public double mahout_f7282_0()
{    return weight;}
public int mahout_f7283_0()
{    return index;}
public void mahout_f7284_0(double newWeight)
{    this.weight = newWeight;}
public void mahout_f7285_0(int index)
{    this.index = index;}
public Vector mahout_f7286_0()
{    return new WeightedVector(getVector().like(), weight, index);}
public String mahout_f7287_0()
{    return String.format("index=%d, weight=%.2f, v=%s", index, weight, getVector());}
public WeightedVector mahout_f7288_0()
{    WeightedVector v = (WeightedVector) super.clone();    v.weight = weight;    v.index = index;    return v;}
public int mahout_f7289_0(WeightedVector a, WeightedVector b)
{    if (a == b) {        return 0;    }    double aWeight = a.getWeight();    double bWeight = b.getWeight();    int r = Double.compare(aWeight, bWeight);    if (r != 0 && Math.abs(aWeight - bWeight) >= DOUBLE_EQUALITY_ERROR) {        return r;    }    double diff = a.minus(b).norm(1);    if (diff < 1.0e-12) {        return 0;    }    for (Vector.Element element : a.all()) {        r = Double.compare(element.get(), b.get(element.index()));        if (r != 0) {            return r;        }    }    return 0;}
public void mahout_f7290_0()
{    assertEquals(new Double(0.0).hashCode(), RandomUtils.hashDouble(0.0));    assertEquals(new Double(1.0).hashCode(), RandomUtils.hashDouble(1.0));    assertEquals(new Double(Double.POSITIVE_INFINITY).hashCode(), RandomUtils.hashDouble(Double.POSITIVE_INFINITY));    assertEquals(new Double(Double.NaN).hashCode(), RandomUtils.hashDouble(Double.NaN));}
public void mahout_f7291_0()
{    assertEquals(new Float(0.0f).hashCode(), RandomUtils.hashFloat(0.0f));    assertEquals(new Float(1.0f).hashCode(), RandomUtils.hashFloat(1.0f));    assertEquals(new Float(Float.POSITIVE_INFINITY).hashCode(), RandomUtils.hashFloat(Float.POSITIVE_INFINITY));    assertEquals(new Float(Float.NaN).hashCode(), RandomUtils.hashFloat(Float.NaN));}
public void mahout_f7292_0()
{    assertEquals(5, RandomUtils.nextTwinPrime(-1));    assertEquals(5, RandomUtils.nextTwinPrime(1));    assertEquals(5, RandomUtils.nextTwinPrime(2));    assertEquals(5, RandomUtils.nextTwinPrime(3));    assertEquals(7, RandomUtils.nextTwinPrime(4));    assertEquals(7, RandomUtils.nextTwinPrime(5));    assertEquals(13, RandomUtils.nextTwinPrime(6));    assertEquals(RandomUtils.MAX_INT_SMALLER_TWIN_PRIME + 2, RandomUtils.nextTwinPrime(RandomUtils.MAX_INT_SMALLER_TWIN_PRIME));    try {        RandomUtils.nextTwinPrime(RandomUtils.MAX_INT_SMALLER_TWIN_PRIME + 1);        fail();    } catch (IllegalArgumentException iae) {        }}
public void mahout_f7293_0()
{    Random rTest0 = RandomUtils.getRandom();    Random rTest1 = RandomUtils.getRandom();    Random r0 = RandomUtils.getRandom(0);    Random r1 = RandomUtils.getRandom(1);    long lTest0 = rTest0.nextLong();    long lTest1 = rTest1.nextLong();    long l0 = r0.nextLong();    long l1 = r1.nextLong();    assertEquals("getRandom() must match getRandom() in unit tests", lTest0, lTest1);    assertTrue("getRandom() must differ from getRandom(0)", lTest0 != l1);    assertTrue("getRandom(0) must differ from getRandom(1)", l0 != l1);}
private static void mahout_f7294_0(Iterator<Vector.Element> nzIter, double[] values)
{    while (nzIter.hasNext()) {        Vector.Element elt = nzIter.next();        assertEquals(elt.index() + " Value: " + values[elt.index()] + " does not equal: " + elt.get(), values[elt.index()], elt.get(), 0.0);    }}
public void mahout_f7295_0()
{    T v0 = vectorToTest(20);    Random gen = RandomUtils.getRandom();    Vector v1 = v0.assign(new Normal(0, 1, gen));        assertEquals(v0.get(12), v1.get(12), 0);    v0.set(12, gen.nextDouble());    assertEquals(v0.get(12), v1.get(12), 0);    assertSame(v0, v1);    Vector v2 = vectorToTest(20).assign(new Normal(0, 1, gen));    Vector dv1 = new DenseVector(v1);    Vector dv2 = new DenseVector(v2);    Vector sv1 = new RandomAccessSparseVector(v1);    Vector sv2 = new RandomAccessSparseVector(v2);    assertEquals(0, dv1.plus(dv2).getDistanceSquared(v1.plus(v2)), FUZZ);    assertEquals(0, dv1.plus(dv2).getDistanceSquared(v1.plus(dv2)), FUZZ);    assertEquals(0, dv1.plus(dv2).getDistanceSquared(v1.plus(sv2)), FUZZ);    assertEquals(0, dv1.plus(dv2).getDistanceSquared(sv1.plus(v2)), FUZZ);    assertEquals(0, dv1.times(dv2).getDistanceSquared(v1.times(v2)), FUZZ);    assertEquals(0, dv1.times(dv2).getDistanceSquared(v1.times(dv2)), FUZZ);    assertEquals(0, dv1.times(dv2).getDistanceSquared(v1.times(sv2)), FUZZ);    assertEquals(0, dv1.times(dv2).getDistanceSquared(sv1.times(v2)), FUZZ);    assertEquals(0, dv1.minus(dv2).getDistanceSquared(v1.minus(v2)), FUZZ);    assertEquals(0, dv1.minus(dv2).getDistanceSquared(v1.minus(dv2)), FUZZ);    assertEquals(0, dv1.minus(dv2).getDistanceSquared(v1.minus(sv2)), FUZZ);    assertEquals(0, dv1.minus(dv2).getDistanceSquared(sv1.minus(v2)), FUZZ);    double z = gen.nextDouble();    assertEquals(0, dv1.divide(z).getDistanceSquared(v1.divide(z)), 1.0e-12);    assertEquals(0, dv1.times(z).getDistanceSquared(v1.times(z)), 1.0e-12);    assertEquals(0, dv1.plus(z).getDistanceSquared(v1.plus(z)), 1.0e-12);    assertEquals(dv1.dot(dv2), v1.dot(v2), FUZZ);    assertEquals(dv1.dot(dv2), v1.dot(dv2), FUZZ);    assertEquals(dv1.dot(dv2), v1.dot(sv2), FUZZ);    assertEquals(dv1.dot(dv2), sv1.dot(v2), FUZZ);    assertEquals(dv1.dot(dv2), dv1.dot(v2), FUZZ);        assertEquals(dv1.getDistanceSquared(dv2), v1.getDistanceSquared(v2), FUZZ);    assertEquals(dv1.getDistanceSquared(dv2), dv1.getDistanceSquared(v2), FUZZ);    assertEquals(dv1.getDistanceSquared(dv2), sv1.getDistanceSquared(v2), FUZZ);    assertEquals(dv1.getDistanceSquared(dv2), v1.getDistanceSquared(dv2), FUZZ);    assertEquals(dv1.getDistanceSquared(dv2), v1.getDistanceSquared(sv2), FUZZ);        assertEquals(dv1.getLengthSquared(), v1.getLengthSquared(), FUZZ);    assertEquals(dv1.getDistanceSquared(dv2), v1.getDistanceSquared(v2), FUZZ);    assertEquals(dv1.getDistanceSquared(dv2), dv1.getDistanceSquared(v2), FUZZ);    assertEquals(dv1.getDistanceSquared(dv2), sv1.getDistanceSquared(v2), FUZZ);    assertEquals(dv1.getDistanceSquared(dv2), v1.getDistanceSquared(dv2), FUZZ);    assertEquals(dv1.getDistanceSquared(dv2), v1.getDistanceSquared(sv2), FUZZ);    assertEquals(dv1.minValue(), v1.minValue(), FUZZ);    assertEquals(dv1.minValueIndex(), v1.minValueIndex());    assertEquals(dv1.maxValue(), v1.maxValue(), FUZZ);    assertEquals(dv1.maxValueIndex(), v1.maxValueIndex());    Vector nv1 = v1.normalize();    assertEquals(0, dv1.getDistanceSquared(v1), FUZZ);    assertEquals(1, nv1.norm(2), FUZZ);    assertEquals(0, dv1.normalize().getDistanceSquared(nv1), FUZZ);    nv1 = v1.normalize(1);    assertEquals(0, dv1.getDistanceSquared(v1), FUZZ);    assertEquals(1, nv1.norm(1), FUZZ);    assertEquals(0, dv1.normalize(1).getDistanceSquared(nv1), FUZZ);    assertEquals(dv1.norm(0), v1.norm(0), FUZZ);    assertEquals(dv1.norm(1), v1.norm(1), FUZZ);    assertEquals(dv1.norm(1.5), v1.norm(1.5), FUZZ);    assertEquals(dv1.norm(2), v1.norm(2), FUZZ);    assertEquals(dv1.zSum(), v1.zSum(), FUZZ);    assertEquals(3.1 * v1.size(), v1.assign(3.1).zSum(), FUZZ);    assertEquals(0, v1.plus(-3.1).norm(1), FUZZ);    v1.assign(dv1);    assertEquals(0, v1.getDistanceSquared(dv1), FUZZ);    assertEquals(dv1.zSum() - dv1.size() * 3.4, v1.assign(Functions.minus(3.4)).zSum(), FUZZ);    assertEquals(dv1.zSum() - dv1.size() * 4.5, v1.assign(Functions.MINUS, 1.1).zSum(), FUZZ);    v1.assign(dv1);    assertEquals(0, dv1.minus(dv2).getDistanceSquared(v1.assign(v2, Functions.MINUS)), FUZZ);    v1.assign(dv1);    assertEquals(dv1.norm(2), Math.sqrt(v1.aggregate(Functions.PLUS, Functions.pow(2))), FUZZ);    assertEquals(dv1.dot(dv2), v1.aggregate(v2, Functions.PLUS, Functions.MULT), FUZZ);    assertEquals(dv1.viewPart(5, 10).zSum(), v1.viewPart(5, 10).zSum(), FUZZ);    Vector v3 = v1.clone();        assertTrue(v0.getClass().isAssignableFrom(v3.getClass()));    assertTrue(v3.getClass().isAssignableFrom(v0.getClass()));    assertEquals(0, v1.getDistanceSquared(v3), FUZZ);    assertNotSame(v1, v3);    v3.assign(0);    assertEquals(0, dv1.getDistanceSquared(v1), FUZZ);    assertEquals(0, v3.getLengthSquared(), FUZZ);    dv1.assign(Functions.ABS);    v1.assign(Functions.ABS);    assertEquals(0, dv1.logNormalize().getDistanceSquared(v1.logNormalize()), FUZZ);    assertEquals(0, dv1.logNormalize(1.5).getDistanceSquared(v1.logNormalize(1.5)), FUZZ);    for (Vector.Element element : v1.all()) {        assertEquals(dv1.get(element.index()), element.get(), 0);        assertEquals(dv1.get(element.index()), v1.get(element.index()), 0);        assertEquals(dv1.get(element.index()), v1.getQuick(element.index()), 0);    }}
 Vector mahout_f7296_0()
{    return test;}
public void mahout_f7297_0() throws Exception
{    super.setUp();    test = generateTestVector(2 * values.length + 1);    for (int i = 0; i < values.length; i++) {        test.set(2 * i + 1, values[i]);    }}
public void mahout_f7298_0()
{    assertEquals("size", 7, test.size());}
public void mahout_f7299_0()
{    Iterator<Vector.Element> iterator = test.nonZeroes().iterator();    checkIterator(iterator, gold);    iterator = test.all().iterator();    checkIterator(iterator, gold);    double[] doubles = { 0.0, 5.0, 0, 3.0 };    RandomAccessSparseVector zeros = new RandomAccessSparseVector(doubles.length);    for (int i = 0; i < doubles.length; i++) {        zeros.setQuick(i, doubles[i]);    }    iterator = zeros.iterateNonZero();    checkIterator(iterator, doubles);    iterator = zeros.iterator();    checkIterator(iterator, doubles);    doubles = new double[] { 0.0, 0.0, 0, 0.0 };    zeros = new RandomAccessSparseVector(doubles.length);    for (int i = 0; i < doubles.length; i++) {        zeros.setQuick(i, doubles[i]);    }    iterator = zeros.iterateNonZero();    checkIterator(iterator, doubles);    iterator = zeros.iterator();    checkIterator(iterator, doubles);}
public void mahout_f7300_0()
{    Vector clone = test.clone();    for (Element e : clone.nonZeroes()) {        e.set(e.get() * 2.0);    }    for (Element e : clone.nonZeroes()) {        assertEquals(test.get(e.index()) * 2.0, e.get(), EPSILON);    }    clone = test.clone();    for (Element e : clone.all()) {        e.set(e.get() * 2.0);    }    for (Element e : clone.all()) {        assertEquals(test.get(e.index()) * 2.0, e.get(), EPSILON);    }}
public void mahout_f7301_0()
{    Vector copy = test.clone();    for (int i = 0; i < test.size(); i++) {        assertEquals("copy [" + i + ']', test.get(i), copy.get(i), EPSILON);    }}
public void mahout_f7302_0()
{    for (int i = 0; i < test.size(); i++) {        if (i % 2 == 0) {            assertEquals("get [" + i + ']', 0.0, test.get(i), EPSILON);        } else {            assertEquals("get [" + i + ']', values[i / 2], test.get(i), EPSILON);        }    }}
public void mahout_f7303_0()
{    test.get(test.size());}
public void mahout_f7304_0()
{    test.get(-1);}
public void mahout_f7305_0()
{    test.set(3, 4.5);    for (int i = 0; i < test.size(); i++) {        if (i % 2 == 0) {            assertEquals("get [" + i + ']', 0.0, test.get(i), EPSILON);        } else if (i == 3) {            assertEquals("set [" + i + ']', 4.5, test.get(i), EPSILON);        } else {            assertEquals("set [" + i + ']', values[i / 2], test.get(i), EPSILON);        }    }}
public void mahout_f7306_0()
{    assertEquals("size", 3, test.getNumNondefaultElements());}
public void mahout_f7307_0()
{    Vector part = test.viewPart(1, 2);    assertEquals("part size", 2, part.getNumNondefaultElements());    for (int i = 0; i < part.size(); i++) {        assertEquals("part[" + i + ']', test.get(i + 1), part.get(i), EPSILON);    }}
public void mahout_f7308_0()
{    test.viewPart(-1, values.length);}
public void mahout_f7309_0()
{    test.viewPart(2, 7);}
public void mahout_f7310_0()
{    test.viewPart(1, 8);}
public void mahout_f7311_0()
{    Vector val = new RandomAccessSparseVector(4);    assertEquals("size", 4, val.size());    for (int i = 0; i < 4; i++) {        assertEquals("get [" + i + ']', 0.0, val.get(i), EPSILON);    }}
public void mahout_f7312_0()
{    double res = test.dot(test);    double expected = 3.3 * 3.3 + 2.2 * 2.2 + 1.1 * 1.1;    assertEquals("dot", expected, res, EPSILON);}
public void mahout_f7313_0()
{    Vector test2 = test.clone();    test2.set(1, 0.0);    test2.set(3, 0.0);    assertEquals(3.3 * 3.3, test2.dot(test), EPSILON);}
public void mahout_f7314_0()
{    test.dot(new DenseVector(test.size() + 1));}
public void mahout_f7315_0()
{    Vector val = test.normalize();    double mag = Math.sqrt(1.1 * 1.1 + 2.2 * 2.2 + 3.3 * 3.3);    for (int i = 0; i < test.size(); i++) {        if (i % 2 == 0) {            assertEquals("get [" + i + ']', 0.0, val.get(i), EPSILON);        } else {            assertEquals("dot", values[i / 2] / mag, val.get(i), EPSILON);        }    }}
public void mahout_f7316_0()
{    Vector val = test.minus(test);    assertEquals("size", test.size(), val.size());    for (int i = 0; i < test.size(); i++) {        assertEquals("get [" + i + ']', 0.0, val.get(i), EPSILON);    }    val = test.minus(test).minus(test);    assertEquals("cardinality", test.size(), val.size());    for (int i = 0; i < test.size(); i++) {        assertEquals("get [" + i + ']', 0.0, val.get(i) + test.get(i), EPSILON);    }    Vector val1 = test.plus(1);    val = val1.minus(test);    for (int i = 0; i < test.size(); i++) {        assertEquals("get [" + i + ']', 1.0, val.get(i), EPSILON);    }    val1 = test.plus(-1);    val = val1.minus(test);    for (int i = 0; i < test.size(); i++) {        assertEquals("get [" + i + ']', -1.0, val.get(i), EPSILON);    }}
public void mahout_f7317_0()
{    Vector val = test.plus(1);    assertEquals("size", test.size(), val.size());    for (int i = 0; i < test.size(); i++) {        if (i % 2 == 0) {            assertEquals("get [" + i + ']', 1.0, val.get(i), EPSILON);        } else {            assertEquals("get [" + i + ']', values[i / 2] + 1.0, val.get(i), EPSILON);        }    }}
public void mahout_f7318_0()
{    Vector val = test.plus(test);    assertEquals("size", test.size(), val.size());    for (int i = 0; i < test.size(); i++) {        if (i % 2 == 0) {            assertEquals("get [" + i + ']', 0.0, val.get(i), EPSILON);        } else {            assertEquals("get [" + i + ']', values[i / 2] * 2.0, val.get(i), EPSILON);        }    }}
public void mahout_f7319_0()
{    test.plus(new DenseVector(test.size() + 1));}
public void mahout_f7320_0()
{    Vector val = test.times(3);    assertEquals("size", test.size(), val.size());    for (int i = 0; i < test.size(); i++) {        if (i % 2 == 0) {            assertEquals("get [" + i + ']', 0.0, val.get(i), EPSILON);        } else {            assertEquals("get [" + i + ']', values[i / 2] * 3.0, val.get(i), EPSILON);        }    }}
public void mahout_f7321_0()
{    Vector val = test.divide(3);    assertEquals("size", test.size(), val.size());    for (int i = 0; i < test.size(); i++) {        if (i % 2 == 0) {            assertEquals("get [" + i + ']', 0.0, val.get(i), EPSILON);        } else {            assertEquals("get [" + i + ']', values[i / 2] / 3.0, val.get(i), EPSILON);        }    }}
public void mahout_f7322_0()
{    Vector val = test.times(test);    assertEquals("size", test.size(), val.size());    for (int i = 0; i < test.size(); i++) {        if (i % 2 == 0) {            assertEquals("get [" + i + ']', 0.0, val.get(i), EPSILON);        } else {            assertEquals("get [" + i + ']', values[i / 2] * values[i / 2], val.get(i), EPSILON);        }    }}
public void mahout_f7323_0()
{    test.times(new DenseVector(test.size() + 1));}
public void mahout_f7324_0()
{    double expected = 0;    for (double value : values) {        expected += value;    }    assertEquals("wrong zSum", expected, test.zSum(), EPSILON);}
public void mahout_f7325_0()
{    Vector other = new RandomAccessSparseVector(test.size());    other.set(1, -2);    other.set(2, -5);    other.set(3, -9);    other.set(4, 1);    double expected = test.minus(other).getLengthSquared();    assertTrue("a.getDistanceSquared(b) != a.minus(b).getLengthSquared", Math.abs(expected - test.getDistanceSquared(other)) < 10.0E-7);}
public void mahout_f7326_0()
{    test.assign(0);    for (int i = 0; i < values.length; i++) {        assertEquals("value[" + i + ']', 0.0, test.getQuick(i), EPSILON);    }}
public void mahout_f7327_0()
{    double[] array = new double[test.size()];    test.assign(array);    for (int i = 0; i < values.length; i++) {        assertEquals("value[" + i + ']', 0.0, test.getQuick(i), EPSILON);    }}
public void mahout_f7328_0()
{    double[] array = new double[test.size() + 1];    test.assign(array);}
public void mahout_f7329_0()
{    Vector other = new DenseVector(test.size());    test.assign(other);    for (int i = 0; i < values.length; i++) {        assertEquals("value[" + i + ']', 0.0, test.getQuick(i), EPSILON);    }}
public void mahout_f7330_0()
{    Vector other = new DenseVector(test.size() - 1);    test.assign(other);}
public void mahout_f7331_0()
{    test.assign(Functions.NEGATE);    for (int i = 1; i < values.length; i += 2) {        assertEquals("value[" + i + ']', -values[i], test.getQuick(i + 2), EPSILON);    }}
public void mahout_f7332_0()
{    test.assign(test, Functions.PLUS);    for (int i = 0; i < values.length; i++) {        if (i % 2 == 0) {            assertEquals("get [" + i + ']', 0.0, test.get(i), EPSILON);        } else {            assertEquals("value[" + i + ']', 2 * values[i - 1], test.getQuick(i), EPSILON);        }    }}
public void mahout_f7333_0()
{    test.assign(Functions.plus(4));    for (int i = 0; i < values.length; i++) {        if (i % 2 == 0) {            assertEquals("get [" + i + ']', 4.0, test.get(i), EPSILON);        } else {            assertEquals("value[" + i + ']', values[i - 1] + 4, test.getQuick(i), EPSILON);        }    }}
public void mahout_f7334_0()
{    test.assign(Functions.mult(4));    for (int i = 0; i < values.length; i++) {        if (i % 2 == 0) {            assertEquals("get [" + i + ']', 0.0, test.get(i), EPSILON);        } else {            assertEquals("value[" + i + ']', values[i - 1] * 4, test.getQuick(i), EPSILON);        }    }}
public void mahout_f7335_0()
{    Vector other = test.like();    assertTrue("not like", test.getClass().isAssignableFrom(other.getClass()));    assertEquals("size", test.size(), other.size());}
public void mahout_f7336_0()
{    Matrix result = test.cross(test);    assertEquals("row size", test.size(), result.rowSize());    assertEquals("col size", test.size(), result.columnSize());    for (int row = 0; row < result.rowSize(); row++) {        for (int col = 0; col < result.columnSize(); col++) {            assertEquals("cross[" + row + "][" + col + ']', test.getQuick(row) * test.getQuick(col), result.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7337_0()
{    final T v0 = vectorToTest(20);    double sum = 0;    int elements = 0;    int nonZero = 0;    for (Element element : v0.all()) {        elements++;        sum += element.get();        if (element.get() != 0) {            nonZero++;        }    }    int nonZeroIterated = Iterables.size(v0.nonZeroes());    assertEquals(20, elements);    assertEquals(v0.size(), elements);    assertEquals(nonZeroIterated, nonZero);    assertEquals(v0.zSum(), sum, 0);}
public void mahout_f7338_0()
{    for (double fuzz : new double[] { 1.0e-5, 1.0e-6, 1.0e-7, 1.0e-8, 1.0e-9, 1.0e-10 }) {        MultiNormal x = new MultiNormal(fuzz, new ConstantVector(0, 20));        for (int i = 0; i < 10000; i++) {            final T v1 = vectorToTest(20);            Vector v2 = v1.plus(x.sample());            if (1 + fuzz * fuzz > 1) {                String msg = String.format("fuzz = %.1g, >", fuzz);                assertTrue(msg, v1.getDistanceSquared(v2) > 0);                assertTrue(msg, v2.getDistanceSquared(v1) > 0);            } else {                String msg = String.format("fuzz = %.1g, >=", fuzz);                assertTrue(msg, v1.getDistanceSquared(v2) >= 0);                assertTrue(msg, v2.getDistanceSquared(v1) >= 0);            }        }    }}
public void mahout_f7339_0()
{    Vector w;    w = generateTestVector(20);    w.set(0, 1.1);    w.set(13, 100500.);    w.set(19, 3.141592);    assertEquals("{0:1.1,13:100500.0,19:3.141592}", w.toString());    w = generateTestVector(12);    w.set(10, 0.1);    assertEquals("{10:0.1}", w.toString());    w = generateTestVector(12);    assertEquals("{}", w.toString());}
public void mahout_f7340_0()
{    double[][] testMatrix = new double[][] { new double[] { 1, 2, 3, 4, 5 }, new double[] { 1, 2, 3, 4, 5 }, new double[] { 1, 2, 3, 4, 5 }, new double[] { 1, 2, 3, 4, 5 }, new double[] { 1, 2, 3, 4, 5 } };    double[][] testMatrix2 = new double[][] { new double[] { 1, 2, 3, 4, 5, 6 }, new double[] { 5, 4, 3, 2, 1, 7 }, new double[] { 1, 2, 3, 4, 5, 8 }, new double[] { 1, 2, 3, 4, 5, 8 }, new double[] { 11, 12, 13, 20, 27, 8 } };    double[][][] testData = new double[][][] { testMatrix, testMatrix2 };    for (int i = 0; i < testData.length; i++) {        Matrix matrixToTest = new DenseMatrix(testData[i]);                for (int j = 0; j < 100; j++) {            validateYtY(matrixToTest, 4);        }                validateYtY(matrixToTest, 1);    }}
private void mahout_f7341_0(Matrix matrixToTest, int numThreads)
{    OpenIntObjectHashMap<Vector> matrixToTestAsRowVectors = asRowVectors(matrixToTest);    ImplicitFeedbackAlternatingLeastSquaresSolver solver = new ImplicitFeedbackAlternatingLeastSquaresSolver(matrixToTest.columnSize(), 1, 1, matrixToTestAsRowVectors, numThreads);    Matrix yTy = matrixToTest.transpose().times(matrixToTest);    Matrix shouldMatchyTy = solver.getYtransposeY(matrixToTestAsRowVectors);    for (int row = 0; row < yTy.rowSize(); row++) {        for (int column = 0; column < yTy.columnSize(); column++) {            assertEquals(yTy.getQuick(row, column), shouldMatchyTy.getQuick(row, column), 0);        }    }}
private OpenIntObjectHashMap<Vector> mahout_f7342_0(Matrix matrix)
{    OpenIntObjectHashMap<Vector> rows = new OpenIntObjectHashMap<>();    for (int row = 0; row < matrix.numRows(); row++) {        rows.put(row, matrix.viewRow(row).clone());    }    return rows;}
public void mahout_f7343_0()
{    int nui = 5;    double lambda = 0.2;    Matrix matrix = new SparseMatrix(5, 5);    AlternatingLeastSquaresSolver.addLambdaTimesNuiTimesE(matrix, lambda, nui);    for (int n = 0; n < 5; n++) {        assertEquals(1.0, matrix.getQuick(n, n), EPSILON);    }}
public void mahout_f7344_0()
{    Vector f1 = new DenseVector(new double[] { 1, 2, 3 });    Vector f2 = new DenseVector(new double[] { 4, 5, 6 });    Matrix miIi = AlternatingLeastSquaresSolver.createMiIi(Arrays.asList(f1, f2), 3);    assertEquals(1.0, miIi.getQuick(0, 0), EPSILON);    assertEquals(2.0, miIi.getQuick(1, 0), EPSILON);    assertEquals(3.0, miIi.getQuick(2, 0), EPSILON);    assertEquals(4.0, miIi.getQuick(0, 1), EPSILON);    assertEquals(5.0, miIi.getQuick(1, 1), EPSILON);    assertEquals(6.0, miIi.getQuick(2, 1), EPSILON);}
public void mahout_f7345_0()
{    Vector ratings = new SequentialAccessSparseVector(3);    ratings.setQuick(1, 1.0);    ratings.setQuick(3, 3.0);    ratings.setQuick(5, 5.0);    Matrix riIiMaybeTransposed = AlternatingLeastSquaresSolver.createRiIiMaybeTransposed(ratings);    assertEquals(1, riIiMaybeTransposed.numCols(), 1);    assertEquals(3, riIiMaybeTransposed.numRows(), 3);    assertEquals(1.0, riIiMaybeTransposed.getQuick(0, 0), EPSILON);    assertEquals(3.0, riIiMaybeTransposed.getQuick(1, 0), EPSILON);    assertEquals(5.0, riIiMaybeTransposed.getQuick(2, 0), EPSILON);}
public void mahout_f7346_0()
{    Vector ratings = new RandomAccessSparseVector(3);    ratings.setQuick(1, 1.0);    ratings.setQuick(3, 3.0);    ratings.setQuick(5, 5.0);    try {        AlternatingLeastSquaresSolver.createRiIiMaybeTransposed(ratings);        fail();    } catch (IllegalArgumentException e) {    }}
public void mahout_f7347_0()
{    MultiNormal f = new MultiNormal(20);    Vector a = f.sample();    Vector b = f.sample();    Vector c = f.sample();    DenseVector x = new DenseVector(a);    Centroid x1 = new Centroid(1, x);    x1.update(new Centroid(2, new DenseVector(b)));    Centroid x2 = new Centroid(x1);    x1.update(c);        Vector mean = a.plus(b).plus(c).assign(Functions.div(3));    assertEquals(0, x1.getVector().minus(mean).norm(1), 1.0e-8);    assertEquals(3, x1.getWeight(), 0);    assertEquals(0, x2.minus(a.plus(b).divide(2)).norm(1), 1.0e-8);    assertEquals(2, x2.getWeight(), 0);    assertEquals(0, new Centroid(x1.getIndex(), x1, x1.getWeight()).minus(x1).norm(1), 1.0e-8);        assertEquals(0, x.minus(x1).norm(1), 0);    assertEquals(3, x1.getWeight(), 1.0e-8);    assertEquals(1, x1.getIndex());}
public Centroid mahout_f7348_0(int size)
{    return new Centroid(new WeightedVector(new DenseVector(size), 3.15, 51));}
public void mahout_f7349_0()
{    assertEquals("size", 3, getTestVector().getNumNonZeroElements());}
 Vector mahout_f7350_0(int cardinality)
{    return new Centroid(new WeightedVector(new DenseVector(cardinality), 3.14, 53));}
public void mahout_f7351_0()
{    Matrix x = new DenseMatrix(3, 3);    x.viewRow(0).assign(new double[] { 1, 2, 3 });    x.viewRow(1).assign(new double[] { 2, 4, 6 });    x.viewRow(2).assign(new double[] { 3, 6, 9 });    CholeskyDecomposition rr = new CholeskyDecomposition(x.transpose().times(x), false);    assertEquals(0, new DenseVector(new double[] { 3.741657, 7.483315, 11.22497 }).aggregate(rr.getL().transpose().viewRow(0), Functions.PLUS, new DoubleDoubleFunction() {        @Override        public double apply(double arg1, double arg2) {            return Math.abs(arg1) - Math.abs(arg2);        }    }), 1.0e-5);    assertEquals(0, rr.getL().viewPart(0, 3, 1, 2).aggregate(Functions.PLUS, Functions.ABS), 1.0e-9);}
public double mahout_f7352_0(double arg1, double arg2)
{    return Math.abs(arg1) - Math.abs(arg2);}
public void mahout_f7353_0()
{    final Random rand = RandomUtils.getRandom();    Matrix z = new DenseMatrix(100, 100);    z.assign(new DoubleFunction() {        @Override        public double apply(double arg1) {            return rand.nextDouble();        }    });    Matrix A = z.times(z.transpose());    for (boolean type = false; !type; type = true) {        CholeskyDecomposition cd = new CholeskyDecomposition(A, type);        Matrix L = cd.getL();                Matrix Abar = L.times(L.transpose());        double error = A.minus(Abar).aggregate(Functions.MAX, Functions.ABS);        Assert.assertEquals("type = " + type, 0, error, 1.0e-10);                Matrix q = cd.solveLeft(z);        Matrix id = q.times(q.transpose());        for (int i = 0; i < id.columnSize(); i++) {            Assert.assertEquals("type = " + type, 1, id.get(i, i), 1.0e-9);            Assert.assertEquals("type = " + type, 1, id.viewRow(i).norm(1), 1.0e-9);        }                q = cd.solveRight(z.transpose());        id = q.transpose().times(q);        for (int i = 0; i < id.columnSize(); i++) {            Assert.assertEquals("type = " + type, 1, id.get(i, i), 1.0e-9);            Assert.assertEquals("type = " + type, 1, id.viewRow(i).norm(1), 1.0e-9);        }    }}
public double mahout_f7354_0(double arg1)
{    return rand.nextDouble();}
public void mahout_f7355_0()
{        double[][] values = new double[3][];    values[0] = new double[] { 1, -1, 1 };    values[1] = new double[] { -1, 1, -1 };    values[2] = new double[] { 1, -1, 2 };    Matrix A = new DenseMatrix(values);        CholeskyDecomposition cd = new CholeskyDecomposition(A, false);    assertEquals(0, cd.getL().times(cd.getL().transpose()).minus(A).aggregate(Functions.PLUS, Functions.ABS), 1.0e-10);        cd = new CholeskyDecomposition(A);    assertEquals(0, cd.getL().times(cd.getL().transpose()).minus(A).aggregate(Functions.PLUS, Functions.ABS), 1.0e-10);}
public void mahout_f7356_0()
{    Matrix A = rank4Matrix();    CholeskyDecomposition cd = new CholeskyDecomposition(A);    PivotedMatrix Ax = new PivotedMatrix(A, cd.getPivot());    CholeskyDecomposition cd2 = new CholeskyDecomposition(Ax, false);    assertEquals(0, cd2.getL().times(cd2.getL().transpose()).minus(Ax).aggregate(Functions.PLUS, Functions.ABS), 1.0e-10);    assertEquals(0, cd.getL().times(cd.getL().transpose()).minus(A).aggregate(Functions.PLUS, Functions.ABS), 1.0e-10);    Assert.assertFalse(cd.isPositiveDefinite());    Matrix L = cd.getL();    Matrix Abar = L.times(L.transpose());    double error = A.minus(Abar).aggregate(Functions.MAX, Functions.ABS);    Assert.assertEquals(0, error, 1.0e-10);}
private static Matrix mahout_f7357_0()
{    final Random rand = RandomUtils.getRandom();    Matrix u = new DenseMatrix(10, 4);    u.assign(new DoubleFunction() {        @Override        public double apply(double arg1) {            return rand.nextDouble();        }    });    Matrix v = new DenseMatrix(10, 4);    v.assign(new DoubleFunction() {        @Override        public double apply(double arg1) {            return rand.nextDouble();        }    });    Matrix z = u.times(v.transpose());    return z.times(z.transpose());}
public double mahout_f7358_0(double arg1)
{    return rand.nextDouble();}
public double mahout_f7359_0(double arg1)
{    return rand.nextDouble();}
public static long mahout_f7360_0(Matrix corpus, double convergence, int maxNumPasses, TrainingState state)
{    return timeSolver(corpus, convergence, maxNumPasses, 10, state);}
public static long mahout_f7361_0(Matrix corpus, double convergence, int maxNumPasses, int desiredRank, TrainingState state)
{    HebbianUpdater updater = new HebbianUpdater();    AsyncEigenVerifier verifier = new AsyncEigenVerifier();    HebbianSolver solver = new HebbianSolver(updater, verifier, convergence, maxNumPasses);    long start = System.nanoTime();    TrainingState finalState = solver.solve(corpus, desiredRank);    assertNotNull(finalState);    state.setCurrentEigens(finalState.getCurrentEigens());    state.setCurrentEigenValues(finalState.getCurrentEigenValues());    long time = 0L;    time += System.nanoTime() - start;    verifier.close();    assertEquals(state.getCurrentEigens().numRows(), desiredRank);    return time / 1000000L;}
public static long mahout_f7362_0(Matrix corpus, TrainingState state)
{    return timeSolver(corpus, state, 10);}
public static long mahout_f7363_0(Matrix corpus, TrainingState state, int rank)
{    return timeSolver(corpus, 0.01, 20, rank, state);}
public void mahout_f7364_0()
{    int numColumns = 800;    Matrix corpus = randomSequentialAccessSparseMatrix(1000, 900, numColumns, 30, 1.0);    int rank = 50;    Matrix eigens = new DenseMatrix(rank, numColumns);    TrainingState state = new TrainingState(eigens, null);    long optimizedTime = timeSolver(corpus, 0.00001, 5, rank, state);    eigens = state.getCurrentEigens();    assertEigen(eigens, corpus, 0.05, false);    assertOrthonormal(eigens, 1.0e-6);    System.out.println("Avg solving (Hebbian) time in ms: " + optimizedTime);}
public void mahout_f7365_1() throws Exception
{    int size = 100;    Matrix m = randomHierarchicalSymmetricMatrix(size);    Vector initialVector = new DenseVector(size);    initialVector.assign(1.0 / Math.sqrt(size));    LanczosSolver solver = new LanczosSolver();    int desiredRank = 80;    LanczosState state = new LanczosState(m, desiredRank, initialVector);        solver.solve(state, desiredRank, true);    EigenDecomposition decomposition = new EigenDecomposition(m);    Vector eigenvalues = decomposition.getRealEigenvalues();    float fractionOfEigensExpectedGood = 0.6f;    for (int i = 0; i < fractionOfEigensExpectedGood * desiredRank; i++) {        double s = state.getSingularValue(i);        double e = eigenvalues.get(i);                assertTrue("Singular value differs from eigenvalue", Math.abs((s - e) / e) < ERROR_TOLERANCE);        Vector v = state.getRightSingularVector(i);        Vector v2 = decomposition.getV().viewColumn(i);        double error = 1 - Math.abs(v.dot(v2) / (v.norm(2) * v2.norm(2)));                assertTrue(i + ": 1 - cosAngle = " + error, error < ERROR_TOLERANCE);    }}
public void mahout_f7366_0() throws Exception
{    int numRows = 800;    int numColumns = 500;    Matrix corpus = randomHierarchicalMatrix(numRows, numColumns, false);    Vector initialVector = new DenseVector(numColumns);    initialVector.assign(1.0 / Math.sqrt(numColumns));    int rank = 50;    LanczosState state = new LanczosState(corpus, rank, initialVector);    LanczosSolver solver = new LanczosSolver();    solver.solve(state, rank, false);    assertOrthonormal(state);    for (int i = 0; i < rank / 2; i++) {        assertEigen(i, state.getRightSingularVector(i), corpus, ERROR_TOLERANCE, false);    }}
public void mahout_f7367_0() throws Exception
{    int numCols = 500;    Matrix corpus = randomHierarchicalSymmetricMatrix(numCols);    Vector initialVector = new DenseVector(numCols);    initialVector.assign(1.0 / Math.sqrt(numCols));    int rank = 30;    LanczosState state = new LanczosState(corpus, rank, initialVector);    LanczosSolver solver = new LanczosSolver();    solver.solve(state, rank, true);}
public static void mahout_f7368_0(Matrix eigens)
{    assertOrthonormal(eigens, 1.0e-6);}
public static void mahout_f7369_1(Matrix currentEigens, double errorMargin)
{    List<String> nonOrthogonals = Lists.newArrayList();    for (int i = 0; i < currentEigens.numRows(); i++) {        Vector ei = currentEigens.viewRow(i);        for (int j = 0; j <= i; j++) {            Vector ej = currentEigens.viewRow(j);            if (ei.norm(2) == 0 || ej.norm(2) == 0) {                continue;            }            double dot = ei.dot(ej);            if (i == j) {                assertTrue("not norm 1 : " + dot + " (eigen #" + i + ')', Math.abs(1.0 - dot) < errorMargin);            } else {                if (Math.abs(dot) > errorMargin) {                                        nonOrthogonals.add("(" + i + ',' + j + ')');                }            }        }            }}
public static void mahout_f7370_1(LanczosState state)
{    double errorMargin = 1.0e-5;    List<String> nonOrthogonals = Lists.newArrayList();    for (int i = 0; i < state.getIterationNumber(); i++) {        Vector ei = state.getRightSingularVector(i);        for (int j = 0; j <= i; j++) {            Vector ej = state.getRightSingularVector(j);            if (ei.norm(2) == 0 || ej.norm(2) == 0) {                continue;            }            double dot = ei.dot(ej);            if (i == j) {                assertTrue("not norm 1 : " + dot + " (eigen #" + i + ')', Math.abs(1.0 - dot) < errorMargin);            } else {                if (Math.abs(dot) > errorMargin) {                                        nonOrthogonals.add("(" + i + ',' + j + ')');                }            }        }        if (!nonOrthogonals.isEmpty()) {                    }    }}
public static void mahout_f7371_0(Matrix eigens, VectorIterable corpus, double errorMargin, boolean isSymmetric)
{    assertEigen(eigens, corpus, eigens.numRows(), errorMargin, isSymmetric);}
public static void mahout_f7372_0(Matrix eigens, VectorIterable corpus, int numEigensToCheck, double errorMargin, boolean isSymmetric)
{    for (int i = 0; i < numEigensToCheck; i++) {        Vector e = eigens.viewRow(i);        assertEigen(i, e, corpus, errorMargin, isSymmetric);    }}
public static void mahout_f7373_1(int i, Vector e, VectorIterable corpus, double errorMargin, boolean isSymmetric)
{    if (e.getLengthSquared() == 0) {        return;    }    Vector afterMultiply = isSymmetric ? corpus.times(e) : corpus.timesSquared(e);    double dot = afterMultiply.dot(e);    double afterNorm = afterMultiply.getLengthSquared();    double error = 1 - Math.abs(dot / Math.sqrt(afterNorm * e.getLengthSquared()));        assertTrue("Error: {" + error + " too high! (for eigen " + i + ')', Math.abs(error) < errorMargin);}
public static Matrix mahout_f7374_0(int numRows, int nonNullRows, int numCols, int entriesPerRow, double entryMean)
{    Matrix m = new SparseRowMatrix(numRows, numCols);        Random r = RandomUtils.getRandom();    for (int i = 0; i < nonNullRows; i++) {        Vector v = new SequentialAccessSparseVector(numCols);        for (int j = 0; j < entriesPerRow; j++) {            int col = r.nextInt(numCols);            double val = r.nextGaussian();            v.set(col, val * entryMean);        }        int c = r.nextInt(numRows);        if (r.nextBoolean() || numRows == nonNullRows) {            m.assignRow(numRows == nonNullRows ? i : c, v);        } else {            Vector other = m.viewRow(r.nextInt(numRows));            if (other != null && other.getLengthSquared() > 0) {                m.assignRow(c, other.clone());            }        }        }    return m;}
public static Matrix mahout_f7375_0(int numRows, int numCols, boolean symmetric)
{    Matrix matrix = new DenseMatrix(numRows, numCols);        Random r = new Random(1234L);    for (int row = 0; row < numRows; row++) {        Vector v = new DenseVector(numCols);        for (int col = 0; col < numCols; col++) {            double val = r.nextGaussian();            v.set(col, val);        }        v.assign(Functions.MULT, 1 / ((row + 1) * v.norm(2)));        matrix.assignRow(row, v);    }    if (symmetric) {        return matrix.times(matrix.transpose());    }    return matrix;}
public static Matrix mahout_f7376_0(int size)
{    return randomHierarchicalMatrix(size, size, true);}
public void mahout_f7377_0()
{    Matrix a = new DenseSymmetricMatrix(new double[] { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 }, false);    System.out.println(a.toString());    assertEquals(0, a.viewDiagonal().minus(new DenseVector(new double[] { 1, 5, 8, 10 })).norm(1), 1.0e-10);    assertEquals(0, a.viewPart(0, 3, 1, 3).viewDiagonal().minus(new DenseVector(new double[] { 2, 6, 9 })).norm(1), 1.0e-10);    assertEquals(4, a.get(0, 3), 1.0e-10);    System.out.println(a);    Matrix m = new DenseMatrix(4, 4).assign(a);    assertEquals(0, m.minus(a).aggregate(Functions.PLUS, Functions.ABS), 1.0e-10);    System.out.println(m);    assertEquals(0, m.transpose().times(m).minus(a.transpose().times(a)).aggregate(Functions.PLUS, Functions.ABS), 1.0e-10);    System.out.println(a.plus(a));    assertEquals(0, m.plus(m).minus(a.plus(a)).aggregate(Functions.PLUS, Functions.ABS), 1.0e-10);}
public void mahout_f7378_0()
{    Matrix a = new DenseSymmetricMatrix(new double[] { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 }, false);    Matrix b = new DenseMatrix(a.numRows(), a.numCols());    b.assign(a);    assertEquals(0, a.minus(b).aggregate(Functions.PLUS, Functions.ABS), 1.0e-10);    EigenDecomposition edA = new EigenDecomposition(a);    EigenDecomposition edB = new EigenDecomposition(b);    System.out.println(edA.getV());    assertEquals(0, edA.getV().minus(edB.getV()).aggregate(Functions.PLUS, Functions.ABS), 1.0e-10);    assertEquals(0, edA.getRealEigenvalues().minus(edA.getRealEigenvalues()).aggregate(Functions.PLUS, Functions.ABS), 1.0e-10);}
public void mahout_f7379_0()
{    DiagonalMatrix a = new DiagonalMatrix(new double[] { 1, 2, 3, 4 });    assertEquals(0, a.viewDiagonal().minus(new DenseVector(new double[] { 1, 2, 3, 4 })).norm(1), 1.0e-10);    assertEquals(0, a.viewPart(0, 3, 0, 3).viewDiagonal().minus(new DenseVector(new double[] { 1, 2, 3 })).norm(1), 1.0e-10);    assertEquals(4, a.get(3, 3), 1.0e-10);    Matrix m = new DenseMatrix(4, 4);    m.assign(a);    assertEquals(0, m.minus(a).aggregate(Functions.PLUS, Functions.ABS), 1.0e-10);    assertEquals(0, m.transpose().times(m).minus(a.transpose().times(a)).aggregate(Functions.PLUS, Functions.ABS), 1.0e-10);    assertEquals(0, m.plus(m).minus(a.plus(a)).aggregate(Functions.PLUS, Functions.ABS), 1.0e-10);    m = new DenseMatrix(new double[][] { { 1, 2, 3, 4 }, { 5, 6, 7, 8 } });    assertEquals(100, a.timesLeft(m).aggregate(Functions.PLUS, Functions.ABS), 1.0e-10);    assertEquals(100, a.times(m.transpose()).aggregate(Functions.PLUS, Functions.ABS), 1.0e-10);}
public void mahout_f7380_0()
{    Vector d = new DenseVector(10);    for (int i = 0; i < 10; i++) {        d.set(i, i * i);    }    DiagonalMatrix m = new DiagonalMatrix(d);    Assert.assertFalse(m.viewRow(0).isDense());    Assert.assertFalse(m.viewColumn(0).isDense());    for (int i = 0; i < 10; i++) {        assertEquals(i * i, m.viewRow(i).zSum(), 0);        assertEquals(i * i, m.viewRow(i).get(i), 0);        assertEquals(i * i, m.viewColumn(i).zSum(), 0);        assertEquals(i * i, m.viewColumn(i).get(i), 0);    }    Iterator<Vector.Element> ix = m.viewRow(7).nonZeroes().iterator();    assertTrue(ix.hasNext());    Vector.Element r = ix.next();    assertEquals(7, r.index());    assertEquals(49, r.get(), 0);    assertFalse(ix.hasNext());    assertEquals(0, m.viewRow(5).get(3), 0);    assertEquals(0, m.viewColumn(8).get(3), 0);    m.viewRow(3).set(3, 1);    assertEquals(1, m.get(3, 3), 0);    for (Vector.Element element : m.viewRow(6).all()) {        if (element.index() == 6) {            assertEquals(36, element.get(), 0);        } else {            assertEquals(0, element.get(), 0);        }    }}
public void mahout_f7381_0() throws IOException
{        Assume.assumeNotNull(System.getProperty("runSlowTests"));    Matrix m0 = new SparseRowMatrix(ROWS, COLUMNS);    Random gen = RandomUtils.getRandom();    for (int i = 0; i < 1000; i++) {        m0.set(gen.nextInt(ROWS), gen.nextInt(COLUMNS), matrixValue(i));    }    File f = File.createTempFile("foo", ".m", getTestTempDir());    f.deleteOnExit();    System.out.printf("Starting to write to %s\n", f.getAbsolutePath());    FileBasedMatrix.writeMatrix(f, m0);    System.out.printf("done\n");    System.out.printf("File is %.1f MB\n", f.length() / 1.0e6);    FileBasedMatrix m1 = new FileBasedMatrix(ROWS, COLUMNS);    System.out.printf("Starting read\n");    m1.setData(f, false);    gen = RandomUtils.getRandom();    for (int i = 0; i < 1000; i++) {        assertEquals(matrixValue(i), m1.get(gen.nextInt(ROWS), gen.nextInt(COLUMNS)), 0.0);    }    System.out.printf("done\n");}
private static int mahout_f7382_0(int i)
{    return (i * 88513) % 10000;}
public void mahout_f7383_0() throws IOException
{    File f = File.createTempFile("matrix", ".m", getTestTempDir());    f.deleteOnExit();    Matrix m0 = new DenseMatrix(100000, 30);    MultiNormal gen = new MultiNormal(30);    for (MatrixSlice row : m0) {        row.vector().assign(gen.sample());    }    FileBasedMatrix.writeMatrix(f, m0);    FileBasedMatrix m = new FileBasedMatrix(100000, 30);    m.setData(f, true);    assertEquals(0, m0.minus(m).aggregate(Functions.MAX, Functions.ABS), 1.0e-8);    int i = 0;    for (MatrixSlice row : m) {        assertEquals(0, row.vector().minus(m0.viewRow(i++)).norm(1), 1.0e-8);    }}
public void mahout_f7384_0() throws IOException
{    File f = File.createTempFile("matrix", ".m", getTestTempDir());    f.deleteOnExit();    Random gen = RandomUtils.getRandom();    Matrix m0 = new SparseRowMatrix(10, 21);    for (MatrixSlice row : m0) {        int len = (int) Math.ceil(-15 * Math.log(1 - gen.nextDouble()));        for (int i = 0; i < len; i++) {            row.vector().set(gen.nextInt(21), 1);        }    }    FileBasedSparseBinaryMatrix.writeMatrix(f, m0);    FileBasedSparseBinaryMatrix m = new FileBasedSparseBinaryMatrix(10, 21);    m.setData(f);    for (MatrixSlice row : m) {        Vector diff = row.vector().minus(m0.viewRow(row.index()));        double error = diff.norm(1);        if (error > 1.0e-14) {            System.out.printf("%s\n", diff);        }        assertEquals(0, error, 1.0e-14);    }}
public static Collection<Object[]> mahout_f7385_0()
{    List<Object[]> data = Lists.newArrayList();    for (Field field : Functions.class.getDeclaredFields()) {        if (field.getType().isAssignableFrom(DoubleDoubleFunction.class) && Modifier.isStatic(field.getModifiers()) && !field.getName().equals("SECOND_LEFT_ZERO")) {            try {                data.add(new Object[] { field.get(null), field.getName() });            } catch (IllegalAccessException e) {                System.out.printf("Couldn't access Functions field %s\n", field.getName());            }        }    }    return data;}
public void mahout_f7386_0()
{    if (!function.isLikeRightPlus()) {        return;    }    for (int i = 0; i < NUM_POINTS; ++i) {        double x = random.nextDouble();        assertEquals(functionName, x, function.apply(x, 0), 0);    }}
public void mahout_f7387_0()
{    if (!function.isLikeLeftMult()) {        return;    }    for (int i = 0; i < NUM_POINTS; ++i) {        double y = random.nextDouble();        assertEquals(functionName, 0, function.apply(0, y), 0);    }}
public void mahout_f7388_0()
{    if (!function.isLikeRightMult()) {        return;    }    for (int i = 0; i < NUM_POINTS; ++i) {        double x = random.nextDouble();        assertEquals(functionName, 0, function.apply(x, 0), 0);    }}
public void mahout_f7389_0()
{    if (!function.isCommutative()) {        return;    }    for (int i = 0; i < NUM_POINTS; ++i) {        double x = random.nextDouble();        double y = random.nextDouble();        assertEquals(functionName, function.apply(x, y), function.apply(y, x), Constants.EPSILON);    }}
public void mahout_f7390_0()
{    if (!function.isAssociative()) {        return;    }    for (int i = 0; i < NUM_POINTS; ++i) {        double x = random.nextDouble();        double y = random.nextDouble();        double z = random.nextDouble();        assertEquals(functionName, function.apply(x, function.apply(y, z)), function.apply(function.apply(x, y), z), Constants.EPSILON);    }}
public void mahout_f7391_0()
{    if (!function.isDensifying()) {        assertEquals(functionName, 0, function.apply(0, 0), 0);    }}
public static void mahout_f7392_0(final AbstractContinousDistribution dist, double[] x, double offset, double scale, int n)
{    double[] xs = Arrays.copyOf(x, x.length);    for (int i = 0; i < xs.length; i++) {        xs[i] = xs[i] * scale + offset;    }    Arrays.sort(xs);        double[] y = new double[n];    for (int i = 0; i < n; i++) {        y[i] = dist.nextDouble();    }    Arrays.sort(y);        double[] p = new double[xs.length + 1];    double lastP = 0;    for (int i = 0; i < xs.length; i++) {        double thisP = dist.cdf(xs[i]);        p[i] = thisP - lastP;        lastP = thisP;    }    p[p.length - 1] = 1 - lastP;        int[] k = new int[xs.length + 1];    int lastJ = 0;    for (int i = 0; i < k.length - 1; i++) {        int j = 0;        while (j < n && y[j] < xs[i]) {            j++;        }        k[i] = j - lastJ;        lastJ = j;    }    k[k.length - 1] = n - lastJ;        UnivariateIntegrator integrator = new RombergIntegrator();    for (int i = 0; i < xs.length - 1; i++) {        double delta = integrator.integrate(1000000, new UnivariateFunction() {            @Override            public double value(double v) {                return dist.pdf(v);            }        }, xs[i], xs[i + 1]);        Assert.assertEquals(delta, p[i + 1], 1.0e-6);    }        double sum = 0;    for (int i = 0; i < k.length; i++) {        if (k[i] != 0) {            sum += k[i] * Math.log(k[i] / p[i] / n);        }    }    sum *= 2;        int dof = k.length - 1;        double z = Math.sqrt(2 * sum) - Math.sqrt(2 * dof - 1);    Assert.assertTrue(String.format("offset=%.3f scale=%.3f Z = %.1f", offset, scale, z), Math.abs(z) < 3);}
public double mahout_f7393_0(double v)
{    return dist.pdf(v);}
 static void mahout_f7394_0(double offset, double scale, AbstractContinousDistribution dist, double[] breaks, double[] quantiles)
{    int i = 0;    for (double x : breaks) {        Assert.assertEquals(String.format("m=%.3f sd=%.3f x=%.3f", offset, scale, x), quantiles[i], dist.cdf(x * scale + offset), 1.0e-6);        i++;    }}
private static double mahout_f7395_0(long y)
{    return (y & 0xffffffffL) * 2.3283064365386963e-10;}
public void mahout_f7396_0()
{    MersenneTwister r = new MersenneTwister();    r.setReferenceSeed(4357);        int i = 0;    for (long x : reference1) {        int y = r.nextInt();        assertEquals("t-ref-int-" + i, x, y);        i++;    }    r.setReferenceSeed(4357);    i = 0;    for (Double x : ref1) {        assertEquals("t-ref-double-" + i, x, toDouble(r.nextInt()), 1.0e-7);        i++;    }}
public void mahout_f7397_0()
{    RandomEngine r = new MersenneTwister(42);    int i = 0;    for (double x : reference3) {        assertEquals("t-regression-" + i, x, r.nextDouble(), 1.0e-7);        i++;    }}
public void mahout_f7398_0()
{    RandomEngine r1 = new MersenneTwister(1275264362);    RandomEngine r2 = new MersenneTwister(new Date(1275264362));    for (int i = 0; i < 100; i++) {        assertEquals("date-" + i, r1.nextInt(), r2.nextInt());    }}
public void mahout_f7399_0()
{    Exponential dist = new Exponential(1, RandomUtils.getRandom());        double[] breaks = { 0.1053605, 0.2231436, 0.3566749, 0.5108256, 0.6931472, 0.9162907, 1.2039728, 1.6094379, 2.3025851 };    for (double lambda : new double[] { 0.01, 0.1, 1, 2, 5, 100 }) {        dist.setState(lambda);        DistributionChecks.checkDistribution(dist, breaks, 0, 1 / lambda, 10000);    }}
public void mahout_f7400_0()
{    Exponential dist = new Exponential(5.0, RandomUtils.getRandom());    for (int i = 0; i < 1000; i++) {        double x = i / 50.0;        assertEquals(1 - Math.exp(-x * 5.0), dist.cdf(x), 1.0e-9);    }}
public void mahout_f7401_0()
{    checkPdf(new Exponential(13.0, null), 13.0);}
private static void mahout_f7402_0(Exponential dist, double lambda)
{    assertEquals(0, dist.pdf(-1), 0);    double sum = 0;    double dx = 0.001 / lambda;    for (double x = 0; x < 20 / lambda; x += dx) {        sum += x * dist.pdf(x) * dx;        assertEquals(Math.exp(-x * lambda) * lambda, dist.pdf(x), 1.0e-9);    }    assertEquals(1 / lambda, sum, 1.0e-6 / lambda);}
public void mahout_f7403_0()
{    Exponential dist = new Exponential(13.0, null);    for (double lambda = 0.1; lambda < 1000; lambda *= 1.3) {        dist.setState(lambda);        checkPdf(dist, lambda);    }}
public void mahout_f7404_0() throws Exception
{    double[] x = { -0.01, 0.1053605, 0.2231436, 0.3566749, 0.5108256, 0.6931472, 0.9162907, 1.2039728, 1.6094379, 2.3025851 };    Exponential dist = new Exponential(1, RandomUtils.getRandom());    for (double lambda : new double[] { 13.0, 0.02, 1.6 }) {        dist.setState(lambda);        checkEmpiricalDistribution(dist, 10000, lambda);        DistributionChecks.checkDistribution(dist, x, 0, 1 / lambda, 10000);    }}
private static void mahout_f7405_0(Exponential dist, int n, double lambda)
{    double[] x = new double[n];    for (int i = 0; i < n; i++) {        x[i] = dist.nextDouble();    }    Arrays.sort(x);    for (int i = 0; i < n; i++) {        double cumulative = (double) i / (n - 1);        assertEquals(String.format("lambda = %.3f", lambda), cumulative, dist.cdf(x[i]), 0.02);    }}
public void mahout_f7406_0()
{    assertEquals("org.apache.mahout.math.jet.random.Exponential(3.1000)", new Exponential(3.1, null).toString());    assertEquals("org.apache.mahout.math.jet.random.Exponential(3.1000)", new Exponential(3.1, null).toString());}
public void mahout_f7407_0()
{    double[] z = new double[100000];    Random gen = RandomUtils.getRandom();    for (double alpha : new double[] { 1, 2, 10, 0.1, 0.01, 100 }) {        Gamma g = new Gamma(alpha, 1, gen);        for (int i = 0; i < z.length; i++) {            z[i] = g.nextDouble();        }        Arrays.sort(z);                for (double q : seq(0.01, 1, 0.01)) {            double p = z[(int) (q * z.length)];            assertEquals(q, g.cdf(p), 0.01);        }    }}
public void mahout_f7408_0()
{    Random gen = RandomUtils.getRandom();        for (double beta : new double[] { 1, 0.1, 2, 100 }) {        Gamma g1 = new Gamma(1, beta, gen);        Gamma g2 = new Gamma(1, 1, gen);        for (double x : seq(0, 0.99, 0.1)) {            assertEquals(String.format(Locale.ENGLISH, "Rate invariance: x = %.4f, alpha = 1, beta = %.1f", x, beta), 1 - Math.exp(-x * beta), g1.cdf(x), 1.0e-9);            assertEquals(String.format(Locale.ENGLISH, "Rate invariance: x = %.4f, alpha = 1, beta = %.1f", x, beta), g2.cdf(beta * x), g1.cdf(x), 1.0e-9);        }    }        for (double alpha : new double[] { 0.01, 0.1, 1, 2, 10, 100, 1000 }) {        Gamma g = new Gamma(alpha, 1, gen);        for (double beta : new double[] { 0.1, 1, 2, 100 }) {            Gamma g1 = new Gamma(alpha, beta, gen);            for (double x : seq(0, 0.9999, 0.001)) {                assertEquals(String.format(Locale.ENGLISH, "Rate invariance: x = %.4f, alpha = %.2f, beta = %.1f", x, alpha, beta), g.cdf(x * beta), g1.cdf(x), 0);            }        }    }        checkGammaCdf(0.01, 1, 0.0000000, 0.9450896, 0.9516444, 0.9554919, 0.9582258, 0.9603474, 0.9620810, 0.9635462, 0.9648148, 0.9659329, 0.9669321);    checkGammaCdf(0.1, 1, 0.0000000, 0.7095387, 0.7591012, 0.7891072, 0.8107067, 0.8275518, 0.8413180, 0.8529198, 0.8629131, 0.8716623, 0.8794196);    checkGammaCdf(1, 1, 0.0000000, 0.1812692, 0.3296800, 0.4511884, 0.5506710, 0.6321206, 0.6988058, 0.7534030, 0.7981035, 0.8347011, 0.8646647);    checkGammaCdf(10, 1, 0.000000e+00, 4.649808e-05, 8.132243e-03, 8.392402e-02, 2.833757e-01, 5.420703e-01, 7.576078e-01, 8.906006e-01, 9.567017e-01, 9.846189e-01, 9.950046e-01);    checkGammaCdf(100, 1, 0.000000e+00, 3.488879e-37, 1.206254e-15, 1.481528e-06, 1.710831e-02, 5.132988e-01, 9.721363e-01, 9.998389e-01, 9.999999e-01, 1.000000e+00, 1.000000e+00);}
private static void mahout_f7409_0(double alpha, double beta, double... values)
{    Gamma g = new Gamma(alpha, beta, RandomUtils.getRandom());    int i = 0;    for (double x : seq(0, 2 * alpha, 2 * alpha / 10)) {        assertEquals(String.format(Locale.ENGLISH, "alpha=%.2f, i=%d, x=%.2f", alpha, i, x), values[i], g.cdf(x), 1.0e-7);        i++;    }}
private static double[] mahout_f7410_0(double from, double to, double by)
{    double[] r = new double[(int) Math.ceil(0.999999 * (to - from) / by)];    int i = 0;    for (double x = from; x < to - (to - from) * 1.0e-6; x += by) {        r[i++] = x;    }    return r;}
public void mahout_f7411_0()
{    Random gen = RandomUtils.getRandom();    for (double alpha : new double[] { 0.01, 0.1, 1, 2, 10, 100 }) {        for (double beta : new double[] { 0.1, 1, 2, 100 }) {            Gamma g1 = new Gamma(alpha, beta, gen);            for (double x : seq(0, 0.99, 0.1)) {                double p = Math.pow(beta, alpha) * Math.pow(x, alpha - 1) * Math.exp(-beta * x - org.apache.mahout.math.jet.stat.Gamma.logGamma(alpha));                assertEquals(String.format(Locale.ENGLISH, "alpha=%.2f, beta=%.2f, x=%.2f\n", alpha, beta, x), p, g1.pdf(x), 1.0e-9);            }        }    }}
public void mahout_f7412_0() throws Exception
{    InputSupplier<InputStreamReader> input = Resources.newReaderSupplier(Resources.getResource("negative-binomial-test-data.csv"), Charsets.UTF_8);    boolean header = true;    for (String line : CharStreams.readLines(input)) {        if (header) {                        header = false;        } else {            Iterable<String> values = onComma.split(line);            int k = Integer.parseInt(Iterables.get(values, 0));            double p = Double.parseDouble(Iterables.get(values, 1));            int r = Integer.parseInt(Iterables.get(values, 2));            double density = Double.parseDouble(Iterables.get(values, 3));            double cume = Double.parseDouble(Iterables.get(values, 4));            NegativeBinomial nb = new NegativeBinomial(r, p, RandomUtils.getRandom());            assertEquals("cumulative " + k + ',' + p + ',' + r, cume, nb.cdf(k), cume * 1.0e-5);            assertEquals("density " + k + ',' + p + ',' + r, density, nb.pdf(k), density * 1.0e-5);        }    }}
public void mahout_f7413_0()
{    Random gen = RandomUtils.getRandom();    double offset = 0;    double scale = 1;    for (int k = 0; k < 20; k++) {        Normal dist = new Normal(offset, scale, null);        DistributionChecks.checkCdf(offset, scale, dist, breaks, quantiles);        offset = gen.nextGaussian();        scale = Math.exp(3 * gen.nextGaussian());    }}
public void mahout_f7414_0()
{    Random gen = RandomUtils.getRandom();    double offset = 0;    double scale = 1;    Normal dist = new Normal(offset, scale, RandomUtils.getRandom());    for (int k = 0; k < 20; k++) {        dist.setState(offset, scale);        DistributionChecks.checkDistribution(dist, breaks, offset, scale, 10000);        offset = gen.nextGaussian();        scale = Math.exp(3 * gen.nextGaussian());    }}
public void mahout_f7415_0() throws Exception
{    Normal dist = new Normal(0, 1, RandomUtils.getRandom());    dist.setState(1.3, 5.9);    DistributionChecks.checkDistribution(dist, breaks, 1.3, 5.9, 10000);}
public void mahout_f7416_0()
{    assertEquals("org.apache.mahout.math.jet.random.Normal(m=1.300000, sd=5.900000)", new Normal(1.3, 5.9, null).toString());}
public void mahout_f7417_0()
{    double[] x = { 1, 2, 5, 10, 20, 50, 100 };    double[] expected = { 1.000000e+00, 1.000000e+00, 2.400000e+01, 3.628800e+05, 1.216451e+17, 6.082819e+62, 9.332622e+155 };    for (int i = 0; i < x.length; i++) {        assertEquals(expected[i], Gamma.gamma(x[i]), expected[i] * 1.0e-5);        assertEquals(gammaInteger(x[i]), Gamma.gamma(x[i]), expected[i] * 1.0e-5);        assertEquals(gammaInteger(x[i]), Math.exp(Gamma.logGamma(x[i])), expected[i] * 1.0e-5);    }}
public void mahout_f7418_0()
{    double[] x = { -30.3, -20.7, -10.5, -1.1, 0.5, 0.99, -0.999 };    double[] expected = { -5.243216e-33, -1.904051e-19, -2.640122e-07, 9.714806e+00, 1.772454e+00, 1.005872e+00, -1.000424e+03 };    for (int i = 0; i < x.length; i++) {        assertEquals(expected[i], Gamma.gamma(x[i]), Math.abs(expected[i] * 1.0e-5));        assertEquals(Math.abs(expected[i]), Math.abs(Math.exp(Gamma.logGamma(x[i]))), Math.abs(expected[i] * 1.0e-5));    }}
private static double mahout_f7419_0(double x)
{    double r = 1;    for (int i = 2; i < x; i++) {        r *= i;    }    return r;}
public void mahout_f7420_0()
{    assertEquals(factorial(4), 4 * 3 * 2, 0);    assertEquals(factorial(4), Gamma.gamma(5), 0);    assertEquals(factorial(14), Gamma.gamma(15), 0);    assertEquals(factorial(34), Gamma.gamma(35), 1.0e-15 * factorial(34));    assertEquals(factorial(44), Gamma.gamma(45), 1.0e-15 * factorial(44));    assertEquals(-6.884137e-40 + 3.508309e-47, Gamma.gamma(-35.1), 1.0e-52);    assertEquals(-3.915646e-41 - 3.526813e-48 - 1.172516e-55, Gamma.gamma(-35.9), 1.0e-52);    assertEquals(-2000000000.577215, Gamma.gamma(-0.5e-9), 1.0e-15 * 2000000000.577215);    assertEquals(1999999999.422784, Gamma.gamma(0.5e-9), 1.0e-15 * 1999999999.422784);    assertEquals(1.324296658017984e+252, Gamma.gamma(146.1), 1.0e-10 * 1.324296658017984e+252);    for (double x : new double[] { 5, 15, 35, 45, -35.1, -35.9, -0.5e-9, 0.5e-9, 146.1 }) {        double ref = Math.log(Math.abs(Gamma.gamma(x)));        double actual = Gamma.logGamma(x);        double diff = Math.abs(ref - actual) / ref;        assertEquals("gamma versus logGamma at " + x + " (diff = " + diff + ')', 0, (ref - actual) / ref, 1.0e-8);    }}
private static double mahout_f7421_0(int n)
{    double r = 1;    for (int i = 2; i <= n; i++) {        r *= i;    }    return r;}
public void mahout_f7422_0()
{    Random r = RandomUtils.getRandom();    for (int i = 0; i < 200; i++) {        double alpha = -50 * Math.log1p(-r.nextDouble());        double beta = -50 * Math.log1p(-r.nextDouble());        double ref = Math.exp(Gamma.logGamma(alpha) + Gamma.logGamma(beta) - Gamma.logGamma(alpha + beta));        double actual = Gamma.beta(alpha, beta);        double err = (ref - actual) / ref;        assertEquals("beta at (" + alpha + ", " + beta + ") relative error = " + err, 0, err, 1.0e-10);    }}
public void mahout_f7423_0() throws IOException
{    Splitter onComma = Splitter.on(",").trimResults();    InputSupplier<InputStreamReader> input = Resources.newReaderSupplier(Resources.getResource("beta-test-data.csv"), Charsets.UTF_8);    boolean header = true;    for (String line : CharStreams.readLines(input)) {        if (header) {                        header = false;        } else {            Iterable<String> values = onComma.split(line);            double alpha = Double.parseDouble(Iterables.get(values, 0));            double beta = Double.parseDouble(Iterables.get(values, 1));            double x = Double.parseDouble(Iterables.get(values, 2));            double ref = Double.parseDouble(Iterables.get(values, 3));            double actual = Gamma.incompleteBeta(alpha, beta, x);            assertEquals(alpha + "," + beta + ',' + x, ref, actual, ref * 1.0e-5);        }    }}
public void mahout_f7424_0()
{            double[] ref = { 2.866516e-07, 4.816530e-07, 8.013697e-07, 1.320248e-06, 2.153811e-06, 3.479323e-06, 5.565743e-06, 8.816559e-06, 1.383023e-05, 2.148428e-05, 3.305072e-05, 5.035210e-05, 7.596947e-05, 1.135152e-04, 1.679855e-04, 2.462079e-04, 3.574003e-04, 5.138562e-04, 7.317683e-04, 1.032198e-03, 1.442193e-03, 1.996034e-03, 2.736602e-03, 3.716808e-03, 5.001037e-03, 6.666521e-03, 8.804535e-03, 1.152131e-02, 1.493850e-02, 1.919309e-02, 2.443656e-02, 3.083320e-02, 3.855748e-02, 4.779035e-02, 5.871452e-02, 7.150870e-02, 8.634102e-02, 1.033618e-01, 1.226957e-01, 1.444345e-01, 1.686293e-01, 1.952845e-01, 2.243525e-01, 2.557301e-01, 2.892574e-01, 3.247181e-01, 3.618436e-01, 4.003175e-01, 4.397847e-01, 4.798600e-01, 5.201400e-01, 5.602153e-01, 5.996825e-01, 6.381564e-01, 6.752819e-01, 7.107426e-01, 7.442699e-01, 7.756475e-01, 8.047155e-01, 8.313707e-01, 8.555655e-01, 8.773043e-01, 8.966382e-01, 9.136590e-01, 9.284913e-01, 9.412855e-01, 9.522096e-01, 9.614425e-01, 9.691668e-01, 9.755634e-01, 9.808069e-01, 9.850615e-01, 9.884787e-01, 9.911955e-01, 9.933335e-01, 9.949990e-01, 9.962832e-01, 9.972634e-01, 9.980040e-01, 9.985578e-01, 9.989678e-01, 9.992682e-01, 9.994861e-01, 9.996426e-01, 9.997538e-01, 9.998320e-01, 9.998865e-01, 9.999240e-01, 9.999496e-01, 9.999669e-01, 9.999785e-01, 9.999862e-01, 9.999912e-01, 9.999944e-01, 9.999965e-01, 9.999978e-01, 9.999987e-01, 9.999992e-01, 9.999995e-01, 9.999997e-01 };    assertEquals(0.682689492137 / 2 + 0.5, Probability.normal(1), 1.0e-7);    int i = 0;    for (double x = -5; x <= 5.005; x += 10.0 / 99) {        assertEquals("Test 1 cdf function at " + x, ref[i], Probability.normal(x), 1.0e-6);        assertEquals("Test 2 cdf function at " + x, ref[i], Probability.normal(12, 1, x + 12), 1.0e-6);        assertEquals("Test 3 cdf function at " + x, ref[i], Probability.normal(12, 0.25, x / 2.0 + 12), 1.0e-6);        i++;    }}
public void mahout_f7425_0()
{                            double[][] ref = new double[5][];    ref[0] = new double[] { 0.00000000, 0.01010101, 0.02020202, 0.03030303, 0.04040404, 0.05050505, 0.06060606, 0.07070707, 0.08080808, 0.09090909, 0.10101010, 0.11111111, 0.12121212, 0.13131313, 0.14141414, 0.15151515, 0.16161616, 0.17171717, 0.18181818, 0.19191919, 0.20202020, 0.21212121, 0.22222222, 0.23232323, 0.24242424, 0.25252525, 0.26262626, 0.27272727, 0.28282828, 0.29292929, 0.30303030, 0.31313131, 0.32323232, 0.33333333, 0.34343434, 0.35353535, 0.36363636, 0.37373737, 0.38383838, 0.39393939, 0.40404040, 0.41414141, 0.42424242, 0.43434343, 0.44444444, 0.45454545, 0.46464646, 0.47474747, 0.48484848, 0.49494949, 0.50505051, 0.51515152, 0.52525253, 0.53535354, 0.54545455, 0.55555556, 0.56565657, 0.57575758, 0.58585859, 0.59595960, 0.60606061, 0.61616162, 0.62626263, 0.63636364, 0.64646465, 0.65656566, 0.66666667, 0.67676768, 0.68686869, 0.69696970, 0.70707071, 0.71717172, 0.72727273, 0.73737374, 0.74747475, 0.75757576, 0.76767677, 0.77777778, 0.78787879, 0.79797980, 0.80808081, 0.81818182, 0.82828283, 0.83838384, 0.84848485, 0.85858586, 0.86868687, 0.87878788, 0.88888889, 0.89898990, 0.90909091, 0.91919192, 0.92929293, 0.93939394, 0.94949495, 0.95959596, 0.96969697, 0.97979798, 0.98989899, 1.00000000 };    ref[1] = new double[] { 0.0000000000, 0.0001020304, 0.0004081216, 0.0009182736, 0.0016324865, 0.0025507601, 0.0036730946, 0.0049994898, 0.0065299459, 0.0082644628, 0.0102030405, 0.0123456790, 0.0146923783, 0.0172431385, 0.0199979594, 0.0229568411, 0.0261197837, 0.0294867871, 0.0330578512, 0.0368329762, 0.0408121620, 0.0449954086, 0.0493827160, 0.0539740843, 0.0587695133, 0.0637690032, 0.0689725538, 0.0743801653, 0.0799918376, 0.0858075707, 0.0918273646, 0.0980512193, 0.1044791348, 0.1111111111, 0.1179471483, 0.1249872462, 0.1322314050, 0.1396796245, 0.1473319049, 0.1551882461, 0.1632486481, 0.1715131109, 0.1799816345, 0.1886542190, 0.1975308642, 0.2066115702, 0.2158963371, 0.2253851648, 0.2350780533, 0.2449750026, 0.2550760127, 0.2653810836, 0.2758902153, 0.2866034078, 0.2975206612, 0.3086419753, 0.3199673503, 0.3314967860, 0.3432302826, 0.3551678400, 0.3673094582, 0.3796551372, 0.3922048771, 0.4049586777, 0.4179165391, 0.4310784614, 0.4444444444, 0.4580144883, 0.4717885930, 0.4857667585, 0.4999489848, 0.5143352719, 0.5289256198, 0.5437200286, 0.5587184981, 0.5739210285, 0.5893276196, 0.6049382716, 0.6207529844, 0.6367717580, 0.6529945924, 0.6694214876, 0.6860524436, 0.7028874605, 0.7199265381, 0.7371696766, 0.7546168758, 0.7722681359, 0.7901234568, 0.8081828385, 0.8264462810, 0.8449137843, 0.8635853484, 0.8824609734, 0.9015406591, 0.9208244057, 0.9403122130, 0.9600040812, 0.9799000102, 1.0000000000 };    ref[2] = new double[] { 0.000000000, 0.001489698, 0.005799444, 0.012698382, 0.021966298, 0.033393335, 0.046779694, 0.061935356, 0.078679798, 0.096841712, 0.116258735, 0.136777178, 0.158251755, 0.180545326, 0.203528637, 0.227080061, 0.251085352, 0.275437393, 0.300035957, 0.324787463, 0.349604743, 0.374406809, 0.399118623, 0.423670875, 0.447999763, 0.472046772, 0.495758466, 0.519086275, 0.541986291, 0.564419069, 0.586349424, 0.607746242, 0.628582288, 0.648834019, 0.668481403, 0.687507740, 0.705899486, 0.723646086, 0.740739801, 0.757175549, 0.772950746, 0.788065147, 0.802520695, 0.816321377, 0.829473074, 0.841983426, 0.853861691, 0.865118615, 0.875766302, 0.885818092, 0.895288433, 0.904192771, 0.912547431, 0.920369513, 0.927676778, 0.934487554, 0.940820632, 0.946695177, 0.952130629, 0.957146627, 0.961762916, 0.965999275, 0.969875437, 0.973411020, 0.976625460, 0.979537944, 0.982167353, 0.984532203, 0.986650598, 0.988540173, 0.990218056, 0.991700827, 0.993004475, 0.994144371, 0.995135237, 0.995991117, 0.996725360, 0.997350600, 0.997878739, 0.998320942, 0.998687627, 0.998988463, 0.999232371, 0.999427531, 0.999581387, 0.999700663, 0.999791377, 0.999858864, 0.999907798, 0.999942219, 0.999965567, 0.999980718, 0.999990021, 0.999995342, 0.999998111, 0.999999376, 0.999999851, 0.999999980, 0.999999999, 1.000000000 };    ref[3] = new double[] { 0.0000000, 0.5858072, 0.6684658, 0.7201859, 0.7578936, 0.7873991, 0.8114552, 0.8316029, 0.8487998, 0.8636849, 0.8767081, 0.8881993, 0.8984080, 0.9075280, 0.9157131, 0.9230876, 0.9297536, 0.9357958, 0.9412856, 0.9462835, 0.9508414, 0.9550044, 0.9588113, 0.9622963, 0.9654896, 0.9684178, 0.9711044, 0.9735707, 0.9758356, 0.9779161, 0.9798276, 0.9815839, 0.9831977, 0.9846805, 0.9860426, 0.9872936, 0.9884422, 0.9894965, 0.9904638, 0.9913509, 0.9921638, 0.9929085, 0.9935900, 0.9942134, 0.9947832, 0.9953034, 0.9957779, 0.9962104, 0.9966041, 0.9969621, 0.9972872, 0.9975821, 0.9978492, 0.9980907, 0.9983088, 0.9985055, 0.9986824, 0.9988414, 0.9989839, 0.9991113, 0.9992251, 0.9993265, 0.9994165, 0.9994963, 0.9995668, 0.9996288, 0.9996834, 0.9997311, 0.9997727, 0.9998089, 0.9998401, 0.9998671, 0.9998901, 0.9999098, 0.9999265, 0.9999406, 0.9999524, 0.9999622, 0.9999703, 0.9999769, 0.9999823, 0.9999866, 0.9999900, 0.9999927, 0.9999947, 0.9999963, 0.9999975, 0.9999983, 0.9999989, 0.9999993, 0.9999996, 0.9999998, 0.9999999, 0.9999999, 1.0000000, 1.0000000, 1.0000000, 1.0000000, 1.0000000, 1.0000000 };    ref[4] = new double[] { 0.00000000, 0.01908202, 0.02195656, 0.02385194, 0.02530810, 0.02650923, 0.02754205, 0.02845484, 0.02927741, 0.03002959, 0.03072522, 0.03137444, 0.03198487, 0.03256240, 0.03311171, 0.03363655, 0.03414001, 0.03462464, 0.03509259, 0.03554568, 0.03598550, 0.03641339, 0.03683054, 0.03723799, 0.03763667, 0.03802739, 0.03841091, 0.03878787, 0.03915890, 0.03952453, 0.03988529, 0.04024162, 0.04059396, 0.04094272, 0.04128827, 0.04163096, 0.04197113, 0.04230909, 0.04264515, 0.04297958, 0.04331268, 0.04364471, 0.04397592, 0.04430658, 0.04463693, 0.04496722, 0.04529770, 0.04562860, 0.04596017, 0.04629265, 0.04662629, 0.04696134, 0.04729804, 0.04763666, 0.04797747, 0.04832073, 0.04866673, 0.04901578, 0.04936816, 0.04972422, 0.05008428, 0.05044871, 0.05081789, 0.05119222, 0.05157213, 0.05195809, 0.05235059, 0.05275018, 0.05315743, 0.05357298, 0.05399753, 0.05443184, 0.05487673, 0.05533315, 0.05580212, 0.05628480, 0.05678247, 0.05729660, 0.05782885, 0.05838111, 0.05895557, 0.05955475, 0.06018161, 0.06083965, 0.06153300, 0.06226670, 0.06304685, 0.06388102, 0.06477877, 0.06575235, 0.06681788, 0.06799717, 0.06932077, 0.07083331, 0.07260394, 0.07474824, 0.07748243, 0.08129056, 0.08771055, 1.00000000 };    double[] alpha = { 1.0, 2.0, 2.0, 0.2, 0.2 };    double[] beta = { 1.0, 1.0, 5.0, 5.0, 0.01 };    for (int j = 0; j < 4; j++) {        for (int i = 0; i < 100; i++) {            double x = i / 99.0;            String p = String.format(Locale.ENGLISH, "pbeta(q=%6.4f, shape1=%5.3f shape2=%5.3f) = %.8f", x, alpha[j], beta[j], ref[j][i]);            assertEquals(p, ref[j][i], Probability.beta(alpha[j], beta[j], x), 1.0e-7);        }    }}
public void mahout_f7426_0()
{    double[] xValues = { 1.1, 2.1, 3.1, 4.1, 5.1, 20.1, 100.1, -0.9 };    double[] ref = { -0.04987244, 0.04543774, 0.78737508, 1.91877719, 3.32976417, 39.63719250, 359.59427179, 2.35807317 };    for (int i = 0; i < xValues.length; i++) {        double x = xValues[i];        assertEquals(ref[i], Gamma.logGamma(x), 1.0e-7);    }}
public void mahout_f7427_0()
{    ObjectArrayList<String> list = new ObjectArrayList<>();    assertTrue(list.isEmpty());    assertEquals(0, list.size());    list.add("1");    list.add("2");    list.add("3");    assertEquals(3, list.size());}
public void mahout_f7428_0()
{    ObjectArrayList<String> list = new ObjectArrayList<>(100);    assertTrue(list.isEmpty());    assertEquals(0, list.size());}
public void mahout_f7429_0()
{    ObjectArrayList<String> list = new ObjectArrayList<>(new String[] { "1", "2", "3" });    assertFalse(list.isEmpty());    assertEquals(3, list.size());}
public void mahout_f7430_0() throws Exception
{    testTempDir = null;    RandomUtils.useTestSeed();}
public void mahout_f7431_0() throws Exception
{    if (testTempDir != null) {        new DeletingVisitor().accept(testTempDir);    }}
protected final File mahout_f7432_0() throws IOException
{    if (testTempDir == null) {        String systemTmpDir = System.getProperty("mahout.test.directory");        if (systemTmpDir == null) {            systemTmpDir = "target/";            systemTmpDir += "test-data";        }        long simpleRandomLong = (long) (Long.MAX_VALUE * Math.random());        testTempDir = new File(systemTmpDir, "mahout-" + getClass().getSimpleName() + '-' + simpleRandomLong);        if (!testTempDir.mkdirs()) {            throw new IOException("Could not create " + testTempDir);        }        testTempDir.deleteOnExit();    }    return testTempDir;}
protected final File mahout_f7433_0(String name) throws IOException
{    return getTestTempFileOrDir(name, false);}
protected final File mahout_f7434_0(String name) throws IOException
{    return getTestTempFileOrDir(name, true);}
private File mahout_f7435_0(String name, boolean dir) throws IOException
{    File f = new File(getTestTempDir(), name);    f.deleteOnExit();    if (dir && !f.mkdirs()) {        throw new IOException("Could not make directory " + f);    }    return f;}
public boolean mahout_f7436_0(File f)
{    if (!f.isFile()) {        f.listFiles(this);    }    f.delete();    return false;}
public void mahout_f7437_0()
{    Matrix m = Matrices.functionalMatrixView(5, 6, new IntIntFunction() {        @Override        public double apply(int row, int col) {            assertTrue(row < 5);            assertTrue(col < 6);            return row + col;        }    });            assertEquals(135, m.aggregate(Functions.PLUS, Functions.IDENTITY), 1e-10);}
public double mahout_f7438_0(int row, int col)
{    assertTrue(row < 5);    assertTrue(col < 6);    return row + col;}
public void mahout_f7439_0()
{    Matrix m = Matrices.gaussianView(5, 6, 1234L);    Matrix controlM = new DenseMatrix(5, 6).assign(m);    System.out.printf("M=\n%s\n", m);    System.out.printf("controlM=\n%s\n", controlM);    Matrix mtm = Matrices.transposedView(m).times(m);    Matrix controlMtm = controlM.transpose().times(controlM);    System.out.printf("M'M=\n%s\n", mtm);    Matrix diff = mtm.minus(controlMtm);    assertEquals(0, diff.aggregate(Functions.PLUS, Functions.ABS), 1e-10);}
public void mahout_f7440_0()
{    Matrix m = new SparseMatrix(1000, 1000);    m.set(1, 1, 33.0);    Matrix mt = Matrices.transposedView(m);    assertTrue(mt.viewColumn(0).isDense() == m.viewRow(0).isDense());    assertTrue(mt.viewRow(0).isDense() == m.viewColumn(0).isDense());    m = new DenseMatrix(10, 10);    m.set(1, 1, 33.0);    mt = Matrices.transposedView(m);    assertTrue(mt.viewColumn(0).isDense());    assertTrue(mt.viewRow(0).isDense());}
public void mahout_f7441_0()
{    Matrix m1 = Matrices.uniformView(5, 6, 1234);    Matrix m2 = Matrices.uniformView(5, 6, 1234);    for (int row = 0; row < m1.numRows(); row++) {        for (int col = 0; col < m1.numCols(); col++) {            assertTrue(m1.getQuick(row, col) >= 0.0);            assertTrue(m1.getQuick(row, col) < 1.0);        }    }    Matrix diff = m1.minus(m2);    assertEquals(0, diff.aggregate(Functions.PLUS, Functions.ABS), 1e-10);}
public void mahout_f7442_0()
{    Matrix m1 = Matrices.symmetricUniformView(5, 6, 1234);    Matrix m2 = Matrices.symmetricUniformView(5, 6, 1234);    for (int row = 0; row < m1.numRows(); row++) {        for (int col = 0; col < m1.numCols(); col++) {            assertTrue(m1.getQuick(row, col) >= -1.0);            assertTrue(m1.getQuick(row, col) < 1.0);        }    }    Matrix diff = m1.minus(m2);    assertEquals(0, diff.aggregate(Functions.PLUS, Functions.ABS), 1e-10);}
public void mahout_f7443_0()
{    Matrix m1 = Matrices.gaussianView(5, 6, 1234);    Matrix m2 = Matrices.gaussianView(5, 6, 1234);    Matrix diff = m1.minus(m2);    assertEquals(0, diff.aggregate(Functions.PLUS, Functions.ABS), 1e-10);}
public void mahout_f7444_0() throws Exception
{    super.setUp();    test = matrixFactory(values);}
public void mahout_f7445_0()
{    assertEquals("row cardinality", values.length, test.rowSize());    assertEquals("col cardinality", values[0].length, test.columnSize());}
public void mahout_f7446_0()
{    Matrix copy = test.clone();    assertSame("wrong class", copy.getClass(), test.getClass());    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', test.getQuick(row, col), copy.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7447_0()
{    double oldValue = 1.23;    double newValue = 2.34;    double[][] values = { { oldValue, 3 }, { 3, 5 }, { 7, 9 } };    Matrix matrix = matrixFactory(values);    Matrix clone = matrix.clone();    clone.set(0, 0, newValue);        assertEquals("Matrix clone is not independent of the original", oldValue, matrix.get(0, 0), EPSILON);}
public void mahout_f7448_0()
{    Iterator<MatrixSlice> it = test.iterator();    MatrixSlice m;    while (it.hasNext() && (m = it.next()) != null) {        Vector v = m.vector();        Vector w = test instanceof SparseColumnMatrix ? test.viewColumn(m.index()) : test.viewRow(m.index());        assertEquals("iterator: " + v + ", randomAccess: " + w, v, w);    }}
public void mahout_f7449_0()
{    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', values[row][col], test.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7450_0()
{    Matrix like = test.like();    assertSame("type", like.getClass(), test.getClass());    assertEquals("rows", test.rowSize(), like.rowSize());    assertEquals("columns", test.columnSize(), like.columnSize());}
public void mahout_f7451_0()
{    Matrix like = test.like(4, 4);    assertSame("type", like.getClass(), test.getClass());    assertEquals("rows", 4, like.rowSize());    assertEquals("columns", 4, like.columnSize());}
public void mahout_f7452_0()
{    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            test.setQuick(row, col, 1.23);            assertEquals("value[" + row + "][" + col + ']', 1.23, test.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7453_0()
{    int[] c = test.getNumNondefaultElements();    assertEquals("row size", values.length, c[ROW]);    assertEquals("col size", values[0].length, c[COL]);}
public void mahout_f7454_0()
{    int[] offset = { 1, 1 };    int[] size = { 2, 1 };    Matrix view = test.viewPart(offset, size);    assertEquals(2, view.rowSize());    assertEquals(1, view.columnSize());    for (int row = 0; row < view.rowSize(); row++) {        for (int col = 0; col < view.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', values[row + 1][col + 1], view.get(row, col), EPSILON);        }    }}
public void mahout_f7455_0()
{    int[] offset = { 1, 1 };    int[] size = { 3, 3 };    test.viewPart(offset, size);}
public void mahout_f7456_0()
{    int[] offset = { 1, 1 };    int[] size = { 2, 2 };    test.viewPart(offset, size);}
public void mahout_f7457_0()
{    int[] offset = { -1, -1 };    int[] size = { 2, 2 };    test.viewPart(offset, size);}
public void mahout_f7458_0()
{    test.assign(4.53);    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', 4.53, test.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7459_0()
{    test.assign(new double[3][2]);    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', 0.0, test.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7460_0()
{    test.assign(new double[test.rowSize() + 1][test.columnSize()]);}
public void mahout_f7461_0()
{    Matrix m = test.viewPart(0, 3, 0, 2);        m = m.viewPart(2, 1, 0, 1);    assertEquals(5.5, m.zSum(), 0);}
public void mahout_f7462_0()
{    test.assign(test, Functions.PLUS);    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', 2 * values[row][col], test.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7463_0()
{    test.assign(test.transpose(), Functions.PLUS);}
public void mahout_f7464_0()
{    Matrix value = test.like();    value.assign(test);    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', test.getQuick(row, col), value.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7465_0()
{    test.assign(test.transpose());}
public void mahout_f7466_0()
{    test.assign(Functions.mult(-1));    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', -values[row][col], test.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7467_0()
{    assertEquals(test.columnSize(), test.viewRow(1).size());    assertEquals(test.columnSize(), test.viewRow(2).size());    Random gen = RandomUtils.getRandom();    for (int row = 0; row < test.rowSize(); row++) {        int j = gen.nextInt(test.columnSize());        double old = test.get(row, j);        double v = gen.nextGaussian();        test.viewRow(row).set(j, v);        assertEquals(v, test.get(row, j), 0);        assertEquals(v, test.viewRow(row).get(j), 0);        test.set(row, j, old);        assertEquals(old, test.get(row, j), 0);        assertEquals(old, test.viewRow(row).get(j), 0);    }}
public void mahout_f7468_0()
{    assertEquals(test.rowSize(), test.viewColumn(0).size());    assertEquals(test.rowSize(), test.viewColumn(1).size());    Random gen = RandomUtils.getRandom();    for (int col = 0; col < test.columnSize(); col++) {        int j = gen.nextInt(test.columnSize());        double old = test.get(col, j);        double v = gen.nextGaussian();        test.viewColumn(col).set(j, v);        assertEquals(v, test.get(j, col), 0);        assertEquals(v, test.viewColumn(col).get(j), 0);        test.set(j, col, old);        assertEquals(old, test.get(j, col), 0);        assertEquals(old, test.viewColumn(col).get(j), 0);    }}
public void mahout_f7469_0()
{    Vector v = test.aggregateRows(new VectorFunction() {        @Override        public double apply(Vector v) {            return v.zSum();        }    });    for (int i = 0; i < test.numRows(); i++) {        assertEquals(test.viewRow(i).zSum(), v.get(i), EPSILON);    }}
public double mahout_f7470_0(Vector v)
{    return v.zSum();}
public void mahout_f7471_0()
{    Vector v = test.aggregateColumns(new VectorFunction() {        @Override        public double apply(Vector v) {            return v.zSum();        }    });    for (int i = 0; i < test.numCols(); i++) {        assertEquals(test.viewColumn(i).zSum(), v.get(i), EPSILON);    }}
public double mahout_f7472_0(Vector v)
{    return v.zSum();}
public void mahout_f7473_0()
{    double total = test.aggregate(Functions.PLUS, Functions.IDENTITY);    assertEquals(test.aggregateRows(new VectorFunction() {        @Override        public double apply(Vector v) {            return v.zSum();        }    }).zSum(), total, EPSILON);}
public double mahout_f7474_0(Vector v)
{    return v.zSum();}
public void mahout_f7475_0()
{    Matrix value = test.divide(4.53);    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', values[row][col] / 4.53, value.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7476_0()
{    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', values[row][col], test.get(row, col), EPSILON);        }    }}
public void mahout_f7477_0()
{    for (int row = -1; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            test.get(row, col);        }    }}
public void mahout_f7478_0()
{    for (int row = 0; row < test.rowSize() + 1; row++) {        for (int col = 0; col < test.columnSize(); col++) {            test.get(row, col);        }    }}
public void mahout_f7479_0()
{    Matrix value = test.minus(test);    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', 0.0, value.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7480_0()
{    test.minus(test.transpose());}
public void mahout_f7481_0()
{    Matrix value = test.plus(4.53);    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', values[row][col] + 4.53, value.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7482_0()
{    Matrix value = test.plus(test);    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', values[row][col] * 2, value.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7483_0()
{    test.plus(test.transpose());}
public void mahout_f7484_0()
{    for (int row = -1; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            test.set(row, col, 1.23);        }    }}
public void mahout_f7485_0()
{    for (int row = 0; row < test.rowSize() + 1; row++) {        for (int col = 0; col < test.columnSize(); col++) {            test.set(row, col, 1.23);        }    }}
public void mahout_f7486_0()
{    Matrix value = test.times(4.53);    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', values[row][col] * 4.53, value.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7487_0()
{    Matrix transpose = test.transpose();    Matrix value = test.times(transpose);    assertEquals("rows", test.rowSize(), value.rowSize());    assertEquals("cols", test.rowSize(), value.columnSize());    Matrix expected = new DenseMatrix(new double[][] { { 5.0, 11.0, 17.0 }, { 11.0, 25.0, 39.0 }, { 17.0, 39.0, 61.0 } }).times(1.21);    for (int i = 0; i < expected.numCols(); i++) {        for (int j = 0; j < expected.numRows(); j++) {            assertTrue("Matrix times transpose not correct: " + i + ", " + j + "\nexpected:\n\t" + expected + "\nactual:\n\t" + value, Math.abs(expected.get(i, j) - value.get(i, j)) < 1.0e-12);        }    }    Matrix timestest = new DenseMatrix(10, 1);    /* will throw ArrayIndexOutOfBoundsException exception without MAHOUT-26 */    timestest.transpose().times(timestest);}
public void mahout_f7488_0()
{    Vector vectorA = new DenseVector(vectorAValues);    Vector testTimesVectorA = test.times(vectorA);    Vector expected = new DenseVector(new double[] { 5.0, 11.0, 17.0 });    assertTrue("Matrix times vector not equals: " + vectorA + " != " + testTimesVectorA, expected.minus(testTimesVectorA).norm(2) < 1.0e-12);    test.times(testTimesVectorA);}
public void mahout_f7489_0()
{    Vector vectorA = new DenseVector(vectorAValues);    Vector ttA = test.timesSquared(vectorA);    Vector ttASlow = test.transpose().times(test.times(vectorA));    assertTrue("M'Mv != M.timesSquared(v): " + ttA + " != " + ttASlow, ttASlow.minus(ttA).norm(2) < 1.0e-12);}
public void mahout_f7490_0()
{    Matrix other = test.like(5, 8);    test.times(other);}
public void mahout_f7491_0()
{    Matrix transpose = test.transpose();    assertEquals("rows", test.columnSize(), transpose.rowSize());    assertEquals("cols", test.rowSize(), transpose.columnSize());    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', test.getQuick(row, col), transpose.getQuick(col, row), EPSILON);        }    }}
public void mahout_f7492_0()
{    double sum = test.zSum();    assertEquals("zsum", 23.1, sum, EPSILON);}
public void mahout_f7493_0()
{    double[] data = { 2.1, 3.2 };    test.assignRow(1, new DenseVector(data));    assertEquals("test[1][0]", 2.1, test.getQuick(1, 0), EPSILON);    assertEquals("test[1][1]", 3.2, test.getQuick(1, 1), EPSILON);}
public void mahout_f7494_0()
{    double[] data = { 2.1, 3.2, 4.3 };    test.assignRow(1, new DenseVector(data));}
public void mahout_f7495_0()
{    double[] data = { 2.1, 3.2, 4.3 };    test.assignColumn(1, new DenseVector(data));    assertEquals("test[0][1]", 2.1, test.getQuick(0, 1), EPSILON);    assertEquals("test[1][1]", 3.2, test.getQuick(1, 1), EPSILON);    assertEquals("test[2][1]", 4.3, test.getQuick(2, 1), EPSILON);}
public void mahout_f7496_0()
{    double[] data = { 2.1, 3.2 };    test.assignColumn(1, new DenseVector(data));}
public void mahout_f7497_0()
{    Vector row = test.viewRow(1);    assertEquals("row size", 2, row.getNumNondefaultElements());        Matrix matrix = new SparseMatrix(1, 1);    Vector view = matrix.viewRow(0);    final double value = 1.23;    view.assign(value);        assertEquals("Matrix value", view.getQuick(0), matrix.getQuick(0, 0), EPSILON);}
public void mahout_f7498_0()
{    test.viewRow(-1);}
public void mahout_f7499_0()
{    test.viewRow(5);}
public void mahout_f7500_0()
{    Vector column = test.viewColumn(1);    assertEquals("row size", 3, column.getNumNondefaultElements());}
public void mahout_f7501_0()
{    test.viewColumn(-1);}
public void mahout_f7502_0()
{    test.viewColumn(5);}
public void mahout_f7503_0()
{    Matrix m = matrixFactory(new double[][] { { 1, 3, 4 }, { 5, 2, 3 }, { 1, 4, 2 } });    assertEquals("determinant", 43.0, m.determinant(), EPSILON);}
public void mahout_f7504_0()
{    Matrix m = matrixFactory(new double[][] { { 1, 3, 4 }, { 5, 2, 3 }, { 1, 4, 2 } });    assertNull("row bindings", m.getRowLabelBindings());    assertNull("col bindings", m.getColumnLabelBindings());    Map<String, Integer> rowBindings = new HashMap<>();    rowBindings.put("Fee", 0);    rowBindings.put("Fie", 1);    rowBindings.put("Foe", 2);    m.setRowLabelBindings(rowBindings);    assertEquals("row", rowBindings, m.getRowLabelBindings());    Map<String, Integer> colBindings = new HashMap<>();    colBindings.put("Foo", 0);    colBindings.put("Bar", 1);    colBindings.put("Baz", 2);    m.setColumnLabelBindings(colBindings);    assertEquals("row", rowBindings, m.getRowLabelBindings());    assertEquals("Fee", m.get(0, 1), m.get("Fee", "Bar"), EPSILON);    double[] newrow = { 9, 8, 7 };    m.set("Foe", newrow);    assertEquals("FeeBaz", m.get(0, 2), m.get("Fee", "Baz"), EPSILON);}
public void mahout_f7505_0()
{    Matrix m = matrixFactory(new double[][] { { 1, 3, 4 }, { 5, 2, 3 }, { 1, 4, 2 } });    assertNull("row bindings", m.getRowLabelBindings());    assertNull("col bindings", m.getColumnLabelBindings());    m.set("Fee", "Foo", 1, 2, 9);    assertNotNull("row", m.getRowLabelBindings());    assertNotNull("row", m.getRowLabelBindings());    assertEquals("Fee", 1, m.getRowLabelBindings().get("Fee").intValue());    assertEquals("Fee", 2, m.getColumnLabelBindings().get("Foo").intValue());    assertEquals("FeeFoo", m.get(1, 2), m.get("Fee", "Foo"), EPSILON);    m.get("Fie", "Foe");}
public void mahout_f7506_0()
{    Matrix m = matrixFactory(new double[][] { { 1, 3, 4 }, { 5, 2, 3 }, { 1, 4, 2 } });    assertNull("row bindings", m.getRowLabelBindings());    assertNull("col bindings", m.getColumnLabelBindings());    Map<String, Integer> rowBindings = new HashMap<>();    rowBindings.put("Fee", 0);    rowBindings.put("Fie", 1);    rowBindings.put("Foe", 2);    m.setRowLabelBindings(rowBindings);    assertEquals("row", rowBindings, m.getRowLabelBindings());    Map<String, Integer> colBindings = new HashMap<>();    colBindings.put("Foo", 0);    colBindings.put("Bar", 1);    colBindings.put("Baz", 2);    m.setColumnLabelBindings(colBindings);    assertEquals("col", colBindings, m.getColumnLabelBindings());}
public void mahout_f7507_0()
{    Matrix matrix = new DenseMatrix(5, 3);    Vector column2 = matrix.viewColumn(2);    Matrix outerProduct = column2.cross(column2);    assertEquals(matrix.numRows(), outerProduct.numRows());    assertEquals(matrix.numRows(), outerProduct.numCols());}
public void mahout_f7508_0()
{    Matrix m = new DenseMatrix(20, 30).assign(Functions.random());    try {        m.viewColumn(30);        fail("Should have thrown exception");    } catch (IllegalArgumentException e) {        assertTrue(e.getMessage().startsWith("Index 30 is outside allowable"));    }    try {        m.viewRow(20);        fail("Should have thrown exception");    } catch (IllegalArgumentException e) {        assertTrue(e.getMessage().startsWith("Index 20 is outside allowable"));    }}
public void mahout_f7509_0() throws Exception
{    byte[] bytes = "Now is the time for all good men to come to the aid of their country".getBytes("UTF-8");    int hash = 0;    for (int i = 0; i < bytes.length; i++) {        hash = hash * 31 + (bytes[i] & 0xff);        bytes[i] = (byte) hash;    }        for (int offset = 0; offset < 10; offset++) {        byte[] arr = new byte[bytes.length + offset];        System.arraycopy(bytes, 0, arr, offset, bytes.length);        for (int len = 0; len < bytes.length; len++) {            int h = MurmurHash3.murmurhash3x8632(arr, offset, len, len);            assertEquals(ANSWERS[len], h);        }    }}
public void mahout_f7510_0() throws UnsupportedEncodingException
{    long h1 = MurmurHash.hash64A("abc".getBytes(Charsets.UTF_8), 0);    long h2 = MurmurHash.hash64A("abc ".getBytes(Charsets.UTF_8), 0);    int flipCount = Long.bitCount(h1 ^ h2);    Assert.assertTrue("Small changes should result in lots of bit flips, only found " + flipCount, flipCount > 25);}
public void mahout_f7511_0()
{        Assert.assertEquals(0x9cc9c33498a95efbL, MurmurHash.hash64A("abc".getBytes(Charsets.UTF_8), 0));    Assert.assertEquals(0xd2c8c9b470122bddL, MurmurHash.hash64A("abc def ghi jkl ".getBytes(Charsets.UTF_8), 0));    Assert.assertEquals(0xcd37895736a81cbcL, MurmurHash.hash64A("abc def ghi jkl moreGoo".getBytes(Charsets.UTF_8), 0));}
public void mahout_f7512_0() throws UnsupportedEncodingException
{    int h1 = MurmurHash.hash("abc".getBytes(Charsets.UTF_8), 0);    int h2 = MurmurHash.hash("abc ".getBytes(Charsets.UTF_8), 0);    int flipCount = Integer.bitCount(h1 ^ h2);    Assert.assertTrue("Small changes should result in lots of bit flips, only found " + flipCount, flipCount > 14);}
public void mahout_f7513_0()
{        byte[] key = { 0x4E, (byte) 0xE3, (byte) 0x91, 0x00, 0x10, (byte) 0x8F, (byte) 0xFF };    int[] expected = { 0xeef8be32, 0x8109dec6, 0x9aaf4192, 0xc1bcaf1c, 0x821d2ce4, 0xd45ed1df, 0x6c0357a7, 0x21d4e845, 0xfa97db50, 0x2f1985c8, 0x5d69782a, 0x0d6e4b85, 0xe7d9cf6b, 0x337e6b49, 0xe1606944, 0xccc18ae8 };    for (int i = 0; i < expected.length; i++) {        int expectedHash = expected[i];        int hash = MurmurHash.hash(key, i);        Assert.assertEquals("i = " + i, expectedHash, hash);    }}
public void mahout_f7514_0()
{    byte[] key = new byte[133];    int[] expected = { 0xd743ae0b, 0xf1b461c6, 0xa45a6ceb, 0xdb15e003, 0x877721a4, 0xc30465f1, 0xfb658ba4, 0x1adf93b2, 0xe40a7931, 0x3da52db0, 0xbf523511, 0x1efaf273, 0xe628c1dd, 0x9a0344df, 0x901c99fc, 0x5ae1aa44 };    for (int i = 0; i < 16; i++) {                setKey(key, i);        int expectedHash = expected[i];        int hash = MurmurHash.hash(key, 0x1234ABCD);        Assert.assertEquals("i = " + i, expectedHash, hash);    }}
public void mahout_f7515_0()
{    int[] expected = { 0xa0c72f8e, 0x29c2f97e, 0x00ca8bba, 0x88387876, 0xe203ce49, 0x58d75952, 0xab84febe, 0x98153c65, 0xcbb38375, 0x6ea1a28b, 0x9afa8f55, 0xfb890eb6, 0x9516cc49, 0x6408a8eb, 0xbb12d3e6, 0x00fb7519 };        for (int i = 0; i < 16; i++) {        byte[] key = new byte[i];        setKey(key, i);        int expectedHash = expected[i];        int hash = MurmurHash.hash(key, 0x7870AAFF);        Assert.assertEquals("i = " + i, expectedHash, hash);    }}
private static void mahout_f7516_0(byte[] key, int start)
{    for (int i = 0; i < key.length; i++) {        key[i] = (byte) ((start + i) & 0xFF);    }}
public void mahout_f7517_0()
{    Matrix x = new DenseMatrix(3, 3);    x.viewRow(0).assign(new double[] { 1, 2, 3 });    x.viewRow(1).assign(new double[] { 2, 4, 6 });    x.viewRow(2).assign(new double[] { 3, 6, 9 });    OldQRDecomposition qr = new OldQRDecomposition(x);    assertFalse(qr.hasFullRank());    assertEquals(0, new DenseVector(new double[] { 3.741657, 7.483315, 11.22497 }).aggregate(qr.getR().viewRow(0), Functions.PLUS, new DoubleDoubleFunction() {        @Override        public double apply(double arg1, double arg2) {            return Math.abs(arg1) - Math.abs(arg2);        }    }), 1.0e-5);}
public double mahout_f7518_0(double arg1, double arg2)
{    return Math.abs(arg1) - Math.abs(arg2);}
public void mahout_f7519_0()
{    Matrix x = matrix();    OldQRDecomposition qr = new OldQRDecomposition(x);    assertTrue(qr.hasFullRank());    Matrix rRef = reshape(new double[] { -2.99129686445138, 0, 0, 0, 0, -0.0282260628674372, -2.38850244769059, 0, 0, 0, 0.733739310355871, 1.48042000631646, 2.29051263117895, 0, 0, -0.0394082168269326, 0.282829484207801, -0.00438521041803086, -2.90823198084203, 0, 0.923669647838536, 1.76679276072492, 0.637690104222683, -0.225890909498753, -1.35732293800944 }, 5, 5);    Matrix r = qr.getR();    assertEquals(rRef, r, 1.0e-8);    Matrix qRef = reshape(new double[] { -0.165178287646573, 0.0510035857637869, 0.13985915987379, -0.120173729496501, -0.453198314345324, 0.644400679630493, -0.503117990820608, 0.24968739845381, 0.323968339146224, -0.465266080134262, 0.276508948773268, -0.687909700644343, 0.0544048888907195, -0.0166677718378263, 0.171309755790717, 0.310339001630029, 0.674790532821663, 0.0058166082200493, -0.381707516461884, 0.300504956413142, -0.105751091334003, 0.410450870871096, 0.31113446615821, 0.179338172684956, 0.361951807617901, 0.763921725548796, 0.380327892605634, -0.287274944594054, 0.0311604042556675, 0.0386096858143961, 0.0387156960650472, -0.232975755728917, 0.0358178276684149, 0.173105775703199, 0.327321867815603, 0.328671945345279, -0.36015879836344, -0.444261660176044, 0.09438499563253, 0.646216148583769 }, 8, 5);    printMatrix("qRef", qRef);    Matrix q = qr.getQ();    printMatrix("q", q);    assertEquals(qRef, q, 1.0e-8);    Matrix x1 = qr.solve(reshape(new double[] { -0.0178247686747641, 0.68631714634098, -0.335464858468858, 1.50249941751569, -0.669901640772149, -0.977025038942455, -1.18857546169856, -1.24792900492054 }, 8, 1));    Matrix xref = reshape(new double[] { -0.0127440093664874, 0.655825940180799, -0.100755415991702, -0.0349559562697406, -0.190744297762028 }, 5, 1);    printMatrix("x1", x1);    printMatrix("xref", xref);    assertEquals(xref, x1, 1.0e-8);}
public void mahout_f7520_0()
{    Matrix x = matrix().transpose();    OldQRDecomposition qr = new OldQRDecomposition(x);    assertFalse(qr.hasFullRank());    Matrix rActual = qr.getR();    Matrix rRef = reshape(new double[] { -2.42812464965842, 0, 0, 0, 0, 0.303587286111356, -2.91663643494775, 0, 0, 0, -0.201812474153156, -0.765485720168378, 1.09989373598954, 0, 0, 1.47980701097885, -0.637545820524326, -1.55519859337935, 0.844655127991726, 0, 0.0248883129453161, 0.00115010570270549, -0.236340588891252, -0.092924118200147, 1.42910099545547, -1.1678472412429, 0.531245845248056, 0.351978196071514, -1.03241474816555, -2.20223861735426, -0.887809959067632, 0.189731251982918, -0.504321849233586, 0.490484123999836, 1.21266692336743, -0.633888169775463, 1.04738559065986, 0.284041239547031, 0.578183510077156, -0.942314870832456 }, 5, 8);    printMatrix("rRef", rRef);    printMatrix("rActual", rActual);    assertEquals(rRef, rActual, 1.0e-8);    Matrix qRef = reshape(new double[] { -0.203489262374627, 0.316761677948356, -0.784155643293468, 0.394321494579, -0.29641971170211, 0.0311283614803723, -0.34755265020736, 0.137138511478328, 0.848579887681972, 0.373287266507375, -0.39603700561249, -0.787812566647329, -0.377864833067864, -0.275080943427399, 0.0636764674878229, 0.0763976893309043, -0.318551137554327, 0.286407036668598, 0.206004127289883, -0.876482672226889, 0.89159476695423, -0.238213616975551, -0.376141107880836, -0.0794701657055114, 0.0227025098210165 }, 5, 5);    Matrix q = qr.getQ();    printMatrix("qRef", qRef);    printMatrix("q", q);    assertEquals(qRef, q, 1.0e-8);    Matrix x1 = qr.solve(b());    Matrix xRef = reshape(new double[] { -0.182580239668147, -0.437233627652114, 0.138787653097464, 0.672934739896228, -0.131420217069083, 0, 0, 0 }, 8, 1);    printMatrix("xRef", xRef);    printMatrix("x", x1);    assertEquals(xRef, x1, 1.0e-8);}
private static void mahout_f7521_0(Matrix ref, Matrix actual, double epsilon)
{    assertEquals(0, ref.minus(actual).aggregate(Functions.MAX, Functions.ABS), epsilon);}
private static void mahout_f7522_0(String name, Matrix m)
{    int rows = m.numRows();    int columns = m.numCols();    System.out.printf("%s - %d x %d\n", name, rows, columns);    for (int i = 0; i < rows; i++) {        for (int j = 0; j < columns; j++) {            System.out.printf("%10.5f", m.get(i, j));        }        System.out.printf("\n");    }    System.out.printf("\n");    System.out.printf("\n");}
private static Matrix mahout_f7523_0()
{    double[] values = { 0.494097293912641, -0.152566866170993, -0.418360266395271, 0.359475300232312, 1.35565069667582, -1.92759373242903, 1.50497526839076, -0.746889132087904, -0.769136838293565, 1.10984954080986, -0.664389974392489, 1.6464660350229, -0.11715420616969, 0.0216221197371269, -0.394972730980765, -0.748293157213142, 1.90402764664962, -0.638042862848559, -0.362336344669668, -0.418261074380526, -0.494211543128429, 1.38828971158414, 0.597110366867923, 1.05341387608687, -0.957461740877418, -2.35528802598249, -1.03171458944128, 0.644319090271635, -0.0569108993041965, -0.14419465550881, -0.0456801828174936, 0.754694392571835, 0.719744008628535, -1.17873249802301, -0.155887528905918, -1.5159868405466, 0.0918931582603128, 1.42179027361583, -0.100495054250176, 0.0687986548485584 };    return reshape(values, 8, 5);}
private static Matrix mahout_f7524_0(double[] values, int rows, int columns)
{    Matrix m = new DenseMatrix(rows, columns);    int i = 0;    for (double v : values) {        m.set(i % rows, i / rows, v);        i++;    }    return m;}
private static Matrix mahout_f7525_0()
{    return reshape(new double[] { -0.0178247686747641, 0.68631714634098, -0.335464858468858, 1.50249941751569, -0.669901640772149 }, 5, 1);}
public void mahout_f7526_0()
{    Vector v = randomVector();    int[] pivot = pivot();    Vector pvv = new PermutedVectorView(v, pivot);        for (int i = 0; i < 20; i++) {        assertEquals("Element " + i, v.get(pivot[i]), pvv.get(i), 0);    }        pvv.set(6, 321);    v.set(9, 512);        for (int i = 0; i < 20; i++) {        assertEquals("Element " + i, v.get(pivot[i]), pvv.get(i), 0);    }}
public void mahout_f7527_0()
{    int[] pivot = pivot();    int[] unpivot = unpivot();    Vector v = randomVector();    PermutedVectorView pvv = new PermutedVectorView(v, pivot);        assertEquals(v.zSum(), pvv.zSum(), 0);    assertEquals(v.getNumNondefaultElements(), pvv.getNumNondefaultElements());    v.set(11, 0);    assertEquals(v.getNumNondefaultElements(), pvv.getNumNondefaultElements());    Iterator<Vector.Element> vi = pvv.iterator();    int i = 0;    while (vi.hasNext()) {        Vector.Element e = vi.next();        assertEquals("Index " + i, i, pivot[e.index()]);        assertEquals("Reverse Index " + i, unpivot[i], e.index());        assertEquals("Self-value " + i, e.get(), pvv.get(e.index()), 0);                assertEquals("Value " + i, v.get(i), e.get(), 0);        i++;    }}
private static int[] mahout_f7528_0()
{    return new int[] { 11, 7, 10, 9, 8, 3, 17, 0, 19, 13, 12, 1, 5, 6, 16, 2, 4, 14, 18, 15 };}
private static int[] mahout_f7529_0()
{    int[] pivot = pivot();    int[] unpivot = new int[20];    for (int i = 0; i < 20; i++) {        unpivot[pivot[i]] = i;    }    return unpivot;}
private static Vector mahout_f7530_0()
{    Vector v = new DenseVector(20);    v.assign(new DoubleFunction() {        private final Random gen = RandomUtils.getRandom();        @Override        public double apply(double arg1) {            return gen.nextDouble();        }    });    return v;}
public double mahout_f7531_0(double arg1)
{    return gen.nextDouble();}
public Matrix mahout_f7532_0(double[][] values)
{    Matrix base = new DenseMatrix(values);                PivotedMatrix pm = new PivotedMatrix(base.like());    pm.swap(0, 1);    pm.swapRows(1, 2);    pm.assign(base);    return pm;}
public void mahout_f7533_0()
{    Matrix m = new DenseMatrix(10, 10);    for (int i = 0; i < 10; i++) {        for (int j = 0; j < 10; j++) {            m.set(i, j, 10 * i + j);        }    }    PivotedMatrix pm = new PivotedMatrix(m);    pm.swap(3, 5);    assertEquals(0, pm.viewDiagonal().minus(new DenseVector(new double[] { 0, 11, 22, 55, 44, 33, 66, 77, 88, 99 })).norm(1), 1.0e-10);    pm.swap(2, 7);    assertEquals(0, pm.viewDiagonal().minus(new DenseVector(new double[] { 0, 11, 77, 55, 44, 33, 66, 22, 88, 99 })).norm(1), 1.0e-10);    pm.swap(5, 8);    assertEquals(0, pm.viewColumn(4).minus(new DenseVector(new double[] { 4.0, 14.0, 74.0, 54.0, 44.0, 84.0, 64.0, 24.0, 34.0, 94.0 })).norm(1), 1.0e-10);    assertEquals(0, pm.viewDiagonal().minus(new DenseVector(new double[] { 0, 11, 77, 55, 44, 88, 66, 22, 33, 99 })).norm(1), 1.0e-10);}
public void mahout_f7534_0()
{    Matrix a = new DenseMatrix(60, 60).assign(Functions.random());    QRDecomposition qr = new QRDecomposition(a);        double maxIdent = qr.getQ().transpose().times(qr.getQ()).viewDiagonal().assign(Functions.plus(-1)).norm(1);    assertEquals(0, maxIdent, 1.0e-13);        Matrix z = qr.getQ().times(qr.getR()).minus(a);    double maxError = z.aggregate(Functions.MIN, Functions.ABS);    assertEquals(0, maxError, 1.0e-13);}
public void mahout_f7535_0()
{    Matrix x = new DenseMatrix(3, 3);    x.viewRow(0).assign(new double[] { 1, 2, 3 });    x.viewRow(1).assign(new double[] { 2, 4, 6 });    x.viewRow(2).assign(new double[] { 3, 6, 9 });    QRDecomposition qr = new QRDecomposition(x);    assertFalse(qr.hasFullRank());    assertEquals(0, new DenseVector(new double[] { 3.741657, 7.483315, 11.22497 }).aggregate(qr.getR().viewRow(0), Functions.PLUS, new DoubleDoubleFunction() {        @Override        public double apply(double arg1, double arg2) {            return Math.abs(arg1) - Math.abs(arg2);        }    }), 1.0e-5);}
public double mahout_f7536_0(double arg1, double arg2)
{    return Math.abs(arg1) - Math.abs(arg2);}
public void mahout_f7537_0()
{    Matrix x = matrix();    QRDecomposition qr = new QRDecomposition(x);    assertTrue(qr.hasFullRank());    Matrix rRef = reshape(new double[] { -2.99129686445138, 0, 0, 0, 0, -0.0282260628674372, -2.38850244769059, 0, 0, 0, 0.733739310355871, 1.48042000631646, 2.29051263117895, 0, 0, -0.0394082168269326, 0.282829484207801, -0.00438521041803086, -2.90823198084203, 0, 0.923669647838536, 1.76679276072492, 0.637690104222683, -0.225890909498753, -1.35732293800944 }, 5, 5);    Matrix r = qr.getR();        assertEquals(0, r.clone().assign(Functions.ABS).minus(rRef.clone().assign(Functions.ABS)).aggregate(Functions.PLUS, Functions.IDENTITY), 1.0e-12);    Matrix qRef = reshape(new double[] { -0.165178287646573, 0.0510035857637869, 0.13985915987379, -0.120173729496501, -0.453198314345324, 0.644400679630493, -0.503117990820608, 0.24968739845381, 0.323968339146224, -0.465266080134262, 0.276508948773268, -0.687909700644343, 0.0544048888907195, -0.0166677718378263, 0.171309755790717, 0.310339001630029, 0.674790532821663, 0.0058166082200493, -0.381707516461884, 0.300504956413142, -0.105751091334003, 0.410450870871096, 0.31113446615821, 0.179338172684956, 0.361951807617901, 0.763921725548796, 0.380327892605634, -0.287274944594054, 0.0311604042556675, 0.0386096858143961, 0.0387156960650472, -0.232975755728917, 0.0358178276684149, 0.173105775703199, 0.327321867815603, 0.328671945345279, -0.36015879836344, -0.444261660176044, 0.09438499563253, 0.646216148583769 }, 8, 5);    printMatrix("qRef", qRef);    Matrix q = qr.getQ();    printMatrix("q", q);    assertEquals(0, q.clone().assign(Functions.ABS).minus(qRef.clone().assign(Functions.ABS)).aggregate(Functions.PLUS, Functions.IDENTITY), 1.0e-12);    Matrix x1 = qr.solve(reshape(new double[] { -0.0178247686747641, 0.68631714634098, -0.335464858468858, 1.50249941751569, -0.669901640772149, -0.977025038942455, -1.18857546169856, -1.24792900492054 }, 8, 1));    Matrix xref = reshape(new double[] { -0.0127440093664874, 0.655825940180799, -0.100755415991702, -0.0349559562697406, -0.190744297762028 }, 5, 1);    printMatrix("x1", x1);    printMatrix("xref", xref);    assertEquals(xref, x1, 1.0e-8);}
public void mahout_f7538_0()
{    Matrix x = matrix().transpose();    QRDecomposition qr = new QRDecomposition(x);    assertTrue(qr.hasFullRank());    Matrix rActual = qr.getR();    Matrix rRef = reshape(new double[] { -2.42812464965842, 0, 0, 0, 0, 0.303587286111356, -2.91663643494775, 0, 0, 0, -0.201812474153156, -0.765485720168378, 1.09989373598954, 0, 0, 1.47980701097885, -0.637545820524326, -1.55519859337935, 0.844655127991726, 0, 0.0248883129453161, 0.00115010570270549, -0.236340588891252, -0.092924118200147, 1.42910099545547, -1.1678472412429, 0.531245845248056, 0.351978196071514, -1.03241474816555, -2.20223861735426, -0.887809959067632, 0.189731251982918, -0.504321849233586, 0.490484123999836, 1.21266692336743, -0.633888169775463, 1.04738559065986, 0.284041239547031, 0.578183510077156, -0.942314870832456 }, 5, 8);    printMatrix("rRef", rRef);    printMatrix("rActual", rActual);    assertEquals(0, rActual.clone().assign(Functions.ABS).minus(rRef.clone().assign(Functions.ABS)).aggregate(Functions.PLUS, Functions.IDENTITY), 1.0e-12);        Matrix qRef = reshape(new double[] { -0.203489262374627, 0.316761677948356, -0.784155643293468, 0.394321494579, -0.29641971170211, 0.0311283614803723, -0.34755265020736, 0.137138511478328, 0.848579887681972, 0.373287266507375, -0.39603700561249, -0.787812566647329, -0.377864833067864, -0.275080943427399, 0.0636764674878229, 0.0763976893309043, -0.318551137554327, 0.286407036668598, 0.206004127289883, -0.876482672226889, 0.89159476695423, -0.238213616975551, -0.376141107880836, -0.0794701657055114, 0.0227025098210165 }, 5, 5);    Matrix q = qr.getQ();    printMatrix("qRef", qRef);    printMatrix("q", q);    assertEquals(0, q.clone().assign(Functions.ABS).minus(qRef.clone().assign(Functions.ABS)).aggregate(Functions.PLUS, Functions.IDENTITY), 1.0e-12);        Matrix x1 = qr.solve(b());    Matrix xRef = reshape(new double[] { -0.182580239668147, -0.437233627652114, 0.138787653097464, 0.672934739896228, -0.131420217069083, 0, 0, 0 }, 8, 1);    printMatrix("xRef", xRef);    printMatrix("x", x1);    assertEquals(xRef, x1, 1.0e-8);    assertEquals(x, qr.getQ().times(qr.getR()), 1.0e-15);}
public void mahout_f7539_0()
{    OnlineSummarizer s1 = new OnlineSummarizer();    OnlineSummarizer s2 = new OnlineSummarizer();    Matrix a = new DenseMatrix(60, 60).assign(Functions.random());    decompositionSpeedCheck(new Decomposer() {        @Override        public QR decompose(Matrix a) {            return new QRDecomposition(a);        }    }, s1, a, "new");    decompositionSpeedCheck(new Decomposer() {        @Override        public QR decompose(Matrix a) {            return new OldQRDecomposition(a);        }    }, s2, a, "old");        System.out.printf("Speedup is about %.1f times\n", s2.getMean() / s1.getMean());    assertTrue(s1.getMean() < 0.5 * s2.getMean());}
public QR mahout_f7540_0(Matrix a)
{    return new QRDecomposition(a);}
public QR mahout_f7541_0(Matrix a)
{    return new OldQRDecomposition(a);}
private static void mahout_f7542_0(Decomposer qrf, OnlineSummarizer s1, Matrix a, String label)
{    int n = 0;    List<Integer> counts = Lists.newArrayList(10, 20, 50, 100, 200, 500);    for (int k : counts) {        double warmup = 0;        double other = 0;        n += k;        for (int i = 0; i < k; i++) {            QR qr = qrf.decompose(a);            warmup = Math.max(warmup, qr.getQ().transpose().times(qr.getQ()).viewDiagonal().assign(Functions.plus(-1)).norm(1));            Matrix z = qr.getQ().times(qr.getR()).minus(a);            other = Math.max(other, z.aggregate(Functions.MIN, Functions.ABS));        }        double maxIdent = 0;        double maxError = 0;        long t0 = System.nanoTime();        for (int i = 0; i < n; i++) {            QR qr = qrf.decompose(a);            maxIdent = Math.max(maxIdent, qr.getQ().transpose().times(qr.getQ()).viewDiagonal().assign(Functions.plus(-1)).norm(1));            Matrix z = qr.getQ().times(qr.getR()).minus(a);            maxError = Math.max(maxError, z.aggregate(Functions.MIN, Functions.ABS));        }        long t1 = System.nanoTime();        if (k > 100) {            s1.add(t1 - t0);        }        System.out.printf("%s %d\t%.1f\t%g\t%g\t%g\n", label, n, (t1 - t0) / 1.0e3 / n, maxIdent, maxError, warmup);    }}
private static void mahout_f7543_0(Matrix ref, Matrix actual, double epsilon)
{    assertEquals(0, ref.minus(actual).aggregate(Functions.MAX, Functions.ABS), epsilon);}
private static void mahout_f7544_0(String name, Matrix m)
{    int rows = m.numRows();    int columns = m.numCols();    System.out.printf("%s - %d x %d\n", name, rows, columns);    for (int i = 0; i < rows; i++) {        for (int j = 0; j < columns; j++) {            System.out.printf("%10.5f", m.get(i, j));        }        System.out.printf("\n");    }    System.out.printf("\n");    System.out.printf("\n");}
private static Matrix mahout_f7545_0()
{    double[] values = { 0.494097293912641, -0.152566866170993, -0.418360266395271, 0.359475300232312, 1.35565069667582, -1.92759373242903, 1.50497526839076, -0.746889132087904, -0.769136838293565, 1.10984954080986, -0.664389974392489, 1.6464660350229, -0.11715420616969, 0.0216221197371269, -0.394972730980765, -0.748293157213142, 1.90402764664962, -0.638042862848559, -0.362336344669668, -0.418261074380526, -0.494211543128429, 1.38828971158414, 0.597110366867923, 1.05341387608687, -0.957461740877418, -2.35528802598249, -1.03171458944128, 0.644319090271635, -0.0569108993041965, -0.14419465550881, -0.0456801828174936, 0.754694392571835, 0.719744008628535, -1.17873249802301, -0.155887528905918, -1.5159868405466, 0.0918931582603128, 1.42179027361583, -0.100495054250176, 0.0687986548485584 };    return reshape(values, 8, 5);}
private static Matrix mahout_f7546_0(double[] values, int rows, int columns)
{    Matrix m = new DenseMatrix(rows, columns);    int i = 0;    for (double v : values) {        m.set(i % rows, i / rows, v);        i++;    }    return m;}
private static Matrix mahout_f7547_0()
{    return reshape(new double[] { -0.0178247686747641, 0.68631714634098, -0.335464858468858, 1.50249941751569, -0.669901640772149 }, 5, 1);}
public void mahout_f7548_0()
{    List<Integer> totals = Lists.newArrayList();    for (int i = 0; i < 1000; i++) {        ChineseRestaurant x = new ChineseRestaurant(10);        Multiset<Integer> counts = HashMultiset.create();        for (int j = 0; j < 100; j++) {            counts.add(x.sample());        }        List<Integer> tmp = Lists.newArrayList();        for (Integer k : counts.elementSet()) {            tmp.add(counts.count(k));        }        Collections.sort(tmp, Collections.reverseOrder());        while (totals.size() < tmp.size()) {            totals.add(0);        }        int j = 0;        for (Integer k : tmp) {            totals.set(j, totals.get(j) + k);            j++;        }    }        assertEquals(25000.0, (double) totals.get(0), 1000);    assertEquals(24000.0, (double) totals.get(1), 1000);    assertEquals(8000.0, (double) totals.get(2), 200);    assertEquals(1000.0, (double) totals.get(15), 50);    assertEquals(1000.0, (double) totals.get(20), 40);}
public void mahout_f7549_0()
{    ChineseRestaurant x = new ChineseRestaurant(100, 1);    Multiset<Integer> counts = HashMultiset.create();    for (int i = 0; i < 10000; i++) {        counts.add(x.sample());    }    assertEquals(10000, x.size());    for (int i = 0; i < 10000; i++) {        assertEquals(1, x.count(i));    }}
public void mahout_f7550_0()
{    ChineseRestaurant s0 = new ChineseRestaurant(10, 0.0);    ChineseRestaurant s5 = new ChineseRestaurant(10, 0.5);    ChineseRestaurant s9 = new ChineseRestaurant(10, 0.9);    Set<Double> splits = ImmutableSet.of(1.0, 1.5, 2.0, 3.0, 5.0, 8.0);    double offset0 = 0;    int k = 0;    int i = 0;    Matrix m5 = new DenseMatrix(20, 3);    Matrix m9 = new DenseMatrix(20, 3);    while (i <= 200000) {        double n = i / Math.pow(10, Math.floor(Math.log10(i)));        if (splits.contains(n)) {                        if (i > 900) {                double predict5 = predictSize(m5.viewPart(0, k, 0, 3), i, 0.5);                assertEquals(predict5, Math.log(s5.size()), 1);                double predict9 = predictSize(m9.viewPart(0, k, 0, 3), i, 0.9);                assertEquals(predict9, Math.log(s9.size()), 1);                        } else if (i > 50) {                double x = 10.5 * Math.log(i) - s0.size();                m5.viewRow(k).assign(new double[] { Math.log(s5.size()), Math.log(i), 1 });                m9.viewRow(k).assign(new double[] { Math.log(s9.size()), Math.log(i), 1 });                k++;                offset0 += (x - offset0) / k;            }            if (i > 10000) {                assertEquals(0.0, (double) hapaxCount(s0) / s0.size(), 0.25);                assertEquals(0.5, (double) hapaxCount(s5) / s5.size(), 0.1);                assertEquals(0.9, (double) hapaxCount(s9) / s9.size(), 0.05);            }        }        s0.sample();        s5.sample();        s9.sample();        i++;    }}
private static double mahout_f7551_0(Matrix m, int currentIndex, double expectedCoefficient)
{    int rows = m.rowSize();    Matrix a = m.viewPart(0, rows, 1, 2);    Matrix b = m.viewPart(0, rows, 0, 1);    Matrix ata = a.transpose().times(a);    Matrix atb = a.transpose().times(b);    QRDecomposition s = new QRDecomposition(ata);    Matrix r = s.solve(atb).transpose();    assertEquals(expectedCoefficient, r.get(0, 0), 0.2);    return r.times(new DenseVector(new double[] { Math.log(currentIndex), 1 })).get(0);}
private static int mahout_f7552_0(ChineseRestaurant s)
{    int r = 0;    for (int i = 0; i < s.size(); i++) {        if (s.count(i) == 1) {            r++;        }    }    return r;}
public void mahout_f7553_0()
{    RandomUtils.useTestSeed();    Empirical z = new Empirical(true, true, 3, 0, 1, 0.5, 2, 1, 3.0);    List<Double> r = Lists.newArrayList();    for (int i = 0; i < 10001; i++) {        r.add(z.sample());    }    Collections.sort(r);    assertEquals(2.0, r.get(5000), 0.15);}
public void mahout_f7554_0()
{    Empirical z = new Empirical(true, true, 3, 0, 1, 0.5, 2, 1, 3.0);    assertEquals(-16.52, z.sample(0), 1.0e-2);    assertEquals(20.47, z.sample(1), 1.0e-2);}
public void mahout_f7555_0()
{    try {        new Empirical(true, false, 20, 0, 1, 0.5, 2, 0.9, 9, 0.99, 10.0);        Assert.fail("Should have caught that");    } catch (IllegalArgumentException e) {    }    try {        new Empirical(false, true, 20, 0.1, 1, 0.5, 2, 0.9, 9, 1, 10.0);        Assert.fail("Should have caught that");    } catch (IllegalArgumentException e) {    }    try {        new Empirical(true, true, 20, -0.1, 1, 0.5, 2, 0.9, 9, 1, 10.0);        Assert.fail("Should have caught that");    } catch (IllegalArgumentException e) {    }    try {        new Empirical(true, true, 20, 0, 1, 0.5, 2, 0.9, 9, 1.2, 10.0);        Assert.fail("Should have caught that");    } catch (IllegalArgumentException e) {    }    try {        new Empirical(true, true, 20, 0, 1, 0.5, 2, 0.4, 9, 1, 10.0);        Assert.fail("Should have caught that");    } catch (IllegalArgumentException e) {    }}
public void mahout_f7556_0()
{    RandomUtils.useTestSeed();    IndianBuffet<String> sampler = IndianBuffet.createTextDocumentSampler(30);    Multiset<String> counts = HashMultiset.create();    int[] lengths = new int[100];    for (int i = 0; i < 30; i++) {        final List<String> doc = sampler.sample();        lengths[doc.size()]++;        for (String w : doc) {            counts.add(w);        }        System.out.printf("%s\n", doc);    }}
public void mahout_f7557_0()
{    RandomUtils.useTestSeed();}
public void mahout_f7558_0()
{    Multiset<String> emptySet = HashMultiset.create();    new Multinomial<>(emptySet);}
public void mahout_f7559_0()
{    Multiset<String> oneThing = HashMultiset.create();    oneThing.add("one");    Multinomial<String> s = new Multinomial<>(oneThing);    assertEquals("one", s.sample(0));    assertEquals("one", s.sample(0.1));    assertEquals("one", s.sample(1));}
public void mahout_f7560_0()
{    Multiset<String> stuff = HashMultiset.create();    for (int i = 0; i < 5; i++) {        stuff.add(String.valueOf(i));    }    Multinomial<String> s = new Multinomial<>(stuff);    double EPSILON = 1.0e-15;    Multiset<String> cnt = HashMultiset.create();    for (int i = 0; i < 5; i++) {        cnt.add(s.sample(i * 0.2));        cnt.add(s.sample(i * 0.2 + EPSILON));        cnt.add(s.sample((i + 1) * 0.2 - EPSILON));    }    assertEquals(5, cnt.elementSet().size());    for (String v : cnt.elementSet()) {        assertEquals(3, cnt.count(v), 1.01);    }    assertTrue(cnt.contains(s.sample(1)));    assertEquals(s.sample(1 - EPSILON), s.sample(1));}
public void mahout_f7561_0()
{    List<String> data = Lists.newArrayList();    for (int i = 0; i < 17; i++) {        String s = "0";        if ((i & 1) != 0) {            s = "1";        }        if ((i & 2) != 0) {            s = "2";        }        if ((i & 4) != 0) {            s = "3";        }        if ((i & 8) != 0) {            s = "4";        }        data.add(s);    }    Multiset<String> stuff = HashMultiset.create();    for (String x : data) {        stuff.add(x);    }    Multinomial<String> s0 = new Multinomial<>(stuff);    Multinomial<String> s1 = new Multinomial<>(stuff);    Multinomial<String> s2 = new Multinomial<>(stuff);    double EPSILON = 1.0e-15;    Multiset<String> cnt = HashMultiset.create();    for (int i = 0; i < 50; i++) {        double p0 = i * 0.02;        double p1 = (i + 1) * 0.02;        cnt.add(s0.sample(p0));        cnt.add(s0.sample(p0 + EPSILON));        cnt.add(s0.sample(p1 - EPSILON));        assertEquals(s0.sample(p0), s1.sample(p0));        assertEquals(s0.sample(p0 + EPSILON), s1.sample(p0 + EPSILON));        assertEquals(s0.sample(p1 - EPSILON), s1.sample(p1 - EPSILON));        assertEquals(s0.sample(p0), s2.sample(p0));        assertEquals(s0.sample(p0 + EPSILON), s2.sample(p0 + EPSILON));        assertEquals(s0.sample(p1 - EPSILON), s2.sample(p1 - EPSILON));    }    assertEquals(s0.sample(0), s1.sample(0));    assertEquals(s0.sample(0 + EPSILON), s1.sample(0 + EPSILON));    assertEquals(s0.sample(1 - EPSILON), s1.sample(1 - EPSILON));    assertEquals(s0.sample(1), s1.sample(1));    assertEquals(s0.sample(0), s2.sample(0));    assertEquals(s0.sample(0 + EPSILON), s2.sample(0 + EPSILON));    assertEquals(s0.sample(1 - EPSILON), s2.sample(1 - EPSILON));    assertEquals(s0.sample(1), s2.sample(1));    assertEquals(5, cnt.elementSet().size());            Map<String, Integer> ref = ImmutableMap.of("3", 35, "2", 18, "1", 9, "0", 16, "4", 72);    for (String v : cnt.elementSet()) {        assertTrue(Math.abs(ref.get(v) - cnt.count(v)) <= 2);    }    assertTrue(cnt.contains(s0.sample(1)));    assertEquals(s0.sample(1 - EPSILON), s0.sample(1));}
public void mahout_f7562_0()
{    Random rand = RandomUtils.getRandom();    Multinomial<Integer> table = new Multinomial<>();    double[] p = new double[10];    for (int i = 0; i < 10; i++) {        p[i] = rand.nextDouble();        table.add(i, p[i]);    }    checkSelfConsistent(table);    for (int i = 0; i < 10; i++) {        assertEquals(p[i], table.getWeight(i), 0);    }}
public void mahout_f7563_0()
{    Multinomial<Integer> table = new Multinomial<>();    for (int i = 0; i < 10000; ++i) {        table.add(i, i);    }        for (Integer sample : table) {        table.set(sample, 0);    }}
public void mahout_f7564_0()
{    Multinomial<Integer> table = new Multinomial<>();        table.add(null, 1);}
public void mahout_f7565_0()
{    Random rand = RandomUtils.getRandom();    Multinomial<Integer> table = new Multinomial<>();    assertEquals(0, table.getWeight(), 1.0e-9);    double total = 0;    double[] p = new double[10];    for (int i = 0; i < 10; i++) {        p[i] = rand.nextDouble();        table.add(i, p[i]);        total += p[i];        assertEquals(total, table.getWeight(), 1.0e-9);    }    assertEquals(total, table.getWeight(), 1.0e-9);    checkSelfConsistent(table);    double delta = p[7] + p[8];    table.delete(7);    p[7] = 0;    table.set(8, 0);    p[8] = 0;    total -= delta;    checkSelfConsistent(table);    assertEquals(total, table.getWeight(), 1.0e-9);    for (int i = 0; i < 10; i++) {        assertEquals(p[i], table.getWeight(i), 0);        assertEquals(p[i] / total, table.getProbability(i), 1.0e-10);    }    table.set(9, 5.1);    total -= p[9];    p[9] = 5.1;    total += 5.1;    assertEquals(total, table.getWeight(), 1.0e-9);    for (int i = 0; i < 10; i++) {        assertEquals(p[i], table.getWeight(i), 0);        assertEquals(p[i] / total, table.getProbability(i), 1.0e-10);    }    checkSelfConsistent(table);    for (int i = 0; i < 10; i++) {        assertEquals(p[i], table.getWeight(i), 0);    }}
private static void mahout_f7566_0(Multinomial<Integer> table)
{    List<Double> weights = table.getWeights();    double totalWeight = table.getWeight();    double p = 0;    int[] k = new int[weights.size()];    for (double weight : weights) {        if (weight > 0) {            if (p > 0) {                k[table.sample(p - 1.0e-9)]++;            }            k[table.sample(p + 1.0e-9)]++;        }        p += weight / totalWeight;    }    k[table.sample(p - 1.0e-9)]++;    assertEquals(1, p, 1.0e-9);    for (int i = 0; i < weights.size(); i++) {        if (table.getWeight(i) > 0) {            assertEquals(2, k[i]);        } else {            assertEquals(0, k[i]);        }    }}
public void mahout_f7567_0()
{    RandomUtils.useTestSeed();}
public void mahout_f7568_0()
{    DenseVector offset = new DenseVector(new double[] { 6, 3, 0 });    MultiNormal n = new MultiNormal(new DenseVector(new double[] { 1, 2, 5 }), offset);    OnlineSummarizer[] s = { new OnlineSummarizer(), new OnlineSummarizer(), new OnlineSummarizer() };    OnlineSummarizer[] cross = { new OnlineSummarizer(), new OnlineSummarizer(), new OnlineSummarizer() };    for (int i = 0; i < 10000; i++) {        Vector v = n.sample();        for (int j = 0; j < 3; j++) {            s[j].add(v.get(j) - offset.get(j));            int k1 = j % 2;            int k2 = (j + 1) / 2 + 1;            cross[j].add((v.get(k1) - offset.get(k1)) * (v.get(k2) - offset.get(k2)));        }    }    for (int j = 0; j < 3; j++) {        assertEquals(0, s[j].getMean() / s[j].getSD(), 0.04);        assertEquals(0, cross[j].getMean() / cross[j].getSD(), 0.04);    }}
public void mahout_f7569_0()
{    MultiNormal gen = new MultiNormal(0.1, new DenseVector(10));    OnlineSummarizer s = new OnlineSummarizer();    for (int i = 0; i < 10000; i++) {        double x = gen.sample().norm(2) / Math.sqrt(10);        s.add(x);    }    assertEquals(0.1, s.getMean(), 0.01);}
public void mahout_f7570_0()
{    RandomUtils.useTestSeed();}
public void mahout_f7571_0()
{    OnlineSummarizer s = new OnlineSummarizer();    Sampler<Double> sampler = new Normal(2, 5);    for (int i = 0; i < 10001; i++) {        s.add(sampler.sample());    }    assertEquals(String.format("m = %.3f, sd = %.3f", s.getMean(), s.getSD()), 2, s.getMean(), 0.04 * s.getSD());    assertEquals(5, s.getSD(), 0.12);}
public void mahout_f7572_0() throws Exception
{    double[] data = new double[10001];    Sampler<Double> sampler = new Normal();    for (int i = 0; i < data.length; i++) {        data[i] = sampler.sample();    }    Arrays.sort(data);    NormalDistribution reference = new NormalDistribution(RandomUtils.getRandom().getRandomGenerator(), 0, 1, NormalDistribution.DEFAULT_INVERSE_ABSOLUTE_ACCURACY);    assertEquals("Median", reference.inverseCumulativeProbability(0.5), data[5000], 0.04);}
public void mahout_f7573_0()
{    RandomUtils.useTestSeed();}
public void mahout_f7574_0()
{    for (double alpha : new double[] { 0.1, 1, 10, 100 }) {        checkDistribution(new PoissonSampler(alpha), alpha);    }}
private static void mahout_f7575_0(Sampler<Double> pd, double alpha)
{    int[] count = new int[(int) Math.max(10, 5 * alpha)];    for (int i = 0; i < 10000; i++) {        count[pd.sample().intValue()]++;    }    IntegerDistribution ref = new PoissonDistribution(RandomUtils.getRandom().getRandomGenerator(), alpha, PoissonDistribution.DEFAULT_EPSILON, PoissonDistribution.DEFAULT_MAX_ITERATIONS);    for (int i = 0; i < count.length; i++) {        assertEquals(ref.probability(i), count[i] / 10000.0, 2.0e-2);    }}
public void mahout_f7576_0()
{    OpenObjectIntHashMap<Integer> base = new OpenObjectIntHashMap<>();    Map<Integer, Integer> reference = new HashMap<>();    List<Operation> ops = Lists.newArrayList();    addOp(ops, Operation.ADD, 60);    addOp(ops, Operation.REMOVE, 30);    addOp(ops, Operation.INDEXOF, 30);    addOp(ops, Operation.CLEAR, 5);    addOp(ops, Operation.ISEMPTY, 2);    addOp(ops, Operation.SIZE, 2);    int max = randomIntBetween(1000, 20000);    for (int reps = 0; reps < max; reps++) {                int k = randomIntBetween(0, max / 4);        int v = randomInt();        switch(randomFrom(ops)) {            case ADD:                assertEquals(reference.put(k, v) == null, base.put(k, v));                break;            case REMOVE:                assertEquals(reference.remove(k) != null, base.removeKey(k));                break;            case INDEXOF:                assertEquals(reference.containsKey(k), base.containsKey(k));                break;            case CLEAR:                reference.clear();                base.clear();                break;            case ISEMPTY:                assertEquals(reference.isEmpty(), base.isEmpty());                break;            case SIZE:                assertEquals(reference.size(), base.size());                break;            default:                throw new RuntimeException();        }    }}
public void mahout_f7577_0()
{    OpenIntObjectHashMap<Integer> base = new OpenIntObjectHashMap<>();    Map<Integer, Integer> reference = new HashMap<>();    List<Operation> ops = Lists.newArrayList();    addOp(ops, Operation.ADD, 60);    addOp(ops, Operation.REMOVE, 30);    addOp(ops, Operation.INDEXOF, 30);    addOp(ops, Operation.CLEAR, 5);    addOp(ops, Operation.ISEMPTY, 2);    addOp(ops, Operation.SIZE, 2);    int max = randomIntBetween(1000, 20000);    for (int reps = 0; reps < max; reps++) {                int k = randomIntBetween(0, max / 4);        int v = randomInt();        switch(randomFrom(ops)) {            case ADD:                assertEquals(reference.put(k, v) == null, base.put(k, v));                break;            case REMOVE:                assertEquals(reference.remove(k) != null, base.removeKey(k));                break;            case INDEXOF:                assertEquals(reference.containsKey(k), base.containsKey(k));                break;            case CLEAR:                reference.clear();                base.clear();                break;            case ISEMPTY:                assertEquals(reference.isEmpty(), base.isEmpty());                break;            case SIZE:                assertEquals(reference.size(), base.size());                break;            default:                throw new RuntimeException();        }    }}
public void mahout_f7578_0()
{    OpenIntIntHashMap base = new OpenIntIntHashMap();    HashMap<Integer, Integer> reference = new HashMap<>();    List<Operation> ops = Lists.newArrayList();    addOp(ops, Operation.ADD, 60);    addOp(ops, Operation.REMOVE, 30);    addOp(ops, Operation.INDEXOF, 30);    addOp(ops, Operation.CLEAR, 5);    addOp(ops, Operation.ISEMPTY, 2);    addOp(ops, Operation.SIZE, 2);    int max = randomIntBetween(1000, 20000);    for (int reps = 0; reps < max; reps++) {                int k = randomIntBetween(0, max / 4);        int v = randomInt();        switch(randomFrom(ops)) {            case ADD:                Integer prevValue = reference.put(k, v);                if (prevValue == null) {                    assertEquals(true, base.put(k, v));                } else {                    assertEquals(prevValue.intValue(), base.get(k));                    assertEquals(false, base.put(k, v));                }                break;            case REMOVE:                assertEquals(reference.containsKey(k), base.containsKey(k));                Integer removed = reference.remove(k);                if (removed == null) {                    assertEquals(false, base.removeKey(k));                } else {                    assertEquals(removed.intValue(), base.get(k));                    assertEquals(true, base.removeKey(k));                }                break;            case INDEXOF:                assertEquals(reference.containsKey(k), base.containsKey(k));                break;            case CLEAR:                reference.clear();                base.clear();                break;            case ISEMPTY:                assertEquals(reference.isEmpty(), base.isEmpty());                break;            case SIZE:                assertEquals(reference.size(), base.size());                break;            default:                throw new RuntimeException();        }    }}
public void mahout_f7579_0()
{    AbstractIntSet base = new OpenIntHashSet();    HashSet<Integer> reference = Sets.newHashSet();    List<Operation> ops = Lists.newArrayList();    addOp(ops, Operation.ADD, 60);    addOp(ops, Operation.REMOVE, 30);    addOp(ops, Operation.INDEXOF, 30);    addOp(ops, Operation.CLEAR, 5);    addOp(ops, Operation.ISEMPTY, 2);    addOp(ops, Operation.SIZE, 2);    int max = randomIntBetween(1000, 20000);    for (int reps = 0; reps < max; reps++) {                int k = randomIntBetween(0, max / 4);        switch(randomFrom(ops)) {            case ADD:                assertEquals(reference.add(k), base.add(k));                break;            case REMOVE:                assertEquals(reference.remove(k), base.remove(k));                break;            case INDEXOF:                assertEquals(reference.contains(k), base.contains(k));                break;            case CLEAR:                reference.clear();                base.clear();                break;            case ISEMPTY:                assertEquals(reference.isEmpty(), base.isEmpty());                break;            case SIZE:                assertEquals(reference.size(), base.size());                break;            default:                throw new RuntimeException();        }    }}
public void mahout_f7580_0()
{    Set<Integer> base = new OpenHashSet<>();    Set<Integer> reference = Sets.newHashSet();    List<Operation> ops = Lists.newArrayList();    addOp(ops, Operation.ADD, 60);    addOp(ops, Operation.REMOVE, 30);    addOp(ops, Operation.INDEXOF, 30);    addOp(ops, Operation.CLEAR, 5);    addOp(ops, Operation.ISEMPTY, 2);    addOp(ops, Operation.SIZE, 2);    int max = randomIntBetween(1000, 20000);    for (int reps = 0; reps < max; reps++) {                int k = randomIntBetween(0, max / 4);        switch(randomFrom(ops)) {            case ADD:                assertEquals(reference.contains(k), base.contains(k));                break;            case REMOVE:                assertEquals(reference.remove(k), base.remove(k));                break;            case INDEXOF:                assertEquals(reference.contains(k), base.contains(k));                break;            case CLEAR:                reference.clear();                base.clear();                break;            case ISEMPTY:                assertEquals(reference.isEmpty(), base.isEmpty());                break;            case SIZE:                assertEquals(reference.size(), base.size());                break;            default:                throw new RuntimeException();        }    }}
public void mahout_f7581_0()
{    AbstractIntSet s = new OpenIntHashSet();    s.clear();    s.add(23);    s.add(46);    s.clear();    s.add(70);    s.add(93);    s.contains(100);}
public void mahout_f7582_0() throws Exception
{    OpenObjectIntHashMap<Integer> m = new OpenObjectIntHashMap<>();        m.clear();    m.put(1, 2);        m.clear();    Field tableField = m.getClass().getDeclaredField("table");    tableField.setAccessible(true);    Object[] table = (Object[]) tableField.get(m);    assertEquals(Sets.newHashSet(Arrays.asList(new Object[] { null })), Sets.newHashSet(Arrays.asList(table)));}
private static void mahout_f7583_0(List<Operation> ops, Operation op, int reps)
{    for (int i = 0; i < reps; i++) {        ops.add(op);    }}
public void mahout_f7584_0()
{    Multiset<Integer> violations = HashMultiset.create();    for (int k = 0; k < 1000; k++) {        List<Float> original = Lists.newArrayList();        Random gen = RandomUtils.getRandom();        for (int i = 0; i < 10000; i++) {            float x = (float) gen.nextDouble();            original.add(x);        }        violations.add(checkCounts(original) <= 12 ? 0 : 1);    }            assertTrue(violations.count(0) >= 985);}
public void mahout_f7585_0()
{    List<Double> original = Lists.newArrayList();    for (int k = 0; k < 10; k++) {        Random gen = RandomUtils.getRandom();        for (int i = 0; i < 10000; i++) {            double x = gen.nextDouble();            original.add(x);        }        checkCounts(original);    }}
public void mahout_f7586_0()
{    List<Long> original = Lists.newArrayList();    for (int k = 0; k < 10; k++) {        Random gen = RandomUtils.getRandom();        for (int i = 0; i < 10000; i++) {            long x = gen.nextLong();            original.add(x);        }        checkCounts(original);    }}
private static int mahout_f7587_0(Collection<T> original)
{    Multiset<T> hashCounts = HashMultiset.create();    for (T v : original) {        hashCounts.add(v);    }    Multiset<Integer> countCounts = HashMultiset.create();    for (T hash : hashCounts) {        countCounts.add(hashCounts.count(hash));    }    return original.size() - countCounts.count(1);}
public void mahout_f7588_0()
{    double[][] m = { new double[] { 0.641284, 0.767303, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000 }, new double[] { 0.767303, 3.050159, 2.561342, 0.000000, 0.000000, 0.000000, 0.000000 }, new double[] { 0.000000, 2.561342, 5.000609, 0.810507, 0.000000, 0.000000, 0.000000 }, new double[] { 0.000000, 0.000000, 0.810507, 0.550477, 0.142853, 0.000000, 0.000000 }, new double[] { 0.000000, 0.000000, 0.000000, 0.142853, 0.254566, 0.000000, 0.000000 }, new double[] { 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.256073, 0.000000 }, new double[] { 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000 } };    Matrix x = new DenseMatrix(m);    EigenDecomposition eig = new EigenDecomposition(x, true);    Matrix d = eig.getD();    Matrix v = eig.getV();    check("EigenvalueDecomposition (evil)...", x.times(v), v.times(d));}
public void mahout_f7589_0()
{    Matrix a = new DenseMatrix(10, 3).assign(new DoubleFunction() {        private final Random gen = RandomUtils.getRandom();        @Override        public double apply(double arg1) {            return gen.nextGaussian();        }    });    a = a.transpose().times(a);    EigenDecomposition eig = new EigenDecomposition(a);    Matrix d = eig.getD();    Matrix v = eig.getV();    check("EigenvalueDecomposition (rank deficient)...", a.times(v), v.times(d));    Assert.assertEquals(0, eig.getImagEigenvalues().norm(1), 1.0e-10);    Assert.assertEquals(3, eig.getRealEigenvalues().norm(0), 1.0e-10);}
public double mahout_f7590_0(double arg1)
{    return gen.nextGaussian();}
public void mahout_f7591_0()
{    double[] evals = { 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0e-7, 0.0, 0.0, -2.0e-7, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0 };    int i = 0;    Matrix a = new DenseMatrix(4, 4);    for (MatrixSlice row : a) {        for (Vector.Element element : row.vector().all()) {            element.set(evals[i++]);        }    }    EigenDecomposition eig = new EigenDecomposition(a);    Matrix d = eig.getD();    Matrix v = eig.getV();    check("EigenvalueDecomposition (nonsymmetric)...", a.times(v), v.times(d));}
public void mahout_f7592_0()
{    int validld = 3;    Matrix A = new DenseMatrix(validld, validld);    double[] columnwise = { 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0 };    int i = 0;    for (MatrixSlice row : A) {        for (Vector.Element element : row.vector().all()) {            element.set(columnwise[i++]);        }    }    EigenDecomposition Eig = new EigenDecomposition(A);    Matrix D = Eig.getD();    Matrix V = Eig.getV();    check("EigenvalueDecomposition (nonsymmetric)...", A.times(V), V.times(D));    A = A.transpose().times(A);    Eig = new EigenDecomposition(A);    D = Eig.getD();    V = Eig.getV();    check("EigenvalueDecomposition (symmetric)...", A.times(V), V.times(D));}
private static void mahout_f7593_0(String msg, Matrix a, Matrix b)
{    Assert.assertEquals(msg, 0, a.minus(b).aggregate(Functions.PLUS, Functions.ABS), 1.0e-10);}
public void mahout_f7594_0()
{    Matrix m = hilbert(5);        assertEquals(1, m.get(0, 0), 0);    assertEquals(0.5, m.get(0, 1), 0);    assertEquals(1 / 6.0, m.get(2, 3), 1.0e-9);    Vector x = new DenseVector(new double[] { 5, -120, 630, -1120, 630 });    Vector b = new DenseVector(5);    b.assign(1);    assertEquals(0, m.times(x).minus(b).norm(2), 1.0e-9);    LSMR r = new LSMR();    Vector x1 = r.solve(m, b);                            assertEquals(0, m.times(x1).minus(b).norm(2), 1.0e-2);    assertEquals(0, m.transpose().times(m).times(x1).minus(m.transpose().times(b)).norm(2), 1.0e-7);        assertEquals(m.times(x1).minus(b).norm(2), r.getResidualNorm(), 1.0e-5);    assertEquals(m.transpose().times(m).times(x1).minus(m.transpose().times(b)).norm(2), r.getNormalEquationResidual(), 1.0e-9);}
public void mahout_f7595_0()
{    Matrix m = new DenseMatrix(200, 30).assign(Functions.random());    Vector b = new DenseVector(200).assign(1);    LSMR r = new LSMR();    Vector x1 = r.solve(m, b);        double norm = new SingularValueDecomposition(m).getS().viewDiagonal().norm(2);    double actual = m.transpose().times(m).times(x1).minus(m.transpose().times(b)).norm(2);    System.out.printf("%.4f\n", actual / norm * 1.0e6);    assertEquals(0, actual, norm * 1.0e-5);        assertEquals(m.times(x1).minus(b).norm(2), r.getResidualNorm(), 1.0e-5);    assertEquals(actual, r.getNormalEquationResidual(), 1.0e-9);}
private static Matrix mahout_f7596_0(int n)
{    Matrix r = new DenseMatrix(n, n);    for (int i = 0; i < n; i++) {        for (int j = 0; j < n; j++) {            r.set(i, j, 1.0 / (i + j + 1));        }    }    return r;}
public void mahout_f7597_0()
{    Matrix a = getA();    Vector b = getB();    ConjugateGradientSolver solver = new ConjugateGradientSolver();    Vector x = solver.solve(a, b);    assertEquals(0.0, Math.sqrt(a.times(x).getDistanceSquared(b)), EPSILON);    assertEquals(0.0, solver.getResidualNorm(), ConjugateGradientSolver.DEFAULT_MAX_ERROR);    assertEquals(10, solver.getIterations());}
public void mahout_f7598_0()
{    Matrix a = getIllConditionedMatrix();    Vector b = getB();    Preconditioner conditioner = new JacobiConditioner(a);    ConjugateGradientSolver solver = new ConjugateGradientSolver();    Vector x = solver.solve(a, b, null, 100, ConjugateGradientSolver.DEFAULT_MAX_ERROR);    double distance = Math.sqrt(a.times(x).getDistanceSquared(b));    assertEquals(0.0, distance, EPSILON);    assertEquals(0.0, solver.getResidualNorm(), ConjugateGradientSolver.DEFAULT_MAX_ERROR);    assertEquals(16, solver.getIterations());    Vector x2 = solver.solve(a, b, conditioner, 100, ConjugateGradientSolver.DEFAULT_MAX_ERROR);        distance = Math.sqrt(a.times(x2).getDistanceSquared(b));    assertEquals(0.0, distance, EPSILON);    assertEquals(0.0, solver.getResidualNorm(), ConjugateGradientSolver.DEFAULT_MAX_ERROR);    assertEquals(15, solver.getIterations());}
public void mahout_f7599_0()
{    Matrix a = getA();    Vector b = getB();    ConjugateGradientSolver solver = new ConjugateGradientSolver();        Vector x = solver.solve(a, b, null, 10, 0.1);    double distance = Math.sqrt(a.times(x).getDistanceSquared(b));    assertTrue(distance > EPSILON);        assertEquals(0.0, distance, 0.1);        assertEquals(7, solver.getIterations());        x = solver.solve(a, b, null, 7, ConjugateGradientSolver.DEFAULT_MAX_ERROR);    distance = Math.sqrt(a.times(x).getDistanceSquared(b));    assertTrue(distance > EPSILON);    assertEquals(0.0, distance, 0.1);    assertEquals(7, solver.getIterations());}
private static Matrix mahout_f7600_0()
{    return reshape(new double[] { 11.7155649822793997, -0.7125253363083646, 4.6473613961860183, 1.6020939468348456, -4.6789817799137134, -0.8140416763434970, -4.5995617505618345, -1.1749070042775340, -1.6747995811678336, 3.1922255171058342, -0.7125253363083646, 12.3400579683994867, -2.6498099427000645, 0.5264507222630669, 0.3783428369189767, -2.1170186159188811, 2.3695134252190528, 3.8182131490333013, 6.5285942298270347, 2.8564814419366353, 4.6473613961860183, -2.6498099427000645, 16.1317933921668484, -0.0409475448061225, 1.4805687075608227, -2.9958076484628950, -2.5288893025027264, -0.9614557539842487, -2.2974738351519077, -1.5516184284572598, 1.6020939468348456, 0.5264507222630669, -0.0409475448061225, 4.1946802122694482, -2.5210038046912198, 0.6634899962909317, 0.4036187419205338, -0.2829211393003727, -0.2283091172980954, 1.1253516563552464, -4.6789817799137134, 0.3783428369189767, 1.4805687075608227, -2.5210038046912198, 19.4307361862733430, -2.5200132222091787, 2.3748511971444510, 11.6426598443305522, -0.1508136510863874, 4.3471343888063512, -0.8140416763434970, -2.1170186159188811, -2.9958076484628950, 0.6634899962909317, -2.5200132222091787, 7.6712334419700747, -3.8687773629502851, -3.0453418711591529, -0.1155580876143619, -2.4025459467422121, -4.5995617505618345, 2.3695134252190528, -2.5288893025027264, 0.4036187419205338, 2.3748511971444510, -3.8687773629502851, 10.4681666057470082, 1.6527180866171229, 2.9341795819365384, -2.1708176372763099, -1.1749070042775340, 3.8182131490333013, -0.9614557539842487, -0.2829211393003727, 11.6426598443305522, -3.0453418711591529, 1.6527180866171229, 16.0050616934176233, 1.1689747208793086, 1.6665090945954870, -1.6747995811678336, 6.5285942298270347, -2.2974738351519077, -0.2283091172980954, -0.1508136510863874, -0.1155580876143619, 2.9341795819365384, 1.1689747208793086, 6.4794329751637481, -1.9197339981871877, 3.1922255171058342, 2.8564814419366353, -1.5516184284572598, 1.1253516563552464, 4.3471343888063512, -2.4025459467422121, -2.1708176372763099, 1.6665090945954870, -1.9197339981871877, 18.9149021356344598 }, 10, 10);}
private static Vector mahout_f7601_0()
{    return new DenseVector(new double[] { -0.552252, 0.038430, 0.058392, -1.234496, 1.240369, 0.373649, 0.505113, 0.503723, 1.215340, -0.391908 });}
private static Matrix mahout_f7602_0()
{    return reshape(new double[] { 0.00695278043678842, 0.09911830022078683, 0.01309584636255063, 0.00652917453032394, 0.04337631487735064, 0.14232165273321387, 0.05808722912361313, -0.06591965049732287, 0.06055771542862332, 0.00577423310349649, 0.09911830022078683, 1.50071402418061428, 0.14988743575884242, 0.07195514527480981, 0.63747362341752722, 1.30711819020414688, 0.82151609385115953, -0.72616125524587938, 1.03490136002022948, 0.12800239664439328, 0.01309584636255063, 0.14988743575884242, 0.04068462583124965, 0.02147022047006482, 0.07388113580146650, 0.58070223915076002, 0.11280336266257514, -0.21690068430020618, 0.04065087561300068, -0.00876895259593769, 0.00652917453032394, 0.07195514527480981, 0.02147022047006482, 0.01140105250542524, 0.03624164348693958, 0.31291554581393255, 0.05648457235205666, -0.11507583016077780, 0.01475756130709823, -0.00584453679519805, 0.04337631487735064, 0.63747362341752722, 0.07388113580146649, 0.03624164348693959, 0.27491543200760571, 0.73410543168748121, 0.36120630002843257, -0.36583546331208316, 0.41472509341940017, 0.04581458758255480, 0.14232165273321387, 1.30711819020414666, 0.58070223915076002, 0.31291554581393255, 0.73410543168748121, 9.02536073121807014, 1.25426385582883104, -3.16186335125594642, -0.19740140818905436, -0.26613760880058035, 0.05808722912361314, 0.82151609385115953, 0.11280336266257514, 0.05648457235205667, 0.36120630002843257, 1.25426385582883126, 0.48661058451606820, -0.57030511336562195, 0.49151280464818098, 0.04428280690189127, -0.06591965049732286, -0.72616125524587938, -0.21690068430020618, -0.11507583016077781, -0.36583546331208316, -3.16186335125594642, -0.57030511336562195, 1.16270815038078945, -0.14837898963724327, 0.05917203395002889, 0.06055771542862331, 1.03490136002022926, 0.04065087561300068, 0.01475756130709823, 0.41472509341940023, -0.19740140818905436, 0.49151280464818103, -0.14837898963724327, 0.86693820682049716, 0.14089688752570340, 0.00577423310349649, 0.12800239664439328, -0.00876895259593769, -0.00584453679519805, 0.04581458758255480, -0.26613760880058035, 0.04428280690189126, 0.05917203395002889, 0.14089688752570340, 0.02901858439788401 }, 10, 10);}
private static Matrix mahout_f7603_0(double[] values, int rows, int columns)
{    Matrix m = new DenseMatrix(rows, columns);    int i = 0;    for (double v : values) {        m.set(i % rows, i / rows, v);        i++;    }    return m;}
public void mahout_f7604_0()
{    Matrix A = lowRankMatrix();    SequentialBigSvd s = new SequentialBigSvd(A, 8);    SingularValueDecomposition svd = new SingularValueDecomposition(A);    Vector reference = new DenseVector(svd.getSingularValues()).viewPart(0, 8);    assertEquals(reference, s.getSingularValues());    assertEquals(A, s.getU().times(new DiagonalMatrix(s.getSingularValues())).times(s.getV().transpose()));}
public void mahout_f7605_0()
{    Matrix A = lowRankMatrix();    SequentialBigSvd s = new SequentialBigSvd(A, 8);    SingularValueDecomposition svd = new SingularValueDecomposition(A);            Matrix u1 = svd.getU().viewPart(0, 20, 0, 4).assign(Functions.ABS);    Matrix u2 = s.getU().viewPart(0, 20, 0, 4).assign(Functions.ABS);    assertEquals(0, u1.minus(u2).aggregate(Functions.PLUS, Functions.ABS), 1.0e-9);}
private static void mahout_f7606_0(Matrix u1, Matrix u2)
{    assertEquals(0, u1.minus(u2).aggregate(Functions.MAX, Functions.ABS), 1.0e-10);}
private static void mahout_f7607_0(Vector u1, Vector u2)
{    assertEquals(0, u1.minus(u2).aggregate(Functions.MAX, Functions.ABS), 1.0e-10);}
public void mahout_f7608_0()
{    Matrix A = lowRankMatrix();    SequentialBigSvd s = new SequentialBigSvd(A, 6);    SingularValueDecomposition svd = new SingularValueDecomposition(A);    Matrix v1 = svd.getV().viewPart(0, 20, 0, 3).assign(Functions.ABS);    Matrix v2 = s.getV().viewPart(0, 20, 0, 3).assign(Functions.ABS);    assertEquals(v1, v2);}
private static Matrix mahout_f7609_0()
{    Matrix u = new RandomTrinaryMatrix(1, 20, 4, false);    Matrix d = new DiagonalMatrix(new double[] { 5, 3, 1, 0.5 });    Matrix v = new RandomTrinaryMatrix(2, 23, 4, false);    return u.times(d).times(v.transpose());}
public void mahout_f7610_0() throws Exception
{    assertEquals(1.386294, LogLikelihood.entropy(1, 1), 0.0001);    assertEquals(0.0, LogLikelihood.entropy(1), 0.0);        try {                LogLikelihood.entropy(-1, -1);        fail();    } catch (IllegalArgumentException e) {    }}
public void mahout_f7611_0() throws Exception
{        assertEquals(2.772589, LogLikelihood.logLikelihoodRatio(1, 0, 0, 1), 0.000001);    assertEquals(27.72589, LogLikelihood.logLikelihoodRatio(10, 0, 0, 10), 0.00001);    assertEquals(39.33052, LogLikelihood.logLikelihoodRatio(5, 1995, 0, 100000), 0.00001);    assertEquals(4730.737, LogLikelihood.logLikelihoodRatio(1000, 1995, 1000, 100000), 0.001);    assertEquals(5734.343, LogLikelihood.logLikelihoodRatio(1000, 1000, 1000, 100000), 0.001);    assertEquals(5714.932, LogLikelihood.logLikelihoodRatio(1000, 1000, 1000, 99000), 0.001);}
public void mahout_f7612_0()
{        assertTrue(LogLikelihood.rootLogLikelihoodRatio(904, 21060, 1144, 283012) > 0.0);        assertTrue(LogLikelihood.rootLogLikelihoodRatio(36, 21928, 60280, 623876) < 0.0);    assertEquals(Math.sqrt(2.772589), LogLikelihood.rootLogLikelihoodRatio(1, 0, 0, 1), 0.000001);    assertEquals(-Math.sqrt(2.772589), LogLikelihood.rootLogLikelihoodRatio(0, 1, 1, 0), 0.000001);    assertEquals(Math.sqrt(27.72589), LogLikelihood.rootLogLikelihoodRatio(10, 0, 0, 10), 0.00001);    assertEquals(Math.sqrt(39.33052), LogLikelihood.rootLogLikelihoodRatio(5, 1995, 0, 100000), 0.00001);    assertEquals(-Math.sqrt(39.33052), LogLikelihood.rootLogLikelihoodRatio(0, 100000, 5, 1995), 0.00001);    assertEquals(Math.sqrt(4730.737), LogLikelihood.rootLogLikelihoodRatio(1000, 1995, 1000, 100000), 0.001);    assertEquals(-Math.sqrt(4730.737), LogLikelihood.rootLogLikelihoodRatio(1000, 100000, 1000, 1995), 0.001);    assertEquals(Math.sqrt(5734.343), LogLikelihood.rootLogLikelihoodRatio(1000, 1000, 1000, 100000), 0.001);    assertEquals(Math.sqrt(5714.932), LogLikelihood.rootLogLikelihoodRatio(1000, 1000, 1000, 99000), 0.001);}
public void mahout_f7613_0()
{    assertTrue(LogLikelihood.rootLogLikelihoodRatio(6, 7567, 1924, 2426487) >= 0.0);}
public void mahout_f7614_0()
{    final Random rand = RandomUtils.getRandom();            Vector p1 = new DenseVector(25).assign(new DoubleFunction() {        @Override        public double apply(double arg1) {            return -Math.log1p(-rand.nextDouble());        }    });        Vector p2 = p1.like().assign(p1);        p1.viewPart(0, 5).assign(0);        p1.viewPart(5, 3).assign(Functions.mult(4));        p1.assign(Functions.div(p1.norm(1)));        p2.assign(Functions.div(p2.norm(1)));        Multiset<Integer> w1 = HashMultiset.create();    for (int i = 0; i < 100; i++) {        w1.add(sample(p1, rand));    }        Multiset<Integer> w2 = HashMultiset.create();    for (int i = 0; i < 1000; i++) {        w2.add(sample(p2, rand));    }        List<LogLikelihood.ScoredItem<Integer>> r = LogLikelihood.compareFrequencies(w1, w2, 8, 0);    assertTrue(r.size() <= 8);    assertFalse(r.isEmpty());    for (LogLikelihood.ScoredItem<Integer> item : r) {        assertTrue(item.getScore() >= 0);    }        assertEquals(7, (int) r.get(0).getItem());        double lastScore = r.get(0).getScore();    for (LogLikelihood.ScoredItem<Integer> item : r) {        assertTrue(item.getScore() <= lastScore);        lastScore = item.getScore();    }        r = LogLikelihood.compareFrequencies(w1, w2, 40, 1);        assertEquals(2, r.size());    assertEquals(7, (int) r.get(0).getItem());    assertEquals(6, (int) r.get(1).getItem());    r = LogLikelihood.compareFrequencies(w1, w2, 1000, -100);    Multiset<Integer> k = HashMultiset.create();    for (LogLikelihood.ScoredItem<Integer> item : r) {        k.add(item.getItem());    }    for (int i = 0; i < 25; i++) {        assertTrue("i = " + i, k.count(i) == 1 || w2.count(i) == 0);    }        assertEquals(w2.elementSet().size(), r.size());    assertEquals(7, (int) r.get(0).getItem());    assertEquals(6, (int) r.get(1).getItem());        assertTrue(r.get(r.size() - 1).getScore() < 0);        lastScore = r.get(0).getScore();    for (LogLikelihood.ScoredItem<Integer> item : r) {        assertTrue(item.getScore() <= lastScore);        lastScore = item.getScore();    }}
public double mahout_f7615_0(double arg1)
{    return -Math.log1p(-rand.nextDouble());}
private static int mahout_f7616_0(Vector p, Random rand)
{    double u = rand.nextDouble();        for (int i = 0; i < p.size(); i++) {        if (u <= p.get(i)) {            return i;        }        u -= p.get(i);    }    return p.size() - 1;}
public void mahout_f7617_0()
{    double[] t = { 11.35718, 21.54637, 28.91061, 33.03586, 39.57767 };    double[] x = { 1.5992071, -1.3577032, -0.3405638, 0.7048632, 0.3020558 };    double[] m = { 1.5992071, -1.0168100, -0.4797436, 0.2836447, 0.2966159 };    OnlineExponentialAverage averager = new OnlineExponentialAverage(5);    for (int i = 0; i < t.length; i++) {        averager.add(t[i], x[i]);        assertEquals("Step " + i, m[i], averager.mean(), 1.0e-6);    }}
public void mahout_f7618_0()
{    Random gen = RandomUtils.getRandom();    Poisson p = new Poisson(5, gen);    double lastT = 0;    double[] k = new double[1000];    double[] t = new double[1000];    for (int i = 1; i < 1000; i++) {                double dt = gen.nextDouble() * 10 + 5;        t[i] = lastT + dt;                k[i] = p.nextInt(dt * 0.2);        lastT = t[i];    }    OnlineExponentialAverage averager = new OnlineExponentialAverage(2000);    for (int i = 1; i < 1000; i++) {        averager.add(t[i], k[i]);    }    assertEquals("Expected rate", 0.2, averager.meanRate(), 0.01);}
public void mahout_f7619_0()
{    /**     *     the reference limits here were derived using a numerical simulation where I took     *     10,000 samples from the distribution in question and computed the stats from that     *     sample to get min, 25%-ile, median and so on. I did this 1000 times to get 5% and     *     95% confidence limits for those values.     */        System.out.printf("normal\n");    check(normal(10000));        System.out.printf("exp\n");    check(exp(10000));        System.out.printf("gamma\n");    check(gamma(10000, 0.1));}
private static void mahout_f7620_0(double[] samples)
{    OnlineSummarizer s = new OnlineSummarizer();    double mean = 0;    double sd = 0;    int n = 1;    for (double x : samples) {        s.add(x);        double old = mean;        mean += (x - mean) / n;        sd += (x - old) * (x - mean);        n++;    }    sd = Math.sqrt(sd / samples.length);    Arrays.sort(samples);                        assertEquals("mean", s.getMean(), mean, 0);    assertEquals("sd", s.getSD(), sd, 1e-8);}
private static double[] mahout_f7621_0(int n)
{    double[] r = new double[n];    Random gen = RandomUtils.getRandom(1L);    for (int i = 0; i < n; i++) {        r[i] = gen.nextGaussian();    }    return r;}
private static double[] mahout_f7622_0(int n)
{    double[] r = new double[n];    Random gen = RandomUtils.getRandom(1L);    for (int i = 0; i < n; i++) {        r[i] = -Math.log1p(-gen.nextDouble());    }    return r;}
private static double[] mahout_f7623_0(int n, double shape)
{    double[] r = new double[n];    Random gen = RandomUtils.getRandom();    AbstractContinousDistribution gamma = new Gamma(shape, shape, gen);    for (int i = 0; i < n; i++) {        r[i] = gamma.nextDouble();    }    return r;}
public Matrix mahout_f7624_0(double[][] values)
{    return new DenseMatrix(values);}
public void mahout_f7625_0()
{    DenseMatrix m = new DenseMatrix(10, 10);    for (int i = 0; i < 10; i++) {        for (int j = 0; j < 10; j++) {            m.set(i, j, 10 * i + j);        }    }    double[][] values = m.getBackingStructure();    Assert.assertEquals(values.length, 10);    Assert.assertEquals(values[0].length, 10);    Assert.assertEquals(values[9][9], 99.0, 0.0);}
 Vector mahout_f7626_0(int cardinality)
{    return new DenseVector(cardinality);}
public void mahout_f7627_0()
{    assertEquals("size", 3, getTestVector().getNumNonZeroElements());}
public DenseVector mahout_f7628_0(int size)
{    DenseVector r = new DenseVector(size);    r.assign(Functions.random());    return r;}
public void mahout_f7629_0()
{    super.testToString();}
public void mahout_f7630_0() throws Exception
{    super.setUp();    int[] offset = { 1, 1 };    int[] card = { 3, 2 };    test = new MatrixView(new DenseMatrix(values), offset, card);}
public void mahout_f7631_0()
{    assertEquals("row cardinality", values.length - 2, test.rowSize());    assertEquals("col cardinality", values[0].length - 1, test.columnSize());}
public void mahout_f7632_0()
{    Matrix copy = test.clone();    assertTrue("wrong class", copy instanceof MatrixView);    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', test.getQuick(row, col), copy.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7633_0()
{    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', values[row + 1][col + 1], test.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7634_0()
{    Matrix like = test.like();    assertTrue("type", like instanceof DenseMatrix);    assertEquals("rows", test.rowSize(), like.rowSize());    assertEquals("columns", test.columnSize(), like.columnSize());}
public void mahout_f7635_0()
{    Matrix like = test.like(4, 4);    assertTrue("type", like instanceof DenseMatrix);    assertEquals("rows", 4, like.rowSize());    assertEquals("columns", 4, like.columnSize());}
public void mahout_f7636_0()
{    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            test.setQuick(row, col, 1.23);            assertEquals("value[" + row + "][" + col + ']', 1.23, test.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7637_0()
{    assertEquals("row size", values.length - 2, test.rowSize());    assertEquals("col size", values[0].length - 1, test.columnSize());}
public void mahout_f7638_0()
{    int[] offset = { 1, 1 };    int[] size = { 2, 1 };    Matrix view = test.viewPart(offset, size);    for (int row = 0; row < view.rowSize(); row++) {        for (int col = 0; col < view.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', values[row + 2][col + 2], view.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7639_0()
{    int[] offset = { 1, 1 };    int[] size = { 3, 3 };    test.viewPart(offset, size);}
public void mahout_f7640_0()
{    int[] offset = { 1, 1 };    int[] size = { 2, 2 };    test.viewPart(offset, size);}
public void mahout_f7641_0()
{    int[] offset = { -1, -1 };    int[] size = { 2, 2 };    test.viewPart(offset, size);}
public void mahout_f7642_0()
{    test.assign(4.53);    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', 4.53, test.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7643_0()
{    test.assign(new double[3][2]);    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', 0.0, test.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7644_0()
{    test.assign(new double[test.rowSize() + 1][test.columnSize()]);}
public void mahout_f7645_0()
{    test.assign(test, Functions.PLUS);    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', 2 * values[row + 1][col + 1], test.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7646_0()
{    test.assign(test.transpose(), Functions.PLUS);}
public void mahout_f7647_0()
{    Matrix value = test.like();    value.assign(test);    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', test.getQuick(row, col), value.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7648_0()
{    test.assign(test.transpose());}
public void mahout_f7649_0()
{    test.assign(Functions.NEGATE);    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', -values[row + 1][col + 1], test.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7650_0()
{    Matrix value = test.divide(4.53);    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', values[row + 1][col + 1] / 4.53, value.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7651_0()
{    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', values[row + 1][col + 1], test.get(row, col), EPSILON);        }    }}
public void mahout_f7652_0()
{    for (int row = -1; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            test.get(row, col);        }    }}
public void mahout_f7653_0()
{    for (int row = 0; row < test.rowSize() + 1; row++) {        for (int col = 0; col < test.columnSize(); col++) {            test.get(row, col);        }    }}
public void mahout_f7654_0()
{    Matrix value = test.minus(test);    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', 0.0, value.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7655_0()
{    test.minus(test.transpose());}
public void mahout_f7656_0()
{    Matrix value = test.plus(4.53);    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', values[row + 1][col + 1] + 4.53, value.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7657_0()
{    Matrix value = test.plus(test);    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', values[row + 1][col + 1] * 2, value.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7658_0()
{    test.plus(test.transpose());}
public void mahout_f7659_0()
{    for (int row = -1; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            test.set(row, col, 1.23);        }    }}
public void mahout_f7660_0()
{    for (int row = 0; row < test.rowSize() + 1; row++) {        for (int col = 0; col < test.columnSize(); col++) {            test.set(row, col, 1.23);        }    }}
public void mahout_f7661_0()
{    Matrix value = test.times(4.53);    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', values[row + 1][col + 1] * 4.53, value.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7662_0()
{    Matrix transpose = test.transpose();    Matrix value = test.times(transpose);    assertEquals("rows", test.rowSize(), value.rowSize());    assertEquals("cols", test.rowSize(), value.columnSize());}
public void mahout_f7663_0()
{    Matrix other = test.like(5, 8);    test.times(other);}
public void mahout_f7664_0()
{    Matrix transpose = test.transpose();    assertEquals("rows", test.columnSize(), transpose.rowSize());    assertEquals("cols", test.rowSize(), transpose.columnSize());    for (int row = 0; row < test.rowSize(); row++) {        for (int col = 0; col < test.columnSize(); col++) {            assertEquals("value[" + row + "][" + col + ']', test.getQuick(row, col), transpose.getQuick(col, row), EPSILON);        }    }}
public void mahout_f7665_0()
{    double sum = test.zSum();    assertEquals("zsum", 29.7, sum, EPSILON);}
public void mahout_f7666_0()
{    double[] data = { 2.1, 3.2 };    test.assignRow(1, new DenseVector(data));    assertEquals("test[1][0]", 2.1, test.getQuick(1, 0), EPSILON);    assertEquals("test[1][1]", 3.2, test.getQuick(1, 1), EPSILON);}
public void mahout_f7667_0()
{    double[] data = { 2.1, 3.2, 4.3 };    test.assignRow(1, new DenseVector(data));}
public void mahout_f7668_0()
{    double[] data = { 2.1, 3.2, 4.3 };    test.assignColumn(1, new DenseVector(data));    assertEquals("test[0][1]", 2.1, test.getQuick(0, 1), EPSILON);    assertEquals("test[1][1]", 3.2, test.getQuick(1, 1), EPSILON);    assertEquals("test[2][1]", 4.3, test.getQuick(2, 1), EPSILON);}
public void mahout_f7669_0()
{    double[] data = { 2.1, 3.2 };    test.assignColumn(1, new DenseVector(data));}
public void mahout_f7670_0()
{    Vector row = test.viewRow(1);    assertEquals("row size", 2, row.getNumNondefaultElements());}
public void mahout_f7671_0()
{    test.viewRow(-1);}
public void mahout_f7672_0()
{    test.viewRow(5);}
public void mahout_f7673_0()
{    Vector column = test.viewColumn(1);    assertEquals("row size", 3, column.getNumNondefaultElements());    int i = 0;    for (double x : new double[] { 3.3, 5.5, 7.7 }) {        assertEquals(x, column.get(i++), 0);    }}
public void mahout_f7674_0()
{    test.viewColumn(-1);}
public void mahout_f7675_0()
{    test.viewColumn(5);}
public void mahout_f7676_0()
{    assertNull("row bindings", test.getRowLabelBindings());    assertNull("col bindings", test.getColumnLabelBindings());    Map<String, Integer> rowBindings = Maps.newHashMap();    rowBindings.put("Fee", 0);    rowBindings.put("Fie", 1);    test.setRowLabelBindings(rowBindings);    assertEquals("row", rowBindings, test.getRowLabelBindings());    Map<String, Integer> colBindings = Maps.newHashMap();    colBindings.put("Foo", 0);    colBindings.put("Bar", 1);    test.setColumnLabelBindings(colBindings);    assertEquals("row", rowBindings, test.getRowLabelBindings());    assertEquals("Fee", test.get(0, 1), test.get("Fee", "Bar"), EPSILON);    double[] newrow = { 9, 8 };    test.set("Fie", newrow);    assertEquals("FeeBar", test.get(0, 1), test.get("Fee", "Bar"), EPSILON);}
public void mahout_f7677_0()
{    assertNull("row bindings", test.getRowLabelBindings());    assertNull("col bindings", test.getColumnLabelBindings());    test.set("Fee", "Foo", 1, 1, 9);    assertNotNull("row", test.getRowLabelBindings());    assertNotNull("row", test.getRowLabelBindings());    assertEquals("Fee", 1, test.getRowLabelBindings().get("Fee").intValue());    assertEquals("Foo", 1, test.getColumnLabelBindings().get("Foo").intValue());    assertEquals("FeeFoo", test.get(1, 1), test.get("Fee", "Foo"), EPSILON);    test.get("Fie", "Foe");}
public void mahout_f7678_0()
{    assertNull("row bindings", test.getRowLabelBindings());    assertNull("col bindings", test.getColumnLabelBindings());    Map<String, Integer> rowBindings = Maps.newHashMap();    rowBindings.put("Fee", 0);    rowBindings.put("Fie", 1);    rowBindings.put("Foe", 2);    test.setRowLabelBindings(rowBindings);    assertEquals("row", rowBindings, test.getRowLabelBindings());    Map<String, Integer> colBindings = Maps.newHashMap();    colBindings.put("Foo", 0);    colBindings.put("Bar", 1);    colBindings.put("Baz", 2);    test.setColumnLabelBindings(colBindings);    assertEquals("col", colBindings, test.getColumnLabelBindings());}
public void mahout_f7679_0()
{    OrderedIntDoubleMapping mapping = new OrderedIntDoubleMapping(1);    assertEquals(0, mapping.getNumMappings());    assertEquals(0.0, mapping.get(0), EPSILON);    assertEquals(0.0, mapping.get(1), EPSILON);    mapping.set(0, 1.1);    assertEquals(1, mapping.getNumMappings());    assertEquals(1.1, mapping.get(0), EPSILON);    assertEquals(0.0, mapping.get(1), EPSILON);    mapping.set(5, 6.6);    assertEquals(2, mapping.getNumMappings());    assertEquals(1.1, mapping.get(0), EPSILON);    assertEquals(0.0, mapping.get(1), EPSILON);    assertEquals(6.6, mapping.get(5), EPSILON);    assertEquals(0.0, mapping.get(6), EPSILON);    mapping.set(0, 0.0);    assertEquals(1, mapping.getNumMappings());    assertEquals(0.0, mapping.get(0), EPSILON);    assertEquals(0.0, mapping.get(1), EPSILON);    assertEquals(6.6, mapping.get(5), EPSILON);    mapping.set(5, 0.0);    assertEquals(0, mapping.getNumMappings());    assertEquals(0.0, mapping.get(0), EPSILON);    assertEquals(0.0, mapping.get(1), EPSILON);    assertEquals(0.0, mapping.get(5), EPSILON);}
public void mahout_f7680_0() throws Exception
{    OrderedIntDoubleMapping mapping = new OrderedIntDoubleMapping(1);    mapping.set(0, 1.1);    mapping.set(5, 6.6);    OrderedIntDoubleMapping clone = mapping.clone();    assertEquals(2, clone.getNumMappings());    assertEquals(1.1, clone.get(0), EPSILON);    assertEquals(0.0, clone.get(1), EPSILON);    assertEquals(6.6, clone.get(5), EPSILON);    assertEquals(0.0, clone.get(6), EPSILON);}
public void mahout_f7681_0()
{    OrderedIntDoubleMapping mapping = new OrderedIntDoubleMapping(false);    mapping.set(1, 1.1);    assertEquals(1, mapping.getNumMappings());    mapping.set(2, 0);    assertEquals(2, mapping.getNumMappings());    mapping.set(0, 0);    assertEquals(3, mapping.getNumMappings());}
public void mahout_f7682_0()
{    OrderedIntDoubleMapping mappingOne = new OrderedIntDoubleMapping(false);    mappingOne.set(0, 0);    mappingOne.set(2, 2);    mappingOne.set(4, 4);    mappingOne.set(10, 10);    OrderedIntDoubleMapping mappingTwo = new OrderedIntDoubleMapping();    mappingTwo.set(1, 1);    mappingTwo.set(3, 3);    mappingTwo.set(5, 5);    mappingTwo.set(10, 20);    mappingOne.merge(mappingTwo);    assertEquals(7, mappingOne.getNumMappings());    for (int i = 0; i < 6; ++i) {        assertEquals(i, mappingOne.get(i), i);    }    assertEquals(20, mappingOne.get(10), 0);}
 Vector mahout_f7683_0(int cardinality)
{    return new RandomAccessSparseVector(cardinality);}
public RandomAccessSparseVector mahout_f7684_0(int size)
{    RandomAccessSparseVector r = new RandomAccessSparseVector(size);    Random gen = RandomUtils.getRandom();    for (int i = 0; i < 3; i++) {        r.set(gen.nextInt(r.size()), gen.nextGaussian());    }    return r;}
public void mahout_f7685_0()
{    Vector w;    w = generateTestVector(20);    w.set(0, 1.1);    w.set(13, 100500.);    w.set(19, 3.141592);    for (String token : Splitter.on(',').split(w.toString().substring(1, w.toString().length() - 1))) {        String[] tokens = token.split(":");        assertEquals(Double.parseDouble(tokens[1]), w.get(Integer.parseInt(tokens[0])), 0.0);    }    w = generateTestVector(12);    w.set(10, 0.1);    assertEquals("{10:0.1}", w.toString());    w = generateTestVector(12);    assertEquals("{}", w.toString());}
 Vector mahout_f7686_0(int cardinality)
{    return new SequentialAccessSparseVector(cardinality);}
public void mahout_f7687_0()
{    Vector w = new SequentialAccessSparseVector(Integer.MAX_VALUE, 12);    w.set(1, 0.4);    w.set(2, 0.4);    w.set(3, -0.666666667);    Vector v = new SequentialAccessSparseVector(Integer.MAX_VALUE, 12);    v.set(3, 1);    assertEquals("super-big", -0.666666667, v.dot(w), EPSILON);}
public SequentialAccessSparseVector mahout_f7688_0(int size)
{    SequentialAccessSparseVector r = new SequentialAccessSparseVector(size);    Random gen = RandomUtils.getRandom();    for (int i = 0; i < 3; i++) {        r.set(gen.nextInt(r.size()), gen.nextGaussian());    }    return r;}
public void mahout_f7689_0()
{    super.testToString();}
public void mahout_f7690_0()
{    double[] singularValues = { 123.456, 2.3, 1.001, 0.999 };    int rows = singularValues.length + 2;    int columns = singularValues.length;    Random r = RandomUtils.getRandom();    SingularValueDecomposition svd = new SingularValueDecomposition(createTestMatrix(r, rows, columns, singularValues));    double[] computedSV = svd.getSingularValues();    assertEquals(singularValues.length, computedSV.length);    for (int i = 0; i < singularValues.length; ++i) {        assertEquals(singularValues[i], computedSV[i], 1.0e-10);    }}
public void mahout_f7691_0()
{    double[] singularValues = { 123.456, 2.3, 1.001, 0.999 };    int rows = singularValues.length;    int columns = singularValues.length + 2;    Random r = RandomUtils.getRandom();    SingularValueDecomposition svd = new SingularValueDecomposition(createTestMatrix(r, rows, columns, singularValues));    double[] computedSV = svd.getSingularValues();    assertEquals(singularValues.length, computedSV.length);    for (int i = 0; i < singularValues.length; ++i) {        assertEquals(singularValues[i], computedSV[i], 1.0e-10);    }}
public void mahout_f7692_0()
{    Matrix matrix = new DenseMatrix(testSquare);    int m = matrix.numRows();    int n = matrix.numCols();    SingularValueDecomposition svd = new SingularValueDecomposition(matrix);    assertEquals(m, svd.getU().numRows());    assertEquals(m, svd.getU().numCols());    assertEquals(m, svd.getS().numCols());    assertEquals(n, svd.getS().numCols());    assertEquals(n, svd.getV().numRows());    assertEquals(n, svd.getV().numCols());}
public void mahout_f7693_0()
{    Matrix matrix = new DenseMatrix(new double[][] { { 15.0 / 2.0, 5.0 / 2.0, 9.0 / 2.0, 3.0 / 2.0 }, { 5.0 / 2.0, 15.0 / 2.0, 3.0 / 2.0, 9.0 / 2.0 }, { 9.0 / 2.0, 3.0 / 2.0, 15.0 / 2.0, 5.0 / 2.0 }, { 3.0 / 2.0, 9.0 / 2.0, 5.0 / 2.0, 15.0 / 2.0 } });    SingularValueDecomposition svd = new SingularValueDecomposition(matrix);    assertEquals(16.0, svd.getSingularValues()[0], 1.0e-14);    assertEquals(8.0, svd.getSingularValues()[1], 1.0e-14);    assertEquals(4.0, svd.getSingularValues()[2], 1.0e-14);    assertEquals(2.0, svd.getSingularValues()[3], 1.0e-14);    Matrix fullCovariance = new DenseMatrix(new double[][] { { 85.0 / 1024, -51.0 / 1024, -75.0 / 1024, 45.0 / 1024 }, { -51.0 / 1024, 85.0 / 1024, 45.0 / 1024, -75.0 / 1024 }, { -75.0 / 1024, 45.0 / 1024, 85.0 / 1024, -51.0 / 1024 }, { 45.0 / 1024, -75.0 / 1024, -51.0 / 1024, 85.0 / 1024 } });    assertEquals(0.0, Algebra.getNorm(fullCovariance.minus(svd.getCovariance(0.0))), 1.0e-14);    Matrix halfCovariance = new DenseMatrix(new double[][] { { 5.0 / 1024, -3.0 / 1024, 5.0 / 1024, -3.0 / 1024 }, { -3.0 / 1024, 5.0 / 1024, -3.0 / 1024, 5.0 / 1024 }, { 5.0 / 1024, -3.0 / 1024, 5.0 / 1024, -3.0 / 1024 }, { -3.0 / 1024, 5.0 / 1024, -3.0 / 1024, 5.0 / 1024 } });    assertEquals(0.0, Algebra.getNorm(halfCovariance.minus(svd.getCovariance(6.0))), 1.0e-14);}
public void mahout_f7694_0()
{    checkAEqualUSVt(new DenseMatrix(testSquare));    checkAEqualUSVt(new DenseMatrix(testNonSquare));    checkAEqualUSVt(new DenseMatrix(testNonSquare).transpose());}
public static void mahout_f7695_0(Matrix matrix)
{    SingularValueDecomposition svd = new SingularValueDecomposition(matrix);    Matrix u = svd.getU();    Matrix s = svd.getS();    Matrix v = svd.getV();        if (s.numRows() < matrix.numRows()) {        Matrix sp = new DenseMatrix(s.numRows() + 1, s.numCols());        Matrix up = new DenseMatrix(u.numRows(), u.numCols() + 1);        for (int i = 0; i < u.numRows(); i++) {            for (int j = 0; j < u.numCols(); j++) {                up.set(i, j, u.get(i, j));            }        }        for (int i = 0; i < s.numRows(); i++) {            for (int j = 0; j < s.numCols(); j++) {                sp.set(i, j, s.get(i, j));            }        }        u = up;        s = sp;    }    double norm = Algebra.getNorm(u.times(s).times(v.transpose()).minus(matrix));    assertEquals(0, norm, NORM_TOLERANCE);}
public void mahout_f7696_0()
{    checkOrthogonal(new SingularValueDecomposition(new DenseMatrix(testSquare)).getU());    checkOrthogonal(new SingularValueDecomposition(new DenseMatrix(testNonSquare)).getU());    checkOrthogonal(new SingularValueDecomposition(new DenseMatrix(testNonSquare).transpose()).getU());}
public void mahout_f7697_0()
{    checkOrthogonal(new SingularValueDecomposition(new DenseMatrix(testSquare)).getV());    checkOrthogonal(new SingularValueDecomposition(new DenseMatrix(testNonSquare)).getV());    checkOrthogonal(new SingularValueDecomposition(new DenseMatrix(testNonSquare).transpose()).getV());}
public static void mahout_f7698_0(Matrix m)
{    Matrix mTm = m.transpose().times(m);    Matrix id = new DenseMatrix(mTm.numRows(), mTm.numRows());    for (int i = 0; i < mTm.numRows(); i++) {        id.set(i, i, 1);    }    assertEquals(0, Algebra.getNorm(mTm.minus(id)), NORM_TOLERANCE);}
public void mahout_f7699_0()
{    SingularValueDecomposition svd = new SingularValueDecomposition(new DenseMatrix(testSquare));    Matrix uRef = new DenseMatrix(new double[][] { { 3.0 / 5.0, 4.0 / 5.0 }, { 4.0 / 5.0, -3.0 / 5.0 } });    Matrix sRef = new DenseMatrix(new double[][] { { 3.0, 0.0 }, { 0.0, 1.0 } });    Matrix vRef = new DenseMatrix(new double[][] { { 4.0 / 5.0, -3.0 / 5.0 }, { 3.0 / 5.0, 4.0 / 5.0 } });        Matrix u = svd.getU();    assertEquals(0, Algebra.getNorm(u.minus(uRef)), NORM_TOLERANCE);    Matrix s = svd.getS();    assertEquals(0, Algebra.getNorm(s.minus(sRef)), NORM_TOLERANCE);    Matrix v = svd.getV();    assertEquals(0, Algebra.getNorm(v.minus(vRef)), NORM_TOLERANCE);}
public void mahout_f7700_0()
{    SingularValueDecomposition svd = new SingularValueDecomposition(new DenseMatrix(testSquare));        assertEquals(3.0, svd.cond(), 1.5e-15);}
public void mahout_f7701_0() throws IOException, InterruptedException, ExecutionException, TimeoutException
{    System.out.printf("starting hanging-svd\n");    final Matrix m = readTsv("hanging-svd.tsv");    SingularValueDecomposition svd = new SingularValueDecomposition(m);    assertEquals(0, m.minus(svd.getU().times(svd.getS()).times(svd.getV().transpose())).aggregate(Functions.PLUS, Functions.ABS), 1e-10);    System.out.printf("No hang\n");}
 Matrix mahout_f7702_0(String name) throws IOException
{    Splitter onTab = Splitter.on("\t");    List<String> lines = Resources.readLines((Resources.getResource(name)), Charsets.UTF_8);    int rows = lines.size();    int columns = Iterables.size(onTab.split(lines.get(0)));    Matrix r = new DenseMatrix(rows, columns);    int row = 0;    for (String line : lines) {        Iterable<String> values = onTab.split(line);        int column = 0;        for (String value : values) {            r.set(row, column, Double.parseDouble(value));            column++;        }        row++;    }    return r;}
private static Matrix mahout_f7703_0(Random r, int rows, int columns, double[] singularValues)
{    Matrix u = createOrthogonalMatrix(r, rows);    Matrix d = createDiagonalMatrix(singularValues, rows, columns);    Matrix v = createOrthogonalMatrix(r, columns);    return u.times(d).times(v);}
public static Matrix mahout_f7704_0(Random r, int size)
{    double[][] data = new double[size][size];    for (int i = 0; i < size; ++i) {        double[] dataI = data[i];        double norm2;        do {                        for (int j = 0; j < size; ++j) {                dataI[j] = 2 * r.nextDouble() - 1;            }                        for (int k = 0; k < i; ++k) {                double[] dataK = data[k];                double dotProduct = 0;                for (int j = 0; j < size; ++j) {                    dotProduct += dataI[j] * dataK[j];                }                for (int j = 0; j < size; ++j) {                    dataI[j] -= dotProduct * dataK[j];                }            }                        norm2 = 0;            for (double dataIJ : dataI) {                norm2 += dataIJ * dataIJ;            }            double inv = 1.0 / Math.sqrt(norm2);            for (int j = 0; j < size; ++j) {                dataI[j] *= inv;            }        } while (norm2 * size < 0.01);    }    return new DenseMatrix(data);}
public static Matrix mahout_f7705_0(double[] diagonal, int rows, int columns)
{    double[][] dData = new double[rows][columns];    for (int i = 0; i < Math.min(rows, columns); ++i) {        dData[i][i] = diagonal[i];    }    return new DenseMatrix(dData);}
public Matrix mahout_f7706_0(double[][] values)
{    Matrix matrix = new SparseColumnMatrix(values.length, values[0].length);    for (int row = 0; row < matrix.rowSize(); row++) {        for (int col = 0; col < matrix.columnSize(); col++) {            matrix.setQuick(row, col, values[row][col]);        }    }    return matrix;}
public void mahout_f7707_0()
{}
public Matrix mahout_f7708_0(double[][] values)
{    Matrix matrix = new SparseMatrix(values.length, values[0].length);    for (int row = 0; row < matrix.rowSize(); row++) {        for (int col = 0; col < matrix.columnSize(); col++) {            matrix.setQuick(row, col, values[row][col]);        }    }    return matrix;}
public void mahout_f7709_0()
{    Matrix a = new SparseMatrix(3, 3);    a.set(0, 0, 1);    a.set(0, 2, 3);    a.set(2, 0, 1);    a.set(2, 1, 2);    Matrix b = new SparseMatrix(3, 3);    b.set(0, 0, 3);    b.set(0, 2, 1);    b.set(1, 1, 5);    b.set(2, 2, 2);    a.assign(b, Functions.PLUS);    assertEquals(4, a.getQuick(0, 0), 0.0);    assertEquals(0, a.getQuick(0, 1), 0.0);    assertEquals(4, a.getQuick(0, 2), 0.0);    assertEquals(0, a.getQuick(1, 0), 0.0);    assertEquals(5, a.getQuick(1, 1), 0.0);    assertEquals(0, a.getQuick(1, 2), 0.0);    assertEquals(1, a.getQuick(2, 0), 0.0);    assertEquals(2, a.getQuick(2, 1), 0.0);    assertEquals(2, a.getQuick(2, 2), 0.0);}
public void mahout_f7710_0()
{    SparseMatrix matrix = createSparseMatrixWithEmptyRow();    Matrix copy = matrix.clone();    assertSame("wrong class", copy.getClass(), matrix.getClass());    SparseMatrix castedCopy = (SparseMatrix) copy;    Iterator<MatrixSlice> originalSlices = matrix.iterator();    Iterator<MatrixSlice> copySlices = castedCopy.iterator();    while (originalSlices.hasNext() && copySlices.hasNext()) {        MatrixSlice originalSlice = originalSlices.next();        MatrixSlice copySlice = copySlices.next();        assertEquals("Wrong row indices.", originalSlice.index(), copySlice.index());        assertEquals("Slices are not equal.", originalSlice, copySlice);    }    assertSame("Number of rows of original and copy are not equal.", originalSlices.hasNext(), copySlices.hasNext());}
private SparseMatrix mahout_f7711_0()
{    SparseMatrix result = new SparseMatrix(3, 3);    result.setQuick(0, 0, 1);    result.setQuick(1, 1, 1);    result.setQuick(1, 2, 1);    return result;}
public Matrix mahout_f7712_0(double[][] values)
{    Matrix matrix = new SparseRowMatrix(values.length, values[0].length);    for (int row = 0; row < matrix.rowSize(); row++) {        for (int col = 0; col < matrix.columnSize(); col++) {            matrix.setQuick(row, col, values[row][col]);        }    }    return matrix;}
public void mahout_f7713_0()
{    Random raw = RandomUtils.getRandom();    Gamma gen = new Gamma(0.1, 0.1, raw);        Matrix x = new SparseRowMatrix(1000, 2000, false);    for (int i = 0; i < 1000; i++) {        int[] values = new int[1000];        for (int k = 0; k < 1000; k++) {            int j = (int) Math.min(1000, gen.nextDouble());            values[j]++;        }        for (int j = 0; j < 1000; j++) {            if (values[j] > 0) {                x.set(i, j, values[j]);            }        }    }    Matrix y = new SparseRowMatrix(2000, 1000, false);    for (int i = 0; i < 2000; i++) {        int[] values = new int[1000];        for (int k = 0; k < 1000; k++) {            int j = (int) Math.min(1000, gen.nextDouble());            values[j]++;        }        for (int j = 0; j < 1000; j++) {            if (values[j] > 0) {                y.set(i, j, values[j]);            }        }    }    long t0 = System.nanoTime();    Matrix z = x.times(y);    double elapsedTime = (System.nanoTime() - t0) * 1e-6;    System.out.printf("done in %.1f ms\n", elapsedTime);    for (int k = 0; k < 1000; k++) {        int i = (int) (-10 * Math.log(raw.nextDouble()));        int j = (int) (-10 * Math.log(raw.nextDouble()));        Assert.assertEquals(x.viewRow(i).dot(y.viewColumn(j)), z.get(i, j), 1e-12);    }}
public void mahout_f7714_0()
{    Random raw = RandomUtils.getRandom();    Gamma gen = new Gamma(0.1, 0.1, raw);        Matrix x = new SparseRowMatrix(1000, 2000, false);    for (int i = 0; i < 1000; i++) {        int[] values = new int[1000];        for (int k = 0; k < 1000; k++) {            int j = (int) Math.min(1000, gen.nextDouble());            values[j]++;        }        for (int j = 0; j < 1000; j++) {            if (values[j] > 0) {                x.set(i, j, values[j]);            }        }    }    Matrix y = new DenseMatrix(2000, 20);    for (int i = 0; i < 2000; i++) {        for (int j = 0; j < 20; j++) {            y.set(i, j, raw.nextDouble());        }    }    long t0 = System.nanoTime();    Matrix z = x.times(y);    double elapsedTime = (System.nanoTime() - t0) * 1e-6;    System.out.printf("done in %.1f ms\n", elapsedTime);    for (int i = 0; i < 1000; i++) {        for (int j = 0; j < 20; j++) {            Assert.assertEquals(x.viewRow(i).dot(y.viewColumn(j)), z.get(i, j), 1e-12);        }    }}
public void mahout_f7715_0()
{    Random raw = RandomUtils.getRandom();    Gamma gen = new Gamma(0.1, 0.1, raw);        Matrix x = new SparseRowMatrix(1000, 2000, false);    for (int i = 0; i < 1000; i++) {        int[] values = new int[1000];        for (int k = 0; k < 1000; k++) {            int j = (int) Math.min(1000, gen.nextDouble());            values[j]++;        }        for (int j = 0; j < 1000; j++) {            if (values[j] > 0) {                x.set(i, j, values[j]);            }        }    }    Vector d = new DenseVector(2000).assign(Functions.random());    Matrix y = new DiagonalMatrix(d);    long t0 = System.nanoTime();    Matrix z = x.times(y);    double elapsedTime = (System.nanoTime() - t0) * 1e-6;    System.out.printf("done in %.1f ms\n", elapsedTime);    for (MatrixSlice row : z) {        for (Vector.Element element : row.nonZeroes()) {            assertEquals(x.get(row.index(), element.index()) * d.get(element.index()), element.get(), 1e-12);        }    }}
public void mahout_f7716_0()
{    Random raw = RandomUtils.getRandom();        Matrix x = new SparseRowMatrix(100, 2000, false).assign(Functions.random());    Matrix y = new SparseRowMatrix(2000, 100, false).assign(Functions.random());    Matrix xd = new DenseMatrix(100, 2000).assign(x);    Matrix yd = new DenseMatrix(2000, 100).assign(y);    assertEquals(0, xd.times(yd).minus(x.times(y)).aggregate(Functions.PLUS, Functions.ABS), 1e-15);    assertEquals(0, x.times(yd).minus(x.times(y)).aggregate(Functions.PLUS, Functions.ABS), 1e-15);    assertEquals(0, xd.times(y).minus(x.times(y)).aggregate(Functions.PLUS, Functions.ABS), 1e-15);}
public void mahout_f7717_0()
{    assertEquals("size", 3, test.size());}
public void mahout_f7718_0() throws Exception
{    Vector copy = test.clone();    for (int i = 0; i < test.size(); i++) {        assertEquals("copy [" + i + ']', test.get(i), copy.get(i), EPSILON);    }}
public void mahout_f7719_0() throws Exception
{    for (int i = 0; i < test.size(); i++) {        assertEquals("get [" + i + ']', values[i + OFFSET], test.get(i), EPSILON);    }}
public void mahout_f7720_0()
{    test.get(test.size());}
public void mahout_f7721_0() throws Exception
{    VectorView view = new VectorView(new DenseVector(values), OFFSET, CARDINALITY);    double[] gold = { 1.1, 2.2, 3.3 };    Iterator<Vector.Element> iter = view.iterator();    checkIterator(iter, gold);    iter = view.iterateNonZero();    checkIterator(iter, gold);    view = new VectorView(new DenseVector(values), 0, CARDINALITY);    gold = new double[] { 0.0, 1.1, 2.2 };    iter = view.iterator();    checkIterator(iter, gold);    gold = new double[] { 1.1, 2.2 };    iter = view.iterateNonZero();    checkIterator(iter, gold);}
private static void mahout_f7722_0(Iterator<Vector.Element> iter, double[] gold)
{    int i = 0;    while (iter.hasNext()) {        Vector.Element elt = iter.next();        assertEquals(elt.index() + " Value: " + gold[i] + " does not equal: " + elt.get(), gold[i], elt.get(), 0.0);        i++;    }}
public void mahout_f7723_0()
{    test.get(-1);}
public void mahout_f7724_0() throws Exception
{    test.set(2, 4.5);    for (int i = 0; i < test.size(); i++) {        assertEquals("set [" + i + ']', i == 2 ? 4.5 : values[OFFSET + i], test.get(i), EPSILON);    }}
public void mahout_f7725_0() throws Exception
{    assertEquals("size", 3, test.getNumNondefaultElements());}
public void mahout_f7726_0() throws Exception
{    Vector part = test.viewPart(1, 2);    assertEquals("part size", 2, part.getNumNondefaultElements());    for (int i = 0; i < part.size(); i++) {        assertEquals("part[" + i + ']', values[OFFSET + i + 1], part.get(i), EPSILON);    }}
public void mahout_f7727_0()
{    test.viewPart(-1, CARDINALITY);}
public void mahout_f7728_0()
{    test.viewPart(2, CARDINALITY);}
public void mahout_f7729_0()
{    test.viewPart(1, values.length + 1);}
public void mahout_f7730_0() throws Exception
{    double res = test.dot(test);    assertEquals("dot", 1.1 * 1.1 + 2.2 * 2.2 + 3.3 * 3.3, res, EPSILON);}
public void mahout_f7731_0()
{    test.dot(new DenseVector(test.size() + 1));}
public void mahout_f7732_0() throws Exception
{    Vector res = test.normalize();    double mag = Math.sqrt(1.1 * 1.1 + 2.2 * 2.2 + 3.3 * 3.3);    for (int i = 0; i < test.size(); i++) {        assertEquals("dot", values[OFFSET + i] / mag, res.get(i), EPSILON);    }}
public void mahout_f7733_0() throws Exception
{    Vector val = test.minus(test);    assertEquals("size", 3, val.size());    for (int i = 0; i < test.size(); i++) {        assertEquals("get [" + i + ']', 0.0, val.get(i), EPSILON);    }}
public void mahout_f7734_0() throws Exception
{    Vector val = test.plus(1);    assertEquals("size", 3, val.size());    for (int i = 0; i < test.size(); i++) {        assertEquals("get [" + i + ']', values[OFFSET + i] + 1, val.get(i), EPSILON);    }}
public void mahout_f7735_0() throws Exception
{    Vector val = test.plus(test);    assertEquals("size", 3, val.size());    for (int i = 0; i < test.size(); i++) {        assertEquals("get [" + i + ']', values[OFFSET + i] * 2, val.get(i), EPSILON);    }}
public void mahout_f7736_0()
{    test.plus(new DenseVector(test.size() + 1));}
public void mahout_f7737_0() throws Exception
{    Vector val = test.times(3);    assertEquals("size", 3, val.size());    for (int i = 0; i < test.size(); i++) {        assertEquals("get [" + i + ']', values[OFFSET + i] * 3, val.get(i), EPSILON);    }}
public void mahout_f7738_0() throws Exception
{    Vector val = test.divide(3);    assertEquals("size", 3, val.size());    for (int i = 0; i < test.size(); i++) {        assertEquals("get [" + i + ']', values[OFFSET + i] / 3, val.get(i), EPSILON);    }}
public void mahout_f7739_0() throws Exception
{    Vector val = test.times(test);    assertEquals("size", 3, val.size());    for (int i = 0; i < test.size(); i++) {        assertEquals("get [" + i + ']', values[OFFSET + i] * values[OFFSET + i], val.get(i), EPSILON);    }}
public void mahout_f7740_0()
{    test.times(new DenseVector(test.size() + 1));}
public void mahout_f7741_0()
{    double expected = 0;    for (int i = OFFSET; i < OFFSET + CARDINALITY; i++) {        expected += values[i];    }    assertEquals("wrong zSum", expected, test.zSum(), EPSILON);}
public void mahout_f7742_0()
{    test.assign(0);    for (int i = 0; i < test.size(); i++) {        assertEquals("value[" + i + ']', 0.0, test.getQuick(i), EPSILON);    }}
public void mahout_f7743_0() throws Exception
{    double[] array = new double[test.size()];    test.assign(array);    for (int i = 0; i < test.size(); i++) {        assertEquals("value[" + i + ']', 0.0, test.getQuick(i), EPSILON);    }}
public void mahout_f7744_0()
{    double[] array = new double[test.size() + 1];    test.assign(array);}
public void mahout_f7745_0() throws Exception
{    Vector other = new DenseVector(test.size());    test.assign(other);    for (int i = 0; i < test.size(); i++) {        assertEquals("value[" + i + ']', 0.0, test.getQuick(i), EPSILON);    }}
public void mahout_f7746_0()
{    Vector other = new DenseVector(test.size() - 1);    test.assign(other);}
public void mahout_f7747_0()
{    test.assign(Functions.NEGATE);    for (int i = 0; i < test.size(); i++) {        assertEquals("value[" + i + ']', -values[i + 1], test.getQuick(i), EPSILON);    }}
public void mahout_f7748_0() throws Exception
{    test.assign(test, Functions.PLUS);    for (int i = 0; i < test.size(); i++) {        assertEquals("value[" + i + ']', 2 * values[i + 1], test.getQuick(i), EPSILON);    }}
public void mahout_f7749_0() throws Exception
{    test.assign(Functions.PLUS, 4);    for (int i = 0; i < test.size(); i++) {        assertEquals("value[" + i + ']', values[i + 1] + 4, test.getQuick(i), EPSILON);    }}
public void mahout_f7750_0() throws Exception
{    test.assign(new TimesFunction(), 4);    for (int i = 0; i < test.size(); i++) {        assertEquals("value[" + i + ']', values[i + 1] * 4, test.getQuick(i), EPSILON);    }}
public void mahout_f7751_0()
{    assertTrue("not like", test.like() instanceof VectorView);}
public void mahout_f7752_0()
{    Matrix result = test.cross(test);    assertEquals("row size", test.size(), result.rowSize());    assertEquals("col size", test.size(), result.columnSize());    for (int row = 0; row < result.rowSize(); row++) {        for (int col = 0; col < result.columnSize(); col++) {            assertEquals("cross[" + row + "][" + col + ']', test.getQuick(row) * test.getQuick(col), result.getQuick(row, col), EPSILON);        }    }}
public void mahout_f7753_0()
{    Matrix a = new UpperTriangular(new double[] { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 }, false);    assertEquals(0, a.viewDiagonal().minus(new DenseVector(new double[] { 1, 5, 8, 10 })).norm(1), 1.0e-10);    assertEquals(0, a.viewPart(0, 3, 1, 3).viewDiagonal().minus(new DenseVector(new double[] { 2, 6, 9 })).norm(1), 1.0e-10);    assertEquals(4, a.get(0, 3), 1.0e-10);    print(a);    Matrix m = new DenseMatrix(4, 4).assign(a);    assertEquals(0, m.minus(a).aggregate(Functions.PLUS, Functions.ABS), 1.0e-10);    print(m);    assertEquals(0, m.transpose().times(m).minus(a.transpose().times(a)).aggregate(Functions.PLUS, Functions.ABS), 1.0e-10);    assertEquals(0, m.plus(m).minus(a.plus(a)).aggregate(Functions.PLUS, Functions.ABS), 1.0e-10);}
private static void mahout_f7754_0(Matrix m)
{    for (int i = 0; i < m.rowSize(); i++) {        for (int j = 0; j < m.columnSize(); j++) {            if (Math.abs(m.get(i, j)) > 1.0e-10) {                System.out.printf("%10.3f ", m.get(i, j));            } else {                System.out.printf("%10s ", (i + j) % 3 == 0 ? "." : "");            }        }        System.out.printf("\n");    }    System.out.printf("\n");}
private static void mahout_f7755_0(Vector v, Vector realV)
{    expect(v.getLookupCost()).andStubReturn(realV instanceof SequentialAccessSparseVector ? Math.round(Math.log(1000)) : realV.getLookupCost());    expect(v.getIteratorAdvanceCost()).andStubReturn(realV.getIteratorAdvanceCost());    expect(v.isAddConstantTime()).andStubReturn(realV.isAddConstantTime());    expect(v.isSequentialAccess()).andStubReturn(realV.isSequentialAccess());    expect(v.isDense()).andStubReturn(realV.isDense());    expect(v.getNumNondefaultElements()).andStubReturn(realV.isDense() ? realV.size() : 1000);    expect(v.size()).andStubReturn(realV.size());}
public void mahout_f7756_0()
{    createStubs(dense, realDense);    createStubs(sasv, realSasv);    createStubs(rasv, realRasv);}
public void mahout_f7757_0()
{    replayAll();        assertEquals(VectorBinaryAggregate.AggregateNonzerosIterateThisLookupThat.class, VectorBinaryAggregate.getBestOperation(dense, dense, Functions.PLUS, Functions.MULT).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionSequential.class, VectorBinaryAggregate.getBestOperation(dense, dense, Functions.MAX_ABS, Functions.MINUS).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionSequential.class, VectorBinaryAggregate.getBestOperation(dense, dense, Functions.PLUS, Functions.MINUS_SQUARED).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionSequential.class, VectorBinaryAggregate.getBestOperation(dense, dense, Functions.PLUS, Functions.MINUS_ABS).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionSequential.class, VectorBinaryAggregate.getBestOperation(dense, dense, Functions.PLUS, Functions.minusAbsPow(1.2)).getClass());        assertEquals(VectorBinaryAggregate.AggregateNonzerosIterateThisLookupThat.class, VectorBinaryAggregate.getBestOperation(dense, dense, Functions.PLUS, Functions.MULT_SQUARE_LEFT).getClass());}
public void mahout_f7758_0()
{    replayAll();        assertEquals(VectorBinaryAggregate.AggregateIterateIntersection.class, VectorBinaryAggregate.getBestOperation(sasv, sasv, Functions.PLUS, Functions.MULT).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionSequential.class, VectorBinaryAggregate.getBestOperation(sasv, sasv, Functions.MAX_ABS, Functions.MINUS).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionSequential.class, VectorBinaryAggregate.getBestOperation(sasv, sasv, Functions.PLUS, Functions.MINUS_SQUARED).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionSequential.class, VectorBinaryAggregate.getBestOperation(sasv, sasv, Functions.PLUS, Functions.MINUS_ABS).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionSequential.class, VectorBinaryAggregate.getBestOperation(sasv, sasv, Functions.PLUS, Functions.minusAbsPow(1.2)).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateIntersection.class, VectorBinaryAggregate.getBestOperation(sasv, sasv, Functions.PLUS, Functions.MULT_SQUARE_LEFT).getClass());}
public void mahout_f7759_0()
{    replayAll();        assertEquals(VectorBinaryAggregate.AggregateNonzerosIterateThisLookupThat.class, VectorBinaryAggregate.getBestOperation(rasv, rasv, Functions.PLUS, Functions.MULT).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionRandom.class, VectorBinaryAggregate.getBestOperation(rasv, rasv, Functions.MAX_ABS, Functions.MINUS).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionRandom.class, VectorBinaryAggregate.getBestOperation(rasv, rasv, Functions.PLUS, Functions.MINUS_SQUARED).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionRandom.class, VectorBinaryAggregate.getBestOperation(rasv, rasv, Functions.PLUS, Functions.MINUS_ABS).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionRandom.class, VectorBinaryAggregate.getBestOperation(rasv, rasv, Functions.PLUS, Functions.minusAbsPow(1.2)).getClass());        assertEquals(VectorBinaryAggregate.AggregateNonzerosIterateThisLookupThat.class, VectorBinaryAggregate.getBestOperation(rasv, rasv, Functions.PLUS, Functions.MULT_SQUARE_LEFT).getClass());}
public void mahout_f7760_0()
{    replayAll();        assertEquals(VectorBinaryAggregate.AggregateNonzerosIterateThisLookupThat.class, VectorBinaryAggregate.getBestOperation(sasv, dense, Functions.PLUS, Functions.MULT).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionSequential.class, VectorBinaryAggregate.getBestOperation(sasv, dense, Functions.MAX_ABS, Functions.MINUS).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionSequential.class, VectorBinaryAggregate.getBestOperation(sasv, dense, Functions.PLUS, Functions.MINUS_SQUARED).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionSequential.class, VectorBinaryAggregate.getBestOperation(sasv, dense, Functions.PLUS, Functions.MINUS_ABS).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionSequential.class, VectorBinaryAggregate.getBestOperation(sasv, dense, Functions.PLUS, Functions.minusAbsPow(1.2)).getClass());        assertEquals(VectorBinaryAggregate.AggregateNonzerosIterateThisLookupThat.class, VectorBinaryAggregate.getBestOperation(sasv, dense, Functions.PLUS, Functions.MULT_SQUARE_LEFT).getClass());}
public void mahout_f7761_0()
{    replayAll();        assertEquals(VectorBinaryAggregate.AggregateNonzerosIterateThatLookupThis.class, VectorBinaryAggregate.getBestOperation(dense, sasv, Functions.PLUS, Functions.MULT).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionSequential.class, VectorBinaryAggregate.getBestOperation(dense, sasv, Functions.MAX_ABS, Functions.MINUS).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionSequential.class, VectorBinaryAggregate.getBestOperation(dense, sasv, Functions.PLUS, Functions.MINUS_SQUARED).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionSequential.class, VectorBinaryAggregate.getBestOperation(dense, sasv, Functions.PLUS, Functions.MINUS_ABS).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionSequential.class, VectorBinaryAggregate.getBestOperation(dense, sasv, Functions.PLUS, Functions.minusAbsPow(1.2)).getClass());        assertEquals(VectorBinaryAggregate.AggregateNonzerosIterateThatLookupThis.class, VectorBinaryAggregate.getBestOperation(dense, sasv, Functions.PLUS, Functions.MULT_SQUARE_LEFT).getClass());}
public void mahout_f7762_0()
{    replayAll();        assertEquals(VectorBinaryAggregate.AggregateNonzerosIterateThatLookupThis.class, VectorBinaryAggregate.getBestOperation(dense, rasv, Functions.PLUS, Functions.MULT).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionRandom.class, VectorBinaryAggregate.getBestOperation(dense, rasv, Functions.MAX_ABS, Functions.MINUS).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionRandom.class, VectorBinaryAggregate.getBestOperation(dense, rasv, Functions.PLUS, Functions.MINUS_SQUARED).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionRandom.class, VectorBinaryAggregate.getBestOperation(dense, rasv, Functions.PLUS, Functions.MINUS_ABS).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionRandom.class, VectorBinaryAggregate.getBestOperation(dense, rasv, Functions.PLUS, Functions.minusAbsPow(1.2)).getClass());        assertEquals(VectorBinaryAggregate.AggregateNonzerosIterateThatLookupThis.class, VectorBinaryAggregate.getBestOperation(dense, rasv, Functions.PLUS, Functions.MULT_SQUARE_LEFT).getClass());}
public void mahout_f7763_0()
{    replayAll();        assertEquals(VectorBinaryAggregate.AggregateNonzerosIterateThisLookupThat.class, VectorBinaryAggregate.getBestOperation(rasv, dense, Functions.PLUS, Functions.MULT).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionRandom.class, VectorBinaryAggregate.getBestOperation(rasv, dense, Functions.MAX_ABS, Functions.MINUS).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionRandom.class, VectorBinaryAggregate.getBestOperation(rasv, dense, Functions.PLUS, Functions.MINUS_SQUARED).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionRandom.class, VectorBinaryAggregate.getBestOperation(rasv, dense, Functions.PLUS, Functions.MINUS_ABS).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionRandom.class, VectorBinaryAggregate.getBestOperation(rasv, dense, Functions.PLUS, Functions.minusAbsPow(1.2)).getClass());        assertEquals(VectorBinaryAggregate.AggregateNonzerosIterateThisLookupThat.class, VectorBinaryAggregate.getBestOperation(rasv, dense, Functions.PLUS, Functions.MULT_SQUARE_LEFT).getClass());}
public void mahout_f7764_0()
{    replayAll();        assertEquals(VectorBinaryAggregate.AggregateNonzerosIterateThisLookupThat.class, VectorBinaryAggregate.getBestOperation(sasv, rasv, Functions.PLUS, Functions.MULT).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionRandom.class, VectorBinaryAggregate.getBestOperation(sasv, rasv, Functions.MAX_ABS, Functions.MINUS).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionRandom.class, VectorBinaryAggregate.getBestOperation(sasv, rasv, Functions.PLUS, Functions.MINUS_SQUARED).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionRandom.class, VectorBinaryAggregate.getBestOperation(sasv, rasv, Functions.PLUS, Functions.MINUS_ABS).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionRandom.class, VectorBinaryAggregate.getBestOperation(sasv, rasv, Functions.PLUS, Functions.minusAbsPow(1.2)).getClass());        assertEquals(VectorBinaryAggregate.AggregateNonzerosIterateThisLookupThat.class, VectorBinaryAggregate.getBestOperation(sasv, rasv, Functions.PLUS, Functions.MULT_SQUARE_LEFT).getClass());}
public void mahout_f7765_0()
{    replayAll();        assertEquals(VectorBinaryAggregate.AggregateNonzerosIterateThatLookupThis.class, VectorBinaryAggregate.getBestOperation(rasv, sasv, Functions.PLUS, Functions.MULT).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionRandom.class, VectorBinaryAggregate.getBestOperation(rasv, sasv, Functions.MAX_ABS, Functions.MINUS).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionRandom.class, VectorBinaryAggregate.getBestOperation(rasv, sasv, Functions.PLUS, Functions.MINUS_SQUARED).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionRandom.class, VectorBinaryAggregate.getBestOperation(rasv, sasv, Functions.PLUS, Functions.MINUS_ABS).getClass());        assertEquals(VectorBinaryAggregate.AggregateIterateUnionRandom.class, VectorBinaryAggregate.getBestOperation(rasv, sasv, Functions.PLUS, Functions.minusAbsPow(1.2)).getClass());        assertEquals(VectorBinaryAggregate.AggregateNonzerosIterateThatLookupThis.class, VectorBinaryAggregate.getBestOperation(rasv, sasv, Functions.PLUS, Functions.MULT_SQUARE_LEFT).getClass());}
private void mahout_f7766_0()
{    replay(dense, sasv, rasv);}
public static Collection<Object[]> mahout_f7767_0()
{    List<Object[]> data = Lists.newArrayList();    for (List<?> entry : Sets.cartesianProduct(Lists.newArrayList(ImmutableSet.of(Functions.PLUS, Functions.PLUS_ABS, Functions.MAX), ImmutableSet.of(Functions.PLUS, Functions.PLUS_ABS, Functions.MULT, Functions.MULT_RIGHT_PLUS1, Functions.MINUS), ImmutableSet.copyOf(VectorBinaryAggregate.OPERATIONS), ImmutableSet.of(new SequentialAccessSparseVector(CARDINALITY), new RandomAccessSparseVector(CARDINALITY), new DenseVector(CARDINALITY)), ImmutableSet.of(new SequentialAccessSparseVector(CARDINALITY), new RandomAccessSparseVector(CARDINALITY), new DenseVector(CARDINALITY))))) {        data.add(entry.toArray());    }    return data;}
public void mahout_f7768_0()
{    Vector x = first.like();    Vector xBase = new DenseVector(CARDINALITY);    List<Double> items = Lists.newArrayList();    for (int i = 0; i < x.size(); ++i) {        items.add(r.nextDouble());    }    for (int i = 1; i < x.size(); ++i) {        x.setQuick(i, items.get(i));        xBase.setQuick(i, items.get(i));    }    Vector y = second.like().assign(x);    Vector yBase = new DenseVector(x);    System.out.printf("aggregator %s; combiner %s; operation %s\n", aggregator, combiner, operation);    double expectedResult = combiner.apply(0, 0);    for (int i = 1; i < x.size(); ++i) {        expectedResult = aggregator.apply(expectedResult, combiner.apply(items.get(i), items.get(i)));    }    double result = operation.aggregate(x, y, aggregator, combiner);    double resultBase = operation.aggregate(xBase, yBase, aggregator, combiner);    assertEquals(expectedResult, result, 0.0);    assertEquals(resultBase, result, 0.0);}
public void mahout_f7769_0()
{    List<Double> items1 = Lists.newArrayList();    List<Double> items2 = Lists.newArrayList();    for (int i = 0; i < CARDINALITY; ++i) {        items1.add(r.nextDouble());        items2.add(r.nextDouble());    }    Vector x = first.like();    Vector xBase = new DenseVector(CARDINALITY);    for (int i = 0; i < x.size(); ++i) {        x.setQuick(i, items1.get(i));        xBase.setQuick(i, items1.get(i));    }    Vector y = second.like();    Vector yBase = new DenseVector(CARDINALITY);    for (int i = 0; i < y.size(); ++i) {        y.setQuick(i, items2.get(i));        yBase.setQuick(i, items2.get(i));    }    System.out.printf("aggregator %s; combiner %s; operation %s\n", aggregator, combiner, operation);    double expectedResult = combiner.apply(items1.get(0), items2.get(0));    for (int i = 1; i < x.size(); ++i) {        expectedResult = aggregator.apply(expectedResult, combiner.apply(items1.get(i), items2.get(i)));    }    double result = operation.aggregate(x, y, aggregator, combiner);    double resultBase = operation.aggregate(xBase, yBase, aggregator, combiner);    assertEquals(expectedResult, result, 0.0);    assertEquals(resultBase, result, 0.0);}
private static void mahout_f7770_0(Vector v, Vector realV)
{    expect(v.getLookupCost()).andStubReturn(realV instanceof SequentialAccessSparseVector ? Math.round(Math.log(1000)) : realV.getLookupCost());    expect(v.getIteratorAdvanceCost()).andStubReturn(realV.getIteratorAdvanceCost());    expect(v.isAddConstantTime()).andStubReturn(realV.isAddConstantTime());    expect(v.isSequentialAccess()).andStubReturn(realV.isSequentialAccess());    expect(v.isDense()).andStubReturn(realV.isDense());    expect(v.getNumNondefaultElements()).andStubReturn(realV.isDense() ? realV.size() : 1000);    expect(v.size()).andStubReturn(realV.size());}
public void mahout_f7771_0()
{    createStubs(dense, realDense);    createStubs(sasv, realSasv);    createStubs(rasv, realRasv);}
public void mahout_f7772_0()
{    replayAll();    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThatLookupThisInplaceUpdates.class, VectorBinaryAssign.getBestOperation(dense, dense, Functions.PLUS).getClass());    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThatLookupThisInplaceUpdates.class, VectorBinaryAssign.getBestOperation(dense, dense, Functions.MINUS).getClass());    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThisLookupThat.class, VectorBinaryAssign.getBestOperation(dense, dense, Functions.MULT).getClass());    assertEquals(VectorBinaryAssign.AssignAllLoopInplaceUpdates.class, VectorBinaryAssign.getBestOperation(dense, dense, Functions.DIV).getClass());    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThatLookupThisInplaceUpdates.class, VectorBinaryAssign.getBestOperation(dense, dense, Functions.SECOND_LEFT_ZERO).getClass());}
public void mahout_f7773_0()
{    replayAll();    assertEquals(VectorBinaryAssign.AssignIterateUnionSequentialMergeUpdates.class, VectorBinaryAssign.getBestOperation(sasv, sasv, Functions.PLUS).getClass());    assertEquals(VectorBinaryAssign.AssignIterateUnionSequentialMergeUpdates.class, VectorBinaryAssign.getBestOperation(sasv, sasv, Functions.MINUS).getClass());    assertEquals(VectorBinaryAssign.AssignIterateUnionSequentialMergeUpdates.class, VectorBinaryAssign.getBestOperation(sasv, sasv, Functions.MULT).getClass());    assertEquals(VectorBinaryAssign.AssignAllIterateSequentialMergeUpdates.class, VectorBinaryAssign.getBestOperation(sasv, sasv, Functions.DIV).getClass());    assertEquals(VectorBinaryAssign.AssignIterateUnionSequentialMergeUpdates.class, VectorBinaryAssign.getBestOperation(sasv, sasv, Functions.SECOND_LEFT_ZERO).getClass());}
public void mahout_f7774_0()
{    replayAll();    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThatLookupThisInplaceUpdates.class, VectorBinaryAssign.getBestOperation(rasv, rasv, Functions.PLUS).getClass());    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThatLookupThisInplaceUpdates.class, VectorBinaryAssign.getBestOperation(rasv, rasv, Functions.MINUS).getClass());    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThisLookupThat.class, VectorBinaryAssign.getBestOperation(rasv, rasv, Functions.MULT).getClass());    assertEquals(VectorBinaryAssign.AssignAllLoopInplaceUpdates.class, VectorBinaryAssign.getBestOperation(rasv, rasv, Functions.DIV).getClass());    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThatLookupThisInplaceUpdates.class, VectorBinaryAssign.getBestOperation(rasv, rasv, Functions.SECOND_LEFT_ZERO).getClass());}
public void mahout_f7775_0()
{    replayAll();    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThatLookupThisMergeUpdates.class, VectorBinaryAssign.getBestOperation(sasv, dense, Functions.PLUS).getClass());    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThatLookupThisMergeUpdates.class, VectorBinaryAssign.getBestOperation(sasv, dense, Functions.MINUS).getClass());    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThisLookupThat.class, VectorBinaryAssign.getBestOperation(sasv, dense, Functions.MULT).getClass());    assertEquals(VectorBinaryAssign.AssignAllIterateThisLookupThatMergeUpdates.class, VectorBinaryAssign.getBestOperation(sasv, dense, Functions.DIV).getClass());    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThatLookupThisMergeUpdates.class, VectorBinaryAssign.getBestOperation(sasv, dense, Functions.SECOND_LEFT_ZERO).getClass());}
public void mahout_f7776_0()
{    replayAll();    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThatLookupThisInplaceUpdates.class, VectorBinaryAssign.getBestOperation(dense, sasv, Functions.PLUS).getClass());    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThatLookupThisInplaceUpdates.class, VectorBinaryAssign.getBestOperation(dense, sasv, Functions.MINUS).getClass());    assertEquals(VectorBinaryAssign.AssignIterateUnionSequentialInplaceUpdates.class, VectorBinaryAssign.getBestOperation(dense, sasv, Functions.MULT).getClass());    assertEquals(VectorBinaryAssign.AssignAllIterateThatLookupThisInplaceUpdates.class, VectorBinaryAssign.getBestOperation(dense, sasv, Functions.DIV).getClass());    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThatLookupThisInplaceUpdates.class, VectorBinaryAssign.getBestOperation(dense, sasv, Functions.SECOND_LEFT_ZERO).getClass());}
public void mahout_f7777_0()
{    replayAll();    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThatLookupThisInplaceUpdates.class, VectorBinaryAssign.getBestOperation(dense, rasv, Functions.PLUS).getClass());    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThatLookupThisInplaceUpdates.class, VectorBinaryAssign.getBestOperation(dense, rasv, Functions.MINUS).getClass());    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThisLookupThat.class, VectorBinaryAssign.getBestOperation(dense, rasv, Functions.MULT).getClass());    assertEquals(VectorBinaryAssign.AssignAllLoopInplaceUpdates.class, VectorBinaryAssign.getBestOperation(dense, rasv, Functions.DIV).getClass());    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThatLookupThisInplaceUpdates.class, VectorBinaryAssign.getBestOperation(dense, rasv, Functions.SECOND_LEFT_ZERO).getClass());}
public void mahout_f7778_0()
{    replayAll();    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThatLookupThisInplaceUpdates.class, VectorBinaryAssign.getBestOperation(rasv, dense, Functions.PLUS).getClass());    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThatLookupThisInplaceUpdates.class, VectorBinaryAssign.getBestOperation(rasv, dense, Functions.MINUS).getClass());    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThisLookupThat.class, VectorBinaryAssign.getBestOperation(rasv, dense, Functions.MULT).getClass());    assertEquals(VectorBinaryAssign.AssignAllLoopInplaceUpdates.class, VectorBinaryAssign.getBestOperation(rasv, dense, Functions.DIV).getClass());    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThatLookupThisInplaceUpdates.class, VectorBinaryAssign.getBestOperation(rasv, dense, Functions.SECOND_LEFT_ZERO).getClass());}
public void mahout_f7779_0()
{    replayAll();    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThatLookupThisInplaceUpdates.class, VectorBinaryAssign.getBestOperation(sasv, rasv, Functions.PLUS).getClass());    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThatLookupThisInplaceUpdates.class, VectorBinaryAssign.getBestOperation(sasv, rasv, Functions.MINUS).getClass());    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThisLookupThat.class, VectorBinaryAssign.getBestOperation(sasv, rasv, Functions.MULT).getClass());    assertEquals(VectorBinaryAssign.AssignAllIterateThisLookupThatMergeUpdates.class, VectorBinaryAssign.getBestOperation(sasv, rasv, Functions.DIV).getClass());    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThatLookupThisInplaceUpdates.class, VectorBinaryAssign.getBestOperation(sasv, rasv, Functions.SECOND_LEFT_ZERO).getClass());}
public void mahout_f7780_0()
{    replayAll();    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThatLookupThisInplaceUpdates.class, VectorBinaryAssign.getBestOperation(rasv, sasv, Functions.PLUS).getClass());    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThatLookupThisInplaceUpdates.class, VectorBinaryAssign.getBestOperation(rasv, sasv, Functions.MINUS).getClass());    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThisLookupThat.class, VectorBinaryAssign.getBestOperation(rasv, sasv, Functions.MULT).getClass());    assertEquals(VectorBinaryAssign.AssignAllIterateThatLookupThisInplaceUpdates.class, VectorBinaryAssign.getBestOperation(rasv, sasv, Functions.DIV).getClass());    assertEquals(VectorBinaryAssign.AssignNonzerosIterateThatLookupThisInplaceUpdates.class, VectorBinaryAssign.getBestOperation(rasv, sasv, Functions.SECOND_LEFT_ZERO).getClass());}
private void mahout_f7781_0()
{    replay(dense, sasv, rasv);}
public static Collection<Object[]> mahout_f7782_0()
{    List<Object[]> data = Lists.newArrayList();    for (List entry : Sets.cartesianProduct(Lists.newArrayList(ImmutableSet.of(Functions.PLUS, Functions.PLUS_ABS, Functions.MULT, Functions.MULT_RIGHT_PLUS1, Functions.MINUS), ImmutableSet.copyOf(VectorBinaryAssign.OPERATIONS)))) {        data.add(entry.toArray());    }    return data;}
public void mahout_f7783_0()
{    SequentialAccessSparseVector x = new SequentialAccessSparseVector(CARDINALITY);    for (int i = 0; i < x.size(); ++i) {        x.setQuick(i, i);    }    SequentialAccessSparseVector y = new SequentialAccessSparseVector(x);    System.out.printf("function %s; operation %s\n", function, operation);    operation.assign(x, y, function);    for (int i = 0; i < x.size(); ++i) {        assertEquals(x.getQuick(i), function.apply(i, i), 0.0);    }}
public void mahout_f7784_0()
{    Vector vec1 = new RandomAccessSparseVector(3);    Vector vec2 = new RandomAccessSparseVector(3);    doTestVectors(vec1, vec2);}
public void mahout_f7785_0()
{    int[] index = { 0, 1, 2, 3, 4, 5 };    double[] values = { 1, 2, 3, 4, 5, 6 };    assertEquals(index.length, values.length);    int n = index.length;    Vector vector = new SequentialAccessSparseVector(n);    for (int i = 0; i < n; i++) {        vector.set(index[i], values[i]);    }    for (int i = 0; i < n; i++) {        assertEquals(vector.get(i), values[i], EPSILON);    }    int elements = 0;    for (Element ignore : vector.all()) {        elements++;    }    assertEquals(n, elements);    assertFalse(new SequentialAccessSparseVector(0).iterator().hasNext());}
public void mahout_f7786_0()
{    int[] index = { 0, 1, 2, 3, 4, 5 };    double[] values = { 1, 2, 3, 4, 5, 6 };    assertEquals(index.length, values.length);    int n = index.length;    Vector vector = new SequentialAccessSparseVector(n);    for (int i = 0; i < n; i++) {        vector.set(index[i], values[i]);    }    for (int i = 0; i < n; i++) {        assertEquals(vector.get(i), values[i], EPSILON);    }    int elements = 0;    for (Element ignored : vector.nonZeroes()) {        elements++;    }    assertEquals(n, elements);    Vector empty = new SequentialAccessSparseVector(0);    assertFalse(empty.nonZeroes().iterator().hasNext());}
public void mahout_f7787_0()
{        RandomAccessSparseVector randomAccessLeft = new RandomAccessSparseVector(3);    Vector sequentialAccessLeft = new SequentialAccessSparseVector(3);    Vector right = new DenseVector(3);    randomAccessLeft.setQuick(0, 1);    randomAccessLeft.setQuick(1, 2);    randomAccessLeft.setQuick(2, 3);    sequentialAccessLeft.setQuick(0, 1);    sequentialAccessLeft.setQuick(1, 2);    sequentialAccessLeft.setQuick(2, 3);    right.setQuick(0, 1);    right.setQuick(1, 2);    right.setQuick(2, 3);    assertEquals(randomAccessLeft, right);    assertEquals(sequentialAccessLeft, right);    assertEquals(sequentialAccessLeft, randomAccessLeft);    Vector leftBar = new DenseVector(3);    leftBar.setQuick(0, 1);    leftBar.setQuick(1, 2);    leftBar.setQuick(2, 3);    assertEquals(leftBar, right);    assertEquals(randomAccessLeft, right);    assertEquals(sequentialAccessLeft, right);    Vector rightBar = new RandomAccessSparseVector(3);    rightBar.setQuick(0, 1);    rightBar.setQuick(1, 2);    rightBar.setQuick(2, 3);    assertEquals(randomAccessLeft, rightBar);    right.setQuick(2, 4);    assertFalse(randomAccessLeft.equals(right));    right = new DenseVector(4);    right.setQuick(0, 1);    right.setQuick(1, 2);    right.setQuick(2, 3);    right.setQuick(3, 3);    assertFalse(randomAccessLeft.equals(right));    randomAccessLeft = new RandomAccessSparseVector(2);    randomAccessLeft.setQuick(0, 1);    randomAccessLeft.setQuick(1, 2);    assertFalse(randomAccessLeft.equals(right));    Vector dense = new DenseVector(3);    right = new DenseVector(3);    right.setQuick(0, 1);    right.setQuick(1, 2);    right.setQuick(2, 3);    dense.setQuick(0, 1);    dense.setQuick(1, 2);    dense.setQuick(2, 3);    assertEquals(dense, right);    RandomAccessSparseVector sparse = new RandomAccessSparseVector(3);    randomAccessLeft = new RandomAccessSparseVector(3);    sparse.setQuick(0, 1);    sparse.setQuick(1, 2);    sparse.setQuick(2, 3);    randomAccessLeft.setQuick(0, 1);    randomAccessLeft.setQuick(1, 2);    randomAccessLeft.setQuick(2, 3);    assertEquals(randomAccessLeft, sparse);    Vector v1 = new VectorView(randomAccessLeft, 0, 2);    Vector v2 = new VectorView(right, 0, 2);    assertEquals(v1, v2);    sparse = new RandomAccessSparseVector(2);    sparse.setQuick(0, 1);    sparse.setQuick(1, 2);    assertEquals(v1, sparse);}
private static void mahout_f7788_0(Vector left, Vector right)
{    left.setQuick(0, 1);    left.setQuick(1, 2);    left.setQuick(2, 3);    right.setQuick(0, 4);    right.setQuick(1, 5);    right.setQuick(2, 6);    double result = left.dot(right);    assertEquals(32.0, result, EPSILON);}
public void mahout_f7789_0()
{    Vector v = new DenseVector(5);    Vector w = new DenseVector(5);    setUpV(v);    setUpW(w);    doTestGetDistanceSquared(v, w);    v = new RandomAccessSparseVector(5);    w = new RandomAccessSparseVector(5);    setUpV(v);    setUpW(w);    doTestGetDistanceSquared(v, w);    v = new SequentialAccessSparseVector(5);    w = new SequentialAccessSparseVector(5);    setUpV(v);    setUpW(w);    doTestGetDistanceSquared(v, w);}
public void mahout_f7790_0() throws Exception
{    Vector v = new DenseVector(4);    Vector w = new DenseVector(4);    v.setQuick(0, 1);    v.setQuick(1, 2);    v.setQuick(2, 0);    v.setQuick(3, 4);    w.setQuick(0, 1);    w.setQuick(1, 1);    w.setQuick(2, 1);    w.setQuick(3, 1);    w.assign(v, Functions.PLUS);    Vector gold = new DenseVector(new double[] { 2, 3, 1, 5 });    assertEquals(w, gold);    assertFalse(v.equals(gold));}
private static void mahout_f7791_0(Vector v)
{    v.setQuick(1, 2);    v.setQuick(2, -4);    v.setQuick(3, -9);}
private static void mahout_f7792_0(Vector w)
{    w.setQuick(0, -5);    w.setQuick(1, -1);    w.setQuick(2, 9);    w.setQuick(3, 0.1);    w.setQuick(4, 2.1);}
private static void mahout_f7793_0(Vector v, Vector w)
{    double expected = v.minus(w).getLengthSquared();    assertEquals(expected, v.getDistanceSquared(w), 1.0e-6);}
public void mahout_f7794_0()
{    Vector v = new DenseVector(5);    setUpV(v);    doTestGetLengthSquared(v);    v = new RandomAccessSparseVector(5);    setUpV(v);    doTestGetLengthSquared(v);    v = new SequentialAccessSparseVector(5);    setUpV(v);    doTestGetLengthSquared(v);}
public static double mahout_f7795_0(Vector v)
{    double d = 0.0;    for (int i = 0; i < v.size(); i++) {        double value = v.get(i);        d += value * value;    }    return d;}
private static void mahout_f7796_0(Vector v)
{    double expected = lengthSquaredSlowly(v);    assertEquals("v.getLengthSquared() != sum_of_squared_elements(v)", expected, v.getLengthSquared(), 0.0);    v.set(v.size() / 2, v.get(v.size() / 2) + 1.0);    expected = lengthSquaredSlowly(v);    assertEquals("mutation via set() fails to change lengthSquared", expected, v.getLengthSquared(), EPSILON);    v.setQuick(v.size() / 5, v.get(v.size() / 5) + 1.0);    expected = lengthSquaredSlowly(v);    assertEquals("mutation via setQuick() fails to change lengthSquared", expected, v.getLengthSquared(), EPSILON);    for (Element e : v.nonZeroes()) {        if (e.index() == v.size() - 2) {            e.set(e.get() - 5.0);        }    }    expected = lengthSquaredSlowly(v);    assertEquals("mutation via dense iterator.set fails to change lengthSquared", expected, v.getLengthSquared(), EPSILON);    int i = 0;    for (Element e : v.nonZeroes()) {        i++;        if (i == v.getNumNondefaultElements() - 1) {            e.set(e.get() - 5.0);        }    }    expected = lengthSquaredSlowly(v);    assertEquals("mutation via sparse iterator.set fails to change lengthSquared", expected, v.getLengthSquared(), EPSILON);    v.assign(3.0);    expected = lengthSquaredSlowly(v);    assertEquals("mutation via assign(double) fails to change lengthSquared", expected, v.getLengthSquared(), EPSILON);    v.assign(Functions.SQUARE);    expected = lengthSquaredSlowly(v);    assertEquals("mutation via assign(square) fails to change lengthSquared", expected, v.getLengthSquared(), EPSILON);    v.assign(new double[v.size()]);    expected = lengthSquaredSlowly(v);    assertEquals("mutation via assign(double[]) fails to change lengthSquared", expected, v.getLengthSquared(), EPSILON);    v.getElement(v.size() / 2).set(2.5);    expected = lengthSquaredSlowly(v);    assertEquals("mutation via v.getElement().set() fails to change lengthSquared", expected, v.getLengthSquared(), EPSILON);    v.normalize();    expected = lengthSquaredSlowly(v);    assertEquals("mutation via normalize() fails to change lengthSquared", expected, v.getLengthSquared(), EPSILON);    v.set(0, 1.5);    v.normalize(1.0);    expected = lengthSquaredSlowly(v);    assertEquals("mutation via normalize(double) fails to change lengthSquared", expected, v.getLengthSquared(), EPSILON);    v.times(2.0);    expected = lengthSquaredSlowly(v);    assertEquals("mutation via times(double) fails to change lengthSquared", expected, v.getLengthSquared(), EPSILON);    v.times(v);    expected = lengthSquaredSlowly(v);    assertEquals("mutation via times(vector) fails to change lengthSquared", expected, v.getLengthSquared(), EPSILON);    v.assign(Functions.POW, 3.0);    expected = lengthSquaredSlowly(v);    assertEquals("mutation via assign(pow, 3.0) fails to change lengthSquared", expected, v.getLengthSquared(), EPSILON);    v.assign(v, Functions.PLUS);    expected = lengthSquaredSlowly(v);    assertEquals("mutation via assign(v,plus) fails to change lengthSquared", expected, v.getLengthSquared(), EPSILON);}
public void mahout_f7797_0()
{    Collection<Integer> expectedIndices = Sets.newHashSet();    int i = 1;    while (i <= 20) {        expectedIndices.add(i * (i + 1) / 2);        i++;    }    Vector denseVector = new DenseVector(i * i);    for (int index : expectedIndices) {        denseVector.set(index, (double) 2 * index);    }    doTestIterators(denseVector, expectedIndices);    Vector randomAccessVector = new RandomAccessSparseVector(i * i);    for (int index : expectedIndices) {        randomAccessVector.set(index, (double) 2 * index);    }    doTestIterators(randomAccessVector, expectedIndices);    Vector sequentialVector = new SequentialAccessSparseVector(i * i);    for (int index : expectedIndices) {        sequentialVector.set(index, (double) 2 * index);    }    doTestIterators(sequentialVector, expectedIndices);}
private static void mahout_f7798_0(Vector vector, Collection<Integer> expectedIndices)
{    expectedIndices = Sets.newHashSet(expectedIndices);    Iterator<Element> allIterator = vector.all().iterator();    int index = 0;    while (allIterator.hasNext()) {        Element element = allIterator.next();        assertEquals(index, element.index());        if (expectedIndices.contains(index)) {            assertEquals((double) index * 2, element.get(), EPSILON);        } else {            assertEquals(0.0, element.get(), EPSILON);        }        index++;    }    for (Element element : vector.nonZeroes()) {        index = element.index();        assertTrue(expectedIndices.contains(index));        assertEquals((double) index * 2, element.get(), EPSILON);        expectedIndices.remove(index);    }    assertTrue(expectedIndices.isEmpty());}
public void mahout_f7799_0()
{    Vector vec1 = new RandomAccessSparseVector(3);    vec1.setQuick(0, 1);    vec1.setQuick(1, 2);    vec1.setQuick(2, 3);    Vector norm = vec1.normalize();    assertNotNull("norm1 is null and it shouldn't be", norm);    Vector vec2 = new SequentialAccessSparseVector(3);    vec2.setQuick(0, 1);    vec2.setQuick(1, 2);    vec2.setQuick(2, 3);    Vector norm2 = vec2.normalize();    assertNotNull("norm1 is null and it shouldn't be", norm2);    Vector expected = new RandomAccessSparseVector(3);    expected.setQuick(0, 0.2672612419124244);    expected.setQuick(1, 0.5345224838248488);    expected.setQuick(2, 0.8017837257372732);    assertEquals(expected, norm);    norm = vec1.normalize(2);    assertEquals(expected, norm);    norm2 = vec2.normalize(2);    assertEquals(expected, norm2);    norm = vec1.normalize(1);    norm2 = vec2.normalize(1);    expected.setQuick(0, 1.0 / 6);    expected.setQuick(1, 2.0 / 6);    expected.setQuick(2, 3.0 / 6);    assertEquals(expected, norm);    assertEquals(expected, norm2);    norm = vec1.normalize(3);                double cube = Math.pow(36, 1.0 / 3);    expected = vec1.divide(cube);    assertEquals(norm, expected);    norm = vec1.normalize(Double.POSITIVE_INFINITY);    norm2 = vec2.normalize(Double.POSITIVE_INFINITY);        expected.setQuick(0, 1.0 / 3);    expected.setQuick(1, 2.0 / 3);    expected.setQuick(2, 3.0 / 3);    assertEquals(norm, expected);    assertEquals(norm2, expected);    norm = vec1.normalize(0);        expected.setQuick(0, 1.0 / 3);    expected.setQuick(1, 2.0 / 3);    expected.setQuick(2, 3.0 / 3);    assertEquals(norm, expected);    try {        vec1.normalize(-1);        fail();    } catch (IllegalArgumentException e) {        }    try {        vec2.normalize(-1);        fail();    } catch (IllegalArgumentException e) {        }}
public void mahout_f7800_0()
{    Vector vec1 = new RandomAccessSparseVector(3);    vec1.setQuick(0, 1);    vec1.setQuick(1, 2);    vec1.setQuick(2, 3);    Vector norm = vec1.logNormalize();    assertNotNull("norm1 is null and it shouldn't be", norm);    Vector vec2 = new SequentialAccessSparseVector(3);    vec2.setQuick(0, 1);    vec2.setQuick(1, 2);    vec2.setQuick(2, 3);    Vector norm2 = vec2.logNormalize();    assertNotNull("norm1 is null and it shouldn't be", norm2);    Vector expected = new DenseVector(new double[] { 0.2672612419124244, 0.4235990463273581, 0.5345224838248488 });    assertVectorEquals(expected, norm, 1.0e-15);    assertVectorEquals(expected, norm2, 1.0e-15);    norm = vec1.logNormalize(2);    assertVectorEquals(expected, norm, 1.0e-15);    norm2 = vec2.logNormalize(2);    assertVectorEquals(expected, norm2, 1.0e-15);    try {        vec1.logNormalize(1);        fail("Should fail with power == 1");    } catch (IllegalArgumentException e) {        }    try {        vec1.logNormalize(-1);        fail("Should fail with negative power");    } catch (IllegalArgumentException e) {        }    try {        vec2.logNormalize(Double.POSITIVE_INFINITY);        fail("Should fail with positive infinity norm");    } catch (IllegalArgumentException e) {        }}
private static void mahout_f7801_0(Vector expected, Vector actual, double epsilon)
{    assertEquals(expected.size(), actual.size());    for (Element x : expected.all()) {        assertEquals(x.get(), actual.get(x.index()), epsilon);    }}
public void mahout_f7802_0()
{    Vector vec1 = new RandomAccessSparseVector(3);    vec1.setQuick(0, -1);    vec1.setQuick(1, -3);    vec1.setQuick(2, -2);    double max = vec1.maxValue();    assertEquals(-1.0, max, 0.0);    int idx = vec1.maxValueIndex();    assertEquals(0, idx);    vec1 = new RandomAccessSparseVector(3);    vec1.setQuick(0, -1);    vec1.setQuick(2, -2);    max = vec1.maxValue();    assertEquals(0.0, max, 0.0);    idx = vec1.maxValueIndex();    assertEquals(1, idx);    vec1 = new SequentialAccessSparseVector(3);    vec1.setQuick(0, -1);    vec1.setQuick(2, -2);    max = vec1.maxValue();    assertEquals(0.0, max, 0.0);    idx = vec1.maxValueIndex();    assertEquals(1, idx);    vec1 = new DenseVector(3);    vec1.setQuick(0, -1);    vec1.setQuick(2, -2);    max = vec1.maxValue();    assertEquals(0.0, max, 0.0);    idx = vec1.maxValueIndex();    assertEquals(1, idx);    vec1 = new RandomAccessSparseVector(3);    max = vec1.maxValue();    assertEquals(0.0, max, EPSILON);    vec1 = new DenseVector(3);    max = vec1.maxValue();    assertEquals(0.0, max, EPSILON);    vec1 = new SequentialAccessSparseVector(3);    max = vec1.maxValue();    assertEquals(0.0, max, EPSILON);    vec1 = new RandomAccessSparseVector(0);    max = vec1.maxValue();    assertEquals(Double.NEGATIVE_INFINITY, max, EPSILON);    vec1 = new DenseVector(0);    max = vec1.maxValue();    assertEquals(Double.NEGATIVE_INFINITY, max, EPSILON);    vec1 = new SequentialAccessSparseVector(0);    max = vec1.maxValue();    assertEquals(Double.NEGATIVE_INFINITY, max, EPSILON);}
public void mahout_f7803_0()
{    Vector vec1 = new RandomAccessSparseVector(3);    vec1.setQuick(0, 1);    vec1.setQuick(1, 3);    vec1.setQuick(2, 2);    double max = vec1.minValue();    assertEquals(1.0, max, 0.0);    int idx = vec1.maxValueIndex();    assertEquals(1, idx);    vec1 = new RandomAccessSparseVector(3);    vec1.setQuick(0, -1);    vec1.setQuick(2, -2);    max = vec1.maxValue();    assertEquals(0.0, max, 0.0);    idx = vec1.maxValueIndex();    assertEquals(1, idx);    vec1 = new SequentialAccessSparseVector(3);    vec1.setQuick(0, -1);    vec1.setQuick(2, -2);    max = vec1.maxValue();    assertEquals(0.0, max, 0.0);    idx = vec1.maxValueIndex();    assertEquals(1, idx);    vec1 = new DenseVector(3);    vec1.setQuick(0, -1);    vec1.setQuick(2, -2);    max = vec1.maxValue();    assertEquals(0.0, max, 0.0);    idx = vec1.maxValueIndex();    assertEquals(1, idx);    vec1 = new RandomAccessSparseVector(3);    max = vec1.maxValue();    assertEquals(0.0, max, EPSILON);    vec1 = new DenseVector(3);    max = vec1.maxValue();    assertEquals(0.0, max, EPSILON);    vec1 = new SequentialAccessSparseVector(3);    max = vec1.maxValue();    assertEquals(0.0, max, EPSILON);    vec1 = new RandomAccessSparseVector(0);    max = vec1.maxValue();    assertEquals(Double.NEGATIVE_INFINITY, max, EPSILON);    vec1 = new DenseVector(0);    max = vec1.maxValue();    assertEquals(Double.NEGATIVE_INFINITY, max, EPSILON);    vec1 = new SequentialAccessSparseVector(0);    max = vec1.maxValue();    assertEquals(Double.NEGATIVE_INFINITY, max, EPSILON);}
public void mahout_f7804_0()
{    Vector vec1 = new DenseVector(3);    Vector vec2 = new DenseVector(3);    doTestVectors(vec1, vec2);}
public void mahout_f7805_0()
{    RandomAccessSparseVector vec1 = new RandomAccessSparseVector(3);    RandomAccessSparseVector vec2 = new RandomAccessSparseVector(6);    SequentialAccessSparseVector vec3 = new SequentialAccessSparseVector(3);    SequentialAccessSparseVector vec4 = new SequentialAccessSparseVector(6);    Vector vecV1 = new VectorView(vec1, 0, 3);    Vector vecV2 = new VectorView(vec2, 2, 3);    Vector vecV3 = new VectorView(vec3, 0, 3);    Vector vecV4 = new VectorView(vec4, 2, 3);    doTestVectors(vecV1, vecV2);    doTestVectors(vecV3, vecV4);}
private static void mahout_f7806_0(double[] apriori, Vector vector)
{    double[] test = new double[apriori.length];    for (Element e : vector.all()) {        test[e.index()] = e.get();    }    for (int i = 0; i < test.length; i++) {        assertEquals(apriori[i], test[i], EPSILON);    }}
public void mahout_f7807_0()
{    double[] apriori = { 0, 1, 2, 3, 4 };    doTestEnumeration(apriori, new VectorView(new DenseVector(new double[] { -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 }), 2, 5));    doTestEnumeration(apriori, new DenseVector(new double[] { 0, 1, 2, 3, 4 }));    Vector sparse = new RandomAccessSparseVector(5);    sparse.set(0, 0);    sparse.set(1, 1);    sparse.set(2, 2);    sparse.set(3, 3);    sparse.set(4, 4);    doTestEnumeration(apriori, sparse);    sparse = new SequentialAccessSparseVector(5);    sparse.set(0, 0);    sparse.set(1, 1);    sparse.set(2, 2);    sparse.set(3, 3);    sparse.set(4, 4);    doTestEnumeration(apriori, sparse);}
public void mahout_f7808_0()
{    Vector v = new DenseVector(5);    Vector w = new DenseVector(5);    setUpFirstVector(v);    setUpSecondVector(w);    doTestAggregation(v, w);    v = new RandomAccessSparseVector(5);    w = new RandomAccessSparseVector(5);    setUpFirstVector(v);    doTestAggregation(v, w);    setUpSecondVector(w);    doTestAggregation(w, v);    v = new SequentialAccessSparseVector(5);    w = new SequentialAccessSparseVector(5);    setUpFirstVector(v);    doTestAggregation(v, w);    setUpSecondVector(w);    doTestAggregation(w, v);}
private static void mahout_f7809_0(Vector v, Vector w)
{    assertEquals("aggregate(plus, pow(2)) not equal to " + v.getLengthSquared(), v.getLengthSquared(), v.aggregate(Functions.PLUS, Functions.pow(2)), EPSILON);    assertEquals("aggregate(plus, abs) not equal to " + v.norm(1), v.norm(1), v.aggregate(Functions.PLUS, Functions.ABS), EPSILON);    assertEquals("aggregate(max, abs) not equal to " + v.norm(Double.POSITIVE_INFINITY), v.norm(Double.POSITIVE_INFINITY), v.aggregate(Functions.MAX, Functions.ABS), EPSILON);    assertEquals("v.dot(w) != v.aggregate(w, plus, mult)", v.dot(w), v.aggregate(w, Functions.PLUS, Functions.MULT), EPSILON);    assertEquals("|(v-w)|^2 != v.aggregate(w, plus, chain(pow(2), minus))", v.minus(w).dot(v.minus(w)), v.aggregate(w, Functions.PLUS, Functions.chain(Functions.pow(2), Functions.MINUS)), EPSILON);}
public void mahout_f7810_0()
{    assertEquals(1.0, new DenseVector(new double[] { 1 }).aggregate(Functions.MIN, Functions.IDENTITY), EPSILON);    assertEquals(1.0, new DenseVector(new double[] { 2, 1 }).aggregate(Functions.MIN, Functions.IDENTITY), EPSILON);    assertEquals(0, new DenseVector(new double[0]).aggregate(Functions.MIN, Functions.IDENTITY), 0);}
public void mahout_f7811_0()
{    assertEquals(3.0, new DenseVector(new double[] { 1 }).aggregate(new DenseVector(new double[] { 2 }), Functions.MIN, Functions.PLUS), EPSILON);    assertEquals(0, new DenseVector(new double[0]).aggregate(new DenseVector(new double[0]), Functions.MIN, Functions.PLUS), 0);}
private static void mahout_f7812_0(Vector v)
{    v.setQuick(1, 2);    v.setQuick(2, 0.5);    v.setQuick(3, -5);}
private static void mahout_f7813_0(Vector v)
{    v.setQuick(0, 3);    v.setQuick(1, -1.5);    v.setQuick(2, -5);    v.setQuick(3, 2);}
public void mahout_f7814_0()
{        Vector sparseLeft = new RandomAccessSparseVector(3);    Vector denseRight = new DenseVector(3);    sparseLeft.setQuick(0, 1);    sparseLeft.setQuick(1, 2);    sparseLeft.setQuick(2, 3);    denseRight.setQuick(0, 1);    denseRight.setQuick(1, 2);    denseRight.setQuick(2, 3);    assertEquals(sparseLeft, denseRight);    assertEquals(sparseLeft.hashCode(), denseRight.hashCode());    sparseLeft = new SequentialAccessSparseVector(3);    sparseLeft.setQuick(0, 1);    sparseLeft.setQuick(1, 2);    sparseLeft.setQuick(2, 3);    assertEquals(sparseLeft, denseRight);    assertEquals(sparseLeft.hashCode(), denseRight.hashCode());    Vector denseLeft = new DenseVector(3);    denseLeft.setQuick(0, 1);    denseLeft.setQuick(1, 2);    denseLeft.setQuick(2, 3);    assertEquals(denseLeft, denseRight);    assertEquals(denseLeft.hashCode(), denseRight.hashCode());    Vector sparseRight = new SequentialAccessSparseVector(3);    sparseRight.setQuick(0, 1);    sparseRight.setQuick(1, 2);    sparseRight.setQuick(2, 3);    assertEquals(sparseLeft, sparseRight);    assertEquals(sparseLeft.hashCode(), sparseRight.hashCode());    DenseVector emptyLeft = new DenseVector(0);    Vector emptyRight = new SequentialAccessSparseVector(0);    assertEquals(emptyLeft, emptyRight);    assertEquals(emptyLeft.hashCode(), emptyRight.hashCode());    emptyRight = new RandomAccessSparseVector(0);    assertEquals(emptyLeft, emptyRight);    assertEquals(emptyLeft.hashCode(), emptyRight.hashCode());}
public void mahout_f7815_0()
{        Vector left = new SequentialAccessSparseVector(3);    Vector right = new SequentialAccessSparseVector(3);    left.setQuick(0, 1);    left.setQuick(2, 2);    right.setQuick(0, 1);    right.setQuick(1, 2);    assertFalse(left.equals(right));    assertFalse(left.hashCode() == right.hashCode());    left = new RandomAccessSparseVector(3);    right = new RandomAccessSparseVector(3);    left.setQuick(0, 1);    left.setQuick(2, 2);    right.setQuick(0, 1);    right.setQuick(1, 2);    assertFalse(left.equals(right));    assertFalse(left.hashCode() == right.hashCode());        right = new SequentialAccessSparseVector(5);    right.setQuick(0, 1);    right.setQuick(2, 2);    assertFalse(left.equals(right));    assertFalse(left.hashCode() == right.hashCode());    right = new RandomAccessSparseVector(5);    right.setQuick(0, 1);    right.setQuick(2, 2);    assertFalse(left.equals(right));    assertFalse(left.hashCode() == right.hashCode());}
public void mahout_f7816_0()
{    testIterator(new RandomAccessSparseVector(99));    testEmptyAllIterator(new RandomAccessSparseVector(0));    testExample1NonZeroIterator(new RandomAccessSparseVector(13));}
public void mahout_f7817_0()
{    testIterator(new SequentialAccessSparseVector(99));    testEmptyAllIterator(new SequentialAccessSparseVector(0));    testExample1NonZeroIterator(new SequentialAccessSparseVector(13));}
public void mahout_f7818_0()
{    testIterator(new DenseVector(99));    testEmptyAllIterator(new DenseVector(0));    testExample1NonZeroIterator(new DenseVector(13));}
private static void mahout_f7819_0(Vector vector)
{    testSkips(vector.like());    testSkipsLast(vector.like());    testEmptyNonZeroIterator(vector.like());    testSingleNonZeroIterator(vector.like());}
private static void mahout_f7820_0(Vector vector)
{    vector.set(0, 1);    vector.set(2, 2);    vector.set(4, 3);    vector.set(6, 4);        Iterator<Element> it = vector.nonZeroes().iterator();    Element element = null;    int i = 0;    HashSet<Integer> indexes = new HashSet<>();    while (it.hasNext()) {                if (i % 2 == 0) {            element = it.next();            indexes.add(element.index());        }                assertEquals(element.get(), vector.get(element.index()), 0);        ++i;    }        assertEquals(7, i);    assertEquals(4, indexes.size());    assertTrue(indexes.contains(0));    assertTrue(indexes.contains(2));    assertTrue(indexes.contains(4));    assertTrue(indexes.contains(6));        it = vector.all().iterator();    element = null;    i = 0;    while (it.hasNext()) {                if (i % 2 == 0) {            element = it.next();        }                assertEquals(element.index(), i / 2);        assertEquals(element.get(), vector.get(i / 2), 0);        ++i;    }        assertEquals(197, i);}
private static void mahout_f7821_0(Vector vector)
{    vector.set(1, 6);    vector.set(98, 6);        Iterator<Element> it = vector.nonZeroes().iterator();    int i = 0;    while (it.hasNext()) {                it.next();        ++i;    }        assertEquals(2, i);        it = vector.all().iterator();    i = 0;    while (it.hasNext()) {                Element element = it.next();        assertEquals(i, element.index());        ++i;    }    assertFalse(it.hasNext());        assertEquals(99, i);}
private static void mahout_f7822_0(Vector vector)
{        Iterator<Element> it = vector.nonZeroes().iterator();    int i = 0;    while (it.hasNext()) {        ++i;    }    assertEquals(0, i);    it = vector.nonZeroes().iterator();    assertFalse(it.hasNext());    try {        it.next();        fail();    } catch (NoSuchElementException e) {        }}
private static void mahout_f7823_0(Vector vector)
{        Iterator<Element> it = vector.all().iterator();    int i = 0;    while (it.hasNext()) {        ++i;    }    assertEquals(0, i);    it = vector.nonZeroes().iterator();    assertFalse(it.hasNext());    try {        it.next();        fail();    } catch (NoSuchElementException e) {        }    it = vector.all().iterator();    assertFalse(it.hasNext());    try {        it.next();        fail();    } catch (NoSuchElementException e) {        }}
public void mahout_f7824_0()
{    DenseVector vector = new DenseVector(10);    vector.assign(1);    vector.setQuick(3, 0);    vector.set(5, 0);    assertEquals(8, vector.getNumNonZeroElements());}
public void mahout_f7825_0()
{    RandomAccessSparseVector vector = new RandomAccessSparseVector(10);    vector.setQuick(3, 1);    vector.set(5, 1);    vector.setQuick(7, 0);    vector.set(9, 0);    assertEquals(2, vector.getNumNonZeroElements());}
public void mahout_f7826_0()
{    SequentialAccessSparseVector vector = new SequentialAccessSparseVector(10);    vector.setQuick(3, 1);    vector.set(5, 1);    vector.setQuick(7, 0);    vector.set(9, 0);    assertEquals(2, vector.getNumNonZeroElements());}
private static void mahout_f7827_0(Vector vector)
{    vector.set(1, 6);        Iterator<Element> it = vector.nonZeroes().iterator();    for (int i = 0; i < 10; ++i) {        assertTrue(it.hasNext());    }    it = vector.nonZeroes().iterator();    it.next();    for (int i = 0; i < 10; ++i) {        assertFalse(it.hasNext());    }    try {        it.next();        fail();    } catch (NoSuchElementException e) {        }}
private static void mahout_f7828_0(Vector vector)
{    double[] val = { 0, 2, 0, 0, 8, 3, 0, 6, 0, 1, 1, 2, 1 };    for (int i = 0; i < val.length; ++i) {        vector.set(i, val[i]);    }    Set<Integer> expected = Sets.newHashSet(1, 4, 5, 7, 9, 10, 11, 12);    Set<Double> expectedValue = Sets.newHashSet(2.0, 8.0, 3.0, 6.0, 1.0);        Iterator<Element> it = vector.nonZeroes().iterator();    int i = 0;    while (it.hasNext()) {        Element e = it.next();        assertTrue(expected.contains(e.index()));        assertTrue(expectedValue.contains(e.get()));        ++i;    }    assertEquals(8, i);        assertEquals(8, vector.getNumNonZeroElements());        it = vector.nonZeroes().iterator();    i = 0;    while (it.hasNext()) {        Element e = it.next();        if (e.index() == 5) {            e.set(0.0);        }        ++i;    }    assertEquals(8, i);    assertEquals(7, vector.getNumNonZeroElements());        it = vector.nonZeroes().iterator();    i = 0;    while (it.hasNext()) {        Element e = it.next();        if (e.index() == 5) {            vector.set(5, 0.0);        }        ++i;    }        assertEquals(7, i);        assertEquals(7, vector.getNumNonZeroElements());}
public void mahout_f7829_0()
{    Vector v = new DenseVector(new double[] { 0.9921337470551008, 1.0031004325833064, 0.9963963182745947 });    Centroid c = new Centroid(3, new DenseVector(v), 2);    assertEquals(c.getVector().getLengthSquared(), c.getLengthSquared(), 1.0e-17);        c.set(0, -1);    System.out.printf("c = %.9f\nv = %.9f\n", c.getLengthSquared(), c.getVector().getLengthSquared());    assertEquals(c.getVector().getLengthSquared(), c.getLengthSquared(), 1.0e-17);}
public Vector mahout_f7830_0(int size)
{    return new WeightedVector(new DenseVector(size), 4.52, 345);}
public void mahout_f7831_0()
{    WeightedVector v1 = new WeightedVector(new DenseVector(new double[] { 1, 2, 3 }), 5.41, 31);    WeightedVector v2 = new WeightedVector(new DenseVector(new double[] { 1, 2, 3 }), 5.00, 31);    WeightedVector v3 = new WeightedVector(new DenseVector(new double[] { 1, 3, 3 }), 5.00, 31);    WeightedVector v4 = v1.clone();    WeightedVectorComparator comparator = new WeightedVectorComparator();    assertTrue(comparator.compare(v1, v2) > 0);    assertTrue(comparator.compare(v3, v1) < 0);    assertTrue(comparator.compare(v3, v2) > 0);    assertEquals(0, comparator.compare(v4, v1));    assertEquals(0, comparator.compare(v1, v1));}
public void mahout_f7832_0()
{    Vector v1 = new DenseVector(10).assign(Functions.random());    WeightedVector v2 = new WeightedVector(v1, v1, 31);    assertEquals(v1.dot(v1), v2.getWeight(), 1.0e-13);    assertEquals(31, v2.getIndex());    Matrix y = new DenseMatrix(10, 4).assign(Functions.random());    Matrix q = new QRDecomposition(y.viewPart(0, 10, 0, 3)).getQ();    Vector nullSpace = y.viewColumn(3).minus(q.times(q.transpose().times(y.viewColumn(3))));    WeightedVector v3 = new WeightedVector(q.viewColumn(0).plus(q.viewColumn(1)), nullSpace, 1);    assertEquals(0, v3.getWeight(), 1.0e-13);    Vector qx = q.viewColumn(0).plus(q.viewColumn(1)).normalize();    WeightedVector v4 = new WeightedVector(qx, q.viewColumn(0), 2);    assertEquals(Math.sqrt(0.5), v4.getWeight(), 1.0e-13);    WeightedVector v5 = WeightedVector.project(q.viewColumn(0), qx);    assertEquals(Math.sqrt(0.5), v5.getWeight(), 1.0e-13);}
public void mahout_f7833_0()
{    assertEquals("size", 3, getTestVector().getNumNonZeroElements());}
 Vector mahout_f7834_0(int cardinality)
{    return new WeightedVector(new DenseVector(cardinality), 3.14, 53);}
public static void mahout_f7838_0(ResultSet resultSet, Statement statement, Connection connection)
{    quietClose(resultSet);    quietClose(statement);    quietClose(connection);}
public static void mahout_f7839_1(Collection<? extends Closeable> closeables) throws IOException
{    Throwable lastThr = null;    for (Closeable closeable : closeables) {        try {            closeable.close();        } catch (Throwable thr) {                        lastThr = thr;        }    }            closeables.clear();    if (lastThr != null) {        if (lastThr instanceof IOException) {            throw (IOException) lastThr;        } else if (lastThr instanceof RuntimeException) {            throw (RuntimeException) lastThr;        } else {            throw (Error) lastThr;        }    }}
public void mahout_f7840_0() throws IOException
{    if (file.isFile()) {        file.delete();    }}
public void mahout_f7841_0() throws IOException
{    if (mo != null) {        mo.close();    }}
public Matrix mahout_f7842_0()
{    return matrix;}
public void mahout_f7843_0(Matrix matrix)
{    this.matrix = matrix;}
public void mahout_f7844_0(DataOutput out) throws IOException
{    writeMatrix(out, matrix);}
public void mahout_f7845_0(DataInput in) throws IOException
{    matrix = readMatrix(in);}
public static void mahout_f7846_0(DataInput in, Map<String, Integer> columnLabelBindings, Map<String, Integer> rowLabelBindings) throws IOException
{    int colSize = in.readInt();    if (colSize > 0) {        for (int i = 0; i < colSize; i++) {            columnLabelBindings.put(in.readUTF(), in.readInt());        }    }    int rowSize = in.readInt();    if (rowSize > 0) {        for (int i = 0; i < rowSize; i++) {            rowLabelBindings.put(in.readUTF(), in.readInt());        }    }}
public static void mahout_f7847_0(DataOutput out, Map<String, Integer> columnLabelBindings, Map<String, Integer> rowLabelBindings) throws IOException
{    if (columnLabelBindings == null) {        out.writeInt(0);    } else {        out.writeInt(columnLabelBindings.size());        for (Map.Entry<String, Integer> stringIntegerEntry : columnLabelBindings.entrySet()) {            out.writeUTF(stringIntegerEntry.getKey());            out.writeInt(stringIntegerEntry.getValue());        }    }    if (rowLabelBindings == null) {        out.writeInt(0);    } else {        out.writeInt(rowLabelBindings.size());        for (Map.Entry<String, Integer> stringIntegerEntry : rowLabelBindings.entrySet()) {            out.writeUTF(stringIntegerEntry.getKey());            out.writeInt(stringIntegerEntry.getValue());        }    }}
public static Matrix mahout_f7848_0(DataInput in) throws IOException
{    int flags = in.readInt();    Preconditions.checkArgument(flags >> NUM_FLAGS == 0, "Unknown flags set: %d", Integer.toString(flags, 2));    boolean dense = (flags & FLAG_DENSE) != 0;    boolean sequential = (flags & FLAG_SEQUENTIAL) != 0;    boolean hasLabels = (flags & FLAG_LABELS) != 0;    boolean isSparseRowMatrix = (flags & FLAG_SPARSE_ROW) != 0;    int rows = in.readInt();    int columns = in.readInt();    byte vectorFlags = in.readByte();    Matrix matrix;    if (dense) {        matrix = new DenseMatrix(rows, columns);        for (int row = 0; row < rows; row++) {            matrix.assignRow(row, VectorWritable.readVector(in, vectorFlags, columns));        }    } else if (isSparseRowMatrix) {        Vector[] rowVectors = new Vector[rows];        for (int row = 0; row < rows; row++) {            rowVectors[row] = VectorWritable.readVector(in, vectorFlags, columns);        }        matrix = new SparseRowMatrix(rows, columns, rowVectors, true, !sequential);    } else {        matrix = new SparseMatrix(rows, columns);        int numNonZeroRows = in.readInt();        int rowsRead = 0;        while (rowsRead++ < numNonZeroRows) {            int rowIndex = in.readInt();            matrix.assignRow(rowIndex, VectorWritable.readVector(in, vectorFlags, columns));        }    }    if (hasLabels) {        Map<String, Integer> columnLabelBindings = new HashMap<>();        Map<String, Integer> rowLabelBindings = new HashMap<>();        readLabels(in, columnLabelBindings, rowLabelBindings);        if (!columnLabelBindings.isEmpty()) {            matrix.setColumnLabelBindings(columnLabelBindings);        }        if (!rowLabelBindings.isEmpty()) {            matrix.setRowLabelBindings(rowLabelBindings);        }    }    return matrix;}
public static void mahout_f7849_0(final DataOutput out, Matrix matrix) throws IOException
{    int flags = 0;    Vector row = matrix.viewRow(0);    boolean isDense = row.isDense();    if (isDense) {        flags |= FLAG_DENSE;    }    if (row.isSequentialAccess()) {        flags |= FLAG_SEQUENTIAL;    }    if (matrix.getRowLabelBindings() != null || matrix.getColumnLabelBindings() != null) {        flags |= FLAG_LABELS;    }    boolean isSparseRowMatrix = matrix instanceof SparseRowMatrix;    if (isSparseRowMatrix) {        flags |= FLAG_SPARSE_ROW;    }    out.writeInt(flags);    out.writeInt(matrix.rowSize());    out.writeInt(matrix.columnSize());        byte vectorFlags = VectorWritable.flags(matrix.viewRow(0), false);    out.writeByte(vectorFlags);    if (isDense || isSparseRowMatrix) {        for (int i = 0; i < matrix.rowSize(); i++) {            VectorWritable.writeVectorContents(out, matrix.viewRow(i), vectorFlags);        }    } else {        IntArrayList rowIndices = ((SparseMatrix) matrix).nonZeroRowIndices();        int numNonZeroRows = rowIndices.size();        out.writeInt(numNonZeroRows);        for (int i = 0; i < numNonZeroRows; i++) {            int rowIndex = rowIndices.getQuick(i);            out.writeInt(rowIndex);            VectorWritable.writeVectorContents(out, matrix.viewRow(rowIndex), vectorFlags);        }    }    if ((flags & FLAG_LABELS) != 0) {        writeLabelBindings(out, matrix.getColumnLabelBindings(), matrix.getRowLabelBindings());    }}
public static void mahout_f7850_0(long value, DataOutput out) throws IOException
{        writeUnsignedVarLong((value << 1) ^ (value >> 63), out);}
public static void mahout_f7851_0(long value, DataOutput out) throws IOException
{    while ((value & 0xFFFFFFFFFFFFFF80L) != 0L) {        out.writeByte(((int) value & 0x7F) | 0x80);        value >>>= 7;    }    out.writeByte((int) value & 0x7F);}
public static void mahout_f7852_0(int value, DataOutput out) throws IOException
{        writeUnsignedVarInt((value << 1) ^ (value >> 31), out);}
public static void mahout_f7853_0(int value, DataOutput out) throws IOException
{    while ((value & 0xFFFFFF80) != 0L) {        out.writeByte((value & 0x7F) | 0x80);        value >>>= 7;    }    out.writeByte(value & 0x7F);}
public static long mahout_f7854_0(DataInput in) throws IOException
{    long raw = readUnsignedVarLong(in);        long temp = (((raw << 63) >> 63) ^ raw) >> 1;        return temp ^ (raw & (1L << 63));}
public static long mahout_f7855_0(DataInput in) throws IOException
{    long value = 0L;    int i = 0;    long b;    while (((b = in.readByte()) & 0x80L) != 0) {        value |= (b & 0x7F) << i;        i += 7;        Preconditions.checkArgument(i <= 63, "Variable length quantity is too long (must be <= 63)");    }    return value | (b << i);}
public static int mahout_f7856_0(DataInput in) throws IOException
{    int raw = readUnsignedVarInt(in);        int temp = (((raw << 31) >> 31) ^ raw) >> 1;        return temp ^ (raw & (1 << 31));}
public static int mahout_f7857_0(DataInput in) throws IOException
{    int value = 0;    int i = 0;    int b;    while (((b = in.readByte()) & 0x80) != 0) {        value |= (b & 0x7F) << i;        i += 7;        Preconditions.checkArgument(i <= 35, "Variable length quantity is too long (must be <= 35)");    }    return value | (b << i);}
public int mahout_f7858_0()
{    return value;}
public void mahout_f7859_0(int value)
{    this.value = value;}
public boolean mahout_f7860_0(Object other)
{    return other instanceof VarIntWritable && ((VarIntWritable) other).value == value;}
public int mahout_f7861_0()
{    return value;}
public String mahout_f7862_0()
{    return String.valueOf(value);}
public VarIntWritable mahout_f7863_0()
{    return new VarIntWritable(value);}
public int mahout_f7864_0(VarIntWritable other)
{    if (value < other.value) {        return -1;    }    if (value > other.value) {        return 1;    }    return 0;}
public void mahout_f7865_0(DataOutput out) throws IOException
{    Varint.writeSignedVarInt(value, out);}
public void mahout_f7866_0(DataInput in) throws IOException
{    value = Varint.readSignedVarInt(in);}
public long mahout_f7867_0()
{    return value;}
public void mahout_f7868_0(long value)
{    this.value = value;}
public boolean mahout_f7869_0(Object other)
{    return other != null && getClass().equals(other.getClass()) && ((VarLongWritable) other).value == value;}
public int mahout_f7870_0()
{    return Longs.hashCode(value);}
public String mahout_f7871_0()
{    return String.valueOf(value);}
public int mahout_f7872_0(VarLongWritable other)
{    if (value >= other.value) {        if (value > other.value) {            return 1;        }    } else {        return -1;    }    return 0;}
public void mahout_f7873_0(DataOutput out) throws IOException
{    Varint.writeSignedVarLong(value, out);}
public void mahout_f7874_0(DataInput in) throws IOException
{    value = Varint.readSignedVarLong(in);}
public Vector mahout_f7875_0()
{    return vector;}
public void mahout_f7876_0(Vector vector)
{    this.vector = vector;}
public boolean mahout_f7877_0()
{    return writesLaxPrecision;}
public void mahout_f7878_0(boolean writesLaxPrecision)
{    this.writesLaxPrecision = writesLaxPrecision;}
public void mahout_f7879_0(DataOutput out) throws IOException
{    writeVector(out, this.vector, this.writesLaxPrecision);}
public void mahout_f7880_0(DataInput in) throws IOException
{    int flags = in.readByte();    int size = Varint.readUnsignedVarInt(in);    readFields(in, (byte) flags, size);}
private void mahout_f7881_0(DataInput in, byte flags, int size) throws IOException
{    Preconditions.checkArgument(flags >> NUM_FLAGS == 0, "Unknown flags set: %d", Integer.toString(flags, 2));    boolean dense = (flags & FLAG_DENSE) != 0;    boolean sequential = (flags & FLAG_SEQUENTIAL) != 0;    boolean named = (flags & FLAG_NAMED) != 0;    boolean laxPrecision = (flags & FLAG_LAX_PRECISION) != 0;    Vector v;    if (dense) {        double[] values = new double[size];        for (int i = 0; i < size; i++) {            values[i] = laxPrecision ? in.readFloat() : in.readDouble();        }        v = new DenseVector(values);    } else {        int numNonDefaultElements = Varint.readUnsignedVarInt(in);        v = sequential ? new SequentialAccessSparseVector(size, numNonDefaultElements) : new RandomAccessSparseVector(size, numNonDefaultElements);        if (sequential) {            int lastIndex = 0;            for (int i = 0; i < numNonDefaultElements; i++) {                int delta = Varint.readUnsignedVarInt(in);                int index = lastIndex + delta;                lastIndex = index;                double value = laxPrecision ? in.readFloat() : in.readDouble();                v.setQuick(index, value);            }        } else {            for (int i = 0; i < numNonDefaultElements; i++) {                int index = Varint.readUnsignedVarInt(in);                double value = laxPrecision ? in.readFloat() : in.readDouble();                v.setQuick(index, value);            }        }    }    if (named) {        String name = in.readUTF();        v = new NamedVector(v, name);    }    vector = v;}
public static void mahout_f7882_0(DataOutput out, Vector vector) throws IOException
{    writeVector(out, vector, false);}
public static byte mahout_f7883_0(Vector vector, boolean laxPrecision)
{    boolean dense = vector.isDense();    boolean sequential = vector.isSequentialAccess();    boolean named = vector instanceof NamedVector;    return (byte) ((dense ? FLAG_DENSE : 0) | (sequential ? FLAG_SEQUENTIAL : 0) | (named ? FLAG_NAMED : 0) | (laxPrecision ? FLAG_LAX_PRECISION : 0));}
public static void mahout_f7884_0(DataOutput out, byte flags, int size) throws IOException
{    out.writeByte(flags);    Varint.writeUnsignedVarInt(size, out);}
public static void mahout_f7885_0(DataOutput out, Vector vector, boolean laxPrecision) throws IOException
{    byte flags = flags(vector, laxPrecision);    writeVectorFlagsAndSize(out, flags, vector.size());    writeVectorContents(out, vector, flags);}
public static void mahout_f7886_0(DataOutput out, Vector vector, byte flags) throws IOException
{    boolean dense = (flags & FLAG_DENSE) != 0;    boolean sequential = (flags & FLAG_SEQUENTIAL) != 0;    boolean named = (flags & FLAG_NAMED) != 0;    boolean laxPrecision = (flags & FLAG_LAX_PRECISION) != 0;    if (dense) {        for (Element element : vector.all()) {            if (laxPrecision) {                out.writeFloat((float) element.get());            } else {                out.writeDouble(element.get());            }        }    } else {        Varint.writeUnsignedVarInt(vector.getNumNonZeroElements(), out);        Iterator<Element> iter = vector.nonZeroes().iterator();        if (sequential) {            int lastIndex = 0;            while (iter.hasNext()) {                Element element = iter.next();                if (element.get() == 0) {                    continue;                }                int thisIndex = element.index();                                Varint.writeUnsignedVarInt(thisIndex - lastIndex, out);                lastIndex = thisIndex;                if (laxPrecision) {                    out.writeFloat((float) element.get());                } else {                    out.writeDouble(element.get());                }            }        } else {            while (iter.hasNext()) {                Element element = iter.next();                if (element.get() == 0) {                                        continue;                }                Varint.writeUnsignedVarInt(element.index(), out);                if (laxPrecision) {                    out.writeFloat((float) element.get());                } else {                    out.writeDouble(element.get());                }            }        }    }    if (named) {        String name = ((NamedVector) vector).getName();        out.writeUTF(name == null ? "" : name);    }}
public static Vector mahout_f7887_0(DataInput in) throws IOException
{    VectorWritable v = new VectorWritable();    v.readFields(in);    return v.get();}
public static Vector mahout_f7888_0(DataInput in, byte vectorFlags, int size) throws IOException
{    VectorWritable v = new VectorWritable();    v.readFields(in, vectorFlags, size);    return v.get();}
public static VectorWritable mahout_f7889_0(Iterator<VectorWritable> vectors)
{    return new VectorWritable(mergeToVector(vectors));}
public static Vector mahout_f7890_0(Iterator<VectorWritable> vectors)
{    Vector accumulator = vectors.next().get();    while (vectors.hasNext()) {        VectorWritable v = vectors.next();        if (v != null) {            for (Element nonZeroElement : v.get().nonZeroes()) {                accumulator.setQuick(nonZeroElement.index(), nonZeroElement.get());            }        }    }    return accumulator;}
public boolean mahout_f7891_0(Object o)
{    return o instanceof VectorWritable && vector.equals(((VectorWritable) o).get());}
public int mahout_f7892_0()
{    return vector.hashCode();}
public String mahout_f7893_0()
{    return vector.toString();}
public void mahout_f7894_0() throws Exception
{    Matrix m = new SparseMatrix(5, 5);    m.set(1, 2, 3.0);    m.set(3, 4, 5.0);    Map<String, Integer> bindings = new HashMap<>();    bindings.put("A", 0);    bindings.put("B", 1);    bindings.put("C", 2);    bindings.put("D", 3);    bindings.put("default", 4);    m.setRowLabelBindings(bindings);    m.setColumnLabelBindings(bindings);    doTestMatrixWritableEquals(m);}
public void mahout_f7895_0() throws Exception
{    Matrix m = new SparseRowMatrix(5, 5);    m.set(1, 2, 3.0);    m.set(3, 4, 5.0);    Map<String, Integer> bindings = new HashMap<>();    bindings.put("A", 0);    bindings.put("B", 1);    bindings.put("C", 2);    bindings.put("D", 3);    bindings.put("default", 4);    m.setRowLabelBindings(bindings);    m.setColumnLabelBindings(bindings);    doTestMatrixWritableEquals(m);}
public void mahout_f7896_0() throws Exception
{    Matrix m = new DenseMatrix(5, 5);    m.set(1, 2, 3.0);    m.set(3, 4, 5.0);    Map<String, Integer> bindings = new HashMap<>();    bindings.put("A", 0);    bindings.put("B", 1);    bindings.put("C", 2);    bindings.put("D", 3);    bindings.put("default", 4);    m.setRowLabelBindings(bindings);    m.setColumnLabelBindings(bindings);    doTestMatrixWritableEquals(m);}
private static void mahout_f7897_0(Matrix m) throws IOException
{    Writable matrixWritable = new MatrixWritable(m);    MatrixWritable matrixWritable2 = new MatrixWritable();    writeAndRead(matrixWritable, matrixWritable2);    Matrix m2 = matrixWritable2.get();    compareMatrices(m, m2);    doCheckBindings(m2.getRowLabelBindings());    doCheckBindings(m2.getColumnLabelBindings());}
private static void mahout_f7898_0(Matrix m, Matrix m2)
{    assertEquals(m.numRows(), m2.numRows());    assertEquals(m.numCols(), m2.numCols());    for (int r = 0; r < m.numRows(); r++) {        for (int c = 0; c < m.numCols(); c++) {            assertEquals(m.get(r, c), m2.get(r, c), EPSILON);        }    }    Map<String, Integer> bindings = m.getRowLabelBindings();    Map<String, Integer> bindings2 = m2.getRowLabelBindings();    assertEquals(bindings == null, bindings2 == null);    if (bindings != null) {        assertEquals(bindings.size(), m.numRows());        assertEquals(bindings.size(), bindings2.size());        for (Map.Entry<String, Integer> entry : bindings.entrySet()) {            assertEquals(entry.getValue(), bindings2.get(entry.getKey()));        }    }    bindings = m.getColumnLabelBindings();    bindings2 = m2.getColumnLabelBindings();    assertEquals(bindings == null, bindings2 == null);    if (bindings != null) {        assertEquals(bindings.size(), bindings2.size());        for (Map.Entry<String, Integer> entry : bindings.entrySet()) {            assertEquals(entry.getValue(), bindings2.get(entry.getKey()));        }    }}
private static void mahout_f7899_0(Map<String, Integer> labels)
{    assertTrue("Missing label", labels.keySet().contains("A"));    assertTrue("Missing label", labels.keySet().contains("B"));    assertTrue("Missing label", labels.keySet().contains("C"));    assertTrue("Missing label", labels.keySet().contains("D"));    assertTrue("Missing label", labels.keySet().contains("default"));}
private static void mahout_f7900_0(Writable toWrite, Writable toRead) throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    try (DataOutputStream dos = new DataOutputStream(baos)) {        toWrite.write(dos);    }    ByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray());    try (DataInputStream dis = new DataInputStream(bais)) {        toRead.readFields(dis);    }}
public void mahout_f7901_0() throws Exception
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    DataOutput out = new DataOutputStream(baos);    Varint.writeUnsignedVarLong(0L, out);    for (long i = 1L; i > 0L && i <= (1L << 62); i <<= 1) {        Varint.writeUnsignedVarLong(i - 1, out);        Varint.writeUnsignedVarLong(i, out);    }    Varint.writeUnsignedVarLong(Long.MAX_VALUE, out);    DataInput in = new DataInputStream(new ByteArrayInputStream(baos.toByteArray()));    assertEquals(0L, Varint.readUnsignedVarLong(in));    for (long i = 1L; i > 0L && i <= (1L << 62); i <<= 1) {        assertEquals(i - 1, Varint.readUnsignedVarLong(in));        assertEquals(i, Varint.readUnsignedVarLong(in));    }    assertEquals(Long.MAX_VALUE, Varint.readUnsignedVarLong(in));}
public void mahout_f7902_0() throws Exception
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    DataOutput out = new DataOutputStream(baos);    Varint.writeSignedVarLong(0L, out);    for (long i = 1L; i <= (1L << 61); i <<= 1) {        Varint.writeSignedVarLong(i - 1, out);        Varint.writeSignedVarLong(i, out);    }    Varint.writeSignedVarLong((1L << 62) - 1, out);    Varint.writeSignedVarLong((1L << 62), out);    Varint.writeSignedVarLong(Long.MAX_VALUE, out);    DataInput in = new DataInputStream(new ByteArrayInputStream(baos.toByteArray()));    assertEquals(0L, Varint.readSignedVarLong(in));    for (long i = 1L; i <= (1L << 61); i <<= 1) {        assertEquals(i - 1, Varint.readSignedVarLong(in));        assertEquals(i, Varint.readSignedVarLong(in));    }    assertEquals((1L << 62) - 1, Varint.readSignedVarLong(in));    assertEquals((1L << 62), Varint.readSignedVarLong(in));    assertEquals(Long.MAX_VALUE, Varint.readSignedVarLong(in));}
public void mahout_f7903_0() throws Exception
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    DataOutput out = new DataOutputStream(baos);    for (long i = -1L; i >= -(1L << 62); i <<= 1) {        Varint.writeSignedVarLong(i, out);        Varint.writeSignedVarLong(i + 1, out);    }    Varint.writeSignedVarLong(Long.MIN_VALUE, out);    Varint.writeSignedVarLong(Long.MIN_VALUE + 1, out);    DataInput in = new DataInputStream(new ByteArrayInputStream(baos.toByteArray()));    for (long i = -1L; i >= -(1L << 62); i <<= 1) {        assertEquals(i, Varint.readSignedVarLong(in));        assertEquals(i + 1, Varint.readSignedVarLong(in));    }    assertEquals(Long.MIN_VALUE, Varint.readSignedVarLong(in));    assertEquals(Long.MIN_VALUE + 1, Varint.readSignedVarLong(in));}
public void mahout_f7904_0() throws Exception
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    DataOutput out = new DataOutputStream(baos);    Varint.writeUnsignedVarInt(0, out);    for (int i = 1; i > 0 && i <= (1 << 30); i <<= 1) {        Varint.writeUnsignedVarLong(i - 1, out);        Varint.writeUnsignedVarLong(i, out);    }    Varint.writeUnsignedVarLong(Integer.MAX_VALUE, out);    DataInput in = new DataInputStream(new ByteArrayInputStream(baos.toByteArray()));    assertEquals(0, Varint.readUnsignedVarInt(in));    for (int i = 1; i > 0 && i <= (1 << 30); i <<= 1) {        assertEquals(i - 1, Varint.readUnsignedVarInt(in));        assertEquals(i, Varint.readUnsignedVarInt(in));    }    assertEquals(Integer.MAX_VALUE, Varint.readUnsignedVarInt(in));}
public void mahout_f7905_0() throws Exception
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    DataOutput out = new DataOutputStream(baos);    Varint.writeSignedVarInt(0, out);    for (int i = 1; i <= (1 << 29); i <<= 1) {        Varint.writeSignedVarLong(i - 1, out);        Varint.writeSignedVarLong(i, out);    }    Varint.writeSignedVarInt((1 << 30) - 1, out);    Varint.writeSignedVarInt((1 << 30), out);    Varint.writeSignedVarInt(Integer.MAX_VALUE, out);    DataInput in = new DataInputStream(new ByteArrayInputStream(baos.toByteArray()));    assertEquals(0, Varint.readSignedVarInt(in));    for (int i = 1; i <= (1 << 29); i <<= 1) {        assertEquals(i - 1, Varint.readSignedVarInt(in));        assertEquals(i, Varint.readSignedVarInt(in));    }    assertEquals((1L << 30) - 1, Varint.readSignedVarInt(in));    assertEquals((1L << 30), Varint.readSignedVarInt(in));    assertEquals(Integer.MAX_VALUE, Varint.readSignedVarInt(in));}
public void mahout_f7906_0() throws Exception
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    DataOutput out = new DataOutputStream(baos);    for (int i = -1; i >= -(1 << 30); i <<= 1) {        Varint.writeSignedVarInt(i, out);        Varint.writeSignedVarInt(i + 1, out);    }    Varint.writeSignedVarInt(Integer.MIN_VALUE, out);    Varint.writeSignedVarInt(Integer.MIN_VALUE + 1, out);    DataInput in = new DataInputStream(new ByteArrayInputStream(baos.toByteArray()));    for (int i = -1; i >= -(1 << 30); i <<= 1) {        assertEquals(i, Varint.readSignedVarInt(in));        assertEquals(i + 1, Varint.readSignedVarInt(in));    }    assertEquals(Integer.MIN_VALUE, Varint.readSignedVarInt(in));    assertEquals(Integer.MIN_VALUE + 1, Varint.readSignedVarInt(in));}
public void mahout_f7907_0() throws Exception
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    DataOutput out = new DataOutputStream(baos);    int expectedSize = 0;    for (int exponent = 0; exponent <= 62; exponent++) {        Varint.writeUnsignedVarLong(1L << exponent, out);        expectedSize += 1 + exponent / 7;        assertEquals(expectedSize, baos.size());    }}
public void mahout_f7908_0() throws Exception
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    DataOutput out = new DataOutputStream(baos);    int expectedSize = 0;    for (int exponent = 0; exponent <= 61; exponent++) {        Varint.writeSignedVarLong(1L << exponent, out);        expectedSize += 1 + ((exponent + 1) / 7);        assertEquals(expectedSize, baos.size());    }    for (int exponent = 0; exponent <= 61; exponent++) {        Varint.writeSignedVarLong(-(1L << exponent) - 1, out);        expectedSize += 1 + ((exponent + 1) / 7);        assertEquals(expectedSize, baos.size());    }}
public void mahout_f7909_0(Vector v)
{    int size = randomInt(v.size() - 1);    for (int i = 0; i < size; ++i) {        v.set(randomInt(v.size() - 1), randomDouble());    }    int zeros = Math.max(2, size / 4);    for (Element e : v.nonZeroes()) {        if (e.index() % zeros == 0) {            e.set(0.0);        }    }}
public void mahout_f7910_0() throws Exception
{    Vector v = new SequentialAccessSparseVector(MAX_VECTOR_SIZE);    createRandom(v);    Vector view = new VectorView(v, 0, v.size());    doTestVectorWritableEquals(view);}
public void mahout_f7911_0() throws Exception
{    Vector v = new SequentialAccessSparseVector(MAX_VECTOR_SIZE);    createRandom(v);    doTestVectorWritableEquals(v);}
public void mahout_f7912_0() throws Exception
{    Vector v = new RandomAccessSparseVector(MAX_VECTOR_SIZE);    createRandom(v);    doTestVectorWritableEquals(v);}
public void mahout_f7913_0() throws Exception
{    Vector v = new DenseVector(MAX_VECTOR_SIZE);    createRandom(v);    doTestVectorWritableEquals(v);}
public void mahout_f7914_0() throws Exception
{    Vector v = new DenseVector(MAX_VECTOR_SIZE);    v = new NamedVector(v, "Victor");    createRandom(v);    doTestVectorWritableEquals(v);}
private static void mahout_f7915_0(Vector v) throws IOException
{    Writable vectorWritable = new VectorWritable(v);    VectorWritable vectorWritable2 = new VectorWritable();    writeAndRead(vectorWritable, vectorWritable2);    Vector v2 = vectorWritable2.get();    if (v instanceof NamedVector) {        assertTrue(v2 instanceof NamedVector);        NamedVector nv = (NamedVector) v;        NamedVector nv2 = (NamedVector) v2;        assertEquals(nv.getName(), nv2.getName());        assertEquals("Victor", nv.getName());    }    assertEquals(v, v2);}
private static void mahout_f7916_0(Writable toWrite, Writable toRead) throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    try (DataOutputStream dos = new DataOutputStream(baos)) {        toWrite.write(dos);    }    ByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray());    try (DataInputStream dis = new DataInputStream(bais)) {        toRead.readFields(dis);    }}
