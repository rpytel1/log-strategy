public void metron_f7253_0() throws Exception
{    PcapOptions.FILTER_IMPL.put(configuration, new FixedPcapFilter.Configurator());    PcapOptions.START_TIME_NS.put(configuration, getTimestamp(0, pcapEntries));    PcapOptions.END_TIME_NS.put(configuration, getTimestamp(pcapEntries.size() - 1, pcapEntries) + 1);    PcapOptions.FIELDS.put(configuration, new HashMap<>());    PcapJob<Map<String, String>> job = new PcapJob<>();    Statusable<Path> results = job.submit(PcapFinalizerStrategies.CLI, configuration);    Assert.assertEquals(Statusable.JobType.MAP_REDUCE, results.getJobType());    waitForJob(results);    Assert.assertEquals(JobStatus.State.SUCCEEDED, results.getStatus().getState());    Pageable<Path> resultPages = results.get();    Iterable<byte[]> bytes = Iterables.transform(resultPages, path -> {        try {            return HDFSUtils.readBytes(path);        } catch (IOException e) {            throw new IllegalStateException(e);        }    });    assertInOrder(bytes);    Assert.assertEquals(pcapEntries.size(), resultPages.getSize());}
public void metron_f7254_0() throws Exception
{    PcapOptions.FILTER_IMPL.put(configuration, new QueryPcapFilter.Configurator());    PcapOptions.START_TIME_NS.put(configuration, getTimestamp(0, pcapEntries));    PcapOptions.END_TIME_NS.put(configuration, getTimestamp(pcapEntries.size() - 1, pcapEntries) + 1);    PcapOptions.FIELDS.put(configuration, "");    PcapJob<String> job = new PcapJob<>();    Statusable<Path> results = job.submit(PcapFinalizerStrategies.CLI, configuration);    Assert.assertEquals(Statusable.JobType.MAP_REDUCE, results.getJobType());    waitForJob(results);    Pageable<Path> resultPages = results.get();    Iterable<byte[]> bytes = Iterables.transform(resultPages, path -> {        try {            return HDFSUtils.readBytes(path);        } catch (IOException e) {            throw new IllegalStateException(e);        }    });    assertInOrder(bytes);    Assert.assertEquals(pcapEntries.size(), resultPages.getSize());}
public void metron_f7255_0() throws Exception
{    PcapOptions.FILTER_IMPL.put(configuration, new FixedPcapFilter.Configurator());    PcapOptions.START_TIME_NS.put(configuration, getTimestamp(0, pcapEntries));    PcapOptions.END_TIME_NS.put(configuration, getTimestamp(pcapEntries.size() - 1, pcapEntries) + 1);    PcapOptions.FIELDS.put(configuration, new HashMap<String, String>() {        {            put(Constants.Fields.DST_PORT.getName(), "22");        }    });    PcapOptions.NUM_RECORDS_PER_FILE.put(configuration, 1);    PcapJob<Map<String, String>> job = new PcapJob<>();    Statusable<Path> results = job.submit(PcapFinalizerStrategies.CLI, configuration);    Assert.assertEquals(Statusable.JobType.MAP_REDUCE, results.getJobType());    waitForJob(results);    Assert.assertEquals(JobStatus.State.SUCCEEDED, results.getStatus().getState());    Pageable<Path> resultPages = results.get();    Iterable<byte[]> bytes = Iterables.transform(resultPages, path -> {        try {            return HDFSUtils.readBytes(path);        } catch (IOException e) {            throw new IllegalStateException(e);        }    });    assertInOrder(bytes);    Assert.assertTrue(resultPages.getSize() > 0);    Assert.assertEquals(Iterables.size(filterPcaps(pcapEntries, new Predicate<JSONObject>() {        @Override        public boolean apply(@Nullable JSONObject input) {            Object prt = input.get(Constants.Fields.DST_PORT.getName());            return prt != null && prt.toString().equals("22");        }    }, withHeaders)), resultPages.getSize());    ByteArrayOutputStream baos = new ByteArrayOutputStream();    PcapMerger.merge(baos, HDFSUtils.readBytes(resultPages.getPage(0)));    Assert.assertTrue(baos.toByteArray().length > 0);}
public boolean metron_f7256_0(@Nullable JSONObject input)
{    Object prt = input.get(Constants.Fields.DST_PORT.getName());    return prt != null && prt.toString().equals("22");}
public void metron_f7257_0() throws Exception
{    PcapOptions.FILTER_IMPL.put(configuration, new QueryPcapFilter.Configurator());    PcapOptions.START_TIME_NS.put(configuration, getTimestamp(0, pcapEntries));    PcapOptions.END_TIME_NS.put(configuration, getTimestamp(pcapEntries.size() - 1, pcapEntries) + 1);    PcapOptions.FIELDS.put(configuration, "ip_dst_port == 22");    PcapJob<String> job = new PcapJob<>();    Statusable<Path> results = job.submit(PcapFinalizerStrategies.CLI, configuration);    Assert.assertEquals(Statusable.JobType.MAP_REDUCE, results.getJobType());    waitForJob(results);    Assert.assertEquals(JobStatus.State.SUCCEEDED, results.getStatus().getState());    Pageable<Path> resultPages = results.get();    Iterable<byte[]> bytes = Iterables.transform(resultPages, path -> {        try {            return HDFSUtils.readBytes(path);        } catch (IOException e) {            throw new IllegalStateException(e);        }    });    assertInOrder(bytes);    Assert.assertEquals(Iterables.size(filterPcaps(pcapEntries, new Predicate<JSONObject>() {        @Override        public boolean apply(@Nullable JSONObject input) {            Object prt = input.get(Constants.Fields.DST_PORT.getName());            return prt != null && prt.toString().equals("22");        }    }, withHeaders)), resultPages.getSize());    ByteArrayOutputStream baos = new ByteArrayOutputStream();    PcapMerger.merge(baos, HDFSUtils.readBytes(resultPages.getPage(0)));    Assert.assertTrue(baos.toByteArray().length > 0);}
public boolean metron_f7258_0(@Nullable JSONObject input)
{    Object prt = input.get(Constants.Fields.DST_PORT.getName());    return prt != null && prt.toString().equals("22");}
public void metron_f7259_0() throws Exception
{    PcapOptions.FILTER_IMPL.put(configuration, new QueryPcapFilter.Configurator());    PcapOptions.START_TIME_NS.put(configuration, getTimestamp(0, pcapEntries));    PcapOptions.END_TIME_NS.put(configuration, getTimestamp(pcapEntries.size() - 1, pcapEntries) + 1);    PcapOptions.FIELDS.put(configuration, "ip_dst_port > 20 and ip_dst_port < 55792");    PcapJob<String> job = new PcapJob<>();    Statusable<Path> results = job.submit(PcapFinalizerStrategies.CLI, configuration);    Assert.assertEquals(Statusable.JobType.MAP_REDUCE, results.getJobType());    waitForJob(results);    Assert.assertEquals(JobStatus.State.SUCCEEDED, results.getStatus().getState());    Pageable<Path> resultPages = results.get();    Iterable<byte[]> bytes = Iterables.transform(results.get(), path -> {        try {            return HDFSUtils.readBytes(path);        } catch (IOException e) {            throw new IllegalStateException(e);        }    });    assertInOrder(bytes);    Assert.assertEquals(Iterables.size(filterPcaps(pcapEntries, new Predicate<JSONObject>() {        @Override        public boolean apply(@Nullable JSONObject input) {            Object prt = input.get(Constants.Fields.DST_PORT.getName());            return prt != null && ((Long) prt > 20 && (Long) prt < 55792);        }    }, withHeaders)), resultPages.getSize());    ByteArrayOutputStream baos = new ByteArrayOutputStream();    PcapMerger.merge(baos, HDFSUtils.readBytes(resultPages.getPage(0)));    Assert.assertTrue(baos.toByteArray().length > 0);}
public boolean metron_f7260_0(@Nullable JSONObject input)
{    Object prt = input.get(Constants.Fields.DST_PORT.getName());    return prt != null && ((Long) prt > 20 && (Long) prt < 55792);}
public void metron_f7261_0() throws Exception
{    PcapOptions.FILTER_IMPL.put(configuration, new QueryPcapFilter.Configurator());    PcapOptions.START_TIME_NS.put(configuration, getTimestamp(0, pcapEntries));    PcapOptions.END_TIME_NS.put(configuration, getTimestamp(pcapEntries.size() - 1, pcapEntries) + 1);    PcapOptions.FIELDS.put(configuration, "ip_dst_port > 55790");    PcapJob<String> job = new PcapJob<>();    Statusable<Path> results = job.submit(PcapFinalizerStrategies.CLI, configuration);    Assert.assertEquals(Statusable.JobType.MAP_REDUCE, results.getJobType());    waitForJob(results);    Assert.assertEquals(JobStatus.State.SUCCEEDED, results.getStatus().getState());    Pageable<Path> resultPages = results.get();    Iterable<byte[]> bytes = Iterables.transform(resultPages, path -> {        try {            return HDFSUtils.readBytes(path);        } catch (IOException e) {            throw new IllegalStateException(e);        }    });    assertInOrder(bytes);    Assert.assertEquals(Iterables.size(filterPcaps(pcapEntries, new Predicate<JSONObject>() {        @Override        public boolean apply(@Nullable JSONObject input) {            Object prt = input.get(Constants.Fields.DST_PORT.getName());            return prt != null && (Long) prt > 55790;        }    }, withHeaders)), resultPages.getSize());    ByteArrayOutputStream baos = new ByteArrayOutputStream();    PcapMerger.merge(baos, HDFSUtils.readBytes(resultPages.getPage(0)));    Assert.assertTrue(baos.toByteArray().length > 0);}
public boolean metron_f7262_0(@Nullable JSONObject input)
{    Object prt = input.get(Constants.Fields.DST_PORT.getName());    return prt != null && (Long) prt > 55790;}
public void metron_f7263_0() throws Exception
{    PcapOptions.FILTER_IMPL.put(configuration, new QueryPcapFilter.Configurator());    PcapOptions.FIELDS.put(configuration, "BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', packet)");    PcapOptions.START_TIME_NS.put(configuration, getTimestamp(0, pcapEntries));    PcapOptions.END_TIME_NS.put(configuration, getTimestamp(pcapEntries.size() - 1, pcapEntries) + 1);    PcapJob<String> job = new PcapJob<>();    Statusable<Path> results = job.submit(PcapFinalizerStrategies.CLI, configuration);    Assert.assertEquals(Statusable.JobType.MAP_REDUCE, results.getJobType());    waitForJob(results);    Assert.assertEquals(JobStatus.State.SUCCEEDED, results.getStatus().getState());    Iterable<byte[]> bytes = Iterables.transform(results.get(), path -> {        try {            return HDFSUtils.readBytes(path);        } catch (IOException e) {            throw new IllegalStateException(e);        }    });    assertInOrder(bytes);    Assert.assertEquals(1, results.get().getSize());    ByteArrayOutputStream baos = new ByteArrayOutputStream();    PcapMerger.merge(baos, HDFSUtils.readBytes(results.get().getPage(0)));    Assert.assertTrue(baos.toByteArray().length > 0);}
private void metron_f7264_0(Statusable statusable) throws Exception
{    for (int t = 0; t < MAX_RETRIES; ++t, Thread.sleep(SLEEP_MS)) {        if (!statusable.getStatus().getState().equals(JobStatus.State.RUNNING)) {            if (statusable.isDone()) {                return;            }        }    }    throw new Exception("Job did not complete within " + (MAX_RETRIES * SLEEP_MS) + " seconds");}
private static Iterable<Map.Entry<byte[], byte[]>> metron_f7265_0(Path pcapFile, boolean withHeaders) throws IOException
{    SequenceFile.Reader reader = new SequenceFile.Reader(new Configuration(), SequenceFile.Reader.file(pcapFile));    List<Map.Entry<byte[], byte[]>> ret = new ArrayList<>();    IntWritable key = new IntWritable();    BytesWritable value = new BytesWritable();    while (reader.next(key, value)) {        byte[] pcapWithHeader = value.copyBytes();                                                long calculatedTs = PcapHelper.getTimestamp(pcapWithHeader);        {            List<PacketInfo> info = PcapHelper.toPacketInfo(pcapWithHeader);            for (PacketInfo pi : info) {                Assert.assertEquals(calculatedTs, pi.getPacketTimeInNanos());                                    }        }        if (withHeaders) {            ret.add(new AbstractMap.SimpleImmutableEntry<>(Bytes.toBytes(calculatedTs), pcapWithHeader));        } else {            byte[] pcapRaw = new byte[pcapWithHeader.length - PcapHelper.GLOBAL_HEADER_SIZE - PcapHelper.PACKET_HEADER_SIZE];            System.arraycopy(pcapWithHeader, PcapHelper.GLOBAL_HEADER_SIZE + PcapHelper.PACKET_HEADER_SIZE, pcapRaw, 0, pcapRaw.length);            ret.add(new AbstractMap.SimpleImmutableEntry<>(Bytes.toBytes(calculatedTs), pcapRaw));        }    }    return Iterables.limit(ret, 2 * (ret.size() / 2));}
public static void metron_f7266_0(Iterable<byte[]> packets)
{    long previous = 0;    for (byte[] packet : packets) {        for (JSONObject json : TO_JSONS.apply(packet)) {            Long current = Long.parseLong(json.get("ts_micro").toString());            Assert.assertNotNull(current);            Assert.assertTrue(Long.compareUnsigned(current, previous) >= 0);            previous = current;        }    }}
public Iterable<JSONObject> metron_f7267_0(@Nullable byte[] input)
{    try {        return PcapHelper.toJSON(PcapHelper.toPacketInfo(input));    } catch (IOException e) {        throw new RuntimeException(e.getMessage(), e);    }}
private Iterable<JSONObject> metron_f7268_0(Iterable<Map.Entry<byte[], byte[]>> pcaps, Predicate<JSONObject> predicate, boolean withHeaders)
{    Function<Map.Entry<byte[], byte[]>, byte[]> pcapTransform = null;    if (!withHeaders) {        final Endianness endianness = Endianness.getNativeEndianness();        pcapTransform = kv -> PcapHelper.addGlobalHeader(PcapHelper.addPacketHeader(Bytes.toLong(kv.getKey()), kv.getValue(), endianness), endianness);    } else {        pcapTransform = kv -> kv.getValue();    }    return Iterables.filter(Iterables.concat(Iterables.transform(Iterables.transform(pcaps, pcapTransform), TO_JSONS)), predicate);}
public void metron_f7269_0() throws IOException
{    MockitoAnnotations.initMocks(this);    execDir = System.getProperty("user.dir");    prefixStrategy = clock -> "random_prefix";}
public void metron_f7270_0() throws Exception
{    String[] args = { "fixed", "-start_time", "500", "-ip_src_addr", "192.168.1.1", "-ip_dst_addr", "192.168.1.2", "-ip_src_port", "8081", "-ip_dst_port", "8082", "-protocol", "6", "-packet_filter", "`casey`" };    HashMap<String, String> query = new HashMap<String, String>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "192.168.1.1");            put(Constants.Fields.DST_ADDR.getName(), "192.168.1.2");            put(Constants.Fields.SRC_PORT.getName(), "8081");            put(Constants.Fields.DST_PORT.getName(), "8082");            put(Constants.Fields.PROTOCOL.getName(), "6");            put(Constants.Fields.INCLUDES_REVERSE_TRAFFIC.getName(), "false");            put(PcapHelper.PacketFields.PACKET_FILTER.getName(), "`casey`");        }    };    FixedPcapConfig config = new FixedPcapConfig(prefixStrategy);    PcapOptions.BASE_PATH.put(config, BASE_INPUT_PATH_DEFAULT);    PcapOptions.BASE_INTERIM_RESULT_PATH.put(config, BASE_INTERIM_RESULT_PATH_DEFAULT);    PcapOptions.FIELDS.put(config, query);    PcapOptions.NUM_REDUCERS.put(config, 10);    PcapOptions.START_TIME_MS.put(config, 500L);    when(jobRunner.submit(isA(Finalizer.class), argThat(mapContaining(config)))).thenReturn(jobRunner);    PcapCli cli = new PcapCli(jobRunner, prefixStrategy);    assertThat("Expect no errors on run", cli.run(args), equalTo(0));    verify(jobRunner).get();}
private Matcher<Map<K, V>> metron_f7271_0(Map<K, V> map)
{    return new TypeSafeMatcher<Map<K, V>>() {        @Override        protected boolean matchesSafely(Map<K, V> item) {            for (K key : map.keySet()) {                if (key.equals(PcapOptions.HADOOP_CONF.getKey())) {                    Configuration itemConfiguration = (Configuration) item.get(PcapOptions.HADOOP_CONF.getKey());                    Map<String, Object> mapConfiguration = (Map<String, Object>) map.get(PcapOptions.HADOOP_CONF.getKey());                    for (String setting : mapConfiguration.keySet()) {                        if (!mapConfiguration.get(setting).equals(itemConfiguration.get(setting, ""))) {                            return false;                        }                    }                } else {                    V itemValue = item.get(key);                    V mapValue = map.get(key);                    if (itemValue != null ? !itemValue.equals(mapValue) : mapValue != null) {                        return false;                    }                }            }            return true;        }        @Override        public void describeTo(Description description) {            description.appendText("Should contain items: ");            for (Entry<K, V> entry : map.entrySet()) {                StringBuilder sb = new StringBuilder();                sb.append("key=");                sb.append(entry.getKey());                sb.append(",value=");                sb.append(entry.getValue());                description.appendText(sb.toString());            }        }    };}
protected boolean metron_f7272_0(Map<K, V> item)
{    for (K key : map.keySet()) {        if (key.equals(PcapOptions.HADOOP_CONF.getKey())) {            Configuration itemConfiguration = (Configuration) item.get(PcapOptions.HADOOP_CONF.getKey());            Map<String, Object> mapConfiguration = (Map<String, Object>) map.get(PcapOptions.HADOOP_CONF.getKey());            for (String setting : mapConfiguration.keySet()) {                if (!mapConfiguration.get(setting).equals(itemConfiguration.get(setting, ""))) {                    return false;                }            }        } else {            V itemValue = item.get(key);            V mapValue = map.get(key);            if (itemValue != null ? !itemValue.equals(mapValue) : mapValue != null) {                return false;            }        }    }    return true;}
public void metron_f7273_0(Description description)
{    description.appendText("Should contain items: ");    for (Entry<K, V> entry : map.entrySet()) {        StringBuilder sb = new StringBuilder();        sb.append("key=");        sb.append(entry.getKey());        sb.append(",value=");        sb.append(entry.getValue());        description.appendText(sb.toString());    }}
public void metron_f7274_0() throws Exception
{    String[] args = { "fixed", "-start_time", "500", "-end_time", "1000", "-base_path", "/base/path", "-base_output_path", "/base/output/path", "-ip_src_addr", "192.168.1.1", "-ip_dst_addr", "192.168.1.2", "-ip_src_port", "8081", "-ip_dst_port", "8082", "-protocol", "6", "-include_reverse", "-num_reducers", "10", "-records_per_file", "1000", "-finalizer_threads", "10" };    Map<String, String> query = new HashMap<String, String>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "192.168.1.1");            put(Constants.Fields.DST_ADDR.getName(), "192.168.1.2");            put(Constants.Fields.SRC_PORT.getName(), "8081");            put(Constants.Fields.DST_PORT.getName(), "8082");            put(Constants.Fields.PROTOCOL.getName(), "6");            put(Constants.Fields.INCLUDES_REVERSE_TRAFFIC.getName(), "true");        }    };    FixedPcapConfig config = new FixedPcapConfig(prefixStrategy);    PcapOptions.BASE_PATH.put(config, "/base/path");    PcapOptions.BASE_INTERIM_RESULT_PATH.put(config, "/base/output/path");    PcapOptions.FIELDS.put(config, query);    PcapOptions.NUM_REDUCERS.put(config, 10);    PcapOptions.START_TIME_MS.put(config, 500L);    PcapOptions.END_TIME_MS.put(config, 1000L);    PcapOptions.NUM_RECORDS_PER_FILE.put(config, 1000);    PcapOptions.PRINT_JOB_STATUS.put(config, true);    PcapOptions.FINALIZER_THREADPOOL_SIZE.put(config, "10");    when(jobRunner.submit(isA(Finalizer.class), argThat(mapContaining(config)))).thenReturn(jobRunner);    PcapCli cli = new PcapCli(jobRunner, prefixStrategy);    assertThat("Expect no errors on run", cli.run(args), equalTo(0));    verify(jobRunner).get();}
public void metron_f7275_0() throws Exception
{    String[] args = { "fixed", "-start_time", "2016-06-13-18:35.00", "-end_time", "2016-06-15-18:35.00", "-date_format", "yyyy-MM-dd-HH:mm.ss", "-base_path", "/base/path", "-base_output_path", "/base/output/path", "-ip_src_addr", "192.168.1.1", "-ip_dst_addr", "192.168.1.2", "-ip_src_port", "8081", "-ip_dst_port", "8082", "-protocol", "6", "-include_reverse", "-num_reducers", "10", "-records_per_file", "1000", "-yq", "pcap", "-finalizer_threads", "10" };    Map<String, String> query = new HashMap<String, String>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "192.168.1.1");            put(Constants.Fields.DST_ADDR.getName(), "192.168.1.2");            put(Constants.Fields.SRC_PORT.getName(), "8081");            put(Constants.Fields.DST_PORT.getName(), "8082");            put(Constants.Fields.PROTOCOL.getName(), "6");            put(Constants.Fields.INCLUDES_REVERSE_TRAFFIC.getName(), "true");        }    };    long startAsNanos = asNanos("2016-06-13-18:35.00", "yyyy-MM-dd-HH:mm.ss");    long endAsNanos = asNanos("2016-06-15-18:35.00", "yyyy-MM-dd-HH:mm.ss");    FixedPcapConfig config = new FixedPcapConfig(prefixStrategy);    PcapOptions.BASE_PATH.put(config, "/base/path");    PcapOptions.BASE_INTERIM_RESULT_PATH.put(config, "/base/output/path");    PcapOptions.FIELDS.put(config, query);    PcapOptions.NUM_REDUCERS.put(config, 10);        PcapOptions.START_TIME_MS.put(config, startAsNanos / 1000000L);        PcapOptions.END_TIME_MS.put(config, endAsNanos / 1000000L);    PcapOptions.NUM_RECORDS_PER_FILE.put(config, 1000);    PcapOptions.PRINT_JOB_STATUS.put(config, true);    PcapOptions.HADOOP_CONF.put(config, new HashMap<String, Object>() {        {            put(MRJobConfig.QUEUE_NAME, "pcap");        }    });    PcapOptions.FINALIZER_THREADPOOL_SIZE.put(config, "10");    when(jobRunner.submit(isA(Finalizer.class), argThat(mapContaining(config)))).thenReturn(jobRunner);    PcapCli cli = new PcapCli(jobRunner, prefixStrategy);    assertThat("Expect no errors on run", cli.run(args), equalTo(0));    verify(jobRunner).get();}
private long metron_f7276_0(String inDate, String format) throws ParseException
{    SimpleDateFormat sdf = new SimpleDateFormat(format);    Date date = sdf.parse(inDate);    return TimestampConverters.MILLISECONDS.toNanoseconds(date.getTime());}
private byte[] metron_f7277_0(String val)
{    return val.getBytes(StandardCharsets.UTF_8);}
public void metron_f7278_0() throws Exception
{    String[] args = { "query", "-start_time", "500", "-query", "some query string" };    String query = "some query string";    FixedPcapConfig config = new FixedPcapConfig(prefixStrategy);    PcapOptions.BASE_PATH.put(config, BASE_INPUT_PATH_DEFAULT);    PcapOptions.BASE_INTERIM_RESULT_PATH.put(config, BASE_INTERIM_RESULT_PATH_DEFAULT);    PcapOptions.FIELDS.put(config, query);    PcapOptions.NUM_REDUCERS.put(config, 10);    PcapOptions.START_TIME_MS.put(config, 500L);    PcapOptions.FINALIZER_THREADPOOL_SIZE.put(config, "1");    when(jobRunner.submit(isA(Finalizer.class), argThat(mapContaining(config)))).thenReturn(jobRunner);    PcapCli cli = new PcapCli(jobRunner, prefixStrategy);    assertThat("Expect no errors on run", cli.run(args), equalTo(0));    verify(jobRunner).get();}
public void metron_f7279_0() throws Exception
{    String[] args = { "query", "-start_time", "500", "-end_time", "1000", "-num_reducers", "10", "-base_path", "/base/path", "-base_output_path", "/base/output/path", "-query", "some query string", "-records_per_file", "1000", "-finalizer_threads", "10" };    String query = "some query string";    FixedPcapConfig config = new FixedPcapConfig(prefixStrategy);    PcapOptions.BASE_PATH.put(config, "/base/path");    PcapOptions.BASE_INTERIM_RESULT_PATH.put(config, "/base/output/path");    PcapOptions.FIELDS.put(config, query);    PcapOptions.NUM_REDUCERS.put(config, 10);        PcapOptions.START_TIME_MS.put(config, 500L);        PcapOptions.END_TIME_MS.put(config, 1000L);    PcapOptions.NUM_RECORDS_PER_FILE.put(config, 1000);    PcapOptions.PRINT_JOB_STATUS.put(config, true);    PcapOptions.FINALIZER_THREADPOOL_SIZE.put(config, "10");    when(jobRunner.submit(isA(Finalizer.class), argThat(mapContaining(config)))).thenReturn(jobRunner);    PcapCli cli = new PcapCli(jobRunner, prefixStrategy);    assertThat("Expect no errors on run", cli.run(args), equalTo(0));    verify(jobRunner).get();}
public void metron_f7280_0() throws Exception
{    String[] args = { "fixed", "-start_time", "500", "-end_time", "1000", "-num_reducers", "10", "-base_path", "/base/path", "-base_output_path", "/base/output/path", "-query", "THIS IS AN ERROR" };    assertCliError(args, "Fixed", "Unrecognized option: -query");}
public void metron_f7281_0(String[] args, String type, String optMsg) throws UnsupportedEncodingException
{    PrintStream originalOutStream = System.out;    PrintStream originalErrOutStream = System.err;    try {        ByteArrayOutputStream bos = new ByteArrayOutputStream();        PrintStream outStream = new PrintStream(new BufferedOutputStream(bos), false, StandardCharsets.UTF_8.name());        System.setOut(outStream);        ByteArrayOutputStream ebos = new ByteArrayOutputStream();        PrintStream errOutStream = new PrintStream(new BufferedOutputStream(ebos), false, StandardCharsets.UTF_8.name());        System.setErr(errOutStream);        PcapCli cli = new PcapCli(jobRunner, clock -> "random_prefix");        assertThat("Expect errors on run", cli.run(args), equalTo(-1));        assertThat("Expect missing required option error: " + ebos.toString(), ebos.toString().contains(optMsg), equalTo(true));        assertThat("Expect usage to be printed: " + bos.toString(), bos.toString().contains("usage: " + type + " filter options"), equalTo(true));    } finally {        System.setOut(originalOutStream);        System.setErr(originalErrOutStream);    }}
public void metron_f7282_0() throws Exception
{    String[] args = { "query", "-start_time", "500", "-end_time", "1000", "-num_reducers", "10", "-base_path", "/base/path", "-base_output_path", "/base/output/path", "-ip_src_addr", "THIS IS AN ERROR" };    assertCliError(args, "Query", "");}
public void metron_f7283_0() throws Exception
{    String[] args = { "fixed", "-ip_src_addr", "192.168.1.1", "-ip_dst_addr", "192.168.1.2", "-ip_src_port", "8081", "-ip_dst_port", "8082", "-protocol", "6", "-num_reducers", "10" };    assertCliError(args, "Fixed", "Missing required option: st");}
public void metron_f7284_0()
{    exception.expect(IllegalArgumentException.class);    exception.expectMessage("Expected a key but none provided");    FromKeyDeserializer deserializer = new FromKeyDeserializer(TimestampConverters.NANOSECONDS);    deserializer.deserializeKeyValue(null, null);}
public static SolrClient metron_f7285_0(Map<String, Object> globalConfig)
{    if (solrClient == null) {        synchronized (SolrClientFactory.class) {            if (solrClient == null) {                solrClient = new CloudSolrClient.Builder().withZkHost(getZkHosts(globalConfig)).build();            }        }    }    return solrClient;}
public static void metron_f7286_1()
{    synchronized (SolrClientFactory.class) {        if (solrClient != null) {            try {                solrClient.close();            } catch (IOException e) {                            } finally {                solrClient = null;            }        }    }}
protected static List<String> metron_f7287_0(Map<String, Object> globalConfig)
{    return Splitter.on(',').trimResults().splitToList((String) globalConfig.getOrDefault(SOLR_ZOOKEEPER, ""));}
public Map<String, FieldType> metron_f7288_1(List<String> indices) throws IOException
{    Map<String, FieldType> indexColumnMetadata = new HashMap<>();    Map<String, String> previousIndices = new HashMap<>();    Set<String> fieldBlackList = Sets.newHashSet(SolrDao.ROOT_FIELD, SolrDao.VERSION_FIELD);    for (String index : indices) {        try {            getIndexFields(index).forEach(field -> {                String name = (String) field.get("name");                if (!fieldBlackList.contains(name)) {                    FieldType type = toFieldType((String) field.get("type"));                    if (!indexColumnMetadata.containsKey(name)) {                        indexColumnMetadata.put(name, type);                                                previousIndices.put(name, index);                    } else {                        FieldType previousType = indexColumnMetadata.get(name);                        if (!type.equals(previousType)) {                            String previousIndexName = previousIndices.get(name);                                                        indexColumnMetadata.put(name, FieldType.OTHER);                                                        fieldBlackList.add(name);                        }                    }                }            });        } catch (SolrServerException e) {            throw new IOException(e);        } catch (SolrException e) {                        if (e.code() != 400) {                throw new IOException(e);            }        }    }    return indexColumnMetadata;}
protected List<Map<String, Object>> metron_f7289_0(String index) throws IOException, SolrServerException
{    List<Map<String, Object>> indexFields = new ArrayList<>();        LukeRequest lukeRequest = new LukeRequest();    LukeResponse lukeResponse = lukeRequest.process(client, index);    for (Entry<String, LukeResponse.FieldInfo> field : lukeResponse.getFieldInfo().entrySet()) {        Map<String, Object> fieldData = new HashMap<>();        fieldData.put("name", field.getValue().getName());        fieldData.put("type", field.getValue().getType());        indexFields.add(fieldData);    }        SchemaRepresentation schemaRepresentation = new SchemaRequest().process(client, index).getSchemaRepresentation();    indexFields.addAll(schemaRepresentation.getFields());    return indexFields;}
private FieldType metron_f7290_0(String type)
{    return solrTypeMap.getOrDefault(type, FieldType.OTHER);}
public void metron_f7291_0(AccessConfig config)
{    if (config.getKerberosEnabled()) {        enableKerberos();    }    if (this.client == null) {        this.accessConfig = config;        this.client = SolrClientFactory.create(config.getGlobalConfigSupplier().get());        this.solrSearchDao = new SolrSearchDao(this.client, this.accessConfig);        this.solrRetrieveLatestDao = new SolrRetrieveLatestDao(this.client, this.accessConfig);        this.solrUpdateDao = new SolrUpdateDao(this.client, this.solrRetrieveLatestDao, this.accessConfig);        this.solrColumnMetadataDao = new SolrColumnMetadataDao(this.client);    }}
public Optional<String> metron_f7292_0(String sensorName, Optional<String> index)
{    if (index.isPresent()) {        return index;    } else {        String realIndex = accessConfig.getIndexSupplier().apply(sensorName);        return Optional.ofNullable(realIndex);    }}
public SearchResponse metron_f7293_0(SearchRequest searchRequest) throws InvalidSearchException
{    return this.solrSearchDao.search(searchRequest);}
public GroupResponse metron_f7294_0(GroupRequest groupRequest) throws InvalidSearchException
{    return this.solrSearchDao.group(groupRequest);}
public Document metron_f7295_0(String guid, String sensorType) throws IOException
{    return this.solrRetrieveLatestDao.getLatest(guid, sensorType);}
public Iterable<Document> metron_f7296_0(List<GetRequest> getRequests) throws IOException
{    return this.solrRetrieveLatestDao.getAllLatest(getRequests);}
public Document metron_f7297_0(Document update, Optional<String> index) throws IOException
{    return this.solrUpdateDao.update(update, index);}
public Map<Document, Optional<String>> metron_f7298_0(Map<Document, Optional<String>> updates) throws IOException
{    return this.solrUpdateDao.batchUpdate(updates);}
public Document metron_f7299_0(CommentAddRemoveRequest request) throws IOException
{    return this.solrUpdateDao.addCommentToAlert(request);}
public Document metron_f7300_0(CommentAddRemoveRequest request) throws IOException
{    return this.solrUpdateDao.removeCommentFromAlert(request);}
public Document metron_f7301_0(RetrieveLatestDao retrieveLatestDao, PatchRequest request, Optional<Long> timestamp) throws OriginalNotFoundException, IOException
{    return solrUpdateDao.patch(retrieveLatestDao, request, timestamp);}
public Map<String, FieldType> metron_f7302_0(List<String> indices) throws IOException
{    return this.solrColumnMetadataDao.getColumnMetadata(indices);}
public Document metron_f7303_0(CommentAddRemoveRequest request, Document latest) throws IOException
{    return this.solrUpdateDao.addCommentToAlert(request, latest);}
public Document metron_f7304_0(CommentAddRemoveRequest request, Document latest) throws IOException
{    return this.solrUpdateDao.removeCommentFromAlert(request, latest);}
 void metron_f7305_0()
{    HttpClientUtil.addConfigurer(new Krb5HttpClientConfigurer());}
public SolrSearchDao metron_f7306_0()
{    return solrSearchDao;}
public SolrUpdateDao metron_f7307_0()
{    return solrUpdateDao;}
public void metron_f7308_0(IndexDao indexDao, Optional<String> threatSort)
{    if (indexDao instanceof MultiIndexDao) {        this.indexDao = indexDao;        MultiIndexDao multiIndexDao = (MultiIndexDao) indexDao;        for (IndexDao childDao : multiIndexDao.getIndices()) {            if (childDao instanceof SolrDao) {                this.solrDao = (SolrDao) childDao;            }        }    } else if (indexDao instanceof SolrDao) {        this.indexDao = indexDao;        this.solrDao = (SolrDao) indexDao;    } else {        throw new IllegalArgumentException("Need a SolrDao when using SolrMetaAlertDao");    }    Supplier<Map<String, Object>> globalConfigSupplier = () -> new HashMap<>();    if (metaAlertSearchDao != null && metaAlertSearchDao.solrSearchDao != null && metaAlertSearchDao.solrSearchDao.getAccessConfig() != null) {        globalConfigSupplier = metaAlertSearchDao.solrSearchDao.getAccessConfig().getGlobalConfigSupplier();    }    MetaAlertConfig config = new MetaAlertConfig(metaAlertsCollection, this.threatSort, globalConfigSupplier) {        @Override        protected String getDefaultThreatTriageField() {            return MetaAlertConstants.THREAT_FIELD_DEFAULT.replace(':', '.');        }        @Override        protected String getDefaultSourceTypeField() {            return Constants.SENSOR_TYPE;        }    };    SolrClient solrClient = SolrClientFactory.create(globalConfigSupplier.get());    this.metaAlertSearchDao = new SolrMetaAlertSearchDao(solrClient, solrDao.getSolrSearchDao(), config);    this.metaAlertRetrieveLatestDao = new SolrMetaAlertRetrieveLatestDao(solrClient, solrDao);    this.metaAlertUpdateDao = new SolrMetaAlertUpdateDao(solrClient, solrDao, metaAlertSearchDao, metaAlertRetrieveLatestDao, config);    if (threatSort.isPresent()) {        this.threatSort = threatSort.get();    }}
protected String metron_f7309_0()
{    return MetaAlertConstants.THREAT_FIELD_DEFAULT.replace(':', '.');}
protected String metron_f7310_0()
{    return Constants.SENSOR_TYPE;}
public Map<String, FieldType> metron_f7312_0(List<String> indices) throws IOException
{    return indexDao.getColumnMetadata(indices);}
public Document metron_f7313_0(String guid, String sensorType) throws IOException
{    return metaAlertRetrieveLatestDao.getLatest(guid, sensorType);}
public Iterable<Document> metron_f7314_0(List<GetRequest> getRequests) throws IOException
{    return metaAlertRetrieveLatestDao.getAllLatest(getRequests);}
public SearchResponse metron_f7315_0(SearchRequest searchRequest) throws InvalidSearchException
{    return metaAlertSearchDao.search(searchRequest);}
public GroupResponse metron_f7316_0(GroupRequest groupRequest) throws InvalidSearchException
{    return metaAlertSearchDao.group(groupRequest);}
public Document metron_f7317_0(Document update, Optional<String> index) throws IOException
{    return metaAlertUpdateDao.update(update, index);}
public Map<Document, Optional<String>> metron_f7318_0(Map<Document, Optional<String>> updates)
{    return metaAlertUpdateDao.batchUpdate(updates);}
public Document metron_f7319_0(RetrieveLatestDao retrieveLatestDao, PatchRequest request, Optional<Long> timestamp) throws OriginalNotFoundException, IOException
{    return metaAlertUpdateDao.patch(retrieveLatestDao, request, timestamp);}
public SearchResponse metron_f7320_0(String guid) throws InvalidSearchException
{    return metaAlertSearchDao.getAllMetaAlertsForAlert(guid);}
public Document metron_f7321_0(MetaAlertCreateRequest request) throws InvalidCreateException, IOException
{    return metaAlertUpdateDao.createMetaAlert(request);}
public Document metron_f7322_0(String metaAlertGuid, List<GetRequest> alertRequests) throws IOException
{    return metaAlertUpdateDao.addAlertsToMetaAlert(metaAlertGuid, alertRequests);}
public Document metron_f7323_0(String metaAlertGuid, List<GetRequest> alertRequests) throws IOException
{    return metaAlertUpdateDao.removeAlertsFromMetaAlert(metaAlertGuid, alertRequests);}
public Document metron_f7324_0(String metaAlertGuid, MetaAlertStatus status) throws IOException
{    return metaAlertUpdateDao.updateMetaAlertStatus(metaAlertGuid, status);}
public Document metron_f7325_0(CommentAddRemoveRequest request) throws IOException
{    return solrDao.addCommentToAlert(request);}
public Document metron_f7326_0(CommentAddRemoveRequest request) throws IOException
{    return solrDao.removeCommentFromAlert(request);}
public Document metron_f7327_0(CommentAddRemoveRequest request, Document latest) throws IOException
{    return solrDao.addCommentToAlert(request, latest);}
public Document metron_f7328_0(CommentAddRemoveRequest request, Document latest) throws IOException
{    return solrDao.removeCommentFromAlert(request, latest);}
public Document metron_f7329_0(String guid, String sensorType) throws IOException
{    if (MetaAlertConstants.METAALERT_TYPE.equals(sensorType)) {                        String guidClause = Constants.GUID + ":" + guid;        SolrQuery query = new SolrQuery();        query.setQuery(guidClause).setFields("*", "[child parentFilter=" + guidClause + " limit=999]");        try {            QueryResponse response = solrClient.query(METAALERTS_COLLECTION, query);                        if (response.getResults().size() == 1) {                SolrDocument result = response.getResults().get(0);                return SolrUtilities.toDocument(result);            } else {                return null;            }        } catch (SolrServerException e) {            throw new IOException("Unable to retrieve metaalert", e);        }    } else {        return solrDao.getLatest(guid, sensorType);    }}
public Iterable<Document> metron_f7330_0(List<GetRequest> getRequests) throws IOException
{    return solrDao.getAllLatest(getRequests);}
public SearchResponse metron_f7331_0(String guid) throws InvalidSearchException
{    if (guid == null || guid.trim().isEmpty()) {        throw new InvalidSearchException("Guid cannot be empty");    }                String activeClause = MetaAlertConstants.STATUS_FIELD + ":" + MetaAlertStatus.ACTIVE.getStatusString();    String guidClause = Constants.GUID + ":" + guid;    String fullClause = "{!parent which=" + activeClause + "}" + guidClause;    String metaalertTypeClause = config.getSourceTypeField() + ":" + MetaAlertConstants.METAALERT_TYPE;    SolrQuery solrQuery = new SolrQuery().setQuery(fullClause).setFields("*", "[child parentFilter=" + metaalertTypeClause + " limit=999]").addSort(Constants.GUID,     SolrQuery.ORDER.asc);        List<SearchResult> allResults = new ArrayList<>();    try {        String cursorMark = CursorMarkParams.CURSOR_MARK_START;        boolean done = false;        while (!done) {            solrQuery.set(CursorMarkParams.CURSOR_MARK_PARAM, cursorMark);            QueryResponse rsp = solrClient.query(METAALERTS_COLLECTION, solrQuery);            String nextCursorMark = rsp.getNextCursorMark();            rsp.getResults().stream().map(solrDocument -> SolrUtilities.getSearchResult(solrDocument, null, solrSearchDao.getAccessConfig().getIndexSupplier())).forEachOrdered(allResults::add);            if (cursorMark.equals(nextCursorMark)) {                done = true;            }            cursorMark = nextCursorMark;        }    } catch (IOException | SolrServerException e) {        throw new InvalidSearchException("Unable to complete search", e);    }    SearchResponse searchResponse = new SearchResponse();    searchResponse.setResults(allResults);    searchResponse.setTotal(allResults.size());    return searchResponse;}
public SearchResponse metron_f7332_1(SearchRequest searchRequest) throws InvalidSearchException
{                String activeStatusClause = MetaAlertConstants.STATUS_FIELD + ":" + MetaAlertStatus.ACTIVE.getStatusString();    String metaalertTypeClause = config.getSourceTypeField() + ":" + MetaAlertConstants.METAALERT_TYPE;                    String parentChildQuery = "(+" + activeStatusClause + " +" + "{!parent which=" + metaalertTypeClause + " v='" + searchRequest.getQuery() + "'})";                    String fullQuery = "(" + searchRequest.getQuery() + " AND -" + MetaAlertConstants.METAALERT_FIELD + ":[* TO *]" + " AND " + "-" + metaalertTypeClause + ")" + " OR " + parentChildQuery;        searchRequest.setQuery(fullQuery);        List<String> fields = searchRequest.getFields();    String fieldList = "*";    if (fields != null) {        fieldList = StringUtils.join(fields, ",");    }        SearchResponse results = solrSearchDao.search(searchRequest, fieldList);            if (fieldList.contains("*") || fieldList.contains(config.getSourceTypeField())) {        List<String> metaalertGuids = new ArrayList<>();        for (SearchResult result : results.getResults()) {            if (result.getSource().get(config.getSourceTypeField()).equals(MetaAlertConstants.METAALERT_TYPE)) {                                metaalertGuids.add(result.getId());            }        }                        if (metaalertGuids.size() > 0) {            Map<String, String> params = new HashMap<>();            params.put("fl", fieldList + ",[child parentFilter=" + metaalertTypeClause + " limit=999]");            SolrParams solrParams = new MapSolrParams(params);            try {                SolrDocumentList solrDocumentList = solrClient.getById(METAALERTS_COLLECTION, metaalertGuids, solrParams);                Map<String, Document> guidToDocuments = new HashMap<>();                for (SolrDocument doc : solrDocumentList) {                    Document document = SolrUtilities.toDocument(doc);                    guidToDocuments.put(document.getGuid(), document);                }                                for (SearchResult result : results.getResults()) {                    Document fullDoc = guidToDocuments.get(result.getId());                    if (fullDoc != null) {                        result.setSource(fullDoc.getDocument());                    }                }            } catch (SolrServerException | IOException e) {                throw new InvalidSearchException("Error when retrieving child alerts for metaalerts", e);            }        }    }    return results;}
public GroupResponse metron_f7333_1(GroupRequest groupRequest) throws InvalidSearchException
{        String sourceType = ClientUtils.escapeQueryChars(config.getSourceTypeField());    String baseQuery = groupRequest.getQuery();    String adjustedQuery = baseQuery + " -" + MetaAlertConstants.METAALERT_FIELD + ":[* TO *]" + " -" + sourceType + ":" + MetaAlertConstants.METAALERT_TYPE;        groupRequest.setQuery(adjustedQuery);    return solrSearchDao.group(groupRequest);}
public Document metron_f7334_0(MetaAlertCreateRequest request) throws InvalidCreateException, IOException
{    List<GetRequest> alertRequests = request.getAlerts();    if (request.getAlerts().isEmpty()) {        throw new InvalidCreateException("MetaAlertCreateRequest must contain alerts");    }    if (request.getGroups().isEmpty()) {        throw new InvalidCreateException("MetaAlertCreateRequest must contain UI groups");    }        Iterable<Document> alerts = getRetrieveLatestDao().getAllLatest(alertRequests);    Document metaAlert = buildCreateDocument(alerts, request.getGroups(), MetaAlertConstants.ALERT_FIELD);    MetaScores.calculateMetaScores(metaAlert, getConfig().getThreatTriageField(), getConfig().getThreatSort());        metaAlert.getDocument().put(getConfig().getSourceTypeField(), MetaAlertConstants.METAALERT_TYPE);        Map<Document, Optional<String>> updates = new HashMap<>();    updates.put(metaAlert, Optional.of(METAALERTS_COLLECTION));    try {                        Map<String, Optional<String>> guidToIndices = alertRequests.stream().collect(Collectors.toMap(GetRequest::getGuid, GetRequest::getIndex));        Map<String, String> guidToSensorTypes = alertRequests.stream().collect(Collectors.toMap(GetRequest::getGuid, GetRequest::getSensorType));        for (Document alert : alerts) {            if (addMetaAlertToAlert(metaAlert.getGuid(), alert)) {                                Optional<String> index = guidToIndices.get(alert.getGuid());                if (!index.isPresent()) {                    index = Optional.ofNullable(guidToSensorTypes.get(alert.getGuid()));                    if (!index.isPresent()) {                        throw new IllegalArgumentException("Could not find index for " + alert.getGuid());                    }                }                updates.put(alert, index);            }        }                update(updates);        solrClient.commit(METAALERTS_COLLECTION);        return metaAlert;    } catch (IOException | SolrServerException e) {        throw new InvalidCreateException("Unable to create meta alert", e);    }}
public Document metron_f7335_0(Document update, Optional<String> collection) throws IOException
{    if (MetaAlertConstants.METAALERT_TYPE.equals(update.getSensorType())) {                throw new UnsupportedOperationException("Meta alerts cannot be directly updated");    }        Map<Document, Optional<String>> updates = new HashMap<>();    updates.put(update, collection);            SearchResponse searchResponse;    try {        searchResponse = metaAlertSearchDao.getAllMetaAlertsForAlert(update.getGuid());    } catch (InvalidSearchException e) {        throw new IOException("Unable to retrieve metaalerts for alert", e);    }    ArrayList<Document> metaAlerts = new ArrayList<>();    for (SearchResult searchResult : searchResponse.getResults()) {        Document doc = new Document(searchResult.getSource(), searchResult.getId(), MetaAlertConstants.METAALERT_TYPE, 0L);        metaAlerts.add(doc);    }    for (Document metaAlert : metaAlerts) {        if (replaceAlertInMetaAlert(metaAlert, update)) {            updates.put(metaAlert, Optional.of(METAALERTS_COLLECTION));        }    }        getUpdateDao().batchUpdate(updates);    try {        solrClient.commit(METAALERTS_COLLECTION);        if (collection.isPresent()) {            solrClient.commit(collection.get());        }    } catch (SolrServerException e) {        throw new IOException("Unable to update document", e);    }    return update;}
public Document metron_f7336_0(CommentAddRemoveRequest request) throws IOException
{    return getUpdateDao().addCommentToAlert(request);}
public Document metron_f7337_0(CommentAddRemoveRequest request) throws IOException
{    return getUpdateDao().removeCommentFromAlert(request);}
public Document metron_f7338_0(CommentAddRemoveRequest request, Document latest) throws IOException
{    return getUpdateDao().addCommentToAlert(request, latest);}
public Document metron_f7339_0(CommentAddRemoveRequest request, Document latest) throws IOException
{    return getUpdateDao().removeCommentFromAlert(request, latest);}
protected boolean metron_f7340_0(Document metaAlert, Document alert)
{    boolean metaAlertUpdated = removeAlertsFromMetaAlert(metaAlert, Collections.singleton(alert.getGuid()));    if (metaAlertUpdated) {        addAlertsToMetaAlert(metaAlert, Collections.singleton(alert));    }    return metaAlertUpdated;}
public Document metron_f7341_0(String metaAlertGuid, List<GetRequest> alertRequests) throws IOException, IllegalStateException
{    Document metaAlert = getRetrieveLatestDao().getLatest(metaAlertGuid, MetaAlertConstants.METAALERT_TYPE);    if (MetaAlertStatus.ACTIVE.getStatusString().equals(metaAlert.getDocument().get(MetaAlertConstants.STATUS_FIELD))) {        Iterable<Document> alerts = getRetrieveLatestDao().getAllLatest(alertRequests);        Map<Document, Optional<String>> updates = buildAddAlertToMetaAlertUpdates(metaAlert, alerts);        update(updates);    } else {        throw new IllegalStateException("Adding alerts to an INACTIVE meta alert is not allowed");    }    try {        solrClient.commit(METAALERTS_COLLECTION);    } catch (SolrServerException e) {        throw new IOException("Unable to commit alerts to metaalert: " + metaAlertGuid, e);    }    return metaAlert;}
public Document metron_f7342_1(String guid, String sensorType) throws IOException
{    try {        Optional<String> index = SolrUtilities.getIndex(config.getIndexSupplier(), sensorType, Optional.empty());        if (!index.isPresent()) {                        return null;        }        SolrDocument solrDocument = client.getById(index.get(), guid);        if (solrDocument == null) {                        return null;        }        return SolrUtilities.toDocument(solrDocument);    } catch (SolrServerException e) {        throw new IOException(e);    }}
public Iterable<Document> metron_f7343_1(List<GetRequest> getRequests) throws IOException
{    Map<String, Collection<String>> collectionIdMap = new HashMap<>();    for (GetRequest getRequest : getRequests) {        Optional<String> index = SolrUtilities.getIndex(config.getIndexSupplier(), getRequest.getSensorType(), getRequest.getIndex());        if (index.isPresent()) {            Collection<String> ids = collectionIdMap.getOrDefault(index.get(), new HashSet<>());            ids.add(getRequest.getGuid());            collectionIdMap.put(index.get(), ids);        } else {                    }    }    try {        List<Document> documents = new ArrayList<>();        for (String collection : collectionIdMap.keySet()) {            SolrDocumentList solrDocumentList = client.getById(collectionIdMap.get(collection), new SolrQuery().set("collection", collection));            documents.addAll(solrDocumentList.stream().map(SolrUtilities::toDocument).collect(Collectors.toList()));        }        return documents;    } catch (SolrServerException e) {        throw new IOException(e);    }}
protected AccessConfig metron_f7344_0()
{    return accessConfig;}
public SearchResponse metron_f7345_0(SearchRequest searchRequest) throws InvalidSearchException
{    return search(searchRequest, null);}
public SearchResponse metron_f7346_1(SearchRequest searchRequest, String fieldList) throws InvalidSearchException
{    validateSearchRequest(searchRequest);    try {        SolrQuery query = buildSearchRequest(searchRequest, fieldList);        QueryResponse response = client.query(query);        logQueryDebugDetail(query, response);        return buildSearchResponse(searchRequest, response);    } catch (SolrException | IOException | SolrServerException e) {        String msg = e.getMessage();                throw new InvalidSearchException(msg, e);    }}
private void metron_f7347_0(SearchRequest searchRequest) throws InvalidSearchException
{    if (searchRequest.getQuery() == null) {        throw new InvalidSearchException("Search query is invalid: null");    }    if (client == null) {        throw new InvalidSearchException("Uninitialized Dao!  You must call init() prior to use.");    }    if (searchRequest.getSize() > accessConfig.getMaxSearchResults()) {        throw new InvalidSearchException("Search result size must be less than " + accessConfig.getMaxSearchResults());    }}
private void metron_f7348_1(SolrQuery query, QueryResponse response)
{    if (LOG.isDebugEnabled()) {        final String ls = System.lineSeparator();            }}
public GroupResponse metron_f7349_1(GroupRequest groupRequest) throws InvalidSearchException
{    try {        validateGroupRequest(groupRequest);        String groupNames = groupRequest.getGroups().stream().map(Group::getField).collect(Collectors.joining(","));        SolrQuery query = new SolrQuery().setStart(0).setRows(0).setQuery(groupRequest.getQuery()).setShowDebugInfo(        LOG.isDebugEnabled());        query.set("collection", getCollections(groupRequest.getIndices()));        Optional<String> scoreField = groupRequest.getScoreField();        if (scoreField.isPresent()) {            query.set("stats", true);            query.set("stats.field", String.format("{!tag=piv1 sum=true}%s", scoreField.get()));        }        query.set("facet", true);        query.set("facet.pivot", String.format("{!stats=piv1}%s", groupNames));        QueryResponse response = client.query(query);        logQueryDebugDetail(query, response);        return buildGroupResponse(groupRequest, response);    } catch (IOException | SolrServerException e) {        String msg = e.getMessage();                throw new InvalidSearchException(msg, e);    }}
private void metron_f7350_0(GroupRequest groupRequest) throws InvalidSearchException
{    if (groupRequest.getGroups() == null || groupRequest.getGroups().size() == 0) {        throw new InvalidSearchException("At least 1 group must be provided.");    }}
protected SolrQuery metron_f7351_0(SearchRequest searchRequest, String fieldList) throws IOException, SolrServerException
{    SolrQuery query = new SolrQuery().setStart(searchRequest.getFrom()).setRows(searchRequest.getSize()).setQuery(searchRequest.getQuery()).setShowDebugInfo(    LOG.isDebugEnabled());        for (SortField sortField : searchRequest.getSort()) {        query.addSort(sortField.getField(), getSolrSortOrder(sortField.getSortOrder()));    }        List<String> fields = searchRequest.getFields();    if (fieldList == null) {        fieldList = "*";        if (fields != null) {            fieldList = StringUtils.join(fields, ",");        }    }    query.set("fl", fieldList);        List<String> facetFields = searchRequest.getFacetFields();    if (facetFields != null) {        facetFields.forEach(query::addFacetField);    }    query.set("collection", getCollections(searchRequest.getIndices()));    return query;}
private String metron_f7352_0(List<String> indices) throws IOException, SolrServerException
{    List<String> existingCollections = CollectionAdminRequest.listCollections(client);    return indices.stream().filter(existingCollections::contains).collect(Collectors.joining(","));}
private SolrQuery.ORDER metron_f7353_0(SortOrder sortOrder)
{    return sortOrder == SortOrder.DESC ? ORDER.desc : ORDER.asc;}
protected Map<String, Map<String, Long>> metron_f7355_0(List<String> fields, QueryResponse solrResponse)
{    Map<String, Map<String, Long>> fieldCounts = new HashMap<>();    for (String field : fields) {        Map<String, Long> valueCounts = new HashMap<>();        FacetField facetField = solrResponse.getFacetField(field);        for (Count facetCount : facetField.getValues()) {            valueCounts.put(facetCount.getName(), facetCount.getCount());        }        fieldCounts.put(field, valueCounts);    }    return fieldCounts;}
protected GroupResponse metron_f7356_0(GroupRequest groupRequest, QueryResponse response)
{    String groupNames = groupRequest.getGroups().stream().map(Group::getField).collect(Collectors.joining(","));    List<PivotField> pivotFields = response.getFacetPivot().get(groupNames);    GroupResponse groupResponse = new GroupResponse();    groupResponse.setGroupedBy(groupRequest.getGroups().get(0).getField());    groupResponse.setGroupResults(getGroupResults(groupRequest, 0, pivotFields));    return groupResponse;}
protected List<GroupResult> metron_f7357_0(GroupRequest groupRequest, int index, List<PivotField> pivotFields)
{    List<Group> groups = groupRequest.getGroups();    List<GroupResult> searchResultGroups = new ArrayList<>();    final GroupOrder groupOrder = groups.get(index).getOrder();    pivotFields.sort((o1, o2) -> {        String s1 = groupOrder.getGroupOrderType() == GroupOrderType.TERM ? o1.getValue().toString() : Integer.toString(o1.getCount());        String s2 = groupOrder.getGroupOrderType() == GroupOrderType.TERM ? o2.getValue().toString() : Integer.toString(o2.getCount());        if (groupOrder.getSortOrder() == SortOrder.ASC) {            return s1.compareTo(s2);        } else {            return s2.compareTo(s1);        }    });    for (PivotField pivotField : pivotFields) {        GroupResult groupResult = new GroupResult();        groupResult.setKey(pivotField.getValue().toString());        groupResult.setTotal(pivotField.getCount());        Optional<String> scoreField = groupRequest.getScoreField();        if (scoreField.isPresent()) {            groupResult.setScore((Double) pivotField.getFieldStatsInfo().get(scoreField.get()).getSum());        }        if (index < groups.size() - 1) {            groupResult.setGroupedBy(groups.get(index + 1).getField());            groupResult.setGroupResults(getGroupResults(groupRequest, index + 1, pivotField.getPivot()));        }        searchResultGroups.add(groupResult);    }    return searchResultGroups;}
public Document metron_f7358_0(Document update, Optional<String> rawIndex) throws IOException
{    Document newVersion = update;        Object commentsObj = update.getDocument().get(COMMENTS_FIELD);    if (commentsObj instanceof List && ((List<Object>) commentsObj).size() > 0 && ((List<Object>) commentsObj).get(0) instanceof Map) {        newVersion = new Document(update);        convertCommentsToRaw(newVersion.getDocument());    }    try {        SolrInputDocument solrInputDocument = SolrUtilities.toSolrInputDocument(newVersion);        Optional<String> index = SolrUtilities.getIndex(config.getIndexSupplier(), newVersion.getSensorType(), rawIndex);        if (index.isPresent()) {            this.client.add(index.get(), solrInputDocument);            this.client.commit(index.get());        } else {            throw new IllegalStateException("Index must be specified or inferred.");        }    } catch (SolrServerException e) {        throw new IOException(e);    }    return newVersion;}
public Map<Document, Optional<String>> metron_f7359_0(Map<Document, Optional<String>> updates) throws IOException
{        Map<String, Collection<SolrInputDocument>> solrCollectionUpdates = new HashMap<>();    Set<String> collectionsUpdated = new HashSet<>();    for (Entry<Document, Optional<String>> entry : updates.entrySet()) {        SolrInputDocument solrInputDocument = SolrUtilities.toSolrInputDocument(entry.getKey());        Optional<String> index = SolrUtilities.getIndex(config.getIndexSupplier(), entry.getKey().getSensorType(), entry.getValue());        if (index.isPresent()) {            Collection<SolrInputDocument> solrInputDocuments = solrCollectionUpdates.getOrDefault(index.get(), new ArrayList<>());            solrInputDocuments.add(solrInputDocument);            solrCollectionUpdates.put(index.get(), solrInputDocuments);            collectionsUpdated.add(index.get());        } else {            String lookupIndex = config.getIndexSupplier().apply(entry.getKey().getSensorType());            Collection<SolrInputDocument> solrInputDocuments = solrCollectionUpdates.getOrDefault(lookupIndex, new ArrayList<>());            solrInputDocuments.add(solrInputDocument);            solrCollectionUpdates.put(lookupIndex, solrInputDocuments);            collectionsUpdated.add(lookupIndex);        }    }    try {        for (Entry<String, Collection<SolrInputDocument>> entry : solrCollectionUpdates.entrySet()) {            this.client.add(entry.getKey(), entry.getValue());        }        for (String collection : collectionsUpdated) {            this.client.commit(collection);        }    } catch (SolrServerException e) {        throw new IOException(e);    }    return updates;}
public Document metron_f7360_0(CommentAddRemoveRequest request) throws IOException
{    Document latest = retrieveLatestDao.getLatest(request.getGuid(), request.getSensorType());    return addCommentToAlert(request, latest);}
public Document metron_f7361_0(CommentAddRemoveRequest request, Document latest) throws IOException
{    if (latest == null || latest.getDocument() == null) {        throw new IOException(String.format("Unable to add comment. Document with guid %s cannot be found.", request.getGuid()));    }    @SuppressWarnings("unchecked")    List<Map<String, Object>> comments = (List<Map<String, Object>>) latest.getDocument().getOrDefault(COMMENTS_FIELD, new ArrayList<>());    List<Map<String, Object>> originalComments = new ArrayList<>(comments);        List<String> commentStrs = new ArrayList<>();    for (Map<String, Object> comment : originalComments) {        commentStrs.add(new AlertComment(comment).asJson());    }    commentStrs.add(new AlertComment(request.getComment(), request.getUsername(), request.getTimestamp()).asJson());    Document newVersion = new Document(latest);    newVersion.getDocument().put(COMMENTS_FIELD, commentStrs);    return update(newVersion, Optional.empty());}
public Document metron_f7362_0(CommentAddRemoveRequest request) throws IOException
{    Document latest = retrieveLatestDao.getLatest(request.getGuid(), request.getSensorType());    return removeCommentFromAlert(request, latest);}
public Document metron_f7363_0(CommentAddRemoveRequest request, Document latest) throws IOException
{    if (latest == null || latest.getDocument() == null) {        throw new IOException(String.format("Unable to remove comment. Document with guid %s cannot be found.", request.getGuid()));    }    @SuppressWarnings("unchecked")    List<Map<String, Object>> commentMap = (List<Map<String, Object>>) latest.getDocument().get(COMMENTS_FIELD);        if (commentMap == null) {        throw new IOException(String.format("Unable to remove comment. Document with guid %s has no comments.", request.getGuid()));    }    List<Map<String, Object>> originalComments = new ArrayList<>(commentMap);    List<AlertComment> comments = new ArrayList<>();    for (Map<String, Object> commentStr : originalComments) {        comments.add(new AlertComment(commentStr));    }    comments.remove(new AlertComment(request.getComment(), request.getUsername(), request.getTimestamp()));    List<String> commentsAsJson = comments.stream().map(AlertComment::asJson).collect(Collectors.toList());    Document newVersion = new Document(latest);    newVersion.getDocument().put(COMMENTS_FIELD, commentsAsJson);    return update(newVersion, Optional.empty());}
public void metron_f7364_0(Map<String, Object> source)
{    @SuppressWarnings("unchecked")    List<Map<String, Object>> comments = (List<Map<String, Object>>) source.get(COMMENTS_FIELD);    if (comments == null || comments.isEmpty()) {        return;    }    List<String> asJson = new ArrayList<>();    for (Map<String, Object> comment : comments) {        asJson.add((new AlertComment(comment)).asJson());    }    source.put(COMMENTS_FIELD, asJson);}
public static SearchResult metron_f7365_0(SolrDocument solrDocument, List<String> fields, Function<String, String> indexSupplier)
{    SearchResult searchResult = new SearchResult();    searchResult.setId((String) solrDocument.getFieldValue(Constants.GUID));    searchResult.setIndex(indexSupplier.apply((String) solrDocument.getFieldValue(Constants.SENSOR_TYPE)));    Map<String, Object> docSource = toDocument(solrDocument).getDocument();    final Map<String, Object> source = new HashMap<>();    if (fields != null) {        fields.forEach(field -> source.put(field, docSource.get(field)));    } else {        source.putAll(docSource);    }    searchResult.setSource(source);    return searchResult;}
public static Document metron_f7366_0(SolrDocument solrDocument)
{    Map<String, Object> document = new HashMap<>();    solrDocument.getFieldNames().stream().filter(name -> !name.equals(SolrDao.VERSION_FIELD)).forEach(name -> document.put(name, solrDocument.getFieldValue(name)));    reformatComments(solrDocument, document);    insertChildAlerts(solrDocument, document);    return new Document(document, (String) solrDocument.getFieldValue(Constants.GUID), (String) solrDocument.getFieldValue(Constants.SENSOR_TYPE), (Long) solrDocument.getFieldValue(Constants.Fields.TIMESTAMP.getName()));}
protected static void metron_f7367_0(SolrDocument solrDocument, Map<String, Object> document)
{        @SuppressWarnings("unchecked")    List<String> commentStrs = (List<String>) solrDocument.get(COMMENTS_FIELD);    if (commentStrs != null) {        try {            List<AlertComment> comments = new ArrayList<>();            for (String commentStr : commentStrs) {                comments.add(new AlertComment(commentStr));            }            document.put(COMMENTS_FIELD, comments.stream().map(AlertComment::asMap).collect(Collectors.toList()));        } catch (ParseException e) {            throw new IllegalStateException("Unable to parse comment", e);        }    }}
protected static void metron_f7368_0(SolrDocument solrDocument, Map<String, Object> document)
{        if (solrDocument.hasChildDocuments() && solrDocument.getFieldValue(Constants.SENSOR_TYPE).equals(MetaAlertConstants.METAALERT_TYPE)) {        List<Map<String, Object>> childDocuments = new ArrayList<>();        for (SolrDocument childDoc : solrDocument.getChildDocuments()) {            Map<String, Object> childDocMap = new HashMap<>();            childDoc.getFieldNames().stream().filter(name -> !name.equals(SolrDao.VERSION_FIELD)).forEach(name -> childDocMap.put(name, childDoc.getFieldValue(name)));            childDocuments.add(childDocMap);        }        document.put(MetaAlertConstants.ALERT_FIELD, childDocuments);    }}
public static SolrInputDocument metron_f7369_0(Document document)
{    SolrInputDocument solrInputDocument = new SolrInputDocument();    for (Map.Entry<String, Object> field : document.getDocument().entrySet()) {        if (field.getKey().equals(MetaAlertConstants.ALERT_FIELD)) {                        List<Map<String, Object>> alerts = (List<Map<String, Object>>) field.getValue();            for (Map<String, Object> alert : alerts) {                SolrInputDocument childDocument = new SolrInputDocument();                for (Map.Entry<String, Object> alertField : alert.entrySet()) {                    childDocument.addField(alertField.getKey(), alertField.getValue());                }                solrInputDocument.addChildDocument(childDocument);            }        } else {            solrInputDocument.addField(field.getKey(), field.getValue());        }    }    return solrInputDocument;}
public static Optional<String> metron_f7370_0(Function<String, String> indexSupplier, String sensorName, Optional<String> index)
{    if (index.isPresent()) {        return index;    } else {        String realIndex = indexSupplier.apply(sensorName);        return Optional.ofNullable(realIndex);    }}
public String metron_f7371_0()
{    return name;}
public FieldType metron_f7372_0()
{    this.sortMissingLast = true;    return this;}
public FieldType metron_f7373_0()
{    this.docValues = true;    return this;}
public FieldType metron_f7374_0()
{    this.multiValued = true;    return this;}
public FieldType metron_f7375_0()
{    this.indexed = true;    return this;}
public FieldType metron_f7376_0()
{    this.stored = true;    return this;}
public String metron_f7377_0()
{    return String.format("<fieldType name=\"%s\" " + "stored=\"%s\" " + "indexed=\"%s\" " + "multiValued=\"%s\" " + "class=\"%s\" " + "sortMissingLast=\"%s\" " + "docValues=\"%s\"" + "/>", name, stored + "", indexed + "", multiValued + "", solrClass + "", sortMissingLast + "", docValues + "");}
public String metron_f7378_0()
{    return solrType.toString();}
public static SolrFields metron_f7379_0(String type)
{    for (SolrFields f : values()) {        if (f.elasticsearchTypes.contains(type)) {            return f;        }    }    return null;}
public static void metron_f7380_0(PrintWriter pw)
{    for (SolrFields f : values()) {        pw.println(TAB + f.getTypeDeclaration());    }}
public static String metron_f7381_0(String fieldName)
{    return fieldName.replace(':', '.');}
public static void metron_f7382_0(PrintWriter pw, Map<String, Object> properties)
{    for (Map.Entry<String, Object> property : properties.entrySet()) {        String fieldName = normalizeField(property.getKey());        System.out.println("Processing property: " + fieldName);        if (fieldName.equals("guid")) {            pw.println(TAB + "<field name=\"guid\" type=\"" + SolrFields.STRING.solrType.getName() + "\" indexed=\"true\" stored=\"true\" required=\"true\" multiValued=\"false\" />");        } else {            String type = (String) ((Map<String, Object>) property.getValue()).get("type");            SolrFields solrField = SolrFields.byElasticsearchType(type);            if (solrField == null) {                System.out.println("Skipping " + fieldName + " because I can't find solr type for " + type);                continue;            }            pw.println(TAB + String.format("<field name=\"%s\" type=\"%s\" indexed=\"true\" stored=\"true\" />", fieldName, solrField.solrType.getName()));        }    }}
public static void metron_f7383_0(PrintWriter pw, List<Map<String, Object>> properties)
{    for (Map<String, Object> dynamicProperty : properties) {        for (Map.Entry<String, Object> dynamicFieldDef : dynamicProperty.entrySet()) {            System.out.println("Processing dynamic property: " + dynamicFieldDef.getKey());            Map<String, Object> def = (Map<String, Object>) dynamicFieldDef.getValue();            String match = (String) def.get("match");            if (match == null) {                match = (String) def.get("path_match");            }            match = normalizeField(match);            String type = (String) ((Map<String, Object>) def.get("mapping")).get("type");            SolrFields solrField = SolrFields.byElasticsearchType(type);            if (solrField == null) {                System.out.println("Skipping " + match + " because I can't find solr type for " + type);                continue;            }            if (solrField == null) {                throw new IllegalStateException("Unable to find associated solr type for " + type + " with dynamic property " + solrField);            }            pw.println(TAB + String.format("<dynamicField name=\"%s\" type=\"%s\" multiValued=\"false\" docValues=\"true\"/>", match, solrField.solrType.getName()));        }    }}
public static void metron_f7384_0(PrintWriter pw, Map<String, Object> template)
{    pw.println(PREAMBLE);    System.out.println("Processing " + template.getOrDefault(TEMPLATE_KEY, "unknown template"));    Map<String, Object> mappings = (Map<String, Object>) template.getOrDefault("mappings", new HashMap<>());    if (mappings.size() != 1) {        System.err.println("Unable to process mappings. We expect exactly 1 mapping, there are " + mappings.size() + " mappings specified");    }    String docName = Iterables.getFirst(mappings.keySet(), null);    pw.println(String.format(SCHEMA_FORMAT, docName));    pw.println(TAB + VERSION_FIELD);    pw.println(TAB + ROOT_FIELD);    for (Map.Entry<String, Object> docTypeToMapping : mappings.entrySet()) {        System.out.println("Processing " + docTypeToMapping.getKey() + " doc type");        Map<String, Object> actualMappings = (Map<String, Object>) docTypeToMapping.getValue();        Map<String, Object> properties = (Map<String, Object>) actualMappings.getOrDefault(PROPERTIES_KEY, new HashMap<>());        processProperties(pw, properties);        List<Map<String, Object>> dynamicMappings = (List<Map<String, Object>>) actualMappings.getOrDefault(DYNAMIC_TEMPLATES_KEY, new ArrayList<>());        processDynamicMappings(pw, dynamicMappings);        pw.println(TAB + DYNAMIC_FIELD_CATCHALL);        pw.println(TAB + UNIQUE_KEY);        SolrFields.printTypes(pw);    }    pw.println("</schema>");    pw.flush();}
public static void metron_f7385_0(String... argv) throws IOException
{    String templateFile = argv[0];    String schemaFile = argv[1];    Map<String, Object> template = JSONUtils.INSTANCE.load(new File(templateFile), JSONUtils.MAP_SUPPLIER);    try (PrintWriter pw = new PrintWriter(new File(schemaFile), StandardCharsets.UTF_8.name())) {        translate(pw, template);    }}
public static SolrParams metron_f7386_0(Map<String, Object> config)
{    if (config == null || config.isEmpty()) {        return null;    }    ModifiableSolrParams ret = new ModifiableSolrParams();    for (Map.Entry<String, Object> kv : config.entrySet()) {        Object v = kv.getValue();        if (v instanceof Boolean) {            ret.set(kv.getKey(), (Boolean) v);        } else if (v instanceof Integer) {            ret.set(kv.getKey(), (Integer) v);        } else if (v instanceof Iterable) {            Iterable vals = (Iterable) v;            String[] strVals = new String[Iterables.size(vals)];            int i = 0;            for (Object o : (Iterable) v) {                strVals[i++] = o.toString();            }        }    }    return ret;}
public void metron_f7387_0(String name, int numShards, int replicationFactor) throws IOException, SolrServerException
{    if (!listCollections().contains(name)) {        request(getCreateCollectionsRequest(name, numShards, replicationFactor));    }}
public QueryRequest metron_f7388_0(String name, int numShards, int replicationFactor)
{    ModifiableSolrParams params = new ModifiableSolrParams();    params.set(SolrConstants.REQUEST_ACTION, CollectionParams.CollectionAction.CREATE.name());    params.set(SolrConstants.REQUEST_NAME, name);    params.set(SolrConstants.REQUEST_NUM_SHARDS, numShards);    params.set(SolrConstants.REQUEST_REPLICATION_FACTOR, replicationFactor);    params.set(SolrConstants.REQUEST_COLLECTION_CONFIG_NAME, name);    QueryRequest request = new QueryRequest(params);    request.setPath(SolrConstants.REQUEST_COLLECTIONS_PATH);    return request;}
public List<String> metron_f7389_0() throws IOException, SolrServerException
{    NamedList<Object> response = request(getListCollectionsRequest(), null);    return (List<String>) response.get(SolrConstants.RESPONSE_COLLECTIONS);}
public QueryRequest metron_f7390_0()
{    ModifiableSolrParams params = new ModifiableSolrParams();    params.set(SolrConstants.REQUEST_ACTION, CollectionParams.CollectionAction.LIST.name());    QueryRequest request = new QueryRequest(params);    request.setPath(SolrConstants.REQUEST_COLLECTIONS_PATH);    return request;}
public Optional<T> metron_f7391_1(Map<String, Object> globalConfig, Class<T> clazz)
{    Object val = globalConfig.get(name);    if (val != null) {        T ret = null;        try {            ret = ConversionUtils.convert(val, clazz);        } catch (ClassCastException cce) {            ret = null;        }        if (ret == null) {                                    if (defaultValue.isPresent()) {                return Optional.ofNullable(ConversionUtils.convert(defaultValue.get(), clazz));            } else {                return Optional.empty();            }        } else {            return Optional.ofNullable(ret);        }    } else {        if (defaultValue.isPresent()) {            return Optional.ofNullable(ConversionUtils.convert(defaultValue.get(), clazz));        } else {            return Optional.empty();        }    }}
public Supplier<IllegalArgumentException> metron_f7392_0(Map<String, Object> globalConfig)
{    String message = "Unable to retrieve " + name + " from global config, value associated is " + globalConfig.get(name);    return () -> new IllegalArgumentException(message);}
public T metron_f7393_0(Map<String, Object> globalConfig, Class<T> clazz)
{    return this.coerceOrDefault(globalConfig, clazz).orElseThrow(this.errorOut(globalConfig));}
public SolrWriter metron_f7394_0(MetronSolrClient solr)
{    this.solr = solr;    return this;}
public void metron_f7395_0(Map<String, Object> globalConfiguration)
{    zookeeperUrl = SolrProperties.ZOOKEEPER_QUORUM.coerceOrDefaultOrExcept(globalConfiguration, String.class);    defaultCollection = SolrProperties.DEFAULT_COLLECTION.coerceOrDefaultOrExcept(globalConfiguration, String.class);    solrHttpConfig = SolrProperties.HTTP_CONFIG.coerceOrDefaultOrExcept(globalConfiguration, Map.class);    shouldCommit = SolrProperties.COMMIT_PER_BATCH.coerceOrDefaultOrExcept(globalConfiguration, Boolean.class);    softCommit = SolrProperties.COMMIT_SOFT.coerceOrDefaultOrExcept(globalConfiguration, Boolean.class);    waitSearcher = SolrProperties.COMMIT_WAIT_SEARCHER.coerceOrDefaultOrExcept(globalConfiguration, Boolean.class);    waitFlush = SolrProperties.COMMIT_WAIT_FLUSH.coerceOrDefaultOrExcept(globalConfiguration, Boolean.class);}
public void metron_f7396_1(Map stormConf, WriterConfiguration configurations) throws IOException, SolrServerException
{    Map<String, Object> globalConfiguration = configurations.getGlobalConfig();    initializeFromGlobalConfig(globalConfiguration);                            if (solr == null) {        if (isKerberosEnabled(stormConf)) {            HttpClientUtil.addConfigurer(new Krb5HttpClientConfigurer());        }        solr = new MetronSolrClient(zookeeperUrl, solrHttpConfig);    }    solr.setDefaultCollection(defaultCollection);}
public Collection<SolrInputDocument> metron_f7397_0(Iterable<BulkMessage<JSONObject>> messages)
{    Collection<SolrInputDocument> ret = new ArrayList<>();    for (BulkMessage<JSONObject> bulkWriterMessage : messages) {        SolrInputDocument document = new SolrInputDocument();        JSONObject message = bulkWriterMessage.getMessage();        for (Object key : message.keySet()) {            Object value = message.get(key);            if (value instanceof Iterable) {                for (Object v : (Iterable) value) {                    document.addField("" + key, v);                }            } else {                document.addField("" + key, value);            }        }        if (!document.containsKey(Constants.GUID)) {            document.addField(Constants.GUID, UUID.randomUUID().toString());        }        ret.add(document);    }    return ret;}
protected String metron_f7398_0(String sourceType, WriterConfiguration configurations)
{    String collection = configurations.getIndex(sourceType);    if (StringUtils.isEmpty(collection)) {        return solr.getDefaultCollection();    }    return collection;}
public BulkWriterResponse metron_f7399_0(String sourceType, WriterConfiguration configurations, List<BulkMessage<JSONObject>> messages) throws Exception
{    String collection = getCollection(sourceType, configurations);    BulkWriterResponse bulkResponse = new BulkWriterResponse();    Collection<SolrInputDocument> docs = toDocs(messages);    Set<MessageId> ids = messages.stream().map(BulkMessage::getId).collect(Collectors.toSet());    try {        Optional<SolrException> exceptionOptional = fromUpdateResponse(solr.add(collection, docs));                if (exceptionOptional.isPresent()) {            bulkResponse.addAllErrors(exceptionOptional.get(), ids);        } else {            if (shouldCommit) {                exceptionOptional = fromUpdateResponse(solr.commit(collection, waitFlush, waitSearcher, softCommit));                if (exceptionOptional.isPresent()) {                    bulkResponse.addAllErrors(exceptionOptional.get(), ids);                }            }            if (!exceptionOptional.isPresent()) {                bulkResponse.addAllSuccesses(ids);            }        }    } catch (HttpSolrClient.RemoteSolrException sse) {        bulkResponse.addAllErrors(sse, ids);    }    return bulkResponse;}
protected Optional<SolrException> metron_f7400_0(UpdateResponse response)
{    if (response != null && response.getStatus() > 0) {        String message = "Solr Update response: " + Joiner.on(",").join(response.getResponse());        return Optional.of(new SolrException(SolrException.ErrorCode.BAD_REQUEST, message));    }    return Optional.empty();}
public String metron_f7401_0()
{    return SOLR_WRITER_NAME;}
public void metron_f7402_0() throws Exception
{    if (solr != null) {        solr.close();    }}
private boolean metron_f7403_0(Map stormConfig)
{    if (stormConfig == null) {        return false;    }    String value = (String) stormConfig.get(JAVA_SECURITY_CONFIG_PROPERTY);    return value != null && !value.isEmpty();}
public static Configurations metron_f7404_0() throws IOException
{    Configurations configurations = new Configurations();    configurations.updateGlobalConfig(ConfigurationsUtils.readGlobalConfigFromFile("../" + TestConstants.SAMPLE_CONFIG_PATH));    return configurations;}
public static ParserConfigurations metron_f7405_0() throws IOException
{    ParserConfigurations configurations = new ParserConfigurations();    configurations.updateGlobalConfig(ConfigurationsUtils.readGlobalConfigFromFile(TestConstants.SAMPLE_CONFIG_PATH));    Map<String, byte[]> sensorParserConfigs = ConfigurationsUtils.readSensorParserConfigsFromFile(TestConstants.PARSER_CONFIGS_PATH);    for (String sensorType : sensorParserConfigs.keySet()) {        configurations.updateSensorParserConfig(sensorType, sensorParserConfigs.get(sensorType));    }    return configurations;}
public static EnrichmentConfigurations metron_f7406_0() throws IOException
{    EnrichmentConfigurations configurations = new EnrichmentConfigurations();    configurations.updateGlobalConfig(ConfigurationsUtils.readGlobalConfigFromFile(TestConstants.SAMPLE_CONFIG_PATH));    Map<String, byte[]> sensorEnrichmentConfigs = ConfigurationsUtils.readSensorEnrichmentConfigsFromFile(TestConstants.SAMPLE_CONFIG_PATH);    for (String sensorType : sensorEnrichmentConfigs.keySet()) {        configurations.updateSensorEnrichmentConfig(sensorType, sensorEnrichmentConfigs.get(sensorType));    }    return configurations;}
public static IndexingConfigurations metron_f7407_0() throws IOException
{    IndexingConfigurations configurations = new IndexingConfigurations();    configurations.updateGlobalConfig(ConfigurationsUtils.readGlobalConfigFromFile("../" + TestConstants.SAMPLE_CONFIG_PATH));    Map<String, byte[]> sensorIndexingConfigs = ConfigurationsUtils.readSensorIndexingConfigsFromFile("../" + TestConstants.SAMPLE_CONFIG_PATH);    for (String sensorType : sensorIndexingConfigs.keySet()) {        configurations.updateSensorIndexingConfig(sensorType, sensorIndexingConfigs.get(sensorType));    }    return configurations;}
public void metron_f7408_0()
{    Map<String, Object> globalConfig = new HashMap<String, Object>() {        {            put(SOLR_ZOOKEEPER, "   zookeeper:2181   ");        }    };    List<String> actual = SolrClientFactory.getZkHosts(globalConfig);    List<String> expected = new ArrayList<>();    expected.add("zookeeper:2181");    assertEquals(expected, actual);}
public void metron_f7409_0()
{    Map<String, Object> globalConfig = new HashMap<String, Object>() {        {            put(SOLR_ZOOKEEPER, "   zookeeper:2181    ,   zookeeper2:2181    ");        }    };    List<String> actual = SolrClientFactory.getZkHosts(globalConfig);    List<String> expected = new ArrayList<>();    expected.add("zookeeper:2181");    expected.add("zookeeper2:2181");    assertEquals(expected, actual);}
public void metron_f7410_0() throws Exception
{    solrColumnMetadataDao = new SolrColumnMetadataDao(null);}
public void metron_f7411_0() throws Exception
{    List<Map<String, Object>> broFields = new ArrayList<>();    broFields.add(new HashMap<String, Object>() {        {            put("name", "string");            put("type", "string");        }    });    broFields.add(new HashMap<String, Object>() {        {            put("name", "int");            put("type", "pint");        }    });    broFields.add(new HashMap<String, Object>() {        {            put("name", "float");            put("type", "pfloat");        }    });    broFields.add(new HashMap<String, Object>() {        {            put("name", "double");            put("type", "pdouble");        }    });    broFields.add(new HashMap<String, Object>() {        {            put("name", "boolean");            put("type", "boolean");        }    });    broFields.add(new HashMap<String, Object>() {        {            put("name", "broField");            put("type", "string");        }    });    broFields.add(new HashMap<String, Object>() {        {            put("name", "conflict");            put("type", "string");        }    });    List<Map<String, Object>> snortFields = new ArrayList<>();    snortFields.add(new HashMap<String, Object>() {        {            put("name", "long");            put("type", "plong");        }    });    snortFields.add(new HashMap<String, Object>() {        {            put("name", "snortField");            put("type", "plong");        }    });    snortFields.add(new HashMap<String, Object>() {        {            put("name", "unknown");            put("type", "unknown");        }    });    broFields.add(new HashMap<String, Object>() {        {            put("name", "conflict");            put("type", "plong");        }    });    solrColumnMetadataDao = spy(new SolrColumnMetadataDao(null));    doReturn(broFields).when(solrColumnMetadataDao).getIndexFields("bro");    doReturn(snortFields).when(solrColumnMetadataDao).getIndexFields("snort");    Map<String, FieldType> columnMetadata = solrColumnMetadataDao.getColumnMetadata(Arrays.asList("bro", "snort"));    assertEquals(FieldType.BOOLEAN, columnMetadata.get("boolean"));    assertEquals(FieldType.TEXT, columnMetadata.get("string"));    assertEquals(FieldType.TEXT, columnMetadata.get("broField"));    assertEquals(FieldType.DOUBLE, columnMetadata.get("double"));    assertEquals(FieldType.LONG, columnMetadata.get("long"));    assertEquals(FieldType.FLOAT, columnMetadata.get("float"));    assertEquals(FieldType.INTEGER, columnMetadata.get("int"));    assertEquals(FieldType.LONG, columnMetadata.get("snortField"));    assertEquals(FieldType.OTHER, columnMetadata.get("conflict"));    assertEquals(FieldType.OTHER, columnMetadata.get("unknown"));}
public void metron_f7412_0() throws Exception
{    exception.expect(IOException.class);    exception.expectMessage("solr exception");    solrColumnMetadataDao = spy(new SolrColumnMetadataDao(null));    doThrow(new SolrServerException("solr exception")).when(solrColumnMetadataDao).getIndexFields("bro");    solrColumnMetadataDao.getColumnMetadata(Arrays.asList("bro", "snort"));}
public void metron_f7413_0() throws Exception
{    solrColumnMetadataDao = spy(new SolrColumnMetadataDao(null));    SolrException solrException = new SolrException(SolrException.ErrorCode.BAD_REQUEST, "solr exception");    doThrow(solrException).when(solrColumnMetadataDao).getIndexFields("bro");    Map<String, FieldType> columnMetadata = solrColumnMetadataDao.getColumnMetadata(Collections.singletonList("bro"));    assertNotNull(columnMetadata);}
public void metron_f7414_0()
{    client = mock(SolrClient.class);    solrSearchDao = mock(SolrSearchDao.class);    solrUpdateDao = mock(SolrUpdateDao.class);    solrRetrieveLatestDao = mock(SolrRetrieveLatestDao.class);    solrColumnMetadataDao = mock(SolrColumnMetadataDao.class);    mockStatic(SolrClientFactory.class);}
public void metron_f7415_0()
{    AccessConfig accessConfig = new AccessConfig();    solrDao = spy(new SolrDao(client, accessConfig, solrSearchDao, solrUpdateDao, solrRetrieveLatestDao, solrColumnMetadataDao));    doNothing().when(solrDao).enableKerberos();    solrDao.init(accessConfig);    verify(solrDao, times(0)).enableKerberos();    accessConfig.setKerberosEnabled(true);    solrDao.init(accessConfig);    verify(solrDao).enableKerberos();}
public void metron_f7416_0() throws Exception
{    AccessConfig accessConfig = new AccessConfig();    accessConfig.setGlobalConfigSupplier(() -> new HashMap<String, Object>() {        {            put(SOLR_ZOOKEEPER, "zookeeper:2181");        }    });    solrDao = spy(new SolrDao());    when(SolrClientFactory.create(accessConfig.getGlobalConfigSupplier().get())).thenReturn(client);    whenNew(SolrSearchDao.class).withArguments(client, accessConfig).thenReturn(solrSearchDao);    whenNew(SolrRetrieveLatestDao.class).withArguments(client, accessConfig).thenReturn(solrRetrieveLatestDao);    whenNew(SolrUpdateDao.class).withArguments(client, solrRetrieveLatestDao, accessConfig).thenReturn(solrUpdateDao);    whenNew(SolrColumnMetadataDao.class).withArguments(client).thenReturn(solrColumnMetadataDao);    solrDao.init(accessConfig);    SearchRequest searchRequest = mock(SearchRequest.class);    solrDao.search(searchRequest);    verify(solrSearchDao).search(searchRequest);    GroupRequest groupRequest = mock(GroupRequest.class);    solrDao.group(groupRequest);    verify(solrSearchDao).group(groupRequest);    solrDao.getLatest("guid", "collection");    verify(solrRetrieveLatestDao).getLatest("guid", "collection");    GetRequest getRequest1 = mock(GetRequest.class);    GetRequest getRequest2 = mock(GetRequest.class);    solrDao.getAllLatest(Arrays.asList(getRequest1, getRequest2));    verify(solrRetrieveLatestDao).getAllLatest(Arrays.asList(getRequest1, getRequest2));    Document document = mock(Document.class);    solrDao.update(document, Optional.of("bro"));    verify(solrUpdateDao).update(document, Optional.of("bro"));    Map<Document, Optional<String>> updates = new HashMap<Document, Optional<String>>() {        {            put(document, Optional.of("bro"));        }    };    solrDao.batchUpdate(updates);    verify(solrUpdateDao).batchUpdate(updates);    solrDao.getColumnMetadata(Arrays.asList("bro", "snort"));    verify(solrColumnMetadataDao).getColumnMetadata(Arrays.asList("bro", "snort"));}
public static void metron_f7417_0()
{    accessConfig.setGlobalConfigSupplier(() -> new HashMap<String, Object>() {        {            put(SOLR_ZOOKEEPER, "zookeeper:2181");        }    });}
public void metron_f7418_0()
{    client = mock(SolrClient.class);    mockStatic(SolrClientFactory.class);    when(SolrClientFactory.create(accessConfig.getGlobalConfigSupplier().get())).thenReturn(client);}
public void metron_f7419_0()
{    IndexDao dao = new IndexDao() {        @Override        public SearchResponse search(SearchRequest searchRequest) {            return null;        }        @Override        public GroupResponse group(GroupRequest groupRequest) {            return null;        }        @Override        public void init(AccessConfig config) {        }        @Override        public Document getLatest(String guid, String sensorType) {            return null;        }        @Override        public Iterable<Document> getAllLatest(List<GetRequest> getRequests) {            return null;        }        @Override        public Document update(Document update, Optional<String> index) {            return null;        }        @Override        public Map<Document, Optional<String>> batchUpdate(Map<Document, Optional<String>> updates) {            return null;        }        @Override        public Document addCommentToAlert(CommentAddRemoveRequest request) {            return null;        }        @Override        public Document removeCommentFromAlert(CommentAddRemoveRequest request) {            return null;        }        @Override        public Document addCommentToAlert(CommentAddRemoveRequest request, Document latest) {            return null;        }        @Override        public Document removeCommentFromAlert(CommentAddRemoveRequest request, Document latest) {            return null;        }        @Override        public Document patch(RetrieveLatestDao dao, PatchRequest request, Optional<Long> timestamp) {            return null;        }        @Override        public Map<String, FieldType> getColumnMetadata(List<String> indices) {            return null;        }    };    SolrMetaAlertDao metaAlertDao = new SolrMetaAlertDao();    metaAlertDao.init(dao);}
public SearchResponse metron_f7420_0(SearchRequest searchRequest)
{    return null;}
public GroupResponse metron_f7421_0(GroupRequest groupRequest)
{    return null;}
public Document metron_f7423_0(String guid, String sensorType)
{    return null;}
public Iterable<Document> metron_f7424_0(List<GetRequest> getRequests)
{    return null;}
public Document metron_f7425_0(Document update, Optional<String> index)
{    return null;}
public Map<Document, Optional<String>> metron_f7426_0(Map<Document, Optional<String>> updates)
{    return null;}
public Document metron_f7427_0(CommentAddRemoveRequest request)
{    return null;}
public Document metron_f7428_0(CommentAddRemoveRequest request)
{    return null;}
public Document metron_f7429_0(CommentAddRemoveRequest request, Document latest)
{    return null;}
public Document metron_f7430_0(CommentAddRemoveRequest request, Document latest)
{    return null;}
public Document metron_f7431_0(RetrieveLatestDao dao, PatchRequest request, Optional<Long> timestamp)
{    return null;}
public Map<String, FieldType> metron_f7432_0(List<String> indices)
{    return null;}
public void metron_f7433_0()
{    HBaseDao dao = new HBaseDao();    SolrMetaAlertDao solrDao = new SolrMetaAlertDao();    solrDao.init(dao, Optional.empty());}
public void metron_f7434_0() throws InvalidCreateException, IOException
{    SolrDao solrDao = new SolrDao();    solrDao.init(accessConfig);    SolrMetaAlertDao emaDao = new SolrMetaAlertDao();    emaDao.init(solrDao);    MetaAlertCreateRequest createRequest = new MetaAlertCreateRequest();    emaDao.createMetaAlert(createRequest);}
public void metron_f7435_0() throws InvalidCreateException, IOException
{    SolrDao solrDao = new SolrDao();    solrDao.init(accessConfig);    MultiIndexDao miDao = new MultiIndexDao(solrDao);    SolrMetaAlertDao emaDao = new SolrMetaAlertDao();    emaDao.init(miDao);    MetaAlertCreateRequest createRequest = new MetaAlertCreateRequest();    createRequest.setAlerts(Collections.singletonList(new GetRequest("don't", "care")));    emaDao.createMetaAlert(createRequest);}
public void metron_f7436_0() throws Exception
{    client = mock(SolrClient.class);    accessConfig = mock(AccessConfig.class);    when(accessConfig.getIndexSupplier()).thenReturn(sensorType -> sensorType);    solrSearchDao = new SolrSearchDao(client, accessConfig);    solrRetrieveLatestDao = new SolrRetrieveLatestDao(client, accessConfig);    mockStatic(CollectionAdminRequest.class);    when(CollectionAdminRequest.listCollections(client)).thenReturn(Arrays.asList("bro", "snort"));}
public void metron_f7437_0() throws Exception
{    SearchRequest searchRequest = mock(SearchRequest.class);    SearchResponse searchResponse = mock(SearchResponse.class);    SolrQuery solrQuery = mock(SolrQuery.class);    QueryResponse queryResponse = mock(QueryResponse.class);    solrSearchDao = spy(new SolrSearchDao(client, accessConfig));    when(searchRequest.getQuery()).thenReturn("query");    doReturn(solrQuery).when(solrSearchDao).buildSearchRequest(searchRequest, "*");    when(client.query(solrQuery)).thenReturn(queryResponse);    doReturn(searchResponse).when(solrSearchDao).buildSearchResponse(searchRequest, queryResponse);    assertEquals(searchResponse, solrSearchDao.search(searchRequest, "*"));    verify(solrSearchDao).buildSearchRequest(searchRequest, "*");    verify(client).query(solrQuery);    verify(solrSearchDao).buildSearchResponse(searchRequest, queryResponse);    verifyNoMoreInteractions(client);}
public void metron_f7438_0() throws Exception
{    exception.expect(InvalidSearchException.class);    exception.expectMessage("Search query is invalid: null");    solrSearchDao.search(new SearchRequest());}
public void metron_f7439_0() throws Exception
{    exception.expect(InvalidSearchException.class);    exception.expectMessage("Uninitialized Dao!  You must call init() prior to use.");    SearchRequest searchRequest = new SearchRequest();    searchRequest.setQuery("query");    new SolrSearchDao(null, accessConfig).search(searchRequest);}
public void metron_f7440_0() throws Exception
{    exception.expect(InvalidSearchException.class);    exception.expectMessage("At least 1 group must be provided.");    GroupRequest groupRequest = mock(GroupRequest.class);    GroupResponse groupResponse = mock(GroupResponse.class);    solrSearchDao = spy(new SolrSearchDao(client, accessConfig));    when(groupRequest.getQuery()).thenReturn("query");    when(groupRequest.getGroups()).thenReturn(null);    when(groupRequest.getScoreField()).thenReturn(Optional.of("scoreField"));    when(groupRequest.getIndices()).thenReturn(Arrays.asList("bro", "snort"));    assertEquals(groupResponse, solrSearchDao.group(groupRequest));    verifyNoMoreInteractions(client);}
public void metron_f7441_0() throws Exception
{    exception.expect(InvalidSearchException.class);    exception.expectMessage("At least 1 group must be provided.");    GroupRequest groupRequest = mock(GroupRequest.class);    GroupResponse groupResponse = mock(GroupResponse.class);    solrSearchDao = spy(new SolrSearchDao(client, accessConfig));    when(groupRequest.getQuery()).thenReturn("query");    when(groupRequest.getGroups()).thenReturn(Collections.EMPTY_LIST);    when(groupRequest.getScoreField()).thenReturn(Optional.of("scoreField"));    when(groupRequest.getIndices()).thenReturn(Arrays.asList("bro", "snort"));    assertEquals(groupResponse, solrSearchDao.group(groupRequest));    verifyNoMoreInteractions(client);}
public void metron_f7442_0() throws Exception
{    exception.expect(InvalidSearchException.class);    exception.expectMessage("Search result size must be less than 100");    when(accessConfig.getMaxSearchResults()).thenReturn(100);    SearchRequest searchRequest = new SearchRequest();    searchRequest.setQuery("query");    searchRequest.setSize(200);    solrSearchDao.search(searchRequest);}
public void metron_f7443_0() throws Exception
{    GroupRequest groupRequest = mock(GroupRequest.class);    QueryResponse queryResponse = mock(QueryResponse.class);    GroupResponse groupResponse = mock(GroupResponse.class);    solrSearchDao = spy(new SolrSearchDao(client, accessConfig));    Group group1 = new Group();    group1.setField("field1");    Group group2 = new Group();    group2.setField("field2");    when(groupRequest.getQuery()).thenReturn("query");    when(groupRequest.getGroups()).thenReturn(Arrays.asList(group1, group2));    when(groupRequest.getScoreField()).thenReturn(Optional.of("scoreField"));    when(groupRequest.getIndices()).thenReturn(Arrays.asList("bro", "snort"));    when(client.query(any())).thenReturn(queryResponse);    doReturn(groupResponse).when(solrSearchDao).buildGroupResponse(groupRequest, queryResponse);    SolrQuery expectedSolrQuery = new SolrQuery().setStart(0).setRows(0).setQuery("query");    expectedSolrQuery.set("collection", "bro,snort");    expectedSolrQuery.set("stats", true);    expectedSolrQuery.set("stats.field", "{!tag=piv1 sum=true}scoreField");    expectedSolrQuery.set("facet", true);    expectedSolrQuery.set("facet.pivot", "{!stats=piv1}field1,field2");    assertEquals(groupResponse, solrSearchDao.group(groupRequest));    verify(client).query(argThat(new SolrQueryMatcher(expectedSolrQuery)));    verify(solrSearchDao).buildGroupResponse(groupRequest, queryResponse);    verifyNoMoreInteractions(client);}
public void metron_f7444_0() throws Exception
{    SolrDocument solrDocument = createSolrDocument("bro", 123456789L);    solrSearchDao = spy(new SolrSearchDao(client, accessConfig));    when(client.getById("collection", "guid")).thenReturn(solrDocument);    Document document = SolrUtilities.toDocument(solrDocument);    assertEquals(document, solrRetrieveLatestDao.getLatest("guid", "collection"));    verify(client).getById("collection", "guid");    verifyNoMoreInteractions(client);}
public void metron_f7445_0() throws Exception
{    GetRequest broRequest1 = new GetRequest("bro-1", "bro");    GetRequest broRequest2 = new GetRequest("bro-2", "bro");    GetRequest snortRequest1 = new GetRequest("snort-1", "snort");    GetRequest snortRequest2 = new GetRequest("snort-2", "snort");    SolrDocument broSolrDoc1 = createSolrDocument("bro", 12345L);    SolrDocument broSolrDoc2 = createSolrDocument("bro", 34567L);    SolrDocument snortSolrDoc1 = createSolrDocument("snort", 12345L);    SolrDocument snortSolrDoc2 = createSolrDocument("snort", 67890L);    Document broDoc1 = SolrUtilities.toDocument(broSolrDoc1);    Document broDoc2 = SolrUtilities.toDocument(broSolrDoc2);    Document snortDoc1 = SolrUtilities.toDocument(snortSolrDoc1);    Document snortDoc2 = SolrUtilities.toDocument(snortSolrDoc2);    solrSearchDao = spy(new SolrSearchDao(client, accessConfig));    SolrDocumentList broList = new SolrDocumentList();    broList.add(broSolrDoc1);    broList.add(broSolrDoc2);    SolrDocumentList snortList = new SolrDocumentList();    snortList.add(snortSolrDoc1);    snortList.add(snortSolrDoc2);    when(client.getById((Collection<String>) argThat(hasItems("bro-1", "bro-2")), argThat(new ModifiableSolrParamsMatcher(new ModifiableSolrParams().set("collection", "bro"))))).thenReturn(broList);    when(client.getById((Collection<String>) argThat(hasItems("snort-1", "snort-2")), argThat(new ModifiableSolrParamsMatcher(new ModifiableSolrParams().set("collection", "snort"))))).thenReturn(snortList);    assertEquals(Arrays.asList(broDoc1, broDoc2, snortDoc1, snortDoc2), solrRetrieveLatestDao.getAllLatest(Arrays.asList(broRequest1, broRequest2, snortRequest1, snortRequest2)));}
public void metron_f7446_0() throws Exception
{    SearchRequest searchRequest = new SearchRequest();    searchRequest.setIndices(Arrays.asList("bro", "snort"));    searchRequest.setSize(5);    searchRequest.setFrom(10);    searchRequest.setQuery("query");    SortField sortField = new SortField();    sortField.setField("sortField");    sortField.setSortOrder("ASC");    searchRequest.setSort(Collections.singletonList(sortField));    searchRequest.setFields(Arrays.asList("field1", "field2"));    searchRequest.setFacetFields(Arrays.asList("facetField1", "facetField2"));    SolrQuery exceptedSolrQuery = new SolrQuery().setStart(10).setRows(5).setQuery("query").addSort("sortField", SolrQuery.ORDER.asc).addField("field1").addField("field2").addFacetField("facetField1", "facetField2");    exceptedSolrQuery.set("collection", "bro,snort");    SolrQuery solrQuery = solrSearchDao.buildSearchRequest(searchRequest, "field1,field2");    assertThat(solrQuery, new SolrQueryMatcher(exceptedSolrQuery));}
public void metron_f7447_0()
{    SearchRequest searchRequest = new SearchRequest();    searchRequest.setFields(Collections.singletonList("id"));    searchRequest.setFacetFields(Collections.singletonList("facetField"));    QueryResponse queryResponse = mock(QueryResponse.class);    SolrDocument solrDocument1 = new SolrDocument();    solrDocument1.setField(Constants.GUID, "id1");    solrDocument1.setField("id", "id1");    SolrDocument solrDocument2 = new SolrDocument();    solrDocument2.setField(Constants.GUID, "id2");    solrDocument2.setField("id", "id2");    solrSearchDao = spy(new SolrSearchDao(client, accessConfig));    SolrDocumentList solrDocumentList = new SolrDocumentList();    solrDocumentList.add(solrDocument1);    solrDocumentList.add(solrDocument2);    solrDocumentList.setNumFound(100);    when(queryResponse.getResults()).thenReturn(solrDocumentList);    SearchResult searchResult1 = new SearchResult();    searchResult1.setId("id1");    HashMap<String, Object> source1 = new HashMap<>();    source1.put("id", "id1");    searchResult1.setSource(source1);    SearchResult searchResult2 = new SearchResult();    searchResult2.setId("id2");    HashMap<String, Object> source2 = new HashMap<>();    source2.put("id", "id2");    searchResult2.setSource(source2);    Map<String, Map<String, Long>> facetCounts = new HashMap<String, Map<String, Long>>() {        {            put("id", new HashMap<String, Long>() {                {                    put("id1", 1L);                    put("id2", 1L);                }            });        }    };    doReturn(facetCounts).when(solrSearchDao).getFacetCounts(Collections.singletonList("facetField"), queryResponse);    SearchResponse expectedSearchResponse = new SearchResponse();    SearchResult expectedSearchResult1 = new SearchResult();    expectedSearchResult1.setId("id1");    expectedSearchResult1.setSource(source1);    SearchResult expectedSearchResult2 = new SearchResult();    expectedSearchResult2.setId("id2");    expectedSearchResult2.setSource(source2);    expectedSearchResponse.setResults(Arrays.asList(expectedSearchResult1, expectedSearchResult2));    expectedSearchResponse.setTotal(100);    expectedSearchResponse.setFacetCounts(facetCounts);    assertEquals(expectedSearchResponse, solrSearchDao.buildSearchResponse(searchRequest, queryResponse));}
public void metron_f7448_0()
{    SolrDocument solrDocument = mock(SolrDocument.class);    when(solrDocument.getFieldValue(Constants.GUID)).thenReturn("guid");    when(solrDocument.getFieldValue(Constants.SENSOR_TYPE)).thenReturn("sensorType");    when(solrDocument.getFieldValue("field1")).thenReturn("value1");    when(solrDocument.getFieldValue("field2")).thenReturn("value2");    when(solrDocument.getFieldNames()).thenReturn(Arrays.asList("field1", "field2"));    SearchResult expectedSearchResult = new SearchResult();    expectedSearchResult.setId("guid");    expectedSearchResult.setIndex("sensorType");    expectedSearchResult.setSource(new HashMap<String, Object>() {        {            put("field1", "value1");        }    });    assertEquals(expectedSearchResult, SolrUtilities.getSearchResult(solrDocument, Collections.singletonList("field1"), solrSearchDao.getAccessConfig().getIndexSupplier()));    SearchResult expectedSearchResultAllFields = new SearchResult();    expectedSearchResultAllFields.setId("guid");    expectedSearchResultAllFields.setIndex("sensorType");    expectedSearchResultAllFields.setSource(new HashMap<String, Object>() {        {            put("field1", "value1");            put("field2", "value2");        }    });    assertEquals(expectedSearchResultAllFields, SolrUtilities.getSearchResult(solrDocument, null, solrSearchDao.getAccessConfig().getIndexSupplier()));}
public void metron_f7449_0()
{    QueryResponse queryResponse = mock(QueryResponse.class);    FacetField facetField1 = new FacetField("field1");    facetField1.add("value1", 1);    facetField1.add("value2", 2);    FacetField facetField2 = new FacetField("field2");    facetField2.add("value3", 3);    facetField2.add("value4", 4);    when(queryResponse.getFacetField("field1")).thenReturn(facetField1);    when(queryResponse.getFacetField("field2")).thenReturn(facetField2);    Map<String, Map<String, Long>> expectedFacetCounts = new HashMap<String, Map<String, Long>>() {        {            put("field1", new HashMap<String, Long>() {                {                    put("value1", 1L);                    put("value2", 2L);                }            });            put("field2", new HashMap<String, Long>() {                {                    put("value3", 3L);                    put("value4", 4L);                }            });        }    };    assertEquals(expectedFacetCounts, solrSearchDao.getFacetCounts(Arrays.asList("field1", "field2"), queryResponse));}
public void metron_f7450_0()
{    GroupRequest groupRequest = mock(GroupRequest.class);    QueryResponse queryResponse = mock(QueryResponse.class);    NamedList namedList = mock(NamedList.class);    List pivotFields = mock(List.class);    List groupResults = mock(List.class);    solrSearchDao = spy(new SolrSearchDao(client, accessConfig));    Group group1 = new Group();    group1.setField("field1");    Group group2 = new Group();    group2.setField("field2");    when(groupRequest.getGroups()).thenReturn(Arrays.asList(group1, group2));    when(queryResponse.getFacetPivot()).thenReturn(namedList);    when(namedList.get("field1,field2")).thenReturn(pivotFields);    doReturn(groupResults).when(solrSearchDao).getGroupResults(groupRequest, 0, pivotFields);    GroupResponse groupResponse = solrSearchDao.buildGroupResponse(groupRequest, queryResponse);    assertEquals("field1", groupResponse.getGroupedBy());    verify(namedList).get("field1,field2");    verify(solrSearchDao).getGroupResults(groupRequest, 0, pivotFields);}
public void metron_f7451_0()
{    GroupRequest groupRequest = new GroupRequest();    Group group1 = new Group();    group1.setField("field1");    GroupOrder groupOrder1 = new GroupOrder();    groupOrder1.setSortOrder("ASC");    groupOrder1.setGroupOrderType("TERM");    group1.setOrder(groupOrder1);    Group group2 = new Group();    group2.setField("field2");    GroupOrder groupOrder2 = new GroupOrder();    groupOrder2.setSortOrder("DESC");    groupOrder2.setGroupOrderType("COUNT");    group2.setOrder(groupOrder2);    groupRequest.setGroups(Arrays.asList(group1, group2));    groupRequest.setScoreField("score");    PivotField level1Pivot1 = mock(PivotField.class);    PivotField level1Pivot2 = mock(PivotField.class);    PivotField level2Pivot1 = mock(PivotField.class);    PivotField level2Pivot2 = mock(PivotField.class);    FieldStatsInfo level1Pivot1FieldStatsInfo = mock(FieldStatsInfo.class);    FieldStatsInfo level1Pivot2FieldStatsInfo = mock(FieldStatsInfo.class);    FieldStatsInfo level2Pivot1FieldStatsInfo = mock(FieldStatsInfo.class);    FieldStatsInfo level2Pivot2FieldStatsInfo = mock(FieldStatsInfo.class);    List<PivotField> level1Pivots = Arrays.asList(level1Pivot1, level1Pivot2);    List<PivotField> level2Pivots = Arrays.asList(level2Pivot1, level2Pivot2);    when(level1Pivot1.getValue()).thenReturn("field1value1");    when(level1Pivot1.getCount()).thenReturn(1);    when(level1Pivot1FieldStatsInfo.getSum()).thenReturn(1.0);    when(level1Pivot1.getFieldStatsInfo()).thenReturn(new HashMap<String, FieldStatsInfo>() {        {            put("score", level1Pivot1FieldStatsInfo);        }    });    when(level1Pivot2.getValue()).thenReturn("field1value2");    when(level1Pivot2.getCount()).thenReturn(2);    when(level1Pivot2FieldStatsInfo.getSum()).thenReturn(2.0);    when(level1Pivot2.getFieldStatsInfo()).thenReturn(new HashMap<String, FieldStatsInfo>() {        {            put("score", level1Pivot2FieldStatsInfo);        }    });    when(level2Pivot1.getValue()).thenReturn("field2value1");    when(level2Pivot1.getCount()).thenReturn(3);    when(level2Pivot1FieldStatsInfo.getSum()).thenReturn(3.0);    when(level2Pivot1.getFieldStatsInfo()).thenReturn(new HashMap<String, FieldStatsInfo>() {        {            put("score", level2Pivot1FieldStatsInfo);        }    });    when(level2Pivot2.getValue()).thenReturn("field2value2");    when(level2Pivot2.getCount()).thenReturn(4);    when(level2Pivot2FieldStatsInfo.getSum()).thenReturn(4.0);    when(level2Pivot2.getFieldStatsInfo()).thenReturn(new HashMap<String, FieldStatsInfo>() {        {            put("score", level2Pivot2FieldStatsInfo);        }    });    when(level1Pivot1.getPivot()).thenReturn(level2Pivots);    List<GroupResult> level1GroupResults = solrSearchDao.getGroupResults(groupRequest, 0, level1Pivots);    assertEquals("field1value1", level1GroupResults.get(0).getKey());    assertEquals(1, level1GroupResults.get(0).getTotal());    assertEquals(1.0, level1GroupResults.get(0).getScore(), 0.00001);    assertEquals("field2", level1GroupResults.get(0).getGroupedBy());    assertEquals("field1value2", level1GroupResults.get(1).getKey());    assertEquals(2, level1GroupResults.get(1).getTotal());    assertEquals(2.0, level1GroupResults.get(1).getScore(), 0.00001);    assertEquals("field2", level1GroupResults.get(1).getGroupedBy());    assertEquals(0, level1GroupResults.get(1).getGroupResults().size());    List<GroupResult> level2GroupResults = level1GroupResults.get(0).getGroupResults();    assertEquals("field2value2", level2GroupResults.get(0).getKey());    assertEquals(4, level2GroupResults.get(0).getTotal());    assertEquals(4.0, level2GroupResults.get(0).getScore(), 0.00001);    assertNull(level2GroupResults.get(0).getGroupedBy());    assertNull(level2GroupResults.get(0).getGroupResults());    assertEquals("field2value1", level2GroupResults.get(1).getKey());    assertEquals(3, level2GroupResults.get(1).getTotal());    assertEquals(3.0, level2GroupResults.get(1).getScore(), 0.00001);    assertNull(level2GroupResults.get(1).getGroupedBy());    assertNull(level2GroupResults.get(1).getGroupResults());}
private SolrDocument metron_f7452_0(String sensorType, Long timestamp)
{    SolrDocument solrDocument = new SolrDocument();    solrDocument.addField(SolrDao.VERSION_FIELD, 1.0);    solrDocument.addField(Constants.GUID, UUID.randomUUID().toString());    solrDocument.addField(Constants.SENSOR_TYPE, sensorType);    solrDocument.addField(Constants.Fields.TIMESTAMP.getName(), timestamp);    solrDocument.addField(Constants.Fields.SRC_ADDR.getName(), "192.168.1.1");    return solrDocument;}
public static void metron_f7453_0()
{    accessConfig.setGlobalConfigSupplier(() -> new HashMap<String, Object>() {        {            put(SOLR_ZOOKEEPER, "zookeeper:2181");        }    });    IndexingConfigurations indexingConfigs = mock(IndexingConfigurations.class);    ConfigurationsCache cache = mock(ConfigurationsCache.class);    Map<String, Object> broIndexingConfig = new HashMap<String, Object>() {        {            put("solr", new HashMap<String, Object>() {                {                }            });        }    };    when(indexingConfigs.getSensorIndexingConfig("bro")).thenReturn(broIndexingConfig);    when(cache.get(IndexingConfigurations.class)).thenReturn(indexingConfigs);    accessConfig.setIndexSupplier(IndexingCacheUtil.getIndexLookupFunction(cache, "solr"));}
public void metron_f7454_0() throws Exception
{    client = mock(SolrClient.class);    solrRetrieveLatestDao = new SolrRetrieveLatestDao(client, accessConfig);    solrUpdateDao = new SolrUpdateDao(client, solrRetrieveLatestDao, accessConfig);}
public void metron_f7455_0() throws Exception
{    Document document = new Document(new HashMap<String, Object>() {        {            put("field", "value");        }    }, "guid", "bro", 0L);    SolrInputDocument solrInputDocument = new SolrInputDocument();    solrInputDocument.addField("field", "value");    solrUpdateDao.update(document, Optional.empty());    verify(client).add(eq("bro"), argThat(new SolrInputDocumentMatcher(solrInputDocument)));}
public void metron_f7456_0() throws Exception
{    Document document = new Document(new HashMap<String, Object>() {        {            put("field", "value");        }    }, "guid", "bro", 0L);    SolrInputDocument solrInputDocument = new SolrInputDocument();    solrInputDocument.addField("field", "value");    solrUpdateDao.update(document, Optional.of("bro"));    verify(client).add(eq("bro"), argThat(new SolrInputDocumentMatcher(solrInputDocument)));}
public void metron_f7457_0() throws Exception
{    Document broDocument1 = new Document(new HashMap<String, Object>() {        {            put("broField1", "value");            put("guid", "broGuid1");        }    }, "broGuid1", "bro", 0L);    Document broDocument2 = new Document(new HashMap<String, Object>() {        {            put("broField2", "value");            put("guid", "broGuid2");        }    }, "broGuid2", "bro", 0L);    Map<Document, Optional<String>> updates = new HashMap<Document, Optional<String>>() {        {            put(broDocument1, Optional.of("bro"));            put(broDocument2, Optional.of("bro"));        }    };    SolrInputDocument broSolrInputDocument1 = new SolrInputDocument();    broSolrInputDocument1.addField("broField1", "value");    broSolrInputDocument1.addField("guid", "broGuid1");    SolrInputDocument broSolrInputDocument2 = new SolrInputDocument();    broSolrInputDocument2.addField("broField2", "value");    broSolrInputDocument2.addField("guid", "broGuid2");    solrUpdateDao.batchUpdate(updates);    verify(client).add(eq("bro"), argThat(new SolrInputDocumentListMatcher(Arrays.asList(broSolrInputDocument1, broSolrInputDocument2))));}
public void metron_f7458_0() throws Exception
{    Document snortDocument1 = new Document(new HashMap<String, Object>() {        {            put("snortField1", "value");            put("guid", "snortGuid1");        }    }, "snortGuid1", "snort", 0L);    Document snortDocument2 = new Document(new HashMap<String, Object>() {        {            put("snortField2", "value");            put("guid", "snortGuid2");        }    }, "snortGuid2", "snort", 0L);    Map<Document, Optional<String>> updates = new HashMap<Document, Optional<String>>() {        {            put(snortDocument1, Optional.empty());            put(snortDocument2, Optional.empty());        }    };    SolrInputDocument snortSolrInputDocument1 = new SolrInputDocument();    snortSolrInputDocument1.addField("snortField1", "value");    snortSolrInputDocument1.addField("guid", "snortGuid1");    SolrInputDocument snortSolrInputDocument2 = new SolrInputDocument();    snortSolrInputDocument2.addField("snortField2", "value");    snortSolrInputDocument2.addField("guid", "snortGuid2");    solrUpdateDao.batchUpdate(updates);    verify(client).add(eq("snort"), argThat(new SolrInputDocumentListMatcher(Arrays.asList(snortSolrInputDocument1, snortSolrInputDocument2))));}
public void metron_f7459_0()
{    List<Map<String, Object>> commentList = new ArrayList<>();    Map<String, Object> comments = new HashMap<>();    comments.put("comment", "test comment");    comments.put("username", "test username");    comments.put("timestamp", 1526424323279L);    commentList.add(comments);    Map<String, Object> document = new HashMap<>();    document.put("testField", "testValue");    document.put(COMMENTS_FIELD, commentList);    solrUpdateDao.convertCommentsToRaw(document);    @SuppressWarnings("unchecked")    List<String> actualComments = (List<String>) document.get(COMMENTS_FIELD);    String expectedComment = "{\"comment\":\"test comment\",\"username\":\"test username\",\"timestamp\":1526424323279}";    assertEquals(expectedComment, actualComments.get(0));    assertEquals(1, actualComments.size());    assertEquals("testValue", document.get("testField"));}
public void metron_f7460_0() throws IOException, OriginalNotFoundException
{        Map<String, Object> latestDoc = new HashMap<>();    latestDoc.put(Constants.GUID, "guid");    List<Map<String, Object>> comments = new ArrayList<>();    comments.add(new AlertComment("comment", "user", 0L).asMap());    comments.add(new AlertComment("comment_2", "user_2", 0L).asMap());    latestDoc.put(COMMENTS_FIELD, comments);    Document latest = new Document(latestDoc, "guid", "bro", 0L);    SolrRetrieveLatestDao retrieveLatestDao = spy(new SolrRetrieveLatestDao(null, accessConfig));    doReturn(latest).when(retrieveLatestDao).getLatest("guid", "bro");        PatchRequest request = new PatchRequest();    request.setIndex("bro");    request.setSensorType("bro");    request.setGuid("guid");    List<Map<String, Object>> patchList = new ArrayList<>();    Map<String, Object> patch = new HashMap<>();    patch.put("op", "add");    patch.put("path", "/project");    patch.put("value", "metron");    patchList.add(patch);    request.setPatch(patchList);    Document actual = solrUpdateDao.getPatchedDocument(retrieveLatestDao, request, Optional.of(0L));        latest.getDocument().put("project", "metron");    assertEquals(actual, latest);}
public UpdateDao metron_f7461_0()
{    return solrUpdateDao;}
public void metron_f7462_0() throws Exception
{    long expectedTimestamp = System.currentTimeMillis();    SolrDocument solrDocument = new SolrDocument();    solrDocument.addField(SolrDao.VERSION_FIELD, 1.0);    solrDocument.addField(Constants.GUID, "guid");    solrDocument.addField(Constants.SENSOR_TYPE, "bro");    solrDocument.addField(Constants.Fields.TIMESTAMP.getName(), expectedTimestamp);    solrDocument.addField("field", "value");    Document expectedDocument = new Document(new HashMap<String, Object>() {        {            put("field", "value");            put(Constants.GUID, "guid");            put(Constants.SENSOR_TYPE, "bro");            put(Constants.Fields.TIMESTAMP.getName(), expectedTimestamp);        }    }, "guid", "bro", expectedTimestamp);    Document actualDocument = SolrUtilities.toDocument(solrDocument);    assertEquals(expectedDocument, actualDocument);}
public Builder metron_f7463_0(int port)
{    this.port = port;    return this;}
public Builder metron_f7464_0(String solrXmlPath)
{    this.solrXmlPath = solrXmlPath;    return this;}
public Builder metron_f7465_0(String name, String configPath)
{    initialCollections.put(name, configPath);    return this;}
public Builder metron_f7466_0(Function<SolrComponent, Void> f)
{    postStartCallback = f;    return this;}
public SolrComponent metron_f7467_0()
{    return new SolrComponent(port, solrXmlPath, initialCollections, postStartCallback);}
public void metron_f7468_0() throws UnableToStartException
{    try {        File baseDir = Files.createTempDirectory("solrcomponent").toFile();        baseDir.deleteOnExit();        miniSolrCloudCluster = new MiniSolrCloudCluster(1, baseDir.toPath(), JettyConfig.builder().setPort(port).build());        for (String name : collections.keySet()) {            String configPath = collections.get(name);            miniSolrCloudCluster.uploadConfigSet(new File(configPath).toPath(), name);            CollectionAdminRequest.createCollection(name, 1, 1).process(miniSolrCloudCluster.getSolrClient());        }        if (postStartCallback != null) {            postStartCallback.apply(this);        }    } catch (Exception e) {        throw new UnableToStartException(e.getMessage(), e);    }}
public void metron_f7469_0()
{    try {        miniSolrCloudCluster.deleteAllCollections();        miniSolrCloudCluster.shutdown();    } catch (Exception e) {        }}
public void metron_f7470_0()
{    try {        miniSolrCloudCluster.deleteAllCollections();    } catch (Exception e) {        }}
public MetronSolrClient metron_f7471_0()
{    return new MetronSolrClient(getZookeeperUrl());}
public MiniSolrCloudCluster metron_f7472_0()
{    return this.miniSolrCloudCluster;}
public String metron_f7473_0()
{    return miniSolrCloudCluster.getZkServer().getZkAddress();}
public void metron_f7474_0(String name, String configPath) throws InterruptedException, IOException, KeeperException, SolrServerException
{    miniSolrCloudCluster.uploadConfigSet(new File(configPath).toPath(), name);    CollectionAdminRequest.createCollection(name, 1, 1).process(miniSolrCloudCluster.getSolrClient());}
public boolean metron_f7475_0(String collection)
{    MetronSolrClient solr = getSolrClient();    boolean collectionFound = false;    try {        collectionFound = solr.listCollections().contains(collection);    } catch (Exception e) {        e.printStackTrace();    }    return collectionFound;}
public List<Map<String, Object>> metron_f7476_0(String collection)
{    List<Map<String, Object>> docs = new ArrayList<>();    CloudSolrClient solr = miniSolrCloudCluster.getSolrClient();    solr.setDefaultCollection(collection);    SolrQuery parameters = new SolrQuery();        if (collection.equals("metaalert")) {        parameters.setQuery("source.type:metaalert").setFields("*", "[child parentFilter=source.type:metaalert limit=999]");    } else {        parameters.set("q", "*:*");    }    try {        solr.commit();        QueryResponse response = solr.query(parameters);        for (SolrDocument solrDocument : response.getResults()) {                        docs.add(SolrUtilities.toDocument(solrDocument).getDocument());        }    } catch (SolrServerException | IOException e) {        e.printStackTrace();    }    return docs;}
public void metron_f7477_0(String collection, List<Map<String, Object>> docs) throws IOException, SolrServerException
{    CloudSolrClient solr = miniSolrCloudCluster.getSolrClient();    solr.setDefaultCollection(collection);    Collection<SolrInputDocument> solrInputDocuments = docs.stream().map(doc -> {        SolrInputDocument solrInputDocument = new SolrInputDocument();        for (Entry<String, Object> entry : doc.entrySet()) {                        if (entry.getValue() instanceof List && !entry.getKey().equals(MetaAlertConstants.METAALERT_FIELD)) {                for (Object entryItem : (List) entry.getValue()) {                    if (entryItem instanceof Map) {                        @SuppressWarnings("unchecked")                        Map<String, Object> childDoc = (Map<String, Object>) entryItem;                        SolrInputDocument childInputDoc = new SolrInputDocument();                        for (Entry<String, Object> childEntry : childDoc.entrySet()) {                            childInputDoc.addField(childEntry.getKey(), childEntry.getValue());                        }                        solrInputDocument.addChildDocument(childInputDoc);                    }                }            } else {                solrInputDocument.addField(entry.getKey(), entry.getValue());            }        }        return solrInputDocument;    }).collect(Collectors.toList());    checkUpdateResponse(solr.add(collection, solrInputDocuments));        checkUpdateResponse(solr.commit(true, true));}
protected void metron_f7478_0(UpdateResponse result) throws IOException
{    if (result.getStatus() != 0) {        throw new IOException("Response error received while adding documents: " + result);    }}
public static Iterable<String> metron_f7479_0(String sensor) throws IOException
{    return Iterables.filter(Files.readLines(new File("src/test/resources/example_data/" + sensor), Charset.defaultCharset()), s -> !s.startsWith("#") && s.length() > 0);}
public static Map<String, Object> metron_f7480_0(String sensorType, SolrComponent component)
{    Map<String, Object> globalConfig = new HashMap<>();    globalConfig.put(SOLR_ZOOKEEPER, component.getZookeeperUrl());    return globalConfig;}
public static SolrComponent metron_f7481_0(String sensor) throws Exception
{    return new SolrComponent.Builder().build();}
public void metron_f7482_0() throws Exception
{    test("error");}
public void metron_f7483_0() throws Exception
{    test("bro");}
public void metron_f7484_0() throws Exception
{    test("snort");}
public void metron_f7485_0() throws Exception
{    test("yaf");}
public String metron_f7486_0(Map<String, Object> m)
{    if (m.containsKey("guid")) {        return (String) m.get("guid");    } else {        return (String) m.get("original_string");    }}
public void metron_f7487_0(String sensorType) throws Exception
{    SolrComponent component = null;    try {        component = createSolrComponent(sensorType);        component.start();        component.addCollection(String.format("%s", sensorType), String.format("src/main/config/schema/%s", sensorType));        Map<String, Object> globalConfig = getGlobalConfig(sensorType, component);        List<BulkMessage<JSONObject>> messages = new ArrayList<>();        Map<String, Map<String, Object>> index = new HashMap<>();        int i = 0;        for (String message : getData(sensorType)) {            if (message.trim().length() > 0) {                Map<String, Object> m = JSONUtils.INSTANCE.load(message.trim(), JSONUtils.MAP_SUPPLIER);                String guid = getGuid(m);                index.put(guid, m);                messages.add(new BulkMessage<>(String.format("message%d", ++i), new JSONObject(m)));            }        }        Assert.assertTrue(messages.size() > 0);        SolrWriter solrWriter = new SolrWriter();        WriterConfiguration writerConfig = new WriterConfiguration() {            @Override            public int getBatchSize(String sensorName) {                return messages.size();            }            @Override            public int getBatchTimeout(String sensorName) {                return 0;            }            @Override            public List<Integer> getAllConfiguredTimeouts() {                return new ArrayList<>();            }            @Override            public String getIndex(String sensorName) {                return sensorType;            }            @Override            public boolean isEnabled(String sensorName) {                return true;            }            @Override            public Map<String, Object> getSensorConfig(String sensorName) {                return new HashMap<String, Object>() {                    {                        put("index", sensorType);                        put("batchSize", messages.size());                        put("enabled", true);                    }                };            }            @Override            public Map<String, Object> getGlobalConfig() {                return globalConfig;            }            @Override            public boolean isDefault(String sensorName) {                return false;            }            @Override            public String getFieldNameConverter(String sensorName) {                return null;            }        };        solrWriter.init(null, writerConfig);        BulkWriterResponse response = solrWriter.write(sensorType, writerConfig, messages);        Assert.assertTrue(response.getErrors().isEmpty());        for (Map<String, Object> m : component.getAllIndexedDocs(sensorType)) {            Map<String, Object> expected = index.get(getGuid(m));            for (Map.Entry<String, Object> field : expected.entrySet()) {                if (field.getValue() instanceof Collection && ((Collection) field.getValue()).size() == 0) {                    continue;                }                if (m.get(field.getKey()) instanceof Number) {                    Number n1 = ConversionUtils.convert(field.getValue(), Double.class);                    Number n2 = (Number) m.get(field.getKey());                    boolean isSame = Math.abs(n1.doubleValue() - n2.doubleValue()) < 1e-3;                    if (!isSame) {                        String s1 = "" + n1.doubleValue();                        String s2 = "" + n2.doubleValue();                        isSame = s1.startsWith(s2) || s2.startsWith(s1);                    }                    Assert.assertTrue("Unable to validate " + field.getKey() + ": " + n1 + " != " + n2, isSame);                } else {                    Assert.assertEquals("Unable to find " + field.getKey(), "" + field.getValue(), "" + m.get(field.getKey()));                }            }        }    } finally {        if (component != null) {            component.stop();        }    }}
public int metron_f7488_0(String sensorName)
{    return messages.size();}
public int metron_f7489_0(String sensorName)
{    return 0;}
public List<Integer> metron_f7490_0()
{    return new ArrayList<>();}
public String metron_f7491_0(String sensorName)
{    return sensorType;}
public boolean metron_f7492_0(String sensorName)
{    return true;}
public Map<String, Object> metron_f7493_0(String sensorName)
{    return new HashMap<String, Object>() {        {            put("index", sensorType);            put("batchSize", messages.size());            put("enabled", true);        }    };}
public Map<String, Object> metron_f7494_0()
{    return globalConfig;}
public boolean metron_f7495_0(String sensorName)
{    return false;}
public String metron_f7496_0(String sensorName)
{    return null;}
public static void metron_f7497_0() throws Exception
{        MAX_RETRIES = 1;        solr = new SolrComponent.Builder().build();    solr.start();    AccessConfig accessConfig = new AccessConfig();    Map<String, Object> globalConfig = new HashMap<String, Object>() {        {            put("solr.clustername", "metron");            put("solr.port", "9300");            put("solr.ip", "localhost");            put("solr.date.format", DATE_FORMAT);            put(SOLR_ZOOKEEPER, solr.getZookeeperUrl());        }    };    accessConfig.setMaxSearchResults(1000);    accessConfig.setGlobalConfigSupplier(() -> globalConfig);    accessConfig.setMaxSearchGroups(100);        accessConfig.setIndexSupplier(s -> s);    solrDao = new SolrDao();    solrDao.init(accessConfig);    MetaAlertConfig config = new MetaAlertConfig(METAALERTS_COLLECTION, THREAT_SORT_DEFAULT, () -> ImmutableMap.of(Constants.SENSOR_TYPE_FIELD_PROPERTY, Constants.SENSOR_TYPE, Constants.THREAT_SCORE_FIELD_PROPERTY, THREAT_FIELD_DEFAULT)) {        @Override        protected String getDefaultThreatTriageField() {            return THREAT_FIELD_DEFAULT.replace(':', '.');        }        @Override        protected String getDefaultSourceTypeField() {            return Constants.SENSOR_TYPE;        }    };    SolrClient solrClient = SolrClientFactory.create(globalConfig);    SolrMetaAlertSearchDao searchDao = new SolrMetaAlertSearchDao(solrClient, solrDao.getSolrSearchDao(), config);    SolrMetaAlertRetrieveLatestDao retrieveLatestDao = new SolrMetaAlertRetrieveLatestDao(solrClient, solrDao);    SolrMetaAlertUpdateDao updateDao = new SolrMetaAlertUpdateDao(solrClient, solrDao, searchDao, retrieveLatestDao, config);    metaDao = new SolrMetaAlertDao(solrDao, searchDao, updateDao, retrieveLatestDao);}
protected String metron_f7498_0()
{    return THREAT_FIELD_DEFAULT.replace(':', '.');}
protected String metron_f7499_0()
{    return Constants.SENSOR_TYPE;}
public void metron_f7500_0() throws IOException, InterruptedException, SolrServerException, KeeperException
{    solr.addCollection(METAALERTS_COLLECTION, "./src/main/config/schema//metaalert");    solr.addCollection(SENSOR_NAME, "./src/test/resources/config/test/conf");}
public static void metron_f7501_0()
{    SolrClientFactory.close();    if (solr != null) {        solr.stop();    }}
public void metron_f7502_0()
{    solr.reset();}
public void metron_f7503_0() throws Exception
{        List<Map<String, Object>> alerts = buildAlerts(4);    alerts.get(0).put(METAALERT_FIELD, Collections.singletonList("meta_active"));    alerts.get(0).put("ip_src_addr", "192.168.1.1");    alerts.get(0).put("ip_src_port", 8010);    alerts.get(1).put(METAALERT_FIELD, Collections.singletonList("meta_active"));    alerts.get(1).put("ip_src_addr", "192.168.1.2");    alerts.get(1).put("ip_src_port", 8009);    alerts.get(2).put("ip_src_addr", "192.168.1.3");    alerts.get(2).put("ip_src_port", 8008);    alerts.get(3).put("ip_src_addr", "192.168.1.4");    alerts.get(3).put("ip_src_port", 8007);    addRecords(alerts, getTestIndexName(), SENSOR_NAME);        setupTypings();        Map<String, Object> activeMetaAlert = buildMetaAlert("meta_active", MetaAlertStatus.ACTIVE, Optional.of(Arrays.asList(alerts.get(0), alerts.get(1))));    Map<String, Object> inactiveMetaAlert = buildMetaAlert("meta_inactive", MetaAlertStatus.INACTIVE, Optional.of(Arrays.asList(alerts.get(2), alerts.get(3))));        addRecords(Arrays.asList(activeMetaAlert, inactiveMetaAlert), METAALERTS_COLLECTION, METAALERT_TYPE);        findCreatedDocs(Arrays.asList(new GetRequest("message_0", SENSOR_NAME), new GetRequest("message_1", SENSOR_NAME), new GetRequest("message_2", SENSOR_NAME), new GetRequest("message_3", SENSOR_NAME), new GetRequest("meta_active", METAALERT_TYPE), new GetRequest("meta_inactive", METAALERT_TYPE)));    SearchResponse searchResponse = metaDao.search(new SearchRequest() {        {            setQuery("ip_src_addr:192.168.1.1 AND ip_src_port:8010");            setIndices(Collections.singletonList(METAALERT_TYPE));            setFrom(0);            setSize(5);            setSort(Collections.singletonList(new SortField() {                {                    setField(Constants.GUID);                }            }));        }    });        Assert.assertEquals(1, searchResponse.getTotal());        List<Map<String, Object>> actualAlerts = (List<Map<String, Object>>) searchResponse.getResults().get(0).getSource().get(MetaAlertConstants.ALERT_FIELD);    Assert.assertEquals(2, actualAlerts.size());    Assert.assertEquals("meta_active", searchResponse.getResults().get(0).getSource().get("guid"));            searchResponse = metaDao.search(new SearchRequest() {        {            setQuery("ip_src_addr:192.168.1.1 AND ip_src_port:8010");            setIndices(queryIndices);            setFrom(0);            setSize(5);            setSort(Collections.singletonList(new SortField() {                {                    setField(Constants.GUID);                }            }));        }    });        Assert.assertEquals(1, searchResponse.getTotal());        actualAlerts = (List<Map<String, Object>>) searchResponse.getResults().get(0).getSource().get(MetaAlertConstants.ALERT_FIELD);    Assert.assertEquals(2, actualAlerts.size());    Assert.assertEquals("meta_active", searchResponse.getResults().get(0).getSource().get("guid"));            searchResponse = metaDao.search(new SearchRequest() {        {            setQuery("ip_src_addr:192.168.1.3 AND ip_src_port:8008");            setIndices(queryIndices);            setFrom(0);            setSize(1);            setSort(Collections.singletonList(new SortField() {                {                    setField(Constants.GUID);                }            }));        }    });        Assert.assertEquals(1, searchResponse.getTotal());        actualAlerts = (List<Map<String, Object>>) searchResponse.getResults().get(0).getSource().get(MetaAlertConstants.ALERT_FIELD);    Assert.assertNull(actualAlerts);    Assert.assertEquals("message_2", searchResponse.getResults().get(0).getSource().get("guid"));}
public void metron_f7504_0() throws Exception
{        List<Map<String, Object>> alerts = buildAlerts(1);    alerts.get(0).put(METAALERT_FIELD, Collections.singletonList("meta_active"));    alerts.get(0).put("ip_src_addr", "192.168.1.1");    alerts.get(0).put("ip_src_port", 8010);    addRecords(alerts, getTestIndexName(), SENSOR_NAME);        setupTypings();        Map<String, Object> activeMetaAlert = buildMetaAlert("meta_active", MetaAlertStatus.ACTIVE, Optional.of(Arrays.asList(alerts.get(0))));        addRecords(Collections.singletonList(activeMetaAlert), METAALERTS_COLLECTION, METAALERT_TYPE);        findCreatedDocs(Collections.singletonList(new GetRequest("meta_active", METAALERT_TYPE)));    SearchResponse searchResponse = metaDao.search(new SearchRequest() {        {            setQuery("ip_src_addr:192.168.1.1 AND ip_src_port:8010");            setIndices(Collections.singletonList(METAALERT_TYPE));            setFrom(0);            setSize(5);            setFields(Collections.singletonList(Constants.GUID));            setSort(Collections.singletonList(new SortField() {                {                    setField(Constants.GUID);                }            }));        }    });        Assert.assertEquals(1, searchResponse.getTotal());        List<Map<String, Object>> actualAlerts = (List<Map<String, Object>>) searchResponse.getResults().get(0).getSource().get(MetaAlertConstants.ALERT_FIELD);    Assert.assertNull(actualAlerts);    Assert.assertEquals("meta_active", searchResponse.getResults().get(0).getSource().get("guid"));}
protected long metron_f7505_0(String fieldName, Object fieldValue) throws InterruptedException
{    long cnt = 0;    for (int t = 0; t < MAX_RETRIES && cnt == 0; ++t, Thread.sleep(SLEEP_MS)) {        List<Map<String, Object>> docs = solr.getAllIndexedDocs(getTestIndexName());        cnt = docs.stream().filter(d -> {            Object newfield = d.get(fieldName);            return newfield != null && newfield.equals(fieldValue);        }).count();    }    return cnt;}
protected long metron_f7506_0(String fieldName, String fieldValue) throws InterruptedException
{    long cnt = 0;    for (int t = 0; t < MAX_RETRIES && cnt == 0; ++t, Thread.sleep(SLEEP_MS)) {        List<Map<String, Object>> docs = solr.getAllIndexedDocs(METAALERTS_COLLECTION);        cnt = docs.stream().filter(d -> {            @SuppressWarnings("unchecked")            List<Map<String, Object>> alerts = (List<Map<String, Object>>) d.get(ALERT_FIELD);            for (Map<String, Object> alert : alerts) {                Object newField = alert.get(fieldName);                if (newField != null && newField.equals(fieldValue)) {                    return true;                }            }            return false;        }).count();    }    return cnt;}
protected void metron_f7507_0(List<Map<String, Object>> inputData, String index, String docType) throws IOException
{        try {        solr.addDocs(index, inputData);    } catch (SolrServerException e) {        throw new IOException("Unable to load Solr Docs", e);    }}
protected String metron_f7509_0()
{    return COLLECTION;}
protected String metron_f7510_0()
{    return METAALERTS_COLLECTION;}
protected String metron_f7511_0()
{    return Constants.SENSOR_TYPE;}
protected void metron_f7512_0() throws IOException
{    try {        List<String> collections = solr.getSolrClient().listCollections();        for (String collection : collections) {            solr.getSolrClient().commit(collection);        }    } catch (SolrServerException e) {        throw new IOException("Unable to commit", e);    }}
protected void metron_f7513_0(Map<String, Object> docMap)
{    docMap.remove(METAALERT_FIELD);}
protected boolean metron_f7514_0()
{    return false;}
protected boolean metron_f7515_0()
{    return false;}
public static void metron_f7516_0() throws Exception
{    solrComponent = new SolrComponent.Builder().build();    solrComponent.start();}
public void metron_f7517_0() throws Exception
{    solrComponent.addCollection(TEST_COLLECTION, "./src/test/resources/config/test/conf");    solrComponent.addCollection(BRO_SENSOR, "./src/main/config/schema/bro");    AccessConfig accessConfig = new AccessConfig();    Map<String, Object> globalConfig = new HashMap<>();    globalConfig.put(SOLR_ZOOKEEPER, solrComponent.getZookeeperUrl());    accessConfig.setGlobalConfigSupplier(() -> globalConfig);        accessConfig.setIndexSupplier(s -> s.equals(TEST_SENSOR) ? TEST_COLLECTION : s);    dao = new SolrDao();    dao.init(accessConfig);    addData(BRO_SENSOR, BRO_SENSOR, expectedTimestamp);    addData(TEST_COLLECTION, TEST_SENSOR, expectedTimestamp);}
public void metron_f7518_0()
{    solrComponent.reset();}
public static void metron_f7519_0()
{    SolrClientFactory.close();    solrComponent.stop();}
public void metron_f7520_0() throws IOException
{    Document actual = dao.getLatest("message_1_bro", BRO_SENSOR);    assertEquals(buildExpectedDocument(BRO_SENSOR, 1), actual);}
public void metron_f7521_0() throws IOException
{    Document actual = dao.getLatest("message_1_bro", TEST_SENSOR);    assertNull(actual);}
public void metron_f7522_0() throws IOException
{    AccessConfig accessConfig = new AccessConfig();    Map<String, Object> globalConfig = new HashMap<>();    globalConfig.put(SOLR_ZOOKEEPER, solrComponent.getZookeeperUrl());    accessConfig.setGlobalConfigSupplier(() -> globalConfig);        accessConfig.setIndexSupplier(s -> null);    dao = new SolrDao();    dao.init(accessConfig);    Document actual = dao.getLatest("message_1_bro", TEST_SENSOR);    assertNull(actual);}
public void metron_f7523_0() throws IOException
{    Document actual = dao.getLatest("message_1_test_sensor", TEST_SENSOR);    assertEquals(buildExpectedDocument(TEST_SENSOR, 1), actual);}
public void metron_f7524_0() throws IOException
{    List<GetRequest> requests = new ArrayList<>();    requests.add(buildGetRequest(BRO_SENSOR, 1));    requests.add(buildGetRequest(BRO_SENSOR, 2));    Iterable<Document> actual = dao.getAllLatest(requests);    Document expected1 = buildExpectedDocument(BRO_SENSOR, 1);    assertTrue(Iterables.contains(actual, expected1));    Document expected2 = buildExpectedDocument(BRO_SENSOR, 2);    assertTrue(Iterables.contains(actual, expected2));    assertEquals(2, Iterables.size(actual));}
public void metron_f7525_0() throws IOException
{    List<GetRequest> requests = new ArrayList<>();    GetRequest getRequestOne = buildGetRequest(TEST_SENSOR, 1);            getRequestOne.setIndex(BRO_SENSOR);    requests.add(getRequestOne);    Iterable<Document> actual = dao.getAllLatest(requests);        assertEquals(0, Iterables.size(actual));}
public void metron_f7526_0() throws IOException
{    List<GetRequest> requests = new ArrayList<>();    requests.add(buildGetRequest(TEST_SENSOR, 1));    requests.add(buildGetRequest(BRO_SENSOR, 2));    Iterable<Document> actual = dao.getAllLatest(requests);    assertTrue(Iterables.contains(actual, buildExpectedDocument(TEST_SENSOR, 1)));    assertTrue(Iterables.contains(actual, buildExpectedDocument(BRO_SENSOR, 2)));    assertEquals(2, Iterables.size(actual));}
public void metron_f7527_0() throws IOException
{    List<GetRequest> requests = new ArrayList<>();    requests.add(buildGetRequest(TEST_SENSOR, 1));    GetRequest brokenRequest = new GetRequest();    brokenRequest.setGuid(buildGuid(BRO_SENSOR, 2));    brokenRequest.setSensorType(TEST_SENSOR);    requests.add(brokenRequest);    Iterable<Document> actual = dao.getAllLatest(requests);    assertTrue(Iterables.contains(actual, buildExpectedDocument(TEST_SENSOR, 1)));    assertEquals(1, Iterables.size(actual));}
protected Document metron_f7528_0(String sensor, int i)
{    Map<String, Object> expectedMapOne = new HashMap<>();    expectedMapOne.put("source.type", sensor);    expectedMapOne.put(Constants.Fields.TIMESTAMP.getName(), expectedTimestamp);    expectedMapOne.put(Constants.GUID, buildGuid(sensor, i));    return new Document(expectedMapOne, buildGuid(sensor, i), sensor, expectedTimestamp);}
protected GetRequest metron_f7529_0(String sensor, int i)
{    GetRequest requestOne = new GetRequest();    requestOne.setGuid(buildGuid(sensor, i));    requestOne.setSensorType(sensor);    return requestOne;}
protected static void metron_f7530_0(String collection, String sensorName, Long timestamp) throws IOException, SolrServerException
{    List<Map<String, Object>> inputData = new ArrayList<>();    for (int i = 0; i < 3; ++i) {        final String name = buildGuid(sensorName, i);        HashMap<String, Object> inputMap = new HashMap<>();        inputMap.put("source.type", sensorName);        inputMap.put(Constants.GUID, name);        inputMap.put(Constants.Fields.TIMESTAMP.getName(), timestamp);        inputData.add(inputMap);    }    solrComponent.addDocs(collection, inputData);}
protected static String metron_f7531_0(String sensorName, int i)
{    return "message_" + i + "_" + sensorName;}
public static void metron_f7532_0() throws Exception
{    indexComponent = startIndex();    dao = createDao();        broData = SearchIntegrationTest.broData.replace("source:type", "source.type");    snortData = SearchIntegrationTest.snortData.replace("source:type", "source.type");    solrComponent.addCollection("bro", "./src/main/config/schema/bro");    solrComponent.addCollection("snort", "./src/main/config/schema/snort");    loadTestData();}
public static void metron_f7533_0()
{    SolrClientFactory.close();    if (solrComponent != null) {        solrComponent.stop();    }}
public IndexDao metron_f7534_0()
{    return dao;}
protected static IndexDao metron_f7535_0()
{    AccessConfig config = new AccessConfig();    config.setMaxSearchResults(100);    config.setMaxSearchGroups(100);    config.setGlobalConfigSupplier(() -> new HashMap<String, Object>() {        {            put(SOLR_ZOOKEEPER, solrComponent.getZookeeperUrl());        }    });    config.setIndexSupplier(sensorType -> sensorType);    IndexDao dao = new SolrDao();    dao.init(config);    return dao;}
protected static InMemoryComponent metron_f7536_0() throws Exception
{    solrComponent = new SolrComponent.Builder().build();    solrComponent.start();    return solrComponent;}
protected static void metron_f7537_0() throws ParseException, IOException, SolrServerException
{    JSONArray broArray = (JSONArray) new JSONParser().parse(broData);    solrComponent.addDocs("bro", broArray);    JSONArray snortArray = (JSONArray) new JSONParser().parse(snortData);    solrComponent.addDocs("snort", snortArray);}
public void metron_f7538_0() throws Exception
{        {        Map<String, FieldType> fieldTypes = dao.getColumnMetadata(Collections.singletonList("bro"));                Assert.assertEquals(263, fieldTypes.size());                Assert.assertEquals(FieldType.TEXT, fieldTypes.get("guid"));        Assert.assertEquals(FieldType.TEXT, fieldTypes.get("source.type"));        Assert.assertEquals(FieldType.IP, fieldTypes.get("ip_src_addr"));        Assert.assertEquals(FieldType.INTEGER, fieldTypes.get("ip_src_port"));        Assert.assertEquals(FieldType.BOOLEAN, fieldTypes.get("is_alert"));                Assert.assertEquals(FieldType.TEXT, fieldTypes.get("username"));                Assert.assertEquals(FieldType.FLOAT, fieldTypes.get("score"));                Assert.assertEquals(FieldType.OTHER, fieldTypes.get("location_point"));                Assert.assertEquals(FieldType.OTHER, fieldTypes.get("timestamp"));                Assert.assertEquals(FieldType.TEXT, fieldTypes.get("method"));                Assert.assertEquals(FieldType.TEXT, fieldTypes.get("ttl"));                Assert.assertEquals(null, fieldTypes.get("dgmlen"));                Assert.assertEquals(null, fieldTypes.get("fake.field"));    }        {        Map<String, FieldType> fieldTypes = dao.getColumnMetadata(Collections.singletonList("snort"));        Assert.assertEquals(33, fieldTypes.size());                Assert.assertEquals(FieldType.TEXT, fieldTypes.get("guid"));        Assert.assertEquals(FieldType.TEXT, fieldTypes.get("source.type"));        Assert.assertEquals(FieldType.IP, fieldTypes.get("ip_src_addr"));        Assert.assertEquals(FieldType.INTEGER, fieldTypes.get("ip_src_port"));        Assert.assertEquals(FieldType.BOOLEAN, fieldTypes.get("is_alert"));                Assert.assertEquals(FieldType.INTEGER, fieldTypes.get("dgmlen"));                Assert.assertEquals(FieldType.FLOAT, fieldTypes.get("score"));                Assert.assertEquals(FieldType.OTHER, fieldTypes.get("location_point"));                Assert.assertEquals(FieldType.OTHER, fieldTypes.get("timestamp"));                Assert.assertEquals(FieldType.TEXT, fieldTypes.get("sig_generator"));                Assert.assertEquals(FieldType.INTEGER, fieldTypes.get("ttl"));                Assert.assertEquals(null, fieldTypes.get("username"));                Assert.assertEquals(null, fieldTypes.get("fake.field"));    }}
public void metron_f7539_0() throws Exception
{    Map<String, FieldType> fieldTypes = dao.getColumnMetadata(Arrays.asList("bro", "snort"));            Assert.assertEquals(FieldType.TEXT, fieldTypes.get("guid"));    Assert.assertEquals(FieldType.TEXT, fieldTypes.get("source.type"));    Assert.assertEquals(FieldType.IP, fieldTypes.get("ip_src_addr"));    Assert.assertEquals(FieldType.INTEGER, fieldTypes.get("ip_src_port"));    Assert.assertEquals(FieldType.BOOLEAN, fieldTypes.get("is_alert"));        Assert.assertEquals(FieldType.TEXT, fieldTypes.get("username"));        Assert.assertEquals(FieldType.INTEGER, fieldTypes.get("dgmlen"));        Assert.assertEquals(FieldType.FLOAT, fieldTypes.get("score"));        Assert.assertEquals(FieldType.OTHER, fieldTypes.get("location_point"));        Assert.assertEquals(FieldType.OTHER, fieldTypes.get("timestamp"));        Assert.assertEquals(FieldType.TEXT, fieldTypes.get("method"));        Assert.assertEquals(FieldType.TEXT, fieldTypes.get("sig_generator"));        Assert.assertEquals(FieldType.OTHER, fieldTypes.get("ttl"));        Assert.assertEquals(null, fieldTypes.get("fake.field"));}
public void metron_f7540_0() throws Exception
{    thrown.expect(InvalidSearchException.class);    SearchRequest request = JSONUtils.INSTANCE.load(differentTypeFilterQuery, SearchRequest.class);    SearchResponse response = dao.search(request);}
protected String metron_f7541_0()
{    return Constants.SENSOR_TYPE;}
protected String metron_f7542_0(String sensorType)
{    return sensorType;}
public static void metron_f7543_0() throws Exception
{    solrComponent = new SolrComponent.Builder().build();    solrComponent.start();}
public void metron_f7544_0() throws Exception
{    solrComponent.addCollection(SENSOR_NAME, "./src/test/resources/config/test/conf");    solrComponent.addCollection("error", "./src/main/config/schema/error");    Map<String, Object> globalConfig = createGlobalConfig();    globalConfig.put(HBaseDao.HBASE_TABLE, TABLE_NAME);    globalConfig.put(HBaseDao.HBASE_CF, CF);    CuratorFramework client = ConfigurationsUtils.getClient(solrComponent.getZookeeperUrl());    client.start();    ZKConfigurationsCache cache = new ZKConfigurationsCache(client);    cache.start();    AccessConfig accessConfig = new AccessConfig();    accessConfig.setGlobalConfigSupplier(() -> globalConfig);    accessConfig.setIndexSupplier(s -> s);    accessConfig.setIndexSupplier(IndexingCacheUtil.getIndexLookupFunction(cache, "solr"));    SolrDao dao = new SolrDao();    dao.init(accessConfig);    setDao(dao);}
public void metron_f7545_0()
{    solrComponent.reset();}
public static void metron_f7546_0()
{    SolrClientFactory.close();    solrComponent.stop();}
protected String metron_f7547_0()
{    return SENSOR_NAME;}
private static Map<String, Object> metron_f7548_0()
{    return new HashMap<String, Object>() {        {            put(SOLR_ZOOKEEPER, solrComponent.getZookeeperUrl());        }    };}
protected void metron_f7549_0(String indexName, String sensorType, List<Map<String, Object>> docs) throws Exception
{    solrComponent.addDocs(indexName, docs);}
protected List<Map<String, Object>> metron_f7550_0(String indexName, String sensorType)
{    return solrComponent.getAllIndexedDocs(indexName);}
public void metron_f7551_0() throws Exception
{    Map<String, Object> fields = new HashMap<>();    fields.put("guid", "bro_1");    fields.put("source.type", SENSOR_NAME);    fields.put("ip_src_port", 8010);    fields.put("long_field", 10000);    fields.put("latitude", 48.5839);    fields.put("score", 10.0);    fields.put("is_alert", true);    fields.put("field.location_point", "48.5839,7.7455");    Document document = new Document(fields, "bro_1", SENSOR_NAME, 0L);    getDao().update(document, Optional.of(SENSOR_NAME));    Document indexedDocument = getDao().getLatest("bro_1", SENSOR_NAME);        assertEquals(8, indexedDocument.getDocument().size());}
public void metron_f7552_0() throws Exception
{    String hugeString = StringUtils.repeat("test ", 1_000_000);    String hugeStringTwo = hugeString + "-2";    Map<String, Object> documentMap = new HashMap<>();    documentMap.put("guid", "error_guid");        documentMap.put("raw_message", hugeString);    documentMap.put("raw_message_1", hugeStringTwo);    Document errorDoc = new Document(documentMap, "error", "error", 0L);    getDao().update(errorDoc, Optional.of("error"));        Document latest = getDao().getLatest("error_guid", "error");    @SuppressWarnings("unchecked")    String actual = (String) latest.getDocument().get("raw_message");    assertEquals(actual, hugeString);    String actualTwo = (String) latest.getDocument().get("raw_message_1");    assertEquals(actualTwo, hugeStringTwo);        documentMap.put("error_hash", hugeString);    errorDoc = new Document(documentMap, "error", "error", 0L);    exception.expect(SolrException.class);    exception.expectMessage("Document contains at least one immense term in field=\"error_hash\"");    getDao().update(errorDoc, Optional.of("error"));}
public boolean metron_f7553_0(Object o)
{    ModifiableSolrParams modifiableSolrParams = (ModifiableSolrParams) o;    for (String name : expectedModifiableSolrParams.getParameterNames()) {        String expectedValue = expectedModifiableSolrParams.get(name);        String value = modifiableSolrParams.get(name);        if (expectedValue == null) {            if (value != null) {                return false;            }        } else {            if (!expectedValue.equals(value)) {                return false;            }        }    }    return true;}
public void metron_f7554_0(Description description)
{    description.appendValue(expectedModifiableSolrParams);}
public boolean metron_f7555_0(Object o)
{    List<SolrInputDocument> solrInputDocuments = (List<SolrInputDocument>) o;    for (int i = 0; i < solrInputDocuments.size(); i++) {        SolrInputDocument solrInputDocument = solrInputDocuments.get(i);        for (int j = 0; j < expectedSolrInputDocuments.size(); j++) {            SolrInputDocument expectedSolrInputDocument = expectedSolrInputDocuments.get(j);            if (solrInputDocument.get("guid").equals(expectedSolrInputDocument.get("guid"))) {                for (String field : solrInputDocument.getFieldNames()) {                    Object expectedValue = expectedSolrInputDocument.getField(field).getValue();                    Object value = solrInputDocument.getField(field).getValue();                    boolean matches = expectedValue != null ? expectedValue.equals(value) : value == null;                    if (!matches) {                        return false;                    }                }            }        }    }    return true;}
public void metron_f7556_0(Description description)
{    description.appendValue(expectedSolrInputDocuments);}
public boolean metron_f7557_0(Object o)
{    SolrInputDocument solrInputDocument = (SolrInputDocument) o;    for (String field : solrInputDocument.getFieldNames()) {        Object expectedValue = expectedSolrInputDocument.getField(field).getValue();        Object value = solrInputDocument.getField(field).getValue();        boolean matches = expectedValue != null ? expectedValue.equals(value) : value == null;        if (!matches) {            return false;        }    }    return true;}
public void metron_f7558_0(Description description)
{    description.appendValue(expectedSolrInputDocument);}
public boolean metron_f7559_0(Object o)
{    SolrQuery solrQuery = (SolrQuery) o;    return Objects.equals(solrQuery.getStart(), expectedSolrQuery.getStart()) && Objects.equals(solrQuery.getRows(), expectedSolrQuery.getRows()) && Objects.equals(solrQuery.getQuery(), expectedSolrQuery.getQuery()) && Objects.equals(solrQuery.getSorts(), expectedSolrQuery.getSorts()) && Objects.equals(solrQuery.getFields(), expectedSolrQuery.getFields()) && Arrays.equals(solrQuery.getFacetFields(), expectedSolrQuery.getFacetFields()) && Objects.equals(solrQuery.get("collection"), expectedSolrQuery.get("collection")) && Objects.equals(solrQuery.get("stats"), expectedSolrQuery.get("stats")) && Objects.equals(solrQuery.get("stats.field"), expectedSolrQuery.get("stats.field")) && Objects.equals(solrQuery.get("facet"), expectedSolrQuery.get("facet")) && Objects.equals(solrQuery.get("facet.pivot"), expectedSolrQuery.get("facet.pivot"));}
public void metron_f7560_0(Description description)
{    description.appendValue(expectedSolrQuery);}
public boolean metron_f7561_0(Object o)
{    QueryRequest queryRequest = (QueryRequest) o;    return name.equals(queryRequest.getParams().get("action"));}
public void metron_f7562_0(Description description)
{    description.appendText(name);}
public void metron_f7563_0() throws Exception
{    final String collection = "metron";    String zookeeperUrl = "zookeeperUrl";    MetronSolrClient metronSolrClient = Mockito.spy(new MetronSolrClient(zookeeperUrl));    Mockito.doReturn(new NamedList<Object>() {        {            add("collections", new ArrayList<String>() {                {                    add(collection);                }            });        }    }).when(metronSolrClient).request(argThat(new CollectionRequestMatcher(CollectionParams.CollectionAction.LIST.name())), (String) isNull());    metronSolrClient.createCollection(collection, 1, 1);    verify(metronSolrClient, times(1)).request(argThat(new CollectionRequestMatcher(CollectionParams.CollectionAction.LIST.name())), (String) isNull());    verify(metronSolrClient, times(0)).request(argThat(new CollectionRequestMatcher(CollectionParams.CollectionAction.CREATE.name())), (String) isNull());    metronSolrClient = Mockito.spy(new MetronSolrClient(zookeeperUrl));    Mockito.doReturn(new NamedList<Object>() {        {            add("collections", new ArrayList<String>());        }    }).when(metronSolrClient).request(argThat(new CollectionRequestMatcher(CollectionParams.CollectionAction.LIST.name())), (String) isNull());    Mockito.doReturn(new NamedList<>()).when(metronSolrClient).request(argThat(new CollectionRequestMatcher(CollectionParams.CollectionAction.CREATE.name())), (String) isNull());    metronSolrClient.createCollection(collection, 1, 1);    verify(metronSolrClient, times(1)).request(argThat(new CollectionRequestMatcher(CollectionParams.CollectionAction.LIST.name())), (String) isNull());    verify(metronSolrClient, times(1)).request(argThat(new CollectionRequestMatcher(CollectionParams.CollectionAction.CREATE.name())), (String) isNull());}
public boolean metron_f7564_0(Object o)
{    QueryRequest queryRequest = (QueryRequest) o;    return name.equals(queryRequest.getParams().get("action"));}
public void metron_f7565_0(Description description)
{    description.appendText(name);}
public boolean metron_f7566_0(Object o)
{    List<SolrInputDocument> docs = (List<SolrInputDocument>) o;    int size = docs.size();    if (size != expectedDocs.size()) {        return false;    }    for (int i = 0; i < size; ++i) {        SolrInputDocument doc = docs.get(i);        Map<String, Object> expectedDoc = expectedDocs.get(i);        for (Map.Entry<String, Object> expectedKv : expectedDoc.entrySet()) {            if (!expectedKv.getValue().equals(doc.get(expectedKv.getKey()).getValue())) {                return false;            }        }    }    return true;}
public void metron_f7567_0(Description description)
{    description.appendText(expectedDocs.toString());}
public void metron_f7568_0() throws Exception
{    IndexingConfigurations configurations = SampleUtil.getSampleIndexingConfigs();    JSONObject message1 = new JSONObject();    message1.put(Constants.GUID, "guid-1");    message1.put(Constants.SENSOR_TYPE, "test");    message1.put("intField", 100);    message1.put("doubleField", 100.0);    JSONObject message2 = new JSONObject();    message2.put(Constants.GUID, "guid-2");    message2.put(Constants.SENSOR_TYPE, "test");    message2.put("intField", 200);    message2.put("doubleField", 200.0);    List<BulkMessage<JSONObject>> messages = new ArrayList<>();    messages.add(new BulkMessage<>("message1", message1));    messages.add(new BulkMessage<>("message2", message2));    String collection = "metron";    MetronSolrClient solr = Mockito.mock(MetronSolrClient.class);    SolrWriter writer = new SolrWriter().withMetronSolrClient(solr);    writer.init(null, new IndexingWriterConfiguration("solr", configurations));    verify(solr, times(1)).setDefaultCollection(collection);    collection = "metron2";    Map<String, Object> globalConfig = configurations.getGlobalConfig();    globalConfig.put("solr.collection", collection);    configurations.updateGlobalConfig(globalConfig);    writer = new SolrWriter().withMetronSolrClient(solr);    writer.init(null, new IndexingWriterConfiguration("solr", configurations));    verify(solr, times(1)).setDefaultCollection(collection);    writer.write("test", new IndexingWriterConfiguration("solr", configurations), messages);    verify(solr, times(1)).add(eq("yaf"), argThat(new SolrInputDocumentMatcher(ImmutableList.of(message1, message2))));    verify(solr, times(1)).commit("yaf", (boolean) SolrWriter.SolrProperties.COMMIT_WAIT_FLUSH.defaultValue.get(), (boolean) SolrWriter.SolrProperties.COMMIT_WAIT_SEARCHER.defaultValue.get(), (boolean) SolrWriter.SolrProperties.COMMIT_SOFT.defaultValue.get());}
public void metron_f7569_0() throws Exception
{    String expected = "test";    Assert.assertEquals(expected, SolrWriter.SolrProperties.ZOOKEEPER_QUORUM.coerceOrDefaultOrExcept(ImmutableMap.of(SolrWriter.SolrProperties.ZOOKEEPER_QUORUM.name, expected), String.class));}
public void metron_f7570_0() throws Exception
{    SolrWriter.SolrProperties.ZOOKEEPER_QUORUM.coerceOrDefaultOrExcept(new HashMap<>(), String.class);}
public void metron_f7571_0() throws Exception
{    Object expected = false;    Assert.assertEquals(expected, SolrWriter.SolrProperties.COMMIT_PER_BATCH.coerceOrDefaultOrExcept(ImmutableMap.of(SolrWriter.SolrProperties.COMMIT_PER_BATCH.name, false), Boolean.class));}
public void metron_f7572_0() throws Exception
{    Assert.assertEquals(SolrWriter.SolrProperties.COMMIT_PER_BATCH.defaultValue.get(), SolrWriter.SolrProperties.COMMIT_PER_BATCH.coerceOrDefaultOrExcept(new HashMap<>(), Boolean.class));    Assert.assertEquals(SolrWriter.SolrProperties.COMMIT_PER_BATCH.defaultValue.get(), SolrWriter.SolrProperties.COMMIT_PER_BATCH.coerceOrDefaultOrExcept(ImmutableMap.of(SolrWriter.SolrProperties.COMMIT_PER_BATCH.name, new DummyClass()), Boolean.class));}
public void metron_f7573_0() throws Exception
{    Object expected = true;    Assert.assertEquals(expected, SolrWriter.SolrProperties.COMMIT_SOFT.coerceOrDefaultOrExcept(ImmutableMap.of(SolrWriter.SolrProperties.COMMIT_SOFT.name, expected), Boolean.class));}
public void metron_f7574_0() throws Exception
{    Assert.assertEquals(SolrWriter.SolrProperties.COMMIT_SOFT.defaultValue.get(), SolrWriter.SolrProperties.COMMIT_SOFT.coerceOrDefaultOrExcept(new HashMap<>(), Boolean.class));    Assert.assertEquals(SolrWriter.SolrProperties.COMMIT_SOFT.defaultValue.get(), SolrWriter.SolrProperties.COMMIT_SOFT.coerceOrDefaultOrExcept(ImmutableMap.of(SolrWriter.SolrProperties.COMMIT_SOFT.name, new DummyClass()), Boolean.class));}
public void metron_f7575_0() throws Exception
{    Object expected = false;    Assert.assertEquals(expected, SolrWriter.SolrProperties.COMMIT_WAIT_FLUSH.coerceOrDefaultOrExcept(ImmutableMap.of(SolrWriter.SolrProperties.COMMIT_WAIT_FLUSH.name, expected), Boolean.class));}
public void metron_f7576_0() throws Exception
{    Assert.assertEquals(SolrWriter.SolrProperties.COMMIT_WAIT_FLUSH.defaultValue.get(), SolrWriter.SolrProperties.COMMIT_WAIT_FLUSH.coerceOrDefaultOrExcept(new HashMap<>(), Boolean.class));    Assert.assertEquals(SolrWriter.SolrProperties.COMMIT_WAIT_FLUSH.defaultValue.get(), SolrWriter.SolrProperties.COMMIT_WAIT_FLUSH.coerceOrDefaultOrExcept(ImmutableMap.of(SolrWriter.SolrProperties.COMMIT_WAIT_FLUSH.name, new DummyClass()), Boolean.class));}
public void metron_f7577_0() throws Exception
{    Object expected = false;    Assert.assertEquals(expected, SolrWriter.SolrProperties.COMMIT_WAIT_SEARCHER.coerceOrDefaultOrExcept(ImmutableMap.of(SolrWriter.SolrProperties.COMMIT_WAIT_SEARCHER.name, expected), Boolean.class));}
public void metron_f7578_0() throws Exception
{    Assert.assertEquals(SolrWriter.SolrProperties.COMMIT_WAIT_SEARCHER.defaultValue.get(), SolrWriter.SolrProperties.COMMIT_WAIT_SEARCHER.coerceOrDefaultOrExcept(new HashMap<>(), Boolean.class));    Assert.assertEquals(SolrWriter.SolrProperties.COMMIT_WAIT_SEARCHER.defaultValue.get(), SolrWriter.SolrProperties.COMMIT_WAIT_SEARCHER.coerceOrDefaultOrExcept(ImmutableMap.of(SolrWriter.SolrProperties.COMMIT_WAIT_SEARCHER.name, new DummyClass()), Boolean.class));}
public void metron_f7579_0() throws Exception
{    Object expected = "mycollection";    Assert.assertEquals(expected, SolrWriter.SolrProperties.DEFAULT_COLLECTION.coerceOrDefaultOrExcept(ImmutableMap.of(SolrWriter.SolrProperties.DEFAULT_COLLECTION.name, expected), String.class));}
public void metron_f7580_0() throws Exception
{    Assert.assertEquals(SolrWriter.SolrProperties.DEFAULT_COLLECTION.defaultValue.get(), SolrWriter.SolrProperties.DEFAULT_COLLECTION.coerceOrDefaultOrExcept(new HashMap<>(), String.class));}
public void metron_f7581_0() throws Exception
{    Object expected = new HashMap<String, Object>() {        {            put("name", "metron");        }    };    Assert.assertEquals(expected, SolrWriter.SolrProperties.HTTP_CONFIG.coerceOrDefaultOrExcept(ImmutableMap.of(SolrWriter.SolrProperties.HTTP_CONFIG.name, expected), Map.class));}
public void metron_f7582_0() throws Exception
{    Assert.assertEquals(SolrWriter.SolrProperties.HTTP_CONFIG.defaultValue.get(), SolrWriter.SolrProperties.HTTP_CONFIG.coerceOrDefaultOrExcept(new HashMap<>(), Map.class));    Assert.assertEquals(SolrWriter.SolrProperties.HTTP_CONFIG.defaultValue.get(), SolrWriter.SolrProperties.HTTP_CONFIG.coerceOrDefaultOrExcept(ImmutableMap.of(SolrWriter.SolrProperties.HTTP_CONFIG.name, new DummyClass()), Map.class));}
public FieldNameConverter metron_f7583_0()
{    return fieldNameConverter;}
public InMemoryComponent metron_f7584_0(final Properties topologyProperties) throws Exception
{    SolrComponent solrComponent = new SolrComponent.Builder().addInitialCollection(collection, "../metron-solr-common/src/main/config/schema/yaf").withPostStartCallback(new Function<SolrComponent, Void>() {        @Nullable        @Override        public Void apply(@Nullable SolrComponent solrComponent) {            topologyProperties.setProperty("solr.zk", solrComponent.getZookeeperUrl());            try {                String testZookeeperUrl = topologyProperties.getProperty(ZKServerComponent.ZOOKEEPER_PROPERTY);                Configurations configurations = SampleUtil.getSampleConfigs();                Map<String, Object> globalConfig = configurations.getGlobalConfig();                globalConfig.put(SolrConstants.SOLR_ZOOKEEPER, solrComponent.getZookeeperUrl());                ConfigurationsUtils.writeGlobalConfigToZookeeper(JSONUtils.INSTANCE.toJSONPretty(globalConfig), testZookeeperUrl);            } catch (Exception e) {                e.printStackTrace();            }            return null;        }    }).build();    return solrComponent;}
public Void metron_f7585_0(@Nullable SolrComponent solrComponent)
{    topologyProperties.setProperty("solr.zk", solrComponent.getZookeeperUrl());    try {        String testZookeeperUrl = topologyProperties.getProperty(ZKServerComponent.ZOOKEEPER_PROPERTY);        Configurations configurations = SampleUtil.getSampleConfigs();        Map<String, Object> globalConfig = configurations.getGlobalConfig();        globalConfig.put(SolrConstants.SOLR_ZOOKEEPER, solrComponent.getZookeeperUrl());        ConfigurationsUtils.writeGlobalConfigToZookeeper(JSONUtils.INSTANCE.toJSONPretty(globalConfig), testZookeeperUrl);    } catch (Exception e) {        e.printStackTrace();    }    return null;}
public Processor<List<Map<String, Object>>> metron_f7586_0(final List<byte[]> inputMessages)
{    return new Processor<List<Map<String, Object>>>() {        List<Map<String, Object>> docs = null;        List<byte[]> errors = null;        @Override        public ReadinessState process(ComponentRunner runner) {            SolrComponent solrComponent = runner.getComponent("search", SolrComponent.class);            KafkaComponent kafkaComponent = runner.getComponent("kafka", KafkaComponent.class);            if (solrComponent.hasCollection(collection)) {                docs = solrComponent.getAllIndexedDocs(collection);                if (docs.size() < inputMessages.size()) {                    errors = kafkaComponent.readMessages(ERROR_TOPIC);                    if (errors.size() > 0 && errors.size() + docs.size() == inputMessages.size()) {                        return ReadinessState.READY;                    }                    return ReadinessState.NOT_READY;                } else {                    return ReadinessState.READY;                }            } else {                return ReadinessState.NOT_READY;            }        }        @Override        public ProcessorResult<List<Map<String, Object>>> getResult() {            ProcessorResult.Builder<List<Map<String, Object>>> builder = new ProcessorResult.Builder();            return builder.withResult(docs).withProcessErrors(errors).build();        }    };}
public ReadinessState metron_f7587_0(ComponentRunner runner)
{    SolrComponent solrComponent = runner.getComponent("search", SolrComponent.class);    KafkaComponent kafkaComponent = runner.getComponent("kafka", KafkaComponent.class);    if (solrComponent.hasCollection(collection)) {        docs = solrComponent.getAllIndexedDocs(collection);        if (docs.size() < inputMessages.size()) {            errors = kafkaComponent.readMessages(ERROR_TOPIC);            if (errors.size() > 0 && errors.size() + docs.size() == inputMessages.size()) {                return ReadinessState.READY;            }            return ReadinessState.NOT_READY;        } else {            return ReadinessState.READY;        }    } else {        return ReadinessState.NOT_READY;    }}
public ProcessorResult<List<Map<String, Object>>> metron_f7588_0()
{    ProcessorResult.Builder<List<Map<String, Object>>> builder = new ProcessorResult.Builder();    return builder.withResult(docs).withProcessErrors(errors).build();}
public void metron_f7589_0(Properties topologyProperties)
{    topologyProperties.setProperty("ra_indexing_writer_class_name", "org.apache.metron.solr.writer.SolrWriter");    topologyProperties.setProperty("ra_indexing_kafka_start", "UNCOMMITTED_EARLIEST");    topologyProperties.setProperty("ra_indexing_workers", "1");    topologyProperties.setProperty("ra_indexing_acker_executors", "0");    topologyProperties.setProperty("ra_indexing_topology_max_spout_pending", "");    topologyProperties.setProperty("ra_indexing_kafka_spout_parallelism", "1");    topologyProperties.setProperty("ra_indexing_writer_parallelism", "1");}
public String metron_f7590_0(String field)
{    return field.replaceFirst("_[dfils]$", "");}
public String metron_f7591_0()
{    return "./src/main/config/solr.properties.j2";}
public String metron_f7592_0()
{    return "../../metron-indexing/metron-indexing-storm/src/main/flux/indexing/random_access/remote.yaml";}
public String metron_f7593_0()
{    return fieldName;}
public static List<FieldsConfiguration> metron_f7594_0(String... configs)
{    List<FieldsConfiguration> ret = new ArrayList<>();    for (String config : configs) {        ret.add(FieldsConfiguration.valueOf(config.toUpperCase()));    }    return ret;}
public static List<FieldsConfiguration> metron_f7595_0(List<String> configs)
{    List<FieldsConfiguration> ret = new ArrayList<>();    for (String config : configs) {        ret.add(FieldsConfiguration.valueOf(config.toUpperCase()));    }    return ret;}
public static Fields metron_f7596_0(Iterable<FieldsConfiguration> configs)
{    List<String> fields = new ArrayList<>();    for (FieldsConfiguration config : configs) {        fields.add(config.fieldName);    }    return new Fields(fields);}
public List<Object> metron_f7597_0(ConsumerRecord<K, V> consumerRecord)
{    Values ret = new Values();    for (FieldsConfiguration config : configurations) {        ret.add(config.recordExtractor.apply(consumerRecord));    }    return ret;}
public Fields metron_f7598_0(String s)
{    return fields;}
public List<String> metron_f7599_0()
{    return DEFAULT_STREAM;}
private static Subscription metron_f7600_0(String topicOrSubscription)
{    if (StringUtils.isEmpty(topicOrSubscription)) {        throw new IllegalArgumentException("Topic name is invalid (empty or null): " + topicOrSubscription);    }    int length = topicOrSubscription.length();    if (topicOrSubscription.charAt(0) == '/' && topicOrSubscription.charAt(length - 1) == '/') {                String substr = topicOrSubscription.substring(1, length - 1);        return new PatternSubscription(Pattern.compile(substr));    } else {        return new NamedSubscription(topicOrSubscription);    }}
private static Class<Deserializer<T>> metron_f7601_0(Optional<String> deserializerClass, String defaultDeserializerClass)
{    try {        return (Class<Deserializer<T>>) Class.forName(deserializerClass.orElse(defaultDeserializerClass));    } catch (Exception e) {        throw new IllegalStateException("Unable to create a deserializer: " + deserializerClass.orElse(defaultDeserializerClass) + ": " + e.getMessage(), e);    }}
private static String metron_f7602_0(String zkQuorum, Map<String, Object> kafkaProps)
{    String brokers = (String) kafkaProps.get(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG);    if (brokers == null) {        try {            return Joiner.on(",").join(KafkaUtils.INSTANCE.getBrokersFromZookeeper(zkQuorum));        } catch (Exception e) {            throw new IllegalStateException("Unable to find the bootstrap servers: " + e.getMessage(), e);        }    }    return brokers;}
public static StormKafkaSpout<K, V> metron_f7603_0(String topic, String zkQuorum, List<String> fieldsConfiguration, Map<String, Object> kafkaProps)
{    Map<String, Object> spoutConfig = SpoutConfiguration.separate(kafkaProps);    SimpleStormKafkaBuilder<K, V> builder = new SimpleStormKafkaBuilder<>(kafkaProps, topic, zkQuorum, fieldsConfiguration);    SpoutConfiguration.configure(builder, spoutConfig);    return new StormKafkaSpout<>(builder);}
public static Map<String, Object> metron_f7604_0(Map<String, Object> config)
{    Map<String, Object> ret = new HashMap<>();    for (SpoutConfiguration spoutConfig : SpoutConfiguration.values()) {        if (config.containsKey(spoutConfig.key)) {            Object val = config.get(spoutConfig.key);            config.remove(spoutConfig.key);            ret.put(spoutConfig.key, val);        }    }    return ret;}
public static KafkaSpoutConfig.Builder metron_f7605_0(KafkaSpoutConfig.Builder<K, V> builder, Map<String, Object> config)
{    for (SpoutConfiguration spoutConfig : SpoutConfiguration.values()) {        if (config.containsKey(spoutConfig.key)) {            Container container = new Container(config, builder, config.get(spoutConfig.key));            spoutConfig.consumer.accept(container);        }    }    return builder;}
public static List<String> metron_f7606_0()
{    List<String> ret = new ArrayList<>();    for (SpoutConfiguration spoutConfig : SpoutConfiguration.values()) {        ret.add(spoutConfig.key);    }    ret.add(ConsumerConfig.GROUP_ID_CONFIG);    ret.add(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG);    ret.add(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG);    return ret;}
public void metron_f7607_1()
{    try {        super.deactivate();    } catch (WakeupException we) {                    } finally {        isShutdown.set(true);    }}
public void metron_f7608_1()
{    try {        if (!isShutdown.get()) {            super.close();            isShutdown.set(true);        }    } catch (WakeupException we) {                    } catch (IllegalStateException ise) {        if (ise.getMessage().contains("This consumer has already been closed")) {                    } else {            throw ise;        }    }}
public static int metron_f7609_0(Object messageIdObj)
{    KafkaSpoutMessageId messageId = (KafkaSpoutMessageId) messageIdObj;    return messageId.getTopicPartition().partition();}
public List<Integer> metron_f7610_0(String streamId, List<Object> tuple, Object messageId)
{    List<Object> t = _callback.apply(tuple, _context.cloneContext().with(EmitContext.Type.PARTITION, getPartition(messageId)).with(EmitContext.Type.STREAM_ID, streamId));    return _delegate.emit(streamId, t, messageId);}
public List<Integer> metron_f7611_0(List<Object> tuple, Object messageId)
{    List<Object> t = _callback.apply(tuple, _context.cloneContext().with(EmitContext.Type.PARTITION, getPartition(messageId)));    return _delegate.emit(t, messageId);}
public List<Integer> metron_f7612_0(List<Object> tuple)
{    List<Object> t = _callback.apply(tuple, _context.cloneContext());    return _delegate.emit(t);}
public List<Integer> metron_f7613_0(String streamId, List<Object> tuple)
{    List<Object> t = _callback.apply(tuple, _context.cloneContext().with(EmitContext.Type.STREAM_ID, streamId));    return _delegate.emit(streamId, t);}
public void metron_f7614_0(int taskId, String streamId, List<Object> tuple, Object messageId)
{    List<Object> t = _callback.apply(tuple, _context.cloneContext().with(EmitContext.Type.STREAM_ID, streamId).with(EmitContext.Type.PARTITION, getPartition(messageId)).with(EmitContext.Type.TASK_ID, taskId));    _delegate.emitDirect(taskId, streamId, t, messageId);}
public void metron_f7615_0(int taskId, List<Object> tuple, Object messageId)
{    List<Object> t = _callback.apply(tuple, _context.cloneContext().with(EmitContext.Type.PARTITION, getPartition(messageId)).with(EmitContext.Type.TASK_ID, taskId));    _delegate.emitDirect(taskId, t, messageId);}
public void metron_f7616_0(int taskId, String streamId, List<Object> tuple)
{    List<Object> t = _callback.apply(tuple, _context.cloneContext().with(EmitContext.Type.STREAM_ID, streamId).with(EmitContext.Type.TASK_ID, taskId));    _delegate.emitDirect(taskId, streamId, t);}
public void metron_f7617_0(int taskId, List<Object> tuple)
{    List<Object> t = _callback.apply(tuple, _context.cloneContext().with(EmitContext.Type.TASK_ID, taskId));    _delegate.emitDirect(taskId, t);}
public void metron_f7618_0(TopologyContext context)
{    _callback = createCallback(callbackClazz);    _context = new EmitContext().with(EmitContext.Type.SPOUT_CONFIG, _spoutConfig).with(EmitContext.Type.UUID, context.getStormId());    _callback.initialize(_context);}
private static Class<? extends Callback> metron_f7619_0(String callbackClass)
{    try {        return (Class<? extends Callback>) Callback.class.forName(callbackClass);    } catch (ClassNotFoundException e) {        throw new RuntimeException(callbackClass + " not found", e);    }}
protected Callback metron_f7620_0(Class<? extends Callback> callbackClass)
{    try {        return callbackClass.getConstructor().newInstance();    } catch (InstantiationException | NoSuchMethodException | InvocationTargetException e) {        throw new RuntimeException("Unable to instantiate callback", e);    } catch (IllegalAccessException e) {        throw new RuntimeException("Illegal access", e);    }}
public void metron_f7621_0(Map conf, final TopologyContext context, final SpoutOutputCollector collector)
{    if (_callback == null) {        initialize(context);    }    super.open(conf, context, new CallbackCollector(_callback, collector, _context.cloneContext().with(EmitContext.Type.OPEN_CONFIG, conf).with(EmitContext.Type.TOPOLOGY_CONTEXT, context)));}
public void metron_f7622_0()
{    super.close();    if (_callback != null) {        try {            _callback.close();        } catch (Exception e) {            throw new IllegalStateException("Unable to close callback", e);        }    }}
public Class<?> metron_f7623_0()
{    return clazz;}
public EmitContext metron_f7624_0(Type t, T o)
{    _context.put(t, t.clazz().cast(o));    return this;}
public void metron_f7625_0(Type t, T o)
{    with(t, o);}
public T metron_f7626_0(Type t)
{    Object o = _context.get(t);    if (o == null) {        return null;    } else {        return (T) o;    }}
public EmitContext metron_f7627_0()
{    try {        return (EmitContext) this.clone();    } catch (CloneNotSupportedException e) {        throw new RuntimeException("Unable to clone emit context.", e);    }}
protected Object metron_f7628_0() throws CloneNotSupportedException
{    EmitContext context = new EmitContext(_context.clone());    return context;}
public void metron_f7629_0()
{    Map<String, Object> config = new HashMap<String, Object>() {        {            put(SpoutConfiguration.FIRST_POLL_OFFSET_STRATEGY.key, "UNCOMMITTED_EARLIEST");            put(SpoutConfiguration.OFFSET_COMMIT_PERIOD_MS.key, "1000");            put("group.id", "foobar");        }    };    Map<String, Object> spoutConfig = SpoutConfiguration.separate(config);    Assert.assertTrue(spoutConfig.containsKey(SpoutConfiguration.FIRST_POLL_OFFSET_STRATEGY.key));    Assert.assertEquals(spoutConfig.get(SpoutConfiguration.FIRST_POLL_OFFSET_STRATEGY.key), "UNCOMMITTED_EARLIEST");    Assert.assertTrue(spoutConfig.containsKey(SpoutConfiguration.OFFSET_COMMIT_PERIOD_MS.key));    Assert.assertEquals(spoutConfig.get(SpoutConfiguration.OFFSET_COMMIT_PERIOD_MS.key), "1000");    Assert.assertEquals(2, spoutConfig.size());    Assert.assertEquals(1, config.size());    Assert.assertEquals(config.get("group.id"), "foobar");}
public void metron_f7630_0()
{    Map<String, Object> config = new HashMap<String, Object>() {        {            put(SpoutConfiguration.OFFSET_COMMIT_PERIOD_MS.key, "1000");            put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "foo:1234");            put("group.id", "foobar");        }    };    Map<String, Object> spoutConfig = SpoutConfiguration.separate(config);    KafkaSpoutConfig.Builder<Object, Object> builder = new SimpleStormKafkaBuilder(config, "topic", null);    SpoutConfiguration.configure(builder, spoutConfig);    KafkaSpoutConfig c = builder.build();    Assert.assertEquals(1000, c.getOffsetsCommitPeriodMs());}
public long metron_f7631_0()
{    return this.period;}
public long metron_f7632_0()
{    return this.delay;}
public TimeUnit metron_f7633_0()
{    return this.timeUnit;}
public boolean metron_f7634_0()
{    boolean expired = System.nanoTime() - this.start >= this.periodNanos;    if (expired) {        this.start = System.nanoTime();    }    return expired;}
public int metron_f7635_0(RetrySchedule entry1, RetrySchedule entry2)
{    int result = Long.valueOf(entry1.nextRetryTimeNanos()).compareTo(entry2.nextRetryTimeNanos());    if (result == 0) {                        result = entry1.hashCode() - entry2.hashCode();    }    return result;}
public void metron_f7636_1()
{    nextRetryTimeNanos = nextTime(msgId);    }
public boolean metron_f7637_0(long currentTimeNanos)
{    return nextRetryTimeNanos <= currentTimeNanos;}
public String metron_f7638_0()
{    return "RetrySchedule{" + "msgId=" + msgId + ", nextRetryTimeNanos=" + nextRetryTimeNanos + '}';}
public KafkaSpoutMessageId metron_f7639_0()
{    return msgId;}
public long metron_f7640_0()
{    return nextRetryTimeNanos;}
public static TimeInterval metron_f7641_0(long length)
{    return new TimeInterval(length, TimeUnit.SECONDS);}
public static TimeInterval metron_f7642_0(long length)
{    return new TimeInterval(length, TimeUnit.MILLISECONDS);}
public static TimeInterval metron_f7643_0(long length)
{    return new TimeInterval(length, TimeUnit.MICROSECONDS);}
public long metron_f7644_0()
{    return lengthNanos;}
public TimeUnit metron_f7645_0()
{    return timeUnit;}
public String metron_f7646_0()
{    return "TimeInterval{" + "length=" + length + ", timeUnit=" + timeUnit + '}';}
public Map<TopicPartition, Long> metron_f7647_1()
{    final Map<TopicPartition, Long> tpToEarliestRetriableOffset = new HashMap<>();    final long currentTimeNanos = System.nanoTime();    for (RetrySchedule retrySchedule : retrySchedules) {        if (retrySchedule.retry(currentTimeNanos)) {            final KafkaSpoutMessageId msgId = retrySchedule.msgId;            final TopicPartition tpForMessage = new TopicPartition(msgId.topic(), msgId.partition());            final Long currentLowestOffset = tpToEarliestRetriableOffset.get(tpForMessage);            if (currentLowestOffset != null) {                tpToEarliestRetriableOffset.put(tpForMessage, Math.min(currentLowestOffset, msgId.offset()));            } else {                tpToEarliestRetriableOffset.put(tpForMessage, msgId.offset());            }        } else {                        break;        }    }        return tpToEarliestRetriableOffset;}
public boolean metron_f7648_1(KafkaSpoutMessageId msgId)
{    boolean retry = false;    if (isScheduled(msgId)) {        final long currentTimeNanos = System.nanoTime();        for (RetrySchedule retrySchedule : retrySchedules) {            if (retrySchedule.retry(currentTimeNanos)) {                if (retrySchedule.msgId.equals(msgId)) {                    retry = true;                                                            break;                }            } else {                                                break;            }        }    }    return retry;}
public boolean metron_f7649_0(KafkaSpoutMessageId msgId)
{    return toRetryMsgs.contains(msgId);}
public boolean metron_f7650_1(KafkaSpoutMessageId msgId)
{    boolean removed = false;    if (isScheduled(msgId)) {        toRetryMsgs.remove(msgId);        for (Iterator<RetrySchedule> iterator = retrySchedules.iterator(); iterator.hasNext(); ) {            final RetrySchedule retrySchedule = iterator.next();            if (retrySchedule.msgId().equals(msgId)) {                iterator.remove();                removed = true;                                break;            }        }    }        LOG.trace("Current state {}", retrySchedules);    return removed;}
public boolean metron_f7651_1(Collection<TopicPartition> topicPartitions)
{    boolean result = false;    for (Iterator<RetrySchedule> rsIterator = retrySchedules.iterator(); rsIterator.hasNext(); ) {        final RetrySchedule retrySchedule = rsIterator.next();        final KafkaSpoutMessageId msgId = retrySchedule.msgId;        final TopicPartition tpRetry = new TopicPartition(msgId.topic(), msgId.partition());        if (!topicPartitions.contains(tpRetry)) {            rsIterator.remove();            toRetryMsgs.remove(msgId);                        LOG.trace("Current state {}", retrySchedules);            result = true;        }    }    return result;}
public boolean metron_f7652_1(KafkaSpoutMessageId msgId)
{    if (msgId.numFails() > maxRetries) {                return false;    } else {                remove(msgId);        final RetrySchedule retrySchedule = new RetrySchedule(msgId, nextTime(msgId));        retrySchedules.add(retrySchedule);        toRetryMsgs.add(msgId);                LOG.trace("Current state {}", retrySchedules);        return true;    }}
public int metron_f7653_0()
{    int count = 0;    final long currentTimeNanos = System.nanoTime();    for (RetrySchedule retrySchedule : retrySchedules) {        if (retrySchedule.retry(currentTimeNanos)) {            ++count;        } else {                        break;        }    }    return count;}
public KafkaSpoutMessageId metron_f7654_0(ConsumerRecord<?, ?> record)
{    KafkaSpoutMessageId msgId = new KafkaSpoutMessageId(record);    if (isScheduled(msgId)) {        for (KafkaSpoutMessageId originalMsgId : toRetryMsgs) {            if (originalMsgId.equals(msgId)) {                return originalMsgId;            }        }    }    return msgId;}
private long metron_f7655_0(KafkaSpoutMessageId msgId)
{    Validate.isTrue(msgId.numFails() > 0, "nextTime assumes the message has failed at least once");    final long currentTimeNanos = System.nanoTime();    final long nextTimeNanos =     msgId.numFails() == 1 ? currentTimeNanos + initialDelay.lengthNanos : currentTimeNanos + delayPeriod.lengthNanos * (long) (Math.pow(2, msgId.numFails() - 1));    return Math.min(nextTimeNanos, currentTimeNanos + maxDelay.lengthNanos);}
public String metron_f7656_0()
{    return toStringImpl();}
private String metron_f7657_0()
{        return "KafkaSpoutRetryExponentialBackoff{" + "delay=" + initialDelay + ", ratio=" + delayPeriod + ", maxRetries=" + maxRetries + ", maxRetryDelay=" + maxDelay + '}';}
public void metron_f7658_0() throws InterruptedException
{    Timer t = new Timer(0, 2, TimeUnit.SECONDS);    Thread.sleep(1000);    Assert.assertFalse(t.isExpiredResetOnTrue());    Thread.sleep(1000);    Assert.assertTrue(t.isExpiredResetOnTrue());}
public void metron_f7659_0()
{    MockitoAnnotations.initMocks(this);}
public boolean metron_f7660_0(Object o)
{    Fields fields = (Fields) o;    return expectedFields.equals(fields.toList());}
public void metron_f7661_0(Description description)
{    description.appendText(String.format("[%s]", Joiner.on(",").join(expectedFields)));}
public void metron_f7662_0(JSONObject message)
{    ImmutableSet keys = ImmutableSet.copyOf(message.keySet());    for (Object key : keys) {        if (key.toString().endsWith(".ts")) {            message.remove(key);        }    }}
public void metron_f7663_0() throws ParseException
{    JSONParser parser = new JSONParser();    sampleMessage = (JSONObject) parser.parse(sampleMessageString);    geoMessage = (JSONObject) parser.parse(geoMessageString);    hostMessage = (JSONObject) parser.parse(hostMessageString);    hbaseEnrichmentMessage = (JSONObject) parser.parse(hbaseEnrichmentMessageString);    streamIds.add("geo");    streamIds.add("stellar");    streamIds.add("host");    streamIds.add("hbaseEnrichment");    joinStreamIds.add("geo:");    joinStreamIds.add("stellar:");    joinStreamIds.add("stellar:numeric");    joinStreamIds.add("stellar:dst_enrichment");    joinStreamIds.add("stellar:src_enrichment");    joinStreamIds.add("stellar:error_test");    joinStreamIds.add("host:");    joinStreamIds.add("hbaseEnrichment:");    joinStreamIds.add("message:");}
public void metron_f7665_0(Tuple input)
{    System.out.println("---------[RECEIVED] " + input);}
public byte[] metron_f7667_0(String s)
{    return _underlying.convert(s);}
public byte[] metron_f7668_0(String s)
{    int len = s.length();    byte[] data = new byte[len / 2];    for (int i = 0; i < len; i += 2) {        data[i / 2] = (byte) ((Character.digit(s.charAt(i), 16) << 4) + Character.digit(s.charAt(i + 1), 16));    }    return data;}
public boolean metron_f7669_0(Object o)
{    Values values = (Values) o;    JSONObject actual = (JSONObject) values.get(0);    actual.remove("timestamp");    expected.remove("timestamp");    actual.remove("stack");    expected.remove("stack");    actual.remove("guid");    expected.remove("guid");    return actual.equals(expected);}
public List<String> metron_f7670_0(String filename) throws IOException
{    System.out.println("Reading stream from " + filename);    List<String> lines = new LinkedList<String>();    InputStream stream = null;    if (new File(filename).exists()) {        stream = new FileInputStream(filename);    } else {        stream = Thread.currentThread().getContextClassLoader().getResourceAsStream(filename);    }    DataInputStream in = new DataInputStream(stream);    BufferedReader br = new BufferedReader(new InputStreamReader(in, StandardCharsets.UTF_8));    String strLine;    while ((strLine = br.readLine()) != null) {                lines.add(strLine);    }    return lines;}
public GenericInternalTestSpout metron_f7671_0(String filename)
{    if (filename != null && filename.length() > 0 && filename.charAt(0) == '$') {        filename = Iterables.getLast(Splitter.on("}").split(filename));    }    _filename = filename;    return this;}
public GenericInternalTestSpout metron_f7672_0(Integer delay)
{    _delay = delay;    return this;}
public GenericInternalTestSpout metron_f7673_0(Boolean repeating)
{    _repeating = repeating;    return this;}
public GenericInternalTestSpout metron_f7674_0(String converter)
{    if (converter == null) {        _converter = BinaryConverters.DEFAULT;    } else {        _converter = BinaryConverters.valueOf(converter);    }    return this;}
public void metron_f7675_0(Map conf, TopologyContext context, SpoutOutputCollector collector)
{    _collector = collector;    try {        Reader = new FileReader();        jsons = Reader.readFromFile(_filename);    } catch (Throwable e) {        System.out.println("Could not read sample JSONs");        e.printStackTrace();    }}
public void metron_f7676_0()
{    Utils.sleep(_delay);    if (cnt < jsons.size()) {        byte[] value;        if (_converter != null) {            value = _converter.convert(jsons.get(cnt));        } else {            value = jsons.get(cnt).getBytes(StandardCharsets.UTF_8);        }        _collector.emit(new Values(value));    }    cnt++;    if (_repeating && cnt == jsons.size() - 1)        cnt = 0;}
public void metron_f7679_0(OutputFieldsDeclarer declarer)
{    declarer.declare(new Fields("message"));}
public String metron_f7680_0()
{    return directoryName;}
public KafkaLoader metron_f7681_0(int delay)
{    this.delay = delay;    return this;}
public KafkaLoader metron_f7682_0(int iterations)
{    this.iterations = iterations;    return this;}
public void metron_f7683_0()
{    Map<String, Object> producerConfig = new HashMap<>();    producerConfig.put("bootstrap.servers", brokerUrl);    producerConfig.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");    producerConfig.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");    kafkaProducer = new KafkaProducer<>(producerConfig);    try {        while (iterations == -1 || iterations-- > 0) {            BufferedReader reader = new BufferedReader(new InputStreamReader(new FileInputStream(samplePath), StandardCharsets.UTF_8));            String line;            while ((line = reader.readLine()) != null) {                kafkaProducer.send(new ProducerRecord<String, String>(topic, line));                Thread.sleep(delay);            }            reader.close();        }    } catch (Exception e) {        e.printStackTrace();    }}
public void metron_f7684_0()
{    kafkaProducer.close();}
public static void metron_f7685_0(String[] args)
{    KafkaLoader kafkaLoader = new KafkaLoader(args[0], args[1], args[2]);    if (args.length > 3)        kafkaLoader.withDelay(Integer.parseInt(args[3]));    if (args.length > 4)        kafkaLoader.withIterations(Integer.parseInt(args[4]));    kafkaLoader.start();    kafkaLoader.stop();}
public static String metron_f7686_0(String pathPrefix, String sensorType, TestDataType testDataType) throws FileNotFoundException
{    File sensorSampleDataPath = new File(pathPrefix + "/" + TestConstants.SAMPLE_DATA_PATH, sensorType);    if (sensorSampleDataPath.exists() && sensorSampleDataPath.isDirectory()) {        File sampleDataPath = new File(sensorSampleDataPath, testDataType.getDirectoryName());        if (sampleDataPath.exists() && sampleDataPath.isDirectory()) {            File[] children = sampleDataPath.listFiles();            if (children != null && children.length > 0) {                return children[0].getAbsolutePath();            }        }    }    throw new FileNotFoundException("Could not find data in " + TestConstants.SAMPLE_DATA_PATH + sensorType + "/" + testDataType.getDirectoryName());}
public static String metron_f7687_0(String sensorType, TestDataType testDataType) throws FileNotFoundException
{    return getSampleDataPath("", sensorType, testDataType);}
public static String metron_f7688_0(String name)
{    return findDir(new File("."), name);}
public static String metron_f7689_0(File startDir, String name)
{    Stack<File> s = new Stack<File>();    s.push(startDir);    while (!s.empty()) {        File parent = s.pop();        if (parent.getName().equalsIgnoreCase(name)) {            return parent.getAbsolutePath();        } else {            File[] children = parent.listFiles();            if (children != null) {                for (File child : children) {                    s.push(child);                }            }        }    }    return null;}
public static void metron_f7690_0(String type, Set<T> expectedPcapIds, Set<T> found)
{    boolean mismatch = false;    for (T f : found) {        if (!expectedPcapIds.contains(f)) {            mismatch = true;            System.out.println("Found " + type + " that I did not expect: " + f);        }    }    for (T expectedId : expectedPcapIds) {        if (!found.contains(expectedId)) {            mismatch = true;            System.out.println("Expected " + type + " that I did not index: " + expectedId);        }    }    Assert.assertFalse(mismatch);}
public static void metron_f7691_0()
{    verboseLogging("%d [%p|%c|%C{1}] %m%n", Level.ALL);}
public static void metron_f7692_0(String pattern, Level level)
{        ConsoleAppender console = new ConsoleAppender();        console.setLayout(new PatternLayout(pattern));    console.setThreshold(level);    console.activateOptions();        Logger.getRootLogger().addAppender(console);}
public static void metron_f7693_0(Class clazz, Level level)
{    Logger logger = Logger.getLogger(clazz);    logger.setLevel(level);}
public static void metron_f7694_0(Level level)
{    Logger logger = Logger.getRootLogger();    logger.setLevel(level);}
public static Level metron_f7695_0()
{    Logger rootLogger = Logger.getRootLogger();    return rootLogger.getLevel();}
public static Level metron_f7696_0(Class clazz)
{    Logger logger = Logger.getLogger(clazz);    return logger.getLevel();}
public static void metron_f7697_0(Class clazz, java.util.logging.Level level)
{    java.util.logging.Logger logger = java.util.logging.Logger.getLogger(clazz.getName());    logger.setLevel(level);}
public static java.util.logging.Level metron_f7698_0(Class clazz)
{    java.util.logging.Logger logger = java.util.logging.Logger.getLogger(clazz.getName());    return logger.getLevel();}
public static void metron_f7699_0(java.util.logging.Level level)
{    java.util.logging.Logger logger = java.util.logging.Logger.getLogger("");    logger.setLevel(level);}
public static java.util.logging.Level metron_f7700_0()
{    java.util.logging.Logger logger = java.util.logging.Logger.getLogger("");    return logger.getLevel();}
public static File metron_f7701_0(File dir) throws IOException
{    return createTempDir(dir, true);}
public static File metron_f7702_0(File dir, boolean cleanup) throws IOException
{    if (!dir.mkdirs() && !dir.exists()) {        throw new IOException(String.format("Failed to create directory structure '%s'", dir.toString()));    }    if (cleanup) {        addCleanupHook(dir.toPath());    }    return dir;}
public static File metron_f7703_0(String prefix) throws IOException
{    return createTempDir(prefix, true);}
public static File metron_f7704_0(String prefix, boolean cleanup) throws IOException
{    Path tmpDir = Files.createTempDirectory(prefix);    addCleanupHook(tmpDir);    return tmpDir.toFile();}
public static void metron_f7705_0(final Path dir)
{    Runtime.getRuntime().addShutdownHook(new Thread() {        @Override        public void run() {            try {                cleanDir(dir);            } catch (IOException e) {                System.out.println(format("Warning: Unable to clean folder '%s'", dir.toString()));            }        }    });}
public void metron_f7706_0()
{    try {        cleanDir(dir);    } catch (IOException e) {        System.out.println(format("Warning: Unable to clean folder '%s'", dir.toString()));    }}
public static void metron_f7707_0(Path dir) throws IOException
{    Files.walkFileTree(dir, new SimpleFileVisitor<Path>() {        @Override        public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException {            Files.delete(file);            return FileVisitResult.CONTINUE;        }        @Override        public FileVisitResult visitFileFailed(Path file, IOException exc) throws IOException {            Files.delete(file);            return FileVisitResult.CONTINUE;        }        @Override        public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException {            if (exc == null) {                return FileVisitResult.CONTINUE;            } else {                throw exc;            }        }    });    Files.delete(dir);}
public FileVisitResult metron_f7708_0(Path file, BasicFileAttributes attrs) throws IOException
{    Files.delete(file);    return FileVisitResult.CONTINUE;}
public FileVisitResult metron_f7709_0(Path file, IOException exc) throws IOException
{    Files.delete(file);    return FileVisitResult.CONTINUE;}
public FileVisitResult metron_f7710_0(Path dir, IOException exc) throws IOException
{    if (exc == null) {        return FileVisitResult.CONTINUE;    } else {        throw exc;    }}
public static File metron_f7711_0(File file, String contents) throws IOException
{    com.google.common.io.Files.createParentDirs(file);    com.google.common.io.Files.write(contents, file, StandardCharsets.UTF_8);    return file;}
public static void metron_f7712_0(String expected, String actual) throws IOException
{    ObjectMapper mapper = new ObjectMapper();    Map m1 = mapper.readValue(expected, Map.class);    Map m2 = mapper.readValue(actual, Map.class);    for (Object k : m1.keySet()) {        Object v1 = m1.get(k);        Object v2 = m2.get(k);        if (v2 == null) {            Assert.fail("Unable to find key: " + k + " in output");        }        if (k.equals("timestamp") || k.equals("guid")) {                        Assert.assertEquals(v1.toString().length(), v2.toString().length());        } else if (!v2.equals(v1)) {            boolean goodDeepDown = false;                        if (((String) k).equals("original_string")) {                try {                    mapper.readValue((String) v1, Map.class);                    assertJsonEqual((String) v1, (String) v2);                    goodDeepDown = true;                } catch (Exception e) {                                }            }            if (!goodDeepDown) {                Assert.assertEquals("value mismatch for " + k, v1, v2);            }        }    }    Assert.assertEquals(m1.size(), m2.size());}
public boolean metron_f7713_1(String sensorType, WriterConfiguration configurations, List<BulkMessage<MESSAGE_T>> messages)
{    boolean shouldFlush = false;    int batchSize = messages.size();    int configuredBatchSize = configurations.getBatchSize(sensorType);        if (batchSize >= configuredBatchSize) {                shouldFlush = true;    }    return shouldFlush;}
public boolean metron_f7715_1(String sensorType, WriterConfiguration configurations, List<BulkMessage<MESSAGE_T>> messages)
{    boolean shouldFlush = false;    long currentTimeMillis = clock.currentTimeMillis();    if (!timeouts.containsKey(sensorType)) {                                long batchTimeoutMs = getBatchTimeout(sensorType, configurations);                timeouts.put(sensorType, currentTimeMillis + batchTimeoutMs);    }    if (timeouts.get(sensorType) <= currentTimeMillis) {                shouldFlush = true;    }    return shouldFlush;}
public void metron_f7716_0(String sensorType, BulkWriterResponse response)
{    timeouts.remove(sensorType);}
protected long metron_f7717_1(String sensorType, WriterConfiguration configurations)
{    int batchTimeoutSecs = configurations.getBatchTimeout(sensorType);    if (batchTimeoutSecs <= 0 || batchTimeoutSecs > maxBatchTimeout) {                batchTimeoutSecs = maxBatchTimeout;    }    return TimeUnit.SECONDS.toMillis(batchTimeoutSecs);}
public void metron_f7718_0(String sensorType, BulkMessage<MESSAGE_T> bulkWriterMessage, BulkMessageWriter<MESSAGE_T> bulkMessageWriter, WriterConfiguration configurations)
{    List<BulkMessage<MESSAGE_T>> messages = sensorMessageCache.getOrDefault(sensorType, new ArrayList<>());    sensorMessageCache.put(sensorType, messages);        if (!configurations.isEnabled(sensorType)) {                flush(sensorType, bulkMessageWriter, configurations, messages);                BulkWriterResponse response = new BulkWriterResponse();        response.addSuccess(bulkWriterMessage.getId());        onFlush(sensorType, response);    } else {        messages.add(bulkWriterMessage);        applyShouldFlush(sensorType, bulkMessageWriter, configurations, sensorMessageCache.get(sensorType));    }}
public void metron_f7720_0(BulkMessageWriter<MESSAGE_T> bulkMessageWriter, WriterConfiguration configurations)
{        for (String sensorType : new HashSet<>(sensorMessageCache.keySet())) {        applyShouldFlush(sensorType, bulkMessageWriter, configurations, sensorMessageCache.get(sensorType));    }}
public void metron_f7721_0(FlushPolicy flushPolicy)
{    this.flushPolicies.add(flushPolicy);}
private void metron_f7722_0(String sensorType, BulkMessageWriter<MESSAGE_T> bulkMessageWriter, WriterConfiguration configurations, List<BulkMessage<MESSAGE_T>> messages)
{    if (messages.size() > 0) {                for (FlushPolicy<MESSAGE_T> flushPolicy : flushPolicies) {            if (flushPolicy.shouldFlush(sensorType, configurations, messages)) {                flush(sensorType, bulkMessageWriter, configurations, messages);                break;            }        }    }}
private void metron_f7723_0(String sensorType, BulkWriterResponse response)
{    sensorMessageCache.remove(sensorType);    for (FlushPolicy flushPolicy : flushPolicies) {        flushPolicy.onFlush(sensorType, response);    }}
public String metron_f7724_0()
{    return key;}
public Object metron_f7725_1(Map<String, Object> config)
{    Object o = config.get(key);    if (o == null) {            }    return o;}
public T metron_f7726_1(Map<String, Object> config, Class<T> clazz)
{    Object o = get(config);    if (o != null) {        return ConversionUtils.convert(o, clazz);    }        return null;}
public String metron_f7727_1(final JSONObject message)
{    String transformedMessage = keys.stream().map(x -> {        Object o = message.get(x);        return o == null ? "" : o.toString();    }).collect(Collectors.joining(delim));        return transformedMessage;}
public void metron_f7728_1(String sensorName, WriterConfiguration configuration)
{    validateEnrichmentType(sensorName, configuration);    validateKeyColumns(sensorName, configuration);    String hbaseProviderImpl = Configurations.HBASE_PROVIDER.getAndConvert(configuration.getSensorConfig(sensorName), String.class);    if (hbaseProviderImpl != null) {        provider = ReflectionUtils.createInstance(hbaseProviderImpl);    }    if (converter == null) {        converter = new EnrichmentConverter();    }    }
private void metron_f7729_0(String sensorName, WriterConfiguration configuration)
{    Map<String, Object> sensorConfig = configuration.getSensorConfig(sensorName);    Object enrichmentTypeObj = Configurations.ENRICHMENT_TYPE.get(sensorConfig);    if (enrichmentTypeObj == null) {        throw new IllegalArgumentException(String.format("%s must be provided", Configurations.ENRICHMENT_TYPE.getKey()));    }    if (!(enrichmentTypeObj instanceof String)) {        throw new IllegalArgumentException(String.format("%s must be a string", Configurations.ENRICHMENT_TYPE.getKey()));    }    String enrichmentType = enrichmentTypeObj.toString();    if (enrichmentType.trim().isEmpty()) {        throw new IllegalArgumentException(String.format("%s must not be an empty string", Configurations.ENRICHMENT_TYPE.getKey()));    }}
private void metron_f7730_0(String sensorName, WriterConfiguration configuration)
{    Map<String, Object> sensorConfig = configuration.getSensorConfig(sensorName);    Object keyColumnsObj = Configurations.KEY_COLUMNS.get(sensorConfig);    try {        List<String> keyColumns = getColumns(keyColumnsObj, true);        if (keyColumns == null || keyColumns.isEmpty()) {            throw new IllegalArgumentException(String.format("%s must be provided", Configurations.KEY_COLUMNS.getKey()));        }    } catch (RuntimeException ex) {        throw new IllegalArgumentException(ex.getMessage(), ex);    }}
private String metron_f7731_0(Object object)
{    return object == null ? "" : object.getClass().getName();}
public void metron_f7732_0(Map stormConf, WriterConfiguration configuration) throws Exception
{    if (converter == null) {        converter = new EnrichmentConverter();    }}
protected synchronized TableProvider metron_f7733_0()
{    if (provider == null) {        provider = new HTableProvider();    }    return provider;}
public Table metron_f7734_1(String tableName, String cf) throws IOException
{    synchronized (this) {        boolean isInitial = this.tableName == null || this.cf == null;        boolean isValid = tableName != null && cf != null;        if (isInitial || (isValid && (!this.tableName.equals(tableName) || !this.cf.equals(cf)))) {            Configuration conf = HBaseConfiguration.create();                        if (table != null) {                table.close();            }                        table = getProvider().getTable(conf, tableName);            this.tableName = tableName;            this.cf = cf;        }        return table;    }}
public Table metron_f7735_0(Map<String, Object> config) throws IOException
{    return getTable(Configurations.HBASE_TABLE.getAndConvert(config, String.class), Configurations.HBASE_CF.getAndConvert(config, String.class));}
private List<String> metron_f7736_1(Object keyColumnsObj, boolean allowNull)
{    Object o = keyColumnsObj;    if (allowNull && keyColumnsObj == null) {                return Collections.emptyList();    }    if (o instanceof String) {                return ImmutableList.of(o.toString());    } else if (o instanceof List) {        List<String> keyCols = new ArrayList<>();        for (Object key : (List) o) {            if (key == null) {                throw new IllegalArgumentException("Column name must not be null");            }            String columnName = key.toString();            if (columnName.trim().isEmpty()) {                throw new IllegalArgumentException("Column name must not be empty");            }            keyCols.add(columnName);        }                return keyCols;    } else {        throw new RuntimeException("Unable to get columns: " + o);    }}
private KeyTransformer metron_f7737_1(Map<String, Object> config)
{    Object o = Configurations.KEY_COLUMNS.get(config);    KeyTransformer transformer = null;    if (keyTransformer != null && keyTransformer.getKey() == o) {        transformer = keyTransformer.getValue();                return transformer;    } else {        List<String> keys = getColumns(o, false);        Object delimObj = Configurations.KEY_DELIM.get(config);        String delim = (delimObj == null || !(delimObj instanceof String)) ? null : delimObj.toString();        KeyTransformer newtransformer = new KeyTransformer(keys, delim);        keyTransformer = new AbstractMap.SimpleEntry<>(o, newtransformer);                return newtransformer;    }}
private EnrichmentValue metron_f7738_0(JSONObject message, Set<String> keyColumns, Set<String> valueColumns)
{    Map<String, Object> metadata = new HashMap<>();    if (valueColumns == null || valueColumns.isEmpty()) {        for (Object kv : message.entrySet()) {            Map.Entry<Object, Object> entry = (Map.Entry<Object, Object>) kv;            if (!keyColumns.contains(entry.getKey())) {                addMetadataEntry(metadata, entry);            }        }        return new EnrichmentValue(metadata);    } else {        for (Object kv : message.entrySet()) {            Map.Entry<Object, Object> entry = (Map.Entry<Object, Object>) kv;            if (valueColumns.contains(entry.getKey())) {                addMetadataEntry(metadata, entry);            }        }        return new EnrichmentValue(metadata);    }}
private void metron_f7739_1(Map<String, Object> metadata, Map.Entry<Object, Object> entry)
{    String key = entry.getKey().toString();    Object value = entry.getValue();        metadata.put(key, value);}
private EnrichmentKey metron_f7740_0(JSONObject message, KeyTransformer transformer, String enrichmentType)
{    if (enrichmentType != null) {        return new EnrichmentKey(enrichmentType, transformer.transform(message));    } else {        return null;    }}
public BulkWriterResponse metron_f7741_1(String sensorType, WriterConfiguration configurations, List<BulkMessage<JSONObject>> messages) throws Exception
{    Map<String, Object> sensorConfig = configurations.getSensorConfig(sensorType);    Table table = getTable(sensorConfig);    KeyTransformer transformer = getTransformer(sensorConfig);    Object enrichmentTypeObj = Configurations.ENRICHMENT_TYPE.get(sensorConfig);    String enrichmentType = enrichmentTypeObj == null ? null : enrichmentTypeObj.toString();    Set<String> valueColumns = new HashSet<>(getColumns(Configurations.VALUE_COLUMNS.get(sensorConfig), true));    List<Put> puts = new ArrayList<>();    for (BulkMessage<JSONObject> bulkWriterMessage : messages) {        EnrichmentKey key = getKey(bulkWriterMessage.getMessage(), transformer, enrichmentType);        EnrichmentValue value = getValue(bulkWriterMessage.getMessage(), transformer.keySet, valueColumns);        if (key == null || value == null) {            continue;        }        Put put = converter.toPut(this.cf, key, value);        if (put != null) {                        puts.add(put);        }    }    Set<MessageId> ids = messages.stream().map(BulkMessage::getId).collect(Collectors.toSet());    BulkWriterResponse response = new BulkWriterResponse();    try {        table.put(puts);    } catch (Exception e) {        response.addAllErrors(e, ids);        return response;    }        response.addAllSuccesses(ids);    return response;}
public String metron_f7742_0()
{    return "hbaseEnrichment";}
public void metron_f7743_0() throws Exception
{    synchronized (this) {        if (table != null) {            table.close();        }    }}
public Object metron_f7744_0(Optional<String> configPrefix, Map<String, Object> config)
{    return config.get(StringUtils.join(".", configPrefix, Optional.of(key)));}
public T metron_f7745_0(Optional<String> configPrefix, Map<String, Object> config, Class<T> clazz)
{    Object o = get(configPrefix, config);    if (o != null) {        return ConversionUtils.convert(o, clazz);    }    return null;}
public KafkaWriter metron_f7746_0(String brokerUrl)
{    this.brokerUrl = brokerUrl;    return this;}
public KafkaWriter metron_f7747_0(String zkQuorum)
{    this.zkQuorum = zkQuorum;    return this;}
public KafkaWriter metron_f7748_0(String keySerializer)
{    this.keySerializer = keySerializer;    return this;}
public KafkaWriter metron_f7749_0(String valueSerializer)
{    this.valueSerializer = valueSerializer;    return this;}
public KafkaWriter metron_f7750_0(Integer requiredAcks)
{    this.requiredAcks = requiredAcks;    return this;}
public KafkaWriter metron_f7751_0(String topic)
{    this.kafkaTopic = topic;    return this;}
public KafkaWriter metron_f7752_0(String topicField)
{    this.kafkaTopicField = topicField;    return this;}
public KafkaWriter metron_f7753_0(String prefix)
{    this.configPrefix = prefix;    return this;}
public KafkaWriter metron_f7754_0(Map<String, Object> extraConfigs)
{    if (producerConfigs == null) {        this.producerConfigs = extraConfigs;    } else if (extraConfigs != null) {        producerConfigs.putAll(extraConfigs);    }    return this;}
public Optional<String> metron_f7755_0()
{    return Optional.ofNullable(configPrefix);}
protected void metron_f7756_0(KafkaProducer kafkaProducer)
{    this.kafkaProducer = kafkaProducer;}
public void metron_f7757_0(String sensorName, WriterConfiguration configuration)
{    Map<String, Object> configMap = configuration.getSensorConfig(sensorName);    String brokerUrl = Configurations.BROKER.getAndConvert(getConfigPrefix(), configMap, String.class);    if (brokerUrl != null) {        this.brokerUrl = brokerUrl;    }    String zkQuorum = Configurations.ZK_QUORUM.getAndConvert(getConfigPrefix(), configMap, String.class);    if (zkQuorum != null) {        withZkQuorum(zkQuorum);    }    String keySerializer = Configurations.KEY_SERIALIZER.getAndConvert(getConfigPrefix(), configMap, String.class);    if (keySerializer != null) {        withKeySerializer(keySerializer);    }    String valueSerializer = Configurations.VALUE_SERIALIZER.getAndConvert(getConfigPrefix(), configMap, String.class);    if (valueSerializer != null) {        withValueSerializer(keySerializer);    }    Integer requiredAcks = Configurations.REQUIRED_ACKS.getAndConvert(getConfigPrefix(), configMap, Integer.class);    if (requiredAcks != null) {        withRequiredAcks(requiredAcks);    }    String topic = Configurations.TOPIC.getAndConvert(getConfigPrefix(), configMap, String.class);    if (topic != null) {        withTopic(topic);    }    String topicField = Configurations.TOPIC_FIELD.getAndConvert(getConfigPrefix(), configMap, String.class);    if (topicField != null) {        withTopicField(topicField);    }    Map<String, Object> producerConfigs = (Map) Configurations.PRODUCER_CONFIGS.get(getConfigPrefix(), configMap);    if (producerConfigs != null) {        withProducerConfigs(producerConfigs);    }}
public void metron_f7758_0(Map stormConf, WriterConfiguration config) throws Exception
{    if (this.zkQuorum != null && this.brokerUrl == null) {        try {            this.brokerUrl = Joiner.on(",").join(KafkaUtils.INSTANCE.getBrokersFromZookeeper(this.zkQuorum));        } catch (Exception e) {            throw new IllegalStateException("Cannot read kafka brokers from zookeeper and you didn't specify them, giving up!", e);        }    }    this.kafkaProducer = new KafkaProducer<>(createProducerConfigs());}
public Map<String, Object> metron_f7759_0()
{    Map<String, Object> producerConfig = new HashMap<>();    producerConfig.put("bootstrap.servers", brokerUrl);    producerConfig.put("key.serializer", keySerializer);    producerConfig.put("value.serializer", valueSerializer);    producerConfig.put("request.required.acks", requiredAcks);    producerConfig.put(ProducerConfig.BATCH_SIZE_CONFIG, DEFAULT_BATCH_SIZE);    producerConfig.putAll(producerConfigs == null ? new HashMap<>() : producerConfigs);    producerConfig = KafkaUtils.INSTANCE.normalizeProtocol(producerConfig);    return producerConfig;}
public Optional<String> metron_f7760_1(JSONObject message)
{    String t = null;    if (kafkaTopicField != null) {        t = (String) message.get(kafkaTopicField);            } else {        t = kafkaTopic;            }    return Optional.ofNullable(t);}
public BulkWriterResponse metron_f7761_1(String sensorType, WriterConfiguration configurations, List<BulkMessage<JSONObject>> messages)
{    BulkWriterResponse writerResponse = new BulkWriterResponse();    List<Map.Entry<MessageId, Future>> results = new ArrayList<>();    for (BulkMessage<JSONObject> bulkWriterMessage : messages) {        MessageId messageId = bulkWriterMessage.getId();        JSONObject message = bulkWriterMessage.getMessage();        String jsonMessage;        try {            jsonMessage = message.toJSONString();        } catch (Throwable t) {            writerResponse.addError(t, messageId);            continue;        }        Optional<String> topic = getKafkaTopic(message);        if (topic.isPresent()) {            Future future = kafkaProducer.send(new ProducerRecord<String, String>(topic.get(), jsonMessage));                        results.add(new AbstractMap.SimpleEntry<>(messageId, future));        } else {                    }    }    Collection<MessageId> ids = messages.stream().map(BulkMessage::getId).collect(Collectors.toList());    try {                kafkaProducer.flush();    } catch (InterruptException e) {        writerResponse.addAllErrors(e, ids);        return writerResponse;    }    for (Map.Entry<MessageId, Future> kv : results) {        try {            kv.getValue().get();            writerResponse.addSuccess(kv.getKey());        } catch (Exception e) {            writerResponse.addError(e, kv.getKey());        }    }    return writerResponse;}
public String metron_f7762_0()
{    return "kafka";}
public void metron_f7763_0() throws Exception
{    kafkaProducer.close();}
public int metron_f7764_0()
{    return min;}
public int metron_f7765_0()
{    return max;}
public Void metron_f7766_0(Void aVoid)
{    int sleepMs = ThreadLocalRandom.current().nextInt(min, max + 1);    try {        Thread.sleep(sleepMs);    } catch (InterruptedException e) {    }    return null;}
public int metron_f7767_0()
{    return latency;}
public Void metron_f7768_0(Void aVoid)
{    if (latency > 0) {        try {            Thread.sleep(latency);        } catch (InterruptedException e) {        }    }    return null;}
public NoopWriter metron_f7769_0(String sleepConfig)
{    sleepFunction = getSleepFunction(sleepConfig);    return this;}
private Function<Void, Void> metron_f7770_0(String sleepConfig)
{    String usageMessage = "Unexpected: " + sleepConfig + " Expected value: integer for a fixed sleep duration in milliseconds (e.g. 10) " + "or a range of latencies separated by a comma (e.g. \"10, 20\") to sleep a random amount in that range.";    try {        if (sleepConfig.contains(",")) {                        Iterable<String> it = Splitter.on(',').split(sleepConfig);            Integer min = ConversionUtils.convert(Iterables.getFirst(it, "").trim(), Integer.class);            Integer max = ConversionUtils.convert(Iterables.getLast(it, "").trim(), Integer.class);            if (min != null && max != null) {                return new RandomLatency(min, max);            }        } else {                        Integer latency = ConversionUtils.convert(sleepConfig.trim(), Integer.class);            if (latency != null) {                return new FixedLatency(latency);            }        }    } catch (Throwable t) {        throw new IllegalArgumentException(usageMessage, t);    }    throw new IllegalArgumentException(usageMessage);}
public void metron_f7771_0(String sensorName, WriterConfiguration configuration)
{    Map<String, Object> config = configuration.getSensorConfig(sensorName);    if (config != null) {        Object noopLatency = config.get("noopLatency");        if (noopLatency != null) {            sleepFunction = getSleepFunction(noopLatency.toString());        }    }}
public BulkWriterResponse metron_f7773_0(String sensorType, WriterConfiguration configurations, List<BulkMessage<JSONObject>> messages) throws Exception
{    if (sleepFunction != null) {        sleepFunction.apply(null);    }    Set<MessageId> ids = messages.stream().map(BulkMessage::getId).collect(Collectors.toSet());    BulkWriterResponse response = new BulkWriterResponse();    response.addAllSuccesses(ids);    return response;}
public String metron_f7774_0()
{    return "noop";}
public void metron_f7776_0(Map stormConf, WriterConfiguration config) throws Exception
{    messageWriter.init();}
public BulkWriterResponse metron_f7777_0(String sensorType, WriterConfiguration configurations, List<BulkMessage<MESSAGE_T>> messages) throws Exception
{    Set<MessageId> ids = messages.stream().map(BulkMessage::getId).collect(Collectors.toSet());    BulkWriterResponse response = new BulkWriterResponse();    if (messages.size() > 1) {        response.addAllErrors(new IllegalStateException("WriterToBulkWriter expects a batch of exactly 1"), ids);        return response;    }    try {        messageWriter.write(sensorType, configurations, Iterables.getFirst(messages, null));    } catch (Exception e) {        response.addAllErrors(e, ids);        return response;    }    response.addAllSuccesses(ids);    return response;}
public String metron_f7778_0()
{    return messageWriter.getName();}
public void metron_f7779_0() throws Exception
{    messageWriter.close();}
public void metron_f7780_0()
{    when(configurations.getBatchSize(sensorType)).thenReturn(2);}
public void metron_f7781_0()
{    BatchSizePolicy<JSONObject> batchSizePolicy = new BatchSizePolicy<>();    messages.add(new BulkMessage<>("message1", new JSONObject()));    messages.add(new BulkMessage<>("message2", new JSONObject()));    assertTrue(batchSizePolicy.shouldFlush(sensorType, configurations, messages));}
public void metron_f7782_0()
{    BatchSizePolicy<JSONObject> batchSizePolicy = new BatchSizePolicy<>();    messages.add(new BulkMessage<>("message1", new JSONObject()));    assertFalse(batchSizePolicy.shouldFlush(sensorType, configurations, messages));}
public void metron_f7783_0()
{    BatchSizePolicy<JSONObject> batchSizePolicy = new BatchSizePolicy<>();    messages.add(new BulkMessage<>("message1", new JSONObject()));    messages.add(new BulkMessage<>("message2", new JSONObject()));    messages.add(new BulkMessage<>("message3", new JSONObject()));    assertTrue(batchSizePolicy.shouldFlush(sensorType, configurations, messages));}
public void metron_f7784_0()
{    Clock clock = mock(Clock.class);    BatchTimeoutPolicy batchTimeoutPolicy = new BatchTimeoutPolicy<>(maxBatchTimeout, clock);    when(configurations.getBatchTimeout(sensor1)).thenReturn(1);    when(configurations.getBatchTimeout(sensor2)).thenReturn(2);        when(clock.currentTimeMillis()).thenReturn(0L);    assertFalse(batchTimeoutPolicy.shouldFlush(sensor1, configurations, messages));    assertFalse(batchTimeoutPolicy.shouldFlush(sensor2, configurations, messages));        when(clock.currentTimeMillis()).thenReturn(999L);    assertFalse(batchTimeoutPolicy.shouldFlush(sensor1, configurations, messages));    assertFalse(batchTimeoutPolicy.shouldFlush(sensor2, configurations, messages));        when(clock.currentTimeMillis()).thenReturn(1000L);    assertTrue(batchTimeoutPolicy.shouldFlush(sensor1, configurations, messages));    assertFalse(batchTimeoutPolicy.shouldFlush(sensor2, configurations, messages));        when(clock.currentTimeMillis()).thenReturn(2000L);    assertTrue(batchTimeoutPolicy.shouldFlush(sensor2, configurations, messages));}
public void metron_f7785_0()
{    Clock clock = mock(Clock.class);    BatchTimeoutPolicy batchTimeoutPolicy = new BatchTimeoutPolicy(maxBatchTimeout, clock);    when(configurations.getBatchTimeout(sensor1)).thenReturn(1);        when(clock.currentTimeMillis()).thenReturn(0L);    assertFalse(batchTimeoutPolicy.shouldFlush(sensor1, configurations, messages));    batchTimeoutPolicy.onFlush(sensor1, new BulkWriterResponse());        when(clock.currentTimeMillis()).thenReturn(1000L);    assertFalse(batchTimeoutPolicy.shouldFlush(sensor1, configurations, messages));        when(clock.currentTimeMillis()).thenReturn(2000L);    assertTrue(batchTimeoutPolicy.shouldFlush(sensor1, configurations, messages));}
public void metron_f7786_0()
{    BatchTimeoutPolicy batchTimeoutPolicy = new BatchTimeoutPolicy(maxBatchTimeout);    when(configurations.getBatchTimeout(sensor1)).thenReturn(5);    assertEquals(5000L, batchTimeoutPolicy.getBatchTimeout(sensor1, configurations));}
public void metron_f7787_0()
{    BatchTimeoutPolicy batchTimeoutPolicy = new BatchTimeoutPolicy(maxBatchTimeout);    when(configurations.getBatchTimeout(sensor1)).thenReturn(0);    assertEquals(maxBatchTimeout * 1000, batchTimeoutPolicy.getBatchTimeout(sensor1, configurations));}
public void metron_f7788_0()
{    MockitoAnnotations.initMocks(this);    message1.put("value", "message1");    message2.put("value", "message2");    messageIds = Arrays.asList(messageId1, messageId2);    messages = new ArrayList<BulkMessage<JSONObject>>() {        {            add(new BulkMessage<>(messageId1, message1));            add(new BulkMessage<>(messageId2, message2));        }    };    when(configurations.isEnabled(any())).thenReturn(true);}
public void metron_f7789_0() throws Exception
{    BulkWriterComponent<JSONObject> bulkWriterComponent = new BulkWriterComponent<>(Collections.singletonList(flushPolicy));    BulkWriterResponse response = new BulkWriterResponse();    response.addAllSuccesses(messageIds);    when(bulkMessageWriter.write(sensorType, configurations, messages)).thenReturn(response);    bulkWriterComponent.write(sensorType, messages.get(0), bulkMessageWriter, configurations);    verify(bulkMessageWriter, times(0)).write(eq(sensorType), eq(configurations), any());    verify(flushPolicy, times(1)).shouldFlush(sensorType, configurations, messages.subList(0, 1));    verify(flushPolicy, times(0)).onFlush(any(), any());    reset(flushPolicy);    when(flushPolicy.shouldFlush(sensorType, configurations, messages)).thenReturn(true);    bulkWriterComponent.write(sensorType, messages.get(1), bulkMessageWriter, configurations);    BulkWriterResponse expectedResponse = new BulkWriterResponse();    expectedResponse.addAllSuccesses(messageIds);    verify(bulkMessageWriter, times(1)).write(sensorType, configurations, Arrays.asList(new BulkMessage<>(messageId1, message1), new BulkMessage<>(messageId2, message2)));    verify(flushPolicy, times(1)).shouldFlush(sensorType, configurations, messages);    verify(flushPolicy, times(1)).onFlush(sensorType, expectedResponse);    verifyNoMoreInteractions(bulkMessageWriter, flushPolicy);}
public void metron_f7790_0() throws Exception
{    BulkWriterComponent<JSONObject> bulkWriterComponent = new BulkWriterComponent<>(Collections.singletonList(flushPolicy));    BulkMessage<JSONObject> beforeDisabledMessage = messages.get(0);    BulkMessage<JSONObject> afterDisabledMessage = messages.get(1);    BulkWriterResponse beforeDisabledResponse = new BulkWriterResponse();    beforeDisabledResponse.addSuccess(beforeDisabledMessage.getId());    BulkWriterResponse afterDisabledResponse = new BulkWriterResponse();    afterDisabledResponse.addSuccess(afterDisabledMessage.getId());    when(bulkMessageWriter.write(sensorType, configurations, Collections.singletonList(messages.get(0)))).thenReturn(beforeDisabledResponse);    bulkWriterComponent.write(sensorType, beforeDisabledMessage, bulkMessageWriter, configurations);    verify(bulkMessageWriter, times(0)).write(eq(sensorType), eq(configurations), any());    verify(flushPolicy, times(1)).shouldFlush(sensorType, configurations, messages.subList(0, 1));    verify(flushPolicy, times(0)).onFlush(any(), any());    when(configurations.isEnabled(sensorType)).thenReturn(false);    bulkWriterComponent.write(sensorType, messages.get(1), bulkMessageWriter, configurations);    verify(bulkMessageWriter, times(1)).write(sensorType, configurations, Collections.singletonList(messages.get(0)));    verify(flushPolicy, times(1)).onFlush(sensorType, beforeDisabledResponse);    verify(flushPolicy, times(1)).onFlush(sensorType, afterDisabledResponse);    verifyNoMoreInteractions(bulkMessageWriter, flushPolicy);}
public void metron_f7791_0() throws Exception
{    BulkWriterComponent<JSONObject> bulkWriterComponent = new BulkWriterComponent<>(Collections.singletonList(flushPolicy));    Throwable e = new Exception("test exception");    BulkWriterResponse response = new BulkWriterResponse();    response.addAllErrors(e, messageIds);    when(bulkMessageWriter.write(sensorType, configurations, messages)).thenReturn(response);    bulkWriterComponent.write(sensorType, messages.get(0), bulkMessageWriter, configurations);    verify(bulkMessageWriter, times(0)).write(eq(sensorType), eq(configurations), any());    verify(flushPolicy, times(1)).shouldFlush(sensorType, configurations, messages.subList(0, 1));    verify(flushPolicy, times(0)).onFlush(any(), any());    reset(flushPolicy);    when(flushPolicy.shouldFlush(sensorType, configurations, messages)).thenReturn(true);    bulkWriterComponent.write(sensorType, messages.get(1), bulkMessageWriter, configurations);    BulkWriterResponse expectedErrorResponse = new BulkWriterResponse();    expectedErrorResponse.addAllErrors(e, messageIds);    verify(bulkMessageWriter, times(1)).write(sensorType, configurations, messages);    verify(flushPolicy, times(1)).shouldFlush(sensorType, configurations, messages);    verify(flushPolicy, times(1)).onFlush(sensorType, expectedErrorResponse);    verifyNoMoreInteractions(bulkMessageWriter, flushPolicy);}
public void metron_f7792_0() throws Exception
{    BulkWriterComponent<JSONObject> bulkWriterComponent = new BulkWriterComponent<>(Collections.singletonList(flushPolicy));    Throwable e = new Exception("test exception");    BulkWriterResponse response = new BulkWriterResponse();    response.addAllErrors(e, messageIds);    when(bulkMessageWriter.write(sensorType, configurations, messages)).thenThrow(e);    bulkWriterComponent.write(sensorType, messages.get(0), bulkMessageWriter, configurations);    verify(bulkMessageWriter, times(0)).write(eq(sensorType), eq(configurations), any());    verify(flushPolicy, times(1)).shouldFlush(sensorType, configurations, messages.subList(0, 1));    verify(flushPolicy, times(0)).onFlush(any(), any());    reset(flushPolicy);    when(flushPolicy.shouldFlush(sensorType, configurations, messages)).thenReturn(true);    bulkWriterComponent.write(sensorType, messages.get(1), bulkMessageWriter, configurations);    BulkWriterResponse expectedErrorResponse = new BulkWriterResponse();    expectedErrorResponse.addAllErrors(e, messageIds);    verify(bulkMessageWriter, times(1)).write(sensorType, configurations, messages);    verify(flushPolicy, times(1)).shouldFlush(sensorType, configurations, messages);    verify(flushPolicy, times(1)).onFlush(sensorType, expectedErrorResponse);    verifyNoMoreInteractions(flushPolicy);}
public void metron_f7793_0() throws Exception
{    BulkWriterComponent<JSONObject> bulkWriterComponent = new BulkWriterComponent<>(Collections.singletonList(flushPolicy));    BulkMessageWriter<JSONObject> bulkMessageWriter = mock(BulkMessageWriter.class);    MessageId successId = new MessageId("successId");    MessageId errorId = new MessageId("errorId");    MessageId missingId = new MessageId("missingId");    JSONObject successMessage = new JSONObject();    successMessage.put("name", "success");    JSONObject errorMessage = new JSONObject();    errorMessage.put("name", "error");    JSONObject missingMessage = new JSONObject();    missingMessage.put("name", "missing");    List<BulkMessage<JSONObject>> allMessages = new ArrayList<BulkMessage<JSONObject>>() {        {            add(new BulkMessage<>(successId, successMessage));            add(new BulkMessage<>(errorId, errorMessage));            add(new BulkMessage<>(missingId, missingMessage));        }    };    BulkWriterResponse bulkWriterResponse = new BulkWriterResponse();    bulkWriterResponse.addSuccess(successId);    Throwable throwable = mock(Throwable.class);    bulkWriterResponse.addError(throwable, errorId);    when(bulkMessageWriter.write(sensorType, configurations, allMessages)).thenReturn(bulkWriterResponse);    bulkWriterComponent.flush(sensorType, bulkMessageWriter, configurations, allMessages);    BulkWriterResponse expectedResponse = new BulkWriterResponse();    expectedResponse.addSuccess(successId);    expectedResponse.addError(throwable, errorId);    expectedResponse.addSuccess(missingId);    verify(flushPolicy, times(1)).onFlush(sensorType, expectedResponse);    verifyNoMoreInteractions(flushPolicy);}
public void metron_f7794_0()
{    BulkWriterComponent<JSONObject> bulkWriterComponent = new BulkWriterComponent<>(Collections.singletonList(flushPolicy));    bulkWriterComponent.write("sensor1", messages.get(0), bulkMessageWriter, configurations);    bulkWriterComponent.write("sensor2", messages.get(1), bulkMessageWriter, configurations);    reset(flushPolicy);    bulkWriterComponent.flushAll(bulkMessageWriter, configurations);    verify(flushPolicy, times(1)).shouldFlush("sensor1", configurations, messages.subList(0, 1));    verify(flushPolicy, times(1)).shouldFlush("sensor2", configurations, messages.subList(1, 2));    verifyNoMoreInteractions(flushPolicy);}
public void metron_f7795_0()
{    MockHBaseTableProvider.addToCache(TABLE_NAME, TABLE_CF);}
public void metron_f7796_0() throws Exception
{    final String sensorType = "dummy";    SimpleHbaseEnrichmentWriter writer = new SimpleHbaseEnrichmentWriter();    WriterConfiguration configuration = createConfig(1, new HashMap<String, Object>(BASE_WRITER_CONFIG) {        {            put(SimpleHbaseEnrichmentWriter.Configurations.KEY_COLUMNS.getKey(), "ip");        }    });    writer.configure(sensorType, configuration);    writer.write(SENSOR_TYPE, configuration, new ArrayList<BulkMessage<JSONObject>>() {        {            add(new BulkMessage<>("messageId", new JSONObject(ImmutableMap.of("ip", "localhost", "user", "cstella", "foo", "bar"))));        }    });    List<LookupKV<EnrichmentKey, EnrichmentValue>> values = getValues();    Assert.assertEquals(1, values.size());    Assert.assertEquals("localhost", values.get(0).getKey().indicator);    Assert.assertEquals("cstella", values.get(0).getValue().getMetadata().get("user"));    Assert.assertEquals("bar", values.get(0).getValue().getMetadata().get("foo"));    Assert.assertEquals(2, values.get(0).getValue().getMetadata().size());}
public void metron_f7797_0() throws Exception
{    final String sensorType = "dummy";    SimpleHbaseEnrichmentWriter writer = new SimpleHbaseEnrichmentWriter();    WriterConfiguration configuration = createConfig(1, new HashMap<String, Object>(BASE_WRITER_CONFIG) {        {            put(SimpleHbaseEnrichmentWriter.Configurations.KEY_COLUMNS.getKey(), "ip");            put(SimpleHbaseEnrichmentWriter.Configurations.VALUE_COLUMNS.getKey(), "user");        }    });    writer.configure(sensorType, configuration);    writer.write(SENSOR_TYPE, configuration, new ArrayList<BulkMessage<JSONObject>>() {        {            add(new BulkMessage<>("messageId", new JSONObject(ImmutableMap.of("ip", "localhost", "user", "cstella", "foo", "bar"))));        }    });    List<LookupKV<EnrichmentKey, EnrichmentValue>> values = getValues();    Assert.assertEquals(1, values.size());    Assert.assertEquals("localhost", values.get(0).getKey().indicator);    Assert.assertEquals("cstella", values.get(0).getValue().getMetadata().get("user"));    Assert.assertNull(values.get(0).getValue().getMetadata().get("foo"));    Assert.assertEquals(1, values.get(0).getValue().getMetadata().size());}
public void metron_f7798_0() throws Exception
{    final String sensorType = "dummy";    SimpleHbaseEnrichmentWriter writer = new SimpleHbaseEnrichmentWriter();    WriterConfiguration configuration = createConfig(1, new HashMap<String, Object>(BASE_WRITER_CONFIG) {        {            put(SimpleHbaseEnrichmentWriter.Configurations.KEY_COLUMNS.getKey(), "ip");            put(SimpleHbaseEnrichmentWriter.Configurations.VALUE_COLUMNS.getKey(), ImmutableList.of("user", "ip"));        }    });    writer.configure(sensorType, configuration);    writer.write(SENSOR_TYPE, configuration, new ArrayList<BulkMessage<JSONObject>>() {        {            add(new BulkMessage<>("messageId", new JSONObject(ImmutableMap.of("ip", "localhost", "user", "cstella", "foo", "bar"))));        }    });    List<LookupKV<EnrichmentKey, EnrichmentValue>> values = getValues();    Assert.assertEquals(1, values.size());    Assert.assertEquals("localhost", values.get(0).getKey().indicator);    Assert.assertEquals("cstella", values.get(0).getValue().getMetadata().get("user"));    Assert.assertEquals("localhost", values.get(0).getValue().getMetadata().get("ip"));    Assert.assertNull(values.get(0).getValue().getMetadata().get("foo"));    Assert.assertEquals(2, values.get(0).getValue().getMetadata().size());}
public void metron_f7799_0()
{    final String sensorType = "dummy";    SimpleHbaseEnrichmentWriter writer = new SimpleHbaseEnrichmentWriter();    WriterConfiguration configuration = createConfig(1, new HashMap<String, Object>() {        {            put(SimpleHbaseEnrichmentWriter.Configurations.KEY_COLUMNS.getKey(), "ip");        }    });    try {        writer.configure(sensorType, configuration);    } catch (IllegalArgumentException ex) {        Assert.assertEquals(String.format("%s must be provided", SimpleHbaseEnrichmentWriter.Configurations.ENRICHMENT_TYPE.getKey()), ex.getMessage());        throw ex;    }}
public void metron_f7800_0()
{    final String sensorType = "dummy";    SimpleHbaseEnrichmentWriter writer = new SimpleHbaseEnrichmentWriter();    WriterConfiguration configuration = createConfig(1, new HashMap<String, Object>() {        {            put(SimpleHbaseEnrichmentWriter.Configurations.KEY_COLUMNS.getKey(), "ip");            put(SimpleHbaseEnrichmentWriter.Configurations.ENRICHMENT_TYPE.getKey(), 10);        }    });    try {        writer.configure(sensorType, configuration);    } catch (IllegalArgumentException ex) {        Assert.assertEquals(String.format("%s must be a string", SimpleHbaseEnrichmentWriter.Configurations.ENRICHMENT_TYPE.getKey()), ex.getMessage());        throw ex;    }}
public void metron_f7801_0()
{    final String sensorType = "dummy";    SimpleHbaseEnrichmentWriter writer = new SimpleHbaseEnrichmentWriter();    WriterConfiguration configuration = createConfig(1, new HashMap<String, Object>() {        {            put(SimpleHbaseEnrichmentWriter.Configurations.KEY_COLUMNS.getKey(), "ip");            put(SimpleHbaseEnrichmentWriter.Configurations.ENRICHMENT_TYPE.getKey(), "  ");        }    });    try {        writer.configure(sensorType, configuration);    } catch (IllegalArgumentException ex) {        Assert.assertEquals(String.format("%s must not be an empty string", SimpleHbaseEnrichmentWriter.Configurations.ENRICHMENT_TYPE.getKey()), ex.getMessage());        throw ex;    }}
public void metron_f7802_0()
{    final String sensorType = "dummy";    SimpleHbaseEnrichmentWriter writer = new SimpleHbaseEnrichmentWriter();    WriterConfiguration configuration = createConfig(1, new HashMap<String, Object>() {        {            put(SimpleHbaseEnrichmentWriter.Configurations.ENRICHMENT_TYPE.getKey(), ENRICHMENT_TYPE);        }    });    try {        writer.configure(sensorType, configuration);    } catch (IllegalArgumentException ex) {        Assert.assertEquals(String.format("%s must be provided", SimpleHbaseEnrichmentWriter.Configurations.KEY_COLUMNS.getKey()), ex.getMessage());        throw ex;    }}
public void metron_f7803_0()
{    final String sensorType = "dummy";    SimpleHbaseEnrichmentWriter writer = new SimpleHbaseEnrichmentWriter();    WriterConfiguration configuration = createConfig(1, new HashMap<String, Object>() {        {            put(SimpleHbaseEnrichmentWriter.Configurations.ENRICHMENT_TYPE.getKey(), ENRICHMENT_TYPE);            put(SimpleHbaseEnrichmentWriter.Configurations.KEY_COLUMNS.getKey(), Arrays.asList("ip", "  "));        }    });    try {        writer.configure(sensorType, configuration);    } catch (IllegalArgumentException ex) {        Assert.assertEquals("Column name must not be empty", ex.getMessage());        throw ex;    }}
public void metron_f7804_0()
{    final String sensorType = "dummy";    SimpleHbaseEnrichmentWriter writer = new SimpleHbaseEnrichmentWriter();    WriterConfiguration configuration = createConfig(1, new HashMap<String, Object>() {        {            put(SimpleHbaseEnrichmentWriter.Configurations.ENRICHMENT_TYPE.getKey(), ENRICHMENT_TYPE);            put(SimpleHbaseEnrichmentWriter.Configurations.KEY_COLUMNS.getKey(), Arrays.asList("ip", null));        }    });    try {        writer.configure(sensorType, configuration);    } catch (IllegalArgumentException ex) {        Assert.assertEquals("Column name must not be null", ex.getMessage());        throw ex;    }}
public static List<LookupKV<EnrichmentKey, EnrichmentValue>> metron_f7805_0() throws IOException
{    MockHTable table = (MockHTable) MockHBaseTableProvider.getFromCache(TABLE_NAME);    Assert.assertNotNull(table);    List<LookupKV<EnrichmentKey, EnrichmentValue>> ret = new ArrayList<>();    EnrichmentConverter converter = new EnrichmentConverter();    for (Result r : table.getScanner(Bytes.toBytes(TABLE_CF))) {        ret.add(converter.fromResult(r, TABLE_CF));    }    return ret;}
public static WriterConfiguration metron_f7806_0(final int batchSize, final Map<String, Object> sensorConfig)
{    return new WriterConfiguration() {        @Override        public int getBatchSize(String sensorName) {            return batchSize;        }        @Override        public int getBatchTimeout(String sensorName) {                        return 0;        }        @Override        public List<Integer> getAllConfiguredTimeouts() {                        return new ArrayList<>();        }        @Override        public String getIndex(String sensorName) {            return SENSOR_TYPE;        }        @Override        public boolean isEnabled(String sensorName) {            return true;        }        @Override        public Map<String, Object> getSensorConfig(String sensorName) {            return sensorConfig;        }        @Override        public Map<String, Object> getGlobalConfig() {            return null;        }        @Override        public boolean isDefault(String sensorName) {            return false;        }        @Override        public String getFieldNameConverter(String sensorName) {            return null;        }    };}
public int metron_f7807_0(String sensorName)
{    return batchSize;}
public int metron_f7808_0(String sensorName)
{        return 0;}
public List<Integer> metron_f7809_0()
{        return new ArrayList<>();}
public String metron_f7810_0(String sensorName)
{    return SENSOR_TYPE;}
public boolean metron_f7811_0(String sensorName)
{    return true;}
public Map<String, Object> metron_f7812_0(String sensorName)
{    return sensorConfig;}
public Map<String, Object> metron_f7813_0()
{    return null;}
public boolean metron_f7814_0(String sensorName)
{    return false;}
public String metron_f7815_0(String sensorName)
{    return null;}
public WriterConfiguration metron_f7816_0(final Map<String, Object> parserConfig)
{    ParserConfigurations configurations = new ParserConfigurations();    configurations.updateSensorParserConfig(SENSOR_TYPE, new SensorParserConfig() {        {            setParserConfig(parserConfig);        }    });    return new ParserWriterConfiguration(configurations);}
public void metron_f7817_0()
{    MockitoAnnotations.initMocks(this);}
public void metron_f7818_0() throws Exception
{    KafkaWriter writer = new KafkaWriter();    WriterConfiguration configuration = createConfiguration(new HashMap<String, Object>() {        {            put("kafka.brokerUrl", "localhost:6667");            put("kafka.topic", SENSOR_TYPE);            put("kafka.producerConfigs", ImmutableMap.of("key1", 1, "key2", "value2"));        }    });    writer.configure(SENSOR_TYPE, configuration);    Map<String, Object> producerConfigs = writer.createProducerConfigs();    assertEquals(producerConfigs.get("bootstrap.servers"), "localhost:6667");    assertEquals(producerConfigs.get("key.serializer"), "org.apache.kafka.common.serialization.StringSerializer");    assertEquals(producerConfigs.get("value.serializer"), "org.apache.kafka.common.serialization.StringSerializer");    assertEquals(producerConfigs.get("request.required.acks"), 1);    assertEquals(producerConfigs.get("key1"), 1);    assertEquals(producerConfigs.get("key2"), "value2");}
public void metron_f7819_0() throws Exception
{    KafkaWriter writer = new KafkaWriter();    writer.withConfigPrefix("prefix");    WriterConfiguration configuration = createConfiguration(new HashMap<String, Object>() {        {            put("prefix.kafka.brokerUrl", "localhost:6667");            put("prefix.kafka.topic", SENSOR_TYPE);            put("prefix.kafka.producerConfigs", ImmutableMap.of("key1", 1, "key2", "value2"));        }    });    writer.configure(SENSOR_TYPE, configuration);    Map<String, Object> producerConfigs = writer.createProducerConfigs();    assertEquals(producerConfigs.get("bootstrap.servers"), "localhost:6667");    assertEquals(producerConfigs.get("key.serializer"), "org.apache.kafka.common.serialization.StringSerializer");    assertEquals(producerConfigs.get("value.serializer"), "org.apache.kafka.common.serialization.StringSerializer");    assertEquals(producerConfigs.get("request.required.acks"), 1);    assertEquals(producerConfigs.get("key1"), 1);    assertEquals(producerConfigs.get("key2"), "value2");}
public void metron_f7820_0() throws Exception
{    KafkaWriter writer = new KafkaWriter();    WriterConfiguration configuration = createConfiguration(new HashMap<String, Object>() {        {            put("kafka.brokerUrl", "localhost:6667");            put("kafka.topic", SENSOR_TYPE);            put("kafka.topicField", "kafka_topic");            put("kafka.producerConfigs", ImmutableMap.of("key1", 1, "key2", "value2"));        }    });    writer.configure(SENSOR_TYPE, configuration);    assertEquals("metron", writer.getKafkaTopic(new JSONObject() {        {            put("kafka_topic", "metron");        }    }).get());    Assert.assertFalse(writer.getKafkaTopic(new JSONObject()).isPresent());}
public void metron_f7821_0() throws Exception
{    KafkaWriter writer = new KafkaWriter();    WriterConfiguration configuration = createConfiguration(new HashMap<String, Object>() {        {            put("kafka.brokerUrl", "localhost:6667");            put("kafka.topicField", "kafka_topic");            put("kafka.producerConfigs", ImmutableMap.of("key1", 1, "key2", "value2"));        }    });    writer.configure(SENSOR_TYPE, configuration);    assertEquals("metron", writer.getKafkaTopic(new JSONObject() {        {            put("kafka_topic", "metron");        }    }).get());    Assert.assertFalse(writer.getKafkaTopic(new JSONObject()).isPresent());}
public void metron_f7822_0() throws Exception
{    KafkaWriter writer = new KafkaWriter();    WriterConfiguration configuration = createConfiguration(new HashMap<String, Object>() {        {            put("kafka.brokerUrl", "localhost:6667");            put("kafka.producerConfigs", ImmutableMap.of("key1", 1, "key2", "value2"));        }    });    writer.configure(SENSOR_TYPE, configuration);    assertEquals(Constants.ENRICHMENT_TOPIC, writer.getKafkaTopic(new JSONObject() {        {            put("kafka_topic", "metron");        }    }).get());    Assert.assertTrue(writer.getKafkaTopic(new JSONObject()).isPresent());}
public void metron_f7823_0() throws Exception
{    KafkaWriter writer = spy(new KafkaWriter());    writer.setKafkaProducer(kafkaProducer);    List<BulkMessage<JSONObject>> messages = new ArrayList<>();    JSONObject successMessage = new JSONObject();    successMessage.put("value", "success");    JSONObject errorMessage = new JSONObject();    errorMessage.put("value", "error");    JSONObject droppedMessage = new JSONObject();    droppedMessage.put("value", "dropped");    messages.add(new BulkMessage<>("successId", successMessage));    messages.add(new BulkMessage<>("errorId", errorMessage));    messages.add(new BulkMessage<>("droppedId", droppedMessage));    doReturn(Optional.of("successTopic")).when(writer).getKafkaTopic(successMessage);    doReturn(Optional.of("errorTopic")).when(writer).getKafkaTopic(errorMessage);    doReturn(Optional.empty()).when(writer).getKafkaTopic(droppedMessage);    Future successFuture = mock(Future.class);    Future errorFuture = mock(Future.class);    ExecutionException throwable = new ExecutionException(new Exception("kafka error"));    when(kafkaProducer.send(new ProducerRecord<String, String>("errorTopic", "{\"value\":\"error\"}"))).thenReturn(errorFuture);    when(kafkaProducer.send(new ProducerRecord<String, String>("successTopic", "{\"value\":\"success\"}"))).thenReturn(successFuture);    when(errorFuture.get()).thenThrow(throwable);    BulkWriterResponse response = new BulkWriterResponse();    response.addSuccess(new MessageId("successId"));    response.addError(throwable, new MessageId("errorId"));    assertEquals(response, writer.write(SENSOR_TYPE, createConfiguration(new HashMap<>()), messages));    verify(kafkaProducer, times(1)).flush();    verify(kafkaProducer, times(1)).send(new ProducerRecord<String, String>("successTopic", "{\"value\":\"success\"}"));    verify(kafkaProducer, times(1)).send(new ProducerRecord<String, String>("errorTopic", "{\"value\":\"error\"}"));    verifyNoMoreInteractions(kafkaProducer);}
public void metron_f7824_0() throws Exception
{    KafkaWriter writer = spy(new KafkaWriter());    writer.setKafkaProducer(kafkaProducer);    List<BulkMessage<JSONObject>> messages = new ArrayList<>();    JSONObject message1 = new JSONObject();    message1.put("value", "message1");    JSONObject message2 = new JSONObject();    message2.put("value", "message2");    messages.add(new BulkMessage<>("messageId1", message1));    messages.add(new BulkMessage<>("messageId2", message2));    doReturn(Optional.of("topic1")).when(writer).getKafkaTopic(message1);    doReturn(Optional.of("topic2")).when(writer).getKafkaTopic(message2);    Future future1 = mock(Future.class);    Future future2 = mock(Future.class);    when(kafkaProducer.send(new ProducerRecord<String, String>("topic1", "{\"value\":\"message1\"}"))).thenReturn(future1);    when(kafkaProducer.send(new ProducerRecord<String, String>("topic2", "{\"value\":\"message2\"}"))).thenReturn(future2);    InterruptException throwable = new InterruptException("kafka flush exception");    doThrow(throwable).when(kafkaProducer).flush();    BulkWriterResponse response = new BulkWriterResponse();    response.addAllErrors(throwable, Arrays.asList(new MessageId("messageId1"), new MessageId("messageId2")));    assertEquals(response, writer.write(SENSOR_TYPE, createConfiguration(new HashMap<>()), messages));    verify(kafkaProducer, times(1)).flush();    verify(kafkaProducer, times(1)).send(new ProducerRecord<String, String>("topic1", "{\"value\":\"message1\"}"));    verify(kafkaProducer, times(1)).send(new ProducerRecord<String, String>("topic2", "{\"value\":\"message2\"}"));    verifyNoMoreInteractions(kafkaProducer);}
public void metron_f7825_0()
{    NoopWriter writer = new NoopWriter().withLatency("10");    Assert.assertTrue(writer.sleepFunction instanceof NoopWriter.FixedLatency);    NoopWriter.FixedLatency sleepFunction = (NoopWriter.FixedLatency) writer.sleepFunction;    Assert.assertEquals(10, sleepFunction.getLatency());}
private void metron_f7826_0(String latencyConfig, int min, int max)
{    NoopWriter writer = new NoopWriter().withLatency(latencyConfig);    Assert.assertTrue(writer.sleepFunction instanceof NoopWriter.RandomLatency);    NoopWriter.RandomLatency sleepFunction = (NoopWriter.RandomLatency) writer.sleepFunction;    Assert.assertEquals(min, sleepFunction.getMin());    Assert.assertEquals(max, sleepFunction.getMax());}
public void metron_f7827_0()
{    ensureRandomLatencyConfig("10,20", 10, 20);    ensureRandomLatencyConfig("10, 20", 10, 20);    ensureRandomLatencyConfig("10 ,20", 10, 20);    ensureRandomLatencyConfig("10 , 20", 10, 20);}
protected Map<Tuple, Collection<MessageId>> metron_f7828_0()
{    return tupleMessageMap;}
protected Map<Tuple, Set<Throwable>> metron_f7829_0()
{    return tupleErrorMap;}
public boolean metron_f7830_0(String sensorType, WriterConfiguration configurations, List<BulkMessage<MESSAGE_T>> messages)
{    return false;}
public void metron_f7831_1(String sensorType, BulkWriterResponse response)
{            Collection<Tuple> tuplesToAck = new ArrayList<>();    tupleMessageMap = tupleMessageMap.entrySet().stream().map(entry -> {        Tuple tuple = entry.getKey();        Collection<MessageId> ids = new ArrayList<>(entry.getValue());                ids.removeAll(response.getSuccesses());                response.getErrors().forEach((throwable, failedIds) -> {            if (ids.removeAll(failedIds)) {                                Set<Throwable> errorList = tupleErrorMap.getOrDefault(tuple, new HashSet<>());                tupleErrorMap.put(tuple, errorList);                errorList.add(throwable);                handleError(sensorType, throwable, tuple);            }        });        return new AbstractMap.SimpleEntry<>(tuple, ids);    }).filter(entry -> {                if (entry.getValue().isEmpty()) {            tuplesToAck.add(entry.getKey());                        return false;        }        return true;    }).collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));        tuplesToAck.forEach(tuple -> {        collector.ack(tuple);    });        Collection<Tuple> failedTuples = tuplesToAck.stream().filter(tuple -> tupleErrorMap.containsKey(tuple)).collect(Collectors.toList());        Set<Throwable> errorsToReport = new HashSet<>();    failedTuples.forEach(tuple -> {                errorsToReport.addAll(tupleErrorMap.remove(tuple));    });    errorsToReport.forEach(throwable -> {                collector.reportError(throwable);    });}
public void metron_f7832_1(Tuple tuple, Collection<String> messageIds)
{        tupleMessageMap.put(tuple, messageIds.stream().map(MessageId::new).collect(Collectors.toSet()));}
private void metron_f7833_0(String sensorType, Throwable e, Tuple tuple)
{    MetronError error = new MetronError().withSensorType(Collections.singleton(sensorType)).withErrorType(Constants.ErrorType.INDEXING_ERROR).withThrowable(e).addRawMessage(messageGetStrategy.get(tuple));    collector.emit(Constants.ERROR_STREAM, new Values(error.getJSONObject()));}
private synchronized void metron_f7834_0()
{    if (initialized)        return;    readGlobalTimeoutConfigs();    calcMaxBatchTimeoutAllowed();    readMinBatchTimeoutRequested();    calcRecommendedTickInterval();    initialized = true;}
private Map metron_f7835_0()
{    Map ret = Utils.readDefaultConfig();    String confFile = System.getProperty("storm.conf.file");    Map storm;    if (confFile == null || confFile.equals("")) {        storm = Utils.findAndReadConfigFile("storm.yaml", false);    } else {        storm = Utils.findAndReadConfigFile(confFile, true);    }    ret.putAll(storm);    return ret;}
private void metron_f7836_0()
{    Map stormConf = readStormConfigWithoutCLI();    Map cliConf = Utils.readCommandLineOpts();        baseMessageTimeoutSecs = (Integer) stormConf.getOrDefault(Config.TOPOLOGY_MESSAGE_TIMEOUT_SECS, 0);    cliMessageTimeoutSecs = (Integer) cliConf.getOrDefault(Config.TOPOLOGY_MESSAGE_TIMEOUT_SECS, 0);        Object scratch;    scratch = stormConf.getOrDefault(Config.TOPOLOGY_TICK_TUPLE_FREQ_SECS, 0);    baseTickTupleFreqSecs = (scratch == null) ? 0 : (Integer) scratch;    scratch = cliConf.getOrDefault(Config.TOPOLOGY_TICK_TUPLE_FREQ_SECS, 0);    cliTickTupleFreqSecs = (scratch == null) ? 0 : (Integer) scratch;}
private void metron_f7837_1()
{        effectiveMessageTimeoutSecs = (cliMessageTimeoutSecs == 0 ? baseMessageTimeoutSecs : cliMessageTimeoutSecs);    if (effectiveMessageTimeoutSecs == 0) {                maxBatchTimeoutAllowedSecs = Integer.MAX_VALUE;    } else {                                        maxBatchTimeoutAllowedSecs = effectiveMessageTimeoutSecs / 2 / batchTimeoutDivisor - 1;        if (maxBatchTimeoutAllowedSecs <= 0) {                        maxBatchTimeoutAllowedSecs = 1;        }    }}
public int metron_f7838_0()
{    if (!initialized) {        this.init();    }    return maxBatchTimeoutAllowedSecs;}
private void metron_f7839_0()
{            List<Integer> configuredTimeouts = listAllConfiguredTimeouts.get();        int minval = Integer.MAX_VALUE;    for (int k : configuredTimeouts) {        if (k < minval && k > 0)            minval = k;    }    minBatchTimeoutRequestedSecs = minval;}
private void metron_f7840_0()
{    recommendedTickIntervalSecs = Integer.min(minBatchTimeoutRequestedSecs, maxBatchTimeoutAllowedSecs);}
public int metron_f7841_1()
{    if (!initialized) {        this.init();    }        if (cliTickTupleFreqSecs > 0 && cliTickTupleFreqSecs > recommendedTickIntervalSecs) {            }    if (cliTickTupleFreqSecs > 0 && cliTickTupleFreqSecs < recommendedTickIntervalSecs) {            }    return recommendedTickIntervalSecs;}
public BulkMessageWriterBolt<CONFIG_T> metron_f7842_0(BulkMessageWriter<JSONObject> bulkMessageWriter)
{    this.bulkMessageWriter = bulkMessageWriter;    return this;}
public BulkMessageWriterBolt<CONFIG_T> metron_f7843_0(MessageWriter<JSONObject> messageWriter)
{    this.bulkMessageWriter = new WriterToBulkWriter<>(messageWriter);    return this;}
public BulkMessageWriterBolt<CONFIG_T> metron_f7844_0(String messageGetStrategyType)
{    this.messageGetStrategyType = messageGetStrategyType;    return this;}
public BulkMessageWriterBolt<CONFIG_T> metron_f7845_0(String messageGetField)
{    this.messageGetField = messageGetField;    return this;}
public BulkMessageWriterBolt<CONFIG_T> metron_f7846_0(int batchTimeoutDivisor)
{    if (batchTimeoutDivisor <= 0) {        throw new IllegalArgumentException(String.format("batchTimeoutDivisor must be positive. Value provided was %s", batchTimeoutDivisor));    }    this.batchTimeoutDivisor = batchTimeoutDivisor;    return this;}
protected void metron_f7847_0(int maxBatchTimeout)
{    this.maxBatchTimeout = maxBatchTimeout;}
public int metron_f7848_0()
{    return maxBatchTimeout;}
public BulkWriterComponent<JSONObject> metron_f7849_0()
{    return writerComponent;}
public void metron_f7850_0(BulkWriterComponent<JSONObject> component)
{    writerComponent = component;}
public Map<String, Object> metron_f7851_1()
{                Function<WriterConfiguration, WriterConfiguration> configurationXform;    if (bulkMessageWriter instanceof WriterToBulkWriter) {        configurationXform = WriterToBulkWriter.TRANSFORMATION;    } else {        configurationXform = x -> x;    }    WriterConfiguration writerconf = configurationXform.apply(getConfigurationStrategy().createWriterConfig(bulkMessageWriter, getConfigurations()));    BatchTimeoutHelper timeoutHelper = new BatchTimeoutHelper(writerconf::getAllConfiguredTimeouts, batchTimeoutDivisor);    this.requestedTickFreqSecs = timeoutHelper.getRecommendedTickInterval();        this.maxBatchTimeout = timeoutHelper.getMaxBatchTimeout();    Map<String, Object> conf = super.getComponentConfiguration();    if (conf == null) {        conf = new HashMap<String, Object>();    }    conf.put(Config.TOPOLOGY_TICK_TUPLE_FREQ_SECS, requestedTickFreqSecs);        return conf;}
public void metron_f7852_0(Map stormConf, TopologyContext context, OutputCollector collector)
{    this.collector = collector;    super.prepare(stormConf, context, collector);    if (messageGetField != null) {        messageGetStrategy = MessageGetters.valueOf(messageGetStrategyType).get(messageGetField);    } else {        messageGetStrategy = MessageGetters.valueOf(messageGetStrategyType).get();    }    if (bulkMessageWriter instanceof WriterToBulkWriter) {        configurationTransformation = WriterToBulkWriter.TRANSFORMATION;    } else {        configurationTransformation = x -> x;    }    ackTuplesPolicy = new AckTuplesPolicy(collector, messageGetStrategy);    try {        WriterConfiguration writerconf = configurationTransformation.apply(getConfigurationStrategy().createWriterConfig(bulkMessageWriter, getConfigurations()));        if (maxBatchTimeout == 0) {                                    BatchTimeoutHelper timeoutHelper = new BatchTimeoutHelper(writerconf::getAllConfiguredTimeouts, batchTimeoutDivisor);            maxBatchTimeout = timeoutHelper.getMaxBatchTimeout();        }        BulkWriterComponent<JSONObject> bulkWriterComponent = new BulkWriterComponent<>(maxBatchTimeout);        bulkWriterComponent.addFlushPolicy(ackTuplesPolicy);        setWriterComponent(bulkWriterComponent);        bulkMessageWriter.init(stormConf, writerconf);        if (bulkMessageWriter instanceof HdfsWriter) {            ((HdfsWriter) bulkMessageWriter).initFileNameFormat(context);        }    } catch (Exception e) {        throw new RuntimeException(e);    }}
public void metron_f7853_0(Map stormConf, TopologyContext context, OutputCollector collector, Clock clock)
{    prepare(stormConf, context, collector);    BulkWriterComponent<JSONObject> bulkWriterComponent = new BulkWriterComponent<>(maxBatchTimeout, clock);    bulkWriterComponent.addFlushPolicy(ackTuplesPolicy);    setWriterComponent(bulkWriterComponent);}
public void metron_f7854_1(Tuple tuple)
{    if (isTick(tuple)) {        try {            if (!(bulkMessageWriter instanceof WriterToBulkWriter)) {                                                getWriterComponent().flushAll(bulkMessageWriter, configurationTransformation.apply(getConfigurationStrategy().createWriterConfig(bulkMessageWriter, getConfigurations())));            }        } catch (Exception e) {            throw new RuntimeException("This should have been caught in the writerComponent.  If you see this, file a JIRA", e);        } finally {            collector.ack(tuple);        }        return;    }    try {        JSONObject message = getMessage(tuple);        if (message == null) {            handleMissingMessage(tuple);            return;        }        String sensorType = MessageUtils.getSensorType(message);        if (sensorType == null) {            handleMissingSensorType(tuple, message);            return;        }        LOG.trace("Writing enrichment message: {}", message);        WriterConfiguration writerConfiguration = configurationTransformation.apply(getConfigurationStrategy().createWriterConfig(bulkMessageWriter, getConfigurations()));        if (writerConfiguration.isDefault(sensorType)) {                        collector.reportError(new Exception("WARNING: Default and (likely) unoptimized writer config used for " + bulkMessageWriter.getName() + " writer and sensor " + sensorType));        }        String messagesId = MessageUtils.getGuid(message);        ackTuplesPolicy.addTupleMessageIds(tuple, Collections.singleton(messagesId));        getWriterComponent().write(sensorType, new BulkMessage<>(messagesId, message), bulkMessageWriter, writerConfiguration);    } catch (Exception e) {        throw new RuntimeException("This should have been caught in the writerComponent.  If you see this, file a JIRA", e);    }}
private JSONObject metron_f7855_1(Tuple tuple)
{    JSONObject message = null;    try {        message = (JSONObject) messageGetStrategy.get(tuple);    } catch (Throwable e) {            }    return message;}
public void metron_f7858_0(OutputFieldsDeclarer declarer)
{    declarer.declareStream(Constants.ERROR_STREAM, new Fields("message"));}
public SyncPolicy metron_f7859_0(String sensor, WriterConfiguration config)
{    try {                                                                        syncPolicy.reset();        byte[] serializedForm = SerDeUtils.toBytes(syncPolicy);        return SerDeUtils.fromBytes(serializedForm, SyncPolicy.class);    } catch (Exception e) {        throw new IllegalStateException(e.getMessage(), e);    }}
public HdfsWriter metron_f7860_0(FileNameFormat fileNameFormat)
{    this.fileNameFormat = fileNameFormat;    return this;}
public HdfsWriter metron_f7861_0(SyncPolicy syncPolicy)
{    this.syncPolicy = syncPolicy;    return this;}
public HdfsWriter metron_f7862_0(FileRotationPolicy rotationPolicy)
{    this.rotationPolicy = rotationPolicy;    return this;}
public HdfsWriter metron_f7863_0(RotationAction action)
{    this.rotationActions.add(action);    return this;}
public HdfsWriter metron_f7864_0(int maxOpenFiles)
{    this.maxOpenFiles = maxOpenFiles;    return this;}
public void metron_f7865_1(Map stormConfig, WriterConfiguration configurations)
{    this.stormConfig = stormConfig;    this.stellarProcessor = new StellarProcessor();    if (syncPolicy != null) {                        syncPolicyCreator = new ClonedSyncPolicyCreator(syncPolicy);    } else {                        syncPolicyCreator = (source, config) -> new CountSyncPolicy(config == null ? 1 : config.getBatchSize(source));    }}
public void metron_f7866_0(TopologyContext topologyContext)
{    this.fileNameFormat.prepare(stormConfig, topologyContext);}
public BulkWriterResponse metron_f7867_1(String sensorType, WriterConfiguration configurations, List<BulkMessage<JSONObject>> messages) throws Exception
{    BulkWriterResponse response = new BulkWriterResponse();    Set<MessageId> ids = messages.stream().map(BulkMessage::getId).collect(Collectors.toSet());        for (BulkMessage<JSONObject> bulkWriterMessage : messages) {        JSONObject message = bulkWriterMessage.getMessage();        String path = getHdfsPathExtension(sensorType, (String) configurations.getSensorConfig(sensorType).getOrDefault(IndexingConfigurations.OUTPUT_PATH_FUNCTION_CONF, ""), message);        try {            LOG.trace("Writing message {} to path: {}", () -> message.toJSONString(), () -> path);            SourceHandler handler = getSourceHandler(sensorType, path, configurations);            handler.handle(message, sensorType, configurations, syncPolicyCreator);        } catch (Exception e) {                        response.addAllErrors(e, ids);        }    }    response.addAllSuccesses(ids);    return response;}
public String metron_f7869_0()
{    return "hdfs";}
public void metron_f7870_1()
{    for (SourceHandler handler : sourceHandlerMap.values()) {                handler.close();    }        sourceHandlerMap.clear();}
 synchronized SourceHandler metron_f7871_1(String sourceType, String stellarResult, WriterConfiguration config) throws IOException
{    SourceHandlerKey key = new SourceHandlerKey(sourceType, stellarResult);    SourceHandler ret = sourceHandlerMap.get(key);    if (ret == null) {        if (sourceHandlerMap.size() >= maxOpenFiles) {            String errorMsg = "Too many HDFS files open! Maximum number of open files is: " + maxOpenFiles + ". Current number of open files is: " + sourceHandlerMap.size();                        throw new IllegalStateException(errorMsg);        }        ret = new SourceHandler(rotationActions, rotationPolicy, syncPolicyCreator.create(sourceType, config), new PathExtensionFileNameFormat(key.getStellarResult(), fileNameFormat), new SourceHandlerCallback(sourceHandlerMap, key));                sourceHandlerMap.put(key, ret);    }    return ret;}
public void metron_f7872_0(Map map, TopologyContext topologyContext)
{    this.delegate.prepare(map, topologyContext);}
public String metron_f7873_0(long rotation, long l1)
{    return delegate.getName(rotation, l1);}
public String metron_f7874_0()
{    return delegate.getPath() + "/" + pathExtension;}
public SourceAwareMoveAction metron_f7875_0(String destDir)
{    destination = destDir;    return this;}
private static String metron_f7876_0(Path filePath)
{    return filePath.getParent().getName();}
public void metron_f7877_1(FileSystem fileSystem, Path filePath) throws IOException
{    Path destPath = new Path(new Path(destination, getSource(filePath)), filePath.getName());        boolean success = fileSystem.rename(filePath, destPath);}
protected void metron_f7878_1(JSONObject message, String sensor, WriterConfiguration config, SyncPolicyCreator syncPolicyCreator) throws IOException
{    byte[] bytes = (message.toJSONString() + "\n").getBytes(StandardCharsets.UTF_8);    synchronized (this.writeLock) {        try {            out.write(bytes);        } catch (IOException writeException) {                                    if (writeException.getMessage().contains("Stream Closed")) {                                rotateOutputFile();                                out.write(bytes);            } else {                throw writeException;            }        }        this.offset += bytes.length;        if (this.syncPolicy.mark(null, this.offset)) {                        if (this.out instanceof HdfsDataOutputStream) {                ((HdfsDataOutputStream) this.out).hsync(EnumSet.of(HdfsDataOutputStream.SyncFlag.UPDATE_LENGTH));            } else {                this.out.hsync();            }                                                this.syncPolicy = syncPolicyCreator.create(sensor, config);        }    }    if (this.rotationPolicy.mark(null, this.offset)) {                        rotateOutputFile();        this.offset = 0;        this.rotationPolicy.reset();    }}
private void metron_f7879_1() throws IOException
{        this.fs = FileSystem.get(new Configuration());    this.currentFile = createOutputFile();        if (this.rotationPolicy instanceof TimedRotationPolicy) {        long interval = ((TimedRotationPolicy) this.rotationPolicy).getInterval();        this.rotationTimer = new Timer(true);        TimerTask task = new TimerTask() {            @Override            public void run() {                try {                                        rotateOutputFile();                } catch (IOException e) {                                    }            }        };        this.rotationTimer.scheduleAtFixedRate(task, interval, interval);    }}
public void metron_f7880_1()
{    try {                rotateOutputFile();    } catch (IOException e) {            }}
protected void metron_f7881_1() throws IOException
{        long start = System.currentTimeMillis();    synchronized (this.writeLock) {        closeOutputFile();                cleanupCallback();                for (RotationAction action : this.rotationActions) {            action.execute(this.fs, this.currentFile);        }    }    long time = System.currentTimeMillis() - start;    }
private Path metron_f7882_1() throws IOException
{                Path path = new Path(this.fileNameFormat.getPath(), this.fileNameFormat.getName(0, System.currentTimeMillis()));        if (fs.getScheme().equals("file")) {                fs.mkdirs(path.getParent());        this.out = new FSDataOutputStream(new FileOutputStream(path.toString()), null);    } else {        this.out = this.fs.create(path);    }    return path;}
protected void metron_f7883_0() throws IOException
{    this.out.close();}
private void metron_f7884_0()
{    this.cleanupCallback.removeKey();}
public void metron_f7885_0()
{    try {        closeOutputFile();        if (rotationTimer != null) {            rotationTimer.cancel();        }        } catch (IOException e) {        throw new RuntimeException("Unable to close output file.", e);    }}
public String metron_f7886_0()
{    return "SourceHandler{" + "rotationActions=" + rotationActions + ", rotationPolicy=" + rotationPolicy + ", syncPolicy=" + syncPolicy + ", fileNameFormat=" + fileNameFormat + ", offset=" + offset + ", out=" + out + ", writeLock=" + writeLock + ", rotationTimer=" + rotationTimer + ", fs=" + fs + ", currentFile=" + currentFile + '}';}
public void metron_f7887_1()
{    SourceHandler removed = sourceHandlerMap.remove(key);    if (removed != null) {        removed.close();    }    }
public String metron_f7888_0()
{    return sourceType;}
public String metron_f7889_0()
{    return stellarResult;}
public boolean metron_f7890_0(Object o)
{    if (this == o) {        return true;    }    if (o == null || getClass() != o.getClass()) {        return false;    }    SourceHandlerKey that = (SourceHandlerKey) o;    if (sourceType != null ? !sourceType.equals(that.sourceType) : that.sourceType != null) {        return false;    }    return stellarResult != null ? stellarResult.equals(that.stellarResult) : that.stellarResult == null;}
public int metron_f7891_0()
{    int result = sourceType != null ? sourceType.hashCode() : 0;    result = 31 * result + (stellarResult != null ? stellarResult.hashCode() : 0);    return result;}
public String metron_f7892_0()
{    return "SourceHandlerKey{" + "sourceType='" + sourceType + '\'' + ", stellarResult='" + stellarResult + '\'' + '}';}
public void metron_f7893_0()
{    MockitoAnnotations.initMocks(this);    ackTuplesPolicy = new AckTuplesPolicy(collector, messageGetStrategy);}
public void metron_f7894_0() throws Exception
{    String messageId1 = "messageId1";    String messageId2 = "messageId2";    String messageId3 = "messageId3";    JSONObject message1 = new JSONObject();    JSONObject message2 = new JSONObject();    JSONObject message3 = new JSONObject();    message1.put("value", "message1");    message2.put("value", "message2");    message3.put("value", "message3");    Tuple tuple3 = mock(Tuple.class);    Throwable e = new Exception("test exception");    MetronError expectedError1 = new MetronError().withSensorType(Collections.singleton(sensorType)).withErrorType(Constants.ErrorType.INDEXING_ERROR).withThrowable(e).withRawMessages(Collections.singletonList(message1));    MetronError expectedError2 = new MetronError().withSensorType(Collections.singleton(sensorType)).withErrorType(Constants.ErrorType.INDEXING_ERROR).withThrowable(e).withRawMessages(Collections.singletonList(message2));    BulkWriterResponse response = new BulkWriterResponse();    response.addAllErrors(e, Arrays.asList(new MessageId(messageId1), new MessageId(messageId2)));    response.addSuccess(new MessageId(messageId3));    when(messageGetStrategy.get(tuple1)).thenReturn(message1);    when(messageGetStrategy.get(tuple2)).thenReturn(message2);    ackTuplesPolicy.addTupleMessageIds(tuple1, Collections.singleton(messageId1));    ackTuplesPolicy.addTupleMessageIds(tuple2, Collections.singleton(messageId2));    ackTuplesPolicy.addTupleMessageIds(tuple3, Collections.singleton(messageId3));    ackTuplesPolicy.onFlush(sensorType, response);    Assert.assertEquals(0, ackTuplesPolicy.getTupleMessageMap().size());    Assert.assertEquals(0, ackTuplesPolicy.getTupleErrorMap().size());    verify(collector, times(1)).emit(eq(Constants.ERROR_STREAM), new Values(argThat(new MetronErrorJSONMatcher(expectedError1.getJSONObject()))));    verify(collector, times(1)).emit(eq(Constants.ERROR_STREAM), new Values(argThat(new MetronErrorJSONMatcher(expectedError2.getJSONObject()))));    verify(collector, times(1)).ack(tuple1);    verify(collector, times(1)).ack(tuple2);    verify(collector, times(1)).ack(tuple3);    verify(collector, times(1)).reportError(e);    verifyNoMoreInteractions(collector);}
public void metron_f7895_0()
{    AckTuplesPolicy ackTuplesPolicy = new AckTuplesPolicy(collector, messageGetStrategy);    JSONObject rawMessage1 = new JSONObject();    JSONObject rawMessage2 = new JSONObject();    rawMessage1.put("value", "rawMessage1");    rawMessage2.put("value", "rawMessage2");    String messageId1 = "messageId1";    String messageId2 = "messageId2";    String messageId3 = "messageId3";    JSONObject message1 = new JSONObject();    JSONObject message2 = new JSONObject();    JSONObject message3 = new JSONObject();    message1.put("value", "message1");    message2.put("value", "message2");    message3.put("value", "message3");    Throwable e1 = new Exception("test exception 1");    Throwable e2 = new Exception("test exception 2");    MetronError expectedError1 = new MetronError().withSensorType(Collections.singleton(sensorType)).withErrorType(Constants.ErrorType.INDEXING_ERROR).withThrowable(e1).withRawMessages(Collections.singletonList(rawMessage1));    MetronError expectedError2 = new MetronError().withSensorType(Collections.singleton(sensorType)).withErrorType(Constants.ErrorType.INDEXING_ERROR).withThrowable(e2).withRawMessages(Collections.singletonList(rawMessage1));    MetronError expectedError3 = new MetronError().withSensorType(Collections.singleton(sensorType)).withErrorType(Constants.ErrorType.INDEXING_ERROR).withThrowable(e1).withRawMessages(Collections.singletonList(rawMessage2));    when(messageGetStrategy.get(tuple1)).thenReturn(rawMessage1);    when(messageGetStrategy.get(tuple2)).thenReturn(rawMessage2);    ackTuplesPolicy.addTupleMessageIds(tuple1, Arrays.asList(messageId1, messageId2));    ackTuplesPolicy.addTupleMessageIds(tuple2, Collections.singletonList(messageId3));    BulkWriterResponse response = new BulkWriterResponse();    response.addError(e1, new MessageId(messageId1));    ackTuplesPolicy.onFlush(sensorType, response);    Assert.assertEquals(2, ackTuplesPolicy.getTupleMessageMap().size());    Assert.assertEquals(1, ackTuplesPolicy.getTupleErrorMap().size());    verify(collector, times(0)).ack(any());    verify(collector, times(0)).reportError(any());    verify(collector, times(1)).emit(eq(Constants.ERROR_STREAM), new Values(argThat(new MetronErrorJSONMatcher(expectedError1.getJSONObject()))));    response = new BulkWriterResponse();    response.addError(e2, new MessageId(messageId2));    response.addError(e1, new MessageId(messageId3));    ackTuplesPolicy.onFlush(sensorType, response);    Assert.assertEquals(0, ackTuplesPolicy.getTupleMessageMap().size());    Assert.assertEquals(0, ackTuplesPolicy.getTupleErrorMap().size());    verify(collector, times(1)).ack(tuple1);    verify(collector, times(1)).ack(tuple2);    verify(collector, times(1)).reportError(e1);    verify(collector, times(1)).reportError(e2);    verify(collector, times(1)).emit(eq(Constants.ERROR_STREAM), new Values(argThat(new MetronErrorJSONMatcher(expectedError2.getJSONObject()))));    verify(collector, times(1)).emit(eq(Constants.ERROR_STREAM), new Values(argThat(new MetronErrorJSONMatcher(expectedError3.getJSONObject()))));    verifyNoMoreInteractions(collector);}
public void metron_f7896_0()
{    ackTuplesPolicy.addTupleMessageIds(tuple1, Collections.singletonList("message1"));    ackTuplesPolicy.addTupleMessageIds(tuple2, Collections.singletonList("message2"));    BulkWriterResponse response = new BulkWriterResponse();    response.addSuccess(new MessageId("message1"));    response.addSuccess(new MessageId("message2"));    ackTuplesPolicy.onFlush(sensorType, response);    Assert.assertEquals(0, ackTuplesPolicy.getTupleMessageMap().size());    verify(collector, times(1)).ack(tuple1);    verify(collector, times(1)).ack(tuple2);    verifyNoMoreInteractions(collector);}
public void metron_f7897_0()
{    ackTuplesPolicy.addTupleMessageIds(tuple1, Arrays.asList("message1", "message2", "message3"));    BulkWriterResponse response = new BulkWriterResponse();    response.addSuccess(new MessageId("message1"));    response.addSuccess(new MessageId("message2"));    ackTuplesPolicy.onFlush(sensorType, response);    verify(collector, times(0)).ack(any());    response = new BulkWriterResponse();    response.addSuccess(new MessageId("message3"));    ackTuplesPolicy.onFlush(sensorType, response);    Assert.assertEquals(0, ackTuplesPolicy.getTupleMessageMap().size());    verify(collector, times(1)).ack(tuple1);    verifyNoMoreInteractions(collector);}
public void metron_f7898_0() throws Exception
{            assertEquals(30, Utils.readStormConfig().getOrDefault(Config.TOPOLOGY_MESSAGE_TIMEOUT_SECS, 0));    BatchTimeoutHelper bth;    bth = new BatchTimeoutHelper(defaultConfigList, 1);    assertEquals(14, bth.getMaxBatchTimeout());    bth = new BatchTimeoutHelper(defaultConfigList, 2);    assertEquals(6, bth.getMaxBatchTimeout());    bth = new BatchTimeoutHelper(defaultConfigList, 3);    assertEquals(4, bth.getMaxBatchTimeout());    bth = new BatchTimeoutHelper(defaultConfigList, 4);    assertEquals(2, bth.getMaxBatchTimeout());    bth = new BatchTimeoutHelper(defaultConfigList, 6);    assertEquals(1, bth.getMaxBatchTimeout());    bth = new BatchTimeoutHelper(defaultConfigList, 20);    assertEquals(1, bth.getMaxBatchTimeout());    bth = new BatchTimeoutHelper(disabledConfigList, 2);    assertEquals(6, bth.getMaxBatchTimeout());    bth = new BatchTimeoutHelper(smallTimeoutsList, 2);    assertEquals(6, bth.getMaxBatchTimeout());}
public void metron_f7899_0() throws Exception
{        BatchTimeoutHelper bth;    bth = new BatchTimeoutHelper(defaultConfigList, 2);    assertEquals(6, bth.getRecommendedTickInterval());    bth = new BatchTimeoutHelper(disabledConfigList, 2);    assertEquals(6, bth.getRecommendedTickInterval());    bth = new BatchTimeoutHelper(largeTimeoutsList, 2);    assertEquals(6, bth.getRecommendedTickInterval());    bth = new BatchTimeoutHelper(smallTimeoutsList, 2);    assertEquals(2, bth.getRecommendedTickInterval());    bth = new BatchTimeoutHelper(illegalTimeoutsList, 2);    assertEquals(2, bth.getRecommendedTickInterval());}
public List<Integer> metron_f7900_0()
{    return list;}
public void metron_f7901_0() throws ParseException
{    JSONParser parser = new JSONParser();    fullMessageList = new ArrayList<>();    sampleMessage = (JSONObject) parser.parse(sampleMessageString);    sampleMessage.put(Constants.GUID, "message1");    sampleMessage.put("field", "value1");    fullMessageList.add(((JSONObject) sampleMessage.clone()));    sampleMessage.put(Constants.GUID, "message2");    sampleMessage.put("field", "value2");    fullMessageList.add(((JSONObject) sampleMessage.clone()));    sampleMessage.put(Constants.GUID, "message3");    sampleMessage.put("field", "value3");    fullMessageList.add(((JSONObject) sampleMessage.clone()));    sampleMessage.put(Constants.GUID, "message4");    sampleMessage.put("field", "value4");    fullMessageList.add(((JSONObject) sampleMessage.clone()));    sampleMessage.put(Constants.GUID, "message5");    sampleMessage.put("field", "value5");    fullMessageList.add(((JSONObject) sampleMessage.clone()));    MockitoAnnotations.initMocks(this);    messageIdList = new ArrayList<>();    tupleList = new ArrayList<>();    messageList = new ArrayList<>();    bulkMessageWriterBolt = spy(new BulkMessageWriterBolt<IndexingConfigurations>("zookeeperUrl", "INDEXING").withBulkMessageWriter(bulkMessageWriter).withMessageGetter(MessageGetters.JSON_FROM_FIELD.name()).withMessageGetterField("message"));    for (int i = 0; i < 5; i++) {        String messageId = String.format("message%s", i + 1);        messageIdList.add(new MessageId(messageId));        JSONObject message = fullMessageList.get(i);        Tuple tuple = mock(Tuple.class);        when(tuple.getValueByField("message")).thenReturn(message);        tupleList.add(tuple);        messageList.add(new BulkMessage<>(messageId, message));    }}
public void metron_f7902_0() throws Exception
{        BulkMessageWriterBolt<IndexingConfigurations> bulkMessageWriterBolt = new BulkMessageWriterBolt<IndexingConfigurations>("zookeeperUrl", "INDEXING").withBulkMessageWriter(bulkMessageWriter).withMessageGetter(MessageGetters.JSON_FROM_FIELD.name()).withMessageGetterField("message");    bulkMessageWriterBolt.setCuratorFramework(client);    bulkMessageWriterBolt.setZKCache(cache);    bulkMessageWriterBolt.getConfigurations().updateSensorIndexingConfig(BaseEnrichmentBoltTest.sensorType, new FileInputStream("../" + BaseEnrichmentBoltTest.sampleSensorIndexingConfigPath));        bulkMessageWriterBolt.declareOutputFields(declarer);    Map stormConf = new HashMap();    bulkMessageWriterBolt.prepare(stormConf, topologyContext, outputCollector);        JSONObject message = (JSONObject) new JSONParser().parse(sampleMessageString);    message.remove("source.type");    when(tuple.getValueByField("message")).thenReturn(message);        bulkMessageWriterBolt.execute(tuple);    verify(outputCollector, times(1)).emit(eq(Constants.ERROR_STREAM), any());    verify(outputCollector, times(1)).ack(tuple);    verify(outputCollector, times(1)).reportError(any(Throwable.class));    Mockito.verifyNoMoreInteractions(outputCollector);}
public void metron_f7903_0() throws Exception
{    Map stormConf = new HashMap();    bulkMessageWriterBolt.setCuratorFramework(client);    bulkMessageWriterBolt.setZKCache(cache);    bulkMessageWriterBolt.getConfigurations().updateSensorIndexingConfig(BaseEnrichmentBoltTest.sensorType, new FileInputStream("../" + BaseEnrichmentBoltTest.sampleSensorIndexingConfigPath));    {        doThrow(new Exception()).when(bulkMessageWriter).init(eq(stormConf), any(WriterConfiguration.class));        try {            bulkMessageWriterBolt.prepare(stormConf, topologyContext, outputCollector);            fail("A runtime exception should be thrown when bulkMessageWriter.init throws an exception");        } catch (RuntimeException e) {        }        reset(bulkMessageWriter);    }    {        when(bulkMessageWriter.getName()).thenReturn("hdfs");        bulkMessageWriterBolt.prepare(stormConf, topologyContext, outputCollector);        verify(bulkMessageWriter, times(1)).init(eq(stormConf), any(WriterConfiguration.class));    }    {        for (int i = 0; i < 4; i++) {            bulkMessageWriterBolt.execute(tupleList.get(i));            verify(bulkMessageWriter, times(0)).write(eq(BaseEnrichmentBoltTest.sensorType), any(WriterConfiguration.class), anyList());        }        BulkWriterResponse response = new BulkWriterResponse();        response.addAllSuccesses(messageIdList);        when(bulkMessageWriter.write(eq(BaseEnrichmentBoltTest.sensorType), any(WriterConfiguration.class), eq(messageList))).thenReturn(response);        bulkMessageWriterBolt.execute(tupleList.get(4));        verify(bulkMessageWriter, times(1)).write(eq(BaseEnrichmentBoltTest.sensorType), any(WriterConfiguration.class), eq(messageList));        tupleList.forEach(tuple -> verify(outputCollector, times(1)).ack(tuple));        reset(outputCollector);    }    {        doThrow(new Exception()).when(bulkMessageWriter).write(eq(BaseEnrichmentBoltTest.sensorType), any(WriterConfiguration.class), anyList());        UnitTestHelper.setLog4jLevel(BulkWriterComponent.class, Level.FATAL);        for (int i = 0; i < 5; i++) {            bulkMessageWriterBolt.execute(tupleList.get(i));        }        UnitTestHelper.setLog4jLevel(BulkWriterComponent.class, Level.ERROR);        tupleList.forEach(tuple -> verify(outputCollector, times(1)).ack(tuple));        verify(outputCollector, times(5)).emit(eq(Constants.ERROR_STREAM), any(Values.class));        verify(outputCollector, times(1)).reportError(any(Throwable.class));    }    Mockito.verifyNoMoreInteractions(outputCollector);}
public void metron_f7904_0() throws Exception
{    FakeClock clock = new FakeClock();    bulkMessageWriterBolt = bulkMessageWriterBolt.withBatchTimeoutDivisor(3);    bulkMessageWriterBolt.setCuratorFramework(client);    bulkMessageWriterBolt.setZKCache(cache);    bulkMessageWriterBolt.getConfigurations().updateSensorIndexingConfig(BaseEnrichmentBoltTest.sensorType, new FileInputStream("../" + BaseEnrichmentBoltTest.sampleSensorIndexingConfigPath));    {        bulkMessageWriterBolt.declareOutputFields(declarer);        verify(declarer, times(1)).declareStream(eq("error"), argThat(new FieldsMatcher("message")));    }    {        Map stormConf = new HashMap();        when(bulkMessageWriter.getName()).thenReturn("elasticsearch");        bulkMessageWriterBolt.prepare(stormConf, topologyContext, outputCollector, clock);        verify(bulkMessageWriter, times(1)).init(eq(stormConf), any(WriterConfiguration.class));    }    {        int batchTimeout = bulkMessageWriterBolt.getMaxBatchTimeout();        assertEquals(4, batchTimeout);        for (int i = 0; i < 4; i++) {            bulkMessageWriterBolt.execute(tupleList.get(i));            verify(bulkMessageWriter, times(0)).write(eq(BaseEnrichmentBoltTest.sensorType), any(WriterConfiguration.class), any(List.class));        }        clock.elapseSeconds(5);        BulkWriterResponse response = new BulkWriterResponse();        response.addAllSuccesses(messageIdList);        when(bulkMessageWriter.write(eq(BaseEnrichmentBoltTest.sensorType), any(WriterConfiguration.class), eq(messageList))).thenReturn(response);        bulkMessageWriterBolt.execute(tupleList.get(4));        verify(bulkMessageWriter, times(1)).write(eq(BaseEnrichmentBoltTest.sensorType), any(WriterConfiguration.class), eq(messageList));        tupleList.forEach(tuple -> verify(outputCollector, times(1)).ack(tuple));    }    Mockito.verifyNoMoreInteractions(outputCollector);}
public void metron_f7905_0() throws Exception
{    FakeClock clock = new FakeClock();    bulkMessageWriterBolt.setCuratorFramework(client);    bulkMessageWriterBolt.setZKCache(cache);    bulkMessageWriterBolt.getConfigurations().updateSensorIndexingConfig(BaseEnrichmentBoltTest.sensorType, new FileInputStream("../" + BaseEnrichmentBoltTest.sampleSensorIndexingConfigPath));    {        bulkMessageWriterBolt.declareOutputFields(declarer);        verify(declarer, times(1)).declareStream(eq("error"), argThat(new FieldsMatcher("message")));    }    {        Map stormConf = new HashMap();        when(bulkMessageWriter.getName()).thenReturn("elasticsearch");        bulkMessageWriterBolt.prepare(stormConf, topologyContext, outputCollector, clock);        verify(bulkMessageWriter, times(1)).init(eq(stormConf), any(WriterConfiguration.class));    }    {        int batchTimeout = bulkMessageWriterBolt.getMaxBatchTimeout();        assertEquals(14, batchTimeout);        for (int i = 0; i < 5; i++) {            bulkMessageWriterBolt.execute(tupleList.get(i));            verify(bulkMessageWriter, times(0)).write(eq(BaseEnrichmentBoltTest.sensorType), any(WriterConfiguration.class), any());        }        Tuple tickTuple = mock(Tuple.class);        when(tickTuple.getValueByField("message")).thenReturn(null);                when(tickTuple.getSourceComponent()).thenReturn("__system");                when(tickTuple.getSourceStreamId()).thenReturn("__tick");        BulkWriterResponse response = new BulkWriterResponse();        response.addAllSuccesses(messageIdList);        when(bulkMessageWriter.write(eq(BaseEnrichmentBoltTest.sensorType), any(WriterConfiguration.class), eq(messageList))).thenReturn(response);        clock.advanceToSeconds(2);        bulkMessageWriterBolt.execute(tickTuple);        verify(bulkMessageWriter, times(0)).write(eq(BaseEnrichmentBoltTest.sensorType), any(WriterConfiguration.class), eq(messageList));                verify(outputCollector, times(1)).ack(tickTuple);        clock.advanceToSeconds(9);        bulkMessageWriterBolt.execute(tickTuple);        verify(bulkMessageWriter, times(1)).write(eq(BaseEnrichmentBoltTest.sensorType), any(WriterConfiguration.class), eq(messageList));        assertEquals(5, tupleList.size());        tupleList.forEach(tuple -> verify(outputCollector, times(1)).ack(tuple));        verify(outputCollector, times(2)).ack(tickTuple);    }    Mockito.verifyNoMoreInteractions(outputCollector);}
public void metron_f7906_0() throws Exception
{    FakeClock clock = new FakeClock();        BulkMessageWriterBolt<IndexingConfigurations> bolt = new BulkMessageWriterBolt<IndexingConfigurations>("zookeeperUrl", "INDEXING").withBulkMessageWriter(bulkMessageWriter).withMessageGetter(MessageGetters.JSON_FROM_POSITION.name()).withMessageGetterField("message");    bolt.setCuratorFramework(client);    bolt.setZKCache(cache);    bolt.getConfigurations().updateSensorIndexingConfig(BaseEnrichmentBoltTest.sensorType, new FileInputStream("../" + BaseEnrichmentBoltTest.sampleSensorIndexingConfigPath));        bolt.declareOutputFields(declarer);    Map stormConf = new HashMap();    bolt.prepare(stormConf, topologyContext, outputCollector, clock);        byte[] invalidJSON = "this is not valid JSON".getBytes(StandardCharsets.UTF_8);    when(tuple.getBinary(0)).thenReturn(invalidJSON);    bolt.execute(tuple);        verify(outputCollector, times(1)).emit(eq(Constants.ERROR_STREAM), any());    verify(outputCollector, times(1)).ack(tuple);    verify(outputCollector, times(1)).reportError(any(Throwable.class));    Mockito.verifyNoMoreInteractions(outputCollector);}
public void metron_f7907_0()
{    BulkMessageWriterBolt<IndexingConfigurations> bulkMessageWriterBolt = new BulkMessageWriterBolt<IndexingConfigurations>("zookeeperUrl", "INDEXING");    bulkMessageWriterBolt.declareOutputFields(declarer);    verify(declarer, times(1)).declareStream(eq("error"), argThat(new FieldsMatcher("message")));}
public void metron_f7908_0()
{    CountSyncPolicy basePolicy = new CountSyncPolicy(5);    ClonedSyncPolicyCreator creator = new ClonedSyncPolicyCreator(basePolicy);        SyncPolicy clonedPolicy = creator.create("blah", null);    for (int i = 0; i < 4; ++i) {        Assert.assertFalse(clonedPolicy.mark(null, i));    }    Assert.assertTrue(clonedPolicy.mark(null, 5));        clonedPolicy = creator.create("blah", null);    Assert.assertFalse(clonedPolicy.mark(null, 0));}
public static void metron_f7909_0() throws Exception
{            Thread.interrupted();}
public void metron_f7910_0() throws IOException
{        folder = tempFolder.newFolder();    testFormat = new DefaultFileNameFormat().withPath(folder.toString()).withExtension(".json").withPrefix("prefix-");}
public void metron_f7911_0()
{    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, new IndexingConfigurations());    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    JSONObject message = new JSONObject();    Object result = writer.getHdfsPathExtension(SENSOR_NAME, null, message);    writer.close();    Assert.assertEquals(SENSOR_NAME, result);}
public void metron_f7912_0()
{    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, new IndexingConfigurations());    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    JSONObject message = new JSONObject();    Object result = writer.getHdfsPathExtension(SENSOR_NAME, "", message);    writer.close();    Assert.assertEquals(SENSOR_NAME, result);}
public void metron_f7913_0()
{    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, new IndexingConfigurations());    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    JSONObject message = new JSONObject();    Object result = writer.getHdfsPathExtension(SENSOR_NAME, "'new'", message);    writer.close();    Assert.assertEquals("new", result);}
public void metron_f7914_0()
{    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, new IndexingConfigurations());    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    JSONObject message = new JSONObject();    message.put("test.key", "test.value");    Object result = writer.getHdfsPathExtension(SENSOR_NAME, "test.key", message);    writer.close();    Assert.assertEquals("test.value", result);}
public void metron_f7915_0()
{    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, new IndexingConfigurations());    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    JSONObject message = new JSONObject();    Object result = writer.getHdfsPathExtension(SENSOR_NAME, "FORMAT('/test/folder/')", message);    writer.close();    Assert.assertEquals("/test/folder/", result);}
public void metron_f7916_0()
{    IndexingConfigurations indexingConfig = new IndexingConfigurations();    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, indexingConfig);    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    JSONObject message = new JSONObject();    message.put("test.key", "test.value");    message.put("test.key.2", "test.value.2");    message.put("test.key.3", "test.value.3");    Object result = writer.getHdfsPathExtension(SENSOR_NAME, "FORMAT('%s/%s/%s', test.key, test.key.2, test.key.3)", message);    writer.close();    Assert.assertEquals("test.value/test.value.2/test.value.3", result);}
public void metron_f7917_0()
{    IndexingConfigurations indexingConfig = new IndexingConfigurations();    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, indexingConfig);    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    String filename = writer.fileNameFormat.getName(1, 1);    Assert.assertEquals("prefix-Xcom-7-1-1.json", filename);    writer.close();}
public void metron_f7918_0()
{    IndexingConfigurations indexingConfig = new IndexingConfigurations();    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, indexingConfig);    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    JSONObject message = new JSONObject();    message.put("test.key", "test.value");    message.put("test.key.2", "test.value.2");    Object result = writer.getHdfsPathExtension(SENSOR_NAME, "FORMAT('%s', test.key)", message);    Assert.assertEquals("test.value", result);    result = writer.getHdfsPathExtension(SENSOR_NAME, "FORMAT('%s/%s', test.key, test.key.2)", message);    Assert.assertEquals("test.value/test.value.2", result);    result = writer.getHdfsPathExtension(SENSOR_NAME, "FORMAT('%s', test.key)", message);    writer.close();    Assert.assertEquals("test.value", result);}
public void metron_f7919_0()
{    IndexingConfigurations indexingConfig = new IndexingConfigurations();    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, indexingConfig);    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    JSONObject message = new JSONObject();    message.put("test.key", "test.value");    Object result = writer.getHdfsPathExtension(SENSOR_NAME, "TO_UPPER(FORMAT(MAP_GET('key', {'key': 'AbC%s'}), test.key))", message);    writer.close();    Assert.assertEquals("ABCTEST.VALUE", result);}
public void metron_f7920_0()
{    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, new IndexingConfigurations());    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    JSONObject message = new JSONObject();    writer.getHdfsPathExtension(SENSOR_NAME, "{'key':'value'}", message);    writer.close();}
public void metron_f7921_0() throws IOException
{    int maxFiles = 2;    IndexingConfigurations indexingConfig = new IndexingConfigurations();    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, indexingConfig);    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat).withMaxOpenFiles(maxFiles);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    for (int i = 0; i < maxFiles; i++) {        writer.getSourceHandler(SENSOR_NAME, Integer.toString(i), null);    }    writer.close();}
public void metron_f7922_0() throws IOException
{    int maxFiles = 2;    IndexingConfigurations indexingConfig = new IndexingConfigurations();    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, indexingConfig);    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat).withMaxOpenFiles(maxFiles);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    for (int i = 0; i < maxFiles + 1; i++) {        writer.getSourceHandler(SENSOR_NAME, Integer.toString(i), null);    }    writer.close();}
public void metron_f7923_0() throws Exception
{    FileNameFormat format = new DefaultFileNameFormat().withPath(folder.toString()).withExtension(".json").withPrefix("prefix-");    HdfsWriter writer = new HdfsWriter().withFileNameFormat(format);    IndexingConfigurations indexingConfig = new IndexingConfigurations();    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, indexingConfig);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    JSONObject message = new JSONObject();    message.put("test.key", "test.value");    message.put("test.key2", "test.value2");    JSONObject message2 = new JSONObject();    message2.put("test.key", "test.value3");    message2.put("test.key2", "test.value2");    List<BulkMessage<JSONObject>> messages = new ArrayList<BulkMessage<JSONObject>>() {        {            add(new BulkMessage("message1", message));            add(new BulkMessage("message2", message2));        }    };    writer.write(SENSOR_NAME, config, messages);    writer.close();    ArrayList<String> expected = new ArrayList<>();    expected.add(message.toJSONString());    expected.add(message2.toJSONString());    Collections.sort(expected);        File outputFolder = new File(folder.getAbsolutePath() + "/" + SENSOR_NAME);    Assert.assertTrue(outputFolder.exists() && outputFolder.isDirectory());    Assert.assertEquals(1, outputFolder.listFiles().length);    for (File file : outputFolder.listFiles()) {        List<String> lines = Files.readAllLines(file.toPath());        Collections.sort(lines);        Assert.assertEquals(expected, lines);    }}
public void metron_f7924_0() throws Exception
{    String function = "FORMAT('test-%s/%s', test.key, test.key)";    WriterConfiguration config = buildWriterConfiguration(function);    FileNameFormat format = new DefaultFileNameFormat().withPath(folder.toString()).withExtension(".json").withPrefix("prefix-");    HdfsWriter writer = new HdfsWriter().withFileNameFormat(format);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());        JSONObject message = new JSONObject();    message.put("test.key", "test.value");    message.put("test.key2", "test.value2");    JSONObject message2 = new JSONObject();    message2.put("test.key", "test.value");    message2.put("test.key3", "test.value2");    List<BulkMessage<JSONObject>> messages = new ArrayList<BulkMessage<JSONObject>>() {        {            add(new BulkMessage<>("message1", message));            add(new BulkMessage<>("message2", message2));        }    };    writer.write(SENSOR_NAME, config, messages);    writer.close();    ArrayList<String> expected = new ArrayList<>();    expected.add(message.toJSONString());    expected.add(message2.toJSONString());    Collections.sort(expected);    File outputFolder = new File(folder.getAbsolutePath() + "/test-test.value/test.value/");    Assert.assertTrue(outputFolder.exists() && outputFolder.isDirectory());    Assert.assertEquals(1, outputFolder.listFiles().length);    for (File file : outputFolder.listFiles()) {        List<String> lines = Files.readAllLines(file.toPath());        Collections.sort(lines);        Assert.assertEquals(expected, lines);    }}
public void metron_f7925_0() throws Exception
{    String function = "FORMAT('test-%s/%s', test.key, test.key)";    WriterConfiguration config = buildWriterConfiguration(function);    FileNameFormat format = new DefaultFileNameFormat().withPath(folder.toString()).withExtension(".json").withPrefix("prefix-");    HdfsWriter writer = new HdfsWriter().withFileNameFormat(format);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());        JSONObject message = new JSONObject();    message.put("test.key", "test.value");    message.put("test.key2", "test.value2");    JSONObject message2 = new JSONObject();    message2.put("test.key", "test.value2");    message2.put("test.key3", "test.value3");    List<BulkMessage<JSONObject>> messages = new ArrayList<BulkMessage<JSONObject>>() {        {            add(new BulkMessage("message1", message));            add(new BulkMessage("message2", message2));        }    };    writer.write(SENSOR_NAME, config, messages);    writer.close();    ArrayList<String> expected1 = new ArrayList<>();    expected1.add(message.toJSONString());    Collections.sort(expected1);    File outputFolder1 = new File(folder.getAbsolutePath() + "/test-test.value/test.value/");    Assert.assertTrue(outputFolder1.exists() && outputFolder1.isDirectory());    Assert.assertEquals(1, outputFolder1.listFiles().length);    for (File file : outputFolder1.listFiles()) {        List<String> lines = Files.readAllLines(file.toPath());        Collections.sort(lines);        Assert.assertEquals(expected1, lines);    }    ArrayList<String> expected2 = new ArrayList<>();    expected2.add(message2.toJSONString());    Collections.sort(expected2);    File outputFolder2 = new File(folder.getAbsolutePath() + "/test-test.value2/test.value2/");    Assert.assertTrue(outputFolder2.exists() && outputFolder2.isDirectory());    Assert.assertEquals(1, outputFolder2.listFiles().length);    for (File file : outputFolder2.listFiles()) {        List<String> lines = Files.readAllLines(file.toPath());        Collections.sort(lines);        Assert.assertEquals(expected2, lines);    }}
public void metron_f7926_0() throws Exception
{    String function = "FORMAT('test-%s/%s', test.key, test.key)";    WriterConfiguration config = buildWriterConfiguration(function);    FileNameFormat format = new DefaultFileNameFormat().withPath(folder.toString()).withExtension(".json").withPrefix("prefix-");    HdfsWriter writer = new HdfsWriter().withFileNameFormat(format);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());        JSONObject message = new JSONObject();    message.put("test.key2", "test.value2");    List<BulkMessage<JSONObject>> messages = new ArrayList<BulkMessage<JSONObject>>() {        {            add(new BulkMessage("message1", message));        }    };    writer.write(SENSOR_NAME, config, messages);    writer.close();    ArrayList<String> expected = new ArrayList<>();    expected.add(message.toJSONString());    Collections.sort(expected);    File outputFolder = new File(folder.getAbsolutePath() + "/test-null/null/");    Assert.assertTrue(outputFolder.exists() && outputFolder.isDirectory());    Assert.assertEquals(1, outputFolder.listFiles().length);    for (File file : outputFolder.listFiles()) {        List<String> lines = Files.readAllLines(file.toPath());        Collections.sort(lines);        Assert.assertEquals(expected, lines);    }}
public void metron_f7927_0() throws Exception
{    String function = "FORMAT('test-%s/%s', test.key, test.key)";    WriterConfiguration config = buildWriterConfiguration(function);    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    JSONObject message = new JSONObject();    message.put("test.key", "test.value");    List<BulkMessage<JSONObject>> messages = new ArrayList<BulkMessage<JSONObject>>() {        {            add(new BulkMessage("message1", message));        }    };    CountSyncPolicy basePolicy = new CountSyncPolicy(5);    ClonedSyncPolicyCreator creator = new ClonedSyncPolicyCreator(basePolicy);    writer.write(SENSOR_NAME, config, messages);    writer.write(SENSOR_NAME, config, messages);    writer.close();    File outputFolder = new File(folder.getAbsolutePath() + "/test-test.value/test.value/");        ArrayList<String> expected = new ArrayList<>();    expected.add(message.toJSONString());    expected.add(message.toJSONString());        Assert.assertEquals(1, outputFolder.listFiles().length);    for (File file : outputFolder.listFiles()) {        List<String> lines = Files.readAllLines(file.toPath());                Assert.assertEquals(2, lines.size());        Assert.assertEquals(expected, lines);    }}
protected WriterConfiguration metron_f7928_0(String function)
{    IndexingConfigurations indexingConfig = new IndexingConfigurations();    Map<String, Object> sensorIndexingConfig = new HashMap<>();    Map<String, Object> writerIndexingConfig = new HashMap<>();    writerIndexingConfig.put(IndexingConfigurations.OUTPUT_PATH_FUNCTION_CONF, function);    sensorIndexingConfig.put(WRITER_NAME, writerIndexingConfig);    indexingConfig.updateSensorIndexingConfig(SENSOR_NAME, sensorIndexingConfig);    return new IndexingWriterConfiguration(WRITER_NAME, indexingConfig);}
private TopologyContext metron_f7929_0()
{    Map<Integer, String> taskToComponent = new HashMap<Integer, String>();    taskToComponent.put(7, "Xcom");    return new TopologyContext(null, null, taskToComponent, null, null, null, null, null, 7, 6703, null, null, null, null, null, null);}
public void metron_f7930_0()
{    FileNameFormat delegate = new DefaultFileNameFormat().withExtension(EXTENSION).withPath(PATH);    FileNameFormat sourceFormat = new PathExtensionFileNameFormat(PATH_EXTENSION, delegate);    String actual = sourceFormat.getPath();    String expected = PATH + "/" + PATH_EXTENSION;    Assert.assertEquals(expected, actual);}
public void metron_f7931_0()
{    FileNameFormat delegate = new DefaultFileNameFormat().withExtension(EXTENSION).withPath(PATH);    FileNameFormat sourceFormat = new PathExtensionFileNameFormat("", delegate);    String actual = sourceFormat.getPath();    Assert.assertEquals(PATH + "/", actual);}
public void metron_f7932_0() throws IOException
{        folder = tempFolder.newFolder();    testFormat = new DefaultFileNameFormat().withPath(folder.toString()).withExtension(".json").withPrefix("prefix-");    rotActions = new ArrayList<>();    rotActions.add(rotAction1);    rotActions.add(rotAction2);}
public void metron_f7933_0() throws IOException
{    SourceHandler handler = new SourceHandler(rotActions,     new FileSizeRotationPolicy(10000, Units.MB), new CountSyncPolicy(1), testFormat, callback);    handler.rotateOutputFile();        verify(rotAction1).execute(any(), any());    verify(rotAction2).execute(any(), any());    verify(callback).removeKey();}
public Builder metron_f7934_0(Callback callback, TreeCacheEvent.Type... types)
{    return with(ImmutableList.of(callback), types);}
public Builder metron_f7935_0(Iterable<? extends Callback> callback, TreeCacheEvent.Type... types)
{    for (TreeCacheEvent.Type t : types) {        List<Callback> cbs = callbacks.get(t);        if (cbs == null) {            cbs = new ArrayList<>();        }        Iterables.addAll(cbs, callback);        callbacks.put(t, cbs);    }    return this;}
public SimpleEventListener metron_f7936_0()
{    return new SimpleEventListener(callbacks);}
public void metron_f7937_1(CuratorFramework client, TreeCacheEvent event) throws Exception
{    String path = null;    byte[] data = null;    if (event != null && event.getData() != null) {        path = event.getData().getPath();        data = event.getData().getData();    }        List<Callback> callback = callbacks.get(event.getType());    if (callback != null) {        for (Callback cb : callback) {            cb.apply(client, path, data);        }    }}
public Builder metron_f7938_0(CuratorFramework client)
{    this.client = Optional.ofNullable(client);    ownClient = false;    return this;}
public Builder metron_f7939_0(String zookeeperUrl)
{    this.client = Optional.ofNullable(createClient(zookeeperUrl, Optional.empty()));    ownClient = true;    return this;}
public Builder metron_f7940_0(String zookeeperUrl, RetryPolicy retryPolicy)
{    this.client = Optional.ofNullable(createClient(zookeeperUrl, Optional.ofNullable(retryPolicy)));    ownClient = true;    return this;}
public Builder metron_f7941_0(TreeCacheListener listener)
{    this.listener.add(listener);    return this;}
public Builder metron_f7942_0(String zkRoot)
{    this.zkRoot = zkRoot;    return this;}
public ZKCache metron_f7943_1()
{    if (!client.isPresent()) {        throw new IllegalArgumentException("Zookeeper client must be specified.");    }    if (listener.isEmpty()) {            }    if (zkRoot == null) {        throw new IllegalArgumentException("Zookeeper root must not be null.");    }    return new ZKCache(client.get(), listener, zkRoot, ownClient);}
public CuratorFramework metron_f7944_0()
{    return client;}
public void metron_f7945_0() throws Exception
{    if (cache == null) {        if (ownClient) {            client.start();        }        TreeCache.Builder builder = TreeCache.newBuilder(client, zkRoot);        builder.setCacheData(true);        cache = builder.build();        for (TreeCacheListener l : listeners) {            cache.getListenable().addListener(l);        }        cache.start();    }}
public void metron_f7946_0()
{    cache.close();    if (ownClient) {        client.close();    }}
public static CuratorFramework metron_f7947_0(String zookeeperUrl, Optional<RetryPolicy> retryPolicy)
{    return CuratorFrameworkFactory.newClient(zookeeperUrl, retryPolicy.orElse(new ExponentialBackoffRetry(DEFAULT_CLIENT_SLEEP_MS, DEFAULT_MAX_RETRIES)));}
public Object metron_f7948_0(List<Object> list, Context context) throws ParseException
{    return System.currentTimeMillis();}
public boolean metron_f7950_0()
{    return true;}
 static Cache<String, StellarCompiler.Expression> metron_f7951_0(int cacheSize, int expiryTime, TimeUnit expiryUnit)
{    CacheLoader<String, StellarCompiler.Expression> loader = key -> compile(key);    return Caffeine.newBuilder().maximumSize(cacheSize).expireAfterAccess(expiryTime, expiryUnit).build(loader);}
public Set<String> metron_f7952_0(final String rule)
{    if (rule == null || isEmpty(rule.trim())) {        return null;    }    StellarCompiler.Expression expression = null;    try {        expression = expressionCache.get(rule, r -> compile(r));    } catch (Throwable e) {        throw new ParseException("Unable to parse: " + rule + " due to: " + e.getMessage(), e);    }    return expression.variablesUsed;}
public T metron_f7953_0(final String rule, final VariableResolver variableResolver, final FunctionResolver functionResolver, final Context context)
{    StellarCompiler.Expression expression = null;    if (rule == null || isEmpty(rule.trim())) {        return null;    }    if (context.getActivityType() == null) {        context.setActivityType(ActivityType.PARSE_ACTIVITY);    }    try {        expression = expressionCache.get(rule, r -> compile(r));    } catch (Throwable e) {        throw createException(rule, variableResolver, e);    }    try {        return clazz.cast(expression.apply(new StellarCompiler.ExpressionState(context, functionResolver, variableResolver)));    } catch (Throwable e) {        throw createException(rule, variableResolver, e);    } finally {                context.setActivityType(null);    }}
private ParseException metron_f7954_0(String rule, VariableResolver resolver, Throwable t)
{    String message = "Unable to parse: " + rule + " due to: " + t.getMessage();    Set<String> variablesUsed = variablesUsed(rule);    if (variablesUsed.isEmpty()) {        return new ParseException(message, t);    }    List<Map.Entry<String, Object>> messagesUsed = new ArrayList<>(variablesUsed.size());    for (String v : variablesUsed) {        Optional<Object> resolved = Optional.ofNullable(resolver.resolve(v));        messagesUsed.add(new AbstractMap.SimpleEntry<>(v, resolved.orElse("missing")));    }    return new ParseException(message + " with relevant variables " + Joiner.on(",").join(messagesUsed), t);}
public static StellarCompiler.Expression metron_f7955_0(final String rule)
{    if (rule == null || isEmpty(rule.trim())) {        return null;    }    ANTLRInputStream input = new ANTLRInputStream(rule);    StellarLexer lexer = new StellarLexer(input);    lexer.removeErrorListeners();    lexer.addErrorListener(new ErrorListener());    TokenStream tokens = new CommonTokenStream(lexer);    StellarParser parser = new StellarParser(tokens);    StellarCompiler treeBuilder = new StellarCompiler(ArithmeticEvaluator.INSTANCE, NumberLiteralEvaluator.INSTANCE, ComparisonExpressionWithOperatorEvaluator.INSTANCE);    parser.addParseListener(treeBuilder);    parser.removeErrorListeners();    parser.addErrorListener(new ErrorListener());    parser.transformation();    return treeBuilder.getExpression();}
public boolean metron_f7956_0(final String rule) throws ParseException
{    return validate(rule, true, Context.EMPTY_CONTEXT());}
public boolean metron_f7957_0(final String rule, final Context context) throws ParseException
{    return validate(rule, true, context);}
public boolean metron_f7958_0(final String rule, final boolean throwException, final Context context) throws ParseException
{    if (rule == null || isEmpty(rule.trim())) {        return true;    }            context.setActivityType(ActivityType.VALIDATION_ACTIVITY);    try {        parse(rule, DefaultVariableResolver.NULL_RESOLVER(), StellarFunctions.FUNCTION_RESOLVER(), context);    } catch (Throwable t) {        if (throwException) {            throw new ParseException("Unable to parse " + rule + ": " + t.getMessage(), t);        } else {            return false;        }    }    return true;}
public static DescriptiveStatistics metron_f7959_0(StellarStatement statement, int warmupRounds, int benchmarkRounds)
{    run(warmupRounds, statement, ts -> {    });    final DescriptiveStatistics stats = new DescriptiveStatistics();    run(benchmarkRounds, statement, ts -> {        stats.addValue(ts);    });    return stats;}
private static void metron_f7960_0(int numTimes, StellarStatement statement, Consumer<Long> func)
{    StellarProcessor processor = new StellarProcessor();    for (int i = 0; i < numTimes; ++i) {        long start = System.nanoTime();        processor.parse(statement.expression, statement.variableResolver, statement.functionResolver, statement.context);        func.accept((System.nanoTime() - start) / 1000);    }}
public static String metron_f7961_0(DescriptiveStatistics stats, Double[] percentiles)
{    StringBuilder sb = new StringBuilder();    sb.append(String.format("round: mean of %dms [+-%d], measured %d rounds;\n", (long) stats.getMean(), (long) stats.getStandardDeviation(), stats.getN()));    sb.append("\tMin - " + (long) stats.getMin() + "\n");    for (double pctile : percentiles) {        sb.append("\t" + pctile + " - " + stats.getPercentile(pctile) + "\n");    }    sb.append("\tMax - " + (long) stats.getMax());    return sb.toString();}
public boolean metron_f7962_0(CommandLine cli)
{    return cli.hasOption(shortCode);}
public String metron_f7963_0(CommandLine cli)
{    return cli.getOptionValue(shortCode);}
public static CommandLine metron_f7964_0(CommandLineParser parser, String[] args)
{    try {        CommandLine cli = parser.parse(getOptions(), args);        if (HELP.has(cli)) {            printHelp();            System.exit(0);        }        return cli;    } catch (org.apache.commons.cli.ParseException e) {        System.err.println("Unable to parse args: " + Joiner.on(' ').join(args));        e.printStackTrace(System.err);        printHelp();        System.exit(-1);        return null;    }}
public static EnumMap<BenchmarkOptions, Optional<Object>> metron_f7965_0(CommandLine cli)
{    EnumMap<BenchmarkOptions, Optional<Object>> ret = new EnumMap<>(BenchmarkOptions.class);    for (BenchmarkOptions option : values()) {        ret.put(option, option.handler.getValue(option, cli));    }    return ret;}
public static void metron_f7966_0()
{    HelpFormatter formatter = new HelpFormatter();    formatter.printHelp("StellarBenchmark", getOptions());}
public static Options metron_f7967_0()
{    Options ret = new Options();    for (BenchmarkOptions o : BenchmarkOptions.values()) {        ret.addOption(o.option);    }    return ret;}
public Option metron_f7968_0(@Nullable String s)
{    return new Option(s, "help", false, "Generate Help screen");}
public Option metron_f7969_0(@Nullable String s)
{    Option o = new Option(s, "warmup", true, "Number of times for warmup per expression. Default: " + DEFAULT_WARMUP);    o.setArgName("NUM");    o.setRequired(false);    return o;}
public Optional<Object> metron_f7970_0(BenchmarkOptions option, CommandLine cli)
{    return Optional.ofNullable(option.get(cli).trim());}
public Option metron_f7971_0(@Nullable String s)
{    Option o = new Option(s, "percentiles", true, "Percentiles to calculate per run. Default: " + Joiner.on(",").join(Arrays.asList(DEFAULT_PERCENTILES)));    o.setArgName("NUM");    o.setRequired(false);    return o;}
public Optional<Object> metron_f7972_0(BenchmarkOptions option, CommandLine cli)
{    return Optional.ofNullable(option.get(cli).trim());}
public Option metron_f7973_0(@Nullable String s)
{    Option o = new Option(s, "num_times", true, "Number of times to run per expression (after warmup). Default: " + DEFAULT_NUM_TIMES);    o.setArgName("NUM");    o.setRequired(false);    return o;}
public Optional<Object> metron_f7974_0(BenchmarkOptions option, CommandLine cli)
{    return Optional.ofNullable(option.get(cli).trim());}
public Option metron_f7975_0(@Nullable String s)
{    Option o = new Option(s, "expressions", true, "Stellar expressions");    o.setArgName("FILE");    o.setRequired(false);    return o;}
public Optional<Object> metron_f7976_0(BenchmarkOptions option, CommandLine cli)
{    return Optional.ofNullable(option.get(cli).trim());}
public Option metron_f7977_0(@Nullable String s)
{    Option o = new Option(s, "variables", true, "File containing a JSON Map of variables to use");    o.setArgName("FILE");    o.setRequired(false);    return o;}
public Optional<Object> metron_f7978_0(BenchmarkOptions option, CommandLine cli)
{    return Optional.ofNullable(option.get(cli).trim());}
public Option metron_f7979_0(@Nullable String s)
{    Option o = new Option(s, "output", true, "File to write output.");    o.setArgName("FILE");    o.setRequired(false);    return o;}
public Optional<Object> metron_f7980_0(BenchmarkOptions option, CommandLine cli)
{    return Optional.ofNullable(option.get(cli).trim());}
public static void metron_f7981_0(String... argv) throws IOException
{    CommandLine cli = BenchmarkOptions.parse(new PosixParser(), argv);    if (!BenchmarkOptions.EXPRESSIONS.has(cli)) {        throw new IllegalStateException("You must at least specify an expressions file.");    }    File expressionsFile = new File(BenchmarkOptions.EXPRESSIONS.get(cli));    Optional<File> variablesFile = Optional.ofNullable(!BenchmarkOptions.VARIABLES.has(cli) ? null : new File(BenchmarkOptions.VARIABLES.get(cli)));    Optional<File> output = Optional.ofNullable(!BenchmarkOptions.OUTPUT.has(cli) ? null : new File(BenchmarkOptions.OUTPUT.get(cli)));    List<String> lines = Files.readLines(expressionsFile, Charset.defaultCharset());    Map<String, Object> variables = new HashMap<>();    if (variablesFile.isPresent()) {        variables = JSONUtils.INSTANCE.load(new FileInputStream(variablesFile.get()), JSONUtils.MAP_SUPPLIER);    }    int numTimes = DEFAULT_NUM_TIMES;    if (BenchmarkOptions.NUM_TIMES.has(cli)) {        numTimes = Integer.parseInt(BenchmarkOptions.NUM_TIMES.get(cli));    }    int warmup = DEFAULT_WARMUP;    if (BenchmarkOptions.WARMUP.has(cli)) {        warmup = Integer.parseInt(BenchmarkOptions.WARMUP.get(cli));    }    Double[] percentiles = DEFAULT_PERCENTILES;    if (BenchmarkOptions.PERCENTILES.has(cli)) {        List<Double> percentileList = new ArrayList<>();        for (String token : Splitter.on(",").split(BenchmarkOptions.PERCENTILES.get(cli))) {            if (token.trim().isEmpty()) {                continue;            }            Double d = Double.parseDouble(token.trim());            percentileList.add(d);        }        percentiles = (Double[]) percentileList.toArray();    }    PrintWriter out = new PrintWriter(new BufferedWriter(new OutputStreamWriter(System.out, StandardCharsets.UTF_8)));    if (output.isPresent()) {        out = new PrintWriter(output.get(), StandardCharsets.UTF_8.name());    }    for (String statement : lines) {        if (statement.trim().startsWith("#") || statement.trim().isEmpty()) {            continue;        }        Microbenchmark.StellarStatement s = new Microbenchmark.StellarStatement();        s.context = Context.EMPTY_CONTEXT();        s.expression = statement;        s.functionResolver = StellarFunctions.FUNCTION_RESOLVER();        s.variableResolver = new MapVariableResolver(variables);        DescriptiveStatistics stats = Microbenchmark.run(s, warmup, numTimes);        out.println("Expression: " + statement);        out.println(Microbenchmark.describe(stats, percentiles));    }    if (argv.length > 2) {        out.close();    }}
public String metron_f7982_0()
{    return expression;}
public Map<String, Object> metron_f7983_0()
{    return input;}
public boolean metron_f7984_0(Object o)
{    if (this == o) {        return true;    }    if (o == null || getClass() != o.getClass()) {        return false;    }    Key key = (Key) o;    return new EqualsBuilder().append(expression, key.expression).append(input, key.input).isEquals();}
public int metron_f7985_0()
{    return new HashCodeBuilder(17, 37).append(expression).append(input).toHashCode();}
public String metron_f7986_0()
{    return new ToStringBuilder(this).append("expression", expression).append("input", input).toString();}
public Object metron_f7987_1(String expression, VariableResolver variableResolver, FunctionResolver functionResolver, Context context)
{    Optional<Object> cacheOpt = context.getCapability(Context.Capabilities.CACHE, false);    if (cacheOpt.isPresent()) {                Cache<Key, Object> cache = (Cache<Key, Object>) cacheOpt.get();        Key k = toKey(expression, variableResolver);        return cache.get(k, x -> parseUncached(x.expression, variableResolver, functionResolver, context));    } else {                return parseUncached(expression, variableResolver, functionResolver, context);    }}
private static T metron_f7991_0(Map<String, Object> config, String key, T defaultVal, Class<T> clazz)
{    Object o = config.get(key);    if (o == null) {        return defaultVal;    }    T ret = ConversionUtils.convert(o, clazz);    return ret == null ? defaultVal : ret;}
public static CuratorFramework metron_f7992_0(String zookeeperUrl)
{    RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);    return CuratorFrameworkFactory.newClient(zookeeperUrl, retryPolicy);}
public static void metron_f7993_0(Map<String, Object> globalConfig, String zookeeperUrl) throws Exception
{    try (CuratorFramework client = getClient(zookeeperUrl)) {        client.start();        writeGlobalConfigToZookeeper(globalConfig, client);    }}
public static void metron_f7994_0(Map<String, Object> globalConfig, CuratorFramework client) throws Exception
{    writeGlobalConfigToZookeeper(JSONUtils.INSTANCE.toJSON(globalConfig), client);}
public static void metron_f7995_0(byte[] globalConfig, String zookeeperUrl) throws Exception
{    try (CuratorFramework client = getClient(zookeeperUrl)) {        client.start();        writeGlobalConfigToZookeeper(globalConfig, client);    }}
public static void metron_f7996_0(byte[] globalConfig, CuratorFramework client) throws Exception
{    GLOBAL.deserialize(new String(globalConfig, StandardCharsets.UTF_8));    writeToZookeeper(GLOBAL.getZookeeperRoot(), globalConfig, client);}
public static void metron_f7997_0(String name, Map<String, Object> config, String zookeeperUrl) throws Exception
{    writeConfigToZookeeper(name, JSONUtils.INSTANCE.toJSON(config), zookeeperUrl);}
public static void metron_f7998_0(String name, byte[] config, String zookeeperUrl) throws Exception
{    try (CuratorFramework client = getClient(zookeeperUrl)) {        client.start();        writeToZookeeper(Constants.ZOOKEEPER_TOPOLOGY_ROOT + "/" + name, config, client);    }}
public static void metron_f7999_0(String path, byte[] configData, CuratorFramework client) throws Exception
{    try {        client.setData().forPath(path, configData);    } catch (KeeperException.NoNodeException e) {        client.create().creatingParentsIfNeeded().forPath(path, configData);    }}
public static byte[] metron_f8000_0(CuratorFramework client) throws Exception
{    return readFromZookeeper(GLOBAL.getZookeeperRoot(), client);}
public static byte[] metron_f8001_0(String name, CuratorFramework client) throws Exception
{    return readFromZookeeper(Constants.ZOOKEEPER_TOPOLOGY_ROOT + "/" + name, client);}
public static byte[] metron_f8002_0(String path, CuratorFramework client) throws Exception
{    if (client != null && client.getData() != null && path != null) {        return client.getData().forPath(path);    }    return new byte[] {};}
public static void metron_f8003_0(CuratorFramework client) throws Exception
{    byte[] ret = null;    try {        ret = readGlobalConfigBytesFromZookeeper(client);    } catch (KeeperException.NoNodeException nne) {        }    if (ret == null || ret.length == 0) {        setupStellarStatically(client, Optional.empty());    } else {        setupStellarStatically(client, Optional.of(new String(ret, StandardCharsets.UTF_8)));    }}
public static void metron_f8004_0(CuratorFramework client, Optional<String> globalConfig)
{    /*      In order to validate stellar functions, the function resolver must be initialized.  Otherwise,      those utilities that require validation cannot validate the stellar expressions necessarily.    */    Context.Builder builder = new Context.Builder().with(Context.Capabilities.ZOOKEEPER_CLIENT, () -> client);    if (globalConfig.isPresent()) {        builder = builder.with(Context.Capabilities.GLOBAL_CONFIG, () -> GLOBAL.deserialize(globalConfig.get())).with(Context.Capabilities.STELLAR_CONFIG, () -> GLOBAL.deserialize(globalConfig.get()));    } else {        builder = builder.with(Context.Capabilities.STELLAR_CONFIG, () -> new HashMap<>());    }    Context stellarContext = builder.build();    StellarFunctions.FUNCTION_RESOLVER().initialize(stellarContext);}
public static byte[] metron_f8005_0(String rootPath) throws IOException
{    byte[] globalConfig = new byte[0];    File configPath = new File(rootPath, GLOBAL.getName() + ".json");    if (configPath.exists()) {        globalConfig = Files.readAllBytes(configPath.toPath());    }    return globalConfig;}
public static void metron_f8006_0(CuratorFramework client, final ConfigurationVisitor callback) throws Exception
{    visitConfigs(client, (type, name, data) -> {        setupStellarStatically(client, Optional.ofNullable(data));        callback.visit(type, name, data);    }, GLOBAL);}
public static void metron_f8007_0(CuratorFramework client, ConfigurationVisitor callback, ConfigurationType configType) throws Exception
{    if (client.checkExists().forPath(configType.getZookeeperRoot()) != null) {        if (configType.equals(GLOBAL)) {            byte[] globalConfigData = client.getData().forPath(configType.getZookeeperRoot());            callback.visit(configType, "global", new String(globalConfigData, StandardCharsets.UTF_8));        }    }}
public static void metron_f8008_0(PrintStream out, CuratorFramework client) throws Exception
{    ConfigurationsUtils.visitConfigs(client, (type, name, data) -> {        type.deserialize(data);        out.println(type + " Config: " + name + "\n" + data);    });}
public String metron_f8009_0()
{    return name;}
public String metron_f8010_0()
{    return directory;}
public Object metron_f8011_0(String s)
{    return deserializer.apply(s);}
public Object metron_f8012_0(String s)
{    return deserialize(s);}
public String metron_f8013_0()
{    return zookeeperRoot;}
public String metron_f8014_0()
{    return name;}
public static Fields metron_f8015_0(String fieldName)
{    return nameToField.get(fieldName);}
public String metron_f8016_0()
{    return name;}
public String metron_f8017_0()
{    return type;}
public Map<String, Object> metron_f8018_0()
{    return ImmutableMap.copyOf(state);}
public void metron_f8019_0(String variable, String expression, Map<String, Object> transientState)
{    Object result = execute(expression, transientState);    if (result == null || variable == null) {        return;    }    state.put(variable, result);}
public void metron_f8020_0(String variable, Object value)
{    if (value == null || variable == null) {        return;    }    state.put(variable, value);}
public T metron_f8021_0(String expression, Map<String, Object> state, Class<T> clazz)
{    Object resultObject = execute(expression, state);        T result = ConversionUtils.convert(resultObject, clazz);    if (result == null) {        throw new IllegalArgumentException(String.format("Unexpected type: expected=%s, actual=%s, expression=%s", clazz.getSimpleName(), ClassUtils.getShortClassName(resultObject, "null"), expression));    }    return result;}
public void metron_f8022_0()
{    this.state = new HashMap<>();}
public void metron_f8023_0(Context context)
{    this.context = context;}
public void metron_f8024_0(FunctionResolver functionResolver)
{    this.functionResolver = functionResolver;}
private Object metron_f8025_0(String expression, Map<String, Object> transientState)
{    VariableResolver variableResolver = new MapVariableResolver(state, transientState);    StellarProcessor processor = new StellarProcessor();    return processor.parse(expression, variableResolver, functionResolver, context);}
public boolean metron_f8026_0(String possible)
{    return is.test(possible);}
public String metron_f8027_0(String encoded)
{    return decode(encoded, false);}
public String metron_f8028_0(String encoded, boolean verify)
{    if (verify) {        if (is.test(encoded)) {            return decode.apply(encoded);        } else {            return encoded;        }    }    return decode.apply(encoded);}
public String metron_f8029_0(String toEncode)
{    return encode.apply(toEncode);}
public Token<? extends Number> metron_f8030_0(BiFunction<Number, Number, Token<? extends Number>> function, Pair<Token<? extends Number>, Token<? extends Number>> p)
{    if (p == null || p.getKey() == null || p.getValue() == null) {        throw new IllegalArgumentException();    }    final Number l = p.getKey().getValue();    final Number r = p.getValue().getValue();    return function.apply(l == null ? 0 : l, r == null ? 0 : r);}
public static BiFunction<Number, Number, Token<? extends Number>> metron_f8031_0(final FrameContext.Context context)
{    return (Number l, Number r) -> {        if (l instanceof Double || r instanceof Double) {            return new Token<>(l.doubleValue() + r.doubleValue(), Double.class, context);        } else if (l instanceof Float || r instanceof Float) {            return new Token<>(l.floatValue() + r.floatValue(), Float.class, context);        } else if (l instanceof Long || r instanceof Long) {            return new Token<>(l.longValue() + r.longValue(), Long.class, context);        } else {            return new Token<>(l.intValue() + r.intValue(), Integer.class, context);        }    };}
public static BiFunction<Number, Number, Token<? extends Number>> metron_f8032_0(final FrameContext.Context context)
{    return (Number l, Number r) -> {        if (l instanceof Double || r instanceof Double) {            return new Token<>(l.doubleValue() * r.doubleValue(), Double.class, context);        } else if (l instanceof Float || r instanceof Float) {            return new Token<>(l.floatValue() * r.floatValue(), Float.class, context);        } else if (l instanceof Long || r instanceof Long) {            return new Token<>(l.longValue() * r.longValue(), Long.class, context);        } else {            return new Token<>(l.intValue() * r.intValue(), Integer.class, context);        }    };}
public static BiFunction<Number, Number, Token<? extends Number>> metron_f8033_0(final FrameContext.Context context)
{    return (Number l, Number r) -> {        if (l instanceof Double || r instanceof Double) {            return new Token<>(l.doubleValue() - r.doubleValue(), Double.class, context);        } else if (l instanceof Float || r instanceof Float) {            return new Token<>(l.floatValue() - r.floatValue(), Float.class, context);        } else if (l instanceof Long || r instanceof Long) {            return new Token<>(l.longValue() - r.longValue(), Long.class, context);        } else {            return new Token<>(l.intValue() - r.intValue(), Integer.class, context);        }    };}
public static BiFunction<Number, Number, Token<? extends Number>> metron_f8034_0(FrameContext.Context context)
{    return (Number l, Number r) -> {        if (l instanceof Double || r instanceof Double) {            return new Token<>(l.doubleValue() / r.doubleValue(), Double.class, context);        } else if (l instanceof Float || r instanceof Float) {            return new Token<>(l.floatValue() / r.floatValue(), Float.class, context);        } else if (l instanceof Long || r instanceof Long) {            return new Token<>(l.longValue() / r.longValue(), Long.class, context);        } else {            return new Token<>(l.intValue() / r.intValue(), Integer.class, context);        }    };}
public ComparisonExpressionEvaluator metron_f8035_0()
{    return evaluator;}
public Token<Boolean> metron_f8036_0(final Token<?> left, final Token<?> right, final StellarParser.ComparisonOpContext op, FrameContext.Context context)
{    if (op.EQ() != null) {        return new Token<>(Strategy.EQUALITY_OPERATORS.evaluator().evaluate(left, right, op), Boolean.class, context);    } else if (op.NEQ() != null) {        return new Token<>(!Strategy.EQUALITY_OPERATORS.evaluator().evaluate(left, right, op), Boolean.class, context);    } else if (op.LT() != null || op.GT() != null || op.LTE() != null || op.GTE() != null) {        return new Token<>(Strategy.COMPARISON_OPERATORS.evaluator().evaluate(left, right, op), Boolean.class, context);    }    throw new ParseException("Unsupported operations. The following expression is invalid: " + left.getValue() + op.getText() + right.getValue());}
public boolean metron_f8037_0(final Token<?> left, final Token<?> right, final StellarParser.ComparisonOpContext op)
{    if (left.getValue() == null || right.getValue() == null) {        return false;    } else if (left.getValue() instanceof Number && right.getValue() instanceof Number) {        return compareNumbers((Number) left.getValue(), (Number) right.getValue(), op);    } else if (left.getValue().getClass() == right.getValue().getClass() && left.getValue() instanceof Comparable && right.getValue() instanceof Comparable) {        return compare((Comparable<?>) left.getValue(), (Comparable<?>) right.getValue(), op);    }    throw new ParseException("Unsupported operations. The following expression is invalid: " + left.getValue() + op + right.getValue());}
private boolean metron_f8038_0(final T l, final T r, final StellarParser.ComparisonOpContext op)
{    int compareTo = l.compareTo(r);    if (op.LT() != null) {        return compareTo < 0;    } else if (op.LTE() != null) {        return compareTo <= 0;    } else if (op.GT() != null) {        return compareTo > 0;    } else if (op.GTE() != null) {        return compareTo >= 0;    }    throw new ParseException("Unsupported operator: " + op);}
private boolean metron_f8039_0(final Number l, final Number r, final StellarParser.ComparisonOpContext op)
{    if (op.LT() != null) {        return lessThan(l, r);    } else if (op.LTE() != null) {        return lessThanEqual(l, r);    } else if (op.GT() != null) {        return greaterThan(l, r);    } else if (op.GTE() != null) {        return greaterThanEqual(l, r);    }    throw new ParseException("Unsupported operator: " + op);}
private boolean metron_f8040_0(final Number l, final Number r)
{    if (l instanceof Double || r instanceof Double) {        return l.doubleValue() < r.doubleValue();    } else if (l instanceof Float || r instanceof Float) {        return l.floatValue() < r.floatValue();    } else if (l instanceof Long || r instanceof Long) {        return l.longValue() < r.longValue();    } else {        return l.intValue() < r.intValue();    }}
private boolean metron_f8041_0(final Number l, final Number r)
{    if (l instanceof Double || r instanceof Double) {        return l.doubleValue() <= r.doubleValue();    } else if (l instanceof Float || r instanceof Float) {        return l.floatValue() <= r.floatValue();    } else if (l instanceof Long || r instanceof Long) {        return l.longValue() <= r.longValue();    } else {        return l.intValue() <= r.intValue();    }}
private boolean metron_f8042_0(final Number l, final Number r)
{    if (l instanceof Double || r instanceof Double) {        return l.doubleValue() > r.doubleValue();    } else if (l instanceof Float || r instanceof Float) {        return l.floatValue() > r.floatValue();    } else if (l instanceof Long || r instanceof Long) {        return l.longValue() > r.longValue();    } else {        return l.intValue() > r.intValue();    }}
private boolean metron_f8043_0(final Number l, final Number r)
{    if (l instanceof Double || r instanceof Double) {        return l.doubleValue() >= r.doubleValue();    } else if (l instanceof Float || r instanceof Float) {        return l.floatValue() >= r.floatValue();    } else if (l instanceof Long || r instanceof Long) {        return l.longValue() >= r.longValue();    } else {        return l.intValue() >= r.intValue();    }}
public Token<Double> metron_f8044_0(StellarParser.DoubleLiteralContext context, FrameContext.Context contextVariety)
{    if (context == null) {        throw new IllegalArgumentException("Cannot evaluate a context that is null.");    }    return new Token<>(Double.parseDouble(context.getText()), Double.class, contextVariety);}
public boolean metron_f8045_0(final Token<?> left, final Token<?> right, final StellarParser.ComparisonOpContext op)
{    if (left.getValue() == null || right.getValue() == null) {        return left.getValue() == right.getValue();    } else if (left.getValue() instanceof Number && right.getValue() instanceof Number) {        return eq((Number) left.getValue(), (Number) right.getValue());    } else {        return left.getValue().equals(right.getValue());    }}
private boolean metron_f8046_0(final Number l, final Number r)
{    if (l instanceof Double || r instanceof Double) {        return l.doubleValue() == r.doubleValue();    } else if (l instanceof Float || r instanceof Float) {        return l.floatValue() == r.floatValue();    } else if (l instanceof Long || r instanceof Long) {        return l.longValue() == r.longValue();    } else {        return l.intValue() == r.intValue();    }}
public Token<Float> metron_f8047_0(StellarParser.FloatLiteralContext context, FrameContext.Context contextVariety)
{    if (context == null) {        throw new IllegalArgumentException("Cannot evaluate a context that is null.");    }    return new Token<>(Float.parseFloat(context.getText()), Float.class, contextVariety);}
public Token<Integer> metron_f8048_0(StellarParser.IntLiteralContext context, FrameContext.Context contextVariety)
{    if (context == null) {        throw new IllegalArgumentException("Cannot evaluate a context that is null.");    }    return new Token<>(Integer.parseInt(context.getText()), Integer.class, contextVariety);}
public Token<Long> metron_f8049_0(StellarParser.LongLiteralContext context, FrameContext.Context contextVariety)
{    if (context == null) {        throw new IllegalArgumentException("Cannot evaluate a context that is null.");    }    String value = context.getText();    if (value.endsWith("l") || value.endsWith("L")) {                value = value.substring(0, value.length() - 1);        return new Token<>(Long.parseLong(value), Long.class, contextVariety);    } else {                throw new ParseException("Invalid format for long. Failed trying to parse a long with the following value: " + value);    }}
 Token<? extends Number> metron_f8050_0(StellarParser.Arithmetic_operandsContext context, Map<Class<? extends StellarParser.Arithmetic_operandsContext>, NumberEvaluator> instanceMap, FrameContext.Context contextVariety)
{    NumberEvaluator evaluator = instanceMap.get(context.getClass());    if (evaluator == null) {        throw new ParseException("Does not support evaluation for type " + context.getClass());    }    return evaluator.evaluate(context, contextVariety);}
public Token<? extends Number> metron_f8051_0(StellarParser.Arithmetic_operandsContext context, FrameContext.Context contextVariety)
{    return evaluate(context, Strategy.strategyMap, contextVariety);}
public FrameContext metron_f8052_0()
{    return variety;}
public String metron_f8053_0()
{    return "Context{" + "variety=" + variety + '}';}
public Context metron_f8054_0()
{    return new Context(this);}
public String[] metron_f8197_0()
{    return tokenNames;}
public Vocabulary metron_f8198_0()
{    return VOCABULARY;}
public String metron_f8199_0()
{    return "Stellar.g4";}
public String[] metron_f8200_0()
{    return ruleNames;}
public String metron_f8201_0()
{    return _serializedATN;}
public String[] metron_f8202_0()
{    return modeNames;}
public ATN metron_f8203_0()
{    return _ATN;}
public String[] metron_f8204_0()
{    return tokenNames;}
public Vocabulary metron_f8205_0()
{    return VOCABULARY;}
public String metron_f8206_0()
{    return "Stellar.g4";}
public String[] metron_f8207_0()
{    return ruleNames;}
public String metron_f8208_0()
{    return _serializedATN;}
public ATN metron_f8209_0()
{    return _ATN;}
public Transformation_exprContext metron_f8210_0()
{    return getRuleContext(Transformation_exprContext.class, 0);}
public TerminalNode metron_f8211_0()
{    return getToken(StellarParser.EOF, 0);}
public int metron_f8212_0()
{    return RULE_transformation;}
public void metron_f8213_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterTransformation(this);}
public void metron_f8214_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitTransformation(this);}
public final TransformationContext metron_f8215_0() throws RecognitionException
{    TransformationContext _localctx = new TransformationContext(_ctx, getState());    enterRule(_localctx, 0, RULE_transformation);    try {        enterOuterAlt(_localctx, 1);        {            setState(66);            transformation_expr();            setState(67);            match(EOF);        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
public int metron_f8216_0()
{    return RULE_transformation_expr;}
public void metron_f8217_0(Transformation_exprContext ctx)
{    super.copyFrom(ctx);}
public Comparison_exprContext metron_f8218_0()
{    return getRuleContext(Comparison_exprContext.class, 0);}
public void metron_f8219_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterComparisonExpression(this);}
public void metron_f8220_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitComparisonExpression(this);}
public Logical_exprContext metron_f8221_0()
{    return getRuleContext(Logical_exprContext.class, 0);}
public void metron_f8222_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterLogicalExpression(this);}
public void metron_f8223_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitLogicalExpression(this);}
public Transformation_entityContext metron_f8224_0()
{    return getRuleContext(Transformation_entityContext.class, 0);}
public void metron_f8225_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterTransformationEntity(this);}
public void metron_f8226_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitTransformationEntity(this);}
public In_exprContext metron_f8227_0()
{    return getRuleContext(In_exprContext.class, 0);}
public void metron_f8228_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterInExpression(this);}
public void metron_f8229_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitInExpression(this);}
public Arithmetic_exprContext metron_f8230_0()
{    return getRuleContext(Arithmetic_exprContext.class, 0);}
public void metron_f8231_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterArithExpression(this);}
public void metron_f8232_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitArithExpression(this);}
public TerminalNode metron_f8233_0()
{    return getToken(StellarParser.LPAREN, 0);}
public Transformation_exprContext metron_f8234_0()
{    return getRuleContext(Transformation_exprContext.class, 0);}
public TerminalNode metron_f8235_0()
{    return getToken(StellarParser.RPAREN, 0);}
public void metron_f8236_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterTransformationExpr(this);}
public void metron_f8237_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitTransformationExpr(this);}
public Conditional_exprContext metron_f8238_0()
{    return getRuleContext(Conditional_exprContext.class, 0);}
public void metron_f8239_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterConditionalExpr(this);}
public void metron_f8240_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitConditionalExpr(this);}
public Match_exprContext metron_f8241_0()
{    return getRuleContext(Match_exprContext.class, 0);}
public void metron_f8242_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterMatchExpr(this);}
public void metron_f8243_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitMatchExpr(this);}
public final Transformation_exprContext metron_f8244_0() throws RecognitionException
{    Transformation_exprContext _localctx = new Transformation_exprContext(_ctx, getState());    enterRule(_localctx, 2, RULE_transformation_expr);    try {        setState(80);        switch(getInterpreter().adaptivePredict(_input, 0, _ctx)) {            case 1:                _localctx = new ConditionalExprContext(_localctx);                enterOuterAlt(_localctx, 1);                {                    setState(69);                    conditional_expr();                }                break;            case 2:                _localctx = new TransformationExprContext(_localctx);                enterOuterAlt(_localctx, 2);                {                    setState(70);                    match(LPAREN);                    setState(71);                    transformation_expr();                    setState(72);                    match(RPAREN);                }                break;            case 3:                _localctx = new ArithExpressionContext(_localctx);                enterOuterAlt(_localctx, 3);                {                    setState(74);                    arithmetic_expr(0);                }                break;            case 4:                _localctx = new TransformationEntityContext(_localctx);                enterOuterAlt(_localctx, 4);                {                    setState(75);                    transformation_entity();                }                break;            case 5:                _localctx = new ComparisonExpressionContext(_localctx);                enterOuterAlt(_localctx, 5);                {                    setState(76);                    comparison_expr(0);                }                break;            case 6:                _localctx = new LogicalExpressionContext(_localctx);                enterOuterAlt(_localctx, 6);                {                    setState(77);                    logical_expr();                }                break;            case 7:                _localctx = new InExpressionContext(_localctx);                enterOuterAlt(_localctx, 7);                {                    setState(78);                    in_expr();                }                break;            case 8:                _localctx = new MatchExprContext(_localctx);                enterOuterAlt(_localctx, 8);                {                    setState(79);                    match_expr();                }                break;        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
public Logical_exprContext metron_f8245_0()
{    return getRuleContext(Logical_exprContext.class, 0);}
public int metron_f8246_0()
{    return RULE_if_expr;}
public void metron_f8247_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterIf_expr(this);}
public void metron_f8248_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitIf_expr(this);}
public final If_exprContext metron_f8249_0() throws RecognitionException
{    If_exprContext _localctx = new If_exprContext(_ctx, getState());    enterRule(_localctx, 4, RULE_if_expr);    try {        enterOuterAlt(_localctx, 1);        {            setState(82);            logical_expr();        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
public Transformation_exprContext metron_f8250_0()
{    return getRuleContext(Transformation_exprContext.class, 0);}
public int metron_f8251_0()
{    return RULE_then_expr;}
public void metron_f8252_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterThen_expr(this);}
public void metron_f8253_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitThen_expr(this);}
public final Then_exprContext metron_f8254_0() throws RecognitionException
{    Then_exprContext _localctx = new Then_exprContext(_ctx, getState());    enterRule(_localctx, 6, RULE_then_expr);    try {        enterOuterAlt(_localctx, 1);        {            setState(84);            transformation_expr();        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
public Transformation_exprContext metron_f8255_0()
{    return getRuleContext(Transformation_exprContext.class, 0);}
public int metron_f8256_0()
{    return RULE_else_expr;}
public void metron_f8257_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterElse_expr(this);}
public void metron_f8258_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitElse_expr(this);}
public final Else_exprContext metron_f8259_0() throws RecognitionException
{    Else_exprContext _localctx = new Else_exprContext(_ctx, getState());    enterRule(_localctx, 8, RULE_else_expr);    try {        enterOuterAlt(_localctx, 1);        {            setState(86);            transformation_expr();        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
public int metron_f8260_0()
{    return RULE_conditional_expr;}
public void metron_f8261_0(Conditional_exprContext ctx)
{    super.copyFrom(ctx);}
public If_exprContext metron_f8262_0()
{    return getRuleContext(If_exprContext.class, 0);}
public TerminalNode metron_f8263_0()
{    return getToken(StellarParser.QUESTION, 0);}
public Then_exprContext metron_f8264_0()
{    return getRuleContext(Then_exprContext.class, 0);}
public TerminalNode metron_f8265_0()
{    return getToken(StellarParser.COLON, 0);}
public Else_exprContext metron_f8266_0()
{    return getRuleContext(Else_exprContext.class, 0);}
public void metron_f8267_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterTernaryFuncWithoutIf(this);}
public void metron_f8268_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitTernaryFuncWithoutIf(this);}
public TerminalNode metron_f8269_0()
{    return getToken(StellarParser.IF, 0);}
public If_exprContext metron_f8270_0()
{    return getRuleContext(If_exprContext.class, 0);}
public TerminalNode metron_f8271_0()
{    return getToken(StellarParser.THEN, 0);}
public Then_exprContext metron_f8272_0()
{    return getRuleContext(Then_exprContext.class, 0);}
public TerminalNode metron_f8273_0()
{    return getToken(StellarParser.ELSE, 0);}
public Else_exprContext metron_f8274_0()
{    return getRuleContext(Else_exprContext.class, 0);}
public void metron_f8275_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterTernaryFuncWithIf(this);}
public void metron_f8276_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitTernaryFuncWithIf(this);}
public final Conditional_exprContext metron_f8277_0() throws RecognitionException
{    Conditional_exprContext _localctx = new Conditional_exprContext(_ctx, getState());    enterRule(_localctx, 10, RULE_conditional_expr);    try {        setState(101);        switch(_input.LA(1)) {            case NOT:            case TRUE:            case FALSE:            case NULL:            case NAN:            case LBRACE:            case LBRACKET:            case LPAREN:            case EXISTS:            case INT_LITERAL:            case DOUBLE_LITERAL:            case FLOAT_LITERAL:            case LONG_LITERAL:            case IDENTIFIER:            case STRING_LITERAL:                _localctx = new TernaryFuncWithoutIfContext(_localctx);                enterOuterAlt(_localctx, 1);                {                    setState(88);                    if_expr();                    setState(89);                    match(QUESTION);                    setState(90);                    then_expr();                    setState(91);                    match(COLON);                    setState(92);                    else_expr();                }                break;            case IF:                _localctx = new TernaryFuncWithIfContext(_localctx);                enterOuterAlt(_localctx, 2);                {                    setState(94);                    match(IF);                    setState(95);                    if_expr();                    setState(96);                    match(THEN);                    setState(97);                    then_expr();                    setState(98);                    match(ELSE);                    setState(99);                    else_expr();                }                break;            default:                throw new NoViableAltException(this);        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
public int metron_f8278_0()
{    return RULE_logical_expr;}
public void metron_f8279_0(Logical_exprContext ctx)
{    super.copyFrom(ctx);}
public B_exprContext metron_f8280_0()
{    return getRuleContext(B_exprContext.class, 0);}
public TerminalNode metron_f8281_0()
{    return getToken(StellarParser.AND, 0);}
public Logical_exprContext metron_f8282_0()
{    return getRuleContext(Logical_exprContext.class, 0);}
public void metron_f8283_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterLogicalExpressionAnd(this);}
public void metron_f8284_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitLogicalExpressionAnd(this);}
public B_exprContext metron_f8285_0()
{    return getRuleContext(B_exprContext.class, 0);}
public void metron_f8286_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterBoleanExpression(this);}
public void metron_f8287_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitBoleanExpression(this);}
public B_exprContext metron_f8288_0()
{    return getRuleContext(B_exprContext.class, 0);}
public TerminalNode metron_f8289_0()
{    return getToken(StellarParser.OR, 0);}
public Logical_exprContext metron_f8290_0()
{    return getRuleContext(Logical_exprContext.class, 0);}
public void metron_f8291_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterLogicalExpressionOr(this);}
public void metron_f8292_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitLogicalExpressionOr(this);}
public final Logical_exprContext metron_f8293_0() throws RecognitionException
{    Logical_exprContext _localctx = new Logical_exprContext(_ctx, getState());    enterRule(_localctx, 12, RULE_logical_expr);    try {        setState(112);        switch(getInterpreter().adaptivePredict(_input, 2, _ctx)) {            case 1:                _localctx = new LogicalExpressionAndContext(_localctx);                enterOuterAlt(_localctx, 1);                {                    setState(103);                    b_expr();                    setState(104);                    match(AND);                    setState(105);                    logical_expr();                }                break;            case 2:                _localctx = new LogicalExpressionOrContext(_localctx);                enterOuterAlt(_localctx, 2);                {                    setState(107);                    b_expr();                    setState(108);                    match(OR);                    setState(109);                    logical_expr();                }                break;            case 3:                _localctx = new BoleanExpressionContext(_localctx);                enterOuterAlt(_localctx, 3);                {                    setState(111);                    b_expr();                }                break;        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
public Comparison_exprContext metron_f8294_0()
{    return getRuleContext(Comparison_exprContext.class, 0);}
public In_exprContext metron_f8295_0()
{    return getRuleContext(In_exprContext.class, 0);}
public int metron_f8296_0()
{    return RULE_b_expr;}
public void metron_f8297_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterB_expr(this);}
public void metron_f8298_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitB_expr(this);}
public final B_exprContext metron_f8299_0() throws RecognitionException
{    B_exprContext _localctx = new B_exprContext(_ctx, getState());    enterRule(_localctx, 14, RULE_b_expr);    try {        setState(116);        switch(getInterpreter().adaptivePredict(_input, 3, _ctx)) {            case 1:                enterOuterAlt(_localctx, 1);                {                    setState(114);                    comparison_expr(0);                }                break;            case 2:                enterOuterAlt(_localctx, 2);                {                    setState(115);                    in_expr();                }                break;        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
public int metron_f8300_0()
{    return RULE_in_expr;}
public void metron_f8301_0(In_exprContext ctx)
{    super.copyFrom(ctx);}
public Identifier_operandContext metron_f8302_0()
{    return getRuleContext(Identifier_operandContext.class, 0);}
public TerminalNode metron_f8303_0()
{    return getToken(StellarParser.NIN, 0);}
public B_exprContext metron_f8304_0()
{    return getRuleContext(B_exprContext.class, 0);}
public void metron_f8305_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterNInExpressionStatement(this);}
public void metron_f8306_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitNInExpressionStatement(this);}
public Identifier_operandContext metron_f8307_0()
{    return getRuleContext(Identifier_operandContext.class, 0);}
public TerminalNode metron_f8308_0()
{    return getToken(StellarParser.IN, 0);}
public B_exprContext metron_f8309_0()
{    return getRuleContext(B_exprContext.class, 0);}
public void metron_f8310_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterInExpressionStatement(this);}
public void metron_f8311_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitInExpressionStatement(this);}
public final In_exprContext metron_f8312_0() throws RecognitionException
{    In_exprContext _localctx = new In_exprContext(_ctx, getState());    enterRule(_localctx, 16, RULE_in_expr);    try {        setState(126);        switch(getInterpreter().adaptivePredict(_input, 4, _ctx)) {            case 1:                _localctx = new InExpressionStatementContext(_localctx);                enterOuterAlt(_localctx, 1);                {                    setState(118);                    identifier_operand();                    setState(119);                    match(IN);                    setState(120);                    b_expr();                }                break;            case 2:                _localctx = new NInExpressionStatementContext(_localctx);                enterOuterAlt(_localctx, 2);                {                    setState(122);                    identifier_operand();                    setState(123);                    match(NIN);                    setState(124);                    b_expr();                }                break;        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
public int metron_f8313_0()
{    return RULE_comparison_expr;}
public void metron_f8314_0(Comparison_exprContext ctx)
{    super.copyFrom(ctx);}
public TerminalNode metron_f8315_0()
{    return getToken(StellarParser.NOT, 0);}
public TerminalNode metron_f8316_0()
{    return getToken(StellarParser.LPAREN, 0);}
public Logical_exprContext metron_f8317_0()
{    return getRuleContext(Logical_exprContext.class, 0);}
public TerminalNode metron_f8318_0()
{    return getToken(StellarParser.RPAREN, 0);}
public void metron_f8319_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterNotFunc(this);}
public void metron_f8320_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitNotFunc(this);}
public TerminalNode metron_f8321_0()
{    return getToken(StellarParser.LPAREN, 0);}
public Logical_exprContext metron_f8322_0()
{    return getRuleContext(Logical_exprContext.class, 0);}
public TerminalNode metron_f8323_0()
{    return getToken(StellarParser.RPAREN, 0);}
public void metron_f8324_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterComparisonExpressionParens(this);}
public void metron_f8325_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitComparisonExpressionParens(this);}
public List<Comparison_exprContext> metron_f8326_0()
{    return getRuleContexts(Comparison_exprContext.class);}
public Comparison_exprContext metron_f8327_0(int i)
{    return getRuleContext(Comparison_exprContext.class, i);}
public Comp_operatorContext metron_f8328_0()
{    return getRuleContext(Comp_operatorContext.class, 0);}
public void metron_f8329_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterComparisonExpressionWithOperator(this);}
public void metron_f8330_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitComparisonExpressionWithOperator(this);}
public Identifier_operandContext metron_f8331_0()
{    return getRuleContext(Identifier_operandContext.class, 0);}
public void metron_f8332_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterOperand(this);}
public void metron_f8333_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitOperand(this);}
public final Comparison_exprContext metron_f8334_0() throws RecognitionException
{    return comparison_expr(0);}
private Comparison_exprContext metron_f8335_0(int _p) throws RecognitionException
{    ParserRuleContext _parentctx = _ctx;    int _parentState = getState();    Comparison_exprContext _localctx = new Comparison_exprContext(_ctx, _parentState);    Comparison_exprContext _prevctx = _localctx;    int _startState = 18;    enterRecursionRule(_localctx, 18, RULE_comparison_expr, _p);    try {        int _alt;        enterOuterAlt(_localctx, 1);        {            setState(139);            switch(getInterpreter().adaptivePredict(_input, 5, _ctx)) {                case 1:                    {                        _localctx = new NotFuncContext(_localctx);                        _ctx = _localctx;                        _prevctx = _localctx;                        setState(129);                        match(NOT);                        setState(130);                        match(LPAREN);                        setState(131);                        logical_expr();                        setState(132);                        match(RPAREN);                    }                    break;                case 2:                    {                        _localctx = new ComparisonExpressionParensContext(_localctx);                        _ctx = _localctx;                        _prevctx = _localctx;                        setState(134);                        match(LPAREN);                        setState(135);                        logical_expr();                        setState(136);                        match(RPAREN);                    }                    break;                case 3:                    {                        _localctx = new OperandContext(_localctx);                        _ctx = _localctx;                        _prevctx = _localctx;                        setState(138);                        identifier_operand();                    }                    break;            }            _ctx.stop = _input.LT(-1);            setState(147);            _errHandler.sync(this);            _alt = getInterpreter().adaptivePredict(_input, 6, _ctx);            while (_alt != 2 && _alt != org.antlr.v4.runtime.atn.ATN.INVALID_ALT_NUMBER) {                if (_alt == 1) {                    if (_parseListeners != null)                        triggerExitRuleEvent();                    _prevctx = _localctx;                    {                        {                            _localctx = new ComparisonExpressionWithOperatorContext(new Comparison_exprContext(_parentctx, _parentState));                            pushNewRecursionContext(_localctx, _startState, RULE_comparison_expr);                            setState(141);                            if (!(precpred(_ctx, 4)))                                throw new FailedPredicateException(this, "precpred(_ctx, 4)");                            setState(142);                            comp_operator();                            setState(143);                            comparison_expr(5);                        }                    }                }                setState(149);                _errHandler.sync(this);                _alt = getInterpreter().adaptivePredict(_input, 6, _ctx);            }        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        unrollRecursionContexts(_parentctx);    }    return _localctx;}
public Identifier_operandContext metron_f8336_0()
{    return getRuleContext(Identifier_operandContext.class, 0);}
public int metron_f8337_0()
{    return RULE_transformation_entity;}
public void metron_f8338_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterTransformation_entity(this);}
public void metron_f8339_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitTransformation_entity(this);}
public final Transformation_entityContext metron_f8340_0() throws RecognitionException
{    Transformation_entityContext _localctx = new Transformation_entityContext(_ctx, getState());    enterRule(_localctx, 20, RULE_transformation_entity);    try {        enterOuterAlt(_localctx, 1);        {            setState(150);            identifier_operand();        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
public int metron_f8341_0()
{    return RULE_comp_operator;}
public void metron_f8342_0(Comp_operatorContext ctx)
{    super.copyFrom(ctx);}
public TerminalNode metron_f8343_0()
{    return getToken(StellarParser.EQ, 0);}
public TerminalNode metron_f8344_0()
{    return getToken(StellarParser.NEQ, 0);}
public TerminalNode metron_f8345_0()
{    return getToken(StellarParser.LT, 0);}
public TerminalNode metron_f8346_0()
{    return getToken(StellarParser.LTE, 0);}
public TerminalNode metron_f8347_0()
{    return getToken(StellarParser.GT, 0);}
public TerminalNode metron_f8348_0()
{    return getToken(StellarParser.GTE, 0);}
public void metron_f8349_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterComparisonOp(this);}
public void metron_f8350_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitComparisonOp(this);}
public final Comp_operatorContext metron_f8351_0() throws RecognitionException
{    Comp_operatorContext _localctx = new Comp_operatorContext(_ctx, getState());    enterRule(_localctx, 22, RULE_comp_operator);    int _la;    try {        _localctx = new ComparisonOpContext(_localctx);        enterOuterAlt(_localctx, 1);        {            setState(152);            _la = _input.LA(1);            if (!((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << EQ) | (1L << NEQ) | (1L << LT) | (1L << LTE) | (1L << GT) | (1L << GTE))) != 0))) {                _errHandler.recoverInline(this);            } else {                consume();            }        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
public TerminalNode metron_f8352_0()
{    return getToken(StellarParser.LPAREN, 0);}
public Op_listContext metron_f8353_0()
{    return getRuleContext(Op_listContext.class, 0);}
public TerminalNode metron_f8354_0()
{    return getToken(StellarParser.RPAREN, 0);}
public int metron_f8355_0()
{    return RULE_func_args;}
public void metron_f8356_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterFunc_args(this);}
public void metron_f8357_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitFunc_args(this);}
public final Func_argsContext metron_f8358_0() throws RecognitionException
{    Func_argsContext _localctx = new Func_argsContext(_ctx, getState());    enterRule(_localctx, 24, RULE_func_args);    try {        setState(160);        switch(getInterpreter().adaptivePredict(_input, 7, _ctx)) {            case 1:                enterOuterAlt(_localctx, 1);                {                    setState(154);                    match(LPAREN);                    setState(155);                    op_list(0);                    setState(156);                    match(RPAREN);                }                break;            case 2:                enterOuterAlt(_localctx, 2);                {                    setState(158);                    match(LPAREN);                    setState(159);                    match(RPAREN);                }                break;        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
public Identifier_operandContext metron_f8359_0()
{    return getRuleContext(Identifier_operandContext.class, 0);}
public Conditional_exprContext metron_f8360_0()
{    return getRuleContext(Conditional_exprContext.class, 0);}
public Comparison_exprContext metron_f8361_0()
{    return getRuleContext(Comparison_exprContext.class, 0);}
public Op_listContext metron_f8362_0()
{    return getRuleContext(Op_listContext.class, 0);}
public TerminalNode metron_f8363_0()
{    return getToken(StellarParser.COMMA, 0);}
public int metron_f8364_0()
{    return RULE_op_list;}
public void metron_f8365_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterOp_list(this);}
public void metron_f8366_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitOp_list(this);}
public final Op_listContext metron_f8367_0() throws RecognitionException
{    return op_list(0);}
private Op_listContext metron_f8368_0(int _p) throws RecognitionException
{    ParserRuleContext _parentctx = _ctx;    int _parentState = getState();    Op_listContext _localctx = new Op_listContext(_ctx, _parentState);    Op_listContext _prevctx = _localctx;    int _startState = 26;    enterRecursionRule(_localctx, 26, RULE_op_list, _p);    try {        int _alt;        enterOuterAlt(_localctx, 1);        {            setState(166);            switch(getInterpreter().adaptivePredict(_input, 8, _ctx)) {                case 1:                    {                        setState(163);                        identifier_operand();                    }                    break;                case 2:                    {                        setState(164);                        conditional_expr();                    }                    break;                case 3:                    {                        setState(165);                        comparison_expr(0);                    }                    break;            }            _ctx.stop = _input.LT(-1);            setState(179);            _errHandler.sync(this);            _alt = getInterpreter().adaptivePredict(_input, 10, _ctx);            while (_alt != 2 && _alt != org.antlr.v4.runtime.atn.ATN.INVALID_ALT_NUMBER) {                if (_alt == 1) {                    if (_parseListeners != null)                        triggerExitRuleEvent();                    _prevctx = _localctx;                    {                        setState(177);                        switch(getInterpreter().adaptivePredict(_input, 9, _ctx)) {                            case 1:                                {                                    _localctx = new Op_listContext(_parentctx, _parentState);                                    pushNewRecursionContext(_localctx, _startState, RULE_op_list);                                    setState(168);                                    if (!(precpred(_ctx, 5)))                                        throw new FailedPredicateException(this, "precpred(_ctx, 5)");                                    setState(169);                                    match(COMMA);                                    setState(170);                                    identifier_operand();                                }                                break;                            case 2:                                {                                    _localctx = new Op_listContext(_parentctx, _parentState);                                    pushNewRecursionContext(_localctx, _startState, RULE_op_list);                                    setState(171);                                    if (!(precpred(_ctx, 3)))                                        throw new FailedPredicateException(this, "precpred(_ctx, 3)");                                    setState(172);                                    match(COMMA);                                    setState(173);                                    conditional_expr();                                }                                break;                            case 3:                                {                                    _localctx = new Op_listContext(_parentctx, _parentState);                                    pushNewRecursionContext(_localctx, _startState, RULE_op_list);                                    setState(174);                                    if (!(precpred(_ctx, 1)))                                        throw new FailedPredicateException(this, "precpred(_ctx, 1)");                                    setState(175);                                    match(COMMA);                                    setState(176);                                    comparison_expr(0);                                }                                break;                        }                    }                }                setState(181);                _errHandler.sync(this);                _alt = getInterpreter().adaptivePredict(_input, 10, _ctx);            }        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        unrollRecursionContexts(_parentctx);    }    return _localctx;}
public TerminalNode metron_f8369_0()
{    return getToken(StellarParser.LBRACKET, 0);}
public TerminalNode metron_f8370_0()
{    return getToken(StellarParser.RBRACKET, 0);}
public Op_listContext metron_f8371_0()
{    return getRuleContext(Op_listContext.class, 0);}
public int metron_f8372_0()
{    return RULE_list_entity;}
public void metron_f8373_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterList_entity(this);}
public void metron_f8374_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitList_entity(this);}
public final List_entityContext metron_f8375_0() throws RecognitionException
{    List_entityContext _localctx = new List_entityContext(_ctx, getState());    enterRule(_localctx, 28, RULE_list_entity);    try {        setState(188);        switch(getInterpreter().adaptivePredict(_input, 11, _ctx)) {            case 1:                enterOuterAlt(_localctx, 1);                {                    setState(182);                    match(LBRACKET);                    setState(183);                    match(RBRACKET);                }                break;            case 2:                enterOuterAlt(_localctx, 2);                {                    setState(184);                    match(LBRACKET);                    setState(185);                    op_list(0);                    setState(186);                    match(RBRACKET);                }                break;        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
public Identifier_operandContext metron_f8376_0()
{    return getRuleContext(Identifier_operandContext.class, 0);}
public TerminalNode metron_f8377_0()
{    return getToken(StellarParser.COLON, 0);}
public Transformation_exprContext metron_f8378_0()
{    return getRuleContext(Transformation_exprContext.class, 0);}
public Comparison_exprContext metron_f8379_0()
{    return getRuleContext(Comparison_exprContext.class, 0);}
public Kv_listContext metron_f8380_0()
{    return getRuleContext(Kv_listContext.class, 0);}
public TerminalNode metron_f8381_0()
{    return getToken(StellarParser.COMMA, 0);}
public int metron_f8382_0()
{    return RULE_kv_list;}
public void metron_f8383_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterKv_list(this);}
public void metron_f8384_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitKv_list(this);}
public final Kv_listContext metron_f8385_0() throws RecognitionException
{    return kv_list(0);}
private Kv_listContext metron_f8386_0(int _p) throws RecognitionException
{    ParserRuleContext _parentctx = _ctx;    int _parentState = getState();    Kv_listContext _localctx = new Kv_listContext(_ctx, _parentState);    Kv_listContext _prevctx = _localctx;    int _startState = 30;    enterRecursionRule(_localctx, 30, RULE_kv_list, _p);    try {        int _alt;        enterOuterAlt(_localctx, 1);        {            setState(199);            switch(getInterpreter().adaptivePredict(_input, 12, _ctx)) {                case 1:                    {                        setState(191);                        identifier_operand();                        setState(192);                        match(COLON);                        setState(193);                        transformation_expr();                    }                    break;                case 2:                    {                        setState(195);                        comparison_expr(0);                        setState(196);                        match(COLON);                        setState(197);                        transformation_expr();                    }                    break;            }            _ctx.stop = _input.LT(-1);            setState(215);            _errHandler.sync(this);            _alt = getInterpreter().adaptivePredict(_input, 14, _ctx);            while (_alt != 2 && _alt != org.antlr.v4.runtime.atn.ATN.INVALID_ALT_NUMBER) {                if (_alt == 1) {                    if (_parseListeners != null)                        triggerExitRuleEvent();                    _prevctx = _localctx;                    {                        setState(213);                        switch(getInterpreter().adaptivePredict(_input, 13, _ctx)) {                            case 1:                                {                                    _localctx = new Kv_listContext(_parentctx, _parentState);                                    pushNewRecursionContext(_localctx, _startState, RULE_kv_list);                                    setState(201);                                    if (!(precpred(_ctx, 2)))                                        throw new FailedPredicateException(this, "precpred(_ctx, 2)");                                    setState(202);                                    match(COMMA);                                    setState(203);                                    identifier_operand();                                    setState(204);                                    match(COLON);                                    setState(205);                                    transformation_expr();                                }                                break;                            case 2:                                {                                    _localctx = new Kv_listContext(_parentctx, _parentState);                                    pushNewRecursionContext(_localctx, _startState, RULE_kv_list);                                    setState(207);                                    if (!(precpred(_ctx, 1)))                                        throw new FailedPredicateException(this, "precpred(_ctx, 1)");                                    setState(208);                                    match(COMMA);                                    setState(209);                                    comparison_expr(0);                                    setState(210);                                    match(COLON);                                    setState(211);                                    transformation_expr();                                }                                break;                        }                    }                }                setState(217);                _errHandler.sync(this);                _alt = getInterpreter().adaptivePredict(_input, 14, _ctx);            }        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        unrollRecursionContexts(_parentctx);    }    return _localctx;}
public TerminalNode metron_f8387_0()
{    return getToken(StellarParser.LBRACE, 0);}
public Kv_listContext metron_f8388_0()
{    return getRuleContext(Kv_listContext.class, 0);}
public TerminalNode metron_f8389_0()
{    return getToken(StellarParser.RBRACE, 0);}
public int metron_f8390_0()
{    return RULE_map_entity;}
public void metron_f8391_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterMap_entity(this);}
public void metron_f8392_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitMap_entity(this);}
public final Map_entityContext metron_f8393_0() throws RecognitionException
{    Map_entityContext _localctx = new Map_entityContext(_ctx, getState());    enterRule(_localctx, 32, RULE_map_entity);    try {        setState(224);        switch(getInterpreter().adaptivePredict(_input, 15, _ctx)) {            case 1:                enterOuterAlt(_localctx, 1);                {                    setState(218);                    match(LBRACE);                    setState(219);                    kv_list(0);                    setState(220);                    match(RBRACE);                }                break;            case 2:                enterOuterAlt(_localctx, 2);                {                    setState(222);                    match(LBRACE);                    setState(223);                    match(RBRACE);                }                break;        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
public int metron_f8394_0()
{    return RULE_arithmetic_expr;}
public void metron_f8395_0(Arithmetic_exprContext ctx)
{    super.copyFrom(ctx);}
public Arithmetic_expr_mulContext metron_f8396_0()
{    return getRuleContext(Arithmetic_expr_mulContext.class, 0);}
public void metron_f8397_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterArithExpr_solo(this);}
public void metron_f8398_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitArithExpr_solo(this);}
public Arithmetic_exprContext metron_f8399_0()
{    return getRuleContext(Arithmetic_exprContext.class, 0);}
public TerminalNode metron_f8400_0()
{    return getToken(StellarParser.MINUS, 0);}
public Arithmetic_expr_mulContext metron_f8401_0()
{    return getRuleContext(Arithmetic_expr_mulContext.class, 0);}
public void metron_f8402_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterArithExpr_minus(this);}
public void metron_f8403_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitArithExpr_minus(this);}
public Arithmetic_exprContext metron_f8404_0()
{    return getRuleContext(Arithmetic_exprContext.class, 0);}
public TerminalNode metron_f8405_0()
{    return getToken(StellarParser.PLUS, 0);}
public Arithmetic_expr_mulContext metron_f8406_0()
{    return getRuleContext(Arithmetic_expr_mulContext.class, 0);}
public void metron_f8407_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterArithExpr_plus(this);}
public void metron_f8408_0(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitArithExpr_plus(this);}
public final Arithmetic_exprContext metron_f8409_0() throws RecognitionException
{    return arithmetic_expr(0);}
private Arithmetic_exprContext metron_f8410_0(int _p) throws RecognitionException
{    ParserRuleContext _parentctx = _ctx;    int _parentState = getState();    Arithmetic_exprContext _localctx = new Arithmetic_exprContext(_ctx, _parentState);    Arithmetic_exprContext _prevctx = _localctx;    int _startState = 34;    enterRecursionRule(_localctx, 34, RULE_arithmetic_expr, _p);    try {        int _alt;        enterOuterAlt(_localctx, 1);        {            {                _localctx = new ArithExpr_soloContext(_localctx);                _ctx = _localctx;                _prevctx = _localctx;                setState(227);                arithmetic_expr_mul(0);            }            _ctx.stop = _input.LT(-1);            setState(237);            _errHandler.sync(this);            _alt = getInterpreter().adaptivePredict(_input, 17, _ctx);            while (_alt != 2 && _alt != org.antlr.v4.runtime.atn.ATN.INVALID_ALT_NUMBER) {                if (_alt == 1) {                    if (_parseListeners != null)                        triggerExitRuleEvent();                    _prevctx = _localctx;                    {                        setState(235);                        switch(getInterpreter().adaptivePredict(_input, 16, _ctx)) {                            case 1:                                {                                    _localctx = new ArithExpr_plusContext(new Arithmetic_exprContext(_parentctx, _parentState));                                    pushNewRecursionContext(_localctx, _startState, RULE_arithmetic_expr);                                    setState(229);                                    if (!(precpred(_ctx, 2)))                                        throw new FailedPredicateException(this, "precpred(_ctx, 2)");                                    setState(230);                                    match(PLUS);                                    setState(231);                                    arithmetic_expr_mul(0);                                }                                break;                            case 2:                                {                                    _localctx = new ArithExpr_minusContext(new Arithmetic_exprContext(_parentctx, _parentState));                                    pushNewRecursionContext(_localctx, _startState, RULE_arithmetic_expr);                                    setState(232);                                    if (!(precpred(_ctx, 1)))                                        throw new FailedPredicateException(this, "precpred(_ctx, 1)");                                    setState(233);                                    match(MINUS);                                    setState(234);                                    arithmetic_expr_mul(0);                                }                                break;                        }                    }                }                setState(239);                _errHandler.sync(this);                _alt = getInterpreter().adaptivePredict(_input, 17, _ctx);            }        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        unrollRecursionContexts(_parentctx);    }    return _localctx;}
public int metron_f8411_0()
{    return RULE_arithmetic_expr_mul;}
public void metron_f8412_0(Arithmetic_expr_mulContext ctx)
{    super.copyFrom(ctx);}
public List<Arithmetic_expr_mulContext> metron_f8413_0()
{    return getRuleContexts(Arithmetic_expr_mulContext.class);}
public Arithmetic_expr_mulContext metron_f8414_0(int i)
{    return getRuleContext(Arithmetic_expr_mulContext.class, i);}
