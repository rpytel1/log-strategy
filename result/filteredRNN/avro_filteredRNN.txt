public static void main(String[] args) throws IOException
{    Schema schema = new Parser().parse(new File("./../user.avsc"));    GenericRecord user1 = new GenericData.Record(schema);    user1.put("name", "Alyssa");    user1.put("favorite_number", 256);        GenericRecord user2 = new GenericData.Record(schema);    user2.put("name", "Ben");    user2.put("favorite_number", 7);    user2.put("favorite_color", "red");        File file = new File("users.avro");    DatumWriter<GenericRecord> datumWriter = new GenericDatumWriter<GenericRecord>(schema);    DataFileWriter<GenericRecord> dataFileWriter = new DataFileWriter<GenericRecord>(datumWriter);    dataFileWriter.create(schema, file);    dataFileWriter.append(user1);    dataFileWriter.append(user2);    dataFileWriter.close();        DatumReader<GenericRecord> datumReader = new GenericDatumReader<GenericRecord>(schema);    DataFileReader<GenericRecord> dataFileReader = new DataFileReader<GenericRecord>(file, datumReader);    GenericRecord user = null;    while (dataFileReader.hasNext()) {                                user = dataFileReader.next(user);        System.out.println(user);    }}
0
public static void main(String[] args) throws IOException
{    User user1 = new User();    user1.setName("Alyssa");    user1.setFavoriteNumber(256);            User user2 = new User("Ben", 7, "red");        User user3 = User.newBuilder().setName("Charlie").setFavoriteColor("blue").setFavoriteNumber(null).build();        File file = new File("users.avro");    DatumWriter<User> userDatumWriter = new SpecificDatumWriter<User>(User.class);    DataFileWriter<User> dataFileWriter = new DataFileWriter<User>(userDatumWriter);    dataFileWriter.create(user1.getSchema(), file);    dataFileWriter.append(user1);    dataFileWriter.append(user2);    dataFileWriter.append(user3);    dataFileWriter.close();        DatumReader<User> userDatumReader = new SpecificDatumReader<User>(User.class);    DataFileReader<User> dataFileReader = new DataFileReader<User>(file, userDatumReader);    User user = null;    while (dataFileReader.hasNext()) {                                user = dataFileReader.next(user);        System.out.println(user);    }}
0
public void map(LongWritable key, Text value, OutputCollector<Text, IntWritable> output, Reporter reporter) throws IOException
{    String line = value.toString();    StringTokenizer tokenizer = new StringTokenizer(line);    while (tokenizer.hasMoreTokens()) {        word.set(tokenizer.nextToken());        output.collect(word, one);    }}
0
public void reduce(Text key, Iterator<IntWritable> values, OutputCollector<AvroWrapper<Pair<CharSequence, Integer>>, NullWritable> output, Reporter reporter) throws IOException
{    int sum = 0;    while (values.hasNext()) {        sum += values.next().get();    }    output.collect(new AvroWrapper<Pair<CharSequence, Integer>>(new Pair<CharSequence, Integer>(key.toString(), sum)), NullWritable.get());}
0
public int run(String[] args) throws Exception
{    if (args.length != 2) {        System.err.println("Usage: AvroWordCount <input path> <output path>");        return -1;    }    JobConf conf = new JobConf(AvroWordCount.class);    conf.setJobName("wordcount");            AvroJob.setOutputSchema(conf, Pair.getPairSchema(Schema.create(Type.STRING), Schema.create(Type.INT)));    conf.setMapperClass(Map.class);    conf.setReducerClass(Reduce.class);    conf.setInputFormat(TextInputFormat.class);    conf.setMapOutputKeyClass(Text.class);    conf.setMapOutputValueClass(IntWritable.class);    conf.setOutputKeyComparatorClass(Text.Comparator.class);    FileInputFormat.setInputPaths(conf, new Path(args[0]));    FileOutputFormat.setOutputPath(conf, new Path(args[1]));    JobClient.runJob(conf);    return 0;}
0
public static void main(String[] args) throws Exception
{    int res = ToolRunner.run(new Configuration(), new AvroWordCount(), args);    System.exit(res);}
0
public static void main(String[] args) throws IOException
{        File file = new File(PATH);    if (file.getParentFile() != null) {        file.getParentFile().mkdirs();    }    DatumWriter<User> userDatumWriter = new SpecificDatumWriter<User>(User.class);    DataFileWriter<User> dataFileWriter = new DataFileWriter<User>(userDatumWriter);    dataFileWriter.create(User.SCHEMA$, file);        User user;    Random random = new Random();    for (int i = 0; i < USERS; i++) {        user = new User("user", null, COLORS[random.nextInt(COLORS.length)]);        dataFileWriter.append(user);        System.out.println(user);    }    dataFileWriter.close();}
0
public void map(User user, AvroCollector<Pair<CharSequence, Integer>> collector, Reporter reporter) throws IOException
{    CharSequence color = user.getFavoriteColor();        if (color == null) {        color = "none";    }    collector.collect(new Pair<CharSequence, Integer>(color, 1));}
0
public void reduce(CharSequence key, Iterable<Integer> values, AvroCollector<Pair<CharSequence, Integer>> collector, Reporter reporter) throws IOException
{    int sum = 0;    for (Integer value : values) {        sum += value;    }    collector.collect(new Pair<CharSequence, Integer>(key, sum));}
0
public int run(String[] args) throws Exception
{    if (args.length != 2) {        System.err.println("Usage: MapredColorCount <input path> <output path>");        return -1;    }    JobConf conf = new JobConf(getConf(), MapredColorCount.class);    conf.setJobName("colorcount");    FileInputFormat.setInputPaths(conf, new Path(args[0]));    FileOutputFormat.setOutputPath(conf, new Path(args[1]));    AvroJob.setMapperClass(conf, ColorCountMapper.class);    AvroJob.setReducerClass(conf, ColorCountReducer.class);                AvroJob.setInputSchema(conf, User.getClassSchema());    AvroJob.setOutputSchema(conf, Pair.getPairSchema(Schema.create(Type.STRING), Schema.create(Type.INT)));    JobClient.runJob(conf);    return 0;}
0
public static void main(String[] args) throws Exception
{    int res = ToolRunner.run(new Configuration(), new MapredColorCount(), args);    System.exit(res);}
0
public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException
{    String line = value.toString();    StringTokenizer tokenizer = new StringTokenizer(line);    while (tokenizer.hasMoreTokens()) {        word.set(tokenizer.nextToken());        context.write(word, one);    }}
0
public void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException
{    int sum = 0;    for (IntWritable value : values) {        sum += value.get();    }    context.write(new AvroWrapper<Pair<CharSequence, Integer>>(new Pair<CharSequence, Integer>(key.toString(), sum)), NullWritable.get());}
0
public int run(String[] args) throws Exception
{    if (args.length != 2) {        System.err.println("Usage: AvroWordCount <input path> <output path>");        return -1;    }    Job job = new Job(getConf());    job.setJarByClass(MapReduceAvroWordCount.class);    job.setJobName("wordcount");            AvroJob.setOutputKeySchema(job, Pair.getPairSchema(Schema.create(Type.STRING), Schema.create(Type.INT)));    job.setOutputValueClass(NullWritable.class);    job.setMapperClass(Map.class);    job.setReducerClass(Reduce.class);    job.setInputFormatClass(TextInputFormat.class);    job.setMapOutputKeyClass(Text.class);    job.setMapOutputValueClass(IntWritable.class);    job.setSortComparatorClass(Text.Comparator.class);    FileInputFormat.setInputPaths(job, new Path(args[0]));    FileOutputFormat.setOutputPath(job, new Path(args[1]));    job.waitForCompletion(true);    return 0;}
0
public static void main(String[] args) throws Exception
{    int res = ToolRunner.run(new Configuration(), new MapReduceAvroWordCount(), args);    System.exit(res);}
0
public void map(AvroKey<User> key, NullWritable value, Context context) throws IOException, InterruptedException
{    CharSequence color = key.datum().getFavoriteColor();    if (color == null) {        color = "none";    }    context.write(new Text(color.toString()), new IntWritable(1));}
0
public void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException
{    int sum = 0;    for (IntWritable value : values) {        sum += value.get();    }    context.write(new AvroKey<CharSequence>(key.toString()), new AvroValue<Integer>(sum));}
0
public int run(String[] args) throws Exception
{    if (args.length != 2) {        System.err.println("Usage: MapReduceColorCount <input path> <output path>");        return -1;    }    Job job = new Job(getConf());    job.setJarByClass(MapReduceColorCount.class);    job.setJobName("Color Count");    FileInputFormat.setInputPaths(job, new Path(args[0]));    FileOutputFormat.setOutputPath(job, new Path(args[1]));    job.setInputFormatClass(AvroKeyInputFormat.class);    job.setMapperClass(ColorCountMapper.class);    AvroJob.setInputKeySchema(job, User.getClassSchema());    job.setMapOutputKeyClass(Text.class);    job.setMapOutputValueClass(IntWritable.class);    job.setOutputFormatClass(AvroKeyValueOutputFormat.class);    job.setReducerClass(ColorCountReducer.class);    AvroJob.setOutputKeySchema(job, Schema.create(Schema.Type.STRING));    AvroJob.setOutputValueSchema(job, Schema.create(Schema.Type.INT));    return (job.waitForCompletion(true) ? 0 : 1);}
0
public static void main(String[] args) throws Exception
{    int res = ToolRunner.run(new MapReduceColorCount(), args);    System.exit(res);}
0
public void addParentField(Field field)
{    chainOfFields.add(field);}
0
public String toString()
{    StringBuilder result = new StringBuilder();    for (Field field : chainOfFields) {        result.insert(0, " --> " + field.name());    }    return "Path in schema:" + result;}
0
public Object getValue()
{    return value;}
0
public String adjustAndSetValue(String varName, String valParamName)
{    return varName + " = " + valParamName + ";";}
0
public Schema getRecommendedSchema()
{    throw new UnsupportedOperationException("No recommended schema for " + getLogicalTypeName());}
0
public T fromBoolean(Boolean value, Schema schema, LogicalType type)
{    throw new UnsupportedOperationException("fromBoolean is not supported for " + type.getName());}
0
public T fromInt(Integer value, Schema schema, LogicalType type)
{    throw new UnsupportedOperationException("fromInt is not supported for " + type.getName());}
0
public T fromLong(Long value, Schema schema, LogicalType type)
{    throw new UnsupportedOperationException("fromLong is not supported for " + type.getName());}
0
public T fromFloat(Float value, Schema schema, LogicalType type)
{    throw new UnsupportedOperationException("fromFloat is not supported for " + type.getName());}
0
public T fromDouble(Double value, Schema schema, LogicalType type)
{    throw new UnsupportedOperationException("fromDouble is not supported for " + type.getName());}
0
public T fromCharSequence(CharSequence value, Schema schema, LogicalType type)
{    throw new UnsupportedOperationException("fromCharSequence is not supported for " + type.getName());}
0
public T fromEnumSymbol(GenericEnumSymbol value, Schema schema, LogicalType type)
{    throw new UnsupportedOperationException("fromEnumSymbol is not supported for " + type.getName());}
0
public T fromFixed(GenericFixed value, Schema schema, LogicalType type)
{    throw new UnsupportedOperationException("fromFixed is not supported for " + type.getName());}
0
public T fromBytes(ByteBuffer value, Schema schema, LogicalType type)
{    throw new UnsupportedOperationException("fromBytes is not supported for " + type.getName());}
0
public T fromArray(Collection<?> value, Schema schema, LogicalType type)
{    throw new UnsupportedOperationException("fromArray is not supported for " + type.getName());}
0
public T fromMap(Map<?, ?> value, Schema schema, LogicalType type)
{    throw new UnsupportedOperationException("fromMap is not supported for " + type.getName());}
0
public T fromRecord(IndexedRecord value, Schema schema, LogicalType type)
{    throw new UnsupportedOperationException("fromRecord is not supported for " + type.getName());}
0
public Boolean toBoolean(T value, Schema schema, LogicalType type)
{    throw new UnsupportedOperationException("toBoolean is not supported for " + type.getName());}
0
public Integer toInt(T value, Schema schema, LogicalType type)
{    throw new UnsupportedOperationException("toInt is not supported for " + type.getName());}
0
public Long toLong(T value, Schema schema, LogicalType type)
{    throw new UnsupportedOperationException("toLong is not supported for " + type.getName());}
0
public Float toFloat(T value, Schema schema, LogicalType type)
{    throw new UnsupportedOperationException("toFloat is not supported for " + type.getName());}
0
public Double toDouble(T value, Schema schema, LogicalType type)
{    throw new UnsupportedOperationException("toDouble is not supported for " + type.getName());}
0
public CharSequence toCharSequence(T value, Schema schema, LogicalType type)
{    throw new UnsupportedOperationException("toCharSequence is not supported for " + type.getName());}
0
public GenericEnumSymbol toEnumSymbol(T value, Schema schema, LogicalType type)
{    throw new UnsupportedOperationException("toEnumSymbol is not supported for " + type.getName());}
0
public GenericFixed toFixed(T value, Schema schema, LogicalType type)
{    throw new UnsupportedOperationException("toFixed is not supported for " + type.getName());}
0
public ByteBuffer toBytes(T value, Schema schema, LogicalType type)
{    throw new UnsupportedOperationException("toBytes is not supported for " + type.getName());}
0
public Collection<?> toArray(T value, Schema schema, LogicalType type)
{    throw new UnsupportedOperationException("toArray is not supported for " + type.getName());}
0
public Map<?, ?> toMap(T value, Schema schema, LogicalType type)
{    throw new UnsupportedOperationException("toMap is not supported for " + type.getName());}
0
public IndexedRecord toRecord(T value, Schema schema, LogicalType type)
{    throw new UnsupportedOperationException("toRecord is not supported for " + type.getName());}
0
public Class<UUID> getConvertedType()
{    return UUID.class;}
0
public Schema getRecommendedSchema()
{    return LogicalTypes.uuid().addToSchema(Schema.create(Schema.Type.STRING));}
0
public String getLogicalTypeName()
{    return "uuid";}
0
public UUID fromCharSequence(CharSequence value, Schema schema, LogicalType type)
{    return UUID.fromString(value.toString());}
0
public CharSequence toCharSequence(UUID value, Schema schema, LogicalType type)
{    return value.toString();}
0
public Class<BigDecimal> getConvertedType()
{    return BigDecimal.class;}
0
public Schema getRecommendedSchema()
{    throw new UnsupportedOperationException("No recommended schema for decimal (scale is required)");}
0
public String getLogicalTypeName()
{    return "decimal";}
0
public BigDecimal fromBytes(ByteBuffer value, Schema schema, LogicalType type)
{    int scale = ((LogicalTypes.Decimal) type).getScale();        byte[] bytes = new byte[value.remaining()];    value.get(bytes);    return new BigDecimal(new BigInteger(bytes), scale);}
0
public ByteBuffer toBytes(BigDecimal value, Schema schema, LogicalType type)
{    int scale = ((LogicalTypes.Decimal) type).getScale();    if (scale != value.scale()) {        throw new AvroTypeException("Cannot encode decimal with scale " + value.scale() + " as scale " + scale);    }    return ByteBuffer.wrap(value.unscaledValue().toByteArray());}
0
public BigDecimal fromFixed(GenericFixed value, Schema schema, LogicalType type)
{    int scale = ((LogicalTypes.Decimal) type).getScale();    return new BigDecimal(new BigInteger(value.bytes()), scale);}
0
public GenericFixed toFixed(BigDecimal value, Schema schema, LogicalType type)
{    int scale = ((LogicalTypes.Decimal) type).getScale();    if (scale != value.scale()) {        throw new AvroTypeException("Cannot encode decimal with scale " + value.scale() + " as scale " + scale);    }    byte fillByte = (byte) (value.signum() < 0 ? 0xFF : 0x00);    byte[] unscaled = value.unscaledValue().toByteArray();    byte[] bytes = new byte[schema.getFixedSize()];    int offset = bytes.length - unscaled.length;        Arrays.fill(bytes, 0, offset, fillByte);    System.arraycopy(unscaled, 0, bytes, offset, bytes.length - offset);    return new GenericData.Fixed(schema, bytes);}
0
public static Object convertToLogicalType(Object datum, Schema schema, LogicalType type, Conversion<?> conversion)
{    if (datum == null) {        return null;    }    if (schema == null || type == null || conversion == null) {        throw new IllegalArgumentException("Parameters cannot be null! Parameter values:" + Arrays.deepToString(new Object[] { datum, schema, type, conversion }));    }    try {        switch(schema.getType()) {            case RECORD:                return conversion.fromRecord((IndexedRecord) datum, schema, type);            case ENUM:                return conversion.fromEnumSymbol((GenericEnumSymbol) datum, schema, type);            case ARRAY:                return conversion.fromArray((Collection) datum, schema, type);            case MAP:                return conversion.fromMap((Map<?, ?>) datum, schema, type);            case FIXED:                return conversion.fromFixed((GenericFixed) datum, schema, type);            case STRING:                return conversion.fromCharSequence((CharSequence) datum, schema, type);            case BYTES:                return conversion.fromBytes((ByteBuffer) datum, schema, type);            case INT:                return conversion.fromInt((Integer) datum, schema, type);            case LONG:                return conversion.fromLong((Long) datum, schema, type);            case FLOAT:                return conversion.fromFloat((Float) datum, schema, type);            case DOUBLE:                return conversion.fromDouble((Double) datum, schema, type);            case BOOLEAN:                return conversion.fromBoolean((Boolean) datum, schema, type);        }        return datum;    } catch (ClassCastException e) {        throw new AvroRuntimeException("Cannot convert " + datum + ":" + datum.getClass().getSimpleName() + ": expected generic type", e);    }}
0
public static Object convertToRawType(Object datum, Schema schema, LogicalType type, Conversion<T> conversion)
{    if (datum == null) {        return null;    }    if (schema == null || type == null || conversion == null) {        throw new IllegalArgumentException("Parameters cannot be null! Parameter values:" + Arrays.deepToString(new Object[] { datum, schema, type, conversion }));    }    try {        Class<T> fromClass = conversion.getConvertedType();        switch(schema.getType()) {            case RECORD:                return conversion.toRecord(fromClass.cast(datum), schema, type);            case ENUM:                return conversion.toEnumSymbol(fromClass.cast(datum), schema, type);            case ARRAY:                return conversion.toArray(fromClass.cast(datum), schema, type);            case MAP:                return conversion.toMap(fromClass.cast(datum), schema, type);            case FIXED:                return conversion.toFixed(fromClass.cast(datum), schema, type);            case STRING:                return conversion.toCharSequence(fromClass.cast(datum), schema, type);            case BYTES:                return conversion.toBytes(fromClass.cast(datum), schema, type);            case INT:                return conversion.toInt(fromClass.cast(datum), schema, type);            case LONG:                return conversion.toLong(fromClass.cast(datum), schema, type);            case FLOAT:                return conversion.toFloat(fromClass.cast(datum), schema, type);            case DOUBLE:                return conversion.toDouble(fromClass.cast(datum), schema, type);            case BOOLEAN:                return conversion.toBoolean(fromClass.cast(datum), schema, type);        }        return datum;    } catch (ClassCastException e) {        throw new AvroRuntimeException("Cannot convert " + datum + ":" + datum.getClass().getSimpleName() + ": expected logical type", e);    }}
0
public void setSchema(Schema schema)
{    if (!SCHEMA.equals(schema))        throw new RuntimeException("Not the Json schema: " + schema);}
0
public void write(Object datum, Encoder out) throws IOException
{    Json.writeObject(datum, out);}
0
public void setSchema(Schema schema)
{    this.written = SCHEMA.equals(written) ? null : schema;}
0
public Object read(Object reuse, Decoder in) throws IOException
{    if (    written == null)        return Json.readObject(in);        if (resolver == null)        resolver = DecoderFactory.get().resolvingDecoder(written, SCHEMA, null);    resolver.configure(in);    Object result = Json.readObject(resolver);    resolver.drain();    return result;}
0
public static Object parseJson(String s)
{    try {        return JacksonUtils.toObject(MAPPER.readTree(FACTORY.createParser(s)));    } catch (IOException e) {        throw new RuntimeException(e);    }}
0
public static String toString(Object datum)
{    return JacksonUtils.toJsonNode(datum).toString();}
0
private static void write(JsonNode node, Encoder out) throws IOException
{    switch(node.asToken()) {        case VALUE_NUMBER_INT:            out.writeIndex(JsonType.LONG.ordinal());            out.writeLong(node.longValue());            break;        case VALUE_NUMBER_FLOAT:            out.writeIndex(JsonType.DOUBLE.ordinal());            out.writeDouble(node.doubleValue());            break;        case VALUE_STRING:            out.writeIndex(JsonType.STRING.ordinal());            out.writeString(node.textValue());            break;        case VALUE_TRUE:            out.writeIndex(JsonType.BOOLEAN.ordinal());            out.writeBoolean(true);            break;        case VALUE_FALSE:            out.writeIndex(JsonType.BOOLEAN.ordinal());            out.writeBoolean(false);            break;        case VALUE_NULL:            out.writeIndex(JsonType.NULL.ordinal());            out.writeNull();            break;        case START_ARRAY:            out.writeIndex(JsonType.ARRAY.ordinal());            out.writeArrayStart();            out.setItemCount(node.size());            for (JsonNode element : node) {                out.startItem();                write(element, out);            }            out.writeArrayEnd();            break;        case START_OBJECT:            out.writeIndex(JsonType.OBJECT.ordinal());            out.writeMapStart();            out.setItemCount(node.size());            Iterator<String> i = node.fieldNames();            while (i.hasNext()) {                out.startItem();                String name = i.next();                out.writeString(name);                write(node.get(name), out);            }            out.writeMapEnd();            break;        default:            throw new AvroRuntimeException(node.asToken() + " unexpected: " + node);    }}
0
private static JsonNode read(Decoder in) throws IOException
{    switch(JsonType.values()[in.readIndex()]) {        case LONG:            return new LongNode(in.readLong());        case DOUBLE:            return new DoubleNode(in.readDouble());        case STRING:            return new TextNode(in.readString());        case BOOLEAN:            return in.readBoolean() ? BooleanNode.TRUE : BooleanNode.FALSE;        case NULL:            in.readNull();            return NullNode.getInstance();        case ARRAY:            ArrayNode array = JsonNodeFactory.instance.arrayNode();            for (long l = in.readArrayStart(); l > 0; l = in.arrayNext()) for (long i = 0; i < l; i++) array.add(read(in));            return array;        case OBJECT:            ObjectNode object = JsonNodeFactory.instance.objectNode();            for (long l = in.readMapStart(); l > 0; l = in.mapNext()) for (long i = 0; i < l; i++) object.set(in.readString(), read(in));            return object;        default:            throw new AvroRuntimeException("Unexpected Json node type");    }}
0
private static void writeObject(Object datum, Encoder out) throws IOException
{    write(JacksonUtils.toJsonNode(datum), out);}
0
private static Object readObject(Decoder in) throws IOException
{    return JacksonUtils.toObject(read(in));}
0
protected final Schema schema()
{    return schema;}
0
protected final Field[] fields()
{    return fields;}
0
protected final boolean[] fieldSetFlags()
{    return fieldSetFlags;}
0
protected final GenericData data()
{    return data;}
0
protected void validate(Field field, Object value)
{    if (isValidValue(field, value)) {    } else if (field.defaultVal() != null) {    } else {        throw new AvroRuntimeException("Field " + field + " does not accept null values");    }}
0
protected static boolean isValidValue(Field f, Object value)
{    if (value != null) {        return true;    }    Schema schema = f.schema();    Type type = schema.getType();        if (type == Type.NULL) {        return true;    }        if (type == Type.UNION) {        for (Schema s : schema.getTypes()) {            if (s.getType() == Type.NULL) {                return true;            }        }    }        return false;}
0
protected Object defaultValue(Field field) throws IOException
{    return data.deepCopy(field.schema(), data.getDefaultValue(field));}
0
public int hashCode()
{    final int prime = 31;    int result = 1;    result = prime * result + Arrays.hashCode(fieldSetFlags);    result = prime * result + ((schema == null) ? 0 : schema.hashCode());    return result;}
0
public boolean equals(Object obj)
{    if (this == obj)        return true;    if (obj == null)        return false;    if (getClass() != obj.getClass())        return false;    @SuppressWarnings("rawtypes")    RecordBuilderBase other = (RecordBuilderBase) obj;    if (!Arrays.equals(fieldSetFlags, other.fieldSetFlags))        return false;    if (schema == null) {        return other.schema == null;    } else {        return schema.equals(other.schema);    }}
0
public Class<LocalDate> getConvertedType()
{    return LocalDate.class;}
0
public String getLogicalTypeName()
{    return "date";}
0
public LocalDate fromInt(Integer daysFromEpoch, Schema schema, LogicalType type)
{    return LocalDate.ofEpochDay(daysFromEpoch);}
0
public Integer toInt(LocalDate date, Schema schema, LogicalType type)
{    long epochDays = date.toEpochDay();    return (int) epochDays;}
0
public Schema getRecommendedSchema()
{    return LogicalTypes.date().addToSchema(Schema.create(Schema.Type.INT));}
0
public Class<LocalTime> getConvertedType()
{    return LocalTime.class;}
0
public String getLogicalTypeName()
{    return "time-millis";}
0
public String adjustAndSetValue(String varName, String valParamName)
{    return varName + " = " + valParamName + ".truncatedTo(java.time.temporal.ChronoUnit.MILLIS);";}
0
public LocalTime fromInt(Integer millisFromMidnight, Schema schema, LogicalType type)
{    return LocalTime.ofNanoOfDay(TimeUnit.MILLISECONDS.toNanos(millisFromMidnight));}
0
public Integer toInt(LocalTime time, Schema schema, LogicalType type)
{    return (int) TimeUnit.NANOSECONDS.toMillis(time.toNanoOfDay());}
0
public Schema getRecommendedSchema()
{    return LogicalTypes.timeMillis().addToSchema(Schema.create(Schema.Type.INT));}
0
public Class<LocalTime> getConvertedType()
{    return LocalTime.class;}
0
public String getLogicalTypeName()
{    return "time-micros";}
0
public String adjustAndSetValue(String varName, String valParamName)
{    return varName + " = " + valParamName + ".truncatedTo(java.time.temporal.ChronoUnit.MICROS);";}
0
public LocalTime fromLong(Long microsFromMidnight, Schema schema, LogicalType type)
{    return LocalTime.ofNanoOfDay(TimeUnit.MICROSECONDS.toNanos(microsFromMidnight));}
0
public Long toLong(LocalTime time, Schema schema, LogicalType type)
{    return TimeUnit.NANOSECONDS.toMicros(time.toNanoOfDay());}
0
public Schema getRecommendedSchema()
{    return LogicalTypes.timeMicros().addToSchema(Schema.create(Schema.Type.LONG));}
0
public Class<Instant> getConvertedType()
{    return Instant.class;}
0
public String getLogicalTypeName()
{    return "timestamp-millis";}
0
public String adjustAndSetValue(String varName, String valParamName)
{    return varName + " = " + valParamName + ".truncatedTo(java.time.temporal.ChronoUnit.MILLIS);";}
0
public Instant fromLong(Long millisFromEpoch, Schema schema, LogicalType type)
{    return Instant.ofEpochMilli(millisFromEpoch);}
0
public Long toLong(Instant timestamp, Schema schema, LogicalType type)
{    return timestamp.toEpochMilli();}
0
public Schema getRecommendedSchema()
{    return LogicalTypes.timestampMillis().addToSchema(Schema.create(Schema.Type.LONG));}
0
public Class<Instant> getConvertedType()
{    return Instant.class;}
0
public String getLogicalTypeName()
{    return "timestamp-micros";}
0
public String adjustAndSetValue(String varName, String valParamName)
{    return varName + " = " + valParamName + ".truncatedTo(java.time.temporal.ChronoUnit.MICROS);";}
0
public Instant fromLong(Long microsFromEpoch, Schema schema, LogicalType type)
{    long epochSeconds = microsFromEpoch / (1_000_000);    long nanoAdjustment = (microsFromEpoch % (1_000_000)) * 1_000;    return Instant.ofEpochSecond(epochSeconds, nanoAdjustment);}
0
public Long toLong(Instant instant, Schema schema, LogicalType type)
{    long seconds = instant.getEpochSecond();    int nanos = instant.getNano();    if (seconds < 0 && nanos > 0) {        long micros = Math.multiplyExact(seconds + 1, 1_000_000);        long adjustment = (nanos / 1_000L) - 1_000_000;        return Math.addExact(micros, adjustment);    } else {        long micros = Math.multiplyExact(seconds, 1_000_000);        return Math.addExact(micros, nanos / 1_000);    }}
0
public Schema getRecommendedSchema()
{    return LogicalTypes.timestampMicros().addToSchema(Schema.create(Schema.Type.LONG));}
0
public Class<LocalDateTime> getConvertedType()
{    return LocalDateTime.class;}
0
public String getLogicalTypeName()
{    return "local-timestamp-millis";}
0
public LocalDateTime fromLong(Long millisFromEpoch, Schema schema, LogicalType type)
{    Instant instant = timestampMillisConversion.fromLong(millisFromEpoch, schema, type);    return LocalDateTime.ofInstant(instant, ZoneOffset.UTC);}
0
public Long toLong(LocalDateTime timestamp, Schema schema, LogicalType type)
{    Instant instant = timestamp.toInstant(ZoneOffset.UTC);    return timestampMillisConversion.toLong(instant, schema, type);}
0
public Schema getRecommendedSchema()
{    return LogicalTypes.localTimestampMillis().addToSchema(Schema.create(Schema.Type.LONG));}
0
public Class<LocalDateTime> getConvertedType()
{    return LocalDateTime.class;}
0
public String getLogicalTypeName()
{    return "local-timestamp-micros";}
0
public LocalDateTime fromLong(Long microsFromEpoch, Schema schema, LogicalType type)
{    Instant instant = timestampMicrosConversion.fromLong(microsFromEpoch, schema, type);    return LocalDateTime.ofInstant(instant, ZoneOffset.UTC);}
0
public Long toLong(LocalDateTime timestamp, Schema schema, LogicalType type)
{    Instant instant = timestamp.toInstant(ZoneOffset.UTC);    return timestampMicrosConversion.toLong(instant, schema, type);}
0
public Schema getRecommendedSchema()
{    return LogicalTypes.localTimestampMicros().addToSchema(Schema.create(Schema.Type.LONG));}
0
protected Codec createInstance()
{    return new BZip2Codec();}
0
public String getName()
{    return DataFileConstants.BZIP2_CODEC;}
0
public ByteBuffer compress(ByteBuffer uncompressedData) throws IOException
{    ByteArrayOutputStream baos = getOutputBuffer(uncompressedData.remaining());    try (BZip2CompressorOutputStream outputStream = new BZip2CompressorOutputStream(baos)) {        outputStream.write(uncompressedData.array(), computeOffset(uncompressedData), uncompressedData.remaining());    }    return ByteBuffer.wrap(baos.toByteArray());}
0
public ByteBuffer decompress(ByteBuffer compressedData) throws IOException
{    ByteArrayInputStream bais = new ByteArrayInputStream(compressedData.array(), computeOffset(compressedData), compressedData.remaining());    try (BZip2CompressorInputStream inputStream = new BZip2CompressorInputStream(bais)) {        ByteArrayOutputStream baos = new ByteArrayOutputStream();        int readCount = -1;        while ((readCount = inputStream.read(buffer, compressedData.position(), buffer.length)) > 0) {            baos.write(buffer, 0, readCount);        }        return ByteBuffer.wrap(baos.toByteArray());    }}
0
public int hashCode()
{    return getName().hashCode();}
0
public boolean equals(Object obj)
{    if (this == obj)        return true;    return obj != null && obj.getClass() == getClass();}
0
private ByteArrayOutputStream getOutputBuffer(int suggestedLength)
{    if (null == outputBuffer) {        outputBuffer = new ByteArrayOutputStream(suggestedLength);    }    outputBuffer.reset();    return outputBuffer;}
0
public String toString()
{    return getName();}
0
protected static int computeOffset(ByteBuffer data)
{    return data.arrayOffset() + data.position();}
0
public static CodecFactory nullCodec()
{    return NullCodec.OPTION;}
0
public static CodecFactory deflateCodec(int compressionLevel)
{    return new DeflateCodec.Option(compressionLevel);}
0
public static CodecFactory xzCodec(int compressionLevel)
{    return new XZCodec.Option(compressionLevel);}
0
public static CodecFactory snappyCodec()
{    try {        return new SnappyCodec.Option();    } catch (Throwable t) {                return null;    }}
1
public static CodecFactory bzip2Codec()
{    return new BZip2Codec.Option();}
0
public static CodecFactory zstandardCodec(int level)
{    return new ZstandardCodec.Option(level, false);}
0
public static CodecFactory zstandardCodec(int level, boolean useChecksum)
{    return new ZstandardCodec.Option(level, useChecksum);}
0
public static CodecFactory fromString(String s)
{    CodecFactory o = REGISTERED.get(s);    if (o == null) {        throw new AvroRuntimeException("Unrecognized codec: " + s);    }    return o;}
0
public static CodecFactory addCodec(String name, CodecFactory c)
{    if (c != null) {        return REGISTERED.put(name, c);    }    return null;}
0
public String toString()
{    Codec instance = this.createInstance();    return instance.toString();}
0
public static FileReader<D> openReader(File file, DatumReader<D> reader) throws IOException
{    SeekableFileInput input = new SeekableFileInput(file);    try {        return openReader(input, reader);    } catch (final Throwable e) {        IOUtils.closeQuietly(input);        throw e;    }}
0
public static FileReader<D> openReader(SeekableInput in, DatumReader<D> reader) throws IOException
{    if (in.length() < MAGIC.length)        throw new InvalidAvroMagicException("Not an Avro data file");        byte[] magic = new byte[MAGIC.length];    in.seek(0);    for (int c = 0; c < magic.length; c = in.read(magic, c, magic.length - c)) {    }    in.seek(0);    if (    Arrays.equals(MAGIC, magic))        return new DataFileReader<>(in, reader);    if (    Arrays.equals(DataFileReader12.MAGIC, magic))        return new DataFileReader12<>(in, reader);    throw new InvalidAvroMagicException("Not an Avro data file");}
0
public static DataFileReader<D> openReader(SeekableInput in, DatumReader<D> reader, Header header, boolean sync) throws IOException
{    DataFileReader<D> dreader = new DataFileReader<>(in, reader, header);        if (sync)        dreader.sync(in.tell());    else        dreader.seek(in.tell());    return dreader;}
0
public void seek(long position) throws IOException
{    sin.seek(position);    vin = DecoderFactory.get().binaryDecoder(this.sin, vin);    datumIn = null;    blockRemaining = 0;    blockStart = position;}
0
public void sync(long position) throws IOException
{    seek(position);        if ((position == 0) && (getMeta("avro.sync") != null)) {                initialize(sin);        return;    }    try {        int i = 0, b;        InputStream in = vin.inputStream();        vin.readFixed(syncBuffer);        do {            int j = 0;            for (; j < SYNC_SIZE; j++) {                if (getHeader().sync[j] != syncBuffer[(i + j) % SYNC_SIZE])                    break;            }            if (j == SYNC_SIZE) {                                blockStart = position + i + SYNC_SIZE;                return;            }            b = in.read();            syncBuffer[i++ % SYNC_SIZE] = (byte) b;        } while (b != -1);    } catch (EOFException e) {        }        blockStart = sin.tell();}
0
protected void blockFinished() throws IOException
{    blockStart = sin.tell() - vin.inputStream().available();}
0
public long previousSync()
{    return blockStart;}
0
public boolean pastSync(long position) throws IOException
{    return ((blockStart >= position + SYNC_SIZE) || (blockStart >= sin.length()));}
0
public long tell() throws IOException
{    return sin.tell();}
0
public void seek(long p) throws IOException
{    if (p < 0)        throw new IOException("Illegal seek: " + p);    in.seek(p);}
0
public long tell() throws IOException
{    return in.tell();}
0
public long length() throws IOException
{    return in.length();}
0
public int read(byte[] b) throws IOException
{    return in.read(b, 0, b.length);}
0
public int read(byte[] b, int off, int len) throws IOException
{    return in.read(b, off, len);}
0
public int read() throws IOException
{    int n = read(oneByte, 0, 1);    if (n == 1) {        return oneByte[0] & 0xff;    } else {        return n;    }}
0
public long skip(long skip) throws IOException
{    long position = in.tell();    long length = in.length();    long remaining = length - position;    if (remaining > skip) {        in.seek(skip);        return in.tell() - position;    } else {        in.seek(remaining);        return in.tell() - position;    }}
0
public void close() throws IOException
{    in.close();    super.close();}
0
public int available() throws IOException
{    long remaining = (in.length() - in.tell());    return (remaining > Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int) remaining;}
0
public synchronized byte[] getMeta(String key)
{    return meta.get(key);}
0
public synchronized String getMetaString(String key)
{    byte[] value = getMeta(key);    if (value == null) {        return null;    }    return new String(value, StandardCharsets.UTF_8);}
0
public synchronized long getMetaLong(String key)
{    return Long.parseLong(getMetaString(key));}
0
public Schema getSchema()
{    return schema;}
0
public Iterator<D> iterator()
{    return this;}
0
public boolean hasNext()
{    if (peek != null || blockCount != 0)        return true;    this.peek = next();    return peek != null;}
0
public D next()
{    if (peek != null) {        D result = peek;        peek = null;        return result;    }    try {        return next(null);    } catch (IOException e) {        throw new RuntimeException(e);    }}
0
public void remove()
{    throw new UnsupportedOperationException();}
0
public synchronized D next(D reuse) throws IOException
{    while (blockCount == 0) {        if (        in.tell() == in.length())            return null;                skipSync();                blockCount = vin.readLong();        if (blockCount == FOOTER_BLOCK) {                        seek(vin.readLong() + in.tell());        }    }    blockCount--;    return reader.read(reuse, vin);}
0
private void skipSync() throws IOException
{    vin.readFixed(syncBuffer);    if (!Arrays.equals(syncBuffer, sync))        throw new IOException("Invalid sync!");}
0
public synchronized void seek(long position) throws IOException
{    in.seek(position);    blockCount = 0;    blockStart = position;    vin = DecoderFactory.get().binaryDecoder(in, vin);}
0
public synchronized void sync(long position) throws IOException
{    if (in.tell() + SYNC_SIZE >= in.length()) {        seek(in.length());        return;    }    in.seek(position);    vin.readFixed(syncBuffer);    for (int i = 0; in.tell() < in.length(); i++) {        int j = 0;        for (; j < sync.length; j++) {            if (sync[j] != syncBuffer[(i + j) % sync.length])                break;        }        if (j == sync.length) {                        seek(in.tell() - SYNC_SIZE);            return;        }        syncBuffer[i % sync.length] = (byte) in.read();    }    seek(in.length());}
0
public boolean pastSync(long position) throws IOException
{    return ((blockStart >= position + SYNC_SIZE) || (blockStart >= in.length()));}
0
public long tell() throws IOException
{    return in.tell();}
0
public synchronized void close() throws IOException
{    in.close();}
0
 void initialize(InputStream in) throws IOException
{    this.header = new Header();    this.vin = DecoderFactory.get().binaryDecoder(in, vin);    byte[] magic = new byte[DataFileConstants.MAGIC.length];    try {                vin.readFixed(magic);    } catch (IOException e) {        throw new IOException("Not an Avro data file.", e);    }    if (!Arrays.equals(DataFileConstants.MAGIC, magic))        throw new InvalidAvroMagicException("Not an Avro data file.");        long l = vin.readMapStart();    if (l > 0) {        do {            for (long i = 0; i < l; i++) {                String key = vin.readString(null).toString();                ByteBuffer value = vin.readBytes(null);                byte[] bb = new byte[value.remaining()];                value.get(bb);                header.meta.put(key, bb);                header.metaKeyList.add(key);            }        } while ((l = vin.mapNext()) != 0);    }        vin.readFixed(header.sync);        header.metaKeyList = Collections.unmodifiableList(header.metaKeyList);    header.schema = new Schema.Parser().setValidate(false).parse(getMetaString(DataFileConstants.SCHEMA));    this.codec = resolveCodec();    reader.setSchema(header.schema);}
0
 void initialize(InputStream in, Header header) throws IOException
{    this.header = header;    this.codec = resolveCodec();    reader.setSchema(header.schema);}
0
 Codec resolveCodec()
{    String codecStr = getMetaString(DataFileConstants.CODEC);    if (codecStr != null) {        return CodecFactory.fromString(codecStr).createInstance();    } else {        return CodecFactory.nullCodec().createInstance();    }}
0
public Header getHeader()
{    return header;}
0
public Schema getSchema()
{    return header.schema;}
0
public List<String> getMetaKeys()
{    return header.metaKeyList;}
0
public byte[] getMeta(String key)
{    return header.meta.get(key);}
0
public String getMetaString(String key)
{    byte[] value = getMeta(key);    if (value == null) {        return null;    }    return new String(value, StandardCharsets.UTF_8);}
0
public long getMetaLong(String key)
{    return Long.parseLong(getMetaString(key));}
0
public Iterator<D> iterator()
{    return this;}
0
public boolean hasNext()
{    try {        if (blockRemaining == 0) {                        if (null != datumIn) {                boolean atEnd = datumIn.isEnd();                if (!atEnd) {                    throw new IOException("Block read partially, the data may be corrupt");                }            }            if (hasNextBlock()) {                block = nextRawBlock(block);                block.decompressUsing(codec);                blockBuffer = block.getAsByteBuffer();                datumIn = DecoderFactory.get().binaryDecoder(blockBuffer.array(), blockBuffer.arrayOffset() + blockBuffer.position(), blockBuffer.remaining(), datumIn);            }        }        return blockRemaining != 0;    } catch (EOFException e) {                return false;    } catch (IOException e) {        throw new AvroRuntimeException(e);    }}
0
public D next()
{    try {        return next(null);    } catch (IOException e) {        throw new AvroRuntimeException(e);    }}
0
public D next(D reuse) throws IOException
{    if (!hasNext())        throw new NoSuchElementException();    D result = reader.read(reuse, datumIn);    if (0 == --blockRemaining) {        blockFinished();    }    return result;}
0
public ByteBuffer nextBlock() throws IOException
{    if (!hasNext())        throw new NoSuchElementException();    if (blockRemaining != blockCount)        throw new IllegalStateException("Not at block start.");    blockRemaining = 0;    datumIn = null;    return blockBuffer;}
0
public long getBlockCount()
{    return blockCount;}
0
public long getBlockSize()
{    return blockSize;}
0
protected void blockFinished() throws IOException
{}
0
 boolean hasNextBlock()
{    try {        if (availableBlock)            return true;        if (vin.isEnd())            return false;                blockRemaining = vin.readLong();                blockSize = vin.readLong();        if (blockSize > Integer.MAX_VALUE || blockSize < 0) {            throw new IOException("Block size invalid or too large for this " + "implementation: " + blockSize);        }        blockCount = blockRemaining;        availableBlock = true;        return true;    } catch (EOFException eof) {        return false;    } catch (IOException e) {        throw new AvroRuntimeException(e);    }}
0
 DataBlock nextRawBlock(DataBlock reuse) throws IOException
{    if (!hasNextBlock()) {        throw new NoSuchElementException();    }    if (reuse == null || reuse.data.length < (int) blockSize) {        reuse = new DataBlock(blockRemaining, (int) blockSize);    } else {        reuse.numEntries = blockRemaining;        reuse.blockSize = (int) blockSize;    }        vin.readFixed(reuse.data, 0, reuse.blockSize);    vin.readFixed(syncBuffer);    availableBlock = false;    if (!Arrays.equals(syncBuffer, header.sync))        throw new IOException("Invalid sync!");    return reuse;}
0
public void remove()
{    throw new UnsupportedOperationException();}
0
public void close() throws IOException
{    vin.inputStream().close();}
0
 byte[] getData()
{    return data;}
0
 long getNumEntries()
{    return numEntries;}
0
 int getBlockSize()
{    return blockSize;}
0
 boolean isFlushOnWrite()
{    return flushOnWrite;}
0
 void setFlushOnWrite(boolean flushOnWrite)
{    this.flushOnWrite = flushOnWrite;}
0
 ByteBuffer getAsByteBuffer()
{    return ByteBuffer.wrap(data, offset, blockSize);}
0
 void decompressUsing(Codec c) throws IOException
{    ByteBuffer result = c.decompress(getAsByteBuffer());    data = result.array();    blockSize = result.remaining();}
0
 void compressUsing(Codec c) throws IOException
{    ByteBuffer result = c.compress(getAsByteBuffer());    data = result.array();    blockSize = result.remaining();}
0
 void writeBlockTo(BinaryEncoder e, byte[] sync) throws IOException
{    e.writeLong(this.numEntries);    e.writeLong(this.blockSize);    e.writeFixed(this.data, offset, this.blockSize);    e.writeFixed(sync);    if (flushOnWrite) {        e.flush();    }}
0
private void assertOpen()
{    if (!isOpen)        throw new AvroRuntimeException("not open");}
0
private void assertNotOpen()
{    if (isOpen)        throw new AvroRuntimeException("already open");}
0
public DataFileWriter<D> setCodec(CodecFactory c)
{    assertNotOpen();    this.codec = c.createInstance();    setMetaInternal(DataFileConstants.CODEC, codec.getName());    return this;}
0
public DataFileWriter<D> setSyncInterval(int syncInterval)
{    if (syncInterval < 32 || syncInterval > (1 << 30)) {        throw new IllegalArgumentException("Invalid syncInterval value: " + syncInterval);    }    this.syncInterval = syncInterval;    return this;}
0
public DataFileWriter<D> create(Schema schema, File file) throws IOException
{    SyncableFileOutputStream sfos = new SyncableFileOutputStream(file);    try {        return create(schema, sfos, null);    } catch (final Throwable e) {        IOUtils.closeQuietly(sfos);        throw e;    }}
0
public DataFileWriter<D> create(Schema schema, OutputStream outs) throws IOException
{    return create(schema, outs, null);}
0
public DataFileWriter<D> create(Schema schema, OutputStream outs, byte[] sync) throws IOException
{    assertNotOpen();    this.schema = schema;    setMetaInternal(DataFileConstants.SCHEMA, schema.toString());    if (sync == null) {        this.sync = generateSync();    } else if (sync.length == 16) {        this.sync = sync;    } else {        throw new IOException("sync must be exactly 16 bytes");    }    init(outs);        vout.writeFixed(DataFileConstants.MAGIC);        vout.writeMapStart();    vout.setItemCount(meta.size());    for (Map.Entry<String, byte[]> entry : meta.entrySet()) {        vout.startItem();        vout.writeString(entry.getKey());        vout.writeBytes(entry.getValue());    }    vout.writeMapEnd();        vout.writeFixed(this.sync);        vout.flush();    return this;}
0
public void setFlushOnEveryBlock(boolean flushOnEveryBlock)
{    this.flushOnEveryBlock = flushOnEveryBlock;}
0
public boolean isFlushOnEveryBlock()
{    return this.flushOnEveryBlock;}
0
public DataFileWriter<D> appendTo(File file) throws IOException
{    try (SeekableInput input = new SeekableFileInput(file)) {        OutputStream output = new SyncableFileOutputStream(file, true);        return appendTo(input, output);    }}
0
public DataFileWriter<D> appendTo(SeekableInput in, OutputStream out) throws IOException
{    assertNotOpen();    DataFileReader<D> reader = new DataFileReader<>(in, new GenericDatumReader<>());    this.schema = reader.getSchema();    this.sync = reader.getHeader().sync;    this.meta.putAll(reader.getHeader().meta);    byte[] codecBytes = this.meta.get(DataFileConstants.CODEC);    if (codecBytes != null) {        String strCodec = new String(codecBytes, StandardCharsets.UTF_8);        this.codec = CodecFactory.fromString(strCodec).createInstance();    } else {        this.codec = CodecFactory.nullCodec().createInstance();    }    init(out);    return this;}
0
private void init(OutputStream outs) throws IOException
{    this.underlyingStream = outs;    this.out = new BufferedFileOutputStream(outs);    EncoderFactory efactory = new EncoderFactory();    this.vout = efactory.binaryEncoder(out, null);    dout.setSchema(schema);    buffer = new NonCopyingByteArrayOutputStream(Math.min((int) (syncInterval * 1.25), Integer.MAX_VALUE / 2 - 1));    this.bufOut = efactory.binaryEncoder(buffer, null);    if (this.codec == null) {        this.codec = CodecFactory.nullCodec().createInstance();    }    this.isOpen = true;}
0
private static byte[] generateSync()
{    try {        MessageDigest digester = MessageDigest.getInstance("MD5");        long time = System.currentTimeMillis();        digester.update((UUID.randomUUID() + "@" + time).getBytes(UTF_8));        return digester.digest();    } catch (NoSuchAlgorithmException e) {        throw new RuntimeException(e);    }}
0
private DataFileWriter<D> setMetaInternal(String key, byte[] value)
{    assertNotOpen();    meta.put(key, value);    return this;}
0
private DataFileWriter<D> setMetaInternal(String key, String value)
{    return setMetaInternal(key, value.getBytes(UTF_8));}
0
public DataFileWriter<D> setMeta(String key, byte[] value)
{    if (isReservedMeta(key)) {        throw new AvroRuntimeException("Cannot set reserved meta key: " + key);    }    return setMetaInternal(key, value);}
0
public static boolean isReservedMeta(String key)
{    return key.startsWith("avro.");}
0
public DataFileWriter<D> setMeta(String key, String value)
{    return setMeta(key, value.getBytes(UTF_8));}
0
public DataFileWriter<D> setMeta(String key, long value)
{    return setMeta(key, Long.toString(value));}
0
public void append(D datum) throws IOException
{    assertOpen();    int usedBuffer = bufferInUse();    try {        dout.write(datum, bufOut);    } catch (IOException | RuntimeException e) {        resetBufferTo(usedBuffer);        throw new AppendWriteException(e);    }    blockCount++;    writeIfBlockFull();}
0
private void resetBufferTo(int size) throws IOException
{    bufOut.flush();    byte[] data = buffer.toByteArray();    buffer.reset();    buffer.write(data, 0, size);}
0
public void appendEncoded(ByteBuffer datum) throws IOException
{    assertOpen();    bufOut.writeFixed(datum);    blockCount++;    writeIfBlockFull();}
0
private int bufferInUse()
{    return (buffer.size() + bufOut.bytesBuffered());}
0
private void writeIfBlockFull() throws IOException
{    if (bufferInUse() >= syncInterval)        writeBlock();}
0
public void appendAllFrom(DataFileStream<D> otherFile, boolean recompress) throws IOException
{    assertOpen();        Schema otherSchema = otherFile.getSchema();    if (!this.schema.equals(otherSchema)) {        throw new IOException("Schema from file " + otherFile + " does not match");    }        writeBlock();    Codec otherCodec = otherFile.resolveCodec();    DataBlock nextBlockRaw = null;    if (codec.equals(otherCodec) && !recompress) {                while (otherFile.hasNextBlock()) {            nextBlockRaw = otherFile.nextRawBlock(nextBlockRaw);            nextBlockRaw.writeBlockTo(vout, sync);        }    } else {        while (otherFile.hasNextBlock()) {            nextBlockRaw = otherFile.nextRawBlock(nextBlockRaw);            nextBlockRaw.decompressUsing(otherCodec);            nextBlockRaw.compressUsing(codec);            nextBlockRaw.writeBlockTo(vout, sync);        }    }}
0
private void writeBlock() throws IOException
{    if (blockCount > 0) {        try {            bufOut.flush();            ByteBuffer uncompressed = buffer.getByteArrayAsByteBuffer();            DataBlock block = new DataBlock(uncompressed, blockCount);            block.setFlushOnWrite(flushOnEveryBlock);            block.compressUsing(codec);            block.writeBlockTo(vout, sync);        } finally {            buffer.reset();            blockCount = 0;        }    }}
0
public long sync() throws IOException
{    assertOpen();    writeBlock();    return out.tell();}
0
public void flush() throws IOException
{    sync();    vout.flush();}
0
public void fSync() throws IOException
{    flush();    if (underlyingStream instanceof Syncable) {        ((Syncable) underlyingStream).sync();    }}
0
public void close() throws IOException
{    if (isOpen) {        flush();        out.close();        isOpen = false;    }}
0
public void write(byte[] b, int off, int len) throws IOException
{    out.write(b, off, len);        position += len;}
0
public long tell()
{    return position + count;}
0
public synchronized void flush() throws IOException
{    try {        super.flush();    } finally {                                count = 0;    }}
0
 ByteBuffer getByteArrayAsByteBuffer()
{    return ByteBuffer.wrap(buf, 0, count);}
0
protected Codec createInstance()
{    return new DeflateCodec(compressionLevel);}
0
public String getName()
{    return DataFileConstants.DEFLATE_CODEC;}
0
public ByteBuffer compress(ByteBuffer data) throws IOException
{    ByteArrayOutputStream baos = getOutputBuffer(data.remaining());    try (OutputStream outputStream = new DeflaterOutputStream(baos, getDeflater())) {        outputStream.write(data.array(), computeOffset(data), data.remaining());    }    return ByteBuffer.wrap(baos.toByteArray());}
0
public ByteBuffer decompress(ByteBuffer data) throws IOException
{    ByteArrayOutputStream baos = getOutputBuffer(data.remaining());    try (OutputStream outputStream = new InflaterOutputStream(baos, getInflater())) {        outputStream.write(data.array(), computeOffset(data), data.remaining());    }    return ByteBuffer.wrap(baos.toByteArray());}
0
private Inflater getInflater()
{    if (null == inflater) {        inflater = new Inflater(nowrap);    }    inflater.reset();    return inflater;}
0
private Deflater getDeflater()
{    if (null == deflater) {        deflater = new Deflater(compressionLevel, nowrap);    }    deflater.reset();    return deflater;}
0
private ByteArrayOutputStream getOutputBuffer(int suggestedLength)
{    if (null == outputBuffer) {        outputBuffer = new ByteArrayOutputStream(suggestedLength);    }    outputBuffer.reset();    return outputBuffer;}
0
public int hashCode()
{    return nowrap ? 0 : 1;}
0
public boolean equals(Object obj)
{    if (this == obj)        return true;    if (obj == null || obj.getClass() != getClass())        return false;    DeflateCodec other = (DeflateCodec) obj;    return (this.nowrap == other.nowrap);}
0
public String toString()
{    return getName() + "-" + compressionLevel;}
0
protected Codec createInstance()
{    return INSTANCE;}
0
public String getName()
{    return DataFileConstants.NULL_CODEC;}
0
public ByteBuffer compress(ByteBuffer buffer) throws IOException
{    return buffer;}
0
public ByteBuffer decompress(ByteBuffer data) throws IOException
{    return data;}
0
public boolean equals(Object other)
{    if (this == other)        return true;    return (other != null && other.getClass() == getClass());}
0
public int hashCode()
{    return 2;}
0
public long length() throws IOException
{    return this.count;}
0
public void seek(long p) throws IOException
{    this.reset();    this.skip(p);}
0
public long tell() throws IOException
{    return this.pos;}
0
public void seek(long p) throws IOException
{    getChannel().position(p);}
0
public long tell() throws IOException
{    return getChannel().position();}
0
public long length() throws IOException
{    return getChannel().size();}
0
protected Codec createInstance()
{    return new SnappyCodec();}
0
public String getName()
{    return DataFileConstants.SNAPPY_CODEC;}
0
public ByteBuffer compress(ByteBuffer in) throws IOException
{    int offset = computeOffset(in);    ByteBuffer out = ByteBuffer.allocate(Snappy.maxCompressedLength(in.remaining()) + 4);    int size = Snappy.compress(in.array(), offset, in.remaining(), out.array(), 0);    crc32.reset();    crc32.update(in.array(), offset, in.remaining());    out.putInt(size, (int) crc32.getValue());    out.limit(size + 4);    return out;}
0
public ByteBuffer decompress(ByteBuffer in) throws IOException
{    int offset = computeOffset(in);    ByteBuffer out = ByteBuffer.allocate(Snappy.uncompressedLength(in.array(), offset, in.remaining() - 4));    int size = Snappy.uncompress(in.array(), offset, in.remaining() - 4, out.array(), 0);    out.limit(size);    crc32.reset();    crc32.update(out.array(), 0, size);    if (in.getInt(in.limit() - 4) != (int) crc32.getValue())        throw new IOException("Checksum failure");    return out;}
0
public int hashCode()
{    return getName().hashCode();}
0
public boolean equals(Object obj)
{    if (this == obj)        return true;    return obj != null && obj.getClass() == getClass();}
0
public void sync() throws IOException
{    getFD().sync();}
0
protected Codec createInstance()
{    return new XZCodec(compressionLevel);}
0
public String getName()
{    return DataFileConstants.XZ_CODEC;}
0
public ByteBuffer compress(ByteBuffer data) throws IOException
{    ByteArrayOutputStream baos = getOutputBuffer(data.remaining());    try (OutputStream outputStream = new XZCompressorOutputStream(baos, compressionLevel)) {        outputStream.write(data.array(), computeOffset(data), data.remaining());    }    return ByteBuffer.wrap(baos.toByteArray());}
0
public ByteBuffer decompress(ByteBuffer data) throws IOException
{    ByteArrayOutputStream baos = getOutputBuffer(data.remaining());    InputStream bytesIn = new ByteArrayInputStream(data.array(), computeOffset(data), data.remaining());    try (InputStream ios = new XZCompressorInputStream(bytesIn)) {        IOUtils.copy(ios, baos);    }    return ByteBuffer.wrap(baos.toByteArray());}
0
private ByteArrayOutputStream getOutputBuffer(int suggestedLength)
{    if (null == outputBuffer) {        outputBuffer = new ByteArrayOutputStream(suggestedLength);    }    outputBuffer.reset();    return outputBuffer;}
0
public int hashCode()
{    return compressionLevel;}
0
public boolean equals(Object obj)
{    if (this == obj)        return true;    if (obj == null || obj.getClass() != getClass())        return false;    XZCodec other = (XZCodec) obj;    return (this.compressionLevel == other.compressionLevel);}
0
public String toString()
{    return getName() + "-" + compressionLevel;}
0
protected Codec createInstance()
{    return new ZstandardCodec(compressionLevel, useChecksum);}
0
public String getName()
{    return DataFileConstants.ZSTANDARD_CODEC;}
0
public ByteBuffer compress(ByteBuffer data) throws IOException
{    ByteArrayOutputStream baos = getOutputBuffer(data.remaining());    try (OutputStream outputStream = ZstandardLoader.output(baos, compressionLevel, useChecksum)) {        outputStream.write(data.array(), computeOffset(data), data.remaining());    }    return ByteBuffer.wrap(baos.toByteArray());}
0
public ByteBuffer decompress(ByteBuffer compressedData) throws IOException
{    ByteArrayOutputStream baos = getOutputBuffer(compressedData.remaining());    InputStream bytesIn = new ByteArrayInputStream(compressedData.array(), computeOffset(compressedData), compressedData.remaining());    try (InputStream ios = ZstandardLoader.input(bytesIn)) {        IOUtils.copy(ios, baos);    }    return ByteBuffer.wrap(baos.toByteArray());}
0
private ByteArrayOutputStream getOutputBuffer(int suggestedLength)
{    if (outputBuffer == null) {        outputBuffer = new ByteArrayOutputStream(suggestedLength);    }    outputBuffer.reset();    return outputBuffer;}
0
public int hashCode()
{    return getName().hashCode();}
0
public boolean equals(Object obj)
{    return (this == obj) || (obj != null && obj.getClass() == this.getClass());}
0
public String toString()
{    return getName() + "[" + compressionLevel + "]";}
0
 static InputStream input(InputStream compressed) throws IOException
{    return new ZstdInputStream(compressed);}
0
 static OutputStream output(OutputStream compressed, int level, boolean checksum) throws IOException
{    int bounded = Math.max(Math.min(level, Zstd.maxCompressionLevel()), Zstd.minCompressionLevel());    return new ZstdOutputStream(compressed, bounded, false, checksum);}
0
 void reset()
{    clear();}
0
 void prune()
{}
0
public static void setStringType(Schema s, StringType stringType)
{        if (stringType == StringType.String)        s.addProp(GenericData.STRING_PROP, GenericData.STRING_TYPE_STRING);}
0
public static GenericData get()
{    return INSTANCE;}
0
public ClassLoader getClassLoader()
{    return classLoader;}
0
public Collection<Conversion<?>> getConversions()
{    return conversions.values();}
0
public void addLogicalTypeConversion(Conversion<?> conversion)
{    conversions.put(conversion.getLogicalTypeName(), conversion);    Class<?> type = conversion.getConvertedType();    if (conversionsByClass.containsKey(type)) {        conversionsByClass.get(type).put(conversion.getLogicalTypeName(), conversion);    } else {        Map<String, Conversion<?>> conversions = new LinkedHashMap<>();        conversions.put(conversion.getLogicalTypeName(), conversion);        conversionsByClass.put(type, conversions);    }}
0
public Conversion<T> getConversionByClass(Class<T> datumClass)
{    Map<String, Conversion<?>> conversions = conversionsByClass.get(datumClass);    if (conversions != null) {        return (Conversion<T>) conversions.values().iterator().next();    }    return null;}
0
public Conversion<T> getConversionByClass(Class<T> datumClass, LogicalType logicalType)
{    Map<String, Conversion<?>> conversions = conversionsByClass.get(datumClass);    if (conversions != null) {        return (Conversion<T>) conversions.get(logicalType.getName());    }    return null;}
0
public Conversion<Object> getConversionFor(LogicalType logicalType)
{    if (logicalType == null) {        return null;    }    return (Conversion<Object>) conversions.get(logicalType.getName());}
0
public Schema getSchema()
{    return schema;}
0
public void put(String key, Object value)
{    Schema.Field field = schema.getField(key);    if (field == null)        throw new AvroRuntimeException("Not a valid schema field: " + key);    values[field.pos()] = value;}
0
public void put(int i, Object v)
{    values[i] = v;}
0
public Object get(String key)
{    Field field = schema.getField(key);    if (field == null)        return null;    return values[field.pos()];}
0
public Object get(int i)
{    return values[i];}
0
public boolean equals(Object o)
{    if (o == this)                return true;    if (!(o instanceof Record))                return false;    Record that = (Record) o;    if (!this.schema.equals(that.schema))                return false;    return GenericData.get().compare(this, that, schema, true) == 0;}
0
public int hashCode()
{    return GenericData.get().hashCode(this, schema);}
0
public int compareTo(Record that)
{    return GenericData.get().compare(this, that, schema);}
0
public String toString()
{    return GenericData.get().toString(this);}
0
public Schema getSchema()
{    return schema;}
0
public int size()
{    return size;}
0
public void clear()
{        Arrays.fill(elements, 0, size, null);    size = 0;}
0
public void reset()
{    size = 0;}
0
public void prune()
{    if (size < elements.length) {        Arrays.fill(elements, size, elements.length, null);    }}
0
public Iterator<T> iterator()
{    return new Iterator<T>() {        private int position = 0;        @Override        public boolean hasNext() {            return position < size;        }        @Override        public T next() {            return (T) elements[position++];        }        @Override        public void remove() {            throw new UnsupportedOperationException();        }    };}
0
public boolean hasNext()
{    return position < size;}
0
public T next()
{    return (T) elements[position++];}
0
public void remove()
{    throw new UnsupportedOperationException();}
0
public T get(int i)
{    if (i >= size)        throw new IndexOutOfBoundsException("Index " + i + " out of bounds.");    return (T) elements[i];}
0
public void add(int location, T o)
{    if (location > size || location < 0) {        throw new IndexOutOfBoundsException("Index " + location + " out of bounds.");    }    if (size == elements.length) {                final int newSize = size + (size >> 1) + 1;        elements = Arrays.copyOf(elements, newSize);    }    System.arraycopy(elements, location, elements, location + 1, size - location);    elements[location] = o;    size++;}
0
public T set(int i, T o)
{    if (i >= size)        throw new IndexOutOfBoundsException("Index " + i + " out of bounds.");    T response = (T) elements[i];    elements[i] = o;    return response;}
0
public T remove(int i)
{    if (i >= size)        throw new IndexOutOfBoundsException("Index " + i + " out of bounds.");    T result = (T) elements[i];    --size;    System.arraycopy(elements, i + 1, elements, i, (size - i));    elements[size] = null;    return result;}
0
public T peek()
{    return (size < elements.length) ? (T) elements[size] : null;}
0
public int compareTo(GenericArray<T> that)
{    return GenericData.get().compare(this, that, this.getSchema());}
0
public void reverse()
{    int left = 0;    int right = elements.length - 1;    while (left < right) {        Object tmp = elements[left];        elements[left] = elements[right];        elements[right] = tmp;        left++;        right--;    }}
0
protected void setSchema(Schema schema)
{    this.schema = schema;    this.bytes = new byte[schema.getFixedSize()];}
0
public Schema getSchema()
{    return schema;}
0
public void bytes(byte[] bytes)
{    this.bytes = bytes;}
0
public byte[] bytes()
{    return bytes;}
0
public boolean equals(Object o)
{    if (o == this)        return true;    return o instanceof GenericFixed && Arrays.equals(bytes, ((GenericFixed) o).bytes());}
0
public int hashCode()
{    return Arrays.hashCode(bytes);}
0
public String toString()
{    return Arrays.toString(bytes);}
0
public int compareTo(Fixed that)
{    return BinaryData.compareBytes(this.bytes, 0, this.bytes.length, that.bytes, 0, that.bytes.length);}
0
public Schema getSchema()
{    return schema;}
0
public boolean equals(Object o)
{    if (o == this)        return true;    return o instanceof GenericEnumSymbol && symbol.equals(o.toString());}
0
public int hashCode()
{    return symbol.hashCode();}
0
public String toString()
{    return symbol;}
0
public int compareTo(EnumSymbol that)
{    return GenericData.get().compare(this, that, schema);}
0
public DatumReader createDatumReader(Schema schema)
{    return new GenericDatumReader(schema, schema, this);}
0
public DatumReader createDatumReader(Schema writer, Schema reader)
{    return new GenericDatumReader(writer, reader, this);}
0
public DatumWriter createDatumWriter(Schema schema)
{    return new GenericDatumWriter(schema, this);}
0
public boolean validate(Schema schema, Object datum)
{    switch(schema.getType()) {        case RECORD:            if (!isRecord(datum))                return false;            for (Field f : schema.getFields()) {                if (!validate(f.schema(), getField(datum, f.name(), f.pos())))                    return false;            }            return true;        case ENUM:            if (!isEnum(datum))                return false;            return schema.getEnumSymbols().contains(datum.toString());        case ARRAY:            if (!(isArray(datum)))                return false;            for (Object element : getArrayAsCollection(datum)) if (!validate(schema.getElementType(), element))                return false;            return true;        case MAP:            if (!(isMap(datum)))                return false;            @SuppressWarnings(value = "unchecked")            Map<Object, Object> map = (Map<Object, Object>) datum;            for (Map.Entry<Object, Object> entry : map.entrySet()) if (!validate(schema.getValueType(), entry.getValue()))                return false;            return true;        case UNION:            try {                int i = resolveUnion(schema, datum);                return validate(schema.getTypes().get(i), datum);            } catch (UnresolvedUnionException e) {                return false;            }        case FIXED:            return datum instanceof GenericFixed && ((GenericFixed) datum).bytes().length == schema.getFixedSize();        case STRING:            return isString(datum);        case BYTES:            return isBytes(datum);        case INT:            return isInteger(datum);        case LONG:            return isLong(datum);        case FLOAT:            return isFloat(datum);        case DOUBLE:            return isDouble(datum);        case BOOLEAN:            return isBoolean(datum);        case NULL:            return datum == null;        default:            return false;    }}
0
public String toString(Object datum)
{    StringBuilder buffer = new StringBuilder();    toString(datum, buffer, new IdentityHashMap<>(128));    return buffer.toString();}
0
protected void toString(Object datum, StringBuilder buffer, IdentityHashMap<Object, Object> seenObjects)
{    if (isRecord(datum)) {        if (seenObjects.containsKey(datum)) {            buffer.append(TOSTRING_CIRCULAR_REFERENCE_ERROR_TEXT);            return;        }        seenObjects.put(datum, datum);        buffer.append("{");        int count = 0;        Schema schema = getRecordSchema(datum);        for (Field f : schema.getFields()) {            toString(f.name(), buffer, seenObjects);            buffer.append(": ");            toString(getField(datum, f.name(), f.pos()), buffer, seenObjects);            if (++count < schema.getFields().size())                buffer.append(", ");        }        buffer.append("}");        seenObjects.remove(datum);    } else if (isArray(datum)) {        if (seenObjects.containsKey(datum)) {            buffer.append(TOSTRING_CIRCULAR_REFERENCE_ERROR_TEXT);            return;        }        seenObjects.put(datum, datum);        Collection<?> array = getArrayAsCollection(datum);        buffer.append("[");        long last = array.size() - 1;        int i = 0;        for (Object element : array) {            toString(element, buffer, seenObjects);            if (i++ < last)                buffer.append(", ");        }        buffer.append("]");        seenObjects.remove(datum);    } else if (isMap(datum)) {        if (seenObjects.containsKey(datum)) {            buffer.append(TOSTRING_CIRCULAR_REFERENCE_ERROR_TEXT);            return;        }        seenObjects.put(datum, datum);        buffer.append("{");        int count = 0;        @SuppressWarnings(value = "unchecked")        Map<Object, Object> map = (Map<Object, Object>) datum;        for (Map.Entry<Object, Object> entry : map.entrySet()) {            buffer.append("\"");            writeEscapedString(String.valueOf(entry.getKey()), buffer);            buffer.append("\": ");            toString(entry.getValue(), buffer, seenObjects);            if (++count < map.size())                buffer.append(", ");        }        buffer.append("}");        seenObjects.remove(datum);    } else if (isString(datum) || isEnum(datum)) {        buffer.append("\"");        writeEscapedString(datum.toString(), buffer);        buffer.append("\"");    } else if (isBytes(datum)) {        buffer.append("\"");        ByteBuffer bytes = ((ByteBuffer) datum).duplicate();        writeEscapedString(StandardCharsets.ISO_8859_1.decode(bytes), buffer);        buffer.append("\"");    } else if ((    (datum instanceof Float) && (((Float) datum).isInfinite() || ((Float) datum).isNaN())) || ((datum instanceof Double) && (((Double) datum).isInfinite() || ((Double) datum).isNaN()))) {        buffer.append("\"");        buffer.append(datum);        buffer.append("\"");    } else if (datum instanceof GenericData) {        if (seenObjects.containsKey(datum)) {            buffer.append(TOSTRING_CIRCULAR_REFERENCE_ERROR_TEXT);            return;        }        seenObjects.put(datum, datum);        toString(datum, buffer, seenObjects);        seenObjects.remove(datum);    } else {        buffer.append(datum);    }}
0
private void writeEscapedString(CharSequence string, StringBuilder builder)
{    for (int i = 0; i < string.length(); i++) {        char ch = string.charAt(i);        switch(ch) {            case '"':                builder.append("\\\"");                break;            case '\\':                builder.append("\\\\");                break;            case '\b':                builder.append("\\b");                break;            case '\f':                builder.append("\\f");                break;            case '\n':                builder.append("\\n");                break;            case '\r':                builder.append("\\r");                break;            case '\t':                builder.append("\\t");                break;            default:                                if ((ch >= '\u0000' && ch <= '\u001F') || (ch >= '\u007F' && ch <= '\u009F') || (ch >= '\u2000' && ch <= '\u20FF')) {                    String hex = Integer.toHexString(ch);                    builder.append("\\u");                    for (int j = 0; j < 4 - hex.length(); j++) builder.append('0');                    builder.append(hex.toUpperCase());                } else {                    builder.append(ch);                }        }    }}
0
public Schema induce(Object datum)
{    if (isRecord(datum)) {        return getRecordSchema(datum);    } else if (isArray(datum)) {        Schema elementType = null;        for (Object element : getArrayAsCollection(datum)) {            if (elementType == null) {                elementType = induce(element);            } else if (!elementType.equals(induce(element))) {                throw new AvroTypeException("No mixed type arrays.");            }        }        if (elementType == null) {            throw new AvroTypeException("Empty array: " + datum);        }        return Schema.createArray(elementType);    } else if (isMap(datum)) {        @SuppressWarnings(value = "unchecked")        Map<Object, Object> map = (Map<Object, Object>) datum;        Schema value = null;        for (Map.Entry<Object, Object> entry : map.entrySet()) {            if (value == null) {                value = induce(entry.getValue());            } else if (!value.equals(induce(entry.getValue()))) {                throw new AvroTypeException("No mixed type map values.");            }        }        if (value == null) {            throw new AvroTypeException("Empty map: " + datum);        }        return Schema.createMap(value);    } else if (datum instanceof GenericFixed) {        return Schema.createFixed(null, null, null, ((GenericFixed) datum).bytes().length);    } else if (isString(datum))        return Schema.create(Type.STRING);    else if (isBytes(datum))        return Schema.create(Type.BYTES);    else if (isInteger(datum))        return Schema.create(Type.INT);    else if (isLong(datum))        return Schema.create(Type.LONG);    else if (isFloat(datum))        return Schema.create(Type.FLOAT);    else if (isDouble(datum))        return Schema.create(Type.DOUBLE);    else if (isBoolean(datum))        return Schema.create(Type.BOOLEAN);    else if (datum == null)        return Schema.create(Type.NULL);    else        throw new AvroTypeException("Can't create schema for: " + datum);}
0
public void setField(Object record, String name, int position, Object o)
{    ((IndexedRecord) record).put(position, o);}
0
public Object getField(Object record, String name, int position)
{    return ((IndexedRecord) record).get(position);}
0
protected Object getRecordState(Object record, Schema schema)
{    return null;}
0
protected void setField(Object r, String n, int p, Object o, Object state)
{    setField(r, n, p, o);}
0
protected Object getField(Object record, String name, int pos, Object state)
{    return getField(record, name, pos);}
0
public int resolveUnion(Schema union, Object datum)
{        if (datum != null) {        Map<String, Conversion<?>> conversions = conversionsByClass.get(datum.getClass());        if (conversions != null) {            List<Schema> candidates = union.getTypes();            for (int i = 0; i < candidates.size(); i += 1) {                LogicalType candidateType = candidates.get(i).getLogicalType();                if (candidateType != null) {                    Conversion<?> conversion = conversions.get(candidateType.getName());                    if (conversion != null) {                        return i;                    }                }            }        }    }    Integer i = union.getIndexNamed(getSchemaName(datum));    if (i != null)        return i;    throw new UnresolvedUnionException(union, datum);}
0
protected String getSchemaName(Object datum)
{    if (datum == null || datum == JsonProperties.NULL_VALUE)        return Type.NULL.getName();    if (isRecord(datum))        return getRecordSchema(datum).getFullName();    if (isEnum(datum))        return getEnumSchema(datum).getFullName();    if (isArray(datum))        return Type.ARRAY.getName();    if (isMap(datum))        return Type.MAP.getName();    if (isFixed(datum))        return getFixedSchema(datum).getFullName();    if (isString(datum))        return Type.STRING.getName();    if (isBytes(datum))        return Type.BYTES.getName();    if (isInteger(datum))        return Type.INT.getName();    if (isLong(datum))        return Type.LONG.getName();    if (isFloat(datum))        return Type.FLOAT.getName();    if (isDouble(datum))        return Type.DOUBLE.getName();    if (isBoolean(datum))        return Type.BOOLEAN.getName();    throw new AvroRuntimeException(String.format("Unknown datum type %s: %s", datum.getClass().getName(), datum));}
0
protected boolean instanceOf(Schema schema, Object datum)
{    switch(schema.getType()) {        case RECORD:            if (!isRecord(datum))                return false;            return (schema.getFullName() == null) ? getRecordSchema(datum).getFullName() == null : schema.getFullName().equals(getRecordSchema(datum).getFullName());        case ENUM:            if (!isEnum(datum))                return false;            return schema.getFullName().equals(getEnumSchema(datum).getFullName());        case ARRAY:            return isArray(datum);        case MAP:            return isMap(datum);        case FIXED:            if (!isFixed(datum))                return false;            return schema.getFullName().equals(getFixedSchema(datum).getFullName());        case STRING:            return isString(datum);        case BYTES:            return isBytes(datum);        case INT:            return isInteger(datum);        case LONG:            return isLong(datum);        case FLOAT:            return isFloat(datum);        case DOUBLE:            return isDouble(datum);        case BOOLEAN:            return isBoolean(datum);        case NULL:            return datum == null;        default:            throw new AvroRuntimeException("Unexpected type: " + schema);    }}
0
protected boolean isArray(Object datum)
{    return datum instanceof Collection;}
0
protected Collection getArrayAsCollection(Object datum)
{    return (Collection) datum;}
0
protected boolean isRecord(Object datum)
{    return datum instanceof IndexedRecord;}
0
protected Schema getRecordSchema(Object record)
{    return ((GenericContainer) record).getSchema();}
0
protected boolean isEnum(Object datum)
{    return datum instanceof GenericEnumSymbol;}
0
protected Schema getEnumSchema(Object enu)
{    return ((GenericContainer) enu).getSchema();}
0
protected boolean isMap(Object datum)
{    return datum instanceof Map;}
0
protected boolean isFixed(Object datum)
{    return datum instanceof GenericFixed;}
0
protected Schema getFixedSchema(Object fixed)
{    return ((GenericContainer) fixed).getSchema();}
0
protected boolean isString(Object datum)
{    return datum instanceof CharSequence;}
0
protected boolean isBytes(Object datum)
{    return datum instanceof ByteBuffer;}
0
protected boolean isInteger(Object datum)
{    return datum instanceof Integer;}
0
protected boolean isLong(Object datum)
{    return datum instanceof Long;}
0
protected boolean isFloat(Object datum)
{    return datum instanceof Float;}
0
protected boolean isDouble(Object datum)
{    return datum instanceof Double;}
0
protected boolean isBoolean(Object datum)
{    return datum instanceof Boolean;}
0
public int hashCode(Object o, Schema s)
{    if (o == null)                return 0;    int hashCode = 1;    switch(s.getType()) {        case RECORD:            for (Field f : s.getFields()) {                if (f.order() == Field.Order.IGNORE)                    continue;                hashCode = hashCodeAdd(hashCode, getField(o, f.name(), f.pos()), f.schema());            }            return hashCode;        case ARRAY:            Collection<?> a = (Collection<?>) o;            Schema elementType = s.getElementType();            for (Object e : a) hashCode = hashCodeAdd(hashCode, e, elementType);            return hashCode;        case UNION:            return hashCode(o, s.getTypes().get(resolveUnion(s, o)));        case ENUM:            return s.getEnumOrdinal(o.toString());        case NULL:            return 0;        case STRING:            return (o instanceof Utf8 ? o : new Utf8(o.toString())).hashCode();        default:            return o.hashCode();    }}
0
protected int hashCodeAdd(int hashCode, Object o, Schema s)
{    return 31 * hashCode + hashCode(o, s);}
0
public int compare(Object o1, Object o2, Schema s)
{    return compare(o1, o2, s, false);}
0
protected int compare(Object o1, Object o2, Schema s, boolean equals)
{    if (o1 == o2)        return 0;    switch(s.getType()) {        case RECORD:            for (Field f : s.getFields()) {                if (f.order() == Field.Order.IGNORE)                                        continue;                int pos = f.pos();                String name = f.name();                int compare = compare(getField(o1, name, pos), getField(o2, name, pos), f.schema(), equals);                if (                compare != 0)                    return f.order() == Field.Order.DESCENDING ? -compare : compare;            }            return 0;        case ENUM:            return s.getEnumOrdinal(o1.toString()) - s.getEnumOrdinal(o2.toString());        case ARRAY:            Collection a1 = (Collection) o1;            Collection a2 = (Collection) o2;            Iterator e1 = a1.iterator();            Iterator e2 = a2.iterator();            Schema elementType = s.getElementType();            while (e1.hasNext() && e2.hasNext()) {                int compare = compare(e1.next(), e2.next(), elementType, equals);                if (compare != 0)                    return compare;            }            return e1.hasNext() ? 1 : (e2.hasNext() ? -1 : 0);        case MAP:            if (equals)                return o1.equals(o2) ? 0 : 1;            throw new AvroRuntimeException("Can't compare maps!");        case UNION:            int i1 = resolveUnion(s, o1);            int i2 = resolveUnion(s, o2);            return (i1 == i2) ? compare(o1, o2, s.getTypes().get(i1), equals) : Integer.compare(i1, i2);        case NULL:            return 0;        case STRING:            Utf8 u1 = o1 instanceof Utf8 ? (Utf8) o1 : new Utf8(o1.toString());            Utf8 u2 = o2 instanceof Utf8 ? (Utf8) o2 : new Utf8(o2.toString());            return u1.compareTo(u2);        default:            return ((Comparable) o1).compareTo(o2);    }}
0
public Object getDefaultValue(Field field)
{    JsonNode json = Accessor.defaultValue(field);    if (json == null)        throw new AvroMissingFieldException("Field " + field + " not set and has no default value", field);    if (json.isNull() && (field.schema().getType() == Type.NULL || (field.schema().getType() == Type.UNION && field.schema().getTypes().get(0).getType() == Type.NULL))) {        return null;    }        Object defaultValue = defaultValueCache.get(field);        if (defaultValue == null)        try {            ByteArrayOutputStream baos = new ByteArrayOutputStream();            BinaryEncoder encoder = EncoderFactory.get().binaryEncoder(baos, null);            Accessor.encode(encoder, field.schema(), json);            encoder.flush();            BinaryDecoder decoder = DecoderFactory.get().binaryDecoder(baos.toByteArray(), null);            defaultValue = createDatumReader(field.schema()).read(null, decoder);                                                defaultValueCache.put(field, defaultValue);        } catch (IOException e) {            throw new AvroRuntimeException(e);        }    return defaultValue;}
0
public T deepCopy(Schema schema, T value)
{    if (value == null)        return null;    LogicalType logicalType = schema.getLogicalType();    if (    logicalType == null)        return (T) deepCopyRaw(schema, value);    Conversion conversion = getConversionByClass(value.getClass(), logicalType);    if (    conversion == null)        return (T) deepCopyRaw(schema, value);            Object raw = Conversions.convertToRawType(value, schema, logicalType, conversion);        Object copy = deepCopyRaw(schema, raw);    return (T) Conversions.convertToLogicalType(copy, schema, logicalType, conversion);}
0
private Object deepCopyRaw(Schema schema, Object value)
{    if (value == null) {        return null;    }    switch(schema.getType()) {        case ARRAY:            List<Object> arrayValue = (List) value;            List<Object> arrayCopy = new GenericData.Array<>(arrayValue.size(), schema);            for (Object obj : arrayValue) {                arrayCopy.add(deepCopy(schema.getElementType(), obj));            }            return arrayCopy;        case BOOLEAN:                        return value;        case BYTES:            ByteBuffer byteBufferValue = (ByteBuffer) value;            int start = byteBufferValue.position();            int length = byteBufferValue.limit() - start;            byte[] bytesCopy = new byte[length];            byteBufferValue.get(bytesCopy, 0, length);            byteBufferValue.position(start);            return ByteBuffer.wrap(bytesCopy, 0, length);        case DOUBLE:                        return value;        case ENUM:            return createEnum(value.toString(), schema);        case FIXED:            return createFixed(null, ((GenericFixed) value).bytes(), schema);        case FLOAT:                        return value;        case INT:                        return value;        case LONG:                        return value;        case MAP:            Map<CharSequence, Object> mapValue = (Map) value;            Map<CharSequence, Object> mapCopy = new HashMap<>(mapValue.size());            for (Map.Entry<CharSequence, Object> entry : mapValue.entrySet()) {                mapCopy.put(deepCopy(STRINGS, entry.getKey()), deepCopy(schema.getValueType(), entry.getValue()));            }            return mapCopy;        case NULL:            return null;        case RECORD:            Object oldState = getRecordState(value, schema);            Object newRecord = newRecord(null, schema);            Object newState = getRecordState(newRecord, schema);            for (Field f : schema.getFields()) {                int pos = f.pos();                String name = f.name();                Object newValue = deepCopy(f.schema(), getField(value, name, pos, oldState));                setField(newRecord, name, pos, newValue, newState);            }            return newRecord;        case STRING:                        if (value instanceof String) {                return value;            } else             if (value instanceof Utf8) {                                return new Utf8((Utf8) value);            }            return new Utf8(value.toString());        case UNION:            return deepCopy(schema.getTypes().get(resolveUnion(schema, value)), value);        default:            throw new AvroRuntimeException("Deep copy failed for schema \"" + schema + "\" and value \"" + value + "\"");    }}
0
public Object createFixed(Object old, Schema schema)
{    if ((old instanceof GenericFixed) && ((GenericFixed) old).bytes().length == schema.getFixedSize())        return old;    return new GenericData.Fixed(schema);}
0
public Object createFixed(Object old, byte[] bytes, Schema schema)
{    GenericFixed fixed = (GenericFixed) createFixed(old, schema);    System.arraycopy(bytes, 0, fixed.bytes(), 0, schema.getFixedSize());    return fixed;}
0
public Object createEnum(String symbol, Schema schema)
{    return new EnumSymbol(schema, symbol);}
0
public Object newRecord(Object old, Schema schema)
{    if (old instanceof IndexedRecord) {        IndexedRecord record = (IndexedRecord) old;        if (record.getSchema() == schema)            return record;    }    return new GenericData.Record(schema);}
0
public GenericData getData()
{    return data;}
0
public Schema getSchema()
{    return actual;}
0
public void setSchema(Schema writer)
{    this.actual = writer;    if (expected == null) {        expected = actual;    }    creatorResolver = null;}
0
public Schema getExpected()
{    return expected;}
0
public void setExpected(Schema reader)
{    this.expected = reader;    creatorResolver = null;}
0
protected final ResolvingDecoder getResolver(Schema actual, Schema expected) throws IOException
{    Thread currThread = Thread.currentThread();    ResolvingDecoder resolver;    if (currThread == creator && creatorResolver != null) {        return creatorResolver;    }    Map<Schema, ResolvingDecoder> cache = RESOLVER_CACHE.get().get(actual);    if (cache == null) {        cache = new WeakIdentityHashMap<>();        RESOLVER_CACHE.get().put(actual, cache);    }    resolver = cache.get(expected);    if (resolver == null) {        resolver = DecoderFactory.get().resolvingDecoder(Schema.applyAliases(actual, expected), expected, null);        cache.put(expected, resolver);    }    if (currThread == creator) {        creatorResolver = resolver;    }    return resolver;}
0
public D read(D reuse, Decoder in) throws IOException
{    ResolvingDecoder resolver = getResolver(actual, expected);    resolver.configure(in);    D result = (D) read(reuse, expected, resolver);    resolver.drain();    return result;}
0
protected Object read(Object old, Schema expected, ResolvingDecoder in) throws IOException
{    Object datum = readWithoutConversion(old, expected, in);    LogicalType logicalType = expected.getLogicalType();    if (logicalType != null) {        Conversion<?> conversion = getData().getConversionFor(logicalType);        if (conversion != null) {            return convert(datum, expected, logicalType, conversion);        }    }    return datum;}
0
protected Object readWithConversion(Object old, Schema expected, LogicalType logicalType, Conversion<?> conversion, ResolvingDecoder in) throws IOException
{    return convert(readWithoutConversion(old, expected, in), expected, logicalType, conversion);}
0
protected Object readWithoutConversion(Object old, Schema expected, ResolvingDecoder in) throws IOException
{    switch(expected.getType()) {        case RECORD:            return readRecord(old, expected, in);        case ENUM:            return readEnum(expected, in);        case ARRAY:            return readArray(old, expected, in);        case MAP:            return readMap(old, expected, in);        case UNION:            return read(old, expected.getTypes().get(in.readIndex()), in);        case FIXED:            return readFixed(old, expected, in);        case STRING:            return readString(old, expected, in);        case BYTES:            return readBytes(old, expected, in);        case INT:            return readInt(old, expected, in);        case LONG:            return in.readLong();        case FLOAT:            return in.readFloat();        case DOUBLE:            return in.readDouble();        case BOOLEAN:            return in.readBoolean();        case NULL:            in.readNull();            return null;        default:            throw new AvroRuntimeException("Unknown type: " + expected);    }}
0
protected Object convert(Object datum, Schema schema, LogicalType type, Conversion<?> conversion)
{    return Conversions.convertToLogicalType(datum, schema, type, conversion);}
0
protected Object readRecord(Object old, Schema expected, ResolvingDecoder in) throws IOException
{    Object r = data.newRecord(old, expected);    Object state = data.getRecordState(r, expected);    for (Field f : in.readFieldOrder()) {        int pos = f.pos();        String name = f.name();        Object oldDatum = null;        if (old != null) {            oldDatum = data.getField(r, name, pos, state);        }        readField(r, f, oldDatum, in, state);    }    return r;}
0
protected void readField(Object r, Field f, Object oldDatum, ResolvingDecoder in, Object state) throws IOException
{    data.setField(r, f.name(), f.pos(), read(oldDatum, f.schema(), in), state);}
0
protected Object readEnum(Schema expected, Decoder in) throws IOException
{    return createEnum(expected.getEnumSymbols().get(in.readEnum()), expected);}
0
protected Object createEnum(String symbol, Schema schema)
{    return data.createEnum(symbol, schema);}
0
protected Object readArray(Object old, Schema expected, ResolvingDecoder in) throws IOException
{    Schema expectedType = expected.getElementType();    long l = in.readArrayStart();    long base = 0;    if (l > 0) {        LogicalType logicalType = expectedType.getLogicalType();        Conversion<?> conversion = getData().getConversionFor(logicalType);        Object array = newArray(old, (int) l, expected);        do {            if (logicalType != null && conversion != null) {                for (long i = 0; i < l; i++) {                    addToArray(array, base + i, readWithConversion(peekArray(array), expectedType, logicalType, conversion, in));                }            } else {                for (long i = 0; i < l; i++) {                    addToArray(array, base + i, readWithoutConversion(peekArray(array), expectedType, in));                }            }            base += l;        } while ((l = in.arrayNext()) > 0);        return pruneArray(array);    } else {        return pruneArray(newArray(old, 0, expected));    }}
0
private Object pruneArray(Object object)
{    if (object instanceof GenericArray<?>) {        ((GenericArray<?>) object).prune();    }    return object;}
0
protected Object peekArray(Object array)
{    return (array instanceof GenericArray) ? ((GenericArray) array).peek() : null;}
0
protected void addToArray(Object array, long pos, Object e)
{    ((Collection) array).add(e);}
0
protected Object readMap(Object old, Schema expected, ResolvingDecoder in) throws IOException
{    Schema eValue = expected.getValueType();    long l = in.readMapStart();    LogicalType logicalType = eValue.getLogicalType();    Conversion<?> conversion = getData().getConversionFor(logicalType);    Object map = newMap(old, (int) l);    if (l > 0) {        do {            if (logicalType != null && conversion != null) {                for (int i = 0; i < l; i++) {                    addToMap(map, readMapKey(null, expected, in), readWithConversion(null, eValue, logicalType, conversion, in));                }            } else {                for (int i = 0; i < l; i++) {                    addToMap(map, readMapKey(null, expected, in), readWithoutConversion(null, eValue, in));                }            }        } while ((l = in.mapNext()) > 0);    }    return map;}
0
protected Object readMapKey(Object old, Schema expected, Decoder in) throws IOException
{    return readString(old, expected, in);}
0
protected void addToMap(Object map, Object key, Object value)
{    ((Map) map).put(key, value);}
0
protected Object readFixed(Object old, Schema expected, Decoder in) throws IOException
{    GenericFixed fixed = (GenericFixed) data.createFixed(old, expected);    in.readFixed(fixed.bytes(), 0, expected.getFixedSize());    return fixed;}
0
protected Object createFixed(Object old, Schema schema)
{    return data.createFixed(old, schema);}
0
protected Object createFixed(Object old, byte[] bytes, Schema schema)
{    return data.createFixed(old, bytes, schema);}
0
protected Object newRecord(Object old, Schema schema)
{    return data.newRecord(old, schema);}
0
protected Object newArray(Object old, int size, Schema schema)
{    if (old instanceof GenericArray) {        ((GenericArray) old).reset();        return old;    } else if (old instanceof Collection) {        ((Collection) old).clear();        return old;    } else        return new GenericData.Array(size, schema);}
0
protected Object newMap(Object old, int size)
{    if (old instanceof Map) {        ((Map) old).clear();        return old;    } else        return new HashMap<>(size);}
0
protected Object readString(Object old, Schema expected, Decoder in) throws IOException
{    Class stringClass = getStringClass(expected);    if (stringClass == String.class)        return in.readString();    if (stringClass == CharSequence.class)        return readString(old, in);    return newInstanceFromString(stringClass, in.readString());}
0
protected Object readString(Object old, Decoder in) throws IOException
{    return in.readString(old instanceof Utf8 ? (Utf8) old : null);}
0
protected Object createString(String value)
{    return new Utf8(value);}
0
protected Class findStringClass(Schema schema)
{    String name = schema.getProp(GenericData.STRING_PROP);    if (name == null)        return CharSequence.class;    switch(GenericData.StringType.valueOf(name)) {        case String:            return String.class;        default:            return CharSequence.class;    }}
0
private Class getStringClass(Schema s)
{    Class c = stringClassCache.get(s);    if (c == null) {        c = findStringClass(s);        stringClassCache.put(s, c);    }    return c;}
0
protected Object newInstanceFromString(Class c, String s)
{    try {        Constructor ctor = stringCtorCache.get(c);        if (ctor == null) {            ctor = c.getDeclaredConstructor(String.class);            ctor.setAccessible(true);            stringCtorCache.put(c, ctor);        }        return ctor.newInstance(s);    } catch (NoSuchMethodException | InvocationTargetException | IllegalAccessException | InstantiationException e) {        throw new AvroRuntimeException(e);    }}
0
protected Object readBytes(Object old, Schema s, Decoder in) throws IOException
{    return readBytes(old, in);}
0
protected Object readBytes(Object old, Decoder in) throws IOException
{    return in.readBytes(old instanceof ByteBuffer ? (ByteBuffer) old : null);}
0
protected Object readInt(Object old, Schema expected, Decoder in) throws IOException
{    return in.readInt();}
0
protected Object createBytes(byte[] value)
{    return ByteBuffer.wrap(value);}
0
public static void skip(Schema schema, Decoder in) throws IOException
{    switch(schema.getType()) {        case RECORD:            for (Field field : schema.getFields()) skip(field.schema(), in);            break;        case ENUM:            in.readInt();            break;        case ARRAY:            Schema elementType = schema.getElementType();            for (long l = in.skipArray(); l > 0; l = in.skipArray()) {                for (long i = 0; i < l; i++) {                    skip(elementType, in);                }            }            break;        case MAP:            Schema value = schema.getValueType();            for (long l = in.skipMap(); l > 0; l = in.skipMap()) {                for (long i = 0; i < l; i++) {                    in.skipString();                    skip(value, in);                }            }            break;        case UNION:            skip(schema.getTypes().get(in.readIndex()), in);            break;        case FIXED:            in.skipFixed(schema.getFixedSize());            break;        case STRING:            in.skipString();            break;        case BYTES:            in.skipBytes();            break;        case INT:            in.readInt();            break;        case LONG:            in.readLong();            break;        case FLOAT:            in.readFloat();            break;        case DOUBLE:            in.readDouble();            break;        case BOOLEAN:            in.readBoolean();            break;        case NULL:            break;        default:            throw new RuntimeException("Unknown type: " + schema);    }}
0
public GenericData getData()
{    return data;}
0
public void setSchema(Schema root)
{    this.root = root;}
0
public void write(D datum, Encoder out) throws IOException
{    Objects.requireNonNull(out, "Encoder cannot be null");    write(root, datum, out);}
0
protected void write(Schema schema, Object datum, Encoder out) throws IOException
{    LogicalType logicalType = schema.getLogicalType();    if (datum != null && logicalType != null) {        Conversion<?> conversion = getData().getConversionByClass(datum.getClass(), logicalType);        writeWithoutConversion(schema, convert(schema, logicalType, conversion, datum), out);    } else {        writeWithoutConversion(schema, datum, out);    }}
0
protected Object convert(Schema schema, LogicalType logicalType, Conversion<T> conversion, Object datum)
{    try {        if (conversion == null) {            return datum;        } else {            return Conversions.convertToRawType(datum, schema, logicalType, conversion);        }    } catch (AvroRuntimeException e) {        Throwable cause = e.getCause();        if (cause != null && cause.getClass() == ClassCastException.class) {                        throw (ClassCastException) cause;        } else {            throw e;        }    }}
0
protected void writeWithoutConversion(Schema schema, Object datum, Encoder out) throws IOException
{    try {        switch(schema.getType()) {            case RECORD:                writeRecord(schema, datum, out);                break;            case ENUM:                writeEnum(schema, datum, out);                break;            case ARRAY:                writeArray(schema, datum, out);                break;            case MAP:                writeMap(schema, datum, out);                break;            case UNION:                int index = resolveUnion(schema, datum);                out.writeIndex(index);                write(schema.getTypes().get(index), datum, out);                break;            case FIXED:                writeFixed(schema, datum, out);                break;            case STRING:                writeString(schema, datum, out);                break;            case BYTES:                writeBytes(datum, out);                break;            case INT:                out.writeInt(((Number) datum).intValue());                break;            case LONG:                out.writeLong((Long) datum);                break;            case FLOAT:                out.writeFloat((Float) datum);                break;            case DOUBLE:                out.writeDouble((Double) datum);                break;            case BOOLEAN:                out.writeBoolean((Boolean) datum);                break;            case NULL:                out.writeNull();                break;            default:                error(schema, datum);        }    } catch (NullPointerException e) {        throw npe(e, " of " + schema.getFullName());    }}
0
protected NullPointerException npe(NullPointerException e, String s)
{    NullPointerException result = new NullPointerException(e.getMessage() + s);    result.initCause(e.getCause() == null ? e : e.getCause());    return result;}
0
protected void writeRecord(Schema schema, Object datum, Encoder out) throws IOException
{    Object state = data.getRecordState(datum, schema);    for (Field f : schema.getFields()) {        writeField(datum, f, out, state);    }}
0
protected void writeField(Object datum, Field f, Encoder out, Object state) throws IOException
{    Object value = data.getField(datum, f.name(), f.pos(), state);    try {        write(f.schema(), value, out);    } catch (NullPointerException e) {        throw npe(e, " in field " + f.name());    }}
0
protected void writeEnum(Schema schema, Object datum, Encoder out) throws IOException
{    if (!data.isEnum(datum))        throw new AvroTypeException("Not an enum: " + datum + " for schema: " + schema);    out.writeEnum(schema.getEnumOrdinal(datum.toString()));}
0
protected void writeArray(Schema schema, Object datum, Encoder out) throws IOException
{    Schema element = schema.getElementType();    long size = getArraySize(datum);    long actualSize = 0;    out.writeArrayStart();    out.setItemCount(size);    for (Iterator<? extends Object> it = getArrayElements(datum); it.hasNext(); ) {        out.startItem();        write(element, it.next(), out);        actualSize++;    }    out.writeArrayEnd();    if (actualSize != size) {        throw new ConcurrentModificationException("Size of array written was " + size + ", but number of elements written was " + actualSize + ". ");    }}
0
protected int resolveUnion(Schema union, Object datum)
{    return data.resolveUnion(union, datum);}
0
protected long getArraySize(Object array)
{    return ((Collection) array).size();}
0
protected Iterator<? extends Object> getArrayElements(Object array)
{    return ((Collection) array).iterator();}
0
protected void writeMap(Schema schema, Object datum, Encoder out) throws IOException
{    Schema value = schema.getValueType();    int size = getMapSize(datum);    int actualSize = 0;    out.writeMapStart();    out.setItemCount(size);    for (Map.Entry<Object, Object> entry : getMapEntries(datum)) {        out.startItem();        writeString(entry.getKey().toString(), out);        write(value, entry.getValue(), out);        actualSize++;    }    out.writeMapEnd();    if (actualSize != size) {        throw new ConcurrentModificationException("Size of map written was " + size + ", but number of entries written was " + actualSize + ". ");    }}
0
protected int getMapSize(Object map)
{    return ((Map) map).size();}
0
protected Iterable<Map.Entry<Object, Object>> getMapEntries(Object map)
{    return ((Map) map).entrySet();}
0
protected void writeString(Schema schema, Object datum, Encoder out) throws IOException
{    writeString(datum, out);}
0
protected void writeString(Object datum, Encoder out) throws IOException
{    out.writeString((CharSequence) datum);}
0
protected void writeBytes(Object datum, Encoder out) throws IOException
{    out.writeBytes((ByteBuffer) datum);}
0
protected void writeFixed(Schema schema, Object datum, Encoder out) throws IOException
{    out.writeFixed(((GenericFixed) datum).bytes(), 0, schema.getFixedSize());}
0
private void error(Schema schema, Object datum)
{    throw new AvroTypeException("Not a " + schema + ": " + datum);}
0
public Object get(String fieldName)
{    return get(schema().getField(fieldName));}
0
public Object get(Field field)
{    return get(field.pos());}
0
protected Object get(int pos)
{    return record.get(pos);}
0
public GenericRecordBuilder set(String fieldName, Object value)
{    return set(schema().getField(fieldName), value);}
0
public GenericRecordBuilder set(Field field, Object value)
{    return set(field, field.pos(), value);}
0
protected GenericRecordBuilder set(int pos, Object value)
{    return set(fields()[pos], pos, value);}
0
private GenericRecordBuilder set(Field field, int pos, Object value)
{    validate(field, value);    record.put(pos, value);    fieldSetFlags()[pos] = true;    return this;}
0
public boolean has(String fieldName)
{    return has(schema().getField(fieldName));}
0
public boolean has(Field field)
{    return has(field.pos());}
0
protected boolean has(int pos)
{    return fieldSetFlags()[pos];}
0
public GenericRecordBuilder clear(String fieldName)
{    return clear(schema().getField(fieldName));}
0
public GenericRecordBuilder clear(Field field)
{    return clear(field.pos());}
0
protected GenericRecordBuilder clear(int pos)
{    record.put(pos, null);    fieldSetFlags()[pos] = false;    return this;}
0
public Record build()
{    Record record;    try {        record = new GenericData.Record(schema());    } catch (Exception e) {        throw new AvroRuntimeException(e);    }    for (Field field : fields()) {        Object value;        try {            value = getWithDefault(field);        } catch (IOException e) {            throw new AvroRuntimeException(e);        }        if (value != null) {            record.put(field.pos(), value);        }    }    return record;}
0
private Object getWithDefault(Field field) throws IOException
{    return fieldSetFlags()[field.pos()] ? record.get(field.pos()) : defaultValue(field);}
0
public int hashCode()
{    final int prime = 31;    int result = super.hashCode();    result = prime * result + ((record == null) ? 0 : record.hashCode());    return result;}
0
public boolean equals(Object obj)
{    if (this == obj)        return true;    if (!super.equals(obj))        return false;    if (getClass() != obj.getClass())        return false;    GenericRecordBuilder other = (GenericRecordBuilder) obj;    if (record == null) {        return other.record == null;    } else        return record.equals(other.record);}
0
public void set(byte[] data1, int off1, int len1, byte[] data2, int off2, int len2)
{    d1.setBuf(data1, off1, len1);    d2.setBuf(data2, off2, len2);}
0
public void clear()
{    d1.clearBuf();    d2.clearBuf();}
0
public static int compare(byte[] b1, int s1, byte[] b2, int s2, Schema schema)
{    return compare(b1, s1, b1.length - s1, b2, s2, b2.length - s2, schema);}
0
public static int compare(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2, Schema schema)
{    Decoders decoders = DECODERS.get();    decoders.set(b1, s1, l1, b2, s2, l2);    try {        return compare(decoders, schema);    } catch (IOException e) {        throw new AvroRuntimeException(e);    } finally {        decoders.clear();    }}
0
private static int compare(Decoders d, Schema schema) throws IOException
{    Decoder d1 = d.d1;    Decoder d2 = d.d2;    switch(schema.getType()) {        case RECORD:            {                for (Field field : schema.getFields()) {                    if (field.order() == Field.Order.IGNORE) {                        GenericDatumReader.skip(field.schema(), d1);                        GenericDatumReader.skip(field.schema(), d2);                        continue;                    }                    int c = compare(d, field.schema());                    if (c != 0) {                        return (field.order() != Field.Order.DESCENDING) ? c : -c;                    }                }                return 0;            }        case ENUM:        case INT:            return Integer.compare(d1.readInt(), d2.readInt());        case LONG:            return Long.compare(d1.readLong(), d2.readLong());        case FLOAT:            return Float.compare(d1.readFloat(), d2.readFloat());        case DOUBLE:            return Double.compare(d1.readDouble(), d2.readDouble());        case BOOLEAN:            return Boolean.compare(d1.readBoolean(), d2.readBoolean());        case ARRAY:            {                                long i = 0;                                long r1 = 0, r2 = 0;                                long l1 = 0, l2 = 0;                while (true) {                    if (r1 == 0) {                                                r1 = d1.readLong();                        if (r1 < 0) {                            r1 = -r1;                            d1.readLong();                        }                        l1 += r1;                    }                    if (r2 == 0) {                        r2 = d2.readLong();                        if (r2 < 0) {                            r2 = -r2;                            d2.readLong();                        }                        l2 += r2;                    }                    if (                    r1 == 0 || r2 == 0)                        return Long.compare(l1, l2);                    long l = Math.min(l1, l2);                    while (i < l) {                                                int c = compare(d, schema.getElementType());                        if (c != 0)                            return c;                        i++;                        r1--;                        r2--;                    }                }            }        case MAP:            throw new AvroRuntimeException("Can't compare maps!");        case UNION:            {                int i1 = d1.readInt();                int i2 = d2.readInt();                int c = Integer.compare(i1, i2);                return c == 0 ? compare(d, schema.getTypes().get(i1)) : c;            }        case FIXED:            {                int size = schema.getFixedSize();                int c = compareBytes(d.d1.getBuf(), d.d1.getPos(), size, d.d2.getBuf(), d.d2.getPos(), size);                d.d1.skipFixed(size);                d.d2.skipFixed(size);                return c;            }        case STRING:        case BYTES:            {                int l1 = d1.readInt();                int l2 = d2.readInt();                int c = compareBytes(d.d1.getBuf(), d.d1.getPos(), l1, d.d2.getBuf(), d.d2.getPos(), l2);                d.d1.skipFixed(l1);                d.d2.skipFixed(l2);                return c;            }        case NULL:            return 0;        default:            throw new AvroRuntimeException("Unexpected schema to compare!");    }}
0
public static int compareBytes(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2)
{    int end1 = s1 + l1;    int end2 = s2 + l2;    for (int i = s1, j = s2; i < end1 && j < end2; i++, j++) {        int a = (b1[i] & 0xff);        int b = (b2[j] & 0xff);        if (a != b) {            return a - b;        }    }    return l1 - l2;}
0
public void set(byte[] bytes, int start, int len)
{    this.decoder.setBuf(bytes, start, len);}
0
public static int hashCode(byte[] bytes, int start, int length, Schema schema)
{    HashData data = HASH_DATA.get();    data.set(bytes, start, length);    try {        return hashCode(data, schema);    } catch (IOException e) {        throw new AvroRuntimeException(e);    }}
0
private static int hashCode(HashData data, Schema schema) throws IOException
{    Decoder decoder = data.decoder;    switch(schema.getType()) {        case RECORD:            {                int hashCode = 1;                for (Field field : schema.getFields()) {                    if (field.order() == Field.Order.IGNORE) {                        GenericDatumReader.skip(field.schema(), decoder);                        continue;                    }                    hashCode = hashCode * 31 + hashCode(data, field.schema());                }                return hashCode;            }        case ENUM:        case INT:            return decoder.readInt();        case BOOLEAN:            return Boolean.hashCode(decoder.readBoolean());        case FLOAT:            return Float.hashCode(decoder.readFloat());        case LONG:            return Long.hashCode(decoder.readLong());        case DOUBLE:            return Double.hashCode(decoder.readDouble());        case ARRAY:            {                Schema elementType = schema.getElementType();                int hashCode = 1;                for (long l = decoder.readArrayStart(); l != 0; l = decoder.arrayNext()) {                    for (long i = 0; i < l; i++) {                        hashCode = hashCode * 31 + hashCode(data, elementType);                    }                }                return hashCode;            }        case MAP:            throw new AvroRuntimeException("Can't hashCode maps!");        case UNION:            return hashCode(data, schema.getTypes().get(decoder.readInt()));        case FIXED:            return hashBytes(1, data, schema.getFixedSize(), false);        case STRING:            return hashBytes(0, data, decoder.readInt(), false);        case BYTES:            return hashBytes(1, data, decoder.readInt(), true);        case NULL:            return 0;        default:            throw new AvroRuntimeException("Unexpected schema to hashCode!");    }}
0
private static int hashBytes(int init, HashData data, int len, boolean rev) throws IOException
{    int hashCode = init;    byte[] bytes = data.decoder.getBuf();    int start = data.decoder.getPos();    int end = start + len;    if (rev)        for (int i = end - 1; i >= start; i--) hashCode = hashCode * 31 + bytes[i];    else        for (int i = start; i < end; i++) hashCode = hashCode * 31 + bytes[i];    data.decoder.skipFixed(len);    return hashCode;}
0
public static int skipLong(byte[] bytes, int start)
{    int i = start;    for (int b = bytes[i++]; ((b & 0x80) != 0); b = bytes[i++]) {    }    return i;}
0
public static int encodeBoolean(boolean b, byte[] buf, int pos)
{    buf[pos] = b ? (byte) 1 : (byte) 0;    return 1;}
0
public static int encodeInt(int n, byte[] buf, int pos)
{        n = (n << 1) ^ (n >> 31);    int start = pos;    if ((n & ~0x7F) != 0) {        buf[pos++] = (byte) ((n | 0x80) & 0xFF);        n >>>= 7;        if (n > 0x7F) {            buf[pos++] = (byte) ((n | 0x80) & 0xFF);            n >>>= 7;            if (n > 0x7F) {                buf[pos++] = (byte) ((n | 0x80) & 0xFF);                n >>>= 7;                if (n > 0x7F) {                    buf[pos++] = (byte) ((n | 0x80) & 0xFF);                    n >>>= 7;                }            }        }    }    buf[pos++] = (byte) n;    return pos - start;}
0
public static int encodeLong(long n, byte[] buf, int pos)
{        n = (n << 1) ^ (n >> 63);    int start = pos;    if ((n & ~0x7FL) != 0) {        buf[pos++] = (byte) ((n | 0x80) & 0xFF);        n >>>= 7;        if (n > 0x7F) {            buf[pos++] = (byte) ((n | 0x80) & 0xFF);            n >>>= 7;            if (n > 0x7F) {                buf[pos++] = (byte) ((n | 0x80) & 0xFF);                n >>>= 7;                if (n > 0x7F) {                    buf[pos++] = (byte) ((n | 0x80) & 0xFF);                    n >>>= 7;                    if (n > 0x7F) {                        buf[pos++] = (byte) ((n | 0x80) & 0xFF);                        n >>>= 7;                        if (n > 0x7F) {                            buf[pos++] = (byte) ((n | 0x80) & 0xFF);                            n >>>= 7;                            if (n > 0x7F) {                                buf[pos++] = (byte) ((n | 0x80) & 0xFF);                                n >>>= 7;                                if (n > 0x7F) {                                    buf[pos++] = (byte) ((n | 0x80) & 0xFF);                                    n >>>= 7;                                    if (n > 0x7F) {                                        buf[pos++] = (byte) ((n | 0x80) & 0xFF);                                        n >>>= 7;                                    }                                }                            }                        }                    }                }            }        }    }    buf[pos++] = (byte) n;    return pos - start;}
0
public static int encodeFloat(float f, byte[] buf, int pos)
{    int len = 1;    int bits = Float.floatToRawIntBits(f);        buf[pos] = (byte) ((bits) & 0xFF);    buf[pos + len++] = (byte) ((bits >>> 8) & 0xFF);    buf[pos + len++] = (byte) ((bits >>> 16) & 0xFF);    buf[pos + len++] = (byte) ((bits >>> 24) & 0xFF);    return 4;}
0
public static int encodeDouble(double d, byte[] buf, int pos)
{    long bits = Double.doubleToRawLongBits(d);    int first = (int) (bits & 0xFFFFFFFF);    int second = (int) ((bits >>> 32) & 0xFFFFFFFF);            buf[pos] = (byte) ((first) & 0xFF);    buf[pos + 4] = (byte) ((second) & 0xFF);    buf[pos + 5] = (byte) ((second >>> 8) & 0xFF);    buf[pos + 1] = (byte) ((first >>> 8) & 0xFF);    buf[pos + 2] = (byte) ((first >>> 16) & 0xFF);    buf[pos + 6] = (byte) ((second >>> 16) & 0xFF);    buf[pos + 7] = (byte) ((second >>> 24) & 0xFF);    buf[pos + 3] = (byte) ((first >>> 24) & 0xFF);    return 8;}
0
 byte[] getBuf()
{    return buf;}
0
 int getPos()
{    return pos;}
0
 int getLimit()
{    return limit;}
0
 void setBuf(byte[] buf, int pos, int len)
{    this.buf = buf;    this.pos = pos;    this.limit = pos + len;}
0
 void clearBuf()
{    this.buf = null;}
0
 BinaryDecoder configure(InputStream in, int bufferSize)
{    configureSource(bufferSize, new InputStreamByteSource(in));    return this;}
0
 BinaryDecoder configure(byte[] data, int offset, int length)
{    configureSource(DecoderFactory.DEFAULT_BUFFER_SIZE, new ByteArrayByteSource(data, offset, length));    return this;}
0
private void configureSource(int bufferSize, ByteSource source)
{    if (null != this.source) {        this.source.detach();    }    source.attach(bufferSize, this);    this.source = source;}
0
public void readNull() throws IOException
{}
0
public boolean readBoolean() throws IOException
{        if (limit == pos) {        limit = source.tryReadRaw(buf, 0, buf.length);        pos = 0;        if (limit == 0) {            throw new EOFException();        }    }    int n = buf[pos++] & 0xff;    return n == 1;}
0
public int readInt() throws IOException
{        ensureBounds(5);    int len = 1;    int b = buf[pos] & 0xff;    int n = b & 0x7f;    if (b > 0x7f) {        b = buf[pos + len++] & 0xff;        n ^= (b & 0x7f) << 7;        if (b > 0x7f) {            b = buf[pos + len++] & 0xff;            n ^= (b & 0x7f) << 14;            if (b > 0x7f) {                b = buf[pos + len++] & 0xff;                n ^= (b & 0x7f) << 21;                if (b > 0x7f) {                    b = buf[pos + len++] & 0xff;                    n ^= (b & 0x7f) << 28;                    if (b > 0x7f) {                        throw new InvalidNumberEncodingException("Invalid int encoding");                    }                }            }        }    }    pos += len;    if (pos > limit) {        throw new EOFException();    }        return (n >>> 1) ^ -(n & 1);}
0
public long readLong() throws IOException
{    ensureBounds(10);    int b = buf[pos++] & 0xff;    int n = b & 0x7f;    long l;    if (b > 0x7f) {        b = buf[pos++] & 0xff;        n ^= (b & 0x7f) << 7;        if (b > 0x7f) {            b = buf[pos++] & 0xff;            n ^= (b & 0x7f) << 14;            if (b > 0x7f) {                b = buf[pos++] & 0xff;                n ^= (b & 0x7f) << 21;                if (b > 0x7f) {                                                            l = innerLongDecode((long) n);                } else {                    l = n;                }            } else {                l = n;            }        } else {            l = n;        }    } else {        l = n;    }    if (pos > limit) {        throw new EOFException();    }        return (l >>> 1) ^ -(l & 1);}
0
private long innerLongDecode(long l) throws IOException
{    int len = 1;    int b = buf[pos] & 0xff;    l ^= (b & 0x7fL) << 28;    if (b > 0x7f) {        b = buf[pos + len++] & 0xff;        l ^= (b & 0x7fL) << 35;        if (b > 0x7f) {            b = buf[pos + len++] & 0xff;            l ^= (b & 0x7fL) << 42;            if (b > 0x7f) {                b = buf[pos + len++] & 0xff;                l ^= (b & 0x7fL) << 49;                if (b > 0x7f) {                    b = buf[pos + len++] & 0xff;                    l ^= (b & 0x7fL) << 56;                    if (b > 0x7f) {                        b = buf[pos + len++] & 0xff;                        l ^= (b & 0x7fL) << 63;                        if (b > 0x7f) {                            throw new InvalidNumberEncodingException("Invalid long encoding");                        }                    }                }            }        }    }    pos += len;    return l;}
0
public float readFloat() throws IOException
{    ensureBounds(4);    int len = 1;    int n = (buf[pos] & 0xff) | ((buf[pos + len++] & 0xff) << 8) | ((buf[pos + len++] & 0xff) << 16) | ((buf[pos + len++] & 0xff) << 24);    if ((pos + 4) > limit) {        throw new EOFException();    }    pos += 4;    return Float.intBitsToFloat(n);}
0
public double readDouble() throws IOException
{    ensureBounds(8);    int len = 1;    int n1 = (buf[pos] & 0xff) | ((buf[pos + len++] & 0xff) << 8) | ((buf[pos + len++] & 0xff) << 16) | ((buf[pos + len++] & 0xff) << 24);    int n2 = (buf[pos + len++] & 0xff) | ((buf[pos + len++] & 0xff) << 8) | ((buf[pos + len++] & 0xff) << 16) | ((buf[pos + len++] & 0xff) << 24);    if ((pos + 8) > limit) {        throw new EOFException();    }    pos += 8;    return Double.longBitsToDouble((((long) n1) & 0xffffffffL) | (((long) n2) << 32));}
0
public Utf8 readString(Utf8 old) throws IOException
{    long length = readLong();    if (length > MAX_ARRAY_SIZE) {        throw new UnsupportedOperationException("Cannot read strings longer than " + MAX_ARRAY_SIZE + " bytes");    }    if (length < 0L) {        throw new AvroRuntimeException("Malformed data. Length is negative: " + length);    }    Utf8 result = (old != null ? old : new Utf8());    result.setByteLength((int) length);    if (0L != length) {        doReadBytes(result.getBytes(), 0, (int) length);    }    return result;}
0
public String readString() throws IOException
{    return readString(scratchUtf8).toString();}
0
public void skipString() throws IOException
{    doSkipBytes(readLong());}
0
public ByteBuffer readBytes(ByteBuffer old) throws IOException
{    int length = readInt();    ByteBuffer result;    if (old != null && length <= old.capacity()) {        result = old;        result.clear();    } else {        result = ByteBuffer.allocate(length);    }    doReadBytes(result.array(), result.position(), length);    result.limit(length);    return result;}
0
public void skipBytes() throws IOException
{    doSkipBytes(readLong());}
0
public void readFixed(byte[] bytes, int start, int length) throws IOException
{    doReadBytes(bytes, start, length);}
0
public void skipFixed(int length) throws IOException
{    doSkipBytes(length);}
0
public int readEnum() throws IOException
{    return readInt();}
0
protected void doSkipBytes(long length) throws IOException
{    int remaining = limit - pos;    if (length <= remaining) {        pos = (int) (pos + length);    } else {        limit = pos = 0;        length -= remaining;        source.skipSourceBytes(length);    }}
0
protected void doReadBytes(byte[] bytes, int start, int length) throws IOException
{    if (length < 0)        throw new AvroRuntimeException("Malformed data. Length is negative: " + length);    int remaining = limit - pos;    if (length <= remaining) {        System.arraycopy(buf, pos, bytes, start, length);        pos += length;    } else {                System.arraycopy(buf, pos, bytes, start, remaining);        start += remaining;        length -= remaining;        pos = limit;                source.readRaw(bytes, start, length);    }}
0
protected long doReadItemCount() throws IOException
{    long result = readLong();    if (result < 0L) {                readLong();        result = -result;    }    return result;}
0
private long doSkipItems() throws IOException
{    long result = readLong();    while (result < 0L) {        final long bytecount = readLong();        doSkipBytes(bytecount);        result = readLong();    }    return result;}
0
public long readArrayStart() throws IOException
{    return doReadItemCount();}
0
public long arrayNext() throws IOException
{    return doReadItemCount();}
0
public long skipArray() throws IOException
{    return doSkipItems();}
0
public long readMapStart() throws IOException
{    return doReadItemCount();}
0
public long mapNext() throws IOException
{    return doReadItemCount();}
0
public long skipMap() throws IOException
{    return doSkipItems();}
0
public int readIndex() throws IOException
{    return readInt();}
0
public boolean isEnd() throws IOException
{    if (pos < limit) {        return false;    }    if (source.isEof()) {        return true;    }        final int read = source.tryReadRaw(buf, 0, buf.length);    pos = 0;    limit = read;    return (0 == read);}
0
private void ensureBounds(int num) throws IOException
{    int remaining = limit - pos;    if (remaining < num) {                source.compactAndFill(buf, pos, minPos, remaining);        if (pos >= limit)            throw new EOFException();    }}
0
public InputStream inputStream()
{    return source;}
0
 void detach()
{    this.buf = decoder.buf;    this.pos = decoder.pos;    this.limit = decoder.limit;    detached = true;}
0
 int getPos()
{    if (detached)        return this.pos;    else        return decoder.pos;}
0
 int getLim()
{    if (detached)        return this.limit;    else        return decoder.limit;}
0
 byte[] getBuf()
{    if (detached)        return this.buf;    else        return decoder.buf;}
0
 void setPos(int pos)
{    if (detached)        this.pos = pos;    else        decoder.pos = pos;}
0
 void setLimit(int limit)
{    if (detached)        this.limit = limit;    else        decoder.limit = limit;}
0
 void setBuf(byte[] buf, int offset, int length)
{    if (detached) {        this.buf = buf;        this.limit = offset + length;        this.pos = offset;    } else {        decoder.buf = buf;        decoder.limit = offset + length;        decoder.pos = offset;        decoder.minPos = offset;    }}
0
protected void attach(int bufferSize, BinaryDecoder decoder)
{    decoder.buf = new byte[bufferSize];    decoder.pos = 0;    decoder.minPos = 0;    decoder.limit = 0;    this.ba = new BufferAccessor(decoder);}
0
protected void detach()
{    ba.detach();}
0
protected void compactAndFill(byte[] buf, int pos, int minPos, int remaining) throws IOException
{    System.arraycopy(buf, pos, buf, minPos, remaining);    ba.setPos(minPos);    int newLimit = remaining + tryReadRaw(buf, minPos + remaining, buf.length - remaining);    ba.setLimit(newLimit);}
0
public int read(byte[] b, int off, int len) throws IOException
{    int lim = ba.getLim();    int pos = ba.getPos();    byte[] buf = ba.getBuf();    int remaining = (lim - pos);    if (remaining >= len) {        System.arraycopy(buf, pos, b, off, len);        pos = pos + len;        ba.setPos(pos);        return len;    } else {                System.arraycopy(buf, pos, b, off, remaining);        pos = pos + remaining;        ba.setPos(pos);                int inputRead = remaining + tryReadRaw(b, off + remaining, len - remaining);        if (inputRead == 0) {            return -1;        } else {            return inputRead;        }    }}
0
public long skip(long n) throws IOException
{    int lim = ba.getLim();    int pos = ba.getPos();    int remaining = lim - pos;    if (remaining > n) {        pos = (int) (pos + n);        ba.setPos(pos);        return n;    } else {        pos = lim;        ba.setPos(pos);        long isSkipCount = trySkipBytes(n - remaining);        return isSkipCount + remaining;    }}
0
public int available() throws IOException
{    return (ba.getLim() - ba.getPos());}
0
protected void skipSourceBytes(long length) throws IOException
{    boolean readZero = false;    while (length > 0) {        long n = in.skip(length);        if (n > 0) {            length -= n;            continue;        }                if (n == 0) {            if (readZero) {                isEof = true;                throw new EOFException();            }            readZero = true;            continue;        }                isEof = true;        throw new EOFException();    }}
0
protected long trySkipBytes(long length) throws IOException
{    long leftToSkip = length;    try {        boolean readZero = false;        while (leftToSkip > 0) {            long n = in.skip(length);            if (n > 0) {                leftToSkip -= n;                continue;            }                        if (n == 0) {                if (readZero) {                    isEof = true;                    break;                }                readZero = true;                continue;            }                        isEof = true;            break;        }    } catch (EOFException eof) {        isEof = true;    }    return length - leftToSkip;}
0
protected void readRaw(byte[] data, int off, int len) throws IOException
{    while (len > 0) {        int read = in.read(data, off, len);        if (read < 0) {            isEof = true;            throw new EOFException();        }        len -= read;        off += read;    }}
0
protected int tryReadRaw(byte[] data, int off, int len) throws IOException
{    int leftToCopy = len;    try {        while (leftToCopy > 0) {            int read = in.read(data, off, leftToCopy);            if (read < 0) {                isEof = true;                break;            }            leftToCopy -= read;            off += read;        }    } catch (EOFException eof) {        isEof = true;    }    return len - leftToCopy;}
0
public int read() throws IOException
{    if (ba.getLim() - ba.getPos() == 0) {        return in.read();    } else {        int position = ba.getPos();        int result = ba.getBuf()[position] & 0xff;        ba.setPos(position + 1);        return result;    }}
0
public boolean isEof()
{    return isEof;}
0
public void close() throws IOException
{    in.close();}
0
protected void attach(int bufferSize, BinaryDecoder decoder)
{        decoder.buf = this.data;    decoder.pos = this.position;    decoder.minPos = this.position;    decoder.limit = this.max;    this.ba = new BufferAccessor(decoder);}
0
protected void skipSourceBytes(long length) throws IOException
{    long skipped = trySkipBytes(length);    if (skipped < length) {        throw new EOFException();    }}
0
protected long trySkipBytes(long length) throws IOException
{        max = ba.getLim();    position = ba.getPos();    long remaining = (long) max - position;    if (remaining >= length) {        position = (int) (position + length);        ba.setPos(position);        return length;    } else {        position += remaining;        ba.setPos(position);        return remaining;    }}
0
protected void readRaw(byte[] data, int off, int len) throws IOException
{    int read = tryReadRaw(data, off, len);    if (read < len) {        throw new EOFException();    }}
0
protected int tryReadRaw(byte[] data, int off, int len) throws IOException
{        return 0;}
0
protected void compactAndFill(byte[] buf, int pos, int minPos, int remaining) throws IOException
{        if (!compacted) {                byte[] tinybuf = new byte[remaining + 16];        System.arraycopy(buf, pos, tinybuf, 0, remaining);        ba.setBuf(tinybuf, 0, remaining);        compacted = true;    }}
0
public int read() throws IOException
{    max = ba.getLim();    position = ba.getPos();    if (position >= max) {        return -1;    } else {        int result = ba.getBuf()[position++] & 0xff;        ba.setPos(position);        return result;    }}
0
public void close() throws IOException
{        ba.setPos(ba.getLim());}
0
public boolean isEof()
{    int remaining = ba.getLim() - ba.getPos();    return (remaining == 0);}
0
public void writeNull() throws IOException
{}
0
public void writeString(Utf8 utf8) throws IOException
{    this.writeBytes(utf8.getBytes(), 0, utf8.getByteLength());}
0
public void writeString(String string) throws IOException
{    if (0 == string.length()) {        writeZero();        return;    }    byte[] bytes = string.getBytes(StandardCharsets.UTF_8);    writeInt(bytes.length);    writeFixed(bytes, 0, bytes.length);}
0
public void writeBytes(ByteBuffer bytes) throws IOException
{    int len = bytes.limit() - bytes.position();    if (0 == len) {        writeZero();    } else {        writeInt(len);        writeFixed(bytes);    }}
0
public void writeBytes(byte[] bytes, int start, int len) throws IOException
{    if (0 == len) {        writeZero();        return;    }    this.writeInt(len);    this.writeFixed(bytes, start, len);}
0
public void writeEnum(int e) throws IOException
{    this.writeInt(e);}
0
public void writeArrayStart() throws IOException
{}
0
public void setItemCount(long itemCount) throws IOException
{    if (itemCount > 0) {        this.writeLong(itemCount);    }}
0
public void startItem() throws IOException
{}
0
public void writeArrayEnd() throws IOException
{    writeZero();}
0
public void writeMapStart() throws IOException
{}
0
public void writeMapEnd() throws IOException
{    writeZero();}
0
public void writeIndex(int unionIndex) throws IOException
{    writeInt(unionIndex);}
0
public boolean check(BlockedValue prev, int pos)
{    assert state != State.ROOT || type == null;    assert (state == State.ROOT || type == Schema.Type.ARRAY || type == Schema.Type.MAP);    assert 0 <= items;        assert 0 != items || start == pos;        assert 1 < items || start == lastFullItem;        assert items <= 1 || start <= lastFullItem;    assert lastFullItem <= pos;    switch(state) {        case ROOT:            assert start == 0;            assert prev == null;            break;        case REGULAR:            assert start >= 0;            assert prev.lastFullItem <= start;            assert 1 <= prev.items;            break;        case OVERFLOW:            assert start == 0;            assert items == 1;            assert prev.state == State.ROOT || prev.state == State.OVERFLOW;            break;    }    return false;}
0
private boolean check()
{    assert buf != null;    assert 0 <= pos;    assert pos <= buf.length : pos + " " + buf.length;    assert blockStack != null;    BlockedValue prev = null;    for (int i = 0; i <= stackTop; i++) {        BlockedValue v = blockStack[i];        v.check(prev, pos);        prev = v;    }    return true;}
0
private void expandStack()
{    int oldLength = blockStack.length;    blockStack = Arrays.copyOf(blockStack, blockStack.length + STACK_STEP);    for (int i = oldLength; i < blockStack.length; i++) {        blockStack[i] = new BlockedValue();    }}
0
 BlockingBinaryEncoder configure(OutputStream out, int blockBufferSize, int binaryEncoderBufferSize)
{    super.configure(out, binaryEncoderBufferSize);    pos = 0;    stackTop = 0;    if (null == buf || buf.length != blockBufferSize) {        buf = new byte[blockBufferSize];    }    assert check();    return this;}
0
public void flush() throws IOException
{    BlockedValue bv = blockStack[stackTop];    if (bv.state == BlockedValue.State.ROOT) {        super.writeFixed(buf, 0, pos);        pos = 0;    } else {        while (bv.state != BlockedValue.State.OVERFLOW) {            compact();        }    }    super.flush();    assert check();}
0
public void writeBoolean(boolean b) throws IOException
{    ensureBounds(1);    pos += BinaryData.encodeBoolean(b, buf, pos);}
0
public void writeInt(int n) throws IOException
{    ensureBounds(5);    pos += BinaryData.encodeInt(n, buf, pos);}
0
public void writeLong(long n) throws IOException
{    ensureBounds(10);    pos += BinaryData.encodeLong(n, buf, pos);}
0
public void writeFloat(float f) throws IOException
{    ensureBounds(4);    pos += BinaryData.encodeFloat(f, buf, pos);}
0
public void writeDouble(double d) throws IOException
{    ensureBounds(8);    pos += BinaryData.encodeDouble(d, buf, pos);}
0
public void writeFixed(byte[] bytes, int start, int len) throws IOException
{    doWriteBytes(bytes, start, len);}
0
public void writeFixed(ByteBuffer bytes) throws IOException
{    int pos = bytes.position();    int len = bytes.remaining();    if (bytes.hasArray()) {        doWriteBytes(bytes.array(), bytes.arrayOffset() + pos, len);    } else {        byte[] b = new byte[len];        bytes.duplicate().get(b, 0, len);        doWriteBytes(b, 0, len);    }}
0
protected void writeZero() throws IOException
{    ensureBounds(1);    buf[pos++] = (byte) 0;}
0
public void writeArrayStart() throws IOException
{    if (stackTop + 1 == blockStack.length) {        expandStack();    }    BlockedValue bv = blockStack[++stackTop];    bv.type = Schema.Type.ARRAY;    bv.state = BlockedValue.State.REGULAR;    bv.start = bv.lastFullItem = pos;    bv.items = 0;    assert check();}
0
public void setItemCount(long itemCount) throws IOException
{    BlockedValue v = blockStack[stackTop];    assert v.type == Schema.Type.ARRAY || v.type == Schema.Type.MAP;    assert v.itemsLeftToWrite == 0;    v.itemsLeftToWrite = itemCount;    assert check();}
0
public void startItem() throws IOException
{    if (blockStack[stackTop].state == BlockedValue.State.OVERFLOW) {        finishOverflow();    }    BlockedValue t = blockStack[stackTop];    t.items++;    t.lastFullItem = pos;    t.itemsLeftToWrite--;    assert check();}
0
public void writeArrayEnd() throws IOException
{    BlockedValue top = blockStack[stackTop];    if (top.type != Schema.Type.ARRAY) {        throw new AvroTypeException("Called writeArrayEnd outside of an array.");    }    if (top.itemsLeftToWrite != 0) {        throw new AvroTypeException("Failed to write expected number of array elements.");    }    endBlockedValue();    assert check();}
0
public void writeMapStart() throws IOException
{    if (stackTop + 1 == blockStack.length) {        expandStack();    }    BlockedValue bv = blockStack[++stackTop];    bv.type = Schema.Type.MAP;    bv.state = BlockedValue.State.REGULAR;    bv.start = bv.lastFullItem = pos;    bv.items = 0;    assert check();}
0
public void writeMapEnd() throws IOException
{    BlockedValue top = blockStack[stackTop];    if (top.type != Schema.Type.MAP) {        throw new AvroTypeException("Called writeMapEnd outside of a map.");    }    if (top.itemsLeftToWrite != 0) {        throw new AvroTypeException("Failed to read write expected number of array elements.");    }    endBlockedValue();    assert check();}
0
public void writeIndex(int unionIndex) throws IOException
{    ensureBounds(5);    pos += BinaryData.encodeInt(unionIndex, buf, pos);}
0
public int bytesBuffered()
{    return pos + super.bytesBuffered();}
0
private void endBlockedValue() throws IOException
{    for (; ; ) {        assert check();        BlockedValue t = blockStack[stackTop];        assert t.state != BlockedValue.State.ROOT;        if (t.state == BlockedValue.State.OVERFLOW) {            finishOverflow();        }        assert t.state == BlockedValue.State.REGULAR;        if (0 < t.items) {            int byteCount = pos - t.start;            if (t.start == 0 && blockStack[stackTop - 1].state != BlockedValue.State.REGULAR) {                                                super.writeInt(-t.items);                super.writeInt(byteCount);            } else {                int headerSize = 0;                headerSize += BinaryData.encodeInt(-t.items, headerBuffer, headerSize);                headerSize += BinaryData.encodeInt(byteCount, headerBuffer, headerSize);                if (buf.length >= pos + headerSize) {                    pos += headerSize;                    final int m = t.start;                    System.arraycopy(buf, m, buf, m + headerSize, byteCount);                    System.arraycopy(headerBuffer, 0, buf, m, headerSize);                } else {                    compact();                    continue;                }            }        }        stackTop--;        ensureBounds(1);                buf[pos++] = 0;        assert check();        if (blockStack[stackTop].state == BlockedValue.State.ROOT) {            flush();        }        return;    }}
0
private void finishOverflow() throws IOException
{    BlockedValue s = blockStack[stackTop];    if (s.state != BlockedValue.State.OVERFLOW) {        throw new IllegalStateException("Not an overflow block");    }    assert check();        super.writeFixed(buf, 0, pos);    pos = 0;        s.state = BlockedValue.State.REGULAR;    s.start = s.lastFullItem = 0;    s.items = 0;    assert check();}
0
private void ensureBounds(int l) throws IOException
{    while (buf.length < (pos + l)) {        if (blockStack[stackTop].state == BlockedValue.State.REGULAR) {            compact();        } else {            super.writeFixed(buf, 0, pos);            pos = 0;        }    }}
0
private void doWriteBytes(byte[] bytes, int start, int len) throws IOException
{    if (len < buf.length) {        ensureBounds(len);        System.arraycopy(bytes, start, buf, pos, len);        pos += len;    } else {        ensureBounds(buf.length);        assert blockStack[stackTop].state == BlockedValue.State.ROOT || blockStack[stackTop].state == BlockedValue.State.OVERFLOW;        write(bytes, start, len);    }}
0
private void write(byte[] b, int off, int len) throws IOException
{    if (blockStack[stackTop].state == BlockedValue.State.ROOT) {        super.writeFixed(b, off, len);    } else {        assert check();        while (buf.length < (pos + len)) {            if (blockStack[stackTop].state == BlockedValue.State.REGULAR) {                compact();            } else {                super.writeFixed(buf, 0, pos);                pos = 0;                if (buf.length <= len) {                    super.writeFixed(b, off, len);                    len = 0;                }            }        }        System.arraycopy(b, off, buf, pos, len);        pos += len;    }    assert check();}
0
private void compact() throws IOException
{    assert check();        BlockedValue s = null;    int i;    for (i = 1; i <= stackTop; i++) {        s = blockStack[i];        if (s.state == BlockedValue.State.REGULAR)            break;    }    assert s != null;                                    super.writeFixed(buf, 0, s.start);        if (1 < s.items) {        super.writeInt(-(s.items - 1));        super.writeInt(s.lastFullItem - s.start);        super.writeFixed(buf, s.start, s.lastFullItem - s.start);        s.start = s.lastFullItem;        s.items = 1;    }        super.writeInt(1);            BlockedValue n = ((i + 1) <= stackTop ? blockStack[i + 1] : null);    int end = (n == null ? pos : n.start);    super.writeFixed(buf, s.lastFullItem, end - s.lastFullItem);        System.arraycopy(buf, end, buf, 0, pos - end);    for (int j = i + 1; j <= stackTop; j++) {        n = blockStack[j];        n.start -= end;        n.lastFullItem -= end;    }    pos -= end;    assert s.items == 1;    s.start = s.lastFullItem = 0;    s.state = BlockedValue.State.OVERFLOW;    assert check();}
0
 BufferedBinaryEncoder configure(OutputStream out, int bufferSize)
{    if (null == out)        throw new NullPointerException("OutputStream cannot be null!");    if (null != this.sink) {        if (pos > 0) {            try {                flushBuffer();            } catch (IOException e) {                throw new AvroRuntimeException("Failure flushing old output", e);            }        }    }    this.sink = new OutputStreamSink(out);    pos = 0;    if (null == buf || buf.length != bufferSize) {        buf = new byte[bufferSize];    }    bulkLimit = buf.length >>> 1;    if (bulkLimit > 512) {        bulkLimit = 512;    }    return this;}
0
public void flush() throws IOException
{    flushBuffer();    sink.innerFlush();}
0
private void flushBuffer() throws IOException
{    if (pos > 0) {        try {            sink.innerWrite(buf, 0, pos);        } finally {            pos = 0;        }    }}
0
private void ensureBounds(int num) throws IOException
{    int remaining = buf.length - pos;    if (remaining < num) {        flushBuffer();    }}
0
public void writeBoolean(boolean b) throws IOException
{        if (buf.length == pos) {        flushBuffer();    }    pos += BinaryData.encodeBoolean(b, buf, pos);}
0
public void writeInt(int n) throws IOException
{    ensureBounds(5);    pos += BinaryData.encodeInt(n, buf, pos);}
0
public void writeLong(long n) throws IOException
{    ensureBounds(10);    pos += BinaryData.encodeLong(n, buf, pos);}
0
public void writeFloat(float f) throws IOException
{    ensureBounds(4);    pos += BinaryData.encodeFloat(f, buf, pos);}
0
public void writeDouble(double d) throws IOException
{    ensureBounds(8);    pos += BinaryData.encodeDouble(d, buf, pos);}
0
public void writeFixed(byte[] bytes, int start, int len) throws IOException
{    if (len > bulkLimit) {                flushBuffer();        sink.innerWrite(bytes, start, len);        return;    }    ensureBounds(len);    System.arraycopy(bytes, start, buf, pos, len);    pos += len;}
0
public void writeFixed(ByteBuffer bytes) throws IOException
{    ByteBuffer readOnlyBytes = bytes.asReadOnlyBuffer();    if (!bytes.hasArray() && bytes.remaining() > bulkLimit) {        flushBuffer();                sink.innerWrite(readOnlyBytes);    } else {        super.writeFixed(readOnlyBytes);    }}
0
protected void writeZero() throws IOException
{    writeByte(0);}
0
private void writeByte(int b) throws IOException
{    if (pos == buf.length) {        flushBuffer();    }    buf[pos++] = (byte) (b & 0xFF);}
0
public int bytesBuffered()
{    return pos;}
0
protected void innerWrite(byte[] bytes, int off, int len) throws IOException
{    out.write(bytes, off, len);}
0
protected void innerFlush() throws IOException
{    out.flush();}
0
protected void innerWrite(ByteBuffer buff) throws IOException
{    channel.write(buff);}
0
public void readFixed(byte[] bytes) throws IOException
{    readFixed(bytes, 0, bytes.length);}
0
public static DecoderFactory defaultFactory()
{    return get();}
0
public static DecoderFactory get()
{    return DEFAULT_FACTORY;}
0
public DecoderFactory configureDecoderBufferSize(int size)
{    if (size < 32)        size = 32;    if (size > 16 * 1024 * 1024)        size = 16 * 1024 * 1024;    this.binaryDecoderBufferSize = size;    return this;}
0
public int getConfiguredBufferSize()
{    return this.binaryDecoderBufferSize;}
0
public BinaryDecoder createBinaryDecoder(InputStream in, BinaryDecoder reuse)
{    return binaryDecoder(in, reuse);}
0
public BinaryDecoder binaryDecoder(InputStream in, BinaryDecoder reuse)
{    if (null == reuse || !reuse.getClass().equals(BinaryDecoder.class)) {        return new BinaryDecoder(in, binaryDecoderBufferSize);    } else {        return reuse.configure(in, binaryDecoderBufferSize);    }}
0
public BinaryDecoder directBinaryDecoder(InputStream in, BinaryDecoder reuse)
{    if (null == reuse || !reuse.getClass().equals(DirectBinaryDecoder.class)) {        return new DirectBinaryDecoder(in);    } else {        return ((DirectBinaryDecoder) reuse).configure(in);    }}
0
public BinaryDecoder createBinaryDecoder(byte[] bytes, int offset, int length, BinaryDecoder reuse)
{    if (null == reuse || !reuse.getClass().equals(BinaryDecoder.class)) {        return new BinaryDecoder(bytes, offset, length);    } else {        return reuse.configure(bytes, offset, length);    }}
0
public BinaryDecoder binaryDecoder(byte[] bytes, int offset, int length, BinaryDecoder reuse)
{    if (null == reuse || !reuse.getClass().equals(BinaryDecoder.class)) {        return new BinaryDecoder(bytes, offset, length);    } else {        return reuse.configure(bytes, offset, length);    }}
0
public BinaryDecoder createBinaryDecoder(byte[] bytes, BinaryDecoder reuse)
{    return binaryDecoder(bytes, 0, bytes.length, reuse);}
0
public BinaryDecoder binaryDecoder(byte[] bytes, BinaryDecoder reuse)
{    return binaryDecoder(bytes, 0, bytes.length, reuse);}
0
public JsonDecoder jsonDecoder(Schema schema, InputStream input) throws IOException
{    return new JsonDecoder(schema, input);}
0
public JsonDecoder jsonDecoder(Schema schema, String input) throws IOException
{    return new JsonDecoder(schema, input);}
0
public ValidatingDecoder validatingDecoder(Schema schema, Decoder wrapped) throws IOException
{    return new ValidatingDecoder(schema, wrapped);}
0
public ResolvingDecoder resolvingDecoder(Schema writer, Schema reader, Decoder wrapped) throws IOException
{    return new ResolvingDecoder(writer, reader, wrapped);}
0
public DecoderFactory configureDecoderBufferSize(int bufferSize)
{    throw new IllegalArgumentException("This Factory instance is Immutable");}
0
public ByteBuffer read(ByteBuffer old, int length) throws IOException
{    ByteBuffer result;    if (old != null && length <= old.capacity()) {        result = old;        result.clear();    } else {        result = ByteBuffer.allocate(length);    }    doReadBytes(result.array(), result.position(), length);    result.limit(length);    return result;}
0
public ByteBuffer read(ByteBuffer old, int length) throws IOException
{    if (old != null) {        return super.read(old, length);    } else {        return bbi.readBuffer(length);    }}
0
 DirectBinaryDecoder configure(InputStream in)
{    this.in = in;    byteReader = (in instanceof ByteBufferInputStream) ? new ReuseByteReader((ByteBufferInputStream) in) : new ByteReader();    return this;}
0
public boolean readBoolean() throws IOException
{    int n = in.read();    if (n < 0) {        throw new EOFException();    }    return n == 1;}
0
public int readInt() throws IOException
{    int n = 0;    int b;    int shift = 0;    do {        b = in.read();        if (b >= 0) {            n |= (b & 0x7F) << shift;            if ((b & 0x80) == 0) {                                return (n >>> 1) ^ -(n & 1);            }        } else {            throw new EOFException();        }        shift += 7;    } while (shift < 32);    throw new InvalidNumberEncodingException("Invalid int encoding");}
0
public long readLong() throws IOException
{    long n = 0;    int b;    int shift = 0;    do {        b = in.read();        if (b >= 0) {            n |= (b & 0x7FL) << shift;            if ((b & 0x80) == 0) {                                return (n >>> 1) ^ -(n & 1);            }        } else {            throw new EOFException();        }        shift += 7;    } while (shift < 64);    throw new InvalidNumberEncodingException("Invalid long encoding");}
0
public float readFloat() throws IOException
{    doReadBytes(buf, 0, 4);    int n = (((int) buf[0]) & 0xff) | ((((int) buf[1]) & 0xff) << 8) | ((((int) buf[2]) & 0xff) << 16) | ((((int) buf[3]) & 0xff) << 24);    return Float.intBitsToFloat(n);}
0
public double readDouble() throws IOException
{    doReadBytes(buf, 0, 8);    long n = (((long) buf[0]) & 0xff) | ((((long) buf[1]) & 0xff) << 8) | ((((long) buf[2]) & 0xff) << 16) | ((((long) buf[3]) & 0xff) << 24) | ((((long) buf[4]) & 0xff) << 32) | ((((long) buf[5]) & 0xff) << 40) | ((((long) buf[6]) & 0xff) << 48) | ((((long) buf[7]) & 0xff) << 56);    return Double.longBitsToDouble(n);}
0
public ByteBuffer readBytes(ByteBuffer old) throws IOException
{    int length = readInt();    return byteReader.read(old, length);}
0
protected void doSkipBytes(long length) throws IOException
{    while (length > 0) {        long n = in.skip(length);        if (n <= 0) {            throw new EOFException();        }        length -= n;    }}
0
protected void doReadBytes(byte[] bytes, int start, int length) throws IOException
{    for (; ; ) {        int n = in.read(bytes, start, length);        if (n == length || length == 0) {            return;        } else if (n < 0) {            throw new EOFException();        }        start += n;        length -= n;    }}
0
public InputStream inputStream()
{    return in;}
0
public boolean isEnd() throws IOException
{    throw new UnsupportedOperationException();}
0
 DirectBinaryEncoder configure(OutputStream out)
{    if (null == out)        throw new NullPointerException("OutputStream cannot be null!");    this.out = out;    return this;}
0
public void flush() throws IOException
{    out.flush();}
0
public void writeBoolean(boolean b) throws IOException
{    out.write(b ? 1 : 0);}
0
public void writeInt(int n) throws IOException
{    int val = (n << 1) ^ (n >> 31);    if ((val & ~0x7F) == 0) {        out.write(val);        return;    } else if ((val & ~0x3FFF) == 0) {        out.write(0x80 | val);        out.write(val >>> 7);        return;    }    int len = BinaryData.encodeInt(n, buf, 0);    out.write(buf, 0, len);}
0
public void writeLong(long n) throws IOException
{        long val = (n << 1) ^ (n >> 63);    if ((val & ~0x7FFFFFFFL) == 0) {        int i = (int) val;        while ((i & ~0x7F) != 0) {            out.write((byte) ((0x80 | i) & 0xFF));            i >>>= 7;        }        out.write((byte) i);        return;    }    int len = BinaryData.encodeLong(n, buf, 0);    out.write(buf, 0, len);}
0
public void writeFloat(float f) throws IOException
{    int len = BinaryData.encodeFloat(f, buf, 0);    out.write(buf, 0, len);}
0
public void writeDouble(double d) throws IOException
{    int len = BinaryData.encodeDouble(d, buf, 0);    out.write(buf, 0, len);}
0
public void writeFixed(byte[] bytes, int start, int len) throws IOException
{    out.write(bytes, start, len);}
0
protected void writeZero() throws IOException
{    out.write(0);}
0
public int bytesBuffered()
{    return 0;}
0
public void writeString(String str) throws IOException
{    writeString(new Utf8(str));}
0
public void writeString(CharSequence charSequence) throws IOException
{    if (charSequence instanceof Utf8)        writeString((Utf8) charSequence);    else        writeString(charSequence.toString());}
0
public void writeBytes(byte[] bytes) throws IOException
{    writeBytes(bytes, 0, bytes.length);}
0
public void writeFixed(byte[] bytes) throws IOException
{    writeFixed(bytes, 0, bytes.length);}
0
public void writeFixed(ByteBuffer bytes) throws IOException
{    int pos = bytes.position();    int len = bytes.limit() - pos;    if (bytes.hasArray()) {        writeFixed(bytes.array(), bytes.arrayOffset() + pos, len);    } else {        byte[] b = new byte[len];        bytes.duplicate().get(b, 0, len);        writeFixed(b, 0, len);    }}
0
public static EncoderFactory get()
{    return DEFAULT_FACTORY;}
0
public EncoderFactory configureBufferSize(int size)
{    if (size < 32)        size = 32;    if (size > 16 * 1024 * 1024)        size = 16 * 1024 * 1024;    this.binaryBufferSize = size;    return this;}
0
public int getBufferSize()
{    return this.binaryBufferSize;}
0
public EncoderFactory configureBlockSize(int size)
{    if (size < MIN_BLOCK_BUFFER_SIZE)        size = MIN_BLOCK_BUFFER_SIZE;    if (size > MAX_BLOCK_BUFFER_SIZE)        size = MAX_BLOCK_BUFFER_SIZE;    this.binaryBlockSize = size;    return this;}
0
public int getBlockSize()
{    return this.binaryBlockSize;}
0
public BinaryEncoder binaryEncoder(OutputStream out, BinaryEncoder reuse)
{    if (null == reuse || !reuse.getClass().equals(BufferedBinaryEncoder.class)) {        return new BufferedBinaryEncoder(out, this.binaryBufferSize);    } else {        return ((BufferedBinaryEncoder) reuse).configure(out, this.binaryBufferSize);    }}
0
public BinaryEncoder directBinaryEncoder(OutputStream out, BinaryEncoder reuse)
{    if (null == reuse || !reuse.getClass().equals(DirectBinaryEncoder.class)) {        return new DirectBinaryEncoder(out);    } else {        return ((DirectBinaryEncoder) reuse).configure(out);    }}
0
public BinaryEncoder blockingBinaryEncoder(OutputStream out, BinaryEncoder reuse)
{    int blockSize = this.binaryBlockSize;    int bufferSize = (blockSize * 2 >= this.binaryBufferSize) ? 32 : this.binaryBufferSize;    if (null == reuse || !reuse.getClass().equals(BlockingBinaryEncoder.class)) {        return new BlockingBinaryEncoder(out, blockSize, bufferSize);    } else {        return ((BlockingBinaryEncoder) reuse).configure(out, blockSize, bufferSize);    }}
0
public JsonEncoder jsonEncoder(Schema schema, OutputStream out) throws IOException
{    return new JsonEncoder(schema, out);}
0
public JsonEncoder jsonEncoder(Schema schema, OutputStream out, boolean pretty) throws IOException
{    return new JsonEncoder(schema, out, pretty);}
0
 JsonEncoder jsonEncoder(Schema schema, JsonGenerator gen) throws IOException
{    return new JsonEncoder(schema, gen);}
0
public ValidatingEncoder validatingEncoder(Schema schema, Encoder encoder) throws IOException
{    return new ValidatingEncoder(schema, encoder);}
0
public EncoderFactory configureBlockSize(int size)
{    throw new AvroRuntimeException("Default EncoderFactory cannot be configured");}
0
public EncoderFactory configureBufferSize(int size)
{    throw new AvroRuntimeException("Default EncoderFactory cannot be configured");}
0
private static Symbol getSymbol(Schema schema)
{    if (null == schema) {        throw new NullPointerException("Schema cannot be null!");    }    return new JsonGrammarGenerator().generate(schema);}
0
public JsonDecoder configure(InputStream in) throws IOException
{    if (null == in) {        throw new NullPointerException("InputStream to read from cannot be null!");    }    parser.reset();    reorderBuffers.clear();    currentReorderBuffer = null;    this.in = jsonFactory.createParser(in);    this.in.nextToken();    return this;}
0
public JsonDecoder configure(String in) throws IOException
{    if (null == in) {        throw new NullPointerException("String to read from cannot be null!");    }    parser.reset();    reorderBuffers.clear();    currentReorderBuffer = null;    this.in = new JsonFactory().createParser(in);    this.in.nextToken();    return this;}
0
private void advance(Symbol symbol) throws IOException
{    this.parser.processTrailingImplicitActions();    if (in.getCurrentToken() == null && this.parser.depth() == 1)        throw new EOFException();    parser.advance(symbol);}
0
public void readNull() throws IOException
{    advance(Symbol.NULL);    if (in.getCurrentToken() == JsonToken.VALUE_NULL) {        in.nextToken();    } else {        throw error("null");    }}
0
public boolean readBoolean() throws IOException
{    advance(Symbol.BOOLEAN);    JsonToken t = in.getCurrentToken();    if (t == JsonToken.VALUE_TRUE || t == JsonToken.VALUE_FALSE) {        in.nextToken();        return t == JsonToken.VALUE_TRUE;    } else {        throw error("boolean");    }}
0
public int readInt() throws IOException
{    advance(Symbol.INT);    if (in.getCurrentToken().isNumeric()) {        int result = in.getIntValue();        in.nextToken();        return result;    } else {        throw error("int");    }}
0
public long readLong() throws IOException
{    advance(Symbol.LONG);    if (in.getCurrentToken().isNumeric()) {        long result = in.getLongValue();        in.nextToken();        return result;    } else {        throw error("long");    }}
0
public float readFloat() throws IOException
{    advance(Symbol.FLOAT);    if (in.getCurrentToken().isNumeric()) {        float result = in.getFloatValue();        in.nextToken();        return result;    } else {        throw error("float");    }}
0
public double readDouble() throws IOException
{    advance(Symbol.DOUBLE);    if (in.getCurrentToken().isNumeric()) {        double result = in.getDoubleValue();        in.nextToken();        return result;    } else {        throw error("double");    }}
0
public Utf8 readString(Utf8 old) throws IOException
{    return new Utf8(readString());}
0
public String readString() throws IOException
{    advance(Symbol.STRING);    if (parser.topSymbol() == Symbol.MAP_KEY_MARKER) {        parser.advance(Symbol.MAP_KEY_MARKER);        if (in.getCurrentToken() != JsonToken.FIELD_NAME) {            throw error("map-key");        }    } else {        if (in.getCurrentToken() != JsonToken.VALUE_STRING) {            throw error("string");        }    }    String result = in.getText();    in.nextToken();    return result;}
0
public void skipString() throws IOException
{    advance(Symbol.STRING);    if (parser.topSymbol() == Symbol.MAP_KEY_MARKER) {        parser.advance(Symbol.MAP_KEY_MARKER);        if (in.getCurrentToken() != JsonToken.FIELD_NAME) {            throw error("map-key");        }    } else {        if (in.getCurrentToken() != JsonToken.VALUE_STRING) {            throw error("string");        }    }    in.nextToken();}
0
public ByteBuffer readBytes(ByteBuffer old) throws IOException
{    advance(Symbol.BYTES);    if (in.getCurrentToken() == JsonToken.VALUE_STRING) {        byte[] result = readByteArray();        in.nextToken();        return ByteBuffer.wrap(result);    } else {        throw error("bytes");    }}
0
private byte[] readByteArray() throws IOException
{    byte[] result = in.getText().getBytes(StandardCharsets.ISO_8859_1);    return result;}
0
public void skipBytes() throws IOException
{    advance(Symbol.BYTES);    if (in.getCurrentToken() == JsonToken.VALUE_STRING) {        in.nextToken();    } else {        throw error("bytes");    }}
0
private void checkFixed(int size) throws IOException
{    advance(Symbol.FIXED);    Symbol.IntCheckAction top = (Symbol.IntCheckAction) parser.popSymbol();    if (size != top.size) {        throw new AvroTypeException("Incorrect length for fixed binary: expected " + top.size + " but received " + size + " bytes.");    }}
0
public void readFixed(byte[] bytes, int start, int len) throws IOException
{    checkFixed(len);    if (in.getCurrentToken() == JsonToken.VALUE_STRING) {        byte[] result = readByteArray();        in.nextToken();        if (result.length != len) {            throw new AvroTypeException("Expected fixed length " + len + ", but got" + result.length);        }        System.arraycopy(result, 0, bytes, start, len);    } else {        throw error("fixed");    }}
0
public void skipFixed(int length) throws IOException
{    checkFixed(length);    doSkipFixed(length);}
0
private void doSkipFixed(int length) throws IOException
{    if (in.getCurrentToken() == JsonToken.VALUE_STRING) {        byte[] result = readByteArray();        in.nextToken();        if (result.length != length) {            throw new AvroTypeException("Expected fixed length " + length + ", but got" + result.length);        }    } else {        throw error("fixed");    }}
0
protected void skipFixed() throws IOException
{    advance(Symbol.FIXED);    Symbol.IntCheckAction top = (Symbol.IntCheckAction) parser.popSymbol();    doSkipFixed(top.size);}
0
public int readEnum() throws IOException
{    advance(Symbol.ENUM);    Symbol.EnumLabelsAction top = (Symbol.EnumLabelsAction) parser.popSymbol();    if (in.getCurrentToken() == JsonToken.VALUE_STRING) {        in.getText();        int n = top.findLabel(in.getText());        if (n >= 0) {            in.nextToken();            return n;        }        throw new AvroTypeException("Unknown symbol in enum " + in.getText());    } else {        throw error("fixed");    }}
0
public long readArrayStart() throws IOException
{    advance(Symbol.ARRAY_START);    if (in.getCurrentToken() == JsonToken.START_ARRAY) {        in.nextToken();        return doArrayNext();    } else {        throw error("array-start");    }}
0
public long arrayNext() throws IOException
{    advance(Symbol.ITEM_END);    return doArrayNext();}
0
private long doArrayNext() throws IOException
{    if (in.getCurrentToken() == JsonToken.END_ARRAY) {        parser.advance(Symbol.ARRAY_END);        in.nextToken();        return 0;    } else {        return 1;    }}
0
public long skipArray() throws IOException
{    advance(Symbol.ARRAY_START);    if (in.getCurrentToken() == JsonToken.START_ARRAY) {        in.skipChildren();        in.nextToken();        advance(Symbol.ARRAY_END);    } else {        throw error("array-start");    }    return 0;}
0
public long readMapStart() throws IOException
{    advance(Symbol.MAP_START);    if (in.getCurrentToken() == JsonToken.START_OBJECT) {        in.nextToken();        return doMapNext();    } else {        throw error("map-start");    }}
0
public long mapNext() throws IOException
{    advance(Symbol.ITEM_END);    return doMapNext();}
0
private long doMapNext() throws IOException
{    if (in.getCurrentToken() == JsonToken.END_OBJECT) {        in.nextToken();        advance(Symbol.MAP_END);        return 0;    } else {        return 1;    }}
0
public long skipMap() throws IOException
{    advance(Symbol.MAP_START);    if (in.getCurrentToken() == JsonToken.START_OBJECT) {        in.skipChildren();        in.nextToken();        advance(Symbol.MAP_END);    } else {        throw error("map-start");    }    return 0;}
0
public int readIndex() throws IOException
{    advance(Symbol.UNION);    Symbol.Alternative a = (Symbol.Alternative) parser.popSymbol();    String label;    if (in.getCurrentToken() == JsonToken.VALUE_NULL) {        label = "null";    } else if (in.getCurrentToken() == JsonToken.START_OBJECT && in.nextToken() == JsonToken.FIELD_NAME) {        label = in.getText();        in.nextToken();        parser.pushSymbol(Symbol.UNION_END);    } else {        throw error("start-union");    }    int n = a.findLabel(label);    if (n < 0)        throw new AvroTypeException("Unknown union branch " + label);    parser.pushSymbol(a.getSymbol(n));    return n;}
0
public Symbol doAction(Symbol input, Symbol top) throws IOException
{    if (top instanceof Symbol.FieldAdjustAction) {        Symbol.FieldAdjustAction fa = (Symbol.FieldAdjustAction) top;        String name = fa.fname;        if (currentReorderBuffer != null) {            try (TokenBuffer tokenBuffer = currentReorderBuffer.savedFields.get(name)) {                if (tokenBuffer != null) {                    currentReorderBuffer.savedFields.remove(name);                    currentReorderBuffer.origParser = in;                    in = tokenBuffer.asParser();                    in.nextToken();                    return null;                }            }        }        if (in.getCurrentToken() == JsonToken.FIELD_NAME) {            do {                String fn = in.getText();                in.nextToken();                if (name.equals(fn) || fa.aliases.contains(fn)) {                    return null;                } else {                    if (currentReorderBuffer == null) {                        currentReorderBuffer = new ReorderBuffer();                    }                    try (TokenBuffer tokenBuffer = new TokenBuffer(in)) {                                                tokenBuffer.copyCurrentStructure(in);                        currentReorderBuffer.savedFields.put(fn, tokenBuffer);                    }                    in.nextToken();                }            } while (in.getCurrentToken() == JsonToken.FIELD_NAME);            throw new AvroTypeException("Expected field name not found: " + fa.fname);        }    } else if (top == Symbol.FIELD_END) {        if (currentReorderBuffer != null && currentReorderBuffer.origParser != null) {            in = currentReorderBuffer.origParser;            currentReorderBuffer.origParser = null;        }    } else if (top == Symbol.RECORD_START) {        if (in.getCurrentToken() == JsonToken.START_OBJECT) {            in.nextToken();            reorderBuffers.push(currentReorderBuffer);            currentReorderBuffer = null;        } else {            throw error("record-start");        }    } else if (top == Symbol.RECORD_END || top == Symbol.UNION_END) {                while (in.getCurrentToken() != JsonToken.END_OBJECT) {            in.nextToken();        }        if (top == Symbol.RECORD_END) {            if (currentReorderBuffer != null && !currentReorderBuffer.savedFields.isEmpty()) {                throw error("Unknown fields: " + currentReorderBuffer.savedFields.keySet());            }            currentReorderBuffer = reorderBuffers.pop();        }                in.nextToken();    } else {        throw new AvroTypeException("Unknown action symbol " + top);    }    return null;}
0
private AvroTypeException error(String type)
{    return new AvroTypeException("Expected " + type + ". Got " + in.getCurrentToken());}
0
public void flush() throws IOException
{    parser.processImplicitActions();    if (out != null) {        out.flush();    }}
0
private static JsonGenerator getJsonGenerator(OutputStream out, boolean pretty) throws IOException
{    if (null == out)        throw new NullPointerException("OutputStream cannot be null");    JsonGenerator g = new JsonFactory().createGenerator(out, JsonEncoding.UTF8);    if (pretty) {        DefaultPrettyPrinter pp = new DefaultPrettyPrinter() {            @Override            public void writeRootValueSeparator(JsonGenerator jg) throws IOException {                jg.writeRaw(LINE_SEPARATOR);            }        };        g.setPrettyPrinter(pp);    } else {        MinimalPrettyPrinter pp = new MinimalPrettyPrinter();        pp.setRootValueSeparator(LINE_SEPARATOR);        g.setPrettyPrinter(pp);    }    return g;}
0
public void writeRootValueSeparator(JsonGenerator jg) throws IOException
{    jg.writeRaw(LINE_SEPARATOR);}
0
public boolean isIncludeNamespace()
{    return includeNamespace;}
0
public void setIncludeNamespace(final boolean includeNamespace)
{    this.includeNamespace = includeNamespace;}
0
public JsonEncoder configure(OutputStream out) throws IOException
{    this.configure(getJsonGenerator(out, false));    return this;}
0
private JsonEncoder configure(JsonGenerator generator) throws IOException
{    if (null == generator)        throw new NullPointerException("JsonGenerator cannot be null");    if (null != parser) {        flush();    }    this.out = generator;    return this;}
0
public void writeNull() throws IOException
{    parser.advance(Symbol.NULL);    out.writeNull();}
0
public void writeBoolean(boolean b) throws IOException
{    parser.advance(Symbol.BOOLEAN);    out.writeBoolean(b);}
0
public void writeInt(int n) throws IOException
{    parser.advance(Symbol.INT);    out.writeNumber(n);}
0
public void writeLong(long n) throws IOException
{    parser.advance(Symbol.LONG);    out.writeNumber(n);}
0
public void writeFloat(float f) throws IOException
{    parser.advance(Symbol.FLOAT);    out.writeNumber(f);}
0
public void writeDouble(double d) throws IOException
{    parser.advance(Symbol.DOUBLE);    out.writeNumber(d);}
0
public void writeString(Utf8 utf8) throws IOException
{    writeString(utf8.toString());}
0
public void writeString(String str) throws IOException
{    parser.advance(Symbol.STRING);    if (parser.topSymbol() == Symbol.MAP_KEY_MARKER) {        parser.advance(Symbol.MAP_KEY_MARKER);        out.writeFieldName(str);    } else {        out.writeString(str);    }}
0
public void writeBytes(ByteBuffer bytes) throws IOException
{    if (bytes.hasArray()) {        writeBytes(bytes.array(), bytes.position(), bytes.remaining());    } else {        byte[] b = new byte[bytes.remaining()];        bytes.duplicate().get(b);        writeBytes(b);    }}
0
public void writeBytes(byte[] bytes, int start, int len) throws IOException
{    parser.advance(Symbol.BYTES);    writeByteArray(bytes, start, len);}
0
private void writeByteArray(byte[] bytes, int start, int len) throws IOException
{    out.writeString(new String(bytes, start, len, StandardCharsets.ISO_8859_1));}
0
public void writeFixed(byte[] bytes, int start, int len) throws IOException
{    parser.advance(Symbol.FIXED);    Symbol.IntCheckAction top = (Symbol.IntCheckAction) parser.popSymbol();    if (len != top.size) {        throw new AvroTypeException("Incorrect length for fixed binary: expected " + top.size + " but received " + len + " bytes.");    }    writeByteArray(bytes, start, len);}
0
public void writeEnum(int e) throws IOException
{    parser.advance(Symbol.ENUM);    Symbol.EnumLabelsAction top = (Symbol.EnumLabelsAction) parser.popSymbol();    if (e < 0 || e >= top.size) {        throw new AvroTypeException("Enumeration out of range: max is " + top.size + " but received " + e);    }    out.writeString(top.getLabel(e));}
0
public void writeArrayStart() throws IOException
{    parser.advance(Symbol.ARRAY_START);    out.writeStartArray();    push();    isEmpty.set(depth());}
0
public void writeArrayEnd() throws IOException
{    if (!isEmpty.get(pos)) {        parser.advance(Symbol.ITEM_END);    }    pop();    parser.advance(Symbol.ARRAY_END);    out.writeEndArray();}
0
public void writeMapStart() throws IOException
{    push();    isEmpty.set(depth());    parser.advance(Symbol.MAP_START);    out.writeStartObject();}
0
public void writeMapEnd() throws IOException
{    if (!isEmpty.get(pos)) {        parser.advance(Symbol.ITEM_END);    }    pop();    parser.advance(Symbol.MAP_END);    out.writeEndObject();}
0
public void startItem() throws IOException
{    if (!isEmpty.get(pos)) {        parser.advance(Symbol.ITEM_END);    }    super.startItem();    isEmpty.clear(depth());}
0
public void writeIndex(int unionIndex) throws IOException
{    parser.advance(Symbol.UNION);    Symbol.Alternative top = (Symbol.Alternative) parser.popSymbol();    Symbol symbol = top.getSymbol(unionIndex);    if (symbol != Symbol.NULL && includeNamespace) {        out.writeStartObject();        out.writeFieldName(top.getLabel(unionIndex));        parser.pushSymbol(Symbol.UNION_END);    }    parser.pushSymbol(symbol);}
0
public Symbol doAction(Symbol input, Symbol top) throws IOException
{    if (top instanceof Symbol.FieldAdjustAction) {        Symbol.FieldAdjustAction fa = (Symbol.FieldAdjustAction) top;        out.writeFieldName(fa.fname);    } else if (top == Symbol.RECORD_START) {        out.writeStartObject();    } else if (top == Symbol.RECORD_END || top == Symbol.UNION_END) {        out.writeEndObject();    } else if (top != Symbol.FIELD_END) {        throw new AvroTypeException("Unknown action symbol " + top);    }    return null;}
0
public Symbol generate(Schema schema)
{    return Symbol.root(generate(schema, new HashMap<>()));}
0
public Symbol generate(Schema sc, Map<LitS, Symbol> seen)
{    switch(sc.getType()) {        case NULL:        case BOOLEAN:        case INT:        case LONG:        case FLOAT:        case DOUBLE:        case STRING:        case BYTES:        case FIXED:        case UNION:            return super.generate(sc, seen);        case ENUM:            return Symbol.seq(Symbol.enumLabelsAction(sc.getEnumSymbols()), Symbol.ENUM);        case ARRAY:            return Symbol.seq(Symbol.repeat(Symbol.ARRAY_END, Symbol.ITEM_END, generate(sc.getElementType(), seen)), Symbol.ARRAY_START);        case MAP:            return Symbol.seq(Symbol.repeat(Symbol.MAP_END, Symbol.ITEM_END, generate(sc.getValueType(), seen), Symbol.MAP_KEY_MARKER, Symbol.STRING), Symbol.MAP_START);        case RECORD:            {                LitS wsc = new LitS(sc);                Symbol rresult = seen.get(wsc);                if (rresult == null) {                    Symbol[] production = new Symbol[sc.getFields().size() * 3 + 2];                    rresult = Symbol.seq(production);                    seen.put(wsc, rresult);                    int i = production.length;                    int n = 0;                    production[--i] = Symbol.RECORD_START;                    for (Field f : sc.getFields()) {                        production[--i] = Symbol.fieldAdjustAction(n, f.name(), f.aliases());                        production[--i] = generate(f.schema(), seen);                        production[--i] = Symbol.FIELD_END;                        n++;                    }                    production[--i] = Symbol.RECORD_END;                }                return rresult;            }        default:            throw new RuntimeException("Unexpected schema type");    }}
0
private void expandStack()
{    stack = Arrays.copyOf(stack, stack.length + Math.max(stack.length, 1024));}
0
public final Symbol advance(Symbol input) throws IOException
{    for (; ; ) {        Symbol top = stack[--pos];        if (top == input) {                        return top;        }        Symbol.Kind k = top.kind;        if (k == Symbol.Kind.IMPLICIT_ACTION) {            Symbol result = symbolHandler.doAction(input, top);            if (result != null) {                return result;            }        } else if (k == Symbol.Kind.TERMINAL) {            throw new AvroTypeException("Attempt to process a " + input + " when a " + top + " was expected.");        } else if (k == Symbol.Kind.REPEATER && input == ((Symbol.Repeater) top).end) {            return input;        } else {            pushProduction(top);        }    }}
0
public final void processImplicitActions() throws IOException
{    while (pos > 1) {        Symbol top = stack[pos - 1];        if (top.kind == Symbol.Kind.IMPLICIT_ACTION) {            pos--;            symbolHandler.doAction(null, top);        } else if (top.kind != Symbol.Kind.TERMINAL) {            pos--;            pushProduction(top);        } else {            break;        }    }}
0
public final void processTrailingImplicitActions() throws IOException
{    while (pos >= 1) {        Symbol top = stack[pos - 1];        if (top.kind == Symbol.Kind.IMPLICIT_ACTION && ((Symbol.ImplicitAction) top).isTrailing) {            pos--;            symbolHandler.doAction(null, top);        } else {            break;        }    }}
0
public final void pushProduction(Symbol sym)
{    Symbol[] p = sym.production;    while (pos + p.length > stack.length) {        expandStack();    }    System.arraycopy(p, 0, stack, pos, p.length);    pos += p.length;}
0
public Symbol popSymbol()
{    return stack[--pos];}
0
public Symbol topSymbol()
{    return stack[pos - 1];}
0
public void pushSymbol(Symbol sym)
{    if (pos == stack.length) {        expandStack();    }    stack[pos++] = sym;}
0
public int depth()
{    return pos;}
0
public void reset()
{    pos = 1;}
0
protected void encode(Encoder e, Schema s, JsonNode n) throws IOException
{    ResolvingGrammarGenerator.encode(e, s, n);}
0
public final Symbol generate(Schema writer, Schema reader) throws IOException
{    Resolver.Action r = Resolver.resolve(writer, reader);    return Symbol.root(generate(r, new HashMap<>()));}
0
private Symbol generate(Resolver.Action action, Map<Object, Symbol> seen) throws IOException
{    if (action instanceof Resolver.DoNothing) {        return simpleGen(action.writer, seen);    } else if (action instanceof Resolver.ErrorAction) {        return Symbol.error(action.toString());    } else if (action instanceof Resolver.Skip) {        return Symbol.skipAction(simpleGen(action.writer, seen));    } else if (action instanceof Resolver.Promote) {        return Symbol.resolve(simpleGen(action.writer, seen), simpleGen(action.reader, seen));    } else if (action instanceof Resolver.ReaderUnion) {        Resolver.ReaderUnion ru = (Resolver.ReaderUnion) action;        Symbol s = generate(ru.actualAction, seen);        return Symbol.seq(Symbol.unionAdjustAction(ru.firstMatch, s), Symbol.UNION);    } else if (action.writer.getType() == Schema.Type.ARRAY) {        Symbol es = generate(((Resolver.Container) action).elementAction, seen);        return Symbol.seq(Symbol.repeat(Symbol.ARRAY_END, es), Symbol.ARRAY_START);    } else if (action.writer.getType() == Schema.Type.MAP) {        Symbol es = generate(((Resolver.Container) action).elementAction, seen);        return Symbol.seq(Symbol.repeat(Symbol.MAP_END, es, Symbol.STRING), Symbol.MAP_START);    } else if (action.writer.getType() == Schema.Type.UNION) {        if (((Resolver.WriterUnion) action).unionEquiv)            return simpleGen(action.writer, seen);        Resolver.Action[] branches = ((Resolver.WriterUnion) action).actions;        Symbol[] symbols = new Symbol[branches.length];        String[] labels = new String[branches.length];        int i = 0;        for (Resolver.Action branch : branches) {            symbols[i] = generate(branch, seen);            labels[i] = action.writer.getTypes().get(i).getFullName();            i++;        }        return Symbol.seq(Symbol.alt(symbols, labels), Symbol.WRITER_UNION_ACTION);    } else if (action instanceof Resolver.EnumAdjust) {        Resolver.EnumAdjust e = (Resolver.EnumAdjust) action;        Object[] adjs = new Object[e.adjustments.length];        for (int i = 0; i < adjs.length; i++) adjs[i] = (0 <= e.adjustments[i] ? new Integer(e.adjustments[i]) : "No match for " + e.writer.getEnumSymbols().get(i));        return Symbol.seq(Symbol.enumAdjustAction(e.reader.getEnumSymbols().size(), adjs), Symbol.ENUM);    } else if (action instanceof Resolver.RecordAdjust) {        Symbol result = seen.get(action);        if (result == null) {            final Resolver.RecordAdjust ra = (Resolver.RecordAdjust) action;            int defaultCount = ra.readerOrder.length - ra.firstDefault;            int count = 1 + ra.fieldActions.length + 3 * defaultCount;            Symbol[] production = new Symbol[count];            result = Symbol.seq(production);            seen.put(action, result);            production[--count] = Symbol.fieldOrderAction(ra.readerOrder);            for (Resolver.Action wfa : ra.fieldActions) production[--count] = generate(wfa, seen);            for (int i = ra.firstDefault; i < ra.readerOrder.length; i++) {                Schema.Field rf = ra.readerOrder[i];                byte[] bb = getBinary(rf.schema(), Accessor.defaultValue(rf));                production[--count] = Symbol.defaultStartAction(bb);                production[--count] = simpleGen(rf.schema(), seen);                production[--count] = Symbol.DEFAULT_END_ACTION;            }        }        return result;    }    throw new IllegalArgumentException("Unrecognized Resolver.Action: " + action);}
0
private Symbol simpleGen(Schema s, Map<Object, Symbol> seen)
{    switch(s.getType()) {        case NULL:            return Symbol.NULL;        case BOOLEAN:            return Symbol.BOOLEAN;        case INT:            return Symbol.INT;        case LONG:            return Symbol.LONG;        case FLOAT:            return Symbol.FLOAT;        case DOUBLE:            return Symbol.DOUBLE;        case BYTES:            return Symbol.BYTES;        case STRING:            return Symbol.STRING;        case FIXED:            return Symbol.seq(new Symbol.IntCheckAction(s.getFixedSize()), Symbol.FIXED);        case ENUM:            return Symbol.seq(Symbol.enumAdjustAction(s.getEnumSymbols().size(), null), Symbol.ENUM);        case ARRAY:            return Symbol.seq(Symbol.repeat(Symbol.ARRAY_END, simpleGen(s.getElementType(), seen)), Symbol.ARRAY_START);        case MAP:            return Symbol.seq(Symbol.repeat(Symbol.MAP_END, simpleGen(s.getValueType(), seen), Symbol.STRING), Symbol.MAP_START);        case UNION:            {                List<Schema> subs = s.getTypes();                Symbol[] symbols = new Symbol[subs.size()];                String[] labels = new String[subs.size()];                int i = 0;                for (Schema b : s.getTypes()) {                    symbols[i] = simpleGen(b, seen);                    labels[i++] = b.getFullName();                }                return Symbol.seq(Symbol.alt(symbols, labels), Symbol.UNION);            }        case RECORD:            {                Symbol result = seen.get(s);                if (result == null) {                    Symbol[] production = new Symbol[s.getFields().size() + 1];                    result = Symbol.seq(production);                    seen.put(s, result);                    int i = production.length;                    production[--i] = Symbol.fieldOrderAction(s.getFields().toArray(new Schema.Field[0]));                    for (Field f : s.getFields()) production[--i] = simpleGen(f.schema(), seen);                                                                }                return result;            }        default:            throw new IllegalArgumentException("Unexpected schema: " + s);    }}
0
private static byte[] getBinary(Schema s, JsonNode n) throws IOException
{    ByteArrayOutputStream out = new ByteArrayOutputStream();    Encoder e = factory.binaryEncoder(out, null);    encode(e, s, n);    e.flush();    return out.toByteArray();}
0
 static void encode(Encoder e, Schema s, JsonNode n) throws IOException
{    switch(s.getType()) {        case RECORD:            for (Field f : s.getFields()) {                String name = f.name();                JsonNode v = n.get(name);                if (v == null) {                    v = Accessor.defaultValue(f);                }                if (v == null) {                    throw new AvroTypeException("No default value for: " + name);                }                encode(e, f.schema(), v);            }            break;        case ENUM:            e.writeEnum(s.getEnumOrdinal(n.textValue()));            break;        case ARRAY:            e.writeArrayStart();            e.setItemCount(n.size());            Schema i = s.getElementType();            for (JsonNode node : n) {                e.startItem();                encode(e, i, node);            }            e.writeArrayEnd();            break;        case MAP:            e.writeMapStart();            e.setItemCount(n.size());            Schema v = s.getValueType();            for (Iterator<String> it = n.fieldNames(); it.hasNext(); ) {                e.startItem();                String key = it.next();                e.writeString(key);                encode(e, v, n.get(key));            }            e.writeMapEnd();            break;        case UNION:            e.writeIndex(0);            encode(e, s.getTypes().get(0), n);            break;        case FIXED:            if (!n.isTextual())                throw new AvroTypeException("Non-string default value for fixed: " + n);            byte[] bb = n.textValue().getBytes(StandardCharsets.ISO_8859_1);            if (bb.length != s.getFixedSize()) {                bb = Arrays.copyOf(bb, s.getFixedSize());            }            e.writeFixed(bb);            break;        case STRING:            if (!n.isTextual())                throw new AvroTypeException("Non-string default value for string: " + n);            e.writeString(n.textValue());            break;        case BYTES:            if (!n.isTextual())                throw new AvroTypeException("Non-string default value for bytes: " + n);            e.writeBytes(n.textValue().getBytes(StandardCharsets.ISO_8859_1));            break;        case INT:            if (!n.isNumber())                throw new AvroTypeException("Non-numeric default value for int: " + n);            e.writeInt(n.intValue());            break;        case LONG:            if (!n.isNumber())                throw new AvroTypeException("Non-numeric default value for long: " + n);            e.writeLong(n.longValue());            break;        case FLOAT:            if (!n.isNumber())                throw new AvroTypeException("Non-numeric default value for float: " + n);            e.writeFloat((float) n.doubleValue());            break;        case DOUBLE:            if (!n.isNumber())                throw new AvroTypeException("Non-numeric default value for double: " + n);            e.writeDouble(n.doubleValue());            break;        case BOOLEAN:            if (!n.isBoolean())                throw new AvroTypeException("Non-boolean default for boolean: " + n);            e.writeBoolean(n.booleanValue());            break;        case NULL:            if (!n.isNull())                throw new AvroTypeException("Non-null default value for null type: " + n);            e.writeNull();            break;    }}
0
public final void skipTo(int target) throws IOException
{    outer: while (target < pos) {        Symbol top = stack[pos - 1];        while (top.kind != Symbol.Kind.TERMINAL) {            if (top.kind == Symbol.Kind.IMPLICIT_ACTION || top.kind == Symbol.Kind.EXPLICIT_ACTION) {                skipHandler.skipAction();            } else {                --pos;                pushProduction(top);            }            continue outer;        }        skipHandler.skipTopSymbol();    }}
0
public final void skipRepeater() throws IOException
{    int target = pos;    Symbol repeater = stack[--pos];    assert repeater.kind == Symbol.Kind.REPEATER;    pushProduction(repeater);    skipTo(target);}
0
public final void skipSymbol(Symbol symToSkip) throws IOException
{    int target = pos;    pushSymbol(symToSkip);    skipTo(target);}
0
 static Symbol root(Symbol... symbols)
{    return new Root(symbols);}
0
 static Symbol seq(Symbol... production)
{    return new Sequence(production);}
0
 static Symbol repeat(Symbol endSymbol, Symbol... symsToRepeat)
{    return new Repeater(endSymbol, symsToRepeat);}
0
 static Symbol alt(Symbol[] symbols, String[] labels)
{    return new Alternative(symbols, labels);}
0
 static Symbol error(String e)
{    return new ErrorAction(e);}
0
 static Symbol resolve(Symbol w, Symbol r)
{    return new ResolvingAction(w, r);}
0
public Symbol flatten(Map<Sequence, Sequence> map, Map<Sequence, List<Fixup>> map2)
{    return this;}
0
public int flattenedSize()
{    return 1;}
0
 static void flatten(Symbol[] in, int start, Symbol[] out, int skip, Map<Sequence, Sequence> map, Map<Sequence, List<Fixup>> map2)
{    for (int i = start, j = skip; i < in.length; i++) {        Symbol s = in[i].flatten(map, map2);        if (s instanceof Sequence) {            Symbol[] p = s.production;            List<Fixup> l = map2.get(s);            if (l == null) {                System.arraycopy(p, 0, out, j, p.length);                                for (List<Fixup> fixups : map2.values()) {                    copyFixups(fixups, out, j, p);                }            } else {                l.add(new Fixup(out, j));            }            j += p.length;        } else {            out[j++] = s;        }    }}
0
private static void copyFixups(List<Fixup> fixups, Symbol[] out, int outPos, Symbol[] toCopy)
{    for (int i = 0, n = fixups.size(); i < n; i += 1) {        Fixup fixup = fixups.get(i);        if (fixup.symbols == toCopy) {            fixups.add(new Fixup(out, fixup.pos + outPos));        }    }}
0
protected static int flattenedSize(Symbol[] symbols, int start)
{    int result = 0;    for (int i = start; i < symbols.length; i++) {        if (symbols[i] instanceof Sequence) {            Sequence s = (Sequence) symbols[i];            result += s.flattenedSize();        } else {            result += 1;        }    }    return result;}
0
public String toString()
{    return printName;}
0
private static Symbol[] makeProduction(Symbol[] symbols)
{    Symbol[] result = new Symbol[flattenedSize(symbols, 0) + 1];    flatten(symbols, 0, result, 1, new HashMap<>(), new HashMap<>());    return result;}
0
public Symbol get(int index)
{    return production[index];}
0
public int size()
{    return production.length;}
0
public Iterator<Symbol> iterator()
{    return new Iterator<Symbol>() {        private int pos = production.length;        @Override        public boolean hasNext() {            return 0 < pos;        }        @Override        public Symbol next() {            if (0 < pos) {                return production[--pos];            } else {                throw new NoSuchElementException();            }        }        @Override        public void remove() {            throw new UnsupportedOperationException();        }    };}
0
public boolean hasNext()
{    return 0 < pos;}
0
public Symbol next()
{    if (0 < pos) {        return production[--pos];    } else {        throw new NoSuchElementException();    }}
0
public void remove()
{    throw new UnsupportedOperationException();}
0
public Sequence flatten(Map<Sequence, Sequence> map, Map<Sequence, List<Fixup>> map2)
{    Sequence result = map.get(this);    if (result == null) {        result = new Sequence(new Symbol[flattenedSize()]);        map.put(this, result);        List<Fixup> l = new ArrayList<>();        map2.put(result, l);        flatten(production, 0, result.production, 0, map, map2);        for (Fixup f : l) {            System.arraycopy(result.production, 0, f.symbols, f.pos, result.production.length);        }        map2.remove(result);    }    return result;}
0
public final int flattenedSize()
{    return flattenedSize(production, 0);}
0
private static Symbol[] makeProduction(Symbol[] p)
{    Symbol[] result = new Symbol[p.length + 1];    System.arraycopy(p, 0, result, 1, p.length);    return result;}
0
public Repeater flatten(Map<Sequence, Sequence> map, Map<Sequence, List<Fixup>> map2)
{    Repeater result = new Repeater(end, new Symbol[flattenedSize(production, 1)]);    flatten(production, 1, result.production, 1, map, map2);    return result;}
0
public static boolean hasErrors(Symbol symbol)
{    return hasErrors(symbol, new HashSet<>());}
0
private static boolean hasErrors(Symbol symbol, Set<Symbol> visited)
{        if (visited.contains(symbol)) {        return false;    }    visited.add(symbol);    switch(symbol.kind) {        case ALTERNATIVE:            return hasErrors(symbol, ((Alternative) symbol).symbols, visited);        case EXPLICIT_ACTION:            return false;        case IMPLICIT_ACTION:            if (symbol instanceof ErrorAction) {                return true;            }            if (symbol instanceof UnionAdjustAction) {                return hasErrors(((UnionAdjustAction) symbol).symToParse, visited);            }            return false;        case REPEATER:            Repeater r = (Repeater) symbol;            return hasErrors(r.end, visited) || hasErrors(symbol, r.production, visited);        case ROOT:        case SEQUENCE:            return hasErrors(symbol, symbol.production, visited);        case TERMINAL:            return false;        default:            throw new RuntimeException("unknown symbol kind: " + symbol.kind);    }}
0
private static boolean hasErrors(Symbol root, Symbol[] symbols, Set<Symbol> visited)
{    if (null != symbols) {        for (Symbol s : symbols) {            if (s == root) {                continue;            }            if (hasErrors(s, visited)) {                return true;            }        }    }    return false;}
0
public Symbol getSymbol(int index)
{    return symbols[index];}
0
public String getLabel(int index)
{    return labels[index];}
0
public int size()
{    return symbols.length;}
0
public int findLabel(String label)
{    if (label != null) {        for (int i = 0; i < labels.length; i++) {            if (label.equals(labels[i])) {                return i;            }        }    }    return -1;}
0
public Alternative flatten(Map<Sequence, Sequence> map, Map<Sequence, List<Fixup>> map2)
{    Symbol[] ss = new Symbol[symbols.length];    for (int i = 0; i < ss.length; i++) {        ss[i] = symbols[i].flatten(map, map2);    }    return new Alternative(ss, labels);}
0
public static IntCheckAction intCheckAction(int size)
{    return new IntCheckAction(size);}
0
public static EnumAdjustAction enumAdjustAction(int rsymCount, Object[] adj)
{    return new EnumAdjustAction(rsymCount, adj);}
0
public static WriterUnionAction writerUnionAction()
{    return new WriterUnionAction();}
0
public ResolvingAction flatten(Map<Sequence, Sequence> map, Map<Sequence, List<Fixup>> map2)
{    return new ResolvingAction(writer.flatten(map, map2), reader.flatten(map, map2));}
0
public static SkipAction skipAction(Symbol symToSkip)
{    return new SkipAction(symToSkip);}
0
public SkipAction flatten(Map<Sequence, Sequence> map, Map<Sequence, List<Fixup>> map2)
{    return new SkipAction(symToSkip.flatten(map, map2));}
0
public static FieldAdjustAction fieldAdjustAction(int rindex, String fname, Set<String> aliases)
{    return new FieldAdjustAction(rindex, fname, aliases);}
0
public static FieldOrderAction fieldOrderAction(Schema.Field[] fields)
{    return new FieldOrderAction(fields);}
0
public static DefaultStartAction defaultStartAction(byte[] contents)
{    return new DefaultStartAction(contents);}
0
public static UnionAdjustAction unionAdjustAction(int rindex, Symbol sym)
{    return new UnionAdjustAction(rindex, sym);}
0
public UnionAdjustAction flatten(Map<Sequence, Sequence> map, Map<Sequence, List<Fixup>> map2)
{    return new UnionAdjustAction(rindex, symToParse.flatten(map, map2));}
0
public static EnumLabelsAction enumLabelsAction(List<String> symbols)
{    return new EnumLabelsAction(symbols);}
0
public String getLabel(int n)
{    return symbols.get(n);}
0
public int findLabel(String l)
{    if (l != null) {        for (int i = 0; i < symbols.size(); i++) {            if (l.equals(symbols.get(i))) {                return i;            }        }    }    return -1;}
0
public Symbol generate(Schema schema)
{    return Symbol.root(generate(schema, new HashMap<>()));}
0
public Symbol generate(Schema sc, Map<LitS, Symbol> seen)
{    switch(sc.getType()) {        case NULL:            return Symbol.NULL;        case BOOLEAN:            return Symbol.BOOLEAN;        case INT:            return Symbol.INT;        case LONG:            return Symbol.LONG;        case FLOAT:            return Symbol.FLOAT;        case DOUBLE:            return Symbol.DOUBLE;        case STRING:            return Symbol.STRING;        case BYTES:            return Symbol.BYTES;        case FIXED:            return Symbol.seq(Symbol.intCheckAction(sc.getFixedSize()), Symbol.FIXED);        case ENUM:            return Symbol.seq(Symbol.intCheckAction(sc.getEnumSymbols().size()), Symbol.ENUM);        case ARRAY:            return Symbol.seq(Symbol.repeat(Symbol.ARRAY_END, generate(sc.getElementType(), seen)), Symbol.ARRAY_START);        case MAP:            return Symbol.seq(Symbol.repeat(Symbol.MAP_END, generate(sc.getValueType(), seen), Symbol.STRING), Symbol.MAP_START);        case RECORD:            {                LitS wsc = new LitS(sc);                Symbol rresult = seen.get(wsc);                if (rresult == null) {                    Symbol[] production = new Symbol[sc.getFields().size()];                    /**                     * We construct a symbol without filling the array. Please see                     * {@link Symbol#production} for the reason.                     */                    rresult = Symbol.seq(production);                    seen.put(wsc, rresult);                    int i = production.length;                    for (Field f : sc.getFields()) {                        production[--i] = generate(f.schema(), seen);                    }                }                return rresult;            }        case UNION:            List<Schema> subs = sc.getTypes();            Symbol[] symbols = new Symbol[subs.size()];            String[] labels = new String[subs.size()];            int i = 0;            for (Schema b : sc.getTypes()) {                symbols[i] = generate(b, seen);                labels[i] = b.getFullName();                i++;            }            return Symbol.seq(Symbol.alt(symbols, labels), Symbol.UNION);        default:            throw new RuntimeException("Unexpected schema type");    }}
0
public boolean equals(Object o)
{    if (!(o instanceof LitS))        return false;    return actual.equals(((LitS) o).actual);}
0
public int hashCode()
{    return actual.hashCode();}
0
public void skipAction() throws IOException
{    parser.popSymbol();}
0
public void skipTopSymbol() throws IOException
{    Symbol top = parser.topSymbol();    if (top == Symbol.NULL) {        readNull();    }    if (top == Symbol.BOOLEAN) {        readBoolean();    } else if (top == Symbol.INT) {        readInt();    } else if (top == Symbol.LONG) {        readLong();    } else if (top == Symbol.FLOAT) {        readFloat();    } else if (top == Symbol.DOUBLE) {        readDouble();    } else if (top == Symbol.STRING) {        skipString();    } else if (top == Symbol.BYTES) {        skipBytes();    } else if (top == Symbol.ENUM) {        readEnum();    } else if (top == Symbol.FIXED) {        skipFixed();    } else if (top == Symbol.UNION) {        readIndex();    } else if (top == Symbol.ARRAY_START) {        skipArray();    } else if (top == Symbol.MAP_START) {        skipMap();    }}
0
public void setItemCount(long itemCount) throws IOException
{    if (counts[pos] != 0) {        throw new AvroTypeException("Incorrect number of items written. " + counts[pos] + " more required.");    }    counts[pos] = itemCount;}
0
public void startItem() throws IOException
{    counts[pos]--;}
0
protected final void push()
{    if (++pos == counts.length) {        counts = Arrays.copyOf(counts, pos + 10);    }    counts[pos] = 0;}
0
protected final void pop()
{    if (counts[pos] != 0) {        throw new AvroTypeException("Incorrect number of items written. " + counts[pos] + " more required.");    }    pos--;}
0
protected final int depth()
{    return pos;}
0
public static Object resolve(Schema writer, Schema reader) throws IOException
{    if (null == writer) {        throw new NullPointerException("writer cannot be null!");    }    if (null == reader) {        throw new NullPointerException("reader cannot be null!");    }    return new ResolvingGrammarGenerator().generate(writer, reader);}
0
public final Schema.Field[] readFieldOrder() throws IOException
{    return ((Symbol.FieldOrderAction) parser.advance(Symbol.FIELD_ACTION)).fields;}
0
public final Schema.Field[] readFieldOrderIfDiff() throws IOException
{    Symbol.FieldOrderAction top = (Symbol.FieldOrderAction) parser.advance(Symbol.FIELD_ACTION);    return (top.noReorder ? null : top.fields);}
0
public final void drain() throws IOException
{    parser.processImplicitActions();}
0
public long readLong() throws IOException
{    Symbol actual = parser.advance(Symbol.LONG);    if (actual == Symbol.INT) {        return in.readInt();    } else if (actual == Symbol.DOUBLE) {        return (long) in.readDouble();    } else {        assert actual == Symbol.LONG;        return in.readLong();    }}
0
public float readFloat() throws IOException
{    Symbol actual = parser.advance(Symbol.FLOAT);    if (actual == Symbol.INT) {        return (float) in.readInt();    } else if (actual == Symbol.LONG) {        return (float) in.readLong();    } else {        assert actual == Symbol.FLOAT;        return in.readFloat();    }}
0
public double readDouble() throws IOException
{    Symbol actual = parser.advance(Symbol.DOUBLE);    if (actual == Symbol.INT) {        return (double) in.readInt();    } else if (actual == Symbol.LONG) {        return (double) in.readLong();    } else if (actual == Symbol.FLOAT) {        return (double) in.readFloat();    } else {        assert actual == Symbol.DOUBLE;        return in.readDouble();    }}
0
public Utf8 readString(Utf8 old) throws IOException
{    Symbol actual = parser.advance(Symbol.STRING);    if (actual == Symbol.BYTES) {        return new Utf8(in.readBytes(null).array());    } else {        assert actual == Symbol.STRING;        return in.readString(old);    }}
0
public String readString() throws IOException
{    Symbol actual = parser.advance(Symbol.STRING);    if (actual == Symbol.BYTES) {        return new String(in.readBytes(null).array(), StandardCharsets.UTF_8);    } else {        assert actual == Symbol.STRING;        return in.readString();    }}
0
public void skipString() throws IOException
{    Symbol actual = parser.advance(Symbol.STRING);    if (actual == Symbol.BYTES) {        in.skipBytes();    } else {        assert actual == Symbol.STRING;        in.skipString();    }}
0
public ByteBuffer readBytes(ByteBuffer old) throws IOException
{    Symbol actual = parser.advance(Symbol.BYTES);    if (actual == Symbol.STRING) {        Utf8 s = in.readString(null);        return ByteBuffer.wrap(s.getBytes(), 0, s.getByteLength());    } else {        assert actual == Symbol.BYTES;        return in.readBytes(old);    }}
0
public void skipBytes() throws IOException
{    Symbol actual = parser.advance(Symbol.BYTES);    if (actual == Symbol.STRING) {        in.skipString();    } else {        assert actual == Symbol.BYTES;        in.skipBytes();    }}
0
public int readEnum() throws IOException
{    parser.advance(Symbol.ENUM);    Symbol.EnumAdjustAction top = (Symbol.EnumAdjustAction) parser.popSymbol();    int n = in.readEnum();    if (top.noAdjustments)        return n;    Object o = top.adjustments[n];    if (o instanceof Integer) {        return (Integer) o;    } else {        throw new AvroTypeException((String) o);    }}
0
public int readIndex() throws IOException
{    parser.advance(Symbol.UNION);    Symbol top = parser.popSymbol();    int result;    if (top instanceof Symbol.UnionAdjustAction) {        result = ((Symbol.UnionAdjustAction) top).rindex;        top = ((Symbol.UnionAdjustAction) top).symToParse;    } else {        result = in.readIndex();        top = ((Symbol.Alternative) top).getSymbol(result);    }    parser.pushSymbol(top);    return result;}
0
public Symbol doAction(Symbol input, Symbol top) throws IOException
{    if (top instanceof Symbol.FieldOrderAction) {        return input == Symbol.FIELD_ACTION ? top : null;    }    if (top instanceof Symbol.ResolvingAction) {        Symbol.ResolvingAction t = (Symbol.ResolvingAction) top;        if (t.reader != input) {            throw new AvroTypeException("Found " + t.reader + " while looking for " + input);        } else {            return t.writer;        }    } else if (top instanceof Symbol.SkipAction) {        Symbol symToSkip = ((Symbol.SkipAction) top).symToSkip;        parser.skipSymbol(symToSkip);    } else if (top instanceof Symbol.WriterUnionAction) {        Symbol.Alternative branches = (Symbol.Alternative) parser.popSymbol();        parser.pushSymbol(branches.getSymbol(in.readIndex()));    } else if (top instanceof Symbol.ErrorAction) {        throw new AvroTypeException(((Symbol.ErrorAction) top).msg);    } else if (top instanceof Symbol.DefaultStartAction) {        Symbol.DefaultStartAction dsa = (Symbol.DefaultStartAction) top;        backup = in;        in = DecoderFactory.get().binaryDecoder(dsa.contents, null);    } else if (top == Symbol.DEFAULT_END_ACTION) {        in = backup;    } else {        throw new AvroTypeException("Unknown action: " + top);    }    return null;}
0
public void skipAction() throws IOException
{    Symbol top = parser.popSymbol();    if (top instanceof Symbol.ResolvingAction) {        parser.pushSymbol(((Symbol.ResolvingAction) top).writer);    } else if (top instanceof Symbol.SkipAction) {        parser.pushSymbol(((Symbol.SkipAction) top).symToSkip);    } else if (top instanceof Symbol.WriterUnionAction) {        Symbol.Alternative branches = (Symbol.Alternative) parser.popSymbol();        parser.pushSymbol(branches.getSymbol(in.readIndex()));    } else if (top instanceof Symbol.ErrorAction) {        throw new AvroTypeException(((Symbol.ErrorAction) top).msg);    } else if (top instanceof Symbol.DefaultStartAction) {        Symbol.DefaultStartAction dsa = (Symbol.DefaultStartAction) top;        backup = in;        in = DecoderFactory.get().binaryDecoder(dsa.contents, null);    } else if (top == Symbol.DEFAULT_END_ACTION) {        in = backup;    }}
0
private static Symbol getSymbol(Schema schema)
{    if (null == schema) {        throw new NullPointerException("Schema cannot be null");    }    return new ValidatingGrammarGenerator().generate(schema);}
0
public ValidatingDecoder configure(Decoder in) throws IOException
{    this.parser.reset();    this.in = in;    return this;}
0
public void readNull() throws IOException
{    parser.advance(Symbol.NULL);    in.readNull();}
0
public boolean readBoolean() throws IOException
{    parser.advance(Symbol.BOOLEAN);    return in.readBoolean();}
0
public int readInt() throws IOException
{    parser.advance(Symbol.INT);    return in.readInt();}
0
public long readLong() throws IOException
{    parser.advance(Symbol.LONG);    return in.readLong();}
0
public float readFloat() throws IOException
{    parser.advance(Symbol.FLOAT);    return in.readFloat();}
0
public double readDouble() throws IOException
{    parser.advance(Symbol.DOUBLE);    return in.readDouble();}
0
public Utf8 readString(Utf8 old) throws IOException
{    parser.advance(Symbol.STRING);    return in.readString(old);}
0
public String readString() throws IOException
{    parser.advance(Symbol.STRING);    return in.readString();}
0
public void skipString() throws IOException
{    parser.advance(Symbol.STRING);    in.skipString();}
0
public ByteBuffer readBytes(ByteBuffer old) throws IOException
{    parser.advance(Symbol.BYTES);    return in.readBytes(old);}
0
public void skipBytes() throws IOException
{    parser.advance(Symbol.BYTES);    in.skipBytes();}
0
private void checkFixed(int size) throws IOException
{    parser.advance(Symbol.FIXED);    Symbol.IntCheckAction top = (Symbol.IntCheckAction) parser.popSymbol();    if (size != top.size) {        throw new AvroTypeException("Incorrect length for fixed binary: expected " + top.size + " but received " + size + " bytes.");    }}
0
public void readFixed(byte[] bytes, int start, int len) throws IOException
{    checkFixed(len);    in.readFixed(bytes, start, len);}
0
public void skipFixed(int length) throws IOException
{    checkFixed(length);    in.skipFixed(length);}
0
protected void skipFixed() throws IOException
{    parser.advance(Symbol.FIXED);    Symbol.IntCheckAction top = (Symbol.IntCheckAction) parser.popSymbol();    in.skipFixed(top.size);}
0
public int readEnum() throws IOException
{    parser.advance(Symbol.ENUM);    Symbol.IntCheckAction top = (Symbol.IntCheckAction) parser.popSymbol();    int result = in.readEnum();    if (result < 0 || result >= top.size) {        throw new AvroTypeException("Enumeration out of range: max is " + top.size + " but received " + result);    }    return result;}
0
public long readArrayStart() throws IOException
{    parser.advance(Symbol.ARRAY_START);    long result = in.readArrayStart();    if (result == 0) {        parser.advance(Symbol.ARRAY_END);    }    return result;}
0
public long arrayNext() throws IOException
{    parser.processTrailingImplicitActions();    long result = in.arrayNext();    if (result == 0) {        parser.advance(Symbol.ARRAY_END);    }    return result;}
0
public long skipArray() throws IOException
{    parser.advance(Symbol.ARRAY_START);    for (long c = in.skipArray(); c != 0; c = in.skipArray()) {        while (c-- > 0) {            parser.skipRepeater();        }    }    parser.advance(Symbol.ARRAY_END);    return 0;}
0
public long readMapStart() throws IOException
{    parser.advance(Symbol.MAP_START);    long result = in.readMapStart();    if (result == 0) {        parser.advance(Symbol.MAP_END);    }    return result;}
0
public long mapNext() throws IOException
{    parser.processTrailingImplicitActions();    long result = in.mapNext();    if (result == 0) {        parser.advance(Symbol.MAP_END);    }    return result;}
0
public long skipMap() throws IOException
{    parser.advance(Symbol.MAP_START);    for (long c = in.skipMap(); c != 0; c = in.skipMap()) {        while (c-- > 0) {            parser.skipRepeater();        }    }    parser.advance(Symbol.MAP_END);    return 0;}
0
public int readIndex() throws IOException
{    parser.advance(Symbol.UNION);    Symbol.Alternative top = (Symbol.Alternative) parser.popSymbol();    int result = in.readIndex();    parser.pushSymbol(top.getSymbol(result));    return result;}
0
public Symbol doAction(Symbol input, Symbol top) throws IOException
{    return null;}
0
public void flush() throws IOException
{    out.flush();}
0
public ValidatingEncoder configure(Encoder encoder)
{    this.parser.reset();    this.out = encoder;    return this;}
0
public void writeNull() throws IOException
{    parser.advance(Symbol.NULL);    out.writeNull();}
0
public void writeBoolean(boolean b) throws IOException
{    parser.advance(Symbol.BOOLEAN);    out.writeBoolean(b);}
0
public void writeInt(int n) throws IOException
{    parser.advance(Symbol.INT);    out.writeInt(n);}
0
public void writeLong(long n) throws IOException
{    parser.advance(Symbol.LONG);    out.writeLong(n);}
0
public void writeFloat(float f) throws IOException
{    parser.advance(Symbol.FLOAT);    out.writeFloat(f);}
0
public void writeDouble(double d) throws IOException
{    parser.advance(Symbol.DOUBLE);    out.writeDouble(d);}
0
public void writeString(Utf8 utf8) throws IOException
{    parser.advance(Symbol.STRING);    out.writeString(utf8);}
0
public void writeString(String str) throws IOException
{    parser.advance(Symbol.STRING);    out.writeString(str);}
0
public void writeString(CharSequence charSequence) throws IOException
{    parser.advance(Symbol.STRING);    out.writeString(charSequence);}
0
public void writeBytes(ByteBuffer bytes) throws IOException
{    parser.advance(Symbol.BYTES);    out.writeBytes(bytes);}
0
public void writeBytes(byte[] bytes, int start, int len) throws IOException
{    parser.advance(Symbol.BYTES);    out.writeBytes(bytes, start, len);}
0
public void writeFixed(byte[] bytes, int start, int len) throws IOException
{    parser.advance(Symbol.FIXED);    Symbol.IntCheckAction top = (Symbol.IntCheckAction) parser.popSymbol();    if (len != top.size) {        throw new AvroTypeException("Incorrect length for fixed binary: expected " + top.size + " but received " + len + " bytes.");    }    out.writeFixed(bytes, start, len);}
0
public void writeEnum(int e) throws IOException
{    parser.advance(Symbol.ENUM);    Symbol.IntCheckAction top = (Symbol.IntCheckAction) parser.popSymbol();    if (e < 0 || e >= top.size) {        throw new AvroTypeException("Enumeration out of range: max is " + top.size + " but received " + e);    }    out.writeEnum(e);}
0
public void writeArrayStart() throws IOException
{    push();    parser.advance(Symbol.ARRAY_START);    out.writeArrayStart();}
0
public void writeArrayEnd() throws IOException
{    parser.advance(Symbol.ARRAY_END);    out.writeArrayEnd();    pop();}
0
public void writeMapStart() throws IOException
{    push();    parser.advance(Symbol.MAP_START);    out.writeMapStart();}
0
public void writeMapEnd() throws IOException
{    parser.advance(Symbol.MAP_END);    out.writeMapEnd();    pop();}
0
public void setItemCount(long itemCount) throws IOException
{    super.setItemCount(itemCount);    out.setItemCount(itemCount);}
0
public void startItem() throws IOException
{    super.startItem();    out.startItem();}
0
public void writeIndex(int unionIndex) throws IOException
{    parser.advance(Symbol.UNION);    Symbol.Alternative top = (Symbol.Alternative) parser.popSymbol();    parser.pushSymbol(top.getSymbol(unionIndex));    out.writeIndex(unionIndex);}
0
public Symbol doAction(Symbol input, Symbol top) throws IOException
{    return null;}
0
protected void addProp(JsonProperties props, String name, JsonNode value)
{    props.addProp(name, value);}
0
public JsonNode putIfAbsent(String key, JsonNode value)
{    JsonNode r = super.putIfAbsent(key, value);    if (r == null) {        propOrder.add(new MapEntry<>(key, value));    }    return r;}
0
public JsonNode put(String key, JsonNode value)
{    return putIfAbsent(key, value);}
0
public Set<Map.Entry<String, JsonNode>> entrySet()
{    return new AbstractSet<Map.Entry<String, JsonNode>>() {        @Override        public Iterator<Map.Entry<String, JsonNode>> iterator() {            return new Iterator<Map.Entry<String, JsonNode>>() {                Iterator<MapEntry<String, JsonNode>> it = propOrder.iterator();                @Override                public boolean hasNext() {                    return it.hasNext();                }                @Override                public java.util.Map.Entry<String, JsonNode> next() {                    return it.next();                }            };        }        @Override        public int size() {            return propOrder.size();        }    };}
0
public Iterator<Map.Entry<String, JsonNode>> iterator()
{    return new Iterator<Map.Entry<String, JsonNode>>() {        Iterator<MapEntry<String, JsonNode>> it = propOrder.iterator();        @Override        public boolean hasNext() {            return it.hasNext();        }        @Override        public java.util.Map.Entry<String, JsonNode> next() {            return it.next();        }    };}
0
public boolean hasNext()
{    return it.hasNext();}
0
public java.util.Map.Entry<String, JsonNode> next()
{    return it.next();}
0
public int size()
{    return propOrder.size();}
0
public String getProp(String name)
{    JsonNode value = getJsonProp(name);    return value != null && value.isTextual() ? value.textValue() : null;}
0
private JsonNode getJsonProp(String name)
{    return props.get(name);}
0
public Object getObjectProp(String name)
{    return JacksonUtils.toObject(props.get(name));}
0
public void addProp(String name, String value)
{    addProp(name, TextNode.valueOf(value));}
0
public void addProp(String name, Object value)
{    if (value instanceof JsonNode) {        addProp(name, (JsonNode) value);    } else {        addProp(name, JacksonUtils.toJsonNode(value));    }}
0
public void putAll(JsonProperties np)
{    for (Map.Entry<? extends String, ? extends JsonNode> e : np.props.entrySet()) addProp(e.getKey(), e.getValue());}
0
private void addProp(String name, JsonNode value)
{    if (reserved.contains(name))        throw new AvroRuntimeException("Can't set reserved property: " + name);    if (value == null)        throw new AvroRuntimeException("Can't set a property to null: " + name);    JsonNode old = props.putIfAbsent(name, value);    if (old != null && !old.equals(value)) {        throw new AvroRuntimeException("Can't overwrite property: " + name);    }}
0
public void addAllProps(JsonProperties properties)
{    for (Entry<String, JsonNode> entry : properties.props.entrySet()) addProp(entry.getKey(), entry.getValue());}
0
public Map<String, Object> getObjectProps()
{    Map<String, Object> result = new LinkedHashMap<>();    for (Map.Entry<String, JsonNode> e : props.entrySet()) result.put(e.getKey(), JacksonUtils.toObject(e.getValue()));    return Collections.unmodifiableMap(result);}
0
 void writeProps(JsonGenerator gen) throws IOException
{    for (Map.Entry<String, JsonNode> e : props.entrySet()) gen.writeObjectField(e.getKey(), e.getValue());}
0
 int propsHashCode()
{    return props.hashCode();}
0
 boolean propsEqual(JsonProperties np)
{    return props.equals(np.props);}
0
public boolean hasProps()
{    return !props.isEmpty();}
0
public String getName()
{    return name;}
0
public Schema addToSchema(Schema schema)
{    validate(schema);    schema.addProp(LOGICAL_TYPE_PROP, name);    schema.setLogicalType(this);    return schema;}
0
public void validate(Schema schema)
{    for (String incompatible : INCOMPATIBLE_PROPS) {        if (schema.getProp(incompatible) != null) {            throw new IllegalArgumentException(LOGICAL_TYPE_PROP + " cannot be used with " + incompatible);        }    }}
0
public static void register(String logicalTypeName, LogicalTypeFactory factory)
{    if (logicalTypeName == null) {        throw new NullPointerException("Invalid logical type name: null");    }    if (factory == null) {        throw new NullPointerException("Invalid logical type factory: null");    }    REGISTERED_TYPES.put(logicalTypeName, factory);}
0
public static LogicalType fromSchema(Schema schema)
{    return fromSchemaImpl(schema, true);}
0
public static LogicalType fromSchemaIgnoreInvalid(Schema schema)
{    return fromSchemaImpl(schema, false);}
0
private static LogicalType fromSchemaImpl(Schema schema, boolean throwErrors)
{    final LogicalType logicalType;    final String typeName = schema.getProp(LogicalType.LOGICAL_TYPE_PROP);    if (typeName == null) {        return null;    }    try {        switch(typeName) {            case TIMESTAMP_MILLIS:                logicalType = TIMESTAMP_MILLIS_TYPE;                break;            case DECIMAL:                logicalType = new Decimal(schema);                break;            case UUID:                logicalType = UUID_TYPE;                break;            case DATE:                logicalType = DATE_TYPE;                break;            case TIMESTAMP_MICROS:                logicalType = TIMESTAMP_MICROS_TYPE;                break;            case TIME_MILLIS:                logicalType = TIME_MILLIS_TYPE;                break;            case TIME_MICROS:                logicalType = TIME_MICROS_TYPE;                break;            case LOCAL_TIMESTAMP_MICROS:                logicalType = LOCAL_TIMESTAMP_MICROS_TYPE;                break;            case LOCAL_TIMESTAMP_MILLIS:                logicalType = LOCAL_TIMESTAMP_MILLIS_TYPE;                break;            default:                final LogicalTypeFactory typeFactory = REGISTERED_TYPES.get(typeName);                if (typeFactory != null) {                    logicalType = REGISTERED_TYPES.get(typeName).fromSchema(schema);                } else {                    logicalType = null;                }                break;        }                if (logicalType != null) {            logicalType.validate(schema);        }    } catch (RuntimeException e) {                if (throwErrors) {            throw e;        }                        return null;    }    return logicalType;}
1
public static Decimal decimal(int precision)
{    return decimal(precision, 0);}
0
public static Decimal decimal(int precision, int scale)
{    return new Decimal(precision, scale);}
0
public static LogicalType uuid()
{    return UUID_TYPE;}
0
public static Date date()
{    return DATE_TYPE;}
0
public static TimeMillis timeMillis()
{    return TIME_MILLIS_TYPE;}
0
public static TimeMicros timeMicros()
{    return TIME_MICROS_TYPE;}
0
public static TimestampMillis timestampMillis()
{    return TIMESTAMP_MILLIS_TYPE;}
0
public static TimestampMicros timestampMicros()
{    return TIMESTAMP_MICROS_TYPE;}
0
public static LocalTimestampMillis localTimestampMillis()
{    return LOCAL_TIMESTAMP_MILLIS_TYPE;}
0
public static LocalTimestampMicros localTimestampMicros()
{    return LOCAL_TIMESTAMP_MICROS_TYPE;}
0
public Schema addToSchema(Schema schema)
{    super.addToSchema(schema);    schema.addProp(PRECISION_PROP, precision);    schema.addProp(SCALE_PROP, scale);    return schema;}
0
public int getPrecision()
{    return precision;}
0
public int getScale()
{    return scale;}
0
public void validate(Schema schema)
{    super.validate(schema);        if (schema.getType() != Schema.Type.FIXED && schema.getType() != Schema.Type.BYTES) {        throw new IllegalArgumentException("Logical type decimal must be backed by fixed or bytes");    }    if (precision <= 0) {        throw new IllegalArgumentException("Invalid decimal precision: " + precision + " (must be positive)");    } else if (precision > maxPrecision(schema)) {        throw new IllegalArgumentException("fixed(" + schema.getFixedSize() + ") cannot store " + precision + " digits (max " + maxPrecision(schema) + ")");    }    if (scale < 0) {        throw new IllegalArgumentException("Invalid decimal scale: " + scale + " (must be positive)");    } else if (scale > precision) {        throw new IllegalArgumentException("Invalid decimal scale: " + scale + " (greater than precision: " + precision + ")");    }}
0
private long maxPrecision(Schema schema)
{    if (schema.getType() == Schema.Type.BYTES) {                return Integer.MAX_VALUE;    } else if (schema.getType() == Schema.Type.FIXED) {        int size = schema.getFixedSize();        return         Math.round(Math.floor(        Math.log10(        Math.pow(2, 8 * size - 1) - 1)));    } else {                return 0;    }}
0
private boolean hasProperty(Schema schema, String name)
{    return (schema.getObjectProp(name) != null);}
0
private int getInt(Schema schema, String name)
{    Object obj = schema.getObjectProp(name);    if (obj instanceof Integer) {        return (Integer) obj;    }    throw new IllegalArgumentException("Expected int " + name + ": " + (obj == null ? "null" : obj + ":" + obj.getClass().getSimpleName()));}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    Decimal decimal = (Decimal) o;    if (precision != decimal.precision)        return false;    return scale == decimal.scale;}
0
public int hashCode()
{    int result = precision;    result = 31 * result + scale;    return result;}
0
public void validate(Schema schema)
{    super.validate(schema);    if (schema.getType() != Schema.Type.INT) {        throw new IllegalArgumentException("Date can only be used with an underlying int type");    }}
0
public void validate(Schema schema)
{    super.validate(schema);    if (schema.getType() != Schema.Type.INT) {        throw new IllegalArgumentException("Time (millis) can only be used with an underlying int type");    }}
0
public void validate(Schema schema)
{    super.validate(schema);    if (schema.getType() != Schema.Type.LONG) {        throw new IllegalArgumentException("Time (micros) can only be used with an underlying long type");    }}
0
public void validate(Schema schema)
{    super.validate(schema);    if (schema.getType() != Schema.Type.LONG) {        throw new IllegalArgumentException("Timestamp (millis) can only be used with an underlying long type");    }}
0
public void validate(Schema schema)
{    super.validate(schema);    if (schema.getType() != Schema.Type.LONG) {        throw new IllegalArgumentException("Timestamp (micros) can only be used with an underlying long type");    }}
0
public void validate(Schema schema)
{    super.validate(schema);    if (schema.getType() != Schema.Type.LONG) {        throw new IllegalArgumentException("Local timestamp (millis) can only be used with an underlying long type");    }}
0
public void validate(Schema schema)
{    super.validate(schema);    if (schema.getType() != Schema.Type.LONG) {        throw new IllegalArgumentException("Local timestamp (micros) can only be used with an underlying long type");    }}
0
public void addSchema(Schema writeSchema)
{    long fp = SchemaNormalization.parsingFingerprint64(writeSchema);    final Schema actualReadSchema = this.readSchema != null ? this.readSchema : writeSchema;    codecByFingerprint.put(fp, new RawMessageDecoder<D>(model, writeSchema, actualReadSchema));}
0
private RawMessageDecoder<D> getDecoder(long fp)
{    RawMessageDecoder<D> decoder = codecByFingerprint.get(fp);    if (decoder != null) {        return decoder;    }    if (resolver != null) {        Schema writeSchema = resolver.findByFingerprint(fp);        if (writeSchema != null) {            addSchema(writeSchema);            return codecByFingerprint.get(fp);        }    }    throw new MissingSchemaException("Cannot resolve schema for fingerprint: " + fp);}
0
public D decode(InputStream stream, D reuse) throws IOException
{    byte[] header = HEADER_BUFFER.get();    try {        if (!readFully(stream, header)) {            throw new BadHeaderException("Not enough header bytes");        }    } catch (IOException e) {        throw new IOException("Failed to read header and fingerprint bytes", e);    }    if (BinaryMessageEncoder.V1_HEADER[0] != header[0] || BinaryMessageEncoder.V1_HEADER[1] != header[1]) {        throw new BadHeaderException(String.format("Unrecognized header bytes: 0x%02X 0x%02X", header[0], header[1]));    }    RawMessageDecoder<D> decoder = getDecoder(FP_BUFFER.get().getLong(2));    return decoder.decode(stream, reuse);}
0
private boolean readFully(InputStream stream, byte[] bytes) throws IOException
{    int pos = 0;    int bytesRead;    while ((bytes.length - pos) > 0 && (bytesRead = stream.read(bytes, pos, bytes.length - pos)) > 0) {        pos += bytesRead;    }    return (pos == bytes.length);}
0
public ByteBuffer encode(D datum) throws IOException
{    return writeCodec.encode(datum);}
0
public void encode(D datum, OutputStream stream) throws IOException
{    writeCodec.encode(datum, stream);}
0
public void encode(D datum, OutputStream stream) throws IOException
{    stream.write(headerBytes);    super.encode(datum, stream);}
0
private static byte[] getWriteHeader(Schema schema)
{    try {        byte[] fp = SchemaNormalization.parsingFingerprint("CRC-64-AVRO", schema);        byte[] ret = new byte[V1_HEADER.length + fp.length];        System.arraycopy(V1_HEADER, 0, ret, 0, V1_HEADER.length);        System.arraycopy(fp, 0, ret, V1_HEADER.length, fp.length);        return ret;    } catch (NoSuchAlgorithmException e) {        throw new AvroRuntimeException(e);    }}
0
public D decode(InputStream stream) throws IOException
{    return decode(stream, null);}
0
public D decode(ByteBuffer encoded) throws IOException
{    return decode(encoded, null);}
0
public D decode(byte[] encoded) throws IOException
{    return decode(encoded, null);}
0
public D decode(ByteBuffer encoded, D reuse) throws IOException
{    ReusableByteBufferInputStream in = BYTE_BUFFER_IN.get();    in.setByteBuffer(encoded);    return decode(in, reuse);}
0
public D decode(byte[] encoded, D reuse) throws IOException
{    ReusableByteArrayInputStream in = BYTE_ARRAY_IN.get();    in.setByteArray(encoded, 0, encoded.length);    return decode(in, reuse);}
0
public D decode(InputStream stream, D reuse)
{    BinaryDecoder decoder = DecoderFactory.get().directBinaryDecoder(stream, DECODER.get());    DECODER.set(decoder);    try {        return reader.read(reuse, decoder);    } catch (IOException e) {        throw new AvroRuntimeException("Decoding datum failed", e);    }}
0
public ByteBuffer encode(D datum) throws IOException
{    BufferOutputStream temp = TEMP.get();    temp.reset();    encode(datum, temp);    if (copyOutputBytes) {        return temp.toBufferWithCopy();    } else {        return temp.toBufferWithoutCopy();    }}
0
public void encode(D datum, OutputStream stream) throws IOException
{    BinaryEncoder encoder = EncoderFactory.get().directBinaryEncoder(stream, ENCODER.get());    ENCODER.set(encoder);    writer.write(datum, encoder);    encoder.flush();}
0
 ByteBuffer toBufferWithoutCopy()
{    return ByteBuffer.wrap(buf, 0, count);}
0
 ByteBuffer toBufferWithCopy()
{    return ByteBuffer.wrap(toByteArray());}
0
public void addSchema(Schema schema)
{    long fp = SchemaNormalization.parsingFingerprint64(schema);    schemas.put(fp, schema);}
0
public Schema findByFingerprint(long fingerprint)
{    return schemas.get(fingerprint);}
0
public String getName()
{    return name;}
0
public Schema getRequest()
{    return request;}
0
public Schema getResponse()
{    return Schema.create(Schema.Type.NULL);}
0
public Schema getErrors()
{    return Schema.createUnion(new ArrayList<>());}
0
public boolean isOneWay()
{    return true;}
0
public String toString()
{    try {        StringWriter writer = new StringWriter();        JsonGenerator gen = Schema.FACTORY.createGenerator(writer);        toJson(gen);        gen.flush();        return writer.toString();    } catch (IOException e) {        throw new AvroRuntimeException(e);    }}
0
 void toJson(JsonGenerator gen) throws IOException
{    gen.writeStartObject();    if (doc != null)        gen.writeStringField("doc", doc);        writeProps(gen);    gen.writeFieldName("request");    request.fieldsToJson(types, gen);    toJson1(gen);    gen.writeEndObject();}
0
 void toJson1(JsonGenerator gen) throws IOException
{    gen.writeStringField("response", "null");    gen.writeBooleanField("one-way", true);}
0
public boolean equals(Object o)
{    if (o == this)        return true;    if (!(o instanceof Message))        return false;    Message that = (Message) o;    return this.name.equals(that.name) && this.request.equals(that.request) && propsEqual(that);}
0
public int hashCode()
{    return name.hashCode() + request.hashCode() + propsHashCode();}
0
public String getDoc()
{    return doc;}
0
public Schema getResponse()
{    return response;}
0
public Schema getErrors()
{    return errors;}
0
public boolean isOneWay()
{    return false;}
0
public boolean equals(Object o)
{    if (!super.equals(o))        return false;    if (!(o instanceof TwoWayMessage))        return false;    TwoWayMessage that = (TwoWayMessage) o;    return this.response.equals(that.response) && this.errors.equals(that.errors);}
0
public int hashCode()
{    return super.hashCode() + response.hashCode() + errors.hashCode();}
0
 void toJson1(JsonGenerator gen) throws IOException
{    gen.writeFieldName("response");    response.toJson(types, gen);        List<Schema> errs = errors.getTypes();    if (errs.size() > 1) {        Schema union = Schema.createUnion(errs.subList(1, errs.size()));        gen.writeFieldName("errors");        union.toJson(types, gen);    }}
0
public String getName()
{    return name;}
0
public String getNamespace()
{    return namespace;}
0
public String getDoc()
{    return doc;}
0
public Collection<Schema> getTypes()
{    return types.values();}
0
public Schema getType(String name)
{    return types.get(name);}
0
public void setTypes(Collection<Schema> newTypes)
{    types = new Schema.Names();    for (Schema s : newTypes) types.add(s);}
0
public Map<String, Message> getMessages()
{    return messages;}
0
public Message createMessage(String name, String doc, Schema request)
{    return new Message(name, doc, new LinkedHashMap<String, String>(), request);}
0
public Message createMessage(Message m, Schema request)
{    return new Message(name, doc, m, request);}
0
public Message createMessage(String name, String doc, JsonProperties propMap, Schema request)
{    return new Message(name, doc, propMap, request);}
0
public Message createMessage(String name, String doc, Map<String, ?> propMap, Schema request)
{    return new Message(name, doc, propMap, request);}
0
public Message createMessage(String name, String doc, Schema request, Schema response, Schema errors)
{    return new TwoWayMessage(name, doc, new LinkedHashMap<String, String>(), request, response, errors);}
0
public Message createMessage(Message m, Schema request, Schema response, Schema errors)
{    return new TwoWayMessage(m.getName(), m.getDoc(), m, request, response, errors);}
0
public Message createMessage(String name, String doc, JsonProperties propMap, Schema request, Schema response, Schema errors)
{    return new TwoWayMessage(name, doc, propMap, request, response, errors);}
0
public Message createMessage(String name, String doc, Map<String, ?> propMap, Schema request, Schema response, Schema errors)
{    return new TwoWayMessage(name, doc, propMap, request, response, errors);}
0
public boolean equals(Object o)
{    if (o == this)        return true;    if (!(o instanceof Protocol))        return false;    Protocol that = (Protocol) o;    return this.name.equals(that.name) && this.namespace.equals(that.namespace) && this.types.equals(that.types) && this.messages.equals(that.messages) && this.propsEqual(that);}
0
public int hashCode()
{    return name.hashCode() + namespace.hashCode() + types.hashCode() + messages.hashCode() + propsHashCode();}
0
public String toString()
{    return toString(false);}
0
public String toString(boolean pretty)
{    try {        StringWriter writer = new StringWriter();        JsonGenerator gen = Schema.FACTORY.createGenerator(writer);        if (pretty)            gen.useDefaultPrettyPrinter();        toJson(gen);        gen.flush();        return writer.toString();    } catch (IOException e) {        throw new AvroRuntimeException(e);    }}
0
 void toJson(JsonGenerator gen) throws IOException
{    types.space(namespace);    gen.writeStartObject();    gen.writeStringField("protocol", name);    gen.writeStringField("namespace", namespace);    if (doc != null)        gen.writeStringField("doc", doc);    writeProps(gen);    gen.writeArrayFieldStart("types");    Schema.Names resolved = new Schema.Names(namespace);    for (Schema type : types.values()) if (!resolved.contains(type))        type.toJson(resolved, gen);    gen.writeEndArray();    gen.writeObjectFieldStart("messages");    for (Map.Entry<String, Message> e : messages.entrySet()) {        gen.writeFieldName(e.getKey());        e.getValue().toJson(gen);    }    gen.writeEndObject();    gen.writeEndObject();}
0
public byte[] getMD5()
{    if (md5 == null)        try {            md5 = MessageDigest.getInstance("MD5").digest(this.toString().getBytes(StandardCharsets.UTF_8));        } catch (Exception e) {            throw new AvroRuntimeException(e);        }    return md5;}
0
public static Protocol parse(File file) throws IOException
{    return parse(Schema.FACTORY.createParser(file));}
0
public static Protocol parse(InputStream stream) throws IOException
{    return parse(Schema.FACTORY.createParser(stream));}
0
public static Protocol parse(String string, String... more)
{    StringBuilder b = new StringBuilder(string);    for (String part : more) b.append(part);    return parse(b.toString());}
0
public static Protocol parse(String string)
{    try {        return parse(Schema.FACTORY.createParser(new ByteArrayInputStream(string.getBytes(StandardCharsets.UTF_8))));    } catch (IOException e) {        throw new AvroRuntimeException(e);    }}
0
private static Protocol parse(JsonParser parser)
{    try {        Protocol protocol = new Protocol();        protocol.parse((JsonNode) Schema.MAPPER.readTree(parser));        return protocol;    } catch (IOException e) {        throw new SchemaParseException(e);    }}
0
private void parse(JsonNode json)
{    parseNamespace(json);    parseName(json);    parseTypes(json);    parseMessages(json);    parseDoc(json);    parseProps(json);}
0
private void parseNamespace(JsonNode json)
{    JsonNode nameNode = json.get("namespace");    if (nameNode == null)                return;    this.namespace = nameNode.textValue();    types.space(this.namespace);}
0
private void parseDoc(JsonNode json)
{    this.doc = parseDocNode(json);}
0
private String parseDocNode(JsonNode json)
{    JsonNode nameNode = json.get("doc");    if (nameNode == null)                return null;    return nameNode.textValue();}
0
private void parseName(JsonNode json)
{    JsonNode nameNode = json.get("protocol");    if (nameNode == null)        throw new SchemaParseException("No protocol name specified: " + json);    this.name = nameNode.textValue();}
0
private void parseTypes(JsonNode json)
{    JsonNode defs = json.get("types");    if (defs == null)                return;    if (!defs.isArray())        throw new SchemaParseException("Types not an array: " + defs);    for (JsonNode type : defs) {        if (!type.isObject())            throw new SchemaParseException("Type not an object: " + type);        Schema.parse(type, types);    }}
0
private void parseProps(JsonNode json)
{    for (Iterator<String> i = json.fieldNames(); i.hasNext(); ) {                String p = i.next();        if (!PROTOCOL_RESERVED.contains(p))            this.addProp(p, json.get(p));    }}
0
private void parseMessages(JsonNode json)
{    JsonNode defs = json.get("messages");    if (defs == null)                return;    for (Iterator<String> i = defs.fieldNames(); i.hasNext(); ) {        String prop = i.next();        this.messages.put(prop, parseMessage(prop, defs.get(prop)));    }}
0
private Message parseMessage(String messageName, JsonNode json)
{    String doc = parseDocNode(json);    Map<String, JsonNode> mProps = new LinkedHashMap<>();    for (Iterator<String> i = json.fieldNames(); i.hasNext(); ) {                String p = i.next();        if (!MESSAGE_RESERVED.contains(p))            mProps.put(p, json.get(p));    }    JsonNode requestNode = json.get("request");    if (requestNode == null || !requestNode.isArray())        throw new SchemaParseException("No request specified: " + json);    List<Field> fields = new ArrayList<>();    for (JsonNode field : requestNode) {        JsonNode fieldNameNode = field.get("name");        if (fieldNameNode == null)            throw new SchemaParseException("No param name: " + field);        JsonNode fieldTypeNode = field.get("type");        if (fieldTypeNode == null)            throw new SchemaParseException("No param type: " + field);        String name = fieldNameNode.textValue();        String fieldDoc = null;        JsonNode fieldDocNode = field.get("doc");        if (fieldDocNode != null)            fieldDoc = fieldDocNode.textValue();        Field newField = new Field(name, Schema.parse(fieldTypeNode, types), fieldDoc, field.get("default"), true, Order.ASCENDING);        Set<String> aliases = Schema.parseAliases(field);        if (aliases != null) {                        for (String alias : aliases) newField.addAlias(alias);        }        Iterator<String> i = field.fieldNames();        while (i.hasNext()) {                        String prop = i.next();            if (            !FIELD_RESERVED.contains(prop))                newField.addProp(prop, field.get(prop));        }        fields.add(newField);    }    Schema request = Schema.createRecord(fields);    boolean oneWay = false;    JsonNode oneWayNode = json.get("one-way");    if (oneWayNode != null) {        if (!oneWayNode.isBoolean())            throw new SchemaParseException("one-way must be boolean: " + json);        oneWay = oneWayNode.booleanValue();    }    JsonNode responseNode = json.get("response");    if (!oneWay && responseNode == null)        throw new SchemaParseException("No response specified: " + json);    JsonNode decls = json.get("errors");    if (oneWay) {        if (decls != null)            throw new SchemaParseException("one-way can't have errors: " + json);        if (responseNode != null && Schema.parse(responseNode, types).getType() != Schema.Type.NULL)            throw new SchemaParseException("One way response must be null: " + json);        return new Message(messageName, doc, mProps, request);    }    Schema response = Schema.parse(responseNode, types);    List<Schema> errs = new ArrayList<>();        errs.add(SYSTEM_ERROR);    if (decls != null) {        if (!decls.isArray())            throw new SchemaParseException("Errors not an array: " + json);        for (JsonNode decl : decls) {            String name = decl.textValue();            Schema schema = this.types.get(name);            if (schema == null)                throw new SchemaParseException("Undefined error: " + name);            if (!schema.isError())                throw new SchemaParseException("Not an error: " + name);            errs.add(schema);        }    }    return new TwoWayMessage(messageName, doc, mProps, request, response, Schema.createUnion(errs));}
0
public static void main(String[] args) throws Exception
{    System.out.println(Protocol.parse(new File(args[0])));}
0
 static void writeArray(boolean[] data, Encoder out) throws IOException
{    int size = data.length;    out.setItemCount(size);    for (boolean datum : data) {        out.startItem();        out.writeBoolean(datum);    }}
0
 static void writeArray(short[] data, Encoder out) throws IOException
{    int size = data.length;    out.setItemCount(size);    for (short datum : data) {        out.startItem();        out.writeInt(datum);    }}
0
 static void writeArray(char[] data, Encoder out) throws IOException
{    int size = data.length;    out.setItemCount(size);    for (char datum : data) {        out.startItem();        out.writeInt(datum);    }}
0
 static void writeArray(int[] data, Encoder out) throws IOException
{    int size = data.length;    out.setItemCount(size);    for (int datum : data) {        out.startItem();        out.writeInt(datum);    }}
0
 static void writeArray(long[] data, Encoder out) throws IOException
{    int size = data.length;    out.setItemCount(size);    for (long datum : data) {        out.startItem();        out.writeLong(datum);    }}
0
 static void writeArray(float[] data, Encoder out) throws IOException
{    int size = data.length;    out.setItemCount(size);    for (float datum : data) {        out.startItem();        out.writeFloat(datum);    }}
0
 static void writeArray(double[] data, Encoder out) throws IOException
{    int size = data.length;    out.setItemCount(size);    for (double datum : data) {        out.startItem();        out.writeDouble(datum);    }}
0
 static Object readArray(Object array, Class<?> elementType, long l, ResolvingDecoder in) throws IOException
{    if (elementType == int.class)        return readArray((int[]) array, l, in);    if (elementType == long.class)        return readArray((long[]) array, l, in);    if (elementType == float.class)        return readArray((float[]) array, l, in);    if (elementType == double.class)        return readArray((double[]) array, l, in);    if (elementType == boolean.class)        return readArray((boolean[]) array, l, in);    if (elementType == char.class)        return readArray((char[]) array, l, in);    if (elementType == short.class)        return readArray((short[]) array, l, in);    return null;}
0
 static boolean[] readArray(boolean[] array, long l, ResolvingDecoder in) throws IOException
{    int index = 0;    do {        int limit = index + (int) l;        if (array.length < limit) {            array = Arrays.copyOf(array, limit);        }        while (index < limit) {            array[index] = in.readBoolean();            index++;        }    } while ((l = in.arrayNext()) > 0);    return array;}
0
 static int[] readArray(int[] array, long l, ResolvingDecoder in) throws IOException
{    int index = 0;    do {        int limit = index + (int) l;        if (array.length < limit) {            array = Arrays.copyOf(array, limit);        }        while (index < limit) {            array[index] = in.readInt();            index++;        }    } while ((l = in.arrayNext()) > 0);    return array;}
0
 static short[] readArray(short[] array, long l, ResolvingDecoder in) throws IOException
{    int index = 0;    do {        int limit = index + (int) l;        if (array.length < limit) {            array = Arrays.copyOf(array, limit);        }        while (index < limit) {            array[index] = (short) in.readInt();            index++;        }    } while ((l = in.arrayNext()) > 0);    return array;}
0
 static char[] readArray(char[] array, long l, ResolvingDecoder in) throws IOException
{    int index = 0;    do {        int limit = index + (int) l;        if (array.length < limit) {            array = Arrays.copyOf(array, limit);        }        while (index < limit) {            array[index] = (char) in.readInt();            index++;        }    } while ((l = in.arrayNext()) > 0);    return array;}
0
 static long[] readArray(long[] array, long l, ResolvingDecoder in) throws IOException
{    int index = 0;    do {        int limit = index + (int) l;        if (array.length < limit) {            array = Arrays.copyOf(array, limit);        }        while (index < limit) {            array[index] = in.readLong();            index++;        }    } while ((l = in.arrayNext()) > 0);    return array;}
0
 static float[] readArray(float[] array, long l, ResolvingDecoder in) throws IOException
{    int index = 0;    do {        int limit = index + (int) l;        if (array.length < limit) {            array = Arrays.copyOf(array, limit);        }        while (index < limit) {            array[index] = in.readFloat();            index++;        }    } while ((l = in.arrayNext()) > 0);    return array;}
0
 static double[] readArray(double[] array, long l, ResolvingDecoder in) throws IOException
{    int index = 0;    do {        int limit = index + (int) l;        if (array.length < limit) {            array = Arrays.copyOf(array, limit);        }        while (index < limit) {            array[index] = in.readDouble();            index++;        }    } while ((l = in.arrayNext()) > 0);    return array;}
0
 T read(Decoder in) throws IOException
{    return this.read(null, in);}
0
protected Schema getSchema()
{    return schema;}
0
protected final void write(Object datum, Encoder out) throws IOException
{    out.writeLong(((Date) datum).getTime());}
0
protected final Date read(Object reuse, Decoder in) throws IOException
{    if (reuse instanceof Date) {        ((Date) reuse).setTime(in.readLong());        return (Date) reuse;    } else        return new Date(in.readLong());}
0
protected void read(Object object, Decoder in) throws IOException
{}
0
protected void write(Object object, Encoder out) throws IOException
{}
0
protected boolean supportsIO()
{    return false;}
0
protected boolean isStringable()
{    return false;}
0
protected boolean isCustomEncoded()
{    return false;}
0
protected FieldAccessor getAccessor(Field field)
{    AvroEncode enc = field.getAnnotation(AvroEncode.class);    if (enc != null)        try {            return new ReflectionBasesAccessorCustomEncoded(field, enc.using().getDeclaredConstructor().newInstance());        } catch (Exception e) {            throw new AvroRuntimeException("Could not instantiate custom Encoding");        }    return new ReflectionBasedAccessor(field);}
0
public String toString()
{    return field.getName();}
0
public Object get(Object object) throws IllegalAccessException
{    return field.get(object);}
0
public void set(Object object, Object value) throws IllegalAccessException, IOException
{    field.set(object, value);}
0
protected Field getField()
{    return field;}
0
protected boolean isStringable()
{    return isStringable;}
0
protected boolean isCustomEncoded()
{    return isCustomEncoded;}
0
protected void read(Object object, Decoder in) throws IOException
{    try {        field.set(object, encoding.read(in));    } catch (IllegalAccessException e) {        throw new AvroRuntimeException(e);    }}
0
protected void write(Object object, Encoder out) throws IOException
{    try {        encoding.write(field.get(object), out);    } catch (IllegalAccessException e) {        throw new AvroRuntimeException(e);    }}
0
protected boolean isCustomEncoded()
{    return true;}
0
protected boolean supportsIO()
{    return true;}
0
protected FieldAccessor getAccessor(Field field)
{    AvroEncode enc = field.getAnnotation(AvroEncode.class);    if (enc != null)        try {            return new UnsafeCustomEncodedField(field, enc.using().getDeclaredConstructor().newInstance());        } catch (Exception e) {            throw new AvroRuntimeException("Could not instantiate custom Encoding");        }    Class<?> c = field.getType();    if (c == int.class)        return new UnsafeIntField(field);    else if (c == long.class)        return new UnsafeLongField(field);    else if (c == byte.class)        return new UnsafeByteField(field);    else if (c == float.class)        return new UnsafeFloatField(field);    else if (c == double.class)        return new UnsafeDoubleField(field);    else if (c == char.class)        return new UnsafeCharField(field);    else if (c == boolean.class)        return new UnsafeBooleanField(field);    else if (c == short.class)        return new UnsafeShortField(field);    else        return new UnsafeObjectField(field);}
0
protected Field getField()
{    return field;}
0
protected boolean supportsIO()
{    return true;}
0
protected boolean isStringable()
{    return isStringable;}
0
protected void set(Object object, Object value)
{    UNSAFE.putInt(object, offset, (Integer) value);}
0
protected Object get(Object object)
{    return UNSAFE.getInt(object, offset);}
0
protected void read(Object object, Decoder in) throws IOException
{    UNSAFE.putInt(object, offset, in.readInt());}
0
protected void write(Object object, Encoder out) throws IOException
{    out.writeInt(UNSAFE.getInt(object, offset));}
0
protected void set(Object object, Object value)
{    UNSAFE.putFloat(object, offset, (Float) value);}
0
protected Object get(Object object)
{    return UNSAFE.getFloat(object, offset);}
0
protected void read(Object object, Decoder in) throws IOException
{    UNSAFE.putFloat(object, offset, in.readFloat());}
0
protected void write(Object object, Encoder out) throws IOException
{    out.writeFloat(UNSAFE.getFloat(object, offset));}
0
protected void set(Object object, Object value)
{    UNSAFE.putShort(object, offset, (Short) value);}
0
protected Object get(Object object)
{    return UNSAFE.getShort(object, offset);}
0
protected void read(Object object, Decoder in) throws IOException
{    UNSAFE.putShort(object, offset, (short) in.readInt());}
0
protected void write(Object object, Encoder out) throws IOException
{    out.writeInt(UNSAFE.getShort(object, offset));}
0
protected void set(Object object, Object value)
{    UNSAFE.putByte(object, offset, (Byte) value);}
0
protected Object get(Object object)
{    return UNSAFE.getByte(object, offset);}
0
protected void read(Object object, Decoder in) throws IOException
{    UNSAFE.putByte(object, offset, (byte) in.readInt());}
0
protected void write(Object object, Encoder out) throws IOException
{    out.writeInt(UNSAFE.getByte(object, offset));}
0
protected void set(Object object, Object value)
{    UNSAFE.putBoolean(object, offset, (Boolean) value);}
0
protected Object get(Object object)
{    return UNSAFE.getBoolean(object, offset);}
0
protected void read(Object object, Decoder in) throws IOException
{    UNSAFE.putBoolean(object, offset, in.readBoolean());}
0
protected void write(Object object, Encoder out) throws IOException
{    out.writeBoolean(UNSAFE.getBoolean(object, offset));}
0
protected void set(Object object, Object value)
{    UNSAFE.putChar(object, offset, (Character) value);}
0
protected Object get(Object object)
{    return UNSAFE.getChar(object, offset);}
0
protected void read(Object object, Decoder in) throws IOException
{    UNSAFE.putChar(object, offset, (char) in.readInt());}
0
protected void write(Object object, Encoder out) throws IOException
{    out.writeInt(UNSAFE.getChar(object, offset));}
0
protected void set(Object object, Object value)
{    UNSAFE.putLong(object, offset, (Long) value);}
0
protected Object get(Object object)
{    return UNSAFE.getLong(object, offset);}
0
protected void read(Object object, Decoder in) throws IOException
{    UNSAFE.putLong(object, offset, in.readLong());}
0
protected void write(Object object, Encoder out) throws IOException
{    out.writeLong(UNSAFE.getLong(object, offset));}
0
protected void set(Object object, Object value)
{    UNSAFE.putDouble(object, offset, (Double) value);}
0
protected Object get(Object object)
{    return UNSAFE.getDouble(object, offset);}
0
protected void read(Object object, Decoder in) throws IOException
{    UNSAFE.putDouble(object, offset, in.readDouble());}
0
protected void write(Object object, Encoder out) throws IOException
{    out.writeDouble(UNSAFE.getDouble(object, offset));}
0
protected void set(Object object, Object value)
{    UNSAFE.putObject(object, offset, value);}
0
protected Object get(Object object)
{    return UNSAFE.getObject(object, offset);}
0
protected boolean supportsIO()
{    return false;}
0
protected Object get(Object object) throws IllegalAccessException
{    return UNSAFE.getObject(object, offset);}
0
protected void set(Object object, Object value) throws IllegalAccessException, IOException
{    UNSAFE.putObject(object, offset, value);}
0
protected void read(Object object, Decoder in) throws IOException
{    UNSAFE.putObject(object, offset, encoding.read(in));}
0
protected void write(Object object, Encoder out) throws IOException
{    encoding.write(UNSAFE.getObject(object, offset), out);}
0
protected boolean isCustomEncoded()
{    return true;}
0
public K getKey()
{    return key;}
0
public V getValue()
{    return value;}
0
public V setValue(V value)
{    V oldValue = this.value;    this.value = value;    return oldValue;}
0
public boolean useCustomCoders()
{    return false;}
0
public static AllowNull get()
{    return INSTANCE;}
0
protected Schema createFieldSchema(Field field, Map<String, Schema> names)
{    Schema schema = super.createFieldSchema(field, names);    if (field.getType().isPrimitive()) {                return schema;    }    return makeNullable(schema);}
0
public static ReflectData get()
{    return INSTANCE;}
0
public ReflectData addStringable(Class c)
{    stringableClasses.add(c);    return this;}
0
public DatumReader createDatumReader(Schema schema)
{    return new ReflectDatumReader(schema, schema, this);}
0
public DatumReader createDatumReader(Schema writer, Schema reader)
{    return new ReflectDatumReader(writer, reader, this);}
0
public DatumWriter createDatumWriter(Schema schema)
{    return new ReflectDatumWriter(schema, this);}
0
public void setField(Object record, String name, int position, Object o)
{    setField(record, name, position, o, null);}
0
protected void setField(Object record, String name, int pos, Object o, Object state)
{    if (record instanceof IndexedRecord) {        super.setField(record, name, pos, o);        return;    }    try {        getAccessorForField(record, name, pos, state).set(record, o);    } catch (IllegalAccessException | IOException e) {        throw new AvroRuntimeException(e);    }}
0
public Object getField(Object record, String name, int position)
{    return getField(record, name, position, null);}
0
protected Object getField(Object record, String name, int pos, Object state)
{    if (record instanceof IndexedRecord) {        return super.getField(record, name, pos);    }    try {        return getAccessorForField(record, name, pos, state).get(record);    } catch (IllegalAccessException e) {        throw new AvroRuntimeException(e);    }}
0
private FieldAccessor getAccessorForField(Object record, String name, int pos, Object optionalState)
{    if (optionalState != null) {        return ((FieldAccessor[]) optionalState)[pos];    }    return getFieldAccessor(record.getClass(), name);}
0
protected boolean isRecord(Object datum)
{    if (datum == null)        return false;    if (super.isRecord(datum))        return true;    if (datum instanceof Collection)        return false;    if (datum instanceof Map)        return false;    if (datum instanceof GenericFixed)        return false;    return getSchema(datum.getClass()).getType() == Schema.Type.RECORD;}
0
protected boolean isArray(Object datum)
{    if (datum == null)        return false;    Class c = datum.getClass();    return (datum instanceof Collection) || (c.isArray() && c.getComponentType() != Byte.TYPE) || isNonStringMap(datum);}
0
protected Collection getArrayAsCollection(Object datum)
{    return (datum instanceof Map) ? ((Map) datum).entrySet() : (Collection) datum;}
0
protected boolean isBytes(Object datum)
{    if (datum == null)        return false;    if (super.isBytes(datum))        return true;    Class c = datum.getClass();    return c.isArray() && c.getComponentType() == Byte.TYPE;}
0
protected Schema getRecordSchema(Object record)
{    if (record instanceof GenericContainer)        return super.getRecordSchema(record);    return getSchema(record.getClass());}
0
public boolean validate(Schema schema, Object datum)
{    switch(schema.getType()) {        case ARRAY:            if (!datum.getClass().isArray())                return super.validate(schema, datum);            int length = java.lang.reflect.Array.getLength(datum);            for (int i = 0; i < length; i++) if (!validate(schema.getElementType(), java.lang.reflect.Array.get(datum, i)))                return false;            return true;        default:            return super.validate(schema, datum);    }}
0
protected ClassAccessorData computeValue(Class<?> c)
{    if (!IndexedRecord.class.isAssignableFrom(c)) {        return new ClassAccessorData(c);    }    return null;}
0
private synchronized FieldAccessor[] getAccessorsFor(Schema schema)
{        FieldAccessor[] result = bySchema.get(schema);    if (result == null) {        result = createAccessorsFor(schema);        bySchema.put(schema, result);    }    return result;}
0
private FieldAccessor[] createAccessorsFor(Schema schema)
{    List<Schema.Field> avroFields = schema.getFields();    FieldAccessor[] result = new FieldAccessor[avroFields.size()];    for (Schema.Field avroField : schema.getFields()) {        result[avroField.pos()] = byName.get(avroField.name());    }    return result;}
0
private FieldAccessor getAccessorFor(String fieldName)
{    FieldAccessor result = byName.get(fieldName);    if (result == null) {        throw new AvroRuntimeException("No field named " + fieldName + " in: " + clazz);    }    return result;}
0
private ClassAccessorData getClassAccessorData(Class<?> c)
{    return ACCESSOR_CACHE.get(c);}
0
private FieldAccessor[] getFieldAccessors(Class<?> c, Schema s)
{    ClassAccessorData data = getClassAccessorData(c);    if (data != null) {        return data.getAccessorsFor(s);    }    return null;}
0
private FieldAccessor getFieldAccessor(Class<?> c, String fieldName)
{    ClassAccessorData data = getClassAccessorData(c);    if (data != null) {        return data.getAccessorFor(fieldName);    }    return null;}
0
 static Class getClassProp(Schema schema, String prop)
{    String name = schema.getProp(prop);    if (name == null)        return null;    Class c = CLASS_CACHE.get(name);    if (c != null)        return c;    try {        c = ClassUtils.forName(name);        CLASS_CACHE.put(name, c);    } catch (ClassNotFoundException e) {        throw new AvroRuntimeException(e);    }    return c;}
0
protected boolean isMap(Object datum)
{    return (datum instanceof Map) && !isNonStringMap(datum);}
0
private boolean isNonStringMap(Object datum)
{    if (datum instanceof Map) {        Map m = (Map) datum;        if (m.size() > 0) {            Class keyClass = m.keySet().iterator().next().getClass();            return !isStringable(keyClass) && !isStringType(keyClass);        }    }    return false;}
0
public Class getClass(Schema schema)
{        Conversion<?> conversion = getConversionFor(schema.getLogicalType());    if (conversion != null) {        return conversion.getConvertedType();    }    switch(schema.getType()) {        case ARRAY:            Class collectionClass = getClassProp(schema, CLASS_PROP);            if (collectionClass != null)                return collectionClass;            Class elementClass = getClass(schema.getElementType());            if (elementClass.isPrimitive()) {                                return ARRAY_CLASSES.get(elementClass);            } else {                return java.lang.reflect.Array.newInstance(elementClass, 0).getClass();            }        case STRING:            Class stringClass = getClassProp(schema, CLASS_PROP);            if (stringClass != null)                return stringClass;            return String.class;        case BYTES:            return BYTES_CLASS;        case INT:            String intClass = schema.getProp(CLASS_PROP);            if (Byte.class.getName().equals(intClass))                return Byte.TYPE;            if (Short.class.getName().equals(intClass))                return Short.TYPE;            if (Character.class.getName().equals(intClass))                return Character.TYPE;        default:            return super.getClass(schema);    }}
0
 Schema createNonStringMapSchema(Type keyType, Type valueType, Map<String, Schema> names)
{    Schema keySchema = createSchema(keyType, names);    Schema valueSchema = createSchema(valueType, names);    Schema.Field keyField = new Schema.Field(NS_MAP_KEY, keySchema, null, null);    Schema.Field valueField = new Schema.Field(NS_MAP_VALUE, valueSchema, null, null);    String name = getNameForNonStringMapRecord(keyType, valueType, keySchema, valueSchema);    Schema elementSchema = Schema.createRecord(name, null, null, false);    elementSchema.setFields(Arrays.asList(keyField, valueField));    Schema arraySchema = Schema.createArray(elementSchema);    return arraySchema;}
0
private String getNameForNonStringMapRecord(Type keyType, Type valueType, Schema keySchema, Schema valueSchema)
{        if (keyType instanceof Class && valueType instanceof Class) {        Class keyClass = (Class) keyType;        Class valueClass = (Class) valueType;        Package pkg1 = keyClass.getPackage();        Package pkg2 = valueClass.getPackage();        if (pkg1 != null && pkg1.getName().startsWith("java") && pkg2 != null && pkg2.getName().startsWith("java")) {            return NS_MAP_ARRAY_RECORD + keyClass.getSimpleName() + valueClass.getSimpleName();        }    }    String name = keySchema.getFullName() + valueSchema.getFullName();    long fingerprint = SchemaNormalization.fingerprint64(name.getBytes(StandardCharsets.UTF_8));    if (fingerprint < 0)                fingerprint = -fingerprint;        String fpString = Long.toString(fingerprint, 16);    return NS_MAP_ARRAY_RECORD + fpString;}
0
 static boolean isNonStringMapSchema(Schema s)
{    if (s != null && s.getType() == Schema.Type.ARRAY) {        Class c = getClassProp(s, CLASS_PROP);        return c != null && Map.class.isAssignableFrom(c);    }    return false;}
0
protected Schema createSchema(Type type, Map<String, Schema> names)
{    if (type instanceof GenericArrayType) {                Type component = ((GenericArrayType) type).getGenericComponentType();        if (        component == Byte.TYPE)            return Schema.create(Schema.Type.BYTES);        Schema result = Schema.createArray(createSchema(component, names));        setElement(result, component);        return result;    } else if (type instanceof ParameterizedType) {        ParameterizedType ptype = (ParameterizedType) type;        Class raw = (Class) ptype.getRawType();        Type[] params = ptype.getActualTypeArguments();        if (Map.class.isAssignableFrom(raw)) {                        Class key = (Class) params[0];            if (isStringable(key)) {                                Schema schema = Schema.createMap(createSchema(params[1], names));                schema.addProp(KEY_CLASS_PROP, key.getName());                return schema;            } else if (key != String.class) {                Schema schema = createNonStringMapSchema(params[0], params[1], names);                schema.addProp(CLASS_PROP, raw.getName());                return schema;            }        } else if (Collection.class.isAssignableFrom(raw)) {                        if (params.length != 1)                throw new AvroTypeException("No array type specified.");            Schema schema = Schema.createArray(createSchema(params[0], names));            schema.addProp(CLASS_PROP, raw.getName());            return schema;        }    } else if ((type == Byte.class) || (type == Byte.TYPE)) {        Schema result = Schema.create(Schema.Type.INT);        result.addProp(CLASS_PROP, Byte.class.getName());        return result;    } else if ((type == Short.class) || (type == Short.TYPE)) {        Schema result = Schema.create(Schema.Type.INT);        result.addProp(CLASS_PROP, Short.class.getName());        return result;    } else if ((type == Character.class) || (type == Character.TYPE)) {        Schema result = Schema.create(Schema.Type.INT);        result.addProp(CLASS_PROP, Character.class.getName());        return result;    } else if (type instanceof Class) {                Class<?> c = (Class<?>) type;        if (        c.isPrimitive() || c == Void.class || c == Boolean.class || c == Integer.class || c == Long.class || c == Float.class || c == Double.class || c == Byte.class || c == Short.class || c == Character.class)            return super.createSchema(type, names);        if (c.isArray()) {                        Class component = c.getComponentType();            if (component == Byte.TYPE) {                                Schema result = Schema.create(Schema.Type.BYTES);                result.addProp(CLASS_PROP, c.getName());                return result;            }            Schema result = Schema.createArray(createSchema(component, names));            result.addProp(CLASS_PROP, c.getName());            setElement(result, component);            return result;        }        AvroSchema explicit = c.getAnnotation(AvroSchema.class);        if (        explicit != null)            return new Schema.Parser().parse(explicit.value());        if (        CharSequence.class.isAssignableFrom(c))            return Schema.create(Schema.Type.STRING);        if (        ByteBuffer.class.isAssignableFrom(c))            return Schema.create(Schema.Type.BYTES);        if (        Collection.class.isAssignableFrom(c))            throw new AvroRuntimeException("Can't find element type of Collection");        Conversion<?> conversion = getConversionByClass(c);        if (conversion != null) {            return conversion.getRecommendedSchema();        }        String fullName = c.getName();        Schema schema = names.get(fullName);        if (schema == null) {                        AvroDoc annotatedDoc = c.getAnnotation(AvroDoc.class);            String doc = (annotatedDoc != null) ? annotatedDoc.value() : null;            String name = c.getSimpleName();            String space = c.getPackage() == null ? "" : c.getPackage().getName();            if (            c.getEnclosingClass() != null)                space = c.getEnclosingClass().getName();            Union union = c.getAnnotation(Union.class);            if (union != null) {                                return getAnnotatedUnion(union, names);            } else if (isStringable(c)) {                                Schema result = Schema.create(Schema.Type.STRING);                result.addProp(CLASS_PROP, c.getName());                return result;            } else if (c.isEnum()) {                                List<String> symbols = new ArrayList<>();                Enum[] constants = (Enum[]) c.getEnumConstants();                for (Enum constant : constants) symbols.add(constant.name());                schema = Schema.createEnum(name, doc, space, symbols);                consumeAvroAliasAnnotation(c, schema);            } else if (GenericFixed.class.isAssignableFrom(c)) {                                int size = c.getAnnotation(FixedSize.class).value();                schema = Schema.createFixed(name, doc, space, size);                consumeAvroAliasAnnotation(c, schema);            } else if (IndexedRecord.class.isAssignableFrom(c)) {                                return super.createSchema(type, names);            } else {                                List<Schema.Field> fields = new ArrayList<>();                boolean error = Throwable.class.isAssignableFrom(c);                schema = Schema.createRecord(name, doc, space, error);                consumeAvroAliasAnnotation(c, schema);                names.put(c.getName(), schema);                for (Field field : getCachedFields(c)) if ((field.getModifiers() & (Modifier.TRANSIENT | Modifier.STATIC)) == 0 && !field.isAnnotationPresent(AvroIgnore.class)) {                    Schema fieldSchema = createFieldSchema(field, names);                    AvroDefault defaultAnnotation = field.getAnnotation(AvroDefault.class);                    Object defaultValue = (defaultAnnotation == null) ? null : Schema.parseJsonToObject(defaultAnnotation.value());                                        annotatedDoc = field.getAnnotation(AvroDoc.class);                    doc = (annotatedDoc != null) ? annotatedDoc.value() : null;                    if (defaultValue == null && fieldSchema.getType() == Schema.Type.UNION) {                        Schema defaultType = fieldSchema.getTypes().get(0);                        if (defaultType.getType() == Schema.Type.NULL) {                            defaultValue = JsonProperties.NULL_VALUE;                        }                    }                                        AvroName annotatedName = field.getAnnotation(AvroName.class);                    String fieldName = (annotatedName != null) ? annotatedName.value() : field.getName();                    Schema.Field recordField = new Schema.Field(fieldName, fieldSchema, doc, defaultValue);                                        AvroMeta[] metadata = field.getAnnotationsByType(AvroMeta.class);                    for (AvroMeta meta : metadata) {                        if (recordField.getObjectProps().containsKey(meta.key())) {                            throw new AvroTypeException("Duplicate field prop key: " + meta.key());                        }                        recordField.addProp(meta.key(), meta.value());                    }                    for (Schema.Field f : fields) {                        if (f.name().equals(fieldName))                            throw new AvroTypeException("double field entry: " + fieldName);                    }                    consumeFieldAlias(field, recordField);                    fields.add(recordField);                }                if (                error)                    fields.add(new Schema.Field("detailMessage", THROWABLE_MESSAGE, null, null));                schema.setFields(fields);                AvroMeta[] metadata = c.getAnnotationsByType(AvroMeta.class);                for (AvroMeta meta : metadata) {                    if (schema.getObjectProps().containsKey(meta.key())) {                        throw new AvroTypeException("Duplicate type prop key: " + meta.key());                    }                    schema.addProp(meta.key(), meta.value());                }            }            names.put(fullName, schema);        }        return schema;    }    return super.createSchema(type, names);}
0
protected boolean isStringable(Class<?> c)
{    return c.isAnnotationPresent(Stringable.class) || super.isStringable(c);}
0
private void setElement(Schema schema, Type element)
{    if (!(element instanceof Class))        return;    Class<?> c = (Class<?>) element;    Union union = c.getAnnotation(Union.class);    if (    union != null)        schema.addProp(ELEMENT_PROP, c.getName());}
0
private Schema getAnnotatedUnion(Union union, Map<String, Schema> names)
{    List<Schema> branches = new ArrayList<>();    for (Class branch : union.value()) branches.add(createSchema(branch, names));    return Schema.createUnion(branches);}
0
public static Schema makeNullable(Schema schema)
{    if (schema.getType() == Schema.Type.UNION) {                for (Schema subType : schema.getTypes()) {            if (subType.getType() == Schema.Type.NULL) {                return schema;            }        }                List<Schema> withNull = new ArrayList<>();        withNull.add(Schema.create(Schema.Type.NULL));        withNull.addAll(schema.getTypes());        return Schema.createUnion(withNull);    } else {                return Schema.createUnion(Arrays.asList(Schema.create(Schema.Type.NULL), schema));    }}
0
private static Field[] getCachedFields(Class<?> recordClass)
{    Field[] fieldsList = FIELDS_CACHE.get(recordClass);    if (fieldsList != null)        return fieldsList;    fieldsList = getFields(recordClass, true);    FIELDS_CACHE.put(recordClass, fieldsList);    return fieldsList;}
0
private static Field[] getFields(Class<?> recordClass, boolean excludeJava)
{    Field[] fieldsList;    Map<String, Field> fields = new LinkedHashMap<>();    Class<?> c = recordClass;    do {        if (excludeJava && c.getPackage() != null && c.getPackage().getName().startsWith("java."))                        break;        for (Field field : c.getDeclaredFields()) if ((field.getModifiers() & (Modifier.TRANSIENT | Modifier.STATIC)) == 0)            if (fields.put(field.getName(), field) != null)                throw new AvroTypeException(c + " contains two fields named: " + field);        c = c.getSuperclass();    } while (c != null);    fieldsList = fields.values().toArray(new Field[0]);    return fieldsList;}
0
protected Schema createFieldSchema(Field field, Map<String, Schema> names)
{    AvroEncode enc = field.getAnnotation(AvroEncode.class);    if (enc != null)        try {            return enc.using().getDeclaredConstructor().newInstance().getSchema();        } catch (Exception e) {            throw new AvroRuntimeException("Could not create schema from custom serializer for " + field.getName());        }    AvroSchema explicit = field.getAnnotation(AvroSchema.class);    if (    explicit != null)        return new Schema.Parser().parse(explicit.value());    Union union = field.getAnnotation(Union.class);    if (union != null)        return getAnnotatedUnion(union, names);    Schema schema = createSchema(field.getGenericType(), names);    if (field.isAnnotationPresent(Stringable.class)) {                schema = Schema.create(Schema.Type.STRING);    }    if (    field.isAnnotationPresent(Nullable.class))        schema = makeNullable(schema);    return schema;}
0
public Protocol getProtocol(Class iface)
{    Protocol protocol = new Protocol(iface.getSimpleName(), iface.getPackage() == null ? "" : iface.getPackage().getName());    Map<String, Schema> names = new LinkedHashMap<>();    Map<String, Message> messages = protocol.getMessages();    Map<TypeVariable<?>, Type> genericTypeVariableMap = ReflectionUtil.resolveTypeVariables(iface);    for (Method method : iface.getMethods()) {        if ((method.getModifiers() & Modifier.STATIC) == 0) {            String name = method.getName();            if (messages.containsKey(name))                throw new AvroTypeException("Two methods with same name: " + name);            messages.put(name, getMessage(method, protocol, names, genericTypeVariableMap));        }    }        List<Schema> types = new ArrayList<>(names.values());    Collections.reverse(types);    protocol.setTypes(types);    return protocol;}
0
private Message getMessage(Method method, Protocol protocol, Map<String, Schema> names, Map<? extends Type, Type> genericTypeMap)
{    List<Schema.Field> fields = new ArrayList<>();    for (Parameter parameter : method.getParameters()) {        Schema paramSchema = getSchema(genericTypeMap.getOrDefault(parameter.getParameterizedType(), parameter.getType()), names);        for (Annotation annotation : parameter.getAnnotations()) {            if (            annotation instanceof AvroSchema)                paramSchema = new Schema.Parser().parse(((AvroSchema) annotation).value());            else if (            annotation instanceof Union)                paramSchema = getAnnotatedUnion(((Union) annotation), names);            else if (            annotation instanceof Nullable)                paramSchema = makeNullable(paramSchema);        }        fields.add(new Schema.Field(parameter.getName(), paramSchema, null, /* doc */        null));    }    Schema request = Schema.createRecord(fields);    Type genericReturnType = method.getGenericReturnType();    Type returnType = genericTypeMap.getOrDefault(genericReturnType, genericReturnType);    Union union = method.getAnnotation(Union.class);    Schema response = union == null ? getSchema(returnType, names) : getAnnotatedUnion(union, names);    if (    method.isAnnotationPresent(Nullable.class))        response = makeNullable(response);    AvroSchema explicit = method.getAnnotation(AvroSchema.class);    if (    explicit != null)        response = new Schema.Parser().parse(explicit.value());    List<Schema> errs = new ArrayList<>();        errs.add(Protocol.SYSTEM_ERROR);    for (Type err : method.getGenericExceptionTypes()) errs.add(getSchema(err, names));    Schema errors = Schema.createUnion(errs);    return protocol.createMessage(method.getName(), null, /* doc */    new LinkedHashMap<String, String>(), /* propMap */    request, response, errors);}
0
private Schema getSchema(Type type, Map<String, Schema> names)
{    try {        return createSchema(type, names);    } catch (AvroTypeException e) {                throw new AvroTypeException("Error getting schema for " + type + ": " + e.getMessage(), e);    }}
0
protected int compare(Object o1, Object o2, Schema s, boolean equals)
{    switch(s.getType()) {        case ARRAY:            if (!o1.getClass().isArray())                break;            Schema elementType = s.getElementType();            int l1 = java.lang.reflect.Array.getLength(o1);            int l2 = java.lang.reflect.Array.getLength(o2);            int l = Math.min(l1, l2);            for (int i = 0; i < l; i++) {                int compare = compare(java.lang.reflect.Array.get(o1, i), java.lang.reflect.Array.get(o2, i), elementType, equals);                if (compare != 0)                    return compare;            }            return Integer.compare(l1, l2);        case BYTES:            if (!o1.getClass().isArray())                break;            byte[] b1 = (byte[]) o1;            byte[] b2 = (byte[]) o2;            return BinaryData.compareBytes(b1, 0, b1.length, b2, 0, b2.length);    }    return super.compare(o1, o2, s, equals);}
0
protected Object getRecordState(Object record, Schema schema)
{    return getFieldAccessors(record.getClass(), schema);}
0
private void consumeAvroAliasAnnotation(Class<?> c, Schema schema)
{    AvroAlias[] aliases = c.getAnnotationsByType(AvroAlias.class);    for (AvroAlias alias : aliases) {        String space = alias.space();        if (AvroAlias.NULL.equals(space))            space = null;        schema.addAlias(alias.alias(), space);    }}
0
private void consumeFieldAlias(Field field, Schema.Field recordField)
{    AvroAlias[] aliases = field.getAnnotationsByType(AvroAlias.class);    for (AvroAlias alias : aliases) {        if (!alias.space().equals(AvroAlias.NULL)) {            throw new AvroRuntimeException("Namespaces are not allowed on field aliases. " + "Offending field: " + recordField.name());        }        recordField.addAlias(alias.alias());    }}
0
public Object createFixed(Object old, Schema schema)
{            LogicalType logicalType = schema.getLogicalType();    if (logicalType != null) {        Conversion<?> conversion = getConversionFor(schema.getLogicalType());        if (conversion != null) {            return new GenericData.Fixed(schema);        }    }    return super.createFixed(old, schema);}
0
public Object newRecord(Object old, Schema schema)
{            LogicalType logicalType = schema.getLogicalType();    if (logicalType != null) {        Conversion<?> conversion = getConversionFor(schema.getLogicalType());        if (conversion != null) {            return new GenericData.Record(schema);        }    }    return super.newRecord(old, schema);}
0
protected Object newArray(Object old, int size, Schema schema)
{    Class<?> collectionClass = ReflectData.getClassProp(schema, SpecificData.CLASS_PROP);    Class<?> elementClass = ReflectData.getClassProp(schema, SpecificData.ELEMENT_PROP);    if (elementClass == null) {                        Conversion<?> elementConversion = getData().getConversionFor(schema.getElementType().getLogicalType());        if (elementConversion != null) {            elementClass = elementConversion.getConvertedType();        }    }    if (collectionClass == null && elementClass == null)                return super.newArray(old, size, schema);    if (collectionClass != null && !collectionClass.isArray()) {        if (old instanceof Collection) {            ((Collection<?>) old).clear();            return old;        }        if (collectionClass.isAssignableFrom(ArrayList.class))            return new ArrayList<>();        return SpecificData.newInstance(collectionClass, schema);    }    if (elementClass == null) {        elementClass = collectionClass.getComponentType();    }    if (elementClass == null) {        ReflectData data = (ReflectData) getData();        elementClass = data.getClass(schema.getElementType());    }    return Array.newInstance(elementClass, size);}
0
protected Object peekArray(Object array)
{    return null;}
0
protected void addToArray(Object array, long pos, Object e)
{    throw new AvroRuntimeException("reflectDatumReader does not use addToArray");}
0
protected Object readArray(Object old, Schema expected, ResolvingDecoder in) throws IOException
{    Schema expectedType = expected.getElementType();    long l = in.readArrayStart();    if (l <= 0) {        return newArray(old, 0, expected);    }    Object array = newArray(old, (int) l, expected);    if (array instanceof Collection) {        @SuppressWarnings("unchecked")        Collection<Object> c = (Collection<Object>) array;        return readCollection(c, expectedType, l, in);    } else if (array instanceof Map) {                if (ReflectData.isNonStringMapSchema(expected)) {            Collection<Object> c = new ArrayList<>();            readCollection(c, expectedType, l, in);            Map m = (Map) array;            for (Object ele : c) {                IndexedRecord rec = ((IndexedRecord) ele);                Object key = rec.get(ReflectData.NS_MAP_KEY_INDEX);                Object value = rec.get(ReflectData.NS_MAP_VALUE_INDEX);                m.put(key, value);            }            return array;        } else {            String msg = "Expected a schema of map with non-string keys but got " + expected;            throw new AvroRuntimeException(msg);        }    } else {        return readJavaArray(array, expectedType, l, in);    }}
0
private Object readJavaArray(Object array, Schema expectedType, long l, ResolvingDecoder in) throws IOException
{    Class<?> elementType = array.getClass().getComponentType();    if (elementType.isPrimitive()) {        return readPrimitiveArray(array, elementType, l, in);    } else {        return readObjectArray((Object[]) array, expectedType, l, in);    }}
0
private Object readPrimitiveArray(Object array, Class<?> c, long l, ResolvingDecoder in) throws IOException
{    return ArrayAccessor.readArray(array, c, l, in);}
0
private Object readObjectArray(Object[] array, Schema expectedType, long l, ResolvingDecoder in) throws IOException
{    LogicalType logicalType = expectedType.getLogicalType();    Conversion<?> conversion = getData().getConversionFor(logicalType);    int index = 0;    if (logicalType != null && conversion != null) {        do {            int limit = index + (int) l;            while (index < limit) {                Object element = readWithConversion(null, expectedType, logicalType, conversion, in);                array[index] = element;                index++;            }        } while ((l = in.arrayNext()) > 0);    } else {        do {            int limit = index + (int) l;            while (index < limit) {                Object element = readWithoutConversion(null, expectedType, in);                array[index] = element;                index++;            }        } while ((l = in.arrayNext()) > 0);    }    return array;}
0
private Object readCollection(Collection<Object> c, Schema expectedType, long l, ResolvingDecoder in) throws IOException
{    LogicalType logicalType = expectedType.getLogicalType();    Conversion<?> conversion = getData().getConversionFor(logicalType);    if (logicalType != null && conversion != null) {        do {            for (int i = 0; i < l; i++) {                Object element = readWithConversion(null, expectedType, logicalType, conversion, in);                c.add(element);            }        } while ((l = in.arrayNext()) > 0);    } else {        do {            for (int i = 0; i < l; i++) {                Object element = readWithoutConversion(null, expectedType, in);                c.add(element);            }        } while ((l = in.arrayNext()) > 0);    }    return c;}
0
protected Object readString(Object old, Decoder in) throws IOException
{    return super.readString(null, in).toString();}
0
protected Object createString(String value)
{    return value;}
0
protected Object readBytes(Object old, Schema s, Decoder in) throws IOException
{    ByteBuffer bytes = in.readBytes(null);    Class<?> c = ReflectData.getClassProp(s, SpecificData.CLASS_PROP);    if (c != null && c.isArray()) {        byte[] result = new byte[bytes.remaining()];        bytes.get(result);        return result;    } else {        return bytes;    }}
0
protected Object readInt(Object old, Schema expected, Decoder in) throws IOException
{    Object value = in.readInt();    String intClass = expected.getProp(SpecificData.CLASS_PROP);    if (Byte.class.getName().equals(intClass))        value = ((Integer) value).byteValue();    else if (Short.class.getName().equals(intClass))        value = ((Integer) value).shortValue();    else if (Character.class.getName().equals(intClass))        value = (char) (int) (Integer) value;    return value;}
0
protected void readField(Object record, Field f, Object oldDatum, ResolvingDecoder in, Object state) throws IOException
{    if (state != null) {        FieldAccessor accessor = ((FieldAccessor[]) state)[f.pos()];        if (accessor != null) {            if (accessor.supportsIO() && (!Schema.Type.UNION.equals(f.schema().getType()) || accessor.isCustomEncoded())) {                accessor.read(record, in);                return;            }            if (accessor.isStringable()) {                try {                    String asString = (String) read(null, f.schema(), in);                    accessor.set(record, asString == null ? null : newInstanceFromString(accessor.getField().getType(), asString));                    return;                } catch (Exception e) {                    throw new AvroRuntimeException("Failed to read Stringable", e);                }            }            LogicalType logicalType = f.schema().getLogicalType();            if (logicalType != null) {                Conversion<?> conversion = getData().getConversionByClass(accessor.getField().getType(), logicalType);                if (conversion != null) {                    try {                        accessor.set(record, convert(readWithoutConversion(oldDatum, f.schema(), in), f.schema(), logicalType, conversion));                    } catch (IllegalAccessException e) {                        throw new AvroRuntimeException("Failed to set " + f);                    }                    return;                }            }            try {                accessor.set(record, readWithoutConversion(oldDatum, f.schema(), in));                return;            } catch (IllegalAccessException e) {                throw new AvroRuntimeException("Failed to set " + f);            }        }    }    super.readField(record, f, oldDatum, in, state);}
0
protected void writeArray(Schema schema, Object datum, Encoder out) throws IOException
{    if (datum instanceof Collection) {        super.writeArray(schema, datum, out);        return;    }    Class<?> elementClass = datum.getClass().getComponentType();    if (null == elementClass) {                throw new AvroRuntimeException("Array data must be a Collection or Array");    }    Schema element = schema.getElementType();    if (elementClass.isPrimitive()) {        Schema.Type type = element.getType();        out.writeArrayStart();        switch(type) {            case BOOLEAN:                if (elementClass.isPrimitive())                    ArrayAccessor.writeArray((boolean[]) datum, out);                break;            case DOUBLE:                ArrayAccessor.writeArray((double[]) datum, out);                break;            case FLOAT:                ArrayAccessor.writeArray((float[]) datum, out);                break;            case INT:                if (elementClass.equals(int.class)) {                    ArrayAccessor.writeArray((int[]) datum, out);                } else if (elementClass.equals(char.class)) {                    ArrayAccessor.writeArray((char[]) datum, out);                } else if (elementClass.equals(short.class)) {                    ArrayAccessor.writeArray((short[]) datum, out);                } else {                    arrayError(elementClass, type);                }                break;            case LONG:                ArrayAccessor.writeArray((long[]) datum, out);                break;            default:                arrayError(elementClass, type);        }        out.writeArrayEnd();    } else {        out.writeArrayStart();        writeObjectArray(element, (Object[]) datum, out);        out.writeArrayEnd();    }}
0
private void writeObjectArray(Schema element, Object[] data, Encoder out) throws IOException
{    int size = data.length;    out.setItemCount(size);    for (Object datum : data) {        this.write(element, datum, out);    }}
0
private void arrayError(Class<?> cl, Schema.Type type)
{    throw new AvroRuntimeException("Error writing array with inner type " + cl + " and avro type: " + type);}
0
protected void writeBytes(Object datum, Encoder out) throws IOException
{    if (datum instanceof byte[])        out.writeBytes((byte[]) datum);    else        super.writeBytes(datum, out);}
0
protected void write(Schema schema, Object datum, Encoder out) throws IOException
{    if (datum instanceof Byte)        datum = ((Byte) datum).intValue();    else if (datum instanceof Short)        datum = ((Short) datum).intValue();    else if (datum instanceof Character)        datum = (int) (char) (Character) datum;    else if (datum instanceof Map && ReflectData.isNonStringMapSchema(schema)) {                                Set entries = ((Map) datum).entrySet();        List<Map.Entry> entryList = new ArrayList<>(entries.size());        for (Object obj : ((Map) datum).entrySet()) {            Map.Entry e = (Map.Entry) obj;            entryList.add(new MapEntry(e.getKey(), e.getValue()));        }        datum = entryList;    }    try {        super.write(schema, datum, out);    } catch (NullPointerException e) {                NullPointerException result = new NullPointerException("in " + schema.getFullName() + " " + e.getMessage());        result.initCause(e.getCause() == null ? e : e.getCause());        throw result;    }}
0
protected void writeField(Object record, Field f, Encoder out, Object state) throws IOException
{    if (state != null) {        FieldAccessor accessor = ((FieldAccessor[]) state)[f.pos()];        if (accessor != null) {            if (accessor.supportsIO() && (!Schema.Type.UNION.equals(f.schema().getType()) || accessor.isCustomEncoded())) {                accessor.write(record, out);                return;            }            if (accessor.isStringable()) {                try {                    Object object = accessor.get(record);                    write(f.schema(), (object == null) ? null : object.toString(), out);                } catch (IllegalAccessException e) {                    throw new AvroRuntimeException("Failed to write Stringable", e);                }                return;            }        }    }    super.writeField(record, f, out, state);}
0
 static void resetFieldAccess()
{            FieldAccess access = null;    try {        if (null == System.getProperty("avro.disable.unsafe")) {            FieldAccess unsafeAccess = load("org.apache.avro.reflect.FieldAccessUnsafe", FieldAccess.class);            if (validate(unsafeAccess)) {                access = unsafeAccess;            }        }    } catch (Throwable ignored) {    }    if (access == null) {        try {            FieldAccess reflectAccess = load("org.apache.avro.reflect.FieldAccessReflect", FieldAccess.class);            if (validate(reflectAccess)) {                access = reflectAccess;            }        } catch (Throwable oops) {            throw new AvroRuntimeException("Unable to load a functional FieldAccess class!");        }    }    fieldAccess = access;}
0
private static T load(String name, Class<T> type) throws Exception
{    return ReflectionUtil.class.getClassLoader().loadClass(name).asSubclass(type).getDeclaredConstructor().newInstance();}
0
public static FieldAccess getFieldAccess()
{    return fieldAccess;}
0
private static boolean validate(FieldAccess access) throws Exception
{    return new AccessorTestClass().validate(access);}
0
private boolean validate(FieldAccess access) throws Exception
{    boolean valid = true;    valid &= validField(access, "b", b, false);    valid &= validField(access, "by", by, (byte) 0xaf);    valid &= validField(access, "c", c, 'C');    valid &= validField(access, "s", s, (short) 321);    valid &= validField(access, "i", i, 111);    valid &= validField(access, "l", l, 54321L);    valid &= validField(access, "f", f, 0.2f);    valid &= validField(access, "d", d, 0.4d);    valid &= validField(access, "o", o, new Object());    valid &= validField(access, "i2", i2, -555);    return valid;}
0
private boolean validField(FieldAccess access, String name, Object original, Object toSet) throws Exception
{    FieldAccessor a;    boolean valid = true;    a = accessor(access, name);    valid &= original.equals(a.get(this));    a.set(this, toSet);    valid &= !original.equals(a.get(this));    return valid;}
0
private FieldAccessor accessor(FieldAccess access, String name) throws Exception
{    return access.getAccessor(this.getClass().getDeclaredField(name));}
0
protected static Map<TypeVariable<?>, Type> resolveTypeVariables(Class<?> iface)
{    return resolveTypeVariables(iface, new IdentityHashMap<>());}
0
private static Map<TypeVariable<?>, Type> resolveTypeVariables(Class<?> iface, Map<TypeVariable<?>, Type> reuse)
{    for (Type type : iface.getGenericInterfaces()) {        if (type instanceof ParameterizedType) {            ParameterizedType parameterizedType = (ParameterizedType) type;            Type rawType = parameterizedType.getRawType();            if (rawType instanceof Class<?>) {                Class<?> classType = (Class<?>) rawType;                TypeVariable<? extends Class<?>>[] typeParameters = classType.getTypeParameters();                Type[] actualTypeArguments = parameterizedType.getActualTypeArguments();                for (int i = 0; i < typeParameters.length; i++) {                    reuse.putIfAbsent(typeParameters[i], reuse.getOrDefault(actualTypeArguments[i], actualTypeArguments[i]));                }                resolveTypeVariables(classType, reuse);            }        }    }    return reuse;}
0
public static Action resolve(Schema writer, Schema reader, GenericData data)
{    return resolve(Schema.applyAliases(writer, reader), reader, data, new HashMap<>());}
0
public static Action resolve(Schema writer, Schema reader)
{    return resolve(writer, reader, GenericData.get());}
0
private static Action resolve(Schema w, Schema r, GenericData d, Map<SeenPair, Action> seen)
{    final Schema.Type wType = w.getType();    final Schema.Type rType = r.getType();    if (wType == Schema.Type.UNION)        return WriterUnion.resolve(w, r, d, seen);    if (wType == rType) {        switch(wType) {            case NULL:            case BOOLEAN:            case INT:            case LONG:            case FLOAT:            case DOUBLE:            case STRING:            case BYTES:                return new DoNothing(w, r, d);            case FIXED:                if (w.getFullName() != null && !w.getFullName().equals(r.getFullName()))                    return new ErrorAction(w, r, d, ErrorType.NAMES_DONT_MATCH);                else if (w.getFixedSize() != r.getFixedSize())                    return new ErrorAction(w, r, d, ErrorType.SIZES_DONT_MATCH);                else                    return new DoNothing(w, r, d);            case ARRAY:                Action et = resolve(w.getElementType(), r.getElementType(), d, seen);                return new Container(w, r, d, et);            case MAP:                Action vt = resolve(w.getValueType(), r.getValueType(), d, seen);                return new Container(w, r, d, vt);            case ENUM:                return EnumAdjust.resolve(w, r, d);            case RECORD:                return RecordAdjust.resolve(w, r, d, seen);            default:                throw new IllegalArgumentException("Unknown type for schema: " + wType);        }    } else if (rType == Schema.Type.UNION)        return ReaderUnion.resolve(w, r, d, seen);    else        return Promote.resolve(w, r, d);}
0
public String toString()
{    switch(this.error) {        case INCOMPATIBLE_SCHEMA_TYPES:        case NAMES_DONT_MATCH:        case SIZES_DONT_MATCH:        case NO_MATCHING_BRANCH:            return "Found " + writer.getFullName() + ", expecting " + reader.getFullName();        case MISSING_REQUIRED_FIELD:            {                List<Field> wfields = writer.getFields();                List<Field> rfields = reader.getFields();                String fname = "<oops>";                for (Field rf : rfields) if (writer.getField(rf.name()) == null && rf.defaultValue() == null)                    fname = rf.name();                return ("Found " + writer.getFullName() + ", expecting " + reader.getFullName() + ", missing required field " + fname);            }        default:            throw new IllegalArgumentException("Unknown error.");    }}
0
public static Action resolve(Schema w, Schema r, GenericData d)
{    if (isValid(w, r))        return new Promote(w, r, d);    else        return new ErrorAction(w, r, d, ErrorType.INCOMPATIBLE_SCHEMA_TYPES);}
0
public static boolean isValid(Schema w, Schema r)
{    if (w.getType() == r.getType())        throw new IllegalArgumentException("Only use when reader and writer are different.");    Schema.Type wt = w.getType();    switch(r.getType()) {        case INT:            switch(wt) {                case INT:                    return true;            }            break;        case LONG:            switch(wt) {                case INT:                case LONG:                    return true;            }            break;        case FLOAT:            switch(wt) {                case INT:                case LONG:                case FLOAT:                    return true;            }            break;        case DOUBLE:            switch(wt) {                case INT:                case LONG:                case FLOAT:                case DOUBLE:                    return true;            }            break;        case BYTES:        case STRING:            switch(wt) {                case STRING:                case BYTES:                    return true;            }            break;    }    return false;}
0
public static Action resolve(Schema w, Schema r, GenericData d)
{    if (w.getFullName() != null && !w.getFullName().equals(r.getFullName()))        return new ErrorAction(w, r, d, ErrorType.NAMES_DONT_MATCH);    final List<String> wsymbols = w.getEnumSymbols();    final List<String> rsymbols = r.getEnumSymbols();    final int defaultIndex = (r.getEnumDefault() == null ? -1 : rsymbols.indexOf(r.getEnumDefault()));    int[] adjustments = new int[wsymbols.size()];    for (int i = 0; i < adjustments.length; i++) {        int j = rsymbols.indexOf(wsymbols.get(i));        adjustments[i] = (0 <= j ? j : defaultIndex);    }    return new EnumAdjust(w, r, d, adjustments);}
0
public boolean noReorder()
{    boolean result = true;    for (int i = 0; result && i < readerOrder.length; i++) result &= (i == readerOrder[i].pos());    return result;}
0
 static Action resolve(Schema w, Schema r, GenericData d, Map<SeenPair, Action> seen)
{    SeenPair wr = new SeenPair(w, r);    Action result = seen.get(wr);    if (result != null)        return result;    /*       * Current implementation doesn't do this check. To pass regressions tests, we       * can't either. if (w.getFullName() != null && !       * w.getFullName().equals(r.getFullName())) { result = new ErrorAction(w, r, d,       * ErrorType.NAMES_DONT_MATCH); seen.put(wr, result); return result; }       */    List<Field> wfields = w.getFields();    List<Field> rfields = r.getFields();    int firstDefault = 0;    for (Schema.Field wf : wfields) if (r.getField(wf.name()) != null)        firstDefault++;    Action[] actions = new Action[wfields.size()];    Field[] reordered = new Field[rfields.size()];    Object[] defaults = new Object[reordered.length - firstDefault];    result = new RecordAdjust(w, r, d, actions, reordered, firstDefault, defaults);        seen.put(wr, result);    int i = 0;    int ridx = 0;    for (Field wField : wfields) {        Field rField = r.getField(wField.name());        if (rField != null) {            reordered[ridx++] = rField;            actions[i++] = Resolver.resolve(wField.schema(), rField.schema(), d, seen);        } else            actions[i++] = new Skip(wField.schema(), d);    }    for (Field rf : rfields) if (w.getField(rf.name()) == null)        if (rf.defaultValue() == null) {            result = new ErrorAction(w, r, d, ErrorType.MISSING_REQUIRED_FIELD);            seen.put(wr, result);            return result;        } else {            defaults[ridx - firstDefault] = d.getDefaultValue(rf);            reordered[ridx++] = rf;        }    return result;}
0
public static Action resolve(Schema w, Schema r, GenericData d, Map<SeenPair, Action> seen)
{    boolean ueqv = unionEquiv(w, r, new HashMap<>());    List<Schema> wb = w.getTypes();    List<Schema> rb = (ueqv ? r.getTypes() : null);    int sz = wb.size();    Action[] actions = new Action[sz];    for (int i = 0; i < sz; i++) actions[i] = Resolver.resolve(wb.get(i), (ueqv ? rb.get(i) : r), d, seen);    return new WriterUnion(w, r, d, ueqv, actions);}
0
public static Action resolve(Schema w, Schema r, GenericData d, Map<SeenPair, Action> seen)
{    if (w.getType() == Schema.Type.UNION)        throw new IllegalArgumentException("Writer schema is union.");    int i = firstMatchingBranch(w, r, d, seen);    if (0 <= i)        return new ReaderUnion(w, r, d, i, Resolver.resolve(w, r.getTypes().get(i), d, seen));    return new ErrorAction(w, r, d, ErrorType.NO_MATCHING_BRANCH);}
0
private static int firstMatchingBranch(Schema w, Schema r, GenericData d, Map<SeenPair, Action> seen)
{    Schema.Type vt = w.getType();        int j = 0;    int structureMatch = -1;    for (Schema b : r.getTypes()) {        if (vt == b.getType())            if (vt == Schema.Type.RECORD || vt == Schema.Type.ENUM || vt == Schema.Type.FIXED) {                String vname = w.getFullName();                String bname = b.getFullName();                                if (vname != null && vname.equals(bname))                    return j;                if (vt == Schema.Type.RECORD && !hasMatchError(RecordAdjust.resolve(w, b, d, seen))) {                    String vShortName = w.getName();                    String bShortName = b.getName();                                        if ((structureMatch < 0) || (vShortName != null && vShortName.equals(bShortName))) {                        structureMatch = j;                    }                }            } else                return j;        j++;    }        if (structureMatch >= 0)        return structureMatch;        j = 0;    for (Schema b : r.getTypes()) {        switch(vt) {            case INT:                switch(b.getType()) {                    case LONG:                    case DOUBLE:                    case FLOAT:                        return j;                }                break;            case LONG:                switch(b.getType()) {                    case DOUBLE:                    case FLOAT:                        return j;                }                break;            case FLOAT:                switch(b.getType()) {                    case DOUBLE:                        return j;                }                break;            case STRING:                switch(b.getType()) {                    case BYTES:                        return j;                }                break;            case BYTES:                switch(b.getType()) {                    case STRING:                        return j;                }                break;        }        j++;    }    return -1;}
0
private static boolean hasMatchError(Action action)
{    if (action instanceof ErrorAction)        return true;    else        for (Action a : ((RecordAdjust) action).fieldActions) if (a instanceof ErrorAction)            return true;    return false;}
0
private static boolean unionEquiv(Schema w, Schema r, Map<SeenPair, Boolean> seen)
{    Schema.Type wt = w.getType();    if (wt != r.getType())        return false;        if ((wt == Schema.Type.RECORD || wt == Schema.Type.FIXED || wt == Schema.Type.ENUM) && !(w.getName() == null || w.getName().equals(r.getName())))        return false;    switch(w.getType()) {        case NULL:        case BOOLEAN:        case INT:        case LONG:        case FLOAT:        case DOUBLE:        case STRING:        case BYTES:            return true;        case ARRAY:            return unionEquiv(w.getElementType(), r.getElementType(), seen);        case MAP:            return unionEquiv(w.getValueType(), r.getValueType(), seen);        case FIXED:            return w.getFixedSize() == r.getFixedSize();        case ENUM:            {                List<String> ws = w.getEnumSymbols();                List<String> rs = r.getEnumSymbols();                if (ws.size() != rs.size())                    return false;                int i = 0;                for (i = 0; i < ws.size(); i++) if (!ws.get(i).equals(rs.get(i)))                    break;                return i == ws.size();            }        case UNION:            {                List<Schema> wb = w.getTypes();                List<Schema> rb = r.getTypes();                if (wb.size() != rb.size())                    return false;                int i = 0;                for (i = 0; i < wb.size(); i++) if (!unionEquiv(wb.get(i), rb.get(i), seen))                    break;                return i == wb.size();            }        case RECORD:            {                SeenPair wsc = new SeenPair(w, r);                if (!seen.containsKey(wsc)) {                                        seen.put(wsc, true);                    List<Field> wb = w.getFields();                    List<Field> rb = r.getFields();                    if (wb.size() != rb.size())                        seen.put(wsc, false);                    else {                        int i = 0;                        for (i = 0; i < wb.size(); i++) if (!unionEquiv(wb.get(i).schema(), rb.get(i).schema(), seen))                            break;                        seen.put(wsc, (i == wb.size()));                    }                }                return seen.get(wsc);            }        default:            throw new IllegalArgumentException("Unknown schema type: " + w.getType());    }}
0
protected Object writeReplace()
{    SerializableSchema ss = new SerializableSchema();    ss.schemaString = toString();    return ss;}
0
private Object readResolve()
{    return new Schema.Parser().parse(schemaString);}
0
public String getName()
{    return name;}
0
public static Schema create(Type type)
{    switch(type) {        case STRING:            return new StringSchema();        case BYTES:            return new BytesSchema();        case INT:            return new IntSchema();        case LONG:            return new LongSchema();        case FLOAT:            return new FloatSchema();        case DOUBLE:            return new DoubleSchema();        case BOOLEAN:            return new BooleanSchema();        case NULL:            return new NullSchema();        default:            throw new AvroRuntimeException("Can't create a: " + type);    }}
0
public void addProp(String name, String value)
{    super.addProp(name, value);    hashCode = NO_HASHCODE;}
0
public void addProp(String name, Object value)
{    super.addProp(name, value);    hashCode = NO_HASHCODE;}
0
public LogicalType getLogicalType()
{    return logicalType;}
0
 void setLogicalType(LogicalType logicalType)
{    this.logicalType = logicalType;}
0
public static Schema createRecord(List<Field> fields)
{    Schema result = createRecord(null, null, null, false);    result.setFields(fields);    return result;}
0
public static Schema createRecord(String name, String doc, String namespace, boolean isError)
{    return new RecordSchema(new Name(name, namespace), doc, isError);}
0
public static Schema createRecord(String name, String doc, String namespace, boolean isError, List<Field> fields)
{    return new RecordSchema(new Name(name, namespace), doc, isError, fields);}
0
public static Schema createEnum(String name, String doc, String namespace, List<String> values)
{    return new EnumSchema(new Name(name, namespace), doc, new LockableArrayList<>(values), null);}
0
public static Schema createEnum(String name, String doc, String namespace, List<String> values, String enumDefault)
{    return new EnumSchema(new Name(name, namespace), doc, new LockableArrayList<>(values), enumDefault);}
0
public static Schema createArray(Schema elementType)
{    return new ArraySchema(elementType);}
0
public static Schema createMap(Schema valueType)
{    return new MapSchema(valueType);}
0
public static Schema createUnion(List<Schema> types)
{    return new UnionSchema(new LockableArrayList<>(types));}
0
public static Schema createUnion(Schema... types)
{    return createUnion(new LockableArrayList<>(types));}
0
public static Schema createFixed(String name, String doc, String space, int size)
{    return new FixedSchema(new Name(name, space), doc, size);}
0
public Type getType()
{    return type;}
0
public Field getField(String fieldname)
{    throw new AvroRuntimeException("Not a record: " + this);}
0
public List<Field> getFields()
{    throw new AvroRuntimeException("Not a record: " + this);}
0
public void setFields(List<Field> fields)
{    throw new AvroRuntimeException("Not a record: " + this);}
0
public List<String> getEnumSymbols()
{    throw new AvroRuntimeException("Not an enum: " + this);}
0
public String getEnumDefault()
{    throw new AvroRuntimeException("Not an enum: " + this);}
0
public int getEnumOrdinal(String symbol)
{    throw new AvroRuntimeException("Not an enum: " + this);}
0
public boolean hasEnumSymbol(String symbol)
{    throw new AvroRuntimeException("Not an enum: " + this);}
0
public String getName()
{    return type.name;}
0
public String getDoc()
{    return null;}
0
public String getNamespace()
{    throw new AvroRuntimeException("Not a named type: " + this);}
0
public String getFullName()
{    return getName();}
0
public void addAlias(String alias)
{    throw new AvroRuntimeException("Not a named type: " + this);}
0
public void addAlias(String alias, String space)
{    throw new AvroRuntimeException("Not a named type: " + this);}
0
public Set<String> getAliases()
{    throw new AvroRuntimeException("Not a named type: " + this);}
0
public boolean isError()
{    throw new AvroRuntimeException("Not a record: " + this);}
0
public Schema getElementType()
{    throw new AvroRuntimeException("Not an array: " + this);}
0
public Schema getValueType()
{    throw new AvroRuntimeException("Not a map: " + this);}
0
public List<Schema> getTypes()
{    throw new AvroRuntimeException("Not a union: " + this);}
0
public Integer getIndexNamed(String name)
{    throw new AvroRuntimeException("Not a union: " + this);}
0
public int getFixedSize()
{    throw new AvroRuntimeException("Not fixed: " + this);}
0
public String toString()
{    return toString(false);}
0
public String toString(boolean pretty)
{    try {        StringWriter writer = new StringWriter();        JsonGenerator gen = FACTORY.createGenerator(writer);        if (pretty)            gen.useDefaultPrettyPrinter();        toJson(new Names(), gen);        gen.flush();        return writer.toString();    } catch (IOException e) {        throw new AvroRuntimeException(e);    }}
0
 void toJson(Names names, JsonGenerator gen) throws IOException
{    if (!hasProps()) {                        gen.writeString(getName());    } else {        gen.writeStartObject();        gen.writeStringField("type", getName());        writeProps(gen);        gen.writeEndObject();    }}
0
 void fieldsToJson(Names names, JsonGenerator gen) throws IOException
{    throw new AvroRuntimeException("Not a record: " + this);}
0
public boolean equals(Object o)
{    if (o == this)        return true;    if (!(o instanceof Schema))        return false;    Schema that = (Schema) o;    if (!(this.type == that.type))        return false;    return equalCachedHash(that) && propsEqual(that);}
0
public final int hashCode()
{    if (hashCode == NO_HASHCODE)        hashCode = computeHash();    return hashCode;}
0
 int computeHash()
{    return getType().hashCode() + propsHashCode();}
0
 final boolean equalCachedHash(Schema other)
{    return (hashCode == other.hashCode) || (hashCode == NO_HASHCODE) || (other.hashCode == NO_HASHCODE);}
0
public boolean isUnion()
{    return this instanceof UnionSchema;}
0
public boolean isNullable()
{    if (!isUnion()) {        return getType().equals(Schema.Type.NULL);    }    for (Schema schema : getTypes()) {        if (schema.isNullable()) {            return true;        }    }    return false;}
0
protected JsonNode defaultValue(Field field)
{    return field.defaultValue();}
0
protected Field createField(String name, Schema schema, String doc, JsonNode defaultValue)
{    return new Field(name, schema, doc, defaultValue, true, Order.ASCENDING);}
0
protected Field createField(String name, Schema schema, String doc, JsonNode defaultValue, boolean validate, Order order)
{    return new Field(name, schema, doc, defaultValue, validate, order);}
0
public String name()
{    return name;}
0
public int pos()
{    return position;}
0
public Schema schema()
{    return schema;}
0
public String doc()
{    return doc;}
0
public boolean hasDefaultValue()
{    return defaultValue != null;}
0
 JsonNode defaultValue()
{    return defaultValue;}
0
public Object defaultVal()
{    return JacksonUtils.toObject(defaultValue, schema);}
0
public Order order()
{    return order;}
0
public void addAlias(String alias)
{    if (aliases == null)        this.aliases = new LinkedHashSet<>();    aliases.add(alias);}
0
public Set<String> aliases()
{    if (aliases == null)        return Collections.emptySet();    return Collections.unmodifiableSet(aliases);}
0
public boolean equals(Object other)
{    if (other == this)        return true;    if (!(other instanceof Field))        return false;    Field that = (Field) other;    return (name.equals(that.name)) && (schema.equals(that.schema)) && defaultValueEquals(that.defaultValue) && (order == that.order) && propsEqual(that);}
0
public int hashCode()
{    return name.hashCode() + schema.computeHash();}
0
private boolean defaultValueEquals(JsonNode thatDefaultValue)
{    if (defaultValue == null)        return thatDefaultValue == null;    if (thatDefaultValue == null)        return false;    if (Double.isNaN(defaultValue.doubleValue()))        return Double.isNaN(thatDefaultValue.doubleValue());    return defaultValue.equals(thatDefaultValue);}
0
public String toString()
{    return name + " type:" + schema.type + " pos:" + position;}
0
public boolean equals(Object o)
{    if (o == this)        return true;    if (!(o instanceof Name))        return false;    Name that = (Name) o;    return Objects.equals(full, that.full);}
0
public int hashCode()
{    return full == null ? 0 : full.hashCode();}
0
public String toString()
{    return full;}
0
public void writeName(Names names, JsonGenerator gen) throws IOException
{    if (name != null)        gen.writeStringField("name", name);    if (space != null) {        if (!space.equals(names.space()))            gen.writeStringField("namespace", space);    } else if (names.space() != null) {                gen.writeStringField("namespace", "");    }}
0
public String getQualified(String defaultSpace)
{    return (space == null || space.equals(defaultSpace)) ? name : full;}
0
public String getName()
{    return name.name;}
0
public String getDoc()
{    return doc;}
0
public String getNamespace()
{    return name.space;}
0
public String getFullName()
{    return name.full;}
0
public void addAlias(String alias)
{    addAlias(alias, null);}
0
public void addAlias(String name, String space)
{    if (aliases == null)        this.aliases = new LinkedHashSet<>();    if (space == null)        space = this.name.space;    aliases.add(new Name(name, space));}
0
public Set<String> getAliases()
{    Set<String> result = new LinkedHashSet<>();    if (aliases != null)        for (Name alias : aliases) result.add(alias.full);    return result;}
0
public boolean writeNameRef(Names names, JsonGenerator gen) throws IOException
{    if (this.equals(names.get(name))) {        gen.writeString(name.getQualified(names.space()));        return true;    } else if (name.name != null) {        names.put(name, this);    }    return false;}
0
public void writeName(Names names, JsonGenerator gen) throws IOException
{    name.writeName(names, gen);}
0
public boolean equalNames(NamedSchema that)
{    return this.name.equals(that.name);}
0
 int computeHash()
{    return super.computeHash() + name.hashCode();}
0
public void aliasesToJson(JsonGenerator gen) throws IOException
{    if (aliases == null || aliases.size() == 0)        return;    gen.writeFieldName("aliases");    gen.writeStartArray();    for (Name alias : aliases) gen.writeString(alias.getQualified(name.space));    gen.writeEndArray();}
0
public boolean equals(Object o)
{    if (!(o instanceof SeenPair))        return false;    return this.s1 == ((SeenPair) o).s1 && this.s2 == ((SeenPair) o).s2;}
0
public int hashCode()
{    return System.identityHashCode(s1) + System.identityHashCode(s2);}
0
public boolean isError()
{    return isError;}
0
public Field getField(String fieldname)
{    if (fieldMap == null)        throw new AvroRuntimeException("Schema fields not set yet");    return fieldMap.get(fieldname);}
0
public List<Field> getFields()
{    if (fields == null)        throw new AvroRuntimeException("Schema fields not set yet");    return fields;}
0
public void setFields(List<Field> fields)
{    if (this.fields != null) {        throw new AvroRuntimeException("Fields are already set");    }    int i = 0;    fieldMap = new HashMap<>();    LockableArrayList ff = new LockableArrayList();    for (Field f : fields) {        if (f.position != -1)            throw new AvroRuntimeException("Field already used: " + f);        f.position = i++;        final Field existingField = fieldMap.put(f.name(), f);        if (existingField != null) {            throw new AvroRuntimeException(String.format("Duplicate field %s in record %s: %s and %s.", f.name(), name, f, existingField));        }        ff.add(f);    }    this.fields = ff.lock();    this.hashCode = NO_HASHCODE;}
0
public boolean equals(Object o)
{    if (o == this)        return true;    if (!(o instanceof RecordSchema))        return false;    RecordSchema that = (RecordSchema) o;    if (!equalCachedHash(that))        return false;    if (!equalNames(that))        return false;    if (!propsEqual(that))        return false;    Set seen = SEEN_EQUALS.get();    SeenPair here = new SeenPair(this, o);    if (seen.contains(here))                return true;    boolean first = seen.isEmpty();    try {        seen.add(here);        return Objects.equals(fields, that.fields);    } finally {        if (first)            seen.clear();    }}
0
 int computeHash()
{    Map seen = SEEN_HASHCODE.get();    if (seen.containsKey(this))                return 0;    boolean first = seen.isEmpty();    try {        seen.put(this, this);        return super.computeHash() + fields.hashCode();    } finally {        if (first)            seen.clear();    }}
0
 void toJson(Names names, JsonGenerator gen) throws IOException
{    if (writeNameRef(names, gen))        return;        String savedSpace = names.space;    gen.writeStartObject();    gen.writeStringField("type", isError ? "error" : "record");    writeName(names, gen);        names.space = name.space;    if (getDoc() != null)        gen.writeStringField("doc", getDoc());    if (fields != null) {        gen.writeFieldName("fields");        fieldsToJson(names, gen);    }    writeProps(gen);    aliasesToJson(gen);    gen.writeEndObject();        names.space = savedSpace;}
0
 void fieldsToJson(Names names, JsonGenerator gen) throws IOException
{    gen.writeStartArray();    for (Field f : fields) {        gen.writeStartObject();        gen.writeStringField("name", f.name());        gen.writeFieldName("type");        f.schema().toJson(names, gen);        if (f.doc() != null)            gen.writeStringField("doc", f.doc());        if (f.hasDefaultValue()) {            gen.writeFieldName("default");            gen.writeTree(f.defaultValue());        }        if (f.order() != Field.Order.ASCENDING)            gen.writeStringField("order", f.order().name);        if (f.aliases != null && f.aliases.size() != 0) {            gen.writeFieldName("aliases");            gen.writeStartArray();            for (String alias : f.aliases) gen.writeString(alias);            gen.writeEndArray();        }        f.writeProps(gen);        gen.writeEndObject();    }    gen.writeEndArray();}
0
public List<String> getEnumSymbols()
{    return symbols;}
0
public boolean hasEnumSymbol(String symbol)
{    return ordinals.containsKey(symbol);}
0
public int getEnumOrdinal(String symbol)
{    return ordinals.get(symbol);}
0
public boolean equals(Object o)
{    if (o == this)        return true;    if (!(o instanceof EnumSchema))        return false;    EnumSchema that = (EnumSchema) o;    return equalCachedHash(that) && equalNames(that) && symbols.equals(that.symbols) && propsEqual(that);}
0
public String getEnumDefault()
{    return enumDefault;}
0
 int computeHash()
{    return super.computeHash() + symbols.hashCode();}
0
 void toJson(Names names, JsonGenerator gen) throws IOException
{    if (writeNameRef(names, gen))        return;    gen.writeStartObject();    gen.writeStringField("type", "enum");    writeName(names, gen);    if (getDoc() != null)        gen.writeStringField("doc", getDoc());    gen.writeArrayFieldStart("symbols");    for (String symbol : symbols) gen.writeString(symbol);    gen.writeEndArray();    if (getEnumDefault() != null)        gen.writeStringField("default", getEnumDefault());    writeProps(gen);    aliasesToJson(gen);    gen.writeEndObject();}
0
public Schema getElementType()
{    return elementType;}
0
public boolean equals(Object o)
{    if (o == this)        return true;    if (!(o instanceof ArraySchema))        return false;    ArraySchema that = (ArraySchema) o;    return equalCachedHash(that) && elementType.equals(that.elementType) && propsEqual(that);}
0
 int computeHash()
{    return super.computeHash() + elementType.computeHash();}
0
 void toJson(Names names, JsonGenerator gen) throws IOException
{    gen.writeStartObject();    gen.writeStringField("type", "array");    gen.writeFieldName("items");    elementType.toJson(names, gen);    writeProps(gen);    gen.writeEndObject();}
0
public Schema getValueType()
{    return valueType;}
0
public boolean equals(Object o)
{    if (o == this)        return true;    if (!(o instanceof MapSchema))        return false;    MapSchema that = (MapSchema) o;    return equalCachedHash(that) && valueType.equals(that.valueType) && propsEqual(that);}
0
 int computeHash()
{    return super.computeHash() + valueType.computeHash();}
0
 void toJson(Names names, JsonGenerator gen) throws IOException
{    gen.writeStartObject();    gen.writeStringField("type", "map");    gen.writeFieldName("values");    valueType.toJson(names, gen);    writeProps(gen);    gen.writeEndObject();}
0
public List<Schema> getTypes()
{    return types;}
0
public Integer getIndexNamed(String name)
{    return indexByName.get(name);}
0
public boolean equals(Object o)
{    if (o == this)        return true;    if (!(o instanceof UnionSchema))        return false;    UnionSchema that = (UnionSchema) o;    return equalCachedHash(that) && types.equals(that.types) && propsEqual(that);}
0
 int computeHash()
{    int hash = super.computeHash();    for (Schema type : types) hash += type.computeHash();    return hash;}
0
public void addProp(String name, String value)
{    throw new AvroRuntimeException("Can't set properties on a union: " + this);}
0
 void toJson(Names names, JsonGenerator gen) throws IOException
{    gen.writeStartArray();    for (Schema type : types) type.toJson(names, gen);    gen.writeEndArray();}
0
public int getFixedSize()
{    return size;}
0
public boolean equals(Object o)
{    if (o == this)        return true;    if (!(o instanceof FixedSchema))        return false;    FixedSchema that = (FixedSchema) o;    return equalCachedHash(that) && equalNames(that) && size == that.size && propsEqual(that);}
0
 int computeHash()
{    return super.computeHash() + size;}
0
 void toJson(Names names, JsonGenerator gen) throws IOException
{    if (writeNameRef(names, gen))        return;    gen.writeStartObject();    gen.writeStringField("type", "fixed");    writeName(names, gen);    if (getDoc() != null)        gen.writeStringField("doc", getDoc());    gen.writeNumberField("size", size);    writeProps(gen);    aliasesToJson(gen);    gen.writeEndObject();}
0
public Parser addTypes(Map<String, Schema> types)
{    for (Schema s : types.values()) names.add(s);    return this;}
0
public Map<String, Schema> getTypes()
{    Map<String, Schema> result = new LinkedHashMap<>();    for (Schema s : names.values()) result.put(s.getFullName(), s);    return result;}
0
public Parser setValidate(boolean validate)
{    this.validate = validate;    return this;}
0
public boolean getValidate()
{    return this.validate;}
0
public Parser setValidateDefaults(boolean validateDefaults)
{    this.validateDefaults = validateDefaults;    return this;}
0
public boolean getValidateDefaults()
{    return this.validateDefaults;}
0
public Schema parse(File file) throws IOException
{    return parse(FACTORY.createParser(file));}
0
public Schema parse(InputStream in) throws IOException
{    return parse(FACTORY.createParser(in).disable(JsonParser.Feature.AUTO_CLOSE_SOURCE));}
0
public Schema parse(String s, String... more)
{    StringBuilder b = new StringBuilder(s);    for (String part : more) b.append(part);    return parse(b.toString());}
0
public Schema parse(String s)
{    try {        return parse(FACTORY.createParser(s));    } catch (IOException e) {        throw new SchemaParseException(e);    }}
0
private Schema parse(JsonParser parser) throws IOException
{    boolean saved = validateNames.get();    boolean savedValidateDefaults = VALIDATE_DEFAULTS.get();    try {        validateNames.set(validate);        VALIDATE_DEFAULTS.set(validateDefaults);        return Schema.parse(MAPPER.readTree(parser), names);    } catch (JsonParseException e) {        throw new SchemaParseException(e);    } finally {        parser.close();        validateNames.set(saved);        VALIDATE_DEFAULTS.set(savedValidateDefaults);    }}
0
public static Schema parse(File file) throws IOException
{    return new Parser().parse(file);}
0
public static Schema parse(InputStream in) throws IOException
{    return new Parser().parse(in);}
0
public static Schema parse(String jsonSchema)
{    return new Parser().parse(jsonSchema);}
0
public static Schema parse(String jsonSchema, boolean validate)
{    return new Parser().setValidate(validate).parse(jsonSchema);}
0
public String space()
{    return space;}
0
public void space(String space)
{    this.space = space;}
0
public Schema get(String o)
{    Type primitive = PRIMITIVES.get(o);    if (primitive != null) {        return Schema.create(primitive);    }    Name name = new Name(o, space);    if (!containsKey(name)) {                name = new Name(o, "");    }    return super.get(name);}
0
public boolean contains(Schema schema)
{    return get(((NamedSchema) schema).name) != null;}
0
public void add(Schema schema)
{    put(((NamedSchema) schema).name, schema);}
0
public Schema put(Name name, Schema schema)
{    if (containsKey(name))        throw new SchemaParseException("Can't redefine: " + name);    return super.put(name, schema);}
0
private static String validateName(String name)
{    if (!validateNames.get())                return name;    int length = name.length();    if (length == 0)        throw new SchemaParseException("Empty name");    char first = name.charAt(0);    if (!(Character.isLetter(first) || first == '_'))        throw new SchemaParseException("Illegal initial character: " + name);    for (int i = 1; i < length; i++) {        char c = name.charAt(i);        if (!(Character.isLetterOrDigit(c) || c == '_'))            throw new SchemaParseException("Illegal character in: " + name);    }    return name;}
0
private static JsonNode validateDefault(String fieldName, Schema schema, JsonNode defaultValue)
{    if (VALIDATE_DEFAULTS.get() && (defaultValue != null) && !isValidDefault(schema, defaultValue)) {                String message = "Invalid default for field " + fieldName + ": " + defaultValue + " not a " + schema;                throw new AvroTypeException(message);    }    return defaultValue;}
0
private static boolean isValidDefault(Schema schema, JsonNode defaultValue)
{    if (defaultValue == null)        return false;    switch(schema.getType()) {        case STRING:        case BYTES:        case ENUM:        case FIXED:            return defaultValue.isTextual();        case INT:        case LONG:        case FLOAT:        case DOUBLE:            return defaultValue.isNumber();        case BOOLEAN:            return defaultValue.isBoolean();        case NULL:            return defaultValue.isNull();        case ARRAY:            if (!defaultValue.isArray())                return false;            for (JsonNode element : defaultValue) if (!isValidDefault(schema.getElementType(), element))                return false;            return true;        case MAP:            if (!defaultValue.isObject())                return false;            for (JsonNode value : defaultValue) if (!isValidDefault(schema.getValueType(), value))                return false;            return true;        case         UNION:            return isValidDefault(schema.getTypes().get(0), defaultValue);        case RECORD:            if (!defaultValue.isObject())                return false;            for (Field field : schema.getFields()) if (!isValidDefault(field.schema(), defaultValue.has(field.name()) ? defaultValue.get(field.name()) : field.defaultValue()))                return false;            return true;        default:            return false;    }}
0
 static Schema parse(JsonNode schema, Names names)
{    if (schema == null) {        throw new SchemaParseException("Cannot parse <null> schema");    }    if (schema.isTextual()) {                Schema result = names.get(schema.textValue());        if (result == null)            throw new SchemaParseException("Undefined name: " + schema);        return result;    } else if (schema.isObject()) {        Schema result;        String type = getRequiredText(schema, "type", "No type");        Name name = null;        String savedSpace = names.space();        String doc = null;        if (type.equals("record") || type.equals("error") || type.equals("enum") || type.equals("fixed")) {            String space = getOptionalText(schema, "namespace");            doc = getOptionalText(schema, "doc");            if (space == null)                space = names.space();            name = new Name(getRequiredText(schema, "name", "No name in schema"), space);            if (name.space != null) {                                names.space(name.space);            }        }        if (PRIMITIVES.containsKey(type)) {                        result = create(PRIMITIVES.get(type));        } else if (type.equals("record") || type.equals("error")) {                        List<Field> fields = new ArrayList<>();            result = new RecordSchema(name, doc, type.equals("error"));            if (name != null)                names.add(result);            JsonNode fieldsNode = schema.get("fields");            if (fieldsNode == null || !fieldsNode.isArray())                throw new SchemaParseException("Record has no fields: " + schema);            for (JsonNode field : fieldsNode) {                String fieldName = getRequiredText(field, "name", "No field name");                String fieldDoc = getOptionalText(field, "doc");                JsonNode fieldTypeNode = field.get("type");                if (fieldTypeNode == null)                    throw new SchemaParseException("No field type: " + field);                if (fieldTypeNode.isTextual() && names.get(fieldTypeNode.textValue()) == null)                    throw new SchemaParseException(fieldTypeNode + " is not a defined name." + " The type of the \"" + fieldName + "\" field must be" + " a defined name or a {\"type\": ...} expression.");                Schema fieldSchema = parse(fieldTypeNode, names);                Field.Order order = Field.Order.ASCENDING;                JsonNode orderNode = field.get("order");                if (orderNode != null)                    order = Field.Order.valueOf(orderNode.textValue().toUpperCase(Locale.ENGLISH));                JsonNode defaultValue = field.get("default");                if (defaultValue != null && (Type.FLOAT.equals(fieldSchema.getType()) || Type.DOUBLE.equals(fieldSchema.getType())) && defaultValue.isTextual())                    defaultValue = new DoubleNode(Double.valueOf(defaultValue.textValue()));                Field f = new Field(fieldName, fieldSchema, fieldDoc, defaultValue, true, order);                Iterator<String> i = field.fieldNames();                while (i.hasNext()) {                                        String prop = i.next();                    if (!FIELD_RESERVED.contains(prop))                        f.addProp(prop, field.get(prop));                }                f.aliases = parseAliases(field);                fields.add(f);            }            result.setFields(fields);        } else if (type.equals("enum")) {                        JsonNode symbolsNode = schema.get("symbols");            if (symbolsNode == null || !symbolsNode.isArray())                throw new SchemaParseException("Enum has no symbols: " + schema);            LockableArrayList<String> symbols = new LockableArrayList<>(symbolsNode.size());            for (JsonNode n : symbolsNode) symbols.add(n.textValue());            JsonNode enumDefault = schema.get("default");            String defaultSymbol = null;            if (enumDefault != null)                defaultSymbol = enumDefault.textValue();            result = new EnumSchema(name, doc, symbols, defaultSymbol);            if (name != null)                names.add(result);        } else if (type.equals("array")) {                        JsonNode itemsNode = schema.get("items");            if (itemsNode == null)                throw new SchemaParseException("Array has no items type: " + schema);            result = new ArraySchema(parse(itemsNode, names));        } else if (type.equals("map")) {                        JsonNode valuesNode = schema.get("values");            if (valuesNode == null)                throw new SchemaParseException("Map has no values type: " + schema);            result = new MapSchema(parse(valuesNode, names));        } else if (type.equals("fixed")) {                        JsonNode sizeNode = schema.get("size");            if (sizeNode == null || !sizeNode.isInt())                throw new SchemaParseException("Invalid or no size: " + schema);            result = new FixedSchema(name, doc, sizeNode.intValue());            if (name != null)                names.add(result);        } else {                        Name nameFromType = new Name(type, names.space);            if (names.containsKey(nameFromType)) {                return names.get(nameFromType);            }            throw new SchemaParseException("Type not supported: " + type);        }        Iterator<String> i = schema.fieldNames();        Set reserved = SCHEMA_RESERVED;        if (type.equals("enum")) {            reserved = ENUM_RESERVED;        }        while (i.hasNext()) {                        String prop = i.next();            if (            !reserved.contains(prop))                result.addProp(prop, schema.get(prop));        }                result.logicalType = LogicalTypes.fromSchemaIgnoreInvalid(result);                names.space(savedSpace);        if (result instanceof NamedSchema) {            Set<String> aliases = parseAliases(schema);            if (            aliases != null)                for (String alias : aliases) result.addAlias(alias);        }        return result;    } else if (schema.isArray()) {                LockableArrayList<Schema> types = new LockableArrayList<>(schema.size());        for (JsonNode typeNode : schema) types.add(parse(typeNode, names));        return new UnionSchema(types);    } else {        throw new SchemaParseException("Schema not yet supported: " + schema);    }}
0
 static Set<String> parseAliases(JsonNode node)
{    JsonNode aliasesNode = node.get("aliases");    if (aliasesNode == null)        return null;    if (!aliasesNode.isArray())        throw new SchemaParseException("aliases not an array: " + node);    Set<String> aliases = new LinkedHashSet<>();    for (JsonNode aliasNode : aliasesNode) {        if (!aliasNode.isTextual())            throw new SchemaParseException("alias not a string: " + aliasNode);        aliases.add(aliasNode.textValue());    }    return aliases;}
0
private static String getRequiredText(JsonNode container, String key, String error)
{    String out = getOptionalText(container, key);    if (null == out) {        throw new SchemaParseException(error + ": " + container);    }    return out;}
0
private static String getOptionalText(JsonNode container, String key)
{    JsonNode jsonNode = container.get(key);    return jsonNode != null ? jsonNode.textValue() : null;}
0
 static JsonNode parseJson(String s)
{    try {        return MAPPER.readTree(FACTORY.createParser(s));    } catch (IOException e) {        throw new RuntimeException(e);    }}
0
public static Object parseJsonToObject(String s)
{    return JacksonUtils.toObject(parseJson(s));}
0
public static Schema applyAliases(Schema writer, Schema reader)
{    if (writer.equals(reader))                return writer;        Map<Schema, Schema> seen = new IdentityHashMap<>(1);    Map<Name, Name> aliases = new HashMap<>(1);    Map<Name, Map<String, String>> fieldAliases = new HashMap<>(1);    getAliases(reader, seen, aliases, fieldAliases);    if (aliases.size() == 0 && fieldAliases.size() == 0)                return writer;    seen.clear();    return applyAliases(writer, seen, aliases, fieldAliases);}
0
private static Schema applyAliases(Schema s, Map<Schema, Schema> seen, Map<Name, Name> aliases, Map<Name, Map<String, String>> fieldAliases)
{    Name name = s instanceof NamedSchema ? ((NamedSchema) s).name : null;    Schema result = s;    switch(s.getType()) {        case RECORD:            if (seen.containsKey(s))                                return seen.get(s);            if (aliases.containsKey(name))                name = aliases.get(name);            result = Schema.createRecord(name.full, s.getDoc(), null, s.isError());            seen.put(s, result);            List<Field> newFields = new ArrayList<>();            for (Field f : s.getFields()) {                Schema fSchema = applyAliases(f.schema, seen, aliases, fieldAliases);                String fName = getFieldAlias(name, f.name, fieldAliases);                Field newF = new Field(fName, fSchema, f.doc, f.defaultValue, true, f.order);                                newF.putAll(f);                newFields.add(newF);            }            result.setFields(newFields);            break;        case ENUM:            if (aliases.containsKey(name))                result = Schema.createEnum(aliases.get(name).full, s.getDoc(), null, s.getEnumSymbols(), s.getEnumDefault());            break;        case ARRAY:            Schema e = applyAliases(s.getElementType(), seen, aliases, fieldAliases);            if (!e.equals(s.getElementType()))                result = Schema.createArray(e);            break;        case MAP:            Schema v = applyAliases(s.getValueType(), seen, aliases, fieldAliases);            if (!v.equals(s.getValueType()))                result = Schema.createMap(v);            break;        case UNION:            List<Schema> types = new ArrayList<>();            for (Schema branch : s.getTypes()) types.add(applyAliases(branch, seen, aliases, fieldAliases));            result = Schema.createUnion(types);            break;        case FIXED:            if (aliases.containsKey(name))                result = Schema.createFixed(aliases.get(name).full, s.getDoc(), null, s.getFixedSize());            break;        default:    }    if (!result.equals(s))                result.putAll(s);    return result;}
0
private static void getAliases(Schema schema, Map<Schema, Schema> seen, Map<Name, Name> aliases, Map<Name, Map<String, String>> fieldAliases)
{    if (schema instanceof NamedSchema) {        NamedSchema namedSchema = (NamedSchema) schema;        if (namedSchema.aliases != null)            for (Name alias : namedSchema.aliases) aliases.put(alias, namedSchema.name);    }    switch(schema.getType()) {        case RECORD:            if (seen.containsKey(schema))                                return;            seen.put(schema, schema);            RecordSchema record = (RecordSchema) schema;            for (Field field : schema.getFields()) {                if (field.aliases != null)                    for (String fieldAlias : field.aliases) {                        Map<String, String> recordAliases = fieldAliases.computeIfAbsent(record.name, k -> new HashMap<>());                        recordAliases.put(fieldAlias, field.name);                    }                getAliases(field.schema, seen, aliases, fieldAliases);            }            if (record.aliases != null && fieldAliases.containsKey(record.name))                for (Name recordAlias : record.aliases) fieldAliases.put(recordAlias, fieldAliases.get(record.name));            break;        case ARRAY:            getAliases(schema.getElementType(), seen, aliases, fieldAliases);            break;        case MAP:            getAliases(schema.getValueType(), seen, aliases, fieldAliases);            break;        case UNION:            for (Schema s : schema.getTypes()) getAliases(s, seen, aliases, fieldAliases);            break;    }}
0
private static String getFieldAlias(Name record, String field, Map<Name, Map<String, String>> fieldAliases)
{    Map<String, String> recordAliases = fieldAliases.get(record);    if (recordAliases == null)        return field;    String alias = recordAliases.get(field);    if (alias == null)        return field;    return alias;}
0
public List<E> lock()
{    locked = true;    return this;}
0
private void ensureUnlocked()
{    if (locked) {        throw new IllegalStateException();    }}
0
public boolean add(E e)
{    ensureUnlocked();    return super.add(e);}
0
public boolean remove(Object o)
{    ensureUnlocked();    return super.remove(o);}
0
public E remove(int index)
{    ensureUnlocked();    return super.remove(index);}
0
public boolean addAll(Collection<? extends E> c)
{    ensureUnlocked();    return super.addAll(c);}
0
public boolean addAll(int index, Collection<? extends E> c)
{    ensureUnlocked();    return super.addAll(index, c);}
0
public boolean removeAll(Collection<?> c)
{    ensureUnlocked();    return super.removeAll(c);}
0
public boolean retainAll(Collection<?> c)
{    ensureUnlocked();    return super.retainAll(c);}
0
public void clear()
{    ensureUnlocked();    super.clear();}
0
public static TypeBuilder<Schema> builder()
{    return new TypeBuilder<>(new SchemaCompletion(), new NameContext());}
0
public static TypeBuilder<Schema> builder(String namespace)
{    return new TypeBuilder<>(new SchemaCompletion(), new NameContext().namespace(namespace));}
0
public static RecordBuilder<Schema> record(String name)
{    return builder().record(name);}
0
public static EnumBuilder<Schema> enumeration(String name)
{    return builder().enumeration(name);}
0
public static FixedBuilder<Schema> fixed(String name)
{    return builder().fixed(name);}
0
public static ArrayBuilder<Schema> array()
{    return builder().array();}
0
public static MapBuilder<Schema> map()
{    return builder().map();}
0
public static BaseTypeBuilder<UnionAccumulator<Schema>> unionOf()
{    return builder().unionOf();}
0
public static BaseTypeBuilder<Schema> nullable()
{    return builder().nullable();}
0
public final S prop(String name, String val)
{    return prop(name, TextNode.valueOf(val));}
0
public final S prop(String name, Object value)
{    return prop(name, JacksonUtils.toJsonNode(value));}
0
 final S prop(String name, JsonNode val)
{    if (!hasProps()) {        props = new HashMap<>();    }    props.put(name, val);    return self();}
0
private boolean hasProps()
{    return (props != null);}
0
 final T addPropsTo(T jsonable)
{    if (hasProps()) {        for (Map.Entry<String, JsonNode> prop : props.entrySet()) {            jsonable.addProp(prop.getKey(), prop.getValue());        }    }    return jsonable;}
0
public final S doc(String doc)
{    this.doc = doc;    return self();}
0
public final S aliases(String... aliases)
{    this.aliases = aliases;    return self();}
0
 final String doc()
{    return doc;}
0
 final String name()
{    return name;}
0
 final NameContext names()
{    return names;}
0
 final Schema addAliasesTo(Schema schema)
{    if (null != aliases) {        for (String alias : aliases) {            schema.addAlias(alias);        }    }    return schema;}
0
 final Field addAliasesTo(Field field)
{    if (null != aliases) {        for (String alias : aliases) {            field.addAlias(alias);        }    }    return field;}
0
public final S namespace(String namespace)
{    this.namespace = namespace;    return self();}
0
 final String space()
{    if (null == namespace) {        return names().namespace;    }    return namespace;}
0
 final Schema completeSchema(Schema schema)
{    addPropsTo(schema);    addAliasesTo(schema);    names().put(schema);    return schema;}
0
 final Completion<R> context()
{    return context;}
0
private R end()
{    Schema schema = immutable;    if (super.hasProps()) {        schema = Schema.create(immutable.getType());        addPropsTo(schema);    }    return context.complete(schema);}
0
private static BooleanBuilder<R> create(Completion<R> context, NameContext names)
{    return new BooleanBuilder<>(context, names);}
0
protected BooleanBuilder<R> self()
{    return this;}
0
public R endBoolean()
{    return super.end();}
0
private static IntBuilder<R> create(Completion<R> context, NameContext names)
{    return new IntBuilder<>(context, names);}
0
protected IntBuilder<R> self()
{    return this;}
0
public R endInt()
{    return super.end();}
0
private static LongBuilder<R> create(Completion<R> context, NameContext names)
{    return new LongBuilder<>(context, names);}
0
protected LongBuilder<R> self()
{    return this;}
0
public R endLong()
{    return super.end();}
0
private static FloatBuilder<R> create(Completion<R> context, NameContext names)
{    return new FloatBuilder<>(context, names);}
0
protected FloatBuilder<R> self()
{    return this;}
0
public R endFloat()
{    return super.end();}
0
private static DoubleBuilder<R> create(Completion<R> context, NameContext names)
{    return new DoubleBuilder<>(context, names);}
0
protected DoubleBuilder<R> self()
{    return this;}
0
public R endDouble()
{    return super.end();}
0
private static StringBldr<R> create(Completion<R> context, NameContext names)
{    return new StringBldr<>(context, names);}
0
protected StringBldr<R> self()
{    return this;}
0
public R endString()
{    return super.end();}
0
private static BytesBuilder<R> create(Completion<R> context, NameContext names)
{    return new BytesBuilder<>(context, names);}
0
protected BytesBuilder<R> self()
{    return this;}
0
public R endBytes()
{    return super.end();}
0
private static NullBuilder<R> create(Completion<R> context, NameContext names)
{    return new NullBuilder<>(context, names);}
0
protected NullBuilder<R> self()
{    return this;}
0
public R endNull()
{    return super.end();}
0
private static FixedBuilder<R> create(Completion<R> context, NameContext names, String name)
{    return new FixedBuilder<>(context, names, name);}
0
protected FixedBuilder<R> self()
{    return this;}
0
public R size(int size)
{    Schema schema = Schema.createFixed(name(), super.doc(), space(), size);    completeSchema(schema);    return context().complete(schema);}
0
private static EnumBuilder<R> create(Completion<R> context, NameContext names, String name)
{    return new EnumBuilder<>(context, names, name);}
0
protected EnumBuilder<R> self()
{    return this;}
0
public R symbols(String... symbols)
{    Schema schema = Schema.createEnum(name(), doc(), space(), Arrays.asList(symbols), this.enumDefault);    completeSchema(schema);    return context().complete(schema);}
0
public EnumBuilder<R> defaultSymbol(String enumDefault)
{    this.enumDefault = enumDefault;    return self();}
0
private static MapBuilder<R> create(Completion<R> context, NameContext names)
{    return new MapBuilder<>(context, names);}
0
protected MapBuilder<R> self()
{    return this;}
0
public TypeBuilder<R> values()
{    return new TypeBuilder<>(new MapCompletion<>(this, context), names);}
0
public R values(Schema valueSchema)
{    return new MapCompletion<>(this, context).complete(valueSchema);}
0
private static ArrayBuilder<R> create(Completion<R> context, NameContext names)
{    return new ArrayBuilder<>(context, names);}
0
protected ArrayBuilder<R> self()
{    return this;}
0
public TypeBuilder<R> items()
{    return new TypeBuilder<>(new ArrayCompletion<>(this, context), names);}
0
public R items(Schema itemsSchema)
{    return new ArrayCompletion<>(this, context).complete(itemsSchema);}
0
private NameContext namespace(String namespace)
{    return new NameContext(schemas, namespace);}
0
private Schema get(String name, String namespace)
{    return getFullname(resolveName(name, namespace));}
0
private Schema getFullname(String fullName)
{    Schema schema = schemas.get(fullName);    if (schema == null) {        throw new SchemaParseException("Undefined name: " + fullName);    }    return schema;}
0
private void put(Schema schema)
{    String fullName = schema.getFullName();    if (schemas.containsKey(fullName)) {        throw new SchemaParseException("Can't redefine: " + fullName);    }    schemas.put(fullName, schema);}
0
private String resolveName(String name, String space)
{    if (PRIMITIVES.contains(name) && space == null) {        return name;    }    int lastDot = name.lastIndexOf('.');    if (lastDot < 0) {                if (space == null) {            space = namespace;        }        if (space != null && !"".equals(space)) {            return space + "." + name;        }    }    return name;}
0
public final R type(Schema schema)
{    return context.complete(schema);}
0
public final R type(String name)
{    return type(name, null);}
0
public final R type(String name, String namespace)
{    return type(names.get(name, namespace));}
0
public final R booleanType()
{    return booleanBuilder().endBoolean();}
0
public final BooleanBuilder<R> booleanBuilder()
{    return BooleanBuilder.create(context, names);}
0
public final R intType()
{    return intBuilder().endInt();}
0
public final IntBuilder<R> intBuilder()
{    return IntBuilder.create(context, names);}
0
public final R longType()
{    return longBuilder().endLong();}
0
public final LongBuilder<R> longBuilder()
{    return LongBuilder.create(context, names);}
0
public final R floatType()
{    return floatBuilder().endFloat();}
0
public final FloatBuilder<R> floatBuilder()
{    return FloatBuilder.create(context, names);}
0
public final R doubleType()
{    return doubleBuilder().endDouble();}
0
public final DoubleBuilder<R> doubleBuilder()
{    return DoubleBuilder.create(context, names);}
0
public final R stringType()
{    return stringBuilder().endString();}
0
public final StringBldr<R> stringBuilder()
{    return StringBldr.create(context, names);}
0
public final R bytesType()
{    return bytesBuilder().endBytes();}
0
public final BytesBuilder<R> bytesBuilder()
{    return BytesBuilder.create(context, names);}
0
public final R nullType()
{    return nullBuilder().endNull();}
0
public final NullBuilder<R> nullBuilder()
{    return NullBuilder.create(context, names);}
0
public final MapBuilder<R> map()
{    return MapBuilder.create(context, names);}
0
public final ArrayBuilder<R> array()
{    return ArrayBuilder.create(context, names);}
0
public final FixedBuilder<R> fixed(String name)
{    return FixedBuilder.create(context, names, name);}
0
public final EnumBuilder<R> enumeration(String name)
{    return EnumBuilder.create(context, names, name);}
0
public final RecordBuilder<R> record(String name)
{    return RecordBuilder.create(context, names, name);}
0
protected BaseTypeBuilder<UnionAccumulator<R>> unionOf()
{    return UnionBuilder.create(context, names);}
0
protected BaseTypeBuilder<R> nullable()
{    return new BaseTypeBuilder<>(new NullableCompletion<>(context), names);}
0
public BaseTypeBuilder<UnionAccumulator<R>> unionOf()
{    return super.unionOf();}
0
public BaseTypeBuilder<R> nullable()
{    return super.nullable();}
0
private static UnionBuilder<R> create(Completion<R> context, NameContext names)
{    return new UnionBuilder<>(context, names);}
0
public final BooleanDefault<R> booleanType()
{    return booleanBuilder().endBoolean();}
0
public final BooleanBuilder<BooleanDefault<R>> booleanBuilder()
{    return BooleanBuilder.create(wrap(new BooleanDefault<>(bldr)), names);}
0
public final IntDefault<R> intType()
{    return intBuilder().endInt();}
0
public final IntBuilder<IntDefault<R>> intBuilder()
{    return IntBuilder.create(wrap(new IntDefault<>(bldr)), names);}
0
public final LongDefault<R> longType()
{    return longBuilder().endLong();}
0
public final LongBuilder<LongDefault<R>> longBuilder()
{    return LongBuilder.create(wrap(new LongDefault<>(bldr)), names);}
0
public final FloatDefault<R> floatType()
{    return floatBuilder().endFloat();}
0
public final FloatBuilder<FloatDefault<R>> floatBuilder()
{    return FloatBuilder.create(wrap(new FloatDefault<>(bldr)), names);}
0
public final DoubleDefault<R> doubleType()
{    return doubleBuilder().endDouble();}
0
public final DoubleBuilder<DoubleDefault<R>> doubleBuilder()
{    return DoubleBuilder.create(wrap(new DoubleDefault<>(bldr)), names);}
0
public final StringDefault<R> stringType()
{    return stringBuilder().endString();}
0
public final StringBldr<StringDefault<R>> stringBuilder()
{    return StringBldr.create(wrap(new StringDefault<>(bldr)), names);}
0
public final BytesDefault<R> bytesType()
{    return bytesBuilder().endBytes();}
0
public final BytesBuilder<BytesDefault<R>> bytesBuilder()
{    return BytesBuilder.create(wrap(new BytesDefault<>(bldr)), names);}
0
public final NullDefault<R> nullType()
{    return nullBuilder().endNull();}
0
public final NullBuilder<NullDefault<R>> nullBuilder()
{    return NullBuilder.create(wrap(new NullDefault<>(bldr)), names);}
0
public final MapBuilder<MapDefault<R>> map()
{    return MapBuilder.create(wrap(new MapDefault<>(bldr)), names);}
0
public final ArrayBuilder<ArrayDefault<R>> array()
{    return ArrayBuilder.create(wrap(new ArrayDefault<>(bldr)), names);}
0
public final FixedBuilder<FixedDefault<R>> fixed(String name)
{    return FixedBuilder.create(wrap(new FixedDefault<>(bldr)), names, name);}
0
public final EnumBuilder<EnumDefault<R>> enumeration(String name)
{    return EnumBuilder.create(wrap(new EnumDefault<>(bldr)), names, name);}
0
public final RecordBuilder<RecordDefault<R>> record(String name)
{    return RecordBuilder.create(wrap(new RecordDefault<>(bldr)), names, name);}
0
private Completion<C> wrap(Completion<C> completion)
{    if (wrapper != null) {        return wrapper.wrap(completion);    }    return completion;}
0
public UnionFieldTypeBuilder<R> unionOf()
{    return new UnionFieldTypeBuilder<>(bldr);}
0
public BaseFieldTypeBuilder<R> nullable()
{    return new BaseFieldTypeBuilder<>(bldr, new NullableCompletionWrapper());}
0
public BaseTypeBuilder<FieldAssembler<R>> optional()
{    return new BaseTypeBuilder<>(new OptionalCompletion<>(bldr), names);}
0
public UnionAccumulator<BooleanDefault<R>> booleanType()
{    return booleanBuilder().endBoolean();}
0
public BooleanBuilder<UnionAccumulator<BooleanDefault<R>>> booleanBuilder()
{    return BooleanBuilder.create(completion(new BooleanDefault<>(bldr)), names);}
0
public UnionAccumulator<IntDefault<R>> intType()
{    return intBuilder().endInt();}
0
public IntBuilder<UnionAccumulator<IntDefault<R>>> intBuilder()
{    return IntBuilder.create(completion(new IntDefault<>(bldr)), names);}
0
public UnionAccumulator<LongDefault<R>> longType()
{    return longBuilder().endLong();}
0
public LongBuilder<UnionAccumulator<LongDefault<R>>> longBuilder()
{    return LongBuilder.create(completion(new LongDefault<>(bldr)), names);}
0
public UnionAccumulator<FloatDefault<R>> floatType()
{    return floatBuilder().endFloat();}
0
public FloatBuilder<UnionAccumulator<FloatDefault<R>>> floatBuilder()
{    return FloatBuilder.create(completion(new FloatDefault<>(bldr)), names);}
0
public UnionAccumulator<DoubleDefault<R>> doubleType()
{    return doubleBuilder().endDouble();}
0
public DoubleBuilder<UnionAccumulator<DoubleDefault<R>>> doubleBuilder()
{    return DoubleBuilder.create(completion(new DoubleDefault<>(bldr)), names);}
0
public UnionAccumulator<StringDefault<R>> stringType()
{    return stringBuilder().endString();}
0
public StringBldr<UnionAccumulator<StringDefault<R>>> stringBuilder()
{    return StringBldr.create(completion(new StringDefault<>(bldr)), names);}
0
public UnionAccumulator<BytesDefault<R>> bytesType()
{    return bytesBuilder().endBytes();}
0
public BytesBuilder<UnionAccumulator<BytesDefault<R>>> bytesBuilder()
{    return BytesBuilder.create(completion(new BytesDefault<>(bldr)), names);}
0
public UnionAccumulator<NullDefault<R>> nullType()
{    return nullBuilder().endNull();}
0
public NullBuilder<UnionAccumulator<NullDefault<R>>> nullBuilder()
{    return NullBuilder.create(completion(new NullDefault<>(bldr)), names);}
0
public MapBuilder<UnionAccumulator<MapDefault<R>>> map()
{    return MapBuilder.create(completion(new MapDefault<>(bldr)), names);}
0
public ArrayBuilder<UnionAccumulator<ArrayDefault<R>>> array()
{    return ArrayBuilder.create(completion(new ArrayDefault<>(bldr)), names);}
0
public FixedBuilder<UnionAccumulator<FixedDefault<R>>> fixed(String name)
{    return FixedBuilder.create(completion(new FixedDefault<>(bldr)), names, name);}
0
public EnumBuilder<UnionAccumulator<EnumDefault<R>>> enumeration(String name)
{    return EnumBuilder.create(completion(new EnumDefault<>(bldr)), names, name);}
0
public RecordBuilder<UnionAccumulator<RecordDefault<R>>> record(String name)
{    return RecordBuilder.create(completion(new RecordDefault<>(bldr)), names, name);}
0
private UnionCompletion<C> completion(Completion<C> context)
{    return new UnionCompletion<>(context, names, new ArrayList<>());}
0
private static RecordBuilder<R> create(Completion<R> context, NameContext names, String name)
{    return new RecordBuilder<>(context, names, name);}
0
protected RecordBuilder<R> self()
{    return this;}
0
public FieldAssembler<R> fields()
{    Schema record = Schema.createRecord(name(), doc(), space(), false);        completeSchema(record);    return new FieldAssembler<>(context(), names().namespace(record.getNamespace()), record);}
0
public FieldBuilder<R> name(String fieldName)
{    return new FieldBuilder<>(this, names, fieldName);}
0
public FieldAssembler<R> requiredBoolean(String fieldName)
{    return name(fieldName).type().booleanType().noDefault();}
0
public FieldAssembler<R> optionalBoolean(String fieldName)
{    return name(fieldName).type().optional().booleanType();}
0
public FieldAssembler<R> nullableBoolean(String fieldName, boolean defaultVal)
{    return name(fieldName).type().nullable().booleanType().booleanDefault(defaultVal);}
0
public FieldAssembler<R> requiredInt(String fieldName)
{    return name(fieldName).type().intType().noDefault();}
0
public FieldAssembler<R> optionalInt(String fieldName)
{    return name(fieldName).type().optional().intType();}
0
public FieldAssembler<R> nullableInt(String fieldName, int defaultVal)
{    return name(fieldName).type().nullable().intType().intDefault(defaultVal);}
0
public FieldAssembler<R> requiredLong(String fieldName)
{    return name(fieldName).type().longType().noDefault();}
0
public FieldAssembler<R> optionalLong(String fieldName)
{    return name(fieldName).type().optional().longType();}
0
public FieldAssembler<R> nullableLong(String fieldName, long defaultVal)
{    return name(fieldName).type().nullable().longType().longDefault(defaultVal);}
0
public FieldAssembler<R> requiredFloat(String fieldName)
{    return name(fieldName).type().floatType().noDefault();}
0
public FieldAssembler<R> optionalFloat(String fieldName)
{    return name(fieldName).type().optional().floatType();}
0
public FieldAssembler<R> nullableFloat(String fieldName, float defaultVal)
{    return name(fieldName).type().nullable().floatType().floatDefault(defaultVal);}
0
public FieldAssembler<R> requiredDouble(String fieldName)
{    return name(fieldName).type().doubleType().noDefault();}
0
public FieldAssembler<R> optionalDouble(String fieldName)
{    return name(fieldName).type().optional().doubleType();}
0
public FieldAssembler<R> nullableDouble(String fieldName, double defaultVal)
{    return name(fieldName).type().nullable().doubleType().doubleDefault(defaultVal);}
0
public FieldAssembler<R> requiredString(String fieldName)
{    return name(fieldName).type().stringType().noDefault();}
0
public FieldAssembler<R> optionalString(String fieldName)
{    return name(fieldName).type().optional().stringType();}
0
public FieldAssembler<R> nullableString(String fieldName, String defaultVal)
{    return name(fieldName).type().nullable().stringType().stringDefault(defaultVal);}
0
public FieldAssembler<R> requiredBytes(String fieldName)
{    return name(fieldName).type().bytesType().noDefault();}
0
public FieldAssembler<R> optionalBytes(String fieldName)
{    return name(fieldName).type().optional().bytesType();}
0
public FieldAssembler<R> nullableBytes(String fieldName, byte[] defaultVal)
{    return name(fieldName).type().nullable().bytesType().bytesDefault(defaultVal);}
0
public R endRecord()
{    record.setFields(fields);    return context.complete(record);}
0
private FieldAssembler<R> addField(Field field)
{    fields.add(field);    return this;}
0
public FieldBuilder<R> orderAscending()
{    order = Schema.Field.Order.ASCENDING;    return self();}
0
public FieldBuilder<R> orderDescending()
{    order = Schema.Field.Order.DESCENDING;    return self();}
0
public FieldBuilder<R> orderIgnore()
{    order = Schema.Field.Order.IGNORE;    return self();}
0
public FieldTypeBuilder<R> type()
{    return new FieldTypeBuilder<>(this);}
0
public GenericDefault<R> type(Schema type)
{    return new GenericDefault<>(this, type);}
0
public GenericDefault<R> type(String name)
{    return type(name, null);}
0
public GenericDefault<R> type(String name, String namespace)
{    Schema schema = names().get(name, namespace);    return type(schema);}
0
private FieldAssembler<R> completeField(Schema schema, Object defaultVal)
{    JsonNode defaultNode = defaultVal == null ? NullNode.getInstance() : toJsonNode(defaultVal);    return completeField(schema, defaultNode);}
0
private FieldAssembler<R> completeField(Schema schema)
{    return completeField(schema, (JsonNode) null);}
0
private FieldAssembler<R> completeField(Schema schema, JsonNode defaultVal)
{    Field field = new Field(name(), schema, doc(), defaultVal, true, order);    addPropsTo(field);    addAliasesTo(field);    return fields.addField(field);}
0
protected FieldBuilder<R> self()
{    return this;}
0
public final FieldAssembler<R> noDefault()
{    return field.completeField(schema);}
0
private FieldAssembler<R> usingDefault(Object defaultVal)
{    return field.completeField(schema, defaultVal);}
0
 final S complete(Schema schema)
{    this.schema = schema;    return self();}
0
public final FieldAssembler<R> booleanDefault(boolean defaultVal)
{    return super.usingDefault(defaultVal);}
0
 final BooleanDefault<R> self()
{    return this;}
0
public final FieldAssembler<R> intDefault(int defaultVal)
{    return super.usingDefault(defaultVal);}
0
 final IntDefault<R> self()
{    return this;}
0
public final FieldAssembler<R> longDefault(long defaultVal)
{    return super.usingDefault(defaultVal);}
0
 final LongDefault<R> self()
{    return this;}
0
public final FieldAssembler<R> floatDefault(float defaultVal)
{    return super.usingDefault(defaultVal);}
0
 final FloatDefault<R> self()
{    return this;}
0
public final FieldAssembler<R> doubleDefault(double defaultVal)
{    return super.usingDefault(defaultVal);}
0
 final DoubleDefault<R> self()
{    return this;}
0
public final FieldAssembler<R> stringDefault(String defaultVal)
{    return super.usingDefault(defaultVal);}
0
 final StringDefault<R> self()
{    return this;}
0
public final FieldAssembler<R> bytesDefault(byte[] defaultVal)
{    return super.usingDefault(ByteBuffer.wrap(defaultVal));}
0
public final FieldAssembler<R> bytesDefault(ByteBuffer defaultVal)
{    return super.usingDefault(defaultVal);}
0
public final FieldAssembler<R> bytesDefault(String defaultVal)
{    return super.usingDefault(defaultVal);}
0
 final BytesDefault<R> self()
{    return this;}
0
public final FieldAssembler<R> nullDefault()
{    return super.usingDefault(null);}
0
 final NullDefault<R> self()
{    return this;}
0
public final FieldAssembler<R> mapDefault(Map<K, V> defaultVal)
{    return super.usingDefault(defaultVal);}
0
 final MapDefault<R> self()
{    return this;}
0
public final FieldAssembler<R> arrayDefault(List<V> defaultVal)
{    return super.usingDefault(defaultVal);}
0
 final ArrayDefault<R> self()
{    return this;}
0
public final FieldAssembler<R> fixedDefault(byte[] defaultVal)
{    return super.usingDefault(ByteBuffer.wrap(defaultVal));}
0
public final FieldAssembler<R> fixedDefault(ByteBuffer defaultVal)
{    return super.usingDefault(defaultVal);}
0
public final FieldAssembler<R> fixedDefault(String defaultVal)
{    return super.usingDefault(defaultVal);}
0
 final FixedDefault<R> self()
{    return this;}
0
public final FieldAssembler<R> enumDefault(String defaultVal)
{    return super.usingDefault(defaultVal);}
0
 final EnumDefault<R> self()
{    return this;}
0
public final FieldAssembler<R> recordDefault(GenericRecord defaultVal)
{    return super.usingDefault(defaultVal);}
0
 final RecordDefault<R> self()
{    return this;}
0
public FieldAssembler<R> noDefault()
{    return field.completeField(schema);}
0
public FieldAssembler<R> withDefault(Object defaultVal)
{    return field.completeField(schema, defaultVal);}
0
protected Schema complete(Schema schema)
{    return schema;}
0
protected R complete(Schema schema)
{        Schema nullable = Schema.createUnion(Arrays.asList(schema, NULL_SCHEMA));    return context.complete(nullable);}
0
protected FieldAssembler<R> complete(Schema schema)
{        Schema optional = Schema.createUnion(Arrays.asList(NULL_SCHEMA, schema));    return bldr.completeField(optional, (Object) null);}
0
 Completion<R> wrap(Completion<R> completion)
{    return new NullableCompletion<>(completion);}
0
protected final R complete(Schema schema)
{    Schema outer = outerSchema(schema);    assembler.addPropsTo(outer);    return context.complete(outer);}
0
protected Schema outerSchema(Schema inner)
{    return Schema.createMap(inner);}
0
protected Schema outerSchema(Schema inner)
{    return Schema.createArray(inner);}
0
protected UnionAccumulator<R> complete(Schema schema)
{    List<Schema> updated = new ArrayList<>(this.schemas);    updated.add(schema);    return new UnionAccumulator<>(context, names, updated);}
0
public BaseTypeBuilder<UnionAccumulator<R>> and()
{    return new UnionBuilder<>(context, names, schemas);}
0
public R endUnion()
{    Schema schema = Schema.createUnion(schemas);    return context.complete(schema);}
0
private static void checkRequired(Object reference, String errorMessage)
{    if (reference == null) {        throw new NullPointerException(errorMessage);    }}
0
private static JsonNode toJsonNode(Object o)
{    try {        String s;        if (o instanceof ByteBuffer) {                                    ByteBuffer bytes = ((ByteBuffer) o);            bytes.mark();            byte[] data = new byte[bytes.remaining()];            bytes.get(data);                        bytes.reset();            s = new String(data, StandardCharsets.ISO_8859_1);            char[] quoted = BufferRecyclers.getJsonStringEncoder().quoteAsString(s);            s = "\"" + new String(quoted) + "\"";        } else if (o instanceof byte[]) {            s = new String((byte[]) o, StandardCharsets.ISO_8859_1);            char[] quoted = BufferRecyclers.getJsonStringEncoder().quoteAsString(s);            s = '\"' + new String(quoted) + '\"';        } else {            s = GenericData.get().toString(o);        }        return new ObjectMapper().readTree(s);    } catch (IOException e) {        throw new SchemaBuilderException(e);    }}
0
public static SchemaPairCompatibility checkReaderWriterCompatibility(final Schema reader, final Schema writer)
{    final SchemaCompatibilityResult compatibility = new ReaderWriterCompatibilityChecker().getCompatibility(reader, writer);    final String message;    switch(compatibility.getCompatibility()) {        case INCOMPATIBLE:            {                message = String.format("Data encoded using writer schema:%n%s%n" + "will or may fail to decode using reader schema:%n%s%n", writer.toString(true), reader.toString(true));                break;            }        case COMPATIBLE:            {                message = READER_WRITER_COMPATIBLE_MESSAGE;                break;            }        default:            throw new AvroRuntimeException("Unknown compatibility: " + compatibility);    }    return new SchemaPairCompatibility(compatibility, reader, writer, message);}
0
public static boolean schemaNameEquals(final Schema reader, final Schema writer)
{    if (objectsEqual(reader.getName(), writer.getName())) {        return true;    }        return reader.getAliases().contains(writer.getFullName());}
0
public static Field lookupWriterField(final Schema writerSchema, final Field readerField)
{    assert (writerSchema.getType() == Type.RECORD);    final List<Field> writerFields = new ArrayList<>();    final Field direct = writerSchema.getField(readerField.name());    if (direct != null) {        writerFields.add(direct);    }    for (final String readerFieldAliasName : readerField.aliases()) {        final Field writerField = writerSchema.getField(readerFieldAliasName);        if (writerField != null) {            writerFields.add(writerField);        }    }    switch(writerFields.size()) {        case 0:            return null;        case 1:            return writerFields.get(0);        default:            {                throw new AvroRuntimeException(String.format("Reader record field %s matches multiple fields in writer record schema %s", readerField, writerSchema));            }    }}
0
public int hashCode()
{    return System.identityHashCode(mReader) ^ System.identityHashCode(mWriter);}
0
public boolean equals(Object obj)
{    if (!(obj instanceof ReaderWriter)) {        return false;    }    final ReaderWriter that = (ReaderWriter) obj;        return (this.mReader == that.mReader) && (this.mWriter == that.mWriter);}
0
public String toString()
{    return String.format("ReaderWriter{reader:%s, writer:%s}", mReader, mWriter);}
0
public SchemaCompatibilityResult getCompatibility(final Schema reader, final Schema writer)
{    Deque<String> location = new ArrayDeque<>();    return getCompatibility(ROOT_REFERENCE_TOKEN, reader, writer, location);}
0
private SchemaCompatibilityResult getCompatibility(String referenceToken, final Schema reader, final Schema writer, final Deque<String> location)
{    location.addFirst(referenceToken);        final ReaderWriter pair = new ReaderWriter(reader, writer);    SchemaCompatibilityResult result = mMemoizeMap.get(pair);    if (result != null) {        if (result.getCompatibility() == SchemaCompatibilityType.RECURSION_IN_PROGRESS) {                                    result = SchemaCompatibilityResult.compatible();        }    } else {                mMemoizeMap.put(pair, SchemaCompatibilityResult.recursionInProgress());        result = calculateCompatibility(reader, writer, location);        mMemoizeMap.put(pair, result);    }    location.removeFirst();    return result;}
1
private SchemaCompatibilityResult calculateCompatibility(final Schema reader, final Schema writer, final Deque<String> location)
{    assert (reader != null);    assert (writer != null);    SchemaCompatibilityResult result = SchemaCompatibilityResult.compatible();    if (reader.getType() == writer.getType()) {        switch(reader.getType()) {            case NULL:            case BOOLEAN:            case INT:            case LONG:            case FLOAT:            case DOUBLE:            case BYTES:            case STRING:                {                    return result;                }            case ARRAY:                {                    return result.mergedWith(getCompatibility("items", reader.getElementType(), writer.getElementType(), location));                }            case MAP:                {                    return result.mergedWith(getCompatibility("values", reader.getValueType(), writer.getValueType(), location));                }            case FIXED:                {                    result = result.mergedWith(checkSchemaNames(reader, writer, location));                    return result.mergedWith(checkFixedSize(reader, writer, location));                }            case ENUM:                {                    result = result.mergedWith(checkSchemaNames(reader, writer, location));                    return result.mergedWith(checkReaderEnumContainsAllWriterEnumSymbols(reader, writer, location));                }            case RECORD:                {                    result = result.mergedWith(checkSchemaNames(reader, writer, location));                    return result.mergedWith(checkReaderWriterRecordFields(reader, writer, location));                }            case UNION:                {                                        int i = 0;                    for (final Schema writerBranch : writer.getTypes()) {                        location.addFirst(Integer.toString(i));                        SchemaCompatibilityResult compatibility = getCompatibility(reader, writerBranch);                        if (compatibility.getCompatibility() == SchemaCompatibilityType.INCOMPATIBLE) {                            String message = String.format("reader union lacking writer type: %s", writerBranch.getType());                            result = result.mergedWith(SchemaCompatibilityResult.incompatible(SchemaIncompatibilityType.MISSING_UNION_BRANCH, reader, writer, message, asList(location)));                        }                        location.removeFirst();                        i++;                    }                                        return result;                }            default:                {                    throw new AvroRuntimeException("Unknown schema type: " + reader.getType());                }        }    } else {                if (writer.getType() == Schema.Type.UNION) {            for (Schema s : writer.getTypes()) {                result = result.mergedWith(getCompatibility(reader, s));            }            return result;        }        switch(reader.getType()) {            case NULL:                return result.mergedWith(typeMismatch(reader, writer, location));            case BOOLEAN:                return result.mergedWith(typeMismatch(reader, writer, location));            case INT:                return result.mergedWith(typeMismatch(reader, writer, location));            case LONG:                {                    return (writer.getType() == Type.INT) ? result : result.mergedWith(typeMismatch(reader, writer, location));                }            case FLOAT:                {                    return ((writer.getType() == Type.INT) || (writer.getType() == Type.LONG)) ? result : result.mergedWith(typeMismatch(reader, writer, location));                }            case DOUBLE:                {                    return ((writer.getType() == Type.INT) || (writer.getType() == Type.LONG) || (writer.getType() == Type.FLOAT)) ? result : result.mergedWith(typeMismatch(reader, writer, location));                }            case BYTES:                {                    return (writer.getType() == Type.STRING) ? result : result.mergedWith(typeMismatch(reader, writer, location));                }            case STRING:                {                    return (writer.getType() == Type.BYTES) ? result : result.mergedWith(typeMismatch(reader, writer, location));                }            case ARRAY:                return result.mergedWith(typeMismatch(reader, writer, location));            case MAP:                return result.mergedWith(typeMismatch(reader, writer, location));            case FIXED:                return result.mergedWith(typeMismatch(reader, writer, location));            case ENUM:                return result.mergedWith(typeMismatch(reader, writer, location));            case RECORD:                return result.mergedWith(typeMismatch(reader, writer, location));            case UNION:                {                    for (final Schema readerBranch : reader.getTypes()) {                        SchemaCompatibilityResult compatibility = getCompatibility(readerBranch, writer);                        if (compatibility.getCompatibility() == SchemaCompatibilityType.COMPATIBLE) {                            return result;                        }                    }                                                            String message = String.format("reader union lacking writer type: %s", writer.getType());                    return result.mergedWith(SchemaCompatibilityResult.incompatible(SchemaIncompatibilityType.MISSING_UNION_BRANCH, reader, writer, message, asList(location)));                }            default:                {                    throw new AvroRuntimeException("Unknown schema type: " + reader.getType());                }        }    }}
0
private SchemaCompatibilityResult checkReaderWriterRecordFields(final Schema reader, final Schema writer, final Deque<String> location)
{    SchemaCompatibilityResult result = SchemaCompatibilityResult.compatible();    location.addFirst("fields");        for (final Field readerField : reader.getFields()) {        location.addFirst(Integer.toString(readerField.pos()));        final Field writerField = lookupWriterField(writer, readerField);        if (writerField == null) {                        if (!readerField.hasDefaultValue()) {                                if (readerField.schema().getType() == Type.ENUM && readerField.schema().getEnumDefault() != null) {                    result = result.mergedWith(getCompatibility("type", readerField.schema(), writer, location));                } else {                    result = result.mergedWith(SchemaCompatibilityResult.incompatible(SchemaIncompatibilityType.READER_FIELD_MISSING_DEFAULT_VALUE, reader, writer, readerField.name(), asList(location)));                }            }        } else {            result = result.mergedWith(getCompatibility("type", readerField.schema(), writerField.schema(), location));        }                location.removeFirst();    }            location.removeFirst();    return result;}
0
private SchemaCompatibilityResult checkReaderEnumContainsAllWriterEnumSymbols(final Schema reader, final Schema writer, final Deque<String> location)
{    SchemaCompatibilityResult result = SchemaCompatibilityResult.compatible();    location.addFirst("symbols");    final Set<String> symbols = new TreeSet<>(writer.getEnumSymbols());    symbols.removeAll(reader.getEnumSymbols());    if (!symbols.isEmpty()) {        if (reader.getEnumDefault() != null && reader.getEnumSymbols().contains(reader.getEnumDefault())) {            symbols.clear();            result = SchemaCompatibilityResult.compatible();        } else {            result = SchemaCompatibilityResult.incompatible(SchemaIncompatibilityType.MISSING_ENUM_SYMBOLS, reader, writer, symbols.toString(), asList(location));        }    }        location.removeFirst();    return result;}
0
private SchemaCompatibilityResult checkFixedSize(final Schema reader, final Schema writer, final Deque<String> location)
{    SchemaCompatibilityResult result = SchemaCompatibilityResult.compatible();    location.addFirst("size");    int actual = reader.getFixedSize();    int expected = writer.getFixedSize();    if (actual != expected) {        String message = String.format("expected: %d, found: %d", expected, actual);        result = SchemaCompatibilityResult.incompatible(SchemaIncompatibilityType.FIXED_SIZE_MISMATCH, reader, writer, message, asList(location));    }        location.removeFirst();    return result;}
0
private SchemaCompatibilityResult checkSchemaNames(final Schema reader, final Schema writer, final Deque<String> location)
{    SchemaCompatibilityResult result = SchemaCompatibilityResult.compatible();    location.addFirst("name");    if (!schemaNameEquals(reader, writer)) {        String message = String.format("expected: %s", writer.getFullName());        result = SchemaCompatibilityResult.incompatible(SchemaIncompatibilityType.NAME_MISMATCH, reader, writer, message, asList(location));    }        location.removeFirst();    return result;}
0
private SchemaCompatibilityResult typeMismatch(final Schema reader, final Schema writer, final Deque<String> location)
{    String message = String.format("reader type: %s not compatible with writer type: %s", reader.getType(), writer.getType());    return SchemaCompatibilityResult.incompatible(SchemaIncompatibilityType.TYPE_MISMATCH, reader, writer, message, asList(location));}
0
public SchemaCompatibilityResult mergedWith(SchemaCompatibilityResult toMerge)
{    List<Incompatibility> mergedIncompatibilities = new ArrayList<>(mIncompatibilities);    mergedIncompatibilities.addAll(toMerge.getIncompatibilities());    SchemaCompatibilityType compatibilityType = mCompatibilityType == SchemaCompatibilityType.COMPATIBLE ? toMerge.mCompatibilityType : SchemaCompatibilityType.INCOMPATIBLE;    return new SchemaCompatibilityResult(compatibilityType, mergedIncompatibilities);}
0
public static SchemaCompatibilityResult compatible()
{    return COMPATIBLE;}
0
public static SchemaCompatibilityResult recursionInProgress()
{    return RECURSION_IN_PROGRESS;}
0
public static SchemaCompatibilityResult incompatible(SchemaIncompatibilityType incompatibilityType, Schema readerFragment, Schema writerFragment, String message, List<String> location)
{    Incompatibility incompatibility = new Incompatibility(incompatibilityType, readerFragment, writerFragment, message, location);    return new SchemaCompatibilityResult(SchemaCompatibilityType.INCOMPATIBLE, Collections.singletonList(incompatibility));}
0
public SchemaCompatibilityType getCompatibility()
{    return mCompatibilityType;}
0
public List<Incompatibility> getIncompatibilities()
{    return mIncompatibilities;}
0
public int hashCode()
{    final int prime = 31;    int result = 1;    result = prime * result + ((mCompatibilityType == null) ? 0 : mCompatibilityType.hashCode());    result = prime * result + ((mIncompatibilities == null) ? 0 : mIncompatibilities.hashCode());    return result;}
0
public boolean equals(Object obj)
{    if (this == obj)        return true;    if (obj == null)        return false;    if (getClass() != obj.getClass())        return false;    SchemaCompatibilityResult other = (SchemaCompatibilityResult) obj;    if (mIncompatibilities == null) {        if (other.mIncompatibilities != null)            return false;    } else if (!mIncompatibilities.equals(other.mIncompatibilities))        return false;    return mCompatibilityType == other.mCompatibilityType;}
0
public String toString()
{    return String.format("SchemaCompatibilityResult{compatibility:%s, incompatibilities:%s}", mCompatibilityType, mIncompatibilities);}
0
public SchemaIncompatibilityType getType()
{    return mType;}
0
public Schema getReaderFragment()
{    return mReaderFragment;}
0
public Schema getWriterFragment()
{    return mWriterFragment;}
0
public String getMessage()
{    return mMessage;}
0
public String getLocation()
{    StringBuilder s = new StringBuilder("/");    boolean first = true;        for (String coordinate : mLocation.subList(1, mLocation.size())) {        if (first) {            first = false;        } else {            s.append('/');        }                s.append(coordinate.replace("~", "~0").replace("/", "~1"));    }    return s.toString();}
0
public int hashCode()
{    final int prime = 31;    int result = 1;    result = prime * result + ((mType == null) ? 0 : mType.hashCode());    result = prime * result + ((mReaderFragment == null) ? 0 : mReaderFragment.hashCode());    result = prime * result + ((mWriterFragment == null) ? 0 : mWriterFragment.hashCode());    result = prime * result + ((mMessage == null) ? 0 : mMessage.hashCode());    result = prime * result + ((mLocation == null) ? 0 : mLocation.hashCode());    return result;}
0
public boolean equals(Object obj)
{    if (this == obj) {        return true;    }    if (obj == null) {        return false;    }    if (getClass() != obj.getClass()) {        return false;    }    Incompatibility other = (Incompatibility) obj;    if (mType != other.mType) {        return false;    }    if (mReaderFragment == null) {        if (other.mReaderFragment != null) {            return false;        }    } else if (!mReaderFragment.equals(other.mReaderFragment)) {        return false;    }    if (mWriterFragment == null) {        if (other.mWriterFragment != null) {            return false;        }    } else if (!mWriterFragment.equals(other.mWriterFragment)) {        return false;    }    if (mMessage == null) {        if (other.mMessage != null) {            return false;        }    } else if (!mMessage.equals(other.mMessage)) {        return false;    }    if (mLocation == null) {        return other.mLocation == null;    } else        return mLocation.equals(other.mLocation);}
0
public String toString()
{    return String.format("Incompatibility{type:%s, location:%s, message:%s, reader:%s, writer:%s}", mType, getLocation(), mMessage, mReaderFragment, mWriterFragment);}
0
public SchemaCompatibilityType getType()
{    return mResult.getCompatibility();}
0
public SchemaCompatibilityResult getResult()
{    return mResult;}
0
public Schema getReader()
{    return mReader;}
0
public Schema getWriter()
{    return mWriter;}
0
public String getDescription()
{    return mDescription;}
0
public String toString()
{    return String.format("SchemaPairCompatibility{result:%s, readerSchema:%s, writerSchema:%s, description:%s}", mResult, mReader, mWriter, mDescription);}
0
public boolean equals(Object other)
{    if ((other instanceof SchemaPairCompatibility)) {        final SchemaPairCompatibility result = (SchemaPairCompatibility) other;        return objectsEqual(result.mResult, mResult) && objectsEqual(result.mReader, mReader) && objectsEqual(result.mWriter, mWriter) && objectsEqual(result.mDescription, mDescription);    } else {        return false;    }}
0
public int hashCode()
{    return Arrays.hashCode(new Object[] { mResult, mReader, mWriter, mDescription });}
0
private static boolean objectsEqual(Object obj1, Object obj2)
{    return Objects.equals(obj1, obj2);}
0
private static List<String> asList(Deque<String> deque)
{    List<String> list = new ArrayList<>(deque);    Collections.reverse(list);    return Collections.unmodifiableList(list);}
0
public static String toParsingForm(Schema s)
{    try {        Map<String, String> env = new HashMap<>();        return build(env, s, new StringBuilder()).toString();    } catch (IOException e) {                throw new RuntimeException(e);    }}
0
public static byte[] fingerprint(String fpName, byte[] data) throws NoSuchAlgorithmException
{    if (fpName.equals("CRC-64-AVRO")) {        long fp = fingerprint64(data);        byte[] result = new byte[8];        for (int i = 0; i < 8; i++) {            result[i] = (byte) fp;            fp >>= 8;        }        return result;    }    MessageDigest md = MessageDigest.getInstance(fpName);    return md.digest(data);}
0
public static long fingerprint64(byte[] data)
{    long result = EMPTY64;    for (byte b : data) result = (result >>> 8) ^ FP64.FP_TABLE[(int) (result ^ b) & 0xff];    return result;}
0
public static byte[] parsingFingerprint(String fpName, Schema s) throws NoSuchAlgorithmException
{    return fingerprint(fpName, toParsingForm(s).getBytes(StandardCharsets.UTF_8));}
0
public static long parsingFingerprint64(Schema s)
{    return fingerprint64(toParsingForm(s).getBytes(StandardCharsets.UTF_8));}
0
private static Appendable build(Map<String, String> env, Schema s, Appendable o) throws IOException
{    boolean firstTime = true;    Schema.Type st = s.getType();    switch(st) {        default:                        return o.append('"').append(st.getName()).append('"');        case UNION:            o.append('[');            for (Schema b : s.getTypes()) {                if (!firstTime)                    o.append(',');                else                    firstTime = false;                build(env, b, o);            }            return o.append(']');        case ARRAY:        case MAP:            o.append("{\"type\":\"").append(st.getName()).append("\"");            if (st == Schema.Type.ARRAY)                build(env, s.getElementType(), o.append(",\"items\":"));            else                build(env, s.getValueType(), o.append(",\"values\":"));            return o.append("}");        case ENUM:        case FIXED:        case RECORD:            String name = s.getFullName();            if (env.get(name) != null)                return o.append(env.get(name));            String qname = "\"" + name + "\"";            env.put(name, qname);            o.append("{\"name\":").append(qname);            o.append(",\"type\":\"").append(st.getName()).append("\"");            if (st == Schema.Type.ENUM) {                o.append(",\"symbols\":[");                for (String enumSymbol : s.getEnumSymbols()) {                    if (!firstTime)                        o.append(',');                    else                        firstTime = false;                    o.append('"').append(enumSymbol).append('"');                }                o.append("]");            } else if (st == Schema.Type.FIXED) {                o.append(",\"size\":").append(Integer.toString(s.getFixedSize()));            } else {                                o.append(",\"fields\":[");                for (Schema.Field f : s.getFields()) {                    if (!firstTime)                        o.append(',');                    else                        firstTime = false;                    o.append("{\"name\":\"").append(f.name()).append("\"");                    build(env, f.schema(), o.append(",\"type\":")).append("}");                }                o.append("]");            }            return o.append("}");    }}
0
private static String getMessage(Schema reader, Schema writer)
{    return "Unable to read schema: \n" + writer.toString(true) + "\nusing schema:\n" + reader.toString(true);}
0
public SchemaValidatorBuilder strategy(SchemaValidationStrategy strategy)
{    this.strategy = strategy;    return this;}
0
public SchemaValidatorBuilder canReadStrategy()
{    this.strategy = new ValidateCanRead();    return this;}
0
public SchemaValidatorBuilder canBeReadStrategy()
{    this.strategy = new ValidateCanBeRead();    return this;}
0
public SchemaValidatorBuilder mutualReadStrategy()
{    this.strategy = new ValidateMutualRead();    return this;}
0
public SchemaValidator validateLatest()
{    valid();    return new ValidateLatest(strategy);}
0
public SchemaValidator validateAll()
{    valid();    return new ValidateAll(strategy);}
0
private void valid()
{    if (null == strategy) {        throw new AvroRuntimeException("SchemaValidationStrategy not specified in builder");    }}
0
public int available() throws IOException
{    return in.available();}
0
public void close() throws IOException
{    in.close();}
0
public boolean markSupported()
{    return false;}
0
public int read() throws IOException
{    return in.read();}
0
public int read(byte[] b) throws IOException
{    return in.read(b);}
0
public int read(byte[] b, int offset, int len) throws IOException
{    return in.read(b, offset, len);}
0
public long skip(long n) throws IOException
{    return in.skip(n);}
0
public void flush() throws IOException
{    out.flush();}
0
public void close() throws IOException
{    out.close();}
0
public void write(int c) throws IOException
{    out.write(c);}
0
public void write(byte[] b) throws IOException
{    out.write(b);}
0
public void write(byte[] b, int offset, int len) throws IOException
{    out.write(b, offset, len);}
0
protected Constructor computeValue(Class<?> c)
{    boolean useSchema = SchemaConstructable.class.isAssignableFrom(c);    try {        Constructor meth = c.getDeclaredConstructor(useSchema ? SCHEMA_ARG : NO_ARG);        meth.setAccessible(true);        return meth;    } catch (Exception e) {        throw new RuntimeException(e);    }}
0
public DatumReader createDatumReader(Schema schema)
{    return new SpecificDatumReader(schema, schema, this);}
0
public DatumReader createDatumReader(Schema writer, Schema reader)
{    return new SpecificDatumReader(writer, reader, this);}
0
public DatumWriter createDatumWriter(Schema schema)
{    return new SpecificDatumWriter(schema, this);}
0
public static SpecificData get()
{    return INSTANCE;}
0
public static SpecificData getForSchema(Schema reader)
{    if (reader.getType() == Type.RECORD) {        final String className = getClassName(reader);        if (className != null) {            final Class<?> clazz;            try {                clazz = Class.forName(className);                return getForClass(clazz);            } catch (ClassNotFoundException e) {                return SpecificData.get();            }        }    }    return SpecificData.get();}
0
public static SpecificData getForClass(Class<T> c)
{    if (SpecificRecordBase.class.isAssignableFrom(c)) {        final Field specificDataField;        try {            specificDataField = c.getDeclaredField("MODEL$");            specificDataField.setAccessible(true);            return (SpecificData) specificDataField.get(null);        } catch (NoSuchFieldException e) {                        return SpecificData.get();        } catch (IllegalAccessException e) {            throw new AvroRuntimeException(e);        }    }    return SpecificData.get();}
0
public boolean useCustomCoders()
{    return useCustomCoderFlag;}
0
public void setCustomCoders(boolean flag)
{    useCustomCoderFlag = flag;}
0
protected boolean isEnum(Object datum)
{    return datum instanceof Enum || super.isEnum(datum);}
0
public Object createEnum(String symbol, Schema schema)
{    Class c = getClass(schema);    if (c == null)                return super.createEnum(symbol, schema);    if (RESERVED_WORDS.contains(symbol))        symbol += "$";    return Enum.valueOf(c, symbol);}
0
protected Schema getEnumSchema(Object datum)
{    return (datum instanceof Enum) ? getSchema(datum.getClass()) : super.getEnumSchema(datum);}
0
public Class getClass(Schema schema)
{    switch(schema.getType()) {        case FIXED:        case RECORD:        case ENUM:            String name = schema.getFullName();            if (name == null)                return null;            Class c = classCache.get(name);            if (c == null) {                try {                    c = ClassUtils.forName(getClassLoader(), getClassName(schema));                } catch (ClassNotFoundException e) {                    try {                                                c = ClassUtils.forName(getClassLoader(), getNestedClassName(schema));                    } catch (ClassNotFoundException ex) {                        c = NO_CLASS;                    }                }                classCache.put(name, c);            }            return c == NO_CLASS ? null : c;        case ARRAY:            return List.class;        case MAP:            return Map.class;        case UNION:                        List<Schema> types = schema.getTypes();            if ((types.size() == 2) && types.contains(NULL_SCHEMA))                return getWrapper(types.get(types.get(0).equals(NULL_SCHEMA) ? 1 : 0));            return Object.class;        case STRING:            if (STRING_TYPE_STRING.equals(schema.getProp(STRING_PROP)))                return String.class;            return CharSequence.class;        case BYTES:            return ByteBuffer.class;        case INT:            return Integer.TYPE;        case LONG:            return Long.TYPE;        case FLOAT:            return Float.TYPE;        case DOUBLE:            return Double.TYPE;        case BOOLEAN:            return Boolean.TYPE;        case NULL:            return Void.TYPE;        default:            throw new AvroRuntimeException("Unknown type: " + schema);    }}
0
private Class getWrapper(Schema schema)
{    switch(schema.getType()) {        case INT:            return Integer.class;        case LONG:            return Long.class;        case FLOAT:            return Float.class;        case DOUBLE:            return Double.class;        case BOOLEAN:            return Boolean.class;    }    return getClass(schema);}
0
public static String getClassName(Schema schema)
{    String namespace = schema.getNamespace();    String name = schema.getName();    if (namespace == null || "".equals(namespace))        return name;        String dot = namespace.endsWith("$") ? "" : ".";    return namespace + dot + name;}
0
private String getNestedClassName(Schema schema)
{    String namespace = schema.getNamespace();    String name = schema.getName();    if (namespace == null || "".equals(namespace))        return name;    return namespace + "$" + name;}
0
protected Schema computeValue(Class<?> type)
{    return createSchema(type, new LinkedHashMap<>());}
0
public Schema getSchema(java.lang.reflect.Type type)
{    try {        if (type instanceof Class) {            return schemaClassCache.get((Class<?>) type);        }        return schemaTypeCache.computeIfAbsent(type, t -> createSchema(t, new LinkedHashMap<>()));    } catch (Exception e) {        throw (e instanceof AvroRuntimeException) ? (AvroRuntimeException) e : new AvroRuntimeException(e);    }}
0
protected Schema createSchema(java.lang.reflect.Type type, Map<String, Schema> names)
{    if (type instanceof Class && CharSequence.class.isAssignableFrom((Class) type))        return Schema.create(Type.STRING);    else if (type == ByteBuffer.class)        return Schema.create(Type.BYTES);    else if ((type == Integer.class) || (type == Integer.TYPE))        return Schema.create(Type.INT);    else if ((type == Long.class) || (type == Long.TYPE))        return Schema.create(Type.LONG);    else if ((type == Float.class) || (type == Float.TYPE))        return Schema.create(Type.FLOAT);    else if ((type == Double.class) || (type == Double.TYPE))        return Schema.create(Type.DOUBLE);    else if ((type == Boolean.class) || (type == Boolean.TYPE))        return Schema.create(Type.BOOLEAN);    else if ((type == Void.class) || (type == Void.TYPE))        return Schema.create(Type.NULL);    else if (type instanceof ParameterizedType) {        ParameterizedType ptype = (ParameterizedType) type;        Class raw = (Class) ptype.getRawType();        java.lang.reflect.Type[] params = ptype.getActualTypeArguments();        if (Collection.class.isAssignableFrom(raw)) {                        if (params.length != 1)                throw new AvroTypeException("No array type specified.");            return Schema.createArray(createSchema(params[0], names));        } else if (Map.class.isAssignableFrom(raw)) {                        java.lang.reflect.Type key = params[0];            java.lang.reflect.Type value = params[1];            if (!(key instanceof Class && CharSequence.class.isAssignableFrom((Class) key)))                throw new AvroTypeException("Map key class not CharSequence: " + key);            return Schema.createMap(createSchema(value, names));        } else {            return createSchema(raw, names);        }    } else if (type instanceof Class) {                Class c = (Class) type;        String fullName = c.getName();        Schema schema = names.get(fullName);        if (schema == null)            try {                schema = (Schema) (c.getDeclaredField("SCHEMA$").get(null));                if (!fullName.equals(getClassName(schema)))                                        schema = new Schema.Parser().parse(schema.toString().replace(schema.getNamespace(), c.getPackage().getName()));            } catch (NoSuchFieldException e) {                throw new AvroRuntimeException("Not a Specific class: " + c);            } catch (IllegalAccessException e) {                throw new AvroRuntimeException(e);            }        names.put(fullName, schema);        return schema;    }    throw new AvroTypeException("Unknown type: " + type);}
0
protected String getSchemaName(Object datum)
{    if (datum != null) {        Class c = datum.getClass();        if (isStringable(c))            return Schema.Type.STRING.getName();    }    return super.getSchemaName(datum);}
0
protected boolean isStringable(Class<?> c)
{    return stringableClasses.contains(c);}
0
protected boolean isStringType(Class<?> c)
{        return CharSequence.class.isAssignableFrom(c);}
0
public Protocol getProtocol(Class iface)
{    try {        Protocol p = (Protocol) (iface.getDeclaredField("PROTOCOL").get(null));        if (!p.getNamespace().equals(iface.getPackage().getName()))                        p = Protocol.parse(p.toString().replace(p.getNamespace(), iface.getPackage().getName()));        return p;    } catch (NoSuchFieldException e) {        throw new AvroRuntimeException("Not a Specific protocol: " + iface);    } catch (IllegalAccessException e) {        throw new AvroRuntimeException(e);    }}
0
protected int compare(Object o1, Object o2, Schema s, boolean eq)
{    switch(s.getType()) {        case ENUM:            if (o1 instanceof Enum)                return ((Enum) o1).ordinal() - ((Enum) o2).ordinal();        default:            return super.compare(o1, o2, s, eq);    }}
0
public static Object newInstance(Class c, Schema s)
{    boolean useSchema = SchemaConstructable.class.isAssignableFrom(c);    Object result;    try {        Constructor meth = CTOR_CACHE.get(c);        result = meth.newInstance(useSchema ? new Object[] { s } : null);    } catch (Exception e) {        throw new RuntimeException(e);    }    return result;}
0
public Object createFixed(Object old, Schema schema)
{    Class c = getClass(schema);    if (c == null)                return super.createFixed(old, schema);    return c.isInstance(old) ? old : newInstance(c, schema);}
0
public Object newRecord(Object old, Schema schema)
{    Class c = getClass(schema);    if (c == null)                return super.newRecord(old, schema);    return (c.isInstance(old) ? old : newInstance(c, schema));}
0
public static BinaryDecoder getDecoder(ObjectInput in)
{    return DecoderFactory.get().directBinaryDecoder(new ExternalizableInput(in), null);}
0
public static BinaryEncoder getEncoder(ObjectOutput out)
{    return EncoderFactory.get().directBinaryEncoder(new ExternalizableOutput(out), null);}
0
public SpecificData getSpecificData()
{    return (SpecificData) getData();}
0
public void setSchema(Schema actual)
{        if (getExpected() == null && actual != null && actual.getType() == Schema.Type.RECORD) {        SpecificData data = getSpecificData();        Class c = data.getClass(actual);        if (c != null && SpecificRecord.class.isAssignableFrom(c))            setExpected(data.getSchema(c));    }    super.setSchema(actual);}
0
protected Class findStringClass(Schema schema)
{    Class stringClass = null;    switch(schema.getType()) {        case STRING:            stringClass = getPropAsClass(schema, SpecificData.CLASS_PROP);            break;        case MAP:            stringClass = getPropAsClass(schema, SpecificData.KEY_CLASS_PROP);            break;    }    if (stringClass != null)        return stringClass;    return super.findStringClass(schema);}
0
private Class getPropAsClass(Schema schema, String prop)
{    String name = schema.getProp(prop);    if (name == null)        return null;    try {        return ClassUtils.forName(getData().getClassLoader(), name);    } catch (ClassNotFoundException e) {        throw new AvroRuntimeException(e);    }}
0
protected Object readRecord(Object old, Schema expected, ResolvingDecoder in) throws IOException
{    SpecificData data = getSpecificData();    if (data.useCustomCoders()) {        old = data.newRecord(old, expected);        if (old instanceof SpecificRecordBase) {            SpecificRecordBase d = (SpecificRecordBase) old;            if (d.hasCustomCoders()) {                d.customDecode(in);                return d;            }        }    }    return super.readRecord(old, expected, in);}
0
protected void readField(Object r, Schema.Field f, Object oldDatum, ResolvingDecoder in, Object state) throws IOException
{    if (r instanceof SpecificRecordBase) {        Conversion<?> conversion = ((SpecificRecordBase) r).getConversion(f.pos());        Object datum;        if (conversion != null) {            datum = readWithConversion(oldDatum, f.schema(), f.schema().getLogicalType(), conversion, in);        } else {            datum = readWithoutConversion(oldDatum, f.schema(), in);        }        getData().setField(r, f.name(), f.pos(), datum);    } else {        super.readField(r, f, oldDatum, in, state);    }}
0
public SpecificData getSpecificData()
{    return (SpecificData) getData();}
0
protected void writeEnum(Schema schema, Object datum, Encoder out) throws IOException
{    if (!(datum instanceof Enum))                super.writeEnum(schema, datum, out);    else        out.writeEnum(((Enum) datum).ordinal());}
0
protected void writeString(Schema schema, Object datum, Encoder out) throws IOException
{    if (!(datum instanceof CharSequence) && getSpecificData().isStringable(datum.getClass())) {                datum = datum.toString();    }    writeString(datum, out);}
0
protected void writeRecord(Schema schema, Object datum, Encoder out) throws IOException
{    if (datum instanceof SpecificRecordBase && this.getSpecificData().useCustomCoders()) {        SpecificRecordBase d = (SpecificRecordBase) datum;        if (d.hasCustomCoders()) {            d.customEncode(out);            return;        }    }    super.writeRecord(schema, datum, out);}
0
protected void writeField(Object datum, Schema.Field f, Encoder out, Object state) throws IOException
{    if (datum instanceof SpecificRecordBase) {        Conversion<?> conversion = ((SpecificRecordBase) datum).getConversion(f.pos());        Schema fieldSchema = f.schema();        LogicalType logicalType = fieldSchema.getLogicalType();        Object value = getData().getField(datum, f.name(), f.pos());        if (conversion != null && logicalType != null) {            value = convert(fieldSchema, logicalType, conversion, value);        }        writeWithoutConversion(fieldSchema, value, out);    } else {        super.writeField(datum, f, out, state);    }}
0
public Object getValue()
{    return value;}
0
public SpecificErrorBuilderBase<T> setValue(Object value)
{    this.value = value;    hasValue = true;    return this;}
0
public boolean hasValue()
{    return hasValue;}
0
public SpecificErrorBuilderBase<T> clearValue()
{    value = null;    hasValue = false;    return this;}
0
public Throwable getCause()
{    return cause;}
0
public SpecificErrorBuilderBase<T> setCause(Throwable cause)
{    this.cause = cause;    hasCause = true;    return this;}
0
public boolean hasCause()
{    return hasCause;}
0
public SpecificErrorBuilderBase<T> clearCause()
{    cause = null;    hasCause = false;    return this;}
0
public boolean equals(Object that)
{    if (that == this)                return true;    if (!(that instanceof SpecificExceptionBase))                return false;    if (this.getClass() != that.getClass())                return false;    return SpecificData.get().compare(this, that, this.getSchema()) == 0;}
0
public int hashCode()
{    return SpecificData.get().hashCode(this, this.getSchema());}
0
public void bytes(byte[] bytes)
{    this.bytes = bytes;}
0
public byte[] bytes()
{    return bytes;}
0
public boolean equals(Object o)
{    if (o == this)        return true;    return o instanceof GenericFixed && Arrays.equals(bytes, ((GenericFixed) o).bytes());}
0
public int hashCode()
{    return Arrays.hashCode(bytes);}
0
public String toString()
{    return Arrays.toString(bytes);}
0
public int compareTo(SpecificFixed that)
{    return BinaryData.compareBytes(this.bytes, 0, this.bytes.length, that.bytes, 0, that.bytes.length);}
0
public SpecificData getSpecificData()
{        return SpecificData.get();}
0
public Conversion<?> getConversion(int field)
{        return null;}
0
public void put(String fieldName, Object value)
{    put(getSchema().getField(fieldName).pos(), value);}
0
public Object get(String fieldName)
{    return get(getSchema().getField(fieldName).pos());}
0
public Conversion<?> getConversion(String fieldName)
{    return getConversion(getSchema().getField(fieldName).pos());}
0
public boolean equals(Object that)
{    if (that == this)                return true;    if (!(that instanceof SpecificRecord))                return false;    if (this.getClass() != that.getClass())                return false;    return getSpecificData().compare(this, that, this.getSchema(), true) == 0;}
0
public int hashCode()
{    return getSpecificData().hashCode(this, this.getSchema());}
0
public int compareTo(SpecificRecord that)
{    return getSpecificData().compare(this, that, this.getSchema());}
0
public String toString()
{    return getSpecificData().toString(this);}
0
public void writeExternal(ObjectOutput out) throws IOException
{    new SpecificDatumWriter(getSchema()).write(this, SpecificData.getEncoder(out));}
0
public void readExternal(ObjectInput in) throws IOException
{    new SpecificDatumReader(getSchema()).read(this, SpecificData.getDecoder(in));}
0
protected boolean hasCustomCoders()
{    return false;}
0
public void customEncode(Encoder out) throws IOException
{    throw new UnsupportedOperationException();}
0
public void customDecode(ResolvingDecoder in) throws IOException
{    throw new UnsupportedOperationException();}
0
public Object getUnresolvedDatum()
{    return unresolvedDatum;}
0
public Schema getUnionSchema()
{    return unionSchema;}
0
public int read() throws IOException
{    ByteBuffer buffer = getBuffer();    if (buffer == null) {        return -1;    }    return buffer.get() & 0xff;}
0
public int read(byte[] b, int off, int len) throws IOException
{    if (len == 0)        return 0;    ByteBuffer buffer = getBuffer();    if (buffer == null) {        return -1;    }    int remaining = buffer.remaining();    if (len > remaining) {        buffer.get(b, off, remaining);        return remaining;    } else {        buffer.get(b, off, len);        return len;    }}
0
public ByteBuffer readBuffer(int length) throws IOException
{    if (length == 0)        return ByteBuffer.allocate(0);    ByteBuffer buffer = getBuffer();    if (buffer == null) {        return ByteBuffer.allocate(0);    }    if (buffer.remaining() == length) {                current++;                return buffer;    }        ByteBuffer result = ByteBuffer.allocate(length);    int start = 0;    while (start < length) start += read(result.array(), start, length - start);    return result;}
0
private ByteBuffer getBuffer() throws IOException
{    while (current < buffers.size()) {        ByteBuffer buffer = buffers.get(current);        if (buffer.hasRemaining())            return buffer;        current++;    }    return null;}
0
public List<ByteBuffer> getBufferList()
{    List<ByteBuffer> result = buffers;    reset();    for (ByteBuffer buffer : result) buffer.flip();    return result;}
0
public void prepend(List<ByteBuffer> lists)
{    for (ByteBuffer buffer : lists) {        buffer.position(buffer.limit());    }    buffers.addAll(0, lists);}
0
public void append(List<ByteBuffer> lists)
{    for (ByteBuffer buffer : lists) {        buffer.position(buffer.limit());    }    buffers.addAll(lists);}
0
public void reset()
{    buffers = new ArrayList<>();    buffers.add(ByteBuffer.allocate(BUFFER_SIZE));}
0
public void write(ByteBuffer buffer)
{    buffers.add(buffer);}
0
public void write(int b)
{    ByteBuffer buffer = buffers.get(buffers.size() - 1);    if (buffer.remaining() < 1) {        buffer = ByteBuffer.allocate(BUFFER_SIZE);        buffers.add(buffer);    }    buffer.put((byte) b);}
0
public void write(byte[] b, int off, int len)
{    ByteBuffer buffer = buffers.get(buffers.size() - 1);    int remaining = buffer.remaining();    while (len > remaining) {        buffer.put(b, off, remaining);        len -= remaining;        off += remaining;        buffer = ByteBuffer.allocate(BUFFER_SIZE);        buffers.add(buffer);        remaining = buffer.remaining();    }    buffer.put(b, off, len);}
0
public void writeBuffer(ByteBuffer buffer) throws IOException
{    if (buffer.remaining() < BUFFER_SIZE) {        write(buffer.array(), buffer.position(), buffer.remaining());    } else {                ByteBuffer dup = buffer.duplicate();                dup.position(buffer.limit());        buffers.add(dup);    }}
0
public static Class<?> forName(String className) throws ClassNotFoundException
{    return ClassUtils.forName(ClassUtils.class, className);}
0
public static Class<?> forName(Class<?> contextClass, String className) throws ClassNotFoundException
{    Class<?> c = null;    if (contextClass.getClassLoader() != null) {        c = forName(className, contextClass.getClassLoader());    }    if (c == null && Thread.currentThread().getContextClassLoader() != null) {        c = forName(className, Thread.currentThread().getContextClassLoader());    }    if (c == null) {        throw new ClassNotFoundException("Failed to load class" + className);    }    return c;}
0
public static Class<?> forName(ClassLoader classLoader, String className) throws ClassNotFoundException
{    Class<?> c = null;    if (classLoader != null) {        c = forName(className, classLoader);    }    if (c == null && Thread.currentThread().getContextClassLoader() != null) {        c = forName(className, Thread.currentThread().getContextClassLoader());    }    if (c == null) {        throw new ClassNotFoundException("Failed to load class" + className);    }    return c;}
0
private static Class<?> forName(String className, ClassLoader classLoader)
{    Class<?> c = null;    if (classLoader != null && className != null) {        try {            c = Class.forName(className, true, classLoader);        } catch (ClassNotFoundException e) {                }    }    return c;}
0
public static void setAccessor(JsonPropertiesAccessor accessor)
{    if (jsonPropertiesAccessor != null)        throw new IllegalStateException("JsonPropertiesAccessor already initialized");    jsonPropertiesAccessor = accessor;}
0
public static void setAccessor(FieldAccessor accessor)
{    if (fieldAccessor != null)        throw new IllegalStateException("FieldAccessor already initialized");    fieldAccessor = accessor;}
0
private static FieldAccessor fieldAccessor()
{    if (fieldAccessor == null)        ensureLoaded(Field.class);    return fieldAccessor;}
0
public static void setAccessor(ResolvingGrammarGeneratorAccessor accessor)
{    if (resolvingGrammarGeneratorAccessor != null)        throw new IllegalStateException("ResolvingGrammarGeneratorAccessor already initialized");    resolvingGrammarGeneratorAccessor = accessor;}
0
private static ResolvingGrammarGeneratorAccessor resolvingGrammarGeneratorAccessor()
{    if (resolvingGrammarGeneratorAccessor == null)        ensureLoaded(ResolvingGrammarGenerator.class);    return resolvingGrammarGeneratorAccessor;}
0
private static void ensureLoaded(Class<?> c)
{    try {        Class.forName(c.getName());    } catch (ClassNotFoundException e) {        }}
0
public static void addProp(JsonProperties props, String name, JsonNode value)
{    jsonPropertiesAccessor.addProp(props, name, value);}
0
public static JsonNode defaultValue(Field field)
{    return fieldAccessor.defaultValue(field);}
0
public static void encode(Encoder e, Schema s, JsonNode n) throws IOException
{    resolvingGrammarGeneratorAccessor().encode(e, s, n);}
0
public static Field createField(String name, Schema schema, String doc, JsonNode defaultValue, boolean validate, Order order)
{    return fieldAccessor().createField(name, schema, doc, defaultValue, validate, order);}
0
public static Field createField(String name, Schema schema, String doc, JsonNode defaultValue)
{    return fieldAccessor().createField(name, schema, doc, defaultValue);}
0
public static JsonNode toJsonNode(Object datum)
{    if (datum == null) {        return null;    }    try {        TokenBuffer generator = new TokenBuffer(new ObjectMapper(), false);        toJson(datum, generator);        return new ObjectMapper().readTree(generator.asParser());    } catch (IOException e) {        throw new AvroRuntimeException(e);    }}
0
 static void toJson(Object datum, JsonGenerator generator) throws IOException
{    if (datum == JsonProperties.NULL_VALUE) {                generator.writeNull();    } else if (datum instanceof Map) {                generator.writeStartObject();        for (Map.Entry<Object, Object> entry : ((Map<Object, Object>) datum).entrySet()) {            generator.writeFieldName(entry.getKey().toString());            toJson(entry.getValue(), generator);        }        generator.writeEndObject();    } else if (datum instanceof Collection) {                generator.writeStartArray();        for (Object element : (Collection<?>) datum) {            toJson(element, generator);        }        generator.writeEndArray();    } else if (datum instanceof byte[]) {                generator.writeString(new String((byte[]) datum, StandardCharsets.ISO_8859_1));    } else if (datum instanceof CharSequence || datum instanceof Enum<?>) {                generator.writeString(datum.toString());    } else if (datum instanceof Double) {                generator.writeNumber((Double) datum);    } else if (datum instanceof Float) {                generator.writeNumber((Float) datum);    } else if (datum instanceof Long) {                generator.writeNumber((Long) datum);    } else if (datum instanceof Integer) {                generator.writeNumber((Integer) datum);    } else if (datum instanceof Boolean) {                generator.writeBoolean((Boolean) datum);    } else {        throw new AvroRuntimeException("Unknown datum class: " + datum.getClass());    }}
0
public static Object toObject(JsonNode jsonNode)
{    return toObject(jsonNode, null);}
0
public static Object toObject(JsonNode jsonNode, Schema schema)
{    if (schema != null && schema.getType().equals(Schema.Type.UNION)) {        return toObject(jsonNode, schema.getTypes().get(0));    }    if (jsonNode == null) {        return null;    } else if (jsonNode.isNull()) {        return JsonProperties.NULL_VALUE;    } else if (jsonNode.isBoolean()) {        return jsonNode.asBoolean();    } else if (jsonNode.isInt()) {        if (schema == null || schema.getType().equals(Schema.Type.INT)) {            return jsonNode.asInt();        } else if (schema.getType().equals(Schema.Type.LONG)) {            return jsonNode.asLong();        }    } else if (jsonNode.isLong()) {        return jsonNode.asLong();    } else if (jsonNode.isDouble() || jsonNode.isFloat()) {        if (schema == null || schema.getType().equals(Schema.Type.DOUBLE)) {            return jsonNode.asDouble();        } else if (schema.getType().equals(Schema.Type.FLOAT)) {            return (float) jsonNode.asDouble();        }    } else if (jsonNode.isTextual()) {        if (schema == null || schema.getType().equals(Schema.Type.STRING) || schema.getType().equals(Schema.Type.ENUM)) {            return jsonNode.asText();        } else if (schema.getType().equals(Schema.Type.BYTES) || schema.getType().equals(Schema.Type.FIXED)) {            return jsonNode.textValue().getBytes(StandardCharsets.ISO_8859_1);        }    } else if (jsonNode.isArray()) {        List l = new ArrayList();        for (JsonNode node : jsonNode) {            l.add(toObject(node, schema == null ? null : schema.getElementType()));        }        return l;    } else if (jsonNode.isObject()) {        Map m = new LinkedHashMap();        for (Iterator<String> it = jsonNode.fieldNames(); it.hasNext(); ) {            String key = it.next();            Schema s = null;            if (schema == null) {                s = null;            } else if (schema.getType().equals(Schema.Type.MAP)) {                s = schema.getValueType();            } else if (schema.getType().equals(Schema.Type.RECORD)) {                s = schema.getField(key).schema();            }            Object value = toObject(jsonNode.get(key), s);            m.put(key, value);        }        return m;    }    return null;}
0
public Iterator<Object> iterator()
{    return new Iterator<Object>() {        private int n;        private Random random = new Random(seed);        @Override        public boolean hasNext() {            return n < count;        }        @Override        public Object next() {            n++;            return generate(root, random, 0);        }        @Override        public void remove() {            throw new UnsupportedOperationException();        }    };}
0
public boolean hasNext()
{    return n < count;}
0
public Object next()
{    n++;    return generate(root, random, 0);}
0
public void remove()
{    throw new UnsupportedOperationException();}
0
private Object generate(Schema schema, Random random, int d)
{    switch(schema.getType()) {        case RECORD:            GenericRecord record = new GenericData.Record(schema);            for (Schema.Field field : schema.getFields()) {                Object value = (field.getObjectProp(USE_DEFAULT) == null) ? generate(field.schema(), random, d + 1) : GenericData.get().getDefaultValue(field);                record.put(field.name(), value);            }            return record;        case ENUM:            List<String> symbols = schema.getEnumSymbols();            return new GenericData.EnumSymbol(schema, symbols.get(random.nextInt(symbols.size())));        case ARRAY:            int length = (random.nextInt(5) + 2) - d;            @SuppressWarnings("rawtypes")            GenericArray<Object> array = new GenericData.Array(length <= 0 ? 0 : length, schema);            for (int i = 0; i < length; i++) array.add(generate(schema.getElementType(), random, d + 1));            return array;        case MAP:            length = (random.nextInt(5) + 2) - d;            Map<Object, Object> map = new HashMap<>(length <= 0 ? 0 : length);            for (int i = 0; i < length; i++) {                map.put(randomString(random, 40), generate(schema.getValueType(), random, d + 1));            }            return map;        case UNION:            List<Schema> types = schema.getTypes();            return generate(types.get(random.nextInt(types.size())), random, d);        case FIXED:            byte[] bytes = new byte[schema.getFixedSize()];            random.nextBytes(bytes);            return new GenericData.Fixed(schema, bytes);        case STRING:            return randomString(random, 40);        case BYTES:            return randomBytes(random, 40);        case INT:            return random.nextInt();        case LONG:            return random.nextLong();        case FLOAT:            return random.nextFloat();        case DOUBLE:            return random.nextDouble();        case BOOLEAN:            return random.nextBoolean();        case NULL:            return null;        default:            throw new RuntimeException("Unknown type: " + schema);    }}
0
private Object randomString(Random random, int maxLength)
{    int length = random.nextInt(maxLength);    byte[] bytes = new byte[length];    for (int i = 0; i < length; i++) {        bytes[i] = (byte) ('a' + random.nextInt('z' - 'a'));    }    return utf8ForString ? new Utf8(bytes) : new String(bytes, UTF8);}
0
private static ByteBuffer randomBytes(Random rand, int maxLength)
{    ByteBuffer bytes = ByteBuffer.allocate(rand.nextInt(maxLength));    bytes.limit(bytes.capacity());    rand.nextBytes(bytes.array());    return bytes;}
0
public static void main(String[] args) throws Exception
{    if (args.length < 3 || args.length > 4) {        System.out.println("Usage: RandomData <schemafile> <outputfile> <count> [codec]");        System.exit(-1);    }    Schema sch = new Schema.Parser().parse(new File(args[0]));    DataFileWriter<Object> writer = new DataFileWriter<>(new GenericDatumWriter<>());    writer.setCodec(CodecFactory.fromString(args.length >= 4 ? args[3] : "null"));    writer.create(sch, new File(args[1]));    try {        for (Object datum : new RandomData(sch, Integer.parseInt(args[2]))) {            writer.append(datum);        }    } finally {        writer.close();    }}
0
public void setByteArray(byte[] buf, int offset, int length)
{    this.buf = buf;    this.pos = offset;    this.count = Math.min(offset + length, buf.length);    this.mark = offset;}
0
public void setByteBuffer(ByteBuffer buf)
{        this.buffer = buf.duplicate();    this.mark = buf.position();}
0
public int read() throws IOException
{    if (buffer.hasRemaining()) {        return buffer.get() & 0xff;    } else {        return -1;    }}
0
public int read(byte[] b, int off, int len) throws IOException
{    if (buffer.remaining() <= 0) {        return -1;    }        int bytesToRead = Math.min(len, buffer.remaining());    buffer.get(b, off, bytesToRead);    return bytesToRead;}
0
public long skip(long n) throws IOException
{    if (n <= 0) {                return 0;    }        int bytesToSkip = n > buffer.remaining() ? buffer.remaining() : (int) n;    buffer.position(buffer.position() + bytesToSkip);    return bytesToSkip;}
0
public synchronized void mark(int readLimit)
{                this.mark = buffer.position();}
0
public synchronized void reset() throws IOException
{    buffer.position(mark);}
0
public boolean markSupported()
{    return true;}
0
public byte[] getBytes()
{    return bytes;}
0
public int getLength()
{    return length;}
0
public int getByteLength()
{    return length;}
0
public Utf8 setLength(int newLength)
{    return setByteLength(newLength);}
0
public Utf8 setByteLength(int newLength)
{    if (newLength > MAX_LENGTH) {        throw new AvroRuntimeException("String length " + newLength + " exceeds maximum allowed");    }    if (this.bytes.length < newLength) {        byte[] newBytes = new byte[newLength];        System.arraycopy(bytes, 0, newBytes, 0, this.length);        this.bytes = newBytes;    }    this.length = newLength;    this.string = null;    return this;}
0
public Utf8 set(String string)
{    this.bytes = getBytesFor(string);    this.length = bytes.length;    this.string = string;    return this;}
0
public String toString()
{    if (this.length == 0)        return "";    if (this.string == null) {        this.string = new String(bytes, 0, length, StandardCharsets.UTF_8);    }    return this.string;}
0
public boolean equals(Object o)
{    if (o == this)        return true;    if (!(o instanceof Utf8))        return false;    Utf8 that = (Utf8) o;    if (!(this.length == that.length))        return false;    byte[] thatBytes = that.bytes;    for (int i = 0; i < this.length; i++) if (bytes[i] != thatBytes[i])        return false;    return true;}
0
public int hashCode()
{    int hash = 0;    for (int i = 0; i < this.length; i++) hash = hash * 31 + bytes[i];    return hash;}
0
public int compareTo(Utf8 that)
{    return BinaryData.compareBytes(this.bytes, 0, this.length, that.bytes, 0, that.length);}
0
public char charAt(int index)
{    return toString().charAt(index);}
0
public int length()
{    return toString().length();}
0
public CharSequence subSequence(int start, int end)
{    return toString().subSequence(start, end);}
0
public static byte[] getBytesFor(String str)
{    return str.getBytes(StandardCharsets.UTF_8);}
0
public void clear()
{    backingStore.clear();    reap();}
0
public boolean containsKey(Object key)
{    reap();    return backingStore.containsKey(new IdentityWeakReference(key));}
0
public boolean containsValue(Object value)
{    reap();    return backingStore.containsValue(value);}
0
public Set<Map.Entry<K, V>> entrySet()
{    reap();    Set<Map.Entry<K, V>> ret = new HashSet<>();    for (Map.Entry<IdentityWeakReference, V> ref : backingStore.entrySet()) {        final K key = ref.getKey().get();        final V value = ref.getValue();        Map.Entry<K, V> entry = new Map.Entry<K, V>() {            @Override            public K getKey() {                return key;            }            @Override            public V getValue() {                return value;            }            @Override            public V setValue(V value) {                throw new UnsupportedOperationException();            }        };        ret.add(entry);    }    return Collections.unmodifiableSet(ret);}
0
public K getKey()
{    return key;}
0
public V getValue()
{    return value;}
0
public V setValue(V value)
{    throw new UnsupportedOperationException();}
0
public Set<K> keySet()
{    reap();    Set<K> ret = new HashSet<>();    for (IdentityWeakReference ref : backingStore.keySet()) {        ret.add(ref.get());    }    return Collections.unmodifiableSet(ret);}
0
public boolean equals(Object o)
{    if (!(o instanceof WeakIdentityHashMap)) {        return false;    }    return backingStore.equals(((WeakIdentityHashMap) o).backingStore);}
0
public V get(Object key)
{    reap();    return backingStore.get(new IdentityWeakReference(key));}
0
public V put(K key, V value)
{    reap();    return backingStore.put(new IdentityWeakReference(key), value);}
0
public int hashCode()
{    reap();    return backingStore.hashCode();}
0
public boolean isEmpty()
{    reap();    return backingStore.isEmpty();}
0
public void putAll(Map t)
{    throw new UnsupportedOperationException();}
0
public V remove(Object key)
{    reap();    return backingStore.remove(new IdentityWeakReference(key));}
0
public int size()
{    reap();    return backingStore.size();}
0
public Collection<V> values()
{    reap();    return backingStore.values();}
0
private synchronized void reap()
{    Object zombie = queue.poll();    while (zombie != null) {        IdentityWeakReference victim = (IdentityWeakReference) zombie;        backingStore.remove(victim);        zombie = queue.poll();    }}
0
public int hashCode()
{    return hash;}
0
public boolean equals(Object o)
{    if (this == o) {        return true;    }    if (!(o instanceof WeakIdentityHashMap.IdentityWeakReference)) {        return false;    }    IdentityWeakReference ref = (IdentityWeakReference) o;    return this.get() == ref.get();}
0
public void validate(Schema toValidate, Iterable<Schema> schemasInOrder) throws SchemaValidationException
{    for (Schema existing : schemasInOrder) {        strategy.validate(toValidate, existing);    }}
0
public void validate(Schema toValidate, Schema existing) throws SchemaValidationException
{    ValidateMutualRead.canRead(toValidate, existing);}
0
public void validate(Schema toValidate, Schema existing) throws SchemaValidationException
{    ValidateMutualRead.canRead(existing, toValidate);}
0
public void validate(Schema toValidate, Iterable<Schema> schemasInOrder) throws SchemaValidationException
{    Iterator<Schema> schemas = schemasInOrder.iterator();    if (schemas.hasNext()) {        Schema existing = schemas.next();        strategy.validate(toValidate, existing);    }}
0
public void validate(Schema toValidate, Schema existing) throws SchemaValidationException
{    canRead(toValidate, existing);    canRead(existing, toValidate);}
0
 static void canRead(Schema writtenWith, Schema readUsing) throws SchemaValidationException
{    boolean error;    try {        error = Symbol.hasErrors(new ResolvingGrammarGenerator().generate(writtenWith, readUsing));    } catch (IOException e) {        throw new SchemaValidationException(readUsing, writtenWith, e);    }    if (error) {        throw new SchemaValidationException(readUsing, writtenWith);    }}
0
public boolean equals(Object that)
{    if (that instanceof BarRecord) {        if (this.beerMsg == null) {            return ((BarRecord) that).beerMsg == null;        } else {            return this.beerMsg.equals(((BarRecord) that).beerMsg);        }    }    return false;}
0
public int hashCode()
{    return beerMsg.hashCode();}
0
public String toString()
{    return BarRecord.class.getSimpleName() + "{msg=" + beerMsg + "}";}
0
public ByteBuffer getPayload()
{    return payload;}
0
public void setPayload(ByteBuffer payload)
{    this.payload = payload;}
0
public TypeEnum getTp()
{    return tp;}
0
public void setTp(TypeEnum tp)
{    this.tp = tp;}
0
public boolean equals(Object ob)
{    if (this == ob)        return true;    if (!(ob instanceof ByteBufferRecord))        return false;    ByteBufferRecord that = (ByteBufferRecord) ob;    if (this.getPayload() == null)        return that.getPayload() == null;    if (!this.getPayload().equals(that.getPayload()))        return false;    if (this.getTp() == null)        return that.getTp() == null;    return this.getTp().equals(that.getTp());}
0
public int hashCode()
{    return this.payload.hashCode();}
0
public static void setUpBeforeClass()
{    primitives = new HashSet<>(Arrays.asList(Type.values()));    primitives.removeAll(Arrays.asList(Type.RECORD, Type.ENUM, Type.ARRAY, Type.MAP, Type.UNION, Type.FIXED));    nonNullPrimitives = new HashSet<>(primitives);    nonNullPrimitives.remove(Type.NULL);}
0
public void testIsValidValueWithPrimitives()
{        for (Type type : primitives) {        Field f = new Field("f", Schema.create(type), null, null);        Assert.assertTrue(RecordBuilderBase.isValidValue(f, new Object()));    }        for (Type type : nonNullPrimitives) {        Field f = new Field("f", Schema.create(type), null, null);        Assert.assertFalse(RecordBuilderBase.isValidValue(f, null));    }}
0
public void testIsValidValueWithNullField()
{        Assert.assertTrue(RecordBuilderBase.isValidValue(new Field("f", Schema.create(Type.NULL), null, null), null));}
0
public void testIsValidValueWithUnion()
{        Schema unionWithoutNull = Schema.createUnion(Arrays.asList(Schema.create(Type.STRING), Schema.create(Type.BOOLEAN)));    Assert.assertTrue(RecordBuilderBase.isValidValue(new Field("f", unionWithoutNull, null, null), new Object()));    Assert.assertFalse(RecordBuilderBase.isValidValue(new Field("f", unionWithoutNull, null, null), null));        Schema unionWithNull = Schema.createUnion(Arrays.asList(Schema.create(Type.STRING), Schema.create(Type.NULL)));    Assert.assertTrue(RecordBuilderBase.isValidValue(new Field("f", unionWithNull, null, null), new Object()));    Assert.assertTrue(RecordBuilderBase.isValidValue(new Field("f", unionWithNull, null, null), null));}
0
public static void createSchemas()
{    TestTimeConversions.DATE_SCHEMA = LogicalTypes.date().addToSchema(Schema.create(Schema.Type.INT));    TestTimeConversions.TIME_MILLIS_SCHEMA = LogicalTypes.timeMillis().addToSchema(Schema.create(Schema.Type.INT));    TestTimeConversions.TIME_MICROS_SCHEMA = LogicalTypes.timeMicros().addToSchema(Schema.create(Schema.Type.LONG));    TestTimeConversions.TIMESTAMP_MILLIS_SCHEMA = LogicalTypes.timestampMillis().addToSchema(Schema.create(Schema.Type.LONG));    TestTimeConversions.TIMESTAMP_MICROS_SCHEMA = LogicalTypes.timestampMicros().addToSchema(Schema.create(Schema.Type.LONG));}
0
public void testDateConversion() throws Exception
{    DateConversion conversion = new DateConversion();        LocalDate Jan_6_1970 = LocalDate.of(1970, 1, 6);        LocalDate Jan_1_1970 = LocalDate.of(1970, 1, 1);        LocalDate Dec_27_1969 = LocalDate.of(1969, 12, 27);    Assert.assertEquals("6 Jan 1970 should be 5", 5, (int) conversion.toInt(Jan_6_1970, DATE_SCHEMA, LogicalTypes.date()));    Assert.assertEquals("1 Jan 1970 should be 0", 0, (int) conversion.toInt(Jan_1_1970, DATE_SCHEMA, LogicalTypes.date()));    Assert.assertEquals("27 Dec 1969 should be -5", -5, (int) conversion.toInt(Dec_27_1969, DATE_SCHEMA, LogicalTypes.date()));    Assert.assertEquals("6 Jan 1970 should be 5", conversion.fromInt(5, DATE_SCHEMA, LogicalTypes.date()), Jan_6_1970);    Assert.assertEquals("1 Jan 1970 should be 0", conversion.fromInt(0, DATE_SCHEMA, LogicalTypes.date()), Jan_1_1970);    Assert.assertEquals("27 Dec 1969 should be -5", conversion.fromInt(-5, DATE_SCHEMA, LogicalTypes.date()), Dec_27_1969);}
0
public void testTimeMillisConversion()
{    TimeMillisConversion conversion = new TimeMillisConversion();    LocalTime oneAM = LocalTime.of(1, 0);    LocalTime afternoon = LocalTime.of(15, 14, 15, 926_000_000);    int afternoonMillis = ((15 * 60 + 14) * 60 + 15) * 1000 + 926;    Assert.assertEquals("Midnight should be 0", 0, (int) conversion.toInt(LocalTime.MIDNIGHT, TIME_MILLIS_SCHEMA, LogicalTypes.timeMillis()));    Assert.assertEquals("01:00 should be 3,600,000", 3_600_000, (int) conversion.toInt(oneAM, TIME_MILLIS_SCHEMA, LogicalTypes.timeMillis()));    Assert.assertEquals("15:14:15.926 should be " + afternoonMillis, afternoonMillis, (int) conversion.toInt(afternoon, TIME_MILLIS_SCHEMA, LogicalTypes.timeMillis()));    Assert.assertEquals("Midnight should be 0", LocalTime.MIDNIGHT, conversion.fromInt(0, TIME_MILLIS_SCHEMA, LogicalTypes.timeMillis()));    Assert.assertEquals("01:00 should be 3,600,000", oneAM, conversion.fromInt(3600000, TIME_MILLIS_SCHEMA, LogicalTypes.timeMillis()));    Assert.assertEquals("15:14:15.926 should be " + afternoonMillis, afternoon, conversion.fromInt(afternoonMillis, TIME_MILLIS_SCHEMA, LogicalTypes.timeMillis()));}
0
public void testTimeMicrosConversion() throws Exception
{    TimeMicrosConversion conversion = new TimeMicrosConversion();    LocalTime oneAM = LocalTime.of(1, 0);    LocalTime afternoon = LocalTime.of(15, 14, 15, 926_551_000);    long afternoonMicros = ((long) (15 * 60 + 14) * 60 + 15) * 1_000_000 + 926_551;    Assert.assertEquals("Midnight should be 0", LocalTime.MIDNIGHT, conversion.fromLong(0L, TIME_MICROS_SCHEMA, LogicalTypes.timeMicros()));    Assert.assertEquals("01:00 should be 3,600,000,000", oneAM, conversion.fromLong(3_600_000_000L, TIME_MICROS_SCHEMA, LogicalTypes.timeMicros()));    Assert.assertEquals("15:14:15.926551 should be " + afternoonMicros, afternoon, conversion.fromLong(afternoonMicros, TIME_MICROS_SCHEMA, LogicalTypes.timeMicros()));    Assert.assertEquals("Midnight should be 0", 0, (long) conversion.toLong(LocalTime.MIDNIGHT, TIME_MICROS_SCHEMA, LogicalTypes.timeMicros()));    Assert.assertEquals("01:00 should be 3,600,000,000", 3_600_000_000L, (long) conversion.toLong(oneAM, TIME_MICROS_SCHEMA, LogicalTypes.timeMicros()));    Assert.assertEquals("15:14:15.926551 should be " + afternoonMicros, afternoonMicros, (long) conversion.toLong(afternoon, TIME_MICROS_SCHEMA, LogicalTypes.timeMicros()));}
0
public void testTimestampMillisConversion() throws Exception
{    TimestampMillisConversion conversion = new TimestampMillisConversion();        long nowInstant = Instant.now().toEpochMilli();        Instant now = conversion.fromLong(nowInstant, TIMESTAMP_MILLIS_SCHEMA, LogicalTypes.timestampMillis());    long roundTrip = conversion.toLong(now, TIMESTAMP_MILLIS_SCHEMA, LogicalTypes.timestampMillis());    Assert.assertEquals("Round-trip conversion should work", nowInstant, roundTrip);    long May_28_2015_21_46_53_221_instant = 1432849613221L;    Instant May_28_2015_21_46_53_221 = ZonedDateTime.of(2015, 5, 28, 21, 46, 53, 221_000_000, ZoneOffset.UTC).toInstant();            Assert.assertEquals("Known date should be correct", May_28_2015_21_46_53_221, conversion.fromLong(May_28_2015_21_46_53_221_instant, TIMESTAMP_MILLIS_SCHEMA, LogicalTypes.timestampMillis()));    Assert.assertEquals("Known date should be correct", May_28_2015_21_46_53_221_instant, (long) conversion.toLong(May_28_2015_21_46_53_221, TIMESTAMP_MILLIS_SCHEMA, LogicalTypes.timestampMillis()));        Assert.assertEquals("1970-01-01 should be 0", Instant.EPOCH, conversion.fromLong(0L, TIMESTAMP_MILLIS_SCHEMA, LogicalTypes.timestampMillis()));    Assert.assertEquals("1970-01-01 should be 0", 0L, (long) conversion.toLong(ZonedDateTime.ofInstant(Instant.EPOCH, ZoneOffset.UTC).toInstant(), TIMESTAMP_MILLIS_SCHEMA, LogicalTypes.timestampMillis()));        long Jul_01_1969_12_00_00_123_instant = -15854400000L + 123;    Instant Jul_01_1969_12_00_00_123 = ZonedDateTime.of(1969, 7, 1, 12, 0, 0, 123_000_000, ZoneOffset.UTC).toInstant();    Assert.assertEquals("Pre 1970 date should be correct", Jul_01_1969_12_00_00_123, conversion.fromLong(Jul_01_1969_12_00_00_123_instant, TIMESTAMP_MILLIS_SCHEMA, LogicalTypes.timestampMillis()));    Assert.assertEquals("Pre 1970 date should be correct", Jul_01_1969_12_00_00_123_instant, (long) conversion.toLong(Jul_01_1969_12_00_00_123, TIMESTAMP_MILLIS_SCHEMA, LogicalTypes.timestampMillis()));}
0
public void testTimestampMicrosConversion() throws Exception
{    TimestampMicrosConversion conversion = new TimestampMicrosConversion();            long May_28_2015_21_46_53_221_843_instant = 1432849613221L * 1000 + 843;    Instant May_28_2015_21_46_53_221_843 = ZonedDateTime.of(2015, 5, 28, 21, 46, 53, 221_843_000, ZoneOffset.UTC).toInstant();    Assert.assertEquals("Known date should be correct", May_28_2015_21_46_53_221_843, conversion.fromLong(May_28_2015_21_46_53_221_843_instant, TIMESTAMP_MICROS_SCHEMA, LogicalTypes.timestampMicros()));    Assert.assertEquals("Known date should be correct", May_28_2015_21_46_53_221_843_instant, (long) conversion.toLong(May_28_2015_21_46_53_221_843, TIMESTAMP_MICROS_SCHEMA, LogicalTypes.timestampMillis()));        Assert.assertEquals("1970-01-01 should be 0", Instant.EPOCH, conversion.fromLong(0L, TIMESTAMP_MILLIS_SCHEMA, LogicalTypes.timestampMillis()));    Assert.assertEquals("1970-01-01 should be 0", 0L, (long) conversion.toLong(ZonedDateTime.ofInstant(Instant.EPOCH, ZoneOffset.UTC).toInstant(), TIMESTAMP_MILLIS_SCHEMA, LogicalTypes.timestampMillis()));        long Jul_01_1969_12_00_00_000_123_instant = -15854400000L * 1000 + 123;    Instant Jul_01_1969_12_00_00_000_123 = ZonedDateTime.of(1969, 7, 1, 12, 0, 0, 123_000, ZoneOffset.UTC).toInstant();    Assert.assertEquals("Pre 1970 date should be correct", Jul_01_1969_12_00_00_000_123, conversion.fromLong(Jul_01_1969_12_00_00_000_123_instant, TIMESTAMP_MILLIS_SCHEMA, LogicalTypes.timestampMillis()));    Assert.assertEquals("Pre 1970 date should be correct", Jul_01_1969_12_00_00_000_123_instant, (long) conversion.toLong(Jul_01_1969_12_00_00_000_123, TIMESTAMP_MILLIS_SCHEMA, LogicalTypes.timestampMillis()));}
0
public void testDynamicSchemaWithDateConversion() throws ClassNotFoundException
{    Schema schema = getReflectedSchemaByName("java.time.LocalDate", new TimeConversions.DateConversion());    Assert.assertEquals("Reflected schema should be logicalType date", DATE_SCHEMA, schema);}
0
public void testDynamicSchemaWithTimeConversion() throws ClassNotFoundException
{    Schema schema = getReflectedSchemaByName("java.time.LocalTime", new TimeConversions.TimeMillisConversion());    Assert.assertEquals("Reflected schema should be logicalType timeMillis", TIME_MILLIS_SCHEMA, schema);}
0
public void testDynamicSchemaWithTimeMicrosConversion() throws ClassNotFoundException
{    Schema schema = getReflectedSchemaByName("java.time.LocalTime", new TimeConversions.TimeMicrosConversion());    Assert.assertEquals("Reflected schema should be logicalType timeMicros", TIME_MICROS_SCHEMA, schema);}
0
public void testDynamicSchemaWithDateTimeConversion() throws ClassNotFoundException
{    Schema schema = getReflectedSchemaByName("java.time.Instant", new TimeConversions.TimestampMillisConversion());    Assert.assertEquals("Reflected schema should be logicalType timestampMillis", TIMESTAMP_MILLIS_SCHEMA, schema);}
0
public void testDynamicSchemaWithDateTimeMicrosConversion() throws ClassNotFoundException
{    Schema schema = getReflectedSchemaByName("java.time.Instant", new TimeConversions.TimestampMicrosConversion());    Assert.assertEquals("Reflected schema should be logicalType timestampMicros", TIMESTAMP_MICROS_SCHEMA, schema);}
0
private Schema getReflectedSchemaByName(String className, Conversion<?> conversion) throws ClassNotFoundException
{        Class<?> cls = Class.forName(className);        ReflectData model = new ReflectData();    model.addLogicalTypeConversion(conversion);    return model.getSchema(cls);}
0
public String getName()
{    return CODECNAME;}
0
public ByteBuffer compress(ByteBuffer in) throws IOException
{    ByteBuffer out = ByteBuffer.allocate(in.remaining());    while (in.position() < in.capacity()) out.put((byte) ~in.get());    return out;}
0
public ByteBuffer decompress(ByteBuffer in) throws IOException
{    ByteBuffer out = ByteBuffer.allocate(in.remaining());    while (in.position() < in.capacity()) out.put((byte) ~in.get());    return out;}
0
public boolean equals(Object other)
{    if (this == other)        return true;    if (other instanceof Codec) {        ByteBuffer original = ByteBuffer.allocate(getName().getBytes(UTF_8).length);        original.put(getName().getBytes(UTF_8));        original.rewind();        try {            return compareDecompress((Codec) other, original);        } catch (IOException e) {            return false;        }    } else        return false;}
0
private boolean compareDecompress(Codec other, ByteBuffer original) throws IOException
{    ByteBuffer compressedA = this.compress(original);    original.rewind();    ByteBuffer compressedB = other.compress(original);    return this.decompress(compressedA).equals(other.decompress((ByteBuffer) compressedA.rewind())) && this.decompress(compressedB).equals(other.decompress((ByteBuffer) compressedB.rewind()));}
0
public int hashCode()
{    return getName().hashCode();}
0
public static Collection<Object[]> data()
{    return Arrays.asList(new Object[][] { { "bzip2", BZip2Codec.class }, { "zstandard", ZstandardCodec.class }, { "null", NullCodec.class }, { "xz", XZCodec.class }, { "snappy", SnappyCodec.class }, { "deflate", DeflateCodec.class } });}
0
public void testCodec() throws IOException
{    int inputSize = 500_000;    byte[] input = generateTestData(inputSize);    Codec codecInstance = CodecFactory.fromString(codec).createInstance();    assertTrue(codecClass.isInstance(codecInstance));    assertTrue(codecInstance.getName().equals(codec));    ByteBuffer inputByteBuffer = ByteBuffer.wrap(input);    ByteBuffer compressedBuffer = codecInstance.compress(inputByteBuffer);    int compressedSize = compressedBuffer.remaining();        assertTrue(compressedSize > 0);                    assertTrue(compressedSize < inputSize || codec.equals("null"));        ByteBuffer decompressedBuffer = codecInstance.decompress(compressedBuffer);        inputByteBuffer.rewind();    Assert.assertEquals(decompressedBuffer, inputByteBuffer);}
0
public void testCodecSlice() throws IOException
{    int inputSize = 500_000;    byte[] input = generateTestData(inputSize);    Codec codecInstance = CodecFactory.fromString(codec).createInstance();    ByteBuffer partialBuffer = ByteBuffer.wrap(input);    partialBuffer.position(17);    ByteBuffer inputByteBuffer = partialBuffer.slice();    ByteBuffer compressedBuffer = codecInstance.compress(inputByteBuffer);    int compressedSize = compressedBuffer.remaining();        assertTrue(compressedSize > 0);        ByteBuffer sliceBuffer = ByteBuffer.allocate(compressedSize + 100);    sliceBuffer.position(50);    sliceBuffer.put(compressedBuffer);    sliceBuffer.limit(compressedSize + 50);    sliceBuffer.position(50);        ByteBuffer decompressedBuffer = codecInstance.decompress(sliceBuffer.slice());        inputByteBuffer.rewind();    Assert.assertEquals(decompressedBuffer, inputByteBuffer);}
0
public static byte[] generateTestData(int inputSize)
{    byte[] arr = new byte[inputSize];    for (int i = 0; i < arr.length; i++) {        arr[i] = (byte) (65 + i % 10);    }    return arr;}
0
public void testCustomCodec()
{    CustomCodec customCodec = new CustomCodec();    Codec snappyCodec = new SnappyCodec.Option().createInstance();    assertTrue(customCodec.equals(new CustomCodec()));    assertFalse(customCodec.equals(snappyCodec));    String testString = "Testing 123";    ByteBuffer original = ByteBuffer.allocate(testString.getBytes(UTF_8).length);    original.put(testString.getBytes(UTF_8));    original.rewind();    ByteBuffer decompressed = null;    try {        ByteBuffer compressed = customCodec.compress(original);        compressed.rewind();        decompressed = customCodec.decompress(compressed);    } catch (IOException e) {        e.printStackTrace();    }    assertEquals(testString, new String(decompressed.array(), UTF_8));}
0
public void write(int b) throws IOException
{    if (byteCnt > 0) {        --byteCnt;    } else if (byteCnt == 0) {        --byteCnt;        throw new IOException("Artificial failure from FailingOutputStream");    } else {        fail("No bytes should have been written after IOException");    }}
0
public void testNoWritingAfterException() throws IOException
{    try (DataFileWriter<Object> writer = new DataFileWriter<>(new GenericDatumWriter<>())) {        writer.create(SCHEMA, new FailingOutputStream(100000));        int recordCnt = 0;        for (Object datum : new RandomData(SCHEMA, 100000, 42)) {            writer.append(datum);            if (++recordCnt % 17 == 0) {                writer.flush();            }        }    } catch (IOException e) {        return;    }    fail("IOException should have been thrown");}
0
private byte[] getSerializedMessage(IndexedRecord message, Schema schema) throws Exception
{    ByteArrayOutputStream baos = new ByteArrayOutputStream(4096);    SpecificDatumWriter<IndexedRecord> writer = new SpecificDatumWriter<>();    try (DataFileWriter<IndexedRecord> dfw = new DataFileWriter<>(writer).create(schema, baos)) {        dfw.append(message);    }    return baos.toByteArray();}
0
private Schema getTestSchema() throws Exception
{    Schema schema = Schema.createRecord("TestRecord", "this is a test record", "org.apache.avro.file", false);    List<Field> fields = new ArrayList<>();    fields.add(new Field("name", Schema.create(Type.STRING), "this is a test field"));    schema.setFields(fields);    return schema;}
0
public void testSerialization() throws Exception
{    Schema testSchema = getTestSchema();    GenericRecord message = new Record(testSchema);    message.put("name", "testValue");    byte[] data = getSerializedMessage(message, testSchema);    GenericDatumReader<IndexedRecord> reader = new GenericDatumReader<>(testSchema);    final IndexedRecord result;    try (SeekableInput in = new SeekableByteArrayInput(data);        FileReader<IndexedRecord> dfr = DataFileReader.openReader(in, reader)) {        result = dfr.next();    }    Assert.assertNotNull(result);    Assert.assertTrue(result instanceof GenericRecord);    Assert.assertEquals(new Utf8("testValue"), ((GenericRecord) result).get("name"));}
0
public void testZstandardToStringAndName() throws IOException
{    Codec codec = CodecFactory.zstandardCodec(3).createInstance();    assertTrue(codec instanceof ZstandardCodec);    assertTrue(codec.getName().equals("zstandard"));    assertTrue(codec.toString().equals("zstandard[3]"));}
0
public static org.apache.avro.Schema getClassSchema()
{    return SCHEMA$;}
0
public static BinaryMessageDecoder<FooBarSpecificRecord> getDecoder()
{    return DECODER;}
0
public static BinaryMessageDecoder<FooBarSpecificRecord> createDecoder(SchemaStore resolver)
{    return new BinaryMessageDecoder<>(MODEL$, SCHEMA$, resolver);}
0
public java.nio.ByteBuffer toByteBuffer() throws java.io.IOException
{    return ENCODER.encode(this);}
0
public static FooBarSpecificRecord fromByteBuffer(java.nio.ByteBuffer b) throws java.io.IOException
{    return DECODER.decode(b);}
0
public org.apache.avro.Schema getSchema()
{    return SCHEMA$;}
0
public java.lang.Object get(int field$)
{    switch(field$) {        case 0:            return id;        case 1:            return name;        case 2:            return nicknames;        case 3:            return relatedids;        case 4:            return typeEnum;        default:            throw new org.apache.avro.AvroRuntimeException("Bad index");    }}
0
public void put(int field$, java.lang.Object value$)
{    switch(field$) {        case 0:            id = (java.lang.Integer) value$;            break;        case 1:            name = (java.lang.String) value$;            break;        case 2:            nicknames = (java.util.List<java.lang.String>) value$;            break;        case 3:            relatedids = (java.util.List<java.lang.Integer>) value$;            break;        case 4:            typeEnum = (org.apache.avro.TypeEnum) value$;            break;        default:            throw new org.apache.avro.AvroRuntimeException("Bad index");    }}
0
public java.lang.Integer getId()
{    return id;}
0
public void setId(java.lang.Integer value)
{    this.id = value;}
0
public java.lang.String getName()
{    return name;}
0
public void setName(java.lang.String value)
{    this.name = value;}
0
public java.util.List<java.lang.String> getNicknames()
{    return nicknames;}
0
public void setNicknames(java.util.List<java.lang.String> value)
{    this.nicknames = value;}
0
public java.util.List<java.lang.Integer> getRelatedids()
{    return relatedids;}
0
public void setRelatedids(java.util.List<java.lang.Integer> value)
{    this.relatedids = value;}
0
public org.apache.avro.TypeEnum getTypeEnum()
{    return typeEnum;}
0
public void setTypeEnum(org.apache.avro.TypeEnum value)
{    this.typeEnum = value;}
0
public static org.apache.avro.FooBarSpecificRecord.Builder newBuilder()
{    return new org.apache.avro.FooBarSpecificRecord.Builder();}
0
public static org.apache.avro.FooBarSpecificRecord.Builder newBuilder(org.apache.avro.FooBarSpecificRecord.Builder other)
{    if (other == null) {        return new org.apache.avro.FooBarSpecificRecord.Builder();    } else {        return new org.apache.avro.FooBarSpecificRecord.Builder(other);    }}
0
public static org.apache.avro.FooBarSpecificRecord.Builder newBuilder(org.apache.avro.FooBarSpecificRecord other)
{    if (other == null) {        return new org.apache.avro.FooBarSpecificRecord.Builder();    } else {        return new org.apache.avro.FooBarSpecificRecord.Builder(other);    }}
0
public java.lang.Integer getId()
{    return id;}
0
public org.apache.avro.FooBarSpecificRecord.Builder setId(int value)
{    validate(fields()[0], value);    this.id = value;    fieldSetFlags()[0] = true;    return this;}
0
public boolean hasId()
{    return fieldSetFlags()[0];}
0
public org.apache.avro.FooBarSpecificRecord.Builder clearId()
{    fieldSetFlags()[0] = false;    return this;}
0
public java.lang.String getName()
{    return name;}
0
public org.apache.avro.FooBarSpecificRecord.Builder setName(java.lang.String value)
{    validate(fields()[1], value);    this.name = value;    fieldSetFlags()[1] = true;    return this;}
0
public boolean hasName()
{    return fieldSetFlags()[1];}
0
public org.apache.avro.FooBarSpecificRecord.Builder clearName()
{    name = null;    fieldSetFlags()[1] = false;    return this;}
0
public java.util.List<java.lang.String> getNicknames()
{    return nicknames;}
0
public org.apache.avro.FooBarSpecificRecord.Builder setNicknames(java.util.List<java.lang.String> value)
{    validate(fields()[2], value);    this.nicknames = value;    fieldSetFlags()[2] = true;    return this;}
0
public boolean hasNicknames()
{    return fieldSetFlags()[2];}
0
public org.apache.avro.FooBarSpecificRecord.Builder clearNicknames()
{    nicknames = null;    fieldSetFlags()[2] = false;    return this;}
0
public java.util.List<java.lang.Integer> getRelatedids()
{    return relatedids;}
0
public org.apache.avro.FooBarSpecificRecord.Builder setRelatedids(java.util.List<java.lang.Integer> value)
{    validate(fields()[3], value);    this.relatedids = value;    fieldSetFlags()[3] = true;    return this;}
0
public boolean hasRelatedids()
{    return fieldSetFlags()[3];}
0
public org.apache.avro.FooBarSpecificRecord.Builder clearRelatedids()
{    relatedids = null;    fieldSetFlags()[3] = false;    return this;}
0
public org.apache.avro.TypeEnum getTypeEnum()
{    return typeEnum;}
0
public org.apache.avro.FooBarSpecificRecord.Builder setTypeEnum(org.apache.avro.TypeEnum value)
{    validate(fields()[4], value);    this.typeEnum = value;    fieldSetFlags()[4] = true;    return this;}
0
public boolean hasTypeEnum()
{    return fieldSetFlags()[4];}
0
public org.apache.avro.FooBarSpecificRecord.Builder clearTypeEnum()
{    typeEnum = null;    fieldSetFlags()[4] = false;    return this;}
0
public FooBarSpecificRecord build()
{    try {        FooBarSpecificRecord record = new FooBarSpecificRecord();        record.id = fieldSetFlags()[0] ? this.id : (java.lang.Integer) defaultValue(fields()[0]);        record.name = fieldSetFlags()[1] ? this.name : (java.lang.String) defaultValue(fields()[1]);        record.nicknames = fieldSetFlags()[2] ? this.nicknames : (java.util.List<java.lang.String>) defaultValue(fields()[2]);        record.relatedids = fieldSetFlags()[3] ? this.relatedids : (java.util.List<java.lang.Integer>) defaultValue(fields()[3]);        record.typeEnum = fieldSetFlags()[4] ? this.typeEnum : (org.apache.avro.TypeEnum) defaultValue(fields()[4]);        return record;    } catch (org.apache.avro.AvroMissingFieldException e) {        throw e;    } catch (java.lang.Exception e) {        throw new org.apache.avro.AvroRuntimeException(e);    }}
0
public void writeExternal(java.io.ObjectOutput out) throws java.io.IOException
{    WRITER$.write(this, SpecificData.getEncoder(out));}
0
public void readExternal(java.io.ObjectInput in) throws java.io.IOException
{    READER$.read(this, SpecificData.getDecoder(in));}
0
public boolean equals(Object that)
{    if (that instanceof FooRecord) {        return this.fooCount == ((FooRecord) that).fooCount;    }    return false;}
0
public int hashCode()
{    return fooCount;}
0
public String toString()
{    return FooRecord.class.getSimpleName() + "{count=" + fooCount + "}";}
0
private static void writeBlock(Encoder vout, FileOutputStream out) throws IOException
{    vout.writeLong(blockCount);    bufOut.flush();    buffer.writeTo(out);    buffer.reset();    blockCount = 0;}
0
public static void main(String[] args) throws Exception
{    if (args.length != 3) {        System.out.println("Usage: GenerateBlockingData <schemafile> <outputfile> <count>");        System.exit(-1);    }    Schema sch = new Schema.Parser().parse(new File(args[0]));    File outputFile = new File(args[1]);    int numObjects = Integer.parseInt(args[2]);    FileOutputStream out = new FileOutputStream(outputFile, false);    DatumWriter<Object> dout = new GenericDatumWriter<>();    dout.setSchema(sch);    Encoder vout = factory.directBinaryEncoder(out, null);        vout.writeLong(numObjects);    for (Object datum : new RandomData(sch, numObjects)) {        dout.write(datum, bufOut);        blockCount++;        if (buffer.size() >= SYNC_INTERVAL) {            writeBlock(vout, out);        }    }    if (blockCount > 0) {        writeBlock(vout, out);    }    out.flush();    out.close();}
0
private static byte[] serializeRecord(FooBarSpecificRecord fooBarSpecificRecord) throws IOException
{    GenericDatumWriter<FooBarSpecificRecord> datumWriter = new GenericDatumWriter<>(FooBarSpecificRecord.SCHEMA$);    ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream();    Encoder encoder = EncoderFactory.get().binaryEncoder(byteArrayOutputStream, null);    datumWriter.write(fooBarSpecificRecord, encoder);    encoder.flush();    return byteArrayOutputStream.toByteArray();}
0
public void testGenericWriteAndRead() throws IOException
{    FooBarSpecificRecord specificRecord = getRecord();    byte[] bytes = serializeRecord(specificRecord);    Decoder decoder = DecoderFactory.get().binaryDecoder(bytes, null);    GenericDatumReader<IndexedRecord> genericDatumReader = new GenericDatumReader<>(FooBarSpecificRecord.SCHEMA$);    IndexedRecord deserialized = new GenericData.Record(FooBarSpecificRecord.SCHEMA$);    genericDatumReader.read(deserialized, decoder);    assertEquals(0, GenericData.get().compare(specificRecord, deserialized, FooBarSpecificRecord.SCHEMA$));}
0
public void testGenericWriteSpecificRead() throws IOException
{    FooBarSpecificRecord specificRecord = getRecord();    byte[] bytes = serializeRecord(specificRecord);    Decoder decoder = DecoderFactory.get().binaryDecoder(bytes, null);    SpecificDatumReader<FooBarSpecificRecord> specificDatumReader = new SpecificDatumReader<>(FooBarSpecificRecord.SCHEMA$);    FooBarSpecificRecord deserialized = new FooBarSpecificRecord();    specificDatumReader.read(deserialized, decoder);    assertEquals(specificRecord, deserialized);}
0
private FooBarSpecificRecord getRecord()
{    return FooBarSpecificRecord.newBuilder().setId(42).setName("foo").setNicknames(Collections.singletonList("bar")).setRelatedids(Collections.singletonList(3)).setTypeEnum(TypeEnum.a).build();}
0
public void testrecordConstructorNullSchema() throws Exception
{    new GenericData.Record(null);}
0
public void testrecordConstructorWrongSchema() throws Exception
{    new GenericData.Record(Schema.create(Schema.Type.INT));}
0
public void testArrayConstructorNullSchema() throws Exception
{    new GenericData.Array<>(1, null);}
0
public void testArrayConstructorWrongSchema() throws Exception
{    new GenericData.Array<>(1, Schema.create(Schema.Type.INT));}
0
public void testRecordCreateEmptySchema() throws Exception
{    Schema s = Schema.createRecord("schemaName", "schemaDoc", "namespace", false);    Record r = new GenericData.Record(s);}
0
public void testGetEmptySchemaFields() throws Exception
{    Schema s = Schema.createRecord("schemaName", "schemaDoc", "namespace", false);    s.getFields();}
0
public void testGetEmptySchemaField() throws Exception
{    Schema s = Schema.createRecord("schemaName", "schemaDoc", "namespace", false);    s.getField("foo");}
0
public void testRecordPutInvalidField() throws Exception
{    Schema s = Schema.createRecord("schemaName", "schemaDoc", "namespace", false);    List<Schema.Field> fields = new ArrayList<>();    fields.add(new Schema.Field("someFieldName", s, "docs", null));    s.setFields(fields);    Record r = new GenericData.Record(s);    r.put("invalidFieldName", "someValue");}
0
public void testHashCode()
{    GenericData.get().hashCode(null, Schema.create(Type.NULL));    GenericData.get().hashCode(null, Schema.createUnion(Arrays.asList(Schema.create(Type.BOOLEAN), Schema.create(Type.STRING))));    List<CharSequence> stuff = new ArrayList<>();    stuff.add("string");    Schema schema = recordSchema();    GenericRecord r = new GenericData.Record(schema);    r.put(0, stuff);    GenericData.get().hashCode(r, schema);}
0
public void testEquals()
{    Schema s = recordSchema();    GenericRecord r0 = new GenericData.Record(s);    GenericRecord r1 = new GenericData.Record(s);    GenericRecord r2 = new GenericData.Record(s);    Collection<CharSequence> l0 = new ArrayDeque<>();    List<CharSequence> l1 = new ArrayList<>();    GenericArray<CharSequence> l2 = new GenericData.Array<>(1, s.getFields().get(0).schema());    String foo = "foo";    l0.add(new StringBuilder(foo));    l1.add(foo);    l2.add(new Utf8(foo));    r0.put(0, l0);    r1.put(0, l1);    r2.put(0, l2);    assertEquals(r0, r1);    assertEquals(r0, r2);    assertEquals(r1, r2);}
0
private Schema recordSchema()
{    List<Field> fields = new ArrayList<>();    fields.add(new Field("anArray", Schema.createArray(Schema.create(Type.STRING)), null, null));    Schema schema = Schema.createRecord("arrayFoo", "test", "mytest", false);    schema.setFields(fields);    return schema;}
0
public void testEquals2()
{    Schema schema1 = Schema.createRecord("r", null, "x", false);    List<Field> fields1 = new ArrayList<>();    fields1.add(new Field("a", Schema.create(Schema.Type.STRING), null, null, Field.Order.IGNORE));    schema1.setFields(fields1);        Schema schema2 = Schema.createRecord("r", null, "x", false);    List<Field> fields2 = new ArrayList<>();    fields2.add(new Field("a", Schema.create(Schema.Type.STRING), null, null, Field.Order.ASCENDING));    schema2.setFields(fields2);    GenericRecord record1 = new GenericData.Record(schema1);    record1.put("a", "1");    GenericRecord record2 = new GenericData.Record(schema2);    record2.put("a", "2");    assertFalse(record2.equals(record1));    assertFalse(record1.equals(record2));}
0
public void testRecordGetFieldDoesntExist() throws Exception
{    List<Field> fields = new ArrayList<>();    Schema schema = Schema.createRecord(fields);    GenericData.Record record = new GenericData.Record(schema);    assertNull(record.get("does not exist"));}
0
public void testArrayReversal()
{    Schema schema = Schema.createArray(Schema.create(Schema.Type.INT));    GenericArray<Integer> forward = new GenericData.Array<>(10, schema);    GenericArray<Integer> backward = new GenericData.Array<>(10, schema);    for (int i = 0; i <= 9; i++) {        forward.add(i);    }    for (int i = 9; i >= 0; i--) {        backward.add(i);    }    forward.reverse();    assertTrue(forward.equals(backward));}
0
public void testArrayListInterface()
{    Schema schema = Schema.createArray(Schema.create(Schema.Type.INT));    GenericArray<Integer> array = new GenericData.Array<>(1, schema);    array.add(99);    assertEquals(Integer.valueOf(99), array.get(0));    List<Integer> list = new ArrayList<>();    list.add(99);    assertEquals(array, list);    assertEquals(list, array);    assertEquals(list.hashCode(), array.hashCode());    try {        array.get(2);        fail("Expected IndexOutOfBoundsException getting index 2");    } catch (IndexOutOfBoundsException e) {    }    array.clear();    assertEquals(0, array.size());    try {        array.get(0);        fail("Expected IndexOutOfBoundsException getting index 0 after clear()");    } catch (IndexOutOfBoundsException e) {    }}
0
public void testArrayAddAtLocation()
{    Schema schema = Schema.createArray(Schema.create(Schema.Type.INT));    GenericArray<Integer> array = new GenericData.Array<>(6, schema);    array.clear();    for (int i = 0; i < 5; ++i) array.add(i);    assertEquals(5, array.size());    array.add(0, 6);    assertEquals(Integer.valueOf(6), array.get(0));    assertEquals(6, array.size());    assertEquals(Integer.valueOf(0), array.get(1));    assertEquals(Integer.valueOf(4), array.get(5));    array.add(6, 7);    assertEquals(Integer.valueOf(7), array.get(6));    assertEquals(7, array.size());    assertEquals(Integer.valueOf(6), array.get(0));    assertEquals(Integer.valueOf(4), array.get(5));    array.add(1, 8);    assertEquals(Integer.valueOf(8), array.get(1));    assertEquals(Integer.valueOf(0), array.get(2));    assertEquals(Integer.valueOf(6), array.get(0));    assertEquals(8, array.size());    try {        array.get(9);        fail("Expected IndexOutOfBoundsException after adding elements");    } catch (IndexOutOfBoundsException e) {    }}
0
public void testArrayRemove()
{    Schema schema = Schema.createArray(Schema.create(Schema.Type.INT));    GenericArray<Integer> array = new GenericData.Array<>(10, schema);    array.clear();    for (int i = 0; i < 10; ++i) array.add(i);    assertEquals(10, array.size());    assertEquals(Integer.valueOf(0), array.get(0));    assertEquals(Integer.valueOf(9), array.get(9));    array.remove(0);    assertEquals(9, array.size());    assertEquals(Integer.valueOf(1), array.get(0));    assertEquals(Integer.valueOf(2), array.get(1));    assertEquals(Integer.valueOf(9), array.get(8));        try {        array.get(9);        fail("Expected IndexOutOfBoundsException after removing an element");    } catch (IndexOutOfBoundsException e) {    }    try {        array.set(9, 99);        fail("Expected IndexOutOfBoundsException after removing an element");    } catch (IndexOutOfBoundsException e) {    }    try {        array.remove(9);        fail("Expected IndexOutOfBoundsException after removing an element");    } catch (IndexOutOfBoundsException e) {    }        assertEquals(Integer.valueOf(9), array.remove(8));    assertEquals(8, array.size());        array.add(88);    assertEquals(Integer.valueOf(88), array.get(8));}
0
public void testArraySet()
{    Schema schema = Schema.createArray(Schema.create(Schema.Type.INT));    GenericArray<Integer> array = new GenericData.Array<>(10, schema);    array.clear();    for (int i = 0; i < 10; ++i) array.add(i);    assertEquals(10, array.size());    assertEquals(Integer.valueOf(0), array.get(0));    assertEquals(Integer.valueOf(5), array.get(5));    assertEquals(Integer.valueOf(5), array.set(5, 55));    assertEquals(10, array.size());    assertEquals(Integer.valueOf(55), array.get(5));}
0
public void testToStringIsJson() throws JsonParseException, IOException
{    Field stringField = new Field("string", Schema.create(Type.STRING), null, null);    Field enumField = new Field("enum", Schema.createEnum("my_enum", "doc", null, Arrays.asList("a", "b", "c")), null, null);    Schema schema = Schema.createRecord("my_record", "doc", "mytest", false);    schema.setFields(Arrays.asList(stringField, enumField));    GenericRecord r = new GenericData.Record(schema);        r.put(stringField.name(), "hello\nthere\"\tyou\u2013}");    r.put(enumField.name(), new GenericData.EnumSymbol(enumField.schema(), "a"));    String json = r.toString();    JsonFactory factory = new JsonFactory();    JsonParser parser = factory.createParser(json);    ObjectMapper mapper = new ObjectMapper();        mapper.readTree(parser);}
0
public void testMapWithNonStringKeyToStringIsJson() throws Exception
{    Schema intMapSchema = new Schema.Parser().parse("{\"type\": \"map\", \"values\": \"string\", \"java-key-class\" : \"java.lang.Integer\"}");    Field intMapField = new Field("intMap", Schema.createMap(intMapSchema), null, null);    Schema decMapSchema = new Schema.Parser().parse("{\"type\": \"map\", \"values\": \"string\", \"java-key-class\" : \"java.math.BigDecimal\"}");    Field decMapField = new Field("decMap", Schema.createMap(decMapSchema), null, null);    Schema boolMapSchema = new Schema.Parser().parse("{\"type\": \"map\", \"values\": \"string\", \"java-key-class\" : \"java.lang.Boolean\"}");    Field boolMapField = new Field("boolMap", Schema.createMap(boolMapSchema), null, null);    Schema fileMapSchema = new Schema.Parser().parse("{\"type\": \"map\", \"values\": \"string\", \"java-key-class\" : \"java.io.File\"}");    Field fileMapField = new Field("fileMap", Schema.createMap(fileMapSchema), null, null);    Schema schema = Schema.createRecord("my_record", "doc", "mytest", false);    schema.setFields(Arrays.asList(intMapField, decMapField, boolMapField, fileMapField));    HashMap<Integer, String> intPair = new HashMap<>();    intPair.put(1, "one");    intPair.put(2, "two");    HashMap<java.math.BigDecimal, String> decPair = new HashMap<>();    decPair.put(java.math.BigDecimal.valueOf(1), "one");    decPair.put(java.math.BigDecimal.valueOf(2), "two");    HashMap<Boolean, String> boolPair = new HashMap<>();    boolPair.put(true, "isTrue");    boolPair.put(false, "isFalse");    boolPair.put(null, null);    HashMap<java.io.File, String> filePair = new HashMap<>();    java.io.File f = new java.io.File(getClass().getResource("/SchemaBuilder.avsc").toURI());    filePair.put(f, "File");    GenericRecord r = new GenericData.Record(schema);    r.put(intMapField.name(), intPair);    r.put(decMapField.name(), decPair);    r.put(boolMapField.name(), boolPair);    r.put(fileMapField.name(), filePair);    String json = r.toString();    JsonFactory factory = new JsonFactory();    JsonParser parser = factory.createParser(json);    ObjectMapper mapper = new ObjectMapper();        mapper.readTree(parser);}
0
public void testToStringEscapesControlCharsInBytes() throws Exception
{    GenericData data = GenericData.get();    ByteBuffer bytes = ByteBuffer.wrap(new byte[] { 'a', '\n', 'b' });    assertEquals("\"a\\nb\"", data.toString(bytes));    assertEquals("\"a\\nb\"", data.toString(bytes));}
0
public void testToStringEscapesControlCharsInMap()
{    GenericData data = GenericData.get();    Map<String, String> m = new HashMap<>();    m.put("a\n\\b", "a\n\\b");    assertEquals("{\"a\\n\\\\b\": \"a\\n\\\\b\"}", data.toString(m));}
0
public void testToStringFixed() throws Exception
{    GenericData data = GenericData.get();    assertEquals("[97, 10, 98]", data.toString(new GenericData.Fixed(Schema.createFixed("test", null, null, 3), new byte[] { 'a', '\n', 'b' })));}
0
public void testToStringDoesNotEscapeForwardSlash() throws Exception
{    GenericData data = GenericData.get();    assertEquals("\"/\"", data.toString("/"));}
0
public void testToStringNanInfinity() throws Exception
{    GenericData data = GenericData.get();    assertEquals("\"Infinity\"", data.toString(Float.POSITIVE_INFINITY));    assertEquals("\"-Infinity\"", data.toString(Float.NEGATIVE_INFINITY));    assertEquals("\"NaN\"", data.toString(Float.NaN));    assertEquals("\"Infinity\"", data.toString(Double.POSITIVE_INFINITY));    assertEquals("\"-Infinity\"", data.toString(Double.NEGATIVE_INFINITY));    assertEquals("\"NaN\"", data.toString(Double.NaN));}
0
public void testCompare()
{        Field integerField = new Field("test", Schema.create(Type.INT), null, null);    List<Field> fields = new ArrayList<>();    fields.add(integerField);    Schema record = Schema.createRecord("test", null, null, false);    record.setFields(fields);    ByteArrayOutputStream b1 = new ByteArrayOutputStream(5);    ByteArrayOutputStream b2 = new ByteArrayOutputStream(5);    BinaryEncoder b1Enc = EncoderFactory.get().binaryEncoder(b1, null);    BinaryEncoder b2Enc = EncoderFactory.get().binaryEncoder(b2, null);        Record testDatum1 = new Record(record);    testDatum1.put(0, 1);    Record testDatum2 = new Record(record);    testDatum2.put(0, 2);    GenericDatumWriter<Record> gWriter = new GenericDatumWriter<>(record);    Integer start1 = 0, start2 = 0;    try {                        gWriter.write(testDatum1, b1Enc);        b1Enc.flush();        start1 = b1.size();        gWriter.write(testDatum1, b1Enc);        b1Enc.flush();        b1.close();        gWriter.write(testDatum2, b2Enc);        b2Enc.flush();        start2 = b2.size();        gWriter.write(testDatum2, b2Enc);        b2Enc.flush();        b2.close();                assertEquals(-1, BinaryData.compare(b1.toByteArray(), start1, b2.toByteArray(), start2, record));    } catch (IOException e) {        fail("IOException while writing records to output stream.");    }}
0
public void testEnumCompare()
{    Schema s = Schema.createEnum("Kind", null, null, Arrays.asList("Z", "Y", "X"));    GenericEnumSymbol z = new GenericData.EnumSymbol(s, "Z");    GenericEnumSymbol z2 = new GenericData.EnumSymbol(s, "Z");    assertEquals(0, z.compareTo(z2));    GenericEnumSymbol y = new GenericData.EnumSymbol(s, "Y");    assertTrue(y.compareTo(z) > 0);    assertTrue(z.compareTo(y) < 0);}
0
public void testByteBufferDeepCopy()
{            byte[] buffer_value = { 0, 1, 2, 3, 0, 0, 0 };    ByteBuffer buffer = ByteBuffer.wrap(buffer_value, 1, 4);    Schema schema = Schema.createRecord("my_record", "doc", "mytest", false);    Field byte_field = new Field("bytes", Schema.create(Type.BYTES), null, null);    schema.setFields(Collections.singletonList(byte_field));    GenericRecord record = new GenericData.Record(schema);    record.put(byte_field.name(), buffer);    GenericRecord copy = GenericData.get().deepCopy(schema, record);    ByteBuffer buffer_copy = (ByteBuffer) copy.get(byte_field.name());    assertEquals(buffer, buffer_copy);}
0
public void testValidateNullableEnum()
{    List<Schema> unionTypes = new ArrayList<>();    Schema schema;    Schema nullSchema = Schema.create(Type.NULL);    Schema enumSchema = Schema.createEnum("AnEnum", null, null, Arrays.asList("X", "Y", "Z"));    GenericEnumSymbol w = new GenericData.EnumSymbol(enumSchema, "W");    GenericEnumSymbol x = new GenericData.EnumSymbol(enumSchema, "X");    GenericEnumSymbol y = new GenericData.EnumSymbol(enumSchema, "Y");    GenericEnumSymbol z = new GenericData.EnumSymbol(enumSchema, "Z");        unionTypes.clear();    unionTypes.add(nullSchema);    unionTypes.add(enumSchema);    schema = Schema.createUnion(unionTypes);    assertTrue(GenericData.get().validate(schema, z));    assertTrue(GenericData.get().validate(schema, y));    assertTrue(GenericData.get().validate(schema, x));    assertFalse(GenericData.get().validate(schema, w));    assertTrue(GenericData.get().validate(schema, null));        unionTypes.clear();    unionTypes.add(enumSchema);    unionTypes.add(nullSchema);    schema = Schema.createUnion(unionTypes);    assertTrue(GenericData.get().validate(schema, z));    assertTrue(GenericData.get().validate(schema, y));    assertTrue(GenericData.get().validate(schema, x));    assertFalse(GenericData.get().validate(schema, w));    assertTrue(GenericData.get().validate(schema, null));}
0
public void validateRequiresGenericSymbolForEnumSchema()
{    final Schema schema = Schema.createEnum("my_enum", "doc", "namespace", Arrays.asList("ONE", "TWO", "THREE"));    final GenericData gd = GenericData.get();    /* positive cases */    assertTrue(gd.validate(schema, new GenericData.EnumSymbol(schema, "ONE")));    assertTrue(gd.validate(schema, new GenericData.EnumSymbol(schema, anEnum.ONE)));    /* negative cases */    assertFalse("We don't expect GenericData to allow a String datum for an enum schema", gd.validate(schema, "ONE"));    assertFalse("We don't expect GenericData to allow a Java Enum for an enum schema", gd.validate(schema, anEnum.ONE));}
0
public void testValidateUnion()
{    Schema type1Schema = SchemaBuilder.record("Type1").fields().requiredString("myString").requiredInt("myInt").endRecord();    Schema type2Schema = SchemaBuilder.record("Type2").fields().requiredString("myString").endRecord();    Schema unionSchema = SchemaBuilder.unionOf().type(type1Schema).and().type(type2Schema).endUnion();    GenericRecord record = new GenericData.Record(type2Schema);    record.put("myString", "myValue");    assertTrue(GenericData.get().validate(unionSchema, record));}
0
public void testToStringSameValues() throws IOException
{    List<Field> fields = new ArrayList<>();    fields.add(new Field("nullstring1", Schema.create(Type.STRING), null, null));    fields.add(new Field("nullstring2", Schema.create(Type.STRING), null, null));    fields.add(new Field("string1", Schema.create(Type.STRING), null, null));    fields.add(new Field("string2", Schema.create(Type.STRING), null, null));    fields.add(new Field("bytes1", Schema.create(Type.BYTES), null, null));    fields.add(new Field("bytes2", Schema.create(Type.BYTES), null, null));    fields.add(new Field("int1", Schema.create(Type.INT), null, null));    fields.add(new Field("int2", Schema.create(Type.INT), null, null));    fields.add(new Field("long1", Schema.create(Type.LONG), null, null));    fields.add(new Field("long2", Schema.create(Type.LONG), null, null));    fields.add(new Field("float1", Schema.create(Type.FLOAT), null, null));    fields.add(new Field("float2", Schema.create(Type.FLOAT), null, null));    fields.add(new Field("double1", Schema.create(Type.DOUBLE), null, null));    fields.add(new Field("double2", Schema.create(Type.DOUBLE), null, null));    fields.add(new Field("boolean1", Schema.create(Type.BOOLEAN), null, null));    fields.add(new Field("boolean2", Schema.create(Type.BOOLEAN), null, null));    List<String> enumValues = new ArrayList<>();    enumValues.add("One");    enumValues.add("Two");    Schema enumSchema = Schema.createEnum("myEnum", null, null, enumValues);    fields.add(new Field("enum1", enumSchema, null, null));    fields.add(new Field("enum2", enumSchema, null, null));    Schema recordSchema = SchemaBuilder.record("aRecord").fields().requiredString("myString").endRecord();    fields.add(new Field("record1", recordSchema, null, null));    fields.add(new Field("record2", recordSchema, null, null));    Schema arraySchema = Schema.createArray(Schema.create(Type.STRING));    fields.add(new Field("array1", arraySchema, null, null));    fields.add(new Field("array2", arraySchema, null, null));    Schema mapSchema = Schema.createMap(Schema.create(Type.STRING));    fields.add(new Field("map1", mapSchema, null, null));    fields.add(new Field("map2", mapSchema, null, null));    Schema schema = Schema.createRecord("Foo", "test", "mytest", false);    schema.setFields(fields);    Record testRecord = new Record(schema);    testRecord.put("nullstring1", null);    testRecord.put("nullstring2", null);    String fortyTwo = "42";    testRecord.put("string1", fortyTwo);    testRecord.put("string2", fortyTwo);    testRecord.put("bytes1", 0x42);    testRecord.put("bytes2", 0x42);    testRecord.put("int1", 42);    testRecord.put("int2", 42);    testRecord.put("long1", 42L);    testRecord.put("long2", 42L);    testRecord.put("float1", 42F);    testRecord.put("float2", 42F);    testRecord.put("double1", 42D);    testRecord.put("double2", 42D);    testRecord.put("boolean1", true);    testRecord.put("boolean2", true);    testRecord.put("enum1", "One");    testRecord.put("enum2", "One");    GenericRecord record = new GenericData.Record(recordSchema);    record.put("myString", "42");    testRecord.put("record1", record);    testRecord.put("record2", record);    GenericArray<String> array = new GenericData.Array<>(1, arraySchema);    array.clear();    array.add("42");    testRecord.put("array1", array);    testRecord.put("array2", array);    Map<String, String> map = new HashMap<>();    map.put("42", "42");    testRecord.put("map1", map);    testRecord.put("map2", map);    String testString = testRecord.toString();    assertFalse("Record with duplicated values results in wrong 'toString()'", testString.contains("CIRCULAR REFERENCE"));}
0
public void testToStringRecursive() throws IOException
{    ReferenceManager manager = new ReferenceManager();    GenericData model = new GenericData();    model.addLogicalTypeConversion(manager.getTracker());    model.addLogicalTypeConversion(manager.getHandler());    Schema parentSchema = Schema.createRecord("Parent", null, null, false);    Schema placeholderSchema = Schema.createRecord("Placeholder", null, null, false);    List<Schema.Field> placeholderFields = new ArrayList<>();        placeholderFields.add(new Schema.Field("id", Schema.create(Schema.Type.LONG), null, null));    placeholderSchema.setFields(placeholderFields);    Referenceable idRef = new Referenceable("id");    Schema parentRefSchema = Schema.createUnion(Schema.create(Schema.Type.NULL), Schema.create(Schema.Type.LONG), idRef.addToSchema(placeholderSchema));    Reference parentRef = new Reference("parent");    List<Schema.Field> childFields = new ArrayList<>();    childFields.add(new Schema.Field("c", Schema.create(Schema.Type.STRING), null, null));    childFields.add(new Schema.Field("parent", parentRefSchema, null, null));    Schema childSchema = parentRef.addToSchema(Schema.createRecord("Child", null, null, false, childFields));    List<Schema.Field> parentFields = new ArrayList<>();    parentFields.add(new Schema.Field("id", Schema.create(Schema.Type.LONG), null, null));    parentFields.add(new Schema.Field("p", Schema.create(Schema.Type.STRING), null, null));    parentFields.add(new Schema.Field("child", childSchema, null, null));    parentSchema.setFields(parentFields);    Schema schema = idRef.addToSchema(parentSchema);    Record parent = new Record(schema);    parent.put("id", 1L);    parent.put("p", "parent data!");    Record child = new Record(childSchema);    child.put("c", "child data!");    child.put("parent", parent);    parent.put("child", child);    try {                assertNotNull(parent.toString());    } catch (StackOverflowError e) {        fail("StackOverflowError occurred");    }}
0
public void testGenericArrayPeek()
{    Schema elementSchema = SchemaBuilder.record("element").fields().requiredString("value").endRecord();    Schema arraySchema = Schema.createArray(elementSchema);    GenericRecord record = new GenericData.Record(elementSchema);    record.put("value", "string");    GenericArray<GenericRecord> list = new GenericData.Array<>(1, arraySchema);    list.add(record);    list.reset();    assertTrue(record == list.peek());    list.prune();    assertNull(list.peek());}
0
public void testWrite() throws IOException
{    String json = "{\"type\": \"record\", \"name\": \"r\", \"fields\": [" + "{ \"name\": \"f1\", \"type\": \"long\" }" + "]}";    Schema s = new Schema.Parser().parse(json);    GenericRecord r = new GenericData.Record(s);    r.put("f1", 100L);    ByteArrayOutputStream bao = new ByteArrayOutputStream();    GenericDatumWriter<GenericRecord> w = new GenericDatumWriter<>(s);    Encoder e = EncoderFactory.get().jsonEncoder(s, bao);    w.write(r, e);    e.flush();    Object o = new GenericDatumReader<GenericRecord>(s).read(null, DecoderFactory.get().jsonDecoder(s, new ByteArrayInputStream(bao.toByteArray())));    assertEquals(r, o);}
0
public void testArrayConcurrentModification() throws Exception
{    String json = "{\"type\": \"array\", \"items\": \"int\" }";    Schema s = new Schema.Parser().parse(json);    final GenericArray<Integer> a = new GenericData.Array<>(1, s);    ByteArrayOutputStream bao = new ByteArrayOutputStream();    final GenericDatumWriter<GenericArray<Integer>> w = new GenericDatumWriter<>(s);    CountDownLatch sizeWrittenSignal = new CountDownLatch(1);    CountDownLatch eltAddedSignal = new CountDownLatch(1);    final TestEncoder e = new TestEncoder(EncoderFactory.get().directBinaryEncoder(bao, null), sizeWrittenSignal, eltAddedSignal);        ExecutorService executor = Executors.newSingleThreadExecutor();    Future<Void> result = executor.submit(() -> {        w.write(a, e);        return null;    });    sizeWrittenSignal.await();        a.add(7);        eltAddedSignal.countDown();    try {        result.get();        fail("Expected ConcurrentModificationException");    } catch (ExecutionException ex) {        assertTrue(ex.getCause() instanceof ConcurrentModificationException);    }}
0
public void testMapConcurrentModification() throws Exception
{    String json = "{\"type\": \"map\", \"values\": \"int\" }";    Schema s = new Schema.Parser().parse(json);    final Map<String, Integer> m = new HashMap<>();    ByteArrayOutputStream bao = new ByteArrayOutputStream();    final GenericDatumWriter<Map<String, Integer>> w = new GenericDatumWriter<>(s);    CountDownLatch sizeWrittenSignal = new CountDownLatch(1);    CountDownLatch eltAddedSignal = new CountDownLatch(1);    final TestEncoder e = new TestEncoder(EncoderFactory.get().directBinaryEncoder(bao, null), sizeWrittenSignal, eltAddedSignal);        ExecutorService executor = Executors.newSingleThreadExecutor();    Future<Void> result = executor.submit(() -> {        w.write(m, e);        return null;    });    sizeWrittenSignal.await();        m.put("a", 7);        eltAddedSignal.countDown();    try {        result.get();        fail("Expected ConcurrentModificationException");    } catch (ExecutionException ex) {        assertTrue(ex.getCause() instanceof ConcurrentModificationException);    }}
0
public void writeArrayStart() throws IOException
{    e.writeArrayStart();    sizeWrittenSignal.countDown();    try {        eltAddedSignal.await();    } catch (InterruptedException e) {        }}
0
public void writeMapStart() throws IOException
{    e.writeMapStart();    sizeWrittenSignal.countDown();    try {        eltAddedSignal.await();    } catch (InterruptedException e) {        }}
0
public void flush() throws IOException
{    e.flush();}
0
public void writeNull() throws IOException
{    e.writeNull();}
0
public void writeBoolean(boolean b) throws IOException
{    e.writeBoolean(b);}
0
public void writeInt(int n) throws IOException
{    e.writeInt(n);}
0
public void writeLong(long n) throws IOException
{    e.writeLong(n);}
0
public void writeFloat(float f) throws IOException
{    e.writeFloat(f);}
0
public void writeDouble(double d) throws IOException
{    e.writeDouble(d);}
0
public void writeString(Utf8 utf8) throws IOException
{    e.writeString(utf8);}
0
public void writeBytes(ByteBuffer bytes) throws IOException
{    e.writeBytes(bytes);}
0
public void writeBytes(byte[] bytes, int start, int len) throws IOException
{    e.writeBytes(bytes, start, len);}
0
public void writeFixed(byte[] bytes, int start, int len) throws IOException
{    e.writeFixed(bytes, start, len);}
0
public void writeEnum(int en) throws IOException
{    e.writeEnum(en);}
0
public void setItemCount(long itemCount) throws IOException
{    e.setItemCount(itemCount);}
0
public void startItem() throws IOException
{    e.startItem();}
0
public void writeArrayEnd() throws IOException
{    e.writeArrayEnd();}
0
public void writeMapEnd() throws IOException
{    e.writeMapEnd();}
0
public void writeIndex(int unionIndex) throws IOException
{    e.writeIndex(unionIndex);}
0
public void writeDoesNotAllowStringForGenericEnum() throws IOException
{    final String json = "{\"type\": \"record\", \"name\": \"recordWithEnum\"," + "\"fields\": [ " + "{\"name\": \"field\", \"type\": " + "{\"type\": \"enum\", \"name\": \"enum\", \"symbols\": " + "[\"ONE\",\"TWO\",\"THREE\"] " + "}" + "}" + "]}";    Schema schema = new Schema.Parser().parse(json);    GenericRecord record = new GenericData.Record(schema);    record.put("field", "ONE");    ByteArrayOutputStream bao = new ByteArrayOutputStream();    GenericDatumWriter<GenericRecord> writer = new GenericDatumWriter<>(schema);    Encoder encoder = EncoderFactory.get().jsonEncoder(schema, bao);    writer.write(record, encoder);}
0
public void writeDoesNotAllowJavaEnumForGenericEnum() throws IOException
{    final String json = "{\"type\": \"record\", \"name\": \"recordWithEnum\"," + "\"fields\": [ " + "{\"name\": \"field\", \"type\": " + "{\"type\": \"enum\", \"name\": \"enum\", \"symbols\": " + "[\"ONE\",\"TWO\",\"THREE\"] " + "}" + "}" + "]}";    Schema schema = new Schema.Parser().parse(json);    GenericRecord record = new GenericData.Record(schema);    record.put("field", AnEnum.ONE);    ByteArrayOutputStream bao = new ByteArrayOutputStream();    GenericDatumWriter<GenericRecord> writer = new GenericDatumWriter<>(schema);    Encoder encoder = EncoderFactory.get().jsonEncoder(schema, bao);    writer.write(record, encoder);}
0
public void writeFieldWithDefaultWithExplicitNullDefaultInSchema() throws Exception
{    Schema schema = schemaWithExplicitNullDefault();    GenericRecord record = createRecordWithDefaultField(schema);    writeObject(schema, record);}
0
public void writeFieldWithDefaultWithoutExplicitNullDefaultInSchema() throws Exception
{    Schema schema = schemaWithoutExplicitNullDefault();    GenericRecord record = createRecordWithDefaultField(schema);    writeObject(schema, record);}
0
private Schema schemaWithExplicitNullDefault()
{    String schema = "{\"type\":\"record\",\"name\":\"my_record\",\"namespace\":\"mytest.namespace\",\"doc\":\"doc\"," + "\"fields\":[{\"name\":\"f\",\"type\":[\"null\",\"string\"],\"doc\":\"field doc doc\", " + "\"default\":null}]}";    return new Schema.Parser().parse(schema);}
0
private Schema schemaWithoutExplicitNullDefault()
{    String schema = "{\"type\":\"record\",\"name\":\"my_record\",\"namespace\":\"mytest.namespace\",\"doc\":\"doc\"," + "\"fields\":[{\"name\":\"f\",\"type\":[\"null\",\"string\"],\"doc\":\"field doc doc\"}]}";    return new Schema.Parser().parse(schema);}
0
private void writeObject(Schema schema, GenericRecord datum) throws Exception
{    BinaryEncoder encoder = EncoderFactory.get().binaryEncoder(new ByteArrayOutputStream(), null);    GenericDatumWriter<GenericData.Record> writer = new GenericDatumWriter<>(schema);    writer.write(schema, datum, encoder);}
0
private GenericRecord createRecordWithDefaultField(Schema schema)
{    GenericRecord record = new GenericData.Record(schema);    record.put("f", schema.getField("f").defaultVal());    return record;}
0
public static void addLogicalTypes()
{    GENERIC.addLogicalTypeConversion(new Conversions.DecimalConversion());    GENERIC.addLogicalTypeConversion(new Conversions.UUIDConversion());    GENERIC.addLogicalTypeConversion(new TimeConversions.LocalTimestampMicrosConversion());    GENERIC.addLogicalTypeConversion(new TimeConversions.LocalTimestampMillisConversion());}
0
public void testReadUUID() throws IOException
{    Schema uuidSchema = Schema.create(Schema.Type.STRING);    LogicalTypes.uuid().addToSchema(uuidSchema);    UUID u1 = UUID.randomUUID();    UUID u2 = UUID.randomUUID();    List<UUID> expected = Arrays.asList(u1, u2);    File test = write(Schema.create(Schema.Type.STRING), u1.toString(), u2.toString());    Assert.assertEquals("Should convert Strings to UUIDs", expected, read(GENERIC.createDatumReader(uuidSchema), test));}
0
public void testWriteUUID() throws IOException
{    Schema stringSchema = Schema.create(Schema.Type.STRING);    stringSchema.addProp(GenericData.STRING_PROP, "String");    Schema uuidSchema = Schema.create(Schema.Type.STRING);    LogicalTypes.uuid().addToSchema(uuidSchema);    UUID u1 = UUID.randomUUID();    UUID u2 = UUID.randomUUID();    List<String> expected = Arrays.asList(u1.toString(), u2.toString());    File test = write(GENERIC, uuidSchema, u1, u2);    Assert.assertEquals("Should read UUIDs as Strings", expected, read(GenericData.get().createDatumReader(stringSchema), test));}
0
public void testWriteNullableUUID() throws IOException
{    Schema stringSchema = Schema.create(Schema.Type.STRING);    stringSchema.addProp(GenericData.STRING_PROP, "String");    Schema nullableStringSchema = Schema.createUnion(Schema.create(Schema.Type.NULL), stringSchema);    Schema uuidSchema = Schema.create(Schema.Type.STRING);    LogicalTypes.uuid().addToSchema(uuidSchema);    Schema nullableUuidSchema = Schema.createUnion(Schema.create(Schema.Type.NULL), uuidSchema);    UUID u1 = UUID.randomUUID();    UUID u2 = UUID.randomUUID();    List<String> expected = Arrays.asList(u1.toString(), u2.toString());    File test = write(GENERIC, nullableUuidSchema, u1, u2);    Assert.assertEquals("Should read UUIDs as Strings", expected, read(GenericData.get().createDatumReader(nullableStringSchema), test));}
0
public void testReadDecimalFixed() throws IOException
{    LogicalType decimal = LogicalTypes.decimal(9, 2);    Schema fixedSchema = Schema.createFixed("aFixed", null, null, 4);    Schema decimalSchema = decimal.addToSchema(Schema.createFixed("aFixed", null, null, 4));    BigDecimal d1 = new BigDecimal("-34.34");    BigDecimal d2 = new BigDecimal("117230.00");    List<BigDecimal> expected = Arrays.asList(d1, d2);    Conversion<BigDecimal> conversion = new Conversions.DecimalConversion();        GenericFixed d1fixed = conversion.toFixed(d1, fixedSchema, decimal);    GenericFixed d2fixed = conversion.toFixed(d2, fixedSchema, decimal);    File test = write(fixedSchema, d1fixed, d2fixed);    Assert.assertEquals("Should convert fixed to BigDecimals", expected, read(GENERIC.createDatumReader(decimalSchema), test));}
0
public void testWriteDecimalFixed() throws IOException
{    LogicalType decimal = LogicalTypes.decimal(9, 2);    Schema fixedSchema = Schema.createFixed("aFixed", null, null, 4);    Schema decimalSchema = decimal.addToSchema(Schema.createFixed("aFixed", null, null, 4));    BigDecimal d1 = new BigDecimal("-34.34");    BigDecimal d2 = new BigDecimal("117230.00");    Conversion<BigDecimal> conversion = new Conversions.DecimalConversion();    GenericFixed d1fixed = conversion.toFixed(d1, fixedSchema, decimal);    GenericFixed d2fixed = conversion.toFixed(d2, fixedSchema, decimal);    List<GenericFixed> expected = Arrays.asList(d1fixed, d2fixed);    File test = write(GENERIC, decimalSchema, d1, d2);    Assert.assertEquals("Should read BigDecimals as fixed", expected, read(GenericData.get().createDatumReader(fixedSchema), test));}
0
public void testReadDecimalBytes() throws IOException
{    LogicalType decimal = LogicalTypes.decimal(9, 2);    Schema bytesSchema = Schema.create(Schema.Type.BYTES);    Schema decimalSchema = decimal.addToSchema(Schema.create(Schema.Type.BYTES));    BigDecimal d1 = new BigDecimal("-34.34");    BigDecimal d2 = new BigDecimal("117230.00");    List<BigDecimal> expected = Arrays.asList(d1, d2);    Conversion<BigDecimal> conversion = new Conversions.DecimalConversion();        ByteBuffer d1bytes = conversion.toBytes(d1, bytesSchema, decimal);    ByteBuffer d2bytes = conversion.toBytes(d2, bytesSchema, decimal);    File test = write(bytesSchema, d1bytes, d2bytes);    Assert.assertEquals("Should convert bytes to BigDecimals", expected, read(GENERIC.createDatumReader(decimalSchema), test));}
0
public void testWriteDecimalBytes() throws IOException
{    LogicalType decimal = LogicalTypes.decimal(9, 2);    Schema bytesSchema = Schema.create(Schema.Type.BYTES);    Schema decimalSchema = decimal.addToSchema(Schema.create(Schema.Type.BYTES));    BigDecimal d1 = new BigDecimal("-34.34");    BigDecimal d2 = new BigDecimal("117230.00");    Conversion<BigDecimal> conversion = new Conversions.DecimalConversion();        ByteBuffer d1bytes = conversion.toBytes(d1, bytesSchema, decimal);    ByteBuffer d2bytes = conversion.toBytes(d2, bytesSchema, decimal);    List<ByteBuffer> expected = Arrays.asList(d1bytes, d2bytes);    File test = write(GENERIC, decimalSchema, d1bytes, d2bytes);    Assert.assertEquals("Should read BigDecimals as bytes", expected, read(GenericData.get().createDatumReader(bytesSchema), test));}
0
private List<D> read(DatumReader<D> reader, File file) throws IOException
{    List<D> data = new ArrayList<>();    try (FileReader<D> fileReader = new DataFileReader<>(file, reader)) {        for (D datum : fileReader) {            data.add(datum);        }    }    return data;}
0
private File write(Schema schema, D... data) throws IOException
{    return write(GenericData.get(), schema, data);}
0
private File write(GenericData model, Schema schema, D... data) throws IOException
{    File file = temp.newFile();    DatumWriter<D> writer = model.createDatumWriter(schema);    try (DataFileWriter<D> fileWriter = new DataFileWriter<>(writer)) {        fileWriter.create(schema, file);        for (D datum : data) {            fileWriter.append(datum);        }    }    return file;}
0
public void testCopyUuid()
{    testCopy(LogicalTypes.uuid().addToSchema(Schema.create(Schema.Type.STRING)), UUID.randomUUID(), GENERIC);}
0
public void testCopyUuidRaw()
{    testCopy(    LogicalTypes.uuid().addToSchema(Schema.create(Schema.Type.STRING)),     UUID.randomUUID().toString(),     GenericData.get());}
0
public void testCopyDecimal()
{    testCopy(LogicalTypes.decimal(9, 2).addToSchema(Schema.create(Schema.Type.BYTES)), new BigDecimal("-34.34"), GENERIC);}
0
public void testCopyDecimalRaw()
{    testCopy(LogicalTypes.decimal(9, 2).addToSchema(Schema.create(Schema.Type.BYTES)), ByteBuffer.wrap(new BigDecimal("-34.34").unscaledValue().toByteArray()),     GenericData.get());}
0
private void testCopy(Schema schema, Object value, GenericData model)
{        checkCopy(value, model.deepCopy(schema, value), false);        Schema recordSchema = Schema.createRecord("X", "", "test", false);    List<Schema.Field> fields = new ArrayList<>();    fields.add(new Schema.Field("x", schema, "", null));    recordSchema.setFields(fields);    GenericRecordBuilder builder = new GenericRecordBuilder(recordSchema);    builder.set("x", value);    GenericData.Record record = builder.build();    checkCopy(record, model.deepCopy(recordSchema, record), true);        Schema arraySchema = Schema.createArray(schema);    ArrayList array = new ArrayList(Collections.singletonList(value));    checkCopy(array, model.deepCopy(arraySchema, array), true);        Schema recordArraySchema = Schema.createArray(recordSchema);    ArrayList recordArray = new ArrayList(Collections.singletonList(record));    checkCopy(recordArray, model.deepCopy(recordArraySchema, recordArray), true);}
0
private void checkCopy(Object original, Object copy, boolean notSame)
{    if (notSame)        Assert.assertNotSame(original, copy);    Assert.assertEquals(original, copy);}
0
public void testReadLocalTimestampMillis() throws IOException
{    LogicalType timestamp = LogicalTypes.localTimestampMillis();    Schema longSchema = Schema.create(Schema.Type.LONG);    Schema timestampSchema = timestamp.addToSchema(Schema.create(Schema.Type.LONG));    LocalDateTime i1 = LocalDateTime.of(1986, 06, 26, 12, 07, 11, 42000000);    LocalDateTime i2 = LocalDateTime.ofInstant(Instant.ofEpochMilli(0), ZoneOffset.UTC);    List<LocalDateTime> expected = Arrays.asList(i1, i2);    Conversion<LocalDateTime> conversion = new TimeConversions.LocalTimestampMillisConversion();        Long i1long = conversion.toLong(i1, longSchema, timestamp);    Long i2long = 0L;    File test = write(longSchema, i1long, i2long);    Assert.assertEquals("Should convert long to LocalDateTime", expected, read(GENERIC.createDatumReader(timestampSchema), test));}
0
public void testWriteLocalTimestampMillis() throws IOException
{    LogicalType timestamp = LogicalTypes.localTimestampMillis();    Schema longSchema = Schema.create(Schema.Type.LONG);    Schema timestampSchema = timestamp.addToSchema(Schema.create(Schema.Type.LONG));    LocalDateTime i1 = LocalDateTime.of(1986, 06, 26, 12, 07, 11, 42000000);    LocalDateTime i2 = LocalDateTime.ofInstant(Instant.ofEpochMilli(0), ZoneOffset.UTC);    Conversion<LocalDateTime> conversion = new TimeConversions.LocalTimestampMillisConversion();    Long d1long = conversion.toLong(i1, longSchema, timestamp);    Long d2long = 0L;    List<Long> expected = Arrays.asList(d1long, d2long);    File test = write(GENERIC, timestampSchema, i1, i2);    Assert.assertEquals("Should read LocalDateTime as longs", expected, read(GenericData.get().createDatumReader(timestampSchema), test));}
0
public void testReadLocalTimestampMicros() throws IOException
{    LogicalType timestamp = LogicalTypes.localTimestampMicros();    Schema longSchema = Schema.create(Schema.Type.LONG);    Schema timestampSchema = timestamp.addToSchema(Schema.create(Schema.Type.LONG));    LocalDateTime i1 = LocalDateTime.of(1986, 06, 26, 12, 07, 11, 420000);    LocalDateTime i2 = LocalDateTime.ofInstant(Instant.ofEpochSecond(0, 4000), ZoneOffset.UTC);    List<LocalDateTime> expected = Arrays.asList(i1, i2);    Conversion<LocalDateTime> conversion = new TimeConversions.LocalTimestampMicrosConversion();        Long i1long = conversion.toLong(i1, longSchema, timestamp);    Long i2long = conversion.toLong(i2, longSchema, timestamp);    File test = write(longSchema, i1long, i2long);    Assert.assertEquals("Should convert long to LocalDateTime", expected, read(GENERIC.createDatumReader(timestampSchema), test));}
0
public void testWriteLocalTimestampMicros() throws IOException
{    LogicalType timestamp = LogicalTypes.localTimestampMicros();    Schema longSchema = Schema.create(Schema.Type.LONG);    Schema timestampSchema = timestamp.addToSchema(Schema.create(Schema.Type.LONG));    LocalDateTime i1 = LocalDateTime.of(1986, 06, 26, 12, 07, 11, 420000);    LocalDateTime i2 = LocalDateTime.ofInstant(Instant.ofEpochSecond(0, 4000), ZoneOffset.UTC);    Conversion<LocalDateTime> conversion = new TimeConversions.LocalTimestampMicrosConversion();    Long d1long = conversion.toLong(i1, longSchema, timestamp);    Long d2long = conversion.toLong(i2, longSchema, timestamp);    List<Long> expected = Arrays.asList(d1long, d2long);    File test = write(GENERIC, timestampSchema, i1, i2);    Assert.assertEquals("Should read LocalDateTime as longs", expected, read(GenericData.get().createDatumReader(timestampSchema), test));}
0
public void testGenericBuilder()
{    Schema schema = recordSchema();    GenericRecordBuilder builder = new GenericRecordBuilder(schema);        for (Field field : schema.getFields()) {        Assert.assertFalse("RecordBuilder should not have field " + field.name(), builder.has(field.name()));        Assert.assertNull("Field " + field.name() + " should be null", builder.get(field.name()));    }        builder.set("intField", 1);    List<String> anArray = Arrays.asList("one", "two", "three");    builder.set("anArray", anArray);    Assert.assertTrue("anArray should be set", builder.has("anArray"));    Assert.assertEquals(anArray, builder.get("anArray"));    Assert.assertFalse("id should not be set", builder.has("id"));    Assert.assertNull(builder.get("id"));        Record record = builder.build();    Assert.assertEquals(1, record.get("intField"));    Assert.assertEquals(anArray, record.get("anArray"));    Assert.assertNotNull(record.get("id"));    Assert.assertEquals("0", record.get("id").toString());        Assert.assertEquals(builder, new GenericRecordBuilder(builder));    Assert.assertEquals(record, new GenericRecordBuilder(record).build());        builder.clear("intField");    Assert.assertFalse(builder.has("intField"));    Assert.assertNull(builder.get("intField"));}
0
public void attemptToSetNonNullableFieldToNull()
{    new GenericRecordBuilder(recordSchema()).set("intField", null);}
0
public void buildWithoutSettingRequiredFields1()
{    new GenericRecordBuilder(recordSchema()).build();}
0
public void buildWithoutSettingRequiredFields2()
{    try {        new GenericRecordBuilder(recordSchema()).set("anArray", Collections.singletonList("one")).build();        Assert.fail("Should have thrown " + AvroRuntimeException.class.getCanonicalName());    } catch (AvroRuntimeException e) {        Assert.assertTrue(e.getMessage().contains("intField"));    }}
0
private static Schema recordSchema()
{    List<Field> fields = new ArrayList<>();    fields.add(new Field("id", Schema.create(Type.STRING), null, "0"));    fields.add(new Field("intField", Schema.create(Type.INT), null, null));    fields.add(new Field("anArray", Schema.createArray(Schema.create(Type.STRING)), null, null));    fields.add(new Field("optionalInt", Schema.createUnion(Arrays.asList(Schema.create(Type.NULL), Schema.create(Type.INT))), null, Schema.NULL_VALUE));    Schema schema = Schema.createRecord("Foo", "test", "mytest", false);    schema.setFields(fields);    return schema;}
0
public void write(ByteBuffer bytes) throws IOException
{    encodeLong(bytes.remaining(), out);    out.write(bytes.array(), bytes.position(), bytes.remaining());}
0
public void flush() throws IOException
{    if (out != null) {        out.flush();    }}
0
public void writeNull() throws IOException
{}
0
public void writeBoolean(boolean b) throws IOException
{    out.write(b ? 1 : 0);}
0
public void writeInt(int n) throws IOException
{    encodeLong(n, out);}
0
public void writeLong(long n) throws IOException
{    encodeLong(n, out);}
0
public void writeFloat(float f) throws IOException
{    encodeFloat(f, out);}
0
public void writeDouble(double d) throws IOException
{    encodeDouble(d, out);}
0
public void writeString(Utf8 utf8) throws IOException
{    encodeString(utf8.getBytes(), 0, utf8.getByteLength());}
0
public void writeString(String string) throws IOException
{    byte[] bytes = Utf8.getBytesFor(string);    encodeString(bytes, 0, bytes.length);}
0
private void encodeString(byte[] bytes, int offset, int length) throws IOException
{    encodeLong(length, out);    out.write(bytes, offset, length);}
0
public void writeBytes(ByteBuffer bytes) throws IOException
{    byteWriter.write(bytes);}
0
public void writeBytes(byte[] bytes, int start, int len) throws IOException
{    encodeLong(len, out);    out.write(bytes, start, len);}
0
public void writeFixed(byte[] bytes, int start, int len) throws IOException
{    out.write(bytes, start, len);}
0
public void writeEnum(int e) throws IOException
{    encodeLong(e, out);}
0
public void writeArrayStart() throws IOException
{}
0
public void setItemCount(long itemCount) throws IOException
{    if (itemCount > 0) {        writeLong(itemCount);    }}
0
public void startItem() throws IOException
{}
0
public void writeArrayEnd() throws IOException
{    encodeLong(0, out);}
0
public void writeMapStart() throws IOException
{}
0
public void writeMapEnd() throws IOException
{    encodeLong(0, out);}
0
public void writeIndex(int unionIndex) throws IOException
{    encodeLong(unionIndex, out);}
0
protected static void encodeLong(long n, OutputStream o) throws IOException
{        n = (n << 1) ^ (n >> 63);    while ((n & ~0x7F) != 0) {        o.write((byte) ((n & 0x7f) | 0x80));        n >>>= 7;    }    o.write((byte) n);}
0
protected static void encodeFloat(float f, OutputStream o) throws IOException
{    long bits = Float.floatToRawIntBits(f);    o.write((int) (bits) & 0xFF);    o.write((int) (bits >> 8) & 0xFF);    o.write((int) (bits >> 16) & 0xFF);    o.write((int) (bits >> 24) & 0xFF);}
0
protected static void encodeDouble(double d, OutputStream o) throws IOException
{    long bits = Double.doubleToRawLongBits(d);    o.write((int) (bits) & 0xFF);    o.write((int) (bits >> 8) & 0xFF);    o.write((int) (bits >> 16) & 0xFF);    o.write((int) (bits >> 24) & 0xFF);    o.write((int) (bits >> 32) & 0xFF);    o.write((int) (bits >> 40) & 0xFF);    o.write((int) (bits >> 48) & 0xFF);    o.write((int) (bits >> 56) & 0xFF);}
0
public void testSomeMethod() throws IOException
{    Schema schema = new Schema.Parser().parse(SCHEMA);    Symbol root = new ResolvingGrammarGenerator().generate(schema, schema);    validateNonNull(root, new HashSet<>());}
0
private static void validateNonNull(final Symbol symb, Set<Symbol> seen)
{    if (seen.contains(symb)) {        return;    } else {        seen.add(symb);    }    if (symb.production != null) {        for (Symbol s : symb.production) {            if (s == null) {                fail("invalid parsing tree should not contain nulls");            }            if (s.kind != Symbol.Kind.ROOT) {                validateNonNull(s, seen);            }        }    }}
0
public void test() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    EncoderFactory factory = EncoderFactory.get();    Encoder e = factory.validatingEncoder(schema, factory.binaryEncoder(baos, null));    ResolvingGrammarGenerator.encode(e, schema, data);    e.flush();}
0
public void testRecordMissingRequiredFieldError() throws Exception
{    Schema schemaWithoutField = SchemaBuilder.record("MyRecord").namespace("ns").fields().name("field1").type().stringType().noDefault().endRecord();    Schema schemaWithField = SchemaBuilder.record("MyRecord").namespace("ns").fields().name("field1").type().stringType().noDefault().name("field2").type().stringType().noDefault().endRecord();    GenericData.Record record = new GenericRecordBuilder(schemaWithoutField).set("field1", "someValue").build();    byte[] data = writeRecord(schemaWithoutField, record);    try {        readRecord(schemaWithField, data);        Assert.fail("Expected exception not thrown");    } catch (AvroTypeException typeException) {        Assert.assertEquals("Incorrect exception message", "Found ns.MyRecord, expecting ns.MyRecord, missing required field field2", typeException.getMessage());    }}
0
public static Collection<Object[]> data()
{    Collection<Object[]> ret = Arrays.asList(new Object[][] { { "{ \"type\": \"record\", \"name\": \"r\", \"fields\": [ " + " { \"name\" : \"f1\", \"type\": \"int\" }, " + " { \"name\" : \"f2\", \"type\": \"float\" } " + "] } }", "{ \"f2\": 10.4, \"f1\": 10 } " }, { "{ \"type\": \"enum\", \"name\": \"e\", \"symbols\": " + "[ \"s1\", \"s2\"] } }", " \"s1\" " }, { "{ \"type\": \"enum\", \"name\": \"e\", \"symbols\": " + "[ \"s1\", \"s2\"] } }", " \"s2\" " }, { "{ \"type\": \"fixed\", \"name\": \"f\", \"size\": 10 }", "\"hello\"" }, { "{ \"type\": \"array\", \"items\": \"int\" }", "[ 10, 20, 30 ]" }, { "{ \"type\": \"map\", \"values\": \"int\" }", "{ \"k1\": 10, \"k3\": 20, \"k3\": 30 }" }, { "[ \"int\", \"long\" ]", "10" }, { "\"string\"", "\"hello\"" }, { "\"bytes\"", "\"hello\"" }, { "\"int\"", "10" }, { "\"long\"", "10" }, { "\"float\"", "10.0" }, { "\"double\"", "10.0" }, { "\"boolean\"", "true" }, { "\"boolean\"", "false" }, { "\"null\"", "null" } });    return ret;}
0
private byte[] writeRecord(Schema schema, GenericData.Record record) throws Exception
{    ByteArrayOutputStream byteStream = new ByteArrayOutputStream();    GenericDatumWriter<GenericData.Record> datumWriter = new GenericDatumWriter<>(schema);    try (DataFileWriter<GenericData.Record> writer = new DataFileWriter<>(datumWriter)) {        writer.create(schema, byteStream);        writer.append(record);    }    return byteStream.toByteArray();}
0
private GenericData.Record readRecord(Schema schema, byte[] data) throws Exception
{    ByteArrayInputStream byteStream = new ByteArrayInputStream(data);    GenericDatumReader<GenericData.Record> datumReader = new GenericDatumReader<>(schema);    try (DataFileStream<GenericData.Record> reader = new DataFileStream<>(byteStream, datumReader)) {        return reader.next();    }}
0
public void testFixed() throws java.io.IOException
{    new ResolvingGrammarGenerator().generate(Schema.createFixed("MyFixed", null, null, 10), Schema.create(Schema.Type.BYTES));    new ResolvingGrammarGenerator().generate(Schema.create(Schema.Type.BYTES), Schema.createFixed("MyFixed", null, null, 10));}
0
public void testUnionResolutionNoStructureMatch() throws Exception
{        Schema read = Schema.createUnion(Arrays.asList(Schema.create(Schema.Type.NULL), point3dNoDefault));    new SchemaValidatorBuilder().canBeReadStrategy().validateAll().validate(point2dFullname, Collections.singletonList(read));}
0
public void testUnionResolutionFirstStructureMatch2d() throws Exception
{        Schema read = Schema.createUnion(Arrays.asList(Schema.create(Schema.Type.NULL), point3dNoDefault, point2d, point3d));    Symbol grammar = new ResolvingGrammarGenerator().generate(point2dFullname, read);    Assert.assertTrue(grammar.production[1] instanceof Symbol.UnionAdjustAction);    Symbol.UnionAdjustAction action = (Symbol.UnionAdjustAction) grammar.production[1];    Assert.assertEquals(2, action.rindex);}
0
public void testUnionResolutionFirstStructureMatch3d() throws Exception
{        Schema read = Schema.createUnion(Arrays.asList(Schema.create(Schema.Type.NULL), point3dNoDefault, point3d, point2d));    Symbol grammar = new ResolvingGrammarGenerator().generate(point2dFullname, read);    Assert.assertTrue(grammar.production[1] instanceof Symbol.UnionAdjustAction);    Symbol.UnionAdjustAction action = (Symbol.UnionAdjustAction) grammar.production[1];    Assert.assertEquals(2, action.rindex);}
0
public void testUnionResolutionNamedStructureMatch() throws Exception
{        Schema read = Schema.createUnion(Arrays.asList(Schema.create(Schema.Type.NULL), point2d, point3dMatchName, point3d));    Symbol grammar = new ResolvingGrammarGenerator().generate(point2dFullname, read);    Assert.assertTrue(grammar.production[1] instanceof Symbol.UnionAdjustAction);    Symbol.UnionAdjustAction action = (Symbol.UnionAdjustAction) grammar.production[1];    Assert.assertEquals(2, action.rindex);}
0
public void testUnionResolutionFullNameMatch() throws Exception
{        Schema read = Schema.createUnion(Arrays.asList(Schema.create(Schema.Type.NULL), point2d, point3dMatchName, point3d, point2dFullname));    Symbol grammar = new ResolvingGrammarGenerator().generate(point2dFullname, read);    Assert.assertTrue(grammar.production[1] instanceof Symbol.UnionAdjustAction);    Symbol.UnionAdjustAction action = (Symbol.UnionAdjustAction) grammar.production[1];    Assert.assertEquals(4, action.rindex);}
0
public static Collection<Object[]> data()
{    return Arrays.asList(new Object[][] { { true }, { false } });}
0
private Decoder newDecoderWithNoData() throws IOException
{    return newDecoder(new byte[0]);}
0
private Decoder newDecoder(byte[] bytes, int start, int len) throws IOException
{    return factory.binaryDecoder(bytes, start, len, null);}
0
private Decoder newDecoder(InputStream in)
{    if (useDirect) {        return factory.directBinaryDecoder(in, null);    } else {        return factory.binaryDecoder(in, null);    }}
0
private Decoder newDecoder(byte[] bytes) throws IOException
{    return factory.binaryDecoder(bytes, null);}
0
public void testEOFBoolean() throws IOException
{    newDecoderWithNoData().readBoolean();}
0
public void testEOFInt() throws IOException
{    newDecoderWithNoData().readInt();}
0
public void testEOFLong() throws IOException
{    newDecoderWithNoData().readLong();}
0
public void testEOFFloat() throws IOException
{    newDecoderWithNoData().readFloat();}
0
public void testEOFDouble() throws IOException
{    newDecoderWithNoData().readDouble();}
0
public void testEOFBytes() throws IOException
{    newDecoderWithNoData().readBytes(null);}
0
public void testEOFString() throws IOException
{    newDecoderWithNoData().readString(new Utf8("a"));}
0
public void testEOFFixed() throws IOException
{    newDecoderWithNoData().readFixed(new byte[1]);}
0
public void testEOFEnum() throws IOException
{    newDecoderWithNoData().readEnum();}
0
public void testReuse() throws IOException
{    ByteBufferOutputStream bbo1 = new ByteBufferOutputStream();    ByteBufferOutputStream bbo2 = new ByteBufferOutputStream();    byte[] b1 = new byte[] { 1, 2 };    BinaryEncoder e1 = e_factory.binaryEncoder(bbo1, null);    e1.writeBytes(b1);    e1.flush();    BinaryEncoder e2 = e_factory.binaryEncoder(bbo2, null);    e2.writeBytes(b1);    e2.flush();    DirectBinaryDecoder d = new DirectBinaryDecoder(new ByteBufferInputStream(bbo1.getBufferList()));    ByteBuffer bb1 = d.readBytes(null);    Assert.assertEquals(b1.length, bb1.limit() - bb1.position());    d.configure(new ByteBufferInputStream(bbo2.getBufferList()));    ByteBuffer bb2 = d.readBytes(null);    Assert.assertEquals(b1.length, bb2.limit() - bb2.position());}
0
public static void generateData() throws IOException
{    int seed = (int) System.currentTimeMillis();        String jsonSchema = "{\"type\": \"record\", \"name\": \"Test\", \"fields\": [" + "{\"name\":\"intField\", \"type\":\"int\"}," + "{\"name\":\"bytesField\", \"type\":\"bytes\"}," + "{\"name\":\"booleanField\", \"type\":\"boolean\"}," + "{\"name\":\"stringField\", \"type\":\"string\"}," + "{\"name\":\"floatField\", \"type\":\"float\"}," + "{\"name\":\"doubleField\", \"type\":\"double\"}," + "{\"name\":\"arrayField\", \"type\": " + "{\"type\":\"array\", \"items\":\"boolean\"}}," + "{\"name\":\"longField\", \"type\":\"long\"}]}";    schema = new Schema.Parser().parse(jsonSchema);    GenericDatumWriter<Object> writer = new GenericDatumWriter<>();    writer.setSchema(schema);    ByteArrayOutputStream baos = new ByteArrayOutputStream(8192);    BinaryEncoder encoder = e_factory.binaryEncoder(baos, null);    for (Object datum : new RandomData(schema, count, seed)) {        writer.write(datum, encoder);        records.add(datum);    }    encoder.flush();    data = baos.toByteArray();}
0
public void testDecodeFromSources() throws IOException
{    GenericDatumReader<Object> reader = new GenericDatumReader<>();    reader.setSchema(schema);    ByteArrayInputStream is = new ByteArrayInputStream(data);    ByteArrayInputStream is2 = new ByteArrayInputStream(data);    ByteArrayInputStream is3 = new ByteArrayInputStream(data);    Decoder fromInputStream = newDecoder(is);    Decoder fromArray = newDecoder(data);    byte[] data2 = new byte[data.length + 30];    Arrays.fill(data2, (byte) 0xff);    System.arraycopy(data, 0, data2, 15, data.length);    Decoder fromOffsetArray = newDecoder(data2, 15, data.length);    BinaryDecoder initOnInputStream = factory.binaryDecoder(new byte[50], 0, 30, null);    initOnInputStream = factory.binaryDecoder(is2, initOnInputStream);    BinaryDecoder initOnArray = factory.binaryDecoder(is3, null);    initOnArray = factory.binaryDecoder(data, 0, data.length, initOnArray);    for (Object datum : records) {        Assert.assertEquals("InputStream based BinaryDecoder result does not match", datum, reader.read(null, fromInputStream));        Assert.assertEquals("Array based BinaryDecoder result does not match", datum, reader.read(null, fromArray));        Assert.assertEquals("offset Array based BinaryDecoder result does not match", datum, reader.read(null, fromOffsetArray));        Assert.assertEquals("InputStream initialized BinaryDecoder result does not match", datum, reader.read(null, initOnInputStream));        Assert.assertEquals("Array initialized BinaryDecoder result does not match", datum, reader.read(null, initOnArray));    }}
0
public void testInputStreamProxy() throws IOException
{    Decoder d = newDecoder(data);    if (d instanceof BinaryDecoder) {        BinaryDecoder bd = (BinaryDecoder) d;        InputStream test = bd.inputStream();        InputStream check = new ByteArrayInputStream(data);        validateInputStreamReads(test, check);        bd = factory.binaryDecoder(data, bd);        test = bd.inputStream();        check = new ByteArrayInputStream(data);        validateInputStreamSkips(test, check);                bd = factory.binaryDecoder(new ByteArrayInputStream(data), bd);        test = bd.inputStream();        check = new ByteArrayInputStream(data);        validateInputStreamReads(test, check);        bd = factory.binaryDecoder(new ByteArrayInputStream(data), bd);        test = bd.inputStream();        check = new ByteArrayInputStream(data);        validateInputStreamSkips(test, check);    }}
0
public void testInputStreamProxyDetached() throws IOException
{    Decoder d = newDecoder(data);    if (d instanceof BinaryDecoder) {        BinaryDecoder bd = (BinaryDecoder) d;        InputStream test = bd.inputStream();        InputStream check = new ByteArrayInputStream(data);                factory.binaryDecoder(new byte[56], null);        InputStream bad = bd.inputStream();        InputStream check2 = new ByteArrayInputStream(data);        validateInputStreamReads(test, check);        Assert.assertFalse(bad.read() == check2.read());    }}
0
public void testInputStreamPartiallyUsed() throws IOException
{    BinaryDecoder bd = factory.binaryDecoder(new ByteArrayInputStream(data), null);    InputStream test = bd.inputStream();    InputStream check = new ByteArrayInputStream(data);        try {        Assert.assertFalse(bd.isEnd());    } catch (UnsupportedOperationException e) {                if (bd.getClass() != DirectBinaryDecoder.class) {            throw e;        }    }        bd.readFloat();        check.skip(4);    validateInputStreamReads(test, check);}
0
private void validateInputStreamReads(InputStream test, InputStream check) throws IOException
{    byte[] bt = new byte[7];    byte[] bc = new byte[7];    while (true) {        int t = test.read();        int c = check.read();        Assert.assertEquals(c, t);        if (-1 == t)            break;        t = test.read(bt);        c = check.read(bc);        Assert.assertEquals(c, t);        Assert.assertArrayEquals(bt, bc);        if (-1 == t)            break;        t = test.read(bt, 1, 4);        c = check.read(bc, 1, 4);        Assert.assertEquals(c, t);        Assert.assertArrayEquals(bt, bc);        if (-1 == t)            break;    }    Assert.assertEquals(0, test.skip(5));    Assert.assertEquals(0, test.available());    Assert.assertFalse(test.getClass() != ByteArrayInputStream.class && test.markSupported());    test.close();}
0
private void validateInputStreamSkips(InputStream test, InputStream check) throws IOException
{    while (true) {        long t2 = test.skip(19);        long c2 = check.skip(19);        Assert.assertEquals(c2, t2);        if (0 == t2)            break;    }    Assert.assertEquals(-1, test.read());}
0
public void testBadIntEncoding() throws IOException
{    byte[] badint = new byte[5];    Arrays.fill(badint, (byte) 0xff);    Decoder bd = factory.binaryDecoder(badint, null);    String message = "";    try {        bd.readInt();    } catch (IOException ioe) {        message = ioe.getMessage();    }    Assert.assertEquals("Invalid int encoding", message);}
0
public void testBadLongEncoding() throws IOException
{    byte[] badint = new byte[10];    Arrays.fill(badint, (byte) 0xff);    Decoder bd = factory.binaryDecoder(badint, null);    String message = "";    try {        bd.readLong();    } catch (IOException ioe) {        message = ioe.getMessage();    }    Assert.assertEquals("Invalid long encoding", message);}
0
public void testNegativeLengthEncoding() throws IOException
{    byte[] bad = new byte[] { (byte) 1 };    Decoder bd = factory.binaryDecoder(bad, null);    String message = "";    try {        bd.readString();    } catch (AvroRuntimeException e) {        message = e.getMessage();    }    Assert.assertEquals("Malformed data. Length is negative: -1", message);}
0
public void testLongLengthEncoding() throws IOException
{        byte[] bad = new byte[] { (byte) -128, (byte) -128, (byte) -128, (byte) -128, (byte) 16 };    Decoder bd = factory.binaryDecoder(bad, null);    bd.readString();}
0
public void testIntTooShort() throws IOException
{    byte[] badint = new byte[4];    Arrays.fill(badint, (byte) 0xff);    newDecoder(badint).readInt();}
0
public void testLongTooShort() throws IOException
{    byte[] badint = new byte[9];    Arrays.fill(badint, (byte) 0xff);    newDecoder(badint).readLong();}
0
public void testFloatTooShort() throws IOException
{    byte[] badint = new byte[3];    Arrays.fill(badint, (byte) 0xff);    newDecoder(badint).readInt();}
0
public void testDoubleTooShort() throws IOException
{    byte[] badint = new byte[7];    Arrays.fill(badint, (byte) 0xff);    newDecoder(badint).readLong();}
0
public void testSkipping() throws IOException
{    Decoder d = newDecoder(data);    skipGenerated(d);    if (d instanceof BinaryDecoder) {        BinaryDecoder bd = (BinaryDecoder) d;        try {            Assert.assertTrue(bd.isEnd());        } catch (UnsupportedOperationException e) {                        if (bd.getClass() != DirectBinaryDecoder.class) {                throw e;            }        }        bd = factory.binaryDecoder(new ByteArrayInputStream(data), bd);        skipGenerated(bd);        try {            Assert.assertTrue(bd.isEnd());        } catch (UnsupportedOperationException e) {                        if (bd.getClass() != DirectBinaryDecoder.class) {                throw e;            }        }    }}
0
private void skipGenerated(Decoder bd) throws IOException
{    for (int i = 0; i < records.size(); i++) {        bd.readInt();        bd.skipBytes();        bd.skipFixed(1);        bd.skipString();        bd.skipFixed(4);        bd.skipFixed(8);        long leftover = bd.skipArray();                bd.skipFixed((int) leftover + 1);        bd.skipFixed(0);        bd.readLong();    }    EOFException eof = null;    try {        bd.skipFixed(4);    } catch (EOFException e) {        eof = e;    }    Assert.assertTrue(null != eof);}
0
public void testEOF() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder e = EncoderFactory.get().binaryEncoder(baos, null);    e.writeLong(0x10000000000000L);    e.flush();    Decoder d = newDecoder(new ByteArrayInputStream(baos.toByteArray()));    Assert.assertEquals(0x10000000000000L, d.readLong());    d.readInt();}
0
public static void generateData(Encoder e, boolean useReadOnlyByteBuffer) throws IOException
{        Random r = new Random(665321);    e.writeNull();    e.writeBoolean(true);    e.writeBoolean(false);    byte[] bytes = new byte[10];    ByteBuffer bb;    if (useReadOnlyByteBuffer) {        bb = ByteBuffer.wrap(bytes, 4, 4).asReadOnlyBuffer();    } else {        bb = ByteBuffer.wrap(bytes, 4, 4);    }    r.nextBytes(bytes);    e.writeBytes(bytes);    e.writeBytes(new byte[0]);    e.writeBytes(bytes, 3, 3);    e.writeBytes(new byte[0], 0, 0);    e.writeBytes(ByteBuffer.wrap(bytes, 2, 2));    e.writeBytes(bb);    e.writeBytes(bb);    e.writeDouble(0.0);    e.writeDouble(-0.0);    e.writeDouble(Double.NaN);    e.writeDouble(r.nextDouble());    e.writeDouble(Double.NEGATIVE_INFINITY);    e.writeEnum(65);    e.writeFixed(bytes);    e.writeFixed(bytes, 7, 2);    e.writeFloat(1.0f);    e.writeFloat(r.nextFloat());    e.writeFloat(Float.POSITIVE_INFINITY);    e.writeFloat(Float.MIN_NORMAL);    e.writeIndex(-2);    e.writeInt(0);    e.writeInt(-1);    e.writeInt(1);    e.writeInt(0x40);    e.writeInt(-0x41);    e.writeInt(0x2000);    e.writeInt(-0x2001);    e.writeInt(0x80000);    e.writeInt(-0x80001);    e.writeInt(0x4000000);    e.writeInt(-0x4000001);    e.writeInt(r.nextInt());    e.writeInt(r.nextInt());    e.writeInt(Integer.MAX_VALUE);    e.writeInt(Integer.MIN_VALUE);    e.writeLong(0);    e.writeLong(-1);    e.writeLong(1);    e.writeLong(0x40);    e.writeLong(-0x41);    e.writeLong(0x2000);    e.writeLong(-0x2001);    e.writeLong(0x80000);    e.writeLong(-0x80001);    e.writeLong(0x4000000);    e.writeLong(-0x4000001);    e.writeLong(0x200000000L);    e.writeLong(-0x200000001L);    e.writeLong(0x10000000000L);    e.writeLong(-0x10000000001L);    e.writeLong(0x800000000000L);    e.writeLong(-0x800000000001L);    e.writeLong(0x40000000000000L);    e.writeLong(-0x40000000000001L);    e.writeLong(0x2000000000000000L);    e.writeLong(-0x2000000000000001L);    e.writeLong(r.nextLong());    e.writeLong(r.nextLong());    e.writeLong(Long.MAX_VALUE);    e.writeLong(Long.MIN_VALUE);    e.writeString(new StringBuilder("StringBuilder\u00A2"));    e.writeString("String\u20AC");    e.writeString("");    e.writeString(new Utf8("Utf8\uD834\uDD1E"));    if (e instanceof BinaryEncoder) {        int count = ((BinaryEncoder) e).bytesBuffered();        System.out.println(e.getClass().getSimpleName() + " buffered: " + count);    }    e.flush();}
0
 static void generateComplexData(Encoder e) throws IOException
{    e.writeArrayStart();    e.setItemCount(1);    e.startItem();    e.writeInt(1);    e.writeArrayEnd();    e.writeMapStart();    e.setItemCount(2);    e.startItem();    e.writeString("foo");    e.writeInt(-1);    e.writeDouble(33.3);    e.startItem();    e.writeString("bar");    e.writeInt(1);    e.writeDouble(-33.3);    e.writeMapEnd();    e.flush();}
0
public static void generateLegacyData() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder e = new LegacyBinaryEncoder(baos);    generateData(e, false);    legacydata = baos.toByteArray();    baos.reset();    generateComplexData(e);    complexdata = baos.toByteArray();}
0
public void testBinaryEncoder() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    BinaryEncoder e = factory.binaryEncoder(baos, null);    generateData(e, true);    byte[] result = baos.toByteArray();    Assert.assertEquals(legacydata.length, result.length);    Assert.assertArrayEquals(legacydata, result);    baos.reset();    generateComplexData(e);    byte[] result2 = baos.toByteArray();    Assert.assertEquals(complexdata.length, result2.length);    Assert.assertArrayEquals(complexdata, result2);}
0
public void testDirectBinaryEncoder() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    BinaryEncoder e = factory.directBinaryEncoder(baos, null);    generateData(e, true);    byte[] result = baos.toByteArray();    Assert.assertEquals(legacydata.length, result.length);    Assert.assertArrayEquals(legacydata, result);    baos.reset();    generateComplexData(e);    byte[] result2 = baos.toByteArray();    Assert.assertEquals(complexdata.length, result2.length);    Assert.assertArrayEquals(complexdata, result2);}
0
public void testBlockingBinaryEncoder() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    BinaryEncoder e = factory.blockingBinaryEncoder(baos, null);    generateData(e, true);    byte[] result = baos.toByteArray();    Assert.assertEquals(legacydata.length, result.length);    Assert.assertArrayEquals(legacydata, result);    baos.reset();    generateComplexData(e);    byte[] result2 = baos.toByteArray();        Assert.assertEquals(complexdata.length + 2, result2.length);        Assert.assertEquals(complexdata[0] >>> 1, result2[0]);}
0
public void scan() throws IOException
{    ArrayDeque<S> countStack = new ArrayDeque<>();    long count = 0;    while (parser.nextToken() != null) {        switch(parser.getCurrentToken()) {            case END_ARRAY:                assertEquals(0, count);                assertTrue(countStack.peek().isArray);                count = countStack.pop().count;                break;            case END_OBJECT:                assertEquals(0, count);                assertFalse(countStack.peek().isArray);                count = countStack.pop().count;                break;            case START_ARRAY:                countStack.push(new S(count, true));                count = input.readArrayStart();                continue;            case VALUE_STRING:                {                    String s = parser.getText();                    int n = s.getBytes(StandardCharsets.UTF_8).length;                    checkString(s, input, n);                    break;                }            case FIELD_NAME:                {                    String s = parser.getCurrentName();                    int n = s.getBytes(StandardCharsets.UTF_8).length;                    checkString(s, input, n);                    continue;                }            case START_OBJECT:                countStack.push(new S(count, false));                count = input.readMapStart();                if (count < 0) {                    count = -count;                                        input.readLong();                }                continue;            default:                throw new RuntimeException("Unsupported: " + parser.getCurrentToken());        }        count--;        if (count == 0) {            count = countStack.peek().isArray ? input.arrayNext() : input.mapNext();        }    }}
0
public void skip(int skipLevel) throws IOException
{    ArrayDeque<S> countStack = new ArrayDeque<>();    long count = 0;    while (parser.nextToken() != null) {        switch(parser.getCurrentToken()) {            case END_ARRAY:                                assertTrue(countStack.peek().isArray);                count = countStack.pop().count;                break;            case END_OBJECT:                                assertFalse(countStack.peek().isArray);                count = countStack.pop().count;                break;            case START_ARRAY:                if (countStack.size() == skipLevel) {                    skipArray(parser, input, depth - skipLevel);                    break;                } else {                    countStack.push(new S(count, true));                    count = input.readArrayStart();                    continue;                }            case VALUE_STRING:                {                    if (countStack.size() == skipLevel) {                        input.skipBytes();                    } else {                        String s = parser.getText();                        int n = s.getBytes(StandardCharsets.UTF_8).length;                        checkString(s, input, n);                    }                    break;                }            case FIELD_NAME:                {                    String s = parser.getCurrentName();                    int n = s.getBytes(StandardCharsets.UTF_8).length;                    checkString(s, input, n);                    continue;                }            case START_OBJECT:                if (countStack.size() == skipLevel) {                    skipMap(parser, input, depth - skipLevel);                    break;                } else {                    countStack.push(new S(count, false));                    count = input.readMapStart();                    if (count < 0) {                        count = -count;                                                input.readLong();                    }                    continue;                }            default:                throw new RuntimeException("Unsupported: " + parser.getCurrentToken());        }        count--;        if (count == 0) {            count = countStack.peek().isArray ? input.arrayNext() : input.mapNext();        }    }}
0
protected static void dump(byte[] bb)
{    int col = 0;    for (byte b : bb) {        if (col % 16 == 0) {            System.out.println();        }        col++;        System.out.print(Integer.toHexString(b & 0xff) + " ");    }    System.out.println();}
0
public void testScan() throws IOException
{    Tests t = new Tests(iSize, iDepth, sInput);    t.scan();}
0
public void testSkip1() throws IOException
{    testSkip(iSize, iDepth, sInput, 0);}
0
public void testSkip2() throws IOException
{    testSkip(iSize, iDepth, sInput, 1);}
0
public void testSkip3() throws IOException
{    testSkip(iSize, iDepth, sInput, 2);}
0
private void testSkip(int bufferSize, int depth, String input, int skipLevel) throws IOException
{    Tests t = new Tests(bufferSize, depth, input);    t.skip(skipLevel);}
0
private static void skipMap(JsonParser parser, Decoder input, int depth) throws IOException
{    for (long l = input.skipMap(); l != 0; l = input.skipMap()) {        for (long i = 0; i < l; i++) {            if (depth == 0) {                input.skipBytes();            } else {                skipArray(parser, input, depth - 1);            }        }    }    parser.skipChildren();}
0
private static void skipArray(JsonParser parser, Decoder input, int depth) throws IOException
{    for (long l = input.skipArray(); l != 0; l = input.skipArray()) {        for (long i = 0; i < l; i++) {            if (depth == 1) {                input.skipBytes();            } else {                skipArray(parser, input, depth - 1);            }        }    }    parser.skipChildren();}
0
private static void checkString(String s, Decoder input, int n) throws IOException
{    ByteBuffer buf = input.readBytes(null);    assertEquals(n, buf.remaining());    String s2 = new String(buf.array(), buf.position(), buf.remaining(), StandardCharsets.UTF_8);    assertEquals(s, s2);}
0
private static void serialize(Encoder cos, JsonParser p, ByteArrayOutputStream os) throws IOException
{    boolean[] isArray = new boolean[100];    int[] counts = new int[100];    int stackTop = -1;    while (p.nextToken() != null) {        switch(p.getCurrentToken()) {            case END_ARRAY:                assertTrue(isArray[stackTop]);                cos.writeArrayEnd();                stackTop--;                break;            case END_OBJECT:                assertFalse(isArray[stackTop]);                cos.writeMapEnd();                stackTop--;                break;            case START_ARRAY:                if (stackTop >= 0 && isArray[stackTop]) {                    cos.setItemCount(1);                    cos.startItem();                    counts[stackTop]++;                }                cos.writeArrayStart();                isArray[++stackTop] = true;                counts[stackTop] = 0;                continue;            case VALUE_STRING:                if (stackTop >= 0 && isArray[stackTop]) {                    cos.setItemCount(1);                    cos.startItem();                    counts[stackTop]++;                }                byte[] bb = p.getText().getBytes(StandardCharsets.UTF_8);                cos.writeBytes(bb);                break;            case START_OBJECT:                if (stackTop >= 0 && isArray[stackTop]) {                    cos.setItemCount(1);                    cos.startItem();                    counts[stackTop]++;                }                cos.writeMapStart();                isArray[++stackTop] = false;                counts[stackTop] = 0;                continue;            case FIELD_NAME:                cos.setItemCount(1);                cos.startItem();                counts[stackTop]++;                cos.writeBytes(p.getCurrentName().getBytes(StandardCharsets.UTF_8));                break;            default:                throw new RuntimeException("Unsupported: " + p.getCurrentToken());        }    }}
0
public static Collection<Object[]> data()
{    return Arrays.asList(new Object[][] { { 64, 0, "" }, { 64, 0, jss(0, 'a') }, { 64, 0, jss(3, 'a') }, { 64, 0, jss(64, 'a') }, { 64, 0, jss(65, 'a') }, { 64, 0, jss(100, 'a') }, { 64, 1, "[]" }, { 64, 1, "[" + jss(0, 'a') + "]" }, { 64, 1, "[" + jss(3, 'a') + "]" }, { 64, 1, "[" + jss(61, 'a') + "]" }, { 64, 1, "[" + jss(62, 'a') + "]" }, { 64, 1, "[" + jss(64, 'a') + "]" }, { 64, 1, "[" + jss(65, 'a') + "]" }, { 64, 1, "[" + jss(0, 'a') + "," + jss(0, '0') + "]" }, { 64, 1, "[" + jss(0, 'a') + "," + jss(10, '0') + "]" }, { 64, 1, "[" + jss(0, 'a') + "," + jss(63, '0') + "]" }, { 64, 1, "[" + jss(0, 'a') + "," + jss(64, '0') + "]" }, { 64, 1, "[" + jss(0, 'a') + "," + jss(65, '0') + "]" }, { 64, 1, "[" + jss(10, 'a') + "," + jss(0, '0') + "]" }, { 64, 1, "[" + jss(10, 'a') + "," + jss(10, '0') + "]" }, { 64, 1, "[" + jss(10, 'a') + "," + jss(51, '0') + "]" }, { 64, 1, "[" + jss(10, 'a') + "," + jss(52, '0') + "]" }, { 64, 1, "[" + jss(10, 'a') + "," + jss(54, '0') + "]" }, { 64, 1, "[" + jss(10, 'a') + "," + jss(55, '0') + "]" }, { 64, 1, "[" + jss(0, 'a') + "," + jss(0, 'a') + "," + jss(0, '0') + "]" }, { 64, 1, "[" + jss(0, 'a') + "," + jss(0, 'a') + "," + jss(63, '0') + "]" }, { 64, 1, "[" + jss(0, 'a') + "," + jss(0, 'a') + "," + jss(64, '0') + "]" }, { 64, 1, "[" + jss(0, 'a') + "," + jss(0, 'a') + "," + jss(65, '0') + "]" }, { 64, 1, "[" + jss(10, 'a') + "," + jss(20, 'A') + "," + jss(10, '0') + "]" }, { 64, 1, "[" + jss(10, 'a') + "," + jss(20, 'A') + "," + jss(23, '0') + "]" }, { 64, 1, "[" + jss(10, 'a') + "," + jss(20, 'A') + "," + jss(24, '0') + "]" }, { 64, 1, "[" + jss(10, 'a') + "," + jss(20, 'A') + "," + jss(25, '0') + "]" }, { 64, 2, "[[]]" }, { 64, 2, "[[" + jss(0, 'a') + "], []]" }, { 64, 2, "[[" + jss(10, 'a') + "], []]" }, { 64, 2, "[[" + jss(59, 'a') + "], []]" }, { 64, 2, "[[" + jss(60, 'a') + "], []]" }, { 64, 2, "[[" + jss(100, 'a') + "], []]" }, { 64, 2, "[[" + jss(10, '0') + ", " + jss(53, 'a') + "], []]" }, { 64, 2, "[[" + jss(10, '0') + ", " + jss(54, 'a') + "], []]" }, { 64, 2, "[[" + jss(10, '0') + ", " + jss(55, 'a') + "], []]" }, { 64, 2, "[[], [" + jss(0, 'a') + "]]" }, { 64, 2, "[[], [" + jss(10, 'a') + "]]" }, { 64, 2, "[[], [" + jss(63, 'a') + "]]" }, { 64, 2, "[[], [" + jss(64, 'a') + "]]" }, { 64, 2, "[[], [" + jss(65, 'a') + "]]" }, { 64, 2, "[[], [" + jss(10, '0') + ", " + jss(53, 'a') + "]]" }, { 64, 2, "[[], [" + jss(10, '0') + ", " + jss(54, 'a') + "]]" }, { 64, 2, "[[], [" + jss(10, '0') + ", " + jss(55, 'a') + "]]" }, { 64, 2, "[[" + jss(10, '0') + "]]" }, { 64, 2, "[[" + jss(62, '0') + "]]" }, { 64, 2, "[[" + jss(63, '0') + "]]" }, { 64, 2, "[[" + jss(64, '0') + "]]" }, { 64, 2, "[[" + jss(10, 'a') + ", " + jss(10, '0') + "]]" }, { 64, 2, "[[" + jss(10, 'a') + ", " + jss(52, '0') + "]]" }, { 64, 2, "[[" + jss(10, 'a') + ", " + jss(53, '0') + "]]" }, { 64, 2, "[[" + jss(10, 'a') + ", " + jss(54, '0') + "]]" }, { 64, 3, "[[[" + jss(10, '0') + "]]]" }, { 64, 3, "[[[" + jss(62, '0') + "]]]" }, { 64, 3, "[[[" + jss(63, '0') + "]]]" }, { 64, 3, "[[[" + jss(64, '0') + "]]]" }, { 64, 3, "[[[" + jss(10, 'a') + ", " + jss(10, '0') + "]]]" }, { 64, 3, "[[[" + jss(10, 'a') + ", " + jss(52, '0') + "]]]" }, { 64, 3, "[[[" + jss(10, 'a') + ", " + jss(53, '0') + "]]]" }, { 64, 3, "[[[" + jss(10, 'a') + "], [" + jss(54, '0') + "]]]" }, { 64, 3, "[[[" + jss(10, 'a') + "], [" + jss(10, '0') + "]]]" }, { 64, 3, "[[[" + jss(10, 'a') + "], [" + jss(52, '0') + "]]]" }, { 64, 3, "[[[" + jss(10, 'a') + "], [" + jss(53, '0') + "]]]" }, { 64, 3, "[[[" + jss(10, 'a') + "], [" + jss(54, '0') + "]]]" }, { 64, 2, "[[\"p\"], [\"mn\"]]" }, { 64, 2, "[[\"pqr\"], [\"mn\"]]" }, { 64, 2, "[[\"pqrstuvwxyz\"], [\"mn\"]]" }, { 64, 2, "[[\"abc\", \"pqrstuvwxyz\"], [\"mn\"]]" }, { 64, 2, "[[\"mn\"], [\"\"]]" }, { 64, 2, "[[\"mn\"], \"abc\"]" }, { 64, 2, "[[\"mn\"], \"abcdefghijk\"]" }, { 64, 2, "[[\"mn\"], \"pqr\", \"abc\"]" }, { 64, 2, "[[\"mn\"]]" }, { 64, 2, "[[\"p\"], [\"mnopqrstuvwx\"]]" }, { 64, 2, "[[\"pqr\"], [\"mnopqrstuvwx\"]]" }, { 64, 2, "[[\"pqrstuvwxyz\"], [\"mnopqrstuvwx\"]]" }, { 64, 2, "[[\"abc\"], \"pqrstuvwxyz\", [\"mnopqrstuvwx\"]]" }, { 64, 2, "[[\"mnopqrstuvwx\"], [\"\"]]" }, { 64, 2, "[[\"mnopqrstuvwx\"], [\"abc\"]]" }, { 64, 2, "[[\"mnopqrstuvwx\"], [\"abcdefghijk\"]]" }, { 64, 2, "[[\"mnopqrstuvwx\"], [\"pqr\", \"abc\"]]" }, { 100, 2, "[[\"pqr\", \"mnopqrstuvwx\"]]" }, { 100, 2, "[[\"pqr\", \"ab\", \"mnopqrstuvwx\"]]" }, { 64, 2, "[[[\"pqr\"]], [[\"ab\"], [\"mnopqrstuvwx\"]]]" }, { 64, 1, "{}" }, { 64, 1, "{\"n\": \"v\"}" }, { 64, 1, "{\"n1\": \"v\", \"n2\": []}" }, { 100, 1, "{\"n1\": \"v\", \"n2\": []}" }, { 100, 1, "{\"n1\": \"v\", \"n2\": [\"abc\"]}" } });}
0
private static String jss(final int n, char c)
{    char[] cc = new char[n + 2];    cc[0] = cc[n + 1] = '"';    for (int i = 1; i < n + 1; i++) {        if (c == 'Z') {            c = 'a';        } else if (c == 'z') {            c = '0';        } else if (c == '9') {            c = 'A';        } else {            c++;        }        cc[i] = c;    }    return new String(cc);}
0
public void testScan() throws IOException
{    TestValidatingIO.check(msg, decoder, calls, values, -1);}
0
public static Collection<Object[]> data()
{    return Arrays.asList(new Object[][] { { 64, 0, "" }, { 64, 0, "S0" }, { 64, 0, "S3" }, { 64, 0, "S64" }, { 64, 0, "S65" }, { 64, 0, "S100" }, { 64, 1, "[]" }, { 64, 1, "[c1sS0]" }, { 64, 1, "[c1sS3]" }, { 64, 1, "[c1sS61]" }, { 64, 1, "[c1sS62]" }, { 64, 1, "[c1sS64]" }, { 64, 1, "[c1sS65]" }, { 64, 1, "[c2sS0sS0]" }, { 64, 1, "[c2sS0sS10]" }, { 64, 1, "[c2sS0sS63]" }, { 64, 1, "[c2sS0sS64]" }, { 64, 1, "[c2sS0sS65]" }, { 64, 1, "[c2sS10sS0]" }, { 64, 1, "[c2sS10sS10]" }, { 64, 1, "[c2sS10sS51]" }, { 64, 1, "[c2sS10sS52]" }, { 64, 1, "[c2sS10sS54]" }, { 64, 1, "[c2sS10sS55]" }, { 64, 1, "[c3sS0sS0sS0]" }, { 64, 1, "[c3sS0sS0sS63]" }, { 64, 1, "[c3sS0sS0sS64]" }, { 64, 1, "[c3sS0sS0sS65]" }, { 64, 1, "[c3sS10sS20sS10]" }, { 64, 1, "[c3sS10sS20sS23]" }, { 64, 1, "[c3sS10sS20sS24]" }, { 64, 1, "[c3sS10sS20sS25]" }, { 64, 1, "[c1s[]]" }, { 64, 1, "[c1s[c1sS0]]" }, { 64, 1, "[c1s[c1sS10]]" }, { 64, 1, "[c2s[c1sS10]s[]]" }, { 64, 1, "[c2s[c1sS59]s[]]" }, { 64, 1, "[c2s[c1sS60]s[]]" }, { 64, 1, "[c2s[c1sS100]s[]]" }, { 64, 1, "[c2s[c2sS10sS53]s[]]" }, { 64, 1, "[c2s[c2sS10sS54]s[]]" }, { 64, 1, "[c2s[c2sS10sS55]s[]]" }, { 64, 1, "[c2s[]s[c1sS0]]" }, { 64, 1, "[c2s[]s[c1sS10]]" }, { 64, 1, "[c2s[]s[c1sS63]]" }, { 64, 1, "[c2s[]s[c1sS64]]" }, { 64, 1, "[c2s[]s[c1sS65]]" }, { 64, 1, "[c2s[]s[c2sS10sS53]]" }, { 64, 1, "[c2s[]s[c2sS10sS54]]" }, { 64, 1, "[c2s[]s[c2sS10sS55]]" }, { 64, 1, "[c1s[c1sS10]]" }, { 64, 1, "[c1s[c1sS62]]" }, { 64, 1, "[c1s[c1sS63]]" }, { 64, 1, "[c1s[c1sS64]]" }, { 64, 1, "[c1s[c2sS10sS10]]" }, { 64, 1, "[c1s[c2sS10sS52]]" }, { 64, 1, "[c1s[c2sS10sS53]]" }, { 64, 1, "[c1s[c2sS10sS54]]" }, { 64, 1, "[c1s[c1s[c1sS10]]]" }, { 64, 1, "[c1s[c1s[c1sS62]]]" }, { 64, 1, "[c1s[c1s[c1sS63]]]" }, { 64, 1, "[c1s[c1s[c1sS64]]]" }, { 64, 1, "[c1s[c1s[c2sS10sS10]]]" }, { 64, 1, "[c1s[c1s[c2sS10sS52]]]" }, { 64, 1, "[c1s[c1s[c2sS10sS53]]]" }, { 64, 1, "[c1s[c1s[c2sS10sS54]]]" }, { 64, 1, "[c1s[c2sS10s[c1sS10]]]" }, { 64, 1, "[c1s[c2sS10s[c1sS52]]]" }, { 64, 1, "[c1s[c2sS10s[c1sS53]]]" }, { 64, 1, "[c1s[c2sS10s[c1sS54]]]" }, { 64, 1, "{}" }, { 64, 1, "{c1sK5S1}" }, { 64, 1, "{c1sK5[]}" }, { 100, 1, "{c1sK5[]}" }, { 100, 1, "{c1sK5[c1sS10]}" }, { 100, 1, "{c1sK5e10}" }, { 100, 1, "{c1sK5U1S10}" }, { 100, 1, "{c1sK5f10S10}" }, { 100, 1, "{c1sK5NS10}" }, { 100, 1, "{c1sK5BS10}" }, { 100, 1, "{c1sK5IS10}" }, { 100, 1, "{c1sK5LS10}" }, { 100, 1, "{c1sK5FS10}" }, { 100, 1, "{c1sK5DS10}" } });}
0
public void testBinaryEncoderInit() throws IOException
{    OutputStream out = new ByteArrayOutputStream();    BinaryEncoder enc = factory.binaryEncoder(out, null);    Assert.assertSame(enc, factory.binaryEncoder(out, enc));}
0
public void testBadBinaryEncoderInit()
{    factory.binaryEncoder(null, null);}
0
public void testBlockingBinaryEncoderInit() throws IOException
{    OutputStream out = new ByteArrayOutputStream();    BinaryEncoder reuse = null;    reuse = factory.blockingBinaryEncoder(out, reuse);    Assert.assertSame(reuse, factory.blockingBinaryEncoder(out, reuse));}
0
public void testBadBlockintBinaryEncoderInit()
{    factory.binaryEncoder(null, null);}
0
public void testDirectBinaryEncoderInit() throws IOException
{    OutputStream out = new ByteArrayOutputStream();    BinaryEncoder enc = factory.directBinaryEncoder(out, null);    Assert.assertSame(enc, factory.directBinaryEncoder(out, enc));}
0
public void testBadDirectBinaryEncoderInit()
{    factory.directBinaryEncoder(null, null);}
0
public void testJsonEncoderInit() throws IOException
{    Schema s = new Schema.Parser().parse("\"int\"");    OutputStream out = new ByteArrayOutputStream();    factory.jsonEncoder(s, out);    JsonEncoder enc = factory.jsonEncoder(s, new JsonFactory().createGenerator(out, JsonEncoding.UTF8));    enc.configure(out);}
0
public void testBadJsonEncoderInitOS() throws IOException
{    factory.jsonEncoder(Schema.create(Type.INT), (OutputStream) null);}
0
public void testBadJsonEncoderInit() throws IOException
{    factory.jsonEncoder(Schema.create(Type.INT), (JsonGenerator) null);}
0
public void testJsonEncoderNewlineDelimited() throws IOException
{    OutputStream out = new ByteArrayOutputStream();    Schema ints = Schema.create(Type.INT);    Encoder e = factory.jsonEncoder(ints, out);    String separator = System.getProperty("line.separator");    GenericDatumWriter<Integer> writer = new GenericDatumWriter<>(ints);    writer.write(1, e);    writer.write(2, e);    e.flush();    Assert.assertEquals("1" + separator + "2", out.toString());}
0
public void testJsonEncoderWhenIncludeNamespaceOptionIsFalse() throws IOException
{    String value = "{\"b\": {\"string\":\"myVal\"}, \"a\": 1}";    String schemaStr = "{\"type\": \"record\", \"name\": \"ab\", \"fields\": [" + "{\"name\": \"a\", \"type\": \"int\"}, {\"name\": \"b\", \"type\": [\"null\", \"string\"]}" + "]}";    Schema schema = new Schema.Parser().parse(schemaStr);    byte[] avroBytes = fromJsonToAvro(value, schema);    ObjectMapper mapper = new ObjectMapper();    Assert.assertEquals(mapper.readTree("{\"b\":\"myVal\",\"a\":1}"), mapper.readTree(fromAvroToJson(avroBytes, schema, false)));}
0
public void testJsonEncoderWhenIncludeNamespaceOptionIsTrue() throws IOException
{    String value = "{\"b\": {\"string\":\"myVal\"}, \"a\": 1}";    String schemaStr = "{\"type\": \"record\", \"name\": \"ab\", \"fields\": [" + "{\"name\": \"a\", \"type\": \"int\"}, {\"name\": \"b\", \"type\": [\"null\", \"string\"]}" + "]}";    Schema schema = new Schema.Parser().parse(schemaStr);    byte[] avroBytes = fromJsonToAvro(value, schema);    ObjectMapper mapper = new ObjectMapper();    Assert.assertEquals(mapper.readTree("{\"b\":{\"string\":\"myVal\"},\"a\":1}"), mapper.readTree(fromAvroToJson(avroBytes, schema, true)));}
0
public void testValidatingEncoderInit() throws IOException
{    Schema s = new Schema.Parser().parse("\"int\"");    OutputStream out = new ByteArrayOutputStream();    Encoder e = factory.directBinaryEncoder(out, null);    factory.validatingEncoder(s, e).configure(e);}
0
public void testJsonRecordOrdering() throws IOException
{    String value = "{\"b\": 2, \"a\": 1}";    Schema schema = new Schema.Parser().parse("{\"type\": \"record\", \"name\": \"ab\", \"fields\": [" + "{\"name\": \"a\", \"type\": \"int\"}, {\"name\": \"b\", \"type\": \"int\"}" + "]}");    GenericDatumReader<Object> reader = new GenericDatumReader<>(schema);    Decoder decoder = DecoderFactory.get().jsonDecoder(schema, value);    Object o = reader.read(null, decoder);    Assert.assertEquals("{\"a\": 1, \"b\": 2}", o.toString());}
0
public void testJsonExcessFields() throws IOException
{    String value = "{\"b\": { \"b3\": 1.4, \"b2\": 3.14, \"b1\": \"h\"}, \"a\": {\"a0\": 45, \"a2\":true, \"a1\": null}}";    Schema schema = new Schema.Parser().parse("{\"type\": \"record\", \"name\": \"ab\", \"fields\": [\n" + "{\"name\": \"a\", \"type\": {\"type\":\"record\",\"name\":\"A\",\"fields\":\n" + "[{\"name\":\"a1\", \"type\":\"null\"}, {\"name\":\"a2\", \"type\":\"boolean\"}]}},\n" + "{\"name\": \"b\", \"type\": {\"type\":\"record\",\"name\":\"B\",\"fields\":\n" + "[{\"name\":\"b1\", \"type\":\"string\"}, {\"name\":\"b2\", \"type\":\"float\"}, {\"name\":\"b3\", \"type\":\"double\"}]}}\n" + "]}");    GenericDatumReader<Object> reader = new GenericDatumReader<>(schema);    Decoder decoder = DecoderFactory.get().jsonDecoder(schema, value);    reader.read(null, decoder);}
0
public void testJsonRecordOrdering2() throws IOException
{    String value = "{\"b\": { \"b3\": 1.4, \"b2\": 3.14, \"b1\": \"h\"}, \"a\": {\"a2\":true, \"a1\": null}}";    Schema schema = new Schema.Parser().parse("{\"type\": \"record\", \"name\": \"ab\", \"fields\": [\n" + "{\"name\": \"a\", \"type\": {\"type\":\"record\",\"name\":\"A\",\"fields\":\n" + "[{\"name\":\"a1\", \"type\":\"null\"}, {\"name\":\"a2\", \"type\":\"boolean\"}]}},\n" + "{\"name\": \"b\", \"type\": {\"type\":\"record\",\"name\":\"B\",\"fields\":\n" + "[{\"name\":\"b1\", \"type\":\"string\"}, {\"name\":\"b2\", \"type\":\"float\"}, {\"name\":\"b3\", \"type\":\"double\"}]}}\n" + "]}");    GenericDatumReader<Object> reader = new GenericDatumReader<>(schema);    Decoder decoder = DecoderFactory.get().jsonDecoder(schema, value);    Object o = reader.read(null, decoder);    Assert.assertEquals("{\"a\": {\"a1\": null, \"a2\": true}, \"b\": {\"b1\": \"h\", \"b2\": 3.14, \"b3\": 1.4}}", o.toString());}
0
public void testJsonRecordOrderingWithProjection() throws IOException
{    String value = "{\"b\": { \"b3\": 1.4, \"b2\": 3.14, \"b1\": \"h\"}, \"a\": {\"a2\":true, \"a1\": null}}";    Schema writerSchema = new Schema.Parser().parse("{\"type\": \"record\", \"name\": \"ab\", \"fields\": [\n" + "{\"name\": \"a\", \"type\": {\"type\":\"record\",\"name\":\"A\",\"fields\":\n" + "[{\"name\":\"a1\", \"type\":\"null\"}, {\"name\":\"a2\", \"type\":\"boolean\"}]}},\n" + "{\"name\": \"b\", \"type\": {\"type\":\"record\",\"name\":\"B\",\"fields\":\n" + "[{\"name\":\"b1\", \"type\":\"string\"}, {\"name\":\"b2\", \"type\":\"float\"}, {\"name\":\"b3\", \"type\":\"double\"}]}}\n" + "]}");    Schema readerSchema = new Schema.Parser().parse("{\"type\": \"record\", \"name\": \"ab\", \"fields\": [\n" + "{\"name\": \"a\", \"type\": {\"type\":\"record\",\"name\":\"A\",\"fields\":\n" + "[{\"name\":\"a1\", \"type\":\"null\"}, {\"name\":\"a2\", \"type\":\"boolean\"}]}}\n" + "]}");    GenericDatumReader<Object> reader = new GenericDatumReader<>(writerSchema, readerSchema);    Decoder decoder = DecoderFactory.get().jsonDecoder(writerSchema, value);    Object o = reader.read(null, decoder);    Assert.assertEquals("{\"a\": {\"a1\": null, \"a2\": true}}", o.toString());}
0
public void testJsonRecordOrderingWithProjection2() throws IOException
{    String value = "{\"b\": { \"b1\": \"h\", \"b2\": [3.14, 3.56], \"b3\": 1.4}, \"a\": {\"a2\":true, \"a1\": null}}";    Schema writerSchema = new Schema.Parser().parse("{\"type\": \"record\", \"name\": \"ab\", \"fields\": [\n" + "{\"name\": \"a\", \"type\": {\"type\":\"record\",\"name\":\"A\",\"fields\":\n" + "[{\"name\":\"a1\", \"type\":\"null\"}, {\"name\":\"a2\", \"type\":\"boolean\"}]}},\n" + "{\"name\": \"b\", \"type\": {\"type\":\"record\",\"name\":\"B\",\"fields\":\n" + "[{\"name\":\"b1\", \"type\":\"string\"}, {\"name\":\"b2\", \"type\":{\"type\":\"array\", \"items\":\"float\"}}, {\"name\":\"b3\", \"type\":\"double\"}]}}\n" + "]}");    Schema readerSchema = new Schema.Parser().parse("{\"type\": \"record\", \"name\": \"ab\", \"fields\": [\n" + "{\"name\": \"a\", \"type\": {\"type\":\"record\",\"name\":\"A\",\"fields\":\n" + "[{\"name\":\"a1\", \"type\":\"null\"}, {\"name\":\"a2\", \"type\":\"boolean\"}]}}\n" + "]}");    GenericDatumReader<Object> reader = new GenericDatumReader<>(writerSchema, readerSchema);    Decoder decoder = DecoderFactory.get().jsonDecoder(writerSchema, value);    Object o = reader.read(null, decoder);    Assert.assertEquals("{\"a\": {\"a1\": null, \"a2\": true}}", o.toString());}
0
public void testArrayBackedByteBuffer() throws IOException
{    ByteBuffer buffer = ByteBuffer.wrap(someBytes(EXAMPLE_DATA_SIZE));    testWithBuffer(buffer);}
0
public void testMappedByteBuffer() throws IOException
{    Path file = Paths.get(DIR.getRoot().getPath() + "testMappedByteBuffer.avro");    Files.write(file, someBytes(EXAMPLE_DATA_SIZE));    MappedByteBuffer buffer = FileChannel.open(file, StandardOpenOption.READ).map(FileChannel.MapMode.READ_ONLY, 0, EXAMPLE_DATA_SIZE);    testWithBuffer(buffer);}
0
private void testWithBuffer(ByteBuffer buffer) throws IOException
{    assertThat(asList(buffer.position(), buffer.remaining()), is(asList(0, EXAMPLE_DATA_SIZE)));    ByteArrayOutputStream output = new ByteArrayOutputStream(EXAMPLE_DATA_SIZE * 2);    EncoderFactory encoderFactory = new EncoderFactory();    encoderFactory.configureBufferSize(ENCODER_BUFFER_SIZE);    Encoder encoder = encoderFactory.binaryEncoder(output, null);    new GenericDatumWriter<ByteBuffer>(Schema.create(Schema.Type.BYTES)).write(buffer, encoder);    encoder.flush();    assertThat(output.toByteArray(), equalTo(avroEncoded(someBytes(EXAMPLE_DATA_SIZE))));        assertThat(asList(buffer.position(), buffer.remaining()), is(asList(0, EXAMPLE_DATA_SIZE)));}
0
private byte[] someBytes(int size)
{    byte[] result = new byte[size];    for (int i = 0; i < size; i++) {        result[i] = (byte) i;    }    return result;}
0
private byte[] avroEncoded(byte[] bytes)
{    assert bytes.length < 64;    byte[] result = new byte[1 + bytes.length];        result[0] = (byte) (bytes.length * 2);    System.arraycopy(bytes, 0, result, 1, bytes.length);    return result;}
0
private byte[] fromJsonToAvro(String json, Schema schema) throws IOException
{    DatumReader<Object> reader = new GenericDatumReader<>(schema);    GenericDatumWriter<Object> writer = new GenericDatumWriter<>(schema);    ByteArrayOutputStream output = new ByteArrayOutputStream();    Decoder decoder = DecoderFactory.get().jsonDecoder(schema, json);    Encoder encoder = EncoderFactory.get().binaryEncoder(output, null);    Object datum = reader.read(null, decoder);    writer.write(datum, encoder);    encoder.flush();    return output.toByteArray();}
0
private String fromAvroToJson(byte[] avroBytes, Schema schema, boolean includeNamespace) throws IOException
{    GenericDatumReader<Object> reader = new GenericDatumReader<>(schema);    DatumWriter<Object> writer = new GenericDatumWriter<>(schema);    ByteArrayOutputStream output = new ByteArrayOutputStream();    JsonEncoder encoder = factory.jsonEncoder(schema, output);    encoder.setIncludeNamespace(includeNamespace);    Decoder decoder = DecoderFactory.get().binaryDecoder(avroBytes, null);    Object datum = reader.read(null, decoder);    writer.write(datum, encoder);    encoder.flush();    output.flush();    return new String(output.toByteArray(), StandardCharsets.UTF_8.name());}
0
public void testInt() throws Exception
{    checkNumeric("int", 1);}
0
public void testLong() throws Exception
{    checkNumeric("long", 1L);}
0
public void testFloat() throws Exception
{    checkNumeric("float", 1.0F);}
0
public void testDouble() throws Exception
{    checkNumeric("double", 1.0);}
0
private void checkNumeric(String type, Object value) throws Exception
{    String def = "{\"type\":\"record\",\"name\":\"X\",\"fields\":" + "[{\"type\":\"" + type + "\",\"name\":\"n\"}]}";    Schema schema = new Schema.Parser().parse(def);    DatumReader<GenericRecord> reader = new GenericDatumReader<>(schema);    String[] records = { "{\"n\":1}", "{\"n\":1.0}" };    for (String record : records) {        Decoder decoder = DecoderFactory.get().jsonDecoder(schema, record);        GenericRecord r = reader.read(null, decoder);        Assert.assertEquals(value, r.get("n"));    }}
0
public void testReorderFields() throws Exception
{    String w = "{\"type\":\"record\",\"name\":\"R\",\"fields\":" + "[{\"type\":\"long\",\"name\":\"l\"}," + "{\"type\":{\"type\":\"array\",\"items\":\"int\"},\"name\":\"a\"}" + "]}";    Schema ws = new Schema.Parser().parse(w);    DecoderFactory df = DecoderFactory.get();    String data = "{\"a\":[1,2],\"l\":100}{\"l\": 200, \"a\":[1,2]}";    JsonDecoder in = df.jsonDecoder(ws, data);    Assert.assertEquals(100, in.readLong());    in.skipArray();    Assert.assertEquals(200, in.readLong());    in.skipArray();}
0
public void testIdentical() throws IOException
{    performTest(eEnc, iSkipL, sJsWrtSchm, sWrtCls, sJsWrtSchm, sWrtCls);}
0
public void testCompatible() throws IOException
{    performTest(eEnc, iSkipL, sJsWrtSchm, sWrtCls, sJsRdrSchm, sRdrCls);}
0
private void performTest(Encoding encoding, int skipLevel, String jsonWriterSchema, String writerCalls, String jsonReaderSchema, String readerCalls) throws IOException
{    for (int i = 0; i < COUNT; i++) {        testOnce(jsonWriterSchema, writerCalls, jsonReaderSchema, readerCalls, encoding, skipLevel);    }}
0
private void testOnce(String jsonWriterSchema, String writerCalls, String jsonReaderSchema, String readerCalls, Encoding encoding, int skipLevel) throws IOException
{    Object[] values = TestValidatingIO.randomValues(writerCalls);    Object[] expected = TestValidatingIO.randomValues(readerCalls);    Schema writerSchema = new Schema.Parser().parse(jsonWriterSchema);    byte[] bytes = TestValidatingIO.make(writerSchema, writerCalls, values, encoding);    Schema readerSchema = new Schema.Parser().parse(jsonReaderSchema);    TestValidatingIO.print(encoding, skipLevel, writerSchema, readerSchema, values, expected);    check(writerSchema, readerSchema, bytes, readerCalls, expected, encoding, skipLevel);}
0
 static void check(Schema wsc, Schema rsc, byte[] bytes, String calls, Object[] values, Encoding encoding, int skipLevel) throws IOException
{            Decoder bvi = null;    switch(encoding) {        case BINARY:        case BLOCKING_BINARY:            bvi = DecoderFactory.get().binaryDecoder(bytes, null);            break;        case JSON:            InputStream in = new ByteArrayInputStream(bytes);            bvi = new JsonDecoder(wsc, in);            break;    }    Decoder vi = new ResolvingDecoder(wsc, rsc, bvi);    String msg = "Error in resolving case: w=" + wsc + ", r=" + rsc;    TestValidatingIO.check(msg, vi, calls, values, skipLevel);}
0
public static Collection<Object[]> data2()
{    return Arrays.asList(TestValidatingIO.convertTo2dArray(encodings, skipLevels, testSchemas()));}
0
private static Object[][] testSchemas()
{        return new Object[][] { { "\"int\"", "I", "\"float\"", "F" }, { "\"int\"", "I", "\"double\"", "D" }, { "\"int\"", "I", "\"long\"", "L" }, { "\"long\"", "L", "\"float\"", "F" }, { "\"long\"", "L", "\"double\"", "D" }, { "\"float\"", "F", "\"double\"", "D" }, { "{\"type\":\"array\", \"items\": \"int\"}", "[]", "{\"type\":\"array\", \"items\": \"long\"}", "[]" }, { "{\"type\":\"array\", \"items\": \"int\"}", "[]", "{\"type\":\"array\", \"items\": \"double\"}", "[]" }, { "{\"type\":\"array\", \"items\": \"long\"}", "[]", "{\"type\":\"array\", \"items\": \"double\"}", "[]" }, { "{\"type\":\"array\", \"items\": \"float\"}", "[]", "{\"type\":\"array\", \"items\": \"double\"}", "[]" }, { "{\"type\":\"array\", \"items\": \"int\"}", "[c1sI]", "{\"type\":\"array\", \"items\": \"long\"}", "[c1sL]" }, { "{\"type\":\"array\", \"items\": \"int\"}", "[c1sI]", "{\"type\":\"array\", \"items\": \"double\"}", "[c1sD]" }, { "{\"type\":\"array\", \"items\": \"long\"}", "[c1sL]", "{\"type\":\"array\", \"items\": \"double\"}", "[c1sD]" }, { "{\"type\":\"array\", \"items\": \"float\"}", "[c1sF]", "{\"type\":\"array\", \"items\": \"double\"}", "[c1sD]" }, { "{\"type\":\"map\", \"values\": \"int\"}", "{}", "{\"type\":\"map\", \"values\": \"long\"}", "{}" }, { "{\"type\":\"map\", \"values\": \"int\"}", "{}", "{\"type\":\"map\", \"values\": \"double\"}", "{}" }, { "{\"type\":\"map\", \"values\": \"long\"}", "{}", "{\"type\":\"map\", \"values\": \"double\"}", "{}" }, { "{\"type\":\"map\", \"values\": \"float\"}", "{}", "{\"type\":\"map\", \"values\": \"double\"}", "{}" }, { "{\"type\":\"map\", \"values\": \"int\"}", "{c1sK5I}", "{\"type\":\"map\", \"values\": \"long\"}", "{c1sK5L}" }, { "{\"type\":\"map\", \"values\": \"int\"}", "{c1sK5I}", "{\"type\":\"map\", \"values\": \"double\"}", "{c1sK5D}" }, { "{\"type\":\"map\", \"values\": \"long\"}", "{c1sK5L}", "{\"type\":\"map\", \"values\": \"double\"}", "{c1sK5D}" }, { "{\"type\":\"map\", \"values\": \"float\"}", "{c1sK5F}", "{\"type\":\"map\", \"values\": \"double\"}", "{c1sK5D}" }, { "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f\", \"type\":\"int\"}]}", "I", "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f\", \"type\":\"long\"}]}", "L" }, { "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f\", \"type\":\"int\"}]}", "I", "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f\", \"type\":\"double\"}]}", "D" },     { "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f0\", \"type\":\"boolean\"}," + "{\"name\":\"f1\", \"type\":\"int\"}," + "{\"name\":\"f2\", \"type\":\"float\"}," + "{\"name\":\"f3\", \"type\":\"bytes\"}," + "{\"name\":\"f4\", \"type\":\"string\"}]}", "BIFbS", "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f0\", \"type\":\"boolean\"}," + "{\"name\":\"f1\", \"type\":\"long\"}," + "{\"name\":\"f2\", \"type\":\"double\"}," + "{\"name\":\"f3\", \"type\":\"string\"}," + "{\"name\":\"f4\", \"type\":\"bytes\"}]}", "BLDSb" }, { "[\"int\"]", "U0I", "[\"long\"]", "U0L" }, { "[\"int\"]", "U0I", "[\"double\"]", "U0D" }, { "[\"long\"]", "U0L", "[\"double\"]", "U0D" }, { "[\"float\"]", "U0F", "[\"double\"]", "U0D" }, { "\"int\"", "I", "[\"int\"]", "U0I" }, { "[\"int\"]", "U0I", "\"int\"", "I" }, { "[\"int\"]", "U0I", "\"long\"", "L" }, { "[\"boolean\", \"int\"]", "U1I", "[\"boolean\", \"long\"]", "U1L" }, { "[\"boolean\", \"int\"]", "U1I", "[\"long\", \"boolean\"]", "U0L" } };}
0
public void testResolving() throws IOException
{    Schema writerSchema = new Schema.Parser().parse(sJsWrtSchm);    byte[] bytes = TestValidatingIO.make(writerSchema, sWrtCls, oaWrtVals, eEnc);    Schema readerSchema = new Schema.Parser().parse(sJsRdrSchm);    TestValidatingIO.print(eEnc, iSkipL, writerSchema, readerSchema, oaWrtVals, oaRdrVals);    TestResolvingIO.check(writerSchema, readerSchema, bytes, sRdrCls, oaRdrVals, eEnc, iSkipL);}
0
public static Collection<Object[]> data3()
{    Collection<Object[]> ret = Arrays.asList(TestValidatingIO.convertTo2dArray(TestResolvingIO.encodings, TestResolvingIO.skipLevels, dataForResolvingTests()));    return ret;}
0
private static Object[][] dataForResolvingTests()
{        return new Object[][] {     { "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f1\", \"type\":\"string\"}," + "{\"name\":\"f2\", \"type\":\"string\"}," + "{\"name\":\"f3\", \"type\":\"int\"}]}", "S10S10IS10S10I", new Object[] { "s1", "s2", 100, "t1", "t2", 200 }, "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f1\", \"type\":\"string\" }," + "{\"name\":\"f2\", \"type\":\"string\"}]}", "RS10S10RS10S10", new Object[] { "s1", "s2", "t1", "t2" } },     { "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f1\", \"type\":\"int\"}," + "{\"name\":\"f2\", \"type\":\"string\"}]}", "IS10", new Object[] { 10, "hello" }, "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f2\", \"type\":\"string\" }," + "{\"name\":\"f1\", \"type\":\"long\"}]}", "RLS10", new Object[] { 10L, "hello" } },     { "{\"type\":\"record\",\"name\":\"r\",\"fields\":[]}", "", new Object[] {}, "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f\", \"type\":\"int\", \"default\": 100}]}", "RI", new Object[] { 100 } }, { "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f2\", \"type\":\"int\"}]}", "I", new Object[] { 10 }, "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f1\", \"type\":\"int\", \"default\": 101}," + "{\"name\":\"f2\", \"type\":\"int\"}]}", "RII", new Object[] { 10, 101 } }, { "{\"type\":\"record\",\"name\":\"outer\",\"fields\":[" + "{\"name\": \"g1\", " + "\"type\":{\"type\":\"record\",\"name\":\"inner\",\"fields\":[" + "{\"name\":\"f2\", \"type\":\"int\"}]}}, " + "{\"name\": \"g2\", \"type\": \"long\"}]}", "IL", new Object[] { 10, 11L }, "{\"type\":\"record\",\"name\":\"outer\",\"fields\":[" + "{\"name\": \"g1\", " + "\"type\":{\"type\":\"record\",\"name\":\"inner\",\"fields\":[" + "{\"name\":\"f1\", \"type\":\"int\", \"default\": 101}," + "{\"name\":\"f2\", \"type\":\"int\"}]}}, " + "{\"name\": \"g2\", \"type\": \"long\"}]}}", "RRIIL", new Object[] { 10, 101, 11L } },     { "{\"type\":\"record\",\"name\":\"outer\",\"fields\":[" + "{\"name\": \"g2\", \"type\": \"long\"}]}", "L", new Object[] { 11L }, "{\"type\":\"record\",\"name\":\"outer\",\"fields\":[" + "{\"name\": \"g1\", " + "\"type\":{\"type\":\"record\",\"name\":\"inner\",\"fields\":[" + "{\"name\":\"f1\", \"type\":\"int\" }," + "{\"name\":\"f2\", \"type\":\"int\"}] }, " + "\"default\": { \"f1\": 10, \"f2\": 101 } }, " + "{\"name\": \"g2\", \"type\": \"long\"}]}", "RLRII", new Object[] { 11L, 10, 101 } }, { "{\"type\":\"record\",\"name\":\"r\",\"fields\":[]}", "", new Object[] {}, "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f\", \"type\":{ \"type\": \"array\", \"items\": \"int\" }, " + "\"default\": [100]}]}", "[c1sI]", new Object[] { 100 } }, { "{ \"type\": \"array\", \"items\": {\"type\":\"record\"," + "\"name\":\"r\",\"fields\":[]} }", "[c1s]", new Object[] {}, "{ \"type\": \"array\", \"items\": {\"type\":\"record\"," + "\"name\":\"r\",\"fields\":[" + "{\"name\":\"f\", \"type\":\"int\", \"default\": 100}]} }", "[c1sI]", new Object[] { 100 } },     { "{\"type\":\"enum\",\"name\":\"e\",\"symbols\":[\"x\",\"y\",\"z\"]}", "e2", new Object[] {}, "{\"type\":\"enum\",\"name\":\"e\",\"symbols\":[ \"y\", \"z\" ]}", "e1", new Object[] {} }, { "{\"type\":\"enum\",\"name\":\"e\",\"symbols\":[ \"x\", \"y\" ]}", "e1", new Object[] {}, "{\"type\":\"enum\",\"name\":\"e\",\"symbols\":[ \"y\", \"z\" ]}", "e0", new Object[] {} },     { "\"int\"", "I", new Object[] { 100 }, "[ \"long\", \"int\"]", "U1I", new Object[] { 100 } }, { "[ \"long\", \"int\"]", "U1I", new Object[] { 100 }, "\"int\"", "I", new Object[] { 100 } },     { "\"int\"", "I", new Object[] { 100 }, "[ \"long\", \"string\"]", "U0L", new Object[] { 100L } }, { "[ \"int\", \"string\"]", "U0I", new Object[] { 100 }, "\"long\"", "L", new Object[] { 100L } },     { "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f0\", \"type\":\"boolean\"}," + "{\"name\":\"f1\", \"type\":\"int\"}," + "{\"name\":\"f2\", \"type\":[\"int\", \"long\"]}," + "{\"name\":\"f3\", \"type\":\"float\"}" + "]}", "BIU0IF", new Object[] { true, 100, 121, 10.75f }, "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f0\", \"type\":\"boolean\"}," + "{\"name\":\"f1\", \"type\":\"long\"}," + "{\"name\":\"f3\", \"type\":\"double\"}]}", "BLD", new Object[] { true, 100L, 10.75d } },     { "{ \"type\": \"array\", \"items\":" + "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f0\", \"type\":\"boolean\"}," + "{\"name\":\"f1\", \"type\": {\"type\":\"array\", \"items\": \"boolean\" }}" + "]}}", "[c2sB[c2sBsB]sB[c3sBsBsB]]", new Object[] { true, false, false, false, true, true, true }, "{ \"type\": \"array\", \"items\":" + "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f0\", \"type\":\"boolean\"}" + "]}}", "[c2sBsB]", new Object[] { true, false } } };}
0
public void testMain() throws IOException
{    for (int i = 0; i < COUNT; i++) {        testOnce(new Schema.Parser().parse(sJsSch), sCl, iSkipL, eEnc);    }}
0
private void testOnce(Schema schema, String calls, int skipLevel, Encoding encoding) throws IOException
{    Object[] values = randomValues(calls);    print(eEnc, iSkipL, schema, schema, values, values);    byte[] bytes = make(schema, calls, values, encoding);    check(schema, bytes, calls, values, skipLevel, encoding);}
0
public static byte[] make(Schema sc, String calls, Object[] values, Encoding encoding) throws IOException
{    EncoderFactory factory = EncoderFactory.get();    ByteArrayOutputStream ba = new ByteArrayOutputStream();    Encoder bvo = null;    switch(encoding) {        case BINARY:            bvo = factory.binaryEncoder(ba, null);            break;        case BLOCKING_BINARY:            bvo = factory.blockingBinaryEncoder(ba, null);            break;        case JSON:            bvo = factory.jsonEncoder(sc, ba);            break;    }    Encoder vo = factory.validatingEncoder(sc, bvo);    generate(vo, calls, values);    vo.flush();    return ba.toByteArray();}
0
public boolean next()
{    if (cpos < chars.length) {        cpos++;    }    return cpos != chars.length;}
0
public char cur()
{    return chars[cpos];}
0
public boolean isDone()
{    return cpos == chars.length;}
0
public static void generate(Encoder vw, String calls, Object[] values) throws IOException
{    InputScanner cs = new InputScanner(calls.toCharArray());    int p = 0;    while (!cs.isDone()) {        char c = cs.cur();        cs.next();        switch(c) {            case 'N':                vw.writeNull();                break;            case 'B':                boolean b = (Boolean) values[p++];                vw.writeBoolean(b);                break;            case 'I':                int ii = (Integer) values[p++];                vw.writeInt(ii);                break;            case 'L':                long l = (Long) values[p++];                vw.writeLong(l);                break;            case 'F':                float f = (Float) values[p++];                vw.writeFloat(f);                break;            case 'D':                double d = (Double) values[p++];                vw.writeDouble(d);                break;            case 'S':                {                    extractInt(cs);                    String s = (String) values[p++];                    vw.writeString(new Utf8(s));                    break;                }            case 'K':                {                    extractInt(cs);                    String s = (String) values[p++];                    vw.writeString(s);                    break;                }            case 'b':                {                    extractInt(cs);                    byte[] bb = (byte[]) values[p++];                    vw.writeBytes(bb);                    break;                }            case 'f':                {                    extractInt(cs);                    byte[] bb = (byte[]) values[p++];                    vw.writeFixed(bb);                    break;                }            case 'e':                {                    int e = extractInt(cs);                    vw.writeEnum(e);                    break;                }            case '[':                vw.writeArrayStart();                break;            case ']':                vw.writeArrayEnd();                break;            case '{':                vw.writeMapStart();                break;            case '}':                vw.writeMapEnd();                break;            case 'c':                vw.setItemCount(extractInt(cs));                break;            case 's':                vw.startItem();                break;            case 'U':                {                    vw.writeIndex(extractInt(cs));                    break;                }            default:                fail();                break;        }    }}
0
public static Object[] randomValues(String calls)
{    Random r = new Random(0L);    InputScanner cs = new InputScanner(calls.toCharArray());    List<Object> result = new ArrayList<>();    while (!cs.isDone()) {        char c = cs.cur();        cs.next();        switch(c) {            case 'N':                break;            case 'B':                result.add(r.nextBoolean());                break;            case 'I':                result.add(r.nextInt());                break;            case 'L':                result.add((long) r.nextInt());                break;            case 'F':                result.add((float) r.nextInt());                break;            case 'D':                result.add((double) r.nextInt());                break;            case 'S':            case 'K':                result.add(nextString(r, extractInt(cs)));                break;            case 'b':            case 'f':                result.add(nextBytes(r, extractInt(cs)));                break;            case 'e':            case 'c':            case 'U':                extractInt(cs);            case '[':            case ']':            case '{':            case '}':            case 's':                break;            default:                fail();                break;        }    }    return result.toArray();}
0
private static int extractInt(InputScanner sc)
{    int r = 0;    while (!sc.isDone()) {        if (Character.isDigit(sc.cur())) {            r = r * 10 + sc.cur() - '0';            sc.next();        } else {            break;        }    }    return r;}
0
private static byte[] nextBytes(Random r, int length)
{    byte[] bb = new byte[length];    r.nextBytes(bb);    return bb;}
0
private static String nextString(Random r, int length)
{    char[] cc = new char[length];    for (int i = 0; i < length; i++) {        cc[i] = (char) ('A' + r.nextInt(26));    }    return new String(cc);}
0
private static void check(Schema sc, byte[] bytes, String calls, Object[] values, final int skipLevel, Encoding encoding) throws IOException
{            Decoder bvi = null;    switch(encoding) {        case BINARY:        case BLOCKING_BINARY:            bvi = DecoderFactory.get().binaryDecoder(bytes, null);            break;        case JSON:            InputStream in = new ByteArrayInputStream(bytes);            bvi = new JsonDecoder(sc, in);    }    Decoder vi = new ValidatingDecoder(sc, bvi);    String msg = "Error in validating case: " + sc;    check(msg, vi, calls, values, skipLevel);}
0
public static void check(String msg, Decoder vi, String calls, Object[] values, final int skipLevel) throws IOException
{    InputScanner cs = new InputScanner(calls.toCharArray());    int p = 0;    int level = 0;    long[] counts = new long[100];    boolean[] isArray = new boolean[100];    boolean[] isEmpty = new boolean[100];    while (!cs.isDone()) {        final char c = cs.cur();        cs.next();        try {            switch(c) {                case 'N':                    vi.readNull();                    break;                case 'B':                    assertEquals(msg, values[p++], vi.readBoolean());                    break;                case 'I':                    assertEquals(msg, values[p++], vi.readInt());                    break;                case 'L':                    assertEquals(msg, values[p++], vi.readLong());                    break;                case 'F':                    if (!(values[p] instanceof Float))                        fail();                    float f = (Float) values[p++];                    assertEquals(msg, f, vi.readFloat(), Math.abs(f / 1000));                    break;                case 'D':                    if (!(values[p] instanceof Double))                        fail();                    double d = (Double) values[p++];                    assertEquals(msg, d, vi.readDouble(), Math.abs(d / 1000));                    break;                case 'S':                    extractInt(cs);                    if (level == skipLevel) {                        vi.skipString();                        p++;                    } else {                        String s = (String) values[p++];                        assertEquals(msg, new Utf8(s), vi.readString(null));                    }                    break;                case 'K':                    extractInt(cs);                    if (level == skipLevel) {                        vi.skipString();                        p++;                    } else {                        String s = (String) values[p++];                        assertEquals(msg, new Utf8(s), vi.readString(null));                    }                    break;                case 'b':                    extractInt(cs);                    if (level == skipLevel) {                        vi.skipBytes();                        p++;                    } else {                        byte[] bb = (byte[]) values[p++];                        ByteBuffer bb2 = vi.readBytes(null);                        byte[] actBytes = new byte[bb2.remaining()];                        System.arraycopy(bb2.array(), bb2.position(), actBytes, 0, bb2.remaining());                        assertArrayEquals(msg, bb, actBytes);                    }                    break;                case 'f':                    {                        int len = extractInt(cs);                        if (level == skipLevel) {                            vi.skipFixed(len);                            p++;                        } else {                            byte[] bb = (byte[]) values[p++];                            byte[] actBytes = new byte[len];                            vi.readFixed(actBytes);                            assertArrayEquals(msg, bb, actBytes);                        }                    }                    break;                case 'e':                    {                        int e = extractInt(cs);                        if (level == skipLevel) {                            vi.readEnum();                        } else {                            assertEquals(msg, e, vi.readEnum());                        }                    }                    break;                case '[':                    if (level == skipLevel) {                        p += skip(msg, cs, vi, true);                        break;                    } else {                        level++;                        counts[level] = vi.readArrayStart();                        isArray[level] = true;                        isEmpty[level] = counts[level] == 0;                        continue;                    }                case '{':                    if (level == skipLevel) {                        p += skip(msg, cs, vi, false);                        break;                    } else {                        level++;                        counts[level] = vi.readMapStart();                        isArray[level] = false;                        isEmpty[level] = counts[level] == 0;                        continue;                    }                case ']':                    assertEquals(msg, 0, counts[level]);                    if (!isEmpty[level]) {                        assertEquals(msg, 0, vi.arrayNext());                    }                    level--;                    break;                case '}':                    assertEquals(0, counts[level]);                    if (!isEmpty[level]) {                        assertEquals(msg, 0, vi.mapNext());                    }                    level--;                    break;                case 's':                    if (counts[level] == 0) {                        if (isArray[level]) {                            counts[level] = vi.arrayNext();                        } else {                            counts[level] = vi.mapNext();                        }                    }                    counts[level]--;                    continue;                case 'c':                    extractInt(cs);                    continue;                case 'U':                    {                        int idx = extractInt(cs);                        assertEquals(msg, idx, vi.readIndex());                        continue;                    }                case 'R':                    ((ResolvingDecoder) vi).readFieldOrder();                    continue;                default:                    fail(msg);            }        } catch (RuntimeException e) {            throw new RuntimeException(msg, e);        }    }    assertEquals(msg, values.length, p);}
0
private static int skip(String msg, InputScanner cs, Decoder vi, boolean isArray) throws IOException
{    final char end = isArray ? ']' : '}';    if (isArray) {        assertEquals(msg, 0, vi.skipArray());    } else if (end == '}') {        assertEquals(msg, 0, vi.skipMap());    }    int level = 0;    int p = 0;    while (!cs.isDone()) {        char c = cs.cur();        cs.next();        switch(c) {            case '[':            case '{':                ++level;                break;            case ']':            case '}':                if (c == end && level == 0) {                    return p;                }                level--;                break;            case 'B':            case 'I':            case 'L':            case 'F':            case 'D':            case 'S':            case 'K':            case 'b':            case 'f':            case 'e':                p++;                break;        }    }    throw new RuntimeException("Don't know how to skip");}
0
public static Collection<Object[]> data()
{    return Arrays.asList(convertTo2dArray(encodings, skipLevels, testSchemas()));}
0
public static Object[][] convertTo2dArray(final Object[][]... values)
{    ArrayList<Object[]> ret = new ArrayList<>();    Iterator<Object[]> iter = cartesian(values);    while (iter.hasNext()) {        Object[] objects = iter.next();        ret.add(objects);    }    Object[][] retArrays = new Object[ret.size()][];    for (int i = 0; i < ret.size(); i++) {        retArrays[i] = ret.get(i);    }    return retArrays;}
0
public static Iterator<Object[]> cartesian(final Object[][]... values)
{    return new Iterator<Object[]>() {        private int[] pos = new int[values.length];        @Override        public boolean hasNext() {            return pos[0] < values[0].length;        }        @Override        public Object[] next() {            Object[][] v = new Object[values.length][];            for (int i = 0; i < v.length; i++) {                v[i] = values[i][pos[i]];            }            for (int i = v.length - 1; i >= 0; i--) {                if (++pos[i] == values[i].length) {                    if (i != 0) {                        pos[i] = 0;                    }                } else {                    break;                }            }            return concat(v);        }        @Override        public void remove() {            throw new UnsupportedOperationException();        }    };}
0
public boolean hasNext()
{    return pos[0] < values[0].length;}
0
public Object[] next()
{    Object[][] v = new Object[values.length][];    for (int i = 0; i < v.length; i++) {        v[i] = values[i][pos[i]];    }    for (int i = v.length - 1; i >= 0; i--) {        if (++pos[i] == values[i].length) {            if (i != 0) {                pos[i] = 0;            }        } else {            break;        }    }    return concat(v);}
0
public void remove()
{    throw new UnsupportedOperationException();}
0
public static Object[] concat(Object[]... oo)
{    int l = 0;    for (Object[] o : oo) {        l += o.length;    }    Object[] result = new Object[l];    l = 0;    for (Object[] o : oo) {        System.arraycopy(o, 0, result, l, o.length);        l += o.length;    }    return result;}
0
 static Object[][] paste(Object[][]... in)
{    Object[][] result = new Object[in[0].length][];    Object[][] cc = new Object[in.length][];    for (int i = 0; i < result.length; i++) {        for (int j = 0; j < cc.length; j++) {            cc[j] = in[j][i];        }        result[i] = concat(cc);    }    return result;}
0
public static Object[][] testSchemas()
{    /**     * The first argument is a schema. The second one is a sequence of (single     * character) mnemonics: N null B boolean I int L long F float D double K     * followed by integer - key-name (and its length) in a map S followed by     * integer - string and its length b followed by integer - bytes and length f     * followed by integer - fixed and length c Number of items to follow in an     * array/map. U followed by integer - Union and its branch e followed by integer     * - Enum and its value [ Start array ] End array { Start map } End map s start     * item     */    return new Object[][] { { "\"null\"", "N" }, { "\"boolean\"", "B" }, { "\"int\"", "I" }, { "\"long\"", "L" }, { "\"float\"", "F" }, { "\"double\"", "D" }, { "\"string\"", "S0" }, { "\"string\"", "S10" }, { "\"bytes\"", "b0" }, { "\"bytes\"", "b10" }, { "{\"type\":\"fixed\", \"name\":\"fi\", \"size\": 1}", "f1" }, { "{\"type\":\"fixed\", \"name\":\"fi\", \"size\": 10}", "f10" }, { "{\"type\":\"enum\", \"name\":\"en\", \"symbols\":[\"v1\", \"v2\"]}", "e1" }, { "{\"type\":\"array\", \"items\": \"boolean\"}", "[]" }, { "{\"type\":\"array\", \"items\": \"int\"}", "[]" }, { "{\"type\":\"array\", \"items\": \"long\"}", "[]" }, { "{\"type\":\"array\", \"items\": \"float\"}", "[]" }, { "{\"type\":\"array\", \"items\": \"double\"}", "[]" }, { "{\"type\":\"array\", \"items\": \"string\"}", "[]" }, { "{\"type\":\"array\", \"items\": \"bytes\"}", "[]" }, { "{\"type\":\"array\", \"items\":{\"type\":\"fixed\", " + "\"name\":\"fi\", \"size\": 10}}", "[]" }, { "{\"type\":\"array\", \"items\": \"boolean\"}", "[c1sB]" }, { "{\"type\":\"array\", \"items\": \"int\"}", "[c1sI]" }, { "{\"type\":\"array\", \"items\": \"long\"}", "[c1sL]" }, { "{\"type\":\"array\", \"items\": \"float\"}", "[c1sF]" }, { "{\"type\":\"array\", \"items\": \"double\"}", "[c1sD]" }, { "{\"type\":\"array\", \"items\": \"string\"}", "[c1sS10]" }, { "{\"type\":\"array\", \"items\": \"bytes\"}", "[c1sb10]" }, { "{\"type\":\"array\", \"items\": \"int\"}", "[c1sIc1sI]" }, { "{\"type\":\"array\", \"items\": \"int\"}", "[c2sIsI]" }, { "{\"type\":\"array\", \"items\":{\"type\":\"fixed\", " + "\"name\":\"fi\", \"size\": 10}}", "[c2sf10sf10]" }, { "{\"type\":\"map\", \"values\": \"boolean\"}", "{}" }, { "{\"type\":\"map\", \"values\": \"int\"}", "{}" }, { "{\"type\":\"map\", \"values\": \"long\"}", "{}" }, { "{\"type\":\"map\", \"values\": \"float\"}", "{}" }, { "{\"type\":\"map\", \"values\": \"double\"}", "{}" }, { "{\"type\":\"map\", \"values\": \"string\"}", "{}" }, { "{\"type\":\"map\", \"values\": \"bytes\"}", "{}" }, { "{\"type\":\"map\", \"values\": " + "{\"type\":\"array\", \"items\":\"int\"}}", "{}" }, { "{\"type\":\"map\", \"values\": \"boolean\"}", "{c1sK5B}" }, { "{\"type\":\"map\", \"values\": \"int\"}", "{c1sK5I}" }, { "{\"type\":\"map\", \"values\": \"long\"}", "{c1sK5L}" }, { "{\"type\":\"map\", \"values\": \"float\"}", "{c1sK5F}" }, { "{\"type\":\"map\", \"values\": \"double\"}", "{c1sK5D}" }, { "{\"type\":\"map\", \"values\": \"string\"}", "{c1sK5S10}" }, { "{\"type\":\"map\", \"values\": \"bytes\"}", "{c1sK5b10}" }, { "{\"type\":\"map\", \"values\": " + "{\"type\":\"array\", \"items\":\"int\"}}", "{c1sK5[c3sIsIsI]}" }, { "{\"type\":\"map\", \"values\": \"boolean\"}", "{c1sK5Bc2sK5BsK5B}" }, { "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f\", \"type\":\"boolean\"}]}", "B" }, { "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f\", \"type\":\"int\"}]}", "I" }, { "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f\", \"type\":\"long\"}]}", "L" }, { "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f\", \"type\":\"float\"}]}", "F" }, { "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f\", \"type\":\"double\"}]}", "D" }, { "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f\", \"type\":\"string\"}]}", "S10" }, { "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f\", \"type\":\"bytes\"}]}", "b10" },     { "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f1\", \"type\":\"int\"}," + "{\"name\":\"f2\", \"type\":\"double\"}," + "{\"name\":\"f3\", \"type\":\"string\"}]}", "IDS10" }, { "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f0\", \"type\":\"null\"}," + "{\"name\":\"f1\", \"type\":\"boolean\"}," + "{\"name\":\"f2\", \"type\":\"int\"}," + "{\"name\":\"f3\", \"type\":\"long\"}," + "{\"name\":\"f4\", \"type\":\"float\"}," + "{\"name\":\"f5\", \"type\":\"double\"}," + "{\"name\":\"f6\", \"type\":\"string\"}," + "{\"name\":\"f7\", \"type\":\"bytes\"}]}", "NBILFDS10b25" },     { "{\"type\":\"record\",\"name\":\"outer\",\"fields\":[" + "{\"name\":\"f1\", \"type\":{\"type\":\"record\", " + "\"name\":\"inner\", \"fields\":[" + "{\"name\":\"g1\", \"type\":\"int\"}, {\"name\":\"g2\", " + "\"type\":\"double\"}]}}," + "{\"name\":\"f2\", \"type\":\"string\"}," + "{\"name\":\"f3\", \"type\":\"inner\"}]}", "IDS10ID" },     { "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f1\", \"type\":\"long\"}," + "{\"name\":\"f2\", " + "\"type\":{\"type\":\"array\", \"items\":\"int\"}}]}", "L[c1sI]" },     { "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f1\", \"type\":\"long\"}," + "{\"name\":\"f2\", " + "\"type\":{\"type\":\"map\", \"values\":\"int\"}}]}", "L{c1sK5I}" },     { "{\"type\":\"array\", \"items\":" + "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f1\", \"type\":\"long\"}," + "{\"name\":\"f2\", \"type\":\"null\"}]}}", "[c2sLNsLN]" }, { "{\"type\":\"array\", \"items\":" + "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f1\", \"type\":\"long\"}," + "{\"name\":\"f2\", " + "\"type\":{\"type\":\"array\", \"items\":\"int\"}}]}}", "[c2sL[c1sI]sL[c2sIsI]]" }, { "{\"type\":\"array\", \"items\":" + "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f1\", \"type\":\"long\"}," + "{\"name\":\"f2\", " + "\"type\":{\"type\":\"map\", \"values\":\"int\"}}]}}", "[c2sL{c1sK5I}sL{c2sK5IsK5I}]" }, { "{\"type\":\"array\", \"items\":" + "{\"type\":\"record\",\"name\":\"r\",\"fields\":[" + "{\"name\":\"f1\", \"type\":\"long\"}," + "{\"name\":\"f2\", " + "\"type\":[\"null\", \"int\"]}]}}", "[c2sLU0NsLU1I]" }, { "[\"boolean\"]", "U0B" }, { "[\"int\"]", "U0I" }, { "[\"long\"]", "U0L" }, { "[\"float\"]", "U0F" }, { "[\"double\"]", "U0D" }, { "[\"string\"]", "U0S10" }, { "[\"bytes\"]", "U0b10" }, { "[\"null\", \"int\"]", "U0N" }, { "[\"boolean\", \"int\"]", "U0B" }, { "[\"boolean\", \"int\"]", "U1I" }, { "[\"boolean\", {\"type\":\"array\", \"items\":\"int\"} ]", "U0B" }, { "[\"boolean\", {\"type\":\"array\", \"items\":\"int\"} ]", "U1[c1sI]" },     { "{\"type\": \"record\", \"name\": \"Node\", \"fields\": [" + "{\"name\":\"label\", \"type\":\"string\"}," + "{\"name\":\"children\", \"type\":" + "{\"type\": \"array\", \"items\": \"Node\" }}]}", "S10[c1sS10[]]" }, { "{\"type\": \"record\", \"name\": \"Lisp\", \"fields\": [" + "{\"name\":\"value\", \"type\":[\"null\", \"string\"," + "{\"type\": \"record\", \"name\": \"Cons\", \"fields\": [" + "{\"name\":\"car\", \"type\":\"Lisp\"}," + "{\"name\":\"cdr\", \"type\":\"Lisp\"}]}]}]}", "U0N" }, { "{\"type\": \"record\", \"name\": \"Lisp\", \"fields\": [" + "{\"name\":\"value\", \"type\":[\"null\", \"string\"," + "{\"type\": \"record\", \"name\": \"Cons\", \"fields\": [" + "{\"name\":\"car\", \"type\":\"Lisp\"}," + "{\"name\":\"cdr\", \"type\":\"Lisp\"}]}]}]}", "U1S10" }, { "{\"type\": \"record\", \"name\": \"Lisp\", \"fields\": [" + "{\"name\":\"value\", \"type\":[\"null\", \"string\"," + "{\"type\": \"record\", \"name\": \"Cons\", \"fields\": [" + "{\"name\":\"car\", \"type\":\"Lisp\"}," + "{\"name\":\"cdr\", \"type\":\"Lisp\"}]}]}]}", "U2U1S10U0N" },     { "{\"type\": \"record\", \"name\": \"Node\", \"fields\": [" + "{\"name\":\"children\", \"type\":" + "{\"type\": \"array\", \"items\": \"Node\" }}]}", "[c1s[c1s[c1s[c1s[c1s[c1s[c1s[c1s[c1s[c1s[c1s[]]]]]]]]]]]]" } };}
0
 static void dump(byte[] bb)
{    int col = 0;    for (byte b : bb) {        if (col % 16 == 0) {            System.out.println();        }        col++;        System.out.print(Integer.toHexString(b & 0xff) + " ");    }    System.out.println();}
0
 static void print(Encoding encoding, int skipLevel, Schema writerSchema, Schema readerSchema, Object[] writtenValues, Object[] expectedValues)
{        printSchemaAndValues("Writer", writerSchema, writtenValues);    printSchemaAndValues("Reader", readerSchema, expectedValues);}
1
private static void printSchemaAndValues(String schemaType, Schema schema, Object[] values)
{        for (Object value : values) {            }}
1
public void testByteBufferRoundTrip() throws Exception
{    MessageEncoder<Record> encoder = new BinaryMessageEncoder<>(GenericData.get(), SCHEMA_V2);    MessageDecoder<Record> decoder = new BinaryMessageDecoder<>(GenericData.get(), SCHEMA_V2);    Record copy = decoder.decode(encoder.encode(V2_RECORDS.get(0)));    Assert.assertNotSame("Copy should not be the same object", copy, V2_RECORDS.get(0));    Assert.assertEquals("Record should be identical after round-trip", V2_RECORDS.get(0), copy);}
0
public void testSchemaEvolution() throws Exception
{    List<ByteBuffer> buffers = new ArrayList<>();    List<Record> records = new ArrayList<>();    records.addAll(V1_RECORDS);    records.addAll(V2_RECORDS);    MessageEncoder<Record> v1Encoder = new BinaryMessageEncoder<>(GenericData.get(), SCHEMA_V1);    MessageEncoder<Record> v2Encoder = new BinaryMessageEncoder<>(GenericData.get(), SCHEMA_V2);    for (Record record : records) {        if (record.getSchema().equals(SCHEMA_V1)) {            buffers.add(v1Encoder.encode(record));        } else {            buffers.add(v2Encoder.encode(record));        }    }    Set<Record> allAsV2 = new HashSet<>(V2_RECORDS);    allAsV2.add(V2_BUILDER.set("id", 1L).set("message", "m-1").clear("data").build());    allAsV2.add(V2_BUILDER.set("id", 2L).set("message", "m-2").clear("data").build());    allAsV2.add(V2_BUILDER.set("id", 4L).set("message", "m-4").clear("data").build());    allAsV2.add(V2_BUILDER.set("id", 6L).set("message", "m-6").clear("data").build());    BinaryMessageDecoder<Record> v2Decoder = new BinaryMessageDecoder<>(GenericData.get(), SCHEMA_V2);    v2Decoder.addSchema(SCHEMA_V1);    Set<Record> decodedUsingV2 = new HashSet<>();    for (ByteBuffer buffer : buffers) {        decodedUsingV2.add(v2Decoder.decode(buffer));    }    Assert.assertEquals(allAsV2, decodedUsingV2);}
0
public void testCompatibleReadFailsWithoutSchema() throws Exception
{    MessageEncoder<Record> v1Encoder = new BinaryMessageEncoder<>(GenericData.get(), SCHEMA_V1);    BinaryMessageDecoder<Record> v2Decoder = new BinaryMessageDecoder<>(GenericData.get(), SCHEMA_V2);    ByteBuffer v1Buffer = v1Encoder.encode(V1_RECORDS.get(3));    v2Decoder.decode(v1Buffer);}
0
public void testCompatibleReadWithSchema() throws Exception
{    MessageEncoder<Record> v1Encoder = new BinaryMessageEncoder<>(GenericData.get(), SCHEMA_V1);    BinaryMessageDecoder<Record> v2Decoder = new BinaryMessageDecoder<>(GenericData.get(), SCHEMA_V2);    v2Decoder.addSchema(SCHEMA_V1);    ByteBuffer v1Buffer = v1Encoder.encode(V1_RECORDS.get(3));    Record record = v2Decoder.decode(v1Buffer);    Assert.assertEquals(V2_BUILDER.set("id", 6L).set("message", "m-6").clear("data").build(), record);}
0
public void testCompatibleReadWithSchemaFromLookup() throws Exception
{    MessageEncoder<Record> v1Encoder = new BinaryMessageEncoder<>(GenericData.get(), SCHEMA_V1);    SchemaStore.Cache schemaCache = new SchemaStore.Cache();    schemaCache.addSchema(SCHEMA_V1);    BinaryMessageDecoder<Record> v2Decoder = new BinaryMessageDecoder<>(GenericData.get(), SCHEMA_V2, schemaCache);    ByteBuffer v1Buffer = v1Encoder.encode(V1_RECORDS.get(2));    Record record = v2Decoder.decode(v1Buffer);    Assert.assertEquals(V2_BUILDER.set("id", 4L).set("message", "m-4").clear("data").build(), record);}
0
public void testIdenticalReadWithSchemaFromLookup() throws Exception
{    MessageEncoder<Record> v1Encoder = new BinaryMessageEncoder<>(GenericData.get(), SCHEMA_V1);    SchemaStore.Cache schemaCache = new SchemaStore.Cache();    schemaCache.addSchema(SCHEMA_V1);            BinaryMessageDecoder<Record> genericDecoder = new BinaryMessageDecoder<>(GenericData.get(), null, schemaCache);    ByteBuffer v1Buffer = v1Encoder.encode(V1_RECORDS.get(2));    Record record = genericDecoder.decode(v1Buffer);    Assert.assertEquals(V1_RECORDS.get(2), record);}
0
public void testBufferReuse() throws Exception
{                MessageEncoder<Record> encoder = new BinaryMessageEncoder<>(GenericData.get(), SCHEMA_V1, false);    ByteBuffer b0 = encoder.encode(V1_RECORDS.get(0));    ByteBuffer b1 = encoder.encode(V1_RECORDS.get(1));    Assert.assertEquals(b0.array(), b1.array());    MessageDecoder<Record> decoder = new BinaryMessageDecoder<>(GenericData.get(), SCHEMA_V1);    Assert.assertEquals("Buffer was reused, decode(b0) should be record 1", V1_RECORDS.get(1), decoder.decode(b0));}
0
public void testBufferCopy() throws Exception
{    MessageEncoder<Record> encoder = new BinaryMessageEncoder<>(GenericData.get(), SCHEMA_V1);    ByteBuffer b0 = encoder.encode(V1_RECORDS.get(0));    ByteBuffer b1 = encoder.encode(V1_RECORDS.get(1));    Assert.assertNotEquals(b0.array(), b1.array());    MessageDecoder<Record> decoder = new BinaryMessageDecoder<>(GenericData.get(), SCHEMA_V1);        Assert.assertEquals("Buffer was copied, decode(b0) should be record 0", V1_RECORDS.get(0), decoder.decode(b0));}
0
public void testByteBufferMissingPayload() throws Exception
{    MessageEncoder<Record> encoder = new BinaryMessageEncoder<>(GenericData.get(), SCHEMA_V2);    MessageDecoder<Record> decoder = new BinaryMessageDecoder<>(GenericData.get(), SCHEMA_V2);    ByteBuffer buffer = encoder.encode(V2_RECORDS.get(0));    buffer.limit(12);    decoder.decode(buffer);}
0
public void testByteBufferMissingFullHeader() throws Exception
{    MessageEncoder<Record> encoder = new BinaryMessageEncoder<>(GenericData.get(), SCHEMA_V2);    MessageDecoder<Record> decoder = new BinaryMessageDecoder<>(GenericData.get(), SCHEMA_V2);    ByteBuffer buffer = encoder.encode(V2_RECORDS.get(0));    buffer.limit(8);    decoder.decode(buffer);}
0
public void testByteBufferBadMarkerByte() throws Exception
{    MessageEncoder<Record> encoder = new BinaryMessageEncoder<>(GenericData.get(), SCHEMA_V2);    MessageDecoder<Record> decoder = new BinaryMessageDecoder<>(GenericData.get(), SCHEMA_V2);    ByteBuffer buffer = encoder.encode(V2_RECORDS.get(0));    buffer.array()[0] = 0x00;    decoder.decode(buffer);}
0
public void testByteBufferBadVersionByte() throws Exception
{    MessageEncoder<Record> encoder = new BinaryMessageEncoder<>(GenericData.get(), SCHEMA_V2);    MessageDecoder<Record> decoder = new BinaryMessageDecoder<>(GenericData.get(), SCHEMA_V2);    ByteBuffer buffer = encoder.encode(V2_RECORDS.get(0));    buffer.array()[1] = 0x00;    decoder.decode(buffer);}
0
public void testByteBufferUnknownSchema() throws Exception
{    MessageEncoder<Record> encoder = new BinaryMessageEncoder<>(GenericData.get(), SCHEMA_V2);    MessageDecoder<Record> decoder = new BinaryMessageDecoder<>(GenericData.get(), SCHEMA_V2);    ByteBuffer buffer = encoder.encode(V2_RECORDS.get(0));    buffer.array()[4] = 0x00;    decoder.decode(buffer);}
0
public void before() throws IOException
{    content = new File(DIR.getRoot().getPath(), "test-content");    try (FileOutputStream out = new FileOutputStream(content)) {        for (int i = 0; i < 100000; i++) {            out.write("hello world\n".getBytes(UTF_8));        }    }}
0
public void test() throws Exception
{    Schema schema = ReflectData.get().getSchema(X.class);    ByteArrayOutputStream bout = new ByteArrayOutputStream();    writeOneXAsAvro(schema, bout);    X record = readOneXFromAvro(schema, bout);    String expected = getmd5(content);    String actual = getmd5(record.content);    assertEquals("md5 for result differed from input", expected, actual);}
0
private X readOneXFromAvro(Schema schema, ByteArrayOutputStream bout) throws IOException
{    SeekableByteArrayInput input = new SeekableByteArrayInput(bout.toByteArray());    ReflectDatumReader<X> datumReader = new ReflectDatumReader<>(schema);    FileReader<X> reader = DataFileReader.openReader(input, datumReader);    Iterator<X> it = reader.iterator();    assertTrue("missing first record", it.hasNext());    X record = it.next();    assertFalse("should be no more records - only wrote one out", it.hasNext());    return record;}
0
private void writeOneXAsAvro(Schema schema, ByteArrayOutputStream bout) throws IOException, FileNotFoundException
{    DatumWriter<X> datumWriter = new ReflectDatumWriter<>(schema);    try (DataFileWriter<X> writer = new DataFileWriter<>(datumWriter)) {        writer.create(schema, bout);        X x = new X();        x.name = "xxx";        try (FileInputStream fis = new FileInputStream(content)) {            try (FileChannel channel = fis.getChannel()) {                long contentLength = content.length();                                ByteBuffer buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, contentLength);                x.content = buffer;                writer.append(x);            }        }        writer.flush();    }}
0
private String getmd5(File content) throws Exception
{    try (FileInputStream fis = new FileInputStream(content)) {        try (FileChannel channel = fis.getChannel()) {            long contentLength = content.length();            ByteBuffer buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, contentLength);            return getmd5(buffer);        }    }}
0
 String getmd5(ByteBuffer buffer) throws NoSuchAlgorithmException
{    MessageDigest mdEnc = MessageDigest.getInstance("MD5");    mdEnc.reset();    mdEnc.update(buffer);    return new BigInteger(1, mdEnc.digest()).toString(16);}
0
public void testNonStringMapKeys() throws Exception
{    Company entityObj1 = buildCompany();    Company entityObj2 = buildCompany();    String testType = "NonStringKeysTest";    Company[] entityObjs = { entityObj1, entityObj2 };    byte[] bytes = testSerialization(testType, entityObj1, entityObj2);    List<GenericRecord> records = testGenericDatumRead(testType, bytes, entityObjs);    GenericRecord record = records.get(0);    Object employees = record.get("employees");    assertTrue("Unable to read 'employees' map", employees instanceof GenericArray);    GenericArray arrayEmployees = ((GenericArray) employees);    Object employeeRecord = arrayEmployees.get(0);    assertTrue(employeeRecord instanceof GenericRecord);    Object key = ((GenericRecord) employeeRecord).get(ReflectData.NS_MAP_KEY);    Object value = ((GenericRecord) employeeRecord).get(ReflectData.NS_MAP_VALUE);    assertTrue(key instanceof GenericRecord);    assertTrue(value instanceof GenericRecord);        Object id = ((GenericRecord) key).get("id");    Object name = ((GenericRecord) value).get("name").toString();    assertTrue((id.equals(1) && name.equals("Foo")) || (id.equals(2) && name.equals("Bar")));    List<Company> records2 = testReflectDatumRead(testType, bytes, entityObjs);    Company co = records2.get(0);    log("Read: " + co);    assertNotNull(co.getEmployees());    assertEquals(2, co.getEmployees().size());    for (Entry<EmployeeId, EmployeeInfo> e : co.getEmployees().entrySet()) {        id = e.getKey().getId();        name = e.getValue().getName();        assertTrue((id.equals(1) && name.equals("Foo")) || (id.equals(2) && name.equals("Bar")));    }    byte[] jsonBytes = testJsonEncoder(testType, entityObj1);    assertNotNull("Unable to serialize using jsonEncoder", jsonBytes);    GenericRecord jsonRecord = testJsonDecoder(testType, jsonBytes, entityObj1);    assertEquals("JSON decoder output not same as Binary Decoder", record, jsonRecord);}
0
public void testNonStringMapKeysInNestedMaps() throws Exception
{    Company2 entityObj1 = buildCompany2();    String testType = "NestedMapsTest";    Company2[] entityObjs = { entityObj1 };    byte[] bytes = testSerialization(testType, entityObj1);    List<GenericRecord> records = testGenericDatumRead(testType, bytes, entityObjs);    GenericRecord record = records.get(0);    Object employees = record.get("employees");    assertTrue("Unable to read 'employees' map", employees instanceof GenericArray);    GenericArray employeesMapArray = ((GenericArray) employees);    Object employeeMapElement = employeesMapArray.get(0);    assertTrue(employeeMapElement instanceof GenericRecord);    Object key = ((GenericRecord) employeeMapElement).get(ReflectData.NS_MAP_KEY);    Object value = ((GenericRecord) employeeMapElement).get(ReflectData.NS_MAP_VALUE);    assertEquals(11, key);    assertTrue(value instanceof GenericRecord);    GenericRecord employeeInfo = (GenericRecord) value;    Object name = employeeInfo.get("name").toString();    assertEquals("Foo", name);    Object companyMap = employeeInfo.get("companyMap");    assertTrue(companyMap instanceof GenericArray);    GenericArray companyMapArray = (GenericArray) companyMap;    Object companyMapElement = companyMapArray.get(0);    assertTrue(companyMapElement instanceof GenericRecord);    key = ((GenericRecord) companyMapElement).get(ReflectData.NS_MAP_KEY);    value = ((GenericRecord) companyMapElement).get(ReflectData.NS_MAP_VALUE);    assertEquals(14, key);    if (value instanceof Utf8)        value = ((Utf8) value).toString();    assertEquals("CompanyFoo", value);    List<Company2> records2 = testReflectDatumRead(testType, bytes, entityObjs);    Company2 co = records2.get(0);    log("Read: " + co);    assertNotNull(co.getEmployees());    assertEquals(1, co.getEmployees().size());    for (Entry<Integer, EmployeeInfo2> e : co.getEmployees().entrySet()) {        Integer id = e.getKey();        name = e.getValue().getName();        assertTrue(id.equals(11) && name.equals("Foo"));        assertEquals("CompanyFoo", e.getValue().companyMap.values().iterator().next());    }    byte[] jsonBytes = testJsonEncoder(testType, entityObj1);    assertNotNull("Unable to serialize using jsonEncoder", jsonBytes);    GenericRecord jsonRecord = testJsonDecoder(testType, jsonBytes, entityObj1);    assertEquals("JSON decoder output not same as Binary Decoder", record, jsonRecord);}
0
public void testRecordNameInvariance() throws Exception
{    SameMapSignature entityObj1 = buildSameMapSignature();    String testType = "RecordNameInvariance";    SameMapSignature[] entityObjs = { entityObj1 };    byte[] bytes = testSerialization(testType, entityObj1);    List<GenericRecord> records = testGenericDatumRead(testType, bytes, entityObjs);    GenericRecord record = records.get(0);    Object map1obj = record.get("map1");    assertTrue("Unable to read map1", map1obj instanceof GenericArray);    GenericArray map1array = ((GenericArray) map1obj);    Object map1element = map1array.get(0);    assertTrue(map1element instanceof GenericRecord);    Object key = ((GenericRecord) map1element).get(ReflectData.NS_MAP_KEY);    Object value = ((GenericRecord) map1element).get(ReflectData.NS_MAP_VALUE);    assertEquals(1, key);    assertEquals("Foo", value.toString());    Object map2obj = record.get("map2");    assertEquals(map1obj, map2obj);    List<SameMapSignature> records2 = testReflectDatumRead(testType, bytes, entityObjs);    SameMapSignature entity = records2.get(0);    log("Read: " + entity);    assertNotNull(entity.getMap1());    assertEquals(1, entity.getMap1().size());    for (Entry<Integer, String> e : entity.getMap1().entrySet()) {        key = e.getKey();        value = e.getValue();        assertEquals(1, key);        assertEquals("Foo", value.toString());    }    assertEquals(entity.getMap1(), entity.getMap2());    assertEquals(entity.getMap1(), entity.getMap3());    assertEquals(entity.getMap1(), entity.getMap4());    ReflectData rdata = ReflectData.get();    Schema schema = rdata.getSchema(SameMapSignature.class);    Schema map1schema = schema.getField("map1").schema().getElementType();    Schema map2schema = schema.getField("map2").schema().getElementType();    Schema map3schema = schema.getField("map3").schema().getElementType();    Schema map4schema = schema.getField("map4").schema().getElementType();    log("Schema for map1 = " + map1schema);    log("Schema for map2 = " + map2schema);    log("Schema for map3 = " + map3schema);    log("Schema for map4 = " + map4schema);    assertEquals(map1schema.getFullName(), "org.apache.avro.reflect.PairIntegerString");    assertEquals(map1schema, map2schema);    assertEquals(map1schema, map3schema);    assertEquals(map1schema, map4schema);    byte[] jsonBytes = testJsonEncoder(testType, entityObj1);    assertNotNull("Unable to serialize using jsonEncoder", jsonBytes);    GenericRecord jsonRecord = testJsonDecoder(testType, jsonBytes, entityObj1);    assertEquals("JSON decoder output not same as Binary Decoder", record.get("map1"), jsonRecord.get("map1"));    assertEquals("JSON decoder output not same as Binary Decoder", record.get("map2"), jsonRecord.get("map2"));}
0
public byte[] testSerialization(String testType, T... entityObjs) throws Exception
{    log("---- Beginning " + testType + " ----");    T entityObj1 = entityObjs[0];    ReflectData rdata = ReflectData.AllowNull.get();    Schema schema = rdata.getSchema(entityObj1.getClass());    assertNotNull("Unable to get schema for " + testType, schema);    log(schema.toString(true));    ReflectDatumWriter<T> datumWriter = new ReflectDatumWriter(entityObj1.getClass(), rdata);    DataFileWriter<T> fileWriter = new DataFileWriter<>(datumWriter);    ByteArrayOutputStream baos = new ByteArrayOutputStream();    fileWriter.create(schema, baos);    for (T entityObj : entityObjs) {        fileWriter.append(entityObj);    }    fileWriter.close();    byte[] bytes = baos.toByteArray();    return bytes;}
0
private List<GenericRecord> testGenericDatumRead(String testType, byte[] bytes, T... entityObjs) throws IOException
{    GenericDatumReader<GenericRecord> datumReader = new GenericDatumReader<>();    SeekableByteArrayInput avroInputStream = new SeekableByteArrayInput(bytes);    DataFileReader<GenericRecord> fileReader = new DataFileReader<>(avroInputStream, datumReader);    Schema schema = fileReader.getSchema();    assertNotNull("Unable to get schema for " + testType, schema);    GenericRecord record = null;    List<GenericRecord> records = new ArrayList<>();    while (fileReader.hasNext()) {        try {            records.add(fileReader.next(record));        } catch (Exception e) {            fail("Fail with schema: " + schema);        }    }    return records;}
0
private List<T> testReflectDatumRead(String testType, byte[] bytes, T... entityObjs) throws IOException
{    ReflectDatumReader<T> datumReader = new ReflectDatumReader<>();    SeekableByteArrayInput avroInputStream = new SeekableByteArrayInput(bytes);    DataFileReader<T> fileReader = new DataFileReader<>(avroInputStream, datumReader);    Schema schema = fileReader.getSchema();    T record = null;    List<T> records = new ArrayList<>();    while (fileReader.hasNext()) {        records.add(fileReader.next(record));    }    return records;}
0
private byte[] testJsonEncoder(String testType, T entityObj) throws IOException
{    ReflectData rdata = ReflectData.AllowNull.get();    Schema schema = rdata.getSchema(entityObj.getClass());    ByteArrayOutputStream os = new ByteArrayOutputStream();    Encoder encoder = EncoderFactory.get().jsonEncoder(schema, os);    ReflectDatumWriter<T> datumWriter = new ReflectDatumWriter<>(schema, rdata);    datumWriter.write(entityObj, encoder);    encoder.flush();    byte[] bytes = os.toByteArray();    System.out.println("JSON encoder output:\n" + new String(bytes, UTF_8));    return bytes;}
0
private GenericRecord testJsonDecoder(String testType, byte[] bytes, T entityObj) throws IOException
{    ReflectData rdata = ReflectData.AllowNull.get();    Schema schema = rdata.getSchema(entityObj.getClass());    GenericDatumReader<GenericRecord> datumReader = new GenericDatumReader<>(schema);    Decoder decoder = DecoderFactory.get().jsonDecoder(schema, new String(bytes, UTF_8));    GenericRecord r = datumReader.read(null, decoder);    return r;}
0
private Company buildCompany()
{    Company co = new Company();    HashMap<EmployeeId, EmployeeInfo> employees = new HashMap<>();    co.setEmployees(employees);    employees.put(new EmployeeId(1), new EmployeeInfo("Foo"));    employees.put(new EmployeeId(2), new EmployeeInfo("Bar"));    return co;}
0
private Company2 buildCompany2()
{    Company2 co = new Company2();    HashMap<Integer, EmployeeInfo2> employees = new HashMap<>();    co.setEmployees(employees);    EmployeeId2 empId = new EmployeeId2(1);    EmployeeInfo2 empInfo = new EmployeeInfo2("Foo");    HashMap<Integer, String> companyMap = new HashMap<>();    empInfo.setCompanyMap(companyMap);    companyMap.put(14, "CompanyFoo");    employees.put(11, empInfo);    return co;}
0
private SameMapSignature buildSameMapSignature()
{    SameMapSignature obj = new SameMapSignature();    obj.setMap1(new HashMap<>());    obj.getMap1().put(1, "Foo");    obj.setMap2(new ConcurrentHashMap<>());    obj.getMap2().put(1, "Foo");    obj.setMap3(new LinkedHashMap<>());    obj.getMap3().put(1, "Foo");    obj.setMap4(new TreeMap<>());    obj.getMap4().put(1, "Foo");    return obj;}
0
private void log(String msg)
{    System.out.println(msg);}
0
public HashMap<EmployeeId, EmployeeInfo> getEmployees()
{    return employees;}
0
public void setEmployees(HashMap<EmployeeId, EmployeeInfo> employees)
{    this.employees = employees;}
0
public String toString()
{    return "Company [employees=" + employees + "]";}
0
public Integer getId()
{    return id;}
0
public void setId(Integer zip)
{    this.id = zip;}
0
public String toString()
{    return "EmployeeId [id=" + id + "]";}
0
public String getName()
{    return name;}
0
public void setName(String name)
{    this.name = name;}
0
public String toString()
{    return "EmployeeInfo [name=" + name + "]";}
0
public HashMap<Integer, EmployeeInfo2> getEmployees()
{    return employees;}
0
public void setEmployees(HashMap<Integer, EmployeeInfo2> employees)
{    this.employees = employees;}
0
public String toString()
{    return "Company2 [employees=" + employees + "]";}
0
public Integer getId()
{    return id;}
0
public void setId(Integer zip)
{    this.id = zip;}
0
public String toString()
{    return "EmployeeId2 [id=" + id + "]";}
0
public String getName()
{    return name;}
0
public void setName(String name)
{    this.name = name;}
0
public HashMap<Integer, String> getCompanyMap()
{    return companyMap;}
0
public void setCompanyMap(HashMap<Integer, String> companyMap)
{    this.companyMap = companyMap;}
0
public String toString()
{    return "EmployeeInfo2 [name=" + name + "]";}
0
public Map<Integer, String> getMap1()
{    return map1;}
0
public void setMap1(HashMap<Integer, String> map1)
{    this.map1 = map1;}
0
public Map<Integer, String> getMap2()
{    return map2;}
0
public void setMap2(ConcurrentHashMap<Integer, String> map2)
{    this.map2 = map2;}
0
public Map<Integer, String> getMap3()
{    return map3;}
0
public void setMap3(LinkedHashMap<Integer, String> map3)
{    this.map3 = map3;}
0
public Map<Integer, String> getMap4()
{    return map4;}
0
public void setMap4(TreeMap<Integer, String> map4)
{    this.map4 = map4;}
0
public void testVoid()
{    check(Void.TYPE, "\"null\"");    check(Void.class, "\"null\"");}
0
public void testBoolean()
{    check(Boolean.TYPE, "\"boolean\"");    check(Boolean.class, "\"boolean\"");}
0
public void testInt()
{    check(Integer.TYPE, "\"int\"");    check(Integer.class, "\"int\"");}
0
public void testByte()
{    check(Byte.TYPE, "{\"type\":\"int\",\"java-class\":\"java.lang.Byte\"}");    check(Byte.class, "{\"type\":\"int\",\"java-class\":\"java.lang.Byte\"}");}
0
public void testShort()
{    check(Short.TYPE, "{\"type\":\"int\",\"java-class\":\"java.lang.Short\"}");    check(Short.class, "{\"type\":\"int\",\"java-class\":\"java.lang.Short\"}");}
0
public void testChar()
{    check(Character.TYPE, "{\"type\":\"int\",\"java-class\":\"java.lang.Character\"}");    check(Character.class, "{\"type\":\"int\",\"java-class\":\"java.lang.Character\"}");}
0
public void testLong()
{    check(Long.TYPE, "\"long\"");    check(Long.class, "\"long\"");}
0
public void testFloat()
{    check(Float.TYPE, "\"float\"");    check(Float.class, "\"float\"");}
0
public void testDouble()
{    check(Double.TYPE, "\"double\"");    check(Double.class, "\"double\"");}
0
public void testString()
{    check("Foo", "\"string\"");}
0
public void testBytes()
{    check(ByteBuffer.allocate(0), "\"bytes\"");    check(new byte[0], "{\"type\":\"bytes\",\"java-class\":\"[B\"}");}
0
public void testUnionWithCollection()
{    Schema s = new Schema.Parser().parse("[\"null\", {\"type\":\"array\",\"items\":\"float\"}]");    GenericData data = ReflectData.get();    assertEquals(1, data.resolveUnion(s, new ArrayList<Float>()));}
0
public void testUnionWithMap()
{    Schema s = new Schema.Parser().parse("[\"null\", {\"type\":\"map\",\"values\":\"float\"}]");    GenericData data = ReflectData.get();    assertEquals(1, data.resolveUnion(s, new HashMap<String, Float>()));}
0
public void testUnionWithMapWithUtf8Keys()
{    Schema s = new Schema.Parser().parse("[\"null\", {\"type\":\"map\",\"values\":\"float\"}]");    GenericData data = ReflectData.get();    HashMap<Utf8, Float> map = new HashMap<>();    map.put(new Utf8("foo"), 1.0f);    assertEquals(1, data.resolveUnion(s, map));}
0
public void testUnionWithFixed()
{    Schema s = new Schema.Parser().parse("[\"null\", {\"type\":\"fixed\",\"name\":\"f\",\"size\":1}]");    Schema f = new Schema.Parser().parse("{\"type\":\"fixed\",\"name\":\"f\",\"size\":1}");    GenericData data = ReflectData.get();    assertEquals(1, data.resolveUnion(s, new GenericData.Fixed(f)));}
0
public void testUnionWithEnum()
{    Schema s = new Schema.Parser().parse("[\"null\", {\"type\":\"enum\",\"name\":\"E\",\"namespace\":" + "\"org.apache.avro.reflect.TestReflect\",\"symbols\":[\"A\",\"B\"]}]");    GenericData data = ReflectData.get();    assertEquals(1, data.resolveUnion(s, E.A));}
0
public void testUnionWithBytes()
{    Schema s = new Schema.Parser().parse("[\"null\", \"bytes\"]");    GenericData data = ReflectData.get();    assertEquals(1, data.resolveUnion(s, ByteBuffer.wrap(new byte[] { 1 })));}
0
public boolean equals(Object o)
{    if (!(o instanceof R1))        return false;    R1 that = (R1) o;    return mapField.equals(that.mapField) && Arrays.equals(this.arrayField, that.arrayField) && listField.equals(that.listField);}
0
public void testMap() throws Exception
{    check(R1.class.getDeclaredField("mapField").getGenericType(), "{\"type\":\"map\",\"values\":\"string\"}");}
0
public void testArray() throws Exception
{    check(R1.class.getDeclaredField("arrayField").getGenericType(), "{\"type\":\"array\",\"items\":\"string\",\"java-class\":\"[Ljava.lang.String;\"}");}
0
public void testList() throws Exception
{    check(R1.class.getDeclaredField("listField").getGenericType(), "{\"type\":\"array\",\"items\":\"string\"" + ",\"java-class\":\"java.util.List\"}");}
0
public void testR1() throws Exception
{    checkReadWrite(new R1());}
0
public boolean equals(Object o)
{    if (!(o instanceof R2))        return false;    R2 that = (R2) o;    return Arrays.equals(this.arrayField, that.arrayField) && collectionField.equals(that.collectionField);}
0
public void testR2() throws Exception
{    R2 r2 = new R2();    r2.arrayField = new String[] { "foo" };    r2.collectionField = new ArrayList<>();    r2.collectionField.add("foo");    checkReadWrite(r2);}
0
public boolean equals(Object o)
{    if (!(o instanceof R3))        return false;    R3 that = (R3) o;    return Arrays.equals(this.intArray, that.intArray);}
0
public void testR3() throws Exception
{    R3 r3 = new R3();    r3.intArray = new int[] { 1 };    checkReadWrite(r3);}
0
public boolean equals(Object o)
{    if (!(o instanceof R4))        return false;    R4 that = (R4) o;    return this.value == that.value && Arrays.equals(this.shorts, that.shorts) && this.b == that.b && this.c == that.c;}
0
public void testR5() throws Exception
{    R5 r5 = new R5();    r5.value = 1;    r5.shorts = new short[] { 3, 255, 256, Short.MAX_VALUE, Short.MIN_VALUE };    r5.b = 99;    r5.c = 'a';    checkReadWrite(r5);}
0
public boolean equals(Object o)
{    if (!(o instanceof R7))        return false;    return this.value == ((R7) o).value;}
0
public boolean equals(Object o)
{    if (!(o instanceof R8))        return false;    return this.value == ((R8) o).value;}
0
public boolean equals(Object o)
{    if (!(o instanceof R9))        return false;    return Arrays.equals(this.r6s, ((R9) o).r6s);}
0
public void testR6() throws Exception
{    R7 r7 = new R7();    r7.value = 1;    checkReadWrite(r7, ReflectData.get().getSchema(R6.class));    R8 r8 = new R8();    r8.value = 1;    checkReadWrite(r8, ReflectData.get().getSchema(R6.class));    R9 r9 = new R9();    r9.r6s = new R6[] { r7, r8 };    checkReadWrite(r9, ReflectData.get().getSchema(R9.class));}
0
public boolean equals(Object o)
{    if (!(o instanceof R9_1))        return false;    if (this.value == null)        return ((R9_1) o).value == null;    return this.value.equals(((R9_1) o).value);}
0
public void testR6_1() throws Exception
{    R7 r7 = new R7();    r7.value = 1;    checkReadWrite(r7, ReflectData.get().getSchema(R6.class));    R8 r8 = new R8();    r8.value = 1;    checkReadWrite(r8, ReflectData.get().getSchema(R6.class));    R9_1 r9_1 = new R9_1();    r9_1.value = null;    checkReadWrite(r9_1, ReflectData.get().getSchema(R9_1.class));    r9_1.value = r7;    checkReadWrite(r9_1, ReflectData.get().getSchema(R9_1.class));    r9_1.value = r8;    checkReadWrite(r9_1, ReflectData.get().getSchema(R9_1.class));}
0
public void testP0() throws Exception
{    Protocol p0 = ReflectData.get().getProtocol(P0.class);    Protocol.Message message = p0.getMessages().get("foo");        Schema response = message.getResponse();    assertEquals(Schema.Type.UNION, response.getType());    assertEquals(Schema.Type.NULL, response.getTypes().get(0).getType());    assertEquals(Schema.Type.STRING, response.getTypes().get(1).getType());        Schema request = message.getRequest();    Field field = request.getField("s");    assertNotNull("field 's' should not be null", field);    Schema param = field.schema();    assertEquals(Schema.Type.UNION, param.getType());    assertEquals(Schema.Type.NULL, param.getTypes().get(0).getType());    assertEquals(Schema.Type.STRING, param.getTypes().get(1).getType());        assertEquals(String.class, ReflectData.get().getClass(response));    assertEquals(String.class, ReflectData.get().getClass(param));}
0
public String toString()
{    return text;}
0
public boolean equals(Object o)
{    if (!(o instanceof R10))        return false;    return this.text.equals(((R10) o).text);}
0
public void testR10() throws Exception
{    Schema r10Schema = ReflectData.get().getSchema(R10.class);    assertEquals(Schema.Type.STRING, r10Schema.getType());    assertEquals(R10.class.getName(), r10Schema.getProp("java-class"));    checkReadWrite(new R10("foo"), r10Schema);}
0
public boolean equals(Object o)
{    if (!(o instanceof R11))        return false;    R11 that = (R11) o;    if (this.text == null)        return that.text == null;    return this.text.equals(that.text);}
0
public void testR11() throws Exception
{    Schema r11Record = ReflectData.get().getSchema(R11.class);    assertEquals(Schema.Type.RECORD, r11Record.getType());    Field r11Field = r11Record.getField("text");    assertEquals(JsonProperties.NULL_VALUE, r11Field.defaultVal());    Schema r11FieldSchema = r11Field.schema();    assertEquals(Schema.Type.UNION, r11FieldSchema.getType());    assertEquals(Schema.Type.NULL, r11FieldSchema.getTypes().get(0).getType());    Schema r11String = r11FieldSchema.getTypes().get(1);    assertEquals(Schema.Type.STRING, r11String.getType());    R11 r11 = new R11();    checkReadWrite(r11, r11Record);    r11.text = "foo";    checkReadWrite(r11, r11Record);}
0
public void testP1() throws Exception
{    Protocol p1 = ReflectData.get().getProtocol(P1.class);    Protocol.Message message = p1.getMessages().get("foo");        Schema response = message.getResponse();    assertEquals(Schema.Type.UNION, response.getType());    assertEquals(Schema.Type.NULL, response.getTypes().get(0).getType());    assertEquals(Schema.Type.STRING, response.getTypes().get(1).getType());        Schema request = message.getRequest();    Field field = request.getField("s");    assertNotNull("field 's' should not be null", field);    Schema param = field.schema();    assertEquals(Schema.Type.UNION, param.getType());    assertEquals(Schema.Type.NULL, param.getTypes().get(0).getType());    assertEquals(Schema.Type.STRING, param.getTypes().get(1).getType());        assertEquals(String.class, ReflectData.get().getClass(response));    assertEquals(String.class, ReflectData.get().getClass(param));}
0
public void testR12() throws Exception
{    Schema s = ReflectData.get().getSchema(R12.class);    assertEquals(Schema.Type.INT, s.getField("x").schema().getType());    assertEquals(new Schema.Parser().parse("{\"type\":\"array\",\"items\":[\"null\",\"string\"]}"), s.getField("strings").schema());}
0
public void testR13() throws Exception
{    Schema s = ReflectData.get().getSchema(R13.class);    assertEquals(Schema.Type.NULL, s.getType());}
0
public void testP4() throws Exception
{    Protocol p = ReflectData.get().getProtocol(P4.class);    Protocol.Message message = p.getMessages().get("foo");    assertEquals(Schema.Type.INT, message.getResponse().getType());    Field field = message.getRequest().getField("x");    assertEquals(Schema.Type.INT, field.schema().getType());}
0
public void testP2() throws Exception
{    Schema e1 = ReflectData.get().getSchema(E1.class);    assertEquals(Schema.Type.RECORD, e1.getType());    assertTrue(e1.isError());    Field message = e1.getField("detailMessage");    assertNotNull("field 'detailMessage' should not be null", message);    Schema messageSchema = message.schema();    assertEquals(Schema.Type.UNION, messageSchema.getType());    assertEquals(Schema.Type.NULL, messageSchema.getTypes().get(0).getType());    assertEquals(Schema.Type.STRING, messageSchema.getTypes().get(1).getType());    Protocol p2 = ReflectData.get().getProtocol(P2.class);    Protocol.Message m = p2.getMessages().get("error");        Schema response = m.getErrors();    assertEquals(Schema.Type.UNION, response.getType());    assertEquals(Schema.Type.STRING, response.getTypes().get(0).getType());    assertEquals(e1, response.getTypes().get(1));}
0
public void testNoPackage() throws Exception
{    Class<?> noPackage = Class.forName("NoPackage");    Schema s = ReflectData.get().getSchema(noPackage);    assertEquals(noPackage.getName(), ReflectData.getClassName(s));}
0
 void checkReadWrite(Object object) throws Exception
{    checkReadWrite(object, ReflectData.get().getSchema(object.getClass()));}
0
 void checkReadWrite(Object object, Schema s) throws Exception
{    ReflectDatumWriter<Object> writer = new ReflectDatumWriter<>(s);    ByteArrayOutputStream out = new ByteArrayOutputStream();    writer.write(object, factory.directBinaryEncoder(out, null));    ReflectDatumReader<Object> reader = new ReflectDatumReader<>(s);    Object after = reader.read(null, DecoderFactory.get().binaryDecoder(out.toByteArray(), null));    assertEquals(object, after);        if (s.getType().equals(Schema.Type.RECORD)) {        Object copy = object.getClass().getDeclaredConstructor().newInstance();        for (Field f : s.getFields()) {            Object val = ReflectData.get().getField(object, f.name(), f.pos());            ReflectData.get().setField(copy, f.name(), f.pos(), val);        }        assertEquals("setField", object, copy);    }}
0
public void testEnum() throws Exception
{    check(E.class, "{\"type\":\"enum\",\"name\":\"E\",\"namespace\":" + "\"org.apache.avro.reflect.TestReflect\",\"symbols\":[\"A\",\"B\"]}");}
0
public void testRecord() throws Exception
{    check(R.class, "{\"type\":\"record\",\"name\":\"R\",\"namespace\":" + "\"org.apache.avro.reflect.TestReflect\",\"fields\":[" + "{\"name\":\"a\",\"type\":\"int\"}," + "{\"name\":\"b\",\"type\":\"long\"}]}");}
0
public void testAnnotationAvroIgnore() throws Exception
{    check(RAvroIgnore.class, "{\"type\":\"record\",\"name\":\"RAvroIgnore\",\"namespace\":" + "\"org.apache.avro.reflect.TestReflect\",\"fields\":[]}");}
0
public void testAnnotationAvroMeta() throws Exception
{    check(RAvroMeta.class, "{\"type\":\"record\",\"name\":\"RAvroMeta\",\"namespace\":" + "\"org.apache.avro.reflect.TestReflect\",\"fields\":[" + "{\"name\":\"a\",\"type\":\"int\",\"K\":\"V\"}]" + ",\"X\":\"Y\"}");}
0
public void testAnnotationMultiAvroMeta()
{    check(RAvroMultiMeta.class, "{\"type\":\"record\",\"name\":\"RAvroMultiMeta\",\"namespace\":" + "\"org.apache.avro.reflect.TestReflect\",\"fields\":[" + "{\"name\":\"a\",\"type\":\"int\",\"K\":\"V\",\"L\":\"W\"}]" + ",\"X\":\"Y\",\"A\":\"B\"}");}
0
public void testAnnotationDuplicateFieldAvroMeta()
{    ReflectData.get().getSchema(RAvroDuplicateFieldMeta.class);}
0
public void testAnnotationDuplicateTypeAvroMeta()
{    ReflectData.get().getSchema(RAvroDuplicateTypeMeta.class);}
0
public void testAnnotationAvroName() throws Exception
{    check(RAvroName.class, "{\"type\":\"record\",\"name\":\"RAvroName\",\"namespace\":" + "\"org.apache.avro.reflect.TestReflect\",\"fields\":[" + "{\"name\":\"b\",\"type\":\"int\"}]}");}
0
public void testAnnotationAvroNameCollide() throws Exception
{    check(RAvroNameCollide.class, "{\"type\":\"record\",\"name\":\"RAvroNameCollide\",\"namespace\":" + "\"org.apache.avro.reflect.TestReflect\",\"fields\":[" + "{\"name\":\"b\",\"type\":\"int\"}," + "{\"name\":\"b\",\"type\":\"int\"}]}");}
0
public void testAnnotationAvroStringableFields() throws Exception
{    check(RAvroStringableField.class, "{\"type\":\"record\",\"name\":\"RAvroStringableField\",\"namespace\":" + "\"org.apache.avro.reflect.TestReflect\",\"fields\":[" + "{\"name\":\"a\",\"type\":\"string\"}]}");}
0
private void check(Object o, String schemaJson)
{    check(o.getClass(), schemaJson);}
0
private void check(java.lang.reflect.Type type, String schemaJson)
{    assertEquals(schemaJson, ReflectData.get().getSchema(type).toString());}
0
public void testRecordIO() throws IOException
{    Schema schm = ReflectData.get().getSchema(SampleRecord.class);    ReflectDatumWriter<SampleRecord> writer = new ReflectDatumWriter<>(schm);    ByteArrayOutputStream out = new ByteArrayOutputStream();    SampleRecord record = new SampleRecord();    record.x = 5;    record.y = 10;    writer.write(record, factory.directBinaryEncoder(out, null));    ReflectDatumReader<SampleRecord> reader = new ReflectDatumReader<>(schm);    SampleRecord decoded = reader.read(null, DecoderFactory.get().binaryDecoder(out.toByteArray(), null));    assertEquals(record, decoded);}
0
public boolean equals(Object o)
{    if (!(o instanceof AvroEncRecord))        return false;    return date.equals(((AvroEncRecord) o).date);}
0
public void testMultipleAnnotations() throws IOException
{    Schema schm = ReflectData.get().getSchema(multipleAnnotationRecord.class);    ReflectDatumWriter<multipleAnnotationRecord> writer = new ReflectDatumWriter<>(schm);    ByteArrayOutputStream out = new ByteArrayOutputStream();    multipleAnnotationRecord record = new multipleAnnotationRecord();    record.i1 = 1;    record.i2 = 2;    record.i3 = 3;    record.i4 = new java.util.Date(4L);    record.i5 = 5;    record.i6 = 6;    record.i7 = new java.util.Date(7L);    record.i8 = 8;    record.i9 = new java.util.Date(9L);    record.i10 = new java.util.Date(10L);    record.i11 = new java.util.Date(11L);    writer.write(record, factory.directBinaryEncoder(out, null));    ReflectDatumReader<multipleAnnotationRecord> reader = new ReflectDatumReader<>(schm);    multipleAnnotationRecord decoded = reader.read(new multipleAnnotationRecord(), DecoderFactory.get().binaryDecoder(out.toByteArray(), null));    assertTrue(decoded.i1 == null);    assertTrue(decoded.i2 == null);    assertTrue(decoded.i3 == null);    assertTrue(decoded.i4 == null);    assertTrue(decoded.i5 == 5);    assertTrue(decoded.i6 == 6);    assertTrue(decoded.i7.getTime() == 7);    assertTrue(decoded.i8 == 8);    assertTrue(decoded.i9.getTime() == 9);    assertTrue(decoded.i10.getTime() == 10);    assertTrue(decoded.i11.getTime() == 11);}
0
public void testAvroEncodeInducing() throws IOException
{    Schema schm = ReflectData.get().getSchema(AvroEncRecord.class);    assertEquals(schm.toString(), "{\"type\":\"record\",\"name\":\"AvroEncRecord\",\"namespace" + "\":\"org.apache.avro.reflect.TestReflect\",\"fields\":[{\"name\":\"date\"," + "\"type\":{\"type\":\"long\",\"CustomEncoding\":\"DateAsLongEncoding\"}}]}");}
0
public void testAvroEncodeIO() throws IOException
{    Schema schm = ReflectData.get().getSchema(AvroEncRecord.class);    ReflectDatumWriter<AvroEncRecord> writer = new ReflectDatumWriter<>(schm);    ByteArrayOutputStream out = new ByteArrayOutputStream();    AvroEncRecord record = new AvroEncRecord();    record.date = new java.util.Date(948833323L);    writer.write(record, factory.directBinaryEncoder(out, null));    ReflectDatumReader<AvroEncRecord> reader = new ReflectDatumReader<>(schm);    AvroEncRecord decoded = reader.read(new AvroEncRecord(), DecoderFactory.get().binaryDecoder(out.toByteArray(), null));    assertEquals(record, decoded);}
0
public void testRecordWithNullIO() throws IOException
{    ReflectData reflectData = ReflectData.AllowNull.get();    Schema schm = reflectData.getSchema(AnotherSampleRecord.class);    ReflectDatumWriter<AnotherSampleRecord> writer = new ReflectDatumWriter<>(schm);    ByteArrayOutputStream out = new ByteArrayOutputStream();        Encoder e = factory.directBinaryEncoder(out, null);    AnotherSampleRecord a = new AnotherSampleRecord();    writer.write(a, e);    AnotherSampleRecord b = new AnotherSampleRecord(10);    writer.write(b, e);    e.flush();    ReflectDatumReader<AnotherSampleRecord> reader = new ReflectDatumReader<>(schm);    ByteArrayInputStream in = new ByteArrayInputStream(out.toByteArray());    Decoder d = DecoderFactory.get().binaryDecoder(in, null);    AnotherSampleRecord decoded = reader.read(null, d);    assertEquals(a, decoded);    decoded = reader.read(null, d);    assertEquals(b, decoded);}
0
public void testDisableUnsafe() throws Exception
{    String saved = System.getProperty("avro.disable.unsafe");    try {        System.setProperty("avro.disable.unsafe", "true");        ReflectData.ACCESSOR_CACHE.remove(multipleAnnotationRecord.class);        ReflectData.ACCESSOR_CACHE.remove(AnotherSampleRecord.class);        ReflectionUtil.resetFieldAccess();        testMultipleAnnotations();        testRecordWithNullIO();    } finally {        if (saved == null)            System.clearProperty("avro.disable.unsafe");        else            System.setProperty("avro.disable.unsafe", saved);        ReflectData.ACCESSOR_CACHE.remove(multipleAnnotationRecord.class);        ReflectData.ACCESSOR_CACHE.remove(AnotherSampleRecord.class);        ReflectionUtil.resetFieldAccess();    }}
0
public int hashCode()
{    return x + y;}
0
public boolean equals(Object obj)
{    if (this == obj)        return true;    if (obj == null)        return false;    if (getClass() != obj.getClass())        return false;    final SampleRecord other = (SampleRecord) obj;    if (x != other.x)        return false;    return y == other.y;}
0
public int hashCode()
{    int hash = (a != null ? a.hashCode() : 0);    hash += (s != null ? s.hashCode() : 0);    return hash;}
0
public boolean equals(Object other)
{    if (other instanceof AnotherSampleRecord) {        AnotherSampleRecord o = (AnotherSampleRecord) other;        return (this.a != null || o.a == null) && (this.a == null || this.a.equals(o.a)) && (this.s != null || o.s == null) && (this.s == null || this.s.equals(o.s));    } else {        return false;    }}
0
public void testForwardReference()
{    ReflectData data = ReflectData.get();    Protocol reflected = data.getProtocol(C.class);    Protocol reparsed = Protocol.parse(reflected.toString());    assertEquals(reflected, reparsed);    assert (reparsed.getTypes().contains(data.getSchema(A.class)));    assert (reparsed.getTypes().contains(data.getSchema(B1.class)));    assert (reparsed.getTypes().contains(data.getSchema(B2.class)));    assert (reparsed.getTypes().contains(data.getSchema(X.class)));}
0
public void testOverloadedMethod()
{    ReflectData.get().getProtocol(P3.class);}
0
public void testNoPackageSchema() throws Exception
{    ReflectData.get().getSchema(Class.forName("NoPackage"));}
0
public void testNoPackageProtocol() throws Exception
{    ReflectData.get().getProtocol(Class.forName("NoPackage"));}
0
public void testReflectWithinGeneric() throws Exception
{    ReflectData data = ReflectData.get();        Schema schema = Schema.createRecord("Foo", "", "x.y.z", false);    List<Schema.Field> fields = new ArrayList<>();    fields.add(new Schema.Field("f", data.getSchema(Y.class), "", null));    schema.setFields(fields);        Y y = new Y();    y.i = 1;    GenericData.Record record = new GenericData.Record(schema);    record.put("f", y);        checkBinary(schema, record);}
0
public void testPrimitiveArray() throws Exception
{    testPrimitiveArrays(false);}
0
public void testPrimitiveArrayBlocking() throws Exception
{    testPrimitiveArrays(true);}
0
private void testPrimitiveArrays(boolean blocking) throws Exception
{    testPrimitiveArray(boolean.class, blocking);    testPrimitiveArray(byte.class, blocking);    testPrimitiveArray(short.class, blocking);    testPrimitiveArray(char.class, blocking);    testPrimitiveArray(int.class, blocking);    testPrimitiveArray(long.class, blocking);    testPrimitiveArray(float.class, blocking);    testPrimitiveArray(double.class, blocking);}
0
private void testPrimitiveArray(Class<?> c, boolean blocking) throws Exception
{    ReflectData data = new ReflectData();    Random r = new Random();    int size = 200;    Object array = Array.newInstance(c, size);    Schema s = data.getSchema(array.getClass());    for (int i = 0; i < size; i++) {        Array.set(array, i, randomFor(c, r));    }    checkBinary(data, s, array, false, blocking);}
0
private Object randomFor(Class<?> c, Random r)
{    if (c == boolean.class)        return r.nextBoolean();    if (c == int.class)        return r.nextInt();    if (c == long.class)        return r.nextLong();    if (c == byte.class)        return (byte) r.nextInt();    if (c == float.class)        return r.nextFloat();    if (c == double.class)        return r.nextDouble();    if (c == char.class)        return (char) r.nextInt();    if (c == short.class)        return (short) r.nextInt();    return null;}
0
public void testNullArray() throws Exception
{    String json = "[{\"type\":\"array\", \"items\": \"long\"}, \"null\"]";    Schema schema = new Schema.Parser().parse(json);    checkBinary(schema, null);}
0
public void testStringables() throws Exception
{    checkStringable(java.math.BigDecimal.class, "10");    checkStringable(java.math.BigInteger.class, "20");    checkStringable(java.net.URI.class, "foo://bar:9000/baz");    checkStringable(java.net.URL.class, "http://bar:9000/baz");    checkStringable(java.io.File.class, "foo.bar");}
0
public void checkStringable(Class c, String value) throws Exception
{    ReflectData data = new ReflectData();    Schema schema = data.getSchema(c);    assertEquals("{\"type\":\"string\",\"java-class\":\"" + c.getName() + "\"}", schema.toString());    checkBinary(schema, c.getConstructor(String.class).newInstance(value));}
0
public void testStringableMapKeys() throws Exception
{    M1 record = new M1();    record.integerKeyMap = new HashMap<>(1);    record.integerKeyMap.put(10, "foo");    record.bigIntegerKeyMap = new HashMap<>(1);    record.bigIntegerKeyMap.put(java.math.BigInteger.TEN, "bar");    record.bigDecimalKeyMap = new HashMap<>(1);    record.bigDecimalKeyMap.put(java.math.BigDecimal.ONE, "bigDecimal");    record.fileKeyMap = new HashMap<>(1);    record.fileKeyMap.put(new java.io.File("foo.bar"), "file");    ReflectData data = new ReflectData().addStringable(Integer.class);    checkBinary(data, data.getSchema(M1.class), record, true);}
0
public void testNullableStringableField() throws Exception
{    NullableStringable datum = new NullableStringable();    datum.number = java.math.BigDecimal.TEN;    Schema schema = ReflectData.AllowNull.get().getSchema(NullableStringable.class);    checkBinary(schema, datum);}
0
public static void checkBinary(ReflectData reflectData, Schema schema, Object datum, boolean equals) throws IOException
{    checkBinary(reflectData, schema, datum, equals, false);}
0
private static void checkBinary(ReflectData reflectData, Schema schema, Object datum, boolean equals, boolean blocking) throws IOException
{    ReflectDatumWriter<Object> writer = new ReflectDatumWriter<>(schema);    ByteArrayOutputStream out = new ByteArrayOutputStream();    if (!blocking) {        writer.write(datum, EncoderFactory.get().directBinaryEncoder(out, null));    } else {        writer.write(datum, new EncoderFactory().configureBlockSize(64).blockingBinaryEncoder(out, null));    }    writer.write(datum, EncoderFactory.get().directBinaryEncoder(out, null));    byte[] data = out.toByteArray();    ReflectDatumReader<Object> reader = new ReflectDatumReader<>(schema);    Object decoded = reader.read(null, DecoderFactory.get().binaryDecoder(data, null));    assertEquals(0, reflectData.compare(datum, decoded, schema, equals));}
0
public static void checkBinary(Schema schema, Object datum) throws IOException
{    checkBinary(ReflectData.get(), schema, datum, false);}
0
public void testReflectFieldError() throws Exception
{    Object datum = "";    try {        ReflectData.get().getField(datum, "notAFieldOfString", 0);    } catch (AvroRuntimeException e) {        assertTrue(e.getMessage().contains(datum.getClass().getName()));    }}
0
public void testAvroAliasOnClass()
{    check(AliasA.class, "{\"type\":\"record\",\"name\":\"AliasA\",\"namespace\":\"org.apache.avro.reflect.TestReflect\",\"fields\":[],\"aliases\":[\"b.a\"]}");    check(AliasB.class, "{\"type\":\"record\",\"name\":\"AliasB\",\"namespace\":\"org.apache.avro.reflect.TestReflect\",\"fields\":[],\"aliases\":[\"a\"]}");    check(AliasC.class, "{\"type\":\"record\",\"name\":\"AliasC\",\"namespace\":\"org.apache.avro.reflect.TestReflect\",\"fields\":[],\"aliases\":[\"a\"]}");}
0
public void testMultipleAliasAnnotationsOnClass()
{    check(MultipleAliasRecord.class, "{\"type\":\"record\",\"name\":\"MultipleAliasRecord\",\"namespace\":\"org.apache.avro.reflect.TestReflect\",\"fields\":[],\"aliases\":[\"space1.alias1\",\"space2.alias2\"]}");}
0
public void testDollarTerminatedNamespaceCompatibility()
{    ReflectData data = ReflectData.get();    Schema s = new Schema.Parser().parse("{\"type\":\"record\",\"name\":\"Z\",\"namespace\":\"org.apache.avro.reflect.TestReflect$\",\"fields\":[]}");    assertEquals(data.getSchema(data.getClass(s)).toString(), "{\"type\":\"record\",\"name\":\"Z\",\"namespace\":\"org.apache.avro.reflect.TestReflect\",\"fields\":[]}");}
0
public void testAvroAliasOnField()
{    Schema expectedSchema = SchemaBuilder.record(ClassWithAliasOnField.class.getSimpleName()).namespace("org.apache.avro.reflect.TestReflect").fields().name("primitiveField").aliases("aliasName").type(Schema.create(org.apache.avro.Schema.Type.INT)).noDefault().endRecord();    check(ClassWithAliasOnField.class, expectedSchema.toString());}
0
public void namespaceDefinitionOnFieldAliasMustThrowException()
{    ReflectData.get().getSchema(ClassWithAliasAndNamespaceOnField.class);}
0
public void testMultipleFieldAliases()
{    Schema expectedSchema = SchemaBuilder.record(ClassWithMultipleAliasesOnField.class.getSimpleName()).namespace("org.apache.avro.reflect.TestReflect").fields().name("primitiveField").aliases("alias1", "alias2").type(Schema.create(org.apache.avro.Schema.Type.INT)).noDefault().endRecord();    check(ClassWithMultipleAliasesOnField.class, expectedSchema.toString());}
0
public void testAvroDefault()
{    check(DefaultTest.class, "{\"type\":\"record\",\"name\":\"DefaultTest\"," + "\"namespace\":\"org.apache.avro.reflect.TestReflect\",\"fields\":[" + "{\"name\":\"foo\",\"type\":\"int\",\"default\":1}]}");}
0
public boolean equals(Object obj)
{    return obj instanceof NullableBytesTest && Arrays.equals(((NullableBytesTest) obj).bytes, this.bytes);}
0
public void testNullableByteArrayNotNullValue() throws Exception
{    checkReadWrite(new NullableBytesTest("foo".getBytes(UTF_8)));}
0
public void testNullableByteArrayNullValue() throws Exception
{    checkReadWrite(new NullableBytesTest());}
0
public void testAvroDoc()
{    check(DocTest.class, "{\"type\":\"record\",\"name\":\"DocTest\",\"namespace\":\"org.apache.avro.reflect.TestReflect\"," + "\"doc\":\"DocTest class docs\"," + "\"fields\":[{\"name\":\"foo\",\"type\":\"int\",\"doc\":\"Some Documentation\"}," + "{\"name\":\"enums\",\"type\":{\"type\":\"enum\",\"name\":\"DocTestEnum\"," + "\"symbols\":[\"ENUM_1\",\"ENUM_2\"]},\"doc\":\"Some other Documentation\"}," + "{\"name\":\"defaultTest\",\"type\":{\"type\":\"record\",\"name\":\"DefaultTest\"," + "\"fields\":[{\"name\":\"foo\",\"type\":\"int\",\"default\":1}]},\"doc\":\"And again\"}]}");}
0
public void testPrimitives()
{        Schema primitives = ReflectData.AllowNull.get().getSchema(Primitives.class);    Assert.assertEquals(requiredSchema(boolean.class), primitives.getField("aBoolean").schema());    Assert.assertEquals(requiredSchema(byte.class), primitives.getField("aByte").schema());    Assert.assertEquals(requiredSchema(short.class), primitives.getField("aShort").schema());    Assert.assertEquals(requiredSchema(int.class), primitives.getField("anInt").schema());    Assert.assertEquals(requiredSchema(long.class), primitives.getField("aLong").schema());    Assert.assertEquals(requiredSchema(float.class), primitives.getField("aFloat").schema());    Assert.assertEquals(requiredSchema(double.class), primitives.getField("aDouble").schema());}
0
public void testWrappers()
{        Schema wrappers = ReflectData.AllowNull.get().getSchema(Wrappers.class);    Assert.assertEquals(nullableSchema(boolean.class), wrappers.getField("aBoolean").schema());    Assert.assertEquals(nullableSchema(byte.class), wrappers.getField("aByte").schema());    Assert.assertEquals(nullableSchema(short.class), wrappers.getField("aShort").schema());    Assert.assertEquals(nullableSchema(int.class), wrappers.getField("anInt").schema());    Assert.assertEquals(nullableSchema(long.class), wrappers.getField("aLong").schema());    Assert.assertEquals(nullableSchema(float.class), wrappers.getField("aFloat").schema());    Assert.assertEquals(nullableSchema(double.class), wrappers.getField("aDouble").schema());    Assert.assertEquals(nullableSchema(Primitives.class), wrappers.getField("anObject").schema());}
0
public void testAllowNullWithNullableAnnotation()
{    Schema withNullable = ReflectData.AllowNull.get().getSchema(AllowNullWithNullable.class);    Assert.assertEquals("Should produce a nullable double", nullableSchema(double.class), withNullable.getField("aDouble").schema());    Schema nullableDoubleOrLong = Schema.createUnion(Arrays.asList(Schema.create(Schema.Type.NULL), Schema.create(Schema.Type.DOUBLE), Schema.create(Schema.Type.LONG)));    Assert.assertEquals("Should add null to a non-null union", nullableDoubleOrLong, withNullable.getField("doubleOrLong").schema());    Assert.assertEquals("Should add null to a non-null union", nullableDoubleOrLong, withNullable.getField("doubleOrLongOrNull1").schema());    Schema doubleOrLongOrNull = Schema.createUnion(Arrays.asList(Schema.create(Schema.Type.DOUBLE), Schema.create(Schema.Type.LONG), Schema.create(Schema.Type.NULL)));    Assert.assertEquals("Should add null to a non-null union", doubleOrLongOrNull, withNullable.getField("doubleOrLongOrNull2").schema());    Assert.assertEquals("Should add null to a non-null union", doubleOrLongOrNull, withNullable.getField("doubleOrLongOrNull3").schema());}
0
private Schema requiredSchema(Class<?> type)
{    return ReflectData.get().getSchema(type);}
0
private Schema nullableSchema(Class<?> type)
{    return Schema.createUnion(Arrays.asList(Schema.create(Schema.Type.NULL), ReflectData.get().getSchema(type)));}
0
public void testWeakSchemaCaching() throws Exception
{    int numSchemas = 1000000;    for (int i = 0; i < numSchemas; i++) {                Schema schema = Schema.createRecord("schema", null, null, false);        schema.setFields(Collections.emptyList());        ReflectData.get().getRecordState(new Object(), schema);    }        ReflectData.ClassAccessorData classData = ReflectData.ACCESSOR_CACHE.get(Object.class);        System.gc();    assertThat("ReflectData cache should release references", classData.bySchema.size(), lessThan(numSchemas));}
0
public void testGenericProtocol()
{    Protocol protocol = ReflectData.get().getProtocol(FooBarProtocol.class);    Schema recordSchema = ReflectData.get().getSchema(FooBarReflectiveRecord.class);    assertThat(protocol.getTypes(), contains(recordSchema));    assertThat(protocol.getMessages().keySet(), containsInAnyOrder("store", "findById", "exists"));    Schema.Field storeArgument = protocol.getMessages().get("store").getRequest().getFields().get(0);    assertThat(storeArgument.schema(), equalTo(recordSchema));    Schema.Field findByIdArgument = protocol.getMessages().get("findById").getRequest().getFields().get(0);    assertThat(findByIdArgument.schema(), equalTo(Schema.create(Schema.Type.STRING)));    Schema findByIdResponse = protocol.getMessages().get("findById").getResponse();    assertThat(findByIdResponse, equalTo(recordSchema));    Schema.Field existsArgument = protocol.getMessages().get("exists").getRequest().getFields().get(0);    assertThat(existsArgument.schema(), equalTo(Schema.create(Schema.Type.STRING)));}
0
private static byte[] serializeWithReflectDatumWriter(T toSerialize, Class<T> toSerializeClass) throws IOException
{    ReflectDatumWriter<T> datumWriter = new ReflectDatumWriter<>(toSerializeClass);    ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream();    Encoder encoder = EncoderFactory.get().binaryEncoder(byteArrayOutputStream, null);    datumWriter.write(toSerialize, encoder);    encoder.flush();    return byteArrayOutputStream.toByteArray();}
0
public void testRead_PojoWithList() throws IOException
{    PojoWithList pojoWithList = new PojoWithList();    pojoWithList.setId(42);    pojoWithList.setRelatedIds(Arrays.asList(1, 2, 3));    byte[] serializedBytes = serializeWithReflectDatumWriter(pojoWithList, PojoWithList.class);    Decoder decoder = DecoderFactory.get().binaryDecoder(serializedBytes, null);    ReflectDatumReader<PojoWithList> reflectDatumReader = new ReflectDatumReader<>(PojoWithList.class);    PojoWithList deserialized = new PojoWithList();    reflectDatumReader.read(deserialized, decoder);    assertEquals(pojoWithList, deserialized);}
0
public void testRead_PojoWithArray() throws IOException
{    PojoWithArray pojoWithArray = new PojoWithArray();    pojoWithArray.setId(42);    pojoWithArray.setRelatedIds(new int[] { 1, 2, 3 });    byte[] serializedBytes = serializeWithReflectDatumWriter(pojoWithArray, PojoWithArray.class);    Decoder decoder = DecoderFactory.get().binaryDecoder(serializedBytes, null);    ReflectDatumReader<PojoWithArray> reflectDatumReader = new ReflectDatumReader<>(PojoWithArray.class);    PojoWithArray deserialized = new PojoWithArray();    reflectDatumReader.read(deserialized, decoder);    assertEquals(pojoWithArray, deserialized);}
0
public int getId()
{    return id;}
0
public void setId(int id)
{    this.id = id;}
0
public List<Integer> getRelatedIds()
{    return relatedIds;}
0
public void setRelatedIds(List<Integer> relatedIds)
{    this.relatedIds = relatedIds;}
0
public int hashCode()
{    final int prime = 31;    int result = 1;    result = prime * result + id;    result = prime * result + ((relatedIds == null) ? 0 : relatedIds.hashCode());    return result;}
0
public boolean equals(Object obj)
{    if (this == obj)        return true;    if (obj == null)        return false;    if (getClass() != obj.getClass())        return false;    PojoWithList other = (PojoWithList) obj;    if (id != other.id)        return false;    if (relatedIds == null) {        return other.relatedIds == null;    } else        return relatedIds.equals(other.relatedIds);}
0
public int getId()
{    return id;}
0
public void setId(int id)
{    this.id = id;}
0
public int[] getRelatedIds()
{    return relatedIds;}
0
public void setRelatedIds(int[] relatedIds)
{    this.relatedIds = relatedIds;}
0
public int hashCode()
{    final int prime = 31;    int result = 1;    result = prime * result + id;    result = prime * result + Arrays.hashCode(relatedIds);    return result;}
0
public boolean equals(Object obj)
{    if (this == obj)        return true;    if (obj == null)        return false;    if (getClass() != obj.getClass())        return false;    PojoWithArray other = (PojoWithArray) obj;    if (id != other.id)        return false;    return Arrays.equals(relatedIds, other.relatedIds);}
0
public void testUnsafeUtil()
{    new Tester().checkUnsafe();}
0
public void testUnsafeWhenNotExists() throws Exception
{    ClassLoader cl = new NoUnsafe();    Class<?> testerClass = cl.loadClass(Tester.class.getName());    testerClass.getDeclaredMethod("checkUnsafe").invoke(testerClass.getDeclaredConstructor().newInstance());}
0
public void checkUnsafe()
{    ReflectionUtil.getFieldAccess();}
0
public java.lang.Class<?> loadClass(String name) throws ClassNotFoundException
{    Class<?> clazz = findLoadedClass(name);    if (clazz != null) {        return clazz;    }    if ("sun.misc.Unsafe".equals(name)) {        throw new ClassNotFoundException(name);    }    if (!name.startsWith("org.apache.avro.")) {        return parent.loadClass(name);    }    InputStream data = parent.getResourceAsStream(name.replace('.', '/') + ".class");        byte[] buf = new byte[10240];    int size;    try {        size = data.read(buf);    } catch (IOException e) {        throw new ClassNotFoundException();    }    clazz = defineClass(name, buf, 0, size);    resolveClass(clazz);    return clazz;}
0
public static void addUUID()
{    REFLECT.addLogicalTypeConversion(new Conversions.UUIDConversion());    REFLECT.addLogicalTypeConversion(new Conversions.DecimalConversion());    REFLECT.addLogicalTypeConversion(new TimeConversions.LocalTimestampMillisConversion());}
0
public void testReflectedSchema()
{    Schema expected = SchemaBuilder.record(RecordWithUUIDList.class.getName()).fields().name("uuids").type().array().items().stringType().noDefault().endRecord();    expected.getField("uuids").schema().addProp(SpecificData.CLASS_PROP, List.class.getName());    LogicalTypes.uuid().addToSchema(expected.getField("uuids").schema().getElementType());    Schema actual = REFLECT.getSchema(RecordWithUUIDList.class);    Assert.assertEquals("Should use the UUID logical type", expected, actual);}
0
public boolean equals(Object other)
{    if (this == other) {        return true;    }    if (other == null || getClass() != other.getClass()) {        return false;    }    DecimalRecordBytes that = (DecimalRecordBytes) other;    if (decimal == null) {        return (that.decimal == null);    }    return decimal.equals(that.decimal);}
0
public int hashCode()
{    return decimal != null ? decimal.hashCode() : 0;}
0
public void testDecimalBytes() throws IOException
{    Schema schema = REFLECT.getSchema(DecimalRecordBytes.class);    Assert.assertEquals("Should have the correct record name", "org.apache.avro.reflect.TestReflectLogicalTypes", schema.getNamespace());    Assert.assertEquals("Should have the correct record name", "DecimalRecordBytes", schema.getName());    Assert.assertEquals("Should have the correct logical type", LogicalTypes.decimal(9, 2), LogicalTypes.fromSchema(schema.getField("decimal").schema()));    DecimalRecordBytes record = new DecimalRecordBytes();    record.decimal = new BigDecimal("3.14");    File test = write(REFLECT, schema, record);    Assert.assertEquals("Should match the decimal after round trip", Collections.singletonList(record), read(REFLECT.createDatumReader(schema), test));}
0
public boolean equals(Object other)
{    if (this == other) {        return true;    }    if (other == null || getClass() != other.getClass()) {        return false;    }    DecimalRecordFixed that = (DecimalRecordFixed) other;    if (decimal == null) {        return (that.decimal == null);    }    return decimal.equals(that.decimal);}
0
public int hashCode()
{    return decimal != null ? decimal.hashCode() : 0;}
0
public void testDecimalFixed() throws IOException
{    Schema schema = REFLECT.getSchema(DecimalRecordFixed.class);    Assert.assertEquals("Should have the correct record name", "org.apache.avro.reflect.TestReflectLogicalTypes", schema.getNamespace());    Assert.assertEquals("Should have the correct record name", "DecimalRecordFixed", schema.getName());    Assert.assertEquals("Should have the correct logical type", LogicalTypes.decimal(9, 2), LogicalTypes.fromSchema(schema.getField("decimal").schema()));    DecimalRecordFixed record = new DecimalRecordFixed();    record.decimal = new BigDecimal("3.14");    File test = write(REFLECT, schema, record);    Assert.assertEquals("Should match the decimal after round trip", Collections.singletonList(record), read(REFLECT.createDatumReader(schema), test));}
0
public boolean equals(Object other)
{    if (this == other) {        return true;    }    if (other == null || getClass() != other.getClass()) {        return false;    }    Pair<?, ?> that = (Pair<?, ?>) other;    if (first == null) {        if (that.first != null) {            return false;        }    } else if (first.equals(that.first)) {        return false;    }    if (second == null) {        return that.second == null;    } else        return !second.equals(that.second);}
0
public int hashCode()
{    return Arrays.hashCode(new Object[] { first, second });}
0
public static Pair<X, Y> of(X first, Y second)
{    return new Pair<>(first, second);}
0
public void testPairRecord() throws IOException
{    ReflectData model = new ReflectData();    model.addLogicalTypeConversion(new Conversion<Pair>() {        @Override        public Class<Pair> getConvertedType() {            return Pair.class;        }        @Override        public String getLogicalTypeName() {            return "pair";        }        @Override        public Pair fromRecord(IndexedRecord value, Schema schema, LogicalType type) {            return Pair.of(value.get(0), value.get(1));        }        @Override        public IndexedRecord toRecord(Pair value, Schema schema, LogicalType type) {            GenericData.Record record = new GenericData.Record(schema);            record.put(0, value.first);            record.put(1, value.second);            return record;        }    });    LogicalTypes.register("pair", new LogicalTypes.LogicalTypeFactory() {        private final LogicalType PAIR = new LogicalType("pair");        @Override        public LogicalType fromSchema(Schema schema) {            return PAIR;        }    });    Schema schema = model.getSchema(PairRecord.class);    Assert.assertEquals("Should have the correct record name", "org.apache.avro.reflect.TestReflectLogicalTypes", schema.getNamespace());    Assert.assertEquals("Should have the correct record name", "PairRecord", schema.getName());    Assert.assertEquals("Should have the correct logical type", "pair", LogicalTypes.fromSchema(schema.getField("pair").schema()).getName());    PairRecord record = new PairRecord();    record.pair = Pair.of(34L, 35L);    List<PairRecord> expected = new ArrayList<>();    expected.add(record);    File test = write(model, schema, record);    Pair<Long, Long> actual = ((PairRecord) TestReflectLogicalTypes.<PairRecord>read(model.createDatumReader(schema), test).get(0)).pair;    Assert.assertEquals("Data should match after serialization round-trip", 34L, (long) actual.first);    Assert.assertEquals("Data should match after serialization round-trip", 35L, (long) actual.second);}
0
public Class<Pair> getConvertedType()
{    return Pair.class;}
0
public String getLogicalTypeName()
{    return "pair";}
0
public Pair fromRecord(IndexedRecord value, Schema schema, LogicalType type)
{    return Pair.of(value.get(0), value.get(1));}
0
public IndexedRecord toRecord(Pair value, Schema schema, LogicalType type)
{    GenericData.Record record = new GenericData.Record(schema);    record.put(0, value.first);    record.put(1, value.second);    return record;}
0
public LogicalType fromSchema(Schema schema)
{    return PAIR;}
0
public void testReadUUID() throws IOException
{    Schema uuidSchema = SchemaBuilder.record(RecordWithUUID.class.getName()).fields().requiredString("uuid").endRecord();    LogicalTypes.uuid().addToSchema(uuidSchema.getField("uuid").schema());    UUID u1 = UUID.randomUUID();    UUID u2 = UUID.randomUUID();    RecordWithStringUUID r1 = new RecordWithStringUUID();    r1.uuid = u1.toString();    RecordWithStringUUID r2 = new RecordWithStringUUID();    r2.uuid = u2.toString();    List<RecordWithUUID> expected = Arrays.asList(new RecordWithUUID(), new RecordWithUUID());    expected.get(0).uuid = u1;    expected.get(1).uuid = u2;    File test = write(ReflectData.get().getSchema(RecordWithStringUUID.class), r1, r2);    Assert.assertEquals("Should convert Strings to UUIDs", expected, read(REFLECT.createDatumReader(uuidSchema), test));        Schema uuidStringSchema = SchemaBuilder.record(RecordWithStringUUID.class.getName()).fields().requiredString("uuid").endRecord();    LogicalTypes.uuid().addToSchema(uuidStringSchema.getField("uuid").schema());    Assert.assertEquals("Should not convert to UUID if accessor is String", Arrays.asList(r1, r2), read(REFLECT.createDatumReader(uuidStringSchema), test));}
0
public void testWriteUUID() throws IOException
{    Schema uuidSchema = SchemaBuilder.record(RecordWithUUID.class.getName()).fields().requiredString("uuid").endRecord();    LogicalTypes.uuid().addToSchema(uuidSchema.getField("uuid").schema());    UUID u1 = UUID.randomUUID();    UUID u2 = UUID.randomUUID();    RecordWithUUID r1 = new RecordWithUUID();    r1.uuid = u1;    RecordWithUUID r2 = new RecordWithUUID();    r2.uuid = u2;    List<RecordWithStringUUID> expected = Arrays.asList(new RecordWithStringUUID(), new RecordWithStringUUID());    expected.get(0).uuid = u1.toString();    expected.get(1).uuid = u2.toString();    File test = write(REFLECT, uuidSchema, r1, r2);        Schema uuidStringSchema = SchemaBuilder.record(RecordWithStringUUID.class.getName()).fields().requiredString("uuid").endRecord();    Assert.assertEquals("Should read uuid as String without UUID conversion", expected, read(REFLECT.createDatumReader(uuidStringSchema), test));    LogicalTypes.uuid().addToSchema(uuidStringSchema.getField("uuid").schema());    Assert.assertEquals("Should read uuid as String without UUID logical type", expected, read(ReflectData.get().createDatumReader(uuidStringSchema), test));}
0
public void testWriteNullableUUID() throws IOException
{    Schema nullableUuidSchema = SchemaBuilder.record(RecordWithUUID.class.getName()).fields().optionalString("uuid").endRecord();    LogicalTypes.uuid().addToSchema(nullableUuidSchema.getField("uuid").schema().getTypes().get(1));    UUID u1 = UUID.randomUUID();    UUID u2 = UUID.randomUUID();    RecordWithUUID r1 = new RecordWithUUID();    r1.uuid = u1;    RecordWithUUID r2 = new RecordWithUUID();    r2.uuid = u2;    List<RecordWithStringUUID> expected = Arrays.asList(new RecordWithStringUUID(), new RecordWithStringUUID());    expected.get(0).uuid = u1.toString();    expected.get(1).uuid = u2.toString();    File test = write(REFLECT, nullableUuidSchema, r1, r2);        Schema nullableUuidStringSchema = SchemaBuilder.record(RecordWithStringUUID.class.getName()).fields().optionalString("uuid").endRecord();    Assert.assertEquals("Should read uuid as String without UUID conversion", expected, read(ReflectData.get().createDatumReader(nullableUuidStringSchema), test));}
0
public void testWriteNullableUUIDReadRequiredString() throws IOException
{    Schema nullableUuidSchema = SchemaBuilder.record(RecordWithUUID.class.getName()).fields().optionalString("uuid").endRecord();    LogicalTypes.uuid().addToSchema(nullableUuidSchema.getField("uuid").schema().getTypes().get(1));    UUID u1 = UUID.randomUUID();    UUID u2 = UUID.randomUUID();    RecordWithUUID r1 = new RecordWithUUID();    r1.uuid = u1;    RecordWithUUID r2 = new RecordWithUUID();    r2.uuid = u2;    List<RecordWithStringUUID> expected = Arrays.asList(new RecordWithStringUUID(), new RecordWithStringUUID());    expected.get(0).uuid = u1.toString();    expected.get(1).uuid = u2.toString();    File test = write(REFLECT, nullableUuidSchema, r1, r2);        Schema uuidStringSchema = SchemaBuilder.record(RecordWithStringUUID.class.getName()).fields().requiredString("uuid").endRecord();    Assert.assertEquals("Should read uuid as String without UUID conversion", expected, read(REFLECT.createDatumReader(uuidStringSchema), test));}
0
public void testReadUUIDMissingLogicalTypeUnsafe() throws IOException
{    String unsafeValue = System.getProperty("avro.disable.unsafe");    try {                System.clearProperty("avro.disable.unsafe");        Assume.assumeTrue(ReflectionUtil.getFieldAccess() instanceof FieldAccessUnsafe);        Schema uuidSchema = SchemaBuilder.record(RecordWithUUID.class.getName()).fields().requiredString("uuid").endRecord();        LogicalTypes.uuid().addToSchema(uuidSchema.getField("uuid").schema());        UUID u1 = UUID.randomUUID();        RecordWithStringUUID r1 = new RecordWithStringUUID();        r1.uuid = u1.toString();        File test = write(ReflectData.get().getSchema(RecordWithStringUUID.class), r1);        RecordWithUUID datum = (RecordWithUUID) read(ReflectData.get().createDatumReader(uuidSchema), test).get(0);        Object uuid = datum.uuid;        Assert.assertTrue("UUID should be a String (unsafe)", uuid instanceof String);    } finally {        if (unsafeValue != null) {            System.setProperty("avro.disable.unsafe", unsafeValue);        }    }}
0
public void testReadUUIDMissingLogicalTypeReflect() throws IOException
{    String unsafeValue = System.getProperty("avro.disable.unsafe");    try {                System.setProperty("avro.disable.unsafe", "true");        Assume.assumeTrue(ReflectionUtil.getFieldAccess() instanceof FieldAccessReflect);        Schema uuidSchema = SchemaBuilder.record(RecordWithUUID.class.getName()).fields().requiredString("uuid").endRecord();        LogicalTypes.uuid().addToSchema(uuidSchema.getField("uuid").schema());        UUID u1 = UUID.randomUUID();        RecordWithStringUUID r1 = new RecordWithStringUUID();        r1.uuid = u1.toString();        File test = write(ReflectData.get().getSchema(RecordWithStringUUID.class), r1);        read(ReflectData.get().createDatumReader(uuidSchema), test).get(0);    } finally {        if (unsafeValue != null) {            System.setProperty("avro.disable.unsafe", unsafeValue);        }    }}
0
public void testWriteUUIDMissingLogicalType() throws IOException
{    Schema uuidSchema = SchemaBuilder.record(RecordWithUUID.class.getName()).fields().requiredString("uuid").endRecord();    LogicalTypes.uuid().addToSchema(uuidSchema.getField("uuid").schema());    UUID u1 = UUID.randomUUID();    UUID u2 = UUID.randomUUID();    RecordWithUUID r1 = new RecordWithUUID();    r1.uuid = u1;    RecordWithUUID r2 = new RecordWithUUID();    r2.uuid = u2;        File test = write(uuidSchema, r1, r2);        Schema uuidStringSchema = SchemaBuilder.record(RecordWithStringUUID.class.getName()).fields().requiredString("uuid").endRecord();            read(ReflectData.get().createDatumReader(uuidStringSchema), test);}
0
public void testReadUUIDGenericRecord() throws IOException
{    Schema uuidSchema = SchemaBuilder.record("RecordWithUUID").fields().requiredString("uuid").endRecord();    LogicalTypes.uuid().addToSchema(uuidSchema.getField("uuid").schema());    UUID u1 = UUID.randomUUID();    UUID u2 = UUID.randomUUID();    RecordWithStringUUID r1 = new RecordWithStringUUID();    r1.uuid = u1.toString();    RecordWithStringUUID r2 = new RecordWithStringUUID();    r2.uuid = u2.toString();    List<GenericData.Record> expected = Arrays.asList(new GenericData.Record(uuidSchema), new GenericData.Record(uuidSchema));    expected.get(0).put("uuid", u1);    expected.get(1).put("uuid", u2);    File test = write(ReflectData.get().getSchema(RecordWithStringUUID.class), r1, r2);    Assert.assertEquals("Should convert Strings to UUIDs", expected, read(REFLECT.createDatumReader(uuidSchema), test));        Schema uuidStringSchema = SchemaBuilder.record(RecordWithStringUUID.class.getName()).fields().requiredString("uuid").endRecord();    LogicalTypes.uuid().addToSchema(uuidSchema.getField("uuid").schema());    Assert.assertEquals("Should not convert to UUID if accessor is String", Arrays.asList(r1, r2), read(REFLECT.createDatumReader(uuidStringSchema), test));}
0
public void testReadUUIDArray() throws IOException
{    Schema uuidArraySchema = SchemaBuilder.record(RecordWithUUIDArray.class.getName()).fields().name("uuids").type().array().items().stringType().noDefault().endRecord();    LogicalTypes.uuid().addToSchema(uuidArraySchema.getField("uuids").schema().getElementType());    UUID u1 = UUID.randomUUID();    UUID u2 = UUID.randomUUID();    GenericRecord r = new GenericData.Record(uuidArraySchema);    r.put("uuids", Arrays.asList(u1.toString(), u2.toString()));    RecordWithUUIDArray expected = new RecordWithUUIDArray();    expected.uuids = new UUID[] { u1, u2 };    File test = write(uuidArraySchema, r);    Assert.assertEquals("Should convert Strings to UUIDs", expected, read(REFLECT.createDatumReader(uuidArraySchema), test).get(0));}
0
public void testWriteUUIDArray() throws IOException
{    Schema uuidArraySchema = SchemaBuilder.record(RecordWithUUIDArray.class.getName()).fields().name("uuids").type().array().items().stringType().noDefault().endRecord();    LogicalTypes.uuid().addToSchema(uuidArraySchema.getField("uuids").schema().getElementType());    Schema stringArraySchema = SchemaBuilder.record("RecordWithUUIDArray").fields().name("uuids").type().array().items().stringType().noDefault().endRecord();    stringArraySchema.getField("uuids").schema().addProp(SpecificData.CLASS_PROP, List.class.getName());    UUID u1 = UUID.randomUUID();    UUID u2 = UUID.randomUUID();    GenericRecord expected = new GenericData.Record(stringArraySchema);    List<String> uuids = new ArrayList<>();    uuids.add(u1.toString());    uuids.add(u2.toString());    expected.put("uuids", uuids);    RecordWithUUIDArray r = new RecordWithUUIDArray();    r.uuids = new UUID[] { u1, u2 };    File test = write(REFLECT, uuidArraySchema, r);    Assert.assertEquals("Should read UUIDs as Strings", expected, read(ReflectData.get().createDatumReader(stringArraySchema), test).get(0));}
0
public void testReadUUIDList() throws IOException
{    Schema uuidListSchema = SchemaBuilder.record(RecordWithUUIDList.class.getName()).fields().name("uuids").type().array().items().stringType().noDefault().endRecord();    uuidListSchema.getField("uuids").schema().addProp(SpecificData.CLASS_PROP, List.class.getName());    LogicalTypes.uuid().addToSchema(uuidListSchema.getField("uuids").schema().getElementType());    UUID u1 = UUID.randomUUID();    UUID u2 = UUID.randomUUID();    GenericRecord r = new GenericData.Record(uuidListSchema);    r.put("uuids", Arrays.asList(u1.toString(), u2.toString()));    RecordWithUUIDList expected = new RecordWithUUIDList();    expected.uuids = Arrays.asList(u1, u2);    File test = write(uuidListSchema, r);    Assert.assertEquals("Should convert Strings to UUIDs", expected, read(REFLECT.createDatumReader(uuidListSchema), test).get(0));}
0
public void testWriteUUIDList() throws IOException
{    Schema uuidListSchema = SchemaBuilder.record(RecordWithUUIDList.class.getName()).fields().name("uuids").type().array().items().stringType().noDefault().endRecord();    uuidListSchema.getField("uuids").schema().addProp(SpecificData.CLASS_PROP, List.class.getName());    LogicalTypes.uuid().addToSchema(uuidListSchema.getField("uuids").schema().getElementType());    Schema stringArraySchema = SchemaBuilder.record("RecordWithUUIDArray").fields().name("uuids").type().array().items().stringType().noDefault().endRecord();    stringArraySchema.getField("uuids").schema().addProp(SpecificData.CLASS_PROP, List.class.getName());    UUID u1 = UUID.randomUUID();    UUID u2 = UUID.randomUUID();    GenericRecord expected = new GenericData.Record(stringArraySchema);    expected.put("uuids", Arrays.asList(u1.toString(), u2.toString()));    RecordWithUUIDList r = new RecordWithUUIDList();    r.uuids = Arrays.asList(u1, u2);    File test = write(REFLECT, uuidListSchema, r);    Assert.assertEquals("Should read UUIDs as Strings", expected, read(REFLECT.createDatumReader(stringArraySchema), test).get(0));}
0
public void testReflectedSchemaLocalDateTime()
{    Schema actual = REFLECT.getSchema(RecordWithTimestamps.class);    Assert.assertEquals("Should have the correct record name", "org.apache.avro.reflect", actual.getNamespace());    Assert.assertEquals("Should have the correct record name", "RecordWithTimestamps", actual.getName());    Assert.assertEquals("Should have the correct physical type", Schema.Type.LONG, actual.getField("localDateTime").schema().getType());    Assert.assertEquals("Should have the correct logical type", LogicalTypes.localTimestampMillis(), LogicalTypes.fromSchema(actual.getField("localDateTime").schema()));}
0
private static List<D> read(DatumReader<D> reader, File file) throws IOException
{    List<D> data = new ArrayList<>();    try (FileReader<D> fileReader = new DataFileReader<>(file, reader)) {        for (D datum : fileReader) {            data.add(datum);        }    }    return data;}
0
private File write(Schema schema, D... data) throws IOException
{    return write(ReflectData.get(), schema, data);}
0
private File write(GenericData model, Schema schema, D... data) throws IOException
{    File file = temp.newFile();    DatumWriter<D> writer = model.createDatumWriter(schema);    try (DataFileWriter<D> fileWriter = new DataFileWriter<>(writer)) {        fileWriter.create(schema, file);        for (D datum : data) {            fileWriter.append(datum);        }    }    return file;}
0
public int hashCode()
{    return uuid.hashCode();}
0
public boolean equals(Object obj)
{    if (obj == null) {        return false;    }    if (!(obj instanceof RecordWithUUID)) {        return false;    }    RecordWithUUID that = (RecordWithUUID) obj;    return this.uuid.equals(that.uuid);}
0
public int hashCode()
{    return uuid.hashCode();}
0
public boolean equals(Object obj)
{    if (obj == null) {        return false;    }    if (!(obj instanceof RecordWithStringUUID)) {        return false;    }    RecordWithStringUUID that = (RecordWithStringUUID) obj;    return this.uuid.equals(that.uuid);}
0
public int hashCode()
{    return Arrays.hashCode(uuids);}
0
public boolean equals(Object obj)
{    if (obj == null) {        return false;    }    if (!(obj instanceof RecordWithUUIDArray)) {        return false;    }    RecordWithUUIDArray that = (RecordWithUUIDArray) obj;    return Arrays.equals(this.uuids, that.uuids);}
0
public int hashCode()
{    return uuids.hashCode();}
0
public boolean equals(Object obj)
{    if (obj == null) {        return false;    }    if (!(obj instanceof RecordWithUUIDList)) {        return false;    }    RecordWithUUIDList that = (RecordWithUUIDList) obj;    return this.uuids.equals(that.uuids);}
0
public int hashCode()
{    return Objects.hash(localDateTime);}
0
public boolean equals(Object obj)
{    if (obj == null) {        return false;    }    if (!(obj instanceof RecordWithTimestamps)) {        return false;    }    RecordWithTimestamps that = (RecordWithTimestamps) obj;    return Objects.equals(that.localDateTime, that.localDateTime);}
0
public static org.apache.avro.Schema getClassSchema()
{    return SCHEMA$;}
0
public static BinaryMessageDecoder<TestRecordWithLogicalTypes> getDecoder()
{    return DECODER;}
0
public static BinaryMessageDecoder<TestRecordWithLogicalTypes> createDecoder(SchemaStore resolver)
{    return new BinaryMessageDecoder<TestRecordWithLogicalTypes>(MODEL$, SCHEMA$, resolver);}
0
public java.nio.ByteBuffer toByteBuffer() throws java.io.IOException
{    return ENCODER.encode(this);}
0
public static TestRecordWithLogicalTypes fromByteBuffer(java.nio.ByteBuffer b) throws java.io.IOException
{    return DECODER.decode(b);}
0
public org.apache.avro.Schema getSchema()
{    return SCHEMA$;}
0
public java.lang.Object get(int field$)
{    switch(field$) {        case 0:            return b;        case 1:            return i32;        case 2:            return i64;        case 3:            return f32;        case 4:            return f64;        case 5:            return s;        case 6:            return d;        case 7:            return t;        case 8:            return ts;        case 9:            return dec;        default:            throw new org.apache.avro.AvroRuntimeException("Bad index");    }}
0
public org.apache.avro.Conversion<?> getConversion(int field)
{    return conversions[field];}
0
public void put(int field$, java.lang.Object value$)
{    switch(field$) {        case 0:            b = (java.lang.Boolean) value$;            break;        case 1:            i32 = (java.lang.Integer) value$;            break;        case 2:            i64 = (java.lang.Long) value$;            break;        case 3:            f32 = (java.lang.Float) value$;            break;        case 4:            f64 = (java.lang.Double) value$;            break;        case 5:            s = (java.lang.CharSequence) value$;            break;        case 6:            d = (java.time.LocalDate) value$;            break;        case 7:            t = (java.time.LocalTime) value$;            break;        case 8:            ts = (java.time.Instant) value$;            break;        case 9:            dec = (java.math.BigDecimal) value$;            break;        default:            throw new org.apache.avro.AvroRuntimeException("Bad index");    }}
0
public java.lang.Boolean getB()
{    return b;}
0
public void setB(java.lang.Boolean value)
{    this.b = value;}
0
public java.lang.Integer getI32()
{    return i32;}
0
public void setI32(java.lang.Integer value)
{    this.i32 = value;}
0
public java.lang.Long getI64()
{    return i64;}
0
public void setI64(java.lang.Long value)
{    this.i64 = value;}
0
public java.lang.Float getF32()
{    return f32;}
0
public void setF32(java.lang.Float value)
{    this.f32 = value;}
0
public java.lang.Double getF64()
{    return f64;}
0
public void setF64(java.lang.Double value)
{    this.f64 = value;}
0
public java.lang.CharSequence getS()
{    return s;}
0
public void setS(java.lang.CharSequence value)
{    this.s = value;}
0
public java.time.LocalDate getD()
{    return d;}
0
public void setD(java.time.LocalDate value)
{    this.d = value;}
0
public java.time.LocalTime getT()
{    return t;}
0
public void setT(java.time.LocalTime value)
{    this.t = value;}
0
public java.time.Instant getTs()
{    return ts;}
0
public void setTs(java.time.Instant value)
{    this.ts = value;}
0
public java.math.BigDecimal getDec()
{    return dec;}
0
public void setDec(java.math.BigDecimal value)
{    this.dec = value;}
0
public static TestRecordWithLogicalTypes.Builder newBuilder()
{    return new TestRecordWithLogicalTypes.Builder();}
0
public static TestRecordWithLogicalTypes.Builder newBuilder(TestRecordWithLogicalTypes.Builder other)
{    if (other == null) {        return new TestRecordWithLogicalTypes.Builder();    } else {        return new TestRecordWithLogicalTypes.Builder(other);    }}
0
public static TestRecordWithLogicalTypes.Builder newBuilder(TestRecordWithLogicalTypes other)
{    if (other == null) {        return new TestRecordWithLogicalTypes.Builder();    } else {        return new TestRecordWithLogicalTypes.Builder(other);    }}
0
public java.lang.Boolean getB()
{    return b;}
0
public TestRecordWithLogicalTypes.Builder setB(boolean value)
{    validate(fields()[0], value);    this.b = value;    fieldSetFlags()[0] = true;    return this;}
0
public boolean hasB()
{    return fieldSetFlags()[0];}
0
public TestRecordWithLogicalTypes.Builder clearB()
{    fieldSetFlags()[0] = false;    return this;}
0
public java.lang.Integer getI32()
{    return i32;}
0
public TestRecordWithLogicalTypes.Builder setI32(int value)
{    validate(fields()[1], value);    this.i32 = value;    fieldSetFlags()[1] = true;    return this;}
0
public boolean hasI32()
{    return fieldSetFlags()[1];}
0
public TestRecordWithLogicalTypes.Builder clearI32()
{    fieldSetFlags()[1] = false;    return this;}
0
public java.lang.Long getI64()
{    return i64;}
0
public TestRecordWithLogicalTypes.Builder setI64(long value)
{    validate(fields()[2], value);    this.i64 = value;    fieldSetFlags()[2] = true;    return this;}
0
public boolean hasI64()
{    return fieldSetFlags()[2];}
0
public TestRecordWithLogicalTypes.Builder clearI64()
{    fieldSetFlags()[2] = false;    return this;}
0
public java.lang.Float getF32()
{    return f32;}
0
public TestRecordWithLogicalTypes.Builder setF32(float value)
{    validate(fields()[3], value);    this.f32 = value;    fieldSetFlags()[3] = true;    return this;}
0
public boolean hasF32()
{    return fieldSetFlags()[3];}
0
public TestRecordWithLogicalTypes.Builder clearF32()
{    fieldSetFlags()[3] = false;    return this;}
0
public java.lang.Double getF64()
{    return f64;}
0
public TestRecordWithLogicalTypes.Builder setF64(double value)
{    validate(fields()[4], value);    this.f64 = value;    fieldSetFlags()[4] = true;    return this;}
0
public boolean hasF64()
{    return fieldSetFlags()[4];}
0
public TestRecordWithLogicalTypes.Builder clearF64()
{    fieldSetFlags()[4] = false;    return this;}
0
public java.lang.CharSequence getS()
{    return s;}
0
public TestRecordWithLogicalTypes.Builder setS(java.lang.CharSequence value)
{    validate(fields()[5], value);    this.s = value;    fieldSetFlags()[5] = true;    return this;}
0
public boolean hasS()
{    return fieldSetFlags()[5];}
0
public TestRecordWithLogicalTypes.Builder clearS()
{    s = null;    fieldSetFlags()[5] = false;    return this;}
0
public java.time.LocalDate getD()
{    return d;}
0
public TestRecordWithLogicalTypes.Builder setD(java.time.LocalDate value)
{    validate(fields()[6], value);    this.d = value;    fieldSetFlags()[6] = true;    return this;}
0
public boolean hasD()
{    return fieldSetFlags()[6];}
0
public TestRecordWithLogicalTypes.Builder clearD()
{    fieldSetFlags()[6] = false;    return this;}
0
public java.time.LocalTime getT()
{    return t;}
0
public TestRecordWithLogicalTypes.Builder setT(java.time.LocalTime value)
{    validate(fields()[7], value);    this.t = value;    fieldSetFlags()[7] = true;    return this;}
0
public boolean hasT()
{    return fieldSetFlags()[7];}
0
public TestRecordWithLogicalTypes.Builder clearT()
{    fieldSetFlags()[7] = false;    return this;}
0
public java.time.Instant getTs()
{    return ts;}
0
public TestRecordWithLogicalTypes.Builder setTs(java.time.Instant value)
{    validate(fields()[8], value);    this.ts = value;    fieldSetFlags()[8] = true;    return this;}
0
public boolean hasTs()
{    return fieldSetFlags()[8];}
0
public TestRecordWithLogicalTypes.Builder clearTs()
{    fieldSetFlags()[8] = false;    return this;}
0
public java.math.BigDecimal getDec()
{    return dec;}
0
public TestRecordWithLogicalTypes.Builder setDec(java.math.BigDecimal value)
{    validate(fields()[9], value);    this.dec = value;    fieldSetFlags()[9] = true;    return this;}
0
public boolean hasDec()
{    return fieldSetFlags()[9];}
0
public TestRecordWithLogicalTypes.Builder clearDec()
{    dec = null;    fieldSetFlags()[9] = false;    return this;}
0
public TestRecordWithLogicalTypes build()
{    try {        TestRecordWithLogicalTypes record = new TestRecordWithLogicalTypes();        record.b = fieldSetFlags()[0] ? this.b : (java.lang.Boolean) defaultValue(fields()[0]);        record.i32 = fieldSetFlags()[1] ? this.i32 : (java.lang.Integer) defaultValue(fields()[1]);        record.i64 = fieldSetFlags()[2] ? this.i64 : (java.lang.Long) defaultValue(fields()[2]);        record.f32 = fieldSetFlags()[3] ? this.f32 : (java.lang.Float) defaultValue(fields()[3]);        record.f64 = fieldSetFlags()[4] ? this.f64 : (java.lang.Double) defaultValue(fields()[4]);        record.s = fieldSetFlags()[5] ? this.s : (java.lang.CharSequence) defaultValue(fields()[5]);        record.d = fieldSetFlags()[6] ? this.d : (java.time.LocalDate) defaultValue(fields()[6]);        record.t = fieldSetFlags()[7] ? this.t : (java.time.LocalTime) defaultValue(fields()[7]);        record.ts = fieldSetFlags()[8] ? this.ts : (java.time.Instant) defaultValue(fields()[8]);        record.dec = fieldSetFlags()[9] ? this.dec : (java.math.BigDecimal) defaultValue(fields()[9]);        return record;    } catch (java.lang.Exception e) {        throw new org.apache.avro.AvroRuntimeException(e);    }}
0
public void writeExternal(java.io.ObjectOutput out) throws java.io.IOException
{    WRITER$.write(this, SpecificData.getEncoder(out));}
0
public void readExternal(java.io.ObjectInput in) throws java.io.IOException
{    READER$.read(this, SpecificData.getDecoder(in));}
0
public static org.apache.avro.Schema getClassSchema()
{    return SCHEMA$;}
0
public java.nio.ByteBuffer toByteBuffer() throws java.io.IOException
{    return ENCODER.encode(this);}
0
public static TestRecordWithoutLogicalTypes fromByteBuffer(java.nio.ByteBuffer b) throws java.io.IOException
{    return DECODER.decode(b);}
0
public org.apache.avro.Schema getSchema()
{    return SCHEMA$;}
0
public java.lang.Object get(int field$)
{    switch(field$) {        case 0:            return b;        case 1:            return i32;        case 2:            return i64;        case 3:            return f32;        case 4:            return f64;        case 5:            return s;        case 6:            return d;        case 7:            return t;        case 8:            return ts;        case 9:            return dec;        default:            throw new org.apache.avro.AvroRuntimeException("Bad index");    }}
0
public void put(int field$, java.lang.Object value$)
{    switch(field$) {        case 0:            b = (java.lang.Boolean) value$;            break;        case 1:            i32 = (java.lang.Integer) value$;            break;        case 2:            i64 = (java.lang.Long) value$;            break;        case 3:            f32 = (java.lang.Float) value$;            break;        case 4:            f64 = (java.lang.Double) value$;            break;        case 5:            s = (java.lang.String) value$;            break;        case 6:            d = (java.lang.Integer) value$;            break;        case 7:            t = (java.lang.Integer) value$;            break;        case 8:            ts = (java.lang.Long) value$;            break;        case 9:            dec = (java.nio.ByteBuffer) value$;            break;        default:            throw new org.apache.avro.AvroRuntimeException("Bad index");    }}
0
public java.lang.Boolean getB()
{    return b;}
0
public java.lang.Integer getI32()
{    return i32;}
0
public java.lang.Long getI64()
{    return i64;}
0
public java.lang.Float getF32()
{    return f32;}
0
public java.lang.Double getF64()
{    return f64;}
0
public java.lang.String getS()
{    return s;}
0
public java.lang.Integer getD()
{    return d;}
0
public java.lang.Integer getT()
{    return t;}
0
public java.lang.Long getTs()
{    return ts;}
0
public java.nio.ByteBuffer getDec()
{    return dec;}
0
public static TestRecordWithoutLogicalTypes.Builder newBuilder()
{    return new TestRecordWithoutLogicalTypes.Builder();}
0
public static TestRecordWithoutLogicalTypes.Builder newBuilder(TestRecordWithoutLogicalTypes.Builder other)
{    return new TestRecordWithoutLogicalTypes.Builder(other);}
0
public static TestRecordWithoutLogicalTypes.Builder newBuilder(TestRecordWithoutLogicalTypes other)
{    return new TestRecordWithoutLogicalTypes.Builder(other);}
0
public java.lang.Boolean getB()
{    return b;}
0
public TestRecordWithoutLogicalTypes.Builder setB(boolean value)
{    validate(fields()[0], value);    this.b = value;    fieldSetFlags()[0] = true;    return this;}
0
public boolean hasB()
{    return fieldSetFlags()[0];}
0
public TestRecordWithoutLogicalTypes.Builder clearB()
{    fieldSetFlags()[0] = false;    return this;}
0
public java.lang.Integer getI32()
{    return i32;}
0
public TestRecordWithoutLogicalTypes.Builder setI32(int value)
{    validate(fields()[1], value);    this.i32 = value;    fieldSetFlags()[1] = true;    return this;}
0
public boolean hasI32()
{    return fieldSetFlags()[1];}
0
public TestRecordWithoutLogicalTypes.Builder clearI32()
{    fieldSetFlags()[1] = false;    return this;}
0
public java.lang.Long getI64()
{    return i64;}
0
public TestRecordWithoutLogicalTypes.Builder setI64(long value)
{    validate(fields()[2], value);    this.i64 = value;    fieldSetFlags()[2] = true;    return this;}
0
public boolean hasI64()
{    return fieldSetFlags()[2];}
0
public TestRecordWithoutLogicalTypes.Builder clearI64()
{    fieldSetFlags()[2] = false;    return this;}
0
public java.lang.Float getF32()
{    return f32;}
0
public TestRecordWithoutLogicalTypes.Builder setF32(float value)
{    validate(fields()[3], value);    this.f32 = value;    fieldSetFlags()[3] = true;    return this;}
0
public boolean hasF32()
{    return fieldSetFlags()[3];}
0
public TestRecordWithoutLogicalTypes.Builder clearF32()
{    fieldSetFlags()[3] = false;    return this;}
0
public java.lang.Double getF64()
{    return f64;}
0
public TestRecordWithoutLogicalTypes.Builder setF64(double value)
{    validate(fields()[4], value);    this.f64 = value;    fieldSetFlags()[4] = true;    return this;}
0
public boolean hasF64()
{    return fieldSetFlags()[4];}
0
public TestRecordWithoutLogicalTypes.Builder clearF64()
{    fieldSetFlags()[4] = false;    return this;}
0
public java.lang.String getS()
{    return s;}
0
public TestRecordWithoutLogicalTypes.Builder setS(java.lang.String value)
{    validate(fields()[5], value);    this.s = value;    fieldSetFlags()[5] = true;    return this;}
0
public boolean hasS()
{    return fieldSetFlags()[5];}
0
public TestRecordWithoutLogicalTypes.Builder clearS()
{    s = null;    fieldSetFlags()[5] = false;    return this;}
0
public java.lang.Integer getD()
{    return d;}
0
public TestRecordWithoutLogicalTypes.Builder setD(int value)
{    validate(fields()[6], value);    this.d = value;    fieldSetFlags()[6] = true;    return this;}
0
public boolean hasD()
{    return fieldSetFlags()[6];}
0
public TestRecordWithoutLogicalTypes.Builder clearD()
{    fieldSetFlags()[6] = false;    return this;}
0
public java.lang.Integer getT()
{    return t;}
0
public TestRecordWithoutLogicalTypes.Builder setT(int value)
{    validate(fields()[7], value);    this.t = value;    fieldSetFlags()[7] = true;    return this;}
0
public boolean hasT()
{    return fieldSetFlags()[7];}
0
public TestRecordWithoutLogicalTypes.Builder clearT()
{    fieldSetFlags()[7] = false;    return this;}
0
public java.lang.Long getTs()
{    return ts;}
0
public TestRecordWithoutLogicalTypes.Builder setTs(long value)
{    validate(fields()[8], value);    this.ts = value;    fieldSetFlags()[8] = true;    return this;}
0
public boolean hasTs()
{    return fieldSetFlags()[8];}
0
public TestRecordWithoutLogicalTypes.Builder clearTs()
{    fieldSetFlags()[8] = false;    return this;}
0
public java.nio.ByteBuffer getDec()
{    return dec;}
0
public TestRecordWithoutLogicalTypes.Builder setDec(java.nio.ByteBuffer value)
{    validate(fields()[9], value);    this.dec = value;    fieldSetFlags()[9] = true;    return this;}
0
public boolean hasDec()
{    return fieldSetFlags()[9];}
0
public TestRecordWithoutLogicalTypes.Builder clearDec()
{    fieldSetFlags()[9] = false;    return this;}
0
public TestRecordWithoutLogicalTypes build()
{    try {        TestRecordWithoutLogicalTypes record = new TestRecordWithoutLogicalTypes();        record.b = fieldSetFlags()[0] ? this.b : (java.lang.Boolean) defaultValue(fields()[0]);        record.i32 = fieldSetFlags()[1] ? this.i32 : (java.lang.Integer) defaultValue(fields()[1]);        record.i64 = fieldSetFlags()[2] ? this.i64 : (java.lang.Long) defaultValue(fields()[2]);        record.f32 = fieldSetFlags()[3] ? this.f32 : (java.lang.Float) defaultValue(fields()[3]);        record.f64 = fieldSetFlags()[4] ? this.f64 : (java.lang.Double) defaultValue(fields()[4]);        record.s = fieldSetFlags()[5] ? this.s : (java.lang.String) defaultValue(fields()[5]);        record.d = fieldSetFlags()[6] ? this.d : (java.lang.Integer) defaultValue(fields()[6]);        record.t = fieldSetFlags()[7] ? this.t : (java.lang.Integer) defaultValue(fields()[7]);        record.ts = fieldSetFlags()[8] ? this.ts : (java.lang.Long) defaultValue(fields()[8]);        record.dec = fieldSetFlags()[9] ? this.dec : (java.nio.ByteBuffer) defaultValue(fields()[9]);        return record;    } catch (Exception e) {        throw new org.apache.avro.AvroRuntimeException(e);    }}
0
public void setUp()
{    Schema intSchema = Schema.create(Type.INT);    intClass = SpecificData.get().getClass(intSchema);    Schema nullSchema = Schema.create(Type.NULL);    Schema nullIntUnionSchema = Schema.createUnion(Arrays.asList(nullSchema, intSchema));    integerClass = SpecificData.get().getClass(nullIntUnionSchema);}
0
public void testClassTypes()
{    assertTrue(intClass.isPrimitive());    assertFalse(integerClass.isPrimitive());}
0
public void testPrimitiveParam() throws Exception
{    assertNotNull(Reflection.class.getMethod("primitive", intClass));}
0
public void testPrimitiveParamError() throws Exception
{    Reflection.class.getMethod("primitiveWrapper", intClass);}
0
public void testPrimitiveWrapperParam() throws Exception
{    assertNotNull(Reflection.class.getMethod("primitiveWrapper", integerClass));}
0
public void testPrimitiveWrapperParamError() throws Exception
{    Reflection.class.getMethod("primitive", integerClass);}
0
public void primitive(int i)
{}
0
public void primitiveWrapper(Integer i)
{}
0
public void put(int i, Object v)
{    switch(i) {        case 0:            x = (Integer) v;            break;        case 1:            y = (String) v;            break;        default:            throw new RuntimeException();    }}
0
public Object get(int i)
{    switch(i) {        case 0:            return x;        case 1:            return y;    }    throw new RuntimeException();}
0
public Schema getSchema()
{    return SCHEMA;}
0
public void testSpecificRecordBase()
{    final TestRecord record = new TestRecord();    record.put("x", 1);    record.put("y", "str");    assertEquals(1, record.get("x"));    assertEquals("str", record.get("y"));}
0
public void testExternalizeable() throws Exception
{    final TestRecord before = new TestRecord();    before.put("x", 1);    before.put("y", "str");    ByteArrayOutputStream bytes = new ByteArrayOutputStream();    ObjectOutputStream out = new ObjectOutputStream(bytes);    out.writeObject(before);    out.close();    ObjectInputStream in = new ObjectInputStream(new ByteArrayInputStream(bytes.toByteArray()));    TestRecord after = (TestRecord) in.readObject();    assertEquals(before, after);}
0
public void testNonStringable() throws Exception
{    final Schema string = Schema.create(Type.STRING);    final ByteArrayOutputStream baos = new ByteArrayOutputStream();    final Encoder encoder = EncoderFactory.get().directBinaryEncoder(baos, null);    final DatumWriter<Object> writer = new SpecificDatumWriter<>(string);    try {        writer.write(new Object(), encoder);        fail("Non stringable object should be rejected.");    } catch (ClassCastException cce) {        }}
0
public void testSpecificToFromByteBufferWithLogicalTypes() throws IOException
{                LocalTime t = LocalTime.now().truncatedTo(ChronoUnit.MILLIS);    Instant instant = Instant.now().truncatedTo(ChronoUnit.MILLIS);    final TestRecordWithLogicalTypes record = new TestRecordWithLogicalTypes(true, 34, 35L, 3.14F, 3019.34, null, LocalDate.now(), t, instant, new BigDecimal("123.45"));    final ByteBuffer b = record.toByteBuffer();    final TestRecordWithLogicalTypes copy = TestRecordWithLogicalTypes.fromByteBuffer(b);    assertEquals(record, copy);}
0
public void testSpecificToFromByteBufferWithoutLogicalTypes() throws IOException
{    final TestRecordWithoutLogicalTypes record = new TestRecordWithoutLogicalTypes(true, 34, 35L, 3.14F, 3019.34, null, (int) System.currentTimeMillis() / 1000, (int) System.currentTimeMillis() / 1000, System.currentTimeMillis(), new Conversions.DecimalConversion().toBytes(new BigDecimal("123.45"), null, LogicalTypes.decimal(9, 2)));    final ByteBuffer b = record.toByteBuffer();    final TestRecordWithoutLogicalTypes copy = TestRecordWithoutLogicalTypes.fromByteBuffer(b);    assertEquals(record, copy);}
0
public void testSpecificByteArrayIncompatibleWithLogicalTypes() throws IOException
{    final TestRecordWithoutLogicalTypes withoutLogicalTypes = new TestRecordWithoutLogicalTypes(true, 34, 35L, 3.14F, 3019.34, null, (int) System.currentTimeMillis() / 1000, (int) System.currentTimeMillis() / 1000, System.currentTimeMillis(), new Conversions.DecimalConversion().toBytes(new BigDecimal("123.45"), null, LogicalTypes.decimal(9, 2)));    final ByteBuffer b = withoutLogicalTypes.toByteBuffer();    TestRecordWithLogicalTypes.fromByteBuffer(b);}
0
public void testSpecificByteArrayIncompatibleWithoutLogicalTypes() throws IOException
{    final TestRecordWithLogicalTypes withLogicalTypes = new TestRecordWithLogicalTypes(true, 34, 35L, 3.14F, 3019.34, null, LocalDate.now(), LocalTime.now(), Instant.now(), new BigDecimal("123.45"));    final ByteBuffer b = withLogicalTypes.toByteBuffer();    TestRecordWithoutLogicalTypes.fromByteBuffer(b);}
0
public Schema addToSchema(Schema schema)
{    super.addToSchema(schema);    schema.addProp(REF_FIELD_NAME, refFieldName);    return schema;}
0
public String getName()
{    return REFERENCE;}
0
public String getRefFieldName()
{    return refFieldName;}
0
public void validate(Schema schema)
{    super.validate(schema);    if (schema.getField(refFieldName) == null) {        throw new IllegalArgumentException("Invalid field name for reference field: " + refFieldName);    }}
0
public Schema addToSchema(Schema schema)
{    super.addToSchema(schema);    schema.addProp(ID_FIELD_NAME, idFieldName);    return schema;}
0
public String getName()
{    return REFERENCEABLE;}
0
public String getIdFieldName()
{    return idFieldName;}
0
public void validate(Schema schema)
{    super.validate(schema);    Schema.Field idField = schema.getField(idFieldName);    if (idField == null || idField.schema().getType() != Schema.Type.LONG) {        throw new IllegalArgumentException("Invalid ID field: " + idFieldName + ": " + idField);    }}
0
public static void addReferenceTypes()
{    LogicalTypes.register(Referenceable.REFERENCEABLE, Referenceable::new);    LogicalTypes.register(Reference.REFERENCE, Reference::new);}
0
public ReferenceableTracker getTracker()
{    return tracker;}
0
public ReferenceHandler getHandler()
{    return handler;}
0
public Class<IndexedRecord> getConvertedType()
{    return (Class) Record.class;}
0
public String getLogicalTypeName()
{    return Referenceable.REFERENCEABLE;}
0
public IndexedRecord fromRecord(IndexedRecord value, Schema schema, LogicalType type)
{        long id = getId(value, schema);        references.put(id, value);        List<Callback> callbacks = callbacksById.get(id);    for (Callback callback : callbacks) {        callback.set(value);    }    return value;}
0
public IndexedRecord toRecord(IndexedRecord value, Schema schema, LogicalType type)
{        long id = getId(value, schema);            ids.put(value, id);    return value;}
0
private long getId(IndexedRecord referenceable, Schema schema)
{    Referenceable info = (Referenceable) schema.getLogicalType();    int idField = schema.getField(info.getIdFieldName()).pos();    return (Long) referenceable.get(idField);}
0
public Class<IndexedRecord> getConvertedType()
{    return (Class) Record.class;}
0
public String getLogicalTypeName()
{    return Reference.REFERENCE;}
0
public IndexedRecord fromRecord(final IndexedRecord record, Schema schema, LogicalType type)
{        final Schema.Field refField = schema.getField(((Reference) type).getRefFieldName());    Long id = (Long) record.get(refField.pos());    if (id != null) {        if (references.containsKey(id)) {            record.put(refField.pos(), references.get(id));        } else {            List<Callback> callbacks = callbacksById.computeIfAbsent(id, k -> new ArrayList<>());                        callbacks.add(referenceable -> record.put(refField.pos(), referenceable));        }    }    return record;}
0
public IndexedRecord toRecord(IndexedRecord record, Schema schema, LogicalType type)
{        Schema.Field refField = schema.getField(((Reference) type).getRefFieldName());    IndexedRecord referenced = (IndexedRecord) record.get(refField.pos());    if (referenced == null) {        return record;    }        return new HijackingIndexedRecord(record, refField.pos(), ids.get(referenced));}
0
public void put(int i, Object v)
{    throw new RuntimeException("[BUG] This is a read-only class.");}
0
public Object get(int i)
{    if (i == index) {        return data;    }    return wrapped.get(i);}
0
public Schema getSchema()
{    return wrapped.getSchema();}
0
public void test() throws IOException
{    ReferenceManager manager = new ReferenceManager();    GenericData model = new GenericData();    model.addLogicalTypeConversion(manager.getTracker());    model.addLogicalTypeConversion(manager.getHandler());    Schema parentSchema = Schema.createRecord("Parent", null, null, false);    Schema parentRefSchema = Schema.createUnion(Schema.create(Schema.Type.NULL), Schema.create(Schema.Type.LONG), parentSchema);    Reference parentRef = new Reference("parent");    List<Schema.Field> childFields = new ArrayList<>();    childFields.add(new Schema.Field("c", Schema.create(Schema.Type.STRING)));    childFields.add(new Schema.Field("parent", parentRefSchema));    Schema childSchema = parentRef.addToSchema(Schema.createRecord("Child", null, null, false, childFields));    List<Schema.Field> parentFields = new ArrayList<>();    parentFields.add(new Schema.Field("id", Schema.create(Schema.Type.LONG)));    parentFields.add(new Schema.Field("p", Schema.create(Schema.Type.STRING)));    parentFields.add(new Schema.Field("child", childSchema));    parentSchema.setFields(parentFields);    Referenceable idRef = new Referenceable("id");    Schema schema = idRef.addToSchema(parentSchema);    System.out.println("Schema: " + schema.toString(true));    Record parent = new Record(schema);    parent.put("id", 1L);    parent.put("p", "parent data!");    Record child = new Record(childSchema);    child.put("c", "child data!");    child.put("parent", parent);    parent.put("child", child);        File data = write(model, schema, parent);    List<Record> records = read(model, schema, data);    Record actual = records.get(0);        Assert.assertEquals("Should correctly read back the parent id", 1L, actual.get("id"));    Assert.assertEquals("Should correctly read back the parent data", new Utf8("parent data!"), actual.get("p"));    Record actualChild = (Record) actual.get("child");    Assert.assertEquals("Should correctly read back the child data", new Utf8("child data!"), actualChild.get("c"));    Object childParent = actualChild.get("parent");    Assert.assertTrue("Should have a parent Record object", childParent instanceof Record);    Record childParentRecord = (Record) actualChild.get("parent");    Assert.assertEquals("Should have the right parent id", 1L, childParentRecord.get("id"));    Assert.assertEquals("Should have the right parent data", new Utf8("parent data!"), childParentRecord.get("p"));}
0
private List<D> read(GenericData model, Schema schema, File file) throws IOException
{    DatumReader<D> reader = newReader(model, schema);    List<D> data = new ArrayList<>();    try (FileReader<D> fileReader = new DataFileReader<>(file, reader)) {        for (D datum : fileReader) {            data.add(datum);        }    }    return data;}
0
private DatumReader<D> newReader(GenericData model, Schema schema)
{    return model.createDatumReader(schema);}
0
private File write(GenericData model, Schema schema, D... data) throws IOException
{    File file = temp.newFile();    DatumWriter<D> writer = model.createDatumWriter(schema);    try (DataFileWriter<D> fileWriter = new DataFileWriter<>(writer)) {        fileWriter.create(schema, file);        for (D datum : data) {            fileWriter.append(datum);        }    }    return file;}
0
public static List<Object[]> codecs()
{    List<Object[]> r = new ArrayList<>();    r.add(new Object[] { null });    r.add(new Object[] { CodecFactory.deflateCodec(0) });    r.add(new Object[] { CodecFactory.deflateCodec(1) });    r.add(new Object[] { CodecFactory.deflateCodec(9) });    r.add(new Object[] { CodecFactory.nullCodec() });    r.add(new Object[] { CodecFactory.snappyCodec() });    r.add(new Object[] { CodecFactory.xzCodec(0) });    r.add(new Object[] { CodecFactory.xzCodec(1) });    r.add(new Object[] { CodecFactory.xzCodec(6) });    r.add(new Object[] { CodecFactory.zstandardCodec(-5) });    r.add(new Object[] { CodecFactory.zstandardCodec(0, true) });    r.add(new Object[] { CodecFactory.zstandardCodec(5, false) });    r.add(new Object[] { CodecFactory.zstandardCodec(18, true) });    return r;}
0
private File makeFile()
{    return new File(DIR.getRoot().getPath(), "test-" + codec + ".avro");}
0
public void runTestsInOrder() throws Exception
{    testGenericWrite();    testGenericRead();    testSplits();    testSyncDiscovery();    testGenericAppend();    testReadWithHeader();    testFSync(false);    testFSync(true);}
0
private void testGenericWrite() throws IOException
{    DataFileWriter<Object> writer = new DataFileWriter<>(new GenericDatumWriter<>()).setSyncInterval(100);    if (codec != null) {        writer.setCodec(codec);    }    writer.create(SCHEMA, makeFile());    try {        int count = 0;        for (Object datum : new RandomData(SCHEMA, COUNT, SEED)) {            writer.append(datum);            if (++count % (COUNT / 3) == 0)                                writer.sync();            if (count == 5) {                                boolean threwProperly = false;                try {                    GenericData.Record record = (GenericData.Record) datum;                    record.put(1, null);                    threwProperly = true;                    writer.append(record);                    threwProperly = false;                } catch (DataFileWriter.AppendWriteException e) {                    System.out.println("Ignoring: " + e);                }                assertTrue("failed to throw when expected", threwProperly);            }        }    } finally {        writer.close();    }        Exception doubleCloseEx = null;    try {        writer.close();    } catch (Exception e) {        doubleCloseEx = e;    }    assertNull("Double close() threw an unexpected exception", doubleCloseEx);}
0
private void testGenericRead() throws IOException
{    try (DataFileReader<Object> reader = new DataFileReader<>(makeFile(), new GenericDatumReader<>())) {        Object datum = null;        if (VALIDATE) {            for (Object expected : new RandomData(SCHEMA, COUNT, SEED)) {                datum = reader.next(datum);                assertEquals(expected, datum);            }        } else {            for (int i = 0; i < COUNT; i++) {                datum = reader.next(datum);            }        }    }}
0
private void testSplits() throws IOException
{    File file = makeFile();    try (DataFileReader<Object> reader = new DataFileReader<>(file, new GenericDatumReader<>())) {        Random rand = new Random(SEED);                int splits = 10;                int length = (int) file.length();                int end = length;                int remaining = end;                int count = 0;        while (remaining > 0) {            int start = Math.max(0, end - rand.nextInt(2 * length / splits));                        reader.sync(start);            while (!reader.pastSync(end)) {                reader.next();                count++;            }            remaining -= end - start;            end = start;        }        assertEquals(COUNT, count);    }}
0
private void testSyncDiscovery() throws IOException
{    File file = makeFile();    try (DataFileReader<Object> reader = new DataFileReader<>(file, new GenericDatumReader<>())) {                ArrayList<Long> syncs = new ArrayList<>();        long previousSync = -1;        while (reader.hasNext()) {            if (reader.previousSync() != previousSync) {                previousSync = reader.previousSync();                syncs.add(previousSync);            }            reader.next();        }                reader.sync(0);        assertEquals(reader.previousSync(), (long) syncs.get(0));                for (Long sync : syncs) {            reader.seek(sync);            assertNotNull(reader.next());        }    }}
0
private void testGenericAppend() throws IOException
{    File file = makeFile();    long start = file.length();    try (DataFileWriter<Object> writer = new DataFileWriter<>(new GenericDatumWriter<>()).appendTo(file)) {        for (Object datum : new RandomData(SCHEMA, COUNT, SEED + 1)) {            writer.append(datum);        }    }    try (DataFileReader<Object> reader = new DataFileReader<>(file, new GenericDatumReader<>())) {        reader.seek(start);        Object datum = null;        if (VALIDATE) {            for (Object expected : new RandomData(SCHEMA, COUNT, SEED + 1)) {                datum = reader.next(datum);                assertEquals(expected, datum);            }        } else {            for (int i = 0; i < COUNT; i++) {                datum = reader.next(datum);            }        }    }}
0
private void testReadWithHeader() throws IOException
{    File file = makeFile();    DataFileReader<Object> reader = new DataFileReader<>(file, new GenericDatumReader<>());        DataFileStream.Header header = reader.getHeader();        SeekableFileInput sin = new SeekableFileInput(file);    sin.seek(sin.length() / 2);    reader = DataFileReader.openReader(sin, new GenericDatumReader<>(), header, true);    assertNotNull("Should be able to reopen from arbitrary point", reader.next());    long validPos = reader.previousSync();        sin.seek(validPos);    reader = DataFileReader.openReader(sin, new GenericDatumReader<>(), header, false);    assertEquals("Should not move from sync point on reopen", validPos, sin.tell());    assertNotNull("Should be able to reopen at sync point", reader.next());}
0
public void testSyncInHeader() throws IOException
{    DataFileReader<Object> reader = new DataFileReader<>(new File("../../../share/test/data/syncInMeta.avro"), new GenericDatumReader<>());    reader.sync(0);    for (Object datum : reader) assertNotNull(datum);}
0
public void test12() throws IOException
{    readFile(new File("../../../share/test/data/test.avro12"), new GenericDatumReader<>());}
0
public void testFlushCount() throws IOException
{    DataFileWriter<Object> writer = new DataFileWriter<>(new GenericDatumWriter<>());    writer.setFlushOnEveryBlock(false);    TestingByteArrayOutputStream out = new TestingByteArrayOutputStream();    writer.create(SCHEMA, out);    int currentCount = 0;    int flushCounter = 0;    try {        for (Object datum : new RandomData(SCHEMA, COUNT, SEED + 1)) {            currentCount++;            writer.append(datum);            writer.sync();            if (currentCount % 10 == 0) {                flushCounter++;                writer.flush();            }        }    } finally {        writer.close();    }    System.out.println("Total number of flushes: " + out.flushCount);                        assertTrue(out.flushCount < currentCount && out.flushCount >= flushCounter);}
0
private void testFSync(boolean useFile) throws IOException
{    try (DataFileWriter<Object> writer = new DataFileWriter<>(new GenericDatumWriter<>())) {        writer.setFlushOnEveryBlock(false);        TestingByteArrayOutputStream out = new TestingByteArrayOutputStream();        if (useFile) {            File f = makeFile();            try (SeekableFileInput in = new SeekableFileInput(f)) {                writer.appendTo(in, out);            }        } else {            writer.create(SCHEMA, out);        }        int currentCount = 0;        int syncCounter = 0;        for (Object datum : new RandomData(SCHEMA, COUNT, SEED + 1)) {            currentCount++;            writer.append(datum);            if (currentCount % 10 == 0) {                writer.fSync();                syncCounter++;            }        }        System.out.println("Total number of syncs: " + out.syncCount);        assertEquals(syncCounter, out.syncCount);    }}
0
 static void readFile(File f, DatumReader<? extends Object> datumReader) throws IOException
{    FileReader<? extends Object> reader = DataFileReader.openReader(f, datumReader);    for (Object datum : reader) {        assertNotNull(datum);    }}
0
public static void main(String[] args) throws Exception
{    File input = new File(args[0]);    Schema projection = null;    if (args.length > 1)        projection = new Schema.Parser().parse(new File(args[1]));    TestDataFile.readFile(input, new GenericDatumReader<>(null, projection));    long start = System.currentTimeMillis();    for (int i = 0; i < 4; i++) TestDataFile.readFile(input, new GenericDatumReader<>(null, projection));    System.out.println("Time: " + (System.currentTimeMillis() - start));}
0
public void flush() throws IOException
{    super.flush();    flushCount++;}
0
public void sync() throws IOException
{    syncCount++;}
0
public static List<Object[]> codecs()
{    List<Object[]> r = new ArrayList<>();    r.add(new Object[] { null, null, false });    r.add(new Object[] { null, null, true });    r.add(new Object[] { CodecFactory.deflateCodec(1), CodecFactory.deflateCodec(6), false });    r.add(new Object[] { CodecFactory.deflateCodec(1), CodecFactory.deflateCodec(6), true });    r.add(new Object[] { CodecFactory.deflateCodec(3), CodecFactory.nullCodec(), false });    r.add(new Object[] { CodecFactory.nullCodec(), CodecFactory.deflateCodec(6), false });    r.add(new Object[] { CodecFactory.xzCodec(1), CodecFactory.xzCodec(2), false });    r.add(new Object[] { CodecFactory.xzCodec(1), CodecFactory.xzCodec(2), true });    r.add(new Object[] { CodecFactory.xzCodec(2), CodecFactory.nullCodec(), false });    r.add(new Object[] { CodecFactory.nullCodec(), CodecFactory.xzCodec(2), false });    return r;}
0
private File makeFile(String name)
{    return new File(DIR.getRoot().getPath(), "test-" + name + ".avro");}
0
public void testConcatenateFiles() throws IOException
{    System.out.println("SEED = " + SEED);    System.out.println("COUNT = " + COUNT);    for (int k = 0; k < 5; k++) {        int syncInterval = 460 + k;        RandomData data1 = new RandomData(SCHEMA, COUNT, SEED);        RandomData data2 = new RandomData(SCHEMA, COUNT, SEED + 1);        File file1 = makeFile((codec == null ? "null" : codec.toString()) + "-A");        File file2 = makeFile((codec2 == null ? "null" : codec2.toString()) + "-B");        DataFileWriter<Object> writer = new DataFileWriter<>(new GenericDatumWriter<>()).setSyncInterval(syncInterval);        if (codec != null) {            writer.setCodec(codec);        }        writer.create(SCHEMA, file1);        try {            for (Object datum : data1) {                writer.append(datum);            }        } finally {            writer.close();        }        DataFileWriter<Object> writer2 = new DataFileWriter<>(new GenericDatumWriter<>()).setSyncInterval(syncInterval);        if (codec2 != null) {            writer2.setCodec(codec2);        }        writer2.create(SCHEMA, file2);        try {            for (Object datum : data2) {                writer2.append(datum);            }        } finally {            writer2.close();        }        DataFileWriter<Object> concatinto = new DataFileWriter<>(new GenericDatumWriter<>()).setSyncInterval(syncInterval);        concatinto.appendTo(file1);        DataFileReader<Object> concatfrom = new DataFileReader<>(file2, new GenericDatumReader<>());        concatinto.appendAllFrom(concatfrom, recompress);        concatinto.close();        concatfrom.close();        concatfrom = new DataFileReader<>(file2, new GenericDatumReader<>());        DataFileReader<Object> concat = new DataFileReader<>(file1, new GenericDatumReader<>());        int count = 0;        try {            Object datum = null;            if (VALIDATE) {                for (Object expected : data1) {                    datum = concat.next(datum);                    assertEquals("at " + count++, expected, datum);                }                for (Object expected : data2) {                    datum = concatfrom.next(datum);                    assertEquals("at " + count++, expected, datum);                }                for (Object expected : data2) {                    datum = concat.next(datum);                    assertEquals("at " + count++, expected, datum);                }            } else {                for (int i = 0; i < COUNT * 2; i++) {                    datum = concat.next(datum);                }            }        } finally {            if (count != 3 * COUNT) {                System.out.println(count + " " + k);            }            concat.close();            concatfrom.close();        }    }}
0
private File makeFile(String name)
{    return new File(DIR, "test-" + name + ".avro");}
0
public void testCorruptedFile() throws IOException
{    Schema schema = Schema.create(Type.STRING);        DataFileWriter<Utf8> w = new DataFileWriter<>(new GenericDatumWriter<>(schema));    ByteArrayOutputStream baos = new ByteArrayOutputStream();    w.create(schema, baos);    w.append(new Utf8("apple"));    w.append(new Utf8("banana"));    w.sync();    w.append(new Utf8("celery"));    w.append(new Utf8("date"));    long pos = w.sync();    w.append(new Utf8("endive"));    w.append(new Utf8("fig"));    w.close();            byte[] original = baos.toByteArray();    int corruptPosition = (int) pos - DataFileConstants.SYNC_SIZE;    int corruptedBytes = 3;    byte[] corrupted = new byte[original.length + corruptedBytes];    System.arraycopy(original, 0, corrupted, 0, corruptPosition);    System.arraycopy(original, corruptPosition, corrupted, corruptPosition + corruptedBytes, original.length - corruptPosition);    File file = makeFile("corrupt");    file.deleteOnExit();    FileOutputStream out = new FileOutputStream(file);    out.write(corrupted);    out.close();        DataFileReader r = new DataFileReader<>(file, new GenericDatumReader<>(schema));    assertEquals("apple", r.next().toString());    assertEquals("banana", r.next().toString());    long prevSync = r.previousSync();    try {        r.next();        fail("Corrupt block should throw exception");    } catch (AvroRuntimeException e) {        assertEquals("Invalid sync!", e.getCause().getMessage());    }        r.sync(prevSync);    assertEquals("endive", r.next().toString());    assertEquals("fig", r.next().toString());    assertFalse(r.hasNext());}
0
private byte[] createDataFile(byte[] sync) throws IOException
{    Schema schema = Schema.create(Type.STRING);    DataFileWriter<Utf8> w = new DataFileWriter<>(new GenericDatumWriter<>(schema));    ByteArrayOutputStream baos = new ByteArrayOutputStream();    w.create(schema, baos, sync);    w.append(new Utf8("apple"));    w.append(new Utf8("banana"));    w.sync();    w.append(new Utf8("celery"));    w.append(new Utf8("date"));    w.sync();    w.append(new Utf8("endive"));    w.append(new Utf8("fig"));    w.close();    return baos.toByteArray();}
0
private static byte[] generateSync()
{    try {        MessageDigest digester = MessageDigest.getInstance("MD5");        long time = System.currentTimeMillis();        digester.update((UUID.randomUUID() + "@" + time).getBytes(UTF_8));        return digester.digest();    } catch (NoSuchAlgorithmException e) {        throw new RuntimeException(e);    }}
0
public void testInvalidSync() throws IOException
{        byte[] sync = new byte[8];    createDataFile(sync);}
0
public void testRandomSync() throws IOException
{    byte[] sync = generateSync();    byte[] randSyncFile = createDataFile(null);    byte[] customSyncFile = createDataFile(sync);    assertFalse(Arrays.equals(randSyncFile, customSyncFile));}
0
public void testCustomSync() throws IOException
{    byte[] sync = generateSync();    byte[] customSyncFile = createDataFile(sync);    byte[] sameCustomSyncFile = createDataFile(sync);    assertTrue(Arrays.equals(customSyncFile, sameCustomSyncFile));}
0
public void testWriteAndRead() throws IOException
{    Schema schema = Schema.create(Type.STRING);        DataFileWriter<Utf8> w = new DataFileWriter<>(new GenericDatumWriter<>(schema));    w.setCodec(CodecFactory.deflateCodec(6));    ByteArrayOutputStream baos = new ByteArrayOutputStream();    w.create(schema, baos);    w.append(new Utf8("hello world"));    w.append(new Utf8("hello moon"));    w.sync();    w.append(new Utf8("bye bye world"));    w.append(new Utf8("bye bye moon"));    w.close();        DataFileStream<Utf8> r = new DataFileStream<>(new ByteArrayInputStream(baos.toByteArray()), new GenericDatumReader<>(schema));    assertEquals("hello world", r.next().toString());    assertEquals("hello moon", r.next().toString());    assertEquals("bye bye world", r.next().toString());    assertEquals("bye bye moon", r.next().toString());    assertFalse(r.hasNext());}
0
public void testUseReservedMeta()
{    DataFileWriter<?> w = new DataFileWriter<>(new GenericDatumWriter<>());    w.setMeta("avro.foo", "bar");}
0
public void testUseMeta() throws IOException
{    DataFileWriter<?> w = new DataFileWriter<>(new GenericDatumWriter<>());    File f = new File(DIR.getRoot().getPath(), "testDataFileMeta.avro");    w.setMeta("hello", "bar");    w.create(Schema.create(Type.NULL), f);    w.close();    DataFileStream<Void> r = new DataFileStream<>(new FileInputStream(f), new GenericDatumReader<>());    assertTrue(r.getMetaKeys().contains("hello"));    assertEquals("bar", r.getMetaString("hello"));}
0
public void testUseMetaAfterCreate() throws IOException
{    DataFileWriter<?> w = new DataFileWriter<>(new GenericDatumWriter<>());    w.create(Schema.create(Type.NULL), new ByteArrayOutputStream());    w.setMeta("foo", "bar");}
0
public void testBlockSizeSetInvalid()
{    int exceptions = 0;    for (int i = -1; i < 33; i++) {                try {            new DataFileWriter<>(new GenericDatumWriter<>()).setSyncInterval(i);        } catch (IllegalArgumentException iae) {            exceptions++;        }    }    assertEquals(33, exceptions);}
0
public void testForLeakingFileDescriptors() throws IOException
{    Path emptyFile = Files.createTempFile("empty", ".avro");    Files.deleteIfExists(emptyFile);    Files.createFile(emptyFile);    long openFilesBeforeOperation = getNumberOfOpenFileDescriptors();    try (DataFileReader<Object> reader = new DataFileReader<>(emptyFile.toFile(), new GenericDatumReader<>())) {        fail("Reading on empty file is supposed to fail.");    } catch (IOException e) {        }    Files.delete(emptyFile);    long openFilesAfterOperation = getNumberOfOpenFileDescriptors();        assertTrue("File descriptor leaked from new DataFileReader() (expected:" + openFilesBeforeOperation + " actual:" + openFilesAfterOperation + ")", openFilesBeforeOperation >= openFilesAfterOperation);}
0
private long getNumberOfOpenFileDescriptors()
{    OperatingSystemMXBean osMxBean = ManagementFactory.getOperatingSystemMXBean();    if (osMxBean instanceof UnixOperatingSystemMXBean) {        return ((UnixOperatingSystemMXBean) osMxBean).getOpenFileDescriptorCount();    }    return 0;}
0
public void testMultiReflectWithUnionBeforeWriting() throws IOException
{    File file = new File(DIR.getRoot().getPath(), "testMultiReflectWithUnionBeforeWriting.avro");    CheckList<Object> check = new CheckList<>();    try (FileOutputStream fos = new FileOutputStream(file)) {        ReflectData reflectData = ReflectData.get();        List<Schema> schemas = Arrays.asList(reflectData.getSchema(FooRecord.class), reflectData.getSchema(BarRecord.class));        Schema union = Schema.createUnion(schemas);        try (DataFileWriter<Object> writer = new DataFileWriter<>(new ReflectDatumWriter<>(union))) {            writer.create(union, fos);                        write(writer, new BarRecord("One beer please"), check);            write(writer, new FooRecord(10), check);            write(writer, new BarRecord("Two beers please"), check);            write(writer, new FooRecord(20), check);        }    }        ReflectDatumReader<Object> din = new ReflectDatumReader<>();    SeekableFileInput sin = new SeekableFileInput(file);    try (DataFileReader<Object> reader = new DataFileReader<>(sin, din)) {        int count = 0;        for (Object datum : reader) {            check.assertEquals(datum, count++);        }        Assert.assertEquals(count, check.size());    }}
0
public void testNull() throws IOException
{    File file = new File(DIR.getRoot().getPath(), "testNull.avro");    CheckList<BarRecord> check = new CheckList<>();    try (FileOutputStream fos = new FileOutputStream(file)) {        ReflectData reflectData = ReflectData.AllowNull.get();        Schema schema = reflectData.getSchema(BarRecord.class);        try (DataFileWriter<BarRecord> writer = new DataFileWriter<>(new ReflectDatumWriter<>(BarRecord.class, reflectData))) {            writer.create(schema, fos);                        write(writer, new BarRecord("One beer please"), check);                        write(writer, new BarRecord(), check);            write(writer, new BarRecord("Two beers please"), check);        }    }    ReflectDatumReader<BarRecord> din = new ReflectDatumReader<>();    try (SeekableFileInput sin = new SeekableFileInput(file)) {        try (DataFileReader<BarRecord> reader = new DataFileReader<>(sin, din)) {            int count = 0;            for (BarRecord datum : reader) {                check.assertEquals(datum, count++);            }            Assert.assertEquals(count, check.size());        }    }}
0
public void testNew() throws IOException
{    ByteBuffer payload = ByteBuffer.allocateDirect(8 * 1024);    for (int i = 0; i < 500; i++) {        payload.putInt(1);    }    payload.flip();    ByteBufferRecord bbr = new ByteBufferRecord();    bbr.setPayload(payload);    bbr.setTp(TypeEnum.b);    ByteArrayOutputStream outputStream = new ByteArrayOutputStream();    ReflectDatumWriter<ByteBufferRecord> writer = new ReflectDatumWriter<>(ByteBufferRecord.class);    BinaryEncoder avroEncoder = EncoderFactory.get().blockingBinaryEncoder(outputStream, null);    writer.write(bbr, avroEncoder);    avroEncoder.flush();    byte[] bytes = outputStream.toByteArray();    ByteArrayInputStream inputStream = new ByteArrayInputStream(bytes);    ReflectDatumReader<ByteBufferRecord> datumReader = new ReflectDatumReader<>(ByteBufferRecord.class);    BinaryDecoder avroDecoder = DecoderFactory.get().binaryDecoder(inputStream, null);    ByteBufferRecord deserialized = datumReader.read(null, avroDecoder);    Assert.assertEquals(bbr, deserialized);}
0
public void testNestedClass() throws IOException
{    File file = new File(DIR.getRoot().getPath(), "testNull.avro");    CheckList<BazRecord> check = new CheckList<>();    try (FileOutputStream fos = new FileOutputStream(file)) {        Schema schema = ReflectData.get().getSchema(BazRecord.class);        try (DataFileWriter<BazRecord> writer = new DataFileWriter<>(new ReflectDatumWriter<>(schema))) {            writer.create(schema, fos);                        write(writer, new BazRecord(10), check);            write(writer, new BazRecord(20), check);        }    }    ReflectDatumReader<BazRecord> din = new ReflectDatumReader<>();    try (SeekableFileInput sin = new SeekableFileInput(file)) {        try (DataFileReader<BazRecord> reader = new DataFileReader<>(sin, din)) {            int count = 0;            for (BazRecord datum : reader) {                check.assertEquals(datum, count++);            }            Assert.assertEquals(count, check.size());        }    }}
0
private void write(DataFileWriter<T> writer, T o, CheckList<T> l) throws IOException
{    writer.append(l.addAndReturn(o));}
0
 T addAndReturn(T check)
{    add(check);    return check;}
0
 void assertEquals(Object toCheck, int i)
{    Assert.assertNotNull(toCheck);    Object o = get(i);    Assert.assertNotNull(o);    Assert.assertEquals(toCheck, o);}
0
public boolean equals(Object that)
{    if (that instanceof BazRecord) {        return this.nbr == ((BazRecord) that).nbr;    }    return false;}
0
public int hashCode()
{    return nbr;}
0
public String toString()
{    return BazRecord.class.getSimpleName() + "{cnt=" + nbr + "}";}
0
public void testFixedDefaultValueDrop()
{    Schema md5 = SchemaBuilder.builder().fixed("MD5").size(16);    Schema frec = SchemaBuilder.builder().record("test").fields().name("hash").type(md5).withDefault(new byte[16]).endRecord();    Schema.Field field = frec.getField("hash");    Assert.assertNotNull(field.defaultVal());    Assert.assertArrayEquals(new byte[16], (byte[]) field.defaultVal());}
0
public void testDecimalFromSchema()
{    Schema schema = Schema.createFixed("aFixed", null, null, 4);    schema.addProp("logicalType", "decimal");    schema.addProp("precision", 9);    schema.addProp("scale", 2);    LogicalType logicalType = LogicalTypes.fromSchemaIgnoreInvalid(schema);    Assert.assertTrue("Should be a Decimal", logicalType instanceof LogicalTypes.Decimal);    LogicalTypes.Decimal decimal = (LogicalTypes.Decimal) logicalType;    Assert.assertEquals("Should have correct precision", 9, decimal.getPrecision());    Assert.assertEquals("Should have correct scale", 2, decimal.getScale());}
0
public void testInvalidLogicalTypeIgnored()
{    final Schema schema = Schema.createFixed("aFixed", null, null, 2);    schema.addProp("logicalType", "decimal");    schema.addProp("precision", 9);    schema.addProp("scale", 2);    Assert.assertNull("Should ignore invalid logical type", LogicalTypes.fromSchemaIgnoreInvalid(schema));}
0
public void testDecimalWithNonByteArrayTypes()
{    final LogicalType decimal = LogicalTypes.decimal(5, 2);        Schema[] nonBytes = new Schema[] { Schema.createRecord("Record", null, null, false), Schema.createArray(Schema.create(Schema.Type.BYTES)), Schema.createMap(Schema.create(Schema.Type.BYTES)), Schema.createEnum("Enum", null, null, Arrays.asList("a", "b")), Schema.createUnion(Arrays.asList(Schema.create(Schema.Type.BYTES), Schema.createFixed("fixed", null, null, 4))), Schema.create(Schema.Type.BOOLEAN), Schema.create(Schema.Type.INT), Schema.create(Schema.Type.LONG), Schema.create(Schema.Type.FLOAT), Schema.create(Schema.Type.DOUBLE), Schema.create(Schema.Type.NULL), Schema.create(Schema.Type.STRING) };    for (final Schema schema : nonBytes) {        assertThrows("Should reject type: " + schema.getType(), IllegalArgumentException.class, "Logical type decimal must be backed by fixed or bytes", () -> {            decimal.addToSchema(schema);            return null;        });    }}
0
public void testUnknownFromJsonNode()
{    Schema schema = Schema.create(Schema.Type.STRING);    schema.addProp("logicalType", "unknown");    schema.addProp("someProperty", 34);    LogicalType logicalType = LogicalTypes.fromSchemaIgnoreInvalid(schema);    Assert.assertNull("Should not return a LogicalType instance", logicalType);}
0
public void testDecimalBytesHasNoPrecisionLimit()
{    Schema schema = Schema.create(Schema.Type.BYTES);        LogicalTypes.decimal(Integer.MAX_VALUE).addToSchema(schema);    Assert.assertEquals("Precision should be an Integer.MAX_VALUE", Integer.MAX_VALUE, ((LogicalTypes.Decimal) LogicalTypes.fromSchemaIgnoreInvalid(schema)).getPrecision());}
0
public void testDecimalFixedPrecisionLimit()
{        final Schema schema = Schema.createFixed("aDecimal", null, null, 4);    assertThrows("Should reject precision", IllegalArgumentException.class, "fixed(4) cannot store 10 digits (max 9)", () -> {        LogicalTypes.decimal(10).addToSchema(schema);        return null;    });    Assert.assertNull("Invalid logical type should not be set on schema", LogicalTypes.fromSchemaIgnoreInvalid(schema));}
0
public void testDecimalFailsWithZeroPrecision()
{    final Schema schema = Schema.createFixed("aDecimal", null, null, 4);    assertThrows("Should reject precision", IllegalArgumentException.class, "Invalid decimal precision: 0 (must be positive)", () -> {        LogicalTypes.decimal(0).addToSchema(schema);        return null;    });    Assert.assertNull("Invalid logical type should not be set on schema", LogicalTypes.fromSchemaIgnoreInvalid(schema));}
0
public void testDecimalFailsWithNegativePrecision()
{    final Schema schema = Schema.createFixed("aDecimal", null, null, 4);    assertThrows("Should reject precision", IllegalArgumentException.class, "Invalid decimal precision: -9 (must be positive)", () -> {        LogicalTypes.decimal(-9).addToSchema(schema);        return null;    });    Assert.assertNull("Invalid logical type should not be set on schema", LogicalTypes.fromSchemaIgnoreInvalid(schema));}
0
public void testDecimalScaleBoundedByPrecision()
{    final Schema schema = Schema.createFixed("aDecimal", null, null, 4);    assertThrows("Should reject precision", IllegalArgumentException.class, "Invalid decimal scale: 10 (greater than precision: 9)", () -> {        LogicalTypes.decimal(9, 10).addToSchema(schema);        return null;    });    Assert.assertNull("Invalid logical type should not be set on schema", LogicalTypes.fromSchemaIgnoreInvalid(schema));}
0
public void testDecimalFailsWithNegativeScale()
{    final Schema schema = Schema.createFixed("aDecimal", null, null, 4);    assertThrows("Should reject precision", IllegalArgumentException.class, "Invalid decimal scale: -2 (must be positive)", () -> {        LogicalTypes.decimal(9, -2).addToSchema(schema);        return null;    });    Assert.assertNull("Invalid logical type should not be set on schema", LogicalTypes.fromSchemaIgnoreInvalid(schema));}
0
public void testSchemaRejectsSecondLogicalType()
{    final Schema schema = Schema.createFixed("aDecimal", null, null, 4);    LogicalTypes.decimal(9).addToSchema(schema);    assertThrows("Should reject second logical type", AvroRuntimeException.class, "Can't overwrite property: scale", () -> {        LogicalTypes.decimal(9, 2).addToSchema(schema);        return null;    });    Assert.assertEquals("First logical type should still be set on schema", LogicalTypes.decimal(9), LogicalTypes.fromSchemaIgnoreInvalid(schema));}
0
public void testDecimalDefaultScale()
{    Schema schema = Schema.createFixed("aDecimal", null, null, 4);        LogicalTypes.decimal(9).addToSchema(schema);    Assert.assertEquals("Scale should be a 0", 0, ((LogicalTypes.Decimal) LogicalTypes.fromSchemaIgnoreInvalid(schema)).getScale());}
0
public void testFixedDecimalToFromJson()
{    Schema schema = Schema.createFixed("aDecimal", null, null, 4);    LogicalTypes.decimal(9, 2).addToSchema(schema);    Schema parsed = new Schema.Parser().parse(schema.toString(true));    Assert.assertEquals("Constructed and parsed schemas should match", schema, parsed);}
0
public void testBytesDecimalToFromJson()
{    Schema schema = Schema.create(Schema.Type.BYTES);    LogicalTypes.decimal(9, 2).addToSchema(schema);    Schema parsed = new Schema.Parser().parse(schema.toString(true));    Assert.assertEquals("Constructed and parsed schemas should match", schema, parsed);}
0
public void testLogicalTypeEquals()
{    LogicalTypes.Decimal decimal90 = LogicalTypes.decimal(9);    LogicalTypes.Decimal decimal80 = LogicalTypes.decimal(8);    LogicalTypes.Decimal decimal92 = LogicalTypes.decimal(9, 2);    assertEqualsTrue("Same decimal", LogicalTypes.decimal(9, 0), decimal90);    assertEqualsTrue("Same decimal", LogicalTypes.decimal(8, 0), decimal80);    assertEqualsTrue("Same decimal", LogicalTypes.decimal(9, 2), decimal92);    assertEqualsFalse("Different logical type", LogicalTypes.uuid(), decimal90);    assertEqualsFalse("Different precision", decimal90, decimal80);    assertEqualsFalse("Different scale", decimal90, decimal92);}
0
public void testLogicalTypeInSchemaEquals()
{    Schema schema1 = Schema.createFixed("aDecimal", null, null, 4);    Schema schema2 = Schema.createFixed("aDecimal", null, null, 4);    Schema schema3 = Schema.createFixed("aDecimal", null, null, 4);    Assert.assertNotSame(schema1, schema2);    Assert.assertNotSame(schema1, schema3);    assertEqualsTrue("No logical types", schema1, schema2);    assertEqualsTrue("No logical types", schema1, schema3);    LogicalTypes.decimal(9).addToSchema(schema1);    assertEqualsFalse("Two has no logical type", schema1, schema2);    LogicalTypes.decimal(9).addToSchema(schema2);    assertEqualsTrue("Same logical types", schema1, schema2);    LogicalTypes.decimal(9, 2).addToSchema(schema3);    assertEqualsFalse("Different logical type", schema1, schema3);}
0
public static void assertEqualsTrue(String message, Object o1, Object o2)
{    Assert.assertTrue("Should be equal (forward): " + message, o1.equals(o2));    Assert.assertTrue("Should be equal (reverse): " + message, o2.equals(o1));}
0
public static void assertEqualsFalse(String message, Object o1, Object o2)
{    Assert.assertFalse("Should be equal (forward): " + message, o1.equals(o2));    Assert.assertFalse("Should be equal (reverse): " + message, o2.equals(o1));}
0
public static void assertThrows(String message, Class<? extends Exception> expected, String containedInMessage, Callable callable)
{    try {        callable.call();        Assert.fail("No exception was thrown (" + message + "), expected: " + expected.getName());    } catch (Exception actual) {        Assert.assertEquals(message, expected, actual.getClass());        Assert.assertTrue("Expected exception message (" + containedInMessage + ") missing: " + actual.getMessage(), actual.getMessage().contains(containedInMessage));    }}
0
public void testSingleSubRecord() throws IOException
{    final Schema child = SchemaBuilder.record("Child").namespace("org.apache.avro.nested").fields().requiredString("childField").endRecord();    final Schema parent = SchemaBuilder.record("Parent").namespace("org.apache.avro.nested").fields().requiredString("parentField1").name("child1").type(child).noDefault().requiredString("parentField2").endRecord();    final String inputAsExpected = "{\n" + " \"parentField1\": \"parentValue1\",\n" + " \"child1\":{\n" + "    \"childField\":\"childValue1\"\n" + " },\n" + " \"parentField2\":\"parentValue2\"\n" + "}";    final ByteArrayInputStream inputStream = new ByteArrayInputStream(inputAsExpected.getBytes(UTF_8));    final JsonDecoder decoder = DecoderFactory.get().jsonDecoder(parent, inputStream);    final DatumReader<Object> reader = new GenericDatumReader<>(parent);    final GenericData.Record decoded = (GenericData.Record) reader.read(null, decoder);    assertThat(decoded.get("parentField1").toString(), equalTo("parentValue1"));    assertThat(decoded.get("parentField2").toString(), equalTo("parentValue2"));    assertThat(((GenericData.Record) decoded.get("child1")).get("childField").toString(), equalTo("childValue1"));}
0
public void testSingleSubRecordExtraField() throws IOException
{    final Schema child = SchemaBuilder.record("Child").namespace("org.apache.avro.nested").fields().requiredString("childField").endRecord();    final Schema parent = SchemaBuilder.record("Parent").namespace("org.apache.avro.nested").fields().requiredString("parentField1").name("child1").type(child).noDefault().requiredString("parentField2").endRecord();    final String inputAsExpected = "{\n" + " \"parentField1\": \"parentValue1\",\n" + " \"child1\":{\n" + "    \"childField\":\"childValue1\",\n" +     "    \"extraField\":\"extraValue\"\n" + " },\n" + " \"parentField2\":\"parentValue2\"\n" + "}";    final ByteArrayInputStream inputStream = new ByteArrayInputStream(inputAsExpected.getBytes(UTF_8));    final JsonDecoder decoder = DecoderFactory.get().jsonDecoder(parent, inputStream);    final DatumReader<Object> reader = new GenericDatumReader<>(parent);    final GenericData.Record decoded = (GenericData.Record) reader.read(null, decoder);    assertThat(decoded.get("parentField1").toString(), equalTo("parentValue1"));    assertThat(decoded.get("parentField2").toString(), equalTo("parentValue2"));    assertThat(((GenericData.Record) decoded.get("child1")).get("childField").toString(), equalTo("childValue1"));}
0
public void testPropEquals()
{    Protocol p1 = new Protocol("P", null, "foo");    p1.addProp("a", "1");    Protocol p2 = new Protocol("P", null, "foo");    p2.addProp("a", "2");    assertFalse(p1.equals(p2));}
0
public void testSplitProtocolBuild()
{    Protocol p = new Protocol("P", null, "foo");    p.addProp("property", "some value");    String protocolString = p.toString();    final int mid = protocolString.length() / 2;    String[] parts = { protocolString.substring(0, mid), protocolString.substring(mid) };    Protocol parsedStringProtocol = org.apache.avro.Protocol.parse(protocolString);    Protocol parsedArrayOfStringProtocol = org.apache.avro.Protocol.parse(protocolString.substring(0, mid), protocolString.substring(mid));    assertNotNull(parsedStringProtocol);    assertNotNull(parsedArrayOfStringProtocol);    assertEquals(parsedStringProtocol.toString(), parsedArrayOfStringProtocol.toString());}
0
public static Collection<Object[]> data()
{    return Arrays.asList(new EncoderType[][] { { EncoderType.BINARY }, { EncoderType.JSON } });}
0
public void doubleWrittenWithUnionSchemaIsConvertedToDoubleSchema() throws Exception
{    Schema writer = UNION_INT_LONG_FLOAT_DOUBLE_RECORD;    Record record = defaultRecordWithSchema(writer, FIELD_A, 42.0);    byte[] encoded = encodeGenericBlob(record);    Record decoded = decodeGenericBlob(DOUBLE_RECORD, writer, encoded);    assertEquals(42.0, decoded.get(FIELD_A));}
0
public void longWrittenWithUnionSchemaIsConvertedToUnionLongFloatSchema() throws Exception
{    Schema writer = UNION_LONG_RECORD;    Record record = defaultRecordWithSchema(writer, FIELD_A, 42L);    byte[] encoded = encodeGenericBlob(record);    Record decoded = decodeGenericBlob(UNION_LONG_FLOAT_RECORD, writer, encoded);    assertEquals(42L, decoded.get(FIELD_A));}
0
public void longWrittenWithUnionSchemaIsConvertedToDoubleSchema() throws Exception
{    Schema writer = UNION_LONG_RECORD;    Record record = defaultRecordWithSchema(writer, FIELD_A, 42L);    byte[] encoded = encodeGenericBlob(record);    Record decoded = decodeGenericBlob(UNION_DOUBLE_RECORD, writer, encoded);    assertEquals(42.0, decoded.get(FIELD_A));}
0
public void intWrittenWithUnionSchemaIsConvertedToDoubleSchema() throws Exception
{    Schema writer = UNION_INT_RECORD;    Record record = defaultRecordWithSchema(writer, FIELD_A, 42);    byte[] encoded = encodeGenericBlob(record);    Record decoded = decodeGenericBlob(UNION_DOUBLE_RECORD, writer, encoded);    assertEquals(42.0, decoded.get(FIELD_A));}
0
public void intWrittenWithUnionSchemaIsReadableByFloatSchema() throws Exception
{    Schema writer = UNION_INT_RECORD;    Record record = defaultRecordWithSchema(writer, FIELD_A, 42);    byte[] encoded = encodeGenericBlob(record);    Record decoded = decodeGenericBlob(FLOAT_RECORD, writer, encoded);    assertEquals(42.0f, decoded.get(FIELD_A));}
0
public void intWrittenWithUnionSchemaIsReadableByFloatUnionSchema() throws Exception
{    Schema writer = UNION_INT_RECORD;    Record record = defaultRecordWithSchema(writer, FIELD_A, 42);    byte[] encoded = encodeGenericBlob(record);    Record decoded = decodeGenericBlob(UNION_FLOAT_RECORD, writer, encoded);    assertEquals(42.0f, decoded.get(FIELD_A));}
0
public void longWrittenWithUnionSchemaIsReadableByFloatSchema() throws Exception
{    Schema writer = UNION_LONG_RECORD;    Record record = defaultRecordWithSchema(writer, FIELD_A, 42L);    byte[] encoded = encodeGenericBlob(record);    Record decoded = decodeGenericBlob(FLOAT_RECORD, writer, encoded);    assertEquals(42.0f, decoded.get(FIELD_A));}
0
public void longWrittenWithUnionSchemaIsReadableByFloatUnionSchema() throws Exception
{    Schema writer = UNION_LONG_RECORD;    Record record = defaultRecordWithSchema(writer, FIELD_A, 42L);    byte[] encoded = encodeGenericBlob(record);    Record decoded = decodeGenericBlob(UNION_FLOAT_RECORD, writer, encoded);    assertEquals(42.0f, decoded.get(FIELD_A));}
0
public void longWrittenWithUnionSchemaIsConvertedToLongFloatUnionSchema() throws Exception
{    Schema writer = UNION_LONG_RECORD;    Record record = defaultRecordWithSchema(writer, FIELD_A, 42L);    byte[] encoded = encodeGenericBlob(record);    Record decoded = decodeGenericBlob(UNION_LONG_FLOAT_RECORD, writer, encoded);    assertEquals(42L, decoded.get(FIELD_A));}
0
public void longWrittenWithUnionSchemaIsConvertedToFloatDoubleUnionSchema() throws Exception
{    Schema writer = UNION_LONG_RECORD;    Record record = defaultRecordWithSchema(writer, FIELD_A, 42L);    byte[] encoded = encodeGenericBlob(record);    Record decoded = decodeGenericBlob(UNION_FLOAT_DOUBLE_RECORD, writer, encoded);    assertEquals(42.0F, decoded.get(FIELD_A));}
0
public void doubleWrittenWithUnionSchemaIsNotConvertedToFloatSchema() throws Exception
{    expectedException.expect(AvroTypeException.class);    expectedException.expectMessage("Found double, expecting float");    Schema writer = UNION_INT_LONG_FLOAT_DOUBLE_RECORD;    Record record = defaultRecordWithSchema(writer, FIELD_A, 42.0);    byte[] encoded = encodeGenericBlob(record);    decodeGenericBlob(FLOAT_RECORD, writer, encoded);}
0
public void floatWrittenWithUnionSchemaIsNotConvertedToLongSchema() throws Exception
{    expectedException.expect(AvroTypeException.class);    expectedException.expectMessage("Found float, expecting long");    Schema writer = UNION_INT_LONG_FLOAT_DOUBLE_RECORD;    Record record = defaultRecordWithSchema(writer, FIELD_A, 42.0f);    byte[] encoded = encodeGenericBlob(record);    decodeGenericBlob(LONG_RECORD, writer, encoded);}
0
public void longWrittenWithUnionSchemaIsNotConvertedToIntSchema() throws Exception
{    expectedException.expect(AvroTypeException.class);    expectedException.expectMessage("Found long, expecting int");    Schema writer = UNION_INT_LONG_FLOAT_DOUBLE_RECORD;    Record record = defaultRecordWithSchema(writer, FIELD_A, 42L);    byte[] encoded = encodeGenericBlob(record);    decodeGenericBlob(INT_RECORD, writer, encoded);}
0
public void intWrittenWithUnionSchemaIsConvertedToAllNumberSchemas() throws Exception
{    Schema writer = UNION_INT_LONG_FLOAT_DOUBLE_RECORD;    Record record = defaultRecordWithSchema(writer, FIELD_A, 42);    byte[] encoded = encodeGenericBlob(record);    assertEquals(42.0, decodeGenericBlob(DOUBLE_RECORD, writer, encoded).get(FIELD_A));    assertEquals(42.0f, decodeGenericBlob(FLOAT_RECORD, writer, encoded).get(FIELD_A));    assertEquals(42L, decodeGenericBlob(LONG_RECORD, writer, encoded).get(FIELD_A));    assertEquals(42, decodeGenericBlob(INT_RECORD, writer, encoded).get(FIELD_A));}
0
public void asciiStringWrittenWithUnionSchemaIsConvertedToBytesSchema() throws Exception
{    Schema writer = UNION_STRING_BYTES_RECORD;    Record record = defaultRecordWithSchema(writer, FIELD_A, "42");    byte[] encoded = encodeGenericBlob(record);    ByteBuffer actual = (ByteBuffer) decodeGenericBlob(BYTES_RECORD, writer, encoded).get(FIELD_A);    assertArrayEquals("42".getBytes(StandardCharsets.UTF_8), actual.array());}
0
public void utf8StringWrittenWithUnionSchemaIsConvertedToBytesSchema() throws Exception
{    String goeran = String.format("G%sran", LATIN_SMALL_LETTER_O_WITH_DIARESIS);    Schema writer = UNION_STRING_BYTES_RECORD;    Record record = defaultRecordWithSchema(writer, FIELD_A, goeran);    byte[] encoded = encodeGenericBlob(record);    ByteBuffer actual = (ByteBuffer) decodeGenericBlob(BYTES_RECORD, writer, encoded).get(FIELD_A);    assertArrayEquals(goeran.getBytes(StandardCharsets.UTF_8), actual.array());}
0
public void asciiBytesWrittenWithUnionSchemaIsConvertedToStringSchema() throws Exception
{    Schema writer = UNION_STRING_BYTES_RECORD;    ByteBuffer buf = ByteBuffer.wrap("42".getBytes(StandardCharsets.UTF_8));    Record record = defaultRecordWithSchema(writer, FIELD_A, buf);    byte[] encoded = encodeGenericBlob(record);    CharSequence read = (CharSequence) decodeGenericBlob(STRING_RECORD, writer, encoded).get(FIELD_A);    assertEquals("42", read.toString());}
0
public void utf8BytesWrittenWithUnionSchemaIsConvertedToStringSchema() throws Exception
{    String goeran = String.format("G%sran", LATIN_SMALL_LETTER_O_WITH_DIARESIS);    Schema writer = UNION_STRING_BYTES_RECORD;    Record record = defaultRecordWithSchema(writer, FIELD_A, goeran);    byte[] encoded = encodeGenericBlob(record);    CharSequence read = (CharSequence) decodeGenericBlob(STRING_RECORD, writer, encoded).get(FIELD_A);    assertEquals(goeran, read.toString());}
0
public void enumRecordCanBeReadWithExtendedEnumSchema() throws Exception
{    Schema writer = ENUM_AB_RECORD;    Record record = defaultRecordWithSchema(writer, FIELD_A, new EnumSymbol(writer, "A"));    byte[] encoded = encodeGenericBlob(record);    Record decoded = decodeGenericBlob(ENUM_ABC_RECORD, writer, encoded);    assertEquals("A", decoded.get(FIELD_A).toString());}
0
public void enumRecordWithExtendedSchemaCanBeReadWithOriginalEnumSchemaIfOnlyOldValues() throws Exception
{    Schema writer = ENUM_ABC_RECORD;    Record record = defaultRecordWithSchema(writer, FIELD_A, new EnumSymbol(writer, "A"));    byte[] encoded = encodeGenericBlob(record);    Record decoded = decodeGenericBlob(ENUM_AB_RECORD, writer, encoded);    assertEquals("A", decoded.get(FIELD_A).toString());}
0
public void enumRecordWithExtendedSchemaCanNotBeReadIfNewValuesAreUsed() throws Exception
{    expectedException.expect(AvroTypeException.class);    expectedException.expectMessage("No match for C");    Schema writer = ENUM_ABC_RECORD;    Record record = defaultRecordWithSchema(writer, FIELD_A, new EnumSymbol(writer, "C"));    byte[] encoded = encodeGenericBlob(record);    decodeGenericBlob(ENUM_AB_RECORD, writer, encoded);}
0
public void recordWrittenWithExtendedSchemaCanBeReadWithOriginalSchemaButLossOfData() throws Exception
{    Schema writer =     SchemaBuilder.record(RECORD_A).fields().name("newTopField").type().stringType().noDefault().name(FIELD_A).type().intType().noDefault().endRecord();    Record record = defaultRecordWithSchema(writer, FIELD_A, 42);    record.put("newTopField", "not decoded");    byte[] encoded = encodeGenericBlob(record);    Record decoded = decodeGenericBlob(INT_RECORD, writer, encoded);    assertEquals(42, decoded.get(FIELD_A));    assertNull(decoded.get("newTopField"));}
0
public void readerWithoutDefaultValueThrowsException() throws Exception
{    expectedException.expect(AvroTypeException.class);    expectedException.expectMessage("missing required field newField");    Schema reader =     SchemaBuilder.record(RECORD_A).fields().name("newField").type().intType().noDefault().name(FIELD_A).type().intType().noDefault().endRecord();    Record record = defaultRecordWithSchema(INT_RECORD, FIELD_A, 42);    byte[] encoded = encodeGenericBlob(record);    decodeGenericBlob(reader, INT_RECORD, encoded);}
0
public void readerWithDefaultValueIsApplied() throws Exception
{    Schema reader =     SchemaBuilder.record(RECORD_A).fields().name("newFieldWithDefault").type().intType().intDefault(    314).name(FIELD_A).type().intType().noDefault().endRecord();    Record record = defaultRecordWithSchema(INT_RECORD, FIELD_A, 42);    byte[] encoded = encodeGenericBlob(record);    Record decoded = decodeGenericBlob(reader, INT_RECORD, encoded);    assertEquals(42, decoded.get(FIELD_A));    assertEquals(314, decoded.get("newFieldWithDefault"));}
0
public void aliasesInSchema() throws Exception
{    Schema writer = new Schema.Parser().parse("{\"namespace\": \"example.avro\", \"type\": \"record\", \"name\": \"User\", \"fields\": [" + "{\"name\": \"name\", \"type\": \"int\"}\n" + "]}\n");    Schema reader = new Schema.Parser().parse("{\"namespace\": \"example.avro\", \"type\": \"record\", \"name\": \"User\", \"fields\": [" + "{\"name\": \"fname\", \"type\": \"int\", \"aliases\" : [ \"name\" ]}\n" + "]}\n");    GenericData.Record record = defaultRecordWithSchema(writer, "name", 1);    byte[] encoded = encodeGenericBlob(record);    GenericData.Record decoded = decodeGenericBlob(reader, reader, encoded);    assertEquals(1, decoded.get("fname"));}
0
private Record defaultRecordWithSchema(Schema schema, String key, T value)
{    Record data = new GenericData.Record(schema);    data.put(key, value);    return data;}
0
private byte[] encodeGenericBlob(GenericRecord data) throws IOException
{    DatumWriter<GenericRecord> writer = new GenericDatumWriter<>(data.getSchema());    ByteArrayOutputStream outStream = new ByteArrayOutputStream();    Encoder encoder = encoderType == EncoderType.BINARY ? EncoderFactory.get().binaryEncoder(outStream, null) : EncoderFactory.get().jsonEncoder(data.getSchema(), outStream);    writer.write(data, encoder);    encoder.flush();    outStream.close();    return outStream.toByteArray();}
0
private Record decodeGenericBlob(Schema expectedSchema, Schema schemaOfBlob, byte[] blob) throws IOException
{    if (blob == null) {        return null;    }    GenericDatumReader<Record> reader = new GenericDatumReader<>();    reader.setExpected(expectedSchema);    reader.setSchema(schemaOfBlob);    Decoder decoder = encoderType == EncoderType.BINARY ? DecoderFactory.get().binaryDecoder(blob, null) : DecoderFactory.get().jsonDecoder(schemaOfBlob, new ByteArrayInputStream(blob));    return reader.read(null, decoder);}
0
public void testSplitSchemaBuild()
{    Schema s = SchemaBuilder.record("HandshakeRequest").namespace("org.apache.avro.ipc").fields().name("clientProtocol").type().optional().stringType().name("meta").type().optional().map().values().bytesType().endRecord();    String schemaString = s.toString();    int mid = schemaString.length() / 2;    Schema parsedStringSchema = new org.apache.avro.Schema.Parser().parse(s.toString());    Schema parsedArrayOfStringSchema = new org.apache.avro.Schema.Parser().parse(schemaString.substring(0, mid), schemaString.substring(mid));    assertNotNull(parsedStringSchema);    assertNotNull(parsedArrayOfStringSchema);    assertEquals(parsedStringSchema.toString(), parsedArrayOfStringSchema.toString());}
0
public void testDefaultRecordWithDuplicateFieldName()
{    String recordName = "name";    Schema schema = Schema.createRecord(recordName, "doc", "namespace", false);    List<Field> fields = new ArrayList<>();    fields.add(new Field("field_name", Schema.create(Type.NULL), null, null));    fields.add(new Field("field_name", Schema.create(Type.INT), null, null));    try {        schema.setFields(fields);        fail("Should not be able to create a record with duplicate field name.");    } catch (AvroRuntimeException are) {        assertTrue(are.getMessage().contains("Duplicate field field_name in record " + recordName));    }}
0
public void testCreateUnionVarargs()
{    List<Schema> types = new ArrayList<>();    types.add(Schema.create(Type.NULL));    types.add(Schema.create(Type.LONG));    Schema expected = Schema.createUnion(types);    Schema schema = Schema.createUnion(Schema.create(Type.NULL), Schema.create(Type.LONG));    assertEquals(expected, schema);}
0
public void testRecordWithNullDoc()
{    Schema schema = Schema.createRecord("name", null, "namespace", false);    String schemaString = schema.toString();    assertNotNull(schemaString);}
0
public void testRecordWithNullNamespace()
{    Schema schema = Schema.createRecord("name", "doc", null, false);    String schemaString = schema.toString();    assertNotNull(schemaString);}
0
public void testEmptyRecordSchema()
{    Schema schema = createDefaultRecord();    String schemaString = schema.toString();    assertNotNull(schemaString);}
0
public void testParseEmptySchema()
{    Schema schema = new Schema.Parser().parse("");}
0
public void testSchemaWithFields()
{    List<Field> fields = new ArrayList<>();    fields.add(new Field("field_name1", Schema.create(Type.NULL), null, null));    fields.add(new Field("field_name2", Schema.create(Type.INT), null, null));    Schema schema = createDefaultRecord();    schema.setFields(fields);    String schemaString = schema.toString();    assertNotNull(schemaString);    assertEquals(2, schema.getFields().size());}
0
public void testSchemaWithNullFields()
{    Schema.createRecord("name", "doc", "namespace", false, null);}
0
public void testIsUnionOnUnionWithMultipleElements()
{    Schema schema = Schema.createUnion(Schema.create(Type.NULL), Schema.create(Type.LONG));    assertTrue(schema.isUnion());}
0
public void testIsUnionOnUnionWithOneElement()
{    Schema schema = Schema.createUnion(Schema.create(Type.LONG));    assertTrue(schema.isUnion());}
0
public void testIsUnionOnRecord()
{    Schema schema = createDefaultRecord();    assertFalse(schema.isUnion());}
0
public void testIsUnionOnArray()
{    Schema schema = Schema.createArray(Schema.create(Type.LONG));    assertFalse(schema.isUnion());}
0
public void testIsUnionOnEnum()
{    Schema schema = Schema.createEnum("name", "doc", "namespace", Collections.singletonList("value"));    assertFalse(schema.isUnion());}
0
public void testIsUnionOnFixed()
{    Schema schema = Schema.createFixed("name", "doc", "space", 10);    assertFalse(schema.isUnion());}
0
public void testIsUnionOnMap()
{    Schema schema = Schema.createMap(Schema.create(Type.LONG));    assertFalse(schema.isUnion());}
0
public void testIsNullableOnUnionWithNull()
{    Schema schema = Schema.createUnion(Schema.create(Type.NULL), Schema.create(Type.LONG));    assertTrue(schema.isNullable());}
0
public void testIsNullableOnUnionWithoutNull()
{    Schema schema = Schema.createUnion(Schema.create(Type.LONG));    assertFalse(schema.isNullable());}
0
public void testIsNullableOnRecord()
{    Schema schema = createDefaultRecord();    assertFalse(schema.isNullable());}
0
private Schema createDefaultRecord()
{    return Schema.createRecord("name", "doc", "namespace", false);}
0
public void testSerialization() throws IOException, ClassNotFoundException
{    try (ByteArrayOutputStream bos = new ByteArrayOutputStream();        ObjectOutputStream oos = new ObjectOutputStream(bos);        InputStream jsonSchema = getClass().getResourceAsStream("/SchemaBuilder.avsc")) {        Schema payload = new Schema.Parser().parse(jsonSchema);        oos.writeObject(payload);        try (ByteArrayInputStream bis = new ByteArrayInputStream(bos.toByteArray());            ObjectInputStream ois = new ObjectInputStream(bis)) {            Schema sp = (Schema) ois.readObject();            assertEquals(payload, sp);        }    }}
0
public void testRecord()
{    Schema schema = SchemaBuilder.record("myrecord").namespace("org.example").aliases("oldrecord").fields().name("f0").aliases("f0alias").type().stringType().noDefault().name("f1").doc("This is f1").type().longType().noDefault().name("f2").type().nullable().booleanType().booleanDefault(true).name("f3").type().unionOf().nullType().and().booleanType().endUnion().nullDefault().endRecord();    Assert.assertEquals("myrecord", schema.getName());    Assert.assertEquals("org.example", schema.getNamespace());    Assert.assertEquals("org.example.oldrecord", schema.getAliases().iterator().next());    Assert.assertFalse(schema.isError());    List<Schema.Field> fields = schema.getFields();    Assert.assertEquals(4, fields.size());    Assert.assertEquals(new Schema.Field("f0", Schema.create(Schema.Type.STRING)), fields.get(0));    Assert.assertTrue(fields.get(0).aliases().contains("f0alias"));    Assert.assertEquals(new Schema.Field("f1", Schema.create(Schema.Type.LONG), "This is f1"), fields.get(1));    List<Schema> types = new ArrayList<>();    types.add(Schema.create(Schema.Type.BOOLEAN));    types.add(Schema.create(Schema.Type.NULL));    Schema optional = Schema.createUnion(types);    Assert.assertEquals(new Schema.Field("f2", optional, null, true), fields.get(2));    List<Schema> types2 = new ArrayList<>();    types2.add(Schema.create(Schema.Type.NULL));    types2.add(Schema.create(Schema.Type.BOOLEAN));    Schema optional2 = Schema.createUnion(types2);    Assert.assertNotEquals(new Schema.Field("f3", optional2, null, (Object) null), fields.get(3));    Assert.assertEquals(new Schema.Field("f3", optional2, null, Schema.Field.NULL_DEFAULT_VALUE), fields.get(3));}
0
public void testDoc()
{    Schema s = SchemaBuilder.fixed("myfixed").doc("mydoc").size(1);    Assert.assertEquals("mydoc", s.getDoc());}
0
public void testProps()
{    Schema s =     SchemaBuilder.builder().intBuilder().prop("p1", "v1").prop("p2", "v2").prop("p2", "v2real").endInt();    int size = s.getObjectProps().size();    Assert.assertEquals(2, size);    Assert.assertEquals("v1", s.getProp("p1"));    Assert.assertEquals("v2real", s.getProp("p2"));}
0
public void testObjectProps()
{    Schema s = SchemaBuilder.builder().intBuilder().prop("booleanProp", true).prop("intProp", Integer.MAX_VALUE).prop("longProp", Long.MAX_VALUE).prop("floatProp", 1.0f).prop("doubleProp", Double.MAX_VALUE).prop("byteProp", new byte[] { 0x41, 0x42, 0x43 }).prop("stringProp", "abc").endInt();        Assert.assertEquals(7, s.getObjectProps().size());    Assert.assertTrue(s.getObjectProp("booleanProp") instanceof Boolean);    Assert.assertEquals(true, s.getObjectProp("booleanProp"));    Assert.assertTrue(s.getObjectProp("intProp") instanceof Integer);    Assert.assertEquals(Integer.MAX_VALUE, s.getObjectProp("intProp"));    Assert.assertTrue(s.getObjectProp("intProp") instanceof Integer);    Assert.assertTrue(s.getObjectProp("longProp") instanceof Long);    Assert.assertEquals(Long.MAX_VALUE, s.getObjectProp("longProp"));    Assert.assertTrue(s.getObjectProp("floatProp") instanceof Double);        Assert.assertEquals(1.0d, s.getObjectProp("floatProp"));    Assert.assertTrue(s.getObjectProp("doubleProp") instanceof Double);    Assert.assertEquals(Double.MAX_VALUE, s.getObjectProp("doubleProp"));        Assert.assertTrue(s.getObjectProp("byteProp") instanceof String);    Assert.assertEquals("ABC", s.getObjectProp("byteProp"));    Assert.assertTrue(s.getObjectProp("stringProp") instanceof String);    Assert.assertEquals("abc", s.getObjectProp("stringProp"));}
0
public void testFieldObjectProps()
{    Schema s = SchemaBuilder.builder().record("MyRecord").fields().name("myField").prop("booleanProp", true).prop("intProp", Integer.MAX_VALUE).prop("longProp", Long.MAX_VALUE).prop("floatProp", 1.0f).prop("doubleProp", Double.MAX_VALUE).prop("byteProp", new byte[] { 0x41, 0x42, 0x43 }).prop("stringProp", "abc").type().intType().noDefault().endRecord();    Schema.Field f = s.getField("myField");        Assert.assertEquals(7, f.getObjectProps().size());    Assert.assertTrue(f.getObjectProp("booleanProp") instanceof Boolean);    Assert.assertEquals(true, f.getObjectProp("booleanProp"));    Assert.assertTrue(f.getObjectProp("intProp") instanceof Integer);    Assert.assertEquals(Integer.MAX_VALUE, f.getObjectProp("intProp"));    Assert.assertTrue(f.getObjectProp("intProp") instanceof Integer);    Assert.assertTrue(f.getObjectProp("longProp") instanceof Long);    Assert.assertEquals(Long.MAX_VALUE, f.getObjectProp("longProp"));    Assert.assertTrue(f.getObjectProp("floatProp") instanceof Double);        Assert.assertEquals(1.0d, f.getObjectProp("floatProp"));    Assert.assertTrue(f.getObjectProp("doubleProp") instanceof Double);    Assert.assertEquals(Double.MAX_VALUE, f.getObjectProp("doubleProp"));        Assert.assertTrue(f.getObjectProp("byteProp") instanceof String);    Assert.assertEquals("ABC", f.getObjectProp("byteProp"));    Assert.assertTrue(f.getObjectProp("stringProp") instanceof String);    Assert.assertEquals("abc", f.getObjectProp("stringProp"));}
0
public void testArrayObjectProp()
{    List<Object> values = new ArrayList<>();    values.add(true);    values.add(Integer.MAX_VALUE);    values.add(Long.MAX_VALUE);    values.add(1.0f);    values.add(Double.MAX_VALUE);    values.add(new byte[] { 0x41, 0x42, 0x43 });    values.add("abc");    Schema s = SchemaBuilder.builder().intBuilder().prop("arrayProp", values).endInt();        Assert.assertEquals(1, s.getObjectProps().size());    Assert.assertTrue(s.getObjectProp("arrayProp") instanceof Collection);    @SuppressWarnings("unchecked")    Collection<Object> valueCollection = (Collection<Object>) s.getObjectProp("arrayProp");    Iterator<Object> iter = valueCollection.iterator();    Assert.assertEquals(7, valueCollection.size());    Assert.assertEquals(true, iter.next());    Assert.assertEquals(Integer.MAX_VALUE, iter.next());    Assert.assertEquals(Long.MAX_VALUE, iter.next());        Assert.assertEquals(1.0d, iter.next());    Assert.assertEquals(Double.MAX_VALUE, iter.next());        Assert.assertEquals("ABC", iter.next());    Assert.assertEquals("abc", iter.next());}
0
public void testFieldArrayObjectProp()
{    List<Object> values = new ArrayList<>();    values.add(true);    values.add(Integer.MAX_VALUE);    values.add(Long.MAX_VALUE);    values.add(1.0f);    values.add(Double.MAX_VALUE);    values.add(new byte[] { 0x41, 0x42, 0x43 });    values.add("abc");    Schema s = SchemaBuilder.builder().record("MyRecord").fields().name("myField").prop("arrayProp", values).type().intType().noDefault().endRecord();    Schema.Field f = s.getField("myField");        Assert.assertEquals(1, f.getObjectProps().size());    Assert.assertTrue(f.getObjectProp("arrayProp") instanceof Collection);    @SuppressWarnings("unchecked")    Collection<Object> valueCollection = (Collection<Object>) f.getObjectProp("arrayProp");    Iterator<Object> iter = valueCollection.iterator();    Assert.assertEquals(7, valueCollection.size());    Assert.assertEquals(true, iter.next());    Assert.assertEquals(Integer.MAX_VALUE, iter.next());    Assert.assertEquals(Long.MAX_VALUE, iter.next());        Assert.assertEquals(1.0d, iter.next());    Assert.assertEquals(Double.MAX_VALUE, iter.next());        Assert.assertEquals("ABC", iter.next());    Assert.assertEquals("abc", iter.next());}
0
public void testMapObjectProp()
{    Map<String, Object> values = new HashMap<>();    values.put("booleanKey", true);    values.put("intKey", Integer.MAX_VALUE);    values.put("longKey", Long.MAX_VALUE);    values.put("floatKey", 1.0f);    values.put("doubleKey", Double.MAX_VALUE);    values.put("byteKey", new byte[] { 0x41, 0x42, 0x43 });    values.put("stringKey", "abc");    Schema s = SchemaBuilder.builder().intBuilder().prop("mapProp", values).endInt();        Assert.assertTrue(s.getObjectProp("mapProp") instanceof Map);    @SuppressWarnings("unchecked")    Map<String, Object> valueMap = (Map<String, Object>) s.getObjectProp("mapProp");    Assert.assertEquals(values.size(), valueMap.size());    Assert.assertTrue(valueMap.get("booleanKey") instanceof Boolean);    Assert.assertEquals(true, valueMap.get("booleanKey"));    Assert.assertTrue(valueMap.get("intKey") instanceof Integer);    Assert.assertEquals(Integer.MAX_VALUE, valueMap.get("intKey"));    Assert.assertTrue(valueMap.get("longKey") instanceof Long);    Assert.assertEquals(Long.MAX_VALUE, valueMap.get("longKey"));        Assert.assertTrue(valueMap.get("floatKey") instanceof Double);    Assert.assertEquals(1.0d, valueMap.get("floatKey"));    Assert.assertTrue(valueMap.get("doubleKey") instanceof Double);    Assert.assertEquals(Double.MAX_VALUE, valueMap.get("doubleKey"));        Assert.assertTrue(valueMap.get("byteKey") instanceof String);    Assert.assertEquals("ABC", valueMap.get("byteKey"));    Assert.assertTrue(valueMap.get("stringKey") instanceof String);    Assert.assertEquals("abc", valueMap.get("stringKey"));}
0
public void testFieldMapObjectProp()
{    Map<String, Object> values = new HashMap<>();    values.put("booleanKey", true);    values.put("intKey", Integer.MAX_VALUE);    values.put("longKey", Long.MAX_VALUE);    values.put("floatKey", 1.0f);    values.put("doubleKey", Double.MAX_VALUE);    values.put("byteKey", new byte[] { 0x41, 0x42, 0x43 });    values.put("stringKey", "abc");    Schema s = SchemaBuilder.builder().record("MyRecord").fields().name("myField").prop("mapProp", values).type().intType().noDefault().endRecord();    Schema.Field f = s.getField("myField");        Assert.assertTrue(f.getObjectProp("mapProp") instanceof Map);    @SuppressWarnings("unchecked")    Map<String, Object> valueMap = (Map<String, Object>) f.getObjectProp("mapProp");    Assert.assertEquals(values.size(), valueMap.size());    Assert.assertTrue(valueMap.get("booleanKey") instanceof Boolean);    Assert.assertEquals(true, valueMap.get("booleanKey"));    Assert.assertTrue(valueMap.get("intKey") instanceof Integer);    Assert.assertEquals(Integer.MAX_VALUE, valueMap.get("intKey"));    Assert.assertTrue(valueMap.get("longKey") instanceof Long);    Assert.assertEquals(Long.MAX_VALUE, valueMap.get("longKey"));        Assert.assertTrue(valueMap.get("floatKey") instanceof Double);    Assert.assertEquals(1.0d, valueMap.get("floatKey"));    Assert.assertTrue(valueMap.get("doubleKey") instanceof Double);    Assert.assertEquals(Double.MAX_VALUE, valueMap.get("doubleKey"));        Assert.assertTrue(valueMap.get("byteKey") instanceof String);    Assert.assertEquals("ABC", valueMap.get("byteKey"));    Assert.assertTrue(valueMap.get("stringKey") instanceof String);    Assert.assertEquals("abc", valueMap.get("stringKey"));}
0
public void testNullObjectProp()
{    SchemaBuilder.builder().intBuilder().prop("nullProp", (Object) null).endInt();}
0
public void testFieldNullObjectProp()
{    SchemaBuilder.builder().record("MyRecord").fields().name("myField").prop("nullProp", (Object) null).type().intType().noDefault().endRecord();}
0
public void testNamespaces()
{    Schema s1 = SchemaBuilder.record("myrecord").namespace("org.example").fields().name("myint").type().intType().noDefault().endRecord();    Schema s2 = SchemaBuilder.record("org.example.myrecord").fields().name("myint").type().intType().noDefault().endRecord();    Schema s3 = SchemaBuilder.record("org.example.myrecord").namespace("org.example2").fields().name("myint").type().intType().noDefault().endRecord();    Schema s4 = SchemaBuilder.builder("org.example").record("myrecord").fields().name("myint").type().intType().noDefault().endRecord();    Assert.assertEquals("myrecord", s1.getName());    Assert.assertEquals("myrecord", s2.getName());    Assert.assertEquals("myrecord", s3.getName());    Assert.assertEquals("myrecord", s4.getName());    Assert.assertEquals("org.example", s1.getNamespace());    Assert.assertEquals("org.example", s2.getNamespace());        Assert.assertEquals("org.example", s3.getNamespace());    Assert.assertEquals("org.example", s4.getNamespace());    Assert.assertEquals("org.example.myrecord", s1.getFullName());    Assert.assertEquals("org.example.myrecord", s2.getFullName());    Assert.assertEquals("org.example.myrecord", s3.getFullName());    Assert.assertEquals("org.example.myrecord", s4.getFullName());}
0
public void testMissingRecordName()
{        SchemaBuilder.record(null).fields().name("f0").type().stringType().noDefault().endRecord();}
0
public void testBoolean()
{    Schema.Type type = Schema.Type.BOOLEAN;    Schema simple = SchemaBuilder.builder().booleanType();    Schema expected = primitive(type, simple);    Schema built1 = SchemaBuilder.builder().booleanBuilder().prop("p", "v").endBoolean();    Assert.assertEquals(expected, built1);}
0
public void testInt()
{    Schema.Type type = Schema.Type.INT;    Schema simple = SchemaBuilder.builder().intType();    Schema expected = primitive(type, simple);    Schema built1 = SchemaBuilder.builder().intBuilder().prop("p", "v").endInt();    Assert.assertEquals(expected, built1);}
0
public void testLong()
{    Schema.Type type = Schema.Type.LONG;    Schema simple = SchemaBuilder.builder().longType();    Schema expected = primitive(type, simple);    Schema built1 = SchemaBuilder.builder().longBuilder().prop("p", "v").endLong();    Assert.assertEquals(expected, built1);}
0
public void testFloat()
{    Schema.Type type = Schema.Type.FLOAT;    Schema simple = SchemaBuilder.builder().floatType();    Schema expected = primitive(type, simple);    Schema built1 = SchemaBuilder.builder().floatBuilder().prop("p", "v").endFloat();    Assert.assertEquals(expected, built1);}
0
public void testDuble()
{    Schema.Type type = Schema.Type.DOUBLE;    Schema simple = SchemaBuilder.builder().doubleType();    Schema expected = primitive(type, simple);    Schema built1 = SchemaBuilder.builder().doubleBuilder().prop("p", "v").endDouble();    Assert.assertEquals(expected, built1);}
0
public void testString()
{    Schema.Type type = Schema.Type.STRING;    Schema simple = SchemaBuilder.builder().stringType();    Schema expected = primitive(type, simple);    Schema built1 = SchemaBuilder.builder().stringBuilder().prop("p", "v").endString();    Assert.assertEquals(expected, built1);}
0
public void testBytes()
{    Schema.Type type = Schema.Type.BYTES;    Schema simple = SchemaBuilder.builder().bytesType();    Schema expected = primitive(type, simple);    Schema built1 = SchemaBuilder.builder().bytesBuilder().prop("p", "v").endBytes();    Assert.assertEquals(expected, built1);}
0
public void testNull()
{    Schema.Type type = Schema.Type.NULL;    Schema simple = SchemaBuilder.builder().nullType();    Schema expected = primitive(type, simple);    Schema built1 = SchemaBuilder.builder().nullBuilder().prop("p", "v").endNull();    Assert.assertEquals(expected, built1);}
0
private Schema primitive(Schema.Type type, Schema bare)
{        Schema bareByName = SchemaBuilder.builder().type(type.getName());    Assert.assertEquals(Schema.create(type), bareByName);    Assert.assertEquals(bareByName, bare);        Schema p = Schema.create(type);    p.addProp("p", "v");    return p;}
0
public void testRecursiveRecord()
{    Schema schema = SchemaBuilder.record("LongList").fields().name("value").type().longType().noDefault().name("next").type().optional().type("LongList").endRecord();    Assert.assertEquals("LongList", schema.getName());    List<Schema.Field> fields = schema.getFields();    Assert.assertEquals(2, fields.size());    Assert.assertEquals(new Schema.Field("value", Schema.create(Schema.Type.LONG), null), fields.get(0));    Assert.assertEquals(Schema.Type.UNION, fields.get(1).schema().getType());    Assert.assertEquals(Schema.Type.NULL, fields.get(1).schema().getTypes().get(0).getType());    Schema recordSchema = fields.get(1).schema().getTypes().get(1);    Assert.assertEquals(Schema.Type.RECORD, recordSchema.getType());    Assert.assertEquals("LongList", recordSchema.getName());    Assert.assertEquals(NullNode.getInstance(), fields.get(1).defaultValue());}
0
public void testEnum()
{    List<String> symbols = Arrays.asList("a", "b");    Schema expected = Schema.createEnum("myenum", null, null, symbols);    expected.addProp("p", "v");    Schema schema = SchemaBuilder.enumeration("myenum").prop("p", "v").symbols("a", "b");    Assert.assertEquals(expected, schema);}
0
public void testEnumWithDefault()
{    List<String> symbols = Arrays.asList("a", "b");    String enumDefault = "a";    Schema expected = Schema.createEnum("myenum", null, null, symbols, enumDefault);    expected.addProp("p", "v");    Schema schema = SchemaBuilder.enumeration("myenum").prop("p", "v").defaultSymbol(enumDefault).symbols("a", "b");    Assert.assertEquals(expected, schema);}
0
public void testFixed()
{    Schema expected = Schema.createFixed("myfixed", null, null, 16);    expected.addAlias("myOldFixed");    Schema schema = SchemaBuilder.fixed("myfixed").aliases("myOldFixed").size(16);    Assert.assertEquals(expected, schema);}
0
public void testArray()
{    Schema longSchema = Schema.create(Schema.Type.LONG);    Schema expected = Schema.createArray(longSchema);    Schema schema1 = SchemaBuilder.array().items().longType();    Assert.assertEquals(expected, schema1);    Schema schema2 = SchemaBuilder.array().items(longSchema);    Assert.assertEquals(expected, schema2);    Schema schema3 = SchemaBuilder.array().prop("p", "v").items().type("long");    expected.addProp("p", "v");    Assert.assertEquals(expected, schema3);}
0
public void testMap()
{    Schema intSchema = Schema.create(Schema.Type.INT);    Schema expected = Schema.createMap(intSchema);    Schema schema1 = SchemaBuilder.map().values().intType();    Assert.assertEquals(expected, schema1);    Schema schema2 = SchemaBuilder.map().values(intSchema);    Assert.assertEquals(expected, schema2);    Schema schema3 = SchemaBuilder.map().prop("p", "v").values().type("int");    expected.addProp("p", "v");    Assert.assertEquals(expected, schema3);}
0
public void testUnionAndNullable()
{    List<Schema> types = new ArrayList<>();    types.add(Schema.create(Schema.Type.LONG));    types.add(Schema.create(Schema.Type.NULL));    Schema expected = Schema.createUnion(types);    Schema schema = SchemaBuilder.unionOf().longType().and().nullType().endUnion();    Assert.assertEquals(expected, schema);    schema = SchemaBuilder.nullable().longType();    Assert.assertEquals(expected, schema);}
0
public void testFields()
{    Schema rec = SchemaBuilder.record("Rec").fields().name("documented").doc("documented").type().nullType().noDefault().name("ascending").orderAscending().type().booleanType().noDefault().name("descending").orderDescending().type().floatType().noDefault().name("ignored").orderIgnore().type().doubleType().noDefault().name("aliased").aliases("anAlias").type().stringType().noDefault().endRecord();    Assert.assertEquals("documented", rec.getField("documented").doc());    Assert.assertEquals(Order.ASCENDING, rec.getField("ascending").order());    Assert.assertEquals(Order.DESCENDING, rec.getField("descending").order());    Assert.assertEquals(Order.IGNORE, rec.getField("ignored").order());    Assert.assertTrue(rec.getField("aliased").aliases().contains("anAlias"));}
0
public void testFieldShortcuts()
{    Schema full = SchemaBuilder.record("Blah").fields().name("rbool").type().booleanType().noDefault().name("obool").type().optional().booleanType().name("nbool").type().nullable().booleanType().booleanDefault(true).name("rint").type().intType().noDefault().name("oint").type().optional().intType().name("nint").type().nullable().intType().intDefault(1).name("rlong").type().longType().noDefault().name("olong").type().optional().longType().name("nlong").type().nullable().longType().longDefault(2L).name("rfloat").type().floatType().noDefault().name("ofloat").type().optional().floatType().name("nfloat").type().nullable().floatType().floatDefault(-1.1f).name("rdouble").type().doubleType().noDefault().name("odouble").type().optional().doubleType().name("ndouble").type().nullable().doubleType().doubleDefault(99.9d).name("rstring").type().stringType().noDefault().name("ostring").type().optional().stringType().name("nstring").type().nullable().stringType().stringDefault("def").name("rbytes").type().bytesType().noDefault().name("obytes").type().optional().bytesType().name("nbytes").type().nullable().bytesType().bytesDefault(new byte[] { 1, 2, 3 }).endRecord();    Schema shortcut = SchemaBuilder.record("Blah").fields().requiredBoolean("rbool").optionalBoolean("obool").nullableBoolean("nbool", true).requiredInt("rint").optionalInt("oint").nullableInt("nint", 1).requiredLong("rlong").optionalLong("olong").nullableLong("nlong", 2L).requiredFloat("rfloat").optionalFloat("ofloat").nullableFloat("nfloat", -1.1f).requiredDouble("rdouble").optionalDouble("odouble").nullableDouble("ndouble", 99.9d).requiredString("rstring").optionalString("ostring").nullableString("nstring", "def").requiredBytes("rbytes").optionalBytes("obytes").nullableBytes("nbytes", new byte[] { 1, 2, 3 }).endRecord();    Assert.assertEquals(full, shortcut);}
0
public void testNames()
{        Schema r = SchemaBuilder.record("Rec").fields().name("f0").type().fixed("org.foo.MyFixed").size(1).noDefault().name("f1").type("org.foo.MyFixed").noDefault().name("f2").type("org.foo.MyFixed", "").noDefault().name("f3").type("org.foo.MyFixed", null).noDefault().name("f4").type("org.foo.MyFixed", "ignorethis").noDefault().name("f5").type("MyFixed", "org.foo").noDefault().endRecord();    Schema expected = Schema.createFixed("org.foo.MyFixed", null, null, 1);    checkField(r, expected, "f0");    checkField(r, expected, "f1");    checkField(r, expected, "f2");    checkField(r, expected, "f3");    checkField(r, expected, "f4");    checkField(r, expected, "f5");        Schema f = SchemaBuilder.builder("").fixed("Foo").size(1);    Assert.assertEquals(Schema.createFixed("Foo", null, null, 1), f);        r = SchemaBuilder.record("Rec").namespace("org.foo").fields().name("f0").type().fixed("MyFixed").size(1).noDefault().name("f1").type("org.foo.MyFixed").noDefault().name("f2").type("org.foo.MyFixed", "").noDefault().name("f3").type("org.foo.MyFixed", null).noDefault().name("f4").type("org.foo.MyFixed", "ignorethis").noDefault().name("f5").type("MyFixed", "org.foo").noDefault().name("f6").type("MyFixed", null).noDefault().name("f7").type("MyFixed").noDefault().endRecord();    checkField(r, expected, "f0");    checkField(r, expected, "f1");    checkField(r, expected, "f2");    checkField(r, expected, "f3");    checkField(r, expected, "f4");    checkField(r, expected, "f5");    checkField(r, expected, "f6");    checkField(r, expected, "f7");        r = SchemaBuilder.record("Rec").namespace("org.rec").fields().name("f0").type().fixed("MyFixed").namespace("org.foo").size(1).noDefault().name("f1").type("org.foo.MyFixed").noDefault().name("f2").type("org.foo.MyFixed", "").noDefault().name("f3").type("org.foo.MyFixed", null).noDefault().name("f4").type("org.foo.MyFixed", "ignorethis").noDefault().name("f5").type("MyFixed", "org.foo").noDefault().endRecord();    checkField(r, expected, "f0");    checkField(r, expected, "f1");    checkField(r, expected, "f2");    checkField(r, expected, "f3");    checkField(r, expected, "f4");    checkField(r, expected, "f5");        expected = Schema.createFixed("MyFixed", null, null, 1);    r = SchemaBuilder.record("Rec").namespace("org.rec").fields().name("f0").type().fixed("MyFixed").namespace("").size(1).noDefault().name("f1").type("MyFixed", "").noDefault().endRecord();    checkField(r, expected, "f0");    checkField(r, expected, "f1");        SchemaBuilder.fixed("org.test.long").size(1);    SchemaBuilder.fixed("long").namespace("org.test").size(1);    SchemaBuilder.builder("org.test").fixed("long").size(1);}
0
private void checkField(Schema r, Schema expected, String name)
{    Assert.assertEquals(expected, r.getField(name).schema());}
0
public void testNamesFailRedefined()
{    SchemaBuilder.record("Rec").fields().name("f0").type().enumeration("MyEnum").symbols("A", "B").enumDefault("A").name("f1").type().enumeration("MyEnum").symbols("X", "Y").noDefault().endRecord();}
0
public void testNamesFailAbsent()
{    SchemaBuilder.builder().type("notdefined");}
0
public void testNameReserved()
{    SchemaBuilder.fixed("long").namespace("").size(1);}
0
public void testFieldTypesAndDefaultValues()
{    byte[] bytedef = new byte[] { 3 };    ByteBuffer bufdef = ByteBuffer.wrap(bytedef);    String strdef = "\u0003";    HashMap<String, String> mapdef = new HashMap<>();    mapdef.put("a", "A");    ArrayList<String> arrdef = new ArrayList<>();    arrdef.add("arr");    Schema rec = SchemaBuilder.record("inner").fields().name("f").type().intType().noDefault().endRecord();    Schema rec2 = SchemaBuilder.record("inner2").fields().name("f2").type().intType().noDefault().endRecord();    GenericData.Record recdef = new GenericRecordBuilder(rec).set("f", 1).build();    GenericData.Record recdef2 = new GenericRecordBuilder(rec2).set("f2", 2).build();    Schema r = SchemaBuilder.record("r").fields().name("boolF").type().booleanType().booleanDefault(false).name("intF").type().intType().intDefault(1).name("longF").type().longType().longDefault(2L).name("floatF").type().floatType().floatDefault(3.0f).name("doubleF").type().doubleType().doubleDefault(4.0d).name("stringF").type().stringType().stringDefault("def").name("bytesF1").type().bytesType().bytesDefault(bytedef).name("bytesF2").type().bytesType().bytesDefault(bufdef).name("bytesF3").type().bytesType().bytesDefault(strdef).name("nullF").type().nullType().nullDefault().name("fixedF1").type().fixed("F1").size(1).fixedDefault(bytedef).name("fixedF2").type().fixed("F2").size(1).fixedDefault(bufdef).name("fixedF3").type().fixed("F3").size(1).fixedDefault(strdef).name("enumF").type().enumeration("E1").symbols("S").enumDefault("S").name("mapF").type().map().values().stringType().mapDefault(mapdef).name("arrayF").type().array().items().stringType().arrayDefault(arrdef).name("recordF").type().record("inner").fields().name("f").type().intType().noDefault().endRecord().recordDefault(recdef).name("byName").type("E1").withDefault("S").name("boolU").type().unionOf().booleanType().and().intType().endUnion().booleanDefault(false).name("intU").type().unionOf().intType().and().longType().endUnion().intDefault(1).name("longU").type().unionOf().longType().and().intType().endUnion().longDefault(2L).name("floatU").type().unionOf().floatType().and().intType().endUnion().floatDefault(3.0f).name("doubleU").type().unionOf().doubleType().and().intType().endUnion().doubleDefault(4.0d).name("stringU").type().unionOf().stringType().and().intType().endUnion().stringDefault("def").name("bytesU").type().unionOf().bytesType().and().intType().endUnion().bytesDefault(bytedef).name("nullU").type().unionOf().nullType().and().intType().endUnion().nullDefault().name("fixedU").type().unionOf().fixed("F4").size(1).and().intType().endUnion().fixedDefault(bytedef).name("enumU").type().unionOf().enumeration("E2").symbols("SS").and().intType().endUnion().enumDefault("SS").name("mapU").type().unionOf().map().values().stringType().and().intType().endUnion().mapDefault(mapdef).name("arrayU").type().unionOf().array().items().stringType().and().intType().endUnion().arrayDefault(arrdef).name("recordU").type().unionOf().record("inner2").fields().name("f2").type().intType().noDefault().endRecord().and().intType().endUnion().recordDefault(recdef2).endRecord();    GenericData.Record newRec = new GenericRecordBuilder(r).build();    Assert.assertEquals(false, newRec.get("boolF"));    Assert.assertEquals(false, newRec.get("boolU"));    Assert.assertEquals(1, newRec.get("intF"));    Assert.assertEquals(1, newRec.get("intU"));    Assert.assertEquals(2L, newRec.get("longF"));    Assert.assertEquals(2L, newRec.get("longU"));    Assert.assertEquals(3f, newRec.get("floatF"));    Assert.assertEquals(3f, newRec.get("floatU"));    Assert.assertEquals(4d, newRec.get("doubleF"));    Assert.assertEquals(4d, newRec.get("doubleU"));    Assert.assertEquals("def", newRec.get("stringF").toString());    Assert.assertEquals("def", newRec.get("stringU").toString());    Assert.assertEquals(bufdef, newRec.get("bytesF1"));    Assert.assertEquals(bufdef, newRec.get("bytesF2"));    Assert.assertEquals(bufdef, newRec.get("bytesF3"));    Assert.assertEquals(bufdef, newRec.get("bytesU"));    Assert.assertNull(newRec.get("nullF"));    Assert.assertNull(newRec.get("nullU"));    Assert.assertArrayEquals(bytedef, ((GenericData.Fixed) newRec.get("fixedF1")).bytes());    Assert.assertArrayEquals(bytedef, ((GenericData.Fixed) newRec.get("fixedF2")).bytes());    Assert.assertArrayEquals(bytedef, ((GenericData.Fixed) newRec.get("fixedF3")).bytes());    Assert.assertArrayEquals(bytedef, ((GenericData.Fixed) newRec.get("fixedU")).bytes());    Assert.assertEquals("S", newRec.get("enumF").toString());    Assert.assertEquals("SS", newRec.get("enumU").toString());    @SuppressWarnings("unchecked")    Map<CharSequence, CharSequence> map = (Map<CharSequence, CharSequence>) newRec.get("mapF");    Assert.assertEquals(mapdef.size(), map.size());    for (Map.Entry<CharSequence, CharSequence> e : map.entrySet()) {        Assert.assertEquals(mapdef.get(e.getKey().toString()), e.getValue().toString());    }    Assert.assertEquals(newRec.get("mapF"), newRec.get("mapU"));    @SuppressWarnings("unchecked")    GenericData.Array<CharSequence> arr = (GenericData.Array<CharSequence>) newRec.get("arrayF");    Assert.assertEquals(arrdef.size(), arr.size());    for (CharSequence c : arr) {        Assert.assertTrue(arrdef.contains(c.toString()));    }    Assert.assertEquals(newRec.get("arrF"), newRec.get("arrU"));    Assert.assertEquals(recdef, newRec.get("recordF"));    Assert.assertEquals(recdef2, newRec.get("recordU"));    Assert.assertEquals("S", newRec.get("byName").toString());}
0
public void testBadDefault()
{    SchemaBuilder.record("r").fields().name("f").type(Schema.create(Schema.Type.INT)).withDefault(new Object()).endRecord();}
0
public void testUnionFieldBuild()
{    SchemaBuilder.record("r").fields().name("allUnion").type().unionOf().booleanType().and().intType().and().longType().and().floatType().and().doubleType().and().stringType().and().bytesType().and().nullType().and().fixed("Fix").size(1).and().enumeration("Enu").symbols("Q").and().array().items().intType().and().map().values().longType().and().record("Rec").fields().name("one").type("Fix").noDefault().endRecord().endUnion().booleanDefault(false).endRecord();}
0
public void testDefaults() throws IOException
{    Schema writeSchema = SchemaBuilder.record("r").fields().name("requiredInt").type().intType().noDefault().name("optionalInt").type().optional().intType().name("nullableIntWithDefault").type().nullable().intType().intDefault(3).endRecord();    GenericData.Record rec1 = new GenericRecordBuilder(writeSchema).set("requiredInt", 1).build();    Assert.assertEquals(1, rec1.get("requiredInt"));    Assert.assertEquals(null, rec1.get("optionalInt"));    Assert.assertEquals(3, rec1.get("nullableIntWithDefault"));    GenericData.Record rec2 = new GenericRecordBuilder(writeSchema).set("requiredInt", 1).set("optionalInt", 2).set("nullableIntWithDefault", 13).build();    Assert.assertEquals(1, rec2.get("requiredInt"));    Assert.assertEquals(2, rec2.get("optionalInt"));    Assert.assertEquals(13, rec2.get("nullableIntWithDefault"));        File file = new File(DIR.getRoot().getPath(), "testDefaults.avro");    try (DataFileWriter<Object> writer = new DataFileWriter<>(new GenericDatumWriter<>())) {        writer.create(writeSchema, file);        writer.append(rec1);        writer.append(rec2);    }    Schema readSchema = SchemaBuilder.record("r").fields().name("requiredInt").type().intType().noDefault().name("optionalInt").type().optional().intType().name("nullableIntWithDefault").type().nullable().intType().intDefault(3).name("newOptionalInt").type().optional().intType().name("newNullableIntWithDefault").type().nullable().intType().intDefault(5).endRecord();    DataFileReader<GenericData.Record> reader = new DataFileReader<>(file, new GenericDatumReader<>(writeSchema, readSchema));    GenericData.Record rec1read = reader.iterator().next();    Assert.assertEquals(1, rec1read.get("requiredInt"));    Assert.assertNull(rec1read.get("optionalInt"));    Assert.assertEquals(3, rec1read.get("nullableIntWithDefault"));    Assert.assertNull(rec1read.get("newOptionalInt"));    Assert.assertEquals(5, rec1read.get("newNullableIntWithDefault"));    GenericData.Record rec2read = reader.iterator().next();    Assert.assertEquals(1, rec2read.get("requiredInt"));    Assert.assertEquals(2, rec2read.get("optionalInt"));    Assert.assertEquals(13, rec2read.get("nullableIntWithDefault"));    Assert.assertNull(rec2read.get("newOptionalInt"));    Assert.assertEquals(5, rec2read.get("newNullableIntWithDefault"));}
0
public void testDefaultTypes()
{    Integer intDef = 1;    Long longDef = 2L;    Float floatDef = 3F;    Double doubleDef = 4D;    Schema schema = SchemaBuilder.record("r").fields().name("int").type().intType().intDefault(intDef).name("long").type().longType().longDefault(longDef).name("float").type().floatType().floatDefault(floatDef).name("double").type().doubleType().doubleDefault(doubleDef).endRecord();    Assert.assertEquals("int field default type or value mismatch", intDef, schema.getField("int").defaultVal());    Assert.assertEquals("long field default type or value mismatch", longDef, schema.getField("long").defaultVal());    Assert.assertEquals("float field default type or value mismatch", floatDef, schema.getField("float").defaultVal());    Assert.assertEquals("double field default type or value mismatch", doubleDef, schema.getField("double").defaultVal());}
0
public void testValidateSchemaPairMissingField() throws Exception
{    final List<Schema.Field> readerFields = list(new Schema.Field("oldfield1", INT_SCHEMA, null, null));    final Schema reader = Schema.createRecord(readerFields);    final SchemaCompatibility.SchemaPairCompatibility expectedResult = new SchemaCompatibility.SchemaPairCompatibility(SchemaCompatibility.SchemaCompatibilityResult.compatible(), reader, WRITER_SCHEMA, SchemaCompatibility.READER_WRITER_COMPATIBLE_MESSAGE);        assertEquals(expectedResult, checkReaderWriterCompatibility(reader, WRITER_SCHEMA));}
0
public void testValidateSchemaPairMissingSecondField() throws Exception
{    final List<Schema.Field> readerFields = list(new Schema.Field("oldfield2", STRING_SCHEMA, null, null));    final Schema reader = Schema.createRecord(readerFields);    final SchemaCompatibility.SchemaPairCompatibility expectedResult = new SchemaCompatibility.SchemaPairCompatibility(SchemaCompatibility.SchemaCompatibilityResult.compatible(), reader, WRITER_SCHEMA, SchemaCompatibility.READER_WRITER_COMPATIBLE_MESSAGE);        assertEquals(expectedResult, checkReaderWriterCompatibility(reader, WRITER_SCHEMA));}
0
public void testValidateSchemaPairAllFields() throws Exception
{    final List<Schema.Field> readerFields = list(new Schema.Field("oldfield1", INT_SCHEMA, null, null), new Schema.Field("oldfield2", STRING_SCHEMA, null, null));    final Schema reader = Schema.createRecord(readerFields);    final SchemaCompatibility.SchemaPairCompatibility expectedResult = new SchemaCompatibility.SchemaPairCompatibility(SchemaCompatibility.SchemaCompatibilityResult.compatible(), reader, WRITER_SCHEMA, SchemaCompatibility.READER_WRITER_COMPATIBLE_MESSAGE);        assertEquals(expectedResult, checkReaderWriterCompatibility(reader, WRITER_SCHEMA));}
0
public void testValidateSchemaNewFieldWithDefault() throws Exception
{    final List<Schema.Field> readerFields = list(new Schema.Field("oldfield1", INT_SCHEMA, null, null), new Schema.Field("newfield1", INT_SCHEMA, null, 42));    final Schema reader = Schema.createRecord(readerFields);    final SchemaCompatibility.SchemaPairCompatibility expectedResult = new SchemaCompatibility.SchemaPairCompatibility(SchemaCompatibility.SchemaCompatibilityResult.compatible(), reader, WRITER_SCHEMA, SchemaCompatibility.READER_WRITER_COMPATIBLE_MESSAGE);        assertEquals(expectedResult, checkReaderWriterCompatibility(reader, WRITER_SCHEMA));}
0
public void testValidateSchemaNewField() throws Exception
{    final List<Schema.Field> readerFields = list(new Schema.Field("oldfield1", INT_SCHEMA, null, null), new Schema.Field("newfield1", INT_SCHEMA, null, null));    final Schema reader = Schema.createRecord(readerFields);    SchemaPairCompatibility compatibility = checkReaderWriterCompatibility(reader, WRITER_SCHEMA);        assertEquals(SchemaCompatibility.SchemaCompatibilityType.INCOMPATIBLE, compatibility.getType());    assertEquals(SchemaCompatibility.SchemaCompatibilityResult.incompatible(SchemaIncompatibilityType.READER_FIELD_MISSING_DEFAULT_VALUE, reader, WRITER_SCHEMA, "newfield1", asList("", "fields", "1")), compatibility.getResult());    assertEquals(String.format("Data encoded using writer schema:%n%s%n" + "will or may fail to decode using reader schema:%n%s%n", WRITER_SCHEMA.toString(true), reader.toString(true)), compatibility.getDescription());    assertEquals(reader, compatibility.getReader());    assertEquals(WRITER_SCHEMA, compatibility.getWriter());}
0
public void testValidateArrayWriterSchema() throws Exception
{    final Schema validReader = Schema.createArray(STRING_SCHEMA);    final Schema invalidReader = Schema.createMap(STRING_SCHEMA);    final SchemaCompatibility.SchemaPairCompatibility validResult = new SchemaCompatibility.SchemaPairCompatibility(SchemaCompatibility.SchemaCompatibilityResult.compatible(), validReader, STRING_ARRAY_SCHEMA, SchemaCompatibility.READER_WRITER_COMPATIBLE_MESSAGE);    final SchemaCompatibility.SchemaPairCompatibility invalidResult = new SchemaCompatibility.SchemaPairCompatibility(SchemaCompatibility.SchemaCompatibilityResult.incompatible(SchemaIncompatibilityType.TYPE_MISMATCH, invalidReader, STRING_ARRAY_SCHEMA, "reader type: MAP not compatible with writer type: ARRAY", Collections.singletonList("")), invalidReader, STRING_ARRAY_SCHEMA, String.format("Data encoded using writer schema:%n%s%n" + "will or may fail to decode using reader schema:%n%s%n", STRING_ARRAY_SCHEMA.toString(true), invalidReader.toString(true)));    assertEquals(validResult, checkReaderWriterCompatibility(validReader, STRING_ARRAY_SCHEMA));    assertEquals(invalidResult, checkReaderWriterCompatibility(invalidReader, STRING_ARRAY_SCHEMA));}
0
public void testValidatePrimitiveWriterSchema() throws Exception
{    final Schema validReader = Schema.create(Schema.Type.STRING);    final SchemaCompatibility.SchemaPairCompatibility validResult = new SchemaCompatibility.SchemaPairCompatibility(SchemaCompatibility.SchemaCompatibilityResult.compatible(), validReader, STRING_SCHEMA, SchemaCompatibility.READER_WRITER_COMPATIBLE_MESSAGE);    final SchemaCompatibility.SchemaPairCompatibility invalidResult = new SchemaCompatibility.SchemaPairCompatibility(SchemaCompatibility.SchemaCompatibilityResult.incompatible(SchemaIncompatibilityType.TYPE_MISMATCH, INT_SCHEMA, STRING_SCHEMA, "reader type: INT not compatible with writer type: STRING", Collections.singletonList("")), INT_SCHEMA, STRING_SCHEMA, String.format("Data encoded using writer schema:%n%s%n" + "will or may fail to decode using reader schema:%n%s%n", STRING_SCHEMA.toString(true), INT_SCHEMA.toString(true)));    assertEquals(validResult, checkReaderWriterCompatibility(validReader, STRING_SCHEMA));    assertEquals(invalidResult, checkReaderWriterCompatibility(INT_SCHEMA, STRING_SCHEMA));}
0
public void testUnionReaderWriterSubsetIncompatibility()
{    final Schema unionWriter = Schema.createUnion(list(INT_SCHEMA, STRING_SCHEMA, LONG_SCHEMA));    final Schema unionReader = Schema.createUnion(list(INT_SCHEMA, STRING_SCHEMA));    final SchemaPairCompatibility result = checkReaderWriterCompatibility(unionReader, unionWriter);    assertEquals(SchemaCompatibilityType.INCOMPATIBLE, result.getType());}
0
public static void validateIncompatibleSchemas(Schema reader, Schema writer, SchemaIncompatibilityType incompatibility, String message, String location)
{    validateIncompatibleSchemas(reader, writer, Collections.singletonList(incompatibility), Collections.singletonList(message), Collections.singletonList(location));}
0
public static void validateIncompatibleSchemas(Schema reader, Schema writer, List<SchemaIncompatibilityType> incompatibilityTypes, List<String> messages, List<String> locations)
{    SchemaPairCompatibility compatibility = checkReaderWriterCompatibility(reader, writer);    SchemaCompatibilityResult compatibilityResult = compatibility.getResult();    assertEquals(reader, compatibility.getReader());    assertEquals(writer, compatibility.getWriter());    assertEquals(SchemaCompatibilityType.INCOMPATIBLE, compatibilityResult.getCompatibility());    assertEquals(incompatibilityTypes.size(), compatibilityResult.getIncompatibilities().size());    for (int i = 0; i < incompatibilityTypes.size(); i++) {        Incompatibility incompatibility = compatibilityResult.getIncompatibilities().get(i);        assertSchemaContains(incompatibility.getReaderFragment(), reader);        assertSchemaContains(incompatibility.getWriterFragment(), writer);        assertEquals(incompatibilityTypes.get(i), incompatibility.getType());        assertEquals(messages.get(i), incompatibility.getMessage());        assertEquals(locations.get(i), incompatibility.getLocation());    }    String description = String.format("Data encoded using writer schema:%n%s%n" + "will or may fail to decode using reader schema:%n%s%n", writer.toString(true), reader.toString(true));    assertEquals(description, compatibility.getDescription());}
0
public void testReaderWriterCompatibility()
{    for (ReaderWriter readerWriter : COMPATIBLE_READER_WRITER_TEST_CASES) {        final Schema reader = readerWriter.getReader();        final Schema writer = readerWriter.getWriter();                final SchemaPairCompatibility result = checkReaderWriterCompatibility(reader, writer);        assertEquals(String.format("Expecting reader %s to be compatible with writer %s, but tested incompatible.", reader, writer), SchemaCompatibilityType.COMPATIBLE, result.getType());    }}
1
public Schema getReaderSchema()
{    return mReaderSchema;}
0
public Schema getWriterSchema()
{    return mWriterSchema;}
0
public Object getDatum()
{    return mDatum;}
0
public Object getDecodedDatum()
{    return mDecodedDatum;}
0
public void testReaderWriterDecodingCompatibility() throws Exception
{    for (DecodingTestCase testCase : DECODING_COMPATIBILITY_TEST_CASES) {        final Schema readerSchema = testCase.getReaderSchema();        final Schema writerSchema = testCase.getWriterSchema();        final Object datum = testCase.getDatum();        final Object expectedDecodedDatum = testCase.getDecodedDatum();                        final ByteArrayOutputStream baos = new ByteArrayOutputStream();        final Encoder encoder = EncoderFactory.get().binaryEncoder(baos, null);        final DatumWriter<Object> datumWriter = new GenericDatumWriter<>(writerSchema);        datumWriter.write(datum, encoder);        encoder.flush();                final byte[] bytes = baos.toByteArray();        final Decoder decoder = DecoderFactory.get().resolvingDecoder(writerSchema, readerSchema, DecoderFactory.get().binaryDecoder(bytes, null));        final DatumReader<Object> datumReader = new GenericDatumReader<>(readerSchema);        final Object decodedDatum = datumReader.read(null, decoder);        assertEquals(String.format("Expecting decoded value %s when decoding value %s whose writer schema is %s " + "using reader schema %s, but value was %s.", expectedDecodedDatum, datum, writerSchema, readerSchema, decodedDatum), expectedDecodedDatum, decodedDatum);    }}
1
 Deque<String> asDeqeue(String... args)
{    List<String> x = Arrays.asList(args);    Collections.reverse(x);    Deque<String> dq = new ArrayDeque<>(x);    return dq;}
0
public void testEnumDefaultNotAppliedWhenWriterFieldMissing() throws Exception
{    expectedException.expect(AvroTypeException.class);    expectedException.expectMessage("Found Record1, expecting Record1, missing required field field1");    Schema writerSchema = SchemaBuilder.record("Record1").fields().name("field2").type(ENUM2_AB_SCHEMA).noDefault().endRecord();    Schema readerSchema = SchemaBuilder.record("Record1").fields().name("field1").type(ENUM_AB_ENUM_DEFAULT_A_SCHEMA).noDefault().endRecord();    GenericRecord datum = new GenericData.Record(writerSchema);    datum.put("field2", new GenericData.EnumSymbol(writerSchema, "B"));    serializeWithWriterThenDeserializeWithReader(writerSchema, datum, readerSchema);}
0
public void testEnumDefaultAppliedWhenNoFieldDefaultDefined() throws Exception
{    Schema writerSchema = SchemaBuilder.record("Record1").fields().name("field1").type(ENUM_ABC_ENUM_DEFAULT_A_SCHEMA).noDefault().endRecord();    Schema readerSchema = SchemaBuilder.record("Record1").fields().name("field1").type(ENUM_AB_ENUM_DEFAULT_A_SCHEMA).noDefault().endRecord();    GenericRecord datum = new GenericData.Record(writerSchema);    datum.put("field1", new GenericData.EnumSymbol(writerSchema, "C"));    GenericRecord decodedDatum = serializeWithWriterThenDeserializeWithReader(writerSchema, datum, readerSchema);        assertEquals("A", decodedDatum.get("field1").toString());}
0
public void testEnumDefaultNotAppliedWhenCompatibleSymbolIsFound() throws Exception
{    Schema writerSchema = SchemaBuilder.record("Record1").fields().name("field1").type(ENUM_ABC_ENUM_DEFAULT_A_SCHEMA).noDefault().endRecord();    Schema readerSchema = SchemaBuilder.record("Record1").fields().name("field1").type(ENUM_AB_ENUM_DEFAULT_A_SCHEMA).noDefault().endRecord();    GenericRecord datum = new GenericData.Record(writerSchema);    datum.put("field1", new GenericData.EnumSymbol(writerSchema, "B"));    GenericRecord decodedDatum = serializeWithWriterThenDeserializeWithReader(writerSchema, datum, readerSchema);    assertEquals("B", decodedDatum.get("field1").toString());}
0
public void testEnumDefaultAppliedWhenFieldDefaultDefined() throws Exception
{    Schema writerSchema = SchemaBuilder.record("Record1").fields().name("field1").type(ENUM_ABC_ENUM_DEFAULT_A_SCHEMA).noDefault().endRecord();    Schema readerSchema = SchemaBuilder.record("Record1").fields().name("field1").type(ENUM_AB_ENUM_DEFAULT_A_SCHEMA).withDefault("B").endRecord();    GenericRecord datum = new GenericData.Record(writerSchema);    datum.put("field1", new GenericData.EnumSymbol(writerSchema, "C"));    GenericRecord decodedDatum = serializeWithWriterThenDeserializeWithReader(writerSchema, datum, readerSchema);        assertEquals("A", decodedDatum.get("field1").toString());}
0
public void testFieldDefaultNotAppliedForUnknownSymbol() throws Exception
{    expectedException.expect(AvroTypeException.class);    expectedException.expectMessage("No match for C");    Schema writerSchema = SchemaBuilder.record("Record1").fields().name("field1").type(ENUM1_ABC_SCHEMA).noDefault().endRecord();    Schema readerSchema = SchemaBuilder.record("Record1").fields().name("field1").type(ENUM1_AB_SCHEMA).withDefault("A").endRecord();    GenericRecord datum = new GenericData.Record(writerSchema);    datum.put("field1", new GenericData.EnumSymbol(writerSchema, "C"));    serializeWithWriterThenDeserializeWithReader(writerSchema, datum, readerSchema);}
0
private GenericRecord serializeWithWriterThenDeserializeWithReader(Schema writerSchema, GenericRecord datum, Schema readerSchema) throws Exception
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = EncoderFactory.get().binaryEncoder(baos, null);    DatumWriter<Object> datumWriter = new GenericDatumWriter<>(writerSchema);    datumWriter.write(datum, encoder);    encoder.flush();    byte[] bytes = baos.toByteArray();    Decoder decoder = DecoderFactory.get().resolvingDecoder(writerSchema, readerSchema, DecoderFactory.get().binaryDecoder(bytes, null));    DatumReader<Object> datumReader = new GenericDatumReader<>(readerSchema);    return (GenericRecord) datumReader.read(null, decoder);}
0
public static Iterable<Object[]> data()
{    Object[][] fields = {     { FIXED_4_BYTES, FIXED_8_BYTES, "expected: 8, found: 4", "/size" }, { FIXED_8_BYTES, FIXED_4_BYTES, "expected: 4, found: 8", "/size" }, { A_DINT_B_DFIXED_8_BYTES_RECORD1, A_DINT_B_DFIXED_4_BYTES_RECORD1, "expected: 4, found: 8", "/fields/1/type/size" }, { A_DINT_B_DFIXED_4_BYTES_RECORD1, A_DINT_B_DFIXED_8_BYTES_RECORD1, "expected: 8, found: 4", "/fields/1/type/size" } };    return Arrays.asList(fields);}
0
public void testFixedSizeMismatchSchemas() throws Exception
{    validateIncompatibleSchemas(reader, writer, SchemaIncompatibilityType.FIXED_SIZE_MISMATCH, details, location);}
0
public static Iterable<Object[]> data()
{    Object[][] fields = {     { ENUM1_AB_SCHEMA, ENUM1_ABC_SCHEMA, "[C]", "/symbols" }, { ENUM1_BC_SCHEMA, ENUM1_ABC_SCHEMA, "[A]", "/symbols" }, { RECORD1_WITH_ENUM_AB, RECORD1_WITH_ENUM_ABC, "[C]", "/fields/0/type/symbols" } };    return Arrays.asList(fields);}
0
public void testTypeMismatchSchemas() throws Exception
{    validateIncompatibleSchemas(reader, writer, SchemaIncompatibilityType.MISSING_ENUM_SYMBOLS, details, location);}
0
public static Iterable<Object[]> data()
{    Object[][] fields = {     { INT_UNION_SCHEMA, INT_STRING_UNION_SCHEMA, Collections.singletonList("reader union lacking writer type: STRING"), Collections.singletonList("/1") }, { STRING_UNION_SCHEMA, INT_STRING_UNION_SCHEMA, Collections.singletonList("reader union lacking writer type: INT"), Collections.singletonList("/0") }, { INT_UNION_SCHEMA, UNION_INT_RECORD1, Collections.singletonList("reader union lacking writer type: RECORD"), Collections.singletonList("/1") }, { INT_UNION_SCHEMA, UNION_INT_RECORD2, Collections.singletonList("reader union lacking writer type: RECORD"), Collections.singletonList("/1") },     { UNION_INT_RECORD1, UNION_INT_RECORD2, Collections.singletonList("reader union lacking writer type: RECORD"), Collections.singletonList("/1") }, { INT_UNION_SCHEMA, UNION_INT_ENUM1_AB, Collections.singletonList("reader union lacking writer type: ENUM"), Collections.singletonList("/1") }, { INT_UNION_SCHEMA, UNION_INT_FIXED_4_BYTES, Collections.singletonList("reader union lacking writer type: FIXED"), Collections.singletonList("/1") }, { INT_UNION_SCHEMA, UNION_INT_BOOLEAN, Collections.singletonList("reader union lacking writer type: BOOLEAN"), Collections.singletonList("/1") }, { INT_UNION_SCHEMA, LONG_UNION_SCHEMA, Collections.singletonList("reader union lacking writer type: LONG"), Collections.singletonList("/0") }, { INT_UNION_SCHEMA, FLOAT_UNION_SCHEMA, Collections.singletonList("reader union lacking writer type: FLOAT"), Collections.singletonList("/0") }, { INT_UNION_SCHEMA, DOUBLE_UNION_SCHEMA, Collections.singletonList("reader union lacking writer type: DOUBLE"), Collections.singletonList("/0") }, { INT_UNION_SCHEMA, BYTES_UNION_SCHEMA, Collections.singletonList("reader union lacking writer type: BYTES"), Collections.singletonList("/0") }, { INT_UNION_SCHEMA, UNION_INT_ARRAY_INT, Collections.singletonList("reader union lacking writer type: ARRAY"), Collections.singletonList("/1") }, { INT_UNION_SCHEMA, UNION_INT_MAP_INT, Collections.singletonList("reader union lacking writer type: MAP"), Collections.singletonList("/1") }, { INT_UNION_SCHEMA, UNION_INT_NULL, Collections.singletonList("reader union lacking writer type: NULL"), Collections.singletonList("/1") }, { INT_UNION_SCHEMA, INT_LONG_FLOAT_DOUBLE_UNION_SCHEMA, asList("reader union lacking writer type: LONG", "reader union lacking writer type: FLOAT", "reader union lacking writer type: DOUBLE"), asList("/1", "/2", "/3") }, { A_DINT_B_DINT_UNION_RECORD1, A_DINT_B_DINT_STRING_UNION_RECORD1, Collections.singletonList("reader union lacking writer type: STRING"), Collections.singletonList("/fields/1/type/1") } };    return Arrays.asList(fields);}
0
public void testMissingUnionBranch() throws Exception
{    List<SchemaIncompatibilityType> types = Collections.nCopies(details.size(), SchemaIncompatibilityType.MISSING_UNION_BRANCH);    validateIncompatibleSchemas(reader, writer, types, details, location);}
0
public void testMultipleIncompatibilities() throws Exception
{    Schema reader = SchemaBuilder.record("base").fields().name("check_enum_symbols_field").type().enumeration("check_enum_symbols_type").symbols("A", "C").noDefault().name("check_enum_name_field").type().enumeration("check_enum_name_type").symbols("A", "B", "C", "D").noDefault().name("type_mismatch_field").type().stringType().noDefault().name("sub_record").type().record("sub_record_type").fields().name("identical_1_field").type().longType().longDefault(42L).name("extra_no_default_field").type().longType().noDefault().name("fixed_length_mismatch_field").type().fixed("fixed_length_mismatch_type").size(4).noDefault().name("union_missing_branches_field").type().unionOf().booleanType().endUnion().noDefault().name("reader_union_does_not_support_type_field").type().unionOf().booleanType().endUnion().noDefault().name("record_fqn_mismatch_field").type().record("recordA").namespace("not_nsA").fields().name("A_field_0").type().booleanType().booleanDefault(true).name("array_type_mismatch_field").type().array().items().stringType().noDefault().endRecord().noDefault().endRecord().noDefault().endRecord();    Schema writer = SchemaBuilder.record("base").fields().name("check_enum_symbols_field").type().enumeration("check_enum_symbols_type").symbols("A", "B", "C", "D").noDefault().name("check_enum_name_field").type().enumeration("check_enum_name_type_ERR").symbols("A", "B", "C", "D").noDefault().name("type_mismatch_field").type().longType().noDefault().name("sub_record").type().record("sub_record_type").fields().name("identical_1_field").type().longType().longDefault(42L).name("fixed_length_mismatch_field").type().fixed("fixed_length_mismatch_type").size(8).noDefault().name("union_missing_branches_field").type().unionOf().booleanType().and().doubleType().and().stringType().endUnion().noDefault().name("reader_union_does_not_support_type_field").type().longType().noDefault().name("record_fqn_mismatch_field").type().record("recordA").namespace("nsA").fields().name("A_field_0").type().booleanType().booleanDefault(true).name("array_type_mismatch_field").type().array().items().booleanType().noDefault().endRecord().noDefault().endRecord().noDefault().endRecord();    List<SchemaIncompatibilityType> types = Arrays.asList(SchemaIncompatibilityType.MISSING_ENUM_SYMBOLS, SchemaIncompatibilityType.NAME_MISMATCH, SchemaIncompatibilityType.TYPE_MISMATCH, SchemaIncompatibilityType.READER_FIELD_MISSING_DEFAULT_VALUE, SchemaIncompatibilityType.FIXED_SIZE_MISMATCH, SchemaIncompatibilityType.MISSING_UNION_BRANCH, SchemaIncompatibilityType.MISSING_UNION_BRANCH, SchemaIncompatibilityType.MISSING_UNION_BRANCH, SchemaIncompatibilityType.TYPE_MISMATCH);    List<String> details = Arrays.asList("[B, D]", "expected: check_enum_name_type_ERR", "reader type: STRING not compatible with writer type: LONG", "extra_no_default_field", "expected: 8, found: 4", "reader union lacking writer type: DOUBLE", "reader union lacking writer type: STRING", "reader union lacking writer type: LONG", "reader type: STRING not compatible with writer type: BOOLEAN");    List<String> location = Arrays.asList("/fields/0/type/symbols", "/fields/1/type/name", "/fields/2/type", "/fields/3/type/fields/1", "/fields/3/type/fields/2/type/size", "/fields/3/type/fields/3/type/1", "/fields/3/type/fields/3/type/2", "/fields/3/type/fields/4/type", "/fields/3/type/fields/5/type/fields/1/type/items");    validateIncompatibleSchemas(reader, writer, types, details, location);}
0
public static Iterable<Object[]> data()
{    Object[][] fields = {     { ENUM1_AB_SCHEMA, ENUM2_AB_SCHEMA, "expected: Enum2", "/name" }, { EMPTY_RECORD2, EMPTY_RECORD1, "expected: Record1", "/name" }, { FIXED_4_BYTES, FIXED_4_ANOTHER_NAME, "expected: AnotherName", "/name" }, { A_DINT_B_DENUM_1_RECORD1, A_DINT_B_DENUM_2_RECORD1, "expected: Enum2", "/fields/1/type/name" } };    return Arrays.asList(fields);}
0
public void testNameMismatchSchemas() throws Exception
{    validateIncompatibleSchemas(reader, writer, SchemaIncompatibilityType.NAME_MISMATCH, details, location);}
0
public static Iterable<Object[]> data()
{    Object[][] fields = {     { A_INT_RECORD1, EMPTY_RECORD1, "a", "/fields/0" }, { A_INT_B_DINT_RECORD1, EMPTY_RECORD1, "a", "/fields/0" } };    return Arrays.asList(fields);}
0
public void testReaderFieldMissingDefaultValueSchemas() throws Exception
{    validateIncompatibleSchemas(reader, writer, SchemaIncompatibilityType.READER_FIELD_MISSING_DEFAULT_VALUE, details, location);}
0
public static Iterable<Object[]> data()
{    Object[][] fields = {     { NULL_SCHEMA, INT_SCHEMA, "reader type: NULL not compatible with writer type: INT", "/" }, { NULL_SCHEMA, LONG_SCHEMA, "reader type: NULL not compatible with writer type: LONG", "/" }, { BOOLEAN_SCHEMA, INT_SCHEMA, "reader type: BOOLEAN not compatible with writer type: INT", "/" }, { INT_SCHEMA, NULL_SCHEMA, "reader type: INT not compatible with writer type: NULL", "/" }, { INT_SCHEMA, BOOLEAN_SCHEMA, "reader type: INT not compatible with writer type: BOOLEAN", "/" }, { INT_SCHEMA, LONG_SCHEMA, "reader type: INT not compatible with writer type: LONG", "/" }, { INT_SCHEMA, FLOAT_SCHEMA, "reader type: INT not compatible with writer type: FLOAT", "/" }, { INT_SCHEMA, DOUBLE_SCHEMA, "reader type: INT not compatible with writer type: DOUBLE", "/" }, { LONG_SCHEMA, FLOAT_SCHEMA, "reader type: LONG not compatible with writer type: FLOAT", "/" }, { LONG_SCHEMA, DOUBLE_SCHEMA, "reader type: LONG not compatible with writer type: DOUBLE", "/" }, { FLOAT_SCHEMA, DOUBLE_SCHEMA, "reader type: FLOAT not compatible with writer type: DOUBLE", "/" }, { DOUBLE_SCHEMA, STRING_SCHEMA, "reader type: DOUBLE not compatible with writer type: STRING", "/" }, { FIXED_4_BYTES, STRING_SCHEMA, "reader type: FIXED not compatible with writer type: STRING", "/" }, { STRING_SCHEMA, BOOLEAN_SCHEMA, "reader type: STRING not compatible with writer type: BOOLEAN", "/" }, { STRING_SCHEMA, INT_SCHEMA, "reader type: STRING not compatible with writer type: INT", "/" }, { BYTES_SCHEMA, NULL_SCHEMA, "reader type: BYTES not compatible with writer type: NULL", "/" }, { BYTES_SCHEMA, INT_SCHEMA, "reader type: BYTES not compatible with writer type: INT", "/" }, { A_INT_RECORD1, INT_SCHEMA, "reader type: RECORD not compatible with writer type: INT", "/" }, { INT_ARRAY_SCHEMA, LONG_ARRAY_SCHEMA, "reader type: INT not compatible with writer type: LONG", "/items" }, { INT_MAP_SCHEMA, INT_ARRAY_SCHEMA, "reader type: MAP not compatible with writer type: ARRAY", "/" }, { INT_ARRAY_SCHEMA, INT_MAP_SCHEMA, "reader type: ARRAY not compatible with writer type: MAP", "/" }, { INT_MAP_SCHEMA, LONG_MAP_SCHEMA, "reader type: INT not compatible with writer type: LONG", "/values" }, { INT_SCHEMA, ENUM2_AB_SCHEMA, "reader type: INT not compatible with writer type: ENUM", "/" }, { ENUM2_AB_SCHEMA, INT_SCHEMA, "reader type: ENUM not compatible with writer type: INT", "/" }, { FLOAT_SCHEMA, INT_LONG_FLOAT_DOUBLE_UNION_SCHEMA, "reader type: FLOAT not compatible with writer type: DOUBLE", "/" }, { LONG_SCHEMA, INT_FLOAT_UNION_SCHEMA, "reader type: LONG not compatible with writer type: FLOAT", "/" }, { INT_SCHEMA, INT_FLOAT_UNION_SCHEMA, "reader type: INT not compatible with writer type: FLOAT", "/" }, { INT_LIST_RECORD, LONG_LIST_RECORD, "reader type: INT not compatible with writer type: LONG", "/fields/0/type" }, { NULL_SCHEMA, INT_SCHEMA, "reader type: NULL not compatible with writer type: INT", "/" } };    return Arrays.asList(fields);}
0
public void testTypeMismatchSchemas() throws Exception
{    validateIncompatibleSchemas(reader, writer, SchemaIncompatibilityType.TYPE_MISMATCH, details, location);}
0
public static List<Object[]> cases() throws IOException
{    return CaseFinder.find(data(), "canonical", new ArrayList<>());}
0
public void testCanonicalization() throws Exception
{    assertEquals(SchemaNormalization.toParsingForm(new Schema.Parser().parse(input)), expectedOutput);}
0
public static List<Object[]> cases() throws IOException
{    return CaseFinder.find(data(), "fingerprint", new ArrayList<>());}
0
public void testCanonicalization() throws Exception
{    Schema s = new Schema.Parser().parse(input);    long carefulFP = altFingerprint(SchemaNormalization.toParsingForm(s));    assertEquals(carefulFP, Long.parseLong(expectedOutput));    assertEqHex(carefulFP, SchemaNormalization.parsingFingerprint64(s));}
0
public static List<Object[]> cases() throws IOException
{    return CaseFinder.find(data(), "fingerprint", new ArrayList<>());}
0
public void testCanonicalization() throws Exception
{    Locale originalDefaultLocale = Locale.getDefault();    Locale.setDefault(Locale.forLanguageTag("tr"));    Schema s = new Schema.Parser().parse(input);    long carefulFP = altFingerprint(SchemaNormalization.toParsingForm(s));    assertEquals(carefulFP, Long.parseLong(expectedOutput));    assertEqHex(carefulFP, SchemaNormalization.parsingFingerprint64(s));    Locale.setDefault(originalDefaultLocale);}
0
private static BufferedReader data() throws IOException
{    return Files.newBufferedReader(Paths.get(DATA_FILE), UTF_8);}
0
public static long altFingerprint(String s)
{                        long tmp = altExtend(SchemaNormalization.EMPTY64, 64, ONE, s.getBytes(UTF_8));    return altExtend(SchemaNormalization.EMPTY64, 64, tmp, POSTFIX);}
0
private static long altExtend(long poly, int degree, long fp, byte[] b)
{    final long overflowBit = 1L << (64 - degree);    for (byte b1 : b) {        for (int j = 1; j < 129; j = j << 1) {            boolean overflow = (0 != (fp & overflowBit));            fp >>>= 1;            if (0 != (j & b1))                                fp |= ONE;            if (overflow) {                                fp ^= poly;            }        }    }    return fp;}
0
private static void assertEqHex(long expected, long actual)
{    String m = format("0x%016x != 0x%016x", expected, actual);    assertTrue(m, expected == actual);}
0
private static String format(String f, Object... args)
{    return (new Formatter()).format(f, args).toString();}
0
public Schema getReader()
{    return mReader;}
0
public Schema getWriter()
{    return mWriter;}
0
 static ArrayList<E> list(E... elements)
{    final ArrayList<E> list = new ArrayList<>();    Collections.addAll(list, elements);    return list;}
0
 static void assertSchemaContains(Schema schemaSubset, Schema original)
{    String subset = schemaSubset.toString(false);    String whole = original.toString(false);    assertTrue(String.format("Subset '%s' not found in '%s'", subset, whole), whole.contains(subset));}
0
public void testAllTypes() throws SchemaValidationException
{    Schema s = SchemaBuilder.record("r").fields().requiredBoolean("boolF").requiredInt("intF").requiredLong("longF").requiredFloat("floatF").requiredDouble("doubleF").requiredString("stringF").requiredBytes("bytesF").name("fixedF1").type().fixed("F1").size(1).noDefault().name("enumF").type().enumeration("E1").symbols("S").noDefault().name("mapF").type().map().values().stringType().noDefault().name("arrayF").type().array().items().stringType().noDefault().name("recordF").type().record("inner").fields().name("f").type().intType().noDefault().endRecord().noDefault().optionalBoolean("boolO").endRecord();    testValidatorPasses(builder.mutualReadStrategy().validateLatest(), s, s);}
0
public void testReadOnePrior() throws SchemaValidationException
{    testValidatorPasses(builder.canReadStrategy().validateLatest(), rec3, rec);    testValidatorPasses(builder.canReadStrategy().validateLatest(), rec5, rec3);    testValidatorFails(builder.canReadStrategy().validateLatest(), rec4, rec);}
0
public void testReadAllPrior() throws SchemaValidationException
{    testValidatorPasses(builder.canReadStrategy().validateAll(), rec3, rec, rec2);    testValidatorFails(builder.canReadStrategy().validateAll(), rec4, rec, rec2, rec3);    testValidatorFails(builder.canReadStrategy().validateAll(), rec5, rec, rec2, rec3);}
0
public void testOnePriorCanRead() throws SchemaValidationException
{    testValidatorPasses(builder.canBeReadStrategy().validateLatest(), rec, rec3);    testValidatorFails(builder.canBeReadStrategy().validateLatest(), rec, rec4);}
0
public void testAllPriorCanRead() throws SchemaValidationException
{    testValidatorPasses(builder.canBeReadStrategy().validateAll(), rec, rec3, rec2);    testValidatorFails(builder.canBeReadStrategy().validateAll(), rec, rec4, rec3, rec2);}
0
public void testOnePriorCompatible() throws SchemaValidationException
{    testValidatorPasses(builder.mutualReadStrategy().validateLatest(), rec, rec3);    testValidatorFails(builder.mutualReadStrategy().validateLatest(), rec, rec4);}
0
public void testAllPriorCompatible() throws SchemaValidationException
{    testValidatorPasses(builder.mutualReadStrategy().validateAll(), rec, rec3, rec2);    testValidatorFails(builder.mutualReadStrategy().validateAll(), rec, rec4, rec3, rec2);}
0
public void testInvalidBuild()
{    builder.strategy(null).validateAll();}
0
public void testReflectMatchStructure() throws SchemaValidationException
{    testValidatorPasses(builder.canBeReadStrategy().validateAll(), circleSchemaDifferentNames, ReflectData.get().getSchema(Circle.class));}
0
public void testReflectWithAllowNullMatchStructure() throws SchemaValidationException
{    testValidatorPasses(builder.canBeReadStrategy().validateAll(), circleSchemaDifferentNames, ReflectData.AllowNull.get().getSchema(Circle.class));}
0
public void testUnionWithIncompatibleElements() throws SchemaValidationException
{    Schema union1 = Schema.createUnion(Collections.singletonList(rec));    Schema union2 = Schema.createUnion(Collections.singletonList(rec4));    testValidatorFails(builder.canReadStrategy().validateAll(), union2, union1);}
0
public void testUnionWithCompatibleElements() throws SchemaValidationException
{    Schema union1 = Schema.createUnion(Collections.singletonList(rec));    Schema union2 = Schema.createUnion(Collections.singletonList(rec3));    testValidatorPasses(builder.canReadStrategy().validateAll(), union2, union1);}
0
public void testSchemaCompatibilitySuccesses() throws SchemaValidationException
{        for (ReaderWriter tc : COMPATIBLE_READER_WRITER_TEST_CASES) {        testValidatorPasses(builder.canReadStrategy().validateAll(), tc.getReader(), tc.getWriter());    }}
0
public void testSchemaCompatibilityFailures() throws SchemaValidationException
{    for (ReaderWriter tc : INCOMPATIBLE_READER_WRITER_TEST_CASES) {        Schema reader = tc.getReader();        Schema writer = tc.getWriter();        expectedException.expect(SchemaValidationException.class);        expectedException.expectMessage("Unable to read schema: \n" + writer.toString());        SchemaValidator validator = builder.canReadStrategy().validateAll();        validator.validate(reader, Collections.singleton(writer));    }}
0
private void testValidatorPasses(SchemaValidator validator, Schema schema, Schema... prev) throws SchemaValidationException
{    ArrayList<Schema> prior = new ArrayList<>();    for (int i = prev.length - 1; i >= 0; i--) {        prior.add(prev[i]);    }    validator.validate(schema, prior);}
0
private void testValidatorFails(SchemaValidator validator, Schema schemaFails, Schema... prev) throws SchemaValidationException
{    ArrayList<Schema> prior = new ArrayList<>();    for (int i = prev.length - 1; i >= 0; i--) {        prior.add(prev[i]);    }    boolean threw = false;    try {                validator.validate(schemaFails, prior);    } catch (SchemaValidationException sve) {        threw = true;    }    Assert.assertTrue(threw);}
0
public void testRecursiveSchemaValidation() throws SchemaValidationException
{        final SchemaValidator backwardValidator = builder.canReadStrategy().validateLatest();    backwardValidator.validate(recursiveSchema, Collections.singletonList(recursiveSchema));}
0
public void testSelfReferenceInUnion()
{    Schema schema = new Schema.Parser().parse(SIMPLE_BINARY_TREE);    Field leftField = schema.getField("left");    assertEquals(JsonProperties.NULL_VALUE, leftField.defaultVal());    final Schema leftFieldSchema = leftField.schema();    assertEquals(Type.UNION, leftFieldSchema.getType());    assertEquals("null", leftFieldSchema.getTypes().get(0).getName());    assertEquals("Node", leftFieldSchema.getTypes().get(1).getName());    Field rightField = schema.getField("right");    assertEquals(JsonProperties.NULL_VALUE, rightField.defaultVal());    final Schema rightFieldSchema = rightField.schema();    assertEquals(Type.UNION, rightFieldSchema.getType());    assertEquals("null", rightFieldSchema.getTypes().get(0).getName());    assertEquals("Node", rightFieldSchema.getTypes().get(1).getName());}
0
public void testSelfReferenceInThreeUnion()
{    Schema schema = new Schema.Parser().parse(THREE_TYPE_UNION);    Field leftField = schema.getField("left");    assertEquals(JsonProperties.NULL_VALUE, leftField.defaultVal());    final Schema leftFieldSchema = leftField.schema();    assertEquals(Type.UNION, leftFieldSchema.getType());    assertEquals("null", leftFieldSchema.getTypes().get(0).getName());    assertEquals("string", leftFieldSchema.getTypes().get(1).getName());    assertEquals("Node", leftFieldSchema.getTypes().get(2).getName());    Field rightField = schema.getField("right");    assertEquals(JsonProperties.NULL_VALUE, rightField.defaultVal());    final Schema rightFieldSchema = rightField.schema();    assertEquals(Type.UNION, rightFieldSchema.getType());    assertEquals("null", rightFieldSchema.getTypes().get(0).getName());    assertEquals("string", rightFieldSchema.getTypes().get(1).getName());    assertEquals("Node", rightFieldSchema.getTypes().get(2).getName());}
0
public static org.apache.avro.Schema getClassSchema()
{    return SCHEMA$;}
0
public org.apache.avro.Schema getSchema()
{    return SCHEMA$;}
0
public static List<Object[]> find(BufferedReader in, String label, List<Object[]> cases) throws IOException
{    if (!Pattern.matches(LABEL_REGEX, label))        throw new IllegalArgumentException("Bad case subcase label: " + label);    final String subcaseMarker = "<<" + label;    for (String line = in.readLine(); ; ) {                while (line != null && !line.startsWith(NEW_CASE_MARKER)) line = in.readLine();        if (line == null)            break;        String input;        input = processHereDoc(in, line);        if (label.equals(NEW_CASE_NAME)) {            cases.add(new Object[] { input, null });            line = in.readLine();            continue;        }                do {            line = in.readLine();        } while (line != null && (!line.startsWith(NEW_CASE_MARKER) && !line.startsWith(subcaseMarker)));        if (line == null || line.startsWith(NEW_CASE_MARKER))            continue;        String expectedOutput = processHereDoc(in, line);        cases.add(new Object[] { input, expectedOutput });    }    in.close();    return cases;}
0
private static String processHereDoc(BufferedReader in, String docStart) throws IOException
{    Matcher m = START_LINE_PATTERN.matcher(docStart);    if (!m.matches())        throw new IllegalArgumentException("Wasn't given the start of a heredoc (\"" + docStart + "\")");    String docName = m.group(1);        String singleLineText = m.group(2);    if (singleLineText.length() != 0) {        if (!singleLineText.startsWith(" "))            throw new IOException("Single-line heredoc missing initial space (\"" + docStart + "\")");        return singleLineText.substring(1);    }        StringBuilder result = new StringBuilder();    String line = in.readLine();    String prevLine = "";    boolean firstTime = true;    while (line != null && !line.equals(docName)) {        if (!firstTime)            result.append(prevLine).append('\n');        else            firstTime = false;        prevLine = line;        line = in.readLine();    }    if (line == null)        throw new IOException("Here document (" + docName + ") terminated by end-of-file.");    return result.append(prevLine).toString();}
0
public void testToJsonNode()
{    assertEquals(null, toJsonNode(null));    assertEquals(NullNode.getInstance(), toJsonNode(JsonProperties.NULL_VALUE));    assertEquals(BooleanNode.TRUE, toJsonNode(true));    assertEquals(IntNode.valueOf(1), toJsonNode(1));    assertEquals(LongNode.valueOf(2), toJsonNode(2L));    assertEquals(FloatNode.valueOf(1.0f), toJsonNode(1.0f));    assertEquals(DoubleNode.valueOf(2.0), toJsonNode(2.0));    assertEquals(TextNode.valueOf("\u0001\u0002"), toJsonNode(new byte[] { 1, 2 }));    assertEquals(TextNode.valueOf("a"), toJsonNode("a"));    assertEquals(TextNode.valueOf("UP"), toJsonNode(Direction.UP));    ArrayNode an = JsonNodeFactory.instance.arrayNode();    an.add(1);    assertEquals(an, toJsonNode(Collections.singletonList(1)));    ObjectNode on = JsonNodeFactory.instance.objectNode();    on.put("a", 1);    assertEquals(on, toJsonNode(Collections.singletonMap("a", 1)));}
0
public void testToObject()
{    assertEquals(null, toObject(null));    assertEquals(JsonProperties.NULL_VALUE, toObject(NullNode.getInstance()));    assertEquals(true, toObject(BooleanNode.TRUE));    assertEquals(1, toObject(IntNode.valueOf(1)));    assertEquals(2L, toObject(IntNode.valueOf(2), Schema.create(Schema.Type.LONG)));    assertEquals(1.0f, toObject(DoubleNode.valueOf(1.0), Schema.create(Schema.Type.FLOAT)));    assertEquals(2.0, toObject(DoubleNode.valueOf(2.0)));    assertEquals(TextNode.valueOf("\u0001\u0002"), toJsonNode(new byte[] { 1, 2 }));    assertArrayEquals(new byte[] { 1, 2 }, (byte[]) toObject(TextNode.valueOf("\u0001\u0002"), Schema.create(Schema.Type.BYTES)));    assertEquals("a", toObject(TextNode.valueOf("a")));    assertEquals("UP", toObject(TextNode.valueOf("UP"), SchemaBuilder.enumeration("Direction").symbols("UP", "DOWN")));    ArrayNode an = JsonNodeFactory.instance.arrayNode();    an.add(1);    assertEquals(Collections.singletonList(1), toObject(an));    ObjectNode on = JsonNodeFactory.instance.objectNode();    on.put("a", 1);    assertEquals(Collections.singletonMap("a", 1), toObject(on));    assertEquals(Collections.singletonMap("a", 1L), toObject(on, SchemaBuilder.record("r").fields().requiredLong("a").endRecord()));    assertEquals(JsonProperties.NULL_VALUE, toObject(NullNode.getInstance(), SchemaBuilder.unionOf().nullType().and().intType().endUnion()));    assertEquals("a", toObject(TextNode.valueOf("a"), SchemaBuilder.unionOf().stringType().and().intType().endUnion()));}
0
public void testOutput() throws Exception
{    List<Object[]> result = new ArrayList<>();    CaseFinder.find(mk(input), label, result);    assertTrue(pr(result), eq(result, expectedOutput));}
0
public void testBadDocLabel1() throws Exception
{    List<Object[]> result = new ArrayList<>();    CaseFinder.find(mk("<<INPUT blah"), "", result);}
0
public void testBadDocLabel2() throws Exception
{    List<Object[]> result = new ArrayList<>();    CaseFinder.find(mk("<<INPUT blah"), "kill-er", result);}
0
public void testBadSingleLineHeredoc() throws Exception
{    List<Object[]> result = new ArrayList<>();    CaseFinder.find(mk("<<INPUTblah"), "foo", result);}
0
public void testUnterminatedHeredoc() throws Exception
{    List<Object[]> result = new ArrayList<>();    CaseFinder.find(mk("<<INPUT"), "foo", result);}
0
private static BufferedReader mk(String s)
{    return new BufferedReader(new StringReader(s));}
0
private static String pr(List<Object[]> t)
{    StringBuilder b = new StringBuilder();    b.append("{ ");    boolean firstTime = true;    for (Object[] p : t) {        if (!firstTime)            b.append(", ");        else            firstTime = false;        b.append("{ \"").append(p[0]).append("\", \"").append(p[1]).append("\" }");    }    b.append("}");    return b.toString();}
0
private static boolean eq(List<Object[]> l1, List<Object[]> l2)
{    if (l1 == null || l2 == null)        return l1 == l2;    if (l1.size() != l2.size())        return false;    for (int i = 0; i < l1.size(); i++) if (!Arrays.equals(l1.get(i), l2.get(i)))        return false;    return true;}
0
public void testByteConstructor() throws Exception
{    byte[] bs = "Foo".getBytes(StandardCharsets.UTF_8);    Utf8 u = new Utf8(bs);    assertEquals(bs.length, u.getByteLength());    for (int i = 0; i < bs.length; i++) {        assertEquals(bs[i], u.getBytes()[i]);    }}
0
public void testArrayReusedWhenLargerThanRequestedSize()
{    byte[] bs = "55555".getBytes(StandardCharsets.UTF_8);    Utf8 u = new Utf8(bs);    assertEquals(5, u.getByteLength());    byte[] content = u.getBytes();    u.setByteLength(3);    assertEquals(3, u.getByteLength());    assertSame(content, u.getBytes());    u.setByteLength(4);    assertEquals(4, u.getByteLength());    assertSame(content, u.getBytes());}
0
public SchemaVisitorAction visitTerminal(final Schema terminal)
{    Schema.Type type = terminal.getType();    Schema newSchema;    switch(type) {                case RECORD:        case ARRAY:        case MAP:        case UNION:            if (!replace.containsKey(terminal)) {                throw new IllegalStateException("Schema " + terminal + " must be already processed");            }            return SchemaVisitorAction.CONTINUE;        case BOOLEAN:        case BYTES:        case DOUBLE:        case FLOAT:        case INT:        case LONG:        case NULL:        case STRING:            newSchema = Schema.create(type);            break;        case ENUM:            newSchema = Schema.createEnum(terminal.getName(), terminal.getDoc(), terminal.getNamespace(), terminal.getEnumSymbols(), terminal.getEnumDefault());            break;        case FIXED:            newSchema = Schema.createFixed(terminal.getName(), terminal.getDoc(), terminal.getNamespace(), terminal.getFixedSize());            break;        default:            throw new IllegalStateException("Unsupported schema " + terminal);    }    copyAllProperties(terminal, newSchema);    replace.put(terminal, newSchema);    return SchemaVisitorAction.CONTINUE;}
0
public static void copyAllProperties(final Schema first, final Schema second)
{    Schemas.copyLogicalTypes(first, second);    Schemas.copyAliases(first, second);    Schemas.copyProperties(first, second);}
0
public static void copyAllProperties(final Field first, final Field second)
{    Schemas.copyAliases(first, second);    Schemas.copyProperties(first, second);}
0
public SchemaVisitorAction visitNonTerminal(final Schema nt)
{    Schema.Type type = nt.getType();    if (type == Schema.Type.RECORD) {        if (SchemaResolver.isUnresolvedSchema(nt)) {                                    final String unresolvedSchemaName = SchemaResolver.getUnresolvedSchemaName(nt);            Schema resSchema = symbolTable.apply(unresolvedSchemaName);            if (resSchema == null) {                throw new AvroTypeException("Unable to resolve " + unresolvedSchemaName);            }            Schema replacement = replace.get(resSchema);            if (replacement == null) {                replace.put(nt, Schemas.visit(resSchema, new ResolvingVisitor(resSchema, new IdentityHashMap<>(), symbolTable)));            } else {                replace.put(nt, replacement);            }        } else {                        Schema newSchema = Schema.createRecord(nt.getName(), nt.getDoc(), nt.getNamespace(), nt.isError());            copyAllProperties(nt, newSchema);            replace.put(nt, newSchema);        }    }    return SchemaVisitorAction.CONTINUE;}
0
public SchemaVisitorAction afterVisitNonTerminal(final Schema nt)
{    Schema.Type type = nt.getType();    Schema newSchema;    switch(type) {        case RECORD:            if (!SchemaResolver.isUnresolvedSchema(nt)) {                newSchema = replace.get(nt);                List<Schema.Field> fields = nt.getFields();                List<Schema.Field> newFields = new ArrayList<>(fields.size());                for (Schema.Field field : fields) {                    Schema.Field newField = new Schema.Field(field.name(), replace.get(field.schema()), field.doc(), field.defaultVal(), field.order());                    copyAllProperties(field, newField);                    newFields.add(newField);                }                newSchema.setFields(newFields);            }            return SchemaVisitorAction.CONTINUE;        case UNION:            List<Schema> types = nt.getTypes();            List<Schema> newTypes = new ArrayList<>(types.size());            for (Schema sch : types) {                newTypes.add(replace.get(sch));            }            newSchema = Schema.createUnion(newTypes);            break;        case ARRAY:            newSchema = Schema.createArray(replace.get(nt.getElementType()));            break;        case MAP:            newSchema = Schema.createMap(replace.get(nt.getValueType()));            break;        default:            throw new IllegalStateException("Illegal type " + type + ", schema " + nt);    }    copyAllProperties(nt, newSchema);    replace.put(nt, newSchema);    return SchemaVisitorAction.CONTINUE;}
0
public Schema get()
{    return replace.get(root);}
0
public String toString()
{    return "ResolvingVisitor{" + "replace=" + replace + ", symbolTable=" + symbolTable + ", root=" + root + '}';}
0
 static Schema unresolvedSchema(final String name)
{    Schema schema = Schema.createRecord(UR_SCHEMA_NAME, "unresolved schema", UR_SCHEMA_NS, false, Collections.EMPTY_LIST);    schema.addProp(UR_SCHEMA_ATTR, name);    return schema;}
0
 static boolean isUnresolvedSchema(final Schema schema)
{    return (schema.getType() == Schema.Type.RECORD && schema.getProp(UR_SCHEMA_ATTR) != null && UR_SCHEMA_NAME.equals(schema.getName()) && UR_SCHEMA_NS.equals(schema.getNamespace()));}
0
 static String getUnresolvedSchemaName(final Schema schema)
{    if (!isUnresolvedSchema(schema)) {        throw new IllegalArgumentException("Not a unresolved schema: " + schema);    }    return schema.getProp(UR_SCHEMA_ATTR);}
0
 static Protocol resolve(final Protocol protocol)
{    Protocol result = new Protocol(protocol.getName(), protocol.getDoc(), protocol.getNamespace());    final Collection<Schema> types = protocol.getTypes();        List<Schema> newSchemas = new ArrayList<>(types.size());    IdentityHashMap<Schema, Schema> replacements = new IdentityHashMap<>();    for (Schema schema : types) {        newSchemas.add(Schemas.visit(schema, new ResolvingVisitor(schema, replacements, new SymbolTable(protocol))));    }        result.setTypes(newSchemas);        for (Map.Entry<String, Protocol.Message> entry : protocol.getMessages().entrySet()) {        Protocol.Message value = entry.getValue();        Protocol.Message nvalue;        if (value.isOneWay()) {            Schema replacement = resolve(replacements, value.getRequest(), protocol);            nvalue = result.createMessage(value.getName(), value.getDoc(), value, replacement);        } else {            Schema request = resolve(replacements, value.getRequest(), protocol);            Schema response = resolve(replacements, value.getResponse(), protocol);            Schema errors = resolve(replacements, value.getErrors(), protocol);            nvalue = result.createMessage(value.getName(), value.getDoc(), value, request, response, errors);        }        result.getMessages().put(entry.getKey(), nvalue);    }    Schemas.copyProperties(protocol, result);    return result;}
0
private static Schema resolve(final IdentityHashMap<Schema, Schema> replacements, final Schema request, final Protocol protocol)
{    Schema replacement = replacements.get(request);    if (replacement == null) {        replacement = Schemas.visit(request, new ResolvingVisitor(request, replacements, new SymbolTable(protocol)));    }    return replacement;}
0
public Schema apply(final String f)
{    return symbolTable.getType(f);}
0
public void copy(final Schema first, final Schema second)
{    Schemas.copyLogicalTypes(first, second);    Schemas.copyAliases(first, second);}
0
public void copy(final Schema.Field first, final Schema.Field second)
{    Schemas.copyAliases(first, second);}
0
public SchemaVisitorAction visitTerminal(final Schema terminal)
{    Schema.Type type = terminal.getType();    Schema newSchema;    switch(type) {                case RECORD:        case ARRAY:        case MAP:        case UNION:            if (!replace.containsKey(terminal)) {                throw new IllegalStateException("Schema " + terminal + " must be already processed");            }            return SchemaVisitorAction.CONTINUE;        case BOOLEAN:        case BYTES:        case DOUBLE:        case FLOAT:        case INT:        case LONG:        case NULL:        case STRING:            newSchema = Schema.create(type);            break;        case ENUM:            newSchema = Schema.createEnum(terminal.getName(), copyDocs ? terminal.getDoc() : null, terminal.getNamespace(), terminal.getEnumSymbols());            break;        case FIXED:            newSchema = Schema.createFixed(terminal.getName(), copyDocs ? terminal.getDoc() : null, terminal.getNamespace(), terminal.getFixedSize());            break;        default:            throw new IllegalStateException("Unsupported schema " + terminal);    }    copyProperties.copy(terminal, newSchema);    replace.put(terminal, newSchema);    return SchemaVisitorAction.CONTINUE;}
0
public SchemaVisitorAction visitNonTerminal(final Schema nt)
{    Schema.Type type = nt.getType();    if (type == RECORD) {        Schema newSchema = Schema.createRecord(nt.getName(), copyDocs ? nt.getDoc() : null, nt.getNamespace(), nt.isError());        copyProperties.copy(nt, newSchema);        replace.put(nt, newSchema);    }    return SchemaVisitorAction.CONTINUE;}
0
public SchemaVisitorAction afterVisitNonTerminal(final Schema nt)
{    Schema.Type type = nt.getType();    Schema newSchema;    switch(type) {        case RECORD:            newSchema = replace.get(nt);            List<Schema.Field> fields = nt.getFields();            List<Schema.Field> newFields = new ArrayList<>(fields.size());            for (Schema.Field field : fields) {                Schema.Field newField = new Schema.Field(field.name(), replace.get(field.schema()), copyDocs ? field.doc() : null, field.defaultVal(), field.order());                copyProperties.copy(field, newField);                newFields.add(newField);            }            newSchema.setFields(newFields);            return SchemaVisitorAction.CONTINUE;        case UNION:            List<Schema> types = nt.getTypes();            List<Schema> newTypes = new ArrayList<>(types.size());            for (Schema sch : types) {                newTypes.add(replace.get(sch));            }            newSchema = Schema.createUnion(newTypes);            break;        case ARRAY:            newSchema = Schema.createArray(replace.get(nt.getElementType()));            break;        case MAP:            newSchema = Schema.createMap(replace.get(nt.getValueType()));            break;        default:            throw new IllegalStateException("Illegal type " + type + ", schema " + nt);    }    copyProperties.copy(nt, newSchema);    replace.put(nt, newSchema);    return SchemaVisitorAction.CONTINUE;}
0
public Schema get()
{    return replace.get(root);}
0
public String toString()
{    return "CloningVisitor{" + "replace=" + replace + ", root=" + root + '}';}
0
public static void copyAliases(final Schema from, final Schema to)
{    switch(    from.getType()) {        case RECORD:        case ENUM:        case FIXED:            Set<String> aliases = from.getAliases();            for (String alias : aliases) {                to.addAlias(alias);            }    }}
0
public static void copyAliases(final Schema.Field from, final Schema.Field to)
{    Set<String> aliases = from.aliases();    for (String alias : aliases) {        to.addAlias(alias);    }}
0
public static void copyLogicalTypes(final Schema from, final Schema to)
{    LogicalType logicalType = from.getLogicalType();    if (logicalType != null) {        logicalType.addToSchema(to);    }}
0
public static void copyProperties(final JsonProperties from, final JsonProperties to)
{    Map<String, Object> objectProps = from.getObjectProps();    for (Map.Entry<String, Object> entry : objectProps.entrySet()) {        to.addProp(entry.getKey(), entry.getValue());    }}
0
public static boolean hasGeneratedJavaClass(final Schema schema)
{    Schema.Type type = schema.getType();    switch(type) {        case ENUM:        case RECORD:        case FIXED:            return true;        default:            return false;    }}
0
public static String getJavaClassName(final Schema schema)
{    String namespace = schema.getNamespace();    if (namespace == null) {        return SpecificCompiler.mangle(schema.getName());    } else {        return namespace + '.' + SpecificCompiler.mangle(schema.getName());    }}
0
public static T visit(final Schema start, final SchemaVisitor<T> visitor)
{        IdentityHashMap<Schema, Schema> visited = new IdentityHashMap<>();                    Deque<Object> dq = new ArrayDeque<>();    dq.addLast(start);    Object current;    while ((current = dq.pollLast()) != null) {        if (current instanceof Supplier) {                        SchemaVisitorAction action = ((Supplier<SchemaVisitorAction>) current).get();            switch(action) {                case CONTINUE:                    break;                case SKIP_SUBTREE:                    throw new UnsupportedOperationException();                case SKIP_SIBLINGS:                    while (dq.getLast() instanceof Schema) {                        dq.removeLast();                    }                    break;                case TERMINATE:                    return visitor.get();                default:                    throw new UnsupportedOperationException("Invalid action " + action);            }        } else {            Schema schema = (Schema) current;            boolean terminate;            if (!visited.containsKey(schema)) {                Schema.Type type = schema.getType();                switch(type) {                    case ARRAY:                        terminate = visitNonTerminal(visitor, schema, dq, Collections.singleton(schema.getElementType()));                        visited.put(schema, schema);                        break;                    case RECORD:                        Iterator<Schema> reverseSchemas = schema.getFields().stream().map(Field::schema).collect(Collectors.toCollection(ArrayDeque::new)).descendingIterator();                        terminate = visitNonTerminal(visitor, schema, dq, () -> reverseSchemas);                        visited.put(schema, schema);                        break;                    case UNION:                        terminate = visitNonTerminal(visitor, schema, dq, schema.getTypes());                        visited.put(schema, schema);                        break;                    case MAP:                        terminate = visitNonTerminal(visitor, schema, dq, Collections.singleton(schema.getValueType()));                        visited.put(schema, schema);                        break;                    case NULL:                    case BOOLEAN:                    case BYTES:                    case DOUBLE:                    case ENUM:                    case FIXED:                    case FLOAT:                    case INT:                    case LONG:                    case STRING:                        terminate = visitTerminal(visitor, schema, dq);                        break;                    default:                        throw new UnsupportedOperationException("Invalid type " + type);                }            } else {                terminate = visitTerminal(visitor, schema, dq);            }            if (terminate) {                return visitor.get();            }        }    }    return visitor.get();}
0
private static boolean visitNonTerminal(final SchemaVisitor visitor, final Schema schema, final Deque<Object> dq, final Iterable<Schema> itSupp)
{    SchemaVisitorAction action = visitor.visitNonTerminal(schema);    switch(action) {        case CONTINUE:            dq.addLast((Supplier<SchemaVisitorAction>) () -> visitor.afterVisitNonTerminal(schema));            for (Schema child : itSupp) {                dq.addLast(child);            }            break;        case SKIP_SUBTREE:            dq.addLast((Supplier<SchemaVisitorAction>) () -> visitor.afterVisitNonTerminal(schema));            break;        case SKIP_SIBLINGS:            while (!dq.isEmpty() && dq.getLast() instanceof Schema) {                dq.removeLast();            }            break;        case TERMINATE:            return true;        default:            throw new UnsupportedOperationException("Invalid action " + action + " for " + schema);    }    return false;}
0
private static boolean visitTerminal(final SchemaVisitor visitor, final Schema schema, final Deque<Object> dq)
{    SchemaVisitorAction action = visitor.visitTerminal(schema);    switch(action) {        case CONTINUE:            break;        case SKIP_SUBTREE:            throw new UnsupportedOperationException("Invalid action " + action + " for " + schema);        case SKIP_SIBLINGS:            while (!dq.isEmpty() && dq.getLast() instanceof Schema) {                dq.removeLast();            }            break;        case TERMINATE:            return true;        default:            throw new UnsupportedOperationException("Invalid action " + action + " for " + schema);    }    return false;}
0
public void setFile(File file)
{    this.src = file;}
0
public void setDestdir(File dir)
{    this.dest = dir;}
0
public void setStringType(StringType type)
{    this.stringType = type;}
0
public StringType getStringType()
{    return this.stringType;}
0
public void addFileset(FileSet set)
{    filesets.add(set);}
0
public void execute()
{    if (src == null && filesets.size() == 0)        throw new BuildException("No file or fileset specified.");    if (src != null)        compile(src);    Project myProject = getProject();    for (FileSet fs : filesets) {        DirectoryScanner ds = fs.getDirectoryScanner(myProject);        File dir = fs.getDir(myProject);        String[] srcs = ds.getIncludedFiles();        for (String src1 : srcs) {            compile(new File(dir, src1));        }    }}
0
protected void doCompile(File src, File dir) throws IOException
{    Protocol protocol = Protocol.parse(src);    SpecificCompiler compiler = new SpecificCompiler(protocol);    compiler.setStringType(getStringType());    compiler.compileToDestination(src, dest);}
0
private void compile(File file)
{    try {        doCompile(file, dest);    } catch (AvroRuntimeException | IOException e) {        throw new BuildException(e);    }}
0
protected void doCompile(File src, File dest) throws IOException
{    final Schema.Parser parser = new Schema.Parser();    final Schema schema = parser.parse(src);    final SpecificCompiler compiler = new SpecificCompiler(schema);    compiler.setStringType(getStringType());    compiler.compileToDestination(src, dest);}
0
public static void main(String[] args) throws IOException
{    if (args.length < 2) {        System.err.println("Usage: SchemaTask <schema.avsc>... <output-folder>");        System.exit(1);    }    File dst = new File(args[args.length - 1]);    for (int i = 0; i < args.length - 1; i++) new SchemaTask().doCompile(new File(args[i]), dst);}
0
 void addLogicalTypeConversions(SpecificData specificData)
{    specificData.addLogicalTypeConversion(new TimeConversions.DateConversion());    specificData.addLogicalTypeConversion(new TimeConversions.TimeMillisConversion());    specificData.addLogicalTypeConversion(new TimeConversions.TimeMicrosConversion());    specificData.addLogicalTypeConversion(new TimeConversions.TimestampMillisConversion());    specificData.addLogicalTypeConversion(new TimeConversions.TimestampMicrosConversion());}
0
public boolean isCreateAllArgsConstructor()
{    return createAllArgsConstructor;}
0
public void setAdditionalVelocityTools(List<Object> additionalVelocityTools)
{    this.additionalVelocityTools = additionalVelocityTools;}
0
public void setTemplateDir(String templateDir)
{    this.templateDir = templateDir;}
0
public void setSuffix(String suffix)
{    this.suffix = suffix;}
0
public boolean deprecatedFields()
{    return (this.fieldVisibility == FieldVisibility.PUBLIC_DEPRECATED);}
0
public boolean publicFields()
{    return (this.fieldVisibility == FieldVisibility.PUBLIC || this.fieldVisibility == FieldVisibility.PUBLIC_DEPRECATED);}
0
public boolean privateFields()
{    return (this.fieldVisibility == FieldVisibility.PRIVATE);}
0
public void setFieldVisibility(FieldVisibility fieldVisibility)
{    this.fieldVisibility = fieldVisibility;}
0
public boolean isCreateSetters()
{    return this.createSetters;}
0
public void setCreateSetters(boolean createSetters)
{    this.createSetters = createSetters;}
0
public boolean isCreateOptionalGetters()
{    return this.createOptionalGetters;}
0
public void setCreateOptionalGetters(boolean createOptionalGetters)
{    this.createOptionalGetters = createOptionalGetters;}
0
public boolean isGettersReturnOptional()
{    return this.gettersReturnOptional;}
0
public void setGettersReturnOptional(boolean gettersReturnOptional)
{    this.gettersReturnOptional = gettersReturnOptional;}
0
public void setEnableDecimalLogicalType(boolean enableDecimalLogicalType)
{    this.enableDecimalLogicalType = enableDecimalLogicalType;}
0
public void addCustomConversion(Class<?> conversionClass)
{    try {        final Conversion<?> conversion = (Conversion<?>) conversionClass.getDeclaredConstructor().newInstance();        specificData.addLogicalTypeConversion(conversion);    } catch (IllegalAccessException | InstantiationException | NoSuchMethodException | InvocationTargetException e) {        throw new RuntimeException("Failed to instantiate conversion class " + conversionClass, e);    }}
0
public Collection<String> getUsedConversionClasses(Schema schema)
{    LinkedHashMap<String, Conversion<?>> classnameToConversion = new LinkedHashMap<>();    for (Conversion<?> conversion : specificData.getConversions()) {        classnameToConversion.put(conversion.getConvertedType().getCanonicalName(), conversion);    }    Collection<String> result = new HashSet<>();    for (String className : getClassNamesOfPrimitiveFields(schema)) {        if (classnameToConversion.containsKey(className)) {            result.add(classnameToConversion.get(className).getClass().getCanonicalName());        }    }    return result;}
0
private Set<String> getClassNamesOfPrimitiveFields(Schema schema)
{    Set<String> result = new HashSet<>();    getClassNamesOfPrimitiveFields(schema, result, new HashSet<>());    return result;}
0
private void getClassNamesOfPrimitiveFields(Schema schema, Set<String> result, Set<Schema> seenSchemas)
{    if (seenSchemas.contains(schema)) {        return;    }    seenSchemas.add(schema);    switch(schema.getType()) {        case RECORD:            for (Schema.Field field : schema.getFields()) {                getClassNamesOfPrimitiveFields(field.schema(), result, seenSchemas);            }            break;        case MAP:            getClassNamesOfPrimitiveFields(schema.getValueType(), result, seenSchemas);            break;        case ARRAY:            getClassNamesOfPrimitiveFields(schema.getElementType(), result, seenSchemas);            break;        case UNION:            for (Schema s : schema.getTypes()) getClassNamesOfPrimitiveFields(s, result, seenSchemas);            break;        case ENUM:        case FIXED:        case NULL:            break;        case STRING:        case BYTES:        case INT:        case LONG:        case FLOAT:        case DOUBLE:        case BOOLEAN:            result.add(javaType(schema));            break;        default:            throw new RuntimeException("Unknown type: " + schema);    }}
0
private void initializeVelocity()
{    this.velocityEngine = new VelocityEngine();            velocityEngine.addProperty("resource.loader", "class, file");    velocityEngine.addProperty("class.resource.loader.class", "org.apache.velocity.runtime.resource.loader.ClasspathResourceLoader");    velocityEngine.addProperty("file.resource.loader.class", "org.apache.velocity.runtime.resource.loader.FileResourceLoader");    velocityEngine.addProperty("file.resource.loader.path", "/, .");    velocityEngine.setProperty("runtime.references.strict", true);            velocityEngine.setProperty("space.gobbling", "bc");}
0
private void initializeSpecificData()
{    addLogicalTypeConversions(specificData);    specificData.addLogicalTypeConversion(new Conversions.DecimalConversion());}
0
 File writeToDestination(File src, File destDir) throws IOException
{    File f = new File(destDir, path);    if (src != null && f.exists() && f.lastModified() >= src.lastModified())                return f;    f.getParentFile().mkdirs();    Writer fw = null;    FileOutputStream fos = null;    try {        if (outputCharacterEncoding != null) {            fos = new FileOutputStream(f);            fw = new OutputStreamWriter(fos, outputCharacterEncoding);        } else {            fw = Files.newBufferedWriter(f.toPath(), UTF_8);        }        fw.write(FILE_HEADER);        fw.write(contents);    } finally {        if (fw != null)            fw.close();        if (fos != null)            fos.close();    }    return f;}
0
public static void compileProtocol(File src, File dest) throws IOException
{    compileProtocol(new File[] { src }, dest);}
0
public static void compileProtocol(File[] srcFiles, File dest) throws IOException
{    for (File src : srcFiles) {        Protocol protocol = Protocol.parse(src);        SpecificCompiler compiler = new SpecificCompiler(protocol);        compiler.compileToDestination(src, dest);    }}
0
public static void compileSchema(File src, File dest) throws IOException
{    compileSchema(new File[] { src }, dest);}
0
public static void compileSchema(File[] srcFiles, File dest) throws IOException
{    Schema.Parser parser = new Schema.Parser();    for (File src : srcFiles) {        Schema schema = parser.parse(src);        SpecificCompiler compiler = new SpecificCompiler(schema);        compiler.compileToDestination(src, dest);    }}
0
private void enqueue(Schema schema)
{    if (queue.contains(schema))        return;    switch(schema.getType()) {        case RECORD:            queue.add(schema);            for (Schema.Field field : schema.getFields()) enqueue(field.schema());            break;        case MAP:            enqueue(schema.getValueType());            break;        case ARRAY:            enqueue(schema.getElementType());            break;        case UNION:            for (Schema s : schema.getTypes()) enqueue(s);            break;        case ENUM:        case FIXED:            queue.add(schema);            break;        case STRING:        case BYTES:        case INT:        case LONG:        case FLOAT:        case DOUBLE:        case BOOLEAN:        case NULL:            break;        default:            throw new RuntimeException("Unknown type: " + schema);    }}
0
 Collection<OutputFile> compile()
{    List<OutputFile> out = new ArrayList<>();    for (Schema schema : queue) {        out.add(compile(schema));    }    if (protocol != null) {        out.add(compileInterface(protocol));    }    return out;}
0
public void compileToDestination(File src, File dst) throws IOException
{    for (Schema schema : queue) {        OutputFile o = compile(schema);        o.writeToDestination(src, dst);    }    if (protocol != null) {        compileInterface(protocol).writeToDestination(src, dst);    }}
0
private String renderTemplate(String templateName, VelocityContext context)
{    Template template;    try {        template = this.velocityEngine.getTemplate(templateName);    } catch (Exception e) {        throw new RuntimeException(e);    }    StringWriter writer = new StringWriter();    template.merge(context, writer);    return writer.toString();}
0
 OutputFile compileInterface(Protocol protocol)
{        protocol = addStringType(protocol);    VelocityContext context = new VelocityContext();    context.put("protocol", protocol);    context.put("this", this);    for (Object velocityTool : additionalVelocityTools) {        String toolName = velocityTool.getClass().getSimpleName().toLowerCase();        context.put(toolName, velocityTool);    }    String out = renderTemplate(templateDir + "protocol.vm", context);    OutputFile outputFile = new OutputFile();    String mangledName = mangle(protocol.getName());    outputFile.path = makePath(mangledName, protocol.getNamespace());    outputFile.contents = out;    outputFile.outputCharacterEncoding = outputCharacterEncoding;    return outputFile;}
0
 String makePath(String name, String space)
{    if (space == null || space.isEmpty()) {        return name + suffix;    } else {        return space.replace('.', File.separatorChar) + File.separatorChar + name + suffix;    }}
0
protected int calcAllArgConstructorParameterUnits(Schema record)
{    if (record.getType() != Schema.Type.RECORD)        throw new RuntimeException("This method must only be called for record schemas.");    return record.getFields().size();}
0
protected void validateRecordForCompilation(Schema record)
{    this.createAllArgsConstructor = calcAllArgConstructorParameterUnits(record) <= MAX_FIELD_PARAMETER_UNIT_COUNT;    if (!this.createAllArgsConstructor) {        Logger logger = LoggerFactory.getLogger(SpecificCompiler.class);            }}
1
 OutputFile compile(Schema schema)
{        schema = addStringType(schema);    String output = "";    VelocityContext context = new VelocityContext();    context.put("this", this);    context.put("schema", schema);    for (Object velocityTool : additionalVelocityTools) {        String toolName = velocityTool.getClass().getSimpleName().toLowerCase();        context.put(toolName, velocityTool);    }    switch(schema.getType()) {        case RECORD:            validateRecordForCompilation(schema);            output = renderTemplate(templateDir + "record.vm", context);            break;        case ENUM:            output = renderTemplate(templateDir + "enum.vm", context);            break;        case FIXED:            output = renderTemplate(templateDir + "fixed.vm", context);            break;        case BOOLEAN:        case NULL:            break;        default:            throw new RuntimeException("Unknown type: " + schema);    }    OutputFile outputFile = new OutputFile();    String name = mangle(schema.getName());    outputFile.path = makePath(name, schema.getNamespace());    outputFile.contents = output;    outputFile.outputCharacterEncoding = outputCharacterEncoding;    return outputFile;}
0
public void setStringType(StringType t)
{    this.stringType = t;}
0
private Protocol addStringType(Protocol p)
{    if (stringType != StringType.String)        return p;    Protocol newP = new Protocol(p.getName(), p.getDoc(), p.getNamespace());    Map<Schema, Schema> types = new LinkedHashMap<>();    for (Map.Entry<String, Object> a : p.getObjectProps().entrySet()) {        newP.addProp(a.getKey(), a.getValue());    }        Collection<Schema> namedTypes = new LinkedHashSet<>();    for (Schema s : p.getTypes()) namedTypes.add(addStringType(s, types));    newP.setTypes(namedTypes);        Map<String, Message> newM = newP.getMessages();    for (Message m : p.getMessages().values()) newM.put(m.getName(), m.isOneWay() ? newP.createMessage(m, addStringType(m.getRequest(), types)) : newP.createMessage(m, addStringType(m.getRequest(), types), addStringType(m.getResponse(), types), addStringType(m.getErrors(), types)));    return newP;}
0
private Schema addStringType(Schema s)
{    if (stringType != StringType.String)        return s;    return addStringType(s, new LinkedHashMap<>());}
0
private Schema addStringType(Schema s, Map<Schema, Schema> seen)
{    if (seen.containsKey(s))                return seen.get(s);    Schema result = s;    switch(s.getType()) {        case STRING:            result = Schema.create(Schema.Type.STRING);            GenericData.setStringType(result, stringType);            break;        case RECORD:            result = Schema.createRecord(s.getFullName(), s.getDoc(), null, s.isError());            for (String alias : s.getAliases())             result.addAlias(alias, null);            seen.put(s, result);            List<Field> newFields = new ArrayList<>();            for (Field f : s.getFields()) {                Schema fSchema = addStringType(f.schema(), seen);                Field newF = new Field(f, fSchema);                newFields.add(newF);            }            result.setFields(newFields);            break;        case ARRAY:            Schema e = addStringType(s.getElementType(), seen);            result = Schema.createArray(e);            break;        case MAP:            Schema v = addStringType(s.getValueType(), seen);            result = Schema.createMap(v);            GenericData.setStringType(result, stringType);            break;        case UNION:            List<Schema> types = new ArrayList<>();            for (Schema branch : s.getTypes()) types.add(addStringType(branch, seen));            result = Schema.createUnion(types);            break;    }    result.addAllProps(s);    seen.put(s, result);    return result;}
0
public String getStringType(Schema s)
{    String prop;    switch(s.getType()) {        case MAP:            prop = SpecificData.KEY_CLASS_PROP;            break;        case STRING:            prop = SpecificData.CLASS_PROP;            break;        default:            throw new IllegalArgumentException("Can't check string-type of non-string/map type: " + s);    }    return getStringType(s.getObjectProp(prop));}
0
private String getStringType(Object overrideClassProperty)
{    if (overrideClassProperty != null)        return overrideClassProperty.toString();    switch(stringType) {        case String:            return "java.lang.String";        case Utf8:            return "org.apache.avro.util.Utf8";        case CharSequence:            return "java.lang.CharSequence";        default:            throw new RuntimeException("Unknown string type: " + stringType);    }}
0
public boolean isStringable(Schema schema)
{    String t = getStringType(schema);    return !(t.equals("java.lang.String") || t.equals("java.lang.CharSequence") || t.equals("org.apache.avro.util.Utf8"));}
0
public String javaType(Schema schema)
{    return javaType(schema, true);}
0
private String javaType(Schema schema, boolean checkConvertedLogicalType)
{    if (checkConvertedLogicalType) {        String convertedLogicalType = getConvertedLogicalType(schema);        if (convertedLogicalType != null) {            return convertedLogicalType;        }    }    switch(schema.getType()) {        case RECORD:        case ENUM:        case FIXED:            return mangle(schema.getFullName());        case ARRAY:            return "java.util.List<" + javaType(schema.getElementType()) + ">";        case MAP:            return "java.util.Map<" + getStringType(schema.getObjectProp(SpecificData.KEY_CLASS_PROP)) + "," + javaType(schema.getValueType()) + ">";        case UNION:                        List<Schema> types = schema.getTypes();            if ((types.size() == 2) && types.contains(NULL_SCHEMA))                return javaType(types.get(types.get(0).equals(NULL_SCHEMA) ? 1 : 0));            return "java.lang.Object";        case STRING:            return getStringType(schema.getObjectProp(SpecificData.CLASS_PROP));        case BYTES:            return "java.nio.ByteBuffer";        case INT:            return "java.lang.Integer";        case LONG:            return "java.lang.Long";        case FLOAT:            return "java.lang.Float";        case DOUBLE:            return "java.lang.Double";        case BOOLEAN:            return "java.lang.Boolean";        case NULL:            return "java.lang.Void";        default:            throw new RuntimeException("Unknown type: " + schema);    }}
0
private String getConvertedLogicalType(Schema schema)
{    if (enableDecimalLogicalType || !(schema.getLogicalType() instanceof LogicalTypes.Decimal)) {        Conversion<?> conversion = specificData.getConversionFor(schema.getLogicalType());        if (conversion != null) {            return conversion.getConvertedType().getName();        }    }    return null;}
0
public String generateSetterCode(Schema schema, String name, String pname)
{    Conversion<?> conversion = specificData.getConversionFor(schema.getLogicalType());    if (conversion != null) {        return conversion.adjustAndSetValue("this." + name, pname);    }    return "this." + name + " = " + pname + ";";}
0
public String javaUnbox(Schema schema)
{    return javaUnbox(schema, false);}
0
public String javaUnbox(Schema schema, boolean unboxNullToVoid)
{    String convertedLogicalType = getConvertedLogicalType(schema);    if (convertedLogicalType != null) {        return convertedLogicalType;    }    switch(schema.getType()) {        case INT:            return "int";        case LONG:            return "long";        case FLOAT:            return "float";        case DOUBLE:            return "double";        case BOOLEAN:            return "boolean";        case NULL:            if (unboxNullToVoid) {                                return "void";            }        default:            return javaType(schema, false);    }}
0
public String indent(int n)
{    return new String(new char[n]).replace('\0', ' ');}
0
public int getNonNullIndex(Schema s)
{    if (s.getType() != Schema.Type.UNION || s.getTypes().size() != 2 || !s.getTypes().contains(NULL_SCHEMA))        throw new IllegalArgumentException("Can only be used on 2-branch union with a null branch: " + s);    return (s.getTypes().get(0).equals(NULL_SCHEMA) ? 1 : 0);}
0
public boolean isCustomCodable(Schema schema)
{    if (schema.isError())        return false;    return isCustomCodable(schema, new HashSet<>());}
0
private boolean isCustomCodable(Schema schema, Set<Schema> seen)
{    if (!seen.add(schema))        return true;    if (schema.getLogicalType() != null)        return false;    boolean result = true;    switch(schema.getType()) {        case RECORD:            for (Schema.Field f : schema.getFields()) result &= isCustomCodable(f.schema(), seen);            break;        case MAP:            result = isCustomCodable(schema.getValueType(), seen);            break;        case ARRAY:            result = isCustomCodable(schema.getElementType(), seen);            break;        case UNION:            List<Schema> types = schema.getTypes();                        if (types.size() != 2 || !types.contains(NULL_SCHEMA))                return false;            for (Schema s : types) result &= isCustomCodable(s, seen);            break;        default:    }    return result;}
0
public boolean hasLogicalTypeField(Schema schema)
{    for (Schema.Field field : schema.getFields()) {        if (field.schema().getLogicalType() != null) {            return true;        }    }    return false;}
0
public String conversionInstance(Schema schema)
{    if (schema == null || schema.getLogicalType() == null) {        return "null";    }    if (LogicalTypes.Decimal.class.equals(schema.getLogicalType().getClass()) && !enableDecimalLogicalType) {        return "null";    }    final Conversion<Object> conversion = specificData.getConversionFor(schema.getLogicalType());    if (conversion != null) {        return "new " + conversion.getClass().getCanonicalName() + "()";    }    return "null";}
0
public String[] javaAnnotations(JsonProperties props)
{    final Object value = props.getObjectProp("javaAnnotation");    if (value == null)        return new String[0];    if (value instanceof String)        return new String[] { value.toString() };    if (value instanceof List) {        final List<?> list = (List<?>) value;        final List<String> annots = new ArrayList<>();        for (Object o : list) {            annots.add(o.toString());        }        return annots.toArray(new String[0]);    }    return new String[0];}
0
public String javaSplit(String s) throws IOException
{        StringBuilder b = new StringBuilder("\"");    for (int i = 0; i < s.length(); i += maxStringChars) {        if (i != 0)                        b.append("\",\"");        String chunk = s.substring(i, Math.min(s.length(), i + maxStringChars));                b.append(javaEscape(chunk));    }        b.append("\"");    return b.toString();}
0
public static String javaEscape(Object o)
{    return o.toString().replace("\\", "\\\\").replace("\"", "\\\"");}
0
public static String escapeForJavadoc(String s)
{    return s.replace("*/", "*&#47;");}
0
public static String nullToEmpty(String x)
{    return x == null ? "" : x;}
0
public static String mangle(String word)
{    return mangle(word, false);}
0
public static String mangle(String word, boolean isError)
{    return mangle(word, isError ? ERROR_RESERVED_WORDS : RESERVED_WORDS);}
0
public static String mangle(String word, Set<String> reservedWords)
{    return mangle(word, reservedWords, false);}
0
public static String mangle(String word, Set<String> reservedWords, boolean isMethod)
{    if (word.contains(".")) {                        int lastDot = word.lastIndexOf(".");        String packageName = word.substring(0, lastDot + 1);        String className = word.substring(lastDot + 1);        return packageName + mangle(className, reservedWords, isMethod);    }    if (reservedWords.contains(word) || (isMethod && reservedWords.contains(Character.toLowerCase(word.charAt(0)) + ((word.length() > 1) ? word.substring(1) : "")))) {        return word + "$";    }    return word;}
0
public static long fingerprint64(Schema schema)
{    return SchemaNormalization.parsingFingerprint64(schema);}
0
public static String generateGetMethod(Schema schema, Field field)
{    return generateMethodName(schema, field, "get", "");}
0
public static String generateGetOptionalMethod(Schema schema, Field field)
{    return generateMethodName(schema, field, "getOptional", "");}
0
public static String generateSetMethod(Schema schema, Field field)
{    return generateMethodName(schema, field, "set", "");}
0
public static String generateHasMethod(Schema schema, Field field)
{    return generateMethodName(schema, field, "has", "");}
0
public static String generateClearMethod(Schema schema, Field field)
{    return generateMethodName(schema, field, "clear", "");}
0
public static boolean hasBuilder(Schema schema)
{    switch(schema.getType()) {        case RECORD:            return true;        case UNION:                        List<Schema> types = schema.getTypes();            if ((types.size() == 2) && types.contains(NULL_SCHEMA)) {                return hasBuilder(types.get(types.get(0).equals(NULL_SCHEMA) ? 1 : 0));            }            return false;        default:            return false;    }}
0
public static String generateGetBuilderMethod(Schema schema, Field field)
{    return generateMethodName(schema, field, "get", "Builder");}
0
public static String generateSetBuilderMethod(Schema schema, Field field)
{    return generateMethodName(schema, field, "set", "Builder");}
0
public static String generateHasBuilderMethod(Schema schema, Field field)
{    return generateMethodName(schema, field, "has", "Builder");}
0
private static String generateMethodName(Schema schema, Field field, String prefix, String postfix)
{            char firstChar = field.name().charAt(0);    String conflictingFieldName = (Character.isLowerCase(firstChar) ? Character.toUpperCase(firstChar) : Character.toLowerCase(firstChar)) + (field.name().length() > 1 ? field.name().substring(1) : "");    boolean fieldNameConflict = schema.getField(conflictingFieldName) != null;    StringBuilder methodBuilder = new StringBuilder(prefix);    String fieldName = mangle(field.name(), schema.isError() ? ERROR_RESERVED_WORDS : ACCESSOR_MUTATOR_RESERVED_WORDS, true);    boolean nextCharToUpper = true;    for (int ii = 0; ii < fieldName.length(); ii++) {        if (fieldName.charAt(ii) == '_') {            nextCharToUpper = true;        } else if (nextCharToUpper) {            methodBuilder.append(Character.toUpperCase(fieldName.charAt(ii)));            nextCharToUpper = false;        } else {            methodBuilder.append(fieldName.charAt(ii));        }    }    methodBuilder.append(postfix);        if (fieldNameConflict) {        if (methodBuilder.charAt(methodBuilder.length() - 1) != '$') {            methodBuilder.append('$');        }        methodBuilder.append(Character.isLowerCase(firstChar) ? '0' : '1');    }    return methodBuilder.toString();}
0
public static boolean isUnboxedJavaTypeNullable(Schema schema)
{    switch(schema.getType()) {                case INT:        case LONG:        case FLOAT:        case DOUBLE:        case BOOLEAN:            return false;        default:            return true;    }}
0
public static void main(String[] args) throws Exception
{        compileProtocol(new File(args[0]), new File(args[1]));}
0
public void setOutputCharacterEncoding(String outputCharacterEncoding)
{    this.outputCharacterEncoding = outputCharacterEncoding;}
0
public void testCycleGeneration() throws ParseException, IOException
{    final ClassLoader cl = Thread.currentThread().getContextClassLoader();    Idl idl = new Idl(cl.getResourceAsStream("input/cycle.avdl"), "UTF-8");    Protocol protocol = idl.CompilationUnit();    String json = protocol.toString();        SpecificCompiler compiler = new SpecificCompiler(protocol);    compiler.setStringType(GenericData.StringType.String);    File output = new File("./target");    compiler.compileToDestination(null, output);    Map<String, Schema> schemas = new HashMap<>();    for (Schema schema : protocol.getTypes()) {        final String name = schema.getName();        schemas.put(name, schema);    }    GenericRecordBuilder rb2 = new GenericRecordBuilder(schemas.get("SampleNode"));    rb2.set("count", 10);    rb2.set("subNodes", Collections.EMPTY_LIST);    GenericData.Record node = rb2.build();    GenericRecordBuilder mb = new GenericRecordBuilder(schemas.get("Method"));    mb.set("declaringClass", "Test");    mb.set("methodName", "test");    GenericData.Record method = mb.build();    GenericRecordBuilder spb = new GenericRecordBuilder(schemas.get("SamplePair"));    spb.set("method", method);    spb.set("node", node);    GenericData.Record sp = spb.build();    GenericRecordBuilder rb = new GenericRecordBuilder(schemas.get("SampleNode"));    rb.set("count", 10);    rb.set("subNodes", Collections.singletonList(sp));    GenericData.Record record = rb.build();    serDeserRecord(record);}
1
private static void serDeserRecord(GenericData.Record data) throws IOException
{    ByteArrayOutputStream bab = new ByteArrayOutputStream();    GenericDatumWriter writer = new GenericDatumWriter(data.getSchema());    final BinaryEncoder directBinaryEncoder = EncoderFactory.get().directBinaryEncoder(bab, null);    writer.write(data, directBinaryEncoder);    directBinaryEncoder.flush();    ByteArrayInputStream bis = new ByteArrayInputStream(bab.toByteArray(), 0, bab.size());    GenericDatumReader reader = new GenericDatumReader(data.getSchema());    BinaryDecoder directBinaryDecoder = DecoderFactory.get().directBinaryDecoder(bis, null);    GenericData.Record read = (GenericData.Record) reader.read(null, directBinaryDecoder);    Assert.assertEquals(data.toString(), read.toString());}
0
public void loadTests()
{    assertTrue(TEST_DIR.exists());    assertTrue(TEST_INPUT_DIR.exists());    assertTrue(TEST_OUTPUT_DIR.exists());    tests = new ArrayList<>();    for (File inF : TEST_INPUT_DIR.listFiles()) {        if (!inF.getName().endsWith(".avdl"))            continue;        if (inF.getName().startsWith("."))            continue;        File outF = new File(TEST_OUTPUT_DIR, inF.getName().replaceFirst("\\.avdl$", ".avpr"));        tests.add(new GenTest(inF, outF));    }}
0
public void runTests() throws Exception
{    if (!"run".equals(TEST_MODE))        return;    int passed = 0, failed = 0;    for (GenTest t : tests) {        try {            t.run();            passed++;        } catch (Exception e) {            failed++;            System.err.println("Failed: " + t.testName());            e.printStackTrace(System.err);        }    }    if (failed > 0) {        fail(String.valueOf(failed) + " tests failed");    }}
0
public void writeTests() throws Exception
{    if (!"write".equals(TEST_MODE))        return;    for (GenTest t : tests) {        t.write();    }}
0
private String generate() throws Exception
{    ClassLoader cl = Thread.currentThread().getContextClassLoader();        File file = new File(".");    String currentWorkPath = file.toURI().toURL().toString();    String newPath = currentWorkPath + "src" + File.separator + "test" + File.separator + "idl" + File.separator + "putOnClassPath" + File.separator;    URL[] newPathURL = new URL[] { new URL(newPath) };    URLClassLoader ucl = new URLClassLoader(newPathURL, cl);    Idl parser = new Idl(in, ucl);    Protocol p = parser.CompilationUnit();    parser.close();    return p.toString();}
0
public String testName()
{    return this.in.getName();}
0
public void run() throws Exception
{    String output = generate();    String slurped = slurp(expectedOut);    assertEquals(slurped.trim(), output.replace("\\r", "").trim());}
0
public void write() throws Exception
{    writeFile(expectedOut, generate());}
0
private static String slurp(File f) throws IOException
{    BufferedReader in = new BufferedReader(new InputStreamReader(new FileInputStream(f), "UTF-8"));    String line = null;    StringBuilder builder = new StringBuilder();    while ((line = in.readLine()) != null) {        builder.append(line);    }    in.close();    ObjectMapper mapper = new ObjectMapper();    JsonNode json = mapper.readTree(builder.toString());    return mapper.writer().writeValueAsString(json);}
0
private static void writeFile(File f, String s) throws IOException
{    FileWriter w = new FileWriter(f);    w.write(s);    w.close();}
0
public void testResolving() throws ParseException, MalformedURLException, IOException
{    File file = new File(".");    String currentWorkPath = file.getAbsolutePath();    String testIdl = currentWorkPath + File.separator + "src" + File.separator + "test" + File.separator + "idl" + File.separator + "cycle.avdl";    Idl compiler = new Idl(new File(testIdl));    Protocol protocol = compiler.CompilationUnit();    System.out.println(protocol);    Assert.assertEquals(5, protocol.getTypes().size());}
0
public void testIsUnresolvedSchemaError1()
{        Schema s = SchemaBuilder.record("R").fields().endRecord();    SchemaResolver.getUnresolvedSchemaName(s);}
0
public void testIsUnresolvedSchemaError2()
{        Schema s = SchemaBuilder.record("R").prop("org.apache.avro.compiler.idl.unresolved.name", "x").fields().endRecord();    SchemaResolver.getUnresolvedSchemaName(s);}
0
public void testIsUnresolvedSchemaError3()
{        Schema s = SchemaBuilder.record("UnresolvedSchema").prop("org.apache.avro.compiler.idl.unresolved.name", "x").fields().endRecord();    SchemaResolver.getUnresolvedSchemaName(s);}
0
public void testGetUnresolvedSchemaNameError()
{    Schema s = SchemaBuilder.fixed("a").size(10);    SchemaResolver.getUnresolvedSchemaName(s);}
0
public SchemaVisitorAction visitTerminal(Schema terminal)
{    System.out.println("Terminal: " + terminal.getFullName());    return SchemaVisitorAction.CONTINUE;}
0
public SchemaVisitorAction visitNonTerminal(Schema terminal)
{    System.out.println("NONTerminal start: " + terminal.getFullName());    return SchemaVisitorAction.CONTINUE;}
0
public SchemaVisitorAction afterVisitNonTerminal(Schema terminal)
{    System.out.println("NONTerminal end: " + terminal.getFullName());    return SchemaVisitorAction.CONTINUE;}
0
public Object get()
{    return null;}
0
public void textCloning()
{    Schema recSchema = new Schema.Parser().parse(SCHEMA);    Schemas.visit(recSchema, new PrintingVisitor());    CloningVisitor cv = new CloningVisitor(recSchema);    Schema trimmed = Schemas.visit(recSchema, cv);    Assert.assertNull(trimmed.getDoc());    Assert.assertNotNull(recSchema.getDoc());    SchemaCompatibility.SchemaCompatibilityType compat = SchemaCompatibility.checkReaderWriterCompatibility(trimmed, recSchema).getType();    Assert.assertEquals(SchemaCompatibility.SchemaCompatibilityType.COMPATIBLE, compat);    compat = SchemaCompatibility.checkReaderWriterCompatibility(recSchema, trimmed).getType();    Assert.assertEquals(SchemaCompatibility.SchemaCompatibilityType.COMPATIBLE, compat);    Assert.assertNotNull(cv.toString());}
0
public void textCloningCopyDocs()
{    Schema recSchema = new Schema.Parser().parse(SCHEMA);    Schemas.visit(recSchema, new PrintingVisitor());    Schema trimmed = Schemas.visit(recSchema, new CloningVisitor(new CloningVisitor.PropertyCopier() {        @Override        public void copy(final Schema first, final Schema second) {            Schemas.copyLogicalTypes(first, second);            Schemas.copyAliases(first, second);        }        @Override        public void copy(final Schema.Field first, final Schema.Field second) {            Schemas.copyAliases(first, second);        }    }, true, recSchema));    Assert.assertEquals("caca", trimmed.getDoc());    Assert.assertNotNull(recSchema.getDoc());    SchemaCompatibility.SchemaCompatibilityType compat = SchemaCompatibility.checkReaderWriterCompatibility(trimmed, recSchema).getType();    Assert.assertEquals(SchemaCompatibility.SchemaCompatibilityType.COMPATIBLE, compat);    compat = SchemaCompatibility.checkReaderWriterCompatibility(recSchema, trimmed).getType();    Assert.assertEquals(SchemaCompatibility.SchemaCompatibilityType.COMPATIBLE, compat);}
0
public void copy(final Schema first, final Schema second)
{    Schemas.copyLogicalTypes(first, second);    Schemas.copyAliases(first, second);}
0
public void copy(final Schema.Field first, final Schema.Field second)
{    Schemas.copyAliases(first, second);}
0
public void testCloningError1()
{        Schema recordSchema = new Schema.Parser().parse("{\"type\": \"record\", \"name\": \"R\", \"fields\":[{\"name\": \"f1\", \"type\": [\"int\", \"long\"]}]}");    new CloningVisitor(recordSchema).visitTerminal(recordSchema.getField("f1").schema());}
0
public void testCloningError2()
{        Schema recordSchema = new Schema.Parser().parse("{\"type\": \"record\", \"name\": \"R\", \"fields\":[{\"name\": \"f1\", \"type\": \"int\"}]}");    new CloningVisitor(recordSchema).afterVisitNonTerminal(recordSchema.getField("f1").schema());}
0
public void testHasGeneratedJavaClass()
{    Assert.assertTrue(Schemas.hasGeneratedJavaClass(new Schema.Parser().parse("{\"type\": \"fixed\", \"name\": \"N\", \"size\": 10}")));    Assert.assertFalse(Schemas.hasGeneratedJavaClass(new Schema.Parser().parse("{\"type\": \"int\"}")));}
0
public void testGetJavaClassName()
{    Assert.assertEquals("N", Schemas.getJavaClassName(new Schema.Parser().parse("{\"type\": \"fixed\", \"name\": \"N\", \"size\": 10}")));    Assert.assertEquals("N", Schemas.getJavaClassName(new Schema.Parser().parse("{\"type\": \"fixed\", \"name\": \"N\", \"size\": 10, \"namespace\": \"\"}")));    Assert.assertEquals("com.example.N", Schemas.getJavaClassName(new Schema.Parser().parse("{\"type\": \"fixed\", \"name\": \"N\", \"size\": 10, \"namespace\": \"com.example\"}")));}
0
public SchemaVisitorAction visitTerminal(Schema terminal)
{    sb.append(terminal);    return SchemaVisitorAction.CONTINUE;}
0
public SchemaVisitorAction visitNonTerminal(Schema nonTerminal)
{    String n = nonTerminal.getName();    sb.append(n).append('.');    if (n.startsWith("t")) {        return SchemaVisitorAction.TERMINATE;    } else if (n.startsWith("ss")) {        return SchemaVisitorAction.SKIP_SIBLINGS;    } else if (n.startsWith("st")) {        return SchemaVisitorAction.SKIP_SUBTREE;    } else {        return SchemaVisitorAction.CONTINUE;    }}
0
public SchemaVisitorAction afterVisitNonTerminal(Schema nonTerminal)
{    sb.append("!");    String n = nonTerminal.getName();    if (n.startsWith("ct")) {        return SchemaVisitorAction.TERMINATE;    } else if (n.startsWith("css")) {        return SchemaVisitorAction.SKIP_SIBLINGS;    } else if (n.startsWith("cst")) {        return SchemaVisitorAction.SKIP_SUBTREE;    } else {        return SchemaVisitorAction.CONTINUE;    }}
0
public String get()
{    return sb.toString();}
0
public void testVisit1()
{    String s1 = "{\"type\": \"record\", \"name\": \"t1\", \"fields\": [" + "{\"name\": \"f1\", \"type\": \"int\"}" + "]}";    Assert.assertEquals("t1.", Schemas.visit(new Schema.Parser().parse(s1), new TestVisitor()));}
0
public void testVisit2()
{    String s2 = "{\"type\": \"record\", \"name\": \"c1\", \"fields\": [" + "{\"name\": \"f1\", \"type\": \"int\"}" + "]}";    Assert.assertEquals("c1.\"int\"!", Schemas.visit(new Schema.Parser().parse(s2), new TestVisitor()));}
0
public void testVisit3()
{    String s3 = "{\"type\": \"record\", \"name\": \"ss1\", \"fields\": [" + "{\"name\": \"f1\", \"type\": \"int\"}" + "]}";    Assert.assertEquals("ss1.", Schemas.visit(new Schema.Parser().parse(s3), new TestVisitor()));}
0
public void testVisit4()
{    String s4 = "{\"type\": \"record\", \"name\": \"st1\", \"fields\": [" + "{\"name\": \"f1\", \"type\": \"int\"}" + "]}";    Assert.assertEquals("st1.!", Schemas.visit(new Schema.Parser().parse(s4), new TestVisitor()));}
0
public void testVisit5()
{    String s5 = "{\"type\": \"record\", \"name\": \"c1\", \"fields\": [" + "{\"name\": \"f1\", \"type\": {\"type\": \"record\", \"name\": \"c2\", \"fields\": " + "[{\"name\": \"f11\", \"type\": \"int\"}]}}," + "{\"name\": \"f2\", \"type\": \"long\"}" + "]}";    Assert.assertEquals("c1.c2.\"int\"!\"long\"!", Schemas.visit(new Schema.Parser().parse(s5), new TestVisitor()));}
0
public void testVisit6()
{    String s6 = "{\"type\": \"record\", \"name\": \"c1\", \"fields\": [" + "{\"name\": \"f1\", \"type\": {\"type\": \"record\", \"name\": \"ss2\", \"fields\": " + "[{\"name\": \"f11\", \"type\": \"int\"}]}}," + "{\"name\": \"f2\", \"type\": \"long\"}" + "]}";    Assert.assertEquals("c1.ss2.!", Schemas.visit(new Schema.Parser().parse(s6), new TestVisitor()));}
0
public void testVisit7()
{    String s7 = "{\"type\": \"record\", \"name\": \"c1\", \"fields\": [" + "{\"name\": \"f1\", \"type\": {\"type\": \"record\", \"name\": \"css2\", \"fields\": " + "[{\"name\": \"f11\", \"type\": \"int\"}]}}," + "{\"name\": \"f2\", \"type\": \"long\"}" + "]}";    Assert.assertEquals("c1.css2.\"int\"!!", Schemas.visit(new Schema.Parser().parse(s7), new TestVisitor()));}
0
public void testVisit8()
{    String s8 = "{\"type\": \"record\", \"name\": \"c1\", \"fields\": [" + "{\"name\": \"f1\", \"type\": {\"type\": \"record\", \"name\": \"cst2\", \"fields\": " + "[{\"name\": \"f11\", \"type\": \"int\"}]}}," + "{\"name\": \"f2\", \"type\": \"int\"}" + "]}";    Schemas.visit(new Schema.Parser().parse(s8), new TestVisitor());}
0
public void testVisit9()
{    String s9 = "{\"type\": \"record\", \"name\": \"c1\", \"fields\": [" + "{\"name\": \"f1\", \"type\": {\"type\": \"record\", \"name\": \"ct2\", \"fields\": " + "[{\"name\": \"f11\", \"type\": \"int\"}]}}," + "{\"name\": \"f2\", \"type\": \"long\"}" + "]}";    Assert.assertEquals("c1.ct2.\"int\"!", Schemas.visit(new Schema.Parser().parse(s9), new TestVisitor()));}
0
public void testVisit10()
{    String s10 = "{\"type\": \"record\", \"name\": \"c1\", \"fields\": [" + "{\"name\": \"f1\", \"type\": {\"type\": \"record\", \"name\": \"ct2\", \"fields\": " + "[{\"name\": \"f11\", \"type\": \"int\"}]}}," + "{\"name\": \"f2\", \"type\": \"int\"}" + "]}";    Schemas.visit(new Schema.Parser().parse(s10), new TestVisitor() {        public SchemaVisitorAction visitTerminal(Schema terminal) {            return SchemaVisitorAction.SKIP_SUBTREE;        }    });}
0
public SchemaVisitorAction visitTerminal(Schema terminal)
{    return SchemaVisitorAction.SKIP_SUBTREE;}
0
public void testVisit11()
{    String s11 = "{\"type\": \"record\", \"name\": \"c1\", \"fields\": [" + "{\"name\": \"f1\", \"type\": {\"type\": \"record\", \"name\": \"c2\", \"fields\": " + "[{\"name\": \"f11\", \"type\": \"int\"},{\"name\": \"f12\", \"type\": \"double\"}" + "]}}," + "{\"name\": \"f2\", \"type\": \"long\"}" + "]}";    Assert.assertEquals("c1.c2.\"int\".!\"long\".!", Schemas.visit(new Schema.Parser().parse(s11), new TestVisitor() {        public SchemaVisitorAction visitTerminal(Schema terminal) {            sb.append(terminal).append('.');            return SchemaVisitorAction.SKIP_SIBLINGS;        }    }));}
0
public SchemaVisitorAction visitTerminal(Schema terminal)
{    sb.append(terminal).append('.');    return SchemaVisitorAction.SKIP_SIBLINGS;}
0
public void testVisit12()
{    String s12 = "{\"type\": \"record\", \"name\": \"c1\", \"fields\": [" + "{\"name\": \"f1\", \"type\": {\"type\": \"record\", \"name\": \"ct2\", \"fields\": " + "[{\"name\": \"f11\", \"type\": \"int\"}]}}," + "{\"name\": \"f2\", \"type\": \"long\"}" + "]}";    Assert.assertEquals("c1.ct2.\"int\".", Schemas.visit(new Schema.Parser().parse(s12), new TestVisitor() {        public SchemaVisitorAction visitTerminal(Schema terminal) {            sb.append(terminal).append('.');            return SchemaVisitorAction.TERMINATE;        }    }));}
0
public SchemaVisitorAction visitTerminal(Schema terminal)
{    sb.append(terminal).append('.');    return SchemaVisitorAction.TERMINATE;}
0
public void testVisit13()
{    String s12 = "{\"type\": \"int\"}";    Assert.assertEquals("\"int\".", Schemas.visit(new Schema.Parser().parse(s12), new TestVisitor() {        public SchemaVisitorAction visitTerminal(Schema terminal) {            sb.append(terminal).append('.');            return SchemaVisitorAction.SKIP_SIBLINGS;        }    }));}
0
public SchemaVisitorAction visitTerminal(Schema terminal)
{    sb.append(terminal).append('.');    return SchemaVisitorAction.SKIP_SIBLINGS;}
0
public void setUp()
{    this.outputFile = new File(this.OUTPUT_DIR.getRoot(), "SimpleRecord.java");}
0
 static void assertCompilesWithJavaCompiler(File dstDir, Collection<SpecificCompiler.OutputFile> outputs) throws IOException
{    assertCompilesWithJavaCompiler(dstDir, outputs, false);}
0
 static void assertCompilesWithJavaCompiler(File dstDir, Collection<SpecificCompiler.OutputFile> outputs, boolean ignoreWarnings) throws IOException
{    if (outputs.isEmpty()) {                return;    }    JavaCompiler compiler = ToolProvider.getSystemJavaCompiler();    StandardJavaFileManager fileManager = compiler.getStandardFileManager(null, null, null);    List<File> javaFiles = new ArrayList<>();    for (SpecificCompiler.OutputFile o : outputs) {        javaFiles.add(o.writeToDestination(null, dstDir));    }    final List<Diagnostic<?>> warnings = new ArrayList<>();    DiagnosticListener<JavaFileObject> diagnosticListener = diagnostic -> {        switch(diagnostic.getKind()) {            case ERROR:                                                break;            case WARNING:            case MANDATORY_WARNING:                                warnings.add(diagnostic);                break;            case NOTE:            case OTHER:                                break;        }    };    JavaCompiler.CompilationTask cTask = compiler.getTask(null, fileManager, diagnosticListener, Collections.singletonList("-Xlint:all"), null, fileManager.getJavaFileObjects(javaFiles.toArray(new File[0])));    boolean compilesWithoutError = cTask.call();    assertTrue(compilesWithoutError);    if (!ignoreWarnings) {        assertEquals("Warnings produced when compiling generated code with -Xlint:all", 0, warnings.size());    }}
1
private static Schema createSampleRecordSchema(int numStringFields, int numDoubleFields)
{    SchemaBuilder.FieldAssembler<Schema> sb = SchemaBuilder.record("sample.record").fields();    for (int i = 0; i < numStringFields; i++) {        sb.name("sf_" + i).type().stringType().noDefault();    }    for (int i = 0; i < numDoubleFields; i++) {        sb.name("df_" + i).type().doubleType().noDefault();    }    return sb.endRecord();}
0
private SpecificCompiler createCompiler() throws IOException
{    Schema.Parser parser = new Schema.Parser();    Schema schema = parser.parse(this.src);    SpecificCompiler compiler = new SpecificCompiler(schema);    String velocityTemplateDir = "src/main/velocity/org/apache/avro/compiler/specific/templates/java/classic/";    compiler.setTemplateDir(velocityTemplateDir);    compiler.setStringType(StringType.CharSequence);    return compiler;}
0
public void testCanReadTemplateFilesOnTheFilesystem() throws IOException
{    SpecificCompiler compiler = createCompiler();    compiler.compileToDestination(this.src, OUTPUT_DIR.getRoot());    assertTrue(new File(OUTPUT_DIR.getRoot(), "SimpleRecord.java").exists());}
0
public void testPublicFieldVisibility() throws IOException
{    SpecificCompiler compiler = createCompiler();    compiler.setFieldVisibility(SpecificCompiler.FieldVisibility.PUBLIC);    assertFalse(compiler.deprecatedFields());    assertTrue(compiler.publicFields());    assertFalse(compiler.privateFields());    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());    assertTrue(this.outputFile.exists());    try (BufferedReader reader = new BufferedReader(new FileReader(this.outputFile))) {        String line;        while ((line = reader.readLine()) != null) {                                                line = line.trim();            assertFalse("Line started with a deprecated field declaration: " + line, line.startsWith("@Deprecated public int value"));        }    }}
0
public void testCreateAllArgsConstructor() throws Exception
{    SpecificCompiler compiler = createCompiler();    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());    assertTrue(this.outputFile.exists());    boolean foundAllArgsConstructor = false;    try (BufferedReader reader = new BufferedReader(new FileReader(this.outputFile))) {        String line;        while (!foundAllArgsConstructor && (line = reader.readLine()) != null) {            foundAllArgsConstructor = line.contains("All-args constructor");        }    }    assertTrue(foundAllArgsConstructor);}
0
public void testMaxValidParameterCounts() throws Exception
{    Schema validSchema1 = createSampleRecordSchema(SpecificCompiler.MAX_FIELD_PARAMETER_UNIT_COUNT, 0);    assertCompilesWithJavaCompiler(new File(OUTPUT_DIR.getRoot(), name.getMethodName() + "1"), new SpecificCompiler(validSchema1).compile());    Schema validSchema2 = createSampleRecordSchema(SpecificCompiler.MAX_FIELD_PARAMETER_UNIT_COUNT - 2, 1);    assertCompilesWithJavaCompiler(new File(OUTPUT_DIR.getRoot(), name.getMethodName() + "2"), new SpecificCompiler(validSchema1).compile());}
0
public void testInvalidParameterCounts() throws Exception
{    Schema invalidSchema1 = createSampleRecordSchema(SpecificCompiler.MAX_FIELD_PARAMETER_UNIT_COUNT + 1, 0);    SpecificCompiler compiler = new SpecificCompiler(invalidSchema1);    assertCompilesWithJavaCompiler(new File(OUTPUT_DIR.getRoot(), name.getMethodName() + "1"), compiler.compile());    Schema invalidSchema2 = createSampleRecordSchema(SpecificCompiler.MAX_FIELD_PARAMETER_UNIT_COUNT, 10);    compiler = new SpecificCompiler(invalidSchema2);    assertCompilesWithJavaCompiler(new File(OUTPUT_DIR.getRoot(), name.getMethodName() + "2"), compiler.compile());}
0
public void testMaxParameterCounts() throws Exception
{    Schema validSchema1 = createSampleRecordSchema(SpecificCompiler.MAX_FIELD_PARAMETER_UNIT_COUNT, 0);    assertTrue(new SpecificCompiler(validSchema1).compile().size() > 0);    Schema validSchema2 = createSampleRecordSchema(SpecificCompiler.MAX_FIELD_PARAMETER_UNIT_COUNT - 2, 1);    assertTrue(new SpecificCompiler(validSchema2).compile().size() > 0);    Schema validSchema3 = createSampleRecordSchema(SpecificCompiler.MAX_FIELD_PARAMETER_UNIT_COUNT - 1, 1);    assertTrue(new SpecificCompiler(validSchema3).compile().size() > 0);    Schema validSchema4 = createSampleRecordSchema(SpecificCompiler.MAX_FIELD_PARAMETER_UNIT_COUNT + 1, 0);    assertTrue(new SpecificCompiler(validSchema4).compile().size() > 0);}
0
public void testCalcAllArgConstructorParameterUnitsFailure()
{    Schema nonRecordSchema = SchemaBuilder.array().items().booleanType();    new SpecificCompiler().calcAllArgConstructorParameterUnits(nonRecordSchema);}
0
public void testPublicDeprecatedFieldVisibility() throws IOException
{    SpecificCompiler compiler = createCompiler();    compiler.setFieldVisibility(SpecificCompiler.FieldVisibility.PUBLIC_DEPRECATED);    assertTrue(compiler.deprecatedFields());    assertTrue(compiler.publicFields());    assertFalse(compiler.privateFields());    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());    assertTrue(this.outputFile.exists());    try (BufferedReader reader = new BufferedReader(new FileReader(this.outputFile))) {        String line;        while ((line = reader.readLine()) != null) {                        line = line.trim();            assertFalse("Line started with a public field declaration: " + line, line.startsWith("public int value"));        }    }}
0
public void testPrivateFieldVisibility() throws IOException
{    SpecificCompiler compiler = createCompiler();    compiler.setFieldVisibility(SpecificCompiler.FieldVisibility.PRIVATE);    assertFalse(compiler.deprecatedFields());    assertFalse(compiler.publicFields());    assertTrue(compiler.privateFields());    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());    assertTrue(this.outputFile.exists());    try (BufferedReader reader = new BufferedReader(new FileReader(this.outputFile))) {        String line = null;        while ((line = reader.readLine()) != null) {                                    line = line.trim();            assertFalse("Line started with a public field declaration: " + line, line.startsWith("public int value"));            assertFalse("Line started with a deprecated field declaration: " + line, line.startsWith("@Deprecated public int value"));        }    }}
0
public void testSettersCreatedByDefault() throws IOException
{    SpecificCompiler compiler = createCompiler();    assertTrue(compiler.isCreateSetters());    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());    assertTrue(this.outputFile.exists());    int foundSetters = 0;    try (BufferedReader reader = new BufferedReader(new FileReader(this.outputFile))) {        String line;        while ((line = reader.readLine()) != null) {                        line = line.trim();            if (line.startsWith("public void setValue(")) {                foundSetters++;            }        }    }    assertEquals("Found the wrong number of setters", 1, foundSetters);}
0
public void testSettersNotCreatedWhenOptionTurnedOff() throws IOException
{    SpecificCompiler compiler = createCompiler();    compiler.setCreateSetters(false);    assertFalse(compiler.isCreateSetters());    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());    assertTrue(this.outputFile.exists());    try (BufferedReader reader = new BufferedReader(new FileReader(this.outputFile))) {        String line;        while ((line = reader.readLine()) != null) {                        line = line.trim();            assertFalse("No line should include the setter: " + line, line.startsWith("public void setValue("));        }    }}
0
public void testSettingOutputCharacterEncoding() throws Exception
{    SpecificCompiler compiler = createCompiler();        compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());    byte[] fileInDefaultEncoding = new byte[(int) this.outputFile.length()];    FileInputStream is = new FileInputStream(this.outputFile);    is.read(fileInDefaultEncoding);        is.close();    if (!this.outputFile.delete()) {                throw new IllegalStateException("unable to delete " + this.outputFile);            }            String differentEncoding = Charset.defaultCharset().equals(Charset.forName("UTF-16")) ? "UTF-32" : "UTF-16";    compiler.setOutputCharacterEncoding(differentEncoding);    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());    byte[] fileInDifferentEncoding = new byte[(int) this.outputFile.length()];    is = new FileInputStream(this.outputFile);    is.read(fileInDifferentEncoding);    is.close();        assertThat("Generated file should contain different bytes after setting non-default encoding", fileInDefaultEncoding, not(equalTo(fileInDifferentEncoding)));        assertThat("Generated files should contain the same characters in the proper encodings", new String(fileInDefaultEncoding), equalTo(new String(fileInDifferentEncoding, differentEncoding)));}
0
public void testJavaTypeWithDecimalLogicalTypeEnabled() throws Exception
{    SpecificCompiler compiler = createCompiler();    compiler.setEnableDecimalLogicalType(true);    Schema dateSchema = LogicalTypes.date().addToSchema(Schema.create(Schema.Type.INT));    Schema timeSchema = LogicalTypes.timeMillis().addToSchema(Schema.create(Schema.Type.INT));    Schema timestampSchema = LogicalTypes.timestampMillis().addToSchema(Schema.create(Schema.Type.LONG));    Schema decimalSchema = LogicalTypes.decimal(9, 2).addToSchema(Schema.create(Schema.Type.BYTES));    Schema uuidSchema = LogicalTypes.uuid().addToSchema(Schema.create(Schema.Type.STRING));                    Assert.assertEquals("Should use LocalDate for date type", "java.time.LocalDate", compiler.javaType(dateSchema));    Assert.assertEquals("Should use LocalTime for time-millis type", "java.time.LocalTime", compiler.javaType(timeSchema));    Assert.assertEquals("Should use DateTime for timestamp-millis type", "java.time.Instant", compiler.javaType(timestampSchema));    Assert.assertEquals("Should use Java BigDecimal type", "java.math.BigDecimal", compiler.javaType(decimalSchema));    Assert.assertEquals("Should use Java CharSequence type", "java.lang.CharSequence", compiler.javaType(uuidSchema));}
0
public void testJavaTypeWithDecimalLogicalTypeDisabled() throws Exception
{    SpecificCompiler compiler = createCompiler();    compiler.setEnableDecimalLogicalType(false);    Schema dateSchema = LogicalTypes.date().addToSchema(Schema.create(Schema.Type.INT));    Schema timeSchema = LogicalTypes.timeMillis().addToSchema(Schema.create(Schema.Type.INT));    Schema timestampSchema = LogicalTypes.timestampMillis().addToSchema(Schema.create(Schema.Type.LONG));    Schema decimalSchema = LogicalTypes.decimal(9, 2).addToSchema(Schema.create(Schema.Type.BYTES));    Schema uuidSchema = LogicalTypes.uuid().addToSchema(Schema.create(Schema.Type.STRING));                    Assert.assertEquals("Should use LocalDate for date type", "java.time.LocalDate", compiler.javaType(dateSchema));    Assert.assertEquals("Should use LocalTime for time-millis type", "java.time.LocalTime", compiler.javaType(timeSchema));    Assert.assertEquals("Should use DateTime for timestamp-millis type", "java.time.Instant", compiler.javaType(timestampSchema));    Assert.assertEquals("Should use ByteBuffer type", "java.nio.ByteBuffer", compiler.javaType(decimalSchema));    Assert.assertEquals("Should use Java CharSequence type", "java.lang.CharSequence", compiler.javaType(uuidSchema));}
0
public void testJavaTypeWithDateTimeTypes() throws Exception
{    SpecificCompiler compiler = createCompiler();    Schema dateSchema = LogicalTypes.date().addToSchema(Schema.create(Schema.Type.INT));    Schema timeSchema = LogicalTypes.timeMillis().addToSchema(Schema.create(Schema.Type.INT));    Schema timeMicrosSchema = LogicalTypes.timeMicros().addToSchema(Schema.create(Schema.Type.LONG));    Schema timestampSchema = LogicalTypes.timestampMillis().addToSchema(Schema.create(Schema.Type.LONG));    Schema timestampMicrosSchema = LogicalTypes.timestampMicros().addToSchema(Schema.create(Schema.Type.LONG));        Assert.assertEquals("Should use java.time.LocalDate for date type", "java.time.LocalDate", compiler.javaType(dateSchema));    Assert.assertEquals("Should use java.time.LocalTime for time-millis type", "java.time.LocalTime", compiler.javaType(timeSchema));    Assert.assertEquals("Should use java.time.Instant for timestamp-millis type", "java.time.Instant", compiler.javaType(timestampSchema));    Assert.assertEquals("Should use java.time.LocalTime for time-micros type", "java.time.LocalTime", compiler.javaType(timeMicrosSchema));    Assert.assertEquals("Should use java.time.Instant for timestamp-micros type", "java.time.Instant", compiler.javaType(timestampMicrosSchema));}
0
public void testJavaUnbox() throws Exception
{    SpecificCompiler compiler = createCompiler();    compiler.setEnableDecimalLogicalType(false);    Schema intSchema = Schema.create(Schema.Type.INT);    Schema longSchema = Schema.create(Schema.Type.LONG);    Schema floatSchema = Schema.create(Schema.Type.FLOAT);    Schema doubleSchema = Schema.create(Schema.Type.DOUBLE);    Schema boolSchema = Schema.create(Schema.Type.BOOLEAN);    Assert.assertEquals("Should use int for Type.INT", "int", compiler.javaUnbox(intSchema));    Assert.assertEquals("Should use long for Type.LONG", "long", compiler.javaUnbox(longSchema));    Assert.assertEquals("Should use float for Type.FLOAT", "float", compiler.javaUnbox(floatSchema));    Assert.assertEquals("Should use double for Type.DOUBLE", "double", compiler.javaUnbox(doubleSchema));    Assert.assertEquals("Should use boolean for Type.BOOLEAN", "boolean", compiler.javaUnbox(boolSchema));    Schema dateSchema = LogicalTypes.date().addToSchema(Schema.create(Schema.Type.INT));    Schema timeSchema = LogicalTypes.timeMillis().addToSchema(Schema.create(Schema.Type.INT));    Schema timestampSchema = LogicalTypes.timestampMillis().addToSchema(Schema.create(Schema.Type.LONG));            Assert.assertEquals("Should use LocalDate for date type", "java.time.LocalDate", compiler.javaUnbox(dateSchema));    Assert.assertEquals("Should use LocalTime for time-millis type", "java.time.LocalTime", compiler.javaUnbox(timeSchema));    Assert.assertEquals("Should use DateTime for timestamp-millis type", "java.time.Instant", compiler.javaUnbox(timestampSchema));}
0
public void testJavaUnboxDateTime() throws Exception
{    SpecificCompiler compiler = createCompiler();    Schema dateSchema = LogicalTypes.date().addToSchema(Schema.create(Schema.Type.INT));    Schema timeSchema = LogicalTypes.timeMillis().addToSchema(Schema.create(Schema.Type.INT));    Schema timestampSchema = LogicalTypes.timestampMillis().addToSchema(Schema.create(Schema.Type.LONG));            Assert.assertEquals("Should use java.time.LocalDate for date type", "java.time.LocalDate", compiler.javaUnbox(dateSchema));    Assert.assertEquals("Should use java.time.LocalTime for time-millis type", "java.time.LocalTime", compiler.javaUnbox(timeSchema));    Assert.assertEquals("Should use java.time.Instant for timestamp-millis type", "java.time.Instant", compiler.javaUnbox(timestampSchema));}
0
public void testNullableLogicalTypesJavaUnboxDecimalTypesEnabled() throws Exception
{    SpecificCompiler compiler = createCompiler();    compiler.setEnableDecimalLogicalType(true);        Schema nullableDecimalSchema1 = Schema.createUnion(Schema.create(Schema.Type.NULL), LogicalTypes.decimal(9, 2).addToSchema(Schema.create(Schema.Type.BYTES)));    Schema nullableDecimalSchema2 = Schema.createUnion(LogicalTypes.decimal(9, 2).addToSchema(Schema.create(Schema.Type.BYTES)), Schema.create(Schema.Type.NULL));    Assert.assertEquals("Should return boxed type", compiler.javaUnbox(nullableDecimalSchema1), "java.math.BigDecimal");    Assert.assertEquals("Should return boxed type", compiler.javaUnbox(nullableDecimalSchema2), "java.math.BigDecimal");}
0
public void testNullableLogicalTypesJavaUnboxDecimalTypesDisabled() throws Exception
{    SpecificCompiler compiler = createCompiler();    compiler.setEnableDecimalLogicalType(false);        Schema nullableDecimalSchema1 = Schema.createUnion(Schema.create(Schema.Type.NULL), LogicalTypes.decimal(9, 2).addToSchema(Schema.create(Schema.Type.BYTES)));    Schema nullableDecimalSchema2 = Schema.createUnion(LogicalTypes.decimal(9, 2).addToSchema(Schema.create(Schema.Type.BYTES)), Schema.create(Schema.Type.NULL));    Assert.assertEquals("Should return boxed type", compiler.javaUnbox(nullableDecimalSchema1), "java.nio.ByteBuffer");    Assert.assertEquals("Should return boxed type", compiler.javaUnbox(nullableDecimalSchema2), "java.nio.ByteBuffer");}
0
public void testNullableTypesJavaUnbox() throws Exception
{    SpecificCompiler compiler = createCompiler();    compiler.setEnableDecimalLogicalType(false);        Schema nullableIntSchema1 = Schema.createUnion(Schema.create(Schema.Type.NULL), Schema.create(Schema.Type.INT));    Schema nullableIntSchema2 = Schema.createUnion(Schema.create(Schema.Type.INT), Schema.create(Schema.Type.NULL));    Assert.assertEquals("Should return boxed type", compiler.javaUnbox(nullableIntSchema1), "java.lang.Integer");    Assert.assertEquals("Should return boxed type", compiler.javaUnbox(nullableIntSchema2), "java.lang.Integer");    Schema nullableLongSchema1 = Schema.createUnion(Schema.create(Schema.Type.NULL), Schema.create(Schema.Type.LONG));    Schema nullableLongSchema2 = Schema.createUnion(Schema.create(Schema.Type.LONG), Schema.create(Schema.Type.NULL));    Assert.assertEquals("Should return boxed type", compiler.javaUnbox(nullableLongSchema1), "java.lang.Long");    Assert.assertEquals("Should return boxed type", compiler.javaUnbox(nullableLongSchema2), "java.lang.Long");    Schema nullableFloatSchema1 = Schema.createUnion(Schema.create(Schema.Type.NULL), Schema.create(Schema.Type.FLOAT));    Schema nullableFloatSchema2 = Schema.createUnion(Schema.create(Schema.Type.FLOAT), Schema.create(Schema.Type.NULL));    Assert.assertEquals("Should return boxed type", compiler.javaUnbox(nullableFloatSchema1), "java.lang.Float");    Assert.assertEquals("Should return boxed type", compiler.javaUnbox(nullableFloatSchema2), "java.lang.Float");    Schema nullableDoubleSchema1 = Schema.createUnion(Schema.create(Schema.Type.NULL), Schema.create(Schema.Type.DOUBLE));    Schema nullableDoubleSchema2 = Schema.createUnion(Schema.create(Schema.Type.DOUBLE), Schema.create(Schema.Type.NULL));    Assert.assertEquals("Should return boxed type", compiler.javaUnbox(nullableDoubleSchema1), "java.lang.Double");    Assert.assertEquals("Should return boxed type", compiler.javaUnbox(nullableDoubleSchema2), "java.lang.Double");    Schema nullableBooleanSchema1 = Schema.createUnion(Schema.create(Schema.Type.NULL), Schema.create(Schema.Type.BOOLEAN));    Schema nullableBooleanSchema2 = Schema.createUnion(Schema.create(Schema.Type.BOOLEAN), Schema.create(Schema.Type.NULL));    Assert.assertEquals("Should return boxed type", compiler.javaUnbox(nullableBooleanSchema1), "java.lang.Boolean");    Assert.assertEquals("Should return boxed type", compiler.javaUnbox(nullableBooleanSchema2), "java.lang.Boolean");}
0
public void testGetUsedConversionClassesForNullableLogicalTypes() throws Exception
{    SpecificCompiler compiler = createCompiler();    compiler.setEnableDecimalLogicalType(true);    Schema nullableDecimal1 = Schema.createUnion(Schema.create(Schema.Type.NULL), LogicalTypes.decimal(9, 2).addToSchema(Schema.create(Schema.Type.BYTES)));    Schema schemaWithNullableDecimal1 = Schema.createRecord("WithNullableDecimal", "", "", false, Collections.singletonList(new Schema.Field("decimal", nullableDecimal1, "", null)));    final Collection<String> usedConversionClasses = compiler.getUsedConversionClasses(schemaWithNullableDecimal1);    Assert.assertEquals(1, usedConversionClasses.size());    Assert.assertEquals("org.apache.avro.Conversions.DecimalConversion", usedConversionClasses.iterator().next());}
0
public void testGetUsedConversionClassesForNullableLogicalTypesInNestedRecord() throws Exception
{    SpecificCompiler compiler = createCompiler();    final Schema schema = new Schema.Parser().parse("{\"type\":\"record\",\"name\":\"NestedLogicalTypesRecord\",\"namespace\":\"org.apache.avro.codegentest.testdata\",\"doc\":\"Test nested types with logical types in generated Java classes\",\"fields\":[{\"name\":\"nestedRecord\",\"type\":{\"type\":\"record\",\"name\":\"NestedRecord\",\"fields\":[{\"name\":\"nullableDateField\",\"type\":[\"null\",{\"type\":\"int\",\"logicalType\":\"date\"}]}]}}]}");    final Collection<String> usedConversionClasses = compiler.getUsedConversionClasses(schema);    Assert.assertEquals(1, usedConversionClasses.size());    Assert.assertEquals("org.apache.avro.data.TimeConversions.DateConversion", usedConversionClasses.iterator().next());}
0
public void testGetUsedConversionClassesForNullableLogicalTypesInArray() throws Exception
{    SpecificCompiler compiler = createCompiler();    final Schema schema = new Schema.Parser().parse("{\"type\":\"record\",\"name\":\"NullableLogicalTypesArray\",\"namespace\":\"org.apache.avro.codegentest.testdata\",\"doc\":\"Test nested types with logical types in generated Java classes\",\"fields\":[{\"name\":\"arrayOfLogicalType\",\"type\":{\"type\":\"array\",\"items\":[\"null\",{\"type\":\"int\",\"logicalType\":\"date\"}]}}]}");    final Collection<String> usedConversionClasses = compiler.getUsedConversionClasses(schema);    Assert.assertEquals(1, usedConversionClasses.size());    Assert.assertEquals("org.apache.avro.data.TimeConversions.DateConversion", usedConversionClasses.iterator().next());}
0
public void testGetUsedConversionClassesForNullableLogicalTypesInArrayOfRecords() throws Exception
{    SpecificCompiler compiler = createCompiler();    final Schema schema = new Schema.Parser().parse("{\"type\":\"record\",\"name\":\"NestedLogicalTypesArray\",\"namespace\":\"org.apache.avro.codegentest.testdata\",\"doc\":\"Test nested types with logical types in generated Java classes\",\"fields\":[{\"name\":\"arrayOfRecords\",\"type\":{\"type\":\"array\",\"items\":{\"type\":\"record\",\"name\":\"RecordInArray\",\"fields\":[{\"name\":\"nullableDateField\",\"type\":[\"null\",{\"type\":\"int\",\"logicalType\":\"date\"}]}]}}}]}");    final Collection<String> usedConversionClasses = compiler.getUsedConversionClasses(schema);    Assert.assertEquals(1, usedConversionClasses.size());    Assert.assertEquals("org.apache.avro.data.TimeConversions.DateConversion", usedConversionClasses.iterator().next());}
0
public void testGetUsedConversionClassesForNullableLogicalTypesInUnionOfRecords() throws Exception
{    SpecificCompiler compiler = createCompiler();    final Schema schema = new Schema.Parser().parse("{\"type\":\"record\",\"name\":\"NestedLogicalTypesUnion\",\"namespace\":\"org.apache.avro.codegentest.testdata\",\"doc\":\"Test nested types with logical types in generated Java classes\",\"fields\":[{\"name\":\"unionOfRecords\",\"type\":[\"null\",{\"type\":\"record\",\"name\":\"RecordInUnion\",\"fields\":[{\"name\":\"nullableDateField\",\"type\":[\"null\",{\"type\":\"int\",\"logicalType\":\"date\"}]}]}]}]}");    final Collection<String> usedConversionClasses = compiler.getUsedConversionClasses(schema);    Assert.assertEquals(1, usedConversionClasses.size());    Assert.assertEquals("org.apache.avro.data.TimeConversions.DateConversion", usedConversionClasses.iterator().next());}
0
public void testGetUsedConversionClassesForNullableLogicalTypesInMapOfRecords() throws Exception
{    SpecificCompiler compiler = createCompiler();    final Schema schema = new Schema.Parser().parse("{\"type\":\"record\",\"name\":\"NestedLogicalTypesMap\",\"namespace\":\"org.apache.avro.codegentest.testdata\",\"doc\":\"Test nested types with logical types in generated Java classes\",\"fields\":[{\"name\":\"mapOfRecords\",\"type\":{\"type\":\"map\",\"values\":{\"type\":\"record\",\"name\":\"RecordInMap\",\"fields\":[{\"name\":\"nullableDateField\",\"type\":[\"null\",{\"type\":\"int\",\"logicalType\":\"date\"}]}]},\"avro.java.string\":\"String\"}}]}");    final Collection<String> usedConversionClasses = compiler.getUsedConversionClasses(schema);    Assert.assertEquals(1, usedConversionClasses.size());    Assert.assertEquals("org.apache.avro.data.TimeConversions.DateConversion", usedConversionClasses.iterator().next());}
0
public void testLogicalTypesWithMultipleFields() throws Exception
{    Schema logicalTypesWithMultipleFields = new Schema.Parser().parse(new File("src/test/resources/logical_types_with_multiple_fields.avsc"));    assertCompilesWithJavaCompiler(new File(OUTPUT_DIR.getRoot(), name.getMethodName()), new SpecificCompiler(logicalTypesWithMultipleFields).compile(), true);}
0
public void testUnionAndFixedFields() throws Exception
{    Schema unionTypesWithMultipleFields = new Schema.Parser().parse(new File("src/test/resources/union_and_fixed_fields.avsc"));    assertCompilesWithJavaCompiler(new File(this.outputFile, name.getMethodName()), new SpecificCompiler(unionTypesWithMultipleFields).compile());}
0
public void testLogicalTypesWithMultipleFieldsDateTime() throws Exception
{    Schema logicalTypesWithMultipleFields = new Schema.Parser().parse(new File("src/test/resources/logical_types_with_multiple_fields.avsc"));    assertCompilesWithJavaCompiler(new File(this.outputFile, name.getMethodName()), new SpecificCompiler(logicalTypesWithMultipleFields).compile());}
0
public void testConversionInstanceWithDecimalLogicalTypeDisabled() throws Exception
{    final SpecificCompiler compiler = createCompiler();    compiler.setEnableDecimalLogicalType(false);    final Schema dateSchema = LogicalTypes.date().addToSchema(Schema.create(Schema.Type.INT));    final Schema timeSchema = LogicalTypes.timeMillis().addToSchema(Schema.create(Schema.Type.INT));    final Schema timestampSchema = LogicalTypes.timestampMillis().addToSchema(Schema.create(Schema.Type.LONG));    final Schema decimalSchema = LogicalTypes.decimal(9, 2).addToSchema(Schema.create(Schema.Type.BYTES));    final Schema uuidSchema = LogicalTypes.uuid().addToSchema(Schema.create(Schema.Type.STRING));    Assert.assertEquals("Should use date conversion for date type", "new org.apache.avro.data.TimeConversions.DateConversion()", compiler.conversionInstance(dateSchema));    Assert.assertEquals("Should use time conversion for time type", "new org.apache.avro.data.TimeConversions.TimeMillisConversion()", compiler.conversionInstance(timeSchema));    Assert.assertEquals("Should use timestamp conversion for date type", "new org.apache.avro.data.TimeConversions.TimestampMillisConversion()", compiler.conversionInstance(timestampSchema));    Assert.assertEquals("Should use null for decimal if the flag is off", "null", compiler.conversionInstance(decimalSchema));    Assert.assertEquals("Should use null for decimal if the flag is off", "null", compiler.conversionInstance(uuidSchema));}
0
public void testConversionInstanceWithDecimalLogicalTypeEnabled() throws Exception
{    SpecificCompiler compiler = createCompiler();    compiler.setEnableDecimalLogicalType(true);    Schema dateSchema = LogicalTypes.date().addToSchema(Schema.create(Schema.Type.INT));    Schema timeSchema = LogicalTypes.timeMillis().addToSchema(Schema.create(Schema.Type.INT));    Schema timestampSchema = LogicalTypes.timestampMillis().addToSchema(Schema.create(Schema.Type.LONG));    Schema decimalSchema = LogicalTypes.decimal(9, 2).addToSchema(Schema.create(Schema.Type.BYTES));    Schema uuidSchema = LogicalTypes.uuid().addToSchema(Schema.create(Schema.Type.STRING));    Assert.assertEquals("Should use date conversion for date type", "new org.apache.avro.data.TimeConversions.DateConversion()", compiler.conversionInstance(dateSchema));    Assert.assertEquals("Should use time conversion for time type", "new org.apache.avro.data.TimeConversions.TimeMillisConversion()", compiler.conversionInstance(timeSchema));    Assert.assertEquals("Should use timestamp conversion for date type", "new org.apache.avro.data.TimeConversions.TimestampMillisConversion()", compiler.conversionInstance(timestampSchema));    Assert.assertEquals("Should use null for decimal if the flag is off", "new org.apache.avro.Conversions.DecimalConversion()", compiler.conversionInstance(decimalSchema));    Assert.assertEquals("Should use null for decimal if the flag is off", "null", compiler.conversionInstance(uuidSchema));}
0
public void testPojoWithOptionalTurnedOffByDefault() throws IOException
{    SpecificCompiler compiler = createCompiler();    compiler.compileToDestination(this.src, OUTPUT_DIR.getRoot());    assertTrue(this.outputFile.exists());    try (BufferedReader reader = new BufferedReader(new FileReader(this.outputFile))) {        String line;        while ((line = reader.readLine()) != null) {            line = line.trim();            assertFalse(line.contains("Optional"));        }    }}
0
public void testPojoWithOptionalCreatedWhenOptionTurnedOn() throws IOException
{    SpecificCompiler compiler = createCompiler();    compiler.setGettersReturnOptional(true);        compiler.compileToDestination(this.src, OUTPUT_DIR.getRoot());    assertTrue(this.outputFile.exists());    int optionalFound = 0;    try (BufferedReader reader = new BufferedReader(new FileReader(this.outputFile))) {        String line;        while ((line = reader.readLine()) != null) {            line = line.trim();            if (line.contains("Optional")) {                optionalFound++;            }        }    }    assertEquals(9, optionalFound);}
0
public void testPojoWithOptionalCreatedWhenOptionalForEverythingTurnedOn() throws IOException
{    SpecificCompiler compiler = createCompiler();        compiler.setCreateOptionalGetters(true);    compiler.compileToDestination(this.src, OUTPUT_DIR.getRoot());    assertTrue(this.outputFile.exists());    int optionalFound = 0;    try (BufferedReader reader = new BufferedReader(new FileReader(this.outputFile))) {        String line;        while ((line = reader.readLine()) != null) {            line = line.trim();            if (line.contains("Optional")) {                optionalFound++;            }        }    }    assertEquals(17, optionalFound);}
0
public void testAdditionalToolsAreInjectedIntoTemplate() throws Exception
{    SpecificCompiler compiler = createCompiler();    List<Object> customTools = new ArrayList<>();    customTools.add(new String());    compiler.setAdditionalVelocityTools(customTools);    compiler.setTemplateDir("src/test/resources/templates_with_custom_tools/");    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());    assertTrue(this.outputFile.exists());    int itWorksFound = 0;    try (BufferedReader reader = new BufferedReader(new FileReader(this.outputFile))) {        String line;        while ((line = reader.readLine()) != null) {            line = line.trim();            if (line.contains("It works!")) {                itWorksFound++;            }        }    }    assertEquals(1, itWorksFound);}
0
public void setUp()
{    MODEL.setCustomCoders(true);}
0
public void withoutSchemaMigration() throws IOException
{    FullRecordV1 src = new FullRecordV1(true, 87231, 731L, 54.2832F, 38.321, "Hi there", null);    Assert.assertTrue("Test schema must allow for custom coders.", ((SpecificRecordBase) src).hasCustomCoders());    ByteArrayOutputStream out = new ByteArrayOutputStream(1024);    Encoder e = EncoderFactory.get().directBinaryEncoder(out, null);    DatumWriter<FullRecordV1> w = (DatumWriter<FullRecordV1>) MODEL.createDatumWriter(V1S);    w.write(src, e);    e.flush();    ByteArrayInputStream in = new ByteArrayInputStream(out.toByteArray());    Decoder d = DecoderFactory.get().directBinaryDecoder(in, null);    DatumReader<FullRecordV1> r = (DatumReader<FullRecordV1>) MODEL.createDatumReader(V1S);    FullRecordV1 dst = r.read(null, d);    Assert.assertEquals(src, dst);}
0
public void withSchemaMigration() throws IOException
{    FullRecordV2 src = new FullRecordV2(true, 731, 87231, 38L, 54.2832F, "Hi there", ByteBuffer.wrap(Utf8.getBytesFor("Hello, world!")));    Assert.assertTrue("Test schema must allow for custom coders.", ((SpecificRecordBase) src).hasCustomCoders());    ByteArrayOutputStream out = new ByteArrayOutputStream(1024);    Encoder e = EncoderFactory.get().directBinaryEncoder(out, null);    DatumWriter<FullRecordV2> w = (DatumWriter<FullRecordV2>) MODEL.createDatumWriter(V2S);    w.write(src, e);    e.flush();    ByteArrayInputStream in = new ByteArrayInputStream(out.toByteArray());    Decoder d = DecoderFactory.get().directBinaryDecoder(in, null);    DatumReader<FullRecordV1> r = (DatumReader<FullRecordV1>) MODEL.createDatumReader(V2S, V1S);    FullRecordV1 dst = r.read(null, d);    FullRecordV1 expected = new FullRecordV1(true, 87231, 731L, 54.2832F, 38.0, null, "Hello, world!");    Assert.assertEquals(expected, dst);}
0
public static T create(Channel channel, Class<T> iface)
{    return create(channel, iface, CallOptions.DEFAULT);}
0
public static T create(Channel channel, Class<T> iface, CallOptions callOptions)
{    Protocol protocol = AvroGrpcUtils.getProtocol(iface);    ServiceDescriptor serviceDescriptor = ServiceDescriptor.create(iface);    ServiceInvocationHandler proxyHandler = new ServiceInvocationHandler(channel, callOptions, protocol, serviceDescriptor);    return (T) Proxy.newProxyInstance(iface.getClassLoader(), new Class[] { iface }, proxyHandler);}
0
public Object invoke(Object proxy, Method method, Object[] args) throws Throwable
{    try {        return invokeUnaryMethod(method, args);    } catch (RuntimeException re) {                throw re;    } catch (Exception e) {                for (Class<?> exceptionClass : method.getExceptionTypes()) {            if (exceptionClass.isInstance(e)) {                throw e;            }        }                throw new AvroRemoteException(e);    }}
0
private Object invokeUnaryMethod(Method method, Object[] args) throws Exception
{    Type[] parameterTypes = method.getParameterTypes();    if ((parameterTypes.length > 0) && (parameterTypes[parameterTypes.length - 1] instanceof Class) && Callback.class.isAssignableFrom(((Class<?>) parameterTypes[parameterTypes.length - 1]))) {                Object[] finalArgs = Arrays.copyOf(args, args.length - 1);        Callback<?> callback = (Callback<?>) args[args.length - 1];        unaryRequest(method.getName(), finalArgs, callback);        return null;    } else {        return unaryRequest(method.getName(), args);    }}
0
private Object unaryRequest(String methodName, Object[] args) throws Exception
{    CallFuture<Object> callFuture = new CallFuture<>();    unaryRequest(methodName, args, callFuture);    try {        return callFuture.get();    } catch (Exception e) {        if (e.getCause() instanceof Exception) {            throw (Exception) e.getCause();        }        throw new AvroRemoteException(e.getCause());    }}
0
private void unaryRequest(String methodName, Object[] args, Callback<RespT> callback) throws Exception
{    StreamObserver<Object> observerAdpater = new CallbackToResponseStreamObserverAdpater<>(callback);    ClientCalls.asyncUnaryCall(channel.newCall(serviceDescriptor.getMethod(methodName, MethodDescriptor.MethodType.UNARY), callOptions), args, observerAdpater);}
0
public void onNext(Object value)
{    if (value instanceof Throwable) {        callback.handleError((Throwable) value);    } else {        callback.handleResult((T) value);    }}
0
public void onError(Throwable t)
{    callback.handleError(new AvroRuntimeException(t));}
0
public void onCompleted()
{}
0
public static ServerServiceDefinition createServiceDefinition(Class iface, Object impl)
{    Protocol protocol = AvroGrpcUtils.getProtocol(iface);    ServiceDescriptor serviceDescriptor = ServiceDescriptor.create(iface);    ServerServiceDefinition.Builder serviceDefinitionBuilder = ServerServiceDefinition.builder(serviceDescriptor.getServiceName());    Map<String, Protocol.Message> messages = protocol.getMessages();    for (Method method : iface.getMethods()) {        Protocol.Message msg = messages.get(method.getName());                if (msg != null) {            UnaryMethodHandler methodHandler = msg.isOneWay() ? new OneWayUnaryMethodHandler(impl, method) : new UnaryMethodHandler(impl, method);            serviceDefinitionBuilder.addMethod(serviceDescriptor.getMethod(method.getName(), MethodDescriptor.MethodType.UNARY), ServerCalls.asyncUnaryCall(methodHandler));        }    }    return serviceDefinitionBuilder.build();}
0
public void invoke(Object[] request, StreamObserver<Object> responseObserver)
{    Object methodResponse = null;    try {        methodResponse = method.invoke(getServiceImpl(), request);    } catch (InvocationTargetException e) {        methodResponse = e.getTargetException();    } catch (Exception e) {        methodResponse = e;    }    responseObserver.onNext(methodResponse);    responseObserver.onCompleted();}
0
public Method getMethod()
{    return method;}
0
public Object getServiceImpl()
{    return serviceImpl;}
0
public void invoke(Object[] request, StreamObserver<Object> responseObserver)
{            responseObserver.onNext(null);    responseObserver.onCompleted();        try {        getMethod().invoke(getServiceImpl(), request);    } catch (Exception e) {        Throwable cause = e;        while (cause.getCause() != null && cause != cause.getCause()) {            cause = cause.getCause();        }        LOG.log(Level.WARNING, "Error processing one-way rpc", cause);    }}
0
public static String getServiceName(Class iface)
{    Protocol protocol = getProtocol(iface);    return protocol.getNamespace() + "." + protocol.getName();}
0
public static Protocol getProtocol(Class iface)
{    try {        Protocol p = (Protocol) (iface.getDeclaredField("PROTOCOL").get(null));        return p;    } catch (NoSuchFieldException e) {        throw new AvroRuntimeException("Not a Specific protocol: " + iface);    } catch (IllegalAccessException e) {        throw new AvroRuntimeException(e);    }}
0
 static void skipAndCloseQuietly(InputStream stream)
{    try {        if (stream instanceof KnownLength && stream.available() > 0) {            stream.skip(stream.available());        } else {                                    byte[] skipBuffer = new byte[4096];            while (true) {                int read = stream.read(skipBuffer);                if (read < skipBuffer.length) {                    break;                }            }        }        stream.close();    } catch (Exception e) {        LOG.log(Level.WARNING, "failed to skip/close the input stream, may cause memory leak", e);    }}
0
public int read(byte[] b, int off, int len) throws IOException
{    return getPartialInternal().read(b, off, len);}
0
public int read() throws IOException
{    return getPartialInternal().read();}
0
private ByteArrayInputStream getPartialInternal() throws IOException
{    if (partial == null) {        ByteArrayOutputStream outputStream = new ByteArrayOutputStream();        drainTo(outputStream);        partial = new ByteArrayInputStream(outputStream.toByteArray());    }    return partial;}
0
protected ByteArrayInputStream getPartial()
{    return partial;}
0
public void write(byte[] b, int off, int len) throws IOException
{    target.write(b, off, len);    writtenCount += len;}
0
public void write(int b) throws IOException
{    target.write(b);    writtenCount += 1;}
0
public void flush() throws IOException
{    target.flush();}
0
public void close() throws IOException
{    target.close();}
0
public int getWrittenCount()
{    return writtenCount;}
0
public InputStream stream(Object[] value)
{    return new AvroRequestInputStream(value, message);}
0
public Object[] parse(InputStream stream)
{    try {        BinaryDecoder in = DECODER_FACTORY.binaryDecoder(stream, null);        Schema reqSchema = message.getRequest();        GenericRecord request = (GenericRecord) new SpecificDatumReader<>(reqSchema).read(null, in);        Object[] args = new Object[reqSchema.getFields().size()];        int i = 0;        for (Schema.Field field : reqSchema.getFields()) {            args[i++] = request.get(field.name());        }        return args;    } catch (IOException e) {        throw Status.INTERNAL.withCause(e).withDescription("Error deserializing avro request arguments").asRuntimeException();    } finally {        AvroGrpcUtils.skipAndCloseQuietly(stream);    }}
0
public int drainTo(OutputStream target) throws IOException
{    int written;    if (getPartial() != null) {        written = (int) ByteStreams.copy(getPartial(), target);    } else {        Schema reqSchema = message.getRequest();        CountingOutputStream outputStream = new CountingOutputStream(target);        BinaryEncoder out = ENCODER_FACTORY.binaryEncoder(outputStream, null);        int i = 0;        for (Schema.Field param : reqSchema.getFields()) {            new SpecificDatumWriter<>(param.schema()).write(args[i++], out);        }        out.flush();        args = null;        written = outputStream.getWrittenCount();    }    return written;}
0
public InputStream stream(Object value)
{    return new AvroResponseInputStream(value, message);}
0
public Object parse(InputStream stream)
{    try {        if (message.isOneWay())            return null;        BinaryDecoder in = DECODER_FACTORY.binaryDecoder(stream, null);        if (!in.readBoolean()) {            Object response = new SpecificDatumReader(message.getResponse()).read(null, in);            return response;        } else {            Object value = new SpecificDatumReader(message.getErrors()).read(null, in);            if (value instanceof Exception) {                return value;            }            return new AvroRuntimeException(value.toString());        }    } catch (IOException e) {        throw Status.INTERNAL.withCause(e).withDescription("Error deserializing avro response").asRuntimeException();    } finally {        AvroGrpcUtils.skipAndCloseQuietly(stream);    }}
0
public int drainTo(OutputStream target) throws IOException
{    int written;    if (getPartial() != null) {        written = (int) ByteStreams.copy(getPartial(), target);    } else {        written = writeResponse(target);    }    return written;}
0
private int writeResponse(OutputStream target) throws IOException
{    int written;    if (message.isOneWay()) {        written = 0;    } else if (response instanceof Exception) {        ByteArrayOutputStream bao = new ByteArrayOutputStream();        BinaryEncoder out = ENCODER_FACTORY.binaryEncoder(bao, null);        try {            out.writeBoolean(true);            new SpecificDatumWriter(message.getErrors()).write(response, out);        } catch (Exception e) {            bao = new ByteArrayOutputStream();            out = ENCODER_FACTORY.binaryEncoder(bao, null);            out.writeBoolean(true);            new SpecificDatumWriter(Protocol.SYSTEM_ERRORS).write(new Utf8(e.toString()), out);        }        out.flush();        byte[] serializedError = bao.toByteArray();        target.write(serializedError);        written = serializedError.length;    } else {        CountingOutputStream outputStream = new CountingOutputStream(target);        BinaryEncoder out = ENCODER_FACTORY.binaryEncoder(outputStream, null);        out.writeBoolean(false);        new SpecificDatumWriter(message.getResponse()).write(response, out);        out.flush();        written = outputStream.getWrittenCount();    }    response = null;    return written;}
0
public static ServiceDescriptor create(Class iface)
{    String serviceName = AvroGrpcUtils.getServiceName(iface);    return SERVICE_DESCRIPTORS.computeIfAbsent(serviceName, key -> new ServiceDescriptor(iface, serviceName));}
0
public String getServiceName()
{    return serviceName;}
0
public MethodDescriptor<Object[], Object> getMethod(String methodName, MethodDescriptor.MethodType methodType)
{    return methods.computeIfAbsent(methodName, key -> MethodDescriptor.<Object[], Object>newBuilder().setFullMethodName(generateFullMethodName(serviceName, methodName)).setType(methodType).setRequestMarshaller(new AvroRequestMarshaller(protocol.getMessages().get(methodName))).setResponseMarshaller(new AvroResponseMarshaller(protocol.getMessages().get(methodName))).build());}
0
private void readPratialAndDrain(int partialToRead, InputStream inputStream, OutputStream target) throws IOException
{        for (int i = 0; i < partialToRead; i++) {        int readByte = inputStream.read();        if (readByte >= 0) {            target.write(readByte);        } else {            break;        }    }    Drainable drainableRequest = (Drainable) inputStream;    drainableRequest.drainTo(target);}
0
public void testAvroRequestReadPartialAndDrain() throws IOException
{    AvroRequestMarshaller requestMarshaller = new AvroRequestMarshaller(message);    InputStream requestInputStream = requestMarshaller.stream(new Object[] { record });    ByteArrayOutputStream requestOutputStream = new ByteArrayOutputStream();    readPratialAndDrain(random.nextInt(7) + 1, requestInputStream, requestOutputStream);    InputStream serialized = new ByteArrayInputStream(requestOutputStream.toByteArray());    Object[] parsedArgs = requestMarshaller.parse(serialized);    assertEquals(1, parsedArgs.length);    assertEquals(record, parsedArgs[0]);}
0
public void testAvroResponseReadPartialAndDrain() throws IOException
{    AvroResponseMarshaller responseMarshaller = new AvroResponseMarshaller(message);    InputStream responseInputStream = responseMarshaller.stream(record);    ByteArrayOutputStream responseOutputStream = new ByteArrayOutputStream();    readPratialAndDrain(random.nextInt(7) + 1, responseInputStream, responseOutputStream);    InputStream serialized = new ByteArrayInputStream(responseOutputStream.toByteArray());    Object parsedResponse = responseMarshaller.parse(serialized);    assertEquals(record, parsedResponse);}
0
public void setUp() throws IOException
{    TestService serviceImpl = new TestServiceImplBase();    setUpServerAndClient(serviceImpl);}
0
private void setUpServerAndClient(TestService serviceImpl) throws IOException
{    if (server != null && !server.isShutdown()) {        server.shutdown();    }    if (channel != null && !channel.isShutdown()) {        channel.shutdownNow();    }    server = ServerBuilder.forPort(0).addService(AvroGrpcServer.createServiceDefinition(TestService.class, serviceImpl)).build();    server.start();    int port = server.getPort();    channel = ManagedChannelBuilder.forAddress("localhost", port).usePlaintext().build();    stub = AvroGrpcClient.create(channel, TestService.class);    callbackStub = AvroGrpcClient.create(channel, TestService.Callback.class);}
0
public void cleanUp()
{    channel.shutdownNow();    server.shutdownNow();}
0
public void testEchoRecord() throws Exception
{    TestRecord echoedRecord = stub.echo(record);    assertEquals(record, echoedRecord);}
0
public void testMultipleArgsAdd() throws Exception
{    int result = stub.add(3, 5, 2);    assertEquals(10, result);}
0
public void testMultipleArgsConcatenate() throws Exception
{    String val1 = "foo-bar";    Boolean val2 = true;    long val3 = 123321L;    int val4 = 42;    assertEquals(val1 + val2 + val3 + val4, stub.concatenate(val1, val2, val3, val4));}
0
public void testCallbackInterface() throws Exception
{    CallFuture<TestRecord> future = new CallFuture<>();    callbackStub.echo(record, future);    assertEquals(record, future.get(1, TimeUnit.SECONDS));}
0
public void testOneWayRpc() throws Exception
{    oneWayStart = new CountDownLatch(1);    oneWayDone = new CountDownLatch(3);    oneWayCount = new AtomicInteger();    stub.ping();    stub.ping();        assertEquals(0, oneWayCount.get());    oneWayStart.countDown();    stub.ping();    oneWayDone.await(1, TimeUnit.SECONDS);    assertEquals(3, oneWayCount.get());}
0
public void testDeclaredError() throws Exception
{    try {        stub.error(true);        fail("Expected exception but none thrown");    } catch (TestError te) {        assertEquals(declaredErrMsg, te.getMessage$());    }}
0
public void testUndeclaredError() throws Exception
{    try {        stub.error(false);        fail("Expected exception but none thrown");    } catch (AvroRuntimeException e) {        assertTrue(e.getMessage().contains(undeclaredErrMsg));    }}
0
public void testNullableResponse() throws Exception
{    setUpServerAndClient(new TestServiceImplBase() {        @Override        public String concatenate(String val1, boolean val2, long val3, int val4) {            return null;        }    });    assertEquals(null, stub.concatenate("foo", true, 42L, 42));}
0
public String concatenate(String val1, boolean val2, long val3, int val4)
{    return null;}
0
public void testGrpcConnectionError() throws Exception
{        channel.shutdownNow();    stub.add(0, 1, 2);}
0
public void testRepeatedRequests() throws Exception
{    TestRecord[] echoedRecords = new TestRecord[5];        for (int i = 0; i < 5; i++) {        echoedRecords[i] = stub.echo(record);    }    for (TestRecord result : echoedRecords) {        assertEquals(record, result);    }}
0
public void testConcurrentClientAccess() throws Exception
{    ExecutorService es = Executors.newCachedThreadPool();    Future<TestRecord>[] records = new Future[5];    Future<Integer>[] adds = new Future[5];        for (int i = 0; i < 5; i++) {        records[i] = es.submit(() -> stub.echo(record));        int j = i;        adds[i] = es.submit(() -> stub.add(j, 2 * j, 3 * j));    }        for (int i = 0; i < 5; i++) {        assertEquals(record, records[i].get());        assertEquals(6 * i, (long) adds[i].get());    }}
0
public void testConcurrentChannels() throws Exception
{    ManagedChannel otherChannel = ManagedChannelBuilder.forAddress("localhost", server.getPort()).usePlaintext().build();    TestService otherStub = AvroGrpcClient.create(otherChannel, TestService.class);    Future<Integer>[] adds = new Future[5];    Future<Integer>[] otherAdds = new Future[5];    ExecutorService es = Executors.newCachedThreadPool();        for (int i = 0; i < 5; i++) {        int j = i;        adds[i] = es.submit(() -> stub.add(j, j - 1, j - 2));        otherAdds[i] = es.submit(() -> otherStub.add(j, j + 1, j + 2));    }        for (int i = 0; i < 5; i++) {        assertEquals((3 * i) - 3, (long) adds[i].get());        assertEquals((3 * i) + 3, (long) otherAdds[i].get());    }    otherChannel.shutdownNow();}
0
public TestRecord echo(TestRecord record)
{    return record;}
0
public int add(int arg1, int arg2, int arg3)
{    return arg1 + arg2 + arg3;}
0
public void error(boolean declared) throws TestError
{    if (declared) {        throw declaredError;    }    throw undeclaredError;}
0
public void ping()
{    try {        oneWayStart.await();        oneWayCount.incrementAndGet();        oneWayDone.countDown();    } catch (InterruptedException e) {        fail("thread interrupted when waiting for all one-way messages");    }}
0
public String concatenate(String val1, boolean val2, long val3, int val4)
{    return val1 + val2 + val3 + val4;}
0
 void verifySerDeAndStandardMethods(T original)
{    final SpecificDatumWriter<T> datumWriterFromSchema = new SpecificDatumWriter<>(original.getSchema());    final SpecificDatumReader<T> datumReaderFromSchema = new SpecificDatumReader<>(original.getSchema(), original.getSchema());    verifySerDeAndStandardMethods(original, datumWriterFromSchema, datumReaderFromSchema);    final SpecificDatumWriter<T> datumWriterFromClass = new SpecificDatumWriter(original.getClass());    final SpecificDatumReader<T> datumReaderFromClass = new SpecificDatumReader(original.getClass());    verifySerDeAndStandardMethods(original, datumWriterFromClass, datumReaderFromClass);}
0
private void verifySerDeAndStandardMethods(T original, SpecificDatumWriter<T> datumWriter, SpecificDatumReader<T> datumReader)
{    final byte[] serialized = serialize(original, datumWriter);    final T copy = deserialize(serialized, datumReader);    Assert.assertEquals(original, copy);                        Assert.assertEquals(original.hashCode(), copy.hashCode());    Assert.assertEquals(original.toString(), copy.toString());}
0
private byte[] serialize(T object, SpecificDatumWriter<T> datumWriter)
{    ByteArrayOutputStream outputStream = new ByteArrayOutputStream();    try {        datumWriter.write(object, EncoderFactory.get().directBinaryEncoder(outputStream, null));        return outputStream.toByteArray();    } catch (IOException e) {        throw new RuntimeException(e);    }}
0
private T deserialize(byte[] bytes, SpecificDatumReader<T> datumReader)
{    try {        final ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(bytes);        return datumReader.read(null, DecoderFactory.get().directBinaryDecoder(byteArrayInputStream, null));    } catch (IOException e) {        throw new RuntimeException(e);    }}
0
public void testNullValues() throws IOException
{    LogicalTypesWithCustomConversion instanceOfGeneratedClass = LogicalTypesWithCustomConversion.newBuilder().setNonNullCustomField(new CustomDecimal(BigInteger.valueOf(100), 2)).build();    verifySerDeAndStandardMethods(instanceOfGeneratedClass);}
0
public void testNonNullValues() throws IOException
{    LogicalTypesWithCustomConversion instanceOfGeneratedClass = LogicalTypesWithCustomConversion.newBuilder().setNonNullCustomField(new CustomDecimal(BigInteger.valueOf(100), 2)).setNullableCustomField(new CustomDecimal(BigInteger.valueOf(3000), 2)).build();    verifySerDeAndStandardMethods(instanceOfGeneratedClass);}
0
public void testDefaultValueOfNullableField() throws IOException
{    LogicalTypesWithDefaults instanceOfGeneratedClass = LogicalTypesWithDefaults.newBuilder().setNonNullDate(LocalDate.now()).build();    verifySerDeAndStandardMethods(instanceOfGeneratedClass);}
0
public void testDefaultValueOfNonNullField() throws IOException
{    LogicalTypesWithDefaults instanceOfGeneratedClass = LogicalTypesWithDefaults.newBuilder().setNullableDate(LocalDate.now()).build();    Assert.assertEquals(DEFAULT_VALUE, instanceOfGeneratedClass.getNonNullDate());    verifySerDeAndStandardMethods(instanceOfGeneratedClass);}
0
public void testWithValues() throws IOException
{    LogicalTypesWithDefaults instanceOfGeneratedClass = LogicalTypesWithDefaults.newBuilder().setNullableDate(LocalDate.now()).setNonNullDate(LocalDate.now()).build();    verifySerDeAndStandardMethods(instanceOfGeneratedClass);}
0
public void testNullableLogicalTypeInNestedRecord()
{    final NestedLogicalTypesRecord nestedLogicalTypesRecord = NestedLogicalTypesRecord.newBuilder().setNestedRecord(NestedRecord.newBuilder().setNullableDateField(LocalDate.now()).build()).build();    verifySerDeAndStandardMethods(nestedLogicalTypesRecord);}
0
public void testNullableLogicalTypeInArray()
{    final NullableLogicalTypesArray logicalTypesArray = NullableLogicalTypesArray.newBuilder().setArrayOfLogicalType(Collections.singletonList(LocalDate.now())).build();    verifySerDeAndStandardMethods(logicalTypesArray);}
0
public void testNullableLogicalTypeInRecordInArray()
{    final NestedLogicalTypesArray nestedLogicalTypesArray = NestedLogicalTypesArray.newBuilder().setArrayOfRecords(Collections.singletonList(RecordInArray.newBuilder().setNullableDateField(LocalDate.now()).build())).build();    verifySerDeAndStandardMethods(nestedLogicalTypesArray);}
0
public void testNullableLogicalTypeInRecordInUnion()
{    final NestedLogicalTypesUnion nestedLogicalTypesUnion = NestedLogicalTypesUnion.newBuilder().setUnionOfRecords(RecordInUnion.newBuilder().setNullableDateField(LocalDate.now()).build()).build();    verifySerDeAndStandardMethods(nestedLogicalTypesUnion);}
0
public void testNullableLogicalTypeInRecordInMap()
{    final NestedLogicalTypesMap nestedLogicalTypesMap = NestedLogicalTypesMap.newBuilder().setMapOfRecords(Collections.singletonMap("key", RecordInMap.newBuilder().setNullableDateField(LocalDate.now()).build())).build();    verifySerDeAndStandardMethods(nestedLogicalTypesMap);}
0
public void testNestedRecordsWithDifferentNamespaces()
{    NestedSomeNamespaceRecord instanceOfGeneratedClass = NestedSomeNamespaceRecord.newBuilder().setNestedRecordBuilder(NestedOtherNamespaceRecord.newBuilder().setSomeField(1)).build();    verifySerDeAndStandardMethods(instanceOfGeneratedClass);}
0
public void testWithNullValues() throws IOException
{    NullableLogicalTypes instanceOfGeneratedClass = NullableLogicalTypes.newBuilder().setNullableDate(null).build();    verifySerDeAndStandardMethods(instanceOfGeneratedClass);}
0
public void testDate() throws IOException
{    NullableLogicalTypes instanceOfGeneratedClass = NullableLogicalTypes.newBuilder().setNullableDate(LocalDate.now()).build();    verifySerDeAndStandardMethods(instanceOfGeneratedClass);}
0
public byte[] toByteArray(int scale)
{    final BigDecimal correctlyScaledValue;    if (scale != internalValue.scale()) {        correctlyScaledValue = internalValue.setScale(scale, RoundingMode.HALF_UP);    } else {        correctlyScaledValue = internalValue;    }    return correctlyScaledValue.unscaledValue().toByteArray();}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    CustomDecimal that = (CustomDecimal) o;    return internalValue.equals(that.internalValue);}
0
public int hashCode()
{    return internalValue.hashCode();}
0
public int compareTo(CustomDecimal o)
{    return this.internalValue.compareTo(o.internalValue);}
0
public Class<CustomDecimal> getConvertedType()
{    return CustomDecimal.class;}
0
public String getLogicalTypeName()
{    return "decimal";}
0
public CustomDecimal fromBytes(ByteBuffer value, Schema schema, LogicalType type)
{    int scale = ((LogicalTypes.Decimal) type).getScale();    byte[] bytes = value.get(new byte[value.remaining()]).array();    return new CustomDecimal(new BigInteger(bytes), scale);}
0
public ByteBuffer toBytes(CustomDecimal value, Schema schema, LogicalType type)
{    int scale = ((LogicalTypes.Decimal) type).getScale();    return ByteBuffer.wrap(value.toByteArray(scale));}
0
public void handleResult(T result)
{    this.result = result;    latch.countDown();    if (chainedCallback != null) {        chainedCallback.handleResult(result);    }}
0
public void handleError(Throwable error)
{    this.error = error;    latch.countDown();    if (chainedCallback != null) {        chainedCallback.handleError(error);    }}
0
public T getResult()
{    return result;}
0
public Throwable getError()
{    return error;}
0
public boolean cancel(boolean mayInterruptIfRunning)
{    return false;}
0
public boolean isCancelled()
{    return false;}
0
public T get() throws InterruptedException, ExecutionException
{    latch.await();    if (error != null) {        throw new ExecutionException(error);    }    return result;}
0
public T get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException
{    if (latch.await(timeout, unit)) {        if (error != null) {            throw new ExecutionException(error);        }        return result;    } else {        throw new TimeoutException();    }}
0
public void await() throws InterruptedException
{    latch.await();}
0
public void await(long timeout, TimeUnit unit) throws InterruptedException, TimeoutException
{    if (!latch.await(timeout, unit)) {        throw new TimeoutException();    }}
0
public boolean isDone()
{    return latch.getCount() <= 0;}
0
public int getPort()
{    return channel.socket().getLocalPort();}
0
public void run()
{    while (true) {        try {            transceiver.writeBuffers(responder.respond(transceiver.readBuffers()));        } catch (ClosedChannelException e) {            return;        } catch (IOException e) {                        throw new RuntimeException(e);        }    }}
1
public void close()
{    this.interrupt();}
0
public static void main(String[] arg) throws Exception
{    DatagramServer server = new DatagramServer(null, new InetSocketAddress(0));    server.start();    System.out.println("started");    server.join();}
0
public String getRemoteName()
{    return remote.toString();}
0
public synchronized List<ByteBuffer> readBuffers() throws IOException
{    buffer.clear();    remote = channel.receive(buffer);        buffer.flip();    List<ByteBuffer> buffers = new ArrayList<>();    while (true) {        int length = buffer.getInt();        if (length == 0) {                        return buffers;        }                ByteBuffer chunk = buffer.slice();        chunk.limit(length);        buffer.position(buffer.position() + length);        buffers.add(chunk);    }}
1
public synchronized void writeBuffers(List<ByteBuffer> buffers) throws IOException
{    buffer.clear();    for (ByteBuffer b : buffers) {        buffer.putInt(b.remaining());                buffer.put(b);    }    buffer.putInt(0);    buffer.flip();    channel.send(buffer, remote);    }
1
public GenericData getGenericData()
{    return data;}
0
public void writeRequest(Schema schema, Object request, Encoder out) throws IOException
{    new GenericDatumWriter<>(schema, data).write(request, out);}
0
public Object readResponse(Schema writer, Schema reader, Decoder in) throws IOException
{    return new GenericDatumReader<>(writer, reader, data).read(null, in);}
0
public Exception readError(Schema writer, Schema reader, Decoder in) throws IOException
{    Object error = new GenericDatumReader<>(writer, reader, data).read(null, in);    if (error instanceof CharSequence)                return new AvroRuntimeException(error.toString());    return new AvroRemoteException(error);}
0
public GenericData getGenericData()
{    return data;}
0
protected DatumWriter<Object> getDatumWriter(Schema schema)
{    return new GenericDatumWriter<>(schema, data);}
0
protected DatumReader<Object> getDatumReader(Schema actual, Schema expected)
{    return new GenericDatumReader<>(actual, expected, data);}
0
public Object readRequest(Schema actual, Schema expected, Decoder in) throws IOException
{    return getDatumReader(actual, expected).read(null, in);}
0
public void writeResponse(Schema schema, Object response, Encoder out) throws IOException
{    getDatumWriter(schema).write(response, out);}
0
public void writeError(Schema schema, Object error, Encoder out) throws IOException
{    if (error instanceof AvroRemoteException)        error = ((AvroRemoteException) error).getValue();    getDatumWriter(schema).write(error, out);}
0
public void setTimeout(int timeout)
{    this.timeout = timeout;}
0
public String getRemoteName()
{    return this.url.toString();}
0
public synchronized List<ByteBuffer> readBuffers() throws IOException
{    try (InputStream in = connection.getInputStream()) {        return readBuffers(in);    }}
0
public synchronized void writeBuffers(List<ByteBuffer> buffers) throws IOException
{    if (proxy == null)        connection = (HttpURLConnection) url.openConnection();    else        connection = (HttpURLConnection) url.openConnection(proxy);    connection.setRequestMethod("POST");    connection.setRequestProperty("Content-Type", CONTENT_TYPE);    connection.setRequestProperty("Content-Length", Integer.toString(getLength(buffers)));    connection.setDoOutput(true);    connection.setReadTimeout(timeout);    connection.setConnectTimeout(timeout);    try (OutputStream out = connection.getOutputStream()) {        writeBuffers(buffers, out);    }}
0
 static int getLength(List<ByteBuffer> buffers)
{    int length = 0;    for (ByteBuffer buffer : buffers) {        length += 4;        length += buffer.remaining();    }    length += 4;    return length;}
0
 static List<ByteBuffer> readBuffers(InputStream in) throws IOException
{    List<ByteBuffer> buffers = new ArrayList<>();    while (true) {        int length = (in.read() << 24) + (in.read() << 16) + (in.read() << 8) + in.read();        if (length == 0) {                        return buffers;        }        ByteBuffer buffer = ByteBuffer.allocate(length);        while (buffer.hasRemaining()) {            int p = buffer.position();            int i = in.read(buffer.array(), p, buffer.remaining());            if (i < 0)                throw new EOFException("Unexpected EOF");            buffer.position(p + i);        }        buffer.flip();        buffers.add(buffer);    }}
0
 static void writeBuffers(List<ByteBuffer> buffers, OutputStream out) throws IOException
{    for (ByteBuffer buffer : buffers) {                writeLength(buffer.limit(), out);        out.write(buffer.array(), buffer.position(), buffer.remaining());        buffer.position(buffer.limit());    }        writeLength(0, out);}
0
private static void writeLength(int length, OutputStream out) throws IOException
{    out.write(0xff & (length >>> 24));    out.write(0xff & (length >>> 16));    out.write(0xff & (length >>> 8));    out.write(0xff & length);}
0
public static Transceiver createTransceiver(URI uri) throws IOException
{    if ("http".equals(uri.getScheme()))        return new HttpTransceiver(uri.toURL());    else if ("avro".equals(uri.getScheme()))        return new SaslSocketTransceiver(new InetSocketAddress(uri.getHost(), uri.getPort()));    else        throw new IOException("unknown uri scheme: " + uri);}
0
public static Server createServer(Responder responder, URI uri) throws IOException
{    if ("avro".equals(uri.getScheme())) {        return new SaslSocketServer(responder, new InetSocketAddress(uri.getHost(), uri.getPort()));    } else if ("http".equals(uri.getScheme())) {        if (!warned) {            LoggerFactory.getLogger(Ipc.class).error("Using Ipc.createServer to create http instances is deprecated.  Create " + " an instace of org.apache.avro.ipc.jetty.HttpServer directly.");            warned = true;        }        try {            Class<?> cls = Class.forName("org.apache.avro.ipc.jetty.HttpServer");            return (Server) cls.getConstructor(Responder.class, Integer.TYPE).newInstance(responder, uri.getPort());        } catch (Throwable t) {                }    }    throw new IOException("unknown uri scheme: " + uri);}
0
public String getRemoteName()
{    return "local";}
0
public List<ByteBuffer> transceive(List<ByteBuffer> request) throws IOException
{    return responder.respond(request);}
0
public List<ByteBuffer> readBuffers() throws IOException
{    throw new UnsupportedOperationException();}
0
public void writeBuffers(List<ByteBuffer> buffers) throws IOException
{    throw new UnsupportedOperationException();}
0
public ReflectData getReflectData()
{    return (ReflectData) getSpecificData();}
0
protected DatumWriter<Object> getDatumWriter(Schema schema)
{    return new ReflectDatumWriter<>(schema, getReflectData());}
0
protected DatumReader<Object> getDatumReader(Schema writer, Schema reader)
{    return new ReflectDatumReader<>(writer, reader, getReflectData());}
0
public static T getClient(Class<T> iface, Transceiver transceiver) throws IOException
{    return getClient(iface, transceiver, new ReflectData(iface.getClassLoader()));}
0
public static T getClient(Class<T> iface, Transceiver transceiver, ReflectData reflectData) throws IOException
{    Protocol protocol = reflectData.getProtocol(iface);    return (T) Proxy.newProxyInstance(reflectData.getClassLoader(), new Class[] { iface }, new ReflectRequestor(protocol, transceiver, reflectData));}
0
public static T getClient(Class<T> iface, ReflectRequestor rreq) throws IOException
{    return (T) Proxy.newProxyInstance(rreq.getReflectData().getClassLoader(), new Class[] { iface }, rreq);}
0
public ReflectData getReflectData()
{    return (ReflectData) getSpecificData();}
0
protected DatumWriter<Object> getDatumWriter(Schema schema)
{    return new ReflectDatumWriter<>(schema, getReflectData());}
0
protected DatumReader<Object> getDatumReader(Schema actual, Schema expected)
{    return new ReflectDatumReader<>(actual, expected, getReflectData());}
0
public void writeError(Schema schema, Object error, Encoder out) throws IOException
{    if (error instanceof CharSequence)                error = error.toString();    super.writeError(schema, error, out);}
0
public Protocol getLocal()
{    return local;}
0
public Transceiver getTransceiver()
{    return transceiver;}
0
public void addRPCPlugin(RPCPlugin plugin)
{    rpcMetaPlugins.add(plugin);}
0
public Object request(String messageName, Object request) throws Exception
{        Request rpcRequest = new Request(messageName, request, new RPCContext());    CallFuture<Object> future = /* only need a Future for two-way messages */    rpcRequest.getMessage().isOneWay() ? null : new CallFuture<>();        request(rpcRequest, future);    if (    future == null)        return null;    try {                return future.get();    } catch (ExecutionException e) {        Throwable error = e.getCause();        if (error instanceof Exception) {            throw (Exception) error;        } else {            throw new AvroRuntimeException(error);        }    }}
0
public void request(String messageName, Object request, Callback<T> callback) throws AvroRemoteException, IOException
{    request(new Request(messageName, request, new RPCContext()), callback);}
0
 void request(Request request, Callback<T> callback) throws AvroRemoteException, IOException
{    Transceiver t = getTransceiver();    if (!t.isConnected()) {                        handshakeLock.lock();        try {            if (t.isConnected()) {                                                handshakeLock.unlock();            } else {                CallFuture<T> callFuture = new CallFuture<>(callback);                t.transceive(request.getBytes(), new TransceiverCallback<>(request, callFuture));                try {                                        callFuture.await();                } catch (InterruptedException e) {                                        Thread.currentThread().interrupt();                }                if (request.getMessage().isOneWay()) {                    Throwable error = callFuture.getError();                    if (error != null) {                        if (error instanceof AvroRemoteException) {                            throw (AvroRemoteException) error;                        } else if (error instanceof AvroRuntimeException) {                            throw (AvroRuntimeException) error;                        } else if (error instanceof IOException) {                            throw (IOException) error;                        } else {                            throw new AvroRuntimeException(error);                        }                    }                }                return;            }        } finally {            if (handshakeLock.isHeldByCurrentThread()) {                handshakeLock.unlock();            }        }    }    if (request.getMessage().isOneWay()) {        t.lockChannel();        try {            t.writeBuffers(request.getBytes());            if (callback != null) {                callback.handleResult(null);            }        } finally {            t.unlockChannel();        }    } else {        t.transceive(request.getBytes(), new TransceiverCallback<>(request, callback));    }}
0
private void writeHandshake(Encoder out) throws IOException
{    if (getTransceiver().isConnected())        return;    MD5 localHash = new MD5();    localHash.bytes(local.getMD5());    String remoteName = transceiver.getRemoteName();    MD5 remoteHash = REMOTE_HASHES.get(remoteName);    if (remoteHash == null) {                remoteHash = localHash;        remote = local;    } else {        remote = REMOTE_PROTOCOLS.get(remoteHash);    }    HandshakeRequest handshake = new HandshakeRequest();    handshake.setClientHash(localHash);    handshake.setServerHash(remoteHash);    if (sendLocalText)        handshake.setClientProtocol(local.toString());    RPCContext context = new RPCContext();    context.setHandshakeRequest(handshake);    for (RPCPlugin plugin : rpcMetaPlugins) {        plugin.clientStartConnect(context);    }    handshake.setMeta(context.requestHandshakeMeta());    HANDSHAKE_WRITER.write(handshake, out);}
0
private boolean readHandshake(Decoder in) throws IOException
{    if (getTransceiver().isConnected())        return true;    boolean established = false;    HandshakeResponse handshake = HANDSHAKE_READER.read(null, in);    switch(handshake.getMatch()) {        case BOTH:            established = true;            sendLocalText = false;            break;        case CLIENT:                        setRemote(handshake);            established = true;            sendLocalText = false;            break;        case NONE:                        setRemote(handshake);            sendLocalText = true;            break;        default:            throw new AvroRuntimeException("Unexpected match: " + handshake.getMatch());    }    RPCContext context = new RPCContext();    context.setHandshakeResponse(handshake);    for (RPCPlugin plugin : rpcMetaPlugins) {        plugin.clientFinishConnect(context);    }    if (established)        getTransceiver().setRemote(remote);    return established;}
1
private void setRemote(HandshakeResponse handshake) throws IOException
{    remote = Protocol.parse(handshake.getServerProtocol().toString());    MD5 remoteHash = handshake.getServerHash();    REMOTE_HASHES.put(transceiver.getRemoteName(), remoteHash);    REMOTE_PROTOCOLS.putIfAbsent(remoteHash, remote);}
0
public Protocol getRemote() throws IOException
{    if (remote != null)                return remote;    MD5 remoteHash = REMOTE_HASHES.get(transceiver.getRemoteName());    if (remoteHash != null) {        remote = REMOTE_PROTOCOLS.get(remoteHash);        if (remote != null)                        return remote;    }    handshakeLock.lock();    try {                ByteBufferOutputStream bbo = new ByteBufferOutputStream();                Encoder out = ENCODER_FACTORY.directBinaryEncoder(bbo, null);        writeHandshake(out);                out.writeInt(0);                out.writeString("");        List<ByteBuffer> response = getTransceiver().transceive(bbo.getBufferList());        ByteBufferInputStream bbi = new ByteBufferInputStream(response);        BinaryDecoder in = DecoderFactory.get().binaryDecoder(bbi, null);        readHandshake(in);        return this.remote;    } finally {        handshakeLock.unlock();    }}
0
public Object readResponse(Schema schema, Decoder in) throws IOException
{    return readResponse(schema, schema, in);}
0
public Object readError(Schema schema, Decoder in) throws IOException
{    return readError(schema, schema, in);}
0
public void handleResult(List<ByteBuffer> responseBytes)
{    ByteBufferInputStream bbi = new ByteBufferInputStream(responseBytes);    BinaryDecoder in = DecoderFactory.get().binaryDecoder(bbi, null);    try {        if (!readHandshake(in)) {                        Request handshake = new Request(request);            getTransceiver().transceive(handshake.getBytes(), new TransceiverCallback<>(handshake, callback));            return;        }    } catch (Exception e) {            }        Response response = new Response(request, in);    Object responseObject;    try {        try {            responseObject = response.getResponse();        } catch (Exception e) {            if (callback != null) {                callback.handleError(e);            }            return;        }        if (callback != null) {            callback.handleResult((T) responseObject);        }    } catch (Throwable t) {            }}
1
public void handleError(Throwable error)
{    callback.handleError(error);}
0
public String getMessageName()
{    return messageName;}
0
public RPCContext getContext()
{    return context;}
0
public Message getMessage()
{    if (message == null) {        message = getLocal().getMessages().get(messageName);        if (message == null) {            throw new AvroRuntimeException("Not a local message: " + messageName);        }    }    return message;}
0
public List<ByteBuffer> getBytes() throws IOException
{    if (requestBytes == null) {        ByteBufferOutputStream bbo = new ByteBufferOutputStream();        BinaryEncoder out = ENCODER_FACTORY.binaryEncoder(bbo, encoder);                Message m = getMessage();        context.setMessage(m);                writeRequest(m.getRequest(), request, out);        out.flush();        List<ByteBuffer> payload = bbo.getBufferList();                writeHandshake(out);        context.setRequestPayload(payload);        for (RPCPlugin plugin : rpcMetaPlugins) {                        plugin.clientSendRequest(context);        }        META_WRITER.write(context.requestCallMeta(), out);                out.writeString(m.getName());        out.flush();        bbo.append(payload);        requestBytes = bbo.getBufferList();    }    return requestBytes;}
0
public Object getResponse() throws Exception
{    Message lm = request.getMessage();    Message rm = remote.getMessages().get(request.getMessageName());    if (rm == null)        throw new AvroRuntimeException("Not a remote message: " + request.getMessageName());    Transceiver t = getTransceiver();    if ((lm.isOneWay() != rm.isOneWay()) && t.isConnected())        throw new AvroRuntimeException("Not both one-way messages: " + request.getMessageName());    if (lm.isOneWay() && t.isConnected())                return null;    RPCContext context = request.getContext();    context.setResponseCallMeta(META_READER.read(null, in));    if (!in.readBoolean()) {                Object response = readResponse(rm.getResponse(), lm.getResponse(), in);        context.setResponse(response);        for (RPCPlugin plugin : rpcMetaPlugins) {            plugin.clientReceiveResponse(context);        }        return response;    } else {        Exception error = readError(rm.getErrors(), lm.getErrors(), in);        context.setError(error);        for (RPCPlugin plugin : rpcMetaPlugins) {            plugin.clientReceiveResponse(context);        }        throw error;    }}
0
public static Protocol getRemote()
{    return REMOTE.get();}
0
public Protocol getLocal()
{    return local;}
0
public void addRPCPlugin(RPCPlugin plugin)
{    rpcMetaPlugins.add(plugin);}
0
public List<ByteBuffer> respond(List<ByteBuffer> buffers) throws IOException
{    return respond(buffers, null);}
0
public List<ByteBuffer> respond(List<ByteBuffer> buffers, Transceiver connection) throws IOException
{    Decoder in = DecoderFactory.get().binaryDecoder(new ByteBufferInputStream(buffers), null);    ByteBufferOutputStream bbo = new ByteBufferOutputStream();    BinaryEncoder out = EncoderFactory.get().binaryEncoder(bbo, null);    Exception error = null;    RPCContext context = new RPCContext();    List<ByteBuffer> payload = null;    List<ByteBuffer> handshake = null;    boolean wasConnected = connection != null && connection.isConnected();    try {        Protocol remote = handshake(in, out, connection);        out.flush();        if (        remote == null)            return bbo.getBufferList();        handshake = bbo.getBufferList();                context.setRequestCallMeta(META_READER.read(null, in));        String messageName = in.readString(null).toString();        if (        messageName.equals(""))            return handshake;        Message rm = remote.getMessages().get(messageName);        if (rm == null)            throw new AvroRuntimeException("No such remote message: " + messageName);        Message m = getLocal().getMessages().get(messageName);        if (m == null)            throw new AvroRuntimeException("No message named " + messageName + " in " + getLocal());        Object request = readRequest(rm.getRequest(), m.getRequest(), in);        context.setMessage(rm);        for (RPCPlugin plugin : rpcMetaPlugins) {            plugin.serverReceiveRequest(context);        }                if ((m.isOneWay() != rm.isOneWay()) && wasConnected)            throw new AvroRuntimeException("Not both one-way: " + messageName);        Object response = null;        try {            REMOTE.set(remote);            response = respond(m, request);            context.setResponse(response);        } catch (Exception e) {            error = e;            context.setError(error);                    } finally {            REMOTE.set(null);        }        if (        m.isOneWay() && wasConnected)            return null;        out.writeBoolean(error != null);        if (error == null)            writeResponse(m.getResponse(), response, out);        else            try {                writeError(m.getErrors(), error, out);            } catch (UnresolvedUnionException e) {                                throw error;            }    } catch (Exception e) {                        context.setError(e);        bbo = new ByteBufferOutputStream();        out = EncoderFactory.get().binaryEncoder(bbo, null);        out.writeBoolean(true);        writeError(Protocol.SYSTEM_ERRORS, new Utf8(e.toString()), out);        if (null == handshake) {            handshake = new ByteBufferOutputStream().getBufferList();        }    }    out.flush();    payload = bbo.getBufferList();        context.setResponsePayload(payload);    for (RPCPlugin plugin : rpcMetaPlugins) {        plugin.serverSendResponse(context);    }    META_WRITER.write(context.responseCallMeta(), out);    out.flush();        bbo.prepend(handshake);    bbo.append(payload);    return bbo.getBufferList();}
1
private Protocol handshake(Decoder in, Encoder out, Transceiver connection) throws IOException
{    if (connection != null && connection.isConnected())        return connection.getRemote();    HandshakeRequest request = handshakeReader.read(null, in);    Protocol remote = protocols.get(request.getClientHash());    if (remote == null && request.getClientProtocol() != null) {        remote = Protocol.parse(request.getClientProtocol().toString());        protocols.put(request.getClientHash(), remote);    }    HandshakeResponse response = new HandshakeResponse();    if (localHash.equals(request.getServerHash())) {        response.setMatch(remote == null ? HandshakeMatch.NONE : HandshakeMatch.BOTH);    } else {        response.setMatch(remote == null ? HandshakeMatch.NONE : HandshakeMatch.CLIENT);    }    if (response.getMatch() != HandshakeMatch.BOTH) {        response.setServerProtocol(local.toString());        response.setServerHash(localHash);    }    RPCContext context = new RPCContext();    context.setHandshakeRequest(request);    context.setHandshakeResponse(response);    for (RPCPlugin plugin : rpcMetaPlugins) {        plugin.serverConnecting(context);    }    handshakeWriter.write(response, out);    if (connection != null && response.getMatch() != HandshakeMatch.NONE)        connection.setRemote(remote);    return remote;}
0
protected void doPost(HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException
{    response.setContentType(HttpTransceiver.CONTENT_TYPE);    List<ByteBuffer> requestBufs = HttpTransceiver.readBuffers(request.getInputStream());    try {        List<ByteBuffer> responseBufs = responder.respond(requestBufs);        response.setContentLength(HttpTransceiver.getLength(responseBufs));        HttpTransceiver.writeBuffers(responseBufs, response.getOutputStream());    } catch (AvroRuntimeException e) {        throw new ServletException(e);    }}
0
public void setHandshakeRequest(HandshakeRequest handshakeRequest)
{    this.handshakeRequest = handshakeRequest;}
0
public HandshakeRequest getHandshakeRequest()
{    return this.handshakeRequest;}
0
public void setHandshakeResponse(HandshakeResponse handshakeResponse)
{    this.handshakeResponse = handshakeResponse;}
0
public HandshakeResponse getHandshakeResponse()
{    return this.handshakeResponse;}
0
public Map<String, ByteBuffer> requestHandshakeMeta()
{    if (handshakeRequest.getMeta() == null)        handshakeRequest.setMeta(new HashMap<>());    return handshakeRequest.getMeta();}
0
 void setRequestHandshakeMeta(Map<String, ByteBuffer> newmeta)
{    handshakeRequest.setMeta(newmeta);}
0
public Map<String, ByteBuffer> responseHandshakeMeta()
{    if (handshakeResponse.getMeta() == null)        handshakeResponse.setMeta(new HashMap<>());    return handshakeResponse.getMeta();}
0
 void setResponseHandshakeMeta(Map<String, ByteBuffer> newmeta)
{    handshakeResponse.setMeta(newmeta);}
0
public Map<String, ByteBuffer> requestCallMeta()
{    if (requestCallMeta == null) {        requestCallMeta = new HashMap<>();    }    return requestCallMeta;}
0
 void setRequestCallMeta(Map<String, ByteBuffer> newmeta)
{    requestCallMeta = newmeta;}
0
public Map<String, ByteBuffer> responseCallMeta()
{    if (responseCallMeta == null) {        responseCallMeta = new HashMap<>();    }    return responseCallMeta;}
0
 void setResponseCallMeta(Map<String, ByteBuffer> newmeta)
{    responseCallMeta = newmeta;}
0
 void setResponse(Object response)
{    this.response = response;    this.error = null;}
0
public Object response()
{    return response;}
0
 void setError(Exception error)
{    this.response = null;    this.error = error;}
0
public Exception error()
{    return error;}
0
public boolean isError()
{    return error != null;}
0
public void setMessage(Message message)
{    this.message = message;}
0
public Message getMessage()
{    return message;}
0
public void setRequestPayload(List<ByteBuffer> payload)
{    this.requestPayload = payload;}
0
public List<ByteBuffer> getRequestPayload()
{    return this.requestPayload;}
0
public List<ByteBuffer> getResponsePayload()
{    return this.responsePayload;}
0
public void setResponsePayload(List<ByteBuffer> payload)
{    this.responsePayload = payload;}
0
public void clientStartConnect(RPCContext context)
{}
0
public void serverConnecting(RPCContext context)
{}
0
public void clientFinishConnect(RPCContext context)
{}
0
public void clientSendRequest(RPCContext context)
{}
0
public void serverReceiveRequest(RPCContext context)
{}
0
public void serverSendResponse(RPCContext context)
{}
0
public void clientReceiveResponse(RPCContext context)
{}
0
public SaslServer getServer()
{    return new AnonymousServer();}
0
public SaslServer getServer() throws SaslException
{    return Sasl.createSaslServer(mechanism, protocol, serverName, props, cbh);}
0
protected Transceiver getTransceiver(SocketChannel channel) throws IOException
{    return new SaslSocketTransceiver(channel, factory.getServer());}
0
public String getMechanismName()
{    return "ANONYMOUS";}
0
public byte[] evaluateResponse(byte[] response) throws SaslException
{    this.user = new String(response, StandardCharsets.UTF_8);    return null;}
0
public boolean isComplete()
{    return user != null;}
0
public String getAuthorizationID()
{    return user;}
0
public byte[] unwrap(byte[] incoming, int offset, int len)
{    throw new UnsupportedOperationException();}
0
public byte[] wrap(byte[] outgoing, int offset, int len)
{    throw new UnsupportedOperationException();}
0
public Object getNegotiatedProperty(String propName)
{    return null;}
0
public void dispose()
{}
0
public boolean isConnected()
{    return remote != null;}
0
public void setRemote(Protocol remote)
{    this.remote = remote;}
0
public Protocol getRemote()
{    return remote;}
0
public String getRemoteName()
{    return channel.socket().getRemoteSocketAddress().toString();}
0
public synchronized List<ByteBuffer> transceive(List<ByteBuffer> request) throws IOException
{    if (saslResponsePiggybacked) {                saslResponsePiggybacked = false;        Status status = readStatus();        ByteBuffer frame = readFrame();        switch(status) {            case COMPLETE:                break;            case FAIL:                throw new SaslException("Fail: " + toString(frame));            default:                throw new IOException("Unexpected SASL status: " + status);        }    }    return super.transceive(request);}
0
private void open(boolean isClient) throws IOException
{        if (isClient) {        ByteBuffer response = EMPTY;        if (sasl.client.hasInitialResponse())            response = ByteBuffer.wrap(sasl.evaluate(response.array()));        write(Status.START, sasl.getMechanismName(), response);        if (sasl.isComplete())            saslResponsePiggybacked = true;    }    while (!sasl.isComplete()) {        Status status = readStatus();        ByteBuffer frame = readFrame();        switch(status) {            case START:                String mechanism = toString(frame);                frame = readFrame();                if (!mechanism.equalsIgnoreCase(sasl.getMechanismName())) {                    write(Status.FAIL, "Wrong mechanism: " + mechanism);                    throw new SaslException("Wrong mechanism: " + mechanism);                }            case CONTINUE:                byte[] response;                try {                    response = sasl.evaluate(frame.array());                    status = sasl.isComplete() ? Status.COMPLETE : Status.CONTINUE;                } catch (SaslException e) {                    response = e.toString().getBytes(StandardCharsets.UTF_8);                    status = Status.FAIL;                }                write(status, response != null ? ByteBuffer.wrap(response) : EMPTY);                break;            case COMPLETE:                sasl.evaluate(frame.array());                if (!sasl.isComplete())                    throw new SaslException("Expected completion!");                break;            case FAIL:                throw new SaslException("Fail: " + toString(frame));            default:                throw new IOException("Unexpected SASL status: " + status);        }    }        String qop = (String) sasl.getNegotiatedProperty(Sasl.QOP);        dataIsWrapped = (qop != null && !qop.equalsIgnoreCase("auth"));}
1
private String toString(ByteBuffer buffer)
{    return new String(buffer.array(), StandardCharsets.UTF_8);}
0
public synchronized List<ByteBuffer> readBuffers() throws IOException
{    List<ByteBuffer> buffers = new ArrayList<>();    while (true) {        ByteBuffer buffer = readFrameAndUnwrap();        if (buffer.remaining() == 0)            return buffers;        buffers.add(buffer);    }}
0
private Status readStatus() throws IOException
{    ByteBuffer buffer = ByteBuffer.allocate(1);    read(buffer);    int status = buffer.get();    if (status > Status.values().length)        throw new IOException("Unexpected SASL status byte: " + status);    return Status.values()[status];}
0
private ByteBuffer readFrameAndUnwrap() throws IOException
{    ByteBuffer frame = readFrame();    if (!dataIsWrapped)        return frame;    ByteBuffer unwrapped = ByteBuffer.wrap(sasl.unwrap(frame.array()));        return unwrapped;}
1
private ByteBuffer readFrame() throws IOException
{    read(readHeader);    ByteBuffer buffer = ByteBuffer.allocate(readHeader.getInt());        read(buffer);    return buffer;}
1
private void read(ByteBuffer buffer) throws IOException
{    buffer.clear();    while (buffer.hasRemaining()) if (channel.read(buffer) == -1)        throw new EOFException();    buffer.flip();}
0
public synchronized void writeBuffers(List<ByteBuffer> buffers) throws IOException
{    if (buffers == null)                return;    List<ByteBuffer> writes = new ArrayList<>(buffers.size() * 2 + 1);    int currentLength = 0;    ByteBuffer currentHeader = writeHeader;    for (ByteBuffer buffer : buffers) {                if (buffer.remaining() == 0)                        continue;        if (dataIsWrapped) {                        buffer = ByteBuffer.wrap(sasl.wrap(buffer.array(), buffer.position(), buffer.remaining()));        }        int length = buffer.remaining();        if (        !dataIsWrapped && (currentLength + length) <= ByteBufferOutputStream.BUFFER_SIZE) {            if (currentLength == 0)                writes.add(currentHeader);            currentLength += length;            currentHeader.clear();            currentHeader.putInt(currentLength);                    } else {            currentLength = length;            currentHeader = ByteBuffer.allocate(4).putInt(length);            writes.add(currentHeader);                    }        currentHeader.flip();        writes.add(buffer);    }        zeroHeader.flip();    writes.add(zeroHeader);    writeFully(writes.toArray(new ByteBuffer[0]));}
1
private void write(Status status, String prefix, ByteBuffer response) throws IOException
{        write(status, prefix);    write(response);}
1
private void write(Status status, String response) throws IOException
{    write(status, ByteBuffer.wrap(response.getBytes(StandardCharsets.UTF_8)));}
0
private void write(Status status, ByteBuffer response) throws IOException
{        ByteBuffer statusBuffer = ByteBuffer.allocate(1);    statusBuffer.clear();    statusBuffer.put((byte) (status.ordinal())).flip();    writeFully(statusBuffer);    write(response);}
1
private void write(ByteBuffer response) throws IOException
{        writeHeader.clear();    writeHeader.putInt(response.remaining()).flip();    writeFully(writeHeader, response);}
1
private void writeFully(ByteBuffer... buffers) throws IOException
{    int length = buffers.length;    int start = 0;    do {        channel.write(buffers, start, length - start);        while (buffers[start].remaining() == 0) {            start++;            if (start == length)                return;        }    } while (true);}
0
public void close() throws IOException
{    if (channel.isOpen()) {                channel.close();    }    sasl.dispose();}
1
public String getMechanismName()
{    if (client != null)        return client.getMechanismName();    else        return server.getMechanismName();}
0
public boolean isComplete()
{    if (client != null)        return client.isComplete();    else        return server.isComplete();}
0
public void dispose() throws SaslException
{    if (client != null)        client.dispose();    else        server.dispose();}
0
public byte[] unwrap(byte[] buf) throws SaslException
{    if (client != null)        return client.unwrap(buf, 0, buf.length);    else        return server.unwrap(buf, 0, buf.length);}
0
public byte[] wrap(byte[] buf) throws SaslException
{    return wrap(buf, 0, buf.length);}
0
public byte[] wrap(byte[] buf, int start, int len) throws SaslException
{    if (client != null)        return client.wrap(buf, start, len);    else        return server.wrap(buf, start, len);}
0
public Object getNegotiatedProperty(String propName)
{    if (client != null)        return client.getNegotiatedProperty(propName);    else        return server.getNegotiatedProperty(propName);}
0
public byte[] evaluate(byte[] buf) throws SaslException
{    if (client != null)        return client.evaluateChallenge(buf);    else        return server.evaluateResponse(buf);}
0
public String getMechanismName()
{    return "ANONYMOUS";}
0
public boolean hasInitialResponse()
{    return true;}
0
public byte[] evaluateChallenge(byte[] challenge) throws SaslException
{    return System.getProperty("user.name").getBytes(StandardCharsets.UTF_8);}
0
public boolean isComplete()
{    return true;}
0
public byte[] unwrap(byte[] incoming, int offset, int len)
{    throw new UnsupportedOperationException();}
0
public byte[] wrap(byte[] outgoing, int offset, int len)
{    throw new UnsupportedOperationException();}
0
public Object getNegotiatedProperty(String propName)
{    return null;}
0
public void dispose()
{}
0
public int getPort()
{    return channel.socket().getLocalPort();}
0
public void run()
{        try {        while (true) {            try {                new Connection(channel.accept());            } catch (ClosedChannelException e) {                return;            } catch (IOException e) {                                throw new RuntimeException(e);            }        }    } finally {                try {            channel.close();        } catch (IOException e) {        }    }}
1
public void close()
{    this.interrupt();    group.interrupt();}
0
protected Transceiver getTransceiver(SocketChannel channel) throws IOException
{    return new SocketTransceiver(channel);}
0
public void run()
{    try {        try {            this.xc = getTransceiver(channel);            while (true) {                xc.writeBuffers(responder.respond(xc.readBuffers(), xc));            }        } catch (EOFException | ClosedChannelException e) {        } finally {            xc.close();        }    } catch (IOException e) {            }}
1
public static void main(String[] arg) throws Exception
{    Responder responder = new GenericResponder(Protocol.parse("{\"protocol\": \"X\"}")) {        @Override        public Object respond(Message message, Object request) throws Exception {            throw new AvroRemoteException("no messages!");        }    };    SocketServer server = new SocketServer(responder, new InetSocketAddress(0));    server.start();    System.out.println("server started on port: " + server.getPort());    server.join();}
0
public Object respond(Message message, Object request) throws Exception
{    throw new AvroRemoteException("no messages!");}
0
public String getRemoteName()
{    return channel.socket().getRemoteSocketAddress().toString();}
0
public synchronized List<ByteBuffer> readBuffers() throws IOException
{    List<ByteBuffer> buffers = new ArrayList<>();    while (true) {        header.clear();        while (header.hasRemaining()) {            if (channel.read(header) < 0)                throw new ClosedChannelException();        }        header.flip();        int length = header.getInt();        if (length == 0) {                        return buffers;        }        ByteBuffer buffer = ByteBuffer.allocate(length);        while (buffer.hasRemaining()) {            if (channel.read(buffer) < 0)                throw new ClosedChannelException();        }        buffer.flip();        buffers.add(buffer);    }}
0
public synchronized void writeBuffers(List<ByteBuffer> buffers) throws IOException
{    if (buffers == null)                return;    for (ByteBuffer buffer : buffers) {        if (buffer.limit() == 0)            continue;                writeLength(buffer.limit());        channel.write(buffer);    }        writeLength(0);}
0
private void writeLength(int length) throws IOException
{    header.clear();    header.putInt(length);    header.flip();    channel.write(header);}
0
public boolean isConnected()
{    return remote != null;}
0
public void setRemote(Protocol remote)
{    this.remote = remote;}
0
public Protocol getRemote()
{    return remote;}
0
public void close() throws IOException
{    if (channel.isOpen()) {                channel.close();    }}
1
public SpecificData getSpecificData()
{    return data;}
0
public Object invoke(Object proxy, Method method, Object[] args) throws Throwable
{    String name = method.getName();    switch(name) {        case "hashCode":            return hashCode();        case "equals":            Object obj = args[0];            return (proxy == obj) || (obj != null && Proxy.isProxyClass(obj.getClass()) && this.equals(Proxy.getInvocationHandler(obj)));        case "toString":            String protocol = "unknown";            String remote = "unknown";            Class<?>[] interfaces = proxy.getClass().getInterfaces();            if (interfaces.length > 0) {                try {                    protocol = Class.forName(interfaces[0].getName()).getSimpleName();                } catch (ClassNotFoundException e) {                }                InvocationHandler handler = Proxy.getInvocationHandler(proxy);                if (handler instanceof Requestor) {                    try {                        remote = ((Requestor) handler).getTransceiver().getRemoteName();                    } catch (IOException e) {                    }                }            }            return "Proxy[" + protocol + "," + remote + "]";        default:            try {                                Type[] parameterTypes = method.getParameterTypes();                if ((parameterTypes.length > 0) && (parameterTypes[parameterTypes.length - 1] instanceof Class) && Callback.class.isAssignableFrom(((Class<?>) parameterTypes[parameterTypes.length - 1]))) {                                        Object[] finalArgs = Arrays.copyOf(args, args.length - 1);                    Callback<?> callback = (Callback<?>) args[args.length - 1];                    request(method.getName(), finalArgs, callback);                    return null;                } else {                    return request(method.getName(), args);                }            } catch (Exception e) {                                for (Class<?> exceptionClass : method.getExceptionTypes()) {                    if (exceptionClass.isAssignableFrom(e.getClass())) {                        throw e;                    }                }                                if (e instanceof RuntimeException) {                    throw e;                }                                throw new AvroRuntimeException(e);            }    }}
0
protected DatumWriter<Object> getDatumWriter(Schema schema)
{    return new SpecificDatumWriter<>(schema, data);}
0
protected DatumReader<Object> getDatumReader(Schema schema)
{    return getDatumReader(schema, schema);}
0
protected DatumReader<Object> getDatumReader(Schema writer, Schema reader)
{    return new SpecificDatumReader<>(writer, reader, data);}
0
public void writeRequest(Schema schema, Object request, Encoder out) throws IOException
{    Object[] args = (Object[]) request;    int i = 0;    for (Schema.Field param : schema.getFields()) getDatumWriter(param.schema()).write(args[i++], out);}
0
public Object readResponse(Schema writer, Schema reader, Decoder in) throws IOException
{    return getDatumReader(writer, reader).read(null, in);}
0
public Exception readError(Schema writer, Schema reader, Decoder in) throws IOException
{    Object value = getDatumReader(writer, reader).read(null, in);    if (value instanceof Exception)        return (Exception) value;    return new AvroRuntimeException(value.toString());}
0
public static T getClient(Class<T> iface, Transceiver transceiver) throws IOException
{    return getClient(iface, transceiver, new SpecificData(iface.getClassLoader()));}
0
public static T getClient(Class<T> iface, Transceiver transceiver, SpecificData data) throws IOException
{    Protocol protocol = data.getProtocol(iface);    return (T) Proxy.newProxyInstance(data.getClassLoader(), new Class[] { iface }, new SpecificRequestor(protocol, transceiver, data));}
0
public static T getClient(Class<T> iface, SpecificRequestor requestor) throws IOException
{    return (T) Proxy.newProxyInstance(requestor.data.getClassLoader(), new Class[] { iface }, requestor);}
0
public static Protocol getRemote(Object proxy) throws IOException
{    return ((Requestor) Proxy.getInvocationHandler(proxy)).getRemote();}
0
public SpecificData getSpecificData()
{    return (SpecificData) getGenericData();}
0
protected DatumWriter<Object> getDatumWriter(Schema schema)
{    return new SpecificDatumWriter<>(schema, getSpecificData());}
0
protected DatumReader<Object> getDatumReader(Schema actual, Schema expected)
{    return new SpecificDatumReader<>(actual, expected, getSpecificData());}
0
public void writeError(Schema schema, Object error, Encoder out) throws IOException
{    getDatumWriter(schema).write(error, out);}
0
public Object respond(Message message, Object request) throws Exception
{    int numParams = message.getRequest().getFields().size();    Object[] params = new Object[numParams];    Class[] paramTypes = new Class[numParams];    int i = 0;    try {        for (Schema.Field param : message.getRequest().getFields()) {            params[i] = ((GenericRecord) request).get(param.name());            paramTypes[i] = getSpecificData().getClass(param.schema());            i++;        }        Method method = impl.getClass().getMethod(message.getName(), paramTypes);        method.setAccessible(true);        return method.invoke(impl, params);    } catch (InvocationTargetException e) {        Throwable error = e.getTargetException();        if (error instanceof Exception) {            throw (Exception) error;        } else {            throw new AvroRuntimeException(error);        }    } catch (NoSuchMethodException | IllegalAccessException e) {        throw new AvroRuntimeException(e);    }}
0
public void add(Float value)
{    super.add(value);    runningSum += value;    runningSumOfSquares += value * value;}
0
public float getMean()
{    if (totalCount == 0) {        return Float.NaN;    }    return runningSum / totalCount;}
0
public float getUnbiasedStdDev()
{    if (totalCount <= 1) {        return Float.NaN;    }    float mean = getMean();    return (float) Math.sqrt((runningSumOfSquares - totalCount * mean * mean) / (totalCount - 1));}
0
public int segment(T value)
{    Map.Entry<T, Integer> e = index.floorEntry(value);    if (e == null) {        throw new SegmenterException("Could not find bucket for: " + value);    }    return e.getValue();}
0
public int size()
{    return index.size();}
0
private String rangeAsString(T a, T b)
{    return String.format("[%s,%s)", a, b == null ? "infinity" : b);}
0
public ArrayList<String> getBoundaryLabels()
{    ArrayList<String> outArray = new ArrayList<>(index.keySet().size());    for (T obj : index.keySet()) {        outArray.add(obj.toString());    }    return outArray;}
0
public ArrayList<String> getBucketLabels()
{    ArrayList<String> outArray = new ArrayList<>(index.keySet().size());    Iterator<String> bucketsIt = this.getBuckets();    while (bucketsIt.hasNext()) {        outArray.add(bucketsIt.next());    }    return outArray;}
0
public Iterator<String> getBuckets()
{    return new Iterator<String>() {        Iterator<T> it = index.keySet().iterator();                T cur = it.next();        int pos = 0;        @Override        public boolean hasNext() {            return (pos < index.keySet().size());        }        @Override        public String next() {            pos = pos + 1;            T left = cur;            cur = it.hasNext() ? it.next() : null;            return rangeAsString(left, cur);        }        @Override        public void remove() {            throw new UnsupportedOperationException();        }    };}
0
public boolean hasNext()
{    return (pos < index.keySet().size());}
0
public String next()
{    pos = pos + 1;    T left = cur;    cur = it.hasNext() ? it.next() : null;    return rangeAsString(left, cur);}
0
public void remove()
{    throw new UnsupportedOperationException();}
0
public void add(T value)
{    int i = segmenter.segment(value);    counts[i]++;    totalCount++;    if (this.recentAdditions.size() > Histogram.MAX_HISTORY_SIZE) {        this.recentAdditions.pollLast();    }    this.recentAdditions.push(value);}
0
public int[] getHistogram()
{    return counts;}
0
public Segmenter<B, T> getSegmenter()
{    return this.segmenter;}
0
public List<T> getRecentAdditions()
{    return this.recentAdditions;}
0
public int getCount()
{    return totalCount;}
0
public String toString()
{    StringBuilder sb = new StringBuilder();    boolean first = true;    for (Entry<B> e : entries()) {        if (!first) {            sb.append(";");        } else {            first = false;        }        sb.append(e.bucket).append("=").append(e.count);    }    return sb.toString();}
0
public Iterator<Entry<B>> iterator()
{    return this;}
0
public boolean hasNext()
{    return i < segmenter.size();}
0
public Entry<B> next()
{    return new Entry<>(bucketNameIterator.next(), counts[i++]);}
0
public void remove()
{    throw new UnsupportedOperationException();}
0
public Iterable<Entry<B>> entries()
{    return new EntryIterator();}
0
public void add(Integer value)
{    super.add(value);    runningSum += value;    runningSumOfSquares += value * value;}
0
public float getMean()
{    if (totalCount == 0) {        return -1;    }    return runningSum / (float) totalCount;}
0
public float getUnbiasedStdDev()
{    if (totalCount <= 1) {        return -1;    }    float mean = getMean();    return (float) Math.sqrt((runningSumOfSquares - totalCount * mean * mean) / (float) (totalCount - 1));}
0
private int getPayloadSize(List<ByteBuffer> payload)
{    if (payload == null) {        return 0;    }    int size = 0;    for (ByteBuffer bb : payload) {        size = size + bb.limit();    }    return size;}
0
public void serverReceiveRequest(RPCContext context)
{    Stopwatch t = new Stopwatch(ticks);    t.start();    this.activeRpcs.put(context, t);    synchronized (receivePayloads) {        IntegerHistogram<?> h = receivePayloads.get(context.getMessage());        if (h == null) {            h = createNewIntegerHistogram();            receivePayloads.put(context.getMessage(), h);        }        h.add(getPayloadSize(context.getRequestPayload()));    }}
0
public void serverSendResponse(RPCContext context)
{    Stopwatch t = this.activeRpcs.remove(context);    t.stop();    publish(context, t);    synchronized (sendPayloads) {        IntegerHistogram<?> h = sendPayloads.get(context.getMessage());        if (h == null) {            h = createNewIntegerHistogram();            sendPayloads.put(context.getMessage(), h);        }        h.add(getPayloadSize(context.getResponsePayload()));    }}
0
public void clientSendRequest(RPCContext context)
{    Stopwatch t = new Stopwatch(ticks);    t.start();    this.activeRpcs.put(context, t);    synchronized (sendPayloads) {        IntegerHistogram<?> h = sendPayloads.get(context.getMessage());        if (h == null) {            h = createNewIntegerHistogram();            sendPayloads.put(context.getMessage(), h);        }        h.add(getPayloadSize(context.getRequestPayload()));    }}
0
public void clientReceiveResponse(RPCContext context)
{    Stopwatch t = this.activeRpcs.remove(context);    t.stop();    publish(context, t);    synchronized (receivePayloads) {        IntegerHistogram<?> h = receivePayloads.get(context.getMessage());        if (h == null) {            h = createNewIntegerHistogram();            receivePayloads.put(context.getMessage(), h);        }        h.add(getPayloadSize(context.getRequestPayload()));    }}
0
private void publish(RPCContext context, Stopwatch t)
{    Message message = context.getMessage();    if (message == null)        throw new IllegalArgumentException();    synchronized (methodTimings) {        FloatHistogram<?> h = methodTimings.get(context.getMessage());        if (h == null) {            h = createNewFloatHistogram();            methodTimings.put(context.getMessage(), h);        }        h.add(nanosToMillis(t.elapsedNanos()));    }}
0
private FloatHistogram<?> createNewFloatHistogram()
{    return new FloatHistogram<>(floatSegmenter);}
0
private IntegerHistogram<?> createNewIntegerHistogram()
{    return new IntegerHistogram<>(integerSegmenter);}
0
 static float nanosToMillis(long elapsedNanos)
{    return elapsedNanos / 1000000.0f;}
0
public ArrayList<HashMap<String, String>> getCharts()
{    return this.charts;}
0
public String getname()
{    return this.name;}
0
public int getNumCalls()
{    return this.numCalls;}
0
protected static List<String> escapeStringArray(List<String> input)
{    for (int i = 0; i < input.size(); i++) {        input.set(i, "\"" + input.get(i).replace("\"", "\\\"") + "\"");    }    return input;}
0
protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException
{    resp.setContentType("text/html");    String url = req.getRequestURL().toString();    String[] parts = url.split("//")[1].split("/");    try {        writeStats(resp.getWriter());    } catch (Exception e) {        e.printStackTrace();    }}
0
public void writeStats(Writer w) throws IOException
{    VelocityContext context = new VelocityContext();    context.put("title", "Avro RPC Stats");        ArrayList<String> rpcs = new ArrayList<>();    ArrayList<RenderableMessage> messages = new ArrayList<>();    for (Entry<RPCContext, Stopwatch> rpc : this.statsPlugin.activeRpcs.entrySet()) {        rpcs.add(renderActiveRpc(rpc.getKey(), rpc.getValue()));    }        Set<Message> keys = null;    synchronized (this.statsPlugin.methodTimings) {        keys = this.statsPlugin.methodTimings.keySet();        for (Message m : keys) {            messages.add(renderMethod(m));        }    }    context.put("inFlightRpcs", rpcs);    context.put("messages", messages);    context.put("currTime", FORMATTER.format(new Date()));    context.put("startupTime", FORMATTER.format(statsPlugin.startupTime));    Template t;    try {        t = velocityEngine.getTemplate("org/apache/avro/ipc/stats/templates/statsview.vm");    } catch (Exception e) {        throw new IOException();    }    t.merge(context, w);}
0
private String renderActiveRpc(RPCContext rpc, Stopwatch stopwatch) throws IOException
{    String out = new String();    out += rpc.getMessage().getName() + ": " + formatMillis(StatsPlugin.nanosToMillis(stopwatch.elapsedNanos()));    return out;}
0
private RenderableMessage renderMethod(Message message)
{    RenderableMessage out = new RenderableMessage(message.getName());    synchronized (this.statsPlugin.methodTimings) {        FloatHistogram<?> hist = this.statsPlugin.methodTimings.get(message);        out.numCalls = hist.getCount();        HashMap<String, String> latencyBar = new HashMap<>();                latencyBar.put("type", "bar");        latencyBar.put("title", "All-Time Latency");        latencyBar.put("units", "ms");        latencyBar.put("numCalls", Integer.toString(hist.getCount()));        latencyBar.put("avg", Float.toString(hist.getMean()));        latencyBar.put("stdDev", Float.toString(hist.getUnbiasedStdDev()));        latencyBar.put("labelStr", Arrays.toString(hist.getSegmenter().getBoundaryLabels().toArray()));        latencyBar.put("boundaryStr", Arrays.toString(escapeStringArray(hist.getSegmenter().getBucketLabels()).toArray()));        latencyBar.put("dataStr", Arrays.toString(hist.getHistogram()));        out.charts.add(latencyBar);        HashMap<String, String> latencyDot = new HashMap<>();        latencyDot.put("title", "Latency");        latencyDot.put("type", "dot");        latencyDot.put("dataStr", Arrays.toString(hist.getRecentAdditions().toArray()));        out.charts.add(latencyDot);    }    synchronized (this.statsPlugin.sendPayloads) {        IntegerHistogram<?> hist = this.statsPlugin.sendPayloads.get(message);        HashMap<String, String> latencyBar = new HashMap<>();                latencyBar.put("type", "bar");        latencyBar.put("title", "All-Time Send Payload");        latencyBar.put("units", "ms");        latencyBar.put("numCalls", Integer.toString(hist.getCount()));        latencyBar.put("avg", Float.toString(hist.getMean()));        latencyBar.put("stdDev", Float.toString(hist.getUnbiasedStdDev()));        latencyBar.put("labelStr", Arrays.toString(hist.getSegmenter().getBoundaryLabels().toArray()));        latencyBar.put("boundaryStr", Arrays.toString(escapeStringArray(hist.getSegmenter().getBucketLabels()).toArray()));        latencyBar.put("dataStr", Arrays.toString(hist.getHistogram()));        out.charts.add(latencyBar);        HashMap<String, String> latencyDot = new HashMap<>();        latencyDot.put("title", "Send Payload");        latencyDot.put("type", "dot");        latencyDot.put("dataStr", Arrays.toString(hist.getRecentAdditions().toArray()));        out.charts.add(latencyDot);    }    synchronized (this.statsPlugin.receivePayloads) {        IntegerHistogram<?> hist = this.statsPlugin.receivePayloads.get(message);        HashMap<String, String> latencyBar = new HashMap<>();                latencyBar.put("type", "bar");        latencyBar.put("title", "All-Time Receive Payload");        latencyBar.put("units", "ms");        latencyBar.put("numCalls", Integer.toString(hist.getCount()));        latencyBar.put("avg", Float.toString(hist.getMean()));        latencyBar.put("stdDev", Float.toString(hist.getUnbiasedStdDev()));        latencyBar.put("labelStr", Arrays.toString(hist.getSegmenter().getBoundaryLabels().toArray()));        latencyBar.put("boundaryStr", Arrays.toString(escapeStringArray(hist.getSegmenter().getBucketLabels()).toArray()));        latencyBar.put("dataStr", Arrays.toString(hist.getHistogram()));        out.charts.add(latencyBar);        HashMap<String, String> latencyDot = new HashMap<>();        latencyDot.put("title", "Recv Payload");        latencyDot.put("type", "dot");        latencyDot.put("dataStr", Arrays.toString(hist.getRecentAdditions().toArray()));        out.charts.add(latencyDot);    }    return out;}
0
private CharSequence formatMillis(float millis)
{    return String.format("%.0fms", millis);}
0
public long elapsedNanos()
{    if (running) {        return this.ticks.ticks() - start;    } else {        if (elapsed == -1)            throw new IllegalStateException();        return elapsed;    }}
0
public void start()
{    if (running)        throw new IllegalStateException();    start = ticks.ticks();    running = true;}
0
public void stop()
{    if (!running)        throw new IllegalStateException();    elapsed = ticks.ticks() - start;    running = false;}
0
public long ticks()
{    return System.nanoTime();}
0
public void lockChannel()
{    channelLock.lock();}
0
public void unlockChannel()
{    if (channelLock.isHeldByCurrentThread()) {        channelLock.unlock();    }}
0
public List<ByteBuffer> transceive(List<ByteBuffer> request) throws IOException
{    lockChannel();    try {        writeBuffers(request);        return readBuffers();    } finally {        unlockChannel();    }}
0
public void transceive(List<ByteBuffer> request, Callback<List<ByteBuffer>> callback) throws IOException
{        try {        List<ByteBuffer> response = transceive(request);        callback.handleResult(response);    } catch (IOException e) {        callback.handleError(e);    }}
0
public boolean isConnected()
{    return false;}
0
public void setRemote(Protocol protocol)
{}
0
public Protocol getRemote()
{    throw new IllegalStateException("Not connected.");}
0
public void close() throws IOException
{}
0
public void testEsc()
{    assertEquals("\\\"", SpecificCompiler.javaEscape("\""));}
0
public void testMakePath()
{    SpecificCompiler compiler = new SpecificCompiler();    assertEquals("foo/bar/Baz.java".replace("/", File.separator), compiler.makePath("Baz", "foo.bar"));    assertEquals("baz.java", compiler.makePath("baz", ""));}
0
public void testPrimitiveSchemaGeneratesNothing()
{    assertEquals(0, new SpecificCompiler(new Schema.Parser().parse("\"double\"")).compile().size());}
0
public void testSimpleEnumSchema() throws IOException
{    Collection<OutputFile> outputs = new SpecificCompiler(new Schema.Parser().parse(TestSchema.BASIC_ENUM_SCHEMA)).compile();    assertEquals(1, outputs.size());    OutputFile o = outputs.iterator().next();    assertEquals(o.path, "Test.java");    assertTrue(o.contents.contains("public enum Test"));    assertCompilesWithJavaCompiler(new File(INPUT_DIR.getRoot(), name.getMethodName()), outputs);}
0
public void testMangleIfReserved()
{    assertEquals("foo", SpecificCompiler.mangle("foo"));    assertEquals("goto$", SpecificCompiler.mangle("goto"));}
0
public void testManglingForProtocols() throws IOException
{    Collection<OutputFile> outputs = new SpecificCompiler(Protocol.parse(PROTOCOL)).compile();    Iterator<OutputFile> i = outputs.iterator();    String errType = i.next().contents;    String protocol = i.next().contents;    assertTrue(errType.contains("public class finally$ extends org.apache.avro.specific.SpecificExceptionBase"));    assertTrue(errType.contains("private boolean catch$;"));    assertTrue(protocol.contains("java.lang.CharSequence goto$(java.lang.CharSequence break$)"));    assertTrue(protocol.contains("public interface default$"));    assertTrue(protocol.contains(" finally$"));    assertCompilesWithJavaCompiler(new File(INPUT_DIR.getRoot(), name.getMethodName()), outputs);}
0
public void testManglingForRecords() throws IOException
{    Collection<OutputFile> outputs = new SpecificCompiler(new Schema.Parser().parse(SCHEMA)).compile();    assertEquals(1, outputs.size());    String contents = outputs.iterator().next().contents;    assertTrue(contents.contains("private java.lang.CharSequence package$;"));    assertTrue(contents.contains("class volatile$ extends"));    assertTrue(contents.contains("volatile$ short$;"));    assertCompilesWithJavaCompiler(new File(INPUT_DIR.getRoot(), name.getMethodName()), outputs);}
0
public void testManglingForEnums() throws IOException
{    String enumSchema = "" + "{ \"name\": \"instanceof\", \"type\": \"enum\"," + "  \"symbols\": [\"new\", \"super\", \"switch\"] }";    Collection<OutputFile> outputs = new SpecificCompiler(new Schema.Parser().parse(enumSchema)).compile();    assertEquals(1, outputs.size());    String contents = outputs.iterator().next().contents;    assertTrue(contents.contains("new$"));    assertCompilesWithJavaCompiler(new File(INPUT_DIR.getRoot(), name.getMethodName()), outputs);}
0
public void testSchemaSplit() throws IOException
{    SpecificCompiler compiler = new SpecificCompiler(new Schema.Parser().parse(SCHEMA));    compiler.maxStringChars = 10;    Collection<OutputFile> files = compiler.compile();    assertCompilesWithJavaCompiler(new File(INPUT_DIR.getRoot(), name.getMethodName()), files);}
0
public void testProtocolSplit() throws IOException
{    SpecificCompiler compiler = new SpecificCompiler(Protocol.parse(PROTOCOL));    compiler.maxStringChars = 10;    Collection<OutputFile> files = compiler.compile();    assertCompilesWithJavaCompiler(new File(INPUT_DIR.getRoot(), name.getMethodName()), files);}
0
public void testSchemaWithDocs()
{    Collection<OutputFile> outputs = new SpecificCompiler(new Schema.Parser().parse(TestSchema.SCHEMA_WITH_DOC_TAGS)).compile();    assertEquals(3, outputs.size());    int count = 0;    for (OutputFile o : outputs) {        if (o.path.endsWith("outer_record.java")) {            count++;            assertTrue(o.contents.contains("/** This is not a world record. */"));            assertTrue(o.contents.contains("/** Inner Fixed */"));            assertTrue(o.contents.contains("/** Inner Enum */"));            assertTrue(o.contents.contains("/** Inner String */"));        }        if (o.path.endsWith("very_inner_fixed.java")) {            count++;            assertTrue(o.contents.contains("/** Very Inner Fixed */"));            assertTrue(o.contents.contains("@org.apache.avro.specific.FixedSize(1)"));        }        if (o.path.endsWith("very_inner_enum.java")) {            count++;            assertTrue(o.contents.contains("/** Very Inner Enum */"));        }    }    assertEquals(3, count);}
0
public void testProtocolWithDocs() throws IOException
{    Protocol protocol = TestProtocolParsing.getSimpleProtocol();    Collection<OutputFile> out = new SpecificCompiler(protocol).compile();    assertEquals(6, out.size());    int count = 0;    for (OutputFile o : out) {        if (o.path.endsWith("Simple.java")) {            count++;            assertTrue(o.contents.contains("/** Protocol used for testing. */"));            assertTrue(o.contents.contains("* Send a greeting"));        }    }    assertEquals("Missed generated protocol!", 1, count);}
0
public void testNeedCompile() throws IOException, InterruptedException
{    String schema = "" + "{ \"name\": \"Foo\", \"type\": \"record\", " + "  \"fields\": [ {\"name\": \"package\", \"type\": \"string\" }," + "                {\"name\": \"short\", \"type\": \"Foo\" } ] }";    File inputFile = new File(INPUT_DIR.getRoot().getPath(), "input.avsc");    try (FileWriter fw = new FileWriter(inputFile)) {        fw.write(schema);    }    File outputDir = OUTPUT_DIR.getRoot();    File outputFile = new File(outputDir, "Foo.java");    outputFile.delete();    assertTrue(!outputFile.exists());    outputDir.delete();    assertTrue(!outputDir.exists());    SpecificCompiler.compileSchema(inputFile, outputDir);    assertTrue(outputDir.exists());    assertTrue(outputFile.exists());    long lastModified = outputFile.lastModified();        Thread.sleep(1000);    SpecificCompiler.compileSchema(inputFile, outputDir);    assertEquals(lastModified, outputFile.lastModified());    try (FileWriter fw = new FileWriter(inputFile)) {        fw.write(schema);    }    SpecificCompiler.compileSchema(inputFile, outputDir);    assertTrue(lastModified != outputFile.lastModified());}
0
private Schema createRecord(String name, boolean isError, Field... fields)
{    Schema record = Schema.createRecord(name, null, null, isError);    record.setFields(Arrays.asList(fields));    return record;}
0
public void generateGetMethod()
{    Field height = new Field("height", Schema.create(Type.INT), null, null);    Field Height = new Field("Height", Schema.create(Type.INT), null, null);    Field height_and_width = new Field("height_and_width", Schema.create(Type.STRING), null, null);    Field message = new Field("message", Schema.create(Type.STRING), null, null);    Field Message = new Field("Message", Schema.create(Type.STRING), null, null);    Field cause = new Field("cause", Schema.create(Type.STRING), null, null);    Field clasz = new Field("class", Schema.create(Type.STRING), null, null);    Field schema = new Field("schema", Schema.create(Type.STRING), null, null);    Field Schema$ = new Field("Schema", Schema.create(Type.STRING), null, null);    assertEquals("getHeight", SpecificCompiler.generateGetMethod(createRecord("test", false, height), height));    assertEquals("getHeightAndWidth", SpecificCompiler.generateGetMethod(createRecord("test", false, height_and_width), height_and_width));    assertEquals("getMessage", SpecificCompiler.generateGetMethod(createRecord("test", false, message), message));    message = new Field("message", Schema.create(Type.STRING), null, null);    assertEquals("getMessage$", SpecificCompiler.generateGetMethod(createRecord("test", true, message), message));    assertEquals("getCause", SpecificCompiler.generateGetMethod(createRecord("test", false, cause), cause));    cause = new Field("cause", Schema.create(Type.STRING), null, null);    assertEquals("getCause$", SpecificCompiler.generateGetMethod(createRecord("test", true, cause), cause));    assertEquals("getClass$", SpecificCompiler.generateGetMethod(createRecord("test", false, clasz), clasz));    clasz = new Field("class", Schema.create(Type.STRING), null, null);    assertEquals("getClass$", SpecificCompiler.generateGetMethod(createRecord("test", true, clasz), clasz));    assertEquals("getSchema$", SpecificCompiler.generateGetMethod(createRecord("test", false, schema), schema));    schema = new Field("schema", Schema.create(Type.STRING), null, null);    assertEquals("getSchema$", SpecificCompiler.generateGetMethod(createRecord("test", true, schema), schema));    height = new Field("height", Schema.create(Type.INT), null, null);    Height = new Field("Height", Schema.create(Type.INT), null, null);    assertEquals("getHeight", SpecificCompiler.generateGetMethod(createRecord("test", false, Height), Height));    height = new Field("height", Schema.create(Type.INT), null, null);    Height = new Field("Height", Schema.create(Type.INT), null, null);    assertEquals("getHeight$0", SpecificCompiler.generateGetMethod(createRecord("test", false, height, Height), height));    height = new Field("height", Schema.create(Type.INT), null, null);    Height = new Field("Height", Schema.create(Type.INT), null, null);    assertEquals("getHeight$1", SpecificCompiler.generateGetMethod(createRecord("test", false, height, Height), Height));    message = new Field("message", Schema.create(Type.STRING), null, null);    Message = new Field("Message", Schema.create(Type.STRING), null, null);    assertEquals("getMessage$", SpecificCompiler.generateGetMethod(createRecord("test", true, Message), Message));    message = new Field("message", Schema.create(Type.STRING), null, null);    Message = new Field("Message", Schema.create(Type.STRING), null, null);    assertEquals("getMessage$0", SpecificCompiler.generateGetMethod(createRecord("test", true, message, Message), message));    message = new Field("message", Schema.create(Type.STRING), null, null);    Message = new Field("Message", Schema.create(Type.STRING), null, null);    assertEquals("getMessage$1", SpecificCompiler.generateGetMethod(createRecord("test", true, message, Message), Message));    schema = new Field("schema", Schema.create(Type.STRING), null, null);    Schema$ = new Field("Schema", Schema.create(Type.STRING), null, null);    assertEquals("getSchema$", SpecificCompiler.generateGetMethod(createRecord("test", false, Schema$), Schema$));    schema = new Field("schema", Schema.create(Type.STRING), null, null);    Schema$ = new Field("Schema", Schema.create(Type.STRING), null, null);    assertEquals("getSchema$0", SpecificCompiler.generateGetMethod(createRecord("test", false, schema, Schema$), schema));    schema = new Field("schema", Schema.create(Type.STRING), null, null);    Schema$ = new Field("Schema", Schema.create(Type.STRING), null, null);    assertEquals("getSchema$1", SpecificCompiler.generateGetMethod(createRecord("test", false, schema, Schema$), Schema$));}
0
public void generateSetMethod()
{    Field height = new Field("height", Schema.create(Type.INT), null, null);    Field Height = new Field("Height", Schema.create(Type.INT), null, null);    Field height_and_width = new Field("height_and_width", Schema.create(Type.STRING), null, null);    Field message = new Field("message", Schema.create(Type.STRING), null, null);    Field Message = new Field("Message", Schema.create(Type.STRING), null, null);    Field cause = new Field("cause", Schema.create(Type.STRING), null, null);    Field clasz = new Field("class", Schema.create(Type.STRING), null, null);    Field schema = new Field("schema", Schema.create(Type.STRING), null, null);    Field Schema$ = new Field("Schema", Schema.create(Type.STRING), null, null);    assertEquals("setHeight", SpecificCompiler.generateSetMethod(createRecord("test", false, height), height));    assertEquals("setHeightAndWidth", SpecificCompiler.generateSetMethod(createRecord("test", false, height_and_width), height_and_width));    assertEquals("setMessage", SpecificCompiler.generateSetMethod(createRecord("test", false, message), message));    message = new Field("message", Schema.create(Type.STRING), null, null);    assertEquals("setMessage$", SpecificCompiler.generateSetMethod(createRecord("test", true, message), message));    assertEquals("setCause", SpecificCompiler.generateSetMethod(createRecord("test", false, cause), cause));    cause = new Field("cause", Schema.create(Type.STRING), null, null);    assertEquals("setCause$", SpecificCompiler.generateSetMethod(createRecord("test", true, cause), cause));    assertEquals("setClass$", SpecificCompiler.generateSetMethod(createRecord("test", false, clasz), clasz));    clasz = new Field("class", Schema.create(Type.STRING), null, null);    assertEquals("setClass$", SpecificCompiler.generateSetMethod(createRecord("test", true, clasz), clasz));    assertEquals("setSchema$", SpecificCompiler.generateSetMethod(createRecord("test", false, schema), schema));    schema = new Field("schema", Schema.create(Type.STRING), null, null);    assertEquals("setSchema$", SpecificCompiler.generateSetMethod(createRecord("test", true, schema), schema));    height = new Field("height", Schema.create(Type.INT), null, null);    Height = new Field("Height", Schema.create(Type.INT), null, null);    assertEquals("setHeight", SpecificCompiler.generateSetMethod(createRecord("test", false, Height), Height));    height = new Field("height", Schema.create(Type.INT), null, null);    Height = new Field("Height", Schema.create(Type.INT), null, null);    assertEquals("setHeight$0", SpecificCompiler.generateSetMethod(createRecord("test", false, height, Height), height));    height = new Field("height", Schema.create(Type.INT), null, null);    Height = new Field("Height", Schema.create(Type.INT), null, null);    assertEquals("setHeight$1", SpecificCompiler.generateSetMethod(createRecord("test", false, height, Height), Height));    message = new Field("message", Schema.create(Type.STRING), null, null);    Message = new Field("Message", Schema.create(Type.STRING), null, null);    assertEquals("setMessage$", SpecificCompiler.generateSetMethod(createRecord("test", true, Message), Message));    message = new Field("message", Schema.create(Type.STRING), null, null);    Message = new Field("Message", Schema.create(Type.STRING), null, null);    assertEquals("setMessage$0", SpecificCompiler.generateSetMethod(createRecord("test", true, message, Message), message));    message = new Field("message", Schema.create(Type.STRING), null, null);    Message = new Field("Message", Schema.create(Type.STRING), null, null);    assertEquals("setMessage$1", SpecificCompiler.generateSetMethod(createRecord("test", true, message, Message), Message));    schema = new Field("schema", Schema.create(Type.STRING), null, null);    Schema$ = new Field("Schema", Schema.create(Type.STRING), null, null);    assertEquals("setSchema$", SpecificCompiler.generateSetMethod(createRecord("test", false, Schema$), Schema$));    schema = new Field("schema", Schema.create(Type.STRING), null, null);    Schema$ = new Field("Schema", Schema.create(Type.STRING), null, null);    assertEquals("setSchema$0", SpecificCompiler.generateSetMethod(createRecord("test", false, schema, Schema$), schema));    schema = new Field("schema", Schema.create(Type.STRING), null, null);    Schema$ = new Field("Schema", Schema.create(Type.STRING), null, null);    assertEquals("setSchema$1", SpecificCompiler.generateSetMethod(createRecord("test", false, schema, Schema$), Schema$));}
0
public void generateHasMethod()
{    Field height = new Field("height", Schema.create(Type.INT), null, null);    Field Height = new Field("Height", Schema.create(Type.INT), null, null);    Field height_and_width = new Field("height_and_width", Schema.create(Type.STRING), null, null);    Field message = new Field("message", Schema.create(Type.STRING), null, null);    Field Message = new Field("Message", Schema.create(Type.STRING), null, null);    Field cause = new Field("cause", Schema.create(Type.STRING), null, null);    Field clasz = new Field("class", Schema.create(Type.STRING), null, null);    Field schema = new Field("schema", Schema.create(Type.STRING), null, null);    Field Schema$ = new Field("Schema", Schema.create(Type.STRING), null, null);    assertEquals("hasHeight", SpecificCompiler.generateHasMethod(createRecord("test", false, height), height));    assertEquals("hasHeightAndWidth", SpecificCompiler.generateHasMethod(createRecord("test", false, height_and_width), height_and_width));    assertEquals("hasMessage", SpecificCompiler.generateHasMethod(createRecord("test", false, message), message));    message = new Field("message", Schema.create(Type.STRING), null, null);    assertEquals("hasMessage$", SpecificCompiler.generateHasMethod(createRecord("test", true, message), message));    assertEquals("hasCause", SpecificCompiler.generateHasMethod(createRecord("test", false, cause), cause));    cause = new Field("cause", Schema.create(Type.STRING), null, null);    assertEquals("hasCause$", SpecificCompiler.generateHasMethod(createRecord("test", true, cause), cause));    assertEquals("hasClass$", SpecificCompiler.generateHasMethod(createRecord("test", false, clasz), clasz));    clasz = new Field("class", Schema.create(Type.STRING), null, null);    assertEquals("hasClass$", SpecificCompiler.generateHasMethod(createRecord("test", true, clasz), clasz));    assertEquals("hasSchema$", SpecificCompiler.generateHasMethod(createRecord("test", false, schema), schema));    schema = new Field("schema", Schema.create(Type.STRING), null, null);    assertEquals("hasSchema$", SpecificCompiler.generateHasMethod(createRecord("test", true, schema), schema));    height = new Field("height", Schema.create(Type.INT), null, null);    Height = new Field("Height", Schema.create(Type.INT), null, null);    assertEquals("hasHeight", SpecificCompiler.generateHasMethod(createRecord("test", false, Height), Height));    height = new Field("height", Schema.create(Type.INT), null, null);    Height = new Field("Height", Schema.create(Type.INT), null, null);    assertEquals("hasHeight$0", SpecificCompiler.generateHasMethod(createRecord("test", false, height, Height), height));    height = new Field("height", Schema.create(Type.INT), null, null);    Height = new Field("Height", Schema.create(Type.INT), null, null);    assertEquals("hasHeight$1", SpecificCompiler.generateHasMethod(createRecord("test", false, height, Height), Height));    message = new Field("message", Schema.create(Type.STRING), null, null);    Message = new Field("Message", Schema.create(Type.STRING), null, null);    assertEquals("hasMessage$", SpecificCompiler.generateHasMethod(createRecord("test", true, Message), Message));    message = new Field("message", Schema.create(Type.STRING), null, null);    Message = new Field("Message", Schema.create(Type.STRING), null, null);    assertEquals("hasMessage$0", SpecificCompiler.generateHasMethod(createRecord("test", true, message, Message), message));    message = new Field("message", Schema.create(Type.STRING), null, null);    Message = new Field("Message", Schema.create(Type.STRING), null, null);    assertEquals("hasMessage$1", SpecificCompiler.generateHasMethod(createRecord("test", true, message, Message), Message));    schema = new Field("schema", Schema.create(Type.STRING), null, null);    Schema$ = new Field("Schema", Schema.create(Type.STRING), null, null);    assertEquals("hasSchema$", SpecificCompiler.generateHasMethod(createRecord("test", false, Schema$), Schema$));    schema = new Field("schema", Schema.create(Type.STRING), null, null);    Schema$ = new Field("Schema", Schema.create(Type.STRING), null, null);    assertEquals("hasSchema$0", SpecificCompiler.generateHasMethod(createRecord("test", false, schema, Schema$), schema));    schema = new Field("schema", Schema.create(Type.STRING), null, null);    Schema$ = new Field("Schema", Schema.create(Type.STRING), null, null);    assertEquals("hasSchema$1", SpecificCompiler.generateHasMethod(createRecord("test", false, schema, Schema$), Schema$));}
0
public void generateClearMethod()
{    Field height = new Field("height", Schema.create(Type.INT), null, null);    Field Height = new Field("Height", Schema.create(Type.INT), null, null);    Field height_and_width = new Field("height_and_width", Schema.create(Type.STRING), null, null);    Field message = new Field("message", Schema.create(Type.STRING), null, null);    Field Message = new Field("Message", Schema.create(Type.STRING), null, null);    Field cause = new Field("cause", Schema.create(Type.STRING), null, null);    Field clasz = new Field("class", Schema.create(Type.STRING), null, null);    Field schema = new Field("schema", Schema.create(Type.STRING), null, null);    Field Schema$ = new Field("Schema", Schema.create(Type.STRING), null, null);    assertEquals("clearHeight", SpecificCompiler.generateClearMethod(createRecord("test", false, height), height));    assertEquals("clearHeightAndWidth", SpecificCompiler.generateClearMethod(createRecord("test", false, height_and_width), height_and_width));    assertEquals("clearMessage", SpecificCompiler.generateClearMethod(createRecord("test", false, message), message));    message = new Field("message", Schema.create(Type.STRING), null, null);    assertEquals("clearMessage$", SpecificCompiler.generateClearMethod(createRecord("test", true, message), message));    assertEquals("clearCause", SpecificCompiler.generateClearMethod(createRecord("test", false, cause), cause));    cause = new Field("cause", Schema.create(Type.STRING), null, null);    assertEquals("clearCause$", SpecificCompiler.generateClearMethod(createRecord("test", true, cause), cause));    assertEquals("clearClass$", SpecificCompiler.generateClearMethod(createRecord("test", false, clasz), clasz));    clasz = new Field("class", Schema.create(Type.STRING), null, null);    assertEquals("clearClass$", SpecificCompiler.generateClearMethod(createRecord("test", true, clasz), clasz));    assertEquals("clearSchema$", SpecificCompiler.generateClearMethod(createRecord("test", false, schema), schema));    schema = new Field("schema", Schema.create(Type.STRING), null, null);    assertEquals("clearSchema$", SpecificCompiler.generateClearMethod(createRecord("test", true, schema), schema));    height = new Field("height", Schema.create(Type.INT), null, null);    Height = new Field("Height", Schema.create(Type.INT), null, null);    assertEquals("clearHeight", SpecificCompiler.generateClearMethod(createRecord("test", false, Height), Height));    height = new Field("height", Schema.create(Type.INT), null, null);    Height = new Field("Height", Schema.create(Type.INT), null, null);    assertEquals("clearHeight$0", SpecificCompiler.generateClearMethod(createRecord("test", false, height, Height), height));    height = new Field("height", Schema.create(Type.INT), null, null);    Height = new Field("Height", Schema.create(Type.INT), null, null);    assertEquals("clearHeight$1", SpecificCompiler.generateClearMethod(createRecord("test", false, height, Height), Height));    message = new Field("message", Schema.create(Type.STRING), null, null);    Message = new Field("Message", Schema.create(Type.STRING), null, null);    assertEquals("clearMessage$", SpecificCompiler.generateClearMethod(createRecord("test", true, Message), Message));    message = new Field("message", Schema.create(Type.STRING), null, null);    Message = new Field("Message", Schema.create(Type.STRING), null, null);    assertEquals("clearMessage$0", SpecificCompiler.generateClearMethod(createRecord("test", true, message, Message), message));    message = new Field("message", Schema.create(Type.STRING), null, null);    Message = new Field("Message", Schema.create(Type.STRING), null, null);    assertEquals("clearMessage$1", SpecificCompiler.generateClearMethod(createRecord("test", true, message, Message), Message));    schema = new Field("schema", Schema.create(Type.STRING), null, null);    Schema$ = new Field("Schema", Schema.create(Type.STRING), null, null);    assertEquals("clearSchema$", SpecificCompiler.generateClearMethod(createRecord("test", false, Schema$), Schema$));    schema = new Field("schema", Schema.create(Type.STRING), null, null);    Schema$ = new Field("Schema", Schema.create(Type.STRING), null, null);    assertEquals("clearSchema$0", SpecificCompiler.generateClearMethod(createRecord("test", false, schema, Schema$), schema));    schema = new Field("schema", Schema.create(Type.STRING), null, null);    Schema$ = new Field("Schema", Schema.create(Type.STRING), null, null);    assertEquals("clearSchema$1", SpecificCompiler.generateClearMethod(createRecord("test", false, schema, Schema$), Schema$));}
0
public void testAnnotations() throws Exception
{        assertNotNull(Simple.class.getAnnotation(TestAnnotation.class));        assertNotNull(TestRecord.class.getAnnotation(TestAnnotation.class));        assertNotNull(MD5.class.getAnnotation(TestAnnotation.class));        assertNotNull(Kind.class.getAnnotation(TestAnnotation.class));        assertNotNull(TestRecord.class.getField("name").getAnnotation(TestAnnotation.class));        assertNotNull(Simple.class.getMethod("ack").getAnnotation(TestAnnotation.class));}
0
public void testAliases() throws IOException
{    Schema s = new Schema.Parser().parse("{\"name\":\"X\",\"type\":\"record\",\"aliases\":[\"Y\"],\"fields\":[" + "{\"name\":\"f\",\"type\":\"int\",\"aliases\":[\"g\"]}]}");    SpecificCompiler compiler = new SpecificCompiler(s);    compiler.setStringType(StringType.valueOf("String"));    Collection<OutputFile> outputs = compiler.compile();    assertEquals(1, outputs.size());    OutputFile o = outputs.iterator().next();    assertEquals(o.path, "X.java");    assertTrue(o.contents.contains("[\\\"Y\\\"]"));    assertTrue(o.contents.contains("[\\\"g\\\"]"));}
0
public static void assertCompiles(File dstDir, Schema schema, boolean useJavaCompiler) throws IOException
{    Collection<OutputFile> outputs = new SpecificCompiler(schema).compile();    assertNotNull(outputs);    if (useJavaCompiler) {        assertCompilesWithJavaCompiler(dstDir, outputs);    }}
0
public static void assertCompiles(File dstDir, Protocol protocol, boolean useJavaCompiler) throws IOException
{    Collection<OutputFile> outputs = new SpecificCompiler(protocol).compile();    assertNotNull(outputs);    if (useJavaCompiler) {        assertCompilesWithJavaCompiler(dstDir, outputs);    }}
0
 static void assertCompilesWithJavaCompiler(File dstDir, Collection<OutputFile> outputs) throws IOException
{    if (outputs.isEmpty()) {                return;    }    List<File> javaFiles = new ArrayList<>();    for (OutputFile o : outputs) {        javaFiles.add(o.writeToDestination(null, dstDir));    }    JavaCompiler compiler = ToolProvider.getSystemJavaCompiler();    StandardJavaFileManager fileManager = compiler.getStandardFileManager(null, null, null);    CompilationTask cTask = compiler.getTask(null, fileManager, null, null, null, fileManager.getJavaFileObjects(javaFiles.toArray(new File[0])));    assertTrue(cTask.call());}
0
public static void printDir()
{    System.out.println("Reading data files from directory: " + DATAFILE_DIR.getAbsolutePath());}
0
public void testGeneratedGeneric() throws IOException
{    System.out.println("Reading with generic:");    DatumReaderProvider<Object> provider = GenericDatumReader::new;    readFiles(provider);}
0
public void testGeneratedSpecific() throws IOException
{    System.out.println("Reading with specific:");    DatumReaderProvider<Interop> provider = SpecificDatumReader::new;    readFiles(provider);}
0
private void readFiles(DatumReaderProvider<T> provider) throws IOException
{    for (File f : Objects.requireNonNull(DATAFILE_DIR.listFiles())) {        System.out.println("Reading: " + f.getName());        try (FileReader<? extends Object> reader = DataFileReader.openReader(f, provider.get())) {            int i = 0;            for (Object datum : reader) {                i++;                Assert.assertNotNull(datum);            }            Assert.assertNotEquals(0, i);        }    }}
0
public void testDeepCopy()
{        Interop.Builder interopBuilder = Interop.newBuilder();    interopBuilder.setArrayField(Arrays.asList(1.1, 1.2, 1.3, 1.4));    interopBuilder.setBoolField(true);    interopBuilder.setBytesField(ByteBuffer.wrap(new byte[] { 1, 2, 3, 4 }));    interopBuilder.setDoubleField(3.14d);    interopBuilder.setEnumField(Kind.B);    interopBuilder.setFixedField(new MD5(new byte[] { 4, 3, 2, 1, 4, 3, 2, 1, 4, 3, 2, 1, 4, 3, 2, 1 }));    interopBuilder.setFloatField(6.022f);    interopBuilder.setIntField(32);    interopBuilder.setLongField(64L);    Map<java.lang.String, org.apache.avro.Foo> map = new HashMap<>(1);    map.put("foo", Foo.newBuilder().setLabel("bar").build());    interopBuilder.setMapField(map);    interopBuilder.setNullField(null);    Node.Builder rootBuilder = Node.newBuilder().setLabel("/");    Node.Builder homeBuilder = Node.newBuilder().setLabel("home");    homeBuilder.setChildren(new ArrayList<>(0));    rootBuilder.setChildren(Collections.singletonList(homeBuilder.build()));    interopBuilder.setRecordField(rootBuilder.build());    interopBuilder.setStringField("Hello");    interopBuilder.setUnionField(Collections.singletonList(ByteBuffer.wrap(new byte[] { 1, 2 })));    Interop interop = interopBuilder.build();        for (Field field : Interop.SCHEMA$.getFields()) {                if (interop.get(field.pos()) instanceof ByteBuffer) {            assertTrue(Arrays.equals(((ByteBuffer) interop.get(field.pos())).array(), ((ByteBuffer) GenericData.get().deepCopy(field.schema(), interop.get(field.pos()))).array()));        } else {            assertEquals(interop.get(field.pos()), SpecificData.get().deepCopy(field.schema(), interop.get(field.pos())));        }                if ((field.schema().getType() != Type.ENUM) && (field.schema().getType() != Type.NULL) && (field.schema().getType() != Type.BOOLEAN) && (field.schema().getType() != Type.INT) && (field.schema().getType() != Type.LONG) && (field.schema().getType() != Type.FLOAT) && (field.schema().getType() != Type.DOUBLE) && (field.schema().getType() != Type.STRING)) {            assertFalse("Field " + field.name() + " is same instance in deep copy", interop.get(field.pos()) == GenericData.get().deepCopy(field.schema(), interop.get(field.pos())));        }    }}
0
protected static Random newRandom()
{    return new Random(SEED);}
0
 void add(List<TestDescriptor> typeList)
{    ALL_TESTS.put(param, this);    typeList.add(this);}
0
private static void usage()
{    StringBuilder usage = new StringBuilder("Usage: Perf [-o <file>] [-c <spec>] { -nowrite | -noread }");    StringBuilder details = new StringBuilder();    details.append(" -o file   (send output to a file)\n");    details.append(" -c [n][t][e][b][c][m] (format as no-header CSV; include Name, Time, Entries/sec, Bytes/sec, bytes/Cycle, and/or min time/op; no spec=all fields)\n");    details.append(" -nowrite   (do not execute write tests)\n");    details.append(" -noread   (do not execute write tests)\n");    for (Map.Entry<String, List<TestDescriptor>> entry : BATCHES.entrySet()) {        List<TestDescriptor> lt = entry.getValue();        String param = entry.getKey();        String paramName = param.substring(1);        usage.append(param).append(" | ");        details.append(" ").append(param).append("   (executes all ").append(paramName).append(" tests):\n");        for (TestDescriptor t : lt) {            usage.append(t.param).append(" | ");            details.append("      ").append(t.param).append("  (").append(t.test.getSimpleName()).append(")\n");        }    }    usage.setLength(usage.length() - 2);    usage.append("}\n");    System.out.println(usage.toString());    System.out.print(details.toString());}
0
public static void main(String[] args) throws Exception
{    if (0 != (COUNT % 4)) {        System.out.println("Property 'org.apache.avro.io.perf.count' must be a multiple of 4.");        System.exit(1);    }    List<Test> tests = new ArrayList<>();    boolean writeTests = true;    boolean readTests = true;    String outputfilename = null;    PrintStream out = System.out;    boolean[] csvFormat = null;    String csvFormatString = null;    for (int i = 0; i < args.length; i++) {        String a = args[i];        TestDescriptor t = ALL_TESTS.get(a);        if (null != t) {            tests.add(t.test.newInstance());            continue;        }        List<TestDescriptor> lt = BATCHES.get(a);        if (null != lt) {            for (TestDescriptor td : lt) {                tests.add(td.test.newInstance());            }            continue;        }        if (i < args.length - 1 && "-o".equals(a)) {            outputfilename = args[++i];            out = new PrintStream(new FileOutputStream(outputfilename));            continue;        }        if ("-c".equals(a)) {            if (i == args.length - 1 || args[i + 1].startsWith("-")) {                                csvFormatString = "ntebcm";                csvFormat = new boolean[] { true, true, true, true, true, true };            } else {                csvFormatString = args[++i];                csvFormat = new boolean[MAX_FIELD_TAG + 1];                for (char c : csvFormatString.toCharArray()) switch(c) {                    case 'n':                        csvFormat[NAME_FIELD] = true;                        break;                    case 't':                        csvFormat[TIME_FIELD] = true;                        break;                    case 'e':                        csvFormat[BYTES_PS_FIELD] = true;                        break;                    case 'b':                        csvFormat[ENTRIES_PS_FIELD] = true;                        break;                    case 'c':                        csvFormat[BYTES_PC_FIELD] = true;                        break;                    case 'm':                        csvFormat[MIN_TIME_FIELD] = true;                        break;                    default:                        usage();                        System.exit(1);                }            }            continue;        }        if ("-nowrite".equals(a)) {            writeTests = false;            continue;        }        if ("-noread".equals(a)) {            readTests = false;            continue;        }        usage();        System.exit(1);    }    if (tests.isEmpty()) {        for (Map.Entry<String, TestDescriptor> entry : ALL_TESTS.entrySet()) {            TestDescriptor t = entry.getValue();            Test test = t.test.newInstance();            tests.add(test);        }    }    System.out.println("Executing tests: \n" + tests + "\n readTests:" + readTests + "\n writeTests:" + writeTests + "\n cycles=" + CYCLES + "\n count=" + (COUNT / 1000) + "K");    if (out != System.out)        System.out.println(" Writing to: " + outputfilename);    if (csvFormat != null)        System.out.println(" CSV format: " + csvFormatString);    TestResult tr = new TestResult();    for (Test t : tests) {        try {                        t.init();            if (t.isReadTest()) {                t.readTest();            }            if (t.isWriteTest()) {                t.writeTest();            }            t.reset();        } catch (Exception e) {            System.out.println("Failed to execute test: " + t.getClass().getSimpleName());            throw e;        }    }    if (csvFormat == null)        printHeader();    for (Test t : tests) {                t.init();        if (t.isReadTest() && readTests) {            for (int i = 0; i < t.cycles / 2; i++) {                t.readTest();            }        }        if (t.isWriteTest() && writeTests) {            for (int i = 0; i < t.cycles / 2; i++) {                t.writeTest();            }        }                System.gc();        if (t.isReadTest() && readTests) {            tr.reset();            for (int i = 0; i < t.cycles; i++) {                tr.update(t.readTest());            }            printResult(out, csvFormat, tr, t, t.name + "Read");        }        if (t.isWriteTest() && writeTests) {            tr.reset();            for (int i = 0; i < t.cycles; i++) {                tr.update(t.writeTest());            }            printResult(out, csvFormat, tr, t, t.name + "Write");        }        t.reset();    }}
0
public void reset()
{    totalTime = 0L;    minTime = Long.MAX_VALUE;}
0
public long update(long t)
{    totalTime += t;    minTime = Math.min(t, minTime);    return t;}
0
private static void printHeader()
{    String header = String.format("%60s     time    M entries/sec   M bytes/sec  bytes/cycle", "test name");    System.out.println(header.toString());}
0
private static void printResult(PrintStream o, boolean[] csv, TestResult tr, Test t, String name)
{    long s = tr.totalTime / 1000;    double entries = (t.cycles * (double) t.count);    double bytes = t.cycles * (double) t.encodedSize;    StringBuilder result = new StringBuilder();    if (csv != null) {        boolean commaneeded = false;        for (int i = 0; i <= MAX_FIELD_TAG; i++) {            if (!csv[i])                continue;            if (commaneeded)                result.append(",");            else                commaneeded = true;            switch(i) {                case NAME_FIELD:                    result.append(name);                    break;                case TIME_FIELD:                    result.append(String.format("%d", (s / 1000)));                    break;                case BYTES_PS_FIELD:                    result.append(String.format("%.3f", (entries / s)));                    break;                case ENTRIES_PS_FIELD:                    result.append(String.format("%.3f", (bytes / s)));                    break;                case BYTES_PC_FIELD:                    result.append(String.format("%d", t.encodedSize));                    break;                case MIN_TIME_FIELD:                    result.append(String.format("%d", tr.minTime));                    break;            }        }    } else {        result.append(String.format("%42s: %6d ms  ", name, (s / 1000)));        result.append(String.format("%10.3f   %11.3f   %11d", (entries / s), (bytes / s), t.encodedSize));    }    o.println(result.toString());}
0
 final boolean isWriteTest()
{    return isWriteTest;}
0
 final boolean isReadTest()
{    return isReadTest;}
0
public String toString()
{    return this.getClass().getSimpleName();}
0
public final long readTest() throws IOException
{    Decoder d = getDecoder();    long t = System.nanoTime();    readInternal(d);    return (System.nanoTime() - t);}
0
public final long writeTest() throws IOException
{    Encoder e = getEncoder();    long t = System.nanoTime();    writeInternal(e);    e.flush();    return (System.nanoTime() - t);}
0
protected Decoder getDecoder() throws IOException
{    return newDecoder();}
0
private Encoder getEncoder() throws IOException
{    return newEncoder(getOutputStream());}
0
protected Decoder newDecoder()
{    return decoder_factory.binaryDecoder(data, null);}
0
protected Encoder newEncoder(ByteArrayOutputStream out) throws IOException
{    Encoder e = (USE_DIRECT_ENCODER ? encoder_factory.directBinaryEncoder(out, null) : encoder_factory.binaryEncoder(out, null));        return e;}
0
private ByteArrayOutputStream getOutputStream()
{    return new ByteArrayOutputStream((int) (encodedSize > 0 ? encodedSize : count));}
0
 void init() throws IOException
{    genSourceData();    ByteArrayOutputStream baos = getOutputStream();    Encoder e = newEncoder(baos);    writeInternal(e);    e.flush();    data = baos.toByteArray();    encodedSize = data.length;}
0
 void genSourceData()
{    Random r = newRandom();    sourceData = new int[count];    for (int i = 0; i < sourceData.length; i += 4) {                sourceData[i] = r.nextInt(50);                sourceData[i + 1] = r.nextInt(5000);                sourceData[i + 2] = r.nextInt(500000);                sourceData[i + 3] = r.nextInt(150000000);    }}
0
 void readInternal(Decoder d) throws IOException
{    for (int i = 0; i < count / 4; i++) {        d.readInt();        d.readInt();        d.readInt();        d.readInt();    }}
0
 void writeInternal(Encoder e) throws IOException
{    for (int i = 0; i < sourceData.length; i += 4) {        e.writeInt(sourceData[i]);        e.writeInt(sourceData[i + 1]);        e.writeInt(sourceData[i + 2]);        e.writeInt(sourceData[i + 3]);    }}
0
 void reset()
{    sourceData = null;    data = null;}
0
 void readInternal(Decoder d) throws IOException
{    for (int i = 0; i < count / 4; i++) {        d.readLong();        d.readLong();        d.readLong();        d.readLong();    }}
0
 void writeInternal(Encoder e) throws IOException
{    for (int i = 0; i < sourceData.length; i += 4) {        e.writeLong(sourceData[i]);        e.writeLong(sourceData[i + 1]);        e.writeLong(sourceData[i + 2]);        e.writeLong(sourceData[i + 3]);    }}
0
 void genSourceData()
{    Random r = newRandom();    sourceData = new long[count];    for (int i = 0; i < sourceData.length; i += 4) {                sourceData[i] = r.nextLong() % 0x7FL;                sourceData[i + 1] = r.nextLong() % 0x1FFFFFL;                sourceData[i + 2] = r.nextLong() % 0x3FFFFFFFFL;                sourceData[i + 3] = r.nextLong() % 0x1FFFFFFFFFFFFL;    }        for (int i = sourceData.length - 16; i < sourceData.length; i++) {        sourceData[i] = r.nextLong();    }}
0
 void readInternal(Decoder d) throws IOException
{    for (int i = 0; i < count / 4; i++) {        d.readLong();        d.readLong();        d.readLong();        d.readLong();    }}
0
 void writeInternal(Encoder e) throws IOException
{    for (int i = 0; i < sourceData.length; i += 4) {        e.writeLong(sourceData[i]);        e.writeLong(sourceData[i + 1]);        e.writeLong(sourceData[i + 2]);        e.writeLong(sourceData[i + 3]);    }}
0
 void reset()
{    sourceData = null;    data = null;}
0
 void genSourceData()
{    Random r = newRandom();    sourceData = new float[count];    for (int i = 0; i < sourceData.length; ) {        sourceData[i++] = r.nextFloat();    }}
0
 void readInternal(Decoder d) throws IOException
{    for (int i = 0; i < count; i += 4) {        d.readFloat();        d.readFloat();        d.readFloat();        d.readFloat();    }}
0
 void writeInternal(Encoder e) throws IOException
{    for (int i = 0; i < sourceData.length; i += 4) {        e.writeFloat(sourceData[i]);        e.writeFloat(sourceData[i + 1]);        e.writeFloat(sourceData[i + 2]);        e.writeFloat(sourceData[i + 3]);    }}
0
 void reset()
{    sourceData = null;    data = null;}
0
 void genSourceData()
{    Random r = newRandom();    sourceData = new double[count];    for (int i = 0; i < sourceData.length; ) {        sourceData[i++] = r.nextDouble();    }}
0
 void readInternal(Decoder d) throws IOException
{    for (int i = 0; i < count; i += 4) {        d.readDouble();        d.readDouble();        d.readDouble();        d.readDouble();    }}
0
 void writeInternal(Encoder e) throws IOException
{    for (int i = 0; i < sourceData.length; i += 4) {        e.writeDouble(sourceData[i]);        e.writeDouble(sourceData[i + 1]);        e.writeDouble(sourceData[i + 2]);        e.writeDouble(sourceData[i + 3]);    }}
0
 void reset()
{    sourceData = null;    data = null;}
0
 void genSourceData()
{    Random r = newRandom();    sourceData = new boolean[count];    for (int i = 0; i < sourceData.length; ) {        sourceData[i++] = r.nextBoolean();    }}
0
 void readInternal(Decoder d) throws IOException
{    for (int i = 0; i < count / 4; i++) {        d.readBoolean();        d.readBoolean();        d.readBoolean();        d.readBoolean();    }}
0
 void writeInternal(Encoder e) throws IOException
{    for (int i = 0; i < sourceData.length; i += 4) {        e.writeBoolean(sourceData[i]);        e.writeBoolean(sourceData[i + 1]);        e.writeBoolean(sourceData[i + 2]);        e.writeBoolean(sourceData[i + 3]);    }}
0
 void reset()
{    sourceData = null;    data = null;}
0
 void genSourceData()
{    Random r = newRandom();    sourceData = new byte[count][];    for (int i = 0; i < sourceData.length; ) {        byte[] data = new byte[r.nextInt(70)];        r.nextBytes(data);        sourceData[i++] = data;    }}
0
 void readInternal(Decoder d) throws IOException
{    ByteBuffer bb = ByteBuffer.allocate(70);    for (int i = 0; i < count / 4; i++) {        d.readBytes(bb);        d.readBytes(bb);        d.readBytes(bb);        d.readBytes(bb);    }}
0
 void writeInternal(Encoder e) throws IOException
{    for (int i = 0; i < sourceData.length; i += 4) {        e.writeBytes(sourceData[i]);        e.writeBytes(sourceData[i + 1]);        e.writeBytes(sourceData[i + 2]);        e.writeBytes(sourceData[i + 3]);    }}
0
 void reset()
{    sourceData = null;    data = null;}
0
private static String randomString(Random r)
{    char[] data = new char[r.nextInt(70)];    for (int j = 0; j < data.length; j++) {        data[j] = (char) ('a' + r.nextInt('z' - 'a'));    }    return new String(data);}
0
 void genSourceData()
{    Random r = newRandom();    sourceData = new String[count];    for (int i = 0; i < sourceData.length; ) sourceData[i++] = randomString(r);}
0
 void readInternal(Decoder d) throws IOException
{    Utf8 utf = new Utf8();    for (int i = 0; i < count / 4; i++) {        d.readString(utf).toString();        d.readString(utf).toString();        d.readString(utf).toString();        d.readString(utf).toString();    }}
0
 void writeInternal(Encoder e) throws IOException
{    for (int i = 0; i < sourceData.length; i += 4) {        e.writeString(sourceData[i]);        e.writeString(sourceData[i + 1]);        e.writeString(sourceData[i + 2]);        e.writeString(sourceData[i + 3]);    }}
0
 void reset()
{    sourceData = null;    data = null;}
0
 void readInternal(Decoder d) throws IOException
{    d.readArrayStart();    for (long i = d.readArrayStart(); i != 0; i = d.arrayNext()) {        for (long j = 0; j < i; j++) {            d.readFloat();            d.readFloat();            d.readFloat();            d.readFloat();        }    }    d.arrayNext();}
0
 void writeInternal(Encoder e) throws IOException
{    int items = sourceData.length / 4;    e.writeArrayStart();    e.setItemCount(1);    e.startItem();    e.writeArrayStart();    e.setItemCount(items);    for (int i = 0; i < sourceData.length; i += 4) {        e.startItem();        e.writeFloat(sourceData[i]);        e.writeFloat(sourceData[i + 1]);        e.writeFloat(sourceData[i + 2]);        e.writeFloat(sourceData[i + 3]);    }    e.writeArrayEnd();    e.writeArrayEnd();}
0
 void readInternal(Decoder d) throws IOException
{    Utf8 key = new Utf8();    for (long i = d.readMapStart(); i != 0; i = d.mapNext()) {        for (long j = 0; j < i; j++) {            key = d.readString(key);            d.readFloat();            d.readFloat();            d.readFloat();            d.readFloat();        }    }}
0
 void writeInternal(Encoder e) throws IOException
{    int items = sourceData.length / 4;    e.writeMapStart();    e.setItemCount(items);    Utf8 foo = new Utf8("foo");    for (int i = 0; i < sourceData.length; i += 4) {        e.startItem();        e.writeString(foo);        e.writeFloat(sourceData[i]);        e.writeFloat(sourceData[i + 1]);        e.writeFloat(sourceData[i + 2]);        e.writeFloat(sourceData[i + 3]);    }    e.writeMapEnd();}
0
 void genSourceData()
{    Random r = newRandom();    sourceData = new Rec[count];    for (int i = 0; i < sourceData.length; i++) {        sourceData[i] = new Rec(r);    }}
0
 void readInternal(Decoder d) throws IOException
{    for (int i = 0; i < count; i++) {        d.readDouble();        d.readDouble();        d.readDouble();        d.readInt();        d.readInt();        d.readInt();    }}
0
 void writeInternal(Encoder e) throws IOException
{    for (Rec r : sourceData) {        e.writeDouble(r.f1);        e.writeDouble(r.f2);        e.writeDouble(r.f3);        e.writeInt(r.f4);        e.writeInt(r.f5);        e.writeInt(r.f6);    }}
0
 void reset()
{    sourceData = null;    data = null;}
0
protected Decoder getDecoder() throws IOException
{    return new ValidatingDecoder(schema, super.getDecoder());}
0
protected Encoder newEncoder(ByteArrayOutputStream out) throws IOException
{    return encoder_factory.validatingEncoder(schema, super.newEncoder(out));}
0
protected Decoder getDecoder() throws IOException
{    return new ResolvingDecoder(schema, schema, super.getDecoder());}
0
protected Decoder getDecoder() throws IOException
{    return new ResolvingDecoder(schema, readerSchema, super.getDecoder());}
0
protected void readInternal(Decoder d) throws IOException
{    ResolvingDecoder r = (ResolvingDecoder) d;    Field[] ff = r.readFieldOrder();    for (int i = 0; i < count; i++) {        for (Field f : ff) {            switch(f.pos()) {                case 0:                case 1:                case 2:                    r.readDouble();                    break;                case 3:                case 4:                case 5:                    r.readInt();                    break;                case 6:                case 7:                    r.readString(null);                    break;            }        }    }}
0
protected Decoder getDecoder() throws IOException
{    return new ResolvingDecoder(schema, readerSchema, super.getDecoder());}
0
protected void readInternal(Decoder d) throws IOException
{    ResolvingDecoder r = (ResolvingDecoder) d;    Field[] ff = r.readFieldOrder();    for (int i = 0; i < count; i++) {        for (Field f : ff) {            switch(f.pos()) {                case 0:                case 1:                case 3:                    r.readDouble();                    break;                case 2:                case 4:                case 5:                    r.readInt();                    break;            }        }    }}
0
protected Decoder getDecoder() throws IOException
{    return new ResolvingDecoder(schema, readerSchema, super.getDecoder());}
0
protected void readInternal(Decoder d) throws IOException
{    ResolvingDecoder r = (ResolvingDecoder) d;    Field[] ff = r.readFieldOrder();    for (int i = 0; i < count; i++) {        for (Field f : ff) {            switch(f.pos()) {                case 0:                case 1:                case 2:                    r.readDouble();                    break;                case 3:                case 4:                case 5:                    r.readLong();                    break;            }        }    }}
0
protected GenericDatumReader<Object> getReader()
{    return reader;}
0
protected GenericDatumReader<Object> newReader()
{    return new GenericDatumReader<>(schema);}
0
 void genSourceData()
{    Random r = newRandom();    sourceData = new GenericRecord[count];    for (int i = 0; i < sourceData.length; i++) {        GenericRecord rec = new GenericData.Record(schema);        rec.put(0, r.nextDouble());        rec.put(1, r.nextDouble());        rec.put(2, r.nextDouble());        rec.put(3, r.nextInt());        rec.put(4, r.nextInt());        rec.put(5, r.nextInt());        sourceData[i] = rec;    }}
0
 void readInternal(Decoder d) throws IOException
{    for (int i = 0; i < count; i++) {        getReader().read(null, d);    }}
0
 void writeInternal(Encoder e) throws IOException
{    GenericDatumWriter<Object> writer = new GenericDatumWriter<>(schema);    for (GenericRecord rec : sourceData) {        writer.write(rec, e);    }}
0
 void reset()
{    sourceData = null;    data = null;}
0
 void genSourceData()
{    Random r = newRandom();    sourceData = new GenericRecord[count];    for (int i = 0; i < sourceData.length; i++) {        GenericRecord rec = new GenericData.Record(schema);        rec.put(0, randomString(r));        rec.put(1, randomString(r));        rec.put(2, randomString(r));        sourceData[i] = rec;    }}
0
 void genSourceData()
{    sourceData = generateGenericNested(schema, count);}
0
 static GenericRecord[] generateGenericNested(Schema schema, int count)
{    Random r = newRandom();    GenericRecord[] sourceData = new GenericRecord[count];    Schema doubleSchema = schema.getFields().get(0).schema();    for (int i = 0; i < sourceData.length; i++) {        GenericRecord rec = new GenericData.Record(schema);        GenericRecord inner;        inner = new GenericData.Record(doubleSchema);        inner.put(0, r.nextDouble());        rec.put(0, inner);        inner = new GenericData.Record(doubleSchema);        inner.put(0, r.nextDouble());        rec.put(1, inner);        inner = new GenericData.Record(doubleSchema);        inner.put(0, r.nextDouble());        rec.put(2, inner);        rec.put(3, r.nextInt());        rec.put(4, r.nextInt());        rec.put(5, r.nextInt());        sourceData[i] = rec;    }    return sourceData;}
0
 void readInternal(Decoder d) throws IOException
{    Schema doubleSchema = schema.getFields().get(0).schema();    for (int i = 0; i < count; i++) {        GenericRecord rec = new GenericData.Record(schema);        GenericRecord inner;        inner = new GenericData.Record(doubleSchema);        inner.put(0, d.readDouble());        rec.put(0, inner);        inner = new GenericData.Record(doubleSchema);        inner.put(0, d.readDouble());        rec.put(1, inner);        inner = new GenericData.Record(doubleSchema);        inner.put(0, d.readDouble());        rec.put(2, inner);        rec.put(3, d.readInt());        rec.put(4, d.readInt());        rec.put(5, d.readInt());    }}
0
 void writeInternal(Encoder e) throws IOException
{    for (GenericRecord rec : sourceData) {        GenericRecord inner;        inner = (GenericRecord) rec.get(0);        e.writeDouble((Double) inner.get(0));        inner = (GenericRecord) rec.get(1);        e.writeDouble((Double) inner.get(0));        inner = (GenericRecord) rec.get(2);        e.writeDouble((Double) inner.get(0));        e.writeInt((Integer) rec.get(3));        e.writeInt((Integer) rec.get(4));        e.writeInt((Integer) rec.get(5));    }}
0
 void genSourceData()
{    sourceData = generateGenericNested(schema, count);}
0
 void reset()
{    data = null;    sourceData = null;}
0
protected GenericDatumReader<Object> newReader()
{    return new GenericDatumReader<>(schema, getReaderSchema());}
0
protected Schema getReaderSchema()
{    return new Schema.Parser().parse(RECORD_SCHEMA_WITH_DEFAULT);}
0
protected Schema getReaderSchema()
{    return new Schema.Parser().parse(RECORD_SCHEMA_WITH_OUT_OF_ORDER);}
0
protected Schema getReaderSchema()
{    return new Schema.Parser().parse(RECORD_SCHEMA_WITH_PROMOTION);}
0
protected Decoder getDecoder()
{    return newDecoder();}
0
protected GenericDatumReader<Object> getReader()
{    return newReader();}
0
protected GenericDatumReader<Object> getReader()
{    return newReader();}
0
protected Decoder getDecoder()
{    return newDecoder();}
0
protected SpecificDatumReader<T> newReader()
{    return new SpecificDatumReader<>(schema);}
0
protected SpecificDatumWriter<T> newWriter()
{    return new SpecificDatumWriter<>(schema);}
0
 void genSourceData()
{    Random r = newRandom();    sourceData = new Object[count];    for (int i = 0; i < sourceData.length; i++) {        sourceData[i] = genSingleRecord(r);    }    reuse = genSingleRecord(r);}
0
 void readInternal(Decoder d) throws IOException
{    for (int i = 0; i < count; i++) {        reader.read(reuse, d);    }}
0
 void writeInternal(Encoder e) throws IOException
{    for (Object sourceDatum : sourceData) {        @SuppressWarnings("unchecked")        T rec = (T) sourceDatum;        writer.write(rec, e);    }}
0
 void reset()
{    sourceData = null;    data = null;}
0
protected FooBarSpecificRecord genSingleRecord(Random r)
{    TypeEnum[] typeEnums = TypeEnum.values();    List<Integer> relatedIds = new ArrayList<>(10);    for (int i = 0; i < 10; i++) {        relatedIds.add(r.nextInt());    }    try {        String[] nicknames = { randomString(r), randomString(r) };        return FooBarSpecificRecord.newBuilder().setId(r.nextInt()).setName(randomString(r)).setNicknames(new ArrayList<>(Arrays.asList(nicknames))).setTypeEnum(typeEnums[r.nextInt(typeEnums.length)]).setRelatedids(relatedIds).build();    } catch (Exception e) {        throw new RuntimeException(e);    }}
0
protected final void genSourceData()
{    Random r = newRandom();    sourceData = (T[]) Array.newInstance(clazz, count);    for (int i = 0; i < sourceData.length; i++) {        sourceData[i] = createDatum(r);    }}
0
protected final void readInternal(Decoder d) throws IOException
{    for (int i = 0; i < count; i++) {        reader.read(null, d);    }}
0
protected final void writeInternal(Encoder e) throws IOException
{    for (T sourceDatum : sourceData) {        writer.write(sourceDatum, e);    }}
0
protected final void reset()
{    sourceData = null;    data = null;}
0
protected Rec createDatum(Random r)
{    return new Rec(r);}
0
protected float[] createDatum(Random r)
{    return populateFloatArray(r, COUNT / count);}
0
protected double[] createDatum(Random r)
{    return populateDoubleArray(r, COUNT / count);}
0
protected float[] createDatum(Random r)
{    return populateFloatArray(r, false);}
0
protected double[] createDatum(Random r)
{    return populateDoubleArray(r);}
0
protected int[] createDatum(Random r)
{    return populateIntArray(r);}
0
protected long[] createDatum(Random r)
{    return populateLongArray(r);}
0
protected Foo createDatum(Random r)
{    return new Foo(r);}
0
private static int smallArraySize(Random r)
{    return r.nextInt(15) + 1;}
0
private static int largeArraySize(Random r)
{    return r.nextInt(97) + 16;}
0
 static float[] populateFloatArray(Random r, boolean large)
{    int size = large ? largeArraySize(r) : smallArraySize(r);    return populateFloatArray(r, size);}
0
 static float[] populateFloatArray(Random r, int size)
{    float[] result = new float[size];    for (int i = 0; i < result.length; i++) {        result[i] = r.nextFloat();    }    return result;}
0
 static double[] populateDoubleArray(Random r)
{    return populateDoubleArray(r, smallArraySize(r));}
0
 static double[] populateDoubleArray(Random r, int size)
{    double[] result = new double[size];    for (int i = 0; i < result.length; i++) {        result[i] = r.nextDouble();    }    return result;}
0
 static int[] populateIntArray(Random r)
{    int size = smallArraySize(r);    int[] result = new int[size];    for (int i = 0; i < result.length; i++) {        result[i] = r.nextInt();    }    return result;}
0
 static long[] populateLongArray(Random r)
{    int size = smallArraySize(r);    long[] result = new long[size];    for (int i = 0; i < result.length; i++) {        result[i] = r.nextLong();    }    return result;}
0
protected FloatFoo createDatum(Random r)
{    return new FloatFoo(r, false);}
0
protected FloatFoo createDatum(Random r)
{    return new FloatFoo(r, true);}
0
protected FloatFoo createDatum(Random r)
{    return new FloatFoo(r, true);}
0
protected Encoder newEncoder(ByteArrayOutputStream out) throws IOException
{    return new EncoderFactory().configureBlockSize(254).blockingBinaryEncoder(out, null);}
0
protected Rec1 createDatum(Random r)
{    return new Rec1(r);}
0
private static String mkSchema(String subschema)
{    return ("{ \"type\": \"record\", \"name\": \"R\", \"fields\": [\n" + "{ \"name\": \"f\", \"type\": " + subschema + "}\n" + "] }");}
0
protected Decoder getDecoder() throws IOException
{    return new ResolvingDecoder(writeSchema, schema, super.getDecoder());}
0
 void readInternal(Decoder d) throws IOException
{    GenericDatumReader<Object> reader = new GenericDatumReader<>(schema);    for (int i = 0; i < count; i++) {        reader.read(null, d);    }}
0
 void writeInternal(Encoder e) throws IOException
{    GenericDatumWriter<Object> writer = new GenericDatumWriter<>(writeSchema);    for (GenericRecord sourceDatum : sourceData) {        writer.write(sourceDatum, e);    }}
0
 void reset()
{    sourceData = null;    data = null;}
0
 void genSourceData()
{    Random r = newRandom();    Schema eSchema = writeSchema.getField("f").schema();    sourceData = new GenericRecord[count];    for (int i = 0; i < sourceData.length; i++) {        GenericRecord rec = new GenericData.Record(writeSchema);        int tag = r.nextInt(2);        rec.put("f", GenericData.get().createEnum(eSchema.getEnumSymbols().get(tag), eSchema));        sourceData[i] = rec;    }}
0
 void genSourceData()
{    Random r = newRandom();    Schema uSchema = writeSchema.getField("f").schema();    sourceData = new GenericRecord[count];    for (int i = 0; i < sourceData.length; i++) {        GenericRecord rec = new GenericData.Record(writeSchema);        int val = r.nextInt(1000000);        Integer v = (val < 750000 ? val : null);        rec.put("f", v);        sourceData[i] = rec;    }}
0
public static void initializeProxy() throws Exception
{    HttpTransceiver client = new HttpTransceiver(new URL("http://localhost"));    SpecificRequestor requestor = new SpecificRequestor(SampleSpecificProtocol.class, client);    proxy = SpecificRequestor.getClient(SampleSpecificProtocol.class, requestor);}
0
public void testHashCode() throws IOException
{    try {        proxy.hashCode();    } catch (AvroRuntimeException e) {        fail(e.getMessage());    }}
0
public void testEquals() throws IOException
{    try {        proxy.equals(proxy);    } catch (AvroRuntimeException e) {        fail(e.getMessage());    }}
0
public void testToString() throws IOException
{    try {        proxy.toString();    } catch (AvroRuntimeException e) {        fail(e.getMessage());    }}
0
public long ticks()
{    return time;}
0
public void passTime(long nanos)
{    time += nanos;}
0
public void testBasicOperation()
{    Segmenter<String, Integer> s = new Histogram.TreeMapSegmenter<>(new TreeSet<>(Arrays.asList(0, 1, 2, 4, 8, 16)));    Histogram<String, Integer> h = new Histogram<>(s);    for (int i = 0; i < 20; ++i) {        h.add(i);    }    assertEquals(20, h.getCount());    assertArrayEquals(new int[] { 1, 1, 2, 4, 8, 4 }, h.getHistogram());    assertEquals("[0,1)=1;[1,2)=1;[2,4)=2;[4,8)=4;[8,16)=8;[16,infinity)=4", h.toString());    String[] correctBucketLabels = { "[0,1)", "[1,2)", "[2,4)", "[4,8)", "[8,16)", "[16,infinity)" };        int pos = 0;    Iterator<String> it = h.getSegmenter().getBuckets();    while (it.hasNext()) {        assertEquals(correctBucketLabels[pos], it.next());        pos = pos + 1;    }    assertEquals(correctBucketLabels.length, pos);    List<String> labels = h.getSegmenter().getBucketLabels();    assertEquals(correctBucketLabels.length, labels.size());    if (labels.size() == correctBucketLabels.length) {        for (int i = 0; i < labels.size(); i++) {            assertEquals(correctBucketLabels[i], labels.get(i));        }    }    String[] correctBoundryLabels = { "0", "1", "2", "4", "8", "16" };    List<String> boundryLabels = h.getSegmenter().getBoundaryLabels();    assertEquals(correctBoundryLabels.length, boundryLabels.size());    if (boundryLabels.size() == correctBoundryLabels.length) {        for (int i = 0; i < boundryLabels.size(); i++) {            assertEquals(correctBoundryLabels[i], boundryLabels.get(i));        }    }    List<Entry<String>> entries = new ArrayList<>();    for (Entry<String> entry : h.entries()) {        entries.add(entry);    }    assertEquals("[0,1)", entries.get(0).bucket);    assertEquals(4, entries.get(5).count);    assertEquals(6, entries.size());    h.add(1010);    h.add(9191);    List<Integer> recent = h.getRecentAdditions();    assertTrue(recent.contains(1010));    assertTrue(recent.contains(9191));}
0
public void testBadValue()
{    Segmenter<String, Long> s = new Histogram.TreeMapSegmenter<>(new TreeSet<>(Arrays.asList(0L, 1L, 2L, 4L, 8L, 16L)));    Histogram<String, Long> h = new Histogram<>(s);    h.add(-1L);}
0
public Iterator<String> getBuckets()
{    return Collections.singletonList("X").iterator();}
0
public List<String> getBoundaryLabels()
{    return Collections.singletonList("X");}
0
public List<String> getBucketLabels()
{    return Collections.singletonList("X");}
0
public int segment(Float value)
{    return 0;}
0
public int size()
{    return 1;}
0
public void testFloatHistogram()
{    FloatHistogram<String> h = new FloatHistogram<>(new SingleBucketSegmenter());    h.add(12.0f);    h.add(10.0f);    h.add(20.0f);    assertEquals(3, h.getCount());    assertEquals(14.0f, h.getMean(), 0.0001);    assertEquals(5.291f, h.getUnbiasedStdDev(), 0.001);}
0
public void testNormal()
{    FakeTicks f = new FakeTicks();    Stopwatch s = new Stopwatch(f);    f.passTime(10);    s.start();    f.passTime(20);    assertEquals(20, s.elapsedNanos());    f.passTime(40);    s.stop();    f.passTime(80);    assertEquals(60, s.elapsedNanos());}
0
public void testNotStarted1()
{    FakeTicks f = new FakeTicks();    Stopwatch s = new Stopwatch(f);    s.elapsedNanos();}
0
public void testNotStarted2()
{    FakeTicks f = new FakeTicks();    Stopwatch s = new Stopwatch(f);    s.stop();}
0
public void testTwiceStarted()
{    FakeTicks f = new FakeTicks();    Stopwatch s = new Stopwatch(f);    s.start();    s.start();}
0
public void testTwiceStopped()
{    FakeTicks f = new FakeTicks();    Stopwatch s = new Stopwatch(f);    s.start();    s.stop();    s.stop();}
0
public void testSystemStopwatch()
{    Stopwatch s = new Stopwatch(Stopwatch.SYSTEM_TICKS);    s.start();    s.stop();    assertTrue(s.elapsedNanos() >= 0);}
0
public Object respond(Message message, Object request) throws AvroRemoteException
{    assertEquals(new Utf8("hello"), ((GenericRecord) request).get("x"));    return new Utf8("there");}
0
public void testSingleRpc() throws Exception
{    Transceiver t = new LocalTransceiver(new TestResponder(protocol));    GenericRecord params = new GenericData.Record(protocol.getMessages().get("m").getRequest());    params.put("x", new Utf8("hello"));    GenericRequestor r = new GenericRequestor(protocol, t);    for (int x = 0; x < 5; x++) assertEquals(new Utf8("there"), r.request("m", params));}
0
public void clientStartConnect(RPCContext context)
{    assertEquals(0, orderCounter.getAndIncrement());}
0
public void clientSendRequest(RPCContext context)
{    assertEquals(1, orderCounter.getAndIncrement());}
0
public void clientReceiveResponse(RPCContext context)
{    assertEquals(6, orderCounter.getAndIncrement());}
0
public void clientFinishConnect(RPCContext context)
{    assertEquals(5, orderCounter.getAndIncrement());}
0
public void serverConnecting(RPCContext context)
{    assertEquals(2, orderCounter.getAndIncrement());}
0
public void serverReceiveRequest(RPCContext context)
{    assertEquals(3, orderCounter.getAndIncrement());}
0
public void serverSendResponse(RPCContext context)
{    assertEquals(4, orderCounter.getAndIncrement());}
0
public void testRpcPluginOrdering() throws Exception
{    OrderPlugin plugin = new OrderPlugin();    SpecificResponder responder = new SpecificResponder(Mail.class, new TestMailImpl());    SpecificRequestor requestor = new SpecificRequestor(Mail.class, new LocalTransceiver(responder));    responder.addRPCPlugin(plugin);    requestor.addRPCPlugin(plugin);    Mail client = SpecificRequestor.getClient(Mail.class, requestor);    Message message = createTestMessage();    client.send(message);}
0
private Message createTestMessage()
{    Message message = Message.newBuilder().setTo("me@test.com").setFrom("you@test.com").setBody("plugin testing").build();    return message;}
0
public String send(Message message)
{    return "Received";}
0
public void fireandforget(Message message)
{}
0
public void testStartServer() throws Exception
{    if (server != null)        return;    server = new SaslSocketServer(new TestResponder(), new InetSocketAddress(0));    server.start();    client = new SaslSocketTransceiver(new InetSocketAddress(server.getPort()));    requestor = new GenericRequestor(PROTOCOL, client);}
0
public void testHandshake() throws IOException
{}
0
public void testResponseChange() throws IOException
{}
0
public void test64kRequest() throws Exception
{    SaslSocketServer s = new SaslSocketServer(new ReflectResponder(ProtoInterface.class, (ProtoInterface) b -> b), new InetSocketAddress(0));    s.start();    SaslSocketTransceiver client = new SaslSocketTransceiver(new InetSocketAddress(s.getPort()));    ProtoInterface proxy = ReflectRequestor.getClient(ProtoInterface.class, client);    byte[] result = proxy.test(new byte[64 * 1024]);    client.close();    s.close();}
0
public void handle(Callback[] callbacks) throws IOException, UnsupportedCallbackException
{    for (Callback c : callbacks) {        if (c instanceof NameCallback) {            ((NameCallback) c).setName(PRINCIPAL);        } else if (c instanceof PasswordCallback) {            ((PasswordCallback) c).setPassword(PASSWORD.toCharArray());        } else if (c instanceof AuthorizeCallback) {            ((AuthorizeCallback) c).setAuthorized(true);        } else if (c instanceof RealmCallback) {            ((RealmCallback) c).setText(REALM);        } else {            throw new UnsupportedCallbackException(c);        }    }}
0
public void testStartServer() throws Exception
{    if (server != null)        return;    server = new SaslSocketServer(new TestResponder(), new InetSocketAddress(0), DIGEST_MD5_MECHANISM, SERVICE, HOST, DIGEST_MD5_PROPS, new TestSaslCallbackHandler());    server.start();    SaslClient saslClient = Sasl.createSaslClient(new String[] { DIGEST_MD5_MECHANISM }, PRINCIPAL, SERVICE, HOST, DIGEST_MD5_PROPS, new TestSaslCallbackHandler());    client = new SaslSocketTransceiver(new InetSocketAddress(server.getPort()), saslClient);    requestor = new GenericRequestor(PROTOCOL, client);}
0
public void testAnonymousClient() throws Exception
{    Server s = new SaslSocketServer(new TestResponder(), new InetSocketAddress(0), DIGEST_MD5_MECHANISM, SERVICE, HOST, DIGEST_MD5_PROPS, new TestSaslCallbackHandler());    s.start();    Transceiver c = new SaslSocketTransceiver(new InetSocketAddress(s.getPort()));    GenericRequestor requestor = new GenericRequestor(PROTOCOL, c);    GenericRecord params = new GenericData.Record(PROTOCOL.getMessages().get("hello").getRequest());    params.put("greeting", "bob");    Utf8 response = (Utf8) requestor.request("hello", params);    assertEquals(new Utf8("goodbye"), response);    s.close();    c.close();}
0
public void handle(Callback[] callbacks) throws IOException, UnsupportedCallbackException
{    for (Callback c : callbacks) {        if (c instanceof NameCallback) {            ((NameCallback) c).setName(PRINCIPAL);        } else if (c instanceof PasswordCallback) {            ((PasswordCallback) c).setPassword("wrong".toCharArray());        } else if (c instanceof AuthorizeCallback) {            ((AuthorizeCallback) c).setAuthorized(true);        } else if (c instanceof RealmCallback) {            ((RealmCallback) c).setText(REALM);        } else {            throw new UnsupportedCallbackException(c);        }    }}
0
public void testWrongPassword() throws Exception
{    Server s = new SaslSocketServer(new TestResponder(), new InetSocketAddress(0), DIGEST_MD5_MECHANISM, SERVICE, HOST, DIGEST_MD5_PROPS, new TestSaslCallbackHandler());    s.start();    SaslClient saslClient = Sasl.createSaslClient(new String[] { DIGEST_MD5_MECHANISM }, PRINCIPAL, SERVICE, HOST, DIGEST_MD5_PROPS, new WrongPasswordCallbackHandler());    Transceiver c = new SaslSocketTransceiver(new InetSocketAddress(server.getPort()), saslClient);    GenericRequestor requestor = new GenericRequestor(PROTOCOL, c);    GenericRecord params = new GenericData.Record(PROTOCOL.getMessages().get("hello").getRequest());    params.put("greeting", "bob");    Utf8 response = (Utf8) requestor.request("hello", params);    assertEquals(new Utf8("goodbye"), response);    s.close();    c.close();}
0
public void testHandshake() throws IOException
{}
0
public void testResponseChange() throws IOException
{}
0
public Schema findByFingerprint(long fingerprint)
{    return cache.findByFingerprint(fingerprint);}
0
public void testCompatibleReadWithSchemaFromSchemaStore() throws Exception
{        NestedEvolve2.Builder rootBuilder = NestedEvolve2.newBuilder().setRootName("RootName");    rootBuilder.setNested(TestRecord2.newBuilder().setName("Name").setValue(1).setData("Data").build());    ByteBuffer nestedEvolve2Buffer = rootBuilder.build().toByteBuffer();        NestedEvolve1 nestedEvolve1 = decoder.decode(nestedEvolve2Buffer);        assertEquals(nestedEvolve1.getRootName(), "RootName");    assertEquals(nestedEvolve1.getNested().getName(), "Name");    assertEquals(nestedEvolve1.getNested().getValue(), 1);}
0
public void testIncompatibleReadWithSchemaFromSchemaStore() throws Exception
{        NestedEvolve3.Builder rootBuilder = NestedEvolve3.newBuilder().setRootName("RootName");    rootBuilder.setNested(TestRecord3.newBuilder().setName("Name").setData("Data").build());    ByteBuffer nestedEvolve3Buffer = rootBuilder.build().toByteBuffer();            decoder.decode(nestedEvolve3Buffer);}
0
public void clientStartConnect(RPCContext context)
{    ByteBuffer buf = ByteBuffer.wrap("ap".getBytes(StandardCharsets.UTF_8));    context.requestHandshakeMeta().put(key, buf);}
0
public void serverConnecting(RPCContext context)
{    Assert.assertNotNull(context.requestHandshakeMeta());    Assert.assertNotNull(context.responseHandshakeMeta());    Assert.assertNull(context.getRequestPayload());    Assert.assertNull(context.getResponsePayload());    if (!context.requestHandshakeMeta().containsKey(key))        return;    ByteBuffer buf = context.requestHandshakeMeta().get(key);    Assert.assertNotNull(buf);    Assert.assertNotNull(buf.array());    String partialstr = new String(buf.array(), StandardCharsets.UTF_8);    Assert.assertNotNull(partialstr);    Assert.assertEquals("partial string mismatch", "ap", partialstr);    buf = ByteBuffer.wrap((partialstr + "ac").getBytes(StandardCharsets.UTF_8));    Assert.assertTrue(buf.remaining() > 0);    context.responseHandshakeMeta().put(key, buf);}
0
public void clientFinishConnect(RPCContext context)
{    Map<String, ByteBuffer> handshakeMeta = context.responseHandshakeMeta();    Assert.assertNull(context.getRequestPayload());    Assert.assertNull(context.getResponsePayload());    Assert.assertNotNull(handshakeMeta);    if (!handshakeMeta.containsKey(key))        return;    ByteBuffer buf = handshakeMeta.get(key);    Assert.assertNotNull(buf);    Assert.assertNotNull(buf.array());    String partialstr = new String(buf.array(), StandardCharsets.UTF_8);    Assert.assertNotNull(partialstr);    Assert.assertEquals("partial string mismatch", "apac", partialstr);    buf = ByteBuffer.wrap((partialstr + "he").getBytes(StandardCharsets.UTF_8));    Assert.assertTrue(buf.remaining() > 0);    handshakeMeta.put(key, buf);    checkRPCMetaMap(handshakeMeta);}
0
public void clientSendRequest(RPCContext context)
{    ByteBuffer buf = ByteBuffer.wrap("ap".getBytes(StandardCharsets.UTF_8));    context.requestCallMeta().put(key, buf);    Assert.assertNotNull(context.getMessage());    Assert.assertNotNull(context.getRequestPayload());    Assert.assertNull(context.getResponsePayload());}
0
public void serverReceiveRequest(RPCContext context)
{    Map<String, ByteBuffer> meta = context.requestCallMeta();    Assert.assertNotNull(meta);    Assert.assertNotNull(context.getMessage());    Assert.assertNull(context.getResponsePayload());    if (!meta.containsKey(key))        return;    ByteBuffer buf = meta.get(key);    Assert.assertNotNull(buf);    Assert.assertNotNull(buf.array());    String partialstr = new String(buf.array(), StandardCharsets.UTF_8);    Assert.assertNotNull(partialstr);    Assert.assertEquals("partial string mismatch", "ap", partialstr);    buf = ByteBuffer.wrap((partialstr + "a").getBytes(StandardCharsets.UTF_8));    Assert.assertTrue(buf.remaining() > 0);    meta.put(key, buf);}
0
public void serverSendResponse(RPCContext context)
{    Assert.assertNotNull(context.requestCallMeta());    Assert.assertNotNull(context.responseCallMeta());    Assert.assertNotNull(context.getResponsePayload());    if (!context.requestCallMeta().containsKey(key))        return;    ByteBuffer buf = context.requestCallMeta().get(key);    Assert.assertNotNull(buf);    Assert.assertNotNull(buf.array());    String partialstr = new String(buf.array(), StandardCharsets.UTF_8);    Assert.assertNotNull(partialstr);    Assert.assertEquals("partial string mismatch", "apa", partialstr);    buf = ByteBuffer.wrap((partialstr + "c").getBytes(StandardCharsets.UTF_8));    Assert.assertTrue(buf.remaining() > 0);    context.responseCallMeta().put(key, buf);}
0
public void clientReceiveResponse(RPCContext context)
{    Assert.assertNotNull(context.responseCallMeta());    Assert.assertNotNull(context.getRequestPayload());    if (!context.responseCallMeta().containsKey(key))        return;    ByteBuffer buf = context.responseCallMeta().get(key);    Assert.assertNotNull(buf);    Assert.assertNotNull(buf.array());    String partialstr = new String(buf.array(), StandardCharsets.UTF_8);    Assert.assertNotNull(partialstr);    Assert.assertEquals("partial string mismatch", "apac", partialstr);    buf = ByteBuffer.wrap((partialstr + "he").getBytes(StandardCharsets.UTF_8));    Assert.assertTrue(buf.remaining() > 0);    context.responseCallMeta().put(key, buf);    checkRPCMetaMap(context.responseCallMeta());}
0
protected void checkRPCMetaMap(Map<String, ByteBuffer> rpcMeta)
{    Assert.assertNotNull(rpcMeta);    Assert.assertTrue("key not present in map", rpcMeta.containsKey(key));    ByteBuffer keybuf = rpcMeta.get(key);    Assert.assertNotNull(keybuf);    Assert.assertTrue("key BB had nothing remaining", keybuf.remaining() > 0);    String str = new String(keybuf.array(), StandardCharsets.UTF_8);    Assert.assertEquals("apache", str);}
0
private Request.Builder createPartialBuilder()
{    Request.Builder requestBuilder = Request.newBuilder();    requestBuilder.setTimestamp(1234567890);    requestBuilder.getConnectionBuilder().setNetworkType(NetworkType.IPv4);    requestBuilder.getHttpRequestBuilder().getUserAgentBuilder().setUseragent("Chrome 123").setId("Foo");    requestBuilder.getHttpRequestBuilder().getURIBuilder().setMethod(HttpMethod.GET).setPath("/index.html");    if (!requestBuilder.getHttpRequestBuilder().getURIBuilder().hasParameters()) {        requestBuilder.getHttpRequestBuilder().getURIBuilder().setParameters(new ArrayList<>());    }    requestBuilder.getHttpRequestBuilder().getURIBuilder().getParameters().add(QueryParameter.newBuilder().setName("Foo").setValue("Bar").build());    return requestBuilder;}
0
public void failOnIncompleteTree()
{    try {        createPartialBuilder().build();    } catch (AvroMissingFieldException amfe) {        assertEquals("Field networkAddress type:STRING pos:1 not set and has no default value", amfe.getMessage());        assertEquals("Path in schema: --> connection --> networkAddress", amfe.toString());        throw amfe;    }    fail("Should NEVER get here");}
0
public void copyBuilder()
{    Request.Builder requestBuilder1 = createPartialBuilder();    Request.Builder requestBuilder2 = Request.newBuilder(requestBuilder1);    requestBuilder1.getConnectionBuilder().setNetworkAddress("1.1.1.1");    requestBuilder2.getConnectionBuilder().setNetworkAddress("2.2.2.2");    requestBuilder2.getHttpRequestBuilder().getUserAgentBuilder().setId("Bar");    Request request1 = requestBuilder1.build();    Request request2 = requestBuilder2.build();    assertEquals(NetworkType.IPv4, request1.getConnection().getNetworkType());    assertEquals("1.1.1.1", request1.getConnection().getNetworkAddress());    assertEquals("Chrome 123", request1.getHttpRequest().getUserAgent().getUseragent());    assertEquals("Foo", request1.getHttpRequest().getUserAgent().getId());    assertEquals(HttpMethod.GET, request1.getHttpRequest().getURI().getMethod());    assertEquals("/index.html", request1.getHttpRequest().getURI().getPath());    assertEquals(1, request1.getHttpRequest().getURI().getParameters().size());    assertEquals("Foo", request1.getHttpRequest().getURI().getParameters().get(0).getName());    assertEquals("Bar", request1.getHttpRequest().getURI().getParameters().get(0).getValue());    assertEquals(NetworkType.IPv4, request2.getConnection().getNetworkType());    assertEquals("2.2.2.2", request2.getConnection().getNetworkAddress());    assertEquals("Chrome 123", request2.getHttpRequest().getUserAgent().getUseragent());    assertEquals("Bar", request2.getHttpRequest().getUserAgent().getId());    assertEquals(HttpMethod.GET, request2.getHttpRequest().getURI().getMethod());    assertEquals("/index.html", request2.getHttpRequest().getURI().getPath());    assertEquals(1, request2.getHttpRequest().getURI().getParameters().size());    assertEquals("Foo", request2.getHttpRequest().getURI().getParameters().get(0).getName());    assertEquals("Bar", request2.getHttpRequest().getURI().getParameters().get(0).getValue());}
0
public void createBuilderFromInstance()
{    Request.Builder requestBuilder1 = createPartialBuilder();    requestBuilder1.getConnectionBuilder().setNetworkAddress("1.1.1.1");    Request request1 = requestBuilder1.build();    Request.Builder requestBuilder2 = Request.newBuilder(request1);    requestBuilder2.getConnectionBuilder().setNetworkAddress("2.2.2.2");    requestBuilder2.getHttpRequestBuilder().getUserAgentBuilder().setId("Bar");    requestBuilder2.getHttpRequestBuilder().getURIBuilder().setMethod(HttpMethod.POST);    requestBuilder2.getHttpRequestBuilder().getUserAgentBuilder().setUseragent("Firefox 456");    Request request2 = requestBuilder2.build();    assertEquals(NetworkType.IPv4, request1.getConnection().getNetworkType());    assertEquals("1.1.1.1", request1.getConnection().getNetworkAddress());    assertEquals("Chrome 123", request1.getHttpRequest().getUserAgent().getUseragent());    assertEquals("Foo", request1.getHttpRequest().getUserAgent().getId());    assertEquals(HttpMethod.GET, request1.getHttpRequest().getURI().getMethod());    assertEquals("/index.html", request1.getHttpRequest().getURI().getPath());    assertEquals(1, request1.getHttpRequest().getURI().getParameters().size());    assertEquals("Foo", request1.getHttpRequest().getURI().getParameters().get(0).getName());    assertEquals("Bar", request1.getHttpRequest().getURI().getParameters().get(0).getValue());    assertEquals(NetworkType.IPv4, request2.getConnection().getNetworkType());    assertEquals("2.2.2.2", request2.getConnection().getNetworkAddress());    assertEquals("Firefox 456", request2.getHttpRequest().getUserAgent().getUseragent());    assertEquals("Bar", request2.getHttpRequest().getUserAgent().getId());    assertEquals(HttpMethod.POST, request2.getHttpRequest().getURI().getMethod());    assertEquals("/index.html", request2.getHttpRequest().getURI().getPath());    assertEquals(1, request2.getHttpRequest().getURI().getParameters().size());    assertEquals("Foo", request2.getHttpRequest().getURI().getParameters().get(0).getName());    assertEquals("Bar", request2.getHttpRequest().getURI().getParameters().get(0).getValue());}
0
private Request.Builder createLastOneTestsBuilder()
{    Request.Builder requestBuilder = Request.newBuilder();    requestBuilder.setTimestamp(1234567890);    requestBuilder.getConnectionBuilder().setNetworkType(NetworkType.IPv4).setNetworkAddress("1.1.1.1");    return requestBuilder;}
0
public void lastOneWins_Setter()
{    Request.Builder requestBuilder = createLastOneTestsBuilder();    requestBuilder.getHttpRequestBuilder().getURIBuilder().setMethod(HttpMethod.GET).setPath("/index.html");    requestBuilder.getHttpRequestBuilder().getUserAgentBuilder().setUseragent("Chrome 123").setId("Foo");    HttpRequest httpRequest = HttpRequest.newBuilder().setUserAgent(new UserAgent("Bar", "Firefox 321")).setURI(HttpURI.newBuilder().setMethod(HttpMethod.POST).setPath("/login.php").build()).build();    Request request = requestBuilder.setHttpRequest(httpRequest).build();    assertEquals(NetworkType.IPv4, request.getConnection().getNetworkType());    assertEquals("1.1.1.1", request.getConnection().getNetworkAddress());    assertEquals(0, request.getHttpRequest().getURI().getParameters().size());    assertEquals("Firefox 321", request.getHttpRequest().getUserAgent().getUseragent());    assertEquals("Bar", request.getHttpRequest().getUserAgent().getId());    assertEquals(HttpMethod.POST, request.getHttpRequest().getURI().getMethod());    assertEquals("/login.php", request.getHttpRequest().getURI().getPath());}
0
public void lastOneWins_Builder()
{    Request.Builder requestBuilder = createLastOneTestsBuilder();    HttpRequest httpRequest = HttpRequest.newBuilder().setUserAgent(new UserAgent("Bar", "Firefox 321")).setURI(HttpURI.newBuilder().setMethod(HttpMethod.POST).setPath("/login.php").build()).build();    requestBuilder.setHttpRequest(httpRequest);    requestBuilder.getHttpRequestBuilder().getURIBuilder().setMethod(HttpMethod.GET).setPath("/index.html");    requestBuilder.getHttpRequestBuilder().getUserAgentBuilder().setUseragent("Chrome 123").setId("Foo");    Request request = requestBuilder.build();    assertEquals(NetworkType.IPv4, request.getConnection().getNetworkType());    assertEquals("1.1.1.1", request.getConnection().getNetworkAddress());    assertEquals("Chrome 123", request.getHttpRequest().getUserAgent().getUseragent());    assertEquals("Foo", request.getHttpRequest().getUserAgent().getId());    assertEquals(0, request.getHttpRequest().getURI().getParameters().size());    assertEquals(HttpMethod.GET, request.getHttpRequest().getURI().getMethod());    assertEquals("/index.html", request.getHttpRequest().getURI().getPath());}
0
public void copyBuilderWithNullables()
{    RecordWithNullables.Builder builder = RecordWithNullables.newBuilder();    assertFalse(builder.hasNullableRecordBuilder());    assertFalse(builder.hasNullableRecord());    assertFalse(builder.hasNullableString());    assertFalse(builder.hasNullableLong());    assertFalse(builder.hasNullableInt());    assertFalse(builder.hasNullableMap());    assertFalse(builder.hasNullableArray());    RecordWithNullables.Builder builderCopy = RecordWithNullables.newBuilder(builder);    assertFalse(builderCopy.hasNullableRecordBuilder());    assertFalse(builderCopy.hasNullableRecord());    assertFalse(builderCopy.hasNullableString());    assertFalse(builderCopy.hasNullableLong());    assertFalse(builderCopy.hasNullableInt());    assertFalse(builderCopy.hasNullableMap());    assertFalse(builderCopy.hasNullableArray());    builderCopy.getNullableRecordBuilder();}
0
public void copyBuilderWithNullablesAndSetToNull()
{        RecordWithNullables.Builder builder = RecordWithNullables.newBuilder();        assertFalse(builder.hasNullableRecordBuilder());    assertFalse(builder.hasNullableRecord());    assertFalse(builder.hasNullableString());    assertFalse(builder.hasNullableLong());    assertFalse(builder.hasNullableInt());    assertFalse(builder.hasNullableMap());    assertFalse(builder.hasNullableArray());        builder.setNullableRecordBuilder(null);    builder.setNullableRecord(null);    builder.setNullableString(null);    builder.setNullableLong(null);    builder.setNullableInt(null);    builder.setNullableMap(null);    builder.setNullableArray(null);        assertFalse(builder.hasNullableRecordBuilder());        assertTrue(builder.hasNullableRecord());    assertTrue(builder.hasNullableString());    assertTrue(builder.hasNullableLong());    assertTrue(builder.hasNullableInt());    assertTrue(builder.hasNullableMap());    assertTrue(builder.hasNullableArray());        builder.getNullableRecordBuilder();    assertTrue(builder.hasNullableRecordBuilder());    assertFalse(builder.hasNullableRecord());        RecordWithNullables.Builder builderCopy = RecordWithNullables.newBuilder(builder);        assertTrue(builder.hasNullableRecordBuilder());    assertFalse(builder.hasNullableRecord());    assertTrue(builder.hasNullableString());    assertTrue(builder.hasNullableLong());    assertTrue(builder.hasNullableInt());    assertTrue(builder.hasNullableMap());    assertTrue(builder.hasNullableArray());}
0
public void getBuilderForRecordWithNullRecord()
{        RecordWithNullables recordWithNullables = RecordWithNullables.newBuilder().build();        RecordWithNullables.Builder builder = RecordWithNullables.newBuilder(recordWithNullables);        builder.getNullableRecordBuilder();}
0
public void getBuilderForNullRecord()
{        RecordWithNullables.newBuilder((RecordWithNullables) null);}
0
public void getBuilderForNullBuilder()
{        RecordWithNullables.newBuilder((RecordWithNullables.Builder) null);}
0
public void validateBrowsingOptionals()
{    Request.Builder requestBuilder = Request.newBuilder();    requestBuilder.setTimestamp(1234567890);    requestBuilder.getHttpRequestBuilder().getUserAgentBuilder().setUseragent("Chrome 123");    requestBuilder.getHttpRequestBuilder().getURIBuilder().setMethod(HttpMethod.GET).setPath("/index.html");    Request request = requestBuilder.build();    assertEquals("Chrome 123", Optional.of(request).flatMap(Request::getOptionalHttpRequest).flatMap(HttpRequest::getOptionalUserAgent).flatMap(UserAgent::getOptionalUseragent).orElse("UNKNOWN"));    assertFalse(Optional.of(request).flatMap(Request::getOptionalHttpRequest).flatMap(HttpRequest::getOptionalUserAgent).flatMap(UserAgent::getOptionalId).isPresent());    assertEquals(HttpMethod.GET, Optional.of(request).flatMap(Request::getOptionalHttpRequest).flatMap(HttpRequest::getOptionalURI).flatMap(HttpURI::getOptionalMethod).orElse(null));    assertEquals("/index.html", Optional.of(request).flatMap(Request::getOptionalHttpRequest).flatMap(HttpRequest::getOptionalURI).flatMap(HttpURI::getOptionalPath).orElse(null));}
0
public void testHashCode()
{    new TestRecord().hashCode();    SpecificData.get().hashCode(null, TestRecord.SCHEMA$);}
0
public void testToString()
{    new TestRecord().toString();}
0
public void testGetMapSchema() throws Exception
{    SpecificData.get().getSchema(X.class.getField("map").getGenericType());}
0
public void testSpecificWithinGeneric() throws Exception
{        Schema schema = Schema.createRecord("Foo", "", "x.y.z", false);    List<Schema.Field> fields = new ArrayList<>();    fields.add(new Schema.Field("f", TestRecord.SCHEMA$, "", null));    schema.setFields(fields);        TestRecord nested = new TestRecord();    nested.setName("foo");    nested.setKind(Kind.BAR);    nested.setHash(new MD5(new byte[] { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5 }));    GenericData.Record record = new GenericData.Record(schema);    record.put("f", nested);        TestSchema.checkBinary(schema, record, new SpecificDatumWriter<>(), new SpecificDatumReader<>());    TestSchema.checkDirectBinary(schema, record, new SpecificDatumWriter<>(), new SpecificDatumReader<>());    TestSchema.checkBlockingBinary(schema, record, new SpecificDatumWriter<>(), new SpecificDatumReader<>());}
0
public void testConvertGenericToSpecific()
{    GenericRecord generic = new GenericData.Record(TestRecord.SCHEMA$);    generic.put("name", "foo");    generic.put("kind", new GenericData.EnumSymbol(Kind.SCHEMA$, "BAR"));    generic.put("hash", new GenericData.Fixed(MD5.SCHEMA$, new byte[] { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5 }));    TestRecord specific = (TestRecord) SpecificData.get().deepCopy(TestRecord.SCHEMA$, generic);}
0
public void testGetClassSchema() throws Exception
{    Assert.assertEquals(TestRecord.getClassSchema(), TestRecord.SCHEMA$);    Assert.assertEquals(MD5.getClassSchema(), MD5.SCHEMA$);    Assert.assertEquals(Kind.getClassSchema(), Kind.SCHEMA$);}
0
public void testSpecificRecordToString() throws IOException
{    FooBarSpecificRecord foo = FooBarSpecificRecord.newBuilder().setId(123).setName("foo").setNicknames(Collections.singletonList("bar")).setRelatedids(Arrays.asList(1, 2, 3)).setTypeEnum(TypeEnum.c).build();    String json = foo.toString();    JsonFactory factory = new JsonFactory();    JsonParser parser = factory.createParser(json);    ObjectMapper mapper = new ObjectMapper();        mapper.readTree(parser);}
0
public void testExternalizeable() throws Exception
{    TestRecord before = new TestRecord();    before.setName("foo");    before.setKind(Kind.BAR);    before.setHash(new MD5(new byte[] { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5 }));    ByteArrayOutputStream bytes = new ByteArrayOutputStream();    ObjectOutputStream out = new ObjectOutputStream(bytes);    out.writeObject(before);    out.close();    ObjectInputStream in = new ObjectInputStream(new ByteArrayInputStream(bytes.toByteArray()));    TestRecord after = (TestRecord) in.readObject();    Assert.assertEquals(before, after);}
0
public void testReservedEnumSymbol() throws Exception
{    Assert.assertEquals(Reserved.default$, SpecificData.get().createEnum("default", Reserved.SCHEMA$));}
0
public static byte[] serializeRecord(FooBarSpecificRecord fooBarSpecificRecord) throws IOException
{    SpecificDatumWriter<FooBarSpecificRecord> datumWriter = new SpecificDatumWriter<>(FooBarSpecificRecord.SCHEMA$);    ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream();    Encoder encoder = EncoderFactory.get().binaryEncoder(byteArrayOutputStream, null);    datumWriter.write(fooBarSpecificRecord, encoder);    encoder.flush();    return byteArrayOutputStream.toByteArray();}
0
public static byte[] serializeRecord(StringablesRecord stringablesRecord) throws IOException
{    SpecificDatumWriter<StringablesRecord> datumWriter = new SpecificDatumWriter<>(StringablesRecord.SCHEMA$);    ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream();    Encoder encoder = EncoderFactory.get().binaryEncoder(byteArrayOutputStream, null);    datumWriter.write(stringablesRecord, encoder);    encoder.flush();    return byteArrayOutputStream.toByteArray();}
0
public void testRead() throws IOException
{    Builder newBuilder = FooBarSpecificRecord.newBuilder();    newBuilder.setId(42);    newBuilder.setName("foo");    newBuilder.setNicknames(Collections.singletonList("bar"));    newBuilder.setRelatedids(Arrays.asList(1, 2, 3));    FooBarSpecificRecord specificRecord = newBuilder.build();    byte[] recordBytes = serializeRecord(specificRecord);    Decoder decoder = DecoderFactory.get().binaryDecoder(recordBytes, null);    SpecificDatumReader<FooBarSpecificRecord> specificDatumReader = new SpecificDatumReader<>(FooBarSpecificRecord.SCHEMA$);    FooBarSpecificRecord deserialized = new FooBarSpecificRecord();    specificDatumReader.read(deserialized, decoder);    assertEquals(specificRecord, deserialized);}
0
public void testStringables() throws IOException
{    StringablesRecord.Builder newBuilder = StringablesRecord.newBuilder();    newBuilder.setValue(new BigDecimal("42.11"));    HashMap<String, BigDecimal> mapWithBigDecimalElements = new HashMap<>();    mapWithBigDecimalElements.put("test", new BigDecimal("11.11"));    newBuilder.setMapWithBigDecimalElements(mapWithBigDecimalElements);    HashMap<BigInteger, String> mapWithBigIntKeys = new HashMap<>();    mapWithBigIntKeys.put(BigInteger.ONE, "test");    newBuilder.setMapWithBigIntKeys(mapWithBigIntKeys);    StringablesRecord stringablesRecord = newBuilder.build();    byte[] recordBytes = serializeRecord(stringablesRecord);    Decoder decoder = DecoderFactory.get().binaryDecoder(recordBytes, null);    SpecificDatumReader<StringablesRecord> specificDatumReader = new SpecificDatumReader<>(StringablesRecord.SCHEMA$);    StringablesRecord deserialized = new StringablesRecord();    specificDatumReader.read(deserialized, decoder);    assertEquals(stringablesRecord, deserialized);}
0
public void testResolveUnion() throws IOException
{    final SpecificDatumWriter<TestRecordWithUnion> writer = new SpecificDatumWriter<>();    Schema schema = TestRecordWithUnion.SCHEMA$;    ByteArrayOutputStream out = new ByteArrayOutputStream();    JsonEncoder encoder = EncoderFactory.get().jsonEncoder(schema, out);    writer.setSchema(schema);    TestRecordWithUnion c = TestRecordWithUnion.newBuilder().setKind(Kind.BAR).setValue("rab").build();    writer.write(c, encoder);    encoder.flush();    out.close();    String expectedJson = String.format("{'kind':{'org.apache.avro.test.Kind':'%s'},'value':{'string':'%s'}}", c.getKind().toString(), c.getValue()).replace('\'', '"');    assertEquals(expectedJson, out.toString("UTF-8"));}
0
public void testSpecificErrorBuilder()
{    TestError.Builder testErrorBuilder = TestError.newBuilder().setValue("value").setCause(new NullPointerException()).setMessage$("message$");        Assert.assertTrue(testErrorBuilder.hasValue());    Assert.assertNotNull(testErrorBuilder.getValue());    Assert.assertTrue(testErrorBuilder.hasCause());    Assert.assertNotNull(testErrorBuilder.getCause());    Assert.assertTrue(testErrorBuilder.hasMessage$());    Assert.assertNotNull(testErrorBuilder.getMessage$());    TestError testError = testErrorBuilder.build();    Assert.assertEquals("value", testError.getValue());    Assert.assertEquals("value", testError.getMessage());    Assert.assertEquals("message$", testError.getMessage$());        Assert.assertEquals(testErrorBuilder, TestError.newBuilder(testErrorBuilder));    Assert.assertEquals(testErrorBuilder, TestError.newBuilder(testError));    TestError error = new TestError("value", new NullPointerException());    error.setMessage$("message");    Assert.assertEquals(error, TestError.newBuilder().setValue("value").setCause(new NullPointerException()).setMessage$("message").build());        testErrorBuilder.clearValue();    Assert.assertFalse(testErrorBuilder.hasValue());    Assert.assertNull(testErrorBuilder.getValue());    testErrorBuilder.clearCause();    Assert.assertFalse(testErrorBuilder.hasCause());    Assert.assertNull(testErrorBuilder.getCause());    testErrorBuilder.clearMessage$();    Assert.assertFalse(testErrorBuilder.hasMessage$());    Assert.assertNull(testErrorBuilder.getMessage$());}
0
public void attemptToSetNonNullableFieldToNull()
{    TestError.newBuilder().setMessage$(null);}
0
public void testSpecificBuilder()
{        Person.Builder builder = Person.newBuilder().setName("James Gosling").setYearOfBirth(1955).setState("CA");    Assert.assertTrue(builder.hasName());    Assert.assertEquals("James Gosling", builder.getName());    Assert.assertTrue(builder.hasYearOfBirth());    Assert.assertEquals(1955, builder.getYearOfBirth());    Assert.assertFalse(builder.hasCountry());    Assert.assertNull(builder.getCountry());    Assert.assertTrue(builder.hasState());    Assert.assertEquals("CA", builder.getState());    Assert.assertFalse(builder.hasFriends());    Assert.assertNull(builder.getFriends());    Assert.assertFalse(builder.hasLanguages());    Assert.assertNull(builder.getLanguages());    Person person = builder.build();    Assert.assertEquals("James Gosling", person.getName());    Assert.assertEquals(1955, person.getYearOfBirth());        Assert.assertEquals("US", person.getCountry());    Assert.assertEquals("CA", person.getState());        Assert.assertNotNull(person.getFriends());    Assert.assertEquals(0, person.getFriends().size());        Assert.assertNotNull(person.getLanguages());    Assert.assertEquals(2, person.getLanguages().size());    Assert.assertEquals("English", person.getLanguages().get(0));    Assert.assertEquals("Java", person.getLanguages().get(1));        Assert.assertEquals(builder, Person.newBuilder(builder));    Assert.assertEquals(person, Person.newBuilder(person).build());    Person.Builder builderCopy = Person.newBuilder(person);    Assert.assertEquals("James Gosling", builderCopy.getName());    Assert.assertEquals(1955, builderCopy.getYearOfBirth());        Assert.assertEquals("US", builderCopy.getCountry());    Assert.assertEquals("CA", builderCopy.getState());        Assert.assertNotNull(builderCopy.getFriends());    Assert.assertEquals(0, builderCopy.getFriends().size());        builderCopy.clearFriends().clearCountry();    Assert.assertFalse(builderCopy.hasFriends());    Assert.assertFalse(builderCopy.hasCountry());    Assert.assertNull(builderCopy.getFriends());    Assert.assertNull(builderCopy.getCountry());    Person person2 = builderCopy.build();    Assert.assertNotNull(person2.getFriends());    Assert.assertTrue(person2.getFriends().isEmpty());}
0
public void testUnions()
{    long datetime = 1234L;    String product = "widget";    PageView p = PageView.newBuilder().setDatetime(1234L).setPageContext(ProductPage.newBuilder().setProduct(product).build()).build();    Assert.assertEquals(datetime, p.getDatetime());    Assert.assertEquals(ProductPage.class, p.getPageContext().getClass());    Assert.assertEquals(product, ((ProductPage) p.getPageContext()).getProduct());    PageView p2 = PageView.newBuilder(p).build();    Assert.assertEquals(datetime, p2.getDatetime());    Assert.assertEquals(ProductPage.class, p2.getPageContext().getClass());    Assert.assertEquals(product, ((ProductPage) p2.getPageContext()).getProduct());    Assert.assertEquals(p, p2);}
0
public void testInterop()
{    Interop interop = Interop.newBuilder().setNullField(null).setArrayField(Arrays.asList(3.14159265, 6.022)).setBoolField(true).setBytesField(ByteBuffer.allocate(4).put(new byte[] { 3, 2, 1, 0 })).setDoubleField(1.41421).setEnumField(Kind.C).setFixedField(new MD5(new byte[] { 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3 })).setFloatField(1.61803f).setIntField(64).setLongField(1024).setMapField(Collections.singletonMap("Foo1", new Foo())).setRecordField(new Node()).setStringField("MyInterop").setUnionField(2.71828).build();    Interop copy = Interop.newBuilder(interop).build();    Assert.assertEquals(interop.getArrayField().size(), copy.getArrayField().size());    Assert.assertEquals(interop.getArrayField(), copy.getArrayField());    Assert.assertEquals(interop.getBoolField(), copy.getBoolField());    Assert.assertEquals(interop.getBytesField(), copy.getBytesField());    Assert.assertEquals(interop.getDoubleField(), copy.getDoubleField(), 0.001);    Assert.assertEquals(interop.getEnumField(), copy.getEnumField());    Assert.assertEquals(interop.getFixedField(), copy.getFixedField());    Assert.assertEquals(interop.getFloatField(), copy.getFloatField(), 0.001);    Assert.assertEquals(interop.getIntField(), copy.getIntField());    Assert.assertEquals(interop.getLongField(), copy.getLongField());    Assert.assertEquals(interop.getMapField(), copy.getMapField());    Assert.assertEquals(interop.getRecordField(), copy.getRecordField());    Assert.assertEquals(interop.getStringField(), copy.getStringField());    Assert.assertEquals(interop.getUnionField(), copy.getUnionField());    Assert.assertEquals(interop, copy);}
0
public void attemptToSetNonNullableFieldToNull()
{    Person.newBuilder().setName(null);}
0
public void buildWithoutSettingRequiredFields1()
{    Person.newBuilder().build();}
0
public void buildWithoutSettingRequiredFields2()
{        try {        Person.newBuilder().setYearOfBirth(1900).setState("MA").build();        Assert.fail("Should have thrown " + AvroRuntimeException.class.getCanonicalName());    } catch (AvroRuntimeException e) {                Assert.assertTrue(e.getMessage().contains("name"));    }}
0
public void buildWithoutSettingRequiredFields3()
{        try {        Person.newBuilder().setName("Anon").setState("CA").build();        Assert.fail("Should have thrown " + AvroRuntimeException.class.getCanonicalName());    } catch (AvroRuntimeException e) {                Assert.assertTrue(e.getMessage().contains("year_of_birth"));    }}
0
public void testBuilderPerformance()
{    int count = 1000000;    List<Person> friends = new ArrayList<>(0);    List<String> languages = new ArrayList<>(Arrays.asList("English", "Java"));    long startTimeNanos = System.nanoTime();    for (int ii = 0; ii < count; ii++) {        Person.newBuilder().setName("James Gosling").setYearOfBirth(1955).setCountry("US").setState("CA").setFriends(friends).setLanguages(languages).build();    }    long durationNanos = System.nanoTime() - startTimeNanos;    double durationMillis = durationNanos / 1e6d;    System.out.println("Built " + count + " records in " + durationMillis + "ms (" + (count / (durationMillis / 1000d)) + " records/sec, " + (durationMillis / count) + "ms/record");}
0
public void testBuilderPerformanceWithDefaultValues()
{    int count = 1000000;    long startTimeNanos = System.nanoTime();    for (int ii = 0; ii < count; ii++) {        Person.newBuilder().setName("James Gosling").setYearOfBirth(1955).setState("CA").build();    }    long durationNanos = System.nanoTime() - startTimeNanos;    double durationMillis = durationNanos / 1e6d;    System.out.println("Built " + count + " records in " + durationMillis + "ms (" + (count / (durationMillis / 1000d)) + " records/sec, " + (durationMillis / count) + "ms/record");}
0
public void testManualBuildPerformance()
{    int count = 1000000;    List<Person> friends = new ArrayList<>(0);    List<String> languages = new ArrayList<>(Arrays.asList("English", "Java"));    long startTimeNanos = System.nanoTime();    for (int ii = 0; ii < count; ii++) {        Person person = new Person();        person.name = "James Gosling";        person.year_of_birth = 1955;        person.state = "CA";        person.country = "US";        person.friends = friends;        person.languages = languages;    }    long durationNanos = System.nanoTime() - startTimeNanos;    double durationMillis = durationNanos / 1e6d;    System.out.println("Built " + count + " records in " + durationMillis + "ms (" + (count / (durationMillis / 1000d)) + " records/sec, " + (durationMillis / count) + "ms/record");}
0
public void testNull() throws Exception
{    Schema schema = new Schema.Parser().parse("\"null\"");    byte[] b = render(null, schema, new GenericDatumWriter<>());    assertEquals(0, BinaryData.compare(b, 0, b, 0, schema));}
0
public void testBoolean() throws Exception
{    check("\"boolean\"", Boolean.FALSE, Boolean.TRUE);}
0
public void testString() throws Exception
{    check("\"string\"", new Utf8(""), new Utf8("a"));    check("\"string\"", new Utf8("a"), new Utf8("b"));    check("\"string\"", new Utf8("a"), new Utf8("ab"));    check("\"string\"", new Utf8("ab"), new Utf8("b"));}
0
public void testBytes() throws Exception
{    check("\"bytes\"", ByteBuffer.wrap(new byte[] {}), ByteBuffer.wrap(new byte[] { 1 }));    check("\"bytes\"", ByteBuffer.wrap(new byte[] { 1 }), ByteBuffer.wrap(new byte[] { 2 }));    check("\"bytes\"", ByteBuffer.wrap(new byte[] { 1, 2 }), ByteBuffer.wrap(new byte[] { 2 }));}
0
public void testInt() throws Exception
{    check("\"int\"", -1, 0);    check("\"int\"", 0, 1);}
0
public void testLong() throws Exception
{    check("\"long\"", 11L, 12L);    check("\"long\"", (long) -1, 1L);}
0
public void testFloat() throws Exception
{    check("\"float\"", 1.1f, 1.2f);    check("\"float\"", (float) -1.1, 1.0f);}
0
public void testDouble() throws Exception
{    check("\"double\"", 1.2, 1.3);    check("\"double\"", -1.2, 1.3);}
0
public void testArray() throws Exception
{    String json = "{\"type\":\"array\", \"items\": \"long\"}";    Schema schema = new Schema.Parser().parse(json);    GenericArray<Long> a1 = new GenericData.Array<>(1, schema);    a1.add(1L);    GenericArray<Long> a2 = new GenericData.Array<>(1, schema);    a2.add(1L);    a2.add(0L);    check(json, a1, a2);}
0
public void testRecord() throws Exception
{    String fields = " \"fields\":[" + "{\"name\":\"f\",\"type\":\"int\",\"order\":\"ignore\"}," + "{\"name\":\"g\",\"type\":\"int\",\"order\":\"descending\"}," + "{\"name\":\"h\",\"type\":\"int\"}]}";    String recordJson = "{\"type\":\"record\", \"name\":\"Test\"," + fields;    Schema schema = new Schema.Parser().parse(recordJson);    GenericData.Record r1 = new GenericData.Record(schema);    r1.put("f", 1);    r1.put("g", 13);    r1.put("h", 41);    GenericData.Record r2 = new GenericData.Record(schema);    r2.put("f", 0);    r2.put("g", 12);    r2.put("h", 41);    check(recordJson, r1, r2);    r2.put("f", 0);    r2.put("g", 13);    r2.put("h", 42);    check(recordJson, r1, r2);    String record2Json = "{\"type\":\"record\", \"name\":\"Test2\"," + fields;    Schema schema2 = new Schema.Parser().parse(record2Json);    GenericData.Record r3 = new GenericData.Record(schema2);    r3.put("f", 1);    r3.put("g", 13);    r3.put("h", 41);        assert (!r1.equals(r3));}
0
public void testEnum() throws Exception
{    String json = "{\"type\":\"enum\", \"name\":\"Test\",\"symbols\": [\"A\", \"B\"]}";    Schema schema = new Schema.Parser().parse(json);    check(json, new GenericData.EnumSymbol(schema, "A"), new GenericData.EnumSymbol(schema, "B"));}
0
public void testFixed() throws Exception
{    String json = "{\"type\": \"fixed\", \"name\":\"Test\", \"size\": 1}";    Schema schema = new Schema.Parser().parse(json);    check(json, new GenericData.Fixed(schema, new byte[] { (byte) 'a' }), new GenericData.Fixed(schema, new byte[] { (byte) 'b' }));}
0
public void testUnion() throws Exception
{    check("[\"string\", \"long\"]", new Utf8("a"), new Utf8("b"), false);    check("[\"string\", \"long\"]", 1L, 2L, false);    check("[\"string\", \"long\"]", new Utf8("a"), 1L, false);}
0
public void testSpecificRecord() throws Exception
{    TestRecord s1 = new TestRecord();    TestRecord s2 = new TestRecord();    s1.setName("foo");    s1.setKind(Kind.BAZ);    s1.setHash(new MD5(new byte[] { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5 }));    s2.setName("bar");    s2.setKind(Kind.BAR);    s2.setHash(new MD5(new byte[] { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 6 }));    Schema schema = SpecificData.get().getSchema(TestRecord.class);    check(schema, s1, s2, true, new SpecificDatumWriter<>(schema), SpecificData.get());    s2.setKind(Kind.BAZ);    check(schema, s1, s2, true, new SpecificDatumWriter<>(schema), SpecificData.get());}
0
private static void check(String schemaJson, T o1, T o2) throws Exception
{    check(schemaJson, o1, o2, true);}
0
private static void check(String schemaJson, T o1, T o2, boolean comparable) throws Exception
{    check(new Schema.Parser().parse(schemaJson), o1, o2, comparable, new GenericDatumWriter<>(), GenericData.get());}
0
private static void check(Schema schema, T o1, T o2, boolean comparable, DatumWriter<T> writer, GenericData comparator) throws Exception
{    byte[] b1 = render(o1, schema, writer);    byte[] b2 = render(o2, schema, writer);    assertEquals(-1, BinaryData.compare(b1, 0, b2, 0, schema));    assertEquals(1, BinaryData.compare(b2, 0, b1, 0, schema));    assertEquals(0, BinaryData.compare(b1, 0, b1, 0, schema));    assertEquals(0, BinaryData.compare(b2, 0, b2, 0, schema));    assertEquals(-1, compare(o1, o2, schema, comparable, comparator));    assertEquals(1, compare(o2, o1, schema, comparable, comparator));    assertEquals(0, compare(o1, o1, schema, comparable, comparator));    assertEquals(0, compare(o2, o2, schema, comparable, comparator));    assert (o1.equals(o1));    assert (o2.equals(o2));    assert (!o1.equals(o2));    assert (!o2.equals(o1));    assert (!o1.equals(new Object()));    assert (!o2.equals(new Object()));    assert (!o1.equals(null));    assert (!o2.equals(null));    assert (o1.hashCode() != o2.hashCode());        if (schema.getType() != Schema.Type.ENUM) {        assertEquals(o1.hashCode(), BinaryData.hashCode(b1, 0, b1.length, schema));        assertEquals(o2.hashCode(), BinaryData.hashCode(b2, 0, b2.length, schema));    }        assertEquals(comparator.hashCode(o1, schema), BinaryData.hashCode(b1, 0, b1.length, schema));    assertEquals(comparator.hashCode(o2, schema), BinaryData.hashCode(b2, 0, b2.length, schema));}
0
private static int compare(Object o1, Object o2, Schema schema, boolean comparable, GenericData comparator)
{    return comparable ? ((Comparable<Object>) o1).compareTo(o2) : comparator.compare(o1, o2, schema);}
0
private static byte[] render(T datum, Schema schema, DatumWriter<T> writer) throws IOException
{    ByteArrayOutputStream out = new ByteArrayOutputStream();    writer.setSchema(schema);    Encoder enc = new EncoderFactory().directBinaryEncoder(out, null);    writer.write(datum, enc);    enc.flush();    return out.toByteArray();}
0
public void testSpecificDatumReaderDefaultCtor() throws IOException
{    File file = new File(DIR.getRoot().getPath(), "testSpecificDatumReaderDefaultCtor");        Schema s1 = new Schema.Parser().parse("{\"type\":\"record\",\"name\":\"Foo\"," + "\"namespace\":\"org.apache.avro\",\"fields\":[" + "{\"name\":\"label\",\"type\":\"string\"}," + "{\"name\":\"id\",\"type\":\"int\"}]}");        try (DataFileWriter<Record> writer = new DataFileWriter<>(new GenericDatumWriter<Record>(s1)).create(s1, file)) {        for (int i = 0; i < 10; i++) {            Record r = new Record(s1);            r.put("label", "" + i);            r.put("id", i);            writer.append(r);        }    }        try (DataFileReader<Foo> reader = new DataFileReader<>(file, new SpecificDatumReader<>())) {        int i = 0;        for (Foo f : reader) {            Assert.assertEquals("" + (i++), f.getLabel());        }        Assert.assertEquals(10, i);    }}
0
public void testStartServer() throws Exception
{    if (server != null)        return;    server = new SocketServer(new ReflectResponder(TestNamespace.class, new TestImpl()), new InetSocketAddress(0));    server.start();    client = new SocketTransceiver(new InetSocketAddress(server.getPort()));    proxy = ReflectRequestor.getClient(TestNamespace.class, client);}
0
public TestRecord echo(TestRecord record)
{    return record;}
0
public void error() throws TestError
{    throw TestError.newBuilder().setMessage$("an error").build();}
0
public void testStartServer() throws Exception
{    if (server != null)        return;    server = new SocketServer(new SpecificResponder(TestNamespace.class, new TestImpl()), new InetSocketAddress(0));    server.start();    client = new SocketTransceiver(new InetSocketAddress(server.getPort()));    proxy = SpecificRequestor.getClient(TestNamespace.class, client);}
0
public void testEcho() throws IOException
{    TestRecord record = new TestRecord();    record.setHash(new MD5(new byte[] { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5 }));    TestRecord echoed = proxy.echo(record);    assertEquals(record, echoed);    assertEquals(record.hashCode(), echoed.hashCode());}
0
public void testError() throws IOException
{    TestError error = null;    try {        proxy.error();    } catch (TestError e) {        error = e;    }    assertNotNull(error);    assertEquals("an error", error.getMessage$());}
0
public static void testStopServer() throws IOException
{    client.close();    server.close();}
0
public Server createServer(Responder testResponder) throws Exception
{    return new DatagramServer(new SpecificResponder(Simple.class, new TestImpl()), new InetSocketAddress("localhost", new Random().nextInt(10000) + 10000));}
0
public Transceiver createTransceiver() throws Exception
{    return new DatagramTransceiver(new InetSocketAddress("localhost", server.getPort()));}
0
protected int getExpectedHandshakeCount()
{    return 0;}
0
public Object respond(Message message, Object request) throws AvroRemoteException
{    GenericRecord params = (GenericRecord) request;    if ("hello".equals(message.getName())) {                return new Utf8("goodbye");    }    if ("echo".equals(message.getName())) {        Object record = params.get("record");                return record;    }    if ("echoBytes".equals(message.getName())) {        Object data = params.get("data");                return data;    }    if ("error".equals(message.getName())) {        if (throwUndeclaredError)            throw new RuntimeException("foo");        GenericRecord error = new GenericData.Record(PROTOCOL.getType("TestError"));        error.put("message", new Utf8("an error"));        throw new AvroRemoteException(error);    }    throw new AvroRuntimeException("unexpected message: " + message.getName());}
1
public void testStartServer() throws Exception
{    if (server != null)        return;    server = new SocketServer(new TestResponder(), new InetSocketAddress(0));    server.start();    client = new SocketTransceiver(new InetSocketAddress(server.getPort()));    requestor = new GenericRequestor(PROTOCOL, client);}
0
public void testHello() throws Exception
{    GenericRecord params = new GenericData.Record(PROTOCOL.getMessages().get("hello").getRequest());    params.put("greeting", new Utf8("bob"));    Utf8 response = (Utf8) requestor.request("hello", params);    assertEquals(new Utf8("goodbye"), response);}
0
public void testEcho() throws Exception
{    GenericRecord record = new GenericData.Record(PROTOCOL.getType("TestRecord"));    record.put("name", new Utf8("foo"));    record.put("kind", new GenericData.EnumSymbol(PROTOCOL.getType("Kind"), "BAR"));    record.put("hash", new GenericData.Fixed(PROTOCOL.getType("MD5"), new byte[] { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5 }));    GenericRecord params = new GenericData.Record(PROTOCOL.getMessages().get("echo").getRequest());    params.put("record", record);    Object echoed = requestor.request("echo", params);    assertEquals(record, echoed);}
0
public void testEchoBytes() throws Exception
{    Random random = new Random();    int length = random.nextInt(1024 * 16);    GenericRecord params = new GenericData.Record(PROTOCOL.getMessages().get("echoBytes").getRequest());    ByteBuffer data = ByteBuffer.allocate(length);    random.nextBytes(data.array());    data.flip();    params.put("data", data);    Object echoed = requestor.request("echoBytes", params);    assertEquals(data, echoed);}
0
public void testError() throws Exception
{    GenericRecord params = new GenericData.Record(PROTOCOL.getMessages().get("error").getRequest());    AvroRemoteException error = null;    try {        requestor.request("error", params);    } catch (AvroRemoteException e) {        error = e;    }    assertNotNull(error);    assertEquals("an error", ((GenericRecord) error.getValue()).get("message").toString());}
0
public void testUndeclaredError() throws Exception
{    this.throwUndeclaredError = true;    RuntimeException error = null;    GenericRecord params = new GenericData.Record(PROTOCOL.getMessages().get("error").getRequest());    try {        requestor.request("error", params);    } catch (RuntimeException e) {        error = e;    } finally {        this.throwUndeclaredError = false;    }    assertNotNull(error);    assertTrue(error.toString().contains("foo"));}
0
public void testHandshake() throws Exception
{    Protocol protocol = new Protocol("Simple", "org.apache.avro.test");    List<Field> fields = new ArrayList<>();    fields.add(new Schema.Field("extra", Schema.create(Schema.Type.BOOLEAN), null, null));    fields.add(new Schema.Field("greeting", Schema.create(Schema.Type.STRING), null, null));    Protocol.Message message = protocol.createMessage("hello", null, /* doc */    new LinkedHashMap<String, String>(), Schema.createRecord(fields), Schema.create(Schema.Type.STRING), Schema.createUnion(new ArrayList<>()));    protocol.getMessages().put("hello", message);    try (Transceiver t = new SocketTransceiver(new InetSocketAddress(server.getPort()))) {        GenericRequestor r = new GenericRequestor(protocol, t);        GenericRecord params = new GenericData.Record(message.getRequest());        params.put("extra", Boolean.TRUE);        params.put("greeting", new Utf8("bob"));        Utf8 response = (Utf8) r.request("hello", params);        assertEquals(new Utf8("goodbye"), response);    }}
0
public void testResponseChange() throws Exception
{    List<Field> fields = new ArrayList<>();    for (Field f : PROTOCOL.getType("TestRecord").getFields()) fields.add(new Field(f.name(), f.schema(), null, null));    fields.add(new Field("extra", Schema.create(Schema.Type.BOOLEAN), null, true));    Schema record = Schema.createRecord("TestRecord", null, "org.apache.avro.test", false);    record.setFields(fields);    Protocol protocol = new Protocol("Simple", "org.apache.avro.test");    List<Field> params = new ArrayList<>();    params.add(new Field("record", record, null, null));    Protocol.Message message = protocol.createMessage("echo", null, new LinkedHashMap<String, String>(), Schema.createRecord(params), record, Schema.createUnion(new ArrayList<>()));    protocol.getMessages().put("echo", message);    try (Transceiver t = new SocketTransceiver(new InetSocketAddress(server.getPort()))) {        GenericRequestor r = new GenericRequestor(protocol, t);        GenericRecord args = new GenericData.Record(message.getRequest());        GenericRecord rec = new GenericData.Record(record);        rec.put("name", new Utf8("foo"));        rec.put("kind", new GenericData.EnumSymbol(PROTOCOL.getType("Kind"), "BAR"));        rec.put("hash", new GenericData.Fixed(PROTOCOL.getType("MD5"), new byte[] { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5 }));        rec.put("extra", Boolean.TRUE);        args.put("record", rec);        GenericRecord response = (GenericRecord) r.request("echo", args);        assertEquals(rec, response);    }}
0
public static void testStopServer() throws Exception
{    client.close();    server.close();}
0
public void testStartServer() throws Exception
{    if (server != null)        return;    Responder responder = new TestResponder();    responder.addRPCPlugin(new RPCMetaTestPlugin("key1"));    responder.addRPCPlugin(new RPCMetaTestPlugin("key2"));    server = new SocketServer(responder, new InetSocketAddress(0));    server.start();    client = new SocketTransceiver(new InetSocketAddress(server.getPort()));    requestor = new GenericRequestor(PROTOCOL, client);    requestor.addRPCPlugin(new RPCMetaTestPlugin("key1"));    requestor.addRPCPlugin(new RPCMetaTestPlugin("key2"));}
0
public static Protocol getSimpleProtocol() throws IOException
{    File file = new File("../../../share/test/schemas/simple.avpr");    return Protocol.parse(file);}
0
public void testParsing() throws IOException
{    Protocol protocol = getSimpleProtocol();    assertEquals(protocol.getDoc(), "Protocol used for testing.");    assertEquals(6, protocol.getMessages().size());    assertEquals("Pretend you're in a cave!", protocol.getMessages().get("echo").getDoc());}
0
private static Message parseMessage(String message) throws Exception
{    return Protocol.parse("{\"protocol\": \"org.foo.Bar\"," + "\"types\": []," + "\"messages\": {" + message + "}}").getMessages().values().iterator().next();}
0
public void oneWay() throws Exception
{    Message m;        m = parseMessage("\"ack\": {" + "\"request\": []," + "\"response\": \"null\"," + "\"one-way\": true}");    assertTrue(m.isOneWay());        m = parseMessage("\"ack\": {" + "\"request\": []," + "\"one-way\": true}");    assertTrue(m.isOneWay());}
0
public void oneWayResponse() throws Exception
{        parseMessage("\"ack\": {" + "\"request\": [\"string\"]," + "\"response\": \"string\"," + "\"one-way\": true}");}
0
public void oneWayError() throws Exception
{        parseMessage("\"ack\": {" + "\"request\": [\"string\"]," + "\"errors\": []," + "\"one-way\": true}");}
0
public void testMessageFieldAliases() throws IOException
{    Protocol protocol = getSimpleProtocol();    final Message msg = protocol.getMessages().get("hello");    assertNotNull(msg);    final Schema.Field field = msg.getRequest().getField("greeting");    assertNotNull(field);    assertTrue(field.aliases().contains("salute"));}
0
public void testMessageCustomProperties() throws IOException
{    Protocol protocol = getSimpleProtocol();    final Message msg = protocol.getMessages().get("hello");    assertNotNull(msg);    final Schema.Field field = msg.getRequest().getField("greeting");    assertNotNull(field);    assertEquals("customValue", field.getProp("customProp"));}
0
public int hashCode()
{    return this.name.hashCode();}
0
public boolean equals(Object that)
{    return this.name.equals(((TestRecord) that).name);}
0
public String hello(String greeting)
{    return "goodbye";}
0
public int add(int arg1, int arg2)
{    return arg1 + arg2;}
0
public TestRecord echo(TestRecord record)
{    return record;}
0
public byte[] echoBytes(byte[] data)
{    return data;}
0
public void error() throws SimpleException
{    if (throwUndeclaredError)        throw new RuntimeException("foo");    throw new SimpleException("foo");}
0
public void testStartServer() throws Exception
{    if (server != null)        return;    server = new SocketServer(new ReflectResponder(Simple.class, new TestImpl()), new InetSocketAddress(0));    server.start();    client = new SocketTransceiver(new InetSocketAddress(server.getPort()));    proxy = ReflectRequestor.getClient(Simple.class, client);}
0
public void testClassLoader() throws Exception
{    ClassLoader loader = new ClassLoader() {    };    ReflectResponder responder = new ReflectResponder(Simple.class, new TestImpl(), new ReflectData(loader));    assertEquals(responder.getReflectData().getClassLoader(), loader);    ReflectRequestor requestor = new ReflectRequestor(Simple.class, client, new ReflectData(loader));    assertEquals(requestor.getReflectData().getClassLoader(), loader);}
0
public void testHello() throws IOException
{    String response = proxy.hello("bob");    assertEquals("goodbye", response);}
0
public void testEcho() throws IOException
{    TestRecord record = new TestRecord();    record.name = "foo";    TestRecord echoed = proxy.echo(record);    assertEquals(record, echoed);}
0
public void testAdd() throws IOException
{    int result = proxy.add(1, 2);    assertEquals(3, result);}
0
public void testEchoBytes() throws IOException
{    Random random = new Random();    int length = random.nextInt(1024 * 16);    byte[] data = new byte[length];    random.nextBytes(data);    byte[] echoed = proxy.echoBytes(data);    assertArrayEquals(data, echoed);}
0
public void testError() throws IOException
{    SimpleException error = null;    try {        proxy.error();    } catch (SimpleException e) {        error = e;    }    assertNotNull(error);    assertEquals("foo", error.getMessage());}
0
public void testUndeclaredError() throws Exception
{    this.throwUndeclaredError = true;    RuntimeException error = null;    try {        proxy.error();    } catch (AvroRuntimeException e) {        error = e;    } finally {        this.throwUndeclaredError = false;    }    assertNotNull(error);    assertTrue(error.toString().contains("foo"));}
0
public static void testStopServer() throws IOException
{    client.close();    server.close();}
0
public void testStartServer() throws Exception
{    if (server != null)        return;    ReflectResponder rresp = new ReflectResponder(Simple.class, new TestImpl());    rresp.addRPCPlugin(new RPCMetaTestPlugin("key1"));    rresp.addRPCPlugin(new RPCMetaTestPlugin("key2"));    server = new SocketServer(rresp, new InetSocketAddress(0));    server.start();    client = new SocketTransceiver(new InetSocketAddress(server.getPort()));    ReflectRequestor requestor = new ReflectRequestor(Simple.class, client);    requestor.addRPCPlugin(new RPCMetaTestPlugin("key1"));    requestor.addRPCPlugin(new RPCMetaTestPlugin("key2"));    proxy = ReflectRequestor.getClient(Simple.class, requestor);}
0
public String hello(String greeting)
{    return "goodbye";}
0
public int add(int arg1, int arg2)
{    return arg1 + arg2;}
0
public TestRecord echo(TestRecord record)
{    return record;}
0
public ByteBuffer echoBytes(ByteBuffer data)
{    return data;}
0
public void error() throws TestError
{    if (throwUndeclaredError)        throw new RuntimeException("foo");    throw TestError.newBuilder().setMessage$("an error").build();}
0
public void ack()
{    ackCount++;}
0
public void testStartServer() throws Exception
{    if (server != null)        return;    responder = new SpecificResponder(Simple.class, new TestImpl());    server = createServer(responder);    server.start();    client = createTransceiver();    SpecificRequestor req = new SpecificRequestor(Simple.class, client);    addRpcPlugins(req);    proxy = SpecificRequestor.getClient(Simple.class, req);    monitor = new HandshakeMonitor();    responder.addRPCPlugin(monitor);}
0
public void addRpcPlugins(Requestor requestor)
{}
0
public Server createServer(Responder testResponder) throws Exception
{    return server = new SocketServer(testResponder, new InetSocketAddress(0));}
0
public Transceiver createTransceiver() throws Exception
{    return new SocketTransceiver(new InetSocketAddress(server.getPort()));}
0
public void testClassLoader() throws Exception
{    ClassLoader loader = new ClassLoader() {    };    SpecificResponder responder = new SpecificResponder(Simple.class, new TestImpl(), new SpecificData(loader));    assertEquals(responder.getSpecificData().getClassLoader(), loader);    SpecificRequestor requestor = new SpecificRequestor(Simple.class, client, new SpecificData(loader));    assertEquals(requestor.getSpecificData().getClassLoader(), loader);}
0
public void testGetRemote() throws IOException
{    assertEquals(Simple.PROTOCOL, SpecificRequestor.getRemote(proxy));}
0
public void testHello() throws IOException
{    String response = proxy.hello("bob");    assertEquals("goodbye", response);}
0
public void testHashCode() throws IOException
{    TestError error = new TestError();    error.hashCode();}
0
public void testEcho() throws IOException
{    TestRecord record = new TestRecord();    record.setName("foo");    record.setKind(Kind.BAR);    record.setHash(new MD5(new byte[] { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5 }));    TestRecord echoed = proxy.echo(record);    assertEquals(record, echoed);    assertEquals(record.hashCode(), echoed.hashCode());}
0
public void testAdd() throws IOException
{    int result = proxy.add(1, 2);    assertEquals(3, result);}
0
public void testEchoBytes() throws IOException
{    Random random = new Random();    int length = random.nextInt(1024 * 16);    ByteBuffer data = ByteBuffer.allocate(length);    random.nextBytes(data.array());    data.flip();    ByteBuffer echoed = proxy.echoBytes(data);    assertEquals(data, echoed);}
0
public void testEmptyEchoBytes() throws IOException
{    ByteBuffer data = ByteBuffer.allocate(0);    ByteBuffer echoed = proxy.echoBytes(data);    data.flip();    assertEquals(data, echoed);}
0
public void testError() throws IOException
{    TestError error = null;    try {        proxy.error();    } catch (TestError e) {        error = e;    }    assertNotNull(error);    assertEquals("an error", error.getMessage$());}
0
public void testUndeclaredError() throws Exception
{    this.throwUndeclaredError = true;    RuntimeException error = null;    try {        proxy.error();    } catch (RuntimeException e) {        error = e;    } finally {        this.throwUndeclaredError = false;    }    assertNotNull(error);    assertTrue(error.toString().contains("foo"));}
0
public void testOneWay() throws IOException
{    ackCount = 0;    proxy.ack();        proxy.hello("foo");    proxy.ack();    try {        Thread.sleep(100);    } catch (InterruptedException e) {    }    assertEquals(2, ackCount);}
0
public void testRepeatedAccess() throws Exception
{    for (int x = 0; x < 1000; x++) {        proxy.hello("hi!");    }}
0
public void testConnectionRefusedOneWay() throws IOException
{    Transceiver client = new HttpTransceiver(new URL("http://localhost:4444"));    SpecificRequestor req = new SpecificRequestor(Simple.class, client);    addRpcPlugins(req);    Simple proxy = SpecificRequestor.getClient(Simple.class, req);    proxy.ack();}
0
public void testParamVariation() throws Exception
{    Protocol protocol = new Protocol("Simple", "org.apache.avro.test");    List<Schema.Field> fields = new ArrayList<>();    fields.add(new Schema.Field("extra", Schema.create(Schema.Type.BOOLEAN), null, null));    fields.add(new Schema.Field("greeting", Schema.create(Schema.Type.STRING), null, null));    Protocol.Message message = protocol.createMessage("hello", null, /* doc */    new LinkedHashMap<String, String>(), Schema.createRecord(fields), Schema.create(Schema.Type.STRING), Schema.createUnion(new ArrayList<>()));    protocol.getMessages().put("hello", message);    try (Transceiver t = createTransceiver()) {        GenericRequestor r = new GenericRequestor(protocol, t);        addRpcPlugins(r);        GenericRecord params = new GenericData.Record(message.getRequest());        params.put("extra", Boolean.TRUE);        params.put("greeting", "bob");        String response = r.request("hello", params).toString();        assertEquals("goodbye", response);    }}
0
public static void testHandshakeCount() throws IOException
{    monitor.assertHandshake();}
0
public static void testStopServer() throws IOException
{    client.close();    server.close();    server = null;}
0
public void serverConnecting(RPCContext context)
{    handshakes++;    int expected = getExpectedHandshakeCount();    if (expected > 0 && handshakes > expected) {        throw new IllegalStateException("Expected number of Protocol negotiation handshakes exceeded expected " + expected + " was " + handshakes);    }        String clientProtocol = context.getHandshakeRequest().clientProtocol;    if (clientProtocol != null) {        assertFalse(seenProtocols.contains(clientProtocol));        seenProtocols.add(clientProtocol);    }}
0
public void assertHandshake()
{    int expected = getExpectedHandshakeCount();    if (expected != REPEATING) {        assertEquals("Expected number of handshakes did not take place.", expected, handshakes);    }}
0
protected int getExpectedHandshakeCount()
{    return 3;}
0
public void testClient() throws Exception
{    for (File f : Objects.requireNonNull(SERVER_PORTS_DIR.listFiles())) {        LineNumberReader reader = new LineNumberReader(new FileReader(f));        int port = Integer.parseInt(reader.readLine());        System.out.println("Validating java client to " + f.getName() + " - " + port);        Transceiver client = new SocketTransceiver(new InetSocketAddress("localhost", port));        proxy = SpecificRequestor.getClient(Simple.class, client);        TestProtocolSpecific proto = new TestProtocolSpecific();        proto.testHello();        proto.testEcho();        proto.testEchoBytes();        proto.testError();        System.out.println("Done! Validation java client to " + f.getName() + " - " + port);    }}
0
public static void main(String[] args) throws Exception
{    SocketServer server = new SocketServer(new SpecificResponder(Simple.class, new TestImpl()), new InetSocketAddress(0));    server.start();    File portFile = new File(SERVER_PORTS_DIR, "java-port");    FileWriter w = new FileWriter(portFile);    w.write(Integer.toString(server.getPort()));    w.close();}
0
public Server createServer(Responder testResponder) throws Exception
{    responder.addRPCPlugin(new RPCMetaTestPlugin("key1"));    responder.addRPCPlugin(new RPCMetaTestPlugin("key2"));    return new SocketServer(responder, new InetSocketAddress(0));}
0
public Transceiver createTransceiver() throws Exception
{    return new SocketTransceiver(new InetSocketAddress(server.getPort()));}
0
public void addRpcPlugins(Requestor req)
{    req.addRPCPlugin(new RPCMetaTestPlugin("key1"));    req.addRPCPlugin(new RPCMetaTestPlugin("key2"));}
0
public void testNull() throws Exception
{    assertEquals(Schema.create(Type.NULL), new Schema.Parser().parse("\"null\""));    assertEquals(Schema.create(Type.NULL), new Schema.Parser().parse("{\"type\":\"null\"}"));    check(new File(DIR.getRoot(), name.getMethodName()), "\"null\"", "null", null);}
0
public void testBoolean() throws Exception
{    assertEquals(Schema.create(Type.BOOLEAN), new Schema.Parser().parse("\"boolean\""));    assertEquals(Schema.create(Type.BOOLEAN), new Schema.Parser().parse("{\"type\":\"boolean\"}"));    check(new File(DIR.getRoot(), name.getMethodName()), "\"boolean\"", "true", Boolean.TRUE);}
0
public void testString() throws Exception
{    assertEquals(Schema.create(Type.STRING), new Schema.Parser().parse("\"string\""));    assertEquals(Schema.create(Type.STRING), new Schema.Parser().parse("{\"type\":\"string\"}"));    check(new File(DIR.getRoot(), name.getMethodName()), "\"string\"", "\"foo\"", new Utf8("foo"));}
0
public void testBytes() throws Exception
{    assertEquals(Schema.create(Type.BYTES), new Schema.Parser().parse("\"bytes\""));    assertEquals(Schema.create(Type.BYTES), new Schema.Parser().parse("{\"type\":\"bytes\"}"));    check(new File(DIR.getRoot(), name.getMethodName()), "\"bytes\"", "\"\\u0000ABC\\u00FF\"", ByteBuffer.wrap(new byte[] { 0, 65, 66, 67, -1 }));}
0
public void testInt() throws Exception
{    assertEquals(Schema.create(Type.INT), new Schema.Parser().parse("\"int\""));    assertEquals(Schema.create(Type.INT), new Schema.Parser().parse("{\"type\":\"int\"}"));    check(new File(DIR.getRoot(), name.getMethodName()), "\"int\"", "9", 9);}
0
public void testLong() throws Exception
{    assertEquals(Schema.create(Type.LONG), new Schema.Parser().parse("\"long\""));    assertEquals(Schema.create(Type.LONG), new Schema.Parser().parse("{\"type\":\"long\"}"));    check(new File(DIR.getRoot(), name.getMethodName()), "\"long\"", "11", 11L);}
0
public void testFloat() throws Exception
{    assertEquals(Schema.create(Type.FLOAT), new Schema.Parser().parse("\"float\""));    assertEquals(Schema.create(Type.FLOAT), new Schema.Parser().parse("{\"type\":\"float\"}"));    check(new File(DIR.getRoot(), name.getMethodName()), "\"float\"", "1.1", 1.1f);    checkDefault("\"float\"", "\"NaN\"", Float.NaN);    checkDefault("\"float\"", "\"Infinity\"", Float.POSITIVE_INFINITY);    checkDefault("\"float\"", "\"-Infinity\"", Float.NEGATIVE_INFINITY);}
0
public void testDouble() throws Exception
{    assertEquals(Schema.create(Type.DOUBLE), new Schema.Parser().parse("\"double\""));    assertEquals(Schema.create(Type.DOUBLE), new Schema.Parser().parse("{\"type\":\"double\"}"));    check(new File(DIR.getRoot(), name.getMethodName()), "\"double\"", "1.2", 1.2);    checkDefault("\"double\"", "\"NaN\"", Double.NaN);    checkDefault("\"double\"", "\"Infinity\"", Double.POSITIVE_INFINITY);    checkDefault("\"double\"", "\"-Infinity\"", Double.NEGATIVE_INFINITY);}
0
public void testArray() throws Exception
{    String json = "{\"type\":\"array\", \"items\": \"long\"}";    Schema schema = new Schema.Parser().parse(json);    Collection<Long> array = new GenericData.Array<>(1, schema);    array.add(1L);    check(new File(DIR.getRoot(), name.getMethodName()), json, "[1]", array);    array = new ArrayList<>(1);    array.add(1L);    check(new File(DIR.getRoot(), name.getMethodName()), json, "[1]", array);        checkParseError("{\"type\":\"array\"}");}
0
public void testMap() throws Exception
{    HashMap<Utf8, Long> map = new HashMap<>();    map.put(new Utf8("a"), 1L);    check(new File(DIR.getRoot(), name.getMethodName()), "{\"type\":\"map\", \"values\":\"long\"}", "{\"a\":1}", map);        checkParseError("{\"type\":\"map\"}");}
0
public void testUnionMap() throws Exception
{    String unionMapSchema = "{\"name\":\"foo\", \"type\":\"record\"," + " \"fields\":[ {\"name\":\"mymap\", \"type\":" + "   [{\"type\":\"map\", \"values\":" + "      [\"int\",\"long\",\"float\",\"string\"]}," + "    \"null\"]" + "   }]" + " }";    check(new File(DIR.getRoot(), name.getMethodName()), unionMapSchema, true);}
0
public void testRecord() throws Exception
{    String recordJson = "{\"type\":\"record\", \"name\":\"Test\", \"fields\":" + "[{\"name\":\"f\", \"type\":\"long\", \"foo\":\"bar\"}]}";    Schema schema = new Schema.Parser().parse(recordJson);    GenericData.Record record = new GenericData.Record(schema);    record.put("f", 11L);    check(new File(DIR.getRoot(), name.getMethodName()), recordJson, "{\"f\":11}", record, false);        assertEquals("bar", schema.getField("f").getProp("foo"));    assertEquals("bar", new Schema.Parser().parse(schema.toString()).getField("f").getProp("foo"));    schema.getField("f").addProp("baz", "boo");    assertEquals("boo", schema.getField("f").getProp("baz"));    checkParseError("{\"type\":\"record\"}");    checkParseError("{\"type\":\"record\",\"name\":\"X\"}");    checkParseError("{\"type\":\"record\",\"name\":\"X\",\"fields\":\"Y\"}");        checkParseError("{\"type\":\"record\",\"name\":\"X\",\"fields\":" + "[{\"name\":\"f\"}]}");        checkParseError("{\"type\":\"record\",\"name\":\"X\",\"fields\":" + "[{\"type\":\"long\"}]}");        checkParseError("{\"type\":\"record\",\"name\":\"1X\",\"fields\":[]}");    checkParseError("{\"type\":\"record\",\"name\":\"X$\",\"fields\":[]}");        checkParseError("{\"type\":\"record\",\"name\":\"X\",\"fields\":[" + "{\"name\":\"1f\",\"type\":\"int\"}]}");    checkParseError("{\"type\":\"record\",\"name\":\"X\",\"fields\":[" + "{\"name\":\"f$\",\"type\":\"int\"}]}");    checkParseError("{\"type\":\"record\",\"name\":\"X\",\"fields\":[" + "{\"name\":\"f.g\",\"type\":\"int\"}]}");}
0
public void testInvalidNameTolerance()
{    new Schema.Parser().setValidate(false).parse("{\"type\":\"record\",\"name\":\"1X\",\"fields\":[]}");    new Schema.Parser().setValidate(false).parse("{\"type\":\"record\",\"name\":\"X-\",\"fields\":[]}");    new Schema.Parser().setValidate(false).parse("{\"type\":\"record\",\"name\":\"X$\",\"fields\":[]}");}
0
public void testMapInRecord() throws Exception
{    String json = "{\"type\":\"record\", \"name\":\"Test\", \"fields\":" + "[{\"name\":\"f\", \"type\": {\"type\":\"map\", \"values\":\"long\"}}]}";    Schema schema = new Schema.Parser().parse(json);    HashMap<Utf8, Long> map = new HashMap<>();    map.put(new Utf8("a"), 1L);    GenericData.Record record = new GenericData.Record(schema);    record.put("f", map);    check(new File(DIR.getRoot(), name.getMethodName()), json, "{\"f\":{\"a\":1}}", record, false);}
0
public void testEnum() throws Exception
{    check(new File(DIR.getRoot(), name.getMethodName()), BASIC_ENUM_SCHEMA, "\"B\"", new GenericData.EnumSymbol(new Schema.Parser().parse(BASIC_ENUM_SCHEMA), "B"), false);        checkParseError("{\"type\":\"enum\"}");        checkParseError("{\"type\":\"enum\",\"symbols\": [\"X\"]}");        checkParseError("{\"type\":\"enum\",\"name\":\"X\",\"symbols\":[\"X\",\"X\"]}");        checkParseError("{\"type\":\"enum\",\"name\":\"X\",\"symbols\":[\"1X\"]}");    checkParseError("{\"type\":\"enum\",\"name\":\"X\",\"symbols\":[\"X$\"]}");    checkParseError("{\"type\":\"enum\",\"name\":\"X\",\"symbols\":[\"X.Y\"]}");}
0
public void testFixed() throws Exception
{    String json = "{\"type\": \"fixed\", \"name\":\"Test\", \"size\": 1}";    Schema schema = new Schema.Parser().parse(json);    check(new File(DIR.getRoot(), name.getMethodName()), json, "\"a\"", new GenericData.Fixed(schema, new byte[] { (byte) 'a' }), false);        checkParseError("{\"type\":\"fixed\"}");}
0
public void testRecursive() throws Exception
{    check(new File(DIR.getRoot(), name.getMethodName()), "{\"type\": \"record\", \"name\": \"Node\", \"fields\": [" + "{\"name\":\"label\", \"type\":\"string\"}," + "{\"name\":\"children\", \"type\":" + "{\"type\": \"array\", \"items\": \"Node\" }}]}", false);}
0
public void testRecursiveEquals() throws Exception
{    String jsonSchema = "{\"type\":\"record\", \"name\":\"List\", \"fields\": [" + "{\"name\":\"next\", \"type\":\"List\"}]}";    Schema s1 = new Schema.Parser().parse(jsonSchema);    Schema s2 = new Schema.Parser().parse(jsonSchema);    assertEquals(s1, s2);        s1.hashCode();}
0
public void testSchemaExplosion() throws Exception
{    for (int i = 1; i < 15; i++) {                                List<Schema> recs = new ArrayList<>();        for (int j = 0; j < i; j++) recs.add(Schema.createRecord("" + (char) ('A' + j), null, null, false));        for (Schema s : recs) {            Schema union = Schema.createUnion(recs);            Field f = new Field("x", union, null, null);            List<Field> fields = new ArrayList<>();            fields.add(f);            s.setFields(fields);        }                for (Schema s1 : recs) {            Schema s2 = new Schema.Parser().parse(s1.toString());            assertEquals(s1.hashCode(), s2.hashCode());            assertEquals(s1, s2);        }    }}
0
public void testLisp() throws Exception
{    check(new File(DIR.getRoot(), name.getMethodName()), LISP_SCHEMA, false);}
0
public void testUnion() throws Exception
{    check(new File(DIR.getRoot(), name.getMethodName()), "[\"string\", \"long\"]", false);    checkDefault("[\"double\", \"long\"]", "1.1", 1.1);        for (String type : new String[] { "int", "long", "float", "double", "string", "bytes", "boolean" }) {                checkValidateDefaults("[\"" + type + "\", \"null\"]", "null");        boolean error = false;        try {                        checkDefault("[\"" + type + "\", \"null\"]", "null", 0);        } catch (AvroTypeException e) {            error = true;        }        assertTrue(error);                checkValidateDefaults("[\"null\", \"" + type + "\"]", "0");        error = false;        try {                        checkDefault("[\"null\", \"" + type + "\"]", "0", null);        } catch (AvroTypeException e) {            error = true;        }        assertTrue(error);    }        String record = "{\"type\":\"record\",\"name\":\"Foo\",\"fields\":[]}";    String fixed = "{\"type\":\"fixed\",\"name\":\"Bar\",\"size\": 1}";    String enu = "{\"type\":\"enum\",\"name\":\"Baz\",\"symbols\": [\"X\"]}";    Schema union = new Schema.Parser().parse("[\"null\",\"string\"," + record + "," + enu + "," + fixed + "]");    checkJson(union, null, "null");    checkJson(union, new Utf8("foo"), "{\"string\":\"foo\"}");    checkJson(union, new GenericData.Record(new Schema.Parser().parse(record)), "{\"Foo\":{}}");    checkJson(union, new GenericData.Fixed(new Schema.Parser().parse(fixed), new byte[] { (byte) 'a' }), "{\"Bar\":\"a\"}");    checkJson(union, new GenericData.EnumSymbol(new Schema.Parser().parse(enu), "X"), "{\"Baz\":\"X\"}");}
0
public void testComplexUnions() throws Exception
{        String partial = "[\"int\", \"long\", \"float\", \"double\", \"boolean\", \"bytes\"," + " \"string\", {\"type\":\"array\", \"items\": \"long\"}," + " {\"type\":\"map\", \"values\":\"long\"}";    String namedTypes = ", {\"type\":\"record\",\"name\":\"Foo\",\"fields\":[]}," + " {\"type\":\"fixed\",\"name\":\"Bar\",\"size\": 1}," + " {\"type\":\"enum\",\"name\":\"Baz\",\"symbols\": [\"X\"]}";    String namedTypes2 = ", {\"type\":\"record\",\"name\":\"Foo2\",\"fields\":[]}," + " {\"type\":\"fixed\",\"name\":\"Bar2\",\"size\": 1}," + " {\"type\":\"enum\",\"name\":\"Baz2\",\"symbols\": [\"X\"]}";    check(new File(DIR.getRoot(), name.getMethodName()), partial + namedTypes + "]", false);    check(new File(DIR.getRoot(), name.getMethodName()), partial + namedTypes + namedTypes2 + "]", false);    checkParseError(partial + namedTypes + namedTypes + "]");        checkUnionError(new Schema[] { Schema.create(Type.INT), Schema.create(Type.INT) });    checkUnionError(new Schema[] { Schema.create(Type.LONG), Schema.create(Type.LONG) });    checkUnionError(new Schema[] { Schema.create(Type.FLOAT), Schema.create(Type.FLOAT) });    checkUnionError(new Schema[] { Schema.create(Type.DOUBLE), Schema.create(Type.DOUBLE) });    checkUnionError(new Schema[] { Schema.create(Type.BOOLEAN), Schema.create(Type.BOOLEAN) });    checkUnionError(new Schema[] { Schema.create(Type.BYTES), Schema.create(Type.BYTES) });    checkUnionError(new Schema[] { Schema.create(Type.STRING), Schema.create(Type.STRING) });    checkUnionError(new Schema[] { Schema.createArray(Schema.create(Type.INT)), Schema.createArray(Schema.create(Type.INT)) });    checkUnionError(new Schema[] { Schema.createMap(Schema.create(Type.INT)), Schema.createMap(Schema.create(Type.INT)) });    List<String> symbols = new ArrayList<>();    symbols.add("NOTHING");        Schema u;    u = buildUnion(new Schema[] { new Schema.Parser().parse("{\"type\":\"record\",\"name\":\"x.A\",\"fields\":[]}"), new Schema.Parser().parse("{\"type\":\"record\",\"name\":\"y.A\",\"fields\":[]}") });    check(new File(DIR.getRoot(), name.getMethodName()), u.toString(), false);    u = buildUnion(new Schema[] { new Schema.Parser().parse("{\"type\":\"enum\",\"name\":\"x.A\",\"symbols\":[\"X\"]}"), new Schema.Parser().parse("{\"type\":\"enum\",\"name\":\"y.A\",\"symbols\":[\"Y\"]}") });    check(new File(DIR.getRoot(), name.getMethodName()), u.toString(), false);    u = buildUnion(new Schema[] { new Schema.Parser().parse("{\"type\":\"fixed\",\"name\":\"x.A\",\"size\":4}"), new Schema.Parser().parse("{\"type\":\"fixed\",\"name\":\"y.A\",\"size\":8}") });    check(new File(DIR.getRoot(), name.getMethodName()), u.toString(), false);        checkUnionError(new Schema[] { Schema.createRecord("Foo", null, "org.test", false), Schema.createRecord("Foo", null, "org.test", false) });    checkUnionError(new Schema[] { Schema.createEnum("Bar", null, "org.test", symbols), Schema.createEnum("Bar", null, "org.test", symbols) });    checkUnionError(new Schema[] { Schema.createFixed("Baz", null, "org.test", 2), Schema.createFixed("Baz", null, "org.test", 1) });    Schema union = buildUnion(new Schema[] { Schema.create(Type.INT) });        checkUnionError(new Schema[] { union });}
0
public void testComplexProp()
{    String json = "{\"type\":\"null\", \"foo\": [0]}";    Schema s = new Schema.Parser().parse(json);    assertNull(s.getProp("foo"));}
0
public void testPropOrdering()
{    String json = "{\"type\":\"int\",\"z\":\"c\",\"yy\":\"b\",\"x\":\"a\"}";    Schema s = new Schema.Parser().parse(json);    assertEquals(json, s.toString());}
0
public void testParseInputStream() throws IOException
{    Schema s = new Schema.Parser().parse(new ByteArrayInputStream("\"boolean\"".getBytes(StandardCharsets.UTF_8)));    assertEquals(new Schema.Parser().parse("\"boolean\""), s);}
0
public void testNamespaceScope()
{    String z = "{\"type\":\"record\",\"name\":\"Z\",\"fields\":[]}";    String y = "{\"type\":\"record\",\"name\":\"q.Y\",\"fields\":[" + "{\"name\":\"f\",\"type\":" + z + "}]}";    String x = "{\"type\":\"record\",\"name\":\"p.X\",\"fields\":[" + "{\"name\":\"f\",\"type\":" + y + "}," + "{\"name\":\"g\",\"type\":" + z + "}" + "]}";    Schema xs = new Schema.Parser().parse(x);    Schema ys = xs.getField("f").schema();    assertEquals("p.Z", xs.getField("g").schema().getFullName());    assertEquals("q.Z", ys.getField("f").schema().getFullName());}
0
public void testNamespaceNesting()
{    String y = "{\"type\":\"record\",\"name\":\"y.Y\",\"fields\":[" + "{\"name\":\"f\",\"type\":\"x.X\"}]}";    String x = "{\"type\":\"record\",\"name\":\"x.X\",\"fields\":[" + "{\"name\":\"f\",\"type\":" + y + "}" + "]}";    Schema xs = new Schema.Parser().parse(x);    assertEquals(xs, new Schema.Parser().parse(xs.toString()));}
0
public void testNestedNullNamespace()
{    Schema inner = new Schema.Parser().parse("{\"type\":\"record\",\"name\":\"Inner\",\"fields\":[]}");    Schema outer = Schema.createRecord("Outer", null, "space", false);    outer.setFields(Collections.singletonList(new Field("f", inner, null, null)));    assertEquals(outer, new Schema.Parser().parse(outer.toString()));}
0
public void testNestedNullNamespaceReferencing()
{    Schema inner = new Schema.Parser().parse("{\"type\":\"record\",\"name\":\"Inner\",\"fields\":[]}");    Schema outer = Schema.createRecord("Outer", null, "space", false);    outer.setFields(Arrays.asList(new Field("f1", inner, null, null), new Field("f2", inner, null, null)));    assertEquals(outer, new Schema.Parser().parse(outer.toString()));}
0
public void testNestedNullNamespaceReferencingWithUnion()
{    Schema inner = new Schema.Parser().parse("{\"type\":\"record\",\"name\":\"Inner\",\"fields\":[]}");    Schema innerUnion = Schema.createUnion(Arrays.asList(inner, Schema.create(Type.NULL)));    Schema outer = Schema.createRecord("Outer", null, "space", false);    outer.setFields(Arrays.asList(new Field("f1", innerUnion, null, null), new Field("f2", innerUnion, null, null)));    assertEquals(outer, new Schema.Parser().parse(outer.toString()));}
0
public void testNestedNonNullNamespace1()
{    Schema inner1 = Schema.createEnum("InnerEnum", null, "space", Collections.singletonList("x"));    Schema inner2 = new Schema.Parser().parse("{\"type\":\"record\",\"namespace\":\"space\",\"name\":" + "\"InnerRecord\",\"fields\":[]}");    Schema nullOuter = Schema.createRecord("Outer", null, null, false);    nullOuter.setFields(Arrays.asList(new Field("f1", inner1, null, null), new Field("f2", inner2, null, null)));    assertEquals(nullOuter, new Schema.Parser().parse(nullOuter.toString()));}
0
public void testNestedNonNullNamespace2()
{    Schema inner1 = Schema.createFixed("InnerFixed", null, "space", 1);    Schema inner2 = new Schema.Parser().parse("{\"type\":\"record\",\"namespace\":\"space\",\"name\":" + "\"InnerRecord\",\"fields\":[]}");    Schema nullOuter = Schema.createRecord("Outer", null, null, false);    nullOuter.setFields(Arrays.asList(new Field("f1", inner1, null, null), new Field("f2", inner2, null, null)));    assertEquals(nullOuter, new Schema.Parser().parse(nullOuter.toString()));}
0
public void testNullNamespaceAlias()
{    Schema s = new Schema.Parser().parse("{\"type\":\"record\",\"name\":\"Z\",\"fields\":[]}");    Schema t = new Schema.Parser().parse("{\"type\":\"record\",\"name\":\"x.Y\",\"aliases\":[\".Z\"]," + "\"fields\":[]}");    Schema u = Schema.applyAliases(s, t);    assertEquals("x.Y", u.getFullName());}
0
public void testNullPointer() throws Exception
{    String recordJson = "{\"type\":\"record\", \"name\":\"Test\", \"fields\":" + "[{\"name\":\"x\", \"type\":\"string\"}]}";    Schema schema = new Schema.Parser().parse(recordJson);    GenericData.Record record = new GenericData.Record(schema);    try {        checkBinary(schema, record, new GenericDatumWriter<>(), new GenericDatumReader<>());    } catch (NullPointerException e) {        assertEquals("null of string in field x of Test", e.getMessage());    }}
0
private static void checkParseError(String json)
{    try {        new Schema.Parser().parse(json);    } catch (SchemaParseException e) {        return;    }    fail("Should not have parsed: " + json);}
0
private static void checkUnionError(Schema[] branches)
{    List<Schema> branchList = Arrays.asList(branches);    try {        Schema.createUnion(branchList);        fail("Union should not have constructed from: " + branchList);    } catch (AvroRuntimeException ignored) {    }}
0
private static Schema buildUnion(Schema[] branches)
{    List<Schema> branchList = Arrays.asList(branches);    return Schema.createUnion(branchList);}
0
public void testDocs()
{    Schema schema = new Schema.Parser().parse(SCHEMA_WITH_DOC_TAGS);    assertEquals("This is not a world record.", schema.getDoc());    assertEquals("Inner Fixed", schema.getField("inner_fixed").doc());    assertEquals("Very Inner Fixed", schema.getField("inner_fixed").schema().getDoc());    assertEquals("Inner String", schema.getField("inner_string").doc());    assertEquals("Inner Enum", schema.getField("inner_enum").doc());    assertEquals("Very Inner Enum", schema.getField("inner_enum").schema().getDoc());    assertEquals("Inner Union", schema.getField("inner_union").doc());}
0
public void testFieldDocs()
{    String schemaStr = "{\"name\": \"Rec\",\"type\": \"record\",\"fields\" : [" + "{\"name\": \"f\", \"type\": \"int\", \"doc\": \"test\"}]}";        Schema schema = new Schema.Parser().parse(schemaStr);    assertEquals("test", schema.getField("f").doc());        schema = new Schema.Parser().parse(schema.toString());    assertEquals("test", schema.getField("f").doc());}
0
public void testAliases()
{    String t1 = "{\"type\":\"record\",\"name\":\"a.b\",\"fields\":[" + "{\"name\":\"f\",\"type\":\"long\"}," + "{\"name\":\"h\",\"type\":\"int\"}]}";    String t2 = "{\"type\":\"record\",\"name\":\"x.y\",\"aliases\":[\"a.b\"]," + "\"fields\":[{\"name\":\"g\",\"type\":\"long\",\"aliases\":[\"f\"]}," + "{\"name\":\"h\",\"type\":\"int\"}]}";    Schema s1 = new Schema.Parser().parse(t1);    Schema s2 = new Schema.Parser().parse(t2);    assertEquals(s1.getAliases(), Collections.emptySet());    assertEquals(s1.getField("f").aliases(), Collections.emptySet());    assertEquals(s2.getAliases(), Collections.singleton("a.b"));    assertEquals(s2.getField("g").aliases(), Collections.singleton("f"));    Schema s3 = Schema.applyAliases(s1, s2);    assertNotSame(s2, s3);    assertEquals(s2, s3);    t1 = "{\"type\":\"enum\",\"name\":\"a.b\"," + "\"symbols\":[\"x\"]}";    t2 = "{\"type\":\"enum\",\"name\":\"a.c\",\"aliases\":[\"b\"]," + "\"symbols\":[\"x\"]}";    s1 = new Schema.Parser().parse(t1);    s2 = new Schema.Parser().parse(t2);    s3 = Schema.applyAliases(s1, s2);    assertNotSame(s2, s3);    assertEquals(s2, s3);    t1 = "{\"type\":\"fixed\",\"name\":\"a\"," + "\"size\": 5}";    t2 = "{\"type\":\"fixed\",\"name\":\"b\",\"aliases\":[\"a\"]," + "\"size\": 5}";    s1 = new Schema.Parser().parse(t1);    s2 = new Schema.Parser().parse(t2);    s3 = Schema.applyAliases(s1, s2);    assertNotSame(s2, s3);    assertEquals(s2, s3);}
0
public void testAliasesSelfReferential()
{    String t1 = "{\"type\":\"record\",\"name\":\"a\",\"fields\":[{\"name\":\"f\",\"type\":{\"type\":\"record\",\"name\":\"C\",\"fields\":[{\"name\":\"c\",\"type\":{\"type\":\"array\",\"items\":[\"null\",\"C\"]}}]}}]}";    String t2 = "{\"type\":\"record\",\"name\":\"x\",\"fields\":[{\"name\":\"f\",\"type\":{\"type\":\"record\",\"name\":\"C\",\"fields\":[{\"name\":\"d\",\"type\":{\"type\":\"array\",\"items\":[\"null\",\"C\"]},\"aliases\":[\"c\"]}]}}],\"aliases\":[\"a\"]}";    Schema s1 = new Schema.Parser().parse(t1);    Schema s2 = new Schema.Parser().parse(t2);    assertEquals(s1.getAliases(), Collections.emptySet());    assertEquals(s2.getAliases(), Collections.singleton("a"));    Schema s3 = Schema.applyAliases(s1, s2);    assertNotSame(s2, s3);    assertEquals(s2, s3);}
0
private static void check(File dst, String schemaJson, String defaultJson, Object defaultValue) throws Exception
{    check(dst, schemaJson, defaultJson, defaultValue, true);}
0
private static void check(File dst, String schemaJson, String defaultJson, Object defaultValue, boolean induce) throws Exception
{    check(dst, schemaJson, induce);    checkDefault(schemaJson, defaultJson, defaultValue);}
0
private static void check(File dst, String jsonSchema, boolean induce) throws Exception
{    Schema schema = new Schema.Parser().parse(jsonSchema);    checkProp(schema);    Object reuse = null;    for (Object datum : new RandomData(schema, COUNT, true)) {        if (induce) {            Schema induced = GenericData.get().induce(datum);            assertEquals("Induced schema does not match.", schema, induced);        }        assertTrue("Datum does not validate against schema " + datum, GenericData.get().validate(schema, datum));        checkBinary(schema, datum, new GenericDatumWriter<>(), new GenericDatumReader<>(), null);        reuse = checkBinary(schema, datum, new GenericDatumWriter<>(), new GenericDatumReader<>(), reuse);        checkDirectBinary(schema, datum, new GenericDatumWriter<>(), new GenericDatumReader<>());        checkBlockingBinary(schema, datum, new GenericDatumWriter<>(), new GenericDatumReader<>());        checkJson(schema, datum, new GenericDatumWriter<>(), new GenericDatumReader<>());                TestSpecificCompiler.assertCompiles(dst, schema, false);                checkBinaryJson(jsonSchema);    }}
0
private static void checkProp(Schema s0) throws Exception
{    if (s0.getType().equals(Schema.Type.UNION))                return;    assertNull(s0.getProp("foo"));    Schema s1 = new Schema.Parser().parse(s0.toString());    s1.addProp("foo", "bar");    assertEquals("bar", s1.getProp("foo"));    assertNotEquals(s0, s1);    Schema s2 = new Schema.Parser().parse(s1.toString());    assertEquals("bar", s2.getProp("foo"));    assertEquals(s1, s2);    assertNotEquals(s0, s2);}
0
public static void checkBinary(Schema schema, Object datum, DatumWriter<Object> writer, DatumReader<Object> reader) throws IOException
{    checkBinary(schema, datum, writer, reader, null);}
0
public static Object checkBinary(Schema schema, Object datum, DatumWriter<Object> writer, DatumReader<Object> reader, Object reuse) throws IOException
{    ByteArrayOutputStream out = new ByteArrayOutputStream();    writer.setSchema(schema);    Encoder encoder = EncoderFactory.get().binaryEncoder(out, null);    writer.write(datum, encoder);    encoder.flush();    byte[] data = out.toByteArray();    reader.setSchema(schema);    Object decoded = reader.read(reuse, DecoderFactory.get().binaryDecoder(data, null));    assertEquals("Decoded data does not match.", datum, decoded);    return decoded;}
0
public static void checkDirectBinary(Schema schema, Object datum, DatumWriter<Object> writer, DatumReader<Object> reader) throws IOException
{    ByteArrayOutputStream out = new ByteArrayOutputStream();    writer.setSchema(schema);    Encoder encoder = EncoderFactory.get().directBinaryEncoder(out, null);    writer.write(datum, encoder);        byte[] data = out.toByteArray();    reader.setSchema(schema);    Object decoded = reader.read(null, DecoderFactory.get().binaryDecoder(data, null));    assertEquals("Decoded data does not match.", datum, decoded);}
0
public static void checkBlockingBinary(Schema schema, Object datum, DatumWriter<Object> writer, DatumReader<Object> reader) throws IOException
{    ByteArrayOutputStream out = new ByteArrayOutputStream();    writer.setSchema(schema);    Encoder encoder = EncoderFactory.get().blockingBinaryEncoder(out, null);    writer.write(datum, encoder);    encoder.flush();    byte[] data = out.toByteArray();    reader.setSchema(schema);    Object decoded = reader.read(null, DecoderFactory.get().binaryDecoder(data, null));    assertEquals("Decoded data does not match.", datum, decoded);}
0
private static void checkJson(Schema schema, Object datum, DatumWriter<Object> writer, DatumReader<Object> reader) throws IOException
{    ByteArrayOutputStream out = new ByteArrayOutputStream();    Encoder encoder = EncoderFactory.get().jsonEncoder(schema, out);    writer.setSchema(schema);    writer.write(datum, encoder);    writer.write(datum, encoder);    encoder.flush();    byte[] data = out.toByteArray();    reader.setSchema(schema);    Decoder decoder = DecoderFactory.get().jsonDecoder(schema, new ByteArrayInputStream(data));    Object decoded = reader.read(null, decoder);    assertEquals("Decoded data does not match.", datum, decoded);    decoded = reader.read(decoded, decoder);    assertEquals("Decoded data does not match.", datum, decoded);}
0
private static void checkJson(Schema schema, Object datum, String json) throws Exception
{    ByteArrayOutputStream out = new ByteArrayOutputStream();    Encoder encoder = EncoderFactory.get().jsonEncoder(schema, out);    DatumWriter<Object> writer = new GenericDatumWriter<>();    writer.setSchema(schema);    writer.write(datum, encoder);    encoder.flush();    byte[] data = out.toByteArray();    String encoded = new String(data, StandardCharsets.UTF_8);    assertEquals("Encoded data does not match.", json, encoded);    DatumReader<Object> reader = new GenericDatumReader<>();    reader.setSchema(schema);    Object decoded = reader.read(null, DecoderFactory.get().jsonDecoder(schema, new ByteArrayInputStream(data)));    assertEquals("Decoded data does not match.", datum, decoded);}
0
public static void checkBinaryJson(String json) throws Exception
{    Object node = Json.parseJson(json);    ByteArrayOutputStream out = new ByteArrayOutputStream();    DatumWriter<Object> writer = new Json.ObjectWriter();    Encoder encoder = EncoderFactory.get().binaryEncoder(out, null);    encoder = EncoderFactory.get().validatingEncoder(Json.SCHEMA, encoder);    writer.write(node, encoder);    encoder.flush();    byte[] bytes = out.toByteArray();    DatumReader<Object> reader = new Json.ObjectReader();    Decoder decoder = DecoderFactory.get().binaryDecoder(bytes, null);    decoder = DecoderFactory.get().validatingDecoder(Json.SCHEMA, decoder);    Object decoded = reader.read(null, decoder);    assertEquals("Decoded json does not match.", Json.toString(node), Json.toString(decoded));}
0
private static void checkDefault(String schemaJson, String defaultJson, Object defaultValue) throws Exception
{    String recordJson = "{\"type\":\"record\", \"name\":\"Foo\", \"fields\":[{\"name\":\"f\", " + "\"type\":" + schemaJson + ", " + "\"default\":" + defaultJson + "}]}";    Schema expected = new Schema.Parser().parse(recordJson);    DatumReader<Object> in = new GenericDatumReader<>(ACTUAL, expected);    GenericData.Record record = (GenericData.Record) in.read(null, DecoderFactory.get().binaryDecoder(new byte[0], null));    assertEquals("Wrong default.", defaultValue, record.get("f"));    assertEquals("Wrong toString", expected, new Schema.Parser().parse(expected.toString()));}
0
private static void checkValidateDefaults(String schemaJson, String defaultJson)
{    try {        Schema.Parser parser = new Schema.Parser();        String recordJson = "{\"type\":\"record\", \"name\":\"Foo\", \"fields\":[{\"name\":\"f\", " + "\"type\":" + schemaJson + ", " + "\"default\":" + defaultJson + "}]}";        parser.parse(recordJson);        fail("Schema of type " + schemaJson + " should not have default " + defaultJson);    } catch (AvroTypeException ignored) {    }}
0
public void testNoDefaultField() throws Exception
{    Schema expected = new Schema.Parser().parse("{\"type\":\"record\", \"name\":\"Foo\", \"fields\":" + "[{\"name\":\"f\", \"type\": \"string\"}]}");    DatumReader<Object> in = new GenericDatumReader<>(ACTUAL, expected);    in.read(null, DecoderFactory.get().binaryDecoder(new ByteArrayInputStream(new byte[0]), null));}
0
public void testEnumMismatch() throws Exception
{    Schema actual = new Schema.Parser().parse("{\"type\":\"enum\",\"name\":\"E\",\"symbols\":[\"X\",\"Y\"]}");    Schema expected = new Schema.Parser().parse("{\"type\":\"enum\",\"name\":\"E\",\"symbols\":[\"Y\",\"Z\"]}");    ByteArrayOutputStream out = new ByteArrayOutputStream();    DatumWriter<Object> writer = new GenericDatumWriter<>(actual);    Encoder encoder = EncoderFactory.get().directBinaryEncoder(out, null);    writer.write(new GenericData.EnumSymbol(actual, "Y"), encoder);    writer.write(new GenericData.EnumSymbol(actual, "X"), encoder);    encoder.flush();    byte[] data = out.toByteArray();    Decoder decoder = DecoderFactory.get().binaryDecoder(data, null);    DatumReader<String> in = new GenericDatumReader<>(actual, expected);    assertEquals("Wrong value", new GenericData.EnumSymbol(expected, "Y"), in.read(null, decoder));    try {        in.read(null, decoder);        fail("Should have thrown exception.");    } catch (AvroTypeException e) {        }}
0
public void testRecordWithPrimitiveName()
{    new Schema.Parser().parse("{\"type\":\"record\", \"name\":\"string\", \"fields\": []}");}
0
public void testEnumWithPrimitiveName()
{    new Schema.Parser().parse("{\"type\":\"enum\", \"name\":\"null\", \"symbols\": [\"A\"]}");}
0
private static Schema enumSchema()
{    return new Schema.Parser().parse("{ \"type\": \"enum\", \"name\": \"e\", " + "\"symbols\": [\"a\", \"b\"]}");}
0
public void testImmutability1()
{    Schema s = enumSchema();    s.addProp("p1", "1");    s.addProp("p1", "2");}
0
public void testImmutability2()
{    Schema s = enumSchema();    s.addProp("p1", null);}
0
private static List<String> lockedArrayList()
{    return new Schema.LockableArrayList<>(Arrays.asList("a", "b", "c")).lock();}
0
public void testLockedArrayList1()
{    lockedArrayList().add("p");}
0
public void testLockedArrayList2()
{    lockedArrayList().remove("a");}
0
public void testLockedArrayList3()
{    lockedArrayList().addAll(Collections.singletonList("p"));}
0
public void testLockedArrayList4()
{    lockedArrayList().addAll(0, Collections.singletonList("p"));}
0
public void testLockedArrayList5()
{    lockedArrayList().removeAll(Collections.singletonList("a"));}
0
public void testLockedArrayList6()
{    lockedArrayList().retainAll(Collections.singletonList("a"));}
0
public void testLockedArrayList7()
{    lockedArrayList().clear();}
0
public void testLockedArrayList8()
{    lockedArrayList().iterator().remove();}
0
public void testLockedArrayList9()
{    Iterator<String> it = lockedArrayList().iterator();    it.next();    it.remove();}
0
public void testLockedArrayList10()
{    lockedArrayList().remove(1);}
0
public void testNames_GetWithInheritedNamespace()
{    Schema schema = Schema.create(Type.STRING);    Schema.Names names = new Schema.Names("space");    names.put(new Schema.Name("Name", "space"), schema);    assertEquals(schema, names.get(new Schema.Name("Name", "space")));    assertEquals(schema, names.get("Name"));}
0
public void testNames_GetWithNullNamespace()
{    Schema schema = Schema.create(Type.STRING);    Schema.Names names = new Schema.Names("space");    names.put(new Schema.Name("Name", ""), schema);    assertEquals(schema, names.get(new Schema.Name("Name", "")));    assertEquals(schema, names.get("Name"));}
0
public void testNames_GetNotFound()
{    Schema.Names names = new Schema.Names("space");    names.put(new Schema.Name("Name", "otherspace"), Schema.create(Type.STRING));    assertNull(names.get("Name"));}
0
public void addConnector(Connector connector)
{    server.addConnector(connector);}
0
public int getPort()
{    return ((ServerConnector) server.getConnectors()[0]).getLocalPort();}
0
public void close()
{    try {        server.stop();    } catch (Exception e) {        throw new AvroRuntimeException(e);    }}
0
public void start()
{    try {        server.start();    } catch (Exception e) {        throw new AvroRuntimeException(e);    }}
0
public void join() throws InterruptedException
{    server.join();}
0
public Resource getResource(String pathInContext)
{            String[] parts = pathInContext.split("/");    String filename = parts[parts.length - 1];    URL resource = getClass().getClassLoader().getResource("org/apache/avro/ipc/stats/static/" + filename);    if (resource == null) {        return null;    }    return Resource.newResource(resource);}
0
public void stop() throws Exception
{    this.httpServer.stop();}
0
public Object respond(Message message, Object request) throws AvroRemoteException
{    return request;}
0
public static void main(String[] args) throws Exception
{    double with = sendRpcs(true) / 1000000000.0;    double without = sendRpcs(false) / 1000000000.0;    System.out.println(String.format("Overhead: %f%%.  RPC/s: %f (with) vs %f (without).  " + "RPC time (ms): %f vs %f", 100 * (with - without) / (without), COUNT / with, COUNT / without, 1000 * with / COUNT, 1000 * without / COUNT));}
0
private static long sendRpcs(boolean withPlugin) throws Exception
{    HttpServer server = createServer(withPlugin);    Transceiver t = new HttpTransceiver(new URL("http://127.0.0.1:" + server.getPort() + "/"));    GenericRequestor requestor = new GenericRequestor(NULL_PROTOCOL, t);    long now = System.nanoTime();    for (int i = 0; i < COUNT; ++i) {        requestor.request("null", null);    }    long elapsed = System.nanoTime() - now;    t.close();    server.close();    return elapsed;}
0
private static HttpServer createServer(boolean withPlugin) throws IOException
{    Responder r = new IdentityResponder(NULL_PROTOCOL);    if (withPlugin) {        r.addRPCPlugin(new StatsPlugin());    }        HttpServer server = new HttpServer(r, 0);    server.start();    return server;}
0
public ByteBuffer read()
{    return DATA.duplicate();}
0
public void write(ByteBuffer data)
{    Assert.assertEquals(SIZE, data.remaining());}
0
public void startServer() throws Exception
{    if (server != null)        return;    server = new HttpServer(new SpecificResponder(BulkData.class, new BulkDataImpl()), 0);    server.start();    Transceiver client = new HttpTransceiver(new URL("http://127.0.0.1:" + server.getPort() + "/"));    proxy = SpecificRequestor.getClient(BulkData.class, client);}
0
public void testRead() throws IOException
{    for (int i = 0; i < COUNT; i++) Assert.assertEquals(SIZE, proxy.read().remaining());}
0
public void testWrite() throws IOException
{    for (int i = 0; i < COUNT; i++) proxy.write(DATA.duplicate());}
0
public static void stopServer() throws Exception
{    server.close();}
0
public static void main(String[] args) throws Exception
{    TestBulkData test = new TestBulkData();    test.startServer();    System.out.println("READ");    long start = System.currentTimeMillis();    test.testRead();    printStats(start);    System.out.println("WRITE");    start = System.currentTimeMillis();    test.testWrite();    printStats(start);    test.stopServer();}
0
private static void printStats(long start)
{    double seconds = (System.currentTimeMillis() - start) / 1000.0;    System.out.println("seconds = " + (int) seconds);    System.out.println("requests/second = " + (int) (COUNT / seconds));    double megabytes = (COUNT * SIZE) / (1024 * 1024.0);    System.out.println("MB = " + (int) megabytes);    System.out.println("MB/second = " + (int) (megabytes / seconds));}
0
public Server createServer(Responder testResponder) throws Exception
{    return new HttpServer(testResponder, 0);}
0
public Transceiver createTransceiver() throws Exception
{    return new HttpTransceiver(new URL("http://127.0.0.1:" + server.getPort() + "/"));}
0
protected int getExpectedHandshakeCount()
{    return REPEATING;}
0
public void testTimeout() throws Throwable
{    ServerSocket s = new ServerSocket(0);    HttpTransceiver client = new HttpTransceiver(new URL("http://127.0.0.1:" + s.getLocalPort() + "/"));    client.setTimeout(100);    Simple proxy = SpecificRequestor.getClient(Simple.class, client);    try {        proxy.hello("foo");        fail("Should have failed with an exception");    } catch (AvroRuntimeException e) {        assertTrue("Got unwanted exception: " + e.getCause(), e.getCause() instanceof SocketTimeoutException);    } finally {        s.close();    }}
0
public void testStatelessOneway() throws Exception
{        Protocol protocol = new Protocol("Simple", "org.apache.avro.test");    Protocol.Message message = protocol.createMessage("ack", null, new LinkedHashMap<String, String>(), Schema.createRecord(new ArrayList<>()), Schema.create(Schema.Type.NULL), Schema.createUnion(new ArrayList<>()));    protocol.getMessages().put("ack", message);        GenericRequestor requestor = new GenericRequestor(protocol, createTransceiver());    requestor.request("ack", new GenericData.Record(message.getRequest()));        requestor.request("ack", new GenericData.Record(message.getRequest()));}
0
public Server createServer(Responder testResponder) throws Exception
{    System.setProperty("javax.net.ssl.keyStore", "src/test/keystore");    System.setProperty("javax.net.ssl.keyStorePassword", "avrotest");    System.setProperty("javax.net.ssl.password", "avrotest");    System.setProperty("javax.net.ssl.trustStore", "src/test/truststore");    System.setProperty("javax.net.ssl.trustStorePassword", "avrotest");    SslConnectionFactory connectionFactory = new SslConnectionFactory("HTTP/1.1");    SslContextFactory sslContextFactory = connectionFactory.getSslContextFactory();    sslContextFactory.setKeyStorePath(System.getProperty("javax.net.ssl.keyStore"));    sslContextFactory.setKeyManagerPassword(System.getProperty("javax.net.ssl.password"));    sslContextFactory.setKeyStorePassword(System.getProperty("javax.net.ssl.keyStorePassword"));    sslContextFactory.setNeedClientAuth(false);    return new HttpServer(testResponder, connectionFactory, "localhost", 18443);}
0
public Transceiver createTransceiver() throws Exception
{    return new HttpTransceiver(new URL("https://localhost:" + server.getPort() + "/"));}
0
protected int getExpectedHandshakeCount()
{    return REPEATING;}
0
private String generateServletResponse(StatsPlugin statsPlugin) throws IOException
{    StatsServlet servlet;    try {        servlet = new StatsServlet(statsPlugin);    } catch (UnavailableException e1) {        throw new IOException();    }    StringWriter w = new StringWriter();    try {        servlet.writeStats(w);    } catch (Exception e) {        e.printStackTrace();    }    String o = w.toString();    return o;}
0
public Object respond(Message message, Object request) throws AvroRemoteException
{    assertEquals(0, ((GenericRecord) request).get("x"));    return 1;}
0
private void makeRequest(Transceiver t) throws Exception
{    GenericRecord params = new GenericData.Record(protocol.getMessages().get("m").getRequest());    params.put("x", 0);    GenericRequestor r = new GenericRequestor(protocol, t);    assertEquals(1, r.request("m", params));}
0
public void testFullServerPath() throws Exception
{    Responder r = new TestResponder(protocol);    StatsPlugin statsPlugin = new StatsPlugin();    r.addRPCPlugin(statsPlugin);    Transceiver t = new LocalTransceiver(r);    for (int i = 0; i < 10; ++i) {        makeRequest(t);    }    String o = generateServletResponse(statsPlugin);    assertTrue(o.contains("10 calls"));}
0
public void testMultipleRPCs() throws IOException
{    org.apache.avro.ipc.stats.FakeTicks t = new org.apache.avro.ipc.stats.FakeTicks();    StatsPlugin statsPlugin = new StatsPlugin(t, StatsPlugin.LATENCY_SEGMENTER, StatsPlugin.PAYLOAD_SEGMENTER);    RPCContext context1 = makeContext();    RPCContext context2 = makeContext();    statsPlugin.serverReceiveRequest(context1);        t.passTime(100 * MS);    statsPlugin.serverReceiveRequest(context2);    String r = generateServletResponse(statsPlugin);        assertTrue(r.contains("m: 0ms"));    assertTrue(r.contains("m: 100ms"));    statsPlugin.serverSendResponse(context1);        t.passTime(900 * MS);    statsPlugin.serverSendResponse(context2);    r = generateServletResponse(statsPlugin);    assertTrue(r.contains("Average: 500.0ms"));}
0
public void testPayloadSize() throws Exception
{    Responder r = new TestResponder(protocol);    StatsPlugin statsPlugin = new StatsPlugin();    r.addRPCPlugin(statsPlugin);    Transceiver t = new LocalTransceiver(r);    makeRequest(t);    String resp = generateServletResponse(statsPlugin);    assertTrue(resp.contains("Average: 2.0"));}
0
private RPCContext makeContext()
{    RPCContext context = new RPCContext();    context.setMessage(message);    return context;}
0
public Object respond(Message message, Object request) throws AvroRemoteException
{    try {        Thread.sleep((Long) ((GenericRecord) request).get("millis"));    } catch (InterruptedException e) {        throw new AvroRemoteException(e);    }    return null;}
0
public static void main(String[] args) throws Exception
{    if (args.length == 0) {        args = new String[] { "7002", "7003" };    }    Protocol protocol = Protocol.parse("{\"protocol\": \"sleepy\", " + "\"messages\": { \"sleep\": {" + "   \"request\": [{\"name\": \"millis\", \"type\": \"long\"}," + "{\"name\": \"data\", \"type\": \"bytes\"}], " + "   \"response\": \"null\"} } }");    Responder r = new SleepyResponder(protocol);    StatsPlugin p = new StatsPlugin();    r.addRPCPlugin(p);        HttpServer avroServer = new HttpServer(r, Integer.parseInt(args[0]));    avroServer.start();    StatsServer ss = new StatsServer(p, 8080);    HttpTransceiver trans = new HttpTransceiver(new URL("http://localhost:" + Integer.parseInt(args[0])));    GenericRequestor req = new GenericRequestor(protocol, trans);    while (true) {        Thread.sleep(1000);        GenericRecord params = new GenericData.Record(protocol.getMessages().get("sleep").getRequest());        Random rand = new Random();        params.put("millis", Math.abs(rand.nextLong()) % 1000);        int payloadSize = Math.abs(rand.nextInt()) % 10000;        byte[] payload = new byte[payloadSize];        rand.nextBytes(payload);        params.put("data", ByteBuffer.wrap(payload));        req.request("sleep", params);    }}
0
public void start()
{}
0
public void close()
{    ChannelGroupFuture future = allChannels.close();    future.awaitUninterruptibly();    channelFactory.releaseExternalResources();    closed.countDown();}
0
public int getPort()
{    return ((InetSocketAddress) serverChannel.getLocalAddress()).getPort();}
0
public void join() throws InterruptedException
{    closed.await();}
0
public int getNumActiveConnections()
{        return allChannels.size() - 1;}
0
public void handleUpstream(ChannelHandlerContext ctx, ChannelEvent e) throws Exception
{    if (e instanceof ChannelStateEvent) {            }    super.handleUpstream(ctx, e);}
1
public void channelOpen(ChannelHandlerContext ctx, ChannelStateEvent e) throws Exception
{    allChannels.add(e.getChannel());    super.channelOpen(ctx, e);}
0
public void messageReceived(ChannelHandlerContext ctx, MessageEvent e)
{    try {        NettyDataPack dataPack = (NettyDataPack) e.getMessage();        List<ByteBuffer> req = dataPack.getDatas();        List<ByteBuffer> res = responder.respond(req, connectionMetadata);                if (res != null) {            dataPack.setDatas(res);            e.getChannel().write(dataPack);        }    } catch (IOException ex) {            }}
1
public void exceptionCaught(ChannelHandlerContext ctx, ExceptionEvent e)
{        e.getChannel().close();    allChannels.remove(e.getChannel());}
1
public void channelClosed(ChannelHandlerContext ctx, ChannelStateEvent e) throws Exception
{        super.channelClosed(ctx, e);    e.getChannel().close();    allChannels.remove(e.getChannel());}
1
protected ChannelUpstreamHandler createNettyClientAvroHandler()
{    return new NettyClientAvroHandler();}
0
protected static Map<String, Object> buildDefaultBootstrapOptions(Long connectTimeoutMillis)
{    Map<String, Object> options = new HashMap<>(3);    options.put(NETTY_TCP_NODELAY_OPTION, DEFAULT_TCP_NODELAY_VALUE);    options.put(NETTY_KEEPALIVE_OPTION, true);    options.put(NETTY_CONNECT_TIMEOUT_OPTION, connectTimeoutMillis == null ? DEFAULT_CONNECTION_TIMEOUT_MILLIS : connectTimeoutMillis);    return options;}
0
private static boolean isChannelReady(Channel channel)
{    return (channel != null) && channel.isOpen() && channel.isBound() && channel.isConnected();}
0
private Channel getChannel() throws IOException
{    if (!isChannelReady(channel)) {                        stateLock.readLock().unlock();        stateLock.writeLock().lock();        try {            if (!isChannelReady(channel)) {                synchronized (channelFutureLock) {                    if (!stopping) {                                                channelFuture = bootstrap.connect(remoteAddr);                    }                }                if (channelFuture != null) {                    try {                        channelFuture.await(connectTimeoutMillis);                    } catch (InterruptedException e) {                                                Thread.currentThread().interrupt();                        throw new IOException("Interrupted while connecting to " + remoteAddr);                    }                    synchronized (channelFutureLock) {                        if (!channelFuture.isSuccess()) {                            throw new IOException("Error connecting to " + remoteAddr, channelFuture.getCause());                        }                        channel = channelFuture.getChannel();                        channelFuture = null;                    }                }            }        } finally {                        stateLock.readLock().lock();            stateLock.writeLock().unlock();        }    }    return channel;}
1
private void disconnect()
{    disconnect(false, false, null);}
0
private void disconnect(boolean awaitCompletion, boolean cancelPendingRequests, Throwable cause)
{    Channel channelToClose = null;    Map<Integer, Callback<List<ByteBuffer>>> requestsToCancel = null;    boolean stateReadLockHeld = stateLock.getReadHoldCount() != 0;    ChannelFuture channelFutureToCancel = null;    synchronized (channelFutureLock) {        if (stopping && channelFuture != null) {            channelFutureToCancel = channelFuture;            channelFuture = null;        }    }    if (channelFutureToCancel != null) {        channelFutureToCancel.cancel();    }    if (stateReadLockHeld) {        stateLock.readLock().unlock();    }    stateLock.writeLock().lock();    try {        if (channel != null) {            if (cause != null) {                            } else {                            }            channelToClose = channel;            channel = null;            remote = null;            if (cancelPendingRequests) {                                                requestsToCancel = new ConcurrentHashMap<>(requests);                requests.clear();            }        }    } finally {        if (stateReadLockHeld) {            stateLock.readLock().lock();        }        stateLock.writeLock().unlock();    }        if ((requestsToCancel != null) && !requestsToCancel.isEmpty()) {                for (Callback<List<ByteBuffer>> request : requestsToCancel.values()) {            request.handleError(cause != null ? cause : new IOException(getClass().getSimpleName() + " closed"));        }    }        if (channelToClose != null) {        ChannelFuture closeFuture = channelToClose.close();        if (awaitCompletion && (closeFuture != null)) {            try {                closeFuture.await(connectTimeoutMillis);            } catch (InterruptedException e) {                                Thread.currentThread().interrupt();                            }        }    }}
1
public void lockChannel()
{}
0
public void unlockChannel()
{}
0
public void close()
{    close(true);}
0
public void close(boolean awaitCompletion)
{    try {                stopping = true;        disconnect(awaitCompletion, true, null);    } finally {                channelFactory.releaseExternalResources();    }}
0
public String getRemoteName() throws IOException
{    stateLock.readLock().lock();    try {        return getChannel().getRemoteAddress().toString();    } finally {        stateLock.readLock().unlock();    }}
0
public List<ByteBuffer> transceive(List<ByteBuffer> request) throws IOException
{    try {        CallFuture<List<ByteBuffer>> transceiverFuture = new CallFuture<>();        transceive(request, transceiverFuture);        return transceiverFuture.get();    } catch (InterruptedException | ExecutionException e) {                return null;    }}
1
public void transceive(List<ByteBuffer> request, Callback<List<ByteBuffer>> callback) throws IOException
{    stateLock.readLock().lock();    try {        int serial = serialGenerator.incrementAndGet();        NettyDataPack dataPack = new NettyDataPack(serial, request);        requests.put(serial, callback);        writeDataPack(dataPack);    } finally {        stateLock.readLock().unlock();    }}
0
public void writeBuffers(List<ByteBuffer> buffers) throws IOException
{    ChannelFuture writeFuture;    stateLock.readLock().lock();    try {        writeFuture = writeDataPack(new NettyDataPack(serialGenerator.incrementAndGet(), buffers));    } finally {        stateLock.readLock().unlock();    }    if (!writeFuture.isDone()) {        try {            writeFuture.await();        } catch (InterruptedException e) {                        Thread.currentThread().interrupt();            throw new IOException("Interrupted while writing Netty data pack", e);        }    }    if (!writeFuture.isSuccess()) {        throw new IOException("Error writing buffers", writeFuture.getCause());    }}
0
private ChannelFuture writeDataPack(NettyDataPack dataPack) throws IOException
{    return getChannel().write(dataPack);}
0
public List<ByteBuffer> readBuffers() throws IOException
{    throw new UnsupportedOperationException();}
0
public Protocol getRemote()
{    stateLock.readLock().lock();    try {        return remote;    } finally {        stateLock.readLock().unlock();    }}
0
public boolean isConnected()
{    stateLock.readLock().lock();    try {        return remote != null;    } finally {        stateLock.readLock().unlock();    }}
0
public void setRemote(Protocol protocol)
{    stateLock.writeLock().lock();    try {        this.remote = protocol;    } finally {        stateLock.writeLock().unlock();    }}
0
public void operationComplete(ChannelFuture future) throws Exception
{    if (!future.isSuccess() && (callback != null)) {        callback.handleError(new IOException("Error writing buffers", future.getCause()));    }}
0
public void handleUpstream(ChannelHandlerContext ctx, ChannelEvent e) throws Exception
{    if (e instanceof ChannelStateEvent) {                ChannelStateEvent cse = (ChannelStateEvent) e;        if ((cse.getState() == ChannelState.OPEN) && (Boolean.FALSE.equals(cse.getValue()))) {                                    disconnect(false, true, null);        }    }    super.handleUpstream(ctx, e);}
1
public void channelOpen(ChannelHandlerContext ctx, ChannelStateEvent e) throws Exception
{        super.channelOpen(ctx, e);}
0
public void messageReceived(ChannelHandlerContext ctx, final MessageEvent e)
{    NettyDataPack dataPack = (NettyDataPack) e.getMessage();    Callback<List<ByteBuffer>> callback = requests.get(dataPack.getSerial());    if (callback == null) {        throw new RuntimeException("Missing previous call info");    }    try {        callback.handleResult(dataPack.getDatas());    } finally {        requests.remove(dataPack.getSerial());    }}
0
public void exceptionCaught(ChannelHandlerContext ctx, ExceptionEvent e)
{    disconnect(false, true, e.getCause());}
0
public Thread newThread(Runnable r)
{    Thread thread = new Thread(r);    thread.setName(prefix + " " + threadId.incrementAndGet());    return thread;}
0
public void setSerial(int serial)
{    this.serial = serial;}
0
public int getSerial()
{    return serial;}
0
public void setDatas(List<ByteBuffer> datas)
{    this.datas = datas;}
0
public List<ByteBuffer> getDatas()
{    return datas;}
0
protected Object encode(ChannelHandlerContext ctx, Channel channel, Object msg) throws Exception
{    NettyDataPack dataPack = (NettyDataPack) msg;    List<ByteBuffer> origs = dataPack.getDatas();    List<ByteBuffer> bbs = new ArrayList<>(origs.size() * 2 + 1);        bbs.add(getPackHeader(dataPack));    for (ByteBuffer b : origs) {                bbs.add(getLengthHeader(b));        bbs.add(b);    }    return ChannelBuffers.wrappedBuffer(bbs.toArray(new ByteBuffer[0]));}
0
private ByteBuffer getPackHeader(NettyDataPack dataPack)
{    ByteBuffer header = ByteBuffer.allocate(8);    header.putInt(dataPack.getSerial());    header.putInt(dataPack.getDatas().size());    header.flip();    return header;}
0
private ByteBuffer getLengthHeader(ByteBuffer buf)
{    ByteBuffer header = ByteBuffer.allocate(4);    header.putInt(buf.limit());    header.flip();    return header;}
0
protected Object decode(ChannelHandlerContext ctx, Channel channel, ChannelBuffer buffer) throws Exception
{    if (!packHeaderRead) {        if (decodePackHeader(ctx, channel, buffer)) {            packHeaderRead = true;        }        return null;    } else {        if (decodePackBody(ctx, channel, buffer)) {                        packHeaderRead = false;            return dataPack;        } else {            return null;        }    }}
0
private boolean decodePackHeader(ChannelHandlerContext ctx, Channel channel, ChannelBuffer buffer) throws Exception
{    if (buffer.readableBytes() < 8) {        return false;    }    int serial = buffer.readInt();    int listSize = buffer.readInt();        if (listSize * SIZEOF_REF > 0.1 * maxMem) {        channel.close().await();        throw new AvroRuntimeException("Excessively large list allocation " + "request detected: " + listSize + " items! Connection closed.");    }    this.listSize = listSize;    dataPack = new NettyDataPack(serial, new ArrayList<>(listSize));    return true;}
0
private boolean decodePackBody(ChannelHandlerContext ctx, Channel channel, ChannelBuffer buffer) throws Exception
{    if (buffer.readableBytes() < 4) {        return false;    }    buffer.markReaderIndex();    int length = buffer.readInt();    if (buffer.readableBytes() < length) {        buffer.resetReaderIndex();        return false;    }    ByteBuffer bb = ByteBuffer.allocate(length);    buffer.readBytes(bb);    bb.flip();    dataPack.getDatas().add(bb);    return dataPack.getDatas().size() == listSize;}
0
public void testNettyTransceiverReleasesNettyChannelOnFailingToConnect() throws Exception
{    LastChannelRememberingChannelFactory socketChannelFactory = null;    try (ServerSocket serverSocket = new ServerSocket(0)) {        socketChannelFactory = new LastChannelRememberingChannelFactory();        try {            new NettyTransceiver(new InetSocketAddress(serverSocket.getLocalPort()), socketChannelFactory, 1L);        } finally {            assertFalse("expected that the channel opened by the transceiver is closed", socketChannelFactory.lastChannel.isOpen());        }    } finally {        if (socketChannelFactory != null) {            socketChannelFactory.releaseExternalResources();        }    }}
0
public SocketChannel newChannel(ChannelPipeline pipeline)
{    return lastChannel = super.newChannel(pipeline);}
0
public String send(Message message)
{    return "Sent message to [" + message.getTo() + "] from [" + message.getFrom() + "] with body [" + message.getBody() + "]";}
0
public void fireandforget(Message message)
{    allMessages.countDown();}
0
private void awaitMessages() throws InterruptedException
{    allMessages.await(2, TimeUnit.SECONDS);}
0
private void assertAllMessagesReceived()
{    assertEquals(0, allMessages.getCount());}
0
public void reset()
{    allMessages = new CountDownLatch(5);}
0
public static void initializeConnections() throws Exception
{        System.out.println("starting server...");    mailService = new MailImpl();    Responder responder = new SpecificResponder(Mail.class, mailService);    server = initializeServer(responder);    server.start();    int serverPort = server.getPort();    System.out.println("server port : " + serverPort);    transceiver = initializeTransceiver(serverPort);    proxy = SpecificRequestor.getClient(Mail.class, transceiver);}
0
protected static Server initializeServer(Responder responder)
{    return new NettyServer(responder, new InetSocketAddress(0));}
0
protected static Transceiver initializeTransceiver(int serverPort) throws IOException
{    return new NettyTransceiver(new InetSocketAddress(serverPort), CONNECT_TIMEOUT_MILLIS);}
0
public static void tearDownConnections() throws Exception
{    transceiver.close();    server.close();}
0
public void testRequestResponse() throws Exception
{    for (int x = 0; x < 5; x++) {        verifyResponse(proxy.send(createMessage()));    }}
0
private void verifyResponse(String result)
{    Assert.assertEquals("Sent message to [wife] from [husband] with body [I love you!]", result);}
0
public void testOneway() throws Exception
{    for (int x = 0; x < 5; x++) {        proxy.fireandforget(createMessage());    }    mailService.awaitMessages();    mailService.assertAllMessagesReceived();}
0
public void testMixtureOfRequests() throws Exception
{    mailService.reset();    for (int x = 0; x < 5; x++) {        Message createMessage = createMessage();        proxy.fireandforget(createMessage);        verifyResponse(proxy.send(createMessage));    }    mailService.awaitMessages();    mailService.assertAllMessagesReceived();}
0
public void testConnectionsCount() throws Exception
{    Transceiver transceiver2 = new NettyTransceiver(new InetSocketAddress(server.getPort()), CONNECT_TIMEOUT_MILLIS);    Mail proxy2 = SpecificRequestor.getClient(Mail.class, transceiver2);    proxy.fireandforget(createMessage());    proxy2.fireandforget(createMessage());    Assert.assertEquals(2, ((NettyServer) server).getNumActiveConnections());    transceiver2.close();            int numActiveConnections = ((NettyServer) server).getNumActiveConnections();    for (int i = 0; i < 50 && numActiveConnections == 2; ++i) {        System.out.println("Server still has 2 active connections; retrying...");        Thread.sleep(100);        numActiveConnections = ((NettyServer) server).getNumActiveConnections();    }    Assert.assertEquals(1, numActiveConnections);}
0
private Message createMessage()
{    Message msg = Message.newBuilder().setTo("wife").setFrom("husband").setBody("I love you!").build();    return msg;}
0
public void testBadRequest() throws IOException
{    int port = server.getPort();    String msg = "GET /status HTTP/1.1\n\n";    InetSocketAddress sockAddr = new InetSocketAddress("127.0.0.1", port);    Socket sock = new Socket();    sock.connect(sockAddr);    OutputStream out = sock.getOutputStream();    out.write(msg.getBytes(StandardCharsets.UTF_8));    out.flush();    byte[] buf = new byte[2048];    int bytesRead = sock.getInputStream().read(buf);    Assert.assertTrue("Connection should have been closed", bytesRead == -1);}
0
public void cleanUpAfter() throws Exception
{    try {        if (transceiver != null) {            transceiver.close();        }    } catch (IOException e) {        e.printStackTrace();    }    try {        if (server != null) {            server.close();        }    } catch (Exception e) {        e.printStackTrace();    }}
0
public void test() throws Exception
{    final CountDownLatch waitLatch = new CountDownLatch(1);    server = new NettyServer(new SpecificResponder(Simple.class, new SimpleImpl(waitLatch)), new InetSocketAddress(0), new NioServerSocketChannelFactory(Executors.newCachedThreadPool(), Executors.newCachedThreadPool()), new ExecutionHandler(Executors.newCachedThreadPool()));    server.start();    transceiver = new NettyTransceiver(new InetSocketAddress(server.getPort()), TestNettyServer.CONNECT_TIMEOUT_MILLIS);        final Simple.Callback simpleClient = SpecificRequestor.getClient(Simple.Callback.class, transceiver);        SpecificRequestor.getRemote(simpleClient);    /*     * 2a. In a background thread, wait for the Client.hello("wait") call to be     * received by the server, then: 2b. Execute the Client.ack() RPC, which will     * unblock the Client.hello("wait") call, allowing it to return to the main     * thread.     */    new Thread() {        @Override        public void run() {            setName(TestNettyServerConcurrentExecution.class.getSimpleName() + "Ack Thread");            try {                                waitLatch.await();                                simpleClient.ack();            } catch (InterruptedException e) {                e.printStackTrace();            }        }    }.start();    /*     * 3. Execute the Client.hello("wait") RPC, which will block until the     * Client.ack() call has completed in the background thread.     */    String response = simpleClient.hello("wait");        Assert.assertEquals("wait", response);}
0
public void run()
{    setName(TestNettyServerConcurrentExecution.class.getSimpleName() + "Ack Thread");    try {                waitLatch.await();                simpleClient.ack();    } catch (InterruptedException e) {        e.printStackTrace();    }}
0
public int add(int arg1, int arg2)
{        return arg1 + arg2;}
0
public String hello(String greeting)
{    if (greeting.equals("wait")) {        try {                        waitLatch.countDown();                        ackLatch.await();        } catch (InterruptedException e) {            Thread.currentThread().interrupt();            return e.toString();        }    }    return greeting;}
0
public void ack()
{        ackLatch.countDown();}
0
public TestRecord echo(TestRecord record)
{    return record;}
0
public ByteBuffer echoBytes(ByteBuffer data)
{    return data;}
0
public void error() throws TestError
{    throw new TestError("TestError");}
0
public static void initializeConnections() throws Exception
{        Responder responder = new SpecificResponder(Simple.class, simpleService);    server = new NettyServer(responder, new InetSocketAddress(0));    server.start();    int serverPort = server.getPort();    System.out.println("server port : " + serverPort);    transceiver = new NettyTransceiver(new InetSocketAddress(serverPort), TestNettyServer.CONNECT_TIMEOUT_MILLIS);    simpleClient = SpecificRequestor.getClient(Simple.Callback.class, transceiver);}
0
public static void tearDownConnections() throws Exception
{    if (transceiver != null) {        transceiver.close();    }    if (server != null) {        server.close();    }}
0
public void greeting() throws Exception
{        Assert.assertEquals("Hello, how are you?", simpleClient.hello("how are you?"));        CallFuture<String> future1 = new CallFuture<>();    simpleClient.hello("World!", future1);    Assert.assertEquals("Hello, World!", future1.get(2, TimeUnit.SECONDS));    Assert.assertNull(future1.getError());        final CallFuture<String> future2 = new CallFuture<>();    simpleClient.hello("what's up?", new Callback<String>() {        @Override        public void handleResult(String result) {            future2.handleResult(result);        }        @Override        public void handleError(Throwable error) {            future2.handleError(error);        }    });    Assert.assertEquals("Hello, what's up?", future2.get(2, TimeUnit.SECONDS));    Assert.assertNull(future2.getError());}
0
public void handleResult(String result)
{    future2.handleResult(result);}
0
public void handleError(Throwable error)
{    future2.handleError(error);}
0
public void echo() throws Exception
{    TestRecord record = TestRecord.newBuilder().setHash(new org.apache.avro.test.MD5(new byte[] { 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8 })).setKind(org.apache.avro.test.Kind.FOO).setName("My Record").build();        Assert.assertEquals(record, simpleClient.echo(record));        CallFuture<TestRecord> future1 = new CallFuture<>();    simpleClient.echo(record, future1);    Assert.assertEquals(record, future1.get(2, TimeUnit.SECONDS));    Assert.assertNull(future1.getError());        final CallFuture<TestRecord> future2 = new CallFuture<>();    simpleClient.echo(record, new Callback<TestRecord>() {        @Override        public void handleResult(TestRecord result) {            future2.handleResult(result);        }        @Override        public void handleError(Throwable error) {            future2.handleError(error);        }    });    Assert.assertEquals(record, future2.get(2, TimeUnit.SECONDS));    Assert.assertNull(future2.getError());}
0
public void handleResult(TestRecord result)
{    future2.handleResult(result);}
0
public void handleError(Throwable error)
{    future2.handleError(error);}
0
public void add() throws Exception
{        Assert.assertEquals(8, simpleClient.add(2, 6));        CallFuture<Integer> future1 = new CallFuture<>();    simpleClient.add(8, 8, future1);    Assert.assertEquals(new Integer(16), future1.get(2, TimeUnit.SECONDS));    Assert.assertNull(future1.getError());        final CallFuture<Integer> future2 = new CallFuture<>();    simpleClient.add(512, 256, new Callback<Integer>() {        @Override        public void handleResult(Integer result) {            future2.handleResult(result);        }        @Override        public void handleError(Throwable error) {            future2.handleError(error);        }    });    Assert.assertEquals(new Integer(768), future2.get(2, TimeUnit.SECONDS));    Assert.assertNull(future2.getError());}
0
public void handleResult(Integer result)
{    future2.handleResult(result);}
0
public void handleError(Throwable error)
{    future2.handleError(error);}
0
public void echoBytes() throws Exception
{    ByteBuffer byteBuffer = ByteBuffer.wrap(new byte[] { 1, 2, 3, 4, 5, 6, 7, 8 });        Assert.assertEquals(byteBuffer, simpleClient.echoBytes(byteBuffer));        CallFuture<ByteBuffer> future1 = new CallFuture<>();    simpleClient.echoBytes(byteBuffer, future1);    Assert.assertEquals(byteBuffer, future1.get(2, TimeUnit.SECONDS));    Assert.assertNull(future1.getError());        final CallFuture<ByteBuffer> future2 = new CallFuture<>();    simpleClient.echoBytes(byteBuffer, new Callback<ByteBuffer>() {        @Override        public void handleResult(ByteBuffer result) {            future2.handleResult(result);        }        @Override        public void handleError(Throwable error) {            future2.handleError(error);        }    });    Assert.assertEquals(byteBuffer, future2.get(2, TimeUnit.SECONDS));    Assert.assertNull(future2.getError());}
0
public void handleResult(ByteBuffer result)
{    future2.handleResult(result);}
0
public void handleError(Throwable error)
{    future2.handleError(error);}
0
public void error() throws IOException, InterruptedException, TimeoutException
{        try {        simpleClient.error();        Assert.fail("Expected " + TestError.class.getCanonicalName());    } catch (TestError e) {        } catch (AvroRemoteException e) {        e.printStackTrace();        Assert.fail("Unexpected error: " + e.toString());    }        CallFuture<Void> future = new CallFuture<>();    simpleClient.error(future);    try {        future.get(2, TimeUnit.SECONDS);        Assert.fail("Expected " + TestError.class.getCanonicalName() + " to be thrown");    } catch (ExecutionException e) {        Assert.assertTrue("Expected " + TestError.class.getCanonicalName(), e.getCause() instanceof TestError);    }    Assert.assertNotNull(future.getError());    Assert.assertTrue("Expected " + TestError.class.getCanonicalName(), future.getError() instanceof TestError);    Assert.assertNull(future.getResult());        final CountDownLatch latch = new CountDownLatch(1);    final AtomicReference<Throwable> errorRef = new AtomicReference<>();    simpleClient.error(new Callback<Void>() {        @Override        public void handleResult(Void result) {            Assert.fail("Expected " + TestError.class.getCanonicalName());        }        @Override        public void handleError(Throwable error) {            errorRef.set(error);            latch.countDown();        }    });    Assert.assertTrue("Timed out waiting for error", latch.await(2, TimeUnit.SECONDS));    Assert.assertNotNull(errorRef.get());    Assert.assertTrue(errorRef.get() instanceof TestError);}
0
public void handleResult(Void result)
{    Assert.fail("Expected " + TestError.class.getCanonicalName());}
0
public void handleError(Throwable error)
{    errorRef.set(error);    latch.countDown();}
0
public void ack() throws Exception
{    simpleClient.ack();    ackLatch.get().await(2, TimeUnit.SECONDS);    Assert.assertTrue("Expected ack flag to be set", ackFlag.get());    ackLatch.set(new CountDownLatch(1));    simpleClient.ack();    ackLatch.get().await(2, TimeUnit.SECONDS);    Assert.assertFalse("Expected ack flag to be cleared", ackFlag.get());}
0
public void testSendAfterChannelClose() throws Exception
{            Server server2 = new NettyServer(new SpecificResponder(Simple.class, simpleService), new InetSocketAddress(0));    server2.start();    try {        int serverPort = server2.getPort();        System.out.println("server2 port : " + serverPort);        try (Transceiver transceiver2 = new NettyTransceiver(new InetSocketAddress(serverPort), TestNettyServer.CONNECT_TIMEOUT_MILLIS)) {            Simple.Callback simpleClient2 = SpecificRequestor.getClient(Simple.Callback.class, transceiver2);                        Assert.assertEquals(3, simpleClient2.add(1, 2));                        CallFuture<Integer> addFuture = new CallFuture<>();            simpleClient2.add(1, 2, addFuture);            Assert.assertEquals(new Integer(3), addFuture.get());                        server2.close();            Thread.sleep(1000L);                                    boolean ioeCaught = false;            try {                simpleClient2.add(1, 2);                Assert.fail("Send after server close should have thrown Exception");            } catch (AvroRuntimeException e) {                ioeCaught = e.getCause() instanceof IOException;                Assert.assertTrue("Expected IOException", ioeCaught);            } catch (Exception e) {                e.printStackTrace();                throw e;            }            Assert.assertTrue("Expected IOException", ioeCaught);                                    ioeCaught = false;            try {                addFuture = new CallFuture<>();                simpleClient2.add(1, 2, addFuture);                addFuture.get();                Assert.fail("Send after server close should have thrown Exception");            } catch (IOException e) {                ioeCaught = true;            } catch (Exception e) {                e.printStackTrace();                throw e;            }            Assert.assertTrue("Expected IOException", ioeCaught);        }    } finally {        server2.close();    }}
0
public void cancelPendingRequestsOnTransceiverClose() throws Exception
{            BlockingSimpleImpl blockingSimpleImpl = new BlockingSimpleImpl();    Server server2 = new NettyServer(new SpecificResponder(Simple.class, blockingSimpleImpl), new InetSocketAddress(0));    server2.start();    try {        int serverPort = server2.getPort();        System.out.println("server2 port : " + serverPort);        CallFuture<Integer> addFuture = new CallFuture<>();        try (Transceiver transceiver2 = new NettyTransceiver(new InetSocketAddress(serverPort), TestNettyServer.CONNECT_TIMEOUT_MILLIS)) {            Simple.Callback simpleClient2 = SpecificRequestor.getClient(Simple.Callback.class, transceiver2);                        Assert.assertEquals(3, simpleClient2.add(1, 2));                        blockingSimpleImpl.acquireRunPermit();            simpleClient2.add(1, 2, addFuture);        }                        boolean ioeThrown = false;        try {            addFuture.get();        } catch (ExecutionException e) {            ioeThrown = e.getCause() instanceof IOException;            Assert.assertTrue(e.getCause() instanceof IOException);        } catch (Exception e) {            e.printStackTrace();            Assert.fail("Unexpected Exception: " + e.toString());        }        Assert.assertTrue("Expected IOException to be thrown", ioeThrown);    } finally {        blockingSimpleImpl.releaseRunPermit();        server2.close();    }}
0
public void cancelPendingRequestsAfterChannelCloseByServerShutdown() throws Throwable
{                                BlockingSimpleImpl blockingSimpleImpl = new BlockingSimpleImpl();    final Server server2 = new NettyServer(new SpecificResponder(Simple.class, blockingSimpleImpl), new InetSocketAddress(0));    server2.start();    Transceiver transceiver2 = null;    try {        int serverPort = server2.getPort();        System.out.println("server2 port : " + serverPort);        transceiver2 = new NettyTransceiver(new InetSocketAddress(serverPort), TestNettyServer.CONNECT_TIMEOUT_MILLIS);        final Simple.Callback simpleClient2 = SpecificRequestor.getClient(Simple.Callback.class, transceiver2);                        blockingSimpleImpl.acquireEnterPermit();                blockingSimpleImpl.acquireRunPermit();                Future<?> clientFuture = Executors.newSingleThreadExecutor().submit(() -> {            try {                simpleClient2.add(3, 4);                Assert.fail("Expected an exception");            } catch (Exception e) {                        }        });                blockingSimpleImpl.acquireEnterPermit();                                                new Thread(server2::close).start();                try {            clientFuture.get(10, TimeUnit.SECONDS);        } catch (ExecutionException e) {            throw e.getCause();        } catch (TimeoutException e) {            Assert.fail("Client request should not be blocked on server shutdown");        }    } finally {        blockingSimpleImpl.releaseRunPermit();        server2.close();        if (transceiver2 != null)            transceiver2.close();    }}
0
public void clientReconnectAfterServerRestart() throws Exception
{            SimpleImpl simpleImpl = new BlockingSimpleImpl();    Server server2 = new NettyServer(new SpecificResponder(Simple.class, simpleImpl), new InetSocketAddress(0));    try {        server2.start();        int serverPort = server2.getPort();        System.out.println("server2 port : " + serverPort);                Transceiver transceiver2 = new NettyTransceiver(new InetSocketAddress(serverPort), TestNettyServer.CONNECT_TIMEOUT_MILLIS);        Simple.Callback simpleClient2 = SpecificRequestor.getClient(Simple.Callback.class, transceiver2);        Assert.assertEquals(3, simpleClient2.add(1, 2));                server2.close();        try {            simpleClient2.add(2, -1);            Assert.fail("Client should not be able to invoke RPCs " + "because server is no longer running");        } catch (Exception e) {                }        Thread.sleep(2000L);        server2 = new NettyServer(new SpecificResponder(Simple.class, simpleImpl), new InetSocketAddress(serverPort));        server2.start();                        Assert.assertEquals(3, simpleClient2.add(1, 2));    } finally {        server2.close();    }}
0
public void performanceTest() throws Exception
{    final int threadCount = 8;    final long runTimeMillis = 10 * 1000L;    ExecutorService threadPool = Executors.newFixedThreadPool(threadCount);    System.out.println("Running performance test for " + runTimeMillis + "ms...");    final AtomicLong rpcCount = new AtomicLong(0L);    final AtomicBoolean runFlag = new AtomicBoolean(true);    final CountDownLatch startLatch = new CountDownLatch(threadCount);    for (int ii = 0; ii < threadCount; ii++) {        threadPool.submit(() -> {            try {                startLatch.countDown();                startLatch.await(2, TimeUnit.SECONDS);                while (runFlag.get()) {                    rpcCount.incrementAndGet();                    Assert.assertEquals("Hello, World!", simpleClient.hello("World!"));                }            } catch (Exception e) {                e.printStackTrace();            }        });    }    startLatch.await(2, TimeUnit.SECONDS);    Thread.sleep(runTimeMillis);    runFlag.set(false);    threadPool.shutdown();    Assert.assertTrue("Timed out shutting down thread pool", threadPool.awaitTermination(2, TimeUnit.SECONDS));    System.out.println("Completed " + rpcCount.get() + " RPCs in " + runTimeMillis + "ms => " + (((double) rpcCount.get() / (double) runTimeMillis) * 1000) + " RPCs/sec, " + ((double) runTimeMillis / (double) rpcCount.get()) + " ms/RPC.");}
0
public String hello(String greeting)
{    return "Hello, " + greeting;}
0
public TestRecord echo(TestRecord record)
{    return record;}
0
public int add(int arg1, int arg2)
{    return arg1 + arg2;}
0
public ByteBuffer echoBytes(ByteBuffer data)
{    return data;}
0
public void error() throws TestError
{    throw TestError.newBuilder().setMessage$("Test Message").build();}
0
public synchronized void ack()
{    ackFlag.set(!ackFlag.get());    ackLatch.get().countDown();}
0
public String hello(String greeting)
{    releaseEnterPermit();    acquireRunPermit();    try {        return super.hello(greeting);    } finally {        releaseRunPermit();    }}
0
public TestRecord echo(TestRecord record)
{    releaseEnterPermit();    acquireRunPermit();    try {        return super.echo(record);    } finally {        releaseRunPermit();    }}
0
public int add(int arg1, int arg2)
{    releaseEnterPermit();    acquireRunPermit();    try {        return super.add(arg1, arg2);    } finally {        releaseRunPermit();    }}
0
public ByteBuffer echoBytes(ByteBuffer data)
{    releaseEnterPermit();    acquireRunPermit();    try {        return super.echoBytes(data);    } finally {        releaseRunPermit();    }}
0
public void error() throws TestError
{    releaseEnterPermit();    acquireRunPermit();    try {        super.error();    } finally {        releaseRunPermit();    }}
0
public void ack()
{    releaseEnterPermit();    acquireRunPermit();    try {        super.ack();    } finally {        releaseRunPermit();    }}
0
public void acquireRunPermit()
{    try {        runSemaphore.acquire();    } catch (InterruptedException e) {        Thread.currentThread().interrupt();        throw new RuntimeException(e);    }}
0
public void releaseRunPermit()
{    runSemaphore.release();}
0
public void acquireEnterPermit()
{    try {        enterSemaphore.acquire();    } catch (InterruptedException e) {        Thread.currentThread().interrupt();        throw new RuntimeException(e);    }}
0
public void releaseEnterPermit()
{    enterSemaphore.release();}
0
protected static Server initializeServer(Responder responder)
{    ChannelFactory channelFactory = new NioServerSocketChannelFactory(Executors.newCachedThreadPool(), Executors.newCachedThreadPool());    return new NettyServer(responder, new InetSocketAddress(0), channelFactory, new CompressionChannelPipelineFactory(), null);}
0
protected static Transceiver initializeTransceiver(int serverPort) throws IOException
{    return new NettyTransceiver(new InetSocketAddress(serverPort), new CompressionChannelFactory(), CONNECT_TIMEOUT_MILLIS);}
0
public SocketChannel newChannel(ChannelPipeline pipeline)
{    try {        ZlibEncoder encoder = new ZlibEncoder(6);        pipeline.addFirst("deflater", encoder);        pipeline.addFirst("inflater", new ZlibDecoder());        return super.newChannel(pipeline);    } catch (Exception ex) {        throw new RuntimeException("Cannot create Compression channel", ex);    }}
0
public ChannelPipeline getPipeline() throws Exception
{    ChannelPipeline pipeline = Channels.pipeline();    ZlibEncoder encoder = new ZlibEncoder(6);    pipeline.addFirst("deflater", encoder);    pipeline.addFirst("inflater", new ZlibDecoder());    return pipeline;}
0
protected static Server initializeServer(Responder responder)
{    ChannelFactory channelFactory = new NioServerSocketChannelFactory(Executors.newCachedThreadPool(), Executors.newCachedThreadPool());    return new NettyServer(responder, new InetSocketAddress(0), channelFactory, new SSLChannelPipelineFactory(), null);}
0
protected static Transceiver initializeTransceiver(int serverPort) throws IOException
{    return new NettyTransceiver(new InetSocketAddress(serverPort), new SSLChannelFactory(), CONNECT_TIMEOUT_MILLIS);}
0
public SocketChannel newChannel(ChannelPipeline pipeline)
{    try {        SSLContext sslContext = SSLContext.getInstance("TLS");        sslContext.init(null, new TrustManager[] { new BogusTrustManager() }, null);        SSLEngine sslEngine = sslContext.createSSLEngine();        sslEngine.setUseClientMode(true);        pipeline.addFirst("ssl", new SslHandler(sslEngine));        return super.newChannel(pipeline);    } catch (Exception ex) {        throw new RuntimeException("Cannot create SSL channel", ex);    }}
0
public void checkClientTrusted(X509Certificate[] certs, String s)
{}
0
public void checkServerTrusted(X509Certificate[] certs, String s)
{}
0
public X509Certificate[] getAcceptedIssuers()
{    return new X509Certificate[0];}
0
private SSLContext createServerSSLContext()
{    try {        KeyStore ks = KeyStore.getInstance("PKCS12");        ks.load(TestNettyServer.class.getResource(TEST_CERTIFICATE).openStream(), TEST_CERTIFICATE_PASSWORD.toCharArray());                KeyManagerFactory kmf = KeyManagerFactory.getInstance(getAlgorithm());        kmf.init(ks, TEST_CERTIFICATE_PASSWORD.toCharArray());        SSLContext serverContext = SSLContext.getInstance("TLS");        serverContext.init(kmf.getKeyManagers(), null, null);        return serverContext;    } catch (Exception e) {        throw new Error("Failed to initialize the server-side SSLContext", e);    }}
0
private String getAlgorithm()
{    String algorithm = Security.getProperty("ssl.KeyManagerFactory.algorithm");    if (algorithm == null) {        algorithm = "SunX509";    }    return algorithm;}
0
public ChannelPipeline getPipeline() throws Exception
{    ChannelPipeline pipeline = Channels.pipeline();    SSLEngine sslEngine = createServerSSLContext().createSSLEngine();    sslEngine.setUseClientMode(false);    pipeline.addLast("ssl", new SslHandler(sslEngine));    return pipeline;}
0
public void testNettyTransceiverWhenServerStops() throws Exception
{    Mail mailService = new TestNettyServer.MailImpl();    Responder responder = new SpecificResponder(Mail.class, mailService);    NettyServer server = new NettyServer(responder, new InetSocketAddress(0));    server.start();    int serverPort = server.getPort();    final NettyTransceiver transceiver = new NettyTransceiver(new InetSocketAddress(serverPort), 60000L);    final Mail mail = SpecificRequestor.getClient(Mail.class, transceiver);    final AtomicInteger successes = new AtomicInteger();    final AtomicInteger failures = new AtomicInteger();    final AtomicBoolean quitOnFailure = new AtomicBoolean();    List<Thread> threads = new ArrayList<>();        for (int i = 0; i < 100; i++) {        Thread thread = new Thread(() -> {            while (true) {                try {                    mail.send(createMessage());                    successes.incrementAndGet();                } catch (Exception e) {                    failures.incrementAndGet();                    if (quitOnFailure.get()) {                        return;                    }                }            }        });        threads.add(thread);        thread.start();    }        while (successes.get() < 10000) {        Thread.sleep(50);    }        server.close();        while (true) {        int previousSuccesses = successes.get();        Thread.sleep(500);        if (previousSuccesses == successes.get()) {            break;        }    }        server.start();                        long now = System.currentTimeMillis();    /*     * System.out.println("Waiting on requests to continue"); int previousSuccesses     * = successes.get(); while (true) { Thread.sleep(500); if (successes.get() >     * previousSuccesses) { break; } if (System.currentTimeMillis() - now > 5000) {     * System.out.println("FYI: requests don't continue immediately..."); break; } }     */        System.out.println("Stopping transceiver");    quitOnFailure.set(true);    now = System.currentTimeMillis();        transceiver.close();        for (Thread thread : threads) {        thread.join();    }    if (System.currentTimeMillis() - now > 10000) {        fail("Stopping NettyTransceiver and waiting for client threads to quit took too long.");    } else {        System.out.println("Stopping NettyTransceiver and waiting for client threads to quit took " + (System.currentTimeMillis() - now) + " ms");    }}
0
private Message createMessage()
{    Message msg = Message.newBuilder().setTo("wife").setFrom("husband").setBody("I love you!").build();    return msg;}
0
public Server createServer(Responder testResponder) throws Exception
{    return new NettyServer(responder, new InetSocketAddress(0));}
0
public Transceiver createTransceiver() throws Exception
{    return new NettyTransceiver(new InetSocketAddress(server.getPort()), 2000L);}
0
protected int getExpectedHandshakeCount()
{    return REPEATING;}
0
public static CodecFactory fromHadoopString(String hadoopCodecClass)
{    CodecFactory o = null;    try {        String avroCodec = HADOOP_AVRO_NAME_MAP.get(hadoopCodecClass);        if (avroCodec != null) {            o = CodecFactory.fromString(avroCodec);        }    } catch (Exception e) {        throw new AvroRuntimeException("Unrecognized hadoop codec: " + hadoopCodecClass, e);    }    return o;}
0
public static String getAvroCodecName(String hadoopCodecClass)
{    return HADOOP_AVRO_NAME_MAP.get(hadoopCodecClass);}
0
public Options withConfiguration(Configuration conf)
{    mConf = conf;    return this;}
0
public Configuration getConfiguration()
{    return mConf;}
0
public Options withPath(Path path)
{    mPath = path;    return this;}
0
public Path getPath()
{    return mPath;}
0
public Options withKeySchema(Schema keySchema)
{    mKeySchema = keySchema;    return this;}
0
public Schema getKeySchema()
{    return mKeySchema;}
0
public Options withValueSchema(Schema valueSchema)
{    mValueSchema = valueSchema;    return this;}
0
public Schema getValueSchema()
{    return mValueSchema;}
0
public Options withDataModel(GenericData model)
{    this.model = model;    return this;}
0
public GenericData getDataModel()
{    return model;}
0
public V get(K key) throws IOException
{            Map.Entry<K, Long> indexEntry = mIndex.floorEntry(key);    if (null == indexEntry) {                return null;    }            mDataFileReader.seek(indexEntry.getValue());        for (AvroKeyValue<K, V> record : this) {        int comparison = model.compare(record.getKey(), key, mKeySchema);        if (0 == comparison) {                                    return record.getValue();        }        if (comparison > 0) {                                    return null;        }    }            return null;}
1
public Iterator<AvroKeyValue<K, V>> iterator()
{    return new AvroKeyValue.Iterator<>(mDataFileReader.iterator());}
0
public void close() throws IOException
{    mDataFileReader.close();}
0
private NavigableMap<K, Long> loadIndexFile(Configuration conf, Path path, Schema keySchema) throws IOException
{    DatumReader<GenericRecord> datumReader = model.createDatumReader(AvroKeyValue.getSchema(keySchema, Schema.create(Schema.Type.LONG)));    NavigableMap<K, Long> index = new TreeMap<>();    try (DataFileReader<GenericRecord> fileReader = new DataFileReader<>(new FsInput(path, conf), datumReader)) {        if (Schema.create(Schema.Type.STRING).equals(keySchema)) {                                                                                                                        index = new TreeMap<>(new AvroCharSequenceComparator<>());        }        for (GenericRecord genericRecord : fileReader) {            AvroKeyValue<K, Long> indexRecord = new AvroKeyValue<>(genericRecord);            index.put(indexRecord.getKey(), indexRecord.getValue());        }    }    return index;}
0
public Options withKeySchema(Schema keySchema)
{    mKeySchema = keySchema;    return this;}
0
public Schema getKeySchema()
{    return mKeySchema;}
0
public Options withValueSchema(Schema valueSchema)
{    mValueSchema = valueSchema;    return this;}
0
public Schema getValueSchema()
{    return mValueSchema;}
0
public Options withConfiguration(Configuration conf)
{    mConf = conf;    return this;}
0
public Configuration getConfiguration()
{    return mConf;}
0
public Options withPath(Path path)
{    mPath = path;    return this;}
0
public Path getPath()
{    return mPath;}
0
public Options withIndexInterval(int indexInterval)
{    mIndexInterval = indexInterval;    return this;}
0
public int getIndexInterval()
{    return mIndexInterval;}
0
public Options withDataModel(GenericData model)
{    this.model = model;    return this;}
0
public GenericData getDataModel()
{    return model;}
0
public Options withCodec(String codec)
{    this.codec = CodecFactory.fromString(codec);    return this;}
0
public Options withCodec(CodecFactory codec)
{    this.codec = codec;    return this;}
0
public CodecFactory getCodec()
{    return this.codec;}
0
public void append(K key, V value) throws IOException
{        if (null != mPreviousKey && model.compare(key, mPreviousKey, mKeySchema) < 0) {        throw new IllegalArgumentException("Records must be inserted in sorted key order." + " Attempted to insert key " + key + " after " + mPreviousKey + ".");    }    mPreviousKey = model.deepCopy(mKeySchema, key);        AvroKeyValue<K, V> dataRecord = new AvroKeyValue<>(new GenericData.Record(mRecordSchema));    dataRecord.setKey(key);    dataRecord.setValue(value);        if (0 == mRecordsWritten++ % mIndexInterval) {                        long position = mDataFileWriter.sync();                AvroKeyValue<K, Long> indexRecord = new AvroKeyValue<>(new GenericData.Record(mIndexSchema));        indexRecord.setKey(key);        indexRecord.setValue(position);        mIndexFileWriter.append(indexRecord.get());    }        mDataFileWriter.append(dataRecord.get());}
0
public void close() throws IOException
{    mIndexFileWriter.close();    mDataFileWriter.close();}
0
public AvroDatumConverter<IN, OUT> create(Class<IN> inputClass)
{    boolean isMapOnly = ((JobConf) getConf()).getNumReduceTasks() == 0;    if (AvroKey.class.isAssignableFrom(inputClass)) {        Schema schema;        if (isMapOnly) {            schema = AvroJob.getMapOutputKeySchema(getConf());            if (null == schema) {                schema = AvroJob.getOutputKeySchema(getConf());            }        } else {            schema = AvroJob.getOutputKeySchema(getConf());        }        if (null == schema) {            throw new IllegalStateException("Writer schema for output key was not set. Use AvroJob.setOutputKeySchema().");        }        return (AvroDatumConverter<IN, OUT>) new AvroWrapperConverter(schema);    }    if (AvroValue.class.isAssignableFrom(inputClass)) {        Schema schema;        if (isMapOnly) {            schema = AvroJob.getMapOutputValueSchema(getConf());            if (null == schema) {                schema = AvroJob.getOutputValueSchema(getConf());            }        } else {            schema = AvroJob.getOutputValueSchema(getConf());        }        if (null == schema) {            throw new IllegalStateException("Writer schema for output value was not set. Use AvroJob.setOutputValueSchema().");        }        return (AvroDatumConverter<IN, OUT>) new AvroWrapperConverter(schema);    }    if (BooleanWritable.class.isAssignableFrom(inputClass)) {        return (AvroDatumConverter<IN, OUT>) new BooleanWritableConverter();    }    if (BytesWritable.class.isAssignableFrom(inputClass)) {        return (AvroDatumConverter<IN, OUT>) new BytesWritableConverter();    }    if (ByteWritable.class.isAssignableFrom(inputClass)) {        return (AvroDatumConverter<IN, OUT>) new ByteWritableConverter();    }    if (DoubleWritable.class.isAssignableFrom(inputClass)) {        return (AvroDatumConverter<IN, OUT>) new DoubleWritableConverter();    }    if (FloatWritable.class.isAssignableFrom(inputClass)) {        return (AvroDatumConverter<IN, OUT>) new FloatWritableConverter();    }    if (IntWritable.class.isAssignableFrom(inputClass)) {        return (AvroDatumConverter<IN, OUT>) new IntWritableConverter();    }    if (LongWritable.class.isAssignableFrom(inputClass)) {        return (AvroDatumConverter<IN, OUT>) new LongWritableConverter();    }    if (NullWritable.class.isAssignableFrom(inputClass)) {        return (AvroDatumConverter<IN, OUT>) new NullWritableConverter();    }    if (Text.class.isAssignableFrom(inputClass)) {        return (AvroDatumConverter<IN, OUT>) new TextConverter();    }    throw new UnsupportedOperationException("Unsupported input type: " + inputClass.getName());}
0
public Object convert(AvroWrapper<?> input)
{    return input.datum();}
0
public Schema getWriterSchema()
{    return mSchema;}
0
public Boolean convert(BooleanWritable input)
{    return input.get();}
0
public Schema getWriterSchema()
{    return mSchema;}
0
public ByteBuffer convert(BytesWritable input)
{    return ByteBuffer.wrap(input.getBytes());}
0
public Schema getWriterSchema()
{    return mSchema;}
0
public GenericFixed convert(ByteWritable input)
{    return new GenericData.Fixed(mSchema, new byte[] { input.get() });}
0
public Schema getWriterSchema()
{    return mSchema;}
0
public Double convert(DoubleWritable input)
{    return input.get();}
0
public Schema getWriterSchema()
{    return mSchema;}
0
public Float convert(FloatWritable input)
{    return input.get();}
0
public Schema getWriterSchema()
{    return mSchema;}
0
public Integer convert(IntWritable input)
{    return input.get();}
0
public Schema getWriterSchema()
{    return mSchema;}
0
public Long convert(LongWritable input)
{    return input.get();}
0
public Schema getWriterSchema()
{    return mSchema;}
0
public Object convert(NullWritable input)
{    return null;}
0
public Schema getWriterSchema()
{    return mSchema;}
0
public CharSequence convert(Text input)
{    return input.toString();}
0
public Schema getWriterSchema()
{    return mSchema;}
0
public Schema getWriterSchema()
{    return mWriterSchema;}
0
public Schema getReaderSchema()
{    return mReaderSchema;}
0
public void open(InputStream inputStream) throws IOException
{    mAvroDecoder = DecoderFactory.get().directBinaryDecoder(inputStream, mAvroDecoder);}
0
public T deserialize(T avroWrapperToReuse) throws IOException
{        if (null == avroWrapperToReuse) {        avroWrapperToReuse = createAvroWrapper();    }        avroWrapperToReuse.datum(mAvroDatumReader.read(avroWrapperToReuse.datum(), mAvroDecoder));    return avroWrapperToReuse;}
0
public void close() throws IOException
{    mAvroDecoder.inputStream().close();}
0
public void setConf(Configuration conf)
{    super.setConf(conf);    if (null != conf) {                                mSchema = AvroJob.getMapOutputKeySchema(conf);        mDataModel = AvroSerialization.createDataModel(conf);    }}
0
public int compare(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2)
{    return BinaryData.compare(b1, s1, b2, s2, mSchema);}
0
public int compare(AvroKey<T> x, AvroKey<T> y)
{    return mDataModel.compare(x.datum(), y.datum(), mSchema);}
0
protected AvroWrapper<D> createAvroWrapper()
{    return new AvroKey<>(null);}
0
public GenericRecord get()
{    return mKeyValueRecord;}
0
public K getKey()
{    return (K) mKeyValueRecord.get(KEY_FIELD);}
0
public V getValue()
{    return (V) mKeyValueRecord.get(VALUE_FIELD);}
0
public void setKey(K key)
{    mKeyValueRecord.put(KEY_FIELD, key);}
0
public void setValue(V value)
{    mKeyValueRecord.put(VALUE_FIELD, value);}
0
public static Schema getSchema(Schema keySchema, Schema valueSchema)
{    Schema schema = Schema.createRecord(KEY_VALUE_PAIR_RECORD_NAME, "A key/value pair", KEY_VALUE_PAIR_RECORD_NAMESPACE, false);    schema.setFields(Arrays.asList(new Schema.Field(KEY_FIELD, keySchema, "The key", null), new Schema.Field(VALUE_FIELD, valueSchema, "The value", null)));    return schema;}
0
public boolean hasNext()
{    return mGenericIterator.hasNext();}
0
public AvroKeyValue<K, V> next()
{    GenericRecord genericRecord = mGenericIterator.next();    if (null == genericRecord) {        return null;    }    return new AvroKeyValue<>(genericRecord);}
0
public void remove()
{    mGenericIterator.remove();}
0
public static SequenceFile.Writer createWriter(Writer.Options options) throws IOException
{    return SequenceFile.createWriter(options.getFileSystem(), options.getConfigurationWithAvroSerialization(), options.getOutputPath(), options.getKeyClass(), options.getValueClass(), options.getBufferSizeBytes(), options.getReplicationFactor(), options.getBlockSizeBytes(), options.getCompressionType(), options.getCompressionCodec(), options.getProgressable(), options.getMetadataWithAvroSchemas());}
0
public Options withFileSystem(FileSystem fileSystem)
{    if (null == fileSystem) {        throw new IllegalArgumentException("Filesystem may not be null");    }    mFileSystem = fileSystem;    return this;}
0
public Options withConfiguration(Configuration conf)
{    if (null == conf) {        throw new IllegalArgumentException("Configuration may not be null");    }    mConf = conf;    return this;}
0
public Options withOutputPath(Path outputPath)
{    if (null == outputPath) {        throw new IllegalArgumentException("Output path may not be null");    }    mOutputPath = outputPath;    return this;}
0
public Options withKeyClass(Class<?> keyClass)
{    if (null == keyClass) {        throw new IllegalArgumentException("Key class may not be null");    }    mKeyClass = keyClass;    return this;}
0
public Options withKeySchema(Schema keyWriterSchema)
{    if (null == keyWriterSchema) {        throw new IllegalArgumentException("Key schema may not be null");    }    withKeyClass(AvroKey.class);    mKeyWriterSchema = keyWriterSchema;    return this;}
0
public Options withValueClass(Class<?> valueClass)
{    if (null == valueClass) {        throw new IllegalArgumentException("Value class may not be null");    }    mValueClass = valueClass;    return this;}
0
public Options withValueSchema(Schema valueWriterSchema)
{    if (null == valueWriterSchema) {        throw new IllegalArgumentException("Value schema may not be null");    }    withValueClass(AvroValue.class);    mValueWriterSchema = valueWriterSchema;    return this;}
0
public Options withBufferSizeBytes(int bytes)
{    if (bytes < 0) {        throw new IllegalArgumentException("Buffer size may not be negative");    }    mBufferSizeBytes = bytes;    return this;}
0
public Options withReplicationFactor(short replicationFactor)
{    if (replicationFactor <= 0) {        throw new IllegalArgumentException("Replication factor must be positive");    }    mReplicationFactor = replicationFactor;    return this;}
0
public Options withBlockSizeBytes(long bytes)
{    if (bytes <= 0) {        throw new IllegalArgumentException("Block size must be positive");    }    mBlockSizeBytes = bytes;    return this;}
0
public Options withProgressable(Progressable progressable)
{    mProgressable = progressable;    return this;}
0
public Options withCompressionType(CompressionType compressionType)
{    mCompressionType = compressionType;    return this;}
0
public Options withCompressionCodec(CompressionCodec compressionCodec)
{    mCompressionCodec = compressionCodec;    return this;}
0
public Options withMetadata(Metadata metadata)
{    if (null == metadata) {        throw new IllegalArgumentException("Metadata may not be null");    }    mMetadata = metadata;    return this;}
0
public FileSystem getFileSystem()
{    if (null == mFileSystem) {        throw new RuntimeException("Must call Options.withFileSystem()");    }    return mFileSystem;}
0
public Configuration getConfiguration()
{    return mConf;}
0
public Configuration getConfigurationWithAvroSerialization()
{    Configuration conf = getConfiguration();    if (null == conf) {        throw new RuntimeException("Must call Options.withConfiguration()");    }    Configuration confWithAvro = new Configuration(conf);    if (null != mKeyWriterSchema) {        AvroSerialization.setKeyWriterSchema(confWithAvro, mKeyWriterSchema);    }    if (null != mValueWriterSchema) {        AvroSerialization.setValueWriterSchema(confWithAvro, mValueWriterSchema);    }    AvroSerialization.addToConfiguration(confWithAvro);    return confWithAvro;}
0
public Path getOutputPath()
{    if (null == mOutputPath) {        throw new RuntimeException("Must call Options.withOutputPath()");    }    return mOutputPath;}
0
public Class<?> getKeyClass()
{    if (null == mKeyClass) {        throw new RuntimeException("Must call Options.withKeyClass() or Options.withKeySchema()");    }    return mKeyClass;}
0
public Class<?> getValueClass()
{    if (null == mValueClass) {        throw new RuntimeException("Must call Options.withValueClass() or Options.withValueSchema()");    }    return mValueClass;}
0
public int getBufferSizeBytes()
{    if (DEFAULT == mBufferSizeBytes) {        return getConfiguration().getInt(IO_FILE_BUFFER_SIZE_KEY, IO_FILE_BUFFER_SIZE_DEFAULT);    }    return mBufferSizeBytes;}
0
public short getReplicationFactor()
{    if (DEFAULT == mReplicationFactor) {        return getFileSystem().getDefaultReplication();    }    return mReplicationFactor;}
0
public long getBlockSizeBytes()
{    if (DEFAULT == mBlockSizeBytes) {        return getFileSystem().getDefaultBlockSize();    }    return mBlockSizeBytes;}
0
public Progressable getProgressable()
{    return mProgressable;}
0
public CompressionType getCompressionType()
{    return mCompressionType;}
0
public CompressionCodec getCompressionCodec()
{    return mCompressionCodec;}
0
public Metadata getMetadata()
{    return mMetadata;}
0
private Metadata getMetadataWithAvroSchemas()
{        assert null != mMetadata;    if (null != mKeyWriterSchema) {        mMetadata.set(METADATA_FIELD_KEY_SCHEMA, new Text(mKeyWriterSchema.toString()));    }    if (null != mValueWriterSchema) {        mMetadata.set(METADATA_FIELD_VALUE_SCHEMA, new Text(mValueWriterSchema.toString()));    }    return mMetadata;}
0
public Options withFileSystem(FileSystem fileSystem)
{    if (null == fileSystem) {        throw new IllegalArgumentException("Filesystem may not be null");    }    mFileSystem = fileSystem;    return this;}
0
public Options withInputPath(Path inputPath)
{    if (null == inputPath) {        throw new IllegalArgumentException("Input path may not be null");    }    mInputPath = inputPath;    return this;}
0
public Options withConfiguration(Configuration conf)
{    if (null == conf) {        throw new IllegalArgumentException("Configuration may not be null");    }    mConf = conf;    return this;}
0
public Options withKeySchema(Schema keyReaderSchema)
{    mKeyReaderSchema = keyReaderSchema;    return this;}
0
public Options withValueSchema(Schema valueReaderSchema)
{    mValueReaderSchema = valueReaderSchema;    return this;}
0
public FileSystem getFileSystem()
{    if (null == mFileSystem) {        throw new RuntimeException("Must call Options.withFileSystem()");    }    return mFileSystem;}
0
public Path getInputPath()
{    if (null == mInputPath) {        throw new RuntimeException("Must call Options.withInputPath()");    }    return mInputPath;}
0
public Configuration getConfiguration()
{    return mConf;}
0
public Configuration getConfigurationWithAvroSerialization() throws IOException
{    Configuration conf = getConfiguration();    if (null == conf) {        throw new RuntimeException("Must call Options.withConfiguration()");    }        Configuration confWithAvro = new Configuration(conf);    AvroSerialization.addToConfiguration(confWithAvro);        Metadata metadata = AvroSequenceFile.getMetadata(getFileSystem(), getInputPath(), confWithAvro);        Text keySchemaText = metadata.get(METADATA_FIELD_KEY_SCHEMA);    if (null != keySchemaText) {                AvroSerialization.setKeyWriterSchema(confWithAvro, new Schema.Parser().parse(keySchemaText.toString()));        if (null != mKeyReaderSchema) {            AvroSerialization.setKeyReaderSchema(confWithAvro, mKeyReaderSchema);        }    }        Text valueSchemaText = metadata.get(METADATA_FIELD_VALUE_SCHEMA);    if (null != valueSchemaText) {                AvroSerialization.setValueWriterSchema(confWithAvro, new Schema.Parser().parse(valueSchemaText.toString()));        if (null != mValueReaderSchema) {            AvroSerialization.setValueReaderSchema(confWithAvro, mValueReaderSchema);        }    }    return confWithAvro;}
1
private static Metadata getMetadata(FileSystem fs, Path path, Configuration conf) throws IOException
{    try (SequenceFile.Reader metadataReader = new SequenceFile.Reader(fs, path, conf)) {        return metadataReader.getMetadata();    }}
0
public boolean accept(Class<?> c)
{    return AvroKey.class.isAssignableFrom(c) || AvroValue.class.isAssignableFrom(c);}
0
public Deserializer<AvroWrapper<T>> getDeserializer(Class<AvroWrapper<T>> c)
{    Configuration conf = getConf();    GenericData dataModel = createDataModel(conf);    if (AvroKey.class.isAssignableFrom(c)) {        Schema writerSchema = getKeyWriterSchema(conf);        Schema readerSchema = getKeyReaderSchema(conf);        DatumReader<T> datumReader = (readerSchema != null) ? dataModel.createDatumReader(writerSchema, readerSchema) : dataModel.createDatumReader(writerSchema);        return new AvroKeyDeserializer<>(writerSchema, readerSchema, datumReader);    } else if (AvroValue.class.isAssignableFrom(c)) {        Schema writerSchema = getValueWriterSchema(conf);        Schema readerSchema = getValueReaderSchema(conf);        DatumReader<T> datumReader = (readerSchema != null) ? dataModel.createDatumReader(writerSchema, readerSchema) : dataModel.createDatumReader(writerSchema);        return new AvroValueDeserializer<>(writerSchema, readerSchema, datumReader);    } else {        throw new IllegalStateException("Only AvroKey and AvroValue are supported.");    }}
0
public Serializer<AvroWrapper<T>> getSerializer(Class<AvroWrapper<T>> c)
{    Configuration conf = getConf();    Schema schema;    if (AvroKey.class.isAssignableFrom(c)) {        schema = getKeyWriterSchema(conf);    } else if (AvroValue.class.isAssignableFrom(c)) {        schema = getValueWriterSchema(conf);    } else {        throw new IllegalStateException("Only AvroKey and AvroValue are supported.");    }    GenericData dataModel = createDataModel(conf);    DatumWriter<T> datumWriter = dataModel.createDatumWriter(schema);    return new AvroSerializer<>(schema, datumWriter);}
0
public static void addToConfiguration(Configuration conf)
{    Collection<String> serializations = conf.getStringCollection("io.serializations");    if (!serializations.contains(AvroSerialization.class.getName())) {        serializations.add(AvroSerialization.class.getName());        conf.setStrings("io.serializations", serializations.toArray(new String[0]));    }}
0
public static void setKeyWriterSchema(Configuration conf, Schema schema)
{    if (null == schema) {        throw new IllegalArgumentException("Writer schema may not be null");    }    conf.set(CONF_KEY_WRITER_SCHEMA, schema.toString());}
0
public static void setKeyReaderSchema(Configuration conf, Schema schema)
{    conf.set(CONF_KEY_READER_SCHEMA, schema.toString());}
0
public static void setValueWriterSchema(Configuration conf, Schema schema)
{    if (null == schema) {        throw new IllegalArgumentException("Writer schema may not be null");    }    conf.set(CONF_VALUE_WRITER_SCHEMA, schema.toString());}
0
public static void setValueReaderSchema(Configuration conf, Schema schema)
{    conf.set(CONF_VALUE_READER_SCHEMA, schema.toString());}
0
public static void setDataModelClass(Configuration conf, Class<? extends GenericData> modelClass)
{    conf.setClass(CONF_DATA_MODEL, modelClass, GenericData.class);}
0
public static Schema getKeyWriterSchema(Configuration conf)
{    String json = conf.get(CONF_KEY_WRITER_SCHEMA);    return null == json ? null : new Schema.Parser().parse(json);}
0
public static Schema getKeyReaderSchema(Configuration conf)
{    String json = conf.get(CONF_KEY_READER_SCHEMA);    return null == json ? null : new Schema.Parser().parse(json);}
0
public static Schema getValueWriterSchema(Configuration conf)
{    String json = conf.get(CONF_VALUE_WRITER_SCHEMA);    return null == json ? null : new Schema.Parser().parse(json);}
0
public static Schema getValueReaderSchema(Configuration conf)
{    String json = conf.get(CONF_VALUE_READER_SCHEMA);    return null == json ? null : new Schema.Parser().parse(json);}
0
public static Class<? extends GenericData> getDataModelClass(Configuration conf)
{    return conf.getClass(CONF_DATA_MODEL, ReflectData.class, GenericData.class);}
0
private static GenericData newDataModelInstance(Class<? extends GenericData> modelClass, Configuration conf)
{    GenericData dataModel;    try {        Constructor<? extends GenericData> ctor = modelClass.getDeclaredConstructor(ClassLoader.class);        ctor.setAccessible(true);        dataModel = ctor.newInstance(conf.getClassLoader());    } catch (Exception e) {        throw new RuntimeException(e);    }    ReflectionUtils.setConf(dataModel, conf);    return dataModel;}
0
public static GenericData createDataModel(Configuration conf)
{    Class<? extends GenericData> modelClass = getDataModelClass(conf);    return newDataModelInstance(modelClass, conf);}
0
public Schema getWriterSchema()
{    return mWriterSchema;}
0
public void open(OutputStream outputStream) throws IOException
{    mOutputStream = outputStream;    mAvroEncoder = ENCODER_FACTORY.binaryEncoder(outputStream, mAvroEncoder);}
0
public void serialize(AvroWrapper<T> avroWrapper) throws IOException
{    mAvroDatumWriter.write(avroWrapper.datum(), mAvroEncoder);                    mAvroEncoder.flush();}
0
public void close() throws IOException
{    mOutputStream.close();}
0
protected AvroWrapper<D> createAvroWrapper()
{    return new AvroValue<>(null);}
0
public int compare(T o1, T o2)
{    if (!(o1 instanceof CharSequence) || !(o2 instanceof CharSequence)) {        throw new RuntimeException("Attempted use of AvroCharSequenceComparator on non-CharSequence objects: " + o1.getClass().getName() + " and " + o2.getClass().getName());    }    return compareCharSequence((CharSequence) o1, (CharSequence) o2);}
0
private int compareCharSequence(CharSequence o1, CharSequence o2)
{    for (int i = 0; i < Math.max(o1.length(), o2.length()); i++) {        int charComparison = compareCharacter(o1, o2, i);        if (0 != charComparison) {            return charComparison;        }    }    return 0;}
0
private int compareCharacter(CharSequence o1, CharSequence o2, int index)
{    if (index < o1.length() && index < o2.length()) {        return Character.compare(o1.charAt(index), o2.charAt(index));    }    if (index >= o1.length() && index >= o2.length()) {        return 0;    }    return o1.length() - o2.length();}
0
protected FileStatus[] listStatus(JobConf job) throws IOException
{    if (job.getBoolean(AvroInputFormat.IGNORE_FILES_WITHOUT_EXTENSION_KEY, AvroInputFormat.IGNORE_INPUTS_WITHOUT_EXTENSION_DEFAULT)) {        List<FileStatus> result = new ArrayList<>();        for (FileStatus file : super.listStatus(job)) if (file.getPath().getName().endsWith(AvroOutputFormat.EXT))            result.add(file);        return result.toArray(new FileStatus[0]);    } else {        return super.listStatus(job);    }}
0
public RecordReader<Text, Text> getRecordReader(InputSplit split, JobConf job, Reporter reporter) throws IOException
{    reporter.setStatus(split.toString());    return new AvroAsTextRecordReader(job, (FileSplit) split);}
0
public Text createKey()
{    return new Text();}
0
public Text createValue()
{    return new Text();}
0
public boolean next(Text key, Text ignore) throws IOException
{    if (!reader.hasNext() || reader.pastSync(end))        return false;    datum = reader.next(datum);    if (datum instanceof ByteBuffer) {        ByteBuffer b = (ByteBuffer) datum;        if (b.hasArray()) {            int offset = b.arrayOffset();            int start = b.position();            int length = b.remaining();            key.set(b.array(), offset + start, offset + start + length);        } else {            byte[] bytes = new byte[b.remaining()];            b.duplicate().get(bytes);            key.set(bytes);        }    } else {        key.set(GenericData.get().toString(datum));    }    return true;}
0
public float getProgress() throws IOException
{    if (end == start) {        return 0.0f;    } else {        return Math.min(1.0f, (getPos() - start) / (float) (end - start));    }}
0
public long getPos() throws IOException
{    return reader.tell();}
0
public void close() throws IOException
{    reader.close();}
0
protected FileStatus[] listStatus(JobConf job) throws IOException
{    if (job.getBoolean(IGNORE_FILES_WITHOUT_EXTENSION_KEY, IGNORE_INPUTS_WITHOUT_EXTENSION_DEFAULT)) {        List<FileStatus> result = new ArrayList<>();        for (FileStatus file : super.listStatus(job)) if (file.getPath().getName().endsWith(AvroOutputFormat.EXT))            result.add(file);        return result.toArray(new FileStatus[0]);    } else {        return super.listStatus(job);    }}
0
public RecordReader<AvroWrapper<T>, NullWritable> getRecordReader(InputSplit split, JobConf job, Reporter reporter) throws IOException
{    reporter.setStatus(split.toString());    return new AvroRecordReader<>(job, (FileSplit) split);}
0
public static void setInputSchema(JobConf job, Schema s)
{    job.set(INPUT_SCHEMA, s.toString());    configureAvroInput(job);}
0
public static Schema getInputSchema(Configuration job)
{    String schemaString = job.get(INPUT_SCHEMA);    return schemaString != null ? new Schema.Parser().parse(schemaString) : null;}
0
public static void setMapOutputSchema(JobConf job, Schema s)
{    job.set(MAP_OUTPUT_SCHEMA, s.toString());    configureAvroShuffle(job);}
0
public static Schema getMapOutputSchema(Configuration job)
{    return new Schema.Parser().parse(job.get(MAP_OUTPUT_SCHEMA, job.get(OUTPUT_SCHEMA)));}
0
public static void setOutputSchema(JobConf job, Schema s)
{    job.set(OUTPUT_SCHEMA, s.toString());    configureAvroOutput(job);}
0
public static void setOutputCodec(JobConf job, String codec)
{    job.set(OUTPUT_CODEC, codec);}
0
public static void setOutputMeta(JobConf job, String key, String value)
{    job.set(TEXT_PREFIX + key, value);}
0
public static void setOutputMeta(JobConf job, String key, long value)
{    job.set(TEXT_PREFIX + key, Long.toString(value));}
0
public static void setOutputMeta(JobConf job, String key, byte[] value)
{    try {        job.set(BINARY_PREFIX + key, URLEncoder.encode(new String(value, StandardCharsets.ISO_8859_1), StandardCharsets.ISO_8859_1.name()));    } catch (UnsupportedEncodingException e) {    }}
0
public static void setInputSequenceFile(JobConf job)
{    job.setInputFormat(SequenceFileInputFormat.class);}
0
public static void setReflect(JobConf job)
{    setInputReflect(job);    setMapOutputReflect(job);}
0
public static void setInputReflect(JobConf job)
{    job.setBoolean(INPUT_IS_REFLECT, true);}
0
public static void setMapOutputReflect(JobConf job)
{    job.setBoolean(MAP_OUTPUT_IS_REFLECT, true);}
0
public static Schema getOutputSchema(Configuration job)
{    return new Schema.Parser().parse(job.get(OUTPUT_SCHEMA));}
0
private static void configureAvroInput(JobConf job)
{    if (job.get("mapred.input.format.class") == null)        job.setInputFormat(AvroInputFormat.class);    if (job.getMapperClass() == IdentityMapper.class)        job.setMapperClass(HadoopMapper.class);    configureAvroShuffle(job);}
0
private static void configureAvroOutput(JobConf job)
{    if (job.get("mapred.output.format.class") == null)        job.setOutputFormat(AvroOutputFormat.class);    if (job.getReducerClass() == IdentityReducer.class)        job.setReducerClass(HadoopReducer.class);    job.setOutputKeyClass(AvroWrapper.class);    configureAvroShuffle(job);}
0
private static void configureAvroShuffle(JobConf job)
{    job.setOutputKeyComparatorClass(AvroKeyComparator.class);    job.setMapOutputKeyClass(AvroKey.class);    job.setMapOutputValueClass(AvroValue.class);        Collection<String> serializations = job.getStringCollection("io.serializations");    if (!serializations.contains(AvroSerialization.class.getName())) {        serializations.add(AvroSerialization.class.getName());        job.setStrings("io.serializations", serializations.toArray(new String[0]));    }}
0
public static void setMapperClass(JobConf job, Class<? extends AvroMapper> c)
{    job.set(MAPPER, c.getName());}
0
public static void setCombinerClass(JobConf job, Class<? extends AvroReducer> c)
{    job.set(COMBINER, c.getName());    job.setCombinerClass(HadoopCombiner.class);}
0
public static void setReducerClass(JobConf job, Class<? extends AvroReducer> c)
{    job.set(REDUCER, c.getName());}
0
public static void setDataModelClass(JobConf job, Class<? extends GenericData> modelClass)
{    job.setClass(CONF_DATA_MODEL, modelClass, GenericData.class);}
0
public static Class<? extends GenericData> getDataModelClass(Configuration conf)
{    return conf.getClass(CONF_DATA_MODEL, ReflectData.class, GenericData.class);}
0
private static GenericData newDataModelInstance(Class<? extends GenericData> modelClass, Configuration conf)
{    GenericData dataModel;    try {        Constructor<? extends GenericData> ctor = modelClass.getDeclaredConstructor(ClassLoader.class);        ctor.setAccessible(true);        dataModel = ctor.newInstance(conf.getClassLoader());    } catch (Exception e) {        throw new RuntimeException(e);    }    ReflectionUtils.setConf(dataModel, conf);    return dataModel;}
0
public static GenericData createDataModel(Configuration conf)
{    return newDataModelInstance(getDataModelClass(conf), conf);}
0
public static GenericData createInputDataModel(Configuration conf)
{    String className = conf.get(CONF_DATA_MODEL, null);    Class<? extends GenericData> modelClass;    if (className != null) {        modelClass = getDataModelClass(conf);    } else if (conf.getBoolean(INPUT_IS_REFLECT, false)) {        modelClass = ReflectData.class;    } else {        modelClass = SpecificData.class;    }    return newDataModelInstance(modelClass, conf);}
0
public static GenericData createMapOutputDataModel(Configuration conf)
{    String className = conf.get(CONF_DATA_MODEL, null);    Class<? extends GenericData> modelClass;    if (className != null) {        modelClass = getDataModelClass(conf);    } else if (conf.getBoolean(MAP_OUTPUT_IS_REFLECT, false)) {        modelClass = ReflectData.class;    } else {        modelClass = SpecificData.class;    }    return newDataModelInstance(modelClass, conf);}
0
public void setConf(Configuration conf)
{    super.setConf(conf);    if (conf != null)        schema = Pair.getKeySchema(AvroJob.getMapOutputSchema(conf));}
0
public int compare(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2)
{    return BinaryData.compare(b1, s1, l1, b2, s2, l2, schema);}
0
public int compare(AvroWrapper<T> x, AvroWrapper<T> y)
{    return ReflectData.get().compare(x.datum(), y.datum(), schema);}
0
public void map(IN datum, AvroCollector<OUT> collector, Reporter reporter) throws IOException
{    collector.collect((OUT) datum);}
0
public void close() throws IOException
{}
0
public void configure(JobConf jobConf)
{}
0
private static void addInputPath(JobConf conf, Path path, Schema inputSchema)
{    String schemaMapping = path.toString() + ";" + toBase64(inputSchema.toString());    String schemas = conf.get(SCHEMA_KEY);    conf.set(SCHEMA_KEY, schemas == null ? schemaMapping : schemas + "," + schemaMapping);    conf.setInputFormat(DelegatingInputFormat.class);}
0
public static void addInputPath(JobConf conf, Path path, Class<? extends AvroMapper> mapperClass, Schema inputSchema)
{    addInputPath(conf, path, inputSchema);    String mapperMapping = path.toString() + ";" + mapperClass.getName();    System.out.println(mapperMapping);    String mappers = conf.get(MAPPERS_KEY);    conf.set(MAPPERS_KEY, mappers == null ? mapperMapping : mappers + "," + mapperMapping);    conf.setMapperClass(DelegatingMapper.class);}
0
 static Map<Path, Class<? extends AvroMapper>> getMapperTypeMap(JobConf conf)
{    if (conf.get(MAPPERS_KEY) == null) {        return Collections.emptyMap();    }    Map<Path, Class<? extends AvroMapper>> m = new HashMap<>();    String[] pathMappings = conf.get(MAPPERS_KEY).split(",");    for (String pathMapping : pathMappings) {        String[] split = pathMapping.split(";");        Class<? extends AvroMapper> mapClass;        try {            mapClass = (Class<? extends AvroMapper>) conf.getClassByName(split[1]);        } catch (ClassNotFoundException e) {            throw new RuntimeException(e);        }        m.put(new Path(split[0]), mapClass);    }    return m;}
0
 static Map<Path, Schema> getInputSchemaMap(JobConf conf)
{    if (conf.get(SCHEMA_KEY) == null) {        return Collections.emptyMap();    }    Map<Path, Schema> m = new HashMap<>();    String[] schemaMappings = conf.get(SCHEMA_KEY).split(",");    Schema.Parser schemaParser = new Schema.Parser();    for (String schemaMapping : schemaMappings) {        String[] split = schemaMapping.split(";");        String schemaString = fromBase64(split[1]);        Schema inputSchema;        try {            inputSchema = schemaParser.parse(schemaString);        } catch (SchemaParseException e) {            throw new RuntimeException(e);        }        m.put(new Path(split[0]), inputSchema);    }    return m;}
0
private static String toBase64(String rawString)
{    final byte[] buf = rawString.getBytes(UTF_8);    return new String(Base64.getMimeEncoder().encode(buf), UTF_8);}
0
private static String fromBase64(String base64String)
{    final byte[] buf = base64String.getBytes(UTF_8);    return new String(Base64.getMimeDecoder().decode(buf), UTF_8);}
0
private static void checkNamedOutput(JobConf conf, String namedOutput, boolean alreadyDefined)
{    List<String> definedChannels = getNamedOutputsList(conf);    if (alreadyDefined && definedChannels.contains(namedOutput)) {        throw new IllegalArgumentException("Named output '" + namedOutput + "' already alreadyDefined");    } else if (!alreadyDefined && !definedChannels.contains(namedOutput)) {        throw new IllegalArgumentException("Named output '" + namedOutput + "' not defined");    }}
0
private static void checkTokenName(String namedOutput)
{    if (namedOutput == null || namedOutput.length() == 0) {        throw new IllegalArgumentException("Name cannot be NULL or empty");    }    for (char ch : namedOutput.toCharArray()) {        if ((ch >= 'A') && (ch <= 'Z')) {            continue;        }        if ((ch >= 'a') && (ch <= 'z')) {            continue;        }        if ((ch >= '0') && (ch <= '9')) {            continue;        }        throw new IllegalArgumentException("Name cannot have a '" + ch + "' char");    }}
0
private static void checkNamedOutputName(String namedOutput)
{    checkTokenName(namedOutput);        if (namedOutput.equals("part")) {        throw new IllegalArgumentException("Named output name cannot be 'part'");    }}
0
public static List<String> getNamedOutputsList(JobConf conf)
{    List<String> names = new ArrayList<>();    StringTokenizer st = new StringTokenizer(conf.get(NAMED_OUTPUTS, ""), " ");    while (st.hasMoreTokens()) {        names.add(st.nextToken());    }    return names;}
0
public static boolean isMultiNamedOutput(JobConf conf, String namedOutput)
{    checkNamedOutput(conf, namedOutput, false);    return conf.getBoolean(MO_PREFIX + namedOutput + MULTI, false);}
0
public static Class<? extends OutputFormat> getNamedOutputFormatClass(JobConf conf, String namedOutput)
{    checkNamedOutput(conf, namedOutput, false);    return conf.getClass(MO_PREFIX + namedOutput + FORMAT, null, OutputFormat.class);}
0
public static void addNamedOutput(JobConf conf, String namedOutput, Class<? extends OutputFormat> outputFormatClass, Schema schema)
{    addNamedOutput(conf, namedOutput, false, outputFormatClass, schema);}
0
public static void addMultiNamedOutput(JobConf conf, String namedOutput, Class<? extends OutputFormat> outputFormatClass, Schema schema)
{    addNamedOutput(conf, namedOutput, true, outputFormatClass, schema);}
0
private static void addNamedOutput(JobConf conf, String namedOutput, boolean multi, Class<? extends OutputFormat> outputFormatClass, Schema schema)
{    checkNamedOutputName(namedOutput);    checkNamedOutput(conf, namedOutput, true);    boolean isMapOnly = conf.getNumReduceTasks() == 0;    if (schema != null)        conf.set(MO_PREFIX + namedOutput + ".schema", schema.toString());    conf.set(NAMED_OUTPUTS, conf.get(NAMED_OUTPUTS, "") + " " + namedOutput);    conf.setClass(MO_PREFIX + namedOutput + FORMAT, outputFormatClass, OutputFormat.class);    conf.setBoolean(MO_PREFIX + namedOutput + MULTI, multi);}
0
public static void setCountersEnabled(JobConf conf, boolean enabled)
{    conf.setBoolean(COUNTERS_ENABLED, enabled);}
0
public static boolean getCountersEnabled(JobConf conf)
{    return conf.getBoolean(COUNTERS_ENABLED, false);}
0
public Iterator<String> getNamedOutputs()
{    return namedOutputs.iterator();}
0
private synchronized RecordWriter getRecordWriter(String namedOutput, String baseFileName, final Reporter reporter, Schema schema) throws IOException
{    RecordWriter writer = recordWriters.get(baseFileName);    if (writer == null) {        if (countersEnabled && reporter == null) {            throw new IllegalArgumentException("Counters are enabled, Reporter cannot be NULL");        }        if (schema != null)            conf.set(MO_PREFIX + namedOutput + ".schema", schema.toString());        JobConf jobConf = new JobConf(conf);        jobConf.set(InternalFileOutputFormat.CONFIG_NAMED_OUTPUT, namedOutput);        FileSystem fs = FileSystem.get(conf);        writer = outputFormat.getRecordWriter(fs, jobConf, baseFileName, reporter);        if (countersEnabled) {            if (reporter == null) {                throw new IllegalArgumentException("Counters are enabled, Reporter cannot be NULL");            }            writer = new RecordWriterWithCounter(writer, baseFileName, reporter);        }        recordWriters.put(baseFileName, writer);    }    return writer;}
0
public void write(Object key, Object value) throws IOException
{    reporter.incrCounter(COUNTERS_GROUP, counterName, 1);    writer.write(key, value);}
0
public void close(Reporter reporter) throws IOException
{    writer.close(reporter);}
0
public void collect(String namedOutput, Reporter reporter, Object datum) throws IOException
{    getCollector(namedOutput, reporter).collect(datum);}
0
public void collect(String namedOutput, Reporter reporter, Schema schema, Object datum) throws IOException
{    getCollector(namedOutput, reporter, schema).collect(datum);}
0
public void collect(String namedOutput, Reporter reporter, Schema schema, Object datum, String baseOutputPath) throws IOException
{    getCollector(namedOutput, null, reporter, baseOutputPath, schema).collect(datum);}
0
public AvroCollector getCollector(String namedOutput, Reporter reporter) throws IOException
{    return getCollector(namedOutput, null, reporter, namedOutput, null);}
0
private AvroCollector getCollector(String namedOutput, Reporter reporter, Schema schema) throws IOException
{    return getCollector(namedOutput, null, reporter, namedOutput, schema);}
0
public AvroCollector getCollector(String namedOutput, String multiName, Reporter reporter) throws IOException
{    return getCollector(namedOutput, multiName, reporter, namedOutput, null);}
0
private AvroCollector getCollector(String namedOutput, Schema schema, Reporter reporter, String baseFileName) throws IOException
{        return getCollector(namedOutput, null, reporter, baseFileName, schema);}
0
private AvroCollector getCollector(String namedOutput, String multiName, Reporter reporter, String baseOutputFileName, Schema schema) throws IOException
{    checkNamedOutputName(namedOutput);    if (!namedOutputs.contains(namedOutput)) {        throw new IllegalArgumentException("Undefined named output '" + namedOutput + "'");    }    boolean multi = isMultiNamedOutput(conf, namedOutput);    if (!multi && multiName != null) {        throw new IllegalArgumentException("Name output '" + namedOutput + "' has not been defined as multi");    }    if (multi) {        checkTokenName(multiName);    }    String baseFileName = (multi) ? namedOutput + "_" + multiName : baseOutputFileName;    final RecordWriter writer = getRecordWriter(namedOutput, baseFileName, reporter, schema);    return new AvroCollector() {        @SuppressWarnings({ "unchecked" })        @Override        public void collect(Object key) throws IOException {            AvroWrapper wrapper = new AvroWrapper(key);            writer.write(wrapper, NullWritable.get());        }        public void collect(Object key, Object value) throws IOException {            writer.write(key, value);        }    };}
0
public void collect(Object key) throws IOException
{    AvroWrapper wrapper = new AvroWrapper(key);    writer.write(wrapper, NullWritable.get());}
0
public void collect(Object key, Object value) throws IOException
{    writer.write(key, value);}
0
public void close() throws IOException
{    for (RecordWriter writer : recordWriters.values()) {        writer.close(null);    }}
0
public RecordWriter<Object, Object> getRecordWriter(FileSystem fs, JobConf job, String baseFileName, Progressable arg3) throws IOException
{    String nameOutput = job.get(CONFIG_NAMED_OUTPUT, null);    String fileName = getUniqueName(job, baseFileName);    Schema schema = null;    String schemastr = job.get(MO_PREFIX + nameOutput + ".schema", null);    if (schemastr != null)        schema = Schema.parse(schemastr);    JobConf outputConf = new JobConf(job);    outputConf.setOutputFormat(getNamedOutputFormatClass(job, nameOutput));    boolean isMapOnly = job.getNumReduceTasks() == 0;    if (schema != null) {        if (isMapOnly)            AvroJob.setMapOutputSchema(outputConf, schema);        else            AvroJob.setOutputSchema(outputConf, schema);    }    OutputFormat outputFormat = outputConf.getOutputFormat();    return outputFormat.getRecordWriter(fs, outputConf, fileName, arg3);}
0
public static void setDeflateLevel(JobConf job, int level)
{    FileOutputFormat.setCompressOutput(job, true);    job.setInt(DEFLATE_LEVEL_KEY, level);}
0
public static void setSyncInterval(JobConf job, int syncIntervalInBytes)
{    job.setInt(SYNC_INTERVAL_KEY, syncIntervalInBytes);}
0
 static void configureDataFileWriter(DataFileWriter<T> writer, JobConf job) throws UnsupportedEncodingException
{    CodecFactory factory = getCodecFactory(job);    if (factory != null) {        writer.setCodec(factory);    }    writer.setSyncInterval(job.getInt(SYNC_INTERVAL_KEY, DEFAULT_SYNC_INTERVAL));        for (Map.Entry<String, String> e : job) {        if (e.getKey().startsWith(AvroJob.TEXT_PREFIX))            writer.setMeta(e.getKey().substring(AvroJob.TEXT_PREFIX.length()), e.getValue());        if (e.getKey().startsWith(AvroJob.BINARY_PREFIX))            writer.setMeta(e.getKey().substring(AvroJob.BINARY_PREFIX.length()), URLDecoder.decode(e.getValue(), StandardCharsets.ISO_8859_1.name()).getBytes(StandardCharsets.ISO_8859_1));    }}
0
 static CodecFactory getCodecFactory(JobConf job)
{    CodecFactory factory = null;    if (FileOutputFormat.getCompressOutput(job)) {        int deflateLevel = job.getInt(DEFLATE_LEVEL_KEY, DEFAULT_DEFLATE_LEVEL);        int xzLevel = job.getInt(XZ_LEVEL_KEY, DEFAULT_XZ_LEVEL);        String codecName = job.get(AvroJob.OUTPUT_CODEC);        if (codecName == null) {            String codecClassName = job.get("mapred.output.compression.codec", null);            String avroCodecName = HadoopCodecFactory.getAvroCodecName(codecClassName);            if (codecClassName != null && avroCodecName != null) {                factory = HadoopCodecFactory.fromHadoopString(codecClassName);                job.set(AvroJob.OUTPUT_CODEC, avroCodecName);                return factory;            } else {                return CodecFactory.deflateCodec(deflateLevel);            }        } else {            if (codecName.equals(DEFLATE_CODEC)) {                factory = CodecFactory.deflateCodec(deflateLevel);            } else if (codecName.equals(XZ_CODEC)) {                factory = CodecFactory.xzCodec(xzLevel);            } else {                factory = CodecFactory.fromString(codecName);            }        }    }    return factory;}
0
public RecordWriter<AvroWrapper<T>, NullWritable> getRecordWriter(FileSystem ignore, JobConf job, String name, Progressable prog) throws IOException
{    boolean isMapOnly = job.getNumReduceTasks() == 0;    Schema schema = isMapOnly ? AvroJob.getMapOutputSchema(job) : AvroJob.getOutputSchema(job);    GenericData dataModel = AvroJob.createDataModel(job);    final DataFileWriter<T> writer = new DataFileWriter<T>(dataModel.createDatumWriter(null));    configureDataFileWriter(writer, job);    Path path = FileOutputFormat.getTaskOutputPath(job, name + EXT);    writer.create(schema, path.getFileSystem(job).create(path));    return new RecordWriter<AvroWrapper<T>, NullWritable>() {        @Override        public void write(AvroWrapper<T> wrapper, NullWritable ignore) throws IOException {            writer.append(wrapper.datum());        }        @Override        public void close(Reporter reporter) throws IOException {            writer.close();        }    };}
0
public void write(AvroWrapper<T> wrapper, NullWritable ignore) throws IOException
{    writer.append(wrapper.datum());}
0
public void close(Reporter reporter) throws IOException
{    writer.close();}
0
public AvroWrapper<T> createKey()
{    return new AvroWrapper<>(null);}
0
public NullWritable createValue()
{    return NullWritable.get();}
0
public boolean next(AvroWrapper<T> wrapper, NullWritable ignore) throws IOException
{    if (!reader.hasNext() || reader.pastSync(end))        return false;    wrapper.datum(reader.next(wrapper.datum()));    return true;}
0
public float getProgress() throws IOException
{    if (end == start) {        return 0.0f;    } else {        return Math.min(1.0f, (getPos() - start) / (float) (end - start));    }}
0
public long getPos() throws IOException
{    return reader.tell();}
0
public void close() throws IOException
{    reader.close();}
0
public void reduce(K key, Iterable<V> values, AvroCollector<OUT> collector, Reporter reporter) throws IOException
{    if (outputPair == null)        outputPair = new Pair<>(AvroJob.getOutputSchema(getConf()));    for (V value : values) {        outputPair.set(key, value);        collector.collect((OUT) outputPair);    }}
0
public void close() throws IOException
{}
0
public void configure(JobConf jobConf)
{}
0
public boolean accept(Class<?> c)
{    return AvroWrapper.class.isAssignableFrom(c);}
0
public Deserializer<AvroWrapper<T>> getDeserializer(Class<AvroWrapper<T>> c)
{    Configuration conf = getConf();    boolean isKey = AvroKey.class.isAssignableFrom(c);    Schema schema = isKey ? Pair.getKeySchema(AvroJob.getMapOutputSchema(conf)) : Pair.getValueSchema(AvroJob.getMapOutputSchema(conf));    GenericData dataModel = AvroJob.createMapOutputDataModel(conf);    DatumReader<T> datumReader = dataModel.createDatumReader(schema);    return new AvroWrapperDeserializer(datumReader, isKey);}
0
public void open(InputStream in)
{    this.decoder = FACTORY.directBinaryDecoder(in, decoder);}
0
public AvroWrapper<T> deserialize(AvroWrapper<T> wrapper) throws IOException
{    T datum = reader.read(wrapper == null ? null : wrapper.datum(), decoder);    if (wrapper == null) {        wrapper = isKey ? new AvroKey<>(datum) : new AvroValue<>(datum);    } else {        wrapper.datum(datum);    }    return wrapper;}
0
public void close() throws IOException
{    decoder.inputStream().close();}
0
public Serializer<AvroWrapper<T>> getSerializer(Class<AvroWrapper<T>> c)
{        boolean isFinalOutput = c.equals(AvroWrapper.class);    Configuration conf = getConf();    Schema schema = isFinalOutput ? AvroJob.getOutputSchema(conf) : (AvroKey.class.isAssignableFrom(c) ? Pair.getKeySchema(AvroJob.getMapOutputSchema(conf)) : Pair.getValueSchema(AvroJob.getMapOutputSchema(conf)));    GenericData dataModel = AvroJob.createDataModel(conf);    return new AvroWrapperSerializer(dataModel.createDatumWriter(schema));}
0
public void open(OutputStream out)
{    this.out = out;    this.encoder = new EncoderFactory().binaryEncoder(out, null);}
0
public void serialize(AvroWrapper<T> wrapper) throws IOException
{    writer.write(wrapper.datum(), encoder);                encoder.flush();}
0
public void close() throws IOException
{    out.close();}
0
public RecordWriter<K, V> getRecordWriter(FileSystem ignore, JobConf job, String name, Progressable prog) throws IOException
{    Schema schema = Schema.create(Schema.Type.BYTES);    final byte[] keyValueSeparator = job.get("mapreduce.output.textoutputformat.separator", "\t").getBytes(StandardCharsets.UTF_8);    final DataFileWriter<ByteBuffer> writer = new DataFileWriter<>(new ReflectDatumWriter<>());    AvroOutputFormat.configureDataFileWriter(writer, job);    Path path = FileOutputFormat.getTaskOutputPath(job, name + EXT);    writer.create(schema, path.getFileSystem(job).create(path));    return new AvroTextRecordWriter(writer, keyValueSeparator);}
0
public void write(K key, V value) throws IOException
{    boolean nullKey = key == null || key instanceof NullWritable;    boolean nullValue = value == null || value instanceof NullWritable;    if (nullKey && nullValue) {        } else if (!nullKey && nullValue) {        writer.append(toByteBuffer(key));    } else if (nullKey && !nullValue) {        writer.append(toByteBuffer(value));    } else {        writer.append(toByteBuffer(key, keyValueSeparator, value));    }}
0
public void close(Reporter reporter) throws IOException
{    writer.close();}
0
private ByteBuffer toByteBuffer(Object o) throws IOException
{    if (o instanceof Text) {        Text to = (Text) o;        return ByteBuffer.wrap(to.getBytes(), 0, to.getLength());    } else {        return ByteBuffer.wrap(o.toString().getBytes(StandardCharsets.UTF_8));    }}
0
private ByteBuffer toByteBuffer(Object key, byte[] sep, Object value) throws IOException
{    byte[] keyBytes, valBytes;    int keyLength, valLength;    if (key instanceof Text) {        Text tkey = (Text) key;        keyBytes = tkey.getBytes();        keyLength = tkey.getLength();    } else {        keyBytes = key.toString().getBytes(StandardCharsets.UTF_8);        keyLength = keyBytes.length;    }    if (value instanceof Text) {        Text tval = (Text) value;        valBytes = tval.getBytes();        valLength = tval.getLength();    } else {        valBytes = value.toString().getBytes(StandardCharsets.UTF_8);        valLength = valBytes.length;    }    ByteBuffer buf = ByteBuffer.allocate(keyLength + sep.length + valLength);    buf.put(keyBytes, 0, keyLength);    buf.put(sep);    buf.put(valBytes, 0, valLength);    buf.rewind();    return buf;}
0
public void close() throws IOException
{    lineRecordReader.close();}
0
public long getPos() throws IOException
{    return lineRecordReader.getPos();}
0
public float getProgress() throws IOException
{    return lineRecordReader.getProgress();}
0
public boolean next(AvroWrapper<Utf8> key, NullWritable value) throws IOException
{    boolean success = lineRecordReader.next(currentKeyHolder, currentValueHolder);    if (success) {        key.datum(new Utf8(currentValueHolder.getBytes()).setByteLength(currentValueHolder.getLength()));    } else {        key.datum(null);    }    return success;}
0
public AvroWrapper<Utf8> createKey()
{    return new AvroWrapper<>(null);}
0
public NullWritable createValue()
{    return NullWritable.get();}
0
public void configure(JobConf conf)
{    compressionCodecs = new CompressionCodecFactory(conf);}
0
protected boolean isSplitable(FileSystem fs, Path file)
{    return compressionCodecs.getCodec(file) == null;}
0
public RecordReader<AvroWrapper<Utf8>, NullWritable> getRecordReader(InputSplit split, JobConf job, Reporter reporter) throws IOException
{    reporter.setStatus(split.toString());    return new Utf8LineRecordReader(job, (FileSplit) split);}
0
public T datum()
{    return datum;}
0
public void datum(T datum)
{    this.datum = datum;}
0
public int hashCode()
{    return (datum == null) ? 0 : datum.hashCode();}
0
public boolean equals(Object obj)
{    if (this == obj)        return true;    if (obj == null)        return false;    if (getClass() != obj.getClass())        return false;    AvroWrapper that = (AvroWrapper) obj;    if (this.datum == null) {        return that.datum == null;    } else        return datum.equals(that.datum);}
0
public String toString()
{    return datum.toString();}
0
public InputSplit[] getSplits(JobConf conf, int numSplits) throws IOException
{    JobConf confCopy = new JobConf(conf);    List<InputSplit> splits = new ArrayList<>();    Map<Path, Class<? extends AvroMapper>> mapperMap = AvroMultipleInputs.getMapperTypeMap(conf);    Map<Path, Schema> schemaMap = AvroMultipleInputs.getInputSchemaMap(conf);    Map<Schema, List<Path>> schemaPaths = new HashMap<>();        for (Entry<Path, Schema> entry : schemaMap.entrySet()) {        if (!schemaPaths.containsKey(entry.getValue())) {            schemaPaths.put(entry.getValue(), new ArrayList<>());            System.out.println(entry.getValue());            System.out.println(entry.getKey());        }        schemaPaths.get(entry.getValue()).add(entry.getKey());    }    for (Entry<Schema, List<Path>> schemaEntry : schemaPaths.entrySet()) {        Schema schema = schemaEntry.getKey();        System.out.println(schema);        InputFormat format = ReflectionUtils.newInstance(AvroInputFormat.class, conf);        List<Path> paths = schemaEntry.getValue();        Map<Class<? extends AvroMapper>, List<Path>> mapperPaths = new HashMap<>();                for (Path path : paths) {            Class<? extends AvroMapper> mapperClass = mapperMap.get(path);            if (!mapperPaths.containsKey(mapperClass)) {                mapperPaths.put(mapperClass, new ArrayList<>());            }            mapperPaths.get(mapperClass).add(path);        }                for (Entry<Class<? extends AvroMapper>, List<Path>> mapEntry : mapperPaths.entrySet()) {            paths = mapEntry.getValue();            Class<? extends AvroMapper> mapperClass = mapEntry.getKey();            if (mapperClass == null) {                mapperClass = (Class<? extends AvroMapper>) conf.getMapperClass();            }            FileInputFormat.setInputPaths(confCopy, paths.toArray(new Path[0]));                                    InputSplit[] pathSplits = format.getSplits(confCopy, numSplits);            for (InputSplit pathSplit : pathSplits) {                splits.add(new TaggedInputSplit(pathSplit, conf, format.getClass(), mapperClass, schema));            }        }    }    return splits.toArray(new InputSplit[0]);}
0
public RecordReader<K, V> getRecordReader(InputSplit split, JobConf conf, Reporter reporter) throws IOException
{            TaggedInputSplit taggedInputSplit = (TaggedInputSplit) split;    Schema schema = taggedInputSplit.getSchema();    AvroJob.setInputSchema(conf, schema);    InputFormat<K, V> inputFormat = (InputFormat<K, V>) ReflectionUtils.newInstance(taggedInputSplit.getInputFormatClass(), conf);    return inputFormat.getRecordReader(taggedInputSplit.getInputSplit(), conf, reporter);}
0
public void configure(JobConf conf)
{    this.conf = conf;    this.isMapOnly = conf.getNumReduceTasks() == 0;}
0
public void map(AvroWrapper<IN> wrapper, NullWritable value, OutputCollector<KO, VO> collector, Reporter reporter) throws IOException
{    if (mapper == null) {        TaggedInputSplit is = (TaggedInputSplit) reporter.getInputSplit();        Class<? extends AvroMapper> mapperClass = is.getMapperClass();        mapper = (AvroMapper<IN, OUT>) ReflectionUtils.newInstance(mapperClass, conf);    }    if (out == null)        out = new MapCollector<OUT, K, V, KO, VO>(collector, isMapOnly);    mapper.map(wrapper.datum(), out, reporter);}
0
public long length()
{    return len;}
0
public int read(byte[] b, int off, int len) throws IOException
{    return stream.read(b, off, len);}
0
public void seek(long p) throws IOException
{    stream.seek(p);}
0
public long tell() throws IOException
{    return stream.getPos();}
0
public void close() throws IOException
{    stream.close();}
0
protected AvroReducer<K, V, Pair<K, V>> getReducer(JobConf conf)
{    return ReflectionUtils.newInstance(conf.getClass(AvroJob.COMBINER, AvroReducer.class, AvroReducer.class), conf);}
0
public void collect(Pair<K, V> datum) throws IOException
{        keyWrapper.datum(datum.key());    valueWrapper.datum(datum.value());    collector.collect(keyWrapper, valueWrapper);}
0
protected AvroCollector<Pair<K, V>> getCollector(OutputCollector<AvroKey<K>, AvroValue<V>> collector)
{    return new PairCollector(collector);}
0
public void configure(JobConf conf)
{    this.mapper = ReflectionUtils.newInstance(conf.getClass(AvroJob.MAPPER, AvroMapper.class, AvroMapper.class), conf);    this.isMapOnly = conf.getNumReduceTasks() == 0;}
0
public void map(AvroWrapper<IN> wrapper, NullWritable value, OutputCollector<KO, VO> collector, Reporter reporter) throws IOException
{    if (this.out == null)        this.out = new MapCollector<>(collector, isMapOnly);    mapper.map(wrapper.datum(), out, reporter);}
0
public void close() throws IOException
{    this.mapper.close();}
0
protected AvroReducer<K, V, OUT> getReducer(JobConf conf)
{    return ReflectionUtils.newInstance(conf.getClass(AvroJob.REDUCER, AvroReducer.class, AvroReducer.class), conf);}
0
public void collect(OUT datum) throws IOException
{    wrapper.datum(datum);    out.collect(wrapper, NullWritable.get());}
0
protected AvroCollector<OUT> getCollector(OutputCollector<AvroWrapper<OUT>, NullWritable> collector)
{    return new ReduceCollector(collector);}
0
public void configure(JobConf conf)
{    this.reducer = getReducer(conf);}
0
public boolean hasNext()
{    return values.hasNext();}
0
public V next()
{    return values.next().datum();}
0
public void remove()
{    throw new UnsupportedOperationException();}
0
public Iterator<V> iterator()
{    return this;}
0
public final void reduce(AvroKey<K> key, Iterator<AvroValue<V>> values, OutputCollector<KO, VO> out, Reporter reporter) throws IOException
{    if (this.collector == null)        this.collector = getCollector(out);    reduceIterable.values = values;    reducer.reduce(key.datum(), reduceIterable, collector, reporter);}
0
public void close() throws IOException
{    this.reducer.close();}
0
public void collect(OUT datum) throws IOException
{    if (isMapOnly) {        wrapper.datum(datum);        collector.collect((KO) wrapper, (VO) NullWritable.get());    } else {                Pair<K, V> pair = (Pair<K, V>) datum;        keyWrapper.datum(pair.key());        valueWrapper.datum(pair.value());        collector.collect((KO) keyWrapper, (VO) valueWrapper);    }}
0
private static void checkIsPairSchema(Schema schema)
{    if (!PAIR.equals(schema.getFullName()))        throw new IllegalArgumentException("Not a Pair schema: " + schema);}
0
public static Schema getKeySchema(Schema pair)
{    checkIsPairSchema(pair);    return pair.getField(KEY).schema();}
0
public static Schema getValueSchema(Schema pair)
{    checkIsPairSchema(pair);    return pair.getField(VALUE).schema();}
0
public static Schema getPairSchema(Schema key, Schema value)
{    Map<Schema, Schema> valueSchemas;    synchronized (SCHEMA_CACHE) {        valueSchemas = SCHEMA_CACHE.computeIfAbsent(key, k -> new WeakHashMap<>());        Schema result;        result = valueSchemas.get(value);        if (result == null) {            result = makePairSchema(key, value);            valueSchemas.put(value, result);        }        return result;    }}
0
private static Schema makePairSchema(Schema key, Schema value)
{    Schema pair = Schema.createRecord(PAIR, null, null, false);    List<Field> fields = new ArrayList<>();    fields.add(new Field(KEY, key, "", null));    fields.add(new Field(VALUE, value, "", null, Field.Order.IGNORE));    pair.setFields(fields);    return pair;}
0
public Schema getSchema()
{    return schema;}
0
public K key()
{    return key;}
0
public void key(K key)
{    this.key = key;}
0
public V value()
{    return value;}
0
public void value(V value)
{    this.value = value;}
0
public void set(K key, V value)
{    this.key = key;    this.value = value;}
0
public boolean equals(Object o)
{    if (o == this)                return true;    if (!(o instanceof Pair))                return false;    Pair that = (Pair) o;    if (!this.schema.equals(that.schema))                return false;    return this.compareTo(that) == 0;}
0
public int hashCode()
{    return GenericData.get().hashCode(this, schema);}
0
public int compareTo(Pair that)
{    return GenericData.get().compare(this, that, schema);}
0
public String toString()
{    return GenericData.get().toString(this);}
0
public Object get(int i)
{    switch(i) {        case 0:            return key;        case 1:            return value;        default:            throw new org.apache.avro.AvroRuntimeException("Bad index: " + i);    }}
0
public void put(int i, Object o)
{    switch(i) {        case 0:            this.key = (K) o;            break;        case 1:            this.value = (V) o;            break;        default:            throw new org.apache.avro.AvroRuntimeException("Bad index: " + i);    }}
0
private static Schema getSchema(Object o)
{    try {        return ReflectData.get().getSchema(o.getClass());    } catch (AvroRuntimeException e) {        throw new AvroRuntimeException("Cannot infer schema for : " + o.getClass() + ".  Must create Pair with explicit key and value schemas.", e);    }}
0
public RecordReader<AvroWrapper<Pair<K, V>>, NullWritable> getRecordReader(InputSplit split, JobConf job, Reporter reporter) throws IOException
{    reporter.setStatus(split.toString());    return new SequenceFileRecordReader<>(job, (FileSplit) split);}
0
public void close() throws IOException
{    reader.close();}
0
public void remove()
{    throw new UnsupportedOperationException();}
0
public Iterator<Pair<K, V>> iterator()
{    return this;}
0
public Schema getSchema()
{    return schema;}
0
private void prepare() throws IOException
{    if (ready)        return;    this.done = !reader.next(key);    ready = true;}
0
public boolean hasNext()
{    try {        prepare();        return !done;    } catch (IOException e) {        throw new AvroRuntimeException(e);    }}
0
public Pair<K, V> next()
{    try {        return next(null);    } catch (IOException e) {        throw new AvroRuntimeException(e);    }}
0
public Pair<K, V> next(Pair<K, V> reuse) throws IOException
{    prepare();    if (!hasNext())        throw new NoSuchElementException();    Pair<K, V> result = reuse;    if (result == null)        result = new Pair<>(schema);    result.key(keyConverter.convert(key));    reader.getCurrentValue(value);    result.value(valConverter.convert(value));        Writable k = key;    key = spareKey;    spareKey = k;    ready = false;    return result;}
0
public void sync(long position) throws IOException
{    if (position > reader.getPosition())        reader.sync(position);    ready = false;}
0
public boolean pastSync(long position) throws IOException
{    return reader.getPosition() >= position && reader.syncSeen();}
0
public long tell() throws IOException
{    return reader.getPosition();}
0
public static WritableData get()
{    return INSTANCE;}
0
public Schema getSchema(java.lang.reflect.Type type)
{    if (WRITABLE_SCHEMAS.containsKey(type))        return WRITABLE_SCHEMAS.get(type);    else        return super.getSchema(type);}
0
public InputSplit getInputSplit()
{    return inputSplit;}
0
public Class<? extends InputFormat> getInputFormatClass()
{    return inputFormatClass;}
0
public Class<? extends AvroMapper> getMapperClass()
{    return mapperClass;}
0
public Schema getSchema()
{    return schema;}
0
public long getLength() throws IOException
{    return inputSplit.getLength();}
0
public String[] getLocations() throws IOException
{    return inputSplit.getLocations();}
0
public void readFields(DataInput in) throws IOException
{    inputSplitClass = (Class<? extends InputSplit>) readClass(in);    inputSplit = ReflectionUtils.newInstance(inputSplitClass, conf);    inputSplit.readFields(in);    inputFormatClass = (Class<? extends InputFormat>) readClass(in);    mapperClass = (Class<? extends AvroMapper>) readClass(in);    String schemaString = Text.readString(in);    schema = schemaParser.parse(schemaString);}
0
private Class<?> readClass(DataInput in) throws IOException
{    String className = Text.readString(in);    try {        return conf.getClassByName(className);    } catch (ClassNotFoundException e) {        throw new RuntimeException("readObject can't find class", e);    }}
0
public void write(DataOutput out) throws IOException
{    Text.writeString(out, inputSplitClass.getName());    inputSplit.write(out);    Text.writeString(out, inputFormatClass.getName());    Text.writeString(out, mapperClass.getName());    Text.writeString(out, schema.toString());}
0
public Configuration getConf()
{    return conf;}
0
public void setConf(Configuration conf)
{    this.conf = conf;}
0
public String toString()
{    return inputSplit.toString();}
0
public int count()
{    return count;}
0
public void count(int count)
{    this.count = count;}
0
public ByteBuffer buffer()
{    return buffer;}
0
public void buffer(ByteBuffer buffer)
{    this.buffer = buffer;}
0
public void close()
{    if (clientTransceiver != null)        try {            clientTransceiver.close();        } catch (IOException e) {        }        if (subprocess != null)        subprocess.destroy();    if (outputServer != null)        outputServer.close();}
0
private Process startSubprocess(JobConf job) throws IOException, InterruptedException
{        List<String> command = new ArrayList<>();    String executable = "";    if (job.getBoolean(TetherJob.TETHER_EXEC_CACHED, false)) {                Path[] localFiles = DistributedCache.getLocalCacheFiles(job);        if (localFiles == null) {                        URI[] files = DistributedCache.getCacheFiles(job);            localFiles = new Path[] { new Path(files[0].toString()) };        }        executable = localFiles[0].toString();        FileUtil.chmod(executable.toString(), "a+x");    } else {        executable = job.get(TetherJob.TETHER_EXEC);    }    command.add(executable);                            String args = job.get(TetherJob.TETHER_EXEC_ARGS);        if (args != null) {        String[] aparams = args.split("\n");        for (int i = 0; i < aparams.length; i++) {            aparams[i] = aparams[i].trim();            if (aparams[i].length() > 0) {                command.add(aparams[i]);            }        }    }    if (System.getProperty("hadoop.log.dir") == null && System.getenv("HADOOP_LOG_DIR") != null)        System.setProperty("hadoop.log.dir", System.getenv("HADOOP_LOG_DIR"));        TaskAttemptID taskid = TaskAttemptID.forName(job.get("mapred.task.id"));    File stdout = TaskLog.getTaskLogFile(taskid, false, TaskLog.LogName.STDOUT);    File stderr = TaskLog.getTaskLogFile(taskid, false, TaskLog.LogName.STDERR);    long logLength = TaskLog.getTaskLogLength(job);    command = TaskLog.captureOutAndError(null, command, stdout, stderr, logLength, false);    stdout.getParentFile().mkdirs();    stderr.getParentFile().mkdirs();        Map<String, String> env = new HashMap<>();    env.put("AVRO_TETHER_OUTPUT_PORT", Integer.toString(outputServer.getPort()));        env.put("AVRO_TETHER_PROTOCOL", job.get(TetherJob.TETHER_PROTOCOL));        String imsg = "";    for (String s : command) {        imsg = s + " ";    }                    ProcessBuilder builder = new ProcessBuilder(command);    System.out.println(command);    builder.environment().putAll(env);    return builder.start();}
1
protected FileStatus[] listStatus(JobConf job) throws IOException
{    if (job.getBoolean(AvroInputFormat.IGNORE_FILES_WITHOUT_EXTENSION_KEY, AvroInputFormat.IGNORE_INPUTS_WITHOUT_EXTENSION_DEFAULT)) {        List<FileStatus> result = new ArrayList<>();        for (FileStatus file : super.listStatus(job)) if (file.getPath().getName().endsWith(AvroOutputFormat.EXT))            result.add(file);        return result.toArray(new FileStatus[0]);    } else {        return super.listStatus(job);    }}
0
public RecordReader<TetherData, NullWritable> getRecordReader(InputSplit split, JobConf job, Reporter reporter) throws IOException
{    reporter.setStatus(split.toString());    return new TetherRecordReader(job, (FileSplit) split);}
0
public static URI getExecutable(JobConf job)
{    try {        return new URI(job.get("avro.tether.executable"));    } catch (URISyntaxException e) {        throw new RuntimeException(e);    }}
0
public static void setExecutable(JobConf job, File executable)
{    setExecutable(job, executable, new ArrayList<>(), false);}
0
public static void setExecutable(JobConf job, File executable, List<String> args, boolean cached)
{    job.set(TETHER_EXEC, executable.toString());    if (args != null) {        StringBuilder sb = new StringBuilder();        for (String a : args) {            sb.append(a);            sb.append('\n');        }        job.set(TETHER_EXEC_ARGS, sb.toString());    }    job.set(TETHER_EXEC_CACHED, (Boolean.valueOf(cached)).toString());}
0
public static TetheredProcess.Protocol getProtocol(JobConf job)
{    if (job.get(TetherJob.TETHER_PROTOCOL) == null) {        return TetheredProcess.Protocol.NONE;    } else if (job.get(TetherJob.TETHER_PROTOCOL).equals("http")) {        return TetheredProcess.Protocol.HTTP;    } else if (job.get(TetherJob.TETHER_PROTOCOL).equals("sasl")) {        return TetheredProcess.Protocol.SASL;    } else {        throw new RuntimeException("Unknown value for protocol: " + job.get(TetherJob.TETHER_PROTOCOL));    }}
0
public static RunningJob runJob(JobConf job) throws IOException
{    setupTetherJob(job);    return JobClient.runJob(job);}
0
public static RunningJob submitJob(JobConf conf) throws IOException
{    setupTetherJob(conf);    return new JobClient(conf).submitJob(conf);}
0
public static void setProtocol(JobConf job, String proto) throws IOException
{    proto = proto.trim().toLowerCase();    if (!(proto.equals("http") || proto.equals("sasl"))) {        throw new IOException("protocol must be 'http' or 'sasl'");    }    job.set(TETHER_PROTOCOL, proto);}
0
private static void setupTetherJob(JobConf job) throws IOException
{    job.setMapRunnerClass(TetherMapRunner.class);    job.setPartitionerClass(TetherPartitioner.class);    job.setReducerClass(TetherReducer.class);    job.setInputFormat(TetherInputFormat.class);    job.setOutputFormat(TetherOutputFormat.class);    job.setOutputKeyClass(TetherData.class);    job.setOutputKeyComparatorClass(TetherKeyComparator.class);    job.setMapOutputValueClass(NullWritable.class);        job.setMapOutputKeyClass(TetherData.class);        if (job.getStrings(TETHER_PROTOCOL) == null) {        job.set(TETHER_PROTOCOL, "sasl");    }        Collection<String> serializations = job.getStringCollection("io.serializations");    if (!serializations.contains(TetherKeySerialization.class.getName())) {        serializations.add(TetherKeySerialization.class.getName());        job.setStrings("io.serializations", serializations.toArray(new String[0]));    }        if (job.getBoolean(TETHER_EXEC_CACHED, false)) {        DistributedCache.addCacheFile(getExecutable(job), job);    }}
0
public void setConf(Configuration conf)
{    super.setConf(conf);    if (conf != null)        schema = AvroJob.getMapOutputSchema(conf);}
0
public int compare(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2)
{    int diff = BinaryData.compare(b1, BinaryData.skipLong(b1, s1), l1, b2, BinaryData.skipLong(b2, s2), l2, schema);    return diff == 0 ? -1 : diff;}
0
public int compare(TetherData x, TetherData y)
{    ByteBuffer b1 = x.buffer(), b2 = y.buffer();    int diff = BinaryData.compare(b1.array(), b1.position(), b2.array(), b2.position(), schema);    return diff == 0 ? -1 : diff;}
0
public boolean accept(Class<?> c)
{    return TetherData.class.isAssignableFrom(c);}
0
public Deserializer<TetherData> getDeserializer(Class<TetherData> c)
{    return new TetherDataDeserializer();}
0
public void open(InputStream in)
{    this.decoder = FACTORY.directBinaryDecoder(in, decoder);}
0
public TetherData deserialize(TetherData datum) throws IOException
{    if (datum == null)        datum = new TetherData();    datum.buffer(decoder.readBytes(datum.buffer()));    return datum;}
0
public void close() throws IOException
{    decoder.inputStream().close();}
0
public Serializer<TetherData> getSerializer(Class<TetherData> c)
{    return new TetherDataSerializer();}
0
public void open(OutputStream out)
{    this.out = out;    this.encoder = EncoderFactory.get().directBinaryEncoder(out, encoder);}
0
public void serialize(TetherData datum) throws IOException
{    encoder.writeBytes(datum.buffer());        encoder.flush();}
0
public void close() throws IOException
{    encoder.flush();    out.close();}
0
public void configure(JobConf job)
{    this.job = job;}
0
public void run(RecordReader<TetherData, NullWritable> recordReader, OutputCollector<TetherData, NullWritable> collector, Reporter reporter) throws IOException
{    try {                process = new TetheredProcess(job, collector, reporter);                        process.inputClient.configure(TaskType.MAP, job.get(AvroJob.INPUT_SCHEMA), AvroJob.getMapOutputSchema(job).toString());                process.inputClient.partitions(job.getNumReduceTasks());                Counter inputRecordCounter = reporter.getCounter("org.apache.hadoop.mapred.Task$Counter", "MAP_INPUT_RECORDS");        TetherData data = new TetherData();        while (recordReader.next(data, NullWritable.get())) {            process.inputClient.input(data.buffer(), data.count());            inputRecordCounter.increment(data.count() - 1);            if (process.outputService.isFinished())                break;        }                process.inputClient.complete();                if (process.outputService.waitForFinish())            throw new IOException("Task failed: " + process.outputService.error());    } catch (Throwable t) {                        process.inputClient.abort();        throw new IOException("Task failed: " + t, t);    } finally {                if (process != null)            process.close();    }}
1
public static void setDeflateLevel(JobConf job, int level)
{    FileOutputFormat.setCompressOutput(job, true);    job.setInt(AvroOutputFormat.DEFLATE_LEVEL_KEY, level);}
0
public RecordWriter<TetherData, NullWritable> getRecordWriter(FileSystem ignore, JobConf job, String name, Progressable prog) throws IOException
{    Schema schema = AvroJob.getOutputSchema(job);    final DataFileWriter writer = new DataFileWriter(new GenericDatumWriter());    if (FileOutputFormat.getCompressOutput(job)) {        int level = job.getInt(AvroOutputFormat.DEFLATE_LEVEL_KEY, CodecFactory.DEFAULT_DEFLATE_LEVEL);        writer.setCodec(CodecFactory.deflateCodec(level));    }    Path path = FileOutputFormat.getTaskOutputPath(job, name + AvroOutputFormat.EXT);    writer.create(schema, path.getFileSystem(job).create(path));    return new RecordWriter<TetherData, NullWritable>() {        @Override        public void write(TetherData datum, NullWritable ignore) throws IOException {            writer.appendEncoded(datum.buffer());        }        @Override        public void close(Reporter reporter) throws IOException {            writer.close();        }    };}
0
public void write(TetherData datum, NullWritable ignore) throws IOException
{    writer.appendEncoded(datum.buffer());}
0
public void close(Reporter reporter) throws IOException
{    writer.close();}
0
public synchronized void configure(int inputPort)
{        this.inputPort = inputPort;    notify();}
1
public synchronized int inputPort() throws Exception
{    if (inputPort == 0) {                wait(TIMEOUT);    }    if (inputPort == 0) {                throw new Exception("Parent process timed out waiting for subprocess to send input port");    }    return inputPort;}
1
public void output(ByteBuffer datum)
{    try {        collector.collect(new TetherData(datum), NullWritable.get());    } catch (Throwable e) {                synchronized (this) {            error = e.toString();        }    }}
1
public void outputPartitioned(int partition, ByteBuffer datum)
{    TetherPartitioner.setNextPartition(partition);    output(datum);}
0
public void status(String message)
{    reporter.setStatus(message.toString());}
0
public void count(String group, String name, long amount)
{    reporter.getCounter(group.toString(), name.toString()).increment(amount);}
0
public synchronized void fail(String message)
{        error = message;    notify();}
1
public synchronized void complete()
{        complete = true;    notify();}
1
public synchronized boolean isFinished()
{    return complete || (error != null);}
0
public String error()
{    return error;}
0
public synchronized boolean waitForFinish() throws InterruptedException
{    while (!isFinished()) wait();    return error != null;}
0
public void configure(JobConf job)
{    schema = AvroJob.getMapOutputSchema(job);}
0
 static void setNextPartition(int newValue)
{    CACHE.set(newValue);}
0
public int getPartition(TetherData key, NullWritable value, int numPartitions)
{    Integer result = CACHE.get();    if (    result != null)        return result;    ByteBuffer b = key.buffer();    int p = b.position();    int hashCode = BinaryData.hashCode(b.array(), p, b.limit() - p, schema);    if (hashCode < 0)        hashCode = -hashCode;    return hashCode % numPartitions;}
0
public Schema getSchema()
{    return reader.getSchema();}
0
public TetherData createKey()
{    return new TetherData();}
0
public NullWritable createValue()
{    return NullWritable.get();}
0
public boolean next(TetherData data, NullWritable ignore) throws IOException
{    if (!reader.hasNext() || reader.pastSync(end))        return false;    data.buffer(reader.nextBlock());    data.count((int) reader.getBlockCount());    return true;}
0
public float getProgress() throws IOException
{    if (end == start) {        return 0.0f;    } else {        return Math.min(1.0f, (in.tell() - start) / (float) (end - start));    }}
0
public long getPos() throws IOException
{    return in.tell();}
0
public void close() throws IOException
{    reader.close();}
0
public void configure(JobConf job)
{    this.job = job;}
0
public void reduce(TetherData datum, Iterator<NullWritable> ignore, OutputCollector<TetherData, NullWritable> collector, Reporter reporter) throws IOException
{    try {        if (process == null) {            process = new TetheredProcess(job, collector, reporter);            process.inputClient.configure(TaskType.REDUCE, AvroJob.getMapOutputSchema(job).toString(), AvroJob.getOutputSchema(job).toString());        }        process.inputClient.input(datum.buffer(), datum.count());    } catch (IOException e) {        error = true;        throw e;    } catch (Exception e) {        error = true;        throw new IOException(e);    }}
0
public void close() throws IOException
{    if (process == null)        return;    try {        if (error)            process.inputClient.abort();        else            process.inputClient.complete();        process.outputService.waitForFinish();    } catch (InterruptedException e) {        throw new IOException(e);    } finally {        process.close();    }}
0
public static void setInputKeySchema(Job job, Schema schema)
{    job.getConfiguration().set(CONF_INPUT_KEY_SCHEMA, schema.toString());}
0
public static void setInputValueSchema(Job job, Schema schema)
{    job.getConfiguration().set(CONF_INPUT_VALUE_SCHEMA, schema.toString());}
0
public static void setMapOutputKeySchema(Job job, Schema schema)
{    job.setMapOutputKeyClass(AvroKey.class);    job.setGroupingComparatorClass(AvroKeyComparator.class);    job.setSortComparatorClass(AvroKeyComparator.class);    AvroSerialization.setKeyWriterSchema(job.getConfiguration(), schema);    AvroSerialization.setKeyReaderSchema(job.getConfiguration(), schema);    AvroSerialization.addToConfiguration(job.getConfiguration());}
0
public static void setMapOutputValueSchema(Job job, Schema schema)
{    job.setMapOutputValueClass(AvroValue.class);    AvroSerialization.setValueWriterSchema(job.getConfiguration(), schema);    AvroSerialization.setValueReaderSchema(job.getConfiguration(), schema);    AvroSerialization.addToConfiguration(job.getConfiguration());}
0
public static void setOutputKeySchema(Job job, Schema schema)
{    job.setOutputKeyClass(AvroKey.class);    job.getConfiguration().set(CONF_OUTPUT_KEY_SCHEMA, schema.toString());}
0
public static void setOutputValueSchema(Job job, Schema schema)
{    job.setOutputValueClass(AvroValue.class);    job.getConfiguration().set(CONF_OUTPUT_VALUE_SCHEMA, schema.toString());}
0
public static void setDataModelClass(Job job, Class<? extends GenericData> modelClass)
{    AvroSerialization.setDataModelClass(job.getConfiguration(), modelClass);}
0
public static Schema getInputKeySchema(Configuration conf)
{    String schemaString = conf.get(CONF_INPUT_KEY_SCHEMA);    return schemaString != null ? new Schema.Parser().parse(schemaString) : null;}
0
public static Schema getInputValueSchema(Configuration conf)
{    String schemaString = conf.get(CONF_INPUT_VALUE_SCHEMA);    return schemaString != null ? new Schema.Parser().parse(schemaString) : null;}
0
public static Schema getMapOutputKeySchema(Configuration conf)
{    return AvroSerialization.getKeyWriterSchema(conf);}
0
public static Schema getMapOutputValueSchema(Configuration conf)
{    return AvroSerialization.getValueWriterSchema(conf);}
0
public static Schema getOutputKeySchema(Configuration conf)
{    String schemaString = conf.get(CONF_OUTPUT_KEY_SCHEMA);    return schemaString != null ? new Schema.Parser().parse(schemaString) : null;}
0
public static Schema getOutputValueSchema(Configuration conf)
{    String schemaString = conf.get(CONF_OUTPUT_VALUE_SCHEMA);    return schemaString != null ? new Schema.Parser().parse(schemaString) : null;}
0
public RecordReader<AvroKey<T>, NullWritable> createRecordReader(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException
{    Schema readerSchema = AvroJob.getInputKeySchema(context.getConfiguration());    if (null == readerSchema) {                    }    return new AvroKeyRecordReader<>(readerSchema);}
1
protected RecordWriter<AvroKey<T>, NullWritable> create(Schema writerSchema, GenericData dataModel, CodecFactory compressionCodec, OutputStream outputStream, int syncInterval) throws IOException
{    return new AvroKeyRecordWriter<>(writerSchema, dataModel, compressionCodec, outputStream, syncInterval);}
0
public RecordWriter<AvroKey<T>, NullWritable> getRecordWriter(TaskAttemptContext context) throws IOException
{    Configuration conf = context.getConfiguration();        Schema writerSchema = AvroJob.getOutputKeySchema(conf);    boolean isMapOnly = context.getNumReduceTasks() == 0;    if (isMapOnly) {        Schema mapOutputSchema = AvroJob.getMapOutputKeySchema(conf);        if (mapOutputSchema != null) {            writerSchema = mapOutputSchema;        }    }    if (null == writerSchema) {        throw new IOException("AvroKeyOutputFormat requires an output schema. Use AvroJob.setOutputKeySchema().");    }    GenericData dataModel = AvroSerialization.createDataModel(conf);    OutputStream out = getAvroFileOutputStream(context);    try {        return mRecordWriterFactory.create(writerSchema, dataModel, getCompressionCodec(context), out, getSyncInterval(context));    } catch (IOException e) {        out.close();        throw e;    }}
0
public boolean nextKeyValue() throws IOException, InterruptedException
{    boolean hasNext = super.nextKeyValue();    mCurrentRecord.datum(getCurrentRecord());    return hasNext;}
0
public AvroKey<T> getCurrentKey() throws IOException, InterruptedException
{    return mCurrentRecord;}
0
public NullWritable getCurrentValue() throws IOException, InterruptedException
{    return NullWritable.get();}
0
public void write(AvroKey<T> record, NullWritable ignore) throws IOException
{    mAvroFileWriter.append(record.datum());}
0
public void close(TaskAttemptContext context) throws IOException
{    mAvroFileWriter.close();}
0
public long sync() throws IOException
{    return mAvroFileWriter.sync();}
0
public RecordReader<AvroKey<K>, AvroValue<V>> createRecordReader(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException
{    Schema keyReaderSchema = AvroJob.getInputKeySchema(context.getConfiguration());    if (null == keyReaderSchema) {                    }    Schema valueReaderSchema = AvroJob.getInputValueSchema(context.getConfiguration());    if (null == valueReaderSchema) {                    }    return new AvroKeyValueRecordReader<>(keyReaderSchema, valueReaderSchema);}
1
public RecordWriter<K, V> getRecordWriter(TaskAttemptContext context) throws IOException
{    Configuration conf = context.getConfiguration();    AvroDatumConverterFactory converterFactory = new AvroDatumConverterFactory(conf);    AvroDatumConverter<K, ?> keyConverter = converterFactory.create((Class<K>) context.getOutputKeyClass());    AvroDatumConverter<V, ?> valueConverter = converterFactory.create((Class<V>) context.getOutputValueClass());    GenericData dataModel = AvroSerialization.createDataModel(conf);    OutputStream out = getAvroFileOutputStream(context);    try {        return new AvroKeyValueRecordWriter<>(keyConverter, valueConverter, dataModel, getCompressionCodec(context), out, getSyncInterval(context));    } catch (IOException e) {        out.close();        throw e;    }}
0
public boolean nextKeyValue() throws IOException, InterruptedException
{    boolean hasNext = super.nextKeyValue();    if (hasNext) {        AvroKeyValue<K, V> avroKeyValue = new AvroKeyValue<>(getCurrentRecord());        mCurrentKey.datum(avroKeyValue.getKey());        mCurrentValue.datum(avroKeyValue.getValue());    } else {        mCurrentKey.datum(null);        mCurrentValue.datum(null);    }    return hasNext;}
0
public AvroKey<K> getCurrentKey() throws IOException, InterruptedException
{    return mCurrentKey;}
0
public AvroValue<V> getCurrentValue() throws IOException, InterruptedException
{    return mCurrentValue;}
0
public Schema getWriterSchema()
{    return mKeyValuePairSchema;}
0
public void write(K key, V value) throws IOException
{    mOutputRecord.setKey(mKeyConverter.convert(key));    mOutputRecord.setValue(mValueConverter.convert(value));    mAvroFileWriter.append(mOutputRecord.get());}
0
public void close(TaskAttemptContext context) throws IOException
{    mAvroFileWriter.close();}
0
public long sync() throws IOException
{    return mAvroFileWriter.sync();}
0
private static void checkTokenName(String namedOutput)
{    if (namedOutput == null || namedOutput.length() == 0) {        throw new IllegalArgumentException("Name cannot be NULL or empty");    }    for (char ch : namedOutput.toCharArray()) {        if ((ch >= 'A') && (ch <= 'Z')) {            continue;        }        if ((ch >= 'a') && (ch <= 'z')) {            continue;        }        if ((ch >= '0') && (ch <= '9')) {            continue;        }        throw new IllegalArgumentException("Name cannot have a '" + ch + "' char");    }}
0
private static void checkBaseOutputPath(String outputPath)
{    if (outputPath.equals("part")) {        throw new IllegalArgumentException("output name cannot be 'part'");    }}
0
private static void checkNamedOutputName(JobContext job, String namedOutput, boolean alreadyDefined)
{    checkTokenName(namedOutput);    checkBaseOutputPath(namedOutput);    List<String> definedChannels = getNamedOutputsList(job);    if (alreadyDefined && definedChannels.contains(namedOutput)) {        throw new IllegalArgumentException("Named output '" + namedOutput + "' already alreadyDefined");    } else if (!alreadyDefined && !definedChannels.contains(namedOutput)) {        throw new IllegalArgumentException("Named output '" + namedOutput + "' not defined");    }}
0
private static List<String> getNamedOutputsList(JobContext job)
{    List<String> names = new ArrayList<>();    StringTokenizer st = new StringTokenizer(job.getConfiguration().get(MULTIPLE_OUTPUTS, ""), " ");    while (st.hasMoreTokens()) {        names.add(st.nextToken());    }    return names;}
0
private static Class<? extends OutputFormat<?, ?>> getNamedOutputFormatClass(JobContext job, String namedOutput)
{    return (Class<? extends OutputFormat<?, ?>>) job.getConfiguration().getClass(MO_PREFIX + namedOutput + FORMAT, null, OutputFormat.class);}
0
public static void addNamedOutput(Job job, String namedOutput, Class<? extends OutputFormat> outputFormatClass, Schema keySchema)
{    addNamedOutput(job, namedOutput, outputFormatClass, keySchema, null);}
0
public static void addNamedOutput(Job job, String namedOutput, Class<? extends OutputFormat> outputFormatClass, Schema keySchema, Schema valueSchema)
{    checkNamedOutputName(job, namedOutput, true);    Configuration conf = job.getConfiguration();    conf.set(MULTIPLE_OUTPUTS, conf.get(MULTIPLE_OUTPUTS, "") + " " + namedOutput);    conf.setClass(MO_PREFIX + namedOutput + FORMAT, outputFormatClass, OutputFormat.class);    conf.set(MO_PREFIX + namedOutput + ".keyschema", keySchema.toString());    if (valueSchema != null) {        conf.set(MO_PREFIX + namedOutput + ".valueschema", valueSchema.toString());    }}
0
public static void setCountersEnabled(Job job, boolean enabled)
{    job.getConfiguration().setBoolean(COUNTERS_ENABLED, enabled);}
0
public static boolean getCountersEnabled(JobContext job)
{    return job.getConfiguration().getBoolean(COUNTERS_ENABLED, false);}
0
public void write(Object key, Object value) throws IOException, InterruptedException
{    context.getCounter(COUNTERS_GROUP, counterName).increment(1);    writer.write(key, value);}
0
public void close(TaskAttemptContext context) throws IOException, InterruptedException
{    writer.close(context);}
0
public void write(String namedOutput, Object key) throws IOException, InterruptedException
{    write(namedOutput, key, NullWritable.get(), namedOutput);}
0
public void write(String namedOutput, Object key, Object value) throws IOException, InterruptedException
{    write(namedOutput, key, value, namedOutput);}
0
public void write(String namedOutput, Object key, Object value, String baseOutputPath) throws IOException, InterruptedException
{    checkNamedOutputName(context, namedOutput, false);    checkBaseOutputPath(baseOutputPath);    if (!namedOutputs.contains(namedOutput)) {        throw new IllegalArgumentException("Undefined named output '" + namedOutput + "'");    }    TaskAttemptContext taskContext = getContext(namedOutput);    getRecordWriter(taskContext, baseOutputPath).write(key, value);}
0
public void write(Object key, Object value, String baseOutputPath) throws IOException, InterruptedException
{    write(key, value, null, null, baseOutputPath);}
0
public void write(Object key, Object value, Schema keySchema, Schema valSchema, String baseOutputPath) throws IOException, InterruptedException
{    checkBaseOutputPath(baseOutputPath);    Job job = Job.getInstance(context.getConfiguration());    setSchema(job, keySchema, valSchema);    TaskAttemptContext taskContext = createTaskAttemptContext(job.getConfiguration(), context.getTaskAttemptID());    getRecordWriter(taskContext, baseOutputPath).write(key, value);}
0
public long sync(String namedOutput, String baseOutputPath) throws IOException, InterruptedException
{    checkNamedOutputName(context, namedOutput, false);    checkBaseOutputPath(baseOutputPath);    if (!namedOutputs.contains(namedOutput)) {        throw new IllegalArgumentException("Undefined named output '" + namedOutput + "'");    }    TaskAttemptContext taskContext = getContext(namedOutput);    RecordWriter recordWriter = getRecordWriter(taskContext, baseOutputPath);    long position = -1;    if (recordWriter instanceof Syncable) {        Syncable syncableWriter = (Syncable) recordWriter;        position = syncableWriter.sync();    }    return position;}
0
private synchronized RecordWriter getRecordWriter(TaskAttemptContext taskContext, String baseFileName) throws IOException, InterruptedException
{        RecordWriter writer = recordWriters.get(baseFileName);        if (writer == null) {                        taskContext.getConfiguration().set("avro.mo.config.namedOutput", baseFileName);        try {            writer = ReflectionUtils.newInstance(taskContext.getOutputFormatClass(), taskContext.getConfiguration()).getRecordWriter(taskContext);        } catch (ClassNotFoundException e) {            throw new IOException(e);        }                if (countersEnabled) {            writer = new RecordWriterWithCounter(writer, baseFileName, context);        }                recordWriters.put(baseFileName, writer);    }    return writer;}
0
private void setSchema(Job job, Schema keySchema, Schema valSchema)
{    boolean isMaponly = job.getNumReduceTasks() == 0;    if (keySchema != null) {        if (isMaponly)            AvroJob.setMapOutputKeySchema(job, keySchema);        else            AvroJob.setOutputKeySchema(job, keySchema);    }    if (valSchema != null) {        if (isMaponly)            AvroJob.setMapOutputValueSchema(job, valSchema);        else            AvroJob.setOutputValueSchema(job, valSchema);    }}
0
private TaskAttemptContext getContext(String nameOutput) throws IOException
{    TaskAttemptContext taskContext = taskContexts.get(nameOutput);    if (taskContext != null) {        return taskContext;    }            Job job = new Job(context.getConfiguration());    job.setOutputFormatClass(getNamedOutputFormatClass(context, nameOutput));    Schema keySchema = null, valSchema = null;    if (job.getConfiguration().get(MO_PREFIX + nameOutput + ".keyschema", null) != null)        keySchema = Schema.parse(job.getConfiguration().get(MO_PREFIX + nameOutput + ".keyschema"));    if (job.getConfiguration().get(MO_PREFIX + nameOutput + ".valueschema", null) != null)        valSchema = Schema.parse(job.getConfiguration().get(MO_PREFIX + nameOutput + ".valueschema"));    setSchema(job, keySchema, valSchema);    taskContext = createTaskAttemptContext(job.getConfiguration(), context.getTaskAttemptID());    taskContexts.put(nameOutput, taskContext);    return taskContext;}
0
private TaskAttemptContext createTaskAttemptContext(Configuration conf, TaskAttemptID taskId)
{        try {        Class<?> c = getTaskAttemptContextClass();        Constructor<?> cons = c.getConstructor(Configuration.class, TaskAttemptID.class);        return (TaskAttemptContext) cons.newInstance(conf, taskId);    } catch (Exception e) {        throw new IllegalStateException(e);    }}
0
private Class<?> getTaskAttemptContextClass()
{    try {        return Class.forName("org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl");    } catch (Exception e) {        try {            return Class.forName("org.apache.hadoop.mapreduce.TaskAttemptContext");        } catch (Exception ex) {            throw new IllegalStateException(ex);        }    }}
0
public void close() throws IOException, InterruptedException
{    for (RecordWriter writer : recordWriters.values()) {        writer.close(context);    }}
0
protected static CodecFactory getCompressionCodec(TaskAttemptContext context)
{    if (FileOutputFormat.getCompressOutput(context)) {                int deflateLevel = context.getConfiguration().getInt(org.apache.avro.mapred.AvroOutputFormat.DEFLATE_LEVEL_KEY, CodecFactory.DEFAULT_DEFLATE_LEVEL);        int xzLevel = context.getConfiguration().getInt(org.apache.avro.mapred.AvroOutputFormat.XZ_LEVEL_KEY, CodecFactory.DEFAULT_XZ_LEVEL);        String outputCodec = context.getConfiguration().get(AvroJob.CONF_OUTPUT_CODEC);        if (outputCodec == null) {            String compressionCodec = context.getConfiguration().get("mapred.output.compression.codec");            String avroCodecName = HadoopCodecFactory.getAvroCodecName(compressionCodec);            if (avroCodecName != null) {                context.getConfiguration().set(AvroJob.CONF_OUTPUT_CODEC, avroCodecName);                return HadoopCodecFactory.fromHadoopString(compressionCodec);            } else {                return CodecFactory.deflateCodec(deflateLevel);            }        } else if (DataFileConstants.DEFLATE_CODEC.equals(outputCodec)) {            return CodecFactory.deflateCodec(deflateLevel);        } else if (DataFileConstants.XZ_CODEC.equals(outputCodec)) {            return CodecFactory.xzCodec(xzLevel);        } else {            return CodecFactory.fromString(outputCodec);        }    }        return CodecFactory.nullCodec();}
0
protected OutputStream getAvroFileOutputStream(TaskAttemptContext context) throws IOException
{    Path path = new Path(((FileOutputCommitter) getOutputCommitter(context)).getWorkPath(), getUniqueFile(context, context.getConfiguration().get("avro.mo.config.namedOutput", "part"), org.apache.avro.mapred.AvroOutputFormat.EXT));    return path.getFileSystem(context.getConfiguration()).create(path);}
0
protected static int getSyncInterval(TaskAttemptContext context)
{    return context.getConfiguration().getInt(org.apache.avro.mapred.AvroOutputFormat.SYNC_INTERVAL_KEY, DataFileConstants.DEFAULT_SYNC_INTERVAL);}
0
public void initialize(InputSplit inputSplit, TaskAttemptContext context) throws IOException, InterruptedException
{    if (!(inputSplit instanceof FileSplit)) {        throw new IllegalArgumentException("Only compatible with FileSplits.");    }    FileSplit fileSplit = (FileSplit) inputSplit;        SeekableInput seekableFileInput = createSeekableInput(context.getConfiguration(), fileSplit.getPath());        Configuration conf = context.getConfiguration();    GenericData dataModel = AvroSerialization.createDataModel(conf);    DatumReader<T> datumReader = dataModel.createDatumReader(mReaderSchema);    mAvroFileReader = createAvroFileReader(seekableFileInput, datumReader);                                    mAvroFileReader.sync(fileSplit.getStart());            mStartPosition = mAvroFileReader.previousSync();                mEndPosition = fileSplit.getStart() + fileSplit.getLength();}
0
public boolean nextKeyValue() throws IOException, InterruptedException
{    assert null != mAvroFileReader;    if (mAvroFileReader.hasNext() && !mAvroFileReader.pastSync(mEndPosition)) {        mCurrentRecord = mAvroFileReader.next(mCurrentRecord);        return true;    }    return false;}
0
public float getProgress() throws IOException, InterruptedException
{    assert null != mAvroFileReader;    if (mEndPosition == mStartPosition) {                return 0.0f;    }    long bytesRead = mAvroFileReader.previousSync() - mStartPosition;    long bytesTotal = mEndPosition - mStartPosition;        return Math.min(1.0f, (float) bytesRead / (float) bytesTotal);}
1
public void close() throws IOException
{    if (null != mAvroFileReader) {        try {            mAvroFileReader.close();        } finally {            mAvroFileReader = null;        }    }}
0
protected T getCurrentRecord()
{    return mCurrentRecord;}
0
protected SeekableInput createSeekableInput(Configuration conf, Path path) throws IOException
{    return new FsInput(path, conf);}
0
protected DataFileReader<T> createAvroFileReader(SeekableInput input, DatumReader<T> datumReader) throws IOException
{    return new DataFileReader<>(input, datumReader);}
0
public RecordReader<K, V> createRecordReader(InputSplit inputSplit, TaskAttemptContext context) throws IOException
{    return new AvroSequenceFileRecordReader();}
0
public void initialize(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException
{    FileSplit fileSplit = (FileSplit) split;    Configuration conf = context.getConfiguration();    Path path = fileSplit.getPath();    FileSystem fs = path.getFileSystem(conf);        AvroSequenceFile.Reader.Options options = new AvroSequenceFile.Reader.Options().withFileSystem(fs).withInputPath(path).withConfiguration(conf);    Schema keySchema = AvroJob.getInputKeySchema(conf);    if (null != keySchema) {        options.withKeySchema(keySchema);    }    Schema valueSchema = AvroJob.getInputValueSchema(conf);    if (null != valueSchema) {        options.withValueSchema(valueSchema);    }    mReader = new AvroSequenceFile.Reader(options);    mEnd = fileSplit.getStart() + fileSplit.getLength();    if (fileSplit.getStart() > mReader.getPosition()) {                mReader.sync(fileSplit.getStart());    }    mStart = mReader.getPosition();    mHasMoreData = mStart < mEnd;}
0
public boolean nextKeyValue() throws IOException, InterruptedException
{    if (!mHasMoreData) {        return false;    }    long pos = mReader.getPosition();    mCurrentKey = (K) mReader.next(mCurrentKey);    if (null == mCurrentKey || (pos >= mEnd && mReader.syncSeen())) {        mHasMoreData = false;        mCurrentKey = null;        mCurrentValue = null;    } else {        mCurrentValue = (V) mReader.getCurrentValue(mCurrentValue);    }    return mHasMoreData;}
0
public K getCurrentKey()
{    return mCurrentKey;}
0
public V getCurrentValue()
{    return mCurrentValue;}
0
public float getProgress() throws IOException
{    if (mEnd == mStart) {        return 0.0f;    } else {        return Math.min(1.0f, (mReader.getPosition() - mStart) / (float) (mEnd - mStart));    }}
0
public synchronized void close() throws IOException
{    mReader.close();}
0
public RecordWriter<K, V> getRecordWriter(TaskAttemptContext context) throws IOException, InterruptedException
{    Configuration conf = context.getConfiguration();        CompressionCodec codec = null;    CompressionType compressionType = CompressionType.NONE;    if (getCompressOutput(context)) {                compressionType = getOutputCompressionType(conf);                Class<?> codecClass = getOutputCompressorClass(context, DefaultCodec.class);        codec = (CompressionCodec) ReflectionUtils.newInstance(codecClass, conf);    }        Path outputFile = getDefaultWorkFile(context, "");    FileSystem fs = outputFile.getFileSystem(conf);        AvroSequenceFile.Writer.Options options = new AvroSequenceFile.Writer.Options().withFileSystem(fs).withConfiguration(conf).withOutputPath(outputFile).withKeyClass(context.getOutputKeyClass()).withValueClass(context.getOutputValueClass()).withProgressable(context).withCompressionType(compressionType).withCompressionCodec(codec);    Schema keySchema = AvroJob.getOutputKeySchema(conf);    if (null != keySchema) {        options.withKeySchema(keySchema);    }    Schema valueSchema = AvroJob.getOutputValueSchema(conf);    if (null != valueSchema) {        options.withValueSchema(valueSchema);    }    final SequenceFile.Writer out = AvroSequenceFile.createWriter(options);    return new RecordWriter<K, V>() {        @Override        public void write(K key, V value) throws IOException {            out.append(key, value);        }        @Override        public void close(TaskAttemptContext context) throws IOException {            out.close();        }    };}
0
public void write(K key, V value) throws IOException
{    out.append(key, value);}
0
public void close(TaskAttemptContext context) throws IOException
{    out.close();}
0
public static void setOutputCompressionType(Job job, CompressionType compressionType)
{    setCompressOutput(job, true);    job.getConfiguration().set(FileOutputFormat.COMPRESS_TYPE, compressionType.name());}
0
public static CompressionType getOutputCompressionType(Configuration conf)
{    String typeName = conf.get(FileOutputFormat.COMPRESS_TYPE);    if (typeName != null) {        return CompressionType.valueOf(typeName);    }    return SequenceFile.getDefaultCompressionType(conf);}
0
public RecordReader<AvroKey<K>, AvroValue<V>> createRecordReader(InputSplit inputSplit, TaskAttemptContext taskAttemptContext) throws IOException
{    return new CombineFileRecordReader((CombineFileSplit) inputSplit, taskAttemptContext, CombineAvroKeyValueFileInputFormat.AvroKeyValueFileRecordReaderWrapper.class);}
0
public void testHadoopCodecFactoryDeflate()
{    CodecFactory hadoopDeflateCodec = HadoopCodecFactory.fromHadoopString("org.apache.hadoop.io.compress.DeflateCodec");    CodecFactory avroDeflateCodec = CodecFactory.fromString("deflate");    assertTrue(hadoopDeflateCodec.getClass().equals(avroDeflateCodec.getClass()));}
0
public void testHadoopCodecFactorySnappy()
{    CodecFactory hadoopSnappyCodec = HadoopCodecFactory.fromHadoopString("org.apache.hadoop.io.compress.SnappyCodec");    CodecFactory avroSnappyCodec = CodecFactory.fromString("snappy");    assertTrue(hadoopSnappyCodec.getClass().equals(avroSnappyCodec.getClass()));}
0
public void testHadoopCodecFactoryBZip2()
{    CodecFactory hadoopSnappyCodec = HadoopCodecFactory.fromHadoopString("org.apache.hadoop.io.compress.BZip2Codec");    CodecFactory avroSnappyCodec = CodecFactory.fromString("bzip2");    assertTrue(hadoopSnappyCodec.getClass().equals(avroSnappyCodec.getClass()));}
0
public void testHadoopCodecFactoryGZip()
{    CodecFactory hadoopSnappyCodec = HadoopCodecFactory.fromHadoopString("org.apache.hadoop.io.compress.GZipCodec");    CodecFactory avroSnappyCodec = CodecFactory.fromString("deflate");    assertTrue(hadoopSnappyCodec.getClass().equals(avroSnappyCodec.getClass()));}
0
public void testHadoopCodecFactoryFail()
{    CodecFactory hadoopSnappyCodec = HadoopCodecFactory.fromHadoopString("org.apache.hadoop.io.compress.FooCodec");    assertTrue(hadoopSnappyCodec == null);}
0
public void testWriteOutOfSortedOrder() throws IOException
{        Configuration conf = new Configuration();    SortedKeyValueFile.Writer.Options options = new SortedKeyValueFile.Writer.Options().withKeySchema(Schema.create(Schema.Type.STRING)).withValueSchema(Schema.create(Schema.Type.STRING)).withConfiguration(conf).withPath(new Path(mTempDir.getRoot().getPath(), "myfile")).withIndexInterval(    2);    try (SortedKeyValueFile.Writer<CharSequence, CharSequence> writer = new SortedKeyValueFile.Writer<>(options)) {                Utf8 key = new Utf8();        writer.append(key.set("banana"), "Banana");                writer.append(key.set("apple"), "Apple");    }}
1
public void testNamedCodecs() throws IOException
{    Configuration conf = new Configuration();    Path myfile = new Path(mTempDir.getRoot().getPath(), "myfile");    Schema key = Schema.create(Schema.Type.STRING);    Schema value = Schema.create(Schema.Type.STRING);    Schema recordSchema = AvroKeyValue.getSchema(key, value);    DatumReader<GenericRecord> datumReader = SpecificData.get().createDatumReader(recordSchema);    DataFileReader<GenericRecord> reader;    SortedKeyValueFile.Writer.Options options = new SortedKeyValueFile.Writer.Options().withKeySchema(key).withValueSchema(value).withConfiguration(conf).withPath(myfile);    SortedKeyValueFile.Writer<CharSequence, CharSequence> writer;    for (String codec : new String[] { "null", "deflate", "snappy", "bzip2" }) {                options.withCodec(codec);        writer = new SortedKeyValueFile.Writer<>(options);        writer.close();        reader = new DataFileReader<>(new FsInput(new Path(myfile, SortedKeyValueFile.DATA_FILENAME), conf), datumReader);        assertEquals(codec, reader.getMetaString("avro.codec"));        reader.close();    }}
1
public void testDeflateClassCodec() throws IOException
{    Configuration conf = new Configuration();    Path myfile = new Path(mTempDir.getRoot().getPath(), "myfile");    Schema key = Schema.create(Schema.Type.STRING);    Schema value = Schema.create(Schema.Type.STRING);    Schema recordSchema = AvroKeyValue.getSchema(key, value);    DatumReader<GenericRecord> datumReader = SpecificData.get().createDatumReader(recordSchema);    DataFileReader<GenericRecord> reader;        SortedKeyValueFile.Writer.Options options = new SortedKeyValueFile.Writer.Options().withKeySchema(key).withValueSchema(value).withConfiguration(conf).withPath(myfile).withCodec(CodecFactory.deflateCodec(9));    SortedKeyValueFile.Writer<CharSequence, CharSequence> writer = new SortedKeyValueFile.Writer<>(options);    writer.close();    reader = new DataFileReader<>(new FsInput(new Path(myfile, SortedKeyValueFile.DATA_FILENAME), conf), datumReader);    assertEquals("deflate", reader.getMetaString("avro.codec"));    reader.close();}
1
public void testBadCodec() throws IOException
{        try {        SortedKeyValueFile.Writer.Options options = new SortedKeyValueFile.Writer.Options().withCodec("foobar");    } catch (AvroRuntimeException e) {        assertEquals("Unrecognized codec: foobar", e.getMessage());    }}
1
public void testWriter() throws IOException
{        Configuration conf = new Configuration();    SortedKeyValueFile.Writer.Options options = new SortedKeyValueFile.Writer.Options().withKeySchema(Schema.create(Schema.Type.STRING)).withValueSchema(Schema.create(Schema.Type.STRING)).withConfiguration(conf).withPath(new Path(mTempDir.getRoot().getPath(), "myfile")).withIndexInterval(    2);    try (SortedKeyValueFile.Writer<CharSequence, CharSequence> writer = new SortedKeyValueFile.Writer<>(options)) {                writer.append("apple", "Apple");        writer.append("banana", "Banana");                writer.append("carrot", "Carrot");        writer.append("durian", "Durian");    }        File directory = new File(mTempDir.getRoot().getPath(), "myfile");    assertTrue(directory.exists());        File indexFile = new File(directory, SortedKeyValueFile.INDEX_FILENAME);    DatumReader<GenericRecord> indexReader = new GenericDatumReader<>(AvroKeyValue.getSchema(options.getKeySchema(), Schema.create(Schema.Type.LONG)));    List<AvroKeyValue<CharSequence, Long>> indexRecords = new ArrayList<>();    try (FileReader<GenericRecord> indexFileReader = DataFileReader.openReader(indexFile, indexReader)) {        for (GenericRecord indexRecord : indexFileReader) {            indexRecords.add(new AvroKeyValue<>(indexRecord));        }    }    assertEquals(2, indexRecords.size());    assertEquals("apple", indexRecords.get(0).getKey().toString());        assertEquals("carrot", indexRecords.get(1).getKey().toString());            File dataFile = new File(directory, SortedKeyValueFile.DATA_FILENAME);    DatumReader<GenericRecord> dataReader = new GenericDatumReader<>(AvroKeyValue.getSchema(options.getKeySchema(), options.getValueSchema()));    try (DataFileReader<GenericRecord> dataFileReader = new DataFileReader<>(dataFile, dataReader)) {        dataFileReader.seek(indexRecords.get(0).getValue());        assertTrue(dataFileReader.hasNext());        AvroKeyValue<CharSequence, CharSequence> appleRecord = new AvroKeyValue<>(dataFileReader.next());        assertEquals("apple", appleRecord.getKey().toString());        assertEquals("Apple", appleRecord.getValue().toString());        dataFileReader.seek(indexRecords.get(1).getValue());        assertTrue(dataFileReader.hasNext());        AvroKeyValue<CharSequence, CharSequence> carrotRecord = new AvroKeyValue<>(dataFileReader.next());        assertEquals("carrot", carrotRecord.getKey().toString());        assertEquals("Carrot", carrotRecord.getValue().toString());        assertTrue(dataFileReader.hasNext());        AvroKeyValue<CharSequence, CharSequence> durianRecord = new AvroKeyValue<>(dataFileReader.next());        assertEquals("durian", durianRecord.getKey().toString());        assertEquals("Durian", durianRecord.getValue().toString());    }}
1
public void testReader() throws IOException
{    Configuration conf = new Configuration();    SortedKeyValueFile.Writer.Options writerOptions = new SortedKeyValueFile.Writer.Options().withKeySchema(Schema.create(Schema.Type.STRING)).withValueSchema(Schema.create(Schema.Type.STRING)).withConfiguration(conf).withPath(new Path(mTempDir.getRoot().getPath(), "myfile")).withIndexInterval(    2);    try (SortedKeyValueFile.Writer<CharSequence, CharSequence> writer = new SortedKeyValueFile.Writer<>(writerOptions)) {                writer.append("apple", "Apple");        writer.append("banana", "Banana");                writer.append("carrot", "Carrot");        writer.append("durian", "Durian");    }        SortedKeyValueFile.Reader.Options readerOptions = new SortedKeyValueFile.Reader.Options().withKeySchema(Schema.create(Schema.Type.STRING)).withValueSchema(Schema.create(Schema.Type.STRING)).withConfiguration(conf).withPath(new Path(mTempDir.getRoot().getPath(), "myfile"));    try (SortedKeyValueFile.Reader<CharSequence, CharSequence> reader = new SortedKeyValueFile.Reader<>(readerOptions)) {        assertEquals("Carrot", reader.get("carrot").toString());        assertEquals("Banana", reader.get("banana").toString());        assertNull(reader.get("a-vegetable"));        assertNull(reader.get("beet"));        assertNull(reader.get("zzz"));    }}
1
public String toString()
{    return s;}
0
public int hashCode()
{    return s.hashCode();}
0
public boolean equals(Object that)
{    return this.s.equals(that.toString());}
0
public int compareTo(Stringy that)
{    return this.s.compareTo(that.s);}
0
public void testAlternateModel() throws Exception
{        ReflectData model = ReflectData.get();    Configuration conf = new Configuration();    SortedKeyValueFile.Writer.Options options = new SortedKeyValueFile.Writer.Options().withKeySchema(model.getSchema(Stringy.class)).withValueSchema(model.getSchema(Stringy.class)).withConfiguration(conf).withPath(new Path(mTempDir.getRoot().getPath(), "reflect")).withDataModel(model).withIndexInterval(2);    try (SortedKeyValueFile.Writer<Stringy, Stringy> writer = new SortedKeyValueFile.Writer<>(options)) {        writer.append(new Stringy("apple"), new Stringy("Apple"));        writer.append(new Stringy("banana"), new Stringy("Banana"));        writer.append(new Stringy("carrot"), new Stringy("Carrot"));        writer.append(new Stringy("durian"), new Stringy("Durian"));    }        SortedKeyValueFile.Reader.Options readerOptions = new SortedKeyValueFile.Reader.Options().withKeySchema(model.getSchema(Stringy.class)).withValueSchema(model.getSchema(Stringy.class)).withConfiguration(conf).withPath(new Path(mTempDir.getRoot().getPath(), "reflect")).withDataModel(model);    try (SortedKeyValueFile.Reader<Stringy, Stringy> reader = new SortedKeyValueFile.Reader<>(readerOptions)) {        assertEquals(new Stringy("Carrot"), reader.get(new Stringy("carrot")));        assertEquals(new Stringy("Banana"), reader.get(new Stringy("banana")));        assertNull(reader.get(new Stringy("a-vegetable")));        assertNull(reader.get(new Stringy("beet")));        assertNull(reader.get(new Stringy("zzz")));    }}
1
public void setup() throws IOException
{    mJob = Job.getInstance();    mFactory = new AvroDatumConverterFactory(mJob.getConfiguration());}
0
public void testConvertAvroKey() throws IOException
{    AvroJob.setOutputKeySchema(mJob, Schema.create(Schema.Type.STRING));    AvroKey<CharSequence> avroKey = new AvroKey<>("foo");    @SuppressWarnings("unchecked")    AvroDatumConverter<AvroKey<CharSequence>, ?> converter = mFactory.create((Class<AvroKey<CharSequence>>) avroKey.getClass());    assertEquals("foo", converter.convert(avroKey).toString());}
0
public void testConvertAvroValue() throws IOException
{    AvroJob.setOutputValueSchema(mJob, Schema.create(Schema.Type.INT));    AvroValue<Integer> avroValue = new AvroValue<>(42);    @SuppressWarnings("unchecked")    AvroDatumConverter<AvroValue<Integer>, Integer> converter = mFactory.create((Class<AvroValue<Integer>>) avroValue.getClass());    assertEquals(42, converter.convert(avroValue).intValue());}
0
public void testConvertBooleanWritable()
{    AvroDatumConverter<BooleanWritable, Boolean> converter = mFactory.create(BooleanWritable.class);    assertEquals(true, converter.convert(new BooleanWritable(true)));}
0
public void testConvertBytesWritable()
{    AvroDatumConverter<BytesWritable, ByteBuffer> converter = mFactory.create(BytesWritable.class);    ByteBuffer bytes = converter.convert(new BytesWritable(new byte[] { 1, 2, 3 }));    assertEquals(1, bytes.get(0));    assertEquals(2, bytes.get(1));    assertEquals(3, bytes.get(2));}
0
public void testConvertByteWritable()
{    AvroDatumConverter<ByteWritable, GenericFixed> converter = mFactory.create(ByteWritable.class);    assertEquals(42, converter.convert(new ByteWritable((byte) 42)).bytes()[0]);}
0
public void testConvertDoubleWritable()
{    AvroDatumConverter<DoubleWritable, Double> converter = mFactory.create(DoubleWritable.class);    assertEquals(2.0, converter.convert(new DoubleWritable(2.0)), 0.00001);}
0
public void testConvertFloatWritable()
{    AvroDatumConverter<FloatWritable, Float> converter = mFactory.create(FloatWritable.class);    assertEquals(2.2f, converter.convert(new FloatWritable(2.2f)), 0.00001);}
0
public void testConvertIntWritable()
{    AvroDatumConverter<IntWritable, Integer> converter = mFactory.create(IntWritable.class);    assertEquals(2, converter.convert(new IntWritable(2)).intValue());}
0
public void testConvertLongWritable()
{    AvroDatumConverter<LongWritable, Long> converter = mFactory.create(LongWritable.class);    assertEquals(123L, converter.convert(new LongWritable(123L)).longValue());}
0
public void testConvertNullWritable()
{    AvroDatumConverter<NullWritable, Object> converter = mFactory.create(NullWritable.class);    assertNull(converter.convert(NullWritable.get()));}
0
public void testConvertText()
{    AvroDatumConverter<Text, CharSequence> converter = mFactory.create(Text.class);    assertEquals("foo", converter.convert(new Text("foo")).toString());}
0
public void testDeserialize() throws IOException
{        Schema writerSchema = Schema.create(Schema.Type.STRING);    Schema readerSchema = Schema.create(Schema.Type.STRING);    ClassLoader classLoader = this.getClass().getClassLoader();    AvroKeyDeserializer<CharSequence> deserializer = new AvroKeyDeserializer<>(writerSchema, readerSchema, classLoader);        assertEquals(writerSchema, deserializer.getWriterSchema());    assertEquals(readerSchema, deserializer.getReaderSchema());        DatumWriter<CharSequence> datumWriter = new GenericDatumWriter<>(writerSchema);    ByteArrayOutputStream outputStream = new ByteArrayOutputStream();    Encoder encoder = EncoderFactory.get().binaryEncoder(outputStream, null);    datumWriter.write("record1", encoder);    datumWriter.write("record2", encoder);    encoder.flush();        ByteArrayInputStream inputStream = new ByteArrayInputStream(outputStream.toByteArray());    deserializer.open(inputStream);    AvroWrapper<CharSequence> record = null;    record = deserializer.deserialize(record);    assertEquals("record1", record.datum().toString());    record = deserializer.deserialize(record);    assertEquals("record2", record.datum().toString());    deserializer.close();}
0
public void testReadAvro() throws IOException
{    Path sequenceFilePath = new Path(new File(mTempDir.getRoot(), "output.seq").getPath());    writeSequenceFile(sequenceFilePath, AvroKey.class, AvroValue.class, Schema.create(Schema.Type.STRING), Schema.create(Schema.Type.INT), new AvroKey<CharSequence>("one"), new AvroValue<>(1), new AvroKey<CharSequence>("two"), new AvroValue<>(2));    Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);    AvroSequenceFile.Reader.Options options = new AvroSequenceFile.Reader.Options().withFileSystem(fs).withInputPath(sequenceFilePath).withKeySchema(Schema.create(Schema.Type.STRING)).withValueSchema(Schema.create(Schema.Type.INT)).withConfiguration(conf);    SequenceFile.Reader reader = new AvroSequenceFile.Reader(options);    AvroKey<CharSequence> key = new AvroKey<>();    AvroValue<Integer> value = new AvroValue<>();        key = (AvroKey<CharSequence>) reader.next(key);    assertNotNull(key);    assertEquals("one", key.datum().toString());    value = (AvroValue<Integer>) reader.getCurrentValue(value);    assertNotNull(value);    assertEquals(1, value.datum().intValue());        key = (AvroKey<CharSequence>) reader.next(key);    assertNotNull(key);    assertEquals("two", key.datum().toString());    value = (AvroValue<Integer>) reader.getCurrentValue(value);    assertNotNull(value);    assertEquals(2, value.datum().intValue());    assertNull("Should be no more records.", reader.next(key));}
0
public void testReadAvroWithoutReaderSchemas() throws IOException
{    Path sequenceFilePath = new Path(new File(mTempDir.getRoot(), "output.seq").getPath());    writeSequenceFile(sequenceFilePath, AvroKey.class, AvroValue.class, Schema.create(Schema.Type.STRING), Schema.create(Schema.Type.INT), new AvroKey<CharSequence>("one"), new AvroValue<>(1), new AvroKey<CharSequence>("two"), new AvroValue<>(2));    Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);    AvroSequenceFile.Reader.Options options = new AvroSequenceFile.Reader.Options().withFileSystem(fs).withInputPath(sequenceFilePath).withConfiguration(conf);    SequenceFile.Reader reader = new AvroSequenceFile.Reader(options);    AvroKey<CharSequence> key = new AvroKey<>();    AvroValue<Integer> value = new AvroValue<>();        key = (AvroKey<CharSequence>) reader.next(key);    assertNotNull(key);    assertEquals("one", key.datum().toString());    value = (AvroValue<Integer>) reader.getCurrentValue(value);    assertNotNull(value);    assertEquals(1, value.datum().intValue());        key = (AvroKey<CharSequence>) reader.next(key);    assertNotNull(key);    assertEquals("two", key.datum().toString());    value = (AvroValue<Integer>) reader.getCurrentValue(value);    assertNotNull(value);    assertEquals(2, value.datum().intValue());    assertNull("Should be no more records.", reader.next(key));}
0
public void testReadWritables() throws IOException
{    Path sequenceFilePath = new Path(new File(mTempDir.getRoot(), "output.seq").getPath());    writeSequenceFile(sequenceFilePath, Text.class, IntWritable.class, null, null, new Text("one"), new IntWritable(1), new Text("two"), new IntWritable(2));    Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);    AvroSequenceFile.Reader.Options options = new AvroSequenceFile.Reader.Options().withFileSystem(fs).withInputPath(sequenceFilePath).withConfiguration(conf);    SequenceFile.Reader reader = new AvroSequenceFile.Reader(options);    Text key = new Text();    IntWritable value = new IntWritable();        assertTrue(reader.next(key));    assertEquals("one", key.toString());    reader.getCurrentValue(value);    assertNotNull(value);    assertEquals(1, value.get());        assertTrue(reader.next(key));    assertEquals("two", key.toString());    reader.getCurrentValue(value);    assertNotNull(value);    assertEquals(2, value.get());    assertFalse("Should be no more records.", reader.next(key));}
0
private void writeSequenceFile(Path file, Class<?> keyClass, Class<?> valueClass, Schema keySchema, Schema valueSchema, Object... records) throws IOException
{        if (0 != records.length % 2) {        throw new IllegalArgumentException("Expected a value for each key record.");    }        Configuration conf = new Configuration();    FileSystem fs = FileSystem.get(conf);    AvroSequenceFile.Writer.Options options = new AvroSequenceFile.Writer.Options().withFileSystem(fs).withConfiguration(conf).withOutputPath(file);    if (null != keySchema) {        options.withKeySchema(keySchema);    } else {        options.withKeyClass(keyClass);    }    if (null != valueSchema) {        options.withValueSchema(valueSchema);    } else {        options.withValueClass(valueClass);    }    SequenceFile.Writer writer = new AvroSequenceFile.Writer(options);        for (int i = 0; i < records.length; i += 2) {        writer.append(records[i], records[i + 1]);    }        writer.close();}
0
public void testAccept()
{    AvroSerialization<CharSequence> serialization = new AvroSerialization<>();    assertTrue(serialization.accept(AvroKey.class));    assertTrue(serialization.accept(AvroValue.class));    assertFalse(serialization.accept(AvroWrapper.class));    assertFalse(serialization.accept(String.class));}
0
public void testGetSerializerForKey() throws IOException
{        Schema writerSchema = Schema.create(Schema.Type.STRING);    Job job = Job.getInstance();    AvroJob.setMapOutputKeySchema(job, writerSchema);        AvroSerialization serialization = ReflectionUtils.newInstance(AvroSerialization.class, job.getConfiguration());    @SuppressWarnings("unchecked")    Serializer<AvroWrapper> serializer = serialization.getSerializer(AvroKey.class);    assertTrue(serializer instanceof AvroSerializer);    AvroSerializer avroSerializer = (AvroSerializer) serializer;        assertEquals(writerSchema, avroSerializer.getWriterSchema());}
0
public void testGetSerializerForValue() throws IOException
{        Schema writerSchema = Schema.create(Schema.Type.STRING);    Job job = Job.getInstance();    AvroJob.setMapOutputValueSchema(job, writerSchema);        AvroSerialization serialization = ReflectionUtils.newInstance(AvroSerialization.class, job.getConfiguration());    @SuppressWarnings("unchecked")    Serializer<AvroWrapper> serializer = serialization.getSerializer(AvroValue.class);    assertTrue(serializer instanceof AvroSerializer);    AvroSerializer avroSerializer = (AvroSerializer) serializer;        assertEquals(writerSchema, avroSerializer.getWriterSchema());}
0
public void testGetDeserializerForKey() throws IOException
{        Schema readerSchema = Schema.create(Schema.Type.STRING);    Job job = Job.getInstance();    AvroJob.setMapOutputKeySchema(job, readerSchema);        AvroSerialization serialization = ReflectionUtils.newInstance(AvroSerialization.class, job.getConfiguration());    @SuppressWarnings("unchecked")    Deserializer<AvroWrapper> deserializer = serialization.getDeserializer(AvroKey.class);    assertTrue(deserializer instanceof AvroKeyDeserializer);    AvroKeyDeserializer avroDeserializer = (AvroKeyDeserializer) deserializer;        assertEquals(readerSchema, avroDeserializer.getReaderSchema());}
0
public void testGetDeserializerForValue() throws IOException
{        Schema readerSchema = Schema.create(Schema.Type.STRING);    Job job = Job.getInstance();    AvroJob.setMapOutputValueSchema(job, readerSchema);        AvroSerialization serialization = ReflectionUtils.newInstance(AvroSerialization.class, job.getConfiguration());    @SuppressWarnings("unchecked")    Deserializer<AvroWrapper> deserializer = serialization.getDeserializer(AvroValue.class);    assertTrue(deserializer instanceof AvroValueDeserializer);    AvroValueDeserializer avroDeserializer = (AvroValueDeserializer) deserializer;        assertEquals(readerSchema, avroDeserializer.getReaderSchema());}
0
public void testClassPath() throws Exception
{    Configuration conf = new Configuration();    ClassLoader loader = conf.getClass().getClassLoader();    AvroSerialization serialization = new AvroSerialization();    serialization.setConf(conf);    AvroDeserializer des = (AvroDeserializer) serialization.getDeserializer(AvroKey.class);    ReflectData data = (ReflectData) ((ReflectDatumReader) des.mAvroDatumReader).getData();    Assert.assertEquals(loader, data.getClassLoader());}
0
private O roundTrip(Schema schema, T data, Class<? extends GenericData> modelClass) throws IOException
{    Job job = Job.getInstance();    AvroJob.setMapOutputKeySchema(job, schema);    if (modelClass != null)        AvroJob.setDataModelClass(job, modelClass);    AvroSerialization serialization = ReflectionUtils.newInstance(AvroSerialization.class, job.getConfiguration());    Serializer<AvroKey<T>> serializer = serialization.getSerializer(AvroKey.class);    Deserializer<AvroKey<O>> deserializer = serialization.getDeserializer(AvroKey.class);    ByteArrayOutputStream baos = new ByteArrayOutputStream();    serializer.open(baos);    serializer.serialize(new AvroKey<>(data));    serializer.close();    ByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray());    deserializer.open(bais);    AvroKey<O> result = null;    result = deserializer.deserialize(result);    deserializer.close();    return result.datum();}
0
public void testRoundTrip() throws Exception
{    Schema schema = Schema.create(Schema.Type.STRING);    assertTrue(roundTrip(schema, "record", null) instanceof String);    assertTrue(roundTrip(schema, "record", GenericData.class) instanceof Utf8);}
0
public void testSerialize() throws IOException
{        Schema writerSchema = Schema.create(Schema.Type.STRING);    AvroSerializer<CharSequence> serializer = new AvroSerializer<>(writerSchema);        assertEquals(writerSchema, serializer.getWriterSchema());        ByteArrayOutputStream outputStream = new ByteArrayOutputStream();    serializer.open(outputStream);    serializer.serialize(new AvroKey<>("record1"));    serializer.serialize(new AvroKey<>("record2"));    serializer.close();        ByteArrayInputStream inputStream = new ByteArrayInputStream(outputStream.toByteArray());    Schema readerSchema = Schema.create(Schema.Type.STRING);    DatumReader<CharSequence> datumReader = new GenericDatumReader<>(readerSchema);    Decoder decoder = DecoderFactory.get().binaryDecoder(inputStream, null);    CharSequence record = null;    record = datumReader.read(record, decoder);    assertEquals("record1", record.toString());    record = datumReader.read(record, decoder);    assertEquals("record2", record.toString());    inputStream.close();}
0
public void testDeserialize() throws IOException
{        Schema writerSchema = Schema.create(Schema.Type.STRING);    Schema readerSchema = Schema.create(Schema.Type.STRING);    ClassLoader classLoader = this.getClass().getClassLoader();    AvroValueDeserializer<CharSequence> deserializer = new AvroValueDeserializer<>(writerSchema, readerSchema, classLoader);        assertEquals(writerSchema, deserializer.getWriterSchema());    assertEquals(readerSchema, deserializer.getReaderSchema());        DatumWriter<CharSequence> datumWriter = new GenericDatumWriter<>(writerSchema);    ByteArrayOutputStream outputStream = new ByteArrayOutputStream();    Encoder encoder = EncoderFactory.get().binaryEncoder(outputStream, null);    datumWriter.write("record1", encoder);    datumWriter.write("record2", encoder);    encoder.flush();        ByteArrayInputStream inputStream = new ByteArrayInputStream(outputStream.toByteArray());    deserializer.open(inputStream);    AvroWrapper<CharSequence> record = null;    record = deserializer.deserialize(record);    assertEquals("record1", record.datum().toString());    record = deserializer.deserialize(record);    assertEquals("record2", record.datum().toString());    deserializer.close();}
0
public void setup()
{    mComparator = new AvroCharSequenceComparator<>();}
0
public void testCompareString()
{    assertEquals(0, mComparator.compare("", ""));    assertThat(mComparator.compare("", "a"), lessThan(0));    assertThat(mComparator.compare("a", ""), greaterThan(0));    assertEquals(0, mComparator.compare("a", "a"));    assertThat(mComparator.compare("a", "b"), lessThan(0));    assertThat(mComparator.compare("b", "a"), greaterThan(0));    assertEquals(0, mComparator.compare("ab", "ab"));    assertThat(mComparator.compare("a", "aa"), lessThan(0));    assertThat(mComparator.compare("aa", "a"), greaterThan(0));    assertThat(mComparator.compare("abc", "abcdef"), lessThan(0));    assertThat(mComparator.compare("abcdef", "abc"), greaterThan(0));}
0
public void testCompareUtf8()
{    assertEquals(0, mComparator.compare(new Utf8(""), new Utf8("")));    assertThat(mComparator.compare(new Utf8(""), new Utf8("a")), lessThan(0));    assertThat(mComparator.compare(new Utf8("a"), new Utf8("")), greaterThan(0));    assertEquals(0, mComparator.compare(new Utf8("a"), new Utf8("a")));    assertThat(mComparator.compare(new Utf8("a"), new Utf8("b")), lessThan(0));    assertThat(mComparator.compare(new Utf8("b"), new Utf8("a")), greaterThan(0));    assertEquals(0, mComparator.compare(new Utf8("ab"), new Utf8("ab")));    assertThat(mComparator.compare(new Utf8("a"), new Utf8("aa")), lessThan(0));    assertThat(mComparator.compare(new Utf8("aa"), new Utf8("a")), greaterThan(0));    assertThat(mComparator.compare(new Utf8("abc"), new Utf8("abcdef")), lessThan(0));    assertThat(mComparator.compare(new Utf8("abcdef"), new Utf8("abc")), greaterThan(0));}
0
public void testCompareUtf8ToString()
{    assertEquals(0, mComparator.compare(new Utf8(""), ""));    assertThat(mComparator.compare(new Utf8(""), "a"), lessThan(0));    assertThat(mComparator.compare(new Utf8("a"), ""), greaterThan(0));    assertEquals(0, mComparator.compare(new Utf8("a"), "a"));    assertThat(mComparator.compare(new Utf8("a"), "b"), lessThan(0));    assertThat(mComparator.compare(new Utf8("b"), "a"), greaterThan(0));    assertEquals(0, mComparator.compare(new Utf8("ab"), "ab"));    assertThat(mComparator.compare(new Utf8("a"), "aa"), lessThan(0));    assertThat(mComparator.compare(new Utf8("aa"), "a"), greaterThan(0));    assertThat(mComparator.compare(new Utf8("abc"), "abcdef"), lessThan(0));    assertThat(mComparator.compare(new Utf8("abcdef"), "abc"), greaterThan(0));}
0
public void setUp() throws Exception
{    conf = new JobConf();    fs = FileSystem.getLocal(conf);    inputDir = new Path(DIR.getRoot().getPath());}
0
public void tearDown() throws Exception
{    fs.delete(inputDir, true);}
0
public void testIgnoreFilesWithoutExtension() throws Exception
{    fs.mkdirs(inputDir);    Path avroFile = new Path(inputDir, "somefile.avro");    Path textFile = new Path(inputDir, "someotherfile.txt");    fs.create(avroFile).close();    fs.create(textFile).close();    FileInputFormat.setInputPaths(conf, inputDir);    AvroInputFormat inputFormat = new AvroInputFormat();    FileStatus[] statuses = inputFormat.listStatus(conf);    assertEquals(1, statuses.length);    assertEquals("somefile.avro", statuses[0].getPath().getName());    conf.setBoolean(AvroInputFormat.IGNORE_FILES_WITHOUT_EXTENSION_KEY, false);    statuses = inputFormat.listStatus(conf);    assertEquals(2, statuses.length);    Set<String> names = new HashSet<>();    names.add(statuses[0].getPath().getName());    names.add(statuses[1].getPath().getName());    assertTrue(names.contains("somefile.avro"));    assertTrue(names.contains("someotherfile.txt"));}
0
public String toString()
{    return id + "\t" + name;}
0
public String toString()
{    return id + "\t" + balance;}
0
public String toString()
{    return ((Integer) id).toString();}
0
public String toString()
{    return recType.toString();}
0
 void setId(int id)
{    this.id = id;}
0
 void setName(CharSequence name)
{    this.name = name;}
0
 void setBalance(long balance)
{    this.balance = balance;}
0
public String toString()
{    return id + "\t" + name + "\t" + balance;}
0
public void map(NamesRecord nameRecord, AvroCollector<Pair<KeyRecord, JoinableRecord>> collector, Reporter reporter) throws IOException
{    collector.collect(new Pair<>(new KeyRecord(nameRecord.id), new JoinableRecord(nameRecord.getClass().getName(), nameRecord.id, nameRecord.name, -1L)));}
0
public void map(BalancesRecord balanceRecord, AvroCollector<Pair<KeyRecord, JoinableRecord>> collector, Reporter reporter) throws IOException
{    collector.collect(new Pair<>(new KeyRecord(balanceRecord.id), new JoinableRecord(balanceRecord.getClass().getName(), balanceRecord.id, "", balanceRecord.balance)));}
0
public void reduce(KeyRecord ID, Iterable<JoinableRecord> joinables, AvroCollector<CompleteRecord> collector, Reporter reporter) throws IOException
{    CompleteRecord rec = new CompleteRecord();    for (JoinableRecord joinable : joinables) {        rec.setId(joinable.id);        if (joinable.recType.toString().contains("NamesRecord")) {            rec.setName(joinable.name);        } else {            rec.setBalance(joinable.balance);        }    }    collector.collect(rec);}
0
public void testJob() throws Exception
{    JobConf job = new JobConf();    Path inputPath1 = new Path(INPUT_DIR_1.getRoot().getPath());    Path inputPath2 = new Path(INPUT_DIR_2.getRoot().getPath());    Path outputPath = new Path(OUTPUT_DIR.getRoot().getPath());    outputPath.getFileSystem(job).delete(outputPath, true);    writeNamesFiles(new File(inputPath1.toUri().getPath()));    writeBalancesFiles(new File(inputPath2.toUri().getPath()));    job.setJobName("multiple-inputs-join");    AvroMultipleInputs.addInputPath(job, inputPath1, NamesMapImpl.class, ReflectData.get().getSchema(NamesRecord.class));    AvroMultipleInputs.addInputPath(job, inputPath2, BalancesMapImpl.class, ReflectData.get().getSchema(BalancesRecord.class));    Schema keySchema = ReflectData.get().getSchema(KeyRecord.class);    Schema valueSchema = ReflectData.get().getSchema(JoinableRecord.class);    AvroJob.setMapOutputSchema(job, Pair.getPairSchema(keySchema, valueSchema));    AvroJob.setOutputSchema(job, ReflectData.get().getSchema(CompleteRecord.class));    AvroJob.setReducerClass(job, ReduceImpl.class);    job.setNumReduceTasks(1);    FileOutputFormat.setOutputPath(job, outputPath);    AvroJob.setReflect(job);    JobClient.runJob(job);    validateCompleteFile(new File(OUTPUT_DIR.getRoot(), "part-00000.avro"));}
0
private void writeNamesFiles(File dir) throws IOException
{    DatumWriter<NamesRecord> writer = new ReflectDatumWriter<>();    File namesFile = new File(dir + "/names.avro");    try (DataFileWriter<NamesRecord> out = new DataFileWriter<>(writer)) {        out.create(ReflectData.get().getSchema(NamesRecord.class), namesFile);        for (int i = 0; i < 5; i++) {            out.append(new NamesRecord(i, "record" + i));        }    }}
0
private void writeBalancesFiles(File dir) throws IOException
{    DatumWriter<BalancesRecord> writer = new ReflectDatumWriter<>();    File namesFile = new File(dir + "/balances.avro");    try (DataFileWriter<BalancesRecord> out = new DataFileWriter<>(writer)) {        out.create(ReflectData.get().getSchema(BalancesRecord.class), namesFile);        for (int i = 0; i < 5; i++) {            out.append(new BalancesRecord(i, (long) i + 100));        }    }}
0
private void validateCompleteFile(File file) throws Exception
{    DatumReader<CompleteRecord> reader = new ReflectDatumReader<>();    int numRecs = 0;    try (InputStream in = new BufferedInputStream(new FileInputStream(file))) {        try (DataFileStream<CompleteRecord> records = new DataFileStream<>(in, reader)) {            for (CompleteRecord rec : records) {                assertEquals(rec.id, numRecs);                assertEquals(rec.balance - 100, rec.id);                assertEquals(rec.name, "record" + rec.id);                numRecs++;            }        }    }    assertEquals(5, numRecs);}
0
public void configure(JobConf Job)
{    this.amos = new AvroMultipleOutputs(Job);}
0
public void map(Utf8 text, AvroCollector<Pair<Utf8, Long>> collector, Reporter reporter) throws IOException
{    StringTokenizer tokens = new StringTokenizer(text.toString());    while (tokens.hasMoreTokens()) {        String tok = tokens.nextToken();        collector.collect(new Pair<>(new Utf8(tok), 1L));        amos.getCollector("myavro2", reporter).collect(new Pair<Utf8, Long>(new Utf8(tok), 1L).toString());    }}
0
public void close() throws IOException
{    amos.close();}
0
public void configure(JobConf Job)
{    amos = new AvroMultipleOutputs(Job);}
0
public void reduce(Utf8 word, Iterable<Long> counts, AvroCollector<Pair<Utf8, Long>> collector, Reporter reporter) throws IOException
{    long sum = 0;    for (long count : counts) sum += count;    Pair<Utf8, Long> outputvalue = new Pair<>(word, sum);    amos.getCollector("myavro", reporter).collect(outputvalue);    amos.collect("myavro1", reporter, outputvalue.toString());    amos.collect("myavro", reporter, new Pair<Utf8, Long>(new Utf8(""), 0L).getSchema(), outputvalue, "testavrofile");    amos.collect("myavro", reporter, Schema.create(Schema.Type.STRING), outputvalue.toString(), "testavrofile1");    collector.collect(new Pair<>(word, sum));}
0
public void close() throws IOException
{    amos.close();}
0
public void runTestsInOrder() throws Exception
{    String avroPath = OUTPUT_DIR.getRoot().getPath();    testJob(avroPath);    testProjection(avroPath);    testProjectionNewMethodsOne(avroPath);    testProjectionNewMethodsTwo(avroPath);    testProjection1(avroPath);    testJobNoreducer();    testProjectionNoreducer(avroPath);}
0
public void testJob(String pathOut) throws Exception
{    JobConf job = new JobConf();    String pathIn = INPUT_DIR.getRoot().getPath();    File fileIn = new File(pathIn, "lines.avro");    Path outputPath = new Path(pathOut);    outputPath.getFileSystem(job).delete(outputPath);    WordCountUtil.writeLinesFile(fileIn);    job.setJobName("AvroMultipleOutputs");    AvroJob.setInputSchema(job, Schema.create(Schema.Type.STRING));    AvroJob.setOutputSchema(job, new Pair<Utf8, Long>(new Utf8(""), 0L).getSchema());    AvroJob.setMapperClass(job, MapImpl.class);    AvroJob.setReducerClass(job, ReduceImpl.class);    FileInputFormat.setInputPaths(job, pathIn);    FileOutputFormat.setOutputPath(job, outputPath);    FileOutputFormat.setCompressOutput(job, false);    AvroMultipleOutputs.addNamedOutput(job, "myavro", AvroOutputFormat.class, new Pair<Utf8, Long>(new Utf8(""), 0L).getSchema());    AvroMultipleOutputs.addNamedOutput(job, "myavro1", AvroOutputFormat.class, Schema.create(Schema.Type.STRING));    AvroMultipleOutputs.addNamedOutput(job, "myavro2", AvroOutputFormat.class, Schema.create(Schema.Type.STRING));    WordCountUtil.setMeta(job);    JobClient.runJob(job);    WordCountUtil.validateCountsFile(new File(outputPath.toString(), "/part-00000.avro"));}
0
public void testProjection(String inputDirectory) throws Exception
{    JobConf job = new JobConf();    Integer defaultRank = -1;    String jsonSchema = "{\"type\":\"record\"," + "\"name\":\"org.apache.avro.mapred.Pair\"," + "\"fields\": [ " + "{\"name\":\"rank\", \"type\":\"int\", \"default\": -1}," + "{\"name\":\"value\", \"type\":\"long\"}" + "]}";    Schema readerSchema = Schema.parse(jsonSchema);    AvroJob.setInputSchema(job, readerSchema);    Path inputPath = new Path(inputDirectory + "/myavro-r-00000.avro");    FileStatus fileStatus = FileSystem.get(job).getFileStatus(inputPath);    FileSplit fileSplit = new FileSplit(inputPath, 0, fileStatus.getLen(), job);    AvroRecordReader<Pair<Integer, Long>> recordReader = new AvroRecordReader<>(job, fileSplit);    AvroWrapper<Pair<Integer, Long>> inputPair = new AvroWrapper<>(null);    NullWritable ignore = NullWritable.get();    long sumOfCounts = 0;    long numOfCounts = 0;    while (recordReader.next(inputPair, ignore)) {        Assert.assertEquals(inputPair.datum().get(0), defaultRank);        sumOfCounts += (Long) inputPair.datum().get(1);        numOfCounts++;    }    Assert.assertEquals(numOfCounts, WordCountUtil.COUNTS.size());    long actualSumOfCounts = 0;    for (Long count : WordCountUtil.COUNTS.values()) {        actualSumOfCounts += count;    }    Assert.assertEquals(sumOfCounts, actualSumOfCounts);}
0
public void testProjectionNewMethodsOne(String inputDirectory) throws Exception
{    JobConf job = new JobConf();    Integer defaultRank = -1;    String jsonSchema = "{\"type\":\"record\"," + "\"name\":\"org.apache.avro.mapred.Pair\"," + "\"fields\": [ " + "{\"name\":\"rank\", \"type\":\"int\", \"default\": -1}," + "{\"name\":\"value\", \"type\":\"long\"}" + "]}";    Schema readerSchema = Schema.parse(jsonSchema);    AvroJob.setInputSchema(job, readerSchema);    Path inputPath = new Path(inputDirectory + "/testavrofile-r-00000.avro");    FileStatus fileStatus = FileSystem.get(job).getFileStatus(inputPath);    FileSplit fileSplit = new FileSplit(inputPath, 0, fileStatus.getLen(), job);    AvroRecordReader<Pair<Integer, Long>> recordReader = new AvroRecordReader<>(job, fileSplit);    AvroWrapper<Pair<Integer, Long>> inputPair = new AvroWrapper<>(null);    NullWritable ignore = NullWritable.get();    long sumOfCounts = 0;    long numOfCounts = 0;    while (recordReader.next(inputPair, ignore)) {        Assert.assertEquals(inputPair.datum().get(0), defaultRank);        sumOfCounts += (Long) inputPair.datum().get(1);        numOfCounts++;    }    Assert.assertEquals(numOfCounts, WordCountUtil.COUNTS.size());    long actualSumOfCounts = 0;    for (Long count : WordCountUtil.COUNTS.values()) {        actualSumOfCounts += count;    }    Assert.assertEquals(sumOfCounts, actualSumOfCounts);}
0
public void testProjection1(String inputDirectory) throws Exception
{    JobConf job = new JobConf();    Schema readerSchema = Schema.create(Schema.Type.STRING);    AvroJob.setInputSchema(job, readerSchema);    Path inputPath = new Path(inputDirectory + "/myavro1-r-00000.avro");    FileStatus fileStatus = FileSystem.get(job).getFileStatus(inputPath);    FileSplit fileSplit = new FileSplit(inputPath, 0, fileStatus.getLen(), job);    AvroWrapper<Utf8> inputPair = new AvroWrapper<>(null);    NullWritable ignore = NullWritable.get();    AvroRecordReader<Utf8> recordReader = new AvroRecordReader<>(job, fileSplit);    long sumOfCounts = 0;    long numOfCounts = 0;    while (recordReader.next(inputPair, ignore)) {        sumOfCounts += Long.parseLong(inputPair.datum().toString().split(":")[2].replace("}", "").trim());        numOfCounts++;    }    Assert.assertEquals(numOfCounts, WordCountUtil.COUNTS.size());    long actualSumOfCounts = 0;    for (Long count : WordCountUtil.COUNTS.values()) {        actualSumOfCounts += count;    }    Assert.assertEquals(sumOfCounts, actualSumOfCounts);}
0
public void testProjectionNewMethodsTwo(String inputDirectory) throws Exception
{    JobConf job = new JobConf();    Schema readerSchema = Schema.create(Schema.Type.STRING);    AvroJob.setInputSchema(job, readerSchema);    Path inputPath = new Path(inputDirectory + "/testavrofile1-r-00000.avro");    FileStatus fileStatus = FileSystem.get(job).getFileStatus(inputPath);    FileSplit fileSplit = new FileSplit(inputPath, 0, fileStatus.getLen(), job);    AvroWrapper<Utf8> inputPair = new AvroWrapper<>(null);    NullWritable ignore = NullWritable.get();    AvroRecordReader<Utf8> recordReader = new AvroRecordReader<>(job, fileSplit);    long sumOfCounts = 0;    long numOfCounts = 0;    while (recordReader.next(inputPair, ignore)) {        sumOfCounts += Long.parseLong(inputPair.datum().toString().split(":")[2].replace("}", "").trim());        numOfCounts++;    }    Assert.assertEquals(numOfCounts, WordCountUtil.COUNTS.size());    long actualSumOfCounts = 0;    for (Long count : WordCountUtil.COUNTS.values()) {        actualSumOfCounts += count;    }    Assert.assertEquals(sumOfCounts, actualSumOfCounts);}
0
public void testJobNoreducer() throws Exception
{    JobConf job = new JobConf();    job.setNumReduceTasks(0);    Path outputPath = new Path(OUTPUT_DIR.getRoot().getPath());    outputPath.getFileSystem(job).delete(outputPath);    WordCountUtil.writeLinesFile(new File(INPUT_DIR.getRoot(), "lines.avro"));    job.setJobName("AvroMultipleOutputs_noreducer");    AvroJob.setInputSchema(job, Schema.create(Schema.Type.STRING));    AvroJob.setOutputSchema(job, new Pair<Utf8, Long>(new Utf8(""), 0L).getSchema());    AvroJob.setMapperClass(job, MapImpl.class);    FileInputFormat.setInputPaths(job, new Path(INPUT_DIR.getRoot().toString()));    FileOutputFormat.setOutputPath(job, outputPath);    FileOutputFormat.setCompressOutput(job, false);    AvroMultipleOutputs.addNamedOutput(job, "myavro2", AvroOutputFormat.class, Schema.create(Schema.Type.STRING));    JobClient.runJob(job);}
0
public void testProjectionNoreducer(String inputDirectory) throws Exception
{    JobConf job = new JobConf();    long onel = 1;    Schema readerSchema = Schema.create(Schema.Type.STRING);    AvroJob.setInputSchema(job, readerSchema);    Path inputPath = new Path(inputDirectory + "/myavro2-m-00000.avro");    FileStatus fileStatus = FileSystem.get(job).getFileStatus(inputPath);    FileSplit fileSplit = new FileSplit(inputPath, 0, fileStatus.getLen(), (String[]) null);    AvroRecordReader<Utf8> recordReader = new AvroRecordReader<>(job, fileSplit);    AvroWrapper<Utf8> inputPair = new AvroWrapper<>(null);    NullWritable ignore = NullWritable.get();    while (recordReader.next(inputPair, ignore)) {        long testl = Long.parseLong(inputPair.datum().toString().split(":")[2].replace("}", "").trim());        Assert.assertEquals(onel, testl);    }}
0
public void testSetSyncInterval()
{    JobConf jobConf = new JobConf();    int newSyncInterval = 100000;    AvroOutputFormat.setSyncInterval(jobConf, newSyncInterval);    assertEquals(newSyncInterval, jobConf.getInt(AvroOutputFormat.SYNC_INTERVAL_KEY, -1));}
0
public void testNoCodec()
{    JobConf job = new JobConf();    assertNull(AvroOutputFormat.getCodecFactory(job));    job = new JobConf();    job.set("mapred.output.compress", "false");    job.set("mapred.output.compression.codec", "org.apache.hadoop.io.compress.BZip2Codec");    assertNull(AvroOutputFormat.getCodecFactory(job));    job = new JobConf();    job.set("mapred.output.compress", "false");    job.set(AvroJob.OUTPUT_CODEC, "bzip2");    assertNull(AvroOutputFormat.getCodecFactory(job));}
0
public void testBZip2CodecUsingHadoopClass()
{    CodecFactory avroBZip2Codec = CodecFactory.fromString("bzip2");    JobConf job = new JobConf();    job.set("mapred.output.compress", "true");    job.set("mapred.output.compression.codec", "org.apache.hadoop.io.compress.BZip2Codec");    CodecFactory factory = AvroOutputFormat.getCodecFactory(job);    assertNotNull(factory);    assertEquals(factory.getClass(), avroBZip2Codec.getClass());}
0
public void testBZip2CodecUsingAvroCodec()
{    CodecFactory avroBZip2Codec = CodecFactory.fromString("bzip2");    JobConf job = new JobConf();    job.set("mapred.output.compress", "true");    job.set(AvroJob.OUTPUT_CODEC, "bzip2");    CodecFactory factory = AvroOutputFormat.getCodecFactory(job);    assertNotNull(factory);    assertEquals(factory.getClass(), avroBZip2Codec.getClass());}
0
public void testDeflateCodecUsingHadoopClass()
{    CodecFactory avroDeflateCodec = CodecFactory.fromString("deflate");    JobConf job = new JobConf();    job.set("mapred.output.compress", "true");    job.set("mapred.output.compression.codec", "org.apache.hadoop.io.compress.DeflateCodec");    CodecFactory factory = AvroOutputFormat.getCodecFactory(job);    assertNotNull(factory);    assertEquals(factory.getClass(), avroDeflateCodec.getClass());}
0
public void testDeflateCodecUsingAvroCodec()
{    CodecFactory avroDeflateCodec = CodecFactory.fromString("deflate");    JobConf job = new JobConf();    job.set("mapred.output.compress", "true");    job.set(AvroJob.OUTPUT_CODEC, "deflate");    CodecFactory factory = AvroOutputFormat.getCodecFactory(job);    assertNotNull(factory);    assertEquals(factory.getClass(), avroDeflateCodec.getClass());}
0
public void testSnappyCodecUsingHadoopClass()
{    CodecFactory avroSnappyCodec = CodecFactory.fromString("snappy");    JobConf job = new JobConf();    job.set("mapred.output.compress", "true");    job.set("mapred.output.compression.codec", "org.apache.hadoop.io.compress.SnappyCodec");    CodecFactory factory = AvroOutputFormat.getCodecFactory(job);    assertNotNull(factory);    assertEquals(factory.getClass(), avroSnappyCodec.getClass());}
0
public void testSnappyCodecUsingAvroCodec()
{    CodecFactory avroSnappyCodec = CodecFactory.fromString("snappy");    JobConf job = new JobConf();    job.set("mapred.output.compress", "true");    job.set(AvroJob.OUTPUT_CODEC, "snappy");    CodecFactory factory = AvroOutputFormat.getCodecFactory(job);    assertNotNull(factory);    assertEquals(factory.getClass(), avroSnappyCodec.getClass());}
0
public void testGZipCodecUsingHadoopClass()
{    CodecFactory avroDeflateCodec = CodecFactory.fromString("deflate");    JobConf job = new JobConf();    job.set("mapred.output.compress", "true");    job.set("mapred.output.compression.codec", "org.apache.hadoop.io.compress.GZipCodec");    CodecFactory factory = AvroOutputFormat.getCodecFactory(job);    assertNotNull(factory);    assertEquals(factory.getClass(), avroDeflateCodec.getClass());}
0
public void testAvroTextRecordWriter() throws Exception
{    File file = new File(tmpFolder.getRoot().getPath(), "writer");    Schema schema = Schema.create(Schema.Type.BYTES);    DatumWriter<ByteBuffer> datumWriter = new GenericDatumWriter<>(schema);    DataFileWriter<ByteBuffer> fileWriter = new DataFileWriter<>(datumWriter);    fileWriter.create(schema, file);    RecordWriter<Object, Object> rw = new AvroTextOutputFormat<>().new AvroTextRecordWriter(fileWriter, "\t".getBytes(StandardCharsets.UTF_8));    rw.write(null, null);    rw.write(null, NullWritable.get());    rw.write(NullWritable.get(), null);    rw.write(NullWritable.get(), NullWritable.get());    rw.write("k1", null);    rw.write("k2", NullWritable.get());    rw.write(null, "v1");    rw.write(NullWritable.get(), "v2");    rw.write("k3", "v3");    rw.write(new Text("k4"), new Text("v4"));    rw.close(null);    DatumReader<ByteBuffer> reader = new GenericDatumReader<>();    DataFileReader<ByteBuffer> fileReader = new DataFileReader<>(file, reader);    assertEquals("k1", asString(fileReader.next()));    assertEquals("k2", asString(fileReader.next()));    assertEquals("v1", asString(fileReader.next()));    assertEquals("v2", asString(fileReader.next()));    assertEquals("k3\tv3", asString(fileReader.next()));    assertEquals("k4\tv4", asString(fileReader.next()));    assertFalse("End", fileReader.hasNext());}
0
private String asString(ByteBuffer buf)
{    byte[] b = new byte[buf.remaining()];    buf.get(b);    return new String(b, StandardCharsets.UTF_8);}
0
public void testSort() throws Exception
{    JobConf job = new JobConf();    String inputPath = INPUT_DIR.getRoot().getPath();    Path outputPath = new Path(OUTPUT_DIR.getRoot().getPath());    outputPath.getFileSystem(job).delete(outputPath, true);    WordCountUtil.writeLinesBytesFile(inputPath);    job.setInputFormat(AvroAsTextInputFormat.class);    job.setOutputFormat(AvroTextOutputFormat.class);    job.setOutputKeyClass(Text.class);    FileInputFormat.setInputPaths(job, new Path(inputPath));    FileOutputFormat.setOutputPath(job, outputPath);    JobClient.runJob(job);    WordCountUtil.validateSortedFile(outputPath.toString() + "/part-00000.avro");}
0
public void testToString()
{    String datum = "my string";    AvroWrapper<CharSequence> wrapper = new AvroWrapper<>(datum);    assertEquals(datum, wrapper.toString());}
0
private static Schema createSchema()
{    List<Field> fields = new ArrayList<>();    fields.add(new Field("Optional", createArraySchema(), "", new ArrayList<>()));    Schema recordSchema = Schema.createRecord("Container", "", "org.apache.avro.mapred", false);    recordSchema.setFields(fields);    return recordSchema;}
0
private static Schema createArraySchema()
{    List<Schema> schemas = new ArrayList<>();    for (int i = 0; i < 5; i++) {        schemas.add(createInnerSchema("optional_field_" + i));    }    Schema unionSchema = Schema.createUnion(schemas);    return Schema.createArray(unionSchema);}
0
private static Schema createInnerSchema(String name)
{    Schema innerrecord = Schema.createRecord(name, "", "", false);    innerrecord.setFields(Collections.singletonList(new Field(name, Schema.create(Type.LONG), "", 0L)));    return innerrecord;}
0
public void setup() throws IOException
{        String dir = DIR.getRoot().getPath();    File infile = new File(dir + "/in");    RandomAccessFile file = new RandomAccessFile(infile, "rw");        file.writeChars("aa bb cc\ndd ee ff\n");    file.close();}
0
public void map(LongWritable key, Text value, OutputCollector<AvroWrapper<Pair<Long, GenericData.Record>>, NullWritable> out, Reporter reporter) throws IOException
{    GenericData.Record optional_entry = new GenericData.Record(createInnerSchema("optional_field_1"));    optional_entry.put("optional_field_1", 0L);    GenericData.Array<GenericData.Record> array = new GenericData.Array<>(1, createArraySchema());    array.add(optional_entry);    GenericData.Record container = new GenericData.Record(createSchema());    container.put("Optional", array);    out.collect(new AvroWrapper<>(new Pair<>(key.get(), container)), NullWritable.get());}
0
public void testJob() throws Exception
{    JobConf job = new JobConf();    Path outputPath = new Path(DIR.getRoot().getPath() + "/out");    outputPath.getFileSystem(job).delete(outputPath);    job.setInputFormat(TextInputFormat.class);    FileInputFormat.setInputPaths(job, DIR.getRoot().getPath() + "/in");    job.setMapperClass(AvroTestConverter.class);    job.setNumReduceTasks(0);    FileOutputFormat.setOutputPath(job, outputPath);    System.out.println(createSchema());    AvroJob.setOutputSchema(job, Pair.getPairSchema(Schema.create(Schema.Type.LONG), createSchema()));    job.setOutputFormat(AvroOutputFormat.class);    JobClient.runJob(job);}
0
public void testCollectionFailure() throws Exception
{    try {        new Pair("foo", new ArrayList());    } catch (AvroRuntimeException e) {        assertTrue(e.getMessage().startsWith("Cannot infer schema"));        return;    }    fail("Expected an AvroRuntimeException");}
0
public String toString()
{    return text;}
0
public void map(Text text, AvroCollector<Pair<Text, Count>> collector, Reporter reporter) throws IOException
{    StringTokenizer tokens = new StringTokenizer(text.toString());    while (tokens.hasMoreTokens()) collector.collect(new Pair<>(new Text(tokens.nextToken()), new Count(1L)));}
0
public void reduce(Text word, Iterable<Count> counts, AvroCollector<WordCount> collector, Reporter reporter) throws IOException
{    long sum = 0;    for (Count count : counts) sum += count.count;    collector.collect(new WordCount(word.text, sum));}
0
public void testJob() throws Exception
{    JobConf job = new JobConf();    String dir = "target/testReflectJob";    Path inputPath = new Path(dir + "/in");    Path outputPath = new Path(dir + "/out");    outputPath.getFileSystem(job).delete(outputPath);    inputPath.getFileSystem(job).delete(inputPath);    writeLinesFile(new File(dir + "/in"));    job.setJobName("reflect");    AvroJob.setInputSchema(job, ReflectData.get().getSchema(Text.class));    AvroJob.setMapOutputSchema(job, new Pair(new Text(""), new Count(0L)).getSchema());    AvroJob.setOutputSchema(job, ReflectData.get().getSchema(WordCount.class));    AvroJob.setMapperClass(job, MapImpl.class);        AvroJob.setReducerClass(job, ReduceImpl.class);    FileInputFormat.setInputPaths(job, inputPath);    FileOutputFormat.setOutputPath(job, outputPath);        AvroJob.setReflect(job);    JobClient.runJob(job);    validateCountsFile(new File(new File(dir, "out"), "part-00000.avro"));}
0
private void writeLinesFile(File dir) throws IOException
{    DatumWriter<Text> writer = new ReflectDatumWriter<>();    DataFileWriter<Text> out = new DataFileWriter<>(writer);    File linesFile = new File(dir + "/lines.avro");    dir.mkdirs();    out.create(ReflectData.get().getSchema(Text.class), linesFile);    for (String line : WordCountUtil.LINES) out.append(new Text(line));    out.close();}
0
private void validateCountsFile(File file) throws Exception
{    DatumReader<WordCount> reader = new ReflectDatumReader<>();    InputStream in = new BufferedInputStream(new FileInputStream(file));    DataFileStream<WordCount> counts = new DataFileStream<>(in, reader);    int numWords = 0;    for (WordCount wc : counts) {        assertEquals(wc.word, WordCountUtil.COUNTS.get(wc.word), (Long) wc.count);        numWords++;    }    in.close();    assertEquals(WordCountUtil.COUNTS.size(), numWords);}
0
public static File file()
{    return new File(INPUT_DIR.getRoot().getPath(), "test.seq");}
0
public static void testWriteSequenceFile() throws IOException
{    Configuration c = new Configuration();    URI uri = file().toURI();    try (SequenceFile.Writer writer = new SequenceFile.Writer(FileSystem.get(uri, c), c, new Path(uri.toString()), LongWritable.class, Text.class)) {        final LongWritable key = new LongWritable();        final Text val = new Text();        for (int i = 0; i < COUNT; ++i) {            key.set(i);            val.set(Integer.toString(i));            writer.append(key, val);        }    }}
0
public void testReadSequenceFile() throws Exception
{    checkFile(new SequenceFileReader<>(file()));}
0
public void checkFile(FileReader<Pair<Long, CharSequence>> reader) throws Exception
{    long i = 0;    for (Pair<Long, CharSequence> p : reader) {        assertEquals((Long) i, p.key());        assertEquals(Long.toString(i), p.value().toString());        i++;    }    assertEquals(COUNT, i);    reader.close();}
0
public void testSequenceFileInputFormat() throws Exception
{    JobConf job = new JobConf();    Path outputPath = new Path(OUTPUT_DIR.getRoot().getPath());    outputPath.getFileSystem(job).delete(outputPath, true);        AvroJob.setInputSequenceFile(job);    FileInputFormat.setInputPaths(job, file().toURI().toString());    AvroJob.setInputSchema(job, SCHEMA);                AvroJob.setOutputSchema(job, SCHEMA);    FileOutputFormat.setOutputPath(job, outputPath);    JobClient.runJob(job);    checkFile(new DataFileReader<>(new File(outputPath.toString() + "/part-00000.avro"), new SpecificDatumReader<>()));}
0
public void map(LongWritable key, Text value, OutputCollector<AvroKey<Long>, AvroValue<Utf8>> out, Reporter reporter) throws IOException
{    out.collect(new AvroKey<>(key.get()), new AvroValue<>(new Utf8(value.toString())));}
0
public void testNonAvroMapper() throws Exception
{    JobConf job = new JobConf();    Path outputPath = new Path(OUTPUT_DIR.getRoot().getPath());    outputPath.getFileSystem(job).delete(outputPath, true);        job.setInputFormat(SequenceFileInputFormat.class);    FileInputFormat.setInputPaths(job, file().toURI().toString());        job.setMapperClass(NonAvroMapper.class);            FileOutputFormat.setOutputPath(job, outputPath);    AvroJob.setOutputSchema(job, SCHEMA);    JobClient.runJob(job);    checkFile(new DataFileReader<>(new File(outputPath.toString() + "/part-00000.avro"), new SpecificDatumReader<>()));}
0
public void map(LongWritable key, Text value, OutputCollector<AvroWrapper<Pair<Long, Utf8>>, NullWritable> out, Reporter reporter) throws IOException
{    out.collect(new AvroWrapper<>(new Pair<>(key.get(), new Utf8(value.toString()))), NullWritable.get());}
0
public void testNonAvroMapOnly() throws Exception
{    JobConf job = new JobConf();    Path outputPath = new Path(OUTPUT_DIR.getRoot().getPath());    outputPath.getFileSystem(job).delete(outputPath, true);        job.setInputFormat(SequenceFileInputFormat.class);    FileInputFormat.setInputPaths(job, file().toURI().toString());        job.setMapperClass(NonAvroOnlyMapper.class);            job.setNumReduceTasks(0);    FileOutputFormat.setOutputPath(job, outputPath);    AvroJob.setOutputSchema(job, SCHEMA);    JobClient.runJob(job);    checkFile(new DataFileReader<>(new File(outputPath.toString() + "/part-00000.avro"), new SpecificDatumReader<>()));}
0
public void reduce(AvroKey<Long> key, Iterator<AvroValue<Utf8>> values, OutputCollector<LongWritable, Text> out, Reporter reporter) throws IOException
{    while (values.hasNext()) {        AvroValue<Utf8> value = values.next();        out.collect(new LongWritable(key.datum()), new Text(value.datum().toString()));    }}
0
public void testNonAvroReducer() throws Exception
{    JobConf job = new JobConf();    Path outputPath = new Path(OUTPUT_DIR.getRoot().getPath());    outputPath.getFileSystem(job).delete(outputPath, true);        AvroJob.setInputSequenceFile(job);    AvroJob.setInputSchema(job, SCHEMA);    FileInputFormat.setInputPaths(job, file().toURI().toString());            AvroJob.setMapOutputSchema(job, SCHEMA);    job.setReducerClass(NonAvroReducer.class);        job.setOutputFormat(SequenceFileOutputFormat.class);    FileOutputFormat.setOutputPath(job, outputPath);        JobClient.runJob(job);    checkFile(new SequenceFileReader<>(new File(outputPath.toString() + "/part-00000")));}
0
public void tearDown()
{    mapCloseCalls.set(0);    mapConfigureCalls.set(0);    reducerCloseCalls.set(0);    reducerConfigureCalls.set(0);}
0
public void testMapOnly() throws Exception
{    JobConf job = new JobConf();    String inDir = System.getProperty("share.dir", "../../../share") + "/test/data";    Path input = new Path(inDir + "/weather.avro");    Path output = new Path("target/test/weather-ident");    output.getFileSystem(job).delete(output);    job.setJobName("identity map weather");    AvroJob.setInputSchema(job, Weather.SCHEMA$);    AvroJob.setOutputSchema(job, Weather.SCHEMA$);    FileInputFormat.setInputPaths(job, input);    FileOutputFormat.setOutputPath(job, output);    FileOutputFormat.setCompressOutput(job, true);        job.setNumReduceTasks(0);    JobClient.runJob(job);        DatumReader<Weather> reader = new SpecificDatumReader<>();    DataFileReader<Weather> check = new DataFileReader<>(new File(inDir + "/weather.avro"), reader);    DataFileReader<Weather> sorted = new DataFileReader<>(new File(output.toString() + "/part-00000.avro"), reader);    for (Weather w : sorted) assertEquals(check.next(), w);    check.close();    sorted.close();}
0
public void map(Weather w, AvroCollector<Pair<Weather, Void>> collector, Reporter reporter) throws IOException
{    collector.collect(new Pair<>(w, (Void) null));}
0
public void close() throws IOException
{    mapCloseCalls.incrementAndGet();}
0
public void configure(JobConf jobConf)
{    mapConfigureCalls.incrementAndGet();}
0
public void reduce(Weather w, Iterable<Void> ignore, AvroCollector<Weather> collector, Reporter reporter) throws IOException
{    collector.collect(w);}
0
public void close() throws IOException
{    reducerCloseCalls.incrementAndGet();}
0
public void configure(JobConf jobConf)
{    reducerConfigureCalls.incrementAndGet();}
0
public void testSort() throws Exception
{    JobConf job = new JobConf();    String inDir = "../../../share/test/data";    Path input = new Path(inDir + "/weather.avro");    Path output = new Path("target/test/weather-sort");    output.getFileSystem(job).delete(output);    job.setJobName("sort weather");    AvroJob.setInputSchema(job, Weather.SCHEMA$);    AvroJob.setMapOutputSchema(job, Pair.getPairSchema(Weather.SCHEMA$, Schema.create(Type.NULL)));    AvroJob.setOutputSchema(job, Weather.SCHEMA$);    AvroJob.setMapperClass(job, SortMapper.class);    AvroJob.setReducerClass(job, SortReducer.class);    FileInputFormat.setInputPaths(job, input);    FileOutputFormat.setOutputPath(job, output);    FileOutputFormat.setCompressOutput(job, true);    AvroJob.setOutputCodec(job, SNAPPY_CODEC);    JobClient.runJob(job);        DatumReader<Weather> reader = new SpecificDatumReader<>();    DataFileReader<Weather> check = new DataFileReader<>(new File(inDir + "/weather-sorted.avro"), reader);    DataFileReader<Weather> sorted = new DataFileReader<>(new File(output.toString() + "/part-00000.avro"), reader);    for (Weather w : sorted) assertEquals(check.next(), w);    check.close();    sorted.close();        assertEquals(1, mapCloseCalls.get());    assertEquals(1, reducerCloseCalls.get());    assertEquals(1, mapConfigureCalls.get());    assertEquals(1, reducerConfigureCalls.get());}
0
public void map(Utf8 text, AvroCollector<Pair<Utf8, Long>> collector, Reporter reporter) throws IOException
{    StringTokenizer tokens = new StringTokenizer(text.toString());    while (tokens.hasMoreTokens()) collector.collect(new Pair<>(new Utf8(tokens.nextToken()), 1L));}
0
public void reduce(Utf8 word, Iterable<Long> counts, AvroCollector<Pair<Utf8, Long>> collector, Reporter reporter) throws IOException
{    long sum = 0;    for (long count : counts) sum += count;    collector.collect(new Pair<>(word, sum));}
0
public void runTestsInOrder() throws Exception
{    String pathOut = OUTPUT_DIR.getRoot().getPath();    testJob(pathOut);    testProjection(pathOut);}
0
public void testJob(String pathOut) throws Exception
{    JobConf job = new JobConf();    String pathIn = INPUT_DIR.getRoot().getPath();    WordCountUtil.writeLinesFile(pathIn + "/lines.avro");    Path outputPath = new Path(pathOut);    outputPath.getFileSystem(job).delete(outputPath);    job.setJobName("wordcount");    AvroJob.setInputSchema(job, Schema.create(Schema.Type.STRING));    AvroJob.setOutputSchema(job, new Pair<Utf8, Long>(new Utf8(""), 0L).getSchema());    AvroJob.setMapperClass(job, MapImpl.class);    AvroJob.setCombinerClass(job, ReduceImpl.class);    AvroJob.setReducerClass(job, ReduceImpl.class);    FileInputFormat.setInputPaths(job, new Path(pathIn));    FileOutputFormat.setOutputPath(job, new Path(pathOut));    FileOutputFormat.setCompressOutput(job, true);    WordCountUtil.setMeta(job);    JobClient.runJob(job);    WordCountUtil.validateCountsFile(new File(pathOut, "part-00000.avro"));}
0
public void testProjection(String inputPathString) throws Exception
{    JobConf job = new JobConf();    Integer defaultRank = -1;    String jsonSchema = "{\"type\":\"record\"," + "\"name\":\"org.apache.avro.mapred.Pair\"," + "\"fields\": [ " + "{\"name\":\"rank\", \"type\":\"int\", \"default\": -1}," + "{\"name\":\"value\", \"type\":\"long\"}" + "]}";    Schema readerSchema = Schema.parse(jsonSchema);    AvroJob.setInputSchema(job, readerSchema);    Path inputPath = new Path(inputPathString + "/part-00000.avro");    FileStatus fileStatus = FileSystem.get(job).getFileStatus(inputPath);    FileSplit fileSplit = new FileSplit(inputPath, 0, fileStatus.getLen(), job);    AvroRecordReader<Pair<Integer, Long>> recordReader = new AvroRecordReader<>(job, fileSplit);    AvroWrapper<Pair<Integer, Long>> inputPair = new AvroWrapper<>(null);    NullWritable ignore = NullWritable.get();    long sumOfCounts = 0;    long numOfCounts = 0;    while (recordReader.next(inputPair, ignore)) {        assertEquals(inputPair.datum().get(0), defaultRank);        sumOfCounts += (Long) inputPair.datum().get(1);        numOfCounts++;    }    assertEquals(numOfCounts, WordCountUtil.COUNTS.size());    long actualSumOfCounts = 0;    for (Long count : WordCountUtil.COUNTS.values()) {        actualSumOfCounts += count;    }    assertEquals(sumOfCounts, actualSumOfCounts);}
0
private void _runjob(String proto) throws Exception
{    String outputPathStr = OUTPUT_DIR.getRoot().getPath();    File inputPath = new File(INPUT_DIR.getRoot(), "lines.avro");    JobConf job = new JobConf();    Path outputPath = new Path(outputPathStr);    outputPath.getFileSystem(job).delete(outputPath, true);        WordCountUtil.writeLinesFile(inputPath);    File exec = new File(System.getProperty("java.home") + "/bin/java");        List<String> execargs = new ArrayList<>();    execargs.add("-classpath");    execargs.add(System.getProperty("java.class.path"));    execargs.add("org.apache.avro.mapred.tether.WordCountTask");    FileInputFormat.addInputPaths(job, inputPath.toString());    FileOutputFormat.setOutputPath(job, outputPath);    TetherJob.setExecutable(job, exec, execargs, false);    Schema outscheme = new Pair<Utf8, Long>(new Utf8(""), 0L).getSchema();    AvroJob.setInputSchema(job, Schema.create(Schema.Type.STRING));    job.set(AvroJob.OUTPUT_SCHEMA, outscheme.toString());    TetherJob.setProtocol(job, proto);    TetherJob.runJob(job);        DatumReader<Pair<Utf8, Long>> reader = new SpecificDatumReader<>();    InputStream cin = new BufferedInputStream(new FileInputStream(outputPath + "/part-00000.avro"));    DataFileStream<Pair<Utf8, Long>> counts = new DataFileStream<>(cin, reader);    int numWords = 0;    for (Pair<Utf8, Long> wc : counts) {        assertEquals(wc.key().toString(), WordCountUtil.COUNTS.get(wc.key().toString()), wc.value());        numWords++;    }    cin.close();    assertEquals(WordCountUtil.COUNTS.size(), numWords);}
0
public void testJob() throws Exception
{    _runjob("sasl");}
0
public void testhtp() throws Exception
{    _runjob("http");}
0
public ByteBuffer data()
{    return ByteBuffer.wrap(buf, 0, count);}
0
public void collect(T record) throws IOException
{    buffer.reset();    writer.write(record, encoder);    encoder.flush();    outputClient.output(buffer.data());}
0
public void collect(T record, int partition) throws IOException
{    buffer.reset();    writer.write(record, encoder);    encoder.flush();    outputClient.outputPartitioned(partition, buffer.data());}
0
 void open(int inputPort) throws IOException
{        String clientPortString = System.getenv("AVRO_TETHER_OUTPUT_PORT");    String protocol = System.getenv("AVRO_TETHER_PROTOCOL");    if (clientPortString == null)        throw new RuntimeException("AVRO_TETHER_OUTPUT_PORT env var is null");    int clientPort = Integer.parseInt(clientPortString);    if (protocol == null) {        throw new RuntimeException("AVRO_TETHER_PROTOCOL env var is null");    }    protocol = protocol.trim().toLowerCase();    TetheredProcess.Protocol proto;    if (protocol.equals("http")) {        proto = TetheredProcess.Protocol.HTTP;    } else if (protocol.equals("sasl")) {        proto = TetheredProcess.Protocol.SASL;    } else {        throw new RuntimeException("AVROT_TETHER_PROTOCOL=" + protocol + " but this protocol is unsupported");    }    switch(proto) {        case SASL:            this.clientTransceiver = new SaslSocketTransceiver(new InetSocketAddress(clientPort));            this.outputClient = SpecificRequestor.getClient(OutputProtocol.class, clientTransceiver);            break;        case HTTP:            this.clientTransceiver = new HttpTransceiver(new URL("http://127.0.0.1:" + clientPort));            this.outputClient = SpecificRequestor.getClient(OutputProtocol.class, clientTransceiver);            break;    }        outputClient.configure(inputPort);}
0
 void configure(TaskType taskType, CharSequence inSchemaText, CharSequence outSchemaText)
{    this.taskType = taskType;    try {        Schema inSchema = new Schema.Parser().parse(inSchemaText.toString());        Schema outSchema = new Schema.Parser().parse(outSchemaText.toString());        switch(taskType) {            case MAP:                this.inReader = new SpecificDatumReader<>(inSchema);                this.midCollector = new Collector<>(outSchema);                break;            case REDUCE:                this.midReader = new SpecificDatumReader<>(inSchema);                this.outCollector = new Collector<>(outSchema);                break;        }    } catch (Throwable e) {        fail(e.toString());    }}
0
 void partitions(int partitions)
{    this.partitions = partitions;}
0
public int partitions()
{    return partitions;}
0
 void input(ByteBuffer data, long count)
{    try {        decoder = decoderFactory.binaryDecoder(data.array(), decoder);        for (long i = 0; i < count; i++) {            switch(taskType) {                case MAP:                    inRecord = inReader.read(inRecord, decoder);                    map(inRecord, midCollector);                    break;                case REDUCE:                    MID prev = midRecord;                    midRecord = midReader.read(midRecordSpare, decoder);                    if (prev != null && !midRecord.equals(prev))                        reduceFlush(prev, outCollector);                    reduce(midRecord, outCollector);                    midRecordSpare = prev;                    break;            }        }    } catch (Throwable e) {                fail(e.toString());    }}
1
 void complete()
{    if (taskType == TaskType.REDUCE && midRecord != null)        try {            reduceFlush(midRecord, outCollector);        } catch (Throwable e) {                        fail(e.toString());        }        outputClient.complete();    }
1
public void status(String message)
{    outputClient.status(message);}
0
public void count(String group, String name, long amount)
{    outputClient.count(group, name, amount);}
0
public void fail(String message)
{    outputClient.fail(message);    close();}
0
 void close()
{        if (clientTransceiver != null)        try {            clientTransceiver.close();        } catch (IOException e) {        }}
1
public void configure(TaskType taskType, String inSchema, String outSchema)
{        task.configure(taskType, inSchema, outSchema);}
1
public synchronized void input(ByteBuffer data, long count)
{    task.input(data, count);}
0
public void partitions(int partitions)
{    task.partitions(partitions);}
0
public void abort()
{        close();}
1
public synchronized void complete()
{        task.complete();}
1
public void join() throws InterruptedException
{        inputServer.join();    }
1
private void close()
{        task.close();        if (inputServer != null)        inputServer.close();}
1
public void map(Utf8 text, Collector<Pair<Utf8, Long>> collector) throws IOException
{    StringTokenizer tokens = new StringTokenizer(text.toString());    while (tokens.hasMoreTokens()) collector.collect(new Pair<>(new Utf8(tokens.nextToken()), 1L));}
0
public void reduce(Pair<Utf8, Long> wc, Collector<Pair<Utf8, Long>> c)
{    sum += wc.value();}
0
public void reduceFlush(Pair<Utf8, Long> wc, Collector<Pair<Utf8, Long>> c) throws IOException
{    wc.value(sum);    c.collect(wc);    sum = 0;}
0
public static void main(String[] args) throws Exception
{    new TetherTaskRunner(new WordCountTask()).join();    }
1
public static void writeLinesFile(String dir) throws IOException
{    writeLinesFile(new File(dir));}
0
public static void writeLinesFile(File dir) throws IOException
{    DatumWriter<Utf8> writer = new GenericDatumWriter<>();    try (DataFileWriter<Utf8> out = new DataFileWriter<>(writer)) {        out.create(Schema.create(Schema.Type.STRING), dir);        for (String line : LINES) {            out.append(new Utf8(line));        }    }}
0
public static void writeLinesBytesFile(String dir) throws IOException
{    writeLinesBytesFile(new File(dir));}
0
public static void writeLinesBytesFile(File dir) throws IOException
{    FileUtil.fullyDelete(dir);    File fileLines = new File(dir + "/lines.avro");    fileLines.getParentFile().mkdirs();    DatumWriter<ByteBuffer> writer = new GenericDatumWriter<>();    try (DataFileWriter<ByteBuffer> out = new DataFileWriter<>(writer)) {        out.create(Schema.create(Schema.Type.BYTES), fileLines);        for (String line : LINES) {            out.append(ByteBuffer.wrap(line.getBytes(StandardCharsets.UTF_8)));        }    }}
0
public static void writeLinesTextFile(File dir) throws IOException
{    FileUtil.fullyDelete(dir);    File fileLines = new File(dir, "lines.avro");    fileLines.getParentFile().mkdirs();    try (PrintStream out = new PrintStream(fileLines)) {        for (String line : LINES) {            out.println(line);        }    }}
0
public static void validateCountsFile(File file) throws Exception
{    int numWords = 0;    DatumReader<Pair<Utf8, Long>> reader = new SpecificDatumReader<>();    try (InputStream in = new BufferedInputStream(new FileInputStream(file))) {        try (DataFileStream<Pair<Utf8, Long>> counts = new DataFileStream<>(in, reader)) {            for (Pair<Utf8, Long> wc : counts) {                assertEquals(wc.key().toString(), COUNTS.get(wc.key().toString()), wc.value());                numWords++;            }            checkMeta(counts);        }    }    assertEquals(COUNTS.size(), numWords);}
0
public static void validateSortedFile(String file) throws Exception
{    validateSortedFile(new File(file));}
0
public static void validateSortedFile(File file) throws Exception
{    DatumReader<ByteBuffer> reader = new GenericDatumReader<>();    try (InputStream in = new BufferedInputStream(new FileInputStream(file))) {        try (DataFileStream<ByteBuffer> lines = new DataFileStream<>(in, reader)) {            List<String> sortedLines = new ArrayList<>(Arrays.asList(LINES));            Collections.sort(sortedLines);            for (String expectedLine : sortedLines) {                ByteBuffer buf = lines.next();                byte[] b = new byte[buf.remaining()];                buf.get(b);                assertEquals(expectedLine, new String(b, StandardCharsets.UTF_8).trim());            }            assertFalse(lines.hasNext());        }    }}
0
public static void setMeta(JobConf job)
{    AvroJob.setOutputMeta(job, STRING_KEY, STRING_META_VALUE);    AvroJob.setOutputMeta(job, LONG_KEY, LONG_META_VALUE);    AvroJob.setOutputMeta(job, BYTES_KEY, BYTES_META_VALUE);}
0
public static void checkMeta(DataFileStream<?> in) throws Exception
{    assertEquals(STRING_META_VALUE, in.getMetaString(STRING_KEY));    assertEquals(LONG_META_VALUE, in.getMetaLong(LONG_KEY));    assertTrue(Arrays.equals(BYTES_META_VALUE, in.getMeta(BYTES_KEY)));}
0
public static File createFile(File file, Schema schema, T... records) throws IOException
{    DatumWriter<T> datumWriter = new GenericDatumWriter<>(schema);    DataFileWriter<T> fileWriter = new DataFileWriter<>(datumWriter);    fileWriter.create(schema, file);    for (T record : records) {        fileWriter.append(record);    }    fileWriter.close();    return file;}
0
public void testCreateRecordReader() throws IOException, InterruptedException
{        Job job = Job.getInstance();    AvroJob.setInputKeySchema(job, Schema.create(Schema.Type.STRING));    Configuration conf = job.getConfiguration();    FileSplit inputSplit = createMock(FileSplit.class);    TaskAttemptContext context = createMock(TaskAttemptContext.class);    expect(context.getConfiguration()).andReturn(conf).anyTimes();    replay(inputSplit);    replay(context);    AvroKeyInputFormat inputFormat = new AvroKeyInputFormat();    @SuppressWarnings("unchecked")    RecordReader<AvroKey<Object>, NullWritable> recordReader = inputFormat.createRecordReader(inputSplit, context);    assertNotNull(inputFormat);    recordReader.close();    verify(inputSplit);    verify(context);}
0
public void testWithNullCodec() throws IOException
{    Configuration conf = new Configuration();    conf.setInt(SYNC_INTERVAL_KEY, TEST_SYNC_INTERVAL);    testGetRecordWriter(conf, CodecFactory.nullCodec(), TEST_SYNC_INTERVAL);}
0
public void testWithDeflateCodec() throws IOException
{    Configuration conf = new Configuration();    conf.setBoolean("mapred.output.compress", true);    conf.setInt(org.apache.avro.mapred.AvroOutputFormat.DEFLATE_LEVEL_KEY, 3);    testGetRecordWriter(conf, CodecFactory.deflateCodec(3), DataFileConstants.DEFAULT_SYNC_INTERVAL);}
0
public void testWithSnappyCode() throws IOException
{    Configuration conf = new Configuration();    conf.setBoolean("mapred.output.compress", true);    conf.set(AvroJob.CONF_OUTPUT_CODEC, DataFileConstants.SNAPPY_CODEC);    conf.setInt(SYNC_INTERVAL_KEY, TEST_SYNC_INTERVAL);    testGetRecordWriter(conf, CodecFactory.snappyCodec(), TEST_SYNC_INTERVAL);}
0
public void testWithBZip2Code() throws IOException
{    Configuration conf = new Configuration();    conf.setBoolean("mapred.output.compress", true);    conf.set(AvroJob.CONF_OUTPUT_CODEC, DataFileConstants.BZIP2_CODEC);    testGetRecordWriter(conf, CodecFactory.bzip2Codec(), DataFileConstants.DEFAULT_SYNC_INTERVAL);}
0
public void testWithZstandardCode() throws IOException
{    Configuration conf = new Configuration();    conf.setBoolean("mapred.output.compress", true);    conf.set(AvroJob.CONF_OUTPUT_CODEC, DataFileConstants.ZSTANDARD_CODEC);    testGetRecordWriter(conf, CodecFactory.zstandardCodec(3), DataFileConstants.DEFAULT_SYNC_INTERVAL);}
0
public void testWithDeflateCodeWithHadoopConfig() throws IOException
{    Configuration conf = new Configuration();    conf.setBoolean("mapred.output.compress", true);    conf.set("mapred.output.compression.codec", "org.apache.hadoop.io.compress.DeflateCodec");    conf.setInt(org.apache.avro.mapred.AvroOutputFormat.DEFLATE_LEVEL_KEY, -1);    conf.setInt(SYNC_INTERVAL_KEY, TEST_SYNC_INTERVAL);    testGetRecordWriter(conf, CodecFactory.deflateCodec(-1), TEST_SYNC_INTERVAL);}
0
public void testWithSnappyCodeWithHadoopConfig() throws IOException
{    Configuration conf = new Configuration();    conf.setBoolean("mapred.output.compress", true);    conf.set("mapred.output.compression.codec", "org.apache.hadoop.io.compress.SnappyCodec");    testGetRecordWriter(conf, CodecFactory.snappyCodec(), DataFileConstants.DEFAULT_SYNC_INTERVAL);}
0
public void testWithBZip2CodeWithHadoopConfig() throws IOException
{    Configuration conf = new Configuration();    conf.setBoolean("mapred.output.compress", true);    conf.set("mapred.output.compression.codec", "org.apache.hadoop.io.compress.BZip2Codec");    conf.setInt(SYNC_INTERVAL_KEY, TEST_SYNC_INTERVAL);    testGetRecordWriter(conf, CodecFactory.bzip2Codec(), TEST_SYNC_INTERVAL);}
0
private void testGetRecordWriter(Configuration conf, CodecFactory expectedCodec, int expectedSyncInterval) throws IOException
{        Job job = Job.getInstance(conf);    job.getConfiguration().set("mapred.output.dir", mTempDir.getRoot().getPath());    Schema writerSchema = Schema.create(Schema.Type.INT);    AvroJob.setOutputKeySchema(job, writerSchema);    TaskAttemptContext context = createMock(TaskAttemptContext.class);    expect(context.getConfiguration()).andReturn(job.getConfiguration()).anyTimes();    expect(context.getTaskAttemptID()).andReturn(TaskAttemptID.forName("attempt_200707121733_0001_m_000000_0")).anyTimes();    expect(context.getNumReduceTasks()).andReturn(1);        @SuppressWarnings("unchecked")    RecordWriter<AvroKey<Integer>, NullWritable> expectedRecordWriter = createMock(RecordWriter.class);    AvroKeyOutputFormat.RecordWriterFactory recordWriterFactory = createMock(AvroKeyOutputFormat.RecordWriterFactory.class);        Capture<CodecFactory> capturedCodecFactory = Capture.newInstance();    expect(    recordWriterFactory.create(    eq(writerSchema),     anyObject(GenericData.class),     capture(capturedCodecFactory),     anyObject(OutputStream.class), eq(expectedSyncInterval))).andReturn(expectedRecordWriter);    replay(context);    replay(expectedRecordWriter);    replay(recordWriterFactory);    AvroKeyOutputFormat<Integer> outputFormat = new AvroKeyOutputFormat<>(recordWriterFactory);    RecordWriter<AvroKey<Integer>, NullWritable> recordWriter = outputFormat.getRecordWriter(context);        assertTrue(capturedCodecFactory.hasCaptured());    assertEquals(expectedCodec.toString(), capturedCodecFactory.getValue().toString());    verify(context);    verify(expectedRecordWriter);    verify(recordWriterFactory);    assertNotNull(recordWriter);    assertTrue(expectedRecordWriter == recordWriter);}
0
public void testReadRecords() throws IOException, InterruptedException
{                final SeekableInput avroFileInput = new SeekableFileInput(AvroFiles.createFile(new File(mTempDir.getRoot(), "myStringfile.avro"), Schema.create(Schema.Type.STRING), "first", "second"));        Schema readerSchema = Schema.create(Schema.Type.STRING);    RecordReader<AvroKey<CharSequence>, NullWritable> recordReader = new AvroKeyRecordReader<CharSequence>(readerSchema) {        @Override        protected SeekableInput createSeekableInput(Configuration conf, Path path) throws IOException {            return avroFileInput;        }    };        Configuration conf = new Configuration();        FileSplit inputSplit = createMock(FileSplit.class);    expect(inputSplit.getPath()).andReturn(new Path("/path/to/an/avro/file")).anyTimes();    expect(inputSplit.getStart()).andReturn(0L).anyTimes();    expect(inputSplit.getLength()).andReturn(avroFileInput.length()).anyTimes();        TaskAttemptContext context = createMock(TaskAttemptContext.class);    expect(context.getConfiguration()).andReturn(conf).anyTimes();        replay(inputSplit);    replay(context);    recordReader.initialize(inputSplit, context);    assertEquals("Progress should be zero before any records are read", 0.0f, recordReader.getProgress(), 0.0f);        AvroKey<CharSequence> key;    NullWritable value;        assertTrue("Expected at least one record", recordReader.nextKeyValue());    key = recordReader.getCurrentKey();    value = recordReader.getCurrentValue();    assertNotNull("First record had null key", key);    assertNotNull("First record had null value", value);    CharSequence firstString = key.datum();    assertEquals("first", firstString.toString());    assertTrue("getCurrentKey() returned different keys for the same record", key == recordReader.getCurrentKey());    assertTrue("getCurrentValue() returned different values for the same record", value == recordReader.getCurrentValue());        assertTrue("Expected to read a second record", recordReader.nextKeyValue());    key = recordReader.getCurrentKey();    value = recordReader.getCurrentValue();    assertNotNull("Second record had null key", key);    assertNotNull("Second record had null value", value);    CharSequence secondString = key.datum();    assertEquals("second", secondString.toString());    assertEquals("Progress should be complete (2 out of 2 records processed)", 1.0f, recordReader.getProgress(), 0.0f);        assertFalse("Expected only 2 records", recordReader.nextKeyValue());        recordReader.close();        verify(inputSplit);    verify(context);}
0
protected SeekableInput createSeekableInput(Configuration conf, Path path) throws IOException
{    return avroFileInput;}
0
public void testWrite() throws IOException
{    Schema writerSchema = Schema.create(Schema.Type.INT);    GenericData dataModel = new ReflectData();    CodecFactory compressionCodec = CodecFactory.nullCodec();    ByteArrayOutputStream outputStream = new ByteArrayOutputStream();    TaskAttemptContext context = createMock(TaskAttemptContext.class);    replay(context);        AvroKeyRecordWriter<Integer> recordWriter = new AvroKeyRecordWriter<>(writerSchema, dataModel, compressionCodec, outputStream);    recordWriter.write(new AvroKey<>(1), NullWritable.get());    recordWriter.write(new AvroKey<>(2), NullWritable.get());    recordWriter.close(context);    verify(context);        InputStream inputStream = new ByteArrayInputStream(outputStream.toByteArray());    Schema readerSchema = Schema.create(Schema.Type.INT);    DatumReader<Integer> datumReader = new SpecificDatumReader<>(readerSchema);    DataFileStream<Integer> dataFileReader = new DataFileStream<>(inputStream, datumReader);        assertTrue(dataFileReader.hasNext());    assertEquals(1, dataFileReader.next().intValue());        assertTrue(dataFileReader.hasNext());    assertEquals(2, dataFileReader.next().intValue());        assertFalse(dataFileReader.hasNext());    dataFileReader.close();}
0
public void testSycnableWrite() throws IOException
{    Schema writerSchema = Schema.create(Schema.Type.INT);    GenericData dataModel = new ReflectData();    CodecFactory compressionCodec = CodecFactory.nullCodec();    FileOutputStream outputStream = new FileOutputStream(new File("target/temp.avro"));    TaskAttemptContext context = createMock(TaskAttemptContext.class);    replay(context);        AvroKeyRecordWriter<Integer> recordWriter = new AvroKeyRecordWriter<>(writerSchema, dataModel, compressionCodec, outputStream);    long positionOne = recordWriter.sync();    recordWriter.write(new AvroKey<>(1), NullWritable.get());    long positionTwo = recordWriter.sync();    recordWriter.write(new AvroKey<>(2), NullWritable.get());    recordWriter.close(context);    verify(context);        Configuration conf = new Configuration();    conf.set("fs.default.name", "file:///");    Path avroFile = new Path("target/temp.avro");    DataFileReader<GenericData.Record> dataFileReader = new DataFileReader<>(new FsInput(avroFile, conf), new SpecificDatumReader<>());    dataFileReader.seek(positionTwo);        assertTrue(dataFileReader.hasNext());    assertEquals(2, dataFileReader.next());    dataFileReader.seek(positionOne);        assertTrue(dataFileReader.hasNext());    assertEquals(1, dataFileReader.next());    dataFileReader.close();}
0
public void testReadRecords() throws IOException, InterruptedException
{                Schema keyValueSchema = AvroKeyValue.getSchema(Schema.create(Schema.Type.STRING), Schema.create(Schema.Type.INT));    AvroKeyValue<CharSequence, Integer> firstInputRecord = new AvroKeyValue<>(new GenericData.Record(keyValueSchema));    firstInputRecord.setKey("first");    firstInputRecord.setValue(1);    AvroKeyValue<CharSequence, Integer> secondInputRecord = new AvroKeyValue<>(new GenericData.Record(keyValueSchema));    secondInputRecord.setKey("second");    secondInputRecord.setValue(2);    final SeekableInput avroFileInput = new SeekableFileInput(AvroFiles.createFile(new File(mTempDir.getRoot(), "myInputFile.avro"), keyValueSchema, firstInputRecord.get(), secondInputRecord.get()));        RecordReader<AvroKey<CharSequence>, AvroValue<Integer>> recordReader = new AvroKeyValueRecordReader<CharSequence, Integer>(Schema.create(Schema.Type.STRING), Schema.create(Schema.Type.INT)) {        @Override        protected SeekableInput createSeekableInput(Configuration conf, Path path) throws IOException {            return avroFileInput;        }    };        Configuration conf = new Configuration();        FileSplit inputSplit = createMock(FileSplit.class);    expect(inputSplit.getPath()).andReturn(new Path("/path/to/an/avro/file")).anyTimes();    expect(inputSplit.getStart()).andReturn(0L).anyTimes();    expect(inputSplit.getLength()).andReturn(avroFileInput.length()).anyTimes();        TaskAttemptContext context = createMock(TaskAttemptContext.class);    expect(context.getConfiguration()).andReturn(conf).anyTimes();        replay(inputSplit);    replay(context);    recordReader.initialize(inputSplit, context);    assertEquals("Progress should be zero before any records are read", 0.0f, recordReader.getProgress(), 0.0f);        AvroKey<CharSequence> key;    AvroValue<Integer> value;        assertTrue("Expected at least one record", recordReader.nextKeyValue());    key = recordReader.getCurrentKey();    value = recordReader.getCurrentValue();    assertNotNull("First record had null key", key);    assertNotNull("First record had null value", value);    assertEquals("first", key.datum().toString());    assertEquals(1, value.datum().intValue());    assertTrue("getCurrentKey() returned different keys for the same record", key == recordReader.getCurrentKey());    assertTrue("getCurrentValue() returned different values for the same record", value == recordReader.getCurrentValue());        assertTrue("Expected to read a second record", recordReader.nextKeyValue());    key = recordReader.getCurrentKey();    value = recordReader.getCurrentValue();    assertNotNull("Second record had null key", key);    assertNotNull("Second record had null value", value);    assertEquals("second", key.datum().toString());    assertEquals(2, value.datum().intValue());    assertEquals("Progress should be complete (2 out of 2 records processed)", 1.0f, recordReader.getProgress(), 0.0f);        assertFalse("Expected only 2 records", recordReader.nextKeyValue());        recordReader.close();        verify(inputSplit);    verify(context);}
0
protected SeekableInput createSeekableInput(Configuration conf, Path path) throws IOException
{    return avroFileInput;}
0
public void testWriteRecords() throws IOException
{    Job job = Job.getInstance();    AvroJob.setOutputValueSchema(job, TextStats.SCHEMA$);    TaskAttemptContext context = createMock(TaskAttemptContext.class);    replay(context);    AvroDatumConverterFactory factory = new AvroDatumConverterFactory(job.getConfiguration());    AvroDatumConverter<Text, ?> keyConverter = factory.create(Text.class);    AvroValue<TextStats> avroValue = new AvroValue<>(null);    @SuppressWarnings("unchecked")    AvroDatumConverter<AvroValue<TextStats>, ?> valueConverter = factory.create((Class<AvroValue<TextStats>>) avroValue.getClass());    CodecFactory compressionCodec = CodecFactory.nullCodec();    ByteArrayOutputStream outputStream = new ByteArrayOutputStream();                AvroKeyValueRecordWriter<Text, AvroValue<TextStats>> writer = new AvroKeyValueRecordWriter<>(keyConverter, valueConverter, new ReflectData(), compressionCodec, outputStream);    TextStats appleStats = new TextStats();    appleStats.setName("apple");    writer.write(new Text("apple"), new AvroValue<>(appleStats));    TextStats bananaStats = new TextStats();    bananaStats.setName("banana");    writer.write(new Text("banana"), new AvroValue<>(bananaStats));    writer.close(context);    verify(context);    ByteArrayInputStream inputStream = new ByteArrayInputStream(outputStream.toByteArray());    Schema readerSchema = AvroKeyValue.getSchema(Schema.create(Schema.Type.STRING), TextStats.SCHEMA$);    DatumReader<GenericRecord> datumReader = new SpecificDatumReader<>(readerSchema);    DataFileStream<GenericRecord> avroFileReader = new DataFileStream<>(inputStream, datumReader);        assertTrue(avroFileReader.hasNext());    AvroKeyValue<CharSequence, TextStats> firstRecord = new AvroKeyValue<>(avroFileReader.next());    assertNotNull(firstRecord.get());    assertEquals("apple", firstRecord.getKey().toString());    assertEquals("apple", firstRecord.getValue().getName().toString());        assertTrue(avroFileReader.hasNext());    AvroKeyValue<CharSequence, TextStats> secondRecord = new AvroKeyValue<>(avroFileReader.next());    assertNotNull(secondRecord.get());    assertEquals("banana", secondRecord.getKey().toString());    assertEquals("banana", secondRecord.getValue().getName().toString());        assertFalse(avroFileReader.hasNext());    avroFileReader.close();}
0
public void testUsingReflection() throws Exception
{    Job job = Job.getInstance();    Schema schema = ReflectData.get().getSchema(R1.class);    AvroJob.setOutputValueSchema(job, schema);    TaskAttemptContext context = createMock(TaskAttemptContext.class);    replay(context);    R1 record = new R1();    record.attribute = "test";    AvroValue<R1> avroValue = new AvroValue<>(record);    ByteArrayOutputStream outputStream = new ByteArrayOutputStream();    AvroDatumConverterFactory factory = new AvroDatumConverterFactory(job.getConfiguration());    AvroDatumConverter<Text, ?> keyConverter = factory.create(Text.class);    @SuppressWarnings("unchecked")    AvroDatumConverter<AvroValue<R1>, R1> valueConverter = factory.create((Class<AvroValue<R1>>) avroValue.getClass());    AvroKeyValueRecordWriter<Text, AvroValue<R1>> writer = new AvroKeyValueRecordWriter<>(keyConverter, valueConverter, new ReflectData(), CodecFactory.nullCodec(), outputStream);    writer.write(new Text("reflectionData"), avroValue);    writer.close(context);    verify(context);    ByteArrayInputStream inputStream = new ByteArrayInputStream(outputStream.toByteArray());    Schema readerSchema = AvroKeyValue.getSchema(Schema.create(Schema.Type.STRING), schema);    DatumReader<GenericRecord> datumReader = new ReflectDatumReader<>(readerSchema);    DataFileStream<GenericRecord> avroFileReader = new DataFileStream<>(inputStream, datumReader);        assertTrue(avroFileReader.hasNext());        AvroKeyValue<CharSequence, R1> firstRecord = new AvroKeyValue<>(avroFileReader.next());    assertNotNull(firstRecord.get());    assertEquals("reflectionData", firstRecord.getKey().toString());    assertEquals(record.attribute, firstRecord.getValue().attribute);}
0
public void testSyncableWriteRecords() throws IOException
{    Job job = Job.getInstance();    AvroJob.setOutputValueSchema(job, TextStats.SCHEMA$);    TaskAttemptContext context = createMock(TaskAttemptContext.class);    replay(context);    AvroDatumConverterFactory factory = new AvroDatumConverterFactory(job.getConfiguration());    AvroDatumConverter<Text, ?> keyConverter = factory.create(Text.class);    AvroValue<TextStats> avroValue = new AvroValue<>(null);    @SuppressWarnings("unchecked")    AvroDatumConverter<AvroValue<TextStats>, ?> valueConverter = factory.create((Class<AvroValue<TextStats>>) avroValue.getClass());    CodecFactory compressionCodec = CodecFactory.nullCodec();    FileOutputStream outputStream = new FileOutputStream(new File("target/temp.avro"));            AvroKeyValueRecordWriter<Text, AvroValue<TextStats>> writer = new AvroKeyValueRecordWriter<>(keyConverter, valueConverter, new ReflectData(), compressionCodec, outputStream);    TextStats appleStats = new TextStats();    appleStats.setName("apple");    long pointOne = writer.sync();    writer.write(new Text("apple"), new AvroValue<>(appleStats));    TextStats bananaStats = new TextStats();    bananaStats.setName("banana");    long pointTwo = writer.sync();    writer.write(new Text("banana"), new AvroValue<>(bananaStats));    writer.close(context);    verify(context);    Configuration conf = new Configuration();    conf.set("fs.default.name", "file:///");    Path avroFile = new Path("target/temp.avro");    DataFileReader<GenericData.Record> avroFileReader = new DataFileReader<>(new FsInput(avroFile, conf), new SpecificDatumReader<>());    avroFileReader.seek(pointTwo);        assertTrue(avroFileReader.hasNext());    AvroKeyValue<CharSequence, TextStats> secondRecord = new AvroKeyValue<>(avroFileReader.next());    assertNotNull(secondRecord.get());    assertEquals("banana", secondRecord.getKey().toString());    assertEquals("banana", secondRecord.getValue().getName().toString());    avroFileReader.seek(pointOne);        assertTrue(avroFileReader.hasNext());    AvroKeyValue<CharSequence, TextStats> firstRecord = new AvroKeyValue<>(avroFileReader.next());    assertNotNull(firstRecord.get());    assertEquals("apple", firstRecord.getKey().toString());    assertEquals("apple", firstRecord.getValue().getName().toString());        avroFileReader.close();}
0
protected void setup(Context context)
{    mOne = new IntWritable(1);}
0
protected void map(LongWritable fileByteOffset, Text line, Context context) throws IOException, InterruptedException
{    context.write(line, mOne);}
0
protected void setup(Context context)
{    mCount = new IntWritable(0);    mText = new Text("");}
0
protected void map(AvroKey<TextStats> record, NullWritable ignore, Context context) throws IOException, InterruptedException
{    mCount.set(record.datum().getCount());    mText.set(record.datum().getName().toString());    context.write(mText, mCount);}
0
protected void setup(Context context)
{    mStats = new AvroKey<>(null);    amos = new AvroMultipleOutputs(context);}
0
protected void reduce(Text line, Iterable<IntWritable> counts, Context context) throws IOException, InterruptedException
{    GenericData.Record record = new GenericData.Record(STATS_SCHEMA);    GenericData.Record record2 = new GenericData.Record(STATS_SCHEMA_2);    int sum = 0;    for (IntWritable count : counts) {        sum += count.get();    }    record.put("name", new Utf8(line.toString()));    record.put("count", sum);    mStats.datum(record);    context.write(mStats, NullWritable.get());    amos.write("myavro", mStats, NullWritable.get());    record2.put("name1", new Utf8(line.toString()));    record2.put("count1", sum);    mStats.datum(record2);    amos.write(mStats, NullWritable.get(), STATS_SCHEMA_2, null, "testnewwrite2");    amos.write("myavro1", mStats);    amos.write(mStats, NullWritable.get(), STATS_SCHEMA, null, "testnewwrite");    amos.write(mStats, NullWritable.get(), "testwritenonschema");}
0
protected void cleanup(Context context) throws IOException, InterruptedException
{    amos.close();}
0
protected void setup(Context context)
{    mStats = new AvroKey<>(null);    amos = new AvroMultipleOutputs(context);}
0
protected void reduce(Text line, Iterable<IntWritable> counts, Context context) throws IOException, InterruptedException
{    TextStats record = new TextStats();    record.setCount(0);    for (IntWritable count : counts) {        record.setCount(record.getCount() + count.get());    }    record.setName(line.toString());    mStats.datum(record);    context.write(mStats, NullWritable.get());    amos.write("myavro3", mStats, NullWritable.get());}
0
protected void cleanup(Context context) throws IOException, InterruptedException
{    amos.close();}
0
protected void map(AvroKey<TextStats> key, NullWritable value, Context context) throws IOException, InterruptedException
{    context.write(key, value);}
0
protected void reduce(AvroKey<TextStats> key, Iterable<NullWritable> ignore, Context context) throws IOException, InterruptedException
{    context.write(key, NullWritable.get());}
0
public void testAvroGenericOutput() throws Exception
{    Job job = Job.getInstance();    FileInputFormat.setInputPaths(job, new Path(getClass().getResource("/org/apache/avro/mapreduce/mapreduce-test-input.txt").toURI().toString()));    job.setInputFormatClass(TextInputFormat.class);    job.setMapperClass(LineCountMapper.class);    job.setMapOutputKeyClass(Text.class);    job.setMapOutputValueClass(IntWritable.class);    job.setReducerClass(GenericStatsReducer.class);    AvroJob.setOutputKeySchema(job, STATS_SCHEMA);    AvroMultipleOutputs.addNamedOutput(job, "myavro", AvroKeyOutputFormat.class, STATS_SCHEMA, null);    AvroMultipleOutputs.addNamedOutput(job, "myavro1", AvroKeyOutputFormat.class, STATS_SCHEMA_2);    job.setOutputFormatClass(AvroKeyOutputFormat.class);    Path outputPath = new Path(DIR.getRoot().getPath() + "/testAvroGenericOutput");    outputPath.getFileSystem(job.getConfiguration()).delete(outputPath, true);    FileOutputFormat.setOutputPath(job, outputPath);    Assert.assertTrue(job.waitForCompletion(true));        FileSystem fileSystem = FileSystem.get(job.getConfiguration());    FileStatus[] outputFiles = fileSystem.globStatus(outputPath.suffix("/myavro-r-00000.avro"));    Assert.assertEquals(1, outputFiles.length);    Map<String, Integer> counts = new HashMap<>();    try (DataFileReader<GenericData.Record> reader = new DataFileReader<>(new FsInput(outputFiles[0].getPath(), job.getConfiguration()), new GenericDatumReader<>(STATS_SCHEMA))) {        for (GenericData.Record record : reader) {            counts.put(((Utf8) record.get("name")).toString(), (Integer) record.get("count"));        }    }    Assert.assertEquals(3, counts.get("apple").intValue());    Assert.assertEquals(2, counts.get("banana").intValue());    Assert.assertEquals(1, counts.get("carrot").intValue());    outputFiles = fileSystem.globStatus(outputPath.suffix("/myavro1-r-00000.avro"));    Assert.assertEquals(1, outputFiles.length);    counts.clear();    try (DataFileReader<GenericData.Record> reader = new DataFileReader<>(new FsInput(outputFiles[0].getPath(), job.getConfiguration()), new GenericDatumReader<>(STATS_SCHEMA_2))) {        for (GenericData.Record record : reader) {            counts.put(((Utf8) record.get("name1")).toString(), (Integer) record.get("count1"));        }    }    Assert.assertEquals(3, counts.get("apple").intValue());    Assert.assertEquals(2, counts.get("banana").intValue());    Assert.assertEquals(1, counts.get("carrot").intValue());    outputFiles = fileSystem.globStatus(outputPath.suffix("/testnewwrite-r-00000.avro"));    Assert.assertEquals(1, outputFiles.length);    counts.clear();    try (DataFileReader<GenericData.Record> reader = new DataFileReader<>(new FsInput(outputFiles[0].getPath(), job.getConfiguration()), new GenericDatumReader<>(STATS_SCHEMA))) {        for (GenericData.Record record : reader) {            counts.put(((Utf8) record.get("name")).toString(), (Integer) record.get("count"));        }    }    Assert.assertEquals(3, counts.get("apple").intValue());    Assert.assertEquals(2, counts.get("banana").intValue());    Assert.assertEquals(1, counts.get("carrot").intValue());    outputFiles = fileSystem.globStatus(outputPath.suffix("/testnewwrite2-r-00000.avro"));    Assert.assertEquals(1, outputFiles.length);    counts.clear();    try (DataFileReader<GenericData.Record> reader = new DataFileReader<>(new FsInput(outputFiles[0].getPath(), job.getConfiguration()), new GenericDatumReader<>(STATS_SCHEMA_2))) {        for (GenericData.Record record : reader) {            counts.put(((Utf8) record.get("name1")).toString(), (Integer) record.get("count1"));        }    }    Assert.assertEquals(3, counts.get("apple").intValue());    Assert.assertEquals(2, counts.get("banana").intValue());    Assert.assertEquals(1, counts.get("carrot").intValue());    outputFiles = fileSystem.globStatus(outputPath.suffix("/testwritenonschema-r-00000.avro"));    Assert.assertEquals(1, outputFiles.length);    counts.clear();    try (DataFileReader<GenericData.Record> reader = new DataFileReader<>(new FsInput(outputFiles[0].getPath(), job.getConfiguration()), new GenericDatumReader<>(STATS_SCHEMA))) {        for (GenericData.Record record : reader) {            counts.put(((Utf8) record.get("name")).toString(), (Integer) record.get("count"));        }    }    Assert.assertEquals(3, counts.get("apple").intValue());    Assert.assertEquals(2, counts.get("banana").intValue());    Assert.assertEquals(1, counts.get("carrot").intValue());}
0
public void testAvroSpecificOutput() throws Exception
{    Job job = Job.getInstance();    FileInputFormat.setInputPaths(job, new Path(getClass().getResource("/org/apache/avro/mapreduce/mapreduce-test-input.txt").toURI().toString()));    job.setInputFormatClass(TextInputFormat.class);    job.setMapperClass(LineCountMapper.class);    job.setMapOutputKeyClass(Text.class);    job.setMapOutputValueClass(IntWritable.class);    AvroMultipleOutputs.addNamedOutput(job, "myavro3", AvroKeyOutputFormat.class, TextStats.SCHEMA$, null);    job.setReducerClass(SpecificStatsReducer.class);    AvroJob.setOutputKeySchema(job, TextStats.SCHEMA$);    job.setOutputFormatClass(AvroKeyOutputFormat.class);    Path outputPath = new Path(DIR.getRoot().getPath() + "/testAvroSpecificOutput");    outputPath.getFileSystem(job.getConfiguration()).delete(outputPath, true);    FileOutputFormat.setOutputPath(job, outputPath);    Assert.assertTrue(job.waitForCompletion(true));    FileSystem fileSystem = FileSystem.get(job.getConfiguration());    FileStatus[] outputFiles = fileSystem.globStatus(outputPath.suffix("/myavro3-*"));    Assert.assertEquals(1, outputFiles.length);    Map<String, Integer> counts = new HashMap<>();    try (DataFileReader<TextStats> reader = new DataFileReader<>(new FsInput(outputFiles[0].getPath(), job.getConfiguration()), new SpecificDatumReader<>())) {        for (TextStats record : reader) {            counts.put(record.getName().toString(), record.getCount());        }    }    Assert.assertEquals(3, counts.get("apple").intValue());    Assert.assertEquals(2, counts.get("banana").intValue());    Assert.assertEquals(1, counts.get("carrot").intValue());}
0
public void testAvroInput() throws Exception
{    Job job = Job.getInstance();    FileInputFormat.setInputPaths(job, new Path(getClass().getResource("/org/apache/avro/mapreduce/mapreduce-test-input.avro").toURI().toString()));    job.setInputFormatClass(AvroKeyInputFormat.class);    AvroJob.setInputKeySchema(job, TextStats.SCHEMA$);    AvroMultipleOutputs.addNamedOutput(job, "myavro3", AvroKeyOutputFormat.class, TextStats.SCHEMA$, null);    job.setMapperClass(StatCountMapper.class);    job.setMapOutputKeyClass(Text.class);    job.setMapOutputValueClass(IntWritable.class);    job.setReducerClass(SpecificStatsReducer.class);    AvroJob.setOutputKeySchema(job, TextStats.SCHEMA$);    job.setOutputFormatClass(AvroKeyOutputFormat.class);    Path outputPath = new Path(DIR.getRoot().getPath() + "/testAvroInput");    FileOutputFormat.setOutputPath(job, outputPath);    Assert.assertTrue(job.waitForCompletion(true));        FileSystem fileSystem = FileSystem.get(job.getConfiguration());    FileStatus[] outputFiles = fileSystem.globStatus(outputPath.suffix("/myavro3-*"));    Assert.assertEquals(1, outputFiles.length);    Map<String, Integer> counts = new HashMap<>();    try (DataFileReader<TextStats> reader = new DataFileReader<>(new FsInput(outputFiles[0].getPath(), job.getConfiguration()), new SpecificDatumReader<>())) {        for (TextStats record : reader) {            counts.put(record.getName().toString(), record.getCount());        }    }    Assert.assertEquals(3, counts.get("apple").intValue());    Assert.assertEquals(2, counts.get("banana").intValue());    Assert.assertEquals(1, counts.get("carrot").intValue());}
0
public void testAvroMapOutput() throws Exception
{    Job job = Job.getInstance();    FileInputFormat.setInputPaths(job, new Path(getClass().getResource("/org/apache/avro/mapreduce/mapreduce-test-input.avro").toURI().toString()));    job.setInputFormatClass(AvroKeyInputFormat.class);    AvroJob.setInputKeySchema(job, TextStats.SCHEMA$);    job.setMapperClass(SortMapper.class);    AvroJob.setMapOutputKeySchema(job, TextStats.SCHEMA$);    job.setMapOutputValueClass(NullWritable.class);    job.setReducerClass(SortReducer.class);    AvroJob.setOutputKeySchema(job, TextStats.SCHEMA$);    job.setOutputFormatClass(AvroKeyOutputFormat.class);    Path outputPath = new Path(DIR.getRoot().getPath() + "/testAvroMapOutput");    FileOutputFormat.setOutputPath(job, outputPath);    Assert.assertTrue(job.waitForCompletion(true));        FileSystem fileSystem = FileSystem.get(job.getConfiguration());    FileStatus[] outputFiles = fileSystem.globStatus(outputPath.suffix("/part-*"));    Assert.assertEquals(1, outputFiles.length);    Map<String, Integer> counts = new HashMap<>();    try (DataFileReader<TextStats> reader = new DataFileReader<>(new FsInput(outputFiles[0].getPath(), job.getConfiguration()), new SpecificDatumReader<>())) {        for (TextStats record : reader) {            counts.put(record.getName().toString(), record.getCount());        }    }    Assert.assertEquals(3, counts.get("apple").intValue());    Assert.assertEquals(2, counts.get("banana").intValue());    Assert.assertEquals(1, counts.get("carrot").intValue());}
0
protected void setup(Context context)
{    mOne = new IntWritable(1);}
0
protected void map(LongWritable fileByteOffset, Text line, Context context) throws IOException, InterruptedException
{    context.write(line, mOne);}
0
protected void setup(Context context)
{    mCount = new IntWritable(0);    mText = new Text("");}
0
protected void map(AvroKey<TextStats> record, NullWritable ignore, Context context) throws IOException, InterruptedException
{    mCount.set(record.datum().getCount());    mText.set(record.datum().getName().toString());    context.write(mText, mCount);}
0
protected void setup(Context context)
{    mStats = new AvroKey<>(null);    amos = new AvroMultipleOutputs(context);}
0
protected void reduce(Text line, Iterable<IntWritable> counts, Context context) throws IOException, InterruptedException
{    GenericData.Record record = new GenericData.Record(STATS_SCHEMA);    GenericData.Record record2 = new GenericData.Record(STATS_SCHEMA_2);    int sum = 0;    for (IntWritable count : counts) {        sum += count.get();    }    record.put("name", new Utf8(line.toString()));    record.put("count", sum);    mStats.datum(record);    context.write(mStats, NullWritable.get());    amos.sync("myavro", "myavro");    amos.write("myavro", mStats, NullWritable.get());    record2.put("name1", new Utf8(line.toString()));    record2.put("count1", sum);    mStats.datum(record2);    amos.write(mStats, NullWritable.get(), STATS_SCHEMA_2, null, "testnewwrite2");    amos.sync("myavro1", "myavro1");    amos.write("myavro1", mStats);    amos.write(mStats, NullWritable.get(), STATS_SCHEMA, null, "testnewwrite");    amos.write(mStats, NullWritable.get(), "testwritenonschema");}
0
protected void cleanup(Context context) throws IOException, InterruptedException
{    amos.close();}
0
protected void setup(Context context)
{    mStats = new AvroKey<>(null);    amos = new AvroMultipleOutputs(context);}
0
protected void reduce(Text line, Iterable<IntWritable> counts, Context context) throws IOException, InterruptedException
{    TextStats record = new TextStats();    record.setCount(0);    for (IntWritable count : counts) {        record.setCount(record.getCount() + count.get());    }    record.setName(line.toString());    mStats.datum(record);    context.write(mStats, NullWritable.get());    amos.sync("myavro3", "myavro3");    amos.write("myavro3", mStats, NullWritable.get());}
0
protected void cleanup(Context context) throws IOException, InterruptedException
{    amos.close();}
0
protected void map(AvroKey<TextStats> key, NullWritable value, Context context) throws IOException, InterruptedException
{    context.write(key, value);}
0
protected void reduce(AvroKey<TextStats> key, Iterable<NullWritable> ignore, Context context) throws IOException, InterruptedException
{    context.write(key, NullWritable.get());}
0
public void testAvroGenericOutput() throws Exception
{    Job job = Job.getInstance();    FileInputFormat.setInputPaths(job, new Path(getClass().getResource("/org/apache/avro/mapreduce/mapreduce-test-input.txt").toURI().toString()));    job.setInputFormatClass(TextInputFormat.class);    job.setMapperClass(LineCountMapper.class);    job.setMapOutputKeyClass(Text.class);    job.setMapOutputValueClass(IntWritable.class);    job.setReducerClass(GenericStatsReducer.class);    AvroJob.setOutputKeySchema(job, STATS_SCHEMA);    AvroMultipleOutputs.addNamedOutput(job, "myavro", AvroKeyOutputFormat.class, STATS_SCHEMA, null);    AvroMultipleOutputs.addNamedOutput(job, "myavro1", AvroKeyOutputFormat.class, STATS_SCHEMA_2);    job.setOutputFormatClass(AvroKeyOutputFormat.class);    Path outputPath = new Path(tmpFolder.getRoot().getPath() + "/out");    outputPath.getFileSystem(job.getConfiguration()).delete(outputPath, true);    FileOutputFormat.setOutputPath(job, outputPath);    Assert.assertTrue(job.waitForCompletion(true));        FileSystem fileSystem = FileSystem.get(job.getConfiguration());    FileStatus[] outputFiles = fileSystem.globStatus(outputPath.suffix("/myavro-r-00000.avro"));    Assert.assertEquals(1, outputFiles.length);    DataFileReader<GenericData.Record> reader = new DataFileReader<>(new FsInput(outputFiles[0].getPath(), job.getConfiguration()), new GenericDatumReader<>(STATS_SCHEMA));    Map<String, Integer> counts = new HashMap<>();    for (GenericData.Record record : reader) {        counts.put(((Utf8) record.get("name")).toString(), (Integer) record.get("count"));    }    reader.close();    Assert.assertEquals(3, counts.get("apple").intValue());    Assert.assertEquals(2, counts.get("banana").intValue());    Assert.assertEquals(1, counts.get("carrot").intValue());    outputFiles = fileSystem.globStatus(outputPath.suffix("/myavro1-r-00000.avro"));    Assert.assertEquals(1, outputFiles.length);    reader = new DataFileReader<>(new FsInput(outputFiles[0].getPath(), job.getConfiguration()), new GenericDatumReader<>(STATS_SCHEMA_2));    counts = new HashMap<>();    for (GenericData.Record record : reader) {        counts.put(((Utf8) record.get("name1")).toString(), (Integer) record.get("count1"));    }    reader.close();    Assert.assertEquals(3, counts.get("apple").intValue());    Assert.assertEquals(2, counts.get("banana").intValue());    Assert.assertEquals(1, counts.get("carrot").intValue());    outputFiles = fileSystem.globStatus(outputPath.suffix("/testnewwrite-r-00000.avro"));    Assert.assertEquals(1, outputFiles.length);    reader = new DataFileReader<>(new FsInput(outputFiles[0].getPath(), job.getConfiguration()), new GenericDatumReader<>(STATS_SCHEMA));    counts = new HashMap<>();    for (GenericData.Record record : reader) {        counts.put(((Utf8) record.get("name")).toString(), (Integer) record.get("count"));    }    reader.close();    Assert.assertEquals(3, counts.get("apple").intValue());    Assert.assertEquals(2, counts.get("banana").intValue());    Assert.assertEquals(1, counts.get("carrot").intValue());    outputFiles = fileSystem.globStatus(outputPath.suffix("/testnewwrite2-r-00000.avro"));    Assert.assertEquals(1, outputFiles.length);    reader = new DataFileReader<>(new FsInput(outputFiles[0].getPath(), job.getConfiguration()), new GenericDatumReader<>(STATS_SCHEMA_2));    counts = new HashMap<>();    for (GenericData.Record record : reader) {        counts.put(((Utf8) record.get("name1")).toString(), (Integer) record.get("count1"));    }    reader.close();    Assert.assertEquals(3, counts.get("apple").intValue());    Assert.assertEquals(2, counts.get("banana").intValue());    Assert.assertEquals(1, counts.get("carrot").intValue());    outputFiles = fileSystem.globStatus(outputPath.suffix("/testwritenonschema-r-00000.avro"));    Assert.assertEquals(1, outputFiles.length);    reader = new DataFileReader<>(new FsInput(outputFiles[0].getPath(), job.getConfiguration()), new GenericDatumReader<>(STATS_SCHEMA));    counts = new HashMap<>();    for (GenericData.Record record : reader) {        counts.put(((Utf8) record.get("name")).toString(), (Integer) record.get("count"));    }    reader.close();    Assert.assertEquals(3, counts.get("apple").intValue());    Assert.assertEquals(2, counts.get("banana").intValue());    Assert.assertEquals(1, counts.get("carrot").intValue());}
0
public void testAvroSpecificOutput() throws Exception
{    Job job = Job.getInstance();    FileInputFormat.setInputPaths(job, new Path(getClass().getResource("/org/apache/avro/mapreduce/mapreduce-test-input.txt").toURI().toString()));    job.setInputFormatClass(TextInputFormat.class);    job.setMapperClass(LineCountMapper.class);    job.setMapOutputKeyClass(Text.class);    job.setMapOutputValueClass(IntWritable.class);    AvroMultipleOutputs.addNamedOutput(job, "myavro3", AvroKeyOutputFormat.class, TextStats.SCHEMA$, null);    job.setReducerClass(SpecificStatsReducer.class);    AvroJob.setOutputKeySchema(job, TextStats.SCHEMA$);    job.setOutputFormatClass(AvroKeyOutputFormat.class);    Path outputPath = new Path(tmpFolder.getRoot().getPath() + "/out-specific");    outputPath.getFileSystem(job.getConfiguration()).delete(outputPath, true);    FileOutputFormat.setOutputPath(job, outputPath);    Assert.assertTrue(job.waitForCompletion(true));    FileSystem fileSystem = FileSystem.get(job.getConfiguration());    FileStatus[] outputFiles = fileSystem.globStatus(outputPath.suffix("/myavro3-*"));    Assert.assertEquals(1, outputFiles.length);    DataFileReader<TextStats> reader = new DataFileReader<>(new FsInput(outputFiles[0].getPath(), job.getConfiguration()), new SpecificDatumReader<>());    Map<String, Integer> counts = new HashMap<>();    for (TextStats record : reader) {        counts.put(record.getName().toString(), record.getCount());    }    reader.close();    Assert.assertEquals(3, counts.get("apple").intValue());    Assert.assertEquals(2, counts.get("banana").intValue());    Assert.assertEquals(1, counts.get("carrot").intValue());}
0
public void testAvroInput() throws Exception
{    Job job = Job.getInstance();    FileInputFormat.setInputPaths(job, new Path(getClass().getResource("/org/apache/avro/mapreduce/mapreduce-test-input.avro").toURI().toString()));    job.setInputFormatClass(AvroKeyInputFormat.class);    AvroJob.setInputKeySchema(job, TextStats.SCHEMA$);    AvroMultipleOutputs.addNamedOutput(job, "myavro3", AvroKeyOutputFormat.class, TextStats.SCHEMA$, null);    job.setMapperClass(StatCountMapper.class);    job.setMapOutputKeyClass(Text.class);    job.setMapOutputValueClass(IntWritable.class);    job.setReducerClass(SpecificStatsReducer.class);    AvroJob.setOutputKeySchema(job, TextStats.SCHEMA$);    job.setOutputFormatClass(AvroKeyOutputFormat.class);    Path outputPath = new Path(tmpFolder.getRoot().getPath() + "/out-specific-input");    FileOutputFormat.setOutputPath(job, outputPath);    Assert.assertTrue(job.waitForCompletion(true));        FileSystem fileSystem = FileSystem.get(job.getConfiguration());    FileStatus[] outputFiles = fileSystem.globStatus(outputPath.suffix("/myavro3-*"));    Assert.assertEquals(1, outputFiles.length);    DataFileReader<TextStats> reader = new DataFileReader<>(new FsInput(outputFiles[0].getPath(), job.getConfiguration()), new SpecificDatumReader<>());    Map<String, Integer> counts = new HashMap<>();    for (TextStats record : reader) {        counts.put(record.getName().toString(), record.getCount());    }    reader.close();    Assert.assertEquals(3, counts.get("apple").intValue());    Assert.assertEquals(2, counts.get("banana").intValue());    Assert.assertEquals(1, counts.get("carrot").intValue());}
0
public void testAvroMapOutput() throws Exception
{    Job job = Job.getInstance();    FileInputFormat.setInputPaths(job, new Path(getClass().getResource("/org/apache/avro/mapreduce/mapreduce-test-input.avro").toURI().toString()));    job.setInputFormatClass(AvroKeyInputFormat.class);    AvroJob.setInputKeySchema(job, TextStats.SCHEMA$);    job.setMapperClass(SortMapper.class);    AvroJob.setMapOutputKeySchema(job, TextStats.SCHEMA$);    job.setMapOutputValueClass(NullWritable.class);    job.setReducerClass(SortReducer.class);    AvroJob.setOutputKeySchema(job, TextStats.SCHEMA$);    job.setOutputFormatClass(AvroKeyOutputFormat.class);    Path outputPath = new Path(tmpFolder.getRoot().getPath() + "/out-specific-input");    FileOutputFormat.setOutputPath(job, outputPath);    Assert.assertTrue(job.waitForCompletion(true));        FileSystem fileSystem = FileSystem.get(job.getConfiguration());    FileStatus[] outputFiles = fileSystem.globStatus(outputPath.suffix("/part-*"));    Assert.assertEquals(1, outputFiles.length);    DataFileReader<TextStats> reader = new DataFileReader<>(new FsInput(outputFiles[0].getPath(), job.getConfiguration()), new SpecificDatumReader<>());    Map<String, Integer> counts = new HashMap<>();    for (TextStats record : reader) {        counts.put(record.getName().toString(), record.getCount());    }    reader.close();    Assert.assertEquals(3, counts.get("apple").intValue());    Assert.assertEquals(2, counts.get("banana").intValue());    Assert.assertEquals(1, counts.get("carrot").intValue());}
0
public void testReadRecords() throws IOException, InterruptedException, ClassNotFoundException
{    Schema keyValueSchema = AvroKeyValue.getSchema(Schema.create(Schema.Type.INT), Schema.create(Schema.Type.STRING));    AvroKeyValue<Integer, CharSequence> record1 = new AvroKeyValue<>(new GenericData.Record(keyValueSchema));    record1.setKey(1);    record1.setValue("apple banana carrot");    AvroFiles.createFile(new File(mTempDir.getRoot(), "combineSplit00.avro"), keyValueSchema, record1.get());    AvroKeyValue<Integer, CharSequence> record2 = new AvroKeyValue<>(new GenericData.Record(keyValueSchema));    record2.setKey(2);    record2.setValue("apple banana");    AvroFiles.createFile(new File(mTempDir.getRoot(), "combineSplit01.avro"), keyValueSchema, record2.get());        Job job = Job.getInstance();    FileInputFormat.setInputPaths(job, new Path(mTempDir.getRoot().getAbsolutePath()));    job.setInputFormatClass(CombineAvroKeyValueFileInputFormat.class);    AvroJob.setInputKeySchema(job, Schema.create(Schema.Type.INT));    AvroJob.setInputValueSchema(job, Schema.create(Schema.Type.STRING));        AvroJob.setMapOutputKeySchema(job, Schema.create(Schema.Type.INT));    AvroJob.setMapOutputValueSchema(job, Schema.create(Schema.Type.STRING));        job.setNumReduceTasks(0);    job.setOutputKeyClass(AvroKey.class);    job.setOutputValueClass(AvroValue.class);        job.setOutputFormatClass(AvroKeyValueOutputFormat.class);    Path outputPath = new Path(mTempDir.getRoot().getPath(), "out");    FileOutputFormat.setOutputPath(job, outputPath);        assertTrue(job.waitForCompletion(true));        File avroFile = new File(outputPath.toString(), "part-m-00000.avro");    DatumReader<GenericRecord> datumReader = new SpecificDatumReader<>(AvroKeyValue.getSchema(Schema.create(Schema.Type.INT), Schema.create(Schema.Type.STRING)));    DataFileReader<GenericRecord> avroFileReader = new DataFileReader<>(avroFile, datumReader);    assertTrue(avroFileReader.hasNext());    while (avroFileReader.hasNext()) {        AvroKeyValue<Integer, CharSequence> mapRecord1 = new AvroKeyValue<>(avroFileReader.next());        assertNotNull(mapRecord1.get());        if (mapRecord1.getKey().intValue() == 1) {            assertEquals("apple banana carrot", mapRecord1.getValue().toString());        } else if (mapRecord1.getKey().intValue() == 2) {            assertEquals("apple banana", mapRecord1.getValue().toString());        } else {            fail("Unknown key " + mapRecord1.getKey().intValue());        }    }}
0
public void setUp() throws Exception
{    conf = new Configuration();    conf.set("fs.default.name", "file:///");    file = new File(DIR.getRoot(), "file.txt");    try (PrintWriter out = new PrintWriter(new OutputStreamWriter(new FileOutputStream(file), StandardCharsets.UTF_8))) {        out.print(FILE_CONTENTS);    }    fsInput = new FsInput(new Path(file.getPath()), conf);}
0
public void tearDown() throws Exception
{    if (fsInput != null) {        fsInput.close();    }}
0
public void testConfigurationConstructor() throws Exception
{    try (FsInput in = new FsInput(new Path(file.getPath()), conf)) {        int expectedByteCount = 1;        byte[] readBytes = new byte[expectedByteCount];        int actualByteCount = fsInput.read(readBytes, 0, expectedByteCount);        assertThat(actualByteCount, is(equalTo(expectedByteCount)));    }}
0
public void testFileSystemConstructor() throws Exception
{    Path path = new Path(file.getPath());    FileSystem fs = path.getFileSystem(conf);    try (FsInput in = new FsInput(path, fs)) {        int expectedByteCount = 1;        byte[] readBytes = new byte[expectedByteCount];        int actualByteCount = fsInput.read(readBytes, 0, expectedByteCount);        assertThat(actualByteCount, is(equalTo(expectedByteCount)));    }}
0
public void testLength() throws IOException
{    assertEquals(fsInput.length(), FILE_CONTENTS.length());}
0
public void testRead() throws Exception
{    byte[] expectedBytes = FILE_CONTENTS.getBytes(StandardCharsets.UTF_8);    byte[] actualBytes = new byte[expectedBytes.length];    int actualByteCount = fsInput.read(actualBytes, 0, actualBytes.length);    assertThat(actualBytes, is(equalTo(expectedBytes)));    assertThat(actualByteCount, is(equalTo(expectedBytes.length)));}
0
public void testSeek() throws Exception
{    int seekPos = FILE_CONTENTS.length() / 2;    byte[] fileContentBytes = FILE_CONTENTS.getBytes(StandardCharsets.UTF_8);    byte expectedByte = fileContentBytes[seekPos];    fsInput.seek(seekPos);    byte[] readBytes = new byte[1];    fsInput.read(readBytes, 0, 1);    byte actualByte = readBytes[0];    assertThat(actualByte, is(equalTo(expectedByte)));}
0
public void testTell() throws Exception
{    long expectedTellPos = FILE_CONTENTS.length() / 2;    fsInput.seek(expectedTellPos);    long actualTellPos = fsInput.tell();    assertThat(actualTellPos, is(equalTo(expectedTellPos)));}
0
private File createInputFile() throws IOException
{    Schema keyValueSchema = AvroKeyValue.getSchema(Schema.create(Schema.Type.INT), Schema.create(Schema.Type.STRING));    AvroKeyValue<Integer, CharSequence> record1 = new AvroKeyValue<>(new GenericData.Record(keyValueSchema));    record1.setKey(1);    record1.setValue("apple banana carrot");    AvroKeyValue<Integer, CharSequence> record2 = new AvroKeyValue<>(new GenericData.Record(keyValueSchema));    record2.setKey(2);    record2.setValue("apple banana");    AvroKeyValue<Integer, CharSequence> record3 = new AvroKeyValue<>(new GenericData.Record(keyValueSchema));    record3.setKey(3);    record3.setValue("apple");    return AvroFiles.createFile(new File(mTempDir.getRoot(), "inputKeyValues.avro"), keyValueSchema, record1.get(), record2.get(), record3.get());}
0
protected void map(AvroKey<Integer> docid, AvroValue<CharSequence> body, Context context) throws IOException, InterruptedException
{    for (String token : body.datum().toString().split(" ")) {        context.write(new Text(token), new IntWritable(docid.datum()));    }}
0
protected void reduce(Text token, Iterable<IntWritable> docids, Context context) throws IOException, InterruptedException
{    List<Integer> hitlist = new ArrayList<>();    for (IntWritable docid : docids) {        hitlist.add(docid.get());    }    context.write(token, new AvroValue<>(hitlist));}
0
public void testKeyValueInput() throws ClassNotFoundException, IOException, InterruptedException
{        File inputFile = createInputFile();        Job job = Job.getInstance();    FileInputFormat.setInputPaths(job, new Path(inputFile.getAbsolutePath()));    job.setInputFormatClass(AvroKeyValueInputFormat.class);    AvroJob.setInputKeySchema(job, Schema.create(Schema.Type.INT));    AvroJob.setInputValueSchema(job, Schema.create(Schema.Type.STRING));        job.setMapperClass(IndexMapper.class);    job.setMapOutputKeyClass(Text.class);    job.setMapOutputValueClass(IntWritable.class);        job.setReducerClass(IndexReducer.class);    job.setOutputKeyClass(Text.class);    job.setOutputValueClass(AvroValue.class);    AvroJob.setOutputValueSchema(job, Schema.createArray(Schema.create(Schema.Type.INT)));        job.setOutputFormatClass(AvroKeyValueOutputFormat.class);    Path outputPath = new Path(mTempDir.getRoot().getPath(), "out-index");    FileOutputFormat.setOutputPath(job, outputPath);        assertTrue(job.waitForCompletion(true));        File avroFile = new File(outputPath.toString(), "part-r-00000.avro");    DatumReader<GenericRecord> datumReader = new SpecificDatumReader<>(AvroKeyValue.getSchema(Schema.create(Schema.Type.STRING), Schema.createArray(Schema.create(Schema.Type.INT))));    DataFileReader<GenericRecord> avroFileReader = new DataFileReader<>(avroFile, datumReader);    assertTrue(avroFileReader.hasNext());    AvroKeyValue<CharSequence, List<Integer>> appleRecord = new AvroKeyValue<>(avroFileReader.next());    assertNotNull(appleRecord.get());    assertEquals("apple", appleRecord.getKey().toString());    List<Integer> appleDocs = appleRecord.getValue();    assertEquals(3, appleDocs.size());    assertTrue(appleDocs.contains(1));    assertTrue(appleDocs.contains(2));    assertTrue(appleDocs.contains(3));    assertTrue(avroFileReader.hasNext());    AvroKeyValue<CharSequence, List<Integer>> bananaRecord = new AvroKeyValue<>(avroFileReader.next());    assertNotNull(bananaRecord.get());    assertEquals("banana", bananaRecord.getKey().toString());    List<Integer> bananaDocs = bananaRecord.getValue();    assertEquals(2, bananaDocs.size());    assertTrue(bananaDocs.contains(1));    assertTrue(bananaDocs.contains(2));    assertTrue(avroFileReader.hasNext());    AvroKeyValue<CharSequence, List<Integer>> carrotRecord = new AvroKeyValue<>(avroFileReader.next());    assertEquals("carrot", carrotRecord.getKey().toString());    List<Integer> carrotDocs = carrotRecord.getValue();    assertEquals(1, carrotDocs.size());    assertTrue(carrotDocs.contains(1));    assertFalse(avroFileReader.hasNext());    avroFileReader.close();}
0
public void testKeyValueInputMapOnly() throws ClassNotFoundException, IOException, InterruptedException
{        File inputFile = createInputFile();        Job job = Job.getInstance();    FileInputFormat.setInputPaths(job, new Path(inputFile.getAbsolutePath()));    job.setInputFormatClass(AvroKeyValueInputFormat.class);    AvroJob.setInputKeySchema(job, Schema.create(Schema.Type.INT));    AvroJob.setInputValueSchema(job, Schema.create(Schema.Type.STRING));        AvroJob.setMapOutputKeySchema(job, Schema.create(Schema.Type.INT));    AvroJob.setMapOutputValueSchema(job, Schema.create(Schema.Type.STRING));        job.setNumReduceTasks(0);    job.setOutputKeyClass(AvroKey.class);    job.setOutputValueClass(AvroValue.class);        job.setOutputFormatClass(AvroKeyValueOutputFormat.class);    Path outputPath = new Path(mTempDir.getRoot().getPath(), "out-index");    FileOutputFormat.setOutputPath(job, outputPath);        assertTrue(job.waitForCompletion(true));        File avroFile = new File(outputPath.toString(), "part-m-00000.avro");    DatumReader<GenericRecord> datumReader = new SpecificDatumReader<>(AvroKeyValue.getSchema(Schema.create(Schema.Type.INT), Schema.create(Schema.Type.STRING)));    DataFileReader<GenericRecord> avroFileReader = new DataFileReader<>(avroFile, datumReader);    assertTrue(avroFileReader.hasNext());    AvroKeyValue<Integer, CharSequence> record1 = new AvroKeyValue<>(avroFileReader.next());    assertNotNull(record1.get());    assertEquals(1, record1.getKey().intValue());    assertEquals("apple banana carrot", record1.getValue().toString());    assertTrue(avroFileReader.hasNext());    AvroKeyValue<Integer, CharSequence> record2 = new AvroKeyValue<>(avroFileReader.next());    assertNotNull(record2.get());    assertEquals(2, record2.getKey().intValue());    assertEquals("apple banana", record2.getValue().toString());    assertTrue(avroFileReader.hasNext());    AvroKeyValue<Integer, CharSequence> record3 = new AvroKeyValue<>(avroFileReader.next());    assertNotNull(record3.get());    assertEquals(3, record3.getKey().intValue());    assertEquals("apple", record3.getValue().toString());    assertFalse(avroFileReader.hasNext());    avroFileReader.close();}
0
protected void setup(Context context)
{    mOne = new IntWritable(1);}
0
protected void map(LongWritable fileByteOffset, Text line, Context context) throws IOException, InterruptedException
{    context.write(line, mOne);}
0
protected void reduce(Text word, Iterable<IntWritable> counts, Context context) throws IOException, InterruptedException
{    int sum = 0;    for (IntWritable count : counts) {        sum += count.get();    }    context.write(word, new IntWritable(sum));}
0
public void testKeyValueMapReduce() throws ClassNotFoundException, IOException, InterruptedException, URISyntaxException
{        Job job = Job.getInstance();    FileInputFormat.setInputPaths(job, new Path(getClass().getResource("/org/apache/avro/mapreduce/mapreduce-test-input.txt").toURI().toString()));    job.setInputFormatClass(TextInputFormat.class);    job.setMapperClass(LineCountMapper.class);    job.setMapOutputKeyClass(Text.class);    job.setMapOutputValueClass(IntWritable.class);    job.setReducerClass(IntSumReducer.class);    job.setOutputKeyClass(Text.class);    job.setOutputValueClass(IntWritable.class);    job.setOutputFormatClass(AvroKeyValueOutputFormat.class);    Path outputPath = new Path(mTempDir.getRoot().getPath() + "/out-wordcount");    FileOutputFormat.setOutputPath(job, outputPath);        assertTrue(job.waitForCompletion(true));            File avroFile = new File(outputPath.toString(), "part-r-00000.avro");    DatumReader<GenericRecord> datumReader = new SpecificDatumReader<>(AvroKeyValue.getSchema(Schema.create(Schema.Type.STRING), Schema.create(Schema.Type.INT)));    DataFileReader<GenericRecord> avroFileReader = new DataFileReader<>(avroFile, datumReader);    assertTrue(avroFileReader.hasNext());    AvroKeyValue<CharSequence, Integer> appleRecord = new AvroKeyValue<>(avroFileReader.next());    assertNotNull(appleRecord.get());    assertEquals("apple", appleRecord.getKey().toString());    assertEquals(3, appleRecord.getValue().intValue());    assertTrue(avroFileReader.hasNext());    AvroKeyValue<CharSequence, Integer> bananaRecord = new AvroKeyValue<>(avroFileReader.next());    assertNotNull(bananaRecord.get());    assertEquals("banana", bananaRecord.getKey().toString());    assertEquals(2, bananaRecord.getValue().intValue());    assertTrue(avroFileReader.hasNext());    AvroKeyValue<CharSequence, Integer> carrotRecord = new AvroKeyValue<>(avroFileReader.next());    assertEquals("carrot", carrotRecord.getKey().toString());    assertEquals(1, carrotRecord.getValue().intValue());    assertFalse(avroFileReader.hasNext());    avroFileReader.close();}
0
protected void setup(Context context)
{    mOne = new IntWritable(1);}
0
protected void map(LongWritable fileByteOffset, Text line, Context context) throws IOException, InterruptedException
{    context.write(line, mOne);}
0
protected void setup(Context context)
{    mCount = new IntWritable(0);    mText = new Text("");}
0
protected void map(AvroKey<TextStats> record, NullWritable ignore, Context context) throws IOException, InterruptedException
{    mCount.set(record.datum().getCount());    mText.set(record.datum().getName().toString());    context.write(mText, mCount);}
0
protected void setup(Context context)
{    mCount = new IntWritable(0);    mText = new Text("");}
0
protected void map(AvroKey<ReflectStats> record, NullWritable ignore, Context context) throws IOException, InterruptedException
{    mCount.set(record.datum().count);    mText.set(record.datum().name);    context.write(mText, mCount);}
0
protected void reduce(Text key, Iterable<IntWritable> counts, Context context) throws IOException, InterruptedException
{    int sum = 0;    for (IntWritable count : counts) {        sum += count.get();    }    context.write(new AvroKey<>(key.toString()), new AvroValue<>(sum));}
0
protected void setup(Context context)
{    mStats = new AvroKey<>(null);}
0
protected void reduce(Text line, Iterable<IntWritable> counts, Context context) throws IOException, InterruptedException
{    GenericData.Record record = new GenericData.Record(STATS_SCHEMA);    int sum = 0;    for (IntWritable count : counts) {        sum += count.get();    }    record.put("name", new Utf8(line.toString()));    record.put("count", sum);    mStats.datum(record);    context.write(mStats, NullWritable.get());}
0
protected void setup(Context context)
{    mStats = new AvroKey<>(null);}
0
protected void reduce(Text line, Iterable<IntWritable> counts, Context context) throws IOException, InterruptedException
{    TextStats record = new TextStats();    record.setCount(0);    for (IntWritable count : counts) {        record.setCount(record.getCount() + count.get());    }    record.setName(line.toString());    mStats.datum(record);    context.write(mStats, NullWritable.get());}
0
protected void setup(Context context)
{    mStats = new AvroKey<>(null);}
0
protected void reduce(Text line, Iterable<IntWritable> counts, Context context) throws IOException, InterruptedException
{    ReflectStats record = new ReflectStats();    record.count = 0;    for (IntWritable count : counts) {        record.count += count.get();    }    record.name = line.toString();    mStats.datum(record);    context.write(mStats, NullWritable.get());}
0
protected void map(AvroKey<TextStats> key, NullWritable value, Context context) throws IOException, InterruptedException
{    context.write(key, value);}
0
protected void reduce(AvroKey<TextStats> key, Iterable<NullWritable> ignore, Context context) throws IOException, InterruptedException
{    context.write(key, NullWritable.get());}
0
public void testAvroGenericOutput() throws Exception
{    Job job = Job.getInstance();    FileInputFormat.setInputPaths(job, new Path(getClass().getResource("/org/apache/avro/mapreduce/mapreduce-test-input.txt").toURI().toString()));    job.setInputFormatClass(TextInputFormat.class);    job.setMapperClass(LineCountMapper.class);    job.setMapOutputKeyClass(Text.class);    job.setMapOutputValueClass(IntWritable.class);    job.setReducerClass(GenericStatsReducer.class);    AvroJob.setOutputKeySchema(job, STATS_SCHEMA);    job.setOutputFormatClass(AvroKeyOutputFormat.class);    Path outputPath = new Path(tmpFolder.getRoot().getPath() + "/out-generic");    FileOutputFormat.setOutputPath(job, outputPath);    Assert.assertTrue(job.waitForCompletion(true));        FileSystem fileSystem = FileSystem.get(job.getConfiguration());    FileStatus[] outputFiles = fileSystem.globStatus(outputPath.suffix("/part-*"));    Assert.assertEquals(1, outputFiles.length);    DataFileReader<GenericData.Record> reader = new DataFileReader<>(new FsInput(outputFiles[0].getPath(), job.getConfiguration()), new GenericDatumReader<>(STATS_SCHEMA));    Map<String, Integer> counts = new HashMap<>();    for (GenericData.Record record : reader) {        counts.put(((Utf8) record.get("name")).toString(), (Integer) record.get("count"));    }    reader.close();    Assert.assertEquals(3, counts.get("apple").intValue());    Assert.assertEquals(2, counts.get("banana").intValue());    Assert.assertEquals(1, counts.get("carrot").intValue());}
0
public void testAvroSpecificOutput() throws Exception
{    Job job = Job.getInstance();    FileInputFormat.setInputPaths(job, new Path(getClass().getResource("/org/apache/avro/mapreduce/mapreduce-test-input.txt").toURI().toString()));    job.setInputFormatClass(TextInputFormat.class);    job.setMapperClass(LineCountMapper.class);    job.setMapOutputKeyClass(Text.class);    job.setMapOutputValueClass(IntWritable.class);    job.setReducerClass(SpecificStatsReducer.class);    AvroJob.setOutputKeySchema(job, TextStats.SCHEMA$);    job.setOutputFormatClass(AvroKeyOutputFormat.class);    Path outputPath = new Path(tmpFolder.getRoot().getPath() + "/out-specific");    FileOutputFormat.setOutputPath(job, outputPath);    Assert.assertTrue(job.waitForCompletion(true));        FileSystem fileSystem = FileSystem.get(job.getConfiguration());    FileStatus[] outputFiles = fileSystem.globStatus(outputPath.suffix("/part-*"));    Assert.assertEquals(1, outputFiles.length);    DataFileReader<TextStats> reader = new DataFileReader<>(new FsInput(outputFiles[0].getPath(), job.getConfiguration()), new SpecificDatumReader<>());    Map<String, Integer> counts = new HashMap<>();    for (TextStats record : reader) {        counts.put(record.getName().toString(), record.getCount());    }    reader.close();    Assert.assertEquals(3, counts.get("apple").intValue());    Assert.assertEquals(2, counts.get("banana").intValue());    Assert.assertEquals(1, counts.get("carrot").intValue());}
0
public void testAvroReflectOutput() throws Exception
{    Job job = Job.getInstance();    FileInputFormat.setInputPaths(job, new Path(getClass().getResource("/org/apache/avro/mapreduce/mapreduce-test-input.txt").toURI().toString()));    job.setInputFormatClass(TextInputFormat.class);    job.setMapperClass(LineCountMapper.class);    job.setMapOutputKeyClass(Text.class);    job.setMapOutputValueClass(IntWritable.class);    job.setReducerClass(ReflectStatsReducer.class);    AvroJob.setOutputKeySchema(job, REFLECT_STATS_SCHEMA);    job.setOutputFormatClass(AvroKeyOutputFormat.class);    Path outputPath = new Path(tmpFolder.getRoot().getPath() + "/out-reflect");    FileOutputFormat.setOutputPath(job, outputPath);    Assert.assertTrue(job.waitForCompletion(true));        FileSystem fileSystem = FileSystem.get(job.getConfiguration());    FileStatus[] outputFiles = fileSystem.globStatus(outputPath.suffix("/part-*"));    Assert.assertEquals(1, outputFiles.length);    DataFileReader<ReflectStats> reader = new DataFileReader<>(new FsInput(outputFiles[0].getPath(), job.getConfiguration()), new ReflectDatumReader<>());    Map<String, Integer> counts = new HashMap<>();    for (ReflectStats record : reader) {        counts.put(record.name, record.count);    }    reader.close();    Assert.assertEquals(3, counts.get("apple").intValue());    Assert.assertEquals(2, counts.get("banana").intValue());    Assert.assertEquals(1, counts.get("carrot").intValue());}
0
public void testAvroInput() throws Exception
{    Job job = Job.getInstance();    FileInputFormat.setInputPaths(job, new Path(getClass().getResource("/org/apache/avro/mapreduce/mapreduce-test-input.avro").toURI().toString()));    job.setInputFormatClass(AvroKeyInputFormat.class);    AvroJob.setInputKeySchema(job, TextStats.SCHEMA$);    job.setMapperClass(StatCountMapper.class);    job.setMapOutputKeyClass(Text.class);    job.setMapOutputValueClass(IntWritable.class);    job.setReducerClass(SpecificStatsReducer.class);    AvroJob.setOutputKeySchema(job, TextStats.SCHEMA$);    job.setOutputFormatClass(AvroKeyOutputFormat.class);    Path outputPath = new Path(tmpFolder.getRoot().getPath() + "/out-specific-input");    FileOutputFormat.setOutputPath(job, outputPath);    Assert.assertTrue(job.waitForCompletion(true));        FileSystem fileSystem = FileSystem.get(job.getConfiguration());    FileStatus[] outputFiles = fileSystem.globStatus(outputPath.suffix("/part-*"));    Assert.assertEquals(1, outputFiles.length);    DataFileReader<TextStats> reader = new DataFileReader<>(new FsInput(outputFiles[0].getPath(), job.getConfiguration()), new SpecificDatumReader<>());    Map<String, Integer> counts = new HashMap<>();    for (TextStats record : reader) {        counts.put(record.getName().toString(), record.getCount());    }    reader.close();    Assert.assertEquals(3, counts.get("apple").intValue());    Assert.assertEquals(2, counts.get("banana").intValue());    Assert.assertEquals(1, counts.get("carrot").intValue());}
0
public void testReflectInput() throws Exception
{    Job job = Job.getInstance();    FileInputFormat.setInputPaths(job, new Path(getClass().getResource("/org/apache/avro/mapreduce/mapreduce-test-input.avro").toURI().toString()));    job.setInputFormatClass(AvroKeyInputFormat.class);    AvroJob.setInputKeySchema(job, REFLECT_STATS_SCHEMA);    job.setMapperClass(ReflectCountMapper.class);    job.setMapOutputKeyClass(Text.class);    job.setMapOutputValueClass(IntWritable.class);    job.setReducerClass(ReflectStatsReducer.class);    AvroJob.setOutputKeySchema(job, REFLECT_STATS_SCHEMA);    job.setOutputFormatClass(AvroKeyOutputFormat.class);    Path outputPath = new Path(tmpFolder.getRoot().getPath() + "/out-reflect-input");    FileOutputFormat.setOutputPath(job, outputPath);    Assert.assertTrue(job.waitForCompletion(true));        FileSystem fileSystem = FileSystem.get(job.getConfiguration());    FileStatus[] outputFiles = fileSystem.globStatus(outputPath.suffix("/part-*"));    Assert.assertEquals(1, outputFiles.length);    DataFileReader<ReflectStats> reader = new DataFileReader<>(new FsInput(outputFiles[0].getPath(), job.getConfiguration()), new ReflectDatumReader<>());    Map<String, Integer> counts = new HashMap<>();    for (ReflectStats record : reader) {        counts.put(record.name, record.count);    }    reader.close();    Assert.assertEquals(3, counts.get("apple").intValue());    Assert.assertEquals(2, counts.get("banana").intValue());    Assert.assertEquals(1, counts.get("carrot").intValue());}
0
public void testAvroMapOutput() throws Exception
{    Job job = Job.getInstance();    FileInputFormat.setInputPaths(job, new Path(getClass().getResource("/org/apache/avro/mapreduce/mapreduce-test-input.avro").toURI().toString()));    job.setInputFormatClass(AvroKeyInputFormat.class);    AvroJob.setInputKeySchema(job, TextStats.SCHEMA$);    job.setMapperClass(SortMapper.class);    AvroJob.setMapOutputKeySchema(job, TextStats.SCHEMA$);    job.setMapOutputValueClass(NullWritable.class);    job.setReducerClass(SortReducer.class);    AvroJob.setOutputKeySchema(job, TextStats.SCHEMA$);    job.setOutputFormatClass(AvroKeyOutputFormat.class);    Path outputPath = new Path(tmpFolder.getRoot().getPath() + "/out-specific-input");    FileOutputFormat.setOutputPath(job, outputPath);    Assert.assertTrue(job.waitForCompletion(true));        FileSystem fileSystem = FileSystem.get(job.getConfiguration());    FileStatus[] outputFiles = fileSystem.globStatus(outputPath.suffix("/part-*"));    Assert.assertEquals(1, outputFiles.length);    DataFileReader<TextStats> reader = new DataFileReader<>(new FsInput(outputFiles[0].getPath(), job.getConfiguration()), new SpecificDatumReader<>());    Map<String, Integer> counts = new HashMap<>();    for (TextStats record : reader) {        counts.put(record.getName().toString(), record.getCount());    }    reader.close();    Assert.assertEquals(3, counts.get("apple").intValue());    Assert.assertEquals(2, counts.get("banana").intValue());    Assert.assertEquals(1, counts.get("carrot").intValue());}
0
public void testAvroUsingTextFileOutput() throws Exception
{    Job job = Job.getInstance();    FileInputFormat.setInputPaths(job, new Path(getClass().getResource("/org/apache/avro/mapreduce/mapreduce-test-input.txt").toURI().toString()));    job.setInputFormatClass(TextInputFormat.class);    job.setMapperClass(LineCountMapper.class);    job.setMapOutputKeyClass(Text.class);    job.setMapOutputValueClass(IntWritable.class);    job.setReducerClass(AvroSumReducer.class);    AvroJob.setOutputKeySchema(job, Schema.create(Schema.Type.STRING));    AvroJob.setOutputValueSchema(job, Schema.create(Schema.Type.INT));    job.setOutputFormatClass(TextOutputFormat.class);    Path outputPath = new Path(tmpFolder.getRoot().getPath() + "/out-text");    FileOutputFormat.setOutputPath(job, outputPath);    Assert.assertTrue(job.waitForCompletion(true));        FileSystem fileSystem = FileSystem.get(job.getConfiguration());    FileStatus[] outputFiles = fileSystem.globStatus(outputPath.suffix("/part-*"));    Assert.assertEquals(1, outputFiles.length);    Path filePath = outputFiles[0].getPath();    InputStream inputStream = filePath.getFileSystem(job.getConfiguration()).open(filePath);    Assert.assertNotNull(inputStream);    try (BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream))) {        Assert.assertTrue(reader.ready());        Assert.assertEquals("apple\t3", reader.readLine());        Assert.assertEquals("banana\t2", reader.readLine());        Assert.assertEquals("carrot\t1", reader.readLine());        Assert.assertFalse(reader.ready());    }}
0
public void execute() throws MojoExecutionException
{    boolean hasSourceDir = null != sourceDirectory && sourceDirectory.isDirectory();    boolean hasImports = null != imports;    boolean hasTestDir = null != testSourceDirectory && testSourceDirectory.isDirectory();    if (!hasSourceDir && !hasTestDir) {        throw new MojoExecutionException("neither sourceDirectory: " + sourceDirectory + " or testSourceDirectory: " + testSourceDirectory + " are directories");    }    if (hasImports) {        for (String importedFile : imports) {            File file = new File(importedFile);            if (file.isDirectory()) {                String[] includedFiles = getIncludedFiles(file.getAbsolutePath(), excludes, getIncludes());                getLog().info("Importing Directory: " + file.getAbsolutePath());                getLog().debug("Importing Directory Files: " + Arrays.toString(includedFiles));                compileFiles(includedFiles, file, outputDirectory);            } else if (file.isFile()) {                getLog().info("Importing File: " + file.getAbsolutePath());                compileFiles(new String[] { file.getName() }, file.getParentFile(), outputDirectory);            }        }    }    if (hasSourceDir) {        String[] includedFiles = getIncludedFiles(sourceDirectory.getAbsolutePath(), excludes, getIncludes());        compileFiles(includedFiles, sourceDirectory, outputDirectory);    }    if (hasImports || hasSourceDir) {        project.addCompileSourceRoot(outputDirectory.getAbsolutePath());    }    if (hasTestDir) {        String[] includedFiles = getIncludedFiles(testSourceDirectory.getAbsolutePath(), testExcludes, getTestIncludes());        compileFiles(includedFiles, testSourceDirectory, testOutputDirectory);        project.addTestCompileSourceRoot(testOutputDirectory.getAbsolutePath());    }}
0
private String[] getIncludedFiles(String absPath, String[] excludes, String[] includes)
{    final FileSetManager fileSetManager = new FileSetManager();    final FileSet fs = new FileSet();    fs.setDirectory(absPath);    fs.setFollowSymlinks(false);        if (imports != null) {        String importExclude = null;        for (String importFile : this.imports) {            File file = new File(importFile);            if (file.isDirectory()) {                importExclude = file.getName() + "/**";            } else if (file.isFile()) {                importExclude = "**/" + file.getName();            }            fs.addExclude(importExclude);        }    }    for (String include : includes) {        fs.addInclude(include);    }    for (String exclude : excludes) {        fs.addExclude(exclude);    }    return fileSetManager.getIncludedFiles(fs);}
0
private void compileFiles(String[] files, File sourceDir, File outDir) throws MojoExecutionException
{    for (String filename : files) {        try {            doCompile(filename, sourceDir, outDir);        } catch (IOException e) {            throw new MojoExecutionException("Error compiling protocol file " + filename + " to " + outDir, e);        }    }}
0
protected SpecificCompiler.FieldVisibility getFieldVisibility()
{    try {        String upper = String.valueOf(this.fieldVisibility).trim().toUpperCase();        return SpecificCompiler.FieldVisibility.valueOf(upper);    } catch (IllegalArgumentException e) {        return SpecificCompiler.FieldVisibility.PRIVATE;    }}
0
protected List<Object> instantiateAdditionalVelocityTools()
{    final List<Object> velocityTools = new ArrayList<>(velocityToolsClassesNames.length);    for (String velocityToolClassName : velocityToolsClassesNames) {        try {            Class klass = Class.forName(velocityToolClassName);            velocityTools.add(klass.newInstance());        } catch (Exception e) {            throw new RuntimeException(e);        }    }    return velocityTools;}
0
protected URLClassLoader createClassLoader() throws DependencyResolutionRequiredException, MalformedURLException
{    final List<URL> urls = appendElements(project.getRuntimeClasspathElements());    urls.addAll(appendElements(project.getTestClasspathElements()));    return new URLClassLoader(urls.toArray(new URL[0]), Thread.currentThread().getContextClassLoader());}
0
private List<URL> appendElements(List runtimeClasspathElements) throws MalformedURLException
{    List<URL> runtimeUrls = new ArrayList<>();    if (runtimeClasspathElements != null) {        for (Object runtimeClasspathElement : runtimeClasspathElements) {            String element = (String) runtimeClasspathElement;            runtimeUrls.add(new File(element).toURI().toURL());        }    }    return runtimeUrls;}
0
protected void doCompile(String filename, File sourceDirectory, File outputDirectory) throws IOException
{    try {        @SuppressWarnings("rawtypes")        List runtimeClasspathElements = project.getRuntimeClasspathElements();        List<URL> runtimeUrls = new ArrayList<>();                        runtimeUrls.add(sourceDirectory.toURI().toURL());                if (runtimeClasspathElements != null && !runtimeClasspathElements.isEmpty()) {            for (Object runtimeClasspathElement : runtimeClasspathElements) {                String element = (String) runtimeClasspathElement;                runtimeUrls.add(new File(element).toURI().toURL());            }        }        URLClassLoader projPathLoader = new URLClassLoader(runtimeUrls.toArray(new URL[0]), Thread.currentThread().getContextClassLoader());        try (Idl parser = new Idl(new File(sourceDirectory, filename), projPathLoader)) {            Protocol p = parser.CompilationUnit();            String json = p.toString(true);            Protocol protocol = Protocol.parse(json);            final SpecificCompiler compiler = new SpecificCompiler(protocol);            compiler.setStringType(GenericData.StringType.valueOf(stringType));            compiler.setTemplateDir(templateDirectory);            compiler.setFieldVisibility(getFieldVisibility());            compiler.setCreateOptionalGetters(createOptionalGetters);            compiler.setGettersReturnOptional(gettersReturnOptional);            compiler.setCreateSetters(createSetters);            compiler.setAdditionalVelocityTools(instantiateAdditionalVelocityTools());            compiler.setEnableDecimalLogicalType(enableDecimalLogicalType);            for (String customConversion : customConversions) {                compiler.addCustomConversion(projPathLoader.loadClass(customConversion));            }            compiler.setOutputCharacterEncoding(project.getProperties().getProperty("project.build.sourceEncoding"));            compiler.compileToDestination(null, outputDirectory);        }    } catch (ParseException | ClassNotFoundException | DependencyResolutionRequiredException e) {        throw new IOException(e);    }}
0
protected String[] getIncludes()
{    return includes;}
0
protected String[] getTestIncludes()
{    return testIncludes;}
0
public void execute() throws MojoExecutionException
{    classLoader = getClassLoader();    reflectData = getReflectData();    if (encoding == null) {        encoding = Charset.defaultCharset().name();        getLog().warn("Property project.build.sourceEncoding not set, using system default " + encoding);    }    for (File sourceDirectory : javaSourceDirectories) {        induceClasses(sourceDirectory);    }}
0
private void induceClasses(File sourceDirectory) throws MojoExecutionException
{    File[] files = sourceDirectory.listFiles();    if (files == null) {        throw new MojoExecutionException("Unable to list files from directory: " + sourceDirectory.getName());    }    for (File inputFile : files) {        if (inputFile.isDirectory()) {            induceClasses(inputFile);            continue;        }        String className = parseClassName(inputFile.getPath());        if (className == null) {                        continue;        }        Class<?> klass = loadClass(classLoader, className);        String fileName = getOutputFileName(klass);        File outputFile = new File(fileName);        outputFile.getParentFile().mkdirs();        try (PrintWriter writer = new PrintWriter(fileName, encoding)) {            if (klass.isInterface()) {                writer.println(reflectData.getProtocol(klass).toString(true));            } else {                writer.println(reflectData.getSchema(klass).toString(true));            }        } catch (AvroRuntimeException e) {            throw new MojoExecutionException("Failed to resolve schema or protocol for class " + klass.getCanonicalName(), e);        } catch (Exception e) {            throw new MojoExecutionException("Failed to write output file for class " + klass.getCanonicalName(), e);        }    }}
0
private String parseClassName(String fileName)
{    String indentifier = "java" + File.separator;    int index = fileName.lastIndexOf(indentifier);    String namespacedFileName = fileName.substring(index + indentifier.length());    if (!namespacedFileName.endsWith(".java")) {        return null;    }    return namespacedFileName.replace(File.separator, ".").replaceFirst("\\.java$", "");}
0
private String getOutputFileName(Class klass)
{    String filename = avroOutputDirectory.getPath() + File.separator + klass.getName().replace(".", File.separator);    if (klass.isInterface()) {        return filename.concat(".avpr");    } else {        return filename.concat(".avsc");    }}
0
private ReflectData getReflectData() throws MojoExecutionException
{    if (reflectDataImplementation == null) {        return allowNull ? ReflectData.AllowNull.get() : ReflectData.get();    }    try {        Constructor<? extends ReflectData> constructor = loadClass(classLoader, reflectDataImplementation).asSubclass(ReflectData.class).getConstructor();        constructor.setAccessible(true);        return constructor.newInstance();    } catch (Exception e) {        throw new MojoExecutionException(String.format("Could not load ReflectData custom implementation %s. Make sure that it has a no-args constructor", reflectDataImplementation), e);    }}
0
private Class<?> loadClass(ClassLoader classLoader, String className) throws MojoExecutionException
{    try {        return classLoader.loadClass(className);    } catch (ClassNotFoundException e) {        throw new MojoExecutionException("Failed to load class " + className, e);    }}
0
private ClassLoader getClassLoader() throws MojoExecutionException
{    ClassLoader classLoader;    try {        List<String> classpathElements = project.getRuntimeClasspathElements();        if (null == classpathElements) {            return Thread.currentThread().getContextClassLoader();        }        URL[] urls = new URL[classpathElements.size()];        for (int i = 0; i < classpathElements.size(); ++i) {            urls[i] = new File(classpathElements.get(i)).toURI().toURL();        }        classLoader = new URLClassLoader(urls, getClass().getClassLoader());    } catch (Exception e) {        throw new MojoExecutionException("Failed to obtain ClassLoader", e);    }    return classLoader;}
0
protected void doCompile(String filename, File sourceDirectory, File outputDirectory) throws IOException
{    final File src = new File(sourceDirectory, filename);    final Protocol protocol = Protocol.parse(src);    final SpecificCompiler compiler = new SpecificCompiler(protocol);    compiler.setTemplateDir(templateDirectory);    compiler.setStringType(StringType.valueOf(stringType));    compiler.setFieldVisibility(getFieldVisibility());    compiler.setCreateOptionalGetters(createOptionalGetters);    compiler.setGettersReturnOptional(gettersReturnOptional);    compiler.setCreateSetters(createSetters);    compiler.setAdditionalVelocityTools(instantiateAdditionalVelocityTools());    compiler.setEnableDecimalLogicalType(enableDecimalLogicalType);    final URLClassLoader classLoader;    try {        classLoader = createClassLoader();        for (String customConversion : customConversions) {            compiler.addCustomConversion(classLoader.loadClass(customConversion));        }    } catch (DependencyResolutionRequiredException | ClassNotFoundException e) {        throw new IOException(e);    }    compiler.setOutputCharacterEncoding(project.getProperties().getProperty("project.build.sourceEncoding"));    compiler.compileToDestination(src, outputDirectory);}
0
protected String[] getIncludes()
{    return includes;}
0
protected String[] getTestIncludes()
{    return testIncludes;}
0
protected void doCompile(String filename, File sourceDirectory, File outputDirectory) throws IOException
{    File src = new File(sourceDirectory, filename);    final Schema schema;        if (imports == null) {        schema = new Schema.Parser().parse(src);    } else {        schema = schemaParser.parse(src);    }    final SpecificCompiler compiler = new SpecificCompiler(schema);    compiler.setTemplateDir(templateDirectory);    compiler.setStringType(StringType.valueOf(stringType));    compiler.setFieldVisibility(getFieldVisibility());    compiler.setCreateOptionalGetters(createOptionalGetters);    compiler.setGettersReturnOptional(gettersReturnOptional);    compiler.setCreateSetters(createSetters);    compiler.setEnableDecimalLogicalType(enableDecimalLogicalType);    try {        final URLClassLoader classLoader = createClassLoader();        for (String customConversion : customConversions) {            compiler.addCustomConversion(classLoader.loadClass(customConversion));        }    } catch (ClassNotFoundException | DependencyResolutionRequiredException e) {        throw new IOException(e);    }    compiler.setOutputCharacterEncoding(project.getProperties().getProperty("project.build.sourceEncoding"));    compiler.setAdditionalVelocityTools(instantiateAdditionalVelocityTools());    compiler.compileToDestination(src, outputDirectory);}
0
protected String[] getIncludes()
{    return includes;}
0
protected String[] getTestIncludes()
{    return testIncludes;}
0
protected void setUp() throws Exception
{    super.setUp();}
0
protected void tearDown() throws Exception
{    super.tearDown();}
0
 void assertFilesExist(File directory, Set<String> expectedFiles)
{    assertNotNull(directory);    assertTrue("Directory " + directory.toString() + " does not exists", directory.exists());    assertNotNull(expectedFiles);    assertTrue(expectedFiles.size() > 0);    final Set<String> filesInDirectory = new HashSet<>(Arrays.asList(directory.list()));    assertEquals(expectedFiles, filesInDirectory);}
0
public void testIdlProtocolMojo() throws Exception
{    final IDLProtocolMojo mojo = (IDLProtocolMojo) lookupMojo("idl-protocol", testPom);    assertNotNull(mojo);    mojo.execute();    final File outputDir = new File(getBasedir(), "target/test-harness/idl/test/");    final Set<String> generatedFiles = new HashSet<>(Arrays.asList("IdlPrivacy.java", "IdlTest.java", "IdlUser.java", "IdlUserWrapper.java", "IdlClasspathImportTest.java"));    assertFilesExist(outputDir, generatedFiles);    final String idlUserContent = FileUtils.fileRead(new File(outputDir, "IdlUser.java"));    assertTrue(idlUserContent.contains("java.time.Instant"));}
0
public void testSetCompilerVelocityAdditionalTools() throws Exception
{    final IDLProtocolMojo mojo = (IDLProtocolMojo) lookupMojo("idl-protocol", injectingVelocityToolsTestPom);    assertNotNull(mojo);    mojo.execute();    final File outputDir = new File(getBasedir(), "target/test-harness/idl-inject/test");    final Set<String> generatedFiles = new HashSet<>(Arrays.asList("IdlPrivacy.java", "IdlTest.java", "IdlUser.java", "IdlUserWrapper.java", "IdlClasspathImportTest.java"));    assertFilesExist(outputDir, generatedFiles);    final String schemaUserContent = FileUtils.fileRead(new File(outputDir, "IdlUser.java"));    assertTrue(schemaUserContent.contains("It works!"));}
0
protected void setUp() throws Exception
{    String baseDir = getBasedir();    schemaPom = new File(baseDir, "src/test/resources/unit/schema/induce-pom.xml");    protocolPom = new File(baseDir, "src/test/resources/unit/protocol/induce-pom.xml");    super.setUp();}
0
protected void tearDown() throws Exception
{    super.tearDown();}
0
public void testInduceMojoExists() throws Exception
{    InduceMojo mojo = (InduceMojo) lookupMojo("induce", schemaPom);    assertNotNull(mojo);}
0
public void testInduceSchema() throws Exception
{    executeMojo(schemaPom);    File outputDir = new File(getBasedir(), "target/test-harness/schemas/org/apache/avro/entities");    assertTrue(outputDir.listFiles().length != 0);    File personSchemaFile = Arrays.stream(outputDir.listFiles()).filter(file -> file.getName().endsWith("Person.avsc")).findFirst().orElseThrow(AssertionError::new);    assertEquals(ReflectData.get().getSchema(Person.class), new Schema.Parser().parse(personSchemaFile));}
0
public void testInducedSchemasFileExtension() throws Exception
{    executeMojo(schemaPom);    File outputDir = new File(getBasedir(), "target/test-harness/schemas/org/apache/avro/entities");    for (File file : outputDir.listFiles()) {        assertTrue(file.getName().contains(".avsc"));    }}
0
public void testInduceProtocol() throws Exception
{    executeMojo(protocolPom);    File outputDir = new File(getBasedir(), "target/test-harness/protocol/org/apache/avro/protocols");    assertTrue(outputDir.listFiles().length != 0);    File remoteProtocolFile = Arrays.stream(outputDir.listFiles()).filter(file -> file.getName().endsWith("Remote.avpr")).findFirst().orElseThrow(AssertionError::new);    assertEquals(ReflectData.get().getProtocol(Remote.class), Protocol.parse(remoteProtocolFile));}
0
public void testInducedProtocolsFileExtension() throws Exception
{    executeMojo(protocolPom);    File outputDir = new File(getBasedir(), "target/test-harness/protocol/org/apache/avro/protocols");    for (File file : outputDir.listFiles()) {        assertTrue(file.getName().contains(".avpr"));    }}
0
private void executeMojo(File pom) throws Exception
{    InduceMojo mojo = (InduceMojo) lookupMojo("induce", pom);    mojo.execute();}
0
public void testProtocolMojo() throws Exception
{    final ProtocolMojo mojo = (ProtocolMojo) lookupMojo("protocol", testPom);    assertNotNull(mojo);    mojo.execute();    final File outputDir = new File(getBasedir(), "target/test-harness/protocol/test");    final Set<String> generatedFiles = new HashSet<>(Arrays.asList("ProtocolPrivacy.java", "ProtocolTest.java", "ProtocolUser.java"));    assertFilesExist(outputDir, generatedFiles);    final String protocolUserContent = FileUtils.fileRead(new File(outputDir, "ProtocolUser.java"));    assertTrue("Got " + protocolUserContent + " instead", protocolUserContent.contains("java.time.Instant"));}
0
public void testSetCompilerVelocityAdditionalTools() throws Exception
{    ProtocolMojo mojo = (ProtocolMojo) lookupMojo("protocol", injectingVelocityToolsTestPom);    assertNotNull(mojo);    mojo.execute();    File outputDir = new File(getBasedir(), "target/test-harness/protocol-inject/test");    final Set<String> generatedFiles = new HashSet<>(Arrays.asList("ProtocolPrivacy.java", "ProtocolTest.java", "ProtocolUser.java"));    assertFilesExist(outputDir, generatedFiles);    String schemaUserContent = FileUtils.fileRead(new File(outputDir, "ProtocolUser.java"));    assertTrue(schemaUserContent.contains("It works!"));}
0
public void testSchemaMojo() throws Exception
{    final SchemaMojo mojo = (SchemaMojo) lookupMojo("schema", testPom);    assertNotNull(mojo);    mojo.execute();    final File outputDir = new File(getBasedir(), "target/test-harness/schema/test");    final Set<String> generatedFiles = new HashSet<>(Arrays.asList("PrivacyDirectImport.java", "PrivacyImport.java", "SchemaPrivacy.java", "SchemaUser.java"));    assertFilesExist(outputDir, generatedFiles);    final String schemaUserContent = FileUtils.fileRead(new File(outputDir, "SchemaUser.java"));    assertTrue(schemaUserContent.contains("java.time.Instant"));}
0
public void testSetCompilerVelocityAdditionalTools() throws Exception
{    final SchemaMojo mojo = (SchemaMojo) lookupMojo("schema", injectingVelocityToolsTestPom);    assertNotNull(mojo);    mojo.execute();    final File outputDir = new File(getBasedir(), "target/test-harness/schema-inject/test");    final Set<String> generatedFiles = new HashSet<>(Arrays.asList("PrivacyDirectImport.java", "PrivacyImport.java", "SchemaPrivacy.java", "SchemaUser.java"));    assertFilesExist(outputDir, generatedFiles);    final String schemaUserContent = FileUtils.fileRead(new File(outputDir, "SchemaUser.java"));    assertTrue("Got " + schemaUserContent + " instead", schemaUserContent.contains("It works!"));}
0
public static void main(String[] args) throws Exception
{    Options options = new Options();    options.addOption(Option.builder().argName("measurementIterations").longOpt("mi").hasArg().desc("The number of measure iterations").numberOfArgs(1).build());    options.addOption(Option.builder().argName("warmupIterations").longOpt("wi").hasArg().desc("The number of warmup iterations").numberOfArgs(1).build());    options.addOption(Option.builder().argName("bulkWarmup").longOpt("bw").desc("Flag to enabled bulk warmup").build());    options.addOption(Option.builder().argName("test").longOpt("test").hasArg().desc("The performance tests to run").build());    options.addOption(Option.builder().argName("help").longOpt("help").desc("Print the help menu").build());    final CommandLine cmd = new DefaultParser().parse(options, args);    if (cmd.hasOption("help")) {        final HelpFormatter formatter = new HelpFormatter();        final PrintWriter pw = new PrintWriter(System.out);        formatter.printUsage(pw, 80, "Perf", options);        pw.flush();        return;    }    String[] tests = cmd.getOptionValues("test");    if (tests == null || tests.length == 0) {        tests = new String[] { Perf.class.getPackage().getName() + ".*" };    }    final Integer measurementIterations = Integer.valueOf(cmd.getOptionValue("mi", "3"));    final Integer warmupIterations = Integer.valueOf(cmd.getOptionValue("wi", "3"));    final ChainedOptionsBuilder runOpt = new OptionsBuilder().mode(Mode.Throughput).timeout(TimeValue.seconds(60)).warmupIterations(warmupIterations).measurementIterations(measurementIterations).forks(1).threads(1).shouldDoGC(true);    if (cmd.hasOption("builkWarmup")) {        runOpt.warmupMode(WarmupMode.BULK);    }    for (final String test : tests) {        runOpt.include(test);    }    new Runner(runOpt.build()).run();}
0
public void encode(final TestStateEncode state) throws Exception
{    final Encoder e = state.encoder;    final int items = state.getBatchSize() / 4;    e.writeArrayStart();    e.setItemCount(1);    e.startItem();    e.writeArrayStart();    e.setItemCount(items);    for (int i = 0; i < state.getBatchSize(); i += 4) {        e.startItem();        e.writeFloat(state.testData[i + 0]);        e.writeFloat(state.testData[i + 1]);        e.writeFloat(state.testData[i + 2]);        e.writeFloat(state.testData[i + 3]);    }    e.writeArrayEnd();    e.writeArrayEnd();}
0
public float decode(final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    float total = 0.0f;    d.readArrayStart();    for (long i = d.readArrayStart(); i != 0; i = d.arrayNext()) {        for (long j = 0; j < i; j++) {            total += d.readFloat();            total += d.readFloat();            total += d.readFloat();            total += d.readFloat();        }    }    d.arrayNext();    return total;}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.testData = new float[getBatchSize()];    for (int i = 0; i < testData.length; i++) {        testData[i] = super.getRandom().nextFloat();    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    final int items = getBatchSize() / 4;    encoder.writeArrayStart();    encoder.setItemCount(1);    encoder.startItem();    encoder.writeArrayStart();    encoder.setItemCount(items);    for (int i = 0; i < getBatchSize(); i += 4) {        encoder.startItem();        encoder.writeFloat(super.getRandom().nextFloat());        encoder.writeFloat(super.getRandom().nextFloat());        encoder.writeFloat(super.getRandom().nextFloat());        encoder.writeFloat(super.getRandom().nextFloat());    }    encoder.writeArrayEnd();    encoder.writeArrayEnd();    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = super.newDecoder(this.testData);}
0
public void encode(final TestStateEncode state) throws Exception
{    final Encoder e = state.encoder;    for (int i = 0; i < state.getBatchSize(); i += 4) {        e.writeBoolean(state.testData[i + 0]);        e.writeBoolean(state.testData[i + 1]);        e.writeBoolean(state.testData[i + 2]);        e.writeBoolean(state.testData[i + 3]);    }}
0
public boolean decode(final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    boolean total = true;    for (int i = 0; i < state.getBatchSize(); i += 4) {        total ^= d.readBoolean();        total ^= d.readBoolean();        total ^= d.readBoolean();        total ^= d.readBoolean();    }    return total;}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.testData = new boolean[getBatchSize()];    for (int i = 0; i < testData.length; i++) {        testData[i] = super.getRandom().nextBoolean();    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    for (int i = 0; i < getBatchSize(); i++) {        encoder.writeBoolean(super.getRandom().nextBoolean());    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = super.newDecoder(this.testData);}
0
public void encode(final TestStateEncode state) throws Exception
{    final Encoder e = state.encoder;    for (int i = 0; i < state.getBatchSize(); i += 4) {        e.writeBytes(state.testData[i + 0]);        e.writeBytes(state.testData[i + 1]);        e.writeBytes(state.testData[i + 2]);        e.writeBytes(state.testData[i + 3]);    }}
0
public ByteBuffer decode(final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    for (int i = 0; i < state.getBatchSize(); i += 4) {        d.readBytes(state.bb);        d.readBytes(state.bb);        d.readBytes(state.bb);        d.readBytes(state.bb);    }    return state.bb;}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.testData = new byte[getBatchSize()][];    for (int i = 0; i < testData.length; i++) {        final byte[] data = new byte[super.getRandom().nextInt(70)];        super.getRandom().nextBytes(data);        testData[i] = data;    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    for (int i = 0; i < getBatchSize(); i++) {        final byte[] data = new byte[super.getRandom().nextInt(70)];        super.getRandom().nextBytes(data);        encoder.writeBytes(data);    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = super.newDecoder(this.testData);}
0
public void encode(final TestStateEncode state) throws Exception
{    final Encoder e = state.encoder;    for (int i = 0; i < state.getBatchSize(); i += 4) {        e.writeDouble(state.testData[i + 0]);        e.writeDouble(state.testData[i + 1]);        e.writeDouble(state.testData[i + 2]);        e.writeDouble(state.testData[i + 3]);    }}
0
public double decode(final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    double total = 0;    for (int i = 0; i < state.getBatchSize(); i += 4) {        total += d.readDouble();        total += d.readDouble();        total += d.readDouble();        total += d.readDouble();    }    return total;}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.testData = new double[getBatchSize()];    for (int i = 0; i < testData.length; i++) {        testData[i] = super.getRandom().nextDouble();    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    for (int i = 0; i < getBatchSize(); i++) {        encoder.writeDouble(super.getRandom().nextDouble());    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = super.newDecoder(this.testData);}
0
public void encode(final TestStateEncode state) throws Exception
{    final Encoder e = state.encoder;    GenericDatumWriter<Object> writer = new GenericDatumWriter<>(state.schema);    for (int i = 0; i < state.getBatchSize(); i += 4) {        writer.write(state.testData[i + 0], e);        writer.write(state.testData[i + 1], e);        writer.write(state.testData[i + 2], e);        writer.write(state.testData[i + 3], e);    }}
0
public void decode(final Blackhole blackHole, final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    final GenericDatumReader<Object> reader = new GenericDatumReader<>(state.schema);    for (int i = 0; i < state.getBatchSize(); i++) {        final Object o = reader.read(null, d);        blackHole.consume(o);    }}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.testData = new GenericRecord[getBatchSize()];    final Schema enumSchema = this.schema.getField("f").schema();    for (int i = 0; i < getBatchSize(); i++) {        final GenericRecord rec = new GenericData.Record(this.schema);        final int tag = super.getRandom().nextInt(2);        rec.put("f", GenericData.get().createEnum(enumSchema.getEnumSymbols().get(tag), enumSchema));        this.testData[i] = rec;    }}
0
private String mkSchema(String subschema)
{    return ("{ \"type\": \"record\", \"name\": \"R\", \"fields\": [\n" + "{ \"name\": \"f\", \"type\": " + subschema + "}\n" + "] }");}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    final GenericDatumWriter<Object> writer = new GenericDatumWriter<>(this.schema);    final Schema enumSchema = this.schema.getField("f").schema();    for (int i = 0; i < getBatchSize(); i++) {        final GenericRecord rec = new GenericData.Record(this.schema);        final int tag = super.getRandom().nextInt(2);        rec.put("f", GenericData.get().createEnum(enumSchema.getEnumSymbols().get(tag), enumSchema));        writer.write(rec, encoder);    }    this.testData = baos.toByteArray();}
0
private String mkSchema(String subschema)
{    return ("{ \"type\": \"record\", \"name\": \"R\", \"fields\": [\n" + "{ \"name\": \"f\", \"type\": " + subschema + "}\n" + "] }");}
0
public void doSetupInvocation() throws Exception
{    this.decoder = super.newDecoder(this.testData);}
0
public void encode(final TestStateEncode state) throws Exception
{    final Encoder e = state.encoder;    for (int i = 0; i < state.getBatchSize(); i += 4) {        e.writeFloat(state.testData[i + 0]);        e.writeFloat(state.testData[i + 1]);        e.writeFloat(state.testData[i + 2]);        e.writeFloat(state.testData[i + 3]);    }}
0
public float decode(final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    float total = 0.0f;    for (int i = 0; i < state.getBatchSize(); i += 4) {        total += d.readFloat();        total += d.readFloat();        total += d.readFloat();        total += d.readFloat();    }    return total;}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.testData = new float[getBatchSize()];    for (int i = 0; i < testData.length; i++) {        testData[i] = super.getRandom().nextFloat();    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    for (int i = 0; i < getBatchSize(); i++) {        encoder.writeFloat(super.getRandom().nextFloat());    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = super.newDecoder(this.testData);}
0
public void encode(final TestStateEncode state) throws Exception
{    final Encoder e = state.encoder;    for (int i = 0; i < state.getBatchSize(); i += 4) {        e.writeInt(state.testData[i + 0]);        e.writeInt(state.testData[i + 1]);        e.writeInt(state.testData[i + 2]);        e.writeInt(state.testData[i + 3]);    }}
0
public int decode(final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    int total = 0;    for (int i = 0; i < state.getBatchSize(); i += 4) {        total += d.readInt();        total += d.readInt();        total += d.readInt();        total += d.readInt();    }    return total;}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.testData = new int[getBatchSize()];    for (int i = 0; i < testData.length; i += 4) {                testData[i + 0] = super.getRandom().nextInt(50);                testData[i + 1] = super.getRandom().nextInt(5000);                testData[i + 2] = super.getRandom().nextInt(500000);                testData[i + 3] = super.getRandom().nextInt(150000000);    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    for (int i = 0; i < getBatchSize(); i += 4) {                encoder.writeInt(super.getRandom().nextInt(50));                encoder.writeInt(super.getRandom().nextInt(5000));                encoder.writeInt(super.getRandom().nextInt(500000));                encoder.writeInt(super.getRandom().nextInt(150000000));    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = super.newDecoder(this.testData);}
0
public void encode(final TestStateEncode state) throws Exception
{    final Encoder e = state.encoder;    for (int i = 0; i < state.getBatchSize(); i += 4) {        e.writeLong(state.testData[i + 0]);        e.writeLong(state.testData[i + 1]);        e.writeLong(state.testData[i + 2]);        e.writeLong(state.testData[i + 3]);    }}
0
public long decode(final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    long total = 0;    for (int i = 0; i < state.getBatchSize(); i += 4) {        total += d.readLong();        total += d.readLong();        total += d.readLong();        total += d.readLong();    }    return total;}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.testData = new long[getBatchSize()];    for (int i = 0; i < testData.length; i += 4) {                testData[i + 0] = super.getRandom().nextLong() % 0x7FL;                testData[i + 1] = super.getRandom().nextLong() % 0x1FFFFFL;                testData[i + 2] = super.getRandom().nextLong() % 0x3FFFFFFFFL;                testData[i + 3] = super.getRandom().nextLong() % 0x1FFFFFFFFFFFFL;    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    for (int i = 0; i < getBatchSize(); i += 4) {                encoder.writeLong(super.getRandom().nextLong() % 0x7FL);                encoder.writeLong(super.getRandom().nextLong() % 0x1FFFFFL);                encoder.writeLong(super.getRandom().nextLong() % 0x3FFFFFFFFL);                encoder.writeLong(super.getRandom().nextLong() % 0x1FFFFFFFFFFFFL);    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = super.newDecoder(this.testData);}
0
public void encode(final TestStateEncode state) throws Exception
{    final Encoder e = state.encoder;    final int items = state.getBatchSize() / 4;    e.writeMapStart();    e.setItemCount(items);    for (int i = 0; i < state.getBatchSize(); i += 4) {        e.startItem();        e.writeString(state.utf);        e.writeFloat(state.testData[i + 0]);        e.writeFloat(state.testData[i + 1]);        e.writeFloat(state.testData[i + 2]);        e.writeFloat(state.testData[i + 3]);    }    e.writeMapEnd();}
0
public float decode(final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    float result = 0.0f;    for (long i = d.readMapStart(); i != 0; i = d.mapNext()) {        for (long j = 0; j < i; j++) {            state.utf = d.readString(state.utf);            result += d.readFloat();            result += d.readFloat();            result += d.readFloat();            result += d.readFloat();        }    }    return result;}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.testData = new float[getBatchSize()];    for (int i = 0; i < testData.length; i++) {        testData[i] = super.getRandom().nextFloat();    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    final int items = getBatchSize() / 4;    encoder.writeMapStart();    encoder.setItemCount(items);    for (int i = 0; i < getBatchSize(); i += 4) {        encoder.startItem();        encoder.writeString("This is a map key");        encoder.writeFloat(super.getRandom().nextFloat());        encoder.writeFloat(super.getRandom().nextFloat());        encoder.writeFloat(super.getRandom().nextFloat());        encoder.writeFloat(super.getRandom().nextFloat());    }    encoder.writeMapEnd();    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = super.newDecoder(this.testData);}
0
public void encode(final TestStateEncode state) throws Exception
{    final Encoder e = state.encoder;    for (int i = 0; i < state.getBatchSize(); i += 4) {        e.writeLong(state.testData[i + 0]);        e.writeLong(state.testData[i + 1]);        e.writeLong(state.testData[i + 2]);        e.writeLong(state.testData[i + 3]);    }}
0
public int decode(final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    int total = 0;    for (int i = 0; i < state.getBatchSize(); i += 4) {        total += d.readLong();        total += d.readLong();        total += d.readLong();        total += d.readLong();    }    return total;}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.testData = new int[getBatchSize()];    for (int i = 0; i < testData.length; i += 4) {                testData[i + 0] = super.getRandom().nextInt(50);                testData[i + 1] = super.getRandom().nextInt(5000);                testData[i + 2] = super.getRandom().nextInt(500000);                testData[i + 3] = super.getRandom().nextInt(150000000);    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    for (int i = 0; i < getBatchSize(); i += 4) {                encoder.writeInt(super.getRandom().nextInt(50));                encoder.writeInt(super.getRandom().nextInt(5000));                encoder.writeInt(super.getRandom().nextInt(500000));                encoder.writeInt(super.getRandom().nextInt(150000000));    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = super.newDecoder(this.testData);}
0
public void encode(final TestStateEncode state) throws Exception
{    final Encoder e = state.encoder;    for (int i = 0; i < state.getBatchSize(); i += 4) {        e.writeString(state.testData[i + 0]);        e.writeString(state.testData[i + 1]);        e.writeString(state.testData[i + 2]);        e.writeString(state.testData[i + 3]);    }}
0
public int decode(final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    int result = 0;    for (int i = 0; i < state.getBatchSize(); i += 4) {        result += d.readString(state.utf).toString().length();        result += d.readString(state.utf).toString().length();        result += d.readString(state.utf).toString().length();        result += d.readString(state.utf).toString().length();    }    return result;}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.testData = new String[getBatchSize()];    for (int i = 0; i < testData.length; i++) {        testData[i] = randomString();    }}
0
private String randomString()
{    final char[] data = new char[super.getRandom().nextInt(70)];    for (int j = 0; j < data.length; j++) {        data[j] = (char) ('a' + super.getRandom().nextInt('z' - 'a'));    }    return new String(data);}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    for (int i = 0; i < getBatchSize(); i++) {        encoder.writeString(randomString());    }    this.testData = baos.toByteArray();}
0
private String randomString()
{    final char[] data = new char[super.getRandom().nextInt(70)];    for (int j = 0; j < data.length; j++) {        data[j] = (char) ('a' + super.getRandom().nextInt('z' - 'a'));    }    return new String(data);}
0
public void doSetupInvocation() throws Exception
{    this.decoder = super.newDecoder(this.testData);}
0
public void encode(final TestStateEncode state) throws Exception
{    final Encoder e = state.encoder;    GenericDatumWriter<Object> writer = new GenericDatumWriter<>(state.schema);    for (int i = 0; i < state.getBatchSize(); i += 4) {        writer.write(state.testData[i + 0], e);        writer.write(state.testData[i + 1], e);        writer.write(state.testData[i + 2], e);        writer.write(state.testData[i + 3], e);    }}
0
public void decode(final Blackhole blackHole, final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    final GenericDatumReader<Object> reader = new GenericDatumReader<>(state.schema);    for (int i = 0; i < state.getBatchSize(); i++) {        final Object o = reader.read(null, d);        blackHole.consume(o);    }}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.testData = new GenericRecord[getBatchSize()];    for (int i = 0; i < getBatchSize(); i++) {        final GenericRecord rec = new GenericData.Record(this.schema);        final int val = super.getRandom().nextInt(1000000);        final Integer v = (val < 750000 ? new Integer(val) : null);        rec.put("f", v);        this.testData[i] = rec;    }}
0
private String mkSchema(String subschema)
{    return ("{ \"type\": \"record\", \"name\": \"R\", \"fields\": [\n" + "{ \"name\": \"f\", \"type\": " + subschema + "}\n" + "] }");}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    final GenericDatumWriter<Object> writer = new GenericDatumWriter<>(this.schema);    for (int i = 0; i < getBatchSize(); i++) {        final GenericRecord rec = new GenericData.Record(this.schema);        final int val = super.getRandom().nextInt(1000000);        final Integer v = (val < 750000 ? new Integer(val) : null);        rec.put("f", v);        writer.write(rec, encoder);    }    this.testData = baos.toByteArray();}
0
private String mkSchema(String subschema)
{    return ("{ \"type\": \"record\", \"name\": \"R\", \"fields\": [\n" + "{ \"name\": \"f\", \"type\": " + subschema + "}\n" + "] }");}
0
public void doSetupInvocation() throws Exception
{    this.decoder = super.newDecoder(this.testData);}
0
public int getBatchSize()
{    return super.getBatchSize() / arraySize;}
0
public int getArraySize()
{    return arraySize;}
0
protected Random getRandom()
{    return this.random;}
0
protected Decoder newDecoder(final byte[] buf)
{    this.reuseDecoder = DECODER_FACTORY.binaryDecoder(buf, this.reuseDecoder);    return this.reuseDecoder;}
0
protected Encoder newEncoder(boolean direct, OutputStream out) throws IOException
{    this.reuseEncoder = (direct ? ENCODER_FACTORY.directBinaryEncoder(out, this.reuseEncoder) : ENCODER_FACTORY.binaryEncoder(out, this.reuseEncoder));    return this.reuseEncoder;}
0
protected Encoder newEncoder(int blockSize, OutputStream out) throws IOException
{    this.reuseBlockingEncoder = ENCODER_FACTORY.configureBlockSize(blockSize).blockingBinaryEncoder(out, this.reuseBlockingEncoder);    return this.reuseBlockingEncoder;}
0
public int getBatchSize()
{    return this.batchSize;}
0
protected OutputStream getNullOutputStream()
{    return NULL_OUTPUTSTREAM;}
0
public void write(int b) throws IOException
{}
0
public void write(byte[] b, int off, int len) throws IOException
{}
0
public void write(byte[] b) throws IOException
{}
0
public void encode(final TestStateEncode state) throws Exception
{    final Encoder e = state.encoder;    final GenericDatumWriter<Object> writer = new GenericDatumWriter<>(state.schema);    for (final GenericRecord rec : state.testData) {        writer.write(rec, e);    }}
0
public void decode(final Blackhole blackhole, final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    final GenericDatumReader<Object> reader = new GenericDatumReader<>(state.schema);    for (int i = 0; i < state.getBatchSize(); i++) {        blackhole.consume(reader.read(null, d));    }}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.testData = new GenericRecord[getBatchSize()];    final Random r = super.getRandom();    Schema doubleSchema = schema.getFields().get(0).schema();    for (int i = 0; i < testData.length; i++) {        GenericRecord rec = new GenericData.Record(schema);        GenericRecord inner;        inner = new GenericData.Record(doubleSchema);        inner.put(0, r.nextDouble());        rec.put(0, inner);        inner = new GenericData.Record(doubleSchema);        inner.put(0, r.nextDouble());        rec.put(1, inner);        inner = new GenericData.Record(doubleSchema);        inner.put(0, r.nextDouble());        rec.put(2, inner);        rec.put(3, r.nextInt());        rec.put(4, r.nextInt());        rec.put(5, r.nextInt());        testData[i] = rec;    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    final Random r = super.getRandom();    for (int i = 0; i < getBatchSize(); i++) {        encoder.writeDouble(r.nextDouble());        encoder.writeDouble(r.nextDouble());        encoder.writeDouble(r.nextDouble());        encoder.writeInt(r.nextInt());        encoder.writeInt(r.nextInt());        encoder.writeInt(r.nextInt());    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = DecoderFactory.get().validatingDecoder(schema, super.newDecoder(this.testData));}
0
public void encode(final TestStateEncode state) throws Exception
{    final Encoder e = state.encoder;    for (final GenericRecord rec : state.testData) {        GenericRecord inner;        inner = (GenericRecord) rec.get(0);        e.writeDouble((Double) inner.get(0));        inner = (GenericRecord) rec.get(1);        e.writeDouble((Double) inner.get(0));        inner = (GenericRecord) rec.get(2);        e.writeDouble((Double) inner.get(0));        e.writeInt((Integer) rec.get(3));        e.writeInt((Integer) rec.get(4));        e.writeInt((Integer) rec.get(5));    }}
0
public void decode(final Blackhole blackhole, final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    Schema doubleSchema = state.schema.getFields().get(0).schema();    for (int i = 0; i < state.getBatchSize(); i++) {        GenericRecord rec = new GenericData.Record(state.schema);        GenericRecord inner;        inner = new GenericData.Record(doubleSchema);        inner.put(0, d.readDouble());        rec.put(0, inner);        inner = new GenericData.Record(doubleSchema);        inner.put(0, d.readDouble());        rec.put(1, inner);        inner = new GenericData.Record(doubleSchema);        inner.put(0, d.readDouble());        rec.put(2, inner);        rec.put(3, d.readInt());        rec.put(4, d.readInt());        rec.put(5, d.readInt());    }}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.testData = new GenericRecord[getBatchSize()];    final Random r = super.getRandom();    Schema doubleSchema = schema.getFields().get(0).schema();    for (int i = 0; i < testData.length; i++) {        GenericRecord rec = new GenericData.Record(schema);        GenericRecord inner;        inner = new GenericData.Record(doubleSchema);        inner.put(0, r.nextDouble());        rec.put(0, inner);        inner = new GenericData.Record(doubleSchema);        inner.put(0, r.nextDouble());        rec.put(1, inner);        inner = new GenericData.Record(doubleSchema);        inner.put(0, r.nextDouble());        rec.put(2, inner);        rec.put(3, r.nextInt());        rec.put(4, r.nextInt());        rec.put(5, r.nextInt());        testData[i] = rec;    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    final Random r = super.getRandom();    for (int i = 0; i < getBatchSize(); i++) {        encoder.writeDouble(r.nextDouble());        encoder.writeDouble(r.nextDouble());        encoder.writeDouble(r.nextDouble());        encoder.writeInt(r.nextInt());        encoder.writeInt(r.nextInt());        encoder.writeInt(r.nextInt());    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = DecoderFactory.get().validatingDecoder(schema, super.newDecoder(this.testData));}
0
public void encode(final TestStateEncode state) throws Exception
{    final Encoder e = state.encoder;    final GenericDatumWriter<Object> writer = new GenericDatumWriter<>(state.readerSchema);    for (final GenericRecord rec : state.testData) {        writer.write(rec, e);    }}
0
public void decode(final Blackhole blackhole, final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    final GenericDatumReader<Object> reader = new GenericDatumReader<>(state.readerSchema);    for (int i = 0; i < state.getBatchSize(); i++) {        blackhole.consume(reader.read(null, d));    }}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.testData = new GenericRecord[getBatchSize()];    for (int i = 0; i < testData.length; i++) {        GenericRecord rec = new GenericData.Record(readerSchema);        rec.put(0, randomString(super.getRandom()));        rec.put(1, randomString(super.getRandom()));        rec.put(2, randomString(super.getRandom()));        testData[i] = rec;    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    for (int i = 0; i < getBatchSize(); i++) {        encoder.writeString(randomString(super.getRandom()));        encoder.writeString(randomString(super.getRandom()));        encoder.writeString(randomString(super.getRandom()));    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = DecoderFactory.get().validatingDecoder(readerSchema, super.newDecoder(this.testData));}
0
private static String randomString(Random r)
{    char[] data = new char[r.nextInt(70)];    for (int j = 0; j < data.length; j++) {        data[j] = (char) ('a' + r.nextInt('z' - 'a'));    }    return new String(data);}
0
public void encode(final TestStateEncode state) throws Exception
{    final Encoder e = state.encoder;    final GenericDatumWriter<Object> writer = new GenericDatumWriter<>(state.schema);    for (final GenericRecord rec : state.testData) {        writer.write(rec, e);    }}
0
public void decode(final Blackhole blackhole, final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    final GenericDatumReader<Object> reader = new GenericDatumReader<>(state.schema);    for (int i = 0; i < state.getBatchSize(); i++) {        blackhole.consume(reader.read(null, d));    }}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.testData = new GenericRecord[getBatchSize()];    final Random r = super.getRandom();    for (int i = 0; i < testData.length; i++) {        final GenericRecord rec = new GenericData.Record(schema);        rec.put(0, r.nextDouble());        rec.put(1, r.nextDouble());        rec.put(2, r.nextDouble());        rec.put(3, r.nextInt());        rec.put(4, r.nextInt());        rec.put(5, r.nextInt());        testData[i] = rec;    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    final Random r = super.getRandom();    for (int i = 0; i < getBatchSize(); i++) {        encoder.writeDouble(r.nextDouble());        encoder.writeDouble(r.nextDouble());        encoder.writeDouble(r.nextDouble());        encoder.writeInt(r.nextInt());        encoder.writeInt(r.nextInt());        encoder.writeInt(r.nextInt());    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = DecoderFactory.get().validatingDecoder(schema, super.newDecoder(this.testData));}
0
public void encode(final TestStateEncode state) throws Exception
{    final Encoder e = state.encoder;    final GenericDatumWriter<Object> writer = new GenericDatumWriter<>(state.schema);    for (final GenericRecord rec : state.testData) {        writer.write(rec, e);    }}
0
public void decode(final Blackhole blackhole, final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    final GenericDatumReader<Object> reader = new GenericDatumReader<>(state.schema);    for (int i = 0; i < state.getBatchSize(); i++) {        blackhole.consume(reader.read(null, d));    }}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.testData = new GenericRecord[getBatchSize()];    final Random r = super.getRandom();    for (int i = 0; i < testData.length; i++) {        final GenericRecord rec = new GenericData.Record(schema);        rec.put(0, r.nextDouble());        rec.put(1, r.nextDouble());        rec.put(2, r.nextDouble());        rec.put(3, r.nextInt());        rec.put(4, r.nextInt());        rec.put(5, r.nextInt());        rec.put(6, randomString(r));        rec.put(7, randomString(r));        testData[i] = rec;    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    final GenericDatumWriter<Object> writer = new GenericDatumWriter<>(this.schema);    final Random r = super.getRandom();    for (int i = 0; i < getBatchSize(); i++) {        final GenericRecord rec = new GenericData.Record(schema);        rec.put(0, r.nextDouble());        rec.put(1, r.nextDouble());        rec.put(2, r.nextDouble());        rec.put(3, r.nextInt());        rec.put(4, r.nextInt());        rec.put(5, r.nextInt());        rec.put(6, randomString(r));        rec.put(7, randomString(r));        writer.write(rec, encoder);    }    encoder.flush();    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = DecoderFactory.get().validatingDecoder(schema, super.newDecoder(this.testData));}
0
private static String randomString(Random r)
{    char[] data = new char[r.nextInt(70)];    for (int j = 0; j < data.length; j++) {        data[j] = (char) ('a' + r.nextInt('z' - 'a'));    }    return new String(data);}
0
public void decode(final Blackhole blackhole, final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    final GenericDatumReader<Object> reader = new GenericDatumReader<>(state.writerSchema, state.readerSchema);    for (int i = 0; i < state.getBatchSize(); i++) {        blackhole.consume(reader.read(null, d));    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    final GenericDatumWriter<Object> writer = new GenericDatumWriter<>(this.writerSchema);    final Random r = super.getRandom();    for (int i = 0; i < getBatchSize(); i++) {        final GenericRecord rec = new GenericData.Record(writerSchema);        rec.put(0, r.nextDouble());        rec.put(1, r.nextDouble());        rec.put(2, r.nextDouble());        rec.put(3, r.nextInt());        rec.put(4, r.nextInt());        rec.put(5, r.nextInt());        writer.write(rec, encoder);    }    encoder.flush();    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = super.newDecoder(this.testData);}
0
public void decode(final Blackhole blackhole, final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    final GenericDatumReader<Object> reader = new GenericDatumReader<>(state.writerSchema, state.readerSchema);    for (int i = 0; i < state.getBatchSize(); i++) {        blackhole.consume(reader.read(null, d));    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    final GenericDatumWriter<Object> writer = new GenericDatumWriter<>(this.writerSchema);    final Random r = super.getRandom();    for (int i = 0; i < getBatchSize(); i++) {        final GenericRecord rec = new GenericData.Record(writerSchema);        rec.put(0, r.nextDouble());        rec.put(1, r.nextDouble());        rec.put(2, r.nextDouble());        rec.put(3, r.nextInt());        rec.put(4, r.nextInt());        rec.put(5, r.nextInt());        writer.write(rec, encoder);    }    encoder.flush();    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = super.newDecoder(this.testData);}
0
public void decode(final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    for (int i = 0; i < state.getBatchSize(); i++) {        d.readDouble();        d.readDouble();        d.readDouble();        d.readInt();        d.readInt();        d.readInt();    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    for (int i = 0; i < getBatchSize(); i++) {        final BasicRecord r = new BasicRecord(super.getRandom());        encoder.writeDouble(r.f1);        encoder.writeDouble(r.f2);        encoder.writeDouble(r.f3);        encoder.writeInt(r.f4);        encoder.writeInt(r.f5);        encoder.writeInt(r.f6);    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = DecoderFactory.get().validatingDecoder(readerSchema, super.newDecoder(this.testData));}
0
public void decode(final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    ResolvingDecoder r = (ResolvingDecoder) d;    Utf8 utf = new Utf8();    Field[] ff = r.readFieldOrder();    for (int i = 0; i < state.getBatchSize(); i++) {        for (int j = 0; j < ff.length; j++) {            Field f = ff[j];            switch(f.pos()) {                case 0:                case 1:                case 2:                    r.readDouble();                    break;                case 3:                case 4:                case 5:                    r.readInt();                    break;                case 6:                case 7:                    r.readString(utf);                    break;            }        }    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    for (int i = 0; i < getBatchSize(); i++) {        final BasicRecord r = new BasicRecord(super.getRandom());        encoder.writeDouble(r.f1);        encoder.writeDouble(r.f2);        encoder.writeDouble(r.f3);        encoder.writeInt(r.f4);        encoder.writeInt(r.f5);        encoder.writeInt(r.f6);    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = DecoderFactory.get().resolvingDecoder(writerSchema, readerSchema, super.newDecoder(this.testData));}
0
public void decode(final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    ResolvingDecoder r = (ResolvingDecoder) d;    Field[] ff = r.readFieldOrder();    for (int i = 0; i < state.getBatchSize(); i++) {        for (int j = 0; j < ff.length; j++) {            Field f = ff[j];            switch(f.pos()) {                case 0:                case 1:                case 3:                    r.readDouble();                    break;                case 2:                case 4:                case 5:                    r.readInt();                    break;            }        }    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    for (int i = 0; i < getBatchSize(); i++) {        final BasicRecord r = new BasicRecord(super.getRandom());        encoder.writeDouble(r.f1);        encoder.writeDouble(r.f2);        encoder.writeDouble(r.f3);        encoder.writeInt(r.f4);        encoder.writeInt(r.f5);        encoder.writeInt(r.f6);    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = DecoderFactory.get().resolvingDecoder(writerSchema, readerSchema, super.newDecoder(this.testData));}
0
public void decode(final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    ResolvingDecoder r = (ResolvingDecoder) d;    Field[] ff = r.readFieldOrder();    for (int i = 0; i < state.getBatchSize(); i++) {        for (int j = 0; j < ff.length; j++) {            Field f = ff[j];            switch(f.pos()) {                case 0:                case 1:                case 2:                    r.readDouble();                    break;                case 3:                case 4:                case 5:                    r.readLong();                    break;            }        }    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    for (int i = 0; i < getBatchSize(); i++) {        final BasicRecord r = new BasicRecord(super.getRandom());        encoder.writeDouble(r.f1);        encoder.writeDouble(r.f2);        encoder.writeDouble(r.f3);        encoder.writeInt(r.f4);        encoder.writeInt(r.f5);        encoder.writeInt(r.f6);    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = DecoderFactory.get().resolvingDecoder(writerSchema, readerSchema, super.newDecoder(this.testData));}
0
public void decode(final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    for (int i = 0; i < state.getBatchSize(); i++) {                d.readDouble();        d.readDouble();        d.readDouble();        d.readInt();        d.readInt();        d.readInt();    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    for (int i = 0; i < getBatchSize(); i++) {        final BasicRecord r = new BasicRecord(super.getRandom());        encoder.writeDouble(r.f1);        encoder.writeDouble(r.f2);        encoder.writeDouble(r.f3);        encoder.writeInt(r.f4);        encoder.writeInt(r.f5);        encoder.writeInt(r.f6);    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = DecoderFactory.get().resolvingDecoder(writerSchema, readerSchema, super.newDecoder(this.testData));}
0
public void encode(final TestStateEncode state) throws Exception
{    final Encoder e = state.encoder;    for (final BasicRecord r : state.testData) {        e.writeDouble(r.f1);        e.writeDouble(r.f2);        e.writeDouble(r.f3);        e.writeInt(r.f4);        e.writeInt(r.f5);        e.writeInt(r.f6);    }}
0
public void decode(final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    for (int i = 0; i < state.getBatchSize(); i++) {        d.readDouble();        d.readDouble();        d.readDouble();        d.readInt();        d.readInt();        d.readInt();    }}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.testData = new BasicRecord[getBatchSize()];    for (int i = 0; i < testData.length; i++) {        testData[i] = new BasicRecord(super.getRandom());    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    for (int i = 0; i < getBatchSize(); i++) {        final BasicRecord r = new BasicRecord(super.getRandom());        encoder.writeDouble(r.f1);        encoder.writeDouble(r.f2);        encoder.writeDouble(r.f3);        encoder.writeInt(r.f4);        encoder.writeInt(r.f5);        encoder.writeInt(r.f6);    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = DecoderFactory.get().validatingDecoder(this.schema, super.newDecoder(this.testData));}
0
public void encode(final TestStateEncode state) throws Exception
{    for (final BigRecord r : state.testData) {        state.datumWriter.write(r, state.encoder);    }}
0
public void decode(final Blackhole blackhole, final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    final ReflectDatumReader<BigRecord> datumReader = new ReflectDatumReader<>(state.schema);    for (int i = 0; i < state.getBatchSize(); i++) {        blackhole.consume(datumReader.read(null, d));    }}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.datumWriter = new ReflectDatumWriter<>(schema);    this.testData = new BigRecord[getBatchSize()];    for (int i = 0; i < testData.length; i++) {        this.testData[i] = new BigRecord(super.getRandom());    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    ReflectDatumWriter<BigRecord> writer = new ReflectDatumWriter<>(schema);    for (int i = 0; i < getBatchSize(); i++) {        final BigRecord r = new BigRecord(super.getRandom());        writer.write(r, encoder);    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = DecoderFactory.get().validatingDecoder(schema, super.newDecoder(this.testData));}
0
public void encode(final TestStateEncode state) throws Exception
{    for (final double[] r : state.testData) {        state.datumWriter.write(r, state.encoder);    }}
0
public void decode(final Blackhole blackhole, final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    final ReflectDatumReader<double[]> datumReader = new ReflectDatumReader<>(state.schema);    for (int i = 0; i < state.getBatchSize(); i++) {        blackhole.consume(datumReader.read(null, d));    }}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.datumWriter = new ReflectDatumWriter<>(schema);    this.testData = new double[getBatchSize()][];    for (int i = 0; i < testData.length; i++) {        this.testData[i] = populateDoubleArray(getRandom(), getArraySize());    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    ReflectDatumWriter<double[]> writer = new ReflectDatumWriter<>(schema);    for (int i = 0; i < this.getBatchSize(); i++) {        final double[] r = populateDoubleArray(getRandom(), getArraySize());        writer.write(r, encoder);    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = DecoderFactory.get().validatingDecoder(schema, super.newDecoder(this.testData));}
0
 static double[] populateDoubleArray(final Random r, final int size)
{    double[] result = new double[size];    for (int i = 0; i < result.length; i++) {        result[i] = r.nextDouble();    }    return result;}
0
public void encode(final TestStateEncode state) throws Exception
{    for (final float[] r : state.testData) {        state.datumWriter.write(r, state.encoder);    }}
0
public void decode(final Blackhole blackhole, final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    final ReflectDatumReader<float[]> datumReader = new ReflectDatumReader<>(state.schema);    for (int i = 0; i < state.getBatchSize(); i++) {        blackhole.consume(datumReader.read(null, d));    }}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.datumWriter = new ReflectDatumWriter<>(schema);    this.testData = new float[getBatchSize()][];    for (int i = 0; i < testData.length; i++) {        this.testData[i] = populateFloatArray(getRandom(), getArraySize());    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    ReflectDatumWriter<float[]> writer = new ReflectDatumWriter<>(schema);    for (int i = 0; i < getBatchSize(); i++) {        final float[] r = populateFloatArray(getRandom(), getArraySize());        writer.write(r, encoder);    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = DecoderFactory.get().validatingDecoder(schema, super.newDecoder(this.testData));}
0
 static float[] populateFloatArray(final Random r, final int size)
{    float[] result = new float[size];    for (int i = 0; i < result.length; i++) {        result[i] = r.nextFloat();    }    return result;}
0
public void encode(final TestStateEncode state) throws Exception
{    for (final int[] r : state.testData) {        state.datumWriter.write(r, state.encoder);    }}
0
public void decode(final Blackhole blackhole, final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    final ReflectDatumReader<int[]> datumReader = new ReflectDatumReader<>(state.schema);    for (int i = 0; i < state.getBatchSize(); i++) {        blackhole.consume(datumReader.read(null, d));    }}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.datumWriter = new ReflectDatumWriter<>(schema);    this.testData = new int[getBatchSize()][];    for (int i = 0; i < testData.length; i++) {        this.testData[i] = populateDoubleArray(getRandom(), getArraySize());    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    ReflectDatumWriter<int[]> writer = new ReflectDatumWriter<>(schema);    for (int i = 0; i < getBatchSize(); i++) {        final int[] r = populateDoubleArray(getRandom(), getArraySize());        writer.write(r, encoder);    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = DecoderFactory.get().validatingDecoder(schema, super.newDecoder(this.testData));}
0
 static int[] populateDoubleArray(final Random r, final int size)
{    int[] result = new int[size];    for (int i = 0; i < result.length; i++) {        result[i] = r.nextInt();    }    return result;}
0
public void encode(final TestStateEncode state) throws Exception
{    for (final float[] r : state.testData) {        state.datumWriter.write(r, state.encoder);    }}
0
public void decode(final Blackhole blackhole, final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    final ReflectDatumReader<float[]> datumReader = new ReflectDatumReader<>(state.schema);    for (int i = 0; i < state.getBatchSize(); i++) {        blackhole.consume(datumReader.read(null, d));    }}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(254, getNullOutputStream());    this.datumWriter = new ReflectDatumWriter<>(schema);    this.testData = new float[getBatchSize()][];    for (int i = 0; i < testData.length; i++) {        this.testData[i] = populateFloatArray(getRandom(), getArraySize());    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    ReflectDatumWriter<float[]> writer = new ReflectDatumWriter<>(schema);    for (int i = 0; i < getBatchSize(); i++) {        final float[] r = populateFloatArray(getRandom(), getArraySize());        writer.write(r, encoder);    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = DecoderFactory.get().validatingDecoder(schema, super.newDecoder(this.testData));}
0
 static float[] populateFloatArray(final Random r, final int size)
{    float[] result = new float[size];    for (int i = 0; i < result.length; i++) {        result[i] = r.nextFloat();    }    return result;}
0
public void encode(final TestStateEncode state) throws Exception
{    for (final float[] r : state.testData) {        state.datumWriter.write(r, state.encoder);    }}
0
public void decode(final Blackhole blackhole, final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    final ReflectDatumReader<float[]> datumReader = new ReflectDatumReader<>(state.schema);    for (int i = 0; i < state.getBatchSize(); i++) {        blackhole.consume(datumReader.read(null, d));    }}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.datumWriter = new ReflectDatumWriter<>(schema);    this.testData = new float[getBatchSize()][];    for (int i = 0; i < testData.length; i++) {        this.testData[i] = populateFloatArray(getRandom(), getArraySize());    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    ReflectDatumWriter<float[]> writer = new ReflectDatumWriter<>(schema);    for (int i = 0; i < getBatchSize(); i++) {        final float[] r = populateFloatArray(getRandom(), getArraySize());        writer.write(r, encoder);    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = DecoderFactory.get().validatingDecoder(schema, super.newDecoder(this.testData));}
0
 static float[] populateFloatArray(final Random r, final int size)
{    float[] result = new float[size];    for (int i = 0; i < result.length; i++) {        result[i] = r.nextFloat();    }    return result;}
0
public void encode(final TestStateEncode state) throws Exception
{    for (final long[] r : state.testData) {        state.datumWriter.write(r, state.encoder);    }}
0
public void decode(final Blackhole blackhole, final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    final ReflectDatumReader<long[]> datumReader = new ReflectDatumReader<>(state.schema);    for (int i = 0; i < state.getBatchSize(); i++) {        blackhole.consume(datumReader.read(null, d));    }}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.datumWriter = new ReflectDatumWriter<>(schema);    this.testData = new long[getBatchSize()][];    for (int i = 0; i < testData.length; i++) {        this.testData[i] = populateDoubleArray(getRandom(), getArraySize());    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    ReflectDatumWriter<long[]> writer = new ReflectDatumWriter<>(schema);    for (int i = 0; i < getBatchSize(); i++) {        final long[] r = populateDoubleArray(getRandom(), getArraySize());        writer.write(r, encoder);    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = DecoderFactory.get().validatingDecoder(schema, super.newDecoder(this.testData));}
0
 static long[] populateDoubleArray(final Random r, final int size)
{    long[] result = new long[size];    for (int i = 0; i < result.length; i++) {        result[i] = r.nextLong();    }    return result;}
0
public void encode(final TestStateEncode state) throws Exception
{    for (final NativeArrayWrapper r : state.testData) {        state.datumWriter.write(r, state.encoder);    }}
0
public void decode(final Blackhole blackhole, final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    final ReflectDatumReader<float[]> datumReader = new ReflectDatumReader<>(state.schema);    for (int i = 0; i < state.getBatchSize(); i++) {        blackhole.consume(datumReader.read(null, d));    }}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.datumWriter = new ReflectDatumWriter<>(schema);    this.testData = new NativeArrayWrapper[getBatchSize()];    for (int i = 0; i < testData.length; i++) {        NativeArrayWrapper wrapper = new NativeArrayWrapper();        wrapper.value = populateFloatArray(getRandom(), getArraySize());        this.testData[i] = wrapper;    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    ReflectDatumWriter<float[]> writer = new ReflectDatumWriter<>(schema);    for (int i = 0; i < getBatchSize(); i++) {        final float[] r = populateFloatArray(getRandom(), getArraySize());        writer.write(r, encoder);    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = DecoderFactory.get().validatingDecoder(schema, super.newDecoder(this.testData));}
0
 static float[] populateFloatArray(final Random r, final int size)
{    float[] result = new float[size];    for (int i = 0; i < result.length; i++) {        result[i] = r.nextFloat();    }    return result;}
0
public void encode(final TestStateEncode state) throws Exception
{    for (final ObjectArrayWrapper r : state.testData) {        state.datumWriter.write(r, state.encoder);    }}
0
public void decode(final Blackhole blackhole, final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    final ReflectDatumReader<BasicRecord[]> datumReader = new ReflectDatumReader<>(state.schema);    for (int i = 0; i < state.getBatchSize(); i++) {        blackhole.consume(datumReader.read(null, d));    }}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.datumWriter = new ReflectDatumWriter<>(schema);    this.testData = new ObjectArrayWrapper[getBatchSize()];    for (int i = 0; i < testData.length; i++) {        ObjectArrayWrapper wrapper = new ObjectArrayWrapper();        wrapper.value = populateRecordArray(getRandom(), getArraySize());        this.testData[i] = wrapper;    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    ReflectDatumWriter<BasicRecord[]> writer = new ReflectDatumWriter<>(schema);    for (int i = 0; i < getBatchSize(); i++) {        final BasicRecord[] r = populateRecordArray(getRandom(), getArraySize());        writer.write(r, encoder);    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = DecoderFactory.get().validatingDecoder(schema, super.newDecoder(this.testData));}
0
 static BasicRecord[] populateRecordArray(final Random r, final int size)
{    BasicRecord[] result = new BasicRecord[size];    for (int i = 0; i < result.length; i++) {        result[i] = new BasicRecord(r);    }    return result;}
0
public void encode(final TestStateEncode state) throws Exception
{    for (final BasicRecord r : state.testData) {        state.datumWriter.write(r, state.encoder);    }}
0
public void decode(final Blackhole blackhole, final TestStateDecode state) throws Exception
{    final Decoder d = state.decoder;    final ReflectDatumReader<BasicRecord> datumReader = new ReflectDatumReader<>(state.schema);    for (int i = 0; i < state.getBatchSize(); i++) {        blackhole.consume(datumReader.read(null, d));    }}
0
public void doSetupTrial() throws Exception
{    this.encoder = super.newEncoder(false, getNullOutputStream());    this.datumWriter = new ReflectDatumWriter<>(schema);    this.testData = new BasicRecord[getBatchSize()];    for (int i = 0; i < testData.length; i++) {        this.testData[i] = new BasicRecord(getRandom());    }}
0
public void doSetupTrial() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    Encoder encoder = super.newEncoder(true, baos);    ReflectDatumWriter<BasicRecord> writer = new ReflectDatumWriter<>(schema);    for (int i = 0; i < getBatchSize(); i++) {        final BasicRecord r = new BasicRecord(getRandom());        writer.write(r, encoder);    }    this.testData = baos.toByteArray();}
0
public void doSetupInvocation() throws Exception
{    this.decoder = DecoderFactory.get().validatingDecoder(schema, super.newDecoder(this.testData));}
0
public static ProtobufData get()
{    return INSTANCE;}
0
public DatumReader createDatumReader(Schema schema)
{    return new ProtobufDatumReader(schema, schema, this);}
0
public DatumWriter createDatumWriter(Schema schema)
{    return new ProtobufDatumWriter(schema, this);}
0
public void setField(Object r, String n, int pos, Object o)
{    setField(r, n, pos, o, getRecordState(r, getSchema(r.getClass())));}
0
public Object getField(Object r, String name, int pos)
{    return getField(r, name, pos, getRecordState(r, getSchema(r.getClass())));}
0
protected void setField(Object r, String n, int pos, Object o, Object state)
{    Builder b = (Builder) r;    FieldDescriptor f = ((FieldDescriptor[]) state)[pos];    switch(f.getType()) {        case MESSAGE:            if (o == null) {                b.clearField(f);                break;            }        default:            b.setField(f, o);    }}
0
protected Object getField(Object record, String name, int pos, Object state)
{    Message m = (Message) record;    FieldDescriptor f = ((FieldDescriptor[]) state)[pos];    switch(f.getType()) {        case MESSAGE:            if (!f.isRepeated() && !m.hasField(f))                return null;        default:            return m.getField(f);    }}
0
protected Object getRecordState(Object r, Schema s)
{    Descriptor d = ((MessageOrBuilder) r).getDescriptorForType();    FieldDescriptor[] fields = fieldCache.get(d);    if (fields == null) {                fields = new FieldDescriptor[s.getFields().size()];        for (Field f : s.getFields()) fields[f.pos()] = d.findFieldByName(f.name());                fieldCache.put(d, fields);    }    return fields;}
0
protected boolean isRecord(Object datum)
{    return datum instanceof Message;}
0
public Object newRecord(Object old, Schema schema)
{    try {        Class c = SpecificData.get().getClass(schema);        if (c == null)                        return newRecord(old, schema);        if (c.isInstance(old))                        return old;        return c.getMethod("newBuilder").invoke(null);    } catch (Exception e) {        throw new RuntimeException(e);    }}
0
protected boolean isArray(Object datum)
{    return datum instanceof List;}
0
protected boolean isBytes(Object datum)
{    return datum instanceof ByteString;}
0
protected Schema getRecordSchema(Object record)
{    Descriptor descriptor = ((Message) record).getDescriptorForType();    Schema schema = schemaCache.get(descriptor);    if (schema == null) {        schema = getSchema(descriptor);        schemaCache.put(descriptor, schema);    }    return schema;}
0
public Schema getSchema(Class c)
{    Schema schema = schemaCache.get(c);    if (schema == null) {                try {            Object descriptor = c.getMethod("getDescriptor").invoke(null);            if (c.isEnum())                schema = getSchema((EnumDescriptor) descriptor);            else                schema = getSchema((Descriptor) descriptor);        } catch (Exception e) {            throw new RuntimeException(e);        }                schemaCache.put(c, schema);    }    return schema;}
0
public Schema getSchema(Descriptor descriptor)
{    Map<Descriptor, Schema> seen = SEEN.get();    if (    seen.containsKey(descriptor))        return seen.get(descriptor);    boolean first = seen.isEmpty();    Conversion conversion = getConversionByDescriptor(descriptor);    if (conversion != null) {        Schema converted = conversion.getRecommendedSchema();        seen.put(descriptor, converted);        return converted;    }    try {        Schema result = Schema.createRecord(descriptor.getName(), null, getNamespace(descriptor.getFile(), descriptor.getContainingType()), false);        seen.put(descriptor, result);        List<Field> fields = new ArrayList<>();        for (FieldDescriptor f : descriptor.getFields()) fields.add(Accessor.createField(f.getName(), getSchema(f), null, getDefault(f)));        result.setFields(fields);        return result;    } finally {        if (first)            seen.clear();    }}
0
public String getNamespace(FileDescriptor fd, Descriptor containing)
{    FileOptions o = fd.getOptions();    String p = o.hasJavaPackage() ? o.getJavaPackage() : fd.getPackage();    String outer = "";    if (!o.getJavaMultipleFiles()) {        if (o.hasJavaOuterClassname()) {            outer = o.getJavaOuterClassname();        } else {            outer = new File(fd.getName()).getName();            outer = outer.substring(0, outer.lastIndexOf('.'));            outer = toCamelCase(outer);        }    }    StringBuilder inner = new StringBuilder();    while (containing != null) {        if (inner.length() == 0) {            inner.insert(0, containing.getName());        } else {            inner.insert(0, containing.getName() + "$");        }        containing = containing.getContainingType();    }    String d1 = (!outer.isEmpty() || inner.length() != 0 ? "." : "");    String d2 = (!outer.isEmpty() && inner.length() != 0 ? "$" : "");    return p + d1 + outer + d2 + inner;}
0
private static String toCamelCase(String s)
{    String[] parts = s.split("_");    StringBuilder camelCaseString = new StringBuilder();    for (String part : parts) {        camelCaseString.append(cap(part));    }    return camelCaseString.toString();}
0
private static String cap(String s)
{    return s.substring(0, 1).toUpperCase() + s.substring(1).toLowerCase();}
0
public Schema getSchema(FieldDescriptor f)
{    Schema s = getNonRepeatedSchema(f);    if (f.isRepeated())        s = Schema.createArray(s);    return s;}
0
private Schema getNonRepeatedSchema(FieldDescriptor f)
{    Schema result;    switch(f.getType()) {        case BOOL:            return Schema.create(Schema.Type.BOOLEAN);        case FLOAT:            return Schema.create(Schema.Type.FLOAT);        case DOUBLE:            return Schema.create(Schema.Type.DOUBLE);        case STRING:            Schema s = Schema.create(Schema.Type.STRING);            GenericData.setStringType(s, GenericData.StringType.String);            return s;        case BYTES:            return Schema.create(Schema.Type.BYTES);        case INT32:        case UINT32:        case SINT32:        case FIXED32:        case SFIXED32:            return Schema.create(Schema.Type.INT);        case INT64:        case UINT64:        case SINT64:        case FIXED64:        case SFIXED64:            return Schema.create(Schema.Type.LONG);        case ENUM:            return getSchema(f.getEnumType());        case MESSAGE:            result = getSchema(f.getMessageType());            if (f.isOptional())                                result = Schema.createUnion(Arrays.asList(NULL, result));            return result;                case GROUP:        default:            throw new RuntimeException("Unexpected type: " + f.getType());    }}
0
public Schema getSchema(EnumDescriptor d)
{    List<String> symbols = new ArrayList<>();    for (EnumValueDescriptor e : d.getValues()) {        symbols.add(e.getName());    }    return Schema.createEnum(d.getName(), null, getNamespace(d.getFile(), d.getContainingType()), symbols);}
0
private JsonNode getDefault(FieldDescriptor f)
{    if (    f.isRequired() || f.isRepeated())        return null;    if (f.hasDefaultValue()) {                Object value = f.getDefaultValue();        switch(f.getType()) {            case ENUM:                value = ((EnumValueDescriptor) value).getName();                break;        }        String json = toString(value);        try {            return MAPPER.readTree(FACTORY.createParser(json));        } catch (IOException e) {            throw new RuntimeException(e);        }    }    switch(    f.getType()) {        case BOOL:            return NODES.booleanNode(false);        case FLOAT:        case DOUBLE:        case INT32:        case UINT32:        case SINT32:        case FIXED32:        case SFIXED32:        case INT64:        case UINT64:        case SINT64:        case FIXED64:        case SFIXED64:            return NODES.numberNode(0);        case STRING:        case BYTES:            return NODES.textNode("");        case ENUM:            return NODES.textNode(f.getEnumType().getValues().get(0).getName());        case MESSAGE:            return NODES.nullNode();                case GROUP:        default:            throw new RuntimeException("Unexpected type: " + f.getType());    }}
0
private Conversion getConversionByDescriptor(Descriptor descriptor)
{    String namespace = getNamespace(descriptor.getFile(), descriptor.getContainingType());    String name = descriptor.getName();        String dot = namespace.endsWith("$") ? "" : ".";    try {        Class clazz = ClassUtils.forName(getClassLoader(), namespace + dot + name);        return getConversionByClass(clazz);    } catch (ClassNotFoundException e) {        return null;    }}
0
protected Object readRecord(Object old, Schema expected, ResolvingDecoder in) throws IOException
{    Message.Builder b = (Message.Builder) super.readRecord(old, expected, in);        return b.build();}
0
protected Object createEnum(String symbol, Schema schema)
{    try {        Class c = SpecificData.get().getClass(schema);        if (c == null)                        return super.createEnum(symbol, schema);        return ((ProtocolMessageEnum) Enum.valueOf(c, symbol)).getValueDescriptor();    } catch (Exception e) {        throw new RuntimeException(e);    }}
0
protected Object readBytes(Object old, Decoder in) throws IOException
{    return ByteString.copyFrom(((ByteBuffer) super.readBytes(old, in)).array());}
0
protected void writeEnum(Schema schema, Object datum, Encoder out) throws IOException
{    if (!(datum instanceof EnumValueDescriptor))                super.writeEnum(schema, datum, out);    else        out.writeEnum(schema.getEnumOrdinal(((EnumValueDescriptor) datum).getName()));}
0
protected void writeBytes(Object datum, Encoder out) throws IOException
{    ByteString bytes = (ByteString) datum;    out.writeBytes(bytes.toByteArray(), 0, bytes.size());}
0
public Class<Timestamp> getConvertedType()
{    return Timestamp.class;}
0
public String getLogicalTypeName()
{    return "timestamp-millis";}
0
public Timestamp fromLong(Long millisFromEpoch, Schema schema, LogicalType type) throws IllegalArgumentException
{    return ProtoConversions.fromLong(millisFromEpoch, TimestampPrecise.Millis);}
0
public Long toLong(Timestamp value, Schema schema, LogicalType type)
{    return ProtoConversions.toLong(value, TimestampPrecise.Millis);}
0
public Schema getRecommendedSchema()
{    return LogicalTypes.timestampMillis().addToSchema(Schema.create(Schema.Type.LONG));}
0
public Class<Timestamp> getConvertedType()
{    return Timestamp.class;}
0
public String getLogicalTypeName()
{    return "timestamp-micros";}
0
public Timestamp fromLong(Long microsFromEpoch, Schema schema, LogicalType type) throws IllegalArgumentException
{    return ProtoConversions.fromLong(microsFromEpoch, TimestampPrecise.Micros);}
0
public Long toLong(Timestamp value, Schema schema, LogicalType type)
{    return ProtoConversions.toLong(value, TimestampPrecise.Micros);}
0
public Schema getRecommendedSchema()
{    return LogicalTypes.timestampMicros().addToSchema(Schema.create(Schema.Type.LONG));}
0
private static long toLong(Timestamp value, TimestampPrecise precise)
{    long rv = 0L;    switch(precise) {        case Millis:            rv = value.getSeconds() * THOUSAND + value.getNanos() / MILLION;            break;        case Micros:            rv = value.getSeconds() * MILLION + value.getNanos() / THOUSAND;            break;    }    return rv;}
0
private static Timestamp fromLong(Long elapsedSinceEpoch, TimestampPrecise precise) throws IllegalArgumentException
{    long seconds = 0L;    int nanos = 0;    switch(precise) {        case Millis:            seconds = Math.floorDiv(elapsedSinceEpoch, THOUSAND);            nanos = (int) Math.floorMod(elapsedSinceEpoch, THOUSAND) * MILLION;            break;        case Micros:            seconds = Math.floorDiv(elapsedSinceEpoch, MILLION);            nanos = (int) Math.floorMod(elapsedSinceEpoch, MILLION) * THOUSAND;            break;    }    if (seconds < SECONDS_LOWERLIMIT || seconds > SECONDS_UPPERLIMIT) {        throw new IllegalArgumentException("given seconds is out of range");    }    if (nanos < NANOSECONDS_LOWERLIMIT || nanos > NANOSECONDS_UPPERLIMIT) {                throw new IllegalArgumentException("given nanos is out of range");    }    return Timestamp.newBuilder().setSeconds(seconds).setNanos(nanos).build();}
0
public final int getNumber()
{    return value;}
0
public static A valueOf(int value)
{    return forNumber(value);}
0
public static A forNumber(int value)
{    switch(value) {        case 1:            return X;        case 2:            return Y;        case 3:            return Z;        default:            return null;    }}
0
public static com.google.protobuf.Internal.EnumLiteMap<A> internalGetValueMap()
{    return internalValueMap;}
0
public A findValueByNumber(int number)
{    return A.forNumber(number);}
0
public final com.google.protobuf.Descriptors.EnumValueDescriptor getValueDescriptor()
{    return getDescriptor().getValues().get(ordinal());}
0
public final com.google.protobuf.Descriptors.EnumDescriptor getDescriptorForType()
{    return getDescriptor();}
0
public static final com.google.protobuf.Descriptors.EnumDescriptor getDescriptor()
{    return org.apache.avro.protobuf.multiplefiles.TestMultipleFiles.getDescriptor().getEnumTypes().get(0);}
0
public static A valueOf(com.google.protobuf.Descriptors.EnumValueDescriptor desc)
{    if (desc.getType() != getDescriptor()) {        throw new java.lang.IllegalArgumentException("EnumValueDescriptor is not for this type.");    }    return VALUES[desc.getIndex()];}
0
public final com.google.protobuf.UnknownFieldSet getUnknownFields()
{    return this.unknownFields;}
0
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.avro.protobuf.multiplefiles.TestMultipleFiles.internal_static_org_apache_avro_protobuf_multiplefiles_Foo_descriptor;}
0
protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.avro.protobuf.multiplefiles.TestMultipleFiles.internal_static_org_apache_avro_protobuf_multiplefiles_Foo_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.avro.protobuf.multiplefiles.Foo.class, org.apache.avro.protobuf.multiplefiles.Foo.Builder.class);}
0
public boolean hasInt32()
{    return ((bitField0_ & 0x00000001) == 0x00000001);}
0
public int getInt32()
{    return int32_;}
0
public boolean hasInt64()
{    return ((bitField0_ & 0x00000002) == 0x00000002);}
0
public long getInt64()
{    return int64_;}
0
public boolean hasUint32()
{    return ((bitField0_ & 0x00000004) == 0x00000004);}
0
public int getUint32()
{    return uint32_;}
0
public boolean hasUint64()
{    return ((bitField0_ & 0x00000008) == 0x00000008);}
0
public long getUint64()
{    return uint64_;}
0
public boolean hasSint32()
{    return ((bitField0_ & 0x00000010) == 0x00000010);}
0
public int getSint32()
{    return sint32_;}
0
public boolean hasSint64()
{    return ((bitField0_ & 0x00000020) == 0x00000020);}
0
public long getSint64()
{    return sint64_;}
0
public boolean hasFixed32()
{    return ((bitField0_ & 0x00000040) == 0x00000040);}
0
public int getFixed32()
{    return fixed32_;}
0
public boolean hasFixed64()
{    return ((bitField0_ & 0x00000080) == 0x00000080);}
0
public long getFixed64()
{    return fixed64_;}
0
public boolean hasSfixed32()
{    return ((bitField0_ & 0x00000100) == 0x00000100);}
0
public int getSfixed32()
{    return sfixed32_;}
0
public boolean hasSfixed64()
{    return ((bitField0_ & 0x00000200) == 0x00000200);}
0
public long getSfixed64()
{    return sfixed64_;}
0
public boolean hasFloat()
{    return ((bitField0_ & 0x00000400) == 0x00000400);}
0
public float getFloat()
{    return float_;}
0
public boolean hasDouble()
{    return ((bitField0_ & 0x00000800) == 0x00000800);}
0
public double getDouble()
{    return double_;}
0
public boolean hasBool()
{    return ((bitField0_ & 0x00001000) == 0x00001000);}
0
public boolean getBool()
{    return bool_;}
0
public boolean hasString()
{    return ((bitField0_ & 0x00002000) == 0x00002000);}
0
public java.lang.String getString()
{    java.lang.Object ref = string_;    if (ref instanceof java.lang.String) {        return (java.lang.String) ref;    } else {        com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;        java.lang.String s = bs.toStringUtf8();        if (bs.isValidUtf8()) {            string_ = s;        }        return s;    }}
0
public com.google.protobuf.ByteString getStringBytes()
{    java.lang.Object ref = string_;    if (ref instanceof java.lang.String) {        com.google.protobuf.ByteString b = com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);        string_ = b;        return b;    } else {        return (com.google.protobuf.ByteString) ref;    }}
0
public boolean hasBytes()
{    return ((bitField0_ & 0x00004000) == 0x00004000);}
0
public com.google.protobuf.ByteString getBytes()
{    return bytes_;}
0
public boolean hasEnum()
{    return ((bitField0_ & 0x00008000) == 0x00008000);}
0
public org.apache.avro.protobuf.multiplefiles.A getEnum()
{    org.apache.avro.protobuf.multiplefiles.A result = org.apache.avro.protobuf.multiplefiles.A.valueOf(enum_);    return result == null ? org.apache.avro.protobuf.multiplefiles.A.Z : result;}
0
public java.util.List<java.lang.Integer> getIntArrayList()
{    return intArray_;}
0
public int getIntArrayCount()
{    return intArray_.size();}
0
public int getIntArray(int index)
{    return intArray_.get(index);}
0
public java.util.List<org.apache.avro.protobuf.multiplefiles.Foo> getFooArrayList()
{    return fooArray_;}
0
public java.util.List<? extends org.apache.avro.protobuf.multiplefiles.FooOrBuilder> getFooArrayOrBuilderList()
{    return fooArray_;}
0
public int getFooArrayCount()
{    return fooArray_.size();}
0
public org.apache.avro.protobuf.multiplefiles.Foo getFooArray(int index)
{    return fooArray_.get(index);}
0
public org.apache.avro.protobuf.multiplefiles.FooOrBuilder getFooArrayOrBuilder(int index)
{    return fooArray_.get(index);}
0
public org.apache.avro.protobuf.multiplefiles.A convert(java.lang.Integer from)
{    org.apache.avro.protobuf.multiplefiles.A result = org.apache.avro.protobuf.multiplefiles.A.valueOf(from);    return result == null ? org.apache.avro.protobuf.multiplefiles.A.X : result;}
0
public java.util.List<org.apache.avro.protobuf.multiplefiles.A> getSymsList()
{    return new com.google.protobuf.Internal.ListAdapter<java.lang.Integer, org.apache.avro.protobuf.multiplefiles.A>(syms_, syms_converter_);}
0
public int getSymsCount()
{    return syms_.size();}
0
public org.apache.avro.protobuf.multiplefiles.A getSyms(int index)
{    return syms_converter_.convert(syms_.get(index));}
0
public boolean hasFoo()
{    return ((bitField0_ & 0x00010000) == 0x00010000);}
0
public org.apache.avro.protobuf.multiplefiles.Foo getFoo()
{    return foo_ == null ? org.apache.avro.protobuf.multiplefiles.Foo.getDefaultInstance() : foo_;}
0
public org.apache.avro.protobuf.multiplefiles.FooOrBuilder getFooOrBuilder()
{    return foo_ == null ? org.apache.avro.protobuf.multiplefiles.Foo.getDefaultInstance() : foo_;}
0
public boolean hasTimestamp()
{    return ((bitField0_ & 0x00020000) == 0x00020000);}
0
public com.google.protobuf.Timestamp getTimestamp()
{    return timestamp_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : timestamp_;}
0
public com.google.protobuf.TimestampOrBuilder getTimestampOrBuilder()
{    return timestamp_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : timestamp_;}
0
public final boolean isInitialized()
{    byte isInitialized = memoizedIsInitialized;    if (isInitialized == 1)        return true;    if (isInitialized == 0)        return false;    if (!hasInt32()) {        memoizedIsInitialized = 0;        return false;    }    for (int i = 0; i < getFooArrayCount(); i++) {        if (!getFooArray(i).isInitialized()) {            memoizedIsInitialized = 0;            return false;        }    }    if (hasFoo()) {        if (!getFoo().isInitialized()) {            memoizedIsInitialized = 0;            return false;        }    }    memoizedIsInitialized = 1;    return true;}
0
public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException
{    if (((bitField0_ & 0x00000001) == 0x00000001)) {        output.writeInt32(1, int32_);    }    if (((bitField0_ & 0x00000002) == 0x00000002)) {        output.writeInt64(2, int64_);    }    if (((bitField0_ & 0x00000004) == 0x00000004)) {        output.writeUInt32(3, uint32_);    }    if (((bitField0_ & 0x00000008) == 0x00000008)) {        output.writeUInt64(4, uint64_);    }    if (((bitField0_ & 0x00000010) == 0x00000010)) {        output.writeSInt32(5, sint32_);    }    if (((bitField0_ & 0x00000020) == 0x00000020)) {        output.writeSInt64(6, sint64_);    }    if (((bitField0_ & 0x00000040) == 0x00000040)) {        output.writeFixed32(7, fixed32_);    }    if (((bitField0_ & 0x00000080) == 0x00000080)) {        output.writeFixed64(8, fixed64_);    }    if (((bitField0_ & 0x00000100) == 0x00000100)) {        output.writeSFixed32(9, sfixed32_);    }    if (((bitField0_ & 0x00000200) == 0x00000200)) {        output.writeSFixed64(10, sfixed64_);    }    if (((bitField0_ & 0x00000400) == 0x00000400)) {        output.writeFloat(11, float_);    }    if (((bitField0_ & 0x00000800) == 0x00000800)) {        output.writeDouble(12, double_);    }    if (((bitField0_ & 0x00001000) == 0x00001000)) {        output.writeBool(13, bool_);    }    if (((bitField0_ & 0x00002000) == 0x00002000)) {        com.google.protobuf.GeneratedMessageV3.writeString(output, 14, string_);    }    if (((bitField0_ & 0x00004000) == 0x00004000)) {        output.writeBytes(15, bytes_);    }    if (((bitField0_ & 0x00008000) == 0x00008000)) {        output.writeEnum(16, enum_);    }    for (int i = 0; i < intArray_.size(); i++) {        output.writeInt32(17, intArray_.get(i));    }    if (((bitField0_ & 0x00010000) == 0x00010000)) {        output.writeMessage(18, getFoo());    }    for (int i = 0; i < syms_.size(); i++) {        output.writeEnum(19, syms_.get(i));    }    for (int i = 0; i < fooArray_.size(); i++) {        output.writeMessage(20, fooArray_.get(i));    }    if (((bitField0_ & 0x00020000) == 0x00020000)) {        output.writeMessage(21, getTimestamp());    }    unknownFields.writeTo(output);}
0
public int getSerializedSize()
{    int size = memoizedSize;    if (size != -1)        return size;    size = 0;    if (((bitField0_ & 0x00000001) == 0x00000001)) {        size += com.google.protobuf.CodedOutputStream.computeInt32Size(1, int32_);    }    if (((bitField0_ & 0x00000002) == 0x00000002)) {        size += com.google.protobuf.CodedOutputStream.computeInt64Size(2, int64_);    }    if (((bitField0_ & 0x00000004) == 0x00000004)) {        size += com.google.protobuf.CodedOutputStream.computeUInt32Size(3, uint32_);    }    if (((bitField0_ & 0x00000008) == 0x00000008)) {        size += com.google.protobuf.CodedOutputStream.computeUInt64Size(4, uint64_);    }    if (((bitField0_ & 0x00000010) == 0x00000010)) {        size += com.google.protobuf.CodedOutputStream.computeSInt32Size(5, sint32_);    }    if (((bitField0_ & 0x00000020) == 0x00000020)) {        size += com.google.protobuf.CodedOutputStream.computeSInt64Size(6, sint64_);    }    if (((bitField0_ & 0x00000040) == 0x00000040)) {        size += com.google.protobuf.CodedOutputStream.computeFixed32Size(7, fixed32_);    }    if (((bitField0_ & 0x00000080) == 0x00000080)) {        size += com.google.protobuf.CodedOutputStream.computeFixed64Size(8, fixed64_);    }    if (((bitField0_ & 0x00000100) == 0x00000100)) {        size += com.google.protobuf.CodedOutputStream.computeSFixed32Size(9, sfixed32_);    }    if (((bitField0_ & 0x00000200) == 0x00000200)) {        size += com.google.protobuf.CodedOutputStream.computeSFixed64Size(10, sfixed64_);    }    if (((bitField0_ & 0x00000400) == 0x00000400)) {        size += com.google.protobuf.CodedOutputStream.computeFloatSize(11, float_);    }    if (((bitField0_ & 0x00000800) == 0x00000800)) {        size += com.google.protobuf.CodedOutputStream.computeDoubleSize(12, double_);    }    if (((bitField0_ & 0x00001000) == 0x00001000)) {        size += com.google.protobuf.CodedOutputStream.computeBoolSize(13, bool_);    }    if (((bitField0_ & 0x00002000) == 0x00002000)) {        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(14, string_);    }    if (((bitField0_ & 0x00004000) == 0x00004000)) {        size += com.google.protobuf.CodedOutputStream.computeBytesSize(15, bytes_);    }    if (((bitField0_ & 0x00008000) == 0x00008000)) {        size += com.google.protobuf.CodedOutputStream.computeEnumSize(16, enum_);    }    {        int dataSize = 0;        for (int i = 0; i < intArray_.size(); i++) {            dataSize += com.google.protobuf.CodedOutputStream.computeInt32SizeNoTag(intArray_.get(i));        }        size += dataSize;        size += 2 * getIntArrayList().size();    }    if (((bitField0_ & 0x00010000) == 0x00010000)) {        size += com.google.protobuf.CodedOutputStream.computeMessageSize(18, getFoo());    }    {        int dataSize = 0;        for (int i = 0; i < syms_.size(); i++) {            dataSize += com.google.protobuf.CodedOutputStream.computeEnumSizeNoTag(syms_.get(i));        }        size += dataSize;        size += 2 * syms_.size();    }    for (int i = 0; i < fooArray_.size(); i++) {        size += com.google.protobuf.CodedOutputStream.computeMessageSize(20, fooArray_.get(i));    }    if (((bitField0_ & 0x00020000) == 0x00020000)) {        size += com.google.protobuf.CodedOutputStream.computeMessageSize(21, getTimestamp());    }    size += unknownFields.getSerializedSize();    memoizedSize = size;    return size;}
0
public boolean equals(final java.lang.Object obj)
{    if (obj == this) {        return true;    }    if (!(obj instanceof org.apache.avro.protobuf.multiplefiles.Foo)) {        return super.equals(obj);    }    org.apache.avro.protobuf.multiplefiles.Foo other = (org.apache.avro.protobuf.multiplefiles.Foo) obj;    boolean result = true;    result = result && (hasInt32() == other.hasInt32());    if (hasInt32()) {        result = result && (getInt32() == other.getInt32());    }    result = result && (hasInt64() == other.hasInt64());    if (hasInt64()) {        result = result && (getInt64() == other.getInt64());    }    result = result && (hasUint32() == other.hasUint32());    if (hasUint32()) {        result = result && (getUint32() == other.getUint32());    }    result = result && (hasUint64() == other.hasUint64());    if (hasUint64()) {        result = result && (getUint64() == other.getUint64());    }    result = result && (hasSint32() == other.hasSint32());    if (hasSint32()) {        result = result && (getSint32() == other.getSint32());    }    result = result && (hasSint64() == other.hasSint64());    if (hasSint64()) {        result = result && (getSint64() == other.getSint64());    }    result = result && (hasFixed32() == other.hasFixed32());    if (hasFixed32()) {        result = result && (getFixed32() == other.getFixed32());    }    result = result && (hasFixed64() == other.hasFixed64());    if (hasFixed64()) {        result = result && (getFixed64() == other.getFixed64());    }    result = result && (hasSfixed32() == other.hasSfixed32());    if (hasSfixed32()) {        result = result && (getSfixed32() == other.getSfixed32());    }    result = result && (hasSfixed64() == other.hasSfixed64());    if (hasSfixed64()) {        result = result && (getSfixed64() == other.getSfixed64());    }    result = result && (hasFloat() == other.hasFloat());    if (hasFloat()) {        result = result && (java.lang.Float.floatToIntBits(getFloat()) == java.lang.Float.floatToIntBits(other.getFloat()));    }    result = result && (hasDouble() == other.hasDouble());    if (hasDouble()) {        result = result && (java.lang.Double.doubleToLongBits(getDouble()) == java.lang.Double.doubleToLongBits(other.getDouble()));    }    result = result && (hasBool() == other.hasBool());    if (hasBool()) {        result = result && (getBool() == other.getBool());    }    result = result && (hasString() == other.hasString());    if (hasString()) {        result = result && getString().equals(other.getString());    }    result = result && (hasBytes() == other.hasBytes());    if (hasBytes()) {        result = result && getBytes().equals(other.getBytes());    }    result = result && (hasEnum() == other.hasEnum());    if (hasEnum()) {        result = result && enum_ == other.enum_;    }    result = result && getIntArrayList().equals(other.getIntArrayList());    result = result && getFooArrayList().equals(other.getFooArrayList());    result = result && syms_.equals(other.syms_);    result = result && (hasFoo() == other.hasFoo());    if (hasFoo()) {        result = result && getFoo().equals(other.getFoo());    }    result = result && (hasTimestamp() == other.hasTimestamp());    if (hasTimestamp()) {        result = result && getTimestamp().equals(other.getTimestamp());    }    result = result && unknownFields.equals(other.unknownFields);    return result;}
0
public int hashCode()
{    if (memoizedHashCode != 0) {        return memoizedHashCode;    }    int hash = 41;    hash = (19 * hash) + getDescriptor().hashCode();    if (hasInt32()) {        hash = (37 * hash) + INT32_FIELD_NUMBER;        hash = (53 * hash) + getInt32();    }    if (hasInt64()) {        hash = (37 * hash) + INT64_FIELD_NUMBER;        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(getInt64());    }    if (hasUint32()) {        hash = (37 * hash) + UINT32_FIELD_NUMBER;        hash = (53 * hash) + getUint32();    }    if (hasUint64()) {        hash = (37 * hash) + UINT64_FIELD_NUMBER;        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(getUint64());    }    if (hasSint32()) {        hash = (37 * hash) + SINT32_FIELD_NUMBER;        hash = (53 * hash) + getSint32();    }    if (hasSint64()) {        hash = (37 * hash) + SINT64_FIELD_NUMBER;        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(getSint64());    }    if (hasFixed32()) {        hash = (37 * hash) + FIXED32_FIELD_NUMBER;        hash = (53 * hash) + getFixed32();    }    if (hasFixed64()) {        hash = (37 * hash) + FIXED64_FIELD_NUMBER;        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(getFixed64());    }    if (hasSfixed32()) {        hash = (37 * hash) + SFIXED32_FIELD_NUMBER;        hash = (53 * hash) + getSfixed32();    }    if (hasSfixed64()) {        hash = (37 * hash) + SFIXED64_FIELD_NUMBER;        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(getSfixed64());    }    if (hasFloat()) {        hash = (37 * hash) + FLOAT_FIELD_NUMBER;        hash = (53 * hash) + java.lang.Float.floatToIntBits(getFloat());    }    if (hasDouble()) {        hash = (37 * hash) + DOUBLE_FIELD_NUMBER;        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(java.lang.Double.doubleToLongBits(getDouble()));    }    if (hasBool()) {        hash = (37 * hash) + BOOL_FIELD_NUMBER;        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(getBool());    }    if (hasString()) {        hash = (37 * hash) + STRING_FIELD_NUMBER;        hash = (53 * hash) + getString().hashCode();    }    if (hasBytes()) {        hash = (37 * hash) + BYTES_FIELD_NUMBER;        hash = (53 * hash) + getBytes().hashCode();    }    if (hasEnum()) {        hash = (37 * hash) + ENUM_FIELD_NUMBER;        hash = (53 * hash) + enum_;    }    if (getIntArrayCount() > 0) {        hash = (37 * hash) + INTARRAY_FIELD_NUMBER;        hash = (53 * hash) + getIntArrayList().hashCode();    }    if (getFooArrayCount() > 0) {        hash = (37 * hash) + FOOARRAY_FIELD_NUMBER;        hash = (53 * hash) + getFooArrayList().hashCode();    }    if (getSymsCount() > 0) {        hash = (37 * hash) + SYMS_FIELD_NUMBER;        hash = (53 * hash) + syms_.hashCode();    }    if (hasFoo()) {        hash = (37 * hash) + FOO_FIELD_NUMBER;        hash = (53 * hash) + getFoo().hashCode();    }    if (hasTimestamp()) {        hash = (37 * hash) + TIMESTAMP_FIELD_NUMBER;        hash = (53 * hash) + getTimestamp().hashCode();    }    hash = (29 * hash) + unknownFields.hashCode();    memoizedHashCode = hash;    return hash;}
0
public static org.apache.avro.protobuf.multiplefiles.Foo parseFrom(java.nio.ByteBuffer data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
0
public static org.apache.avro.protobuf.multiplefiles.Foo parseFrom(java.nio.ByteBuffer data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
0
public static org.apache.avro.protobuf.multiplefiles.Foo parseFrom(com.google.protobuf.ByteString data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
0
public static org.apache.avro.protobuf.multiplefiles.Foo parseFrom(com.google.protobuf.ByteString data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
0
public static org.apache.avro.protobuf.multiplefiles.Foo parseFrom(byte[] data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
0
public static org.apache.avro.protobuf.multiplefiles.Foo parseFrom(byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
0
public static org.apache.avro.protobuf.multiplefiles.Foo parseFrom(java.io.InputStream input) throws java.io.IOException
{    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);}
0
public static org.apache.avro.protobuf.multiplefiles.Foo parseFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input, extensionRegistry);}
0
public static org.apache.avro.protobuf.multiplefiles.Foo parseDelimitedFrom(java.io.InputStream input) throws java.io.IOException
{    return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(PARSER, input);}
0
public static org.apache.avro.protobuf.multiplefiles.Foo parseDelimitedFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(PARSER, input, extensionRegistry);}
0
public static org.apache.avro.protobuf.multiplefiles.Foo parseFrom(com.google.protobuf.CodedInputStream input) throws java.io.IOException
{    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);}
0
public static org.apache.avro.protobuf.multiplefiles.Foo parseFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input, extensionRegistry);}
0
public Builder newBuilderForType()
{    return newBuilder();}
0
public static Builder newBuilder()
{    return DEFAULT_INSTANCE.toBuilder();}
0
public static Builder newBuilder(org.apache.avro.protobuf.multiplefiles.Foo prototype)
{    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);}
0
public Builder toBuilder()
{    return this == DEFAULT_INSTANCE ? new Builder() : new Builder().mergeFrom(this);}
0
protected Builder newBuilderForType(com.google.protobuf.GeneratedMessageV3.BuilderParent parent)
{    Builder builder = new Builder(parent);    return builder;}
0
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.avro.protobuf.multiplefiles.TestMultipleFiles.internal_static_org_apache_avro_protobuf_multiplefiles_Foo_descriptor;}
0
protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.avro.protobuf.multiplefiles.TestMultipleFiles.internal_static_org_apache_avro_protobuf_multiplefiles_Foo_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.avro.protobuf.multiplefiles.Foo.class, org.apache.avro.protobuf.multiplefiles.Foo.Builder.class);}
0
private void maybeForceBuilderInitialization()
{    if (com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders) {        getFooArrayFieldBuilder();        getFooFieldBuilder();        getTimestampFieldBuilder();    }}
0
public Builder clear()
{    super.clear();    int32_ = 0;    bitField0_ = (bitField0_ & ~0x00000001);    int64_ = 0L;    bitField0_ = (bitField0_ & ~0x00000002);    uint32_ = 0;    bitField0_ = (bitField0_ & ~0x00000004);    uint64_ = 0L;    bitField0_ = (bitField0_ & ~0x00000008);    sint32_ = 0;    bitField0_ = (bitField0_ & ~0x00000010);    sint64_ = 0L;    bitField0_ = (bitField0_ & ~0x00000020);    fixed32_ = 0;    bitField0_ = (bitField0_ & ~0x00000040);    fixed64_ = 0L;    bitField0_ = (bitField0_ & ~0x00000080);    sfixed32_ = 0;    bitField0_ = (bitField0_ & ~0x00000100);    sfixed64_ = 0L;    bitField0_ = (bitField0_ & ~0x00000200);    float_ = 0F;    bitField0_ = (bitField0_ & ~0x00000400);    double_ = 0D;    bitField0_ = (bitField0_ & ~0x00000800);    bool_ = false;    bitField0_ = (bitField0_ & ~0x00001000);    string_ = "";    bitField0_ = (bitField0_ & ~0x00002000);    bytes_ = com.google.protobuf.ByteString.EMPTY;    bitField0_ = (bitField0_ & ~0x00004000);    enum_ = 3;    bitField0_ = (bitField0_ & ~0x00008000);    intArray_ = java.util.Collections.emptyList();    bitField0_ = (bitField0_ & ~0x00010000);    if (fooArrayBuilder_ == null) {        fooArray_ = java.util.Collections.emptyList();        bitField0_ = (bitField0_ & ~0x00020000);    } else {        fooArrayBuilder_.clear();    }    syms_ = java.util.Collections.emptyList();    bitField0_ = (bitField0_ & ~0x00040000);    if (fooBuilder_ == null) {        foo_ = null;    } else {        fooBuilder_.clear();    }    bitField0_ = (bitField0_ & ~0x00080000);    if (timestampBuilder_ == null) {        timestamp_ = null;    } else {        timestampBuilder_.clear();    }    bitField0_ = (bitField0_ & ~0x00100000);    return this;}
0
public com.google.protobuf.Descriptors.Descriptor getDescriptorForType()
{    return org.apache.avro.protobuf.multiplefiles.TestMultipleFiles.internal_static_org_apache_avro_protobuf_multiplefiles_Foo_descriptor;}
0
public org.apache.avro.protobuf.multiplefiles.Foo getDefaultInstanceForType()
{    return org.apache.avro.protobuf.multiplefiles.Foo.getDefaultInstance();}
0
public org.apache.avro.protobuf.multiplefiles.Foo build()
{    org.apache.avro.protobuf.multiplefiles.Foo result = buildPartial();    if (!result.isInitialized()) {        throw newUninitializedMessageException(result);    }    return result;}
0
public org.apache.avro.protobuf.multiplefiles.Foo buildPartial()
{    org.apache.avro.protobuf.multiplefiles.Foo result = new org.apache.avro.protobuf.multiplefiles.Foo(this);    int from_bitField0_ = bitField0_;    int to_bitField0_ = 0;    if (((from_bitField0_ & 0x00000001) == 0x00000001)) {        to_bitField0_ |= 0x00000001;    }    result.int32_ = int32_;    if (((from_bitField0_ & 0x00000002) == 0x00000002)) {        to_bitField0_ |= 0x00000002;    }    result.int64_ = int64_;    if (((from_bitField0_ & 0x00000004) == 0x00000004)) {        to_bitField0_ |= 0x00000004;    }    result.uint32_ = uint32_;    if (((from_bitField0_ & 0x00000008) == 0x00000008)) {        to_bitField0_ |= 0x00000008;    }    result.uint64_ = uint64_;    if (((from_bitField0_ & 0x00000010) == 0x00000010)) {        to_bitField0_ |= 0x00000010;    }    result.sint32_ = sint32_;    if (((from_bitField0_ & 0x00000020) == 0x00000020)) {        to_bitField0_ |= 0x00000020;    }    result.sint64_ = sint64_;    if (((from_bitField0_ & 0x00000040) == 0x00000040)) {        to_bitField0_ |= 0x00000040;    }    result.fixed32_ = fixed32_;    if (((from_bitField0_ & 0x00000080) == 0x00000080)) {        to_bitField0_ |= 0x00000080;    }    result.fixed64_ = fixed64_;    if (((from_bitField0_ & 0x00000100) == 0x00000100)) {        to_bitField0_ |= 0x00000100;    }    result.sfixed32_ = sfixed32_;    if (((from_bitField0_ & 0x00000200) == 0x00000200)) {        to_bitField0_ |= 0x00000200;    }    result.sfixed64_ = sfixed64_;    if (((from_bitField0_ & 0x00000400) == 0x00000400)) {        to_bitField0_ |= 0x00000400;    }    result.float_ = float_;    if (((from_bitField0_ & 0x00000800) == 0x00000800)) {        to_bitField0_ |= 0x00000800;    }    result.double_ = double_;    if (((from_bitField0_ & 0x00001000) == 0x00001000)) {        to_bitField0_ |= 0x00001000;    }    result.bool_ = bool_;    if (((from_bitField0_ & 0x00002000) == 0x00002000)) {        to_bitField0_ |= 0x00002000;    }    result.string_ = string_;    if (((from_bitField0_ & 0x00004000) == 0x00004000)) {        to_bitField0_ |= 0x00004000;    }    result.bytes_ = bytes_;    if (((from_bitField0_ & 0x00008000) == 0x00008000)) {        to_bitField0_ |= 0x00008000;    }    result.enum_ = enum_;    if (((bitField0_ & 0x00010000) == 0x00010000)) {        intArray_ = java.util.Collections.unmodifiableList(intArray_);        bitField0_ = (bitField0_ & ~0x00010000);    }    result.intArray_ = intArray_;    if (fooArrayBuilder_ == null) {        if (((bitField0_ & 0x00020000) == 0x00020000)) {            fooArray_ = java.util.Collections.unmodifiableList(fooArray_);            bitField0_ = (bitField0_ & ~0x00020000);        }        result.fooArray_ = fooArray_;    } else {        result.fooArray_ = fooArrayBuilder_.build();    }    if (((bitField0_ & 0x00040000) == 0x00040000)) {        syms_ = java.util.Collections.unmodifiableList(syms_);        bitField0_ = (bitField0_ & ~0x00040000);    }    result.syms_ = syms_;    if (((from_bitField0_ & 0x00080000) == 0x00080000)) {        to_bitField0_ |= 0x00010000;    }    if (fooBuilder_ == null) {        result.foo_ = foo_;    } else {        result.foo_ = fooBuilder_.build();    }    if (((from_bitField0_ & 0x00100000) == 0x00100000)) {        to_bitField0_ |= 0x00020000;    }    if (timestampBuilder_ == null) {        result.timestamp_ = timestamp_;    } else {        result.timestamp_ = timestampBuilder_.build();    }    result.bitField0_ = to_bitField0_;    onBuilt();    return result;}
0
public Builder clone()
{    return (Builder) super.clone();}
0
public Builder setField(com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value)
{    return (Builder) super.setField(field, value);}
0
public Builder clearField(com.google.protobuf.Descriptors.FieldDescriptor field)
{    return (Builder) super.clearField(field);}
0
public Builder clearOneof(com.google.protobuf.Descriptors.OneofDescriptor oneof)
{    return (Builder) super.clearOneof(oneof);}
0
public Builder setRepeatedField(com.google.protobuf.Descriptors.FieldDescriptor field, int index, java.lang.Object value)
{    return (Builder) super.setRepeatedField(field, index, value);}
0
public Builder addRepeatedField(com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value)
{    return (Builder) super.addRepeatedField(field, value);}
0
public Builder mergeFrom(com.google.protobuf.Message other)
{    if (other instanceof org.apache.avro.protobuf.multiplefiles.Foo) {        return mergeFrom((org.apache.avro.protobuf.multiplefiles.Foo) other);    } else {        super.mergeFrom(other);        return this;    }}
0
public Builder mergeFrom(org.apache.avro.protobuf.multiplefiles.Foo other)
{    if (other == org.apache.avro.protobuf.multiplefiles.Foo.getDefaultInstance())        return this;    if (other.hasInt32()) {        setInt32(other.getInt32());    }    if (other.hasInt64()) {        setInt64(other.getInt64());    }    if (other.hasUint32()) {        setUint32(other.getUint32());    }    if (other.hasUint64()) {        setUint64(other.getUint64());    }    if (other.hasSint32()) {        setSint32(other.getSint32());    }    if (other.hasSint64()) {        setSint64(other.getSint64());    }    if (other.hasFixed32()) {        setFixed32(other.getFixed32());    }    if (other.hasFixed64()) {        setFixed64(other.getFixed64());    }    if (other.hasSfixed32()) {        setSfixed32(other.getSfixed32());    }    if (other.hasSfixed64()) {        setSfixed64(other.getSfixed64());    }    if (other.hasFloat()) {        setFloat(other.getFloat());    }    if (other.hasDouble()) {        setDouble(other.getDouble());    }    if (other.hasBool()) {        setBool(other.getBool());    }    if (other.hasString()) {        bitField0_ |= 0x00002000;        string_ = other.string_;        onChanged();    }    if (other.hasBytes()) {        setBytes(other.getBytes());    }    if (other.hasEnum()) {        setEnum(other.getEnum());    }    if (!other.intArray_.isEmpty()) {        if (intArray_.isEmpty()) {            intArray_ = other.intArray_;            bitField0_ = (bitField0_ & ~0x00010000);        } else {            ensureIntArrayIsMutable();            intArray_.addAll(other.intArray_);        }        onChanged();    }    if (fooArrayBuilder_ == null) {        if (!other.fooArray_.isEmpty()) {            if (fooArray_.isEmpty()) {                fooArray_ = other.fooArray_;                bitField0_ = (bitField0_ & ~0x00020000);            } else {                ensureFooArrayIsMutable();                fooArray_.addAll(other.fooArray_);            }            onChanged();        }    } else {        if (!other.fooArray_.isEmpty()) {            if (fooArrayBuilder_.isEmpty()) {                fooArrayBuilder_.dispose();                fooArrayBuilder_ = null;                fooArray_ = other.fooArray_;                bitField0_ = (bitField0_ & ~0x00020000);                fooArrayBuilder_ = com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ? getFooArrayFieldBuilder() : null;            } else {                fooArrayBuilder_.addAllMessages(other.fooArray_);            }        }    }    if (!other.syms_.isEmpty()) {        if (syms_.isEmpty()) {            syms_ = other.syms_;            bitField0_ = (bitField0_ & ~0x00040000);        } else {            ensureSymsIsMutable();            syms_.addAll(other.syms_);        }        onChanged();    }    if (other.hasFoo()) {        mergeFoo(other.getFoo());    }    if (other.hasTimestamp()) {        mergeTimestamp(other.getTimestamp());    }    this.mergeUnknownFields(other.unknownFields);    onChanged();    return this;}
0
public final boolean isInitialized()
{    if (!hasInt32()) {        return false;    }    for (int i = 0; i < getFooArrayCount(); i++) {        if (!getFooArray(i).isInitialized()) {            return false;        }    }    if (hasFoo()) {        if (!getFoo().isInitialized()) {            return false;        }    }    return true;}
0
public Builder mergeFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    org.apache.avro.protobuf.multiplefiles.Foo parsedMessage = null;    try {        parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);    } catch (com.google.protobuf.InvalidProtocolBufferException e) {        parsedMessage = (org.apache.avro.protobuf.multiplefiles.Foo) e.getUnfinishedMessage();        throw e.unwrapIOException();    } finally {        if (parsedMessage != null) {            mergeFrom(parsedMessage);        }    }    return this;}
0
public boolean hasInt32()
{    return ((bitField0_ & 0x00000001) == 0x00000001);}
0
public int getInt32()
{    return int32_;}
0
public Builder setInt32(int value)
{    bitField0_ |= 0x00000001;    int32_ = value;    onChanged();    return this;}
0
public Builder clearInt32()
{    bitField0_ = (bitField0_ & ~0x00000001);    int32_ = 0;    onChanged();    return this;}
0
public boolean hasInt64()
{    return ((bitField0_ & 0x00000002) == 0x00000002);}
0
public long getInt64()
{    return int64_;}
0
public Builder setInt64(long value)
{    bitField0_ |= 0x00000002;    int64_ = value;    onChanged();    return this;}
0
public Builder clearInt64()
{    bitField0_ = (bitField0_ & ~0x00000002);    int64_ = 0L;    onChanged();    return this;}
0
public boolean hasUint32()
{    return ((bitField0_ & 0x00000004) == 0x00000004);}
0
public int getUint32()
{    return uint32_;}
0
public Builder setUint32(int value)
{    bitField0_ |= 0x00000004;    uint32_ = value;    onChanged();    return this;}
0
public Builder clearUint32()
{    bitField0_ = (bitField0_ & ~0x00000004);    uint32_ = 0;    onChanged();    return this;}
0
public boolean hasUint64()
{    return ((bitField0_ & 0x00000008) == 0x00000008);}
0
public long getUint64()
{    return uint64_;}
0
public Builder setUint64(long value)
{    bitField0_ |= 0x00000008;    uint64_ = value;    onChanged();    return this;}
0
public Builder clearUint64()
{    bitField0_ = (bitField0_ & ~0x00000008);    uint64_ = 0L;    onChanged();    return this;}
0
public boolean hasSint32()
{    return ((bitField0_ & 0x00000010) == 0x00000010);}
0
public int getSint32()
{    return sint32_;}
0
public Builder setSint32(int value)
{    bitField0_ |= 0x00000010;    sint32_ = value;    onChanged();    return this;}
0
public Builder clearSint32()
{    bitField0_ = (bitField0_ & ~0x00000010);    sint32_ = 0;    onChanged();    return this;}
0
public boolean hasSint64()
{    return ((bitField0_ & 0x00000020) == 0x00000020);}
0
public long getSint64()
{    return sint64_;}
0
public Builder setSint64(long value)
{    bitField0_ |= 0x00000020;    sint64_ = value;    onChanged();    return this;}
0
public Builder clearSint64()
{    bitField0_ = (bitField0_ & ~0x00000020);    sint64_ = 0L;    onChanged();    return this;}
0
public boolean hasFixed32()
{    return ((bitField0_ & 0x00000040) == 0x00000040);}
0
public int getFixed32()
{    return fixed32_;}
0
public Builder setFixed32(int value)
{    bitField0_ |= 0x00000040;    fixed32_ = value;    onChanged();    return this;}
0
public Builder clearFixed32()
{    bitField0_ = (bitField0_ & ~0x00000040);    fixed32_ = 0;    onChanged();    return this;}
0
public boolean hasFixed64()
{    return ((bitField0_ & 0x00000080) == 0x00000080);}
0
public long getFixed64()
{    return fixed64_;}
0
public Builder setFixed64(long value)
{    bitField0_ |= 0x00000080;    fixed64_ = value;    onChanged();    return this;}
0
public Builder clearFixed64()
{    bitField0_ = (bitField0_ & ~0x00000080);    fixed64_ = 0L;    onChanged();    return this;}
0
public boolean hasSfixed32()
{    return ((bitField0_ & 0x00000100) == 0x00000100);}
0
public int getSfixed32()
{    return sfixed32_;}
0
public Builder setSfixed32(int value)
{    bitField0_ |= 0x00000100;    sfixed32_ = value;    onChanged();    return this;}
0
public Builder clearSfixed32()
{    bitField0_ = (bitField0_ & ~0x00000100);    sfixed32_ = 0;    onChanged();    return this;}
0
public boolean hasSfixed64()
{    return ((bitField0_ & 0x00000200) == 0x00000200);}
0
public long getSfixed64()
{    return sfixed64_;}
0
public Builder setSfixed64(long value)
{    bitField0_ |= 0x00000200;    sfixed64_ = value;    onChanged();    return this;}
0
public Builder clearSfixed64()
{    bitField0_ = (bitField0_ & ~0x00000200);    sfixed64_ = 0L;    onChanged();    return this;}
0
public boolean hasFloat()
{    return ((bitField0_ & 0x00000400) == 0x00000400);}
0
public float getFloat()
{    return float_;}
0
public Builder setFloat(float value)
{    bitField0_ |= 0x00000400;    float_ = value;    onChanged();    return this;}
0
public Builder clearFloat()
{    bitField0_ = (bitField0_ & ~0x00000400);    float_ = 0F;    onChanged();    return this;}
0
public boolean hasDouble()
{    return ((bitField0_ & 0x00000800) == 0x00000800);}
0
public double getDouble()
{    return double_;}
0
public Builder setDouble(double value)
{    bitField0_ |= 0x00000800;    double_ = value;    onChanged();    return this;}
0
public Builder clearDouble()
{    bitField0_ = (bitField0_ & ~0x00000800);    double_ = 0D;    onChanged();    return this;}
0
public boolean hasBool()
{    return ((bitField0_ & 0x00001000) == 0x00001000);}
0
public boolean getBool()
{    return bool_;}
0
public Builder setBool(boolean value)
{    bitField0_ |= 0x00001000;    bool_ = value;    onChanged();    return this;}
0
public Builder clearBool()
{    bitField0_ = (bitField0_ & ~0x00001000);    bool_ = false;    onChanged();    return this;}
0
public boolean hasString()
{    return ((bitField0_ & 0x00002000) == 0x00002000);}
0
public java.lang.String getString()
{    java.lang.Object ref = string_;    if (!(ref instanceof java.lang.String)) {        com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;        java.lang.String s = bs.toStringUtf8();        if (bs.isValidUtf8()) {            string_ = s;        }        return s;    } else {        return (java.lang.String) ref;    }}
0
public com.google.protobuf.ByteString getStringBytes()
{    java.lang.Object ref = string_;    if (ref instanceof String) {        com.google.protobuf.ByteString b = com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);        string_ = b;        return b;    } else {        return (com.google.protobuf.ByteString) ref;    }}
0
public Builder setString(java.lang.String value)
{    if (value == null) {        throw new NullPointerException();    }    bitField0_ |= 0x00002000;    string_ = value;    onChanged();    return this;}
0
public Builder clearString()
{    bitField0_ = (bitField0_ & ~0x00002000);    string_ = getDefaultInstance().getString();    onChanged();    return this;}
0
public Builder setStringBytes(com.google.protobuf.ByteString value)
{    if (value == null) {        throw new NullPointerException();    }    bitField0_ |= 0x00002000;    string_ = value;    onChanged();    return this;}
0
public boolean hasBytes()
{    return ((bitField0_ & 0x00004000) == 0x00004000);}
0
public com.google.protobuf.ByteString getBytes()
{    return bytes_;}
0
public Builder setBytes(com.google.protobuf.ByteString value)
{    if (value == null) {        throw new NullPointerException();    }    bitField0_ |= 0x00004000;    bytes_ = value;    onChanged();    return this;}
0
public Builder clearBytes()
{    bitField0_ = (bitField0_ & ~0x00004000);    bytes_ = getDefaultInstance().getBytes();    onChanged();    return this;}
0
public boolean hasEnum()
{    return ((bitField0_ & 0x00008000) == 0x00008000);}
0
public org.apache.avro.protobuf.multiplefiles.A getEnum()
{    org.apache.avro.protobuf.multiplefiles.A result = org.apache.avro.protobuf.multiplefiles.A.valueOf(enum_);    return result == null ? org.apache.avro.protobuf.multiplefiles.A.Z : result;}
0
public Builder setEnum(org.apache.avro.protobuf.multiplefiles.A value)
{    if (value == null) {        throw new NullPointerException();    }    bitField0_ |= 0x00008000;    enum_ = value.getNumber();    onChanged();    return this;}
0
public Builder clearEnum()
{    bitField0_ = (bitField0_ & ~0x00008000);    enum_ = 3;    onChanged();    return this;}
0
private void ensureIntArrayIsMutable()
{    if (!((bitField0_ & 0x00010000) == 0x00010000)) {        intArray_ = new java.util.ArrayList<java.lang.Integer>(intArray_);        bitField0_ |= 0x00010000;    }}
0
public java.util.List<java.lang.Integer> getIntArrayList()
{    return java.util.Collections.unmodifiableList(intArray_);}
0
public int getIntArrayCount()
{    return intArray_.size();}
0
public int getIntArray(int index)
{    return intArray_.get(index);}
0
public Builder setIntArray(int index, int value)
{    ensureIntArrayIsMutable();    intArray_.set(index, value);    onChanged();    return this;}
0
public Builder addIntArray(int value)
{    ensureIntArrayIsMutable();    intArray_.add(value);    onChanged();    return this;}
0
public Builder addAllIntArray(java.lang.Iterable<? extends java.lang.Integer> values)
{    ensureIntArrayIsMutable();    com.google.protobuf.AbstractMessageLite.Builder.addAll(values, intArray_);    onChanged();    return this;}
0
public Builder clearIntArray()
{    intArray_ = java.util.Collections.emptyList();    bitField0_ = (bitField0_ & ~0x00010000);    onChanged();    return this;}
0
private void ensureFooArrayIsMutable()
{    if (!((bitField0_ & 0x00020000) == 0x00020000)) {        fooArray_ = new java.util.ArrayList<org.apache.avro.protobuf.multiplefiles.Foo>(fooArray_);        bitField0_ |= 0x00020000;    }}
0
public java.util.List<org.apache.avro.protobuf.multiplefiles.Foo> getFooArrayList()
{    if (fooArrayBuilder_ == null) {        return java.util.Collections.unmodifiableList(fooArray_);    } else {        return fooArrayBuilder_.getMessageList();    }}
0
public int getFooArrayCount()
{    if (fooArrayBuilder_ == null) {        return fooArray_.size();    } else {        return fooArrayBuilder_.getCount();    }}
0
public org.apache.avro.protobuf.multiplefiles.Foo getFooArray(int index)
{    if (fooArrayBuilder_ == null) {        return fooArray_.get(index);    } else {        return fooArrayBuilder_.getMessage(index);    }}
0
public Builder setFooArray(int index, org.apache.avro.protobuf.multiplefiles.Foo value)
{    if (fooArrayBuilder_ == null) {        if (value == null) {            throw new NullPointerException();        }        ensureFooArrayIsMutable();        fooArray_.set(index, value);        onChanged();    } else {        fooArrayBuilder_.setMessage(index, value);    }    return this;}
0
public Builder setFooArray(int index, org.apache.avro.protobuf.multiplefiles.Foo.Builder builderForValue)
{    if (fooArrayBuilder_ == null) {        ensureFooArrayIsMutable();        fooArray_.set(index, builderForValue.build());        onChanged();    } else {        fooArrayBuilder_.setMessage(index, builderForValue.build());    }    return this;}
0
public Builder addFooArray(org.apache.avro.protobuf.multiplefiles.Foo value)
{    if (fooArrayBuilder_ == null) {        if (value == null) {            throw new NullPointerException();        }        ensureFooArrayIsMutable();        fooArray_.add(value);        onChanged();    } else {        fooArrayBuilder_.addMessage(value);    }    return this;}
0
public Builder addFooArray(int index, org.apache.avro.protobuf.multiplefiles.Foo value)
{    if (fooArrayBuilder_ == null) {        if (value == null) {            throw new NullPointerException();        }        ensureFooArrayIsMutable();        fooArray_.add(index, value);        onChanged();    } else {        fooArrayBuilder_.addMessage(index, value);    }    return this;}
0
public Builder addFooArray(org.apache.avro.protobuf.multiplefiles.Foo.Builder builderForValue)
{    if (fooArrayBuilder_ == null) {        ensureFooArrayIsMutable();        fooArray_.add(builderForValue.build());        onChanged();    } else {        fooArrayBuilder_.addMessage(builderForValue.build());    }    return this;}
0
public Builder addFooArray(int index, org.apache.avro.protobuf.multiplefiles.Foo.Builder builderForValue)
{    if (fooArrayBuilder_ == null) {        ensureFooArrayIsMutable();        fooArray_.add(index, builderForValue.build());        onChanged();    } else {        fooArrayBuilder_.addMessage(index, builderForValue.build());    }    return this;}
0
public Builder addAllFooArray(java.lang.Iterable<? extends org.apache.avro.protobuf.multiplefiles.Foo> values)
{    if (fooArrayBuilder_ == null) {        ensureFooArrayIsMutable();        com.google.protobuf.AbstractMessageLite.Builder.addAll(values, fooArray_);        onChanged();    } else {        fooArrayBuilder_.addAllMessages(values);    }    return this;}
0
public Builder clearFooArray()
{    if (fooArrayBuilder_ == null) {        fooArray_ = java.util.Collections.emptyList();        bitField0_ = (bitField0_ & ~0x00020000);        onChanged();    } else {        fooArrayBuilder_.clear();    }    return this;}
0
public Builder removeFooArray(int index)
{    if (fooArrayBuilder_ == null) {        ensureFooArrayIsMutable();        fooArray_.remove(index);        onChanged();    } else {        fooArrayBuilder_.remove(index);    }    return this;}
0
public org.apache.avro.protobuf.multiplefiles.Foo.Builder getFooArrayBuilder(int index)
{    return getFooArrayFieldBuilder().getBuilder(index);}
0
public org.apache.avro.protobuf.multiplefiles.FooOrBuilder getFooArrayOrBuilder(int index)
{    if (fooArrayBuilder_ == null) {        return fooArray_.get(index);    } else {        return fooArrayBuilder_.getMessageOrBuilder(index);    }}
0
public java.util.List<? extends org.apache.avro.protobuf.multiplefiles.FooOrBuilder> getFooArrayOrBuilderList()
{    if (fooArrayBuilder_ != null) {        return fooArrayBuilder_.getMessageOrBuilderList();    } else {        return java.util.Collections.unmodifiableList(fooArray_);    }}
0
public org.apache.avro.protobuf.multiplefiles.Foo.Builder addFooArrayBuilder()
{    return getFooArrayFieldBuilder().addBuilder(org.apache.avro.protobuf.multiplefiles.Foo.getDefaultInstance());}
0
public org.apache.avro.protobuf.multiplefiles.Foo.Builder addFooArrayBuilder(int index)
{    return getFooArrayFieldBuilder().addBuilder(index, org.apache.avro.protobuf.multiplefiles.Foo.getDefaultInstance());}
0
public java.util.List<org.apache.avro.protobuf.multiplefiles.Foo.Builder> getFooArrayBuilderList()
{    return getFooArrayFieldBuilder().getBuilderList();}
0
private com.google.protobuf.RepeatedFieldBuilderV3<org.apache.avro.protobuf.multiplefiles.Foo, org.apache.avro.protobuf.multiplefiles.Foo.Builder, org.apache.avro.protobuf.multiplefiles.FooOrBuilder> getFooArrayFieldBuilder()
{    if (fooArrayBuilder_ == null) {        fooArrayBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<org.apache.avro.protobuf.multiplefiles.Foo, org.apache.avro.protobuf.multiplefiles.Foo.Builder, org.apache.avro.protobuf.multiplefiles.FooOrBuilder>(fooArray_, ((bitField0_ & 0x00020000) == 0x00020000), getParentForChildren(), isClean());        fooArray_ = null;    }    return fooArrayBuilder_;}
0
private void ensureSymsIsMutable()
{    if (!((bitField0_ & 0x00040000) == 0x00040000)) {        syms_ = new java.util.ArrayList<java.lang.Integer>(syms_);        bitField0_ |= 0x00040000;    }}
0
public java.util.List<org.apache.avro.protobuf.multiplefiles.A> getSymsList()
{    return new com.google.protobuf.Internal.ListAdapter<java.lang.Integer, org.apache.avro.protobuf.multiplefiles.A>(syms_, syms_converter_);}
0
public int getSymsCount()
{    return syms_.size();}
0
public org.apache.avro.protobuf.multiplefiles.A getSyms(int index)
{    return syms_converter_.convert(syms_.get(index));}
0
public Builder setSyms(int index, org.apache.avro.protobuf.multiplefiles.A value)
{    if (value == null) {        throw new NullPointerException();    }    ensureSymsIsMutable();    syms_.set(index, value.getNumber());    onChanged();    return this;}
0
public Builder addSyms(org.apache.avro.protobuf.multiplefiles.A value)
{    if (value == null) {        throw new NullPointerException();    }    ensureSymsIsMutable();    syms_.add(value.getNumber());    onChanged();    return this;}
0
public Builder addAllSyms(java.lang.Iterable<? extends org.apache.avro.protobuf.multiplefiles.A> values)
{    ensureSymsIsMutable();    for (org.apache.avro.protobuf.multiplefiles.A value : values) {        syms_.add(value.getNumber());    }    onChanged();    return this;}
0
public Builder clearSyms()
{    syms_ = java.util.Collections.emptyList();    bitField0_ = (bitField0_ & ~0x00040000);    onChanged();    return this;}
0
public boolean hasFoo()
{    return ((bitField0_ & 0x00080000) == 0x00080000);}
0
public org.apache.avro.protobuf.multiplefiles.Foo getFoo()
{    if (fooBuilder_ == null) {        return foo_ == null ? org.apache.avro.protobuf.multiplefiles.Foo.getDefaultInstance() : foo_;    } else {        return fooBuilder_.getMessage();    }}
0
public Builder setFoo(org.apache.avro.protobuf.multiplefiles.Foo value)
{    if (fooBuilder_ == null) {        if (value == null) {            throw new NullPointerException();        }        foo_ = value;        onChanged();    } else {        fooBuilder_.setMessage(value);    }    bitField0_ |= 0x00080000;    return this;}
0
public Builder setFoo(org.apache.avro.protobuf.multiplefiles.Foo.Builder builderForValue)
{    if (fooBuilder_ == null) {        foo_ = builderForValue.build();        onChanged();    } else {        fooBuilder_.setMessage(builderForValue.build());    }    bitField0_ |= 0x00080000;    return this;}
0
public Builder mergeFoo(org.apache.avro.protobuf.multiplefiles.Foo value)
{    if (fooBuilder_ == null) {        if (((bitField0_ & 0x00080000) == 0x00080000) && foo_ != null && foo_ != org.apache.avro.protobuf.multiplefiles.Foo.getDefaultInstance()) {            foo_ = org.apache.avro.protobuf.multiplefiles.Foo.newBuilder(foo_).mergeFrom(value).buildPartial();        } else {            foo_ = value;        }        onChanged();    } else {        fooBuilder_.mergeFrom(value);    }    bitField0_ |= 0x00080000;    return this;}
0
public Builder clearFoo()
{    if (fooBuilder_ == null) {        foo_ = null;        onChanged();    } else {        fooBuilder_.clear();    }    bitField0_ = (bitField0_ & ~0x00080000);    return this;}
0
public org.apache.avro.protobuf.multiplefiles.Foo.Builder getFooBuilder()
{    bitField0_ |= 0x00080000;    onChanged();    return getFooFieldBuilder().getBuilder();}
0
public org.apache.avro.protobuf.multiplefiles.FooOrBuilder getFooOrBuilder()
{    if (fooBuilder_ != null) {        return fooBuilder_.getMessageOrBuilder();    } else {        return foo_ == null ? org.apache.avro.protobuf.multiplefiles.Foo.getDefaultInstance() : foo_;    }}
0
private com.google.protobuf.SingleFieldBuilderV3<org.apache.avro.protobuf.multiplefiles.Foo, org.apache.avro.protobuf.multiplefiles.Foo.Builder, org.apache.avro.protobuf.multiplefiles.FooOrBuilder> getFooFieldBuilder()
{    if (fooBuilder_ == null) {        fooBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<org.apache.avro.protobuf.multiplefiles.Foo, org.apache.avro.protobuf.multiplefiles.Foo.Builder, org.apache.avro.protobuf.multiplefiles.FooOrBuilder>(getFoo(), getParentForChildren(), isClean());        foo_ = null;    }    return fooBuilder_;}
0
public boolean hasTimestamp()
{    return ((bitField0_ & 0x00100000) == 0x00100000);}
0
public com.google.protobuf.Timestamp getTimestamp()
{    if (timestampBuilder_ == null) {        return timestamp_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : timestamp_;    } else {        return timestampBuilder_.getMessage();    }}
0
public Builder setTimestamp(com.google.protobuf.Timestamp value)
{    if (timestampBuilder_ == null) {        if (value == null) {            throw new NullPointerException();        }        timestamp_ = value;        onChanged();    } else {        timestampBuilder_.setMessage(value);    }    bitField0_ |= 0x00100000;    return this;}
0
public Builder setTimestamp(com.google.protobuf.Timestamp.Builder builderForValue)
{    if (timestampBuilder_ == null) {        timestamp_ = builderForValue.build();        onChanged();    } else {        timestampBuilder_.setMessage(builderForValue.build());    }    bitField0_ |= 0x00100000;    return this;}
0
public Builder mergeTimestamp(com.google.protobuf.Timestamp value)
{    if (timestampBuilder_ == null) {        if (((bitField0_ & 0x00100000) == 0x00100000) && timestamp_ != null && timestamp_ != com.google.protobuf.Timestamp.getDefaultInstance()) {            timestamp_ = com.google.protobuf.Timestamp.newBuilder(timestamp_).mergeFrom(value).buildPartial();        } else {            timestamp_ = value;        }        onChanged();    } else {        timestampBuilder_.mergeFrom(value);    }    bitField0_ |= 0x00100000;    return this;}
0
public Builder clearTimestamp()
{    if (timestampBuilder_ == null) {        timestamp_ = null;        onChanged();    } else {        timestampBuilder_.clear();    }    bitField0_ = (bitField0_ & ~0x00100000);    return this;}
0
public com.google.protobuf.Timestamp.Builder getTimestampBuilder()
{    bitField0_ |= 0x00100000;    onChanged();    return getTimestampFieldBuilder().getBuilder();}
0
public com.google.protobuf.TimestampOrBuilder getTimestampOrBuilder()
{    if (timestampBuilder_ != null) {        return timestampBuilder_.getMessageOrBuilder();    } else {        return timestamp_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : timestamp_;    }}
0
private com.google.protobuf.SingleFieldBuilderV3<com.google.protobuf.Timestamp, com.google.protobuf.Timestamp.Builder, com.google.protobuf.TimestampOrBuilder> getTimestampFieldBuilder()
{    if (timestampBuilder_ == null) {        timestampBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<com.google.protobuf.Timestamp, com.google.protobuf.Timestamp.Builder, com.google.protobuf.TimestampOrBuilder>(getTimestamp(), getParentForChildren(), isClean());        timestamp_ = null;    }    return timestampBuilder_;}
0
public final Builder setUnknownFields(final com.google.protobuf.UnknownFieldSet unknownFields)
{    return super.setUnknownFields(unknownFields);}
0
public final Builder mergeUnknownFields(final com.google.protobuf.UnknownFieldSet unknownFields)
{    return super.mergeUnknownFields(unknownFields);}
0
public static org.apache.avro.protobuf.multiplefiles.Foo getDefaultInstance()
{    return DEFAULT_INSTANCE;}
0
public Foo parsePartialFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return new Foo(input, extensionRegistry);}
0
public static com.google.protobuf.Parser<Foo> parser()
{    return PARSER;}
0
public com.google.protobuf.Parser<Foo> getParserForType()
{    return PARSER;}
0
public org.apache.avro.protobuf.multiplefiles.Foo getDefaultInstanceForType()
{    return DEFAULT_INSTANCE;}
0
public final com.google.protobuf.UnknownFieldSet getUnknownFields()
{    return this.unknownFields;}
0
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.avro.protobuf.multiplefiles.TestMultipleFiles.internal_static_org_apache_avro_protobuf_multiplefiles_M_descriptor;}
0
protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.avro.protobuf.multiplefiles.TestMultipleFiles.internal_static_org_apache_avro_protobuf_multiplefiles_M_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.avro.protobuf.multiplefiles.M.class, org.apache.avro.protobuf.multiplefiles.M.Builder.class);}
0
public final int getNumber()
{    return value;}
0
public static N valueOf(int value)
{    return forNumber(value);}
0
public static N forNumber(int value)
{    switch(value) {        case 1:            return A;        default:            return null;    }}
0
public static com.google.protobuf.Internal.EnumLiteMap<N> internalGetValueMap()
{    return internalValueMap;}
0
public N findValueByNumber(int number)
{    return N.forNumber(number);}
0
public final com.google.protobuf.Descriptors.EnumValueDescriptor getValueDescriptor()
{    return getDescriptor().getValues().get(ordinal());}
0
public final com.google.protobuf.Descriptors.EnumDescriptor getDescriptorForType()
{    return getDescriptor();}
0
public static final com.google.protobuf.Descriptors.EnumDescriptor getDescriptor()
{    return org.apache.avro.protobuf.multiplefiles.M.getDescriptor().getEnumTypes().get(0);}
0
public static N valueOf(com.google.protobuf.Descriptors.EnumValueDescriptor desc)
{    if (desc.getType() != getDescriptor()) {        throw new java.lang.IllegalArgumentException("EnumValueDescriptor is not for this type.");    }    return VALUES[desc.getIndex()];}
0
public final boolean isInitialized()
{    byte isInitialized = memoizedIsInitialized;    if (isInitialized == 1)        return true;    if (isInitialized == 0)        return false;    memoizedIsInitialized = 1;    return true;}
0
public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException
{    unknownFields.writeTo(output);}
0
public int getSerializedSize()
{    int size = memoizedSize;    if (size != -1)        return size;    size = 0;    size += unknownFields.getSerializedSize();    memoizedSize = size;    return size;}
0
public boolean equals(final java.lang.Object obj)
{    if (obj == this) {        return true;    }    if (!(obj instanceof org.apache.avro.protobuf.multiplefiles.M)) {        return super.equals(obj);    }    org.apache.avro.protobuf.multiplefiles.M other = (org.apache.avro.protobuf.multiplefiles.M) obj;    boolean result = true;    result = result && unknownFields.equals(other.unknownFields);    return result;}
0
public int hashCode()
{    if (memoizedHashCode != 0) {        return memoizedHashCode;    }    int hash = 41;    hash = (19 * hash) + getDescriptor().hashCode();    hash = (29 * hash) + unknownFields.hashCode();    memoizedHashCode = hash;    return hash;}
0
public static org.apache.avro.protobuf.multiplefiles.M parseFrom(java.nio.ByteBuffer data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
0
public static org.apache.avro.protobuf.multiplefiles.M parseFrom(java.nio.ByteBuffer data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
0
public static org.apache.avro.protobuf.multiplefiles.M parseFrom(com.google.protobuf.ByteString data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
0
public static org.apache.avro.protobuf.multiplefiles.M parseFrom(com.google.protobuf.ByteString data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
0
public static org.apache.avro.protobuf.multiplefiles.M parseFrom(byte[] data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
0
public static org.apache.avro.protobuf.multiplefiles.M parseFrom(byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
0
public static org.apache.avro.protobuf.multiplefiles.M parseFrom(java.io.InputStream input) throws java.io.IOException
{    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);}
0
public static org.apache.avro.protobuf.multiplefiles.M parseFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input, extensionRegistry);}
0
public static org.apache.avro.protobuf.multiplefiles.M parseDelimitedFrom(java.io.InputStream input) throws java.io.IOException
{    return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(PARSER, input);}
0
public static org.apache.avro.protobuf.multiplefiles.M parseDelimitedFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(PARSER, input, extensionRegistry);}
0
public static org.apache.avro.protobuf.multiplefiles.M parseFrom(com.google.protobuf.CodedInputStream input) throws java.io.IOException
{    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);}
0
public static org.apache.avro.protobuf.multiplefiles.M parseFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input, extensionRegistry);}
0
public Builder newBuilderForType()
{    return newBuilder();}
0
public static Builder newBuilder()
{    return DEFAULT_INSTANCE.toBuilder();}
0
public static Builder newBuilder(org.apache.avro.protobuf.multiplefiles.M prototype)
{    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);}
0
public Builder toBuilder()
{    return this == DEFAULT_INSTANCE ? new Builder() : new Builder().mergeFrom(this);}
0
protected Builder newBuilderForType(com.google.protobuf.GeneratedMessageV3.BuilderParent parent)
{    Builder builder = new Builder(parent);    return builder;}
0
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.avro.protobuf.multiplefiles.TestMultipleFiles.internal_static_org_apache_avro_protobuf_multiplefiles_M_descriptor;}
0
protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.avro.protobuf.multiplefiles.TestMultipleFiles.internal_static_org_apache_avro_protobuf_multiplefiles_M_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.avro.protobuf.multiplefiles.M.class, org.apache.avro.protobuf.multiplefiles.M.Builder.class);}
0
private void maybeForceBuilderInitialization()
{    if (com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders) {    }}
0
public Builder clear()
{    super.clear();    return this;}
0
public com.google.protobuf.Descriptors.Descriptor getDescriptorForType()
{    return org.apache.avro.protobuf.multiplefiles.TestMultipleFiles.internal_static_org_apache_avro_protobuf_multiplefiles_M_descriptor;}
0
public org.apache.avro.protobuf.multiplefiles.M getDefaultInstanceForType()
{    return org.apache.avro.protobuf.multiplefiles.M.getDefaultInstance();}
0
public org.apache.avro.protobuf.multiplefiles.M build()
{    org.apache.avro.protobuf.multiplefiles.M result = buildPartial();    if (!result.isInitialized()) {        throw newUninitializedMessageException(result);    }    return result;}
0
public org.apache.avro.protobuf.multiplefiles.M buildPartial()
{    org.apache.avro.protobuf.multiplefiles.M result = new org.apache.avro.protobuf.multiplefiles.M(this);    onBuilt();    return result;}
0
public Builder clone()
{    return (Builder) super.clone();}
0
public Builder setField(com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value)
{    return (Builder) super.setField(field, value);}
0
public Builder clearField(com.google.protobuf.Descriptors.FieldDescriptor field)
{    return (Builder) super.clearField(field);}
0
public Builder clearOneof(com.google.protobuf.Descriptors.OneofDescriptor oneof)
{    return (Builder) super.clearOneof(oneof);}
0
public Builder setRepeatedField(com.google.protobuf.Descriptors.FieldDescriptor field, int index, java.lang.Object value)
{    return (Builder) super.setRepeatedField(field, index, value);}
0
public Builder addRepeatedField(com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value)
{    return (Builder) super.addRepeatedField(field, value);}
0
public Builder mergeFrom(com.google.protobuf.Message other)
{    if (other instanceof org.apache.avro.protobuf.multiplefiles.M) {        return mergeFrom((org.apache.avro.protobuf.multiplefiles.M) other);    } else {        super.mergeFrom(other);        return this;    }}
0
public Builder mergeFrom(org.apache.avro.protobuf.multiplefiles.M other)
{    if (other == org.apache.avro.protobuf.multiplefiles.M.getDefaultInstance())        return this;    this.mergeUnknownFields(other.unknownFields);    onChanged();    return this;}
0
public final boolean isInitialized()
{    return true;}
0
public Builder mergeFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    org.apache.avro.protobuf.multiplefiles.M parsedMessage = null;    try {        parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);    } catch (com.google.protobuf.InvalidProtocolBufferException e) {        parsedMessage = (org.apache.avro.protobuf.multiplefiles.M) e.getUnfinishedMessage();        throw e.unwrapIOException();    } finally {        if (parsedMessage != null) {            mergeFrom(parsedMessage);        }    }    return this;}
0
public final Builder setUnknownFields(final com.google.protobuf.UnknownFieldSet unknownFields)
{    return super.setUnknownFields(unknownFields);}
0
public final Builder mergeUnknownFields(final com.google.protobuf.UnknownFieldSet unknownFields)
{    return super.mergeUnknownFields(unknownFields);}
0
public static org.apache.avro.protobuf.multiplefiles.M getDefaultInstance()
{    return DEFAULT_INSTANCE;}
0
public M parsePartialFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return new M(input, extensionRegistry);}
0
public static com.google.protobuf.Parser<M> parser()
{    return PARSER;}
0
public com.google.protobuf.Parser<M> getParserForType()
{    return PARSER;}
0
public org.apache.avro.protobuf.multiplefiles.M getDefaultInstanceForType()
{    return DEFAULT_INSTANCE;}
0
public static void registerAllExtensions(com.google.protobuf.ExtensionRegistryLite registry)
{}
0
public static void registerAllExtensions(com.google.protobuf.ExtensionRegistry registry)
{    registerAllExtensions((com.google.protobuf.ExtensionRegistryLite) registry);}
0
public static com.google.protobuf.Descriptors.FileDescriptor getDescriptor()
{    return descriptor;}
0
public com.google.protobuf.ExtensionRegistry assignDescriptors(com.google.protobuf.Descriptors.FileDescriptor root)
{    descriptor = root;    return null;}
0
public static void registerAllExtensions(com.google.protobuf.ExtensionRegistryLite registry)
{}
0
public static void registerAllExtensions(com.google.protobuf.ExtensionRegistry registry)
{    registerAllExtensions((com.google.protobuf.ExtensionRegistryLite) registry);}
0
public final int getNumber()
{    return value;}
0
public static A valueOf(int value)
{    return forNumber(value);}
0
public static A forNumber(int value)
{    switch(value) {        case 1:            return X;        case 2:            return Y;        case 3:            return Z;        default:            return null;    }}
0
public static com.google.protobuf.Internal.EnumLiteMap<A> internalGetValueMap()
{    return internalValueMap;}
0
public A findValueByNumber(int number)
{    return A.forNumber(number);}
0
public final com.google.protobuf.Descriptors.EnumValueDescriptor getValueDescriptor()
{    return getDescriptor().getValues().get(ordinal());}
0
public final com.google.protobuf.Descriptors.EnumDescriptor getDescriptorForType()
{    return getDescriptor();}
0
public static final com.google.protobuf.Descriptors.EnumDescriptor getDescriptor()
{    return org.apache.avro.protobuf.noopt.Test.getDescriptor().getEnumTypes().get(0);}
0
public static A valueOf(com.google.protobuf.Descriptors.EnumValueDescriptor desc)
{    if (desc.getType() != getDescriptor()) {        throw new java.lang.IllegalArgumentException("EnumValueDescriptor is not for this type.");    }    return VALUES[desc.getIndex()];}
0
public final com.google.protobuf.UnknownFieldSet getUnknownFields()
{    return this.unknownFields;}
0
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.avro.protobuf.noopt.Test.internal_static_org_apache_avro_protobuf_noopt_Foo_descriptor;}
0
protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.avro.protobuf.noopt.Test.internal_static_org_apache_avro_protobuf_noopt_Foo_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.avro.protobuf.noopt.Test.Foo.class, org.apache.avro.protobuf.noopt.Test.Foo.Builder.class);}
0
public boolean hasInt32()
{    return ((bitField0_ & 0x00000001) == 0x00000001);}
0
public int getInt32()
{    return int32_;}
0
public boolean hasInt64()
{    return ((bitField0_ & 0x00000002) == 0x00000002);}
0
public long getInt64()
{    return int64_;}
0
public boolean hasUint32()
{    return ((bitField0_ & 0x00000004) == 0x00000004);}
0
public int getUint32()
{    return uint32_;}
0
public boolean hasUint64()
{    return ((bitField0_ & 0x00000008) == 0x00000008);}
0
public long getUint64()
{    return uint64_;}
0
public boolean hasSint32()
{    return ((bitField0_ & 0x00000010) == 0x00000010);}
0
public int getSint32()
{    return sint32_;}
0
public boolean hasSint64()
{    return ((bitField0_ & 0x00000020) == 0x00000020);}
0
public long getSint64()
{    return sint64_;}
0
public boolean hasFixed32()
{    return ((bitField0_ & 0x00000040) == 0x00000040);}
0
public int getFixed32()
{    return fixed32_;}
0
public boolean hasFixed64()
{    return ((bitField0_ & 0x00000080) == 0x00000080);}
0
public long getFixed64()
{    return fixed64_;}
0
public boolean hasSfixed32()
{    return ((bitField0_ & 0x00000100) == 0x00000100);}
0
public int getSfixed32()
{    return sfixed32_;}
0
public boolean hasSfixed64()
{    return ((bitField0_ & 0x00000200) == 0x00000200);}
0
public long getSfixed64()
{    return sfixed64_;}
0
public boolean hasFloat()
{    return ((bitField0_ & 0x00000400) == 0x00000400);}
0
public float getFloat()
{    return float_;}
0
public boolean hasDouble()
{    return ((bitField0_ & 0x00000800) == 0x00000800);}
0
public double getDouble()
{    return double_;}
0
public boolean hasBool()
{    return ((bitField0_ & 0x00001000) == 0x00001000);}
0
public boolean getBool()
{    return bool_;}
0
public boolean hasString()
{    return ((bitField0_ & 0x00002000) == 0x00002000);}
0
public java.lang.String getString()
{    java.lang.Object ref = string_;    if (ref instanceof java.lang.String) {        return (java.lang.String) ref;    } else {        com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;        java.lang.String s = bs.toStringUtf8();        if (bs.isValidUtf8()) {            string_ = s;        }        return s;    }}
0
public com.google.protobuf.ByteString getStringBytes()
{    java.lang.Object ref = string_;    if (ref instanceof java.lang.String) {        com.google.protobuf.ByteString b = com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);        string_ = b;        return b;    } else {        return (com.google.protobuf.ByteString) ref;    }}
0
public boolean hasBytes()
{    return ((bitField0_ & 0x00004000) == 0x00004000);}
0
public com.google.protobuf.ByteString getBytes()
{    return bytes_;}
0
public boolean hasEnum()
{    return ((bitField0_ & 0x00008000) == 0x00008000);}
0
public org.apache.avro.protobuf.noopt.Test.A getEnum()
{    org.apache.avro.protobuf.noopt.Test.A result = org.apache.avro.protobuf.noopt.Test.A.valueOf(enum_);    return result == null ? org.apache.avro.protobuf.noopt.Test.A.Z : result;}
0
public java.util.List<java.lang.Integer> getIntArrayList()
{    return intArray_;}
0
public int getIntArrayCount()
{    return intArray_.size();}
0
public int getIntArray(int index)
{    return intArray_.get(index);}
0
public java.util.List<org.apache.avro.protobuf.noopt.Test.Foo> getFooArrayList()
{    return fooArray_;}
0
public java.util.List<? extends org.apache.avro.protobuf.noopt.Test.FooOrBuilder> getFooArrayOrBuilderList()
{    return fooArray_;}
0
public int getFooArrayCount()
{    return fooArray_.size();}
0
public org.apache.avro.protobuf.noopt.Test.Foo getFooArray(int index)
{    return fooArray_.get(index);}
0
public org.apache.avro.protobuf.noopt.Test.FooOrBuilder getFooArrayOrBuilder(int index)
{    return fooArray_.get(index);}
0
public org.apache.avro.protobuf.noopt.Test.A convert(java.lang.Integer from)
{    org.apache.avro.protobuf.noopt.Test.A result = org.apache.avro.protobuf.noopt.Test.A.valueOf(from);    return result == null ? org.apache.avro.protobuf.noopt.Test.A.X : result;}
0
public java.util.List<org.apache.avro.protobuf.noopt.Test.A> getSymsList()
{    return new com.google.protobuf.Internal.ListAdapter<java.lang.Integer, org.apache.avro.protobuf.noopt.Test.A>(syms_, syms_converter_);}
0
public int getSymsCount()
{    return syms_.size();}
0
public org.apache.avro.protobuf.noopt.Test.A getSyms(int index)
{    return syms_converter_.convert(syms_.get(index));}
0
public boolean hasFoo()
{    return ((bitField0_ & 0x00010000) == 0x00010000);}
0
public org.apache.avro.protobuf.noopt.Test.Foo getFoo()
{    return foo_ == null ? org.apache.avro.protobuf.noopt.Test.Foo.getDefaultInstance() : foo_;}
0
public org.apache.avro.protobuf.noopt.Test.FooOrBuilder getFooOrBuilder()
{    return foo_ == null ? org.apache.avro.protobuf.noopt.Test.Foo.getDefaultInstance() : foo_;}
0
public boolean hasTimestamp()
{    return ((bitField0_ & 0x00020000) == 0x00020000);}
0
public com.google.protobuf.Timestamp getTimestamp()
{    return timestamp_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : timestamp_;}
0
public com.google.protobuf.TimestampOrBuilder getTimestampOrBuilder()
{    return timestamp_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : timestamp_;}
0
public final boolean isInitialized()
{    byte isInitialized = memoizedIsInitialized;    if (isInitialized == 1)        return true;    if (isInitialized == 0)        return false;    if (!hasInt32()) {        memoizedIsInitialized = 0;        return false;    }    for (int i = 0; i < getFooArrayCount(); i++) {        if (!getFooArray(i).isInitialized()) {            memoizedIsInitialized = 0;            return false;        }    }    if (hasFoo()) {        if (!getFoo().isInitialized()) {            memoizedIsInitialized = 0;            return false;        }    }    memoizedIsInitialized = 1;    return true;}
0
public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException
{    if (((bitField0_ & 0x00000001) == 0x00000001)) {        output.writeInt32(1, int32_);    }    if (((bitField0_ & 0x00000002) == 0x00000002)) {        output.writeInt64(2, int64_);    }    if (((bitField0_ & 0x00000004) == 0x00000004)) {        output.writeUInt32(3, uint32_);    }    if (((bitField0_ & 0x00000008) == 0x00000008)) {        output.writeUInt64(4, uint64_);    }    if (((bitField0_ & 0x00000010) == 0x00000010)) {        output.writeSInt32(5, sint32_);    }    if (((bitField0_ & 0x00000020) == 0x00000020)) {        output.writeSInt64(6, sint64_);    }    if (((bitField0_ & 0x00000040) == 0x00000040)) {        output.writeFixed32(7, fixed32_);    }    if (((bitField0_ & 0x00000080) == 0x00000080)) {        output.writeFixed64(8, fixed64_);    }    if (((bitField0_ & 0x00000100) == 0x00000100)) {        output.writeSFixed32(9, sfixed32_);    }    if (((bitField0_ & 0x00000200) == 0x00000200)) {        output.writeSFixed64(10, sfixed64_);    }    if (((bitField0_ & 0x00000400) == 0x00000400)) {        output.writeFloat(11, float_);    }    if (((bitField0_ & 0x00000800) == 0x00000800)) {        output.writeDouble(12, double_);    }    if (((bitField0_ & 0x00001000) == 0x00001000)) {        output.writeBool(13, bool_);    }    if (((bitField0_ & 0x00002000) == 0x00002000)) {        com.google.protobuf.GeneratedMessageV3.writeString(output, 14, string_);    }    if (((bitField0_ & 0x00004000) == 0x00004000)) {        output.writeBytes(15, bytes_);    }    if (((bitField0_ & 0x00008000) == 0x00008000)) {        output.writeEnum(16, enum_);    }    for (int i = 0; i < intArray_.size(); i++) {        output.writeInt32(17, intArray_.get(i));    }    if (((bitField0_ & 0x00010000) == 0x00010000)) {        output.writeMessage(18, getFoo());    }    for (int i = 0; i < syms_.size(); i++) {        output.writeEnum(19, syms_.get(i));    }    for (int i = 0; i < fooArray_.size(); i++) {        output.writeMessage(20, fooArray_.get(i));    }    if (((bitField0_ & 0x00020000) == 0x00020000)) {        output.writeMessage(21, getTimestamp());    }    unknownFields.writeTo(output);}
0
public int getSerializedSize()
{    int size = memoizedSize;    if (size != -1)        return size;    size = 0;    if (((bitField0_ & 0x00000001) == 0x00000001)) {        size += com.google.protobuf.CodedOutputStream.computeInt32Size(1, int32_);    }    if (((bitField0_ & 0x00000002) == 0x00000002)) {        size += com.google.protobuf.CodedOutputStream.computeInt64Size(2, int64_);    }    if (((bitField0_ & 0x00000004) == 0x00000004)) {        size += com.google.protobuf.CodedOutputStream.computeUInt32Size(3, uint32_);    }    if (((bitField0_ & 0x00000008) == 0x00000008)) {        size += com.google.protobuf.CodedOutputStream.computeUInt64Size(4, uint64_);    }    if (((bitField0_ & 0x00000010) == 0x00000010)) {        size += com.google.protobuf.CodedOutputStream.computeSInt32Size(5, sint32_);    }    if (((bitField0_ & 0x00000020) == 0x00000020)) {        size += com.google.protobuf.CodedOutputStream.computeSInt64Size(6, sint64_);    }    if (((bitField0_ & 0x00000040) == 0x00000040)) {        size += com.google.protobuf.CodedOutputStream.computeFixed32Size(7, fixed32_);    }    if (((bitField0_ & 0x00000080) == 0x00000080)) {        size += com.google.protobuf.CodedOutputStream.computeFixed64Size(8, fixed64_);    }    if (((bitField0_ & 0x00000100) == 0x00000100)) {        size += com.google.protobuf.CodedOutputStream.computeSFixed32Size(9, sfixed32_);    }    if (((bitField0_ & 0x00000200) == 0x00000200)) {        size += com.google.protobuf.CodedOutputStream.computeSFixed64Size(10, sfixed64_);    }    if (((bitField0_ & 0x00000400) == 0x00000400)) {        size += com.google.protobuf.CodedOutputStream.computeFloatSize(11, float_);    }    if (((bitField0_ & 0x00000800) == 0x00000800)) {        size += com.google.protobuf.CodedOutputStream.computeDoubleSize(12, double_);    }    if (((bitField0_ & 0x00001000) == 0x00001000)) {        size += com.google.protobuf.CodedOutputStream.computeBoolSize(13, bool_);    }    if (((bitField0_ & 0x00002000) == 0x00002000)) {        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(14, string_);    }    if (((bitField0_ & 0x00004000) == 0x00004000)) {        size += com.google.protobuf.CodedOutputStream.computeBytesSize(15, bytes_);    }    if (((bitField0_ & 0x00008000) == 0x00008000)) {        size += com.google.protobuf.CodedOutputStream.computeEnumSize(16, enum_);    }    {        int dataSize = 0;        for (int i = 0; i < intArray_.size(); i++) {            dataSize += com.google.protobuf.CodedOutputStream.computeInt32SizeNoTag(intArray_.get(i));        }        size += dataSize;        size += 2 * getIntArrayList().size();    }    if (((bitField0_ & 0x00010000) == 0x00010000)) {        size += com.google.protobuf.CodedOutputStream.computeMessageSize(18, getFoo());    }    {        int dataSize = 0;        for (int i = 0; i < syms_.size(); i++) {            dataSize += com.google.protobuf.CodedOutputStream.computeEnumSizeNoTag(syms_.get(i));        }        size += dataSize;        size += 2 * syms_.size();    }    for (int i = 0; i < fooArray_.size(); i++) {        size += com.google.protobuf.CodedOutputStream.computeMessageSize(20, fooArray_.get(i));    }    if (((bitField0_ & 0x00020000) == 0x00020000)) {        size += com.google.protobuf.CodedOutputStream.computeMessageSize(21, getTimestamp());    }    size += unknownFields.getSerializedSize();    memoizedSize = size;    return size;}
0
public boolean equals(final java.lang.Object obj)
{    if (obj == this) {        return true;    }    if (!(obj instanceof org.apache.avro.protobuf.noopt.Test.Foo)) {        return super.equals(obj);    }    org.apache.avro.protobuf.noopt.Test.Foo other = (org.apache.avro.protobuf.noopt.Test.Foo) obj;    boolean result = true;    result = result && (hasInt32() == other.hasInt32());    if (hasInt32()) {        result = result && (getInt32() == other.getInt32());    }    result = result && (hasInt64() == other.hasInt64());    if (hasInt64()) {        result = result && (getInt64() == other.getInt64());    }    result = result && (hasUint32() == other.hasUint32());    if (hasUint32()) {        result = result && (getUint32() == other.getUint32());    }    result = result && (hasUint64() == other.hasUint64());    if (hasUint64()) {        result = result && (getUint64() == other.getUint64());    }    result = result && (hasSint32() == other.hasSint32());    if (hasSint32()) {        result = result && (getSint32() == other.getSint32());    }    result = result && (hasSint64() == other.hasSint64());    if (hasSint64()) {        result = result && (getSint64() == other.getSint64());    }    result = result && (hasFixed32() == other.hasFixed32());    if (hasFixed32()) {        result = result && (getFixed32() == other.getFixed32());    }    result = result && (hasFixed64() == other.hasFixed64());    if (hasFixed64()) {        result = result && (getFixed64() == other.getFixed64());    }    result = result && (hasSfixed32() == other.hasSfixed32());    if (hasSfixed32()) {        result = result && (getSfixed32() == other.getSfixed32());    }    result = result && (hasSfixed64() == other.hasSfixed64());    if (hasSfixed64()) {        result = result && (getSfixed64() == other.getSfixed64());    }    result = result && (hasFloat() == other.hasFloat());    if (hasFloat()) {        result = result && (java.lang.Float.floatToIntBits(getFloat()) == java.lang.Float.floatToIntBits(other.getFloat()));    }    result = result && (hasDouble() == other.hasDouble());    if (hasDouble()) {        result = result && (java.lang.Double.doubleToLongBits(getDouble()) == java.lang.Double.doubleToLongBits(other.getDouble()));    }    result = result && (hasBool() == other.hasBool());    if (hasBool()) {        result = result && (getBool() == other.getBool());    }    result = result && (hasString() == other.hasString());    if (hasString()) {        result = result && getString().equals(other.getString());    }    result = result && (hasBytes() == other.hasBytes());    if (hasBytes()) {        result = result && getBytes().equals(other.getBytes());    }    result = result && (hasEnum() == other.hasEnum());    if (hasEnum()) {        result = result && enum_ == other.enum_;    }    result = result && getIntArrayList().equals(other.getIntArrayList());    result = result && getFooArrayList().equals(other.getFooArrayList());    result = result && syms_.equals(other.syms_);    result = result && (hasFoo() == other.hasFoo());    if (hasFoo()) {        result = result && getFoo().equals(other.getFoo());    }    result = result && (hasTimestamp() == other.hasTimestamp());    if (hasTimestamp()) {        result = result && getTimestamp().equals(other.getTimestamp());    }    result = result && unknownFields.equals(other.unknownFields);    return result;}
0
public int hashCode()
{    if (memoizedHashCode != 0) {        return memoizedHashCode;    }    int hash = 41;    hash = (19 * hash) + getDescriptor().hashCode();    if (hasInt32()) {        hash = (37 * hash) + INT32_FIELD_NUMBER;        hash = (53 * hash) + getInt32();    }    if (hasInt64()) {        hash = (37 * hash) + INT64_FIELD_NUMBER;        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(getInt64());    }    if (hasUint32()) {        hash = (37 * hash) + UINT32_FIELD_NUMBER;        hash = (53 * hash) + getUint32();    }    if (hasUint64()) {        hash = (37 * hash) + UINT64_FIELD_NUMBER;        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(getUint64());    }    if (hasSint32()) {        hash = (37 * hash) + SINT32_FIELD_NUMBER;        hash = (53 * hash) + getSint32();    }    if (hasSint64()) {        hash = (37 * hash) + SINT64_FIELD_NUMBER;        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(getSint64());    }    if (hasFixed32()) {        hash = (37 * hash) + FIXED32_FIELD_NUMBER;        hash = (53 * hash) + getFixed32();    }    if (hasFixed64()) {        hash = (37 * hash) + FIXED64_FIELD_NUMBER;        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(getFixed64());    }    if (hasSfixed32()) {        hash = (37 * hash) + SFIXED32_FIELD_NUMBER;        hash = (53 * hash) + getSfixed32();    }    if (hasSfixed64()) {        hash = (37 * hash) + SFIXED64_FIELD_NUMBER;        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(getSfixed64());    }    if (hasFloat()) {        hash = (37 * hash) + FLOAT_FIELD_NUMBER;        hash = (53 * hash) + java.lang.Float.floatToIntBits(getFloat());    }    if (hasDouble()) {        hash = (37 * hash) + DOUBLE_FIELD_NUMBER;        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(java.lang.Double.doubleToLongBits(getDouble()));    }    if (hasBool()) {        hash = (37 * hash) + BOOL_FIELD_NUMBER;        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(getBool());    }    if (hasString()) {        hash = (37 * hash) + STRING_FIELD_NUMBER;        hash = (53 * hash) + getString().hashCode();    }    if (hasBytes()) {        hash = (37 * hash) + BYTES_FIELD_NUMBER;        hash = (53 * hash) + getBytes().hashCode();    }    if (hasEnum()) {        hash = (37 * hash) + ENUM_FIELD_NUMBER;        hash = (53 * hash) + enum_;    }    if (getIntArrayCount() > 0) {        hash = (37 * hash) + INTARRAY_FIELD_NUMBER;        hash = (53 * hash) + getIntArrayList().hashCode();    }    if (getFooArrayCount() > 0) {        hash = (37 * hash) + FOOARRAY_FIELD_NUMBER;        hash = (53 * hash) + getFooArrayList().hashCode();    }    if (getSymsCount() > 0) {        hash = (37 * hash) + SYMS_FIELD_NUMBER;        hash = (53 * hash) + syms_.hashCode();    }    if (hasFoo()) {        hash = (37 * hash) + FOO_FIELD_NUMBER;        hash = (53 * hash) + getFoo().hashCode();    }    if (hasTimestamp()) {        hash = (37 * hash) + TIMESTAMP_FIELD_NUMBER;        hash = (53 * hash) + getTimestamp().hashCode();    }    hash = (29 * hash) + unknownFields.hashCode();    memoizedHashCode = hash;    return hash;}
0
public static org.apache.avro.protobuf.noopt.Test.Foo parseFrom(java.nio.ByteBuffer data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
0
public static org.apache.avro.protobuf.noopt.Test.Foo parseFrom(java.nio.ByteBuffer data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
0
public static org.apache.avro.protobuf.noopt.Test.Foo parseFrom(com.google.protobuf.ByteString data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
0
public static org.apache.avro.protobuf.noopt.Test.Foo parseFrom(com.google.protobuf.ByteString data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
0
public static org.apache.avro.protobuf.noopt.Test.Foo parseFrom(byte[] data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
0
public static org.apache.avro.protobuf.noopt.Test.Foo parseFrom(byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
0
public static org.apache.avro.protobuf.noopt.Test.Foo parseFrom(java.io.InputStream input) throws java.io.IOException
{    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);}
0
public static org.apache.avro.protobuf.noopt.Test.Foo parseFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input, extensionRegistry);}
0
public static org.apache.avro.protobuf.noopt.Test.Foo parseDelimitedFrom(java.io.InputStream input) throws java.io.IOException
{    return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(PARSER, input);}
0
public static org.apache.avro.protobuf.noopt.Test.Foo parseDelimitedFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(PARSER, input, extensionRegistry);}
0
public static org.apache.avro.protobuf.noopt.Test.Foo parseFrom(com.google.protobuf.CodedInputStream input) throws java.io.IOException
{    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);}
0
public static org.apache.avro.protobuf.noopt.Test.Foo parseFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input, extensionRegistry);}
0
public Builder newBuilderForType()
{    return newBuilder();}
0
public static Builder newBuilder()
{    return DEFAULT_INSTANCE.toBuilder();}
0
public static Builder newBuilder(org.apache.avro.protobuf.noopt.Test.Foo prototype)
{    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);}
0
public Builder toBuilder()
{    return this == DEFAULT_INSTANCE ? new Builder() : new Builder().mergeFrom(this);}
0
protected Builder newBuilderForType(com.google.protobuf.GeneratedMessageV3.BuilderParent parent)
{    Builder builder = new Builder(parent);    return builder;}
0
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.avro.protobuf.noopt.Test.internal_static_org_apache_avro_protobuf_noopt_Foo_descriptor;}
0
protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.avro.protobuf.noopt.Test.internal_static_org_apache_avro_protobuf_noopt_Foo_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.avro.protobuf.noopt.Test.Foo.class, org.apache.avro.protobuf.noopt.Test.Foo.Builder.class);}
0
private void maybeForceBuilderInitialization()
{    if (com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders) {        getFooArrayFieldBuilder();        getFooFieldBuilder();        getTimestampFieldBuilder();    }}
0
public Builder clear()
{    super.clear();    int32_ = 0;    bitField0_ = (bitField0_ & ~0x00000001);    int64_ = 0L;    bitField0_ = (bitField0_ & ~0x00000002);    uint32_ = 0;    bitField0_ = (bitField0_ & ~0x00000004);    uint64_ = 0L;    bitField0_ = (bitField0_ & ~0x00000008);    sint32_ = 0;    bitField0_ = (bitField0_ & ~0x00000010);    sint64_ = 0L;    bitField0_ = (bitField0_ & ~0x00000020);    fixed32_ = 0;    bitField0_ = (bitField0_ & ~0x00000040);    fixed64_ = 0L;    bitField0_ = (bitField0_ & ~0x00000080);    sfixed32_ = 0;    bitField0_ = (bitField0_ & ~0x00000100);    sfixed64_ = 0L;    bitField0_ = (bitField0_ & ~0x00000200);    float_ = 0F;    bitField0_ = (bitField0_ & ~0x00000400);    double_ = 0D;    bitField0_ = (bitField0_ & ~0x00000800);    bool_ = false;    bitField0_ = (bitField0_ & ~0x00001000);    string_ = "";    bitField0_ = (bitField0_ & ~0x00002000);    bytes_ = com.google.protobuf.ByteString.EMPTY;    bitField0_ = (bitField0_ & ~0x00004000);    enum_ = 3;    bitField0_ = (bitField0_ & ~0x00008000);    intArray_ = java.util.Collections.emptyList();    bitField0_ = (bitField0_ & ~0x00010000);    if (fooArrayBuilder_ == null) {        fooArray_ = java.util.Collections.emptyList();        bitField0_ = (bitField0_ & ~0x00020000);    } else {        fooArrayBuilder_.clear();    }    syms_ = java.util.Collections.emptyList();    bitField0_ = (bitField0_ & ~0x00040000);    if (fooBuilder_ == null) {        foo_ = null;    } else {        fooBuilder_.clear();    }    bitField0_ = (bitField0_ & ~0x00080000);    if (timestampBuilder_ == null) {        timestamp_ = null;    } else {        timestampBuilder_.clear();    }    bitField0_ = (bitField0_ & ~0x00100000);    return this;}
0
public com.google.protobuf.Descriptors.Descriptor getDescriptorForType()
{    return org.apache.avro.protobuf.noopt.Test.internal_static_org_apache_avro_protobuf_noopt_Foo_descriptor;}
0
public org.apache.avro.protobuf.noopt.Test.Foo getDefaultInstanceForType()
{    return org.apache.avro.protobuf.noopt.Test.Foo.getDefaultInstance();}
0
public org.apache.avro.protobuf.noopt.Test.Foo build()
{    org.apache.avro.protobuf.noopt.Test.Foo result = buildPartial();    if (!result.isInitialized()) {        throw newUninitializedMessageException(result);    }    return result;}
0
public org.apache.avro.protobuf.noopt.Test.Foo buildPartial()
{    org.apache.avro.protobuf.noopt.Test.Foo result = new org.apache.avro.protobuf.noopt.Test.Foo(this);    int from_bitField0_ = bitField0_;    int to_bitField0_ = 0;    if (((from_bitField0_ & 0x00000001) == 0x00000001)) {        to_bitField0_ |= 0x00000001;    }    result.int32_ = int32_;    if (((from_bitField0_ & 0x00000002) == 0x00000002)) {        to_bitField0_ |= 0x00000002;    }    result.int64_ = int64_;    if (((from_bitField0_ & 0x00000004) == 0x00000004)) {        to_bitField0_ |= 0x00000004;    }    result.uint32_ = uint32_;    if (((from_bitField0_ & 0x00000008) == 0x00000008)) {        to_bitField0_ |= 0x00000008;    }    result.uint64_ = uint64_;    if (((from_bitField0_ & 0x00000010) == 0x00000010)) {        to_bitField0_ |= 0x00000010;    }    result.sint32_ = sint32_;    if (((from_bitField0_ & 0x00000020) == 0x00000020)) {        to_bitField0_ |= 0x00000020;    }    result.sint64_ = sint64_;    if (((from_bitField0_ & 0x00000040) == 0x00000040)) {        to_bitField0_ |= 0x00000040;    }    result.fixed32_ = fixed32_;    if (((from_bitField0_ & 0x00000080) == 0x00000080)) {        to_bitField0_ |= 0x00000080;    }    result.fixed64_ = fixed64_;    if (((from_bitField0_ & 0x00000100) == 0x00000100)) {        to_bitField0_ |= 0x00000100;    }    result.sfixed32_ = sfixed32_;    if (((from_bitField0_ & 0x00000200) == 0x00000200)) {        to_bitField0_ |= 0x00000200;    }    result.sfixed64_ = sfixed64_;    if (((from_bitField0_ & 0x00000400) == 0x00000400)) {        to_bitField0_ |= 0x00000400;    }    result.float_ = float_;    if (((from_bitField0_ & 0x00000800) == 0x00000800)) {        to_bitField0_ |= 0x00000800;    }    result.double_ = double_;    if (((from_bitField0_ & 0x00001000) == 0x00001000)) {        to_bitField0_ |= 0x00001000;    }    result.bool_ = bool_;    if (((from_bitField0_ & 0x00002000) == 0x00002000)) {        to_bitField0_ |= 0x00002000;    }    result.string_ = string_;    if (((from_bitField0_ & 0x00004000) == 0x00004000)) {        to_bitField0_ |= 0x00004000;    }    result.bytes_ = bytes_;    if (((from_bitField0_ & 0x00008000) == 0x00008000)) {        to_bitField0_ |= 0x00008000;    }    result.enum_ = enum_;    if (((bitField0_ & 0x00010000) == 0x00010000)) {        intArray_ = java.util.Collections.unmodifiableList(intArray_);        bitField0_ = (bitField0_ & ~0x00010000);    }    result.intArray_ = intArray_;    if (fooArrayBuilder_ == null) {        if (((bitField0_ & 0x00020000) == 0x00020000)) {            fooArray_ = java.util.Collections.unmodifiableList(fooArray_);            bitField0_ = (bitField0_ & ~0x00020000);        }        result.fooArray_ = fooArray_;    } else {        result.fooArray_ = fooArrayBuilder_.build();    }    if (((bitField0_ & 0x00040000) == 0x00040000)) {        syms_ = java.util.Collections.unmodifiableList(syms_);        bitField0_ = (bitField0_ & ~0x00040000);    }    result.syms_ = syms_;    if (((from_bitField0_ & 0x00080000) == 0x00080000)) {        to_bitField0_ |= 0x00010000;    }    if (fooBuilder_ == null) {        result.foo_ = foo_;    } else {        result.foo_ = fooBuilder_.build();    }    if (((from_bitField0_ & 0x00100000) == 0x00100000)) {        to_bitField0_ |= 0x00020000;    }    if (timestampBuilder_ == null) {        result.timestamp_ = timestamp_;    } else {        result.timestamp_ = timestampBuilder_.build();    }    result.bitField0_ = to_bitField0_;    onBuilt();    return result;}
0
public Builder clone()
{    return (Builder) super.clone();}
0
public Builder setField(com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value)
{    return (Builder) super.setField(field, value);}
0
public Builder clearField(com.google.protobuf.Descriptors.FieldDescriptor field)
{    return (Builder) super.clearField(field);}
0
public Builder clearOneof(com.google.protobuf.Descriptors.OneofDescriptor oneof)
{    return (Builder) super.clearOneof(oneof);}
0
public Builder setRepeatedField(com.google.protobuf.Descriptors.FieldDescriptor field, int index, java.lang.Object value)
{    return (Builder) super.setRepeatedField(field, index, value);}
0
public Builder addRepeatedField(com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value)
{    return (Builder) super.addRepeatedField(field, value);}
0
public Builder mergeFrom(com.google.protobuf.Message other)
{    if (other instanceof org.apache.avro.protobuf.noopt.Test.Foo) {        return mergeFrom((org.apache.avro.protobuf.noopt.Test.Foo) other);    } else {        super.mergeFrom(other);        return this;    }}
0
public Builder mergeFrom(org.apache.avro.protobuf.noopt.Test.Foo other)
{    if (other == org.apache.avro.protobuf.noopt.Test.Foo.getDefaultInstance())        return this;    if (other.hasInt32()) {        setInt32(other.getInt32());    }    if (other.hasInt64()) {        setInt64(other.getInt64());    }    if (other.hasUint32()) {        setUint32(other.getUint32());    }    if (other.hasUint64()) {        setUint64(other.getUint64());    }    if (other.hasSint32()) {        setSint32(other.getSint32());    }    if (other.hasSint64()) {        setSint64(other.getSint64());    }    if (other.hasFixed32()) {        setFixed32(other.getFixed32());    }    if (other.hasFixed64()) {        setFixed64(other.getFixed64());    }    if (other.hasSfixed32()) {        setSfixed32(other.getSfixed32());    }    if (other.hasSfixed64()) {        setSfixed64(other.getSfixed64());    }    if (other.hasFloat()) {        setFloat(other.getFloat());    }    if (other.hasDouble()) {        setDouble(other.getDouble());    }    if (other.hasBool()) {        setBool(other.getBool());    }    if (other.hasString()) {        bitField0_ |= 0x00002000;        string_ = other.string_;        onChanged();    }    if (other.hasBytes()) {        setBytes(other.getBytes());    }    if (other.hasEnum()) {        setEnum(other.getEnum());    }    if (!other.intArray_.isEmpty()) {        if (intArray_.isEmpty()) {            intArray_ = other.intArray_;            bitField0_ = (bitField0_ & ~0x00010000);        } else {            ensureIntArrayIsMutable();            intArray_.addAll(other.intArray_);        }        onChanged();    }    if (fooArrayBuilder_ == null) {        if (!other.fooArray_.isEmpty()) {            if (fooArray_.isEmpty()) {                fooArray_ = other.fooArray_;                bitField0_ = (bitField0_ & ~0x00020000);            } else {                ensureFooArrayIsMutable();                fooArray_.addAll(other.fooArray_);            }            onChanged();        }    } else {        if (!other.fooArray_.isEmpty()) {            if (fooArrayBuilder_.isEmpty()) {                fooArrayBuilder_.dispose();                fooArrayBuilder_ = null;                fooArray_ = other.fooArray_;                bitField0_ = (bitField0_ & ~0x00020000);                fooArrayBuilder_ = com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ? getFooArrayFieldBuilder() : null;            } else {                fooArrayBuilder_.addAllMessages(other.fooArray_);            }        }    }    if (!other.syms_.isEmpty()) {        if (syms_.isEmpty()) {            syms_ = other.syms_;            bitField0_ = (bitField0_ & ~0x00040000);        } else {            ensureSymsIsMutable();            syms_.addAll(other.syms_);        }        onChanged();    }    if (other.hasFoo()) {        mergeFoo(other.getFoo());    }    if (other.hasTimestamp()) {        mergeTimestamp(other.getTimestamp());    }    this.mergeUnknownFields(other.unknownFields);    onChanged();    return this;}
0
public final boolean isInitialized()
{    if (!hasInt32()) {        return false;    }    for (int i = 0; i < getFooArrayCount(); i++) {        if (!getFooArray(i).isInitialized()) {            return false;        }    }    if (hasFoo()) {        if (!getFoo().isInitialized()) {            return false;        }    }    return true;}
0
public Builder mergeFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    org.apache.avro.protobuf.noopt.Test.Foo parsedMessage = null;    try {        parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);    } catch (com.google.protobuf.InvalidProtocolBufferException e) {        parsedMessage = (org.apache.avro.protobuf.noopt.Test.Foo) e.getUnfinishedMessage();        throw e.unwrapIOException();    } finally {        if (parsedMessage != null) {            mergeFrom(parsedMessage);        }    }    return this;}
0
public boolean hasInt32()
{    return ((bitField0_ & 0x00000001) == 0x00000001);}
0
public int getInt32()
{    return int32_;}
0
public Builder setInt32(int value)
{    bitField0_ |= 0x00000001;    int32_ = value;    onChanged();    return this;}
0
public Builder clearInt32()
{    bitField0_ = (bitField0_ & ~0x00000001);    int32_ = 0;    onChanged();    return this;}
0
public boolean hasInt64()
{    return ((bitField0_ & 0x00000002) == 0x00000002);}
0
public long getInt64()
{    return int64_;}
0
public Builder setInt64(long value)
{    bitField0_ |= 0x00000002;    int64_ = value;    onChanged();    return this;}
0
public Builder clearInt64()
{    bitField0_ = (bitField0_ & ~0x00000002);    int64_ = 0L;    onChanged();    return this;}
0
public boolean hasUint32()
{    return ((bitField0_ & 0x00000004) == 0x00000004);}
0
public int getUint32()
{    return uint32_;}
0
public Builder setUint32(int value)
{    bitField0_ |= 0x00000004;    uint32_ = value;    onChanged();    return this;}
0
public Builder clearUint32()
{    bitField0_ = (bitField0_ & ~0x00000004);    uint32_ = 0;    onChanged();    return this;}
0
public boolean hasUint64()
{    return ((bitField0_ & 0x00000008) == 0x00000008);}
0
public long getUint64()
{    return uint64_;}
0
public Builder setUint64(long value)
{    bitField0_ |= 0x00000008;    uint64_ = value;    onChanged();    return this;}
0
public Builder clearUint64()
{    bitField0_ = (bitField0_ & ~0x00000008);    uint64_ = 0L;    onChanged();    return this;}
0
public boolean hasSint32()
{    return ((bitField0_ & 0x00000010) == 0x00000010);}
0
public int getSint32()
{    return sint32_;}
0
public Builder setSint32(int value)
{    bitField0_ |= 0x00000010;    sint32_ = value;    onChanged();    return this;}
0
public Builder clearSint32()
{    bitField0_ = (bitField0_ & ~0x00000010);    sint32_ = 0;    onChanged();    return this;}
0
public boolean hasSint64()
{    return ((bitField0_ & 0x00000020) == 0x00000020);}
0
public long getSint64()
{    return sint64_;}
0
public Builder setSint64(long value)
{    bitField0_ |= 0x00000020;    sint64_ = value;    onChanged();    return this;}
0
public Builder clearSint64()
{    bitField0_ = (bitField0_ & ~0x00000020);    sint64_ = 0L;    onChanged();    return this;}
0
public boolean hasFixed32()
{    return ((bitField0_ & 0x00000040) == 0x00000040);}
0
public int getFixed32()
{    return fixed32_;}
0
public Builder setFixed32(int value)
{    bitField0_ |= 0x00000040;    fixed32_ = value;    onChanged();    return this;}
0
public Builder clearFixed32()
{    bitField0_ = (bitField0_ & ~0x00000040);    fixed32_ = 0;    onChanged();    return this;}
0
public boolean hasFixed64()
{    return ((bitField0_ & 0x00000080) == 0x00000080);}
0
public long getFixed64()
{    return fixed64_;}
0
public Builder setFixed64(long value)
{    bitField0_ |= 0x00000080;    fixed64_ = value;    onChanged();    return this;}
0
public Builder clearFixed64()
{    bitField0_ = (bitField0_ & ~0x00000080);    fixed64_ = 0L;    onChanged();    return this;}
0
public boolean hasSfixed32()
{    return ((bitField0_ & 0x00000100) == 0x00000100);}
0
public int getSfixed32()
{    return sfixed32_;}
0
public Builder setSfixed32(int value)
{    bitField0_ |= 0x00000100;    sfixed32_ = value;    onChanged();    return this;}
0
public Builder clearSfixed32()
{    bitField0_ = (bitField0_ & ~0x00000100);    sfixed32_ = 0;    onChanged();    return this;}
0
public boolean hasSfixed64()
{    return ((bitField0_ & 0x00000200) == 0x00000200);}
0
public long getSfixed64()
{    return sfixed64_;}
0
public Builder setSfixed64(long value)
{    bitField0_ |= 0x00000200;    sfixed64_ = value;    onChanged();    return this;}
0
public Builder clearSfixed64()
{    bitField0_ = (bitField0_ & ~0x00000200);    sfixed64_ = 0L;    onChanged();    return this;}
0
public boolean hasFloat()
{    return ((bitField0_ & 0x00000400) == 0x00000400);}
0
public float getFloat()
{    return float_;}
0
public Builder setFloat(float value)
{    bitField0_ |= 0x00000400;    float_ = value;    onChanged();    return this;}
0
public Builder clearFloat()
{    bitField0_ = (bitField0_ & ~0x00000400);    float_ = 0F;    onChanged();    return this;}
0
public boolean hasDouble()
{    return ((bitField0_ & 0x00000800) == 0x00000800);}
0
public double getDouble()
{    return double_;}
0
public Builder setDouble(double value)
{    bitField0_ |= 0x00000800;    double_ = value;    onChanged();    return this;}
0
public Builder clearDouble()
{    bitField0_ = (bitField0_ & ~0x00000800);    double_ = 0D;    onChanged();    return this;}
0
public boolean hasBool()
{    return ((bitField0_ & 0x00001000) == 0x00001000);}
0
public boolean getBool()
{    return bool_;}
0
public Builder setBool(boolean value)
{    bitField0_ |= 0x00001000;    bool_ = value;    onChanged();    return this;}
0
public Builder clearBool()
{    bitField0_ = (bitField0_ & ~0x00001000);    bool_ = false;    onChanged();    return this;}
0
public boolean hasString()
{    return ((bitField0_ & 0x00002000) == 0x00002000);}
0
public java.lang.String getString()
{    java.lang.Object ref = string_;    if (!(ref instanceof java.lang.String)) {        com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;        java.lang.String s = bs.toStringUtf8();        if (bs.isValidUtf8()) {            string_ = s;        }        return s;    } else {        return (java.lang.String) ref;    }}
0
public com.google.protobuf.ByteString getStringBytes()
{    java.lang.Object ref = string_;    if (ref instanceof String) {        com.google.protobuf.ByteString b = com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);        string_ = b;        return b;    } else {        return (com.google.protobuf.ByteString) ref;    }}
0
public Builder setString(java.lang.String value)
{    if (value == null) {        throw new NullPointerException();    }    bitField0_ |= 0x00002000;    string_ = value;    onChanged();    return this;}
0
public Builder clearString()
{    bitField0_ = (bitField0_ & ~0x00002000);    string_ = getDefaultInstance().getString();    onChanged();    return this;}
0
public Builder setStringBytes(com.google.protobuf.ByteString value)
{    if (value == null) {        throw new NullPointerException();    }    bitField0_ |= 0x00002000;    string_ = value;    onChanged();    return this;}
0
public boolean hasBytes()
{    return ((bitField0_ & 0x00004000) == 0x00004000);}
0
public com.google.protobuf.ByteString getBytes()
{    return bytes_;}
0
public Builder setBytes(com.google.protobuf.ByteString value)
{    if (value == null) {        throw new NullPointerException();    }    bitField0_ |= 0x00004000;    bytes_ = value;    onChanged();    return this;}
0
public Builder clearBytes()
{    bitField0_ = (bitField0_ & ~0x00004000);    bytes_ = getDefaultInstance().getBytes();    onChanged();    return this;}
0
public boolean hasEnum()
{    return ((bitField0_ & 0x00008000) == 0x00008000);}
0
public org.apache.avro.protobuf.noopt.Test.A getEnum()
{    org.apache.avro.protobuf.noopt.Test.A result = org.apache.avro.protobuf.noopt.Test.A.valueOf(enum_);    return result == null ? org.apache.avro.protobuf.noopt.Test.A.Z : result;}
0
public Builder setEnum(org.apache.avro.protobuf.noopt.Test.A value)
{    if (value == null) {        throw new NullPointerException();    }    bitField0_ |= 0x00008000;    enum_ = value.getNumber();    onChanged();    return this;}
0
public Builder clearEnum()
{    bitField0_ = (bitField0_ & ~0x00008000);    enum_ = 3;    onChanged();    return this;}
0
private void ensureIntArrayIsMutable()
{    if (!((bitField0_ & 0x00010000) == 0x00010000)) {        intArray_ = new java.util.ArrayList<java.lang.Integer>(intArray_);        bitField0_ |= 0x00010000;    }}
0
public java.util.List<java.lang.Integer> getIntArrayList()
{    return java.util.Collections.unmodifiableList(intArray_);}
0
public int getIntArrayCount()
{    return intArray_.size();}
0
public int getIntArray(int index)
{    return intArray_.get(index);}
0
public Builder setIntArray(int index, int value)
{    ensureIntArrayIsMutable();    intArray_.set(index, value);    onChanged();    return this;}
0
public Builder addIntArray(int value)
{    ensureIntArrayIsMutable();    intArray_.add(value);    onChanged();    return this;}
0
public Builder addAllIntArray(java.lang.Iterable<? extends java.lang.Integer> values)
{    ensureIntArrayIsMutable();    com.google.protobuf.AbstractMessageLite.Builder.addAll(values, intArray_);    onChanged();    return this;}
0
public Builder clearIntArray()
{    intArray_ = java.util.Collections.emptyList();    bitField0_ = (bitField0_ & ~0x00010000);    onChanged();    return this;}
0
private void ensureFooArrayIsMutable()
{    if (!((bitField0_ & 0x00020000) == 0x00020000)) {        fooArray_ = new java.util.ArrayList<org.apache.avro.protobuf.noopt.Test.Foo>(fooArray_);        bitField0_ |= 0x00020000;    }}
0
public java.util.List<org.apache.avro.protobuf.noopt.Test.Foo> getFooArrayList()
{    if (fooArrayBuilder_ == null) {        return java.util.Collections.unmodifiableList(fooArray_);    } else {        return fooArrayBuilder_.getMessageList();    }}
0
public int getFooArrayCount()
{    if (fooArrayBuilder_ == null) {        return fooArray_.size();    } else {        return fooArrayBuilder_.getCount();    }}
0
public org.apache.avro.protobuf.noopt.Test.Foo getFooArray(int index)
{    if (fooArrayBuilder_ == null) {        return fooArray_.get(index);    } else {        return fooArrayBuilder_.getMessage(index);    }}
0
public Builder setFooArray(int index, org.apache.avro.protobuf.noopt.Test.Foo value)
{    if (fooArrayBuilder_ == null) {        if (value == null) {            throw new NullPointerException();        }        ensureFooArrayIsMutable();        fooArray_.set(index, value);        onChanged();    } else {        fooArrayBuilder_.setMessage(index, value);    }    return this;}
0
public Builder setFooArray(int index, org.apache.avro.protobuf.noopt.Test.Foo.Builder builderForValue)
{    if (fooArrayBuilder_ == null) {        ensureFooArrayIsMutable();        fooArray_.set(index, builderForValue.build());        onChanged();    } else {        fooArrayBuilder_.setMessage(index, builderForValue.build());    }    return this;}
0
public Builder addFooArray(org.apache.avro.protobuf.noopt.Test.Foo value)
{    if (fooArrayBuilder_ == null) {        if (value == null) {            throw new NullPointerException();        }        ensureFooArrayIsMutable();        fooArray_.add(value);        onChanged();    } else {        fooArrayBuilder_.addMessage(value);    }    return this;}
0
public Builder addFooArray(int index, org.apache.avro.protobuf.noopt.Test.Foo value)
{    if (fooArrayBuilder_ == null) {        if (value == null) {            throw new NullPointerException();        }        ensureFooArrayIsMutable();        fooArray_.add(index, value);        onChanged();    } else {        fooArrayBuilder_.addMessage(index, value);    }    return this;}
0
public Builder addFooArray(org.apache.avro.protobuf.noopt.Test.Foo.Builder builderForValue)
{    if (fooArrayBuilder_ == null) {        ensureFooArrayIsMutable();        fooArray_.add(builderForValue.build());        onChanged();    } else {        fooArrayBuilder_.addMessage(builderForValue.build());    }    return this;}
0
public Builder addFooArray(int index, org.apache.avro.protobuf.noopt.Test.Foo.Builder builderForValue)
{    if (fooArrayBuilder_ == null) {        ensureFooArrayIsMutable();        fooArray_.add(index, builderForValue.build());        onChanged();    } else {        fooArrayBuilder_.addMessage(index, builderForValue.build());    }    return this;}
0
public Builder addAllFooArray(java.lang.Iterable<? extends org.apache.avro.protobuf.noopt.Test.Foo> values)
{    if (fooArrayBuilder_ == null) {        ensureFooArrayIsMutable();        com.google.protobuf.AbstractMessageLite.Builder.addAll(values, fooArray_);        onChanged();    } else {        fooArrayBuilder_.addAllMessages(values);    }    return this;}
0
public Builder clearFooArray()
{    if (fooArrayBuilder_ == null) {        fooArray_ = java.util.Collections.emptyList();        bitField0_ = (bitField0_ & ~0x00020000);        onChanged();    } else {        fooArrayBuilder_.clear();    }    return this;}
0
public Builder removeFooArray(int index)
{    if (fooArrayBuilder_ == null) {        ensureFooArrayIsMutable();        fooArray_.remove(index);        onChanged();    } else {        fooArrayBuilder_.remove(index);    }    return this;}
0
public org.apache.avro.protobuf.noopt.Test.Foo.Builder getFooArrayBuilder(int index)
{    return getFooArrayFieldBuilder().getBuilder(index);}
0
public org.apache.avro.protobuf.noopt.Test.FooOrBuilder getFooArrayOrBuilder(int index)
{    if (fooArrayBuilder_ == null) {        return fooArray_.get(index);    } else {        return fooArrayBuilder_.getMessageOrBuilder(index);    }}
0
public java.util.List<? extends org.apache.avro.protobuf.noopt.Test.FooOrBuilder> getFooArrayOrBuilderList()
{    if (fooArrayBuilder_ != null) {        return fooArrayBuilder_.getMessageOrBuilderList();    } else {        return java.util.Collections.unmodifiableList(fooArray_);    }}
0
public org.apache.avro.protobuf.noopt.Test.Foo.Builder addFooArrayBuilder()
{    return getFooArrayFieldBuilder().addBuilder(org.apache.avro.protobuf.noopt.Test.Foo.getDefaultInstance());}
0
public org.apache.avro.protobuf.noopt.Test.Foo.Builder addFooArrayBuilder(int index)
{    return getFooArrayFieldBuilder().addBuilder(index, org.apache.avro.protobuf.noopt.Test.Foo.getDefaultInstance());}
0
public java.util.List<org.apache.avro.protobuf.noopt.Test.Foo.Builder> getFooArrayBuilderList()
{    return getFooArrayFieldBuilder().getBuilderList();}
0
private com.google.protobuf.RepeatedFieldBuilderV3<org.apache.avro.protobuf.noopt.Test.Foo, org.apache.avro.protobuf.noopt.Test.Foo.Builder, org.apache.avro.protobuf.noopt.Test.FooOrBuilder> getFooArrayFieldBuilder()
{    if (fooArrayBuilder_ == null) {        fooArrayBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<org.apache.avro.protobuf.noopt.Test.Foo, org.apache.avro.protobuf.noopt.Test.Foo.Builder, org.apache.avro.protobuf.noopt.Test.FooOrBuilder>(fooArray_, ((bitField0_ & 0x00020000) == 0x00020000), getParentForChildren(), isClean());        fooArray_ = null;    }    return fooArrayBuilder_;}
0
private void ensureSymsIsMutable()
{    if (!((bitField0_ & 0x00040000) == 0x00040000)) {        syms_ = new java.util.ArrayList<java.lang.Integer>(syms_);        bitField0_ |= 0x00040000;    }}
0
public java.util.List<org.apache.avro.protobuf.noopt.Test.A> getSymsList()
{    return new com.google.protobuf.Internal.ListAdapter<java.lang.Integer, org.apache.avro.protobuf.noopt.Test.A>(syms_, syms_converter_);}
0
public int getSymsCount()
{    return syms_.size();}
0
public org.apache.avro.protobuf.noopt.Test.A getSyms(int index)
{    return syms_converter_.convert(syms_.get(index));}
0
public Builder setSyms(int index, org.apache.avro.protobuf.noopt.Test.A value)
{    if (value == null) {        throw new NullPointerException();    }    ensureSymsIsMutable();    syms_.set(index, value.getNumber());    onChanged();    return this;}
0
public Builder addSyms(org.apache.avro.protobuf.noopt.Test.A value)
{    if (value == null) {        throw new NullPointerException();    }    ensureSymsIsMutable();    syms_.add(value.getNumber());    onChanged();    return this;}
0
public Builder addAllSyms(java.lang.Iterable<? extends org.apache.avro.protobuf.noopt.Test.A> values)
{    ensureSymsIsMutable();    for (org.apache.avro.protobuf.noopt.Test.A value : values) {        syms_.add(value.getNumber());    }    onChanged();    return this;}
0
public Builder clearSyms()
{    syms_ = java.util.Collections.emptyList();    bitField0_ = (bitField0_ & ~0x00040000);    onChanged();    return this;}
0
public boolean hasFoo()
{    return ((bitField0_ & 0x00080000) == 0x00080000);}
0
public org.apache.avro.protobuf.noopt.Test.Foo getFoo()
{    if (fooBuilder_ == null) {        return foo_ == null ? org.apache.avro.protobuf.noopt.Test.Foo.getDefaultInstance() : foo_;    } else {        return fooBuilder_.getMessage();    }}
0
public Builder setFoo(org.apache.avro.protobuf.noopt.Test.Foo value)
{    if (fooBuilder_ == null) {        if (value == null) {            throw new NullPointerException();        }        foo_ = value;        onChanged();    } else {        fooBuilder_.setMessage(value);    }    bitField0_ |= 0x00080000;    return this;}
0
public Builder setFoo(org.apache.avro.protobuf.noopt.Test.Foo.Builder builderForValue)
{    if (fooBuilder_ == null) {        foo_ = builderForValue.build();        onChanged();    } else {        fooBuilder_.setMessage(builderForValue.build());    }    bitField0_ |= 0x00080000;    return this;}
0
public Builder mergeFoo(org.apache.avro.protobuf.noopt.Test.Foo value)
{    if (fooBuilder_ == null) {        if (((bitField0_ & 0x00080000) == 0x00080000) && foo_ != null && foo_ != org.apache.avro.protobuf.noopt.Test.Foo.getDefaultInstance()) {            foo_ = org.apache.avro.protobuf.noopt.Test.Foo.newBuilder(foo_).mergeFrom(value).buildPartial();        } else {            foo_ = value;        }        onChanged();    } else {        fooBuilder_.mergeFrom(value);    }    bitField0_ |= 0x00080000;    return this;}
0
public Builder clearFoo()
{    if (fooBuilder_ == null) {        foo_ = null;        onChanged();    } else {        fooBuilder_.clear();    }    bitField0_ = (bitField0_ & ~0x00080000);    return this;}
0
public org.apache.avro.protobuf.noopt.Test.Foo.Builder getFooBuilder()
{    bitField0_ |= 0x00080000;    onChanged();    return getFooFieldBuilder().getBuilder();}
0
public org.apache.avro.protobuf.noopt.Test.FooOrBuilder getFooOrBuilder()
{    if (fooBuilder_ != null) {        return fooBuilder_.getMessageOrBuilder();    } else {        return foo_ == null ? org.apache.avro.protobuf.noopt.Test.Foo.getDefaultInstance() : foo_;    }}
0
private com.google.protobuf.SingleFieldBuilderV3<org.apache.avro.protobuf.noopt.Test.Foo, org.apache.avro.protobuf.noopt.Test.Foo.Builder, org.apache.avro.protobuf.noopt.Test.FooOrBuilder> getFooFieldBuilder()
{    if (fooBuilder_ == null) {        fooBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<org.apache.avro.protobuf.noopt.Test.Foo, org.apache.avro.protobuf.noopt.Test.Foo.Builder, org.apache.avro.protobuf.noopt.Test.FooOrBuilder>(getFoo(), getParentForChildren(), isClean());        foo_ = null;    }    return fooBuilder_;}
0
public boolean hasTimestamp()
{    return ((bitField0_ & 0x00100000) == 0x00100000);}
0
public com.google.protobuf.Timestamp getTimestamp()
{    if (timestampBuilder_ == null) {        return timestamp_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : timestamp_;    } else {        return timestampBuilder_.getMessage();    }}
0
public Builder setTimestamp(com.google.protobuf.Timestamp value)
{    if (timestampBuilder_ == null) {        if (value == null) {            throw new NullPointerException();        }        timestamp_ = value;        onChanged();    } else {        timestampBuilder_.setMessage(value);    }    bitField0_ |= 0x00100000;    return this;}
0
public Builder setTimestamp(com.google.protobuf.Timestamp.Builder builderForValue)
{    if (timestampBuilder_ == null) {        timestamp_ = builderForValue.build();        onChanged();    } else {        timestampBuilder_.setMessage(builderForValue.build());    }    bitField0_ |= 0x00100000;    return this;}
0
public Builder mergeTimestamp(com.google.protobuf.Timestamp value)
{    if (timestampBuilder_ == null) {        if (((bitField0_ & 0x00100000) == 0x00100000) && timestamp_ != null && timestamp_ != com.google.protobuf.Timestamp.getDefaultInstance()) {            timestamp_ = com.google.protobuf.Timestamp.newBuilder(timestamp_).mergeFrom(value).buildPartial();        } else {            timestamp_ = value;        }        onChanged();    } else {        timestampBuilder_.mergeFrom(value);    }    bitField0_ |= 0x00100000;    return this;}
0
public Builder clearTimestamp()
{    if (timestampBuilder_ == null) {        timestamp_ = null;        onChanged();    } else {        timestampBuilder_.clear();    }    bitField0_ = (bitField0_ & ~0x00100000);    return this;}
0
public com.google.protobuf.Timestamp.Builder getTimestampBuilder()
{    bitField0_ |= 0x00100000;    onChanged();    return getTimestampFieldBuilder().getBuilder();}
0
public com.google.protobuf.TimestampOrBuilder getTimestampOrBuilder()
{    if (timestampBuilder_ != null) {        return timestampBuilder_.getMessageOrBuilder();    } else {        return timestamp_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : timestamp_;    }}
0
private com.google.protobuf.SingleFieldBuilderV3<com.google.protobuf.Timestamp, com.google.protobuf.Timestamp.Builder, com.google.protobuf.TimestampOrBuilder> getTimestampFieldBuilder()
{    if (timestampBuilder_ == null) {        timestampBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<com.google.protobuf.Timestamp, com.google.protobuf.Timestamp.Builder, com.google.protobuf.TimestampOrBuilder>(getTimestamp(), getParentForChildren(), isClean());        timestamp_ = null;    }    return timestampBuilder_;}
0
public final Builder setUnknownFields(final com.google.protobuf.UnknownFieldSet unknownFields)
{    return super.setUnknownFields(unknownFields);}
0
public final Builder mergeUnknownFields(final com.google.protobuf.UnknownFieldSet unknownFields)
{    return super.mergeUnknownFields(unknownFields);}
0
public static org.apache.avro.protobuf.noopt.Test.Foo getDefaultInstance()
{    return DEFAULT_INSTANCE;}
0
public Foo parsePartialFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return new Foo(input, extensionRegistry);}
0
public static com.google.protobuf.Parser<Foo> parser()
{    return PARSER;}
0
public com.google.protobuf.Parser<Foo> getParserForType()
{    return PARSER;}
0
public org.apache.avro.protobuf.noopt.Test.Foo getDefaultInstanceForType()
{    return DEFAULT_INSTANCE;}
0
public final com.google.protobuf.UnknownFieldSet getUnknownFields()
{    return this.unknownFields;}
0
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.avro.protobuf.noopt.Test.internal_static_org_apache_avro_protobuf_noopt_M_descriptor;}
0
protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.avro.protobuf.noopt.Test.internal_static_org_apache_avro_protobuf_noopt_M_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.avro.protobuf.noopt.Test.M.class, org.apache.avro.protobuf.noopt.Test.M.Builder.class);}
0
public final int getNumber()
{    return value;}
0
public static N valueOf(int value)
{    return forNumber(value);}
0
public static N forNumber(int value)
{    switch(value) {        case 1:            return A;        default:            return null;    }}
0
public static com.google.protobuf.Internal.EnumLiteMap<N> internalGetValueMap()
{    return internalValueMap;}
0
public N findValueByNumber(int number)
{    return N.forNumber(number);}
0
public final com.google.protobuf.Descriptors.EnumValueDescriptor getValueDescriptor()
{    return getDescriptor().getValues().get(ordinal());}
0
public final com.google.protobuf.Descriptors.EnumDescriptor getDescriptorForType()
{    return getDescriptor();}
0
public static final com.google.protobuf.Descriptors.EnumDescriptor getDescriptor()
{    return org.apache.avro.protobuf.noopt.Test.M.getDescriptor().getEnumTypes().get(0);}
0
public static N valueOf(com.google.protobuf.Descriptors.EnumValueDescriptor desc)
{    if (desc.getType() != getDescriptor()) {        throw new java.lang.IllegalArgumentException("EnumValueDescriptor is not for this type.");    }    return VALUES[desc.getIndex()];}
0
public final boolean isInitialized()
{    byte isInitialized = memoizedIsInitialized;    if (isInitialized == 1)        return true;    if (isInitialized == 0)        return false;    memoizedIsInitialized = 1;    return true;}
0
public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException
{    unknownFields.writeTo(output);}
0
public int getSerializedSize()
{    int size = memoizedSize;    if (size != -1)        return size;    size = 0;    size += unknownFields.getSerializedSize();    memoizedSize = size;    return size;}
0
public boolean equals(final java.lang.Object obj)
{    if (obj == this) {        return true;    }    if (!(obj instanceof org.apache.avro.protobuf.noopt.Test.M)) {        return super.equals(obj);    }    org.apache.avro.protobuf.noopt.Test.M other = (org.apache.avro.protobuf.noopt.Test.M) obj;    boolean result = true;    result = result && unknownFields.equals(other.unknownFields);    return result;}
0
public int hashCode()
{    if (memoizedHashCode != 0) {        return memoizedHashCode;    }    int hash = 41;    hash = (19 * hash) + getDescriptor().hashCode();    hash = (29 * hash) + unknownFields.hashCode();    memoizedHashCode = hash;    return hash;}
0
public static org.apache.avro.protobuf.noopt.Test.M parseFrom(java.nio.ByteBuffer data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
0
public static org.apache.avro.protobuf.noopt.Test.M parseFrom(java.nio.ByteBuffer data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
0
public static org.apache.avro.protobuf.noopt.Test.M parseFrom(com.google.protobuf.ByteString data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
0
public static org.apache.avro.protobuf.noopt.Test.M parseFrom(com.google.protobuf.ByteString data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
0
public static org.apache.avro.protobuf.noopt.Test.M parseFrom(byte[] data) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data);}
0
public static org.apache.avro.protobuf.noopt.Test.M parseFrom(byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return PARSER.parseFrom(data, extensionRegistry);}
0
public static org.apache.avro.protobuf.noopt.Test.M parseFrom(java.io.InputStream input) throws java.io.IOException
{    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);}
0
public static org.apache.avro.protobuf.noopt.Test.M parseFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input, extensionRegistry);}
0
public static org.apache.avro.protobuf.noopt.Test.M parseDelimitedFrom(java.io.InputStream input) throws java.io.IOException
{    return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(PARSER, input);}
0
public static org.apache.avro.protobuf.noopt.Test.M parseDelimitedFrom(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(PARSER, input, extensionRegistry);}
0
public static org.apache.avro.protobuf.noopt.Test.M parseFrom(com.google.protobuf.CodedInputStream input) throws java.io.IOException
{    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);}
0
public static org.apache.avro.protobuf.noopt.Test.M parseFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input, extensionRegistry);}
0
public Builder newBuilderForType()
{    return newBuilder();}
0
public static Builder newBuilder()
{    return DEFAULT_INSTANCE.toBuilder();}
0
public static Builder newBuilder(org.apache.avro.protobuf.noopt.Test.M prototype)
{    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);}
0
public Builder toBuilder()
{    return this == DEFAULT_INSTANCE ? new Builder() : new Builder().mergeFrom(this);}
0
protected Builder newBuilderForType(com.google.protobuf.GeneratedMessageV3.BuilderParent parent)
{    Builder builder = new Builder(parent);    return builder;}
0
public static final com.google.protobuf.Descriptors.Descriptor getDescriptor()
{    return org.apache.avro.protobuf.noopt.Test.internal_static_org_apache_avro_protobuf_noopt_M_descriptor;}
0
protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable internalGetFieldAccessorTable()
{    return org.apache.avro.protobuf.noopt.Test.internal_static_org_apache_avro_protobuf_noopt_M_fieldAccessorTable.ensureFieldAccessorsInitialized(org.apache.avro.protobuf.noopt.Test.M.class, org.apache.avro.protobuf.noopt.Test.M.Builder.class);}
0
private void maybeForceBuilderInitialization()
{    if (com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders) {    }}
0
public Builder clear()
{    super.clear();    return this;}
0
public com.google.protobuf.Descriptors.Descriptor getDescriptorForType()
{    return org.apache.avro.protobuf.noopt.Test.internal_static_org_apache_avro_protobuf_noopt_M_descriptor;}
0
public org.apache.avro.protobuf.noopt.Test.M getDefaultInstanceForType()
{    return org.apache.avro.protobuf.noopt.Test.M.getDefaultInstance();}
0
public org.apache.avro.protobuf.noopt.Test.M build()
{    org.apache.avro.protobuf.noopt.Test.M result = buildPartial();    if (!result.isInitialized()) {        throw newUninitializedMessageException(result);    }    return result;}
0
public org.apache.avro.protobuf.noopt.Test.M buildPartial()
{    org.apache.avro.protobuf.noopt.Test.M result = new org.apache.avro.protobuf.noopt.Test.M(this);    onBuilt();    return result;}
0
public Builder clone()
{    return (Builder) super.clone();}
0
public Builder setField(com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value)
{    return (Builder) super.setField(field, value);}
0
public Builder clearField(com.google.protobuf.Descriptors.FieldDescriptor field)
{    return (Builder) super.clearField(field);}
0
public Builder clearOneof(com.google.protobuf.Descriptors.OneofDescriptor oneof)
{    return (Builder) super.clearOneof(oneof);}
0
public Builder setRepeatedField(com.google.protobuf.Descriptors.FieldDescriptor field, int index, java.lang.Object value)
{    return (Builder) super.setRepeatedField(field, index, value);}
0
public Builder addRepeatedField(com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value)
{    return (Builder) super.addRepeatedField(field, value);}
0
public Builder mergeFrom(com.google.protobuf.Message other)
{    if (other instanceof org.apache.avro.protobuf.noopt.Test.M) {        return mergeFrom((org.apache.avro.protobuf.noopt.Test.M) other);    } else {        super.mergeFrom(other);        return this;    }}
0
public Builder mergeFrom(org.apache.avro.protobuf.noopt.Test.M other)
{    if (other == org.apache.avro.protobuf.noopt.Test.M.getDefaultInstance())        return this;    this.mergeUnknownFields(other.unknownFields);    onChanged();    return this;}
0
public final boolean isInitialized()
{    return true;}
0
public Builder mergeFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException
{    org.apache.avro.protobuf.noopt.Test.M parsedMessage = null;    try {        parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);    } catch (com.google.protobuf.InvalidProtocolBufferException e) {        parsedMessage = (org.apache.avro.protobuf.noopt.Test.M) e.getUnfinishedMessage();        throw e.unwrapIOException();    } finally {        if (parsedMessage != null) {            mergeFrom(parsedMessage);        }    }    return this;}
0
public final Builder setUnknownFields(final com.google.protobuf.UnknownFieldSet unknownFields)
{    return super.setUnknownFields(unknownFields);}
0
public final Builder mergeUnknownFields(final com.google.protobuf.UnknownFieldSet unknownFields)
{    return super.mergeUnknownFields(unknownFields);}
0
public static org.apache.avro.protobuf.noopt.Test.M getDefaultInstance()
{    return DEFAULT_INSTANCE;}
0
public M parsePartialFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException
{    return new M(input, extensionRegistry);}
0
public static com.google.protobuf.Parser<M> parser()
{    return PARSER;}
0
public com.google.protobuf.Parser<M> getParserForType()
{    return PARSER;}
0
public org.apache.avro.protobuf.noopt.Test.M getDefaultInstanceForType()
{    return DEFAULT_INSTANCE;}
0
public static com.google.protobuf.Descriptors.FileDescriptor getDescriptor()
{    return descriptor;}
0
public com.google.protobuf.ExtensionRegistry assignDescriptors(com.google.protobuf.Descriptors.FileDescriptor root)
{    descriptor = root;    return null;}
0
public void testMessage() throws Exception
{    System.out.println(ProtobufData.get().getSchema(Foo.class).toString(true));    Foo.Builder builder = Foo.newBuilder();    builder.setInt32(0);    builder.setInt64(2);    builder.setUint32(3);    builder.setUint64(4);    builder.setSint32(5);    builder.setSint64(6);    builder.setFixed32(7);    builder.setFixed64(8);    builder.setSfixed32(9);    builder.setSfixed64(10);    builder.setFloat(1.0F);    builder.setDouble(2.0);    builder.setBool(true);    builder.setString("foo");    builder.setBytes(ByteString.copyFromUtf8("bar"));    builder.setEnum(A.X);    builder.addIntArray(27);    builder.addSyms(A.Y);    Foo fooInner = builder.build();    Foo fooInArray = builder.build();    builder = Foo.newBuilder(fooInArray);    builder.addFooArray(fooInArray);    com.google.protobuf.Timestamp ts = com.google.protobuf.Timestamp.newBuilder().setSeconds(1L).setNanos(2).build();    builder.setTimestamp(ts);    builder = Foo.newBuilder(fooInner);    builder.setFoo(fooInner);    Foo foo = builder.build();    System.out.println(foo);    ByteArrayOutputStream bao = new ByteArrayOutputStream();    ProtobufDatumWriter<Foo> w = new ProtobufDatumWriter<>(Foo.class);    Encoder e = EncoderFactory.get().binaryEncoder(bao, null);    w.write(foo, e);    e.flush();    Object o = new ProtobufDatumReader<>(Foo.class).read(null, DecoderFactory.get().binaryDecoder(new ByteArrayInputStream(bao.toByteArray()), null));    assertEquals(foo, o);}
0
public void testNestedEnum() throws Exception
{    Schema s = ProtobufData.get().getSchema(N.class);    assertEquals(N.class.getName(), SpecificData.get().getClass(s).getName());}
0
public void testNestedClassNamespace() throws Exception
{    Schema s = ProtobufData.get().getSchema(Foo.class);    assertEquals(org.apache.avro.protobuf.noopt.Test.class.getName(), s.getNamespace());}
0
public void testClassNamespaceInMultipleFiles() throws Exception
{    Schema fooSchema = ProtobufData.get().getSchema(org.apache.avro.protobuf.multiplefiles.Foo.class);    assertEquals(org.apache.avro.protobuf.multiplefiles.Foo.class.getPackage().getName(), fooSchema.getNamespace());    Schema nSchema = ProtobufData.get().getSchema(org.apache.avro.protobuf.multiplefiles.M.N.class);    assertEquals(org.apache.avro.protobuf.multiplefiles.M.class.getName(), nSchema.getNamespace());}
0
public void testGetNonRepeatedSchemaWithLogicalType() throws Exception
{    ProtoConversions.TimestampMillisConversion conversion = new ProtoConversions.TimestampMillisConversion();        ProtobufData instance1 = new ProtobufData();    Schema s1 = instance1.getSchema(com.google.protobuf.Timestamp.class);    assertNotEquals(conversion.getRecommendedSchema(), s1);        ProtobufData instance2 = new ProtobufData();    instance2.addLogicalTypeConversion(conversion);    Schema s2 = instance2.getSchema(com.google.protobuf.Timestamp.class);    assertEquals(conversion.getRecommendedSchema(), s2);}
0
public static void createSchemas()
{    TestProtoConversions.TIMESTAMP_MILLIS_SCHEMA = LogicalTypes.timestampMillis().addToSchema(Schema.create(Schema.Type.LONG));    TestProtoConversions.TIMESTAMP_MICROS_SCHEMA = LogicalTypes.timestampMicros().addToSchema(Schema.create(Schema.Type.LONG));}
0
public void testTimestampMillisConversion() throws Exception
{    TimestampMillisConversion conversion = new TimestampMillisConversion();    Timestamp May_28_2015_21_46_53_221_ts = Timestamp.newBuilder().setSeconds(1432849613L).setNanos(221000000).build();    Timestamp Jan_2_1900_3_4_5_678_ts = Timestamp.newBuilder().setSeconds(-2208891355L).setNanos(678000000).build();    long instant = May_28_2015_21_46_53_221.getTimeInMillis();    Timestamp tsFromInstant = conversion.fromLong(instant, TIMESTAMP_MILLIS_SCHEMA, LogicalTypes.timestampMillis());    long roundTrip = conversion.toLong(tsFromInstant, TIMESTAMP_MILLIS_SCHEMA, LogicalTypes.timestampMillis());    Assert.assertEquals("Round-trip conversion should work", instant, roundTrip);    Assert.assertEquals("Known timestamp should be correct", May_28_2015_21_46_53_221_ts, conversion.fromLong(instant, TIMESTAMP_MILLIS_SCHEMA, LogicalTypes.timestampMillis()));    Assert.assertEquals("Known timestamp should be correct", instant, (long) conversion.toLong(May_28_2015_21_46_53_221_ts, TIMESTAMP_MILLIS_SCHEMA, LogicalTypes.timestampMillis()));    instant = Jan_2_1900_3_4_5_678.getTimeInMillis();    tsFromInstant = conversion.fromLong(instant, TIMESTAMP_MILLIS_SCHEMA, LogicalTypes.timestampMillis());    roundTrip = conversion.toLong(tsFromInstant, TIMESTAMP_MILLIS_SCHEMA, LogicalTypes.timestampMillis());    Assert.assertEquals("Round-trip conversion should work", instant, roundTrip);    Assert.assertEquals("Known timestamp should be correct", Jan_2_1900_3_4_5_678_ts, conversion.fromLong(instant, TIMESTAMP_MILLIS_SCHEMA, LogicalTypes.timestampMillis()));    Assert.assertEquals("Known timestamp should be correct", instant, (long) conversion.toLong(Jan_2_1900_3_4_5_678_ts, TIMESTAMP_MILLIS_SCHEMA, LogicalTypes.timestampMillis()));}
0
public void testTimestampMicrosConversion()
{    TimestampMicrosConversion conversion = new TimestampMicrosConversion();    Timestamp May_28_2015_21_46_53_221_843_ts = Timestamp.newBuilder().setSeconds(1432849613L).setNanos(221843000).build();    Timestamp Jan_2_1900_3_4_5_678_901_ts = Timestamp.newBuilder().setSeconds(-2208891355L).setNanos(678901000).build();    long instant = May_28_2015_21_46_53_221.getTimeInMillis() * 1000 + 843;    Timestamp tsFromInstant = conversion.fromLong(instant, TIMESTAMP_MICROS_SCHEMA, LogicalTypes.timestampMicros());    long roundTrip = conversion.toLong(tsFromInstant, TIMESTAMP_MICROS_SCHEMA, LogicalTypes.timestampMicros());    Assert.assertEquals("Round-trip conversion should work", instant, roundTrip);    Assert.assertEquals("Known timestamp should be correct", May_28_2015_21_46_53_221_843_ts, conversion.fromLong(instant, TIMESTAMP_MICROS_SCHEMA, LogicalTypes.timestampMicros()));    Assert.assertEquals("Known timestamp should be correct", instant, (long) conversion.toLong(May_28_2015_21_46_53_221_843_ts, TIMESTAMP_MICROS_SCHEMA, LogicalTypes.timestampMicros()));    instant = Jan_2_1900_3_4_5_678.getTimeInMillis() * 1000 + 901;    tsFromInstant = conversion.fromLong(instant, TIMESTAMP_MICROS_SCHEMA, LogicalTypes.timestampMicros());    roundTrip = conversion.toLong(tsFromInstant, TIMESTAMP_MICROS_SCHEMA, LogicalTypes.timestampMicros());    Assert.assertEquals("Round-trip conversion should work", instant, roundTrip);    Assert.assertEquals("Known timestamp should be correct", Jan_2_1900_3_4_5_678_901_ts, conversion.fromLong(instant, TIMESTAMP_MICROS_SCHEMA, LogicalTypes.timestampMicros()));    Assert.assertEquals("Known timestamp should be correct", instant, (long) conversion.toLong(Jan_2_1900_3_4_5_678_901_ts, TIMESTAMP_MICROS_SCHEMA, LogicalTypes.timestampMicros()));}
0
public void testTimestampMillisConversionSecondsLowerLimit() throws Exception
{    TimestampMillisConversion conversion = new TimestampMillisConversion();    long exceeded = (ProtoConversions.SECONDS_LOWERLIMIT - 1) * 1000;    conversion.fromLong(exceeded, TIMESTAMP_MILLIS_SCHEMA, LogicalTypes.timestampMillis());}
0
public void testTimestampMillisConversionSecondsUpperLimit() throws Exception
{    TimestampMillisConversion conversion = new TimestampMillisConversion();    long exceeded = (ProtoConversions.SECONDS_UPPERLIMIT + 1) * 1000;    conversion.fromLong(exceeded, TIMESTAMP_MILLIS_SCHEMA, LogicalTypes.timestampMillis());}
0
public void testTimestampMicrosConversionSecondsLowerLimit() throws Exception
{    TimestampMicrosConversion conversion = new TimestampMicrosConversion();    long exceeded = (ProtoConversions.SECONDS_LOWERLIMIT - 1) * 1000000;    conversion.fromLong(exceeded, TIMESTAMP_MICROS_SCHEMA, LogicalTypes.timestampMicros());}
0
public void testTimestampMicrosConversionSecondsUpperLimit() throws Exception
{    TimestampMicrosConversion conversion = new TimestampMicrosConversion();    long exceeded = (ProtoConversions.SECONDS_UPPERLIMIT + 1) * 1000000;    conversion.fromLong(exceeded, TIMESTAMP_MICROS_SCHEMA, LogicalTypes.timestampMicros());}
0
public void testDynamicSchemaWithDateTimeConversion() throws ClassNotFoundException
{    Schema schema = getReflectedSchemaByName("com.google.protobuf.Timestamp", new TimestampMillisConversion());    Assert.assertEquals("Reflected schema should be logicalType timestampMillis", TIMESTAMP_MILLIS_SCHEMA, schema);}
0
public void testDynamicSchemaWithDateTimeMicrosConversion() throws ClassNotFoundException
{    Schema schema = getReflectedSchemaByName("com.google.protobuf.Timestamp", new TimestampMicrosConversion());    Assert.assertEquals("Reflected schema should be logicalType timestampMicros", TIMESTAMP_MICROS_SCHEMA, schema);}
0
private Schema getReflectedSchemaByName(String className, Conversion<?> conversion) throws ClassNotFoundException
{        Class<?> cls = Class.forName(className);        ReflectData model = new ReflectData();    model.addLogicalTypeConversion(conversion);    return model.getSchema(cls);}
0
public static ThriftData get()
{    return INSTANCE;}
0
public DatumReader createDatumReader(Schema schema)
{    return new ThriftDatumReader(schema, schema, this);}
0
public DatumWriter createDatumWriter(Schema schema)
{    return new ThriftDatumWriter(schema, this);}
0
public void setField(Object r, String n, int pos, Object o)
{    setField(r, n, pos, o, getRecordState(r, getSchema(r.getClass())));}
0
public Object getField(Object r, String name, int pos)
{    return getField(r, name, pos, getRecordState(r, getSchema(r.getClass())));}
0
protected void setField(Object r, String n, int pos, Object v, Object state)
{    if (v == null && r instanceof TUnion)        return;    ((TBase) r).setFieldValue(((TFieldIdEnum[]) state)[pos], v);}
0
protected Object getField(Object record, String name, int pos, Object state)
{    TFieldIdEnum f = ((TFieldIdEnum[]) state)[pos];    TBase struct = (TBase) record;    if (struct.isSet(f))        return struct.getFieldValue(f);    return null;}
0
protected Object getRecordState(Object r, Schema s)
{    TFieldIdEnum[] fields = fieldCache.get(s);    if (fields == null) {                fields = new TFieldIdEnum[s.getFields().size()];        Class c = r.getClass();        for (TFieldIdEnum f : FieldMetaData.getStructMetaDataMap((Class<? extends TBase>) c).keySet()) fields[s.getField(f.getFieldName()).pos()] = f;                fieldCache.put(s, fields);    }    return fields;}
0
protected String getSchemaName(Object datum)
{        if (datum instanceof Short)        return Schema.Type.INT.getName();        if (datum instanceof Byte)        return Schema.Type.INT.getName();    return super.getSchemaName(datum);}
0
protected boolean isRecord(Object datum)
{    return datum instanceof TBase;}
0
protected boolean isEnum(Object datum)
{    return datum instanceof TEnum;}
0
protected Schema getEnumSchema(Object datum)
{    return getSchema(datum.getClass());}
0
protected boolean isBytes(Object datum)
{    if (datum instanceof ByteBuffer)        return true;    if (datum == null)        return false;    Class c = datum.getClass();    return c.isArray() && c.getComponentType() == Byte.TYPE;}
0
public Object newRecord(Object old, Schema schema)
{    try {        Class c = ClassUtils.forName(SpecificData.getClassName(schema));        if (c == null)                        return newRecord(old, schema);        if (c.isInstance(old))                        return old;                return c.newInstance();    } catch (Exception e) {        throw new RuntimeException(e);    }}
0
protected Schema getRecordSchema(Object record)
{    return getSchema(record.getClass());}
0
public Schema getSchema(Class c)
{    Schema schema = schemaCache.get(c);    if (schema == null) {                try {            if (TEnum.class.isAssignableFrom(c)) {                                List<String> symbols = new ArrayList<>();                for (Enum e : ((Class<? extends Enum>) c).getEnumConstants()) symbols.add(e.name());                schema = Schema.createEnum(c.getName(), null, null, symbols);            } else if (TBase.class.isAssignableFrom(c)) {                                schema = Schema.createRecord(c.getName(), null, null, Throwable.class.isAssignableFrom(c));                List<Field> fields = new ArrayList<>();                for (FieldMetaData f : FieldMetaData.getStructMetaDataMap((Class<? extends TBase>) c).values()) {                    Schema s = getSchema(f.valueMetaData);                    if (f.requirementType == TFieldRequirementType.OPTIONAL && (s.getType() != Schema.Type.UNION))                        s = nullable(s);                    fields.add(new Field(f.fieldName, s, null, null));                }                schema.setFields(fields);            } else {                throw new RuntimeException("Not a Thrift-generated class: " + c);            }        } catch (Exception e) {            throw new RuntimeException(e);        }                schemaCache.put(c, schema);    }    return schema;}
0
private Schema getSchema(FieldValueMetaData f)
{    switch(f.type) {        case TType.BOOL:            return Schema.create(Schema.Type.BOOLEAN);        case TType.BYTE:            Schema b = Schema.create(Schema.Type.INT);            b.addProp(THRIFT_PROP, "byte");            return b;        case TType.I16:            Schema s = Schema.create(Schema.Type.INT);            s.addProp(THRIFT_PROP, "short");            return s;        case TType.I32:            return Schema.create(Schema.Type.INT);        case TType.I64:            return Schema.create(Schema.Type.LONG);        case TType.DOUBLE:            return Schema.create(Schema.Type.DOUBLE);        case TType.ENUM:            EnumMetaData enumMeta = (EnumMetaData) f;            return nullable(getSchema(enumMeta.enumClass));        case TType.LIST:            ListMetaData listMeta = (ListMetaData) f;            return nullable(Schema.createArray(getSchema(listMeta.elemMetaData)));        case TType.MAP:            MapMetaData mapMeta = (MapMetaData) f;            if (mapMeta.keyMetaData.type != TType.STRING)                throw new AvroRuntimeException("Map keys must be strings: " + f);            Schema map = Schema.createMap(getSchema(mapMeta.valueMetaData));            GenericData.setStringType(map, GenericData.StringType.String);            return nullable(map);        case TType.SET:            SetMetaData setMeta = (SetMetaData) f;            Schema set = Schema.createArray(getSchema(setMeta.elemMetaData));            set.addProp(THRIFT_PROP, "set");            return nullable(set);        case TType.STRING:            if (f.isBinary())                return nullable(Schema.create(Schema.Type.BYTES));            Schema string = Schema.create(Schema.Type.STRING);            GenericData.setStringType(string, GenericData.StringType.String);            return nullable(string);        case TType.STRUCT:            StructMetaData structMeta = (StructMetaData) f;            Schema record = getSchema(structMeta.structClass);            return nullable(record);        case TType.VOID:            return NULL;        default:            throw new RuntimeException("Unexpected type in field: " + f);    }}
0
private Schema nullable(Schema schema)
{    return Schema.createUnion(Arrays.asList(NULL, schema));}
0
protected Object createEnum(String symbol, Schema schema)
{    try {        Class c = ClassUtils.forName(SpecificData.getClassName(schema));        if (c == null)                        return super.createEnum(symbol, schema);        return Enum.valueOf(c, symbol);    } catch (Exception e) {        throw new AvroRuntimeException(e);    }}
0
protected Object readInt(Object old, Schema s, Decoder in) throws IOException
{    String type = s.getProp(ThriftData.THRIFT_PROP);    int value = in.readInt();    if (type != null) {        if ("byte".equals(type))            return (byte) value;        if ("short".equals(type))            return (short) value;    }    return value;}
0
protected Object newArray(Object old, int size, Schema schema)
{    if ("set".equals(schema.getProp(ThriftData.THRIFT_PROP))) {        if (old instanceof Set) {            ((Set) old).clear();            return old;        }        return new HashSet();    } else {        return super.newArray(old, size, schema);    }}
0
protected void writeBytes(Object datum, Encoder out) throws IOException
{        out.writeBytes(ByteBuffer.wrap((byte[]) datum));}
0
public int getValue()
{    return value;}
0
public static E findByValue(int value)
{    switch(value) {        case 1:            return X;        case 2:            return Y;        case 3:            return Z;        default:            return null;    }}
0
public static _Fields findByThriftId(int fieldId)
{    switch(fieldId) {        case         1:            return MESSAGE;        default:            return null;    }}
0
public static _Fields findByThriftIdOrThrow(int fieldId)
{    _Fields fields = findByThriftId(fieldId);    if (fields == null)        throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");    return fields;}
0
public static _Fields findByName(String name)
{    return byName.get(name);}
0
public short getThriftFieldId()
{    return _thriftId;}
0
public String getFieldName()
{    return _fieldName;}
0
public Error deepCopy()
{    return new Error(this);}
0
public void clear()
{    this.message = null;}
0
public String getMessage()
{    return this.message;}
0
public void setMessage(String message)
{    this.message = message;}
0
public void unsetMessage()
{    this.message = null;}
0
public boolean isSetMessage()
{    return this.message != null;}
0
public void setMessageIsSet(boolean value)
{    if (!value) {        this.message = null;    }}
0
public void setFieldValue(_Fields field, Object value)
{    switch(field) {        case MESSAGE:            if (value == null) {                unsetMessage();            } else {                setMessage((String) value);            }            break;    }}
0
public Object getFieldValue(_Fields field)
{    switch(field) {        case MESSAGE:            return getMessage();    }    throw new IllegalStateException();}
0
public boolean isSet(_Fields field)
{    if (field == null) {        throw new IllegalArgumentException();    }    switch(field) {        case MESSAGE:            return isSetMessage();    }    throw new IllegalStateException();}
0
public boolean equals(Object that)
{    if (that == null)        return false;    if (that instanceof Error)        return this.equals((Error) that);    return false;}
0
public boolean equals(Error that)
{    if (that == null)        return false;    boolean this_present_message = true && this.isSetMessage();    boolean that_present_message = true && that.isSetMessage();    if (this_present_message || that_present_message) {        if (!(this_present_message && that_present_message))            return false;        return this.message.equals(that.message);    }    return true;}
0
public int hashCode()
{    return 0;}
0
public int compareTo(Error other)
{    if (!getClass().equals(other.getClass())) {        return getClass().getName().compareTo(other.getClass().getName());    }    int lastComparison = 0;    lastComparison = Boolean.compare(isSetMessage(), other.isSetMessage());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetMessage()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.message, other.message);        if (lastComparison != 0) {            return lastComparison;        }    }    return 0;}
0
public _Fields fieldForId(int fieldId)
{    return _Fields.findByThriftId(fieldId);}
0
public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException
{    schemes.get(iprot.getScheme()).getScheme().read(iprot, this);}
0
public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException
{    schemes.get(oprot.getScheme()).getScheme().write(oprot, this);}
0
public String toString()
{    StringBuilder sb = new StringBuilder("Error(");    boolean first = true;    sb.append("message:");    if (this.message == null) {        sb.append("null");    } else {        sb.append(this.message);    }    first = false;    sb.append(")");    return sb.toString();}
0
public void validate() throws org.apache.thrift.TException
{}
0
private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException
{    try {        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
0
private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException
{    try {        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
0
public ErrorStandardScheme getScheme()
{    return new ErrorStandardScheme();}
0
public void read(org.apache.thrift.protocol.TProtocol iprot, Error struct) throws org.apache.thrift.TException
{    org.apache.thrift.protocol.TField schemeField;    iprot.readStructBegin();    while (true) {        schemeField = iprot.readFieldBegin();        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) {            break;        }        switch(schemeField.id) {            case             1:                if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {                    struct.message = iprot.readString();                    struct.setMessageIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            default:                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);        }        iprot.readFieldEnd();    }    iprot.readStructEnd();    struct.validate();}
0
public void write(org.apache.thrift.protocol.TProtocol oprot, Error struct) throws org.apache.thrift.TException
{    struct.validate();    oprot.writeStructBegin(STRUCT_DESC);    if (struct.message != null) {        oprot.writeFieldBegin(MESSAGE_FIELD_DESC);        oprot.writeString(struct.message);        oprot.writeFieldEnd();    }    oprot.writeFieldStop();    oprot.writeStructEnd();}
0
public ErrorTupleScheme getScheme()
{    return new ErrorTupleScheme();}
0
public void write(org.apache.thrift.protocol.TProtocol prot, Error struct) throws org.apache.thrift.TException
{    TTupleProtocol oprot = (TTupleProtocol) prot;    BitSet optionals = new BitSet();    if (struct.isSetMessage()) {        optionals.set(0);    }    oprot.writeBitSet(optionals, 1);    if (struct.isSetMessage()) {        oprot.writeString(struct.message);    }}
0
public void read(org.apache.thrift.protocol.TProtocol prot, Error struct) throws org.apache.thrift.TException
{    TTupleProtocol iprot = (TTupleProtocol) prot;    BitSet incoming = iprot.readBitSet(1);    if (incoming.get(0)) {        struct.message = iprot.readString();        struct.setMessageIsSet(true);    }}
0
public Client getClient(org.apache.thrift.protocol.TProtocol prot)
{    return new Client(prot);}
0
public Client getClient(org.apache.thrift.protocol.TProtocol iprot, org.apache.thrift.protocol.TProtocol oprot)
{    return new Client(iprot, oprot);}
0
public void ping() throws org.apache.thrift.TException
{    send_ping();    recv_ping();}
0
public void send_ping() throws org.apache.thrift.TException
{    ping_args args = new ping_args();    sendBase("ping", args);}
0
public void recv_ping() throws org.apache.thrift.TException
{    ping_result result = new ping_result();    receiveBase(result, "ping");}
0
public int add(int num1, int num2) throws org.apache.thrift.TException
{    send_add(num1, num2);    return recv_add();}
0
public void send_add(int num1, int num2) throws org.apache.thrift.TException
{    add_args args = new add_args();    args.setNum1(num1);    args.setNum2(num2);    sendBase("add", args);}
0
public int recv_add() throws org.apache.thrift.TException
{    add_result result = new add_result();    receiveBase(result, "add");    if (result.isSetSuccess()) {        return result.success;    }    throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, "add failed: unknown result");}
0
public void zip() throws org.apache.thrift.TException
{    send_zip();}
0
public void send_zip() throws org.apache.thrift.TException
{    zip_args args = new zip_args();    sendBase("zip", args);}
0
public AsyncClient getAsyncClient(org.apache.thrift.transport.TNonblockingTransport transport)
{    return new AsyncClient(protocolFactory, clientManager, transport);}
0
public void ping(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException
{    checkReady();    ping_call method_call = new ping_call(resultHandler, this, ___protocolFactory, ___transport);    this.___currentMethod = method_call;    ___manager.call(method_call);}
0
public void write_args(org.apache.thrift.protocol.TProtocol prot) throws org.apache.thrift.TException
{    prot.writeMessageBegin(new org.apache.thrift.protocol.TMessage("ping", org.apache.thrift.protocol.TMessageType.CALL, 0));    ping_args args = new ping_args();    args.write(prot);    prot.writeMessageEnd();}
0
public Object getResult() throws org.apache.thrift.TException
{    if (getState() != org.apache.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {        throw new IllegalStateException("Method call not finished!");    }    org.apache.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());    org.apache.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);    (new Client(prot)).recv_ping();    return null;}
0
public void add(int num1, int num2, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException
{    checkReady();    add_call method_call = new add_call(num1, num2, resultHandler, this, ___protocolFactory, ___transport);    this.___currentMethod = method_call;    ___manager.call(method_call);}
0
public void write_args(org.apache.thrift.protocol.TProtocol prot) throws org.apache.thrift.TException
{    prot.writeMessageBegin(new org.apache.thrift.protocol.TMessage("add", org.apache.thrift.protocol.TMessageType.CALL, 0));    add_args args = new add_args();    args.setNum1(num1);    args.setNum2(num2);    args.write(prot);    prot.writeMessageEnd();}
0
public Object getResult() throws org.apache.thrift.TException
{    if (getState() != org.apache.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {        throw new IllegalStateException("Method call not finished!");    }    org.apache.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());    org.apache.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);    return (new Client(prot)).recv_add();}
0
public void zip(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException
{    checkReady();    zip_call method_call = new zip_call(resultHandler, this, ___protocolFactory, ___transport);    this.___currentMethod = method_call;    ___manager.call(method_call);}
0
public void write_args(org.apache.thrift.protocol.TProtocol prot) throws org.apache.thrift.TException
{    prot.writeMessageBegin(new org.apache.thrift.protocol.TMessage("zip", org.apache.thrift.protocol.TMessageType.CALL, 0));    zip_args args = new zip_args();    args.write(prot);    prot.writeMessageEnd();}
0
public Object getResult()
{    if (getState() != org.apache.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {        throw new IllegalStateException("Method call not finished!");    }    org.apache.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());    org.apache.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);    return prot;}
0
private static Map<String, org.apache.thrift.ProcessFunction<I, ? extends org.apache.thrift.TBase>> getProcessMap(Map<String, org.apache.thrift.ProcessFunction<I, ? extends org.apache.thrift.TBase>> processMap)
{    processMap.put("ping", new ping());    processMap.put("add", new add());    processMap.put("zip", new zip());    return processMap;}
0
public ping_args getEmptyArgsInstance()
{    return new ping_args();}
0
protected boolean isOneway()
{    return false;}
0
public ping_result getResult(I iface, ping_args args) throws org.apache.thrift.TException
{    ping_result result = new ping_result();    iface.ping();    return result;}
0
public add_args getEmptyArgsInstance()
{    return new add_args();}
0
protected boolean isOneway()
{    return false;}
0
public add_result getResult(I iface, add_args args) throws org.apache.thrift.TException
{    add_result result = new add_result();    result.success = iface.add(args.num1, args.num2);    result.setSuccessIsSet(true);    return result;}
0
public zip_args getEmptyArgsInstance()
{    return new zip_args();}
0
protected boolean isOneway()
{    return true;}
0
public org.apache.thrift.TBase getResult(I iface, zip_args args) throws org.apache.thrift.TException
{    iface.zip();    return null;}
0
private static Map<String, org.apache.thrift.AsyncProcessFunction<I, ? extends org.apache.thrift.TBase, ?>> getProcessMap(Map<String, org.apache.thrift.AsyncProcessFunction<I, ? extends org.apache.thrift.TBase, ?>> processMap)
{    processMap.put("ping", new ping());    processMap.put("add", new add());    processMap.put("zip", new zip());    return processMap;}
0
public ping_args getEmptyArgsInstance()
{    return new ping_args();}
0
public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid)
{    final org.apache.thrift.AsyncProcessFunction fcall = this;    return new AsyncMethodCallback<Void>() {        @Override        public void onComplete(Void o) {            ping_result result = new ping_result();            try {                fcall.sendResponse(fb, result, org.apache.thrift.protocol.TMessageType.REPLY, seqid);                return;            } catch (Exception e) {                            }            fb.close();        }        @Override        public void onError(Exception e) {            byte msgType = org.apache.thrift.protocol.TMessageType.REPLY;            org.apache.thrift.TBase msg;            ping_result result = new ping_result();            {                msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;                msg = (org.apache.thrift.TBase) new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());            }            try {                fcall.sendResponse(fb, msg, msgType, seqid);                return;            } catch (Exception ex) {                            }            fb.close();        }    };}
1
public void onComplete(Void o)
{    ping_result result = new ping_result();    try {        fcall.sendResponse(fb, result, org.apache.thrift.protocol.TMessageType.REPLY, seqid);        return;    } catch (Exception e) {            }    fb.close();}
1
public void onError(Exception e)
{    byte msgType = org.apache.thrift.protocol.TMessageType.REPLY;    org.apache.thrift.TBase msg;    ping_result result = new ping_result();    {        msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;        msg = (org.apache.thrift.TBase) new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());    }    try {        fcall.sendResponse(fb, msg, msgType, seqid);        return;    } catch (Exception ex) {            }    fb.close();}
1
protected boolean isOneway()
{    return false;}
0
public void start(I iface, ping_args args, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws TException
{    iface.ping(resultHandler);}
0
public add_args getEmptyArgsInstance()
{    return new add_args();}
0
public AsyncMethodCallback<Integer> getResultHandler(final AsyncFrameBuffer fb, final int seqid)
{    final org.apache.thrift.AsyncProcessFunction fcall = this;    return new AsyncMethodCallback<Integer>() {        @Override        public void onComplete(Integer o) {            add_result result = new add_result();            result.success = o;            result.setSuccessIsSet(true);            try {                fcall.sendResponse(fb, result, org.apache.thrift.protocol.TMessageType.REPLY, seqid);                return;            } catch (Exception e) {                            }            fb.close();        }        @Override        public void onError(Exception e) {            byte msgType = org.apache.thrift.protocol.TMessageType.REPLY;            org.apache.thrift.TBase msg;            add_result result = new add_result();            {                msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;                msg = (org.apache.thrift.TBase) new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());            }            try {                fcall.sendResponse(fb, msg, msgType, seqid);                return;            } catch (Exception ex) {                            }            fb.close();        }    };}
1
public void onComplete(Integer o)
{    add_result result = new add_result();    result.success = o;    result.setSuccessIsSet(true);    try {        fcall.sendResponse(fb, result, org.apache.thrift.protocol.TMessageType.REPLY, seqid);        return;    } catch (Exception e) {            }    fb.close();}
1
public void onError(Exception e)
{    byte msgType = org.apache.thrift.protocol.TMessageType.REPLY;    org.apache.thrift.TBase msg;    add_result result = new add_result();    {        msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;        msg = (org.apache.thrift.TBase) new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());    }    try {        fcall.sendResponse(fb, msg, msgType, seqid);        return;    } catch (Exception ex) {            }    fb.close();}
1
protected boolean isOneway()
{    return false;}
0
public void start(I iface, add_args args, org.apache.thrift.async.AsyncMethodCallback<Integer> resultHandler) throws TException
{    iface.add(args.num1, args.num2, resultHandler);}
0
public zip_args getEmptyArgsInstance()
{    return new zip_args();}
0
public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid)
{    final org.apache.thrift.AsyncProcessFunction fcall = this;    return new AsyncMethodCallback<Void>() {        @Override        public void onComplete(Void o) {        }        @Override        public void onError(Exception e) {        }    };}
0
public void onComplete(Void o)
{}
0
public void onError(Exception e)
{}
0
protected boolean isOneway()
{    return true;}
0
public void start(I iface, zip_args args, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws TException
{    iface.zip(resultHandler);}
0
public static _Fields findByThriftId(int fieldId)
{    switch(fieldId) {        default:            return null;    }}
0
public static _Fields findByThriftIdOrThrow(int fieldId)
{    _Fields fields = findByThriftId(fieldId);    if (fields == null)        throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");    return fields;}
0
public static _Fields findByName(String name)
{    return byName.get(name);}
0
public short getThriftFieldId()
{    return _thriftId;}
0
public String getFieldName()
{    return _fieldName;}
0
public ping_args deepCopy()
{    return new ping_args(this);}
0
public void clear()
{}
0
public void setFieldValue(_Fields field, Object value)
{    switch(field) {    }}
0
public Object getFieldValue(_Fields field)
{    switch(field) {    }    throw new IllegalStateException();}
0
public boolean isSet(_Fields field)
{    if (field == null) {        throw new IllegalArgumentException();    }    switch(field) {    }    throw new IllegalStateException();}
0
public boolean equals(Object that)
{    if (that == null)        return false;    if (that instanceof ping_args)        return this.equals((ping_args) that);    return false;}
0
public boolean equals(ping_args that)
{    return that != null;}
0
public int hashCode()
{    return 0;}
0
public int compareTo(ping_args other)
{    if (!getClass().equals(other.getClass())) {        return getClass().getName().compareTo(other.getClass().getName());    }    int lastComparison = 0;    return 0;}
0
public _Fields fieldForId(int fieldId)
{    return _Fields.findByThriftId(fieldId);}
0
public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException
{    schemes.get(iprot.getScheme()).getScheme().read(iprot, this);}
0
public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException
{    schemes.get(oprot.getScheme()).getScheme().write(oprot, this);}
0
public String toString()
{    boolean first = true;    return "ping_args(" + ")";}
0
public void validate() throws org.apache.thrift.TException
{}
0
private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException
{    try {        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
0
private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException
{    try {        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
0
public ping_argsStandardScheme getScheme()
{    return new ping_argsStandardScheme();}
0
public void read(org.apache.thrift.protocol.TProtocol iprot, ping_args struct) throws org.apache.thrift.TException
{    org.apache.thrift.protocol.TField schemeField;    iprot.readStructBegin();    while (true) {        schemeField = iprot.readFieldBegin();        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) {            break;        }        switch(schemeField.id) {            default:                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);        }        iprot.readFieldEnd();    }    iprot.readStructEnd();    struct.validate();}
0
public void write(org.apache.thrift.protocol.TProtocol oprot, ping_args struct) throws org.apache.thrift.TException
{    struct.validate();    oprot.writeStructBegin(STRUCT_DESC);    oprot.writeFieldStop();    oprot.writeStructEnd();}
0
public ping_argsTupleScheme getScheme()
{    return new ping_argsTupleScheme();}
0
public void write(org.apache.thrift.protocol.TProtocol prot, ping_args struct) throws org.apache.thrift.TException
{    TTupleProtocol oprot = (TTupleProtocol) prot;}
0
public void read(org.apache.thrift.protocol.TProtocol prot, ping_args struct) throws org.apache.thrift.TException
{    TTupleProtocol iprot = (TTupleProtocol) prot;}
0
public static _Fields findByThriftId(int fieldId)
{    switch(fieldId) {        default:            return null;    }}
0
public static _Fields findByThriftIdOrThrow(int fieldId)
{    _Fields fields = findByThriftId(fieldId);    if (fields == null)        throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");    return fields;}
0
public static _Fields findByName(String name)
{    return byName.get(name);}
0
public short getThriftFieldId()
{    return _thriftId;}
0
public String getFieldName()
{    return _fieldName;}
0
public ping_result deepCopy()
{    return new ping_result(this);}
0
public void clear()
{}
0
public void setFieldValue(_Fields field, Object value)
{    switch(field) {    }}
0
public Object getFieldValue(_Fields field)
{    switch(field) {    }    throw new IllegalStateException();}
0
public boolean isSet(_Fields field)
{    if (field == null) {        throw new IllegalArgumentException();    }    switch(field) {    }    throw new IllegalStateException();}
0
public boolean equals(Object that)
{    if (that == null)        return false;    if (that instanceof ping_result)        return this.equals((ping_result) that);    return false;}
0
public boolean equals(ping_result that)
{    return that != null;}
0
public int hashCode()
{    return 0;}
0
public int compareTo(ping_result other)
{    if (!getClass().equals(other.getClass())) {        return getClass().getName().compareTo(other.getClass().getName());    }    int lastComparison = 0;    return 0;}
0
public _Fields fieldForId(int fieldId)
{    return _Fields.findByThriftId(fieldId);}
0
public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException
{    schemes.get(iprot.getScheme()).getScheme().read(iprot, this);}
0
public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException
{    schemes.get(oprot.getScheme()).getScheme().write(oprot, this);}
0
public String toString()
{    boolean first = true;    return "ping_result(" + ")";}
0
public void validate() throws org.apache.thrift.TException
{}
0
private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException
{    try {        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
0
private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException
{    try {        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
0
public ping_resultStandardScheme getScheme()
{    return new ping_resultStandardScheme();}
0
public void read(org.apache.thrift.protocol.TProtocol iprot, ping_result struct) throws org.apache.thrift.TException
{    org.apache.thrift.protocol.TField schemeField;    iprot.readStructBegin();    while (true) {        schemeField = iprot.readFieldBegin();        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) {            break;        }        switch(schemeField.id) {            default:                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);        }        iprot.readFieldEnd();    }    iprot.readStructEnd();    struct.validate();}
0
public void write(org.apache.thrift.protocol.TProtocol oprot, ping_result struct) throws org.apache.thrift.TException
{    struct.validate();    oprot.writeStructBegin(STRUCT_DESC);    oprot.writeFieldStop();    oprot.writeStructEnd();}
0
public ping_resultTupleScheme getScheme()
{    return new ping_resultTupleScheme();}
0
public void write(org.apache.thrift.protocol.TProtocol prot, ping_result struct) throws org.apache.thrift.TException
{    TTupleProtocol oprot = (TTupleProtocol) prot;}
0
public void read(org.apache.thrift.protocol.TProtocol prot, ping_result struct) throws org.apache.thrift.TException
{    TTupleProtocol iprot = (TTupleProtocol) prot;}
0
public static _Fields findByThriftId(int fieldId)
{    switch(fieldId) {        case         1:            return NUM1;        case         2:            return NUM2;        default:            return null;    }}
0
public static _Fields findByThriftIdOrThrow(int fieldId)
{    _Fields fields = findByThriftId(fieldId);    if (fields == null)        throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");    return fields;}
0
public static _Fields findByName(String name)
{    return byName.get(name);}
0
public short getThriftFieldId()
{    return _thriftId;}
0
public String getFieldName()
{    return _fieldName;}
0
public add_args deepCopy()
{    return new add_args(this);}
0
public void clear()
{    setNum1IsSet(false);    this.num1 = 0;    setNum2IsSet(false);    this.num2 = 0;}
0
public int getNum1()
{    return this.num1;}
0
public void setNum1(int num1)
{    this.num1 = num1;    setNum1IsSet(true);}
0
public void unsetNum1()
{    __isset_bitfield = EncodingUtils.clearBit(__isset_bitfield, __NUM1_ISSET_ID);}
0
public boolean isSetNum1()
{    return EncodingUtils.testBit(__isset_bitfield, __NUM1_ISSET_ID);}
0
public void setNum1IsSet(boolean value)
{    __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __NUM1_ISSET_ID, value);}
0
public int getNum2()
{    return this.num2;}
0
public void setNum2(int num2)
{    this.num2 = num2;    setNum2IsSet(true);}
0
public void unsetNum2()
{    __isset_bitfield = EncodingUtils.clearBit(__isset_bitfield, __NUM2_ISSET_ID);}
0
public boolean isSetNum2()
{    return EncodingUtils.testBit(__isset_bitfield, __NUM2_ISSET_ID);}
0
public void setNum2IsSet(boolean value)
{    __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __NUM2_ISSET_ID, value);}
0
public void setFieldValue(_Fields field, Object value)
{    switch(field) {        case NUM1:            if (value == null) {                unsetNum1();            } else {                setNum1((Integer) value);            }            break;        case NUM2:            if (value == null) {                unsetNum2();            } else {                setNum2((Integer) value);            }            break;    }}
0
public Object getFieldValue(_Fields field)
{    switch(field) {        case NUM1:            return getNum1();        case NUM2:            return getNum2();    }    throw new IllegalStateException();}
0
public boolean isSet(_Fields field)
{    if (field == null) {        throw new IllegalArgumentException();    }    switch(field) {        case NUM1:            return isSetNum1();        case NUM2:            return isSetNum2();    }    throw new IllegalStateException();}
0
public boolean equals(Object that)
{    if (that == null)        return false;    if (that instanceof add_args)        return this.equals((add_args) that);    return false;}
0
public boolean equals(add_args that)
{    if (that == null)        return false;    boolean this_present_num1 = true;    boolean that_present_num1 = true;    if (this_present_num1 || that_present_num1) {        if (!(this_present_num1 && that_present_num1))            return false;        if (this.num1 != that.num1)            return false;    }    boolean this_present_num2 = true;    boolean that_present_num2 = true;    if (this_present_num2 || that_present_num2) {        if (!(this_present_num2 && that_present_num2))            return false;        return this.num2 == that.num2;    }    return true;}
0
public int hashCode()
{    return 0;}
0
public int compareTo(add_args other)
{    if (!getClass().equals(other.getClass())) {        return getClass().getName().compareTo(other.getClass().getName());    }    int lastComparison = 0;    lastComparison = Boolean.compare(isSetNum1(), other.isSetNum1());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetNum1()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.num1, other.num1);        if (lastComparison != 0) {            return lastComparison;        }    }    lastComparison = Boolean.compare(isSetNum2(), other.isSetNum2());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetNum2()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.num2, other.num2);        if (lastComparison != 0) {            return lastComparison;        }    }    return 0;}
0
public _Fields fieldForId(int fieldId)
{    return _Fields.findByThriftId(fieldId);}
0
public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException
{    schemes.get(iprot.getScheme()).getScheme().read(iprot, this);}
0
public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException
{    schemes.get(oprot.getScheme()).getScheme().write(oprot, this);}
0
public String toString()
{    StringBuilder sb = new StringBuilder("add_args(");    boolean first = true;    sb.append("num1:");    sb.append(this.num1);    first = false;    if (!first)        sb.append(", ");    sb.append("num2:");    sb.append(this.num2);    first = false;    sb.append(")");    return sb.toString();}
0
public void validate() throws org.apache.thrift.TException
{}
0
private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException
{    try {        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
0
private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException
{    try {                        __isset_bitfield = 0;        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
0
public add_argsStandardScheme getScheme()
{    return new add_argsStandardScheme();}
0
public void read(org.apache.thrift.protocol.TProtocol iprot, add_args struct) throws org.apache.thrift.TException
{    org.apache.thrift.protocol.TField schemeField;    iprot.readStructBegin();    while (true) {        schemeField = iprot.readFieldBegin();        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) {            break;        }        switch(schemeField.id) {            case             1:                if (schemeField.type == org.apache.thrift.protocol.TType.I32) {                    struct.num1 = iprot.readI32();                    struct.setNum1IsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            case             2:                if (schemeField.type == org.apache.thrift.protocol.TType.I32) {                    struct.num2 = iprot.readI32();                    struct.setNum2IsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            default:                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);        }        iprot.readFieldEnd();    }    iprot.readStructEnd();    struct.validate();}
0
public void write(org.apache.thrift.protocol.TProtocol oprot, add_args struct) throws org.apache.thrift.TException
{    struct.validate();    oprot.writeStructBegin(STRUCT_DESC);    oprot.writeFieldBegin(NUM1_FIELD_DESC);    oprot.writeI32(struct.num1);    oprot.writeFieldEnd();    oprot.writeFieldBegin(NUM2_FIELD_DESC);    oprot.writeI32(struct.num2);    oprot.writeFieldEnd();    oprot.writeFieldStop();    oprot.writeStructEnd();}
0
public add_argsTupleScheme getScheme()
{    return new add_argsTupleScheme();}
0
public void write(org.apache.thrift.protocol.TProtocol prot, add_args struct) throws org.apache.thrift.TException
{    TTupleProtocol oprot = (TTupleProtocol) prot;    BitSet optionals = new BitSet();    if (struct.isSetNum1()) {        optionals.set(0);    }    if (struct.isSetNum2()) {        optionals.set(1);    }    oprot.writeBitSet(optionals, 2);    if (struct.isSetNum1()) {        oprot.writeI32(struct.num1);    }    if (struct.isSetNum2()) {        oprot.writeI32(struct.num2);    }}
0
public void read(org.apache.thrift.protocol.TProtocol prot, add_args struct) throws org.apache.thrift.TException
{    TTupleProtocol iprot = (TTupleProtocol) prot;    BitSet incoming = iprot.readBitSet(2);    if (incoming.get(0)) {        struct.num1 = iprot.readI32();        struct.setNum1IsSet(true);    }    if (incoming.get(1)) {        struct.num2 = iprot.readI32();        struct.setNum2IsSet(true);    }}
0
public static _Fields findByThriftId(int fieldId)
{    switch(fieldId) {        case         0:            return SUCCESS;        default:            return null;    }}
0
public static _Fields findByThriftIdOrThrow(int fieldId)
{    _Fields fields = findByThriftId(fieldId);    if (fields == null)        throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");    return fields;}
0
public static _Fields findByName(String name)
{    return byName.get(name);}
0
public short getThriftFieldId()
{    return _thriftId;}
0
public String getFieldName()
{    return _fieldName;}
0
public add_result deepCopy()
{    return new add_result(this);}
0
public void clear()
{    setSuccessIsSet(false);    this.success = 0;}
0
public int getSuccess()
{    return this.success;}
0
public void setSuccess(int success)
{    this.success = success;    setSuccessIsSet(true);}
0
public void unsetSuccess()
{    __isset_bitfield = EncodingUtils.clearBit(__isset_bitfield, __SUCCESS_ISSET_ID);}
0
public boolean isSetSuccess()
{    return EncodingUtils.testBit(__isset_bitfield, __SUCCESS_ISSET_ID);}
0
public void setSuccessIsSet(boolean value)
{    __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __SUCCESS_ISSET_ID, value);}
0
public void setFieldValue(_Fields field, Object value)
{    switch(field) {        case SUCCESS:            if (value == null) {                unsetSuccess();            } else {                setSuccess((Integer) value);            }            break;    }}
0
public Object getFieldValue(_Fields field)
{    switch(field) {        case SUCCESS:            return getSuccess();    }    throw new IllegalStateException();}
0
public boolean isSet(_Fields field)
{    if (field == null) {        throw new IllegalArgumentException();    }    switch(field) {        case SUCCESS:            return isSetSuccess();    }    throw new IllegalStateException();}
0
public boolean equals(Object that)
{    if (that == null)        return false;    if (that instanceof add_result)        return this.equals((add_result) that);    return false;}
0
public boolean equals(add_result that)
{    if (that == null)        return false;    boolean this_present_success = true;    boolean that_present_success = true;    if (this_present_success || that_present_success) {        if (!(this_present_success && that_present_success))            return false;        return this.success == that.success;    }    return true;}
0
public int hashCode()
{    return 0;}
0
public int compareTo(add_result other)
{    if (!getClass().equals(other.getClass())) {        return getClass().getName().compareTo(other.getClass().getName());    }    int lastComparison = 0;    lastComparison = Boolean.compare(isSetSuccess(), other.isSetSuccess());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetSuccess()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.success, other.success);        if (lastComparison != 0) {            return lastComparison;        }    }    return 0;}
0
public _Fields fieldForId(int fieldId)
{    return _Fields.findByThriftId(fieldId);}
0
public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException
{    schemes.get(iprot.getScheme()).getScheme().read(iprot, this);}
0
public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException
{    schemes.get(oprot.getScheme()).getScheme().write(oprot, this);}
0
public String toString()
{    StringBuilder sb = new StringBuilder("add_result(");    boolean first = true;    sb.append("success:");    sb.append(this.success);    first = false;    sb.append(")");    return sb.toString();}
0
public void validate() throws org.apache.thrift.TException
{}
0
private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException
{    try {        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
0
private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException
{    try {                        __isset_bitfield = 0;        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
0
public add_resultStandardScheme getScheme()
{    return new add_resultStandardScheme();}
0
public void read(org.apache.thrift.protocol.TProtocol iprot, add_result struct) throws org.apache.thrift.TException
{    org.apache.thrift.protocol.TField schemeField;    iprot.readStructBegin();    while (true) {        schemeField = iprot.readFieldBegin();        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) {            break;        }        switch(schemeField.id) {            case             0:                if (schemeField.type == org.apache.thrift.protocol.TType.I32) {                    struct.success = iprot.readI32();                    struct.setSuccessIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            default:                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);        }        iprot.readFieldEnd();    }    iprot.readStructEnd();    struct.validate();}
0
public void write(org.apache.thrift.protocol.TProtocol oprot, add_result struct) throws org.apache.thrift.TException
{    struct.validate();    oprot.writeStructBegin(STRUCT_DESC);    if (struct.isSetSuccess()) {        oprot.writeFieldBegin(SUCCESS_FIELD_DESC);        oprot.writeI32(struct.success);        oprot.writeFieldEnd();    }    oprot.writeFieldStop();    oprot.writeStructEnd();}
0
public add_resultTupleScheme getScheme()
{    return new add_resultTupleScheme();}
0
public void write(org.apache.thrift.protocol.TProtocol prot, add_result struct) throws org.apache.thrift.TException
{    TTupleProtocol oprot = (TTupleProtocol) prot;    BitSet optionals = new BitSet();    if (struct.isSetSuccess()) {        optionals.set(0);    }    oprot.writeBitSet(optionals, 1);    if (struct.isSetSuccess()) {        oprot.writeI32(struct.success);    }}
0
public void read(org.apache.thrift.protocol.TProtocol prot, add_result struct) throws org.apache.thrift.TException
{    TTupleProtocol iprot = (TTupleProtocol) prot;    BitSet incoming = iprot.readBitSet(1);    if (incoming.get(0)) {        struct.success = iprot.readI32();        struct.setSuccessIsSet(true);    }}
0
public static _Fields findByThriftId(int fieldId)
{    switch(fieldId) {        default:            return null;    }}
0
public static _Fields findByThriftIdOrThrow(int fieldId)
{    _Fields fields = findByThriftId(fieldId);    if (fields == null)        throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");    return fields;}
0
public static _Fields findByName(String name)
{    return byName.get(name);}
0
public short getThriftFieldId()
{    return _thriftId;}
0
public String getFieldName()
{    return _fieldName;}
0
public zip_args deepCopy()
{    return new zip_args(this);}
0
public void clear()
{}
0
public void setFieldValue(_Fields field, Object value)
{    switch(field) {    }}
0
public Object getFieldValue(_Fields field)
{    switch(field) {    }    throw new IllegalStateException();}
0
public boolean isSet(_Fields field)
{    if (field == null) {        throw new IllegalArgumentException();    }    switch(field) {    }    throw new IllegalStateException();}
0
public boolean equals(Object that)
{    if (that == null)        return false;    if (that instanceof zip_args)        return this.equals((zip_args) that);    return false;}
0
public boolean equals(zip_args that)
{    return that != null;}
0
public int hashCode()
{    return 0;}
0
public int compareTo(zip_args other)
{    if (!getClass().equals(other.getClass())) {        return getClass().getName().compareTo(other.getClass().getName());    }    int lastComparison = 0;    return 0;}
0
public _Fields fieldForId(int fieldId)
{    return _Fields.findByThriftId(fieldId);}
0
public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException
{    schemes.get(iprot.getScheme()).getScheme().read(iprot, this);}
0
public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException
{    schemes.get(oprot.getScheme()).getScheme().write(oprot, this);}
0
public String toString()
{    boolean first = true;    return "zip_args(" + ")";}
0
public void validate() throws org.apache.thrift.TException
{}
0
private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException
{    try {        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
0
private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException
{    try {        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
0
public zip_argsStandardScheme getScheme()
{    return new zip_argsStandardScheme();}
0
public void read(org.apache.thrift.protocol.TProtocol iprot, zip_args struct) throws org.apache.thrift.TException
{    org.apache.thrift.protocol.TField schemeField;    iprot.readStructBegin();    while (true) {        schemeField = iprot.readFieldBegin();        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) {            break;        }        switch(schemeField.id) {            default:                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);        }        iprot.readFieldEnd();    }    iprot.readStructEnd();    struct.validate();}
0
public void write(org.apache.thrift.protocol.TProtocol oprot, zip_args struct) throws org.apache.thrift.TException
{    struct.validate();    oprot.writeStructBegin(STRUCT_DESC);    oprot.writeFieldStop();    oprot.writeStructEnd();}
0
public zip_argsTupleScheme getScheme()
{    return new zip_argsTupleScheme();}
0
public void write(org.apache.thrift.protocol.TProtocol prot, zip_args struct) throws org.apache.thrift.TException
{    TTupleProtocol oprot = (TTupleProtocol) prot;}
0
public void read(org.apache.thrift.protocol.TProtocol prot, zip_args struct) throws org.apache.thrift.TException
{    TTupleProtocol iprot = (TTupleProtocol) prot;}
0
public static _Fields findByThriftId(int fieldId)
{    switch(fieldId) {        case         1:            return FOO;        case         2:            return BAR;        default:            return null;    }}
0
public static _Fields findByThriftIdOrThrow(int fieldId)
{    _Fields fields = findByThriftId(fieldId);    if (fields == null)        throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");    return fields;}
0
public static _Fields findByName(String name)
{    return byName.get(name);}
0
public short getThriftFieldId()
{    return _thriftId;}
0
public String getFieldName()
{    return _fieldName;}
0
public FooOrBar deepCopy()
{    return new FooOrBar(this);}
0
public static FooOrBar foo(String value)
{    FooOrBar x = new FooOrBar();    x.setFoo(value);    return x;}
0
public static FooOrBar bar(String value)
{    FooOrBar x = new FooOrBar();    x.setBar(value);    return x;}
0
protected void checkType(_Fields setField, Object value) throws ClassCastException
{    switch(setField) {        case FOO:            if (value instanceof String) {                break;            }            throw new ClassCastException("Was expecting value of type String for field 'foo', but got " + value.getClass().getSimpleName());        case BAR:            if (value instanceof String) {                break;            }            throw new ClassCastException("Was expecting value of type String for field 'bar', but got " + value.getClass().getSimpleName());        default:            throw new IllegalArgumentException("Unknown field id " + setField);    }}
0
protected Object standardSchemeReadValue(org.apache.thrift.protocol.TProtocol iprot, org.apache.thrift.protocol.TField field) throws org.apache.thrift.TException
{    _Fields setField = _Fields.findByThriftId(field.id);    if (setField != null) {        switch(setField) {            case FOO:                if (field.type == FOO_FIELD_DESC.type) {                    String foo;                    foo = iprot.readString();                    return foo;                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, field.type);                    return null;                }            case BAR:                if (field.type == BAR_FIELD_DESC.type) {                    String bar;                    bar = iprot.readString();                    return bar;                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, field.type);                    return null;                }            default:                throw new IllegalStateException("setField wasn't null, but didn't match any of the case statements!");        }    } else {        org.apache.thrift.protocol.TProtocolUtil.skip(iprot, field.type);        return null;    }}
0
protected void standardSchemeWriteValue(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException
{    switch(setField_) {        case FOO:            String foo = (String) value_;            oprot.writeString(foo);            return;        case BAR:            String bar = (String) value_;            oprot.writeString(bar);            return;        default:            throw new IllegalStateException("Cannot write union with unknown field " + setField_);    }}
0
protected Object tupleSchemeReadValue(org.apache.thrift.protocol.TProtocol iprot, short fieldID) throws org.apache.thrift.TException
{    _Fields setField = _Fields.findByThriftId(fieldID);    if (setField != null) {        switch(setField) {            case FOO:                String foo;                foo = iprot.readString();                return foo;            case BAR:                String bar;                bar = iprot.readString();                return bar;            default:                throw new IllegalStateException("setField wasn't null, but didn't match any of the case statements!");        }    } else {        throw new TProtocolException("Couldn't find a field with field id " + fieldID);    }}
0
protected void tupleSchemeWriteValue(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException
{    switch(setField_) {        case FOO:            String foo = (String) value_;            oprot.writeString(foo);            return;        case BAR:            String bar = (String) value_;            oprot.writeString(bar);            return;        default:            throw new IllegalStateException("Cannot write union with unknown field " + setField_);    }}
0
protected org.apache.thrift.protocol.TField getFieldDesc(_Fields setField)
{    switch(setField) {        case FOO:            return FOO_FIELD_DESC;        case BAR:            return BAR_FIELD_DESC;        default:            throw new IllegalArgumentException("Unknown field id " + setField);    }}
0
protected org.apache.thrift.protocol.TStruct getStructDesc()
{    return STRUCT_DESC;}
0
protected _Fields enumForId(short id)
{    return _Fields.findByThriftIdOrThrow(id);}
0
public _Fields fieldForId(int fieldId)
{    return _Fields.findByThriftId(fieldId);}
0
public String getFoo()
{    if (getSetField() == _Fields.FOO) {        return (String) getFieldValue();    } else {        throw new RuntimeException("Cannot get field 'foo' because union is currently set to " + getFieldDesc(getSetField()).name);    }}
0
public void setFoo(String value)
{    if (value == null)        throw new NullPointerException();    setField_ = _Fields.FOO;    value_ = value;}
0
public String getBar()
{    if (getSetField() == _Fields.BAR) {        return (String) getFieldValue();    } else {        throw new RuntimeException("Cannot get field 'bar' because union is currently set to " + getFieldDesc(getSetField()).name);    }}
0
public void setBar(String value)
{    if (value == null)        throw new NullPointerException();    setField_ = _Fields.BAR;    value_ = value;}
0
public boolean isSetFoo()
{    return setField_ == _Fields.FOO;}
0
public boolean isSetBar()
{    return setField_ == _Fields.BAR;}
0
public boolean equals(Object other)
{    if (other instanceof FooOrBar) {        return equals((FooOrBar) other);    } else {        return false;    }}
0
public boolean equals(FooOrBar other)
{    return other != null && getSetField() == other.getSetField() && getFieldValue().equals(other.getFieldValue());}
0
public int compareTo(FooOrBar other)
{    int lastComparison = org.apache.thrift.TBaseHelper.compareTo(getSetField(), other.getSetField());    if (lastComparison == 0) {        return org.apache.thrift.TBaseHelper.compareTo(getFieldValue(), other.getFieldValue());    }    return lastComparison;}
0
public int hashCode()
{    return 0;}
0
private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException
{    try {        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
0
private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException
{    try {        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
0
public static _Fields findByThriftId(int fieldId)
{    switch(fieldId) {        case         1:            return X;        default:            return null;    }}
0
public static _Fields findByThriftIdOrThrow(int fieldId)
{    _Fields fields = findByThriftId(fieldId);    if (fields == null)        throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");    return fields;}
0
public static _Fields findByName(String name)
{    return byName.get(name);}
0
public short getThriftFieldId()
{    return _thriftId;}
0
public String getFieldName()
{    return _fieldName;}
0
public Nested deepCopy()
{    return new Nested(this);}
0
public void clear()
{    setXIsSet(false);    this.x = 0;}
0
public int getX()
{    return this.x;}
0
public void setX(int x)
{    this.x = x;    setXIsSet(true);}
0
public void unsetX()
{    __isset_bitfield = EncodingUtils.clearBit(__isset_bitfield, __X_ISSET_ID);}
0
public boolean isSetX()
{    return EncodingUtils.testBit(__isset_bitfield, __X_ISSET_ID);}
0
public void setXIsSet(boolean value)
{    __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __X_ISSET_ID, value);}
0
public void setFieldValue(_Fields field, Object value)
{    switch(field) {        case X:            if (value == null) {                unsetX();            } else {                setX((Integer) value);            }            break;    }}
0
public Object getFieldValue(_Fields field)
{    switch(field) {        case X:            return getX();    }    throw new IllegalStateException();}
0
public boolean isSet(_Fields field)
{    if (field == null) {        throw new IllegalArgumentException();    }    switch(field) {        case X:            return isSetX();    }    throw new IllegalStateException();}
0
public boolean equals(Object that)
{    if (that == null)        return false;    if (that instanceof Nested)        return this.equals((Nested) that);    return false;}
0
public boolean equals(Nested that)
{    if (that == null)        return false;    boolean this_present_x = true;    boolean that_present_x = true;    if (this_present_x || that_present_x) {        if (!(this_present_x && that_present_x))            return false;        return this.x == that.x;    }    return true;}
0
public int hashCode()
{    return 0;}
0
public int compareTo(Nested other)
{    if (!getClass().equals(other.getClass())) {        return getClass().getName().compareTo(other.getClass().getName());    }    int lastComparison = 0;    lastComparison = Boolean.compare(isSetX(), other.isSetX());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetX()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.x, other.x);        if (lastComparison != 0) {            return lastComparison;        }    }    return 0;}
0
public _Fields fieldForId(int fieldId)
{    return _Fields.findByThriftId(fieldId);}
0
public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException
{    schemes.get(iprot.getScheme()).getScheme().read(iprot, this);}
0
public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException
{    schemes.get(oprot.getScheme()).getScheme().write(oprot, this);}
0
public String toString()
{    StringBuilder sb = new StringBuilder("Nested(");    boolean first = true;    sb.append("x:");    sb.append(this.x);    first = false;    sb.append(")");    return sb.toString();}
0
public void validate() throws org.apache.thrift.TException
{}
0
private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException
{    try {        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
0
private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException
{    try {                        __isset_bitfield = 0;        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
0
public NestedStandardScheme getScheme()
{    return new NestedStandardScheme();}
0
public void read(org.apache.thrift.protocol.TProtocol iprot, Nested struct) throws org.apache.thrift.TException
{    org.apache.thrift.protocol.TField schemeField;    iprot.readStructBegin();    while (true) {        schemeField = iprot.readFieldBegin();        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) {            break;        }        switch(schemeField.id) {            case             1:                if (schemeField.type == org.apache.thrift.protocol.TType.I32) {                    struct.x = iprot.readI32();                    struct.setXIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            default:                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);        }        iprot.readFieldEnd();    }    iprot.readStructEnd();    struct.validate();}
0
public void write(org.apache.thrift.protocol.TProtocol oprot, Nested struct) throws org.apache.thrift.TException
{    struct.validate();    oprot.writeStructBegin(STRUCT_DESC);    oprot.writeFieldBegin(X_FIELD_DESC);    oprot.writeI32(struct.x);    oprot.writeFieldEnd();    oprot.writeFieldStop();    oprot.writeStructEnd();}
0
public NestedTupleScheme getScheme()
{    return new NestedTupleScheme();}
0
public void write(org.apache.thrift.protocol.TProtocol prot, Nested struct) throws org.apache.thrift.TException
{    TTupleProtocol oprot = (TTupleProtocol) prot;    BitSet optionals = new BitSet();    if (struct.isSetX()) {        optionals.set(0);    }    oprot.writeBitSet(optionals, 1);    if (struct.isSetX()) {        oprot.writeI32(struct.x);    }}
0
public void read(org.apache.thrift.protocol.TProtocol prot, Nested struct) throws org.apache.thrift.TException
{    TTupleProtocol iprot = (TTupleProtocol) prot;    BitSet incoming = iprot.readBitSet(1);    if (incoming.get(0)) {        struct.x = iprot.readI32();        struct.setXIsSet(true);    }}
0
public static _Fields findByThriftId(int fieldId)
{    switch(fieldId) {        case         1:            return BOOL_FIELD;        case         2:            return BYTE_FIELD;        case         16:            return BYTE_OPTIONAL_FIELD;        case         3:            return I16_FIELD;        case         15:            return I16_OPTIONAL_FIELD;        case         4:            return I32_FIELD;        case         5:            return I64_FIELD;        case         6:            return DOUBLE_FIELD;        case         7:            return STRING_FIELD;        case         8:            return BINARY_FIELD;        case         9:            return MAP_FIELD;        case         10:            return LIST_FIELD;        case         11:            return SET_FIELD;        case         12:            return ENUM_FIELD;        case         13:            return STRUCT_FIELD;        case         14:            return FOO_OR_BAR;        default:            return null;    }}
0
public static _Fields findByThriftIdOrThrow(int fieldId)
{    _Fields fields = findByThriftId(fieldId);    if (fields == null)        throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");    return fields;}
0
public static _Fields findByName(String name)
{    return byName.get(name);}
0
public short getThriftFieldId()
{    return _thriftId;}
0
public String getFieldName()
{    return _fieldName;}
0
public Test deepCopy()
{    return new Test(this);}
0
public void clear()
{    setBoolFieldIsSet(false);    this.boolField = false;    setByteFieldIsSet(false);    this.byteField = 0;    setByteOptionalFieldIsSet(false);    this.byteOptionalField = 0;    setI16FieldIsSet(false);    this.i16Field = 0;    setI16OptionalFieldIsSet(false);    this.i16OptionalField = 0;    setI32FieldIsSet(false);    this.i32Field = 0;    setI64FieldIsSet(false);    this.i64Field = 0;    setDoubleFieldIsSet(false);    this.doubleField = 0.0;    this.stringField = null;    this.binaryField = null;    this.mapField = null;    this.listField = null;    this.setField = null;    this.enumField = null;    this.structField = null;    this.fooOrBar = null;}
0
public boolean isBoolField()
{    return this.boolField;}
0
public void setBoolField(boolean boolField)
{    this.boolField = boolField;    setBoolFieldIsSet(true);}
0
public void unsetBoolField()
{    __isset_bitfield = EncodingUtils.clearBit(__isset_bitfield, __BOOLFIELD_ISSET_ID);}
0
public boolean isSetBoolField()
{    return EncodingUtils.testBit(__isset_bitfield, __BOOLFIELD_ISSET_ID);}
0
public void setBoolFieldIsSet(boolean value)
{    __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __BOOLFIELD_ISSET_ID, value);}
0
public byte getByteField()
{    return this.byteField;}
0
public void setByteField(byte byteField)
{    this.byteField = byteField;    setByteFieldIsSet(true);}
0
public void unsetByteField()
{    __isset_bitfield = EncodingUtils.clearBit(__isset_bitfield, __BYTEFIELD_ISSET_ID);}
0
public boolean isSetByteField()
{    return EncodingUtils.testBit(__isset_bitfield, __BYTEFIELD_ISSET_ID);}
0
public void setByteFieldIsSet(boolean value)
{    __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __BYTEFIELD_ISSET_ID, value);}
0
public byte getByteOptionalField()
{    return this.byteOptionalField;}
0
public void setByteOptionalField(byte byteOptionalField)
{    this.byteOptionalField = byteOptionalField;    setByteOptionalFieldIsSet(true);}
0
public void unsetByteOptionalField()
{    __isset_bitfield = EncodingUtils.clearBit(__isset_bitfield, __BYTEOPTIONALFIELD_ISSET_ID);}
0
public boolean isSetByteOptionalField()
{    return EncodingUtils.testBit(__isset_bitfield, __BYTEOPTIONALFIELD_ISSET_ID);}
0
public void setByteOptionalFieldIsSet(boolean value)
{    __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __BYTEOPTIONALFIELD_ISSET_ID, value);}
0
public short getI16Field()
{    return this.i16Field;}
0
public void setI16Field(short i16Field)
{    this.i16Field = i16Field;    setI16FieldIsSet(true);}
0
public void unsetI16Field()
{    __isset_bitfield = EncodingUtils.clearBit(__isset_bitfield, __I16FIELD_ISSET_ID);}
0
public boolean isSetI16Field()
{    return EncodingUtils.testBit(__isset_bitfield, __I16FIELD_ISSET_ID);}
0
public void setI16FieldIsSet(boolean value)
{    __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __I16FIELD_ISSET_ID, value);}
0
public short getI16OptionalField()
{    return this.i16OptionalField;}
0
public void setI16OptionalField(short i16OptionalField)
{    this.i16OptionalField = i16OptionalField;    setI16OptionalFieldIsSet(true);}
0
public void unsetI16OptionalField()
{    __isset_bitfield = EncodingUtils.clearBit(__isset_bitfield, __I16OPTIONALFIELD_ISSET_ID);}
0
public boolean isSetI16OptionalField()
{    return EncodingUtils.testBit(__isset_bitfield, __I16OPTIONALFIELD_ISSET_ID);}
0
public void setI16OptionalFieldIsSet(boolean value)
{    __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __I16OPTIONALFIELD_ISSET_ID, value);}
0
public int getI32Field()
{    return this.i32Field;}
0
public void setI32Field(int i32Field)
{    this.i32Field = i32Field;    setI32FieldIsSet(true);}
0
public void unsetI32Field()
{    __isset_bitfield = EncodingUtils.clearBit(__isset_bitfield, __I32FIELD_ISSET_ID);}
0
public boolean isSetI32Field()
{    return EncodingUtils.testBit(__isset_bitfield, __I32FIELD_ISSET_ID);}
0
public void setI32FieldIsSet(boolean value)
{    __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __I32FIELD_ISSET_ID, value);}
0
public long getI64Field()
{    return this.i64Field;}
0
public void setI64Field(long i64Field)
{    this.i64Field = i64Field;    setI64FieldIsSet(true);}
0
public void unsetI64Field()
{    __isset_bitfield = EncodingUtils.clearBit(__isset_bitfield, __I64FIELD_ISSET_ID);}
0
public boolean isSetI64Field()
{    return EncodingUtils.testBit(__isset_bitfield, __I64FIELD_ISSET_ID);}
0
public void setI64FieldIsSet(boolean value)
{    __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __I64FIELD_ISSET_ID, value);}
0
public double getDoubleField()
{    return this.doubleField;}
0
public void setDoubleField(double doubleField)
{    this.doubleField = doubleField;    setDoubleFieldIsSet(true);}
0
public void unsetDoubleField()
{    __isset_bitfield = EncodingUtils.clearBit(__isset_bitfield, __DOUBLEFIELD_ISSET_ID);}
0
public boolean isSetDoubleField()
{    return EncodingUtils.testBit(__isset_bitfield, __DOUBLEFIELD_ISSET_ID);}
0
public void setDoubleFieldIsSet(boolean value)
{    __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __DOUBLEFIELD_ISSET_ID, value);}
0
public String getStringField()
{    return this.stringField;}
0
public void setStringField(String stringField)
{    this.stringField = stringField;}
0
public void unsetStringField()
{    this.stringField = null;}
0
public boolean isSetStringField()
{    return this.stringField != null;}
0
public void setStringFieldIsSet(boolean value)
{    if (!value) {        this.stringField = null;    }}
0
public byte[] getBinaryField()
{    setBinaryField(org.apache.thrift.TBaseHelper.rightSize(binaryField));    return binaryField == null ? null : binaryField.array();}
0
public ByteBuffer bufferForBinaryField()
{    return binaryField;}
0
public void setBinaryField(byte[] binaryField)
{    setBinaryField(binaryField == null ? null : ByteBuffer.wrap(binaryField));}
0
public void setBinaryField(ByteBuffer binaryField)
{    this.binaryField = binaryField;}
0
public void unsetBinaryField()
{    this.binaryField = null;}
0
public boolean isSetBinaryField()
{    return this.binaryField != null;}
0
public void setBinaryFieldIsSet(boolean value)
{    if (!value) {        this.binaryField = null;    }}
0
public int getMapFieldSize()
{    return (this.mapField == null) ? 0 : this.mapField.size();}
0
public void putToMapField(String key, int val)
{    if (this.mapField == null) {        this.mapField = new HashMap<>();    }    this.mapField.put(key, val);}
0
public Map<String, Integer> getMapField()
{    return this.mapField;}
0
public void setMapField(Map<String, Integer> mapField)
{    this.mapField = mapField;}
0
public void unsetMapField()
{    this.mapField = null;}
0
public boolean isSetMapField()
{    return this.mapField != null;}
0
public void setMapFieldIsSet(boolean value)
{    if (!value) {        this.mapField = null;    }}
0
public int getListFieldSize()
{    return (this.listField == null) ? 0 : this.listField.size();}
0
public java.util.Iterator<Integer> getListFieldIterator()
{    return (this.listField == null) ? null : this.listField.iterator();}
0
public void addToListField(int elem)
{    if (this.listField == null) {        this.listField = new ArrayList<>();    }    this.listField.add(elem);}
0
public List<Integer> getListField()
{    return this.listField;}
0
public void setListField(List<Integer> listField)
{    this.listField = listField;}
0
public void unsetListField()
{    this.listField = null;}
0
public boolean isSetListField()
{    return this.listField != null;}
0
public void setListFieldIsSet(boolean value)
{    if (!value) {        this.listField = null;    }}
0
public int getSetFieldSize()
{    return (this.setField == null) ? 0 : this.setField.size();}
0
public java.util.Iterator<Integer> getSetFieldIterator()
{    return (this.setField == null) ? null : this.setField.iterator();}
0
public void addToSetField(int elem)
{    if (this.setField == null) {        this.setField = new HashSet<>();    }    this.setField.add(elem);}
0
public Set<Integer> getSetField()
{    return this.setField;}
0
public void setSetField(Set<Integer> setField)
{    this.setField = setField;}
0
public void unsetSetField()
{    this.setField = null;}
0
public boolean isSetSetField()
{    return this.setField != null;}
0
public void setSetFieldIsSet(boolean value)
{    if (!value) {        this.setField = null;    }}
0
public E getEnumField()
{    return this.enumField;}
0
public void setEnumField(E enumField)
{    this.enumField = enumField;}
0
public void unsetEnumField()
{    this.enumField = null;}
0
public boolean isSetEnumField()
{    return this.enumField != null;}
0
public void setEnumFieldIsSet(boolean value)
{    if (!value) {        this.enumField = null;    }}
0
public Nested getStructField()
{    return this.structField;}
0
public void setStructField(Nested structField)
{    this.structField = structField;}
0
public void unsetStructField()
{    this.structField = null;}
0
public boolean isSetStructField()
{    return this.structField != null;}
0
public void setStructFieldIsSet(boolean value)
{    if (!value) {        this.structField = null;    }}
0
public FooOrBar getFooOrBar()
{    return this.fooOrBar;}
0
public void setFooOrBar(FooOrBar fooOrBar)
{    this.fooOrBar = fooOrBar;}
0
public void unsetFooOrBar()
{    this.fooOrBar = null;}
0
public boolean isSetFooOrBar()
{    return this.fooOrBar != null;}
0
public void setFooOrBarIsSet(boolean value)
{    if (!value) {        this.fooOrBar = null;    }}
0
public void setFieldValue(_Fields field, Object value)
{    switch(field) {        case BOOL_FIELD:            if (value == null) {                unsetBoolField();            } else {                setBoolField((Boolean) value);            }            break;        case BYTE_FIELD:            if (value == null) {                unsetByteField();            } else {                setByteField((Byte) value);            }            break;        case BYTE_OPTIONAL_FIELD:            if (value == null) {                unsetByteOptionalField();            } else {                setByteOptionalField((Byte) value);            }            break;        case I16_FIELD:            if (value == null) {                unsetI16Field();            } else {                setI16Field((Short) value);            }            break;        case I16_OPTIONAL_FIELD:            if (value == null) {                unsetI16OptionalField();            } else {                setI16OptionalField((Short) value);            }            break;        case I32_FIELD:            if (value == null) {                unsetI32Field();            } else {                setI32Field((Integer) value);            }            break;        case I64_FIELD:            if (value == null) {                unsetI64Field();            } else {                setI64Field((Long) value);            }            break;        case DOUBLE_FIELD:            if (value == null) {                unsetDoubleField();            } else {                setDoubleField((Double) value);            }            break;        case STRING_FIELD:            if (value == null) {                unsetStringField();            } else {                setStringField((String) value);            }            break;        case BINARY_FIELD:            if (value == null) {                unsetBinaryField();            } else {                setBinaryField((ByteBuffer) value);            }            break;        case MAP_FIELD:            if (value == null) {                unsetMapField();            } else {                setMapField((Map<String, Integer>) value);            }            break;        case LIST_FIELD:            if (value == null) {                unsetListField();            } else {                setListField((List<Integer>) value);            }            break;        case SET_FIELD:            if (value == null) {                unsetSetField();            } else {                setSetField((Set<Integer>) value);            }            break;        case ENUM_FIELD:            if (value == null) {                unsetEnumField();            } else {                setEnumField((E) value);            }            break;        case STRUCT_FIELD:            if (value == null) {                unsetStructField();            } else {                setStructField((Nested) value);            }            break;        case FOO_OR_BAR:            if (value == null) {                unsetFooOrBar();            } else {                setFooOrBar((FooOrBar) value);            }            break;    }}
0
public Object getFieldValue(_Fields field)
{    switch(field) {        case BOOL_FIELD:            return isBoolField();        case BYTE_FIELD:            return getByteField();        case BYTE_OPTIONAL_FIELD:            return getByteOptionalField();        case I16_FIELD:            return getI16Field();        case I16_OPTIONAL_FIELD:            return getI16OptionalField();        case I32_FIELD:            return getI32Field();        case I64_FIELD:            return getI64Field();        case DOUBLE_FIELD:            return getDoubleField();        case STRING_FIELD:            return getStringField();        case BINARY_FIELD:            return getBinaryField();        case MAP_FIELD:            return getMapField();        case LIST_FIELD:            return getListField();        case SET_FIELD:            return getSetField();        case ENUM_FIELD:            return getEnumField();        case STRUCT_FIELD:            return getStructField();        case FOO_OR_BAR:            return getFooOrBar();    }    throw new IllegalStateException();}
0
public boolean isSet(_Fields field)
{    if (field == null) {        throw new IllegalArgumentException();    }    switch(field) {        case BOOL_FIELD:            return isSetBoolField();        case BYTE_FIELD:            return isSetByteField();        case BYTE_OPTIONAL_FIELD:            return isSetByteOptionalField();        case I16_FIELD:            return isSetI16Field();        case I16_OPTIONAL_FIELD:            return isSetI16OptionalField();        case I32_FIELD:            return isSetI32Field();        case I64_FIELD:            return isSetI64Field();        case DOUBLE_FIELD:            return isSetDoubleField();        case STRING_FIELD:            return isSetStringField();        case BINARY_FIELD:            return isSetBinaryField();        case MAP_FIELD:            return isSetMapField();        case LIST_FIELD:            return isSetListField();        case SET_FIELD:            return isSetSetField();        case ENUM_FIELD:            return isSetEnumField();        case STRUCT_FIELD:            return isSetStructField();        case FOO_OR_BAR:            return isSetFooOrBar();    }    throw new IllegalStateException();}
0
public boolean equals(Object that)
{    if (that == null)        return false;    if (that instanceof Test)        return this.equals((Test) that);    return false;}
0
public boolean equals(Test that)
{    if (that == null)        return false;    boolean this_present_boolField = true;    boolean that_present_boolField = true;    if (this_present_boolField || that_present_boolField) {        if (!(this_present_boolField && that_present_boolField))            return false;        if (this.boolField != that.boolField)            return false;    }    boolean this_present_byteField = true;    boolean that_present_byteField = true;    if (this_present_byteField || that_present_byteField) {        if (!(this_present_byteField && that_present_byteField))            return false;        if (this.byteField != that.byteField)            return false;    }    boolean this_present_byteOptionalField = true && this.isSetByteOptionalField();    boolean that_present_byteOptionalField = true && that.isSetByteOptionalField();    if (this_present_byteOptionalField || that_present_byteOptionalField) {        if (!(this_present_byteOptionalField && that_present_byteOptionalField))            return false;        if (this.byteOptionalField != that.byteOptionalField)            return false;    }    boolean this_present_i16Field = true;    boolean that_present_i16Field = true;    if (this_present_i16Field || that_present_i16Field) {        if (!(this_present_i16Field && that_present_i16Field))            return false;        if (this.i16Field != that.i16Field)            return false;    }    boolean this_present_i16OptionalField = true && this.isSetI16OptionalField();    boolean that_present_i16OptionalField = true && that.isSetI16OptionalField();    if (this_present_i16OptionalField || that_present_i16OptionalField) {        if (!(this_present_i16OptionalField && that_present_i16OptionalField))            return false;        if (this.i16OptionalField != that.i16OptionalField)            return false;    }    boolean this_present_i32Field = true && this.isSetI32Field();    boolean that_present_i32Field = true && that.isSetI32Field();    if (this_present_i32Field || that_present_i32Field) {        if (!(this_present_i32Field && that_present_i32Field))            return false;        if (this.i32Field != that.i32Field)            return false;    }    boolean this_present_i64Field = true;    boolean that_present_i64Field = true;    if (this_present_i64Field || that_present_i64Field) {        if (!(this_present_i64Field && that_present_i64Field))            return false;        if (this.i64Field != that.i64Field)            return false;    }    boolean this_present_doubleField = true;    boolean that_present_doubleField = true;    if (this_present_doubleField || that_present_doubleField) {        if (!(this_present_doubleField && that_present_doubleField))            return false;        if (this.doubleField != that.doubleField)            return false;    }    boolean this_present_stringField = true && this.isSetStringField();    boolean that_present_stringField = true && that.isSetStringField();    if (this_present_stringField || that_present_stringField) {        if (!(this_present_stringField && that_present_stringField))            return false;        if (!this.stringField.equals(that.stringField))            return false;    }    boolean this_present_binaryField = true && this.isSetBinaryField();    boolean that_present_binaryField = true && that.isSetBinaryField();    if (this_present_binaryField || that_present_binaryField) {        if (!(this_present_binaryField && that_present_binaryField))            return false;        if (!this.binaryField.equals(that.binaryField))            return false;    }    boolean this_present_mapField = true && this.isSetMapField();    boolean that_present_mapField = true && that.isSetMapField();    if (this_present_mapField || that_present_mapField) {        if (!(this_present_mapField && that_present_mapField))            return false;        if (!this.mapField.equals(that.mapField))            return false;    }    boolean this_present_listField = true && this.isSetListField();    boolean that_present_listField = true && that.isSetListField();    if (this_present_listField || that_present_listField) {        if (!(this_present_listField && that_present_listField))            return false;        if (!this.listField.equals(that.listField))            return false;    }    boolean this_present_setField = true && this.isSetSetField();    boolean that_present_setField = true && that.isSetSetField();    if (this_present_setField || that_present_setField) {        if (!(this_present_setField && that_present_setField))            return false;        if (!this.setField.equals(that.setField))            return false;    }    boolean this_present_enumField = true && this.isSetEnumField();    boolean that_present_enumField = true && that.isSetEnumField();    if (this_present_enumField || that_present_enumField) {        if (!(this_present_enumField && that_present_enumField))            return false;        if (!this.enumField.equals(that.enumField))            return false;    }    boolean this_present_structField = true && this.isSetStructField();    boolean that_present_structField = true && that.isSetStructField();    if (this_present_structField || that_present_structField) {        if (!(this_present_structField && that_present_structField))            return false;        if (!this.structField.equals(that.structField))            return false;    }    boolean this_present_fooOrBar = true && this.isSetFooOrBar();    boolean that_present_fooOrBar = true && that.isSetFooOrBar();    if (this_present_fooOrBar || that_present_fooOrBar) {        if (!(this_present_fooOrBar && that_present_fooOrBar))            return false;        return this.fooOrBar.equals(that.fooOrBar);    }    return true;}
0
public int hashCode()
{    return 0;}
0
public int compareTo(Test other)
{    if (!getClass().equals(other.getClass())) {        return getClass().getName().compareTo(other.getClass().getName());    }    int lastComparison = 0;    lastComparison = Boolean.compare(isSetBoolField(), other.isSetBoolField());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetBoolField()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.boolField, other.boolField);        if (lastComparison != 0) {            return lastComparison;        }    }    lastComparison = Boolean.compare(isSetByteField(), other.isSetByteField());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetByteField()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.byteField, other.byteField);        if (lastComparison != 0) {            return lastComparison;        }    }    lastComparison = Boolean.compare(isSetByteOptionalField(), other.isSetByteOptionalField());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetByteOptionalField()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.byteOptionalField, other.byteOptionalField);        if (lastComparison != 0) {            return lastComparison;        }    }    lastComparison = Boolean.compare(isSetI16Field(), other.isSetI16Field());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetI16Field()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.i16Field, other.i16Field);        if (lastComparison != 0) {            return lastComparison;        }    }    lastComparison = Boolean.compare(isSetI16OptionalField(), other.isSetI16OptionalField());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetI16OptionalField()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.i16OptionalField, other.i16OptionalField);        if (lastComparison != 0) {            return lastComparison;        }    }    lastComparison = Boolean.compare(isSetI32Field(), other.isSetI32Field());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetI32Field()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.i32Field, other.i32Field);        if (lastComparison != 0) {            return lastComparison;        }    }    lastComparison = Boolean.compare(isSetI64Field(), other.isSetI64Field());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetI64Field()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.i64Field, other.i64Field);        if (lastComparison != 0) {            return lastComparison;        }    }    lastComparison = Boolean.compare(isSetDoubleField(), other.isSetDoubleField());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetDoubleField()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.doubleField, other.doubleField);        if (lastComparison != 0) {            return lastComparison;        }    }    lastComparison = Boolean.compare(isSetStringField(), other.isSetStringField());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetStringField()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.stringField, other.stringField);        if (lastComparison != 0) {            return lastComparison;        }    }    lastComparison = Boolean.compare(isSetBinaryField(), other.isSetBinaryField());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetBinaryField()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.binaryField, other.binaryField);        if (lastComparison != 0) {            return lastComparison;        }    }    lastComparison = Boolean.compare(isSetMapField(), other.isSetMapField());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetMapField()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.mapField, other.mapField);        if (lastComparison != 0) {            return lastComparison;        }    }    lastComparison = Boolean.compare(isSetListField(), other.isSetListField());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetListField()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.listField, other.listField);        if (lastComparison != 0) {            return lastComparison;        }    }    lastComparison = Boolean.compare(isSetSetField(), other.isSetSetField());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetSetField()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.setField, other.setField);        if (lastComparison != 0) {            return lastComparison;        }    }    lastComparison = Boolean.compare(isSetEnumField(), other.isSetEnumField());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetEnumField()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.enumField, other.enumField);        if (lastComparison != 0) {            return lastComparison;        }    }    lastComparison = Boolean.compare(isSetStructField(), other.isSetStructField());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetStructField()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.structField, other.structField);        if (lastComparison != 0) {            return lastComparison;        }    }    lastComparison = Boolean.compare(isSetFooOrBar(), other.isSetFooOrBar());    if (lastComparison != 0) {        return lastComparison;    }    if (isSetFooOrBar()) {        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.fooOrBar, other.fooOrBar);        if (lastComparison != 0) {            return lastComparison;        }    }    return 0;}
0
public _Fields fieldForId(int fieldId)
{    return _Fields.findByThriftId(fieldId);}
0
public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException
{    schemes.get(iprot.getScheme()).getScheme().read(iprot, this);}
0
public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException
{    schemes.get(oprot.getScheme()).getScheme().write(oprot, this);}
0
public String toString()
{    StringBuilder sb = new StringBuilder("Test(");    boolean first = true;    sb.append("boolField:");    sb.append(this.boolField);    first = false;    if (!first)        sb.append(", ");    sb.append("byteField:");    sb.append(this.byteField);    first = false;    if (isSetByteOptionalField()) {        if (!first)            sb.append(", ");        sb.append("byteOptionalField:");        sb.append(this.byteOptionalField);        first = false;    }    if (!first)        sb.append(", ");    sb.append("i16Field:");    sb.append(this.i16Field);    first = false;    if (isSetI16OptionalField()) {        if (!first)            sb.append(", ");        sb.append("i16OptionalField:");        sb.append(this.i16OptionalField);        first = false;    }    if (isSetI32Field()) {        if (!first)            sb.append(", ");        sb.append("i32Field:");        sb.append(this.i32Field);        first = false;    }    if (!first)        sb.append(", ");    sb.append("i64Field:");    sb.append(this.i64Field);    first = false;    if (!first)        sb.append(", ");    sb.append("doubleField:");    sb.append(this.doubleField);    first = false;    if (!first)        sb.append(", ");    sb.append("stringField:");    if (this.stringField == null) {        sb.append("null");    } else {        sb.append(this.stringField);    }    first = false;    if (isSetBinaryField()) {        if (!first)            sb.append(", ");        sb.append("binaryField:");        if (this.binaryField == null) {            sb.append("null");        } else {            org.apache.thrift.TBaseHelper.toString(this.binaryField, sb);        }        first = false;    }    if (!first)        sb.append(", ");    sb.append("mapField:");    if (this.mapField == null) {        sb.append("null");    } else {        sb.append(this.mapField);    }    first = false;    if (!first)        sb.append(", ");    sb.append("listField:");    if (this.listField == null) {        sb.append("null");    } else {        sb.append(this.listField);    }    first = false;    if (!first)        sb.append(", ");    sb.append("setField:");    if (this.setField == null) {        sb.append("null");    } else {        sb.append(this.setField);    }    first = false;    if (!first)        sb.append(", ");    sb.append("enumField:");    if (this.enumField == null) {        sb.append("null");    } else {        sb.append(this.enumField);    }    first = false;    if (!first)        sb.append(", ");    sb.append("structField:");    if (this.structField == null) {        sb.append("null");    } else {        sb.append(this.structField);    }    first = false;    if (!first)        sb.append(", ");    sb.append("fooOrBar:");    if (this.fooOrBar == null) {        sb.append("null");    } else {        sb.append(this.fooOrBar);    }    first = false;    sb.append(")");    return sb.toString();}
0
public void validate() throws org.apache.thrift.TException
{        if (structField != null) {        structField.validate();    }}
0
private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException
{    try {        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
0
private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException
{    try {                        __isset_bitfield = 0;        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));    } catch (org.apache.thrift.TException te) {        throw new java.io.IOException(te);    }}
0
public TestStandardScheme getScheme()
{    return new TestStandardScheme();}
0
public void read(org.apache.thrift.protocol.TProtocol iprot, Test struct) throws org.apache.thrift.TException
{    org.apache.thrift.protocol.TField schemeField;    iprot.readStructBegin();    while (true) {        schemeField = iprot.readFieldBegin();        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) {            break;        }        switch(schemeField.id) {            case             1:                if (schemeField.type == org.apache.thrift.protocol.TType.BOOL) {                    struct.boolField = iprot.readBool();                    struct.setBoolFieldIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            case             2:                if (schemeField.type == org.apache.thrift.protocol.TType.BYTE) {                    struct.byteField = iprot.readByte();                    struct.setByteFieldIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            case             16:                if (schemeField.type == org.apache.thrift.protocol.TType.BYTE) {                    struct.byteOptionalField = iprot.readByte();                    struct.setByteOptionalFieldIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            case             3:                if (schemeField.type == org.apache.thrift.protocol.TType.I16) {                    struct.i16Field = iprot.readI16();                    struct.setI16FieldIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            case             15:                if (schemeField.type == org.apache.thrift.protocol.TType.I16) {                    struct.i16OptionalField = iprot.readI16();                    struct.setI16OptionalFieldIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            case             4:                if (schemeField.type == org.apache.thrift.protocol.TType.I32) {                    struct.i32Field = iprot.readI32();                    struct.setI32FieldIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            case             5:                if (schemeField.type == org.apache.thrift.protocol.TType.I64) {                    struct.i64Field = iprot.readI64();                    struct.setI64FieldIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            case             6:                if (schemeField.type == org.apache.thrift.protocol.TType.DOUBLE) {                    struct.doubleField = iprot.readDouble();                    struct.setDoubleFieldIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            case             7:                if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {                    struct.stringField = iprot.readString();                    struct.setStringFieldIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            case             8:                if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {                    struct.binaryField = iprot.readBinary();                    struct.setBinaryFieldIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            case             9:                if (schemeField.type == org.apache.thrift.protocol.TType.MAP) {                    {                        org.apache.thrift.protocol.TMap _map0 = iprot.readMapBegin();                        struct.mapField = new HashMap<>(2 * _map0.size);                        for (int _i1 = 0; _i1 < _map0.size; ++_i1) {                            String _key2;                            int _val3;                            _key2 = iprot.readString();                            _val3 = iprot.readI32();                            struct.mapField.put(_key2, _val3);                        }                        iprot.readMapEnd();                    }                    struct.setMapFieldIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            case             10:                if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {                    {                        org.apache.thrift.protocol.TList _list4 = iprot.readListBegin();                        struct.listField = new ArrayList<>(_list4.size);                        for (int _i5 = 0; _i5 < _list4.size; ++_i5) {                            int _elem6;                            _elem6 = iprot.readI32();                            struct.listField.add(_elem6);                        }                        iprot.readListEnd();                    }                    struct.setListFieldIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            case             11:                if (schemeField.type == org.apache.thrift.protocol.TType.SET) {                    {                        org.apache.thrift.protocol.TSet _set7 = iprot.readSetBegin();                        struct.setField = new HashSet<>(2 * _set7.size);                        for (int _i8 = 0; _i8 < _set7.size; ++_i8) {                            int _elem9;                            _elem9 = iprot.readI32();                            struct.setField.add(_elem9);                        }                        iprot.readSetEnd();                    }                    struct.setSetFieldIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            case             12:                if (schemeField.type == org.apache.thrift.protocol.TType.I32) {                    struct.enumField = E.findByValue(iprot.readI32());                    struct.setEnumFieldIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            case             13:                if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {                    struct.structField = new Nested();                    struct.structField.read(iprot);                    struct.setStructFieldIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            case             14:                if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {                    struct.fooOrBar = new FooOrBar();                    struct.fooOrBar.read(iprot);                    struct.setFooOrBarIsSet(true);                } else {                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);                }                break;            default:                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);        }        iprot.readFieldEnd();    }    iprot.readStructEnd();    struct.validate();}
0
public void write(org.apache.thrift.protocol.TProtocol oprot, Test struct) throws org.apache.thrift.TException
{    struct.validate();    oprot.writeStructBegin(STRUCT_DESC);    oprot.writeFieldBegin(BOOL_FIELD_FIELD_DESC);    oprot.writeBool(struct.boolField);    oprot.writeFieldEnd();    oprot.writeFieldBegin(BYTE_FIELD_FIELD_DESC);    oprot.writeByte(struct.byteField);    oprot.writeFieldEnd();    oprot.writeFieldBegin(I16_FIELD_FIELD_DESC);    oprot.writeI16(struct.i16Field);    oprot.writeFieldEnd();    if (struct.isSetI32Field()) {        oprot.writeFieldBegin(I32_FIELD_FIELD_DESC);        oprot.writeI32(struct.i32Field);        oprot.writeFieldEnd();    }    oprot.writeFieldBegin(I64_FIELD_FIELD_DESC);    oprot.writeI64(struct.i64Field);    oprot.writeFieldEnd();    oprot.writeFieldBegin(DOUBLE_FIELD_FIELD_DESC);    oprot.writeDouble(struct.doubleField);    oprot.writeFieldEnd();    if (struct.stringField != null) {        oprot.writeFieldBegin(STRING_FIELD_FIELD_DESC);        oprot.writeString(struct.stringField);        oprot.writeFieldEnd();    }    if (struct.binaryField != null) {        if (struct.isSetBinaryField()) {            oprot.writeFieldBegin(BINARY_FIELD_FIELD_DESC);            oprot.writeBinary(struct.binaryField);            oprot.writeFieldEnd();        }    }    if (struct.mapField != null) {        oprot.writeFieldBegin(MAP_FIELD_FIELD_DESC);        {            oprot.writeMapBegin(new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.I32, struct.mapField.size()));            for (Map.Entry<String, Integer> _iter10 : struct.mapField.entrySet()) {                oprot.writeString(_iter10.getKey());                oprot.writeI32(_iter10.getValue());            }            oprot.writeMapEnd();        }        oprot.writeFieldEnd();    }    if (struct.listField != null) {        oprot.writeFieldBegin(LIST_FIELD_FIELD_DESC);        {            oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.I32, struct.listField.size()));            for (int _iter11 : struct.listField) {                oprot.writeI32(_iter11);            }            oprot.writeListEnd();        }        oprot.writeFieldEnd();    }    if (struct.setField != null) {        oprot.writeFieldBegin(SET_FIELD_FIELD_DESC);        {            oprot.writeSetBegin(new org.apache.thrift.protocol.TSet(org.apache.thrift.protocol.TType.I32, struct.setField.size()));            for (int _iter12 : struct.setField) {                oprot.writeI32(_iter12);            }            oprot.writeSetEnd();        }        oprot.writeFieldEnd();    }    if (struct.enumField != null) {        oprot.writeFieldBegin(ENUM_FIELD_FIELD_DESC);        oprot.writeI32(struct.enumField.getValue());        oprot.writeFieldEnd();    }    if (struct.structField != null) {        oprot.writeFieldBegin(STRUCT_FIELD_FIELD_DESC);        struct.structField.write(oprot);        oprot.writeFieldEnd();    }    if (struct.fooOrBar != null) {        oprot.writeFieldBegin(FOO_OR_BAR_FIELD_DESC);        struct.fooOrBar.write(oprot);        oprot.writeFieldEnd();    }    if (struct.isSetI16OptionalField()) {        oprot.writeFieldBegin(I16_OPTIONAL_FIELD_FIELD_DESC);        oprot.writeI16(struct.i16OptionalField);        oprot.writeFieldEnd();    }    if (struct.isSetByteOptionalField()) {        oprot.writeFieldBegin(BYTE_OPTIONAL_FIELD_FIELD_DESC);        oprot.writeByte(struct.byteOptionalField);        oprot.writeFieldEnd();    }    oprot.writeFieldStop();    oprot.writeStructEnd();}
0
public TestTupleScheme getScheme()
{    return new TestTupleScheme();}
0
public void write(org.apache.thrift.protocol.TProtocol prot, Test struct) throws org.apache.thrift.TException
{    TTupleProtocol oprot = (TTupleProtocol) prot;    BitSet optionals = new BitSet();    if (struct.isSetBoolField()) {        optionals.set(0);    }    if (struct.isSetByteField()) {        optionals.set(1);    }    if (struct.isSetByteOptionalField()) {        optionals.set(2);    }    if (struct.isSetI16Field()) {        optionals.set(3);    }    if (struct.isSetI16OptionalField()) {        optionals.set(4);    }    if (struct.isSetI32Field()) {        optionals.set(5);    }    if (struct.isSetI64Field()) {        optionals.set(6);    }    if (struct.isSetDoubleField()) {        optionals.set(7);    }    if (struct.isSetStringField()) {        optionals.set(8);    }    if (struct.isSetBinaryField()) {        optionals.set(9);    }    if (struct.isSetMapField()) {        optionals.set(10);    }    if (struct.isSetListField()) {        optionals.set(11);    }    if (struct.isSetSetField()) {        optionals.set(12);    }    if (struct.isSetEnumField()) {        optionals.set(13);    }    if (struct.isSetStructField()) {        optionals.set(14);    }    if (struct.isSetFooOrBar()) {        optionals.set(15);    }    oprot.writeBitSet(optionals, 16);    if (struct.isSetBoolField()) {        oprot.writeBool(struct.boolField);    }    if (struct.isSetByteField()) {        oprot.writeByte(struct.byteField);    }    if (struct.isSetByteOptionalField()) {        oprot.writeByte(struct.byteOptionalField);    }    if (struct.isSetI16Field()) {        oprot.writeI16(struct.i16Field);    }    if (struct.isSetI16OptionalField()) {        oprot.writeI16(struct.i16OptionalField);    }    if (struct.isSetI32Field()) {        oprot.writeI32(struct.i32Field);    }    if (struct.isSetI64Field()) {        oprot.writeI64(struct.i64Field);    }    if (struct.isSetDoubleField()) {        oprot.writeDouble(struct.doubleField);    }    if (struct.isSetStringField()) {        oprot.writeString(struct.stringField);    }    if (struct.isSetBinaryField()) {        oprot.writeBinary(struct.binaryField);    }    if (struct.isSetMapField()) {        {            oprot.writeI32(struct.mapField.size());            for (Map.Entry<String, Integer> _iter13 : struct.mapField.entrySet()) {                oprot.writeString(_iter13.getKey());                oprot.writeI32(_iter13.getValue());            }        }    }    if (struct.isSetListField()) {        {            oprot.writeI32(struct.listField.size());            for (int _iter14 : struct.listField) {                oprot.writeI32(_iter14);            }        }    }    if (struct.isSetSetField()) {        {            oprot.writeI32(struct.setField.size());            for (int _iter15 : struct.setField) {                oprot.writeI32(_iter15);            }        }    }    if (struct.isSetEnumField()) {        oprot.writeI32(struct.enumField.getValue());    }    if (struct.isSetStructField()) {        struct.structField.write(oprot);    }    if (struct.isSetFooOrBar()) {        struct.fooOrBar.write(oprot);    }}
0
public void read(org.apache.thrift.protocol.TProtocol prot, Test struct) throws org.apache.thrift.TException
{    TTupleProtocol iprot = (TTupleProtocol) prot;    BitSet incoming = iprot.readBitSet(16);    if (incoming.get(0)) {        struct.boolField = iprot.readBool();        struct.setBoolFieldIsSet(true);    }    if (incoming.get(1)) {        struct.byteField = iprot.readByte();        struct.setByteFieldIsSet(true);    }    if (incoming.get(2)) {        struct.byteOptionalField = iprot.readByte();        struct.setByteOptionalFieldIsSet(true);    }    if (incoming.get(3)) {        struct.i16Field = iprot.readI16();        struct.setI16FieldIsSet(true);    }    if (incoming.get(4)) {        struct.i16OptionalField = iprot.readI16();        struct.setI16OptionalFieldIsSet(true);    }    if (incoming.get(5)) {        struct.i32Field = iprot.readI32();        struct.setI32FieldIsSet(true);    }    if (incoming.get(6)) {        struct.i64Field = iprot.readI64();        struct.setI64FieldIsSet(true);    }    if (incoming.get(7)) {        struct.doubleField = iprot.readDouble();        struct.setDoubleFieldIsSet(true);    }    if (incoming.get(8)) {        struct.stringField = iprot.readString();        struct.setStringFieldIsSet(true);    }    if (incoming.get(9)) {        struct.binaryField = iprot.readBinary();        struct.setBinaryFieldIsSet(true);    }    if (incoming.get(10)) {        {            org.apache.thrift.protocol.TMap _map16 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.I32, iprot.readI32());            struct.mapField = new HashMap<>(2 * _map16.size);            for (int _i17 = 0; _i17 < _map16.size; ++_i17) {                String _key18;                int _val19;                _key18 = iprot.readString();                _val19 = iprot.readI32();                struct.mapField.put(_key18, _val19);            }        }        struct.setMapFieldIsSet(true);    }    if (incoming.get(11)) {        {            org.apache.thrift.protocol.TList _list20 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.I32, iprot.readI32());            struct.listField = new ArrayList<>(_list20.size);            for (int _i21 = 0; _i21 < _list20.size; ++_i21) {                int _elem22;                _elem22 = iprot.readI32();                struct.listField.add(_elem22);            }        }        struct.setListFieldIsSet(true);    }    if (incoming.get(12)) {        {            org.apache.thrift.protocol.TSet _set23 = new org.apache.thrift.protocol.TSet(org.apache.thrift.protocol.TType.I32, iprot.readI32());            struct.setField = new HashSet<>(2 * _set23.size);            for (int _i24 = 0; _i24 < _set23.size; ++_i24) {                int _elem25;                _elem25 = iprot.readI32();                struct.setField.add(_elem25);            }        }        struct.setSetFieldIsSet(true);    }    if (incoming.get(13)) {        struct.enumField = E.findByValue(iprot.readI32());        struct.setEnumFieldIsSet(true);    }    if (incoming.get(14)) {        struct.structField = new Nested();        struct.structField.read(iprot);        struct.setStructFieldIsSet(true);    }    if (incoming.get(15)) {        struct.fooOrBar = new FooOrBar();        struct.fooOrBar.read(iprot);        struct.setFooOrBarIsSet(true);    }}
0
public void testStruct() throws Exception
{    System.out.println(ThriftData.get().getSchema(Test.class).toString(true));    Test test = new Test();    test.setBoolField(true);    test.setByteField((byte) 2);    test.setI16Field((short) 3);    test.setI16OptionalField((short) 14);    test.setI32Field(4);    test.setI64Field(5L);    test.setDoubleField(2.0);    test.setStringField("foo");    test.setBinaryField(ByteBuffer.wrap(new byte[] { 0, -1 }));    test.setMapField(Collections.singletonMap("x", 1));    test.setListField(Collections.singletonList(7));    test.setSetField(Collections.singleton(8));    test.setEnumField(E.X);    test.setStructField(new Nested(9));    test.setFooOrBar(FooOrBar.foo("x"));    System.out.println(test);    check(test);}
0
public void testOptionals() throws Exception
{    Test test = new Test();    test.setBoolField(true);    test.setByteField((byte) 2);    test.setByteOptionalField((byte) 4);    test.setI16Field((short) 3);    test.setI16OptionalField((short) 15);    test.setI64Field(5L);    test.setDoubleField(2.0);    System.out.println(test);    check(test);}
0
private void check(Test test) throws Exception
{    ByteArrayOutputStream bao = new ByteArrayOutputStream();    ThriftDatumWriter<Test> w = new ThriftDatumWriter<>(Test.class);    Encoder e = EncoderFactory.get().binaryEncoder(bao, null);    w.write(test, e);    e.flush();    Object o = new ThriftDatumReader<>(Test.class).read(null, DecoderFactory.get().binaryDecoder(new ByteArrayInputStream(bao.toByteArray()), null));    assertEquals(test, o);}
0
public int run(InputStream stdin, PrintStream out, PrintStream err, List<String> args) throws Exception
{    OptionParser optionParser = new OptionParser();    OptionSpec<Void> noPrettyOption = optionParser.accepts("no-pretty", "Turns off pretty printing.");    OptionSpec<String> schemaFileOption = optionParser.accepts("schema-file", "File containing schema, must not occur with inline schema.").withOptionalArg().ofType(String.class);    OptionSet optionSet = optionParser.parse(args.toArray(new String[0]));    Boolean noPretty = optionSet.has(noPrettyOption);    List<String> nargs = (List<String>) optionSet.nonOptionArguments();    String schemaFile = schemaFileOption.value(optionSet);    if (nargs.size() != (schemaFile == null ? 2 : 1)) {        err.println("fragtojson --no-pretty --schema-file <file> [inline-schema] input-file");        err.println("   converts Avro fragments to JSON.");        optionParser.printHelpOn(err);        err.println("   A dash '-' for input-file means stdin.");        return 1;    }    Schema schema;    String inputFile;    if (schemaFile == null) {        schema = new Schema.Parser().parse(nargs.get(0));        inputFile = nargs.get(1);    } else {        schema = Util.parseSchemaFromFS(schemaFile);        inputFile = nargs.get(0);    }    InputStream input = Util.fileOrStdin(inputFile, stdin);    try {        DatumReader<Object> reader = new GenericDatumReader<>(schema);        BinaryDecoder binaryDecoder = DecoderFactory.get().binaryDecoder(input, null);        DatumWriter<Object> writer = new GenericDatumWriter<>(schema);        JsonEncoder jsonEncoder = EncoderFactory.get().jsonEncoder(schema, out, !noPretty);        Object datum = null;        while (!binaryDecoder.isEnd()) {            datum = reader.read(datum, binaryDecoder);            writer.write(datum, jsonEncoder);            jsonEncoder.flush();        }        out.println();        out.flush();    } finally {        Util.close(input);    }    return 0;}
0
public String getName()
{    return "fragtojson";}
0
public String getShortDescription()
{    return "Renders a binary-encoded Avro datum as JSON.";}
0
public int run(InputStream in, PrintStream out, PrintStream err, List<String> args) throws Exception
{    OptionParser optParser = new OptionParser();    OptionSpec<Long> offsetOpt = optParser.accepts("offset", "offset for reading input").withRequiredArg().ofType(Long.class).defaultsTo(new Long(0));    OptionSpec<Long> limitOpt = optParser.accepts("limit", "maximum number of records in the outputfile").withRequiredArg().ofType(Long.class).defaultsTo(Long.MAX_VALUE);    OptionSpec<Double> fracOpt = optParser.accepts("samplerate", "rate at which records will be collected").withRequiredArg().ofType(Double.class).defaultsTo(new Double(1));    OptionSet opts = optParser.parse(args.toArray(new String[0]));    List<String> nargs = (List<String>) opts.nonOptionArguments();    if (nargs.size() < 2) {        printHelp(out);        return 0;    }    inFiles = Util.getFiles(nargs.subList(0, nargs.size() - 1));    System.out.println("List of input files:");    for (Path p : inFiles) {        System.out.println(p);    }    currentInput = -1;    nextInput();    OutputStream output = out;    String lastArg = nargs.get(nargs.size() - 1);    if (nargs.size() > 1 && !lastArg.equals("-")) {        output = Util.createFromFS(lastArg);    }    writer = new DataFileWriter<>(new GenericDatumWriter<>());    String codecName = reader.getMetaString(DataFileConstants.CODEC);    CodecFactory codec = (codecName == null) ? CodecFactory.fromString(DataFileConstants.NULL_CODEC) : CodecFactory.fromString(codecName);    writer.setCodec(codec);    for (String key : reader.getMetaKeys()) {        if (!DataFileWriter.isReservedMeta(key)) {            writer.setMeta(key, reader.getMeta(key));        }    }    writer.create(schema, output);    long offset = opts.valueOf(offsetOpt);    long limit = opts.valueOf(limitOpt);    double samplerate = opts.valueOf(fracOpt);    sampleCounter = 1;    totalCopied = 0;    reuse = null;    if (limit < 0) {        System.out.println("limit has to be non-negative");        this.printHelp(out);        return 1;    }    if (offset < 0) {        System.out.println("offset has to be non-negative");        this.printHelp(out);        return 1;    }    if (samplerate < 0 || samplerate > 1) {        System.out.println("samplerate has to be a number between 0 and 1");        this.printHelp(out);        return 1;    }    skip(offset);    writeRecords(limit, samplerate);    System.out.println(totalCopied + " records written.");    writer.flush();    writer.close();    Util.close(out);    return 0;}
0
private void nextInput() throws IOException
{    currentInput++;    Path path = inFiles.get(currentInput);    FSDataInputStream input = new FSDataInputStream(Util.openFromFS(path));    reader = new DataFileStream<>(input, new GenericDatumReader<>());    if (schema == null) {                schema = reader.getSchema();    } else if (!schema.equals(reader.getSchema())) {                throw new IOException("schemas dont match");    }}
0
private boolean hasNextInput()
{    return inFiles.size() > (currentInput + 1);}
0
private long skip(long skip) throws IOException
{    long skipped = 0;    while (0 < skip && reader.hasNext()) {        reader.next(reuse);        skip--;        skipped++;    }    if ((0 < skip) && hasNextInput()) {                nextInput();        skipped = skipped + skip(skip);    }    return skipped;}
0
private long writeRecords(long count, double samplerate) throws IOException
{    long written = 0;    while (written < count && reader.hasNext()) {        reuse = reader.next(reuse);        sampleCounter = sampleCounter + samplerate;        if (sampleCounter >= 1) {            writer.append(reuse);            written++;            sampleCounter--;        }    }    totalCopied = totalCopied + written;    if (written < count && hasNextInput()) {                nextInput();        written = written + writeRecords(count - written, samplerate);    }    return written;}
0
private void printHelp(PrintStream out)
{    out.println("cat --offset <offset> --limit <limit> --samplerate <samplerate> [input-files...] output-file");    out.println();    out.println("extracts records from a list of input files into a new file.");    out.println("--offset      start of the extract");    out.println("--limit       maximum number of records in the output file.");    out.println("--samplerate  rate at which records will be collected");    out.println("A dash ('-') can be given to direct output to stdout");}
0
public String getName()
{    return "cat";}
0
public String getShortDescription()
{    return "Extracts samples from files";}
0
public int run(InputStream in, PrintStream out, PrintStream err, List<String> args) throws Exception
{    if (args.isEmpty()) {        printHelp(out);        return 0;    }    OutputStream output = out;    if (args.size() > 1) {        output = Util.fileOrStdout(args.get(args.size() - 1), out);        args = args.subList(0, args.size() - 1);    }    DataFileWriter<GenericRecord> writer = new DataFileWriter<>(new GenericDatumWriter<>());    Schema schema = null;    Map<String, byte[]> metadata = new TreeMap<>();    String inputCodec = null;    for (String inFile : expandsInputFiles(args)) {        InputStream input = Util.fileOrStdin(inFile, in);        DataFileStream<GenericRecord> reader = new DataFileStream<>(input, new GenericDatumReader<>());        if (schema == null) {                                    schema = reader.getSchema();            for (String key : reader.getMetaKeys()) {                if (!DataFileWriter.isReservedMeta(key)) {                    byte[] metadatum = reader.getMeta(key);                    metadata.put(key, metadatum);                    writer.setMeta(key, metadatum);                }            }            inputCodec = reader.getMetaString(DataFileConstants.CODEC);            if (inputCodec == null) {                inputCodec = DataFileConstants.NULL_CODEC;            }            writer.setCodec(CodecFactory.fromString(inputCodec));            writer.create(schema, output);        } else {                        if (!schema.equals(reader.getSchema())) {                err.println("input files have different schemas");                reader.close();                return 1;            }            for (String key : reader.getMetaKeys()) {                if (!DataFileWriter.isReservedMeta(key)) {                    byte[] metadatum = reader.getMeta(key);                    byte[] writersMetadatum = metadata.get(key);                    if (!Arrays.equals(metadatum, writersMetadatum)) {                        err.println("input files have different non-reserved metadata");                        reader.close();                        return 2;                    }                }            }            String thisCodec = reader.getMetaString(DataFileConstants.CODEC);            if (thisCodec == null) {                thisCodec = DataFileConstants.NULL_CODEC;            }            if (!inputCodec.equals(thisCodec)) {                err.println("input files have different codecs");                reader.close();                return 3;            }        }        writer.appendAllFrom(reader, /* recompress */        false);        reader.close();    }    writer.close();    return 0;}
0
private static List<String> expandsInputFiles(List<String> args) throws IOException
{    List<String> files = new ArrayList<>();    for (String arg : args) {        if (arg.equals("-")) {            files.add(arg);        } else {            List<Path> paths = Util.getFiles(arg);            for (Path path : paths) {                files.add(path.toString());            }        }    }    return files;}
0
private void printHelp(PrintStream out)
{    out.println("concat [input-file...] output-file");    out.println();    out.println("Concatenates one or more input files into a new output file");    out.println("by appending the input blocks without decoding them. The input");    out.println("files must have the same schema, metadata and codec. If they");    out.println("do not the tool will return the following error codes:");    out.println("  1 if the schemas don't match");    out.println("  2 if the metadata doesn't match");    out.println("  3 if the codecs don't match");    out.println("If no input files are given stdin will be used. The tool");    out.println("0 on success. A dash ('-') can be given as an input file");    out.println("to use stdin, and as an output file to use stdout. If a directory");    out.println("is given as an input-file all the files within this directory");    out.println("are used.");}
0
public String getName()
{    return "concat";}
0
public String getShortDescription()
{    return "Concatenates avro files without re-compressing.";}
0
public String getName()
{    return "random";}
0
public String getShortDescription()
{    return "Creates a file with randomly generated instances of a schema.";}
0
public int run(InputStream stdin, PrintStream out, PrintStream err, List<String> args) throws Exception
{    OptionParser p = new OptionParser();    OptionSpec<Integer> count = p.accepts("count", "Record Count").withRequiredArg().ofType(Integer.class);    OptionSpec<String> codec = Util.compressionCodecOption(p);    OptionSpec<Integer> level = Util.compressionLevelOption(p);    OptionSpec<String> file = p.accepts("schema-file", "Schema File").withOptionalArg().ofType(String.class);    OptionSpec<String> inschema = p.accepts("schema", "Schema").withOptionalArg().ofType(String.class);    OptionSpec<Long> seedOpt = p.accepts("seed", "Seed for random").withOptionalArg().ofType(Long.class);    OptionSet opts = p.parse(args.toArray(new String[0]));    if (opts.nonOptionArguments().size() != 1) {        err.println("Usage: outFile (filename or '-' for stdout)");        p.printHelpOn(err);        return 1;    }    args = (List<String>) opts.nonOptionArguments();    String schemastr = inschema.value(opts);    String schemafile = file.value(opts);    Long seed = seedOpt.value(opts);    if (schemastr == null && schemafile == null) {        err.println("Need input schema (--schema-file) or (--schema)");        p.printHelpOn(err);        return 1;    }    Schema schema = (schemafile != null) ? Util.parseSchemaFromFS(schemafile) : new Schema.Parser().parse(schemastr);    DataFileWriter<Object> writer = new DataFileWriter<>(new GenericDatumWriter<>());    writer.setCodec(Util.codecFactory(opts, codec, level));    writer.create(schema, Util.fileOrStdout(args.get(0), out));    Integer countValue = count.value(opts);    if (countValue == null) {        err.println("Need count (--count)");        p.printHelpOn(err);        writer.close();        return 1;    }    RandomData rd = seed == null ? new RandomData(schema, countValue) : new RandomData(schema, countValue, seed);    for (Object datum : rd) writer.append(datum);    writer.close();    return 0;}
0
public String getName()
{    return "getmeta";}
0
public String getShortDescription()
{    return "Prints out the metadata of an Avro data file.";}
0
public int run(InputStream stdin, PrintStream out, PrintStream err, List<String> args) throws Exception
{    OptionParser p = new OptionParser();    OptionSpec<String> keyOption = p.accepts("key", "Metadata key").withOptionalArg().ofType(String.class);    OptionSet opts = p.parse(args.toArray(new String[0]));    String keyName = keyOption.value(opts);    List<String> nargs = (List<String>) opts.nonOptionArguments();    if (nargs.size() != 1) {        err.println("Expected 1 arg: input_file");        p.printHelpOn(err);        return 1;    }    FsInput in = Util.openSeekableFromFS(args.get(0));    DataFileReader<Void> reader = new DataFileReader<>(in, new GenericDatumReader<>());    if (keyName != null) {        byte[] value = reader.getMeta(keyName);        if (value != null) {            out.write(value, 0, value.length);            out.println();        }    } else {        List<String> keys = reader.getMetaKeys();        for (String key : keys) {            out.print(escapeKey(key));            out.print('\t');            byte[] value = reader.getMeta(key);            out.write(value, 0, value.length);            out.println();        }    }    return 0;}
0
 static String escapeKey(String key)
{        key = key.replace("\\", "\\\\");        key = key.replace("\t", "\\t");        key = key.replace("\n", "\\n");        key = key.replace("\r", "\\r");    return key;}
0
public String getName()
{    return "getschema";}
0
public String getShortDescription()
{    return "Prints out schema of an Avro data file.";}
0
public int run(InputStream stdin, PrintStream out, PrintStream err, List<String> args) throws Exception
{    if (args.size() != 1) {        err.println("Expected 1 argument: input_file");        return 1;    }    DataFileReader<Void> reader = new DataFileReader<>(Util.openSeekableFromFS(args.get(0)), new GenericDatumReader<>());    out.println(reader.getSchema().toString(true));    return 0;}
0
public String getName()
{    return "tojson";}
0
public String getShortDescription()
{    return "Dumps an Avro data file as JSON, record per line or pretty.";}
0
public int run(InputStream stdin, PrintStream out, PrintStream err, List<String> args) throws Exception
{    OptionParser optionParser = new OptionParser();    OptionSpec<Void> prettyOption = optionParser.accepts("pretty", "Turns on pretty printing.");    String headDesc = String.format("Converts the first X records (default is %d).", DEFAULT_HEAD_COUNT);    OptionSpec<String> headOption = optionParser.accepts("head", headDesc).withOptionalArg();    OptionSet optionSet = optionParser.parse(args.toArray(new String[0]));    Boolean pretty = optionSet.has(prettyOption);    List<String> nargs = new ArrayList<>((List<String>) optionSet.nonOptionArguments());    long headCount = getHeadCount(optionSet, headOption, nargs);    if (nargs.size() != 1) {        printHelp(err);        err.println();        optionParser.printHelpOn(err);        return 1;    }    BufferedInputStream inStream = Util.fileOrStdin(nargs.get(0), stdin);    GenericDatumReader<Object> reader = new GenericDatumReader<>();    try (DataFileStream<Object> streamReader = new DataFileStream<>(inStream, reader)) {        Schema schema = streamReader.getSchema();        DatumWriter<Object> writer = new GenericDatumWriter<>(schema);        JsonEncoder encoder = EncoderFactory.get().jsonEncoder(schema, out, pretty);        for (long recordCount = 0; streamReader.hasNext() && recordCount < headCount; recordCount++) {            Object datum = streamReader.next();            writer.write(datum, encoder);        }        encoder.flush();        out.println();        out.flush();    }    return 0;}
0
private static long getHeadCount(OptionSet optionSet, OptionSpec<String> headOption, List<String> nargs)
{    long headCount = Long.MAX_VALUE;    if (optionSet.has(headOption)) {        headCount = DEFAULT_HEAD_COUNT;        List<String> headValues = optionSet.valuesOf(headOption);        if (headValues.size() > 0) {                        try {                headCount = Long.parseLong(headValues.get(0));                if (headCount < 0)                    throw new AvroRuntimeException("--head count must not be negative");            } catch (NumberFormatException ex) {                nargs.addAll(headValues);            }        }    }    return headCount;}
0
private void printHelp(PrintStream ps)
{    ps.println("tojson [--pretty] [--head[=X]] input-file");    ps.println();    ps.println(getShortDescription());    ps.println("A dash ('-') can be given as an input file to use stdin");}
0
public String getName()
{    return "repair";}
0
public String getShortDescription()
{    return "Recovers data from a corrupt Avro Data file";}
0
private void printInfo(PrintStream output)
{    output.println("Insufficient arguments.  Arguments:  [-o option] " + "input_file output_file \n" + "   Where option is one of the following: \n" + "      " + ALL + " (default) recover as many records as possible.\n" + "      " + PRIOR + "         recover only records prior to the first instance" + " of corruption \n" + "      " + AFTER + "         recover only records after the first instance of" + " corruption.\n" + "      " + REPORT + "        print the corruption report only, reporting the\n" + "                    number of valid and corrupted blocks and records\n" + "   input_file is the file to read from.  output_file is the file to\n" + "   create and write recovered data to.  output_file is ignored if\n" + "   using the report option.");}
0
public int run(InputStream stdin, PrintStream out, PrintStream err, List<String> args) throws Exception
{    if (args.size() < 2) {        printInfo(err);        return 1;    }    int index = 0;    String input = args.get(index);    String option = "all";    if ("-o".equals(input)) {        option = args.get(1);        index += 2;    }    if (!OPTIONS.contains(option) || (args.size() - index < 1)) {        printInfo(err);        return 1;    }    input = args.get(index++);    if (!REPORT.equals(option)) {        if (args.size() - index < 1) {            printInfo(err);            return 1;        }    }    if (ALL.equals(option)) {        return recoverAll(input, args.get(index), out, err);    } else if (PRIOR.equals(option)) {        return recoverPrior(input, args.get(index), out, err);    } else if (AFTER.equals(option)) {        return recoverAfter(input, args.get(index), out, err);    } else if (REPORT.equals(option)) {        return reportOnly(input, out, err);    } else {        return 1;    }}
0
private int recover(String input, String output, PrintStream out, PrintStream err, boolean recoverPrior, boolean recoverAfter) throws IOException
{    File infile = new File(input);    if (!infile.canRead()) {        err.println("cannot read file: " + input);        return 1;    }    out.println("Recovering file: " + input);    GenericDatumReader<Object> reader = new GenericDatumReader<>();    try (DataFileReader<Object> fileReader = new DataFileReader<>(infile, reader)) {        Schema schema = fileReader.getSchema();        String codecStr = fileReader.getMetaString(DataFileConstants.CODEC);        CodecFactory codecFactory = CodecFactory.fromString("" + codecStr);        List<String> metas = fileReader.getMetaKeys();        if (recoverPrior || recoverAfter) {            GenericDatumWriter<Object> writer = new GenericDatumWriter<>();            DataFileWriter<Object> fileWriter = new DataFileWriter<>(writer);            try {                File outfile = new File(output);                for (String key : metas) {                    if (!key.startsWith("avro.")) {                        byte[] val = fileReader.getMeta(key);                        fileWriter.setMeta(key, val);                    }                }                fileWriter.setCodec(codecFactory);                int result = innerRecover(fileReader, fileWriter, out, err, recoverPrior, recoverAfter, schema, outfile);                return result;            } catch (Exception e) {                e.printStackTrace(err);                return 1;            }        } else {            return innerRecover(fileReader, null, out, err, recoverPrior, recoverAfter, null, null);        }    }}
0
private int innerRecover(DataFileReader<Object> fileReader, DataFileWriter<Object> fileWriter, PrintStream out, PrintStream err, boolean recoverPrior, boolean recoverAfter, Schema schema, File outfile)
{    int numBlocks = 0;    int numCorruptBlocks = 0;    int numRecords = 0;    int numCorruptRecords = 0;    int recordsWritten = 0;    long position = fileReader.previousSync();    long blockSize = 0;    long blockCount = 0;    boolean fileWritten = false;    try {        while (true) {            try {                if (!fileReader.hasNext()) {                    out.println("File Summary: ");                    out.println("  Number of blocks: " + numBlocks + " Number of corrupt blocks: " + numCorruptBlocks);                    out.println("  Number of records: " + numRecords + " Number of corrupt records: " + numCorruptRecords);                    if (recoverAfter || recoverPrior) {                        out.println("  Number of records written " + recordsWritten);                    }                    out.println();                    return 0;                }                position = fileReader.previousSync();                blockCount = fileReader.getBlockCount();                blockSize = fileReader.getBlockSize();                numRecords += blockCount;                long blockRemaining = blockCount;                numBlocks++;                boolean lastRecordWasBad = false;                long badRecordsInBlock = 0;                while (blockRemaining > 0) {                    try {                        Object datum = fileReader.next();                        if ((recoverPrior && numCorruptBlocks == 0) || (recoverAfter && numCorruptBlocks > 0)) {                            if (!fileWritten) {                                try {                                    fileWriter.create(schema, outfile);                                    fileWritten = true;                                } catch (Exception e) {                                    e.printStackTrace(err);                                    return 1;                                }                            }                            try {                                fileWriter.append(datum);                                recordsWritten++;                            } catch (Exception e) {                                e.printStackTrace(err);                                throw e;                            }                        }                        blockRemaining--;                        lastRecordWasBad = false;                    } catch (Exception e) {                        long pos = blockCount - blockRemaining;                        if (badRecordsInBlock == 0) {                                                        numCorruptBlocks++;                            err.println("Corrupt block: " + numBlocks + " Records in block: " + blockCount + " uncompressed block size: " + blockSize);                            err.println("Corrupt record at position: " + (pos));                        } else {                                                        err.println("Corrupt record at position: " + (pos));                            if (lastRecordWasBad) {                                                                err.println("Second consecutive bad record in block: " + numBlocks + ". Skipping remainder of block. ");                                numCorruptRecords += blockRemaining;                                badRecordsInBlock += blockRemaining;                                try {                                    fileReader.sync(position);                                } catch (Exception e2) {                                    err.println("failed to sync to sync marker, aborting");                                    e2.printStackTrace(err);                                    return 1;                                }                                break;                            }                        }                        blockRemaining--;                        lastRecordWasBad = true;                        numCorruptRecords++;                        badRecordsInBlock++;                    }                }                if (badRecordsInBlock != 0) {                    err.println("** Number of unrecoverable records in block: " + (badRecordsInBlock));                }                position = fileReader.previousSync();            } catch (Exception e) {                err.println("Failed to read block " + numBlocks + ". Unknown record " + "count in block.  Skipping. Reason: " + e.getMessage());                numCorruptBlocks++;                try {                    fileReader.sync(position);                } catch (Exception e2) {                    err.println("failed to sync to sync marker, aborting");                    e2.printStackTrace(err);                    return 1;                }            }        }    } finally {        if (fileWritten) {            try {                fileWriter.close();            } catch (Exception e) {                e.printStackTrace(err);                return 1;            }        }    }}
0
private int reportOnly(String input, PrintStream out, PrintStream err) throws IOException
{    return recover(input, null, out, err, false, false);}
0
private int recoverAfter(String input, String output, PrintStream out, PrintStream err) throws IOException
{    return recover(input, output, out, err, false, true);}
0
private int recoverPrior(String input, String output, PrintStream out, PrintStream err) throws IOException
{    return recover(input, output, out, err, true, false);}
0
private int recoverAll(String input, String output, PrintStream out, PrintStream err) throws IOException
{    return recover(input, output, out, err, true, true);}
0
public String getName()
{    return "fromjson";}
0
public String getShortDescription()
{    return "Reads JSON records and writes an Avro data file.";}
0
public int run(InputStream stdin, PrintStream out, PrintStream err, List<String> args) throws Exception
{    OptionParser p = new OptionParser();    OptionSpec<String> codec = Util.compressionCodecOptionWithDefault(p, DataFileConstants.NULL_CODEC);    OptionSpec<Integer> level = Util.compressionLevelOption(p);    OptionSpec<String> file = p.accepts("schema-file", "Schema File").withOptionalArg().ofType(String.class);    OptionSpec<String> inschema = p.accepts("schema", "Schema").withOptionalArg().ofType(String.class);    OptionSet opts = p.parse(args.toArray(new String[0]));    List<String> nargs = (List<String>) opts.nonOptionArguments();    if (nargs.size() != 1) {        err.println("Expected 1 arg: input_file");        p.printHelpOn(err);        return 1;    }    String schemastr = inschema.value(opts);    String schemafile = file.value(opts);    if (schemastr == null && schemafile == null) {        err.println("Need an input schema file (--schema-file) or inline schema (--schema)");        p.printHelpOn(err);        return 1;    }    Schema schema = (schemafile != null) ? Util.parseSchemaFromFS(schemafile) : new Schema.Parser().parse(schemastr);    DatumReader<Object> reader = new GenericDatumReader<>(schema);    InputStream input = Util.fileOrStdin(nargs.get(0), stdin);    try {        DataInputStream din = new DataInputStream(input);        DataFileWriter<Object> writer = new DataFileWriter<>(new GenericDatumWriter<>());        writer.setCodec(Util.codecFactory(opts, codec, level, DataFileConstants.NULL_CODEC));        writer.create(schema, out);        Decoder decoder = DecoderFactory.get().jsonDecoder(schema, din);        Object datum;        while (true) {            try {                datum = reader.read(null, decoder);            } catch (EOFException e) {                break;            }            writer.append(datum);        }        writer.close();    } finally {        Util.close(input);    }    return 0;}
0
public String getName()
{    return "fromtext";}
0
public String getShortDescription()
{    return "Imports a text file into an avro data file.";}
0
public int run(InputStream stdin, PrintStream out, PrintStream err, List<String> args) throws Exception
{    OptionParser p = new OptionParser();    OptionSpec<Integer> level = Util.compressionLevelOption(p);    OptionSpec<String> codec = Util.compressionCodecOption(p);    OptionSet opts = p.parse(args.toArray(new String[0]));    List<String> nargs = (List<String>) opts.nonOptionArguments();    if (nargs.size() != 2) {        err.println("Expected 2 args: from_file to_file (local filenames," + " Hadoop URI's, or '-' for stdin/stdout");        p.printHelpOn(err);        return 1;    }    CodecFactory codecFactory = Util.codecFactory(opts, codec, level);    BufferedInputStream inStream = Util.fileOrStdin(nargs.get(0), stdin);    BufferedOutputStream outStream = Util.fileOrStdout(nargs.get(1), out);    DataFileWriter<ByteBuffer> writer = new DataFileWriter<>(new GenericDatumWriter<>());    writer.setCodec(codecFactory);    writer.create(new Schema.Parser().parse(TEXT_FILE_SCHEMA), outStream);    ByteBuffer line = ByteBuffer.allocate(128);    boolean returnSeen = false;    byte[] buf = new byte[8192];    for (int end = inStream.read(buf); end != -1; end = inStream.read(buf)) {        for (int i = 0; i < end; i++) {            int b = buf[i] & 0xFF;            if (b == '\n') {                                if (!returnSeen) {                    System.out.println("Writing line = " + line.position());                    line.flip();                    writer.append(line);                    line.clear();                } else {                    returnSeen = false;                }            } else if (b == '\r') {                                line.flip();                writer.append(line);                line.clear();                returnSeen = true;            } else {                if (line.position() == line.limit()) {                                        ByteBuffer tempLine = ByteBuffer.allocate(line.limit() * 2);                    line.flip();                    tempLine.put(line);                    line = tempLine;                }                line.put((byte) b);                returnSeen = false;            }        }    }    writer.close();    inStream.close();    return 0;}
0
public int run(InputStream in, PrintStream out, PrintStream err, List<String> args) throws Exception
{    PrintStream parseOut = out;    if (args.size() > 2 || (args.size() == 1 && (args.get(0).equals("--help") || args.get(0).equals("-help")))) {        err.println("Usage: idl [in] [out]");        err.println();        err.println("If an output path is not specified, outputs to stdout.");        err.println("If no input or output is specified, takes input from");        err.println("stdin and outputs to stdin.");        err.println("The special path \"-\" may also be specified to refer to");        err.println("stdin and stdout.");        return -1;    }    Idl parser;    if (args.size() >= 1 && !"-".equals(args.get(0))) {        parser = new Idl(new File(args.get(0)));    } else {        parser = new Idl(in);    }    if (args.size() == 2 && !"-".equals(args.get(1))) {        parseOut = new PrintStream(new FileOutputStream(args.get(1)));    }    Protocol p = parser.CompilationUnit();    try {        parseOut.print(p.toString(true));    } finally {        if (        parseOut != out)            parseOut.close();    }    return 0;}
0
public String getName()
{    return "idl";}
0
public String getShortDescription()
{    return "Generates a JSON schema from an Avro IDL file";}
0
public int run(InputStream in, PrintStream out, PrintStream err, List<String> args) throws Exception
{    if (args.isEmpty() || args.size() > 2 || isRequestingHelp(args)) {        err.println("Usage: idl2schemata [idl] [outdir]");        err.println("");        err.println("If an output directory is not specified, " + "outputs to current directory.");        return -1;    }    boolean pretty = true;    Idl parser = new Idl(new File(args.get(0)));    File outputDirectory = getOutputDirectory(args);    for (Schema schema : parser.CompilationUnit().getTypes()) {        print(schema, outputDirectory, pretty);    }    parser.close();    return 0;}
0
private boolean isRequestingHelp(List<String> args)
{    return args.size() == 1 && (args.get(0).equals("--help") || args.get(0).equals("-help"));}
0
private File getOutputDirectory(List<String> args)
{    String dirname = (args.size() == 2) ? args.get(1) : "";    File outputDirectory = new File(dirname);    outputDirectory.mkdirs();    return outputDirectory;}
0
private void print(Schema schema, File outputDirectory, boolean pretty) throws FileNotFoundException
{    String dirpath = outputDirectory.getAbsolutePath();    String filename = dirpath + "/" + schema.getName() + ".avsc";    FileOutputStream fileOutputStream = new FileOutputStream(filename);    PrintStream printStream = new PrintStream(fileOutputStream);    printStream.println(schema.toString(pretty));    printStream.close();}
0
public String getName()
{    return "idl2schemata";}
0
public String getShortDescription()
{    return "Extract JSON schemata of the types from an Avro IDL file";}
0
public int run(InputStream in, PrintStream out, PrintStream err, List<String> args) throws Exception
{    if (args.size() == 0 || args.size() > 2) {        System.err.println("Usage: [colon-delimited-classpath] classname");        return 1;    }    ClassLoader classLoader = Thread.currentThread().getContextClassLoader();    String className;    if (args.size() == 2) {        String classpaths = args.get(0);        className = args.get(1);        if (!classpaths.isEmpty()) {            String[] paths = args.get(0).split(":");            URL[] urls = new URL[paths.length];            for (int i = 0; i < paths.length; ++i) {                urls[i] = new File(paths[i]).toURI().toURL();            }            classLoader = URLClassLoader.newInstance(urls, classLoader);        }    } else {        className = args.get(0);    }    Class<?> klass = classLoader.loadClass(className);    if (klass.isInterface()) {        System.out.println(ReflectData.get().getProtocol(klass).toString(true));    } else {        System.out.println(ReflectData.get().getSchema(klass).toString(true));    }    return 0;}
0
public String getName()
{    return "induce";}
0
public String getShortDescription()
{    return "Induce schema/protocol from Java class/interface via reflection.";}
0
public int run(InputStream stdin, PrintStream out, PrintStream err, List<String> args) throws Exception
{    OptionParser optionParser = new OptionParser();    OptionSpec<String> schemaFileOption = optionParser.accepts("schema-file", "File containing schema, must not occur with inline schema.").withOptionalArg().ofType(String.class);    OptionSet optionSet = optionParser.parse(args.toArray(new String[0]));    List<String> nargs = (List<String>) optionSet.nonOptionArguments();    String schemaFile = schemaFileOption.value(optionSet);    if (nargs.size() != (schemaFile == null ? 2 : 1)) {        err.println("jsontofrag --schema-file <file> [inline-schema] input-file");        err.println("   converts JSON to Avro fragments.");        optionParser.printHelpOn(err);        err.println("   A dash '-' for input-file means stdin.");        return 1;    }    Schema schema;    String inputFile;    if (schemaFile == null) {        schema = new Schema.Parser().parse(nargs.get(0));        inputFile = nargs.get(1);    } else {        schema = Util.parseSchemaFromFS(schemaFile);        inputFile = nargs.get(0);    }    InputStream input = Util.fileOrStdin(inputFile, stdin);    try {        GenericDatumReader<Object> reader = new GenericDatumReader<>(schema);        JsonDecoder jsonDecoder = DecoderFactory.get().jsonDecoder(schema, input);        GenericDatumWriter<Object> writer = new GenericDatumWriter<>(schema);        Encoder e = EncoderFactory.get().binaryEncoder(out, null);        Object datum = null;        while (true) {            try {                datum = reader.read(datum, jsonDecoder);            } catch (EOFException eofException) {                break;            }            writer.write(datum, e);            e.flush();        }    } finally {        Util.close(input);    }    return 0;}
0
public String getName()
{    return "jsontofrag";}
0
public String getShortDescription()
{    return "Renders a JSON-encoded Avro datum as binary.";}
0
public static void main(String[] args) throws Exception
{    int rc = new Main().run(args);    System.exit(rc);}
0
private int run(String[] args) throws Exception
{    if (args.length != 0) {        Tool tool = tools.get(args[0]);        if (tool != null) {            return tool.run(System.in, System.out, System.err, Arrays.asList(args).subList(1, args.length));        }    }    System.err.print("Version ");    try (InputStream versionInput = Main.class.getClassLoader().getResourceAsStream("VERSION.txt")) {        printStream(versionInput);    }    System.err.print(" of ");    try (InputStream noticeInput = Main.class.getClassLoader().getResourceAsStream("META-INF/NOTICE")) {        printHead(noticeInput, 5);    }    System.err.println("----------------");    System.err.println("Available tools:");    for (Tool k : tools.values()) {        System.err.printf("%" + maxLen + "s  %s\n", k.getName(), k.getShortDescription());    }    return 1;}
0
private static void printStream(InputStream in) throws Exception
{    byte[] buffer = new byte[1024];    for (int i = in.read(buffer); i != -1; i = in.read(buffer)) System.err.write(buffer, 0, i);}
0
private static void printHead(InputStream in, int lines) throws Exception
{    BufferedReader r = new BufferedReader(new InputStreamReader(in));    for (int i = 0; i < lines; i++) {        String line = r.readLine();        if (line == null) {            break;        }        System.err.println(line);    }}
0
public int run(InputStream in, PrintStream out, PrintStream err, List<String> args) throws Exception
{    OptionParser optParser = new OptionParser();    OptionSpec<String> codecOpt = Util.compressionCodecOptionWithDefault(optParser, DataFileConstants.NULL_CODEC);    OptionSpec<Integer> levelOpt = Util.compressionLevelOption(optParser);    OptionSet opts = optParser.parse(args.toArray(new String[0]));    List<String> nargs = (List<String>) opts.nonOptionArguments();    if (nargs.size() > 2) {        err.println("Expected at most an input file and output file.");        optParser.printHelpOn(err);        return 1;    }    InputStream input = in;    boolean inputNeedsClosing = false;    if (nargs.size() > 0 && !nargs.get(0).equals("-")) {        input = Util.openFromFS(nargs.get(0));        inputNeedsClosing = true;    }    OutputStream output = out;    boolean outputNeedsClosing = false;    if (nargs.size() > 1 && !nargs.get(1).equals("-")) {        output = Util.createFromFS(nargs.get(1));        outputNeedsClosing = true;    }    DataFileStream<GenericRecord> reader = new DataFileStream<>(input, new GenericDatumReader<>());    Schema schema = reader.getSchema();    DataFileWriter<GenericRecord> writer = new DataFileWriter<>(new GenericDatumWriter<>());        CodecFactory codec = Util.codecFactory(opts, codecOpt, levelOpt, DataFileConstants.NULL_CODEC);    writer.setCodec(codec);    for (String key : reader.getMetaKeys()) {        if (!DataFileWriter.isReservedMeta(key)) {            writer.setMeta(key, reader.getMeta(key));        }    }    writer.create(schema, output);    writer.appendAllFrom(reader, true);    writer.flush();    if (inputNeedsClosing) {        input.close();    }    if (outputNeedsClosing) {        output.close();    }    return 0;}
0
public String getName()
{    return "recodec";}
0
public String getShortDescription()
{    return "Alters the codec of a data file.";}
0
public String getName()
{    return "rpcprotocol";}
0
public String getShortDescription()
{    return "Output the protocol of a RPC service";}
0
public int run(InputStream in, PrintStream out, PrintStream err, List<String> args) throws Exception
{    if (args.size() != 1) {        err.println("Usage: uri");        return 1;    }    URI uri = URI.create(args.get(0));    try (Transceiver transceiver = Ipc.createTransceiver(uri)) {                HandshakeRequest rq = HandshakeRequest.newBuilder().setClientHash(new MD5(new byte[16])).setServerHash(new MD5(new byte[16])).setClientProtocol(null).setMeta(new LinkedHashMap<>()).build();        DatumWriter<HandshakeRequest> handshakeWriter = new SpecificDatumWriter<>(HandshakeRequest.class);        ByteBufferOutputStream byteBufferOutputStream = new ByteBufferOutputStream();        BinaryEncoder encoder = EncoderFactory.get().binaryEncoder(byteBufferOutputStream, null);        handshakeWriter.write(rq, encoder);        encoder.flush();                List<ByteBuffer> response = transceiver.transceive(byteBufferOutputStream.getBufferList());                ByteBufferInputStream byteBufferInputStream = new ByteBufferInputStream(response);        DatumReader<HandshakeResponse> handshakeReader = new SpecificDatumReader<>(HandshakeResponse.class);        HandshakeResponse handshakeResponse = handshakeReader.read(null, DecoderFactory.get().binaryDecoder(byteBufferInputStream, null));        Protocol p = Protocol.parse(handshakeResponse.getServerProtocol());                out.println(p.toString(true));    }    return 0;}
0
public String getName()
{    return "rpcreceive";}
0
public String getShortDescription()
{    return "Opens an RPC Server and listens for one message.";}
0
public Object respond(Message message, Object request) throws AvroRemoteException
{    if (!message.equals(expectedMessage)) {        out.println(String.format("Expected message '%s' but received '%s'.", expectedMessage.getName(), message.getName()));        latch.countDown();        throw new IllegalArgumentException("Unexpected message.");    }    out.print(message.getName());    out.print("\t");    try {        JsonEncoder jsonEncoder = EncoderFactory.get().jsonEncoder(message.getRequest(), out);        GenericDatumWriter<Object> writer = new GenericDatumWriter<>(message.getRequest());        writer.write(request, jsonEncoder);        jsonEncoder.flush();        out.flush();    } catch (IOException e) {        throw new RuntimeException(e);    }    out.println();    new Thread(() -> {        try {            Thread.sleep(1000);        } catch (InterruptedException e) {        }        latch.countDown();    }).start();    return response;}
0
public int run(InputStream in, PrintStream out, PrintStream err, List<String> args) throws Exception
{        int r = run1(in, out, err, args);    if (r != 0) {        return r;    }    return run2(err);}
0
 int run1(InputStream in, PrintStream out, PrintStream err, List<String> args) throws Exception
{    OptionParser p = new OptionParser();    OptionSpec<String> file = p.accepts("file", "Data file containing response datum.").withRequiredArg().ofType(String.class);    OptionSpec<String> data = p.accepts("data", "JSON-encoded response datum.").withRequiredArg().ofType(String.class);    OptionSet opts = p.parse(args.toArray(new String[0]));    args = (List<String>) opts.nonOptionArguments();    if (args.size() != 3) {        err.println("Usage: uri protocol_file message_name (-data d | -file f)");        p.printHelpOn(err);        return 1;    }    URI uri = new URI(args.get(0));    Protocol protocol = Protocol.parse(new File(args.get(1)));    String messageName = args.get(2);    expectedMessage = protocol.getMessages().get(messageName);    if (expectedMessage == null) {        err.println(String.format("No message named '%s' found in protocol '%s'.", messageName, protocol));        return 1;    }    if (data.value(opts) != null) {        this.response = Util.jsonToGenericDatum(expectedMessage.getResponse(), data.value(opts));    } else if (file.value(opts) != null) {        this.response = Util.datumFromFile(expectedMessage.getResponse(), file.value(opts));    } else {        err.println("One of -data or -file must be specified.");        return 1;    }    this.out = out;    latch = new CountDownLatch(1);    server = Ipc.createServer(new SinkResponder(protocol), uri);    server.start();    out.println("Port: " + server.getPort());    return 0;}
0
 int run2(PrintStream err) throws InterruptedException
{    latch.await();    err.println("Closing server.");    server.close();    return 0;}
0
public String getName()
{    return "rpcsend";}
0
public String getShortDescription()
{    return "Sends a single RPC message.";}
0
public int run(InputStream in, PrintStream out, PrintStream err, List<String> args) throws Exception
{    OptionParser p = new OptionParser();    OptionSpec<String> file = p.accepts("file", "Data file containing request parameters.").withRequiredArg().ofType(String.class);    OptionSpec<String> data = p.accepts("data", "JSON-encoded request parameters.").withRequiredArg().ofType(String.class);    OptionSet opts = p.parse(args.toArray(new String[0]));    args = (List<String>) opts.nonOptionArguments();    if (args.size() != 3) {        err.println("Usage: uri protocol_file message_name (-data d | -file f)");        p.printHelpOn(err);        return 1;    }    URI uri = new URI(args.get(0));    Protocol protocol = Protocol.parse(new File(args.get(1)));    String messageName = args.get(2);    Message message = protocol.getMessages().get(messageName);    if (message == null) {        err.println(String.format("No message named '%s' found in protocol '%s'.", messageName, protocol));        return 1;    }    Object datum;    if (data.value(opts) != null) {        datum = Util.jsonToGenericDatum(message.getRequest(), data.value(opts));    } else if (file.value(opts) != null) {        datum = Util.datumFromFile(message.getRequest(), file.value(opts));    } else {        err.println("One of -data or -file must be specified.");        return 1;    }    GenericRequestor client = new GenericRequestor(protocol, Ipc.createTransceiver(uri));    Object response = client.request(message.getName(), datum);    dumpJson(out, message.getResponse(), response);    return 0;}
0
private void dumpJson(PrintStream out, Schema schema, Object datum) throws IOException
{    DatumWriter<Object> writer = new GenericDatumWriter<>(schema);    JsonEncoder jsonEncoder = EncoderFactory.get().jsonEncoder(schema, out, true);    writer.write(datum, jsonEncoder);    jsonEncoder.flush();    out.println();    out.flush();}
0
public int run(InputStream in, PrintStream out, PrintStream err, List<String> args) throws Exception
{    final OptionParser optParser = new OptionParser();    final OptionSpec<String> fingerprintOpt = optParser.accepts("fingerprint", "Fingerprint algorithm to use. Recommended Avro practice dictiates " + "that \"CRC-64-AVRO\" is used for 64-bit fingerprints, \"MD5\" is " + "used for 128-bit fingerprints, and \"SHA-256\" is used for 256-bit " + "fingerprints.").withRequiredArg().ofType(String.class).defaultsTo("CRC-64-AVRO");    final OptionSet opts = optParser.parse(args.toArray(new String[0]));    final Schema.Parser parser = new Schema.Parser();    final List<String> nargs = (List<String>) opts.nonOptionArguments();    if (nargs.size() < 1) {        printHelp(out, optParser);        return 0;    }    for (final String fileOrStdin : (List<String>) opts.nonOptionArguments()) {        final InputStream input = Util.fileOrStdin(fileOrStdin, in);        try {            final Schema schema = parser.parse(input);            final byte[] fingerprint = SchemaNormalization.parsingFingerprint(opts.valueOf(fingerprintOpt), schema);            out.format("%s %s%n", Util.encodeHex(fingerprint), fileOrStdin);        } finally {            Util.close(input);        }    }    return 0;}
0
public String getName()
{    return "fingerprint";}
0
public String getShortDescription()
{    return "Returns the fingerprint for the schemas.";}
0
private void printHelp(PrintStream out, OptionParser optParser) throws IOException
{    out.println("fingerprint [--fingerprint <fingerprint>] input-file [inputfile [inputfile...]]");    out.println();    out.println("generates fingerprints based on Avro specification.");    optParser.printHelpOn(out);    out.println("A dash ('-') can be given to read a schema from stdin");}
0
public String getName()
{    return "canonical";}
0
public String getShortDescription()
{    return "Converts an Avro Schema to its canonical form";}
0
public int run(InputStream stdin, PrintStream out, PrintStream err, List<String> args) throws Exception
{    OptionParser p = new OptionParser();    OptionSet opts = p.parse(args.toArray(new String[0]));    if (opts.nonOptionArguments().size() != 2) {        err.println("Expected 2 args: infile outfile (filenames or '-' for stdin/stdout)");        p.printHelpOn(err);        return 1;    }    BufferedInputStream inStream = Util.fileOrStdin(args.get(0), stdin);    BufferedOutputStream outStream = Util.fileOrStdout(args.get(1), out);    Schema schema = new Schema.Parser().parse(inStream);    String canonicalForm = SchemaNormalization.toParsingForm(schema);    outStream.write(canonicalForm.getBytes(StandardCharsets.UTF_8));    Util.close(inStream);    Util.close(outStream);    return 0;}
0
public int run(InputStream in, PrintStream out, PrintStream err, List<String> args) throws Exception
{    if (args.size() < 3) {        System.err.println("Usage: [-encoding <outputencoding>] [-string] [-bigDecimal] [-templateDir <templateDir>] (schema|protocol) input... outputdir");        System.err.println(" input - input files or directories");        System.err.println(" outputdir - directory to write generated java");        System.err.println(" -encoding <outputencoding> - set the encoding of " + "output file(s)");        System.err.println(" -string - use java.lang.String instead of Utf8");        System.err.println(" -bigDecimal - use java.math.BigDecimal for " + "decimal type instead of java.nio.ByteBuffer");        System.err.println(" -templateDir - directory with custom Velocity templates");        return 1;    }    StringType stringType = StringType.CharSequence;    boolean useLogicalDecimal = false;    Optional<String> encoding = Optional.empty();    Optional<String> templateDir = Optional.empty();    int arg = 0;    if ("-encoding".equals(args.get(arg))) {        arg++;        encoding = Optional.of(args.get(arg));        arg++;    }    if ("-string".equals(args.get(arg))) {        stringType = StringType.String;        arg++;    }    if ("-bigDecimal".equalsIgnoreCase(args.get(arg))) {        useLogicalDecimal = true;        arg++;    }    if ("-templateDir".equals(args.get(arg))) {        arg++;        templateDir = Optional.of(args.get(arg));        arg++;    }    String method = args.get(arg);    List<File> inputs = new ArrayList<>();    File output = new File(args.get(args.size() - 1));    for (int i = arg + 1; i < args.size() - 1; i++) {        inputs.add(new File(args.get(i)));    }    if ("schema".equals(method)) {        Schema.Parser parser = new Schema.Parser();        for (File src : determineInputs(inputs, SCHEMA_FILTER)) {            Schema schema = parser.parse(src);            final SpecificCompiler compiler = new SpecificCompiler(schema);            executeCompiler(compiler, encoding, stringType, useLogicalDecimal, templateDir, src, output);        }    } else if ("protocol".equals(method)) {        for (File src : determineInputs(inputs, PROTOCOL_FILTER)) {            Protocol protocol = Protocol.parse(src);            final SpecificCompiler compiler = new SpecificCompiler(protocol);            executeCompiler(compiler, encoding, stringType, useLogicalDecimal, templateDir, src, output);        }    } else {        System.err.println("Expected \"schema\" or \"protocol\".");        return 1;    }    return 0;}
0
private void executeCompiler(SpecificCompiler compiler, Optional<String> encoding, StringType stringType, boolean enableDecimalLogicalType, Optional<String> templateDir, File src, File output) throws IOException
{    compiler.setStringType(stringType);    templateDir.ifPresent(compiler::setTemplateDir);    compiler.setEnableDecimalLogicalType(enableDecimalLogicalType);    encoding.ifPresent(compiler::setOutputCharacterEncoding);    compiler.compileToDestination(src, output);}
0
public String getName()
{    return "compile";}
0
public String getShortDescription()
{    return "Generates Java code for the given schema.";}
0
private static File[] determineInputs(List<File> inputs, FilenameFilter filter)
{        Set<File> fileSet = new LinkedHashSet<>();    for (File file : inputs) {                if (file.isDirectory()) {            File[] files = file.listFiles(filter);            Collections.addAll(fileSet, files != null ? files : new File[0]);        } else         {            fileSet.add(file);        }    }    if (fileSet.size() > 0) {        System.err.println("Input files to compile:");        for (File file : fileSet) {            System.err.println("  " + file);        }    } else {        System.err.println("No input files found.");    }    return fileSet.toArray(new File[0]);}
0
public boolean accept(File dir, String name)
{    return name.endsWith(this.extension);}
0
public String getName()
{    return "tether";}
0
public String getShortDescription()
{    return "Run a tethered mapreduce job.";}
0
public int run(InputStream ins, PrintStream outs, PrintStream err, List<String> args) throws Exception
{    String[] argarry = args.toArray(new String[0]);    Options opts = new Options();    Option helpopt = OptionBuilder.hasArg(false).withDescription("print this message").create("help");    Option inopt = OptionBuilder.hasArg().isRequired().withDescription("comma-separated input paths").create("in");    Option outopt = OptionBuilder.hasArg().isRequired().withDescription("The output path.").create("out");    Option pargs = OptionBuilder.hasArg().withDescription("A string containing the command line arguments to pass to the tethered process. String should be enclosed in quotes").create("exec_args");    Option popt = OptionBuilder.hasArg().isRequired().withDescription("executable program, usually in HDFS").create("program");    Option outscopt = OptionBuilder.withType(File.class).hasArg().isRequired().withDescription("schema file for output of reducer").create("outschema");    Option outscmapopt = OptionBuilder.withType(File.class).hasArg().withDescription("(optional) map output schema file,  if different from outschema").create("outschemamap");    Option redopt = OptionBuilder.withType(Integer.class).hasArg().withDescription("(optional) number of reducers").create("reduces");    Option cacheopt = OptionBuilder.withType(Boolean.class).hasArg().withDescription("(optional) boolean indicating whether or not the exectuable should be distributed via distributed cache").create("exec_cached");    Option protoopt = OptionBuilder.hasArg().withDescription("(optional) specifies the transport protocol 'http' or 'sasl'").create("protocol");    opts.addOption(redopt);    opts.addOption(outscopt);    opts.addOption(popt);    opts.addOption(pargs);    opts.addOption(inopt);    opts.addOption(outopt);    opts.addOption(helpopt);    opts.addOption(outscmapopt);    opts.addOption(cacheopt);    opts.addOption(protoopt);    CommandLineParser parser = new GnuParser();    String[] genargs = null;    CommandLine line = null;    HelpFormatter formatter = new HelpFormatter();    JobConf job = new JobConf();    try {        line = parser.parse(opts, argarry);        if (line.hasOption("help")) {            formatter.printHelp("tether", opts);            return 0;        }        genargs = line.getArgs();        FileInputFormat.addInputPaths(job, line.getOptionValue("in"));        FileOutputFormat.setOutputPath(job, new Path(line.getOptionValue("out")));        List<String> exargs = null;        Boolean cached = false;        if (line.hasOption("exec_args")) {            String[] splitargs = line.getOptionValue("exec_args").split(" ");            exargs = new ArrayList<>(Arrays.asList(splitargs));        }        if (line.hasOption("exec_cached")) {            cached = Boolean.parseBoolean(line.getOptionValue("exec_cached"));        }        TetherJob.setExecutable(job, new File(line.getOptionValue("program")), exargs, cached);        File outschema = (File) line.getParsedOptionValue("outschema");        job.set(AvroJob.OUTPUT_SCHEMA, Schema.parse(outschema).toString());        if (line.hasOption("outschemamap")) {            job.set(AvroJob.MAP_OUTPUT_SCHEMA, new Schema.Parser().parse((File) line.getParsedOptionValue("outschemamap")).toString());        }        if (line.hasOption("reduces")) {            job.setNumReduceTasks((Integer) line.getParsedOptionValue("reduces"));        }        if (line.hasOption("protocol")) {            TetherJob.setProtocol(job, line.getOptionValue("protocol"));        }    } catch (Exception exp) {        System.out.println("Unexpected exception: " + exp.getMessage());        formatter.printHelp("tether", opts);        return -1;    }    TetherJob.runJob(job);    return 0;}
0
public String getName()
{    return "totext";}
0
public String getShortDescription()
{    return "Converts an Avro data file to a text file.";}
0
public int run(InputStream stdin, PrintStream out, PrintStream err, List<String> args) throws Exception
{    OptionParser p = new OptionParser();    OptionSet opts = p.parse(args.toArray(new String[0]));    if (opts.nonOptionArguments().size() != 2) {        err.println("Expected 2 args: from_file to_file (filenames or '-' for stdin/stdout");        p.printHelpOn(err);        return 1;    }    BufferedInputStream inStream = Util.fileOrStdin(args.get(0), stdin);    BufferedOutputStream outStream = Util.fileOrStdout(args.get(1), out);    GenericDatumReader<Object> reader = new GenericDatumReader<>();    DataFileStream<Object> fileReader = new DataFileStream<>(inStream, reader);    if (!fileReader.getSchema().equals(new Schema.Parser().parse(TEXT_FILE_SCHEMA))) {        err.println("Avro file is not generic text schema");        p.printHelpOn(err);        fileReader.close();        return 1;    }    while (fileReader.hasNext()) {        ByteBuffer outBuff = (ByteBuffer) fileReader.next();        outStream.write(outBuff.array());        outStream.write(LINE_SEPARATOR);    }    fileReader.close();    Util.close(inStream);    Util.close(outStream);    return 0;}
0
public String getName()
{    return "totrevni";}
0
public String getShortDescription()
{    return "Converts an Avro data file to a Trevni file.";}
0
public int run(InputStream stdin, PrintStream out, PrintStream err, List<String> args) throws Exception
{    OptionParser p = new OptionParser();    OptionSpec<String> codec = p.accepts("codec", "Compression codec").withRequiredArg().defaultsTo("null").ofType(String.class);    OptionSet opts = p.parse(args.toArray(new String[0]));    if (opts.nonOptionArguments().size() != 2) {        err.println("Usage: inFile outFile (filenames or '-' for stdin/stdout)");        p.printHelpOn(err);        return 1;    }    args = (List<String>) opts.nonOptionArguments();    DataFileStream<Object> reader = new DataFileStream(Util.fileOrStdin(args.get(0), stdin), new GenericDatumReader<>());    OutputStream outs = Util.fileOrStdout(args.get(1), out);    AvroColumnWriter<Object> writer = new AvroColumnWriter<>(reader.getSchema(), new ColumnFileMetaData().setCodec(codec.value(opts)));    for (Object datum : reader) writer.write(datum);    writer.writeTo(outs);    outs.close();    reader.close();    return 0;}
0
public String getName()
{    return "trevni_random";}
0
public String getShortDescription()
{    return "Create a Trevni file filled with random instances of a schema.";}
0
public int run(InputStream stdin, PrintStream out, PrintStream err, List<String> args) throws Exception
{    if (args.size() != 3) {        err.println("Usage: schemaFile count outputFile");        return 1;    }    File schemaFile = new File(args.get(0));    int count = Integer.parseInt(args.get(1));    File outputFile = new File(args.get(2));    Schema schema = new Schema.Parser().parse(schemaFile);    AvroColumnWriter<Object> writer = new AvroColumnWriter<>(schema, new ColumnFileMetaData());    for (Object datum : new RandomData(schema, count)) writer.write(datum);    writer.writeTo(outputFile);    return 0;}
0
public String getName()
{    return "trevni_meta";}
0
public String getShortDescription()
{    return "Dumps a Trevni file's metadata as JSON.";}
0
public int run(InputStream stdin, PrintStream out, PrintStream err, List<String> args) throws Exception
{    String filename;    boolean pretty = false;    if (args.size() == 2 && "-pretty".equals(args.get(0))) {        pretty = true;        filename = args.get(1);    } else if (args.size() == 1) {        filename = args.get(0);    } else {        err.println("Usage: [-pretty] input");        return 1;    }    dump(TrevniUtil.input(filename), out, pretty);    return 0;}
0
public void dump(Input input, PrintStream out, boolean pretty) throws IOException
{    this.generator = FACTORY.createGenerator(out, JsonEncoding.UTF8);    if (pretty) {        generator.useDefaultPrettyPrinter();    } else {                MinimalPrettyPrinter pp = new MinimalPrettyPrinter();        pp.setRootValueSeparator(System.getProperty("line.separator"));        generator.setPrettyPrinter(pp);    }    ColumnFileReader reader = new ColumnFileReader(input);    generator.writeStartObject();    generator.writeNumberField("rowCount", reader.getRowCount());    generator.writeNumberField("columnCount", reader.getColumnCount());    generator.writeFieldName("metadata");    dump(reader.getMetaData());    generator.writeFieldName("columns");    generator.writeStartArray();    for (ColumnMetaData c : reader.getColumnMetaData()) dump(c);    generator.writeEndArray();    generator.writeEndObject();    generator.flush();    out.println();    reader.close();}
0
private void dump(MetaData<?> meta) throws IOException
{    generator.writeStartObject();    for (Map.Entry<String, byte[]> e : meta.entrySet()) generator.writeStringField(e.getKey(), new String(e.getValue(), StandardCharsets.ISO_8859_1));    generator.writeEndObject();}
0
public String getName()
{    return "trevni_tojson";}
0
public String getShortDescription()
{    return "Dumps a Trevni file as JSON.";}
0
public int run(InputStream stdin, PrintStream out, PrintStream err, List<String> args) throws Exception
{    String filename;    boolean pretty = false;    if (args.size() == 2 && "-pretty".equals(args.get(0))) {        pretty = true;        filename = args.get(1);    } else if (args.size() == 1) {        filename = args.get(0);    } else {        err.println("Usage: [-pretty] input");        return 1;    }    toJson(TrevniUtil.input(filename), out, pretty);    return 0;}
0
public void toJson(Input input, PrintStream out, boolean pretty) throws IOException
{    this.generator = FACTORY.createGenerator(out, JsonEncoding.UTF8);    if (pretty) {        generator.useDefaultPrettyPrinter();    } else {                MinimalPrettyPrinter pp = new MinimalPrettyPrinter();        pp.setRootValueSeparator(System.getProperty("line.separator"));        generator.setPrettyPrinter(pp);    }    ColumnFileReader reader = new ColumnFileReader(input);    int columnCount = (int) reader.getColumnCount();    this.values = new ColumnValues[columnCount];    this.shortNames = new String[columnCount];    for (int i = 0; i < columnCount; i++) {        values[i] = reader.getValues(i);        shortNames[i] = shortName(reader.getColumnMetaData(i));    }    List<ColumnMetaData> roots = reader.getRoots();    for (long row = 0; row < reader.getRowCount(); row++) {        for (ColumnValues v : values) v.startRow();        generator.writeStartObject();        for (ColumnMetaData root : roots) valueToJson(root);        generator.writeEndObject();    }    generator.flush();    out.println();    reader.close();}
0
private void valueToJson(ColumnMetaData column) throws IOException
{    generator.writeFieldName(shortNames[column.getNumber()]);    ColumnValues in = values[column.getNumber()];    if (!column.isArray()) {        primitiveToJson(column, in.nextValue());    } else {        generator.writeStartArray();        int length = in.nextLength();        for (int i = 0; i < length; i++) {            Object value = in.nextValue();            List<ColumnMetaData> children = column.getChildren();            if (children.size() == 0) {                primitiveToJson(column, value);            } else {                generator.writeStartObject();                if (value != null) {                    generator.writeFieldName("value$");                    primitiveToJson(column, value);                }                for (ColumnMetaData child : children) valueToJson(child);                generator.writeEndObject();            }        }        generator.writeEndArray();    }}
0
private void primitiveToJson(ColumnMetaData column, Object value) throws IOException
{    switch(column.getType()) {        case NULL:            generator.writeNull();            break;        case BOOLEAN:            generator.writeBoolean((Boolean) value);            break;        case INT:            generator.writeNumber((Integer) value);            break;        case LONG:            generator.writeNumber((Long) value);            break;        case FIXED32:            generator.writeNumber((Integer) value);            break;        case FIXED64:            generator.writeNumber((Long) value);            break;        case FLOAT:            generator.writeNumber((Float) value);            break;        case DOUBLE:            generator.writeNumber((Double) value);            break;        case STRING:            generator.writeString((String) value);            break;        case BYTES:            generator.writeBinary((byte[]) value);            break;        default:            throw new RuntimeException("Unknown value type: " + column.getType());    }}
0
private String shortName(ColumnMetaData column)
{    String name = column.getName();    ColumnMetaData parent = column.getParent();    if (parent != null && name.startsWith(parent.getName()))        name = name.substring(parent.getName().length());    if (!Character.isLetterOrDigit(name.charAt(0)))        name = name.substring(1);    return name;}
0
 static Input input(String filename) throws IOException
{    if (filename.startsWith("hdfs://")) {        return new HadoopInput(new Path(filename), new Configuration());    } else {        return new InputFile(new File(filename));    }}
0
 static InputStream input(String filename, InputStream stdin) throws IOException
{    if (filename.equals("-"))        return new BufferedInputStream(stdin);    else if (filename.startsWith("hdfs://")) {        FileSystem fs = FileSystem.get(URI.create(filename), new Configuration());        return new BufferedInputStream(fs.open(new Path(filename)));    } else {        return new BufferedInputStream(new FileInputStream(new File(filename)));    }}
0
 static OutputStream output(String filename, OutputStream stdout) throws IOException
{    if (filename.equals("-"))        return new BufferedOutputStream(stdout);    else if (filename.startsWith("hdfs://")) {        FileSystem fs = FileSystem.get(URI.create(filename), new Configuration());        return new BufferedOutputStream(fs.create(new Path(filename)));    } else {        return new BufferedOutputStream(new FileOutputStream(new File(filename)));    }}
0
 static BufferedInputStream fileOrStdin(String filename, InputStream stdin) throws IOException
{    return new BufferedInputStream(filename.equals("-") ? stdin : openFromFS(filename));}
0
 static BufferedOutputStream fileOrStdout(String filename, OutputStream stdout) throws IOException
{    return new BufferedOutputStream(filename.equals("-") ? stdout : createFromFS(filename));}
0
 static InputStream openFromFS(String filename) throws IOException
{    Path p = new Path(filename);    return p.getFileSystem(new Configuration()).open(p);}
0
 static InputStream openFromFS(Path filename) throws IOException
{    return filename.getFileSystem(new Configuration()).open(filename);}
0
 static FsInput openSeekableFromFS(String filename) throws IOException
{    return new FsInput(new Path(filename), new Configuration());}
0
 static OutputStream createFromFS(String filename) throws IOException
{    Path p = new Path(filename);    return new BufferedOutputStream(p.getFileSystem(new Configuration()).create(p));}
0
 static void close(InputStream in)
{    if (!System.in.equals(in)) {        try {            in.close();        } catch (IOException e) {            System.err.println("could not close InputStream " + in.toString());        }    }}
0
 static void close(OutputStream out)
{    if (!System.out.equals(out)) {        try {            out.close();        } catch (IOException e) {            System.err.println("could not close OutputStream " + out.toString());        }    }}
0
 static Schema parseSchemaFromFS(String filename) throws IOException
{    InputStream stream = openFromFS(filename);    try {        return new Schema.Parser().parse(stream);    } finally {        close(stream);    }}
0
 static List<Path> getFiles(String fileOrDirName) throws IOException
{    List<Path> pathList = new ArrayList<>();    Path path = new Path(fileOrDirName);    FileSystem fs = path.getFileSystem(new Configuration());    if (fs.isFile(path)) {        pathList.add(path);    } else if (fs.isDirectory(path)) {        for (FileStatus status : fs.listStatus(path)) {            if (!status.isDirectory()) {                pathList.add(status.getPath());            }        }    } else {        FileStatus[] fileStatuses = fs.globStatus(path);        if (fileStatuses != null) {            for (FileStatus status : fileStatuses) {                pathList.add(status.getPath());            }        } else {            throw new FileNotFoundException(fileOrDirName);        }    }    Collections.sort(pathList);    return pathList;}
0
 static List<Path> getFiles(List<String> fileOrDirNames) throws IOException
{    ArrayList<Path> pathList = new ArrayList<>();    for (String name : fileOrDirNames) {        pathList.addAll(getFiles(name));    }    Collections.sort(pathList);    return pathList;}
0
 static Object jsonToGenericDatum(Schema schema, String jsonData) throws IOException
{    GenericDatumReader<Object> reader = new GenericDatumReader<>(schema);    Object datum = reader.read(null, DecoderFactory.get().jsonDecoder(schema, jsonData));    return datum;}
0
 static Object datumFromFile(Schema schema, String file) throws IOException
{    try (DataFileReader<Object> in = new DataFileReader<>(new File(file), new GenericDatumReader<>(schema))) {        return in.next();    }}
0
 static OptionSpec<String> compressionCodecOption(OptionParser optParser)
{    return optParser.accepts("codec", "Compression codec").withRequiredArg().ofType(String.class).defaultsTo(DEFLATE_CODEC);}
0
 static OptionSpec<String> compressionCodecOptionWithDefault(OptionParser optParser, String s)
{    return optParser.accepts("codec", "Compression codec").withRequiredArg().ofType(String.class).defaultsTo(s);}
0
 static OptionSpec<Integer> compressionLevelOption(OptionParser optParser)
{    return optParser.accepts("level", "Compression level (only applies to deflate, xz, and zstandard)").withRequiredArg().ofType(Integer.class).defaultsTo(Deflater.DEFAULT_COMPRESSION);}
0
 static CodecFactory codecFactory(OptionSet opts, OptionSpec<String> codec, OptionSpec<Integer> level)
{    return codecFactory(opts, codec, level, DEFLATE_CODEC);}
0
 static CodecFactory codecFactory(OptionSet opts, OptionSpec<String> codec, OptionSpec<Integer> level, String defaultCodec)
{    String codecName = opts.hasArgument(codec) ? codec.value(opts) : defaultCodec;    if (codecName.equals(DEFLATE_CODEC)) {        return CodecFactory.deflateCodec(level.value(opts));    } else if (codecName.equals(DataFileConstants.XZ_CODEC)) {        return CodecFactory.xzCodec(level.value(opts));    } else if (codecName.equals(DataFileConstants.ZSTANDARD_CODEC)) {        return CodecFactory.zstandardCodec(level.value(opts));    } else {        return CodecFactory.fromString(codec.value(opts));    }}
0
 static String encodeHex(final byte[] data)
{    final int l = data.length;    final char[] out = new char[l << 1];        for (int i = 0, j = 0; i < l; i++) {        out[j++] = DIGITS_LOWER[(0xF0 & data[i]) >>> 4];        out[j++] = DIGITS_LOWER[0x0F & data[i]];    }    return new String(out);}
0
public static org.apache.avro.Schema getClassSchema()
{    return SCHEMA$;}
0
public static BinaryMessageEncoder<Player> getEncoder()
{    return ENCODER;}
0
public static BinaryMessageDecoder<Player> getDecoder()
{    return DECODER;}
0
public static BinaryMessageDecoder<Player> createDecoder(SchemaStore resolver)
{    return new BinaryMessageDecoder<Player>(MODEL$, SCHEMA$, resolver);}
0
public java.nio.ByteBuffer toByteBuffer() throws java.io.IOException
{    return ENCODER.encode(this);}
0
public static Player fromByteBuffer(java.nio.ByteBuffer b) throws java.io.IOException
{    return DECODER.decode(b);}
0
public org.apache.avro.specific.SpecificData getSpecificData()
{    return MODEL$;}
0
public org.apache.avro.Schema getSchema()
{    return SCHEMA$;}
0
public java.lang.Object get(int field$)
{    switch(field$) {        case 0:            return number;        case 1:            return first_name;        case 2:            return last_name;        case 3:            return position;        default:            throw new org.apache.avro.AvroRuntimeException("Bad index");    }}
0
public void put(int field$, java.lang.Object value$)
{    switch(field$) {        case 0:            number = (java.lang.Integer) value$;            break;        case 1:            first_name = (java.lang.CharSequence) value$;            break;        case 2:            last_name = (java.lang.CharSequence) value$;            break;        case 3:            position = (java.util.List<avro.examples.baseball.Position>) value$;            break;        default:            throw new org.apache.avro.AvroRuntimeException("Bad index");    }}
0
public int getNumber()
{    return number;}
0
public void setNumber(int value)
{    this.number = value;}
0
public java.lang.CharSequence getFirstName()
{    return first_name;}
0
public void setFirstName(java.lang.CharSequence value)
{    this.first_name = value;}
0
public java.lang.CharSequence getLastName()
{    return last_name;}
0
public void setLastName(java.lang.CharSequence value)
{    this.last_name = value;}
0
public java.util.List<avro.examples.baseball.Position> getPosition()
{    return position;}
0
public void setPosition(java.util.List<avro.examples.baseball.Position> value)
{    this.position = value;}
0
public static avro.examples.baseball.Player.Builder newBuilder()
{    return new avro.examples.baseball.Player.Builder();}
0
public static avro.examples.baseball.Player.Builder newBuilder(avro.examples.baseball.Player.Builder other)
{    if (other == null) {        return new avro.examples.baseball.Player.Builder();    } else {        return new avro.examples.baseball.Player.Builder(other);    }}
0
public static avro.examples.baseball.Player.Builder newBuilder(avro.examples.baseball.Player other)
{    if (other == null) {        return new avro.examples.baseball.Player.Builder();    } else {        return new avro.examples.baseball.Player.Builder(other);    }}
0
public int getNumber()
{    return number;}
0
public avro.examples.baseball.Player.Builder setNumber(int value)
{    validate(fields()[0], value);    this.number = value;    fieldSetFlags()[0] = true;    return this;}
0
public boolean hasNumber()
{    return fieldSetFlags()[0];}
0
public avro.examples.baseball.Player.Builder clearNumber()
{    fieldSetFlags()[0] = false;    return this;}
0
public java.lang.CharSequence getFirstName()
{    return first_name;}
0
public avro.examples.baseball.Player.Builder setFirstName(java.lang.CharSequence value)
{    validate(fields()[1], value);    this.first_name = value;    fieldSetFlags()[1] = true;    return this;}
0
public boolean hasFirstName()
{    return fieldSetFlags()[1];}
0
public avro.examples.baseball.Player.Builder clearFirstName()
{    first_name = null;    fieldSetFlags()[1] = false;    return this;}
0
public java.lang.CharSequence getLastName()
{    return last_name;}
0
public avro.examples.baseball.Player.Builder setLastName(java.lang.CharSequence value)
{    validate(fields()[2], value);    this.last_name = value;    fieldSetFlags()[2] = true;    return this;}
0
public boolean hasLastName()
{    return fieldSetFlags()[2];}
0
public avro.examples.baseball.Player.Builder clearLastName()
{    last_name = null;    fieldSetFlags()[2] = false;    return this;}
0
public java.util.List<avro.examples.baseball.Position> getPosition()
{    return position;}
0
public avro.examples.baseball.Player.Builder setPosition(java.util.List<avro.examples.baseball.Position> value)
{    validate(fields()[3], value);    this.position = value;    fieldSetFlags()[3] = true;    return this;}
0
public boolean hasPosition()
{    return fieldSetFlags()[3];}
0
public avro.examples.baseball.Player.Builder clearPosition()
{    position = null;    fieldSetFlags()[3] = false;    return this;}
0
public Player build()
{    try {        Player record = new Player();        record.number = fieldSetFlags()[0] ? this.number : (java.lang.Integer) defaultValue(fields()[0]);        record.first_name = fieldSetFlags()[1] ? this.first_name : (java.lang.CharSequence) defaultValue(fields()[1]);        record.last_name = fieldSetFlags()[2] ? this.last_name : (java.lang.CharSequence) defaultValue(fields()[2]);        record.position = fieldSetFlags()[3] ? this.position : (java.util.List<avro.examples.baseball.Position>) defaultValue(fields()[3]);        return record;    } catch (org.apache.avro.AvroMissingFieldException e) {        throw e;    } catch (java.lang.Exception e) {        throw new org.apache.avro.AvroRuntimeException(e);    }}
0
public void writeExternal(java.io.ObjectOutput out) throws java.io.IOException
{    WRITER$.write(this, SpecificData.getEncoder(out));}
0
public void readExternal(java.io.ObjectInput in) throws java.io.IOException
{    READER$.read(this, SpecificData.getDecoder(in));}
0
protected boolean hasCustomCoders()
{    return true;}
0
public void customEncode(org.apache.avro.io.Encoder out) throws java.io.IOException
{    out.writeInt(this.number);    out.writeString(this.first_name);    out.writeString(this.last_name);    long size0 = this.position.size();    out.writeArrayStart();    out.setItemCount(size0);    long actualSize0 = 0;    for (avro.examples.baseball.Position e0 : this.position) {        actualSize0++;        out.startItem();        out.writeEnum(e0.ordinal());    }    out.writeArrayEnd();    if (actualSize0 != size0)        throw new java.util.ConcurrentModificationException("Array-size written was " + size0 + ", but element count was " + actualSize0 + ".");}
0
public void customDecode(org.apache.avro.io.ResolvingDecoder in) throws java.io.IOException
{    org.apache.avro.Schema.Field[] fieldOrder = in.readFieldOrderIfDiff();    if (fieldOrder == null) {        this.number = in.readInt();        this.first_name = in.readString(this.first_name instanceof Utf8 ? (Utf8) this.first_name : null);        this.last_name = in.readString(this.last_name instanceof Utf8 ? (Utf8) this.last_name : null);        long size0 = in.readArrayStart();        java.util.List<avro.examples.baseball.Position> a0 = this.position;        if (a0 == null) {            a0 = new SpecificData.Array<avro.examples.baseball.Position>((int) size0, SCHEMA$.getField("position").schema());            this.position = a0;        } else            a0.clear();        SpecificData.Array<avro.examples.baseball.Position> ga0 = (a0 instanceof SpecificData.Array ? (SpecificData.Array<avro.examples.baseball.Position>) a0 : null);        for (; 0 < size0; size0 = in.arrayNext()) {            for (; size0 != 0; size0--) {                avro.examples.baseball.Position e0 = (ga0 != null ? ga0.peek() : null);                e0 = avro.examples.baseball.Position.values()[in.readEnum()];                a0.add(e0);            }        }    } else {        for (int i = 0; i < 4; i++) {            switch(fieldOrder[i].pos()) {                case 0:                    this.number = in.readInt();                    break;                case 1:                    this.first_name = in.readString(this.first_name instanceof Utf8 ? (Utf8) this.first_name : null);                    break;                case 2:                    this.last_name = in.readString(this.last_name instanceof Utf8 ? (Utf8) this.last_name : null);                    break;                case 3:                    long size0 = in.readArrayStart();                    java.util.List<avro.examples.baseball.Position> a0 = this.position;                    if (a0 == null) {                        a0 = new SpecificData.Array<avro.examples.baseball.Position>((int) size0, SCHEMA$.getField("position").schema());                        this.position = a0;                    } else                        a0.clear();                    SpecificData.Array<avro.examples.baseball.Position> ga0 = (a0 instanceof SpecificData.Array ? (SpecificData.Array<avro.examples.baseball.Position>) a0 : null);                    for (; 0 < size0; size0 = in.arrayNext()) {                        for (; size0 != 0; size0--) {                            avro.examples.baseball.Position e0 = (ga0 != null ? ga0.peek() : null);                            e0 = avro.examples.baseball.Position.values()[in.readEnum()];                            a0.add(e0);                        }                    }                    break;                default:                    throw new java.io.IOException("Corrupt ResolvingDecoder.");            }        }    }}
0
public static org.apache.avro.Schema getClassSchema()
{    return SCHEMA$;}
0
public org.apache.avro.Schema getSchema()
{    return SCHEMA$;}
0
public static org.apache.avro.Schema getClassSchema()
{    return SCHEMA$;}
0
public static BinaryMessageEncoder<FieldTest> getEncoder()
{    return ENCODER;}
0
public static BinaryMessageDecoder<FieldTest> getDecoder()
{    return DECODER;}
0
public static BinaryMessageDecoder<FieldTest> createDecoder(SchemaStore resolver)
{    return new BinaryMessageDecoder<FieldTest>(MODEL$, SCHEMA$, resolver);}
0
public java.nio.ByteBuffer toByteBuffer() throws java.io.IOException
{    return ENCODER.encode(this);}
0
public static FieldTest fromByteBuffer(java.nio.ByteBuffer b) throws java.io.IOException
{    return DECODER.decode(b);}
0
public org.apache.avro.specific.SpecificData getSpecificData()
{    return MODEL$;}
0
public org.apache.avro.Schema getSchema()
{    return SCHEMA$;}
0
public java.lang.Object get(int field$)
{    switch(field$) {        case 0:            return number;        case 1:            return last_name;        case 2:            return timestamp;        case 3:            return timestampMicros;        case 4:            return timeMillis;        case 5:            return timeMicros;        default:            throw new org.apache.avro.AvroRuntimeException("Bad index");    }}
0
public org.apache.avro.Conversion<?> getConversion(int field)
{    return conversions[field];}
0
public void put(int field$, java.lang.Object value$)
{    switch(field$) {        case 0:            number = (java.lang.Integer) value$;            break;        case 1:            last_name = (java.lang.String) value$;            break;        case 2:            timestamp = (java.time.Instant) value$;            break;        case 3:            timestampMicros = (java.time.Instant) value$;            break;        case 4:            timeMillis = (java.time.LocalTime) value$;            break;        case 5:            timeMicros = (java.time.LocalTime) value$;            break;        default:            throw new org.apache.avro.AvroRuntimeException("Bad index");    }}
0
public int getNumber()
{    return number;}
0
public void setNumber(int value)
{    this.number = value;}
0
public java.lang.String getLastName()
{    return last_name;}
0
public void setLastName(java.lang.String value)
{    this.last_name = value;}
0
public java.time.Instant getTimestamp()
{    return timestamp;}
0
public void setTimestamp(java.time.Instant value)
{    this.timestamp = value.truncatedTo(java.time.temporal.ChronoUnit.MILLIS);}
0
public java.time.Instant getTimestampMicros()
{    return timestampMicros;}
0
public void setTimestampMicros(java.time.Instant value)
{    this.timestampMicros = value.truncatedTo(java.time.temporal.ChronoUnit.MICROS);}
0
public java.time.LocalTime getTimeMillis()
{    return timeMillis;}
0
public void setTimeMillis(java.time.LocalTime value)
{    this.timeMillis = value.truncatedTo(java.time.temporal.ChronoUnit.MILLIS);}
0
public java.time.LocalTime getTimeMicros()
{    return timeMicros;}
0
public void setTimeMicros(java.time.LocalTime value)
{    this.timeMicros = value.truncatedTo(java.time.temporal.ChronoUnit.MICROS);}
0
public static avro.examples.baseball.FieldTest.Builder newBuilder()
{    return new avro.examples.baseball.FieldTest.Builder();}
0
public static avro.examples.baseball.FieldTest.Builder newBuilder(avro.examples.baseball.FieldTest.Builder other)
{    if (other == null) {        return new avro.examples.baseball.FieldTest.Builder();    } else {        return new avro.examples.baseball.FieldTest.Builder(other);    }}
0
public static avro.examples.baseball.FieldTest.Builder newBuilder(avro.examples.baseball.FieldTest other)
{    if (other == null) {        return new avro.examples.baseball.FieldTest.Builder();    } else {        return new avro.examples.baseball.FieldTest.Builder(other);    }}
0
public int getNumber()
{    return number;}
0
public avro.examples.baseball.FieldTest.Builder setNumber(int value)
{    validate(fields()[0], value);    this.number = value;    fieldSetFlags()[0] = true;    return this;}
0
public boolean hasNumber()
{    return fieldSetFlags()[0];}
0
public avro.examples.baseball.FieldTest.Builder clearNumber()
{    fieldSetFlags()[0] = false;    return this;}
0
public java.lang.String getLastName()
{    return last_name;}
0
public avro.examples.baseball.FieldTest.Builder setLastName(java.lang.String value)
{    validate(fields()[1], value);    this.last_name = value;    fieldSetFlags()[1] = true;    return this;}
0
public boolean hasLastName()
{    return fieldSetFlags()[1];}
0
public avro.examples.baseball.FieldTest.Builder clearLastName()
{    last_name = null;    fieldSetFlags()[1] = false;    return this;}
0
public java.time.Instant getTimestamp()
{    return timestamp;}
0
public avro.examples.baseball.FieldTest.Builder setTimestamp(java.time.Instant value)
{    validate(fields()[2], value);    this.timestamp = value.truncatedTo(java.time.temporal.ChronoUnit.MILLIS);    fieldSetFlags()[2] = true;    return this;}
0
public boolean hasTimestamp()
{    return fieldSetFlags()[2];}
0
public avro.examples.baseball.FieldTest.Builder clearTimestamp()
{    fieldSetFlags()[2] = false;    return this;}
0
public java.time.Instant getTimestampMicros()
{    return timestampMicros;}
0
public avro.examples.baseball.FieldTest.Builder setTimestampMicros(java.time.Instant value)
{    validate(fields()[3], value);    this.timestampMicros = value.truncatedTo(java.time.temporal.ChronoUnit.MICROS);    fieldSetFlags()[3] = true;    return this;}
0
public boolean hasTimestampMicros()
{    return fieldSetFlags()[3];}
0
public avro.examples.baseball.FieldTest.Builder clearTimestampMicros()
{    fieldSetFlags()[3] = false;    return this;}
0
public java.time.LocalTime getTimeMillis()
{    return timeMillis;}
0
public avro.examples.baseball.FieldTest.Builder setTimeMillis(java.time.LocalTime value)
{    validate(fields()[4], value);    this.timeMillis = value.truncatedTo(java.time.temporal.ChronoUnit.MILLIS);    fieldSetFlags()[4] = true;    return this;}
0
public boolean hasTimeMillis()
{    return fieldSetFlags()[4];}
0
public avro.examples.baseball.FieldTest.Builder clearTimeMillis()
{    fieldSetFlags()[4] = false;    return this;}
0
public java.time.LocalTime getTimeMicros()
{    return timeMicros;}
0
public avro.examples.baseball.FieldTest.Builder setTimeMicros(java.time.LocalTime value)
{    validate(fields()[5], value);    this.timeMicros = value.truncatedTo(java.time.temporal.ChronoUnit.MICROS);    fieldSetFlags()[5] = true;    return this;}
0
public boolean hasTimeMicros()
{    return fieldSetFlags()[5];}
0
public avro.examples.baseball.FieldTest.Builder clearTimeMicros()
{    fieldSetFlags()[5] = false;    return this;}
0
public FieldTest build()
{    try {        FieldTest record = new FieldTest();        record.number = fieldSetFlags()[0] ? this.number : (java.lang.Integer) defaultValue(fields()[0]);        record.last_name = fieldSetFlags()[1] ? this.last_name : (java.lang.String) defaultValue(fields()[1]);        record.timestamp = fieldSetFlags()[2] ? this.timestamp : (java.time.Instant) defaultValue(fields()[2]);        record.timestampMicros = fieldSetFlags()[3] ? this.timestampMicros : (java.time.Instant) defaultValue(fields()[3]);        record.timeMillis = fieldSetFlags()[4] ? this.timeMillis : (java.time.LocalTime) defaultValue(fields()[4]);        record.timeMicros = fieldSetFlags()[5] ? this.timeMicros : (java.time.LocalTime) defaultValue(fields()[5]);        return record;    } catch (org.apache.avro.AvroMissingFieldException e) {        throw e;    } catch (java.lang.Exception e) {        throw new org.apache.avro.AvroRuntimeException(e);    }}
0
public void writeExternal(java.io.ObjectOutput out) throws java.io.IOException
{    WRITER$.write(this, SpecificData.getEncoder(out));}
0
public void readExternal(java.io.ObjectInput in) throws java.io.IOException
{    READER$.read(this, SpecificData.getDecoder(in));}
0
public static org.apache.avro.Schema getClassSchema()
{    return SCHEMA$;}
0
public static BinaryMessageEncoder<Player> getEncoder()
{    return ENCODER;}
0
public static BinaryMessageDecoder<Player> getDecoder()
{    return DECODER;}
0
public static BinaryMessageDecoder<Player> createDecoder(SchemaStore resolver)
{    return new BinaryMessageDecoder<Player>(MODEL$, SCHEMA$, resolver);}
0
public java.nio.ByteBuffer toByteBuffer() throws java.io.IOException
{    return ENCODER.encode(this);}
0
public static Player fromByteBuffer(java.nio.ByteBuffer b) throws java.io.IOException
{    return DECODER.decode(b);}
0
public org.apache.avro.specific.SpecificData getSpecificData()
{    return MODEL$;}
0
public org.apache.avro.Schema getSchema()
{    return SCHEMA$;}
0
public java.lang.Object get(int field$)
{    switch(field$) {        case 0:            return number;        case 1:            return first_name;        case 2:            return last_name;        case 3:            return position;        default:            throw new org.apache.avro.AvroRuntimeException("Bad index");    }}
0
public void put(int field$, java.lang.Object value$)
{    switch(field$) {        case 0:            number = (java.lang.Integer) value$;            break;        case 1:            first_name = (java.lang.String) value$;            break;        case 2:            last_name = (java.lang.String) value$;            break;        case 3:            position = (java.util.List<avro.examples.baseball.Position>) value$;            break;        default:            throw new org.apache.avro.AvroRuntimeException("Bad index");    }}
0
public int getNumber()
{    return number;}
0
public void setNumber(int value)
{    this.number = value;}
0
public java.lang.String getFirstName()
{    return first_name;}
0
public void setFirstName(java.lang.String value)
{    this.first_name = value;}
0
public java.lang.String getLastName()
{    return last_name;}
0
public void setLastName(java.lang.String value)
{    this.last_name = value;}
0
public java.util.List<avro.examples.baseball.Position> getPosition()
{    return position;}
0
public void setPosition(java.util.List<avro.examples.baseball.Position> value)
{    this.position = value;}
0
public static avro.examples.baseball.Player.Builder newBuilder()
{    return new avro.examples.baseball.Player.Builder();}
0
public static avro.examples.baseball.Player.Builder newBuilder(avro.examples.baseball.Player.Builder other)
{    if (other == null) {        return new avro.examples.baseball.Player.Builder();    } else {        return new avro.examples.baseball.Player.Builder(other);    }}
0
public static avro.examples.baseball.Player.Builder newBuilder(avro.examples.baseball.Player other)
{    if (other == null) {        return new avro.examples.baseball.Player.Builder();    } else {        return new avro.examples.baseball.Player.Builder(other);    }}
0
public int getNumber()
{    return number;}
0
public avro.examples.baseball.Player.Builder setNumber(int value)
{    validate(fields()[0], value);    this.number = value;    fieldSetFlags()[0] = true;    return this;}
0
public boolean hasNumber()
{    return fieldSetFlags()[0];}
0
public avro.examples.baseball.Player.Builder clearNumber()
{    fieldSetFlags()[0] = false;    return this;}
0
public java.lang.String getFirstName()
{    return first_name;}
0
public avro.examples.baseball.Player.Builder setFirstName(java.lang.String value)
{    validate(fields()[1], value);    this.first_name = value;    fieldSetFlags()[1] = true;    return this;}
0
public boolean hasFirstName()
{    return fieldSetFlags()[1];}
0
public avro.examples.baseball.Player.Builder clearFirstName()
{    first_name = null;    fieldSetFlags()[1] = false;    return this;}
0
public java.lang.String getLastName()
{    return last_name;}
0
public avro.examples.baseball.Player.Builder setLastName(java.lang.String value)
{    validate(fields()[2], value);    this.last_name = value;    fieldSetFlags()[2] = true;    return this;}
0
public boolean hasLastName()
{    return fieldSetFlags()[2];}
0
public avro.examples.baseball.Player.Builder clearLastName()
{    last_name = null;    fieldSetFlags()[2] = false;    return this;}
0
public java.util.List<avro.examples.baseball.Position> getPosition()
{    return position;}
0
public avro.examples.baseball.Player.Builder setPosition(java.util.List<avro.examples.baseball.Position> value)
{    validate(fields()[3], value);    this.position = value;    fieldSetFlags()[3] = true;    return this;}
0
public boolean hasPosition()
{    return fieldSetFlags()[3];}
0
public avro.examples.baseball.Player.Builder clearPosition()
{    position = null;    fieldSetFlags()[3] = false;    return this;}
0
public Player build()
{    try {        Player record = new Player();        record.number = fieldSetFlags()[0] ? this.number : (java.lang.Integer) defaultValue(fields()[0]);        record.first_name = fieldSetFlags()[1] ? this.first_name : (java.lang.String) defaultValue(fields()[1]);        record.last_name = fieldSetFlags()[2] ? this.last_name : (java.lang.String) defaultValue(fields()[2]);        record.position = fieldSetFlags()[3] ? this.position : (java.util.List<avro.examples.baseball.Position>) defaultValue(fields()[3]);        return record;    } catch (org.apache.avro.AvroMissingFieldException e) {        throw e;    } catch (java.lang.Exception e) {        throw new org.apache.avro.AvroRuntimeException(e);    }}
0
public void writeExternal(java.io.ObjectOutput out) throws java.io.IOException
{    WRITER$.write(this, SpecificData.getEncoder(out));}
0
public void readExternal(java.io.ObjectInput in) throws java.io.IOException
{    READER$.read(this, SpecificData.getDecoder(in));}
0
protected boolean hasCustomCoders()
{    return true;}
0
public void customEncode(org.apache.avro.io.Encoder out) throws java.io.IOException
{    out.writeInt(this.number);    out.writeString(this.first_name);    out.writeString(this.last_name);    long size0 = this.position.size();    out.writeArrayStart();    out.setItemCount(size0);    long actualSize0 = 0;    for (avro.examples.baseball.Position e0 : this.position) {        actualSize0++;        out.startItem();        out.writeEnum(e0.ordinal());    }    out.writeArrayEnd();    if (actualSize0 != size0)        throw new java.util.ConcurrentModificationException("Array-size written was " + size0 + ", but element count was " + actualSize0 + ".");}
0
public void customDecode(org.apache.avro.io.ResolvingDecoder in) throws java.io.IOException
{    org.apache.avro.Schema.Field[] fieldOrder = in.readFieldOrderIfDiff();    if (fieldOrder == null) {        this.number = in.readInt();        this.first_name = in.readString();        this.last_name = in.readString();        long size0 = in.readArrayStart();        java.util.List<avro.examples.baseball.Position> a0 = this.position;        if (a0 == null) {            a0 = new SpecificData.Array<avro.examples.baseball.Position>((int) size0, SCHEMA$.getField("position").schema());            this.position = a0;        } else            a0.clear();        SpecificData.Array<avro.examples.baseball.Position> ga0 = (a0 instanceof SpecificData.Array ? (SpecificData.Array<avro.examples.baseball.Position>) a0 : null);        for (; 0 < size0; size0 = in.arrayNext()) {            for (; size0 != 0; size0--) {                avro.examples.baseball.Position e0 = (ga0 != null ? ga0.peek() : null);                e0 = avro.examples.baseball.Position.values()[in.readEnum()];                a0.add(e0);            }        }    } else {        for (int i = 0; i < 4; i++) {            switch(fieldOrder[i].pos()) {                case 0:                    this.number = in.readInt();                    break;                case 1:                    this.first_name = in.readString();                    break;                case 2:                    this.last_name = in.readString();                    break;                case 3:                    long size0 = in.readArrayStart();                    java.util.List<avro.examples.baseball.Position> a0 = this.position;                    if (a0 == null) {                        a0 = new SpecificData.Array<avro.examples.baseball.Position>((int) size0, SCHEMA$.getField("position").schema());                        this.position = a0;                    } else                        a0.clear();                    SpecificData.Array<avro.examples.baseball.Position> ga0 = (a0 instanceof SpecificData.Array ? (SpecificData.Array<avro.examples.baseball.Position>) a0 : null);                    for (; 0 < size0; size0 = in.arrayNext()) {                        for (; size0 != 0; size0--) {                            avro.examples.baseball.Position e0 = (ga0 != null ? ga0.peek() : null);                            e0 = avro.examples.baseball.Position.values()[in.readEnum()];                            a0.add(e0);                        }                    }                    break;                default:                    throw new java.io.IOException("Corrupt ResolvingDecoder.");            }        }    }}
0
public static org.apache.avro.Schema getClassSchema()
{    return SCHEMA$;}
0
public org.apache.avro.Schema getSchema()
{    return SCHEMA$;}
0
public static org.apache.avro.Schema getClassSchema()
{    return SCHEMA$;}
0
public org.apache.avro.Schema getSchema()
{    return SCHEMA$;}
0
private GenericRecord aDatum(Type ofType, int forRow)
{    GenericRecord record;    switch(ofType) {        case STRING:            record = new GenericData.Record(STRINGSCHEMA);            record.put("value", String.valueOf(forRow % 100));            return record;        case INT:            record = new GenericData.Record(INTSCHEMA);            record.put("value", forRow);            return record;        default:            throw new AssertionError("I can't generate data for this type");    }}
0
private File generateData(String file, Type type, Map<String, String> metadata, CodecFactory codec) throws Exception
{    File inputFile = new File(DIR.getRoot(), file);    inputFile.deleteOnExit();    Schema schema = null;    if (type.equals(Schema.Type.INT)) {        schema = INTSCHEMA;    }    if (type.equals(Schema.Type.STRING)) {        schema = STRINGSCHEMA;    }    DataFileWriter<Object> writer = new DataFileWriter<>(new GenericDatumWriter<>(schema));    for (Entry<String, String> metadatum : metadata.entrySet()) {        writer.setMeta(metadatum.getKey(), metadatum.getValue());    }    writer.setCodec(codec);    writer.create(schema, inputFile);    for (int i = 0; i < ROWS_IN_INPUT_FILES; i++) {        writer.append(aDatum(type, i));    }    writer.close();    return inputFile;}
0
private int getFirstIntDatum(File file) throws Exception
{    DataFileStream<GenericRecord> reader = new DataFileStream<>(new FileInputStream(file), new GenericDatumReader<>());    int result = (Integer) reader.next().get(0);    System.out.println(result);    reader.close();    return result;}
0
private int numRowsInFile(File output) throws Exception
{    DataFileStream<GenericRecord> reader = new DataFileStream<>(new FileInputStream(output), new GenericDatumReader<>());    Iterator<GenericRecord> rows = reader.iterator();    int rowcount = 0;    while (rows.hasNext()) {        ++rowcount;        rows.next();    }    reader.close();    return rowcount;}
0
public void testCat() throws Exception
{    Map<String, String> metadata = new HashMap<>();    metadata.put("myMetaKey", "myMetaValue");    File input1 = generateData("input1.avro", Type.INT, metadata, DEFLATE);    File input2 = generateData("input2.avro", Type.INT, metadata, SNAPPY);    File input3 = generateData("input3.avro", Type.INT, metadata, DEFLATE);    File output = new File(DIR.getRoot(), name.getMethodName() + ".avro");    output.deleteOnExit();        List<String> args = asList(input1.getAbsolutePath(), input2.getAbsolutePath(), input3.getAbsolutePath(), "--offset", String.valueOf(OFFSET), "--limit", String.valueOf(LIMIT_WITHIN_INPUT_BOUNDS), "--samplerate", String.valueOf(SAMPLERATE), output.getAbsolutePath());    int returnCode = new CatTool().run(System.in, System.out, System.err, args);    assertEquals(0, returnCode);    assertEquals(LIMIT_WITHIN_INPUT_BOUNDS, numRowsInFile(output));        args = asList(input1.getParentFile().getAbsolutePath(), output.getAbsolutePath(), "--offset", String.valueOf(OFFSET), "--limit", String.valueOf(LIMIT_WITHIN_INPUT_BOUNDS));    returnCode = new CatTool().run(System.in, System.out, System.err, args);    assertEquals(0, returnCode);    assertEquals(LIMIT_WITHIN_INPUT_BOUNDS, numRowsInFile(output));        args = asList(new File(input1.getParentFile(), "/*").getAbsolutePath(), output.getAbsolutePath(), "--offset", String.valueOf(OFFSET), "--limit", String.valueOf(LIMIT_WITHIN_INPUT_BOUNDS));    returnCode = new CatTool().run(System.in, System.out, System.err, args);    assertEquals(0, returnCode);    assertEquals(LIMIT_WITHIN_INPUT_BOUNDS, numRowsInFile(output));}
0
public void testLimitOutOfBounds() throws Exception
{    Map<String, String> metadata = new HashMap<>();    metadata.put("myMetaKey", "myMetaValue");    File input1 = generateData("input1.avro", Type.INT, metadata, DEFLATE);    File output = new File(DIR.getRoot(), name.getMethodName() + ".avro");    output.deleteOnExit();    List<String> args = asList(input1.getAbsolutePath(), "--offset=" + String.valueOf(OFFSET), "--limit=" + String.valueOf(LIMIT_OUT_OF_INPUT_BOUNDS), output.getAbsolutePath());    int returnCode = new CatTool().run(System.in, System.out, System.err, args);    assertEquals(0, returnCode);    assertEquals(ROWS_IN_INPUT_FILES - OFFSET, numRowsInFile(output));}
0
public void testSamplerateAccuracy() throws Exception
{    Map<String, String> metadata = new HashMap<>();    metadata.put("myMetaKey", "myMetaValue");    File input1 = generateData("input1.avro", Type.INT, metadata, DEFLATE);    File output = new File(DIR.getRoot(), name.getMethodName() + ".avro");    output.deleteOnExit();    List<String> args = asList(input1.getAbsolutePath(), output.getAbsolutePath(), "--offset", String.valueOf(OFFSET), "--samplerate", String.valueOf(SAMPLERATE));    int returnCode = new CatTool().run(System.in, System.out, System.err, args);    assertEquals(0, returnCode);    assertTrue("Outputsize is not roughly (Inputsize - Offset) * samplerate", (ROWS_IN_INPUT_FILES - OFFSET) * SAMPLERATE - numRowsInFile(output) < 2);    assertTrue("", (ROWS_IN_INPUT_FILES - OFFSET) * SAMPLERATE - numRowsInFile(output) > -2);}
0
public void testOffSetAccuracy() throws Exception
{    Map<String, String> metadata = new HashMap<>();    metadata.put("myMetaKey", "myMetaValue");    File input1 = generateData("input1.avro", Type.INT, metadata, DEFLATE);    File output = new File(DIR.getRoot(), name.getMethodName() + ".avro");    output.deleteOnExit();    List<String> args = asList(input1.getAbsolutePath(), "--offset", String.valueOf(OFFSET), "--limit", String.valueOf(LIMIT_WITHIN_INPUT_BOUNDS), "--samplerate", String.valueOf(SAMPLERATE), output.getAbsolutePath());    int returnCode = new CatTool().run(System.in, System.out, System.err, args);    assertEquals(0, returnCode);    assertEquals("output does not start at offset", OFFSET, getFirstIntDatum(output));}
0
public void testOffsetBiggerThanInput() throws Exception
{    Map<String, String> metadata = new HashMap<>();    metadata.put("myMetaKey", "myMetaValue");    File input1 = generateData("input1.avro", Type.INT, metadata, DEFLATE);    File output = new File(DIR.getRoot(), name.getMethodName() + ".avro");    output.deleteOnExit();    List<String> args = asList(input1.getAbsolutePath(), "--offset", String.valueOf(ROWS_IN_INPUT_FILES + 1), output.getAbsolutePath());    int returnCode = new CatTool().run(System.in, System.out, System.err, args);    assertEquals(0, returnCode);    assertEquals("output is not empty", 0, numRowsInFile(output));}
0
public void testSamplerateSmallerThanInput() throws Exception
{    Map<String, String> metadata = new HashMap<>();    metadata.put("myMetaKey", "myMetaValue");    File input1 = generateData("input1.avro", Type.INT, metadata, DEFLATE);    File output = new File(DIR.getRoot(), name.getMethodName() + ".avro");    output.deleteOnExit();    List<String> args = asList(input1.getAbsolutePath(), output.getAbsolutePath(), "--offset=" + Integer.toString(OFFSET), "--samplerate=" + Double.toString(SAMPLERATE_TOO_SMALL));    int returnCode = new CatTool().run(System.in, System.out, System.err, args);    assertEquals(0, returnCode);    assertEquals("output should only contain the record at offset", OFFSET, getFirstIntDatum(output));}
0
public void testDifferentSchemasFail() throws Exception
{    Map<String, String> metadata = new HashMap<>();    metadata.put("myMetaKey", "myMetaValue");    File input1 = generateData("input1.avro", Type.STRING, metadata, DEFLATE);    File input2 = generateData("input2.avro", Type.INT, metadata, DEFLATE);    File output = new File(DIR.getRoot(), name.getMethodName() + ".avro");    output.deleteOnExit();    List<String> args = asList(input1.getAbsolutePath(), input2.getAbsolutePath(), output.getAbsolutePath());    new CatTool().run(System.in, System.out, System.err, args);}
0
public void testHelpfulMessageWhenNoArgsGiven() throws Exception
{    ByteArrayOutputStream buffer = new ByteArrayOutputStream(1024);    int returnCode;    try (PrintStream out = new PrintStream(buffer)) {        returnCode = new CatTool().run(System.in, out, System.err, Collections.emptyList());    }    assertEquals(0, returnCode);    assertTrue("should have lots of help", buffer.toString().trim().length() > 200);}
0
private Object aDatum(Type ofType, int forRow)
{    switch(ofType) {        case STRING:            return String.valueOf(forRow % 100);        case INT:            return forRow;        default:            throw new AssertionError("I can't generate data for this type");    }}
0
private File generateData(String file, Type type, Map<String, String> metadata, CodecFactory codec) throws Exception
{    File inputFile = new File(INPUT_DIR.getRoot(), file);    Schema schema = Schema.create(type);    try (DataFileWriter<Object> writer = new DataFileWriter<>(new GenericDatumWriter<>(schema))) {        for (Entry<String, String> metadatum : metadata.entrySet()) {            writer.setMeta(metadatum.getKey(), metadatum.getValue());        }        writer.setCodec(codec);        writer.create(schema, inputFile);        for (int i = 0; i < ROWS_IN_INPUT_FILES; i++) {            writer.append(aDatum(type, i));        }    }    return inputFile;}
0
private CodecFactory getCodec(File output) throws Exception
{    try (DataFileStream<GenericRecord> reader = new DataFileStream<>(new FileInputStream(output), new GenericDatumReader<>())) {        String codec = reader.getMetaString(DataFileConstants.CODEC);        return codec == null ? CodecFactory.nullCodec() : CodecFactory.fromString(codec);    }}
0
private int numRowsInFile(File output) throws Exception
{    int rowcount = 0;    try (DataFileStream<Utf8> reader = new DataFileStream<>(new FileInputStream(output), new GenericDatumReader<>())) {        for (Utf8 ignored : reader) {            ++rowcount;        }    }    return rowcount;}
0
public void testDirConcat() throws Exception
{    Map<String, String> metadata = new HashMap<>();    for (int i = 0; i < 3; i++) {        generateData(name.getMethodName() + "-" + i + ".avro", Type.STRING, metadata, DEFLATE);    }    File output = new File(OUTPUT_DIR.getRoot(), name.getMethodName() + ".avro");    List<String> args = asList(INPUT_DIR.getRoot().getAbsolutePath(), output.getAbsolutePath());    int returnCode = new ConcatTool().run(System.in, System.out, System.err, args);    assertEquals(0, returnCode);    assertEquals(ROWS_IN_INPUT_FILES * 3, numRowsInFile(output));}
0
public void testGlobPatternConcat() throws Exception
{    Map<String, String> metadata = new HashMap<>();    for (int i = 0; i < 3; i++) {        generateData(name.getMethodName() + "-" + i + ".avro", Type.STRING, metadata, DEFLATE);    }    File output = new File(OUTPUT_DIR.getRoot(), name.getMethodName() + ".avro");    List<String> args = asList(new File(INPUT_DIR.getRoot(), "/*").getAbsolutePath(), output.getAbsolutePath());    int returnCode = new ConcatTool().run(System.in, System.out, System.err, args);    assertEquals(0, returnCode);    assertEquals(ROWS_IN_INPUT_FILES * 3, numRowsInFile(output));}
0
public void testFileDoesNotExist() throws Exception
{    File output = new File(INPUT_DIR.getRoot(), name.getMethodName() + ".avro");    List<String> args = asList(new File(INPUT_DIR.getRoot(), "/doNotExist").getAbsolutePath(), output.getAbsolutePath());    new ConcatTool().run(System.in, System.out, System.err, args);}
0
public void testConcat() throws Exception
{    Map<String, String> metadata = new HashMap<>();    metadata.put("myMetaKey", "myMetaValue");    File input1 = generateData(name.getMethodName() + "-1.avro", Type.STRING, metadata, DEFLATE);    File input2 = generateData(name.getMethodName() + "-2.avro", Type.STRING, metadata, DEFLATE);    File input3 = generateData(name.getMethodName() + "-3.avro", Type.STRING, metadata, DEFLATE);    File output = new File(OUTPUT_DIR.getRoot(), name.getMethodName() + ".avro");    List<String> args = asList(input1.getAbsolutePath(), input2.getAbsolutePath(), input3.getAbsolutePath(), output.getAbsolutePath());    int returnCode = new ConcatTool().run(System.in, System.out, System.err, args);    assertEquals(0, returnCode);    assertEquals(ROWS_IN_INPUT_FILES * 3, numRowsInFile(output));    assertEquals(getCodec(input1).getClass(), getCodec(output).getClass());}
0
public void testDifferentSchemasFail() throws Exception
{    Map<String, String> metadata = new HashMap<>();    metadata.put("myMetaKey", "myMetaValue");    File input1 = generateData(name.getMethodName() + "-1.avro", Type.STRING, metadata, DEFLATE);    File input2 = generateData(name.getMethodName() + "-2.avro", Type.INT, metadata, DEFLATE);    File output = new File(OUTPUT_DIR.getRoot(), name.getMethodName() + ".avro");    List<String> args = asList(input1.getAbsolutePath(), input2.getAbsolutePath(), output.getAbsolutePath());    int returnCode = new ConcatTool().run(System.in, System.out, System.err, args);    assertEquals(1, returnCode);}
0
public void testDifferentMetadataFail() throws Exception
{    Map<String, String> metadata1 = new HashMap<>();    metadata1.put("myMetaKey", "myMetaValue");    Map<String, String> metadata2 = new HashMap<>();    metadata2.put("myOtherMetaKey", "myOtherMetaValue");    File input1 = generateData(name.getMethodName() + "-1.avro", Type.STRING, metadata1, DEFLATE);    File input2 = generateData(name.getMethodName() + "-2.avro", Type.STRING, metadata2, DEFLATE);    File output = new File(OUTPUT_DIR.getRoot(), name.getMethodName() + ".avro");    List<String> args = asList(input1.getAbsolutePath(), input2.getAbsolutePath(), output.getAbsolutePath());    int returnCode = new ConcatTool().run(System.in, System.out, System.err, args);    assertEquals(2, returnCode);}
0
public void testDifferentCodecFail() throws Exception
{    Map<String, String> metadata = new HashMap<>();    metadata.put("myMetaKey", "myMetaValue");    File input1 = generateData(name.getMethodName() + "-1.avro", Type.STRING, metadata, DEFLATE);    File input2 = generateData(name.getMethodName() + "-2.avro", Type.STRING, metadata, CodecFactory.nullCodec());    File output = new File(OUTPUT_DIR.getRoot(), name.getMethodName() + ".avro");    List<String> args = asList(input1.getAbsolutePath(), input2.getAbsolutePath(), output.getAbsolutePath());    int returnCode = new ConcatTool().run(System.in, System.out, System.err, args);    assertEquals(3, returnCode);}
0
public void testHelpfulMessageWhenNoArgsGiven() throws Exception
{    int returnCode;    try (ByteArrayOutputStream buffer = new ByteArrayOutputStream(1024)) {        try (PrintStream out = new PrintStream(buffer)) {            returnCode = new ConcatTool().run(System.in, out, System.err, Collections.emptyList());        }        assertTrue("should have lots of help", buffer.toString().trim().length() > 200);    }    assertEquals(0, returnCode);}
0
public void before()
{    out = new ByteArrayOutputStream();    err = new ByteArrayOutputStream();}
0
public void after() throws Exception
{    out.close();    err.close();}
0
private int run(List<String> args) throws Exception
{    PrintStream output = new PrintStream(out);    PrintStream saveOut = System.out;    PrintStream error = new PrintStream(err);    PrintStream saveErr = System.err;    try {        System.setOut(output);        System.setErr(error);        return new CreateRandomFileTool().run(null, output, error, args);    } finally {        System.setOut(saveOut);        System.setErr(saveErr);    }}
0
private void check(String... extraArgs) throws Exception
{    ArrayList<String> args = new ArrayList<>();    args.addAll(Arrays.asList(OUT_FILE.toString(), "--count", COUNT, "--schema-file", SCHEMA_FILE.toString(), "--seed", Long.toString(SEED)));    args.addAll(Arrays.asList(extraArgs));    run(args);    DataFileReader<Object> reader = new DataFileReader<>(OUT_FILE, new GenericDatumReader<>());    Iterator<Object> found = reader.iterator();    for (Object expected : new RandomData(schemaParser.parse(SCHEMA_FILE), Integer.parseInt(COUNT), SEED)) assertEquals(expected, found.next());    reader.close();}
0
private void checkMissingCount(String... extraArgs) throws Exception
{    ArrayList<String> args = new ArrayList<>();    args.addAll(Arrays.asList(OUT_FILE.toString(), "--schema-file", SCHEMA_FILE.toString(), "--seed", Long.toString(SEED)));    args.addAll(Arrays.asList(extraArgs));    run(args);    assertTrue(err.toString().contains("Need count (--count)"));}
0
public void testSimple() throws Exception
{    check();}
0
public void testCodec() throws Exception
{    check("--codec", "snappy");}
0
public void testMissingCountParameter() throws Exception
{    checkMissingCount();}
0
public void testStdOut() throws Exception
{    TestUtil.resetRandomSeed();    run(Arrays.asList("-", "--count", COUNT, "--schema-file", SCHEMA_FILE.toString(), "--seed", Long.toString(SEED)));    byte[] file = out.toByteArray();    DataFileStream<Object> reader = new DataFileStream<>(new ByteArrayInputStream(file), new GenericDatumReader<>());    Iterator<Object> found = reader.iterator();    for (Object expected : new RandomData(schemaParser.parse(SCHEMA_FILE), Integer.parseInt(COUNT), SEED)) assertEquals(expected, found.next());    reader.close();}
0
public void testDefaultCodec() throws Exception
{        run(Collections.emptyList());    assertTrue(err.toString().contains("Compression codec (default: deflate)"));}
0
public static void writeCorruptFile() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    long pos;        try (DataFileWriter<Utf8> w = new DataFileWriter<>(new GenericDatumWriter<>(SCHEMA))) {        w.create(SCHEMA, baos);        w.append(new Utf8("apple"));        w.append(new Utf8("banana"));        w.append(new Utf8("celery"));        w.sync();        w.append(new Utf8("date"));        w.append(new Utf8("endive"));        w.append(new Utf8("fig"));        pos = w.sync();        w.append(new Utf8("guava"));        w.append(new Utf8("hazelnut"));    }    byte[] original = baos.toByteArray();        int corruptPosition = (int) pos - DataFileConstants.SYNC_SIZE;    int corruptedBytes = 3;    byte[] corrupted = new byte[original.length + corruptedBytes];    System.arraycopy(original, 0, corrupted, 0, corruptPosition);    System.arraycopy(original, corruptPosition, corrupted, corruptPosition + corruptedBytes, original.length - corruptPosition);    corruptBlockFile = new File(DIR.getRoot(), "corruptBlock.avro");    corruptBlockFile.deleteOnExit();    try (FileOutputStream out = new FileOutputStream(corruptBlockFile)) {        out.write(corrupted);    }            corruptPosition = (int) pos - DataFileConstants.SYNC_SIZE - (1 + "fig".length() + 1 + "endive".length());    corrupted = new byte[original.length];    System.arraycopy(original, 0, corrupted, 0, original.length);    BinaryData.encodeLong(-1, corrupted, corruptPosition);    corruptRecordFile = new File(DIR.getRoot(), "corruptRecord.avro");    corruptRecordFile.deleteOnExit();    try (FileOutputStream out = new FileOutputStream(corruptRecordFile)) {        out.write(corrupted);    }}
0
public void setUp()
{    repairedFile = new File(DIR.getRoot(), "repaired.avro");}
0
private String run(Tool tool, String... args) throws Exception
{    return run(tool, null, args);}
0
private String run(Tool tool, InputStream stdin, String... args) throws Exception
{    ByteArrayOutputStream out = new ByteArrayOutputStream();    PrintStream stdout = new PrintStream(out);    tool.run(stdin, stdout, System.err, Arrays.asList(args));    return out.toString("UTF-8").replace("\r", "");}
0
public void testReportCorruptBlock() throws Exception
{    String output = run(new DataFileRepairTool(), "-o", "report", corruptBlockFile.getPath());    assertTrue(output, output.contains("Number of blocks: 2 Number of corrupt blocks: 1"));    assertTrue(output, output.contains("Number of records: 5 Number of corrupt records: 0"));}
0
public void testReportCorruptRecord() throws Exception
{    String output = run(new DataFileRepairTool(), "-o", "report", corruptRecordFile.getPath());    assertTrue(output, output.contains("Number of blocks: 3 Number of corrupt blocks: 1"));    assertTrue(output, output.contains("Number of records: 8 Number of corrupt records: 2"));}
0
public void testRepairAllCorruptBlock() throws Exception
{    String output = run(new DataFileRepairTool(), "-o", "all", corruptBlockFile.getPath(), repairedFile.getPath());    assertTrue(output, output.contains("Number of blocks: 2 Number of corrupt blocks: 1"));    assertTrue(output, output.contains("Number of records: 5 Number of corrupt records: 0"));    checkFileContains(repairedFile, "apple", "banana", "celery", "guava", "hazelnut");}
0
public void testRepairAllCorruptRecord() throws Exception
{    String output = run(new DataFileRepairTool(), "-o", "all", corruptRecordFile.getPath(), repairedFile.getPath());    assertTrue(output, output.contains("Number of blocks: 3 Number of corrupt blocks: 1"));    assertTrue(output, output.contains("Number of records: 8 Number of corrupt records: 2"));    checkFileContains(repairedFile, "apple", "banana", "celery", "date", "guava", "hazelnut");}
0
public void testRepairPriorCorruptBlock() throws Exception
{    String output = run(new DataFileRepairTool(), "-o", "prior", corruptBlockFile.getPath(), repairedFile.getPath());    assertTrue(output, output.contains("Number of blocks: 2 Number of corrupt blocks: 1"));    assertTrue(output, output.contains("Number of records: 5 Number of corrupt records: 0"));    checkFileContains(repairedFile, "apple", "banana", "celery");}
0
public void testRepairPriorCorruptRecord() throws Exception
{    String output = run(new DataFileRepairTool(), "-o", "prior", corruptRecordFile.getPath(), repairedFile.getPath());    assertTrue(output, output.contains("Number of blocks: 3 Number of corrupt blocks: 1"));    assertTrue(output, output.contains("Number of records: 8 Number of corrupt records: 2"));    checkFileContains(repairedFile, "apple", "banana", "celery", "date");}
0
public void testRepairAfterCorruptBlock() throws Exception
{    String output = run(new DataFileRepairTool(), "-o", "after", corruptBlockFile.getPath(), repairedFile.getPath());    assertTrue(output, output.contains("Number of blocks: 2 Number of corrupt blocks: 1"));    assertTrue(output, output.contains("Number of records: 5 Number of corrupt records: 0"));    checkFileContains(repairedFile, "guava", "hazelnut");}
0
public void testRepairAfterCorruptRecord() throws Exception
{    String output = run(new DataFileRepairTool(), "-o", "after", corruptRecordFile.getPath(), repairedFile.getPath());    assertTrue(output, output.contains("Number of blocks: 3 Number of corrupt blocks: 1"));    assertTrue(output, output.contains("Number of records: 8 Number of corrupt records: 2"));    checkFileContains(repairedFile, "guava", "hazelnut");}
0
private void checkFileContains(File repairedFile, String... lines) throws IOException
{    DataFileReader r = new DataFileReader<>(repairedFile, new GenericDatumReader<>(SCHEMA));    for (String line : lines) {        assertEquals(line, r.next().toString());    }    assertFalse(r.hasNext());}
0
public static void writeSampleFile() throws IOException
{    sampleFile = new File(DIR.getRoot(), TestDataFileTools.class.getName() + ".avro");    schema = Schema.create(Type.INT);    schemaFile = new File(DIR.getRoot(), "schema-temp.schema");    try (FileWriter fw = new FileWriter(schemaFile)) {        fw.append(schema.toString());    }    StringBuilder builder = new StringBuilder();    try (DataFileWriter<Object> writer = new DataFileWriter<>(new GenericDatumWriter<>(schema))) {        writer.setMeta(KEY_NEEDING_ESCAPES, "");        writer.create(schema, sampleFile);        for (int i = 0; i < COUNT; ++i) {            builder.append(Integer.toString(i));            builder.append("\n");            writer.append(i);        }    }    jsonData = builder.toString();}
0
private String run(Tool tool, String... args) throws Exception
{    return run(tool, null, args);}
0
private String run(Tool tool, InputStream stdin, String... args) throws Exception
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    PrintStream p = new PrintStream(baos);        tool.run(    stdin,     p,     null, Arrays.asList(args));    return baos.toString("UTF-8").replace("\r", "");}
0
public void testRead() throws Exception
{    assertEquals(jsonData, run(new DataFileReadTool(), sampleFile.getPath()));}
0
public void testReadStdin() throws Exception
{    FileInputStream stdin = new FileInputStream(sampleFile);    assertEquals(jsonData, run(new DataFileReadTool(), stdin, "-"));}
0
public void testReadToJsonPretty() throws Exception
{    assertEquals(jsonData, run(new DataFileReadTool(), "--pretty", sampleFile.getPath()));}
0
public void testReadHeadDefaultCount() throws Exception
{        String expectedJson = jsonData.substring(0, 20);    assertEquals(expectedJson, run(new DataFileReadTool(), "--head", sampleFile.getPath()));}
0
public void testReadHeadEquals3Count() throws Exception
{        String expectedJson = jsonData.substring(0, 6);    assertEquals(expectedJson, run(new DataFileReadTool(), "--head=3", sampleFile.getPath()));}
0
public void testReadHeadSpace5Count() throws Exception
{        String expectedJson = jsonData.substring(0, 10);    assertEquals(expectedJson, run(new DataFileReadTool(), "--head", "5", sampleFile.getPath()));}
0
public void testReadHeadLongCount() throws Exception
{    assertEquals(jsonData, run(new DataFileReadTool(), "--head=3000000000", sampleFile.getPath()));}
0
public void testReadHeadEqualsZeroCount() throws Exception
{    assertEquals("\n", run(new DataFileReadTool(), "--head=0", sampleFile.getPath()));}
0
public void testReadHeadNegativeCount() throws Exception
{    assertEquals("\n", run(new DataFileReadTool(), "--head=-5", sampleFile.getPath()));}
0
public void testGetMeta() throws Exception
{    String output = run(new DataFileGetMetaTool(), sampleFile.getPath());    assertTrue(output, output.contains("avro.schema\t" + schema.toString() + "\n"));    assertTrue(output, output.contains(ESCAPED_KEY + "\t\n"));}
0
public void testGetMetaForSingleKey() throws Exception
{    assertEquals(schema.toString() + "\n", run(new DataFileGetMetaTool(), sampleFile.getPath(), "--key", "avro.schema"));}
0
public void testGetSchema() throws Exception
{    assertEquals(schema.toString() + "\n", run(new DataFileGetSchemaTool(), sampleFile.getPath()));}
0
public void testWriteWithDeflate() throws Exception
{    testWrite("deflate", Arrays.asList("--codec", "deflate"), "deflate");}
0
public void testWrite() throws Exception
{    testWrite("plain", Collections.emptyList(), "null");}
0
public void testWrite(String name, List<String> extra, String expectedCodec) throws Exception
{    testWrite(name, extra, expectedCodec, "-schema", schema.toString());    testWrite(name, extra, expectedCodec, "-schema-file", schemaFile.toString());}
0
public void testWrite(String name, List<String> extra, String expectedCodec, String... extraArgs) throws Exception
{    File outFile = new File(DIR.getRoot(), TestDataFileTools.class + ".testWrite." + name + ".avro");    try (FileOutputStream fout = new FileOutputStream(outFile)) {        try (PrintStream out = new PrintStream(fout)) {            List<String> args = new ArrayList<>();            Collections.addAll(args, extraArgs);            args.add("-");            args.addAll(extra);                        new DataFileWriteTool().run(            new ByteArrayInputStream(jsonData.getBytes("UTF-8")),             new PrintStream(out),             null, args);        }    }        GenericDatumReader<Object> reader = new GenericDatumReader<>();    try (DataFileReader<Object> fileReader = new DataFileReader<>(outFile, reader)) {        int i = 0;        for (Object datum : fileReader) {            assertEquals(i, datum);            i++;        }        assertEquals(COUNT, i);        assertEquals(schema, fileReader.getSchema());        String codecStr = fileReader.getMetaString("avro.codec");        if (null == codecStr) {            codecStr = "null";        }        assertEquals(expectedCodec, codecStr);    }}
0
public void testFailureOnWritingPartialJSONValues() throws Exception
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    PrintStream out = new PrintStream(baos);        new DataFileWriteTool().run(    new ByteArrayInputStream("{".getBytes("UTF-8")),     new PrintStream(out),     null, Arrays.asList("-schema", "{ \"type\":\"record\", \"fields\":" + "[{\"name\":\"foo\", \"type\":\"string\"}], " + "\"name\":\"boring\" }", "-"));}
0
public void testWritingZeroJsonValues() throws Exception
{    File outFile = writeToAvroFile("zerojsonvalues", schema.toString(), "");    assertEquals(0, countRecords(outFile));}
0
private int countRecords(File outFile) throws IOException
{    GenericDatumReader<Object> reader = new GenericDatumReader<>();    try (DataFileReader<Object> fileReader = new DataFileReader<>(outFile, reader)) {        int i = 0;        for (@SuppressWarnings("unused") Object datum : fileReader) {            i++;        }        return i;    }}
0
public void testDifferentSeparatorsBetweenJsonRecords() throws Exception
{    File outFile = writeToAvroFile("separators", "{ \"type\":\"array\", \"items\":\"int\" }", "[]    [] []\n[][3]     ");    assertEquals(5, countRecords(outFile));}
0
public File writeToAvroFile(String testName, String schema, String json) throws Exception
{    File outFile = new File(DIR.getRoot(), TestDataFileTools.class + "." + testName + ".avro");    try (FileOutputStream fout = new FileOutputStream(outFile)) {        try (PrintStream out = new PrintStream(fout)) {                        new DataFileWriteTool().run(            new ByteArrayInputStream(json.getBytes("UTF-8")),             new PrintStream(out),             null, Arrays.asList("-schema", schema, "-"));        }    }    return outFile;}
0
public void testDefaultCodec() throws Exception
{        ByteArrayOutputStream baos = new ByteArrayOutputStream();    PrintStream err = new PrintStream(baos);    new DataFileWriteTool().run(new ByteArrayInputStream(jsonData.getBytes()), null, err, Collections.emptyList());    assertTrue(baos.toString().contains("Compression codec (default: null)"));}
0
public void testSplitIdlIntoSchemata() throws Exception
{    String idl = "src/test/idl/protocol.avdl";    String outdir = "target/test-split";    List<String> arglist = Arrays.asList(idl, outdir);    new IdlToSchemataTool().run(null, null, null, arglist);    String[] files = new File(outdir).list();    assertEquals(4, files.length);}
0
public void testBinaryToJson() throws Exception
{    binaryToJson(AVRO, JSON, STRING_SCHEMA);}
0
public void testJsonToBinary() throws Exception
{    jsonToBinary(JSON, AVRO, STRING_SCHEMA);}
0
public void testMultiBinaryToJson() throws Exception
{    binaryToJson(AVRO + AVRO + AVRO, JSON + JSON + JSON, STRING_SCHEMA);}
0
public void testMultiJsonToBinary() throws Exception
{    jsonToBinary(JSON + JSON + JSON, AVRO + AVRO + AVRO, STRING_SCHEMA);}
0
public void testBinaryToNoPrettyJson() throws Exception
{    binaryToJson(AVRO, JSON, "--no-pretty", STRING_SCHEMA);}
0
public void testMultiBinaryToNoPrettyJson() throws Exception
{    binaryToJson(AVRO + AVRO + AVRO, JSON + JSON + JSON, "--no-pretty", STRING_SCHEMA);}
0
public void testBinaryToJsonSchemaFile() throws Exception
{    binaryToJson(AVRO, JSON, "--schema-file", schemaFile(DIR.getRoot()));}
0
public void testJsonToBinarySchemaFile() throws Exception
{    jsonToBinary(JSON, AVRO, "--schema-file", schemaFile(DIR.getRoot()));}
0
private void binaryToJson(String avro, String json, String... options) throws Exception
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    PrintStream p = new PrintStream(new BufferedOutputStream(baos));    List<String> args = new ArrayList<>(Arrays.asList(options));    args.add("-");        new BinaryFragmentToJsonTool().run(    new ByteArrayInputStream(avro.getBytes(StandardCharsets.UTF_8)),     p,     null, args);    System.out.println(baos.toString(UTF8).replace("\r", ""));    assertEquals(json, baos.toString(UTF8).replace("\r", ""));}
0
private void jsonToBinary(String json, String avro, String... options) throws Exception
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    PrintStream p = new PrintStream(new BufferedOutputStream(baos));    List<String> args = new ArrayList<>(Arrays.asList(options));    args.add("-");        new JsonToBinaryFragmentTool().run(    new ByteArrayInputStream(json.getBytes(StandardCharsets.UTF_8)),     p,     null, args);    assertEquals(avro, baos.toString(UTF8));}
0
private static String schemaFile(File dir) throws IOException
{    File schemaFile = new File(dir, "String.avsc");    try (FileWriter fw = new FileWriter(schemaFile)) {        fw.append(STRING_SCHEMA);    }    return schemaFile.toString();}
0
public void testToolDescriptionLength()
{    Main m = new Main();    for (Tool t : m.tools.values()) {                if (m.maxLen + 2 + t.getShortDescription().length() > 80) {            fail("Tool description too long: " + t.getName());        }    }}
0
public void testToolNameLength()
{        final int MAX_NAME_LENGTH = 13;    Main m = new Main();    for (Tool t : m.tools.values()) {        if (t.getName().length() > MAX_NAME_LENGTH) {            fail("Tool name too long (" + t.getName().length() + "): " + t.getName() + ". Max length is: " + MAX_NAME_LENGTH);        }    }}
0
public void testRecodec() throws Exception
{    String metaKey = "myMetaKey";    String metaValue = "myMetaValue";    File inputFile = new File(DIR.getRoot(), "input.avro");    Schema schema = Schema.create(Type.STRING);    DataFileWriter<String> writer = new DataFileWriter<>(new GenericDatumWriter<String>(schema)).setMeta(metaKey, metaValue).create(schema, inputFile);        for (int i = 0; i < 100000; i++) {        writer.append("" + i % 100);    }    writer.close();    File defaultOutputFile = new File(DIR.getRoot(), "default-output.avro");    File nullOutputFile = new File(DIR.getRoot(), "null-output.avro");    File deflateDefaultOutputFile = new File(DIR.getRoot(), "deflate-default-output.avro");    File deflate1OutputFile = new File(DIR.getRoot(), "deflate-1-output.avro");    File deflate9OutputFile = new File(DIR.getRoot(), "deflate-9-output.avro");    new RecodecTool().run(new FileInputStream(inputFile), new PrintStream(defaultOutputFile), null, new ArrayList<>());    new RecodecTool().run(new FileInputStream(inputFile), new PrintStream(nullOutputFile), null, Collections.singletonList("--codec=null"));    new RecodecTool().run(new FileInputStream(inputFile), new PrintStream(deflateDefaultOutputFile), null, Collections.singletonList("--codec=deflate"));    new RecodecTool().run(new FileInputStream(inputFile), new PrintStream(deflate1OutputFile), null, asList("--codec=deflate", "--level=1"));    new RecodecTool().run(new FileInputStream(inputFile), new PrintStream(deflate9OutputFile), null, asList("--codec=deflate", "--level=9"));            Assert.assertEquals(metaValue, new DataFileReader<Void>(defaultOutputFile, new GenericDatumReader<>()).getMetaString(metaKey));        Assert.assertEquals(defaultOutputFile.length(), nullOutputFile.length());        assertLessThan(deflateDefaultOutputFile.length(), nullOutputFile.length());    assertLessThan(deflate1OutputFile.length(), nullOutputFile.length());    assertLessThan(deflate9OutputFile.length(), nullOutputFile.length());        assertLessThan(deflate9OutputFile.length(), deflate1OutputFile.length());}
0
private static void assertLessThan(long less, long more)
{    if (less >= more) {        Assert.fail("Expected " + less + " to be less than " + more);    }}
0
public static List<Object[]> data()
{    return Arrays.asList(new Object[] { "http" }, new Object[] { "avro" });}
0
public void setUp() throws Exception
{    String protocolFile = System.getProperty("share.dir", "../../../share") + "/test/schemas/simple.avpr";    simpleProtocol = Protocol.parse(new File(protocolFile));        ByteArrayOutputStream baos1 = new ByteArrayOutputStream();    PrintStream p1 = new PrintStream(baos1);    receive = new RpcReceiveTool();    receive.run1(null, p1, System.err, Arrays.asList(uriScheme + "://0.0.0.0:0/", protocolFile, "hello", "-data", "\"Hello!\""));}
0
public void tearDown() throws Exception
{    if (receive != null)                receive.server.close();}
0
public void testRpcProtocol() throws Exception
{        ByteArrayOutputStream baos2 = new ByteArrayOutputStream();    PrintStream p2 = new PrintStream(baos2, true, "UTF-8");    RpcProtocolTool testObject = new RpcProtocolTool();    testObject.run(null, p2, System.err, Collections.singletonList(uriScheme + "://127.0.0.1:" + receive.server.getPort() + "/"));    p2.flush();    assertEquals("Expected the simple.avpr protocol to be echoed to standout", simpleProtocol, Protocol.parse(baos2.toString("UTF-8")));}
0
public void testServeAndSend() throws Exception
{    String protocolFile = System.getProperty("share.dir", "../../../share") + "/test/schemas/simple.avpr";    ByteArrayOutputStream baos1 = new ByteArrayOutputStream();    PrintStream p1 = new PrintStream(baos1);    RpcReceiveTool receive = new RpcReceiveTool();    receive.run1(null, p1, System.err, Arrays.asList("http://0.0.0.0:0/", protocolFile, "hello", "-data", "\"Hello!\""));    ByteArrayOutputStream baos2 = new ByteArrayOutputStream();    PrintStream p2 = new PrintStream(baos2);    RpcSendTool send = new RpcSendTool();    send.run(null, p2, System.err, Arrays.asList("http://127.0.0.1:" + receive.server.getPort() + "/", protocolFile, "hello", "-data", "{ \"greeting\": \"Hi!\" }"));    receive.run2(System.err);    assertTrue(baos1.toString("UTF-8").replace("\r", "").endsWith("hello\t{\"greeting\":\"Hi!\"}\n"));    assertEquals("\"Hello!\"\n", baos2.toString("UTF-8").replace("\r", ""));}
0
public void setUp()
{    TEST_OUTPUT_DIR.delete();}
0
public void testCompileSchemaSingleFile() throws Exception
{    doCompile(new String[] { "-encoding", "UTF-8", "schema", TEST_INPUT_DIR.toString() + "/position.avsc", TEST_OUTPUT_DIR.getPath() });    assertFileMatch(TEST_EXPECTED_POSITION, TEST_OUTPUT_POSITION);}
0
public void testCompileSchemaTwoFiles() throws Exception
{    doCompile(new String[] { "-encoding", "UTF-8", "schema", TEST_INPUT_DIR.toString() + "/position.avsc", TEST_INPUT_DIR.toString() + "/player.avsc", TEST_OUTPUT_DIR.getPath() });    assertFileMatch(TEST_EXPECTED_POSITION, TEST_OUTPUT_POSITION);    assertFileMatch(TEST_EXPECTED_PLAYER, TEST_OUTPUT_PLAYER);}
0
public void testCompileSchemaFileAndDirectory() throws Exception
{    doCompile(new String[] { "-encoding", "UTF-8", "schema", TEST_INPUT_DIR.toString() + "/position.avsc", TEST_INPUT_DIR.toString(), TEST_OUTPUT_DIR.getPath() });    assertFileMatch(TEST_EXPECTED_POSITION, TEST_OUTPUT_POSITION);    assertFileMatch(TEST_EXPECTED_PLAYER, TEST_OUTPUT_PLAYER);}
0
public void testCompileSchemasUsingString() throws Exception
{    doCompile(new String[] { "-encoding", "UTF-8", "-string", "schema", TEST_INPUT_DIR.toString() + "/position.avsc", TEST_INPUT_DIR.toString() + "/player.avsc", TEST_OUTPUT_STRING_DIR.getPath() });    assertFileMatch(TEST_EXPECTED_STRING_POSITION, TEST_OUTPUT_STRING_POSITION);    assertFileMatch(TEST_EXPECTED_STRING_PLAYER, TEST_OUTPUT_STRING_PLAYER);}
0
public void testCompileSchemasWithVariousFieldTypes() throws Exception
{    doCompile(new String[] { "-encoding", "UTF-8", "-string", "schema", TEST_INPUT_DIR.toString() + "/fieldtest.avsc", TEST_INPUT_DIR.toString() + "/fieldtest.avsc", TEST_OUTPUT_STRING_DIR.getPath() });    assertFileMatch(TEST_EXPECTED_STRING_FIELDTEST, TEST_OUTPUT_STRING_FIELDTEST);}
0
private void doCompile(String[] args) throws Exception
{    SpecificCompilerTool tool = new SpecificCompilerTool();    tool.run(null, null, null, Arrays.asList((args)));}
0
private static void assertFileMatch(File expected, File found) throws IOException
{    Assert.assertEquals("Found file: " + found + " does not match expected file: " + expected, readFile(expected), readFile(found));}
0
private static String readFile(File file) throws IOException
{    BufferedReader reader = new BufferedReader(new InputStreamReader(new FileInputStream(file), "UTF-8"));    StringBuilder sb = new StringBuilder();    String line = null;    boolean first = true;    while ((line = reader.readLine()) != null) {        if (!first) {            sb.append("\n");            first = false;        }        sb.append(line);    }    return sb.toString();}
0
public void test() throws Exception
{        Schema outscheme = new Pair<Utf8, Long>(new Utf8(""), 0L).getSchema();        File midscfile = new File(INPUT_DIR.getRoot().getPath(), "midschema.avpr");    try (FileWriter hf = new FileWriter(midscfile)) {        hf.write(outscheme.toString());    }    JobConf job = new JobConf();    String inputPathStr = INPUT_DIR.getRoot().getPath();    String outputPathStr = OUTPUT_DIR.getRoot().getPath();    Path outputPath = new Path(outputPathStr);    outputPath.getFileSystem(job).delete(outputPath, true);        WordCountUtil.writeLinesFile(inputPathStr + "/lines.avro");        String execargs = "-classpath " + System.getProperty("java.class.path");    execargs += " org.apache.avro.mapred.tether.WordCountTask";        java.util.List<String> runargs = new java.util.ArrayList<>();    runargs.addAll(java.util.Arrays.asList("--program", "java"));    runargs.addAll(asList("--exec_args", '"' + execargs + '"'));    runargs.addAll(asList("--exec_cached", "false"));    runargs.addAll(asList("--in", inputPathStr));    runargs.addAll(asList("--out", outputPath.toString()));    runargs.addAll(asList("--outschema", midscfile.toString()));    TetherTool tool = new TetherTool();    tool.run(null, null, System.err, runargs);            int numWords = 0;    DatumReader<Pair<Utf8, Long>> reader = new SpecificDatumReader<>();    try (InputStream cin = new BufferedInputStream(new FileInputStream(outputPathStr + "/part-00000.avro"))) {        DataFileStream<Pair<Utf8, Long>> counts = new DataFileStream<>(cin, reader);        for (Pair<Utf8, Long> wc : counts) {            assertEquals(wc.key().toString(), WordCountUtil.COUNTS.get(wc.key().toString()), wc.value());            numWords++;        }    }    assertEquals(WordCountUtil.COUNTS.size(), numWords);}
0
public static void writeRandomFile() throws IOException
{    schema = Schema.create(Type.BYTES);    lines = new ByteBuffer[COUNT];    linesFile = new File(DIR.getRoot(), "random.lines");    OutputStream out = new BufferedOutputStream(new FileOutputStream(linesFile));    Random rand = new Random();    for (int j = 0; j < COUNT; j++) {        byte[] line = new byte[rand.nextInt(512)];        System.out.println("Creating line = " + line.length);        for (int i = 0; i < line.length; i++) {            int b = rand.nextInt(256);            while (b == '\n' || b == '\r') b = rand.nextInt(256);            line[i] = (byte) b;        }        out.write(line);        out.write(LINE_SEP);        lines[j] = ByteBuffer.wrap(line);    }    out.close();}
0
private void fromText(String name, String... args) throws Exception
{    File avroFile = new File(DIR.getRoot(), name + ".avro");    ArrayList<String> arglist = new ArrayList<>(Arrays.asList(args));    arglist.add(linesFile.toString());    arglist.add(avroFile.toString());    new FromTextTool().run(null, null, null, arglist);        DataFileReader<ByteBuffer> file = new DataFileReader<>(avroFile, new GenericDatumReader<>());    int i = 0;    for (ByteBuffer line : file) {        System.out.println("Reading line = " + line.remaining());        assertEquals(line, lines[i]);        i++;    }    assertEquals(COUNT, i);}
0
public void testFromText() throws Exception
{    fromText("null", "--codec", "null");    fromText("deflate", "--codec", "deflate");    fromText("snappy", "--codec", "snappy");}
0
public static void testToText() throws Exception
{    toText("null");    toText("deflate");    toText("snappy");}
0
private static void toText(String name) throws Exception
{    File avroFile = new File(DIR.getRoot(), name + ".avro");    File outFile = new File(DIR.getRoot(), name + ".lines");    ArrayList<String> arglist = new ArrayList<>();    arglist.add(avroFile.toString());    arglist.add(outFile.toString());    new ToTextTool().run(null, null, null, arglist);        try (InputStream orig = new BufferedInputStream(new FileInputStream(linesFile))) {        try (InputStream after = new BufferedInputStream(new FileInputStream(outFile))) {            int b;            while ((b = orig.read()) != -1) {                assertEquals(b, after.read());            }            assertEquals(-1, after.read());        }    }}
0
public void testDefaultCodec() throws Exception
{        ByteArrayOutputStream baos = new ByteArrayOutputStream();    PrintStream err = new PrintStream(baos);    new FromTextTool().run(null, null, err, Collections.emptyList());    Assert.assertTrue(baos.toString().contains("Compression codec (default: deflate)"));}
0
private String run(String... args) throws Exception
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    PrintStream p = new PrintStream(baos);    new ToTrevniTool().run(null, p, null, Arrays.asList(args));    return baos.toString("UTF-8").replace("\r", "");}
0
public void test() throws Exception
{    Schema schema = new Schema.Parser().parse(SCHEMA_FILE);    DataFileWriter<Object> writer = new DataFileWriter<>(new GenericDatumWriter<>());    writer.create(schema, Util.createFromFS(AVRO_FILE.toString()));    for (Object datum : new RandomData(schema, COUNT, SEED)) writer.append(datum);    writer.close();    run(AVRO_FILE.toString(), TREVNI_FILE.toString());    AvroColumnReader<Object> reader = new AvroColumnReader<>(new AvroColumnReader.Params(TREVNI_FILE));    Iterator<Object> found = reader.iterator();    for (Object expected : new RandomData(schema, COUNT, SEED)) assertEquals(expected, found.next());    reader.close();}
0
private void zstandardCompressionLevel(int level) throws Exception
{    OptionParser optParser = new OptionParser();    OptionSpec<String> codecOpt = Util.compressionCodecOption(optParser);    OptionSpec<Integer> levelOpt = Util.compressionLevelOption(optParser);    OptionSet opts = optParser.parse(new String[] { "--codec", "zstandard", "--level", String.valueOf(level) });    CodecFactory codecFactory = Util.codecFactory(opts, codecOpt, levelOpt);    Method createInstance = CodecFactory.class.getDeclaredMethod("createInstance");    createInstance.setAccessible(true);    Codec codec = (ZstandardCodec) createInstance.invoke(codecFactory);    Assert.assertEquals(String.format("zstandard[%d]", level), codec.toString());}
0
public void testCodecFactoryZstandardCompressionLevel() throws Exception
{    zstandardCompressionLevel(1);    zstandardCompressionLevel(CodecFactory.DEFAULT_ZSTANDARD_LEVEL);}
0
public ColumnMetaData[] getColumns()
{    return columns.toArray(new ColumnMetaData[0]);}
0
public int[] getArrayWidths()
{    int[] result = new int[arrayWidths.size()];    int i = 0;    for (Integer width : arrayWidths) result[i++] = width;    return result;}
0
private void columnize(String path, Schema s, ColumnMetaData parent, boolean isArray)
{    if (isSimple(s)) {        if (path == null)            path = s.getFullName();        addColumn(path, simpleValueType(s), parent, isArray);        return;    }    if (    seen.containsKey(s))        throw new TrevniRuntimeException("Cannot shred recursive schemas: " + s);    seen.put(s, s);    switch(s.getType()) {        case MAP:            path = path == null ? ">" : path + ">";            int start = columns.size();            ColumnMetaData p = addColumn(path, ValueType.NULL, parent, true);            addColumn(p(path, "key", ""), ValueType.STRING, p, false);            columnize(p(path, "value", ""), s.getValueType(), p, false);                        arrayWidths.set(start, columns.size() - start);            break;        case RECORD:            for (            Field field :             s.getFields()) columnize(p(path, field.name(), "#"), field.schema(), parent, isArray);            break;        case ARRAY:            path = path == null ? "[]" : path + "[]";            addArrayColumn(path, s.getElementType(), parent);            break;        case UNION:            for (            Schema branch :             s.getTypes()) if (branch.getType() != Schema.Type.NULL)                addArrayColumn(p(path, branch, "/"), branch, parent);            break;        default:            throw new TrevniRuntimeException("Unknown schema: " + s);    }    seen.remove(s);}
0
private String p(String parent, Schema child, String sep)
{    if (child.getType() == Schema.Type.UNION)        return parent;    return p(parent, child.getFullName(), sep);}
0
private String p(String parent, String child, String sep)
{    return parent == null ? child : parent + sep + child;}
0
private ColumnMetaData addColumn(String path, ValueType type, ColumnMetaData parent, boolean isArray)
{    ColumnMetaData column = new ColumnMetaData(path, type);    if (parent != null)        column.setParent(parent);    column.isArray(isArray);    columns.add(column);        arrayWidths.add(1);    return column;}
0
private void addArrayColumn(String path, Schema element, ColumnMetaData parent)
{    if (path == null)        path = element.getFullName();    if (isSimple(element)) {                addColumn(path, simpleValueType(element), parent, true);        return;    }        int start = columns.size();    ColumnMetaData array = addColumn(path, ValueType.NULL, parent, true);    columnize(path, element, array, false);        arrayWidths.set(start, columns.size() - start);}
0
 static boolean isSimple(Schema s)
{    switch(s.getType()) {        case NULL:        case BOOLEAN:        case INT:        case LONG:        case FLOAT:        case DOUBLE:        case BYTES:        case STRING:        case ENUM:        case FIXED:            return true;        default:            return false;    }}
0
private ValueType simpleValueType(Schema s)
{    switch(s.getType()) {        case NULL:            return ValueType.NULL;        case BOOLEAN:            return ValueType.BOOLEAN;        case INT:            return ValueType.INT;        case LONG:            return ValueType.LONG;        case FLOAT:            return ValueType.FLOAT;        case DOUBLE:            return ValueType.DOUBLE;        case BYTES:            return ValueType.BYTES;        case STRING:            return ValueType.STRING;        case ENUM:            return ValueType.INT;        case FIXED:            return ValueType.BYTES;        default:            throw new TrevniRuntimeException("Unknown schema: " + s);    }}
0
public Params setSchema(Schema schema)
{    this.schema = schema;    return this;}
0
public Params setModel(GenericData model)
{    this.model = model;    return this;}
0
public Schema getFileSchema()
{    return fileSchema;}
0
 void initialize() throws IOException
{        Map<String, Integer> fileColumnNumbers = new HashMap<>();    int i = 0;    for (ColumnMetaData c : new AvroColumnator(fileSchema).getColumns()) fileColumnNumbers.put(c.getName(), i++);        AvroColumnator readColumnator = new AvroColumnator(readSchema);    this.arrayWidths = readColumnator.getArrayWidths();    ColumnMetaData[] readColumns = readColumnator.getColumns();    this.values = new ColumnValues[readColumns.length];    int j = 0;    for (ColumnMetaData c : readColumns) {        Integer n = fileColumnNumbers.get(c.getName());        if (n != null)            values[j++] = reader.getValues(n);    }    findDefaults(readSchema, fileSchema);}
0
private void findDefaults(Schema read, Schema write)
{    switch(read.getType()) {        case NULL:        case BOOLEAN:        case INT:        case LONG:        case FLOAT:        case DOUBLE:        case BYTES:        case STRING:        case ENUM:        case FIXED:            if (read.getType() != write.getType())                throw new TrevniRuntimeException("Type mismatch: " + read + " & " + write);            break;        case MAP:            findDefaults(read.getValueType(), write.getValueType());            break;        case ARRAY:            findDefaults(read.getElementType(), write.getElementType());            break;        case UNION:            for (Schema s : read.getTypes()) {                Integer index = write.getIndexNamed(s.getFullName());                if (index == null)                    throw new TrevniRuntimeException("No matching branch: " + s);                findDefaults(s, write.getTypes().get(index));            }            break;        case RECORD:            for (Field f : read.getFields()) {                Field g = write.getField(f.name());                if (g == null)                    setDefault(read, f);                else                    findDefaults(f.schema(), g.schema());            }            break;        default:            throw new TrevniRuntimeException("Unknown schema: " + read);    }}
0
private void setDefault(Schema record, Field f)
{    String recordName = record.getFullName();    Map<String, Object> recordDefaults = defaults.computeIfAbsent(recordName, k -> new HashMap<>());    recordDefaults.put(f.name(), model.getDefaultValue(f));}
0
public Iterator<D> iterator()
{    return this;}
0
public boolean hasNext()
{    return values[0].hasNext();}
0
public long getRowCount()
{    return reader.getRowCount();}
0
public D next()
{    try {        for (ColumnValues value : values) if (value != null)            value.startRow();        this.column = 0;        return (D) read(readSchema);    } catch (IOException e) {        throw new TrevniRuntimeException(e);    }}
0
private Object read(Schema s) throws IOException
{    if (isSimple(s))        return nextValue(s, column++);    final int startColumn = column;    switch(s.getType()) {        case MAP:            int size = values[column].nextLength();            Map map = new HashMap(size);            for (int i = 0; i < size; i++) {                this.column = startColumn;                                values[column++].nextValue();                                String key = (String) values[column++].nextValue();                                map.put(key, read(s.getValueType()));            }            column = startColumn + arrayWidths[startColumn];            return map;        case RECORD:            Object record = model.newRecord(null, s);            Map<String, Object> rDefaults = defaults.get(s.getFullName());            for (Field f : s.getFields()) {                Object value = ((rDefaults != null) && rDefaults.containsKey(f.name())) ? model.deepCopy(f.schema(), rDefaults.get(f.name())) : read(f.schema());                model.setField(record, f.name(), f.pos(), value);            }            return record;        case ARRAY:            int length = values[column].nextLength();            List elements = new GenericData.Array(length, s);            for (int i = 0; i < length; i++) {                this.column = startColumn;                Object value = nextValue(s, column++);                if (!isSimple(s.getElementType()))                    value = read(s.getElementType());                elements.add(value);            }            column = startColumn + arrayWidths[startColumn];            return elements;        case UNION:            Object value = null;            for (Schema branch : s.getTypes()) {                if (branch.getType() == Schema.Type.NULL)                    continue;                if (values[column].nextLength() == 1) {                    value = nextValue(branch, column);                    column++;                    if (!isSimple(branch))                        value = read(branch);                } else {                    column += arrayWidths[column];                }            }            return value;        default:            throw new TrevniRuntimeException("Unknown schema: " + s);    }}
0
private Object nextValue(Schema s, int column) throws IOException
{    Object v = values[column].nextValue();    switch(s.getType()) {        case ENUM:            return model.createEnum(s.getEnumSymbols().get((Integer) v), s);        case FIXED:            return model.createFixed(null, ((ByteBuffer) v).array(), s);    }    return v;}
0
public void remove()
{    throw new UnsupportedOperationException();}
0
public void close() throws IOException
{    reader.close();}
0
public long sizeEstimate()
{    return writer.sizeEstimate();}
0
public void writeTo(OutputStream out) throws IOException
{    writer.writeTo(out);}
0
public void writeTo(File file) throws IOException
{    writer.writeTo(file);}
0
public void write(D value) throws IOException
{    writer.startRow();    int count = write(value, schema, 0);    assert (count == writer.getColumnCount());    writer.endRow();}
0
private int write(Object o, Schema s, int column) throws IOException
{    if (isSimple(s)) {        writeValue(o, s, column);        return column + 1;    }    switch(s.getType()) {        case MAP:            Map<?, ?> map = (Map) o;            writer.writeLength(map.size(), column);            for (Map.Entry e : map.entrySet()) {                writer.writeValue(null, column);                writer.writeValue(e.getKey(), column + 1);                int c = write(e.getValue(), s.getValueType(), column + 2);                assert (c == column + arrayWidths[column]);            }            return column + arrayWidths[column];        case RECORD:            for (Field f : s.getFields()) column = write(model.getField(o, f.name(), f.pos()), f.schema(), column);            return column;        case ARRAY:            Collection elements = (Collection) o;            writer.writeLength(elements.size(), column);            if (isSimple(s.getElementType())) {                                for (Object element : elements) writeValue(element, s.getElementType(), column);                return column + 1;            }            for (Object element : elements) {                writer.writeValue(null, column);                int c = write(element, s.getElementType(), column + 1);                assert (c == column + arrayWidths[column]);            }            return column + arrayWidths[column];        case UNION:            int b = model.resolveUnion(s, o);            int i = 0;            for (Schema branch : s.getTypes()) {                boolean selected = i++ == b;                if (branch.getType() == Schema.Type.NULL)                    continue;                if (!selected) {                    writer.writeLength(0, column);                    column += arrayWidths[column];                } else {                    writer.writeLength(1, column);                    if (isSimple(branch)) {                        writeValue(o, branch, column++);                    } else {                        writer.writeValue(null, column);                        column = write(o, branch, column + 1);                    }                }            }            return column;        default:            throw new TrevniRuntimeException("Unknown schema: " + s);    }}
0
private void writeValue(Object value, Schema s, int column) throws IOException
{    switch(s.getType()) {        case STRING:            if (            value instanceof Utf8)                value = value.toString();            break;        case ENUM:            if (value instanceof Enum)                value = ((Enum) value).ordinal();            else                value = s.getEnumOrdinal(value.toString());            break;        case FIXED:            value = ((GenericFixed) value).bytes();            break;    }    writer.writeValue(value, column);}
0
protected boolean isSplitable(FileSystem fs, Path filename)
{    return false;}
0
protected FileStatus[] listStatus(JobConf job) throws IOException
{    List<FileStatus> result = new ArrayList<>();    job.setBoolean("mapred.input.dir.recursive", true);    for (FileStatus file : super.listStatus(job)) if (file.getPath().getName().endsWith(AvroTrevniOutputFormat.EXT))        result.add(file);    return result.toArray(new FileStatus[0]);}
0
public RecordReader<AvroWrapper<T>, NullWritable> getRecordReader(InputSplit split, final JobConf job, Reporter reporter) throws IOException
{    final FileSplit file = (FileSplit) split;    reporter.setStatus(file.toString());    final AvroColumnReader.Params params = new AvroColumnReader.Params(new HadoopInput(file.getPath(), job));    params.setModel(ReflectData.get());    if (job.get(AvroJob.INPUT_SCHEMA) != null)        params.setSchema(AvroJob.getInputSchema(job));    return new RecordReader<AvroWrapper<T>, NullWritable>() {        private AvroColumnReader<T> reader = new AvroColumnReader<>(params);        private float rows = reader.getRowCount();        private long row;        @Override        public AvroWrapper<T> createKey() {            return new AvroWrapper<>(null);        }        @Override        public NullWritable createValue() {            return NullWritable.get();        }        @Override        public boolean next(AvroWrapper<T> wrapper, NullWritable ignore) throws IOException {            if (!reader.hasNext())                return false;            wrapper.datum(reader.next());            row++;            return true;        }        @Override        public float getProgress() throws IOException {            return row / rows;        }        @Override        public long getPos() throws IOException {            return row;        }        @Override        public void close() throws IOException {            reader.close();        }    };}
0
public AvroWrapper<T> createKey()
{    return new AvroWrapper<>(null);}
0
public NullWritable createValue()
{    return NullWritable.get();}
0
public boolean next(AvroWrapper<T> wrapper, NullWritable ignore) throws IOException
{    if (!reader.hasNext())        return false;    wrapper.datum(reader.next());    row++;    return true;}
0
public float getProgress() throws IOException
{    return row / rows;}
0
public long getPos() throws IOException
{    return row;}
0
public void close() throws IOException
{    reader.close();}
0
public static void setMeta(JobConf job, String key, String value)
{    job.set(META_PREFIX + key, value);}
0
public RecordWriter<AvroWrapper<T>, NullWritable> getRecordWriter(FileSystem ignore, final JobConf job, final String name, Progressable prog) throws IOException
{    boolean isMapOnly = job.getNumReduceTasks() == 0;    final Schema schema = isMapOnly ? AvroJob.getMapOutputSchema(job) : AvroJob.getOutputSchema(job);    final ColumnFileMetaData meta = filterMetadata(job);    final Path dir = FileOutputFormat.getTaskOutputPath(job, name);    final FileSystem fs = dir.getFileSystem(job);    if (!fs.mkdirs(dir))        throw new IOException("Failed to create directory: " + dir);    final long blockSize = fs.getDefaultBlockSize(dir);    return new RecordWriter<AvroWrapper<T>, NullWritable>() {        private int part = 0;        private AvroColumnWriter<T> writer = new AvroColumnWriter<>(schema, meta, ReflectData.get());        private void flush() throws IOException {            try (OutputStream out = fs.create(new Path(dir, "part-" + (part++) + EXT))) {                writer.writeTo(out);            }            writer = new AvroColumnWriter<>(schema, meta, ReflectData.get());        }        @Override        public void write(AvroWrapper<T> wrapper, NullWritable ignore) throws IOException {            writer.write(wrapper.datum());            if (            writer.sizeEstimate() >= blockSize)                flush();        }        public void close(Reporter reporter) throws IOException {            flush();        }    };}
0
private void flush() throws IOException
{    try (OutputStream out = fs.create(new Path(dir, "part-" + (part++) + EXT))) {        writer.writeTo(out);    }    writer = new AvroColumnWriter<>(schema, meta, ReflectData.get());}
0
public void write(AvroWrapper<T> wrapper, NullWritable ignore) throws IOException
{    writer.write(wrapper.datum());    if (    writer.sizeEstimate() >= blockSize)        flush();}
0
public void close(Reporter reporter) throws IOException
{    flush();}
0
 static ColumnFileMetaData filterMetadata(final JobConf job)
{    final ColumnFileMetaData meta = new ColumnFileMetaData();    for (Map.Entry<String, String> e : job) if (e.getKey().startsWith(META_PREFIX))        meta.put(e.getKey().substring(META_PREFIX.length()), e.getValue().getBytes(StandardCharsets.UTF_8));    return meta;}
0
public long length()
{    return len;}
0
public int read(long p, byte[] b, int s, int l) throws IOException
{    return stream.read(p, b, s, l);}
0
public void close() throws IOException
{    stream.close();}
0
public RecordReader<AvroKey<T>, NullWritable> createRecordReader(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException
{    return new AvroTrevniKeyRecordReader<>();}
0
public RecordWriter<AvroKey<T>, NullWritable> getRecordWriter(TaskAttemptContext context) throws IOException, InterruptedException
{    return new AvroTrevniKeyRecordWriter<>(context);}
0
public AvroKey<T> getCurrentKey() throws IOException, InterruptedException
{    return mCurrentKey;}
0
public NullWritable getCurrentValue() throws IOException, InterruptedException
{    return NullWritable.get();}
0
public boolean nextKeyValue() throws IOException, InterruptedException
{    boolean hasNext = super.nextKeyValue();    mCurrentKey.datum(getCurrentRecord());    return hasNext;}
0
public void write(AvroKey<T> key, NullWritable value) throws IOException, InterruptedException
{    writer.write(key.datum());    if (    writer.sizeEstimate() >= blockSize)        flush();}
0
protected Schema initSchema(TaskAttemptContext context)
{    boolean isMapOnly = context.getNumReduceTasks() == 0;    return isMapOnly ? AvroJob.getMapOutputKeySchema(context.getConfiguration()) : AvroJob.getOutputKeySchema(context.getConfiguration());}
0
public RecordReader<AvroKey<K>, AvroValue<V>> createRecordReader(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException
{    return new AvroTrevniKeyValueRecordReader<>();}
0
public RecordWriter<AvroKey<K>, AvroValue<V>> getRecordWriter(TaskAttemptContext context) throws IOException, InterruptedException
{    return new AvroTrevniKeyValueRecordWriter<>(context);}
0
public AvroKey<K> getCurrentKey() throws IOException, InterruptedException
{    return mCurrentKey;}
0
public AvroValue<V> getCurrentValue() throws IOException, InterruptedException
{    return mCurrentValue;}
0
public boolean nextKeyValue() throws IOException, InterruptedException
{    boolean hasNext = super.nextKeyValue();    AvroKeyValue<K, V> avroKeyValue = new AvroKeyValue<>(getCurrentRecord());    mCurrentKey.datum(avroKeyValue.getKey());    mCurrentValue.datum(avroKeyValue.getValue());    return hasNext;}
0
public void write(AvroKey<K> key, AvroValue<V> value) throws IOException, InterruptedException
{    keyValueRecord.setKey(key.datum());    keyValueRecord.setValue(value.datum());    writer.write(keyValueRecord.get());    if (    writer.sizeEstimate() >= blockSize)        flush();}
0
protected Schema initSchema(TaskAttemptContext context)
{    AvroDatumConverterFactory converterFactory = new AvroDatumConverterFactory(context.getConfiguration());    keyConverter = converterFactory.create((Class<K>) context.getOutputKeyClass());    valueConverter = converterFactory.create((Class<V>) context.getOutputValueClass());        return AvroKeyValue.getSchema(keyConverter.getWriterSchema(), valueConverter.getWriterSchema());}
0
public void initialize(InputSplit inputSplit, TaskAttemptContext context) throws IOException, InterruptedException
{    final FileSplit file = (FileSplit) inputSplit;    context.setStatus(file.toString());    final AvroColumnReader.Params params = new AvroColumnReader.Params(new HadoopInput(file.getPath(), context.getConfiguration()));    params.setModel(ReflectData.get());    if (AvroJob.getInputKeySchema(context.getConfiguration()) != null) {        params.setSchema(AvroJob.getInputKeySchema(context.getConfiguration()));    }    reader = new AvroColumnReader<>(params);    rows = reader.getRowCount();}
0
public boolean nextKeyValue() throws IOException, InterruptedException
{    if (!reader.hasNext())        return false;    mCurrentRecord = reader.next();    row++;    return true;}
0
protected T getCurrentRecord()
{    return mCurrentRecord;}
0
public void close() throws IOException
{    reader.close();}
0
public float getProgress() throws IOException, InterruptedException
{    return row / rows;}
0
public void flush() throws IOException
{    try (OutputStream out = fs.create(new Path(dirPath, "part-" + (part++) + EXT))) {        writer.writeTo(out);    }    writer = new AvroColumnWriter<>(schema, meta, ReflectData.get());}
0
public void close(TaskAttemptContext arg0) throws IOException, InterruptedException
{    flush();}
0
 static ColumnFileMetaData filterMetadata(final Configuration configuration)
{    final ColumnFileMetaData meta = new ColumnFileMetaData();    for (Entry<String, String> confEntry : configuration) {        if (confEntry.getKey().startsWith(META_PREFIX))            meta.put(confEntry.getKey().substring(META_PREFIX.length()), confEntry.getValue().getBytes(StandardCharsets.UTF_8));    }    return meta;}
0
protected void setup(Context context)
{    mCount.set(1);}
0
protected void map(AvroKey<String> key, NullWritable value, Context context) throws IOException, InterruptedException
{    try {        StringTokenizer tokens = new StringTokenizer(key.datum());        while (tokens.hasMoreTokens()) {            mText.set(tokens.nextToken());            context.write(mText, mCount);        }    } catch (Exception e) {        throw new RuntimeException(key + " " + key.datum(), e);    }}
0
protected void reduce(Text key, Iterable<LongWritable> values, Context context) throws IOException, InterruptedException
{    long sum = 0;    for (LongWritable value : values) {        sum += value.get();    }    resultKey.datum(key.toString());    resultValue.datum(sum);    context.write(resultKey, resultValue);}
0
protected void map(AvroKey<String> key, AvroValue<Long> value, Context context) throws IOException, InterruptedException
{    total += value.datum();}
0
public void testIOFormat() throws Exception
{    checkOutputFormat();    checkInputFormat();}
0
public void checkOutputFormat() throws Exception
{    Job job = Job.getInstance();    WordCountUtil wordCountUtil = new WordCountUtil("trevniMapReduceKeyValueTest", "part-r-00000");    wordCountUtil.writeLinesFile();    AvroJob.setInputKeySchema(job, STRING);    AvroJob.setOutputKeySchema(job, STRING);    AvroJob.setOutputValueSchema(job, LONG);    job.setMapperClass(WordCountMapper.class);    job.setReducerClass(WordCountReducer.class);    job.setMapOutputKeyClass(Text.class);    job.setMapOutputValueClass(LongWritable.class);    FileInputFormat.setInputPaths(job, new Path(wordCountUtil.getDir().toString() + "/in"));    FileOutputFormat.setOutputPath(job, new Path(wordCountUtil.getDir().toString() + "/out"));    FileOutputFormat.setCompressOutput(job, true);    job.setInputFormatClass(AvroKeyInputFormat.class);    job.setOutputFormatClass(AvroTrevniKeyValueOutputFormat.class);    job.waitForCompletion(true);    wordCountUtil.validateCountsFileGenericRecord();}
0
public void checkInputFormat() throws Exception
{    Job job = Job.getInstance();    WordCountUtil wordCountUtil = new WordCountUtil("trevniMapReduceKeyValueTest");    job.setMapperClass(Counter.class);    FileInputFormat.setInputPaths(job, new Path(wordCountUtil.getDir().toString() + "/out/*"));    job.setInputFormatClass(AvroTrevniKeyValueInputFormat.class);    job.setNumReduceTasks(0);    job.setOutputFormatClass(NullOutputFormat.class);    total = 0;    job.waitForCompletion(true);    assertEquals(WordCountUtil.TOTAL, total);}
0
protected void setup(Context context)
{    mCount.set(1);}
0
protected void map(AvroKey<String> key, NullWritable value, Context context) throws IOException, InterruptedException
{    try {        StringTokenizer tokens = new StringTokenizer(key.datum());        while (tokens.hasMoreTokens()) {            mText.set(tokens.nextToken());            context.write(mText, mCount);        }    } catch (Exception e) {        throw new RuntimeException(key + " " + key.datum(), e);    }}
0
protected void setup(Context context)
{    result = new AvroKey<>();    result.datum(new Record(Pair.getPairSchema(STRING, LONG)));}
0
protected void reduce(Text key, Iterable<LongWritable> values, Context context) throws IOException, InterruptedException
{    long count = 0;    for (LongWritable value : values) {        count += value.get();    }    result.datum().put("key", key.toString());    result.datum().put("value", count);    context.write(result, NullWritable.get());}
0
protected void map(AvroKey<GenericData.Record> key, NullWritable value, Context context) throws IOException, InterruptedException
{    total += (Long) key.datum().get("value");}
0
public void testIOFormat() throws Exception
{    checkOutputFormat();    checkInputFormat();}
0
public void checkOutputFormat() throws Exception
{    Job job = Job.getInstance();    WordCountUtil wordCountUtil = new WordCountUtil("trevniMapReduceKeyTest", "part-r-00000");    wordCountUtil.writeLinesFile();    AvroJob.setInputKeySchema(job, STRING);    AvroJob.setOutputKeySchema(job, Pair.getPairSchema(STRING, LONG));    job.setMapperClass(WordCountMapper.class);    job.setReducerClass(WordCountReducer.class);    job.setMapOutputKeyClass(Text.class);    job.setMapOutputValueClass(LongWritable.class);    FileInputFormat.setInputPaths(job, new Path(wordCountUtil.getDir().toString() + "/in"));    FileOutputFormat.setOutputPath(job, new Path(wordCountUtil.getDir().toString() + "/out"));    FileOutputFormat.setCompressOutput(job, true);    job.setInputFormatClass(AvroKeyInputFormat.class);    job.setOutputFormatClass(AvroTrevniKeyOutputFormat.class);    job.waitForCompletion(true);    wordCountUtil.validateCountsFile();}
0
public void checkInputFormat() throws Exception
{    Job job = Job.getInstance();    WordCountUtil wordCountUtil = new WordCountUtil("trevniMapReduceKeyTest");    job.setMapperClass(Counter.class);    Schema subSchema = new Schema.Parser().parse("{\"type\":\"record\"," + "\"name\":\"PairValue\"," + "\"fields\": [ " + "{\"name\":\"value\", \"type\":\"long\"}" + "]}");    AvroJob.setInputKeySchema(job, subSchema);    FileInputFormat.setInputPaths(job, new Path(wordCountUtil.getDir().toString() + "/out/*"));    job.setInputFormatClass(AvroTrevniKeyInputFormat.class);    job.setNumReduceTasks(0);    job.setOutputFormatClass(NullOutputFormat.class);    total = 0;    job.waitForCompletion(true);    assertEquals(WordCountUtil.TOTAL, total);}
0
public void testCases() throws Exception
{    for (File f : DIR.listFiles()) if (f.isDirectory() && !f.getName().startsWith("."))        runCase(f);}
0
private void runCase(File dir) throws Exception
{    Schema schema = new Schema.Parser().parse(new File(dir, "input.avsc"));    List<Object> data = fromJson(schema, new File(dir, "input.json"));        AvroColumnWriter<Object> writer = new AvroColumnWriter<>(schema, new ColumnFileMetaData());    for (Object datum : data) writer.write(datum);    writer.writeTo(FILE);        checkRead(schema, data);        for (File f : dir.listFiles()) if (f.isDirectory() && !f.getName().startsWith(".")) {        Schema s = new Schema.Parser().parse(new File(f, "sub.avsc"));        checkRead(s, fromJson(s, new File(f, "sub.json")));    }}
0
private void checkRead(Schema s, List<Object> data) throws Exception
{    try (AvroColumnReader<Object> reader = new AvroColumnReader<>(new AvroColumnReader.Params(FILE).setSchema(s))) {        for (Object datum : data) assertEquals(datum, reader.next());    }}
0
private List<Object> fromJson(Schema schema, File file) throws Exception
{    List<Object> data = new ArrayList<>();    try (InputStream in = new FileInputStream(file)) {        DatumReader reader = new GenericDatumReader(schema);        Decoder decoder = DecoderFactory.get().jsonDecoder(schema, in);        while (true) data.add(reader.read(null, decoder));    } catch (EOFException e) {    }    return data;}
0
public void setUp()
{    writtenRecord = new GenericData.Record(writer);    writtenRecord.put("a", "record");    writtenRecord.put("b", 21);    innerRecord = new GenericData.Record(inner);    innerRecord.put("c11", 1);    innerRecord.put("c12", "hello");    evolvedRecord = new GenericData.Record(evolved);    evolvedRecord.put("a", "record");    evolvedRecord.put("b", 21);    evolvedRecord.put("c", innerRecord);}
0
public void testTrevniEvolvedRead() throws IOException
{    AvroColumnWriter<GenericRecord> acw = new AvroColumnWriter<>(writer, new ColumnFileMetaData());    acw.write(writtenRecord);    File serializedTrevni = File.createTempFile("trevni", null);    acw.writeTo(serializedTrevni);    AvroColumnReader.Params params = new Params(serializedTrevni);    params.setSchema(evolved);    AvroColumnReader<GenericRecord> acr = new AvroColumnReader<>(params);    GenericRecord readRecord = acr.next();    Assert.assertEquals(evolvedRecord, readRecord);    Assert.assertFalse(acr.hasNext());}
0
public void testAvroEvolvedRead() throws IOException
{    File serializedAvro = File.createTempFile("avro", null);    DatumWriter<GenericRecord> dw = new GenericDatumWriter<>(writer);    DataFileWriter<GenericRecord> dfw = new DataFileWriter<>(dw);    dfw.create(writer, serializedAvro);    dfw.append(writtenRecord);    dfw.flush();    dfw.close();    GenericDatumReader<GenericRecord> reader = new GenericDatumReader<>(writer);    reader.setExpected(evolved);    DataFileReader<GenericRecord> dfr = new DataFileReader<>(serializedAvro, reader);    GenericRecord readRecord = dfr.next();    Assert.assertEquals(evolvedRecord, readRecord);    Assert.assertFalse(dfr.hasNext());}
0
public void testMetadataFiltering() throws Exception
{    JobConf job = new JobConf();    job.set(AvroTrevniOutputFormat.META_PREFIX + "test1", "1");    job.set(AvroTrevniOutputFormat.META_PREFIX + "test2", "2");    job.set("test3", "3");    job.set(AvroJob.TEXT_PREFIX + "test4", "4");    job.set(AvroTrevniOutputFormat.META_PREFIX + "test5", "5");    ColumnFileMetaData metadata = AvroTrevniOutputFormat.filterMetadata(job);    assertTrue(metadata.get("test1") != null);    assertTrue(new String(metadata.get("test1")).equals("1"));    assertTrue(metadata.get("test2") != null);    assertTrue(new String(metadata.get("test2")).equals("2"));    assertTrue(metadata.get("test5") != null);    assertTrue(new String(metadata.get("test5")).equals("5"));    assertTrue(metadata.get("test3") == null);    assertTrue(metadata.get("test4") == null);}
0
public void testPrimitives() throws Exception
{    check(Schema.create(Schema.Type.NULL), new ColumnMetaData("null", ValueType.NULL));    check(Schema.create(Schema.Type.BOOLEAN), new ColumnMetaData("boolean", ValueType.BOOLEAN));    check(Schema.create(Schema.Type.INT), new ColumnMetaData("int", ValueType.INT));    check(Schema.create(Schema.Type.LONG), new ColumnMetaData("long", ValueType.LONG));    check(Schema.create(Schema.Type.FLOAT), new ColumnMetaData("float", ValueType.FLOAT));    check(Schema.create(Schema.Type.DOUBLE), new ColumnMetaData("double", ValueType.DOUBLE));    check(Schema.create(Schema.Type.BYTES), new ColumnMetaData("bytes", ValueType.BYTES));    check(Schema.create(Schema.Type.STRING), new ColumnMetaData("string", ValueType.STRING));    check(Schema.createEnum("E", null, null, Arrays.asList("X", "Y", "Z")), new ColumnMetaData("E", ValueType.INT));    check(Schema.createFixed("F", null, null, 5), new ColumnMetaData("F", ValueType.BYTES));}
0
public void testSimpleRecord() throws Exception
{    check(new Schema.Parser().parse(SIMPLE_RECORD), new ColumnMetaData("x", ValueType.INT), new ColumnMetaData("y", ValueType.STRING));}
0
public void testDefaultValue() throws Exception
{    String s = "{\"type\":\"record\",\"name\":\"R\",\"fields\":[" + SIMPLE_FIELDS + "," + "{\"name\":\"z\",\"type\":\"int\"," + "\"default\":1,\"" + RandomData.USE_DEFAULT + "\":true}" + "]}";    checkWrite(new Schema.Parser().parse(SIMPLE_RECORD));    checkRead(new Schema.Parser().parse(s));}
0
public void testNestedRecord() throws Exception
{    String s = "{\"type\":\"record\",\"name\":\"S\",\"fields\":[" + "{\"name\":\"x\",\"type\":\"int\"}," + "{\"name\":\"R\",\"type\":" + SIMPLE_RECORD + "}," + "{\"name\":\"y\",\"type\":\"string\"}" + "]}";    check(new Schema.Parser().parse(s), new ColumnMetaData("x", ValueType.INT), new ColumnMetaData("R#x", ValueType.INT), new ColumnMetaData("R#y", ValueType.STRING), new ColumnMetaData("y", ValueType.STRING));}
0
public void testNamedRecord() throws Exception
{    String s = "{\"type\":\"record\",\"name\":\"S\",\"fields\":[" + "{\"name\":\"R1\",\"type\":" + SIMPLE_RECORD + "}," + "{\"name\":\"R2\",\"type\":\"R\"}" + "]}";    check(new Schema.Parser().parse(s), new ColumnMetaData("R1#x", ValueType.INT), new ColumnMetaData("R1#y", ValueType.STRING), new ColumnMetaData("R2#x", ValueType.INT), new ColumnMetaData("R2#y", ValueType.STRING));}
0
public void testSimpleArray() throws Exception
{    String s = "{\"type\":\"array\",\"items\":\"long\"}";    check(new Schema.Parser().parse(s), new ColumnMetaData("[]", ValueType.LONG).isArray(true));}
0
public void testArray() throws Exception
{    ColumnMetaData p = new ColumnMetaData("[]", ValueType.NULL).isArray(true);    check(new Schema.Parser().parse(RECORD_ARRAY), p, new ColumnMetaData("[]#x", ValueType.INT).setParent(p), new ColumnMetaData("[]#y", ValueType.STRING).setParent(p));}
0
public void testSimpleUnion() throws Exception
{    String s = "[\"int\",\"string\"]";    check(new Schema.Parser().parse(s), new ColumnMetaData("int", ValueType.INT).isArray(true), new ColumnMetaData("string", ValueType.STRING).isArray(true));}
0
public void testSimpleOptional() throws Exception
{    String s = "[\"null\",\"string\"]";    check(new Schema.Parser().parse(s), new ColumnMetaData("string", ValueType.STRING).isArray(true));}
0
public void testUnion() throws Exception
{    ColumnMetaData p = new ColumnMetaData("R", ValueType.NULL).isArray(true);    check(new Schema.Parser().parse(UNION), new ColumnMetaData("int", ValueType.INT).isArray(true), p, new ColumnMetaData("R#x", ValueType.INT).setParent(p), new ColumnMetaData("R#y", ValueType.STRING).setParent(p));}
0
public void testNestedArray() throws Exception
{    String s = "{\"type\":\"record\",\"name\":\"S\",\"fields\":[" + "{\"name\":\"x\",\"type\":\"int\"}," + "{\"name\":\"A\",\"type\":" + RECORD_ARRAY + "}," + "{\"name\":\"y\",\"type\":\"string\"}" + "]}";    ColumnMetaData p = new ColumnMetaData("A[]", ValueType.NULL).isArray(true);    check(new Schema.Parser().parse(s), new ColumnMetaData("x", ValueType.INT), p, new ColumnMetaData("A[]#x", ValueType.INT).setParent(p), new ColumnMetaData("A[]#y", ValueType.STRING).setParent(p), new ColumnMetaData("y", ValueType.STRING));}
0
public void testNestedUnion() throws Exception
{    String s = "{\"type\":\"record\",\"name\":\"S\",\"fields\":[" + "{\"name\":\"x\",\"type\":\"int\"}," + "{\"name\":\"u\",\"type\":" + UNION + "}," + "{\"name\":\"y\",\"type\":\"string\"}" + "]}";    ColumnMetaData p = new ColumnMetaData("u/R", ValueType.NULL).isArray(true);    check(new Schema.Parser().parse(s), new ColumnMetaData("x", ValueType.INT), new ColumnMetaData("u/int", ValueType.INT).isArray(true), p, new ColumnMetaData("u/R#x", ValueType.INT).setParent(p), new ColumnMetaData("u/R#y", ValueType.STRING).setParent(p), new ColumnMetaData("y", ValueType.STRING));}
0
public void testUnionInArray() throws Exception
{    String s = "{\"type\":\"record\",\"name\":\"S\",\"fields\":[" + "{\"name\":\"a\",\"type\":{\"type\":\"array\",\"items\":" + UNION + "}}" + "]}";    ColumnMetaData p = new ColumnMetaData("a[]", ValueType.NULL).isArray(true);    ColumnMetaData r = new ColumnMetaData("a[]/R", ValueType.NULL).setParent(p).isArray(true);    check(new Schema.Parser().parse(s), p, new ColumnMetaData("a[]/int", ValueType.INT).setParent(p).isArray(true), r, new ColumnMetaData("a[]/R#x", ValueType.INT).setParent(r), new ColumnMetaData("a[]/R#y", ValueType.STRING).setParent(r));}
0
public void testArrayInUnion() throws Exception
{    String s = "{\"type\":\"record\",\"name\":\"S\",\"fields\":[" + "{\"name\":\"a\",\"type\":[\"int\"," + RECORD_ARRAY + "]}]}";    ColumnMetaData q = new ColumnMetaData("a/array", ValueType.NULL).isArray(true);    ColumnMetaData r = new ColumnMetaData("a/array[]", ValueType.NULL).setParent(q).isArray(true);    check(new Schema.Parser().parse(s), new ColumnMetaData("a/int", ValueType.INT).isArray(true), q, r, new ColumnMetaData("a/array[]#x", ValueType.INT).setParent(r), new ColumnMetaData("a/array[]#y", ValueType.STRING).setParent(r));}
0
public void testSimpleMap() throws Exception
{    String s = "{\"type\":\"map\",\"values\":\"long\"}";    ColumnMetaData p = new ColumnMetaData(">", ValueType.NULL).isArray(true);    check(new Schema.Parser().parse(s), p, new ColumnMetaData(">key", ValueType.STRING).setParent(p), new ColumnMetaData(">value", ValueType.LONG).setParent(p));}
0
public void testMap() throws Exception
{    String s = "{\"type\":\"map\",\"values\":" + SIMPLE_RECORD + "}";    ColumnMetaData p = new ColumnMetaData(">", ValueType.NULL).isArray(true);    check(new Schema.Parser().parse(s), p, new ColumnMetaData(">key", ValueType.STRING).setParent(p), new ColumnMetaData(">value#x", ValueType.INT).setParent(p), new ColumnMetaData(">value#y", ValueType.STRING).setParent(p));}
0
private void check(Schema s, ColumnMetaData... expected) throws Exception
{    ColumnMetaData[] shredded = new AvroColumnator(s).getColumns();    assertEquals(expected.length, shredded.length);    for (int i = 0; i < expected.length; i++) assertEquals(expected[i].toString(), shredded[i].toString());    checkWrite(s);    checkRead(s);}
0
private void checkWrite(Schema schema) throws IOException
{    AvroColumnWriter<Object> writer = new AvroColumnWriter<>(schema, new ColumnFileMetaData());    int count = 0;    for (Object datum : new RandomData(schema, COUNT, SEED)) {                writer.write(datum);    }    writer.writeTo(FILE);}
0
private void checkRead(Schema schema) throws IOException
{    AvroColumnReader<Object> reader = new AvroColumnReader<>(new AvroColumnReader.Params(FILE).setSchema(schema));    for (Object expected : new RandomData(schema, COUNT, SEED)) assertEquals(expected, reader.next());    reader.close();}
0
public void map(String text, AvroCollector<Pair<String, Long>> collector, Reporter reporter) throws IOException
{    StringTokenizer tokens = new StringTokenizer(text);    while (tokens.hasMoreTokens()) collector.collect(new Pair<>(tokens.nextToken(), 1L));}
0
public void reduce(String word, Iterable<Long> counts, AvroCollector<Pair<String, Long>> collector, Reporter reporter) throws IOException
{    long sum = 0;    for (long count : counts) sum += count;    collector.collect(new Pair<>(word, sum));}
0
public void runTestsInOrder() throws Exception
{    testOutputFormat();    testInputFormat();}
0
public void testOutputFormat() throws Exception
{    JobConf job = new JobConf();    WordCountUtil wordCountUtil = new WordCountUtil("trevniMapredTest");    wordCountUtil.writeLinesFile();    AvroJob.setInputSchema(job, STRING);    AvroJob.setOutputSchema(job, Pair.getPairSchema(STRING, LONG));    AvroJob.setMapperClass(job, MapImpl.class);    AvroJob.setCombinerClass(job, ReduceImpl.class);    AvroJob.setReducerClass(job, ReduceImpl.class);    FileInputFormat.setInputPaths(job, new Path(wordCountUtil.getDir().toString() + "/in"));    FileOutputFormat.setOutputPath(job, new Path(wordCountUtil.getDir().toString() + "/out"));    FileOutputFormat.setCompressOutput(job, true);    job.setOutputFormat(AvroTrevniOutputFormat.class);    JobClient.runJob(job);    wordCountUtil.validateCountsFile();}
0
public void map(GenericRecord r, AvroCollector<Void> collector, Reporter reporter) throws IOException
{    total += (Long) r.get("value");}
0
public void testInputFormat() throws Exception
{    JobConf job = new JobConf();    WordCountUtil wordCountUtil = new WordCountUtil("trevniMapredTest");    Schema subSchema = new Schema.Parser().parse("{\"type\":\"record\"," + "\"name\":\"PairValue\"," + "\"fields\": [ " + "{\"name\":\"value\", \"type\":\"long\"}" + "]}");    AvroJob.setInputSchema(job, subSchema);    AvroJob.setMapperClass(job, Counter.class);    FileInputFormat.setInputPaths(job, new Path(wordCountUtil.getDir().toString() + "/out/*"));    job.setInputFormat(AvroTrevniInputFormat.class);        job.setNumReduceTasks(0);        job.setOutputFormat(NullOutputFormat.class);    total = 0;    JobClient.runJob(job);    assertEquals(WordCountUtil.TOTAL, total);}
0
public File getDir()
{    return dir;}
0
public void writeLinesFile() throws IOException
{    FileUtil.fullyDelete(dir);    DatumWriter<String> writer = new GenericDatumWriter<>();    DataFileWriter<String> out = new DataFileWriter<>(writer);    linesFiles.getParentFile().mkdirs();    out.create(Schema.create(Schema.Type.STRING), linesFiles);    for (String line : LINES) out.append(line);    out.close();}
0
public void validateCountsFile() throws Exception
{    AvroColumnReader<Pair<String, Long>> reader = new AvroColumnReader<>(new AvroColumnReader.Params(countFiles).setModel(SpecificData.get()));    int numWords = 0;    for (Pair<String, Long> wc : reader) {        assertEquals(wc.key(), COUNTS.get(wc.key()), wc.value());        numWords++;    }    reader.close();    assertEquals(COUNTS.size(), numWords);}
0
public void validateCountsFileGenericRecord() throws Exception
{    AvroColumnReader<GenericRecord> reader = new AvroColumnReader<>(new AvroColumnReader.Params(countFiles).setModel(SpecificData.get()));    int numWords = 0;    for (GenericRecord wc : reader) {        assertEquals((String) wc.get("key"), COUNTS.get(wc.get("key")), wc.get("value"));                numWords++;    }    reader.close();    assertEquals(COUNTS.size(), numWords);}
0
public void writeLength(int l) throws IOException
{    assert this.length == 0;    assert l >= 0;    this.length = l;    if (l == runValue) {                runLength++;        return;    }        flushRun();    if (l == 1 || l == 0) {                runLength = 1;        runValue = l;    } else {                getBuffer().writeLength(l);    }}
0
public void writeValue(Object value) throws IOException
{    assert length > 0;    if (getMeta().getType() != ValueType.NULL) {        flushRun();        getBuffer().writeValue(value, getMeta().getType());    }    length -= 1;}
0
 void flushBuffer() throws IOException
{    flushRun();    super.flushBuffer();}
0
private void flushRun() throws IOException
{    if (    runLength == 0)        return;    else if (    runLength == 1)        getBuffer().writeLength(runValue);    else                getBuffer().writeLength((3 - runValue) - (runLength << 1));        runLength = 0;    runValue = NONE;}
0
public void writeTo(OutputBuffer out) throws IOException
{    out.writeFixed32(rowCount);    out.writeFixed32(uncompressedSize);    out.writeFixed32(compressedSize);}
0
public static BlockDescriptor read(InputBuffer in) throws IOException
{    BlockDescriptor result = new BlockDescriptor();    result.rowCount = in.readFixed32();    result.uncompressedSize = in.readFixed32();    result.compressedSize = in.readFixed32();    return result;}
0
 ByteBuffer compress(ByteBuffer uncompressedData) throws IOException
{    ByteArrayOutputStream baos = getOutputBuffer(uncompressedData.remaining());    try (BZip2CompressorOutputStream outputStream = new BZip2CompressorOutputStream(baos)) {        outputStream.write(uncompressedData.array());    }    ByteBuffer result = ByteBuffer.wrap(baos.toByteArray());    return result;}
0
 ByteBuffer decompress(ByteBuffer compressedData) throws IOException
{    ByteArrayInputStream bais = new ByteArrayInputStream(compressedData.array());    try (BZip2CompressorInputStream inputStream = new BZip2CompressorInputStream(bais)) {        ByteArrayOutputStream baos = new ByteArrayOutputStream();        byte[] buffer = new byte[DEFAULT_BUFFER_SIZE];        int readCount = -1;        while ((readCount = inputStream.read(buffer, compressedData.position(), buffer.length)) > 0) {            baos.write(buffer, 0, readCount);        }        ByteBuffer result = ByteBuffer.wrap(baos.toByteArray());        return result;    }}
0
private ByteArrayOutputStream getOutputBuffer(int suggestedLength)
{    if (null == outputBuffer)        outputBuffer = new ByteArrayOutputStream(suggestedLength);    outputBuffer.reset();    return outputBuffer;}
0
public static Checksum get(MetaData meta)
{    String name = meta.getChecksum();    if (name == null || "null".equals(name))        return new NullChecksum();    else if ("crc32".equals(name))        return new Crc32Checksum();    else        throw new TrevniRuntimeException("Unknown checksum: " + name);}
0
public static Codec get(MetaData meta)
{    String name = meta.getCodec();    if (name == null || "null".equals(name))        return new NullCodec();    else if ("deflate".equals(name))        return new DeflateCodec();    else if ("snappy".equals(name))        return new SnappyCodec();    else if ("bzip2".equals(name))        return new BZip2Codec();    else        throw new TrevniRuntimeException("Unknown codec: " + name);}
0
public int findBlock(long row)
{    int block = Arrays.binarySearch(firstRows, row);    if (block < 0)        block = -block - 2;    return block;}
0
public int findBlock(T value)
{    int block = Arrays.binarySearch(firstValues, value);    if (block < 0)        block = -block - 2;    return block;}
0
public int blockCount()
{    return blocks.length;}
0
public long lastRow(int block)
{    if (blocks.length == 0 || block < 0)        return 0;    return firstRows[block] + blocks[block].rowCount;}
0
public void ensureBlocksRead() throws IOException
{    if (blocks != null)        return;        InputBuffer in = new InputBuffer(file, start);    int blockCount = in.readFixed32();    BlockDescriptor[] blocks = new BlockDescriptor[blockCount];    if (metaData.hasIndexValues())        firstValues = (T[]) new Comparable[blockCount];    for (int i = 0; i < blockCount; i++) {        blocks[i] = BlockDescriptor.read(in);        if (metaData.hasIndexValues())            firstValues[i] = in.readValue(metaData.getType());    }    dataStart = in.tell();        Checksum checksum = Checksum.get(metaData);    blockStarts = new long[blocks.length];    firstRows = new long[blocks.length];    long startPosition = dataStart;    long row = 0;    for (int i = 0; i < blockCount; i++) {        BlockDescriptor b = blocks[i];        blockStarts[i] = startPosition;        firstRows[i] = row;        startPosition += b.compressedSize + checksum.size();        row += b.rowCount;    }    this.blocks = blocks;}
0
 static ColumnFileMetaData read(InputBuffer in) throws IOException
{    ColumnFileMetaData result = new ColumnFileMetaData();    MetaData.read(in, result);    return result;}
0
public long getRowCount()
{    return rowCount;}
0
public long getColumnCount()
{    return columnCount;}
0
public ColumnFileMetaData getMetaData()
{    return metaData;}
0
public ColumnMetaData[] getColumnMetaData()
{    ColumnMetaData[] result = new ColumnMetaData[columnCount];    for (int i = 0; i < columnCount; i++) result[i] = columns[i].metaData;    return result;}
0
public List<ColumnMetaData> getRoots()
{    List<ColumnMetaData> result = new ArrayList<>();    for (int i = 0; i < columnCount; i++) if (columns[i].metaData.getParent() == null)        result.add(columns[i].metaData);    return result;}
0
public ColumnMetaData getColumnMetaData(int number)
{    return columns[number].metaData;}
0
public ColumnMetaData getColumnMetaData(String name)
{    return getColumn(name).metaData;}
0
private ColumnDescriptor<T> getColumn(String name)
{    ColumnDescriptor column = columnsByName.get(name);    if (column == null)        throw new TrevniRuntimeException("No column named: " + name);    return (ColumnDescriptor<T>) column;}
0
private void readHeader() throws IOException
{    InputBuffer in = new InputBuffer(file, 0);    readMagic(in);    this.rowCount = in.readFixed64();    this.columnCount = in.readFixed32();    this.metaData = ColumnFileMetaData.read(in);    this.columnsByName = new HashMap<>(columnCount);    columns = new ColumnDescriptor[columnCount];    readColumnMetaData(in);    readColumnStarts(in);}
0
private void readMagic(InputBuffer in) throws IOException
{    byte[] magic = new byte[ColumnFileWriter.MAGIC.length];    try {        in.readFully(magic);    } catch (IOException e) {        throw new IOException("Not a data file.");    }    if (!(Arrays.equals(ColumnFileWriter.MAGIC, magic) || !Arrays.equals(ColumnFileWriter.MAGIC_1, magic) || !Arrays.equals(ColumnFileWriter.MAGIC_0, magic)))        throw new IOException("Not a data file.");}
0
private void readColumnMetaData(InputBuffer in) throws IOException
{    for (int i = 0; i < columnCount; i++) {        ColumnMetaData meta = ColumnMetaData.read(in, this);        meta.setDefaults(this.metaData);        ColumnDescriptor column = new ColumnDescriptor(file, meta);        columns[i] = column;        meta.setNumber(i);        columnsByName.put(meta.getName(), column);    }}
0
private void readColumnStarts(InputBuffer in) throws IOException
{    for (int i = 0; i < columnCount; i++) columns[i].start = in.readFixed64();}
0
public ColumnValues<T> getValues(String columnName) throws IOException
{    return new ColumnValues<>(getColumn(columnName));}
0
public ColumnValues<T> getValues(int column) throws IOException
{    return new ColumnValues<>(columns[column]);}
0
public void close() throws IOException
{    file.close();}
0
private void checkColumns(ColumnMetaData[] columnMeta)
{    Set<String> seen = new HashSet<>();    for (ColumnMetaData c : columnMeta) {        String name = c.getName();        if (seen.contains(name))            throw new TrevniRuntimeException("Duplicate column name: " + name);        ColumnMetaData parent = c.getParent();        if (parent != null && !seen.contains(parent.getName()))            throw new TrevniRuntimeException("Parent must precede child: " + name);        seen.add(name);    }}
0
 void incrementSize(int n)
{    size += n;}
0
public long sizeEstimate()
{    return size;}
0
public ColumnFileMetaData getMetaData()
{    return metaData;}
0
public int getColumnCount()
{    return columnCount;}
0
public void writeRow(Object... row) throws IOException
{    startRow();    for (int column = 0; column < columnCount; column++) writeValue(row[column], column);    endRow();}
0
public void startRow() throws IOException
{    for (int column = 0; column < columnCount; column++) columns[column].startRow();}
0
public void writeLength(int length, int column) throws IOException
{    columns[column].writeLength(length);}
0
public void writeValue(Object value, int column) throws IOException
{    columns[column].writeValue(value);}
0
public void endRow() throws IOException
{    for (int column = 0; column < columnCount; column++) columns[column].endRow();    rowCount++;}
0
public void writeTo(File file) throws IOException
{    try (OutputStream out = new FileOutputStream(file)) {        writeTo(out);    }}
0
public void writeTo(OutputStream out) throws IOException
{    writeHeader(out);    for (int column = 0; column < columnCount; column++) columns[column].writeTo(out);}
0
private void writeHeader(OutputStream out) throws IOException
{    OutputBuffer header = new OutputBuffer();        header.write(MAGIC);        header.writeFixed64(rowCount);        header.writeFixed32(columnCount);        metaData.write(header);    for (ColumnOutputBuffer column : columns)     column.getMeta().write(header);    for (long start : computeStarts(header.size()))     header.writeFixed64(start);    header.writeTo(out);}
0
private long[] computeStarts(long start) throws IOException
{    long[] result = new long[columnCount];        start += columnCount * 8;    for (int column = 0; column < columnCount; column++) {        result[column] = start;        start += columns[column].size();    }    return result;}
0
public String getName()
{    return name;}
0
public ValueType getType()
{    return type;}
0
public ColumnMetaData getParent()
{    return parent;}
0
public List<ColumnMetaData> getChildren()
{    return children;}
0
public boolean isArray()
{    return isArray;}
0
public int getNumber()
{    return number;}
0
 void setNumber(int number)
{    this.number = number;}
0
public ColumnMetaData hasIndexValues(boolean values)
{    if (isArray)        throw new TrevniRuntimeException("Array column cannot have index: " + this);    this.values = values;    return setReservedBoolean(VALUES_KEY, values);}
0
public ColumnMetaData setParent(ColumnMetaData parent)
{    if (!parent.isArray())        throw new TrevniRuntimeException("Parent is not an array: " + parent);    if (values)        throw new TrevniRuntimeException("Array column cannot have index: " + this);    this.parent = parent;    parent.children.add(this);    return setReserved(PARENT_KEY, parent.getName());}
0
public ColumnMetaData isArray(boolean isArray)
{    if (values)        throw new TrevniRuntimeException("Array column cannot have index: " + this);    this.isArray = isArray;    return setReservedBoolean(ARRAY_KEY, isArray);}
0
public boolean hasIndexValues()
{    return getBoolean(VALUES_KEY);}
0
 static ColumnMetaData read(InputBuffer in, ColumnFileReader file) throws IOException
{    ColumnMetaData result = new ColumnMetaData();    MetaData.read(in, result);    result.name = result.getString(NAME_KEY);    result.type = ValueType.forName(result.getString(TYPE_KEY));    result.values = result.getBoolean(VALUES_KEY);    result.isArray = result.getBoolean(ARRAY_KEY);    String parentName = result.getString(PARENT_KEY);    if (parentName != null)        result.setParent(file.getColumnMetaData(parentName));    return result;}
0
public ColumnMetaData getMeta()
{    return meta;}
0
public OutputBuffer getBuffer()
{    return buffer;}
0
public void startRow() throws IOException
{    if (buffer.isFull())        flushBuffer();}
0
public void writeLength(int length) throws IOException
{    throw new TrevniRuntimeException("Not an array column: " + meta);}
0
public void writeValue(Object value) throws IOException
{    buffer.writeValue(value, meta.getType());    if (meta.hasIndexValues() && rowCount == 0)        firstValues.add(buffer.toByteArray());}
0
public void endRow() throws IOException
{    rowCount++;}
0
 void flushBuffer() throws IOException
{    if (rowCount == 0)        return;    ByteBuffer raw = buffer.asByteBuffer();    ByteBuffer c = codec.compress(raw);    blockDescriptors.add(new BlockDescriptor(rowCount, raw.remaining(), c.remaining()));    ByteBuffer data = ByteBuffer.allocate(c.remaining() + checksum.size());    data.put(c);    data.put(checksum.compute(raw));    blockData.add(data.array());    int sizeIncrement =     (4 * 3) + (    firstValues != null ? firstValues.get(firstValues.size() - 1).length : 0) +     data.position();    writer.incrementSize(sizeIncrement);    size += sizeIncrement;    buffer = new OutputBuffer();    rowCount = 0;}
0
public long size() throws IOException
{    flushBuffer();    return size;}
0
public void writeTo(OutputStream out) throws IOException
{    OutputBuffer header = new OutputBuffer();    header.writeFixed32(blockDescriptors.size());    for (int i = 0; i < blockDescriptors.size(); i++) {        blockDescriptors.get(i).writeTo(header);        if (meta.hasIndexValues())            header.write(firstValues.get(i));    }    header.writeTo(out);    for (byte[] data : blockData) out.write(data);}
0
public long getRow()
{    return row;}
0
public void seek(long r) throws IOException
{    if (    r < row || r >= column.lastRow(block))                startBlock(column.findBlock(r));    while (r > row && hasNext()) {                values.skipValue(type);        row++;    }    previous = null;}
0
public void seek(T v) throws IOException
{    if (!column.metaData.hasIndexValues())        throw new TrevniRuntimeException("Column does not have value index: " + column.metaData.getName());    if (    previous == null || previous.compareTo(v) > 0 || (block != column.blockCount() - 1 && column.firstValues[block + 1].compareTo(v) <= 0))                startBlock(column.findBlock(v));    while (hasNext()) {                long savedPosition = values.tell();        T savedPrevious = previous;        if (next().compareTo(v) >= 0) {            values.seek(savedPosition);            previous = savedPrevious;            row--;            return;        }    }}
0
private void startBlock(int block) throws IOException
{    this.block = block;    this.row = column.firstRows[block];    in.seek(column.blockStarts[block]);    int end = column.blocks[block].compressedSize;    byte[] raw = new byte[end + checksum.size()];    in.readFully(raw);    ByteBuffer data = codec.decompress(ByteBuffer.wrap(raw, 0, end));    if (!checksum.compute(data).equals(ByteBuffer.wrap(raw, end, checksum.size())))        throw new IOException("Checksums mismatch.");    values = new InputBuffer(new InputBytes(data));}
0
public Iterator iterator()
{    return this;}
0
public boolean hasNext()
{    return block < column.blockCount() - 1 || row < column.lastRow(block);}
0
public T next()
{    if (column.metaData.isArray() || column.metaData.getParent() != null)        throw new TrevniRuntimeException("Column is array: " + column.metaData.getName());    try {        startRow();        return nextValue();    } catch (IOException e) {        throw new TrevniRuntimeException(e);    }}
0
public void startRow() throws IOException
{    if (row >= column.lastRow(block)) {        if (block >= column.blockCount())            throw new TrevniRuntimeException("Read past end of column.");        startBlock(block + 1);    }    row++;}
0
public int nextLength() throws IOException
{    if (!column.metaData.isArray())        throw new TrevniRuntimeException("Column is not array: " + column.metaData.getName());    assert arrayLength == 0;    return arrayLength = values.readLength();}
0
public T nextValue() throws IOException
{    arrayLength--;    return previous = values.readValue(type);}
0
public void remove()
{    throw new UnsupportedOperationException();}
0
public int size()
{    return 4;}
0
public ByteBuffer compute(ByteBuffer data)
{    crc32.reset();    crc32.update(data.array(), data.position(), data.remaining());    ByteBuffer result = ByteBuffer.allocate(size());    result.putInt((int) crc32.getValue());    result.flip();    return result;}
0
 ByteBuffer compress(ByteBuffer data) throws IOException
{    ByteArrayOutputStream baos = getOutputBuffer(data.remaining());    writeAndClose(data, new DeflaterOutputStream(baos, getDeflater()));    return ByteBuffer.wrap(baos.toByteArray());}
0
 ByteBuffer decompress(ByteBuffer data) throws IOException
{    ByteArrayOutputStream baos = getOutputBuffer(data.remaining());    writeAndClose(data, new InflaterOutputStream(baos, getInflater()));    return ByteBuffer.wrap(baos.toByteArray());}
0
private void writeAndClose(ByteBuffer data, OutputStream out) throws IOException
{    out.write(data.array(), data.position(), data.remaining());    out.close();}
0
private Inflater getInflater()
{    if (null == inflater)        inflater = new Inflater(true);    inflater.reset();    return inflater;}
0
private Deflater getDeflater()
{    if (null == deflater)        deflater = new Deflater(Deflater.DEFAULT_COMPRESSION, true);    deflater.reset();    return deflater;}
0
private ByteArrayOutputStream getOutputBuffer(int suggestedLength)
{    if (null == outputBuffer)        outputBuffer = new ByteArrayOutputStream(suggestedLength);    outputBuffer.reset();    return outputBuffer;}
0
public void seek(long position) throws IOException
{    runLength = 0;    if (position >= (offset - limit) && position <= offset) {                pos = (int) (limit - (offset - position));        return;    }    pos = 0;    limit = 0;    offset = position;}
0
public long tell()
{    return (offset - limit) + pos;}
0
public long length()
{    return inLength;}
0
public T readValue(ValueType type) throws IOException
{    switch(type) {        case NULL:            return null;        case BOOLEAN:            return (T) Boolean.valueOf(readBoolean());        case INT:            return (T) Integer.valueOf(readInt());        case LONG:            return (T) Long.valueOf(readLong());        case FIXED32:            return (T) Integer.valueOf(readFixed32());        case FIXED64:            return (T) Long.valueOf(readFixed64());        case FLOAT:            return (T) Float.valueOf(readFloat());        case DOUBLE:            return (T) Double.valueOf(readDouble());        case STRING:            return (T) readString();        case BYTES:            return (T) readBytes(null);        default:            throw new TrevniRuntimeException("Unknown value type: " + type);    }}
0
public void skipValue(ValueType type) throws IOException
{    switch(type) {        case NULL:            break;        case BOOLEAN:            readBoolean();            break;        case INT:            readInt();            break;        case LONG:            readLong();            break;        case FIXED32:        case FLOAT:            skip(4);            break;        case FIXED64:        case DOUBLE:            skip(8);            break;        case STRING:        case BYTES:            skipBytes();            break;        default:            throw new TrevniRuntimeException("Unknown value type: " + type);    }}
0
public boolean readBoolean() throws IOException
{    if (bitCount == 0)        read();    int bits = buf[pos - 1] & 0xff;    int bit = (bits >> bitCount) & 1;    bitCount++;    if (bitCount == 8)        bitCount = 0;    return bit == 0 ? false : true;}
0
public int readLength() throws IOException
{    bitCount = 0;    if (runLength > 0) {                runLength--;        return runValue;    }    int length = readInt();    if (    length >= 0)        return length;        runLength = (1 - length) >>> 1;    runValue = (length + 1) & 1;    return runValue;}
0
public int readInt() throws IOException
{    if ((limit - pos) < 5) {                int b = read();        int n = b & 0x7f;        for (int shift = 7; b > 0x7f; shift += 7) {            b = read();            n ^= (b & 0x7f) << shift;        }                return (n >>> 1) ^ -(n & 1);    }    int len = 1;    int b = buf[pos] & 0xff;    int n = b & 0x7f;    if (b > 0x7f) {        b = buf[pos + len++] & 0xff;        n ^= (b & 0x7f) << 7;        if (b > 0x7f) {            b = buf[pos + len++] & 0xff;            n ^= (b & 0x7f) << 14;            if (b > 0x7f) {                b = buf[pos + len++] & 0xff;                n ^= (b & 0x7f) << 21;                if (b > 0x7f) {                    b = buf[pos + len++] & 0xff;                    n ^= (b & 0x7f) << 28;                    if (b > 0x7f) {                        throw new IOException("Invalid int encoding");                    }                }            }        }    }    pos += len;    if (pos > limit)        throw new EOFException();        return (n >>> 1) ^ -(n & 1);}
0
public long readLong() throws IOException
{    if ((limit - pos) < 10) {                int b = read();        long n = b & 0x7f;        for (int shift = 7; b > 0x7f; shift += 7) {            b = read();            n ^= (b & 0x7fL) << shift;        }                return (n >>> 1) ^ -(n & 1);    }    int b = buf[pos++] & 0xff;    int n = b & 0x7f;    long l;    if (b > 0x7f) {        b = buf[pos++] & 0xff;        n ^= (b & 0x7f) << 7;        if (b > 0x7f) {            b = buf[pos++] & 0xff;            n ^= (b & 0x7f) << 14;            if (b > 0x7f) {                b = buf[pos++] & 0xff;                n ^= (b & 0x7f) << 21;                if (b > 0x7f) {                                                            l = innerLongDecode((long) n);                } else {                    l = n;                }            } else {                l = n;            }        } else {            l = n;        }    } else {        l = n;    }    if (pos > limit) {        throw new EOFException();    }        return (l >>> 1) ^ -(l & 1);}
0
private long innerLongDecode(long l) throws IOException
{    int len = 1;    int b = buf[pos] & 0xff;    l ^= (b & 0x7fL) << 28;    if (b > 0x7f) {        b = buf[pos + len++] & 0xff;        l ^= (b & 0x7fL) << 35;        if (b > 0x7f) {            b = buf[pos + len++] & 0xff;            l ^= (b & 0x7fL) << 42;            if (b > 0x7f) {                b = buf[pos + len++] & 0xff;                l ^= (b & 0x7fL) << 49;                if (b > 0x7f) {                    b = buf[pos + len++] & 0xff;                    l ^= (b & 0x7fL) << 56;                    if (b > 0x7f) {                        b = buf[pos + len++] & 0xff;                        l ^= (b & 0x7fL) << 63;                        if (b > 0x7f) {                            throw new IOException("Invalid long encoding");                        }                    }                }            }        }    }    pos += len;    return l;}
0
public float readFloat() throws IOException
{    return Float.intBitsToFloat(readFixed32());}
0
public int readFixed32() throws IOException
{    if (    (limit - pos) < 4)        return read() | (read() << 8) | (read() << 16) | (read() << 24);    int len = 1;    int n = (buf[pos] & 0xff) | ((buf[pos + len++] & 0xff) << 8) | ((buf[pos + len++] & 0xff) << 16) | ((buf[pos + len++] & 0xff) << 24);    if ((pos + 4) > limit)        throw new EOFException();    pos += 4;    return n;}
0
public double readDouble() throws IOException
{    return Double.longBitsToDouble(readFixed64());}
0
public long readFixed64() throws IOException
{    return (readFixed32() & 0xFFFFFFFFL) | (((long) readFixed32()) << 32);}
0
public String readString() throws IOException
{    int length = readInt();    if (length <= (limit - pos)) {                String result = utf8.decode(ByteBuffer.wrap(buf, pos, length)).toString();        pos += length;        return result;    }    byte[] bytes = new byte[length];    readFully(bytes, 0, length);    return utf8.decode(ByteBuffer.wrap(bytes, 0, length)).toString();}
0
public byte[] readBytes() throws IOException
{    byte[] result = new byte[readInt()];    readFully(result);    return result;}
0
public ByteBuffer readBytes(ByteBuffer old) throws IOException
{    int length = readInt();    ByteBuffer result;    if (old != null && length <= old.capacity()) {        result = old;        result.clear();    } else {        result = ByteBuffer.allocate(length);    }    readFully(result.array(), result.position(), length);    result.limit(length);    return result;}
0
public void skipBytes() throws IOException
{    skip(readInt());}
0
private void skip(long length) throws IOException
{    seek(tell() + length);}
0
public int read() throws IOException
{    if (pos >= limit) {        limit = readInput(buf, 0, buf.length);        pos = 0;    }    return buf[pos++] & 0xFF;}
0
public void readFully(byte[] bytes) throws IOException
{    readFully(bytes, 0, bytes.length);}
0
public void readFully(byte[] bytes, int start, int len) throws IOException
{    int buffered = limit - pos;    if (len > buffered) {                        System.arraycopy(buf, pos, bytes, start, buffered);        start += buffered;        len -= buffered;        pos += buffered;        if (len > buf.length) {                        do {                                int read = readInput(bytes, start, len);                len -= read;                start += read;            } while (len > 0);            return;        }                limit = readInput(buf, 0, buf.length);        pos = 0;    }        System.arraycopy(buf, pos, bytes, start, len);    pos += len;}
0
private int readInput(byte[] b, int start, int len) throws IOException
{    int read = in.read(offset, b, start, len);    if (read < 0)        throw new EOFException();    offset += read;    return read;}
0
public long length() throws IOException
{    return this.count;}
0
public synchronized int read(long pos, byte[] b, int start, int len) throws IOException
{    this.pos = (int) pos;    return read(b, start, len);}
0
 byte[] getBuffer()
{    return buf;}
0
public long length() throws IOException
{    return channel.size();}
0
public int read(long position, byte[] b, int start, int len) throws IOException
{    return channel.read(ByteBuffer.wrap(b, start, len), position);}
0
public void close() throws IOException
{    channel.close();}
0
 void setDefaults(MetaData defaults)
{    this.defaults = defaults;}
0
public String getCodec()
{    return getString(CODEC_KEY);}
0
public T setCodec(String codec)
{    setReserved(CODEC_KEY, codec);    return (T) this;}
0
public String getChecksum()
{    return getString(CHECKSUM_KEY);}
0
public T setChecksum(String checksum)
{    setReserved(CHECKSUM_KEY, checksum);    return (T) this;}
0
public String getString(String key)
{    byte[] value = get(key);    if (value == null && defaults != null)        value = defaults.get(key);    if (value == null)        return null;    return new String(value, StandardCharsets.UTF_8);}
0
public long getLong(String key)
{    return Long.parseLong(getString(key));}
0
public boolean getBoolean(String key)
{    return get(key) != null;}
0
public T set(String key, byte[] value)
{    if (isReserved(key)) {        throw new TrevniRuntimeException("Cannot set reserved key: " + key);    }    put(key, value);    return (T) this;}
0
public static boolean isReserved(String key)
{    return key.startsWith(RESERVED_KEY_PREFIX);}
0
public T set(String key, String value)
{    return set(key, value.getBytes(StandardCharsets.UTF_8));}
0
 T setReserved(String key, String value)
{    put(key, value.getBytes(StandardCharsets.UTF_8));    return (T) this;}
0
 T setReservedBoolean(String key, boolean value)
{    if (value)        setReserved(key, "");    else        remove(key);    return (T) this;}
0
public T set(String key, long value)
{    return set(key, Long.toString(value));}
0
 void write(OutputBuffer out) throws IOException
{    out.writeInt(size());    for (Map.Entry<String, byte[]> e : entrySet()) {        out.writeString(e.getKey());        out.writeBytes(e.getValue());    }}
0
 static void read(InputBuffer in, MetaData<?> metaData) throws IOException
{    int size = in.readInt();    for (int i = 0; i < size; i++) metaData.put(in.readString(), in.readBytes());}
0
public String toString()
{    StringBuilder builder = new StringBuilder();    builder.append('{').append(' ');    for (Map.Entry<String, byte[]> e : entrySet()) {        builder.append(e.getKey());        builder.append('=');        builder.append(new String(e.getValue(), StandardCharsets.ISO_8859_1));        builder.append(' ');    }    builder.append('}');    return builder.toString();}
0
public int size()
{    return 0;}
0
public ByteBuffer compute(ByteBuffer data)
{    return ByteBuffer.allocate(0);}
0
 ByteBuffer compress(ByteBuffer buffer) throws IOException
{    return buffer;}
0
 ByteBuffer decompress(ByteBuffer data) throws IOException
{    return data;}
0
public boolean isFull()
{    return size() >= BLOCK_SIZE;}
0
public ByteBuffer asByteBuffer()
{    return ByteBuffer.wrap(buf, 0, count);}
0
public void writeValue(Object value, ValueType type) throws IOException
{    switch(type) {        case NULL:            break;        case BOOLEAN:            writeBoolean((Boolean) value);            break;        case INT:            writeInt((Integer) value);            break;        case LONG:            writeLong((Long) value);            break;        case FIXED32:            writeFixed32((Integer) value);            break;        case FIXED64:            writeFixed64((Long) value);            break;        case FLOAT:            writeFloat((Float) value);            break;        case DOUBLE:            writeDouble((Double) value);            break;        case STRING:            writeString((String) value);            break;        case BYTES:            if (value instanceof ByteBuffer)                writeBytes((ByteBuffer) value);            else                writeBytes((byte[]) value);            break;        default:            throw new TrevniRuntimeException("Unknown value type: " + type);    }}
0
public void writeBoolean(boolean value)
{    if (bitCount == 0) {                ensure(1);        count++;    }    if (value)        buf[count - 1] |= (byte) (1 << bitCount);    bitCount++;    if (bitCount == 8)        bitCount = 0;}
0
public void writeLength(int length) throws IOException
{    bitCount = 0;    writeInt(length);}
0
public void writeString(String string) throws IOException
{    byte[] bytes = string.getBytes(StandardCharsets.UTF_8);    writeInt(bytes.length);    write(bytes, 0, bytes.length);}
0
public void writeBytes(ByteBuffer bytes)
{    int pos = bytes.position();    int start = bytes.arrayOffset() + pos;    int len = bytes.limit() - pos;    writeBytes(bytes.array(), start, len);}
0
public void writeBytes(byte[] bytes)
{    writeBytes(bytes, 0, bytes.length);}
0
public void writeBytes(byte[] bytes, int start, int len)
{    writeInt(len);    write(bytes, start, len);}
0
public void writeFloat(float f) throws IOException
{    writeFixed32(Float.floatToRawIntBits(f));}
0
public void writeDouble(double d) throws IOException
{    writeFixed64(Double.doubleToRawLongBits(d));}
0
public void writeFixed32(int i) throws IOException
{    ensure(4);    buf[count] = (byte) ((i) & 0xFF);    buf[count + 1] = (byte) ((i >>> 8) & 0xFF);    buf[count + 2] = (byte) ((i >>> 16) & 0xFF);    buf[count + 3] = (byte) ((i >>> 24) & 0xFF);    count += 4;}
0
public void writeFixed64(long l) throws IOException
{    ensure(8);    int first = (int) (l & 0xFFFFFFFF);    int second = (int) ((l >>> 32) & 0xFFFFFFFF);    buf[count] = (byte) ((first) & 0xFF);    buf[count + 4] = (byte) ((second) & 0xFF);    buf[count + 5] = (byte) ((second >>> 8) & 0xFF);    buf[count + 1] = (byte) ((first >>> 8) & 0xFF);    buf[count + 2] = (byte) ((first >>> 16) & 0xFF);    buf[count + 6] = (byte) ((second >>> 16) & 0xFF);    buf[count + 7] = (byte) ((second >>> 24) & 0xFF);    buf[count + 3] = (byte) ((first >>> 24) & 0xFF);    count += 8;}
0
public void writeInt(int n)
{    ensure(5);        n = (n << 1) ^ (n >> 31);    if ((n & ~0x7F) != 0) {        buf[count++] = (byte) ((n | 0x80) & 0xFF);        n >>>= 7;        if (n > 0x7F) {            buf[count++] = (byte) ((n | 0x80) & 0xFF);            n >>>= 7;            if (n > 0x7F) {                buf[count++] = (byte) ((n | 0x80) & 0xFF);                n >>>= 7;                if (n > 0x7F) {                    buf[count++] = (byte) ((n | 0x80) & 0xFF);                    n >>>= 7;                }            }        }    }    buf[count++] = (byte) n;}
0
public void writeLong(long n) throws IOException
{    ensure(10);        n = (n << 1) ^ (n >> 63);    if ((n & ~0x7FL) != 0) {        buf[count++] = (byte) ((n | 0x80) & 0xFF);        n >>>= 7;        if (n > 0x7F) {            buf[count++] = (byte) ((n | 0x80) & 0xFF);            n >>>= 7;            if (n > 0x7F) {                buf[count++] = (byte) ((n | 0x80) & 0xFF);                n >>>= 7;                if (n > 0x7F) {                    buf[count++] = (byte) ((n | 0x80) & 0xFF);                    n >>>= 7;                    if (n > 0x7F) {                        buf[count++] = (byte) ((n | 0x80) & 0xFF);                        n >>>= 7;                        if (n > 0x7F) {                            buf[count++] = (byte) ((n | 0x80) & 0xFF);                            n >>>= 7;                            if (n > 0x7F) {                                buf[count++] = (byte) ((n | 0x80) & 0xFF);                                n >>>= 7;                                if (n > 0x7F) {                                    buf[count++] = (byte) ((n | 0x80) & 0xFF);                                    n >>>= 7;                                    if (n > 0x7F) {                                        buf[count++] = (byte) ((n | 0x80) & 0xFF);                                        n >>>= 7;                                    }                                }                            }                        }                    }                }            }        }    }    buf[count++] = (byte) n;}
0
private void ensure(int n)
{    if (count + n > buf.length)        buf = Arrays.copyOf(buf, Math.max(buf.length << 1, count + n));}
0
public static int size(Object value, ValueType type)
{    switch(type) {        case NULL:            return 0;        case INT:            return size((Integer) value);        case LONG:            return size((Long) value);        case FIXED32:        case FLOAT:            return 4;        case FIXED64:        case DOUBLE:            return 8;        case STRING:            return size((String) value);        case BYTES:            if (value instanceof ByteBuffer)                return size((ByteBuffer) value);            return size((byte[]) value);        default:            throw new TrevniRuntimeException("Unknown value type: " + type);    }}
0
public static int size(int n)
{        n = (n << 1) ^ (n >> 31);    if (n <= (1 << (7 * 1)) - 1)        return 1;    if (n <= (1 << (7 * 2)) - 1)        return 2;    if (n <= (1 << (7 * 3)) - 1)        return 3;    if (n <= (1 << (7 * 4)) - 1)        return 4;    return 5;}
0
public static int size(long n)
{        n = (n << 1) ^ (n >> 63);    if (n <= (1 << (7 * 1)) - 1)        return 1;    if (n <= (1 << (7 * 2)) - 1)        return 2;    if (n <= (1 << (7 * 3)) - 1)        return 3;    if (n <= (1 << (7 * 4)) - 1)        return 4;    if (n <= (1 << (7 * 5)) - 1)        return 5;    if (n <= (1 << (7 * 6)) - 1)        return 6;    if (n <= (1 << (7 * 7)) - 1)        return 7;    if (n <= (1 << (7 * 8)) - 1)        return 8;    if (n <= (1 << (7 * 9)) - 1)        return 9;    return 10;}
0
public static int size(ByteBuffer bytes)
{    int length = bytes.remaining();    return size(length) + length;}
0
public static int size(byte[] bytes)
{    int length = bytes.length;    return size(length) + length;}
0
public static int size(String string)
{    int length = utf8Length(string);    return size(length) + length;}
0
private static int utf8Length(String string)
{    int stringLength = string.length();    int utf8Length = 0;    for (int i = 0; i < stringLength; i++) {        char c = string.charAt(i);                int p = c;        if (        Character.isHighSurrogate(c) && i != stringLength - 1 && Character.isLowSurrogate(string.charAt(i + 1))) {            p = string.codePointAt(i);            i++;        }        if (p <= 0x007F) {            utf8Length += 1;        } else if (p <= 0x07FF) {            utf8Length += 2;        } else if (p <= 0x0FFFF) {            utf8Length += 3;        } else if (p <= 0x01FFFFF) {            utf8Length += 4;        } else if (p <= 0x03FFFFFF) {            utf8Length += 5;        } else {            utf8Length += 6;        }    }    return utf8Length;}
0
 ByteBuffer compress(ByteBuffer in) throws IOException
{    ByteBuffer out = ByteBuffer.allocate(Snappy.maxCompressedLength(in.remaining()));    int size = Snappy.compress(in.array(), in.position(), in.remaining(), out.array(), 0);    out.limit(size);    return out;}
0
 ByteBuffer decompress(ByteBuffer in) throws IOException
{    ByteBuffer out = ByteBuffer.allocate(Snappy.uncompressedLength(in.array(), in.position(), in.remaining()));    int size = Snappy.uncompress(in.array(), in.position(), in.remaining(), out.array(), 0);    out.limit(size);    return out;}
0
public String getName()
{    return name;}
0
public static ValueType forName(String name)
{    return valueOf(name.toUpperCase());}
0
public void testBZip2CompressionAndDecompression() throws IOException
{    MetaData meta = new MetaData();    meta.setCodec("bzip2");    Codec codec = Codec.get(meta);        assertTrue(codec instanceof BZip2Codec);        final int inputByteSize = BZip2Codec.DEFAULT_BUFFER_SIZE * 3 + 42;    byte[] inputByteArray = new byte[inputByteSize];        for (int i = 0; i < inputByteSize; i++) {        inputByteArray[i] = (byte) (65 + i % 10);    }    ByteBuffer inputByteBuffer = ByteBuffer.wrap(inputByteArray);    ByteBuffer compressedBuffer = codec.compress(inputByteBuffer);        assertTrue(compressedBuffer.array().length > 0);        assertTrue(compressedBuffer.array().length < inputByteArray.length);    ByteBuffer decompressedBuffer = codec.decompress(compressedBuffer);        assertTrue(decompressedBuffer.array().length == inputByteArray.length);        byte[] outputByteArray = decompressedBuffer.array();    System.arraycopy(outputByteArray, 0, inputByteArray, 0, inputByteSize);}
0
public static Collection<Object[]> codecs()
{    Object[][] data = new Object[][] { { "null", "null" }, { "snappy", "crc32" }, { "deflate", "crc32" } };    return Arrays.asList(data);}
0
private ColumnFileMetaData createFileMeta()
{    return new ColumnFileMetaData().setCodec(codec).setChecksum(checksum);}
0
public void testEmptyFile() throws Exception
{    FILE.delete();    ColumnFileWriter out = new ColumnFileWriter(createFileMeta());    out.writeTo(FILE);    ColumnFileReader in = new ColumnFileReader(FILE);    Assert.assertEquals(0, in.getRowCount());    Assert.assertEquals(0, in.getColumnCount());    in.close();}
0
public void testEmptyColumn() throws Exception
{    FILE.delete();    ColumnFileWriter out = new ColumnFileWriter(createFileMeta(), new ColumnMetaData("test", ValueType.INT));    out.writeTo(FILE);    ColumnFileReader in = new ColumnFileReader(FILE);    Assert.assertEquals(0, in.getRowCount());    Assert.assertEquals(1, in.getColumnCount());    ColumnValues<Integer> values = in.getValues("test");    for (int i : values) throw new Exception("no value should be found");    in.close();}
0
public void testInts() throws Exception
{    FILE.delete();    ColumnFileWriter out = new ColumnFileWriter(createFileMeta(), new ColumnMetaData("test", ValueType.INT));    Random random = TestUtil.createRandom();    for (int i = 0; i < COUNT; i++) out.writeRow(TestUtil.randomLength(random));    out.writeTo(FILE);    random = TestUtil.createRandom();    ColumnFileReader in = new ColumnFileReader(FILE);    Assert.assertEquals(COUNT, in.getRowCount());    Assert.assertEquals(1, in.getColumnCount());    Iterator<Integer> i = in.getValues("test");    int count = 0;    while (i.hasNext()) {        Assert.assertEquals(TestUtil.randomLength(random), (int) i.next());        count++;    }    Assert.assertEquals(COUNT, count);}
0
public void testLongs() throws Exception
{    FILE.delete();    ColumnFileWriter out = new ColumnFileWriter(createFileMeta(), new ColumnMetaData("test", ValueType.LONG));    Random random = TestUtil.createRandom();    for (int i = 0; i < COUNT; i++) out.writeRow(random.nextLong());    out.writeTo(FILE);    random = TestUtil.createRandom();    ColumnFileReader in = new ColumnFileReader(FILE);    Assert.assertEquals(COUNT, in.getRowCount());    Assert.assertEquals(1, in.getColumnCount());    Iterator<Long> i = in.getValues("test");    int count = 0;    while (i.hasNext()) {        Assert.assertEquals(random.nextLong(), (long) i.next());        count++;    }    Assert.assertEquals(COUNT, count);}
0
public void testStrings() throws Exception
{    FILE.delete();    ColumnFileWriter out = new ColumnFileWriter(createFileMeta(), new ColumnMetaData("test", ValueType.STRING));    Random random = TestUtil.createRandom();    for (int i = 0; i < COUNT; i++) out.writeRow(TestUtil.randomString(random));    out.writeTo(FILE);    random = TestUtil.createRandom();    ColumnFileReader in = new ColumnFileReader(FILE);    Assert.assertEquals(COUNT, in.getRowCount());    Assert.assertEquals(1, in.getColumnCount());    Iterator<String> i = in.getValues("test");    int count = 0;    while (i.hasNext()) {        Assert.assertEquals(TestUtil.randomString(random), i.next());        count++;    }    Assert.assertEquals(COUNT, count);}
0
public void testTwoColumn() throws Exception
{    FILE.delete();    ColumnFileWriter out = new ColumnFileWriter(createFileMeta(), new ColumnMetaData("a", ValueType.FIXED32), new ColumnMetaData("b", ValueType.STRING));    Random random = TestUtil.createRandom();    for (int i = 0; i < COUNT; i++) out.writeRow(random.nextInt(), TestUtil.randomString(random));    out.writeTo(FILE);    random = TestUtil.createRandom();    ColumnFileReader in = new ColumnFileReader(FILE);    Assert.assertEquals(COUNT, in.getRowCount());    Assert.assertEquals(2, in.getColumnCount());    Iterator<String> i = in.getValues("a");    Iterator<String> j = in.getValues("b");    int count = 0;    while (i.hasNext() && j.hasNext()) {        Assert.assertEquals(random.nextInt(), i.next());        Assert.assertEquals(TestUtil.randomString(random), j.next());        count++;    }    Assert.assertEquals(COUNT, count);}
0
public void testSeekLongs() throws Exception
{    FILE.delete();    ColumnFileWriter out = new ColumnFileWriter(createFileMeta(), new ColumnMetaData("test", ValueType.LONG));    Random random = TestUtil.createRandom();    int seekCount = COUNT / 1024;    int[] seekRows = new int[seekCount];    Map<Integer, Integer> seekRowMap = new HashMap<>(seekCount);    while (seekRowMap.size() < seekCount) {        int row = random.nextInt(COUNT);        if (!seekRowMap.containsKey(row)) {            seekRows[seekRowMap.size()] = row;            seekRowMap.put(row, seekRowMap.size());        }    }    Long[] seekValues = new Long[seekCount];    for (int i = 0; i < COUNT; i++) {        long l = random.nextLong();        out.writeRow(l);        if (seekRowMap.containsKey(i))            seekValues[seekRowMap.get(i)] = l;    }    out.writeTo(FILE);    ColumnFileReader in = new ColumnFileReader(FILE);    ColumnValues<Long> v = in.getValues("test");    for (int i = 0; i < seekCount; i++) {        v.seek(seekRows[i]);        Assert.assertEquals(seekValues[i], v.next());    }}
0
public void testSeekStrings() throws Exception
{    FILE.delete();    ColumnFileWriter out = new ColumnFileWriter(createFileMeta(), new ColumnMetaData("test", ValueType.STRING).hasIndexValues(true));    Random random = TestUtil.createRandom();    int seekCount = COUNT / 1024;    Map<Integer, Integer> seekRowMap = new HashMap<>(seekCount);    while (seekRowMap.size() < seekCount) {        int row = random.nextInt(COUNT);        if (!seekRowMap.containsKey(row))            seekRowMap.put(row, seekRowMap.size());    }    String[] values = new String[COUNT];    for (int i = 0; i < COUNT; i++) values[i] = TestUtil.randomString(random);    Arrays.sort(values);    String[] seekValues = new String[seekCount];    for (int i = 0; i < COUNT; i++) {        out.writeRow(values[i]);        if (seekRowMap.containsKey(i))            seekValues[seekRowMap.get(i)] = values[i];    }    out.writeTo(FILE);    ColumnFileReader in = new ColumnFileReader(FILE);    ColumnValues<String> v = in.getValues("test");    for (int i = 0; i < seekCount; i++) {        v.seek(seekValues[i]);        Assert.assertEquals(seekValues[i], v.next());    }}
0
public void testRandomReads() throws Exception
{    Random random = new Random(19820210);    int length = random.nextInt(SIZE) + 1;    byte[] data = new byte[length];    random.nextBytes(data);    Input in = new InputBytes(data);    for (int i = 0; i < COUNT; i++) {        int p = random.nextInt(length);        int l = Math.min(random.nextInt(SIZE / 10), length - p);        byte[] buffer = new byte[l];        in.read(p, buffer, 0, l);        Assert.assertArrayEquals(Arrays.copyOfRange(data, p, p + l), buffer);    }}
0
public void testEmpty() throws Exception
{    OutputBuffer out = new OutputBuffer();    ByteArrayOutputStream temp = new ByteArrayOutputStream();    InputBuffer in = new InputBuffer(new InputBytes(out.toByteArray()));    Assert.assertEquals(0, in.tell());    Assert.assertEquals(0, in.length());}
0
public void testZero() throws Exception
{    Random random = TestUtil.createRandom();    OutputBuffer out = new OutputBuffer();    out.writeInt(0);    byte[] bytes = out.toByteArray();    Assert.assertEquals(1, bytes.length);    Assert.assertEquals(0, bytes[0]);    InputBuffer in = new InputBuffer(new InputBytes(out.toByteArray()));    Assert.assertEquals(0, in.readInt());}
0
public void testBoolean() throws Exception
{    Random random = TestUtil.createRandom();    OutputBuffer out = new OutputBuffer();    for (int i = 0; i < COUNT; i++) out.writeValue(random.nextBoolean(), ValueType.BOOLEAN);    InputBuffer in = new InputBuffer(new InputBytes(out.toByteArray()));    random = TestUtil.createRandom();    for (int i = 0; i < COUNT; i++) Assert.assertEquals(random.nextBoolean(), in.readValue(ValueType.BOOLEAN));}
0
public void testInt() throws Exception
{    Random random = TestUtil.createRandom();    OutputBuffer out = new OutputBuffer();    for (int i = 0; i < COUNT; i++) out.writeInt(random.nextInt());    InputBuffer in = new InputBuffer(new InputBytes(out.toByteArray()));    random = TestUtil.createRandom();    for (int i = 0; i < COUNT; i++) Assert.assertEquals(random.nextInt(), in.readInt());}
0
public void testLong() throws Exception
{    Random random = TestUtil.createRandom();    OutputBuffer out = new OutputBuffer();    for (int i = 0; i < COUNT; i++) out.writeLong(random.nextLong());    InputBuffer in = new InputBuffer(new InputBytes(out.toByteArray()));    random = TestUtil.createRandom();    for (int i = 0; i < COUNT; i++) Assert.assertEquals(random.nextLong(), in.readLong());}
0
public void testFixed32() throws Exception
{    Random random = TestUtil.createRandom();    OutputBuffer out = new OutputBuffer();    for (int i = 0; i < COUNT; i++) out.writeFixed32(random.nextInt());    InputBuffer in = new InputBuffer(new InputBytes(out.toByteArray()));    random = TestUtil.createRandom();    for (int i = 0; i < COUNT; i++) Assert.assertEquals(random.nextInt(), in.readFixed32());}
0
public void testFixed64() throws Exception
{    Random random = TestUtil.createRandom();    OutputBuffer out = new OutputBuffer();    for (int i = 0; i < COUNT; i++) out.writeFixed64(random.nextLong());    InputBuffer in = new InputBuffer(new InputBytes(out.toByteArray()));    random = TestUtil.createRandom();    for (int i = 0; i < COUNT; i++) Assert.assertEquals(random.nextLong(), in.readFixed64());}
0
public void testFloat() throws Exception
{    Random random = TestUtil.createRandom();    OutputBuffer out = new OutputBuffer();    for (int i = 0; i < COUNT; i++) out.writeFloat(random.nextFloat());    InputBuffer in = new InputBuffer(new InputBytes(out.toByteArray()));    random = TestUtil.createRandom();    for (int i = 0; i < COUNT; i++) Assert.assertEquals(random.nextFloat(), in.readFloat(), 0);}
0
public void testDouble() throws Exception
{    OutputBuffer out = new OutputBuffer();    for (int i = 0; i < COUNT; i++) out.writeDouble(Double.MIN_VALUE);    InputBuffer in = new InputBuffer(new InputBytes(out.toByteArray()));    for (int i = 0; i < COUNT; i++) Assert.assertEquals(Double.MIN_VALUE, in.readDouble(), 0);}
0
public void testBytes() throws Exception
{    Random random = TestUtil.createRandom();    OutputBuffer out = new OutputBuffer();    for (int i = 0; i < COUNT; i++) out.writeBytes(TestUtil.randomBytes(random));    InputBuffer in = new InputBuffer(new InputBytes(out.toByteArray()));    random = TestUtil.createRandom();    for (int i = 0; i < COUNT; i++) Assert.assertEquals(TestUtil.randomBytes(random), in.readBytes(null));}
0
public void testString() throws Exception
{    Random random = TestUtil.createRandom();    OutputBuffer out = new OutputBuffer();    for (int i = 0; i < COUNT; i++) out.writeString(TestUtil.randomString(random));    InputBuffer in = new InputBuffer(new InputBytes(out.toByteArray()));    random = TestUtil.createRandom();    for (int i = 0; i < COUNT; i++) Assert.assertEquals(TestUtil.randomString(random), in.readString());}
0
public void testSkipNull() throws Exception
{    long sentinel = Long.MAX_VALUE;    OutputBuffer out = new OutputBuffer();    out.writeValue(null, ValueType.NULL);    out.writeLong(sentinel);    InputBuffer in = new InputBuffer(new InputBytes(out.toByteArray()));    in.skipValue(ValueType.NULL);    Assert.assertEquals(sentinel, in.readLong());}
0
public void testSkipBoolean() throws Exception
{    long sentinel = Long.MAX_VALUE;    OutputBuffer out = new OutputBuffer();    out.writeValue(false, ValueType.BOOLEAN);    out.writeLong(sentinel);    InputBuffer in = new InputBuffer(new InputBytes(out.toByteArray()));    in.skipValue(ValueType.BOOLEAN);    Assert.assertEquals(sentinel, in.readLong());}
0
public void testSkipInt() throws Exception
{    long sentinel = Long.MAX_VALUE;    OutputBuffer out = new OutputBuffer();    out.writeValue(Integer.MAX_VALUE, ValueType.INT);    out.writeLong(sentinel);    InputBuffer in = new InputBuffer(new InputBytes(out.toByteArray()));    in.skipValue(ValueType.INT);    Assert.assertEquals(sentinel, in.readLong());}
0
public void testSkipLong() throws Exception
{    long sentinel = Long.MAX_VALUE;    OutputBuffer out = new OutputBuffer();    out.writeValue(Long.MAX_VALUE, ValueType.LONG);    out.writeLong(sentinel);    InputBuffer in = new InputBuffer(new InputBytes(out.toByteArray()));    in.skipValue(ValueType.LONG);    Assert.assertEquals(sentinel, in.readLong());}
0
public void testSkipFixed32() throws Exception
{    long sentinel = Long.MAX_VALUE;    OutputBuffer out = new OutputBuffer();    out.writeValue(Integer.MAX_VALUE, ValueType.FIXED32);    out.writeLong(sentinel);    InputBuffer in = new InputBuffer(new InputBytes(out.toByteArray()));    in.skipValue(ValueType.LONG);    Assert.assertEquals(sentinel, in.readLong());}
0
public void testSkipFixed64() throws Exception
{    long sentinel = Long.MAX_VALUE;    OutputBuffer out = new OutputBuffer();    out.writeValue(Long.MAX_VALUE, ValueType.FIXED64);    out.writeLong(sentinel);    InputBuffer in = new InputBuffer(new InputBytes(out.toByteArray()));    in.skipValue(ValueType.LONG);    Assert.assertEquals(sentinel, in.readLong());}
0
public void testSkipFloat() throws Exception
{    long sentinel = Long.MAX_VALUE;    OutputBuffer out = new OutputBuffer();    out.writeValue(Float.MAX_VALUE, ValueType.FLOAT);    out.writeLong(sentinel);    InputBuffer in = new InputBuffer(new InputBytes(out.toByteArray()));    in.skipValue(ValueType.FLOAT);    Assert.assertEquals(sentinel, in.readLong());}
0
public void testSkipDouble() throws Exception
{    long sentinel = Long.MAX_VALUE;    OutputBuffer out = new OutputBuffer();    out.writeValue(Double.MAX_VALUE, ValueType.DOUBLE);    out.writeLong(sentinel);    InputBuffer in = new InputBuffer(new InputBytes(out.toByteArray()));    in.skipValue(ValueType.DOUBLE);    Assert.assertEquals(sentinel, in.readLong());}
0
public void testSkipString() throws Exception
{    long sentinel = Long.MAX_VALUE;    OutputBuffer out = new OutputBuffer();    out.writeValue("trevni", ValueType.STRING);    out.writeLong(sentinel);    InputBuffer in = new InputBuffer(new InputBytes(out.toByteArray()));    in.skipValue(ValueType.STRING);    Assert.assertEquals(sentinel, in.readLong());}
0
public void testSkipBytes() throws Exception
{    long sentinel = Long.MAX_VALUE;    OutputBuffer out = new OutputBuffer();    out.writeValue("trevni".getBytes(UTF_8), ValueType.BYTES);    out.writeLong(sentinel);    InputBuffer in = new InputBuffer(new InputBytes(out.toByteArray()));    in.skipValue(ValueType.BYTES);    Assert.assertEquals(sentinel, in.readLong());}
0
public void testInitPos() throws Exception
{    long sentinel = Long.MAX_VALUE;    OutputBuffer out = new OutputBuffer();    out.writeValue(Integer.MAX_VALUE, ValueType.INT);    out.writeLong(sentinel);    InputBuffer in = new InputBuffer(new InputBytes(out.toByteArray()));    in.readInt();    long pos = in.tell();    in = new InputBuffer(new InputBytes(out.toByteArray()), pos);    Assert.assertEquals(sentinel, in.readLong());}
0
public static long getRandomSeed()
{    if (!seedSet) {        String configured = System.getProperty("test.seed");        if (configured != null)            seed = Long.valueOf(configured);        else            seed = System.currentTimeMillis();        System.err.println("test.seed=" + seed);        seedSet = true;    }    return seed;}
0
public static void resetRandomSeed()
{    seedSet = false;}
0
public static Random createRandom()
{    return new Random(getRandomSeed());}
0
public static ByteBuffer randomBytes(Random random)
{    byte[] bytes = new byte[randomLength(random)];    random.nextBytes(bytes);    return ByteBuffer.wrap(bytes);}
0
public static String randomString(Random random)
{    int length = randomLength(random);    char[] chars = new char[length];    for (int i = 0; i < length; i++) chars[i] = (char) ('a' + random.nextInt('z' - 'a'));    return new String(chars);}
0
public static int randomLength(Random random)
{    int n = random.nextInt();    if (n < 0)        n = -n;    return n & ((n & 0xF0000) != 0 ? 0xF : ((n & 0xFF0000) != 0 ? 0xFF : ((n & 0xFFF0000) != 0 ? 0xFFF : 0xFFFF)));}
0
public void testRandomLength()
{    long total = 0;    int count = 1024 * 1024;    int min = Short.MAX_VALUE;    int max = 0;    Random r = createRandom();    for (int i = 0; i < count; i++) {        int length = randomLength(r);        if (min > length)            min = length;        if (max < length)            max = length;        total += length;    }    Assert.assertEquals(0, min);    Assert.assertTrue(max > 1024 * 32);    float average = total / (float) count;    Assert.assertTrue(average > 16.0f);    Assert.assertTrue(average < 64.0f);}
0
